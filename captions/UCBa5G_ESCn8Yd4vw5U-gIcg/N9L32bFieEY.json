[
  {
    "start": "0",
    "end": "5380"
  },
  {
    "text": "Hello, everyone. My name is Lisa. I'm a third year PhD\nstudent in the NLP group.",
    "start": "5380",
    "end": "10540"
  },
  {
    "text": "I'm advised by Percy and Tatsu. Today, I will give a lecture\non natural language generation.",
    "start": "10540",
    "end": "16250"
  },
  {
    "text": "And this is also the\nresearch area that I work on, so I'm super excited about it. And I'm happy to\nanswer any questions,",
    "start": "16250",
    "end": "22060"
  },
  {
    "text": "both during the lecture\nand after class, about natural\nlanguage generation. So NLG is a super\nexciting area and is also",
    "start": "22060",
    "end": "30190"
  },
  {
    "text": "moving really, really fast. So today, we will discuss\nall the excitement of NLG.",
    "start": "30190",
    "end": "36070"
  },
  {
    "text": "But before we get into\nthe really exciting part, I have to make\nsome announcements. So first, it is\nvery, very important",
    "start": "36070",
    "end": "43030"
  },
  {
    "text": "for you to remember to sign\nup for AWS by midnight today. So this will concern--",
    "start": "43030",
    "end": "49150"
  },
  {
    "text": "this is related to our homework\n5, whether you have GPU access, and then also related\nto your final project.",
    "start": "49150",
    "end": "54920"
  },
  {
    "text": "So please, please remember to\nsign up for AWS by tonight. And second, the\nproject proposal is",
    "start": "54920",
    "end": "62500"
  },
  {
    "text": "due on Tuesday, next Tuesday. And I think assignment\n4 is just due.",
    "start": "62500",
    "end": "68950"
  },
  {
    "text": "Hopefully, you had fun with\nmachine translation and stuff. And also, assignment 5 is\nout today, I think just now.",
    "start": "68950",
    "end": "76930"
  },
  {
    "text": "And it is due on Friday, like,\nbasically Friday midnight. And last, we will\nhold a transformer--",
    "start": "76930",
    "end": "85810"
  },
  {
    "text": "we'll hold a Hugging\nFace transformer library tutorial this Friday. So if your final\nproject is related",
    "start": "85810",
    "end": "92500"
  },
  {
    "text": "to implementing transformers\nor playing with large language models, you should definitely\ngo to this tutorial because it's going to\nbe very, very helpful.",
    "start": "92500",
    "end": "100060"
  },
  {
    "text": "Also, yeah, just one\nmore time, please remember to sign up\nfor AWS because this is the final hard deadline.",
    "start": "100060",
    "end": "107710"
  },
  {
    "text": "OK, cool, now moving\non to the main topic for today, the very exciting\nnatural language generation",
    "start": "107710",
    "end": "113530"
  },
  {
    "text": "stuff. So today, we will discuss, what\nis NLG, review some models, discuss about how to\ndecode from language models",
    "start": "113530",
    "end": "121030"
  },
  {
    "text": "and how to train\nlanguage models, and we will also talk\nabout evaluations.",
    "start": "121030",
    "end": "126110"
  },
  {
    "text": "And finally, we'll discuss\nethical and risk considerations with the current NLG systems.",
    "start": "126110",
    "end": "131210"
  },
  {
    "text": "So these natural language\ngeneration techniques are going to be really\nexciting because this",
    "start": "131210",
    "end": "136370"
  },
  {
    "text": "is kind of getting us closer to\nexplain the magic of ChatGPT, which is a super\npopular model recently.",
    "start": "136370",
    "end": "142459"
  },
  {
    "text": "And practically\nspeaking, they could also help you with your\nfinal project if you decide to work on something\nrelated to text generation.",
    "start": "142460",
    "end": "149220"
  },
  {
    "text": "So let's get started. To begin with, let's\nask the question of, what is natural\nlanguage generation?",
    "start": "149220",
    "end": "155959"
  },
  {
    "text": "So natural language\ngeneration is actually a really broad category. People have divided NLP into\nnatural language understanding",
    "start": "155960",
    "end": "164180"
  },
  {
    "text": "and natural language generation. So the understanding\npart mostly means that the task input is\nin natural language,",
    "start": "164180",
    "end": "170960"
  },
  {
    "text": "such as semantic parsing,\nnatural language inference, and so on. Whereas, natural\nlanguage generation",
    "start": "170960",
    "end": "177800"
  },
  {
    "text": "means that the task output\nis in natural language. So NLG focuses on\nsystems that produce",
    "start": "177800",
    "end": "184700"
  },
  {
    "text": "fluent, coherent,\nand useful language outputs for humans to use.",
    "start": "184700",
    "end": "189830"
  },
  {
    "text": "Historically, there\nare many NLG systems that use rule-based systems\nsuch as templates or infilling.",
    "start": "189830",
    "end": "196910"
  },
  {
    "text": "But nowadays, deep learning\nis powering almost every text generation systems.",
    "start": "196910",
    "end": "202130"
  },
  {
    "text": "So this lecture today\nwill be mostly focused on deep learning stuff.",
    "start": "202130",
    "end": "207719"
  },
  {
    "text": "So first, what are some examples\nof natural language generation? It's actually everywhere,\nincluding our homework.",
    "start": "207720",
    "end": "214520"
  },
  {
    "text": "Machine translation\nis a form of NLG where the input is some\nutterance in the source",
    "start": "214520",
    "end": "219590"
  },
  {
    "text": "language and the\noutput is generated text in a target language. Digital assistants,\nsuch as Siri or Alexa,",
    "start": "219590",
    "end": "227510"
  },
  {
    "text": "they are also NLG systems. So it takes in-dialogue history\nand generates continuations",
    "start": "227510",
    "end": "233060"
  },
  {
    "text": "of the conversation. There is also\nsummarization systems that take in a long document,\nsuch as a research article,",
    "start": "233060",
    "end": "241220"
  },
  {
    "text": "and then the idea is\ntrying to summarize it into a few sentences\nthat are easy to read.",
    "start": "241220",
    "end": "247190"
  },
  {
    "text": "So beyond this\nclassic tasks, there are some more interesting uses\nlike creative story writing",
    "start": "247190",
    "end": "253269"
  },
  {
    "text": "where you can prompt a language\nmodel with a story plot, and then it will give\nyou some creative stories",
    "start": "253270",
    "end": "258819"
  },
  {
    "text": "that are aligned with the plot. There is data to text where\nyou give the language model some database or some tables.",
    "start": "258820",
    "end": "265540"
  },
  {
    "text": "And then the idea\nis that it will output some textual description\nof the table content.",
    "start": "265540",
    "end": "270620"
  },
  {
    "text": "And finally, there is also,\nlike, visual description based on our systems\nlike image captioning",
    "start": "270620",
    "end": "275920"
  },
  {
    "text": "or like image-based\nstorytelling. So the really cool example is\nthe popular ChatGPT models,",
    "start": "275920",
    "end": "285580"
  },
  {
    "text": "so ChatGPT is also\nan NLG system. It is very general\npurpose, so therefore, you",
    "start": "285580",
    "end": "291520"
  },
  {
    "text": "can use it to do many different\ntasks with different prompts. For example, we can use\nChatGPT to simulate a chat bot.",
    "start": "291520",
    "end": "300850"
  },
  {
    "text": "It can answer questions about,\nlike, creative gifts for 10 years old. It can be used to do\npoetry generation,",
    "start": "300850",
    "end": "308500"
  },
  {
    "text": "like for example, we\ncan ask it to generate a poem about sorting algorithms. And it's actually-- well, I\nwouldn't say it's very poetic,",
    "start": "308500",
    "end": "316060"
  },
  {
    "text": "but at least, it has the\nsame format as a poem and the content is\nactually correct.",
    "start": "316060",
    "end": "322400"
  },
  {
    "text": "So ChatGPT can also be used\nin some really useful settings",
    "start": "322400",
    "end": "327820"
  },
  {
    "text": "like web search. So here, Bing is\naugmented with ChatGPT, and there are some\nTwitter threads",
    "start": "327820",
    "end": "333370"
  },
  {
    "text": "saying that the magic of ChatGPT\nis that it actually makes people be happy to use Bing.",
    "start": "333370",
    "end": "338633"
  },
  {
    "text": "[LAUGHTER]  So there are so many\ntasks that actually",
    "start": "338633",
    "end": "344440"
  },
  {
    "text": "belong to the NLG category. So how do we\ncategorize these tasks? One common way is to think about\nthe open-endedness of the task.",
    "start": "344440",
    "end": "352250"
  },
  {
    "text": "So here, we draw a line for\nthe spectrum of open-endedness. On the one end, we have tasks\nlike machine translation",
    "start": "352250",
    "end": "359500"
  },
  {
    "text": "and summarization, so we\nconsider them not very open ended because for\neach source sentence,",
    "start": "359500",
    "end": "365660"
  },
  {
    "text": "the output is almost\ndetermined by the input. Because, basically,\nwe are trying",
    "start": "365660",
    "end": "370730"
  },
  {
    "text": "to do machine\ntranslation, the semantics should be exactly similar\nto the input sentence. So there are only\na few ways that you",
    "start": "370730",
    "end": "377390"
  },
  {
    "text": "can rephrase the\noutput, like authorities have announced that today\nis a national holiday. You can rephrase it\na little bit to say,",
    "start": "377390",
    "end": "383930"
  },
  {
    "text": "today is a national holiday\nannounced by the authorities. But the actual space\nis really small",
    "start": "383930",
    "end": "389360"
  },
  {
    "text": "because you have to make sure\nthe semantics doesn't change. So we can say that the output\nspace here is not very diverse.",
    "start": "389360",
    "end": "397670"
  },
  {
    "text": "And moving to the\nmiddle of the spectrum, there is dialogue tasks\nsuch as task-driven dialogue",
    "start": "397670",
    "end": "402920"
  },
  {
    "text": "or chitchat dialogue. So we can see that for\neach dialogue input, there are multiple responses\nand the degree of freedom",
    "start": "402920",
    "end": "409730"
  },
  {
    "text": "has increased. Here we can say-- we can respond by\nsaying good, and you? Or we can say about,\nthanks for asking.",
    "start": "409730",
    "end": "417110"
  },
  {
    "text": "Barely surviving\nall my homeworks. So here, we are observing\nthat there are actually multiple ways to continue\nthis conversation.",
    "start": "417110",
    "end": "424520"
  },
  {
    "text": "And then this is where we\nsay the output space is getting more and more diverse. And on the other\nend of the spectrum,",
    "start": "424520",
    "end": "432240"
  },
  {
    "text": "there is the very\nopen-ended generation tasks like story generation. So given the input like\nwrite me a story about three",
    "start": "432240",
    "end": "439100"
  },
  {
    "text": "little pigs, there\nare so many ways to continue the\nprompt, like we can write about them going to\nschools, building houses,",
    "start": "439100",
    "end": "445280"
  },
  {
    "text": "like they always do. So the valid output\nhere is extremely large, and we call this\nopen-ended generation.",
    "start": "445280",
    "end": "453590"
  },
  {
    "text": "So it's hard to\nreally draw a boundary between open-ended and\nnon-open-ended tasks, but we still try to give\na rough categorization.",
    "start": "453590",
    "end": "461340"
  },
  {
    "text": "So open-ended generation\nrefers to tasks whose output distribution\nhas a high degree of freedom",
    "start": "461340",
    "end": "467300"
  },
  {
    "text": "or non-open-ended\ngeneration tasks refers to tasks where the input\nwill almost certainly determine",
    "start": "467300",
    "end": "475039"
  },
  {
    "text": "the output generation. Examples of\nnon-open-ended generations are machine translation\nsummarization.",
    "start": "475040",
    "end": "481160"
  },
  {
    "text": "And examples of\nopen-ended generations are story generation,\nchitchat dialogue, task-oriented\ndialogue, et cetera.",
    "start": "481160",
    "end": "488690"
  },
  {
    "text": "So how do we formalize\nthis categorization? One way of formalizing\nis by computing the entropy of an NLG system.",
    "start": "488690",
    "end": "495629"
  },
  {
    "text": "So high entropy\nmeans that we are to the right of the spectrum. So it is more open-ended.",
    "start": "495630",
    "end": "502220"
  },
  {
    "text": "And low entropy means that we\nare to the left of the spectrum and less open-ended. So there's two\nclasses of NLG tasks",
    "start": "502220",
    "end": "510080"
  },
  {
    "text": "actually require different\ndecoding and training approaches, as we\nwill talk about later.",
    "start": "510080",
    "end": "516620"
  },
  {
    "text": "OK, cool, now let's recall\nsome previous lectures and review the NLG\nmodels and trainings",
    "start": "516620",
    "end": "522199"
  },
  {
    "text": "that we have studied before. So I think we discussed the\nbasics of natural language",
    "start": "522200",
    "end": "527630"
  },
  {
    "text": "generation. So here is how autoregressive\nlanguage model works. At each time step,\nour model would",
    "start": "527630",
    "end": "533509"
  },
  {
    "text": "take in a sequence\nof tokens as input. And here, it is y less than t.",
    "start": "533510",
    "end": "538550"
  },
  {
    "text": "And the output is\nbasically the new token yt. So to decide on yt,\nwe first use the model",
    "start": "538550",
    "end": "546170"
  },
  {
    "text": "to assign a score for each\ntoken in the vocabulary, denoted as s. And then we apply softmax to get\nthe next token distribution p,",
    "start": "546170",
    "end": "554570"
  },
  {
    "text": "and we choose a\ntoken according to this next token distribution. And similarly, once we\nhave predicted yt hat,",
    "start": "554570",
    "end": "561589"
  },
  {
    "text": "we then pass it back into the\nlanguage model as the input, predicted byt hat t plus 1.",
    "start": "561590",
    "end": "566660"
  },
  {
    "text": "And then we do so recursively\nuntil we've reached the end of the sequence.",
    "start": "566660",
    "end": "571670"
  },
  {
    "text": "So any questions so far? OK, good.",
    "start": "571670",
    "end": "577550"
  },
  {
    "text": "So for the two types of NLG\ntasks that we talked about, the open-ended and\nnon-open-ended tasks,",
    "start": "577550",
    "end": "583490"
  },
  {
    "text": "they tend to prefer different\nmodel architectures. So for now, open-ended tasks\nlike machine translation,",
    "start": "583490",
    "end": "589550"
  },
  {
    "text": "we typically use an\nencoder-decoder system, where the autoregressive\ndecoder that we just talked",
    "start": "589550",
    "end": "595400"
  },
  {
    "text": "about functions as the decoder. And then we have another\nbidirectional encoder for encoding the inputs.",
    "start": "595400",
    "end": "600899"
  },
  {
    "text": "So this is kind of what you\nimplemented for assignment 4 because the encoder is like\nthe bidirectional LSTM,",
    "start": "600900",
    "end": "607880"
  },
  {
    "text": "and the decoder is another\nLSTM that is autoregressive. So for more open-ended\ntasks, typically,",
    "start": "607880",
    "end": "615020"
  },
  {
    "text": "autoregressive generation\nmodel is the only component.",
    "start": "615020",
    "end": "620870"
  },
  {
    "text": "Of course, these architectures\nare not really hard constraints because an autoregressive\ndecoder alone can also be",
    "start": "620870",
    "end": "627350"
  },
  {
    "text": "used to do machine translation. And an encoder-decoder\nmodel can also be used for storage generation.",
    "start": "627350",
    "end": "632900"
  },
  {
    "text": "So this is kind of the\nconvention for now, but it's a reasonable\nconvention because using",
    "start": "632900",
    "end": "638540"
  },
  {
    "text": "decoder-only model for MT\ntends to hurt performance compared to an\nencoder-decoder model for MT.",
    "start": "638540",
    "end": "644930"
  },
  {
    "text": "And using an encoder-decoder\nmodel for open-ended generation seems to achieve\nsimilar performance",
    "start": "644930",
    "end": "650540"
  },
  {
    "text": "to a decoder-only model. And therefore, if you\nhave the compute budget to train an\nencoder-decoder model,",
    "start": "650540",
    "end": "656120"
  },
  {
    "text": "you might just be better off by\nonly training a larger decoder model. So it's kind of more of an\nallocation of resources problem",
    "start": "656120",
    "end": "662779"
  },
  {
    "text": "than whether this architecture\nwill typecheck with our task. ",
    "start": "662780",
    "end": "670100"
  },
  {
    "text": "OK, so how do we train\nsuch a language model? In previous lectures,\nwe talked about",
    "start": "670100",
    "end": "675230"
  },
  {
    "text": "that the language models are\ntrained by maximum likelihood. So basically, we were\ntrying to maximize",
    "start": "675230",
    "end": "681380"
  },
  {
    "text": "the probability of\nthe next token, yt, given the preceding words. And this is our\noptimization objective.",
    "start": "681380",
    "end": "688850"
  },
  {
    "text": "So at each time step, this can\nbe regarded as a classification task because we are trying to\ndistinguish the actual word, yt",
    "start": "688850",
    "end": "696710"
  },
  {
    "text": "star, from all the remaining\nwords in the vocabulary. And this is also called teacher\nforcing because, at each time",
    "start": "696710",
    "end": "703790"
  },
  {
    "text": "step, we are using the gold\nstandard y star less than t",
    "start": "703790",
    "end": "709310"
  },
  {
    "text": "as input to the model. Whereas, presumably,\nat generation time,",
    "start": "709310",
    "end": "714350"
  },
  {
    "text": "you wouldn't have\nany access to y star, so you would have to use\nthe model's own prediction to feed it back into the model\nto generate the next token.",
    "start": "714350",
    "end": "721790"
  },
  {
    "text": "And that is called\nstudent forcing, which we'll talk in detail later. ",
    "start": "721790",
    "end": "728290"
  },
  {
    "text": "Oh, sorry. Yeah? I began raising\nit two slides ago. About autoregressive, we've\nnever used that word before.",
    "start": "728290",
    "end": "734700"
  },
  {
    "text": "What does it mean? Autoregressive? Oh, it just means, like-- so let's look at these\nanimations again.",
    "start": "734700",
    "end": "742220"
  },
  {
    "text": "Oops, sorry. Oh, it just looks like\nyou are generating word from left to right, one by one. So here, suppose that you\nare given y less than t.",
    "start": "742220",
    "end": "750500"
  },
  {
    "text": "And then autoregressive,\nyou first generate yt. And then once you\nhave yt, you'll feed it back in,\ngenerate yt plus 1",
    "start": "750500",
    "end": "756977"
  },
  {
    "text": "and then feed it back in,\ngenerate another thing. So this left to right\nnature because you are using chain rule to\ncondition on the tokens",
    "start": "756978",
    "end": "764960"
  },
  {
    "text": "that you just generated. This chain rule thing is\ncalled autoregressive. And typically, I think,\nconventionally, we",
    "start": "764960",
    "end": "770727"
  },
  {
    "text": "are doing left to\nright autoregressive by generating from\nleft to right. But there are also other\nmore interesting models",
    "start": "770727",
    "end": "776300"
  },
  {
    "text": "that can do backward or\ninfill and other things. This idea of generating\none token at once is autoregressive.",
    "start": "776300",
    "end": "784210"
  },
  {
    "text": "Cool. Any other questions? Yep.",
    "start": "784210",
    "end": "789280"
  },
  {
    "text": " So at inference time,\nour decoding algorithm",
    "start": "789280",
    "end": "796380"
  },
  {
    "text": "will define a function to select\na token from this distribution. So we've discussed that\nwe can use the language",
    "start": "796380",
    "end": "803040"
  },
  {
    "text": "model to compute this p, which\nis the next token distribution. And then g here,\nbased on our notation,",
    "start": "803040",
    "end": "808920"
  },
  {
    "text": "is the decoding\nalgorithm, which helps us select what token we are\nactually going to use for yt.",
    "start": "808920",
    "end": "814230"
  },
  {
    "text": "So the obvious\ndecoding algorithm is to greedily choose the\nhighest probability token as yt hat for each time step.",
    "start": "814230",
    "end": "822010"
  },
  {
    "text": "So while this basic\nalgorithm sort of works because they work for\nyour homework 4, to do better, there are two main\navenues that we can take.",
    "start": "822010",
    "end": "829470"
  },
  {
    "text": "We can decide to\nimprove decoding and we can also decide\nto improve the training.",
    "start": "829470",
    "end": "834748"
  },
  {
    "text": "Of course, there are other\nthings that we can do. We can improve training\ndata and we can improve model architectures.",
    "start": "834748",
    "end": "839970"
  },
  {
    "text": "But for this lecture, we will\nfocus on decoding and training. So now let's talk about how\ndecoding algorithms work",
    "start": "839970",
    "end": "848649"
  },
  {
    "text": "for natural language\ngeneration models. Before that, I'm happy\nto take any questions about the previous slides.",
    "start": "848650",
    "end": "854080"
  },
  {
    "text": " OK, yeah. Sorry, can you just\nexplain one more time",
    "start": "854080",
    "end": "860290"
  },
  {
    "text": "the difference between teacher\nforcing and student forcing? I think I'll go into this\nin detail later, but sure.",
    "start": "860290",
    "end": "867070"
  },
  {
    "text": "So basically, for\nteacher forcing, the idea is that you do\nteacher forcing where you'll train the language model\nbecause you already",
    "start": "867070",
    "end": "872590"
  },
  {
    "text": "observe the gold text. So you kind of use the gold\ntext up until time step t, put it into the model,\nand then the model",
    "start": "872590",
    "end": "879880"
  },
  {
    "text": "will try to predict yt plus 1. Whereas, student forcing means\nthat you don't have access",
    "start": "879880",
    "end": "885190"
  },
  {
    "text": "to this gold reference data. Instead, you are still trying\nto generate a sequence of data, so you have to use the text\nthat you generated yourself",
    "start": "885190",
    "end": "892480"
  },
  {
    "text": "using the model, and then feed\nit back into the model as input to predict t plus 1. That's the primary difference.",
    "start": "892480",
    "end": "900959"
  },
  {
    "text": "Cool. So what is decoding all about? At each time step, our\nmodel computes a vector",
    "start": "900960",
    "end": "908070"
  },
  {
    "text": "of score for each token. So it takes in preceding context\ny less than t and produce",
    "start": "908070",
    "end": "913560"
  },
  {
    "text": "a score s. And then we try to compute\na probability distribution p, all of these scores,\nby just applying softmax",
    "start": "913560",
    "end": "920580"
  },
  {
    "text": "to normalize them. And our decoding\nalgorithm is defined as this function g, which takes\nin the probability distribution",
    "start": "920580",
    "end": "929190"
  },
  {
    "text": "and tries to map\nit to some word. Basically, try to select a\ntoken from this probability distribution.",
    "start": "929190",
    "end": "934810"
  },
  {
    "text": "So in the machine\ntranslation lecture, we talked about\ngreedy decoding which",
    "start": "934810",
    "end": "939930"
  },
  {
    "text": "selects the highest probability\ntoken of this p distribution.",
    "start": "939930",
    "end": "945399"
  },
  {
    "text": "And we also talked\nabout beam search, which has the same objective\nas greedy decoding, which is that we are both trying to\nfind the most likely string",
    "start": "945400",
    "end": "952980"
  },
  {
    "text": "defined based on the model. But instead of doing so\ngreedily, for beam search, we actually explore a\nwider range of candidates.",
    "start": "952980",
    "end": "960320"
  },
  {
    "text": "So we have a wider\nexploration of candidates by keeping always like k\ncandidates in the beam.",
    "start": "960320",
    "end": "968120"
  },
  {
    "text": "So overall, this maximum\nprobability decoding is good for low entropy tasks\nlike machine translation",
    "start": "968120",
    "end": "973870"
  },
  {
    "text": "and summarization. But it actually\nencounters more problems for open-ended generation.",
    "start": "973870",
    "end": "979160"
  },
  {
    "text": "So the most likely string\nis actually very repetitive when we try to do\nopen-ended text generation.",
    "start": "979160",
    "end": "986650"
  },
  {
    "text": "As we can see in this\nexample, the context is perfectly normal. It's about, I mean, a unicorn\ntrying to speak English.",
    "start": "986650",
    "end": "993430"
  },
  {
    "text": "But the continuation,\nthe first part of it is-- it looks great. It's like valid English. It talks about science.",
    "start": "993430",
    "end": "999339"
  },
  {
    "text": "But suddenly, it\nstarts to repeat, and it starts to repeat, I\nthink, a institution's name.",
    "start": "999340",
    "end": "1006360"
  },
  {
    "text": "So why does this happen? If we look at, for\nexample, this plot",
    "start": "1006360",
    "end": "1012030"
  },
  {
    "text": "which shows the language\nmodel's probability assigned to the sequence \"I don't know,\"\nwe can see here is the pattern.",
    "start": "1012030",
    "end": "1019920"
  },
  {
    "text": "It has regular probability. But if we keep repeating\nthis phrase \"I don't know, I don't know, I don't\nknow\" for 10 times,",
    "start": "1019920",
    "end": "1026130"
  },
  {
    "text": "then we can see that\nthere is a decreasing trend in their negative\nlog likelihood.",
    "start": "1026130",
    "end": "1031150"
  },
  {
    "text": "So the y-axis is the\nnegative log probability. We can see this\ndecreasing trend which means that the\nmodel actually has",
    "start": "1031150",
    "end": "1037709"
  },
  {
    "text": "higher probability as\nthe repeat goes on, which is quite strange because\nit's suggesting that there",
    "start": "1037710",
    "end": "1044069"
  },
  {
    "text": "is a self-amplification effect. So the more repeat we\nhave, the more confident the model becomes\nabout this repeat.",
    "start": "1044069",
    "end": "1052120"
  },
  {
    "text": "And this keeps going on. We can see that for \"I\nam tired,\" \"I am tired\" repeats 100 times. We can see a continuously\ndecreasing trend",
    "start": "1052120",
    "end": "1059100"
  },
  {
    "text": "until the model is\nalmost 100% sure that it's going to keep\nrepeating the same thing.",
    "start": "1059100",
    "end": "1065490"
  },
  {
    "text": "And sadly, this problem is not\nreally solved by architecture. Here, the red plot\nis a LSTM model",
    "start": "1065490",
    "end": "1073409"
  },
  {
    "text": "and the blue curve is\na transformer model. We can see that\nboth model kind of suffers from the same problem.",
    "start": "1073410",
    "end": "1079140"
  },
  {
    "text": "And scale also doesn't\nsolve this problem, so we kind of believe that scale\nis the magical thing in NLP.",
    "start": "1079140",
    "end": "1084870"
  },
  {
    "text": "But even models with\n175 billion parameters will still suffer\nfrom repetition",
    "start": "1084870",
    "end": "1090840"
  },
  {
    "text": "if we try to find the\nmost likely string.",
    "start": "1090840",
    "end": "1096070"
  },
  {
    "text": "So how do we reduce repetition? One canonical approach\nis to do n-gram blocking.",
    "start": "1096070",
    "end": "1101820"
  },
  {
    "text": "So the principle is very simple. Basically, you just don't want\nto see the same n-gram twice.",
    "start": "1101820",
    "end": "1107220"
  },
  {
    "text": "If we set n to be\n3, then for any text that contains the\nphrase \"I am happy,\" the next time you\nsee the prefix \"I",
    "start": "1107220",
    "end": "1113640"
  },
  {
    "text": "am,\" n-gram blocking\nwould automatically set the probability of happy\nto be 0 so that you will never",
    "start": "1113640",
    "end": "1120090"
  },
  {
    "text": "see this tri-gram again. But clearly, this n-gram\nblocking heuristic",
    "start": "1120090",
    "end": "1125940"
  },
  {
    "text": "has some problems\nbecause sometimes it is quite common for you to want\nto see a person's name appear twice or three times\nor even more in a text.",
    "start": "1125940",
    "end": "1133740"
  },
  {
    "text": "But this n-gram blocking will\neliminate that possibility. So what are better options that\npossibly are more complicated?",
    "start": "1133740",
    "end": "1141309"
  },
  {
    "text": "For example, we can use a\ndifferent training objective. Instead of training\nby MLE, we can train",
    "start": "1141310",
    "end": "1147450"
  },
  {
    "text": "by unlikelihood objective. So in this approach,\nthe model is actually",
    "start": "1147450",
    "end": "1152940"
  },
  {
    "text": "penalized for generating\nalready-seen tokens. So it's kind of like putting\nthis n-gram blocking idea",
    "start": "1152940",
    "end": "1158700"
  },
  {
    "text": "into training time. Rather than at decoding\ntime for this constraint, at training time, we just\ndecrease the probability",
    "start": "1158700",
    "end": "1164550"
  },
  {
    "text": "of repetition. Another training objective\nis coverage wells, which uses the attention\nmechanism to prevent",
    "start": "1164550",
    "end": "1172920"
  },
  {
    "text": "repetition. So basically, if you try\nto regularize and enforce your attention so\nthat it's always attending to different\nwords for each token,",
    "start": "1172920",
    "end": "1179820"
  },
  {
    "text": "then it is highly\nlikely that you are not going to repeat\nbecause repetition tends to happen when you have\nsimilar attention patterns.",
    "start": "1179820",
    "end": "1188860"
  },
  {
    "text": "Another different\nangle is that, instead of searching for the\nmost likely string, we can use a different\ndecoding objective.",
    "start": "1188860",
    "end": "1195510"
  },
  {
    "text": "So maybe we can\nsearch for strings that maximizes the\ndifference between log probabilities of two models.",
    "start": "1195510",
    "end": "1201690"
  },
  {
    "text": "Say that we want to maximize the\nlog probability of large model minus log of small model. In this way, because both\nmodels are repetitive,",
    "start": "1201690",
    "end": "1208710"
  },
  {
    "text": "so they kind of cancel out. So they would both assign high\nprobabilities of repetition. And after applying\nthis new objective,",
    "start": "1208710",
    "end": "1215790"
  },
  {
    "text": "the repetition\nstuff will actually be penalized because\nit cancels out. So here comes the\nbroader question.",
    "start": "1215790",
    "end": "1223170"
  },
  {
    "text": "Is finding the\nmost likely string even a reasonable thing to do\nfor open-ended text generation?",
    "start": "1223170",
    "end": "1228840"
  },
  {
    "text": "The answer is probably no\nbecause this doesn't really match human pattern.",
    "start": "1228840",
    "end": "1233970"
  },
  {
    "text": "So we can see in this\nplot, the orange curve is the human pattern\nand the blue curve is the machine-generated\ntext using beam search.",
    "start": "1233970",
    "end": "1241200"
  },
  {
    "text": "So we can see that\nwhen human talks, there are actually\nlots of uncertainty,",
    "start": "1241200",
    "end": "1246240"
  },
  {
    "text": "as we can see by the fluctuation\nof the probabilities. For some words, we\ncan be very certain.",
    "start": "1246240",
    "end": "1251309"
  },
  {
    "text": "For some words, we are\na little bit unsure. Whereas here, for the\nmodel distribution, it's always very sure.",
    "start": "1251310",
    "end": "1256320"
  },
  {
    "text": "It's always assigning\nprobability 1 to the sequence. So because we now are\nseeing, basically, there",
    "start": "1256320",
    "end": "1263320"
  },
  {
    "text": "is a mismatch between\nthe two distributions, so it's kind of suggesting\nthat maybe searching",
    "start": "1263320",
    "end": "1268809"
  },
  {
    "text": "for the most likely string\nis not the right decoding objective at all. Any questions so far\nbefore we move on?",
    "start": "1268810",
    "end": "1275300"
  },
  {
    "text": "Yeah. So is this the\nunderlying mechanism for some detector of\nwhether some text is",
    "start": "1275300",
    "end": "1281530"
  },
  {
    "text": "generated by ChatGPT? Not really because--\nso this can only",
    "start": "1281530",
    "end": "1286690"
  },
  {
    "text": "detect the really simple\nthings that humans are also able to detect, repetition. So in order to avoid\nthe previous problems",
    "start": "1286690",
    "end": "1294280"
  },
  {
    "text": "that we've talked about, I'll\ntalk about some other decoding families that generate\nmore robust text",
    "start": "1294280",
    "end": "1300160"
  },
  {
    "text": "that actually look like this,\nwhose probability distribution looks like the orange curve.",
    "start": "1300160",
    "end": "1305330"
  },
  {
    "text": "So I wouldn't say this is the\nto-go answer for watermarking or detection.",
    "start": "1305330",
    "end": "1310940"
  },
  {
    "text": "Could you repeat the\nstudent's question? Oh, yeah. OK, cool, so she asked\nabout whether this mechanism",
    "start": "1310940",
    "end": "1318370"
  },
  {
    "text": "of plotting the\nprobabilities of human text and machine-generated\ntext is one",
    "start": "1318370",
    "end": "1323409"
  },
  {
    "text": "way of detecting\nwhether some text is generated by model or human. And my answer is,\nI don't think so,",
    "start": "1323410",
    "end": "1330220"
  },
  {
    "text": "but this could be an\ninteresting research direction. Because I feel like there are\nmore robust decoding approaches",
    "start": "1330220",
    "end": "1337690"
  },
  {
    "text": "that generate text that\nactually fluctuates a lot. ",
    "start": "1337690",
    "end": "1344140"
  },
  {
    "text": "So yeah, let's talk about\nthe decoding algorithm that is able to generate\ntext that fluctuates. So given that searching\nfor the most likely string",
    "start": "1344140",
    "end": "1352000"
  },
  {
    "text": "is a bad idea, what\nelse should we do? And how do we simulate\nthat human pattern? And the answer to this is\nto introduce randomness",
    "start": "1352000",
    "end": "1359080"
  },
  {
    "text": "and stochasticity to decoding. So suppose that we are sampling\na token from this distribution",
    "start": "1359080",
    "end": "1366740"
  },
  {
    "text": "p. Basically, we are\ntrying to sample yt hat from this distribution. It is random so that you can\nessentially sample any token",
    "start": "1366740",
    "end": "1374110"
  },
  {
    "text": "in the distribution. Previously, you were kind\nof restricted to selecting restroom or grocery. But now you can select\nbathroom instead.",
    "start": "1374110",
    "end": "1382660"
  },
  {
    "text": "So however, sampling introduces\na new set of problems. Since we never really zero\nout any token probabilities,",
    "start": "1382660",
    "end": "1390660"
  },
  {
    "text": "vanilla sampling\nwould make every token in the vocabulary\na viable option. And in some unlucky cases, we\nmight end up with a bad word.",
    "start": "1390660",
    "end": "1399730"
  },
  {
    "text": "So assuming that we already have\na very well-trained model, even",
    "start": "1399730",
    "end": "1404790"
  },
  {
    "text": "if most of the probability\nmass of the distribution is over the limited\nset of good options,",
    "start": "1404790",
    "end": "1410100"
  },
  {
    "text": "the tail of the\ndistribution will still be very long because we have so\nmany words in our vocabulary.",
    "start": "1410100",
    "end": "1415620"
  },
  {
    "text": "And therefore, if we add all\nthose longtails, in aggregate, they still have a\nconsiderable mass.",
    "start": "1415620",
    "end": "1420990"
  },
  {
    "text": "So statistically\nspeaking, this is called heavy-tailed\ndistribution, and language is exactly a\nheavy-tailed distribution.",
    "start": "1420990",
    "end": "1427660"
  },
  {
    "text": "So for example,\nlike, many tokens are probably really\nwrong in this context.",
    "start": "1427660",
    "end": "1433299"
  },
  {
    "text": "And then, given that we\nhave a good language model, we assign them each\nvery little probability. But this doesn't really\nsolve the problem",
    "start": "1433300",
    "end": "1440610"
  },
  {
    "text": "because there are\nso many of them, so you aggregate them\nas a group will still have a high chance\nof being selected.",
    "start": "1440610",
    "end": "1447950"
  },
  {
    "text": "And the solution\nhere that we have for this problem of long\ntail is that we should just cut off the tail.",
    "start": "1447950",
    "end": "1453400"
  },
  {
    "text": "We should just zero\nout the probabilities that we don't want. And one idea is\ncalled top-k sampling",
    "start": "1453400",
    "end": "1460660"
  },
  {
    "text": "where the idea is\nthat we would only sample from the top-k tokens in\nthe probability distribution.",
    "start": "1460660",
    "end": "1468909"
  },
  {
    "text": "Any questions for now?  OK, yeah. Well, the model we were\nlooking at a second ago",
    "start": "1468910",
    "end": "1477299"
  },
  {
    "text": "had some very low probability\nsamples as well on the graph, right? How would top-k\nsampling deal with that?",
    "start": "1477300",
    "end": "1485190"
  },
  {
    "text": "You mean this one or you mean-- The orange-blue graph\nof the human versus--",
    "start": "1485190",
    "end": "1491700"
  },
  {
    "text": "Oh, yeah, yeah. So top-k will basically\neliminate-- it will not--",
    "start": "1491700",
    "end": "1497130"
  },
  {
    "text": "it will make it\nimpossible to generate the super low\nprobability tokens. So technically, it's not\nexactly simulating this pattern",
    "start": "1497130",
    "end": "1504263"
  },
  {
    "text": "because now you don't have\nthe super low probability tokens, whereas humans can\ngenerate super low probability",
    "start": "1504263",
    "end": "1509400"
  },
  {
    "text": "tokens in a fluent way. But yeah, that could\nbe another hint",
    "start": "1509400",
    "end": "1514559"
  },
  {
    "text": "that people can\nuse for detecting machine-generated text. Yeah? Does it also depend on the type\nof text you want to generate?",
    "start": "1514560",
    "end": "1522370"
  },
  {
    "text": "For example, a poem or novels\nor more creative writing, is it then you decide\nthe hyperparameter?",
    "start": "1522370",
    "end": "1528930"
  },
  {
    "text": "Yeah, yeah, for sure. K is a hyperparameter that,\ndepending on the type of task, you will choose k differently.",
    "start": "1528930",
    "end": "1535030"
  },
  {
    "text": "Mostly, for close-ended\ntasks, k should be small, and for open-ended,\nk should be large. Yeah, question in the back.",
    "start": "1535030",
    "end": "1542650"
  },
  {
    "text": "I guess, intuitively, this is\nbuilt off of one of the earlier questions. Why don't we consider the case\nlike where we sample and then",
    "start": "1542650",
    "end": "1550510"
  },
  {
    "text": "we just weight the probability\nof each word by its, like, score or something rather\nthan just looking at top-k,",
    "start": "1550510",
    "end": "1556380"
  },
  {
    "text": "but we don't do, like,\na weighted sampling type of situation. So we still have that small\nbut non-zero probability",
    "start": "1556380",
    "end": "1562060"
  },
  {
    "text": "of selecting. I think top-k is also weighted. So top-k just kind of\nzeros out all the tails",
    "start": "1562060",
    "end": "1570130"
  },
  {
    "text": "of the distribution. But for the things that\nit didn't zero out, it's not like a uniform\nchoice among the k.",
    "start": "1570130",
    "end": "1575950"
  },
  {
    "text": "It's still trying to choose\nproportional to the scores that you computed. Is that just, like,\ncomputationally more efficient",
    "start": "1575950",
    "end": "1583270"
  },
  {
    "text": "because you don't have to\ndo for, like, 17,000 words? It can be like for\nlike 10 or something?",
    "start": "1583270",
    "end": "1589300"
  },
  {
    "text": "Yeah, sure. That could be one\ngain of top-k decoding is that your softmax will\ntake in fewer candidates.",
    "start": "1589300",
    "end": "1597970"
  },
  {
    "text": "Yeah. That's not the main reason. I think you should show-- Yeah, I'll keep talking\nabout the main reason.",
    "start": "1597970",
    "end": "1602980"
  },
  {
    "start": "1602980",
    "end": "1608150"
  },
  {
    "text": "So we've discussed this part. And then here, this is the\nformal-- this is kind of the-- formally what is happening\nfor top-k sampling,",
    "start": "1608150",
    "end": "1616130"
  },
  {
    "text": "now that we are only sampling\nfrom the top-k tokens of the probability distribution. And as we've said, k\nis a hyperparameter,",
    "start": "1616130",
    "end": "1623480"
  },
  {
    "text": "so we can set k to\nbe large or small. If we increase k,\nthis means that we",
    "start": "1623480",
    "end": "1628970"
  },
  {
    "text": "are making our\noutput more diverse but at the risk of including\nsome tokens that are bad.",
    "start": "1628970",
    "end": "1634130"
  },
  {
    "text": "If we decrease k, then\nwe are making more conservative and safe options. But possibly, the\ngeneration will",
    "start": "1634130",
    "end": "1639560"
  },
  {
    "text": "be quite generic and boring.  So is top-k decoding\ngood enough?",
    "start": "1639560",
    "end": "1646780"
  },
  {
    "text": "The answer is, not really\nbecause we can still find some problems\nwith top-k decoding.",
    "start": "1646780",
    "end": "1652000"
  },
  {
    "text": "For example, in the context,\nshe said I never blank. There are many\nwords that are still",
    "start": "1652000",
    "end": "1657730"
  },
  {
    "text": "valid options such as went, ate. But those words got zeroed\nout because they are not",
    "start": "1657730",
    "end": "1663850"
  },
  {
    "text": "in the top-k candidates. So this actually leads to bad\nrecall for your generation system.",
    "start": "1663850",
    "end": "1669290"
  },
  {
    "text": "And similarly, another\nfailure of top-k is that it can also\ncut off too quickly.",
    "start": "1669290",
    "end": "1675050"
  },
  {
    "text": "So in this example, code is\nnot really a valid answer, according to common sense\nbecause you probably don't",
    "start": "1675050",
    "end": "1680890"
  },
  {
    "text": "want to eat a piece of code. But the probability\nremains non-zero, meaning that the model might\nstill sample code as an output,",
    "start": "1680890",
    "end": "1689409"
  },
  {
    "text": "despite with low probability,\nbut it might still happen. And this means bad precision\nfor the generation model.",
    "start": "1689410",
    "end": "1697390"
  },
  {
    "text": "So given this problems\nwith top-k decoding, how can we address them?",
    "start": "1697390",
    "end": "1703260"
  },
  {
    "text": "How can we address\nthis issue of there is no single k that\nfits all circumstances?",
    "start": "1703260",
    "end": "1709460"
  },
  {
    "text": "This is basically because\nthe probability distribution that we sample from are dynamic. So when the probability\ndistribution",
    "start": "1709460",
    "end": "1715670"
  },
  {
    "text": "is relatively flat,\nhaving a small k will remove many viable options.",
    "start": "1715670",
    "end": "1720690"
  },
  {
    "text": "So having a limited k will\nremove many viable options. And we want k to be\nlarger for this case.",
    "start": "1720690",
    "end": "1726559"
  },
  {
    "text": "Similarly, when a\ndistribution p is too picky, then we want the--",
    "start": "1726560",
    "end": "1732860"
  },
  {
    "text": "a high k would allow for too\nmany options to be viable. And instead, we might\nwant a smaller k",
    "start": "1732860",
    "end": "1739010"
  },
  {
    "text": "so that we are being safer. So the solution here\nis that maybe k is just a bad hyperparameter.",
    "start": "1739010",
    "end": "1744830"
  },
  {
    "text": "And instead of doing k, we\nshould think about probability. We should think about how to\nsample from tokens in the top p",
    "start": "1744830",
    "end": "1752660"
  },
  {
    "text": "probability percentiles of\nthe cumulative probability mass of the CDF, for example.",
    "start": "1752660",
    "end": "1760770"
  },
  {
    "text": "So now the advantage of\ndoing top-p sampling, where we sample from the\ntop-p percentile",
    "start": "1760770",
    "end": "1767390"
  },
  {
    "text": "of the cumulative\nprobability mass is that this is actually\nequivalent to we have now a adaptive k for\neach different distribution.",
    "start": "1767390",
    "end": "1775370"
  },
  {
    "text": "And let me explain what I\nmean by having an adaptive k. So in the first\ndistribution, this",
    "start": "1775370",
    "end": "1781760"
  },
  {
    "text": "is like a regular\npower law of language. That's kind of typical. And then doing\ntop-k sampling means",
    "start": "1781760",
    "end": "1788930"
  },
  {
    "text": "we are selecting the top-k. But doing top-p\nsampling means that we are zooming into maybe\nlike something that's",
    "start": "1788930",
    "end": "1795230"
  },
  {
    "text": "similar to top k in effect. But if I have a relatively\nflat distribution, like the blue one, we\ncan see that doing top-p",
    "start": "1795230",
    "end": "1802700"
  },
  {
    "text": "means that we are\nincluding more candidates. And then if we have a\nmore skewed distribution,",
    "start": "1802700",
    "end": "1807830"
  },
  {
    "text": "like the green one, doing\ntop-p means that we actually include fewer candidates. So by actually selecting,\nlike, the top-p percentile",
    "start": "1807830",
    "end": "1816440"
  },
  {
    "text": "in the probability\ndistribution, we are actually having\na more flexible k,",
    "start": "1816440",
    "end": "1821720"
  },
  {
    "text": "and therefore,\nhave a better sense of what are the good\noptions in the model.",
    "start": "1821720",
    "end": "1827010"
  },
  {
    "text": "Any questions about\ntop-p, top-k decoding? ",
    "start": "1827010",
    "end": "1832490"
  },
  {
    "text": "So everything's clear? Yeah, sounds good. So to go back to that\nquestion, doing top-k",
    "start": "1832490",
    "end": "1839570"
  },
  {
    "text": "is not necessarily saving\ncompute or this whole idea is not really compute\nsaving intended",
    "start": "1839570",
    "end": "1845600"
  },
  {
    "text": "because, in the case\nof top-p, in order to select the top\npercentile, we still",
    "start": "1845600",
    "end": "1850910"
  },
  {
    "text": "need to compute the softmax\nover the entire vocabulary set in order for us to\ndo top-k properly,",
    "start": "1850910",
    "end": "1856910"
  },
  {
    "text": "to compute the p properly. So therefore, it's not\nreally saving compute but it's improving performance.",
    "start": "1856910",
    "end": "1864740"
  },
  {
    "text": "Cool, moving on. So yeah, much more to go\nwith decoding algorithms.",
    "start": "1864740",
    "end": "1870320"
  },
  {
    "text": "Besides the top-k and\ntop-p that we've discussed, there are some more\nrecent approaches like typical sampling,\nwhere the idea is",
    "start": "1870320",
    "end": "1878330"
  },
  {
    "text": "that we want to\nrelate the score based on the entropy of\nthe distribution and try to generate\ntexts that are closer",
    "start": "1878330",
    "end": "1884299"
  },
  {
    "text": "to the negative-- whose\nprobability is closer to the negative entropy\nof the data distribution.",
    "start": "1884300",
    "end": "1890330"
  },
  {
    "text": "This kind of means\nthat if you have a close-ended task or\nnon-open-ended task, you want-- it has\nsmaller entropy so,",
    "start": "1890330",
    "end": "1897409"
  },
  {
    "text": "you want a negative log\nprobability to be smaller, so you want probability\nto be larger. So it kind of type\nchecks very well.",
    "start": "1897410",
    "end": "1904590"
  },
  {
    "text": "And additionally,\nthere is also epsilon sampling coming from John.",
    "start": "1904590",
    "end": "1910460"
  },
  {
    "text": "So this is an idea where\nwe set the threshold to lower bound probabilities. So basically, if you have\na word whose probability",
    "start": "1910460",
    "end": "1917960"
  },
  {
    "text": "is less than 0.03, for\nexample, then that word will never appear in\nthe output distribution.",
    "start": "1917960",
    "end": "1924500"
  },
  {
    "text": "That word will never\nbe part of your output because it has so\nlow probability.",
    "start": "1924500",
    "end": "1929700"
  },
  {
    "text": "Yeah? What's the entropy\nof a distribution? Oh, cool, great question.",
    "start": "1929700",
    "end": "1935090"
  },
  {
    "text": "So the entropy distribution\nis defined as-- you can suppose that we have\na discrete distribution.",
    "start": "1935090",
    "end": "1942020"
  },
  {
    "text": "We can go over it like--\nwe'll just enumerate x. And then it's like negative\nlog probability of x.",
    "start": "1942020",
    "end": "1949610"
  },
  {
    "text": "So if we write it from an\nexpectation perspective, it's basically expected\nof log probability of x.",
    "start": "1949610",
    "end": "1956480"
  },
  {
    "text": "OK, I have to do\na little bit here. So this is the entropy\nof a distribution.",
    "start": "1956480",
    "end": "1964760"
  },
  {
    "text": "And then, so basically,\nif your distribution is very concentrated\nto a few words,",
    "start": "1964760",
    "end": "1969860"
  },
  {
    "text": "then the entropy will\nbe relatively small. If your distribution\nis very flat,",
    "start": "1969860",
    "end": "1974990"
  },
  {
    "text": "then your entropy\nwill be very large. Yeah. What if the epsilon\nsampling is set such",
    "start": "1974990",
    "end": "1982769"
  },
  {
    "text": "that we have no valid options? Oh, yeah, I mean, there will be\nsome back off cases, I think.",
    "start": "1982770",
    "end": "1989550"
  },
  {
    "text": "So in the case that there\nis no valid options, you probably still want to\nselect one or two things",
    "start": "1989550",
    "end": "1995880"
  },
  {
    "text": "just as an edge case, I think.  OK, cool, moving on.",
    "start": "1995880",
    "end": "2003390"
  },
  {
    "text": "So another hyperparameter that\nwe can tune to affect decoding is the temperature parameter.",
    "start": "2003390",
    "end": "2009899"
  },
  {
    "text": "So recall that previously\nat each time step, we ask the model\nto compute a score,",
    "start": "2009900",
    "end": "2015450"
  },
  {
    "text": "and then we renormalize that\nscore using softmax to get a probability distribution. So one thing that\nwe can adjust here",
    "start": "2015450",
    "end": "2021899"
  },
  {
    "text": "is that we can insert\nthis temperature parameter tau to relate to the score. So basically, we just\ndivide all the Sw by tau.",
    "start": "2021900",
    "end": "2030270"
  },
  {
    "text": "And after dividing\nthis, we apply softmax and we get a new distribution. And this temperature\nadjustment is not really",
    "start": "2030270",
    "end": "2038220"
  },
  {
    "text": "going to affect the monotonicity\nof the distribution. For example, if word A has\nhigher probability than word B",
    "start": "2038220",
    "end": "2044970"
  },
  {
    "text": "previously, then\nafter the adjustment, word A is still going to have a\nhigher probability than word B.",
    "start": "2044970",
    "end": "2050610"
  },
  {
    "text": "But their relative\ndifference will change. So for example, if we\nraise the temperature tau",
    "start": "2050610",
    "end": "2058649"
  },
  {
    "text": "to be greater than 1,\nthen the distribution pt will become more uniform. It will be flatter.",
    "start": "2058650",
    "end": "2064750"
  },
  {
    "text": "And this kind of\nimplies that there will be more diverse output\nbecause our distribution is",
    "start": "2064750",
    "end": "2069790"
  },
  {
    "text": "flatter and it's more spread\nout across different words in the vocabulary.",
    "start": "2069790",
    "end": "2075280"
  },
  {
    "text": "On the other hand, if\nwe lower the temperature tau less than 1, then\npt becomes very spiky.",
    "start": "2075280",
    "end": "2081969"
  },
  {
    "text": "And then this means that,\nif we sample from the pt, we'll get less diverse output.",
    "start": "2081969",
    "end": "2087440"
  },
  {
    "text": "So because here the probability\nis concentrated only on the top words. So in the very extreme\ncase, if we set tau",
    "start": "2087440",
    "end": "2093760"
  },
  {
    "text": "to be very, very close to\n0, then the probability will kind of be a one-hot vector\nwhere all the probability mass",
    "start": "2093760",
    "end": "2100660"
  },
  {
    "text": "will be centered on one word. And then this kind\nof reduces back to argmax sampling\nor greedy decoding.",
    "start": "2100660",
    "end": "2107590"
  },
  {
    "text": "So temperature is\na hyperparameter as well, as for k and\np in top-k and top-p.",
    "start": "2107590",
    "end": "2113349"
  },
  {
    "text": "It is a hyperparameter\nfor decoding. It can be tuned for beam\nsearch and sampling algorithms.",
    "start": "2113350",
    "end": "2118780"
  },
  {
    "text": "So it's kind of orthogonal\nto the approaches that we discussed before.",
    "start": "2118780",
    "end": "2123910"
  },
  {
    "text": "Any questions so far?  OK, cool.",
    "start": "2123910",
    "end": "2129330"
  },
  {
    "text": "Temperature is so easy.  So well, because sampling\nstill involves randomness,",
    "start": "2129330",
    "end": "2136980"
  },
  {
    "text": "right, even though we\ntry very hard in terms of truncating the tail,\nsampling still has randomness.",
    "start": "2136980",
    "end": "2143220"
  },
  {
    "text": "So what if we're just unlucky\nand decode a bad sequence from the model? One common solution\nis to do reranking.",
    "start": "2143220",
    "end": "2150000"
  },
  {
    "text": "So basically, we would\ndecode a bunch of sequences. Like, for example, we can\ndecode 10 candidates, but, like,",
    "start": "2150000",
    "end": "2155940"
  },
  {
    "text": "10 or 30 is up to you. The only choice is that\nyou want to balance between your compute\nefficiency and performance.",
    "start": "2155940",
    "end": "2162580"
  },
  {
    "text": "So if you decode too many\nsequences, then of course, your performance is\ngoing to increase, but it's also very\ncostly to just generate",
    "start": "2162580",
    "end": "2170490"
  },
  {
    "text": "a lot of things for one example. And then, so once you have\na bunch of sample sequences,",
    "start": "2170490",
    "end": "2177690"
  },
  {
    "text": "then we are trying\nto define a score to approximate the quality\nof the sequence and rerank",
    "start": "2177690",
    "end": "2182819"
  },
  {
    "text": "everything and rerank all\nthe candidates by this score. So the simple thing to do is we\ncan use perplexity as a metric,",
    "start": "2182820",
    "end": "2191230"
  },
  {
    "text": "as a scoring function. But we need to be careful\nthat, because we have talked about this, like, the\nextreme of perplexity,",
    "start": "2191230",
    "end": "2197800"
  },
  {
    "text": "like, if we try to\nargmax log probability, when we try to aim for\na super low perplexity,",
    "start": "2197800",
    "end": "2202870"
  },
  {
    "text": "the texts are actually\nvery repetitive. So we shouldn't really aim\nfor extremely low perplexity.",
    "start": "2202870",
    "end": "2208060"
  },
  {
    "text": "And perplexity, to some extent,\nis not a perfect rescoring function.",
    "start": "2208060",
    "end": "2213110"
  },
  {
    "text": "It's not a perfect scoring\nfunction because it's not really robust to maximize.",
    "start": "2213110",
    "end": "2218380"
  },
  {
    "text": "So alternatively, the\nrerankers can actually use a wide variety of\nother scoring functions.",
    "start": "2218380",
    "end": "2223960"
  },
  {
    "text": "Like we can score texts based\non their style, their discourse coherence, their entailment,\nfactuality properties,",
    "start": "2223960",
    "end": "2230770"
  },
  {
    "text": "consistency, and so on.  And additionally, we can compose\nmultiple rerankers together.",
    "start": "2230770",
    "end": "2239470"
  },
  {
    "text": "Yeah, question? Small question. You mentioned 10 candidates\nor any number of candidates.",
    "start": "2239470",
    "end": "2244760"
  },
  {
    "text": "Yeah. What's the strategy you\nusually use to generate these other candidates?",
    "start": "2244760",
    "end": "2249910"
  },
  {
    "text": "Like what heuristic do you use? Yeah, so basically, the idea\nis to sample from the model,",
    "start": "2249910",
    "end": "2255109"
  },
  {
    "text": "right? So when you sample from the\nmodel, each time you sample, you're going to get\na different output. And then that's what I mean\nby different candidate.",
    "start": "2255110",
    "end": "2261910"
  },
  {
    "text": "So if you sample 10 times,\nyou will very likely get 10 different outputs.",
    "start": "2261910",
    "end": "2266980"
  },
  {
    "text": "And then you are just given\nthis 10 different outputs that come from sampling. You can just decide to rerank\nthem and select the candidate",
    "start": "2266980",
    "end": "2274930"
  },
  {
    "text": "that has the highest score. Where does the\nrandomness come from? Oh, because we\nare sampling here.",
    "start": "2274930",
    "end": "2281200"
  },
  {
    "text": "That sample-- OK. Yeah, for example, if we are\ndoing like top-k sampling, then well, suppose that A\nand B are equally probable.",
    "start": "2281200",
    "end": "2288760"
  },
  {
    "text": "Then you might sample\nA or might sample B with the same probability.",
    "start": "2288760",
    "end": "2294250"
  },
  {
    "text": "OK, cool. And another cool thing that\nwe can do with reranking is that we can compose\nmultiple rerankers together.",
    "start": "2294250",
    "end": "2300370"
  },
  {
    "text": "So basically, suppose you have\na scoring function for style and you have a scoring function\nfor factual consistency.",
    "start": "2300370",
    "end": "2306280"
  },
  {
    "text": "You can just add those two\nscoring functions together to get a new scoring\nfunction and then rerank",
    "start": "2306280",
    "end": "2311619"
  },
  {
    "text": "everything based\non your new scoring function to get texts that\nare both good at style and good at factual consistency.",
    "start": "2311620",
    "end": "2320410"
  },
  {
    "text": "So when you say that when\nyou rerank by the score, do we just pick the decoding\nthat has the highest score,",
    "start": "2320410",
    "end": "2326200"
  },
  {
    "text": "or do we do some more sampling\nagain based on the score? The idea is you just\ntake the decoding that",
    "start": "2326200",
    "end": "2331390"
  },
  {
    "text": "has the highest score because\nyou already have, let's say, 10 candidates. So out of this,\nyou only need one. And then, you just choose one\nthat has the highest score.",
    "start": "2331390",
    "end": "2338575"
  },
  {
    "text": " Cool. Any other questions?",
    "start": "2338575",
    "end": "2345550"
  },
  {
    "text": "Sorry. What is perplexity? Perplexity is like-- you\ncan kind of regard it",
    "start": "2345550",
    "end": "2351790"
  },
  {
    "text": "as log probabilities. It's like e to the\nnegative log probabilities.",
    "start": "2351790",
    "end": "2358269"
  },
  {
    "text": "It's kind of like if a\ntoken has high perplexity, then it means it has a low\nprobability because you",
    "start": "2358270",
    "end": "2364869"
  },
  {
    "text": "are more perplexed.  OK, so taking a step back\nto summarize this decoding",
    "start": "2364870",
    "end": "2372640"
  },
  {
    "text": "section. We have discussed many\ndecoding approaches, from selecting the most probable\nstring to sampling and then",
    "start": "2372640",
    "end": "2380859"
  },
  {
    "text": "to various truncation\napproaches that we can do to improve sampling like\ntop-p, top-k, epsilon, typical",
    "start": "2380860",
    "end": "2386710"
  },
  {
    "text": "decoding. And finally, we discuss\nhow we can do in terms of reranking the results.",
    "start": "2386710",
    "end": "2392529"
  },
  {
    "text": "So decoding is still a really\nessential problem in NLG, and there are lots of works\nto be done here still,",
    "start": "2392530",
    "end": "2399759"
  },
  {
    "text": "especially as ChatGPT is\nso powerful we should all go study decoding. So it would be\ninteresting if you",
    "start": "2399760",
    "end": "2406299"
  },
  {
    "text": "want to do such final projects. And also, different\ndecoding algorithms can allow us to inject different\ninductive biases to the text",
    "start": "2406300",
    "end": "2415270"
  },
  {
    "text": "that we are trying to generate. And some of the most\nimpactful advances in NLG in the last\ncouple of years",
    "start": "2415270",
    "end": "2421809"
  },
  {
    "text": "actually come from simple but\neffective decoding algorithms. For example, the\nnucleus sampling paper",
    "start": "2421810",
    "end": "2428020"
  },
  {
    "text": "is actually very,\nvery highly cited. So moving on to talk\nabout training NLG models.",
    "start": "2428020",
    "end": "2436720"
  },
  {
    "text": "Well, we have seen this example\nbefore in the decoding slides, and I'm just trying to show them\nagain because even though we",
    "start": "2436720",
    "end": "2443000"
  },
  {
    "text": "can solve this repetition\nproblem instead of doing search, doing sampling,\nbut it's still",
    "start": "2443000",
    "end": "2449420"
  },
  {
    "text": "concerning from a language\nmodeling perspective that your model would\nput so much probability",
    "start": "2449420",
    "end": "2454730"
  },
  {
    "text": "on such repetitive\nand degenerate text. So we ask this question,\nwell, is repetition due to how",
    "start": "2454730",
    "end": "2460418"
  },
  {
    "text": "language models are trained?  You have also seen\nthis problem before,",
    "start": "2460418",
    "end": "2466500"
  },
  {
    "text": "which shows this\ndecaying pattern or this\nself-amplification effect. So we can conclude\nfrom this observation",
    "start": "2466500",
    "end": "2473240"
  },
  {
    "text": "that model trained\nvia MLE objective learns really bad mode\nof the distribution,",
    "start": "2473240",
    "end": "2479810"
  },
  {
    "text": "by mode of the distribution,\nI mean the arg max of the distribution. So basically, they would\nassign high probability",
    "start": "2479810",
    "end": "2484910"
  },
  {
    "text": "to terrible strings. And this is definitely\nproblematic for a model perspective.",
    "start": "2484910",
    "end": "2490320"
  },
  {
    "text": "So why is this the case? Shouldn't MLE be\nlike a gold standard in machine learning in general,\nnot just machine translation?",
    "start": "2490320",
    "end": "2497960"
  },
  {
    "text": "Shouldn't MLE be like a gold\nstandard for machine learning? The answer here is not\nreally, especially for text,",
    "start": "2497960",
    "end": "2504010"
  },
  {
    "text": "because MLE has some\nproblem for sequential data. And we call this\nproblem exposure bias.",
    "start": "2504010",
    "end": "2510730"
  },
  {
    "text": "So training with\nteacher forcing leads to exposure bias\nat generation time because, during training,\nour model's inputs",
    "start": "2510730",
    "end": "2518080"
  },
  {
    "text": "are gold context tokens from\nreal human-generated texts as denoted as y hat\nless than t here.",
    "start": "2518080",
    "end": "2524700"
  },
  {
    "text": "But during generation time, our\nmodel's input become previously decoded tokens from\nthe model y hat t.",
    "start": "2524700",
    "end": "2532270"
  },
  {
    "text": "And suppose that our model has\nminor errors, then like y hat",
    "start": "2532270",
    "end": "2537550"
  },
  {
    "text": "less than t will be much worse\nin terms of quality than y star less than t. And this discrepancy is\nterrible because it actually",
    "start": "2537550",
    "end": "2545350"
  },
  {
    "text": "causes a discrepancy between\ntraining and test time, which actually hurts\nmodel performance,",
    "start": "2545350",
    "end": "2551170"
  },
  {
    "text": "and we call this\nproblem exposure bias.  So people have\nproposed many solution",
    "start": "2551170",
    "end": "2557770"
  },
  {
    "text": "to address this\nexposure bias problem. One thing to do is to do\nschedule sampling, which",
    "start": "2557770",
    "end": "2564290"
  },
  {
    "text": "means that with probability\np, we try to decode a token",
    "start": "2564290",
    "end": "2569450"
  },
  {
    "text": "and feed it back in as\ncontext to train the model. And with probability\n1 minus p, we",
    "start": "2569450",
    "end": "2575750"
  },
  {
    "text": "use the gold token as context. So throughout training,\nwe try to increase p to gradually warm it\nup and then prepare it",
    "start": "2575750",
    "end": "2583910"
  },
  {
    "text": "for test time generation. So this leads to\nimprovement in practice because, using these\np probabilities,",
    "start": "2583910",
    "end": "2591920"
  },
  {
    "text": "we're actually gradually trying\nto narrow the discrepancy between training and test time.",
    "start": "2591920",
    "end": "2597840"
  },
  {
    "text": "But the objective is\nactually quite strange, and training can\nbe very unstable.",
    "start": "2597840",
    "end": "2603049"
  },
  {
    "text": "Another idea is to do\nDataset Aggregation, and the method is called DAgger.",
    "start": "2603050",
    "end": "2608809"
  },
  {
    "text": "Essentially at various\ninterval during training, we try to generate a sequence\nof texts from the current model",
    "start": "2608810",
    "end": "2614540"
  },
  {
    "text": "and then use this and then\nput this sequence of texts into the training data. So we're kind of continuously\ndoing this training data",
    "start": "2614540",
    "end": "2622000"
  },
  {
    "text": "augmentation scheme to\nmake sure that the training distribution and the\ngeneration distribution",
    "start": "2622000",
    "end": "2627640"
  },
  {
    "text": "are closer together. So both approaches, both\nscheduled sampling and dataset aggregation, are ways to\nnarrow the discrepancy",
    "start": "2627640",
    "end": "2635020"
  },
  {
    "text": "between training and test. Yes, question. What is a gold token? What is the? Gold token.",
    "start": "2635020",
    "end": "2640600"
  },
  {
    "text": "Oh, gold token just\nmeans human text. I mean, it's like, well, we\nwill train a language model.",
    "start": "2640600",
    "end": "2646450"
  },
  {
    "text": "You will see also corpus\nthat are human-written. Gold is just human. ",
    "start": "2646450",
    "end": "2653580"
  },
  {
    "text": "OK, cool. So another approach is to do\nretrieval augmented generation.",
    "start": "2653580",
    "end": "2658690"
  },
  {
    "text": "So we first learn to retrieve\na sequence from some existing corpus of prototypes,\nand then we",
    "start": "2658690",
    "end": "2664260"
  },
  {
    "text": "train a model to actually\nedit the retrieved text by doing insertion,\ndeletion, or swapping.",
    "start": "2664260",
    "end": "2671190"
  },
  {
    "text": "We can add or remove\ntokens from this prototype and then try to modify\nit into another sentence.",
    "start": "2671190",
    "end": "2679109"
  },
  {
    "text": "So this doesn't really\nsuffer from exposure bias because we start from a\nhigh-quality prototype.",
    "start": "2679110",
    "end": "2684600"
  },
  {
    "text": "So that at training\ntime and at test time, you don't really\nhave the discrepancy anymore because you are not\ngenerating from left to right.",
    "start": "2684600",
    "end": "2693299"
  },
  {
    "text": "Another approach is to do\nreinforcement learning. So here, the idea is to\ncast your generation problem",
    "start": "2693300",
    "end": "2699990"
  },
  {
    "text": "as a Markov decision process. So there is the state s, which\nis the model's representation",
    "start": "2699990",
    "end": "2706740"
  },
  {
    "text": "for all the preceding context. There is action a, which\nis basically the next token",
    "start": "2706740",
    "end": "2712590"
  },
  {
    "text": "that we are trying to pick. And there's policy which\nis the language model or also called the decoder.",
    "start": "2712590",
    "end": "2717789"
  },
  {
    "text": "And there is the reward\nr which is provided by some external score. And the idea here,\nwell, we won't",
    "start": "2717790",
    "end": "2725200"
  },
  {
    "text": "go into details about\nreinforcement learning and how it works, but we will\nrecommend the class CS 234.",
    "start": "2725200",
    "end": "2734000"
  },
  {
    "text": "So in the reinforcement\nlearning context, because reinforcement learning\ninvolves a reward function,",
    "start": "2734000",
    "end": "2739370"
  },
  {
    "text": "that's very important. So how do we do reward\nestimation for text generation? Well, very natural\nidea is to just use",
    "start": "2739370",
    "end": "2746810"
  },
  {
    "text": "the evaluation metrics. So because you are trying to\ndo well in terms of evaluation, so why not just improve\nfor evaluation metrics",
    "start": "2746810",
    "end": "2754130"
  },
  {
    "text": "directly at training time? For example, in the case\nof machine translation, we can use BLEU score\nas the reward function.",
    "start": "2754130",
    "end": "2761300"
  },
  {
    "text": "In the case of summarization,\nwe can use ROUGE score as the reward function. But we really need to be careful\nabout optimizing for tasks",
    "start": "2761300",
    "end": "2769670"
  },
  {
    "text": "as opposed to gaming the reward\nbecause evaluation metrics are merely proxies for the\ngeneration quality.",
    "start": "2769670",
    "end": "2775790"
  },
  {
    "text": "So sometimes, suppose that\nyou run RL and improve the BLEU score by a lot, but\nwhen you run human evaluations,",
    "start": "2775790",
    "end": "2783260"
  },
  {
    "text": "humans might still\nthink that, well, this generated text is no better than\nthe previous one or even worse",
    "start": "2783260",
    "end": "2788990"
  },
  {
    "text": "even though it gives you\nmuch better BLEU score. So we want to be careful\nabout this case of not",
    "start": "2788990",
    "end": "2794940"
  },
  {
    "text": "gaming the reward. So what behaviors can we\ntie to a reward function?",
    "start": "2794940",
    "end": "2800130"
  },
  {
    "text": "This is about reward design\nand reward estimation. There are so many\nthings that we can do. We can do cross-modality\nconsistency",
    "start": "2800130",
    "end": "2806790"
  },
  {
    "text": "for image captioning. We can do sentence\nsimplicity to make sure",
    "start": "2806790",
    "end": "2812580"
  },
  {
    "text": "that we are generating\nsimple English that are understandable. We can do formality\nand politeness",
    "start": "2812580",
    "end": "2817650"
  },
  {
    "text": "to make sure that I don't know\nyour chatbot doesn't suddenly yell at you. And the most important thing\nthat's really, really popular",
    "start": "2817650",
    "end": "2826049"
  },
  {
    "text": "is recently is human preference. So we should just\nbuild a reward model",
    "start": "2826050",
    "end": "2831780"
  },
  {
    "text": "that captures human preference. And this is actually\nthe technique behind the ChatGPT model.",
    "start": "2831780",
    "end": "2837070"
  },
  {
    "text": "So the idea here\nis that we would ask human to rank a\nbunch of generated text based on their\npreference, and then we",
    "start": "2837070",
    "end": "2843720"
  },
  {
    "text": "will use this preference data\nto learn a reward function which will basically always assign\nhigh score to something",
    "start": "2843720",
    "end": "2851730"
  },
  {
    "text": "that humans might prefer and\nassign allow score to something that humans wouldn't prefer.",
    "start": "2851730",
    "end": "2857280"
  },
  {
    "text": "Yeah, question. Will it be more expensive\nto just [INAUDIBLE]?? Like, is it all\njust [INAUDIBLE]??",
    "start": "2857280",
    "end": "2863250"
  },
  {
    "text": "Oh, yeah, sure. I mean, it is going\nto be very expensive. But I feel like compared\nto all the cost of training",
    "start": "2863250",
    "end": "2868619"
  },
  {
    "text": "models training like 170\nbillion parameter models, I feel like OpenAI\nand Google are,",
    "start": "2868620",
    "end": "2874440"
  },
  {
    "text": "well, they can afford\nhiring lots of humans to do human annotations\nand ask their preference.",
    "start": "2874440",
    "end": "2880320"
  },
  {
    "text": "How much data would we need\nto do something like this? This is a great question.",
    "start": "2880320",
    "end": "2886089"
  },
  {
    "text": "So I think it's kind of a\nmystery about how much data you exactly need to achieve\nthe level of performance",
    "start": "2886090",
    "end": "2892410"
  },
  {
    "text": "of ChatGPT. But roughly speaking,\nI feel like whenever you try to fine-tune a model\non some downstream task,",
    "start": "2892410",
    "end": "2899138"
  },
  {
    "text": "similarly, here you\nare trying to fine-tune your model on human preference. It do need quite a lot\nof data, like maybe",
    "start": "2899138",
    "end": "2905820"
  },
  {
    "text": "on the scale of 50k to 100k. That's roughly the scale\nthat Anthropic actually",
    "start": "2905820",
    "end": "2911190"
  },
  {
    "text": "released some dataset\nabout human preference. That's roughly the scale\nthat they released, I think,",
    "start": "2911190",
    "end": "2916290"
  },
  {
    "text": "if I remember correctly. Yeah, question. So we talked about\nearlier about how many",
    "start": "2916290",
    "end": "2921470"
  },
  {
    "text": "of the state-of-the-art\nlanguage models use transformers as their architecture. How do you apply reinforcement\nlearning to this model?",
    "start": "2921470",
    "end": "2930730"
  },
  {
    "text": "To-- what do you mean? To transformer model? Yeah. I feel like\nreinforcement learning",
    "start": "2930730",
    "end": "2937599"
  },
  {
    "text": "is kind of a modeling tool. I mean, it's kind\nof an objective that you are trying to optimize. Instead of an NLU\nobjective, now you",
    "start": "2937600",
    "end": "2943990"
  },
  {
    "text": "are optimizing for\nan RL objective. So it's not really--\nit's kind of orthogonal",
    "start": "2943990",
    "end": "2949210"
  },
  {
    "text": "to the architecture choice. So transformer is\nan architecture. You just use\ntransformer to give you",
    "start": "2949210",
    "end": "2954850"
  },
  {
    "text": "probability of the\nnext token distribution or to try to estimate\nprobability of a sequence.",
    "start": "2954850",
    "end": "2960430"
  },
  {
    "text": "And then, once you have the\nprobability of a sequence, you use that probability\nof the sequence pass it into the RL\nobjective that you have.",
    "start": "2960430",
    "end": "2968619"
  },
  {
    "text": "And then suppose that you are\ntrying to do policy gradient or something. Then you need to estimate the\nprobability of that sequence.",
    "start": "2968620",
    "end": "2975400"
  },
  {
    "text": "And then you just need\nto be able to backprop through transformer,\nwhich is doable.",
    "start": "2975400",
    "end": "2980730"
  },
  {
    "text": "Yeah, so I think the\nquestion about architecture and objectives are orthogonal. So even if you have an\nLSTM, you can do it.",
    "start": "2980730",
    "end": "2986730"
  },
  {
    "text": "If you have a transformer,\nyou can also do it. Yeah. Cool. Hope I answered that question.",
    "start": "2986730",
    "end": "2994070"
  },
  {
    "text": "Yeah? I think just like the model T4\nto T4 for this kind of reward. For example, we can\nbuild another transformer",
    "start": "2994070",
    "end": "3000660"
  },
  {
    "text": "to calculate it? Yeah, I think that's\nexactly what they did. So, for example, you\nwould have GPT-3.",
    "start": "3000660",
    "end": "3007440"
  },
  {
    "text": "You use GPT-3 as the\ngenerator that generate text, and you kind of have another\npre-trained model that",
    "start": "3007440",
    "end": "3014190"
  },
  {
    "text": "could probably also\nbe GPT-3, but I'm guessing here that you fine-tune\nit to learn human preference.",
    "start": "3014190",
    "end": "3019890"
  },
  {
    "text": "And then once you have a\nhuman preference model, you use the human\npreference model to put it into RL\nas the reward model,",
    "start": "3019890",
    "end": "3027300"
  },
  {
    "text": "and then use the original\nGPT-3 as the policy model and then you apply RL\nobjectives and then update them.",
    "start": "3027300",
    "end": "3034600"
  },
  {
    "text": "So that you will get a new model\nthat's better at everything.",
    "start": "3034600",
    "end": "3040360"
  },
  {
    "text": "OK, cool. Actually, if you are\nvery curious about RLHF, I would encourage you to come\nto the next lecture, where",
    "start": "3040360",
    "end": "3047740"
  },
  {
    "text": "Jesse will talk about RLHF. RLHF is shorthand for\nRL using Human Feedback.",
    "start": "3047740",
    "end": "3055420"
  },
  {
    "text": " So takeaways.",
    "start": "3055420",
    "end": "3060450"
  },
  {
    "text": "Teacher forcing is\nstill the main algorithm for training text\ngeneration models,",
    "start": "3060450",
    "end": "3065760"
  },
  {
    "text": "and exposure bias causes\nproblems in text generation models. For example, it causes\nmodels to lose coherence,",
    "start": "3065760",
    "end": "3073020"
  },
  {
    "text": "causes model to be repetitive. And models must learn to recover\nfrom their own bad samples",
    "start": "3073020",
    "end": "3078870"
  },
  {
    "text": "by using techniques like\nscheduled sampling or DAgger.",
    "start": "3078870",
    "end": "3084180"
  },
  {
    "text": "Another approach to\nreduce exposure bias is to start with good text\nlike retrieval plus generation.",
    "start": "3084180",
    "end": "3090880"
  },
  {
    "text": "And we also discussed how\nto do training with RL. And this can actually\nmake model learn behaviors",
    "start": "3090880",
    "end": "3097319"
  },
  {
    "text": "that are preferred by human-- that are preferred by human\nor preferred by some metrics.",
    "start": "3097320",
    "end": "3102780"
  },
  {
    "text": "So to be very up to date,\nin the best language model nowadays, ChatGPT, the\ntraining is actually pipelined.",
    "start": "3102780",
    "end": "3110370"
  },
  {
    "text": "For example, we would first\npre-train a large language models using internet\ncorpus by self-supervision,",
    "start": "3110370",
    "end": "3115950"
  },
  {
    "text": "and this kind of gets you GPT-3,\nwhich is the original version.",
    "start": "3115950",
    "end": "3121030"
  },
  {
    "text": "And then, you would do some\nsort of instruction tuning to fine-tune the language\nmodel, to fine-tune",
    "start": "3121030",
    "end": "3126100"
  },
  {
    "text": "the pre-trained language model\nso that it learns roughly how to follow human instructions. And finally, we will\ndo RLHF to make sure",
    "start": "3126100",
    "end": "3133450"
  },
  {
    "text": "that these models are well\naligned with human preference. So if we start\nRLHF from scratch,",
    "start": "3133450",
    "end": "3140078"
  },
  {
    "text": "it's probably going to be\nvery hard for the model to converge because\nRL is hard to train for text data, et cetera.",
    "start": "3140078",
    "end": "3146630"
  },
  {
    "text": "So RL doesn't really\nwork from scratch. But with all this smart\ntricks about pre-training",
    "start": "3146630",
    "end": "3152500"
  },
  {
    "text": "and instruction tuning,\nsuddenly, now, they're off to a good start.",
    "start": "3152500",
    "end": "3159520"
  },
  {
    "text": "Cool. Any questions so far? OK. Yes?",
    "start": "3159520",
    "end": "3165020"
  },
  {
    "text": "I'm sorry. This is going [INAUDIBLE],,\nbut is the difference between DAgger and\nscheduled sampling just how",
    "start": "3165020",
    "end": "3171789"
  },
  {
    "text": "long the replacement words are? You mean the difference between\nDAgger and scheduled sampling",
    "start": "3171790",
    "end": "3178960"
  },
  {
    "text": "is how long the sequence are? Yeah, I think roughly that is\nit because, like for DAgger,",
    "start": "3178960",
    "end": "3185168"
  },
  {
    "text": "you are kind of trying\nto-- you are trying to put in a full generated sequence.",
    "start": "3185168",
    "end": "3190240"
  },
  {
    "text": "But I feel like there can\nbe variations of DAgger. DAgger is just like a\nhigh-level framework, an idea. There can be\nvariations of DAgger",
    "start": "3190240",
    "end": "3197410"
  },
  {
    "text": "that are very similar to\nscheduled sampling, I think. I feel like for\nschedule sampling is kind of a more smoothed\nversion of DAgger",
    "start": "3197410",
    "end": "3204730"
  },
  {
    "text": "because, for DAgger,\nyou have to, like-- for, well, basically\nfor this epoch,",
    "start": "3204730",
    "end": "3209980"
  },
  {
    "text": "I am generating something. And then, after\nthis epoch finishes, I put this into the data\ntogether and then train",
    "start": "3209980",
    "end": "3215470"
  },
  {
    "text": "for another epoch. Whereas DAgger seems to\nbe more flexible in terms of when you add data in.",
    "start": "3215470",
    "end": "3221350"
  },
  {
    "text": "Yes. So like if for DAgger, if you\nregress your models coming out, like how does it help the\nmodel improve performance?",
    "start": "3221350",
    "end": "3228890"
  },
  {
    "text": "I think that's a good question. I feel like if you regress\nthe model, for example, if you",
    "start": "3228890",
    "end": "3235120"
  },
  {
    "text": "regress the model\non its own output, I think there should be\nsmarter ways than to exactly",
    "start": "3235120",
    "end": "3242349"
  },
  {
    "text": "regress on your own output. For example, you might\nstill like consult some gold reference data. For example, given that you\nask the model to generate",
    "start": "3242350",
    "end": "3249790"
  },
  {
    "text": "for something and then\nyou can instead of using-- say, you ask the model\ngenerate for five tokens,",
    "start": "3249790",
    "end": "3256059"
  },
  {
    "text": "and then instead of using\nthe model's generation to be the sixth\ntoken, you probably",
    "start": "3256060",
    "end": "3261609"
  },
  {
    "text": "try to find some examples\nin the training data that would be a good\ncontinuations and then you",
    "start": "3261610",
    "end": "3266740"
  },
  {
    "text": "try to plug that in by\nlike connecting the model generation and some gold\ntext and then, therefore, you",
    "start": "3266740",
    "end": "3274119"
  },
  {
    "text": "are able to kind of correct the\nmodel even though it probably went off-path a little bit\nby generating its own stuff.",
    "start": "3274120",
    "end": "3280865"
  },
  {
    "text": "So it's kind of\nletting the model learn how to correct for itself. But, yes, I think you are right.",
    "start": "3280865",
    "end": "3285980"
  },
  {
    "text": "If you just ask the model to-- if you just put model\ngeneration in the data,",
    "start": "3285980",
    "end": "3291140"
  },
  {
    "text": "it shouldn't really work. Yeah, any other questions?",
    "start": "3291140",
    "end": "3297690"
  },
  {
    "text": "Cool. Moving on. ",
    "start": "3297690",
    "end": "3305340"
  },
  {
    "text": "Yes, so now we'll\ntalk about how we are going to evaluate NLG systems. So there are three types\nof methods for evaluation.",
    "start": "3305340",
    "end": "3313300"
  },
  {
    "text": "There is content\noverlap metrics. There is model-based metrics. And there is human evaluations.",
    "start": "3313300",
    "end": "3319920"
  },
  {
    "text": "So first, content overlap\nmetrics compute a score based on lexical similarities\nbetween the generated text",
    "start": "3319920",
    "end": "3326190"
  },
  {
    "text": "and the gold reference text. So the advantage\nof this approach is that it's very fast and\nefficient, and widely used.",
    "start": "3326190",
    "end": "3332490"
  },
  {
    "text": "For example, BLEU score\nis very popular in MT, and ROUGE score is very\npopular in summarization.",
    "start": "3332490",
    "end": "3338700"
  },
  {
    "text": " So this models are very popular\nbecause, well, these methods",
    "start": "3338700",
    "end": "3344250"
  },
  {
    "text": "are very popular because they\nare cheap and easy to run. But they are not really\nthe ideal metrics.",
    "start": "3344250",
    "end": "3349590"
  },
  {
    "text": "For example, simply\nrely on lexical overlap might miss some rephrasings that\nhave the same semantic meaning,",
    "start": "3349590",
    "end": "3356460"
  },
  {
    "text": "or it might reward text\nwith a large portion of lexical overlap but actually\nhave the opposite meaning.",
    "start": "3356460",
    "end": "3362520"
  },
  {
    "text": "So you have lots of both\nfalse positive and false negative problems. So despite all\nthese disadvantages,",
    "start": "3362520",
    "end": "3369760"
  },
  {
    "text": "the metrics are still the\ngold evaluation standard in machine translation. Part of the reason is that MT\nis actually super close-ended.",
    "start": "3369760",
    "end": "3377860"
  },
  {
    "text": "It's very non-open-ended,\nand then, therefore, this is probably still fine\nto use a BLEU score",
    "start": "3377860",
    "end": "3385210"
  },
  {
    "text": "to measure machine translation. And they get progressively\nworse for tasks that are more open-ended.",
    "start": "3385210",
    "end": "3390940"
  },
  {
    "text": "For example, they get\nworse for summarization because the output text\nbecomes much harder to measure.",
    "start": "3390940",
    "end": "3398380"
  },
  {
    "text": "They are much worse for dialogue\nwhich is more open-ended. And then they are\nmuch, much worse for story generation,\nwhich is also open-ended.",
    "start": "3398380",
    "end": "3405819"
  },
  {
    "text": "And then the drawback here\nis that because the n-gram metrics--",
    "start": "3405820",
    "end": "3410830"
  },
  {
    "text": "this is because, like, suppose\nthat you are generating a story that's\nrelatively long, then if you are still\nlooking at word overlap,",
    "start": "3410830",
    "end": "3417470"
  },
  {
    "text": "then you might actually get\nvery high n-gram scores because of your text is very long,\nnot because it's actually",
    "start": "3417470",
    "end": "3423250"
  },
  {
    "text": "of high quality. Just because you\nare talking so much that you might have covered\na lot of points already.",
    "start": "3423250",
    "end": "3429515"
  },
  {
    "text": "Yes. Can you [INAUDIBLE]\nexactly like that and compared to the cosine\nsimilarity between vectors?",
    "start": "3429515",
    "end": "3435250"
  },
  {
    "text": "Yes, exactly. That's kind of the\nnext thing that I will talk about as a better\nmetric for evaluation.",
    "start": "3435250",
    "end": "3442359"
  },
  {
    "text": "But for now, let's do like a\ncase study of a failure mode for BLEU score, for example.",
    "start": "3442360",
    "end": "3448400"
  },
  {
    "text": "So suppose that Chris\nasks a question, \"Are you enjoying the CS224N lectures?\" The correct answer, of\ncourse, is \"Heck yes!\"",
    "start": "3448400",
    "end": "3456280"
  },
  {
    "text": "So if we have this if one\nof the answer is \"Yes!\"",
    "start": "3456280",
    "end": "3461530"
  },
  {
    "text": "it will get a score\nof 0.61 because it has some lexical overlap\nwith the correct answer.",
    "start": "3461530",
    "end": "3467269"
  },
  {
    "text": "If you answer \"You\nknow it!\" then it gets a relatively lower score\nbecause it doesn't really have",
    "start": "3467270",
    "end": "3472990"
  },
  {
    "text": "any lexical overlap except\nfrom the exclamation mark. And if you answer \"Yup,\"\nthis is semantically correct,",
    "start": "3472990",
    "end": "3480250"
  },
  {
    "text": "but it actually gets\nzero score because there is no lexical overlap\nbetween the gold answer",
    "start": "3480250",
    "end": "3485890"
  },
  {
    "text": "and the generation. If you answer, \"Heck no!\" This should be wrong. But because it has lots of--",
    "start": "3485890",
    "end": "3492970"
  },
  {
    "text": "but because it has\nlots of lexical overlap with the correct\nanswer, it's actually getting some high scores.",
    "start": "3492970",
    "end": "3499520"
  },
  {
    "text": "So these two cases are\nthe major failure modes of lexical-based\nn-gram overlap metrics.",
    "start": "3499520",
    "end": "3505750"
  },
  {
    "text": "You get false negatives\nand false positives. So moving beyond this failure\nmodes of lexical-based metrics,",
    "start": "3505750",
    "end": "3515890"
  },
  {
    "text": "the next step is to check\nfor semantic similarities. And model-based\nmetrics are better at capturing the\nsemantic similarities.",
    "start": "3515890",
    "end": "3523400"
  },
  {
    "text": "So this is kind of similar\nto what you kind of raised up a couple minutes ago. We can actually use\nlearned representation",
    "start": "3523400",
    "end": "3530440"
  },
  {
    "text": "of words and\nsentences to compute semantic similarities between\ngenerated and referenced text.",
    "start": "3530440",
    "end": "3538310"
  },
  {
    "text": "So now we are no longer\nbottlenecked by n-gram, and instead, we are\nusing embeddings.",
    "start": "3538310",
    "end": "3543369"
  },
  {
    "text": "And this embeddings are\ngoing to be pre-trained, but the methods\ncan still live on because we can just swap in\ndifferent pre-trained methods",
    "start": "3543370",
    "end": "3549670"
  },
  {
    "text": "and use the fixed metrics. So here are some good\nexamples of the metrics that could be used.",
    "start": "3549670",
    "end": "3556150"
  },
  {
    "text": "One thing is to do\nvector similarity. This is very similar\nto homework one, where you are trying to compute\nsimilarity between words,",
    "start": "3556150",
    "end": "3563290"
  },
  {
    "text": "except now we are\ntrying to compute similarity between sentences. There are some ideas of how\nto go from word similarity",
    "start": "3563290",
    "end": "3570732"
  },
  {
    "text": "to sentence similarity. For example, you can just\naverage the embedding, which is like a relatively naive\nidea, but it works sometimes.",
    "start": "3570732",
    "end": "3579730"
  },
  {
    "text": "Another high-level\nidea is that we can measure word mover's distance.",
    "start": "3579730",
    "end": "3585160"
  },
  {
    "text": "The idea here is that we\ncan use optimal transport to align the source and\ntarget word embeddings.",
    "start": "3585160",
    "end": "3591730"
  },
  {
    "text": "Suppose that your\nsource word embedding is \"Obama speaks to\nthe media in Illinois,\"",
    "start": "3591730",
    "end": "3597490"
  },
  {
    "text": "and the target is \"The President\ngraced the press in Chicago,\" from a human\nevaluation perspective.",
    "start": "3597490",
    "end": "3604090"
  },
  {
    "text": "These two are\nactually very similar, but they are not exactly\naligned word by word. So we need to figure out how to\noptimally align word to word,",
    "start": "3604090",
    "end": "3612260"
  },
  {
    "text": "align Obama to President,\nalign Chicago to Illinois, and then, therefore, we\ncan compute a score--",
    "start": "3612260",
    "end": "3617990"
  },
  {
    "text": "we can compute the pairwise\nword embedding difference between this and\nthen get a good score",
    "start": "3617990",
    "end": "3623780"
  },
  {
    "text": "for the model-- for the\nsentence similarities. And finally, there\nis BERTSCORE which",
    "start": "3623780",
    "end": "3629240"
  },
  {
    "text": "is also a very popular metric\nfor semantic similarity. So it first computes\npairwise cosine distance",
    "start": "3629240",
    "end": "3635060"
  },
  {
    "text": "using BERT embeddings,\nand then it finds an optimal alignment\nbetween the source and target",
    "start": "3635060",
    "end": "3641000"
  },
  {
    "text": "sentence, and then they\nfinally compute some score. So I feel like these details\nare not really that important,",
    "start": "3641000",
    "end": "3647760"
  },
  {
    "text": "but the high-level idea is super\nimportant is that we can now",
    "start": "3647760",
    "end": "3653510"
  },
  {
    "text": "use word embeddings to compute\nsentence similarities by doing some sort of smart\nalignment and then",
    "start": "3653510",
    "end": "3658730"
  },
  {
    "text": "transform from word similarity\nto sentence similarities. To move beyond\nword embeddings, we",
    "start": "3658730",
    "end": "3664510"
  },
  {
    "text": "can also use sentence\nembeddings to compute sentence similarities. So typically, this doesn't\nhave the very comprehensive",
    "start": "3664510",
    "end": "3670890"
  },
  {
    "text": "alignment by word\nproblem, but it has similar problems about you\nneed to now align sentences",
    "start": "3670890",
    "end": "3676109"
  },
  {
    "text": "or phrases in a sentence. And similarly, there is BLEURT\nwhich is slightly different.",
    "start": "3676110",
    "end": "3681640"
  },
  {
    "text": "It is a regression\nmodel based on BERT. So the model is trained\nas a regression problem",
    "start": "3681640",
    "end": "3688020"
  },
  {
    "text": "to return a score that\nindicate how good the text is in terms of grammaticality and\nthe meaning of the reference--",
    "start": "3688020",
    "end": "3693990"
  },
  {
    "text": "and similarity with\nthe reference text. So this is kind of like trading\nevaluation as a regression problem.",
    "start": "3693990",
    "end": "3700480"
  },
  {
    "text": "Any questions so far? ",
    "start": "3700480",
    "end": "3708230"
  },
  {
    "text": "OK, cool. We can move on. So all the previous mentioned\napproaches are evaluating",
    "start": "3708230",
    "end": "3713690"
  },
  {
    "text": "semantic similarities. So they can be applied to\nnon-open-ended generation tasks. But what about\nopen-ended settings?",
    "start": "3713690",
    "end": "3720620"
  },
  {
    "text": "So here, enforcing\nsemantic similarity seems wrong because\na story can be perfectly fluent and\nperfectly high quality",
    "start": "3720620",
    "end": "3727640"
  },
  {
    "text": "without having to reassemble\nany of the reference stories. So one idea here\nis that maybe we",
    "start": "3727640",
    "end": "3734059"
  },
  {
    "text": "want to evaluate open-ended\ntext generation using this MAUVE score. MAUVE score computes the\ninformation divergence",
    "start": "3734060",
    "end": "3741320"
  },
  {
    "text": "in a quantized embedding space\nbetween the generated text and the gold reference text. So here is roughly the\ndetail of what's going on.",
    "start": "3741320",
    "end": "3749000"
  },
  {
    "text": "Suppose that you\nhave a batch of texts from the gold reference\nthat are human-written, and you have a batch of text\nthat's generated by your model.",
    "start": "3749000",
    "end": "3756800"
  },
  {
    "text": "Step number one is that you\nwant to embed this text. You want to put this text into\nsome continuous representation",
    "start": "3756800",
    "end": "3762350"
  },
  {
    "text": "space which is kind of\nthe figure to the left. But it's really hard to\ncompute any distance metrics",
    "start": "3762350",
    "end": "3768630"
  },
  {
    "text": "in this continuous\nembedding space because, well, different\nsentences might actually lie",
    "start": "3768630",
    "end": "3773640"
  },
  {
    "text": "very far away from each other. So the idea here is\nthat we are trying to do a k-means cluster to\ndiscretize the continuous space",
    "start": "3773640",
    "end": "3781110"
  },
  {
    "text": "into some discrete space. Now after the discretization,\nwe can actually have a histogram for the\ngold human-written text",
    "start": "3781110",
    "end": "3789750"
  },
  {
    "text": "and the histogram for the\nmachine-generated text. And then we can now compute\nprecision and recall",
    "start": "3789750",
    "end": "3795690"
  },
  {
    "text": "using these two\ndiscretized distributions, and then we can compute\nprecision by forward KL",
    "start": "3795690",
    "end": "3801330"
  },
  {
    "text": "and recall by backward KL. Yes, question. Why do we want to discretize it?",
    "start": "3801330",
    "end": "3806369"
  },
  {
    "text": "I didn't catch that. Why do we want to discretize it? So imagine that you-- suppose--",
    "start": "3806370",
    "end": "3811710"
  },
  {
    "text": "it's equivalent to answer\nwhy is it hard to work with the continuous space. The idea is like if you\nembed a word, if you embed",
    "start": "3811710",
    "end": "3819030"
  },
  {
    "text": "a sentence into the continuous\nspace, say that it lies here, and you embed another sentence\nin the continuous space here.",
    "start": "3819030",
    "end": "3824400"
  },
  {
    "text": "Suppose that you only have a\nfinite number of sentences. Then they would basically\nbe Dirac delta distributions",
    "start": "3824400",
    "end": "3830460"
  },
  {
    "text": "in your manifold, right? So it's hard to-- You probably want a\nsmoother distribution,",
    "start": "3830460",
    "end": "3835770"
  },
  {
    "text": "but it's hard to define what\nis a good smooth distribution in the case of text embedding\nbecause they are not",
    "start": "3835770",
    "end": "3841710"
  },
  {
    "text": "super interpretable. So therefore, eventually,\nyou will have, if you embed everything\nin the continuous space,",
    "start": "3841710",
    "end": "3847530"
  },
  {
    "text": "you will have lots of Dirac\ndeltas that are just very high and then not really\nconnected to their neighbors.",
    "start": "3847530",
    "end": "3856800"
  },
  {
    "text": "So it's hard to quantify\nKL divergence or a distance metrics in that space.",
    "start": "3856800",
    "end": "3862012"
  },
  {
    "text": "Well, for example, you have\nto make some assumptions. For example, you want to\nmake Gaussian assumptions that I want to smooth all the\nembeddings by convolving it",
    "start": "3862012",
    "end": "3869850"
  },
  {
    "text": "with a Gaussian. And then, you can start getting\nsome meaningful distance metrics. But with just the\nembeddings alone,",
    "start": "3869850",
    "end": "3877043"
  },
  {
    "text": "you're not going to get\nmeaningful distance metrics. And then it doesn't\nreally make sense to smooth things using\nGaussian because who",
    "start": "3877043",
    "end": "3882690"
  },
  {
    "text": "said word representations\nare Gaussian-related? Yeah, question.",
    "start": "3882690",
    "end": "3887910"
  },
  {
    "text": "How strong are the continuous\ntwo-dimensional distributions? I think this requires\nsome Gaussian smoothing.",
    "start": "3887910",
    "end": "3893990"
  },
  {
    "text": "Yeah, I think the plot is\nmade with some smoothing. Yeah. I mean, I didn't\nmake the plot, so I couldn't be perfectly sure.",
    "start": "3893990",
    "end": "3899810"
  },
  {
    "text": "But I think the\nfact that it looks like this means that you\nsmooth it a little bit. So different word embeddings--",
    "start": "3899810",
    "end": "3905798"
  },
  {
    "text": "These are kind of\nsentence embeddings or concatenated word\nembeddings because you are comparing sentences to\nsentences, not words to words.",
    "start": "3905798",
    "end": "3912275"
  },
  {
    "text": "Yeah. So the advantage\nof MAUVE score is that it is applicable\nto open-ended settings",
    "start": "3912275",
    "end": "3919040"
  },
  {
    "text": "because you are now\nmeasuring precision and recall with regard to\nthe target distribution.",
    "start": "3919040",
    "end": "3927150"
  },
  {
    "text": "Cool. So it has a better\nprobabilistic interpretation than all the previous\nsimilarity metrics.",
    "start": "3927150",
    "end": "3932599"
  },
  {
    "text": " Cool. Any other questions?",
    "start": "3932600",
    "end": "3937700"
  },
  {
    "text": "Yes. So if we're trying to maximize\nprecision-recall here,",
    "start": "3937700",
    "end": "3943670"
  },
  {
    "text": "how is that different\nfrom just trying to maximize the similarity\nbetween the target and the output distribution?",
    "start": "3943670",
    "end": "3949940"
  },
  {
    "text": "Yeah, that's a good question. Well, this is\nbecause in the case where it's really hard to\nget exactly the same thing.",
    "start": "3949940",
    "end": "3957829"
  },
  {
    "text": "Well, for example, I\nwould say that maybe because I've never\ntried this myself. But if you try to run off\na machine translation task,",
    "start": "3957830",
    "end": "3965510"
  },
  {
    "text": "you might get very high score. But for if you try to run BLEU\nscore on an open-ended text",
    "start": "3965510",
    "end": "3971180"
  },
  {
    "text": "generation, you will\nget super low score. It's just not really\nmeasurable because everything's so different from each other.",
    "start": "3971180",
    "end": "3977190"
  },
  {
    "text": "So I feel like MAUVE is kind\nof a middle ground where you are trying to evaluate\nsomething that are actually",
    "start": "3977190",
    "end": "3982490"
  },
  {
    "text": "very far away from each\nother, but you still want a meaningful\nrepresentation.",
    "start": "3982490",
    "end": "3987943"
  },
  {
    "text": "Yeah, of course. I mean, if your source and\ntarget are exactly the same or are just different\nup to some rephrasings,",
    "start": "3987943",
    "end": "3993920"
  },
  {
    "text": "you will get the\nbest MAUVE score. But maybe that's not really\nwhat you're looking for because, given the\ncurrent situation,",
    "start": "3993920",
    "end": "4000470"
  },
  {
    "text": "you only have generations\nthat are very far away from the gold text. How do we evaluate\nthis type of things?",
    "start": "4000470",
    "end": "4007069"
  },
  {
    "text": "Yes, question in the back. I'm still trying to\nunderstand the MAUVE score. Is it possible to\nwrite out the math even",
    "start": "4007070",
    "end": "4014450"
  },
  {
    "text": "in just kind of\npseudo-simple form? Yeah, I think it's possible.",
    "start": "4014450",
    "end": "4019880"
  },
  {
    "text": "Maybe we can put this\ndiscussion after class because I kind of want\nto finish my slides.",
    "start": "4019880",
    "end": "4025620"
  },
  {
    "text": "Yeah, but happy to\nchat after class. There is a paper about if\nyou search for MAUVE score.",
    "start": "4025620",
    "end": "4030960"
  },
  {
    "text": "I think it's probably the best\npaper in some ICML or Europe's conference as well.",
    "start": "4030960",
    "end": "4036530"
  },
  {
    "text": "OK, so moving on. I've pointed out that there\nare so many evaluation methods.",
    "start": "4036530",
    "end": "4041700"
  },
  {
    "text": "So let's take a\nstep back and think about what's a good metric\nfor evaluation methods. So how do we\nevaluate evaluations?",
    "start": "4041700",
    "end": "4048380"
  },
  {
    "text": "Nowadays, the gold\nstandard is still to check how well this metric\nis aligned with human judgment.",
    "start": "4048380",
    "end": "4054690"
  },
  {
    "text": "So if a model match\nhuman preference, in other words, if the metric\nis very correlated with--",
    "start": "4054690",
    "end": "4060710"
  },
  {
    "text": "if the metric correlates very\nstrongly with human judgment, then we say that the\nmetric is a good metric.",
    "start": "4060710",
    "end": "4066060"
  },
  {
    "text": "So in this plot, people have\nplot BLEU score and human score on y and x-axis, respectively.",
    "start": "4066060",
    "end": "4073319"
  },
  {
    "text": "And then, because we\ndidn't see a correlation, a strong correlation,\nthis kind of suggests that BLEU score\nis not a very good metric.",
    "start": "4073320",
    "end": "4081450"
  },
  {
    "text": "So actually, the gold standard\nfor human evaluation-- the gold standard for\nevaluating language models",
    "start": "4081450",
    "end": "4088340"
  },
  {
    "text": "is always to do\nhuman evaluation. So automatic metrics fall short\nof matching human decisions,",
    "start": "4088340",
    "end": "4095720"
  },
  {
    "text": "and human evaluation is kind\nof the most important criteria for evaluating text that\nare generated from a model.",
    "start": "4095720",
    "end": "4103080"
  },
  {
    "text": "And it's also the gold standard\nin developing automatic metrics because we want everything\nto match human evaluation.",
    "start": "4103080",
    "end": "4108920"
  },
  {
    "text": " So what do we mean\nby human evaluation? How is it conducted?",
    "start": "4108920",
    "end": "4115189"
  },
  {
    "text": "Typically, we will provide\nhuman annotators with some axis that we care about,\nlike fluency,",
    "start": "4115189",
    "end": "4121640"
  },
  {
    "text": "coherence for open-ended\ntext generation. Suppose that we also care about\nfactuality for summarization.",
    "start": "4121640",
    "end": "4127549"
  },
  {
    "text": "We care about style of the\nwriting, and common sense, for example, if we're trying\nto write a children's story.",
    "start": "4127550",
    "end": "4133040"
  },
  {
    "text": " Essentially another\nthing to note",
    "start": "4133040",
    "end": "4138350"
  },
  {
    "text": "is that please don't\ncompare human evaluations across different papers\nor different studies because human evaluations\ntends to not be well-calibrated",
    "start": "4138350",
    "end": "4145699"
  },
  {
    "text": "and are not really reproducible. Even though we believe\nthat human evaluations are",
    "start": "4145700",
    "end": "4150920"
  },
  {
    "text": "the gold standard, there\nare still many drawbacks. For example, human evaluations\nare really slow and expensive.",
    "start": "4150920",
    "end": "4158540"
  },
  {
    "text": "But even beyond the\nskill and expensiveness, they are still not\nperfect because,",
    "start": "4158540",
    "end": "4163729"
  },
  {
    "text": "first, human evaluations, the\nresults may be inconsistent, and they may not be\nvery reproducible.",
    "start": "4163729",
    "end": "4169170"
  },
  {
    "text": "So if you ask the same human\nwhether you like A or B, they might say A the first\ntime and B the second time.",
    "start": "4169170",
    "end": "4174859"
  },
  {
    "text": "And then human evaluations are\ntypically not really logical. And really, sometimes,\nthe human annotators",
    "start": "4174859",
    "end": "4181910"
  },
  {
    "text": "might misinterpret\nyour question. Suppose that you want them to\nmeasure coherence of the text.",
    "start": "4181910",
    "end": "4187040"
  },
  {
    "text": "Different people have different\ncriteria for coherence. Some people might\nthink coherence is equivalent to\nfluency, and then they",
    "start": "4187040",
    "end": "4192950"
  },
  {
    "text": "look for grammaticality errors. Some people might\nthink coherence means how well your\ncontinuation is aligned",
    "start": "4192950",
    "end": "4199490"
  },
  {
    "text": "with the prompt or the topic. So there are all sorts\nof misunderstandings that might make human\nevaluation very hard.",
    "start": "4199490",
    "end": "4208070"
  },
  {
    "text": "And finally, human\nevaluation only measures precision, not recall. This means that you can\ngive a sentence to human",
    "start": "4208070",
    "end": "4214970"
  },
  {
    "text": "and ask the human how do\nyou like this sentence, but you couldn't ask the human\nlike whether this model is",
    "start": "4214970",
    "end": "4220910"
  },
  {
    "text": "able to generate all possible\nsentences that are good. So it's only a\nprecision-based metrics, not",
    "start": "4220910",
    "end": "4226520"
  },
  {
    "text": "a recall-based metrics. So here are two\napproaches that tries to combine human\nevaluations with modeling.",
    "start": "4226520",
    "end": "4234770"
  },
  {
    "text": "For example, the first\nidea is basically trying to learn a metric\nfrom human judgment",
    "start": "4234770",
    "end": "4241130"
  },
  {
    "text": "basically by trying to use human\njudgment data as training data",
    "start": "4241130",
    "end": "4246440"
  },
  {
    "text": "and then train a model to\nsimulate human judgment. And the second\napproach is trying to ask the human and\nmodel to collaborate so",
    "start": "4246440",
    "end": "4254390"
  },
  {
    "text": "that the human would be in\ncharge of evaluating precision, whereas the model would be in\ncharge of evaluating recall.",
    "start": "4254390",
    "end": "4262010"
  },
  {
    "text": "Also, we have tried approaches\nin terms of evaluating models interactively. So, in this case,\nwe will no longer--",
    "start": "4262010",
    "end": "4268610"
  },
  {
    "text": "we not only care about\nthe output quality. We also care about\nhow the person feels",
    "start": "4268610",
    "end": "4274160"
  },
  {
    "text": "when they interact with\nthe model, when they try to be a co-author\nwith the model, and how the person feels about\nthe writing process, et cetera.",
    "start": "4274160",
    "end": "4282900"
  },
  {
    "text": "So this is called\ntrying to evaluate the models more interactively. ",
    "start": "4282900",
    "end": "4289219"
  },
  {
    "text": "So the takeaway here\nis that content overlap is a bad metric.",
    "start": "4289220",
    "end": "4294550"
  },
  {
    "text": "Model-based metrics\nbecome better because it's more\nfocused on semantics, but it's still not good enough.",
    "start": "4294550",
    "end": "4299980"
  },
  {
    "text": "Human judgment is\nthe gold standard, but it's hard to do\nhuman judgment-- it's hard to do human study well.",
    "start": "4299980",
    "end": "4306010"
  },
  {
    "text": "And in many cases, this is\na hint for final project. The best judge of the output\nquality is actually you.",
    "start": "4306010",
    "end": "4312670"
  },
  {
    "text": "So if you want to\ndo a final project in like natural\nlanguage generation, you should look at the\nmodel output yourself",
    "start": "4312670",
    "end": "4318670"
  },
  {
    "text": "and don't just rely on the\nnumbers that are reported by BLEU square or something.",
    "start": "4318670",
    "end": "4325030"
  },
  {
    "text": "Cool. So finally, we will discuss\nethical considerations of natural language\ngeneration problems.",
    "start": "4325030",
    "end": "4332570"
  },
  {
    "text": "So as language models\ngets better and better, ethical considerations\nbecomes much more pressing.",
    "start": "4332570",
    "end": "4338110"
  },
  {
    "text": "So we want to ensure\nthat the model are well aligned with human values. For example, We want to\nmake sure the models are not",
    "start": "4338110",
    "end": "4344500"
  },
  {
    "text": "harmful, they are\nnot toxic, and we want to make sure that the\nmodels are unbiased and fair to all demographics groups.",
    "start": "4344500",
    "end": "4351170"
  },
  {
    "text": "So, for example,\nhere, we also don't want the model to generate\nany harmful content.",
    "start": "4351170",
    "end": "4357130"
  },
  {
    "text": "Basically, I try\nto prompt ChatGPT to say, can you write me some\ntoxic content ChatGPT politely",
    "start": "4357130",
    "end": "4362320"
  },
  {
    "text": "refused me, which I'm\nquite happy about. But there are other people who\nkind try to jailbreak ChatGPT.",
    "start": "4362320",
    "end": "4371530"
  },
  {
    "text": "The idea here is that ChatGPT,\nactually, I think internally, they probably implement\nsome detection tools",
    "start": "4371530",
    "end": "4377410"
  },
  {
    "text": "so that when you try to\nprompt it adversarially, it's going to avoid\ndoing adversarial things.",
    "start": "4377410",
    "end": "4382900"
  },
  {
    "text": "But here, there are many\nvery complicated ways to prompt ChatGPT so that\nyou can get over the firewall",
    "start": "4382900",
    "end": "4390230"
  },
  {
    "text": "and then, therefore, still\nask ChatGPT to generate some I don't know, like bad English.",
    "start": "4390230",
    "end": "4395795"
  },
  {
    "start": "4395795",
    "end": "4401760"
  },
  {
    "text": "So another problem with\nthis large language models is that they are not\nnecessarily truthful.",
    "start": "4401760",
    "end": "4407790"
  },
  {
    "text": "So, for example,\nthis very famous news that Google's model actually\ngenerate factual errors, which",
    "start": "4407790",
    "end": "4415530"
  },
  {
    "text": "is quite disappointing, but\nthe way the model talks about it is very convincing, so\nlike you wouldn't really",
    "start": "4415530",
    "end": "4422970"
  },
  {
    "text": "know that it's a factual error\nunless you go check that this is not the picture\nof-- this is not",
    "start": "4422970",
    "end": "4428220"
  },
  {
    "text": "the first picture or something. So we want to avoid\nthis type of problems.",
    "start": "4428220",
    "end": "4433470"
  },
  {
    "text": "Actually, the\nmodels have already been trying very hard to\nrefrain from like generating",
    "start": "4433470",
    "end": "4438809"
  },
  {
    "text": "harmful content, but like\nfor models that are more open source and are smaller, the\nsame problem still appears.",
    "start": "4438810",
    "end": "4446940"
  },
  {
    "text": "And then typically, when\nwe do our final project or when we work with\nmodels, we are probably going to deal with\nmuch smaller models,",
    "start": "4446940",
    "end": "4453340"
  },
  {
    "text": "and then therefore, we need\nto think about ways to deal with this problems better. So text generation\nmodels are often",
    "start": "4453340",
    "end": "4459210"
  },
  {
    "text": "constructed from\npre-trained language models, and then pre-trained\nlanguage models are trained on internet\ndata, which contains",
    "start": "4459210",
    "end": "4465280"
  },
  {
    "text": "lots of harmful stuff and bias. So when the models are\nprompted for this information,",
    "start": "4465280",
    "end": "4472390"
  },
  {
    "text": "they will just repeat\nthe negative stereotypes that they learn from the\ninternet training data. So one way to avoid this\nis to do extensive data",
    "start": "4472390",
    "end": "4480250"
  },
  {
    "text": "cleaning so that the\npre-training data does not contain any bias or\nstereotypical content.",
    "start": "4480250",
    "end": "4485520"
  },
  {
    "text": "However, this is going to be\nvery labor intensive and almost impossible to do\nbecause filtering a large amount of internet data\nis just so costly that it's not",
    "start": "4485520",
    "end": "4493533"
  },
  {
    "text": "really possible.  Again, with existing language\nmodels like GPT-2 Medium,",
    "start": "4493533",
    "end": "4501830"
  },
  {
    "text": "there are some\nadversarial inputs that almost always\ntrigger toxic content, and these models might be\nexploited in the real world",
    "start": "4501830",
    "end": "4510880"
  },
  {
    "text": "by ill-intended people. So, for example, there's a paper\nabout universal adversarial",
    "start": "4510880",
    "end": "4516789"
  },
  {
    "text": "triggers where the authors\njust find some universal set of words that would trigger bad\ncontents from the model-- that",
    "start": "4516790",
    "end": "4523218"
  },
  {
    "text": "would trigger toxic\ncontent from the model.  And sometimes, even if you\ndon't try to trigger the model,",
    "start": "4523218",
    "end": "4530800"
  },
  {
    "text": "the model might still start\nto generate toxic content by itself. So, in this case, the\npre-trained language models",
    "start": "4530800",
    "end": "4537820"
  },
  {
    "text": "are prompted with very\ninnocuous prompts, but they still degenerate\ninto toxic content.",
    "start": "4537820",
    "end": "4543220"
  },
  {
    "text": "So the takeaway here\nis that models really shouldn't be deployed\nwithout proper safeguards",
    "start": "4543220",
    "end": "4548980"
  },
  {
    "text": "to control for toxic content\nor any harmful contents in general. And models should\nnot be deployed",
    "start": "4548980",
    "end": "4554989"
  },
  {
    "text": "without careful considerations\nof how users will interact with these models. ",
    "start": "4554990",
    "end": "4562190"
  },
  {
    "text": "So in the ethics section,\none major takeaway is that we are\ntrying to advocate",
    "start": "4562190",
    "end": "4567250"
  },
  {
    "text": "that you need to think\nmore about your model-- about the model that\nyou are building. So before deploying or\npublishing any NLG models,",
    "start": "4567250",
    "end": "4574870"
  },
  {
    "text": "please check if the model's\noutput is not harmful, and please check if the model is\nrobust to all the trigger words",
    "start": "4574870",
    "end": "4582550"
  },
  {
    "text": "and other adversarial prompts. And, of course, there are more. Well, basically,\none can never do",
    "start": "4582550",
    "end": "4588909"
  },
  {
    "text": "enough to improve the ethics\nof text generation systems. And OK, cool, I still\nhave three minutes left.",
    "start": "4588910",
    "end": "4595310"
  },
  {
    "text": "So I can still do\nconcluding thoughts. The idea here,\nwell, today we talk about the exciting applications\nof natural language generation",
    "start": "4595310",
    "end": "4602650"
  },
  {
    "text": "systems. But, well, one might\nthink that well given",
    "start": "4602650",
    "end": "4607840"
  },
  {
    "text": "that ChatGPT is already so\ngood, are there any other things that we can do research-wise? If you try interacting\nwith these models--",
    "start": "4607840",
    "end": "4614950"
  },
  {
    "text": "if you try to interact\nwith these models, actually you can see\nthat there are still lots of limitations in their\nskills and performance.",
    "start": "4614950",
    "end": "4621800"
  },
  {
    "text": "For example, ChatGPT is\nable to do a lot of things with manipulating text,\nbut it couldn't really",
    "start": "4621800",
    "end": "4628480"
  },
  {
    "text": "create interesting contents,\nor it couldn't really think deeply about stuff.",
    "start": "4628480",
    "end": "4634180"
  },
  {
    "text": "So there are lots of chat\nrooms, and there are still many improvements ahead. And evaluation remains\na really huge challenge",
    "start": "4634180",
    "end": "4641470"
  },
  {
    "text": "in natural language generation. Basically, we need better\nways to automatically evaluate performance of NLG models\nbecause human evaluations are",
    "start": "4641470",
    "end": "4649760"
  },
  {
    "text": "expensive and not reproducible. So it's better to\nfigure out ways how to compile all those\nhuman judgment into a very",
    "start": "4649760",
    "end": "4658460"
  },
  {
    "text": "reliable and trustworthy model. And also, with the advance of\nall this large-scale language",
    "start": "4658460",
    "end": "4664849"
  },
  {
    "text": "models doing like\nneural natural language generation has been\nreset, and it's never",
    "start": "4664850",
    "end": "4672050"
  },
  {
    "text": "been easier to jump\ninto this space because now there are all the\ntools that are already there for you to build upon.",
    "start": "4672050",
    "end": "4678420"
  },
  {
    "text": "And finally, it is one\nof the most exciting and fun areas of NLP to work on. So yeah, I'm happy to\nchat more about NLG",
    "start": "4678420",
    "end": "4685010"
  },
  {
    "text": "if you have any questions\nboth after class and in class. I guess in one minute.",
    "start": "4685010",
    "end": "4691520"
  },
  {
    "text": "OK, cool. That's everything. So do you have any questions? If you don't, we\ncan end the class.",
    "start": "4691520",
    "end": "4698830"
  },
  {
    "start": "4698830",
    "end": "4704000"
  }
]
[
  {
    "text": "Now, we're going to\ndo the lab on deep",
    "start": "0",
    "end": "3140"
  },
  {
    "text": "learning for chapter ten.",
    "start": "3140",
    "end": "4760"
  },
  {
    "text": "And we're going to show you\nhow we fit the models that we",
    "start": "4760",
    "end": "8180"
  },
  {
    "text": "saw in the chapter.",
    "start": "8180",
    "end": "10610"
  },
  {
    "text": "So we implement deep learning\nthrough the Keras package",
    "start": "10610",
    "end": "15469"
  },
  {
    "text": "in R, which is a frontend\nto TensorFlow, which is",
    "start": "15470",
    "end": "21050"
  },
  {
    "text": "the system developed at Google.",
    "start": "21050",
    "end": "24080"
  },
  {
    "text": "And Keras and TensorFlow\nare implemented in Python.",
    "start": "24080",
    "end": "28970"
  },
  {
    "text": "And so there are package Keras\ninterfaces to the Python code.",
    "start": "28970",
    "end": "34399"
  },
  {
    "text": "So this is quite\na different level",
    "start": "34400",
    "end": "37220"
  },
  {
    "text": "to what we've seen up till now.",
    "start": "37220",
    "end": "39320"
  },
  {
    "text": "So in order to be able to run\nKeras, as we do in this lab,",
    "start": "39320",
    "end": "45680"
  },
  {
    "text": "you need to have a Python\nimplementation on your machine,",
    "start": "45680",
    "end": "50420"
  },
  {
    "text": "on your computer.",
    "start": "50420",
    "end": "52579"
  },
  {
    "text": "So it's a little bit\nof a learning curve,",
    "start": "52580",
    "end": "55220"
  },
  {
    "text": "but it's manageable.",
    "start": "55220",
    "end": "57620"
  },
  {
    "text": "On the book website,\nthere's instructions",
    "start": "57620",
    "end": "62280"
  },
  {
    "text": "on how to install\nKeras, TensorFlow,",
    "start": "62280",
    "end": "65640"
  },
  {
    "text": "and Python on your machine\nfor all the popular machines.",
    "start": "65640",
    "end": "70650"
  },
  {
    "text": "And this, the Keras\nsystem that we use",
    "start": "70650",
    "end": "74250"
  },
  {
    "text": "follows the book\nby Francis Chollet",
    "start": "74250",
    "end": "77340"
  },
  {
    "text": "and JJ Allaire called,\nDeep Learning with R.",
    "start": "77340",
    "end": "83579"
  },
  {
    "text": "And so it may be useful to get\na copy of this book as well.",
    "start": "83580",
    "end": "89820"
  },
  {
    "text": "So we assume that you have Keras\nup and running on your machine,",
    "start": "89820",
    "end": "94500"
  },
  {
    "text": "if you want to follow\nthrough on this lab.",
    "start": "94500",
    "end": "97870"
  },
  {
    "text": "Now, the other thing\nwe're doing in this lab",
    "start": "97870",
    "end": "100270"
  },
  {
    "text": "is, you'll see\nthere's a lot of text.",
    "start": "100270",
    "end": "102700"
  },
  {
    "text": "And for the new\nedition of the book,",
    "start": "102700",
    "end": "105640"
  },
  {
    "text": "we've presented all\nthe labs and give code",
    "start": "105640",
    "end": "111070"
  },
  {
    "text": "for all the labs in\na number of formats.",
    "start": "111070",
    "end": "113770"
  },
  {
    "text": "One of them is R\nmarkdown format,",
    "start": "113770",
    "end": "116380"
  },
  {
    "text": "which is what you see here.",
    "start": "116380",
    "end": "118070"
  },
  {
    "text": "And this pretty much faithfully\nreproduces exactly what's",
    "start": "118070",
    "end": "122800"
  },
  {
    "text": "in the lab in the book.",
    "start": "122800",
    "end": "125250"
  },
  {
    "text": "So it's a good\nopportunity to learn",
    "start": "125250",
    "end": "127920"
  },
  {
    "text": "the ins and outs of our\nmarkdown, which is really",
    "start": "127920",
    "end": "131160"
  },
  {
    "text": "a good way of writing R code\nand recording what you're doing",
    "start": "131160",
    "end": "136020"
  },
  {
    "text": "and the trains of\nthought and so on.",
    "start": "136020",
    "end": "138240"
  },
  {
    "text": "And you're running R markdown\nin what environment here?",
    "start": "138240",
    "end": "141460"
  },
  {
    "text": "Well, so we're running\nthis in our studio itself.",
    "start": "141460",
    "end": "145870"
  },
  {
    "text": "So this is our studio window.",
    "start": "145870",
    "end": "148260"
  },
  {
    "text": "And it, of course,\nunderstands R markdown.",
    "start": "148260",
    "end": "151860"
  },
  {
    "text": "And you'll see, there's\na really nice interface",
    "start": "151860",
    "end": "154440"
  },
  {
    "text": "for running R markdown.",
    "start": "154440",
    "end": "156420"
  },
  {
    "text": "OK, so let's get started.",
    "start": "156420",
    "end": "158020"
  },
  {
    "text": "So you see a lot of text.",
    "start": "158020",
    "end": "159540"
  },
  {
    "text": "And in fact, if you were to knit\nthis file, it would chug along,",
    "start": "159540",
    "end": "165659"
  },
  {
    "text": "and it would produce an\nHTML document in this case,",
    "start": "165660",
    "end": "170280"
  },
  {
    "text": "that when you look at it, it's\ngoing to look just like the lab.",
    "start": "170280",
    "end": "173640"
  },
  {
    "text": "Modulo a few tiny little\nmaybe differences,",
    "start": "173640",
    "end": "177030"
  },
  {
    "text": "but it'll look pretty\nmuch like the lab.",
    "start": "177030",
    "end": "180180"
  },
  {
    "text": "So here, we scroll down.",
    "start": "180180",
    "end": "182280"
  },
  {
    "text": "And the first thing\nwe do is we're",
    "start": "182280",
    "end": "185470"
  },
  {
    "text": "going to implement\nthe single layer",
    "start": "185470",
    "end": "187480"
  },
  {
    "text": "network on the hitter's data,\nwhich we saw in the chapter.",
    "start": "187480",
    "end": "193510"
  },
  {
    "text": "We say, library ISRL2.",
    "start": "193510",
    "end": "196140"
  },
  {
    "text": "So for the second\nedition of the book,",
    "start": "196140",
    "end": "199000"
  },
  {
    "text": "we've got a new library,\nwhich pretty much includes",
    "start": "199000",
    "end": "202930"
  },
  {
    "text": "the old library plus\nwhatever additional data sets",
    "start": "202930",
    "end": "206439"
  },
  {
    "text": "and maybe functions we\nneed in the second edition.",
    "start": "206440",
    "end": "209690"
  },
  {
    "text": "And that's called ISLR2,\nwhich you can get from Cran.",
    "start": "209690",
    "end": "213160"
  },
  {
    "text": "And then the first few lines are\nreading in the hitter's data.",
    "start": "213160",
    "end": "217390"
  },
  {
    "text": "The hitter's data has\ngot missing values.",
    "start": "217390",
    "end": "220750"
  },
  {
    "text": "So we use the function\nna.omit to remove all rows",
    "start": "220750",
    "end": "225070"
  },
  {
    "text": "with missing values, in fact.",
    "start": "225070",
    "end": "226930"
  },
  {
    "text": "And then we also\nset the random seed.",
    "start": "226930",
    "end": "229510"
  },
  {
    "text": "And we select a\ntest set, which is",
    "start": "229510",
    "end": "233200"
  },
  {
    "text": "going to be one-third\nof the data set, OK.",
    "start": "233200",
    "end": "235940"
  },
  {
    "text": "And so to implement\nthis whole chunk,",
    "start": "235940",
    "end": "238330"
  },
  {
    "text": "I'm just going to press\nthe arrow key here.",
    "start": "238330",
    "end": "242530"
  },
  {
    "text": "And there, it's done, OK.",
    "start": "242530",
    "end": "244780"
  },
  {
    "text": "No output, it just does it.",
    "start": "244780",
    "end": "247030"
  },
  {
    "text": "And then we're going to fit a\nlinear model, which, of course,",
    "start": "247030",
    "end": "249920"
  },
  {
    "text": "this is familiar.",
    "start": "249920",
    "end": "250790"
  },
  {
    "text": "So we use the LM function.",
    "start": "250790",
    "end": "253239"
  },
  {
    "text": "The response is salary.",
    "start": "253240",
    "end": "255550"
  },
  {
    "text": "So this is the baseball hitters\nand salary of the batsman.",
    "start": "255550",
    "end": "261700"
  },
  {
    "text": "Twiddle dot, again, means to\nuse all the other variables,",
    "start": "261700",
    "end": "264580"
  },
  {
    "text": "except salary as features.",
    "start": "264580",
    "end": "268419"
  },
  {
    "text": "And we use gitters\nminus test IDs.",
    "start": "268420",
    "end": "271430"
  },
  {
    "text": "So we're going to use\nthe training data.",
    "start": "271430",
    "end": "273139"
  },
  {
    "text": "So we subset out the test data.",
    "start": "273140",
    "end": "275530"
  },
  {
    "text": "And then we do a prediction\non the test data.",
    "start": "275530",
    "end": "279220"
  },
  {
    "text": "And then we compute\nthe test error.",
    "start": "279220",
    "end": "281990"
  },
  {
    "text": "So I'll just do\nit, first of all.",
    "start": "281990",
    "end": "284349"
  },
  {
    "text": "And we see, in this interface,\nthe output just appears",
    "start": "284350",
    "end": "288280"
  },
  {
    "text": "on the screen in the markdown.",
    "start": "288280",
    "end": "290240"
  },
  {
    "text": "So that's very convenient.",
    "start": "290240",
    "end": "292030"
  },
  {
    "text": "So that's the mean\nabsolute prediction",
    "start": "292030",
    "end": "294460"
  },
  {
    "text": "error on the test data.",
    "start": "294460",
    "end": "296919"
  },
  {
    "text": "Now, we used another incantation\nthat we've not necessarily",
    "start": "296920",
    "end": "300550"
  },
  {
    "text": "used before.",
    "start": "300550",
    "end": "301509"
  },
  {
    "text": "And that's the function\nwidth, which is really nice.",
    "start": "301510",
    "end": "304610"
  },
  {
    "text": "So width takes, as a first\nargument, the data frame.",
    "start": "304610",
    "end": "308699"
  },
  {
    "text": "And then the\nsubsequent expression",
    "start": "308700",
    "end": "311730"
  },
  {
    "text": "can use any of the variables\nby naming the data frame",
    "start": "311730",
    "end": "314490"
  },
  {
    "text": "and compute something.",
    "start": "314490",
    "end": "316080"
  },
  {
    "text": "And so that's what we did here.",
    "start": "316080",
    "end": "317909"
  },
  {
    "text": "So with gitters test study,\nso using that as the data,",
    "start": "317910",
    "end": "322380"
  },
  {
    "text": "we're able to just\nreference lpred and salary",
    "start": "322380",
    "end": "325500"
  },
  {
    "text": "and compute the\nmean absolute error.",
    "start": "325500",
    "end": "328680"
  },
  {
    "text": "So that's nice.",
    "start": "328680",
    "end": "330690"
  },
  {
    "text": "OK, the next thing\nwe're going to use",
    "start": "330690",
    "end": "332880"
  },
  {
    "text": "is glmnet because we\nwant to fit a lasso",
    "start": "332880",
    "end": "335610"
  },
  {
    "text": "model to the hitters\ndata-- well, gitters.",
    "start": "335610",
    "end": "340289"
  },
  {
    "text": "Glmnet doesn't know\nabout formulas.",
    "start": "340290",
    "end": "343150"
  },
  {
    "text": "They're not\nimplemented in glmnet.",
    "start": "343150",
    "end": "345310"
  },
  {
    "text": "So we need to make\nan x and a y matrix.",
    "start": "345310",
    "end": "348270"
  },
  {
    "text": "And so we use a\nfunction model matrix,",
    "start": "348270",
    "end": "352169"
  },
  {
    "text": "which is a handy function.",
    "start": "352170",
    "end": "354340"
  },
  {
    "text": "It can take a formula.",
    "start": "354340",
    "end": "355690"
  },
  {
    "text": "In this case, we tell it,\nsalary is the response",
    "start": "355690",
    "end": "358890"
  },
  {
    "text": "because we want\nit to exclude it.",
    "start": "358890",
    "end": "361320"
  },
  {
    "text": "And dot means, again,\nall the variables.",
    "start": "361320",
    "end": "364050"
  },
  {
    "text": "And minus 1 means we\ndon't want an intercept.",
    "start": "364050",
    "end": "366520"
  },
  {
    "text": "Otherwise, model matrix would\nnormally include an intercept,",
    "start": "366520",
    "end": "369330"
  },
  {
    "text": "and you tell it the data.",
    "start": "369330",
    "end": "371319"
  },
  {
    "text": "And we call that x And\ny is the salary data.",
    "start": "371320",
    "end": "376890"
  },
  {
    "text": "And we've actually\nwrapped the function scale",
    "start": "376890",
    "end": "379440"
  },
  {
    "text": "around that model matrix.",
    "start": "379440",
    "end": "380910"
  },
  {
    "text": "And scale will standardize the\ncolumns to have unit variance",
    "start": "380910",
    "end": "386320"
  },
  {
    "text": "and mean 0.",
    "start": "386320",
    "end": "387337"
  },
  {
    "text": "I thought we normally\nhave intercepts.",
    "start": "387337",
    "end": "388920"
  },
  {
    "text": "Why are we excluding one now?",
    "start": "388920",
    "end": "391290"
  },
  {
    "text": "Good point, Rob.",
    "start": "391290",
    "end": "392440"
  },
  {
    "text": "We do want an\nintercept in the model.",
    "start": "392440",
    "end": "394590"
  },
  {
    "text": "But glmnet, when\nyou give it an x,",
    "start": "394590",
    "end": "396960"
  },
  {
    "text": "it expects just the variables.",
    "start": "396960",
    "end": "399449"
  },
  {
    "text": "And it automatically\nputs in an intercept.",
    "start": "399450",
    "end": "401720"
  },
  {
    "text": "So if we left the\nintercept in, there'd",
    "start": "401720",
    "end": "403620"
  },
  {
    "text": "be two constants in the model.",
    "start": "403620",
    "end": "405376"
  },
  {
    "text": "And I guess you'd also\nshrink the intercept, which",
    "start": "405377",
    "end": "407460"
  },
  {
    "text": "you don't normally want to do.",
    "start": "407460",
    "end": "409000"
  },
  {
    "text": "Exactly.",
    "start": "409000",
    "end": "409500"
  },
  {
    "start": "409500",
    "end": "412260"
  },
  {
    "text": "So I've clicked that chunk and\nthat will have run that code.",
    "start": "412260",
    "end": "418620"
  },
  {
    "text": "OK, so the next thing\nis library glmnet.",
    "start": "418620",
    "end": "423210"
  },
  {
    "text": "We use a cv.glmnet\non the training data.",
    "start": "423210",
    "end": "427560"
  },
  {
    "text": "In other words, x minus\ntest ID, y minus test ID.",
    "start": "427560",
    "end": "433260"
  },
  {
    "text": "And we tell cv.glmnet that we\nwant to use mean absolute error.",
    "start": "433260",
    "end": "439050"
  },
  {
    "text": "Otherwise, it would use, by\ndefault, mean squared error.",
    "start": "439050",
    "end": "442530"
  },
  {
    "text": "And then we make\npredictions from that model.",
    "start": "442530",
    "end": "447270"
  },
  {
    "text": "And we tell it to\nmake the predictions",
    "start": "447270",
    "end": "449580"
  },
  {
    "text": "that lambda.min, which\nis the minimum value",
    "start": "449580",
    "end": "452400"
  },
  {
    "text": "on the cross-validation curve.",
    "start": "452400",
    "end": "454229"
  },
  {
    "text": "Then we compute the\nmean absolute error.",
    "start": "454230",
    "end": "457690"
  },
  {
    "text": "And so we run that\ncode, some message",
    "start": "457690",
    "end": "460840"
  },
  {
    "text": "to say that it's loaded\nthe glmnet package.",
    "start": "460840",
    "end": "463510"
  },
  {
    "text": "And it implements it.",
    "start": "463510",
    "end": "465700"
  },
  {
    "text": "We didn't plot the\ncross-validation curve here,",
    "start": "465700",
    "end": "468310"
  },
  {
    "text": "but we could have.",
    "start": "468310",
    "end": "469860"
  },
  {
    "text": "I can just jump into my code\nhere and just say, plot cvfit.",
    "start": "469860",
    "end": "475860"
  },
  {
    "start": "475860",
    "end": "478759"
  },
  {
    "text": "And just run that single line.",
    "start": "478760",
    "end": "481040"
  },
  {
    "text": "And we get the\nplot of the cvfit.",
    "start": "481040",
    "end": "486200"
  },
  {
    "text": "But we didn't include\nthat in the package.",
    "start": "486200",
    "end": "489560"
  },
  {
    "text": "OK, so now, we're ready\nto fit a neural network.",
    "start": "489560",
    "end": "492270"
  },
  {
    "text": "So we load the Keras library.",
    "start": "492270",
    "end": "497050"
  },
  {
    "text": "And now, we write\nsome code to build up",
    "start": "497050",
    "end": "499990"
  },
  {
    "text": "the structure of the model.",
    "start": "499990",
    "end": "503445"
  },
  {
    "text": "So the model is called modnn.",
    "start": "503446",
    "end": "505900"
  },
  {
    "text": "So it's a structure that stores\nthe details of what the model is",
    "start": "505900",
    "end": "511070"
  },
  {
    "text": "going to look like.",
    "start": "511070",
    "end": "512200"
  },
  {
    "text": "So Keras model sequential\nis just some code that says,",
    "start": "512200",
    "end": "516679"
  },
  {
    "text": "it's going to be a\nfeedforward neural network.",
    "start": "516679",
    "end": "519080"
  },
  {
    "text": "And then we'll tell you more\nabout the pipe in a moment.",
    "start": "519080",
    "end": "523400"
  },
  {
    "text": "We pipe it into a\ncall to layer dense,",
    "start": "523400",
    "end": "526870"
  },
  {
    "text": "which tells you\nthat there's going",
    "start": "526870",
    "end": "528520"
  },
  {
    "text": "to be 50 units at the hidden\nlayer with relu activation.",
    "start": "528520",
    "end": "533290"
  },
  {
    "text": "And the input shape is going to\nbe the number of columns of x.",
    "start": "533290",
    "end": "538089"
  },
  {
    "text": "So in other words, it's\ngoing from the input layer",
    "start": "538090",
    "end": "540640"
  },
  {
    "text": "with the number of columns of\nx to the hidden layer, which",
    "start": "540640",
    "end": "543730"
  },
  {
    "text": "has 50 units.",
    "start": "543730",
    "end": "545060"
  },
  {
    "text": "And then we want to-- we\npipe that into the layer",
    "start": "545060",
    "end": "548350"
  },
  {
    "text": "dropout, where we have\na dropout rate of 0.4",
    "start": "548350",
    "end": "552069"
  },
  {
    "text": "and then into the layer dense,\nwhich is for the output unit,",
    "start": "552070",
    "end": "557050"
  },
  {
    "text": "OK.",
    "start": "557050",
    "end": "558130"
  },
  {
    "text": "So this, well, let's run that.",
    "start": "558130",
    "end": "560980"
  },
  {
    "text": "And you'll see, it waits a\nwhile, while it's running it.",
    "start": "560980",
    "end": "563889"
  },
  {
    "text": "Because what's going on in\nthe background is the Python,",
    "start": "563890",
    "end": "568730"
  },
  {
    "text": "it gets fired up.",
    "start": "568730",
    "end": "570800"
  },
  {
    "text": "And there's a whole\nlot of stuff printed.",
    "start": "570800",
    "end": "573040"
  },
  {
    "text": "It might look scary\nwhen you see it,",
    "start": "573040",
    "end": "574550"
  },
  {
    "text": "but there's nothing\nreally bad in that.",
    "start": "574550",
    "end": "576930"
  },
  {
    "text": "And it's just saying that the\nPython's been implemented.",
    "start": "576930",
    "end": "579839"
  },
  {
    "text": "And this model\nspecification has been",
    "start": "579840",
    "end": "582800"
  },
  {
    "text": "transmitted to the Python\nprogram that's running, OK.",
    "start": "582800",
    "end": "588000"
  },
  {
    "text": "So let's talk about\nthe pipe operator.",
    "start": "588000",
    "end": "591000"
  },
  {
    "text": "This is not something\nwe've encountered before.",
    "start": "591000",
    "end": "593670"
  },
  {
    "text": "And it's really\nuseful, especially",
    "start": "593670",
    "end": "595649"
  },
  {
    "text": "for specifying neural network\nmodels because it makes",
    "start": "595650",
    "end": "598770"
  },
  {
    "text": "the code much more readable.",
    "start": "598770",
    "end": "601140"
  },
  {
    "text": "Because we can basically\nput in separate lines",
    "start": "601140",
    "end": "605160"
  },
  {
    "text": "for each layer in the network,\nincluding things like dropout,",
    "start": "605160",
    "end": "609120"
  },
  {
    "text": "OK.",
    "start": "609120",
    "end": "610476"
  },
  {
    "text": "So how does it work?",
    "start": "610476",
    "end": "611970"
  },
  {
    "text": "Well, we'll illustrate\nit on a simple example.",
    "start": "611970",
    "end": "615379"
  },
  {
    "text": "So earlier, we used\nthe scale command.",
    "start": "615380",
    "end": "619240"
  },
  {
    "text": "We made model matrix\nand then wrapped",
    "start": "619240",
    "end": "621450"
  },
  {
    "text": "around its scale, which would\ntake the output of model matrix",
    "start": "621450",
    "end": "625530"
  },
  {
    "text": "and apply the scale function.",
    "start": "625530",
    "end": "627690"
  },
  {
    "text": "And without argument,\nscale, by default,",
    "start": "627690",
    "end": "630660"
  },
  {
    "text": "standardizes to mean 0\nand constant variance,",
    "start": "630660",
    "end": "633899"
  },
  {
    "text": "each of the columns, OK.",
    "start": "633900",
    "end": "636270"
  },
  {
    "text": "But these compound expressions\ncan be a little bit difficult",
    "start": "636270",
    "end": "639390"
  },
  {
    "text": "to read, especially if they\nget nested a few layers deep.",
    "start": "639390",
    "end": "644610"
  },
  {
    "text": "So here, we do the same thing,\nbut using the pipe operator.",
    "start": "644610",
    "end": "649320"
  },
  {
    "text": "So we call model matrix, and\nwe want to assign it to x.",
    "start": "649320",
    "end": "654480"
  },
  {
    "text": "But what we do is we pipe\nthe output of model matrix",
    "start": "654480",
    "end": "659350"
  },
  {
    "text": "into the scale function\nwith no arguments.",
    "start": "659350",
    "end": "662860"
  },
  {
    "text": "And what that does is the\noutput of model matrix",
    "start": "662860",
    "end": "666790"
  },
  {
    "text": "becomes the first--",
    "start": "666790",
    "end": "668079"
  },
  {
    "text": "the pipe causes that to be\nthe first argument to scale.",
    "start": "668080",
    "end": "671560"
  },
  {
    "text": "And then any other arguments\nthat are listed in scale",
    "start": "671560",
    "end": "675295"
  },
  {
    "text": "here will be the\nsubsequent arguments.",
    "start": "675295",
    "end": "678010"
  },
  {
    "text": "So that has the same\neffect as doing the scale.",
    "start": "678010",
    "end": "682532"
  },
  {
    "text": "There's no need to run\nit because we've already",
    "start": "682532",
    "end": "684490"
  },
  {
    "text": "done the scale.",
    "start": "684490",
    "end": "686399"
  },
  {
    "text": "OK, all good?",
    "start": "686400",
    "end": "688610"
  },
  {
    "text": "Back to the neural network.",
    "start": "688610",
    "end": "690070"
  },
  {
    "text": "So we've set up modnn.",
    "start": "690070",
    "end": "692310"
  },
  {
    "text": "And it's got some\ndetails of the fit.",
    "start": "692310",
    "end": "696060"
  },
  {
    "text": "It's got a dropout\nlayer and so on.",
    "start": "696060",
    "end": "699360"
  },
  {
    "text": "Now, we're going to add further\ndetails to modnn that control",
    "start": "699360",
    "end": "704100"
  },
  {
    "text": "the fitting algorithm, OK.",
    "start": "704100",
    "end": "707819"
  },
  {
    "text": "So we're going to just follow\nthe examples given in the Keras",
    "start": "707820",
    "end": "712260"
  },
  {
    "text": "book.",
    "start": "712260",
    "end": "712790"
  },
  {
    "text": "We're going to use\nsquared error loss.",
    "start": "712790",
    "end": "715350"
  },
  {
    "text": "And so again, we pipe\nmodnn into compile,",
    "start": "715350",
    "end": "720420"
  },
  {
    "text": "loss equals mean squared error.",
    "start": "720420",
    "end": "722290"
  },
  {
    "text": "We tell it the optimizer.",
    "start": "722290",
    "end": "723899"
  },
  {
    "text": "It's the default optimizer.",
    "start": "723900",
    "end": "725790"
  },
  {
    "text": "And we tell it the metrics\nwe're interested in,",
    "start": "725790",
    "end": "728009"
  },
  {
    "text": "mean absolute error.",
    "start": "728010",
    "end": "729480"
  },
  {
    "text": "So in this previous\nline, the pipe operator",
    "start": "729480",
    "end": "732839"
  },
  {
    "text": "passes modnn as the first\nargument to compile.",
    "start": "732840",
    "end": "736930"
  },
  {
    "text": "So the compile function\ndoes not actually",
    "start": "736930",
    "end": "739779"
  },
  {
    "text": "change the R object\nmodnn in this case,",
    "start": "739780",
    "end": "742330"
  },
  {
    "text": "but it does communicate\nthe specifications",
    "start": "742330",
    "end": "744730"
  },
  {
    "text": "to the corresponding Python\ninstance of this model that",
    "start": "744730",
    "end": "748269"
  },
  {
    "text": "has been created along the way.",
    "start": "748270",
    "end": "750370"
  },
  {
    "text": "So this is interesting,\nwhat's going on here.",
    "start": "750370",
    "end": "753020"
  },
  {
    "text": "It looks like we're\ncreating and we're",
    "start": "753020",
    "end": "756310"
  },
  {
    "text": "going to fit this modnn in R.\nBut actually, what we're doing",
    "start": "756310",
    "end": "760000"
  },
  {
    "text": "is transmitting this information\nto the Python instance on how",
    "start": "760000",
    "end": "766590"
  },
  {
    "text": "it's going to fit the model.",
    "start": "766590",
    "end": "768060"
  },
  {
    "text": "So it's a very special kind\nof thing that's going on.",
    "start": "768060",
    "end": "773940"
  },
  {
    "text": "OK, now we're going\nto fit the model.",
    "start": "773940",
    "end": "776610"
  },
  {
    "text": "It's going to use\nstochastic gradient descent.",
    "start": "776610",
    "end": "779640"
  },
  {
    "text": "And we're going to specify the\nnumber of epochs and the batch",
    "start": "779640",
    "end": "782940"
  },
  {
    "text": "size.",
    "start": "782940",
    "end": "784290"
  },
  {
    "text": "So the batch size\nis going to be 32.",
    "start": "784290",
    "end": "788009"
  },
  {
    "text": "Which means that each time\nwe do a gradient update,",
    "start": "788010",
    "end": "791910"
  },
  {
    "text": "we randomly select 32 of\nthe training observations",
    "start": "791910",
    "end": "795029"
  },
  {
    "text": "for computing the gradient,\nthe batch gradient.",
    "start": "795030",
    "end": "798870"
  },
  {
    "text": "And we make a move\ndown the gradient.",
    "start": "798870",
    "end": "801610"
  },
  {
    "text": "And was that specified\nalready, the batch size?",
    "start": "801610",
    "end": "804120"
  },
  {
    "text": "No, Rob, that's coming up.",
    "start": "804120",
    "end": "807940"
  },
  {
    "text": "So this is preamble to that.",
    "start": "807940",
    "end": "809820"
  },
  {
    "text": "So maybe we should\nlook at it, OK.",
    "start": "809820",
    "end": "812820"
  },
  {
    "text": "So this is where\nwe're going to say it.",
    "start": "812820",
    "end": "815880"
  },
  {
    "text": "You can see, we've\nactually commented out.",
    "start": "815880",
    "end": "819060"
  },
  {
    "text": "In the actual lab,\nit says 1,500 epochs.",
    "start": "819060",
    "end": "822710"
  },
  {
    "text": "That would take a\nlittle bit long.",
    "start": "822710",
    "end": "824570"
  },
  {
    "text": "So we're going to--",
    "start": "824570",
    "end": "825580"
  },
  {
    "start": "825580",
    "end": "828130"
  },
  {
    "text": "we commented it out\nand changed it to 600.",
    "start": "828130",
    "end": "831067"
  },
  {
    "text": "In fact, I'm going to\nget this thing running",
    "start": "831067",
    "end": "832900"
  },
  {
    "text": "right now because it\ntakes a little while.",
    "start": "832900",
    "end": "837070"
  },
  {
    "text": "And then I'll tell\nyou about the epochs.",
    "start": "837070",
    "end": "840210"
  },
  {
    "text": "So yeah.",
    "start": "840210",
    "end": "841570"
  },
  {
    "text": "So batch size of 32, there's\n176 training data observations.",
    "start": "841570",
    "end": "848330"
  },
  {
    "text": "So if you divide\nthat by 32, there's",
    "start": "848330",
    "end": "850720"
  },
  {
    "text": "going to be about five\ngradient steps per epoch.",
    "start": "850720",
    "end": "855790"
  },
  {
    "text": "Because remember, an epoch\nis the equivalent number",
    "start": "855790",
    "end": "858970"
  },
  {
    "text": "of gradient steps,\nso that you've",
    "start": "858970",
    "end": "861129"
  },
  {
    "text": "gone through the whole\ntraining data set once.",
    "start": "861130",
    "end": "865620"
  },
  {
    "text": "On the right here,\nwe see, actually,",
    "start": "865620",
    "end": "867150"
  },
  {
    "text": "a progress plot of the\nneural network fitting.",
    "start": "867150",
    "end": "871530"
  },
  {
    "text": "This is particular to\nRStudio, where this happens.",
    "start": "871530",
    "end": "875430"
  },
  {
    "text": "In the top, we've\ngot the default loss,",
    "start": "875430",
    "end": "877410"
  },
  {
    "text": "which is squared error loss.",
    "start": "877410",
    "end": "879120"
  },
  {
    "text": "The green curve\nis the validation.",
    "start": "879120",
    "end": "881850"
  },
  {
    "text": "It's actually the test\ndata in this case.",
    "start": "881850",
    "end": "884019"
  },
  {
    "text": "And the blue is the training.",
    "start": "884020",
    "end": "886440"
  },
  {
    "text": "And down below, we've\ngot mean, absolute error.",
    "start": "886440",
    "end": "890190"
  },
  {
    "text": "Same story, blue is training.",
    "start": "890190",
    "end": "894090"
  },
  {
    "text": "Green is validation.",
    "start": "894090",
    "end": "895900"
  },
  {
    "text": "They're pretty much on top\nof each other, the two.",
    "start": "895900",
    "end": "898140"
  },
  {
    "text": "And notice the training\nloss is a little bit jumpy.",
    "start": "898140",
    "end": "903370"
  },
  {
    "text": "And that's because this\ngradient descent is jumpy",
    "start": "903370",
    "end": "907380"
  },
  {
    "text": "because there's some randomness\nin the observations used",
    "start": "907380",
    "end": "913350"
  },
  {
    "text": "for computing the gradient.",
    "start": "913350",
    "end": "915014"
  },
  {
    "text": "It doesn't really\noverfit at all.",
    "start": "915015",
    "end": "916507"
  },
  {
    "text": "Is that right?",
    "start": "916507",
    "end": "917090"
  },
  {
    "text": "It doesn't look like it's\noverfit at all, yeah.",
    "start": "917090",
    "end": "919170"
  },
  {
    "text": "So we could have actually\ngone on a bit longer.",
    "start": "919170",
    "end": "922290"
  },
  {
    "text": "And that's an\ninteresting point, Rob,",
    "start": "922290",
    "end": "924149"
  },
  {
    "text": "because it seems often that\nthese neural networks are",
    "start": "924150",
    "end": "929130"
  },
  {
    "text": "slow to overfit.",
    "start": "929130",
    "end": "930870"
  },
  {
    "text": "And it's partly, I\nguess, the learning rate.",
    "start": "930870",
    "end": "934950"
  },
  {
    "text": "There's a-- I forget what\nthe learning rate is here.",
    "start": "934950",
    "end": "938152"
  },
  {
    "text": "We didn't actually specify\nit, I don't believe.",
    "start": "938152",
    "end": "940110"
  },
  {
    "text": "It's a default, but it's\na small learning rate.",
    "start": "940110",
    "end": "942910"
  },
  {
    "text": "So that's how far you go\ndown the gradient each time.",
    "start": "942910",
    "end": "946110"
  },
  {
    "text": "And use dropout as\nwell, which regularizes.",
    "start": "946110",
    "end": "948730"
  },
  {
    "text": "And the dropout as well, yeah.",
    "start": "948730",
    "end": "950790"
  },
  {
    "text": "There's also a window\nhere, which shows all the--",
    "start": "950790",
    "end": "955320"
  },
  {
    "text": "more details of each\nof the gradient steps.",
    "start": "955320",
    "end": "958860"
  },
  {
    "text": "And you can wade through\nthat if you wish.",
    "start": "958860",
    "end": "960970"
  },
  {
    "text": "But with the plot,\nit's good enough.",
    "start": "960970",
    "end": "963189"
  },
  {
    "text": "So we'll just move that away.",
    "start": "963190",
    "end": "967340"
  },
  {
    "text": "There's a little\nitem here that you",
    "start": "967340",
    "end": "971660"
  },
  {
    "text": "can use to open up those guys.",
    "start": "971660",
    "end": "974629"
  },
  {
    "text": "You can also directly\nplot the history.",
    "start": "974630",
    "end": "977760"
  },
  {
    "text": "If you're not in\nRStudio and you're",
    "start": "977760",
    "end": "979430"
  },
  {
    "text": "running R in a different system,\nyou can directly produce a plot,",
    "start": "979430",
    "end": "983570"
  },
  {
    "text": "and you get something\nlike that, which",
    "start": "983570",
    "end": "985400"
  },
  {
    "text": "is very similar to the\nplot we've just seen, OK.",
    "start": "985400",
    "end": "990510"
  },
  {
    "text": "All right, so just a point.",
    "start": "990510",
    "end": "995920"
  },
  {
    "text": "So we ran the fit.",
    "start": "995920",
    "end": "996760"
  },
  {
    "text": "Yeah, we did it\nwith 600 iterations.",
    "start": "996760",
    "end": "999670"
  },
  {
    "text": "If we ran the fit\na second time, it",
    "start": "999670",
    "end": "1002700"
  },
  {
    "text": "would start from where we left\noff because the Python code has",
    "start": "1002700",
    "end": "1007920"
  },
  {
    "text": "just stopped where it is.",
    "start": "1007920",
    "end": "1009940"
  },
  {
    "text": "And if you run fit again,\nit'll just continue.",
    "start": "1009940",
    "end": "1012370"
  },
  {
    "text": "The plot would\ncontinue, but it would",
    "start": "1012370",
    "end": "1014580"
  },
  {
    "text": "continue starting from the\npoint where it had ended before.",
    "start": "1014580",
    "end": "1019450"
  },
  {
    "text": "We won't do that now.",
    "start": "1019450",
    "end": "1021870"
  },
  {
    "text": "So at the end of the day, we can\nuse the predict method for Keras",
    "start": "1021870",
    "end": "1029369"
  },
  {
    "text": "and for neural networks.",
    "start": "1029369",
    "end": "1031720"
  },
  {
    "text": "And we give it the test data,\nand we evaluate the performance",
    "start": "1031720",
    "end": "1035669"
  },
  {
    "text": "on the test data.",
    "start": "1035670",
    "end": "1037349"
  },
  {
    "text": "And this is slightly different\nto what we reported in the book",
    "start": "1037349",
    "end": "1041189"
  },
  {
    "text": "because we only used a\ntraining sample of size 600.",
    "start": "1041190",
    "end": "1043799"
  },
  {
    "text": "And it's about the same as\nthe least squares, I think,",
    "start": "1043800",
    "end": "1046050"
  },
  {
    "text": "are a little worse.",
    "start": "1046050",
    "end": "1047550"
  },
  {
    "text": "Yeah, exactly.",
    "start": "1047550",
    "end": "1049890"
  },
  {
    "text": "And the other thing to\nnote, and we point this out",
    "start": "1049890",
    "end": "1052840"
  },
  {
    "text": "in the chapter, is that even if\nyou had to run the model right",
    "start": "1052840",
    "end": "1056760"
  },
  {
    "text": "from the beginning, 1,500\nsteps, the second time,",
    "start": "1056760",
    "end": "1061360"
  },
  {
    "text": "it wouldn't give\nexactly the same answer",
    "start": "1061360",
    "end": "1063280"
  },
  {
    "text": "because of the slight randomness\nin the stochastic gradient",
    "start": "1063280",
    "end": "1067330"
  },
  {
    "text": "descent.",
    "start": "1067330",
    "end": "1067880"
  },
  {
    "text": "Even with the same seed?",
    "start": "1067880",
    "end": "1069550"
  },
  {
    "text": "Well, the seed is a sticky\nissue with Keras, Rob,",
    "start": "1069550",
    "end": "1074200"
  },
  {
    "text": "because it turns\nout it's difficult",
    "start": "1074200",
    "end": "1077289"
  },
  {
    "text": "or we haven't figured\nout how to set the Python",
    "start": "1077290",
    "end": "1080260"
  },
  {
    "text": "seed from inside Keras.",
    "start": "1080260",
    "end": "1082510"
  },
  {
    "text": "Yeah, so that's a slight.",
    "start": "1082510",
    "end": "1086770"
  },
  {
    "text": "It's a slight issue.",
    "start": "1086770",
    "end": "1089550"
  },
  {
    "text": "OK, so that's the end\nof the simple example.",
    "start": "1089550",
    "end": "1094050"
  },
  {
    "text": "We now move to a multi-layer\nnetwork on the MNIST digit data.",
    "start": "1094050",
    "end": "1098770"
  },
  {
    "text": "This is a bigger,\nmore serious data set.",
    "start": "1098770",
    "end": "1101460"
  },
  {
    "text": "And these data are available\nfrom the Keras package,",
    "start": "1101460",
    "end": "1105360"
  },
  {
    "text": "as are other important\ndata sets for our lab.",
    "start": "1105360",
    "end": "1109440"
  },
  {
    "text": "There's actually a\ndedicated command",
    "start": "1109440",
    "end": "1111600"
  },
  {
    "text": "in Keras called dataset_mnist\nto get the data.",
    "start": "1111600",
    "end": "1117010"
  },
  {
    "text": "And then we have a few\ncommands to pull off.",
    "start": "1117010",
    "end": "1120600"
  },
  {
    "text": "This is an object\nwith a lot of--",
    "start": "1120600",
    "end": "1122520"
  },
  {
    "text": "a list with a lot of components.",
    "start": "1122520",
    "end": "1124230"
  },
  {
    "text": "And we pull off the\nx, the y, x test,",
    "start": "1124230",
    "end": "1126900"
  },
  {
    "text": "y test, these are all designated\ntraining and test sets",
    "start": "1126900",
    "end": "1131130"
  },
  {
    "text": "and make them available.",
    "start": "1131130",
    "end": "1134190"
  },
  {
    "text": "And you'll see that there's\n60,000 training images,",
    "start": "1134190",
    "end": "1138360"
  },
  {
    "text": "each 28 by 28 grayscale\nimages and 1,000 test images.",
    "start": "1138360",
    "end": "1145299"
  },
  {
    "text": "And of course, the class\nlabels are between 0 and 9.",
    "start": "1145300",
    "end": "1150230"
  },
  {
    "text": "These are the digits.",
    "start": "1150230",
    "end": "1152860"
  },
  {
    "text": "So the images, the\ndata, the x matrix",
    "start": "1152860",
    "end": "1159320"
  },
  {
    "text": "is stored as a\nthree-dimensional array.",
    "start": "1159320",
    "end": "1163009"
  },
  {
    "text": "It's got 60,000 by 28 by 28.",
    "start": "1163010",
    "end": "1167000"
  },
  {
    "text": "So we actually want to\nreshape that into a matrix.",
    "start": "1167000",
    "end": "1169920"
  },
  {
    "text": "So we're going to\nflatten out the 28 by 28.",
    "start": "1169920",
    "end": "1173120"
  },
  {
    "text": "And there's commands in the\nKeras package for doing that.",
    "start": "1173120",
    "end": "1177710"
  },
  {
    "text": "And we're also going\nto turn the response",
    "start": "1177710",
    "end": "1181159"
  },
  {
    "text": "into a categorical\nvariable, using",
    "start": "1181160",
    "end": "1184520"
  },
  {
    "text": "Keras command to categorical.",
    "start": "1184520",
    "end": "1187160"
  },
  {
    "text": "So this is just to turn\nthe input into a format",
    "start": "1187160",
    "end": "1190160"
  },
  {
    "text": "that the neural\nnetwork understands.",
    "start": "1190160",
    "end": "1194070"
  },
  {
    "text": "One other thing, when\nyou fit neural networks,",
    "start": "1194070",
    "end": "1197519"
  },
  {
    "text": "it's pretty sensitive to\nthe scale of the variables.",
    "start": "1197520",
    "end": "1201930"
  },
  {
    "text": "So if you have one\nvariable that ranges",
    "start": "1201930",
    "end": "1204930"
  },
  {
    "text": "from 0 to 1 and another variable\nthat ranges from minus 500",
    "start": "1204930",
    "end": "1210030"
  },
  {
    "text": "to plus 500, it's going\nto cause some problems",
    "start": "1210030",
    "end": "1213600"
  },
  {
    "text": "with the neural network.",
    "start": "1213600",
    "end": "1215140"
  },
  {
    "text": "And so it's generally better\nto scale the variables maybe",
    "start": "1215140",
    "end": "1220080"
  },
  {
    "text": "to an interval, say, 0, 1, or\nto standardize them to have,",
    "start": "1220080",
    "end": "1223980"
  },
  {
    "text": "say, unit variance to\navoid that sensitivity.",
    "start": "1223980",
    "end": "1228360"
  },
  {
    "text": "So in the case of these images,\neach bit is an 8-bit grayscale",
    "start": "1228360",
    "end": "1234179"
  },
  {
    "text": "value.",
    "start": "1234180",
    "end": "1234777"
  },
  {
    "text": "And the actual numbers,\nif you look at them,",
    "start": "1234777",
    "end": "1236610"
  },
  {
    "text": "they lie between 0 and 255.",
    "start": "1236610",
    "end": "1239799"
  },
  {
    "text": "That's 2 to the 8,\ndifferent numbers.",
    "start": "1239800",
    "end": "1243450"
  },
  {
    "text": "So we'll rescale them\nto lie between 0 and 1.",
    "start": "1243450",
    "end": "1247320"
  },
  {
    "text": "And that's a simple command.",
    "start": "1247320",
    "end": "1249659"
  },
  {
    "text": "It just does element-wise\non x train and x test, OK.",
    "start": "1249660",
    "end": "1255060"
  },
  {
    "text": "So now, the data are ready\nfor the neural network.",
    "start": "1255060",
    "end": "1259650"
  },
  {
    "text": "So again, a call to model\nthe Keras model sequential.",
    "start": "1259650",
    "end": "1264210"
  },
  {
    "text": "And now, we're going\nto have more layers.",
    "start": "1264210",
    "end": "1266120"
  },
  {
    "text": "So we've got the--",
    "start": "1266120",
    "end": "1267250"
  },
  {
    "text": "first is the input layer.",
    "start": "1267250",
    "end": "1269210"
  },
  {
    "text": "The input layer\nhas got 784 units.",
    "start": "1269210",
    "end": "1271730"
  },
  {
    "text": "It was 28 by 28 images.",
    "start": "1271730",
    "end": "1274010"
  },
  {
    "text": "And the first hidden\nlayer is going",
    "start": "1274010",
    "end": "1275560"
  },
  {
    "text": "to have 256 units\nwith relu activation.",
    "start": "1275560",
    "end": "1280100"
  },
  {
    "text": "Pipe that through a\ndropout layer with 0.4.",
    "start": "1280100",
    "end": "1284809"
  },
  {
    "text": "Then the second layer is going\nto have 128 units, also relu.",
    "start": "1284810",
    "end": "1291200"
  },
  {
    "text": "We'll do a dropout of 0.3.",
    "start": "1291200",
    "end": "1294779"
  },
  {
    "text": "So that's slightly less dropout.",
    "start": "1294780",
    "end": "1298180"
  },
  {
    "text": "And then the final output\nlayer has 10 units.",
    "start": "1298180",
    "end": "1300820"
  },
  {
    "text": "And the activation\nis softmax, which",
    "start": "1300820",
    "end": "1305460"
  },
  {
    "text": "turns the output\ninto probabilities",
    "start": "1305460",
    "end": "1308159"
  },
  {
    "text": "for the 10 classes.",
    "start": "1308160",
    "end": "1309380"
  },
  {
    "text": "Now, how do we decide on this\narchitecture, like the 256,",
    "start": "1309380",
    "end": "1313220"
  },
  {
    "text": "the dropout layer, the\nthree, the number of layers,",
    "start": "1313220",
    "end": "1315880"
  },
  {
    "text": "the dropout number of units?",
    "start": "1315880",
    "end": "1317450"
  },
  {
    "text": "That's a good question, Rob.",
    "start": "1317450",
    "end": "1319149"
  },
  {
    "text": "It's actually quite tricky.",
    "start": "1319150",
    "end": "1320980"
  },
  {
    "text": "You'll see this, as we\nbuild more and more complex",
    "start": "1320980",
    "end": "1323910"
  },
  {
    "text": "networks, these\nparameters, they multiply.",
    "start": "1323910",
    "end": "1326710"
  },
  {
    "text": "There's many of them.",
    "start": "1326710",
    "end": "1327850"
  },
  {
    "text": "And why do we use 0.4\nhere and 0.3 here?",
    "start": "1327850",
    "end": "1330780"
  },
  {
    "text": "I think I copied it\nfrom the Keras book,",
    "start": "1330780",
    "end": "1332880"
  },
  {
    "text": "where they used this example.",
    "start": "1332880",
    "end": "1334650"
  },
  {
    "text": "But yeah, those are\nthings that can sometimes",
    "start": "1334650",
    "end": "1337470"
  },
  {
    "text": "take a lot of time,\ntrial and error",
    "start": "1337470",
    "end": "1339419"
  },
  {
    "text": "to get those right, including--\nand also the number of units.",
    "start": "1339420",
    "end": "1342560"
  },
  {
    "text": "Although the general\nidea is that you",
    "start": "1342560",
    "end": "1345240"
  },
  {
    "text": "make a large number of\nunits, hidden units and you",
    "start": "1345240",
    "end": "1349380"
  },
  {
    "text": "use some form of regularization.",
    "start": "1349380",
    "end": "1351325"
  },
  {
    "text": "So it's better to have\ntoo many than too few?",
    "start": "1351325",
    "end": "1353200"
  },
  {
    "text": "Yes, I think that's\nthe current thinking.",
    "start": "1353200",
    "end": "1356429"
  },
  {
    "text": "So let's make sure\nwe run that code.",
    "start": "1356430",
    "end": "1359000"
  },
  {
    "text": "So again, this is\nnot doing much work",
    "start": "1359000",
    "end": "1361470"
  },
  {
    "text": "except just specifying the\nmodel through these layers",
    "start": "1361470",
    "end": "1365890"
  },
  {
    "text": "and making extensive use\nof the pipe operator, OK.",
    "start": "1365890",
    "end": "1370660"
  },
  {
    "text": "So we can do a\nsummary of the model.",
    "start": "1370660",
    "end": "1373490"
  },
  {
    "text": "And that's nice because\nyou can actually",
    "start": "1373490",
    "end": "1375520"
  },
  {
    "text": "check that you did it right.",
    "start": "1375520",
    "end": "1377050"
  },
  {
    "text": "And it gives you a description\nof each of the layers",
    "start": "1377050",
    "end": "1379900"
  },
  {
    "text": "and what's in.",
    "start": "1379900",
    "end": "1381880"
  },
  {
    "text": "And it looks shocking,\nbut we've got.",
    "start": "1381880",
    "end": "1386470"
  },
  {
    "text": "235,000 parameters, OK.",
    "start": "1386470",
    "end": "1390039"
  },
  {
    "text": "We've only got 60,000\ntraining observations.",
    "start": "1390040",
    "end": "1393460"
  },
  {
    "text": "So this is a case where\nthe neural network is way",
    "start": "1393460",
    "end": "1396549"
  },
  {
    "text": "over-parameterized, but we're\ngoing to use regularization.",
    "start": "1396550",
    "end": "1401980"
  },
  {
    "text": "So who knows what the\neffect of dimension is?",
    "start": "1401980",
    "end": "1405320"
  },
  {
    "text": "But nominally, that's how\nmany parameters there are.",
    "start": "1405320",
    "end": "1408862"
  },
  {
    "text": "Oh, we didn't have\nto blank that out.",
    "start": "1408862",
    "end": "1412180"
  },
  {
    "text": "If you do the parameter-- if\nyou look at the parameters,",
    "start": "1412180",
    "end": "1415450"
  },
  {
    "text": "if you wanted to\nactually reconcile",
    "start": "1415450",
    "end": "1417669"
  },
  {
    "text": "these numbers with the\nnumbers that we see here,",
    "start": "1417670",
    "end": "1420070"
  },
  {
    "text": "you have to take into\naccount that there's",
    "start": "1420070",
    "end": "1422019"
  },
  {
    "text": "a bias term, which is an\nintercept in each of the layers,",
    "start": "1422020",
    "end": "1425560"
  },
  {
    "text": "in the input layer and\neach of the hidden layers.",
    "start": "1425560",
    "end": "1427990"
  },
  {
    "text": "And when you add those in, you\ncan get to this number, OK.",
    "start": "1427990",
    "end": "1433590"
  },
  {
    "text": "We're telling that the loss\nis categorical cross entropy.",
    "start": "1433590",
    "end": "1437520"
  },
  {
    "text": "That's essentially the\nmulti-class logistic regression",
    "start": "1437520",
    "end": "1440970"
  },
  {
    "text": "loss function, in fact,\nthe log likelihood.",
    "start": "1440970",
    "end": "1445679"
  },
  {
    "text": "And we give it details\nfor the optimization.",
    "start": "1445680",
    "end": "1448600"
  },
  {
    "text": "And again, these were\nprescribed in the Keras book.",
    "start": "1448600",
    "end": "1453390"
  },
  {
    "text": "And one can look\nup help on these",
    "start": "1453390",
    "end": "1455705"
  },
  {
    "text": "and see what the\ndifferent options are.",
    "start": "1455705",
    "end": "1457330"
  },
  {
    "text": "But we use, basically,\nthe default.",
    "start": "1457330",
    "end": "1459539"
  },
  {
    "text": "So I'll get that running.",
    "start": "1459540",
    "end": "1462060"
  },
  {
    "text": "And now, we fit the model.",
    "start": "1462060",
    "end": "1464010"
  },
  {
    "text": "Again, I've reduced\ndown to 15 epochs.",
    "start": "1464010",
    "end": "1468960"
  },
  {
    "text": "I'm using a batch size.",
    "start": "1468960",
    "end": "1470649"
  },
  {
    "text": "We're using a batch size of 128,\nwhich may seem really modest,",
    "start": "1470650",
    "end": "1475350"
  },
  {
    "text": "given that we've got 60,000\ntraining observations.",
    "start": "1475350",
    "end": "1478740"
  },
  {
    "text": "But the idea is to use many\nrelatively small batches,",
    "start": "1478740",
    "end": "1484020"
  },
  {
    "text": "and you may tend to\nmake better progress.",
    "start": "1484020",
    "end": "1487020"
  },
  {
    "text": "And now, we tell it to use\na validation split of 0.2.",
    "start": "1487020",
    "end": "1491460"
  },
  {
    "text": "So in fact, we're using 20% of\nthe 60,000 training observations",
    "start": "1491460",
    "end": "1497320"
  },
  {
    "text": "as a validation set, so that\nwe can track the history",
    "start": "1497320",
    "end": "1501130"
  },
  {
    "text": "of the model as it's going.",
    "start": "1501130",
    "end": "1502500"
  },
  {
    "start": "1502500",
    "end": "1506133"
  },
  {
    "text": "I think how amazing this is.",
    "start": "1506133",
    "end": "1507300"
  },
  {
    "text": "We're sitting here, this is\nrunning on a MacBook Pro, just",
    "start": "1507300",
    "end": "1510800"
  },
  {
    "text": "a laptop.",
    "start": "1510800",
    "end": "1511790"
  },
  {
    "text": "And we're fitting, how was it,\n250,000 parameters in a model?",
    "start": "1511790",
    "end": "1514850"
  },
  {
    "text": "250,000 parameters.",
    "start": "1514850",
    "end": "1516890"
  },
  {
    "text": "And each movement here\nmeans it's processed 60,000",
    "start": "1516890",
    "end": "1521960"
  },
  {
    "text": "observations or a bit less\nbecause the validation split.",
    "start": "1521960",
    "end": "1525470"
  },
  {
    "text": "Totally amazing.",
    "start": "1525470",
    "end": "1526220"
  },
  {
    "text": "I guess, they got all\nthe credit for that",
    "start": "1526220",
    "end": "1527928"
  },
  {
    "text": "goes to Google and TensorFlow\nand all the smarts they use,",
    "start": "1527928",
    "end": "1531049"
  },
  {
    "text": "both software and hardware.",
    "start": "1531050",
    "end": "1532740"
  },
  {
    "text": "Yes.",
    "start": "1532740",
    "end": "1533240"
  },
  {
    "text": "Yeah, it's amazing.",
    "start": "1533240",
    "end": "1534300"
  },
  {
    "text": "It is amazing.",
    "start": "1534300",
    "end": "1535620"
  },
  {
    "text": "We're really blessed to have\npackages like TensorFlow",
    "start": "1535620",
    "end": "1539210"
  },
  {
    "text": "available.",
    "start": "1539210",
    "end": "1540559"
  },
  {
    "text": "And it's used in\nall over the place.",
    "start": "1540560",
    "end": "1545180"
  },
  {
    "text": "OK, so here's some\ndetails of the machine.",
    "start": "1545180",
    "end": "1548270"
  },
  {
    "text": "And along the lines\nthat Rob brought up,",
    "start": "1548270",
    "end": "1553080"
  },
  {
    "text": "that fitting the model, it\nsays here to two point--",
    "start": "1553080",
    "end": "1559340"
  },
  {
    "text": "it took 144 seconds\nfor the full model,",
    "start": "1559340",
    "end": "1562289"
  },
  {
    "text": "if we used all the epochs\non this particular MacBook",
    "start": "1562290",
    "end": "1565430"
  },
  {
    "text": "Pro, which is a 2.9 gigahertz\nwith 32 gigabytes of RAM.",
    "start": "1565430",
    "end": "1570200"
  },
  {
    "text": "OK, we can score the\nmodel for accuracy.",
    "start": "1570200",
    "end": "1574720"
  },
  {
    "text": "And it does an\namazing 98% accuracy",
    "start": "1574720",
    "end": "1579400"
  },
  {
    "text": "on the test data,\nwhich is really good.",
    "start": "1579400",
    "end": "1583560"
  },
  {
    "text": "Again, we use the\npipe command here.",
    "start": "1583560",
    "end": "1586140"
  },
  {
    "text": "So here, we actually\nwrote a little function",
    "start": "1586140",
    "end": "1588370"
  },
  {
    "text": "called accuracy, which takes,\nas an argument, the predictions",
    "start": "1588370",
    "end": "1593350"
  },
  {
    "text": "and a second argument, the\ntruth and just computes",
    "start": "1593350",
    "end": "1598120"
  },
  {
    "text": "the mean classification error.",
    "start": "1598120",
    "end": "1600830"
  },
  {
    "text": "So it looks to see how\noften the predictions are",
    "start": "1600830",
    "end": "1604510"
  },
  {
    "text": "equal to the truth.",
    "start": "1604510",
    "end": "1606400"
  },
  {
    "text": "We use the word drop\nbecause the predictions",
    "start": "1606400",
    "end": "1610300"
  },
  {
    "text": "come in the form of arrays.",
    "start": "1610300",
    "end": "1613150"
  },
  {
    "text": "And we don't want them\nto get in the way.",
    "start": "1613150",
    "end": "1615790"
  },
  {
    "text": "And so we run predict.classes.",
    "start": "1615790",
    "end": "1618910"
  },
  {
    "text": "We give it x.test.",
    "start": "1618910",
    "end": "1619885"
  },
  {
    "text": "That will give predictions\nfor the digit class.",
    "start": "1619885",
    "end": "1623650"
  },
  {
    "text": "And we just pipe that\nstraight into accuracy.",
    "start": "1623650",
    "end": "1626200"
  },
  {
    "text": "And when you use\nthe pipe command,",
    "start": "1626200",
    "end": "1629279"
  },
  {
    "text": "we only have to name\nthe test set, which",
    "start": "1629280",
    "end": "1632370"
  },
  {
    "text": "is the second argument.",
    "start": "1632370",
    "end": "1633660"
  },
  {
    "text": "Because the first argument is\nthe output of predict.classes.",
    "start": "1633660",
    "end": "1639000"
  },
  {
    "text": "And that's how it's used.",
    "start": "1639000",
    "end": "1642900"
  },
  {
    "text": "So in the chapter,\nwe also report",
    "start": "1642900",
    "end": "1645540"
  },
  {
    "text": "the results of LDA,\nwhich is described",
    "start": "1645540",
    "end": "1650250"
  },
  {
    "text": "in chapter four of the book and\nmulticlass logistic regression.",
    "start": "1650250",
    "end": "1655170"
  },
  {
    "text": "So packages like\nglmnet can handle",
    "start": "1655170",
    "end": "1658810"
  },
  {
    "text": "multiclass logistic\nregression just fine.",
    "start": "1658810",
    "end": "1660910"
  },
  {
    "text": "But it turns out they're quite\nslow on such a large data set.",
    "start": "1660910",
    "end": "1665110"
  },
  {
    "text": "And we tried other\npackages in R to fit",
    "start": "1665110",
    "end": "1669040"
  },
  {
    "text": "the multiclass logistic\nregression on these data.",
    "start": "1669040",
    "end": "1672880"
  },
  {
    "text": "And we ran into problems, speed\nand/or other problems with R.",
    "start": "1672880",
    "end": "1677650"
  },
  {
    "text": "And then it occurred to\nus that we could actually",
    "start": "1677650",
    "end": "1679720"
  },
  {
    "text": "fit this model using a deep\nnetwork with no hidden layers,",
    "start": "1679720",
    "end": "1683679"
  },
  {
    "text": "which is nice.",
    "start": "1683680",
    "end": "1685990"
  },
  {
    "text": "So here we go.",
    "start": "1685990",
    "end": "1687059"
  },
  {
    "start": "1687060",
    "end": "1689880"
  },
  {
    "text": "So we just go from input\nstraight to output using,",
    "start": "1689880",
    "end": "1694180"
  },
  {
    "text": "again, the softmax activation.",
    "start": "1694180",
    "end": "1698410"
  },
  {
    "text": "And if you do the\nparameter count here,",
    "start": "1698410",
    "end": "1700780"
  },
  {
    "text": "you'll find out that's exactly\nright for multiclass logistic",
    "start": "1700780",
    "end": "1703840"
  },
  {
    "text": "regression.",
    "start": "1703840",
    "end": "1705730"
  },
  {
    "text": "And now, we fit the\nmodel just as before.",
    "start": "1705730",
    "end": "1707790"
  },
  {
    "start": "1707790",
    "end": "1713150"
  },
  {
    "text": "And this one looks like\nI'm doing all 30 epochs.",
    "start": "1713150",
    "end": "1717290"
  },
  {
    "text": "And it's fitting that\nlogistic regression model.",
    "start": "1717290",
    "end": "1719925"
  },
  {
    "text": "It's doing a little\nbit worse, I think.",
    "start": "1719925",
    "end": "1721550"
  },
  {
    "text": "Weren't we up at 95 before?",
    "start": "1721550",
    "end": "1724670"
  },
  {
    "text": "Yes, so we were up at 98 before.",
    "start": "1724670",
    "end": "1727520"
  },
  {
    "text": "And so you can see\nthe advantage, Rob,",
    "start": "1727520",
    "end": "1730580"
  },
  {
    "text": "of the neural network.",
    "start": "1730580",
    "end": "1734029"
  },
  {
    "text": "Because logistic regression\nlooks like it gets to about 93%",
    "start": "1734030",
    "end": "1738560"
  },
  {
    "text": "on the test data.",
    "start": "1738560",
    "end": "1740150"
  },
  {
    "text": "And the neural\nnetwork got to 98%.",
    "start": "1740150",
    "end": "1743130"
  },
  {
    "text": "So this gave exactly the\nsame answer as glmnet,",
    "start": "1743130",
    "end": "1745470"
  },
  {
    "text": "if we could run glmnet.",
    "start": "1745470",
    "end": "1746480"
  },
  {
    "text": "It would, yes.",
    "start": "1746480",
    "end": "1747559"
  },
  {
    "text": "Well, exactly--",
    "start": "1747560",
    "end": "1749270"
  },
  {
    "text": "It wouldn't.",
    "start": "1749270",
    "end": "1749960"
  },
  {
    "text": "Well, why not, Rob.",
    "start": "1749960",
    "end": "1750980"
  },
  {
    "text": "Well, it's an approximation.",
    "start": "1750980",
    "end": "1752294"
  },
  {
    "text": "It's doing stochastic\ngradient descent,",
    "start": "1752295",
    "end": "1753920"
  },
  {
    "text": "so it's not actually getting\nto the global minimum.",
    "start": "1753920",
    "end": "1756930"
  },
  {
    "text": "Ah, that's a good point.",
    "start": "1756930",
    "end": "1758050"
  },
  {
    "text": "But maybe who cares,\nif it performs better.",
    "start": "1758050",
    "end": "1762070"
  },
  {
    "text": "It performs-- yeah, it will\nperform as well as glmnet.",
    "start": "1762070",
    "end": "1766330"
  },
  {
    "text": "Well, approximately as well.",
    "start": "1766330",
    "end": "1768200"
  },
  {
    "text": "And it probably very similar.",
    "start": "1768200",
    "end": "1770672"
  },
  {
    "text": "It seems like it's\nleveled off here.",
    "start": "1770672",
    "end": "1774510"
  }
]
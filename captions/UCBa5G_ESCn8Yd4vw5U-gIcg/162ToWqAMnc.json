[
  {
    "start": "0",
    "end": "5360"
  },
  {
    "text": "So we're going to pick back up\nwhere we left off on Tuesday. So we were talking about finding\nfailures using optimization.",
    "start": "5360",
    "end": "14390"
  },
  {
    "text": "And we had set up this\noptimization problem where we said that we\nhad these variables.",
    "start": "14390",
    "end": "19980"
  },
  {
    "text": "We need to decide which was the\ninitial state and some sequence of disturbances. We were going to minimize\nsome objective function that",
    "start": "19980",
    "end": "26330"
  },
  {
    "text": "represents closeness to\nfailure, subject to the fact that tau or our trajectory is a\nrollout given that initial state",
    "start": "26330",
    "end": "35030"
  },
  {
    "text": "and sequence of disturbances. So we said we needed\nsome objective",
    "start": "35030",
    "end": "40503"
  },
  {
    "text": "that kind of represented\ncloseness to failure. And we remembered from\nchapter 3 that robustness",
    "start": "40503",
    "end": "46160"
  },
  {
    "text": "does exactly this,\nexactly what we want here, or smooth robustness, if we're\ngoing to use an optimization",
    "start": "46160",
    "end": "51560"
  },
  {
    "text": "algorithm that needs gradients. And so we said we'll just use\nthis as our objective function. But then we were just\ntalking at the end of lecture",
    "start": "51560",
    "end": "57830"
  },
  {
    "text": "about how this might be a\nproblem because it might result in very unlikely trajectories.",
    "start": "57830",
    "end": "63460"
  },
  {
    "text": "So if we just tell it\nto minimize robustness, it can do whatever\nthe heck it wants to try to make the robustness\nas small as possible.",
    "start": "63460",
    "end": "70770"
  },
  {
    "text": "But in doing that,\nit could potentially do very unlikely things. So for example, we saw\nthis trajectory here",
    "start": "70770",
    "end": "76350"
  },
  {
    "text": "where we're sampling\ndisturbances from our disturbance\ndistribution. But this disturbance here,\naccording to this distribution,",
    "start": "76350",
    "end": "82500"
  },
  {
    "text": "is very low probability. It's very unlikely. And if we just do that\na whole bunch of times, we are able to make\nthe pendulum fall over.",
    "start": "82500",
    "end": "90159"
  },
  {
    "text": "We're able to make\nthe trajectory fail. But this is very unlikely and\nmaybe not the type of failure that we're necessarily\ninterested in.",
    "start": "90160",
    "end": "97477"
  },
  {
    "text": "So we said our\nsolution here was going to be to incorporate\nlikelihood into the objective.",
    "start": "97477",
    "end": "103030"
  },
  {
    "text": "So that's what we're\ngoing to do now. We left off here where\nwe said, OK, well, if we're going to\ndo that, we now",
    "start": "103030",
    "end": "108180"
  },
  {
    "text": "need to know how we\ncould actually evaluate the likelihood of a trajectory.",
    "start": "108180",
    "end": "113400"
  },
  {
    "text": "So the likelihood\nof a trajectory is just going to be the\nlikelihood of the initial state that we got, and then\nthe likelihood of all",
    "start": "113400",
    "end": "120500"
  },
  {
    "text": "of the disturbances that we\nsampled after that occurring. So what we're\ngoing to do here is we'll show the same\ntrajectory we've",
    "start": "120500",
    "end": "127070"
  },
  {
    "text": "been looking at over\nand over, and now we're just going to keep track of\neverything that we've sampled and the likelihood\nof that occurring.",
    "start": "127070",
    "end": "133440"
  },
  {
    "text": "So we'll say p tau, so\nwe'll say p tau represents the probability\nof trajectory tau,",
    "start": "133440",
    "end": "140060"
  },
  {
    "text": "is going to be equal\nto the probability of this kind of initial\nstate that we sample.",
    "start": "140060",
    "end": "145523"
  },
  {
    "text": "So we look at whatever\nthe probability density was for that initial state. We're going to include\nthat in our probability",
    "start": "145523",
    "end": "152300"
  },
  {
    "text": "of the trajectory. And then we need to keep kind\nof accumulating probability every time we sample something.",
    "start": "152300",
    "end": "158340"
  },
  {
    "text": "So next, we sample a disturbance\nfor the first time step. So we want to look\nat the probability density for that disturbance.",
    "start": "158340",
    "end": "164243"
  },
  {
    "text": "And now we're saying,\nOK, it's the probability that this initial state occurred\nand that this disturbance occurred.",
    "start": "164243",
    "end": "169920"
  },
  {
    "text": "And so we're just going\nto multiply it over here. And then we go to\nour next state.",
    "start": "169920",
    "end": "175200"
  },
  {
    "text": "We now sample\nanother disturbance from this distribution. So we look at the likelihood\nof that disturbance",
    "start": "175200",
    "end": "180210"
  },
  {
    "text": "that we sampled. Add that to our product. And then we just\ncontinue doing this",
    "start": "180210",
    "end": "185610"
  },
  {
    "text": "for the rest of the\ntrajectory, all the way out to our final depth where\nwe have the final disturbance",
    "start": "185610",
    "end": "194549"
  },
  {
    "text": "that we sample. So the likelihood\nof a trajectory is just going to be the\nproduct of all of these things.",
    "start": "194550",
    "end": "202860"
  },
  {
    "text": "So here it is in code. Specifically we have the\nproduct of each disturbance",
    "start": "202860",
    "end": "208920"
  },
  {
    "text": "at each time step given the\nstate, action, and observation. We could break that up\ninto each kind of component",
    "start": "208920",
    "end": "215820"
  },
  {
    "text": "of the disturbance. So we said we had a\ndisturbance for the agent, a disturbance for\nthe environment, and a disturbance\nfor the sensor.",
    "start": "215820",
    "end": "220900"
  },
  {
    "text": "So we just multiply\nthose three together. So that's how each\nof these breaks down.",
    "start": "220900",
    "end": "225960"
  },
  {
    "text": "And so here's what it looks\nlike in code in the book. Here we're implementing\nthe log PDF.",
    "start": "225960",
    "end": "231460"
  },
  {
    "text": "We're just taking\nthe log of this. And the reason for\nthat is because as we begin to multiply things,\nwhen we multiply small numbers",
    "start": "231460",
    "end": "239547"
  },
  {
    "text": "and we multiply many\nof them together, we get very, very small numbers. And that can be kind\nof difficult to work with and result in some\npoor numerical stability.",
    "start": "239547",
    "end": "247150"
  },
  {
    "text": "So if we take the\nlog of this, we're able to just do addition\ninstead of multiplication. And so that's why we\ncompute the log PDF here.",
    "start": "247150",
    "end": "255640"
  },
  {
    "text": "Here we're also\nworking with log. So it actually does-- this is only somewhat right. It actually does return\nthe PDF because we take",
    "start": "255640",
    "end": "262449"
  },
  {
    "text": "the exponent of it at the end. But in general, we're working\nwith logs in this function",
    "start": "262450",
    "end": "268479"
  },
  {
    "text": "as well where we're just\nkind of getting the log probability for our initial\nstate that occurred,",
    "start": "268480",
    "end": "274130"
  },
  {
    "text": "and then we're\nadding on the log PDF of the disturbance that occurred\nat every single time step.",
    "start": "274130",
    "end": "281358"
  },
  {
    "text": "OK, so now we know\nhow to calculate the likelihood of a trajectory. So we can incorporate that\ninto our objective function",
    "start": "281358",
    "end": "288280"
  },
  {
    "text": "with the hope of\nfinding likely failures. So here's our new\nobjective function",
    "start": "288280",
    "end": "293370"
  },
  {
    "text": "that we're going\nto consider here. And there's two possible cases. So the first case is that\nthe trajectory is a failure.",
    "start": "293370",
    "end": "300490"
  },
  {
    "text": "So in this case, it's\nwritten tau, not in PSI. So every time you see that,\nwe'll use this quite a bit",
    "start": "300490",
    "end": "306660"
  },
  {
    "text": "in the class, anytime you\nsee that means trajectory not in specification. Meaning trajectory doesn't\nsatisfy the specification.",
    "start": "306660",
    "end": "313930"
  },
  {
    "text": "Meaning the trajectory\nis a failure. So that's just kind\nof a mathematical way that we write that a trajectory\nis a failure trajectory.",
    "start": "313930",
    "end": "322500"
  },
  {
    "text": "So if it's a failure\ntrajectory, then we're going to return the negative\nlikelihood of the trajectory.",
    "start": "322500",
    "end": "328690"
  },
  {
    "text": "So that means if we put\na failure trajectory into this objective,\nwe're going to say take that failure trajectory\nand try to make it more likely,",
    "start": "328690",
    "end": "335740"
  },
  {
    "text": "try to minimize the\nnegative likelihood of it. And then the second case here,\nwhich is the case at the bottom,",
    "start": "335740",
    "end": "343000"
  },
  {
    "text": "if the trajectory\nis not a failure, then we don't care about\nits likelihood just yet, we just want to move\nthe trajectory closer",
    "start": "343000",
    "end": "349350"
  },
  {
    "text": "to being a failure. So we still try to\nminimize the robustness if it's not a failure.",
    "start": "349350",
    "end": "355806"
  },
  {
    "text": "OK, so now I'm going to\nshow what this looks like. So here I'm showing\na different example",
    "start": "355806",
    "end": "361240"
  },
  {
    "text": "than the pendulum\nwe've been seeing. This is a Gridworld where\nthe agent can move around",
    "start": "361240",
    "end": "366340"
  },
  {
    "text": "on these grid squares. But every once in\na while, instead of moving in the\ndirection it wants to, it will slip to some other grid\nsquare in a different direction.",
    "start": "366340",
    "end": "374650"
  },
  {
    "text": "You can imagine if we had\nno disturbances at all-- So the disturbances\nhere are what causes it to slip in\nthese other directions.",
    "start": "374650",
    "end": "382100"
  },
  {
    "text": "If we had no\ndisturbances at all, we would just follow this\npath here to the goal, and we're trying to\navoid the obstacle.",
    "start": "382100",
    "end": "389560"
  },
  {
    "text": "And so a likely\ntrajectory is kind of going to stay near this path,\nbut we want it to also fail.",
    "start": "389560",
    "end": "396457"
  },
  {
    "text": "So I'm going to show\nwhat happens if we just minimize the\nrobustness versus if we minimize this new objective.",
    "start": "396457",
    "end": "401960"
  },
  {
    "text": "And what I'm showing here is-- what I will be showing\nis the evolution of a population\nmethod, which is kind",
    "start": "401960",
    "end": "409683"
  },
  {
    "text": "of a category of\noptimization algorithms that I'll talk\nabout in a minute. But really, the idea is\njust that we maintain a whole population\nof samples, so we",
    "start": "409683",
    "end": "416330"
  },
  {
    "text": "maintain a whole population\nof possible trajectories, and our goal is to move\nthat population iteratively",
    "start": "416330",
    "end": "422030"
  },
  {
    "text": "towards optimizing\nour objective. So when I show the\nnext animation here,",
    "start": "422030",
    "end": "428142"
  },
  {
    "text": "you're going to see both of\nthese populations change. And you'll see how\nthey differ with one objective versus the other.",
    "start": "428142",
    "end": "433920"
  },
  {
    "text": "So let's check that out.  OK, so you can see\nhere we've kind",
    "start": "433920",
    "end": "439400"
  },
  {
    "text": "of converged this population\nwhere most of the trajectories just go almost straight\nto the obstacle.",
    "start": "439400",
    "end": "445230"
  },
  {
    "text": "And then over here we've kind\nof with this new objective that incorporates likelihood,\nwe found this failure that stays kind of close\nto the nominal path,",
    "start": "445230",
    "end": "453470"
  },
  {
    "text": "and then only kind of\ndeviates right at the end and falls into the obstacle. ",
    "start": "453470",
    "end": "459920"
  },
  {
    "text": "So here's just what that\nlooks kind of over time throughout the progression\nof the algorithm. ",
    "start": "459920",
    "end": "470880"
  },
  {
    "text": "OK, so that's what\nwe want to do. And it turns out if\nwe could actually find the global minimum\nof this objective,",
    "start": "470880",
    "end": "477169"
  },
  {
    "text": "we would get the most\nlikely failure, which is a nice property to have. However, a lot of\ntimes we can't actually",
    "start": "477170",
    "end": "482590"
  },
  {
    "text": "find the global minimum because\nour optimization algorithms just aren't designed to do\nthat or aren't able to do that.",
    "start": "482590",
    "end": "489400"
  },
  {
    "text": "So I just want to give you a few\nnotes on using this objective. The first thing is that it needs\nto be the case that failures",
    "start": "489400",
    "end": "496060"
  },
  {
    "text": "never have a higher objective\nvalue than successes. Because if that's\nthe case, then we",
    "start": "496060",
    "end": "501100"
  },
  {
    "text": "might actually not encourage\nthe algorithm to find a failure. It might find a success that's\nsomehow better than a failure.",
    "start": "501100",
    "end": "509620"
  },
  {
    "text": "But you might be\nthinking, OK, no problem. Because when we do have\na success trajectory,",
    "start": "509620",
    "end": "516500"
  },
  {
    "text": "we know that the robustness\nis greater than 0. And so we said in\nthis case where we have a success trajectory,\nwe just return the robustness.",
    "start": "516500",
    "end": "523548"
  },
  {
    "text": "So successes are always going to\nhave positive objective values. And then the negative\nlikelihood of something,",
    "start": "523549",
    "end": "529597"
  },
  {
    "text": "which is what we return\nwhen it's a failure, well, since probability\nalways has to be positive, probability density\nalways has to be positive,",
    "start": "529597",
    "end": "535930"
  },
  {
    "text": "this is always going\nto be negative. So this is always going\nto be less than 0. So it seems like\nwe're good to go.",
    "start": "535930",
    "end": "542070"
  },
  {
    "text": "And that's true. But there's also\none more problem, which is that this\nkind of p of tau",
    "start": "542070",
    "end": "547560"
  },
  {
    "text": "here, as we were\ntalking about earlier, we're multiplying lots of things\ntogether, lots of small numbers together. So we might get a really,\nreally small number.",
    "start": "547560",
    "end": "553930"
  },
  {
    "text": "And this might be not\nvery numerically stable. So it can be difficult for\noptimization algorithms,",
    "start": "553930",
    "end": "560110"
  },
  {
    "text": "especially on the\ncomputer, to actually go about optimizing this type\nof objective effectively.",
    "start": "560110",
    "end": "566108"
  },
  {
    "text": "And so you might think,\nOK, let's just take the log, which is like\nwhat we did before and make everything\nmore numerically stable.",
    "start": "566108",
    "end": "571509"
  },
  {
    "text": "But then this breaks\nour first requirement because the log likelihood\ncould be less than 0.",
    "start": "571510",
    "end": "576790"
  },
  {
    "text": "So that means this\ncould be less than 0. So this negative, this\ncould be greater than 0.",
    "start": "576790",
    "end": "582340"
  },
  {
    "text": "And then we don't have this\nproperty that we needed anymore. And so all of that is kind of\njust to say that even though",
    "start": "582340",
    "end": "589350"
  },
  {
    "text": "if we could get the\nglobal minimum of this, this is what we\nwould want to do. Sometimes a different\nobjective actually works",
    "start": "589350",
    "end": "595080"
  },
  {
    "text": "better in practice. And so in practice,\nwhat we often do is instead kind of just combine\nthese two into one single case,",
    "start": "595080",
    "end": "602370"
  },
  {
    "text": "where we trade off between\nminimizing the robustness and minimizing the\nnegative log likelihood.",
    "start": "602370",
    "end": "609750"
  },
  {
    "text": "So for example, here\nwe have the robustness, we have the log\nlikelihood, and then we have this weighting\nparameter that we",
    "start": "609750",
    "end": "615870"
  },
  {
    "text": "call lambda which kind of\ntrades off between the two. So this is a parameter that\nyou would need to tune.",
    "start": "615870",
    "end": "621880"
  },
  {
    "text": "And if you looked at what was\ncoming out of your optimization and maybe you found Oh,\nit's not finding failures,",
    "start": "621880",
    "end": "627460"
  },
  {
    "text": "then you would want to increase\nthis weighting parameter, et cetera, or maybe decrease.",
    "start": "627460",
    "end": "632668"
  },
  {
    "text": "I don't know. You need to look at the various\ntrade offs between the two.",
    "start": "632668",
    "end": "638730"
  },
  {
    "text": "OK, and so then now we have\nour objective function. And then we need to optimize.",
    "start": "638730",
    "end": "644010"
  },
  {
    "text": "So here's the algorithm we\nprovide in the book for it. It looks super simple because\nwe've kind of abstracted away",
    "start": "644010",
    "end": "649830"
  },
  {
    "text": "a lot of things here. But really what's going on is we\nspecify some objective function.",
    "start": "649830",
    "end": "655540"
  },
  {
    "text": "So that could be anything\nthat we just talked about. So it could be like\nthe robustness. It could be the likelihood\nobjective, et cetera.",
    "start": "655540",
    "end": "664050"
  },
  {
    "text": "We give it some optimizer. So this is really what\nwe're like abstracting away quite a bit. But the reason\nwe're doing this is",
    "start": "664050",
    "end": "669930"
  },
  {
    "text": "because we've now formulated\nthe problem in such a way that it's set up as an\noptimization problem.",
    "start": "669930",
    "end": "675010"
  },
  {
    "text": "And so there's lots of\nalgorithms off the shelf that people have already\nimplemented that can do this kind of thing for you.",
    "start": "675010",
    "end": "680709"
  },
  {
    "text": "And so you could just use open\nsource algorithms to do this. So in the book,\nwe show an example where we use a Julia package for\noptimization called optim.jl.",
    "start": "680710",
    "end": "689170"
  },
  {
    "text": "There's another nice\nJulia package called JMP. There's various optimization\npackages out there.",
    "start": "689170",
    "end": "694650"
  },
  {
    "text": "And you could just\nplug-in an optimizer from any of those that\ncould take in our objective and do this optimization.",
    "start": "694650",
    "end": "701790"
  },
  {
    "text": "But I do want to mention a\nfew things about this kind of mysterious optimizer. So we did talk about\nit a little bit",
    "start": "701790",
    "end": "708569"
  },
  {
    "text": "in the lectures\non model building. And in those lectures, we just\nsaid it takes in an objective,",
    "start": "708570",
    "end": "714761"
  },
  {
    "text": "it takes in some parameters,\nit does some mysterious stuff, and then it outputs\nthe optimum for us. So I'm going to open up that\nblack box just slightly more,",
    "start": "714762",
    "end": "723640"
  },
  {
    "text": "although we're not going\nto get to in detail today. But what's going on here is now\nin this case, our parameters",
    "start": "723640",
    "end": "730170"
  },
  {
    "text": "that we're inputting to our\noptimizer, our initial state and our sequence\nof disturbances,",
    "start": "730170",
    "end": "735820"
  },
  {
    "text": "so it gets to pick\nall of those things. We give it our\nobjective, and then it's going to output this\noptimal trajectory for us.",
    "start": "735820",
    "end": "743520"
  },
  {
    "text": "And there's two different\nkind of categories of methods that I want you\nguys to know about. The first category is called\nlocal descent methods.",
    "start": "743520",
    "end": "751950"
  },
  {
    "text": "And what these\nmethods do is let's say that this, for example, is\nour objective function that we want to find the minimum of.",
    "start": "751950",
    "end": "757620"
  },
  {
    "text": "A local descent method starts\nfrom some initial guess. So here it's just a point. For our actual\ntrajectories, it'll",
    "start": "757620",
    "end": "763720"
  },
  {
    "text": "be like a full trajectory\nas our initial guess. And then it kind\nof just moves that",
    "start": "763720",
    "end": "769300"
  },
  {
    "text": "guess slowly towards a minimum. One very common problem\nwith local descent methods",
    "start": "769300",
    "end": "775810"
  },
  {
    "text": "is that it does depend on that\ninitial guess where you end up. So here, looking at this,\nthis is the global minimum",
    "start": "775810",
    "end": "782379"
  },
  {
    "text": "we were shooting for. But if we started over here\nand we descended from there, we might end up getting stuck\nin this kind of local minimum.",
    "start": "782380",
    "end": "790750"
  },
  {
    "text": "So you're not always guaranteed\nto get the global minimum there.",
    "start": "790750",
    "end": "795850"
  },
  {
    "text": "So one kind of fix\nto that, or a thing that you could try\nto do to improve, is instead of just\ntaking one sample",
    "start": "795850",
    "end": "801280"
  },
  {
    "text": "and moving it\ntowards the minimum, you can maintain a full\npopulation of samples, and then try to move those\ntowards various minima.",
    "start": "801280",
    "end": "808940"
  },
  {
    "text": "So now we're kind of covering\nmore parts of the input space. ",
    "start": "808940",
    "end": "815829"
  },
  {
    "text": "And then within local\ndescent methods, there's these things called\nfirst order and second order methods.",
    "start": "815830",
    "end": "821508"
  },
  {
    "text": "You don't need to know\ntoo much about them, but I just want you to\nknow-- well, one thing we can name drop a little bit.",
    "start": "821508",
    "end": "827320"
  },
  {
    "text": "So gradient descent, many of\nyou have probably heard of. It's very commonly used\nfor training machine learning models.",
    "start": "827320",
    "end": "832600"
  },
  {
    "text": "Similarly, Adam and LBFGS is\na common second order method. So those are just\na few names, things",
    "start": "832600",
    "end": "839250"
  },
  {
    "text": "you might look up if you want\nto plug in an optimization algorithm. But the real thing I want\nyou to know about these",
    "start": "839250",
    "end": "845610"
  },
  {
    "text": "is that they do\nrequire gradients. So they require us\nto be able to take the gradient of our\nobjective function,",
    "start": "845610",
    "end": "851650"
  },
  {
    "text": "so for example, the robustness,\nor that likelihood objective, with respect to our inputs. So that means we need to\nbe able to differentiate",
    "start": "851650",
    "end": "858300"
  },
  {
    "text": "through the full\nrollout function. We need to know the\nfull model dynamics.",
    "start": "858300",
    "end": "865063"
  },
  {
    "text": "We need to know all the\nmathematics behind it. And so we have a black box\nmodel like we talked about in the second lecture.",
    "start": "865063",
    "end": "870660"
  },
  {
    "text": "This is not going\nto be plausible. Because we don't actually know\nthe mathematics that are going on, we can't take the gradient.",
    "start": "870660",
    "end": "877450"
  },
  {
    "text": "But if we can, these methods\ntend to be quite powerful. And again, like I said,\nit's kind of insane how they can just train\nthese machine learning models",
    "start": "877450",
    "end": "883839"
  },
  {
    "text": "with millions and\nmillions of parameters. But if we can't\ntake the gradient, we're not totally stuck here.",
    "start": "883840",
    "end": "890750"
  },
  {
    "text": "We can actually use something\ncalled zero order methods, or sometimes they're\ncalled direct methods. And they basically do\nthis descent just based",
    "start": "890750",
    "end": "897640"
  },
  {
    "text": "on function evaluation. So all you have to be able\nto do is take an input and get the objective\nvalue output.",
    "start": "897640",
    "end": "902780"
  },
  {
    "text": "You don't need to know\nwhat happens in between. So you might have heard of\nHooke-Jeeves or Nelder-Mead.",
    "start": "902780",
    "end": "908420"
  },
  {
    "text": "These are very common\ndirect methods. And what's cool\nabout them is they can work for Black box systems.",
    "start": "908420",
    "end": "914029"
  },
  {
    "text": "So even if you have just\nthis big, crazy simulator, you don't know how it works,\nas long as you can give it",
    "start": "914030",
    "end": "920200"
  },
  {
    "text": "your input state\nand disturbances and get out a trajectory\nsuch that you could evaluate the objective,\nyou could actually",
    "start": "920200",
    "end": "926680"
  },
  {
    "text": "use these methods to find\nfailures of these systems.",
    "start": "926680",
    "end": "932050"
  },
  {
    "text": "OK, so let's look at what local\ndescent methods look like. So here's going to be an\nexample of gradient descent.",
    "start": "932050",
    "end": "940560"
  },
  {
    "text": "And we're looking\nat the pendulum again, where each of these\ndots represents a disturbance.",
    "start": "940560",
    "end": "945705"
  },
  {
    "text": "And the way we've\ninitialized it, you remember we need some\nof initial guess here. So we've just said that we\nstart at an initial state of 0.",
    "start": "945705",
    "end": "952150"
  },
  {
    "text": "And all of our\ndisturbances are also 0. So the pendulum\njust kind of stays completely vertical\nthe whole time.",
    "start": "952150",
    "end": "959339"
  },
  {
    "text": "And then you'll see we\ncan take a step here. So if you notice, even if you\nblinked, maybe you didn't. But there's a tiny\nstep that occurred here",
    "start": "959340",
    "end": "966690"
  },
  {
    "text": "where we just kind of perturbed\nthese disturbances ever so slightly to try to move that\ntrajectory towards a failure.",
    "start": "966690",
    "end": "973500"
  },
  {
    "text": "And then as we continue\nto take more steps, you can see we slowly perturb\nit and select these disturbances",
    "start": "973500",
    "end": "979830"
  },
  {
    "text": "to a point where we can\ncause the pendulum to fail. So that's local descent.",
    "start": "979830",
    "end": "985960"
  },
  {
    "text": "And then to contrast that\nwith population methods, in this case, we're now\nmaintaining a full population",
    "start": "985960",
    "end": "992459"
  },
  {
    "text": "of possible samples. So we're maintaining a whole\nbunch of different trajectories for the pendulum.",
    "start": "992460",
    "end": "997570"
  },
  {
    "text": "And then now every\ntime we take a step, we update all the samples\nin that population to try to move them\ntowards failure.",
    "start": "997570",
    "end": "1003670"
  },
  {
    "text": "And then over time,\nwe get to a point where we can find multiple\nfailures of the system.",
    "start": "1003670",
    "end": "1010170"
  },
  {
    "text": "And what's kind of cool\nabout population methods is you'll remember in local\ndescent, when we just",
    "start": "1010170",
    "end": "1016278"
  },
  {
    "text": "did gradient descent,\nit kind of just perturbed the trajectory until\nit just went off to one side.",
    "start": "1016278",
    "end": "1021340"
  },
  {
    "text": "So we just found\none failure mode. But what's kind of cool\nabout population methods is they kind of\nencourage the population",
    "start": "1021340",
    "end": "1026849"
  },
  {
    "text": "to spread out amongst all of\nthese different possible minima. And so we're actually\nable to find failures",
    "start": "1026849",
    "end": "1033240"
  },
  {
    "text": "in both failure modes\nfor the inverted pendulum when we use methods like this. ",
    "start": "1033240",
    "end": "1041368"
  },
  {
    "text": "A quick question. Yeah. So when you say you take a step,\nyou mean like an optimization step in that case?",
    "start": "1041369",
    "end": "1047280"
  },
  {
    "text": "Oh, yeah, good question. The question was,\nwhen I take a step, do I mean optimization step. So yeah, I can\nsee how that would be getting confused\nwith like the step",
    "start": "1047280",
    "end": "1053920"
  },
  {
    "text": "that we talk about\nin this class. I mean, yeah, a step of\nthe optimization algorithm. And in that case, the optimum\nwould be kind of with respect",
    "start": "1053920",
    "end": "1062170"
  },
  {
    "text": "to-- well, I mean, we\nhave this cost function that we defined that\ntrades off your robustness",
    "start": "1062170",
    "end": "1068410"
  },
  {
    "text": "and your likelihood, right? And so the optimum or kind of\nthe picture that you showed,",
    "start": "1068410",
    "end": "1073850"
  },
  {
    "text": "we don't just have all\nfailure cases, because we also want them to be likely.",
    "start": "1073850",
    "end": "1080289"
  },
  {
    "text": "Yeah, yeah. So the question was\nlike so we're not just going to have all possible\nfailure cases because we want them to be likely.",
    "start": "1080290",
    "end": "1085640"
  },
  {
    "text": "So we're just going to be\nfinding the likely ones. That is true. I'm actually not\nsure what objective I used for that example.",
    "start": "1085640",
    "end": "1091370"
  },
  {
    "text": "I might have just\nbeen using robustness. But if you were using that\nobjective, that's true.",
    "start": "1091370",
    "end": "1097570"
  },
  {
    "text": "All right, so that is a super\nbrief overview of the huge field of optimization.",
    "start": "1097570",
    "end": "1103720"
  },
  {
    "text": "If you want to know\nmore about it-- So for this class, that\nshould be sufficient. I just want you to\nunderstand the trade",
    "start": "1103720",
    "end": "1109075"
  },
  {
    "text": "offs between these\nmethods so that you can go to these\noff-the-shelf tools and plug them in to do\nthis falsification for you,",
    "start": "1109075",
    "end": "1115420"
  },
  {
    "text": "and mainly understanding\nthat black box versus needing gradients type of thing.",
    "start": "1115420",
    "end": "1120530"
  },
  {
    "text": "But it is a really interesting\nfield and super, super useful to know things about. So I would recommend this class,\nif you haven't taken it yet,",
    "start": "1120530",
    "end": "1128140"
  },
  {
    "text": "next quarter, taught by Michael,\nand he'll dive into these in much, much more detail.",
    "start": "1128140",
    "end": "1133700"
  },
  {
    "text": "So I would definitely recommend. OK, so yeah, just to recap here.",
    "start": "1133700",
    "end": "1140150"
  },
  {
    "text": "We talked about how to\nsystematically search for failures. And I introduced fuzzing,\nwhich is, like I said,",
    "start": "1140150",
    "end": "1147169"
  },
  {
    "text": "where I would start\nwith for project 1. And then I talked about\nthis optimization,",
    "start": "1147170",
    "end": "1152960"
  },
  {
    "text": "which can help us more\nsystematically try to optimize these\nobjectives to find failures.",
    "start": "1152960",
    "end": "1159650"
  },
  {
    "text": "And that's what I\nwould do if I wanted to improve my leaderboard\nscore on project 1.",
    "start": "1159650",
    "end": "1165940"
  },
  {
    "text": "Any questions on this lecture? Yeah.",
    "start": "1165940",
    "end": "1171550"
  },
  {
    "text": "[INAUDIBLE] you're\nretaining the samples,",
    "start": "1171550",
    "end": "1179780"
  },
  {
    "text": "but [INAUDIBLE] doing\nlevel set methods, it's just one sample at a time.",
    "start": "1179780",
    "end": "1186370"
  },
  {
    "text": "I don't really\nunderstand what it is. Yeah, so the question\nis like, can I",
    "start": "1186370",
    "end": "1192700"
  },
  {
    "text": "explain population\nmethods a little bit more, like what's the\ndifference between that, and just kind of maintaining\none sample and moving it.",
    "start": "1192700",
    "end": "1199450"
  },
  {
    "text": "So I think the idea is\nkind of if we go back here. Oops.",
    "start": "1199450",
    "end": "1204650"
  },
  {
    "text": "Wait a minute. So with local descent,\nwe just take one sample and we try to move it.",
    "start": "1204650",
    "end": "1212139"
  },
  {
    "text": "With global, or sorry, with\npopulation methods, what we can do here is now\nwe've kind of just",
    "start": "1212140",
    "end": "1217240"
  },
  {
    "text": "sampled all over our possible\nspace of in this case, like just X, but in\ngeneral, it would be a bunch",
    "start": "1217240",
    "end": "1223570"
  },
  {
    "text": "of different trajectories. And so that allows\nus to get a more global view of what's going on.",
    "start": "1223570",
    "end": "1229020"
  },
  {
    "text": "And then we can take\nall of those samples, and now some of them will end\nup in this minima, some of them will end up here, some\nof them will end up here.",
    "start": "1229020",
    "end": "1234900"
  },
  {
    "text": "And so it's kind of\na way to avoid just ending up in one local minima. [INAUDIBLE]",
    "start": "1234900",
    "end": "1240049"
  },
  {
    "text": "Yeah. So each X, like\neach starting sample is a whole trajectory,\nnot just an initial space",
    "start": "1240050",
    "end": "1246799"
  },
  {
    "text": "that we're starting from? It's the whole trajectory? Yeah, exactly. So the question was each X\nis like a whole trajectory?",
    "start": "1246800",
    "end": "1252030"
  },
  {
    "text": "Yeah. So here I'm just showing it in\n1D so we can actually visualize it. But in general, like\nwe're searching over this kind of big\nspace that can be",
    "start": "1252030",
    "end": "1258769"
  },
  {
    "text": "like 50 dimensional or\nsomething like that. It's a full trajectory. OK, so let's go to\nthe next lecture.",
    "start": "1258770",
    "end": "1269030"
  },
  {
    "text": "Everything we just talked\nabout was doing falsification. For this next\nlecture, we're also going to talk about\nfalsification,",
    "start": "1269030",
    "end": "1275040"
  },
  {
    "text": "but we're going to come\nat it from a slightly different perspective. So before we were\nusing optimization.",
    "start": "1275040",
    "end": "1280830"
  },
  {
    "text": "And we were also\ndoing lots of setup with these disturbances\nand whatnot, and now we're going to do\nfalsification through planning.",
    "start": "1280830",
    "end": "1288420"
  },
  {
    "text": "OK, so I'm going to\nintroduce this topic with a little bit of a story. So the question is, why do we\nsave our work periodically.",
    "start": "1288420",
    "end": "1296846"
  },
  {
    "text": "This is kind of a\nrhetorical question. But basically, over-- You can probably imagine\nwhere this story is going.",
    "start": "1296847",
    "end": "1302780"
  },
  {
    "text": "So over the holidays quite\nrecently, me and my husband",
    "start": "1302780",
    "end": "1308560"
  },
  {
    "text": "were like visiting family. And he didn't have very\nmany days off work, so he had to work remotely\nfor a lot of our trip.",
    "start": "1308560",
    "end": "1316733"
  },
  {
    "text": "And so we were both kind of\nworking remotely from my dad's kitchen, and we\nwere like getting ready to wrap up for the day\nand go grab dinner with my dad.",
    "start": "1316733",
    "end": "1323720"
  },
  {
    "text": "And all of a sudden, I\nheard some commotion coming from his side of the kitchen. And I looked up and I was\nlike, what's going on.",
    "start": "1323720",
    "end": "1330800"
  },
  {
    "text": "And he was like, my\ncomputer just crashed and I lost everything,\nand Oh my gosh,",
    "start": "1330800",
    "end": "1336115"
  },
  {
    "text": "and I can't go to dinner\nnow, and blah, blah, blah. And I was like, oh, let's try\nto get it like turned back on.",
    "start": "1336115",
    "end": "1343120"
  },
  {
    "text": "When was the last\ntime you saved. And his reply? Three hours ago.",
    "start": "1343120",
    "end": "1350130"
  },
  {
    "text": "So I like to think\nthat I'm normally a very kind and caring wife. But in that moment,\nsomething just came over me",
    "start": "1350130",
    "end": "1357950"
  },
  {
    "text": "and I was like, you haven't\nsaved in three hours? That's on you. For the record, wrong thing\nto say when someone has just",
    "start": "1357950",
    "end": "1366020"
  },
  {
    "text": "lost three hours of work. So anyway, then I switched back\nto and caring wife and was like,",
    "start": "1366020",
    "end": "1372898"
  },
  {
    "text": "OK, we'll get this figured out. You can do this after dinner. We'll get it all redone. It's OK. But it kind of gets\nme thinking, OK,",
    "start": "1372898",
    "end": "1379620"
  },
  {
    "text": "why do we save our\nwork periodically? Because I'm just like, Control\nS like every five seconds.",
    "start": "1379620",
    "end": "1385550"
  },
  {
    "text": "So very different from\nthis three hour cadence that he was on. And I think the reason we\nsave our work periodically",
    "start": "1385550",
    "end": "1391970"
  },
  {
    "text": "is because rather than just kind\nof at the beginning and the end is because we want to be\nable to go back to the point that we were at before.",
    "start": "1391970",
    "end": "1397860"
  },
  {
    "text": "So we don't want to have to\nbuild everything up all at once. And if something bad were\nto happen, like for example,",
    "start": "1397860",
    "end": "1403300"
  },
  {
    "text": "we don't like the\ndirection we were going, or our entire computer crashes,\nwe can just go back to the point that we were at before.",
    "start": "1403300",
    "end": "1409650"
  },
  {
    "text": "And so the idea of this\nlecture is that maybe sometimes it's kind of easier to\niteratively build something up",
    "start": "1409650",
    "end": "1415710"
  },
  {
    "text": "than to do it all at once. So that's what we're\ngoing to talk about with these planning algorithms.",
    "start": "1415710",
    "end": "1422430"
  },
  {
    "text": "And if you remember from last\nlecture, which we were just talking about, so it\nshould be quite fresh,",
    "start": "1422430",
    "end": "1428250"
  },
  {
    "text": "we had this optimization\nproblem where we were minimizing over the\nentire space of initial states",
    "start": "1428250",
    "end": "1433470"
  },
  {
    "text": "and the disturbances\nat every single time step in the trajectory. And we can just rewrite\nthis optimization problem,",
    "start": "1433470",
    "end": "1439570"
  },
  {
    "text": "so we have tau equals rollout,\nwe could just replace the tau with the rollout. So I'm going to\nrewrite it like that.",
    "start": "1439570",
    "end": "1446039"
  },
  {
    "text": "And so this kind of\noptimization problem, it typically involves\nsearching over a very high dimensional\nspace, as we've already",
    "start": "1446040",
    "end": "1451328"
  },
  {
    "text": "mentioned a few times. So for example, for\nthe inverted pendulum,",
    "start": "1451328",
    "end": "1456360"
  },
  {
    "text": "we have our initial state,\nwhich is two-dimensional, and then each of our\ndisturbances is two-dimensional,",
    "start": "1456360",
    "end": "1463080"
  },
  {
    "text": "but we have one for\nevery single time step. So this kind of sequences\nof sequence of disturbances",
    "start": "1463080",
    "end": "1468380"
  },
  {
    "text": "is going to be two\ntimes D dimensional. So for example, if we had a\ndepth of 21, which is actually",
    "start": "1468380",
    "end": "1474637"
  },
  {
    "text": "even smaller than the depth\nthat we had been looking at, we were looking at 41\nbefore, the search space is going to be 44 dimensional.",
    "start": "1474637",
    "end": "1481057"
  },
  {
    "text": "So this is already pretty\nbig, and that's not even a huge problem. So for these bigger\nproblems that",
    "start": "1481057",
    "end": "1486590"
  },
  {
    "text": "have even bigger states\nor bigger disturbances, it could be hundreds\nof dimensions that we're trying\nto search over.",
    "start": "1486590",
    "end": "1492420"
  },
  {
    "text": "And that's kind of a\nlot to do all at once. And so what planning\nalgorithms allow us to do",
    "start": "1492420",
    "end": "1498230"
  },
  {
    "text": "is to basically iteratively\nbuild up this trajectory instead.",
    "start": "1498230",
    "end": "1504350"
  },
  {
    "text": "So for the plan for\ntoday, we're going to talk about a\ncategory of methods",
    "start": "1504350",
    "end": "1511039"
  },
  {
    "text": "for quite a bit of the\nlecture called tree search. And one of the really cool\ncontributions, I think,",
    "start": "1511040",
    "end": "1516560"
  },
  {
    "text": "of the book we\ncreated is that we unified quite a bit of\ndifferent types of tree search",
    "start": "1516560",
    "end": "1521970"
  },
  {
    "text": "that are out there\ninto just two steps. So we're going to talk\nabout that framework.",
    "start": "1521970",
    "end": "1527388"
  },
  {
    "text": "And then we'll talk about\nsome specific implementations of that. So we'll talk about one\ncalled heuristic search,",
    "start": "1527388",
    "end": "1532590"
  },
  {
    "text": "we'll talk about Monte\nCarlo tree search, a little bit about\nreinforcement learning, and a little bit about some\nrequirements for the simulator",
    "start": "1532590",
    "end": "1539669"
  },
  {
    "text": "that you're using if you\nwant to use these methods. OK, so let's get started\nwith tree search.",
    "start": "1539670",
    "end": "1548340"
  },
  {
    "text": "Here's a tree that's\nsearching for its groove. [LAUGHTER] ",
    "start": "1548340",
    "end": "1554070"
  },
  {
    "text": "For those of you who\nhaven't seen this before, this is Michael. [LAUGHTER] ",
    "start": "1554070",
    "end": "1560250"
  },
  {
    "text": "He got to live out his\nlifelong dream of dressing as the Stanford tree.",
    "start": "1560250",
    "end": "1565920"
  },
  {
    "text": "All right. All right, so we're not really\ntalking about that type of tree, although it's quite fun.",
    "start": "1565920",
    "end": "1571910"
  },
  {
    "text": " We're talking about this\ntype of tree in this lecture.",
    "start": "1571910",
    "end": "1579820"
  },
  {
    "text": "So the kind of structure\nof the trees that we're going to be looking\nat for this lecture is every single node\nin the tree is going",
    "start": "1579820",
    "end": "1586690"
  },
  {
    "text": "to be some state for our system. And then every\ntransition or every edge represents a transition\nbetween the nodes.",
    "start": "1586690",
    "end": "1593750"
  },
  {
    "text": "So to get from this state,\nwe had this disturbance, which resulted in\nobservation O, action A, and then eventually the\nnext state S. Any questions",
    "start": "1593750",
    "end": "1602529"
  },
  {
    "text": "on that structure? Yeah. Sorry, just to\nclarify, the letter X",
    "start": "1602530",
    "end": "1608020"
  },
  {
    "text": "is used a lot since\ndisturbance and also here. Can you clarify what\nexactly the letter X is?",
    "start": "1608020",
    "end": "1614110"
  },
  {
    "text": "Yeah, we typically use\nit to mean disturbance. So the question was, can you\nclarify what the letter X is. Here it's meaning\ndisturbance, for sure.",
    "start": "1614110",
    "end": "1621130"
  },
  {
    "text": "Sometimes if we're just talking\nabout general optimization or a very general\nvariable, we also use X.",
    "start": "1621130",
    "end": "1626389"
  },
  {
    "text": "So I can see the\nconfusion there. But here it's disturbance. Yeah. ",
    "start": "1626390",
    "end": "1634210"
  },
  {
    "text": "OK, so an example that we're\ngoing to use quite a bit throughout this lecture is what\nwe call it the continuum world.",
    "start": "1634210",
    "end": "1639970"
  },
  {
    "text": "It's in the back of the book. But the general idea\nhere is it's kind of a continuous version\nof a grid world problem.",
    "start": "1639970",
    "end": "1646300"
  },
  {
    "text": "So we have an agent that can\nmove around within this space, and it needs to reach this goal\nwhile avoiding this obstacle.",
    "start": "1646300",
    "end": "1652270"
  },
  {
    "text": "And it can take actions of-- similar to the grid world,\nit can take actions of up, down, left and right,\nand it will move one unit",
    "start": "1652270",
    "end": "1659309"
  },
  {
    "text": "in all of those directions. But again, like the grid\nworld, it's slippery. But now, instead\nof slipping exactly",
    "start": "1659310",
    "end": "1665400"
  },
  {
    "text": "in one of the\ncardinal directions, it can just-- if it says\nit's going to move up, it might just slip a little\nbit at some angle that's",
    "start": "1665400",
    "end": "1672480"
  },
  {
    "text": "kind of close to up\nbut not quite up. And so our disturbances\nin this case are just the things\nthat cause it to slip",
    "start": "1672480",
    "end": "1678000"
  },
  {
    "text": "and how much it slips basically. And so we could look at\nwhat a tree might look like for this continuum world.",
    "start": "1678000",
    "end": "1684880"
  },
  {
    "text": "So here each node in the\ntree is a different state. So we're actually\nshowing the nodes",
    "start": "1684880",
    "end": "1689940"
  },
  {
    "text": "where the states actually are. So this node represents\nthis exact position in the continuum world.",
    "start": "1689940",
    "end": "1695720"
  },
  {
    "text": "And then the edges are possible\ntransitions between states. So for example,\nat the root node, one disturbance would\ntake us to this state,",
    "start": "1695720",
    "end": "1702610"
  },
  {
    "text": "and another disturbance\nwould take us to this state. ",
    "start": "1702610",
    "end": "1708100"
  },
  {
    "text": "OK, and so now that we\nhave a concrete problem, let's talk about what a typical\niteration of a tree search",
    "start": "1708100",
    "end": "1714759"
  },
  {
    "text": "algorithm might look like. So what we do is we\nhave our current tree",
    "start": "1714760",
    "end": "1719950"
  },
  {
    "text": "that we've maintained. And the first thing that\nwe do is we select a node that we want to focus on.",
    "start": "1719950",
    "end": "1725750"
  },
  {
    "text": "So for example, we\nselect this one. In a bit, I'll talk about\nhow we actually select this. But this is just the first step.",
    "start": "1725750",
    "end": "1730983"
  },
  {
    "text": "And then once we've\nselected a node, we do something called the\nExtend step where we extend it.",
    "start": "1730983",
    "end": "1736509"
  },
  {
    "text": "And all that's going on here\nis we sample a new disturbance, which gives us a new\nobservation action and brings us to\na different state.",
    "start": "1736510",
    "end": "1742845"
  },
  {
    "text": " So to summarize here, we\nhave basically two steps",
    "start": "1742845",
    "end": "1751330"
  },
  {
    "text": "in a tree search algorithm. One is the Select\nstep, where we select one of the nodes that's\ncurrently in the tree to extend.",
    "start": "1751330",
    "end": "1757627"
  },
  {
    "text": "And then the other\nis the Extend step, where we actually extend it. So I haven't talked\nabout how these work.",
    "start": "1757627",
    "end": "1763950"
  },
  {
    "text": "And in fact, though, with\njust these two steps, we can create kind of a general\nalgorithm for tree search",
    "start": "1763950",
    "end": "1770075"
  },
  {
    "text": "that's going to\nallow us to unify all of these different\ntypes of tree search. We're going to talk about. So all that's going on here\nis we initialize our tree",
    "start": "1770075",
    "end": "1776730"
  },
  {
    "text": "in some way. And then every single step of\nthe algorithm, we select a node,",
    "start": "1776730",
    "end": "1782200"
  },
  {
    "text": "and then we extend it. And all of the algorithms that\nwe're going to talk about just differ in how they actually\ngo about implementing",
    "start": "1782200",
    "end": "1789660"
  },
  {
    "text": "this Select and Extend step. So how do they decide\nwhich node to select, and then how do they select\na disturbance to extend it.",
    "start": "1789660",
    "end": "1797230"
  },
  {
    "text": "Yeah. Quick question. What is the S here? Is it like the state on\none time step in a rollout,",
    "start": "1797230",
    "end": "1802720"
  },
  {
    "text": "or is it like the initial state? Yeah, so the question was\nwhat is S. So each of these S",
    "start": "1802720",
    "end": "1809039"
  },
  {
    "text": "is like a different\npossible state. So the root node would be\nlike the initial state, and then all of these\nother S's are like states",
    "start": "1809040",
    "end": "1815740"
  },
  {
    "text": "you could reach from there. OK, so it's like having\nthe entire [INAUDIBLE]?",
    "start": "1815740",
    "end": "1821350"
  },
  {
    "text": "Yeah, so like here, here, here\nwould be like a depth of 3. Yeah.",
    "start": "1821350",
    "end": "1828910"
  },
  {
    "text": "OK, so that's tree search. And now we're just\ngoing to talk about all of these different ways we\ncan implement those Select",
    "start": "1828910",
    "end": "1834550"
  },
  {
    "text": "and Extend steps. So the first type of search\nwe're going to talk about is heuristic search.",
    "start": "1834550",
    "end": "1840340"
  },
  {
    "text": "And no surprise,\nheuristic search uses-- heuristic search\nalgorithms use heuristics",
    "start": "1840340",
    "end": "1845830"
  },
  {
    "text": "to explore the space of\npossible trajectories. Another name you might\nhave heard this go by",
    "start": "1845830",
    "end": "1851350"
  },
  {
    "text": "is rapidly exploring\nrandom trees, or RRT. That's kind of another\nname for the algorithms",
    "start": "1851350",
    "end": "1857530"
  },
  {
    "text": "we're going to be talking about. So the way that RRT\nworks is, again, we have to implement these two\nsteps, Select and Extend.",
    "start": "1857530",
    "end": "1865190"
  },
  {
    "text": "So starting with the Select\nstep, the first thing that we do is we sample a goal state.",
    "start": "1865190",
    "end": "1870240"
  },
  {
    "text": "So we just sample some\nstate from our state space. That's the goal that\nwe're trying to get to.",
    "start": "1870240",
    "end": "1875300"
  },
  {
    "text": "Then we compute\nsome of objective for each node in\nthe current tree. So each of those states that\nwe have in our current tree,",
    "start": "1875300",
    "end": "1882510"
  },
  {
    "text": "we compute some\nsort of objective. I haven't told you what\nthat objective is yet, but we compute it based\non the goal state.",
    "start": "1882510",
    "end": "1888390"
  },
  {
    "text": "And then we'll select the node\nwith the lowest objective. I'll do an example in a second.",
    "start": "1888390",
    "end": "1894260"
  },
  {
    "text": "Once we've selected a\nnode, that's the node that we want to extend. And so to extend it, we\njust select a disturbance.",
    "start": "1894260",
    "end": "1900779"
  },
  {
    "text": "We take a step from the selected\nnode using that selected disturbance, and then add\nthe result to the tree.",
    "start": "1900780",
    "end": "1906630"
  },
  {
    "text": "And then we can just keep\nrepeating this process to build up the tree. So let me show an example\nto make this concrete.",
    "start": "1906630",
    "end": "1914160"
  },
  {
    "text": "So with our continuum\nworld, we'll start with our Select step. So let's say this is the\ncurrent tree that we have.",
    "start": "1914160",
    "end": "1920450"
  },
  {
    "text": "And the first thing we do\nis sample a goal state. So kind of the vanilla version\nof RRT, the kind of simplest thing you could do is you could\njust take your entire state",
    "start": "1920450",
    "end": "1927750"
  },
  {
    "text": "space and sample a\nrandom state from it and just say that's\nyour goal state. So here's our goal state. It's this yellow star.",
    "start": "1927750",
    "end": "1934500"
  },
  {
    "text": "And then we compute\nsome of objective for each node in the tree\nbased on the goal state.",
    "start": "1934500",
    "end": "1940390"
  },
  {
    "text": "So one very simple objective\nwe could use here, for example, is just like the\ndistance to the goal. So we can look at this goal\nand compute its distance",
    "start": "1940390",
    "end": "1947520"
  },
  {
    "text": "to each node in the tree. And then all we're going\nto do is select the node",
    "start": "1947520",
    "end": "1952800"
  },
  {
    "text": "with the lowest objective value. So in this case, we're\nselecting the node that's closest to this goal state.",
    "start": "1952800",
    "end": "1957919"
  },
  {
    "text": " So this is the node that\nwe've selected to extend.",
    "start": "1957920",
    "end": "1963970"
  },
  {
    "text": "And now we need to extend it. So one really simple\nthing we can do is just sample a\nrandom disturbance.",
    "start": "1963970",
    "end": "1969280"
  },
  {
    "text": "So in this node, our action\nor our agent wants to go up. And so a disturbance is going\nto be some slipping with respect",
    "start": "1969280",
    "end": "1977310"
  },
  {
    "text": "to this action to go up. And so we'll just sample\na random disturbance. So we just slip a\nlittle bit to the right.",
    "start": "1977310",
    "end": "1984420"
  },
  {
    "text": "And then we take a step\nfollowing that disturbance and add the result to the tree.",
    "start": "1984420",
    "end": "1990300"
  },
  {
    "text": "And then we just\nstart over again. Question? So what's [INAUDIBLE]?",
    "start": "1990300",
    "end": "1995630"
  },
  {
    "text": "Are we trying to\nachieve [INAUDIBLE]?  Sort of.",
    "start": "1995630",
    "end": "2000993"
  },
  {
    "text": "So the question\nwas, are we trying to choose the lowest\nobjective because we're trying to make it fail. In a second, I'm going to\nshow an extension where that's",
    "start": "2000993",
    "end": "2007750"
  },
  {
    "text": "the case, because what\nwe're doing right now is a little bit silly. Because right now we're\njust sampling a goal state",
    "start": "2007750",
    "end": "2012940"
  },
  {
    "text": "like uniformly from in here. So we're choosing\nthe lowest objective to try to get it\nto the goal state. So whatever goal state--",
    "start": "2012940",
    "end": "2018920"
  },
  {
    "text": "Let me see if I\ncan go back here. Whatever goal state\nwe sampled, we're choosing an objective that\nshould hopefully move it",
    "start": "2018920",
    "end": "2024790"
  },
  {
    "text": "towards this goal state. The lowest objective just means\ncloser to this goal state.",
    "start": "2024790",
    "end": "2030000"
  },
  {
    "text": "To the goal state. Yeah, exactly. One other question. I guess it looks at least\nthe way that this [INAUDIBLE]",
    "start": "2030000",
    "end": "2038019"
  },
  {
    "text": "is set up, you don't\nneed to [INAUDIBLE]. So you're only looking\nat those [INAUDIBLE]",
    "start": "2038020",
    "end": "2043630"
  },
  {
    "text": "that you've extended further,\none of the [INAUDIBLE] would not be able to explore\n[INAUDIBLE] in any extending",
    "start": "2043630",
    "end": "2052790"
  },
  {
    "text": "other than that,\nbecause you're probably only going to extend\nthe one that's like closest to the thing. So you're never adding new\nnodes to explore after.",
    "start": "2052790",
    "end": "2060349"
  },
  {
    "text": "Yeah, so the question was,\nhow are you ever going to extend and really explore\nthe space because you're only",
    "start": "2060350",
    "end": "2065869"
  },
  {
    "text": "going to extend the ones that\nare closest to the goal state. Well, so in this case, we just\nsampled a random goal state.",
    "start": "2065870",
    "end": "2071399"
  },
  {
    "text": "So it happened to be here. But if we had sampled a goal\nstate that, for example, was like right here, we would end\nup selecting the root node",
    "start": "2071400",
    "end": "2077388"
  },
  {
    "text": "to extend. And so then we would\nextend this node. So we can actually--\nwe'll end up extending-- we could extend\nany of these nodes",
    "start": "2077389",
    "end": "2083960"
  },
  {
    "text": "depending on where the\ngoal state got sampled. So generally the nodes,\nthere's additional nodes",
    "start": "2083960",
    "end": "2091310"
  },
  {
    "text": "that pop up after the fact,\nusually, where that's, I guess--",
    "start": "2091310",
    "end": "2097340"
  },
  {
    "text": "Like in the extended step? Yeah, so I guess like\nwhen we extended it, usually isn't it that\nthere's additional notes that",
    "start": "2097340",
    "end": "2105180"
  },
  {
    "text": "kind of pop up from that space? Yeah, so when we extended this\nnode, this node popped up.",
    "start": "2105180",
    "end": "2112920"
  },
  {
    "text": "[INAUDIBLE] No, no, no. So the question was, does\nit start from here now?",
    "start": "2112920",
    "end": "2119369"
  },
  {
    "text": "Do we like just decide this\nnode is like the next one we're going to do? No. So we repeat this process. So this is our new tree.",
    "start": "2119370",
    "end": "2125440"
  },
  {
    "text": "We're going to go back\nto the Select step. We're going to\nsample a goal state. And we're going to now\nconsider all of these nodes",
    "start": "2125440",
    "end": "2131340"
  },
  {
    "text": "and decide which one\nwe want to extend next. Yeah. Yeah, can you make some\nnormative statements",
    "start": "2131340",
    "end": "2139170"
  },
  {
    "text": "about what we want the\nobjective to look like and what the goal state to be?",
    "start": "2139170",
    "end": "2144420"
  },
  {
    "text": "Like-- In general, you mean? Sorry? Like in general? Yeah, what are-- make\nsome normative statements",
    "start": "2144420",
    "end": "2149970"
  },
  {
    "text": "about what's the point? Like what are these things? What is the point. Good question.",
    "start": "2149970",
    "end": "2156660"
  },
  {
    "text": "So the goal state, I'm\ngoing to show in a second, be kind of nice\nif our goal state was right here, because we're\ntrying to find a failure.",
    "start": "2156660",
    "end": "2163380"
  },
  {
    "text": "So that's where\nwe're heading here. But in general, for\nRRT, just if your goal is to just explore the\nspace as much as possible,",
    "start": "2163380",
    "end": "2170099"
  },
  {
    "text": "you want to sample\nyour goal state from all over the place,\nanywhere in your state space. But then for computing\nthe objective,",
    "start": "2170100",
    "end": "2176490"
  },
  {
    "text": "your goal state is\nnow the new goal that you're trying to get to. And so your objective\nshould be something such",
    "start": "2176490",
    "end": "2182270"
  },
  {
    "text": "that the nodes you extend will\nget you close to that goal. So why isn't something like\nEuclidean distance almost",
    "start": "2182270",
    "end": "2188305"
  },
  {
    "text": "[INAUDIBLE]? Well, sometimes we're\nnot in a scenario where it's like a continuum\nworld and Euclidean",
    "start": "2188305",
    "end": "2195319"
  },
  {
    "text": "distance might not\nhave an actual meaning. Yeah. In this case, Euclidean\ndistance typically makes sense.",
    "start": "2195320",
    "end": "2201780"
  },
  {
    "text": "OK.  Any other questions? So what we're going\nto do is are we",
    "start": "2201780",
    "end": "2208580"
  },
  {
    "text": "going to be the S [INAUDIBLE]\ndimensional space and then",
    "start": "2208580",
    "end": "2213740"
  },
  {
    "text": "the objective function,\nmeaning like the one that we discussed\nearlier for trajectory, we're going to do that somehow?",
    "start": "2213740",
    "end": "2221340"
  },
  {
    "text": "We will get to objective\nfunctions in a second. So right now we're\nnot really assuming there's any objective other\nthan finding a failure.",
    "start": "2221340",
    "end": "2227170"
  },
  {
    "text": "And really, with rapidly\nexploring random trees, the way I've presented\nit right now, the objective we're\nkind of optimizing",
    "start": "2227170",
    "end": "2233520"
  },
  {
    "text": "is just explore the space\nof possible trajectories for the most part. And we're just hoping that we\nmight stumble upon a failure.",
    "start": "2233520",
    "end": "2241170"
  },
  {
    "text": "So just on that\nnote, here's what the algorithm might look like,\nstarting from the beginning.",
    "start": "2241170",
    "end": "2247242"
  },
  {
    "text": "So at every iteration,\nyou're going to see a sample of goal state\nand extend the tree outward towards that goal state.",
    "start": "2247242",
    "end": "2252496"
  },
  {
    "text": "But the goal state gets\nsampled from a whole bunch of different places. And so we extend different\nnodes and build out this tree.",
    "start": "2252497",
    "end": "2260180"
  },
  {
    "text": " So here's what it looked like. I think this is like\n100 or so iterations.",
    "start": "2260180",
    "end": "2268320"
  },
  {
    "text": "But you might be thinking, OK,\nso we did explore the space. You look like you're deciding.",
    "start": "2268320",
    "end": "2276150"
  },
  {
    "text": "Why we got so lucky as\nto always not hit the red and always hit the green? Like we are trending\ntowards the green",
    "start": "2276150",
    "end": "2282042"
  },
  {
    "text": "and also not hitting the red. Yeah, yeah, that's\na good observation. It simply should not emerge. Oh, yeah, so it seems like this\nis random, but what's going on",
    "start": "2282042",
    "end": "2289510"
  },
  {
    "text": "is when I sampled, maybe I\ndidn't fully explain this, but when I sampled-- when\nwe select the disturbance,",
    "start": "2289510",
    "end": "2295820"
  },
  {
    "text": "I'm sampling from the nominal\ndisturbance distribution. So when we want to\ngo up here, we're",
    "start": "2295820",
    "end": "2302260"
  },
  {
    "text": "more likely to get disturbances\nthat actually do lead us up. So we're going to end up\ngetting trajectories or a tree",
    "start": "2302260",
    "end": "2307569"
  },
  {
    "text": "that kind of moves\nin the way that we expect the system to with these\nrandomly sampled disturbances.",
    "start": "2307570",
    "end": "2313119"
  },
  {
    "text": "So that's already learned. The system is already like\ntrying to get to this. Yeah, the system is trained\nto try to get to green,",
    "start": "2313120",
    "end": "2320180"
  },
  {
    "text": "and we're trying\nto find scenarios where it might get to the red. Yeah. But so we did explore the\nspace, but this didn't quite",
    "start": "2320180",
    "end": "2327277"
  },
  {
    "text": "work because we didn't\nactually find any failures. So like I said,\nwe were just kind of trying to explore\nthe space as much as possible, the space of possible\ntrajectories, and in hopes",
    "start": "2327277",
    "end": "2335532"
  },
  {
    "text": "that we might find a failure. But we didn't. So one thing we could do is we\ncould just run this for longer",
    "start": "2335532",
    "end": "2341070"
  },
  {
    "text": "and hope that we\ndo find a failure. But we could probably be a\nlittle bit smarter about this.",
    "start": "2341070",
    "end": "2346329"
  },
  {
    "text": "And instead, we'll just try\nto make some improvements to our algorithm.",
    "start": "2346330",
    "end": "2351990"
  },
  {
    "text": "So we already kind of\nalluded to one improvement. And that's in the Select step.",
    "start": "2351990",
    "end": "2357192"
  },
  {
    "text": "So before, we were\njust kind of sampling from the entire space\nof possible states at every single iteration\nin order to sample our goal.",
    "start": "2357193",
    "end": "2365670"
  },
  {
    "text": "So we could just get a\ngoal kind of anywhere. But we know what\nour goal is like. We're trying to find a failure.",
    "start": "2365670",
    "end": "2371890"
  },
  {
    "text": "So why not just sample\nstates from the goal state",
    "start": "2371890",
    "end": "2377220"
  },
  {
    "text": "or from the failure region-- sample goal states\nfrom the failure region every single time rather\nthan this entire space.",
    "start": "2377220",
    "end": "2384250"
  },
  {
    "text": "So that's kind of\none improvement that we can very quickly make. And so we'll just say instead\nof sampling goal states from all",
    "start": "2384250",
    "end": "2390000"
  },
  {
    "text": "over, we'll just always\nsample a goal state in the failure region. Why didn't we just\ndo this off the bat?",
    "start": "2390000",
    "end": "2396620"
  },
  {
    "text": "Well, it is the case that not\nall systems have an easily identifiable failure reason.",
    "start": "2396620",
    "end": "2401990"
  },
  {
    "text": "So like I said, like Euclidean\ndistance makes sense here. This continuum world is\nlike a really nice problem to demonstrate all\nof these things on.",
    "start": "2401990",
    "end": "2408320"
  },
  {
    "text": "But in other\nscenarios, it might not be so obvious like what\nis the region of states that represent a failure.",
    "start": "2408320",
    "end": "2413960"
  },
  {
    "text": "Especially when there's\ntemporal properties involved, you might not be able to\nsay, if I get to this state, it's like for sure a failure.",
    "start": "2413960",
    "end": "2421000"
  },
  {
    "text": "And so we can't always do this. But in cases where we can,\nthis can make our algorithm perform quite a bit better.",
    "start": "2421000",
    "end": "2426630"
  },
  {
    "text": " And then secondly, in the Extend\nstep, so we did talk about--",
    "start": "2426630",
    "end": "2431891"
  },
  {
    "text": "I was just kind of\nsampling a disturbance from the nominal\ntrajectory distribution. So the only thing we were\ndoing to incorporate our goal",
    "start": "2431892",
    "end": "2439150"
  },
  {
    "text": "was selecting a node that\nwas near the goal to extend. But we then were just\npicking any disturbance.",
    "start": "2439150",
    "end": "2444407"
  },
  {
    "text": "So we weren't really\npicking a disturbance to try to steer us\ntowards the goal. So we could add that in.",
    "start": "2444407",
    "end": "2449650"
  },
  {
    "text": "So let's zoom in on this kind\nof lower left corner here. And let's say that, for\nexample, is our goal,",
    "start": "2449650",
    "end": "2455289"
  },
  {
    "text": "and this is the particular node\nthat we're going to extend. What we could do is we could try\nto sample the disturbance that",
    "start": "2455290",
    "end": "2461640"
  },
  {
    "text": "would get us as close as we\npossibly can to this goal. So what we might do is sample--",
    "start": "2461640",
    "end": "2466968"
  },
  {
    "text": "one way to do this\nwould be to sample a whole bunch of\ndisturbances, and then pick the one that\ngot us the closest",
    "start": "2466968",
    "end": "2472470"
  },
  {
    "text": "to extend for the next step. ",
    "start": "2472470",
    "end": "2477940"
  },
  {
    "text": "Question? Yeah. I just [INAUDIBLE] So when we\ntry to find pathways that are",
    "start": "2477940",
    "end": "2488400"
  },
  {
    "text": "most likely to get from-- or\nmost likely type of failures to happen, isn't that the--",
    "start": "2488400",
    "end": "2493964"
  },
  {
    "text": "Great question. So the question was,\nwere we trying to find the most likely failure.",
    "start": "2493965",
    "end": "2499440"
  },
  {
    "text": "In the previous lecture, when\nwe were doing the optimization, that was an option\nfor the objective, and that's generally a\ngood objective to use.",
    "start": "2499440",
    "end": "2506140"
  },
  {
    "text": "That's typically\nwhat we want to find. What I've presented so far\nis not using that objective.",
    "start": "2506140",
    "end": "2512963"
  },
  {
    "text": "But in a little bit,\nwe're going to talk about how we actually could.",
    "start": "2512963",
    "end": "2518109"
  },
  {
    "text": "Any other questions on this?  Yep.",
    "start": "2518110",
    "end": "2524350"
  },
  {
    "text": "So this isn't generally the\nmost likely failure trajectory.",
    "start": "2524350",
    "end": "2531560"
  },
  {
    "text": "We're just trying to manipulate\nour searches so that they're constrained to minimize\nthe overall space that we",
    "start": "2531560",
    "end": "2540790"
  },
  {
    "text": "have to look over? Yeah, so you can\nthink of our objective right now as just\nwe're just trying to find any failure\nthat we possibly can.",
    "start": "2540790",
    "end": "2547910"
  },
  {
    "text": "Yeah. Yeah. So for the disturbance,\nare we always selecting",
    "start": "2547910",
    "end": "2555190"
  },
  {
    "text": "disturbances that we measure\na distance to the goal state and we just go there?",
    "start": "2555190",
    "end": "2562517"
  },
  {
    "text": "For this particular-- For this particular one. --case, yeah. We would just--\nWell, so really what",
    "start": "2562518",
    "end": "2568330"
  },
  {
    "text": "our goal is to pick the\ndisturbance that would get us closest to the goal state of all\npossible disturbances we could",
    "start": "2568330",
    "end": "2573950"
  },
  {
    "text": "choose from. One way to do that is to\nsample a bunch of disturbances and pick the one that\ngets us the closest.",
    "start": "2573950",
    "end": "2579150"
  },
  {
    "text": "We could try some\nfancier like optimization to actually try to\nfind that disturbance. But in this case, we're simply\njust sampling [INAUDIBLE]?",
    "start": "2579150",
    "end": "2586579"
  },
  {
    "text": "Yeah, exactly. And you can imagine, the\nmore samples we take, more computational expense,\nbut the better we'll get.",
    "start": "2586580",
    "end": "2592789"
  },
  {
    "text": "So there's that trade off. Yeah. ",
    "start": "2592790",
    "end": "2598630"
  },
  {
    "text": "Cool. So now we've made those\ntwo modifications. And you can see the algorithm\nruns much more efficiently.",
    "start": "2598630",
    "end": "2604710"
  },
  {
    "text": "And we're able to\nfind a failure. And we're able to find\nit pretty quickly. ",
    "start": "2604710",
    "end": "2610849"
  },
  {
    "text": "OK, we found a failure. So that's two very\ncommon extensions,",
    "start": "2610850",
    "end": "2615890"
  },
  {
    "text": "very easy things to tweak\nto make the algorithm run a little bit better. There's a few other common\nheuristics that people use.",
    "start": "2615890",
    "end": "2624410"
  },
  {
    "text": "One is coverage metrics. So we actually alluded to these\na little bit in the last class when we were talking about\nhow do we know when to stop.",
    "start": "2624410",
    "end": "2631778"
  },
  {
    "text": "And so one thing you might\nwant to do when you're kind of making\nthese random trees is you might want to explore the\nspace of possible trajectories",
    "start": "2631778",
    "end": "2638619"
  },
  {
    "text": "like truly, as much as possible. And so one thing you could do\nis actually use coverage metrics",
    "start": "2638620",
    "end": "2643990"
  },
  {
    "text": "to guide the search. So you could-- in this\ncase, your objective is explore the space\nas much as possible.",
    "start": "2643990",
    "end": "2649730"
  },
  {
    "text": "And there's these metrics\ncalled dispersion. And I think we talked\nabout another one called star discrepancy\nin the book, that",
    "start": "2649730",
    "end": "2656560"
  },
  {
    "text": "allow you to understand\nhow well you've covered the space of possible\nstates, and then",
    "start": "2656560",
    "end": "2664330"
  },
  {
    "text": "use that to select the next node\nto extend or to do the Extend step.",
    "start": "2664330",
    "end": "2669760"
  },
  {
    "text": "And then, for example, when we\nuse coverage metrics like this,",
    "start": "2669760",
    "end": "2676000"
  },
  {
    "text": "we can measure the growth\nof this coverage over time. So here we're\nplotting, for example,",
    "start": "2676000",
    "end": "2681020"
  },
  {
    "text": "as we run the tree\nsearch algorithm, the result of some\ncoverage metric over time. And you can see it kind of\nstarts to plateau at the end",
    "start": "2681020",
    "end": "2688349"
  },
  {
    "text": "here. And so you can imagine when\nour coverage isn't growing much anymore, our tree is not\nreally changing much anymore.",
    "start": "2688350",
    "end": "2694260"
  },
  {
    "text": "And so we can say\nlike, maybe that's a good time to terminate\nthe tree search algorithm. So there's no guarantees here. There still might be spaces\nwe haven't explored or haven't",
    "start": "2694260",
    "end": "2702660"
  },
  {
    "text": "found. But this is kind of one way that\nwe could make that decision.",
    "start": "2702660",
    "end": "2707730"
  },
  {
    "text": "Unfortunately, we\ndon't really have time to actually dig into these for\nthis iteration of the class",
    "start": "2707730",
    "end": "2713070"
  },
  {
    "text": "anyway. But if you're interested,\nit's all in the book. We have nice implementations\nof these things.",
    "start": "2713070",
    "end": "2718720"
  },
  {
    "text": "And I think it's a really cool\ntopic, so definitely check it out if you're interested.",
    "start": "2718720",
    "end": "2723870"
  },
  {
    "text": "The second common heuristic,\nwhich I think a lot of you have already been\nasking about, we're",
    "start": "2723870",
    "end": "2729240"
  },
  {
    "text": "going to dive into, which\nis alternative objectives. So before, we were just kind\nof trying to explore the space. Now can we actually\nincorporate those objectives",
    "start": "2729240",
    "end": "2736470"
  },
  {
    "text": "we had last time where we wanted\nto find the most likely failure or, for example, maybe we\nwant to find the shortest",
    "start": "2736470",
    "end": "2741960"
  },
  {
    "text": "path to a failure, how do we\ngo about incorporating those.",
    "start": "2741960",
    "end": "2748109"
  },
  {
    "text": "OK, and so the way that we do\nthis, kind of maybe no surprise, is we can incorporate\nalternative objectives",
    "start": "2748110",
    "end": "2754770"
  },
  {
    "text": "when we do that kind of compute\nobjective step in the Select step. So if you remember,\nwe had the Select step",
    "start": "2754770",
    "end": "2761250"
  },
  {
    "text": "and we had some\ngoal state, and then we were computing an objective\nfor each node in the tree",
    "start": "2761250",
    "end": "2766900"
  },
  {
    "text": "based on this goal state. We can change how we compute\nthis objective in order",
    "start": "2766900",
    "end": "2772320"
  },
  {
    "text": "to incorporate\nalternative objectives. ",
    "start": "2772320",
    "end": "2779250"
  },
  {
    "text": "OK, so from before,\nfor example, we had this goal state here\nmaybe in the failure region.",
    "start": "2779250",
    "end": "2785260"
  },
  {
    "text": "And when we were deciding to\nextend this particular node, we realized that it\nwas just the closest",
    "start": "2785260",
    "end": "2790470"
  },
  {
    "text": "to this possible\nto this goal state. And now what we're\ngoing to do instead",
    "start": "2790470",
    "end": "2796470"
  },
  {
    "text": "is we're going to specify\nthis cost function. And the cost function\nconsists of two things.",
    "start": "2796470",
    "end": "2802270"
  },
  {
    "text": "So the first thing\nthat it consists of is something that we'll\ncall the current cost. And that's basically the cost\nit required to get to the node",
    "start": "2802270",
    "end": "2809960"
  },
  {
    "text": "that we're currently at. So it's like this kind of cost\nthat we have so far to get here.",
    "start": "2809960",
    "end": "2815615"
  },
  {
    "text": "And then the second part\nof the cost function is kind of the cost to go. But there's one\nproblem with this part",
    "start": "2815615",
    "end": "2822440"
  },
  {
    "text": "of the cost function, which\nis that we don't really know the cost to go. Like maybe the path goes\nlike this to get there,",
    "start": "2822440",
    "end": "2827970"
  },
  {
    "text": "or maybe the path goes\nlike this to get there. We don't really\nknow what's left. Because if we knew\nwhat was left, we would have already\nsolved the problem",
    "start": "2827970",
    "end": "2834347"
  },
  {
    "text": "because we'd already know how to\nget to where we're trying to go. And so that's kind of the issue.",
    "start": "2834347",
    "end": "2840120"
  },
  {
    "text": "We don't know this. And so what we\ntypically do is instead we try to estimate it using some\nheuristic function that we'll",
    "start": "2840120",
    "end": "2847010"
  },
  {
    "text": "call H. So for\nexample, in this case, one heuristic\nfunction we might use is just the Euclidean distance\nbetween our current state",
    "start": "2847010",
    "end": "2854510"
  },
  {
    "text": "and the goal state. And that's kind\nof our cost to go. ",
    "start": "2854510",
    "end": "2859940"
  },
  {
    "text": "So for example, if we now\nwant to find the shortest path to failure,\nour current cost",
    "start": "2859940",
    "end": "2865440"
  },
  {
    "text": "would just be the distance to\nthe current node in the tree. So this pink part here.",
    "start": "2865440",
    "end": "2871680"
  },
  {
    "text": "And then our cost to go would\nmaybe just be the distance to the goal as the crow flies. So just whatever the most\ndirect path to the goal is,",
    "start": "2871680",
    "end": "2879340"
  },
  {
    "text": "what is that distance. And we'll add those together. So then we would compute this\nfor all of our different nodes",
    "start": "2879340",
    "end": "2886710"
  },
  {
    "text": "in the tree. And then pick the smallest\none to extend next.",
    "start": "2886710",
    "end": "2893530"
  },
  {
    "text": "So looking at this, it's\na little bit hard to tell, but does anyone have\nany guesses of which one we would extend next?",
    "start": "2893530",
    "end": "2899733"
  },
  {
    "text": " I heard six, yeah.",
    "start": "2899733",
    "end": "2905040"
  },
  {
    "text": "Number six. Number six. Yeah, number six. So it's kind of hard\nto tell, but this is like if we add the\npink and the purple,",
    "start": "2905040",
    "end": "2911980"
  },
  {
    "text": "the 6 will be the lowest one. So because you can imagine one\nlooks like it's kind of close, but it kind of had to go\nback and forth like this.",
    "start": "2911980",
    "end": "2919180"
  },
  {
    "text": "So we would actually extend\nnumber six next based on this cost function.",
    "start": "2919180",
    "end": "2924910"
  },
  {
    "text": "OK, so that was if we want\nthe shortest path to failure. But now as many of\nyou have been wanting",
    "start": "2924910",
    "end": "2930700"
  },
  {
    "text": "to know, how do we find\nthe most likely failure. So for most likely\nfailure, our current cost",
    "start": "2930700",
    "end": "2938500"
  },
  {
    "text": "is just going to be the negative\nlog likelihood of the trajectory so far. So remember we need\na cost, something",
    "start": "2938500",
    "end": "2944350"
  },
  {
    "text": "that we want to minimize. So we need the negative\nlog likelihood for this.",
    "start": "2944350",
    "end": "2950710"
  },
  {
    "text": "And one note here\nis that costs must be positive to ensure that\nthe search will terminate.",
    "start": "2950710",
    "end": "2956630"
  },
  {
    "text": "So if costs were negative and\nwe're trying to minimize cost, then we could just go in circles\nforever, kind of that boat",
    "start": "2956630",
    "end": "2962680"
  },
  {
    "text": "was in that one game we saw. We could just go in circles\nforever and continue to minimize our cost.",
    "start": "2962680",
    "end": "2968030"
  },
  {
    "text": "So we need to make sure\nthat costs are positive so that we will actually encourage\nthe search to terminate.",
    "start": "2968030",
    "end": "2974950"
  },
  {
    "text": "But the problem here is\nat negative log likelihood might in fact be negative. And so we have this issue\nwhere we need to make sure",
    "start": "2974950",
    "end": "2982290"
  },
  {
    "text": "that this is positive. So we just add on some constant\ntypically maybe the highest log",
    "start": "2982290",
    "end": "2988140"
  },
  {
    "text": "likelihood you could\nhave so that all of them will be positive. You just need to\nbasically make sure",
    "start": "2988140",
    "end": "2993490"
  },
  {
    "text": "that you're never going to\nhave any negative costs. And then finally,\nthe cost to go is",
    "start": "2993490",
    "end": "3000036"
  },
  {
    "text": "we're going to need some\nway to basically estimate the negative log likelihood\nthat we have left.",
    "start": "3000037",
    "end": "3005570"
  },
  {
    "text": "So there's various\nways to do this. There's no kind of super\nstraightforward obvious way. But one thing you could\ndo is you could just",
    "start": "3005570",
    "end": "3011660"
  },
  {
    "text": "say like, well, the\ndistance to goal is a proxy for this\nnegative log likelihood,",
    "start": "3011660",
    "end": "3016740"
  },
  {
    "text": "because shorter paths tend to\nhave higher likelihood, just",
    "start": "3016740",
    "end": "3022010"
  },
  {
    "text": "because it's probably unlikely\nthat it's kind of going around all over like this\nand then gets to the goal and this is going to\nbe a more likely path.",
    "start": "3022010",
    "end": "3030140"
  },
  {
    "text": "Again, this is just a heuristic. So it's just something we're\nusing to help guide the search. So it's not an issue\nif it's totally wrong.",
    "start": "3030140",
    "end": "3036930"
  },
  {
    "text": "But we just need something\nthat's kind of close. Any questions on this?",
    "start": "3036930",
    "end": "3042869"
  },
  {
    "text": "Yeah. I'm still confused about this. The requirement for\nthis plus C since I",
    "start": "3042870",
    "end": "3049860"
  },
  {
    "text": "would think the negative\nlog likelihood is--",
    "start": "3049860",
    "end": "3055740"
  },
  {
    "text": "Is it unbounded in\nthe minus direction?",
    "start": "3055740",
    "end": "3062250"
  },
  {
    "text": "I guess it depends on\nwhat distribution you're sampling from. So in a lot of cases, you know\nkind of the bounds for it.",
    "start": "3062250",
    "end": "3070984"
  },
  {
    "start": "3070985",
    "end": "3076260"
  },
  {
    "text": "I guess I'm a bit confused\nbecause the concern is that we might find a loop\nin our trajectories, which",
    "start": "3076260",
    "end": "3083880"
  },
  {
    "text": "minimizes our cost. But I think since our cost is-- we're trying to maximize\nour likelihood by minimizing",
    "start": "3083880",
    "end": "3091440"
  },
  {
    "text": "our cost, there must\nbe a lower bound, because our likelihood\ncan't be, or I guess our probability\ncan't be higher than 1.",
    "start": "3091440",
    "end": "3098350"
  },
  {
    "text": "Yeah, well, probability\ndensity can be higher than 1,",
    "start": "3098350",
    "end": "3103810"
  },
  {
    "text": "because the probability density\nis not an actual probability. But if you know,\nfor example, I'm",
    "start": "3103810",
    "end": "3109599"
  },
  {
    "text": "sampling from a\nGaussian distribution for my disturbances,\nthen you can get a bound on how big the log\nlikelihood could get,",
    "start": "3109600",
    "end": "3117970"
  },
  {
    "text": "how big that density\ncould get, and then you could just add on a constant\nto make sure that you're always going to be positive.",
    "start": "3117970",
    "end": "3125109"
  },
  {
    "text": "OK, yeah.  Yeah, I wouldn't worry too\nmuch about the details here.",
    "start": "3125110",
    "end": "3132295"
  },
  {
    "text": "If you were actually\ngoing about implementing this, which we did for some\nof the figures in the book. That's where we\ndiscovered this issue.",
    "start": "3132295",
    "end": "3137840"
  },
  {
    "text": "And it's basically you\njust need to bump it up to make sure that your\nsearch will terminate.",
    "start": "3137840",
    "end": "3145599"
  },
  {
    "text": "Cool. So here's what it\nlooks like with both of these different\ncost functions.",
    "start": "3145600",
    "end": "3150635"
  },
  {
    "text": "So we talked about\nshortest paths to failure. When we run this, we'll get\na path that kind of just goes directly to the obstacle.",
    "start": "3150635",
    "end": "3156672"
  },
  {
    "text": "But this might not\nbe super likely, because we're going to sample\na bunch of disturbances that are kind of maybe quite large. They're not very\nlikely to happen.",
    "start": "3156672",
    "end": "3163890"
  },
  {
    "text": "And then what's shown\nhere also in white is the nominal\npath that the agent",
    "start": "3163890",
    "end": "3168960"
  },
  {
    "text": "would take if we had\nno disturbances at all. And then if we look at what's\nthe result of finding the most",
    "start": "3168960",
    "end": "3175410"
  },
  {
    "text": "likely failure\nusing this method, we get something that stays\nmuch closer to the nominal path and just kind of deviates at the\nend and falls into the obstacle.",
    "start": "3175410",
    "end": "3183005"
  },
  {
    "text": " Yeah.",
    "start": "3183005",
    "end": "3189140"
  },
  {
    "text": "Can you go over again how we\nwould estimate the negative log likelihood of the places to\ngo, since we haven't actually",
    "start": "3189140",
    "end": "3196200"
  },
  {
    "text": "gone there yet? But is it just that we\nhave a general sense of the cost for every\nsingle path to get there?",
    "start": "3196200",
    "end": "3203579"
  },
  {
    "text": "Yeah, so the question is\nlike, can I go over again how we estimate the negative\nlog likelihood to go. So it's kind of\ndifficult to get right.",
    "start": "3203580",
    "end": "3211450"
  },
  {
    "text": "So if you're this far\naway from the obstacle,",
    "start": "3211450",
    "end": "3216670"
  },
  {
    "text": "one thing you could do\nis just say like, OK, I'm this distance away, and\nyou can use distance",
    "start": "3216670",
    "end": "3222130"
  },
  {
    "text": "almost as a proxy\nfor likelihood, because the more time steps that\nyou're kind of moving around, the more time steps\nyou're accumulating",
    "start": "3222130",
    "end": "3228400"
  },
  {
    "text": "these samples of disturbances,\nand so the lower your likelihood is going to be.",
    "start": "3228400",
    "end": "3234619"
  },
  {
    "text": "And so you can of say ones\nthat are closer to the goal will have a lower\nlog likelihood to go.",
    "start": "3234620",
    "end": "3241730"
  },
  {
    "text": "And that's just a proxy. There's other ways that you\ncould try to estimate it. For example, you could do\na whole bunch of rollouts",
    "start": "3241730",
    "end": "3246790"
  },
  {
    "text": "and try to look at the log\nlikelihood of those rollouts and look at what was to go.",
    "start": "3246790",
    "end": "3252009"
  },
  {
    "text": "Yeah. I guess the question\nis like, what's the difference between--\nbecause you use distance as a heuristic for the\nshortest path to failure.",
    "start": "3252010",
    "end": "3258859"
  },
  {
    "text": "So like why can we use distance\nagain for the likelyhood? So again, these are just\nheuristics to guide the search.",
    "start": "3258860",
    "end": "3268820"
  },
  {
    "text": "So it might not perform as\nwell as if we could actually--",
    "start": "3268820",
    "end": "3274100"
  },
  {
    "text": "It's probably a better proxy\nhere because these two things match. Here it might not\nperform as well,",
    "start": "3274100",
    "end": "3280830"
  },
  {
    "text": "but we're using it as a\nproxy for this one as well. But for the current cost, we can\nactually use the negative log likelihood.",
    "start": "3280830",
    "end": "3286380"
  },
  {
    "text": "So that will make a difference. ",
    "start": "3286380",
    "end": "3293630"
  },
  {
    "text": "Yeah, but maybe-- Yeah, this is the part where\nyou would take advantage",
    "start": "3293630",
    "end": "3298910"
  },
  {
    "text": "of any kind of domain expertise\nthat many domains don't have the natural definition\nof distance here.",
    "start": "3298910",
    "end": "3307700"
  },
  {
    "text": "Yeah, just to repeat that,\nMichael was noting that in this case, or\nin lots of cases, like we would just need to use\ndomain expertise to design all",
    "start": "3307700",
    "end": "3315320"
  },
  {
    "text": "of these various heuristics,\nbecause sometimes like distance isn't even like\nan obvious thing or something",
    "start": "3315320",
    "end": "3320690"
  },
  {
    "text": "that we would talk about\nin a particular domain. Everything's just very clear in\nthis continuum world, which is why we used it as an example.",
    "start": "3320690",
    "end": "3327030"
  },
  {
    "text": "But in general, this might\nnot always be so obvious. ",
    "start": "3327030",
    "end": "3332440"
  },
  {
    "text": "Good questions. All right.",
    "start": "3332440",
    "end": "3337840"
  },
  {
    "text": "OK, so just one more\nnote on all of this. It turns out that if the\nheuristic is something",
    "start": "3337840",
    "end": "3344950"
  },
  {
    "text": "that we call admissible, and the\nstate space and the disturbance space are both discrete,\nthen this algorithm",
    "start": "3344950",
    "end": "3352720"
  },
  {
    "text": "turns into A star search,\nwhich is kind of cool. So some of you may have\nheard of A star, what",
    "start": "3352720",
    "end": "3358690"
  },
  {
    "text": "does it mean for a\nheuristic to be admissible. It's admissible\nif it's guaranteed",
    "start": "3358690",
    "end": "3363910"
  },
  {
    "text": "to never overestimate the cost\nof reaching the goal state. So again, kind of\nMichael was saying,",
    "start": "3363910",
    "end": "3369830"
  },
  {
    "text": "this takes domain\nknowledge to design. And it's not always easy to\ndesign a heuristic for which this property is true.",
    "start": "3369830",
    "end": "3376190"
  },
  {
    "text": "But let's look at\nthe Gridworld example now because we need our\nstate and disturbance space to be discrete.",
    "start": "3376190",
    "end": "3381829"
  },
  {
    "text": "So we're going to switch\nto a discrete problem here. And we can think about what\nan admissible heuristic might look like here.",
    "start": "3381830",
    "end": "3387710"
  },
  {
    "text": "So let's imagine that this\nis the node that we need to estimate the cost to go for.",
    "start": "3387710",
    "end": "3392960"
  },
  {
    "text": "A very common\nadmissible heuristic to use this distance\nas the crow flies,",
    "start": "3392960",
    "end": "3398309"
  },
  {
    "text": "so the Euclidean distance\nbetween the state we're at and the state that\nwe're trying to get to.",
    "start": "3398310",
    "end": "3404599"
  },
  {
    "text": "And the reason that we know\nthat this is admissible is because it will never be\ngreater than the actual cost",
    "start": "3404600",
    "end": "3410445"
  },
  {
    "text": "of reaching the goal state. So we know from here we\ncan't actually do this, because in the grid\nworld, we're only",
    "start": "3410445",
    "end": "3415700"
  },
  {
    "text": "allowed to move in these\ndiscrete directions between cells. So the shortest path is\nactually going to be like that.",
    "start": "3415700",
    "end": "3423320"
  },
  {
    "text": "And so we know that this\nby the laws of triangles is always going to be smaller.",
    "start": "3423320",
    "end": "3429110"
  },
  {
    "text": "And so similarly, this is\nthe case from any state that we encounter. And so the Euclidean distance\nis an admissible heuristic here.",
    "start": "3429110",
    "end": "3438770"
  },
  {
    "text": "And then this turns into\nthe A star search algorithm, which means that\nwe're guaranteed to find the optimal path.",
    "start": "3438770",
    "end": "3446369"
  },
  {
    "text": "So in RRT, we were just\nkind of encouraging it too, we were hoping to find\nthese good paths to failure.",
    "start": "3446370",
    "end": "3451510"
  },
  {
    "text": "There was no guarantees\ninvolved there. When we have these\nspecific conditions, we're actually able to\nguarantee that we'll",
    "start": "3451510",
    "end": "3457980"
  },
  {
    "text": "find the shortest path or\nthe most likely failure. So here's what that looks\nlike for the grid world, the shortest path just kind\nof goes right to the obstacle.",
    "start": "3457980",
    "end": "3465267"
  },
  {
    "text": "And then the most likely failure\nstays along the nominal path until it kind of dips\ndown at the very end.",
    "start": "3465267",
    "end": "3471319"
  },
  {
    "start": "3471320",
    "end": "3477600"
  },
  {
    "text": "Yeah. [INAUDIBLE] intuitive\nreason to understand",
    "start": "3477600",
    "end": "3483060"
  },
  {
    "text": "the why it shouldn't\noverestimate the cost of reaching the goals.",
    "start": "3483060",
    "end": "3488807"
  },
  {
    "text": "OK, hopefully I'm not going\nto butcher this answer because it's been a while\nsince I've looked at A star. But so the question\nwas, is there",
    "start": "3488807",
    "end": "3493955"
  },
  {
    "text": "an intuitive reason for why\nit can't overestimate it. Typically, when you're\ndoing A star search, you prioritize certain\nnodes on top of others,",
    "start": "3493955",
    "end": "3501312"
  },
  {
    "text": "and you need to\nmake sure that it's going to be prioritized\nin the right order. Did I say that right?",
    "start": "3501312",
    "end": "3507470"
  },
  {
    "text": "You get a guarantee of sounding\ncompleteness if it's admissible. Yeah, but the intuition\nfor why that's the case.",
    "start": "3507470",
    "end": "3515070"
  },
  {
    "text": "Yeah. OK. So I would recommend-- We're not really going to\nget into it in this class, but I would recommend\nchecking out",
    "start": "3515070",
    "end": "3520357"
  },
  {
    "text": "there's some really nice YouTube\nvideos on like A star search. And I think it will\nbecome pretty clear why all this fits together.",
    "start": "3520357",
    "end": "3526735"
  },
  {
    "text": " This is kind of funny\nbecause I honestly",
    "start": "3526735",
    "end": "3533359"
  },
  {
    "text": "didn't think we'd get this far. And so when I was looking\nthrough my slides last night, I only went up to here.",
    "start": "3533360",
    "end": "3538830"
  },
  {
    "text": "And then I told my husband,\nif we got this far, I was going to be doing\nslideshow karaoke, which is when you have a\nslideshow and you",
    "start": "3538830",
    "end": "3544460"
  },
  {
    "text": "don't know what's coming next. So here you go. [LAUGHTER] All right, now we're going\nto talk about something",
    "start": "3544460",
    "end": "3551810"
  },
  {
    "text": "called Monte Carlo tree search. So we try to balance--",
    "start": "3551810",
    "end": "3557150"
  },
  {
    "text": "So what's cool about Monte Carlo\ntree search kind of beyond RRT",
    "start": "3557150",
    "end": "3562339"
  },
  {
    "text": "is that we have\nthis explicit way to balance between\nexploration and exploitation. So the idea here is\nthat we want to explore",
    "start": "3562340",
    "end": "3569880"
  },
  {
    "text": "the space of possible\ntrajectories, but we also know\nthat there-- are after we do some\nexploration, we know that there's some\ntrajectories that are more",
    "start": "3569880",
    "end": "3576059"
  },
  {
    "text": "likely to lead us to failure. And so we want to also be able\nto exploit that knowledge.",
    "start": "3576060",
    "end": "3582000"
  },
  {
    "text": "And we'll do this by\ndetermining promising paths, by maintaining a value estimate\nfor each node in the tree.",
    "start": "3582000",
    "end": "3589900"
  },
  {
    "text": "And we're going to call\nthis value estimate Q. And just to avoid any confusion\noff the bat, in other classes,",
    "start": "3589900",
    "end": "3598810"
  },
  {
    "text": "for example, if you\ntook AA228, we're often trying to\nmaximize our value just to keep it consistent with\nall the costs that we've",
    "start": "3598810",
    "end": "3605700"
  },
  {
    "text": "been talking about so far. In this case, we're going to\nactually want to minimize Q just for this class.",
    "start": "3605700",
    "end": "3612660"
  },
  {
    "text": "OK, and so what's really cool is\nwe showed that we can actually just kind of frame Monte Carlo\ntree search in the same way",
    "start": "3612660",
    "end": "3618728"
  },
  {
    "text": "that we framed these\nother algorithms where you have a Select step and\nyou have an Extend step.",
    "start": "3618728",
    "end": "3624370"
  },
  {
    "text": "And in the Select step, at a\nhigh level, what's going on is we want to select a node that\nwe currently have in the tree",
    "start": "3624370",
    "end": "3631180"
  },
  {
    "text": "to extend based on\na heuristic that balances between exploration\nand exploitation.",
    "start": "3631180",
    "end": "3637099"
  },
  {
    "text": "So that's where that\npart kind of comes in. And then when we get\nto the Extend part, we sample a disturbance,\nadd it to the tree",
    "start": "3637100",
    "end": "3643720"
  },
  {
    "text": "and propagate the\nresults back up. So I'll show you what\nthat means exactly.",
    "start": "3643720",
    "end": "3648730"
  },
  {
    "text": "So again, we're going to assume\nthat we've had some tree so far that we're starting with.",
    "start": "3648730",
    "end": "3654020"
  },
  {
    "text": "And let's talk about what we\ndo for each of these steps. So first, we'll start\nwith the Select step.",
    "start": "3654020",
    "end": "3660849"
  },
  {
    "text": "And in Monte Carlo tree\nsearch, like I said, we maintain this value function\nfor every node in the tree,",
    "start": "3660850",
    "end": "3668740"
  },
  {
    "text": "or value estimate for\nevery node in the tree. So that's what this Q is. Every single node has\nsome Q associated with it.",
    "start": "3668740",
    "end": "3675890"
  },
  {
    "text": "And again, we want lower values\nmean that they're better.",
    "start": "3675890",
    "end": "3681510"
  },
  {
    "text": "So for example, just to\ngive you some intuition, like this node is pretty\nclose to the failure, so it has a pretty low value.",
    "start": "3681510",
    "end": "3688320"
  },
  {
    "text": "The other thing that we maintain\nfor each node in the tree is this count N, which is\njust the number of times",
    "start": "3688320",
    "end": "3694830"
  },
  {
    "text": "that we've visited that\nnode in our tree search. So we're assuming that\nalready the tree search has been going on for a little bit.",
    "start": "3694830",
    "end": "3700952"
  },
  {
    "text": "And so we have some Ns and\nsome Qs from these nodes. And now we want to do one more\niteration of Monte Carlo tree",
    "start": "3700952",
    "end": "3708090"
  },
  {
    "text": "search. And so the first thing we\ndo is this Select step. And the way it\nworks is I want you",
    "start": "3708090",
    "end": "3713250"
  },
  {
    "text": "to imagine that you're\nin this space here, and you're going to\nwalk along this tree. And we're going to\nstart at the root node.",
    "start": "3713250",
    "end": "3720190"
  },
  {
    "text": "And for every Select step,\nthe first thing that we do is we look and see if the number\nof children of the current root",
    "start": "3720190",
    "end": "3726270"
  },
  {
    "text": "node is less than or\nequal to this value here, where N is\nthe number of times",
    "start": "3726270",
    "end": "3733530"
  },
  {
    "text": "we visited the node\nthat we're currently at, and K and alpha are\nsome hyperparameters. So alpha should be\nbetween 0 and 1.",
    "start": "3733530",
    "end": "3741250"
  },
  {
    "text": "But in general, you\ncan just select these and they'll kind of\ncontrol the trade off between how much we will\nend up extending or sampling",
    "start": "3741250",
    "end": "3749620"
  },
  {
    "text": "new things from this\nnode versus going kind of deeper in the tree.",
    "start": "3749620",
    "end": "3755260"
  },
  {
    "text": "And then if it is the case\nthat the number of children is less than this\nnumber, then that",
    "start": "3755260",
    "end": "3760720"
  },
  {
    "text": "means we want more\nchildren for this node. And so we're going to say Yes. And we would select it and\nmove to the Extend step.",
    "start": "3760720",
    "end": "3768279"
  },
  {
    "text": "If not, we move to the child\nnode that minimizes this. So I'm going to get into what's\ngoing on here in a second.",
    "start": "3768280",
    "end": "3775850"
  },
  {
    "text": "But just know that if\nYes, we're going to extend it, go over to the Extend step. If no, we're going to\nstart traversing this tree.",
    "start": "3775850",
    "end": "3784630"
  },
  {
    "text": "So let's talk about actually\nwhat's going on if we do want to traverse the tree.",
    "start": "3784630",
    "end": "3790450"
  },
  {
    "text": "And this is where we actually\nbalance between exploration and exploitation. So we're at some\nspot and we're going",
    "start": "3790450",
    "end": "3796210"
  },
  {
    "text": "to look at all of\nthe places we could go by looking at all of the\nchild nodes that we have. And we're going to compute\nthis value for every single one",
    "start": "3796210",
    "end": "3803900"
  },
  {
    "text": "of the children. And this value is kind of a\ncombination of two things.",
    "start": "3803900",
    "end": "3809130"
  },
  {
    "text": "The first thing is this Q child. So that's exploitation. So if the child already has--",
    "start": "3809130",
    "end": "3814420"
  },
  {
    "text": "So we're going to end up\npicking the lowest one. So we want this value to be low\nif we want to pick the child.",
    "start": "3814420",
    "end": "3819980"
  },
  {
    "text": "And so this exploitation is,\nwell, if the Q is already low then it might be a\ngood idea to go there",
    "start": "3819980",
    "end": "3825050"
  },
  {
    "text": "because we know that that's\nprobably a promising path. But we also want to explore. So we don't always just want\nto exploit what we know,",
    "start": "3825050",
    "end": "3831770"
  },
  {
    "text": "because there might be something\nbetter out there that we don't know about. And so this term here\nkind of balances that.",
    "start": "3831770",
    "end": "3838530"
  },
  {
    "text": "So if we haven't visited that\nchild node very much then this value is\ngoing to be bigger,",
    "start": "3838530",
    "end": "3844890"
  },
  {
    "text": "and so we're going to get a\nbigger what we call exploration bonus. And that's going to\ntell us well, OK,",
    "start": "3844890",
    "end": "3850470"
  },
  {
    "text": "maybe the Q is not so good, but\nwe haven't been there very much. So let's go explore that node.",
    "start": "3850470",
    "end": "3855640"
  },
  {
    "text": "And the way we control the trade\noff between these two things is with this thing we call\nthe exploration bonus.",
    "start": "3855640",
    "end": "3861710"
  },
  {
    "text": "And that allows us to trade\noff between this exploration and exploitation, depending\non what we want to do.",
    "start": "3861710",
    "end": "3868410"
  },
  {
    "text": " Was there any questions on that? Yeah.",
    "start": "3868410",
    "end": "3873850"
  },
  {
    "text": "[INAUDIBLE] the numerator is\nthe same as the denominator? So the-- Let's go back here.",
    "start": "3873850",
    "end": "3879590"
  },
  {
    "text": "So the N in the\nnumerator is the number of times you visited the node\nthat you're currently at. And now you're looking\nat the children",
    "start": "3879590",
    "end": "3885460"
  },
  {
    "text": "to decide what to go to. And so the N in the denominator\nis the number of times you visited that\nchild you're deciding",
    "start": "3885460",
    "end": "3891070"
  },
  {
    "text": "if you want to go visit. All right, thanks. OK.",
    "start": "3891070",
    "end": "3898120"
  },
  {
    "text": "So let's do an example here. So let's imagine that, for\nexample, K is equal to 1,",
    "start": "3898120",
    "end": "3903130"
  },
  {
    "text": "and alpha is equal to 0.5\nfor these parameters here. I just picked these to\nmake the problem work out.",
    "start": "3903130",
    "end": "3910030"
  },
  {
    "text": "So now if we plug in\nN here, we get 2.82. So is the number of children,\nwhich is 3, less than 2.82?",
    "start": "3910030",
    "end": "3920960"
  },
  {
    "text": "No. So we're going to follow\nthis path over here. And so now we need to\nlook at each child node.",
    "start": "3920960",
    "end": "3928020"
  },
  {
    "text": "And we're going to compute\nthis value for each child node to decide which one we\nwant to move to next.",
    "start": "3928020",
    "end": "3933680"
  },
  {
    "text": "So for example for\nthis child node, we'll just plug in our Q child\nand our Ns, and we get 9.26.",
    "start": "3933680",
    "end": "3940770"
  },
  {
    "text": "For this one, we get 0.78. And for this one, we get 11.26.",
    "start": "3940770",
    "end": "3947630"
  },
  {
    "text": "And so we're going to move\nto the one with the lowest. And so one other thing\nI forgot to mention,",
    "start": "3947630",
    "end": "3953820"
  },
  {
    "text": "this is sometimes called\na lower confidence bound. Maybe you've seen\nthe opposite in AA228",
    "start": "3953820",
    "end": "3959660"
  },
  {
    "text": "where we have a plus\nhere, because we want Q to be higher in AA228.",
    "start": "3959660",
    "end": "3965600"
  },
  {
    "text": "In that case, it's called\nan upper confidence bound. OK, so we're going to pick the\none that's the lowest here.",
    "start": "3965600",
    "end": "3971790"
  },
  {
    "text": "So that's this one. And then we're going to\njust move to that node and repeat this process.",
    "start": "3971790",
    "end": "3978609"
  },
  {
    "text": "And so now we'll repeat\nthis process again. So we can say K equals\n1, alpha equals 0.5.",
    "start": "3978610",
    "end": "3984230"
  },
  {
    "text": "Let's compute this term here. We get 1, the number of--",
    "start": "3984230",
    "end": "3989392"
  },
  {
    "text": "I don't think we get 1. We get 2. Maybe that didn't update. But we get 2 here, because\nthe square root of--",
    "start": "3989392",
    "end": "3997450"
  },
  {
    "text": "Oh wait. Yeah, I didn't update these\nnumbers but we should get 2. I'll fix that in\nthe slides later.",
    "start": "3997450",
    "end": "4003960"
  },
  {
    "text": "So we get 2, because I\nwanted to stop at this node. And so this inequality\nis satisfied.",
    "start": "4003960",
    "end": "4011140"
  },
  {
    "text": "And so we're going\nto select this node and move on to the Extend step. Ignore these numbers.",
    "start": "4011140",
    "end": "4016840"
  },
  {
    "text": "They don't add up.  Any questions there?",
    "start": "4016840",
    "end": "4024000"
  },
  {
    "text": "Yeah. I'm a little confused\nby the K and alpha.",
    "start": "4024000",
    "end": "4029010"
  },
  {
    "text": "I guess like where\ndoes that come from? It's kind of just a heuristic\npeople use to decide--",
    "start": "4029010",
    "end": "4036309"
  },
  {
    "text": "So basically when\nyou're at a node, you have a bunch\nof children, you can decide whether you\nwant to extend that node",
    "start": "4036310",
    "end": "4043420"
  },
  {
    "text": "or just go deeper in the tree. And you can imagine that if\nyou have a ton of children, then you probably don't\nneed to sample more of them.",
    "start": "4043420",
    "end": "4050720"
  },
  {
    "text": "And so you probably want\nto go deeper in the tree. And this basically\nbalances between--",
    "start": "4050720",
    "end": "4057430"
  },
  {
    "text": "it kind of balances\nthat objective. So it allows you to say,\nif I have more children, then I probably just want\nto go to one of them.",
    "start": "4057430",
    "end": "4065440"
  },
  {
    "text": "Which would mean that we\nfollow this step where we go traverse the tree further.",
    "start": "4065440",
    "end": "4070750"
  },
  {
    "text": "But if I have enough\nchildren, or if I have not enough\nchildren, then I would want to go to the Extend\nstep at that particular node.",
    "start": "4070750",
    "end": "4079270"
  },
  {
    "text": "Does that make sense? And K and alpha\nare just parameters you pick that will kind of\ncontrol how many children you",
    "start": "4079270",
    "end": "4085600"
  },
  {
    "text": "end up with. Yeah. Is this condition here\n[INAUDIBLE] continuous world",
    "start": "4085600",
    "end": "4091790"
  },
  {
    "text": "that we have? Because I remember in AA228,\nwe just started with MCTS",
    "start": "4091790",
    "end": "4097520"
  },
  {
    "text": "and there was no checking\nhow many children each year. Yes, good question. So you have to do\nthis when there's not",
    "start": "4097520",
    "end": "4106159"
  },
  {
    "text": "a discrete number\nof outcomes that you could have when you're switching\nfrom one node to another. So because we're in a\ncontinuous case, kind",
    "start": "4106160",
    "end": "4112131"
  },
  {
    "text": "of what you aid with\nthe continuum world, we could just sample\nchildren forever and ever and ever and ever,\nbecause every disturbance",
    "start": "4112132",
    "end": "4118430"
  },
  {
    "text": "is going to be\ndifferent, because it's like a continuous space\nof possible things that could happen. And so we need to control\nthen how many children we",
    "start": "4118430",
    "end": "4125899"
  },
  {
    "text": "have by doing this. So in other versions of MCTS\nwhere things are discrete, you don't have to\nworry about this.",
    "start": "4125899",
    "end": "4132890"
  },
  {
    "text": "Yeah. Is there a step in which we\nupdate the back propagating at some point? Yeah.",
    "start": "4132890",
    "end": "4138439"
  },
  {
    "text": "Oh, OK, OK. Got it. And then this is\nprogressive whitening. Yes, this is called\nprogressive [INAUDIBLE].",
    "start": "4138439",
    "end": "4143660"
  },
  {
    "text": "Yes.  Yeah. So earlier when it was like,\nthere's not enough children,",
    "start": "4143660",
    "end": "4151250"
  },
  {
    "text": "and so we were on the\nno arrow, and then we choose the child\nthat minimizes that score, when we choose the\nchild that minimizes that score,",
    "start": "4151250",
    "end": "4159409"
  },
  {
    "text": "do we step to that\nchild and then we start the algorithm\nagain from that child,",
    "start": "4159410",
    "end": "4164660"
  },
  {
    "text": "or you go back to the--? Yeah, so we were here. And then we said we\nhave enough children,",
    "start": "4164660",
    "end": "4171560"
  },
  {
    "text": "we're going to move on. And then we chose to move here. And now we're here\nand we're doing we're doing this whole\ndecision all over again.",
    "start": "4171560",
    "end": "4178509"
  },
  {
    "text": "But I messed up the numbers, so. Like if K equals 1\nand alpha equals 0.5,",
    "start": "4178510",
    "end": "4184399"
  },
  {
    "text": "then we're going to get 1\ntimes N equals 4 to the 0.5. So 1 times the square\nroot of 4, which is 2.",
    "start": "4184399",
    "end": "4191600"
  },
  {
    "text": "And then the number\nof children is 2. And it is the case that 2\nis less than or equal to 2.",
    "start": "4191600",
    "end": "4196640"
  },
  {
    "text": "So we would move to here. And I had updated\nthese, but I guess it didn't save or something. No, that makes sense.",
    "start": "4196640",
    "end": "4203650"
  },
  {
    "text": "Yeah, save your work, guys. OK. Did you have a question?",
    "start": "4203650",
    "end": "4209780"
  },
  {
    "text": "OK. Anything else? Yep.",
    "start": "4209780",
    "end": "4215960"
  },
  {
    "text": "Yeah, N is the number of times\nthat you visited the node. Is that correct?",
    "start": "4215960",
    "end": "4221490"
  },
  {
    "text": "Oh, wait, what's\nQ one more time? Q is this value estimate\nthat we're maintaining. So I'll show it a little\nbit how you end up",
    "start": "4221490",
    "end": "4228050"
  },
  {
    "text": "computing it or estimating it. But the intuition there is\nthat a lower Q is what we want.",
    "start": "4228050",
    "end": "4234510"
  },
  {
    "text": "So a lower Q would be something\nthat's closer to a failure. Thank you. ",
    "start": "4234510",
    "end": "4243140"
  },
  {
    "text": "Any other questions? In a sense, it's\nlike a cost to go.",
    "start": "4243140",
    "end": "4248420"
  },
  {
    "text": "Yes, in a sense, it's\nlike a cost to go. ",
    "start": "4248420",
    "end": "4254714"
  },
  {
    "text": "OK, so now we've\ndecided that we're not going to propagate down\nthe tree any further.",
    "start": "4254714",
    "end": "4260040"
  },
  {
    "text": "We're going to extend\nthis node that we're at. And so what we do is we\njust sample a disturbance.",
    "start": "4260040",
    "end": "4266130"
  },
  {
    "text": "So maybe we sample\nthis one, for example. We add it to the tree.",
    "start": "4266130",
    "end": "4271320"
  },
  {
    "text": "And then whenever we add\na new node to the tree, we need to now\ninitialize its N and Q.",
    "start": "4271320",
    "end": "4277300"
  },
  {
    "text": "So N is just going to be 1. We just visited\nit this one time.",
    "start": "4277300",
    "end": "4282660"
  },
  {
    "text": "But we need to decide what\nto give it for its value Q. And so we need some\nway to estimate this.",
    "start": "4282660",
    "end": "4287860"
  },
  {
    "text": "And this is where you have\nto use domain knowledge or make design decisions\nfor this algorithm.",
    "start": "4287860",
    "end": "4293383"
  },
  {
    "text": "But one thing you could do is\nyou could, for example, just imagine doing a whole\nbunch of rollouts from this particular state.",
    "start": "4293383",
    "end": "4299620"
  },
  {
    "text": "And then that gives\nus an idea of how good everything is going to be\nin the future from this state. And maybe you compute\nthe robustness",
    "start": "4299620",
    "end": "4306443"
  },
  {
    "text": "of these rollouts, the\naverage robustness, something like that, some\nmetric that gives you an idea of how like\nwhat Michael was saying,",
    "start": "4306443",
    "end": "4312730"
  },
  {
    "text": "that your cost to go. And so for example,\nmaybe we get Q equals 3.",
    "start": "4312730",
    "end": "4318270"
  },
  {
    "text": "And so now for our node,\nwe've now added this new node to the tree with\nwe visited it once,",
    "start": "4318270",
    "end": "4324230"
  },
  {
    "text": "and we estimated\nits value to be 3. And then as we were\nasking earlier,",
    "start": "4324230",
    "end": "4329480"
  },
  {
    "text": "we need to propagate what we\njust saw back up the tree, because now we have new\ninformation about how everything",
    "start": "4329480",
    "end": "4334970"
  },
  {
    "text": "goes. And so we go to the\nnodes that we saw before, and we increase\ntheir visit count,",
    "start": "4334970",
    "end": "4341030"
  },
  {
    "text": "because we've now\nvisited them again. And then we also update\ntheir Q to be this moving",
    "start": "4341030",
    "end": "4346820"
  },
  {
    "text": "average of the Q that\nit thought that it was and the Q that we just\nfound when we went to that node.",
    "start": "4346820",
    "end": "4354030"
  },
  {
    "text": "So this is basically just\nkind of a moving average. You can look at the\nformula for it in the book.",
    "start": "4354030",
    "end": "4359853"
  },
  {
    "text": "And then we propagate all the\nway back up to the root node and do the same thing. ",
    "start": "4359853",
    "end": "4365720"
  },
  {
    "text": "Yeah. So but when we define\nour two functions, we can change the\nparameters, so a lot more",
    "start": "4365720",
    "end": "4373880"
  },
  {
    "text": "be like a lot of\ndifferent roots have been created before we actually\nkind of hit more like extend",
    "start": "4373880",
    "end": "4381630"
  },
  {
    "text": "heavy than just like following\nand how do we optimize that?",
    "start": "4381630",
    "end": "4386760"
  },
  {
    "text": "Are we going to optimize that\nor just figure out [INAUDIBLE]? Yeah, so the question\nwas like, can we",
    "start": "4386760",
    "end": "4392730"
  },
  {
    "text": "make it more extend heavier? How do we optimize\nlike how far we go down the tree, that kind of stuff?",
    "start": "4392730",
    "end": "4398010"
  },
  {
    "text": "So that progressive\nwidening step, we can choose alpha\nand K to trade off between how deep we go.",
    "start": "4398010",
    "end": "4405130"
  },
  {
    "text": "So if we want more\nchildren, we're not going to go as deep then. And then this idea\nof when we do then",
    "start": "4405130",
    "end": "4410580"
  },
  {
    "text": "traverse the tree, we\nbalance between exploration and exploitation,\nand that C parameter",
    "start": "4410580",
    "end": "4416190"
  },
  {
    "text": "we had in the lower\nconfidence bound allows us to trade\noff between the two. So if we want more\nexploitation, we",
    "start": "4416190",
    "end": "4423930"
  },
  {
    "text": "would go deeper down the tree,\ndeeper down the paths that are promising. If we want more\nexploration, we would end up",
    "start": "4423930",
    "end": "4429643"
  },
  {
    "text": "of going down maybe\nless promising paths. I think my question is\nlike, how do we pick C",
    "start": "4429643",
    "end": "4435239"
  },
  {
    "text": "and how do we optimize-- [INTERPOSING VOICES] Yeah, yeah, yeah,\nthat's what I mean. I'm like, how do we--",
    "start": "4435240",
    "end": "4440731"
  },
  {
    "text": "We pick somebody now,\nbut it's is there any methodology of this\nis like the best you",
    "start": "4440731",
    "end": "4446289"
  },
  {
    "text": "can do if you want to have the\nmaximum coverage or this is-- like no matter what I to find.",
    "start": "4446290",
    "end": "4452469"
  },
  {
    "text": "So for K and alpha, there's\nrecommended parameters that people use is\ntypically, like 2 and 0.5.",
    "start": "4452470",
    "end": "4458435"
  },
  {
    "text": "But sometimes you\nhave to mess with it. For the exploration\nbonus, I think it's probably problem dependent,\nbecause you're like depending",
    "start": "4458435",
    "end": "4467469"
  },
  {
    "text": "on this Q function and stuff. So like the way you'd\nsearch any hyperparameter",
    "start": "4467470",
    "end": "4473469"
  },
  {
    "text": "when you're trying\nto run an algorithm. So I would try\nsomething, and you can look at the\ntree that comes out",
    "start": "4473470",
    "end": "4479110"
  },
  {
    "text": "and be like, hey, I feel\nlike that's exploring more than I want it to, so\nI'm going to up this value or whatever.",
    "start": "4479110",
    "end": "4484155"
  },
  {
    "start": "4484155",
    "end": "4490751"
  },
  {
    "text": "OK, then you just\nrepeat this process. And let me just show\nyou what this looks like to wrap up lecture today.",
    "start": "4490751",
    "end": "4496720"
  },
  {
    "text": "This is one of my favorite\nfigures from the entire book. So what I'm going\nto show here is I'm going to show a run\nof Monte Carlo tree search",
    "start": "4496720",
    "end": "4504030"
  },
  {
    "text": "to try to get to this failure. And then nodes that\nare visited more often",
    "start": "4504030",
    "end": "4510540"
  },
  {
    "text": "or kind of edges that\nare followed more often are going to be a little\nbit darker than the ones",
    "start": "4510540",
    "end": "4516719"
  },
  {
    "text": "that are followed less often. And so you'll be able to see of\nthis balance between exploration and exploitation.",
    "start": "4516720",
    "end": "4522520"
  },
  {
    "start": "4522520",
    "end": "4531270"
  },
  {
    "text": "OK, really cool. All right, so I\nthink Tuesday we'll",
    "start": "4531270",
    "end": "4537420"
  },
  {
    "text": "continue with the\nrest of this lecture. And then we have a super\nawesome guest lecture from the other textbook\nauthor, Anthony Corso,",
    "start": "4537420",
    "end": "4545800"
  },
  {
    "text": "that will be related\nto all of the things that I just talked about. I'll give you some more real\nworld applications for it.",
    "start": "4545800",
    "end": "4552650"
  },
  {
    "start": "4552650",
    "end": "4557000"
  }
]
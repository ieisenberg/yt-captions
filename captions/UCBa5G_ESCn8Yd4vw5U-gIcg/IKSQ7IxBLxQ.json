[
  {
    "start": "0",
    "end": "5120"
  },
  {
    "text": "So we've been talking\nabout collision avoidance as one of our example problems. And many of you\nknow both Michael",
    "start": "5120",
    "end": "10640"
  },
  {
    "text": "and I worked on a system\ncalled ACAS X, which does airborne collision avoidance.",
    "start": "10640",
    "end": "16369"
  },
  {
    "text": "And what's really cool\nabout this is I mentioned, I think at one point in\nthis class, they trained this model of the airspace\non nine months of radar data",
    "start": "16370",
    "end": "24439"
  },
  {
    "text": "across the continental\nUnited States. For those of you who\ntook AA228, this model is actually represented\nas a Bayesian network,",
    "start": "24440",
    "end": "31170"
  },
  {
    "text": "which is pretty cool. And you can basically\nsample aircraft encounters from this Bayesian\nnetwork in order",
    "start": "31170",
    "end": "37190"
  },
  {
    "text": "to simulate two aircraft\nflying at each other to understand whether or not\nyour system will be preventing",
    "start": "37190",
    "end": "43250"
  },
  {
    "text": "a near midair\ncollision or an NMAC. And so what you want\nto end up computing is the probability\nthat with your system,",
    "start": "43250",
    "end": "50970"
  },
  {
    "text": "the aircraft result\nin a near midair collision, given that they're\nin some of encounter scenario.",
    "start": "50970",
    "end": "57262"
  },
  {
    "text": "And so you could do\nthat by just sampling a bunch of encounters from\nthis Bayesian network, and then trying to see how many\nof them result in NMAC when",
    "start": "57262",
    "end": "65440"
  },
  {
    "text": "you use your collision\navoidance system. But as I mentioned in\nthe paper, and as we've talked about quite\na bit in this class,",
    "start": "65440",
    "end": "72110"
  },
  {
    "text": "is that this approach tends\nto be quite inefficient because you're not going to\nget very many near midair",
    "start": "72110",
    "end": "78070"
  },
  {
    "text": "collisions, because\nin the airspace, it's generally\npretty safe already. You're not in a lot\nof scenarios where",
    "start": "78070",
    "end": "83470"
  },
  {
    "text": "you would result in a near\nmidair collision, which is a good thing. And so if you want to get a\nbetter estimate on these things,",
    "start": "83470",
    "end": "89750"
  },
  {
    "text": "you can actually sample from\na different distribution by biasing the distribution\nafter you sample",
    "start": "89750",
    "end": "95770"
  },
  {
    "text": "from the Bayesian network\nto have smaller vertical and horizontal miss distances. And then that will give you\nthe more interesting behavior",
    "start": "95770",
    "end": "102490"
  },
  {
    "text": "you need. And then you can do this\nimportance reweighting in order to get an estimate of the\nprobability of near midair",
    "start": "102490",
    "end": "109600"
  },
  {
    "text": "collision. So there's just a cool\nreal-world example",
    "start": "109600",
    "end": "114700"
  },
  {
    "text": "of importance sampling helping\nout in basically estimating the probability of collision for\nthe ACAS X collision avoidance",
    "start": "114700",
    "end": "122640"
  },
  {
    "text": "system. So yeah, if you guys\nare interested in more, I'll share this paper on Ed.",
    "start": "122640",
    "end": "129270"
  },
  {
    "text": "It was written by Michael. So it's, of course, a wonderful\npaper, and you can check it out.",
    "start": "129270",
    "end": "134944"
  },
  {
    "text": "[INAUDIBLE] They use a slash-- although I'm not so sure\nabout this multi-italicized.",
    "start": "134944",
    "end": "143160"
  },
  {
    "text": "I don't know. But this was years ago, so-- [INAUDIBLE]",
    "start": "143160",
    "end": "149280"
  },
  {
    "text": "You've grown since then. We'll give you a good-- Yeah. A growth mindset. Growth mindset.",
    "start": "149280",
    "end": "155430"
  },
  {
    "text": "OK, cool. So with that, we're going to\ntalk about explainability today.",
    "start": "155430",
    "end": "161340"
  },
  {
    "text": "And so far in this class, we've\nactually just been like this.",
    "start": "161340",
    "end": "166660"
  },
  {
    "text": "So we've either been like, it\ndoesn't work or it does work. We found failures. We estimated\nprobability of failure.",
    "start": "166660",
    "end": "172750"
  },
  {
    "text": "We sometimes prove that\nthere were no failures. And sometimes that gave us\ninsights into what was going on,",
    "start": "172750",
    "end": "178290"
  },
  {
    "text": "but we're never really\nexplicitly explaining like, why does it work? Why does it not work? We're just like, it works.",
    "start": "178290",
    "end": "183440"
  },
  {
    "text": "And sometimes that's OK. Sometimes you can just be\nlike, all right, it works. We have a proof that it works. So I'm good. I'm just going to go for it.",
    "start": "183440",
    "end": "189290"
  },
  {
    "text": "But sometimes it really does\nmatter why it actually works or why it's doing what it's\ndoing because you couldn't",
    "start": "189290",
    "end": "194510"
  },
  {
    "text": "get fooled by it. It could always be working\nand all of these things that you're validating over. But maybe there's some metrics\nthat you missed out on.",
    "start": "194510",
    "end": "200940"
  },
  {
    "text": "And it turns out it would do\nreally poorly on those metrics. And if you can instead explain\nthe behavior of a system",
    "start": "200940",
    "end": "206960"
  },
  {
    "text": "and be like, OK, the system\nis making this decision or it fails in this way\nbecause of this and this,",
    "start": "206960",
    "end": "212460"
  },
  {
    "text": "then you might\nhave a better idea of what's actually going on. And you can feel more\nconfident when you deploy the system in the real world.",
    "start": "212460",
    "end": "219710"
  },
  {
    "text": "So sometimes it's good to\nknow why it actually works. So that's what we're\ngoing to do today.",
    "start": "219710",
    "end": "225780"
  },
  {
    "text": "We're going to talk\nabout a whole bunch of different techniques\nfor explainability. We'll start with\npolicy visualization.",
    "start": "225780",
    "end": "231960"
  },
  {
    "text": "Then we'll talk for a while\nabout feature importance. We'll talk about surrogate\nmodels for explaining policies.",
    "start": "231960",
    "end": "239610"
  },
  {
    "text": "And then we're going to talk\nabout the last two topics briefly. But we'll talk about\ncounterfactuals and failure mode",
    "start": "239610",
    "end": "245190"
  },
  {
    "text": "characterization. So let's just jump in here. Policy visualization we've\nactually already done",
    "start": "245190",
    "end": "252120"
  },
  {
    "text": "a whole bunch in this class. Because really,\nwhat you could do is you could just visualize\nsome rollouts of your system.",
    "start": "252120",
    "end": "257790"
  },
  {
    "text": "So we've done this\nlots of times. So for example, we could roll\nout our collision avoidance system a whole bunch of times\nand just look at what happens.",
    "start": "257790",
    "end": "264370"
  },
  {
    "text": "And so we can see there's\ntwo modes of behavior. It either goes above the\nintruder or below the intruder.",
    "start": "264370",
    "end": "270850"
  },
  {
    "text": "And really this is one of maybe\nthe first things that you would do when you design a system. You just roll it out and make\nsure it looks reasonable.",
    "start": "270850",
    "end": "279330"
  },
  {
    "text": "Same with the inverted pendulum. We can see for the\nmost part, it just stays upright with\nan angle of 0,",
    "start": "279330",
    "end": "285150"
  },
  {
    "text": "and then sometimes\nit falls over. OK. So that's one\nthing you could do.",
    "start": "285150",
    "end": "290405"
  },
  {
    "text": "Another thing you\ncould do is try to plot the policy of the agent. So let's actually look at\nthe one on the right first.",
    "start": "290405",
    "end": "297210"
  },
  {
    "text": "This is the inverted\npendulum policy. And what's nice about the\ninverted pendulum is it has a 2D",
    "start": "297210",
    "end": "302919"
  },
  {
    "text": "state. And the policy is only\ndependent on the current state. So we can look at\nwhat the agent would",
    "start": "302920",
    "end": "308600"
  },
  {
    "text": "say to do if it was given\nan observation of any of these states. So we have theta on this\naxis, omega on this axis,",
    "start": "308600",
    "end": "315330"
  },
  {
    "text": "and we can just sanity check\nthat all of this makes sense. So for example, at 0, 0, so that\nmeans we're perfectly upright",
    "start": "315330",
    "end": "321889"
  },
  {
    "text": "and we're not moving at all. We would hope then that we\nwould just stay that way. So we'd want to\napply a torque of 0.",
    "start": "321890",
    "end": "328140"
  },
  {
    "text": "So we can see here,\nwe get a torque of 0. Seems reasonable. If we move to the right here\nwhere theta is positive,",
    "start": "328140",
    "end": "335370"
  },
  {
    "text": "we get a negative\ntorque because we want to push it back\nup the other way. If we move to the left,\nwe get a positive torque",
    "start": "335370",
    "end": "341210"
  },
  {
    "text": "to push it back up and so on. So this is just a nice sanity\ncheck to plot the policy.",
    "start": "341210",
    "end": "347479"
  },
  {
    "text": "For the collision\navoidance system, we can do a similar thing. But now the actions\nare discrete.",
    "start": "347480",
    "end": "352848"
  },
  {
    "text": "So here we're plotting\na slice of the state space, where on this axis, we\nhave the time to collision.",
    "start": "352848",
    "end": "358280"
  },
  {
    "text": "And then on this axis, we\nhave the relative altitude between the ownship\nand intruder.",
    "start": "358280",
    "end": "363970"
  },
  {
    "text": "And so you could imagine\nthe ownship is right here-- oh, sorry, the intruder\nis right here in the plot.",
    "start": "363970",
    "end": "369165"
  },
  {
    "text": "And then you could\nimagine if you put the ownship at\nany of these places, this is the action\nthat it would get.",
    "start": "369165",
    "end": "374780"
  },
  {
    "text": "So if we're above the\nintruder, we get told to climb. If we're below, we\nget told to descend. And if we're far enough\nabove or far enough below,",
    "start": "374780",
    "end": "381889"
  },
  {
    "text": "we get no advisory\nclear of conflict. We don't need to do\nanything because we're not in a dangerous situation.",
    "start": "381890",
    "end": "390069"
  },
  {
    "text": "So this is very interesting. And this is actually\nsomething they did when they were\nfirst generating the policies for ACAS X.",
    "start": "390070",
    "end": "395900"
  },
  {
    "text": "And you can find some\ninteresting unintuitive features, so for example,\nthis notch back here.",
    "start": "395900",
    "end": "403360"
  },
  {
    "text": "Maybe if you take an AA228. Does anyone have any\nideas of why this notch isn't like filled in? Why it's no advisory?",
    "start": "403360",
    "end": "410590"
  },
  {
    "text": "Yeah. [INAUDIBLE] Yeah, yeah.",
    "start": "410590",
    "end": "415620"
  },
  {
    "text": "So we don't know whether or\nnot climbing or descending is going to be better yet.",
    "start": "415620",
    "end": "421620"
  },
  {
    "text": "So it's interesting. You can discover\ninteresting features by doing this policy\nvisualization. So it's definitely something\nthat I would recommend",
    "start": "421620",
    "end": "428520"
  },
  {
    "text": "as you're designing systems. And then another thing to note\nhere for the collision avoidance",
    "start": "428520",
    "end": "433980"
  },
  {
    "text": "policy is specifically that\nwe're plotting a policy slice. So what's nice about\nthe inverted pendulum",
    "start": "433980",
    "end": "439470"
  },
  {
    "text": "is the state was\nonly two-dimensional. So we could just plot\nthe entire policy and see what it looked like.",
    "start": "439470",
    "end": "444550"
  },
  {
    "text": "The state for the\ncollision avoidance policy is actually four-dimensional. So we can't just plot the whole\nthing at once and visualize it.",
    "start": "444550",
    "end": "452410"
  },
  {
    "text": "We have to plot slices,\nbecause again, we don't really know how to visualize\nfour dimensions.",
    "start": "452410",
    "end": "458460"
  },
  {
    "text": "And so you have to plot\ndifferent slices of it.",
    "start": "458460",
    "end": "464130"
  },
  {
    "text": "And so another way\nto do this when you have these more complicated\nhigh-dimensional policies is",
    "start": "464130",
    "end": "470780"
  },
  {
    "text": "to partition the state space. And I know this is blurry. It's really bothering\nme, but I honestly didn't have time to\nfix it, so I'm sorry.",
    "start": "470780",
    "end": "477860"
  },
  {
    "text": "It's not blurry in the book. I don't know. Some PDF renders\nmake this blurry. I don't know what's going on. But anyway, so pretend\nit's not blurry.",
    "start": "477860",
    "end": "485539"
  },
  {
    "text": "So we can also partition\nthe state space into a bunch of regions\nand then simulate",
    "start": "485540",
    "end": "491780"
  },
  {
    "text": "a bunch of trajectories. So we'll just imagine\nall those rollouts that we had from before.",
    "start": "491780",
    "end": "497310"
  },
  {
    "text": "And then every time it\npasses through a region, we mark down what action\nit took in that region.",
    "start": "497310",
    "end": "503220"
  },
  {
    "text": "And so it might not always\nhave the same vertical rate or previous action\nonce in these regions. So it might not always take\nthe same action in each region,",
    "start": "503220",
    "end": "510445"
  },
  {
    "text": "but we just keep tracking\neach region of the action that it took. And then, for example,\nwe could maybe plot the action that was taken\nmost frequently in each region.",
    "start": "510445",
    "end": "518580"
  },
  {
    "text": "Yeah. Sorry. What is this trying to solve? We're just trying to be\nable to visualize the policy",
    "start": "518580",
    "end": "524150"
  },
  {
    "text": "that's four-dimensional and-- How does-- [INAUDIBLE]\nversus this versus just throwing\nout a bunch?",
    "start": "524150",
    "end": "529900"
  },
  {
    "text": "Well, we're plotting the\naction that got taken as we were doing the rollouts. Oh, OK, I see. So we're trying to visualize--",
    "start": "529900",
    "end": "535990"
  },
  {
    "text": "And the pendulum is\nhistory dependent. That's why. The pendulum is not\nhistory dependent.",
    "start": "535990",
    "end": "541590"
  },
  {
    "text": "It's [INAUDIBLE] dependent. Oh. It's history-- Yes, yes. Actually this one's\nnot history-dependent.",
    "start": "541590",
    "end": "546641"
  },
  {
    "text": "It's just because we're plotting\na slice of the state space that you might get\ndifferent ones.",
    "start": "546642",
    "end": "551720"
  },
  {
    "text": "But that does bring me\nto my next point, which is what's really nice about\nthis method is it works for non-Markovian systems.",
    "start": "551720",
    "end": "557630"
  },
  {
    "text": "So if it is history-dependent,\nwe can't just look over the state space\nand be like, in this state, I'm going to take this\naction because it also",
    "start": "557630",
    "end": "564550"
  },
  {
    "text": "depends on how you got\nto that state sometimes. And so in this case, we\ncan actually just simulate",
    "start": "564550",
    "end": "570010"
  },
  {
    "text": "a bunch of rollouts. Then we know how we got\nto every single state. And we can still make this\nkind of visualization.",
    "start": "570010",
    "end": "575240"
  },
  {
    "text": "So this is nice if you\nhave a complex potentially non-Markovian system as well.",
    "start": "575240",
    "end": "582490"
  },
  {
    "text": "OK. Great. So that's the first thing. So just visualize your policy. That's something that's\nalways pretty simple to do",
    "start": "582490",
    "end": "589230"
  },
  {
    "text": "but also can be quite\nuseful in finding bugs. OK. So now we're going to talk for\na while about this thing called",
    "start": "589230",
    "end": "596023"
  },
  {
    "text": "feature importance. I think this is\nwhat a lot of people think of when they\nthink of explainability. And basically the goal\nof feature importance",
    "start": "596023",
    "end": "602580"
  },
  {
    "text": "is to understand the\ncontribution of various features to the overall\nbehavior of a system.",
    "start": "602580",
    "end": "608072"
  },
  {
    "text": "And features could be\nlots of different things. So it could be the\nstate of the system. It could be the\ndisturbances that we apply.",
    "start": "608072",
    "end": "613330"
  },
  {
    "text": "It could be the pixels of an\nimage, lots of different things. We want to understand how\nthose things influence",
    "start": "613330",
    "end": "619560"
  },
  {
    "text": "the behavior of our system or\nsome output that we care about. So here's a couple of examples\nto make it more concrete.",
    "start": "619560",
    "end": "626950"
  },
  {
    "text": "So say we have an\naircraft that's taking images of a runway. And we're using those images to\nsteer ourselves down the runway.",
    "start": "626950",
    "end": "634089"
  },
  {
    "text": "Then we might want to know,\ngiven a particular image, what pixels in the image were most\nimportant for us to decide",
    "start": "634090",
    "end": "640829"
  },
  {
    "text": "on the steering angle that we\nwere eventually going to take. And so the brighter\npixels in this image,",
    "start": "640830",
    "end": "647190"
  },
  {
    "text": "I'll talk about how we\nfind this in a second. But this would give us an\nidea of the pixels that were most important in deciding\nwhat steering angle to take.",
    "start": "647190",
    "end": "657560"
  },
  {
    "text": "And then similarly,\nwe can do something with trajectories for\ndisturbances where we would say,",
    "start": "657560",
    "end": "663980"
  },
  {
    "text": "so here's our inverted\npendulum trajectory. Each of these dots here is\nan observation disturbance.",
    "start": "663980",
    "end": "669779"
  },
  {
    "text": "So it's like where the\npendulum thought that it was. And then the darker dots\nindicate points that",
    "start": "669780",
    "end": "677750"
  },
  {
    "text": "or disturbances that\nwere more influential in the final outcome\nof the trajectory or in the robustness\nof the trajectory.",
    "start": "677750",
    "end": "685370"
  },
  {
    "text": "And so it turns out that\ndisturbances earlier on, and we'll see this\nin a second, end up being more influential\nthan disturbances",
    "start": "685370",
    "end": "691490"
  },
  {
    "text": "later in the trajectory. Cool. So there's two ways that we can\nthink about feature importance.",
    "start": "691490",
    "end": "698840"
  },
  {
    "text": "One way is something called\nsensitivity analysis. And the second way\nis Shapley values. And we're going to talk\nabout both of these.",
    "start": "698840",
    "end": "705720"
  },
  {
    "text": "So starting with\nsensitivity analysis. So what sensitivity\nanalysis allows us to do",
    "start": "705720",
    "end": "711060"
  },
  {
    "text": "is to understand how a\nparticular output changes when a single feature is changed.",
    "start": "711060",
    "end": "718080"
  },
  {
    "text": "So here's an example. Here just a notional example. So let's imagine we have\na trajectory of an agent",
    "start": "718080",
    "end": "723600"
  },
  {
    "text": "through some environment. And the white trajectory is\nlike the trajectory that we see.",
    "start": "723600",
    "end": "729270"
  },
  {
    "text": "And so these both have the\nsame white trajectory here.",
    "start": "729270",
    "end": "734370"
  },
  {
    "text": "But then let's say that\nwe change one feature. So we maybe resample\na disturbance",
    "start": "734370",
    "end": "739410"
  },
  {
    "text": "at this point in the trajectory. And then we roll out the\nrest of the trajectory with the same\ndisturbances from there.",
    "start": "739410",
    "end": "745540"
  },
  {
    "text": "So we just perturb one\npoint in the trajectory. And we do that\nfor both of these.",
    "start": "745540",
    "end": "751380"
  },
  {
    "text": "Can anyone guess which of\nthese has a higher sensitivity? The one on the right\nor the one on the left?",
    "start": "751380",
    "end": "758180"
  },
  {
    "text": "Yeah. OK. The one on the right. I think you're all pointing the\nopposite way for me, but yeah.",
    "start": "758180",
    "end": "764779"
  },
  {
    "text": "OK. This one has higher sensitivity. So basically, all\nwe're doing is trying to understand if we\nchange this thing,",
    "start": "764780",
    "end": "771090"
  },
  {
    "text": "does it affect the\nfinal outcome a lot? And if it affects\nit a lot or we have this high viability\nof possible outcomes,",
    "start": "771090",
    "end": "778020"
  },
  {
    "text": "we say it has high sensitivity. And if we have a low viability\nof possible outcomes, it has a low sensitivity.",
    "start": "778020",
    "end": "783600"
  },
  {
    "text": " OK. So here's one way that\nwe can compute this.",
    "start": "783600",
    "end": "789510"
  },
  {
    "text": "So let's say that we wanted to\ncompute the sensitivity for all of the disturbances in\na particular trajectory.",
    "start": "789510",
    "end": "795240"
  },
  {
    "text": "What we could do is\nsay we want to compute the sensitivity of the final\nresult of this trajectory",
    "start": "795240",
    "end": "800820"
  },
  {
    "text": "or maybe the robustness\nof this trajectory with respect to just\nthis first disturbance.",
    "start": "800820",
    "end": "806810"
  },
  {
    "text": "So what we could\ndo is we could say, I'm going to keep all\nof the disturbances the same for the rest\nof the trajectory.",
    "start": "806810",
    "end": "812340"
  },
  {
    "text": "But I'm going to resample\nthis first disturbance maybe from its nominal\ndisturbance distribution or something like that.",
    "start": "812340",
    "end": "818810"
  },
  {
    "text": "And then we're going to simulate\nall those resampled versions and see the spread of the\ntrajectories that results.",
    "start": "818810",
    "end": "825779"
  },
  {
    "text": "So we can maybe\nlook at the spread or for example, the standard\ndeviation of the robustness values we get when we\nresample and simulate",
    "start": "825780",
    "end": "833090"
  },
  {
    "text": "those new trajectories\nfor that point. So that's how we get this. And that gives us the\nsensitivity at this point.",
    "start": "833090",
    "end": "839310"
  },
  {
    "text": "We could do that again\nwith the next disturbance. So we're going to keep this\ndisturbance constant and all the future ones\nconstant and look",
    "start": "839310",
    "end": "845750"
  },
  {
    "text": "at the spread over trajectories. And then we can just repeat this\nfor the rest of the trajectory,",
    "start": "845750",
    "end": "852150"
  },
  {
    "text": "looking at the spread of the\npossible resulting trajectories. And we change that disturbance.",
    "start": "852150",
    "end": "857280"
  },
  {
    "text": "And maybe I'll just\nplay that one more time. You'll notice that as\nwe get towards the end",
    "start": "857280",
    "end": "862640"
  },
  {
    "text": "of the trajectory, the spread\ndecreases more and more. And so you can\nsee that we end up",
    "start": "862640",
    "end": "868250"
  },
  {
    "text": "finding out that\nthe robustness is less sensitive to the\ndisturbances applied later",
    "start": "868250",
    "end": "874770"
  },
  {
    "text": "in the trajectory than\nthe ones applied here. Yeah. Isn't this always true with\nany multiplicative system?",
    "start": "874770",
    "end": "882779"
  },
  {
    "text": "Because variance-- say it\nusually is invariant variable. Some time you multiply\nthem all together and their [INAUDIBLE]\nvariance, which",
    "start": "882780",
    "end": "888870"
  },
  {
    "text": "is monotonically increasing. I feel like if you had a really\nbad disturbance right here",
    "start": "888870",
    "end": "896339"
  },
  {
    "text": "or something, you might\nfind that it's really sensitive to the disturbance. In general, I would say\ndisturbance was roughly similar",
    "start": "896340",
    "end": "902040"
  },
  {
    "text": "across [INAUDIBLE]. It doesn't only apply to\n[INAUDIBLE] like moving earlier points over [INAUDIBLE]",
    "start": "902040",
    "end": "908010"
  },
  {
    "text": "I think that's generally true. Yeah, I'm not saying\nwe necessarily found an interesting\nexplanation, but we found an explanation.",
    "start": "908010",
    "end": "914020"
  },
  {
    "text": "Yeah, so I think--\nbut it's a good point. It's like these things come\nout, and it's up to humans to interpret them and\ndecide if they make sense.",
    "start": "914020",
    "end": "920821"
  },
  {
    "text": "So maybe you do interpret\nthis and you're like, yeah, it makes sense earlier\none should affect it more, and then you just go with that.",
    "start": "920822",
    "end": "926769"
  },
  {
    "text": "But we always blame\nour childhood. [LAUGHTER] ",
    "start": "926770",
    "end": "933680"
  },
  {
    "text": "That was a good one. OK. So when you say spread,\ndoes that mean variance?",
    "start": "933680",
    "end": "941520"
  },
  {
    "text": "That's one way to\ncalculate spread, yeah. So when I made these colors,\nthat is what I was looking at, was variance.",
    "start": "941520",
    "end": "947329"
  },
  {
    "text": "You can pick any metric you\nwant to quantify and spread. Yeah.",
    "start": "947330",
    "end": "953990"
  },
  {
    "text": "OK. So we can also do this\nfor our taxi problem. So just to define it\na little bit more,",
    "start": "953990",
    "end": "959940"
  },
  {
    "text": "we have this image of a runway. And then what we're\ngoing to do is we're going to pass\nthis image of a runway",
    "start": "959940",
    "end": "965100"
  },
  {
    "text": "through a neural network. And it outputs a\nsteering angle that's supposed to keep us going\nstraight down the runway.",
    "start": "965100",
    "end": "972529"
  },
  {
    "text": "And this is 64 by 64, so\nit has 4,096 pixels total. And so what we\ncould do is we could",
    "start": "972530",
    "end": "978770"
  },
  {
    "text": "go through each one of\nthese pixels in here, keep everything else\nthe same, resample",
    "start": "978770",
    "end": "983810"
  },
  {
    "text": "just the value of that pixel and\nsee how it changes our steering angle. And then we can plot\nthe relative change",
    "start": "983810",
    "end": "991510"
  },
  {
    "text": "of all of these steering\nangles or the relative spread in the change of the steering\nangle on top of the image.",
    "start": "991510",
    "end": "997940"
  },
  {
    "text": "So when we do that, we\nget something like this. And so it's kind of noisy,\nbut it looks roughly",
    "start": "997940",
    "end": "1003029"
  },
  {
    "text": "like the most\nsensitive pixels are the ones that are in the portion\nof the image, which would really",
    "start": "1003030",
    "end": "1009779"
  },
  {
    "text": "help us localize where\nwe are, because it's the portion of the image that\nshows the edge lines and some of the center lines.",
    "start": "1009780",
    "end": "1015940"
  },
  {
    "text": "So we can look at this\nand be like, OK, it seems like it's paying\nattention to the thing that we expect it to.",
    "start": "1015940",
    "end": "1023880"
  },
  {
    "text": "Any questions on that?  To actually get this\nmean, you're not",
    "start": "1023880",
    "end": "1031920"
  },
  {
    "text": "perturbing each pixel, right? I am. And what might be\nthe drawback of that?",
    "start": "1031920",
    "end": "1038908"
  },
  {
    "text": "You can use backdrop. You could. Yeah. [INAUDIBLE]",
    "start": "1038909",
    "end": "1044220"
  },
  {
    "text": "Yeah. But why would we want to\ndo that instead of this? I like-- a little faster.",
    "start": "1044220",
    "end": "1050179"
  },
  {
    "text": "Yeah, it goes a little faster. Yeah, so exactly. This is pretty inefficient. So this is like what\nwe're going for.",
    "start": "1050180",
    "end": "1057490"
  },
  {
    "text": "And we want to find if we\nchange this, what happens? But doing that sampling for\nall 4,096 pixels actually takes",
    "start": "1057490",
    "end": "1065330"
  },
  {
    "text": "quite a long time to the point\nwhere when we were putting this figure in the book, I\nactually cached it so that it",
    "start": "1065330",
    "end": "1071060"
  },
  {
    "text": "doesn't redo this every\ntime the book compiles. So it is quite expensive.",
    "start": "1071060",
    "end": "1076640"
  },
  {
    "text": "And so we could reduce\nthe computational costs using backpropagation or using\nsomething called saliency maps.",
    "start": "1076640",
    "end": "1083720"
  },
  {
    "text": "And the idea behind\nsaliency maps is that they use gradients\nto identify inputs",
    "start": "1083720",
    "end": "1089000"
  },
  {
    "text": "that are most\nimportant or salient, that's where the word\ncomes from, in determining a particular outcome.",
    "start": "1089000",
    "end": "1096409"
  },
  {
    "text": "So basically all we're doing\nis we're, in this case, going to take the\ngradient of the robustness of the trajectory with\nrespect to each disturbance.",
    "start": "1096410",
    "end": "1103769"
  },
  {
    "text": "And the idea is that\ninputs that or features that have higher gradients. That means that\nsmall changes in them",
    "start": "1103770",
    "end": "1110020"
  },
  {
    "text": "will affect the output more. And so if we just plot the\nmagnitude of the gradient,",
    "start": "1110020",
    "end": "1115669"
  },
  {
    "text": "that should indicate which\nfeatures it's more sensitive to. That's the general idea.",
    "start": "1115670",
    "end": "1120857"
  },
  {
    "text": "It turns out that seems\nto work pretty well. So here's what it looked like\nwhen we did the sensitivity analysis, where we perturbed\neach one at a time sampling.",
    "start": "1120857",
    "end": "1129315"
  },
  {
    "text": "And if we just\ntake the gradient, we get something\nthat's quite similar. So that's another way to\napproximate these things.",
    "start": "1129315",
    "end": "1138070"
  },
  {
    "text": "We can also do that\nwith the taxi problem. So here's what we got\nwhen we did perturbing",
    "start": "1138070",
    "end": "1143590"
  },
  {
    "text": "each one individually. And then we take the gradient. We get something a\nlittle bit different, but it's focusing\non a similar area,",
    "start": "1143590",
    "end": "1149679"
  },
  {
    "text": "focusing on the edge\nlines of the runway.",
    "start": "1149680",
    "end": "1155020"
  },
  {
    "text": "Yeah. [INAUDIBLE] When is it worth doing both?",
    "start": "1155020",
    "end": "1161721"
  },
  {
    "text": "That's a good question. I think one point I want\nto make on this slide, and then I'm going to continue\nto make on the future slides,",
    "start": "1161722",
    "end": "1167330"
  },
  {
    "text": "is this produces a slightly\ndifferent explanation than this. And it just means they're\ndifferent definitions",
    "start": "1167330",
    "end": "1173720"
  },
  {
    "text": "of sensitivity. So maybe this one's a little\nmore local because you're taking the gradient. And that just talks\nabout a small region",
    "start": "1173720",
    "end": "1180200"
  },
  {
    "text": "around your current input. But in general,\nI think it can be difficult to interpret,\nwhy does this one seem",
    "start": "1180200",
    "end": "1187009"
  },
  {
    "text": "like it's focusing here? And this one seems like\nit's only the edge lines, and it's not always obvious. And that's one of the challenges\nwith explanation techniques,",
    "start": "1187010",
    "end": "1196049"
  },
  {
    "text": "because it's up\nto the human then to interpret whether\nthey make sense. So sometimes it might make sense\nto do a few of these methods",
    "start": "1196050",
    "end": "1202490"
  },
  {
    "text": "and see if they all\nproduce something similar. But yeah. ",
    "start": "1202490",
    "end": "1210510"
  },
  {
    "text": "OK.  Cool. And so there is still one\nissue with this method, though,",
    "start": "1210510",
    "end": "1216740"
  },
  {
    "text": "or maybe a few issues\nwith this method. But one of the issues is\nthat it might miss out on saturated features.",
    "start": "1216740",
    "end": "1224530"
  },
  {
    "text": "So here's what that means. So let's look at a\nreally simple example. So we just have\none input feature,",
    "start": "1224530",
    "end": "1229970"
  },
  {
    "text": "and we're interested\nin the output f of x. So our input feature is x,\nand our output is f of x.",
    "start": "1229970",
    "end": "1236240"
  },
  {
    "text": "So just looking\nat this plot here, does it seem like f of x is\nsensitive to the value for x,",
    "start": "1236240",
    "end": "1244640"
  },
  {
    "text": "would you say? Yeah, nodding heads. So yeah, I would agree.",
    "start": "1244640",
    "end": "1250220"
  },
  {
    "text": "I think it's\nsensitive as we change the value for x, f of x is\ndefinitely changing here.",
    "start": "1250220",
    "end": "1255940"
  },
  {
    "text": "But let's say that we were\nlooking at one individual data point. And our current\npoint was right here.",
    "start": "1255940",
    "end": "1262040"
  },
  {
    "text": "And we used the gradient to\nhelp us understand sensitivity. So then we would get a\ngradient that looks like this.",
    "start": "1262040",
    "end": "1268900"
  },
  {
    "text": "And it's pretty flat. So we're going to\nconclude that f of x is actually not really sensitive\nto x, because this gradient is",
    "start": "1268900",
    "end": "1276070"
  },
  {
    "text": "very flat. It's very small. But that's not necessarily\nwhat's going on here.",
    "start": "1276070",
    "end": "1281210"
  },
  {
    "text": "It's just that x is in a very\nsaturated point of the feature",
    "start": "1281210",
    "end": "1288450"
  },
  {
    "text": "function, basically. And so what some\npeople do instead is they say let's start\nat some baseline point.",
    "start": "1288450",
    "end": "1295750"
  },
  {
    "text": "So maybe we start at 0. And then let's take\nthe gradient there. So now we've got a\nmuch bigger gradient.",
    "start": "1295750",
    "end": "1302050"
  },
  {
    "text": "And then we can just\nmake our way continually taking gradients to the\ncurrent point that we're at.",
    "start": "1302050",
    "end": "1309390"
  },
  {
    "text": "And so now you can\nsee as we take-- and then basically what\nwe do is we average",
    "start": "1309390",
    "end": "1315990"
  },
  {
    "text": "over all of these\ngradients here. And so we'll get\nsome nonzero or not super flat gradients\nin there to show",
    "start": "1315990",
    "end": "1322710"
  },
  {
    "text": "that this output is actually\nsensitive to this input. So this algorithm specifically\nis called integrated gradients.",
    "start": "1322710",
    "end": "1329470"
  },
  {
    "text": "And basically you just start\nfrom some baseline, gradually move to the current\npoint that you're at,",
    "start": "1329470",
    "end": "1335490"
  },
  {
    "text": "and then average the\ngradients along the way. ",
    "start": "1335490",
    "end": "1341659"
  },
  {
    "text": "So I guess if you want to see\nsensitivity to nominal things,",
    "start": "1341660",
    "end": "1347930"
  },
  {
    "text": "like you may have\nsaturation for some features",
    "start": "1347930",
    "end": "1353780"
  },
  {
    "text": "in nonnominal situations,\nbut you may have,",
    "start": "1353780",
    "end": "1359210"
  },
  {
    "text": "if I can compose any image,\nthen this neural network will have remarkable amounts of\ngradient for specific pixels.",
    "start": "1359210",
    "end": "1370080"
  },
  {
    "text": "So maybe if I were to push\nall of the data set through",
    "start": "1370080",
    "end": "1379190"
  },
  {
    "text": "and then zero out the loss\nand then backprop through it or whatever procedure you\nhave, and then average",
    "start": "1379190",
    "end": "1385700"
  },
  {
    "text": "all the saliency maps versus\nstarting in a baseline.",
    "start": "1385700",
    "end": "1392086"
  },
  {
    "text": "I don't know what the\nbaseline is, but let's say it's the zero\nimage, which is not,",
    "start": "1392087",
    "end": "1398060"
  },
  {
    "text": "hopefully it wouldn't be the\ncase of the blindfolded plane, but that's out of distribution.",
    "start": "1398060",
    "end": "1404530"
  },
  {
    "text": "Yeah, I think the idea-- so I'm actually going\nto show an example next where we do start with a\nbaseline of the zero image. That seems to be\nthe common thing",
    "start": "1404530",
    "end": "1410715"
  },
  {
    "text": "that people use this method do. I think the idea is if you start\nfrom a completely black image,",
    "start": "1410715",
    "end": "1418103"
  },
  {
    "text": "and we're going to\nsee this in a second, and you make your way to the-- so you slowly basically\nincrease the brightness",
    "start": "1418103",
    "end": "1424570"
  },
  {
    "text": "until you get to the image\nthat you're interested in. Features will appear\nat some point.",
    "start": "1424570",
    "end": "1429768"
  },
  {
    "text": "At some point, you'll\nreally be able to see the edges and whatever. And then you want to capture\nbasically that moment when it",
    "start": "1429768",
    "end": "1437140"
  },
  {
    "text": "appears and get the gradient. That's the idea. And when you're doing\nthis, your current point",
    "start": "1437140",
    "end": "1442960"
  },
  {
    "text": "is one example image? Is one example image. So you would need to\npick a handful that you--",
    "start": "1442960",
    "end": "1449380"
  },
  {
    "text": "yeah, yeah. Yeah, good question. OK. So yeah, let's see that example.",
    "start": "1449380",
    "end": "1455903"
  },
  {
    "text": "So we're going to\ndo the same taxi image that we saw before, but\nright now it's completely black, so we don't actually\nsee any of the edges.",
    "start": "1455903",
    "end": "1462750"
  },
  {
    "text": "And so I'm going to play\nan animation in a second. And what I want you to\ndo is pay attention. So we're going to\nlook at the gradients.",
    "start": "1462750",
    "end": "1469289"
  },
  {
    "text": "As we move from\nthis black image, it's slowly going to increase\nthe brightness to the image that we're interested in.",
    "start": "1469290",
    "end": "1475510"
  },
  {
    "text": "And as we move from this\nimage to that image, we'll look at what the\ngradients for this pixel",
    "start": "1475510",
    "end": "1481919"
  },
  {
    "text": "right here that's\nhighlighted in blue look like and then the gradients\nfor this pixel that's",
    "start": "1481920",
    "end": "1487320"
  },
  {
    "text": "highlighted in green look like. And it's going to be plotted\nover on this axis here.",
    "start": "1487320",
    "end": "1492940"
  },
  {
    "text": "So let's just watch this here. ",
    "start": "1492940",
    "end": "1499900"
  },
  {
    "text": "OK. So that's what happens. Maybe I'll try to\nplay it one more time. Oh, that didn't work.",
    "start": "1499900",
    "end": "1506670"
  },
  {
    "text": "Oh, no. Hold on. What's happening? There we go.",
    "start": "1506670",
    "end": "1511720"
  },
  {
    "text": "OK. Play that one more time. ",
    "start": "1511720",
    "end": "1517250"
  },
  {
    "text": "OK. So basically what happened here\nis like, as we might expect,",
    "start": "1517250",
    "end": "1522830"
  },
  {
    "text": "this green pixel\nhere, it's not really near any of the edge lines. It doesn't seem like we\nshould be sensitive to that.",
    "start": "1522830",
    "end": "1528690"
  },
  {
    "text": "And in fact, we find\nthat the gradient is pretty small the\nwhole way there. Whereas this blue pixel here, we\nhave this big change in gradient",
    "start": "1528690",
    "end": "1536750"
  },
  {
    "text": "as we move from the black\nimage to our true image. Yeah. [INAUDIBLE] gradient\nor the function?",
    "start": "1536750",
    "end": "1544563"
  },
  {
    "text": "I'm calling it the gradient. The gradient. So blue is not only large in\nterms of integrated gradients,",
    "start": "1544563",
    "end": "1550470"
  },
  {
    "text": "it's also large. And gradients are keeping\nhigh the whole time. Yeah, that's true. I wish I found an example\nwhere that wasn't the case.",
    "start": "1550470",
    "end": "1557429"
  },
  {
    "text": "But yeah, this would also\nhave ended up working fine with the saliency map. Yeah. ",
    "start": "1557430",
    "end": "1566450"
  },
  {
    "text": "Any other questions on this? Yes. So this is what we call\nexplainability threat.",
    "start": "1566450",
    "end": "1573490"
  },
  {
    "text": "Yes.  So now let's say-- [LAUGHTER]",
    "start": "1573490",
    "end": "1579735"
  },
  {
    "text": "So let's say we have\ndone this, and we do explainability\nactually usually",
    "start": "1579735",
    "end": "1585570"
  },
  {
    "text": "to solve a bigger problem. So I don't know, try to\nreason how this model",
    "start": "1585570",
    "end": "1591090"
  },
  {
    "text": "can use in a greater context. Can you maybe explain\nif I do, for example, this how I can use this to solve\nwhat is that explainability",
    "start": "1591090",
    "end": "1600330"
  },
  {
    "text": "useful for, I guess? I think what explainability\nis useful for,",
    "start": "1600330",
    "end": "1605919"
  },
  {
    "text": "so I'm actually going\nto very shortly provide a word of caution about\nusing all of these things. But in my opinion,\nif the explanations",
    "start": "1605920",
    "end": "1613080"
  },
  {
    "text": "are true to what's\ngoing on, what's useful for having explainability\nis like your system could be",
    "start": "1613080",
    "end": "1620820"
  },
  {
    "text": "fooling you that it's correct. You always want to still\nscrutinize good results too, because you might have some\nbug that actually caused",
    "start": "1620820",
    "end": "1627570"
  },
  {
    "text": "you to get the good results. So we could do all of these\nother validation things and be like, oh, the probability\nof failure is really low.",
    "start": "1627570",
    "end": "1633287"
  },
  {
    "text": "Or like we proved that under\nthese assumptions it works. But maybe it's working\nfor all the wrong reasons and then it's not going\nto generalize correctly.",
    "start": "1633287",
    "end": "1640630"
  },
  {
    "text": "And so in my opinion, what\nexplainability would do is give you some extra\nconfidence to be like, no, it's focusing\non the right thing.",
    "start": "1640630",
    "end": "1646180"
  },
  {
    "text": "It's focusing on\nthe feature that we think it should be focusing\non to make this decision.",
    "start": "1646180",
    "end": "1653190"
  },
  {
    "text": "So that's how I\nwould say to use it. Yeah. It might also help\nyou understand",
    "start": "1653190",
    "end": "1658560"
  },
  {
    "text": "where you might find-- where you might have additional\nfailure modes of your system. Use very big words like prove\nand generalization related",
    "start": "1658560",
    "end": "1667140"
  },
  {
    "text": "to this. But yeah. Well, yeah, I think\nif you find that it's focusing on these\nlines, I might expect",
    "start": "1667140",
    "end": "1674850"
  },
  {
    "text": "it to generalize to another\nimage where there's lines. I think it's coming, but we\ndon't have to go into this, but I think there's a\nbunch of papers that show",
    "start": "1674850",
    "end": "1680820"
  },
  {
    "text": "that you can get good looking. But you can use methods\nlike this saliency maps, and it looks good. But actually this is a\nvery misleading result,",
    "start": "1680820",
    "end": "1689020"
  },
  {
    "text": "and the model doesn't really-- Yeah, we're going\nto get to that. I agree with you. I had a whole hour of\ndiscussion about this.",
    "start": "1689020",
    "end": "1694970"
  },
  {
    "text": "We did have a\ndiscussion about this. It's a bit contentious. So anyway, but I'm\nshowing you the basics.",
    "start": "1694970",
    "end": "1701679"
  },
  {
    "text": "This is what people-- OK, in I think,\nyeah, in general. So you can even get different\nexplanations of doing this.",
    "start": "1701680",
    "end": "1708080"
  },
  {
    "text": "So I think integrated gradients\nit did in fact smooth out what was going on\nwith the taxi thing.",
    "start": "1708080",
    "end": "1713299"
  },
  {
    "text": "Now it seems very\nclear that we're looking at the edge\nlines of the runway. These are all just different\ndefinitions of sensitivity.",
    "start": "1713300",
    "end": "1719540"
  },
  {
    "text": "So we have to decide as humans\nwhat we want to make of it. Yeah, did you have a question?",
    "start": "1719540",
    "end": "1725680"
  },
  {
    "text": "I'm just a little mixed up on\nwhat baseline input is here. Is that problem-specific?",
    "start": "1725680",
    "end": "1732220"
  },
  {
    "text": "Is problem-specific. For images, people often will\nuse an entirely black image or an entirely white image.",
    "start": "1732220",
    "end": "1739840"
  },
  {
    "text": "But you just have\nto pick something. ",
    "start": "1739840",
    "end": "1745929"
  },
  {
    "text": "Any other questions? Hard to say. The most useful reason why\nI've done this in my life",
    "start": "1745930",
    "end": "1754590"
  },
  {
    "text": "is to identify real buckets\nof why your model is failing at test time.",
    "start": "1754590",
    "end": "1760300"
  },
  {
    "text": "And now you have three\nbuckets, and then you add more data to call to\nimprove it on those models.",
    "start": "1760300",
    "end": "1766590"
  },
  {
    "text": "And so if you want to know\nwhy, if you want to improve it, it's not working. I got 80% F1 score.",
    "start": "1766590",
    "end": "1772960"
  },
  {
    "text": "Cool. What do you do? OK. So you use it like to identify\nwhy things might be failing",
    "start": "1772960",
    "end": "1778980"
  },
  {
    "text": "or where you might\nneed more data. Yeah, for example, at Apple,\nwe didn't get into it,",
    "start": "1778980",
    "end": "1785500"
  },
  {
    "text": "but we were using parking\nlots and golf courses because the trajectories\nare very similar in both.",
    "start": "1785500",
    "end": "1792840"
  },
  {
    "text": "Your GPS data is going to look\nvery similar in both situations. And so we were like, oh, well,\nwe can identify that these are--",
    "start": "1792840",
    "end": "1801360"
  },
  {
    "text": "in the world, this\nis the map that we're getting really inaccurate on. And what are the-- oh,\nthat's a parking lot,",
    "start": "1801360",
    "end": "1806370"
  },
  {
    "text": "and that's a golf course. OK, we need more data or\nadd RGB because one does not",
    "start": "1806370",
    "end": "1812750"
  },
  {
    "text": "look like the other. So you can add\nthose conversations. But I think there what\nyou're actually doing--",
    "start": "1812750",
    "end": "1819090"
  },
  {
    "text": "and I think that this is a great\napproach for interpretability, but actually you're\nlooking at the samples",
    "start": "1819090",
    "end": "1824660"
  },
  {
    "text": "that you do poorly on. And then you actually\nconsider metadata about it.",
    "start": "1824660",
    "end": "1830370"
  },
  {
    "text": "So you take the set\nof great samples, and then you notice, oh, these\nare actually all golf course",
    "start": "1830370",
    "end": "1835850"
  },
  {
    "text": "images. But now the feature that\nyou're actually interpreting is the fact that\nit's a golf course",
    "start": "1835850",
    "end": "1841429"
  },
  {
    "text": "and not whether the\npixel is green or gray. [INAUDIBLE] was a golf course. It's actually saliency on\ngeospatial on the full globe.",
    "start": "1841430",
    "end": "1849060"
  },
  {
    "text": "So we were like, we\nhave a net going in and output and then output in\nsome class we wanted to attack.",
    "start": "1849060",
    "end": "1855290"
  },
  {
    "text": "And then we did this and that. And this is the areas\nthat we do worse on.",
    "start": "1855290",
    "end": "1861200"
  },
  {
    "text": "[INAUDIBLE] versus a big block. Now it's the\nspecific pixel that's really causing a lot of issues.",
    "start": "1861200",
    "end": "1867830"
  },
  {
    "text": " Yeah, I guess one more use for\nexplainability, if done well,",
    "start": "1867830",
    "end": "1875030"
  },
  {
    "text": "is sometimes you\nhave shareholders that they need an explanation. So there's some\nregulations, like, if you're",
    "start": "1875030",
    "end": "1881538"
  },
  {
    "text": "operating in certain\ndomains, they actually require you to be\nable to explain what your system is doing, whether\nit's a faithful explanation",
    "start": "1881538",
    "end": "1887700"
  },
  {
    "text": "or not. And so you need to be\nable to provide these. And ideally they're\nworking correctly.",
    "start": "1887700",
    "end": "1894820"
  },
  {
    "text": "OK. And there's a ton of others. So I just touched\non saliency maps, or the vanilla saliency map is\nthis gradient magnitude thing.",
    "start": "1894820",
    "end": "1903320"
  },
  {
    "text": "That's one I touched on. I touched on\nintegrated gradients, but there's a ton of other\nversions of these things",
    "start": "1903320",
    "end": "1908410"
  },
  {
    "text": "that people have come up with. SmoothGrad is a popular\none where you just take the gradient of a bunch\nof noisy versions of your image",
    "start": "1908410",
    "end": "1915040"
  },
  {
    "text": "and average that together. There's just a ton of these. But here we go.",
    "start": "1915040",
    "end": "1920630"
  },
  {
    "text": "You should be careful. So this is my word\nof warning to you. So this actually comes\nfrom a paper that's--",
    "start": "1920630",
    "end": "1925663"
  },
  {
    "text": "well, specifically this\npaper called sanity checks for saliency maps. And they're basically talking\nabout how a lot of these things",
    "start": "1925663",
    "end": "1933240"
  },
  {
    "text": "you need to be careful\nthe information that you draw from them. And basically the idea here is\nthey have this image of a bird,",
    "start": "1933240",
    "end": "1940410"
  },
  {
    "text": "and they're providing\nexplanations for why it's calling it a bird. And each of these different\ntypes of explanations",
    "start": "1940410",
    "end": "1948179"
  },
  {
    "text": "produces a different\nsaliency map. But it all looks like the bird.",
    "start": "1948180",
    "end": "1953380"
  },
  {
    "text": "And then it turns out, though,\nif you just take the image-- you ignore the model that you're\ntrying to explain completely.",
    "start": "1953380",
    "end": "1960240"
  },
  {
    "text": "You just put the image\nthrough an edge detector. You get this image\non the right here, which just looks like all the\nexplanations that we saw before.",
    "start": "1960240",
    "end": "1968950"
  },
  {
    "text": "And that's not so good. We don't want the\nexplanation of the model that we're trying to explain\nto not depend on the model",
    "start": "1968950",
    "end": "1976290"
  },
  {
    "text": "that we're trying to explain. That's not a good thing. And so what's interesting is\nthey note in just their abstract",
    "start": "1976290",
    "end": "1983180"
  },
  {
    "text": "here-- they say through\nextensive experiments we show that some existing\nsaliency methods are",
    "start": "1983180",
    "end": "1988190"
  },
  {
    "text": "both independent of the\nmodel, which, as I just said, and the data generating process. So they also show in this\npaper that you could just",
    "start": "1988190",
    "end": "1995095"
  },
  {
    "text": "like mix up all the\nlabels of your data, and then you still get the same\nexplanation for why everything is, which shouldn't be true.",
    "start": "1995095",
    "end": "2001460"
  },
  {
    "text": "Yeah. But this is not entirely bad in\nthe sense of this is [INAUDIBLE] [LAUGHTER]",
    "start": "2001460",
    "end": "2007292"
  },
  {
    "text": "This is like-- maybe I'm\n[INAUDIBLE] pretraining brain and that's why I'm\nthinking about this. But in some sense, you're\nlearning some feature",
    "start": "2007292",
    "end": "2014988"
  },
  {
    "text": "about the picture that's\ninherent to the picture. If I see a picture of a bird,\nno matter what I'm trying to do, it's like a bird.",
    "start": "2014988",
    "end": "2020360"
  },
  {
    "text": "And then whatever the downstream\ntask is, it's like a bird. And learning to learn-- the model learning\nto look at edges",
    "start": "2020360",
    "end": "2026620"
  },
  {
    "text": "is never a good thing, no\nmatter what I'm trying to do. I think you are in a\npretraining brain, I think.",
    "start": "2026620",
    "end": "2034870"
  },
  {
    "text": "[LAUGHTER] Because they actually\ndo talk in this paper about how there are\ncertain architectures that",
    "start": "2034870",
    "end": "2040220"
  },
  {
    "text": "have inductive biases. So yes, you put a\nconvolutional network, and then even if you\nhave random weights,",
    "start": "2040220",
    "end": "2046980"
  },
  {
    "text": "you still might get an\nedge detector anyway. But the gradient [INAUDIBLE]",
    "start": "2046980",
    "end": "2052450"
  },
  {
    "text": "Third. Which? This gradient? Yeah. [INAUDIBLE] I don't know if that\nreally looks like anything.",
    "start": "2052450",
    "end": "2060750"
  },
  {
    "text": "But yeah. So that's one thing\nto be cautious about and actually just\nto build on that. So this is very concerning.",
    "start": "2060750",
    "end": "2068510"
  },
  {
    "text": "So this is basically that row\nthat we were just seeing here with all of the\ndifferent methods with the original explanation.",
    "start": "2068510",
    "end": "2074820"
  },
  {
    "text": "And then what they did in this\npaper was they took each row. They went layer by\nlayer in the network",
    "start": "2074820",
    "end": "2081169"
  },
  {
    "text": "and just replaced the weights of\neach layer with random weights. So here they just\nreplaced the end layer",
    "start": "2081170",
    "end": "2086300"
  },
  {
    "text": "with random weights,\njust the logits. And then as you move to\nthe right in this plot, once you get all\nthe way here, you",
    "start": "2086300",
    "end": "2091330"
  },
  {
    "text": "have a completely\nrandom network. So it's not the\nsame model at all that you were trying\nto explain before. And they just look the same\nas you go all the way across.",
    "start": "2091330",
    "end": "2100099"
  },
  {
    "text": "So this is very concerning. They showed that\nsome of the methods this doesn't seem to happen,\nlike, I think, this one maybe.",
    "start": "2100100",
    "end": "2107200"
  },
  {
    "text": "I don't really know. But it's just some caution\nthat you should take this",
    "start": "2107200",
    "end": "2114268"
  },
  {
    "text": "into account when you're going\nto try to apply these methods. I think it's easy\nfor us as humans to make explanations\nout of things",
    "start": "2114268",
    "end": "2120800"
  },
  {
    "text": "if we stare at them\nfor long enough, but it's not always a\nfaithful explanation. So in general, we should\nbe careful to ensure",
    "start": "2120800",
    "end": "2127720"
  },
  {
    "text": "that we do not find meaning\nwhere there isn't any. I really thought there\nwould be a good joke here, and I ran out of time.",
    "start": "2127720",
    "end": "2134030"
  },
  {
    "text": "So sorry. We're at that point\nin the quarter. But this sent me a really funny\nthing right around this moment",
    "start": "2134030",
    "end": "2142840"
  },
  {
    "text": "last night. And so I was like, oh, I'll\njust throw this in there. OK. So I've seen things\nlike this before.",
    "start": "2142840",
    "end": "2149000"
  },
  {
    "text": "Actually one of our labmates\nwrote one of these for Julia. But this is honestly, I\nthink one of the best ones",
    "start": "2149000",
    "end": "2155244"
  },
  {
    "text": "that I've seen. So I'll just let you appreciate\nit for like 10 seconds or so. Because there's some\nreally good stuff in here.",
    "start": "2155245",
    "end": "2161638"
  },
  {
    "text": "[INAUDIBLE] Is it? There is an animal rescue. Does it throw rocks?",
    "start": "2161638",
    "end": "2170880"
  },
  {
    "text": "Exceptions are weird, but\nit does do something similar to that. Gotcha. Gotcha.",
    "start": "2170880",
    "end": "2176490"
  },
  {
    "text": "Yeah, this one's just-- it's\ngood to think things over. --everyone it all makes sense. Yeah.",
    "start": "2176490",
    "end": "2182280"
  },
  {
    "text": "Even though I'm a\nmillennial, I can [INAUDIBLE] Vibe?",
    "start": "2182280",
    "end": "2188339"
  },
  {
    "text": "Yeah. [INAUDIBLE] It's so cute.",
    "start": "2188340",
    "end": "2194760"
  },
  {
    "text": "Oh, yeah. ",
    "start": "2194760",
    "end": "2201450"
  },
  {
    "text": "Yeah. Anyway.",
    "start": "2201450",
    "end": "2206777"
  },
  {
    "text": "He had some help anyway. What is the ratio [INAUDIBLE]?",
    "start": "2206778",
    "end": "2213060"
  },
  {
    "text": "Oh, no. OK. What have we got? All right. Moving on. You can download\nthe slides later",
    "start": "2213060",
    "end": "2219830"
  },
  {
    "text": "if you're not done\nlooking at it. I think on interpretability,\nif you want something",
    "start": "2219830",
    "end": "2227059"
  },
  {
    "text": "beyond the grad-cam, I\nthink these days there's this topic called mechanistic\ninterpretability, which",
    "start": "2227060",
    "end": "2232850"
  },
  {
    "text": "is hot right now. But it's very much\nan unsolved problem. But that tries to solve the--",
    "start": "2232850",
    "end": "2238160"
  },
  {
    "text": "oh, instead of doing\ninterpretability on a pixel level, can\nwe do interpretability on a semantic level?",
    "start": "2238160",
    "end": "2244372"
  },
  {
    "text": "A bird is made up of a beak and\na wing and these kind of things. And I think it's an\namazing research topic.",
    "start": "2244372",
    "end": "2249750"
  },
  {
    "text": "If you're looking for\nresearch problems. That equivalently have\nthe same issues of this,",
    "start": "2249750",
    "end": "2255099"
  },
  {
    "text": "like, it could be\ncomplete nonsense. Yeah, you can talk if you want. So alternate opinion.",
    "start": "2255100",
    "end": "2262280"
  },
  {
    "text": "Sorry, you had an\nhour-long conversation about how you dislike\nmechanistic interpretability because I think it's actually\nexacerbating this problem,",
    "start": "2262280",
    "end": "2268393"
  },
  {
    "text": "not minimizing it. Highly contentious topics today. Yes.",
    "start": "2268393",
    "end": "2273590"
  },
  {
    "text": "All right. Blind spot. OK. But I think all of this is\nreally good to think about.",
    "start": "2273590",
    "end": "2280350"
  },
  {
    "text": "And one thing that\ngives me hope is if we can really get to the core\nof what these models are doing,",
    "start": "2280350",
    "end": "2286080"
  },
  {
    "text": "and we can have these\nexplanations that really do explain what's going\non, I think there's a lot you can do about them.",
    "start": "2286080",
    "end": "2291440"
  },
  {
    "text": "But there's research to be\ndone, I think is where we're at. OK. So that's sensitivity analysis.",
    "start": "2291440",
    "end": "2298188"
  },
  {
    "text": "And then the other thing\nabout feature importance that I want to talk\nabout is these things called Shapley values.",
    "start": "2298188",
    "end": "2303290"
  },
  {
    "text": "And basically the\nkey difference here is that when we were just\ndoing sensitivity analysis, we were looking at the\neffect of varying only one",
    "start": "2303290",
    "end": "2310610"
  },
  {
    "text": "feature at a time. Whereas for Shapley\nvalues, we're able to actually capture\ninteractions between features.",
    "start": "2310610",
    "end": "2319130"
  },
  {
    "text": "So let me motivate why\nwe might want to do this or where this might matter. So we're going to consider\na super simplified",
    "start": "2319130",
    "end": "2325970"
  },
  {
    "text": "version of a wildfire scenario. So imagine we have some\nregion of the world. And we have divided that\nregion into different cells",
    "start": "2325970",
    "end": "2332789"
  },
  {
    "text": "that could either be\nburning or not burning. So the not burning\ncells are in white, and the burning\ncells are in red.",
    "start": "2332790",
    "end": "2338860"
  },
  {
    "text": "And let's say that\nmost of this is land that is not really occupied. So we're not super\nconcerned about it. But in this upper right\ncorner here, maybe there's",
    "start": "2338860",
    "end": "2345743"
  },
  {
    "text": "some expensive property\nor homes or people, and we want to make\nsure that this is not going to catch on fire.",
    "start": "2345743",
    "end": "2351388"
  },
  {
    "text": "Or at least we want to\nunderstand the probability that this particular\ncorner catches on fire.",
    "start": "2351388",
    "end": "2357510"
  },
  {
    "text": "So this is our current state. We're going to represent a state\nas just which cells are burning and which are not burning.",
    "start": "2357510",
    "end": "2362770"
  },
  {
    "text": "And then we're going to have a\nvery simple version of dynamics for this problem, where the\nprobability that a cell is",
    "start": "2362770",
    "end": "2370440"
  },
  {
    "text": "burning at the next time\nstep is going to be 1. If it was burning at\nthe previous time step, so we'll just assume it's\ngoing to stay burning.",
    "start": "2370440",
    "end": "2377520"
  },
  {
    "text": "And then every cell\nthat's neighboring a cell that's burning at\nthe previous time step",
    "start": "2377520",
    "end": "2382710"
  },
  {
    "text": "has a 30% chance that it's\nburning at the next time step. So all these probabilities\nare just zeros here.",
    "start": "2382710",
    "end": "2389050"
  },
  {
    "text": "And then this is neighboring\na cell that was burning. So it's 0.3 and so on.",
    "start": "2389050",
    "end": "2394609"
  },
  {
    "text": "So basically now we can say\nthat in this kind of cell that we care about, we\nknow that the probability that it's burning at the\nnext time step is 0.3.",
    "start": "2394610",
    "end": "2404890"
  },
  {
    "text": "OK. So now let's look at this\ncell, particularly right here. So say this is the feature\nthat we're interested in.",
    "start": "2404890",
    "end": "2410970"
  },
  {
    "text": "So we'll say each of\nour features is a cell. We're interested\nin this feature. Does this cell have an\neffect on the probability",
    "start": "2410970",
    "end": "2418490"
  },
  {
    "text": "of the upper right\ncorner burning? What do you guys think?",
    "start": "2418490",
    "end": "2424280"
  },
  {
    "text": "Yes. Yeah, I would say that it does. But if we're doing\nsensitivity analysis here's",
    "start": "2424280",
    "end": "2429330"
  },
  {
    "text": "what would happen. We would just remove\nthis one feature. We would change\njust this feature.",
    "start": "2429330",
    "end": "2434670"
  },
  {
    "text": "And then if we look at our\nprobability of the cell burning",
    "start": "2434670",
    "end": "2439910"
  },
  {
    "text": "at the next time step with\njust this one removed, it's still equal to 0.3, because\nwe still had this cell burning.",
    "start": "2439910",
    "end": "2446280"
  },
  {
    "text": "And so this one is giving\nit this 0.3 probability, because we just need one\nof the neighboring cells to be burning for it to\nhave a 0.3 chance of burning",
    "start": "2446280",
    "end": "2454840"
  },
  {
    "text": "at the next time step. So if we were just doing this\nsensitivity analysis, where we just consider one\nfeature at a time,",
    "start": "2454840",
    "end": "2460730"
  },
  {
    "text": "we would actually conclude that\nthis cell here has basically no effect on the probability\nthat this cell is",
    "start": "2460730",
    "end": "2467710"
  },
  {
    "text": "burning at the next time step. Yeah. Actually, we would conclude\nthat either has an effect on--",
    "start": "2467710",
    "end": "2473320"
  },
  {
    "text": "This one too? This one too? Yeah. Yeah, we'd also conclude that. That's correct.",
    "start": "2473320",
    "end": "2478880"
  },
  {
    "text": "Yeah. So basically what's\ngoing on here is we're missing out\non the interactions between these features,\nbecause it does still matter.",
    "start": "2478880",
    "end": "2485300"
  },
  {
    "text": "We need at least one of\nthese two to be burning. And so it does seem like\nit still affects it.",
    "start": "2485300",
    "end": "2490630"
  },
  {
    "text": "And so yeah, if we get\nrid of this one as well, then we see that\nit will actually",
    "start": "2490630",
    "end": "2496055"
  },
  {
    "text": "change the probability that it's\nburning at the next time step, because now it has no chance.",
    "start": "2496055",
    "end": "2501369"
  },
  {
    "text": "And so in general, what\nwe want to do is actually consider the effect of\nchanging subsets of features,",
    "start": "2501370",
    "end": "2507210"
  },
  {
    "text": "not just changing one\nfeature at a time. And so to do this, we use\nsomething called Shapley values.",
    "start": "2507210",
    "end": "2515180"
  },
  {
    "text": "And here's basically the idea. So we're going to go back\nto our wildfire scenario.",
    "start": "2515180",
    "end": "2520313"
  },
  {
    "text": "And we'll just go back to\nthe state that we were in. Again, we're concerned about the\nprobability of this cell burning",
    "start": "2520313",
    "end": "2525350"
  },
  {
    "text": "at the next time step. And then what we're\ngoing to do is we're going to say we're\ninterested in the Shapley value",
    "start": "2525350",
    "end": "2531770"
  },
  {
    "text": "for this particular feature. So we don't want to get zero. We're hoping that\nwe can actually show that it is, in fact,\nsensitive to this feature.",
    "start": "2531770",
    "end": "2538460"
  },
  {
    "text": "And then we're going to fix just\nsome random subset of cells. So I just picked\na random subset.",
    "start": "2538460",
    "end": "2543839"
  },
  {
    "text": "All of these blue\ncells are fixed. We're going to say they\nalways keep the same value. So if they're burning,\nthey'll always be burning.",
    "start": "2543840",
    "end": "2550412"
  },
  {
    "text": "If they're not burning,\nthey'll always not be burning. And then what we're going to do\nis all of the rest of the cells",
    "start": "2550412",
    "end": "2555980"
  },
  {
    "text": "are the ones that are not blue. We're going to randomly\nsample whether they're burning",
    "start": "2555980",
    "end": "2562130"
  },
  {
    "text": "or not, given the probabilities\nof those things occurring. So then let's say we randomly\nresampled all the ones that",
    "start": "2562130",
    "end": "2569620"
  },
  {
    "text": "weren't fixed. And now actually both of\nthese turned to not burning. They got resampled.",
    "start": "2569620",
    "end": "2574750"
  },
  {
    "text": "And now we look at this\nprobability over here. And we see that the probability\nthat it's burning is 0.",
    "start": "2574750",
    "end": "2581320"
  },
  {
    "text": "Then we're going to repeat\nthis exact same process. Except we're going to\nfix this cell to what",
    "start": "2581320",
    "end": "2586750"
  },
  {
    "text": "its original feature value was. So we're going to fix cell i. We're going to add that to the\nsubset of cells that's fixed.",
    "start": "2586750",
    "end": "2592640"
  },
  {
    "text": "So it's back to burning, and now\nwe have this 0.3 probability. And then we're going to look at\nthe difference between these two",
    "start": "2592640",
    "end": "2598960"
  },
  {
    "text": "scenarios. So basically what\nwe're saying is we have this subset where\nthis value was fixed to what its original value was.",
    "start": "2598960",
    "end": "2604730"
  },
  {
    "text": "And then we have this\nsubset where we let this value be randomly sampled. And we're going to look at the\ndifference in the feature value",
    "start": "2604730",
    "end": "2612190"
  },
  {
    "text": "that we care about\nfor when it was fixed versus when it was not fixed.",
    "start": "2612190",
    "end": "2617540"
  },
  {
    "text": "So what we did was\nwe basically said, OK, we're going\nto fix the subset. We're going to\nresample all the rest. And one of the times\nwhen we fixed the subset,",
    "start": "2617540",
    "end": "2624458"
  },
  {
    "text": "we're going to include\nthe feature we care about. And one of the times,\nwe're not going to include the feature\nthat we care about.",
    "start": "2624458",
    "end": "2629680"
  },
  {
    "text": "And that will give\nus-- if we take the difference between these\ntwo things, that will give us an idea of how much\nof a difference,",
    "start": "2629680",
    "end": "2635010"
  },
  {
    "text": "including versus not including\nthat feature makes basically. Yeah.",
    "start": "2635010",
    "end": "2640230"
  },
  {
    "text": "How do you choose the\nbest of the blue boxes? How do I choose\nwhich ones are blue?",
    "start": "2640230",
    "end": "2646960"
  },
  {
    "text": "Yeah. Randomly pick a subset. So we randomly pick a subset. Mm-hmm. And in addition, we then freeze\nand unfreeze a certain feature.",
    "start": "2646960",
    "end": "2655690"
  },
  {
    "text": "And then once we unfreeze it,\nwe also randomly sampled out. Yep. We freeze and\nunfreeze the feature",
    "start": "2655690",
    "end": "2661140"
  },
  {
    "text": "that we're interested in\ncomputing the Shapley value of. But what if we happen to\nrandomly pick the other one,",
    "start": "2661140",
    "end": "2667650"
  },
  {
    "text": "like, the one that was causing\nit, the one that looked like--",
    "start": "2667650",
    "end": "2672750"
  },
  {
    "text": "the one in-- What if we picked this one? Yeah. ",
    "start": "2672750",
    "end": "2678790"
  },
  {
    "text": "We would also get 0.3\nhere, and this would be 0. But you want to do it. We imagine doing this like 30\ntimes and averaging the results.",
    "start": "2678790",
    "end": "2685215"
  },
  {
    "text": "Yeah.  OK. And so basically what we're\ndoing for Shapley values,",
    "start": "2685215",
    "end": "2691902"
  },
  {
    "text": "it can be a little bit difficult\nto wrap your head around. But basically what\nwe're doing is we say we want to take the\nexpectation of this difference,",
    "start": "2691903",
    "end": "2698250"
  },
  {
    "text": "so including versus\nnot including, across all possible subsets. So here we did this subset.",
    "start": "2698250",
    "end": "2703860"
  },
  {
    "text": "Imagine we ran it\n30 times, computed this difference, all those\n30 times, got some value.",
    "start": "2703860",
    "end": "2710369"
  },
  {
    "text": "And then we want to just\ntake all possible subsets and do this same thing.",
    "start": "2710370",
    "end": "2716060"
  },
  {
    "text": "Can anyone think of what\nmight be a problem here? ",
    "start": "2716060",
    "end": "2721880"
  },
  {
    "text": "Yeah. There's way too many\ndifferent substates to check. Yeah, yeah. There's a ton of subsets.",
    "start": "2721880",
    "end": "2727950"
  },
  {
    "text": "So the challenge is that\nthere's quite a few of them. And in this example where we\njust have 25 features, even",
    "start": "2727950",
    "end": "2734780"
  },
  {
    "text": "there's over 16 million\npossible subsets. So for every feature we want to\ncompute the Shapley value of,",
    "start": "2734780",
    "end": "2739960"
  },
  {
    "text": "we would have to try all\n16 million subsets, do that randomly sampling\na bunch of times to estimate the\nexpectation, and so on.",
    "start": "2739960",
    "end": "2746450"
  },
  {
    "text": "And this just basically\nbecomes intractable. And in practice\nthen what people do is they'll just randomly\nsample a few different subsets,",
    "start": "2746450",
    "end": "2754600"
  },
  {
    "text": "and it actually tends to provide\na pretty reasonable estimate. So you can just implement\nthis by randomly",
    "start": "2754600",
    "end": "2761140"
  },
  {
    "text": "sampling some of the subsets. And you don't need to go\nthrough all 16 million of them.",
    "start": "2761140",
    "end": "2767289"
  },
  {
    "text": "Any questions on that? ",
    "start": "2767290",
    "end": "2772930"
  },
  {
    "text": "Yeah. Yeah. Each of the 16 million\nsubsets you would then need to perform the sampling\nwhere you like hold some fixed.",
    "start": "2772930",
    "end": "2780619"
  },
  {
    "text": "And so it'd be actually\nlike k times 16 million. I s that-- Yeah. Yeah, exactly.",
    "start": "2780620",
    "end": "2786160"
  },
  {
    "text": "I mean technically it's defined\nin terms of the expectation. But that's another thing\nyou have to estimate. So then yeah, you're basically\nestimating that expectation.",
    "start": "2786160",
    "end": "2793190"
  },
  {
    "text": " OK. So yeah, and then I just\nwant you to get in your mind",
    "start": "2793190",
    "end": "2800790"
  },
  {
    "text": "that all that's\ngoing on, it's a lot. And I didn't show\nthe math purposefully because I think that's even\nmore confusing to parse.",
    "start": "2800790",
    "end": "2807280"
  },
  {
    "text": "But basically we're just\nlooking at all possible subsets, seeing how including a feature\nversus not including a feature",
    "start": "2807280",
    "end": "2814619"
  },
  {
    "text": "in that subset affects it. And then that gives us an idea\nof how important that feature is in the context of all of the\nother features that we have.",
    "start": "2814620",
    "end": "2823559"
  },
  {
    "text": "So here's what the Shapley\nvalues for our inverted pendulum look like. And you can see\nthe Shapley values",
    "start": "2823560",
    "end": "2829530"
  },
  {
    "text": "are like the highest for some\nof these disturbances that make it seem like it's closer\nto upright than it actually is,",
    "start": "2829530",
    "end": "2836500"
  },
  {
    "text": "which makes sense. So if we make the pendulum think\nthat it's closer to upright, it won't apply enough\ntorque to actually move it",
    "start": "2836500",
    "end": "2843420"
  },
  {
    "text": "towards upright. And so these should\nbe the things that really have an effect\non the final outcome of the trajectory.",
    "start": "2843420",
    "end": "2850320"
  },
  {
    "text": "And we can verify this. So what we could do is we\ncould say like what happens if we remove, let's say, the\nfeature with the fourth highest",
    "start": "2850320",
    "end": "2856820"
  },
  {
    "text": "Shapley value? So we just take that\ndisturbance, and we set it to 0. Then we can see that\nthe new trajectory, it",
    "start": "2856820",
    "end": "2863210"
  },
  {
    "text": "changes a little bit. It's like a little less close to\nfailing, but it's still failing. Then we can say, let's take\nthe one with the second highest",
    "start": "2863210",
    "end": "2870300"
  },
  {
    "text": "Shapley value also changes a\nlittle bit, the third highest, and the fourth highest. But then if we\ntake away all four",
    "start": "2870300",
    "end": "2877099"
  },
  {
    "text": "of these features at the same\ntime, so we zero out all four of these disturbances, we\nget a pretty huge difference",
    "start": "2877100",
    "end": "2883190"
  },
  {
    "text": "in the trajectory. And so we're basically finding\nout what are the four features? If we wanted to\nremove four features",
    "start": "2883190",
    "end": "2889280"
  },
  {
    "text": "or control our disturbances\nat these four time steps, the trajectory would be\nnot a failure anymore.",
    "start": "2889280",
    "end": "2896720"
  },
  {
    "text": "So that's what the Shapley\nvalues can give you. Yeah. So to get to these four we take\ntop k of the Shapley values?",
    "start": "2896720",
    "end": "2903860"
  },
  {
    "text": "Yeah, that's what I did. Yeah. Yeah. Yeah. [INAUDIBLE] these two\nvalues are [INAUDIBLE]",
    "start": "2903860",
    "end": "2913350"
  },
  {
    "text": "or is it to see the\ninteraction of features",
    "start": "2913350",
    "end": "2918570"
  },
  {
    "text": "for an entire final trajectory\nkind of thing rather than that? Because I guess in\nthe previous example",
    "start": "2918570",
    "end": "2924990"
  },
  {
    "text": "where we had the\nwildfire, I thought it was each subset\ninteracting with one another",
    "start": "2924990",
    "end": "2932940"
  },
  {
    "text": "rather than the\nactual output of one. So maybe I'm just not\nhaving [INAUDIBLE]",
    "start": "2932940",
    "end": "2938250"
  },
  {
    "text": "Yeah, so I think\nwhat's cool about all these explainability methods\nis they're very broad. Do you want to just know what is\nthe effect on some output given",
    "start": "2938250",
    "end": "2947250"
  },
  {
    "text": "some set of input features? So in the wildfire\ncase, the output was whether or not that\ntop right cell was burning.",
    "start": "2947250",
    "end": "2953680"
  },
  {
    "text": "And the input features\nwere whether or not all of the other cells\nwere burning basically.",
    "start": "2953680",
    "end": "2960840"
  },
  {
    "text": "In this case, the output is the\nrobustness of the trajectory, and the input is the\ndisturbance at each time step.",
    "start": "2960840",
    "end": "2967510"
  },
  {
    "text": "So in one case,\nthe features were at a single snapshot in time.",
    "start": "2967510",
    "end": "2973080"
  },
  {
    "text": "And in this case,\nthey're over time. Does that make sense? ",
    "start": "2973080",
    "end": "2980750"
  },
  {
    "text": "Any other questions on this? ",
    "start": "2980750",
    "end": "2987490"
  },
  {
    "text": "[INAUDIBLE] thing I'm\njust saying [INAUDIBLE]",
    "start": "2987490",
    "end": "2992900"
  },
  {
    "text": "it's not all subsets, but it's\nin this example, when you're",
    "start": "2992900",
    "end": "2998359"
  },
  {
    "text": "turning one disturbance on and\noff, but the process would be,",
    "start": "2998360",
    "end": "3005150"
  },
  {
    "text": "I create a random\nassignment of disturbances. I do it and I have this\none disturbance on,",
    "start": "3005150",
    "end": "3012220"
  },
  {
    "text": "one disturbance be off. I get two values I subtract. And then I do it again\nfor another assignment,",
    "start": "3012220",
    "end": "3018933"
  },
  {
    "text": "and another\nassignment [INAUDIBLE] Yeah, well, so you have-- --assignments could be\ncompletely not possible or rare.",
    "start": "3018933",
    "end": "3026740"
  },
  {
    "text": "You'd want it to be\nsomewhat nominal. Yeah, so you would basically\ntake the trajectory you have.",
    "start": "3026740",
    "end": "3032487"
  },
  {
    "text": "So say you have a\nfailure trajectory. You're like, I\nwant to understand the contribution\nof each disturbance to causing this\nfailure, basically.",
    "start": "3032488",
    "end": "3038380"
  },
  {
    "text": "Then you would say, every time\nyou compute that difference, you're going to sample\na random subset,",
    "start": "3038380",
    "end": "3044950"
  },
  {
    "text": "so basically a random\nsubset of time steps. You're going to say I'm\ngoing to fix the disturbances at those time steps.",
    "start": "3044950",
    "end": "3050279"
  },
  {
    "text": "I'm going to change\nthe disturbances at all of the other time steps. See what the robustness is.",
    "start": "3050280",
    "end": "3055660"
  },
  {
    "text": "Then I'm going to include\nthe feature that I care about in the set that's fixed.",
    "start": "3055660",
    "end": "3060828"
  },
  {
    "text": "And then I'm going to\ntake that difference. And then the next\ntime you're going to sample another random\nsubset and you're just going to keep doing this.",
    "start": "3060828",
    "end": "3066339"
  },
  {
    "text": "Does that make sense? Yeah, I guess it's the random\npart is what's concerning to me.",
    "start": "3066340",
    "end": "3074010"
  },
  {
    "text": "You would resample from probably\nthe nominal disturbance. Right. That's what I'm trying to do. Yeah, you would resemble from\nthe nominal distribution,",
    "start": "3074010",
    "end": "3080680"
  },
  {
    "text": "cause you're taking the\nexpectation over the things that you didn't fix. And the expectation\nwould be with respect to the nominal [INAUDIBLE]",
    "start": "3080680",
    "end": "3089176"
  },
  {
    "text": "OK. And so yeah, I didn't really\ngo through the math here. I think the notation\ngets really messy. So we tried as hard as\nwe could in the book",
    "start": "3089176",
    "end": "3095632"
  },
  {
    "text": "to make it as not\nmessy as possible. And we also have it\nimplemented in code if you guys want\nto check it out.",
    "start": "3095632",
    "end": "3101180"
  },
  {
    "text": "But yeah, so you can\ngo through the math. Like I said, the\nnotation gets messy, but it's not super\ncrazy what's going on.",
    "start": "3101180",
    "end": "3106408"
  },
  {
    "text": "It's just like including\nversus not including a feature. And that turns out to be really\nhard to write down cleanly in math.",
    "start": "3106408",
    "end": "3113210"
  },
  {
    "text": "OK. So that's feature importance. So that's a big part of\nwhat people think about",
    "start": "3113210",
    "end": "3118340"
  },
  {
    "text": "with explainability. Another thing that you\ncan do for explainability is use surrogate models.",
    "start": "3118340",
    "end": "3124710"
  },
  {
    "text": "So we often use these to\nexplain the policies of agents. And specifically if we\nhave an agent, for example,",
    "start": "3124710",
    "end": "3131490"
  },
  {
    "text": "with a complex policy,\nmaybe a neural network, something like that, we\ncould build a surrogate model to actually approximate\nthat policy.",
    "start": "3131490",
    "end": "3138299"
  },
  {
    "text": "And ideally, we use\na surrogate model that's just already easier\nto interpret off the bat.",
    "start": "3138300",
    "end": "3145640"
  },
  {
    "text": "And so as we're\nthinking about what to use for a surrogate model,\nthere's a couple of things that we might want\nto keep in mind.",
    "start": "3145640",
    "end": "3151930"
  },
  {
    "text": "One is that we want\nour surrogate model to have high fidelity. So it should accurately\nrepresent the policy",
    "start": "3151930",
    "end": "3157750"
  },
  {
    "text": "that it's modeling. Because if it doesn't, then\ntrying to explain that policy is not going to\nmake a lot of sense, because it doesn't actually\nmatch the policy that we're",
    "start": "3157750",
    "end": "3164552"
  },
  {
    "text": "trying to explain. And then second, we do want\nit to be interpretable, because we want to be able to\nthen take this and look at it",
    "start": "3164552",
    "end": "3172120"
  },
  {
    "text": "ourselves and try\nto draw conclusions about what the agent is doing.",
    "start": "3172120",
    "end": "3177220"
  },
  {
    "text": "And typically, as\nyou might imagine, there's a trade-off between\nthese two properties, because if we\ncould have a policy",
    "start": "3177220",
    "end": "3182740"
  },
  {
    "text": "with high interpretability\nthat perfectly approximates the true policy, we\nmight as well just",
    "start": "3182740",
    "end": "3187780"
  },
  {
    "text": "use the policy with\nhigh interpretability as our actual policy. So in general, there tends to\nbe a trade-off between these two",
    "start": "3187780",
    "end": "3193540"
  },
  {
    "text": "things.  So there's a couple of\ndifferent examples of models",
    "start": "3193540",
    "end": "3198940"
  },
  {
    "text": "we could use for this. One example is a linear model. So say we just want\nto model some behavior",
    "start": "3198940",
    "end": "3205950"
  },
  {
    "text": "of an agent represented\nby this function f of x. Then we can just take\na linear sum of all",
    "start": "3205950",
    "end": "3211410"
  },
  {
    "text": "of the weights multiplied by all\nof the different subcomponents of x.",
    "start": "3211410",
    "end": "3217109"
  },
  {
    "text": "And the reason that\nthis tends to be interpretable is because\nthese weights then provide an indication of\nthe relative importance",
    "start": "3217110",
    "end": "3223410"
  },
  {
    "text": "of each feature, because\nif the weight has a higher magnitude, then it's\ngoing to have a bigger effect on the output f of x.",
    "start": "3223410",
    "end": "3229970"
  },
  {
    "text": " OK. And oftentimes we use\na local linear model.",
    "start": "3229970",
    "end": "3235853"
  },
  {
    "text": "So a lot of times\nwe're not trying to explain the entire policy of\nthe agent over its full input domain.",
    "start": "3235853",
    "end": "3241770"
  },
  {
    "text": "Because linear\nmodels typically work best when they're just\nin some local region.",
    "start": "3241770",
    "end": "3247770"
  },
  {
    "text": "And some of you may have heard\nthis very famous explanation technique called LIME. That's basically creating--\nit doesn't necessarily",
    "start": "3247770",
    "end": "3254918"
  },
  {
    "text": "need to be linear models, but\na big portion of the LIME paper is talking about local linear\nmodels of the features.",
    "start": "3254918",
    "end": "3260420"
  },
  {
    "text": " OK, so just to see what that\nlooks like, we have this",
    "start": "3260420",
    "end": "3267830"
  },
  {
    "text": "is our collision avoidance\npolicy a little bit zoomed in. And let's say that\nwe want to create a local model of the policy in\nthis particular region here.",
    "start": "3267830",
    "end": "3276420"
  },
  {
    "text": "So we're just\nlooking at everything that's in this circle. What is or how can we explain\nwhat the policy is doing here?",
    "start": "3276420",
    "end": "3285380"
  },
  {
    "text": "So what we could do is we\ncould draw a bunch of samples from this small region,\nsmall circular region,",
    "start": "3285380",
    "end": "3293299"
  },
  {
    "text": "and label them with\nthe action that gets taken at each of those points. And then train a linear model\nto approximate the policy",
    "start": "3293300",
    "end": "3301400"
  },
  {
    "text": "in that region. So then we end up with maybe\nsomething that looks like this. And so you can see\nwithin this circle,",
    "start": "3301400",
    "end": "3308330"
  },
  {
    "text": "it approximates it quite well. But again, this\nis a local model. So if we look at the\nrest of the policy,",
    "start": "3308330",
    "end": "3313880"
  },
  {
    "text": "it certainly doesn't do a\ngood job of approximating it. But we can understand\nwithin this region,",
    "start": "3313880",
    "end": "3319460"
  },
  {
    "text": "this model accurately\nmatches the true policy.",
    "start": "3319460",
    "end": "3325060"
  },
  {
    "text": "And then we can actually look\nat the weights of the model, like we said we were\ngoing to, and understand",
    "start": "3325060",
    "end": "3330250"
  },
  {
    "text": "how important each feature is. For example, we can\nsee that it seems like the weight for both\nthe relative altitude",
    "start": "3330250",
    "end": "3337600"
  },
  {
    "text": "of the aircraft and\nthe time to collision is important for determining\nthe action that we",
    "start": "3337600",
    "end": "3342700"
  },
  {
    "text": "take in this particular region. You probably figure\nthat out without this",
    "start": "3342700",
    "end": "3347920"
  },
  {
    "text": "for this particular example. But in general, when we have\nthese higher dimensional things, building these linear\nmodels can be really useful.",
    "start": "3347920",
    "end": "3355210"
  },
  {
    "text": "And then, for example,\nwe could compare that to a local model for a different\npart of the state space. So for example, maybe we\nfit a model to this region",
    "start": "3355210",
    "end": "3362770"
  },
  {
    "text": "here that's in the middle. And here we find that we\nget a nice linear model that",
    "start": "3362770",
    "end": "3367839"
  },
  {
    "text": "separates these two actions. And then if we look at the\nweights, we see as we expect,",
    "start": "3367840",
    "end": "3374349"
  },
  {
    "text": "the output or the action\nthat the agent takes is highly dependent on\nthe relative altitude",
    "start": "3374350",
    "end": "3379440"
  },
  {
    "text": "in this region, but no\nmatter the time to collision, it doesn't really\nchange the action.",
    "start": "3379440",
    "end": "3384849"
  },
  {
    "text": "So we can see we have a very\nlow wait for time to collision. And so we could do this in\na bunch of different areas",
    "start": "3384850",
    "end": "3390270"
  },
  {
    "text": "of the state space\nand get this idea of where each input feature\nis important to the action",
    "start": "3390270",
    "end": "3396180"
  },
  {
    "text": "that the policy takes.  Any questions on that?",
    "start": "3396180",
    "end": "3401345"
  },
  {
    "text": " Yeah. Is there a feasible\nway to sample",
    "start": "3401345",
    "end": "3407970"
  },
  {
    "text": "what goes into creating\nyour linear model? You know how we\nspend a lot of time talking about classification\nor finding important points.",
    "start": "3407970",
    "end": "3415200"
  },
  {
    "text": "Do we want to set our weighting\nexogenously to something that would be nice for-- Like in terms of\nwhere to do this?",
    "start": "3415200",
    "end": "3421201"
  },
  {
    "text": "Yeah, where to\nset for my example like how to build\nthe linear model. Yeah, I feel like you\njust need some domain",
    "start": "3421201",
    "end": "3426390"
  },
  {
    "text": "knowledge of where you think-- where you don't understand\nand want to produce a linear model to understand.",
    "start": "3426390",
    "end": "3432926"
  },
  {
    "start": "3432926",
    "end": "3438965"
  },
  {
    "text": "OK. And then as I mentioned, there's\nthis trade-off between fidelity and interpretability.",
    "start": "3438965",
    "end": "3444560"
  },
  {
    "text": "And so the better that our\nmodel fits, for example, the policy in this\nregion, generally",
    "start": "3444560",
    "end": "3451270"
  },
  {
    "text": "it has lower interpretability. So if we want to\nget a better fit-- so like this straight line here\ndoesn't really seem to fit this",
    "start": "3451270",
    "end": "3457840"
  },
  {
    "text": "curved edge very well-- we could add more features. So instead of just\nthe state variables",
    "start": "3457840",
    "end": "3464050"
  },
  {
    "text": "like age and time\nto collision, we could add time to collision\nsquared or age times time",
    "start": "3464050",
    "end": "3469150"
  },
  {
    "text": "to collision or whatever. But now if we look\nat these weights, we're like, OK, age\ntimes time to collision",
    "start": "3469150",
    "end": "3476680"
  },
  {
    "text": "has a higher weight\nthan just age by itself. But it's not super\ninterpretable to us",
    "start": "3476680",
    "end": "3481720"
  },
  {
    "text": "as to what that actually means. So even though it\nfits it better, we lose some of that\ninterpretability.",
    "start": "3481720",
    "end": "3488158"
  },
  {
    "text": "In general, when you're\ndoing these things, you need to make\ndecisions that help you balance these trade-offs.",
    "start": "3488158",
    "end": "3493275"
  },
  {
    "text": " OK.",
    "start": "3493275",
    "end": "3498285"
  },
  {
    "text": "It's white now because\nI didn't have time to turn this into dark thing. So another example of\nan interpretable model",
    "start": "3498285",
    "end": "3507360"
  },
  {
    "text": "is a decision tree. So we're back to our collision\navoidance policy here.",
    "start": "3507360",
    "end": "3513150"
  },
  {
    "text": "And we can now try to\ntrain a decision tree to approximate this policy.",
    "start": "3513150",
    "end": "3518860"
  },
  {
    "text": "I'm not going to explain how\nyou train decision trees. But there's nice packages\nout there to do that for you. There's one in Julia\ncalled DecisionTree.jl.",
    "start": "3518860",
    "end": "3527760"
  },
  {
    "text": "Oh, man, I thought\nI removed this. OK, these are actually\nlabeled backwards, so ignore them or reverse\nthem in your mind.",
    "start": "3527760",
    "end": "3535950"
  },
  {
    "text": "I fixed that in the\nbook about an hour ago. OK. So basically, though we've\ntrained a decision tree",
    "start": "3535950",
    "end": "3542070"
  },
  {
    "text": "to approximate this policy. And what this decision\ntree is showing is all the black nodes indicate\na split on the relative altitude",
    "start": "3542070",
    "end": "3551520"
  },
  {
    "text": "dimension. And then if we had any gray\nnodes, which we don't, they would indicate a split on the\ntime to collision dimension.",
    "start": "3551520",
    "end": "3558500"
  },
  {
    "text": "So basically we're saying, OK,\nstart at relative altitude of 0. If our current relative\naltitude is greater than 0,",
    "start": "3558500",
    "end": "3566400"
  },
  {
    "text": "then we go over here, and we\nask ourselves one more question. Is our current relative\naltitude greater than 98?",
    "start": "3566400",
    "end": "3572093"
  },
  {
    "text": " If so, then we're\nseparated enough,",
    "start": "3572093",
    "end": "3577520"
  },
  {
    "text": "and then we can be\nclear of conflict. If not, we're a little\nbit close together. We should tell the\naircraft to climb.",
    "start": "3577520",
    "end": "3585710"
  },
  {
    "text": "We should tell the\naircraft to climb. And then that way we'll\nget more relative altitude. We could do the same\nthing over here.",
    "start": "3585710",
    "end": "3591780"
  },
  {
    "text": "We'll say like, OK,\nwe're less than 0. Are we far enough less than 0? Yes, then no advisory.",
    "start": "3591780",
    "end": "3598020"
  },
  {
    "text": "Are we too close? Then we tell it to descend.",
    "start": "3598020",
    "end": "3603170"
  },
  {
    "text": "Any questions on what\nthis decision tree means? ",
    "start": "3603170",
    "end": "3609150"
  },
  {
    "text": "OK. So this is very\ninterpretable to us, seems like the policy\nis pretty sensible. If it's above you, then\nwe check how much above.",
    "start": "3609150",
    "end": "3616070"
  },
  {
    "text": "And if it's far enough\nabove, we do nothing. And if it's too close,\nthen we tell it to climb. This all seems\nreasonable, so this",
    "start": "3616070",
    "end": "3621790"
  },
  {
    "text": "helps us interpret our policy. But of course, it's not exactly\nfaithful to the true policy.",
    "start": "3621790",
    "end": "3628430"
  },
  {
    "text": "So here's what this decision\ntree policy would look like. We just created these\nlayers here basically.",
    "start": "3628430",
    "end": "3635560"
  },
  {
    "text": "And again, we have the same\ntrade-off between the fidelity",
    "start": "3635560",
    "end": "3640690"
  },
  {
    "text": "and the interpretability. So here we can get\na decision tree to represent a policy that looks\nmuch closer to our true policy.",
    "start": "3640690",
    "end": "3648170"
  },
  {
    "text": "But then we have this\nbig decision tree with lots of different\nbranches that we would need to go down to try to\nunderstand what it's actually",
    "start": "3648170",
    "end": "3653920"
  },
  {
    "text": "doing. OK, so that's surrogate models.",
    "start": "3653920",
    "end": "3659119"
  },
  {
    "text": "Now we'll talk\nabout the last two very briefly, starting\nwith counterfactuals.",
    "start": "3659120",
    "end": "3665345"
  },
  {
    "text": "OK. So with counterfactuals,\nlet me give you a little bit of\nbehind the scenes",
    "start": "3665345",
    "end": "3670920"
  },
  {
    "text": "into me making this lecture. So here's basically\nwhat happened. So I was going to be out\nof town this weekend,",
    "start": "3670920",
    "end": "3678279"
  },
  {
    "text": "and I was pushing up against\nthe end of last week. And I was like, I really need\nto get this lecture done,",
    "start": "3678280",
    "end": "3683940"
  },
  {
    "text": "because I'm not\ngoing to have time to work on it on the weekend. And so Friday was supposed\nto be my day that I was very productive on this lecture.",
    "start": "3683940",
    "end": "3690690"
  },
  {
    "text": "But you may have\nnoticed this Band-Aid on my face, which basically\nI got bit by a bug, I think.",
    "start": "3690690",
    "end": "3696670"
  },
  {
    "text": "And I woke up on Friday\nmorning, and my whole right side of my face was super swollen. I couldn't even open\nmy eye all the way.",
    "start": "3696670",
    "end": "3703060"
  },
  {
    "text": "And I was like,\nthis is not good. My husband looked at\nme and he was like, you need to go to urgent care. I FaceTimed my mom\nand she was like,",
    "start": "3703060",
    "end": "3708780"
  },
  {
    "text": "you need to go to urgent care. I was like, all right. So I spent my Friday\nmorning in urgent care. It turns out,\napparently it's fine",
    "start": "3708780",
    "end": "3714150"
  },
  {
    "text": "and the swelling is going\ndown, but I don't know. So I wasn't working on\nthis lecture, basically. And then I was working on this\nlecture very late last night.",
    "start": "3714150",
    "end": "3723520"
  },
  {
    "text": "And I have just found\nmyself wondering that if I could go back in time\nand not get bit by this bug,",
    "start": "3723520",
    "end": "3731270"
  },
  {
    "text": "would I be able to actually have\ntime to explain counterfactuals to you? And the answer is\nmaybe, but not today.",
    "start": "3731270",
    "end": "3738270"
  },
  {
    "text": "[LAUGHTER] OK. Maybe the people\nlaughing harder got",
    "start": "3738270",
    "end": "3743480"
  },
  {
    "text": "the deeper meaning\nof that joke, which is like, that's a\ncounterfactual itself. So basically a counterfactual\nis like when you go back in time",
    "start": "3743480",
    "end": "3751520"
  },
  {
    "text": "and say what would have\nhappened if I did this? And so that could be a way\nto explain your methods.",
    "start": "3751520",
    "end": "3756660"
  },
  {
    "text": "And if you're interested,\nyou can check out section 11.5 of the book. But yeah, I really didn't have\ntime to make slides on that.",
    "start": "3756660",
    "end": "3764780"
  },
  {
    "text": "OK, so that's counterfactuals. And the last thing is failure\nmode characterization.",
    "start": "3764780",
    "end": "3773760"
  },
  {
    "text": "So a lot of times we've\nmaybe learned about different algorithms that we\ncould use to find",
    "start": "3773760",
    "end": "3780230"
  },
  {
    "text": "different failures of systems. So maybe we did\nfalsification or we sampled from a failure distribution. And we have all\nof these failures,",
    "start": "3780230",
    "end": "3785587"
  },
  {
    "text": "and we want to basically\nmake sense of them. And so we can actually just\nuse clustering algorithms",
    "start": "3785587",
    "end": "3791350"
  },
  {
    "text": "to do this. So we'll basically\ncreate groupings of failure trajectories that\nare similar to one another.",
    "start": "3791350",
    "end": "3796579"
  },
  {
    "text": "And sometimes that can\ngive us some insight into what's going on or what\nthese different failures mean.",
    "start": "3796580",
    "end": "3803320"
  },
  {
    "text": "So I'm not going to go super in\ndetail on clustering algorithms.",
    "start": "3803320",
    "end": "3808420"
  },
  {
    "text": "But basically what\nyou can do, you can use a very common\none called k-means,",
    "start": "3808420",
    "end": "3813799"
  },
  {
    "text": "which is iteratively finds\ntwo nice distinct clusters or however many distinct\nclusters you want",
    "start": "3813800",
    "end": "3819850"
  },
  {
    "text": "to try to find of your data. So here we're doing\nthat on the pendulum. And you can see over time,\nwe eventually converge",
    "start": "3819850",
    "end": "3827080"
  },
  {
    "text": "upon these two\ndifferent clusters. And whenever you\ndo this clustering, you need to pick what features\nyou want to cluster based on.",
    "start": "3827080",
    "end": "3835340"
  },
  {
    "text": "So here we're clustering all\nof our failure trajectories based on the average\nangle of the trajectory",
    "start": "3835340",
    "end": "3840790"
  },
  {
    "text": "and the average angular\nvelocity over the trajectory. And it turns out when\nwe do that, we get",
    "start": "3840790",
    "end": "3847010"
  },
  {
    "text": "these two really nice clusters. Nothing too crazy is\ngoing on here, though. We just get a cluster where\nit falls over to the right,",
    "start": "3847010",
    "end": "3852990"
  },
  {
    "text": "and one cluster where it\nfalls over to the left. But in general, when you\nhave lots of failure modes",
    "start": "3852990",
    "end": "3858468"
  },
  {
    "text": "and they're not so\neasy to interpret, this can be a nice,\nuseful tool for you.",
    "start": "3858468",
    "end": "3865310"
  },
  {
    "text": "In general, though, the\nresults depend on the features that we use for clustering.",
    "start": "3865310",
    "end": "3870750"
  },
  {
    "text": "So there we just hand-picked\naverage theta and average omega. But we could just do it over\nthe entire state vector.",
    "start": "3870750",
    "end": "3878130"
  },
  {
    "text": "So we could just take\nwhatever dimensional, like, 100 dimensional state vector\nthat we have and just cluster",
    "start": "3878130",
    "end": "3883849"
  },
  {
    "text": "in that 100 dimensional region. And we still get something\nactually pretty interpretable. We get the same thing.",
    "start": "3883850",
    "end": "3889220"
  },
  {
    "text": "We could also cluster over\nthe action trajectories. So we can just take\nall the actions, stack them together, and\ncluster in that space.",
    "start": "3889220",
    "end": "3896900"
  },
  {
    "text": "Or we could cluster\nover the disturbances. In this case for the pendulum,\nclustering over the disturbances",
    "start": "3896900",
    "end": "3902780"
  },
  {
    "text": "didn't result in something that\nwas very interpretable to us. We just get a big mix\nof trajectories there.",
    "start": "3902780",
    "end": "3909320"
  },
  {
    "text": "That doesn't mean much. But if this is\ninteresting to you,",
    "start": "3909320",
    "end": "3914585"
  },
  {
    "text": "you should talk to [INAUDIBLE],\nbecause they recently did some really cool\nresearch where they were able to look at\na subspace of this",
    "start": "3914585",
    "end": "3923380"
  },
  {
    "text": "by performing PCA and trying\nto understand clusters in the high-dimensional\ndisturbance space.",
    "start": "3923380",
    "end": "3930200"
  },
  {
    "text": "So potentially interesting\navenues there and you can talk to [INAUDIBLE] if you\nwant to know more about it.",
    "start": "3930200",
    "end": "3936580"
  },
  {
    "text": "OK. And then lastly,\nanother thing that's really cool that I'm not going\nto get super in detail on",
    "start": "3936580",
    "end": "3942370"
  },
  {
    "text": "is that we can cluster based\non temporal logic features. So like I said, everything\nyou get out of this",
    "start": "3942370",
    "end": "3949150"
  },
  {
    "text": "is really dependent on\nwhatever features you throw into your clustering algorithm. But you can actually get\nreally creative on the features",
    "start": "3949150",
    "end": "3956260"
  },
  {
    "text": "that you do throw in there. So there's this thing\ncalled parametric signal temporal logic, which allows\nyou to assign parameters",
    "start": "3956260",
    "end": "3963940"
  },
  {
    "text": "to temporal logic formulas. And you can actually\ndo your clustering in that particular\nparameter space.",
    "start": "3963940",
    "end": "3969680"
  },
  {
    "text": "And so then your\nclusters will correspond to different temporal\nlogic formulas. And that would help you\nbasically understand,",
    "start": "3969680",
    "end": "3976630"
  },
  {
    "text": "OK, these failures, for\nexample, in this case, it's like these failures\nare failures that fell over before time whatever.",
    "start": "3976630",
    "end": "3983500"
  },
  {
    "text": "And these failures\nare failures that fell over after time, whatever.",
    "start": "3983500",
    "end": "3988840"
  },
  {
    "text": "And so you can get more\ninteresting, more interpretable clusters by automatically\ndoing it in the temporal logic",
    "start": "3988840",
    "end": "3995470"
  },
  {
    "text": "parameter space.  Cool. OK. So that's pretty much it for\nexplainability techniques.",
    "start": "3995470",
    "end": "4003309"
  },
  {
    "text": "So we talked about a whole bunch\nof different explainability techniques. We talked about how maybe\nit's a little bit contentious.",
    "start": "4003310",
    "end": "4010020"
  },
  {
    "text": "And in general, I just\nwant you to keep in mind that there are just some\nthings in this world that can't be explained.",
    "start": "4010020",
    "end": "4016820"
  },
  {
    "start": "4016820",
    "end": "4021000"
  }
]
[
  {
    "text": "Hi, everyone.",
    "start": "10090",
    "end": "11030"
  },
  {
    "text": "I'm Somrita.",
    "start": "11030",
    "end": "11860"
  },
  {
    "text": "Today, I'll talk\nto you a little bit",
    "start": "11860",
    "end": "13360"
  },
  {
    "text": "about learning-enabled\nadaptation to evolving",
    "start": "13360",
    "end": "15760"
  },
  {
    "text": "conditions in robotics.",
    "start": "15760",
    "end": "17603"
  },
  {
    "text": "And so, of course, I know I'm\npreaching to the choir here.",
    "start": "17603",
    "end": "20020"
  },
  {
    "text": "Today, we're seeing\nrobots in more places.",
    "start": "20020",
    "end": "21920"
  },
  {
    "text": "Of course, autonomous\ncars, which we'll",
    "start": "21920",
    "end": "23545"
  },
  {
    "text": "hear more about soon.",
    "start": "23545",
    "end": "25570"
  },
  {
    "text": "Also in the skies,\nin warehouses,",
    "start": "25570",
    "end": "28180"
  },
  {
    "text": "and in surgery rooms.",
    "start": "28180",
    "end": "30190"
  },
  {
    "text": "And so one thing that all of\nthese robots have in common",
    "start": "30190",
    "end": "33010"
  },
  {
    "text": "is that they're built off of\nthis autonomy stack, right?",
    "start": "33010",
    "end": "35441"
  },
  {
    "text": "Today, I'll be talking to you\nmostly about the model piece,",
    "start": "35442",
    "end": "37900"
  },
  {
    "text": "but I want to talk\nto you about how",
    "start": "37900",
    "end": "39358"
  },
  {
    "text": "that kind of fits in to the\nrest of the autonomy stack here.",
    "start": "39358",
    "end": "45710"
  },
  {
    "text": "So the model, we can think of it\nas taking in these observations",
    "start": "45710",
    "end": "48399"
  },
  {
    "text": "x.",
    "start": "48400",
    "end": "49360"
  },
  {
    "text": "And it's parametrized by\nsome parameters theta,",
    "start": "49360",
    "end": "51520"
  },
  {
    "text": "and you get an output\nprediction from this.",
    "start": "51520",
    "end": "53730"
  },
  {
    "text": "This prediction is\nthen used by a planner",
    "start": "53730",
    "end": "55480"
  },
  {
    "text": "to generate a planner policy.",
    "start": "55480",
    "end": "57070"
  },
  {
    "text": "And a controller translates\nthat planner policy",
    "start": "57070",
    "end": "59260"
  },
  {
    "text": "into these low level\nactuations, which",
    "start": "59260",
    "end": "61239"
  },
  {
    "text": "is how the robot will\ninteract with its environment.",
    "start": "61240",
    "end": "65050"
  },
  {
    "text": "And then raw signals\nfrom the environment",
    "start": "65050",
    "end": "66970"
  },
  {
    "text": "are picked up by\nsensors to generate",
    "start": "66970",
    "end": "68500"
  },
  {
    "text": "the observations, which is\nwhat will feed into the model.",
    "start": "68500",
    "end": "70875"
  },
  {
    "text": "So that's how this\nmodel fits in.",
    "start": "70875",
    "end": "73730"
  },
  {
    "text": "Now, as roboticists,\nof course, we",
    "start": "73730",
    "end": "75230"
  },
  {
    "text": "try to make this whole stack,\nand especially the model,",
    "start": "75230",
    "end": "77930"
  },
  {
    "text": "as robust as possible and\ncapture all of the conditions",
    "start": "77930",
    "end": "80570"
  },
  {
    "text": "that we expect the robot\nmight see during deployment.",
    "start": "80570",
    "end": "83850"
  },
  {
    "text": "The reality, though, is that\nduring deployment, there's",
    "start": "83850",
    "end": "86540"
  },
  {
    "text": "often a change in\nconditions, whether that's",
    "start": "86540",
    "end": "88760"
  },
  {
    "text": "for the environment or the\nrobot, that we didn't predict",
    "start": "88760",
    "end": "91850"
  },
  {
    "text": "and we did not expect.",
    "start": "91850",
    "end": "93439"
  },
  {
    "text": "And we often need to\nrespond in a timely manner.",
    "start": "93440",
    "end": "95990"
  },
  {
    "text": "Not just say, OK, something\nunexpected happened and move on,",
    "start": "95990",
    "end": "98907"
  },
  {
    "text": "but we actually need\nto respond, maybe",
    "start": "98907",
    "end": "100490"
  },
  {
    "text": "before the next communication\nor over the system lifetime.",
    "start": "100490",
    "end": "104329"
  },
  {
    "text": "And so the very broad research\nquestion that kind of guides",
    "start": "104330",
    "end": "107270"
  },
  {
    "text": "my PhD work is, how can\nautonomous systems reliably",
    "start": "107270",
    "end": "110240"
  },
  {
    "text": "adapt to these unexpected\nevolving conditions",
    "start": "110240",
    "end": "113090"
  },
  {
    "text": "during deployment?",
    "start": "113090",
    "end": "114530"
  },
  {
    "text": "And so today, I want to\ntalk to you specifically",
    "start": "114530",
    "end": "116990"
  },
  {
    "text": "about one type of\nevolving conditions,",
    "start": "116990",
    "end": "119000"
  },
  {
    "text": "which is shifted distribution.",
    "start": "119000",
    "end": "120373"
  },
  {
    "text": "So when you have these kinds\nof distribution shifts,",
    "start": "120373",
    "end": "122540"
  },
  {
    "text": "how can you adapt\nyour model over time?",
    "start": "122540",
    "end": "124790"
  },
  {
    "text": "And so we'll take\na look specifically",
    "start": "124790",
    "end": "127070"
  },
  {
    "text": "at adapting to\nout-of-distribution inputs.",
    "start": "127070",
    "end": "128820"
  },
  {
    "text": "And as a case study,\nwe'll use this data set",
    "start": "128820",
    "end": "132190"
  },
  {
    "text": "of satellite images.",
    "start": "132190",
    "end": "133790"
  },
  {
    "text": "And from these, we'll try to\nestimate the pose of a satellite",
    "start": "133790",
    "end": "136480"
  },
  {
    "text": "from these camera images.",
    "start": "136480",
    "end": "138370"
  },
  {
    "text": "So that's kind of what\nthe model looks like,",
    "start": "138370",
    "end": "141489"
  },
  {
    "text": "is that we'll have some\ncamera image of the satellite",
    "start": "141490",
    "end": "143740"
  },
  {
    "text": "and we're trying to\npredict its pose.",
    "start": "143740",
    "end": "145340"
  },
  {
    "text": "So pose in 3D space, which\nmeans its position x, y, z,",
    "start": "145340",
    "end": "148330"
  },
  {
    "text": "as well as its orientation.",
    "start": "148330",
    "end": "149750"
  },
  {
    "text": "So that could be its roll,\npitch, yaw or quaternions,",
    "start": "149750",
    "end": "152410"
  },
  {
    "text": "however you want\nto represent that.",
    "start": "152410",
    "end": "153920"
  },
  {
    "text": "And the reason why\nwe want this model",
    "start": "153920",
    "end": "155507"
  },
  {
    "text": "is because there's some\ndownstream decision-making logic",
    "start": "155507",
    "end": "157840"
  },
  {
    "text": "that might use\nthis for trajectory",
    "start": "157840",
    "end": "159640"
  },
  {
    "text": "tracking or autonomous docking\nwith this satellite, something",
    "start": "159640",
    "end": "162970"
  },
  {
    "text": "like that, or to\nclean up space debris.",
    "start": "162970",
    "end": "164950"
  },
  {
    "text": "But let's focus on\nthe model itself.",
    "start": "164950",
    "end": "167379"
  },
  {
    "text": "And we know that this is true\nfor a lot of learned models,",
    "start": "167380",
    "end": "170140"
  },
  {
    "text": "that the performance\nof this model",
    "start": "170140",
    "end": "171722"
  },
  {
    "text": "depends on whether the\ninput that you're seeing",
    "start": "171722",
    "end": "173680"
  },
  {
    "text": "is similar to what the\nmodel has been trained on.",
    "start": "173680",
    "end": "176187"
  },
  {
    "text": "In fact, that's a mathematical\nassumption that we make,",
    "start": "176188",
    "end": "178480"
  },
  {
    "text": "is that it's going\nto be IID, which",
    "start": "178480",
    "end": "180250"
  },
  {
    "text": "is that it's going to be drawn\nfrom the same distribution.",
    "start": "180250",
    "end": "183040"
  },
  {
    "text": "In reality, the distribution\nof inputs that you see",
    "start": "183040",
    "end": "185530"
  },
  {
    "text": "can often change after\ndeployment, especially",
    "start": "185530",
    "end": "188080"
  },
  {
    "text": "if you're deploying this\nover a long mission lifetime.",
    "start": "188080",
    "end": "190370"
  },
  {
    "text": "So you might start seeing things\nlike Earth in the background",
    "start": "190370",
    "end": "192912"
  },
  {
    "text": "or lens flares that you\ndidn't train on originally.",
    "start": "192912",
    "end": "195560"
  },
  {
    "text": "And so when you have these\nkinds of observations",
    "start": "195560",
    "end": "198590"
  },
  {
    "text": "that come from a\ndifferent distribution,",
    "start": "198590",
    "end": "200330"
  },
  {
    "text": "we call them out-of-distribution\nobservations.",
    "start": "200330",
    "end": "203230"
  },
  {
    "text": "And these out-of-distribution\nobservations",
    "start": "203230",
    "end": "204980"
  },
  {
    "text": "can lead to incorrect\npredictions.",
    "start": "204980",
    "end": "206970"
  },
  {
    "text": "And we care about this because\nthat can lead to unsafe outcomes",
    "start": "206970",
    "end": "210050"
  },
  {
    "text": "by the downstream\ndecision making logic.",
    "start": "210050",
    "end": "212930"
  },
  {
    "text": "And so, really,\nwhat we're asking",
    "start": "212930",
    "end": "214370"
  },
  {
    "text": "is, OK, we want this kind\nof lifelong deployment",
    "start": "214370",
    "end": "216620"
  },
  {
    "text": "of learning-enabled\ncomponents, but we",
    "start": "216620",
    "end": "218540"
  },
  {
    "text": "know that the data distribution\nmay change over time.",
    "start": "218540",
    "end": "220769"
  },
  {
    "text": "So how do we adapt to that?",
    "start": "220770",
    "end": "222860"
  },
  {
    "text": "So this is how I envision\nthe data lifecycle.",
    "start": "222860",
    "end": "225885"
  },
  {
    "text": "I said lifelong deployment.",
    "start": "225885",
    "end": "227010"
  },
  {
    "text": "What does the data\nlifecycle look like?",
    "start": "227010",
    "end": "228659"
  },
  {
    "text": "You can think of this as a\nsequence of inputs coming in.",
    "start": "228660",
    "end": "231450"
  },
  {
    "text": "In this case, they're images.",
    "start": "231450",
    "end": "233420"
  },
  {
    "text": "These might be sequential,\nthese might be batched.",
    "start": "233420",
    "end": "235565"
  },
  {
    "text": "And then you have a model that\noutputs some kind of prediction.",
    "start": "235565",
    "end": "238190"
  },
  {
    "text": "Here, that's the pose\nof the satellite.",
    "start": "238190",
    "end": "240530"
  },
  {
    "text": "In addition to that,\nwe often will have",
    "start": "240530",
    "end": "244220"
  },
  {
    "text": "some measure of uncertainty.",
    "start": "244220",
    "end": "245850"
  },
  {
    "text": "So there are various different\ntechniques to do this.",
    "start": "245850",
    "end": "248210"
  },
  {
    "text": "And these types of\nuncertainties are",
    "start": "248210",
    "end": "249710"
  },
  {
    "text": "what we use to do\nout-of-distribution detection",
    "start": "249710",
    "end": "252080"
  },
  {
    "text": "or runtime monitoring.",
    "start": "252080",
    "end": "253650"
  },
  {
    "text": "And this by itself could be\na whole, not just a talk,",
    "start": "253650",
    "end": "257000"
  },
  {
    "text": "but a whole thesis.",
    "start": "257000",
    "end": "257870"
  },
  {
    "text": "So out-of-distribution\ndetection or runtime monitoring",
    "start": "257870",
    "end": "260120"
  },
  {
    "text": "requires that we have some\nnotion of the uncertainty",
    "start": "260120",
    "end": "262287"
  },
  {
    "text": "of the model.",
    "start": "262287",
    "end": "263449"
  },
  {
    "text": "What I want to do, though,\nis go a little bit further.",
    "start": "263450",
    "end": "265700"
  },
  {
    "text": "I don't just care about\ndetecting that something",
    "start": "265700",
    "end": "267700"
  },
  {
    "text": "is out-of-distribution.",
    "start": "267700",
    "end": "268710"
  },
  {
    "text": "I also want to be\nable to adapt to that.",
    "start": "268710",
    "end": "270449"
  },
  {
    "text": "So I want to close\nthe loop here.",
    "start": "270450",
    "end": "272000"
  },
  {
    "text": "And how we're\ngoing to do that is",
    "start": "272000",
    "end": "273410"
  },
  {
    "text": "we're going to\nselect some of these",
    "start": "273410",
    "end": "275420"
  },
  {
    "text": "to actually label, which means\nthat we'll select a subset,",
    "start": "275420",
    "end": "277918"
  },
  {
    "text": "we'll flag them, and\nsay, OK, these are not",
    "start": "277918",
    "end": "279710"
  },
  {
    "text": "just out-of-distribution,\nbut I actually",
    "start": "279710",
    "end": "281376"
  },
  {
    "text": "want to generate labels for\nthese, and then request labels.",
    "start": "281377",
    "end": "284390"
  },
  {
    "text": "So this might look for\nthe satellite cases.",
    "start": "284390",
    "end": "286200"
  },
  {
    "text": "You have to downlink\nthis image to the ground",
    "start": "286200",
    "end": "287750"
  },
  {
    "text": "and ask a human or\nsome other oracle",
    "start": "287750",
    "end": "289400"
  },
  {
    "text": "to actually label this for you.",
    "start": "289400",
    "end": "290790"
  },
  {
    "text": "So this is an expensive process.",
    "start": "290790",
    "end": "293120"
  },
  {
    "text": "And of course, then\nyou use these labels",
    "start": "293120",
    "end": "295610"
  },
  {
    "text": "to fine tune or\nretrain your model.",
    "start": "295610",
    "end": "298199"
  },
  {
    "text": "So now you can adapt to\nthis distribution shift.",
    "start": "298200",
    "end": "300463"
  },
  {
    "text": "So essentially, things that\nwere out-of-distribution",
    "start": "300463",
    "end": "302630"
  },
  {
    "text": "will slowly become\nin-distribution",
    "start": "302630",
    "end": "304100"
  },
  {
    "text": "and you can start to\ntrust your model more",
    "start": "304100",
    "end": "305870"
  },
  {
    "text": "on these kinds of inputs.",
    "start": "305870",
    "end": "307470"
  },
  {
    "text": "And so this kind of\nforms the four pieces",
    "start": "307470",
    "end": "310020"
  },
  {
    "text": "of this idea of doing this\ndata life cycle management.",
    "start": "310020",
    "end": "313229"
  },
  {
    "text": "And steps 1 and 2, we think\nyou can do onboard your robot.",
    "start": "313230",
    "end": "317182"
  },
  {
    "text": "So these should be\ncomputationally inexpensive.",
    "start": "317182",
    "end": "319140"
  },
  {
    "text": "Steps 3 and 4, of\ncourse, are expensive",
    "start": "319140",
    "end": "320765"
  },
  {
    "text": "and you want to be\nvery judicious with how",
    "start": "320765",
    "end": "322710"
  },
  {
    "text": "you select your labels.",
    "start": "322710",
    "end": "324360"
  },
  {
    "text": "And so this might\nbe obvious, but I",
    "start": "324360",
    "end": "326490"
  },
  {
    "text": "want to drive home the point\nthat the more images you",
    "start": "326490",
    "end": "329220"
  },
  {
    "text": "flag, the more labels that you\nrequest, the more fine tuning",
    "start": "329220",
    "end": "331923"
  },
  {
    "text": "you do of your model,\nyou're giving your model",
    "start": "331923",
    "end": "333840"
  },
  {
    "text": "more information.",
    "start": "333840",
    "end": "334858"
  },
  {
    "text": "And therefore, you're likely\nto see better performance.",
    "start": "334858",
    "end": "337150"
  },
  {
    "text": "But this comes at a cost.",
    "start": "337150",
    "end": "338402"
  },
  {
    "text": "And so this performance\nand cost tradeoff",
    "start": "338402",
    "end": "340110"
  },
  {
    "text": "is something we'll come\nback to in a little bit.",
    "start": "340110",
    "end": "342449"
  },
  {
    "text": "But let's step through this.",
    "start": "342450",
    "end": "343870"
  },
  {
    "text": "How do we even do this?",
    "start": "343870",
    "end": "345010"
  },
  {
    "text": "Let's go through\neach part one by one.",
    "start": "345010",
    "end": "346777"
  },
  {
    "text": "So first, let's talk about\nout-of-distribution detection",
    "start": "346777",
    "end": "349110"
  },
  {
    "text": "or runtime monitoring.",
    "start": "349110",
    "end": "350669"
  },
  {
    "text": "And so one way of doing this\nis to use Bayesian methods.",
    "start": "350670",
    "end": "354220"
  },
  {
    "text": "I'm kind of just sketching out\na much more involved algorithm",
    "start": "354220",
    "end": "357050"
  },
  {
    "text": "here.",
    "start": "357050",
    "end": "357550"
  },
  {
    "text": "But the idea essentially is\nyou choose a prior distribution",
    "start": "357550",
    "end": "360330"
  },
  {
    "text": "over your functions, you compute\nyour posterior distribution,",
    "start": "360330",
    "end": "363610"
  },
  {
    "text": "given your training data.",
    "start": "363610",
    "end": "364919"
  },
  {
    "text": "That allows you to evaluate\nthe predictive uncertainty",
    "start": "364920",
    "end": "367680"
  },
  {
    "text": "at your test points.",
    "start": "367680",
    "end": "369330"
  },
  {
    "text": "And so, essentially,\nif you've seen",
    "start": "369330",
    "end": "371477"
  },
  {
    "text": "a lot of points that are close\nto what you're seeing now",
    "start": "371477",
    "end": "373810"
  },
  {
    "text": "in the test data,\nyou know that you're",
    "start": "373810",
    "end": "375393"
  },
  {
    "text": "relatively confident or not as\nuncertain about those points,",
    "start": "375393",
    "end": "379090"
  },
  {
    "text": "and vice versa for\nout-of-distribution points.",
    "start": "379090",
    "end": "381317"
  },
  {
    "text": "So if you apply this\nkind of technique",
    "start": "381317",
    "end": "382900"
  },
  {
    "text": "to a pre-trained\ndeep neural network,",
    "start": "382900",
    "end": "384639"
  },
  {
    "text": "you get the SCOD algorithm.",
    "start": "384640",
    "end": "386110"
  },
  {
    "text": "And I'll talk a little\nbit, just again,",
    "start": "386110",
    "end": "387969"
  },
  {
    "text": "sketch out the SCOD\nalgorithm itself.",
    "start": "387970",
    "end": "389930"
  },
  {
    "text": "And so what this looks like--",
    "start": "389930",
    "end": "392604"
  },
  {
    "text": "let's see if I can\npull up a pointer.",
    "start": "392605",
    "end": "394390"
  },
  {
    "text": "Yeah, so often what you're\ndoing here is, let's say,",
    "start": "397440",
    "end": "399810"
  },
  {
    "text": "you have some kind\nof model like this.",
    "start": "399810",
    "end": "401970"
  },
  {
    "text": "And then what\nyou'll do offline is",
    "start": "401970",
    "end": "403620"
  },
  {
    "text": "you start with some\nprior on your weights.",
    "start": "403620",
    "end": "405370"
  },
  {
    "text": "You have some prior distribution\non your weights right here.",
    "start": "405370",
    "end": "407870"
  },
  {
    "text": "Then you take your training\ndata, or more realistically,",
    "start": "407870",
    "end": "410370"
  },
  {
    "text": "a representative subset\nset of your training data,",
    "start": "410370",
    "end": "412840"
  },
  {
    "text": "you pass that through and\nupdate your posterior.",
    "start": "412840",
    "end": "415223"
  },
  {
    "text": "So now you-- or\nupdate your belief",
    "start": "415223",
    "end": "416639"
  },
  {
    "text": "to get your posterior\non your weights.",
    "start": "416640",
    "end": "418810"
  },
  {
    "text": "Using this, you can kind of\nconstruct essentially two",
    "start": "418810",
    "end": "421970"
  },
  {
    "text": "things.",
    "start": "421970",
    "end": "422470"
  },
  {
    "text": "One, your output, as\nwell as the Jacobian,",
    "start": "422470",
    "end": "424220"
  },
  {
    "text": "which is a linearization\nof your model itself.",
    "start": "424220",
    "end": "427630"
  },
  {
    "text": "Now you can-- now you basically\nhave your distribution",
    "start": "427630",
    "end": "430710"
  },
  {
    "text": "over your outputs.",
    "start": "430710",
    "end": "431830"
  },
  {
    "text": "And the entropy of\nthat distribution",
    "start": "431830",
    "end": "433664"
  },
  {
    "text": "can give you a measure of\nyour overall uncertainty.",
    "start": "433665",
    "end": "435790"
  },
  {
    "text": "So this is one way\nof getting a scalar",
    "start": "435790",
    "end": "437373"
  },
  {
    "text": "value of your uncertainty.",
    "start": "437373",
    "end": "438762"
  },
  {
    "text": "So that's what SCOD does,\nit gives you a scalar value",
    "start": "438762",
    "end": "440970"
  },
  {
    "text": "of your uncertainty.",
    "start": "440970",
    "end": "442020"
  },
  {
    "text": "So now, the key idea here\nis that, OK, you can now",
    "start": "442020",
    "end": "444750"
  },
  {
    "text": "detect out-of-distribution\ninputs by estimating",
    "start": "444750",
    "end": "447312"
  },
  {
    "text": "the functional\nuncertainty and then",
    "start": "447312",
    "end": "448770"
  },
  {
    "text": "thresholding the\nuncertainty value to say,",
    "start": "448770",
    "end": "450780"
  },
  {
    "text": "all right, at this point,\nwe are in distribution.",
    "start": "450780",
    "end": "452822"
  },
  {
    "text": "If our uncertainty is high,\nwe are out of distribution.",
    "start": "452822",
    "end": "455220"
  },
  {
    "text": "Let's take a look at\nthat on a toy case.",
    "start": "455220",
    "end": "457498"
  },
  {
    "text": "So first, this is\nlike the MNIST data",
    "start": "457498",
    "end": "459039"
  },
  {
    "text": "set where you have\nthese handwritten digits",
    "start": "459040",
    "end": "460420"
  },
  {
    "text": "and you're trying\nto classify what",
    "start": "460420",
    "end": "461837"
  },
  {
    "text": "digit has been written down.",
    "start": "461837",
    "end": "463085"
  },
  {
    "text": "So during training, you might\nhave seen digits like this.",
    "start": "463085",
    "end": "465460"
  },
  {
    "text": "Maybe during deployment--\nthis is a toy example-- maybe",
    "start": "465460",
    "end": "468100"
  },
  {
    "text": "mix in some fashion-MNIST\nimages, things",
    "start": "468100",
    "end": "469870"
  },
  {
    "text": "that don't look like digits,\nand you train a classifier",
    "start": "469870",
    "end": "473620"
  },
  {
    "text": "and you add a SCOD wrapper.",
    "start": "473620",
    "end": "474887"
  },
  {
    "text": "And you see that you're able\nto detect the ones that you",
    "start": "474887",
    "end": "477220"
  },
  {
    "text": "think are out of distribution.",
    "start": "477220",
    "end": "478470"
  },
  {
    "text": "So this kind of matches\nour expectations.",
    "start": "478470",
    "end": "480925"
  },
  {
    "text": "Again, though, I said,\nthe focus of this talk",
    "start": "480925",
    "end": "482800"
  },
  {
    "text": "is not about detecting\nthat something is out",
    "start": "482800",
    "end": "484330"
  },
  {
    "text": "of distribution, but\nadapting to it over time.",
    "start": "484330",
    "end": "486199"
  },
  {
    "text": "So in order to adapt\nto it over time,",
    "start": "486200",
    "end": "487750"
  },
  {
    "text": "we need to subsample these.",
    "start": "487750",
    "end": "489240"
  },
  {
    "text": "Some of these I want\nto store and label",
    "start": "489240",
    "end": "491410"
  },
  {
    "text": "because I want my model\neventually to not just do well",
    "start": "491410",
    "end": "494260"
  },
  {
    "text": "on the digits, but also start\nto learn these new classes",
    "start": "494260",
    "end": "497410"
  },
  {
    "text": "that we're seeing.",
    "start": "497410",
    "end": "498440"
  },
  {
    "text": "In order to do that, I need\nto select a subset of them",
    "start": "498440",
    "end": "500890"
  },
  {
    "text": "to label.",
    "start": "500890",
    "end": "501525"
  },
  {
    "text": "It would be great\nif I could take",
    "start": "501525",
    "end": "502900"
  },
  {
    "text": "every single out-of-distribution\nimage, generate",
    "start": "502900",
    "end": "505005"
  },
  {
    "text": "labels, and fine\ntune, but that's",
    "start": "505005",
    "end": "506380"
  },
  {
    "text": "a pretty expensive process.",
    "start": "506380",
    "end": "507560"
  },
  {
    "text": "You wouldn't want to\ndo that, for example,",
    "start": "507560",
    "end": "509169"
  },
  {
    "text": "with an autonomous car,\nwhere you have lots",
    "start": "509170",
    "end": "510520"
  },
  {
    "text": "of frames that you're seeing.",
    "start": "510520",
    "end": "511789"
  },
  {
    "text": "So how do you\nsubselect from this?",
    "start": "511790",
    "end": "513950"
  },
  {
    "text": "Well, I said SCOD outputs\nthe scalar uncertainty value.",
    "start": "513950",
    "end": "517400"
  },
  {
    "text": "So one reasonable thing\nto do is to just select",
    "start": "517400",
    "end": "520150"
  },
  {
    "text": "the two in this case that have\nthe highest uncertainty, right?",
    "start": "520150",
    "end": "522740"
  },
  {
    "text": "So that's pretty reasonable.",
    "start": "522740",
    "end": "524950"
  },
  {
    "text": "I would say that this looks OK.",
    "start": "524950",
    "end": "527350"
  },
  {
    "text": "These are relatively\ncorrelated images.",
    "start": "527350",
    "end": "529940"
  },
  {
    "text": "They're about the same shape.",
    "start": "529940",
    "end": "531970"
  },
  {
    "text": "So maybe we can do better,\nbut we'll come back to that.",
    "start": "531970",
    "end": "534318"
  },
  {
    "text": "Let's look at this on the actual\nexample that we were talking",
    "start": "534318",
    "end": "536860"
  },
  {
    "text": "about with satellite\npose estimation,",
    "start": "536860",
    "end": "538402"
  },
  {
    "text": "where we have a training data\nset that looks like this.",
    "start": "538402",
    "end": "540740"
  },
  {
    "text": "And then during\ndeployment, we see",
    "start": "540740",
    "end": "542260"
  },
  {
    "text": "some that are not from\nthe same distribution.",
    "start": "542260",
    "end": "544990"
  },
  {
    "text": "We ask SCOD which ones\nare out of distribution,",
    "start": "544990",
    "end": "547190"
  },
  {
    "text": "and the answer is that\nyou get are pretty",
    "start": "547190",
    "end": "549065"
  },
  {
    "text": "much what you would expect.",
    "start": "549065",
    "end": "550190"
  },
  {
    "text": "The ones that have a lens flare\nor Earth in the background",
    "start": "550190",
    "end": "552040"
  },
  {
    "text": "are the ones that\nSCOD thinks are",
    "start": "552040",
    "end": "553660"
  },
  {
    "text": "more likely to be\nout-of-distribution.",
    "start": "553660",
    "end": "555699"
  },
  {
    "text": "Again, though, what\nwe care about is",
    "start": "555700",
    "end": "557320"
  },
  {
    "text": "subsampling some of these so\nwe can label them and retrain.",
    "start": "557320",
    "end": "559960"
  },
  {
    "text": "If you use the ones\nthat SCOD thinks",
    "start": "559960",
    "end": "561940"
  },
  {
    "text": "the model has the\nhighest uncertainty on,",
    "start": "561940",
    "end": "563860"
  },
  {
    "text": "you get these two images.",
    "start": "563860",
    "end": "565153"
  },
  {
    "text": "And I would say that's\ngreat, but we're really",
    "start": "565153",
    "end": "567070"
  },
  {
    "text": "missing out on something here.",
    "start": "567070",
    "end": "568430"
  },
  {
    "text": "We're missing out on-- there\nare a couple classes of OOD",
    "start": "568430",
    "end": "571000"
  },
  {
    "text": "that we're seeing, and we're\nnot able to really capture",
    "start": "571000",
    "end": "573430"
  },
  {
    "text": "all of that by just\nasking what the model is",
    "start": "573430",
    "end": "575290"
  },
  {
    "text": "most uncertain about.",
    "start": "575290",
    "end": "576529"
  },
  {
    "text": "So can we do this subsampling\nmore intelligently?",
    "start": "576530",
    "end": "579490"
  },
  {
    "text": "So that's what I'll\ntalk about next,",
    "start": "579490",
    "end": "580990"
  },
  {
    "text": "is selecting a subset\nof inputs for labeling.",
    "start": "580990",
    "end": "584390"
  },
  {
    "text": "So how should we do that?",
    "start": "584390",
    "end": "586322"
  },
  {
    "text": "How should we select a subset of\nthese out-of-distribution inputs",
    "start": "586322",
    "end": "589030"
  },
  {
    "text": "now that we have detected them?",
    "start": "589030",
    "end": "590480"
  },
  {
    "text": "So we can store them and then\nlabel them, retrain our model.",
    "start": "590480",
    "end": "594230"
  },
  {
    "text": "And what I propose is\nthat we should ideally",
    "start": "594230",
    "end": "596660"
  },
  {
    "text": "choose a diverse subset.",
    "start": "596660",
    "end": "597690"
  },
  {
    "text": "So not just the ones we're\nmost uncertain about,",
    "start": "597690",
    "end": "599690"
  },
  {
    "text": "but the ones that we\nthink are diverse,",
    "start": "599690",
    "end": "601315"
  },
  {
    "text": "so that we are, one, being\njudicious about our bandwidth",
    "start": "601315",
    "end": "603860"
  },
  {
    "text": "limitations.",
    "start": "603860",
    "end": "604500"
  },
  {
    "text": "In this case, you know,\nyou can't actually",
    "start": "604500",
    "end": "606380"
  },
  {
    "text": "downlink every single\nimage that you see.",
    "start": "606380",
    "end": "608690"
  },
  {
    "text": "But also we're maximizing the\ninformation gain to the model.",
    "start": "608690",
    "end": "611393"
  },
  {
    "text": "And this is also correlated\nwith an idea of novelty.",
    "start": "611393",
    "end": "613560"
  },
  {
    "text": "A lot of times in\nrobotics, you would",
    "start": "613560",
    "end": "615102"
  },
  {
    "text": "want to capture the things\nthat you see that are novel.",
    "start": "615102",
    "end": "617810"
  },
  {
    "text": "And so the problem statement\nis from a batch of m inputs,",
    "start": "617810",
    "end": "620910"
  },
  {
    "text": "how do you select b\ninputs for labeling?",
    "start": "620910",
    "end": "623540"
  },
  {
    "text": "Or more concretely, how do\nyou select b diverse inputs",
    "start": "623540",
    "end": "625970"
  },
  {
    "text": "for labeling?",
    "start": "625970",
    "end": "627379"
  },
  {
    "text": "And so, now, before we dive\ninto the algorithm itself,",
    "start": "627380",
    "end": "632225"
  },
  {
    "text": "we'll call this-- this\nis diverse subsampling",
    "start": "632225",
    "end": "634100"
  },
  {
    "text": "using SCOD, DS-SCOD.",
    "start": "634100",
    "end": "635579"
  },
  {
    "text": "Before we dive\ninto the algorithm,",
    "start": "635580",
    "end": "637670"
  },
  {
    "text": "let's take a quick look at\nsome of the math behind it.",
    "start": "637670",
    "end": "640860"
  },
  {
    "text": "So consider the D zero is\nyour training data set.",
    "start": "640860",
    "end": "643980"
  },
  {
    "text": "Consider the D p as\nthe full test data set.",
    "start": "643980",
    "end": "646042"
  },
  {
    "text": "Everything that you're\nseeing that is out",
    "start": "646042",
    "end": "647750"
  },
  {
    "text": "of distribution\nor you've detected",
    "start": "647750",
    "end": "649167"
  },
  {
    "text": "it to be out-of-distribution.",
    "start": "649167",
    "end": "650779"
  },
  {
    "text": "Ideally, you would have\nyour entire new test",
    "start": "650780",
    "end": "653120"
  },
  {
    "text": "data set as well.",
    "start": "653120",
    "end": "654330"
  },
  {
    "text": "If you could do that, if you\ncould have your training data",
    "start": "654330",
    "end": "658100"
  },
  {
    "text": "set and everything\nthat you've added,",
    "start": "658100",
    "end": "660079"
  },
  {
    "text": "this would be your\nfull data posterior.",
    "start": "660080",
    "end": "661830"
  },
  {
    "text": "So this is what I would\nideally like to calculate.",
    "start": "661830",
    "end": "663913"
  },
  {
    "text": "Or if you think of that in a\nlog posterior form, what I want",
    "start": "663913",
    "end": "666920"
  },
  {
    "text": "to calculate is this term here.",
    "start": "666920",
    "end": "668279"
  },
  {
    "text": "So I want to be able\nto ideally calculate",
    "start": "668280",
    "end": "669988"
  },
  {
    "text": "the posterior update as a result\nof choosing one of those inputs",
    "start": "669988",
    "end": "673279"
  },
  {
    "text": "x i.",
    "start": "673280",
    "end": "674442"
  },
  {
    "text": "Unfortunately, this is not\ncomputationally tractable.",
    "start": "674442",
    "end": "676650"
  },
  {
    "text": "I can't actually calculate this.",
    "start": "676650",
    "end": "678320"
  },
  {
    "text": "But I can come up with\nthese approximations.",
    "start": "678320",
    "end": "680720"
  },
  {
    "text": "If I take one of\nthose terms and look",
    "start": "680720",
    "end": "682310"
  },
  {
    "text": "at the log likelihood of the\ndata, so just this first term",
    "start": "682310",
    "end": "685070"
  },
  {
    "text": "right here, I can approximate\nthis with a second order Laplace",
    "start": "685070",
    "end": "688190"
  },
  {
    "text": "approximation that depends\non the Jacobian matrix of how",
    "start": "688190",
    "end": "691340"
  },
  {
    "text": "much your outputs change\nwith respect to your weights,",
    "start": "691340",
    "end": "693590"
  },
  {
    "text": "and the Fisher information\nmatrix of your output",
    "start": "693590",
    "end": "696020"
  },
  {
    "text": "distribution.",
    "start": "696020",
    "end": "696930"
  },
  {
    "text": "So these are things\nI can quantify",
    "start": "696930",
    "end": "699963"
  },
  {
    "text": "and things that actually are\nout-of-distribution detection",
    "start": "699963",
    "end": "702380"
  },
  {
    "text": "algorithms SCOD already does.",
    "start": "702380",
    "end": "704550"
  },
  {
    "text": "So this is not exact, but\nwe can quantify or update",
    "start": "704550",
    "end": "708350"
  },
  {
    "text": "for the ith input\nin these terms.",
    "start": "708350",
    "end": "711079"
  },
  {
    "text": "Now, if we make\nthat assumption, we",
    "start": "711080",
    "end": "713840"
  },
  {
    "text": "say, OK, our update,\nif you pick the ith",
    "start": "713840",
    "end": "715700"
  },
  {
    "text": "point is this expression.",
    "start": "715700",
    "end": "719540"
  },
  {
    "text": "Now, what is the update if\nyou pick all of your inputs?",
    "start": "719540",
    "end": "722000"
  },
  {
    "text": "So if I pick everything\nthat was available",
    "start": "722000",
    "end": "723860"
  },
  {
    "text": "to me, if I could do that,\nwell, what would my update be?",
    "start": "723860",
    "end": "726890"
  },
  {
    "text": "Versus what would my update\nbe if I picked points",
    "start": "726890",
    "end": "729500"
  },
  {
    "text": "according to some\nbinary vector c,",
    "start": "729500",
    "end": "731570"
  },
  {
    "text": "where c is essentially a\nsequence of zeros and ones,",
    "start": "731570",
    "end": "734430"
  },
  {
    "text": "it's of length m, and only\nb of them can be set to 1?",
    "start": "734430",
    "end": "737610"
  },
  {
    "text": "So essentially, which\nones am I picking?",
    "start": "737610",
    "end": "739610"
  },
  {
    "text": "What I want to do is minimize\nthe loss of information.",
    "start": "739610",
    "end": "742140"
  },
  {
    "text": "So I want to minimize the\ndifference between the two.",
    "start": "742140",
    "end": "744348"
  },
  {
    "text": "What I'm saying is, I'm only\nallowed to pick up to b.",
    "start": "744348",
    "end": "747980"
  },
  {
    "text": "Which b should I pick so that\nI get as much information that",
    "start": "747980",
    "end": "751220"
  },
  {
    "text": "is as close as possible to\npicking all of the m inputs?",
    "start": "751220",
    "end": "755279"
  },
  {
    "text": "So I want to minimize the loss\nof information essentially here.",
    "start": "755280",
    "end": "758010"
  },
  {
    "text": "So each element of c, like I\nsaid, has to be either 0 or 1,",
    "start": "758010",
    "end": "760880"
  },
  {
    "text": "and up to b of them\ncan be equal to 1.",
    "start": "760880",
    "end": "763050"
  },
  {
    "text": "So that's all the\nconstraints here.",
    "start": "763050",
    "end": "765029"
  },
  {
    "text": "Now, there is a\nrelaxation that makes",
    "start": "765030",
    "end": "767360"
  },
  {
    "text": "this computationally tractable.",
    "start": "767360",
    "end": "769227"
  },
  {
    "text": "Essentially, this lets\nyou solve this using",
    "start": "769228",
    "end": "771020"
  },
  {
    "text": "a Frank-Wolfe optimization.",
    "start": "771020",
    "end": "772280"
  },
  {
    "text": "You kind of form\na kernel function.",
    "start": "772280",
    "end": "773910"
  },
  {
    "text": "You relax some of\nyour constraints.",
    "start": "773910",
    "end": "775139"
  },
  {
    "text": "So instead of having these\nstrict binary constraints,",
    "start": "775140",
    "end": "777348"
  },
  {
    "text": "they are now\nnon-negative constraints.",
    "start": "777348",
    "end": "778980"
  },
  {
    "text": "But we'll skip over that for\na second and kind of say, OK,",
    "start": "778980",
    "end": "781639"
  },
  {
    "text": "there is a tractable\nway of actually solving",
    "start": "781640",
    "end": "783710"
  },
  {
    "text": "this minimization problem.",
    "start": "783710",
    "end": "785720"
  },
  {
    "text": "OK, so now let's take a look--",
    "start": "785720",
    "end": "787639"
  },
  {
    "text": "so, OK, the summary\nof the takeaways",
    "start": "787640",
    "end": "790430"
  },
  {
    "text": "from this whole\nalgorithm is just this,",
    "start": "790430",
    "end": "792470"
  },
  {
    "text": "is that the kind of\nintermediate quantities,",
    "start": "792470",
    "end": "796279"
  },
  {
    "text": "such as Jacobians,\nthat you generated",
    "start": "796280",
    "end": "797870"
  },
  {
    "text": "from out-of-distribution\ntechniques,",
    "start": "797870",
    "end": "799732"
  },
  {
    "text": "out-of-distribution\ndetection techniques,",
    "start": "799732",
    "end": "801440"
  },
  {
    "text": "you can reuse that as a\nmeasure of deformation gain",
    "start": "801440",
    "end": "804110"
  },
  {
    "text": "that you would get\nfrom each input.",
    "start": "804110",
    "end": "805950"
  },
  {
    "text": "That's the point.",
    "start": "805950",
    "end": "806810"
  },
  {
    "text": "The point is that\nnot only can they",
    "start": "806810",
    "end": "808397"
  },
  {
    "text": "tell you which ones are\nout-of-distribution,",
    "start": "808397",
    "end": "810230"
  },
  {
    "text": "they also tell you-- they encode\na measure of deformation gain",
    "start": "810230",
    "end": "813500"
  },
  {
    "text": "that you're getting.",
    "start": "813500",
    "end": "814350"
  },
  {
    "text": "And then from an information\ntheoretic perspective,",
    "start": "814350",
    "end": "816475"
  },
  {
    "text": "we're just choosing the subset\nof inputs that collectively",
    "start": "816475",
    "end": "819170"
  },
  {
    "text": "maximize your information gain.",
    "start": "819170",
    "end": "821329"
  },
  {
    "text": "So let's look at some\nof those toy examples",
    "start": "821330",
    "end": "823778"
  },
  {
    "text": "that we looked at before.",
    "start": "823778",
    "end": "824820"
  },
  {
    "text": "So if you remember from the mix\nof MNIST and fashion-MNIST data",
    "start": "824820",
    "end": "829133"
  },
  {
    "text": "points, these were\nthe two that we",
    "start": "829133",
    "end": "830550"
  },
  {
    "text": "would get if we selected\nthe ones that we",
    "start": "830550",
    "end": "832320"
  },
  {
    "text": "were most uncertain about.",
    "start": "832320",
    "end": "833620"
  },
  {
    "text": "If we now subsample for\ndiversity specifically,",
    "start": "833620",
    "end": "836910"
  },
  {
    "text": "we get things that\nI would say maybe",
    "start": "836910",
    "end": "838529"
  },
  {
    "text": "look a little bit less\ncorrelated, slightly more",
    "start": "838530",
    "end": "840900"
  },
  {
    "text": "diverse.",
    "start": "840900",
    "end": "842040"
  },
  {
    "text": "Back to the satellite pose\nestimation example again.",
    "start": "842040",
    "end": "845250"
  },
  {
    "text": "Initially, we were sampling\nby highest uncertainty.",
    "start": "845250",
    "end": "847420"
  },
  {
    "text": "And I would say that the\ntwo that we were selecting",
    "start": "847420",
    "end": "848910"
  },
  {
    "text": "were from the same\nclass, the same type",
    "start": "848910",
    "end": "850962"
  },
  {
    "text": "of out-of-distribution.",
    "start": "850962",
    "end": "851920"
  },
  {
    "text": "They both kind of have\na lens flare, right?",
    "start": "851920",
    "end": "853779"
  },
  {
    "text": "If you select for diversity\nexplicitly, the sorts of things",
    "start": "853780",
    "end": "856890"
  },
  {
    "text": "you start seeing start to sample\nfrom the different classes",
    "start": "856890",
    "end": "860040"
  },
  {
    "text": "or types of out-of-distribution.",
    "start": "860040",
    "end": "861399"
  },
  {
    "text": "So you're kind of\ngetting more information.",
    "start": "861400",
    "end": "863760"
  },
  {
    "text": "OK, so great.",
    "start": "863760",
    "end": "864440"
  },
  {
    "text": "We've seen this qualitatively,\nbut the real proof is,",
    "start": "864440",
    "end": "866970"
  },
  {
    "text": "quantitatively, does this work\nin the full data life cycle?",
    "start": "866970",
    "end": "869769"
  },
  {
    "text": "Does this actually\nresult in an improvement?",
    "start": "869770",
    "end": "871690"
  },
  {
    "text": "So now, we'll request labels\nand we'll retrain the model",
    "start": "871690",
    "end": "874680"
  },
  {
    "text": "and we'll do this over\nits full life cycle.",
    "start": "874680",
    "end": "876930"
  },
  {
    "text": "So that's what we're asking\nis, again, coming back",
    "start": "876930",
    "end": "879300"
  },
  {
    "text": "to that idea of in the\nfull data life cycle,",
    "start": "879300",
    "end": "881399"
  },
  {
    "text": "what is the tradeoff between\nlabeling cost and performance?",
    "start": "881400",
    "end": "885453"
  },
  {
    "text": "So as a reminder, this\nis kind of what I think",
    "start": "885453",
    "end": "887370"
  },
  {
    "text": "of as the data life cycle.",
    "start": "887370",
    "end": "889380"
  },
  {
    "text": "And what's changing here is just\nthe images that each of these",
    "start": "889380",
    "end": "893370"
  },
  {
    "text": "algorithms flag for relabeling.",
    "start": "893370",
    "end": "894672"
  },
  {
    "text": "For each of these\nalgorithms, we'll",
    "start": "894672",
    "end": "896130"
  },
  {
    "text": "give them like a fixed budget,\nwhich is the number of labels",
    "start": "896130",
    "end": "898200"
  },
  {
    "text": "that they're allowed to request.",
    "start": "898200",
    "end": "899500"
  },
  {
    "text": "And that's the only thing\nthat's changing here.",
    "start": "899500",
    "end": "901458"
  },
  {
    "text": "They're still going through the\nsame life cycle individually.",
    "start": "901458",
    "end": "904080"
  },
  {
    "text": "OK.",
    "start": "904080",
    "end": "904690"
  },
  {
    "text": "So, let's look at\nthe performance",
    "start": "904690",
    "end": "907170"
  },
  {
    "text": "versus cost tradeoffs.",
    "start": "907170",
    "end": "908230"
  },
  {
    "text": "So on the x-axis, we'll\nplot the average improvement",
    "start": "908230",
    "end": "910740"
  },
  {
    "text": "in model performance.",
    "start": "910740",
    "end": "911740"
  },
  {
    "text": "I'll talk about improvement.",
    "start": "911740",
    "end": "913020"
  },
  {
    "text": "On the y-axis is\nthe labeling cost.",
    "start": "913020",
    "end": "914528"
  },
  {
    "text": "So essentially, what percentage\nof out-of-distribution inputs",
    "start": "914528",
    "end": "917070"
  },
  {
    "text": "am I labeling?",
    "start": "917070",
    "end": "918000"
  },
  {
    "text": "Now, I'm benchmarking\nthis against let's say",
    "start": "918000",
    "end": "920010"
  },
  {
    "text": "we label nothing.",
    "start": "920010",
    "end": "920760"
  },
  {
    "text": "That's the black\ntriangle down here.",
    "start": "920760",
    "end": "922540"
  },
  {
    "text": "If you label\nnothing, even if you",
    "start": "922540",
    "end": "924389"
  },
  {
    "text": "say out-of-distribution inputs,\nwe're not going to label it.",
    "start": "924390",
    "end": "926110"
  },
  {
    "text": "So we just have our\nbaseline performance.",
    "start": "926110",
    "end": "927730"
  },
  {
    "text": "Whatever we did during\nthe original training,",
    "start": "927730",
    "end": "929605"
  },
  {
    "text": "that's all we get.",
    "start": "929605",
    "end": "930370"
  },
  {
    "text": "So that's our baseline\nperformance, a 0% improvement",
    "start": "930370",
    "end": "932880"
  },
  {
    "text": "in performance, and\nwe're not labeling",
    "start": "932880",
    "end": "934650"
  },
  {
    "text": "any of our\nout-of-distribution inputs.",
    "start": "934650",
    "end": "936233"
  },
  {
    "text": "We're at 0,0 essentially.",
    "start": "936233",
    "end": "937782"
  },
  {
    "text": "On the flip side, let's just say\nwe don't care about the budget.",
    "start": "937783",
    "end": "940450"
  },
  {
    "text": "We're just going to\nlabel every time we see",
    "start": "940450",
    "end": "941580"
  },
  {
    "text": "an out-of-distribution input.",
    "start": "941580",
    "end": "942690"
  },
  {
    "text": "No such thing as a budget,\nwe're going to label everything.",
    "start": "942690",
    "end": "945148"
  },
  {
    "text": "So that's 100% cost.",
    "start": "945148",
    "end": "946003"
  },
  {
    "text": "And theoretically, also the most\ninformation given to the model.",
    "start": "946003",
    "end": "948670"
  },
  {
    "text": "So 100% improvement\nin model performance.",
    "start": "948670",
    "end": "952420"
  },
  {
    "text": "And so with those\ntwo benchmarks,",
    "start": "952420",
    "end": "953950"
  },
  {
    "text": "let's start thinking about\nways to go in between.",
    "start": "953950",
    "end": "956140"
  },
  {
    "text": "Rather than those\ntwo extremes, how",
    "start": "956140",
    "end": "957760"
  },
  {
    "text": "about we start\nselecting randomly",
    "start": "957760",
    "end": "959410"
  },
  {
    "text": "some of those\nout-of-distribution inputs?",
    "start": "959410",
    "end": "961160"
  },
  {
    "text": "So between 5% to\n75%, let's start",
    "start": "961160",
    "end": "963699"
  },
  {
    "text": "subselecting some\nout-of-distribution inputs.",
    "start": "963700",
    "end": "966530"
  },
  {
    "text": "And perhaps unsurprisingly,\nyou see this kind of tradeoff,",
    "start": "966530",
    "end": "969100"
  },
  {
    "text": "right?",
    "start": "969100",
    "end": "969600"
  },
  {
    "text": "So the more information\nyou give to the model,",
    "start": "969600",
    "end": "971529"
  },
  {
    "text": "the more labeling you do,\nthe better model performance",
    "start": "971530",
    "end": "973780"
  },
  {
    "text": "you get.",
    "start": "973780",
    "end": "975273"
  },
  {
    "text": "We can be a little\nbit more intelligent.",
    "start": "975273",
    "end": "976940"
  },
  {
    "text": "One of the things\nwe proposed was",
    "start": "976940",
    "end": "978315"
  },
  {
    "text": "to say, OK, let's use that\nmeasure of SCOD uncertainty.",
    "start": "978315",
    "end": "981250"
  },
  {
    "text": "So instead of just\npicking 5% randomly,",
    "start": "981250",
    "end": "983380"
  },
  {
    "text": "let's pick the 5% that the\nmodel is most uncertain about,",
    "start": "983380",
    "end": "985960"
  },
  {
    "text": "or the 75% that the model\nis most uncertain about.",
    "start": "985960",
    "end": "988043"
  },
  {
    "text": "And you see that we do\na little bit better.",
    "start": "988043",
    "end": "989835"
  },
  {
    "text": "For the same labeling cost,\nwe get slightly better model",
    "start": "989835",
    "end": "992530"
  },
  {
    "text": "performance.",
    "start": "992530",
    "end": "993610"
  },
  {
    "text": "And then if we start thinking\nabout diversity, where",
    "start": "993610",
    "end": "996399"
  },
  {
    "text": "we actually explicitly\nchoosing the 5% or 75%,",
    "start": "996400",
    "end": "999370"
  },
  {
    "text": "that collectively gives\nthe model more information,",
    "start": "999370",
    "end": "1002520"
  },
  {
    "text": "we see that we do a lot better.",
    "start": "1002520",
    "end": "1004110"
  },
  {
    "text": "We, for the same\nlabeling cost, we",
    "start": "1004110",
    "end": "1005730"
  },
  {
    "text": "get much better model\nperformance improvement.",
    "start": "1005730",
    "end": "1007980"
  },
  {
    "text": "In this particular\ncase, for this data set,",
    "start": "1007980",
    "end": "1009870"
  },
  {
    "text": "we get performance comparable\nto labeling 100% of inputs",
    "start": "1009870",
    "end": "1014820"
  },
  {
    "text": "while only labeling\nabout 50% of them.",
    "start": "1014820",
    "end": "1017760"
  },
  {
    "text": "The key idea I want\nto leave you with",
    "start": "1017760",
    "end": "1019567"
  },
  {
    "text": "is that we've talked\nabout a framework",
    "start": "1019567",
    "end": "1021150"
  },
  {
    "text": "to evaluate the full\ndata life cycle.",
    "start": "1021150",
    "end": "1023293"
  },
  {
    "text": "We've talked about an algorithm\nto select a diverse subset",
    "start": "1023293",
    "end": "1025709"
  },
  {
    "text": "of test inputs.",
    "start": "1025710",
    "end": "1026919"
  },
  {
    "text": "And one thing I\njust want to put out",
    "start": "1026920",
    "end": "1028470"
  },
  {
    "text": "there is that we've also been\ndeveloping this open source",
    "start": "1028470",
    "end": "1030845"
  },
  {
    "text": "benchmark that is application\nagnostic to compare algorithms",
    "start": "1030845",
    "end": "1033959"
  },
  {
    "text": "that do this kind of\ndetection and adaptation",
    "start": "1033960",
    "end": "1036569"
  },
  {
    "text": "to out-of-distribution inputs.",
    "start": "1036569",
    "end": "1039095"
  },
  {
    "text": "I think I've got\nlike one minute.",
    "start": "1039095",
    "end": "1040470"
  },
  {
    "text": "In that one minute I\nhave, I'll talk quickly",
    "start": "1040470",
    "end": "1042900"
  },
  {
    "text": "about some other\npieces of work that",
    "start": "1042900",
    "end": "1044459"
  },
  {
    "text": "are being done in the lab\nthinking about this problem.",
    "start": "1044460",
    "end": "1046720"
  },
  {
    "text": "So if you've been kind\nof following along",
    "start": "1046720",
    "end": "1048270"
  },
  {
    "text": "or if you're familiar\nwith continual learning,",
    "start": "1048270",
    "end": "1049620"
  },
  {
    "text": "you're probably\nalready thinking about,",
    "start": "1049620",
    "end": "1051480"
  },
  {
    "text": "well, the more\nretraining you do,",
    "start": "1051480",
    "end": "1052860"
  },
  {
    "text": "what do you do about\nforgetting your original data?",
    "start": "1052860",
    "end": "1054750"
  },
  {
    "text": "This is a common problem, right?",
    "start": "1054750",
    "end": "1056117"
  },
  {
    "text": "So you keep retraining on\nnew classes, what if you",
    "start": "1056117",
    "end": "1058200"
  },
  {
    "text": "forget your original data?",
    "start": "1058200",
    "end": "1059470"
  },
  {
    "text": "And we've shown\nthat there's ways",
    "start": "1059470",
    "end": "1060845"
  },
  {
    "text": "of utilizing the same\nuncertainty estimates to help",
    "start": "1060845",
    "end": "1063450"
  },
  {
    "text": "you generate a regularization\nterm to prevent",
    "start": "1063450",
    "end": "1065909"
  },
  {
    "text": "some of that forgetting.",
    "start": "1065910",
    "end": "1067500"
  },
  {
    "text": "We've also started\nthinking about,",
    "start": "1067500",
    "end": "1069120"
  },
  {
    "text": "can we construct\nruntime monitors",
    "start": "1069120",
    "end": "1070860"
  },
  {
    "text": "if you know the different\nthings that might",
    "start": "1070860",
    "end": "1072757"
  },
  {
    "text": "cause your out-of-distribution?",
    "start": "1072758",
    "end": "1074050"
  },
  {
    "text": "So I've been talking about\nthese different classes of OOD.",
    "start": "1074050",
    "end": "1076590"
  },
  {
    "text": "Well, can you actually\ndistinguish between them?",
    "start": "1076590",
    "end": "1078370"
  },
  {
    "text": "Can you construct\nruntime monitors",
    "start": "1078370",
    "end": "1079470"
  },
  {
    "text": "that distinguish between\ndifferent classes",
    "start": "1079470",
    "end": "1081220"
  },
  {
    "text": "of out-of-distribution?",
    "start": "1081220",
    "end": "1082275"
  },
  {
    "text": "So we have some work there.",
    "start": "1082275",
    "end": "1083400"
  },
  {
    "text": "And we're also\ntalking about we said",
    "start": "1083400",
    "end": "1085440"
  },
  {
    "text": "that expensive piece\nin adapting to OOD",
    "start": "1085440",
    "end": "1087720"
  },
  {
    "text": "is actually\ngenerating the labels.",
    "start": "1087720",
    "end": "1089289"
  },
  {
    "text": "So how much of this can you\ndo in the absence of labels?",
    "start": "1089290",
    "end": "1091720"
  },
  {
    "text": "So in a self-supervised\nfashion, how much of this",
    "start": "1091720",
    "end": "1093840"
  },
  {
    "text": "can you kind of\ndo by just finding",
    "start": "1093840",
    "end": "1095460"
  },
  {
    "text": "invariant features between\nin-distribution and",
    "start": "1095460",
    "end": "1097377"
  },
  {
    "text": "out-of-distribution data?",
    "start": "1097377",
    "end": "1099269"
  },
  {
    "text": "Yeah, so the main thing I hope\nI've been able to convince you",
    "start": "1099270",
    "end": "1102690"
  },
  {
    "text": "is that if you're\ngoing to want to adapt",
    "start": "1102690",
    "end": "1104673"
  },
  {
    "text": "to out-of-distribution\ninputs over a lifetime,",
    "start": "1104673",
    "end": "1106590"
  },
  {
    "text": "you would benefit from\ncurating for diversity.",
    "start": "1106590",
    "end": "1109679"
  },
  {
    "text": "But on that note, yeah, just\nhappy to take questions.",
    "start": "1109680",
    "end": "1112420"
  },
  {
    "text": "I have one.",
    "start": "1124220",
    "end": "1125090"
  },
  {
    "text": "Your abstract mentioned\nphysics-based.",
    "start": "1125090",
    "end": "1127830"
  },
  {
    "text": "Yes.",
    "start": "1127830",
    "end": "1128330"
  },
  {
    "text": "And here, I guess,\nthe physics is--",
    "start": "1128330",
    "end": "1132289"
  },
  {
    "text": "is what?",
    "start": "1132290",
    "end": "1132980"
  },
  {
    "text": "So I actually ended up splitting\nmy talk into two pieces",
    "start": "1132980",
    "end": "1135650"
  },
  {
    "text": "and then discarded one of them.",
    "start": "1135650",
    "end": "1137240"
  },
  {
    "text": "Sorry about that.",
    "start": "1137240",
    "end": "1138120"
  },
  {
    "text": "OK.",
    "start": "1138120",
    "end": "1138620"
  },
  {
    "text": "But we can talk about\nthat other piece.",
    "start": "1138620",
    "end": "1140670"
  },
  {
    "text": "OK.",
    "start": "1140670",
    "end": "1141170"
  },
  {
    "text": "Some other time.",
    "start": "1141170",
    "end": "1141840"
  },
  {
    "text": "Very basic questions.",
    "start": "1145040",
    "end": "1146250"
  },
  {
    "text": "When you were saying\nthat adapting the model.",
    "start": "1146250",
    "end": "1148820"
  },
  {
    "text": "So mainly what you were\ndoing is the changing",
    "start": "1148820",
    "end": "1150980"
  },
  {
    "text": "the parameters of a\nfixed model, right?",
    "start": "1150980",
    "end": "1152625"
  },
  {
    "text": "You are not changing the whole\narchitecture of the model,",
    "start": "1152625",
    "end": "1155000"
  },
  {
    "text": "right?\nNot changing architecture.",
    "start": "1155000",
    "end": "1156050"
  },
  {
    "text": "So essentially\nupdating the weights.",
    "start": "1156050",
    "end": "1157775"
  },
  {
    "text": "Just fine tuning you are doing.",
    "start": "1157775",
    "end": "1159330"
  },
  {
    "text": "But is it enough often?",
    "start": "1159330",
    "end": "1160529"
  },
  {
    "text": "Because if the new samples\nare very different,",
    "start": "1160530",
    "end": "1163370"
  },
  {
    "text": "you might have to just\nrepair the model in a very",
    "start": "1163370",
    "end": "1165530"
  },
  {
    "text": "different way rather than just\ntuning the parameters, right?",
    "start": "1165530",
    "end": "1168030"
  },
  {
    "text": "That's a good question.",
    "start": "1168030",
    "end": "1168988"
  },
  {
    "text": "And it really\ndepends on how severe",
    "start": "1168988",
    "end": "1170690"
  },
  {
    "text": "your distribution shift is and\nwhether your original model",
    "start": "1170690",
    "end": "1173299"
  },
  {
    "text": "is expressive enough to capture\nyour distribution shift.",
    "start": "1173300",
    "end": "1176370"
  },
  {
    "text": "So you're right.",
    "start": "1176370",
    "end": "1177558"
  },
  {
    "text": "And you would have to keep\nmonitoring performance",
    "start": "1177558",
    "end": "1179600"
  },
  {
    "text": "to see if that\nhypothesis is valid.",
    "start": "1179600",
    "end": "1182240"
  },
  {
    "text": "In a lot of cases where things\nare just slightly shifted",
    "start": "1182240",
    "end": "1185270"
  },
  {
    "text": "and you see gradual\nshifts, you know,",
    "start": "1185270",
    "end": "1186992"
  },
  {
    "text": "you were trying to do\nsomething like pose estimation,",
    "start": "1186992",
    "end": "1189200"
  },
  {
    "text": "you'd still be\nusing a CNN, right?",
    "start": "1189200",
    "end": "1191070"
  },
  {
    "text": "Yeah.",
    "start": "1191070",
    "end": "1191570"
  },
  {
    "text": "All you really need to do\nis update your weights.",
    "start": "1191570",
    "end": "1193490"
  },
  {
    "text": "It's still expressive enough.",
    "start": "1193490",
    "end": "1194690"
  },
  {
    "text": "So this kind of\nmethod would work.",
    "start": "1194690",
    "end": "1196106"
  },
  {
    "text": "But there are definitely\ncases where you're right,",
    "start": "1196107",
    "end": "1198410"
  },
  {
    "text": "where it's a drastic\nenough distribution",
    "start": "1198410",
    "end": "1200150"
  },
  {
    "text": "shift that you might actually\nwant to completely retrain.",
    "start": "1200150",
    "end": "1202580"
  },
  {
    "text": "Have you a method for doing\nthat, or doing that smartly?",
    "start": "1202580",
    "end": "1206690"
  },
  {
    "text": "So I think one of the\nthings you could do",
    "start": "1206690",
    "end": "1208793"
  },
  {
    "text": "is kind of just keep\ntrack of your performance",
    "start": "1208793",
    "end": "1210710"
  },
  {
    "text": "as you're going along.",
    "start": "1210710",
    "end": "1211980"
  },
  {
    "text": "And if you don't see a good\nimprovement in performance",
    "start": "1211980",
    "end": "1214669"
  },
  {
    "text": "by fine tuning,\nyou're probably going",
    "start": "1214670",
    "end": "1216740"
  },
  {
    "text": "to have to start\nthinking about that.",
    "start": "1216740",
    "end": "1219530"
  },
  {
    "text": "Yeah, about maybe choosing\na different model.",
    "start": "1219530",
    "end": "1221992"
  },
  {
    "text": "I think some of that\nis also a little bit",
    "start": "1221992",
    "end": "1223700"
  },
  {
    "text": "about knowing initially what\nyour model is capable of, right?",
    "start": "1223700",
    "end": "1227264"
  },
  {
    "text": "So if you're still dealing\nwith the similar type of image",
    "start": "1227265",
    "end": "1229640"
  },
  {
    "text": "inputs, if you're still dealing\nwith similar predictions",
    "start": "1229640",
    "end": "1233090"
  },
  {
    "text": "that you're doing, it's\nreasonable to assume",
    "start": "1233090",
    "end": "1235250"
  },
  {
    "text": "that in those cases,\nit doesn't make sense",
    "start": "1235250",
    "end": "1237988"
  },
  {
    "text": "to change your architecture.",
    "start": "1237988",
    "end": "1239155"
  },
  {
    "text": "But real world is\nfull of surprises.",
    "start": "1239155",
    "end": "1241130"
  },
  {
    "text": "Definitely.",
    "start": "1241130",
    "end": "1242390"
  },
  {
    "text": "Thank you.",
    "start": "1242390",
    "end": "1242910"
  },
  {
    "text": "And which domains are more\nprone to distribution shift?",
    "start": "1246200",
    "end": "1248953"
  },
  {
    "text": "I don't know if you've\ndone some work on that.",
    "start": "1248953",
    "end": "1250870"
  },
  {
    "text": "Sorry, could you repeat that?",
    "start": "1250870",
    "end": "1251340"
  },
  {
    "text": "Which domains are more\nprone to distribution shift.",
    "start": "1251340",
    "end": "1254164"
  },
  {
    "text": "Oh, yes.",
    "start": "1254165",
    "end": "1255450"
  },
  {
    "text": "So we've talked a lot about\nperception right here,",
    "start": "1255450",
    "end": "1258149"
  },
  {
    "text": "and so I'll stick to\nsome perception examples.",
    "start": "1258150",
    "end": "1260235"
  },
  {
    "text": "I think a lot of autonomous\ndriving companies",
    "start": "1260235",
    "end": "1262110"
  },
  {
    "text": "think a lot about distribution\nshifts because, you know,",
    "start": "1262110",
    "end": "1265530"
  },
  {
    "text": "I've been told this\nanecdote is that, you know,",
    "start": "1265530",
    "end": "1268655"
  },
  {
    "text": "you think about\ntraining in rain.",
    "start": "1268655",
    "end": "1270030"
  },
  {
    "text": "You go out in San Francisco,\nyou train in rain.",
    "start": "1270030",
    "end": "1272083"
  },
  {
    "text": "But then rain apparently\nis a little bit",
    "start": "1272083",
    "end": "1273750"
  },
  {
    "text": "different in each\ncity, depending",
    "start": "1273750",
    "end": "1275125"
  },
  {
    "text": "on the size of the\nraindrop and the type",
    "start": "1275125",
    "end": "1276920"
  },
  {
    "text": "of humidity in the atmosphere.",
    "start": "1276920",
    "end": "1278170"
  },
  {
    "text": "So that itself is just\na distribution shift.",
    "start": "1278170",
    "end": "1279700"
  },
  {
    "text": "You've trained on\nrain, but you tried",
    "start": "1279700",
    "end": "1281242"
  },
  {
    "text": "doing the same kind of\nrainy weather driving",
    "start": "1281242",
    "end": "1283139"
  },
  {
    "text": "in a different city.",
    "start": "1283140",
    "end": "1284200"
  },
  {
    "text": "That's a distribution shift.",
    "start": "1284200",
    "end": "1285460"
  },
  {
    "text": "You can overcome it by just,\nyou know, training with that,",
    "start": "1285460",
    "end": "1288143"
  },
  {
    "text": "but that's a type of\ndistribution shift.",
    "start": "1288143",
    "end": "1289809"
  },
  {
    "text": "I think the ones that are\nmaybe more common than people",
    "start": "1289810",
    "end": "1292260"
  },
  {
    "text": "think about are like\nchanges in lighting.",
    "start": "1292260",
    "end": "1294000"
  },
  {
    "text": "So that forms a\ndistribution shift.",
    "start": "1294000",
    "end": "1296983"
  },
  {
    "text": "One that a lot of\npeople care about also",
    "start": "1296983",
    "end": "1298650"
  },
  {
    "text": "is sensor degradation.",
    "start": "1298650",
    "end": "1299800"
  },
  {
    "text": "So as you have the same sensors\nout in the field for a while,",
    "start": "1299800",
    "end": "1302520"
  },
  {
    "text": "your sensors can\ndegrade over time",
    "start": "1302520",
    "end": "1304305"
  },
  {
    "text": "and that will change slightly\nwhat your image looks like.",
    "start": "1304305",
    "end": "1306680"
  },
  {
    "text": "Or you might just have slightly\ndifferent configurations",
    "start": "1306680",
    "end": "1308890"
  },
  {
    "text": "of sensors.",
    "start": "1308890",
    "end": "1309390"
  },
  {
    "text": "You might mount your sensors\nslightly differently.",
    "start": "1309390",
    "end": "1311480"
  },
  {
    "text": "And that can affect\na perception module.",
    "start": "1311480",
    "end": "1314410"
  },
  {
    "text": "That little bit of\ndrift and exactly",
    "start": "1314410",
    "end": "1316690"
  },
  {
    "text": "where the sensors are mounted\ncan form a distribution shift.",
    "start": "1316690",
    "end": "1319190"
  },
  {
    "text": "And these are things you\nwould want to adapt to.",
    "start": "1319190",
    "end": "1321827"
  },
  {
    "text": "But just some ideas only\nin the perception field.",
    "start": "1321828",
    "end": "1323870"
  },
  {
    "text": "We can talk about\nother modules as well.",
    "start": "1323870",
    "end": "1325860"
  },
  {
    "text": "Well, thank you very much.",
    "start": "1330237",
    "end": "1331320"
  },
  {
    "text": "I have a question.",
    "start": "1331320",
    "end": "1332139"
  },
  {
    "text": "[INAUDIBLE] your SCOD, it\nhappens entirely at the edge",
    "start": "1332140",
    "end": "1335590"
  },
  {
    "text": "on the--",
    "start": "1335590",
    "end": "1336590"
  },
  {
    "text": "OK.",
    "start": "1336590",
    "end": "1337090"
  },
  {
    "text": "Yes.",
    "start": "1337090",
    "end": "1337590"
  },
  {
    "text": "We intend it to be [INAUDIBLE].",
    "start": "1337590",
    "end": "1338987"
  },
  {
    "text": "And you have some\nGitHub stuff where--",
    "start": "1338987",
    "end": "1340570"
  },
  {
    "text": "because there's a number\nof nice active learning",
    "start": "1340570",
    "end": "1342570"
  },
  {
    "text": "libraries and it'd be\nnice to give this a whirl.",
    "start": "1342570",
    "end": "1345710"
  },
  {
    "text": "Yeah.",
    "start": "1345710",
    "end": "1347770"
  },
  {
    "text": "We'd love that.",
    "start": "1347770",
    "end": "1349480"
  },
  {
    "text": "Great.",
    "start": "1349480",
    "end": "1350020"
  },
  {
    "text": "Thanks.",
    "start": "1350020",
    "end": "1351900"
  }
]
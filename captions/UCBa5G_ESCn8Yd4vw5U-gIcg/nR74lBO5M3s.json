[
  {
    "text": "uh so this talk is based on our paper uh which is titled Google's multilingual neural machine translation system and",
    "start": "11759",
    "end": "18760"
  },
  {
    "text": "then uh we have a colon and you say enabling zero shot translation so my",
    "start": "18760",
    "end": "24160"
  },
  {
    "text": "name is Melvin this I'm from the Google translate team but this is a joint work done with many people from the brain",
    "start": "24160",
    "end": "30880"
  },
  {
    "text": "Google brain team and the Google translate team uh first of all happy International Women's Day to",
    "start": "30880",
    "end": "39800"
  },
  {
    "text": "everyone see so why do we care about uh translations so about 50% of the",
    "start": "41039",
    "end": "46840"
  },
  {
    "text": "internet is in English and only 20% of the world's population speak English and",
    "start": "46840",
    "end": "54239"
  },
  {
    "text": "on the right you see this graph these are the top 10 languages on the web um English Chinese Russian German Spanish",
    "start": "54239",
    "end": "62239"
  },
  {
    "text": "Japanese French polish Korean and Portuguese and they make up about 80% of",
    "start": "62239",
    "end": "68400"
  },
  {
    "text": "the web and you notice that languages like Arabic or Hindi which makes up",
    "start": "68400",
    "end": "74240"
  },
  {
    "text": "about 300 million speakers each they're not even in the top 10 so Google's mission is to make this information",
    "start": "74240",
    "end": "80520"
  },
  {
    "text": "accessible to everyone so we definitely need translations about Google",
    "start": "80520",
    "end": "87479"
  },
  {
    "text": "Translate is uh we have about about 1 billion translations every day and we",
    "start": "87479",
    "end": "94000"
  },
  {
    "text": "have about half a billion monthly active users and we support about 103 different",
    "start": "94000",
    "end": "100280"
  },
  {
    "text": "languages question on your last yeah so I've actually spoken with",
    "start": "100280",
    "end": "107520"
  },
  {
    "text": "Portuguese and the thing they point out to me is the vast majority of Portuguese",
    "start": "107520",
    "end": "113240"
  },
  {
    "text": "are in the Brazilian domain like five times as many yeah so you're you're saying that are you using the PT there",
    "start": "113240",
    "end": "120719"
  },
  {
    "text": "or any of the others no we Club both of them it's not we don't just that's fine",
    "start": "120719",
    "end": "125960"
  },
  {
    "text": "that was not clear yeah and please ask questions I have a lot of time yeah I",
    "start": "125960",
    "end": "131720"
  },
  {
    "text": "have a lot of time yeah country Cod language codes not country codes so about uh this slide one",
    "start": "131720",
    "end": "138440"
  },
  {
    "text": "interesting thing about Google Translate is is one of those products where 95% of",
    "start": "138440",
    "end": "143599"
  },
  {
    "text": "usage is outside of the US so our top countries are like Brazil India Mexico",
    "start": "143599",
    "end": "150599"
  },
  {
    "text": "um Germany Italy but you'd expect every other Google product has 90% usage in the US and you know 10% elsewhere how do",
    "start": "150599",
    "end": "159159"
  },
  {
    "text": "I know what you machine translation so it started with Warren Weaver in",
    "start": "159159",
    "end": "165200"
  },
  {
    "text": "1949 um he used this uh tall towers analogy so you're in a tower on the left",
    "start": "165200",
    "end": "172159"
  },
  {
    "text": "and you want to communicate with someone on the right he says do not shout from Tower to Tower but go down to the common",
    "start": "172159",
    "end": "178239"
  },
  {
    "text": "basement and try to talk to each other each other and um he was hinting at some kind of an interlingua which exists in",
    "start": "178239",
    "end": "184840"
  },
  {
    "text": "the basement and uh let's look at a brief uh history of machine translation",
    "start": "184840",
    "end": "192560"
  },
  {
    "text": "so it started with uh in the 1950s and then 1960s cyran which is the",
    "start": "192560",
    "end": "198640"
  },
  {
    "text": "first machine translation company uh was founded in the 1990s people were doing",
    "start": "198640",
    "end": "204920"
  },
  {
    "text": "uh IBM models word-based models and then people started doing statistical Mt",
    "start": "204920",
    "end": "210959"
  },
  {
    "text": "and uh in the 2000s the there's this thing called phras space machine translation that became very popular and",
    "start": "210959",
    "end": "217480"
  },
  {
    "text": "that started being the state-ofthe-art for for over a decade actually and then",
    "start": "217480",
    "end": "222840"
  },
  {
    "text": "you started seeing applications that started to use deep learning which is",
    "start": "222840",
    "end": "228120"
  },
  {
    "text": "using these neural networks and the first success was uh in speech recognition but slowly it uh caught up",
    "start": "228120",
    "end": "235040"
  },
  {
    "text": "to machine translation so about 2014 was the first neural machine trans ation",
    "start": "235040",
    "end": "240200"
  },
  {
    "text": "paper and then 2016 there was our paper from Google but",
    "start": "240200",
    "end": "246400"
  },
  {
    "text": "uh a lot has happened between 2014 and now so here is uh well before",
    "start": "246400",
    "end": "254280"
  },
  {
    "text": "that uh here is a quick intro about what phrase based machine translation did it",
    "start": "254280",
    "end": "260239"
  },
  {
    "text": "had uh it split the sentence into a bunch of pieces and it translated phrase by phrase and at the end it tried to put",
    "start": "260239",
    "end": "266840"
  },
  {
    "text": "it together like a puzzle piece so it translated one puzzle piece the next one and then using it tried to stitch it",
    "start": "266840",
    "end": "272639"
  },
  {
    "text": "together but when you have a neural machine translation this is an exaggeration but you can think of it as",
    "start": "272639",
    "end": "278400"
  },
  {
    "text": "a painter trying to paint it from scratch uh so it's trying to make continuous and a global decision instead",
    "start": "278400",
    "end": "283960"
  },
  {
    "text": "of making these uh local decisions here's what's happened in",
    "start": "283960",
    "end": "289039"
  },
  {
    "text": "neural Mt from 2014 to 17 so uh you initially had the first paper come out",
    "start": "289039",
    "end": "295639"
  },
  {
    "text": "then there was a paper on large vocabulary nmt then we saw the same",
    "start": "295639",
    "end": "300840"
  },
  {
    "text": "architecture being used for image captioning open Mt in 2015 was the first",
    "start": "300840",
    "end": "306880"
  },
  {
    "text": "um public competition that had a neural system in it wt5 also the first WMT that",
    "start": "306880",
    "end": "313639"
  },
  {
    "text": "had a neural system in it bunch of work on subword neural machine translation",
    "start": "313639",
    "end": "318840"
  },
  {
    "text": "people started doing multilingual neural machine translation multisource wt6 by",
    "start": "318840",
    "end": "325039"
  },
  {
    "text": "that point the 90% of the winners were neural machine translation system so it's it's it had already started to",
    "start": "325039",
    "end": "330759"
  },
  {
    "text": "change and people were trying to do zero resource neural machine translation then",
    "start": "330759",
    "end": "335800"
  },
  {
    "text": "we had Google's paper and the papers on fully character neural machine",
    "start": "335800",
    "end": "341479"
  },
  {
    "text": "translation and finally the zero shot translation but you can see that there's",
    "start": "341479",
    "end": "347160"
  },
  {
    "text": "a lot happening a lot of people are looking into it and it's an interesting research",
    "start": "347160",
    "end": "353440"
  },
  {
    "text": "topic so just a step back uh what is uh sequence modeling so you want want to",
    "start": "353440",
    "end": "359880"
  },
  {
    "text": "predict uh the likelihood of a sequence so what is the probability of this",
    "start": "359880",
    "end": "364960"
  },
  {
    "text": "sequence right and a sequence can be uh a picture a video some speech or it can",
    "start": "364960",
    "end": "372800"
  },
  {
    "text": "also be a piece of text uh the typical example is a language",
    "start": "372800",
    "end": "379039"
  },
  {
    "text": "model so in a language model you want to say How likely is a given sentence so",
    "start": "379039",
    "end": "385039"
  },
  {
    "text": "you would uh you will model this as a product of these condition probabilities",
    "start": "385039",
    "end": "391000"
  },
  {
    "text": "and in an engr language model you would have the nth order Marco assumption which is that you only depend on the",
    "start": "391000",
    "end": "397080"
  },
  {
    "text": "previous n minus one words and you don't depend on anything else but we want non- maravian sequence",
    "start": "397080",
    "end": "404520"
  },
  {
    "text": "modeling which is in maravian modeling we ignore anything that's beyond the context but in non-markovian we want to",
    "start": "404520",
    "end": "411360"
  },
  {
    "text": "support multiple variable length sequences so you would end up having to model the entire sequence right and they",
    "start": "411360",
    "end": "417919"
  },
  {
    "text": "have to be variable length so what's one way to handle variable lens sequences you use recurrence and that's where",
    "start": "417919",
    "end": "425240"
  },
  {
    "text": "these recurrent neural networks come into play called rnns so here is a small example if you",
    "start": "425240",
    "end": "432879"
  },
  {
    "text": "wanted to model this sentence the cat sat on with an RNN you would have the input sequence and then you have an",
    "start": "432879",
    "end": "439680"
  },
  {
    "text": "internal memory state which is the one in purple that that keeps track of the state at each time step and then you",
    "start": "439680",
    "end": "446400"
  },
  {
    "text": "need a function that takes at each time step the input and the memory State and it can recurse at each time step so",
    "start": "446400",
    "end": "453400"
  },
  {
    "text": "you'd have probability of the and then you'd have probability of cat given everything else probably of sat given",
    "start": "453400",
    "end": "459520"
  },
  {
    "text": "everything else and so on some more information about rnns they",
    "start": "459520",
    "end": "466599"
  },
  {
    "text": "technically have unlimited depth because you can unroll the can you go back one slide yeah so in order to do that you",
    "start": "466599",
    "end": "474759"
  },
  {
    "text": "have to have a vocabulary yeah and you have to have a",
    "start": "474759",
    "end": "481159"
  },
  {
    "text": "complete representation of your yes you do but that may work for French because",
    "start": "481159",
    "end": "489479"
  },
  {
    "text": "of the academy Fran but it doesn't really work for English because English is constantly creating new words that's",
    "start": "489479",
    "end": "496520"
  },
  {
    "text": "that's a good point so I I actually get to that uh but that's an interesting question right you if you have a machine",
    "start": "496520",
    "end": "502639"
  },
  {
    "text": "translation system or you want to model a sequence you need to have an open vocabulary so you need to support",
    "start": "502639",
    "end": "508240"
  },
  {
    "text": "everything right uh and I get to that in a little bit uh more information is these are",
    "start": "508240",
    "end": "514880"
  },
  {
    "text": "they have unlimited depth they're General computers so they're also Universal function approximators so they",
    "start": "514880",
    "end": "521279"
  },
  {
    "text": "can learn any program so you can think of it think of it like this there is an input at every time step and then",
    "start": "521279",
    "end": "527279"
  },
  {
    "text": "there's a recurrence and it outputs a memory state that you can use how do you train this RNN is you",
    "start": "527279",
    "end": "535560"
  },
  {
    "text": "unroll the loop and you apply back propagation as you do to every other neural network so you would back",
    "start": "535560",
    "end": "541839"
  },
  {
    "text": "propagate through time and these rnns have problems in that they have this",
    "start": "541839",
    "end": "548040"
  },
  {
    "text": "problem of Vanishing or exploding gradients since the sequence is too long as you go further down the sequence your",
    "start": "548040",
    "end": "554240"
  },
  {
    "text": "gradients can explode or vanish and uh as the name suggests you need a long",
    "start": "554240",
    "end": "560120"
  },
  {
    "text": "time long-term memory which is why we use long short-term memories they were founded back uh in",
    "start": "560120",
    "end": "566000"
  },
  {
    "text": "1995 but they're very popular now so this is what we use uh so this is a vanilla RNN and then",
    "start": "566000",
    "end": "573480"
  },
  {
    "text": "there is an lstm RNN but for most practical purposes you can think of an lstm as a blackbox which is just a",
    "start": "573480",
    "end": "579600"
  },
  {
    "text": "better RNN that you can use and from sequence modeling now you",
    "start": "579600",
    "end": "586399"
  },
  {
    "text": "want to get to uh sequence to sequence modeling so you have an input sequence",
    "start": "586399",
    "end": "591519"
  },
  {
    "text": "and then you want to map it to an output sequence and here we call the left side",
    "start": "591519",
    "end": "597120"
  },
  {
    "text": "what is called an encoder the encoder is trying to encode the input sequence and then on the right side you have the",
    "start": "597120",
    "end": "602839"
  },
  {
    "text": "decoder which looks at the encoding of the input sentence and tries to predict the output sequence and since we already",
    "start": "602839",
    "end": "610519"
  },
  {
    "text": "said because we're using an RNN we can support uh any sequence lens in both the",
    "start": "610519",
    "end": "615720"
  },
  {
    "text": "input and the output so U here is the encoder which is",
    "start": "615720",
    "end": "621320"
  },
  {
    "text": "in pink so the cat sat and you can see that as each at each time step you're",
    "start": "621320",
    "end": "626440"
  },
  {
    "text": "trying to model the sequence and at this point this representation you're actually",
    "start": "626440",
    "end": "631959"
  },
  {
    "text": "modeling the entire sequence in that representation in that one vector it's a it's a vector of about thousand numbers",
    "start": "631959",
    "end": "638240"
  },
  {
    "text": "and you're modeling the entire input sequence in that one vector and now you want to decode So based on this you want",
    "start": "638240",
    "end": "645720"
  },
  {
    "text": "to predict what is my first Target token you're going to say d and then again you",
    "start": "645720",
    "end": "652360"
  },
  {
    "text": "predict what's the second given that I predicted d uh cuts and then the next word and you keep",
    "start": "652360",
    "end": "660399"
  },
  {
    "text": "doing this until you encounter an end of sequence token so when the model produces an end of sequence token we say",
    "start": "660399",
    "end": "666680"
  },
  {
    "text": "oh okay we're done decoding here is the output of the model so you can stack these sequence to",
    "start": "666680",
    "end": "674440"
  },
  {
    "text": "sequence model so you can have instead of having just one of these layers you can have multiple layers stacked on top of each other",
    "start": "674440",
    "end": "681200"
  },
  {
    "text": "and yeah and then there was a bottleneck",
    "start": "681200",
    "end": "687800"
  },
  {
    "text": "that I talked about uh because here you see the encoder is trying to encode the entire sequence and then when you want",
    "start": "687800",
    "end": "693639"
  },
  {
    "text": "to decode we use this mechanism called the attention that is trying to pay attention to every input in the encoder",
    "start": "693639",
    "end": "700880"
  },
  {
    "text": "so when when I'm trying to predict the first token I can look I can cheet and I can look up every one of the encodings",
    "start": "700880",
    "end": "708839"
  },
  {
    "text": "that I want to look at and the darker the line the more the attention it's giving to that sequence so when you're",
    "start": "708839",
    "end": "714000"
  },
  {
    "text": "trying to predict uh the first word saying knowledge you would want to pay attention to the Chinese word that means",
    "start": "714000",
    "end": "719800"
  },
  {
    "text": "knowledge much more than the other words so you can see that there's a dark line and then question yeah but you don't",
    "start": "719800",
    "end": "725519"
  },
  {
    "text": "look backwards you don't look backwards when you're in the second one you don't don't look at the you don't look back one in",
    "start": "725519",
    "end": "731600"
  },
  {
    "text": "the sequence you do look back at the last token you predicted okay yeah it's yeah you do",
    "start": "731600",
    "end": "738959"
  },
  {
    "text": "like the you know what you predicted previously so when you're decoding is you know what in the last one you don't",
    "start": "738959",
    "end": "744720"
  },
  {
    "text": "look all the way back you don't look all the way back you just look one back there",
    "start": "744720",
    "end": "750760"
  },
  {
    "text": "actually if you if you look at the picture there are lines which go to each Source word but some of them are almost",
    "start": "752760",
    "end": "761320"
  },
  {
    "text": "transparent because the weight of this is zero the weight is implemented it",
    "start": "761320",
    "end": "766639"
  },
  {
    "text": "computes a weighted sum over the source",
    "start": "766639",
    "end": "771560"
  },
  {
    "text": "sent to the point of Point yeah why I see so the words that are",
    "start": "771800",
    "end": "777160"
  },
  {
    "text": "closer to it probably influence that word so they have a higher weight yes and the ones that are far further",
    "start": "777160",
    "end": "783440"
  },
  {
    "text": "away have less influence on the ordering so it's similar to how a human would do it so",
    "start": "783440",
    "end": "790199"
  },
  {
    "text": "when you have a long sentence you read the entire sentence and then you start translating and then like oh I forgot what I had to translate I go and I look",
    "start": "790199",
    "end": "796720"
  },
  {
    "text": "back it's like okay I have to translate this segment I translate it and then you say oh I have to translate this segment I go I look back you kind of give a",
    "start": "796720",
    "end": "803880"
  },
  {
    "text": "mechanism for the model to attend to different things this is a mechanism is called Soft attention because it computes a probability distribution of a",
    "start": "803880",
    "end": "811040"
  },
  {
    "text": "source sentence and then takes a weighted sum so when it looks at this",
    "start": "811040",
    "end": "816920"
  },
  {
    "text": "word it's actually looking a little bit all around but mostly at this one and there is also hard attention where the",
    "start": "816920",
    "end": "824600"
  },
  {
    "text": "network is built differently need to be trained differently it strictly ignores everything else and just looks well we",
    "start": "824600",
    "end": "831920"
  },
  {
    "text": "use this is not what we do yeah we use sof tension in our models so this kind of solves the bottleneck problem like",
    "start": "831920",
    "end": "838079"
  },
  {
    "text": "you had all of the input sequence in one vector but now you can kind of cheat and go back and look at the entire input",
    "start": "838079",
    "end": "844440"
  },
  {
    "text": "sequence um so when you put all of it together this is our uh architecture for Google",
    "start": "844440",
    "end": "851880"
  },
  {
    "text": "system so you have a deep encoder and a deep decoder and you can see that the",
    "start": "851880",
    "end": "856959"
  },
  {
    "text": "there is an attention mechanism uh in the middle that the model uses to pay attention to things things are",
    "start": "856959",
    "end": "864360"
  },
  {
    "text": "parallelized uh using gpus so each of these layers run on a different gpus so they don't don't have to wait for each",
    "start": "864360",
    "end": "871160"
  },
  {
    "text": "other and uh at the top you have a softmax which predicts the token at each",
    "start": "871160",
    "end": "880440"
  },
  {
    "text": "time but it's uh there's a lot in the picture and the Y correspond to every",
    "start": "880440",
    "end": "888040"
  },
  {
    "text": "single word that's possible yeah okay yeah it's a huge soft exactly so getting",
    "start": "888040",
    "end": "894759"
  },
  {
    "text": "to the next slide so you have a vocabulary size problem so you have to support all of the words that you want",
    "start": "894759",
    "end": "900000"
  },
  {
    "text": "to decode and for example dog or dogs in Russian if you wanted to cover all of",
    "start": "900000",
    "end": "905079"
  },
  {
    "text": "its forms you would need 130,000 words so this form of dog is the 13 30,000",
    "start": "905079",
    "end": "912040"
  },
  {
    "text": "word in the vocabulary so you would have to support all of those and if you go even further if you want to support dog",
    "start": "912040",
    "end": "917120"
  },
  {
    "text": "breeding then you need about 2 million vocabulary elements in your um",
    "start": "917120",
    "end": "923600"
  },
  {
    "text": "softmax right here some examples how you get to",
    "start": "923600",
    "end": "929880"
  },
  {
    "text": "how do you get to these large numbers it's just a frequency of all Russian words in a",
    "start": "929880",
    "end": "936360"
  },
  {
    "text": "carpus on on this picture the words are shown in frequency",
    "start": "936360",
    "end": "942680"
  },
  {
    "text": "order in the training Corpus so we assume that if we want to use a vocabulary of 100,000 words we will use",
    "start": "942680",
    "end": "949199"
  },
  {
    "text": "the most frequent 100,000 so now all the word forms of dog in Russian they occur in this vocabulary",
    "start": "949199",
    "end": "956240"
  },
  {
    "text": "and they occur at positions 12,000 13,000 and so on thank you so if we take",
    "start": "956240",
    "end": "964360"
  },
  {
    "text": "the top we will need on the right we will need 2 million",
    "start": "964360",
    "end": "969800"
  },
  {
    "text": "and this will only cover a few variations and all possible variations maybe not even present in the",
    "start": "969800",
    "end": "977920"
  },
  {
    "text": "C yeah so because of that we use uh subword segmentation where we segment",
    "start": "979360",
    "end": "985240"
  },
  {
    "text": "each word into different pieces based on frequency so now you can see that uh",
    "start": "985240",
    "end": "992319"
  },
  {
    "text": "this word for dog is split into two tokens now so now you can model them",
    "start": "992319",
    "end": "997600"
  },
  {
    "text": "with just 32,000 words and then the the word for dog breeding is actually split up into three tokens and this token",
    "start": "997600",
    "end": "1003759"
  },
  {
    "text": "splitting is done based on frequencies so you would uh split uh you would combine two characters if they're most",
    "start": "1003759",
    "end": "1010800"
  },
  {
    "text": "frequent in the vocabulary you would combine the third character as well if it's also frequent so it's a statistics",
    "start": "1010800",
    "end": "1015880"
  },
  {
    "text": "based splitting and this splitting allows us to cover all of most of the",
    "start": "1015880",
    "end": "1021440"
  },
  {
    "text": "vocabulary with just 32,000 words uh but it increases the sequence length so now you have longer sequences because you're",
    "start": "1021440",
    "end": "1027558"
  },
  {
    "text": "splitting up each word uh by about 20 to 50% right so it's essentially open",
    "start": "1027559",
    "end": "1035319"
  },
  {
    "text": "vocabulary by using these word pieces so if you had a sentence we realize that word pieces are the best choice you see",
    "start": "1035319",
    "end": "1042600"
  },
  {
    "text": "that most of the words are pretty common and they're not split but something like realized which is a little uncommon is",
    "start": "1042600",
    "end": "1048919"
  },
  {
    "text": "is split into two and if you had another language you're translating into Tamil",
    "start": "1048919",
    "end": "1054240"
  },
  {
    "text": "you would have some words that are split some words are not split based on frequencies",
    "start": "1054240",
    "end": "1060039"
  },
  {
    "text": "again and then now you have this problem of latency so translation speed was a",
    "start": "1060840",
    "end": "1067039"
  },
  {
    "text": "major launch blocker for us when we were building these neural networks because you have these large networks which have",
    "start": "1067039",
    "end": "1072880"
  },
  {
    "text": "to process these long sequences because we were using these subword units and these neural networks are notoriously",
    "start": "1072880",
    "end": "1078559"
  },
  {
    "text": "famous for large matrix multiplication so they take a long time many other restrictions like a lot of memory is",
    "start": "1078559",
    "end": "1084919"
  },
  {
    "text": "required so which is why we had these tensor processing units I think I believe that's the talk that's going to",
    "start": "1084919",
    "end": "1090880"
  },
  {
    "text": "be uh uh next week uh we're going to talk about the tpus but Google invested in making these custom Asic long back so",
    "start": "1090880",
    "end": "1098080"
  },
  {
    "text": "they they they realized that oh okay we're going to use a bunch of neural networks so let's build custom Hardware",
    "start": "1098080",
    "end": "1104480"
  },
  {
    "text": "to accelerate these neural networks and uh we started building models that supported these tpus and we went from",
    "start": "1104480",
    "end": "1111919"
  },
  {
    "text": "initially having uh 10 seconds to decode an entire sentence to about 200 millisecs by using these uh",
    "start": "1111919",
    "end": "1119760"
  },
  {
    "text": "tpus right so you can see the latency uh in",
    "start": "1119760",
    "end": "1125200"
  },
  {
    "text": "the blue you see the neural system and in the red you see the previous phras based system and uh one thing to notice",
    "start": "1125200",
    "end": "1132960"
  },
  {
    "text": "is the blue lines are almost almost flat like they they're constant there's not a",
    "start": "1132960",
    "end": "1138559"
  },
  {
    "text": "lot of variance but the red lines they vary a lot some of the languages have high latency some other languages have",
    "start": "1138559",
    "end": "1145559"
  },
  {
    "text": "low latencies because we were doing uh model to model tuning like oh this this language is bad we would go and tune",
    "start": "1145559",
    "end": "1152200"
  },
  {
    "text": "that model for that language and make the beam larger and things like that but with these neural system it's almost",
    "start": "1152200",
    "end": "1157880"
  },
  {
    "text": "flat but they're still worse than uh the previous system they're still like far",
    "start": "1157880",
    "end": "1163960"
  },
  {
    "text": "like two to three times worse than the phas space system uh but we did experiment where we showed users slow",
    "start": "1163960",
    "end": "1170480"
  },
  {
    "text": "translations we would take 1% of our users show them two times slower",
    "start": "1170480",
    "end": "1175600"
  },
  {
    "text": "translations three times slower translations and we didn't see a significant effect of doing that so uh",
    "start": "1175600",
    "end": "1181520"
  },
  {
    "text": "because we have much better quality with these models we decided to launch them despite the fact there was lower sorry",
    "start": "1181520",
    "end": "1187720"
  },
  {
    "text": "what's the B so that's the our neural machine translation system b stands for",
    "start": "1187720",
    "end": "1193640"
  },
  {
    "text": "brain yeah that's a yeah",
    "start": "1193640",
    "end": "1199480"
  },
  {
    "text": "and then uh we needed a lot of capacity right you don't need just one TPU you need lots of tpus to serve all of the",
    "start": "1199880",
    "end": "1206679"
  },
  {
    "text": "traffic and uh Google uh machine translation was one of the first users",
    "start": "1206679",
    "end": "1212039"
  },
  {
    "text": "of TPU so we essentially had a check that said use all tpus at Google and at",
    "start": "1212039",
    "end": "1217559"
  },
  {
    "text": "one point we were the highest users of TPU inside Google just machine",
    "start": "1217559",
    "end": "1223519"
  },
  {
    "text": "translations so we were replacing this system on the left which is the old phas",
    "start": "1224960",
    "end": "1230080"
  },
  {
    "text": "space system it had lots of individual pieces and each of them were optimized uh in a different way with the with the",
    "start": "1230080",
    "end": "1237200"
  },
  {
    "text": "neural network with essentially a large neural network it does end to end learning it's simple but the results are",
    "start": "1237200",
    "end": "1244240"
  },
  {
    "text": "much much better uh in Translation did a project recently",
    "start": "1244240",
    "end": "1252880"
  },
  {
    "text": "translation and regard the TR because you have to speak in either the age or",
    "start": "1252880",
    "end": "1260280"
  },
  {
    "text": "the depend of age you're masculine or feminine you have different translations",
    "start": "1260280",
    "end": "1265880"
  },
  {
    "text": "that's that's you with that in the end to end solution that you have um we did some experiments on that uh but uh let",
    "start": "1265880",
    "end": "1274640"
  },
  {
    "text": "me let me get to it in a bit but we do address that uh not right now but we can easily address that uh so there are like",
    "start": "1274640",
    "end": "1281919"
  },
  {
    "text": "different formalities based on if you're speaking to an older person if you're speaking to a younger person the",
    "start": "1281919",
    "end": "1287039"
  },
  {
    "text": "translation changes and the the only way of knowing these things is to let the user say that hey I'm talking to this",
    "start": "1287039",
    "end": "1293919"
  },
  {
    "text": "old person he's male give me a translation from English to Russian or English to Hindi uh but right now we",
    "start": "1293919",
    "end": "1301360"
  },
  {
    "text": "don't do that we just translate from English to Hindi and we assume the age I",
    "start": "1301360",
    "end": "1308760"
  },
  {
    "text": "guess so uh when we started on this project everyone said oh it'll take 3 years to launch U it actually took about",
    "start": "1309080",
    "end": "1317559"
  },
  {
    "text": "uh more than a year so a few people from the Google brain team they started in September of 2015",
    "start": "1317559",
    "end": "1324600"
  },
  {
    "text": "working on this project and around Fe February of 2016 they obtained the first",
    "start": "1324600",
    "end": "1330039"
  },
  {
    "text": "large scale results inside Google and from Feb to September a lot of people",
    "start": "1330039",
    "end": "1335200"
  },
  {
    "text": "were involved and we said uh we put in a lot of work we launched the first language pair which was Chinese to",
    "start": "1335200",
    "end": "1341000"
  },
  {
    "text": "English and uh in November we launched about 16 different language pairs um",
    "start": "1341000",
    "end": "1349559"
  },
  {
    "text": "so how did it go did people like it so we did a silent launch in Japan so in Japan we started serving them neural",
    "start": "1349640",
    "end": "1356200"
  },
  {
    "text": "translations but we did not tell them that it was neural and people actually found out so it Google translate in",
    "start": "1356200",
    "end": "1362799"
  },
  {
    "text": "Japanese became the most trending topic on Twitter in just one day so people",
    "start": "1362799",
    "end": "1368120"
  },
  {
    "text": "were so excited because uh Japanese for instance um one of the team members said",
    "start": "1368120",
    "end": "1373279"
  },
  {
    "text": "it it went from being unusable to usable actually the translation quality jump was huge and then how long did that",
    "start": "1373279",
    "end": "1379799"
  },
  {
    "text": "persist six hours later was it back to zero no we didn't check but then the next day check that was probably wise",
    "start": "1379799",
    "end": "1388799"
  },
  {
    "text": "yeah but then the next I checked it to okay but the next day we announced it I",
    "start": "1388799",
    "end": "1394159"
  },
  {
    "text": "think in a few days we were announcing it publicly so there's a there's a good example so there is Hemingways the Snows",
    "start": "1394159",
    "end": "1401360"
  },
  {
    "text": "of Kilimanjaro um I think this was one of the first tweets or something so there was a Japanese Professor who took this",
    "start": "1401360",
    "end": "1408880"
  },
  {
    "text": "piece from Hemingway and he manually translated it into Japanese and he said",
    "start": "1408880",
    "end": "1414480"
  },
  {
    "text": "okay this is my translation of Hemingway I want to see how good Google Translate is translate is when I get it back so he",
    "start": "1414480",
    "end": "1422440"
  },
  {
    "text": "took his Japanese text and uh let me show you first if what you what he got",
    "start": "1422440",
    "end": "1428400"
  },
  {
    "text": "when he put it into the old system that raises a question on that particular one that's example which is also you you can",
    "start": "1428400",
    "end": "1434760"
  },
  {
    "text": "go to the next your next slide and that's so it points out is 19,000 ft",
    "start": "1434760",
    "end": "1439919"
  },
  {
    "text": "japaneses Japanese now use metric right so did he give them the meter uh no idea",
    "start": "1439919",
    "end": "1447440"
  },
  {
    "text": "but yeah I'm guessing he did a faithful translation what he thought was best you think that's the show",
    "start": "1447440",
    "end": "1454320"
  },
  {
    "text": "St oh no wait yeah wait till you see the translation so let's just focus on the",
    "start": "1454320",
    "end": "1459760"
  },
  {
    "text": "last sentence so it says uh no one has explain what the leopard was seeking at that altitude so let's just focus on",
    "start": "1459760",
    "end": "1466279"
  },
  {
    "text": "this last sentence and if you put it into our whole system you get back whether the leopard had what that demand",
    "start": "1466279",
    "end": "1473760"
  },
  {
    "text": "at that altitude there is no that nobody explained so it is uh I don't know if",
    "start": "1473760",
    "end": "1479120"
  },
  {
    "text": "you get anything out of it uh but when you put it into the new system it says",
    "start": "1479120",
    "end": "1485200"
  },
  {
    "text": "no one can explain what leopard was seeking at that altitude so it was almost perfect uh and if you look at the",
    "start": "1485200",
    "end": "1492080"
  },
  {
    "text": "whole if you look at the whole passage there's just two errors and what the it",
    "start": "1492080",
    "end": "1497200"
  },
  {
    "text": "was missing a bunch of of Articles and uh so this guy was so excited by this and he started tweeting about it and",
    "start": "1497200",
    "end": "1503799"
  },
  {
    "text": "that's how it started but you can see the difference in quality from going from the old system to the new",
    "start": "1503799",
    "end": "1510600"
  },
  {
    "text": "system so some examples we the way we measured quality was we did a human",
    "start": "1510600",
    "end": "1516120"
  },
  {
    "text": "experiment we showed uh two systems side by side to humans we would show a",
    "start": "1516120",
    "end": "1522039"
  },
  {
    "text": "sentence in English and we would show the old Japanese translation and the new Japanese translation and we would ask",
    "start": "1522039",
    "end": "1527480"
  },
  {
    "text": "them to rate it on a 0 to six scale so zero means very bad translation six means uh very good",
    "start": "1527480",
    "end": "1535000"
  },
  {
    "text": "translation and uh previously we would consider any significant gain would be",
    "start": "1535000",
    "end": "1541279"
  },
  {
    "text": "greater than 0.1 so if your new system was greater than 0. one compared to the old system we would consider it",
    "start": "1541279",
    "end": "1546480"
  },
  {
    "text": "significant and launchable and uh when we built the first model the Chinese to English model we got uh 6 uh which was a",
    "start": "1546480",
    "end": "1555600"
  },
  {
    "text": "large gain and someone actually looked it up so in the past 10 years all of the improvements that we've made on Chinese",
    "start": "1555600",
    "end": "1562640"
  },
  {
    "text": "to English was actually less than 6 so in just a single shift from phas space",
    "start": "1562640",
    "end": "1568120"
  },
  {
    "text": "to neural networks we got more gains than in the past 10 years put together and for most other language pars we've",
    "start": "1568120",
    "end": "1574760"
  },
  {
    "text": "been seeing greater than 0.5 some even greater than one Japanese for instance was greater than one so it would go from",
    "start": "1574760",
    "end": "1581159"
  },
  {
    "text": "a rating of three to rating of 4.5 or something like that so here is more numbers so we have",
    "start": "1581159",
    "end": "1589120"
  },
  {
    "text": "the on the human scale 0 to 6 Z being bad six being good you have the blue as",
    "start": "1589120",
    "end": "1594880"
  },
  {
    "text": "the phrase based system and then you have the orange which are humans human",
    "start": "1594880",
    "end": "1600520"
  },
  {
    "text": "quality it's just an approximation of human quality it's just the average human it's not the best translator ever",
    "start": "1600520",
    "end": "1606520"
  },
  {
    "text": "right and then you have the neural system which is in green and you can see that in most cases it actually Bridges",
    "start": "1606520",
    "end": "1612559"
  },
  {
    "text": "the Gap by at least half so sometimes it's pretty close sometimes it's halfway between the old system and the",
    "start": "1612559",
    "end": "1620520"
  },
  {
    "text": "human what is perfect translation that's what whatever",
    "start": "1620520",
    "end": "1626240"
  },
  {
    "text": "someone's looking at it he says it's a six that's that's a perfect translation that's a subjective opinion of a person",
    "start": "1626240",
    "end": "1633000"
  },
  {
    "text": "who is bra yeah but we get subjective opinions from multiple people not not just yeah",
    "start": "1633000",
    "end": "1639480"
  },
  {
    "text": "yeah when you do when you do the when you show them and you write hand R from",
    "start": "1639480",
    "end": "1644799"
  },
  {
    "text": "Z to six they're Bilal people who so you you see the yeah you see the original and you see both and they're bilingual",
    "start": "1644799",
    "end": "1651360"
  },
  {
    "text": "people but uh one of the things we've noticed is this kind of presentation actually bies people in that uh if you",
    "start": "1651360",
    "end": "1658200"
  },
  {
    "text": "had one system that was really good and the other is really bad it forces them to push the scoring this way instead of",
    "start": "1658200",
    "end": "1664640"
  },
  {
    "text": "giving it a three and a five they would give it a zero and a six right uh we",
    "start": "1664640",
    "end": "1670039"
  },
  {
    "text": "noticed it and we're starting to do single presentations we would just show one system and then show the next system",
    "start": "1670039",
    "end": "1676880"
  },
  {
    "text": "and aggregate later",
    "start": "1676880",
    "end": "1680120"
  },
  {
    "text": "but uh now then we launched a few language pairs we launched Chinese and then we realized though this does not",
    "start": "1682279",
    "end": "1688600"
  },
  {
    "text": "scale uh so each of these models take about two to three weeks to train and they need about hundreds of millions of",
    "start": "1688600",
    "end": "1695039"
  },
  {
    "text": "examples to work really well and with uh 103 languages that Google translate",
    "start": "1695039",
    "end": "1700440"
  },
  {
    "text": "supports you would have to go and build approximately 103 squar of these models",
    "start": "1700440",
    "end": "1706440"
  },
  {
    "text": "and uh obviously it's it's going to be impossible even at Google scale right uh so we wanted to use uh",
    "start": "1706440",
    "end": "1714919"
  },
  {
    "text": "multilingual models so previously we would have different models for different language pairs you had an",
    "start": "1714919",
    "end": "1721399"
  },
  {
    "text": "English to French model you had an English to Spanish but we wanted to combine all of them into a single",
    "start": "1721399",
    "end": "1728159"
  },
  {
    "text": "multilingual model so we wanted to build a single model that can translate all of these languages",
    "start": "1728159",
    "end": "1734760"
  },
  {
    "text": "together right and the way we did it was the simplest thing we could think of we would Preen The Source sentence with a",
    "start": "1734760",
    "end": "1742120"
  },
  {
    "text": "token to indicate what the target language is going to be let me give you an example so if you had a source sentence and you want to translate it",
    "start": "1742120",
    "end": "1748760"
  },
  {
    "text": "into the target sentence for example if you had this English sentence and that's",
    "start": "1748760",
    "end": "1753840"
  },
  {
    "text": "the translation we you would add this token at the beginning that's saying oh this sentence",
    "start": "1753840",
    "end": "1759320"
  },
  {
    "text": "needs to be translated to German and then if you want to translate the same sentence to Spanish you would add",
    "start": "1759320",
    "end": "1764880"
  },
  {
    "text": "another token that says oh this is going to Spanish and uh if you want to translate to",
    "start": "1764880",
    "end": "1769960"
  },
  {
    "text": "English you add this English token and now you would just take the data for different language pairs you would add",
    "start": "1769960",
    "end": "1776279"
  },
  {
    "text": "this token and combine them and just give it to the neural network so this was the simplest thing we could think of",
    "start": "1776279",
    "end": "1782760"
  },
  {
    "text": "and it actually worked right so that's the that's the brilliant part uh all of",
    "start": "1782760",
    "end": "1788399"
  },
  {
    "text": "our models right now that that are multilingual use just this just this thing why didn't you need a source",
    "start": "1788399",
    "end": "1794880"
  },
  {
    "text": "language token as well as that's a that's a good question so uh we wanted the model to be Source",
    "start": "1794880",
    "end": "1801559"
  },
  {
    "text": "agnostic so one of one reason that I can think of right now is when you go to Google Translate you don't have to",
    "start": "1801559",
    "end": "1807840"
  },
  {
    "text": "select the source language you can start typing and the system will automatically detect your language now when we put the",
    "start": "1807840",
    "end": "1815480"
  },
  {
    "text": "source token it kind of restricts the model and it gives it gives the model more information but we wanted the model",
    "start": "1815480",
    "end": "1822080"
  },
  {
    "text": "to be as general as possible so when you don't put in the source source token the model is actually Source agnostic",
    "start": "1822080",
    "end": "1828600"
  },
  {
    "text": "uh it doesn't care about what the source sentence is it only cares that it has to translate it into this language so now",
    "start": "1828600",
    "end": "1835080"
  },
  {
    "text": "the output is vocabulary from a lot of different languages yes so is your softmax now even Huger uh that's a good",
    "start": "1835080",
    "end": "1842240"
  },
  {
    "text": "question again uh in the next slide so we still use 32,000 word pieces and what",
    "start": "1842240",
    "end": "1849159"
  },
  {
    "text": "we do is we equally represent them across different languages so if you had a system that had English Spanish and",
    "start": "1849159",
    "end": "1855360"
  },
  {
    "text": "French we would take all the top words and um if an English word occurred",
    "start": "1855360",
    "end": "1860399"
  },
  {
    "text": "10,000 times but a French word occurred only 5,000 times but it's the first French word we would make them equal and",
    "start": "1860399",
    "end": "1867559"
  },
  {
    "text": "our vocabulary would be multilingual so it would be the most frequent English words the most frequent French words the most frequent Spanish words and the word",
    "start": "1867559",
    "end": "1875039"
  },
  {
    "text": "pieces would also be split based on the counts and you can do that with just",
    "start": "1875039",
    "end": "1880799"
  },
  {
    "text": "32,000 langes all langu well just we use only 32,000 yeah for multiple different",
    "start": "1880799",
    "end": "1890039"
  },
  {
    "text": "languages with different scripts yeah langu no no no we don't use one",
    "start": "1890039",
    "end": "1897120"
  },
  {
    "text": "model for all of them we're not yet there we just use four to five or 10 10",
    "start": "1897120",
    "end": "1903320"
  },
  {
    "text": "in one model how do you represent them do you because there's many many many",
    "start": "1903320",
    "end": "1908600"
  },
  {
    "text": "character sets yeah um we Ed the own the",
    "start": "1908600",
    "end": "1914000"
  },
  {
    "text": "whatever the script the language uses so if it was in Japanese word we would use the Japanese script and if it was English we would use the Latin script so",
    "start": "1914000",
    "end": "1921559"
  },
  {
    "text": "in Japanese there are three scripts that are used for every yeah we we use Kani and",
    "start": "1921559",
    "end": "1927919"
  },
  {
    "text": "hakana we don't change anything we don't like transer it",
    "start": "1927919",
    "end": "1934200"
  },
  {
    "text": "yeah you just take the most frequent Unicode characters and for some languages you",
    "start": "1934200",
    "end": "1940799"
  },
  {
    "text": "need a few hundreds for some and then same way our training data",
    "start": "1940799",
    "end": "1947919"
  },
  {
    "text": "is also represented equally so if you wanted to Club four of these language pairs into one model we would look",
    "start": "1947919",
    "end": "1953880"
  },
  {
    "text": "through the counts if the first one had 10 million and the second one had 5 million we would oversample the second",
    "start": "1953880",
    "end": "1959240"
  },
  {
    "text": "one to be 10 million so such that um everything is equally represented in the",
    "start": "1959240",
    "end": "1964440"
  },
  {
    "text": "model so training takes about uh 10 million steps takes about 3 weeks on",
    "start": "1964440",
    "end": "1970080"
  },
  {
    "text": "roughly 100 gpus so it's a long time you need a lot of patience you press a button wait three weeks and then see",
    "start": "1970080",
    "end": "1976240"
  },
  {
    "text": "what happens how you get you train data did you uh so we get it from the web we",
    "start": "1976240",
    "end": "1982000"
  },
  {
    "text": "go to the web and try to mine parallel sentences so if you go to bbc.com we",
    "start": "1982000",
    "end": "1987799"
  },
  {
    "text": "would detect that it's in English and then if you go to the BBC website for Spanish we would detect all these pages",
    "start": "1987799",
    "end": "1994200"
  },
  {
    "text": "are the same these are parallel sentences so for evaluating these models",
    "start": "1994200",
    "end": "2000440"
  },
  {
    "text": "we used what what is called the Blue score which is a which is a standard criteria for machine translation",
    "start": "2000440",
    "end": "2005840"
  },
  {
    "text": "evaluation and the higher the score the better that's all you need to know so",
    "start": "2005840",
    "end": "2011440"
  },
  {
    "text": "with the training do you ever get a problem where you detect that those two websites are the same and it turns out",
    "start": "2011440",
    "end": "2016919"
  },
  {
    "text": "that they just done the dumb thing and used Google translate and say just sampling what the previous bad",
    "start": "2016919",
    "end": "2023320"
  },
  {
    "text": "translation we we we have a lot of that problem uh we still haven't addressed it for some languages it's as high as 50%",
    "start": "2023320",
    "end": "2030919"
  },
  {
    "text": "is using Google translate so we try to Watermark our translations but it's not",
    "start": "2030919",
    "end": "2036360"
  },
  {
    "text": "as reliable but it's an interesting problem how about the Monty Python phrase book I don't know where the",
    "start": "2036360",
    "end": "2044039"
  },
  {
    "text": "translations are purposely malicious yeah it we get a lot of that too where",
    "start": "2044039",
    "end": "2051560"
  },
  {
    "text": "you did you Fe your output fact as an input is your system stable at this",
    "start": "2051560",
    "end": "2057520"
  },
  {
    "text": "point uh yes yeah to some extent it's pretty robust no to a large extent it's pretty",
    "start": "2057520",
    "end": "2064878"
  },
  {
    "text": "robust some error analysis uh to know uh that",
    "start": "2064879",
    "end": "2071440"
  },
  {
    "text": "to improve the model quality the quality of performance do you need to have more",
    "start": "2071440",
    "end": "2076560"
  },
  {
    "text": "flexible model or more data uh that's a question good question",
    "start": "2076560",
    "end": "2082599"
  },
  {
    "text": "I I it's always the case that if you have better data you get better quality so even with these neural networks",
    "start": "2082599",
    "end": "2088560"
  },
  {
    "text": "because they're end to endend everything boils down to the data so there's a lot of data Engineering in preparing the",
    "start": "2088560",
    "end": "2093839"
  },
  {
    "text": "right data and also in also in what data you see in which order that also people",
    "start": "2093839",
    "end": "2100000"
  },
  {
    "text": "show that it matters that you see some examples before other examples and things like that so it's more on the",
    "start": "2100000",
    "end": "2106720"
  },
  {
    "text": "data side so there are three different types",
    "start": "2106720",
    "end": "2113440"
  },
  {
    "text": "of uh multilingual translation that you can use uh so you can use uh that people",
    "start": "2113440",
    "end": "2119880"
  },
  {
    "text": "have been using so there's a many to one translation where you have many languages um on the source and then you",
    "start": "2119880",
    "end": "2126320"
  },
  {
    "text": "have one language on the target and you have uh one to many you have one language on the source and you have many",
    "start": "2126320",
    "end": "2131960"
  },
  {
    "text": "languages on the target side and then you can have many languages to many languages right and uh people in",
    "start": "2131960",
    "end": "2138320"
  },
  {
    "text": "literature use um these they make a copy of these encoder in the decoder for",
    "start": "2138320",
    "end": "2144520"
  },
  {
    "text": "different languages but in our system since we just add this token all we see",
    "start": "2144520",
    "end": "2150400"
  },
  {
    "text": "is just one red box one green box one blue box so we have a single encoder a single attention mechanism and a single",
    "start": "2150400",
    "end": "2156400"
  },
  {
    "text": "decoder um so that's it and uh there are some",
    "start": "2156400",
    "end": "2162599"
  },
  {
    "text": "results now right so we started off with doing many to one experiments which was the easiest case so you had many",
    "start": "2162599",
    "end": "2169000"
  },
  {
    "text": "languages going to English and um you can see that there's a single model there's a multilingual model so the",
    "start": "2169000",
    "end": "2175119"
  },
  {
    "text": "multilingual model I have to clarify in this case is is the same size and the same setting as the single model um so",
    "start": "2175119",
    "end": "2183920"
  },
  {
    "text": "even despite the fact that it models two languages it's just the same size and one of the reasons is you can make the",
    "start": "2183920",
    "end": "2190280"
  },
  {
    "text": "model bigger but then now you cannot serve it because it's going to be slow to train and uh it's going to be large",
    "start": "2190280",
    "end": "2196800"
  },
  {
    "text": "right so we always stuck to the same size for all of these experiments so now you see that the multilingual model is",
    "start": "2196800",
    "end": "2203480"
  },
  {
    "text": "all also already starting to do better than the single model in most cases you can see gains so WMT is this academic",
    "start": "2203480",
    "end": "2210760"
  },
  {
    "text": "data set which is like a standard uh public data set where people report numbers um and prod is our production",
    "start": "2210760",
    "end": "2218760"
  },
  {
    "text": "data set our production system um and here it's it's a good story right",
    "start": "2218760",
    "end": "2225000"
  },
  {
    "text": "everything is positive this is what you want now we did the harder case which is",
    "start": "2225000",
    "end": "2230160"
  },
  {
    "text": "going from one language to many languages right so in the first row if you see that we have this over sampling",
    "start": "2230160",
    "end": "2239000"
  },
  {
    "text": "uh the English to German set is about seven times less than the English to French set so when we do oversampling we",
    "start": "2239000",
    "end": "2246119"
  },
  {
    "text": "would basically repeat the English English to German said seven times more and make it equal but in the second",
    "start": "2246119",
    "end": "2251640"
  },
  {
    "text": "column we said okay what if we don't do this oversampling what what happens now you see that the English to German said",
    "start": "2251640",
    "end": "2257480"
  },
  {
    "text": "because it is out outweighed by the French it goes really bad so we realize",
    "start": "2257480",
    "end": "2263240"
  },
  {
    "text": "that we always have to over sample and make sure that the data is equally distributed across all",
    "start": "2263240",
    "end": "2268880"
  },
  {
    "text": "languages and you start to see some losses in the WMT setting but in the production setting because you have a",
    "start": "2268880",
    "end": "2275720"
  },
  {
    "text": "lot of languages a lot of data sorry in these two languages it was still not too bad uh but then we realized that uh",
    "start": "2275720",
    "end": "2283200"
  },
  {
    "text": "since we started seeing these negative numbers the decoder the fact that the decoder has to decode multiple languages",
    "start": "2283200",
    "end": "2290359"
  },
  {
    "text": "is much more of a constraint than the fact that the encoder had to encode multiple languages so the bottleneck",
    "start": "2290359",
    "end": "2296520"
  },
  {
    "text": "seemed to be in the decoder side when you're trying to predict sequences in different",
    "start": "2296520",
    "end": "2301920"
  },
  {
    "text": "languages I'm confused on the English to French why does it better with no",
    "start": "2301920",
    "end": "2309200"
  },
  {
    "text": "oversampling than with oversampling uh because with no oversampling the English to French is",
    "start": "2309200",
    "end": "2314960"
  },
  {
    "text": "about 7even times more data than English to German so it kind of hijacks the multilingual model and oh I see yeah of",
    "start": "2314960",
    "end": "2321400"
  },
  {
    "text": "course yeah so now we did okay what if we did",
    "start": "2321400",
    "end": "2327240"
  },
  {
    "text": "both directions we do many to many there's a lot of numbers on these slides",
    "start": "2327240",
    "end": "2332480"
  },
  {
    "text": "but uh it's still interesting that a single Model A multilingual model model",
    "start": "2332480",
    "end": "2338040"
  },
  {
    "text": "that can model these four language pairs is almost comparable in equality to what single different models could do but",
    "start": "2338040",
    "end": "2345119"
  },
  {
    "text": "it's it's not that you get better performance it's just you get comparable performance with losses everywhere right",
    "start": "2345119",
    "end": "2352319"
  },
  {
    "text": "and we wanted to push this thing to the limits we said okay what if we take our six largest languages so that would mean",
    "start": "2352319",
    "end": "2359240"
  },
  {
    "text": "12 pairs in every direction and we put it into a single model the same size as",
    "start": "2359240",
    "end": "2365680"
  },
  {
    "text": "that of a single model right so this multilingual model you can see this blue column there is like - 3.5 - 2.5 it's",
    "start": "2365680",
    "end": "2374160"
  },
  {
    "text": "it's significantly worse than the single system but it's an unfair comparison when you think about it so the 12 single",
    "start": "2374160",
    "end": "2380960"
  },
  {
    "text": "models combined have a total of three billion parameters but this one multilingual",
    "start": "2380960",
    "end": "2386839"
  },
  {
    "text": "model just has 300 million parameters right so uh we we wrote in our initial",
    "start": "2386839",
    "end": "2394400"
  },
  {
    "text": "paper that if we had if you build bigger models this difference is going to go down that's what we had written we",
    "start": "2394400",
    "end": "2400040"
  },
  {
    "text": "believe that if the model was bigger it would do better and then we sent it out for review and the reviewer said oh you",
    "start": "2400040",
    "end": "2406800"
  },
  {
    "text": "keep saying it's an unfair comparison why don't you increase the model size and show us that it improves but then uh",
    "start": "2406800",
    "end": "2413480"
  },
  {
    "text": "once you increase the model size it's going to take even more months to train right but we did know that this question was coming so we started training these",
    "start": "2413480",
    "end": "2419760"
  },
  {
    "text": "models before we sent them out for review by the time it came back we the models were converged right so here here",
    "start": "2419760",
    "end": "2427000"
  },
  {
    "text": "you see see that the the multimodel which is the standard size the the single model it has about 3.3 billion",
    "start": "2427000",
    "end": "2434000"
  },
  {
    "text": "parameters because it's modeling 12 different languages there are 12 different models and then a single multilingual model has 255 you see that",
    "start": "2434000",
    "end": "2441520"
  },
  {
    "text": "the average loss in blue score is about minus 1.7 and as you keep increasing the",
    "start": "2441520",
    "end": "2446680"
  },
  {
    "text": "size of the multilingual model the loss keeps going down and now you could ask oh why don't you keep going further till",
    "start": "2446680",
    "end": "2452160"
  },
  {
    "text": "it became greater than oh again it takes months to train maybe the next time I give you the talk the model would have",
    "start": "2452160",
    "end": "2457599"
  },
  {
    "text": "converged and uh we'll have better numbers but uh the fact is that if you throw more parameters at the model it's",
    "start": "2457599",
    "end": "2464319"
  },
  {
    "text": "uh it it'll be able to model all of the languages that's that was an interesting um well expected",
    "start": "2464319",
    "end": "2473200"
  },
  {
    "text": "observation so here's how it looks so when we train these models you would",
    "start": "2473760",
    "end": "2479000"
  },
  {
    "text": "have a lot of English to Korean data you would have you would add the token and then you'd have Korean to English data",
    "start": "2479000",
    "end": "2484319"
  },
  {
    "text": "you'd add the token to indicate that it's going to English you add English to Japanese data you would add the two Japanese token and then you have",
    "start": "2484319",
    "end": "2490560"
  },
  {
    "text": "Japanese to English data two English token so we started merging these languages together we started adding the",
    "start": "2490560",
    "end": "2495720"
  },
  {
    "text": "token and building these multilingual models this is during training so when we were training we did we just did this",
    "start": "2495720",
    "end": "2501359"
  },
  {
    "text": "and we asked the question can this model do more at test time so this model that was trained on these four language Paras",
    "start": "2501359",
    "end": "2508040"
  },
  {
    "text": "can now learn to translate between Japanese to Korean and Korean to Japanese without ever seeing any",
    "start": "2508040",
    "end": "2515079"
  },
  {
    "text": "examples between these two languages so essentially we took a Japanese sentence",
    "start": "2515079",
    "end": "2520760"
  },
  {
    "text": "and usually what the model saw was the two English token we would ask it to translate to English and we said hey we're going to cheat you we're going to",
    "start": "2520760",
    "end": "2526800"
  },
  {
    "text": "say to Korean now can you translate to Korean and it actually did it with pretty good accuracy and we call this",
    "start": "2526800",
    "end": "2534319"
  },
  {
    "text": "zero shot translation because in machine learning if some when you use a lot of data it can do something when you just",
    "start": "2534319",
    "end": "2540599"
  },
  {
    "text": "use one example and the model learns to learns that example you call it one shot learning but when you don't have any",
    "start": "2540599",
    "end": "2546400"
  },
  {
    "text": "examples this zero shot learning you had a question okay",
    "start": "2546400",
    "end": "2553880"
  },
  {
    "text": "okay so uh we were experimenting with the quality of this zero shot translation so it's not all Rosy it's",
    "start": "2553880",
    "end": "2560440"
  },
  {
    "text": "not like you get the best translation right so say you had a multilingual system that's trying to model two",
    "start": "2560440",
    "end": "2566520"
  },
  {
    "text": "language paes in this case the language codes are English to Spanish Portuguese to English I'm sorry about the language",
    "start": "2566520",
    "end": "2572800"
  },
  {
    "text": "codes everywhere uh and then we said uh can this actually translate from",
    "start": "2572800",
    "end": "2579880"
  },
  {
    "text": "Portuguese to Spanish it did not see any Portuguese to Spanish data when it was trained but during test time can it",
    "start": "2579880",
    "end": "2586200"
  },
  {
    "text": "translate and we get a blue score of 21.6 it seems pretty high right yeah 21",
    "start": "2586200",
    "end": "2592160"
  },
  {
    "text": "we said oh wow this is awesome so now what we do is we add we have another",
    "start": "2592160",
    "end": "2597559"
  },
  {
    "text": "model where we added the other two language directions so when you think about it this model the first model is",
    "start": "2597559",
    "end": "2604079"
  },
  {
    "text": "learning to encode Portuguese and it's learning to decode Spanish so you can say hey wait a minute it learned to",
    "start": "2604079",
    "end": "2609760"
  },
  {
    "text": "encode Portuguese and then it learned to decode Spanish it's obvious that it can translate between the two it's just that",
    "start": "2609760",
    "end": "2615359"
  },
  {
    "text": "it do not see any examples and now we said what if we taught it to uh decode",
    "start": "2615359",
    "end": "2621200"
  },
  {
    "text": "Portuguese and encode Spanish though in the in the bottom model you're actually adding the reverse you're not adding uh",
    "start": "2621200",
    "end": "2628400"
  },
  {
    "text": "encoding of Portuguese and decoding of Spanish but you're adding encoding of Spanish and decoding of Portuguese so if",
    "start": "2628400",
    "end": "2634040"
  },
  {
    "text": "the model was just trying to memorize these sentences Portuguese to Spanish on this side to",
    "start": "2634040",
    "end": "2639400"
  },
  {
    "text": "this side this shouldn't help right but then it actually got better quality so",
    "start": "2639400",
    "end": "2645119"
  },
  {
    "text": "this means that the model actually has some sort of representation that is beyond just these Portuguese Spanish",
    "start": "2645119",
    "end": "2650880"
  },
  {
    "text": "languages so any data that's added to the model is helping the model generalize in the zero shot",
    "start": "2650880",
    "end": "2657000"
  },
  {
    "text": "Direction uh just for comparison right uh previously Google translate when it's",
    "start": "2657000",
    "end": "2663000"
  },
  {
    "text": "when it builds these models you we only have data from English to a language and",
    "start": "2663000",
    "end": "2668400"
  },
  {
    "text": "a language to English because it's hard to get data well Portuguese to Spanish",
    "start": "2668400",
    "end": "2673440"
  },
  {
    "text": "may be easy but it's hard to get data for Portuguese to Vietnamese for example on the web you cannot go onto the web",
    "start": "2673440",
    "end": "2678680"
  },
  {
    "text": "and try to find parallel documents in Portuguese and Vietnamese so if you wanted to serve something like Portuguese to Vietnamese what we would",
    "start": "2678680",
    "end": "2685119"
  },
  {
    "text": "do is we would take a Portuguese sentence translate it into English and then we' take the English sentence and translate it into Portuguese we call",
    "start": "2685119",
    "end": "2691800"
  },
  {
    "text": "this bridging so we always bridge to English um so the phrase based system if",
    "start": "2691800",
    "end": "2697440"
  },
  {
    "text": "it did bridging for Portuguese to Spanish it would get about 28.9 so doing bridging is much is much",
    "start": "2697440",
    "end": "2705680"
  },
  {
    "text": "better than the zero shot translation right so zero shot translation is not the best quality um and if you had two",
    "start": "2705680",
    "end": "2712640"
  },
  {
    "text": "neural systems and you bridged through English you would get even better translation quality and if you took all",
    "start": "2712640",
    "end": "2719119"
  },
  {
    "text": "the Portuguese to Spanish data at your disposal and you built a separate system for that language instead of bridging",
    "start": "2719119",
    "end": "2724319"
  },
  {
    "text": "you would get even better quality right so why do you get better quality when you build a separate system because",
    "start": "2724319",
    "end": "2730680"
  },
  {
    "text": "there's lots of information when you go through English for example if you go from Japanese to Korean if you translate",
    "start": "2730680",
    "end": "2736440"
  },
  {
    "text": "the Japanese sentence to English you lose all formality information because Japanese has formality but English does not have formality and so it's a lossy",
    "start": "2736440",
    "end": "2743800"
  },
  {
    "text": "process um so what we did was hey we have this zero shot model on the left at",
    "start": "2743800",
    "end": "2749520"
  },
  {
    "text": "the bottom what if we gave it a few examples of Portuguese to Spanish just to fine-tune the model can it do better",
    "start": "2749520",
    "end": "2757119"
  },
  {
    "text": "ation of Portuguese to Spanish and with just a few examples 5% more examples and",
    "start": "2757119",
    "end": "2762400"
  },
  {
    "text": "if you train it for about 1% of the time that the original model takes you get",
    "start": "2762400",
    "end": "2768440"
  },
  {
    "text": "better performance than all of the previous approaches that you had at your",
    "start": "2768440",
    "end": "2773960"
  },
  {
    "text": "disposal but no blue scores to show us that uh so",
    "start": "2774520",
    "end": "2780520"
  },
  {
    "text": "so then we said okay this zero shot translation is interesting can we actually look into the internal",
    "start": "2788400",
    "end": "2793839"
  },
  {
    "text": "representation of the model and try to figure out if it's actually doing this language agnostic",
    "start": "2793839",
    "end": "2801880"
  },
  {
    "text": "thing so this is a hard diagram to explain I've tried a bunch of times I'll",
    "start": "2801880",
    "end": "2806960"
  },
  {
    "text": "do my best so what what we did was we took uh a bunch of sentences uh say a",
    "start": "2806960",
    "end": "2812920"
  },
  {
    "text": "thousand sentences and we translated we had translations for them in three languages we had the same sentence in",
    "start": "2812920",
    "end": "2818640"
  },
  {
    "text": "English the same sentence in Japanese and the same sentence in Korean and we would pass three sentences through the",
    "start": "2818640",
    "end": "2825400"
  },
  {
    "text": "model and get the internal state of the model and we' plot it into the high dimension into a high dimensional space",
    "start": "2825400",
    "end": "2831720"
  },
  {
    "text": "so in this diagram on the left figure a every sentence every group of sentences every group of three sentences in three",
    "start": "2831720",
    "end": "2838000"
  },
  {
    "text": "languages is one color so you can see that there are some clusters like there's this cluster on the left that's",
    "start": "2838000",
    "end": "2843280"
  },
  {
    "text": "one color there's a green cluster there's a yellow cluster at the bottom and then there's this red cluster so",
    "start": "2843280",
    "end": "2849160"
  },
  {
    "text": "each cluster is three sentences that based on the internal representation of the model right and then so let's zoom",
    "start": "2849160",
    "end": "2857000"
  },
  {
    "text": "into one of these clusters in figure B right and then in figure C to make it easier we color code uh these sentences",
    "start": "2857000",
    "end": "2865200"
  },
  {
    "text": "based on the language so here you can see that the Orange is the English and then the blue is the Korean and the red",
    "start": "2865200",
    "end": "2871839"
  },
  {
    "text": "is the Japanese sentence so it's the same sentence in all of these languages but despite the fact that these",
    "start": "2871839",
    "end": "2878319"
  },
  {
    "text": "languages have different scripts and different grammars the model sees them the same because it's clustering them",
    "start": "2878319",
    "end": "2883839"
  },
  {
    "text": "into the same space so this sort of gave us proof that oh even though these sentences are in different languages if",
    "start": "2883839",
    "end": "2890319"
  },
  {
    "text": "they mean the same thing it looks the same to the model when you're mapping like",
    "start": "2890319",
    "end": "2897520"
  },
  {
    "text": "multi-dimension high dimension what I guess what are the dimensions I mean I get the the clusters of color and",
    "start": "2897520",
    "end": "2903920"
  },
  {
    "text": "everything like that essentially where how is it being Ma so it's a it's a",
    "start": "2903920",
    "end": "2909280"
  },
  {
    "text": "thousand dimensional Vector that we take and which two are these no I mean uh it's a thousand",
    "start": "2909280",
    "end": "2916440"
  },
  {
    "text": "dimensional vector and we tne it down to 3D we use tne to compress it to 3D plot",
    "start": "2916440",
    "end": "2922200"
  },
  {
    "text": "yeah uh and essentially um the vector that we take is actually the is based on",
    "start": "2922200",
    "end": "2928559"
  },
  {
    "text": "the attention so every time the model is trying to translate we take the representation of the model that's",
    "start": "2928559",
    "end": "2934000"
  },
  {
    "text": "attending to in the source side",
    "start": "2934000",
    "end": "2938720"
  },
  {
    "text": "yeah so there's more analysis more dots right uh I'll try to explain it well",
    "start": "2940400",
    "end": "2947880"
  },
  {
    "text": "this time so on the left you have this diagram it's the same um where you have",
    "start": "2947880",
    "end": "2953799"
  },
  {
    "text": "these blue dots are translations from Portuguese to English and the yellow",
    "start": "2953799",
    "end": "2959119"
  },
  {
    "text": "dots are translations from English to Spanish and now the Red Dot is what we call the zero shot translation right it",
    "start": "2959119",
    "end": "2965799"
  },
  {
    "text": "learns to translate from from Portuguese to Spanish so we took these translations and we mapped them into this space and",
    "start": "2965799",
    "end": "2973160"
  },
  {
    "text": "you would expect that uh since all these sentences are the same it's the same Portuguese being translated to English",
    "start": "2973160",
    "end": "2979240"
  },
  {
    "text": "it's the same English being translated to Spanish and since they are all the same you'd expect them to be on top of",
    "start": "2979240",
    "end": "2984559"
  },
  {
    "text": "each other right but then we when we this is actually it's a 3D plot we zoomed into the worst part it's not like",
    "start": "2984559",
    "end": "2991040"
  },
  {
    "text": "all of it is on the right but we noticed the huge cluster on the left Which is far away from the blue and the yellow",
    "start": "2991040",
    "end": "2998440"
  },
  {
    "text": "dots right so there's a huge cluster of red which is the zero shot translation that's far away from the original",
    "start": "2998440",
    "end": "3005720"
  },
  {
    "text": "translations and we looked into it and we saw hey can we measure the distance",
    "start": "3005720",
    "end": "3010760"
  },
  {
    "text": "between this Red Dot and the blue and the yellow dot that it corresponds to so if you had a Portuguese to Spanish",
    "start": "3010760",
    "end": "3016559"
  },
  {
    "text": "translation how far is it from the Portuguese to English translation and the English to Spanish translation and",
    "start": "3016559",
    "end": "3022720"
  },
  {
    "text": "we noticed that the farther away in the space that the Red Dot was the lower the quality of that translation was and the",
    "start": "3022720",
    "end": "3029319"
  },
  {
    "text": "closer it was to these Portuguese to English and English to Spanish translation the higher the quality which",
    "start": "3029319",
    "end": "3034920"
  },
  {
    "text": "is what you would expect so if the model is learning some sort of representation you would expect uh these zero shot",
    "start": "3034920",
    "end": "3041680"
  },
  {
    "text": "translations to be close to the parent but not far away so there was a correlation between blue score and the",
    "start": "3041680",
    "end": "3046920"
  },
  {
    "text": "distance from these things uh interesting thing is why why",
    "start": "3046920",
    "end": "3054240"
  },
  {
    "text": "don't we add the source token which uh was the question asked before so now the model is Source agnostic so if you had a",
    "start": "3054240",
    "end": "3060359"
  },
  {
    "text": "Japanese sentence that translates to I'm a student at Tokyo University you had a Korean sentence that translates to the",
    "start": "3060359",
    "end": "3066880"
  },
  {
    "text": "same thing you can do this kind of mixing or code switching between Japanese and",
    "start": "3066880",
    "end": "3073160"
  },
  {
    "text": "Korean uhuh the eming the final outut of the ening it's uh it's actually the",
    "start": "3073160",
    "end": "3080480"
  },
  {
    "text": "attention uh embedding so when you're trying to decode you attend to all of the source tokens and you compute a",
    "start": "3080480",
    "end": "3087880"
  },
  {
    "text": "weighted average across all the source that's what we that's what we map so those are the",
    "start": "3087880",
    "end": "3093359"
  },
  {
    "text": "activations of the of the nodes that translate between the first part first part of the translation process and the",
    "start": "3093359",
    "end": "3098799"
  },
  {
    "text": "second part of the that's right so each the attention at one time step",
    "start": "3098799",
    "end": "3105319"
  },
  {
    "text": "yeah and you can encode that in just4",
    "start": "3105319",
    "end": "3111000"
  },
  {
    "text": "yeah what if the source like Hindi is in English form yeah that's a good question",
    "start": "3111000",
    "end": "3117319"
  },
  {
    "text": "it actually depends on the data right so if in your data you see a lot of examples with Hindi English font you",
    "start": "3117319",
    "end": "3123680"
  },
  {
    "text": "learn to translate it h the and English font but if there's not enough data of that representation you learn to not",
    "start": "3123680",
    "end": "3131520"
  },
  {
    "text": "translate so in this case you have a Japanese to Korean multilingual model",
    "start": "3132920",
    "end": "3138319"
  },
  {
    "text": "and now you can do handle this kind of code switching so if you had a Japanese sentence and You' switch to Korean I",
    "start": "3138319",
    "end": "3143839"
  },
  {
    "text": "don't think anyone would do that this is just for for for an example but it can still the model can still process this",
    "start": "3143839",
    "end": "3149280"
  },
  {
    "text": "sentence because it it does not care as long as you say translate this segment to English it can do it um",
    "start": "3149280",
    "end": "3158440"
  },
  {
    "text": "perfectly then we said okay we're mixing languages on the source site can we mix",
    "start": "3158440",
    "end": "3163520"
  },
  {
    "text": "languages on the target side right and uh this was mostly work done by Maxim who's sitting here and the interesting",
    "start": "3163520",
    "end": "3169920"
  },
  {
    "text": "question there is the token that represents what the target language is going to be is just this one token",
    "start": "3169920",
    "end": "3176079"
  },
  {
    "text": "that's saying hey this is going to Japanese and then there's another token saying hey this is going to Russian",
    "start": "3176079",
    "end": "3181160"
  },
  {
    "text": "right so we started experimenting with this linear combination of these tokens so if you had an English to Russian and",
    "start": "3181160",
    "end": "3187839"
  },
  {
    "text": "Bellar Russian model or if you had a multilingual model with all the Russian related languages you would take the",
    "start": "3187839",
    "end": "3193720"
  },
  {
    "text": "Russian token you would add a weight to it and then you would take the bellerian token you would add a weight to it and we would sum it up so we'd go from in",
    "start": "3193720",
    "end": "3200720"
  },
  {
    "text": "the table you see going from zero so that means it's completely Russian and then if you go to one that's complet",
    "start": "3200720",
    "end": "3206920"
  },
  {
    "text": "belarussian right and in the middle the model actually switches to Ukrainian because when it's trying to translate",
    "start": "3206920",
    "end": "3214040"
  },
  {
    "text": "from uh from Russian to belarussian it goes through Ukrainian it's like okay I'll go to Ukrainian and then I'll give",
    "start": "3214040",
    "end": "3219559"
  },
  {
    "text": "you your belarussian at the end which is very interesting so more examples so here we",
    "start": "3219559",
    "end": "3227040"
  },
  {
    "text": "go from uh Japanese in W equals 0 and Korean at the bottom W equals 1 and U",
    "start": "3227040",
    "end": "3235200"
  },
  {
    "text": "you can see that gradually the grammar changes from Japanese to Korean and we",
    "start": "3235200",
    "end": "3240520"
  },
  {
    "text": "asked about this to a Korean speaker and he said at w equal 0.58 the model actually translates like",
    "start": "3240520",
    "end": "3247079"
  },
  {
    "text": "a mix of Japanese and Korean and at wal 6 it translates it into Korean but the",
    "start": "3247079",
    "end": "3253000"
  },
  {
    "text": "ordering is similar to Japanese so so finally it gives you the right",
    "start": "3253000",
    "end": "3260040"
  },
  {
    "text": "Korean here is an example with uh Spanish and Portuguese it's going from 0",
    "start": "3260040",
    "end": "3266000"
  },
  {
    "text": "equals Spanish and then when you go to one it's uh completely Portuguese you can see that some words change one at a",
    "start": "3266000",
    "end": "3274680"
  },
  {
    "text": "time so it's a gradual scale most of the time how do you encode that weight in",
    "start": "3274680",
    "end": "3280480"
  },
  {
    "text": "the input so we take the embedding for this token yeah and we multiply it by",
    "start": "3280480",
    "end": "3285960"
  },
  {
    "text": "0.5 and we take the embedding for the other it's all a vector right so we take the two",
    "start": "3285960",
    "end": "3292839"
  },
  {
    "text": "vectors yeah that's that's all the examples I had so I have a some",
    "start": "3294680",
    "end": "3300400"
  },
  {
    "text": "questions yes yeah so you you you talked about training mhm um but I didn't hear",
    "start": "3300400",
    "end": "3306559"
  },
  {
    "text": "you me mention maintenance maintenance yeah",
    "start": "3306559",
    "end": "3312000"
  },
  {
    "text": "uh well what do you mean by maintenance do you well so I mean let's leave the influence of",
    "start": "3312000",
    "end": "3320400"
  },
  {
    "text": "the Google translate out of the equation for but language has changed right so",
    "start": "3320400",
    "end": "3325920"
  },
  {
    "text": "you train a language at time a m it wouldn't necessarily be the same at time",
    "start": "3325920",
    "end": "3333200"
  },
  {
    "text": "yeah yeah that's a good point so an interesting joke inside the translate team is according for our team the",
    "start": "3333200",
    "end": "3340079"
  },
  {
    "text": "president is is still George W bush because that's what the data on the internet says so when we mine these",
    "start": "3340079",
    "end": "3345880"
  },
  {
    "text": "examples when someone says president of the United States it's George W bush that's what we we spit out so it depends",
    "start": "3345880",
    "end": "3352480"
  },
  {
    "text": "uh you should get the right data so we have to keep mining new data and we have to retrain these models with the new",
    "start": "3352480",
    "end": "3358359"
  },
  {
    "text": "data so that's what I mean by m yeah so you have to retrain it so how you do that uh because we just switched to",
    "start": "3358359",
    "end": "3364720"
  },
  {
    "text": "these neural models we haven't done we haven't M maintained them or swapped them yet but we would do it every few",
    "start": "3364720",
    "end": "3371559"
  },
  {
    "text": "months I believe okay and then the next problem is if we bring Google translate back into the equation yeah how do you",
    "start": "3371559",
    "end": "3377640"
  },
  {
    "text": "make sure that you're not training the world rather than the world training",
    "start": "3377640",
    "end": "3383359"
  },
  {
    "text": "you what do you mean by that as in producing the wrong text for other",
    "start": "3383359",
    "end": "3389359"
  },
  {
    "text": "people to learn",
    "start": "3389359",
    "end": "3393799"
  },
  {
    "text": "um so you you you go to the world you you",
    "start": "3395000",
    "end": "3403119"
  },
  {
    "text": "develop a probability map and then your probability map is not an exact",
    "start": "3403119",
    "end": "3408440"
  },
  {
    "text": "representation of the probability map in the world it's by some you use it over",
    "start": "3408440",
    "end": "3414079"
  },
  {
    "text": "and over and over again right and and just by constant use it's like the big lie you say it over and over and over",
    "start": "3414079",
    "end": "3420599"
  },
  {
    "text": "again and it becomes true well yeah that's that's a problem I guess but why",
    "start": "3420599",
    "end": "3425880"
  },
  {
    "text": "is it a problem yeah why is it a problem I don't know like yeah we people",
    "start": "3425880",
    "end": "3430920"
  },
  {
    "text": "language keeps changing and we can change our data to update the model it's a problem for main to know whether",
    "start": "3430920",
    "end": "3436960"
  },
  {
    "text": "you're looking at yourself or looking at the world that's practical manifestation",
    "start": "3436960",
    "end": "3442039"
  },
  {
    "text": "of this problem the Practical manifestation of this problem would be Google translate trains on its own",
    "start": "3442039",
    "end": "3449359"
  },
  {
    "text": "translations right which already happens and as Melvin said we know already that",
    "start": "3449359",
    "end": "3455319"
  },
  {
    "text": "this is a problem and yeah the fundamental question is can you distinguish human translation from",
    "start": "3455319",
    "end": "3461720"
  },
  {
    "text": "machine trans I don't think that's the only issue right so if if Google translate would be over indexing on the outputs um",
    "start": "3461720",
    "end": "3468400"
  },
  {
    "text": "certain words right and then people grew up learning through Google translate right uh wouldn't they start to use",
    "start": "3468400",
    "end": "3474839"
  },
  {
    "text": "those words more yeah that that's true I mean one of the like one way to solve this is we have uh we have this",
    "start": "3474839",
    "end": "3481720"
  },
  {
    "text": "community thing where people can actually go and edit the translations and we learn from those much more than",
    "start": "3481720",
    "end": "3488000"
  },
  {
    "text": "our actual data so if we had 100 examples of something but if one human went ahead and said hey this example is",
    "start": "3488000",
    "end": "3493799"
  },
  {
    "text": "wrong this is the right one we learn much more from that example come back my earlier question",
    "start": "3493799",
    "end": "3499400"
  },
  {
    "text": "about tone for your age and masculinity or femininity yeah I if your system go",
    "start": "3499400",
    "end": "3506680"
  },
  {
    "text": "on like that you're going to wipe out the language basically neutralize no so",
    "start": "3506680",
    "end": "3513400"
  },
  {
    "text": "voice no no no so one of the things that we're actually doing is when you have this multilingual system we just add",
    "start": "3513400",
    "end": "3519160"
  },
  {
    "text": "this token that says oh hey go to this language right one of the other things that we experimented with is you can add",
    "start": "3519160",
    "end": "3525079"
  },
  {
    "text": "a token that says hey translate it formally and it works so it learns from",
    "start": "3525079",
    "end": "3530119"
  },
  {
    "text": "examples that this sentence has to be if you put the token that says formal it has to be translated formally",
    "start": "3530119",
    "end": "3536559"
  },
  {
    "text": "and you put another token that says hey this is a male person you put a token for male it translates it into a male",
    "start": "3536559",
    "end": "3542000"
  },
  {
    "text": "how do you know that in the first place uh we would get it from the data so for for for example formality you can you",
    "start": "3542000",
    "end": "3548599"
  },
  {
    "text": "know that some pronouns are used in the formal sense some are in the informal sense so You' have to get it from the",
    "start": "3548599",
    "end": "3555000"
  },
  {
    "text": "data you'd have to have a mechanism to for detecting these things so coming back to your token it",
    "start": "3555000",
    "end": "3561720"
  },
  {
    "text": "seems like a lot of the power you derive is just from that simple token you add at the beginning so like how do you",
    "start": "3561720",
    "end": "3567079"
  },
  {
    "text": "train that token it's just trained as a it's not trained in any special way it's just one one of the characters in the",
    "start": "3567079",
    "end": "3574240"
  },
  {
    "text": "sequence one of the words in the sequence so there's no special handling so what kind of a cost function",
    "start": "3574240",
    "end": "3581319"
  },
  {
    "text": "do you use to guide decoding during beam search and if you done ablation studies like you peniz",
    "start": "3581319",
    "end": "3586799"
  },
  {
    "text": "longer we do some sort of length normalization to to handle the different",
    "start": "3586799",
    "end": "3594039"
  },
  {
    "text": "lens is that what you were asking or in general like do you have different cause functions used during no it's just",
    "start": "3594039",
    "end": "3601000"
  },
  {
    "text": "one most singular English nouns are preceded with an article why is it that your Hemingway example in the very",
    "start": "3601000",
    "end": "3607720"
  },
  {
    "text": "beginning had trouble yeah that's a that's a good question so one of the things could be that uh the data is just",
    "start": "3607720",
    "end": "3616039"
  },
  {
    "text": "like that so most of these things you just point to the data right so we we it could be the case that the",
    "start": "3616039",
    "end": "3623680"
  },
  {
    "text": "translations of Japanese to English on the web people om articles or things like",
    "start": "3623680",
    "end": "3629200"
  },
  {
    "text": "that oh there are many other data problems like for example if you looked at examples from English to Hindi then",
    "start": "3629200",
    "end": "3635960"
  },
  {
    "text": "you'd see this weird odd case where people who are translating this Hindi word would instead of translating they",
    "start": "3635960",
    "end": "3641359"
  },
  {
    "text": "would try to transliterate it into Hindi and now you feed this data into the model it learns to do it the same way as",
    "start": "3641359",
    "end": "3646799"
  },
  {
    "text": "it was in the data so have you have you looked at domains",
    "start": "3646799",
    "end": "3653400"
  },
  {
    "text": "at all yeah so I mean I would think that technical material would be a different",
    "start": "3653400",
    "end": "3660839"
  },
  {
    "text": "domain and have a different property than poetry for example yes uh we do we",
    "start": "3660839",
    "end": "3667160"
  },
  {
    "text": "don't we train on all the data we have we train on all of the data that we have but we are starting to look at training",
    "start": "3667160",
    "end": "3673880"
  },
  {
    "text": "on different domains and specializing models for different domains have a question um there was a",
    "start": "3673880",
    "end": "3680640"
  },
  {
    "text": "question earlier about stability if you translate from X to Y and translate back",
    "start": "3680640",
    "end": "3686280"
  },
  {
    "text": "mhm I I would think that there must be a fuzzy gray interpretation of what a",
    "start": "3686280",
    "end": "3692599"
  },
  {
    "text": "translation is right and I would think that maybe one way you could automatically hone that down is not by",
    "start": "3692599",
    "end": "3699559"
  },
  {
    "text": "taking just the single quote best translation but take the top two or",
    "start": "3699559",
    "end": "3704599"
  },
  {
    "text": "three or 10 take each of those translate back to the source language and take the",
    "start": "3704599",
    "end": "3709720"
  },
  {
    "text": "top two or 3 or 10 so you have nine or 100 possible circuits yeah compare those",
    "start": "3709720",
    "end": "3716279"
  },
  {
    "text": "with what you started with and see to what extent try try to match them up and see",
    "start": "3716279",
    "end": "3722359"
  },
  {
    "text": "which ones are bizarre versus which one seem to for an adjective or something it might come back as the same or a",
    "start": "3722359",
    "end": "3727880"
  },
  {
    "text": "different and that would tell you which route perhaps to wait more heavily that that's a good question we do use beam",
    "start": "3727880",
    "end": "3733920"
  },
  {
    "text": "search when we decode so when we decode these neural sequences probably like you're picking the top top one you",
    "start": "3733920",
    "end": "3740119"
  },
  {
    "text": "always pick one out of eight or one out of four and there are a lot of gains from doing the beam search that the top",
    "start": "3740119",
    "end": "3747559"
  },
  {
    "text": "on can the source be audio no not in this model not yet otherwise you could",
    "start": "3747559",
    "end": "3754559"
  },
  {
    "text": "solve the previous question you know English font Hindi audio coupling it to",
    "start": "3754559",
    "end": "3760079"
  },
  {
    "text": "audio and then right yeah that that would be awesome if you do speech to speech",
    "start": "3760079",
    "end": "3766480"
  },
  {
    "text": "right it's a dumb question what happens if you translate English to English it",
    "start": "3766480",
    "end": "3772160"
  },
  {
    "text": "it kind of lears to paraphrase a little bit just zero change or no it paraphrases a little bit",
    "start": "3772160",
    "end": "3778920"
  },
  {
    "text": "so it was we did look at it it learns to paraphrase so something uh I had some examples that I didn't put in the slides",
    "start": "3778920",
    "end": "3785319"
  },
  {
    "text": "but something like uh takes a long time uh trans gets paraphrased to too late or",
    "start": "3785319",
    "end": "3790839"
  },
  {
    "text": "something like that it does like small things but most of the time it copies the words but in some cases it",
    "start": "3790839",
    "end": "3798319"
  },
  {
    "text": "paraphrases I was never much good at foreign languages um but as an engineer",
    "start": "3800559",
    "end": "3807079"
  },
  {
    "text": "when I learned two yeah very basics of some other languages I kept wondering if",
    "start": "3807079",
    "end": "3813359"
  },
  {
    "text": "there was a way to evaluate what language is best in some weird aesthetic sense the most explicit the most",
    "start": "3813359",
    "end": "3820440"
  },
  {
    "text": "Alternatives the the clearest vocabulary the least ambiguity I'm wondering if this system",
    "start": "3820440",
    "end": "3826839"
  },
  {
    "text": "gives you some way of trying to answer a question like that if you you said you use English as an Intermediate",
    "start": "3826839",
    "end": "3832359"
  },
  {
    "text": "Language you might try using several other langu as the intermediate and evaluate to what",
    "start": "3832359",
    "end": "3839039"
  },
  {
    "text": "extent the results are more reliable if you go through Russian for instance because of the that's the that's the",
    "start": "3839039",
    "end": "3845520"
  },
  {
    "text": "question that that in this model it's not going through English it's going through this interlingua that it learns",
    "start": "3845520",
    "end": "3850559"
  },
  {
    "text": "on its own okay so instead of forcing the model to go through English you're saying hey go through whatever you think",
    "start": "3850559",
    "end": "3856359"
  },
  {
    "text": "is best I I didn't mean for the sake of making your product work better I meant for just aesthetically answering the the",
    "start": "3856359",
    "end": "3863039"
  },
  {
    "text": "philosophical question about what language is the it could be interesting like one of the",
    "start": "3863039",
    "end": "3868079"
  },
  {
    "text": "things uh someone was telling me was uh there was this uh paper that said all",
    "start": "3868079",
    "end": "3874000"
  },
  {
    "text": "languages have the same uh they try to reduce the dependency length so people",
    "start": "3874000",
    "end": "3879480"
  },
  {
    "text": "when they speak the language they try to make the sentence as short as possible so they were saying that can you use",
    "start": "3879480",
    "end": "3885359"
  },
  {
    "text": "this model to prove it that all languages have this kind of thing so we could use it to do those kinds of",
    "start": "3885359",
    "end": "3892000"
  },
  {
    "text": "experiments but we haven't yet what do you do without vocabulary",
    "start": "3892000",
    "end": "3897039"
  },
  {
    "text": "words uh say that again out of vocabulary words you've never seen yeah",
    "start": "3897039",
    "end": "3902119"
  },
  {
    "text": "so what happens with these word pieces is uh as you're at the top they're",
    "start": "3902119",
    "end": "3907200"
  },
  {
    "text": "mostly words as you go down the frequency list they get split up but as you go below they they're characters so",
    "start": "3907200",
    "end": "3913480"
  },
  {
    "text": "when you have Auto vocabulary words the model tries to make up these characters so that's kind of neat in that when you",
    "start": "3913480",
    "end": "3918920"
  },
  {
    "text": "had a proper name it would transliterate it into the target language instead of trying to learn that name it would just",
    "start": "3918920",
    "end": "3925119"
  },
  {
    "text": "copy the character um just just curious um so you have",
    "start": "3925119",
    "end": "3930400"
  },
  {
    "text": "these various languages and say you're expressing the same idea in all these languages so a language is like a camera",
    "start": "3930400",
    "end": "3937960"
  },
  {
    "text": "and the sentence in that particular Lang language is like a picture of the actual object which is the idea okay right so",
    "start": "3937960",
    "end": "3945799"
  },
  {
    "text": "um is there something um so have have you like try to figure out how the idea",
    "start": "3945799",
    "end": "3952760"
  },
  {
    "text": "and the language can be decoupled in a certain sense H that's a good question well we're doing some of it in that this",
    "start": "3952760",
    "end": "3959559"
  },
  {
    "text": "representation is kind of language independent there's no it doesn't depend on the on the script it does not depend",
    "start": "3959559",
    "end": "3967200"
  },
  {
    "text": "on the sequence of characters but it depends on this 1,00 dimensional Vector of numbers of floating Point",
    "start": "3967200",
    "end": "3974760"
  },
  {
    "text": "numbers so um you said that you get your material for training from the web yeah",
    "start": "3975000",
    "end": "3982200"
  },
  {
    "text": "and then you use an example of PBC uh having the same material in in",
    "start": "3982200",
    "end": "3989000"
  },
  {
    "text": "different languages so that's all very that's all very current um now Google's",
    "start": "3989000",
    "end": "3995279"
  },
  {
    "text": "also got this project taking the written library and uh converting it are you",
    "start": "3995279",
    "end": "4001599"
  },
  {
    "text": "using any of that material so because of uh legal reasons we're not supposed to use Google Books uh even if that they're",
    "start": "4001599",
    "end": "4010559"
  },
  {
    "text": "100 years old no for some sort of legal reason we've been trying to use it for a long time but we we cannot use it I",
    "start": "4010559",
    "end": "4017720"
  },
  {
    "text": "guess we'll figure it out but uh I think the yeah we we cannot use it for legal",
    "start": "4017720",
    "end": "4024400"
  },
  {
    "text": "reasons your feedback mechanism is that automatic or they just call you and tell",
    "start": "4024400",
    "end": "4029839"
  },
  {
    "text": "you the translation was wrong no you can if you use the app or you use it on the",
    "start": "4029839",
    "end": "4035160"
  },
  {
    "text": "browser you can just press it and type the correct translation no I it goes to",
    "start": "4035160",
    "end": "4040400"
  },
  {
    "text": "the system or you just look at it later no it go it we collect all the examples and it goes into the system again the",
    "start": "4040400",
    "end": "4046440"
  },
  {
    "text": "next time we train you control the flow yeah we control the flow we we have so when someone gives a correction what we",
    "start": "4046440",
    "end": "4053559"
  },
  {
    "text": "do is we have this thing called Community where people who love their language say I love Hindi I go to",
    "start": "4053559",
    "end": "4059240"
  },
  {
    "text": "translate community and I can when I'm free I can give translations of sentences so we show them these",
    "start": "4059240",
    "end": "4065440"
  },
  {
    "text": "Corrections that other people did we say hey this person said this is a translation of this what do you think",
    "start": "4065440",
    "end": "4070920"
  },
  {
    "text": "and if multiple people say yes this is the right translation we accept it So you you're not using all like 103",
    "start": "4070920",
    "end": "4078440"
  },
  {
    "text": "versus 103 you have smaller groups and I imagine those break down to like romance languages versus not that's that's a",
    "start": "4078440",
    "end": "4084559"
  },
  {
    "text": "good question so uh we right now we are grouping according to language family well we did experiments like I did a lot",
    "start": "4084559",
    "end": "4090799"
  },
  {
    "text": "of experiments that tried to put Korean and Portuguese together and it was still still the same quality so it does not",
    "start": "4090799",
    "end": "4096960"
  },
  {
    "text": "care about the language throwing like bask or sort of the I didn't do any extreme ones but you",
    "start": "4096960",
    "end": "4102758"
  },
  {
    "text": "know it doesn't seem to care that much how",
    "start": "4102759",
    "end": "4108199"
  },
  {
    "text": "about calt we'll try",
    "start": "4110359",
    "end": "4116000"
  },
  {
    "text": "it did did you try any I don't know humor pums",
    "start": "4116000",
    "end": "4121880"
  },
  {
    "text": "no it's pretty bad at it I think um so is there a reason why you",
    "start": "4121880",
    "end": "4128278"
  },
  {
    "text": "use a one hot encoding for the for the for the you know result instead of something like word",
    "start": "4128279",
    "end": "4133359"
  },
  {
    "text": "to no uh no all of these are vector representations they're not one heart at",
    "start": "4133359",
    "end": "4139880"
  },
  {
    "text": "the end so so you know you pick you pick a single one from the list right right so so is I mean there are already like",
    "start": "4139880",
    "end": "4147600"
  },
  {
    "text": "there are already embeddings of words in semantic space that that will presumably have like a smaller amount of output",
    "start": "4147600",
    "end": "4153920"
  },
  {
    "text": "parameters right well the when you pick from these different vocabulary elements like 32,000 of them right you pick one",
    "start": "4153920",
    "end": "4160679"
  },
  {
    "text": "of them but these 32,000 word pieces are represented as an embedd",
    "start": "4160679",
    "end": "4166238"
  },
  {
    "text": "oh okay so it's not it's not a one no it's not a one it's an embedding",
    "start": "4166239",
    "end": "4172080"
  },
  {
    "text": "yeah so I mean this is a very simple question in terms of machine learning thing but it's like how much weight do",
    "start": "4172080",
    "end": "4179040"
  },
  {
    "text": "you give to like uh wordss which are pretty rare So if you've seen only like couple of examples do you think that can",
    "start": "4179040",
    "end": "4185440"
  },
  {
    "text": "get suppressed uh it does tend to get suppressed and that's a that's a problem and one of the things one of the ways",
    "start": "4185440",
    "end": "4191880"
  },
  {
    "text": "you can solve it is you can wait your examples based on how important they but we don't do that right now well there is",
    "start": "4191880",
    "end": "4198600"
  },
  {
    "text": "also one factor that because we use this statistical subo segmentation the",
    "start": "4198600",
    "end": "4204719"
  },
  {
    "text": "distribution of frequencies of these species is much more uniform than the Z",
    "start": "4204719",
    "end": "4210760"
  },
  {
    "text": "distribution you will see if you looked at the language itself so we hope that",
    "start": "4210760",
    "end": "4216120"
  },
  {
    "text": "uh it can learn something meaningful about each of these pieces and when the",
    "start": "4216120",
    "end": "4221199"
  },
  {
    "text": "infrequent word consists of many of these pieces we hope that some of them",
    "start": "4221199",
    "end": "4226840"
  },
  {
    "text": "have shared meaning with other words like stem in the word will occur many",
    "start": "4226840",
    "end": "4232159"
  },
  {
    "text": "more times than this particular complex form which is using that stamp but yeah mostly just hope that it",
    "start": "4232159",
    "end": "4241760"
  },
  {
    "text": "works yeah how about words exploding into phrases for example in in it",
    "start": "4241760",
    "end": "4247080"
  },
  {
    "text": "there's I think there's 37 words and we try to translate them into",
    "start": "4247080",
    "end": "4252640"
  },
  {
    "text": "English some of those words turn into phrases in some TR sentences right again",
    "start": "4252640",
    "end": "4257920"
  },
  {
    "text": "because we use these subwords uh we would handle them so would you get well you would you would",
    "start": "4257920",
    "end": "4264600"
  },
  {
    "text": "get whatever is based on the context so if the training data is saying in this",
    "start": "4264600",
    "end": "4269719"
  },
  {
    "text": "context always translated into the phrase then we would throw out the phrase if the training data says in this",
    "start": "4269719",
    "end": "4275040"
  },
  {
    "text": "context give give a word out we would give a word out so let me uh conclude",
    "start": "4275040",
    "end": "4280800"
  },
  {
    "text": "because I'm running low on time and then questions um so we show that gnmt which is Google's nmt system this leads to a",
    "start": "4280800",
    "end": "4288159"
  },
  {
    "text": "huge leap in Translation quality multilingual nmt allows us to do zero shot",
    "start": "4288159",
    "end": "4294480"
  },
  {
    "text": "translation so visualizations that we did they're hinting at the presence of an interlingual between these languages",
    "start": "4294480",
    "end": "4301800"
  },
  {
    "text": "and we've just scratched the surface of the interlingual there's there's a lot to do we need to explore more and",
    "start": "4301800",
    "end": "4307560"
  },
  {
    "text": "there's a lot lot of interesting problems to solve in the coming years uh this could be what the future looks like",
    "start": "4307560",
    "end": "4314600"
  },
  {
    "text": "instead of having a machine translation system you could have a single system that does multiple tasks uh and in",
    "start": "4314600",
    "end": "4320400"
  },
  {
    "text": "multiple languages so you can have a system that can translate from English to Spanish it can also do English",
    "start": "4320400",
    "end": "4326000"
  },
  {
    "text": "sentiment it can do English parsing it can also do German parsing things like that this could be a reality",
    "start": "4326000",
    "end": "4333679"
  },
  {
    "text": "right there are some resources here uh some links to articles some blog",
    "start": "4333679",
    "end": "4340400"
  },
  {
    "text": "posts and uh thank you very much for your ination invitation gets L up",
    "start": "4340400",
    "end": "4349360"
  },
  {
    "text": "here the papers you mentioned they're out already correct uh yeah for 16",
    "start": "4355520",
    "end": "4362719"
  },
  {
    "text": "languages and yesterday we launched uh three more languages Hindi",
    "start": "4362719",
    "end": "4369360"
  },
  {
    "text": "Vietnamese yeah we're launching more and more languages what does the numbers compare versus Skype",
    "start": "4369360",
    "end": "4377639"
  },
  {
    "text": "transl yeah I mean I I don't think I can comment on it I don't know like how no",
    "start": "4377639",
    "end": "4384600"
  },
  {
    "text": "only we only know that we only know their quality if they do it on a public data set that we also have access to",
    "start": "4384600",
    "end": "4391159"
  },
  {
    "text": "right yeah well we believe we're better",
    "start": "4391159",
    "end": "4397280"
  },
  {
    "text": "but yeah so what about local dialect I mean like in Hindu and Chinese there",
    "start": "4399679",
    "end": "4406719"
  },
  {
    "text": "tremendous amount of local di right uh yeah we don't handle it right now but uh",
    "start": "4406719",
    "end": "4414159"
  },
  {
    "text": "one of the sad things is uh language is kind of weaning out right these dialects are not most of the time they're spoken",
    "start": "4414159",
    "end": "4420960"
  },
  {
    "text": "they're not written and uh there's not a lot of data on the web so the only way we could pick up this dialect is if",
    "start": "4420960",
    "end": "4428159"
  },
  {
    "text": "there were there was data on the web and we see it a question yes um have you",
    "start": "4428159",
    "end": "4435920"
  },
  {
    "text": "running using emoji which is sort of another kind of there's debate whether",
    "start": "4435920",
    "end": "4441480"
  },
  {
    "text": "or not oh it does learn to translate the Emoji so it splits up the Emoji and then",
    "start": "4441480",
    "end": "4447239"
  },
  {
    "text": "copies it it learns to copy the Emoji most of the time so have so you you have seen it going so English emoj oh no no",
    "start": "4447239",
    "end": "4454520"
  },
  {
    "text": "we haven't translated Emoji across language no Emotion Detector it's difficult to find parallel",
    "start": "4454520",
    "end": "4461679"
  },
  {
    "text": "data for that's the main problem and it's also difficult to classify data into",
    "start": "4461679",
    "end": "4468600"
  },
  {
    "text": "dialects so is it is is the difficulty finding things that are in English",
    "start": "4468600",
    "end": "4473679"
  },
  {
    "text": "translated yeah yeah I mean that I can help with question you had a question for I'm",
    "start": "4473679",
    "end": "4480800"
  },
  {
    "text": "not sure this has practical value but it might be intriguing and for historical values to introduce Esperanto into the",
    "start": "4480800",
    "end": "4488440"
  },
  {
    "text": "mix and have you done that no that's a that's a good question I'm working on a side personal project where I'm trying",
    "start": "4488440",
    "end": "4494360"
  },
  {
    "text": "to do this but no we haven't done it people the",
    "start": "4494360",
    "end": "4502600"
  },
  {
    "text": "world isn't very much as par data examples are there no there there are",
    "start": "4504360",
    "end": "4509440"
  },
  {
    "text": "not many yeah have you tried translating poetry",
    "start": "4509440",
    "end": "4515960"
  },
  {
    "text": "like does it preserve the Aesthetics maybe uh not so well but most of the time yeah",
    "start": "4515960",
    "end": "4522760"
  },
  {
    "text": "you get the idea of what the poet is trying to say",
    "start": "4522760",
    "end": "4526960"
  },
  {
    "text": "work on Hy I don't want to keep hugging okay um towards the beginning of your",
    "start": "4528719",
    "end": "4534639"
  },
  {
    "text": "presentation one of the things I was wondering was the extent to which the engineers and Architects were themselves",
    "start": "4534639",
    "end": "4541360"
  },
  {
    "text": "multilingual in a broad range bilingual or multi thinking that that would help",
    "start": "4541360",
    "end": "4547199"
  },
  {
    "text": "them understand the problems right but as you got into it I'm thinking that one",
    "start": "4547199",
    "end": "4552800"
  },
  {
    "text": "doesn't need to understand the problems if one is designing the network and",
    "start": "4552800",
    "end": "4558840"
  },
  {
    "text": "turning the crank until it it comes out so that that's a that's a fair uh point",
    "start": "4558840",
    "end": "4564840"
  },
  {
    "text": "no one we don't have to know the language to do this is there value or do you have multilingual polyglots or",
    "start": "4564840",
    "end": "4571639"
  },
  {
    "text": "whatever working on the team and do they have any insight into what issues might oh I can speak a few languages Max see",
    "start": "4571639",
    "end": "4577120"
  },
  {
    "text": "my guest can speak a few languages uh but uh there is value in that uh if you",
    "start": "4577120",
    "end": "4582320"
  },
  {
    "text": "see something wrong you can immediately spot it in trying to send it out to do these evaluations and get it back what",
    "start": "4582320",
    "end": "4589840"
  },
  {
    "text": "languages for instance do you consider yourself me oh I can speak uh English",
    "start": "4589840",
    "end": "4595080"
  },
  {
    "text": "Hindi Tamil and a little bit of German and think Maxine can speak French Russian and English Russian Russian and",
    "start": "4595080",
    "end": "4603120"
  },
  {
    "text": "French and Eng you guys are doing far better than the founders of AI um mcarthy new Russian okay mitsky",
    "start": "4603120",
    "end": "4612440"
  },
  {
    "text": "basically only spoke English right well then my followup to that with your",
    "start": "4612440",
    "end": "4618159"
  },
  {
    "text": "patience is that this really does go back to some early AI thought experiments I don't know if this was",
    "start": "4618159",
    "end": "4624199"
  },
  {
    "text": "cheing or someone else the idea that a man in a box that was seeing his slips and looking at answers and finding out",
    "start": "4624199",
    "end": "4631920"
  },
  {
    "text": "how to match the pattern Chinese room this was John John in a sense that's what you're doing",
    "start": "4631920",
    "end": "4639120"
  },
  {
    "text": "here if the if the coders don't understand this they're just finding something else to match one thing",
    "start": "4639120",
    "end": "4645560"
  },
  {
    "text": "against something else right so maybe this is a dumb question but isn't this a",
    "start": "4645560",
    "end": "4650880"
  },
  {
    "text": "fairly sophisticated AI system that would pass the AI test I don't know we should we should",
    "start": "4650880",
    "end": "4656760"
  },
  {
    "text": "test it but that's a point that's a good point it's that the model does not know what language it's seeing but it can do",
    "start": "4656760",
    "end": "4664360"
  },
  {
    "text": "the what it's asked to do can you ask it from same language back to the same language like this",
    "start": "4664360",
    "end": "4671320"
  },
  {
    "text": "person really means to say this if you train it enough",
    "start": "4671320",
    "end": "4677639"
  },
  {
    "text": "yes Trump is input and no",
    "start": "4677639",
    "end": "4683840"
  },
  {
    "text": "comments would it be possible to add a structure to some of",
    "start": "4683840",
    "end": "4688960"
  },
  {
    "text": "your thata I suppose that this piece is a poem this piece is a technical article",
    "start": "4688960",
    "end": "4695960"
  },
  {
    "text": "yeah I mean and would that make it would definitely help um and one of the things you can do is you if you tag these",
    "start": "4695960",
    "end": "4702800"
  },
  {
    "text": "examples based on some domains and when someone is trying to translate you can give them the option to say hey this is",
    "start": "4702800",
    "end": "4708800"
  },
  {
    "text": "the tech domain give me the best translation so then we can do the best",
    "start": "4708800",
    "end": "4713960"
  },
  {
    "text": "translation can you speculate an applications to other domains and what",
    "start": "4713960",
    "end": "4719440"
  },
  {
    "text": "I'm thinking is a genetics where you can like learn to translate a sequence of",
    "start": "4719440",
    "end": "4724960"
  },
  {
    "text": "protein one in humans and Ma for example but is there anything else if you yeah I",
    "start": "4724960",
    "end": "4732159"
  },
  {
    "text": "mean one thing that's interesting is as long as you have enough examples I think the the system can learn by itself so if",
    "start": "4732159",
    "end": "4738840"
  },
  {
    "text": "you had enough examples of human to animal genes we can do a pretty good job at",
    "start": "4738840",
    "end": "4745520"
  },
  {
    "text": "it all right I think people are tired of questions",
    "start": "4745880",
    "end": "4752440"
  }
]
[
  {
    "start": "0",
    "end": "5750"
  },
  {
    "text": "OK, guys, let's get started. So I think last week I spent\nsome time reading the feedback",
    "start": "5750",
    "end": "16580"
  },
  {
    "text": "from the survey. I've been going\nthrough all of them. So I guess I'm not going to\ndiscuss every points there.",
    "start": "16580",
    "end": "24290"
  },
  {
    "text": "All the points are well taken. And thanks for all the\nvery helpful feedback.",
    "start": "24290",
    "end": "30200"
  },
  {
    "text": "And for some of those,\nI'm going to improve. I guess there are also some\nother conflictory requests,",
    "start": "30200",
    "end": "38540"
  },
  {
    "text": "which still are\nvery understandable because different people\nhave different preferences. That's completely fine.",
    "start": "38540",
    "end": "44899"
  },
  {
    "text": "But I guess I'm just\nsaying that it's not that, oh, I can't address all\nthe possible requests just",
    "start": "44900",
    "end": "50600"
  },
  {
    "text": "because sometimes there\nare some constraints. But of course,\nsometimes I think even",
    "start": "50600",
    "end": "57740"
  },
  {
    "text": "conflictory requests can be\naddressed if you are creative. I will try to do that as well.",
    "start": "57740",
    "end": "63530"
  },
  {
    "start": "63530",
    "end": "69049"
  },
  {
    "text": "I guess there's one thing I want\nto discuss a little bit, which I think might be useful for\nyou is not trying to find",
    "start": "69050",
    "end": "74120"
  },
  {
    "text": "any excuses for the lecture. But I think some\npeople mentioned that it's a little bit hard\nto follow the notes, well,",
    "start": "74120",
    "end": "84130"
  },
  {
    "text": "at least in the lecture. I can completely\nunderstand that. I wrote pretty fast,\nwhich I'm going to slow down a little\nbit, at least to make",
    "start": "84130",
    "end": "90350"
  },
  {
    "text": "the layout and the format a\nbit cleaner, easier to read. But I think, in\nmy opinion, this--",
    "start": "90350",
    "end": "97430"
  },
  {
    "text": "of course, I'm not saying\nthat you have to really follow my way to take courses. I typically don't\ntake a lot of notes.",
    "start": "97430",
    "end": "105270"
  },
  {
    "text": "I think at least\nthis course I tried to design so that you don't have\nto take all the notes yourself",
    "start": "105270",
    "end": "111132"
  },
  {
    "text": "just because we're going\nto have Scribe notes later. And some of the Scribe\nnotes are already there.",
    "start": "111133",
    "end": "117020"
  },
  {
    "text": "And when I listen to\na theoretical lecture, I try to think more so\nthat I can remember them",
    "start": "117020",
    "end": "124190"
  },
  {
    "text": "in my head a little bit. Because I feel that,\nat least for me, it takes too much energy\nfor taking all the notes.",
    "start": "124190",
    "end": "133480"
  },
  {
    "text": "I'm not sure that this\nis useful for everyone. I don't think it can\nbe useful for everyone, but maybe you can\ntry it a little bit",
    "start": "133480",
    "end": "140239"
  },
  {
    "text": "just to see whether it's easier\nif you take a bit less notes and try to remember\na little more.",
    "start": "140240",
    "end": "146329"
  },
  {
    "text": "Otherwise, I'm\ngoing to slow down a little bit at least in\nterms of the writing for sure. And also, probably I'm\ngoing to kind of slow down",
    "start": "146330",
    "end": "153140"
  },
  {
    "text": "a little bit in terms of the\noverall pace a little bit as well, given some of\nthe feedbacks saying",
    "start": "153140",
    "end": "160640"
  },
  {
    "text": "that some of the lectures\nare a little bit too fast. And also, another\nthing is that I",
    "start": "160640",
    "end": "165740"
  },
  {
    "text": "think the homework\nquestions-- you know, indeed, some of the questions, I think\nI probably made the mistake that a few subquestions\nare a bit too difficult.",
    "start": "165740",
    "end": "174570"
  },
  {
    "text": "They were bonus questions\nin the past offerings, and this quarter\nI thought that you",
    "start": "174570",
    "end": "180515"
  },
  {
    "text": "have a team of three people. So maybe I can put\nthem as regular points. But still, they are probably\na little bit too difficult.",
    "start": "180515",
    "end": "187189"
  },
  {
    "text": "They require some kind of\nfix, as you probably noticed, some [INAUDIBLE].",
    "start": "187190",
    "end": "192510"
  },
  {
    "text": "Right. So, yeah. But I guess-- I checked the last homework.",
    "start": "192510",
    "end": "198019"
  },
  {
    "text": "I think there is\nnothing like that. Most of the questions\nprobably shouldn't",
    "start": "198020",
    "end": "203450"
  },
  {
    "text": "require anything super special\ntricks about common topics.",
    "start": "203450",
    "end": "208910"
  },
  {
    "text": "And I guess another\nthing is that, if you want to take some bonus points,\nI guess there are other ways,",
    "start": "208910",
    "end": "215489"
  },
  {
    "text": "for example, do some\nScribe notes, improve existing lectures. If you don't care about A-plus,\nI think the bonus point--",
    "start": "215490",
    "end": "223690"
  },
  {
    "text": "the bonus point is always the\nsame as the regular points, in some sense, if you look\nat the grading policy.",
    "start": "223690",
    "end": "230409"
  },
  {
    "text": "At least, from your\nperspective, it's worth the same as\nthe regular points.",
    "start": "230410",
    "end": "236260"
  },
  {
    "text": "Basically, the grading policy\nis that we first decide the cut off before the bonus points.",
    "start": "236260",
    "end": "241900"
  },
  {
    "text": "And then the bonus\npoints can only make you have\nbetter letter grade. OK.",
    "start": "241900",
    "end": "249190"
  },
  {
    "text": "Anyway, so, yeah, I guess there\nare other very important, very",
    "start": "249190",
    "end": "255370"
  },
  {
    "text": "nice feedbacks, which\nI'm going to incorporate as well in the lecture. I'm not going to discuss\nall of those points just",
    "start": "255370",
    "end": "262000"
  },
  {
    "text": "to save some time. OK, so maybe let's get\ninto the technical part",
    "start": "262000",
    "end": "269620"
  },
  {
    "text": "if there's not any other\nquestions, other discussions.",
    "start": "269620",
    "end": "274780"
  },
  {
    "text": "So I guess, last\nWednesday, I was sick. And we asked you to\nwatch the video online.",
    "start": "274780",
    "end": "282970"
  },
  {
    "text": "And roughly\nspeaking, what we did in the video is that we talk\nabout this optimization,",
    "start": "282970",
    "end": "290110"
  },
  {
    "text": "like a nonconvex optimization. ",
    "start": "290110",
    "end": "297240"
  },
  {
    "text": "And I think so the\nmain point there was that, if you have\nthe so-called property",
    "start": "297240",
    "end": "303259"
  },
  {
    "text": "of local minima, all\nlocal minima global, then",
    "start": "303260",
    "end": "311020"
  },
  {
    "text": "you can find global minima. Of course, there are\ntechnical things, like there is so-called\nstrict set point, which",
    "start": "311020",
    "end": "316600"
  },
  {
    "text": "we discussed in a video. And there are other\nkind of things",
    "start": "316600",
    "end": "321670"
  },
  {
    "text": "that are a little bit subtle,\nbut this is the main point. And so, basically, you only\nhave to show that this is true,",
    "start": "321670",
    "end": "327520"
  },
  {
    "text": "and then you can find a\nglobal minima of the nonconvex function. This kind of search from a\nbroader kind of point of view",
    "start": "327520",
    "end": "336550"
  },
  {
    "text": "is successful. And in some sense, what\nI'm going to discuss next is another example of this.",
    "start": "336550",
    "end": "342560"
  },
  {
    "text": "However, there are some\nkind of special subtleties.",
    "start": "342560",
    "end": "348760"
  },
  {
    "text": "So basically, what we showed\nlast time is that this is really true globally. The statement, all\nlocal minima are global,",
    "start": "348760",
    "end": "356170"
  },
  {
    "text": "are basically-- this is a true\nstatement for the entire space.",
    "start": "356170",
    "end": "361587"
  },
  {
    "text": "And today, what we're\ngoing to discuss is that you're only looking at\na special part of the space. So in some sense, the function\nwe are going to discuss today",
    "start": "361587",
    "end": "368748"
  },
  {
    "text": "looks like something like this. You have some kind\nof complex part about this function, which you\ndon't know how to characterize.",
    "start": "368748",
    "end": "375440"
  },
  {
    "text": "But you identify a small\npart where this is true. You look at a\nspecial region where",
    "start": "375440",
    "end": "382080"
  },
  {
    "text": "all local minima are global. And there is actually a\ngood global minimum there, so then you just only\nwork in that region.",
    "start": "382080",
    "end": "390150"
  },
  {
    "text": "And that's kind\nof the connection to the previous lecture. There are other issues\nwith this kind of approach,",
    "start": "390150",
    "end": "397139"
  },
  {
    "text": "I guess, we discussed\na little bit in one of the outlining lecture.",
    "start": "397140",
    "end": "402449"
  },
  {
    "text": "The limitation would be that\nyou identify this region where everything is nice.",
    "start": "402450",
    "end": "408150"
  },
  {
    "text": "The landscape is just so nice. But is this the region you\nreally care about, right? So if you really care about\nfinding a global minimum",
    "start": "408150",
    "end": "415230"
  },
  {
    "text": "of the tuning loss, then yes. This has to be the region. Because you find a global\nminima of the tuning loss.",
    "start": "415230",
    "end": "420600"
  },
  {
    "text": "But if you care about\nother properties, like generalization\nperformance, then it",
    "start": "420600",
    "end": "426270"
  },
  {
    "text": "might be not the right region\nthat you should focus on. But for today's lecture,\nwe don't care about that.",
    "start": "426270",
    "end": "432540"
  },
  {
    "text": "We just say we're going to\ngo through what this works, and then we talk\nabout limitations.",
    "start": "432540",
    "end": "437695"
  },
  {
    "text": "And in the future\nlectures, we're going to talk about ways to, in\nsome sense, improve upon this",
    "start": "437695",
    "end": "443120"
  },
  {
    "text": "or kind of like fix the issues\nof this kind of approach. ",
    "start": "443120",
    "end": "449155"
  },
  {
    "text": "OK. So that's a very rough kind\nof a high level overview.",
    "start": "449155",
    "end": "454980"
  },
  {
    "text": "And also, by the way, if\nyou haven't seen my notes or announcement on Ed,\nso there are actually",
    "start": "454980",
    "end": "462300"
  },
  {
    "text": "two videos that we\nask you to watch for making up the last lecture. So one of them is\na full lecture,",
    "start": "462300",
    "end": "469050"
  },
  {
    "text": "and the other one\nhas 15 minutes. So they are about this\nnonconvex optimization,",
    "start": "469050",
    "end": "474630"
  },
  {
    "text": "all local minima, global\nminima kind of phenomena. And this does relate to one\nof the homework questions.",
    "start": "474630",
    "end": "480630"
  },
  {
    "text": "The question itself is still,\nin some sense, self-contained. But I think it's useful for you\nto know the basic idea, even",
    "start": "480630",
    "end": "489570"
  },
  {
    "text": "the basic proof ideas\nin those two videos so that you can\nsee better how do",
    "start": "489570",
    "end": "495127"
  },
  {
    "text": "you do the homework question.  OK.",
    "start": "495127",
    "end": "500440"
  },
  {
    "text": "So today, let's talk\nabout the thing we are-- about the special region thing.",
    "start": "500440",
    "end": "506770"
  },
  {
    "text": "And this is also often called\nneural tangent kernel approach. I guess the name\ndoesn't really--",
    "start": "506770",
    "end": "514870"
  },
  {
    "text": "so far, just think of\nthis as a placeholder. I'm going to explain why this\nis called neural tangent kernel.",
    "start": "514870",
    "end": "521919"
  },
  {
    "text": "So the basic idea\nis that you look at some special place\naround a neighborhood",
    "start": "521919",
    "end": "527649"
  },
  {
    "text": "of your initialization, and\nyou do some Taylor expansion. So Taylor expanding--\nand this works",
    "start": "527650",
    "end": "534410"
  },
  {
    "text": "for any nonlinear function. So suppose you have\nyou have a nonlinear--",
    "start": "534410",
    "end": "540700"
  },
  {
    "text": "or even linear, but\nnon-linear would be the most interesting case--\na nonlinear model f theta x.",
    "start": "540700",
    "end": "547279"
  },
  {
    "text": "And then you do a\nTaylor expansion",
    "start": "547280",
    "end": "552590"
  },
  {
    "text": "around initialization. Say that's 0. ",
    "start": "552590",
    "end": "559690"
  },
  {
    "text": "And when you Taylor expand the\nmodel at the initialization-- so your model is f theta x.",
    "start": "559690",
    "end": "565930"
  },
  {
    "text": "You Taylor expand with respect\nto the parameters, but not input.",
    "start": "565930",
    "end": "571300"
  },
  {
    "text": "So the input is fixed, and\nthe parameter is the variable. So say that 0 is\nthe reference point. And then you look at the\ngradient with vector theta",
    "start": "571300",
    "end": "579250"
  },
  {
    "text": "evaluate at theta 0. This is the first order\ngradient times theta minus 0.",
    "start": "579250",
    "end": "585010"
  },
  {
    "text": "So this is the first\norder Taylor expansion. And then you say you have\nsome higher order terms, which",
    "start": "585010",
    "end": "593140"
  },
  {
    "text": "we are going to ignore. And once you do this, you\ncan define maybe this one.",
    "start": "593140",
    "end": "600690"
  },
  {
    "text": "Let's call this g theta x. Of course, it also\ndepends on theta 0. But let's say theta is the\nvariable, so that 0 is fixed.",
    "start": "600690",
    "end": "607970"
  },
  {
    "text": "So this is a function of theta. So this is a linear function.",
    "start": "607970",
    "end": "615070"
  },
  {
    "text": "So if you define\nthis, then g theta x is a linear function in theta.",
    "start": "615070",
    "end": "621130"
  },
  {
    "text": " Because where theta shows up--\nsee, it only shows up here.",
    "start": "621130",
    "end": "628259"
  },
  {
    "text": "And it shows up linearly. And basically, you\nlinearize your model.",
    "start": "628260",
    "end": "637500"
  },
  {
    "text": "And you can also,\nI guess, define the other theta, which is\nthe difference between theta",
    "start": "637500",
    "end": "643620"
  },
  {
    "text": "and theta 0. I guess, technically,\nyou should call this--",
    "start": "643620",
    "end": "648990"
  },
  {
    "text": "maybe this is a affine\nfunction because there is a constant term,\naffine function.",
    "start": "648990",
    "end": "654930"
  },
  {
    "text": "In theta or in the other theta,\nthey are not too different.",
    "start": "654930",
    "end": "660610"
  },
  {
    "text": "I guess just want to introduce\nthis notation, delta theta. ",
    "start": "660610",
    "end": "665760"
  },
  {
    "text": "And so f theta 0, this\nreference point, this is a constant from this\nperspective, right?",
    "start": "665760",
    "end": "673610"
  },
  {
    "text": "It's a constant that\ndoesn't depend-- constant for fixed x.",
    "start": "673610",
    "end": "679630"
  },
  {
    "text": "It doesn't change\nas you change theta.  And in some sense, this is\njust not that important, so",
    "start": "679630",
    "end": "692730"
  },
  {
    "text": "not very important. Because it's a constant. And sometimes for\nconvenience, you choose--",
    "start": "692730",
    "end": "707180"
  },
  {
    "text": "so choose theta 0\nsuch that f theta 0",
    "start": "707180",
    "end": "714589"
  },
  {
    "text": "x is equal to 0 for every x. ",
    "start": "714590",
    "end": "720529"
  },
  {
    "text": "How do you do it? So you do it-- so if you really\nwant to do this, you need to--",
    "start": "720530",
    "end": "726542"
  },
  {
    "text": "for example, what\nyou can do is you can design network that you\nsplit your networking into two",
    "start": "726542",
    "end": "733430"
  },
  {
    "text": "parts. So maybe you have-- suppose before you\nhave a network, you have all of\nthese connections.",
    "start": "733430",
    "end": "741320"
  },
  {
    "text": "And then for the second layer-- maybe for some layers, split\nit into two halves, right? So you have something like this\nand then something like this.",
    "start": "741320",
    "end": "751190"
  },
  {
    "text": "And you do the same\nthing in these two halves, exactly the same\nthing in these two halves. And then you put plus 1\nhere and minus 1 here,",
    "start": "751190",
    "end": "759110"
  },
  {
    "text": "so that they got canceled. So that you have a still\nsomewhat random initialization,",
    "start": "759110",
    "end": "764430"
  },
  {
    "text": "but the initialization\nhas a functionality that the functionality of\nthis initial model is 0.",
    "start": "764430",
    "end": "773100"
  },
  {
    "text": "I'm not sure whether my\ndrawing makes any sense.  I see some confusion\nin your face,",
    "start": "773100",
    "end": "779657"
  },
  {
    "text": "but this is supposed\nto be something simple.  For example, let's\nsay you have some",
    "start": "779657",
    "end": "785840"
  },
  {
    "text": "of linear models, some of-- sorry, two layer networks,\nsum of ai times sigma of wi",
    "start": "785840",
    "end": "792589"
  },
  {
    "text": "transpose x, i from 1 to i. Suppose this is a model. And what you can do is you\ncan say you added to minus ai",
    "start": "792590",
    "end": "800750"
  },
  {
    "text": "sigma wi transpose x. So you have 2n neurons.",
    "start": "800750",
    "end": "806320"
  },
  {
    "text": "And the wi's the same,\nand the ai's are paired.",
    "start": "806320",
    "end": "812350"
  },
  {
    "text": "So then this becomes 0, right? So they have 2n\nneurons, and one part",
    "start": "812350",
    "end": "817899"
  },
  {
    "text": "is the same as the other\npart in terms of w. And in terms of a, they\nare negation of each other. Then you make it 0.",
    "start": "817900",
    "end": "823720"
  },
  {
    "text": "And you still have relatively\ngood randomness, right? You can still choose wi to be\nrandom as long as these are all",
    "start": "823720",
    "end": "830590"
  },
  {
    "text": "wi's and these are ai's. So anyway, this is a not\nsuper important point.",
    "start": "830590",
    "end": "835930"
  },
  {
    "text": "And also, even\nyou don't do this, you can still somewhat\nkind of get away from it because this f theta\n0 x is a constant.",
    "start": "835930",
    "end": "844165"
  },
  {
    "text": "So basically, from now on, we're\ngoing to assume this f theta 0 x is 0 in most of the cases.",
    "start": "844165",
    "end": "849459"
  },
  {
    "text": " And if you think\nabout this, right--",
    "start": "849460",
    "end": "855360"
  },
  {
    "text": "so basically, this is saying\nthat y prime-- suppose you take y prime to be y\nminus this constant, which",
    "start": "855360",
    "end": "865199"
  },
  {
    "text": "we are going to assume is 0. But so far, I said\nfor this equation",
    "start": "865200",
    "end": "871150"
  },
  {
    "text": "I think we can still\nthink of as generic. So then you get this is a linear\nfunction, theta transpose.",
    "start": "871150",
    "end": "878520"
  },
  {
    "text": "So it's going to be grad theta\nf theta 0 x times 0 theta.",
    "start": "878520",
    "end": "887280"
  },
  {
    "text": "And this becomes a\nlinear function 0 theta. So this you can think of\nthis as the parameter,",
    "start": "887280",
    "end": "894390"
  },
  {
    "text": "and this you can think\nof this as a feature map. So this is the same\nas the feature map",
    "start": "894390",
    "end": "901350"
  },
  {
    "text": "phi of x that we discussed,\nfor example, in CS229 when you have a kernel method.",
    "start": "901350",
    "end": "908040"
  },
  {
    "text": "And while this is\na feature map, this is something that doesn't\ndepend on the parameter, right? So theta 0 is fixed already.",
    "start": "908040",
    "end": "914820"
  },
  {
    "text": "So f theta 0 of x is really just\na fixed function of x, right?",
    "start": "914820",
    "end": "920280"
  },
  {
    "text": "So this is a fixed\nlet's call this,",
    "start": "920280",
    "end": "930430"
  },
  {
    "text": "of x given the\narchitecture and theta 0.",
    "start": "930430",
    "end": "938024"
  },
  {
    "text": "But it doesn't depend\non the delta theta. So in some sense, it just\nbecomes kernel method.",
    "start": "938025",
    "end": "946020"
  },
  {
    "text": "And this-- so you can define-- ",
    "start": "946020",
    "end": "951180"
  },
  {
    "text": "whoops, what's going on? So I guess, for simplicity,\nif you assume f theta 0",
    "start": "951180",
    "end": "959750"
  },
  {
    "text": "x is 0, then y and\ny prime the same. So basically, you are\nfitting a linear function",
    "start": "959750",
    "end": "966110"
  },
  {
    "text": "onto your target. And this becomes kernel method. You can define the\nkernel k x, x prime to be",
    "start": "966110",
    "end": "977820"
  },
  {
    "text": "the inner product of features of\nthe phi of x transpose phi of x",
    "start": "977820",
    "end": "986050"
  },
  {
    "text": "prime, which is the inner\nproduct of these two gradient. ",
    "start": "986050",
    "end": "999910"
  },
  {
    "text": "And why this is called\nneural tangent kernel? The reason is that this is\nthe tangent of the network.",
    "start": "999910",
    "end": "1011420"
  },
  {
    "text": "It's the gradient\nof the network. ",
    "start": "1011420",
    "end": "1018964"
  },
  {
    "text": "I think then that's why\nit's called neural tangent kernel because the feature is\nthe gradient of the network.",
    "start": "1018964",
    "end": "1026805"
  },
  {
    "text": "Anyway, the neural tangent\nkernel is just the name.  OK.",
    "start": "1026805",
    "end": "1031954"
  },
  {
    "start": "1031955",
    "end": "1037549"
  },
  {
    "text": "So suppose we just use\nmodel-- we just use g theta",
    "start": "1037550",
    "end": "1045119"
  },
  {
    "text": "x instead of the original model. ",
    "start": "1045119",
    "end": "1051730"
  },
  {
    "text": "Then basically you just got\nkernel method, a linear model",
    "start": "1051730",
    "end": "1062710"
  },
  {
    "text": "on top of the feature, right?",
    "start": "1062710",
    "end": "1068890"
  },
  {
    "text": "And in the loss\nfunction, so suppose you believe that theta is\nclose to theta 0, so 1 theta.",
    "start": "1068890",
    "end": "1077500"
  },
  {
    "text": "Then you can also\nkind of intuitively say, OK, my original\nloss function, which",
    "start": "1077500",
    "end": "1082870"
  },
  {
    "text": "is a function of the\nmodel output and y, probably is approximately close\nto my new loss function, right,",
    "start": "1082870",
    "end": "1090529"
  },
  {
    "text": "which is g theta of x and y. And this is linear.",
    "start": "1090530",
    "end": "1096540"
  },
  {
    "text": " And the whole thing is\nconvex because l is convex.",
    "start": "1096540",
    "end": "1105029"
  },
  {
    "text": "A convex function composed\nwith linear function is still convex, right?",
    "start": "1105030",
    "end": "1110730"
  },
  {
    "text": "But this is when theta\nis very close to theta 0. ",
    "start": "1110730",
    "end": "1119970"
  },
  {
    "text": "And so, basically,\nthe question-- so the remaining thing is\njust really that, so how valid",
    "start": "1119970",
    "end": "1128760"
  },
  {
    "text": "is this approximation? Because everything sounds nice.",
    "start": "1128760",
    "end": "1134200"
  },
  {
    "text": "After we did this, everything\nbecomes super easy. But in what cases\nthis can be valid?",
    "start": "1134200",
    "end": "1142930"
  },
  {
    "text": "Go ahead. [INAUDIBLE] the inner\nproduct [INAUDIBLE]..",
    "start": "1142930",
    "end": "1151564"
  },
  {
    "text": " Yeah. So the inner product is just\nthe typical inner product.",
    "start": "1151564",
    "end": "1157419"
  },
  {
    "text": "You just take the-- because these two are\njust vectors, right? [INAUDIBLE]",
    "start": "1157420",
    "end": "1166067"
  },
  {
    "text": "OK, so what's the\ndimensionality here? So gradient of, say, this\nthing, is in a dimension",
    "start": "1166067",
    "end": "1172900"
  },
  {
    "text": "that's a P if theta is in RP. So it has the same\ndimensionality as--",
    "start": "1172900",
    "end": "1178165"
  },
  {
    "text": "OK, I guess it also\ndepends on what f is. So let's suppose\nf is from some RD",
    "start": "1178165",
    "end": "1186372"
  },
  {
    "text": "to R. D is the dimension of x. ",
    "start": "1186372",
    "end": "1195580"
  },
  {
    "text": "But the point is that the\noutput is one-dimensional. And then you take the gradient\nwith respect to theta.",
    "start": "1195580",
    "end": "1200590"
  },
  {
    "text": "You get a P-dimensional\nvector, where P is the dimension of the theta. So the gradient with\nrespect to theta",
    "start": "1200590",
    "end": "1206770"
  },
  {
    "text": "has the same dimension as theta. That makes sense, right? So this is a\nP-dimensional vector, and you just take inner\nproduct of two vectors",
    "start": "1206770",
    "end": "1215350"
  },
  {
    "text": "to define a feature.  Makes sense?",
    "start": "1215350",
    "end": "1221502"
  },
  {
    "text": "Cool. OK?  So I guess to proceed, I'll\ndefine two notations just",
    "start": "1221502",
    "end": "1229960"
  },
  {
    "text": "for the simplicity. So let's define L hat f theta\nto be the empirical loss",
    "start": "1229960",
    "end": "1235899"
  },
  {
    "text": "with the model f theta. ",
    "start": "1235900",
    "end": "1241899"
  },
  {
    "text": "This is just a\nformality so that we can write this easier in this. And L hat g theta is the\nloss with the model xg theta.",
    "start": "1241900",
    "end": "1254910"
  },
  {
    "text": "OK?  So the key idea is that--",
    "start": "1254910",
    "end": "1260270"
  },
  {
    "text": " so in certain cases, this Taylor\nexpansion makes sense, right?",
    "start": "1260270",
    "end": "1268030"
  },
  {
    "text": "So I guess, the Taylor\nexpansion can make sense, can work for certain cases.",
    "start": "1268030",
    "end": "1275980"
  },
  {
    "start": "1275980",
    "end": "1282720"
  },
  {
    "text": "Here, we're going to hide-- what for what cases it\nmakes sense, can work, it's going to be a big\nquestion that we probably",
    "start": "1282720",
    "end": "1293100"
  },
  {
    "text": "will discuss at the very end. But so far, let's say just\nlet's see how does it work.",
    "start": "1293100",
    "end": "1298510"
  },
  {
    "text": "So the way that they\nwork is the following, so in the following sense. ",
    "start": "1298510",
    "end": "1305600"
  },
  {
    "text": "So how do you say\nit works, right? So you say that there exists\na neighborhood of theta 0 such",
    "start": "1305600",
    "end": "1317990"
  },
  {
    "text": "that in this neighborhood-- so\nlet's call this neighborhood b theta, theta 0, such that--",
    "start": "1317990",
    "end": "1333470"
  },
  {
    "text": "several things happens. So one thing is that you have\nan accurate approximation",
    "start": "1333470",
    "end": "1339440"
  },
  {
    "text": "in terms of function value. So the f theta is somewhat\nclose to g theta of x.",
    "start": "1339440",
    "end": "1347050"
  },
  {
    "text": "And as a result,\nL hat f theta is close to L hat g theta for every\ntheta in this neighborhood B",
    "start": "1347050",
    "end": "1356840"
  },
  {
    "text": "theta 0. So that's something you want,\nwhich makes sense, right?",
    "start": "1356840",
    "end": "1362472"
  },
  {
    "text": "So this is the point\nof Taylor expansion. You want to approximate\noriginal function. And also, you want\nthat it suffices",
    "start": "1362472",
    "end": "1369519"
  },
  {
    "text": "to optimize in B theta 0.",
    "start": "1369520",
    "end": "1377090"
  },
  {
    "text": "Because if, in this B\ntheta 0, there is no good-- maybe let me draw this again.",
    "start": "1377090",
    "end": "1383510"
  },
  {
    "text": " So basically, what\nwe are saying is",
    "start": "1383510",
    "end": "1389050"
  },
  {
    "text": "there is a neighborhood\nthat's got B theta 0. And this neighborhood,\nfirst of all, you have--",
    "start": "1389050",
    "end": "1396460"
  },
  {
    "text": "say suppose your empirical\nloss is look like this. And maybe there's something\nelse happening somewhere else.",
    "start": "1396460",
    "end": "1403880"
  },
  {
    "text": "We don't know. So first of all, if you do the\nquadratic approximation, using Taylor expansion on theta 0.",
    "start": "1403880",
    "end": "1411706"
  },
  {
    "text": "Let's say this is theta 0. You do a quadratic expansion.",
    "start": "1411706",
    "end": "1417030"
  },
  {
    "text": "It looks something\nlike this, very close. This is my drawing.",
    "start": "1417030",
    "end": "1422760"
  },
  {
    "text": "So basically, you can think\nthis red one, this red one, is g theta of x.",
    "start": "1422760",
    "end": "1428549"
  },
  {
    "text": "And the black one\nis f theta of x. So the quadratic\nexpansion is very",
    "start": "1428550",
    "end": "1433649"
  },
  {
    "text": "close to the\noriginal expansion-- sorry, the original function.",
    "start": "1433650",
    "end": "1438690"
  },
  {
    "text": "And second, you want\nthat it suffices to optimize here, right? Because if both the red\nand the black curve,",
    "start": "1438690",
    "end": "1446440"
  },
  {
    "text": "even though they are close,\nif they are both very high, it doesn't make sense to\nzoom into this region, right?",
    "start": "1446440",
    "end": "1451920"
  },
  {
    "text": "You should leave this region. But you can say that it\nsuffices to optimize here in terms of following sense.",
    "start": "1451920",
    "end": "1460540"
  },
  {
    "text": "So there exists an\napproximate global min theta",
    "start": "1460540",
    "end": "1468390"
  },
  {
    "text": "hat in B theta 0. ",
    "start": "1468390",
    "end": "1479060"
  },
  {
    "text": "So I'm using the\nsuperscript for the 0, which might be a mistake. But let me\nconsistently use that.",
    "start": "1479060",
    "end": "1487720"
  },
  {
    "text": " I think in some other lectures\nI use superscript for time.",
    "start": "1487720",
    "end": "1494060"
  },
  {
    "text": "So that's why I keep using\nsuperscript for time. Anyway, so you want to\nhave a theta hat such",
    "start": "1494060",
    "end": "1500470"
  },
  {
    "text": "that it's global min. And actually, here,\nyou want that L hat g theta hat to be\napproximately 0.",
    "start": "1500470",
    "end": "1508510"
  },
  {
    "text": "And this indicates\nthat you are global min because 0 is the minimum. There is no way\nyou can go below 0.",
    "start": "1508510",
    "end": "1516610"
  },
  {
    "text": "So if you are close\nto 0, it means you have to be\nclose to global min. And this also implies that L\nhat f theta hat is close to 0.",
    "start": "1516610",
    "end": "1528559"
  },
  {
    "text": " But with these two,\nwe still don't really",
    "start": "1528560",
    "end": "1534650"
  },
  {
    "text": "understand how do we optimize\nthe black curve, right? So you also want to know\nthat optimizing this loss L",
    "start": "1534650",
    "end": "1545390"
  },
  {
    "text": "hat f theta is similar to\noptimizing L hat g theta.",
    "start": "1545390",
    "end": "1555790"
  },
  {
    "start": "1555790",
    "end": "1561870"
  },
  {
    "text": "And not only this, but also-- and does not leave B theta 0.",
    "start": "1561870",
    "end": "1573870"
  },
  {
    "text": "Because if you leave B\ntheta 0, then all bets are off your Taylor\nexpansion breaks. So you have to say that,\nwhen optimize, either the L",
    "start": "1573870",
    "end": "1581880"
  },
  {
    "text": "hat f or the L hat g, I\ndon't leave this region. So everything is\nconfined to this region.",
    "start": "1581880",
    "end": "1588520"
  },
  {
    "text": "And so this is how\nwe make it work. Of course, you can ask whether\nthis is really reflecting",
    "start": "1588520",
    "end": "1595230"
  },
  {
    "text": "what happens in reality. The answer is no, not always. But so far, we are just\ntrying to make this work",
    "start": "1595230",
    "end": "1602940"
  },
  {
    "text": "under certain cases, so\nthat we can appreciate why",
    "start": "1602940",
    "end": "1608159"
  },
  {
    "text": "we have to improve this way. So in some sense, 3 is kind of\na little bit like extension.",
    "start": "1608160",
    "end": "1614520"
  },
  {
    "text": "So 3, to some extent,\nfollows from 1, 2.",
    "start": "1614520",
    "end": "1623690"
  },
  {
    "text": "Because if you have a global\nminimum in this region, right, and the black and red are\nclose, then why optimizing it?",
    "start": "1623690",
    "end": "1631517"
  },
  {
    "text": "Optimizing probably\nshould converge to that global minimum, and\nyou should stay in that region.",
    "start": "1631517",
    "end": "1636530"
  },
  {
    "text": "To some extent, it\nfollows 1, 2, but not",
    "start": "1636530",
    "end": "1642640"
  },
  {
    "text": "exactly technically, but\nstill requires a formal proof. ",
    "start": "1642640",
    "end": "1652110"
  },
  {
    "text": "So what I'm saying is that,\nif you really just want something somewhat informal\nto think about the dependency,",
    "start": "1652110",
    "end": "1657500"
  },
  {
    "text": "then probably you only\nhave to first make sure 1, 2 is happening. But if you really\nwant everything,",
    "start": "1657500",
    "end": "1664880"
  },
  {
    "text": "then you need to\nprove the three. ",
    "start": "1664880",
    "end": "1670860"
  },
  {
    "text": "And 1, 2, 3, you\ncan make this work, can be all true in\nvarious settings",
    "start": "1670860",
    "end": "1679410"
  },
  {
    "text": "with either over\nparameterization",
    "start": "1679410",
    "end": "1688728"
  },
  {
    "text": "and/or some particular\nscaling of the initialization.",
    "start": "1688728",
    "end": "1699900"
  },
  {
    "text": "So if you play with\nthe initialization or you play with the\nwidth, and also, you",
    "start": "1699900",
    "end": "1708860"
  },
  {
    "text": "need small stochasticity, even\nsmall or even 0 stochasticity.",
    "start": "1708860",
    "end": "1716530"
  },
  {
    "start": "1716530",
    "end": "1722770"
  },
  {
    "text": "So if you play with the\noverparameterization and scaling of\nthe initialization and also insist that there's\nno stochasticity that",
    "start": "1722770",
    "end": "1729370"
  },
  {
    "text": "make you leave or go very far-- because the\nstochasticity will let you leave the\nlocal neighborhood.",
    "start": "1729370",
    "end": "1736570"
  },
  {
    "text": "So that's why you want\nsmall stochasticity. So then you can\nachieve all of this.",
    "start": "1736570",
    "end": "1741575"
  },
  {
    "text": "And how do you get\nsmall stochasticity? In a nutshell, you\neither need by--",
    "start": "1741575",
    "end": "1746649"
  },
  {
    "text": "so to get small\nstochasticity, you need to either do smaller linear\nrate or full batch gradient",
    "start": "1746650",
    "end": "1754796"
  },
  {
    "text": "descent.  So in some sense, this\nis the limitation, right?",
    "start": "1754796",
    "end": "1761320"
  },
  {
    "text": "So this is the limitation\nbecause you require this. And this is the also\nlimitation because you have to play with it.",
    "start": "1761320",
    "end": "1766710"
  },
  {
    "text": "You cannot just say-- and what you really\neventually get is probably not exactly matching\nwhat people do in practice.",
    "start": "1766710",
    "end": "1777200"
  },
  {
    "text": "OK, cool. So now, let's see\nhow do we do 1, 2.",
    "start": "1777200",
    "end": "1782580"
  },
  {
    "text": "But still, regardless\nof all the limitations, still this is kind of\nan interesting approach.",
    "start": "1782580",
    "end": "1789210"
  },
  {
    "text": "It's kind of surprising that\nsuch a region even exists. Even you think about\nthe 1, two2 right, so you don't care about\nany limitations of it.",
    "start": "1789210",
    "end": "1795600"
  },
  {
    "text": "It's still kind of interesting\nthat there exists such region that you can basically be close\nto a convex function, actually",
    "start": "1795600",
    "end": "1801510"
  },
  {
    "text": "a quadratic function if the\nloss is quadratic, right? And there's still\na global minimum.",
    "start": "1801510",
    "end": "1807180"
  },
  {
    "text": "It suggests that there's\na lot of flexibilities in this landscape of\nneural networks, right? So when you have a lot\nof overparameterizations",
    "start": "1807180",
    "end": "1815250"
  },
  {
    "text": "and nonconvexity, then\nsomewhere you have to have a convex region, right?",
    "start": "1815250",
    "end": "1820677"
  },
  {
    "text": "So that's basically\nwhat it's saying, right? So in this landscape\nglobally, it's very nonconvex,\nvery complicated.",
    "start": "1820677",
    "end": "1826470"
  },
  {
    "text": "But at some special places\nin some neighborhoods, you are really having\na convex function.",
    "start": "1826470",
    "end": "1831990"
  },
  {
    "text": "And that convex function has\na global minimum, which is 0. So even this is still\nsomewhat surprising.",
    "start": "1831990",
    "end": "1839740"
  },
  {
    "text": "OK. So now, let's try to\nformalize 1 and 2.",
    "start": "1839740",
    "end": "1846304"
  },
  {
    "text": " And then we talk about 3.",
    "start": "1846305",
    "end": "1851440"
  },
  {
    "text": "So how do we do this? So let's introduce\nsome notation. Let phi i to be the\nphi of xi, the features",
    "start": "1851440",
    "end": "1863110"
  },
  {
    "text": "for the i-th example,\nwhich is really this. ",
    "start": "1863110",
    "end": "1869680"
  },
  {
    "text": "And I defined this feature\nmatrix to be phi n transpose.",
    "start": "1869680",
    "end": "1886410"
  },
  {
    "text": "You put all the features\nin a row in this n by p where p is the\nnumber of parameters.",
    "start": "1886410",
    "end": "1893789"
  },
  {
    "text": " So now, we can see that the\nloss functions with respect",
    "start": "1893790",
    "end": "1905309"
  },
  {
    "text": "to the linear model is\njust the linear regression problem, which you are\nprobably familiar with.",
    "start": "1905310",
    "end": "1911160"
  },
  {
    "text": "And I'm taking quadratic\nloss or mean square loss.",
    "start": "1911160",
    "end": "1916750"
  },
  {
    "text": " So this is just the yi minus\ndelta theta transpose times phi",
    "start": "1916750",
    "end": "1928080"
  },
  {
    "text": "of xi-- recall that you have basically\nlinear model in delta theta--",
    "start": "1928080",
    "end": "1934200"
  },
  {
    "text": "and squared. All right, so I guess\nmaybe it's easier",
    "start": "1934200",
    "end": "1940880"
  },
  {
    "text": "to write in the other\nway so that it's more consistent with\nthe notation here--",
    "start": "1940880",
    "end": "1947460"
  },
  {
    "text": "transpose delta theta. ",
    "start": "1947460",
    "end": "1954240"
  },
  {
    "text": "So if you write in\nthe matrix notation, this would be 1 over n times\nthe 2-norm of y minus phi times",
    "start": "1954240",
    "end": "1965120"
  },
  {
    "text": "delta theta 2-norm\nsquared where y vec is the concatenation of all\nthe labels, which is the Rn.",
    "start": "1965120",
    "end": "1974558"
  },
  {
    "text": " So this just sounds\nvery familiar",
    "start": "1974558",
    "end": "1979740"
  },
  {
    "text": "with linear regression. It's exactly linear regression\nwhere delta theta is your parameter, phi is your\ndesign matrix or the feature",
    "start": "1979740",
    "end": "1989365"
  },
  {
    "text": "matrix.  And let's assume-- this is\njust for convenience-- yi is",
    "start": "1989365",
    "end": "1997500"
  },
  {
    "text": "on the order of 1. So that's the 2-norm's y is\non the order of square root n.",
    "start": "1997500",
    "end": "2005400"
  },
  {
    "text": "So here's the lemma that kind\nof characterize what is the--",
    "start": "2005400",
    "end": "2010565"
  },
  {
    "text": " I guess, so lemma--",
    "start": "2010565",
    "end": "2016640"
  },
  {
    "text": "this is in sum for two. And sometimes you are trying to\nsee that in what neighborhood",
    "start": "2016640",
    "end": "2022590"
  },
  {
    "text": "you have a global minimum. So suppose p is bigger than n.",
    "start": "2022590",
    "end": "2030270"
  },
  {
    "text": "You have more features and\nthen more theta points. And the rank of this feature\nmatrix, it equals to n.",
    "start": "2030270",
    "end": "2040130"
  },
  {
    "text": "And the minimum\nsingular value is",
    "start": "2040130",
    "end": "2046190"
  },
  {
    "text": "equal to sigma greater than 0.",
    "start": "2046190",
    "end": "2051349"
  },
  {
    "text": "Then let the norm\nsolutions to y hat to this.",
    "start": "2051350",
    "end": "2074564"
  },
  {
    "text": "All right. So you want to fit phi\ndelta theta 2 y vec.",
    "start": "2074564",
    "end": "2080219"
  },
  {
    "text": "And you want to understand what\nis the nearest global minimum, right? So the other thing is this is\nthe nearest global minimum.",
    "start": "2080219",
    "end": "2088710"
  },
  {
    "text": "This is the nearest global\nmin in some sense, right? Because if you fit it, you\nare achieving the global min.",
    "start": "2088710",
    "end": "2096970"
  },
  {
    "text": "And you want delta theta\nhat to be the smallest, so that means you are\nlooking for the nearest one. And if you are looking\nfor the nearest one,",
    "start": "2096970",
    "end": "2103725"
  },
  {
    "text": "then you can have a bound on\nthe nearest global minimum where",
    "start": "2103725",
    "end": "2109040"
  },
  {
    "text": "the bound is something like\nthis, square root and over",
    "start": "2109040",
    "end": "2116520"
  },
  {
    "text": "sigma. So the bound itself, so far,\nis not that interpretable.",
    "start": "2116520",
    "end": "2122370"
  },
  {
    "text": "But the point here\nis that this means",
    "start": "2122370",
    "end": "2128660"
  },
  {
    "text": "that, if you take the ball, B\ntheta 0, to have this radius,",
    "start": "2128660",
    "end": "2135849"
  },
  {
    "text": "to be all the theta\nsuch that this goes theta 0 plus delta theta such\nthat delta theta 2-norm is less",
    "start": "2135850",
    "end": "2146150"
  },
  {
    "text": "than of square root\nn sigma over sigma, then this ball, this B theta,\nwill contain a global minimum.",
    "start": "2146150",
    "end": "2153799"
  },
  {
    "text": "Contains a global minimum. ",
    "start": "2153800",
    "end": "2164220"
  },
  {
    "text": "OK, so this is characterizing\nhow large the ball needs to be, how large the\nregion needs to be,",
    "start": "2164220",
    "end": "2169860"
  },
  {
    "text": "so that it can\ncontain a global min. And a number here, so far the\nnumber is not interpretable.",
    "start": "2169860",
    "end": "2175102"
  },
  {
    "text": "I'm going to compare it\nwith some other things. Because by itself, you\nknow, how large the region? If you just care\nabout 2, then you",
    "start": "2175102",
    "end": "2181853"
  },
  {
    "text": "can just take the region\nto be as large as possible. You have to compare it\nwith something else. And the proof is\nalso pretty easy.",
    "start": "2181853",
    "end": "2188140"
  },
  {
    "text": "This is really just a\nsimple trivial thing. Like you say you can write\ndelta theta hat to be--",
    "start": "2188140",
    "end": "2195720"
  },
  {
    "text": "because you are-- the\nminimum norm solution is the pseudo inverse\nof phi times y vec.",
    "start": "2195720",
    "end": "2204170"
  },
  {
    "text": "And there are some-- I guess, this is not\nextremely obvious, but you can invoke this is some\nrelatively basic properties",
    "start": "2204170",
    "end": "2213550"
  },
  {
    "text": "of the pseudo inverse. You know that the operator\nnorm of a pseudo inverse is less than the minimum\nsingular value of phi.",
    "start": "2213550",
    "end": "2222960"
  },
  {
    "text": "Actually, these are-- I think they're\nexactly the same. ",
    "start": "2222960",
    "end": "2229130"
  },
  {
    "text": "And this is equal\nto 1 over sigma. And then you know\nthat you have a bound",
    "start": "2229130",
    "end": "2235700"
  },
  {
    "text": "on delta theta 2-norm by\nusing the operative form",
    "start": "2235700",
    "end": "2242410"
  },
  {
    "text": "of the pseudo inverse of phi\ntimes the 2-norm of y vec.",
    "start": "2242410",
    "end": "2247940"
  },
  {
    "text": "So this becomes 1 over sigma\ntimes square root of 2. That's it.",
    "start": "2247940",
    "end": "2253710"
  },
  {
    "text": "I guess I don't even need\na big O. I don't know why I have the big O, sorry.",
    "start": "2253710",
    "end": "2259855"
  },
  {
    "text": " Just for me, it's always\nsafe to have big O,",
    "start": "2259855",
    "end": "2266170"
  },
  {
    "text": "so it's just part of my brain. You cannot work with\nwithout big O anyway.",
    "start": "2266170",
    "end": "2271690"
  },
  {
    "text": "But here, you don't need\nanything, any constant. Oh, I guess there's a--",
    "start": "2271690",
    "end": "2277850"
  },
  {
    "text": "I think I need a big\nO because I'm only assuming that y is on the\norder of square root n, sorry.",
    "start": "2277850",
    "end": "2284000"
  },
  {
    "text": "So because here I'm\nonly assuming this is-- y is less than O\nfrom square root n.",
    "start": "2284000",
    "end": "2289460"
  },
  {
    "text": "So that's why I need a big\nO. But anyway, the constant doesn't matter here.",
    "start": "2289460",
    "end": "2295140"
  },
  {
    "text": "You get the points, I guess. OK, so any questions so far?",
    "start": "2295140",
    "end": "2303200"
  },
  {
    "start": "2303200",
    "end": "2311829"
  },
  {
    "text": "So now, let's see\nwhether this region, whether it's too\nbig or too small. It sounds somewhat big\nbecause n is there.",
    "start": "2311830",
    "end": "2318920"
  },
  {
    "text": "But actually, you'll see\nthat the region is not that big because the sigma could\nbe made very big in some sense.",
    "start": "2318920",
    "end": "2326520"
  },
  {
    "text": "Or there are some\nrelative kind of things which you have to compare\nit with something else,",
    "start": "2326520",
    "end": "2331565"
  },
  {
    "text": "right, because you have to\ncompare this with how good you have approximation\nin the region.",
    "start": "2331565",
    "end": "2337710"
  },
  {
    "text": "So next one is for the lemma.  So this is for\none in some sense.",
    "start": "2337710",
    "end": "2346790"
  },
  {
    "text": "So suppose this\nis beta-Lipschitz.",
    "start": "2346790",
    "end": "2356800"
  },
  {
    "text": "Suppose this gradient\nof the network is Lipschitz in theta in\na sense that, for every x,",
    "start": "2356800",
    "end": "2367329"
  },
  {
    "text": "for every theta and theta\nprime, you have this. ",
    "start": "2367330",
    "end": "2375450"
  },
  {
    "text": "So I think this is 0\nbecause we always only care about the gradient at theta 0.",
    "start": "2375450",
    "end": "2381289"
  },
  {
    "text": "You evaluate it at theta 0.  Wait, sorry. My bad, my bad.",
    "start": "2381290",
    "end": "2388827"
  },
  {
    "text": "Sorry, my bad. OK. So here, what I'm writing here,\nthis is a function of theta",
    "start": "2388827",
    "end": "2394440"
  },
  {
    "text": "because I evaluate at some\narbitrary theta, let's say. So I want this as a function of\ntheta to be Lipschitz in theta.",
    "start": "2394440",
    "end": "2402700"
  },
  {
    "text": "So that means that, if you\nchoose two different place where either theta\nor theta prime,",
    "start": "2402700",
    "end": "2409050"
  },
  {
    "text": "the differences between\nthem is L2-norm. I have to use our L2-norm\nhere because they are vectors.",
    "start": "2409050",
    "end": "2416099"
  },
  {
    "text": "And you want to\nsay that L2-norm is bounded by the differences\nin the theta space.",
    "start": "2416100",
    "end": "2423830"
  },
  {
    "text": "So if you have this, then we\nknow that, after the x minus g",
    "start": "2423830",
    "end": "2430585"
  },
  {
    "text": "theta x, your approximation is\nless than big O of beta times",
    "start": "2430585",
    "end": "2438500"
  },
  {
    "text": "the difference on the delta\ntheta, 2-norm squared.",
    "start": "2438500",
    "end": "2445410"
  },
  {
    "text": "Because the difference between\nthese two is basically, in some sense, depends\non how far you are away from the reference point.",
    "start": "2445410",
    "end": "2451650"
  },
  {
    "text": "The reference point should\nbe exactly the same. And if you are a little bit more\naway from the reference point,",
    "start": "2451650",
    "end": "2456990"
  },
  {
    "text": "then you're going\nto incur some loss. And the loss is something\non the second order. That's also intuitive.",
    "start": "2456990",
    "end": "2464280"
  },
  {
    "text": "So the important thing is that,\nfor every theta in the B theta",
    "start": "2464280",
    "end": "2469970"
  },
  {
    "text": "0 that we just defined, we have\nthat f theta x minus g theta x",
    "start": "2469970",
    "end": "2480320"
  },
  {
    "text": "is less than beta n\nsquared over sigma squared. And that's just by plugging in\nthe definition of B theta 0.",
    "start": "2480320",
    "end": "2487790"
  },
  {
    "text": "The B theta 0 has this radius. square root n over sigma.",
    "start": "2487790",
    "end": "2493530"
  },
  {
    "text": "And you plug it\nin into this here.  So you plug in this here.",
    "start": "2493530",
    "end": "2500370"
  },
  {
    "text": "You get that in this\nregion, you have some bound on how good\nyour approximation is.",
    "start": "2500370",
    "end": "2507200"
  },
  {
    "text": "So-- Is that for beta n? Oh, sorry. Let's try this beta n, my bad.",
    "start": "2507200",
    "end": "2513030"
  },
  {
    "text": "It's just a copy\npasting error, OK-- yeah, beta n squared.",
    "start": "2513030",
    "end": "2520190"
  },
  {
    "text": "OK, so far this bound-- ",
    "start": "2520190",
    "end": "2529380"
  },
  {
    "text": "so I saw a question. By the way, you can\nfeel free to unmute, but I can read the question now.",
    "start": "2529380",
    "end": "2534690"
  },
  {
    "text": "So how do we define\nphi superscript plus?",
    "start": "2534690",
    "end": "2539760"
  },
  {
    "text": "Oh, this is the-- so what is this phi plus? This is the pseudo\ninverse of phi.",
    "start": "2539760",
    "end": "2553470"
  },
  {
    "text": "I think this is called-- there's actually-- this is\nthe most common definition",
    "start": "2553470",
    "end": "2560040"
  },
  {
    "text": "of pseudo inverse of phi. I guess you can roughly think\nof as the inverse of phi",
    "start": "2560040",
    "end": "2569310"
  },
  {
    "text": "with some small caveat. Yes, more tangential\nto the inverse.",
    "start": "2569310",
    "end": "2576450"
  },
  {
    "text": "Thanks for the\ncomments in the chat. ",
    "start": "2576450",
    "end": "2582020"
  },
  {
    "text": "I think this is supposed to be\ntaught in the linear algebra course maybe. I don't know.",
    "start": "2582020",
    "end": "2587690"
  },
  {
    "text": "I'm not sure what\nI can say about it. What you know about it is\nthat, at least in this case,",
    "start": "2587690",
    "end": "2598900"
  },
  {
    "text": "I think maybe just for\nthe sake of simplicity, just think of the pseudo\ninverse as the inverse",
    "start": "2598900",
    "end": "2605680"
  },
  {
    "text": "if you are not super\nfamiliar with it. And then you can verify\nthis is a good solution",
    "start": "2605680",
    "end": "2612070"
  },
  {
    "text": "to this equation, right? Because if you multiply to\nthe inverse, you get this.",
    "start": "2612070",
    "end": "2617710"
  },
  {
    "text": "So the inverse cancels with\nphi, and you get delta theta. Sorry.",
    "start": "2617710",
    "end": "2624230"
  },
  {
    "text": "So you plug in this delta\ntheta to this equation. You can cancel phi and phi to\nthe inverse, and you get y vec.",
    "start": "2624230",
    "end": "2630500"
  },
  {
    "text": "That's how you verify this is\na solution to the equation.",
    "start": "2630500",
    "end": "2636545"
  },
  {
    "start": "2636545",
    "end": "2641839"
  },
  {
    "text": "And also, I think another\nuseful thing to know is that the pseudo inverse\nhas exactly the same--",
    "start": "2641840",
    "end": "2647640"
  },
  {
    "text": "it has the inverse of the\nspectrum of the original one, right? So suppose the phi has singular\nvalue sigma 1 up to sigma k.",
    "start": "2647640",
    "end": "2658320"
  },
  {
    "text": "And then the pseudo inverse\nhas singular value 1",
    "start": "2658320",
    "end": "2667560"
  },
  {
    "text": "over sigma 1 up\nto 1 over sigma k. ",
    "start": "2667560",
    "end": "2672980"
  },
  {
    "text": "And this, you know, if all\nthe sigmas are positive, right, you ignore the\n0 singular values,",
    "start": "2672980",
    "end": "2678589"
  },
  {
    "text": "then this is exactly true. So the singular values are\njust typically inverted.",
    "start": "2678590",
    "end": "2684550"
  },
  {
    "text": "OK, cool. So I hope that\nanswers the question. OK, going back to the\nsecond lemma for number one,",
    "start": "2684550",
    "end": "2691869"
  },
  {
    "text": "so this is saying that, in\nthis neighborhood, how good your approximation is, right? So we got this number.",
    "start": "2691870",
    "end": "2699770"
  },
  {
    "text": "So I'm going to\nexplain this number. That's the important thing. So how small is this? If this is small, that's great.",
    "start": "2699770",
    "end": "2705760"
  },
  {
    "text": "If this is big,\nthat's a problem. But maybe let me just say\nthe proof of this lemma.",
    "start": "2705760",
    "end": "2711310"
  },
  {
    "text": "The proof of the lemma\nis kind of basically this follows the basic\nfact that, from the fact",
    "start": "2711310",
    "end": "2720450"
  },
  {
    "text": "that, if you have h theta\nsatisfies gradient of h theta",
    "start": "2720450",
    "end": "2731244"
  },
  {
    "text": "is Lipschitz.  And this gradient\nof h Lipschitz is",
    "start": "2731245",
    "end": "2737240"
  },
  {
    "text": "basically equivalent\nto the Hessian and operator norm\nis bound by beta.",
    "start": "2737240",
    "end": "2745330"
  },
  {
    "text": "If everything is\ndifferentiable, then you know you can bound the\ninequality of the Taylor",
    "start": "2745330",
    "end": "2750910"
  },
  {
    "text": "expansion. So you can say that g theta\nminus g theta-- h theta",
    "start": "2750910",
    "end": "2757024"
  },
  {
    "text": "0 minus gradient h theta\n0 theta theta 0, this",
    "start": "2757024",
    "end": "2764990"
  },
  {
    "text": "is bounded by O of beta theta\nminus theta 0 2-norm squared.",
    "start": "2764990",
    "end": "2773650"
  },
  {
    "text": "And this h theta will\nbe just f theta x. In our case, if you take\nh theta to be f theta x,",
    "start": "2773650",
    "end": "2780580"
  },
  {
    "text": "then you get the lemma above.",
    "start": "2780580",
    "end": "2785670"
  },
  {
    "text": "So the point is your\napproximation error is second order in\nthe order of theta,",
    "start": "2785670",
    "end": "2792120"
  },
  {
    "text": "in the difference between your\npoint and the reference point. ",
    "start": "2792120",
    "end": "2799750"
  },
  {
    "text": "OK. And there's a small remark. Another small remark is that,\nif the f theta involves ReLU,",
    "start": "2799750",
    "end": "2812549"
  },
  {
    "text": "then nabla f theta is\nnot even continuous. ",
    "start": "2812550",
    "end": "2819960"
  },
  {
    "text": "So it cannot be\nLipschitz everywhere. ",
    "start": "2819960",
    "end": "2827820"
  },
  {
    "text": "And this requires\nsome special fix. So it requires special fixes.",
    "start": "2827820",
    "end": "2835500"
  },
  {
    "text": "The fixes is not that surprising\njust because-- and even though it's not\ncontinuous everywhere,",
    "start": "2835500",
    "end": "2841410"
  },
  {
    "text": "it's still continuous\nalmost everywhere. So basically, it's kind\nof close to be Lipschitz. And in some sense, L\nf theta x is still--",
    "start": "2841410",
    "end": "2849647"
  },
  {
    "text": "like, if you look at the\naverage over data points, then you still have\nsome Lipschitzness. But I think let's\nnot discuss that.",
    "start": "2849647",
    "end": "2855390"
  },
  {
    "text": "It's a little bit\nkind of like low level details which is not important. We can just assume we are\ndealing with not ReLU.",
    "start": "2855390",
    "end": "2863258"
  },
  {
    "text": "We are dealing with\nsomething like sigmoid, then there is no such issue.",
    "start": "2863258",
    "end": "2868460"
  },
  {
    "text": "OK, cool. So now, let's go back to\nthe main thing, right? So the main thing is whether\nthis is a good bound, right?",
    "start": "2868460",
    "end": "2874160"
  },
  {
    "text": "So you say that you have\nfound the B theta 0. And you have showed\nthat, in this B theta 0,",
    "start": "2874160",
    "end": "2879600"
  },
  {
    "text": "you have such an\napproximation error. So important fact is that what\nis this beta n sigma squared.",
    "start": "2879600",
    "end": "2886640"
  },
  {
    "text": "Is this small or big? And the important\nthing is that-- so the interesting thing\nis that this thing is not",
    "start": "2886640",
    "end": "2897210"
  },
  {
    "text": "scaling invariant. So n is something you\ncannot change, right? But beta over sigma is\nnot scaling invariant.",
    "start": "2897210",
    "end": "2907740"
  },
  {
    "text": "So what does that mean? I think you can interpret\nthis in some way.",
    "start": "2907740",
    "end": "2914240"
  },
  {
    "text": "But in some sense, that beta-- basically, I think\nthe easiest way to think about is that\nyou have a square, and below it you have\nbeta, the beta on top.",
    "start": "2914240",
    "end": "2925190"
  },
  {
    "text": "So somehow you can\nplay with the scaling to make this going to 0. So there are two cases.",
    "start": "2925190",
    "end": "2931422"
  },
  {
    "text": "Actually, there are\nmore than two cases, but I'm going to\ndiscuss two cases. These are different\npapers, but I'm",
    "start": "2931423",
    "end": "2936851"
  },
  {
    "text": "going to unify them\nin the following way. So there are two cases where\nbeta over sigma squared",
    "start": "2936852",
    "end": "2942780"
  },
  {
    "text": "can go to 0. So the first way is that you can\nreparameterize with a scalar.",
    "start": "2942780",
    "end": "2956000"
  },
  {
    "text": "And this is in Chizat and Bach. ",
    "start": "2956000",
    "end": "2963480"
  },
  {
    "text": "I think this is '19. And the paper is called Lazy\nTraining of Neural Network,",
    "start": "2963480",
    "end": "2969850"
  },
  {
    "text": "something like that. So I guess the\npaper title suggests that they're saying that this\nis a lazy way of training",
    "start": "2969850",
    "end": "2977210"
  },
  {
    "text": "networks. It's not really the final\nway you should leave it. But nevertheless, the\npaper is very nice.",
    "start": "2977210",
    "end": "2983980"
  },
  {
    "text": "And what they do\nis the following. So they say that so let your f\ntheta x, your parameterization,",
    "start": "2983980",
    "end": "2995170"
  },
  {
    "text": "to be the following. You take alpha times,\nlet's say, f theta bar x.",
    "start": "2995170",
    "end": "3001780"
  },
  {
    "text": "And this, let's\nmake this a fixed-- actually, this is a standard\nneural network and fixed,",
    "start": "3001780",
    "end": "3014675"
  },
  {
    "text": "fixed in the sense\nthat you don't change the architecture, right? You just take whatever standard\nnetwork with any finite width,",
    "start": "3014675",
    "end": "3020836"
  },
  {
    "text": "with fixed width and\ndepth, so and so forth,",
    "start": "3020836",
    "end": "3030720"
  },
  {
    "text": "right, something that\nyou don't change. And it's for this perspective. And you only change alpha.",
    "start": "3030720",
    "end": "3036680"
  },
  {
    "text": "So for every alpha you define\nperfect, it's a valid network. It's just you have a different\nscaling in front of it.",
    "start": "3036680",
    "end": "3042890"
  },
  {
    "text": "So for every alpha, you\ngot a neural network. And then let's see how does\neverything change as you",
    "start": "3042890",
    "end": "3048020"
  },
  {
    "text": "change alpha. And also, you fix\ninitialization, scheme theta 0.",
    "start": "3048020",
    "end": "3056130"
  },
  {
    "text": "And then let's consider, let's\nsay, sigma bar is the sigma",
    "start": "3056130",
    "end": "3061170"
  },
  {
    "text": "mean of the base network. Let's say the base network\nis the f bar theta.",
    "start": "3061170",
    "end": "3067680"
  },
  {
    "text": "So it's the sigma\nmean of this base 1. ",
    "start": "3067680",
    "end": "3081730"
  },
  {
    "text": "This is the-- right? And let beta bar be the\nLipschitzness also of the base",
    "start": "3081730",
    "end": "3090839"
  },
  {
    "text": "1. ",
    "start": "3090840",
    "end": "3096470"
  },
  {
    "text": "So you can think of sigma\nbar and beta bar are not changing as you change alpha.",
    "start": "3096470",
    "end": "3103390"
  },
  {
    "text": "And now, let's see how does the\nalpha change the final sigma and beta of your final network.",
    "start": "3103390",
    "end": "3109045"
  },
  {
    "text": " So sigma is equal\nto alpha sigma bar.",
    "start": "3109045",
    "end": "3115250"
  },
  {
    "text": "Because once you have\nconsidered f theta, you multiply this alpha. So all the features,\nright, like the gradient,",
    "start": "3115250",
    "end": "3122119"
  },
  {
    "text": "becomes alpha times bigger. And everything becomes\nalpha times bigger, right?",
    "start": "3122120",
    "end": "3127360"
  },
  {
    "text": "So this is just\nbecause, when you take the gradient with respect to--",
    "start": "3127360",
    "end": "3133270"
  },
  {
    "text": "this is just\nbecause of 2, right? So if you take gradient with\nrespect to theta of the f, it's the same as alpha times the\ngradient of theta with respect",
    "start": "3133270",
    "end": "3141470"
  },
  {
    "text": "to--  the gradient of f bar\nwith vector theta, right?",
    "start": "3141470",
    "end": "3147470"
  },
  {
    "text": "So you have a chain rule. So everything got scaled. And beta also got\nscaled by alpha",
    "start": "3147470",
    "end": "3154089"
  },
  {
    "text": "just because the gradient got\nscaled for the same reason. And then you can see that\nyou get for free some factor",
    "start": "3154090",
    "end": "3160779"
  },
  {
    "text": "about alpha in this equation. So beta over sigma squared\nbecomes beta bar over sigma bar",
    "start": "3160780",
    "end": "3166990"
  },
  {
    "text": "squared times 1 over alpha. And this can go to 0 as\nalpha goes to infinity.",
    "start": "3166990",
    "end": "3173230"
  },
  {
    "text": " So basically, they're saying\nthat whatever network you take,",
    "start": "3173230",
    "end": "3179660"
  },
  {
    "text": "whatever initialization, as long\nas your sigma bar and beta bar they are reasonable and they are\nnot 0 or something like that--",
    "start": "3179660",
    "end": "3189380"
  },
  {
    "text": "and now, sigma bar is not 0. So you have some beta bar\nover sigma bar squared. That might be bad.",
    "start": "3189380",
    "end": "3195030"
  },
  {
    "text": "But you can always\nrescale, reparameterize it, with a constant\nin front of it so that this key quantity,\nbeta sigma squared,",
    "start": "3195030",
    "end": "3203420"
  },
  {
    "text": "becomes going to 0. And if this goes to\n0, what does it mean? It means that your approximation\nbecomes better and better.",
    "start": "3203420",
    "end": "3210560"
  },
  {
    "text": "And at some point, if you\nchange your alpha large enough, you make this approximation\nsuper good, right?",
    "start": "3210560",
    "end": "3216440"
  },
  {
    "text": " So basically, you found\nthe neighborhood such",
    "start": "3216440",
    "end": "3221809"
  },
  {
    "text": "that, in that neighborhood,\nyour approximation is very good if you take alpha to be big. ",
    "start": "3221810",
    "end": "3229840"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "3229840",
    "end": "3236166"
  },
  {
    "text": "No, the loss wouldn't\nchange, right? That's a good question. The loss, what is the loss?",
    "start": "3236166",
    "end": "3241530"
  },
  {
    "text": "The loss is something\ncomposed with-- composed on top of\nthis network, right?",
    "start": "3241530",
    "end": "3247720"
  },
  {
    "text": "So the loss is L of-- for example, alpha f\nbar theta x, y, right?",
    "start": "3247720",
    "end": "3255840"
  },
  {
    "text": " So first of all, at\ninitialization, we always",
    "start": "3255840",
    "end": "3262630"
  },
  {
    "text": "try to make the initialization\n0, the output at initialization 0. So that wouldn't change.",
    "start": "3262630",
    "end": "3267970"
  },
  {
    "text": "And second, even though\nseemingly this whole thing",
    "start": "3267970",
    "end": "3273060"
  },
  {
    "text": "is big-- sure, that's true. But we show that you\nhave a global minimum",
    "start": "3273060",
    "end": "3278820"
  },
  {
    "text": "where this B in\nthis neighborhood you have a global minimum. ",
    "start": "3278820",
    "end": "3287145"
  },
  {
    "text": "I'm not sure whether\nthat makes sense. ",
    "start": "3287145",
    "end": "3298395"
  },
  {
    "text": "So in some sense, I think-- OK, let me try to draw a\nfigure to answer this question. So the question is what\nhappens-- when alpha is big,",
    "start": "3298395",
    "end": "3304890"
  },
  {
    "text": "it sounds like function\nvalue becomes big, right? So that's true. But I think what happens is\nthat, for example, suppose",
    "start": "3304890",
    "end": "3315970"
  },
  {
    "text": "you have-- ",
    "start": "3315970",
    "end": "3322050"
  },
  {
    "text": "not sure. ",
    "start": "3322050",
    "end": "3327450"
  },
  {
    "text": "So how do I visualize this? ",
    "start": "3327450",
    "end": "3334400"
  },
  {
    "text": "I think your loss will be--\nso if you stretch alpha, your loss will be sharper. ",
    "start": "3334400",
    "end": "3340610"
  },
  {
    "text": "So if you look at everything,\nyou look at dependency on alpha, so if you\nmake alpha bigger,",
    "start": "3340610",
    "end": "3346730"
  },
  {
    "text": "you make this neighborhood\nsmaller, right? So you make the\nneighborhood smaller.",
    "start": "3346730",
    "end": "3352310"
  },
  {
    "text": "So you're going to get\nsomething like this, very sharp in the neighborhood. ",
    "start": "3352310",
    "end": "3364202"
  },
  {
    "text": "So if alpha is\nbigger, actually you can find even something that\nis very close by to make the--",
    "start": "3364202",
    "end": "3371700"
  },
  {
    "text": "so you have to even move even\nless from initialization.",
    "start": "3371700",
    "end": "3378700"
  },
  {
    "text": "That's because, if you\ndo a little bit of work, then you actually already\nkind of already fit the data.",
    "start": "3378700",
    "end": "3385930"
  },
  {
    "text": " I'm not sure whether\nthat makes sense.",
    "start": "3385930",
    "end": "3391880"
  },
  {
    "text": "OK, so there's always one\nthing which is useful, which is, the f\ntheta 0 x, this is 0.",
    "start": "3391880",
    "end": "3397529"
  },
  {
    "text": "So basically, you always\nstart with this where you don't have any scale, right?",
    "start": "3397530",
    "end": "3404140"
  },
  {
    "text": "So this is just literally 0. And if alpha is big, then\nthis is still 0, right?",
    "start": "3404140",
    "end": "3410550"
  },
  {
    "text": "But when alpha is big, you are\nmore sensitive to theta, right? So that's why, if you\nchange a little bit, then",
    "start": "3410550",
    "end": "3416755"
  },
  {
    "text": "you can already fit your data.  So you only have to change very,\nvery little from the theta 0",
    "start": "3416755",
    "end": "3425040"
  },
  {
    "text": "to fit your data. And when you change\nvery little, then",
    "start": "3425040",
    "end": "3431040"
  },
  {
    "text": "actually your approximation is\nvery good in that neighborhood. ",
    "start": "3431040",
    "end": "3440070"
  },
  {
    "text": "I'm not sure whether\nthat makes some sense, but maybe you can discuss. It's a little bit confusing.",
    "start": "3440070",
    "end": "3445349"
  },
  {
    "text": "I agree, right? It's just really because the\nonly thing that happens here is how does this\nbeta and sigma--",
    "start": "3445350",
    "end": "3452980"
  },
  {
    "text": "the relative difference\nbetween beta and sigma, how does that depend\non alpha, right? ",
    "start": "3452980",
    "end": "3460410"
  },
  {
    "text": "So in some sense, if\nyou have larger alpha, you need to have\nsmaller neighborhood.",
    "start": "3460410",
    "end": "3465750"
  },
  {
    "start": "3465750",
    "end": "3470870"
  },
  {
    "text": "But the approximation\nerrors scales faster because your function\nis kind of much kind",
    "start": "3470870",
    "end": "3477800"
  },
  {
    "text": "of more nonsmooth, right? So your function\nbecomes sharper.",
    "start": "3477800",
    "end": "3483500"
  },
  {
    "text": "But actually, the\nneighborhood shrinks faster than the sharpness grows.",
    "start": "3483500",
    "end": "3490860"
  },
  {
    "text": "So that's why it's working. Yeah.",
    "start": "3490860",
    "end": "3496069"
  },
  {
    "text": "I hope that somewhat\nanswers the question, right? But generally, this is kind\nof somewhat kind of confusing.",
    "start": "3496070",
    "end": "3503480"
  },
  {
    "text": "And there's another case\nwhere we can also see this. So the other case is if\nyou overparameterize.",
    "start": "3503480",
    "end": "3511492"
  },
  {
    "start": "3511492",
    "end": "3520940"
  },
  {
    "text": "So here, let's say, suppose-- this is actually the original\nfirst few papers which",
    "start": "3520940",
    "end": "3530900"
  },
  {
    "text": "invites the NTK approach take. So basically, what\nyou do is you say",
    "start": "3530900",
    "end": "3537410"
  },
  {
    "text": "you have a model y hat, which is\nequal to 1 over square m times",
    "start": "3537410",
    "end": "3543680"
  },
  {
    "text": "sum of ai sigma wi transpose x. This is a two-layer\nnetwork with m neurals.",
    "start": "3543680",
    "end": "3550490"
  },
  {
    "text": "And I'm scaling this\njust in some sense mostly for convenience.",
    "start": "3550490",
    "end": "3556740"
  },
  {
    "text": "Because whatever\nscale you do, you can also change other\nscales to compensate. And the convenience\ncome from that,",
    "start": "3556740",
    "end": "3564089"
  },
  {
    "text": "if I choose everything\non order of 1, then this will output something\non the order of 1, which",
    "start": "3564090",
    "end": "3569620"
  },
  {
    "text": "you will see. But maybe let's discuss\nthat in a moment after I introduce the notation.",
    "start": "3569620",
    "end": "3575140"
  },
  {
    "text": "So I'm going to have this matrix\nw, which contains all the rows. And W is in m by d.",
    "start": "3575140",
    "end": "3585930"
  },
  {
    "text": "And sigma is ReLU here. I guess, well, maybe let's\nnot say sigma squared.",
    "start": "3585930",
    "end": "3594089"
  },
  {
    "text": "Sigma is something\nlike it's 1-Lipschitz.",
    "start": "3594090",
    "end": "3599810"
  },
  {
    "text": " And it has second\norder derivative. Second order derivative. Actually, yeah.",
    "start": "3599810",
    "end": "3605375"
  },
  {
    "start": "3605375",
    "end": "3614200"
  },
  {
    "text": "So you wouldn't see how those\ncome into play explicitly.",
    "start": "3614200",
    "end": "3619780"
  },
  {
    "text": "They're not super important. And what is initialization? This ai 0-- so actually\nai is initialized",
    "start": "3619780",
    "end": "3627820"
  },
  {
    "text": "to be plus 1 minus 1 initially\nand not optimized at all.",
    "start": "3627820",
    "end": "3638580"
  },
  {
    "text": "So they are not even parameters,\ntechnically speaking. And wi is a parameter.",
    "start": "3638580",
    "end": "3644240"
  },
  {
    "text": "w0 is initialized from Gaussian. A d-dimensional Gaussian\nwith spherical co-variance.",
    "start": "3644240",
    "end": "3652720"
  },
  {
    "text": "And let's say x has the norm\nnorm of x is on the order of 1.",
    "start": "3652720",
    "end": "3659040"
  },
  {
    "text": "It's on the order of 1.  This is just for convenience,\nso that we have a fixed scaling.",
    "start": "3659040",
    "end": "3668260"
  },
  {
    "text": "And let's say theta--",
    "start": "3668260",
    "end": "3674380"
  },
  {
    "text": "so the parameter theta is\nreally just a vector version.",
    "start": "3674380",
    "end": "3680230"
  },
  {
    "text": "d times m is just really\na vectorized version of w. So vectorized version of w, OK? ",
    "start": "3680230",
    "end": "3693369"
  },
  {
    "text": "And so we'll assume\nm goes to infinity.",
    "start": "3693370",
    "end": "3703980"
  },
  {
    "text": "So m is eventually\ntechnically poly, and then d.",
    "start": "3703980",
    "end": "3709740"
  },
  {
    "text": "So a and d are\nconsidered to be fixed, and m is something that will\nbecome bigger and bigger.",
    "start": "3709740",
    "end": "3714930"
  },
  {
    "text": "And that's the power. So everything comes\nfrom the scaling of m.",
    "start": "3714930",
    "end": "3720170"
  },
  {
    "text": "So I guess, just\nto explain why we want to have this 1\nover square root m and a initialization scale\nlike this, so scaling--",
    "start": "3720170",
    "end": "3729690"
  },
  {
    "text": "and I think the reason,\nat least one reason, is that, if you look at this,\nso sigma wi 0 transpose x,",
    "start": "3729690",
    "end": "3739080"
  },
  {
    "text": "this is on order of 1.  Because wi is a spherical\nGaussian and x has norm 1,",
    "start": "3739080",
    "end": "3748240"
  },
  {
    "text": "a spherical Gaussian\ntimes a norm 1 thing will have expectations that\nwill roughly be on order of 1.",
    "start": "3748240",
    "end": "3754420"
  },
  {
    "text": "And then you take\nsome value or kind of something like\nvalue sigmoid, then you are going to\nbe on order of 1.",
    "start": "3754420",
    "end": "3760180"
  },
  {
    "text": "And then the sum of this will\nbe on order of square root m,",
    "start": "3760180",
    "end": "3769631"
  },
  {
    "text": "right, because you have m of\nthese things that are somewhat plus 1 minus 1. ",
    "start": "3769632",
    "end": "3777190"
  },
  {
    "text": "And because ai is\nplus 1 minus 1. So you cancel them\nin some sense, and then you get\nsquare root of m. ",
    "start": "3777190",
    "end": "3784750"
  },
  {
    "text": "And that means f theta\n0x is on the order of 1",
    "start": "3784750",
    "end": "3791700"
  },
  {
    "text": "because you'd have another\n1 over squared m in front.",
    "start": "3791700",
    "end": "3797250"
  },
  {
    "text": "So that's one of the reason why\nyou choose this scaling, OK?",
    "start": "3797250",
    "end": "3804810"
  },
  {
    "text": "So initially, our output\nis on the order of 1. And now, let's see how does\nthis sigma and beta depends",
    "start": "3804810",
    "end": "3810750"
  },
  {
    "text": "on all of these quantities. So we hope that this key\nquantity beta over sigma",
    "start": "3810750",
    "end": "3816120"
  },
  {
    "text": "squared to go to 0 as\nm goes to infinity. ",
    "start": "3816120",
    "end": "3823090"
  },
  {
    "text": "So let's first look at a sigma. Sigma is the sigma min of\nthis feature matrix phi.",
    "start": "3823090",
    "end": "3830050"
  },
  {
    "text": " And this is also the\nsame as the sigma",
    "start": "3830050",
    "end": "3836960"
  },
  {
    "text": "min of this phi phi transpose.",
    "start": "3836960",
    "end": "3843849"
  },
  {
    "text": "This is just equality\nbecause phi phi transpose, the spectrum, is just the square\nroot of the spectrum of phi.",
    "start": "3843850",
    "end": "3852730"
  },
  {
    "text": "And what is phi phi transpose? Phi phi transpose is basically\nthis empirical kernel matrix,",
    "start": "3852730",
    "end": "3857740"
  },
  {
    "text": "right? The ij, essentially, is\njust the inner product between two features\nof two examples.",
    "start": "3857740",
    "end": "3866609"
  },
  {
    "start": "3866610",
    "end": "3873557"
  },
  {
    "text": "And let's look at what the\nscaling of this phi phi transpose. So to do that, you have to\nlook at what's the gradient.",
    "start": "3873557",
    "end": "3880600"
  },
  {
    "text": "So let's look at the gradient. So f theta, if you\nlook at the derivative",
    "start": "3880600",
    "end": "3887000"
  },
  {
    "text": "of the output with respect\nto each of these wi, then you can use\nchain rule and then",
    "start": "3887000",
    "end": "3895310"
  },
  {
    "text": "you can get something\nlike this times x.",
    "start": "3895310",
    "end": "3900900"
  },
  {
    "text": "So this is the gradient of every\nneural wi, every vector wi.",
    "start": "3900900",
    "end": "3907529"
  },
  {
    "text": "And that means that, if\nyou look at the gradient, the entire gradient, all the\ngradient of all the vectors",
    "start": "3907530",
    "end": "3917029"
  },
  {
    "text": "if you look at the norm, then\nit's 1 over m times the sum over m of the i transpose\nx times x 2-norm square,",
    "start": "3917030",
    "end": "3928119"
  },
  {
    "text": "which is 1 over m times the\n2-norm of x squared times-- ",
    "start": "3928120",
    "end": "3942510"
  },
  {
    "text": "and what is this? It's kind of hard to know\nexactly what is this, but I think you mostly\ncare about what's the dependency on m, right?",
    "start": "3942510",
    "end": "3950470"
  },
  {
    "text": "So what's the dependency on m? Then this, as m goes to\ninfinity by concentration-- ",
    "start": "3950470",
    "end": "3960630"
  },
  {
    "text": "so as m goes to\ninfinity, this is really just converging to expectation\nbecause this is empirical sum.",
    "start": "3960630",
    "end": "3967170"
  },
  {
    "text": "This is a 1 over m here, right? So sigma prime w\ntranspose x square",
    "start": "3967170",
    "end": "3972962"
  },
  {
    "text": "where w is from the\nspherical Gaussian times the 2-norm of x square,\nwhich is 1 basically, right?",
    "start": "3972962",
    "end": "3983560"
  },
  {
    "text": "And this whole thing\nwill not depend on-- this whole thing will be\nsomething like O of 1.",
    "start": "3983560",
    "end": "3988690"
  },
  {
    "text": "So I guess, to see it's O\n1 maybe it's some somewhat tricky, but at least you\nknow that this is not",
    "start": "3988690",
    "end": "3996040"
  },
  {
    "text": "depending on m. So m is not in this equation.",
    "start": "3996040",
    "end": "4003680"
  },
  {
    "text": "So basically, this is saying\nthat every quantity here, as m",
    "start": "4003680",
    "end": "4011140"
  },
  {
    "text": "going to infinity, the norm\nof this is on order of 1, doesn't change that.\nm goes to infinity.",
    "start": "4011140",
    "end": "4017320"
  },
  {
    "text": "And also, you can\ndo the same thing for the inner product\nof 2, for example.",
    "start": "4017320",
    "end": "4024790"
  },
  {
    "text": " And the same thing\nhappens that, if you",
    "start": "4024790",
    "end": "4029820"
  },
  {
    "text": "look at the inner product,\nit's something like this,",
    "start": "4029820",
    "end": "4043070"
  },
  {
    "text": "I transpose--",
    "start": "4043070",
    "end": "4049030"
  },
  {
    "text": "so this is, I think, technically\nthere should be a 0 here.",
    "start": "4049030",
    "end": "4055410"
  },
  {
    "text": "That is the\ninitialization, prime. ",
    "start": "4055410",
    "end": "4065109"
  },
  {
    "text": "And as m goes to infinity,\nby concentration,",
    "start": "4065110",
    "end": "4073440"
  },
  {
    "text": "this is concentrated around\nthe expectation of it. The expectation is something\nlike sigma prime wi transpose",
    "start": "4073440",
    "end": "4081830"
  },
  {
    "text": "x sigma prime wi transpose x. ",
    "start": "4081830",
    "end": "4089570"
  },
  {
    "text": "This I can write the following,\nw transpose x sigma prime w transpose x prime times\nx and x prime, where",
    "start": "4089570",
    "end": "4098089"
  },
  {
    "text": "w is from the spherical\nGaussian, right.",
    "start": "4098090",
    "end": "4103109"
  },
  {
    "start": "4103109",
    "end": "4108889"
  },
  {
    "text": "So again, this does\nnot depend on m, OK?",
    "start": "4108890",
    "end": "4114251"
  },
  {
    "text": " So basically, this is saying\nthat this entire matrix phi phi",
    "start": "4114251",
    "end": "4120950"
  },
  {
    "text": "transpose goes to some\nkind of a constant matrix",
    "start": "4120950",
    "end": "4130640"
  },
  {
    "text": "as m goes to infinity.  And I think, this\nmatrix, sometimes people",
    "start": "4130640",
    "end": "4136390"
  },
  {
    "text": "call it K infinity. And this is the neural\ntangent kernel with m",
    "start": "4136390",
    "end": "4146009"
  },
  {
    "text": "equals to infinity. So this is the fixed matrix. And you can show that\nthis is a matrix that",
    "start": "4146010",
    "end": "4161509"
  },
  {
    "text": "at least is a full rank. So I'm going to skip this part.",
    "start": "4161510",
    "end": "4168120"
  },
  {
    "text": "So it can be shown that this\nK infinity is full rank.",
    "start": "4168120",
    "end": "4175359"
  },
  {
    "text": " And let's take sigma min to be\nthe sigma min of K infinity,",
    "start": "4175359",
    "end": "4185359"
  },
  {
    "text": "which is larger than 0.  Then, basically, you\ncan show that the phi",
    "start": "4185359",
    "end": "4191259"
  },
  {
    "text": "phi transpose for the sigma\nmin of phi phi transpose--",
    "start": "4191260",
    "end": "4197949"
  },
  {
    "text": " sorry, phi phi.",
    "start": "4197950",
    "end": "4203524"
  },
  {
    "start": "4203524",
    "end": "4209340"
  },
  {
    "text": "This is larger than, for\nexample, 1/2 times sigma min,",
    "start": "4209340",
    "end": "4215380"
  },
  {
    "text": "if m is sufficiently big, just\nbecause phi phi transpose is converging to the constant\nmatrix K infinity.",
    "start": "4215380",
    "end": "4224770"
  },
  {
    "text": "So if m is sufficiently\nbig, then your eigenvalues should also converge.",
    "start": "4224770",
    "end": "4230080"
  },
  {
    "text": "This value, again, is not-- I didn't do it\nexactly rigorously.",
    "start": "4230080",
    "end": "4235570"
  },
  {
    "text": "But you can expect\nthat, when you converge to some matrix, your eigenvalue,\nyour spectrum should also",
    "start": "4235570",
    "end": "4242230"
  },
  {
    "text": "converge to that matrix. ",
    "start": "4242230",
    "end": "4248320"
  },
  {
    "text": "So with all of this,\nso basically this is saying that\nyour sigma is not--",
    "start": "4248320",
    "end": "4253810"
  },
  {
    "text": "this is our sigma, right? The sigma is not\nchanging, in some sense, as m goes to infinity.",
    "start": "4253810",
    "end": "4260170"
  },
  {
    "text": "But let's see what beta changes. So now-- how beta changes\nas m goes to infinity.",
    "start": "4260170",
    "end": "4270690"
  },
  {
    "text": "We will show that\nthe beta goes to 0 as m goes to\ninfinity so that beta over sigma squared, the\nkey quantity, will go to 0.",
    "start": "4270690",
    "end": "4278610"
  },
  {
    "text": "And let's see how\nmuch time I have.",
    "start": "4278610",
    "end": "4288452"
  },
  {
    "start": "4288453",
    "end": "4299320"
  },
  {
    "text": "OK. So now, what we\ndo is that we want",
    "start": "4299320",
    "end": "4305560"
  },
  {
    "text": "to look at the Lipschitzness of\nbeta, which means that you care about these two things, the\ndifference between these two",
    "start": "4305560",
    "end": "4313320"
  },
  {
    "text": "things. And we have computed\nwhat the gradient is. The gradient-- both of these\nare matrices because theta",
    "start": "4313320",
    "end": "4323220"
  },
  {
    "text": "is a matrix, right? And the gradient of\neach column or each row",
    "start": "4323220",
    "end": "4331770"
  },
  {
    "text": "is something like this. So this is really a\nmatrix with entries",
    "start": "4331770",
    "end": "4347970"
  },
  {
    "text": "times x where i is from 1 to m. So you have each of\nthese is a gradient.",
    "start": "4347970",
    "end": "4355090"
  },
  {
    "text": "So that's why, if you look at\nthe norm between these two,",
    "start": "4355090",
    "end": "4362869"
  },
  {
    "text": "if you look at the\nEuclidean norm, then it's the sum of the norms\nof each of the components.",
    "start": "4362870",
    "end": "4370040"
  },
  {
    "text": "So you get 1 over m, which come\nfrom this 1 over squared m. And then you look at a norm\nof each of these components.",
    "start": "4370040",
    "end": "4375940"
  },
  {
    "text": "This is a scalar. This is a vector. So you get x 2-norm\ntimes the scalar sigma",
    "start": "4375940",
    "end": "4381340"
  },
  {
    "text": "prime x minus sigma prime wi\nprime transpose x squared.",
    "start": "4381340",
    "end": "4388520"
  },
  {
    "text": " And then so suppose\nyou want to get--",
    "start": "4388520",
    "end": "4394610"
  },
  {
    "text": "let's try to get rid\nof this sigma prime. So let's say this is less\nthan 1 over m times--",
    "start": "4394610",
    "end": "4400205"
  },
  {
    "text": " just without the sigma prime.",
    "start": "4400205",
    "end": "4405420"
  },
  {
    "text": "And this is you're assuming\nthat sigma prime is",
    "start": "4405420",
    "end": "4415219"
  },
  {
    "text": "1-Lipschitz O of 1-Lipschitz. ",
    "start": "4415220",
    "end": "4420820"
  },
  {
    "text": "Let's put a big O here. ",
    "start": "4420820",
    "end": "4426270"
  },
  {
    "text": "And then, of course, this\ndoesn't work for ReLU. As I said, for ReLU, we\nhave to fix it in some way.",
    "start": "4426270",
    "end": "4433260"
  },
  {
    "text": " OK. And then you say that this is\nyou get rid of the x again.",
    "start": "4433260",
    "end": "4444360"
  },
  {
    "text": "So m times sum over i m.",
    "start": "4444360",
    "end": "4450900"
  },
  {
    "text": "I guess the norm of x\nis 1, as we claimed. And this one we just\nuse Cauchy-Schwarz.",
    "start": "4450900",
    "end": "4456969"
  },
  {
    "text": "Let's say wi minus wi prime\n2-norm squared times x 2-norm",
    "start": "4456970",
    "end": "4467440"
  },
  {
    "text": "squared. That's this part. And x 2-norm squared is also\n1, so we can just do this.",
    "start": "4467440",
    "end": "4473688"
  },
  {
    "text": " And then this is 1 over\nm times the distance",
    "start": "4473688",
    "end": "4483070"
  },
  {
    "text": "between theta and theta\nprime in Euclidean distance. ",
    "start": "4483070",
    "end": "4488950"
  },
  {
    "text": "So this is saying that the\nLipschitzness is 1 over m. Oh, I guess the Lipschitz\nis 1 over square root m",
    "start": "4488950",
    "end": "4495670"
  },
  {
    "text": "because we didn't take\nthe square root, right? So x 2-norm is less than\n1 over square root m 2.",
    "start": "4495670",
    "end": "4510920"
  },
  {
    "text": "So beta is 1 over square root m.",
    "start": "4510920",
    "end": "4517239"
  },
  {
    "text": "And now, if we look at this\nkey quantity, beta over sigma",
    "start": "4517240",
    "end": "4525310"
  },
  {
    "text": "squared, then this\nis equals to 1 over square root m over sigma.",
    "start": "4525310",
    "end": "4530500"
  },
  {
    "text": "Sigma is something\nlike sigma bar squared. Sorry, sigma is\nthis, something that doesn't depend on m, right,\nso sigma min square, right?",
    "start": "4530500",
    "end": "4539670"
  },
  {
    "text": "So this will go to 0\nas m goes to infinity.",
    "start": "4539670",
    "end": "4544860"
  },
  {
    "text": " So here I think\nthe radius you need",
    "start": "4544860",
    "end": "4550820"
  },
  {
    "text": "is always the same because\nsigma is always the same. But your function becomes\nmore and more smooth.",
    "start": "4550820",
    "end": "4558585"
  },
  {
    "text": "Your gradient becomes\nmore and more Lipschitz as you have more\nand more neurons.",
    "start": "4558585",
    "end": "4563610"
  },
  {
    "text": "So that's why eventually,\nas you have more neurons, you can get into this regime.",
    "start": "4563610",
    "end": "4568760"
  },
  {
    "start": "4568760",
    "end": "4588599"
  },
  {
    "text": "Let's see. ",
    "start": "4588600",
    "end": "4622989"
  },
  {
    "text": "OK, so, I guess, let me take\nthe next 10 minutes to discuss the outline of the next steps.",
    "start": "4622990",
    "end": "4630610"
  },
  {
    "text": "So any questions so far?  So now, suppose I\ntry to establish 3.",
    "start": "4630610",
    "end": "4644930"
  },
  {
    "text": "So recall that 3 is about\noptimizing g, and optimizing over f are similar.",
    "start": "4644930",
    "end": "4651890"
  },
  {
    "text": "So you can basically\ndo two things.",
    "start": "4651890",
    "end": "4659370"
  },
  {
    "text": "There are a lot of different\nways to analyze this. And all the analysis kind\nof, I think, probably",
    "start": "4659370",
    "end": "4664740"
  },
  {
    "text": "you can think of as\ntwo steps implicitly even though the first\nstep probably don't have to write in the paper.",
    "start": "4664740",
    "end": "4670305"
  },
  {
    "text": "But I'm pretty sure\nmany people do that when they derive the analysis.",
    "start": "4670305",
    "end": "4676270"
  },
  {
    "text": "So you first step, it\nsounds reasonable to say that you first analyze\noptimization of L hat g theta.",
    "start": "4676270",
    "end": "4685990"
  },
  {
    "text": "And the second step\nis that you somehow analyze optimization\nof L hat f theta",
    "start": "4685990",
    "end": "4696630"
  },
  {
    "text": "by somewhat reusing\nproofs in A in some way.",
    "start": "4696630",
    "end": "4706688"
  },
  {
    "text": "Of course, you cannot\nre-use exactly, but you can probably\nre-use most of the ideas.",
    "start": "4706688",
    "end": "4713180"
  },
  {
    "text": "And your intuition is that\nthese two things are similar, so somehow you can\nreuse the proof",
    "start": "4713180",
    "end": "4718699"
  },
  {
    "text": "to do the actual optimization\nfor the neural artwork f theta.",
    "start": "4718700",
    "end": "4725120"
  },
  {
    "text": "And there are two ways for\nA. I think, essentially, you",
    "start": "4725120",
    "end": "4734970"
  },
  {
    "text": "can say two ways. Maybe there is a\npossibility that I missed some of the existing papers. But roughly speaking,\nthere are two ways for A.",
    "start": "4734970",
    "end": "4742770"
  },
  {
    "text": "And, therefore, there are\ntwo ways for B in some sense. ",
    "start": "4742770",
    "end": "4751700"
  },
  {
    "text": "So the first way,\nlet's say i, is that you leverage the strong\nconvexity of this L hat g",
    "start": "4751700",
    "end": "4766445"
  },
  {
    "text": "theta, and then show\nexponential convergence.",
    "start": "4766445",
    "end": "4774739"
  },
  {
    "start": "4774740",
    "end": "4779980"
  },
  {
    "text": "I have to say that the\ndefinition of strong convexity, I'm not sure whether I have\nreally given it in this course.",
    "start": "4779980",
    "end": "4786370"
  },
  {
    "text": "This is a stronger\nnotion of convexity if you haven't heard of it. You probably don't.",
    "start": "4786370",
    "end": "4792250"
  },
  {
    "text": "It's not super essential\nfor this course. But if you have heard of it,\nyou know what kind of things",
    "start": "4792250",
    "end": "4797620"
  },
  {
    "text": "I'm talking about. Because this\nanalyzing A, this is analyzing how do you\noptimize a convex function.",
    "start": "4797620",
    "end": "4802659"
  },
  {
    "text": "It does require a little bit\nof optimization background. At least on a\nconceptual level, you",
    "start": "4802660",
    "end": "4809562"
  },
  {
    "text": "can imagine there are\nmany different ways to analyze all optimizations\nfor regression.",
    "start": "4809562",
    "end": "4815765"
  },
  {
    "text": "So strong convexity is the\nstronger version of convexity. And you can somewhat use that\nto get the very fast convergence",
    "start": "4815765",
    "end": "4822040"
  },
  {
    "text": "rate. Exponential means,\nevery time, you decay the error by\na constant factor",
    "start": "4822040",
    "end": "4827420"
  },
  {
    "text": "so that you get exponential\ndecay of the errors. And another way to\ndo this is that you",
    "start": "4827420",
    "end": "4833170"
  },
  {
    "text": "don't use the strong convexity\nbecause sometimes you actually don't have the strong\nconvexity in certain cases.",
    "start": "4833170",
    "end": "4839417"
  },
  {
    "text": "So you don't use the\nstrong convexity, but only use the smoothness. ",
    "start": "4839417",
    "end": "4848875"
  },
  {
    "text": "The smoothness means that you\nhave a bounded second order derivative. And again, if you have\ntaken some courses",
    "start": "4848875",
    "end": "4855780"
  },
  {
    "text": "about optimization, then this\nwould make a lot of sense probably because there\nare different ways to analyze optimization.",
    "start": "4855780",
    "end": "4861210"
  },
  {
    "text": "Sometimes you only\nhave smoothness. You have a different\nkind of analysis. ",
    "start": "4861210",
    "end": "4867540"
  },
  {
    "text": "And based on these\ntwo approaches, you can get two different\nproofs for B as well. And we're only going\nto talk about A.",
    "start": "4867540",
    "end": "4875380"
  },
  {
    "text": "So we only talk about A-- sorry, talk about i,\nthe first approach.",
    "start": "4875380",
    "end": "4883150"
  },
  {
    "text": "And for this approach, no\nprior knowledge is required. You probably wouldn't\nunderstand exactly what I'm",
    "start": "4883150",
    "end": "4888700"
  },
  {
    "text": "saying about this\nconceptual thing, but the actual proof doesn't\nrequire prior knowledge.",
    "start": "4888700",
    "end": "4893710"
  },
  {
    "text": "And it's actually also pretty\nintuitive by itself as well. So I think we are going to\ntalk about the approach,",
    "start": "4893710",
    "end": "4902110"
  },
  {
    "text": "the concrete analysis,\nnext week, next lecture. But before ending\nthis lecture, let",
    "start": "4902110",
    "end": "4907929"
  },
  {
    "text": "me make another remark,\nwhich I think is useful. And in some sense,\nit's useful for two,",
    "start": "4907930",
    "end": "4914260"
  },
  {
    "text": "for the second approach, more. But it's also useful\nfor the first approach. So this is an\ninteresting observation,",
    "start": "4914260",
    "end": "4924810"
  },
  {
    "text": "or maybe intuition you\ncan say, and particularly",
    "start": "4924810",
    "end": "4931780"
  },
  {
    "text": "useful for two. ",
    "start": "4931780",
    "end": "4940980"
  },
  {
    "text": "So this is saying\nat any theta t.",
    "start": "4940980",
    "end": "4947270"
  },
  {
    "text": "Suppose you take\nthis Taylor expansion",
    "start": "4947270",
    "end": "4956760"
  },
  {
    "text": "with reference point theta t. So now, we are not taking\nTaylor expansion at theta 0.",
    "start": "4956760",
    "end": "4963099"
  },
  {
    "text": "We are taking Taylor\nexpansion at theta t. You can define this g t of\ntheta x is a function of theta.",
    "start": "4963100",
    "end": "4970360"
  },
  {
    "text": "And it Taylor\nexpanded at theta t, so the reference\npoint is theta t. And they have gradient f theta\nt x times theta minus theta t.",
    "start": "4970360",
    "end": "4981489"
  },
  {
    "text": "So this is the linear function.  And then you can consider nabla\nL f theta at theta t, right?",
    "start": "4981490",
    "end": "4996349"
  },
  {
    "text": "So this is the gradient\nthat you actually--  This is the gradient\nyou are taking.",
    "start": "4996350",
    "end": "5010560"
  },
  {
    "text": "Because what you really care\nabout is optimizing f, right? So this is the gradient\nyou are taking. But actually, it's the\nsame as the gradient",
    "start": "5010560",
    "end": "5022280"
  },
  {
    "text": "of this Taylor expansion\nat a same point, theta t. So these two thing--",
    "start": "5022280",
    "end": "5027890"
  },
  {
    "text": " there's two t here. This is theta t.",
    "start": "5027890",
    "end": "5033670"
  },
  {
    "text": "And this t is indicating that\nthis is also Taylor expansion at the reference point theta t.",
    "start": "5033670",
    "end": "5040540"
  },
  {
    "text": "So while this is the case,\nI guess, if you want, you can take the derivative\nand you can verify it.",
    "start": "5040540",
    "end": "5046180"
  },
  {
    "text": "But fundamentally,\nthis is actually-- it's really just\nsaying that, f theta t,",
    "start": "5046180",
    "end": "5054183"
  },
  {
    "text": "f theta and g theta t agree\nup to first order at theta t.",
    "start": "5054184",
    "end": "5067860"
  },
  {
    "text": "This is by Taylor expansion. If they agree up to\nfirst order at theta t, then anything that's--",
    "start": "5067860",
    "end": "5076800"
  },
  {
    "text": "so this implies L all of\nf theta and L of g theta t",
    "start": "5076800",
    "end": "5086130"
  },
  {
    "text": "also agree up to a\nfirst order at theta t.",
    "start": "5086130",
    "end": "5093820"
  },
  {
    "text": " So that's why-- so what\ndoes this really mean?",
    "start": "5093820",
    "end": "5102000"
  },
  {
    "text": "This really means that gradient\ndescent on f, on this function",
    "start": "5102000",
    "end": "5108320"
  },
  {
    "text": "or maybe technically\non L hat f theta,",
    "start": "5108320",
    "end": "5113989"
  },
  {
    "text": "you are taking gradient\nonly with respect to the f. This is the same as taking\nonline gradient descent.",
    "start": "5113990",
    "end": "5125995"
  },
  {
    "text": " I guess I haven't defined\nonline gradient descent,",
    "start": "5125995",
    "end": "5131610"
  },
  {
    "text": "but let me define\nthat in a moment after I write down-- on\na sequence of changing",
    "start": "5131610",
    "end": "5138010"
  },
  {
    "text": "objective L g theta\n0 up to L g theta t.",
    "start": "5138010",
    "end": "5152630"
  },
  {
    "text": "So what does online gradient\ndescent really mean? It just really means\nthat every time you take the gradient of\nthe new function-- you",
    "start": "5152630",
    "end": "5159860"
  },
  {
    "text": "have a sequence of functions. And every time you\nget a new function and you take the gradient\nof that function,",
    "start": "5159860",
    "end": "5164970"
  },
  {
    "text": "you take a one step. So that's online\ngradient descent. So basically, you are saying\nthat taking gradient descent",
    "start": "5164970",
    "end": "5171530"
  },
  {
    "text": "on this fixed function L\nhat is the same as taking gradients updates with respect\nto a sequence of changing",
    "start": "5171530",
    "end": "5178940"
  },
  {
    "text": "functions. And this is actually\nhow the second step, the second approach,\nreally works.",
    "start": "5178940",
    "end": "5186230"
  },
  {
    "text": "So this means that you can\nuse online learning approach.",
    "start": "5186230",
    "end": "5195090"
  },
  {
    "text": " I guess, in this\nculture, I'm not planning",
    "start": "5195090",
    "end": "5203530"
  },
  {
    "text": "to talk about online learning. But online learning is\ntrying to deal with the case where we have a changing\nsequence of changing functions.",
    "start": "5203530",
    "end": "5211307"
  },
  {
    "text": "So you are not optimizing\na single function. You have a changing-- changing distribution,\nor changing environment,",
    "start": "5211307",
    "end": "5216710"
  },
  {
    "text": "or changing loss\nfunction, whatsoever. So there is a rich literature on\nhow do you analyze optimization",
    "start": "5216710",
    "end": "5224060"
  },
  {
    "text": "when you have a sequence\nof changing loss functions. And this is exactly\nwhat this is about.",
    "start": "5224060",
    "end": "5231079"
  },
  {
    "text": "You are having a sequence\nof changing loss functions. And if you analyze that, you\ncan analyze the original cases.",
    "start": "5231080",
    "end": "5240140"
  },
  {
    "text": "Now, here there are\nalso spectral structures about these loss functions\nbecause they are all somewhat similar to each other, right?",
    "start": "5240140",
    "end": "5246148"
  },
  {
    "text": "So they are all Taylor\nexpansions with respect to reference points that\nare in a small region.",
    "start": "5246148",
    "end": "5252960"
  },
  {
    "text": "So you can also leverage\nadditional information about that. Yeah, so this is chapter\n10 in the lecture notes.",
    "start": "5252960",
    "end": "5260650"
  },
  {
    "text": "But I think, in\nthis quarter, I just don't think we have\ntime to go there.",
    "start": "5260650",
    "end": "5267526"
  },
  {
    "text": "OK, I think I'm\nalready 5 minutes late. And next lecture, we are going\nto talk about the approach",
    "start": "5267526",
    "end": "5274540"
  },
  {
    "text": "one, which is more\nself-contained and also kind of\ncleaner to some extent.",
    "start": "5274540",
    "end": "5283860"
  },
  {
    "text": "OK, maybe just a last comment-- I think there are many different\nneural tangent kernel papers.",
    "start": "5283860",
    "end": "5291070"
  },
  {
    "text": "I probably am not\nsuper comprehensive, but I think most\nof them basically",
    "start": "5291070",
    "end": "5296710"
  },
  {
    "text": "is a combination of\nthese several things. So one thing is that you\nhave to optimize this,",
    "start": "5296710",
    "end": "5301929"
  },
  {
    "text": "establish this third\nstep of optimization. And you have two ways,\ntwo large ways, and maybe",
    "start": "5301930",
    "end": "5307420"
  },
  {
    "text": "some even subtle differences,\nunderlying differences. And also, you have to establish\nthe first two properties.",
    "start": "5307420",
    "end": "5315670"
  },
  {
    "text": "And those are properties\nnot about optimization. They are about your\nparameterization of your function class\nor initialization, right?",
    "start": "5315670",
    "end": "5322270"
  },
  {
    "text": "So there, you can\nalso have a bunch of different flexibilities. You can change the\nreference, the scaling. You can change the width.",
    "start": "5322270",
    "end": "5328510"
  },
  {
    "text": "You can do many\ndifferent things. Or you can even change, for\nexample, the architecture",
    "start": "5328510",
    "end": "5334570"
  },
  {
    "text": "in certain cases to make\nit more efficient or less efficient in certain cases. ",
    "start": "5334570",
    "end": "5343510"
  },
  {
    "text": "Yeah. So I'm not-- I\ndon't want to have a very comprehensive\ndiscussion of this NTK",
    "start": "5343510",
    "end": "5349630"
  },
  {
    "text": "just because there are\nso many limitations. But I think it's a useful thing\nto know given that there are so many works in it.",
    "start": "5349630",
    "end": "5355540"
  },
  {
    "text": "And there are, indeed,\nsome nice ideas there. OK, cool. So I guess I'll continue\non next Wednesday.",
    "start": "5355540",
    "end": "5363280"
  },
  {
    "text": "Thanks. ",
    "start": "5363280",
    "end": "5369000"
  }
]
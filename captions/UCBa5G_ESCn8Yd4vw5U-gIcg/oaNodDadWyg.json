[
  {
    "start": "0",
    "end": "9481"
  },
  {
    "text": "JACKIE PETERSON: Now, I'd like\nto introduce our presenter today. Today, I have Dr.\nNigam Shah with me.",
    "start": "9481",
    "end": "14730"
  },
  {
    "text": "Dr. Nigam Shah is a professor of\nMedicine at Stanford University and chief data scientist\nfor Stanford Health Care.",
    "start": "14730",
    "end": "21750"
  },
  {
    "text": "His research is focused on\nbringing AI into clinical use safely, ethically,\nand cost effectively.",
    "start": "21750",
    "end": "27900"
  },
  {
    "text": "Dr. Shah is an inventor\non eight patents, has authored over 300\nscientific publications,",
    "start": "27900",
    "end": "35090"
  },
  {
    "text": "and has co-founded\nthree companies. Dr. Shah was inducted\ninto the American College of Medical Informatics\nin 2015, and the American",
    "start": "35090",
    "end": "43580"
  },
  {
    "text": "Society for Clinical\nInvestigation in 2016. He holds an MBBS from Baroda\nMedical College in India,",
    "start": "43580",
    "end": "51290"
  },
  {
    "text": "a PhD from Penn\nState University, and completed postdoctoral\ntraining at Stanford University.",
    "start": "51290",
    "end": "57300"
  },
  {
    "text": "So thank you for being here. I'll now pass it\nover to Dr. Shah. NIGAM SHAH: Thank you. Thank you, Jackie.",
    "start": "57300",
    "end": "62600"
  },
  {
    "text": "It's a great fun to be here\nand talk about this new course offering and contextualize\nit in light of all of the fun",
    "start": "62600",
    "end": "70740"
  },
  {
    "text": "things happening on our campus. So let's take over slides.",
    "start": "70740",
    "end": "76250"
  },
  {
    "text": "All right. So one of the things\nthat we're really excited to share with\nyou is that yes, there's",
    "start": "76250",
    "end": "82200"
  },
  {
    "text": "a lot of buzz about AI,\nthere's a lot of buzz about ML and all of those things.",
    "start": "82200",
    "end": "88390"
  },
  {
    "text": "But a little known thing that\nwe often do not talk about is the data.",
    "start": "88390",
    "end": "93490"
  },
  {
    "text": "Your AI, your ML is only as good\nas the data it is trained upon.",
    "start": "93490",
    "end": "98869"
  },
  {
    "text": "And we like to think of data\nin the form of timelines. So we use data\nfrom these patient",
    "start": "98870",
    "end": "105640"
  },
  {
    "text": "timelines to build\nthe AI or the machine learning or generally\nspeaking, to build models.",
    "start": "105640",
    "end": "111299"
  },
  {
    "text": "So to orient ourselves, we have\nan arrow of time going left to right, and we have-- this\nis a fictional individual who",
    "start": "111300",
    "end": "119049"
  },
  {
    "text": "got admitted to the\nhospital about four times in a certain night the hospital\nsays they also ended up",
    "start": "119050",
    "end": "125020"
  },
  {
    "text": "in the ICU. And then below that are\nall of the different data types that we collected\nduring their treatment.",
    "start": "125020",
    "end": "133090"
  },
  {
    "text": "EKGs, blood pressure,\nrespiratory rate, cardiac output, medication\norders, and some documents",
    "start": "133090",
    "end": "140380"
  },
  {
    "text": "are written lab\ntests and reports are collected, and so on.",
    "start": "140380",
    "end": "145930"
  },
  {
    "text": "And we love to start thinking\nabout AI, responsible AI,",
    "start": "145930",
    "end": "151909"
  },
  {
    "text": "machine learning, all of that\nwith this data view in mind. And let's call this thing\na patient timeline object.",
    "start": "151910",
    "end": "158860"
  },
  {
    "text": "And then the reason this\nmatters is in a typical health",
    "start": "158860",
    "end": "164380"
  },
  {
    "text": "care setting at any\ngiven point in time, we do not collect everything.",
    "start": "164380",
    "end": "169569"
  },
  {
    "text": "So if we look at any time point\none of those vertical columns, some modalities are collected,\nthe ones that were necessary.",
    "start": "169570",
    "end": "177040"
  },
  {
    "text": "Or if you look at a particular\nrow of data, data modality, there is no\nparticular individual,",
    "start": "177040",
    "end": "183830"
  },
  {
    "text": "including the\npatient, that would have a longitudinal coverage\nfor about five or more years.",
    "start": "183830",
    "end": "190170"
  },
  {
    "text": "And that is crucially\nimportant to know because how we manipulate these\ndata, these timelines, what",
    "start": "190170",
    "end": "198570"
  },
  {
    "text": "we do to them, how we process\nthe text, how we do the feature engineering, all of that has a\nlot more effect on your final AI",
    "start": "198570",
    "end": "206400"
  },
  {
    "text": "or model performance\nthan anything else. And that is something we cover\nquite heavily in the classes",
    "start": "206400",
    "end": "212940"
  },
  {
    "text": "that we teach here. So let's say we've got\nthat foundation applied,",
    "start": "212940",
    "end": "218489"
  },
  {
    "text": "we have these timelines,\nand we have them from millions of patients.",
    "start": "218490",
    "end": "224480"
  },
  {
    "text": "So with them, we build models. I've put models in a\nlittle box on the left",
    "start": "224480",
    "end": "229580"
  },
  {
    "text": "because that's not what we're\ngoing to focus on today. They could be\nlogistic regressions,",
    "start": "229580",
    "end": "235430"
  },
  {
    "text": "they could be deep\nneural networks. But what we'll\nfocus on is what do we do with those\nmodels in health care.",
    "start": "235430",
    "end": "242170"
  },
  {
    "text": "And I would argue we\ndo two big things. We make decisions about\nwhether to treat a patient",
    "start": "242170",
    "end": "247960"
  },
  {
    "text": "and how to treat a patient. So whether to treat is in this\nlight orange and how to treat is in blue.",
    "start": "247960",
    "end": "253600"
  },
  {
    "text": "From a computational\nstandpoint, the whether to treat can be further broken up\ninto a task of classification",
    "start": "253600",
    "end": "262150"
  },
  {
    "text": "or diagnosis in\nmedical parlance. Or a prediction task, a proper\nfuture looking estimate,",
    "start": "262150",
    "end": "269270"
  },
  {
    "text": "otherwise known as prognosis. Now, in general language,\noften these terms get abused a little bit.",
    "start": "269270",
    "end": "275840"
  },
  {
    "text": "And we might say things like\nor you might hear things like, we analyze this image and we\npredict there is pneumonia",
    "start": "275840",
    "end": "282580"
  },
  {
    "text": "or we analyze this image and we\npredict there's a dog in there. It's not a prediction,\nthat's a classification.",
    "start": "282580",
    "end": "289130"
  },
  {
    "text": "The dog was already a dog\nbefore you took the picture. The pneumonia was already there\nbefore you took the X-ray.",
    "start": "289130",
    "end": "295120"
  },
  {
    "text": "So that's in the top\nrow classification. And that's also something\nto pay attention to because a lot of\nthings in medicine",
    "start": "295120",
    "end": "301669"
  },
  {
    "text": "or in particular in AI, in\nhealth care or machine learning in medicine that masquerade\nas predictions are not really",
    "start": "301670",
    "end": "308840"
  },
  {
    "text": "predictions. Like you might hear things\nlike we have the sepsis predictor, well, there's no such\nthing as a sepsis predictor.",
    "start": "308840",
    "end": "315770"
  },
  {
    "text": "Most of those things are\nfiguring out the fact that the patient has sepsis\nand the care team doesn't know.",
    "start": "315770",
    "end": "321530"
  },
  {
    "text": "It's a classification. And that semantics,\npedantic as it sounds,",
    "start": "321530",
    "end": "326580"
  },
  {
    "text": "is really important because if\nyou think you're predicting, you're tempted to do something\nto prevent that outcome.",
    "start": "326580",
    "end": "332790"
  },
  {
    "text": "But if you know that\nall you're doing is classifying and\ndiagnosing, then you think about treating\nand not prevention.",
    "start": "332790",
    "end": "339300"
  },
  {
    "text": "So it does matter how\nwe use these words and it's a really important\ndistinction to make.",
    "start": "339300",
    "end": "345560"
  },
  {
    "text": "Sepsis things are classifiers\nand not predictors. The blue part, the\nrecommendation,",
    "start": "345560",
    "end": "351750"
  },
  {
    "text": "that's actually the hardest. Given the data\nhave so many holes, quote unquote\n\"biases'', so to speak,",
    "start": "351750",
    "end": "358470"
  },
  {
    "text": "it's really hard to do\nreliable recommendation. In fact, it's been a 40-year\njourney in medicine to figure",
    "start": "358470",
    "end": "365870"
  },
  {
    "text": "that out, and I'm going to soon\ntalk about one of the efforts that we succeeded in on campus.",
    "start": "365870",
    "end": "372379"
  },
  {
    "text": "So three things we can do. The other question\nto ask at this point, is are we doing those technical\nexercises, classification,",
    "start": "372380",
    "end": "380110"
  },
  {
    "text": "prediction, recommendation\nfor advancing the science of medicine? The practice of medicine or\nthe delivery of medical care.",
    "start": "380110",
    "end": "389580"
  },
  {
    "text": "And I'll give you an\nexample to illustrate. It's possible to do\nsome elegant math",
    "start": "389580",
    "end": "395310"
  },
  {
    "text": "and figure out that\nthis condition called heart failure with\npreserved ejection fraction has three subtypes.",
    "start": "395310",
    "end": "400710"
  },
  {
    "text": "And that would be in the\ntop row, first column. It's a classification advancing\nour scientific understanding",
    "start": "400710",
    "end": "406890"
  },
  {
    "text": "of the disease that this thing\nwe thought was 1 is indeed 3. And subtype 1, you\nmight die in two years",
    "start": "406890",
    "end": "413699"
  },
  {
    "text": "and subtype 3 you're\nfine for a decade. The second column\npractice would advance",
    "start": "413700",
    "end": "419650"
  },
  {
    "text": "if we have two more things. I have a test, could\nbe a blood test, could be an algorithmic\ntest, could be an AI test,",
    "start": "419650",
    "end": "427009"
  },
  {
    "text": "could be an imaging\ntest, doesn't matter. Patient walks in, I do\nthe test and it tells me, are they subtype\n1, 2, or 3 And then",
    "start": "427010",
    "end": "433620"
  },
  {
    "text": "I have a treatment\nat my disposal. To treat the ones\nthat are higher risk more aggressively\nor differently.",
    "start": "433620",
    "end": "440150"
  },
  {
    "text": "Because if we just\ntreat and then-- if we just test and then treat\neverybody the exact same way, all we're doing is\nincreasing the cost of care.",
    "start": "440150",
    "end": "446970"
  },
  {
    "text": "That's the middle column. And then the third,\nthe delivery advances. If we do this test\nand train regime,",
    "start": "446970",
    "end": "454410"
  },
  {
    "text": "we do it for five years or 10\nyears for 1,000 people or 10,000 people, they live longer\nor they cost less,",
    "start": "454410",
    "end": "460930"
  },
  {
    "text": "have better quality of life. And so as we think about the\nuses of AI, the uses of machine",
    "start": "460930",
    "end": "468270"
  },
  {
    "text": "learning, it's really\nimportant to park it in this kind of a mental grid\nto get a sense of exactly",
    "start": "468270",
    "end": "473683"
  },
  {
    "text": "what is it that we're doing. I'm going to give you this one\nexample of the middle column last row.",
    "start": "473683",
    "end": "479379"
  },
  {
    "text": "So it's an effort we\ndid on our campus, it goes by the name of\nthe Green Button project. And the idea was quite simple.",
    "start": "479380",
    "end": "485990"
  },
  {
    "text": "It's been around\nfor 40 or 50 years that when we have a difficult\ncase at the bedside,",
    "start": "485990",
    "end": "491509"
  },
  {
    "text": "can we query all of\nour similar patients that those patient\ntimeline objects that we had for millions\nof other patients,",
    "start": "491510",
    "end": "499150"
  },
  {
    "text": "aggregate that and provide\na better decision that then we would otherwise make.",
    "start": "499150",
    "end": "504910"
  },
  {
    "text": "So we did that. We actually ran such a\nbedside consultation service where you could\nrefer a case to us",
    "start": "504910",
    "end": "510729"
  },
  {
    "text": "and we would provide a written\nreport with a recommendation. ",
    "start": "510730",
    "end": "517330"
  },
  {
    "text": "Now, why does this matter? So on the left are\nsome numbers, just",
    "start": "517330",
    "end": "522469"
  },
  {
    "text": "to give you a\nintuitive sense for how unreliable medical evidence is.",
    "start": "522470",
    "end": "530370"
  },
  {
    "text": "So in this case, this work\nthat I was not involved with, a couple of physicians tracked\nover a period of about a week",
    "start": "530370",
    "end": "537100"
  },
  {
    "text": "the decisions that they\nmade and then went back. And it's a survey\nand they were asked,",
    "start": "537100",
    "end": "543910"
  },
  {
    "text": "for the decisions\nyou make, did you have any prior published data? And about 80% of the\ntime, they did not.",
    "start": "543910",
    "end": "551520"
  },
  {
    "text": "Now, that doesn't mean\nthe data didn't exist. It means they were not-- they were not aware of it and\ndid not have any access to it.",
    "start": "551520",
    "end": "558589"
  },
  {
    "text": "And in their own subjective\nassessment, less than 3% of the decisions had a study\nspecific to the question at hand",
    "start": "558590",
    "end": "565420"
  },
  {
    "text": "that the physician knew. Now, you could argue\nthat some of it is just better\nliterature searching,",
    "start": "565420",
    "end": "571810"
  },
  {
    "text": "but when you have about\n80% of the decisions not have any prior published\ndata, the thing to do",
    "start": "571810",
    "end": "579040"
  },
  {
    "text": "is to analyze data\non demand, which is what our prior project did. And when that project was\ndone, our dean and CEO",
    "start": "579040",
    "end": "587050"
  },
  {
    "text": "said like, how are we going\nto scale this and share it to the rest of the world? So in a classic\nSilicon Valley fashion,",
    "start": "587050",
    "end": "592880"
  },
  {
    "text": "we spun out a company\nthat's this thing called anthropos health. But the thing I\nwant to share here",
    "start": "592880",
    "end": "598889"
  },
  {
    "text": "is, yes, now we can do\nthese bedside studies. On our campus we should\ntake us about a day or two.",
    "start": "598890",
    "end": "604330"
  },
  {
    "text": "The company reduced it to\nunder 24 Hours, Sometimes even a few hours.",
    "start": "604330",
    "end": "609440"
  },
  {
    "text": "And then with the\nadvent of generative AI, you can now have a facility\nto essentially chat",
    "start": "609440",
    "end": "617710"
  },
  {
    "text": "with the statistical\nstudy generation system so you can have this study\ndone for you on demand",
    "start": "617710",
    "end": "624640"
  },
  {
    "text": "in a few minutes. And so sort of gives\nyou a sense for we",
    "start": "624640",
    "end": "630160"
  },
  {
    "text": "can go from data\nto better decisions with the use of different\nkinds of technologies,",
    "start": "630160",
    "end": "636320"
  },
  {
    "text": "machine learning, chatbots,\nand so on at a very rapid clip. All right.",
    "start": "636320",
    "end": "641530"
  },
  {
    "text": "Let's look at one more example. Middle row, last column. In this case, we're doing\nrelatively simple AI,",
    "start": "641530",
    "end": "648420"
  },
  {
    "text": "we're not doing deep neural\nnetworks or anything. We are predicting\nwho's going to become",
    "start": "648420",
    "end": "655110"
  },
  {
    "text": "medically costly next year. And then based on that, we\nwould take a medical action,",
    "start": "655110",
    "end": "662800"
  },
  {
    "text": "as in enroll them in a concierge\ncare program or a diabetes management program or a blood\npressure management program",
    "start": "662800",
    "end": "668670"
  },
  {
    "text": "or something of that nature. This is a little bit old now. It was in 2015. And in our best estimate, by\ntaking such proactive action,",
    "start": "668670",
    "end": "679019"
  },
  {
    "text": "we estimated that\nabout 10% to 15% of the future cost of\ncare of those patients",
    "start": "679020",
    "end": "685320"
  },
  {
    "text": "could be saved without\nsacrificing quality, in fact, doing less invasive\nprocedures to them.",
    "start": "685320",
    "end": "691450"
  },
  {
    "text": "So that's an advancement\nin the delivery that is driven by a prediction.",
    "start": "691450",
    "end": "699060"
  },
  {
    "text": "So to bring it together,\n\"AI'' and I put it in quotes",
    "start": "699060",
    "end": "704350"
  },
  {
    "text": "because it could be machine\nlearning, it could be a model, that gives us some\nrisk estimation.",
    "start": "704350",
    "end": "710470"
  },
  {
    "text": "Something like this person is\ngoing to be expensive next year. That's the first bullet point. You're predicting cost.",
    "start": "710470",
    "end": "716139"
  },
  {
    "text": "But we can have a whole\nbunch of other predictions. And the ones on the\nscreen, the top one are the operational ones.",
    "start": "716140",
    "end": "722420"
  },
  {
    "text": "Sorry, the top one\nare the biology ones. I put the cost one\nthere by accident.",
    "start": "722420",
    "end": "728420"
  },
  {
    "text": "The middle one are practice. And then the last set\nare again about delivery.",
    "start": "728420",
    "end": "733700"
  },
  {
    "text": "So for example, we\ncan predict no shows for providing patient transport. Or we can have image classifiers\ntell us whether an ischemic--",
    "start": "733700",
    "end": "743180"
  },
  {
    "text": "whether a stroke is\nischemic or hemorrhagic and decide who to put\non an air ambulance so that we can drill a\nhole and get the blood out",
    "start": "743180",
    "end": "749140"
  },
  {
    "text": "from the skull. Across all of this,\nthe consistent theme",
    "start": "749140",
    "end": "755210"
  },
  {
    "text": "is that the AI just\ngives us a risk estimate. Value comes from taking action\nin the case of cost blooms,",
    "start": "755210",
    "end": "763020"
  },
  {
    "text": "taking the early intervention. In the case of this\nother one mortality",
    "start": "763020",
    "end": "768200"
  },
  {
    "text": "prediction by performing\nadvanced care planning. Or in the case of\npredicting no shows,",
    "start": "768200",
    "end": "773430"
  },
  {
    "text": "providing transportation\nsupport or whatever else the actual intervention\nnecessary might be.",
    "start": "773430",
    "end": "779090"
  },
  {
    "text": "So that is what clued us\nin into this interplay that we study and we\nteach on our campus.",
    "start": "779090",
    "end": "785820"
  },
  {
    "text": "Is that the model\nstratifies by risk. Value comes from taking\nsome responsive action. So this little 3-star logo is\na quick way to remember it.",
    "start": "785820",
    "end": "795240"
  },
  {
    "text": "The yellow thing is the computer\nscience, the statistics. The green box is given\nthat number from the model,",
    "start": "795240",
    "end": "803160"
  },
  {
    "text": "what are we going to do? Do we have the work\ncapacity to follow through?",
    "start": "803160",
    "end": "808380"
  },
  {
    "text": "Is the action, that's the red\nbox that we're going to take. Is it going to have net\nbenefit, all things considered?",
    "start": "808380",
    "end": "814320"
  },
  {
    "text": "So we study this interplay. There's about 5, 6\nfaculty that work on this. About 25 or so papers.",
    "start": "814320",
    "end": "821110"
  },
  {
    "text": "And at the end of the\nday, after all of that, we came up with\nthis one key insight that that's on the\nnext slide, which",
    "start": "821110",
    "end": "829290"
  },
  {
    "text": "is that we need to focus on\nwhat can we achieve given work",
    "start": "829290",
    "end": "834449"
  },
  {
    "text": "capacity. So in this funny\nlooking plot, what we've done is on\nthe X-axis, we've",
    "start": "834450",
    "end": "840640"
  },
  {
    "text": "rank ordered cases based\non 1 minus the probability of something happening.",
    "start": "840640",
    "end": "845990"
  },
  {
    "text": "So 0 means highest chance\nof some event happening, whatever that event\nmight be cost bloom,",
    "start": "845990",
    "end": "851260"
  },
  {
    "text": "being a hemorrhagic stroke,\nor mortality, or whatever. And it's ordered\nfrom high to low.",
    "start": "851260",
    "end": "858040"
  },
  {
    "text": "On the Y-axis is we're\ntracking the cumulative benefit that we're getting. We take action on the first\ncase, we get some benefit.",
    "start": "858040",
    "end": "865632"
  },
  {
    "text": "The second case, we get more. So it keeps going up. We hit some maximum,\nthat blue dot,",
    "start": "865632",
    "end": "871100"
  },
  {
    "text": "and then we start seeing\ndiminishing returns. The key thing is how far down\nthe list will we be able to go?",
    "start": "871100",
    "end": "879779"
  },
  {
    "text": "And we have to\nanswer that up front because value comes from being\nable to act on the AI's output.",
    "start": "879780",
    "end": "888140"
  },
  {
    "text": "And so after we've\ndone all of this work, we sort of\nencapsulated all that.",
    "start": "888140",
    "end": "895660"
  },
  {
    "text": "Sorry. I want to go one more slide. Here. In this approach we call FURM--",
    "start": "895660",
    "end": "905210"
  },
  {
    "text": "Fair, Useful, Reliable Models. And it's a multi-step process.",
    "start": "905210",
    "end": "910800"
  },
  {
    "text": "But the essence of it is that\none plot that I was showing you, what can we achieve\ngiven capacity?",
    "start": "910800",
    "end": "918890"
  },
  {
    "text": "And so the first step, we ask\na whole bunch of questions. We do usefulness simulations,\nwe do financial projections,",
    "start": "918890",
    "end": "925760"
  },
  {
    "text": "we do ethical\nconsiderations analysis. Then we ask the question, how to\nbuild the model, the yellow box.",
    "start": "925760",
    "end": "932810"
  },
  {
    "text": "And then stage 3 is\nan honest assessment. Did we change what\nwe wanted to change?",
    "start": "932810",
    "end": "938720"
  },
  {
    "text": "So we got to monitor, we got to\ndo some prospective evaluation. So this is five seven years of\nwork packaged into a process",
    "start": "938720",
    "end": "947020"
  },
  {
    "text": "that we actually\nuse on our campus on a routine basis in our\nown health care system.",
    "start": "947020",
    "end": "952280"
  },
  {
    "text": "But before we arrived at\nthat, when we looked around, and the reason we\nare now sharing this",
    "start": "952280",
    "end": "958220"
  },
  {
    "text": "broadly is that the way\nthings are done right now is unsustainable.",
    "start": "958220",
    "end": "964430"
  },
  {
    "text": "And I have some too\nshocking numbers just to hit home the point.",
    "start": "964430",
    "end": "969750"
  },
  {
    "text": "So on the left is\nwhen we analyzed that if we look at all the\nguidance about how thou shalt do",
    "start": "969750",
    "end": "976070"
  },
  {
    "text": "good AI, we looked at about\n16 or 17 different sort of recommendations.",
    "start": "976070",
    "end": "982360"
  },
  {
    "text": "Collectively, those efforts had\n220 atomic pieces of guidance",
    "start": "982360",
    "end": "987380"
  },
  {
    "text": "about how you should do good AI. In half of them was about\nhow to build a model.",
    "start": "987380",
    "end": "994080"
  },
  {
    "text": "Meaning, if we go\nback here, about half of the guidance in the community\nwas about this yellow box",
    "start": "994080",
    "end": "1000649"
  },
  {
    "text": "at the top. And precious little\non how should we do the workflow\nanalysis, how should we",
    "start": "1000650",
    "end": "1006650"
  },
  {
    "text": "look at whether it's\nethical, how should we look at sustainability, and so on. On the right is an estimate that\none of my colleagues calculated",
    "start": "1006650",
    "end": "1014000"
  },
  {
    "text": "doing some very amazing science\nfor sites over 10 years, validating a model that when\nyou walk into the ED tells you",
    "start": "1014000",
    "end": "1022490"
  },
  {
    "text": "immediately who should get a\n12-lead EKG versus who can wait for a couple of minutes for\ntheir registration to be done.",
    "start": "1022490",
    "end": "1028660"
  },
  {
    "text": "It took them 10 years\nand about $28 million to get this tested and\nvalidated at multiple sites.",
    "start": "1028660",
    "end": "1036189"
  },
  {
    "text": "And so this current\norganization of work, the way sort of medical\nresearch is practiced,",
    "start": "1036190",
    "end": "1042319"
  },
  {
    "text": "is just simply\nunsustainable, which is another reason that we need\nthese processes like that FURM",
    "start": "1042319",
    "end": "1047680"
  },
  {
    "text": "assessment so that we can\ndo these activities better in health care.",
    "start": "1047680",
    "end": "1053470"
  },
  {
    "text": "So that basically brings\nme to this little table. How do we do this responsibly?",
    "start": "1053470",
    "end": "1059169"
  },
  {
    "text": "Sustainably could be another\nword you could put there. ",
    "start": "1059170",
    "end": "1064600"
  },
  {
    "text": "We'd like to think of\nthings in three steps. The first is discovery or\nsolving for the science.",
    "start": "1064600",
    "end": "1070679"
  },
  {
    "text": "The second is\ndevelopment or validating that the intent of what\nyou're trying to do",
    "start": "1070680",
    "end": "1075880"
  },
  {
    "text": "is going to pan out. And then the third is\ndissemination or scaling. And the three stages are\noutlined in this little blog",
    "start": "1075880",
    "end": "1084850"
  },
  {
    "text": "post for which the link is\nat the bottom of the slide around welcoming innovation.",
    "start": "1084850",
    "end": "1090190"
  },
  {
    "text": "But for standard AI, like\nwe've actually-- at least we have a decent worldview. We know what to do here.",
    "start": "1090190",
    "end": "1096640"
  },
  {
    "text": "The discovery is too\nslow, too costly. We know that. So we can attack it.",
    "start": "1096640",
    "end": "1102010"
  },
  {
    "text": "The development, we know we\nneed to focus on achievable benefit that plot I was showing\nyou how far down the list are",
    "start": "1102010",
    "end": "1108190"
  },
  {
    "text": "we going to get. And we know that we\nneed to calculate financial sustainability,\nand for that, we",
    "start": "1108190",
    "end": "1114858"
  },
  {
    "text": "might need to change\nbusiness models. So, for example, if\nyou're classifying hemorrhage or ischemic stroke,\nyou only have one air ambulance.",
    "start": "1114858",
    "end": "1121683"
  },
  {
    "text": "That's not going to work because\nwhat if three people need that particular facility.",
    "start": "1121683",
    "end": "1127120"
  },
  {
    "text": "So that's what feeds\ninto our FURM assessment. The link is right there,\nfurm.stanford.edu.",
    "start": "1127120",
    "end": "1135960"
  },
  {
    "text": "And then I'll walk you\nthrough the FURM assessment and then I'll just acknowledge\nthat the second column,",
    "start": "1135960",
    "end": "1141910"
  },
  {
    "text": "generative AI has a whole\nbunch of question marks and we'll come back to that. All right, so what do we\ndo in the FURM assessment?",
    "start": "1141910",
    "end": "1149160"
  },
  {
    "text": "Well, the first thing\nis the workflow. What are we going to do? So what I have on here\nis an example workflow",
    "start": "1149160",
    "end": "1154740"
  },
  {
    "text": "of a classifier that\nidentifies a person who might have undiagnosed\nPeripheral artery disease.",
    "start": "1154740",
    "end": "1160990"
  },
  {
    "text": "And then a whole bunch of\nthings happen, vascular medicine specialist looks at it. You might need to refer them to\na primary care doctor who then",
    "start": "1160990",
    "end": "1168120"
  },
  {
    "text": "refers them to a\nvascular specialist who does an ankle brachial index\ntest patient may decline it,",
    "start": "1168120",
    "end": "1174400"
  },
  {
    "text": "they may agree, and so on. The point here is not the\nexact steps in this workflow. The point is that\nwe need clarity",
    "start": "1174400",
    "end": "1181920"
  },
  {
    "text": "on the responsible action\nwhen we build the classifier. That's the key point.",
    "start": "1181920",
    "end": "1187440"
  },
  {
    "text": "When we build that\nmodel, that yellow box, this is the green box, the\npolicy and the workflow. What are we going to\ndo when, who does it,",
    "start": "1187440",
    "end": "1194120"
  },
  {
    "text": "and what is our\nthreshold for action. So we do this up front. This is directly\nfrom that form paper",
    "start": "1194120",
    "end": "1200120"
  },
  {
    "text": "so that you can look\nat it later as well. Now, in that same\nassessment and that",
    "start": "1200120",
    "end": "1206809"
  },
  {
    "text": "what and why the first step, we\nalso do an ethics assessment. We look at the\ndifferent considerations",
    "start": "1206810",
    "end": "1212480"
  },
  {
    "text": "about the workflow that\nis going to execute. Is it equitable? Is the model reliable?",
    "start": "1212480",
    "end": "1219340"
  },
  {
    "text": "Is there a governance\nprocess to decide if somebody disagrees with the\noutput or what's being done?",
    "start": "1219340",
    "end": "1224850"
  },
  {
    "text": "Is there autonomy\nin decision making or are people forced to go along\nwith what the model recommends?",
    "start": "1224850",
    "end": "1231070"
  },
  {
    "text": "I'm sure some of you have\nseen the coverage in Stat News about algorithms used\nby insurance companies",
    "start": "1231070",
    "end": "1236150"
  },
  {
    "text": "to deny care, and we don't want\nto fall into that kind of trap either. Again, better than done up\nfront in the first stage",
    "start": "1236150",
    "end": "1243860"
  },
  {
    "text": "before anything is deployed. And so this FURM assessment\nprocess helps us do that.",
    "start": "1243860",
    "end": "1250679"
  },
  {
    "text": "And then this little table is,\nagain, from the paper itself. It is about how we\nuse these assessments.",
    "start": "1250680",
    "end": "1257010"
  },
  {
    "text": "So this is about six cases,\nthe one we were looking at is the first row. And in the end, the summary\nboils down to how many people,",
    "start": "1257010",
    "end": "1264970"
  },
  {
    "text": "how many patients are impacted. So it's about 1,400 in that\nexample we've been looking at.",
    "start": "1264970",
    "end": "1270090"
  },
  {
    "text": "Is it sustainable? And are there any\nethical problems?",
    "start": "1270090",
    "end": "1276299"
  },
  {
    "text": "If a large number of people\nare going to benefit, there's no ethics problems\nas far as we can see,",
    "start": "1276300",
    "end": "1282450"
  },
  {
    "text": "and it's sustainable,\nthose are the projects we want to advance further. So it's like, upfront\nanalysis of so",
    "start": "1282450",
    "end": "1290550"
  },
  {
    "text": "that we can find good\nprojects to pursue. We also have to do\nsome capacity planning.",
    "start": "1290550",
    "end": "1296980"
  },
  {
    "text": "When you want to do responsible\nAI in a health care system, we can't just keep launching\nproject after project",
    "start": "1296980",
    "end": "1304150"
  },
  {
    "text": "after project. There's only a few\npeople in IT, and so we",
    "start": "1304150",
    "end": "1310240"
  },
  {
    "text": "did some basic operational\nengineering work and said, OK, if we want to do--",
    "start": "1310240",
    "end": "1315669"
  },
  {
    "text": "if it takes us about\nsix weeks or eight weeks to do this assessment for\nethics, financial projections,",
    "start": "1315670",
    "end": "1322190"
  },
  {
    "text": "workflow simulation, and so on,\nhow many concurrent assessments",
    "start": "1322190",
    "end": "1329320"
  },
  {
    "text": "do we need to be running so that\nwe can get through at least one per month?",
    "start": "1329320",
    "end": "1335010"
  },
  {
    "text": "And so it's something\ncalled Little's law, very simple, basic, operations\nengineering 101 level thing,",
    "start": "1335010",
    "end": "1341500"
  },
  {
    "text": "but it basically tells\nus we need a team that can handle two\nat the same time so that one is coming off the\nconveyor belt every month,",
    "start": "1341500",
    "end": "1348345"
  },
  {
    "text": "so to speak.  And all of this doesn't\nreally get us anywhere",
    "start": "1348345",
    "end": "1355078"
  },
  {
    "text": "unless there's good governance. So that's this life cycle of how\nwe make sure everything we say",
    "start": "1355078",
    "end": "1361760"
  },
  {
    "text": "we need done, does get done. So that FURM assessment\nis that yellow box in the center with a\nblack outline around it.",
    "start": "1361760",
    "end": "1369919"
  },
  {
    "text": "And this is our workflow. But the gist here for\na general audience is that on top is\nthe operational work",
    "start": "1369920",
    "end": "1377664"
  },
  {
    "text": "that your organization\nis already doing, like standard\nway of doing things.",
    "start": "1377665",
    "end": "1383060"
  },
  {
    "text": "Right below that is\nyour IT department supporting all of\nthat standard work. Those everybody has.",
    "start": "1383060",
    "end": "1388660"
  },
  {
    "text": "You need to add these\ntwo other things. The green row,\nwhich is governance. How are you going\nto make decisions",
    "start": "1388660",
    "end": "1394620"
  },
  {
    "text": "and whose job is it to say no? And then in order to make\nthose decisions, what are the analyzes,\nthese FURM assessments",
    "start": "1394620",
    "end": "1401700"
  },
  {
    "text": "that you're going\nto do to produce the numbers like patients\naffected, sustainability,",
    "start": "1401700",
    "end": "1408210"
  },
  {
    "text": "the absence of any harm\nto certain subgroups based on which your governance\nbody is going to make decisions.",
    "start": "1408210",
    "end": "1415420"
  },
  {
    "text": "So those are the\nfour key components. You have your standard\nwork, you have your IT team, you need governance, and\nthen this FURM assessment",
    "start": "1415420",
    "end": "1421920"
  },
  {
    "text": "process to figure\nout what's good, what's bad, what you should,\nwhat you should not do. So that's a summary of all of\nthe work on our campus on making",
    "start": "1421920",
    "end": "1430350"
  },
  {
    "text": "sure how we ensure\nthat the things we do with machine learning\nare fair, useful, reliable,",
    "start": "1430350",
    "end": "1437500"
  },
  {
    "text": "and all that. So all of this was nice\nand good till 2022,",
    "start": "1437500",
    "end": "1443580"
  },
  {
    "text": "and then along came LLMs. And this whole thing kind\nof got a little bit--",
    "start": "1443580",
    "end": "1449930"
  },
  {
    "text": "get a little bit turned around. And I showed you\nthat little table where the last column was empty\nor had two question marks.",
    "start": "1449930",
    "end": "1456210"
  },
  {
    "text": "So let's go through that. We have a couple of minutes. So remember this timeline.",
    "start": "1456210",
    "end": "1463320"
  },
  {
    "text": "Now, when we say\nlanguage, most of us will think of English,\nSpanish, German, Gujarati,",
    "start": "1463320",
    "end": "1469395"
  },
  {
    "text": "Hindi, what have you, some\nnatural language that humans use. But for a computer, a\n\"language'', and that's why I",
    "start": "1469395",
    "end": "1475320"
  },
  {
    "text": "put it in quotes, is a sequence\nof tokens that come from some",
    "start": "1475320",
    "end": "1480570"
  },
  {
    "text": "finite vocabulary,\nlike a dictionary. With that lens, the\npatient timeline",
    "start": "1480570",
    "end": "1487410"
  },
  {
    "text": "is a language\nbecause these tokens come from a finite dictionary.",
    "start": "1487410",
    "end": "1492700"
  },
  {
    "text": "ICD codes, CPT codes, LOINC\ncodes and things like that. So that \"EHR'' language which\nis at the bottom again put",
    "start": "1492700",
    "end": "1499230"
  },
  {
    "text": "in quotes because it's not a\nlanguage you and I can speak, is a sequence of tokens that\nthese two things happen at this",
    "start": "1499230",
    "end": "1506140"
  },
  {
    "text": "visit. This prescription was done. Then the second visit\nhappened at which something else happened. These are all codes\nthat we see in the data.",
    "start": "1506140",
    "end": "1515050"
  },
  {
    "text": "So if we take this\nworldview, now we have two ways of\nbuilding language models.",
    "start": "1515050",
    "end": "1521090"
  },
  {
    "text": "The top is the\nclassical language, as in natural language. We have text, we have documents,\nwe can learn a language model,",
    "start": "1521090",
    "end": "1529100"
  },
  {
    "text": "and that would help us do\nchat and summarization. That's the general\nway of using it.",
    "start": "1529100",
    "end": "1535370"
  },
  {
    "text": "But then we can\nuse these timelines that we've been talking about\nfor the past 20 minutes, and that would\nallow us to forecast",
    "start": "1535370",
    "end": "1541820"
  },
  {
    "text": "what is going to happen. And that's a unique way of using\nlanguage models or generative AI",
    "start": "1541820",
    "end": "1546890"
  },
  {
    "text": "in health care. And so again, I've been very\nsort of proponent of verifying",
    "start": "1546890",
    "end": "1555409"
  },
  {
    "text": "do these things\nwork as advertised? So for the general stuff,\nwhich is this blue thing, blue at the top, on our campus,\nwe did a couple of projects,",
    "start": "1555410",
    "end": "1563760"
  },
  {
    "text": "trying to ask, do these\nthings have benefit when used at the bedside?",
    "start": "1563760",
    "end": "1569040"
  },
  {
    "text": "So I'm going to show\nyou two examples and we can do more in\nthe Q&A. So on the left,",
    "start": "1569040",
    "end": "1574310"
  },
  {
    "text": "is we took some questions\nfrom that bedside service that we talked about at\nthe beginning of the talk.",
    "start": "1574310",
    "end": "1580200"
  },
  {
    "text": "And about 60 or so questions,\nand we submitted them to GPT 3.5",
    "start": "1580200",
    "end": "1585750"
  },
  {
    "text": "and to GPT 4. And then the answers were shown\nto 12 doctors with the task",
    "start": "1585750",
    "end": "1592200"
  },
  {
    "text": "to tell us whether the answers\nagreed with what we already knew, the reference\nanswer, they disagreed,",
    "start": "1592200",
    "end": "1597900"
  },
  {
    "text": "or they couldn't tell. And as you can see in the\nthree rows of that table, from GPT 3.5 to 4 agreement\ngoes up, disagreement goes down,",
    "start": "1597900",
    "end": "1607520"
  },
  {
    "text": "cannot tell goes down. So that's great. But the bottom row is about\n40% to 50% of the time the 12th",
    "start": "1607520",
    "end": "1615310"
  },
  {
    "text": "physicians couldn't\ndecide what was the case. So it's like having a\nperson at the bedside",
    "start": "1615310",
    "end": "1621860"
  },
  {
    "text": "giving you confident\nsounding suggestions and you can't tell whether\nthey're right or wrong.",
    "start": "1621860",
    "end": "1628440"
  },
  {
    "text": "Not high utility there. On the right, is the\ntasks doctors want",
    "start": "1628440",
    "end": "1636809"
  },
  {
    "text": "done using language models. There is an example, we had\nthis project called MedAlign, and what we did was to ask how\naligned are the language model",
    "start": "1636810",
    "end": "1645750"
  },
  {
    "text": "outputs for medical needs. So hence MedAlign. So a task might be something\nsummarize from the EHR",
    "start": "1645750",
    "end": "1654190"
  },
  {
    "text": "the strokes the patient\nhad and their associated neurological deficits. And that has to be done in the\ncontext of a given patient's",
    "start": "1654190",
    "end": "1660660"
  },
  {
    "text": "EHR. So we had about 15 clinicians\ntype out the correct answer",
    "start": "1660660",
    "end": "1667830"
  },
  {
    "text": "after reading the EHR,\nthat's in the yellow box. And then we gave\nthe same instruction",
    "start": "1667830",
    "end": "1672870"
  },
  {
    "text": "and the medical record\nto a language model, and it fills out the green box.",
    "start": "1672870",
    "end": "1678013"
  },
  {
    "text": "Well, it turns out\neven in the best case setup, 35% error\nrate in answering",
    "start": "1678013",
    "end": "1684390"
  },
  {
    "text": "these kinds of medical prompts. So that's what\nhappens when we're",
    "start": "1684390",
    "end": "1690200"
  },
  {
    "text": "looking at these\noff-the-shelf chat and summarization\nregular language models.",
    "start": "1690200",
    "end": "1697610"
  },
  {
    "text": "What about the other\nside, the red side? So I'll show you this one plot. Now we're trying to train\nmodels that forecast.",
    "start": "1697610",
    "end": "1705470"
  },
  {
    "text": "And so on the X-axis here, I\nhave number of positive examples",
    "start": "1705470",
    "end": "1710870"
  },
  {
    "text": "based on which I'm going\nto make my forecasting classifier or my predictor.",
    "start": "1710870",
    "end": "1716539"
  },
  {
    "text": "On the Y-axis is the\nperformance receiver operator curve in\nthis particular case.",
    "start": "1716540",
    "end": "1722090"
  },
  {
    "text": "We tried a whole bunch of\nthings the gradient boosted models, logistic regression,\nrandom forest, those were",
    "start": "1722090",
    "end": "1728150"
  },
  {
    "text": "the orange, yellow,\nand blue, which somehow has gotten removed. And then there's\nthe dark blue, which",
    "start": "1728150",
    "end": "1734120"
  },
  {
    "text": "is the timeline\ntrained language model. And as you can see, the blue\nline, the dark blue line",
    "start": "1734120",
    "end": "1741670"
  },
  {
    "text": "is always on top\nof the other lines. That's just for a\nhigher accuracy, period.",
    "start": "1741670",
    "end": "1748230"
  },
  {
    "text": "But the fun part is, if you look\nat on the X-axis, the number",
    "start": "1748230",
    "end": "1753540"
  },
  {
    "text": "where it says about 64,\nand then follow it up, you will find a blue dot at the\nAURs of about 78 or something.",
    "start": "1753540",
    "end": "1763590"
  },
  {
    "text": "But that blue dot is on par\nor better than the highest red, orange, or light blue dot.",
    "start": "1763590",
    "end": "1769560"
  },
  {
    "text": "Which means by\nusing these methods, I can train a\nlanguage model or I",
    "start": "1769560",
    "end": "1775320"
  },
  {
    "text": "can train a predictor that is\nas good or better than I could train with classical methods\nusing all available training",
    "start": "1775320",
    "end": "1783390"
  },
  {
    "text": "data. So not only do I get 3\nto 19% higher accuracy, it trains eight times faster\nand uses 95% less training data.",
    "start": "1783390",
    "end": "1793130"
  },
  {
    "text": "And we have publicly released\nthese kinds of models, we call them climber and\nmotor if you Google around",
    "start": "1793130",
    "end": "1798610"
  },
  {
    "text": "on GitHub or so on. All right. So that basically brings me\nback to wrapping this up.",
    "start": "1798610",
    "end": "1805880"
  },
  {
    "text": "And in the case of\nlanguage models or gen AI, I think we need to focus on this\npurple box, which is verifying",
    "start": "1805880",
    "end": "1814300"
  },
  {
    "text": "benefits, razor focus on that. There's lots of tech\ncompanies building models.",
    "start": "1814300",
    "end": "1821240"
  },
  {
    "text": "Cost millions of dollars,\nhundreds of millions of dollars, which academic\nsites cannot afford.",
    "start": "1821240",
    "end": "1826549"
  },
  {
    "text": "But we are the ones who can\nask these hard questions. Do these things actually\ndo as advertised?",
    "start": "1826550",
    "end": "1835200"
  },
  {
    "text": "That brings me to\nthis closeout, which is for the generative\nAI, the last column,",
    "start": "1835200",
    "end": "1841380"
  },
  {
    "text": "we need to develop\nthis worldview. And so I've added\na citation there, which wasn't there on\nthe previous slide.",
    "start": "1841380",
    "end": "1847950"
  },
  {
    "text": "And I don't know how the\ndevelopment and dissemination for this is going to scale. Is there ROI? Like, I don't know.",
    "start": "1847950",
    "end": "1853740"
  },
  {
    "text": "I'm not yet convinced. And you see article after\narticle coming out saying,",
    "start": "1853740",
    "end": "1859290"
  },
  {
    "text": "maybe not. There's five articles\nin the New York times that say is AI better\nthan doctors or not, and giving conflicting answers.",
    "start": "1859290",
    "end": "1865920"
  },
  {
    "text": "But the one thing\nI can say for sure is that we have to focus\non verifying benefits. Like that has to be there.",
    "start": "1865920",
    "end": "1873780"
  },
  {
    "text": "All right. So that basically\nbrings me to the end of this conversation in terms\nof how we think about building",
    "start": "1873780",
    "end": "1880300"
  },
  {
    "text": "fair, useful, reliable\nmodels on our campus and the class where we'll\nshare that with you.",
    "start": "1880300",
    "end": "1885650"
  },
  {
    "text": "And you got a little\npreview today. JACKIE PETERSON: Great. Thanks, Dr. Shah,\nfor taking the time",
    "start": "1885650",
    "end": "1891190"
  },
  {
    "text": "to share your knowledge\nwith us today. First question here. ",
    "start": "1891190",
    "end": "1897899"
  },
  {
    "text": "How do you separate the data\nengineering versus data science work given how spread out and\nunruly health care data can be?",
    "start": "1897900",
    "end": "1905790"
  },
  {
    "text": "I often feel like I only do data\nwrangling or database creation. Is that still useful overall?",
    "start": "1905790",
    "end": "1911299"
  },
  {
    "text": " NIGAM SHAH: Those\ntwo functions-- data engineering\nand data science",
    "start": "1911300",
    "end": "1918059"
  },
  {
    "text": "have to live side by side. In fact, at our institution,\nwe put it in the same team.",
    "start": "1918060",
    "end": "1925350"
  },
  {
    "text": "We just call the team\ndata science team, but it has more data engineers\nthan data scientists.",
    "start": "1925350",
    "end": "1931330"
  },
  {
    "text": "And you need to have this\narrangement where they're not on the other side of the\nfence like throwing data",
    "start": "1931330",
    "end": "1937110"
  },
  {
    "text": "at each other, so to speak. But they have to\nwork collaboratively because what the\nscience that needs done",
    "start": "1937110",
    "end": "1943169"
  },
  {
    "text": "will dictate the engineering,\nthe extraction, the cleanup, and all that. And decisions will be\nmade during the cleanup",
    "start": "1943170",
    "end": "1950010"
  },
  {
    "text": "and extraction that affect\nthe kind of science you can and cannot do. So those two things like hand\nin glove, have to work together.",
    "start": "1950010",
    "end": "1956660"
  },
  {
    "text": " JACKIE PETERSON:\nAnd then once you have your data usable,\nhow long does it",
    "start": "1956660",
    "end": "1963590"
  },
  {
    "text": "take from when you start\nanalyzing or modeling the data to when you come\nup with something that's presentable?",
    "start": "1963590",
    "end": "1969940"
  },
  {
    "text": "NIGAM SHAH: So that depends\non the team maturity. So the first time, it\nalways takes way longer.",
    "start": "1969940",
    "end": "1976950"
  },
  {
    "text": "And as you do multiple\nreplications through that, it gets faster and\ncheaper and more reliable.",
    "start": "1976950",
    "end": "1983879"
  },
  {
    "text": "So to give exact\nnumbers, the first time we did something end-to-end,\nlike we didn't have a team,",
    "start": "1983880",
    "end": "1988920"
  },
  {
    "text": "everybody's\nvolunteering their time, and we're coordinating over\nemail, and Friday nights,",
    "start": "1988920",
    "end": "1995210"
  },
  {
    "text": "and so on, it took us five\nyears to seven years end-to-end. OK, a really long time.",
    "start": "1995210",
    "end": "2002260"
  },
  {
    "text": "The next time we did\nsomething, but we're building the platforms, the\nwork procedures, and everything",
    "start": "2002260",
    "end": "2008560"
  },
  {
    "text": "necessary to do what we\ndid over five, seven years and then redo it in\na production setting,",
    "start": "2008560",
    "end": "2015550"
  },
  {
    "text": "let's say it took us\na year and a half. The third time we do something,\nwe can do it in four months.",
    "start": "2015550",
    "end": "2021730"
  },
  {
    "text": "And hopefully, the next time\nwe'll be down to a month. So that sort of\ngives you a way of-- as you do these replications,\nyou can keep reducing by 50%,",
    "start": "2021730",
    "end": "2032150"
  },
  {
    "text": "and in three or four\nreplications, you get to a stage where you're quite mature.",
    "start": "2032150",
    "end": "2038070"
  },
  {
    "text": "Practice. JACKIE PETERSON: And\nthen the next question is, how do you account for\nthe accuracy of EHR data?",
    "start": "2038070",
    "end": "2047555"
  },
  {
    "text": "NIGAM SHAH: EHR data, you\nhave to take it as a given that they're noisy, they\nhave errors, and so on.",
    "start": "2047555",
    "end": "2053520"
  },
  {
    "text": "So for anything you\ncan include, always look for multiple\nlines of corroboration. So, for example, just because\nthere's a code for diabetes,",
    "start": "2053520",
    "end": "2061360"
  },
  {
    "text": "you can't believe it. You have to look at the HbA1C. You have to look at medications. For everything, you\nwant at least two",
    "start": "2061360",
    "end": "2067569"
  },
  {
    "text": "or three independent\npieces of information confirming or\ncorroborating that fact.",
    "start": "2067570",
    "end": "2073533"
  },
  {
    "text": " JACKIE PETERSON: Is\nStanford training its own",
    "start": "2073534",
    "end": "2080060"
  },
  {
    "text": "on medical analysis? NIGAM SHAH: Short answer, no.",
    "start": "2080060",
    "end": "2085250"
  },
  {
    "text": "We did try. But the way and the pace at\nwhich this field is moving, I think it's more efficient\nto take an open source",
    "start": "2085250",
    "end": "2094190"
  },
  {
    "text": "model with no copyright\nissues and then continue its fine training as opposed\nto trained from scratch.",
    "start": "2094190",
    "end": "2101099"
  },
  {
    "text": "Training from\nscratch is expensive.  JACKIE PETERSON: Another\nquestion coming in here",
    "start": "2101100",
    "end": "2107570"
  },
  {
    "text": "is what are the most promising\napplications of machine learning in medicine and how can they\nimprove patient outcomes",
    "start": "2107570",
    "end": "2113390"
  },
  {
    "text": "and health efficiency? And do you think that's\npossible to develop--",
    "start": "2113390",
    "end": "2119630"
  },
  {
    "text": "it says develop it\nin low countries. I'm not sure. NIGAM SHAH: Low\nresource, low resource.",
    "start": "2119630",
    "end": "2124895"
  },
  {
    "text": "JACKIE PETERSON: Low\nresource countries. NIGAM SHAH: So I\nthink you definitely have to look at the structural\nissues of the health care",
    "start": "2124895",
    "end": "2134240"
  },
  {
    "text": "system in which the\nwork is being done. So I like breaking things up\ninto either science practice",
    "start": "2134240",
    "end": "2140640"
  },
  {
    "text": "delivery or you could just\nsay clinical and non-clinical to keep it simple and\njust have two buckets.",
    "start": "2140640",
    "end": "2147329"
  },
  {
    "text": "Depending on the\nenvironment, you might prioritize differently. And I'll give an example.",
    "start": "2147330",
    "end": "2152460"
  },
  {
    "text": "Here at least in the\nUS, in academic centers, we typically deal with\ncomplex clinical cases",
    "start": "2152460",
    "end": "2159810"
  },
  {
    "text": "and hence trying to throw a\nnew technology at something that a human trained\n10 years to do,",
    "start": "2159810",
    "end": "2166000"
  },
  {
    "text": "probably not the wisest\nuse of the technology. And so operational applications\nsuch as transcription,",
    "start": "2166000",
    "end": "2172600"
  },
  {
    "text": "responding to messages, billing\napplications, and so on, tend to have higher\npenetrance and adoption.",
    "start": "2172600",
    "end": "2182220"
  },
  {
    "text": "But if you're in\na resource setting where you have to do iCare\nmanagement for a whole bunch",
    "start": "2182220",
    "end": "2188670"
  },
  {
    "text": "of diabetics, and your\nchoices are they get no iCare, or you can use a retinal\nscanning algorithm that",
    "start": "2188670",
    "end": "2197350"
  },
  {
    "text": "might not be perfect\nas an ophthalmologist, but is 90% of the\nway there, you might",
    "start": "2197350",
    "end": "2202930"
  },
  {
    "text": "choose to do differently\nand use AI for clinical care because your option\nalternative, there is no care.",
    "start": "2202930",
    "end": "2209690"
  },
  {
    "text": "And so I think the choice you\nmake and what's deemed important is definitely affected\nby the circumstances",
    "start": "2209690",
    "end": "2216760"
  },
  {
    "text": "in which that technology\nis going to be deployed.  JACKIE PETERSON: Is there an\nexample where academic work was",
    "start": "2216760",
    "end": "2224860"
  },
  {
    "text": "applied to solve real-life\nproblems in the health care industry? NIGAM SHAH: Many, many.",
    "start": "2224860",
    "end": "2230770"
  },
  {
    "text": "So I'll cite just one if you\nsearch for Stanford Health Care,",
    "start": "2230770",
    "end": "2235850"
  },
  {
    "text": "H-I-M-S-S HIMSS\nDavies, D-A-V-I-E-S,",
    "start": "2235850",
    "end": "2240970"
  },
  {
    "text": "you'll find more details on our\nwork on predicting mortality",
    "start": "2240970",
    "end": "2246430"
  },
  {
    "text": "for improving advanced\ncare planning. And over the years, this\nthing has been around.",
    "start": "2246430",
    "end": "2251450"
  },
  {
    "text": "It's improved the care\nof over 6,000 patients, and that's what we\ngot the award for.",
    "start": "2251450",
    "end": "2257088"
  },
  {
    "text": "JACKIE PETERSON: These\nare great questions. So keep submitting these\nquestions in the Q&A because we still have some\nmore time for Dr. Shah.",
    "start": "2257088",
    "end": "2263700"
  },
  {
    "text": "Is generative AI applicable\nin behavioral health aside from the clinical setting?",
    "start": "2263700",
    "end": "2271025"
  },
  {
    "text": "NIGAM SHAH: That's a tough one. I have personally\nnot worked with using generative AI, particularly\nchatbots for mental health.",
    "start": "2271025",
    "end": "2278830"
  },
  {
    "text": "I know there's a lot of\neffort going in that space. But on the flip side, there's\nalso ridiculous errors.",
    "start": "2278830",
    "end": "2286360"
  },
  {
    "text": "Like there was this\nincident about Gemini telling a high schooler to\ngo kill themselves while it",
    "start": "2286360",
    "end": "2291599"
  },
  {
    "text": "was giving homework advice. So I see the\npotential, but I would",
    "start": "2291600",
    "end": "2297210"
  },
  {
    "text": "say haven't yet made up my\nmind if that is the best use of the technology today. JACKIE PETERSON: How do you\nfigure out patients involvement",
    "start": "2297210",
    "end": "2306299"
  },
  {
    "text": "in implementing the FEMR model? NIGAM SHAH: So here\nwe have something",
    "start": "2306300",
    "end": "2313440"
  },
  {
    "text": "called a patient family\nadvisory council. And so in training the model\nis done with de-identified data",
    "start": "2313440",
    "end": "2321060"
  },
  {
    "text": "and the patients\nalready consented for use of their de-identified\ndata for research.",
    "start": "2321060",
    "end": "2326190"
  },
  {
    "text": "But then once the\nmodel is trained and you're using it to\nsay, predict or classify",
    "start": "2326190",
    "end": "2331470"
  },
  {
    "text": "peripheral artery\ndisease or what have you, that workflow that\nI was showing you,",
    "start": "2331470",
    "end": "2338240"
  },
  {
    "text": "is shown to a patient\nfamily advisory council. The actions we're going to\ntake are also shared with them",
    "start": "2338240",
    "end": "2344900"
  },
  {
    "text": "to make sure that if you put\nyourself in the patient's shoes, they would feel comfortable\nwith an algorithm nudging care",
    "start": "2344900",
    "end": "2351740"
  },
  {
    "text": "one way or the other. You're absolutely right\nthat a lot of times",
    "start": "2351740",
    "end": "2357650"
  },
  {
    "text": "is the developers of\nthe algorithms making those judgments\nor pronouncements. And I don't think\nthat is appropriate.",
    "start": "2357650",
    "end": "2363060"
  },
  {
    "text": "It is necessary to have\nmultiple stakeholders, at the minimum, the clinician\nusers, the patients,",
    "start": "2363060",
    "end": "2369430"
  },
  {
    "text": "and the administrators\napart from the developers of the algorithm. ",
    "start": "2369430",
    "end": "2375590"
  },
  {
    "text": "JACKIE PETERSON: What are\nthe practical examples of using machine learning in\nlaboratories like in histology,",
    "start": "2375590",
    "end": "2382579"
  },
  {
    "text": "cytology, or flow cytometry? NIGAM SHAH: So our\npathology department",
    "start": "2382580",
    "end": "2390200"
  },
  {
    "text": "has some quite interesting work. In fact, a faculty\nmember, James Zou, has an effort to have\na deep neural net that",
    "start": "2390200",
    "end": "2399170"
  },
  {
    "text": "can become your extension. And I think the effort\nis called nuclei.io.",
    "start": "2399170",
    "end": "2404874"
  },
  {
    "text": " Just like you have your own\nspell checker and something that",
    "start": "2404874",
    "end": "2410060"
  },
  {
    "text": "helps you improve\nyour documents, it helps you read your slides. And it will find the\nportions of the slide",
    "start": "2410060",
    "end": "2416240"
  },
  {
    "text": "that a human should see. And then it also learns\nfrom your behavior.",
    "start": "2416240",
    "end": "2421590"
  },
  {
    "text": "So it kind of becomes\nan AI that you have trained to behave like\nyou and augment your work.",
    "start": "2421590",
    "end": "2426970"
  },
  {
    "text": "So there's lots of stuff\nlike that happening. I would say the cell sorter,\nwhich gives you a CVC based",
    "start": "2426970",
    "end": "2435260"
  },
  {
    "text": "on shining some laser and\ndoing some calculation, is probably amongst the most\nwidely used AI in every health",
    "start": "2435260",
    "end": "2441980"
  },
  {
    "text": "care system. Nobody counts white blood cells\nby looking through a microscope and using a cell\ncounter anymore.",
    "start": "2441980",
    "end": "2449150"
  },
  {
    "text": "So there's a pretty\nbroad range in pathology. On the one hand, you\ncould say the cell sorters, which have been\naround for several decades now,",
    "start": "2449150",
    "end": "2456060"
  },
  {
    "text": "is the most prevalent\nin pathology. And the other end\nis this fancy things that help you read your\nslide and then stuff",
    "start": "2456060",
    "end": "2461930"
  },
  {
    "text": "in between for sure. JACKIE PETERSON: What do you see\nas the most critical data gaps",
    "start": "2461930",
    "end": "2468530"
  },
  {
    "text": "in current EHR systems, and how\nis Stanford Medicine addressing them?",
    "start": "2468530",
    "end": "2474261"
  },
  {
    "text": "NIGAM SHAH: I would say the\nbiggest gaps are that we have-- it's different to call it a gap.",
    "start": "2474261",
    "end": "2480220"
  },
  {
    "text": "The biggest issues are that\nwe have too many systems. A typical hospital runs anywhere\nfrom 500 to 1,000 IT systems.",
    "start": "2480220",
    "end": "2490420"
  },
  {
    "text": "And Epic is one of them\nor Cerner or whatever EHR system is. And then you'll\nhave a PACS system,",
    "start": "2490420",
    "end": "2495880"
  },
  {
    "text": "and have a lab system, and\nan ophthalmology system, and a surgery video system, and\nanesthesia system, and so on.",
    "start": "2495880",
    "end": "2502119"
  },
  {
    "text": "So I think it is a myth to\nbelieve that all medical data is",
    "start": "2502120",
    "end": "2507370"
  },
  {
    "text": "in the EHR. In fact, it is scattered\nover hundreds of IT systems.",
    "start": "2507370",
    "end": "2513280"
  },
  {
    "text": "And I think that\nis the biggest gap, or you could say the biggest\nopportunity to combine and put",
    "start": "2513280",
    "end": "2518470"
  },
  {
    "text": "it in one place. JACKIE PETERSON:\nHow do you advocate for removing bias in predictions\nmade by these models?",
    "start": "2518470",
    "end": "2525670"
  },
  {
    "text": "NIGAM SHAH: So I have a pretty\nnon-traditional view on it. So whenever the word\nbias gets mentioned,",
    "start": "2525670",
    "end": "2534460"
  },
  {
    "text": "I think of two things. One interpretation\nof that is that there is a systematic\ndifference in the models",
    "start": "2534460",
    "end": "2541450"
  },
  {
    "text": "performance for people belonging\nto different subgroups. And I didn't use the word\nbias, systematic difference",
    "start": "2541450",
    "end": "2547840"
  },
  {
    "text": "in the models performance. And then another\ninterpretation of the word bias is that there's a\nsystematic difference",
    "start": "2547840",
    "end": "2553600"
  },
  {
    "text": "in the accrual of some\nbenefit the action or its reward that we're going\nto do as a result of the model's",
    "start": "2553600",
    "end": "2560260"
  },
  {
    "text": "output. And we don't want\nsystematic difference for people belonging\nto different subgroups.",
    "start": "2560260",
    "end": "2566540"
  },
  {
    "text": "And so the kind of bias to\nworry about is the latter.",
    "start": "2566540",
    "end": "2572090"
  },
  {
    "text": "We want to make sure that\nthe model plus the workflow when they're used\ntogether, there",
    "start": "2572090",
    "end": "2579320"
  },
  {
    "text": "is no systematic\ndifference in the accrual of benefit to people belonging\nto different subgroups.",
    "start": "2579320",
    "end": "2586579"
  },
  {
    "text": "And so that is dependent\nless on the model and more on our policies\nand the workflows that",
    "start": "2586580",
    "end": "2594560"
  },
  {
    "text": "are driven by the model output. And so I would\nencourage focusing on those as opposed to just\nremoving the model side",
    "start": "2594560",
    "end": "2603530"
  },
  {
    "text": "differences. In fact, we have a\nblog post many years ago now at the Human\nCentered AI Institute",
    "start": "2603530",
    "end": "2609500"
  },
  {
    "text": "about when algorithmic\nfixes fail. So if you search\nfor that, you'll basically find this breakdown\nand some suggestions",
    "start": "2609500",
    "end": "2616609"
  },
  {
    "text": "on if it doesn't work\nthat you can beat out the difference from the\nmodel, what else can you do to make sure that\nthe accrual of benefit",
    "start": "2616610",
    "end": "2622940"
  },
  {
    "text": "doesn't remain\nsystematically different. ",
    "start": "2622940",
    "end": "2628302"
  },
  {
    "text": "JACKIE PETERSON: Are\ntraceability, explainability requirements slowing\ndown progress of AI model advancements?",
    "start": "2628302",
    "end": "2636160"
  },
  {
    "text": "NIGAM SHAH: So\nshort answer, yes. But the right answer\nis kind of it depends.",
    "start": "2636160",
    "end": "2643579"
  },
  {
    "text": "So I'll cite another\nblog post which is about, should models be explainable?",
    "start": "2643580",
    "end": "2650270"
  },
  {
    "text": "And on that, if you\nGoogle for that, it's one of our HAI blog posts.",
    "start": "2650270",
    "end": "2655369"
  },
  {
    "text": "It breaks down\nthis notion or need for explainability,\ninterpretability,",
    "start": "2655370",
    "end": "2660980"
  },
  {
    "text": "or transparency. Those three kind of\nwords get used semi interchangeably\ninto its purpose.",
    "start": "2660980",
    "end": "2668210"
  },
  {
    "text": "So sometimes you want that\nin order to debug your system and we call that the\nengineers interpretability.",
    "start": "2668210",
    "end": "2675770"
  },
  {
    "text": "Sometimes you want\nto know so that you can get an idea of what you can\ndo to mitigate that outcome.",
    "start": "2675770",
    "end": "2682890"
  },
  {
    "text": "So that you need causal\ninterpretability. And sometimes what you need\nis you just want to see that",
    "start": "2682890",
    "end": "2689760"
  },
  {
    "text": "so that you can decide whether\nyou can trust it or not. And so the needs of these\nthree different scenarios",
    "start": "2689760",
    "end": "2696640"
  },
  {
    "text": "are quite different. So if you imagine them as three\ncircles and make a Venn diagram, you get seven zones.",
    "start": "2696640",
    "end": "2702700"
  },
  {
    "text": "So you need to know\nwhat is the purpose somebody is asking\nfor explainability",
    "start": "2702700",
    "end": "2709180"
  },
  {
    "text": "or interpretability. And then if the purpose\nis to establish trust",
    "start": "2709180",
    "end": "2714580"
  },
  {
    "text": "and you keep providing the\nengineering explanation, in fact, it might set you back. And what you might need to do is\nliterally do a prospective study",
    "start": "2714580",
    "end": "2722829"
  },
  {
    "text": "to establish trust in\na randomized setting. Like most physicians,\nmy physician friends",
    "start": "2722830",
    "end": "2730200"
  },
  {
    "text": "can't explain to me\nhow Tylenol works. But we trust it because it's\nbeen tested so many times.",
    "start": "2730200",
    "end": "2736730"
  },
  {
    "text": "Same thing for a lot of drugs. I mean, there's 4,900 or so\ndrugs, and for a lot of them, we don't know how they work.",
    "start": "2736730",
    "end": "2742630"
  },
  {
    "text": "But we have tested them\nprospectively to establish the trust that they do work. ",
    "start": "2742630",
    "end": "2750310"
  },
  {
    "text": "JACKIE PETERSON: Are\nthere any studies to compare error rates in\nmedical diagnosis and treatment",
    "start": "2750310",
    "end": "2755480"
  },
  {
    "text": "with assistance from AI models\nversus when it is only based on human effort without AI? NIGAM SHAH: Yes, there's a\ncouple of efforts already.",
    "start": "2755480",
    "end": "2763190"
  },
  {
    "text": "Now, like the most recent one I\nknow of is a colleague of mine, Jonathan Chen, where they\ngave a few case vignettes",
    "start": "2763190",
    "end": "2771200"
  },
  {
    "text": "to physicians, gave the exact\nsame case vignettes to GPT 4, and then gave doctors those case\nvignettes and access to GPT 4",
    "start": "2771200",
    "end": "2779480"
  },
  {
    "text": "and said, hey, use\nAI to help yourself. And the finding was not\nwhat everybody expected.",
    "start": "2779480",
    "end": "2785450"
  },
  {
    "text": "It turns out that when doctors\nare given access to AI, they sometimes shoot themselves\nin the foot and make mistakes.",
    "start": "2785450",
    "end": "2792900"
  },
  {
    "text": "So JUST AI was better\nthan Doctor Plus AI. You can conclude all\nsorts of fun things,",
    "start": "2792900",
    "end": "2798330"
  },
  {
    "text": "but in Jonathan's own\ntelling, part of the reason seems to be that\nthe physicians that",
    "start": "2798330",
    "end": "2804590"
  },
  {
    "text": "were given those vignettes\nthey didn't really know how to use the AI,\nso they were using it",
    "start": "2804590",
    "end": "2809779"
  },
  {
    "text": "in a very suboptimal setting. They were using it more like\na search engine, so to speak.",
    "start": "2809780",
    "end": "2815099"
  },
  {
    "text": "And so I think more work needs\nto be done so that we know how",
    "start": "2815100",
    "end": "2820860"
  },
  {
    "text": "these things can be used\nin practice as opposed to just ask the question,\nshould they be used or not.",
    "start": "2820860",
    "end": "2828013"
  },
  {
    "text": "JACKIE PETERSON:\nThe next question is are full EHRs can be\nconsidered the raw material to teach AI, do you agree?",
    "start": "2828013",
    "end": "2834865"
  },
  {
    "text": " NIGAM SHAH: Not\nentirely, because you",
    "start": "2834865",
    "end": "2842230"
  },
  {
    "text": "do want the stuff\nfrom the textbooks and sort of a sanitized version\nof online sources UpToDate",
    "start": "2842230",
    "end": "2850210"
  },
  {
    "text": "or PubMed or what have you. I wouldn't make EHRs the only\nthing to train an AI model",
    "start": "2850210",
    "end": "2857320"
  },
  {
    "text": "or teach an AI model. But yes, it is one\nof the raw materials. JACKIE PETERSON: It says\nother than GE PACS-AI,",
    "start": "2857320",
    "end": "2864799"
  },
  {
    "text": "are there any practical\nmedical imaging AI in work? NIGAM SHAH: Tons I mean, I'm not\npersonally working on medical",
    "start": "2864800",
    "end": "2872550"
  },
  {
    "text": "imaging models, but if you look\nat the FDA's, SaMD approvals,",
    "start": "2872550",
    "end": "2879490"
  },
  {
    "text": "about 992, or roughly\n1,000 things approved, but half or more of\nthem are image-based.",
    "start": "2879490",
    "end": "2886470"
  },
  {
    "text": "2/3 of them radiology,\nthe other cardiology. JACKIE PETERSON: OK.",
    "start": "2886470",
    "end": "2892810"
  },
  {
    "text": "I think that's\nour last question. If there's any more\nquestions, go ahead and put them in the Q&A box.",
    "start": "2892810",
    "end": "2900560"
  },
  {
    "text": "If not, we can move on. But I think that\nwas our last one.",
    "start": "2900560",
    "end": "2905805"
  },
  {
    "text": " All right. So in that case, we can wrap up.",
    "start": "2905805",
    "end": "2913069"
  },
  {
    "text": "So thank you for sharing\nyour questions with us. And again, if you want to\nlearn more from Dr. Shah,",
    "start": "2913070",
    "end": "2922180"
  },
  {
    "text": "feel free to join our\napplications of machine learning and medicine program. You can also explore more\nfrom the Stanford Center",
    "start": "2922180",
    "end": "2928563"
  },
  {
    "text": "for Health Education by visiting\nhealtheducation.stanford.edu.",
    "start": "2928563",
    "end": "2934270"
  },
  {
    "text": "We'll also be sending\nout a recording of this session via\nemail very soon, so feel",
    "start": "2934270",
    "end": "2940660"
  },
  {
    "text": "free to revisit this content. And again, thank you\nfor joining us today. We hope you have a great week.",
    "start": "2940660",
    "end": "2947150"
  },
  {
    "text": "We hope to see you again\nin our next session. So thank you. NIGAM SHAH: Thank you. Thanks for having me. JACKIE PETERSON:\nThanks, Dr. Shah.",
    "start": "2947150",
    "end": "2953247"
  },
  {
    "text": "This is great. ",
    "start": "2953247",
    "end": "2955000"
  }
]
[
  {
    "start": "0",
    "end": "5390"
  },
  {
    "text": "OK. Let's just get started. Welcome to lecture 14, everyone.",
    "start": "5390",
    "end": "12200"
  },
  {
    "text": "I hope you've been\ndoing well and managing",
    "start": "12200",
    "end": "17450"
  },
  {
    "text": "all of the various deadlines. So today, we'll be looking at\ntwo interesting applications",
    "start": "17450",
    "end": "24289"
  },
  {
    "text": "of language models. The first half I'll be talking\nabout using language models",
    "start": "24290",
    "end": "29390"
  },
  {
    "text": "to reason in domains like\nmath, geometry, doing things like spatial reasoning.",
    "start": "29390",
    "end": "35820"
  },
  {
    "text": "And then in the second\nhalf of the lecture, I'll be talking\nabout how you can use language models\nto take actions",
    "start": "35820",
    "end": "42140"
  },
  {
    "text": "in grounded environments. OK. So a little bit of a disclaimer.",
    "start": "42140",
    "end": "48930"
  },
  {
    "text": "A lot of the content\ntoday is research that was done in the\nlast three, four years.",
    "start": "48930",
    "end": "54030"
  },
  {
    "text": "So there's plenty of questions,\nplenty of unanswered questions, and not a lot of for answers.",
    "start": "54030",
    "end": "60440"
  },
  {
    "text": "So let's-- maybe we can have\nmore of a discussion around",
    "start": "60440",
    "end": "66159"
  },
  {
    "text": "these topics, OK? OK. So let's get started\nwith reasoning.",
    "start": "66160",
    "end": "72310"
  },
  {
    "text": "So experts like to start\na lecture on reasoning by really talking about what are\nthe various kinds of reasoning,",
    "start": "72310",
    "end": "78710"
  },
  {
    "text": "so I'm going to\ndo that here, OK? But at a high level, it's really\nabout using facts and logic to arrive at an answer, OK?",
    "start": "78710",
    "end": "85452"
  },
  {
    "text": "But more concretely, there's\nthree distinct categories of reasoning that\nwe can talk about.",
    "start": "85452",
    "end": "91790"
  },
  {
    "text": "The first one, which is probably\nthe one that most of you are familiar with, is\ndeductive reasoning,",
    "start": "91790",
    "end": "97429"
  },
  {
    "text": "where we go from rules of logic\nalong with a premise to come up",
    "start": "97430",
    "end": "103360"
  },
  {
    "text": "with a firm conclusion. So an example of\nthat could be that we have the sentence all mammals\nhave kidneys and all whales",
    "start": "103360",
    "end": "111910"
  },
  {
    "text": "are mammals. And then we can come\nup with the conclusion, all whales have kidneys. And we could do multiple\nsuch steps of reasoning, OK?",
    "start": "111910",
    "end": "120090"
  },
  {
    "text": "A second form of\nreasoning is inductive, where given observations,\nwe derive conclusions, OK?",
    "start": "120090",
    "end": "128688"
  },
  {
    "text": "So maybe we've learned\nfrom experience that every time we see\na creature with wings,",
    "start": "128689",
    "end": "135720"
  },
  {
    "text": "it is usually a bird. And let's say we\nobserve a state where",
    "start": "135720",
    "end": "142580"
  },
  {
    "text": "we see a creature with wings. And using our using\nour experience, we can come up with\nthis conclusion",
    "start": "142580",
    "end": "148130"
  },
  {
    "text": "that the creature is\nlikely to be a bird. So that form of reasoning\nis inductive, OK? And finally, we have\nabductive reasoning",
    "start": "148130",
    "end": "156590"
  },
  {
    "text": "where we're given an\nobservation and then we start drawing possible\nexplanations, OK?",
    "start": "156590",
    "end": "162790"
  },
  {
    "text": "So maybe you see a\ncar that cannot start, and there's a puddle of\nliquid under the engine.",
    "start": "162790",
    "end": "169500"
  },
  {
    "text": "And then you start drawing\ninferences about the situation. So one of them could be that the\ncar has a leak in the radiator,",
    "start": "169500",
    "end": "176190"
  },
  {
    "text": "OK? All right. And apart from that\ntaxonomy, we can also",
    "start": "176190",
    "end": "181920"
  },
  {
    "text": "think of reasoning in\nformal and informal terms, where formal reasoning\ninvolves using",
    "start": "181920",
    "end": "187560"
  },
  {
    "text": "axioms and rules of formal logic\nto derive truth conditions, OK?",
    "start": "187560",
    "end": "193444"
  },
  {
    "text": "There's also informal reasoning,\nwhich is what you and I probably do every day.",
    "start": "193444",
    "end": "198700"
  },
  {
    "text": "And here, we just reason\nabout everyday situations and use common sense\nto derive conclusions.",
    "start": "198700",
    "end": "205360"
  },
  {
    "text": "For most of the lecture,\nwhen I say reasoning, I will mean informal\ndeductive reasoning,",
    "start": "205360",
    "end": "211050"
  },
  {
    "text": "and that's often going to\ninvolve multiple steps. OK. So let's come back to\nlanguage models, OK?",
    "start": "211050",
    "end": "220532"
  },
  {
    "text": "So we've learned in\nlectures 9, 10, 11 that language models are\nreally, really good at--",
    "start": "220532",
    "end": "227110"
  },
  {
    "text": "or large language models\nare really, really good at coming up with plausible\ncontinuations of text that",
    "start": "227110",
    "end": "232740"
  },
  {
    "text": "reflect human preferences\nand constraints. Today, we will try to answer\nif they can also reason, OK?",
    "start": "232740",
    "end": "241200"
  },
  {
    "text": "So one of the most basic ways we\ncan try to answer this question",
    "start": "241200",
    "end": "246480"
  },
  {
    "text": "is we are prompting, OK? And we've probably\nalready seen this.",
    "start": "246480",
    "end": "252250"
  },
  {
    "text": "There is this\npopular method called chain of thought prompting,\nwhere you get a language",
    "start": "252250",
    "end": "257338"
  },
  {
    "text": "model to produce a reasoning\nstep before producing an answer. And we could do\nthis by providing",
    "start": "257339",
    "end": "264180"
  },
  {
    "text": "some in-context examples\nwith explicit reasoning steps that the language model can\nthen mimic at test time.",
    "start": "264180",
    "end": "271880"
  },
  {
    "text": "OK. So that's chain of\nthought prompting. Another rather surprising\nproperty of language models",
    "start": "271880",
    "end": "279408"
  },
  {
    "text": "is that sometimes\nyou don't even have to show them these\nin-context examples, and you could just prompt\nthem with the sentence,",
    "start": "279408",
    "end": "285490"
  },
  {
    "text": "let's think step\nby step, and you can get these\nreasoning rationales",
    "start": "285490",
    "end": "290970"
  },
  {
    "text": "before they produce an answer. OK. So that's pretty simple.",
    "start": "290970",
    "end": "296630"
  },
  {
    "text": "But let's keep going, OK? So another popular way to prompt\nlanguage models to do reasoning",
    "start": "296630",
    "end": "303230"
  },
  {
    "text": "is we are self-consistency. So here what we do is\ninstead of greedily sampling",
    "start": "303230",
    "end": "311090"
  },
  {
    "text": "a rationale followed\nby an answer, we are going to sample\nmultiple reasoning steps",
    "start": "311090",
    "end": "316430"
  },
  {
    "text": "and correspondingly\nmultiple answers, OK? So what we see in the figure on\nthe right, we have a question,",
    "start": "316430",
    "end": "324389"
  },
  {
    "text": "and then what you\nwould normally do with chain of thought\nprompting is you would greedily decode a rationale and then\ncondition on the rationale",
    "start": "324390",
    "end": "331970"
  },
  {
    "text": "to generate an answer. With self-consistency, we are\ngoing to sample multiple times or sample multiple rationales.",
    "start": "331970",
    "end": "338550"
  },
  {
    "text": "They are all going to\nlead to multiple answers, and then we're going to pick the\none that is the most common, OK?",
    "start": "338550",
    "end": "344480"
  },
  {
    "text": "With the idea being\nthat if an answer keeps appearing for\nmultiple rationales",
    "start": "344480",
    "end": "349979"
  },
  {
    "text": "the majority of the\nrationales agree on, then it's more\nlikely to be correct.",
    "start": "349980",
    "end": "355670"
  },
  {
    "text": "And the authors of\nself-consistency find that on a variety of\nmathematical reasoning tasks,",
    "start": "355670",
    "end": "362430"
  },
  {
    "text": "if you add this simple\nidea of self-consistency where you sample multiple\ntimes and sort of do",
    "start": "362430",
    "end": "368389"
  },
  {
    "text": "majority voting, that improves\nperformance pretty drastically over standard chain of thought.",
    "start": "368390",
    "end": "375350"
  },
  {
    "text": "And interestingly, when I saw\nthis result the first time, I thought, OK, this is just\nlike ensembling, which is",
    "start": "375350",
    "end": "382100"
  },
  {
    "text": "where we learned this in CS229. The idea is if you want to boost\nthe performance of your system,",
    "start": "382100",
    "end": "388260"
  },
  {
    "text": "I'm going to produce,\nlike, 10 classifiers with different random seeds. And I'm going to produce\na classification decision,",
    "start": "388260",
    "end": "395419"
  },
  {
    "text": "and I'm going to do\na majority voting. But it turns out that it's\ndoing maybe a little bit more",
    "start": "395420",
    "end": "400730"
  },
  {
    "text": "than just simple ensembling. So the authors also compared\nan ensembling approach where",
    "start": "400730",
    "end": "406310"
  },
  {
    "text": "it's the same language model\nwith multiple different prompts, and then you do\nmajority voting there,",
    "start": "406310",
    "end": "411870"
  },
  {
    "text": "and then turns out that\nself-consistency is better than just simple ensembling.",
    "start": "411870",
    "end": "419290"
  },
  {
    "text": "OK. So earlier today,\nI said that I'll be talking about\nmulti-step reasoning.",
    "start": "419290",
    "end": "425740"
  },
  {
    "text": "So far, we've looked at sort\nof math problems, but not-- and, like, prompting\nbut not necessarily",
    "start": "425740",
    "end": "431200"
  },
  {
    "text": "multi-step reasoning. One of the main kind of aspects\nabout multi-step reasoning is it",
    "start": "431200",
    "end": "437740"
  },
  {
    "text": "involves breaking down a large\nproblem into several subparts, where--",
    "start": "437740",
    "end": "443380"
  },
  {
    "text": "and answering each\nof the subparts and then combining everything\ninto a solution, OK?",
    "start": "443380",
    "end": "449140"
  },
  {
    "text": "So there's this kind of\ndecomposition strategy that was integrated into\nanother prompting method called",
    "start": "449140",
    "end": "455080"
  },
  {
    "text": "least to most prompting. And the idea behind\nleast to most prompting is, like I said,\ngiven a question,",
    "start": "455080",
    "end": "462710"
  },
  {
    "text": "we're going to first break\nit down into sub-questions as shown here.",
    "start": "462710",
    "end": "468820"
  },
  {
    "text": "And then given\nthese sub-question, the language model will sort of\nanswer each of the sub questions",
    "start": "468820",
    "end": "475350"
  },
  {
    "text": "and then condition\non its answers to the sub questions is going\nto generate the final answer.",
    "start": "475350",
    "end": "482819"
  },
  {
    "text": "And this is kind of how\nit looks like for sort of a math reasoning problem.",
    "start": "482820",
    "end": "488560"
  },
  {
    "text": "So in standard chain\nof thought prompting, you would have a\nquestion followed by a rationale and the answer\nwith least to most prompting,",
    "start": "488560",
    "end": "497410"
  },
  {
    "text": "which is this\ndecomposition strategy. You would take the\nquestion and then",
    "start": "497410",
    "end": "502590"
  },
  {
    "text": "instead of directly\nproducing a rationale, you sort of ask the language\nmodel to break it down",
    "start": "502590",
    "end": "507990"
  },
  {
    "text": "into problems. And then you have these\ntwo different sub-problems, and then you start answering\nboth of those sub-problems",
    "start": "507990",
    "end": "515400"
  },
  {
    "text": "and then condition your\nfinal answer on the answers to those sub-problems.",
    "start": "515400",
    "end": "521789"
  },
  {
    "text": "So OK. So that's just like a\nprompting method, right? One interesting experiment\nfrom least to most prompting",
    "start": "521789",
    "end": "529709"
  },
  {
    "text": "was showing that\nyou can sometimes generalize from a small\nnumber of reasoning steps to a much larger number\nof reasoning steps.",
    "start": "529710",
    "end": "536649"
  },
  {
    "text": "So here, in this sort\nof math word problem, there's two reasoning steps.",
    "start": "536650",
    "end": "543130"
  },
  {
    "text": "And if we show this prompt\nto the language model sort of as in-context\nexample, we",
    "start": "543130",
    "end": "550110"
  },
  {
    "text": "see that it continues\nto generalize even on examples that require more\nthan five steps of reasoning",
    "start": "550110",
    "end": "557730"
  },
  {
    "text": "and in a way, that's much better\nthan standard chain of thought.",
    "start": "557730",
    "end": "562740"
  },
  {
    "text": "But it's not entirely clear\nif structuring inference in this manner is\nreally fundamental.",
    "start": "562740",
    "end": "568770"
  },
  {
    "text": "One of the other\nresults they reported was sort of that with\nenough prompt engineering,",
    "start": "568770",
    "end": "575680"
  },
  {
    "text": "so the rows corresponding to\nbest, normal chain of thought",
    "start": "575680",
    "end": "580710"
  },
  {
    "text": "is on par with least\nto most prompting. But it's kind of\nan interesting idea of trying to break down\nproblems into sub-problems,",
    "start": "580710",
    "end": "587702"
  },
  {
    "text": "solving the sub-problems\nand then sort of building up a solution based on your\nanswers to the sub-problems.",
    "start": "587702",
    "end": "594201"
  },
  {
    "text": "OK. So all this was different\nsort of prompting methods to get reasoning behavior\nout of language models.",
    "start": "594202",
    "end": "600449"
  },
  {
    "text": "Can we do something more? So one of the things that\nwe might be interested in",
    "start": "600450",
    "end": "605750"
  },
  {
    "text": "is instead of trying to\nget really large language models to do reasoning,\nmaybe we want",
    "start": "605750",
    "end": "612800"
  },
  {
    "text": "to somehow get this kind of\nreasoning behavior in a smaller language model. And one popular\napproach for doing that",
    "start": "612800",
    "end": "620600"
  },
  {
    "text": "is distillation,\nwhere maybe you want to fine tune a smaller LLaMA\nmodel by teaching it to imitate",
    "start": "620600",
    "end": "628490"
  },
  {
    "text": "a larger LLaMA model. And so that's what we're\ngoing to look at now, OK?",
    "start": "628490",
    "end": "634802"
  },
  {
    "text": "So this model is called Orca. And at a high\nlevel, Orca is going to fine tune a smaller\n13 billion LLaMA language",
    "start": "634802",
    "end": "644360"
  },
  {
    "text": "model on explanations\nproduced by GPT-4, OK?",
    "start": "644360",
    "end": "649630"
  },
  {
    "text": "And to construct this\ndata, it's pretty simple. It has these three steps.",
    "start": "649630",
    "end": "655480"
  },
  {
    "text": "So the first step is we get a\nwide variety of instructions",
    "start": "655480",
    "end": "660779"
  },
  {
    "text": "from the FLAN-v2 collection. So FLAN-v2 is\nbasically a data set.",
    "start": "660780",
    "end": "666550"
  },
  {
    "text": "It kind of accumulates\nmultiple data sets into one sort of collection. And it consists of\ninstructions paired",
    "start": "666550",
    "end": "674040"
  },
  {
    "text": "with questions and answers. And I'll show an example\nof this in a moment.",
    "start": "674040",
    "end": "680199"
  },
  {
    "text": "And then we're going to\nprompt GPT-4 or ChatGPT",
    "start": "680200",
    "end": "685410"
  },
  {
    "text": "with these instructions\nalong with a system message. And the objective of\nthe system message",
    "start": "685410",
    "end": "692010"
  },
  {
    "text": "is to get ChatGPT\nor GPT-4 to produce an informative explanation\nalong with the answer.",
    "start": "692010",
    "end": "699850"
  },
  {
    "text": "So here, we have a question\nabout simple data processing,",
    "start": "699850",
    "end": "705180"
  },
  {
    "text": "about calculating the median. And there's a system\ninstruction that says, please justify your steps\nand kind of answer step by step.",
    "start": "705180",
    "end": "714860"
  },
  {
    "text": "And in producing its\noutput, the model sort of provides a fairly\ndetailed explanation",
    "start": "714860",
    "end": "722170"
  },
  {
    "text": "of how it got to the answer. And what Orca is going\nto do is use precisely",
    "start": "722170",
    "end": "727240"
  },
  {
    "text": "this explanation to fine tune\na much smaller model, OK? So that's what's\ngoing to happen.",
    "start": "727240",
    "end": "733970"
  },
  {
    "text": "Once we have these\nexplanations, we're going to fine tune a\nmuch smaller 13 billion",
    "start": "733970",
    "end": "739780"
  },
  {
    "text": "parameter LLaMA model on\nthese explanations, OK?",
    "start": "739780",
    "end": "745394"
  },
  {
    "text": "So, so far, we've looked\nat math reasoning and sort",
    "start": "745394",
    "end": "752589"
  },
  {
    "text": "of grade school math problems. Let's kind of turn to\na different benchmark",
    "start": "752590",
    "end": "757687"
  },
  {
    "text": "for reasoning. So we're going to\nlook at BigBench-hard. And this is another data set\nfor multi-step reasoning, OK?",
    "start": "757687",
    "end": "766744"
  },
  {
    "text": "And let's look at some\nexamples from BigBench-hard. So it consists of multiple\ndifferent subtasks.",
    "start": "766744",
    "end": "774117"
  },
  {
    "text": "So there's a total of\n23 different subtasks. I'm going to show\na few examples. So one of them is evaluating\nBoolean expressions.",
    "start": "774117",
    "end": "781360"
  },
  {
    "text": "So the question is true and\nfalse and not true and true is, OK?",
    "start": "781360",
    "end": "786760"
  },
  {
    "text": "So that's basically evaluate\nthis Boolean expression. And with sort of\nchain of thought,",
    "start": "786760",
    "end": "796360"
  },
  {
    "text": "the model can evaluate\neach of the subexpressions and get to the final answer.",
    "start": "796360",
    "end": "803100"
  },
  {
    "text": "And another example of a task\nfrom BigBench-hard is data understanding where\nmaybe the question is--",
    "start": "803100",
    "end": "813410"
  },
  {
    "text": "sorry, this is data\nunderstanding not data understanding. So the question is\ntomorrow is a given",
    "start": "813410",
    "end": "818880"
  },
  {
    "text": "date, what is the date\none year ago from today in a given format?",
    "start": "818880",
    "end": "824709"
  },
  {
    "text": "And it's paired\nwith some options. And again, the model can\nsort of think step by step,",
    "start": "824710",
    "end": "829720"
  },
  {
    "text": "following basic chain of thought\nand then come up with an answer. So this is kind of the\nflavor of tasks in BigBench.",
    "start": "829720",
    "end": "837190"
  },
  {
    "text": "Most of these involve\nmulti-step reasoning. They're fairly synthetic\nbut also reasonably",
    "start": "837190",
    "end": "844350"
  },
  {
    "text": "hard for language models, OK? Another example is\ngeometric shapes",
    "start": "844350",
    "end": "850210"
  },
  {
    "text": "and this one is\npretty surprising that language models\ncan do anything here.",
    "start": "850210",
    "end": "855580"
  },
  {
    "text": "So you're given sort of\nthe SVG path element. And I have no idea\nwhat this renders as.",
    "start": "855580",
    "end": "863650"
  },
  {
    "text": "But the question is,\njust given the SVG, what",
    "start": "863650",
    "end": "869040"
  },
  {
    "text": "shape you're going to get, OK? And there's a bunch of options.",
    "start": "869040",
    "end": "874420"
  },
  {
    "text": "And then again, the model\nprompted with let's think step by step, will\nproduce some answer. We don't know if it's\ncorrect, but it's",
    "start": "874420",
    "end": "880545"
  },
  {
    "text": "going to produce\nsome answer, OK? And so it's basically\nthis data set covering different kinds of\nreasonings, spatial reasoning,",
    "start": "880545",
    "end": "888870"
  },
  {
    "text": "data understanding,\nevaluating Booleans, and it's sort of multi-choice.",
    "start": "888870",
    "end": "894600"
  },
  {
    "text": "So it's easier to kind of get\nsort of an accuracy number.",
    "start": "894600",
    "end": "900649"
  },
  {
    "text": "And so yeah. So it covers a wide\nvariety of different tasks.",
    "start": "900650",
    "end": "905990"
  },
  {
    "text": "On the left, we have performance\nfrom really large language models.",
    "start": "905990",
    "end": "911930"
  },
  {
    "text": "This is zero-shot chain of\nthought with just the prompt, let's think step by step.",
    "start": "911930",
    "end": "919070"
  },
  {
    "text": "So GPT-4 has some potential\ncontamination issues with BigBench-hard. So let's-- maybe we\ncan ignore that column.",
    "start": "919070",
    "end": "927920"
  },
  {
    "text": "Vicuna is-- I think\na few months ago,",
    "start": "927920",
    "end": "933620"
  },
  {
    "text": "it was state of the art as an\ninstruction tuned LLaMA 13B",
    "start": "933620",
    "end": "938630"
  },
  {
    "text": "model. And Orca is, again, a LLaMA 13B\nthat's fine tuned specifically",
    "start": "938630",
    "end": "945050"
  },
  {
    "text": "on this, like, explanation data\nwhere you have instructions,",
    "start": "945050",
    "end": "951140"
  },
  {
    "text": "and then you have explanations\nfrom ChatGPT or GPT-4 and you fine tune on that.",
    "start": "951140",
    "end": "956450"
  },
  {
    "text": "And we see that overall, it\noutperforms ChatGPT maybe",
    "start": "956450",
    "end": "962120"
  },
  {
    "text": "because it's\nspecialized to just, like, these reasoning\nproblems, and it outperforms",
    "start": "962120",
    "end": "967220"
  },
  {
    "text": "Vicuna, which was not\ntrained on these really extensive explanations.",
    "start": "967220",
    "end": "973730"
  },
  {
    "text": "So that's one way you can\nget a smaller language model to display some kind\nof reasoning behavior, OK?",
    "start": "973730",
    "end": "981053"
  },
  {
    "text": "So this was all great. And we are very happy that you\ncan just generate rationales",
    "start": "981053",
    "end": "988160"
  },
  {
    "text": "from a big LLM and then\nfine tune a smaller language model on that. But then someone could\nask, why not just",
    "start": "988160",
    "end": "994190"
  },
  {
    "text": "fine tune the big language model\non its own rationales, right? So that's also been explored.",
    "start": "994190",
    "end": "1001050"
  },
  {
    "text": "And there's a bunch of\ndifferent methods that do this. I'm going to talk about\none of them called reinforced\nself-training or REST,",
    "start": "1001050",
    "end": "1007959"
  },
  {
    "text": "and it's going to alternate\nbetween two stages. The first stage, given a\nreasoning problem and perhaps",
    "start": "1007960",
    "end": "1016500"
  },
  {
    "text": "the prompt, let's\nthink step by step, I'm going to have the\nlanguage model generate multiple rationales, OK?",
    "start": "1016500",
    "end": "1022542"
  },
  {
    "text": "And then I'm going to filter\nthese rationales based on whether they give me the\ncorrect answer or not, OK?",
    "start": "1022542",
    "end": "1029254"
  },
  {
    "text": "So think about the\nword algebra problems, someone has three apples,\nsomeone else has four apples.",
    "start": "1029254",
    "end": "1036310"
  },
  {
    "text": "You generate a rationale, and\nthe answer comes out to be 7. You keep that rationale,\nthe answer is 12.",
    "start": "1036310",
    "end": "1041650"
  },
  {
    "text": "You sort of leave\nthat rationale out. And then I'm going to\ndo an update step where",
    "start": "1041650",
    "end": "1047790"
  },
  {
    "text": "I'm going to take these\nrationales that I filtered in my first stage. I'm going to fine tune the\nlanguage model on that.",
    "start": "1047790",
    "end": "1054610"
  },
  {
    "text": "And then I can do\nthis iteratively. Now I have an updated\nlanguage model. I can get hopefully\nbetter rationales,",
    "start": "1054610",
    "end": "1061230"
  },
  {
    "text": "and then I can update\nthe language model on better rationales to get\nan even better language model, and I keep doing that, OK?",
    "start": "1061230",
    "end": "1068966"
  },
  {
    "text": "And the results are\npromising but what we find",
    "start": "1068966",
    "end": "1074840"
  },
  {
    "text": "is on GSM8K, which is this\ngrade school math data set",
    "start": "1074840",
    "end": "1081020"
  },
  {
    "text": "of algebraic word\nproblems, as you increase the number of iterations\nof self-training,",
    "start": "1081020",
    "end": "1087810"
  },
  {
    "text": "we see a slight\nimprovement in performance, and then it starts degrading.",
    "start": "1087810",
    "end": "1093830"
  },
  {
    "text": "Math is another data\nset that, again, focuses on multi-step reasoning\nor covering math problems.",
    "start": "1093830",
    "end": "1101759"
  },
  {
    "text": "And again, on this\ndata set, we see that as we do more iterations\nof this reinforced self-training",
    "start": "1101760",
    "end": "1108830"
  },
  {
    "text": "paradigm, we see an\nimprovement in the accuracy. And the numbers in orange here\nare a much larger palm model.",
    "start": "1108830",
    "end": "1120570"
  },
  {
    "text": "And the numbers in blue\nare a smaller model. And the dashed\nlines represent what",
    "start": "1120570",
    "end": "1125870"
  },
  {
    "text": "you get sort of if you\ndid supervised fine tuning on human provided rationales.",
    "start": "1125870",
    "end": "1131669"
  },
  {
    "text": "So one of the promising\nthings about this approach is when you do multiple\niterations of self-training",
    "start": "1131670",
    "end": "1139309"
  },
  {
    "text": "on your own rationales,\nyou can outperform sort of human generated rationales.",
    "start": "1139310",
    "end": "1147470"
  },
  {
    "text": "And that is exemplified again\nin this graph where what we find",
    "start": "1147470",
    "end": "1154130"
  },
  {
    "text": "is the blue bar represents\naccuracy when you take the palm",
    "start": "1154130",
    "end": "1159740"
  },
  {
    "text": "model and you do\nsupervised fine tuning on human provided\nrationales, OK?",
    "start": "1159740",
    "end": "1165240"
  },
  {
    "text": "And then in green\nis if you did-- if you controlled\nfor the-- sorry.",
    "start": "1165240",
    "end": "1171390"
  },
  {
    "text": "So blue is if you fine tune on\nall human provided rationales. Orange is if you fine tune\non one rationale per training",
    "start": "1171390",
    "end": "1179500"
  },
  {
    "text": "example, OK? And these are written by humans. In green, it's what you\nget if you fine tune",
    "start": "1179500",
    "end": "1189220"
  },
  {
    "text": "on one rationale chosen at\nrandom per question, which is generated by the model.",
    "start": "1189220",
    "end": "1195320"
  },
  {
    "text": "So it's controlling for\nthe number of rationales. And we see that it outperforms\nhuman provided rationales.",
    "start": "1195320",
    "end": "1200870"
  },
  {
    "text": "And then if you sort of do\nthe full multi-step iterative procedure where you keep\nimproving the model,",
    "start": "1200870",
    "end": "1207500"
  },
  {
    "text": "we see, again, a\nboost in performance. So that's super promising.",
    "start": "1207500",
    "end": "1215169"
  },
  {
    "text": "Let's kind of start\nrevisiting the question that we asked in the\nbeginning about reasoning",
    "start": "1215170",
    "end": "1221620"
  },
  {
    "text": "in language models, OK? So one way of answering\nthat question is we",
    "start": "1221620",
    "end": "1228280"
  },
  {
    "text": "can apply all these methods,\nand we can look at benchmarks. But maybe the way to answer\nthe question correctly",
    "start": "1228280",
    "end": "1234909"
  },
  {
    "text": "is to be more systematic, come\nup with counterfactual tasks and be very careful about\npossible data contamination.",
    "start": "1234910",
    "end": "1244010"
  },
  {
    "text": "And I'm going to show\nsome results around that.",
    "start": "1244010",
    "end": "1249280"
  },
  {
    "text": "So we started the lecture\nwith chain of thought. And maybe the first\nquestion to ask",
    "start": "1249280",
    "end": "1255370"
  },
  {
    "text": "is, are the rationales\nthat the model produces with chain of thought faithful?",
    "start": "1255370",
    "end": "1261100"
  },
  {
    "text": "What I mean by faithful\nis maybe the model produces some rationale, and\nthen it produces an answer.",
    "start": "1261100",
    "end": "1267110"
  },
  {
    "text": "But maybe the answer does not\neven depend on the rationale that it produced, right? So maybe the question\nwas, Tom has 3 apples,",
    "start": "1267110",
    "end": "1275110"
  },
  {
    "text": "and Jerry has 4 apples. And the rationale. It produced was, OK, Tom\nhas 3 apples, Jerry has 4,",
    "start": "1275110",
    "end": "1280270"
  },
  {
    "text": "3 plus 4 is 7, so\nthe answer is 25. So in a case like that, you'd\nsay that the model was not",
    "start": "1280270",
    "end": "1286960"
  },
  {
    "text": "faithful to its rationale. And so what we see in this plot\nis a very careful experiment",
    "start": "1286960",
    "end": "1294600"
  },
  {
    "text": "where on the x-axis, we have\nthe number of reasoning samples.",
    "start": "1294600",
    "end": "1304750"
  },
  {
    "text": "So OK. So the setup is\nsomething like this. So for every question, the\nmodel produces a rationale,",
    "start": "1304750",
    "end": "1310770"
  },
  {
    "text": "and a rationale here\nis multiple sentences. And what we're\ngoing to do is we're",
    "start": "1310770",
    "end": "1316230"
  },
  {
    "text": "going to force the model\nto sort of early exit from its rationalization\nand just,",
    "start": "1316230",
    "end": "1322290"
  },
  {
    "text": "like, force it to\nproduce an answer, OK? So if it produced\nfour rationales,",
    "start": "1322290",
    "end": "1327580"
  },
  {
    "text": "I can early exit right\nafter the first rationale and ask it to produce an answer. I can exit after the\nsecond rationale,",
    "start": "1327580",
    "end": "1333490"
  },
  {
    "text": "ask it to produce an\nanswer, and so on. And what I'm going\nto plot on the y-axis is the model's accuracy after\nearly exiting in this procedure.",
    "start": "1333490",
    "end": "1343950"
  },
  {
    "text": "So let's say that I early\nexited after just one rationale, and the model produced\nexactly the same answer",
    "start": "1343950",
    "end": "1350250"
  },
  {
    "text": "that it would if it had seen all\nfour sentences in its rationale. Then maybe we can conclude\nthat the kind of reasoning",
    "start": "1350250",
    "end": "1360120"
  },
  {
    "text": "is not faithful. Like, it doesn't matter if the\nmodel sees the full rationale or just the first sentence.",
    "start": "1360120",
    "end": "1366149"
  },
  {
    "text": "And if you take that\nto the extreme maybe you terminate even\nwithout any rationale,",
    "start": "1366150",
    "end": "1372700"
  },
  {
    "text": "it produces the same answer. So the results here\nare somewhat mixed, but we see that there are\nenough data sets where it",
    "start": "1372700",
    "end": "1382169"
  },
  {
    "text": "doesn't matter if\nyou see the full-- if the model sees the full\nrationale before answering, or if you early-- sort of early exit.",
    "start": "1382170",
    "end": "1388230"
  },
  {
    "text": "You kind of get the\nsame answer, which means that sometimes\nthese rationales may",
    "start": "1388230",
    "end": "1394679"
  },
  {
    "text": "be post-hoc explanations\nof the model's answer, OK? Another experiment that tries to\nanswer this exact same question",
    "start": "1394680",
    "end": "1403740"
  },
  {
    "text": "is you can take\nthese rationales, and then you can\nstart corrupting them.",
    "start": "1403740",
    "end": "1409080"
  },
  {
    "text": "So maybe your\nrationale was length 4. And then I generate the first\nrationale, the second rationale",
    "start": "1409080",
    "end": "1414870"
  },
  {
    "text": "and for the third rationale,\nI just corrupt it, OK? And then the fourth\nrationale, and then I ask the model to\ngenerate my answer.",
    "start": "1414870",
    "end": "1421260"
  },
  {
    "text": "If it turns out that no matter\nhow much I corrupt my rationale, the model produces\nthe same answer,",
    "start": "1421260",
    "end": "1427830"
  },
  {
    "text": "then I can conclude that,\nagain, the answer kind of did not depend on my rationale.",
    "start": "1427830",
    "end": "1433160"
  },
  {
    "text": "So on the x-axis, we are\nlooking at the number",
    "start": "1433160",
    "end": "1438560"
  },
  {
    "text": "of-- the percentage\nof reasoning steps before I add sort of a\nmistake in the rationale, OK?",
    "start": "1438560",
    "end": "1445684"
  },
  {
    "text": "So what you should see is\nkind of a strictly increasing",
    "start": "1445685",
    "end": "1450835"
  },
  {
    "text": "sort of trend where if I\nadd a mistake after the very first step, then\nthat's probably going",
    "start": "1450835",
    "end": "1458090"
  },
  {
    "text": "to change the answer a lot. And then if I add a mistake\nafter the last step, that maybe doesn't change\nthe answer all that much.",
    "start": "1458090",
    "end": "1463740"
  },
  {
    "text": "But again, we find that\nfor some data sets, it so happens that you can add\na mistake in the first sentence",
    "start": "1463740",
    "end": "1471653"
  },
  {
    "text": "in your rationale,\nand the answer is not going to change all that much. And so that's also\nkind of an indicator",
    "start": "1471653",
    "end": "1477640"
  },
  {
    "text": "that maybe these rationales are\nsort of post-hoc explanations of the model's behavior.",
    "start": "1477640",
    "end": "1484270"
  },
  {
    "text": "So yeah. So there's a lot of lines here. So if anyone has questions,\nsee a few blank faces",
    "start": "1484270",
    "end": "1490600"
  },
  {
    "text": "in the audience. ",
    "start": "1490600",
    "end": "1498620"
  },
  {
    "text": "OK. So let's keep moving. OK. So that was about, like,\nwhether the models--",
    "start": "1498620",
    "end": "1506380"
  },
  {
    "text": "whether, sorry, chain of thought\nexpresses kind of a reasoning that the model is faithful to.",
    "start": "1506380",
    "end": "1511720"
  },
  {
    "text": "Another question\nyou could ask is, what if I changed my\nsetting a little bit, right?",
    "start": "1511720",
    "end": "1516945"
  },
  {
    "text": "So my model, let's\nsay, I observe that it's able to do\narithmetic in base 10,",
    "start": "1516945",
    "end": "1522680"
  },
  {
    "text": "so it's able to answer\nsomething like 12 plus 14, does that mean that my model\nknows how to do arithmetic",
    "start": "1522680",
    "end": "1528830"
  },
  {
    "text": "or maybe there was just\nthis exact same example",
    "start": "1528830",
    "end": "1533860"
  },
  {
    "text": "was present in\nthe training data? So one way you\ncould test for this is by creating\ncounterfactuals, which,",
    "start": "1533860",
    "end": "1540945"
  },
  {
    "text": "based on our\nunderstanding of the data, you expect to not be\npresent that frequently in the training data.",
    "start": "1540945",
    "end": "1547660"
  },
  {
    "text": "So instead of doing\nbase 10 addition, you could do addition in base 9. And then if the model has\nthe same accuracy in base 9,",
    "start": "1547660",
    "end": "1555320"
  },
  {
    "text": "then you can conclude\nthat maybe this model has understood how to do addition.",
    "start": "1555320",
    "end": "1560470"
  },
  {
    "text": "Similarly for logic,\nmaybe the reason why the model is so good\nat solving logic problems",
    "start": "1560470",
    "end": "1568195"
  },
  {
    "text": "is because it has seen\nsomething very similar in its training data. So what if I construct a\nworld where, I don't know,",
    "start": "1568195",
    "end": "1575080"
  },
  {
    "text": "corgis are reptiles, can it\nstill do this logic problem?",
    "start": "1575080",
    "end": "1580690"
  },
  {
    "text": "OK. And so what we find is there is\nsometimes a pretty significant",
    "start": "1580690",
    "end": "1587700"
  },
  {
    "text": "drop when you move from-- there's a question. Sorry, could you define what\nthe counterfactual-- why",
    "start": "1587700",
    "end": "1593760"
  },
  {
    "text": "is base 9 the\ncounterfactual with base 10? So it's a counterfactual--",
    "start": "1593760",
    "end": "1599549"
  },
  {
    "text": "excuse me-- in the sense that\nthe authors comment that base 10",
    "start": "1599550",
    "end": "1605460"
  },
  {
    "text": "addition is like frequently\nobserved in training data, but very few people\ndo base 9 addition.",
    "start": "1605460",
    "end": "1611100"
  },
  {
    "text": "And so there's going to be\nmuch fewer examples of this in training data. So it's more so\nout-of-distribution rather",
    "start": "1611100",
    "end": "1616605"
  },
  {
    "text": "than counterfactual, right? Yeah, yeah. So you can also call it\nout-of-distribution, for sure. ",
    "start": "1616605",
    "end": "1625620"
  },
  {
    "text": "And yeah. So, like, from\nresults, like, what we see is there's this drop\nin performance even for very",
    "start": "1625620",
    "end": "1633120"
  },
  {
    "text": "simple logic problems\nthat don't involve multiple steps of reasoning. There's a kind of a\nsignificant drop in performance",
    "start": "1633120",
    "end": "1642179"
  },
  {
    "text": "which maybe suggests that there\nis not that much reasoning, there's more memorization.",
    "start": "1642180",
    "end": "1648750"
  },
  {
    "text": "Yeah. So we could keep going with this\nparadigm of changing the problem",
    "start": "1648750",
    "end": "1655800"
  },
  {
    "text": "settings so that\nit starts looking sort of out of distribution\nto the training corpus.",
    "start": "1655800",
    "end": "1662640"
  },
  {
    "text": "And this is exactly what\nwas done in this paper that looked at analogical reasoning.",
    "start": "1662640",
    "end": "1668610"
  },
  {
    "text": "So basically, the setup\nis something like this. I'm going to show certain\nexamples of string",
    "start": "1668610",
    "end": "1675720"
  },
  {
    "text": "transformations. And I'm going to ask the model\nto generalize to new examples, OK?",
    "start": "1675720",
    "end": "1681320"
  },
  {
    "text": "So in this extend sequence\nproblem, I have abcd, and the output is abcde and\nthen given ijkl, the model",
    "start": "1681320",
    "end": "1690840"
  },
  {
    "text": "has to produce ijklm, OK? And so on. Now the way you can\nsort of make this",
    "start": "1690840",
    "end": "1698610"
  },
  {
    "text": "into a counterfactual\nor something that is out of distribution is maybe\nyou can kind of change what",
    "start": "1698610",
    "end": "1707270"
  },
  {
    "text": "the extent sequence task is. So now instead of\noutputting abcde,",
    "start": "1707270",
    "end": "1712730"
  },
  {
    "text": "maybe the model has\nto output abcdf, OK? So instead of outputting-- the\nnext character has to output",
    "start": "1712730",
    "end": "1720500"
  },
  {
    "text": "sort of one more-- so the second character\nafter the next and so on.",
    "start": "1720500",
    "end": "1726920"
  },
  {
    "text": "The other kind of\ncounterfactual you could add is instead of operating\non the standard alphabet,",
    "start": "1726920",
    "end": "1734040"
  },
  {
    "text": "you could modify the\nalphabet completely. So instead of the\nalphabet being abcd, maybe you start at xy and so on.",
    "start": "1734040",
    "end": "1741850"
  },
  {
    "text": " So what we find is--",
    "start": "1741850",
    "end": "1748400"
  },
  {
    "text": "so we find two things. The first thing that\nwe find is that there's a significant drop\nin performance",
    "start": "1748400",
    "end": "1754639"
  },
  {
    "text": "as we go from the standard\nsort of analogical reasoning problem to one of\nthese counterfactuals",
    "start": "1754640",
    "end": "1760610"
  },
  {
    "text": "where we either\nchange the alphabet, we change the\ndescription of the task so that it becomes\nslightly unnatural.",
    "start": "1760610",
    "end": "1767110"
  },
  {
    "text": "On the other hand,\nthe authors also did this exact same\nexperiment on human subjects",
    "start": "1767110",
    "end": "1772450"
  },
  {
    "text": "where they find very little\ndecrease in performance, OK?",
    "start": "1772450",
    "end": "1779055"
  },
  {
    "text": "So overall, what\nthis result suggest is maybe there is\nsome reasoning,",
    "start": "1779056",
    "end": "1784929"
  },
  {
    "text": "maybe there's some memorization,\nbut there's nothing systematic, OK?",
    "start": "1784930",
    "end": "1789981"
  },
  {
    "text": "So again, this is all\nemerging, so maybe someone will find that if you change\nyour prompt a little bit,",
    "start": "1789982",
    "end": "1797150"
  },
  {
    "text": "no models can do reasoning. But this is kind of the\ncurrent lay of the land.",
    "start": "1797150",
    "end": "1803100"
  },
  {
    "text": "OK.  So that was the reasoning\nmodule of the lecture.",
    "start": "1803100",
    "end": "1809570"
  },
  {
    "text": "I'm going to now switch gears\nand talk about language model",
    "start": "1809570",
    "end": "1814644"
  },
  {
    "text": "agents.  And this is kind of related\nto reasoning in the sense",
    "start": "1814645",
    "end": "1822040"
  },
  {
    "text": "that reasoning involves sort of\nthis multi-step inferences where given some facts,\nyou have to arrive",
    "start": "1822040",
    "end": "1828520"
  },
  {
    "text": "at completely new conclusions. With agents, what we'll see is\nthat there's some high level",
    "start": "1828520",
    "end": "1834700"
  },
  {
    "text": "kind of objective a\nmodel has to accomplish, and it has to reason\nabout post conditions,",
    "start": "1834700",
    "end": "1840070"
  },
  {
    "text": "object affordances, kind\nof uncertainty in the world to carry out a\nsequence of steps.",
    "start": "1840070",
    "end": "1847960"
  },
  {
    "text": "So let's start with\nsome terminology, OK? So we have our agent\non the right that's",
    "start": "1847960",
    "end": "1855730"
  },
  {
    "text": "going to be some neural network,\nand then we have an environment.",
    "start": "1855730",
    "end": "1861820"
  },
  {
    "text": "And I'll give some\nexamples of what these environments could be.",
    "start": "1861820",
    "end": "1867850"
  },
  {
    "text": "The agent receives\nan observation from its environment. And based on the observation,\nit issues an action, OK?",
    "start": "1867850",
    "end": "1878092"
  },
  {
    "text": "And along with that, it\nreceives this second variable g, and g represents a\nlanguage instruction, OK?",
    "start": "1878092",
    "end": "1887970"
  },
  {
    "text": "So there's many names for\nthis setting and these models",
    "start": "1887970",
    "end": "1893549"
  },
  {
    "text": "digital agent, language\ncondition policy or an instruction\nfollowing agent.",
    "start": "1893550",
    "end": "1900900"
  },
  {
    "text": "Some examples of\nenvironments are maybe it's sort of a web browser in\nsort of a browsing environment",
    "start": "1900900",
    "end": "1909840"
  },
  {
    "text": "where the objective\nis to book a flight from San Francisco to New York.",
    "start": "1909840",
    "end": "1915330"
  },
  {
    "text": "And the observation could\neither be a raw pixel that the model sees or it could\nbe the HTML DOM representation.",
    "start": "1915330",
    "end": "1927480"
  },
  {
    "text": "And the action space, if\nyou're looking at these web environments, could be typing\non specific web elements,",
    "start": "1927480",
    "end": "1935289"
  },
  {
    "text": "clicking on web elements, moving\nyour mouse to a certain web element to interact\nwith it, and so on.",
    "start": "1935290",
    "end": "1942059"
  },
  {
    "text": "And yeah, I mean,\nlike this has sort of a vast number\nof applications.",
    "start": "1942060",
    "end": "1947328"
  },
  {
    "text": "I don't think I can\ncover all applications, but we can look at some. So there's obviously like\ndigital assistants, like--",
    "start": "1947328",
    "end": "1957561"
  },
  {
    "text": "I'm not going to say\nthe names because I know people's mobiles\nmight start popping up.",
    "start": "1957561",
    "end": "1963150"
  },
  {
    "text": "But you can give them\nnatural language commands and set an alarm, set\nreminders and so on.",
    "start": "1963150",
    "end": "1971490"
  },
  {
    "text": "You could also do natural\nlanguage programming where you could, given\nnatural language descriptions,",
    "start": "1971490",
    "end": "1979260"
  },
  {
    "text": "get a model to sort\nof write Python code. Another example of this\ncould be UI automation,",
    "start": "1979260",
    "end": "1986170"
  },
  {
    "text": "where maybe you want to\ndo automated testing of UI elements. And so instead of having a human\nsort of verify whether a UI",
    "start": "1986170",
    "end": "1996780"
  },
  {
    "text": "element works, maybe\nyou can get a model to execute actions corresponding\nto a given instruction.",
    "start": "1996780",
    "end": "2002630"
  },
  {
    "text": "Or it could be something\nmore sort of user facing where given some\nkind of complex environment",
    "start": "2002630",
    "end": "2009700"
  },
  {
    "text": "like Spotify, you could ask\nan agent to play some songs.",
    "start": "2009700",
    "end": "2015039"
  },
  {
    "text": "And then finally, there is this\nsort of emerging application where we want to add additional\ntools or plugins to language",
    "start": "2015040",
    "end": "2025630"
  },
  {
    "text": "models so that they can control\nvarious different applications. ",
    "start": "2025630",
    "end": "2032860"
  },
  {
    "text": "OK. So before we look at how we\ncan use language models to do instruction following,\nI think it's",
    "start": "2032860",
    "end": "2039250"
  },
  {
    "text": "very helpful to look at how this\nwas done before language models.",
    "start": "2039250",
    "end": "2044320"
  },
  {
    "text": "So there are basically\nthree main ideas. Sometimes the right thing\nto do was collect examples",
    "start": "2044320",
    "end": "2055359"
  },
  {
    "text": "of utterances paired\nwith logical forms.",
    "start": "2055360",
    "end": "2060440"
  },
  {
    "text": "So logical forms\ncould be some kind of an executable representation\nthat you could just",
    "start": "2060440",
    "end": "2066158"
  },
  {
    "text": "execute against either a\nknowledge graph or a database to get an answer.",
    "start": "2066159",
    "end": "2072020"
  },
  {
    "text": "So maybe you have a query\nlike what state borders Texas, and then there exists some\nsort of program description",
    "start": "2072020",
    "end": "2080800"
  },
  {
    "text": "that you could execute\nagainst a knowledge graph to get sort of an\nanswer or a list here.",
    "start": "2080800",
    "end": "2089559"
  },
  {
    "text": "And idea number one\nthat people looked at was to treat this as almost\nlike machine translation, right?",
    "start": "2089560",
    "end": "2095449"
  },
  {
    "text": "So you have a source\nlanguage, which is sort of English\ncommands, and then you",
    "start": "2095449",
    "end": "2102970"
  },
  {
    "text": "have a target\nlanguage, which is sort of these, like,\nmeaning representations",
    "start": "2102970",
    "end": "2108010"
  },
  {
    "text": "or logical forms. And then you could\napply the same machinery from assignment three to build\nkind of a natural language",
    "start": "2108010",
    "end": "2115030"
  },
  {
    "text": "interface here, OK? So you directly\nmaximize the probability of a sequence of actions\ngiven a goal or a command.",
    "start": "2115030",
    "end": "2125580"
  },
  {
    "text": "Idea number two was something\na little bit more complex.",
    "start": "2125580",
    "end": "2130780"
  },
  {
    "text": "So here you have instructions\npaired with actions.",
    "start": "2130780",
    "end": "2137190"
  },
  {
    "text": "Instead of directly mapping\ninstructions to actions, I'm going to infer an\nexecutable plan, OK,",
    "start": "2137190",
    "end": "2146100"
  },
  {
    "text": "from these instructions\nand action sequences. And I'm going to train a\nmodel to go from instructions",
    "start": "2146100",
    "end": "2154350"
  },
  {
    "text": "to these plans, and then\ndefine a very rich execution model that's going to\ndirectly execute these plans.",
    "start": "2154350",
    "end": "2162120"
  },
  {
    "text": "The advantage of this is maybe\nthere is more sort of high level decisions you could encode in\nyour plan, which would be harder",
    "start": "2162120",
    "end": "2170640"
  },
  {
    "text": "to, like, get into\nthe model if you were to just train it\nto produce the action",
    "start": "2170640",
    "end": "2176180"
  },
  {
    "text": "trajectories directly. And I have an example of a\nsystem like that from 2011,",
    "start": "2176180",
    "end": "2181619"
  },
  {
    "text": "which was basically an agent\nthat could navigate in sort of grounded environments.",
    "start": "2181620",
    "end": "2188190"
  },
  {
    "text": "And yeah, the idea was\nsomething like this that you kind of took an\ninstruction and obtained a plan,",
    "start": "2188190",
    "end": "2196610"
  },
  {
    "text": "and then you would train\na semantic parser, which is basically like this kind of\nmachine translation system that",
    "start": "2196610",
    "end": "2203690"
  },
  {
    "text": "would convert commands into\nsequences into this plan. And then once that's\ntrained, at test time,",
    "start": "2203690",
    "end": "2210180"
  },
  {
    "text": "given a completely new\ninstruction, you would run the semantic\nparser, get this plan,",
    "start": "2210180",
    "end": "2215940"
  },
  {
    "text": "and then execute it in\nthis execution model, OK? And I have an example\nof an instruction",
    "start": "2215940",
    "end": "2223190"
  },
  {
    "text": "and a plan from\nthis 2011 system.",
    "start": "2223190",
    "end": "2228560"
  },
  {
    "text": "The third idea,\nwhich is probably maybe the first one\nthat comes to mind",
    "start": "2228560",
    "end": "2235340"
  },
  {
    "text": "if you see a\nsetting like that is to use reinforcement\nlearning directly. And what people did there\nwas to use RL to directly",
    "start": "2235340",
    "end": "2244820"
  },
  {
    "text": "map instructions into actions. So I'm going to\nlearn a policy that",
    "start": "2244820",
    "end": "2249860"
  },
  {
    "text": "outputs actions that\nmaximize some reward, OK, which is conditioned\non my natural language",
    "start": "2249860",
    "end": "2256130"
  },
  {
    "text": "instruction and the observation. And this reward could\nbe both sparse, which",
    "start": "2256130",
    "end": "2261800"
  },
  {
    "text": "is I carry out the\nentire task, and then my environment tells me if\nI achieve the task or not, or it could be something that\nI obtain after each step.",
    "start": "2261800",
    "end": "2269849"
  },
  {
    "text": "So I take an action and\nthen the environment tells me if this action\nsort of completed",
    "start": "2269850",
    "end": "2276019"
  },
  {
    "text": "some percentage\nof my task or not. And on the top, I've included\nan example of a system from 2009",
    "start": "2276020",
    "end": "2283490"
  },
  {
    "text": "that did this for automated\nwindows debugging. And so you have some\nnatural language instruction",
    "start": "2283490",
    "end": "2292460"
  },
  {
    "text": "to click some UI\nelements, and that gets mapped into kind\nof an API command",
    "start": "2292460",
    "end": "2298330"
  },
  {
    "text": "that the model executes\none after the other. OK. So these are basically the\nthree main ideas that people",
    "start": "2298330",
    "end": "2306040"
  },
  {
    "text": "had before language models. So you would either\ntrain semantic parsers. You would either\ninfer these plans",
    "start": "2306040",
    "end": "2313870"
  },
  {
    "text": "from instruction\ntrajectory pairs, and then learn to directly model\nplans and then have an execution",
    "start": "2313870",
    "end": "2320829"
  },
  {
    "text": "model that can execute plans. Or you would do\nreinforcement learning if you had a reward signal.",
    "start": "2320830",
    "end": "2327160"
  },
  {
    "text": "So how do we do things in 2024? So there are a few ways\nto think about this.",
    "start": "2327160",
    "end": "2334330"
  },
  {
    "text": "I think maybe most\ninstructive is to think about what we are\ntrying to achieve, right?",
    "start": "2334330",
    "end": "2339780"
  },
  {
    "text": "So we are trying to\nmodel trajectories, so sequence of actions,\nconditioned on some goal, OK?",
    "start": "2339780",
    "end": "2345650"
  },
  {
    "text": "So I want my model to book a\nflight from San Francisco to New York, and I want it to produce\na trajectory of, like, maybe",
    "start": "2345650",
    "end": "2353740"
  },
  {
    "text": "typing and clicking actions. So let's look at\nhow that factorizes. So the probability of a\ntrajectory conditioned",
    "start": "2353740",
    "end": "2362050"
  },
  {
    "text": "on a goal or an instruction\nis just the probability of the state action,\nnext state, and so on",
    "start": "2362050",
    "end": "2371110"
  },
  {
    "text": "conditioned on the goal. And you could factorize\nthat into two terms. So the first term is\nsort of the transition",
    "start": "2371110",
    "end": "2379308"
  },
  {
    "text": "dynamics of the environment. And that's just\nwhat happens if I take a certain action\nin a given state,",
    "start": "2379308",
    "end": "2386599"
  },
  {
    "text": "how is my state going to change? And the second object is sort\nof the agent policy, which",
    "start": "2386600",
    "end": "2392980"
  },
  {
    "text": "is given my goal and\nthe trajectory so far, what is the next action\nI should be taking, OK?",
    "start": "2392980",
    "end": "2400502"
  },
  {
    "text": "And then sort of\npeople quickly realize that you could just treat this\nas kind of a generative problem.",
    "start": "2400502",
    "end": "2408920"
  },
  {
    "text": "So you could treat the\nproblem of decision-making in environments as sort of a\ngenerative trajectory modeling",
    "start": "2408920",
    "end": "2415920"
  },
  {
    "text": "problem. And what I have in\nsort of the top right is an example of\na transformer that",
    "start": "2415920",
    "end": "2423750"
  },
  {
    "text": "just takes the history of\nactions it's taken so far, the current state, and some\nindication of what task",
    "start": "2423750",
    "end": "2433210"
  },
  {
    "text": "it should achieve\nhere based on reward, but it could be a\nnatural language string. And it's just trained to predict\nwhat's the next action, OK?",
    "start": "2433210",
    "end": "2441660"
  },
  {
    "text": "And you could just train an\nautoregressive language model to do this. And it turned out that\nthis worked very well",
    "start": "2441660",
    "end": "2448080"
  },
  {
    "text": "in sort of an offline RL case. Question. Sorry. In the figure, why are\nwe predicting one action",
    "start": "2448080",
    "end": "2454080"
  },
  {
    "text": "from the current action? Sorry? So we are predicting one action\nbefore and the current action.",
    "start": "2454080",
    "end": "2462840"
  },
  {
    "text": "Oh, so no. So you predict an action,\nexecute that, append that to your trajectory, and then\nyou predict the next action",
    "start": "2462840",
    "end": "2470580"
  },
  {
    "text": "and so on. Got it. So we resolve three input\ntokens into one output token",
    "start": "2470580",
    "end": "2475747"
  },
  {
    "text": "and train an output [INAUDIBLE]? Yes. OK. Sounds good. And it turned out that\nthis worked really well.",
    "start": "2475747",
    "end": "2482670"
  },
  {
    "text": "And so instead of getting\nthese latent plans",
    "start": "2482670",
    "end": "2488599"
  },
  {
    "text": "and training semantic\nparsers or trying to do reinforcement learning,\nwe started using language models",
    "start": "2488600",
    "end": "2495980"
  },
  {
    "text": "as policies. And so a simple way\nto do all of that is to prompt a language\nmodel in a loop, OK?",
    "start": "2495980",
    "end": "2504998"
  },
  {
    "text": "So we're going to specify\nthe action space in text. So this is like a simple\nsort of language model agent.",
    "start": "2504998",
    "end": "2512490"
  },
  {
    "text": "This is not going to work\nat all but probably just illustrative of how\nagents can be built now.",
    "start": "2512490",
    "end": "2518960"
  },
  {
    "text": "So you provide an\naction space in text. So maybe it's a\ndigital environment",
    "start": "2518960",
    "end": "2525870"
  },
  {
    "text": "and maybe it can type,\nmaybe it can click, maybe it can type\ncharacters, maybe it",
    "start": "2525870",
    "end": "2531200"
  },
  {
    "text": "can move mouse somewhere. You provide it an\ninstruction, and you",
    "start": "2531200",
    "end": "2537170"
  },
  {
    "text": "provide it the sequence of\nactions and observations",
    "start": "2537170",
    "end": "2542299"
  },
  {
    "text": "it's received so far, OK? And then condition\non all that, you ask",
    "start": "2542300",
    "end": "2547520"
  },
  {
    "text": "it to predict the next action. And there's nothing\ndeep going on here.",
    "start": "2547520",
    "end": "2553500"
  },
  {
    "text": "This is just chain of thought\nprompting in a loop, OK? But the hope is that\nbecause all of this--",
    "start": "2553500",
    "end": "2561830"
  },
  {
    "text": "because we reduce the\nproblem of decision-making into just autoregressive\nmodeling, this could work.",
    "start": "2561830",
    "end": "2567869"
  },
  {
    "text": "And indeed, a slightly more\ncomplex version of this can work in some environments.",
    "start": "2567870",
    "end": "2574320"
  },
  {
    "text": "OK. So now, I'm going to give\na little flavor of what different environments look\nlike now for evaluating language",
    "start": "2574320",
    "end": "2582680"
  },
  {
    "text": "models as agents. So the simplest environment\nthat people consider is MiniWoB.",
    "start": "2582680",
    "end": "2592450"
  },
  {
    "text": "So this is a sandbox\nenvironment that evaluates like basic\nbrowser interactions,",
    "start": "2592450",
    "end": "2598095"
  },
  {
    "text": "like Maybe on a mini\nTwitter environment, can you get a language model\nto retweet a given tweet?",
    "start": "2598095",
    "end": "2605380"
  },
  {
    "text": "Given sort of a\nsimulated email client, can the model forward\nsomeone's email?",
    "start": "2605380",
    "end": "2610850"
  },
  {
    "text": "Can it compose an email? Can it click on\ncertain buttons or not?",
    "start": "2610850",
    "end": "2616809"
  },
  {
    "text": "It's not at all real world,\nso it's not real websites. And it's relatively\nshort horizon.",
    "start": "2616810",
    "end": "2622550"
  },
  {
    "text": "So given any\ninstruction, most tasks can be accomplished in\nunder three actions.",
    "start": "2622550",
    "end": "2630490"
  },
  {
    "text": "But zero-shot performance of\neven the best language models is still far from perfect, even\non this very simple benchmark.",
    "start": "2630490",
    "end": "2638320"
  },
  {
    "text": "A second, slightly more real\nworld, benchmark is WebArena.",
    "start": "2638320",
    "end": "2643450"
  },
  {
    "text": "And this is also a\nsandbox environment, but it's kind of a pretty close\napproximation of real websites",
    "start": "2643450",
    "end": "2651320"
  },
  {
    "text": "that span e-commerce. So there is a\nwebsite in WebArena that resembles Amazon,\nsocial media, so something",
    "start": "2651320",
    "end": "2658220"
  },
  {
    "text": "that resembles Twitter. And additionally, there are\nutility tools like maps.",
    "start": "2658220",
    "end": "2663390"
  },
  {
    "text": "So an instruction\ncould require a model to open up sort of\na map application,",
    "start": "2663390",
    "end": "2668760"
  },
  {
    "text": "find the shortest path\nfrom point A to point B and use that in its later\nsequence of actions.",
    "start": "2668760",
    "end": "2675810"
  },
  {
    "text": "And there's multi-tab browsing\nlike we kind of commonly do. So with MiniWoB, there's\nonly one single tab,",
    "start": "2675810",
    "end": "2683870"
  },
  {
    "text": "and with WebArena, I think this\nwas the first environment that introduced this idea where\nyou kind of have multiple tabs",
    "start": "2683870",
    "end": "2691430"
  },
  {
    "text": "and the agent can sort of\nswitch between apps or tabs. And again, we are going to\nevaluate functional correctness,",
    "start": "2691430",
    "end": "2701270"
  },
  {
    "text": "which is whether the model\nsort of give the correct answer at the end, whether the\nsequence of steps it took",
    "start": "2701270",
    "end": "2708240"
  },
  {
    "text": "give the intended\nbehavior, as opposed to whether it took a\nsequence of steps that maybe a user\nhad pre-programmed.",
    "start": "2708240",
    "end": "2715859"
  },
  {
    "text": "So another popular kind\nof environment is--",
    "start": "2715860",
    "end": "2722280"
  },
  {
    "text": "a data set is WebLINX. So WebLINX also has\nmulti-tab browsing.",
    "start": "2722280",
    "end": "2727680"
  },
  {
    "text": "And it has web interactions\non real websites. So this is not sandboxed\napproximations of real websites.",
    "start": "2727680",
    "end": "2734890"
  },
  {
    "text": "This is not sandboxed\nkind of just, like, browser-- like\nbrowser interactions.",
    "start": "2734890",
    "end": "2740320"
  },
  {
    "text": "These are like\nactual real websites. And it also introduced, like, a\nnew action where the agent could",
    "start": "2740320",
    "end": "2748650"
  },
  {
    "text": "communicate with the user. So maybe there's\nsome instruction, which is to reserve kind of,\nI don't know, like a movie",
    "start": "2748650",
    "end": "2759180"
  },
  {
    "text": "or, like, a buy a movie\nticket or something. And then at some\npoint, the model has to request credit\ncard information.",
    "start": "2759180",
    "end": "2766060"
  },
  {
    "text": "And so there is this\nadditional action where a human could be involved\nin communicating with the agent.",
    "start": "2766060",
    "end": "2774990"
  },
  {
    "text": "And this is not an\nenvironment but just a collection of interactions. So you can't, for example,\ndo any kind of exploration",
    "start": "2774990",
    "end": "2782428"
  },
  {
    "text": "or online learning here,\nbut you could definitely use this for evaluating.",
    "start": "2782428",
    "end": "2787712"
  },
  {
    "text": "OK. So this was just a taste of\nwhat some benchmarks look like for language model agents.",
    "start": "2787712",
    "end": "2794849"
  },
  {
    "text": "So how are we going to\ntrain these models, right? So given that we\nare going to train--",
    "start": "2794850",
    "end": "2801839"
  },
  {
    "text": "we're going to treat, like,\ndecision-making as sort of casual-- as causal language\nmodeling, we're",
    "start": "2801840",
    "end": "2807060"
  },
  {
    "text": "not going to use any of\nthe ideas from pre-LLMs. The standard practice is\nto do in-context learning",
    "start": "2807060",
    "end": "2814500"
  },
  {
    "text": "with few-shot examples. And in the few-shot examples\ntypically for any new kind",
    "start": "2814500",
    "end": "2821930"
  },
  {
    "text": "of website or any\nnew use case, you're going to get humans to perform\nthose tasks and sort of feed",
    "start": "2821930",
    "end": "2828620"
  },
  {
    "text": "that into the\nlanguage models prompt as in-context demonstrations,\nwhich it could then",
    "start": "2828620",
    "end": "2833990"
  },
  {
    "text": "use to solve similar looking\ntasks on very similar websites.",
    "start": "2833990",
    "end": "2840380"
  },
  {
    "text": "So obviously, this\nis not scalable. There's thousands\nof environments.",
    "start": "2840380",
    "end": "2845660"
  },
  {
    "text": "On some environments, there's\nlots of different interactions that are possible. And so maybe there's\nsomething better",
    "start": "2845660",
    "end": "2852350"
  },
  {
    "text": "that we can do than just\nsort of getting humans to provide demonstrations\nfor every new use case.",
    "start": "2852350",
    "end": "2860960"
  },
  {
    "text": "And so we are going\nto use something that we saw early\non in the lecture, OK, which was to\nuse the language",
    "start": "2860960",
    "end": "2867050"
  },
  {
    "text": "model to generate rationales\nand then fine tune on that. And here, we don't\nhave rationales,",
    "start": "2867050",
    "end": "2872910"
  },
  {
    "text": "but we could produce\naction trajectories. And then we're going to use\nthat as supervision, OK?",
    "start": "2872910",
    "end": "2879250"
  },
  {
    "text": "So the way that looks like\nis something like this. So let's say I have\nsome environment.",
    "start": "2879250",
    "end": "2886779"
  },
  {
    "text": "Let's say it's some\nMiniWoB environment. And I'm going to just get\nan agent that can randomly",
    "start": "2886780",
    "end": "2893290"
  },
  {
    "text": "explore the environment. So it will just execute a random\nsequence of clicks and types",
    "start": "2893290",
    "end": "2898960"
  },
  {
    "text": "and scrolling operations. And let's say it produces\nsome trajectories, OK?",
    "start": "2898960",
    "end": "2905020"
  },
  {
    "text": "And now, I'm going to\nuse these trajectories and somehow filter them. So that was the\nidea from earlier. So you're going to get a\nbunch of different outputs,",
    "start": "2905020",
    "end": "2911440"
  },
  {
    "text": "and then you're going\nto filter it somehow. So here, we are going\nto use a second language model because we don't know what\na good trajectory looks like.",
    "start": "2911440",
    "end": "2920599"
  },
  {
    "text": "So not like a math problem where\nyou know the correct answer. We just had a language model\ninteract with a website",
    "start": "2920600",
    "end": "2927190"
  },
  {
    "text": "and generate trajectories, and\nwe want to somehow filter out what are good trajectories. And so we're going to\nuse a second model that",
    "start": "2927190",
    "end": "2934750"
  },
  {
    "text": "will produce a description\nof these trajectories.",
    "start": "2934750",
    "end": "2939950"
  },
  {
    "text": "And the idea here\nis that if you can get a model to produce\na description of what",
    "start": "2939950",
    "end": "2945550"
  },
  {
    "text": "the sequence of\nactions corresponds to, then maybe that's a good enough\nsignal for a good trajectory,",
    "start": "2945550",
    "end": "2952420"
  },
  {
    "text": "OK? And so maybe given\nthe first trajectory, it guesses that the instruction\nwas to book a flight",
    "start": "2952420",
    "end": "2958930"
  },
  {
    "text": "from San Francisco to New York. For the second trajectory, it\nset the date to some given date,",
    "start": "2958930",
    "end": "2967420"
  },
  {
    "text": "and maybe it wasn't\nable to come up with any good sort\nof instruction",
    "start": "2967420",
    "end": "2972520"
  },
  {
    "text": "for the third trajectory. And then we're going\nto do something, again,",
    "start": "2972520",
    "end": "2977870"
  },
  {
    "text": "that we saw earlier on, which is\nto kind of do this iteratively. So now, we have a goal that\nwe got for a trajectory.",
    "start": "2977870",
    "end": "2987950"
  },
  {
    "text": "And now, I'm going to get the\nlanguage model to condition its behavior on this goal.",
    "start": "2987950",
    "end": "2993400"
  },
  {
    "text": "So the goal is to set the\ndate as some given date and now, instead of\ndoing random exploration,",
    "start": "2993400",
    "end": "3000180"
  },
  {
    "text": "the model is going to produce\na sequence of actions that have a better correspondence\nwith some natural language",
    "start": "3000180",
    "end": "3006260"
  },
  {
    "text": "instruction. So it produced a trajectory\nbased on that instruction.",
    "start": "3006260",
    "end": "3012650"
  },
  {
    "text": "And then I'm going to use sort\nof some coarse filter that's just going to look\nat correspondences",
    "start": "3012650",
    "end": "3019310"
  },
  {
    "text": "between the instruction\nand the sequence of actions and the states the\nlanguage model visited",
    "start": "3019310",
    "end": "3026060"
  },
  {
    "text": "and use that to decide if the\ntrajectory was a good trajectory for the instruction.",
    "start": "3026060",
    "end": "3032390"
  },
  {
    "text": "And in this case,\ngiven the instruction, this seems like a\npretty good trajectory",
    "start": "3032390",
    "end": "3038390"
  },
  {
    "text": "for completing this task,\nand so then we add it to a set of examples, OK?",
    "start": "3038390",
    "end": "3045800"
  },
  {
    "text": "But maybe sometimes\nthings are not so good. So for that second instruction,\nthe generated label",
    "start": "3045800",
    "end": "3053300"
  },
  {
    "text": "was to book a flight from\nSan Francisco to New York. And let's say we run that again\nthrough the language model,",
    "start": "3053300",
    "end": "3059910"
  },
  {
    "text": "and it produced a\nsecond trajectory, OK? And clearly, this does\nnot seem like a kind",
    "start": "3059910",
    "end": "3066590"
  },
  {
    "text": "of a successful\ntrajectory corresponding to booking a flight. And so what do we do here?",
    "start": "3066590",
    "end": "3072780"
  },
  {
    "text": "Maybe we can throw\naway this interaction but interactions\nare pretty costly. Like specifically, if you're\nlooking at real websites,",
    "start": "3072780",
    "end": "3080580"
  },
  {
    "text": "then each interaction could\ntake a few milliseconds, and so maybe we don't want to\nthrow away this interaction.",
    "start": "3080580",
    "end": "3087080"
  },
  {
    "text": "So what are we're\ngoing to do here is, again, invoke the re-labeler\nto take the trajectory",
    "start": "3087080",
    "end": "3093080"
  },
  {
    "text": "and assign it a new label. So the model was not\nsuccessful at accomplishing the task it set out to do but\nit accomplished something.",
    "start": "3093080",
    "end": "3100085"
  },
  {
    "text": "And we're going to come up with\nthe best guess of what that was with a second language model. And it's going to say that,\nOK, maybe the instruction you",
    "start": "3100085",
    "end": "3108200"
  },
  {
    "text": "accomplished instead was\nto set the origin to SFO and the destination\nto New York City, OK?",
    "start": "3108200",
    "end": "3114390"
  },
  {
    "text": "And so that's going to get fed\nback into the language model, and we're going to keep\ndoing this iteratively",
    "start": "3114390",
    "end": "3120220"
  },
  {
    "text": "till our filter says that this\nis a good instruction trajectory pair. OK. So we have the same idea\nof using a language model",
    "start": "3120220",
    "end": "3127930"
  },
  {
    "text": "to sort of generate outputs and\nsome iterative procedure that",
    "start": "3127930",
    "end": "3132970"
  },
  {
    "text": "will give us kind of a good\nset of training examples.",
    "start": "3132970",
    "end": "3138849"
  },
  {
    "text": "So overall, the method\nlooks something like this. You have some environment.",
    "start": "3138850",
    "end": "3146020"
  },
  {
    "text": "We are going to use kind of an\nunconditioned language model to just randomly\nexplore the environment",
    "start": "3146020",
    "end": "3152650"
  },
  {
    "text": "and generate a sequence\nof trajectories. And then we're going to\nconvert these trajectories",
    "start": "3152650",
    "end": "3157990"
  },
  {
    "text": "into synthetic training data\nby iteratively converting trajectories into natural\nlanguage descriptions,",
    "start": "3157990",
    "end": "3166010"
  },
  {
    "text": "and then taking natural\nlanguage descriptions and converting them into even\nbetter trajectories, and so on.",
    "start": "3166010",
    "end": "3171220"
  },
  {
    "text": "And once we have this collection\nof synthetic examples, there are two\nthings we could do.",
    "start": "3171220",
    "end": "3177040"
  },
  {
    "text": "One could fine tune\nusing this data. But the simplest\nthing you could do is kind repeat the paradigm\nearlier of replace human",
    "start": "3177040",
    "end": "3186510"
  },
  {
    "text": "provided demonstrations\nin context with these synthetic\ndemonstrations.",
    "start": "3186510",
    "end": "3192810"
  },
  {
    "text": "And we find a reasonable\nboost in performance or 13 point improvement\non the MiniWoB benchmark.",
    "start": "3192810",
    "end": "3200020"
  },
  {
    "text": "And again, even the MiniWoB\nis very, very simple. Zero-shot performance for\neven the best language models",
    "start": "3200020",
    "end": "3205920"
  },
  {
    "text": "is far from perfect. And we also see an\nimprovement on second sort of multi-step tool\nuse environment.",
    "start": "3205920",
    "end": "3214110"
  },
  {
    "text": "But so far, we've only\nlooked at text, right? But maybe for real\nworld applications",
    "start": "3214110",
    "end": "3221099"
  },
  {
    "text": "it's kind of intractable\nto for every environment obtain the HTML and feed\nthat into the language models",
    "start": "3221100",
    "end": "3227580"
  },
  {
    "text": "context. Sometimes there can\nbe tens of thousands of DOM elements and then\ncorresponding JavaScript,",
    "start": "3227580",
    "end": "3236109"
  },
  {
    "text": "and inputting all that into\nthe language models context could be intractable. And maybe that's\nalso not the best way",
    "start": "3236110",
    "end": "3242370"
  },
  {
    "text": "to kind of show the\nstate of the environment. Maybe the best way\nis to directly show",
    "start": "3242370",
    "end": "3249059"
  },
  {
    "text": "the pixels corresponding\nto the environment. And so now, we're going to\nlook at some examples of vision",
    "start": "3249060",
    "end": "3257940"
  },
  {
    "text": "language models that people have\nused for building these agents, OK?",
    "start": "3257940",
    "end": "3263515"
  },
  {
    "text": "So the first one that we're\ngoing to look at is LLaVA.",
    "start": "3263515",
    "end": "3269130"
  },
  {
    "text": "And the idea here is, again,\nkind of similar to Orca that we looked at in sort of the\nreasoning half of the lecture.",
    "start": "3269130",
    "end": "3277020"
  },
  {
    "text": "We're going to use\nGPT-4 to generate, this time, both\ninstructions and responses",
    "start": "3277020",
    "end": "3284910"
  },
  {
    "text": "for textual\ndescriptions of images. So maybe there's\nan image, and we're",
    "start": "3284910",
    "end": "3290940"
  },
  {
    "text": "going to sort of use metadata\ncorresponding to that image to come up with a\ntextual description,",
    "start": "3290940",
    "end": "3297780"
  },
  {
    "text": "feed that into GPT-4 and ask it\nto generate possible questions",
    "start": "3297780",
    "end": "3303170"
  },
  {
    "text": "and responses. And then we're going to jointly\nfine tune sort of an image",
    "start": "3303170",
    "end": "3310220"
  },
  {
    "text": "encoder here, a CLIP\nalong with a text",
    "start": "3310220",
    "end": "3316340"
  },
  {
    "text": "only decoder here, Vicuna,\nwhich is a LLaMA model that is instruction tuned.",
    "start": "3316340",
    "end": "3322610"
  },
  {
    "text": "And through this sort of\njoint fine tuning, at the end, we kind of get this\nimage encoder that",
    "start": "3322610",
    "end": "3329480"
  },
  {
    "text": "can output language responses. And now, we can ask\nquestions about images, maybe use that to directly input\nscreenshots instead of HTML DOM",
    "start": "3329480",
    "end": "3339470"
  },
  {
    "text": "elements. So a second approach that looked\nat sort of building joint image",
    "start": "3339470",
    "end": "3349250"
  },
  {
    "text": "language models that then\npeople later adapted to agents was Pix2Struct.",
    "start": "3349250",
    "end": "3354869"
  },
  {
    "text": "And the idea is,\nagain, very similar. There's an image encoder\nand a text decoder.",
    "start": "3354870",
    "end": "3361519"
  },
  {
    "text": "The image encoder will\nsort of take the image, convert them into\npatches, and assign",
    "start": "3361520",
    "end": "3367339"
  },
  {
    "text": "each patch sort\nof a position ID, run that through a transformer. And then there's a decoder that\nwill decode out some text, OK?",
    "start": "3367340",
    "end": "3376725"
  },
  {
    "text": "One of the new things\nthat Pix2Struct introduced was a new pre-training task. So for a lot of the\npre-training was fairly simple.",
    "start": "3376725",
    "end": "3386490"
  },
  {
    "text": "We're going to use\nGPT-4 to just generate sort of synthetic\nquestions and responses",
    "start": "3386490",
    "end": "3393020"
  },
  {
    "text": "based on textual\ndescriptions of images. But there's only so far you can\ngo with textual descriptions of images.",
    "start": "3393020",
    "end": "3398240"
  },
  {
    "text": "What Pix2Struct did was to look\nat screenshots from websites",
    "start": "3398240",
    "end": "3404150"
  },
  {
    "text": "and mask out screenshots, and\nthen ask the transformer decoder",
    "start": "3404150",
    "end": "3409660"
  },
  {
    "text": "to produce HTML corresponding\nto the masked out elements. So here there is this list\nthat has a corresponding HTML.",
    "start": "3409660",
    "end": "3421329"
  },
  {
    "text": "One of the data\npoints in Pix2Struct looks something like this. So you might mask\nout, let's say,",
    "start": "3421330",
    "end": "3428980"
  },
  {
    "text": "the first answer\ncorresponding to Python and ask the model to produce\nthe HTML corresponding to just",
    "start": "3428980",
    "end": "3436600"
  },
  {
    "text": "the patch that was masked out. And so this seems like\na more natural sort",
    "start": "3436600",
    "end": "3442750"
  },
  {
    "text": "of pre-training\nobjective that can maybe have better interactions\nbetween image and text.",
    "start": "3442750",
    "end": "3450849"
  },
  {
    "text": "And then this was also\nadapted for building like these multimodal agents.",
    "start": "3450850",
    "end": "3456369"
  },
  {
    "text": "OK. So at this point, I just\nwant to kind of highlight that this is really an\nemerging application.",
    "start": "3456370",
    "end": "3465370"
  },
  {
    "text": "There's kind of this huge\nkind of prompting gap, is what I like to call it. So if you do not do\nextensive prompting",
    "start": "3465370",
    "end": "3472570"
  },
  {
    "text": "and if you do not use bespoke\nfew short examples where for every different\nenvironment you",
    "start": "3472570",
    "end": "3478330"
  },
  {
    "text": "have a different set\nof few short examples, even the best language\nmodels are very, very far from perfect even\non very, very simple tasks",
    "start": "3478330",
    "end": "3485470"
  },
  {
    "text": "like MiniWoB. Where the goal was just to\nclick on certain elements",
    "start": "3485470",
    "end": "3490809"
  },
  {
    "text": "or respond to someone's\nemail where in MiniWoB, that just takes,\nlike, five actions.",
    "start": "3490810",
    "end": "3498400"
  },
  {
    "text": "And then even for something\nas simple as MiniWoB, even after doing extensive\nprompting and few-shot examples,",
    "start": "3498400",
    "end": "3506630"
  },
  {
    "text": "is just like a\ndrop in performance as you go from sort of\nthe simplest tasks that",
    "start": "3506630",
    "end": "3512890"
  },
  {
    "text": "involve mapping an instruction\ninto a single action, to mapping an instruction\ninto maybe five or 10 actions.",
    "start": "3512890",
    "end": "3520510"
  },
  {
    "text": "So long horizon planning\nis still very, very hard even on these very\nsimple benchmarks.",
    "start": "3520510",
    "end": "3527940"
  },
  {
    "text": "And then if you look at\nsomething more complex like WebArena, which tries\nto approximate real websites,",
    "start": "3527940",
    "end": "3534369"
  },
  {
    "text": "has multi-tab browsing,\nhas external tools that the model can\nuse, there's just",
    "start": "3534370",
    "end": "3539610"
  },
  {
    "text": "a huge difference between sort\nof human level task success rate",
    "start": "3539610",
    "end": "3544860"
  },
  {
    "text": "and what the best models get,\neven after prompting even with few-shot examples.",
    "start": "3544860",
    "end": "3550633"
  },
  {
    "text": " And then the kinds\nof errors models",
    "start": "3550633",
    "end": "3556170"
  },
  {
    "text": "make are also pretty weird. So one of the examples\nfrom WebLINX was--",
    "start": "3556170",
    "end": "3564690"
  },
  {
    "text": "the task was to just\nopen Google Translate and sign in using\ncredentials, and there",
    "start": "3564690",
    "end": "3570780"
  },
  {
    "text": "was an email and a password. And then what GPT-4-- we did was instead of\ntyping in the password,",
    "start": "3570780",
    "end": "3578290"
  },
  {
    "text": "it just typed in the email\ninto the password tab. And it just couldn't\nrecover from this error.",
    "start": "3578290",
    "end": "3583480"
  },
  {
    "text": "So it tried to sign\nin, there was an error. It tried to insert-- tried to type in the\nemail again and so on.",
    "start": "3583480",
    "end": "3590290"
  },
  {
    "text": "And I'm sure with extensive\nprompting, you can fix this and maybe that's besides\nthe point, right?",
    "start": "3590290",
    "end": "3596369"
  },
  {
    "text": "And then again, there was\nlike a different example where the model had\nto issue a search.",
    "start": "3596370",
    "end": "3604630"
  },
  {
    "text": "And then instead of issuing the\nsearch with the correct term, it sort of repeated the\nsame term like three times.",
    "start": "3604630",
    "end": "3612660"
  },
  {
    "text": "And obviously, that's not\ngoing to return any results.",
    "start": "3612660",
    "end": "3619170"
  },
  {
    "text": "So there's a lot of room for\nimprovement, as you can see. And there's lots to\nbe done in this space.",
    "start": "3619170",
    "end": "3625885"
  },
  {
    "text": "OK. So I'm going to recap\nand take any questions. So we kind of looked at\ntwo different things today.",
    "start": "3625885",
    "end": "3634079"
  },
  {
    "text": "We looked at reasoning\nand language models. We saw that there's a few ways\nthat you can get reasoning",
    "start": "3634080",
    "end": "3640830"
  },
  {
    "text": "like behavior in\nlanguage models. You can prompt them\nin various ways. So the simplest example of that\nis chain of thought prompting.",
    "start": "3640830",
    "end": "3647700"
  },
  {
    "text": "You can do chain of\nthought prompting, but generate multiple\nrationales and sort of try to reconcile them\nand pick the answer",
    "start": "3647700",
    "end": "3655309"
  },
  {
    "text": "that was most, like, frequent. You can do sort of problem\ndecomposition in your prompt,",
    "start": "3655310",
    "end": "3662670"
  },
  {
    "text": "so ask the model to\nexplicitly decompose a problem into multiple\nsteps before answering.",
    "start": "3662670",
    "end": "3669109"
  },
  {
    "text": "So that was our prompting. You could also try and train\nspecialized small language",
    "start": "3669110",
    "end": "3674780"
  },
  {
    "text": "models for reasoning by\ngenerating rationales from a big language\nmodel, and then fine tuning a smaller language\nmodel on these rationales.",
    "start": "3674780",
    "end": "3684710"
  },
  {
    "text": "Instead of fine tuning\na smaller language model on rationales from a\nbig language model, you could just fine\ntune the big language",
    "start": "3684710",
    "end": "3692150"
  },
  {
    "text": "model on its own rationales and\nkeep doing this iteratively. And we saw that\nsometimes, if you do multiple iterations of that,\nperformance can keep improving",
    "start": "3692150",
    "end": "3701120"
  },
  {
    "text": "and can even outperform sort\nof human provided rationales.",
    "start": "3701120",
    "end": "3706270"
  },
  {
    "text": "But on the flip side,\nwe saw that while there are some initial reasons\nto be optimistic,",
    "start": "3706270",
    "end": "3713330"
  },
  {
    "text": "if we go and do\ncounterfactual evaluation, we see that it's not\nclear if the models are",
    "start": "3713330",
    "end": "3720760"
  },
  {
    "text": "good because they're\nreasoning or if models are good because all\nof these problems",
    "start": "3720760",
    "end": "3725860"
  },
  {
    "text": "are in some shape or form\nalready in the training data, and we saw that with sort of\ncounterfactual evaluation.",
    "start": "3725860",
    "end": "3732880"
  },
  {
    "text": "In the second part, we looked\nat language model agents. We kind of talked about\nthe historical perspective",
    "start": "3732880",
    "end": "3738970"
  },
  {
    "text": "through which people build\nsort of grounded agents. And then we saw that\nyou could recast",
    "start": "3738970",
    "end": "3745150"
  },
  {
    "text": "the problem of decision-making\nas just sort of causal language modeling.",
    "start": "3745150",
    "end": "3750829"
  },
  {
    "text": "And then we looked\nat various ways through which people have\nmodeled decision-making",
    "start": "3750830",
    "end": "3756880"
  },
  {
    "text": "with language models. Most of it involves prompting\nand in-context learning. And then we looked at a\nmethod similar to sort",
    "start": "3756880",
    "end": "3765190"
  },
  {
    "text": "of what we saw in\nthe first module, generating synthetic\ndemonstrations. And here, we looked at doing\nexploration and the same kind",
    "start": "3765190",
    "end": "3773170"
  },
  {
    "text": "of iterative relabeling. Most of the language models we\nlooked at today were text only.",
    "start": "3773170",
    "end": "3780160"
  },
  {
    "text": "We saw some examples\nof language models that can take both\ntext and visual input.",
    "start": "3780160",
    "end": "3786760"
  },
  {
    "text": "And then we saw that benchmarks\nare very, very challenging.",
    "start": "3786760",
    "end": "3791840"
  },
  {
    "text": "Models make kind of\ntrivial mistakes. There's a huge gap\nbetween human performance",
    "start": "3791840",
    "end": "3796930"
  },
  {
    "text": "and what we get with models. So there's a huge-- like, there's a huge difference\nbetween human performance",
    "start": "3796930",
    "end": "3804160"
  },
  {
    "text": "and where models are and\na lot of room for driving further improvement. And maybe some of you are\ndoing it for your projects.",
    "start": "3804160",
    "end": "3811270"
  },
  {
    "text": "Thank you. [APPLAUSE] ",
    "start": "3811270",
    "end": "3822000"
  }
]
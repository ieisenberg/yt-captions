[
  {
    "text": "all right thanks Alex for the introduction and thanks for inviting me you know that was great I don't need to motivate anything so everybody's",
    "start": "10740",
    "end": "17310"
  },
  {
    "text": "motivated for thinking about robots and autonomous systems that interact with people so I'm dorsa I'm in computer",
    "start": "17310",
    "end": "25110"
  },
  {
    "text": "science and electrical engineering and and my research is about algorithm design for robots so I'm very interested",
    "start": "25110",
    "end": "30660"
  },
  {
    "text": "in designing algorithms for robots that can actually interact people with people and and are safe so when we think about",
    "start": "30660",
    "end": "38129"
  },
  {
    "text": "these autonomous systems so robots kind of immediate like pictures that might",
    "start": "38129",
    "end": "43229"
  },
  {
    "text": "come to our mind are things like this so we might have things like autonomous or semi-autonomous driving or controlling",
    "start": "43229",
    "end": "50640"
  },
  {
    "text": "drones from the ground we might have things like service robotics so like doing tasks with robots in our homes",
    "start": "50640",
    "end": "57360"
  },
  {
    "text": "let's say or like robotic surgery and and I know these systems are very",
    "start": "57360",
    "end": "62820"
  },
  {
    "text": "different from each other but one common thing that they have like one thing that they have in common with each other is",
    "start": "62820",
    "end": "68189"
  },
  {
    "text": "that they're all safety-critical and they all need to interact with people so each one of these systems is quite",
    "start": "68189",
    "end": "75030"
  },
  {
    "text": "challenging there's a lot of engineering behind like getting these things working but but the common aspect here is we",
    "start": "75030",
    "end": "81509"
  },
  {
    "text": "want to care about interaction and we want to care about the safety of some of these systems and when we think about",
    "start": "81509",
    "end": "87149"
  },
  {
    "text": "our robots today or autonomous systems today they're not very safe or they're",
    "start": "87149",
    "end": "92820"
  },
  {
    "text": "not very interactive and and I have some videos here that I was going to show so",
    "start": "92820",
    "end": "98810"
  },
  {
    "text": "so this is from the DARPA Robotics Challenge in 2015 I'm sure a lot of you",
    "start": "98810",
    "end": "104399"
  },
  {
    "text": "guys have seen this any robot Isis that gives a talk this is kind of their first slide that look at all these robots that",
    "start": "104399",
    "end": "110670"
  },
  {
    "text": "is kind of the state of the other abadox but they fail it's just who they do fail but there are some success stories there",
    "start": "110670",
    "end": "116729"
  },
  {
    "text": "too and as I said there's a lot of engineering there's a lot of hard work that goes into like designing these systems so yeah so this is like three",
    "start": "116729",
    "end": "125759"
  },
  {
    "text": "years ago and as you can see our best robots today are not very good with",
    "start": "125759",
    "end": "132120"
  },
  {
    "text": "dealing like on certain situations or dynamic situations and it's not just",
    "start": "132120",
    "end": "137580"
  },
  {
    "text": "robots it's autonomous systems in general so here I have this video from the Tesla autopilot crash where the",
    "start": "137580",
    "end": "143040"
  },
  {
    "text": "vehicle doesn't detect a car on the side of the road and there's this fatal crash and also when",
    "start": "143040",
    "end": "150270"
  },
  {
    "text": "it comes to interaction or not that great especially if that interaction is",
    "start": "150270",
    "end": "157680"
  },
  {
    "text": "with people and this is one of my favorite videos so in this case the person has no idea what the quadrotor is",
    "start": "157680",
    "end": "163830"
  },
  {
    "text": "going to do next and then because of that is really scared and he doesn't know like how to interact with the quadrotor and and if you're thinking",
    "start": "163830",
    "end": "171090"
  },
  {
    "text": "about designing algorithms for these systems we should we should really think",
    "start": "171090",
    "end": "177150"
  },
  {
    "text": "about interaction and we should really think about say safety and some of the issues that goes on like when we are",
    "start": "177150",
    "end": "182220"
  },
  {
    "text": "thinking about design of algorithms for robots so uh I say my research every",
    "start": "182220",
    "end": "187920"
  },
  {
    "text": "time I think about a robot or an autonomous system there's usually a human involved and there is an interaction between them and their core",
    "start": "187920",
    "end": "194100"
  },
  {
    "text": "problems that I'm very interested in is at the intersection of a bunch of different field so I'm interested in",
    "start": "194100",
    "end": "199470"
  },
  {
    "text": "safe and interactive autonomy and that requires a bunch of different fields it's not like a single field that can",
    "start": "199470",
    "end": "205050"
  },
  {
    "text": "come and solve it so we are interested in learning and control and optimization because at the end of the day I want to",
    "start": "205050",
    "end": "211140"
  },
  {
    "text": "I want to control this system I want to control my robot arm I want to control my autonomous car and there's a lot of learning and optimization going on there",
    "start": "211140",
    "end": "217770"
  },
  {
    "text": "which becomes very important I also want to interact with people and there's this emerging field and robotics called human",
    "start": "217770",
    "end": "224580"
  },
  {
    "text": "robot interaction and the idea is let's think about how humans act around us and how we can predict what humans are going",
    "start": "224580",
    "end": "231420"
  },
  {
    "text": "to do next and based on that plan better so it's not as much about cognitive science or getting into people's head",
    "start": "231420",
    "end": "237780"
  },
  {
    "text": "it's more about better design of like mod algorithms for robots knowing and",
    "start": "237780",
    "end": "243780"
  },
  {
    "text": "predicting what people are going to do next and the top area I've put there is",
    "start": "243780",
    "end": "249360"
  },
  {
    "text": "a serie called formal methods which is an area in computer science it's actually not taught in many schools so",
    "start": "249360",
    "end": "255180"
  },
  {
    "text": "when I go through like some schools like they don't even know what it is but it's basically this area which is about",
    "start": "255180",
    "end": "260880"
  },
  {
    "text": "proving guarantees and providing correctness about systems so these systems could be programs could be",
    "start": "260880",
    "end": "267000"
  },
  {
    "text": "circuits could also be controllers for autonomous systems could be could be a",
    "start": "267000",
    "end": "272430"
  },
  {
    "text": "policy that's running on my robot so what would be interesting is to look at the intersection",
    "start": "272430",
    "end": "277900"
  },
  {
    "text": "of some of these fills where we can bring in formal methods ideas and talk about correctness of some of these systems at the same time we can bring in",
    "start": "277900",
    "end": "284860"
  },
  {
    "text": "human robot interaction and think about the interaction between humans and robots and do algorithm design so that's",
    "start": "284860",
    "end": "290470"
  },
  {
    "text": "kind of the area I'm very interested in today I'm mainly going to talk about",
    "start": "290470",
    "end": "296139"
  },
  {
    "text": "human robot interaction and how that comes in I'm not talking about as much about formal methods there are",
    "start": "296139",
    "end": "302229"
  },
  {
    "text": "implications of safety but I'm not talking about that as much today all",
    "start": "302229",
    "end": "308350"
  },
  {
    "text": "right okay so I know I've motivated the problem to be about any general human",
    "start": "308350",
    "end": "315280"
  },
  {
    "text": "robot system and and almost everything I say today applies to any almost any human robot system but I want to focus",
    "start": "315280",
    "end": "322270"
  },
  {
    "text": "on autonomous and semi autonomous driving as the main subject of this this talk and when we think about autonomous",
    "start": "322270",
    "end": "329740"
  },
  {
    "text": "or semi-autonomous driving maybe maybe the first thing that would come to our mind is Google's self-driving project so",
    "start": "329740",
    "end": "335320"
  },
  {
    "text": "that was one of the pioneer one of the pioneers of thinking about autonomous or semi-autonomous driving and then they",
    "start": "335320",
    "end": "341500"
  },
  {
    "text": "started with this notion of having semi autonomous cars where the car was driving autonomously on highways because",
    "start": "341500",
    "end": "347560"
  },
  {
    "text": "I was easier and whenever II was getting off a highway it would basically transition control back to the person",
    "start": "347560",
    "end": "353349"
  },
  {
    "text": "towing the person I'm getting off the highway this is too difficult you got to come and take over control and city",
    "start": "353349",
    "end": "359590"
  },
  {
    "text": "driving was human driven but all of a sudden in May of 2014 Google decided to",
    "start": "359590",
    "end": "366190"
  },
  {
    "text": "completely change their plan and come up with this new design which has this fully autonomous vehicle and then go",
    "start": "366190",
    "end": "373389"
  },
  {
    "text": "with this fully autonomous vehicle and eliminates the steering wheel and braking pedal and it completely",
    "start": "373389",
    "end": "379000"
  },
  {
    "text": "eliminates the human driver so so they decided to have this this new design of",
    "start": "379000",
    "end": "384610"
  },
  {
    "text": "fully autonomous cars and actually I remember at the time I was at Berkeley and Anthony lobanovsky was working on a",
    "start": "384610",
    "end": "391060"
  },
  {
    "text": "project came and gave a talk at Berkeley and he actually mentioned one of the reasons that they're going fully autonomous is modeling humans seems very",
    "start": "391060",
    "end": "398770"
  },
  {
    "text": "difficult and this is a human inside of the car so thinking about what the human inside of the car is going to do next",
    "start": "398770",
    "end": "404620"
  },
  {
    "text": "can be very challenging and they decided to just get rid of the humans have this new design",
    "start": "404620",
    "end": "410639"
  },
  {
    "text": "but then if you look at like where Google went immediately after that well they have these monthly reports and in",
    "start": "410639",
    "end": "417669"
  },
  {
    "text": "only a span of a few months they had eleven accidents in all of these accidents the Google car was being",
    "start": "417669",
    "end": "424569"
  },
  {
    "text": "rear-ended so of course it wasn't Google's problem it was it was the other cars problem but what the question that",
    "start": "424569",
    "end": "430419"
  },
  {
    "text": "came to my mind at the time was well why am I not being rendered 11 times instead",
    "start": "430419",
    "end": "436869"
  },
  {
    "text": "Oh a few months yes yeah and then yeah",
    "start": "436869",
    "end": "442449"
  },
  {
    "text": "so like I'm I save all maybe Google is driving way more than me Google is driving so much then actual",
    "start": "442449",
    "end": "447550"
  },
  {
    "text": "numbers is actually in the reports I don't remember the actual number but of course Google is going to drive more than I drive but why am I not being",
    "start": "447550",
    "end": "453309"
  },
  {
    "text": "rarer than that many times and years of driving like years of driving I don't really I only had like one accident in",
    "start": "453309",
    "end": "459789"
  },
  {
    "text": "my driving experience of yours now and if you think about it this is not a",
    "start": "459789",
    "end": "464830"
  },
  {
    "text": "problem and just Google this is a problem with most car companies they're trying to put these vehicles in a world",
    "start": "464830",
    "end": "469869"
  },
  {
    "text": "where humans don't behave by the book like you might assume humans are going to follow all the rules and drive like",
    "start": "469869",
    "end": "475419"
  },
  {
    "text": "at 15 miles per hour but humans are not going to really do that because they have their own kind of rules of playing",
    "start": "475419",
    "end": "482139"
  },
  {
    "text": "and playing when you're when they're on roads so so we started looking at the picture that kind of looked like this this kind of motivated our pick our our",
    "start": "482139",
    "end": "489999"
  },
  {
    "text": "research so even if I eliminate the driver inside of the car there are still human driven cars around me there are",
    "start": "489999",
    "end": "495879"
  },
  {
    "text": "still pedestrians around me and I actually need to think about the interactions between between these other",
    "start": "495879",
    "end": "500889"
  },
  {
    "text": "agents it's no longer just cars so they",
    "start": "500889",
    "end": "511659"
  },
  {
    "text": "know they're they're driving be trust now that was on yeah trucking is you",
    "start": "511659",
    "end": "524740"
  },
  {
    "text": "know a lot of people think trucking would be the first thing that would be automated because highway driving is",
    "start": "524740",
    "end": "530050"
  },
  {
    "text": "easier right so like if you can have trucks automated on highways that can solve a lot of problems but yeah so we",
    "start": "530050",
    "end": "536259"
  },
  {
    "text": "started thinking about this problem and certain thing about autonomous cars and if you think about autonomous cars well",
    "start": "536259",
    "end": "542980"
  },
  {
    "text": "autonomous car today they try to optimize for reaching for their destination so they try to go",
    "start": "542980",
    "end": "548149"
  },
  {
    "text": "towards their destination and at the same time they try to avoid unsafe regions of the road like the boundaries",
    "start": "548149",
    "end": "553790"
  },
  {
    "text": "of the road and if there happens to be another vehicle on the road they usually treat that vehicle as a moving obstacle",
    "start": "553790",
    "end": "560779"
  },
  {
    "text": "so basically try to do collision avoidance with this moving obstacle but",
    "start": "560779",
    "end": "566449"
  },
  {
    "text": "if you think about it does this vehicle it's not just the moving obstacle like that happens to sit there right there's",
    "start": "566449",
    "end": "571879"
  },
  {
    "text": "a human inside it and the human has a model of the world and also times for reaching for his action so his goals so",
    "start": "571879",
    "end": "579730"
  },
  {
    "text": "think about it whether we want it or not or whatever we plan for it or not the",
    "start": "579730",
    "end": "585049"
  },
  {
    "text": "actions of an autonomous car actually effects the actions of other drivers and and we actually need to take that into",
    "start": "585049",
    "end": "590119"
  },
  {
    "text": "account we need to think about these effects and responses and and we do see these type of behaviors in our everyday",
    "start": "590119",
    "end": "596360"
  },
  {
    "text": "lives for example if I want to change lanes I don't assume this car is a moving obstacle what I do is I start nudging in",
    "start": "596360",
    "end": "603049"
  },
  {
    "text": "in front of the person and I expect the other driver to slow down and respond to my actions and then make room for me and",
    "start": "603049",
    "end": "608929"
  },
  {
    "text": "that's how I change lanes and and unfortunately that's not currently how",
    "start": "608929",
    "end": "614509"
  },
  {
    "text": "autonomous car companies is it's actually a video recent video of a more car where the car is trying to change",
    "start": "614509",
    "end": "622670"
  },
  {
    "text": "lanes because it's an exit lane and it starts signalling doing everything right but it just can't do it because it",
    "start": "622670",
    "end": "630769"
  },
  {
    "text": "doesn't think about the actual interaction that goes on between its actions and yaller agents so it has to",
    "start": "630769",
    "end": "636290"
  },
  {
    "text": "actually exit come back around and do it again so this is a problem right our",
    "start": "636290",
    "end": "643009"
  },
  {
    "text": "cars our autonomous cars today don't really drive human-like the drivers",
    "start": "643009",
    "end": "656130"
  },
  {
    "text": "[Laughter] there's rules how to get in and know how",
    "start": "656130",
    "end": "663619"
  },
  {
    "text": "to get in yeah it happened no no no computer a regular drivers test driver",
    "start": "663619",
    "end": "669739"
  },
  {
    "text": "says would be interesting job yeah and yeah no I could not be the goal leave to me that sort of sounded off",
    "start": "669739",
    "end": "676449"
  },
  {
    "text": "but like then you have to kind of what if you miss a goal so every time like yeah you're right like like you have to",
    "start": "676449",
    "end": "682730"
  },
  {
    "text": "come up with the rulebook of like all sorts of things to try I mean like you would always like miss something so you",
    "start": "682730",
    "end": "688069"
  },
  {
    "text": "want to have something that is a little bit more more like less handy Cody like",
    "start": "688069",
    "end": "693920"
  },
  {
    "text": "I would think would be awesome it like I'm not suggesting we have that today it would be awesome to have something like",
    "start": "693920",
    "end": "699199"
  },
  {
    "text": "that so it's sort of thinking about this problem and and we thought about modeling this interaction that goes on",
    "start": "699199",
    "end": "705980"
  },
  {
    "text": "between an autonomous car and a human driven car as a dynamical system so what",
    "start": "705980",
    "end": "711410"
  },
  {
    "text": "I mean by that is I have direct control over the actions of the autonomous car so that's let me call that you are so",
    "start": "711410",
    "end": "717829"
  },
  {
    "text": "that's the steering angle and acceleration for you for the autonomous car and in some sense we have indirect",
    "start": "717829",
    "end": "723740"
  },
  {
    "text": "control over the actions of the human driven car what's called at you H so also that's the steering angle and",
    "start": "723740",
    "end": "729319"
  },
  {
    "text": "acceleration of the human German car and when I say indirect control what I mean",
    "start": "729319",
    "end": "734329"
  },
  {
    "text": "by that is well if I take actions that should affect the actions of the human so in some sense I can indirectly make",
    "start": "734329",
    "end": "740240"
  },
  {
    "text": "humans do things and this is kind of like an under actuated system if you have taken a controls class and",
    "start": "740240",
    "end": "746180"
  },
  {
    "text": "electrical engineering you've probably seen under actuated systems and this is kind of like an under actuated system so",
    "start": "746180",
    "end": "752990"
  },
  {
    "text": "more specifically what we are doing here is we're trying to find these actions for the autonomous car that maximizes",
    "start": "752990",
    "end": "760160"
  },
  {
    "text": "some some objective some rewards function and and that reward function is a function of state and actions which is",
    "start": "760160",
    "end": "766160"
  },
  {
    "text": "usual but now I'm saying this reward function should depend on the actions of the human should actually affect humans",
    "start": "766160",
    "end": "772699"
  },
  {
    "text": "and the good question to ask is well what does the human do I footing you a chest are there as kind of these optimal",
    "start": "772699",
    "end": "779779"
  },
  {
    "text": "actions that the human is going to do this model of the human and a good question to ask is well how do I know",
    "start": "779779",
    "end": "784850"
  },
  {
    "text": "what UHS store is where does UHS star comes from so the way we are modeling",
    "start": "784850",
    "end": "790009"
  },
  {
    "text": "the human in this work is is we are assuming that our humans are approximately optimizing their own",
    "start": "790009",
    "end": "795649"
  },
  {
    "text": "reward function let me call that our H so they're kind of dismissed this is",
    "start": "795649",
    "end": "801980"
  },
  {
    "text": "like if you want to remember one math from this stock this is kind of the math that to remember this slide has a lot of",
    "start": "801980",
    "end": "807230"
  },
  {
    "text": "questions in it so the fur question is go okay now that I put our H here well how do I know what our H is",
    "start": "807230",
    "end": "813100"
  },
  {
    "text": "where does our H come from what does it mean to have a reward function of the human how do I come up with UHS star now",
    "start": "813100",
    "end": "820869"
  },
  {
    "text": "that I know it's our H like is it fair to assume that humans are optimizing a reward function what if they're not",
    "start": "820869",
    "end": "826689"
  },
  {
    "text": "optimizing that what if like we are near access scenario and the human is not really doing that so now that I have",
    "start": "826689",
    "end": "832869"
  },
  {
    "text": "that let's say I have the perfect knowledge of predicting what humans are doing even if I have that I'm putting",
    "start": "832869",
    "end": "838360"
  },
  {
    "text": "they're putting it up there how do I go about solving that top optimization so",
    "start": "838360",
    "end": "844269"
  },
  {
    "text": "this is a nested optimization each one of these rewards functions are non convex nonlinear functions I need to",
    "start": "844269",
    "end": "849999"
  },
  {
    "text": "optimize in real time on the vehicle to to go so so look even optimizing that even if I know everything can be quite",
    "start": "849999",
    "end": "856240"
  },
  {
    "text": "challenging and then another question is what should be the reward function of the robot so what is our our look that's",
    "start": "856240",
    "end": "863709"
  },
  {
    "text": "a report design problem like what is a good reward function to put under on the autonomous car so I want to just briefly",
    "start": "863709",
    "end": "870550"
  },
  {
    "text": "talk about some of these questions I want to first talk about the reward function of the human unless there are",
    "start": "870550",
    "end": "875620"
  },
  {
    "text": "any questions on this other vehicles",
    "start": "875620",
    "end": "886449"
  },
  {
    "text": "that are kind of in our local vicinity we do take into account their actions into the formulation and now we assume",
    "start": "886449",
    "end": "892749"
  },
  {
    "text": "that we can affect them but most of our work we just consider the closest vehicle to me and think about the",
    "start": "892749",
    "end": "899139"
  },
  {
    "text": "effects and responses just between the two cars we were doing some work now that's thinking about it from the",
    "start": "899139",
    "end": "904480"
  },
  {
    "text": "transportation perspective of if I throw in like a few autonomous cars how can they help it something like traffic but",
    "start": "904480",
    "end": "911410"
  },
  {
    "text": "you're taking a very different view there so like it's a very high higher level Network level you I thought",
    "start": "911410",
    "end": "917259"
  },
  {
    "text": "control theory to me that's a final problem multi put multi output right you have to",
    "start": "917259",
    "end": "923529"
  },
  {
    "text": "say symmetry so humans on the other computer but still so you can think of",
    "start": "923529",
    "end": "930519"
  },
  {
    "text": "this as a game theoretic gray bear you don't have a symmetry like like you actually have symmetric my actions can",
    "start": "930519",
    "end": "935799"
  },
  {
    "text": "affect you your actions can affect me computationally you can't really solve that in real-time",
    "start": "935799",
    "end": "942700"
  },
  {
    "text": "no these are nonlinear narcotic but",
    "start": "942700",
    "end": "948770"
  },
  {
    "text": "anyway but they're not like they're going to fall into like local optima anyways they're not going to like sorry",
    "start": "948770",
    "end": "954460"
  },
  {
    "text": "if you do just oh I talked to it yeah learning does not solve that problem not",
    "start": "954460",
    "end": "962860"
  },
  {
    "text": "[Laughter] okay so let me talk about the reverse",
    "start": "964800",
    "end": "970610"
  },
  {
    "text": "function of the human so what is that like what are we actually doing in figuring out whether of course function is so the way we were approaching the",
    "start": "970610",
    "end": "977210"
  },
  {
    "text": "problem is running this algorithm called imitation learning or specifically",
    "start": "977210",
    "end": "982280"
  },
  {
    "text": "universe reinforcement learning or inverse optimal control same thing which is this idea of let me collect",
    "start": "982280",
    "end": "988070"
  },
  {
    "text": "trajectories of how humans drive and then from that learn a reward function that if I optimize that I would get the",
    "start": "988070",
    "end": "995180"
  },
  {
    "text": "same trajectories so it's learning from demonstrations I collect demonstrations of how humans like let's say pick up an object and",
    "start": "995180",
    "end": "1001270"
  },
  {
    "text": "from a lot of these demonstrations maybe I can figure out a reward function that if I optimize I I can get the same sort",
    "start": "1001270",
    "end": "1008110"
  },
  {
    "text": "of behavior and the specific assumption we are making here in this approach which is called maximum entropy in",
    "start": "1008110",
    "end": "1013690"
  },
  {
    "text": "reinforcement learning is probability of actions of humans is proportional to",
    "start": "1013690",
    "end": "1018820"
  },
  {
    "text": "exponential over rewards function so all that means is if I have an action that I think is better and it's going to take",
    "start": "1018820",
    "end": "1025209"
  },
  {
    "text": "me to a better state I'm going to wait that action exponentially higher so that's kind of the only assumption I'm",
    "start": "1025209",
    "end": "1031900"
  },
  {
    "text": "making on how humans are driving and you also need to kind of like put a structure around this reward function",
    "start": "1031900",
    "end": "1038290"
  },
  {
    "text": "the specific structure we are putting here is assuming that it's a linear combination of a set of hand-coded",
    "start": "1038290",
    "end": "1043630"
  },
  {
    "text": "features so these are things like collision avoidance or staying within your own lane or road or like this sort",
    "start": "1043630",
    "end": "1049630"
  },
  {
    "text": "of these are heading or your velocity or these different type of features that are representative here so the thing",
    "start": "1049630",
    "end": "1056980"
  },
  {
    "text": "that we want to learn at the end of the day are the weights of the features assuming that it's a linear combination of these nonlinear features and and with",
    "start": "1056980",
    "end": "1065350"
  },
  {
    "text": "this approach I would have a model of how normal human drivers are going to drive so it have this reward function",
    "start": "1065350",
    "end": "1071320"
  },
  {
    "text": "that I can learn offline from gathering trajectories of how human stray and then I can put that",
    "start": "1071320",
    "end": "1079130"
  },
  {
    "text": "back in here and I can go about solving this nested optimization so we have to make a few",
    "start": "1079130",
    "end": "1087020"
  },
  {
    "text": "approximations here to make this actually work in real time so I want to go through some of these approximations",
    "start": "1087020",
    "end": "1093020"
  },
  {
    "text": "so the first approximation is well first of all we don't have full knowledge of the world so what we are going to do is",
    "start": "1093020",
    "end": "1098480"
  },
  {
    "text": "we are going to apply this approach called model predictive control and then the idea is I have a horizon and I'm",
    "start": "1098480",
    "end": "1103730"
  },
  {
    "text": "going to pick that horizon plan for that horizon take a step and then refine and the horizon I pick is based on how much",
    "start": "1103730",
    "end": "1110930"
  },
  {
    "text": "my sensor concerns or based on how much computation power I have I might have liked so much computation power to",
    "start": "1110930",
    "end": "1116810"
  },
  {
    "text": "actually optimize this in real time on the vehicle and so this is a common approach that that we do the second",
    "start": "1116810",
    "end": "1124760"
  },
  {
    "text": "assumption is going back to this this game-playing thing that i was talking about so so if you think about it the actions of the robot affects the actions",
    "start": "1124760",
    "end": "1131450"
  },
  {
    "text": "of the human the actions of the human affects the actions of robots robot might know that and even like go further",
    "start": "1131450",
    "end": "1136910"
  },
  {
    "text": "in human might know that and then go further in and you might have like infinite regress already here like me",
    "start": "1136910",
    "end": "1142640"
  },
  {
    "text": "affecting you you affecting me and I'll go forever but the way we are solving this is actually as a stackelberg game",
    "start": "1142640",
    "end": "1150050"
  },
  {
    "text": "or as a leader follower game and the idea is you are cutting the game at the second time step I'm assuming my robot",
    "start": "1150050",
    "end": "1156890"
  },
  {
    "text": "is thinking it can affect the humans but the humans are observing the optimal actions of the robot and the reason that",
    "start": "1156890",
    "end": "1165110"
  },
  {
    "text": "this makes sense or works in this setting is humans don't really play chess when it comes to driving cars like",
    "start": "1165110",
    "end": "1171800"
  },
  {
    "text": "they're not thinking that many layers down there's actually psychology studies that talk about the fact that humans only think two levels downwind or",
    "start": "1171800",
    "end": "1178340"
  },
  {
    "text": "driving like they're not thinking about the effects of their actions so many layers down when they're driving so so",
    "start": "1178340",
    "end": "1186110"
  },
  {
    "text": "in that sense this is this is sort of okay and another reason that the this assumption doesn't hurt us too much is",
    "start": "1186110",
    "end": "1192380"
  },
  {
    "text": "you're solving this in a model predictive control fashion so your repining at every time step so even if I",
    "start": "1192380",
    "end": "1197870"
  },
  {
    "text": "make an incorrect kind of decision even if I don't like do the exactly right the right thing to do here I can reap on",
    "start": "1197870",
    "end": "1205250"
  },
  {
    "text": "have come out of it in the next time step and are finding horizon is like 0.1 seconds so you're planning for every",
    "start": "1205250",
    "end": "1210920"
  },
  {
    "text": "we're flying for every point five second but the step is point one yeah any so",
    "start": "1210920",
    "end": "1221240"
  },
  {
    "text": "the MPC where a sensor is 0.5 but the time step is point 1 yeah so so I plan",
    "start": "1221240",
    "end": "1227210"
  },
  {
    "text": "for the next point 5 seconds I take a step next point one second I'm in new place and I keep going how does that",
    "start": "1227210",
    "end": "1236780"
  },
  {
    "text": "interact with the human reaction time",
    "start": "1236780",
    "end": "1241810"
  },
  {
    "text": "yeah so they're studies looking at how human so human reactions there are",
    "start": "1242140",
    "end": "1249320"
  },
  {
    "text": "studies that talk about human reaction time and they can range from like two seconds to like eight seconds right depending on how much they're in control",
    "start": "1249320",
    "end": "1256310"
  },
  {
    "text": "or not and whatnot so yeah so in this case this is the kind",
    "start": "1256310",
    "end": "1262910"
  },
  {
    "text": "of reaction time of the autonomous car right so and then you're just observing where the human is and you're not really",
    "start": "1262910",
    "end": "1268430"
  },
  {
    "text": "like putting in human reaction time in this setup there's another work that I'm",
    "start": "1268430",
    "end": "1274700"
  },
  {
    "text": "not talking about it in this sock where you're doing transition of control to the human and there you're actually thinking about human reaction time and",
    "start": "1274700",
    "end": "1281150"
  },
  {
    "text": "how much can I plan further and like bringing in this idea of human reaction time in the story but yeah human",
    "start": "1281150",
    "end": "1287720"
  },
  {
    "text": "reaction times are not that great",
    "start": "1287720",
    "end": "1291820"
  },
  {
    "text": "because those tend to just cross legs or",
    "start": "1304090",
    "end": "1309890"
  },
  {
    "text": "if you see in your an Anaheim by a particular accent you see a car two lanes over to the left you know it's",
    "start": "1309890",
    "end": "1317630"
  },
  {
    "text": "going to cut across you to get on the ball that way yeah I'll come back to that so I'll come accident or oh nice",
    "start": "1317630",
    "end": "1323240"
  },
  {
    "text": "lights and then I'll come back to your question because like to slice from now",
    "start": "1323240",
    "end": "1328550"
  },
  {
    "text": "it's sort of answers the question but doesn't completely let's come back to that all right so I didn't and then",
    "start": "1328550",
    "end": "1336230"
  },
  {
    "text": "finally the final assumption we are making here is when you're modeling humans you're modeling them as probabilistic agents",
    "start": "1336230",
    "end": "1341990"
  },
  {
    "text": "who are approximately optimizing this reward function but when it comes to planning which is when you're solving this nested optimization you're actually",
    "start": "1341990",
    "end": "1349640"
  },
  {
    "text": "like assuming our humans are deterministic and are deterministic we're picking the maximum of the reward function as opposed to approximately",
    "start": "1349640",
    "end": "1356210"
  },
  {
    "text": "optimizing it again the reason is timing so the reason is I could technically say",
    "start": "1356210",
    "end": "1361940"
  },
  {
    "text": "the human is approximately optimizing this and kind of add like add like a noise factor into it but that can mess",
    "start": "1361940",
    "end": "1369260"
  },
  {
    "text": "up the timing of my optimization yeah all right so so then when we try to",
    "start": "1369260",
    "end": "1376580"
  },
  {
    "text": "solve this problem the type of like as I mentioned these are nonlinear non convex functions so the best really that we can",
    "start": "1376580",
    "end": "1383570"
  },
  {
    "text": "do these days is to use gradient descent type approaches so specifically we are",
    "start": "1383570",
    "end": "1388820"
  },
  {
    "text": "using quasi needs and techniques for their fast convergence and even doing that is not bad easy so if we're doing",
    "start": "1388820",
    "end": "1395420"
  },
  {
    "text": "something like gradient descent in this set up I need to have a model of why I need to have an expression representing",
    "start": "1395420",
    "end": "1401420"
  },
  {
    "text": "my reward function the thing I'm optimizing reward function robot so I already have that I also need to have an",
    "start": "1401420",
    "end": "1407720"
  },
  {
    "text": "expression for the gradient of the reward function with respect to a decision variable which is you are and",
    "start": "1407720",
    "end": "1412780"
  },
  {
    "text": "following chain rule I get that expression and this particular",
    "start": "1412780",
    "end": "1418130"
  },
  {
    "text": "expression is actually not that easy to find all its elements specifically this term is the term that I can't just",
    "start": "1418130",
    "end": "1425720"
  },
  {
    "text": "immediately have the value for it which is exactly how much the actions of the robot is affecting the actions of the",
    "start": "1425720",
    "end": "1431300"
  },
  {
    "text": "human so this is that that gradient is specifically specifying and Dada Dada",
    "start": "1431300",
    "end": "1436760"
  },
  {
    "text": "Dada amando value so what we were doing in this case is a math trick really so",
    "start": "1436760",
    "end": "1442190"
  },
  {
    "text": "so what we are doing is we're using implicit differentiation we are taking to the reward function of the human",
    "start": "1442190",
    "end": "1447400"
  },
  {
    "text": "that's a function I can take its derivative at the optimum which is UHS",
    "start": "1447400",
    "end": "1452810"
  },
  {
    "text": "start so I can take this gradient with respect to you H at the optimum that should be equal to zero that's only true",
    "start": "1452810",
    "end": "1459560"
  },
  {
    "text": "if my function is nice which is nice in my case then I can take another gradient of everything with respect to u R and",
    "start": "1459560",
    "end": "1466190"
  },
  {
    "text": "that's also equal to zero and pretty much every term here can be computed except",
    "start": "1466190",
    "end": "1471710"
  },
  {
    "text": "for this term so I can solve for that term and that's exactly the missing term that I had up there so I can basically",
    "start": "1471710",
    "end": "1478399"
  },
  {
    "text": "use this math trick of implicit differentiation to extract out this gradient put that back up there now I",
    "start": "1478399",
    "end": "1485510"
  },
  {
    "text": "have an expression for my gradient I have an expression for my function I can use my favorite quasi-newton method to",
    "start": "1485510",
    "end": "1491600"
  },
  {
    "text": "go about solving this so specifically we are using this method called l-bfgs and using tensorflow",
    "start": "1491600",
    "end": "1497270"
  },
  {
    "text": "to optimize things alright so let's look",
    "start": "1497270",
    "end": "1505429"
  },
  {
    "text": "at some of the implications of this so imagine I have an autonomous car that's",
    "start": "1505429",
    "end": "1510980"
  },
  {
    "text": "the orange car I have a human driven car that's a white car and let's say the autonomous car wants to change lanes it",
    "start": "1510980",
    "end": "1517789"
  },
  {
    "text": "wants to go to the left lane so so normally you would autonomous car is due today is something like the very more car so what they do is they look at the",
    "start": "1517789",
    "end": "1525279"
  },
  {
    "text": "velocity of the human driven car they project that and they want to be safe so they do something like this they slow",
    "start": "1525279",
    "end": "1531890"
  },
  {
    "text": "down and merge behind this vehicle so go behind this vehicle what our car does",
    "start": "1531890",
    "end": "1537500"
  },
  {
    "text": "based on this nested optimization thing that we are running it's actually something different our car this nice",
    "start": "1537500",
    "end": "1544039"
  },
  {
    "text": "act a little bit more aggressively and it cuts in front of but then that way",
    "start": "1544039",
    "end": "1552980"
  },
  {
    "text": "you never can change lanes like have you driven on 101 on 101 if you want to change lanes and if you don't cut in",
    "start": "1552980",
    "end": "1558679"
  },
  {
    "text": "front o people no one yes so I would say",
    "start": "1558679",
    "end": "1568159"
  },
  {
    "text": "this is more human like I agree that this is not like this might be a little bit more aggressive even right like cutting in front of people doesn't seem",
    "start": "1568159",
    "end": "1573919"
  },
  {
    "text": "that safe if I want to have a telling us cars that are super safe this is not a very safe thing to do like doing that but by doing that I'm actually like",
    "start": "1573919",
    "end": "1580700"
  },
  {
    "text": "violating not violating safety conditions but putting myself at more risk of colliding even but I'm actually",
    "start": "1580700",
    "end": "1589490"
  },
  {
    "text": "arguing that not doing that can also put you at risk because because if you're driving and waiting for every car to",
    "start": "1589490",
    "end": "1595010"
  },
  {
    "text": "pass like maybe the car behind you doesn't realize that you're driving or you're you're driving more mechanically",
    "start": "1595010",
    "end": "1601070"
  },
  {
    "text": "and then might actually hit you from behind so so Anna like I think human stripe like there's a",
    "start": "1601070",
    "end": "1606750"
  },
  {
    "text": "lot of times humans start like nudging in and cutting in front of people and making other people slow down by their",
    "start": "1606750",
    "end": "1612600"
  },
  {
    "text": "actions and this is if I have a model a true model of the human so in this case",
    "start": "1612600",
    "end": "1617760"
  },
  {
    "text": "I can only do this if my model of the human driven car is very good if I know exactly this human driven car is going",
    "start": "1617760",
    "end": "1624450"
  },
  {
    "text": "to respond and slow down we also saw some interesting other behaviors that",
    "start": "1624450",
    "end": "1632610"
  },
  {
    "text": "are definitely not human like so well we saw was with running this algorithm we",
    "start": "1632610",
    "end": "1639630"
  },
  {
    "text": "had the scenario in the two cars arrive at an intersection at the same time and the autonomous card the orange car here",
    "start": "1639630",
    "end": "1646260"
  },
  {
    "text": "is rewarded for making the human go first so it really wants the white car to",
    "start": "1646260",
    "end": "1651299"
  },
  {
    "text": "cross first this is actually the heat map of the reward function really wants the human car to just pass worse so what",
    "start": "1651299",
    "end": "1658620"
  },
  {
    "text": "our car decided to do in this setting was it was a little bit surprising decided to back up this hard doing but",
    "start": "1658620",
    "end": "1669720"
  },
  {
    "text": "if you think about it by backing up the car is making more room and making it safer and more likely for the human car",
    "start": "1669720",
    "end": "1677100"
  },
  {
    "text": "to cross first and and I've never seen any car autonomous or not autonomous",
    "start": "1677100",
    "end": "1682590"
  },
  {
    "text": "back up at intersections I computed that but I've seen pedestrians there's a lot",
    "start": "1682590",
    "end": "1687840"
  },
  {
    "text": "of sensor Destin's back up told you that you should cross first I'm not crossing so it was kind of interesting to see",
    "start": "1687840",
    "end": "1693510"
  },
  {
    "text": "that the car just decided to use motion to coordinate with the other driver without like hand coding anything of oh",
    "start": "1693510",
    "end": "1700020"
  },
  {
    "text": "I'm at an intersection or not it's like you just decided to use motion to better like coordinate with this other agent",
    "start": "1700020",
    "end": "1706100"
  },
  {
    "text": "it's called signalling yeah yeah so we don't have yeah so if we have if you",
    "start": "1706100",
    "end": "1711299"
  },
  {
    "text": "have an actual signal like you might actually get signaling behavior but in this case the only thing we have control",
    "start": "1711299",
    "end": "1716400"
  },
  {
    "text": "over is motion like that's the main thing we have control over behind it",
    "start": "1716400",
    "end": "1721620"
  },
  {
    "text": "what would happen that always comes up it's not going to echo it does have collision avoidance it cares about",
    "start": "1721620",
    "end": "1726720"
  },
  {
    "text": "collision avoidance more than like doing like this type of behavior so so there's a balance between the different things",
    "start": "1726720",
    "end": "1732299"
  },
  {
    "text": "that it's optimizing collision avoidance is definitely the first thing two mice and the interesting thing is",
    "start": "1732299",
    "end": "1738570"
  },
  {
    "text": "this is something that we get in human robot interaction - like if I have like a robot interacting with me in a home setting we are actually interested in",
    "start": "1738570",
    "end": "1745590"
  },
  {
    "text": "using motion to coordinate with people better or use like legible motion that's more like expressive for the human to do",
    "start": "1745590",
    "end": "1752280"
  },
  {
    "text": "things and it's kind of interesting to get more expressive motion from cars in this setup and they decided to",
    "start": "1752280",
    "end": "1757650"
  },
  {
    "text": "coordinate so of course none of this makes sense unless it works with real people so what we decided to do is we",
    "start": "1757650",
    "end": "1765000"
  },
  {
    "text": "decided to do a user study where we brought in users to drive on a car simulator with a steering wheel I'm braking pedal so this was a very simple",
    "start": "1765000",
    "end": "1772110"
  },
  {
    "text": "simulator where you actually did some studies later which fancier simulator zouri would actually feel their forces",
    "start": "1772110",
    "end": "1777330"
  },
  {
    "text": "this is like very simple but what we saw was for this scenario in a car decides",
    "start": "1777330",
    "end": "1783360"
  },
  {
    "text": "to backup the ideal human crosses first so being on the other side of star means",
    "start": "1783360",
    "end": "1788940"
  },
  {
    "text": "crossing first and the purple shirt actually corresponds to the ideal human and by ideal human what I mean is this",
    "start": "1788940",
    "end": "1795690"
  },
  {
    "text": "is the learned model of my human this is from inverse reinforcement learning this is me simulating what the human would do",
    "start": "1795690",
    "end": "1801570"
  },
  {
    "text": "if the human were to follow this reward function I've learned right so the",
    "start": "1801570",
    "end": "1807150"
  },
  {
    "text": "driving idea to Clara and I are all or they're a user study both of them from users and both of them were our grad",
    "start": "1807150",
    "end": "1814950"
  },
  {
    "text": "students our undergrads like running on the simulator and what we saw is though",
    "start": "1814950",
    "end": "1825240"
  },
  {
    "text": "our users do something very similar to the ideal human so the orange",
    "start": "1825240",
    "end": "1830429"
  },
  {
    "text": "directories corresponds to trajectories of real users this is the average and standard error of what the user soup and",
    "start": "1830429",
    "end": "1835890"
  },
  {
    "text": "they all cross first so they do something similar to the ideal human and they all cross first but if I'm not",
    "start": "1835890",
    "end": "1842730"
  },
  {
    "text": "planning with a human model if I'm doing the usual thing of just planning for the autonomous car without considering any",
    "start": "1842730",
    "end": "1848220"
  },
  {
    "text": "human models what my users decide to do is something very different they do the great trajectories and they all cross",
    "start": "1848220",
    "end": "1853950"
  },
  {
    "text": "second so the gap that we have here between the orange and grey trajectory is actually the gap that we can create",
    "start": "1853950",
    "end": "1859800"
  },
  {
    "text": "which is modeling humans and how they would respond into our planning algorithms which i think is kind of cool",
    "start": "1859800",
    "end": "1868470"
  },
  {
    "text": "all right so I think we kind of we all agree to generate safe motion we need to",
    "start": "1868470",
    "end": "1876250"
  },
  {
    "text": "anticipate what this human driven car might do next and and one way of anticipating that is by modeling the",
    "start": "1876250",
    "end": "1882970"
  },
  {
    "text": "human as an agent who is approximately optimizing maybe some reward function that's one way of modeling the human but",
    "start": "1882970",
    "end": "1891190"
  },
  {
    "text": "then we kind of run into this video just a little disturbing so this is a video",
    "start": "1891190",
    "end": "1896350"
  },
  {
    "text": "of a truck driver let me see if this runs and then there is a vehicle on the",
    "start": "1896350",
    "end": "1901420"
  },
  {
    "text": "side of the road it's signaling it's doing everything right for changing lanes until like now and for some reason",
    "start": "1901420",
    "end": "1909550"
  },
  {
    "text": "this truck driver is not letting this car in yeah so you might say maybe the",
    "start": "1909550",
    "end": "1917230"
  },
  {
    "text": "truck driver was sleep or very angry or completely out of it I think you what",
    "start": "1917230",
    "end": "1922570"
  },
  {
    "text": "our driver was kind of aggressive to it kept pushing if I was the other driver at some point I would give up I would go back to my lane me like this car is not",
    "start": "1922570",
    "end": "1929260"
  },
  {
    "text": "letting me in I'm done with this this is not happening so if you think about it well different",
    "start": "1929260",
    "end": "1935320"
  },
  {
    "text": "drivers have different driving styles you might have aggressive drivers or timid drivers or you might have distracted or attentive drivers and and",
    "start": "1935320",
    "end": "1943630"
  },
  {
    "text": "when it comes to modeling humans we can't just rely on a single driving style where we assume everyone follows",
    "start": "1943630",
    "end": "1949630"
  },
  {
    "text": "the same reward function and and just we can just go with that right we actually need to differentiate between different",
    "start": "1949630",
    "end": "1955630"
  },
  {
    "text": "people's driving styles and different ways that people respond to our actions so we thought about modeling that into",
    "start": "1955630",
    "end": "1962260"
  },
  {
    "text": "our formulation and that was kind of what we decided to do next so we took our formulation and we just added a term",
    "start": "1962260",
    "end": "1968170"
  },
  {
    "text": "let's call that terms theta and theta here just represents driving style and what I can do is I can have a belief",
    "start": "1968170",
    "end": "1975310"
  },
  {
    "text": "over the driving style and I can update that belief at every time step based on the observations that I get so",
    "start": "1975310",
    "end": "1982000"
  },
  {
    "text": "observations would be how this car is driving right next to me and observations is probability of actions of the human driven car given the state",
    "start": "1982000",
    "end": "1989260"
  },
  {
    "text": "and theta and I can just update my belief of how the car drives so this",
    "start": "1989260",
    "end": "1996040"
  },
  {
    "text": "kind of works ok but there is a problem with this and the problem is we got to get lucky",
    "start": "1996040",
    "end": "2002040"
  },
  {
    "text": "to see any informative behaviors from the white car here for example if I have",
    "start": "2002040",
    "end": "2007650"
  },
  {
    "text": "this turtle it looks harmless and I might go my whole life thinking that but it's holy",
    "start": "2007650",
    "end": "2014370"
  },
  {
    "text": "and you start poking the turned off that you realize what sort of turtle you're",
    "start": "2014370",
    "end": "2019410"
  },
  {
    "text": "dealing with so currently you're kind of stuck in the turtle situation you have",
    "start": "2019410",
    "end": "2024929"
  },
  {
    "text": "the white the the orange car it's kind of observing the white car it doesn't really know what the white car is going",
    "start": "2024929",
    "end": "2029970"
  },
  {
    "text": "to do next but it's just an impassive estimation of the behavior of the white",
    "start": "2029970",
    "end": "2036690"
  },
  {
    "text": "car but if you think about it the autonomous car is not just the passive observer let's sits there right it's",
    "start": "2036690",
    "end": "2042570"
  },
  {
    "text": "also an actor it can take actions and we have already seen like its actions can",
    "start": "2042570",
    "end": "2047730"
  },
  {
    "text": "actually influence other people right you can cut in front of people and make other people slow down for you so you",
    "start": "2047730",
    "end": "2052830"
  },
  {
    "text": "can actually make other people respond so yeah the cars that I've been driven",
    "start": "2052830",
    "end": "2061830"
  },
  {
    "text": "by people can also be automated and can have interactions with weight so if",
    "start": "2061830",
    "end": "2067290"
  },
  {
    "text": "every car was autonomous so my",
    "start": "2067290",
    "end": "2073280"
  },
  {
    "text": "coordinator yeah so if cars are connected or liquid-like short yeah yeah",
    "start": "2073280",
    "end": "2079290"
  },
  {
    "text": "there is there's a big literature on connected vehicles so connected so there",
    "start": "2079290",
    "end": "2085888"
  },
  {
    "text": "is a ton so there's a whole literature on autonomous vehicle if there's a whole digital and just connected vehicles I know people definitely like thinking",
    "start": "2085889",
    "end": "2091200"
  },
  {
    "text": "about like maybe we should change the infrastructure so cars can actually communicate with each other that sounds like a very reasonable thing to do so",
    "start": "2091200",
    "end": "2098010"
  },
  {
    "text": "there's a lot of research there in this case no we haven't like looked at like communication as much like explicit",
    "start": "2098010",
    "end": "2104460"
  },
  {
    "text": "communication as much but that quick like solved many problems and if all cars were autonomous and they could",
    "start": "2104460",
    "end": "2109740"
  },
  {
    "text": "communicate with each other like we didn't need like traffic we wouldn't need traffic lights like like everything",
    "start": "2109740",
    "end": "2114990"
  },
  {
    "text": "could just like go through and there is actually research that tries to like show that - for the other driver for the",
    "start": "2114990",
    "end": "2124650"
  },
  {
    "text": "other driver so if you could find out if the guys once you see crashing cars per",
    "start": "2124650",
    "end": "2129840"
  },
  {
    "text": "head so you cheating behind him the legal would you're not supposed to do that according",
    "start": "2129840",
    "end": "2136759"
  },
  {
    "text": "to them so maybe what we are doing is so",
    "start": "2136759",
    "end": "2142009"
  },
  {
    "text": "let me go back to what you're actually doing initiative and then doing something so what we actually do is we",
    "start": "2142009",
    "end": "2154970"
  },
  {
    "text": "try to bring in these actions these urs into our formulation and then what we",
    "start": "2154970",
    "end": "2161299"
  },
  {
    "text": "are optimizing for the reward function of the robot is now a combination of reaching the goal which is what it was",
    "start": "2161299",
    "end": "2167960"
  },
  {
    "text": "before this is what I was doing before and another term that corresponds to information gained so so this is a",
    "start": "2167960",
    "end": "2173930"
  },
  {
    "text": "difference between entropy over belief of driving style of this guy and this",
    "start": "2173930",
    "end": "2179119"
  },
  {
    "text": "time step or says next time step how much information can I get about this driver so so while I'm doing this like",
    "start": "2179119",
    "end": "2185660"
  },
  {
    "text": "when I'm optimizing this reward function my autonomous car is trying to reach at school but at the same time it tries to",
    "start": "2185660",
    "end": "2190910"
  },
  {
    "text": "kind of gain information about is it safe for me to cut in front of this person or is it not so it tries to like",
    "start": "2190910",
    "end": "2196069"
  },
  {
    "text": "get as much information as possible and and Landa here is the usual trade-off that we would have between exploration",
    "start": "2196069",
    "end": "2202309"
  },
  {
    "text": "and exploitation not a robotics type work so there is usually this problem like how much they explore how much",
    "start": "2202309",
    "end": "2208849"
  },
  {
    "text": "should I exploit and you're using standard techniques for setting lambda okay so then my robot is going to",
    "start": "2208849",
    "end": "2218420"
  },
  {
    "text": "optimize an expectation over the reward function because this is probabilistic now and what we see is for changing ways",
    "start": "2218420",
    "end": "2224930"
  },
  {
    "text": "if I don't really know what type of driver the white car is my algorithm the thing it decides to output is it decides",
    "start": "2224930",
    "end": "2230630"
  },
  {
    "text": "to kind of nudge in like creeping a little bit to see what happens and if it decides the white car here is",
    "start": "2230630",
    "end": "2237259"
  },
  {
    "text": "a distracted human it goes back to its Lane realizing this outer driver is not going to I mean this is not going to be",
    "start": "2237259",
    "end": "2243650"
  },
  {
    "text": "a safe thing to do but if it realizes that the white car in this case is attentive it completes the marriage",
    "start": "2243650",
    "end": "2250609"
  },
  {
    "text": "because it knows that this vehicle is actually going to slow down and make room for it so it kind of updates that",
    "start": "2250609",
    "end": "2257240"
  },
  {
    "text": "reward function on they go online to do a better behavior and safer behavior in this setup by doing active information",
    "start": "2257240",
    "end": "2264170"
  },
  {
    "text": "yet so again we decided to do user study so",
    "start": "2264170",
    "end": "2269290"
  },
  {
    "text": "in this case we had distracted drivers distracted the driver drivers were playing a game on a mobile phone they",
    "start": "2269290",
    "end": "2274990"
  },
  {
    "text": "were playing candy crush because I was obsessed with candy crush time and and",
    "start": "2274990",
    "end": "2280090"
  },
  {
    "text": "what we saw was for an intersection scenario this is a different",
    "start": "2280090",
    "end": "2285280"
  },
  {
    "text": "intersection scenario this is two cars arrive at intersection but the orange car wants to cross it doesn't",
    "start": "2285280",
    "end": "2290770"
  },
  {
    "text": "necessarily want the human the white car to cross first but it doesn't know what type of driver the white cars so if",
    "start": "2290770",
    "end": "2297850"
  },
  {
    "text": "you're doing passive estimation with passive estimation the autonomous car decides to just sit there just like does",
    "start": "2297850",
    "end": "2303340"
  },
  {
    "text": "nothing it sits and with passive estimation it becomes really hard to differentiate between distracted and",
    "start": "2303340",
    "end": "2310060"
  },
  {
    "text": "attentive humans they almost do the same thing so these are like data from real users again like I have the average and",
    "start": "2310060",
    "end": "2316690"
  },
  {
    "text": "standard error of different users that I have in this case but if I'm doing active information gathering my car",
    "start": "2316690",
    "end": "2323350"
  },
  {
    "text": "decides to nudge in creeping a little bit and then we actually see the behavior of the autonomous car here",
    "start": "2323350",
    "end": "2328840"
  },
  {
    "text": "decides to nudge in and if it decides the person is attentive it keeps going forward but if it decides to human is",
    "start": "2328840",
    "end": "2334900"
  },
  {
    "text": "distracted slows down and even goes back at some point and when the robot does",
    "start": "2334900",
    "end": "2340030"
  },
  {
    "text": "this when the autonomous car does this what we get is we actually get this type of behavior and we can easily",
    "start": "2340030",
    "end": "2346000"
  },
  {
    "text": "differentiate between distracted and attentive humans because they respond very differently so the gap here is kind",
    "start": "2346000",
    "end": "2351940"
  },
  {
    "text": "of the gap that our algorithm allows us to create because attentive drivers kind of slow down and let you go first and",
    "start": "2351940",
    "end": "2358210"
  },
  {
    "text": "don't cross on the other hand like distracted drivers don't see you and they continue like going ok and we can",
    "start": "2358210",
    "end": "2366670"
  },
  {
    "text": "even have like a look at the belief of driving style which was kind of the term we were looking at so if in the case",
    "start": "2366670",
    "end": "2372340"
  },
  {
    "text": "that people are attentive belief of attentiveness with active information gathering goes higher but it's passive",
    "start": "2372340",
    "end": "2378490"
  },
  {
    "text": "estimation almost stays the same throughout so it becomes really hard to kind of figure out what people are doing",
    "start": "2378490",
    "end": "2383910"
  },
  {
    "text": "right so kind of just to summarize this part of the talk really the key idea",
    "start": "2383910",
    "end": "2390760"
  },
  {
    "text": "here is that robots actions affect the actions of other drivers or other humans",
    "start": "2390760",
    "end": "2396010"
  },
  {
    "text": "around them and the thing we wanted to do was you want to actually model those effects and responses and even more than that",
    "start": "2396010",
    "end": "2401619"
  },
  {
    "text": "leverage those for better safety efficiency coordination and even estimation like as we see in the active",
    "start": "2401619",
    "end": "2408280"
  },
  {
    "text": "information gathering um so don't worry",
    "start": "2408280",
    "end": "2432430"
  },
  {
    "text": "the second part is not to lie but I was wondering if I should skip parts of it yeah so so that was kind of the big idea",
    "start": "2432430",
    "end": "2439210"
  },
  {
    "text": "that we had kind of been in this set up and let me started thinking about the human models a little bit more carefully",
    "start": "2439210",
    "end": "2445270"
  },
  {
    "text": "and thinking about well what is it about the humans that we really care about like looking at and and and yeah I'm",
    "start": "2445270",
    "end": "2452890"
  },
  {
    "text": "thinking about and yeah as you've seen already well different people might have different preferences about how any",
    "start": "2452890",
    "end": "2459700"
  },
  {
    "text": "given robot should act right and the problem is getting demonstration so the",
    "start": "2459700",
    "end": "2465790"
  },
  {
    "text": "way we are doing this right now the way that we modeled humans is by using inverse optimal control or aniversary",
    "start": "2465790",
    "end": "2471730"
  },
  {
    "text": "unfortunate learning where we collect trajectories of how humans do things like we get demonstrations from humans",
    "start": "2471730",
    "end": "2477880"
  },
  {
    "text": "but getting demonstrations from humans isn't always not that easy actually demonstrating trajectories for robots",
    "start": "2477880",
    "end": "2484930"
  },
  {
    "text": "with more than a few degrees of freedom can be quite challenging so there's actually work trying to look at teaching",
    "start": "2484930",
    "end": "2490630"
  },
  {
    "text": "robots to do tasks and when you have a robot with like seven degrees of freedom it becomes really difficult to",
    "start": "2490630",
    "end": "2495940"
  },
  {
    "text": "demonstrate a good trajectory and even tell operate that that robot to do a task you know in a way that is perfect",
    "start": "2495940",
    "end": "2501520"
  },
  {
    "text": "so first off demonstrations can be really challenging so is that even a good way of thinking about humans the second issue is there's",
    "start": "2501520",
    "end": "2509920"
  },
  {
    "text": "a study that looks at driving demonstrations and what they throw is",
    "start": "2509920",
    "end": "2515200"
  },
  {
    "text": "they collect the driving demonstrations and replayed the same demonstrations to the same people and apparently people",
    "start": "2515200",
    "end": "2522280"
  },
  {
    "text": "don't really like how they drive themselves it turns out they think their driving is aggressive and they",
    "start": "2522280",
    "end": "2529190"
  },
  {
    "text": "prefer something that's a little bit more conservative than their own driving so then if that is true then driving",
    "start": "2529190",
    "end": "2535579"
  },
  {
    "text": "demonstrations are not even that informative of of human's preferences of how a car should drive so we started",
    "start": "2535579",
    "end": "2543500"
  },
  {
    "text": "kind of thinking about this other idea that maybe instead of demonstrations we can leverage comparisons as opposed to",
    "start": "2543500",
    "end": "2550130"
  },
  {
    "text": "demonstrations which can be very useful observations of how a robot should act and what I mean by that is what I can do",
    "start": "2550130",
    "end": "2558470"
  },
  {
    "text": "is I can have this this FET robot that's going to do two different trajectories",
    "start": "2558470",
    "end": "2563869"
  },
  {
    "text": "and I can ask a user well which one do you prefer you don't need to tell operate this you don't need to like",
    "start": "2563869",
    "end": "2569390"
  },
  {
    "text": "actually get the robot do any of this but which one do you prefer like what if I if you were to compare this to which",
    "start": "2569390",
    "end": "2574730"
  },
  {
    "text": "one you prefer and if humans response tells me in four it gives me information if of if the human really wants the blue",
    "start": "2574730",
    "end": "2580549"
  },
  {
    "text": "Cup or the red Cup in this case in driving we can do a similar thing we can we can show two different trajectories",
    "start": "2580549",
    "end": "2586670"
  },
  {
    "text": "let's call those SCI asip and we would ask him and so which one do you prefer and in this case the humans response",
    "start": "2586670",
    "end": "2593960"
  },
  {
    "text": "gives us information about that reward function I've been talking about so I was trying to learn a reward function representing what the humans are doing",
    "start": "2593960",
    "end": "2600920"
  },
  {
    "text": "and if the human tells me well I likes ib oversee a that gives me information about which rewards function is so that",
    "start": "2600920",
    "end": "2608869"
  },
  {
    "text": "gives the information of w dot v fib is greater than W that's why a and W are",
    "start": "2608869",
    "end": "2615319"
  },
  {
    "text": "the weights the things we really want to learn and fees are these features these hand-coded features about each one of",
    "start": "2615319",
    "end": "2620539"
  },
  {
    "text": "these scenarios and they're evaluated at scenario a or scenario B so let me just",
    "start": "2620539",
    "end": "2627410"
  },
  {
    "text": "move things around a little bit so the question I'm really asking is let me define this new fee and the question I'm",
    "start": "2627410",
    "end": "2632809"
  },
  {
    "text": "really asking every time from the human is tell me if WI fee is positive or negative like I'm just asking which",
    "start": "2632809",
    "end": "2639349"
  },
  {
    "text": "which side of like the hyperplane of W dot fee I should be looking at so so",
    "start": "2639349",
    "end": "2645049"
  },
  {
    "text": "more specifically so imagine WY is in a three-dimensional space let's say that I only have three",
    "start": "2645049",
    "end": "2650510"
  },
  {
    "text": "ways so if that is the case well I can actually assume that W is in a unit pole",
    "start": "2650510",
    "end": "2655940"
  },
  {
    "text": "because the sign of W is the only thing we care about we don't actually care about about the value of W the sign is",
    "start": "2655940",
    "end": "2661010"
  },
  {
    "text": "the only thing trying to learn and we can sample from this space and every time I ask if the",
    "start": "2661010",
    "end": "2668550"
  },
  {
    "text": "human in question that that that that quarry or that question corresponds to a hyperplane in this space so that's a",
    "start": "2668550",
    "end": "2675630"
  },
  {
    "text": "hyperplane of W dot V equal to zero and the humans response gives me information",
    "start": "2675630",
    "end": "2680790"
  },
  {
    "text": "about which side is preferred so if the human tells me W dash P is positive I would take or negative I would take",
    "start": "2680790",
    "end": "2686700"
  },
  {
    "text": "either side of this hyperplane and then row what I can do is I can rear a things so I'm going to repay my samples and I'm",
    "start": "2686700",
    "end": "2694290"
  },
  {
    "text": "not completely removing the other side because we're assuming humans are noisy so they're not going to answer every",
    "start": "2694290",
    "end": "2699480"
  },
  {
    "text": "question accurately a hundred percent right this is actually the noise model we are using for the humans which is",
    "start": "2699480",
    "end": "2706109"
  },
  {
    "text": "using the Boltzmann distribution for how humans act backed by some psychology",
    "start": "2706109",
    "end": "2711810"
  },
  {
    "text": "literature so so this is my first question every time like this is my",
    "start": "2711810",
    "end": "2717180"
  },
  {
    "text": "first question the human tells me that it's on this side of the hyperplane so the second time that I'm coming up with",
    "start": "2717180",
    "end": "2722430"
  },
  {
    "text": "a question with a query it really matters like what hyperplane that corresponds to right I might pick a",
    "start": "2722430",
    "end": "2728580"
  },
  {
    "text": "question that corresponds to a hyperplane that gives me the exact information and quickly converges to the",
    "start": "2728580",
    "end": "2734700"
  },
  {
    "text": "thing I care about or I might ask another question that doesn't give me that information at all like it would be",
    "start": "2734700",
    "end": "2740130"
  },
  {
    "text": "a hyperplane that's not that informative so we're kind of modeling this problem as a volume removal problem like if",
    "start": "2740130",
    "end": "2746670"
  },
  {
    "text": "there's a volume here I'm trying to remove as much volume as possible to quickly converge to the particular W I",
    "start": "2746670",
    "end": "2752490"
  },
  {
    "text": "care about and and and do this in an active manner with the minimal number of queries I would need from the from the",
    "start": "2752490",
    "end": "2758880"
  },
  {
    "text": "human so the idea is when you are thinking about generating these queries",
    "start": "2758880",
    "end": "2764820"
  },
  {
    "text": "is query Z to be generated actively we should look at like the response of the human from the previous time step and",
    "start": "2764820",
    "end": "2770010"
  },
  {
    "text": "use that response to actively generate the next query and the big challenge",
    "start": "2770010",
    "end": "2776520"
  },
  {
    "text": "here is that when we are thinking about these queries these questions that I'm asking the human like this these queries",
    "start": "2776520",
    "end": "2782550"
  },
  {
    "text": "can lie in a very high dimensional space I need to eat it's a continuous high",
    "start": "2782550",
    "end": "2787740"
  },
  {
    "text": "dimensional space and I need to think about the initial position of all the vehicles and the environment I need to",
    "start": "2787740",
    "end": "2793980"
  },
  {
    "text": "come up with the church actors of all the other vehicles in the world and I also need to come up with two alternatives to informative",
    "start": "2793980",
    "end": "2800190"
  },
  {
    "text": "alternatives for for my own car and then this can be quite challenging because you're thinking about this continuous",
    "start": "2800190",
    "end": "2806070"
  },
  {
    "text": "high dimensional space and usually how people approach this is they discretize the world and they try to sample from",
    "start": "2806070",
    "end": "2812520"
  },
  {
    "text": "that discrete world but the way we're doing this is instead of discretizing the world we are directly synthesizing",
    "start": "2812520",
    "end": "2818910"
  },
  {
    "text": "these queries from the continuous space so we are solving this as an optimization problem as opposed to like",
    "start": "2818910",
    "end": "2824160"
  },
  {
    "text": "discretizing the world and sampling from that so more specifically this is the optimization so the problem we are",
    "start": "2824160",
    "end": "2832650"
  },
  {
    "text": "solving is we are trying to find a set of queries those are fees that maximize this minimum volume removed at every",
    "start": "2832650",
    "end": "2840089"
  },
  {
    "text": "time step so this is a volume inside of that that Yunis ball that I was showing you and then this term here is just",
    "start": "2840089",
    "end": "2846390"
  },
  {
    "text": "representing the minimum volume removed using that specific update function that we have up there subject to the fact",
    "start": "2846390",
    "end": "2853830"
  },
  {
    "text": "that these queries correspond to reasonable trajectories that are actually realistic and don't collide",
    "start": "2853830",
    "end": "2859560"
  },
  {
    "text": "with each other and are reasonable so so this is kind of a problem that allows us to create these queries and this is a",
    "start": "2859560",
    "end": "2866369"
  },
  {
    "text": "sub-module or optimization because our objective is volume removed here and we actually have methods that can do this",
    "start": "2866369",
    "end": "2872640"
  },
  {
    "text": "quite fast and minimize the number of queries like required to learn a model of the human so let's look at some of",
    "start": "2872640",
    "end": "2883830"
  },
  {
    "text": "the convergence results so what we saw was our method converges much faster than non active methods methods that",
    "start": "2883830",
    "end": "2889500"
  },
  {
    "text": "don't consider this previous response of the human and in addition to that it",
    "start": "2889500",
    "end": "2894599"
  },
  {
    "text": "even converges faster that methods that are active but discretize the world so when we are continuously generating",
    "start": "2894599",
    "end": "2900390"
  },
  {
    "text": "these queries we can actually come very much faster and what we saw was well we",
    "start": "2900390",
    "end": "2905730"
  },
  {
    "text": "actually ran this user study where we asked users and ask for their preferences in a driving scenario and",
    "start": "2905730",
    "end": "2911490"
  },
  {
    "text": "and what we saw was after like around 40 queries different users converge to very",
    "start": "2911490",
    "end": "2919980"
  },
  {
    "text": "similar and reasonable weights for each one of these features so we have five",
    "start": "2919980",
    "end": "2925500"
  },
  {
    "text": "features for the driving case these are the different features for the driving case this is the before figure of what the",
    "start": "2925500",
    "end": "2931289"
  },
  {
    "text": "weights are and as you can see the weights are converging to very similar results so each line corresponds to a",
    "start": "2931289",
    "end": "2936390"
  },
  {
    "text": "user so all users kind of prefer a very similar type of driving driving style",
    "start": "2936390",
    "end": "2941720"
  },
  {
    "text": "there are some differences between like the purple one let's say purple ones for collision avoidance so we kind of see",
    "start": "2941720",
    "end": "2949769"
  },
  {
    "text": "different convergences between these different different users and in addition to that well what we asked our",
    "start": "2949769",
    "end": "2956640"
  },
  {
    "text": "users was if they prefer this this reward function that's learned as opposed to other rewards function it's",
    "start": "2956640",
    "end": "2962249"
  },
  {
    "text": "like perturbations of the reward function and it's small or large noise and what we saw was the learned reward function from preferences is actually",
    "start": "2962249",
    "end": "2968970"
  },
  {
    "text": "quite like afterwards people were very happy with this particular learned reward function and it kind of",
    "start": "2968970",
    "end": "2974249"
  },
  {
    "text": "represents what humans want in driving all right questions so far so this is",
    "start": "2974249",
    "end": "2985650"
  },
  {
    "text": "kind of cool right this was the formulation we're doing active learning over humans preferences we were coming",
    "start": "2985650",
    "end": "2990989"
  },
  {
    "text": "up with a minimal number of queries to quickly converge to humans preferences and kind of our objective was I want to",
    "start": "2990989",
    "end": "2996930"
  },
  {
    "text": "do this fast I want to come up with the minimal number of things I can do this fast but problem with this optimization",
    "start": "2996930",
    "end": "3002989"
  },
  {
    "text": "is well synthesizing the queries themselves is a little too slow so sure",
    "start": "3002989",
    "end": "3008359"
  },
  {
    "text": "I have like only 10 queries and with 10 questions I can figure out what humans want but I ask my first question and an",
    "start": "3008359",
    "end": "3016099"
  },
  {
    "text": "irate like 20 minutes to come up with the next question and I wait another like 30 minutes to call over the third",
    "start": "3016099",
    "end": "3021499"
  },
  {
    "text": "question so synthesizing each one of these queries can be really slow and and",
    "start": "3021499",
    "end": "3026509"
  },
  {
    "text": "the other problem is humans responses come in sequentially so if you're doing this active method you actually need to",
    "start": "3026509",
    "end": "3032150"
  },
  {
    "text": "wait for the net response of the human to synthesize the next one so we have kind of this sequential process and you",
    "start": "3032150",
    "end": "3037670"
  },
  {
    "text": "have to wait for too long to actually get the answer for your for your optimization so the idea that we had was",
    "start": "3037670",
    "end": "3045380"
  },
  {
    "text": "well maybe instead of synthesizing these new new queries at every time step let's just synthesize a batch of queries",
    "start": "3045380",
    "end": "3050900"
  },
  {
    "text": "let's just pick a good batch of queries if I have that batch I can even paralyze things if I want to learn the",
    "start": "3050900",
    "end": "3056989"
  },
  {
    "text": "preferences of a population I can paralyze that and that that's probably good enough and that can make things much faster if",
    "start": "3056989",
    "end": "3063980"
  },
  {
    "text": "at every time step I'm computing a batch so that changes the optimization to",
    "start": "3063980",
    "end": "3069410"
  },
  {
    "text": "something like this so every time I'm running this optimization I'm optimizing a batch of them so I'm optimizing B",
    "start": "3069410",
    "end": "3075079"
  },
  {
    "text": "number of queries at the same time and and the big thing I want to I want to",
    "start": "3075079",
    "end": "3080720"
  },
  {
    "text": "make sure is is actually satisfied is I want to make sure that the elements inside of this patch are all so far from",
    "start": "3080720",
    "end": "3086359"
  },
  {
    "text": "each other there are also different in our from each other so we run a few heuristics honestly to make sure that",
    "start": "3086359",
    "end": "3091940"
  },
  {
    "text": "these elements in my batch are far enough from each other and the problem",
    "start": "3091940",
    "end": "3097279"
  },
  {
    "text": "of coming up with a good batch is this problem of maximizing the average pairwise distance between the elements",
    "start": "3097279",
    "end": "3102920"
  },
  {
    "text": "inside of the batch so this is called a maximum diversification problem it's shown to be np-hard so obviously we don't have like that",
    "start": "3102920",
    "end": "3110839"
  },
  {
    "text": "much of hope of finding the optimal thing here but we use these set of heuristics to just find the best match",
    "start": "3110839",
    "end": "3116869"
  },
  {
    "text": "possible so I don't want to go through all these heuristics so the idea is can",
    "start": "3116869",
    "end": "3122119"
  },
  {
    "text": "be approximated and we are approximating this with various heuristics so the simplest thing is I'm gonna greedily",
    "start": "3122119",
    "end": "3127670"
  },
  {
    "text": "pick the best one at every time step and pick the best elements here",
    "start": "3127670",
    "end": "3132710"
  },
  {
    "text": "but the problem ingredient is now like if my batch size is 5 and I'm selecting 5 points from from here the pairwise",
    "start": "3132710",
    "end": "3139279"
  },
  {
    "text": "distance between them is still quite small so so 1 & 2 are not that different from each other so 1 & 2 are not giving",
    "start": "3139279",
    "end": "3145880"
  },
  {
    "text": "me that information how much information so we've ran a few other heuristics I'm",
    "start": "3145880",
    "end": "3152930"
  },
  {
    "text": "not gonna go through all of them maybe I just I'll just briefly talk about the last one so this last method we are",
    "start": "3152930",
    "end": "3158869"
  },
  {
    "text": "using is called successive elimination and the very successive elimination works is we are gonna choose the closest",
    "start": "3158869",
    "end": "3164569"
  },
  {
    "text": "two pairs and then after that we are going to remove the one with the lowest entropy and we just keep repeating this",
    "start": "3164569",
    "end": "3171200"
  },
  {
    "text": "so I'm going to choose these two remove the one with lowest entropy choose these two remove the one with the lowest",
    "start": "3171200",
    "end": "3176539"
  },
  {
    "text": "entropy and I would keep doing that until I'm left with the right amount of",
    "start": "3176539",
    "end": "3182619"
  },
  {
    "text": "samples that I need in this case it's 5 and these are kind of the five samples that are far enough from each other and",
    "start": "3182619",
    "end": "3188539"
  },
  {
    "text": "are informative enough for my batch to use every time I run the algorithm",
    "start": "3188539",
    "end": "3194859"
  },
  {
    "text": "all right so here are some some results here so the green is going to be the",
    "start": "3195230",
    "end": "3201930"
  },
  {
    "text": "normal active learning method without any batch like using any battery obviously that's going to converge much",
    "start": "3201930",
    "end": "3207300"
  },
  {
    "text": "faster and everything else and this successive elimination method also converges fairly okay considering a kind",
    "start": "3207300",
    "end": "3215910"
  },
  {
    "text": "of a batch size here and obviously it's going to be worse than the non batch and fit but it performs relatively better",
    "start": "3215910",
    "end": "3221760"
  },
  {
    "text": "than some of these other heuristics we also like looked at this for this",
    "start": "3221760",
    "end": "3227730"
  },
  {
    "text": "particular driving example so for the driving example we kind of see the same type of plot here for for convergence so",
    "start": "3227730",
    "end": "3235320"
  },
  {
    "text": "non batch converges fairly fast successive elimination at some point like reaches the batch method",
    "start": "3235320",
    "end": "3240690"
  },
  {
    "text": "the other interesting thing is the time though so as you can see the time of the non batch method is much much worse than",
    "start": "3240690",
    "end": "3247290"
  },
  {
    "text": "the successive elimination so timing wise we would be doing a lot better when we have like a good batch size and then",
    "start": "3247290",
    "end": "3254880"
  },
  {
    "text": "in addition to that like one question might be well what is a good batch size so so what would be a good size to pick",
    "start": "3254880",
    "end": "3261120"
  },
  {
    "text": "so here this plot is kind of showing that so so we're looking at different results of convergence for different",
    "start": "3261120",
    "end": "3266280"
  },
  {
    "text": "batch sizes and we have the timing of each one of these batch sizes here so the idea would be if you have like",
    "start": "3266280",
    "end": "3271770"
  },
  {
    "text": "limited time then you can pick your specific time and that gives you a batch size and you kind of see the convergence",
    "start": "3271770",
    "end": "3277320"
  },
  {
    "text": "results there we don't have theoretical results connecting these two here so this is all",
    "start": "3277320",
    "end": "3282930"
  },
  {
    "text": "done like experimentally here okay all right so I'm gonna just quickly show",
    "start": "3282930",
    "end": "3288180"
  },
  {
    "text": "this for two example so this is for the driving case so with no prior preference",
    "start": "3288180",
    "end": "3294120"
  },
  {
    "text": "no idea what I'm doing so I'm doing crazy things and then after 30 queries our car is learning heading preferences",
    "start": "3294120",
    "end": "3300930"
  },
  {
    "text": "so it learns like what sort of heading it should keep and then after 70 queries it finally learns to keep heading and a",
    "start": "3300930",
    "end": "3307440"
  },
  {
    "text": "new collision avoidance and and finally just learns humans preferences so this is learning humans preferences without",
    "start": "3307440",
    "end": "3313440"
  },
  {
    "text": "any driving data it's just from like 70 comparisons between between generated trajectories using the batch active",
    "start": "3313440",
    "end": "3320130"
  },
  {
    "text": "learning method we've also like ran this for a bunch of different experiments I'm",
    "start": "3320130",
    "end": "3326100"
  },
  {
    "text": "not showing all of them the only thing I have here is the tosser example so this is a modular example where we have an agent",
    "start": "3326100",
    "end": "3332730"
  },
  {
    "text": "that is tossing a ball inside either one of these baskets the green basket is preferred so at the beginning it doesn't",
    "start": "3332730",
    "end": "3339270"
  },
  {
    "text": "know what the preferences is and over time it kind of learns how to throw a ball and how to throw it in a basket",
    "start": "3339270",
    "end": "3345780"
  },
  {
    "text": "it's kind of cool because it's just like on its own from comparisons it's learning throwing and learning how to",
    "start": "3345780",
    "end": "3352079"
  },
  {
    "text": "throw it in a basket so like it's a lot of things to learn basically all right",
    "start": "3352079",
    "end": "3363230"
  },
  {
    "text": "okay so just to summarize kind of this part of the talk well the idea here was",
    "start": "3363230",
    "end": "3369650"
  },
  {
    "text": "demonstrations getting demonstrations as difficult demonstrations can be noisy can not be really what we were looking",
    "start": "3369650",
    "end": "3375690"
  },
  {
    "text": "for so maybe we should be looking for something else like comparisons pairwise comparisons and try to use pairwise",
    "start": "3375690",
    "end": "3381900"
  },
  {
    "text": "comparisons to learn humans preferences and specifically we looked at this this active method where we actively",
    "start": "3381900",
    "end": "3388589"
  },
  {
    "text": "synthesize new queries to quickly converge to the true human reward",
    "start": "3388589",
    "end": "3393809"
  },
  {
    "text": "function and minimize the number of queries required to learn humans preferences and then after that we",
    "start": "3393809",
    "end": "3398970"
  },
  {
    "text": "realized well each one of the queries take a lot of time to be generated so instead can we use a batch method and by",
    "start": "3398970",
    "end": "3405599"
  },
  {
    "text": "using a batch method will we reduce the query generation time and in addition to that we can even paralyze things because",
    "start": "3405599",
    "end": "3411299"
  },
  {
    "text": "if I want to learn the human preferences of population I can just run run them at the same time and I don't need to wait",
    "start": "3411299",
    "end": "3417270"
  },
  {
    "text": "like sequential you wait for the for the responses to write okay so some of the",
    "start": "3417270",
    "end": "3423660"
  },
  {
    "text": "directions is we were thinking about going from here like about this project is if you think about it I've been",
    "start": "3423660",
    "end": "3430319"
  },
  {
    "text": "looking at the single reward function that's a linear combination of a set of features right and that reward function",
    "start": "3430319",
    "end": "3436319"
  },
  {
    "text": "alone might not be very representative of what humans are doing so we are trying to look at more interesting",
    "start": "3436319",
    "end": "3442200"
  },
  {
    "text": "models of humans like mixture models and trying to learn humans preferences when we have these more complicated models of",
    "start": "3442200",
    "end": "3449040"
  },
  {
    "text": "humans and there are some interesting theoretical questions there because her voice comparisons are actually not",
    "start": "3449040",
    "end": "3455309"
  },
  {
    "text": "enough for us to just learn like these mixture models if I have a mixture of",
    "start": "3455309",
    "end": "3460380"
  },
  {
    "text": "gaussians say representing what my humans do which is a good model of humans because maybe",
    "start": "3460380",
    "end": "3465500"
  },
  {
    "text": "humans in Boston Drive very differently from humans in power otters so so then you you actually might have a mixture",
    "start": "3465500",
    "end": "3471230"
  },
  {
    "text": "model so if you have that type of type of model pairwise comparisons are just not enough we actually need to like go",
    "start": "3471230",
    "end": "3477140"
  },
  {
    "text": "to a higher level and ask for a full ranking and all trajectories to try to learn this so those are some of the",
    "start": "3477140",
    "end": "3482230"
  },
  {
    "text": "theoretical directions we were looking at you're also thinking about combining comparisons and demonstrations and then",
    "start": "3482230",
    "end": "3488300"
  },
  {
    "text": "kind of get the good side of the both worlds to to quickly learn better models",
    "start": "3488300",
    "end": "3493310"
  },
  {
    "text": "of humans I don't know what I have after this oh so I was just gonna wrap up so",
    "start": "3493310",
    "end": "3499910"
  },
  {
    "text": "this is kind of the beginning picture that I had oh these are some of the things we were doing in my lab today so we are interested in human robot",
    "start": "3499910",
    "end": "3506600"
  },
  {
    "text": "interaction and collaboration so in general we are very interested in collaboration shared control trying to",
    "start": "3506600",
    "end": "3512690"
  },
  {
    "text": "predict humans intent from also just visual data you're looking at learning tell operation math so how can I like to",
    "start": "3512690",
    "end": "3518420"
  },
  {
    "text": "operate a robot with high degrees of freedom to do tasks you're interested in social navigation so if I have a robot",
    "start": "3518420",
    "end": "3524540"
  },
  {
    "text": "that navigates in crowds of people what sort of actions should it take how should it interact with people and also",
    "start": "3524540",
    "end": "3530600"
  },
  {
    "text": "you're doing some work around safety where we are thinking about safe learning so if I'm actively gathering information if I'm exploring can I do",
    "start": "3530600",
    "end": "3537560"
  },
  {
    "text": "that in a manner that's that's considered safe like how would I how would I do safe exploration about the",
    "start": "3537560",
    "end": "3543860"
  },
  {
    "text": "environment or the state of the other agents so these are some of the directions that you're currently looking at in my lab there are some other",
    "start": "3543860",
    "end": "3551480"
  },
  {
    "text": "assertions that or entry I don't want to go through your slides sure Oh slicer real quick",
    "start": "3551480",
    "end": "3557360"
  },
  {
    "text": "another another problem that we might have is if you remember my nested",
    "start": "3557360",
    "end": "3563120"
  },
  {
    "text": "optimization this was kind of the optimization I had there right I was assuming that my humans are optimizing",
    "start": "3563120",
    "end": "3569120"
  },
  {
    "text": "this our age this reward function and this is assuming humans or optimizers of a rational rewards function and if you",
    "start": "3569120",
    "end": "3576740"
  },
  {
    "text": "think about humans tend to be not very rational or optimizers and it's also hello today so that's Y all of the care",
    "start": "3576740",
    "end": "3589300"
  },
  {
    "text": "that's true actually what we are looking at right now so we aren't interested in thinking",
    "start": "3592330",
    "end": "3597469"
  },
  {
    "text": "about how human stripe and it comes to near access and is not this scenario but your accident scenarios and there's a",
    "start": "3597469",
    "end": "3603529"
  },
  {
    "text": "lot of interesting work from behavioral economics that thinks about similar type of problems like sadya of prospect",
    "start": "3603529",
    "end": "3609049"
  },
  {
    "text": "theory which is thinking about how humans behave when it comes to high gain and high loss situations and they might",
    "start": "3609049",
    "end": "3615739"
  },
  {
    "text": "not be optimizing a particular reward function and kind of some of these ideas",
    "start": "3615739",
    "end": "3621410"
  },
  {
    "text": "is the fact that humans are not irrational but they're bounded rational",
    "start": "3621410",
    "end": "3627019"
  },
  {
    "text": "so they have bounded resources maybe they have about a time about it memory quickly like this site and it's",
    "start": "3627019",
    "end": "3632390"
  },
  {
    "text": "challenging scenarios and the idea is can be used some of these some of these knowledge that exists in behavioral",
    "start": "3632390",
    "end": "3638660"
  },
  {
    "text": "economics to model humans and in scenarios that are challenging or in your accident setting",
    "start": "3638660",
    "end": "3645650"
  },
  {
    "text": "yeah maybe let me just talk about this real quick to so um so that's all good",
    "start": "3645650",
    "end": "3651079"
  },
  {
    "text": "typing model humans maybe I have models of my human driven cars and at the end of the day I need to plan for my",
    "start": "3651079",
    "end": "3656959"
  },
  {
    "text": "autonomous car I need to figure out what the autonomous car should do and sometimes when i model humans like this",
    "start": "3656959",
    "end": "3662689"
  },
  {
    "text": "two safest strategy for the autonomous car just doesn't exist like if I want to be safe and if I want to like assume my",
    "start": "3662689",
    "end": "3669650"
  },
  {
    "text": "humans falling to some some space then then sometimes I just cannot find like my controller will come out in feasible",
    "start": "3669650",
    "end": "3675619"
  },
  {
    "text": "or unrealizable and you would say well that just doesn't exist the thing you're looking for is not going to be safe and",
    "start": "3675619",
    "end": "3682069"
  },
  {
    "text": "then this is not a crazy idea even Google that's trying to go for your tournaments they have around 300 this",
    "start": "3682069",
    "end": "3688849"
  },
  {
    "text": "engagement in this engagements and 400k miles of driving so that's about oneness",
    "start": "3688849",
    "end": "3694579"
  },
  {
    "text": "engagement per month for a typical driver this engagement means that the car doesn't know what it's doing is",
    "start": "3694579",
    "end": "3700609"
  },
  {
    "text": "transferring control to the human or the human feels unsafe so the human is going to take take over control so if you",
    "start": "3700609",
    "end": "3708169"
  },
  {
    "text": "won't have that many dis engagements we need to have better ways of like handling these challenging scenarios and",
    "start": "3708169",
    "end": "3713839"
  },
  {
    "text": "and one way is this idea of transfer of control but I know if people have mixed feelings about transfer of control to",
    "start": "3713839",
    "end": "3719929"
  },
  {
    "text": "the human especially like considering humans reaction time if it is eight seconds lots of things can happen in",
    "start": "3719929",
    "end": "3725089"
  },
  {
    "text": "eight say but we should have better ways of thinking about this challenging risky scenarios maybe like have a supervisor",
    "start": "3725089",
    "end": "3730970"
  },
  {
    "text": "that takes over control and and I'm sure that's something that Google is thinking about these days too but in general like",
    "start": "3730970",
    "end": "3736190"
  },
  {
    "text": "we are interested in being able to diagnose and repair and understand what what caused the failure and then again",
    "start": "3736190",
    "end": "3742640"
  },
  {
    "text": "this is not just about cars it's about human robot interaction - if a robot fails at doing a task it shouldn't just",
    "start": "3742640",
    "end": "3748640"
  },
  {
    "text": "come out and say well sorry that didn't happen I failed it should just come out with some reasoning of why it felt like",
    "start": "3748640",
    "end": "3754430"
  },
  {
    "text": "what felt like what was it that you weren't able to do and have this kind of iterative process between the human and",
    "start": "3754430",
    "end": "3760339"
  },
  {
    "text": "robot to just do tasks better and and finally kind of another direction that",
    "start": "3760339",
    "end": "3765559"
  },
  {
    "text": "I'm very excited about these days is taking this whole idea of human robot interaction in autonomous driving to a",
    "start": "3765559",
    "end": "3772069"
  },
  {
    "text": "higher level when we are thinking about networks of vehicles and we have multiple autonomous cars and multiple",
    "start": "3772069",
    "end": "3777769"
  },
  {
    "text": "human driven cars and thinking about how interactions between autonomous and human driven cars can affect kind of",
    "start": "3777769",
    "end": "3784130"
  },
  {
    "text": "social objectives like like traffic or yeah so for example if I have a set of",
    "start": "3784130",
    "end": "3789140"
  },
  {
    "text": "trucks that can platoon and get behind each other maybe that can actually help with the traffic that you would see on",
    "start": "3789140",
    "end": "3795380"
  },
  {
    "text": "the roads and how can we like do that in a in an efficient manner all right",
    "start": "3795380",
    "end": "3800480"
  },
  {
    "text": "that's all this is a lab I can take any questions",
    "start": "3800480",
    "end": "3806528"
  },
  {
    "text": "[Applause]",
    "start": "3806890",
    "end": "3812269"
  },
  {
    "text": "so generally it seems that creating cases is really important with these mathematical models so you know like how",
    "start": "3814299",
    "end": "3820549"
  },
  {
    "text": "is the human driver going around where the environmental conditions so how many of these cases are inherently built in",
    "start": "3820549",
    "end": "3826760"
  },
  {
    "text": "models versus the model was creating new categories better than anything yeah and",
    "start": "3826760",
    "end": "3832730"
  },
  {
    "text": "it's so that's kind of like test case generation right like if I want to make sure that my models of the car driving",
    "start": "3832730",
    "end": "3838369"
  },
  {
    "text": "is going to work out well I need to generate new test cases so another project you're looking at right now it's actually automatic test case generation",
    "start": "3838369",
    "end": "3844730"
  },
  {
    "text": "like how can we automatically generate new interesting test cases the type of approaches we were thinking or similar",
    "start": "3844730",
    "end": "3849950"
  },
  {
    "text": "to the active learning type of approaches I was talking about so there we were actively generating scenarios to",
    "start": "3849950",
    "end": "3855829"
  },
  {
    "text": "figure out model of human now we want to actively generate new scenarios and informative scenarios that can tell us",
    "start": "3855829",
    "end": "3861680"
  },
  {
    "text": "something about like driving of the autonomous vehicle so that works very",
    "start": "3861680",
    "end": "3868400"
  },
  {
    "text": "well if everything falls into the model that I have in my simulator the other problem is most of unsafe settings could",
    "start": "3868400",
    "end": "3875599"
  },
  {
    "text": "happen because it's not even in the simulator so it's not it's like unknown unknown I didn't know that that I should",
    "start": "3875599",
    "end": "3881690"
  },
  {
    "text": "model that in my simulator and those are harder to catch it yeah how much data do",
    "start": "3881690",
    "end": "3890869"
  },
  {
    "text": "you have access to of actual driving scenarios and can you use that to make",
    "start": "3890869",
    "end": "3903400"
  },
  {
    "text": "okay we appear to have but a big batch of Boston drivers or New York drivers",
    "start": "3903400",
    "end": "3909829"
  },
  {
    "text": "versus simpler more civilized California [Laughter]",
    "start": "3909829",
    "end": "3918759"
  },
  {
    "text": "we're talking about here we collect our data on a simulator so we have the",
    "start": "3918759",
    "end": "3924079"
  },
  {
    "text": "simple simulator where we can do fancier controlling and then we have this force fact a force feedback simulator where we",
    "start": "3924079",
    "end": "3930470"
  },
  {
    "text": "actually fill the forces and it's like a little bit more realistic and here at Stanford you have the cars centers a",
    "start": "3930470",
    "end": "3936980"
  },
  {
    "text": "Center for Automotive Research so they're they basically have like a Honda sitting in a room kind of like this",
    "start": "3936980",
    "end": "3942770"
  },
  {
    "text": "and there was like a screen around you and you can basically sit in the Honda and drive and that's kind of where we look at collecting data we had some data",
    "start": "3942770",
    "end": "3950300"
  },
  {
    "text": "from car companies too but most of it was just like 101 driving data and yeah",
    "start": "3950300",
    "end": "3956450"
  },
  {
    "text": "so the how much matter is if it is all like 101 driving it it kind of like all looks the same so so the informativeness",
    "start": "3956450",
    "end": "3963560"
  },
  {
    "text": "of the data or kind of like diversity of the data is the main thing that would be interesting for us to look at yeah I",
    "start": "3963560",
    "end": "3970430"
  },
  {
    "text": "haven't seen much public data on like Boston driving or like knowledge of driving yeah every company for example",
    "start": "3970430",
    "end": "3977000"
  },
  {
    "text": "is collecting just their own camera",
    "start": "3977000",
    "end": "3992600"
  },
  {
    "text": "observe a lot about how people actually respond to experiments yes so there is",
    "start": "3992600",
    "end": "4003310"
  },
  {
    "text": "some data sets of like just cameras so there's this ng same data set which is a public data set that's online that is",
    "start": "4003310",
    "end": "4009940"
  },
  {
    "text": "just a camera looking at a highway and looks at like basically cars arriving so depends so for the traffic work for",
    "start": "4009940",
    "end": "4017080"
  },
  {
    "text": "you're looking at like traffic data like that high-level data of just cars like passing by it's probably good enough for",
    "start": "4017080",
    "end": "4023500"
  },
  {
    "text": "like Nora level I won't actually control this vehicle I want to know the location of my car I kind of haven't want to have",
    "start": "4023500",
    "end": "4029350"
  },
  {
    "text": "a good sensing over the other drivers are so so for that it's harder to find",
    "start": "4029350",
    "end": "4034420"
  },
  {
    "text": "like this proximity they're doing the",
    "start": "4034420",
    "end": "4039640"
  },
  {
    "text": "experiments you want to do yes super example yeah you're saying I could put like a sensor on my own car and then",
    "start": "4039640",
    "end": "4045160"
  },
  {
    "text": "drive around and get some data essentially sensor every car on the road",
    "start": "4045160",
    "end": "4050800"
  },
  {
    "text": "because they're all doing experiments on each other hmm yeah but like we don't have sensors on",
    "start": "4050800",
    "end": "4055870"
  },
  {
    "text": "all the cars and you don't have to its optics what I said i watch a car and I noticed it doing goofy stuff",
    "start": "4055870",
    "end": "4061870"
  },
  {
    "text": "uh-huh people drive that way yes yeah so so it's a combination of like that ng",
    "start": "4061870",
    "end": "4069670"
  },
  {
    "text": "smell you're like I'll have images of cars driving versus like some of these works like you could technically work",
    "start": "4069670",
    "end": "4075580"
  },
  {
    "text": "from images if like try to what we're looking at is follow them for a while to notice",
    "start": "4075580",
    "end": "4082060"
  },
  {
    "text": "because each car is going to be a different behavioral function and then there's how they respond to each other",
    "start": "4082060",
    "end": "4087850"
  },
  {
    "text": "and some people interact badly with each other and some people don't yeah so we could generate a bunch of",
    "start": "4087850",
    "end": "4094450"
  },
  {
    "text": "different models yeah and that's actually very interesting because like",
    "start": "4094450",
    "end": "4100088"
  },
  {
    "text": "when I think about this the interaction work I talked about you might say like",
    "start": "4100089",
    "end": "4106000"
  },
  {
    "text": "I'm going to slow down here because I just saw that car like taking over that other car so you look at the interaction",
    "start": "4106000",
    "end": "4111700"
  },
  {
    "text": "of other cars with each other and that affects your actions too which is not something we have model we haven't",
    "start": "4111700",
    "end": "4116830"
  },
  {
    "text": "modeled that here but that totally affects your actions too and that's kind of another layer of thinking about it it",
    "start": "4116830",
    "end": "4122020"
  },
  {
    "text": "certainly gives you a bottle of both cars the second it puzzles me how you",
    "start": "4122020",
    "end": "4133600"
  },
  {
    "text": "can get rich information about what the other driver is doing with the planning horizon less than the human reaction",
    "start": "4133600",
    "end": "4139450"
  },
  {
    "text": "time so um the model of the human yeah so the axial information so because for",
    "start": "4139450",
    "end": "4145930"
  },
  {
    "text": "the first book you're not doing active information gathering right if you're not doing active information gathering the model of the human is learned",
    "start": "4145930",
    "end": "4151088"
  },
  {
    "text": "offline so I'm not like you know you know like not you're not trying to update it in an online fashion in the",
    "start": "4151089",
    "end": "4157420"
  },
  {
    "text": "first work right so I'm just looking at how humans drive are fine then in an online fashion I just see what their",
    "start": "4157420",
    "end": "4162670"
  },
  {
    "text": "stake is and I just evaluate my function of my reward function in that state so I",
    "start": "4162670",
    "end": "4168069"
  },
  {
    "text": "don't need to like observe a history of the human or like 0.5 seconds of human driving to update that because I already",
    "start": "4168070",
    "end": "4174640"
  },
  {
    "text": "have a model of how normal drivers drive for the other kind of active information-gathering type of work",
    "start": "4174640",
    "end": "4179710"
  },
  {
    "text": "you're doing the nudging in type action so so with that you cannot kind of observe what people are doing and have",
    "start": "4179710",
    "end": "4185560"
  },
  {
    "text": "this belief kind of going over time it's not just so the belief is going to be a longer-term thing it's not just for the",
    "start": "4185560",
    "end": "4191920"
  },
  {
    "text": "planning horizon so my belief of the driving self the person if it is 50/50 aggressive not aggressive is I'm going",
    "start": "4191920",
    "end": "4199390"
  },
  {
    "text": "to keep that belief until I see that like like for the whole period of time that I see that car that question",
    "start": "4199390",
    "end": "4207960"
  },
  {
    "text": "oh it seems like that seven or eight",
    "start": "4207960",
    "end": "4215700"
  },
  {
    "text": "second human reaction time is from reading a book in a it's fully",
    "start": "4215700",
    "end": "4221550"
  },
  {
    "text": "autonomous car to getting the full situation of the two second is actually",
    "start": "4221550",
    "end": "4238230"
  },
  {
    "text": "reacting some easy actually thing is quite large I think it's the wrong like",
    "start": "4238230",
    "end": "4243630"
  },
  {
    "text": "I think it's quite I don't remember the like literature like that there's a study in Germany that looks at kind of",
    "start": "4243630",
    "end": "4249990"
  },
  {
    "text": "like all versions of it but I don't remember the exact number but I remember it was high you have a one-foot ruler",
    "start": "4249990",
    "end": "4261390"
  },
  {
    "text": "and you have somebody let it slip from their fingers and with you only to the",
    "start": "4261390",
    "end": "4267240"
  },
  {
    "text": "other end most people can catch it before it goes through and that's a quarter-second yeah what we're driving",
    "start": "4267240",
    "end": "4272730"
  },
  {
    "text": "like specifically for driving right I'm I'm very sure that it's like longer or",
    "start": "4272730",
    "end": "4278820"
  },
  {
    "text": "very long ger than the planning horizon that even a time like no multi miss Mars use like not even like model on humans",
    "start": "4278820",
    "end": "4283980"
  },
  {
    "text": "like usually the Thomas cars use a point two second like we're buying so it's definitely like longer than that yeah I",
    "start": "4283980",
    "end": "4291990"
  },
  {
    "text": "mean the state of the amygdala is gonna affect which mode the humanism yeah so I",
    "start": "4291990",
    "end": "4308610"
  },
  {
    "text": "don't know tell us like the exact details of it but from like what we see",
    "start": "4308610",
    "end": "4313800"
  },
  {
    "text": "like they have started thinking about like different models and kind of taking",
    "start": "4313800",
    "end": "4320220"
  },
  {
    "text": "that into account as opposed to previously like I remember like I don't know two years ago like even when you",
    "start": "4320220",
    "end": "4325470"
  },
  {
    "text": "talk to car companies so they they would model humans is they would model them as agents who are just going constant",
    "start": "4325470",
    "end": "4330930"
  },
  {
    "text": "velocity so if they're going 60 miles per hour they're just going to keep going 60 miles per hour it's not that",
    "start": "4330930",
    "end": "4336090"
  },
  {
    "text": "bad honestly because if you're doing MPC like even if you assume this person is going 60 miles per hour",
    "start": "4336090",
    "end": "4341530"
  },
  {
    "text": "Oh next second like it's not hurting you too much it just makes you to take like",
    "start": "4341530",
    "end": "4347200"
  },
  {
    "text": "more conservative actions because you think that person is not going to be ever affected actually you know going",
    "start": "4347200",
    "end": "4364120"
  },
  {
    "text": "too fast and then you're getting close so hard you get this big you know sound and you kind of like makes you a lot of",
    "start": "4364120",
    "end": "4375130"
  },
  {
    "text": "companies are heading to now like trying to drive the human can get to operate the human yeah yeah so now goes the",
    "start": "4375130",
    "end": "4385210"
  },
  {
    "text": "shares control so they're like different ways don't like they make sure it comes",
    "start": "4385210",
    "end": "4390430"
  },
  {
    "text": "into human robot interaction to me so that's it yes thank you",
    "start": "4390430",
    "end": "4397199"
  },
  {
    "text": "Terry today operates UAVs with more people environment that you're running",
    "start": "4399060",
    "end": "4416820"
  },
  {
    "text": "the software compiler and you know just all of that crap has to work nice to",
    "start": "4416820",
    "end": "4423190"
  },
  {
    "text": "work yes yes I realize here I'm assuming everything if they don't work the meatiness we can just make algorithms a",
    "start": "4423190",
    "end": "4429250"
  },
  {
    "text": "little bit more conservative so if I can model that that well with some uncertainty the system is going to fail",
    "start": "4429250",
    "end": "4435220"
  },
  {
    "text": "maybe I shouldn't trust my actions as much so so you can kind of just propagate that uncertainty back into",
    "start": "4435220",
    "end": "4440560"
  },
  {
    "text": "planning and make your actions a little bit more conservative so if I think my model of the human is not exactly right",
    "start": "4440560",
    "end": "4447280"
  },
  {
    "text": "or if I think I can't sense the human like exactly right with this probability I'm not going to cut in front of the",
    "start": "4447280",
    "end": "4452650"
  },
  {
    "text": "person I'm going to like slow down you",
    "start": "4452650",
    "end": "4457229"
  },
  {
    "text": "you",
    "start": "4463130",
    "end": "4465190"
  }
]
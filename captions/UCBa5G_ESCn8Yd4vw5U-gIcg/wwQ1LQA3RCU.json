[
  {
    "start": "0",
    "end": "5680"
  },
  {
    "text": "Hey, everyone. Thanks for coming to\nour CS25 lecture today. So today we're honored to\nhave Jim Fan from NVIDIA,",
    "start": "5680",
    "end": "12700"
  },
  {
    "text": "who we're talking\nabout generalist agents in open-ended worlds. And he's a senior AI\nresearch scientist",
    "start": "12700",
    "end": "19540"
  },
  {
    "text": "at NVIDIA, where his mission is\nto build generally capable AI agents with applications to\ngaming robotics and software",
    "start": "19540",
    "end": "27340"
  },
  {
    "text": "automation. And his research spans\nfoundation models, multimodal AI,\nreinforcement learning,",
    "start": "27340",
    "end": "33280"
  },
  {
    "text": "and open-ended learning. He obtained his PhD\ndegree in computer science",
    "start": "33280",
    "end": "38500"
  },
  {
    "text": "from here, at Stanford, advised\nby Professor Fei-Fei Li. And previously, he did\nresearch internships",
    "start": "38500",
    "end": "44920"
  },
  {
    "text": "at OpenAI, Google AI, as well\nas Mila-Quebec AI Institute.",
    "start": "44920",
    "end": "51129"
  },
  {
    "text": "So yeah, give it up for Jim. ",
    "start": "51130",
    "end": "60120"
  },
  {
    "text": "Yeah, thanks for having me. So I want to start with\na story of two kittens.",
    "start": "60120",
    "end": "67860"
  },
  {
    "text": "It's a story that gave me a lot\nof inspiration over my career. So I want to share\nthis one first.",
    "start": "67860",
    "end": "73950"
  },
  {
    "text": "You know, back in 1963,\nthere are two scientists from MIT, Held and Hein.",
    "start": "73950",
    "end": "79270"
  },
  {
    "text": "They did this\ningenious experiment where they put two newborn\nkittens in this device,",
    "start": "79270",
    "end": "85380"
  },
  {
    "text": "and the kittens have not\nseen the visual world yet. So it's kind of like\na merry-go-round where the two kittens are linked\nby a rigid mechanical bar.",
    "start": "85380",
    "end": "93789"
  },
  {
    "text": "So their movements are,\nlike, exactly mirrored. And there is an active kitten\non the right-hand side,",
    "start": "93790",
    "end": "99300"
  },
  {
    "text": "and that's the only one able to\nmove freely and then transmit the motion over this link\nto the passive kitten,",
    "start": "99300",
    "end": "106470"
  },
  {
    "text": "which is confined to the basket\nand cannot really control its own movements. And then, after\na couple of days,",
    "start": "106470",
    "end": "112860"
  },
  {
    "text": "Held and Hein kind of\ntake the kidneys out of this merry-go-round and then\ndid visual testing on them,",
    "start": "112860",
    "end": "119010"
  },
  {
    "text": "and they found that\nonly the active kitten was able to develop a\nhealthy visual motor loop.",
    "start": "119010",
    "end": "124140"
  },
  {
    "text": "Like, you know,\nresponding correctly to approaching objects\nor, like, visual cliffs. But the passive kitten did not\nhave a healthy visual system.",
    "start": "124140",
    "end": "132850"
  },
  {
    "text": "So I find this\nexperiment fascinating because it shows the\nimportance of having",
    "start": "132850",
    "end": "138580"
  },
  {
    "text": "this embodied, active\nexperience to really go round a system of intelligence.",
    "start": "138580",
    "end": "145970"
  },
  {
    "text": "And let's put this experiment\nin today's AI context, right? We actually have a very\npowerful passive kitten,",
    "start": "145970",
    "end": "152689"
  },
  {
    "text": "and that is ChatGPT. It passively observes\nand rehearses",
    "start": "152690",
    "end": "158150"
  },
  {
    "text": "the text on the internet, and\nit doesn't have any embodiment. And because of\nthis, its knowledge",
    "start": "158150",
    "end": "163340"
  },
  {
    "text": "is kind of abstract\nand ungrounded, and that partially\ncontributes to the fact that ChatGPT\nhallucinates things that",
    "start": "163340",
    "end": "170510"
  },
  {
    "text": "are just incompatible\nwith our common sense and our physical experience. And I believe the future\nbelongs to active kittens, which",
    "start": "170510",
    "end": "178880"
  },
  {
    "text": "translates to generalist agents. They are the decision-makers\nin a constant feedback loop,",
    "start": "178880",
    "end": "185000"
  },
  {
    "text": "and they are embodied in\nthis fully immersive world. They are also not\nmutually exclusive",
    "start": "185000",
    "end": "190430"
  },
  {
    "text": "with the passive kitten. And in fact, I see the\nactive embodiment part as a layer on top of the\npassive pre-training from lots",
    "start": "190430",
    "end": "198770"
  },
  {
    "text": "and lots of internet data. So, are we there yet?",
    "start": "198770",
    "end": "204790"
  },
  {
    "text": "Have we achieved generalization? You know, back in\n2016, I remember it was like spring of 2016.",
    "start": "204790",
    "end": "211570"
  },
  {
    "text": "I was sitting an undergraduate\nclass at Columbia University, but I wasn't paying\nattention to the lecture. I was watching a board game\ntournament on my laptop.",
    "start": "211570",
    "end": "220210"
  },
  {
    "text": "And this screenshot\nwas the moment when AlphaGo versus Lee\nSedol-- and AlphaGo won",
    "start": "220210",
    "end": "227430"
  },
  {
    "text": "three matches out of five\nand became the first ever to beat a human champion\nat a game of Go. You know, I remember the\nadrenaline that day, right?",
    "start": "227430",
    "end": "234690"
  },
  {
    "text": "I've seen history unfold. Oh, my god. We are, you know,\nfinally getting to HAI. And everyone is like so excited.",
    "start": "234690",
    "end": "240970"
  },
  {
    "text": "And I think that was the\nmoment when AI agents entered the mainstream. But, you know, like when\nthe excitement fades,",
    "start": "240970",
    "end": "249380"
  },
  {
    "text": "I felt that even though our\ngoal was so mighty and so great,",
    "start": "249380",
    "end": "254570"
  },
  {
    "text": "it could only do one\nthing and one thing alone. Right? And afterwards,\nyou know, in 2019,",
    "start": "254570",
    "end": "261229"
  },
  {
    "text": "there were more\nimpressive achievements. Like OpenAI Five beating\nthe human champions at a game of DOTA and AlphaStar\nfrom DeepMind beat StarCraft.",
    "start": "261230",
    "end": "270690"
  },
  {
    "text": "But all of these,\nwith AlphaGo, they all have a single kind of theme, and\nthat is to beat the opponent.",
    "start": "270690",
    "end": "278100"
  },
  {
    "text": "There is this one objective\nthat the agent needs to do, and the model is trained on DOTA\nor Go cannot generalize to any",
    "start": "278100",
    "end": "287539"
  },
  {
    "text": "other tasks. It cannot even play other games,\nlike Super Mario or Minecraft, and the world is fixed and have\nvery little room for open-ended",
    "start": "287540",
    "end": "295790"
  },
  {
    "text": "creativity and exploration. So I argue that a\ngeneralist agent",
    "start": "295790",
    "end": "301760"
  },
  {
    "text": "should have the following\nessential properties. First, it should\nbe able to pursue very complex, semantically\nrich, and open-ended objectives.",
    "start": "301760",
    "end": "310620"
  },
  {
    "text": "Basically, you explain what\nyou want in natural language, and the agent should\nperform the actions for you in a dynamic world.",
    "start": "310620",
    "end": "316760"
  },
  {
    "text": "And second, the agent\nshould have a large amount of pre-trained knowledge\ninstead of knowing",
    "start": "316760",
    "end": "322460"
  },
  {
    "text": "only a few concepts that's\nextremely specific to the task. And third, massively multitask.",
    "start": "322460",
    "end": "329020"
  },
  {
    "text": "Right? A generalist agent,\nas the name implies, needs to do more than\njust a couple of things.",
    "start": "329020",
    "end": "335310"
  },
  {
    "text": "It should be, in the best\ncase, infinitely multitask, as expressive as human\nlanguage can dictate.",
    "start": "335310",
    "end": "344120"
  },
  {
    "text": "So what does it take? Correspondingly, we need\nthree main ingredients.",
    "start": "344120",
    "end": "349310"
  },
  {
    "text": "First is the environment. Right? The environment needs\nto be open-ended enough",
    "start": "349310",
    "end": "354590"
  },
  {
    "text": "because the agent's\ncapability is upper bounded by the environment complexity.",
    "start": "354590",
    "end": "360800"
  },
  {
    "text": "And I'd argue that Earth is\nactually a perfect example because it's so open-ended\nin this world we live in",
    "start": "360800",
    "end": "366350"
  },
  {
    "text": "that it allows an\nalgorithm called natural evolution to produce all\nthe diverse forms and behaviors",
    "start": "366350",
    "end": "372140"
  },
  {
    "text": "of life on this planet. So can we have a simulator that\nis essentially a low-fi Earth,",
    "start": "372140",
    "end": "377600"
  },
  {
    "text": "but we can still run\nit on the lab clusters?",
    "start": "377600",
    "end": "383080"
  },
  {
    "text": "And second, we need\nto provide the agent with massive pre-training\ndata because exploration in an open-ended world from\nscratch is just intractable,",
    "start": "383080",
    "end": "391480"
  },
  {
    "text": "and the data will serve\nat least two purposes. One, as a reference manual\non how to do things.",
    "start": "391480",
    "end": "397250"
  },
  {
    "text": "And second, as a\nguidance on what are the interesting\nthings worth pursuing. And, you know, GPT is\nonly at least up to GPT 4.",
    "start": "397250",
    "end": "406419"
  },
  {
    "text": "It only learns from\npure text on the web. But can we provide agent\nwith much richer data,",
    "start": "406420",
    "end": "411780"
  },
  {
    "text": "such as video walkthrough, or\nlike multimedia wiki documents,",
    "start": "411780",
    "end": "417060"
  },
  {
    "text": "and other media forms? And finally, once we have the\nenvironment and the database,",
    "start": "417060",
    "end": "424470"
  },
  {
    "text": "we are ready to train foundation\nmodels for the agents, and it should be flexible enough\nto pursue the open-ended tasks",
    "start": "424470",
    "end": "431759"
  },
  {
    "text": "without any\ntask-specific assumptions and also scalable\nenough to compress",
    "start": "431760",
    "end": "436950"
  },
  {
    "text": "all of the multimodal data\nthat I just described. And here, language,\nI argue, will",
    "start": "436950",
    "end": "442740"
  },
  {
    "text": "play at least two key roles. One is as a simple and\nintuitive interface to communicate a task, to\ncommunicate the human intentions",
    "start": "442740",
    "end": "450870"
  },
  {
    "text": "to the agent. And second, as a\nbridge to ground all of the multimodal\nconcepts and signals.",
    "start": "450870",
    "end": "457659"
  },
  {
    "text": "And that train of\nthought landed us in Minecraft, the best-selling\nvideo game of all time.",
    "start": "457660",
    "end": "465250"
  },
  {
    "text": "And for those who\nare unfamiliar, Minecraft is a procedurally\ngenerated 3D voxel world.",
    "start": "465250",
    "end": "471350"
  },
  {
    "text": "And in the game,\nyou can basically do whatever your heart desires. And what's so special\nabout the game",
    "start": "471350",
    "end": "476700"
  },
  {
    "text": "is that unlike AlphaGo,\nStarCraft, or DOTA, Minecraft defines no particular\nobjective to maximize,",
    "start": "476700",
    "end": "485280"
  },
  {
    "text": "no particular opponent\nto beat, and doesn't even have a fixed storyline. And that makes it very well\nsuited as a truly open-ended AI",
    "start": "485280",
    "end": "492630"
  },
  {
    "text": "playground. And here, we see people doing\nextremely impressive things in Minecraft.",
    "start": "492630",
    "end": "497890"
  },
  {
    "text": "Like, this is a\nYouTube video where a gamer built the entire\nHogwarts Castle block by block",
    "start": "497890",
    "end": "504570"
  },
  {
    "text": "by hand in a game. And here's another example\nof someone just digging",
    "start": "504570",
    "end": "510300"
  },
  {
    "text": "a big hole in the\nground and then making this beautiful\nunderground temple with a river",
    "start": "510300",
    "end": "515789"
  },
  {
    "text": "nearby. It's all crafted by hand. And one more. This is someone building\na functioning CPU circuit",
    "start": "515789",
    "end": "524750"
  },
  {
    "text": "inside a game because\nthere is something called redstone in Minecraft that\nyou can build circuits out",
    "start": "524750",
    "end": "531500"
  },
  {
    "text": "of it, like logical gates. And actually the game\nis turing complete. You can simulate a\ncomputer inside a game.",
    "start": "531500",
    "end": "538200"
  },
  {
    "text": "Just think about\nhow crazy that is. And here I want to\nhighlight a number, that is 140 million active players.",
    "start": "538200",
    "end": "546060"
  },
  {
    "text": "And just to put this\nnumber in perspective, this is more than twice\nthe population of UK.",
    "start": "546060",
    "end": "552950"
  },
  {
    "text": "And that is the amount\nof people playing Minecraft on a daily basis. And, you know, it\njust so happens",
    "start": "552950",
    "end": "558690"
  },
  {
    "text": "that gamers are generally\nhappier than PhDs. So they love to stream and\nshare what they're doing,",
    "start": "558690",
    "end": "566350"
  },
  {
    "text": "and that produces a huge amount\nof data every day online. And there's this treasure\ntrove of learning materials",
    "start": "566350",
    "end": "573839"
  },
  {
    "text": "that we can tap into for\ntraining generalist agents. You know, remember, the data is\nthe key for foundation models.",
    "start": "573840",
    "end": "581270"
  },
  {
    "text": "So we introduce MineDojo,\na new open framework to help the community develop\ngenerally capable agents using",
    "start": "581270",
    "end": "589760"
  },
  {
    "text": "Minecraft as a kind\nof primordial soup. ",
    "start": "589760",
    "end": "595070"
  },
  {
    "text": "MineDojo features\nthree major parts-- an open-ended environment, an\ninternet-scale knowledge base,",
    "start": "595070",
    "end": "600920"
  },
  {
    "text": "and then a generalist agent\ndeveloped with a simulator and a massive data.",
    "start": "600920",
    "end": "606200"
  },
  {
    "text": "So let's zoom in the first one. Here is a sample gallery\nof the interesting things",
    "start": "606200",
    "end": "611389"
  },
  {
    "text": "that you can do\nwith MineDojo's API. We feature a massive\nbenchmarking suite of more than",
    "start": "611390",
    "end": "617600"
  },
  {
    "text": "3,000 tasks, and this is by far\nthe largest open source agent",
    "start": "617600",
    "end": "622610"
  },
  {
    "text": "benchmark to our knowledge. And we implement a\nvery versatile API that unlocks the full\npotential of the game.",
    "start": "622610",
    "end": "629400"
  },
  {
    "text": "Like, for example, MineDojo\nsupports multimodal observation and for action\nspace, like moving,",
    "start": "629400",
    "end": "637040"
  },
  {
    "text": "or attack, or\ninventory management. And then it can be\ncustomized at every detail.",
    "start": "637040",
    "end": "642140"
  },
  {
    "text": "Like you can tweak the terrains,\nthe weather, block placement,",
    "start": "642140",
    "end": "647510"
  },
  {
    "text": "monster spawning,\nand just anything you want to customize\nin the game. And given the simulator,\nwe introduce around 1,500",
    "start": "647510",
    "end": "655900"
  },
  {
    "text": "programmatic tasks, which are\ntasks that have grown through success conditions\ndefined in Python code.",
    "start": "655900",
    "end": "662920"
  },
  {
    "text": "And you can also\nexplicitly write down like the sparse or the dense\nreward functions using this API. And some examples are like\nharvesting different resources,",
    "start": "662920",
    "end": "670870"
  },
  {
    "text": "unlocking the tech tree, or\nfighting various monsters and getting reward.",
    "start": "670870",
    "end": "676510"
  },
  {
    "text": "And all these tasks\ncome with language prompts that are templated. Next, we also introduce\n1,500 creative tasks that are",
    "start": "676510",
    "end": "684990"
  },
  {
    "text": "free-form and open-ended,\nand that is in contrast to the programmatic\ntasks I just mentioned.",
    "start": "684990",
    "end": "690380"
  },
  {
    "text": "So, for example, let's say we\nwant the agent to put a house. But what makes a\nhouse a house, right?",
    "start": "690380",
    "end": "697320"
  },
  {
    "text": "It is ill-defined. And just like image\ngeneration, you don't know if it generates\na cat correctly or not.",
    "start": "697320",
    "end": "704960"
  },
  {
    "text": "So it's very difficult to\nuse simple Python programs to give these kind of\ntask reward functions.",
    "start": "704960",
    "end": "710420"
  },
  {
    "text": "And the best way is to use\nfoundation models trained on internet-scale knowledge\nso that the model itself",
    "start": "710420",
    "end": "717800"
  },
  {
    "text": "understands abstract\nconcepts like, you know, the concept of a house.",
    "start": "717800",
    "end": "724139"
  },
  {
    "text": "And finally, there's\none task that holds a very special\nstatus called playthrough, which is to beat the final boss\nof Minecraft, the Ender Dragon.",
    "start": "724140",
    "end": "732209"
  },
  {
    "text": "So Minecraft doesn't\nforce you to do this task. As we said, it doesn't\nhave a fixed storyline, but it's still considered\na really big milestone",
    "start": "732210",
    "end": "739350"
  },
  {
    "text": "for any kind of\nbeginner human players. I want to highlight it is an\nextremely difficult task that",
    "start": "739350",
    "end": "745860"
  },
  {
    "text": "requires very complex\npreparation, exploration, and also martial skills. And for an average\nhuman, it will",
    "start": "745860",
    "end": "752610"
  },
  {
    "text": "take many hours or\neven days to solve easily over like\none million action",
    "start": "752610",
    "end": "758610"
  },
  {
    "text": "steps in a single episode. And that would be the longest\nbenchmarking task for policy",
    "start": "758610",
    "end": "763649"
  },
  {
    "text": "learning ever created here. So I admit I am personally\na below-average human.",
    "start": "763650",
    "end": "769170"
  },
  {
    "text": "I was never able to\nbeat Ender Dragon, and my friends laugh at me. And I'm like, OK, one day, my\nAI will avenge my poor skills.",
    "start": "769170",
    "end": "778660"
  },
  {
    "text": "Right? That was one of the\nmotivations for this project. Now, let's move on to\nthe second ingredient,",
    "start": "778660",
    "end": "785850"
  },
  {
    "text": "the internet-scale knowledge\nbase part of MineDojo. We offer three data sets here,\nthe YouTube, Wiki, and Reddit.",
    "start": "785850",
    "end": "792980"
  },
  {
    "text": "And combined, they are the\nlargest open-ended agent behavior database ever\ncompiled to our knowledge.",
    "start": "792980",
    "end": "800589"
  },
  {
    "text": "The first is YouTube,\nand we already said Minecraft is one of the\nmost streamed games on YouTube.",
    "start": "800590",
    "end": "807430"
  },
  {
    "text": "And gamers love to narrate\nwhat they're doing. So we collected more than\n700,000 videos with two billion",
    "start": "807430",
    "end": "814779"
  },
  {
    "text": "words in the\ncorresponding transcripts. And these transcripts\nwill help the agent",
    "start": "814780",
    "end": "820000"
  },
  {
    "text": "learn about human strategies and\ncreativities without us manually labeling things.",
    "start": "820000",
    "end": "825420"
  },
  {
    "text": " And second, the\nMinecraft player base",
    "start": "825420",
    "end": "830470"
  },
  {
    "text": "is so crazy that\nthey have compiled a huge Minecraft-specific\nWikipedia that basically",
    "start": "830470",
    "end": "837370"
  },
  {
    "text": "explains everything\nyou ever need to know in every version of the game. It's crazy.",
    "start": "837370",
    "end": "843260"
  },
  {
    "text": "And we scrape 7,000 wiki pages\nwith interleaving multimodal data like images,\ntables, and diagrams,",
    "start": "843260",
    "end": "850420"
  },
  {
    "text": "and here are some screenshots. Like this is a gallery\nof all of the monsters and their corresponding\nbehaviors,",
    "start": "850420",
    "end": "857410"
  },
  {
    "text": "like spawn and attack patterns. And also, like the\nthousands of crafting",
    "start": "857410",
    "end": "862420"
  },
  {
    "text": "recipes are all present on the\nWiki, and we scrape all of them. And while like complex\ndiagrams, and tables,",
    "start": "862420",
    "end": "868360"
  },
  {
    "text": "and embedded figures, now we\nhave something like GPT-4V. It may be able to understand\nmany of these diagrams.",
    "start": "868360",
    "end": "876680"
  },
  {
    "text": "And finally, the\nMinecraft subreddit is one of the most active\nforums across the entire Reddit.",
    "start": "876680",
    "end": "883610"
  },
  {
    "text": "And players showcase\ntheir creations and also ask questions for help. So we scraped more than 300,000\nposts from the Minecraft Reddit.",
    "start": "883610",
    "end": "892220"
  },
  {
    "text": "And here are some\nexamples of how people use the Reddit as a kind\nof Stack Overflow for Minecraft.",
    "start": "892220",
    "end": "899180"
  },
  {
    "text": "And we can see that some\nof the top-voted answers are actually quite good. Like someone is asking, oh,\nwhy doesn't my wheat farm grow?",
    "start": "899180",
    "end": "906033"
  },
  {
    "text": "And the answer says\nyou need to light up the room with more torches. You don't have enough lighting.",
    "start": "906033",
    "end": "912270"
  },
  {
    "text": "Now, given the massive task\nsuite and internet data, we have the essential components\nto build generalist agents.",
    "start": "912270",
    "end": "921180"
  },
  {
    "text": "So in the first\nMineDojo paper, we introduced a foundation\nmodel called MineCLIP. And the idea is very simple.",
    "start": "921180",
    "end": "927850"
  },
  {
    "text": "I can explain it\nin three slides. Basically, for our\nYouTube database, we have time-aligned\nvideos and transcripts.",
    "start": "927850",
    "end": "935500"
  },
  {
    "text": "And these are actually\nthe real tutorial videos from our data set. You see on the third\nclip, you know,",
    "start": "935500",
    "end": "942400"
  },
  {
    "text": "as I raise my ax in\nfront of this pig, there's only one thing that\nyou know going to happen.",
    "start": "942400",
    "end": "947590"
  },
  {
    "text": "There is actually\nsomeone who said this, a big YouTuber of Minecraft.",
    "start": "947590",
    "end": "952890"
  },
  {
    "text": "And then, given\nthis data, we train MineCLIP in the same\nspirit as OpenAI CLIP.",
    "start": "952890",
    "end": "958649"
  },
  {
    "text": "So for those who are\nunfamiliar, OpenAI CLIP is a contrastive model\nthat learns the association",
    "start": "958650",
    "end": "964620"
  },
  {
    "text": "between image and its caption. And here it's a\nvery similar idea. But this time it is a video\ntext contrastive model,",
    "start": "964620",
    "end": "972240"
  },
  {
    "text": "and we associate the text\nwith a video snippet that runs about 8 to 16 seconds each.",
    "start": "972240",
    "end": "979010"
  },
  {
    "text": " And intuitively, MineCLIP\nlearns the association",
    "start": "979010",
    "end": "985720"
  },
  {
    "text": "between the video\nand the transcript that describes the\nactivity in the video.",
    "start": "985720",
    "end": "990850"
  },
  {
    "text": "And MineCLIP outputs a\nscore between 0 and 1, where one means a perfect\ncorrelation between the text",
    "start": "990850",
    "end": "996279"
  },
  {
    "text": "and video, and 0 means the text\nis irrelevant to the activity. So you see, this is effectively\na language-prompted foundation",
    "start": "996280",
    "end": "1005370"
  },
  {
    "text": "reward model that knows\nthe nuances of things like forests, animal, behaviors,\nand architectures in Minecraft.",
    "start": "1005370",
    "end": "1014730"
  },
  {
    "text": "So how do we use\nMineCLIP in action? Here's an example of our agent\ninteracting with the simulator.",
    "start": "1014730",
    "end": "1021220"
  },
  {
    "text": "And here, the task is\nshear sheep to obtain wool. And as the agent explores\nin the simulator,",
    "start": "1021220",
    "end": "1028230"
  },
  {
    "text": "it generates a video snippet\nas a moving window, which can be encoded and\nfed into MineCLIP",
    "start": "1028230",
    "end": "1035310"
  },
  {
    "text": "along with an encoding\nof the text prompt here. And MineCLIP completes\nthe association.",
    "start": "1035310",
    "end": "1040909"
  },
  {
    "text": "Right? The higher the\nassociation is, the more the agent's behavior\nin this video aligns",
    "start": "1040910",
    "end": "1047230"
  },
  {
    "text": "with the language, which is\na task you want it to do. And that becomes\nthe reward function",
    "start": "1047230",
    "end": "1052270"
  },
  {
    "text": "to any reinforcement\nlearning algorithm. So this looks very\nfamiliar, right?",
    "start": "1052270",
    "end": "1058240"
  },
  {
    "text": "Because It's essentially\nRL from human feedback, or RLHF in Minecraft.",
    "start": "1058240",
    "end": "1065970"
  },
  {
    "text": "And RLHF was the\ncornerstone algorithm that made ChatGPT\npossible, and I believe it will play a critical\nrole in generalist agents",
    "start": "1065970",
    "end": "1073440"
  },
  {
    "text": "as well. I'll quickly gloss over\nsome quantitative results.",
    "start": "1073440",
    "end": "1078730"
  },
  {
    "text": "I promise there won't be like\nmany tables of numbers here. For these eight tasks, we show\nthe percentage success rate",
    "start": "1078730",
    "end": "1085210"
  },
  {
    "text": "over 200 test episodes. And here in the green\ncircle is two variants",
    "start": "1085210",
    "end": "1090670"
  },
  {
    "text": "of our MineCLIP method. And in the orange circles\nare the baselines. So I'll highlight\none baseline, which",
    "start": "1090670",
    "end": "1097890"
  },
  {
    "text": "is that we construct a dense\nreward function manually for each task using\nthe MineDojo API.",
    "start": "1097890",
    "end": "1104550"
  },
  {
    "text": "It's a Python API. And you can consider this\ncolumn as a kind of Oracle, the upper bound of\nthe performance,",
    "start": "1104550",
    "end": "1110790"
  },
  {
    "text": "because we put a\nlot of human efforts into designing these reward\nfunctions just for the tasks.",
    "start": "1110790",
    "end": "1117000"
  },
  {
    "text": "And we can see that\nMineCLIP is able to match the quality of many of these.",
    "start": "1117000",
    "end": "1122140"
  },
  {
    "text": "Not all of them, but\nmany of these manual engineering rewards. It is important to\nhighlight that MineCLIP",
    "start": "1122140",
    "end": "1127769"
  },
  {
    "text": "is open vocabulary. So we use a single model for\nall of these tasks instead of one model for each, and we\nsimply prompt the reward model",
    "start": "1127770",
    "end": "1135899"
  },
  {
    "text": "with different tasks. And that's the only variation. ",
    "start": "1135900",
    "end": "1143000"
  },
  {
    "text": "One major feature\nof foundation model is strong generalization\nout of box. So can now agent generalize\nto dramatic changes",
    "start": "1143000",
    "end": "1150860"
  },
  {
    "text": "in the visual appearance? So we did this experiment\nwhere, during training, we only train our agents on a default\nterrain at noon on a sunny day.",
    "start": "1150860",
    "end": "1161420"
  },
  {
    "text": "But we tested zero-shot in\na diverse range of terrains, weathers, and day-night cycles,\nand you can customize everything",
    "start": "1161420",
    "end": "1168120"
  },
  {
    "text": "in MineDojo. And in our paper,\nwe have numbers showing that MineCLIP\nsignificantly beats an off-the-shelf\nvisual encoder when",
    "start": "1168120",
    "end": "1175670"
  },
  {
    "text": "facing these kind of\ndistribution shift out of box. And this is no surprise, right? Because MineCLIP was trained\non hundreds of thousands",
    "start": "1175670",
    "end": "1182720"
  },
  {
    "text": "of clips from Minecraft\nvideos on YouTube, which have a very good\ncoverage of all the scenarios.",
    "start": "1182720",
    "end": "1191140"
  },
  {
    "text": "And I think that is just a\ntestament to the big advantage of using internet-scale data\nbecause you get robustness out",
    "start": "1191140",
    "end": "1199750"
  },
  {
    "text": "of box. And here are some demos of\nour learned agent behaviors on various tasks.",
    "start": "1199750",
    "end": "1205710"
  },
  {
    "text": "So you may notice that these\ntasks are relatively short, around like 100\nto 500 timestamps.",
    "start": "1205710",
    "end": "1212010"
  },
  {
    "text": "And that is because\nMineCLIP is not able to plan over very\nlong time horizons.",
    "start": "1212010",
    "end": "1218200"
  },
  {
    "text": "And it is an inherent limitation\nin the training pipeline because we could only use 8\nto 16 seconds of the video,",
    "start": "1218200",
    "end": "1225370"
  },
  {
    "text": "so it's constrained\nto like short actions. But our hope is to build an\nagent that can explore and make",
    "start": "1225370",
    "end": "1231809"
  },
  {
    "text": "new discoveries autonomously\njust all by itself, and it keeps going. And in 2022, this goal seems\nquite out of reach for us.",
    "start": "1231810",
    "end": "1239860"
  },
  {
    "text": "MineDojo was June 2022. And this year,\nsomething happened. And that is GPT-4, a language\nmodel that's so good at coding",
    "start": "1239860",
    "end": "1249710"
  },
  {
    "text": "and long-horizon planning, so\nwe just cannot sit still, right? We built Voyager, the\nfirst large language",
    "start": "1249710",
    "end": "1257120"
  },
  {
    "text": "model-powered lifelong\nlearning agent. And when we set Voyager\nloose in Minecraft,",
    "start": "1257120",
    "end": "1262790"
  },
  {
    "text": "we see that it just keeps going. And by the way, all\nthese video snippets are from a single\nepisode of Voyager.",
    "start": "1262790",
    "end": "1269810"
  },
  {
    "text": "It's not from\ndifferent episodes. It's a single one. And we see that Voyager is\njust able to keep exploring",
    "start": "1269810",
    "end": "1277030"
  },
  {
    "text": "the terrains, mine all kinds of\nmaterials, fight monsters, craft hundreds of recipes, and\nunlock an ever-expanding tree",
    "start": "1277030",
    "end": "1284529"
  },
  {
    "text": "of diverse skills. So how do we do this?",
    "start": "1284530",
    "end": "1290020"
  },
  {
    "text": "If we want to use the\nfull power of GPT-4, a central question is\nhow to stringify things,",
    "start": "1290020",
    "end": "1295149"
  },
  {
    "text": "converting this 3D world into\na textual representation. We need a magic box here.",
    "start": "1295150",
    "end": "1302520"
  },
  {
    "text": "And thankfully, again, the crazy\nMinecraft community already built one for us, and it's\nbeen around for many years.",
    "start": "1302520",
    "end": "1309390"
  },
  {
    "text": "It's called Mineflayer,\na high-level JavaScript API that's actively maintained\nto work with any Minecraft",
    "start": "1309390",
    "end": "1315809"
  },
  {
    "text": "version. And the beauty of\nMineflayer is it has access to the game\nstate's surrounding agent,",
    "start": "1315810",
    "end": "1322500"
  },
  {
    "text": "like the nearby blocks,\nanimals, and enemies. So we effectively have a\nground-truth perception module",
    "start": "1322500",
    "end": "1329190"
  },
  {
    "text": "as textual input. And at the same time, Mineflayer\nalso supports action APIs",
    "start": "1329190",
    "end": "1334410"
  },
  {
    "text": "that we can compose skills. And now that we can\nconvert everything to text,",
    "start": "1334410",
    "end": "1340470"
  },
  {
    "text": "we are ready to construct\nan agent on top of GPT-4. So on a high level, there\nare three components.",
    "start": "1340470",
    "end": "1346710"
  },
  {
    "text": "One is a coding module\nthat writes JavaScript code to control the\ngame bot, and it's",
    "start": "1346710",
    "end": "1353039"
  },
  {
    "text": "the main module that generates\nthe executable actions. And second, we have a code base\nto store the correctly written",
    "start": "1353040",
    "end": "1360149"
  },
  {
    "text": "code and look it\nup in the future if the agent needs\nto recall the skill. And in this way, we\ndon't duplicate efforts.",
    "start": "1360150",
    "end": "1366707"
  },
  {
    "text": "And when we're facing similar\nsituations in the future, the agent knows what to do. And third, we have\na curriculum that",
    "start": "1366708",
    "end": "1374130"
  },
  {
    "text": "proposes what to do next, given\nthe agent's current capabilities and also situation.",
    "start": "1374130",
    "end": "1379830"
  },
  {
    "text": "And when you wire these\ncomponents up together, you get a loop that drives the\nagent indefinitely and achieves",
    "start": "1379830",
    "end": "1387240"
  },
  {
    "text": "something like\nlifelong learning. So let's zoom in\nthe center module.",
    "start": "1387240",
    "end": "1393159"
  },
  {
    "text": "We prompt GPT-4 with\ndocumentations and examples on how to use a subset\nof the Mineflayer API,",
    "start": "1393160",
    "end": "1399730"
  },
  {
    "text": "and GPT-4 writes code\nto take actions given the current assigned task. And because JavaScript\nruns a code interpreter,",
    "start": "1399730",
    "end": "1407059"
  },
  {
    "text": "GPT-4 is able to define\nfunctions on the fly and run it interactively. But the code that GPT-4 writes\nisn't always correct, right?",
    "start": "1407060",
    "end": "1414740"
  },
  {
    "text": "Just like human errors,\nyou can't get everything correct on the first try. So we developed an iterative\nprompting mechanism",
    "start": "1414740",
    "end": "1421000"
  },
  {
    "text": "to refine the program. And there are three\ntypes of feedback here. The environment feedback.",
    "start": "1421000",
    "end": "1426655"
  },
  {
    "text": "Like, you know, what\nare the new materials you got after taking\nan action, or, you know, some enemies nearby?",
    "start": "1426655",
    "end": "1432799"
  },
  {
    "text": "And the execution error from\nthe JavaScript interpreter, if you wrote some buggy code\nlike undefined variable,",
    "start": "1432800",
    "end": "1438970"
  },
  {
    "text": "for example, if it\nhallucinates something. And another GPT-4 that provides\ncritique through self-reflection",
    "start": "1438970",
    "end": "1447009"
  },
  {
    "text": "from the Asian state and the\nworld state, and that also helps refine the program effectively.",
    "start": "1447010",
    "end": "1453309"
  },
  {
    "text": "So I want to show\nsome quick example of how the critic provides\nfeedback on the task completion",
    "start": "1453310",
    "end": "1458620"
  },
  {
    "text": "progress. So let's say in\nthe first example, the task is to craft\na spyglass, and GPT-4",
    "start": "1458620",
    "end": "1464620"
  },
  {
    "text": "looks at the agent's\ninventory and decides that it has enough copper\nbut not enough amherst",
    "start": "1464620",
    "end": "1470470"
  },
  {
    "text": "as a material. And the second task is to kill\nthree sheeps to collect food.",
    "start": "1470470",
    "end": "1475630"
  },
  {
    "text": "And each sheep drops\none unit of wool, but there are only two\nunits in the inventory. So two different reasons and\nsays that, OK, you have one more",
    "start": "1475630",
    "end": "1483490"
  },
  {
    "text": "sheep to go, and likewise. Now, moving on to\nthe second part.",
    "start": "1483490",
    "end": "1489770"
  },
  {
    "text": "Once Voyager implements\na skill correctly, we save it to our\npersistent storage.",
    "start": "1489770",
    "end": "1495350"
  },
  {
    "text": "And you can think of the skill\nlibrary as a code repository written entirely by a language\nmodel through interaction with",
    "start": "1495350",
    "end": "1502640"
  },
  {
    "text": "the 3D world. And the agent can\nrecord new skills and also retrieve skills\nfrom the library facing",
    "start": "1502640",
    "end": "1509570"
  },
  {
    "text": "similar situations\nin the future, so it doesn't have to go through\nthis whole program refinement that we just saw, which\nis quite inefficient.",
    "start": "1509570",
    "end": "1516870"
  },
  {
    "text": "But you do it once,\nyou save it to disk. And in this way, Voyager kind of\nbootstraps its own capabilities",
    "start": "1516870",
    "end": "1524240"
  },
  {
    "text": "recursively as it explores\nand experiments in a game.",
    "start": "1524240",
    "end": "1529473"
  },
  {
    "text": "And let's dive a\nlittle bit deeper into how the skill\nlibrary is implemented. So this is how we\ninsert a new skill.",
    "start": "1529473",
    "end": "1535940"
  },
  {
    "text": "First, we use GPT 3.5\nto summarize the program into plain English, and\nsummarization is very easy.",
    "start": "1535940",
    "end": "1542140"
  },
  {
    "text": "And GPT-4 is\nexpensive, so we just go for a cheaper, cheaper tier.",
    "start": "1542140",
    "end": "1547330"
  },
  {
    "text": "And then we embed this\nsummary as the key, and we save the program,\nwhich is a bunch of code,",
    "start": "1547330",
    "end": "1553600"
  },
  {
    "text": "as the value. And we find that doing\nthis makes retrieval better because the\nsummary is more semantic",
    "start": "1553600",
    "end": "1559720"
  },
  {
    "text": "and the code is a\nbit more discreet. And you insert it. ",
    "start": "1559720",
    "end": "1566600"
  },
  {
    "text": "And now for the\nretrieval process. When Voyager is faced\nwith a new task, let's say craft iron\npickaxe, we again",
    "start": "1566600",
    "end": "1573679"
  },
  {
    "text": "use GPT 3.5 to generate a\nhint on how to solve the task, and that is something like a\nnatural language paragraph.",
    "start": "1573680",
    "end": "1580430"
  },
  {
    "text": "And then we embed that\nand use that as the query into the vector database,\nand we retrieve the skill",
    "start": "1580430",
    "end": "1587930"
  },
  {
    "text": "from the library. So you can think of it as\na kind of in-context replay",
    "start": "1587930",
    "end": "1593289"
  },
  {
    "text": "buffer in the reinforcement\nlearning literature. And now, moving on\nto the third part.",
    "start": "1593290",
    "end": "1600950"
  },
  {
    "text": "We have another GPT-4 that\nproposes a task to do, given its own capabilities\nat the moment.",
    "start": "1600950",
    "end": "1607549"
  },
  {
    "text": "And here, we give GPT-4\na very high-level kind of unsupervised\nobjective, that is,",
    "start": "1607550",
    "end": "1612740"
  },
  {
    "text": "to obtain as many unique\nitems as possible. That is our\nhigh-level directive. And then GPT-4\ntakes this directive",
    "start": "1612740",
    "end": "1619610"
  },
  {
    "text": "and implements a curriculum of\nprogressively harder challenges",
    "start": "1619610",
    "end": "1624710"
  },
  {
    "text": "and more novel\nchallenges to solve. So it's kind of like\ncuriosity exploration, where",
    "start": "1624710",
    "end": "1631850"
  },
  {
    "text": "it is called novelty search\nin the prior literature but implemented\npurely in context. Yeah, if you are listening, then\nassume the next example is fun.",
    "start": "1631850",
    "end": "1640032"
  },
  {
    "text": "[LAUGHING] Let's go through this\nexample together, right? Just to show you\nhow Voyager works,",
    "start": "1640032",
    "end": "1647120"
  },
  {
    "text": "the whole complicated data\nflow that I just showed. So, the agent finds\nitself hungry.",
    "start": "1647120",
    "end": "1653480"
  },
  {
    "text": "It only has one out\nof 20 hunger bar. So GPT-4 knows that it\nneeds to find food ASAP.",
    "start": "1653480",
    "end": "1659100"
  },
  {
    "text": "And then it senses there are\nfour entities nearby, a cat, a villager, a pig,\nand some wheat seeds.",
    "start": "1659100",
    "end": "1666350"
  },
  {
    "text": "And now GPT-4 starts a\nself-reflection, right? Like, do I kill the cat and\nvillager to get some meat?",
    "start": "1666350",
    "end": "1672070"
  },
  {
    "text": "That sounds horrible. How about the wheat seeds? I can use the seeds\nto grow a farm,",
    "start": "1672070",
    "end": "1677610"
  },
  {
    "text": "but that's going to\ntake a very long time until I can generate some food. So, sorry, Piggy.",
    "start": "1677610",
    "end": "1682870"
  },
  {
    "text": "You are the one being chosen. [LAUGHTER] So GPT-4 looks at the inventory,\nwhich is the agent state.",
    "start": "1682870",
    "end": "1689160"
  },
  {
    "text": "There is a piece of\niron in inventory. So it recalls-- Voyager recalls a skill\nfrom the library, that",
    "start": "1689160",
    "end": "1696060"
  },
  {
    "text": "is to craft an iron sword\nand then use that skill to start pursuing, to\nstart learning a new skill,",
    "start": "1696060",
    "end": "1702220"
  },
  {
    "text": "and that is hunt pig. And once the hunt-pig\nroutine is successful,",
    "start": "1702220",
    "end": "1707909"
  },
  {
    "text": "GPT-4 saves it to\nthe skill library. That's roughly how it works.",
    "start": "1707910",
    "end": "1712930"
  },
  {
    "text": "Yeah. And putting all\nof these together, we have this iterative prompting\nmechanism, the skill library,",
    "start": "1712930",
    "end": "1718169"
  },
  {
    "text": "and an automatic curriculum. And all of these\ncombine is Voyager's",
    "start": "1718170",
    "end": "1723320"
  },
  {
    "text": "no-gradient architecture, where\nwe don't train any new models or fine-tune any parameters, and\nallows Voyager to self-bootstrap",
    "start": "1723320",
    "end": "1732740"
  },
  {
    "text": "on top of GPT-4\neven though we are treating the underlying\nlanguage model as a black box. ",
    "start": "1732740",
    "end": "1740640"
  },
  {
    "text": "It looks like my example worked,\nand they started to listen. [LAUGHS]",
    "start": "1740640",
    "end": "1745919"
  },
  {
    "text": "Yeah. So yeah, these are the\ntasks that Voyager picked up",
    "start": "1745920",
    "end": "1751570"
  },
  {
    "text": "along the way. And we didn't\npre-program any of these. It's all Voyager's idea.",
    "start": "1751570",
    "end": "1756610"
  },
  {
    "text": "The agent is kind of\nforever curious and also forever pursuing new\nadventures just by itself.",
    "start": "1756610",
    "end": "1763779"
  },
  {
    "text": "So to quickly show some\nquantitative results, here we have a\nlearning curve where",
    "start": "1763780",
    "end": "1770080"
  },
  {
    "text": "the x-axis is the number\nof prompting iterations, and the y-axis is the\nnumber of unique items",
    "start": "1770080",
    "end": "1776080"
  },
  {
    "text": "that Voyager discovered as\nit's exploring in environment. And these two curves are\nbaselines, ReAct and Reflection.",
    "start": "1776080",
    "end": "1787390"
  },
  {
    "text": "And this is AutoGPT, which is\nlike a popular software repo. Basically, you can\nthink of it as combining",
    "start": "1787390",
    "end": "1793060"
  },
  {
    "text": "ReAct and a task\nplanner that decomposes an objective into subgoals.",
    "start": "1793060",
    "end": "1798130"
  },
  {
    "text": "And this is Voyager. We're able to obtain\nthree times more novel items than the prior methods\nand also unlock the entire tech",
    "start": "1798130",
    "end": "1806350"
  },
  {
    "text": "tree significantly faster. And if you take away\nthe scale library,",
    "start": "1806350",
    "end": "1811690"
  },
  {
    "text": "you see that Voyager\nreally suffers. The performance takes a\nhit because every time it needs to kind of\nrepeat and relearn",
    "start": "1811690",
    "end": "1818530"
  },
  {
    "text": "every skill from\nscratch, and it starts to make a lot more\nmistakes, and that really degrades the exploration.",
    "start": "1818530",
    "end": "1826510"
  },
  {
    "text": "Here, these two are the bird-eye\nviews of the Minecraft map. And these circles are\nwhat the prior methods",
    "start": "1826510",
    "end": "1834010"
  },
  {
    "text": "are able to explore given the\nsame prompting iteration budget. And we see that they tend\nto get stuck in local areas",
    "start": "1834010",
    "end": "1841990"
  },
  {
    "text": "and kind of fail\nto explore more. But the Voyager is\nable to navigate distances at least two times\nas much as the prior works.",
    "start": "1841990",
    "end": "1852420"
  },
  {
    "text": "So it's able to visit\na lot more places because to satisfy this\nhigh-level directive",
    "start": "1852420",
    "end": "1858210"
  },
  {
    "text": "of obtaining as many\nunique items as possible, you've got to travel, right? If you stay at one\nplace, you will quickly",
    "start": "1858210",
    "end": "1864030"
  },
  {
    "text": "exhaust the interesting\nthings to do. And Voyager travels\na lot, so that's how we came up with the name.",
    "start": "1864030",
    "end": "1871640"
  },
  {
    "text": "So finally, one limitation is\nthat Voyager does not currently support visual perception\nbecause the GPT-4 that we",
    "start": "1871640",
    "end": "1879020"
  },
  {
    "text": "used back then was text only. But there's nothing\nstopping Voyager from adopting like multimodal\nlanguage models in the future.",
    "start": "1879020",
    "end": "1887160"
  },
  {
    "text": "So here we have a little\nproof-of-concept demo where we ask a human to\nbasically function as the image",
    "start": "1887160",
    "end": "1892820"
  },
  {
    "text": "captioner, and the\nhuman will tell Voyager that as you're building\nthese houses, what are",
    "start": "1892820",
    "end": "1898503"
  },
  {
    "text": "the things that are missing? Like, you place a\ndoor incorrectly. Like, the roof is also\nnot done correctly.",
    "start": "1898503",
    "end": "1905010"
  },
  {
    "text": "So the human is acting as a\ncritic module of the Voyager stack. And we see that with\nsome of that help,",
    "start": "1905010",
    "end": "1912050"
  },
  {
    "text": "Voyager is able to build a\nfarm house and a nether portal, but it has a hard time\nunderstanding 3D spatial",
    "start": "1912050",
    "end": "1918770"
  },
  {
    "text": "coordinates just by itself\nin a textual domain. ",
    "start": "1918770",
    "end": "1924680"
  },
  {
    "text": "Now, after doing Voyager,\nwe're considering, like, where else can we\napply this idea of coding",
    "start": "1924680",
    "end": "1932450"
  },
  {
    "text": "in an embodied environment,\nobserve the feedback, and iteratively\nrefine the program?",
    "start": "1932450",
    "end": "1938539"
  },
  {
    "text": "So we came to realize that\nphysics simulations themselves are also just Python code.",
    "start": "1938540",
    "end": "1944450"
  },
  {
    "text": "So why not apply some of\nthe principles from Voyager and do something\nin another domain?",
    "start": "1944450",
    "end": "1951250"
  },
  {
    "text": "What if you apply Voyager in a\nspace of this physics simulator API? And this is Eureka, which\nmy team announced just",
    "start": "1951250",
    "end": "1958870"
  },
  {
    "text": "like three days ago. Fresh out of the oven. It is an open-ended\nagent that designs",
    "start": "1958870",
    "end": "1964899"
  },
  {
    "text": "reward functions for robot\ndexterity at superhuman level. And it turns out that GPT-4\nplus reinforcement learning",
    "start": "1964900",
    "end": "1972250"
  },
  {
    "text": "can spin a pen much\nbetter than I do. I gave up on this task a long\ntime ago, from childhood.",
    "start": "1972250",
    "end": "1979870"
  },
  {
    "text": "It's so hard for me. So Eureka's idea is very\nsimple and intuitive.",
    "start": "1979870",
    "end": "1987020"
  },
  {
    "text": "GPT-4 generates a bunch of\npossible reward function candidates\nimplemented in Python,",
    "start": "1987020",
    "end": "1992630"
  },
  {
    "text": "and then you just do a\nfull reinforcement learning training loop for each candidate\nin a GPU accelerator simulator.",
    "start": "1992630",
    "end": "2001390"
  },
  {
    "text": "And you get a\nperformance metric, and you take the best candidates\nand feedback to GPT-4,",
    "start": "2001390",
    "end": "2007000"
  },
  {
    "text": "and it samples the next\nproposals of the candidates and keeps improving the whole\npopulation of the reward",
    "start": "2007000",
    "end": "2013240"
  },
  {
    "text": "functions. That's the whole idea. It's kind of like an\nin-context evolutionary search.",
    "start": "2013240",
    "end": "2020130"
  },
  {
    "text": "So here's the initial\nreward generation, where Eureka takes as context\nthe environment code of NVIDIA's",
    "start": "2020130",
    "end": "2027000"
  },
  {
    "text": "Isaac Sim, and a\ntask description, and samples the initial reward\nfunction implementation.",
    "start": "2027000",
    "end": "2034220"
  },
  {
    "text": "So we found that the simulator\ncalled itself is actually a very good reference manual\nbecause it tells Eureka what",
    "start": "2034220",
    "end": "2040100"
  },
  {
    "text": "are the variables you can use. Like, you know,\nthe hand positions. Like, here, the fingertip\nposition, the fingertip save,",
    "start": "2040100",
    "end": "2046519"
  },
  {
    "text": "the rotation angular\nvelocity, et cetera. So, you know all\nof these variables",
    "start": "2046520",
    "end": "2051800"
  },
  {
    "text": "from the simulator\ncode, and you know how they interact with each other. So that serves as a very\ngood in-context instruction.",
    "start": "2051800",
    "end": "2061250"
  },
  {
    "text": "So Eureka doesn't\nneed to reference any human-written\nreward functions.",
    "start": "2061250",
    "end": "2066408"
  },
  {
    "text": "And then, once you have\nthe generated reward, you plug it into any\nreinforcement learning algorithm",
    "start": "2066409",
    "end": "2071540"
  },
  {
    "text": "and just train it to completion. So this step is typically\nvery costly and very slow",
    "start": "2071540",
    "end": "2077840"
  },
  {
    "text": "because reinforcement\nlearning itself is slow. And we were only able to scale\nup Eureka because of [INAUDIBLE]",
    "start": "2077840",
    "end": "2084529"
  },
  {
    "text": "which runs 1,000 simulated\nenvironment copies on a single GPU.",
    "start": "2084530",
    "end": "2089969"
  },
  {
    "text": "So basically, you can think\nof it as speeding up reality by 1,000x.",
    "start": "2089969",
    "end": "2096565"
  },
  {
    "text": "And then, after training, you\nwill get the performance metrics back on each reward component.",
    "start": "2096565",
    "end": "2102180"
  },
  {
    "text": "And as we saw from\nVoyager, GPT-4 is very good at self-reflection. So we leverage that capability.",
    "start": "2102180",
    "end": "2109500"
  },
  {
    "text": "And there's a software\ntrial reminding",
    "start": "2109500",
    "end": "2115640"
  },
  {
    "text": "you to activate a license. Yeah. So Voyager reflects on it\nand then proposes mutations",
    "start": "2115640",
    "end": "2124200"
  },
  {
    "text": "on the code. So here, the mutations we\nfound can be very diverse,",
    "start": "2124200",
    "end": "2129990"
  },
  {
    "text": "ranging from something as\nsimple as just changing a hyperparameter in the reward\nfunction waiting all the way",
    "start": "2129990",
    "end": "2136200"
  },
  {
    "text": "to adding completely novel\ncomponents to the reward function. And in our experiments,\nEureka turns out",
    "start": "2136200",
    "end": "2144280"
  },
  {
    "text": "to be a superhuman reward\nengineer, actually outperforming some of the\nfunctions implemented",
    "start": "2144280",
    "end": "2150430"
  },
  {
    "text": "by the expert human engineers\non NVIDIA's Isaac Sim team.",
    "start": "2150430",
    "end": "2156750"
  },
  {
    "text": "So here are some\nmore demos of how Eureka is able to write\nvery complex rewards that",
    "start": "2156750",
    "end": "2162360"
  },
  {
    "text": "lead to these extremely\ndexterous behaviors. And we can actually train the\nrobot hand to rotate pens.",
    "start": "2162360",
    "end": "2169380"
  },
  {
    "text": "Not just, you know,\nin one direction, but in different directions\nalong different pseudo-axis.",
    "start": "2169380",
    "end": "2175380"
  },
  {
    "text": "I think one major\ncontribution of Eureka, different from\nVoyager, is to bridge the gap between high-level\nreasoning and low-level motor",
    "start": "2175380",
    "end": "2183720"
  },
  {
    "text": "controls. So Eureka introduces\na new paradigm that I'm calling hybrid\ngradient architecture.",
    "start": "2183720",
    "end": "2190290"
  },
  {
    "text": "So recall, Voyager is a\nno-gradient architecture. We don't touch anything,\nand we don't train anything.",
    "start": "2190290",
    "end": "2195670"
  },
  {
    "text": "But Eureka is a hybrid gradient\nwhere a black box inference-only language model instructs a white\nbox learnable neural network.",
    "start": "2195670",
    "end": "2204900"
  },
  {
    "text": "So you can think\nof it as two loops. Right? The outer loop is\ngreater than 3, and it's driven by GPT-4 kind of\nselecting the reward functions.",
    "start": "2204900",
    "end": "2214200"
  },
  {
    "text": "And the inner loop\nis gradient-based. You train it like a full\nreinforcement learning episode from it to achieve\nextreme dexterity",
    "start": "2214200",
    "end": "2221970"
  },
  {
    "text": "using a specialized like-- by training a special\nneural network controller.",
    "start": "2221970",
    "end": "2227160"
  },
  {
    "text": "And you must have both\nloops to succeed to deliver this kind of dexterity. And I think it will be a very\nuseful paradigm for training",
    "start": "2227160",
    "end": "2235510"
  },
  {
    "text": "robot agents in the future. So, you know, these days,\nwhen I go on Twitter, or X,",
    "start": "2235510",
    "end": "2243530"
  },
  {
    "text": "I see AI conquering\nnew lands every week-- you know, chat, image\ngeneration, and music.",
    "start": "2243530",
    "end": "2250220"
  },
  {
    "text": "They're all very\nwell within reach. But MineDojo,\nVoyager, and Eureka,",
    "start": "2250220",
    "end": "2255410"
  },
  {
    "text": "these are just scratching the\nsurface of open-ended generalist agents.",
    "start": "2255410",
    "end": "2260599"
  },
  {
    "text": "And looking forward, I want\nto share two key research directions that I personally\nfind extremely promising,",
    "start": "2260600",
    "end": "2267530"
  },
  {
    "text": "and I'm also working\non it myself. The first is a\ncontinuation of MineCLIP, basically, how to develop\nmethods that learn",
    "start": "2267530",
    "end": "2275480"
  },
  {
    "text": "from internet-scale videos. And the second is multimodal\nfoundation models now",
    "start": "2275480",
    "end": "2280760"
  },
  {
    "text": "that GPT-4V is coming, but it\nis just the beginning of an era. And I think it's important\nto have all the modalities",
    "start": "2280760",
    "end": "2289070"
  },
  {
    "text": "in a single foundation model. So first, about videos.",
    "start": "2289070",
    "end": "2294819"
  },
  {
    "text": "We all know that videos\nare abundant, right? Like, so many data on\nYouTube, way too many",
    "start": "2294820",
    "end": "2301450"
  },
  {
    "text": "for our limited GPUs to process. They're extremely\nuseful to train",
    "start": "2301450",
    "end": "2306579"
  },
  {
    "text": "models that not only have\ndynamic perception and intuitive physics but also capture the\ncomplexity of human creativity",
    "start": "2306580",
    "end": "2314500"
  },
  {
    "text": "and human behaviors. It's all good, except that\nwhen you are using video",
    "start": "2314500",
    "end": "2320860"
  },
  {
    "text": "to pre-train embodied\nagents, there is huge distribution shift. You also don't get\nthe action labels,",
    "start": "2320860",
    "end": "2326285"
  },
  {
    "text": "and you don't get\nany of the groundings because you're a\npassive observer. So I think here\nis a demonstration",
    "start": "2326285",
    "end": "2332350"
  },
  {
    "text": "of why learning from\nvideo is hard, even for natural intelligence. So little cat is seeing\nboxers shaking their head",
    "start": "2332350",
    "end": "2341000"
  },
  {
    "text": "and it thinks maybe shaking head\nis the best way to do fighting. [LAUGHING]",
    "start": "2341000",
    "end": "2347440"
  },
  {
    "text": "Right? This is why learning\nfrom video is hard. [LAUGHING]",
    "start": "2347440",
    "end": "2354020"
  },
  {
    "text": "You have no idea, like, why-- [LAUGHS] This is too good. Let's play this again.",
    "start": "2354020",
    "end": "2360029"
  },
  {
    "text": "You have no idea why Tyson\nis doing this, right? Like the cat has no idea. And then it associates this with\njust the wrong kind of policy.",
    "start": "2360030",
    "end": "2368244"
  },
  {
    "text": "[LAUGHING] But for sure, you know, it\ndoesn't help the fighting,",
    "start": "2368245",
    "end": "2373460"
  },
  {
    "text": "but it definitely boosts\nthe cat's confidence. [LAUGHING]",
    "start": "2373460",
    "end": "2378950"
  },
  {
    "text": "That's why learning\nfrom video is hard. Now, I want to point out\na few of latest research",
    "start": "2378950",
    "end": "2385080"
  },
  {
    "text": "in how to leverage so much\nvideo for generalist agents. There are a couple\nof approaches.",
    "start": "2385080",
    "end": "2391210"
  },
  {
    "text": "The first is the simplest. Just learn kind of\na visual feature extractor from the videos.",
    "start": "2391210",
    "end": "2396740"
  },
  {
    "text": "So this is R3M from\nChelsea's group at Stanford. And this model is still an\nimage-level representation,",
    "start": "2396740",
    "end": "2403500"
  },
  {
    "text": "just that it uses\na video-level loss function to train\nmore specifically time-contrastive learning.",
    "start": "2403500",
    "end": "2409830"
  },
  {
    "text": "And after that, you can use\nthis as an image backbone for any agent,\nbut you still need",
    "start": "2409830",
    "end": "2415590"
  },
  {
    "text": "to fine-tune using\ndomain-specific data for the agent.",
    "start": "2415590",
    "end": "2420849"
  },
  {
    "text": "The second path is to learn\nreward functions from video, and MineCLIP is one model\nunder this category.",
    "start": "2420850",
    "end": "2429310"
  },
  {
    "text": "It uses a contrastive objective\nbetween the transcript and video. And here, this work,\nVIP, is another way",
    "start": "2429310",
    "end": "2436270"
  },
  {
    "text": "to learn a\nsimilarity-based reward for goal-conditioned\ntasks in the image space.",
    "start": "2436270",
    "end": "2441520"
  },
  {
    "text": "So this work, VIP, is led\nby [AUDIO OUT],, who was also the first author of Eureka, and\nEureka is his internship project",
    "start": "2441520",
    "end": "2448089"
  },
  {
    "text": "with me. And the third idea\nis very interesting. Can we directly do imitation\nlearning from video,",
    "start": "2448090",
    "end": "2456330"
  },
  {
    "text": "but better than the\ncat that we just saw? So we just said,\nyou know, the videos",
    "start": "2456330",
    "end": "2461910"
  },
  {
    "text": "don't have the actions, right? We need to find some ways\nto pseudo-label the actions.",
    "start": "2461910",
    "end": "2467430"
  },
  {
    "text": "And this is video pre-training\nof GPT from OpenAI last year to solve long-range\ntasks in Minecraft.",
    "start": "2467430",
    "end": "2474480"
  },
  {
    "text": "And here, the pipeline\nworks like this. Basically, you use a keyboard\nand a mouse, action space.",
    "start": "2474480",
    "end": "2481869"
  },
  {
    "text": "So you can align this action\nspace with the human actions. And OpenAI hires a bunch\nof Minecraft players",
    "start": "2481870",
    "end": "2489660"
  },
  {
    "text": "and actually collect\ndata in-house. So they record the episodes\ndone by those gamers.",
    "start": "2489660",
    "end": "2494910"
  },
  {
    "text": "And now you have a data set of\nvideo and action pairs, right? And you train something called\nan inverse dynamics model, which",
    "start": "2494910",
    "end": "2502980"
  },
  {
    "text": "is to take the observation\nand then predict the actions that caused\nthe observation to change.",
    "start": "2502980",
    "end": "2509140"
  },
  {
    "text": "So that's the inverse\ndynamics model, and that becomes\na labeler that you",
    "start": "2509140",
    "end": "2514510"
  },
  {
    "text": "can apply to in-the-wild\nYouTube videos that don't have the actions. So you apply the IDM to 70K\nhours of in-the-wild YouTube",
    "start": "2514510",
    "end": "2523660"
  },
  {
    "text": "videos, and you will get these\npseudo-actions that are not always correct but also\nway better than random.",
    "start": "2523660",
    "end": "2530049"
  },
  {
    "text": "And then you train\nimitation learning on top of this augmented data set. And in this way, OpenAI\nis able to greatly expand",
    "start": "2530050",
    "end": "2538270"
  },
  {
    "text": "the data because the original\ndata collected from the humans are high quality, but\nthey're extremely expensive.",
    "start": "2538270",
    "end": "2545320"
  },
  {
    "text": "While in-the-wild YouTube\nvideos are very cheap, but you don't have the\nactions, so they kind of solved and got the\nbest of both worlds.",
    "start": "2545320",
    "end": "2552670"
  },
  {
    "text": "But still, you know, it's really\nexpensive to hire these humans. Now, what's beyond\nthe videos, right?",
    "start": "2552670",
    "end": "2560440"
  },
  {
    "text": "I'm a firm believer that\nmultimodal models will be the future, and I see text as a\nvery lossy kind of 1D projection",
    "start": "2560440",
    "end": "2567520"
  },
  {
    "text": "of our physical world. So it's essential to include\nthe other sensory modalities",
    "start": "2567520",
    "end": "2572530"
  },
  {
    "text": "to provide a full,\nembodied experience. And in the context\nof embodied agents, I think the input will be a\nmixture of text, images, videos,",
    "start": "2572530",
    "end": "2581500"
  },
  {
    "text": "and even audio in the future,\nand the output will be actions. So here's a very early example\nof a multimodal language",
    "start": "2581500",
    "end": "2590799"
  },
  {
    "text": "model for robot learning. So let's imagine\na household robot. We can ask the robot to bring us\na cup of tea from the kitchen.",
    "start": "2590800",
    "end": "2598960"
  },
  {
    "text": "But if we want to\nbe more specific, I want this particular cup. That is my favorite cup. So show me this image.",
    "start": "2598960",
    "end": "2606210"
  },
  {
    "text": "And we also provide a video demo\nof how we want to mop the floor",
    "start": "2606210",
    "end": "2611490"
  },
  {
    "text": "and ask the robot to imitate\nthe similar motion in context. And when the robot sees\nan unfamiliar object",
    "start": "2611490",
    "end": "2618049"
  },
  {
    "text": "like a sweeper, we can explain\nit by providing an image and showing, this is a sweeper. Now, go ahead and do\nsomething with the tool.",
    "start": "2618050",
    "end": "2625440"
  },
  {
    "text": "And finally, to\nensure safety, we can say, take a\npicture of that room, and just do not enter that room.",
    "start": "2625440",
    "end": "2631470"
  },
  {
    "text": "To achieve this,\nback last year, we proposed a model called VIMA,\nwhich stands for visual motor",
    "start": "2631470",
    "end": "2638610"
  },
  {
    "text": "attention. And in this work, we introduced\na concept called multimodal prompting, where the prompt can\nbe a mixture of text, image,",
    "start": "2638610",
    "end": "2646800"
  },
  {
    "text": "and videos. And this provides a very\nexpressive API that just unifies",
    "start": "2646800",
    "end": "2651960"
  },
  {
    "text": "a bunch of different robot tasks\nthat otherwise would require a very different pipeline\nor specialized models",
    "start": "2651960",
    "end": "2658320"
  },
  {
    "text": "to solve in prior literature. And VIMA simply\ntokenizes everything,",
    "start": "2658320",
    "end": "2665040"
  },
  {
    "text": "converting image and text\ninto sequences of tokens and training a\ntransformer on top to output the robot arm\nactions autoregressively",
    "start": "2665040",
    "end": "2673770"
  },
  {
    "text": "one step at a time\nduring inference time. So just to look at some\nof the examples here.",
    "start": "2673770",
    "end": "2680210"
  },
  {
    "text": "Like, this prompt rearrange\nobjects to match the scene. It's a classical task\ncalled visual goal",
    "start": "2680210",
    "end": "2685309"
  },
  {
    "text": "reaching that has a big\nbody of prior works on it. And that's how our robot\ndoes it, given this prompt.",
    "start": "2685310",
    "end": "2693920"
  },
  {
    "text": "And we can also give it\nnovel concepts in context. Like, this is a blicket. This is a wug.",
    "start": "2693920",
    "end": "2699619"
  },
  {
    "text": "Now, put the wug into a blicket,\nand both words are nonsensical. So it's not in\nthe training data,",
    "start": "2699620",
    "end": "2705109"
  },
  {
    "text": "but VIMA is able to generalize\nzero-shot and follow the motion to manipulate this object.",
    "start": "2705110",
    "end": "2711140"
  },
  {
    "text": "So the bot understands what\nwe want and then follow this trajectory. And finally, we can give\nit a more complex prompt.",
    "start": "2711140",
    "end": "2718080"
  },
  {
    "text": "Like, these are the\nsafety constraints. Sweep the box into this, but\nwithout exceeding that line.",
    "start": "2718080",
    "end": "2723560"
  },
  {
    "text": "And we do this using the\ninterleaving image and text tokens.",
    "start": "2723560",
    "end": "2730480"
  },
  {
    "text": "And recently, Google Brain\nRobotics followed up after VIMA with RT-1 and RT-2, robot\ntransformer 1 and 2.",
    "start": "2730480",
    "end": "2738910"
  },
  {
    "text": "And RT-2 is using\na similar recipe as I described,\nwhere they first kind of pre-train on\ninternet-scale data",
    "start": "2738910",
    "end": "2746410"
  },
  {
    "text": "and then fine-tune with some\nhuman-collected demonstrations on the Google robots. And RoboCat from DeepMind\nis another interesting work.",
    "start": "2746410",
    "end": "2754780"
  },
  {
    "text": "They train a single,\nunified policy that works not just\non a single robot",
    "start": "2754780",
    "end": "2760540"
  },
  {
    "text": "but actually across different\nembodiments, different robot forms, and even generalize\nto a new hardware.",
    "start": "2760540",
    "end": "2767190"
  },
  {
    "text": "So I think this is like a\nhigher form of multimodal agent where the physical form factor,\nthe morphology of the agent",
    "start": "2767190",
    "end": "2773670"
  },
  {
    "text": "itself, is another modality. So that concludes our\nLooking Forward section.",
    "start": "2773670",
    "end": "2781640"
  },
  {
    "text": "And lastly, I want to put\nall the links together of the works I described.",
    "start": "2781640",
    "end": "2787170"
  },
  {
    "text": "So this is minedojo.org. We have open-source everything. Well, for all the projects, we\nare big fans of open source.",
    "start": "2787170",
    "end": "2794700"
  },
  {
    "text": "We open source as\nmuch as we can, including like the model code,\ncheckpoints, simulator code,",
    "start": "2794700",
    "end": "2801920"
  },
  {
    "text": "and training data. And this is\nvoyager.minedojo.org.",
    "start": "2801920",
    "end": "2807490"
  },
  {
    "text": "This is Eureka. And this is VIMA.",
    "start": "2807490",
    "end": "2813250"
  },
  {
    "text": "And one more thing, right? If you just want an excuse\nto play Minecraft at work,",
    "start": "2813250",
    "end": "2818590"
  },
  {
    "text": "then MineDojo is perfect\nfor you because you are collecting\nhuman demonstration to train generalist agent.",
    "start": "2818590",
    "end": "2824020"
  },
  {
    "text": "And if there's one thing that\nyou take away from this talk, it should be this slide.",
    "start": "2824020",
    "end": "2829880"
  },
  {
    "text": "And lastly, I just want\nto remind all of us. You know, despite all\nthe progress I've shown, what we can do is still very\nfar from human ingenuity",
    "start": "2829880",
    "end": "2838940"
  },
  {
    "text": "as embodied agents. You know, these are the\nvideos from our data set of people doing like\ndecorating a winter wonderland",
    "start": "2838940",
    "end": "2846950"
  },
  {
    "text": "or building the functioning\nCPU circuit within Minecraft, and we are very far from\nthat as AI research.",
    "start": "2846950",
    "end": "2853630"
  },
  {
    "text": "So here's a call\nto the community. If human can do these\nmind-blowing tasks, then why not our AI, right?",
    "start": "2853630",
    "end": "2860460"
  },
  {
    "text": "Let's find out together. ",
    "start": "2860460",
    "end": "2867000"
  }
]
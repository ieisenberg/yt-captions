[
  {
    "start": "0",
    "end": "158"
  },
  {
    "text": "We're now going to\nstart a discussion",
    "start": "158",
    "end": "1700"
  },
  {
    "text": "of multiple linear regression,\nwhich is regression",
    "start": "1700",
    "end": "3783"
  },
  {
    "text": "with more than one predictor.",
    "start": "3783",
    "end": "6029"
  },
  {
    "text": "I should say the term\nregression is unusual.",
    "start": "6030",
    "end": "10690"
  },
  {
    "text": "You might be wondering\nwhy linear regression is",
    "start": "10690",
    "end": "12809"
  },
  {
    "text": "a linear model.",
    "start": "12810",
    "end": "14160"
  },
  {
    "text": "And this actually\nis an unusual term.",
    "start": "14160",
    "end": "16030"
  },
  {
    "text": "It's actually historical,\nit comes from the idea",
    "start": "16030",
    "end": "18180"
  },
  {
    "text": "of regression toward the mean,\nwhich is a concept which was",
    "start": "18180",
    "end": "22470"
  },
  {
    "text": "discussed in the early 1900s.",
    "start": "22470",
    "end": "24740"
  },
  {
    "text": "Now, you might want to\nlook that up yourself.",
    "start": "24740",
    "end": "26830"
  },
  {
    "text": "And later on in\nthe course, we'll",
    "start": "26830",
    "end": "28680"
  },
  {
    "text": "describe what regression\ntowards the mean is.",
    "start": "28680",
    "end": "31480"
  },
  {
    "text": "But it's resulted in this\nunusual name for a linear model",
    "start": "31480",
    "end": "35309"
  },
  {
    "text": "called linear regression.",
    "start": "35310",
    "end": "38680"
  },
  {
    "text": "But we have to live\nwith this term,",
    "start": "38680",
    "end": "40620"
  },
  {
    "text": "because it's become\ntime-honored.",
    "start": "40620",
    "end": "43110"
  },
  {
    "text": "So multiple linear\nregression now",
    "start": "43110",
    "end": "45360"
  },
  {
    "text": "extends the simple model to we\nhave more than one predictor.",
    "start": "45360",
    "end": "48990"
  },
  {
    "text": "In this our example, we\nhave three predictors,",
    "start": "48990",
    "end": "51390"
  },
  {
    "text": "so we want to fit\nthem all together,",
    "start": "51390",
    "end": "52890"
  },
  {
    "text": "and use them all together\nto predict the outcome.",
    "start": "52890",
    "end": "55710"
  },
  {
    "text": "So here's the model.",
    "start": "55710",
    "end": "58200"
  },
  {
    "text": "We have an overall\nintercept term,",
    "start": "58200",
    "end": "61195"
  },
  {
    "text": "and then we have\na slope for each",
    "start": "61195",
    "end": "62570"
  },
  {
    "text": "of the predictors\nin the model, which",
    "start": "62570",
    "end": "64250"
  },
  {
    "text": "again, the betas or the\nparameters, they're unknown,",
    "start": "64250",
    "end": "67670"
  },
  {
    "text": "and the X's are observed and\nwe're trying to use the X's",
    "start": "67670",
    "end": "70159"
  },
  {
    "text": "to predict Y. So\nin the advertising",
    "start": "70160",
    "end": "73340"
  },
  {
    "text": "example, to be particular,\nwe'll have the three predictors",
    "start": "73340",
    "end": "76549"
  },
  {
    "text": "TV, radio, and\nnewspaper advertising,",
    "start": "76550",
    "end": "79310"
  },
  {
    "text": "and we're going to\ntry to predict sales.",
    "start": "79310",
    "end": "81079"
  },
  {
    "text": "And we have the error\nterm for allowing points",
    "start": "81080",
    "end": "83720"
  },
  {
    "text": "to deviate around the function.",
    "start": "83720",
    "end": "86070"
  },
  {
    "text": "And now the function actually\nis called a hyperplane.",
    "start": "86070",
    "end": "89280"
  },
  {
    "text": "Let's actually flip ahead\nto slide 19 for a moment,",
    "start": "89280",
    "end": "92850"
  },
  {
    "text": "I have a picture of this.",
    "start": "92850",
    "end": "94159"
  },
  {
    "text": "So whereas before we had a\nline, now it's a hyperplane.",
    "start": "94160",
    "end": "99290"
  },
  {
    "text": "So I've been able to draw it\nhere just for two predictors,",
    "start": "99290",
    "end": "103840"
  },
  {
    "text": "it's hard to draw for three.",
    "start": "103840",
    "end": "105070"
  },
  {
    "text": "But now the lines is now\nreplaced by this flat surface",
    "start": "105070",
    "end": "108850"
  },
  {
    "text": "called a plane, or hyperplane.",
    "start": "108850",
    "end": "111220"
  },
  {
    "text": "So here's our data points.",
    "start": "111220",
    "end": "113510"
  },
  {
    "text": "For each point we have its two\npredictor values, let's say, TV",
    "start": "113510",
    "end": "117310"
  },
  {
    "text": "and newspaper.",
    "start": "117310",
    "end": "118270"
  },
  {
    "text": "And we have its sales\non the vertical axis.",
    "start": "118270",
    "end": "121100"
  },
  {
    "text": "And here each data\npoint is a red point.",
    "start": "121100",
    "end": "125619"
  },
  {
    "text": "What multiple\nregression does, it",
    "start": "125620",
    "end": "127390"
  },
  {
    "text": "fits a hyperplane, a\nplane to these points",
    "start": "127390",
    "end": "130388"
  },
  {
    "text": "to minimize the squared\ndistance between each point",
    "start": "130389",
    "end": "133600"
  },
  {
    "text": "and the closest\npoint on the plane.",
    "start": "133600",
    "end": "135580"
  },
  {
    "text": "Very intuitive in the same\nway we did it with for a line,",
    "start": "135580",
    "end": "139940"
  },
  {
    "text": "now the line becomes a plane.",
    "start": "139940",
    "end": "142580"
  },
  {
    "text": "So let's now go back\nto the model again.",
    "start": "142580",
    "end": "150110"
  },
  {
    "text": "So this is the\nequation of hyperplane",
    "start": "150110",
    "end": "152650"
  },
  {
    "text": "with its coefficients.",
    "start": "152650",
    "end": "154239"
  },
  {
    "start": "154240",
    "end": "157180"
  },
  {
    "text": "Well, before we talk about the\nleast squares estimates and some",
    "start": "157180",
    "end": "161890"
  },
  {
    "text": "of the details, let's\nstep back for a moment,",
    "start": "161890",
    "end": "165050"
  },
  {
    "text": "think about how we might\ninterpret the regression",
    "start": "165050",
    "end": "167092"
  },
  {
    "text": "coefficients, because now\nthere's more than one of them.",
    "start": "167092",
    "end": "169424"
  },
  {
    "text": "In the simple model,\nwe have only one",
    "start": "169425",
    "end": "170980"
  },
  {
    "text": "to deal with, now we\nhave a multiple say,",
    "start": "170980",
    "end": "173200"
  },
  {
    "text": "three coefficients.",
    "start": "173200",
    "end": "174879"
  },
  {
    "text": "How do we interpret\nthem together?",
    "start": "174880",
    "end": "177820"
  },
  {
    "text": "Well, if the predictors\nhad no correlation,",
    "start": "177820",
    "end": "182660"
  },
  {
    "text": "now it's in the data, then we\ncan talk about each coefficient",
    "start": "182660",
    "end": "186970"
  },
  {
    "text": "separately.",
    "start": "186970",
    "end": "188260"
  },
  {
    "text": "We can make statements\nlike a unit change in Xj",
    "start": "188260",
    "end": "191049"
  },
  {
    "text": "for example, which is associated\nwith a beta j change, that's",
    "start": "191050",
    "end": "194080"
  },
  {
    "text": "its coefficient in\nthe outcome with all",
    "start": "194080",
    "end": "196570"
  },
  {
    "text": "the other variables fixed.",
    "start": "196570",
    "end": "200000"
  },
  {
    "text": "But predictors are not usually\nuncorrelated in the data.",
    "start": "200000",
    "end": "204850"
  },
  {
    "text": "For example, here we\ncan expect, and we'll",
    "start": "204850",
    "end": "207710"
  },
  {
    "text": "see that actually the various\namounts spent on the three",
    "start": "207710",
    "end": "211280"
  },
  {
    "text": "advertising are\nquite are correlated.",
    "start": "211280",
    "end": "213640"
  },
  {
    "text": "So these interpretations are\ndifficult in observational data",
    "start": "213640",
    "end": "220330"
  },
  {
    "text": "that are correlated.",
    "start": "220330",
    "end": "221620"
  },
  {
    "text": "What problem does the\ncorrelation cause?",
    "start": "221620",
    "end": "225319"
  },
  {
    "text": "Well, the variance\nof all coefficients",
    "start": "225320",
    "end": "227470"
  },
  {
    "text": "tend to increase\nsometimes dramatically.",
    "start": "227470",
    "end": "230230"
  },
  {
    "text": "In particular, imagine we\nhave two predictors, which",
    "start": "230230",
    "end": "232989"
  },
  {
    "text": "are almost identical.",
    "start": "232990",
    "end": "234910"
  },
  {
    "text": "Then we can't really\nseparate their coefficients.",
    "start": "234910",
    "end": "239040"
  },
  {
    "text": "If I have a coefficient\non one variable,",
    "start": "239040",
    "end": "241269"
  },
  {
    "text": "I could just as soon\nmove that coefficient",
    "start": "241270",
    "end": "243110"
  },
  {
    "text": "to the other variable,\nand the fit of the model",
    "start": "243110",
    "end": "245320"
  },
  {
    "text": "is going to be\npretty much the same.",
    "start": "245320",
    "end": "247160"
  },
  {
    "text": "So the variance of\nthe coefficients",
    "start": "247160",
    "end": "248630"
  },
  {
    "text": "of those two predictors\nare going to be very large.",
    "start": "248630",
    "end": "252360"
  },
  {
    "text": "And then interpretation\nbecomes difficult",
    "start": "252360",
    "end": "255800"
  },
  {
    "text": "when there's correlation,\nbecause one can't really say,",
    "start": "255800",
    "end": "259250"
  },
  {
    "text": "suppose I were to change Xj.",
    "start": "259250",
    "end": "261269"
  },
  {
    "text": "In other words, we\ncan think about,",
    "start": "261269",
    "end": "262790"
  },
  {
    "text": "suppose I was to increase\nthe TV advertising",
    "start": "262790",
    "end": "265850"
  },
  {
    "text": "by a certain amount, what\nwould be the effect on sales?",
    "start": "265850",
    "end": "268960"
  },
  {
    "text": "Well, if that happened,\nprobably wouldn't",
    "start": "268960",
    "end": "272660"
  },
  {
    "text": "be reasonable to assume\nthat the other advertising",
    "start": "272660",
    "end": "274820"
  },
  {
    "text": "budgets stay the same.",
    "start": "274820",
    "end": "276340"
  },
  {
    "text": "For example, maybe the company\nhas a fixed budget overall,",
    "start": "276340",
    "end": "279818"
  },
  {
    "text": "so that if I increase\nTV advertising,",
    "start": "279818",
    "end": "281360"
  },
  {
    "text": "I would have to decrease\nthe other advertising.",
    "start": "281360",
    "end": "284139"
  },
  {
    "text": "Or maybe TV advertising\nis increasing",
    "start": "284140",
    "end": "286090"
  },
  {
    "text": "just because the company\nhas more money in general,",
    "start": "286090",
    "end": "288340"
  },
  {
    "text": "and decides it\nwants to spend more",
    "start": "288340",
    "end": "291580"
  },
  {
    "text": "on advertising of all kinds.",
    "start": "291580",
    "end": "293349"
  },
  {
    "text": "So this is in both those\ncases, we can't really",
    "start": "293350",
    "end": "297910"
  },
  {
    "text": "talk about the change\nof one predictor",
    "start": "297910",
    "end": "300130"
  },
  {
    "text": "with the other one's fixed,\nbecause the predictors will tend",
    "start": "300130",
    "end": "303490"
  },
  {
    "text": "to move together in real data.",
    "start": "303490",
    "end": "306160"
  },
  {
    "text": "And what this means is claims\nof causality should be avoided.",
    "start": "306160",
    "end": "309560"
  },
  {
    "text": "We can't really say that\none predictor causes",
    "start": "309560",
    "end": "313540"
  },
  {
    "text": "the outcome when\nthere's predictors",
    "start": "313540",
    "end": "317400"
  },
  {
    "text": "in the system that are\ncorrelated with that given",
    "start": "317400",
    "end": "319830"
  },
  {
    "text": "predictor.",
    "start": "319830",
    "end": "320819"
  },
  {
    "text": "So this becomes a\ncomplicated challenge",
    "start": "320820",
    "end": "326310"
  },
  {
    "text": "to try to discuss causality,\nand we're going to avoid that.",
    "start": "326310",
    "end": "330139"
  },
  {
    "text": "And there's a nice\nbook, which actually,",
    "start": "330140",
    "end": "333020"
  },
  {
    "text": "when I was a\ngraduate student, it",
    "start": "333020",
    "end": "334626"
  },
  {
    "text": "was one of the books I\nlearned from, Data Analysis",
    "start": "334627",
    "end": "336710"
  },
  {
    "text": "and Regression by\nMosteller and Tukey, two",
    "start": "336710",
    "end": "338600"
  },
  {
    "text": "very famous statisticians.",
    "start": "338600",
    "end": "341360"
  },
  {
    "text": "And I look at the book now,\nand I don't like the book",
    "start": "341360",
    "end": "346310"
  },
  {
    "text": "that much overall, but\nthere's one wonderful chapter",
    "start": "346310",
    "end": "349250"
  },
  {
    "text": "called The Woes of\nRegression Coefficients",
    "start": "349250",
    "end": "351530"
  },
  {
    "text": "that talks about the problems\nof interpreting regression",
    "start": "351530",
    "end": "355310"
  },
  {
    "text": "coefficients when there's a\nmultiple regression model.",
    "start": "355310",
    "end": "357650"
  },
  {
    "text": "That's a very useful\nchapter to read.",
    "start": "357650",
    "end": "361570"
  },
  {
    "text": "And I've made this point.",
    "start": "361570",
    "end": "362660"
  },
  {
    "text": "So the first point\nhere, I've just",
    "start": "362660",
    "end": "364077"
  },
  {
    "text": "made that the regression\ncoefficient, what it measures",
    "start": "364077",
    "end": "368199"
  },
  {
    "text": "is the change in Y\nper unit change in Xj",
    "start": "368200",
    "end": "370810"
  },
  {
    "text": "with all other\npredictors held fixed.",
    "start": "370810",
    "end": "373880"
  },
  {
    "text": "But this is not usually\na reflection of reality,",
    "start": "373880",
    "end": "376460"
  },
  {
    "text": "because usually when you\nchange one predictor,",
    "start": "376460",
    "end": "378410"
  },
  {
    "text": "the others change\nas well, I mentioned",
    "start": "378410",
    "end": "380690"
  },
  {
    "text": "the example with advertising.",
    "start": "380690",
    "end": "382640"
  },
  {
    "text": "So here's a couple\nof examples which",
    "start": "382640",
    "end": "386390"
  },
  {
    "text": "I'll just have you think about.",
    "start": "386390",
    "end": "388760"
  },
  {
    "text": "And maybe we'll\nput it on a quiz,",
    "start": "388760",
    "end": "390210"
  },
  {
    "text": "but here's the first example to\nhave you think about this point.",
    "start": "390210",
    "end": "394380"
  },
  {
    "text": "Suppose I measure the total\namount of change in your pocket,",
    "start": "394380",
    "end": "398910"
  },
  {
    "text": "and that's why they also measure\ntwo predictors, the number",
    "start": "398910",
    "end": "402090"
  },
  {
    "text": "of coins, and the number of\npennies, nickels, and dimes,",
    "start": "402090",
    "end": "405650"
  },
  {
    "text": "that's X2.",
    "start": "405650",
    "end": "407729"
  },
  {
    "text": "Now by itself the\nregression coefficient",
    "start": "407730",
    "end": "409410"
  },
  {
    "text": "of Y on the total number of\npennies, nickels, and dimes",
    "start": "409410",
    "end": "411640"
  },
  {
    "text": "will probably be\npositive, the more",
    "start": "411640",
    "end": "413130"
  },
  {
    "text": "you have of these,\nthe more likely",
    "start": "413130",
    "end": "414547"
  },
  {
    "text": "that your have more change.",
    "start": "414547",
    "end": "417030"
  },
  {
    "text": "But what about if I\nhave X1 in the model?",
    "start": "417030",
    "end": "421000"
  },
  {
    "text": "And so for a given\nlevel of X1, think about",
    "start": "421000",
    "end": "426680"
  },
  {
    "text": "whether the coefficient of X2\nwill be positive or negative?",
    "start": "426680",
    "end": "430820"
  },
  {
    "text": "And we'll talk about the\nanswer to this later on.",
    "start": "430820",
    "end": "435120"
  },
  {
    "text": "But it's a simple example\nwhere you can see now",
    "start": "435120",
    "end": "438680"
  },
  {
    "text": "how the presence\nof one predictor",
    "start": "438680",
    "end": "440509"
  },
  {
    "text": "affects the way that we think\ninterpret the coefficient",
    "start": "440510",
    "end": "443300"
  },
  {
    "text": "of another predictor.",
    "start": "443300",
    "end": "444539"
  },
  {
    "text": "And of course,\nthese two predictors",
    "start": "444540",
    "end": "445998"
  },
  {
    "text": "are highly correlated\nby construction.",
    "start": "445998",
    "end": "448783"
  },
  {
    "text": "Another example,\nwhich is actually",
    "start": "448783",
    "end": "450199"
  },
  {
    "text": "from this chapter in this\nbook from American Football,",
    "start": "450200",
    "end": "455630"
  },
  {
    "text": "Y is the number of tackles by\na football player in a season,",
    "start": "455630",
    "end": "461940"
  },
  {
    "text": "W and H is height and weight.",
    "start": "461940",
    "end": "464510"
  },
  {
    "text": "And they imagine that they\ntake data from this situation,",
    "start": "464510",
    "end": "469250"
  },
  {
    "text": "they fit a regression model,\nand they obtain, beta 0,",
    "start": "469250",
    "end": "475810"
  },
  {
    "text": "but the coefficient\nof weight is 0.50,",
    "start": "475810",
    "end": "478639"
  },
  {
    "text": "coefficient of\nheight is minus 0.10,",
    "start": "478640",
    "end": "481700"
  },
  {
    "text": "which seems to say that it's\nbetter to be short to make more",
    "start": "481700",
    "end": "487060"
  },
  {
    "text": "tackles.",
    "start": "487060",
    "end": "488565"
  },
  {
    "text": "So the question\nwe're asking here",
    "start": "488565",
    "end": "489940"
  },
  {
    "text": "is, how would you interpret this\ncoefficient of height, given",
    "start": "489940",
    "end": "493600"
  },
  {
    "text": "that weights in the model.",
    "start": "493600",
    "end": "494960"
  },
  {
    "text": "And again, think about this\nand we'll return to the answer",
    "start": "494960",
    "end": "497485"
  },
  {
    "text": "later.",
    "start": "497485",
    "end": "497985"
  },
  {
    "start": "497985",
    "end": "500490"
  },
  {
    "text": "And they also mention\nin that same book,",
    "start": "500490",
    "end": "505530"
  },
  {
    "text": "there's two quotes,\nessentially by George Box,",
    "start": "505530",
    "end": "508440"
  },
  {
    "text": "who was another\nfamous statistician.",
    "start": "508440",
    "end": "510420"
  },
  {
    "text": "\"Essentially, all models are\nwrong, but some are useful.\"",
    "start": "510420",
    "end": "513210"
  },
  {
    "text": "So this it's interesting,\nbecause it's true",
    "start": "513210",
    "end": "515700"
  },
  {
    "text": "that, as we saw on\nthe very first slide,",
    "start": "515700",
    "end": "518190"
  },
  {
    "text": "the regression model, a linear\nmodel, is never exactly right,",
    "start": "518190",
    "end": "521880"
  },
  {
    "text": "but it's often very useful.",
    "start": "521880",
    "end": "524560"
  },
  {
    "text": "So it's important to remember\nthat the model that you assume,",
    "start": "524560",
    "end": "527790"
  },
  {
    "text": "is not to take it too\nseriously, test out your model.",
    "start": "527790",
    "end": "532769"
  },
  {
    "text": "Remember that it's going to\nbe wrong, but also remember,",
    "start": "532770",
    "end": "537480"
  },
  {
    "text": "that despite the fact that\nit's an approximation,",
    "start": "537480",
    "end": "541029"
  },
  {
    "text": "it can be a very\nuseful approximation",
    "start": "541030",
    "end": "542670"
  },
  {
    "text": "in many situations.",
    "start": "542670",
    "end": "544079"
  },
  {
    "text": "And then at this\npoint in the chapter,",
    "start": "544080",
    "end": "546660"
  },
  {
    "text": "also paraphrasing George\nBox, which really it sums up",
    "start": "546660",
    "end": "550384"
  },
  {
    "text": "what I talked about, trying\nto interpret regression",
    "start": "550385",
    "end": "552510"
  },
  {
    "text": "coefficients, the\nonly way to find out",
    "start": "552510",
    "end": "554093"
  },
  {
    "text": "what will happen when a\ncomplex system is disturbed",
    "start": "554093",
    "end": "556230"
  },
  {
    "text": "is to disturb the system, not\nmerely to observe it passively.",
    "start": "556230",
    "end": "560649"
  },
  {
    "text": "If you want to make\na causal statement",
    "start": "560650",
    "end": "563260"
  },
  {
    "text": "about a predictor\nfor an outcome,",
    "start": "563260",
    "end": "565270"
  },
  {
    "text": "you actually have to be able\nto take the system and perturb",
    "start": "565270",
    "end": "568270"
  },
  {
    "text": "that particular predictor,\nkeeping the other ones fixed,",
    "start": "568270",
    "end": "573100"
  },
  {
    "text": "that will allow you to\nmake a causal statement",
    "start": "573100",
    "end": "575170"
  },
  {
    "text": "about a variable like Xj in\nits effect on the outcome.",
    "start": "575170",
    "end": "579550"
  },
  {
    "text": "It's not good enough simply\nto observe some observations",
    "start": "579550",
    "end": "587550"
  },
  {
    "text": "from the system, we can't use\nthat data to conclude causality.",
    "start": "587550",
    "end": "591560"
  },
  {
    "text": "So if you want to know what\nhappens when a complex system is",
    "start": "591560",
    "end": "594060"
  },
  {
    "text": "perturbed, you have to perturb\nit, you can't simply observe it.",
    "start": "594060",
    "end": "597670"
  },
  {
    "text": "So I think that's a wise\nsummary of the use of models",
    "start": "597670",
    "end": "605490"
  },
  {
    "text": "and observational data.",
    "start": "605490",
    "end": "606545"
  },
  {
    "start": "606545",
    "end": "609519"
  },
  {
    "text": "So how do we find the\nleast squares estimates",
    "start": "609520",
    "end": "613180"
  },
  {
    "text": "for the multiple\nregression model?",
    "start": "613180",
    "end": "614899"
  },
  {
    "text": "Well, it's really very\nmuch the same tack",
    "start": "614900",
    "end": "618160"
  },
  {
    "text": "we took for the simple model.",
    "start": "618160",
    "end": "619730"
  },
  {
    "text": "So, first of all,\nour predictions",
    "start": "619730",
    "end": "623199"
  },
  {
    "text": "will be given by this equation,\nthis is the intercept.",
    "start": "623200",
    "end": "626660"
  },
  {
    "text": "And remember, we have one slope\nparameter for each predictor.",
    "start": "626660",
    "end": "629990"
  },
  {
    "text": "We put hats on\nthere, as we always",
    "start": "629990",
    "end": "632290"
  },
  {
    "text": "will when we infer that value\nfrom data, the estimates.",
    "start": "632290",
    "end": "637360"
  },
  {
    "text": "And now what's called the\nmultiple least squares",
    "start": "637360",
    "end": "639459"
  },
  {
    "text": "estimates, are the\nvalues that minimize",
    "start": "639460",
    "end": "641500"
  },
  {
    "text": "the sum of squared deviations\nof points around the plane.",
    "start": "641500",
    "end": "646320"
  },
  {
    "start": "646320",
    "end": "649700"
  },
  {
    "text": "Remember I had\nshowed this picture.",
    "start": "649700",
    "end": "651620"
  },
  {
    "text": "Here's my data points,\nhere's my approximating least",
    "start": "651620",
    "end": "655670"
  },
  {
    "text": "squares plane.",
    "start": "655670",
    "end": "656730"
  },
  {
    "text": "And I'm going to choose\nthe orientation and height",
    "start": "656730",
    "end": "659540"
  },
  {
    "text": "of this plane to minimize\nthe total squared distance",
    "start": "659540",
    "end": "661880"
  },
  {
    "text": "between the red points and their\nclosest point on the hyperplane.",
    "start": "661880",
    "end": "667230"
  },
  {
    "text": "Those are called the\nleast squares estimates.",
    "start": "667230",
    "end": "670519"
  },
  {
    "text": "I'm going to call it the\nmultiple least squares",
    "start": "670520",
    "end": "672860"
  },
  {
    "text": "estimates, because there's\nmultiple predictors.",
    "start": "672860",
    "end": "676190"
  },
  {
    "text": "There is a formula for these\ncoefficients, for the estimates.",
    "start": "676190",
    "end": "679440"
  },
  {
    "text": "It's messy, and it's not\nsomething that one ever computes",
    "start": "679440",
    "end": "682640"
  },
  {
    "text": "by hand, although probably\nin the early 1960s,",
    "start": "682640",
    "end": "684980"
  },
  {
    "text": "people used to do these, poor\nguys used to actually compute",
    "start": "684980",
    "end": "687740"
  },
  {
    "text": "least squares estimates by hand.",
    "start": "687740",
    "end": "689550"
  },
  {
    "text": "They were good at doing\nmatrix computations.",
    "start": "689550",
    "end": "692279"
  },
  {
    "text": "But today we have the\nluxury of fast computers.",
    "start": "692280",
    "end": "694850"
  },
  {
    "text": "And in a program like R, or\nany other statistical package,",
    "start": "694850",
    "end": "697931"
  },
  {
    "text": "we can compute the least squares\nestimates for very big data sets",
    "start": "697932",
    "end": "700640"
  },
  {
    "text": "very quickly.",
    "start": "700640",
    "end": "701430"
  },
  {
    "text": "So we don't need to worry\nabout the formula, we just",
    "start": "701430",
    "end": "703790"
  },
  {
    "text": "need to know what\nwe're doing, which",
    "start": "703790",
    "end": "705290"
  },
  {
    "text": "is refining the values\nof the coefficients that",
    "start": "705290",
    "end": "707269"
  },
  {
    "text": "minimize the sum of squares.",
    "start": "707270",
    "end": "709930"
  },
  {
    "start": "709930",
    "end": "713540"
  },
  {
    "text": "So here's what we get\nfor the advertising data.",
    "start": "713540",
    "end": "717769"
  },
  {
    "text": "The top table are the\ncoefficients, standard errors,",
    "start": "717770",
    "end": "723980"
  },
  {
    "text": "et cetera.",
    "start": "723980",
    "end": "724500"
  },
  {
    "text": "So these are the least\nsquares estimates.",
    "start": "724500",
    "end": "729220"
  },
  {
    "text": "Again, there's a\nlot of terminology",
    "start": "729220",
    "end": "731290"
  },
  {
    "text": "here, coefficient or parameter.",
    "start": "731290",
    "end": "733279"
  },
  {
    "text": "We'll use those interchangeably.\nand as people do.",
    "start": "733280",
    "end": "736272"
  },
  {
    "text": "The intercept, again,\nwe're not typically",
    "start": "736272",
    "end": "737980"
  },
  {
    "text": "interested in the intercept,\nbecause that's just telling us",
    "start": "737980",
    "end": "740438"
  },
  {
    "text": "whether the other\nthree predictors",
    "start": "740438",
    "end": "743200"
  },
  {
    "text": "to 0, whether the sales is\nthe average sales value.",
    "start": "743200",
    "end": "750232"
  },
  {
    "text": "So we don't really\ncare about that,",
    "start": "750232",
    "end": "751690"
  },
  {
    "text": "but we care about\nthe slopes, which",
    "start": "751690",
    "end": "753430"
  },
  {
    "text": "are these three values here.",
    "start": "753430",
    "end": "756310"
  },
  {
    "text": "So we see, for example,\nthe coefficient of TV",
    "start": "756310",
    "end": "760590"
  },
  {
    "text": "is 0.046, standard error.",
    "start": "760590",
    "end": "763000"
  },
  {
    "text": "The T statistic is the ratio,\n0.046 divided by 0.0014.",
    "start": "763000",
    "end": "767940"
  },
  {
    "text": "And the T statistic, do you\nremember I said that T statistic",
    "start": "767940",
    "end": "771570"
  },
  {
    "text": "of bigger than about two is\nsignificant P value of 0.05 .",
    "start": "771570",
    "end": "777460"
  },
  {
    "text": "So the P value of 32 is\nhuge, and the P value",
    "start": "777460",
    "end": "780120"
  },
  {
    "text": "is less than 0.0001.",
    "start": "780120",
    "end": "782970"
  },
  {
    "text": "Similarly for radio,\nvery big effect.",
    "start": "782970",
    "end": "785850"
  },
  {
    "text": "Newspaper.",
    "start": "785850",
    "end": "787110"
  },
  {
    "text": "Newspaper looks like it's\nnot having much effect,",
    "start": "787110",
    "end": "789430"
  },
  {
    "text": "its T statistic is\nminus 0.18, which has",
    "start": "789430",
    "end": "792960"
  },
  {
    "text": "got a P value, which is large.",
    "start": "792960",
    "end": "796170"
  },
  {
    "text": "And P value is close to 1.",
    "start": "796170",
    "end": "798040"
  },
  {
    "text": "P values above 0.05 or\n0.1 are not significant,",
    "start": "798040",
    "end": "801940"
  },
  {
    "text": "they're not evidence\nagainst the null hypothesis,",
    "start": "801940",
    "end": "807850"
  },
  {
    "text": "which is the coefficient of 0.",
    "start": "807850",
    "end": "809949"
  },
  {
    "text": "But let's be more careful\nhow we interpret this.",
    "start": "809950",
    "end": "814323"
  },
  {
    "text": "Remember, each of\nthese statements",
    "start": "814323",
    "end": "815740"
  },
  {
    "text": "is made conditional on the\nother two being in the model.",
    "start": "815740",
    "end": "818110"
  },
  {
    "text": "So in particular,\nthis coefficient",
    "start": "818110",
    "end": "821140"
  },
  {
    "text": "says, given I have the amount\nof money spent on radio",
    "start": "821140",
    "end": "825910"
  },
  {
    "text": "and newspaper,\nspending money on TV",
    "start": "825910",
    "end": "830569"
  },
  {
    "text": "still produces a\nchange in sales.",
    "start": "830570",
    "end": "834420"
  },
  {
    "text": "So in the presence of the other\ntwo predictors, TV is important.",
    "start": "834420",
    "end": "840779"
  },
  {
    "text": "Similarly for radio, the\npresence of TV and newspaper",
    "start": "840780",
    "end": "847720"
  },
  {
    "text": "advertising, radio\nadvertising can be effective,",
    "start": "847720",
    "end": "851170"
  },
  {
    "text": "but newspaper is not in\nthe presence of these two.",
    "start": "851170",
    "end": "854120"
  },
  {
    "text": "So in particular, on its own,\nnewspaper may be significant,",
    "start": "854120",
    "end": "860510"
  },
  {
    "text": "this coefficient\nmay be significant,",
    "start": "860510",
    "end": "862030"
  },
  {
    "text": "but in the presence of the other\ntwo, in the multiple model,",
    "start": "862030",
    "end": "864530"
  },
  {
    "text": "it's not showing significance.",
    "start": "864530",
    "end": "867020"
  },
  {
    "text": "And we can look at the\ncorrelations actually here.",
    "start": "867020",
    "end": "870790"
  },
  {
    "text": "Here are the simple correlations\nbetween the predictors.",
    "start": "870790",
    "end": "874949"
  },
  {
    "text": "And we see there's some\nsignificant correlations.",
    "start": "874950",
    "end": "878190"
  },
  {
    "text": "For example, TV and sales.",
    "start": "878190",
    "end": "882830"
  },
  {
    "text": "Well, sales is the outcome.",
    "start": "882830",
    "end": "885630"
  },
  {
    "text": "But in particular, let's\nsee, radio and newspaper",
    "start": "885630",
    "end": "890270"
  },
  {
    "text": "have a correlation of 0.35.",
    "start": "890270",
    "end": "894450"
  },
  {
    "text": "So what's likely happened here\nis that any effect of newspaper",
    "start": "894450",
    "end": "899250"
  },
  {
    "text": "has been soaked up by\nradio, because they're",
    "start": "899250",
    "end": "901590"
  },
  {
    "text": "correlated at 0.35.",
    "start": "901590",
    "end": "904330"
  },
  {
    "text": "So the radio in the model,\nnewspaper is no longer needed,",
    "start": "904330",
    "end": "908920"
  },
  {
    "text": "it doesn't tell\nus anything more.",
    "start": "908920",
    "end": "911079"
  },
  {
    "text": "It doesn't improve\nthe prediction,",
    "start": "911080",
    "end": "913120"
  },
  {
    "text": "given we've measured\nthe radio advertising,",
    "start": "913120",
    "end": "915610"
  },
  {
    "text": "and that's because of the\ncorrelation being 0.35.",
    "start": "915610",
    "end": "919980"
  },
  {
    "text": "On the other hand,\nlooks like TV and radio",
    "start": "919980",
    "end": "921810"
  },
  {
    "text": "are pretty uncorrelated,\nand so their effects",
    "start": "921810",
    "end": "924870"
  },
  {
    "text": "are somewhat complementary.",
    "start": "924870",
    "end": "928170"
  },
  {
    "text": "So that completes our\ndiscussion of this example.",
    "start": "928170",
    "end": "930386"
  },
  {
    "text": "In the next segment, we'll talk\nabout some important questions",
    "start": "930387",
    "end": "932970"
  },
  {
    "text": "that arise when you use\nregression for real data",
    "start": "932970",
    "end": "935459"
  },
  {
    "text": "analysis.",
    "start": "935460",
    "end": "937310"
  }
]
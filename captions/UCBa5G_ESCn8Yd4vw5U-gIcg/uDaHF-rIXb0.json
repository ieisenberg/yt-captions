[
  {
    "start": "0",
    "end": "5330"
  },
  {
    "text": "Welcome back, everyone. I hope you all had\na good weekend. So we're going to\ntoday get into the very",
    "start": "5330",
    "end": "11480"
  },
  {
    "text": "last chapter of the book. So we've made it through all 12\nchapters, which is pretty cool.",
    "start": "11480",
    "end": "16850"
  },
  {
    "text": "And we're going to be talking\nabout runtime monitoring. We have talked about a\nwhole bunch of methods up",
    "start": "16850",
    "end": "24919"
  },
  {
    "text": "to this point for validation. And all of these methods we can\ncall offline validation methods.",
    "start": "24920",
    "end": "30900"
  },
  {
    "text": "So these are things that\nwe would do potentially before deploying the\nsystem into the real world. So we might find failures,\nestimates, probability",
    "start": "30900",
    "end": "38630"
  },
  {
    "text": "of failure, try to get\nsome formal guarantees, do some explainability.",
    "start": "38630",
    "end": "43640"
  },
  {
    "text": "And we're doing all of this\nbased on some model of the world that we made, which we talked\nabout some ways to make models",
    "start": "43640",
    "end": "50090"
  },
  {
    "text": "in the second and third lecture. But we said it's really hard\nto model all possible things",
    "start": "50090",
    "end": "55969"
  },
  {
    "text": "that we might see. And inevitably, this\nmodel is probably going to miss stuff,\nespecially if we're",
    "start": "55970",
    "end": "61300"
  },
  {
    "text": "trying to model systems\nthat operate in very complicated environments. So for example, cars that\noperate in these various road",
    "start": "61300",
    "end": "68230"
  },
  {
    "text": "environments. So for example, the\nvideo on the left here is like this\ncrazy edge case",
    "start": "68230",
    "end": "75670"
  },
  {
    "text": "that this Waymo vehicle sees\nwhere it's like, I don't know, I'm sure that giant random\nfountain in the middle",
    "start": "75670",
    "end": "82840"
  },
  {
    "text": "of the road was probably not\nsomething that was in the model. Maybe like a fire hydrant\nexploded or something.",
    "start": "82840",
    "end": "88653"
  },
  {
    "text": "And then it kind\nof just drives up to it stops and doesn't\nreally know what to do. But at least it\ndoesn't go through it.",
    "start": "88653",
    "end": "94330"
  },
  {
    "text": "And then I think this\nvideo on the right here is one that Anthony showed\nduring his guest lecture.",
    "start": "94330",
    "end": "99923"
  },
  {
    "text": "But basically what's\ngoing on is there's a Tesla that's\ndriving down the road and it keeps detecting\nall these traffic lights,",
    "start": "99923",
    "end": "105680"
  },
  {
    "text": "and it turns out that it's\nfollowing a truck that was transporting traffic lights. So again, these are just\nlike these crazy edge cases",
    "start": "105680",
    "end": "111400"
  },
  {
    "text": "that we can try as much\nas we want to incorporate every possible edge case into\nour model, but at some point,",
    "start": "111400",
    "end": "117470"
  },
  {
    "text": "we're just not going to be able\nto think of every possible thing that could happen.",
    "start": "117470",
    "end": "122940"
  },
  {
    "text": "And this kind of brings\nme back to a slide from my second lecture, where\nwe were talking about modeling,",
    "start": "122940",
    "end": "128830"
  },
  {
    "text": "and I was talking about\nmy general thoughts on making models. And I was identifying some\nof these key challenges here.",
    "start": "128830",
    "end": "135629"
  },
  {
    "text": "And I said, kind of one\nof the main key challenges is that we need to end up with\na model that's expressive enough",
    "start": "135630",
    "end": "141870"
  },
  {
    "text": "to capture all\npossible scenarios that the system encounters. So random water shooting out\nof road, or traffic lights",
    "start": "141870",
    "end": "148739"
  },
  {
    "text": "on a truck, we\nwould want our model to be able to capture all\nof these possible things. And I mentioned to you that\nbasically every single time I",
    "start": "148740",
    "end": "156180"
  },
  {
    "text": "give a talk on validation,\nit seems like I always get at least one question\nwhere someone comes up and they say, totally\nvalid question, which",
    "start": "156180",
    "end": "163500"
  },
  {
    "text": "is just how can I capture\nall possible scenarios that my crazy whatever\nsystem is going to end up in.",
    "start": "163500",
    "end": "169900"
  },
  {
    "text": "I don't even know\nwhat they all are. I probably wasn't going\nto think of that traffic lights on truck thing.",
    "start": "169900",
    "end": "175210"
  },
  {
    "text": "So how do I deal with this. So again, it's a\ntotally valid question, because it's a really\nhard thing to do.",
    "start": "175210",
    "end": "181370"
  },
  {
    "text": "And so my response, I told\nyou in the second lecture is always like, yeah,\nit's totally a problem. This is really hard.",
    "start": "181370",
    "end": "187569"
  },
  {
    "text": "But I mentioned that\nthere's some hope here, and that you should stay tuned\nfor the runtime monitoring chapter.",
    "start": "187570",
    "end": "193310"
  },
  {
    "text": "So here we are. So runtime monitoring is\ngoing to be the solution here.",
    "start": "193310",
    "end": "199900"
  },
  {
    "text": "So again, we do our best\nto model the world when we do our offline validation. But we're inevitably\ngoing to miss stuff.",
    "start": "199900",
    "end": "205850"
  },
  {
    "text": "And so my answer to all of this\nbasically is runtime monitoring.",
    "start": "205850",
    "end": "211060"
  },
  {
    "text": "So you may have seen\nthis wonderful quote from Hitchhiker's Guide to\nthe Galaxy by Douglas Adams. That's, \"The ultimate answer\nto life, the universe,",
    "start": "211060",
    "end": "218680"
  },
  {
    "text": "and everything is 42.\" I would like to revise\nit slightly and just say that the ultimate\nanswer to life,",
    "start": "218680",
    "end": "224870"
  },
  {
    "text": "the universe, and everything\nis runtime monitoring. So I'm a big, big proponent\nof runtime monitoring.",
    "start": "224870",
    "end": "230870"
  },
  {
    "text": "I think it's going to be\nabsolutely necessary to catch all those things we didn't\ncatch in offline validation and actually deploy our systems\nsafely in the real world.",
    "start": "230870",
    "end": "241760"
  },
  {
    "text": "OK, so with that, the\ngoal of runtime monitoring is to basically flag situations\nthat might be hazardous",
    "start": "241760",
    "end": "249080"
  },
  {
    "text": "when they occur\nso we can trigger some kind of fallback mechanism. So we should ideally understand\nthat we're in a situation",
    "start": "249080",
    "end": "255110"
  },
  {
    "text": "that maybe we didn't validate\nfor, we haven't seen before, we don't know what's\ngoing on, and we can trigger some kind\nof fallback mechanism.",
    "start": "255110",
    "end": "262140"
  },
  {
    "text": "So that could be something\nlike entering into a safe mode. Maybe if you're driving,\nit's just stop the car.",
    "start": "262140",
    "end": "268220"
  },
  {
    "text": "Maybe if you have some human\noperator that's in the loop, you could transfer control\nback to this human operator.",
    "start": "268220",
    "end": "274320"
  },
  {
    "text": "Lots of different\nthings you can do. We're not going to talk super\nspecifically about that. But what we're going\nto focus on today",
    "start": "274320",
    "end": "279833"
  },
  {
    "text": "is like how can we flag\nthese situations that might be hazardous.",
    "start": "279833",
    "end": "285770"
  },
  {
    "text": "So that kind of brings me\nhere into the plan for today. So we're going to talk\nabout lots of different ways",
    "start": "285770",
    "end": "291170"
  },
  {
    "text": "that we could do this. One way is operational\ndesign domain monitoring.",
    "start": "291170",
    "end": "296672"
  },
  {
    "text": "That's what we'll start with. Then we'll get into\nuncertainty quantification. And there's two different\ntypes of uncertainty",
    "start": "296672",
    "end": "303300"
  },
  {
    "text": "we're going to talk about. The first one is\noutput uncertainty. And the second one\nis model uncertainty.",
    "start": "303300",
    "end": "309539"
  },
  {
    "text": "And then super\nbriefly we're going to talk about\nfailure monitoring. And then this is\nmy last lecture,",
    "start": "309540",
    "end": "316900"
  },
  {
    "text": "so we'll wrap up the course. So sad. OK.",
    "start": "316900",
    "end": "322182"
  },
  {
    "text": "So let's jump in with\noperational design domain monitoring. OK, so this idea behind--",
    "start": "322182",
    "end": "329530"
  },
  {
    "text": "And by the way, I\nthink some of you may have heard of\nout-of-distribution detection techniques.",
    "start": "329530",
    "end": "335250"
  },
  {
    "text": "There's different ways\nto categorize this. I think this is\nvery similar to what you would think of\nwhen you maybe hear",
    "start": "335250",
    "end": "341460"
  },
  {
    "text": "out-of-distribution detection. So you can equate these\ntwo in your brain. But for our\npurposes, we're going",
    "start": "341460",
    "end": "347370"
  },
  {
    "text": "to call this operational\ndesign domain monitoring. And the idea is\nthat systems have these things called operational\ndesign domains or ODDs.",
    "start": "347370",
    "end": "355780"
  },
  {
    "text": "And these are basically\nthe set of conditions under which we've designed\nour system to operate safely.",
    "start": "355780",
    "end": "362290"
  },
  {
    "text": "So this could be daytime\nconditions with no rain or something like that.",
    "start": "362290",
    "end": "368070"
  },
  {
    "text": "And basically the idea here\nis like what this could be is like actually the\nset of conditions that the model that we\nuse for validation covers.",
    "start": "368070",
    "end": "376419"
  },
  {
    "text": "So we created some model,\nwe validated against it, and that model contains\nsome set of conditions,",
    "start": "376420",
    "end": "382470"
  },
  {
    "text": "or models some\nset of conditions. And then the idea\nis like if we then operate outside the ODD, or the\noperational design domain, then",
    "start": "382470",
    "end": "390810"
  },
  {
    "text": "we are outside of the conditions\nthat the model we used for validation covers,\nand so our validation",
    "start": "390810",
    "end": "396540"
  },
  {
    "text": "results may no longer be valid. So basically the\ngeneral idea here is just that we want\nto flag situations that",
    "start": "396540",
    "end": "402990"
  },
  {
    "text": "could potentially\nbe us operating outside our operational\ndesign domain. And in that case, we\nwould have basically",
    "start": "402990",
    "end": "411180"
  },
  {
    "text": "no more guarantees on safety\nor our validation results don't mean anything anymore.",
    "start": "411180",
    "end": "417009"
  },
  {
    "text": "And so for example,\nthere's a decent chance, I would imagine, that truck\ntransporting traffic lights",
    "start": "417010",
    "end": "422680"
  },
  {
    "text": "was not in the\noperational design domain that Tesla defined for\ntheir self-driving car,",
    "start": "422680",
    "end": "428990"
  },
  {
    "text": "understandably, because this\nis like a weird, crazy thing to contrive in\nyour mind that you",
    "start": "428990",
    "end": "434050"
  },
  {
    "text": "would have had to come up with. And so the next best thing\nthat we can do, I would say,",
    "start": "434050",
    "end": "440139"
  },
  {
    "text": "is to monitor at runtime\nwhether a system is operating within its\noperational design domain.",
    "start": "440140",
    "end": "446882"
  },
  {
    "text": "Which is a non-trivial\nthing to do. And we're going to talk about\ndifferent methods to do this. But this is kind of our goal. ",
    "start": "446882",
    "end": "454120"
  },
  {
    "text": "So in order to\nmonitor whether or not we're in the operational\ndesign domain, we have to figure out some way\nto represent what this thing is.",
    "start": "454120",
    "end": "462220"
  },
  {
    "text": "And there are multiple\nways to do this. One option is to just use a\nbunch of hand-designed features.",
    "start": "462220",
    "end": "468710"
  },
  {
    "text": "So for example, maybe for\nthe aircraft taxi system, we could say something like\nwe designed it for days where",
    "start": "468710",
    "end": "474440"
  },
  {
    "text": "there's no clouds\nin the sky, there's no glare coming from\nthe sun, it's daytime, and it operates on\ntaxiway A. So maybe this",
    "start": "474440",
    "end": "482060"
  },
  {
    "text": "is like a super\nrestrictive system, but maybe that's\nall we tested for. And if it turns out that were\noutside of these conditions,",
    "start": "482060",
    "end": "487740"
  },
  {
    "text": "then we can't use\nthe system, or we say that we're outside the ODD. And so this is\nsomething we could just",
    "start": "487740",
    "end": "493190"
  },
  {
    "text": "write down ourselves and\nmaybe even check ourselves on the day of before we\ngo deploy our taxi system.",
    "start": "493190",
    "end": "500900"
  },
  {
    "text": "And then there's\nalso one more way that we could define\nthe operational design domain, which is to take\na data-driven approach.",
    "start": "500900",
    "end": "507570"
  },
  {
    "text": "So instead of ourselves\nhand designing all of the different features\nthat say what's in the ODD,",
    "start": "507570",
    "end": "513140"
  },
  {
    "text": "we can take a bunch\nof data from maybe it's all the data that we\nuse for our validation.",
    "start": "513140",
    "end": "519349"
  },
  {
    "text": "So maybe like for\nthe continuum world, maybe we like simulated a\nwhole bunch of trajectories, and we have all of\nthese trajectories",
    "start": "519350",
    "end": "525230"
  },
  {
    "text": "that we saw during our\noffline validation. Or for example, maybe for\nthis intruder detection,",
    "start": "525230",
    "end": "531900"
  },
  {
    "text": "aircraft detection\nsystem, we have all of the images that we\ntrained it on, all of the images that we validated over, and that\ndefines the operational design",
    "start": "531900",
    "end": "539640"
  },
  {
    "text": "domain of the system. So these are both like\nequally valid ways to do this.",
    "start": "539640",
    "end": "544840"
  },
  {
    "text": "And in some cases,\nyou might want to use one versus the other. Yeah I have two questions for this.",
    "start": "544840",
    "end": "550630"
  },
  {
    "text": "So first of all, this is\nrespective or ignorant of the model that\nwe actually use. It's just something about the\nproblem space and the data?",
    "start": "550630",
    "end": "558600"
  },
  {
    "text": "And then for the\nsecond approach, where is the design when you\ndo data-driven definition",
    "start": "558600",
    "end": "565860"
  },
  {
    "text": "of your design domain? Because I feel like when you\nhave hand-designed features, make some sense to say I\ndesign the kind of domain",
    "start": "565860",
    "end": "571890"
  },
  {
    "text": "that I want to work on, but I\nfeel like the right approach is much more like\nout-of-distribution perspective",
    "start": "571890",
    "end": "577980"
  },
  {
    "text": "on this question here. Like the word design\nis like [INAUDIBLE]?",
    "start": "577980",
    "end": "583844"
  },
  {
    "text": "Right. Well, I mean, the data you\nuse is a design decision,",
    "start": "583844",
    "end": "589270"
  },
  {
    "text": "I would say. OK. You can call it the\noperational data domain.",
    "start": "589270",
    "end": "598230"
  },
  {
    "text": "Or the distribution of samples\nthat we need to work on. OK, yeah. Sure, we can say it comes\nfrom a distribution.",
    "start": "598230",
    "end": "605830"
  },
  {
    "text": "That is, we will actually make\nthat assumption in a few slides. [INAUDIBLE] is the difference\nbetween out-of-distribution,",
    "start": "605830",
    "end": "611259"
  },
  {
    "text": "which is kind of the right side,\nand out of the design domain, which is the left side.",
    "start": "611260",
    "end": "618000"
  },
  {
    "text": "I would say Yes. I think out-of-distribution\ndetection, in my opinion, is kind of a subset of this.",
    "start": "618000",
    "end": "625840"
  },
  {
    "text": "But I think the way people\nuse the term is pretty loose. So it depends. yeah.",
    "start": "625840",
    "end": "631832"
  },
  {
    "text": "But we are going to assume\na distribution soon. Yeah. So actually I think maybe\nextending or reframing",
    "start": "631832",
    "end": "637350"
  },
  {
    "text": "the question, do we have to\ndo anything with the data that we're doing in a\ndata-driven approach in the sense of does the\ndata also have to be somehow",
    "start": "637350",
    "end": "644760"
  },
  {
    "text": "integral part of model\ndesign, or can it just be some data [INAUDIBLE]? I think, ideally,\nyou want your data",
    "start": "644760",
    "end": "652750"
  },
  {
    "text": "to represent where you\nexpect your model to work. Sure.",
    "start": "652750",
    "end": "657850"
  },
  {
    "text": "So-- Do you want-- like, do you\nonly have the guarantees if you",
    "start": "657850",
    "end": "663730"
  },
  {
    "text": "say train your model\nto learn this data or is there any notion of we\nhave to use this data somehow",
    "start": "663730",
    "end": "670390"
  },
  {
    "text": "in the design of the policy,\nor at least in the evaluation? I think it depends on\nwhat kind of confidence",
    "start": "670390",
    "end": "678850"
  },
  {
    "text": "you want to have in\nyour ODD monitor. Ideally, I think you\nwould use the data",
    "start": "678850",
    "end": "684490"
  },
  {
    "text": "that you used in validation. Because if you use the data\nthat you use for validation, then you know I did all\nthis offline validation",
    "start": "684490",
    "end": "691300"
  },
  {
    "text": "using this data. So I have all of these offline\nresults that tell me how safe I should be given this data set.",
    "start": "691300",
    "end": "696830"
  },
  {
    "text": "And now I want to know when I'm\noperating online, am I outside of a region that\nI validated over.",
    "start": "696830",
    "end": "702649"
  },
  {
    "text": "So that's what I would do. OK, so they're\nboth equally valid.",
    "start": "702650",
    "end": "712538"
  },
  {
    "text": "Kind of depending on maybe\nthe situation that you're in and what's easier. But I will say that this one on\nthe left here the hand design",
    "start": "712538",
    "end": "719630"
  },
  {
    "text": "features, it does\nrequire domain knowledge. So it requires us to\nsit down and write out what are all the conditions that\nwe have designed our system for.",
    "start": "719630",
    "end": "727500"
  },
  {
    "text": "And it can be quite\ndifficult, I would say, to enumerate all of these. So we're going to focus for\nthe rest of this lecture",
    "start": "727500",
    "end": "735560"
  },
  {
    "text": "on this more automatic\nway of doing things with these data-driven\napproaches.",
    "start": "735560",
    "end": "741769"
  },
  {
    "text": "And so we're going to start with\nthis continuum world example. And we're going to use it as\nkind of a running example.",
    "start": "741770",
    "end": "748400"
  },
  {
    "text": "So basically what\nwe've done is we've assumed that we've done\nsome offline validation. So maybe we just did a very\nsimple offline validation",
    "start": "748400",
    "end": "754940"
  },
  {
    "text": "in this case, where we just\ndid a bunch of rollouts, and saw that they all reached\nthe goal, and none of them reached the obstacle.",
    "start": "754940",
    "end": "761160"
  },
  {
    "text": "And we're going to\nsay that, OK, if we're in the operational\ndesign domain defined by all of these rollouts, then\nwe expect our system to be safe.",
    "start": "761160",
    "end": "768650"
  },
  {
    "text": "And if we're outside\nof it, well, we haven't validated over that. So we don't know\nwhat's going on, and we probably want\nto flag that situation.",
    "start": "768650",
    "end": "775340"
  },
  {
    "text": "So we're going to\nuse this as our data. And specifically, we'll\njust take all of the states that we saw when we were\ndoing all of these rollouts",
    "start": "775340",
    "end": "783170"
  },
  {
    "text": "and use that as the data points\nto define our operational design domain.",
    "start": "783170",
    "end": "789062"
  },
  {
    "text": "OK, and so basically\nour goal here is then to determine\nthe set of states,",
    "start": "789062",
    "end": "795630"
  },
  {
    "text": "so the set of any of the states\nin this outer square here, that are part of the\noperational design domain.",
    "start": "795630",
    "end": "802710"
  },
  {
    "text": "And kind of\nlogically, the idea is that states near\nstates that we saw during our offline\nvalidation should probably",
    "start": "802710",
    "end": "809960"
  },
  {
    "text": "be within the operational\ndesign domain. So with that, maybe kind of\nthe first most obvious thing",
    "start": "809960",
    "end": "816740"
  },
  {
    "text": "to try then is to just say that\nthe operational design domain is the set of points whose nearest\nneighbor in the data set",
    "start": "816740",
    "end": "823620"
  },
  {
    "text": "is within some\nthreshold distance. So basically when we look\nat any point in here, we look at its nearest\nneighbor in the data set.",
    "start": "823620",
    "end": "830529"
  },
  {
    "text": "If it's above the\nthreshold, we say it's outside the\noperational design domain. And if it's within\nthe threshold,",
    "start": "830530",
    "end": "836440"
  },
  {
    "text": "then it's within the ODD. And then you can see that the\nblue shaded region here, given",
    "start": "836440",
    "end": "843030"
  },
  {
    "text": "some threshold, would be like\nthe operational design domain that we define. So then if we're operating and\nwe find ourselves in a state",
    "start": "843030",
    "end": "849810"
  },
  {
    "text": "out here, we can flag it and\nsay that we're not in an area that we've explored before.",
    "start": "849810",
    "end": "856156"
  },
  {
    "text": "OK, so let me show you\nsome different things we can do with nearest neighbors.",
    "start": "856156",
    "end": "863262"
  },
  {
    "text": "OK, so this is the same\nplot we had before. Zoom in a bit. ",
    "start": "863262",
    "end": "871740"
  },
  {
    "text": "So here we can vary\nthis threshold distance that we use to\ndecide whether or not",
    "start": "871740",
    "end": "877170"
  },
  {
    "text": "to include a point in the\noperational design domain. So if I decrease this\nthreshold, do you",
    "start": "877170",
    "end": "883900"
  },
  {
    "text": "think that the operational\ndesign domain will become more or less conservative?",
    "start": "883900",
    "end": "889510"
  },
  {
    "text": "And conservative,\nmeaning like it only includes points near\nthe points we've seen,",
    "start": "889510",
    "end": "895480"
  },
  {
    "text": "and less conservative\nwould be like it includes a whole bunch of extra points. So if I decrease the threshold,\nmore or less conservative?",
    "start": "895480",
    "end": "903259"
  },
  {
    "text": " More. Wait, sorry, the\nthreshold [INAUDIBLE]?",
    "start": "903260",
    "end": "909700"
  },
  {
    "text": "This threshold, which is the\ndistance that's required, it needs to be\nthis close in order to be considered in the\noperational design domain.",
    "start": "909700",
    "end": "915685"
  },
  {
    "text": "More. More conservative,\nyeah, exactly. So we're going to get like less\nand less area that we cover.",
    "start": "915685",
    "end": "922220"
  },
  {
    "text": "We need to be closer and\ncloser to these points, and then to the point\nwhere we could basically just say that the\npoints we've seen",
    "start": "922220",
    "end": "927579"
  },
  {
    "text": "are operational design domain. If we haven't seen this\npoint before, it's not. And then of course, if\nwe go the other way,",
    "start": "927580",
    "end": "932899"
  },
  {
    "text": "we get these very big design\ndomains that maybe include areas that we wouldn't want. So you got to tune\nthis threshold.",
    "start": "932900",
    "end": "939412"
  },
  {
    "text": "Another thing that you can do\nwith nearest neighbors, which is kind of cool. Is you can-- So here\nwe're just showing points",
    "start": "939412",
    "end": "945650"
  },
  {
    "text": "where the closest neighbor\nis within some threshold. But we could up\nthat requirement.",
    "start": "945650",
    "end": "950730"
  },
  {
    "text": "So we could say we\nneed two neighbors, we need two points to be\nwithin some threshold, which would allow us to get rid of\nsome of the outliers out here.",
    "start": "950730",
    "end": "958170"
  },
  {
    "text": "So if I decrease\nthis back and let's increase the number of\nnearest neighbors we require, you see it gets rid of\nsome of these outliers that",
    "start": "958170",
    "end": "965408"
  },
  {
    "text": "are just kind of by themselves,\nbecause we're requiring two points to be nearby.",
    "start": "965408",
    "end": "970670"
  },
  {
    "text": "And we can continue\nto increase this, and you'll see it gets rid of\nsome of the ones on the edge.",
    "start": "970670",
    "end": "975720"
  },
  {
    "text": "So it just depends on how you\nwant to define it basically. OK, so here it is\nimplemented in code.",
    "start": "975720",
    "end": "983639"
  },
  {
    "text": "We basically just compute\nthe nearest neighbors and then check if they're\nwithin this threshold.",
    "start": "983640",
    "end": "989600"
  },
  {
    "text": "OK, but what do you guys think. Are maybe some potential\ndrawbacks of this nearest neighbors approach?",
    "start": "989600",
    "end": "996860"
  },
  {
    "text": "Yeah. [INAUDIBLE] conservative\nin the sense of I'm only looking at the points I've\nseen and also only directly",
    "start": "996860",
    "end": "1004030"
  },
  {
    "text": "next to them, or you set\nyour threshold to be high, and it also could be-- like\nyou're basically not adaptive. It's just either,\ngiven your threshold,",
    "start": "1004030",
    "end": "1011120"
  },
  {
    "text": "it's either way too\nconservative or way too general. Yeah, I mean, you might be\nable to find a good threshold",
    "start": "1011120",
    "end": "1016570"
  },
  {
    "text": "depending on the\nsystem you have. But yeah, you have to\ntune the threshold.",
    "start": "1016570",
    "end": "1021740"
  },
  {
    "text": "I guess I'm thinking\nmore in terms of computation, what might\nbe a potential drawback of this approach.",
    "start": "1021740",
    "end": "1027230"
  },
  {
    "text": "Yeah. You need to compute\nnearest neighbor distance for all points. Yeah, exactly.",
    "start": "1027230",
    "end": "1032272"
  },
  {
    "text": "And there's actually\none more, if anyone wants to try to\nguess, one more issue. Yeah. In high dimensions,\ndistances become very strange",
    "start": "1032273",
    "end": "1040689"
  },
  {
    "text": "in high dimensions. Yeah, I knew you were\ngoing to say that. [LAUGHTER]  But also I think\n[INAUDIBLE] calibrated.",
    "start": "1040690",
    "end": "1047599"
  },
  {
    "text": "Yeah. I think the data structure\nKD [? tree ?] gives you a very fast lookup even for\nvery large numbers of points.",
    "start": "1047599",
    "end": "1053390"
  },
  {
    "text": "I don't think it's\na big problem. True. OK, so the true\ncomputational problem",
    "start": "1053390",
    "end": "1058460"
  },
  {
    "text": "is it requires storing\nthe entire data set in memory at runtime. So even if you have\nthe KD tree, you",
    "start": "1058460",
    "end": "1064180"
  },
  {
    "text": "need to store the\nentire data set. I'm sure there's data\nstructures [INAUDIBLE].",
    "start": "1064180",
    "end": "1069254"
  },
  {
    "text": "No, surprisingly, this is\nactually our biggest bottleneck for [INAUDIBLE]. It's not any of the\nlanguage models. Nearest neighbor search is\nactually our biggest bottleneck",
    "start": "1069255",
    "end": "1075620"
  },
  {
    "text": "for [? Wallace ?] for Ragdoll. So it's actually\nquite extensive. The high dimensional\nthing, do you",
    "start": "1075620",
    "end": "1081020"
  },
  {
    "text": "keep that in your back\npocket, because I am going to talk about it later. I just don't want to\nget to it just yet. But it totally is also an issue.",
    "start": "1081020",
    "end": "1086810"
  },
  {
    "text": "OK, but yeah. So basically the\ncomputation can be an issue if we have to store the\nentire data set in memory.",
    "start": "1086810",
    "end": "1092940"
  },
  {
    "text": "We might not want to\ntake that on board with us when we\ndeploy it at runtime and have to check every single\ntime, find the nearest neighbor.",
    "start": "1092940",
    "end": "1100700"
  },
  {
    "text": "And so-- But the KD tree could reduce\nit to logarithmic time",
    "start": "1100700",
    "end": "1106010"
  },
  {
    "text": "for each [INAUDIBLE] Yeah, so it helps. We still have to store the data.",
    "start": "1106010",
    "end": "1112430"
  },
  {
    "text": "OK, and so one way, though,\nthat we could potentially improve this without\nlosing too much accuracy",
    "start": "1112430",
    "end": "1118500"
  },
  {
    "text": "is to just cluster\nall of the data. So we could run like K-means\nclustering or something like that. Cluster all of the data, get\nall of the cluster centers,",
    "start": "1118500",
    "end": "1126130"
  },
  {
    "text": "and then just use those data\npoints to define the nearest neighbors. So we'll say you need to\nbe within some distance",
    "start": "1126130",
    "end": "1131670"
  },
  {
    "text": "of the cluster centers. And then you don't need to-- You only need to store\nthe cluster centers,",
    "start": "1131670",
    "end": "1136960"
  },
  {
    "text": "and you only need\nto check distance to all of the cluster centers. ",
    "start": "1136960",
    "end": "1144054"
  },
  {
    "text": "So that's one option. Another thing we could\ndo without trying to upload the whole data set or\ncluster centers onto our robot",
    "start": "1144054",
    "end": "1152220"
  },
  {
    "text": "or whatever we're\ndeploying is we could use a more compact\nset representation, such as a polytope.",
    "start": "1152220",
    "end": "1159150"
  },
  {
    "text": "So does anyone, given\nall of these points, does anyone have an\nidea of how we might define a polytope from them?",
    "start": "1159150",
    "end": "1164524"
  },
  {
    "text": " Yeah. [INAUDIBLE]",
    "start": "1164525",
    "end": "1171480"
  },
  {
    "text": "Yeah, exactly. You could just take the outside\nvertices, or in other words, the convex hull of the data.",
    "start": "1171480",
    "end": "1178172"
  },
  {
    "text": "OK, but there is one\nkind of issue with this, is like our ODD seems like\nit's kind of non-convex.",
    "start": "1178172",
    "end": "1185600"
  },
  {
    "text": "And if we just take\nthe convex hull, we're including this\nwhole region there that doesn't really seem to be\npart of the operational design",
    "start": "1185600",
    "end": "1191799"
  },
  {
    "text": "domain. And so one thing that\nwe could do instead is like cluster the data.",
    "start": "1191800",
    "end": "1197270"
  },
  {
    "text": "So maybe we cluster it into\ntwo different clusters, the blue one, and\nthe purple one. And then we take the\nunion of the convex hull",
    "start": "1197270",
    "end": "1204250"
  },
  {
    "text": "of both of these clusters\nand we get a nicer shape. And we could just do that\nwith more and more clusters",
    "start": "1204250",
    "end": "1209350"
  },
  {
    "text": "to get a better shape. OK, so I'm going to show you\nin a second what the algorithm",
    "start": "1209350",
    "end": "1217060"
  },
  {
    "text": "looks like for this. But before I do, I want\nto show you a quick Slack conversation about it.",
    "start": "1217060",
    "end": "1222470"
  },
  {
    "text": "So when we were writing\nthis chapter of the book, I messaged and I said,\nOK, so hear me out.",
    "start": "1222470",
    "end": "1229360"
  },
  {
    "text": "If we do decide to include\nalgorithms for some of the ODD monitors we're\nstill debating, we could have an\nalgorithm like this.",
    "start": "1229360",
    "end": "1235760"
  },
  {
    "text": "It looks like this. It's a hull monitor. And then [MUTED] replied\nand said, you know,",
    "start": "1235760",
    "end": "1242110"
  },
  {
    "text": "I'm absolutely on\nboard with this. I love it. If the HullMonitor's\nchecks pass, it could send a HullPass flag.",
    "start": "1242110",
    "end": "1249450"
  },
  {
    "text": "[LAUGHTER]  And this is how I know I\nwork with the absolute best people in the whole world.",
    "start": "1249450",
    "end": "1255530"
  },
  {
    "text": "So yeah. So here it is. This is like the one joke from\nthis class that actually made it",
    "start": "1255530",
    "end": "1263350"
  },
  {
    "text": "into the book. So here's our hull monitor\nif you're having trouble picturing this, there you go.",
    "start": "1263350",
    "end": "1270240"
  },
  {
    "text": " Points inside, inside, outside.",
    "start": "1270240",
    "end": "1275830"
  },
  {
    "text": "And it really doesn't\nlike the \"I\" and monitor, which is kind of strange. But yeah.",
    "start": "1275830",
    "end": "1282465"
  },
  {
    "text": "OK, so that's-- Did anyone have questions\non the hull monitors? ",
    "start": "1282465",
    "end": "1291310"
  },
  {
    "text": "OK. So one more option for defining\nthe operational design domain",
    "start": "1291310",
    "end": "1297620"
  },
  {
    "text": "is to use the super\nlevel set of a function. So now we're going to\ntalk about distributions.",
    "start": "1297620",
    "end": "1303060"
  },
  {
    "text": "So what we could do is\ndefine it as the super level set of a distribution.",
    "start": "1303060",
    "end": "1308750"
  },
  {
    "text": "Super level set, if you're\nnot familiar with the term, it's just all the points\nthat results in a function",
    "start": "1308750",
    "end": "1313760"
  },
  {
    "text": "value greater than some value. So just think of if you\nhad a plot of a function,",
    "start": "1313760",
    "end": "1318800"
  },
  {
    "text": "just like chop\noff at some value, and it's all those\npoints that correspond to that value or higher.",
    "start": "1318800",
    "end": "1325580"
  },
  {
    "text": "And so what we could do is\njust like fit a distribution to our data. So maybe we fit a multivariate\nGaussian to our data set.",
    "start": "1325580",
    "end": "1333000"
  },
  {
    "text": "And then we say we'll\ntake the Super level set of the probability\ndensity of this distribution.",
    "start": "1333000",
    "end": "1339470"
  },
  {
    "text": "So we'll say, if\nthe density is high enough in this\ndistribution at our point, then we'll include\nit in the ODD.",
    "start": "1339470",
    "end": "1346280"
  },
  {
    "text": "Otherwise, not. So taking the super\nlevel set would give us some set like this.",
    "start": "1346280",
    "end": "1352500"
  },
  {
    "text": "But this doesn't look great. And the kind of caveat\nhere is that you need to make sure that you\nselect a model class when",
    "start": "1352500",
    "end": "1359850"
  },
  {
    "text": "you're selecting this\ndistribution that's expressive enough. So a multivariate\nGaussian doesn't really fit this data set very well.",
    "start": "1359850",
    "end": "1366960"
  },
  {
    "text": "But a mixture of\nmultivariate Gaussians fits the data pretty well. And so we could take this upper\nlevel set of this mixture.",
    "start": "1366960",
    "end": "1374559"
  },
  {
    "text": "And then we get a\npretty nice definition of our operational\ndesign domain. And one thing that's\nkind of nice about this",
    "start": "1374560",
    "end": "1381150"
  },
  {
    "text": "is it can actually\neasily trade off between these high density\nand low density regions. So for we don't\nreally want to include",
    "start": "1381150",
    "end": "1387570"
  },
  {
    "text": "the regions of low density in\nour operational design domain, because we validated over those,\nbut not super significantly,",
    "start": "1387570",
    "end": "1394650"
  },
  {
    "text": "because we never really\nsaw these states very much. We can easily trade off by\njust changing that threshold",
    "start": "1394650",
    "end": "1399720"
  },
  {
    "text": "for the distribution. Any questions on that?",
    "start": "1399720",
    "end": "1404880"
  },
  {
    "text": "Yeah. So we've taken into\naccount that we're making this choice at the\nsuper level set itself doesn't",
    "start": "1404880",
    "end": "1412290"
  },
  {
    "text": "have a great [INAUDIBLE]. Correct. So yeah, you basically\nthrow the distribution away",
    "start": "1412290",
    "end": "1420630"
  },
  {
    "text": "when you create this. Because typically right\nnow all we're trying to do is have a binary flag.",
    "start": "1420630",
    "end": "1425740"
  },
  {
    "text": "Is it in the ODD, is it not? You could imagine,\ndepending on how you deploy your\nruntime monitor, you",
    "start": "1425740",
    "end": "1431340"
  },
  {
    "text": "could keep around\nthe distribution and try to use that value to\ndo decision making as well.",
    "start": "1431340",
    "end": "1437490"
  },
  {
    "text": "It just depends on your task.  Any other questions on this?",
    "start": "1437490",
    "end": "1442655"
  },
  {
    "text": " OK.",
    "start": "1442655",
    "end": "1449380"
  },
  {
    "text": "There's one other way you can\nuse this super level set idea. And that is to take\nthe super level",
    "start": "1449380",
    "end": "1455399"
  },
  {
    "text": "set of a model that's trained to\noutput a likelihood of a point being in the operational\ndesign domain.",
    "start": "1455400",
    "end": "1461919"
  },
  {
    "text": "So for example, we could\ngather a whole bunch of data. We keep the data we had in\nthe operational design domain.",
    "start": "1461920",
    "end": "1467605"
  },
  {
    "text": "And we could can gather\na whole bunch of data outside the operational\ndesign domain, and then train a classifier\nto take in a point",
    "start": "1467605",
    "end": "1474940"
  },
  {
    "text": "and say, is it\noutside or inside, and output a\nprobability of that.",
    "start": "1474940",
    "end": "1480130"
  },
  {
    "text": "So maybe we get a classifier\nwith probabilities that look like this. And then we can just\nthreshold that probability",
    "start": "1480130",
    "end": "1486010"
  },
  {
    "text": "and say if that probability\nis greater than some value, we'll say that it's inside of\nthe operational design domain,",
    "start": "1486010",
    "end": "1491960"
  },
  {
    "text": "and we get something like this. What might be a drawback\nof this approach?",
    "start": "1491960",
    "end": "1498075"
  },
  {
    "text": " Yeah. You have to fit a\ndistribution each time. And if your system is\nway too complicated,",
    "start": "1498075",
    "end": "1505050"
  },
  {
    "text": "you either have to\nmake a lot of additions or a lot of very\nfancy distributions.",
    "start": "1505050",
    "end": "1510790"
  },
  {
    "text": "You might need a fancy\ndistribution, but specifically for fitting this classifier,\nwhat did we need?",
    "start": "1510790",
    "end": "1516480"
  },
  {
    "start": "1516480",
    "end": "1521679"
  },
  {
    "text": "What were all those\nred data points? ",
    "start": "1521680",
    "end": "1526850"
  },
  {
    "text": "Stuff that doesn't\nneed to [INAUDIBLE]. Stuff that was outside of the\noperational design domain.",
    "start": "1526850",
    "end": "1533530"
  },
  {
    "text": "So basically we had all\nthose white data points. All the methods\nup to this point, we just used the\nwhite data points that we fitted distribution\nof white data points,",
    "start": "1533530",
    "end": "1540382"
  },
  {
    "text": "et cetera, et cetera. But here we had to get all\nof these red data points",
    "start": "1540382",
    "end": "1545480"
  },
  {
    "text": "from outside the ODD,\nthen fit this classifier. And the problem is, like,\nif we had all of that data",
    "start": "1545480",
    "end": "1552230"
  },
  {
    "text": "from outside the\noperational design domain, we probably just would\nhave designed our system with that data.",
    "start": "1552230",
    "end": "1557370"
  },
  {
    "text": "So-- Yeah. But if you go and\nfalsify your system, and you have a bunch of\nstuff that's going to fail,",
    "start": "1557370",
    "end": "1564900"
  },
  {
    "text": "and then suddenly you have\nboth in and out of the ODD. I would say the\nODD is everything you saw during validation,\nwhether it failed or not.",
    "start": "1564900",
    "end": "1572340"
  },
  {
    "text": "Oh, I see. OK. Yeah, and so there\ncould be states like we just never even saw. Like a truck transporting\ntraffic lights is the idea here.",
    "start": "1572340",
    "end": "1579179"
  },
  {
    "text": "And so we want to\nsay, so the blue is like everything we've seen,\nwhether it failed or not. In this case, none of them\nfailed because they all",
    "start": "1579180",
    "end": "1584990"
  },
  {
    "text": "made it to the goal. And we just want to say,\nwhen are we in a situation that we haven't seen.",
    "start": "1584990",
    "end": "1590020"
  },
  {
    "text": "But then to train this,\nwe would need data that we haven't seen, which\nis kind of the problem. [INAUDIBLE]",
    "start": "1590020",
    "end": "1595590"
  },
  {
    "text": "Yeah, exactly. That's kind of the issue\nwith this approach. So sometimes like you\ncan get a little bit",
    "start": "1595590",
    "end": "1600600"
  },
  {
    "text": "of out-of-distribution data. Like for example, say\nyou had a taxi system that was trained to\noperate during the day,",
    "start": "1600600",
    "end": "1606100"
  },
  {
    "text": "but you have a few\nimages at night. So maybe you could try to train\na classifier to distinguish the ones that were at night.",
    "start": "1606100",
    "end": "1612040"
  },
  {
    "text": "But if you had a whole bunch\nof images of the taxi system operating at night,\nyou might as well have just trained\non those images.",
    "start": "1612040",
    "end": "1617547"
  },
  {
    "text": "And so a lot of times\nit's not super useful, if your method for operational\ndesign domain detection",
    "start": "1617547",
    "end": "1623670"
  },
  {
    "text": "requires data from outside\nthe operational design domain. Because you\ntypically don't have.",
    "start": "1623670",
    "end": "1629160"
  },
  {
    "text": "Yeah. So it's just something\nto keep in mind. Any other questions on this?",
    "start": "1629160",
    "end": "1637320"
  },
  {
    "text": "Yeah. I think the biggest\nissue with this is that it's not always\na given that you have",
    "start": "1637320",
    "end": "1643230"
  },
  {
    "text": "a compact and useful state\nrepresentation in vector form,",
    "start": "1643230",
    "end": "1648346"
  },
  {
    "text": "in any vector space. Take images for example,\nyou can flatten it and do it in pixel space. Yeah. That'd be ridiculous.",
    "start": "1648347",
    "end": "1653940"
  },
  {
    "text": "Do not do that. So you have to-- Right into to the\nnext slide here. So this all works really\nwell in low dimensions,",
    "start": "1653940",
    "end": "1660970"
  },
  {
    "text": "but things get a little\nweird in high dimensions. Specifically ODDs\ndefined by images.",
    "start": "1660970",
    "end": "1667030"
  },
  {
    "text": "So good point. So yeah, that's exactly\nwhere we're headed. So this will satisfy you\na little bit as well.",
    "start": "1667030",
    "end": "1673480"
  },
  {
    "text": "I totally agree. It's like way harder. And it's way harder, mostly due\nto this curse of dimensionality",
    "start": "1673480",
    "end": "1678660"
  },
  {
    "text": "where the volume of the space\nthat the data must cover increases exponentially with\nthe dimension of the data.",
    "start": "1678660",
    "end": "1685660"
  },
  {
    "text": "So for our taxi images, for\nexample, there are 4,096 pixels. So we have a 4,096 dimensional\nspace that we now need to cover",
    "start": "1685660",
    "end": "1692880"
  },
  {
    "text": "with all of our images. And that's just not\nvery easy to do. So we're going to need\na whole bunch of data",
    "start": "1692880",
    "end": "1699580"
  },
  {
    "text": "if we want to adequately\ncover that space. And then secondly, as you\nwere kind of pointing out,",
    "start": "1699580",
    "end": "1704620"
  },
  {
    "text": "and as you were kind\nof pointing out, is that distance metrics tend\nto lose meaning once you're",
    "start": "1704620",
    "end": "1710080"
  },
  {
    "text": "in a space like this. So, for example, what is the\ndistance between two images. Is it like the Euclidean\ndistance between vectors",
    "start": "1710080",
    "end": "1718030"
  },
  {
    "text": "of pixel values. This isn't super obvious,\nand a lot of times you want more of a\nsemantic distance",
    "start": "1718030",
    "end": "1723550"
  },
  {
    "text": "measure between two images. But this is just like in\ngeneral, not an obvious thing to do.",
    "start": "1723550",
    "end": "1729039"
  },
  {
    "text": "So you need to be careful when\nyou scale up to high dimensions. So there's a few things\nyou can do about this.",
    "start": "1729040",
    "end": "1735130"
  },
  {
    "text": "One option is to\njust kind of brute force it and just get more\ndata and get better models.",
    "start": "1735130",
    "end": "1740687"
  },
  {
    "text": "So you could just\ntry to use something like, maybe a Gaussian\nis not going to work, but you could try to fit\nlike a normalizing flow.",
    "start": "1740687",
    "end": "1747460"
  },
  {
    "text": "Although there's been\nshown that there's issues trying to do that as well. If you're interested,\ntalk to me later.",
    "start": "1747460",
    "end": "1753070"
  },
  {
    "text": "But this is one option. You could just try to have\nbetter models that scale to these high\ndimensional settings.",
    "start": "1753070",
    "end": "1760510"
  },
  {
    "text": "Another option is to assume\nthat your high dimensional data, like your whole set of\nimages, came from some lower",
    "start": "1760510",
    "end": "1766700"
  },
  {
    "text": "dimensional manifold,\nand then try to find that manifold\nand do all of your--",
    "start": "1766700",
    "end": "1772040"
  },
  {
    "text": "define your operational\ndesign domain in that lower\ndimensional manifold.",
    "start": "1772040",
    "end": "1777350"
  },
  {
    "text": "So what does that look like. Here let's say we took our 4,096\ndimensional taxi images and we",
    "start": "1777350",
    "end": "1784430"
  },
  {
    "text": "used some dimensionality\nreduction techniques. So in this case, we\nused an autoencoder. But there's lots of different\ntechniques you can use.",
    "start": "1784430",
    "end": "1791550"
  },
  {
    "text": "I'm not really going\nto talk about that. But here we basically took this\n4,096 dimensional image and we",
    "start": "1791550",
    "end": "1798110"
  },
  {
    "text": "projected it down into\na two-dimensional space. So this is completely\nvisualizing the new dimension",
    "start": "1798110",
    "end": "1804710"
  },
  {
    "text": "of the images. So we have two features here. And so this image,\nfor example, would",
    "start": "1804710",
    "end": "1811549"
  },
  {
    "text": "map to one of the points in\nthis two dimensional space. And then a bunch of other\nimages that look like it,",
    "start": "1811550",
    "end": "1818280"
  },
  {
    "text": "but from different\nangles and cross track on the runway will produce\ndifferent points in this lower",
    "start": "1818280",
    "end": "1825720"
  },
  {
    "text": "dimensional space. And now this\ntwo-dimensional distance seems to make a little\nbit more sense here.",
    "start": "1825720",
    "end": "1831910"
  },
  {
    "text": "And so we could just define\nour operational design domain in this lower dimensional space. So maybe using nearest\nneighbors, or any of the other",
    "start": "1831910",
    "end": "1839190"
  },
  {
    "text": "approaches that I\njust talked about. And then the idea is now when\nwe get a new image at runtime,",
    "start": "1839190",
    "end": "1846940"
  },
  {
    "text": "so for example this\nimage here, this image actually doesn't really\nlook like this image here.",
    "start": "1846940",
    "end": "1854200"
  },
  {
    "text": "It's pretty like saturated. Maybe there's some weird sun\nglare that's causing this. But it's super bright.",
    "start": "1854200",
    "end": "1859630"
  },
  {
    "text": "We can barely see the edges. This is not part of our\noperational design domain. And it turns out\nif we project it",
    "start": "1859630",
    "end": "1865409"
  },
  {
    "text": "into this lower\ndimensional manifold, along with a bunch of other\nimages that look very similar, we get the red points\nthat you see here.",
    "start": "1865410",
    "end": "1872409"
  },
  {
    "text": "And so now we can actually\nsee that the image when",
    "start": "1872410",
    "end": "1877860"
  },
  {
    "text": "we project it is not part of\nthe operational design domain. And so we, at runtime, be\nable to flag that and say,",
    "start": "1877860",
    "end": "1883850"
  },
  {
    "text": "hey, we got a point\nthat's not in this lower dimensional manifold,\nand so we're going to flag that as outside\nthe operational design domain.",
    "start": "1883850",
    "end": "1893170"
  },
  {
    "text": "But there is one\nissue with this. So let's say that we\ngot this image instead.",
    "start": "1893170",
    "end": "1898690"
  },
  {
    "text": "This is also not in the\noperational design domain, because this one's\nactually super dark. It's more like we were doing\nthis at night or something",
    "start": "1898690",
    "end": "1905080"
  },
  {
    "text": "like that. It's not in our operational\ndesign domain of daytime images. But it turns out\nif we project this",
    "start": "1905080",
    "end": "1911470"
  },
  {
    "text": "into our lower dimensional\nmanifold and a bunch of points like it, we get all\nof these yellow points here, which actually\nkind of projected",
    "start": "1911470",
    "end": "1918850"
  },
  {
    "text": "into a region in\nthis manifold that's part of the operational\ndesign domain. But this is not the\nbehavior that we wanted.",
    "start": "1918850",
    "end": "1925539"
  },
  {
    "text": "And for example, like\nthis white point here is another image that's actually\nin the operational design",
    "start": "1925540",
    "end": "1932679"
  },
  {
    "text": "domain. And they project wo\npoints very close to each other in this\nlower dimensional space. Now it turns out\nthere's a name for this.",
    "start": "1932680",
    "end": "1938930"
  },
  {
    "text": "It's called feature collapse. And the idea is that when you\nproject down to these lower dimensional spaces,\nthere's no guarantee",
    "start": "1938930",
    "end": "1945250"
  },
  {
    "text": "that these distinct\nsets of images are actually going to remain\nseparated in these spaces.",
    "start": "1945250",
    "end": "1951320"
  },
  {
    "text": "And so you need to be\ncareful, because it worked for these saturated images, but\nthen all of these dark images",
    "start": "1951320",
    "end": "1957130"
  },
  {
    "text": "actually collapsed to a region\ninside of the operational design domain defined by\nour daytime images.",
    "start": "1957130",
    "end": "1964610"
  },
  {
    "text": "So it's just something\nto be careful of. Any questions on that?",
    "start": "1964610",
    "end": "1969945"
  },
  {
    "text": " Yeah. I think some people also use--",
    "start": "1969945",
    "end": "1976780"
  },
  {
    "text": "you get some embedding\nof your which I guess, again, is like a low dimensional\nrepresentation of your images.",
    "start": "1976780",
    "end": "1982340"
  },
  {
    "text": "And then you do\ncosine similarity. How would that fit into this? Pretty similar.",
    "start": "1982340",
    "end": "1987830"
  },
  {
    "text": "So I think that would just be-- So this I would consider to\nbe a two-dimensional embedding basically.",
    "start": "1987830",
    "end": "1993200"
  },
  {
    "text": "And then we're using\nEuclidean distance. But you could use\ncosine distance instead to define the nearest neighbors.",
    "start": "1993200",
    "end": "1999145"
  },
  {
    "text": "Yeah. So it would be a similar thing. You wouldn't have this\nfeature collapsed I suppose. I think you would.",
    "start": "1999145",
    "end": "2004840"
  },
  {
    "text": "Like the cosine distance\nbetween these yellow points and this white point is still\ngoing to be quite small.",
    "start": "2004840",
    "end": "2009955"
  },
  {
    "text": "So I think you still\nhave an issue of feature collapse in that case. ",
    "start": "2009955",
    "end": "2016610"
  },
  {
    "text": "Yeah. Are there ways to detect\nfeature collapse other than just looking at the data?",
    "start": "2016610",
    "end": "2021885"
  },
  {
    "text": " I would say there aren't really\ngood ways to detect it other",
    "start": "2021885",
    "end": "2027940"
  },
  {
    "text": "than when you're testing,\nyou might notice it. But that's kind of why it's a\nproblem, is because of the fact",
    "start": "2027940",
    "end": "2034090"
  },
  {
    "text": "that you can't detect it. And also this is still\nirrespective of the model",
    "start": "2034090",
    "end": "2041158"
  },
  {
    "text": "that we want to validate. So this is just a function,\nagain, of the data, and whether or not our\nmodel will actually",
    "start": "2041158",
    "end": "2046958"
  },
  {
    "text": "work now on the entire manifold\nor something like this, we haven't made any\nstatement about that, right? Yeah, exactly.",
    "start": "2046958",
    "end": "2051960"
  },
  {
    "text": "So that's why I'm\nsaying like the data you use to define your\noperational design domain is ideally the data that\nyou saw during validation,",
    "start": "2051960",
    "end": "2058510"
  },
  {
    "text": "during your offline validation. So you've run probability and\nfailure analysis on that data. You've run formal methods\non that data or something.",
    "start": "2058510",
    "end": "2065870"
  },
  {
    "text": "And now you-- So you know\nthis is how I expect my system to perform in this region.",
    "start": "2065870",
    "end": "2072544"
  },
  {
    "text": "And if I'm outside\nthat region, there's just no guarantee basically. ",
    "start": "2072545",
    "end": "2080560"
  },
  {
    "text": "OK. Was there any other\nquestions on that?",
    "start": "2080560",
    "end": "2086060"
  },
  {
    "text": "Yeah. [INAUDIBLE] are they\njust kind of arbitrary?",
    "start": "2086060",
    "end": "2091250"
  },
  {
    "text": "There's like arbitrary. So I just trained like\nan autoencoder which like goes from high\ndimension, low dimension, and then tries to project\nit back to high dimension.",
    "start": "2091250",
    "end": "2098270"
  },
  {
    "text": "And it's just whatever comes\nout in the middle there a lot of times it's not\nsuper interpretable.",
    "start": "2098270",
    "end": "2104380"
  },
  {
    "text": "Yeah. And it doesn't have to be 2D. I did it 2D, obviously,\nso we could visualize it. But you'd probably\nget better performance",
    "start": "2104380",
    "end": "2110680"
  },
  {
    "text": "if you didn't collapse all the\nway down to two dimensions. OK.",
    "start": "2110680",
    "end": "2115700"
  },
  {
    "text": "All right, so that's operational\ndesign domain monitoring. So again, this is just\nchecking like we've defined some domain we expect\nour system to operate in.",
    "start": "2115700",
    "end": "2122730"
  },
  {
    "text": "How can we just tell if\nwe're outside of that domain. Now we're going to talk about\nsomething called uncertainty",
    "start": "2122730",
    "end": "2129350"
  },
  {
    "text": "quantification. And the basic idea\nhere is just that it's helpful to understand\nour uncertainty",
    "start": "2129350",
    "end": "2135530"
  },
  {
    "text": "in the various aspects of the\ncurrent and future behavior of the system. Because if we're uncertain\nabout what's happening right now",
    "start": "2135530",
    "end": "2141140"
  },
  {
    "text": "or what's about to\nhappen, we might want to flag that situation,\nand again, like transfer control back to a human or\nenter some of safe mode.",
    "start": "2141140",
    "end": "2148290"
  },
  {
    "text": "So this is actually\nusing some model of the behavior of\nthe system and trying",
    "start": "2148290",
    "end": "2154310"
  },
  {
    "text": "to quantify our uncertainty. So that's basically what we do. We'll create a\nmodel that predicts",
    "start": "2154310",
    "end": "2159590"
  },
  {
    "text": "some aspect of system behavior. So it could be predicting the\ncurrent state of the system. It could be predicting the next\naction of the system, something",
    "start": "2159590",
    "end": "2166425"
  },
  {
    "text": "like that. And then we understand the\nuncertainty in that prediction to understand what's going on.",
    "start": "2166425",
    "end": "2173310"
  },
  {
    "text": "So for example, maybe\nwe train our robot to say like, I think I'm\n2 meters from the wall, but I'm only 60% sure of this.",
    "start": "2173310",
    "end": "2180048"
  },
  {
    "text": "And then we can take\nthat information and decide what we want\nthe robot to do from there.",
    "start": "2180048",
    "end": "2186030"
  },
  {
    "text": "OK, so there's two\ntypes of uncertainty. And I'm going to give a\nlittle demo on each of them",
    "start": "2186030",
    "end": "2193260"
  },
  {
    "text": "to help you learn what they are. And so the first\ntype of uncertainty we're going to do a\nlittle exercise here.",
    "start": "2193260",
    "end": "2198910"
  },
  {
    "text": "So this is two pictures. I guess you can't really see\nwhat's in them at all just yet.",
    "start": "2198910",
    "end": "2204130"
  },
  {
    "text": "But one of these\npictures is Michael. And one of these-- Michael is a teenager. And one of these pictures is\nMatt Damon, who he supposedly",
    "start": "2204130",
    "end": "2212250"
  },
  {
    "text": "looked like as a teenager. And so I'm going-- who he did look\nlike as a teenager.",
    "start": "2212250",
    "end": "2218800"
  },
  {
    "text": "So I'm going to-- He didn't age as gracefully. [LAUGHTER]  He didn't age as gracefully.",
    "start": "2218800",
    "end": "2225035"
  },
  {
    "text": "What if Matt Damon is\ngoing to watch this? We can try to make it happen.",
    "start": "2225035",
    "end": "2231250"
  },
  {
    "text": "OK, so I'm going to have you\ntry to guess which one is which. Right now they're\nkind of too dark,",
    "start": "2231250",
    "end": "2237020"
  },
  {
    "text": "but we're going to make them\nprogressively a little bit brighter. So let's make go one level up.",
    "start": "2237020",
    "end": "2242180"
  },
  {
    "text": "Can you tell there's\npeople in there? I can tell on my iPad,\nbut maybe not here. All right, let's go one more.",
    "start": "2242180",
    "end": "2247965"
  },
  {
    "text": "OK, you can start to see\nthe outline of some people. All right, which one do\nyou guys think is Michael?",
    "start": "2247965",
    "end": "2253335"
  },
  {
    "text": " The one on the right?",
    "start": "2253335",
    "end": "2258915"
  },
  {
    "text": "[INTERPOSING VOICES]  Yeah. The one on the left? I can't see a semicircle.",
    "start": "2258915",
    "end": "2265000"
  },
  {
    "text": "There seems to be-- [INTERPOSING VOICES] You're confident. Very confident. Left?",
    "start": "2265000",
    "end": "2270400"
  },
  {
    "text": "Left. Left, for sure. I don't know. Has your confidence increased?",
    "start": "2270400",
    "end": "2276910"
  },
  {
    "text": "Certainly left. Certainly left. Left. OK. Yeah, Michael is on the left.",
    "start": "2276910",
    "end": "2283690"
  },
  {
    "text": "Although I still\ncan't really tell. I don't know. It's pretty close.",
    "start": "2283690",
    "end": "2288740"
  },
  {
    "text": "I'm still a little\nbit uncertain here. My certainty and\nhopefully your certainty",
    "start": "2288740",
    "end": "2294040"
  },
  {
    "text": "as well has increased\nas we increase the brightness of those photos.",
    "start": "2294040",
    "end": "2299349"
  },
  {
    "text": "And that is an example\nof output uncertainty. So when they were\nsuper dark, you didn't really know\nwhich one was Michael",
    "start": "2299350",
    "end": "2305829"
  },
  {
    "text": "and which one was Matt Damon. And when they were light, maybe\nyou still couldn't really tell, but maybe you were slightly\nmore certain that this one was,",
    "start": "2305830",
    "end": "2312980"
  },
  {
    "text": "in fact, Michael as a teenager. OK, so that's the idea\nbehind output uncertainty.",
    "start": "2312980",
    "end": "2319600"
  },
  {
    "text": "Here's model uncertainty. So can anyone tell\nme what this is? ",
    "start": "2319600",
    "end": "2329079"
  },
  {
    "text": "OK, that's kind of the point. So you guys don't have an\ninternal model for what this is. It turns out that this is a\npicture from the early days",
    "start": "2329080",
    "end": "2337900"
  },
  {
    "text": "of image generation. Early days being, I\nguess, 2022, where this was like DALL-E\nand someone asked",
    "start": "2337900",
    "end": "2344470"
  },
  {
    "text": "it to generate a photo\nof a bottle of ranch dressing testifying in court.",
    "start": "2344470",
    "end": "2349650"
  },
  {
    "text": "So that's what this is\nsupposed to be, I guess. But this is model uncertainty,\nbecause your internal model",
    "start": "2349650",
    "end": "2356030"
  },
  {
    "text": "of the world probably doesn't\nhave a bottle of ranch dressing testifying in court,\nlike inside of it, because you've probably\nnever seen that before.",
    "start": "2356030",
    "end": "2362970"
  },
  {
    "text": "I know I certainly haven't. And so this is\nmodel uncertainty. It's like a lack\nof data or a lack of knowledge about the world.",
    "start": "2362970",
    "end": "2370220"
  },
  {
    "text": "OK, here's one more example\nof model uncertainty. OK, so go ahead and study\nthese for a second here.",
    "start": "2370220",
    "end": "2376200"
  },
  {
    "text": "It shouldn't take too long. It's not a trick question. OK, what is that expression?",
    "start": "2376200",
    "end": "2383005"
  },
  {
    "text": "5. 5. Yeah, there wasn't\nanything crazy going on. OK, what about this?",
    "start": "2383006",
    "end": "2388430"
  },
  {
    "text": "Yeah. You have an answer for this one? [INAUDIBLE] well.",
    "start": "2388430",
    "end": "2393800"
  },
  {
    "text": "No, sorry, 3. What? Wait, where did you get that?",
    "start": "2393800",
    "end": "2399830"
  },
  {
    "text": "I'm assuming-- He speaks Unicode. Oh, OK.",
    "start": "2399830",
    "end": "2405319"
  },
  {
    "text": "This is good. So you could accidentally have\nmodels be confidently wrong. [LAUGHTER]",
    "start": "2405320",
    "end": "2412486"
  },
  {
    "text": " Oh no. The point was to\nmodel uncertainty. You just don't\nknow what this is.",
    "start": "2412486",
    "end": "2419460"
  },
  {
    "text": "We'd rather our model\nthrow up its hands and say, I don't know than just assume. Yeah, do you have a question?",
    "start": "2419460",
    "end": "2424900"
  },
  {
    "text": "Sorry, what is the like Michael,\nMatt Damon and [INAUDIBLE]? Which one is which.",
    "start": "2424900",
    "end": "2431222"
  },
  {
    "text": "The output uncertainty. The output is like whether\nit's Michael or Matt Damon. Oh, we are, but.",
    "start": "2431222",
    "end": "2437369"
  },
  {
    "text": "You are uncertain\nin that output. Oh, I see. So I am the policy\nand I'm [INAUDIBLE] You're the policy.",
    "start": "2437370",
    "end": "2442480"
  },
  {
    "text": "You're the policy here too. And the ranch dressing,\nyou are also the policy. We know, [INAUDIBLE]",
    "start": "2442480",
    "end": "2447720"
  },
  {
    "text": "Or the model. We're looking at your internal\nmodel and we're saying, is your internal model--",
    "start": "2447720",
    "end": "2453960"
  },
  {
    "text": "what is your internal model's\ncertainty or uncertainty of which one's Matt Damon\nand which one's Michael.",
    "start": "2453960",
    "end": "2459369"
  },
  {
    "text": "And here we're saying now you\nhave this model that you got and then you use that internal\nmodel to calculate this one.",
    "start": "2459370",
    "end": "2465375"
  },
  {
    "text": "Your internal\nmodel knows nothing about what cry face and\nupside down face does.",
    "start": "2465375",
    "end": "2470960"
  },
  {
    "text": "And so then you would\njust ideally say like, I don't know what this is. It's like model uncertainty.",
    "start": "2470960",
    "end": "2476140"
  },
  {
    "text": "Got it. Yeah. Yeah, isn't this just more like\nout-of-distribution situation",
    "start": "2476140",
    "end": "2484089"
  },
  {
    "text": "where this is just something\nwe have no concept of at all. But there's not really any\nuncertainty here because I",
    "start": "2484090",
    "end": "2489970"
  },
  {
    "text": "can't be like, maybe it's\nthis or maybe it's that, and I would say 50/50. But instead I'm just like,\nI have no idea at all.",
    "start": "2489970",
    "end": "2497073"
  },
  {
    "text": "Well, there is\nuncertainty, right? The fact that like upside down\nface is minus and crying face",
    "start": "2497073",
    "end": "2502705"
  },
  {
    "text": "is divide is like-- Yeah, I think it's debatable.",
    "start": "2502705",
    "end": "2510110"
  },
  {
    "text": "And I've gone back and forth\nmyself a lot about this. I think we've gone back\nand forth about this. I think the way I'm going to\npresent model uncertainty later",
    "start": "2510110",
    "end": "2517750"
  },
  {
    "text": "is very similar to just like a\nbinary, like are we uncertain, are we not uncertain. Because I agree with you that\nit's pretty tough to define",
    "start": "2517750",
    "end": "2525100"
  },
  {
    "text": "a scale of uncertainty there. But the way we\ncome at it is from a probabilistic perspective.",
    "start": "2525100",
    "end": "2531800"
  },
  {
    "text": "So that's why I would\ncall it uncertainty. But I agree with you. I think it's hard\nto really define.",
    "start": "2531800",
    "end": "2538810"
  },
  {
    "text": "But it's still what\nthe test to know if this is uncertainty,\noutput uncertainty or model uncertainty, from what the\nexamples that I just saw, it",
    "start": "2538810",
    "end": "2547300"
  },
  {
    "text": "would be, the first one, it's\nwithin the ODD, but I'm there,",
    "start": "2547300",
    "end": "2554150"
  },
  {
    "text": "but I'm just a little bit\nuncertain and I can help you do, which would probably get\nto you, but it's just",
    "start": "2554150",
    "end": "2560500"
  },
  {
    "text": "some level of probability\non the output I can scale. This one is way outside of--",
    "start": "2560500",
    "end": "2568750"
  },
  {
    "text": "Yeah, yeah, I think\nthat's exactly right. So like to summarize what\nyou just said, so it's output uncertainty occurs when\na single input can lead",
    "start": "2568750",
    "end": "2575619"
  },
  {
    "text": "to multiple different outputs. So like maybe we have\nrandomness in the real world due to other agents.",
    "start": "2575620",
    "end": "2581120"
  },
  {
    "text": "So it's like I know\nexactly where I am, but like I don't know what\nthese people are going to do. But I know that\nI don't know what these people are going to do.",
    "start": "2581120",
    "end": "2586817"
  },
  {
    "text": "But it's just not\nsomething that I can know. Or the outcome of a coin\nflip, heads or tails. I know it's going to\nland heads or tails,",
    "start": "2586817",
    "end": "2593310"
  },
  {
    "text": "and I know I'm not sure\nwhich one, but one of those is going to happen. And another common example\nwould be like sensor noise.",
    "start": "2593310",
    "end": "2599460"
  },
  {
    "text": "So we know that our\nsensors are noisy. We know that one\nstate could lead to different possible\nobservations,",
    "start": "2599460",
    "end": "2605299"
  },
  {
    "text": "because our sensors are noisy. We just don't know what\nthose necessarily are. So a lot of times\nthis is referred",
    "start": "2605300",
    "end": "2611510"
  },
  {
    "text": "to as aleatoric uncertainty\nor irreducible uncertainty. It's just inherent in the world.",
    "start": "2611510",
    "end": "2616970"
  },
  {
    "text": "And then model\nuncertainty occurs due to limitations of the\nmodel that we're using to predict our system behavior.",
    "start": "2616970",
    "end": "2622620"
  },
  {
    "text": "So for example, due\nto a lack of data. And so we could call this\nepistemic uncertainty sometimes,",
    "start": "2622620",
    "end": "2628940"
  },
  {
    "text": "or some people call this\nreducible uncertainty. Because if we just learned\nabout that topic, then we could make our predictions.",
    "start": "2628940",
    "end": "2635990"
  },
  {
    "text": "What were those [INAUDIBLE]? I don't know.",
    "start": "2635990",
    "end": "2641089"
  },
  {
    "text": "Just multiplication\nand division. Yes. But you had them backwards. [LAUGHTER]",
    "start": "2641090",
    "end": "2647284"
  },
  {
    "text": " ChatGPT gave an answer. Wow.",
    "start": "2647284",
    "end": "2652410"
  },
  {
    "text": "With some reasoning.  The first one is 5.",
    "start": "2652410",
    "end": "2659400"
  },
  {
    "text": "That was right. That was right. Did it get the second one?",
    "start": "2659400",
    "end": "2665850"
  },
  {
    "text": "I'm a little confused\nby this hallucination. OK, sounds good.",
    "start": "2665850",
    "end": "2674040"
  },
  {
    "text": "OK. So just to illustrate\nthis here, say we have a very simple\ndata set that we're",
    "start": "2674040",
    "end": "2679620"
  },
  {
    "text": "going to use as a running\nexample, where we have some input point X\nand some output Y,",
    "start": "2679620",
    "end": "2685520"
  },
  {
    "text": "and then here's our\ndata points that we have to learn this model. And so here we have\nlow output uncertainty.",
    "start": "2685520",
    "end": "2692859"
  },
  {
    "text": "They're kind of all\nclumped together. And then over on this side, we\nhave high output uncertainty. And then in the middle, where we\nhave basically no data at all,",
    "start": "2692860",
    "end": "2701410"
  },
  {
    "text": "we have high model uncertainty. Questions on that? ",
    "start": "2701410",
    "end": "2709200"
  },
  {
    "text": "OK. All right, so we're going to\nstart with output uncertainty. And output uncertainty\nis present in the data",
    "start": "2709200",
    "end": "2716070"
  },
  {
    "text": "that we gather from the system. So we're in our\noperational design domain. We just know that there's\nthis inherent uncertainty",
    "start": "2716070",
    "end": "2722010"
  },
  {
    "text": "in the world. And because it's present\nin the data that we gather, we can actually\nthen use this data",
    "start": "2722010",
    "end": "2727590"
  },
  {
    "text": "to train a model that can\nquantify this uncertainty, because we can learn\nit from the data.",
    "start": "2727590",
    "end": "2732863"
  },
  {
    "text": "And we do that by\ntraining a model to output parameters\nof a distribution over its prediction. So we're not just going to\npredict the current state we're",
    "start": "2732863",
    "end": "2739440"
  },
  {
    "text": "in, for example, we'll\npredict the current state we're in with some\nvariance around that state.",
    "start": "2739440",
    "end": "2745290"
  },
  {
    "text": "And so to do this,\nwe get to throw back to my favorite derivation ever\nthat I showed you in lecture 2,",
    "start": "2745290",
    "end": "2751870"
  },
  {
    "text": "where we basically derived\nthe least squares loss function by making an assumption\nthat our data was generated",
    "start": "2751870",
    "end": "2758560"
  },
  {
    "text": "by applying some\nfunction to our input and then applying some\nGaussian noise to it.",
    "start": "2758560",
    "end": "2764507"
  },
  {
    "text": "And if you remember,\nwe plugged this all in and we maximized the log\nlikelihood of the data and we saw that that was\nequivalent to the least",
    "start": "2764508",
    "end": "2770950"
  },
  {
    "text": "squares loss function. But the key assumption that\nwe made when we did this was that the\nvariance is constant.",
    "start": "2770950",
    "end": "2779690"
  },
  {
    "text": "So we said, we\nadd Gaussian noise to it but with some\nconstant variance.",
    "start": "2779690",
    "end": "2784730"
  },
  {
    "text": "It does not depend on our input. And now we want to\nactually quantify given our input, what is\nour current uncertainty.",
    "start": "2784730",
    "end": "2792170"
  },
  {
    "text": "And so we're going to allow\nthat variance to vary. So we have non-constant\nor varying variance.",
    "start": "2792170",
    "end": "2798380"
  },
  {
    "text": "And we're going to instead say\nthat our mean or our prediction, which we were calling F\nbefore, is a function of X.",
    "start": "2798380",
    "end": "2806180"
  },
  {
    "text": "So this is the same as before. But now we're going to say we're\nalso going to allow our variance",
    "start": "2806180",
    "end": "2811540"
  },
  {
    "text": "to be a function of X. So before when we were\ndoing this optimization, we could just get\nrid of the variance,",
    "start": "2811540",
    "end": "2817790"
  },
  {
    "text": "because our theta\ndidn't depend on it. But now we're saying that\nour parameter's theta predict",
    "start": "2817790",
    "end": "2825289"
  },
  {
    "text": "both the variance and the mean. So we have to keep those\nterms in our expression. But we just follow the\nexact same process.",
    "start": "2825290",
    "end": "2832800"
  },
  {
    "text": "And now we get a\nkind of loss function that we could\noptimize that contains",
    "start": "2832800",
    "end": "2838220"
  },
  {
    "text": "both the mean and the variance. So we could learn both\nof those from our data.",
    "start": "2838220",
    "end": "2844160"
  },
  {
    "text": "So this is basically the\nloss that we would plug-in when we train our model. And just to give\nyou some intuition",
    "start": "2844160",
    "end": "2850700"
  },
  {
    "text": "here, if we look\nat the terms that are present in\nthis loss function, so we still have this\nmean squared error",
    "start": "2850700",
    "end": "2856130"
  },
  {
    "text": "term that we had\nbefore, but now we have some stuff that has\nto do with the variance that it outputs.",
    "start": "2856130",
    "end": "2861950"
  },
  {
    "text": "And the second term here is\njust the log of the variance. And we're trying to minimize. So it says, minimize\nthe log of the variance.",
    "start": "2861950",
    "end": "2867645"
  },
  {
    "text": "So make the variance small. But then the second term, we\nalso want this term to be small,",
    "start": "2867645",
    "end": "2873950"
  },
  {
    "text": "because we're\ntrying to minimize, but the variance is\non the denominator. And so in this case,\nmaking the variance bigger",
    "start": "2873950",
    "end": "2880410"
  },
  {
    "text": "will actually make\nthis term smaller. And so basically what\nwe're saying here is there's two ways to\nmake this term small.",
    "start": "2880410",
    "end": "2887410"
  },
  {
    "text": "We can minimize the mean\nsquared error between the output and our prediction. Or we could increase\nthe variance.",
    "start": "2887410",
    "end": "2893920"
  },
  {
    "text": "And so the idea is in\nwhere we can't minimize this mean squared\nerror, because there's all sorts of output\nuncertainty, and so we",
    "start": "2893920",
    "end": "2900270"
  },
  {
    "text": "can't make a prediction\nthat perfectly matches all of our data\npoints, then we'll try to make this variance high.",
    "start": "2900270",
    "end": "2906580"
  },
  {
    "text": "So it's basically saying make\nthe variance high in areas where the squared error is high. So in areas where we can't\nmake as good of a prediction,",
    "start": "2906580",
    "end": "2913840"
  },
  {
    "text": "we want to output\na high variance. And then in general, though, we\nwant to output a lower variance. And it turns out\nif you balance them",
    "start": "2913840",
    "end": "2920670"
  },
  {
    "text": "in this way, you'll actually get\na calibrated output uncertainty,",
    "start": "2920670",
    "end": "2926190"
  },
  {
    "text": "which I think is super So here's what this\nwould look like. Here's our data set that we\nwere using as a running example.",
    "start": "2926190",
    "end": "2933070"
  },
  {
    "text": "And I actually just\ntrained a model using this exact loss\nfunction to output both the mean and the variance.",
    "start": "2933070",
    "end": "2940140"
  },
  {
    "text": "And here I'm plotting the mean\nof the model as this blue line here. And then I'm plotting two\nstandard deviations away",
    "start": "2940140",
    "end": "2948030"
  },
  {
    "text": "as the shaded region there, plus\nor minus 2 standard deviations. So we're assuming\nthis is Gaussian.",
    "start": "2948030",
    "end": "2954339"
  },
  {
    "text": "So that should contain\nabout 95% of the data. And you can see that\nit pretty much does. So it actually works quite well.",
    "start": "2954340",
    "end": "2960310"
  },
  {
    "text": "And this is like a\nvery standard practice for quantifying the uncertainty\nof regression models.",
    "start": "2960310",
    "end": "2968520"
  },
  {
    "text": "Any questions on that? ",
    "start": "2968520",
    "end": "2976140"
  },
  {
    "text": "Yeah. I guess one thing is that\nwhere we have no data, it's still pretty confident.",
    "start": "2976140",
    "end": "2981690"
  },
  {
    "text": "So that's maybe not great. Yeah, I'm going to talk\nabout that in a little bit. But basically like\nyeah, you can't really",
    "start": "2981690",
    "end": "2988950"
  },
  {
    "text": "trust the uncertainty\nin this region. Yeah, that's a good point. ",
    "start": "2988950",
    "end": "2995200"
  },
  {
    "text": "So now we can say where\nwe have low variance.",
    "start": "2995200",
    "end": "3000460"
  },
  {
    "text": "It corresponds to low\noutput uncertainty. We were saying when we\nlooked at the data before. And where we have\nhigh variance it",
    "start": "3000460",
    "end": "3006119"
  },
  {
    "text": "corresponds to high\noutput uncertainty. For classification models, a\nlot of classification models",
    "start": "3006120",
    "end": "3013410"
  },
  {
    "text": "by default already actually\noutput a distribution. So any classification model\nthat applies a softmax function",
    "start": "3013410",
    "end": "3019560"
  },
  {
    "text": "at the end already outputs\na discrete distribution, because it'll output these\nvalues for the classes that",
    "start": "3019560",
    "end": "3025619"
  },
  {
    "text": "sum up to 1. So we take the\nsoftmax of the output. And then, for\nexample, we can now",
    "start": "3025620",
    "end": "3030960"
  },
  {
    "text": "say that we're 80%\nconfident that class number one is the true label.",
    "start": "3030960",
    "end": "3038220"
  },
  {
    "text": "And then in general we could say\nlike this type of a distribution has low uncertainty. And then if we're\nkind of equally",
    "start": "3038220",
    "end": "3043920"
  },
  {
    "text": "confident that each\nclass is the label, then we have pretty\nhigh uncertainty in what the true class is.",
    "start": "3043920",
    "end": "3050110"
  },
  {
    "text": "And so in this\nscenario, we would be more concerned and more\nlikely to flag that scenario",
    "start": "3050110",
    "end": "3055790"
  },
  {
    "text": "for runtime monitoring. OK, but there's an\nissue here, which",
    "start": "3055790",
    "end": "3062540"
  },
  {
    "text": "has been shown a number of\ntimes, which is that we often end up actually having an\nissue with the of the output",
    "start": "3062540",
    "end": "3068810"
  },
  {
    "text": "distribution. So there's this really\ncool paper from a while ago that talks about how\nmodern neural networks tend",
    "start": "3068810",
    "end": "3074510"
  },
  {
    "text": "to not be well calibrated. So if you just train\na neural network with a softmax layer on the\nend, the softmax probabilities",
    "start": "3074510",
    "end": "3081230"
  },
  {
    "text": "are probably not actually the\nprobability that it's correct. If you remember\nfrom chapter 2, when",
    "start": "3081230",
    "end": "3088340"
  },
  {
    "text": "we were doing model validation\nand we were plotting like these calibration\ncurves and stuff, we had this curve\nthat was supposed",
    "start": "3088340",
    "end": "3094310"
  },
  {
    "text": "to line up with Y\nequals X, you can see that this blue model which\nis like a modern neural network,",
    "start": "3094310",
    "end": "3099570"
  },
  {
    "text": "doesn't seem like it's\nvery well calibrated. So in general, this\nis just like an issue that comes up quite often.",
    "start": "3099570",
    "end": "3106910"
  },
  {
    "text": "And the reason for this\nis that it turns out that if we were able to\nperfectly minimize the log likelihood when we were\ntraining our model, then--",
    "start": "3106910",
    "end": "3116300"
  },
  {
    "text": "So that means we had infinite\ndata of the distribution we were trying to match. We had infinite model\ncapacity, and we",
    "start": "3116300",
    "end": "3122150"
  },
  {
    "text": "were able to get the global\nminimum of that model, then the output\ndistribution would perfectly",
    "start": "3122150",
    "end": "3127190"
  },
  {
    "text": "match the true distribution\nthat we care about. But of course, in practice\nthat's never the case.",
    "start": "3127190",
    "end": "3132720"
  },
  {
    "text": "So training is\nalways approximate. We never have infinite\ndata, we never have infinite model capacity.",
    "start": "3132720",
    "end": "3138470"
  },
  {
    "text": "And so we need to typically\napply some additional techniques after the fact. If we actually want\nto have a calibrated",
    "start": "3138470",
    "end": "3144470"
  },
  {
    "text": "model that we can trust\nthe uncertainties for. ",
    "start": "3144470",
    "end": "3150830"
  },
  {
    "text": "And so I'm just going\nto go through one really short calibration\ntechnique, because we",
    "start": "3150830",
    "end": "3156980"
  },
  {
    "text": "don't have much time. But if you're interested\nthere's more information on this in that\nsection of the book.",
    "start": "3156980",
    "end": "3162927"
  },
  {
    "text": "But one thing we\ncould do is something called temperature\nscaling, which is really simple for a\nsoftmax classification models.",
    "start": "3162927",
    "end": "3169050"
  },
  {
    "text": "So here's our softmax function. And essentially all we do is add\nin this extra parameter called",
    "start": "3169050",
    "end": "3175700"
  },
  {
    "text": "lambda. And it basically adjusts\nour softmax probabilities. So by the way, also\nsometimes this lambda is",
    "start": "3175700",
    "end": "3183290"
  },
  {
    "text": "written as 1 over t. And T is called a\ntemperature parameter. And that's why it's called\ntemperature scaling.",
    "start": "3183290",
    "end": "3188618"
  },
  {
    "text": "But these are like\nequivalent formulations. So we have various values\nwe can pick for lambda.",
    "start": "3188618",
    "end": "3195569"
  },
  {
    "text": "If we pick lambda\nequals 1 this just reduces to the typical softmax\nfunction that we always use.",
    "start": "3195570",
    "end": "3201660"
  },
  {
    "text": "So we'll just get the\nprobabilities we had before. If lambda is equal to 0, then\nwe get X of 0, which is 1.",
    "start": "3201660",
    "end": "3209369"
  },
  {
    "text": "And this is also\ngoing to be X of 0. So it's going to be 1\ndivided by the sum up to K of 1, or 1 over\nK. And it's going",
    "start": "3209370",
    "end": "3216200"
  },
  {
    "text": "to be that same thing\nfor all of our classes. So it's basically\njust going to tend towards this uniform probability\nacross all of our classes.",
    "start": "3216200",
    "end": "3224780"
  },
  {
    "text": "And if lambda is\nequal to infinity, it's going to go in\nthe opposite direction and we're going to assign\nall of our confidence",
    "start": "3224780",
    "end": "3230610"
  },
  {
    "text": "to the maximum class.",
    "start": "3230610",
    "end": "3236160"
  },
  {
    "text": "And so ideally we probably want\nto be somewhere in between here. But we know that this was\nnot calibrated properly.",
    "start": "3236160",
    "end": "3242830"
  },
  {
    "text": "And so we want to basically\npick a value for lambda that gets us a better calibration.",
    "start": "3242830",
    "end": "3248880"
  },
  {
    "text": "So again, we can pick\na value for lambda that minimizes the negative log\nlikelihood on a calibration set.",
    "start": "3248880",
    "end": "3254470"
  },
  {
    "text": "So we have some set of data. We'll pick a value for lambda,\ncompute the negative log likelihood on all of that\ndata, and then pick the value",
    "start": "3254470",
    "end": "3261750"
  },
  {
    "text": "for lambda that does the best. So I'll show you what that\nlooks like real quick. ",
    "start": "3261750",
    "end": "3269015"
  },
  {
    "text": "OK, so here's some\ndata I trained for a model that is\ntrained to predict",
    "start": "3269015",
    "end": "3275040"
  },
  {
    "text": "the action for the\ncontinuum world problem. And you can see\nwhen lambda is 1,",
    "start": "3275040",
    "end": "3280750"
  },
  {
    "text": "so that's when we do\nno temperature scaling, it doesn't seem like it's\ncalibrated super well.",
    "start": "3280750",
    "end": "3285940"
  },
  {
    "text": "We're kind of not matching\nthis line Y equals X. And then what we can\ndo is we can actually",
    "start": "3285940",
    "end": "3291520"
  },
  {
    "text": "vary lambda and plot the\nnegative log likelihood over this calibration data set.",
    "start": "3291520",
    "end": "3296920"
  },
  {
    "text": "And what we want to do is try\nto minimize the negative log likelihood. So we'll try to move\nlambda to the right",
    "start": "3296920",
    "end": "3304190"
  },
  {
    "text": "so we get to the minimum of\nthis negative log likelihood, and then we get something\nthat's a little bit closer",
    "start": "3304190",
    "end": "3309430"
  },
  {
    "text": "to calibrated. Because we're only\nvarying one parameter, we're never going\nto necessarily be able to get it to be\nperfectly calibrated.",
    "start": "3309430",
    "end": "3316400"
  },
  {
    "text": "But we can just do\nour best by picking kind of the minimum\nnegative log likelihood.",
    "start": "3316400",
    "end": "3323380"
  },
  {
    "text": "And then of course, if we\nmake lambda really high, then we get this\nvery bad calibration. And same with if\nwe make it too low",
    "start": "3323380",
    "end": "3330730"
  },
  {
    "text": "and it's the same if\nwe make it too high. Any questions on that?",
    "start": "3330730",
    "end": "3336020"
  },
  {
    "text": "Yeah What is a\ncalibration data set?",
    "start": "3336020",
    "end": "3342610"
  },
  {
    "text": "It would be data. It's basically like a\nvalidation data set, but just like another\none on top of that you're",
    "start": "3342610",
    "end": "3349359"
  },
  {
    "text": "using to calibrate your model. So it should come from the\nsame distribution as the data",
    "start": "3349360",
    "end": "3355000"
  },
  {
    "text": "that you trained on. I guess it doesn't have to. It should come from\nthe distribution",
    "start": "3355000",
    "end": "3360280"
  },
  {
    "text": "that you expect your model\nto see when you deploy it in the real world. OK, so that was one way\nto quantify uncertainty",
    "start": "3360280",
    "end": "3369700"
  },
  {
    "text": "where we output\nthese distributions and then maybe we calibrate\nthem because sometimes they're not necessarily going\nto be calibrated.",
    "start": "3369700",
    "end": "3375490"
  },
  {
    "text": "But we can also use these things\ncalled prediction sets, which I'm probably just going to go\nthrough really fast due to time.",
    "start": "3375490",
    "end": "3382059"
  },
  {
    "text": "But the idea here is we\ncan instead of outputting a distribution, we\ncan output a set and just say like where\nthis confident, which",
    "start": "3382060",
    "end": "3388480"
  },
  {
    "text": "is our coverage,\nsay, we're like 95% confident that our true\noutput is in this set.",
    "start": "3388480",
    "end": "3394580"
  },
  {
    "text": "So for example,\nmaybe our robot is like I think I'm right here,\nplus or minus 2 meters,",
    "start": "3394580",
    "end": "3400450"
  },
  {
    "text": "and I'm 95% confident that\nI'm like here, plus or minus 2 meters. And that's our prediction set.",
    "start": "3400450",
    "end": "3406819"
  },
  {
    "text": "So one way to get\na prediction set. And again, I'm going to go\nthrough this kind of fast. So happy to talk\noffline about it,",
    "start": "3406820",
    "end": "3412520"
  },
  {
    "text": "is like maybe we\nwant a prediction set with 95% coverage. And we know this is our\ndistribution over the output.",
    "start": "3412520",
    "end": "3417990"
  },
  {
    "text": "So we could just take the 95%\ninterval or 95% probability",
    "start": "3417990",
    "end": "3423590"
  },
  {
    "text": "mass of this distribution,\nand then that would define our prediction set.",
    "start": "3423590",
    "end": "3429320"
  },
  {
    "text": "In a classification\ntask, maybe we want to have 95% of the\nprobability in our prediction",
    "start": "3429320",
    "end": "3434359"
  },
  {
    "text": "set. So we're basically just\ngoing to include classes until we've accumulated 95%\nof the probability mass.",
    "start": "3434360",
    "end": "3442050"
  },
  {
    "text": "So that would be\nsomething like this. And then we can use\nthese prediction sets",
    "start": "3442050",
    "end": "3447470"
  },
  {
    "text": "to understand whether\nwe have high uncertainty or low uncertainty. So the bigger the prediction\nset, the higher our uncertainty,",
    "start": "3447470",
    "end": "3455870"
  },
  {
    "text": "because we're like maybe I'm\nlike I'm 95% confident that I'm here plus or minus 100 meters. OK, I'm quite uncertain\nin where I'm actually at,",
    "start": "3455870",
    "end": "3463100"
  },
  {
    "text": "versus I'm 95%\nconfident that I'm here plus or minus 2\ncentimeters, then I'm pretty certain where I'm at.",
    "start": "3463100",
    "end": "3471450"
  },
  {
    "text": "OK, so an issue with\nthis approach, just to go a little bit more quickly. This would assume then that\nour output distribution",
    "start": "3471450",
    "end": "3479370"
  },
  {
    "text": "is calibrated,\nbecause we would have to take that uncertainty set. If our output distribution\nis not calibrated, we're going to get the\nwrong uncertainty set.",
    "start": "3479370",
    "end": "3486572"
  },
  {
    "text": "So one thing we could\ndo is we could just use all the methods I\ntalked about to calibrate this distribution first.",
    "start": "3486572",
    "end": "3493740"
  },
  {
    "text": "Or we could take everyone's\nfamous buzzword these days and apply something called\nconformal prediction, which",
    "start": "3493740",
    "end": "3500820"
  },
  {
    "text": "is everyone's favorite. And conformal\nprediction basically allows us to generate accurate\nprediction sets, even using",
    "start": "3500820",
    "end": "3508200"
  },
  {
    "text": "an uncalibrated\nuncertainty measure. So that's why it's so popular,\nbecause we can generate",
    "start": "3508200",
    "end": "3513272"
  },
  {
    "text": "these prediction sets without\nhaving to do that calibration step that I talked about,\nwhich is kind of cool. So that's the main takeaway\nI want you to have,",
    "start": "3513272",
    "end": "3520270"
  },
  {
    "text": "because I put this in here to\nmake sure I stayed on track, because I want to finish. So it's 2:32.",
    "start": "3520270",
    "end": "3526160"
  },
  {
    "text": "So we're going to be skipping\nto model uncertainty, and here's a paper.",
    "start": "3526160",
    "end": "3531319"
  },
  {
    "text": "It's super good, though. So if you haven't gotten\ninto conformal prediction and just want to get an\nidea of what's going on,",
    "start": "3531320",
    "end": "3537590"
  },
  {
    "text": "this paper is\nreally, really good. And they also have\na YouTube tutorial that goes with it\nthat I think is also",
    "start": "3537590",
    "end": "3543940"
  },
  {
    "text": "really good if you're more into\nwatching videos, which I am. OK, so I'll just\nflip through these.",
    "start": "3543940",
    "end": "3551590"
  },
  {
    "text": "Here's how it works. But we're not really\ngoing to talk about it. ",
    "start": "3551590",
    "end": "3567130"
  },
  {
    "text": "OK, that was output uncertainty. OK, so now there's this\nidea of model uncertainty. And so you might\nask, which we were",
    "start": "3567130",
    "end": "3573855"
  },
  {
    "text": "kind of talking about\nbefore, is like why can't you quantify model uncertainty\nin the same way.",
    "start": "3573855",
    "end": "3580390"
  },
  {
    "text": "And the reason is because\nmodel uncertainty is typically due to a lack of data.",
    "start": "3580390",
    "end": "3585650"
  },
  {
    "text": "So we don't have\ndata in this region. And so there's no reason to\nexpect our uncertainty estimate",
    "start": "3585650",
    "end": "3591460"
  },
  {
    "text": "to be calibrated in this region,\nbecause we have no data there. And so maybe the data\nwe were missing actually",
    "start": "3591460",
    "end": "3597760"
  },
  {
    "text": "looks like this. And we have no reason to believe\nthat that couldn't be the case.",
    "start": "3597760",
    "end": "3602812"
  },
  {
    "text": "And we just don't know. So we can't expect our\nuncertainty estimate that we predict using output\nuncertainty methods to actually",
    "start": "3602812",
    "end": "3609520"
  },
  {
    "text": "be calibrated and also allow us\nto predict model uncertainty.",
    "start": "3609520",
    "end": "3614820"
  },
  {
    "text": "OK, so then what do\nwe do about this. OK, so here we go again.",
    "start": "3614820",
    "end": "3620589"
  },
  {
    "text": "Why pick just one model when\nwe can maintain a distribution over all possible models.",
    "start": "3620590",
    "end": "3626680"
  },
  {
    "text": "And so again, we're going to\ntake a Bayesian approach here. And the idea is\nthat basically there",
    "start": "3626680",
    "end": "3633460"
  },
  {
    "text": "are many possible models that\nwe could use to fit this data.",
    "start": "3633460",
    "end": "3638570"
  },
  {
    "text": "So all of these models\nhere actually fit this data pretty well, but they\nlook quite different",
    "start": "3638570",
    "end": "3643790"
  },
  {
    "text": "in this region in\nthe middle here, which indicates to us that we\nhave high model uncertainty",
    "start": "3643790",
    "end": "3649160"
  },
  {
    "text": "in this region in the middle. And so the way we're\ngoing to define",
    "start": "3649160",
    "end": "3654680"
  },
  {
    "text": "this is we're going\nto say that there's a distribution over\npossible models that could have\ngenerated this data.",
    "start": "3654680",
    "end": "3661120"
  },
  {
    "text": "And we're going to\ncall that P theta given D, where theta is the parameters\nof the model that could have",
    "start": "3661120",
    "end": "3667490"
  },
  {
    "text": "been used to generate the data. And then when we want to make\na prediction over a new point,",
    "start": "3667490",
    "end": "3673710"
  },
  {
    "text": "we're going to use\nthis expression here, where we say the probability\nof the output given the input",
    "start": "3673710",
    "end": "3680960"
  },
  {
    "text": "and all possible\nmodels basically is going to be the integral\nover all possible models",
    "start": "3680960",
    "end": "3689090"
  },
  {
    "text": "of the probability of the\noutput given a specific model. So if we knew our model was\ngiven by the parameters theta,",
    "start": "3689090",
    "end": "3697230"
  },
  {
    "text": "what would be the probability\nthat we got that data point, times the probability of\nthat specific model given",
    "start": "3697230",
    "end": "3704070"
  },
  {
    "text": "the data that we have. So this is a Bayesian approach.",
    "start": "3704070",
    "end": "3709799"
  },
  {
    "text": "And specifically this technique\nis called Bayesian model averaging. So all we're doing\nis we're saying",
    "start": "3709800",
    "end": "3714869"
  },
  {
    "text": "there's lots of models\nthat can fit this data. And so we're not just\ngoing to pick one. Instead we're going to average\nover all possible models",
    "start": "3714870",
    "end": "3722700"
  },
  {
    "text": "to get our output.  But as you might imagine,\nthere's an integral here,",
    "start": "3722700",
    "end": "3730030"
  },
  {
    "text": "and we're integrating\nover all possible models. That feels like it's\npretty intractable. And it turns out\nlike in general,",
    "start": "3730030",
    "end": "3735455"
  },
  {
    "text": "performing this\ncomputation is intractable. And so one thing that we\ncould try to do instead",
    "start": "3735455",
    "end": "3743010"
  },
  {
    "text": "is use MCMC to draw samples\nof theta given our data.",
    "start": "3743010",
    "end": "3748170"
  },
  {
    "text": "But you could imagine\nsometimes theta is like the parameters of\nan entire neural network. And so people have explored ways\nto try to do MCMC like this.",
    "start": "3748170",
    "end": "3756250"
  },
  {
    "text": "But in general,\nit's quite difficult to also do this MCMC, and\nthat could even be intractable",
    "start": "3756250",
    "end": "3762550"
  },
  {
    "text": "depending on the model class\nthat we're interested in. OK, so what do we\nactually do about this.",
    "start": "3762550",
    "end": "3770050"
  },
  {
    "text": "It turns out one thing\nthat tends to work really well in practice is that we just\napply approximate Bayesian model",
    "start": "3770050",
    "end": "3778000"
  },
  {
    "text": "averaging by creating\nan ensemble of models, so we'll call that\nthis fancy M here,",
    "start": "3778000",
    "end": "3784390"
  },
  {
    "text": "that all have high likelihood. Likelihood according\nto P theta given D.",
    "start": "3784390",
    "end": "3789520"
  },
  {
    "text": "So like all those models\nthat I was showing on the previous slide,\nthey all fit the data well, so they would all have\nhigh likelihood according",
    "start": "3789520",
    "end": "3795520"
  },
  {
    "text": "to this probability\ndistribution. And then we just\napproximate the integral by basically averaging over all\nof the models in our ensemble.",
    "start": "3795520",
    "end": "3803073"
  },
  {
    "text": " So what this looks like\nis like maybe one way",
    "start": "3803073",
    "end": "3808540"
  },
  {
    "text": "to do this is we just start like\nwe're training a neural network or something, for example. And we just start with a\ndifferent initialization,",
    "start": "3808540",
    "end": "3815550"
  },
  {
    "text": "perform our optimization. And hopefully that puts us in\nbasically different local minima",
    "start": "3815550",
    "end": "3821119"
  },
  {
    "text": "of our loss function. And so then we end\nup with a whole bunch of models that have this high P\ntheta given D or low negative P",
    "start": "3821120",
    "end": "3829790"
  },
  {
    "text": "theta given D, and then we\nget this kind of distribution",
    "start": "3829790",
    "end": "3834860"
  },
  {
    "text": "over possible models. And then we could know here by\ntaking the average of our models that we have high output\nhigh model uncertainty.",
    "start": "3834860",
    "end": "3843770"
  },
  {
    "text": "Yeah. I feel like one place\nwhere this also comes up, maybe even more naturally\nis in the Gaussian process,",
    "start": "3843770",
    "end": "3850310"
  },
  {
    "text": "and how we were planning\nto talk about it, but I think maybe\nmany people know it. And it's an even more\nnatural application",
    "start": "3850310",
    "end": "3857095"
  },
  {
    "text": "of this, where\nyou just basically have a prior uncertainty\nthat's quite large. And then only if you're kind of\ncertain about the uncertainty",
    "start": "3857095",
    "end": "3865910"
  },
  {
    "text": "kind of reduces. And I feel like\nthis would be also. So I actually generated this\nfigure using a Gaussian.",
    "start": "3865910",
    "end": "3871590"
  },
  {
    "text": "Ahah. Don't tell anyone. But yeah, I think\nthe one challenge",
    "start": "3871590",
    "end": "3876770"
  },
  {
    "text": "there is like Gaussian\nprocesses tend to not scale super well to higher dimensions,\nsuper high dimensional things.",
    "start": "3876770",
    "end": "3883670"
  },
  {
    "text": "So that's like-- But they're\nsupernaturally encoded the ideas of the\nmodel uncertainty and the aleatoric\nuncertainty kind of.",
    "start": "3883670",
    "end": "3890810"
  },
  {
    "text": "[INAUDIBLE] Sure, sure. Yeah, good point.",
    "start": "3890810",
    "end": "3896180"
  },
  {
    "text": "Which is why it was\nvery easy to generate this figure using [INAUDIBLE]. Yeah.",
    "start": "3896180",
    "end": "3902330"
  },
  {
    "text": "So I have a question for the\nfigure on the bottom left.",
    "start": "3902330",
    "end": "3907550"
  },
  {
    "text": "It seems that as your, say,\nyour loss function becomes more convex, then this\nbecomes more difficult.",
    "start": "3907550",
    "end": "3916700"
  },
  {
    "text": "Because you're more likely\nfor your ensembles to collapse those same parameters.",
    "start": "3916700",
    "end": "3922890"
  },
  {
    "text": "So then are you still\nable to use ensembles? In some sense, how would you\nget the parts of your ensemble",
    "start": "3922890",
    "end": "3931880"
  },
  {
    "text": "to be sufficient [INAUDIBLE]? Yeah, that's a great question. I'm going to show an example\nof that in a couple of slides.",
    "start": "3931880",
    "end": "3937090"
  },
  {
    "text": "But to answer your question\nabout how to address it, I won't really talk about that. there's various--\nI think there's",
    "start": "3937090",
    "end": "3943890"
  },
  {
    "text": "something called randomized\nprior functions or something. Basically if you're training\nlike an ensemble of networks,",
    "start": "3943890",
    "end": "3950380"
  },
  {
    "text": "you first train them to\nrepresent different functions or in the loss, you have them\nrepresent different functions.",
    "start": "3950380",
    "end": "3956470"
  },
  {
    "text": "But then in the spot\nwhere your data is, it should collapse to\nthe thing that you want. So there's various ways\nto try to encourage",
    "start": "3956470",
    "end": "3963030"
  },
  {
    "text": "this extra diversity in the\nmodels in your ensemble. You could also try different\nmodel architectures.",
    "start": "3963030",
    "end": "3969369"
  },
  {
    "text": "So that they're less likely to\nhave some common local minima. But in general,\nit's like something",
    "start": "3969370",
    "end": "3975540"
  },
  {
    "text": "you have to worry about. So yeah. Yeah. If your data is entirely\nconvex or quite convex,",
    "start": "3975540",
    "end": "3983350"
  },
  {
    "text": "your true data, then,\nthis is not a problem, because if it's true, your\nmodel will fit super duper well.",
    "start": "3983350",
    "end": "3990660"
  },
  {
    "text": "Yeah, I guess if there's\none global minima-- None of this is\nactually [INAUDIBLE]",
    "start": "3990660",
    "end": "3995820"
  },
  {
    "text": "--then you're OK. Yeah. Yeah. I would say typically that's\nnot the case, but yeah. ",
    "start": "3995820",
    "end": "4002990"
  },
  {
    "text": "Any other questions. ",
    "start": "4002990",
    "end": "4010430"
  },
  {
    "text": "OK. Just to give another example. We could do this also for\nclassification models.",
    "start": "4010430",
    "end": "4016620"
  },
  {
    "text": "So let's say that we\nwanted to train a model to predict the action that's\ntaken in all of the states",
    "start": "4016620",
    "end": "4022970"
  },
  {
    "text": "that we have for\nour continuum world. We could train an\nensemble to do that.",
    "start": "4022970",
    "end": "4028290"
  },
  {
    "text": "And then, for example, in\nareas where we have no data, it should average out to a\nmodel that basically just has",
    "start": "4028290",
    "end": "4034940"
  },
  {
    "text": "equal probability for all\nof the different actions. And then where we do\nhave lots of data,",
    "start": "4034940",
    "end": "4040590"
  },
  {
    "text": "then we get very certain\nwhich action we think we're going to take. ",
    "start": "4040590",
    "end": "4050730"
  },
  {
    "text": "OK. So yeah, to get back to\nthe question we just had.",
    "start": "4050730",
    "end": "4057060"
  },
  {
    "text": "A problem to watch out\nfor with ensembles, so we hope that this\nhappens, they end up in a whole bunch of\ndifferent local minima,",
    "start": "4057060",
    "end": "4062380"
  },
  {
    "text": "but there's not\nnecessarily any reason to say that this couldn't\nhappen where they all end up in the same local\nminima and then",
    "start": "4062380",
    "end": "4068022"
  },
  {
    "text": "they all just collapse\nto the same thing. And then there was\na few minutes ago, they're going to\nbe very confidently",
    "start": "4068022",
    "end": "4073200"
  },
  {
    "text": "wrong about you know. Sorry, Robert, just\nboosting your confidence",
    "start": "4073200",
    "end": "4078372"
  },
  {
    "text": "before your defense.  So yeah, this could happen.",
    "start": "4078372",
    "end": "4083800"
  },
  {
    "text": "And it's actually happened to\nme when I applied ensembles in my research. They're all wrong in the\nsame way on some data points.",
    "start": "4083800",
    "end": "4090250"
  },
  {
    "text": "And then yeah, it's something\nthat you risk there. So in general, you should try\nto ensure sufficient diversity.",
    "start": "4090250",
    "end": "4098469"
  },
  {
    "text": "I think in the book we do cite\none paper about how to do this. But in general, yeah, this\nis an area of research",
    "start": "4098470",
    "end": "4104412"
  },
  {
    "text": "that people have looked into.  OK, so I think we're about\ngoing to make it here.",
    "start": "4104412",
    "end": "4112009"
  },
  {
    "text": "So the next thing-- So we've determined-- So\nhere's how I would see this",
    "start": "4112010",
    "end": "4117068"
  },
  {
    "text": "being deployed on a system. One thing we do is\nwe determine if we're in the operational\ndesign domain.",
    "start": "4117069",
    "end": "4123049"
  },
  {
    "text": "So that's kind of the\nfirst check that we have. Are we even operating in the\nregion that we validated over.",
    "start": "4123050",
    "end": "4129939"
  },
  {
    "text": "Then maybe we try to\nquantify our uncertainty within that region. Model uncertainty, I\nwould actually still categorize with point number\n1 a little bit as well.",
    "start": "4129939",
    "end": "4139329"
  },
  {
    "text": "But then let's say, OK, we're\ngood with our uncertainty. We know we're in our\noperational design domain.",
    "start": "4139330",
    "end": "4145640"
  },
  {
    "text": "But we just did a whole\nbunch of offline validation and we found that failures\ndo still sometimes happen within our\noperational design domain.",
    "start": "4145640",
    "end": "4152389"
  },
  {
    "text": "So even though we\nknow that we're in this region that we validated\nover, that we trained on, we still might\nfail, and we might",
    "start": "4152390",
    "end": "4158290"
  },
  {
    "text": "want to monitor for\nthat along the way. And so that's basically the\nidea behind failure monitoring,",
    "start": "4158290",
    "end": "4164469"
  },
  {
    "text": "is that we've determined\nthat we are operating within the operational\ndesign domain, but we still could potentially\nbe in a dangerous scenario.",
    "start": "4164470",
    "end": "4171288"
  },
  {
    "text": "But the difference here\nis that we know about it, because we've done\nthis validation and we know where these\nfailures might occur.",
    "start": "4171288",
    "end": "4178399"
  },
  {
    "text": "So there's various things\nthat we could do here. Basically simplest\nthing you could do is you could just like run a\nbunch of offline validation",
    "start": "4178399",
    "end": "4185960"
  },
  {
    "text": "algorithms online. So you could just like\nrun reachability analysis online from the exact\nstate that you're at.",
    "start": "4185960",
    "end": "4192479"
  },
  {
    "text": "You could do a bunch\nof rollouts online from the state that\nyou're at and try to get an estimate of the\nprobability of failure.",
    "start": "4192479",
    "end": "4198210"
  },
  {
    "text": "Obviously, these are things\nthat could potentially be computationally\nexpensive, so it might be difficult to do at runtime.",
    "start": "4198210",
    "end": "4204180"
  },
  {
    "text": "But these are things\nthat you could do. Another thing you\ncould do is say you calculated the\nprobability of failure",
    "start": "4204180",
    "end": "4210890"
  },
  {
    "text": "from all of your\nstates offline, maybe using the probabilistic\nreachability analysis we talked about.",
    "start": "4210890",
    "end": "4217200"
  },
  {
    "text": "And so now we have this idea\nof probability of failure. Given our current state, if we\nwere in any of these red states,",
    "start": "4217200",
    "end": "4223740"
  },
  {
    "text": "we would have a high\nprobability of failure. And then we can just\nstore that online",
    "start": "4223740",
    "end": "4229520"
  },
  {
    "text": "and monitor whether\nwe're entering into any regions or\nstates where we have a high probability of failure.",
    "start": "4229520",
    "end": "4236659"
  },
  {
    "text": "And so then maybe we would\njust monitor this as we go.",
    "start": "4236660",
    "end": "4242150"
  },
  {
    "text": "This is a good animation\nto end on right. I'll play it one more time. Here we go. [LAUGHTER]",
    "start": "4242150",
    "end": "4247975"
  },
  {
    "text": " It's actually flying\ninto another plane. But yeah. [LAUGHTER]",
    "start": "4247975",
    "end": "4253041"
  },
  {
    "text": " All right, one more\ntime, one more time. [LAUGHTER]",
    "start": "4253041",
    "end": "4259486"
  },
  {
    "text": " OK. OK, cool. Any questions on\nfailure monitoring?",
    "start": "4259486",
    "end": "4266640"
  },
  {
    "text": "There's more in the\nbook about this. I'm just talking\nabout it briefly. ",
    "start": "4266640",
    "end": "4274050"
  },
  {
    "text": "OK. [INAUDIBLE] one thing that from\na computer vision standpoint, all computer vision\nsystems that have deployed,",
    "start": "4274050",
    "end": "4280230"
  },
  {
    "text": "we would very frequently do\nTTA, is what it's called. It's specifically in\nthe computer vision",
    "start": "4280230",
    "end": "4285659"
  },
  {
    "text": "literature [INAUDIBLE] logs. And it's covered a\nlittle bit, but I'm not looking at the probability.",
    "start": "4285660",
    "end": "4291880"
  },
  {
    "text": "It's usually for\ndetection and it's post. So provided it's\nabove 0.5 probability,",
    "start": "4291880",
    "end": "4297580"
  },
  {
    "text": "the bounding box is 0.5,\nthen I would keep it. And if I do [? odds ?] to the\nimage and the thing goes away,",
    "start": "4297580",
    "end": "4308350"
  },
  {
    "text": "or if it's still there, the box\ngoes away or it's still there or it changes, then\nthat's uncertainty. So it's the variance in the\noutput, not the absolute value",
    "start": "4308350",
    "end": "4318449"
  },
  {
    "text": "of the variance like\nthe absolute value. And so-- You would like augment the\nimage in a few different ways",
    "start": "4318450",
    "end": "4325650"
  },
  {
    "text": "or perturb it, and then-- And this is done all the\ntime in self-driving.",
    "start": "4325650",
    "end": "4331060"
  },
  {
    "text": "So you'll run on 100\nversions of every image, because your ConvNet is likely\nimplemented in firmware,",
    "start": "4331060",
    "end": "4338290"
  },
  {
    "text": "it's as fast as\npossible, especially FPN, like that's the\nbase for all models. And then you push\nit out and you'll",
    "start": "4338290",
    "end": "4345010"
  },
  {
    "text": "run 100 version logs of every\nsingle image, especially when you have exposure\nissues and all that stuff.",
    "start": "4345010",
    "end": "4353330"
  },
  {
    "text": "So that would be my only comment\nto that what did you call it.",
    "start": "4353330",
    "end": "4358730"
  },
  {
    "text": "You called it-- Bayesian model averaging? Yeah. No, no, no, it's\nnot model averaging.",
    "start": "4358730",
    "end": "4364000"
  },
  {
    "text": "Because the model\nstays constant. Yeah, yeah, it's more\nlike data averaging what you're describing. Yeah, you had a name\nfor it, but yeah.",
    "start": "4364000",
    "end": "4369700"
  },
  {
    "text": "Oh. I think that's like sensitivity. OK. Yeah, [INAUDIBLE]",
    "start": "4369700",
    "end": "4375250"
  },
  {
    "text": "It's sensitivity. Yeah, yeah. Well, that's interesting\nto know about.",
    "start": "4375250",
    "end": "4381400"
  },
  {
    "text": "OK, course wrap up. Here we go, guys. All right, so we\nstarted with this.",
    "start": "4381400",
    "end": "4388580"
  },
  {
    "text": "We talked about\nin other courses. You mess around a little bit. In this course, you're\ngoing to find out. So I hope you feel that you\nhave sufficiently found out now.",
    "start": "4388580",
    "end": "4397660"
  },
  {
    "text": "Or maybe with the project\nthree and the final project, you'll feel that way. We talked about lots\nof different methods",
    "start": "4397660",
    "end": "4403850"
  },
  {
    "text": "for validating systems, all\nthe way from failure analysis, formal guarantees,\nexplanations, and then",
    "start": "4403850",
    "end": "4409190"
  },
  {
    "text": "today we just talked\nabout what to do when you deploy the system at runtime. But hopefully you\nnoticed that there",
    "start": "4409190",
    "end": "4415040"
  },
  {
    "text": "was kind of holes in all\nof these various methods. There were limitations\nthat we talked through",
    "start": "4415040",
    "end": "4420230"
  },
  {
    "text": "as we were going through\nall of these methods. But again, with the\nSwiss cheese model, the idea is that these holes\nor limitations hopefully",
    "start": "4420230",
    "end": "4427310"
  },
  {
    "text": "don't line up. And so if we can apply\nenough of them at once, we can build a safety case.",
    "start": "4427310",
    "end": "4432530"
  },
  {
    "text": "So I just want to remind you\nthat there's no silver bullet here in safety validation. We need to build a safety case.",
    "start": "4432530",
    "end": "4438540"
  },
  {
    "text": "And hopefully this course\ngave you a good starting point for how to do this. And there's lots\nof open questions",
    "start": "4438540",
    "end": "4445670"
  },
  {
    "text": "that maybe have even\ncome up during lecture that still need to be solved for\nall of these various techniques.",
    "start": "4445670",
    "end": "4451377"
  },
  {
    "text": "So if you're interested, I\nthink it's a really good area of research to go into. And so there's lots of\nresearch you can do.",
    "start": "4451377",
    "end": "4457949"
  },
  {
    "text": "And hopefully also these\nwill be helpful tools as you go into industry.",
    "start": "4457950",
    "end": "4463820"
  },
  {
    "text": "OK, so thank you all\nso much for being part of this first\nedition of this course.",
    "start": "4463820",
    "end": "4469200"
  },
  {
    "text": "I've had so much fun doing\nthese lectures with you and seeing all of your\nquestions that you have, and all the projects\nthat you've done.",
    "start": "4469200",
    "end": "4476300"
  },
  {
    "text": "It's been a super\ngreat time for me, so I really appreciate\nyou tagging along for the first edition.",
    "start": "4476300",
    "end": "4482630"
  },
  {
    "text": "Definitely stay in\ntouch and reach out if you ever need anything,\nvalidation or otherwise. You have my email.",
    "start": "4482630",
    "end": "4489000"
  },
  {
    "text": "Super happy to keep in touch. And I just want to wrap up\nby saying that sometimes you",
    "start": "4489000",
    "end": "4495140"
  },
  {
    "text": "might find out in not\nthe best way possible, and you might find yourself\nknocked down a little bit.",
    "start": "4495140",
    "end": "4501469"
  },
  {
    "text": "But if you do find\nyourself in that situation, I hope that you will laugh\nit off and get back up",
    "start": "4501470",
    "end": "4507470"
  },
  {
    "text": "and take another swing at it. So Yay. [APPLAUSE]",
    "start": "4507470",
    "end": "4515680"
  },
  {
    "start": "4515680",
    "end": "4521000"
  }
]
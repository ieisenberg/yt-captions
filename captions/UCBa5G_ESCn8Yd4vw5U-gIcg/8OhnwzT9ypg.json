[
  {
    "start": "0",
    "end": "24000"
  },
  {
    "text": "Uh, hi, everyone. My name's Jiaxuan,",
    "start": "4340",
    "end": "6855"
  },
  {
    "text": "and I'm the head TA of this course.",
    "start": "6855",
    "end": "8835"
  },
  {
    "text": "And really an amazing experience to work",
    "start": "8835",
    "end": "11490"
  },
  {
    "text": "with you guys and I hope you learn a lot from the course.",
    "start": "11490",
    "end": "14160"
  },
  {
    "text": "Uh, today I'm excited to present, uh,",
    "start": "14160",
    "end": "16529"
  },
  {
    "text": "my recent, uh, research, Design Space of Graph Neural Networks.",
    "start": "16530",
    "end": "19850"
  },
  {
    "text": "[NOISE] So in this lecture,",
    "start": "19850",
    "end": "24270"
  },
  {
    "start": "24000",
    "end": "90000"
  },
  {
    "text": "uh, we cover some key questions for GNN design.",
    "start": "24270",
    "end": "27485"
  },
  {
    "text": "Uh, specifically, we want to answer how to",
    "start": "27485",
    "end": "30320"
  },
  {
    "text": "find a good GNN design for a specific GNN task.",
    "start": "30320",
    "end": "33410"
  },
  {
    "text": "Uh, this problem is really important, but also challenging, uh,",
    "start": "33410",
    "end": "37285"
  },
  {
    "text": "because domain experts want to use state-of-art GNN on their specific task.",
    "start": "37285",
    "end": "42665"
  },
  {
    "text": "However, there are tons of possible GNN architectures.",
    "start": "42665",
    "end": "46640"
  },
  {
    "text": "Uh, for example, in this lecture,",
    "start": "46640",
    "end": "48350"
  },
  {
    "text": "we have covered GCN,",
    "start": "48350",
    "end": "49594"
  },
  {
    "text": "GraphSAGE, GAT, GIN, etc.",
    "start": "49595",
    "end": "51740"
  },
  {
    "text": "Uh, the issue here is that",
    "start": "51740",
    "end": "54275"
  },
  {
    "text": "the best GNN design in one task can perform badly for another task.",
    "start": "54275",
    "end": "59110"
  },
  {
    "text": "And redo the hyperparameter grid search for each new task is not feasible.",
    "start": "59110",
    "end": "63590"
  },
  {
    "text": "And I'm sure you have some hands-on experience in your, uh,",
    "start": "63590",
    "end": "66895"
  },
  {
    "text": "final project and, you know,",
    "start": "66895",
    "end": "68450"
  },
  {
    "text": "tuning the hyperparameter of GNNs is notoriously hard.",
    "start": "68450",
    "end": "71469"
  },
  {
    "text": "Uh, In this lecture, our, uh,",
    "start": "71470",
    "end": "74085"
  },
  {
    "text": "key contribution in this work is that",
    "start": "74085",
    "end": "76280"
  },
  {
    "text": "the first systematic study for a GNN design space and task space.",
    "start": "76280",
    "end": "80065"
  },
  {
    "text": "And in addition, we also released the called platform GraphGym,",
    "start": "80065",
    "end": "83520"
  },
  {
    "text": "uh, which is a powerful platform for exploring different GNN designs and tasks.",
    "start": "83520",
    "end": "87679"
  },
  {
    "text": "[NOISE] Uh, to begin,",
    "start": "87680",
    "end": "91500"
  },
  {
    "start": "90000",
    "end": "147000"
  },
  {
    "text": "we first introduce the terminology that we'll use in this, uh, lecture.",
    "start": "91500",
    "end": "94940"
  },
  {
    "text": "Um, so a design means a concrete model instantiation.",
    "start": "94940",
    "end": "99055"
  },
  {
    "text": "For example, a four-layer GraphSAGE is a specific design.",
    "start": "99055",
    "end": "103265"
  },
  {
    "text": "Design dimensions characterize a design.",
    "start": "103265",
    "end": "106055"
  },
  {
    "text": "For example, a design dimension could be the number of layers,",
    "start": "106055",
    "end": "109655"
  },
  {
    "text": "L, which could take values among 4,",
    "start": "109655",
    "end": "112220"
  },
  {
    "text": "uh, 2, 4, 6, 8.",
    "start": "112220",
    "end": "114385"
  },
  {
    "text": "And design choice is the actual selective value in the design dimensions.",
    "start": "114385",
    "end": "119255"
  },
  {
    "text": "For example, the number of layers, L equals 2.",
    "start": "119255",
    "end": "122329"
  },
  {
    "text": "Design space, uh, consists of a Cartesian product of",
    "start": "122330",
    "end": "125990"
  },
  {
    "text": "all the design dimensions relate to enumerate all the possible designs within the space.",
    "start": "125990",
    "end": "131330"
  },
  {
    "text": "A task is the, a- a- a specific type of interest,",
    "start": "131330",
    "end": "134375"
  },
  {
    "text": "which could be, for example,",
    "start": "134375",
    "end": "135890"
  },
  {
    "text": "uh, node classification on Cora data set,",
    "start": "135890",
    "end": "138140"
  },
  {
    "text": "graph classification on ENZYMES data set.",
    "start": "138140",
    "end": "140690"
  },
  {
    "text": "And the task space consists of all the tasks that we care about.",
    "start": "140690",
    "end": "145560"
  },
  {
    "text": "And in this paper we introduced the notion of GNN design space,",
    "start": "146870",
    "end": "150840"
  },
  {
    "start": "147000",
    "end": "303000"
  },
  {
    "text": "and actually, we have, uh,",
    "start": "150840",
    "end": "152144"
  },
  {
    "text": "go into much deta- detail in the previous lecture,",
    "start": "152145",
    "end": "154845"
  },
  {
    "text": "so here we'll just do a quick recap.",
    "start": "154845",
    "end": "156900"
  },
  {
    "text": "Uh, so in the d- GNN design space,",
    "start": "156900",
    "end": "159930"
  },
  {
    "text": "we consider first, uh,",
    "start": "159930",
    "end": "161310"
  },
  {
    "text": "the intra-layer, uh, design.",
    "start": "161310",
    "end": "163245"
  },
  {
    "text": "And we have introduced that a GNN layer can be understood as,",
    "start": "163245",
    "end": "167060"
  },
  {
    "text": "uh, two parts, the transformation function,",
    "start": "167060",
    "end": "169819"
  },
  {
    "text": "and the aggregation function.",
    "start": "169820",
    "end": "171625"
  },
  {
    "text": "And, uh, here we propose a general instantiation under this perspective.",
    "start": "171625",
    "end": "176230"
  },
  {
    "text": "So concretely, it contains four different dimensions.",
    "start": "176230",
    "end": "179700"
  },
  {
    "text": "Uh, so we have, uh,",
    "start": "179700",
    "end": "181444"
  },
  {
    "text": "whether to add BatchNorm,",
    "start": "181445",
    "end": "183080"
  },
  {
    "text": "uh, whether to add dropout,",
    "start": "183080",
    "end": "184490"
  },
  {
    "text": "uh, the exact selection of the acti- activation function,",
    "start": "184490",
    "end": "188120"
  },
  {
    "text": "and the selection of the aggregation function.",
    "start": "188120",
    "end": "191370"
  },
  {
    "text": "Next, uh, we are going to design the inter-layer connectivity.",
    "start": "193430",
    "end": "198090"
  },
  {
    "text": "And the lecture, we have also introduced, uh,",
    "start": "198090",
    "end": "200750"
  },
  {
    "text": "different ways of organizing GNN layers.",
    "start": "200750",
    "end": "203635"
  },
  {
    "text": "And in- in this, uh, in this work, uh,",
    "start": "203635",
    "end": "205935"
  },
  {
    "text": "we consider adding some, uh,",
    "start": "205935",
    "end": "207735"
  },
  {
    "text": "pre-process layers and post-process layer,",
    "start": "207735",
    "end": "209760"
  },
  {
    "text": "uh, in addition to the GNN layers, uh,",
    "start": "209760",
    "end": "212700"
  },
  {
    "text": "which can, uh, jointly,",
    "start": "212700",
    "end": "214452"
  },
  {
    "text": "uh, form a complete graph neural network.",
    "start": "214452",
    "end": "217420"
  },
  {
    "text": "So the intuition of adding pre-process layer is that it could pretty important,",
    "start": "217420",
    "end": "222010"
  },
  {
    "text": "uh, when expressing node feature encoders are needed.",
    "start": "222010",
    "end": "225415"
  },
  {
    "text": "So for example, when our nodes are extracted from images or text,",
    "start": "225415",
    "end": "230269"
  },
  {
    "text": "we'll be consider using some, uh,",
    "start": "230270",
    "end": "231800"
  },
  {
    "text": "expressive, say, convolutional neural networks",
    "start": "231800",
    "end": "234095"
  },
  {
    "text": "or transformers to encode these node features.",
    "start": "234095",
    "end": "237490"
  },
  {
    "text": "And then we may also add",
    "start": "237490",
    "end": "239190"
  },
  {
    "text": "some post-process layer after applying graph neural network computation,",
    "start": "239190",
    "end": "243425"
  },
  {
    "text": "which are important when we are going to say",
    "start": "243425",
    "end": "246515"
  },
  {
    "text": "a reason or transformation over node embeddings.",
    "start": "246515",
    "end": "249685"
  },
  {
    "text": "And some example, uh, are, say, uh,",
    "start": "249685",
    "end": "252270"
  },
  {
    "text": "doing gra- graph classification,",
    "start": "252270",
    "end": "254125"
  },
  {
    "text": "or some applications around are not expressed.",
    "start": "254125",
    "end": "257680"
  },
  {
    "text": "And the core, uh,",
    "start": "257680",
    "end": "259440"
  },
  {
    "text": "core of the graph neural network are, uh, GNN layers.",
    "start": "259440",
    "end": "262950"
  },
  {
    "text": "And there we consider different strategies to add skip connections.",
    "start": "262950",
    "end": "267165"
  },
  {
    "text": "And we found that this really helps improve,",
    "start": "267165",
    "end": "269880"
  },
  {
    "text": "uh, deep GNNs performance.",
    "start": "269880",
    "end": "272380"
  },
  {
    "text": "Uh, then finally, we'll cover different learning configurations for GNNs.",
    "start": "273760",
    "end": "279615"
  },
  {
    "text": "And actually, this is often neglected,",
    "start": "279615",
    "end": "282270"
  },
  {
    "text": "uh, in current literature, uh,",
    "start": "282270",
    "end": "284099"
  },
  {
    "text": "but in practice, we found that",
    "start": "284100",
    "end": "285510"
  },
  {
    "text": "these learning configurations have high impact on- on a GNN's performance.",
    "start": "285510",
    "end": "289380"
  },
  {
    "text": "So specifically, we'll consider, uh,",
    "start": "289380",
    "end": "291275"
  },
  {
    "text": "the batch size, the learning rate,",
    "start": "291275",
    "end": "293625"
  },
  {
    "text": "the optimizer for gradient update,",
    "start": "293625",
    "end": "295350"
  },
  {
    "text": "and- and how many epochs do we train our models.",
    "start": "295350",
    "end": "299200"
  },
  {
    "text": "So in summary, uh,",
    "start": "301760",
    "end": "304005"
  },
  {
    "start": "303000",
    "end": "361000"
  },
  {
    "text": "we have proposed a general GNN design space that consist of,",
    "start": "304005",
    "end": "307350"
  },
  {
    "text": "uh intra-layer design, inter-layer design, and learning configuration.",
    "start": "307350",
    "end": "311175"
  },
  {
    "text": "And If you com, uh, consider all the possible combinations,",
    "start": "311175",
    "end": "314453"
  },
  {
    "text": "this really lead to a huge space,",
    "start": "314454",
    "end": "316185"
  },
  {
    "text": "so it contains, uh,",
    "start": "316185",
    "end": "317490"
  },
  {
    "text": "315,000 possible GNN designs.",
    "start": "317490",
    "end": "321180"
  },
  {
    "text": "And, um, to clarify,",
    "start": "321180",
    "end": "325259"
  },
  {
    "text": "our purpose here, uh,",
    "start": "325260",
    "end": "327175"
  },
  {
    "text": "is that we don't want to and what cannot cover",
    "start": "327175",
    "end": "330275"
  },
  {
    "text": "all the possible GNN designs because for example,",
    "start": "330275",
    "end": "333165"
  },
  {
    "text": "we can even add more, uh, design dimension,",
    "start": "333165",
    "end": "335430"
  },
  {
    "text": "say rather to add attention,",
    "start": "335430",
    "end": "337100"
  },
  {
    "text": "how many attention it has to use, and etc.",
    "start": "337100",
    "end": "339365"
  },
  {
    "text": "So this space is really a very- very huge.",
    "start": "339365",
    "end": "342565"
  },
  {
    "text": "So what we're trying to do is to propose a mindset transition.",
    "start": "342565",
    "end": "346100"
  },
  {
    "text": "So we want to demonstrate that studying",
    "start": "346100",
    "end": "348365"
  },
  {
    "text": "a design space is more effective than studying individual GNN designs,",
    "start": "348365",
    "end": "351860"
  },
  {
    "text": "such as, uh, uh, considering- only considering GraphSAGE,",
    "start": "351860",
    "end": "355009"
  },
  {
    "text": "GAT, those individual designs.",
    "start": "355010",
    "end": "357540"
  },
  {
    "text": "So after introducing the GNN design space,",
    "start": "359960",
    "end": "363495"
  },
  {
    "start": "361000",
    "end": "610000"
  },
  {
    "text": "we'll then introduce the GNN task space.",
    "start": "363495",
    "end": "365925"
  },
  {
    "text": "And we'll categorize GNN task,",
    "start": "365925",
    "end": "367935"
  },
  {
    "text": "uh, into different, uh, categories.",
    "start": "367935",
    "end": "370260"
  },
  {
    "text": "Um, so the common practice is to categorize GNN task into node classification,",
    "start": "370260",
    "end": "375455"
  },
  {
    "text": "edge, uh, prediction, and graph level prediction tasks.",
    "start": "375455",
    "end": "378115"
  },
  {
    "text": "And we have covered how do we do this in previous lectures.",
    "start": "378115",
    "end": "381680"
  },
  {
    "text": "Although this, uh, this technology is reasonable, it is not precise.",
    "start": "381680",
    "end": "385639"
  },
  {
    "text": "So for example, if we consider a node prediction and we could do say,",
    "start": "385640",
    "end": "390095"
  },
  {
    "text": "predict node clustering coefficient.",
    "start": "390095",
    "end": "392555"
  },
  {
    "text": "Another task could be, uh,",
    "start": "392555",
    "end": "394169"
  },
  {
    "text": "we will predict a node subject area in a citation network.",
    "start": "394170",
    "end": "397985"
  },
  {
    "text": "So although these tasks are all node classification, uh,",
    "start": "397985",
    "end": "401509"
  },
  {
    "text": "they are completely, uh, completely different in terms of their semantic meaning.",
    "start": "401510",
    "end": "405540"
  },
  {
    "text": "However, creating a precise taxono- ta-",
    "start": "405540",
    "end": "408825"
  },
  {
    "text": "taxonomy of GNN tasks is very hard because first, uh,",
    "start": "408825",
    "end": "412610"
  },
  {
    "text": "this is really subjective how you want to categorize different task,",
    "start": "412610",
    "end": "415569"
  },
  {
    "text": "and second there is normal GNN task can always merge and you cannot,",
    "start": "415570",
    "end": "419740"
  },
  {
    "text": "uh, uh, predict the future of the- the unknown, uh, GNN tasks.",
    "start": "419740",
    "end": "424625"
  },
  {
    "text": "So our innovation here is to propose a quantitative task similarity metric.",
    "start": "424625",
    "end": "429500"
  },
  {
    "text": "And our purpose here is to understand GNN task and, uh,",
    "start": "429500",
    "end": "434000"
  },
  {
    "text": "uh, uh result we can transfer the best GNN models across different tasks.",
    "start": "434000",
    "end": "439600"
  },
  {
    "text": "And- so here's a concrete,",
    "start": "441000",
    "end": "443200"
  },
  {
    "text": "uh, our innovation, uh,",
    "start": "443200",
    "end": "444475"
  },
  {
    "text": "where we propose, uh,",
    "start": "444475",
    "end": "445990"
  },
  {
    "text": "quantitative task similarity metric.",
    "start": "445990",
    "end": "448285"
  },
  {
    "text": "So to do this, uh, we will first select a notion called anchor models.",
    "start": "448285",
    "end": "453160"
  },
  {
    "text": "So here's a concrete example.",
    "start": "453160",
    "end": "454885"
  },
  {
    "text": "Suppose we want to, uh,",
    "start": "454885",
    "end": "456190"
  },
  {
    "text": "measure the similarity between tasks A, B,",
    "start": "456190",
    "end": "458590"
  },
  {
    "text": "and C, and then the anchor models are M_1 through M_5.",
    "start": "458590",
    "end": "463180"
  },
  {
    "text": "The second step is that we'll characterize a task by ranking the performance,",
    "start": "463180",
    "end": "468130"
  },
  {
    "text": "uh, of anchor models.",
    "start": "468130",
    "end": "469675"
  },
  {
    "text": "So here I say task A have the ranking of say, 1, 2, 3, 4, 5.",
    "start": "469675",
    "end": "473905"
  },
  {
    "text": "Task B have the ranking, uh,",
    "start": "473905",
    "end": "475480"
  },
  {
    "text": "which is different, which is a 1, 3, 2, 4, 5.",
    "start": "475480",
    "end": "478690"
  },
  {
    "text": "And task C again has another ranking",
    "start": "478690",
    "end": "481195"
  },
  {
    "text": "among the anchor models in terms of their performance.",
    "start": "481195",
    "end": "484615"
  },
  {
    "text": "And our argue-, uh, the key insight here is that, uh,",
    "start": "484615",
    "end": "488020"
  },
  {
    "text": "the task with simi- similarity rankings,",
    "start": "488020",
    "end": "491199"
  },
  {
    "text": "uh, similar rankings are considered as similar.",
    "start": "491200",
    "end": "494020"
  },
  {
    "text": "So for example, um,",
    "start": "494020",
    "end": "495479"
  },
  {
    "text": "here we can see the similarity between the rankings of,",
    "start": "495480",
    "end": "498925"
  },
  {
    "text": "uh, task A and task B is pretty high.",
    "start": "498925",
    "end": "501474"
  },
  {
    "text": "And the similarity between task A and C is pretty low.",
    "start": "501475",
    "end": "504835"
  },
  {
    "text": "And this way, we can give a quantitative measure between different- different tasks.",
    "start": "504835",
    "end": "510235"
  },
  {
    "text": "Uh, the next question is that how do we select the anchor models?",
    "start": "510235",
    "end": "514849"
  },
  {
    "text": "So more concretely, we will do, uh,",
    "start": "515270",
    "end": "518250"
  },
  {
    "text": "three steps to select the anchor models.",
    "start": "518250",
    "end": "520830"
  },
  {
    "text": "Uh, first, we'll pick a small dataset that it easy to work on.",
    "start": "520830",
    "end": "525225"
  },
  {
    "text": "And second, we'll randomly sample N models",
    "start": "525225",
    "end": "528345"
  },
  {
    "text": "from our design space and we'll run them on our dataset.",
    "start": "528345",
    "end": "531819"
  },
  {
    "text": "For example, we can sample 100 models,",
    "start": "531820",
    "end": "534100"
  },
  {
    "text": "uh, from our entire design space.",
    "start": "534100",
    "end": "536829"
  },
  {
    "text": "The third step is that we'll sort these models based on their performance and then we'll",
    "start": "536830",
    "end": "542095"
  },
  {
    "text": "evenly select M models as",
    "start": "542095",
    "end": "544120"
  },
  {
    "text": "the anchor models whose performance range from the worst to the best.",
    "start": "544120",
    "end": "547810"
  },
  {
    "text": "So for example, we have picked,",
    "start": "547810",
    "end": "549505"
  },
  {
    "text": "uh, random 100 models,",
    "start": "549505",
    "end": "551305"
  },
  {
    "text": "we will sort them by their performance and then say we'll pick the top model as",
    "start": "551305",
    "end": "555550"
  },
  {
    "text": "the first anchor set- anchor model and then set the 10th percentile,",
    "start": "555550",
    "end": "559839"
  },
  {
    "text": "uh, model as the second anchor model.",
    "start": "559840",
    "end": "562090"
  },
  {
    "text": "And then up to the worst model among 100 models.",
    "start": "562090",
    "end": "565630"
  },
  {
    "text": "And our goal here,",
    "start": "565630",
    "end": "567235"
  },
  {
    "text": "is really to come up with a wide spectrum of models.",
    "start": "567235",
    "end": "570745"
  },
  {
    "text": "And our integration is that a bad model in",
    "start": "570745",
    "end": "573339"
  },
  {
    "text": "one task could actually be great for another task.",
    "start": "573340",
    "end": "576175"
  },
  {
    "text": "And we have verified this,",
    "start": "576175",
    "end": "577735"
  },
  {
    "text": "uh, with our experiments results.",
    "start": "577735",
    "end": "580040"
  },
  {
    "text": "Contrarily, we co- can collect, uh,",
    "start": "580710",
    "end": "584050"
  },
  {
    "text": "32 tasks, uh, which are,",
    "start": "584050",
    "end": "586029"
  },
  {
    "text": "uh, nodes and graph classification tasks.",
    "start": "586030",
    "end": "588115"
  },
  {
    "text": "And we have six real-world node classification tasks, uh,",
    "start": "588115",
    "end": "591220"
  },
  {
    "text": "12 synthetic node classification tasks, uh,",
    "start": "591220",
    "end": "593709"
  },
  {
    "text": "including a predicting node clustering coefficient, and node PageRank.",
    "start": "593710",
    "end": "598165"
  },
  {
    "text": "And then we also have six real-world graph classification tasks",
    "start": "598165",
    "end": "601555"
  },
  {
    "text": "and eight synthetic graph classification tasks,",
    "start": "601555",
    "end": "603940"
  },
  {
    "text": "uh, including, uh, predicting graph average path lengths.",
    "start": "603940",
    "end": "608150"
  },
  {
    "text": "The final topic we will cover is that having defined, uh,",
    "start": "609060",
    "end": "612550"
  },
  {
    "start": "610000",
    "end": "767000"
  },
  {
    "text": "our GNN design space and task space,",
    "start": "612550",
    "end": "614635"
  },
  {
    "text": "how do we evaluate the GNN designs?",
    "start": "614635",
    "end": "616795"
  },
  {
    "text": "For example, we want to answer the question like, uh,",
    "start": "616795",
    "end": "619180"
  },
  {
    "text": "is graph- is BatchNorm generally useful for GNNs?",
    "start": "619180",
    "end": "623335"
  },
  {
    "text": "Um, here the common practice is just to pick one model,",
    "start": "623335",
    "end": "626905"
  },
  {
    "text": "for example, a five layer,",
    "start": "626905",
    "end": "628210"
  },
  {
    "text": "64-dimensional GCN, and compare two models,",
    "start": "628210",
    "end": "631360"
  },
  {
    "text": "uh, with or without BatchNorm.",
    "start": "631360",
    "end": "634225"
  },
  {
    "text": "Uh, our approach here is that,",
    "start": "634225",
    "end": "636190"
  },
  {
    "text": "uh, is more rigorous.",
    "start": "636190",
    "end": "637660"
  },
  {
    "text": "Uh, that is, uh,",
    "start": "637660",
    "end": "638740"
  },
  {
    "text": "we know that we have defined 300,000 models and 32 tasks,",
    "start": "638740",
    "end": "643240"
  },
  {
    "text": "and this data leads to, uh, uh,",
    "start": "643240",
    "end": "645550"
  },
  {
    "text": "about 10 million model-task combinations.",
    "start": "645550",
    "end": "648084"
  },
  {
    "text": "And what we are gonna do is to first sample from",
    "start": "648084",
    "end": "650620"
  },
  {
    "text": "the 10 million possible model-task combinations and we'll",
    "start": "650620",
    "end": "653680"
  },
  {
    "text": "rank the models with BatchNorm equals true or false.",
    "start": "653680",
    "end": "657385"
  },
  {
    "text": "The next question is that how do we make it scalable and convincing?",
    "start": "657385",
    "end": "660940"
  },
  {
    "text": "[NOISE] And more concretely,",
    "start": "660940",
    "end": "664870"
  },
  {
    "text": "our proposed approach called,",
    "start": "664870",
    "end": "666460"
  },
  {
    "text": "uh, controlled random search.",
    "start": "666460",
    "end": "668290"
  },
  {
    "text": "So the first step, is to sample",
    "start": "668290",
    "end": "670704"
  },
  {
    "text": "random model-task configurations from the entire design space.",
    "start": "670705",
    "end": "674185"
  },
  {
    "text": "And we perturb the BatchNorm equals true or false.",
    "start": "674185",
    "end": "677635"
  },
  {
    "text": "So for example, uh, we have different, uh,",
    "start": "677635",
    "end": "680320"
  },
  {
    "text": "uh, models with different,",
    "start": "680320",
    "end": "682000"
  },
  {
    "text": "uh, GNN designs, such as, uh,",
    "start": "682000",
    "end": "683470"
  },
  {
    "text": "ReLu activation, PReLu activation,",
    "start": "683470",
    "end": "686019"
  },
  {
    "text": "and different number of layers,",
    "start": "686020",
    "end": "687610"
  },
  {
    "text": "different la- layer connectivity and they're applied to different GNN tasks.",
    "start": "687610",
    "end": "691735"
  },
  {
    "text": "What we're going to do is that,",
    "start": "691735",
    "end": "693250"
  },
  {
    "text": "we will fix the all- the rest of design and task dimensions,",
    "start": "693250",
    "end": "696565"
  },
  {
    "text": "but only perturb its BatchNorm dimensions into true or false.",
    "start": "696565",
    "end": "700330"
  },
  {
    "text": "And in the meantime, we will control the computational budget for",
    "start": "700330",
    "end": "703540"
  },
  {
    "text": "all the models so that this comparison is really rigorous.",
    "start": "703540",
    "end": "707579"
  },
  {
    "text": "And then we will rank BatchNorm equals true or false by their performance.",
    "start": "707580",
    "end": "712500"
  },
  {
    "text": "Here, lower ranking is better.",
    "start": "712500",
    "end": "714290"
  },
  {
    "text": "So for example, we can see, okay, uh,",
    "start": "714290",
    "end": "716560"
  },
  {
    "text": "in one application BatchNorm equals true have validation accuracy of 0.75, uh,",
    "start": "716560",
    "end": "721510"
  },
  {
    "text": "but false with only, uh,",
    "start": "721510",
    "end": "723550"
  },
  {
    "text": "0.54, which means that BatchNorm equals true is better.",
    "start": "723550",
    "end": "727315"
  },
  {
    "text": "So it has a lower ranking of 1.",
    "start": "727315",
    "end": "729565"
  },
  {
    "text": "And sometimes there could be a tie because the two,",
    "start": "729565",
    "end": "732265"
  },
  {
    "text": "uh, choices are pretty close in terms of their performance.",
    "start": "732265",
    "end": "735504"
  },
  {
    "text": "The final step is to plot average or",
    "start": "735504",
    "end": "738430"
  },
  {
    "text": "distribution of the ranking of the BatchNorm equals true or false.",
    "start": "738430",
    "end": "741745"
  },
  {
    "text": "So for example, here we see the average ranking of the BatchNorm is true is lower,",
    "start": "741745",
    "end": "746320"
  },
  {
    "text": "which means that, uh, in general BatchNorm is equals true often provokes better.",
    "start": "746320",
    "end": "751390"
  },
  {
    "text": "So to summarize, um, here,",
    "start": "751390",
    "end": "753820"
  },
  {
    "text": "we really propose an approach to convincingly evaluate any new design dimensions.",
    "start": "753820",
    "end": "758410"
  },
  {
    "text": "And for example, we can use",
    "start": "758410",
    "end": "759910"
  },
  {
    "text": "the same strategy to evaluate a new GNN layer that we propose.",
    "start": "759910",
    "end": "764180"
  },
  {
    "text": "So here are the, uh, key results.",
    "start": "765930",
    "end": "768925"
  },
  {
    "start": "767000",
    "end": "877000"
  },
  {
    "text": "First, we will demonstrate a general guideline for GNN designs.",
    "start": "768925",
    "end": "772915"
  },
  {
    "text": "So, uh, we showed that certain design choices exhibit clear advantages.",
    "start": "772915",
    "end": "777339"
  },
  {
    "text": "So we'll first look at those intralayer designs.",
    "start": "777340",
    "end": "780130"
  },
  {
    "text": "Um, the first, uh, conclusion that,",
    "start": "780130",
    "end": "782470"
  },
  {
    "text": "uh, BatchNorm equals true, are generally better.",
    "start": "782470",
    "end": "785334"
  },
  {
    "text": "And our explanation is that GNNs are hard to optimize,",
    "start": "785335",
    "end": "789055"
  },
  {
    "text": "therefore, batch normalization can really help,",
    "start": "789055",
    "end": "791214"
  },
  {
    "text": "um, the gradient update.",
    "start": "791215",
    "end": "792895"
  },
  {
    "text": "And then we found that dropout equals 0,",
    "start": "792895",
    "end": "795580"
  },
  {
    "text": "which means no dropout is often better.",
    "start": "795580",
    "end": "797980"
  },
  {
    "text": "Because we found that GNNs actually experience",
    "start": "797980",
    "end": "800920"
  },
  {
    "text": "under fitting more often than over fitting.",
    "start": "800920",
    "end": "803440"
  },
  {
    "text": "So BatchNorm-, uh, sorry.",
    "start": "803440",
    "end": "805405"
  },
  {
    "text": "So our drop out doesn't-, uh, it doesn't help too much.",
    "start": "805405",
    "end": "809590"
  },
  {
    "text": "And then we found that, uh,",
    "start": "809590",
    "end": "811390"
  },
  {
    "text": "PRelu activation actually really stands out.",
    "start": "811390",
    "end": "814510"
  },
  {
    "text": "And this is our new findings in this paper and, ah,",
    "start": "814510",
    "end": "817795"
  },
  {
    "text": "versus the common practice of only using the ReLu activation.",
    "start": "817795",
    "end": "821725"
  },
  {
    "text": "And finally, we found that sum aggregation is always",
    "start": "821725",
    "end": "824410"
  },
  {
    "text": "better because we have explained in the lecture,",
    "start": "824410",
    "end": "827004"
  },
  {
    "text": "that sum is the most expressive agg- aggregator that we could have.",
    "start": "827005",
    "end": "831380"
  },
  {
    "text": "And then we'll go on to look at the inter-layer designs.",
    "start": "832860",
    "end": "836334"
  },
  {
    "text": "Um, first, we found that the optimal number of layers is really hard to decide.",
    "start": "836335",
    "end": "841300"
  },
  {
    "text": "You can see their rankings are pretty, uh, even.",
    "start": "841300",
    "end": "844209"
  },
  {
    "text": "And we argue that this is really highly dependent on the task that we have.",
    "start": "844210",
    "end": "849370"
  },
  {
    "text": "And also we find that, uh,",
    "start": "849370",
    "end": "851529"
  },
  {
    "text": "sk- skip connections can really enable",
    "start": "851530",
    "end": "854095"
  },
  {
    "text": "hierarchical node representation therefore is much desired.",
    "start": "854095",
    "end": "858379"
  },
  {
    "text": "And finally, we will look at the learning configurations.",
    "start": "859530",
    "end": "863200"
  },
  {
    "text": "We found that the optimal batch size and learning rate is also hard to decide.",
    "start": "863200",
    "end": "867460"
  },
  {
    "text": "And therefore it's highly dependent on the task.",
    "start": "867460",
    "end": "869980"
  },
  {
    "text": "And we found that the Adam optimizer and training more epochs are generally better.",
    "start": "869980",
    "end": "875570"
  },
  {
    "text": "The second key result is the understanding of GNN tasks.",
    "start": "876930",
    "end": "880945"
  },
  {
    "start": "877000",
    "end": "983000"
  },
  {
    "text": "First, we found that GNN designs in different tasks vary significantly.",
    "start": "880945",
    "end": "885535"
  },
  {
    "text": "So this motivates that studying the task space is really crucial.",
    "start": "885535",
    "end": "889764"
  },
  {
    "text": "So if we look at design,",
    "start": "889765",
    "end": "891580"
  },
  {
    "text": "um, tradeoff in different tasks,",
    "start": "891580",
    "end": "893645"
  },
  {
    "text": "like BZR proteins and smallworld,",
    "start": "893645",
    "end": "896200"
  },
  {
    "text": "sometimes max aggregation is better,",
    "start": "896200",
    "end": "897965"
  },
  {
    "text": "sometimes mean is better and sometimes sum is better.",
    "start": "897965",
    "end": "900680"
  },
  {
    "text": "And similarly for a number of layers,",
    "start": "900680",
    "end": "902555"
  },
  {
    "text": "sometimes a eight-layer is better,",
    "start": "902555",
    "end": "904370"
  },
  {
    "text": "sometimes two-layer is better, uh, and etc.",
    "start": "904370",
    "end": "908100"
  },
  {
    "text": "So this, uh, argues that our GNN task space is pretty helpful.",
    "start": "909360",
    "end": "914269"
  },
  {
    "text": "So what we're going to do is to compute pairwise similarities between all GNN tasks.",
    "start": "914270",
    "end": "919980"
  },
  {
    "text": "So, uh, recall how we compute GNN task.",
    "start": "919980",
    "end": "922769"
  },
  {
    "text": "We will measure the similarity based on anchor model performance.",
    "start": "922770",
    "end": "926210"
  },
  {
    "text": "And then, uh, the argument is that our task similarity computation is really cheap.",
    "start": "926210",
    "end": "931295"
  },
  {
    "text": "And we found that using 12-anchor models is already a good approximation.",
    "start": "931295",
    "end": "936510"
  },
  {
    "text": "And our key result is that the proposed GNN task space is pretty informative.",
    "start": "937980",
    "end": "943264"
  },
  {
    "text": "So we identify two group of GNN task.",
    "start": "943265",
    "end": "946410"
  },
  {
    "text": "Group A relies on feature information.",
    "start": "946410",
    "end": "949009"
  },
  {
    "text": "Uh, and these are some node cla- or graph",
    "start": "949010",
    "end": "951740"
  },
  {
    "text": "classification task where input graphs have high dimensional features.",
    "start": "951740",
    "end": "955535"
  },
  {
    "text": "And Group B, our task relies on structural information where nods have fewer of,",
    "start": "955535",
    "end": "961079"
  },
  {
    "text": "uh, features but predictions are highly dependent on the graph structure.",
    "start": "961080",
    "end": "966000"
  },
  {
    "text": "And then we'll do PCA and do dimension,",
    "start": "967470",
    "end": "971079"
  },
  {
    "text": "uh, reduction, uh, to visualize this in 2D space.",
    "start": "971080",
    "end": "974105"
  },
  {
    "text": "And indeed we verified that similar tasks can have similar best architecture designs.",
    "start": "974105",
    "end": "979889"
  },
  {
    "text": "And finally, we will go on to transfer,",
    "start": "982060",
    "end": "985040"
  },
  {
    "start": "983000",
    "end": "1064000"
  },
  {
    "text": "uh, our approach to novel task.",
    "start": "985040",
    "end": "987065"
  },
  {
    "text": "So here we conduct a case study that is to generalize",
    "start": "987065",
    "end": "989750"
  },
  {
    "text": "the best models to unseen OGB task and to,",
    "start": "989750",
    "end": "993445"
  },
  {
    "text": "uh, that the observation that the OGB, uh,",
    "start": "993445",
    "end": "995905"
  },
  {
    "text": "molecule, uh, prediction task is unique from other tasks.",
    "start": "995905",
    "end": "999380"
  },
  {
    "text": "So it's 20 times larger,",
    "start": "999380",
    "end": "1000850"
  },
  {
    "text": "highly imbalanced, and requires out-of-distribution generalization.",
    "start": "1000850",
    "end": "1004069"
  },
  {
    "text": "So this is really a novel task compared to the tasks that we have seen.",
    "start": "1004070",
    "end": "1007760"
  },
  {
    "text": "And here's a concrete step to apply our approach to a novel task.",
    "start": "1007760",
    "end": "1012015"
  },
  {
    "text": "So the first step is to measure 12,",
    "start": "1012015",
    "end": "1014290"
  },
  {
    "text": "uh, anchor model performance on a new task.",
    "start": "1014290",
    "end": "1017065"
  },
  {
    "text": "And then we're going to compute similarity between the new task and the existing task.",
    "start": "1017065",
    "end": "1021815"
  },
  {
    "text": "Finally, we'll recommend the best design",
    "start": "1021815",
    "end": "1024730"
  },
  {
    "text": "from the existing task with the highest similarity.",
    "start": "1024730",
    "end": "1028370"
  },
  {
    "text": "So here are the concrete results.",
    "start": "1028460",
    "end": "1030990"
  },
  {
    "text": "Um, so we'll pick two models,",
    "start": "1030990",
    "end": "1032880"
  },
  {
    "text": "uh, using our task similarity metric.",
    "start": "1032880",
    "end": "1035475"
  },
  {
    "text": "So task A is highly similar to OGB and task B are not similar to OGB.",
    "start": "1035475",
    "end": "1040275"
  },
  {
    "text": "And our finding is that transferring the best model from task A,",
    "start": "1040275",
    "end": "1044560"
  },
  {
    "text": "really achieves SOTA performance on OGB.",
    "start": "1044560",
    "end": "1047110"
  },
  {
    "text": "However, uh, transfer the best model from task B performs badly on OGB.",
    "start": "1047110",
    "end": "1051309"
  },
  {
    "text": "So this really, uh, illustrates that the proposed task metric is really helpful.",
    "start": "1051310",
    "end": "1056330"
  },
  {
    "text": "And our task space can really guide the best model transfer to node tasks.",
    "start": "1056330",
    "end": "1061880"
  },
  {
    "text": "To summarize- to summary,",
    "start": "1062870",
    "end": "1065430"
  },
  {
    "start": "1064000",
    "end": "1090000"
  },
  {
    "text": "uh, in this paper,",
    "start": "1065430",
    "end": "1066790"
  },
  {
    "text": "we proposed the first systematic investigation of general guidelines for GNN design.",
    "start": "1066790",
    "end": "1071875"
  },
  {
    "text": "And the understandings of GNN tasks as well",
    "start": "1071875",
    "end": "1074370"
  },
  {
    "text": "as transferring best GNN designs across tasks.",
    "start": "1074370",
    "end": "1076960"
  },
  {
    "text": "In addition, we also released GraphGym as an easy to use code platform for GNNs.",
    "start": "1076960",
    "end": "1081799"
  },
  {
    "text": "Uh, thank you for your attention.",
    "start": "1081800",
    "end": "1084730"
  }
]
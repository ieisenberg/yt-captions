[
  {
    "start": "0",
    "end": "4950"
  },
  {
    "text": "Welcome to the class.",
    "start": "4950",
    "end": "6450"
  },
  {
    "text": "Today we are going to\ndiscuss deep generative",
    "start": "6450",
    "end": "9090"
  },
  {
    "text": "models for graphs.",
    "start": "9090",
    "end": "10740"
  },
  {
    "text": "So let me explain\nthat in more detail.",
    "start": "10740",
    "end": "14380"
  },
  {
    "text": "So, so far we talked about how\nto classify nodes and edges",
    "start": "14380",
    "end": "19530"
  },
  {
    "text": "and perhaps entire graphs.",
    "start": "19530",
    "end": "21750"
  },
  {
    "text": "But now we are going to\ntalk about a new task, which",
    "start": "21750",
    "end": "24720"
  },
  {
    "text": "is the task of\ngenerating the graph.",
    "start": "24720",
    "end": "27119"
  },
  {
    "text": "The idea is that we want to\nhave a generative model that",
    "start": "27120",
    "end": "30240"
  },
  {
    "text": "is going to generate\na synthetic graph that",
    "start": "30240",
    "end": "33870"
  },
  {
    "text": "will be similar to\nthe real-world graph.",
    "start": "33870",
    "end": "38309"
  },
  {
    "text": "An application of this\ntype of graph generation",
    "start": "38310",
    "end": "42030"
  },
  {
    "text": "happens in many\ndifferent places.",
    "start": "42030",
    "end": "44399"
  },
  {
    "text": "You can imagine that you can\nrepresent molecules as graphs",
    "start": "44400",
    "end": "48480"
  },
  {
    "text": "of bonds between the atoms.",
    "start": "48480",
    "end": "51420"
  },
  {
    "text": "And then in this case,\nyou want to generate",
    "start": "51420",
    "end": "54059"
  },
  {
    "text": "novel molecular structures\nbased on this generative model.",
    "start": "54060",
    "end": "59400"
  },
  {
    "text": "Or for example in\nmaterial design,",
    "start": "59400",
    "end": "61540"
  },
  {
    "text": "you may want to generate\noptimal material structures",
    "start": "61540",
    "end": "65550"
  },
  {
    "text": "and this is what you can do.",
    "start": "65550",
    "end": "66870"
  },
  {
    "text": "In social network\nmodeling, you may",
    "start": "66870",
    "end": "68610"
  },
  {
    "text": "want to generate\nsynthetic social networks",
    "start": "68610",
    "end": "71530"
  },
  {
    "text": "so that you can then use\nthem for various kinds",
    "start": "71530",
    "end": "74760"
  },
  {
    "text": "of downstream tasks.",
    "start": "74760",
    "end": "76020"
  },
  {
    "text": "And even in some other\napplications for example,",
    "start": "76020",
    "end": "78460"
  },
  {
    "text": "if you think about generating\nrealistic road layouts.",
    "start": "78460",
    "end": "81930"
  },
  {
    "text": "If you want to think\nabout generating",
    "start": "81930",
    "end": "83820"
  },
  {
    "text": "realistic layouts of cities,\nall these types of things",
    "start": "83820",
    "end": "87585"
  },
  {
    "text": "you can model as a graph\ngeneration process.",
    "start": "87585",
    "end": "92100"
  },
  {
    "text": "And even for example, some\ncombinatorial problems",
    "start": "92100",
    "end": "95189"
  },
  {
    "text": "like the satisfiability problem\nor the Boolean satisfiability",
    "start": "95190",
    "end": "98820"
  },
  {
    "text": "problem, you can generate\nartificial instances",
    "start": "98820",
    "end": "102930"
  },
  {
    "text": "of that problem by representing\nthe satisfiability instance",
    "start": "102930",
    "end": "107040"
  },
  {
    "text": "as a graph and then learning\nhow to generate those graphs.",
    "start": "107040",
    "end": "111190"
  },
  {
    "text": "So in all of these\ncases basically,",
    "start": "111190",
    "end": "114370"
  },
  {
    "text": "the goal is that\nwe want to learn",
    "start": "114370",
    "end": "116130"
  },
  {
    "text": "how to generate a\ngraph that is somehow",
    "start": "116130",
    "end": "119909"
  },
  {
    "text": "similar to the underlying\nreal-world graph.",
    "start": "119910",
    "end": "124280"
  },
  {
    "text": "And the field of\ngraph generation",
    "start": "124280",
    "end": "127369"
  },
  {
    "text": "has a rich tradition.",
    "start": "127370",
    "end": "129919"
  },
  {
    "text": "And the way this\nstarted, it started",
    "start": "129919",
    "end": "131990"
  },
  {
    "text": "with the study of properties\nof complex networks",
    "start": "131990",
    "end": "135470"
  },
  {
    "text": "like real-world networks.",
    "start": "135470",
    "end": "138290"
  },
  {
    "text": "And identifying what are\nthe fundamental properties",
    "start": "138290",
    "end": "141620"
  },
  {
    "text": "that these real-world\nnetworks have",
    "start": "141620",
    "end": "143510"
  },
  {
    "text": "like power or scale-free\ndegree distributions",
    "start": "143510",
    "end": "148549"
  },
  {
    "text": "and also like the\nsmall world property",
    "start": "148550",
    "end": "151160"
  },
  {
    "text": "and so on and so forth.",
    "start": "151160",
    "end": "152750"
  },
  {
    "text": "Based on these fundamental\nproperties of complex networks,",
    "start": "152750",
    "end": "155870"
  },
  {
    "text": "then there have been\na lot of development",
    "start": "155870",
    "end": "159470"
  },
  {
    "text": "of generative models\nfor graphs, which",
    "start": "159470",
    "end": "162170"
  },
  {
    "text": "generally fell into two camps.",
    "start": "162170",
    "end": "165440"
  },
  {
    "text": "One camp was very\nmechanistic generative models",
    "start": "165440",
    "end": "169430"
  },
  {
    "text": "like the preferential attachment\nmodel, that basically allowed",
    "start": "169430",
    "end": "173780"
  },
  {
    "text": "us to explain how could\ncertain properties",
    "start": "173780",
    "end": "176240"
  },
  {
    "text": "like the scale-free\nproperty of networks",
    "start": "176240",
    "end": "178160"
  },
  {
    "text": "arise from this microscopic\npreferential attachment type",
    "start": "178160",
    "end": "181790"
  },
  {
    "text": "model.",
    "start": "181790",
    "end": "182780"
  },
  {
    "text": "Another set of models\nfor generating graphs,",
    "start": "182780",
    "end": "186530"
  },
  {
    "text": "came mostly from the statistics\nand the social networking",
    "start": "186530",
    "end": "190069"
  },
  {
    "text": "literature where basically, the\nidea was that there is maybe",
    "start": "190070",
    "end": "192950"
  },
  {
    "text": "some, that there might be\nsome latent social groups",
    "start": "192950",
    "end": "196190"
  },
  {
    "text": "and based on those\nlatent social groups,",
    "start": "196190",
    "end": "199520"
  },
  {
    "text": "edges of the social\nnetwork get created.",
    "start": "199520",
    "end": "201650"
  },
  {
    "text": "And then the question is,\nhow can you take that model,",
    "start": "201650",
    "end": "204019"
  },
  {
    "text": "fit it to the data and\nperhaps discover the groups?",
    "start": "204020",
    "end": "207990"
  },
  {
    "text": "However, today and\nin this lecture,",
    "start": "207990",
    "end": "211260"
  },
  {
    "text": "we are going to\nuse deep learning",
    "start": "211260",
    "end": "213170"
  },
  {
    "text": "and representation\nlearning to learn",
    "start": "213170",
    "end": "215420"
  },
  {
    "text": "how to generate the graphs.",
    "start": "215420",
    "end": "217020"
  },
  {
    "text": "So in contrast to prior work in\nsome sense that either assumed",
    "start": "217020",
    "end": "223050"
  },
  {
    "text": "some mechanistic\ngenerative process",
    "start": "223050",
    "end": "225180"
  },
  {
    "text": "or assumed some statistical\nmodel that was motivated",
    "start": "225180",
    "end": "228780"
  },
  {
    "text": "by the-- let's say\nsocial science, here",
    "start": "228780",
    "end": "231209"
  },
  {
    "text": "we want to be kind of\nagnostic in this respect.",
    "start": "231210",
    "end": "236220"
  },
  {
    "text": "And the goal will be that,\ncan we basically given a graph",
    "start": "236220",
    "end": "240240"
  },
  {
    "text": "or given a couple of graphs,\ncan we learn how to gene--",
    "start": "240240",
    "end": "243660"
  },
  {
    "text": "what the properties\nof those graphs are,",
    "start": "243660",
    "end": "245820"
  },
  {
    "text": "and how can we\ngenerate more instances",
    "start": "245820",
    "end": "248580"
  },
  {
    "text": "of those types of graphs?",
    "start": "248580",
    "end": "249970"
  },
  {
    "text": "So we'll be kind of\ncompletely general,",
    "start": "249970",
    "end": "252010"
  },
  {
    "text": "we'll just learn from the data\nin this kind of representation",
    "start": "252010",
    "end": "255269"
  },
  {
    "text": "learning framework.",
    "start": "255270",
    "end": "257440"
  },
  {
    "text": "So this is one way how\nwe can look into this.",
    "start": "257440",
    "end": "261180"
  },
  {
    "text": "Another way how we\ncan look into this",
    "start": "261180",
    "end": "262919"
  },
  {
    "text": "is that, so far in\nthis class we've",
    "start": "262920",
    "end": "265080"
  },
  {
    "text": "been talking about the deep\ngraph encoders, where basically",
    "start": "265080",
    "end": "267990"
  },
  {
    "text": "the idea was that, we have a\ncomplex network, complex graph,",
    "start": "267990",
    "end": "272160"
  },
  {
    "text": "complex relational\nstructure on the input",
    "start": "272160",
    "end": "274470"
  },
  {
    "text": "and you want to pass it\nthrough several layers",
    "start": "274470",
    "end": "277530"
  },
  {
    "text": "of this representation and\na deep learning network that",
    "start": "277530",
    "end": "282150"
  },
  {
    "text": "at the end produces-- let's\nsay node embeddings, edge",
    "start": "282150",
    "end": "285570"
  },
  {
    "text": "embeddings, entire\ngraph embeddings, right?",
    "start": "285570",
    "end": "288230"
  },
  {
    "text": "So this is what we call\na deep graph encoder",
    "start": "288230",
    "end": "290700"
  },
  {
    "text": "because it takes the\ngraph as the input",
    "start": "290700",
    "end": "292500"
  },
  {
    "text": "and encodes it into some\nkind of representation.",
    "start": "292500",
    "end": "295860"
  },
  {
    "text": "The task of graph\ngeneration actually",
    "start": "295860",
    "end": "298379"
  },
  {
    "text": "goes in the other direction.",
    "start": "298380",
    "end": "300600"
  },
  {
    "text": "It wants to start on\nthe right-hand side",
    "start": "300600",
    "end": "302880"
  },
  {
    "text": "and then through a series of\ncomplex nonlinear transforms",
    "start": "302880",
    "end": "306270"
  },
  {
    "text": "wants to output the\nentire graph, right?",
    "start": "306270",
    "end": "309190"
  },
  {
    "text": "So our input perhaps will be\na little small noise parameter",
    "start": "309190",
    "end": "312588"
  },
  {
    "text": "or something like\nthat and we'll want",
    "start": "312588",
    "end": "314130"
  },
  {
    "text": "to kind of expand\nthat until we have",
    "start": "314130",
    "end": "317190"
  },
  {
    "text": "the entire graph on the output.",
    "start": "317190",
    "end": "319370"
  },
  {
    "text": "So we will be kind of decoding\nrather than encoding, right?",
    "start": "319370",
    "end": "323040"
  },
  {
    "text": "We'll take a small\npiece of information",
    "start": "323040",
    "end": "325080"
  },
  {
    "text": "and expand it into\nthe entire graph",
    "start": "325080",
    "end": "327060"
  },
  {
    "text": "rather than taking\na complex structure",
    "start": "327060",
    "end": "329669"
  },
  {
    "text": "and compress it into or\ninto its representation.",
    "start": "329670",
    "end": "333820"
  },
  {
    "text": "So we are talking about\ndeep graph decoders,",
    "start": "333820",
    "end": "337410"
  },
  {
    "text": "because on the output we want\nto generate an entire network.",
    "start": "337410",
    "end": "342190"
  },
  {
    "text": "So in order for us to do\nthat, I want to first tell you",
    "start": "342190",
    "end": "345240"
  },
  {
    "text": "about kind of how are we going\nto set up the problem in terms",
    "start": "345240",
    "end": "350370"
  },
  {
    "text": "of its set up, in\nterms of its kind",
    "start": "350370",
    "end": "352270"
  },
  {
    "text": "of mathematical\nstatistical foundation.",
    "start": "352270",
    "end": "354780"
  },
  {
    "text": "And then I'm going to talk\nabout what methods allow",
    "start": "354780",
    "end": "359070"
  },
  {
    "text": "us to achieve the goal\nof graph generation",
    "start": "359070",
    "end": "363330"
  },
  {
    "text": "using representation learning.",
    "start": "363330",
    "end": "365409"
  },
  {
    "text": "So let's talk about\ngraph generation.",
    "start": "365410",
    "end": "368640"
  },
  {
    "text": "Generally, we have two\ntasks we will talk about",
    "start": "368640",
    "end": "372030"
  },
  {
    "text": "in this lecture.",
    "start": "372030",
    "end": "372880"
  },
  {
    "text": "First, is what we will call\nrealistic graph generation,",
    "start": "372880",
    "end": "376232"
  },
  {
    "text": "where we want to\ngenerate the graphs that",
    "start": "376232",
    "end": "377940"
  },
  {
    "text": "are similar to a\ngiven set of graphs.",
    "start": "377940",
    "end": "380160"
  },
  {
    "text": "And I'm going to define\nthis much more rigorously",
    "start": "380160",
    "end": "382920"
  },
  {
    "text": "in a second.",
    "start": "382920",
    "end": "383920"
  },
  {
    "text": "And then the second\ntask, I'm also",
    "start": "383920",
    "end": "385650"
  },
  {
    "text": "going to talk about is what\nwe call goal-directed graph",
    "start": "385650",
    "end": "388710"
  },
  {
    "text": "generation.",
    "start": "388710",
    "end": "389490"
  },
  {
    "text": "What basically you want\nto generate a graph",
    "start": "389490",
    "end": "391440"
  },
  {
    "text": "that optimizes a\ngiven constraint",
    "start": "391440",
    "end": "393600"
  },
  {
    "text": "or a given objective.",
    "start": "393600",
    "end": "395080"
  },
  {
    "text": "So if you are generating\na molecule you could say,",
    "start": "395080",
    "end": "397289"
  },
  {
    "text": "I want to generate molecules\nthat have a given property,",
    "start": "397290",
    "end": "400830"
  },
  {
    "text": "maybe the property\nis solubility,",
    "start": "400830",
    "end": "402900"
  },
  {
    "text": "maybe the property is that\nthese molecules are non-toxic.",
    "start": "402900",
    "end": "406110"
  },
  {
    "text": "And you say I want to generate\nmolecules that are non-toxic.",
    "start": "406110",
    "end": "408870"
  },
  {
    "text": "So how do I generate the\nmost non-toxic molecule?",
    "start": "408870",
    "end": "411735"
  },
  {
    "text": "Or how do I generate the\nmolecule that is most soluble",
    "start": "411735",
    "end": "416069"
  },
  {
    "text": "and still looks like drugs?",
    "start": "416070",
    "end": "418500"
  },
  {
    "text": "Imagine another case\nI was giving example",
    "start": "418500",
    "end": "420900"
  },
  {
    "text": "before if I want to generate a\nroad network-- a realistic road",
    "start": "420900",
    "end": "423690"
  },
  {
    "text": "network of a city, that is\na graph generation problem.",
    "start": "423690",
    "end": "426600"
  },
  {
    "text": "I could say, I want to\ngenerate the optimal road",
    "start": "426600",
    "end": "429000"
  },
  {
    "text": "network of a city,\nright, whatever",
    "start": "429000",
    "end": "431400"
  },
  {
    "text": "the optimality constraint is\nthat is kind of, we assume",
    "start": "431400",
    "end": "436590"
  },
  {
    "text": "it is given to us, right?",
    "start": "436590",
    "end": "437850"
  },
  {
    "text": "So that's what we mean by\ngoal-directed graph generation",
    "start": "437850",
    "end": "441665"
  },
  {
    "text": "where you want to generate\na graph with a given--",
    "start": "441665",
    "end": "444240"
  },
  {
    "text": "with a given goal that optimizes\na given black box objective",
    "start": "444240",
    "end": "448080"
  },
  {
    "text": "function.",
    "start": "448080",
    "end": "448900"
  },
  {
    "text": "So that's the two parts\nof the lecture today.",
    "start": "448900",
    "end": "452540"
  },
  {
    "text": "But first, let's\ntalk about how do we",
    "start": "452540",
    "end": "455310"
  },
  {
    "text": "set up this graph generation\ntask as a machine learning",
    "start": "455310",
    "end": "459540"
  },
  {
    "text": "task?",
    "start": "459540",
    "end": "460080"
  },
  {
    "text": "So we are going to proceed\nin the following way.",
    "start": "460080",
    "end": "463800"
  },
  {
    "text": "We are going to assume that the\ngraphs are sampled from this p",
    "start": "463800",
    "end": "467819"
  },
  {
    "text": "data distribution.",
    "start": "467820",
    "end": "469060"
  },
  {
    "text": "So basically nature is\nsampling from p data",
    "start": "469060",
    "end": "472200"
  },
  {
    "text": "and is giving us graphs.",
    "start": "472200",
    "end": "473800"
  },
  {
    "text": "Our goal will be to learn\na distribution p model",
    "start": "473800",
    "end": "478860"
  },
  {
    "text": "and then be able to learn how\nto sample from this p model.",
    "start": "478860",
    "end": "483750"
  },
  {
    "text": "So basically, given\nthe input data,",
    "start": "483750",
    "end": "487050"
  },
  {
    "text": "we are going to learn a\nprobability distribution p",
    "start": "487050",
    "end": "490620"
  },
  {
    "text": "model over the\ngraphs, and then we",
    "start": "490620",
    "end": "492540"
  },
  {
    "text": "are going to sample new\ngraphs from that probability",
    "start": "492540",
    "end": "495540"
  },
  {
    "text": "distribution.",
    "start": "495540",
    "end": "496170"
  },
  {
    "text": "And right, and our\ngoal somehow will",
    "start": "496170",
    "end": "497760"
  },
  {
    "text": "be, that we want this p model\ndistribution to be as close as",
    "start": "497760",
    "end": "501930"
  },
  {
    "text": "possible to this unknown\np data distribution",
    "start": "501930",
    "end": "506130"
  },
  {
    "text": "that we don't have access to,\nthat only nature has access to,",
    "start": "506130",
    "end": "509850"
  },
  {
    "text": "right, the data set creator\nhas access to this p data.",
    "start": "509850",
    "end": "512760"
  },
  {
    "text": "We want to approximate\np data with p model.",
    "start": "512760",
    "end": "516120"
  },
  {
    "text": "And then as we have approximated\np data with p model,",
    "start": "516120",
    "end": "519729"
  },
  {
    "text": "we want to draw\nadditional instances,",
    "start": "519730",
    "end": "521849"
  },
  {
    "text": "we want to generate\nadditional graphs,",
    "start": "521850",
    "end": "523769"
  },
  {
    "text": "we want to generate additional\nsamples from the p model",
    "start": "523770",
    "end": "528180"
  },
  {
    "text": "and those would be the graphs\nwe will want to generate.",
    "start": "528180",
    "end": "531830"
  },
  {
    "text": "So if we want to do\nthis, then there are--",
    "start": "531830",
    "end": "534970"
  },
  {
    "text": "this is an instance of what we\ncall generative models, right?",
    "start": "534970",
    "end": "538360"
  },
  {
    "text": "We assume we want to learn a\ngenerative model for graphs",
    "start": "538360",
    "end": "541540"
  },
  {
    "text": "from a set of input graphs,\nlet's call them x i.",
    "start": "541540",
    "end": "545529"
  },
  {
    "text": "Here, as I said before p data\nis the data distribution which",
    "start": "545530",
    "end": "549790"
  },
  {
    "text": "is not known to us and we\ndon't have access to it,",
    "start": "549790",
    "end": "552430"
  },
  {
    "text": "all we have access\nto it are samples",
    "start": "552430",
    "end": "555580"
  },
  {
    "text": "x that are sampled from\nthis unknown p data.",
    "start": "555580",
    "end": "559040"
  },
  {
    "text": "We also will have another family\nof probability distributions,",
    "start": "559040",
    "end": "563769"
  },
  {
    "text": "let's call them p model\nthat are defined by theta,",
    "start": "563770",
    "end": "567280"
  },
  {
    "text": "theta are parameters\nof our model.",
    "start": "567280",
    "end": "571180"
  },
  {
    "text": "And we will want to use\nthis p model distribution",
    "start": "571180",
    "end": "573520"
  },
  {
    "text": "to approximate p data.",
    "start": "573520",
    "end": "575830"
  },
  {
    "text": "And then, what\nwould be our goal?",
    "start": "575830",
    "end": "577910"
  },
  {
    "text": "We have two-step goal.",
    "start": "577910",
    "end": "579250"
  },
  {
    "text": "First goal is to find parameters\ntheta so that p model closely",
    "start": "579250",
    "end": "584140"
  },
  {
    "text": "approximates p data, and this\nis called a density estimation",
    "start": "584140",
    "end": "587740"
  },
  {
    "text": "task.",
    "start": "587740",
    "end": "588430"
  },
  {
    "text": "And then we also want to be\nable to sample from p model.",
    "start": "588430",
    "end": "593460"
  },
  {
    "text": "Basically means, we want to\nbe able to generate new graphs",
    "start": "593460",
    "end": "596110"
  },
  {
    "text": "from this now p model\ndistribution to which we",
    "start": "596110",
    "end": "599110"
  },
  {
    "text": "have access to, right?",
    "start": "599110",
    "end": "600730"
  },
  {
    "text": "We want to generate new\nsamples, new graphs from it.",
    "start": "600730",
    "end": "604750"
  },
  {
    "text": "So let me give you\nmore details, right?",
    "start": "604750",
    "end": "607090"
  },
  {
    "text": "Our goal is to make p model be\nas close to p data as possible.",
    "start": "607090",
    "end": "611650"
  },
  {
    "text": "And the key principle we\nare going to use here,",
    "start": "611650",
    "end": "613830"
  },
  {
    "text": "is the principle of maximum\nlikelihood estimation,",
    "start": "613830",
    "end": "616990"
  },
  {
    "text": "which is a fundamental approach\nto modeling distributions.",
    "start": "616990",
    "end": "620190"
  },
  {
    "text": "Basically the way you can\nthink of it is the following,",
    "start": "620190",
    "end": "623120"
  },
  {
    "text": "we want to find parameters\ntheta star of our p model",
    "start": "623120",
    "end": "627720"
  },
  {
    "text": "distribution such that the\nlog likelihood of the data",
    "start": "627720",
    "end": "633089"
  },
  {
    "text": "points x of the graphs x that\nare sampled from this p data",
    "start": "633090",
    "end": "636810"
  },
  {
    "text": "distribution, their log\nlikelihood under our model--",
    "start": "636810",
    "end": "641670"
  },
  {
    "text": "under p model that is basically\ndefined or parameterized",
    "start": "641670",
    "end": "645089"
  },
  {
    "text": "by theta, is as large\nas possible, right?",
    "start": "645090",
    "end": "647740"
  },
  {
    "text": "So our goal is to\nfind parameters theta",
    "start": "647740",
    "end": "650160"
  },
  {
    "text": "star, such that the\nobserved data points x.",
    "start": "650160",
    "end": "653459"
  },
  {
    "text": "So basically, the\nobserved graphs",
    "start": "653460",
    "end": "656580"
  },
  {
    "text": "have the highest log likelihood\namong all possible choices",
    "start": "656580",
    "end": "660840"
  },
  {
    "text": "of theta, right?",
    "start": "660840",
    "end": "662695"
  },
  {
    "text": "And of course here,\nthe important thing",
    "start": "662695",
    "end": "664320"
  },
  {
    "text": "will be that p model needs\nto be flexible enough",
    "start": "664320",
    "end": "667080"
  },
  {
    "text": "that it's able to model p data.",
    "start": "667080",
    "end": "669060"
  },
  {
    "text": "And then the question\nis, how do we search over",
    "start": "669060",
    "end": "672240"
  },
  {
    "text": "all the instances of probability\ndistributions captured",
    "start": "672240",
    "end": "677310"
  },
  {
    "text": "by this p model?",
    "start": "677310",
    "end": "678750"
  },
  {
    "text": "So we actually kind of capture\nby these parameters theta, so",
    "start": "678750",
    "end": "683520"
  },
  {
    "text": "that the likelihood of\nthe data that we observe",
    "start": "683520",
    "end": "686520"
  },
  {
    "text": "is as high as possible, right?",
    "start": "686520",
    "end": "689190"
  },
  {
    "text": "And in other words,\nthe goal is to find",
    "start": "689190",
    "end": "691380"
  },
  {
    "text": "the model that is most likely\nto have generated the observed",
    "start": "691380",
    "end": "694500"
  },
  {
    "text": "data x, right?",
    "start": "694500",
    "end": "696060"
  },
  {
    "text": "Find the p model that\nis most likely to have",
    "start": "696060",
    "end": "698700"
  },
  {
    "text": "generated the observed data x.",
    "start": "698700",
    "end": "701700"
  },
  {
    "text": "Now, this is the\nfirst part, which",
    "start": "701700",
    "end": "703680"
  },
  {
    "text": "is the density estimation.",
    "start": "703680",
    "end": "705300"
  },
  {
    "text": "The second part\nis also important,",
    "start": "705300",
    "end": "707700"
  },
  {
    "text": "because once we have the\ndensity that's not enough.",
    "start": "707700",
    "end": "710290"
  },
  {
    "text": "We need to be able to draw\nsamples from it, right?",
    "start": "710290",
    "end": "712800"
  },
  {
    "text": "We want to create samples from\nthis complex distribution.",
    "start": "712800",
    "end": "716519"
  },
  {
    "text": "And a common approach how\nyou can generate samples",
    "start": "716520",
    "end": "721770"
  },
  {
    "text": "from a complex distribution\nwould be the following.",
    "start": "721770",
    "end": "725160"
  },
  {
    "text": "Is that first, you start with\nthe simple noise distribution",
    "start": "725160",
    "end": "728220"
  },
  {
    "text": "just like a simple,\nlet's say a scalar value",
    "start": "728220",
    "end": "732269"
  },
  {
    "text": "that's a normally distributed\n0 mean unit need to variance.",
    "start": "732270",
    "end": "735780"
  },
  {
    "text": "And then you want to have\nthis complex function that",
    "start": "735780",
    "end": "738330"
  },
  {
    "text": "will take this\nlittle noise kernel",
    "start": "738330",
    "end": "740520"
  },
  {
    "text": "and is going to expand it\nuntil you have the sample x.",
    "start": "740520",
    "end": "744540"
  },
  {
    "text": "So in our case, we'll start\nwith a little random seed,",
    "start": "744540",
    "end": "747690"
  },
  {
    "text": "and we are going to expand\nit into a full graph x.",
    "start": "747690",
    "end": "752430"
  },
  {
    "text": "Where of course, now the\nhope is that x will follow",
    "start": "752430",
    "end": "755430"
  },
  {
    "text": "the distribution of p model.",
    "start": "755430",
    "end": "757930"
  },
  {
    "text": "So in our case, how do we\ndesign this function f?",
    "start": "757930",
    "end": "761190"
  },
  {
    "text": "We are going to use\ndeep neural networks,",
    "start": "761190",
    "end": "763170"
  },
  {
    "text": "and train them so that they can\nstart with the little kernel",
    "start": "763170",
    "end": "766410"
  },
  {
    "text": "and generate the graph.",
    "start": "766410",
    "end": "768910"
  },
  {
    "text": "So that's how we are\ngoing to do this.",
    "start": "768910",
    "end": "772629"
  },
  {
    "text": "So now in terms of\ndeep generative models,",
    "start": "772630",
    "end": "775680"
  },
  {
    "text": "our model will be an instance\nof an auto-regressive model.",
    "start": "775680",
    "end": "780480"
  },
  {
    "text": "Where this p model will be used\nboth for density estimation",
    "start": "780480",
    "end": "784440"
  },
  {
    "text": "and sampling, right, because\nwe have these two goals, right?",
    "start": "784440",
    "end": "788310"
  },
  {
    "text": "And in general you don't have\nto use the same neural network",
    "start": "788310",
    "end": "796020"
  },
  {
    "text": "to both do the\ndensity estimation",
    "start": "796020",
    "end": "798360"
  },
  {
    "text": "and to do the sampling and\nthere are other approaches",
    "start": "798360",
    "end": "801570"
  },
  {
    "text": "that you could choose to do here\nlike variational autoencoders",
    "start": "801570",
    "end": "805020"
  },
  {
    "text": "or generative adversarial\nnetworks and so on.",
    "start": "805020",
    "end": "809290"
  },
  {
    "text": "But in our case, we are going\nto use an auto-regressive model.",
    "start": "809290",
    "end": "812589"
  },
  {
    "text": "And the idea is\nthat, we are going",
    "start": "812590",
    "end": "815220"
  },
  {
    "text": "to model this complex\ndistribution as a product",
    "start": "815220",
    "end": "818129"
  },
  {
    "text": "of simpler distributions.",
    "start": "818130",
    "end": "819990"
  },
  {
    "text": "And the reason why\nwe can do this,",
    "start": "819990",
    "end": "821970"
  },
  {
    "text": "is of the chain rule in\nprobability and Bayesian",
    "start": "821970",
    "end": "826180"
  },
  {
    "text": "networks.",
    "start": "826180",
    "end": "826680"
  },
  {
    "text": "So we're basically--\nwhich basically tells us,",
    "start": "826680",
    "end": "828600"
  },
  {
    "text": "that any joint distribution\non a set of variables",
    "start": "828600",
    "end": "832980"
  },
  {
    "text": "can be exactly\nmodeled or expressed",
    "start": "832980",
    "end": "835800"
  },
  {
    "text": "as a product over the\nconditional distribution,",
    "start": "835800",
    "end": "841640"
  },
  {
    "text": "right?",
    "start": "841640",
    "end": "842170"
  },
  {
    "text": "So basically I'm\nsaying this p model",
    "start": "842170",
    "end": "845000"
  },
  {
    "text": "that is a complex\ndistribution over my x, which",
    "start": "845000",
    "end": "850950"
  },
  {
    "text": "may be a set of\nrandom variables,",
    "start": "850950",
    "end": "852930"
  },
  {
    "text": "I can write it out as a product\nover all these random variables",
    "start": "852930",
    "end": "856680"
  },
  {
    "text": "from the first one\nto the last one,",
    "start": "856680",
    "end": "858839"
  },
  {
    "text": "where all I have\nto now express is",
    "start": "858840",
    "end": "862470"
  },
  {
    "text": "this probability of a\nrandom variability t given",
    "start": "862470",
    "end": "866370"
  },
  {
    "text": "the values instances of all\nthe previous random variables,",
    "start": "866370",
    "end": "870570"
  },
  {
    "text": "right?",
    "start": "870570",
    "end": "871540"
  },
  {
    "text": "So in our case for example,\nif x would be a vector,",
    "start": "871540",
    "end": "874750"
  },
  {
    "text": "then x sub t is the t-th\ncoordinate of that vector,",
    "start": "874750",
    "end": "878797"
  },
  {
    "text": "right?",
    "start": "878797",
    "end": "880230"
  },
  {
    "text": "If x is a sentence, then x sub\nt would be the word, right?",
    "start": "880230",
    "end": "883810"
  },
  {
    "text": "So I'm basically saying,\nrather than generating",
    "start": "883810",
    "end": "886200"
  },
  {
    "text": "an entire sentence or to write\nout the probability of a given,",
    "start": "886200",
    "end": "890020"
  },
  {
    "text": "let's say sentence,\nI'm going to--",
    "start": "890020",
    "end": "891930"
  },
  {
    "text": "I can model that\nas a product where",
    "start": "891930",
    "end": "893850"
  },
  {
    "text": "I say, given the words\nso far, how likely",
    "start": "893850",
    "end": "896759"
  },
  {
    "text": "or what is the probability\nof the next word?",
    "start": "896760",
    "end": "898800"
  },
  {
    "text": "And if I multiply this\nout, I have the probability",
    "start": "898800",
    "end": "902399"
  },
  {
    "text": "of the entire sentence.",
    "start": "902400",
    "end": "903510"
  },
  {
    "text": "And we can do this without\nany loss of generality",
    "start": "903510",
    "end": "906930"
  },
  {
    "text": "or any approximation,\nif we really",
    "start": "906930",
    "end": "909330"
  },
  {
    "text": "condition on all the\nprevious words, all",
    "start": "909330",
    "end": "912480"
  },
  {
    "text": "the previous elements, right?",
    "start": "912480",
    "end": "914459"
  },
  {
    "text": "In our case, what this\nmeans is that the way",
    "start": "914460",
    "end": "918000"
  },
  {
    "text": "we apply these two\ngraphs is that, we",
    "start": "918000",
    "end": "919740"
  },
  {
    "text": "are going to represent\na graph as a sequence",
    "start": "919740",
    "end": "923250"
  },
  {
    "text": "as a set of actions.",
    "start": "923250",
    "end": "924690"
  },
  {
    "text": "And we are going to say, a-ha,\nthe probability of next action",
    "start": "924690",
    "end": "927960"
  },
  {
    "text": "is conditioned on all\nthe previous actions.",
    "start": "927960",
    "end": "931350"
  },
  {
    "text": "And now what will the actions\nbe, it will be add a node,",
    "start": "931350",
    "end": "935459"
  },
  {
    "text": "add an edge, right?",
    "start": "935460",
    "end": "936280"
  },
  {
    "text": "That's the way we are\ngoing to think of this.",
    "start": "936280",
    "end": "939770"
  },
  {
    "start": "939770",
    "end": "944000"
  }
]
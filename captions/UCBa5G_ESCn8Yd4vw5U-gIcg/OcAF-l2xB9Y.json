[
  {
    "start": "0",
    "end": "6000"
  },
  {
    "start": "0",
    "end": "5370"
  },
  {
    "text": "Hi. In this module, I'm going to\ntalk about the backpropagation algorithm for computing\ngradients automatically.",
    "start": "5370",
    "end": "11840"
  },
  {
    "start": "6000",
    "end": "18000"
  },
  {
    "text": "It's generally associated\nwith training neural networks, but it's actually a far\nmore general algorithm.",
    "start": "11840",
    "end": "18680"
  },
  {
    "start": "18000",
    "end": "129000"
  },
  {
    "text": "So let's begin with our\nmotivating example, which is, suppose we're doing regression\nwith a four-layer neural",
    "start": "18680",
    "end": "24490"
  },
  {
    "text": "network. So remember that\nwe compute the loss on a given example,\nthe loss with respect",
    "start": "24490",
    "end": "32049"
  },
  {
    "text": "to a particular example. And now, we have the\nweights of the network.",
    "start": "32049",
    "end": "39100"
  },
  {
    "text": "V1, V2, V3, and w is equal to-- and remember the form\nof the neural network,",
    "start": "39100",
    "end": "45690"
  },
  {
    "text": "you start with a feature vector,\nyou multiply it by some weight matrix, it gives you a vector.",
    "start": "45690",
    "end": "52590"
  },
  {
    "text": "And send it through the\nactivation function. Repeatedly apply a matrix.",
    "start": "52590",
    "end": "59950"
  },
  {
    "text": "Send it to an\nactivation function to left multiply by a matrix. Send it through an\nactivation function.",
    "start": "59950",
    "end": "66110"
  },
  {
    "text": "You take a final vector. You take the dot\nproduct with respect to the final weight vector.",
    "start": "66110",
    "end": "71200"
  },
  {
    "text": "And that gives you your score. So this is the prediction,\nsubtract the target value.",
    "start": "71200",
    "end": "79590"
  },
  {
    "text": "And you square it, that\ngives you your loss.",
    "start": "79590",
    "end": "84619"
  },
  {
    "text": "So now, if you wanted to train\nthis neural network using stochastic gradient\ndescent, you would",
    "start": "84620",
    "end": "89860"
  },
  {
    "text": "need to compute the gradient\nof this loss function with respect to each\nof the parameters.",
    "start": "89860",
    "end": "96500"
  },
  {
    "text": "So for example, you would\ncompute the gradient of the loss with respect\nto V1, that gives you",
    "start": "96500",
    "end": "102579"
  },
  {
    "text": "a gradient update, which\nyou can then use to update V1, same with V2, 3, and w.",
    "start": "102580",
    "end": "111100"
  },
  {
    "text": "So now, you can sit down\nwith this lovely expression. And you can just\ngrind through the math",
    "start": "111100",
    "end": "116890"
  },
  {
    "text": "and get the expressions. It's straightforward,\nbut it's rather tedious. The question is, how can you\nget the gradients without all",
    "start": "116890",
    "end": "125200"
  },
  {
    "text": "doing all this manual work?  So the answer to that\nis computation graphs.",
    "start": "125200",
    "end": "133440"
  },
  {
    "start": "129000",
    "end": "206000"
  },
  {
    "text": "So here is our loss\nfunction again. And what we're going to do\nis write down the computation",
    "start": "133440",
    "end": "139530"
  },
  {
    "text": "graph for these mathematics. Computation graph is a\ndirected acyclic graph,",
    "start": "139530",
    "end": "145020"
  },
  {
    "text": "whose root node represents\nthe final expression, this loss function. And each node represents\nintermediate sub expressions,",
    "start": "145020",
    "end": "154590"
  },
  {
    "text": "like 1 cube x, for example. Now what this computation graph\nis going to allow us to do",
    "start": "154590",
    "end": "161300"
  },
  {
    "text": "is allows us to apply the\nbackpropagation algorithm to the computation\ngraph and automatically",
    "start": "161300",
    "end": "167630"
  },
  {
    "text": "get gradients out. So there's two purposes actually\nthat we're going to do this.",
    "start": "167630",
    "end": "174660"
  },
  {
    "text": "The first is computing the\ngradients automatically. And this is how deep\nlearning packages",
    "start": "174660",
    "end": "180950"
  },
  {
    "text": "like TensorFlow and PyTorch\nwork behind the hood. And second of all,\nwe're going to use this",
    "start": "180950",
    "end": "187790"
  },
  {
    "text": "as a tool to gain insight\ninto the modular structure of the gradients,\nand try to demystify.",
    "start": "187790",
    "end": "194209"
  },
  {
    "text": "Because taking\ngradients by hand, you can lead it into\nsituations where you just have a lot of symbols.",
    "start": "194210",
    "end": "199820"
  },
  {
    "text": "But using a graph, we can\nstart to see the structure. ",
    "start": "199820",
    "end": "206900"
  },
  {
    "start": "206000",
    "end": "371000"
  },
  {
    "text": "OK. So our starting point is to\nthink about functions as boxes.",
    "start": "206900",
    "end": "212530"
  },
  {
    "text": "So imagine you have\nthis expression, a plus b, and that gives\nrise to some group of c.",
    "start": "212530",
    "end": "219800"
  },
  {
    "text": "So I'm going to represent this\nas a very simple computation graph where you have a and b.",
    "start": "219800",
    "end": "227200"
  },
  {
    "text": "And these arrows point into\nthis box that does plus.",
    "start": "227200",
    "end": "232330"
  },
  {
    "text": "And the result will be\nlabeled as c here, OK?",
    "start": "232330",
    "end": "237500"
  },
  {
    "text": "So now, the question\nis if I change a or b",
    "start": "237500",
    "end": "244660"
  },
  {
    "text": "by a small amount, how\nmuch does c change? Oh, this is just the\nnotion of a gradient.",
    "start": "244660",
    "end": "251180"
  },
  {
    "text": "So informally, we can look\nat this as a plus b equals c.",
    "start": "251180",
    "end": "258940"
  },
  {
    "text": "Now, if I go and fiddle\nwith a a little bit, I add epsilon, so what happens\nto the right hand side?",
    "start": "258940",
    "end": "267220"
  },
  {
    "text": "While on the right hand side,\nI just get plus 1 epsilon.",
    "start": "267220",
    "end": "272440"
  },
  {
    "text": "And what I'm going to do, so the\ngradient of c with respect to a",
    "start": "272440",
    "end": "277710"
  },
  {
    "text": "is 1? I'm just going to\nwrite it on there. So this can be\ninterpreted as kind",
    "start": "277710",
    "end": "284270"
  },
  {
    "text": "of amplification or a gain. By moving a by a\nlittle bit, this is kind of the\nmultiplicative factor",
    "start": "284270",
    "end": "290840"
  },
  {
    "text": "that c needs to be multiplied. So let's do the other side.",
    "start": "290840",
    "end": "295870"
  },
  {
    "text": "So a plus b, and you\nadd a bit of noise to b.",
    "start": "295870",
    "end": "301050"
  },
  {
    "text": "And again, you get\n1 plus epsilon. So the gradient of c with\nrespect to b is 1 as well.",
    "start": "301050",
    "end": "309800"
  },
  {
    "text": "Here's another example,\nc equals a times b. So as a computation\ngraph, a and b",
    "start": "309800",
    "end": "316180"
  },
  {
    "text": "go into this box, which\nthe takes dot product, and you get c.",
    "start": "316180",
    "end": "322979"
  },
  {
    "text": "So what happens when you\nadd epsilon noise to a?",
    "start": "322980",
    "end": "330220"
  },
  {
    "text": "a plus epsilon times\nb is equal to c plus. And now, you have b\nepsilon coming out.",
    "start": "330220",
    "end": "338440"
  },
  {
    "text": "So therefore, the gradient of\nc with respect to a is now b. And analogously,\nwe add noise to b.",
    "start": "338440",
    "end": "347530"
  },
  {
    "text": "And we see that the\ncontribution to the output c is a times epsilon, a epsilon.",
    "start": "347530",
    "end": "356900"
  },
  {
    "text": "Hence, therefore, the\ngradient over here is a.",
    "start": "356900",
    "end": "362250"
  },
  {
    "text": "So this all should\nbe kind of familiar. I've just cast the\nsum and product rules for differentiation\nin graphical form.",
    "start": "362250",
    "end": "371780"
  },
  {
    "start": "371000",
    "end": "520000"
  },
  {
    "text": "So let's do a few more\nkind of small examples. These small examples are going\nto be the building blocks.",
    "start": "371780",
    "end": "377750"
  },
  {
    "text": "It turns out that you can\ntake these building blocks and compose them to\nbuild all sorts of more complicated functions.",
    "start": "377750",
    "end": "384590"
  },
  {
    "text": "So here's example we\nsaw before-- a plus b, and the gradients are\n1 and 1, a minus b,",
    "start": "384590",
    "end": "393270"
  },
  {
    "text": "the gradients are 1 and minus 1. Because if you add\nepsilon to b, then",
    "start": "393270",
    "end": "399009"
  },
  {
    "text": "this difference is going\nto go down by epsilon. Here, we saw this example,\na times b and the gradients",
    "start": "399010",
    "end": "407470"
  },
  {
    "text": "on b and a. If you look at the\nsquared function, a squared, the gradient\nwith respect to input as 2a,",
    "start": "407470",
    "end": "417400"
  },
  {
    "text": "so that's kind of\nthe power rule. Let's consider a and b\nwhere you take the max, OK?",
    "start": "417400",
    "end": "425590"
  },
  {
    "text": "So this one, let's\nthink about this. So if I add a little bit--\nif I add epsilon to a,",
    "start": "425590",
    "end": "432865"
  },
  {
    "text": "how is that going\nto change the max? Well, if a is\ngreater than that b,",
    "start": "432865",
    "end": "439240"
  },
  {
    "text": "then it's just going to\nchange the max by epsilon.",
    "start": "439240",
    "end": "444289"
  },
  {
    "text": "But if a is less\nthan b, then it's going to be 0, because\nb is going to be less.",
    "start": "444290",
    "end": "451169"
  },
  {
    "text": "So the gradient of this max\nof a and b with respect to a is the indicator function\nof whether a is greater",
    "start": "451170",
    "end": "458880"
  },
  {
    "text": "than or not. And symmetrically, the\ngradient with respect to b",
    "start": "458880",
    "end": "464370"
  },
  {
    "text": "is whether b is\ngreater than a, OK?",
    "start": "464370",
    "end": "469430"
  },
  {
    "text": "And finally, here is\nthe logistic function, a sent through this\nlogistic function.",
    "start": "469430",
    "end": "476850"
  },
  {
    "text": "And a little bit of algebra,\nwhich I'll spare you of, produces this actually\nquite elegant expression,",
    "start": "476850",
    "end": "482819"
  },
  {
    "text": "which is sigma times 1 minus. And you can kind of check that\nas a goes to infinity or minus",
    "start": "482820",
    "end": "493240"
  },
  {
    "text": "infinity. Remember, the sigmoid\nis going to saturate at 1 or 0, which means\nthis gradient is actually",
    "start": "493240",
    "end": "501340"
  },
  {
    "text": "going to go to 0. So that's just a\nsimple sanity check. OK. So these are the\nbasic building blocks.",
    "start": "501340",
    "end": "508880"
  },
  {
    "text": "And that's really kind of all\nthe brute force differentiation",
    "start": "508880",
    "end": "515349"
  },
  {
    "text": "that we're going to really do. The rest is just composition. ",
    "start": "515350",
    "end": "521199"
  },
  {
    "start": "520000",
    "end": "602000"
  },
  {
    "text": "So now, we take these\nbuilding blocks, and we put them together. So here's a simple example.",
    "start": "521200",
    "end": "526500"
  },
  {
    "text": "So suppose you take\na squared, you get b. And then you take b, and you\nsquare it, and you get c.",
    "start": "526500",
    "end": "533880"
  },
  {
    "text": "So by the building blocks\nfrom the previous slide, we know that the\ngradient on this edge",
    "start": "533880",
    "end": "541080"
  },
  {
    "text": "is going to be 2 times,\ninput here, which is b. And the gradient along this\nedge is going to be 2 times a.",
    "start": "541080",
    "end": "550550"
  },
  {
    "text": "OK. So now, using these two, we can\napply chain rule from calculus",
    "start": "550550",
    "end": "556510"
  },
  {
    "text": "to compute the gradient\nof c with respect to a.",
    "start": "556510",
    "end": "561652"
  },
  {
    "text": "And this is going to be nothing\nmore than just the product of those two quantities.",
    "start": "561652",
    "end": "567820"
  },
  {
    "text": "So in this case,\nwe've got 2b times 2a. And remember that b is equal to\na squared, substitute that in",
    "start": "567820",
    "end": "576560"
  },
  {
    "text": "and you get 4a cubed. And remember, c is\na to the fourth.",
    "start": "576560",
    "end": "584220"
  },
  {
    "text": "So we can verify\nthat this is indeed consistent with our goal.",
    "start": "584220",
    "end": "589300"
  },
  {
    "text": "OK? So in general, you can\ncompute these gradients",
    "start": "589300",
    "end": "595900"
  },
  {
    "text": "by simply taking the\nproduct along edges. And that's going to be\nreally useful on this slide.",
    "start": "595900",
    "end": "603790"
  },
  {
    "start": "602000",
    "end": "825000"
  },
  {
    "text": "OK. So now, let's turn\nto our first example. The hinge loss for\nlinear classification.",
    "start": "603790",
    "end": "611108"
  },
  {
    "text": "We actually did this\none before, but I just want to do it again through the\nlens of a computation graph. So here's a loss function.",
    "start": "611108",
    "end": "618180"
  },
  {
    "text": "And given this\nloss function, I'm going to construct\nthe computation graph, and then compute the gradient\nof the loss with respect to w.",
    "start": "618180",
    "end": "627310"
  },
  {
    "text": "So working bottom up, we\nhave the weight vector. And we have the feature vector.",
    "start": "627310",
    "end": "633550"
  },
  {
    "text": "And we take the dot product. That gives us a score. We take the score.",
    "start": "633550",
    "end": "639240"
  },
  {
    "text": "We take y, and\nmultiply them together, and that gives us the margin. 1 minus the margin, and you\ntake the max of that and 0,",
    "start": "639240",
    "end": "650720"
  },
  {
    "text": "and you get the loss. So another nice thing\nabout the computation graph is it allows you to annotate\nthese sub-expressions",
    "start": "650720",
    "end": "657980"
  },
  {
    "text": "and see how the computation\nand what the pieces are.",
    "start": "657980",
    "end": "664199"
  },
  {
    "text": "OK. So now, let us\ncompute the gradient of the loss with respect to w.",
    "start": "664200",
    "end": "671230"
  },
  {
    "text": "And what I'm going\nto do here is all I need to do is compute\nthe gradients along all",
    "start": "671230",
    "end": "677180"
  },
  {
    "text": "of these edges from\nloss down to w, OK?",
    "start": "677180",
    "end": "682370"
  },
  {
    "text": "And so let's begin\nat the top here. So the gradient with n--\noh, here is our cheat sheet.",
    "start": "682370",
    "end": "689070"
  },
  {
    "text": "Don't forget the cheat sheet. So we just now pattern match. Here's a max over two things.",
    "start": "689070",
    "end": "694699"
  },
  {
    "text": "Well, what's on this edge? It's first thing greater\nthan second thing. OK. So the gradient here is\ngoing to be first thing which",
    "start": "694700",
    "end": "702800"
  },
  {
    "text": "is 1 minus margin greater than\nthe second thing, which is 0. And now what about this edge?",
    "start": "702800",
    "end": "709350"
  },
  {
    "text": "So here is minus 1. So that's minus 1. What about this times?",
    "start": "709350",
    "end": "716270"
  },
  {
    "text": "Times is the second input. And the second input here is y.",
    "start": "716270",
    "end": "723630"
  },
  {
    "text": "And here's another times the\nsecond import is cube x, OK? So this allows us to\nthink about the gradients,",
    "start": "723630",
    "end": "732600"
  },
  {
    "text": "one piece at a time. And all of the little\nedges are just invocations of this cheat sheet here.",
    "start": "732600",
    "end": "740140"
  },
  {
    "text": "OK. Now, we're ready to\nread off the gradient of the loss with respect to w.",
    "start": "740140",
    "end": "746760"
  },
  {
    "text": "And this is just going to be\nproduct of all the edges, OK? ",
    "start": "746760",
    "end": "753990"
  },
  {
    "text": "First, we have 1 minus\nmargin greater than 0. So I'm going to rewrite\nthat as margin less than 1,",
    "start": "753990",
    "end": "763200"
  },
  {
    "text": "verified that's the same thing. We have a minus sign here. That's a minus sign here.",
    "start": "763200",
    "end": "769680"
  },
  {
    "text": "And then we have y. And then we have a phi of x.",
    "start": "769680",
    "end": "775610"
  },
  {
    "text": "We multiply them all together. And that's the expression. And you can verify that this is\nindeed the gradient of the loss",
    "start": "775610",
    "end": "783230"
  },
  {
    "text": "function. OK? In summary, we computed\nthe computation graph.",
    "start": "783230",
    "end": "790930"
  },
  {
    "text": "And then we applied this cheat\nsheet to the individual edges. And then you just multiply\nthem all together.",
    "start": "790930",
    "end": "797215"
  },
  {
    "text": " And just as another\nnote, remember,",
    "start": "797215",
    "end": "803520"
  },
  {
    "text": "the gradient with\nrespect to w is really--",
    "start": "803520",
    "end": "808710"
  },
  {
    "text": "think about perturbations. If you change w by a\nlittle bit, how much is the loss going to change?",
    "start": "808710",
    "end": "815720"
  },
  {
    "text": "And the change is\ngoing to be the product of all these kind of\namplifications evaluated",
    "start": "815720",
    "end": "821660"
  },
  {
    "text": "at a particular point.  All right. So now, let's do\nneural networks now.",
    "start": "821660",
    "end": "830050"
  },
  {
    "start": "825000",
    "end": "1457000"
  },
  {
    "text": "So this is not going to\nbe really anything new. It's just going to be\na different example.",
    "start": "830050",
    "end": "835540"
  },
  {
    "text": "So I'm going to do\ntwo-layer neural networks. And we're going to, again,\nbuild this computation graph up.",
    "start": "835540",
    "end": "844230"
  },
  {
    "text": "So we have the feature vector. You have the first\nlayer weight matrix of v. You take the product.",
    "start": "844230",
    "end": "852459"
  },
  {
    "text": "And then you stick this through\nthe activation function. And we're going to label that\nh, which is the hidden vector.",
    "start": "852460",
    "end": "862870"
  },
  {
    "text": "And now we're going to take the\ndot product of w and h, that gives you the score.",
    "start": "862870",
    "end": "869930"
  },
  {
    "text": "And then now, its score\nminus y is a residual.",
    "start": "869930",
    "end": "876120"
  },
  {
    "text": "And the residual\nsquare is a loss. OK? Another aside is that the\ncomputation graph really",
    "start": "876120",
    "end": "883120"
  },
  {
    "text": "allows you to see\nvisually this modularity. So that part up here is\njust the square loss.",
    "start": "883120",
    "end": "891700"
  },
  {
    "text": "And the part down here is\nany way of computing a score.",
    "start": "891700",
    "end": "901230"
  },
  {
    "text": "Before, we had a class\nlinear predictor. And now, we have\ntwo-layer neural network.",
    "start": "901230",
    "end": "907519"
  },
  {
    "text": "It could be a four-layer neural\nnetwork, which in a computation graph is just a [INAUDIBLE].",
    "start": "907520",
    "end": "912750"
  },
  {
    "text": "OK. So that's a computation graph. Now, let's-- to perform\nstochastic gradient descent,",
    "start": "912750",
    "end": "918350"
  },
  {
    "text": "we need to compute the gradient\nwith respect to both w and b, OK?",
    "start": "918350",
    "end": "923720"
  },
  {
    "text": "So let's compute the gradient\nwith respect to w of the loss.",
    "start": "923720",
    "end": "928910"
  },
  {
    "text": "And what I'm going to\ndo is look at the edges",
    "start": "928910",
    "end": "936220"
  },
  {
    "text": "and compute the gradients, OK? So here's our cheat sheet. So OK.",
    "start": "936220",
    "end": "941500"
  },
  {
    "text": "What goes on this edge? What's the gradient\nof the square? This is just 2 times the input,\nwhich is in this case 2 times",
    "start": "941500",
    "end": "948850"
  },
  {
    "text": "the residual. What about this edge? So minus, so this\nshould just be a 1 here.",
    "start": "948850",
    "end": "959980"
  },
  {
    "text": "And then what about this edge? This is just going to be\nthe second input here,",
    "start": "959980",
    "end": "966700"
  },
  {
    "text": "so that is an h, OK? So now, multiply all\nthese things together, and you get the gradient of\nthe loss function with respect",
    "start": "966700",
    "end": "977440"
  },
  {
    "text": "to w, OK? ",
    "start": "977440",
    "end": "982709"
  },
  {
    "text": "All right. So one thing you can\nkind of double check",
    "start": "982710",
    "end": "988920"
  },
  {
    "text": "is that we did do the\ngradient of the square lots for linear predictors. And it was also two times\nthe of residual times",
    "start": "988920",
    "end": "996720"
  },
  {
    "text": "the feature vector instead of h. And now, we just have h,\nwhich is a kind of a stand",
    "start": "996720",
    "end": "1003200"
  },
  {
    "text": "in for the feature vector\nas far as w is concerned.",
    "start": "1003200",
    "end": "1009470"
  },
  {
    "text": "But that's kind of\na nice sanity check. All right. So now, let's do this\nmore complicated one.",
    "start": "1009470",
    "end": "1014610"
  },
  {
    "text": "So this, we want to compute\nthe gradient with respect to v of loss of\nall the arguments.",
    "start": "1014610",
    "end": "1023290"
  },
  {
    "text": "And this equals-- let's\nfill in all the edges.",
    "start": "1023290",
    "end": "1029650"
  },
  {
    "text": "So first of all, notice that\nthese two edges are actually in common with this power.",
    "start": "1029650",
    "end": "1036819"
  },
  {
    "text": "We can go ahead and\nwrite them down. So one cool thing about\ncomputation graphs is it allows you\nto see the shared",
    "start": "1036819",
    "end": "1043839"
  },
  {
    "text": "structure that the gradients\nactually have themselves, also have common\nsub-expressions.",
    "start": "1043839",
    "end": "1051140"
  },
  {
    "text": "OK. So now, we need to\ndo more work here. So the gradient on this\nedge is going to be",
    "start": "1051140",
    "end": "1057910"
  },
  {
    "text": "the other input, which is w. This is sigma. So the gradient is going\nto be sigma, the input",
    "start": "1057910",
    "end": "1065740"
  },
  {
    "text": "minus 1 minus sigma. So this is going to just\nbe h times 1 minus h.",
    "start": "1065740",
    "end": "1074809"
  },
  {
    "text": "This hollow circle here\nrepresents the element product",
    "start": "1074810",
    "end": "1081350"
  },
  {
    "text": "of vector, so you\ntake two vectors, and you multiply the\nelements together.",
    "start": "1081350",
    "end": "1086810"
  },
  {
    "text": "And this is because\nthis function is applying just elementwise.",
    "start": "1086810",
    "end": "1092990"
  },
  {
    "text": "And then what about\nthis final edge? This is just going to be phi of\nx, which is this other input.",
    "start": "1092990",
    "end": "1100492"
  },
  {
    "text": "And now, we can just multiply\nthe rest of these things together. So we have w times\nh, times 1 minus h,",
    "start": "1100492",
    "end": "1110640"
  },
  {
    "text": "times a phi of x transpose.",
    "start": "1110640",
    "end": "1116220"
  },
  {
    "text": "So there's a slight\nkind of annoyance here. Because here, we\nhave V times phi",
    "start": "1116220",
    "end": "1122370"
  },
  {
    "text": "of x, whereas before, there's no\ntranspose here because we just have w dot something.",
    "start": "1122370",
    "end": "1128190"
  },
  {
    "text": "And w dot is the same\nas w transpose, OK? But the high level\nis that the product",
    "start": "1128190",
    "end": "1136440"
  },
  {
    "text": "of all of these\ngreen pieces yields the gradient of the loss\nwith respect to v. OK?",
    "start": "1136440",
    "end": "1148700"
  },
  {
    "text": "All right. So that finishes\nup this example. ",
    "start": "1148700",
    "end": "1155460"
  },
  {
    "text": "So now, we have mainly used\nthis graphical representation to visualize the computation of\nfunction values and gradients.",
    "start": "1155460",
    "end": "1165350"
  },
  {
    "text": "But the problems\nof backpropagation is that we didn't have\nto do any of that at all. I just did that to\nkind of illustrate",
    "start": "1165350",
    "end": "1172730"
  },
  {
    "text": "the inner workings of\ngradient computations on the computation.",
    "start": "1172730",
    "end": "1179179"
  },
  {
    "text": "But now, we're going to\nintroduce a backpropagation algorithm, which is a general\nprocedure for computing",
    "start": "1179180",
    "end": "1184280"
  },
  {
    "text": "these gradients. So we never have\nto worry about it. I'm going to do\nthis backpropagation",
    "start": "1184280",
    "end": "1190800"
  },
  {
    "text": "for a simple example,\nwhich is just this squared loss and\nlinear regression.",
    "start": "1190800",
    "end": "1198500"
  },
  {
    "text": "And one note is that\npreviously, we've worked with symbolic\nexpressions.",
    "start": "1198500",
    "end": "1206029"
  },
  {
    "text": "But the actual\nalgorithm is going to operate on numbers usually. So what I'm going to do is\nwork with a concrete example",
    "start": "1206030",
    "end": "1214250"
  },
  {
    "text": "and walk through the\nbackpropagation algorithm with this example.",
    "start": "1214250",
    "end": "1219269"
  },
  {
    "text": "So the backpropagation\nalgorithm includes two steps, a forward\nstep and a backward step.",
    "start": "1219270",
    "end": "1226830"
  },
  {
    "text": "So in the forward step,\nwhat we're going to do is we're going to compute\na bunch of forward values",
    "start": "1226830",
    "end": "1233780"
  },
  {
    "text": "from the leaves to the root. And each forward value\nis simply the value",
    "start": "1233780",
    "end": "1238940"
  },
  {
    "text": "of that sub expression\nrooted at i. The value could be a\nscalar, vector, or a matrix.",
    "start": "1238940",
    "end": "1245340"
  },
  {
    "text": "So let's walk through\nthis example here, OK. So at the leaves, we\nhave w, which is (3,1).",
    "start": "1245340",
    "end": "1253039"
  },
  {
    "text": "And we have the\nfeature vector (1,2). So now, if you take\nthese two quantities,",
    "start": "1253040",
    "end": "1261120"
  },
  {
    "text": "and you take the dot product,\nyou get 3 plus 2, which is 5.",
    "start": "1261120",
    "end": "1271230"
  },
  {
    "text": "And now, you take the score 5. And you take y,\nsubtract them, and you",
    "start": "1271230",
    "end": "1278270"
  },
  {
    "text": "get the residual, which is 3. Notice that the forward\nvalue of this node",
    "start": "1278270",
    "end": "1283865"
  },
  {
    "text": "is 5, and the forward\nvalue of this node is 3. And now, finally,\nyou'd square this.",
    "start": "1283865",
    "end": "1291170"
  },
  {
    "text": "And the value of the square\nis 3 squared, which is 9,",
    "start": "1291170",
    "end": "1296870"
  },
  {
    "text": "or value at this node is 9, OK? So now, we're done\nwith the forward phase.",
    "start": "1296870",
    "end": "1302570"
  },
  {
    "text": "All we've done is\nevaluated the loss. But importantly, we have also\nremembered all the values",
    "start": "1302570",
    "end": "1310550"
  },
  {
    "text": "along the way, which\nwill come in handy. So now, the backward\nstep is we're",
    "start": "1310550",
    "end": "1319130"
  },
  {
    "text": "going to compute a backward\nvalue, gi, one for every node.",
    "start": "1319130",
    "end": "1325250"
  },
  {
    "text": "And this is going\nto be the gradient of the loss with respect\nto the value at that node.",
    "start": "1325250",
    "end": "1332539"
  },
  {
    "text": "So if that node changes value,\nhow does the loss change? So the backward pass is\ngoing to compute the values",
    "start": "1332540",
    "end": "1339730"
  },
  {
    "text": "from the root to the leaves. So let's do this for example. So the base case, gradient of\nthe loss with respect to loss",
    "start": "1339730",
    "end": "1347679"
  },
  {
    "text": "is 1. And now, we look at the\ngradient on this edge.",
    "start": "1347680",
    "end": "1355340"
  },
  {
    "text": "We did this before. It's just two\ntimes the residual. OK. So now, we need to compute the\nbackward value of this node,",
    "start": "1355340",
    "end": "1364515"
  },
  {
    "text": "OK? To do that, we're going\nto take the backward value of the parent, and multiply\nwhatever's on this edge.",
    "start": "1364515",
    "end": "1374270"
  },
  {
    "text": "What's on this edge is\n2 times the residual. The residual is 3. So it's 2 times 3, which is 6.",
    "start": "1374270",
    "end": "1381800"
  },
  {
    "text": "And so 1 times 6 is 6. Notice that in computing\nthis backward value,",
    "start": "1381800",
    "end": "1387410"
  },
  {
    "text": "I'm using the\nintermediate computations from the forward pass.",
    "start": "1387410",
    "end": "1393420"
  },
  {
    "text": "OK. So let's continue. So the gradient\non this edge is 1.",
    "start": "1393420",
    "end": "1399020"
  },
  {
    "text": "So backward value\nhere is 6, which is the parent backward\nvalue, times what's",
    "start": "1399020",
    "end": "1404750"
  },
  {
    "text": "on this edge, which is 1. That gives us 6. And then the backward\nvalue of this node",
    "start": "1404750",
    "end": "1411330"
  },
  {
    "text": "is 6 times, what's\non this edge, which is this other input (1,2).",
    "start": "1411330",
    "end": "1417150"
  },
  {
    "text": "And that gives us (6,12). So to conclude, the\nbackpropagation algorithm",
    "start": "1417150",
    "end": "1423770"
  },
  {
    "text": "takes these concrete\nvalues, this expression, and produces the gradient\nof the loss with respect",
    "start": "1423770",
    "end": "1433190"
  },
  {
    "text": "to w evaluated at\nthese concrete values. And that's (6,12).",
    "start": "1433190",
    "end": "1439290"
  },
  {
    "text": "OK? And the back\npropagation algorithm remember works for\nany computation graph",
    "start": "1439290",
    "end": "1444870"
  },
  {
    "text": "or layered neural networks,\nmuch more complicated models. But this is just\na simple example",
    "start": "1444870",
    "end": "1450330"
  },
  {
    "text": "to show you the dynamics of\nforward pass and backward pass. ",
    "start": "1450330",
    "end": "1457880"
  },
  {
    "start": "1457000",
    "end": "1555000"
  },
  {
    "text": "OK. So now, we have the back\npropagation algorithm, we compute gradients,\nwe stick these gradients",
    "start": "1457880",
    "end": "1463419"
  },
  {
    "text": "into stochastic\ngradient descent. And then we just run\nstochastic gradient descent, and then we get some weights.",
    "start": "1463420",
    "end": "1471200"
  },
  {
    "text": "So now, one question\nis, what do we get? So we wanted to optimize\nthe training loss using",
    "start": "1471200",
    "end": "1480320"
  },
  {
    "text": "stochastic gradient descent. But running stochastic\ngradient descent, does it actually\nminimize these weights?",
    "start": "1480320",
    "end": "1487530"
  },
  {
    "text": "This is a little bit of\na delicate question here. So for linear\npredictors, turns out",
    "start": "1487530",
    "end": "1494990"
  },
  {
    "text": "that the training\nloss for a convex loss is going to be a\nconvex function, which",
    "start": "1494990",
    "end": "1501830"
  },
  {
    "text": "means that it is going to have\na single global minimum, which",
    "start": "1501830",
    "end": "1508466"
  },
  {
    "text": "means that if you\nstart at some point, and then you just follow\nyour nose by running gradient descent with\nappropriate step size,",
    "start": "1508467",
    "end": "1514909"
  },
  {
    "text": "it's going to converge\nto the global optimum. But for neural\nnetworks, the TrainLoss",
    "start": "1514910",
    "end": "1522510"
  },
  {
    "text": "is non-convex, and\nwhich means that there's no guarantees at all.",
    "start": "1522510",
    "end": "1528710"
  },
  {
    "text": "And you're going to converge\nto the global minimum. You're lucky you can\nconverge to a local minimum.",
    "start": "1528710",
    "end": "1535590"
  },
  {
    "text": "So optimization of neural\nnetworks is in principle hard. But of course,\npeople do it anyway.",
    "start": "1535590",
    "end": "1542160"
  },
  {
    "text": "And you actually get\nsome good results. So there's a gap between\ntheory and practice, which",
    "start": "1542160",
    "end": "1549540"
  },
  {
    "text": "is not quite understood yet. But in practice, getting\nneural networks to train",
    "start": "1549540",
    "end": "1559110"
  },
  {
    "start": "1555000",
    "end": "1761000"
  },
  {
    "text": "properly is a little bit hard. But I think of it as kind\nof like driving stick. There's just a lot of\ndegrees of freedom.",
    "start": "1559110",
    "end": "1565950"
  },
  {
    "text": "You can stall and get stuck. But if you know\nwhat you're doing, you can actually get\na lot of good results.",
    "start": "1565950",
    "end": "1572090"
  },
  {
    "text": "OK? So here are some\nexamples, just to give you a flavor of what\nneeds to be done, OK?",
    "start": "1572090",
    "end": "1578680"
  },
  {
    "text": "So here is a two-layer\nneural network. And here is the loss function.",
    "start": "1578680",
    "end": "1584020"
  },
  {
    "text": "The first is\ninitialization matters. So if you have a\nconvex function, wherever you initialize,\nyou run it for long enough.",
    "start": "1584020",
    "end": "1590230"
  },
  {
    "text": "You converge to\nthe local optimum. For a non-convex function,\nif you initialize here, you might get stuck up here.",
    "start": "1590230",
    "end": "1596399"
  },
  {
    "text": "If you initialize\nover here, you'll get stuck here and so on. So generally, you have to\nbe a little bit careful",
    "start": "1596400",
    "end": "1601710"
  },
  {
    "text": "about how you initialize. You can't initialize at 0.",
    "start": "1601710",
    "end": "1607500"
  },
  {
    "text": "Because it turns out that all\nthe rows of your weight matrix",
    "start": "1607500",
    "end": "1613200"
  },
  {
    "text": "are going to be identical,\nwhich is not very useful. So you temporarily\ninitialize around 0",
    "start": "1613200",
    "end": "1619590"
  },
  {
    "text": "with some kind of random noise. Or you can use pre-training to\ninitialize your neural network",
    "start": "1619590",
    "end": "1625830"
  },
  {
    "text": "as well, which we\nwon't cover right now. Another thing that people do\nis called overparameterization.",
    "start": "1625830",
    "end": "1635420"
  },
  {
    "text": "So here, this corresponds\nto adding more hidden units than you really need.",
    "start": "1635420",
    "end": "1641020"
  },
  {
    "text": "This corresponds to having a\nlot of rows of this matrix.",
    "start": "1641020",
    "end": "1646450"
  },
  {
    "text": "And the idea here is that the\nmore hidden units you have,",
    "start": "1646450",
    "end": "1652080"
  },
  {
    "text": "the more kind of\n\"chances\" you have of having the network\nlearn something",
    "start": "1652080",
    "end": "1657710"
  },
  {
    "text": "reasonable by your data. So some of the units might die\noff and not be very useful, but maybe like some fraction of\nthem will actually be useful.",
    "start": "1657710",
    "end": "1667510"
  },
  {
    "text": "And the final thing\nthat people do is using adaptive\nstep sizes, which is generally an extension of\nstochastic gradient descent.",
    "start": "1667510",
    "end": "1675510"
  },
  {
    "text": "Remembers, in stochastic\ngradient descent, we had a single step\nsize, eta, which controlled how fast you move.",
    "start": "1675510",
    "end": "1682900"
  },
  {
    "text": "With methods like\nAdaGrad or Adam, you actually get a per feature,\nor a per parameter step size.",
    "start": "1682900",
    "end": "1691290"
  },
  {
    "text": "So for every weight,\nyou get a number of which dictates\nhow fast you should be moving in that direction.",
    "start": "1691290",
    "end": "1697250"
  },
  {
    "text": "And this generally\nleads to better results. OK.",
    "start": "1697250",
    "end": "1702710"
  },
  {
    "text": "So one maybe high level\nthing to keep in mind is don't let your gradients\nvanish or explode.",
    "start": "1702710",
    "end": "1710100"
  },
  {
    "text": "So if I explain this, it\nwill become kind of clear. So when you run gradient descent\nor stochastic gradient descent,",
    "start": "1710100",
    "end": "1718740"
  },
  {
    "text": "if your gradients vanish, which\nmeans become too small or close to zero, then you'll get stuck,\nand you won't make progress.",
    "start": "1718740",
    "end": "1727140"
  },
  {
    "text": "But if your gradients\nbecome too large, then you'll just explode. And you will oscillate\nand might diverge.",
    "start": "1727140",
    "end": "1735460"
  },
  {
    "text": "So with careful initialization,\nand setting up the step sizes, generally, and even designing\nof the neural network",
    "start": "1735460",
    "end": "1744400"
  },
  {
    "text": "architecture, all of this\nis around of kind of makingz sure that your gradients\ndon't vanish or explode.",
    "start": "1744400",
    "end": "1751419"
  },
  {
    "text": "OK. So that's all the\nguidance I'll provide you. There's a lot more to\nbe said on this topic. We're just kind of giving\nyou a high level overview.",
    "start": "1751420",
    "end": "1759600"
  },
  {
    "text": " OK. So let's summarize now. So the most important\ntopic of this module",
    "start": "1759600",
    "end": "1768920"
  },
  {
    "start": "1761000",
    "end": "1847000"
  },
  {
    "text": "is that of a\ncomputation graph This allows you to\nrepresent arbitrary",
    "start": "1768920",
    "end": "1774270"
  },
  {
    "text": "mathematical expressions. And these expressions are built\nout of these simple building blocks.",
    "start": "1774270",
    "end": "1780360"
  },
  {
    "text": "And I hope that the idea\nof computation graphs will allow you to get a better\nvisual understanding of what",
    "start": "1780360",
    "end": "1788580"
  },
  {
    "text": "your mathematical\nexpressions are doing, and also, what gradient\ncomputations are about.",
    "start": "1788580",
    "end": "1794920"
  },
  {
    "text": "And then we saw we had a\nbackpropagation algorithm, which is this general purpose\nalgorithm for leveraging",
    "start": "1794920",
    "end": "1801990"
  },
  {
    "text": "the computation graph to\ncompute the gradients.",
    "start": "1801990",
    "end": "1807170"
  },
  {
    "text": "So notice that we've done\nthis kind of in the context of neural networks.",
    "start": "1807170",
    "end": "1812480"
  },
  {
    "text": "But I stress that computation\ngraphs and backpropagation is fully general.",
    "start": "1812480",
    "end": "1817630"
  },
  {
    "text": "It allows you to handle\nmany, many functions. And the generality is one of\nthese reasons that you can--",
    "start": "1817630",
    "end": "1826570"
  },
  {
    "text": "it allows you to iterate very\nquickly on new types of models and loss functions, and\nopens up this new paradigm",
    "start": "1826570",
    "end": "1833860"
  },
  {
    "text": "for model development,\ndifferential programming, which we'll talk about\nin a future module.",
    "start": "1833860",
    "end": "1839390"
  },
  {
    "text": "All right. That's it. Thanks. ",
    "start": "1839390",
    "end": "1847000"
  }
]
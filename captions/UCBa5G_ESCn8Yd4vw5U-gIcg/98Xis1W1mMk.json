[
  {
    "start": "0",
    "end": "102000"
  },
  {
    "text": "and good afternoon everyone so hi everyone I'm Stuart Overman from",
    "start": "11269",
    "end": "18710"
  },
  {
    "text": "the abstract quickly about me so I was a",
    "start": "18710",
    "end": "24980"
  },
  {
    "text": "graduate student here at Stanford as well so I did my PhD research with Mike",
    "start": "24980",
    "end": "29990"
  },
  {
    "text": "Flynn Martin and others here right here at Stanford in the architecture and rithmetic group and I used to frequently",
    "start": "29990",
    "end": "35630"
  },
  {
    "text": "attend EE 380 while I was a student so it's really great to be back here on campus to in order to talk with you",
    "start": "35630",
    "end": "41300"
  },
  {
    "text": "about NVIDIA GPU computing as Andy was kind of alluding to and do it so here in the EE 380 colloquium a little bit more",
    "start": "41300",
    "end": "49039"
  },
  {
    "text": "I'm currently vice president of GPU ASIC engineering at Nvidia and I've been there at Nvidia now for 15 years and",
    "start": "49039",
    "end": "54920"
  },
  {
    "text": "today I want to talk about the journey that nvidia and the GPU have taken from pc gaming to deep learning so in this",
    "start": "54920",
    "end": "62629"
  },
  {
    "text": "talk we're going to explore what a GPU is today how its evolved and many of the",
    "start": "62629",
    "end": "67670"
  },
  {
    "text": "technical decisions that were made along the way and an overview of some of the major applications that rely on GPUs and",
    "start": "67670",
    "end": "74390"
  },
  {
    "text": "I'm going to try to give you some of my own perspectives of how the GPUs have evolved during this time frame I'm going",
    "start": "74390",
    "end": "79790"
  },
  {
    "text": "to include some videos and demos throughout the presentation to help motivate and illustrate certain topics",
    "start": "79790",
    "end": "86000"
  },
  {
    "text": "after all you know nvidia is a graphics company so any such presentation wouldn't be complete without some",
    "start": "86000",
    "end": "91549"
  },
  {
    "text": "graphics so I want everyone to sit back strap in there's going to be a lot of information I really am going to try to",
    "start": "91549",
    "end": "97520"
  },
  {
    "text": "cover this journey as efficiently as I can so some background about Nvidia first of",
    "start": "97520",
    "end": "104719"
  },
  {
    "start": "102000",
    "end": "255000"
  },
  {
    "text": "all you know who we are and what we do have I presume based on Andy's introduction that are people generally",
    "start": "104719",
    "end": "112610"
  },
  {
    "text": "aware of who and what Nvidia is yeah I'm curious are there any gamers amongst the",
    "start": "112610",
    "end": "117649"
  },
  {
    "text": "crowd here as well now good good some hands ok good so we're going to talk",
    "start": "117649",
    "end": "123380"
  },
  {
    "text": "about all of ads so our primary business in Nvidia is providing world-class accelerated computing solutions and",
    "start": "123380",
    "end": "129679"
  },
  {
    "text": "accelerated computing it Nvidia is about GPU computing the GPU is created by",
    "start": "129680",
    "end": "135170"
  },
  {
    "text": "Nvidia to accelerate originally graphics and games but today the G and GPU today",
    "start": "135170",
    "end": "142310"
  },
  {
    "text": "it really is just another way of saying that it's massively parallel throughput computing not",
    "start": "142310",
    "end": "147840"
  },
  {
    "text": "just for graphics kind of again as Andy was alluding to it's really general-purpose GPU computing it's",
    "start": "147840",
    "end": "153330"
  },
  {
    "text": "evolved over time GPU computing has from just gaming to game physics to",
    "start": "153330",
    "end": "158519"
  },
  {
    "text": "professional visualization to general-purpose computing with a focus on high performance computing",
    "start": "158519",
    "end": "164519"
  },
  {
    "text": "data centers and deep learning AI cloud computing in automotive so we'll talk about these these different businesses",
    "start": "164519",
    "end": "171569"
  },
  {
    "text": "that we actually have and the way we think about the entire computing market for for each of these markets that we",
    "start": "171569",
    "end": "177420"
  },
  {
    "text": "see here each of these businesses gaming probe visualization data center and auto we offer we have a platform of",
    "start": "177420",
    "end": "183780"
  },
  {
    "text": "processors software systems and services and what we do is we develop a new GPU",
    "start": "183780",
    "end": "189599"
  },
  {
    "text": "architecture generally every 12 to 18 months and I don't know if you're familiar with some of our architectures",
    "start": "189599",
    "end": "195299"
  },
  {
    "text": "we'll talk about them here there's been named after different physicists and what we do if you think about it from object-oriented programming perspective",
    "start": "195299",
    "end": "202110"
  },
  {
    "text": "each architecture is basically a class it's a blueprint for how we're going to design our GPUs for that entire",
    "start": "202110",
    "end": "207780"
  },
  {
    "text": "architecture and then we actually instance objects in this case GPUs the target each of these markets so we'll",
    "start": "207780",
    "end": "214049"
  },
  {
    "text": "have big to little GPUs for gaming we have specific ones for a quad so for for",
    "start": "214049",
    "end": "219660"
  },
  {
    "text": "gaming for probe is for data center for emprah motto and specifically just since I'm going to use some of the naming",
    "start": "219660",
    "end": "225299"
  },
  {
    "text": "throughout the talk I'll refer to this we've got so our GeForce business is",
    "start": "225299",
    "end": "231150"
  },
  {
    "text": "what is if you've heard of the brand that's our brand for gaming so when you think of GeForce that's our PC gaming",
    "start": "231150",
    "end": "236310"
  },
  {
    "text": "there's quad row for pro visualization there's our Tesla business that targets the data center in our Tegra business",
    "start": "236310",
    "end": "242669"
  },
  {
    "text": "for automotive and it's a it's a branded platform business model not a component model we don't just sell chips",
    "start": "242669",
    "end": "248880"
  },
  {
    "text": "we actually sell complete solutions for these markets so with that I want to",
    "start": "248880",
    "end": "255690"
  },
  {
    "start": "255000",
    "end": "315000"
  },
  {
    "text": "just let's start with just a little review of the two primary businesses that I was just alluding to gaming and",
    "start": "255690",
    "end": "261329"
  },
  {
    "text": "high-performance computing so Nvidia started as a gaming company as I mentioned I don't know how if you guys know how big the the gaming market is I",
    "start": "261329",
    "end": "269419"
  },
  {
    "text": "mean is it like this bigger it's actually it's exactly it's like this big it's 100 it's a hundred billion",
    "start": "269419",
    "end": "275669"
  },
  {
    "text": "dollar industry Gaming is it's the world's largest entertainment industry bigger than Hollywood and bigger than",
    "start": "275669",
    "end": "280979"
  },
  {
    "text": "pro sport and today PC game is a huge portion of the hundred billion dollar gaming market",
    "start": "280979",
    "end": "286090"
  },
  {
    "text": "it's bigger than the two consoles combined and this has been driven by the improved image quality and performance",
    "start": "286090",
    "end": "291550"
  },
  {
    "text": "of the PC backwards compatibility free-to-play games and even more",
    "start": "291550",
    "end": "296950"
  },
  {
    "text": "recently eSports in amongst these g-forces in fact the predominant brand and the PC gaming space GeForce is",
    "start": "296950",
    "end": "304030"
  },
  {
    "text": "actually the world's largest PC platform with over 200 million users so this is a big thing there's I want you to be",
    "start": "304030",
    "end": "310810"
  },
  {
    "text": "understand when I say GeForce that the connotation is PC gaming by the way just",
    "start": "310810",
    "end": "316630"
  },
  {
    "start": "315000",
    "end": "344000"
  },
  {
    "text": "as a quick side note you may be familiar Nvidia has also been involved in console gaming to the extent that we're",
    "start": "316630",
    "end": "322120"
  },
  {
    "text": "primarily focused on PCs we were actually in the original Xbox the PlayStation 3 and and now I don't know",
    "start": "322120",
    "end": "327640"
  },
  {
    "text": "if any of you are familiar with a new Nintendo switch maybe some of you have them there they tend to still be a little bit difficult to actually acquire",
    "start": "327640",
    "end": "334210"
  },
  {
    "text": "it's a unique gaming device that can switch between being a TV based console and a portable handheld device and it's",
    "start": "334210",
    "end": "340510"
  },
  {
    "text": "powered by its nvidia tegra SOC and for",
    "start": "340510",
    "end": "345640"
  },
  {
    "start": "344000",
    "end": "397000"
  },
  {
    "text": "those who you know I yep GeForce GTX great but they're expensive I don't know the one invest and putting together",
    "start": "345640",
    "end": "351430"
  },
  {
    "text": "whole PC we actually have a great solution today now for cloud gaming you can effectively get access to a high-end",
    "start": "351430",
    "end": "356860"
  },
  {
    "text": "GeForce GPU on-demand from the cloud I think probably all aware of how cloud",
    "start": "356860",
    "end": "362980"
  },
  {
    "text": "computing is revolutionising most applications out there from music and videos storage and compute GeForce now",
    "start": "362980",
    "end": "370060"
  },
  {
    "text": "is our cloud gaming service it's been likened to in some some respects and Netflix for games so now if you want to",
    "start": "370060",
    "end": "377470"
  },
  {
    "text": "you can instantly stream games that you want it's basically a game console in the sky so in fact we're this it's there",
    "start": "377470",
    "end": "384730"
  },
  {
    "text": "today you can she'll you can stream to your shield Android TV and you can also stream for free we have a Mac beta",
    "start": "384730",
    "end": "392080"
  },
  {
    "text": "program right now so you can actually go online and do that stream ok and then",
    "start": "392080",
    "end": "399850"
  },
  {
    "start": "397000",
    "end": "429000"
  },
  {
    "text": "quickly in the supercomputing field GPUs are used for many different functions but most can be divided into two groups",
    "start": "399850",
    "end": "406270"
  },
  {
    "text": "there's simulation and visualization and there's a many different applications which I'm sure many of you are aware of",
    "start": "406270",
    "end": "412510"
  },
  {
    "text": "how GPUs are used to accelerate high-performance computing solutions we talked about different simulations and",
    "start": "412510",
    "end": "418390"
  },
  {
    "text": "how they can be used from drug designs seismic automotive across the board and you there's fairly dramatic speed ups",
    "start": "418390",
    "end": "425710"
  },
  {
    "text": "that can be done when we actually use GPUs GPU computing so at this part I'm",
    "start": "425710",
    "end": "432190"
  },
  {
    "start": "429000",
    "end": "512000"
  },
  {
    "text": "going to start with the end in mind so we're gonna go in a little bit of a journey but what does a GPU look like",
    "start": "432190",
    "end": "437470"
  },
  {
    "text": "today in 2017 so this is the Tesla V 100",
    "start": "437470",
    "end": "444640"
  },
  {
    "text": "the first chip with the volta architecture this was announced earlier this year I don't know how many of you may be familiar with it and it was",
    "start": "444640",
    "end": "450670"
  },
  {
    "text": "actually more details were presented last it was in August at hot chips I don't know if any of you were there at",
    "start": "450670",
    "end": "456280"
  },
  {
    "text": "hardships and you saw this yep so it's pretty much quite the Beast 21 billion transistors 815 square millimeters in 60",
    "start": "456280",
    "end": "463960"
  },
  {
    "text": "nanometers FinFET extraordinary amount of inter GPU bandwidth memory bandwidth",
    "start": "463960",
    "end": "470650"
  },
  {
    "text": "compute bandwidth question how many of",
    "start": "470650",
    "end": "477850"
  },
  {
    "text": "course it's a good question tell you what I'm gonna come back to this and I'm",
    "start": "477850",
    "end": "483700"
  },
  {
    "text": "we're gonna go we'll go into that and some more but so I can actually develop some of that terminology but just as a",
    "start": "483700",
    "end": "489760"
  },
  {
    "text": "quick just to understand what is actually this mean it's with a chip like that what do you get you get",
    "start": "489760",
    "end": "495550"
  },
  {
    "text": "seven-and-a-half teraflops of double precision performance fifteen teraflops of single and you know marketing what a",
    "start": "495550",
    "end": "501790"
  },
  {
    "text": "mind-boggling 120 teraflops of deep learning acceleration performance in the form of our tensor course that was just",
    "start": "501790",
    "end": "507760"
  },
  {
    "text": "being discussed so the question arises how do we get here right so we Andy",
    "start": "507760",
    "end": "515380"
  },
  {
    "start": "512000",
    "end": "582000"
  },
  {
    "text": "talked to the beginning there's there were different how did the whole",
    "start": "515380",
    "end": "520510"
  },
  {
    "text": "computing market kind of evolve our CEO Jensen Wang he describes invidious performance and position today as",
    "start": "520510",
    "end": "526920"
  },
  {
    "text": "destiny meets serendipity there are people who think that this was Nvidia this company was an overnight success",
    "start": "526920",
    "end": "532390"
  },
  {
    "text": "just happen just right place but in fact like most situations like this overnight",
    "start": "532390",
    "end": "538150"
  },
  {
    "text": "overnight things actually take years to get here and that's what I want to talk through as the years it took so does to",
    "start": "538150",
    "end": "543700"
  },
  {
    "text": "describe this I want to take you as I said on a bit of a Back to the Future ride an accelerated view of some",
    "start": "543700",
    "end": "549220"
  },
  {
    "text": "CGP advances in invidious history so as",
    "start": "549220",
    "end": "555069"
  },
  {
    "text": "we do this I could talk through you these things but sometimes the common saying is a picture is worth a thousand",
    "start": "555069",
    "end": "561699"
  },
  {
    "text": "words so maybe a video is worth even more [Music]",
    "start": "561699",
    "end": "580640"
  },
  {
    "text": "okay so the the intent was to show you that we've actually developed what we've",
    "start": "581620",
    "end": "587840"
  },
  {
    "start": "582000",
    "end": "656000"
  },
  {
    "text": "developed over the 25 years and it's taken us the the GP was developed in and",
    "start": "587840",
    "end": "593270"
  },
  {
    "text": "it was first started in 1999 and that's what's being described here the sole of",
    "start": "593270",
    "end": "598910"
  },
  {
    "text": "the GPU was to accelerate computationally intensive applications so fundamentally as I showed you on my",
    "start": "598910",
    "end": "604940"
  },
  {
    "text": "initial slides the intent is to be an accelerator and the GPU was initially",
    "start": "604940",
    "end": "610310"
  },
  {
    "text": "introduced to accelerate PC gaming and 3d graphics that what was the computationally challenging problem at",
    "start": "610310",
    "end": "617060"
  },
  {
    "text": "the time and that at the time that was PC gaming and the goal was to be able to create and approach the image quality of",
    "start": "617060",
    "end": "623780"
  },
  {
    "text": "movie studio offline rendering farms but in real time so instead of hours per",
    "start": "623780",
    "end": "628940"
  },
  {
    "text": "frame the idea is how can we do the quality that you could see the basically photo realistic quality at greater than",
    "start": "628940",
    "end": "635630"
  },
  {
    "text": "60 frames per second so this involved how do we do this millions of pixels per",
    "start": "635630",
    "end": "641180"
  },
  {
    "text": "frame can in fact all be operated on in parallel and in fact people refer to the 3d graphics problem as almost",
    "start": "641180",
    "end": "647150"
  },
  {
    "text": "embarrassingly parallel so what we would do is use large arrays of floating-point units to in fact expand exploit this",
    "start": "647150",
    "end": "653900"
  },
  {
    "text": "wide and deep parallelism so some classic GPUs I said that I was going to",
    "start": "653900",
    "end": "660800"
  },
  {
    "start": "656000",
    "end": "700000"
  },
  {
    "text": "give some of my own perspectives on GPUs based on my experience and I want to",
    "start": "660800",
    "end": "666830"
  },
  {
    "text": "start by discussing one of the very first NVIDIA GPUs that I worked on so if we think about the classic GPUs briefly",
    "start": "666830",
    "end": "672830"
  },
  {
    "text": "go back to 13 years ago there was the GeForce 6 6000 series in the 7000 series",
    "start": "672830",
    "end": "678320"
  },
  {
    "text": "an example was the 7900 GTX and just to place this so there this is 13 years ago",
    "start": "678320",
    "end": "684620"
  },
  {
    "text": "with 278 million transistors 650 megahertz clock 196 square millimeters",
    "start": "684620",
    "end": "690590"
  },
  {
    "text": "in nineteen an ohmmeter 300 gigaflops of single precision can we even remember kind of when dyes look",
    "start": "690590",
    "end": "696920"
  },
  {
    "text": "like that so but this is what we had",
    "start": "696920",
    "end": "701620"
  },
  {
    "start": "700000",
    "end": "760000"
  },
  {
    "text": "in the GPU we render an image as a collection of triangles I'm not sure our people are generally familiar with 3d",
    "start": "702410",
    "end": "707959"
  },
  {
    "text": "the 3d graphics implementation and this is just a quick summary of how the",
    "start": "707959",
    "end": "714800"
  },
  {
    "text": "polygons which are the how the entire image is collected how its rendered if",
    "start": "714800",
    "end": "720079"
  },
  {
    "text": "we look at it we start with triangles coming in commands from the host processor we would then take vertices of",
    "start": "720079",
    "end": "726079"
  },
  {
    "text": "the triangles and put them through our vertex processors we would then do scan conversion where we actually create per",
    "start": "726079",
    "end": "733010"
  },
  {
    "text": "triangle data both plain equations perhaps for how different different fee",
    "start": "733010",
    "end": "739940"
  },
  {
    "text": "aspects can may vary across the triangle and then we actually do the conversion to pixels we then may do a various",
    "start": "739940",
    "end": "746930"
  },
  {
    "text": "amount of pixel shading on the actual operation using various pixel shaders we may do conditional texture mapping do",
    "start": "746930",
    "end": "753470"
  },
  {
    "text": "final raster opera aster operations and then eventually we draw out a memory so this is classic you know vanilla GPU",
    "start": "753470",
    "end": "761149"
  },
  {
    "start": "760000",
    "end": "805000"
  },
  {
    "text": "rendering and there's another brief aside we can talk about numeric representations in a GPU because we're",
    "start": "761149",
    "end": "767690"
  },
  {
    "text": "going to come back to this even for the earlier question within that within this",
    "start": "767690",
    "end": "772990"
  },
  {
    "text": "diagram that we talked about here across those functions there's all sorts of different numeric formats there's all",
    "start": "772990",
    "end": "779209"
  },
  {
    "text": "different fixed point and integer formats a variety of floating-point formats there's the classic 16-bit",
    "start": "779209",
    "end": "785120"
  },
  {
    "text": "32-bit there's the less classic 24-bit there's a variety of different formats",
    "start": "785120",
    "end": "790850"
  },
  {
    "text": "that are exist inside of a GPU and with these up there's also blocked floating-point formats where we treat",
    "start": "790850",
    "end": "796699"
  },
  {
    "text": "multiple operands is having a common exponent so there's many different representations numerix lots of",
    "start": "796699",
    "end": "802610"
  },
  {
    "text": "different processing that was happening in this classic GPU and if we actually take a look at it the way it was built",
    "start": "802610",
    "end": "808490"
  },
  {
    "start": "805000",
    "end": "851000"
  },
  {
    "text": "then you actually had we actually had a vertex fetch engine as I alluded to",
    "start": "808490",
    "end": "814760"
  },
  {
    "text": "there were eight vertex shaders the conversion to pixels 24 pixel shaders we",
    "start": "814760",
    "end": "821240"
  },
  {
    "text": "would redistribute the pixels to our various pixel engines and finally we would have our memory partitions so this",
    "start": "821240",
    "end": "829399"
  },
  {
    "text": "is what if things look like about 13 years ago now I wonder if this will actually work",
    "start": "829399",
    "end": "836319"
  },
  {
    "text": "and that doesn't seem to work either that's why okay so we were probably in",
    "start": "836330",
    "end": "843030"
  },
  {
    "text": "the interest of time we'll we'll keep going here so I was going to show you we can come back to what graphics look like",
    "start": "843030",
    "end": "850050"
  },
  {
    "text": "on those but I'm not in the interest of time we'll keep going here so into it 13",
    "start": "850050",
    "end": "857010"
  },
  {
    "start": "851000",
    "end": "955000"
  },
  {
    "text": "years ago we had pixel shaders we had vertex shaders we had this independent",
    "start": "857010",
    "end": "862110"
  },
  {
    "text": "logic you'll notice I didn't talk about general-purpose computation we just had these collections of engines working on",
    "start": "862110",
    "end": "868170"
  },
  {
    "text": "these different formats with the goal of accelerating a really hard computationally difficult problem that",
    "start": "868170",
    "end": "873300"
  },
  {
    "text": "of PC gaming PC graphics but in g80 which is about 11 years ago it really",
    "start": "873300",
    "end": "879660"
  },
  {
    "text": "redefined what the GPU was and Andy also alluded to this about and he said his",
    "start": "879660",
    "end": "884850"
  },
  {
    "text": "timing was just about right there in 2006 Nvidia released the g8 II the",
    "start": "884850",
    "end": "890100"
  },
  {
    "text": "GeForce 8800 it was the first GPU with a unified shader processor architecture",
    "start": "890100",
    "end": "895320"
  },
  {
    "text": "and it also introduced the SM streaming multiprocessor which is an array of simple streaming processors which at the",
    "start": "895320",
    "end": "902670"
  },
  {
    "text": "time were referred to as SPS but today are more commonly referred to as CUDA cores we'll get to the terminology here",
    "start": "902670",
    "end": "908810"
  },
  {
    "text": "but that there's some there's science and involved in the definition in this",
    "start": "908810",
    "end": "916590"
  },
  {
    "text": "case now that we're unified all of the shader stages use the same instruction set all the shaders they execute on the",
    "start": "916590",
    "end": "923010"
  },
  {
    "text": "same hardware and this allowed for better sharing of SM hardware resources this is based on the recognition that",
    "start": "923010",
    "end": "928200"
  },
  {
    "text": "there are underutilized hardware and we could actually get much greater utilization if instead of having",
    "start": "928200",
    "end": "933540"
  },
  {
    "text": "separate we could actually just share the common array so instead of having these independent Hardware of feature",
    "start": "933540",
    "end": "939510"
  },
  {
    "text": "Hardware shading engines for shader type a B C and D we now just had this unified",
    "start": "939510",
    "end": "945000"
  },
  {
    "text": "shader core and all of the shader types would run on that unified shader so so",
    "start": "945000",
    "end": "956880"
  },
  {
    "start": "955000",
    "end": "1046000"
  },
  {
    "text": "some commentary about this we're now up from we were at 278 million transistors 13 years ago we're now up to 681 million",
    "start": "956880",
    "end": "966120"
  },
  {
    "text": "transistors and 470 square millimeters in nineteen an ohmmeter the g80 was the first to support microsoft directx 10",
    "start": "966120",
    "end": "973490"
  },
  {
    "text": "now this is the point in what one of the key reasons I wanted to bring this GPU",
    "start": "973490",
    "end": "978510"
  },
  {
    "text": "up I know some of you depending on who you are 11 years ago was a long time",
    "start": "978510",
    "end": "984090"
  },
  {
    "text": "don't even necessarily know what you know a GPU was or what a unified shader was then but what we did then was we",
    "start": "984090",
    "end": "990060"
  },
  {
    "text": "invested a little extra hardware we referred to it as epsilon in the SM 2 also support general-purpose",
    "start": "990060",
    "end": "996680"
  },
  {
    "text": "general-purpose throughput computing and this was the beginning of CUDA everywhere so we specifically said we",
    "start": "996680",
    "end": "1003590"
  },
  {
    "text": "wanted to make an investment in this GPU to enable in Hardware general-purpose GPU computing one other interesting",
    "start": "1003590",
    "end": "1011720"
  },
  {
    "text": "thing that we did was the functional units in G 80 were designed to run at twice the clock the core clock frequency",
    "start": "1011720",
    "end": "1017720"
  },
  {
    "text": "with the goal of area efficiency we wanted to have the number of units to be as conservatory conserving as much as we",
    "start": "1017720",
    "end": "1024949"
  },
  {
    "text": "can of that at the time precious die space in this led to 576 gigaflops where",
    "start": "1024950",
    "end": "1030860"
  },
  {
    "text": "the functional units were operating at one-and-a-half gigahertz and for the first time we actually had I Triple E",
    "start": "1030860",
    "end": "1036319"
  },
  {
    "text": "compliant floating-point atom floating-point multiply in those shaders and this unified shader and it was",
    "start": "1036320",
    "end": "1041810"
  },
  {
    "text": "dissipating 155 Watts so at least from",
    "start": "1041810",
    "end": "1048920"
  },
  {
    "start": "1046000",
    "end": "1118000"
  },
  {
    "text": "one respect at least from my perspective others this was some at the beginning of GP this was the GPU beginning of GPU",
    "start": "1048920",
    "end": "1055040"
  },
  {
    "text": "computing in just a differentiate what is throughput computing versus latency",
    "start": "1055040",
    "end": "1060350"
  },
  {
    "text": "optimize latency oriented computing I would summarize it as with a traditional latency optimized computing we're trying",
    "start": "1060350",
    "end": "1067250"
  },
  {
    "text": "to minimize the amount of time per unit work and to do so this is a traditional",
    "start": "1067250",
    "end": "1072800"
  },
  {
    "text": "CPU perspective we want to have as many large cores as we can with as many large caches as we can so that we can reduce",
    "start": "1072800",
    "end": "1079460"
  },
  {
    "text": "the memory access time and in general we want to reduce the control hazard the",
    "start": "1079460",
    "end": "1084950"
  },
  {
    "text": "control hazard penalties so we would put large branch predictors speculative",
    "start": "1084950",
    "end": "1090020"
  },
  {
    "text": "execution anything we can to reduce time per unit time per unit of work in contrast throughput computing for",
    "start": "1090020",
    "end": "1096680"
  },
  {
    "text": "example GPU computing the goal is to maximize the amount of work per unit time and rather than investing in late",
    "start": "1096680",
    "end": "1103000"
  },
  {
    "text": "see reduction Hardware explicitly the goal is to have as many simple compute cores in hardware scheduling as possible",
    "start": "1103000",
    "end": "1109870"
  },
  {
    "text": "the goal being to maximize the amount of math that's available for actually doing the throughput computing so that was GA",
    "start": "1109870",
    "end": "1116770"
  },
  {
    "text": "T and as I said it was also the start of CUDA everywhere and are people aware of",
    "start": "1116770",
    "end": "1123820"
  },
  {
    "start": "1118000",
    "end": "1144000"
  },
  {
    "text": "CUDA what that is or I don't know somewhat familiar used it this was really the first time we've been able to have C and C++ available for a",
    "start": "1123820",
    "end": "1131080"
  },
  {
    "text": "throughput computing it was first made available back in 2006 with a with G 80",
    "start": "1131080",
    "end": "1136420"
  },
  {
    "text": "and base it brings throughput computing to a very accessible interface so if we",
    "start": "1136420",
    "end": "1145600"
  },
  {
    "text": "look at the G 80 architecture unlike the 7900 that I showed you now there's just",
    "start": "1145600",
    "end": "1151000"
  },
  {
    "text": "one array of processors known as streaming multi processors or SMS which are these here and this is a blow-up of",
    "start": "1151000",
    "end": "1157930"
  },
  {
    "text": "one of them these are the SPS the functional units that I talked about aka CUDA cores here and we have the same",
    "start": "1157930",
    "end": "1166570"
  },
  {
    "text": "vertex work distribution hardware to dispatch work to the array before we had independent vertex shaders we have pixel",
    "start": "1166570",
    "end": "1174700"
  },
  {
    "text": "work distribution specific hardware to distribute pixel work to the independent",
    "start": "1174700",
    "end": "1180550"
  },
  {
    "text": "to the streaming processor array and then the key investment was this",
    "start": "1180550",
    "end": "1185650"
  },
  {
    "text": "additional EPS of epsilon of hardware to support compute work distributions so we",
    "start": "1185650",
    "end": "1190810"
  },
  {
    "text": "could explicitly launch compute shaders and have them use the stringing processor array for general-purpose",
    "start": "1190810",
    "end": "1196480"
  },
  {
    "text": "computing does that make sense to everyone any questions on dat here so I mentioned",
    "start": "1196480",
    "end": "1205580"
  },
  {
    "start": "1204000",
    "end": "1325000"
  },
  {
    "text": "have different architectures or classes that are effectively define the",
    "start": "1205580",
    "end": "1210950"
  },
  {
    "text": "blueprints for a GPUs and I said that they were generally named after physicists so we had there was the first",
    "start": "1210950",
    "end": "1216560"
  },
  {
    "text": "one we had there was the six and seven thousand there was a ga T the first full",
    "start": "1216560",
    "end": "1222760"
  },
  {
    "text": "purpose intended to be build that would also enabled general-purpose computing with significant increases in",
    "start": "1222760",
    "end": "1231430"
  },
  {
    "text": "investments in what it would take to do throughput computing was the Fermi architecture G of 100 we're up to three",
    "start": "1231430",
    "end": "1238640"
  },
  {
    "text": "billion transistors now in 2011 so this is six years ago five hundred twenty-nine square millimeters and 40",
    "start": "1238640",
    "end": "1244970"
  },
  {
    "text": "nanometer 1150 gigahertz huh it means",
    "start": "1244970",
    "end": "1254470"
  },
  {
    "text": "thank you terahertz yeah we'll call that may G was supposed to be an M everything",
    "start": "1257830",
    "end": "1264170"
  },
  {
    "text": "was an M up until now so M Eggert so this is a third generation SM yes I got",
    "start": "1264170",
    "end": "1269720"
  },
  {
    "text": "that's correct so that was just the genes so one of the key contributions here was the addition of the new 2008",
    "start": "1269720",
    "end": "1279440"
  },
  {
    "text": "754 compliant fuse multiply ad unit which were able to use and deploy and we",
    "start": "1279440",
    "end": "1285200"
  },
  {
    "text": "actually in GA TI didn't explicitly call it out but the only memory access from the sm from the cuda cores was through",
    "start": "1285200",
    "end": "1291940"
  },
  {
    "text": "explicitly accessible shared memory there was no caching available directly from the processor with Fermi we",
    "start": "1291940",
    "end": "1299270"
  },
  {
    "text": "actually added a configurable l1 cache that could dual as a shared memory so we",
    "start": "1299270",
    "end": "1304550"
  },
  {
    "text": "were up to now right around a teraflop of FB 32 and a 515 gigaflops of FP 64",
    "start": "1304550",
    "end": "1311270"
  },
  {
    "text": "but you'll notice we're now up to almost 250 watts so the observation here was",
    "start": "1311270",
    "end": "1317630"
  },
  {
    "text": "that things have gotten powerful in multiple respects so we recognize that",
    "start": "1317630",
    "end": "1325000"
  },
  {
    "start": "1325000",
    "end": "1503000"
  },
  {
    "text": "and over the next two years we actually developed the the Kepler architecture",
    "start": "1325000",
    "end": "1330860"
  },
  {
    "text": "and the Tesla k40 was the a from the Tesla business that was it's instance",
    "start": "1330860",
    "end": "1338030"
  },
  {
    "text": "one of its in chances of the Kepler architecture that the gk110 was the GPU and it was",
    "start": "1338030",
    "end": "1344340"
  },
  {
    "text": "released actually in 2013 and now you see we're going even larger where it's set over seven billion transistors five",
    "start": "1344340",
    "end": "1351180"
  },
  {
    "text": "hundred and fifty square millimeters and twenty eight nanometer yeah in what and",
    "start": "1351180",
    "end": "1357360"
  },
  {
    "text": "cache went away no I don't have the cash cash the cash is there with Kepler this",
    "start": "1357360",
    "end": "1368190"
  },
  {
    "text": "is I wanted to provide a perspective we recognized the the challenges as we said",
    "start": "1368190",
    "end": "1373640"
  },
  {
    "text": "there's a number of limits that are have been we've been facing in process or",
    "start": "1373640",
    "end": "1378750"
  },
  {
    "text": "design there's there's Moore's law challenges we're getting more transistors but they're not getting faster so where do we get our",
    "start": "1378750",
    "end": "1385650"
  },
  {
    "text": "performance from you okay we have throughput computing we can put more math units down but at the limit we're",
    "start": "1385650",
    "end": "1392550"
  },
  {
    "text": "going to be power constrained we can't up until now we've been increasing power along the way so we took a step back and",
    "start": "1392550",
    "end": "1398940"
  },
  {
    "text": "we had intense focus on power efficiency and explicitly one of the things we did is remember how I said that we had our",
    "start": "1398940",
    "end": "1405300"
  },
  {
    "text": "functional units running at twice the clock frequency so I would ask the the",
    "start": "1405300",
    "end": "1410520"
  },
  {
    "text": "simple question which I would hope many people get asked is there it you know the simple equation for dynamic power",
    "start": "1410520",
    "end": "1416870"
  },
  {
    "text": "anybody talk great summarizing obviously",
    "start": "1416870",
    "end": "1427320"
  },
  {
    "text": "be squared out something of that nature so the challenge is yes we were reducing",
    "start": "1427320",
    "end": "1432690"
  },
  {
    "text": "the area but in fact to reduce the area we couldn't do it perfectly linearly but the F part was definitely doubling so in",
    "start": "1432690",
    "end": "1439590"
  },
  {
    "text": "fact we were paying a lot in power by doing that so this was a trade-off of",
    "start": "1439590",
    "end": "1444600"
  },
  {
    "text": "area efficiency versus power efficiency so we explicitly started on the go wider in a bit slower to be effect better",
    "start": "1444600",
    "end": "1452550"
  },
  {
    "text": "power efficiency in Kepler was the first to do this so we had an extreme focus on trading up area efficiency versus power",
    "start": "1452550",
    "end": "1458880"
  },
  {
    "text": "efficiency as a result we ended up it over for teraflops with this GPU in",
    "start": "1458880",
    "end": "1465150"
  },
  {
    "text": "single precision and one point for teraflops of double precision at 235",
    "start": "1465150",
    "end": "1470370"
  },
  {
    "text": "watts the single-wide it is now 1:30 it's a",
    "start": "1470370",
    "end": "1478789"
  },
  {
    "text": "good question so one could ask why 1/2 why went through the intent was it's a",
    "start": "1478789",
    "end": "1490250"
  },
  {
    "text": "good question I think that maybe this will be in the will see how time permits at the end to give the the the good",
    "start": "1490250",
    "end": "1496130"
  },
  {
    "text": "answer it was it was just a balance an investment of where we wanted to spend our diarrhea it's really that simple um",
    "start": "1496130",
    "end": "1503360"
  },
  {
    "text": "just the investment here was again in performance per watt the intent was to",
    "start": "1503360",
    "end": "1509299"
  },
  {
    "text": "be as fast and as efficient as we could so the goal was in firming to have a fixed number of cores here you can see",
    "start": "1509299",
    "end": "1515840"
  },
  {
    "text": "the ratio of control to datapath versus in Kepler where we tried to then put",
    "start": "1515840",
    "end": "1520850"
  },
  {
    "text": "down many more cores again wider and slower on the functional units and then",
    "start": "1520850",
    "end": "1527120"
  },
  {
    "text": "that actually gained us over three times in Perth per watt now the astute observer would note that this was in 28 nanometer and this is in",
    "start": "1527120",
    "end": "1536659"
  },
  {
    "text": "40 so there's more than one variable play here but together between design efficiency and process we were able to",
    "start": "1536659",
    "end": "1543590"
  },
  {
    "text": "get over 3x improvement in performance",
    "start": "1543590",
    "end": "1547179"
  },
  {
    "text": "of the Titan supercomputer at Oakridge which in 2012 I think that's the date on",
    "start": "1555220",
    "end": "1561350"
  },
  {
    "text": "that it was the world's number one open science supercomputer so that that machine was the flagship system it had",
    "start": "1561350",
    "end": "1568400"
  },
  {
    "text": "over 18,000 k40 nodes sorry K 20 nodes a",
    "start": "1568400",
    "end": "1573620"
  },
  {
    "text": "version of that and together it was over 20 petaflop x' it still is still better that's the Titan supercomputer at",
    "start": "1573620",
    "end": "1579500"
  },
  {
    "text": "Oakridge question this is Oak Ridge so it's our federal",
    "start": "1579500",
    "end": "1586970"
  },
  {
    "text": "government it's open you can make I think you can make grants to get access to the Machine all the secret stuff is",
    "start": "1586970",
    "end": "1597440"
  },
  {
    "text": "not available yeah well like networks there might be a secret computer that's",
    "start": "1597440",
    "end": "1602840"
  },
  {
    "text": "bigger someplace correct and this that there's the top500 which we can talk about but not everyone",
    "start": "1602840",
    "end": "1609900"
  },
  {
    "text": "even necessarily submits to the top 500 top 500 is something that you actively",
    "start": "1609900",
    "end": "1615180"
  },
  {
    "text": "try to bench and say here are my benchmark results so this was in 2012",
    "start": "1615180",
    "end": "1620820"
  },
  {
    "text": "and 2013 so I mentioned that we have GPUs that are instanced from classes",
    "start": "1620820",
    "end": "1627300"
  },
  {
    "text": "from architectures we've had there was Fermi there was Kepler I'm not going to",
    "start": "1627300",
    "end": "1633030"
  },
  {
    "text": "take you through there was also Maxwell over the past from 2014 and 2015 but if",
    "start": "1633030",
    "end": "1639059"
  },
  {
    "text": "we jump now to kind of recent days let's jump to 2016 have people heard of the",
    "start": "1639059",
    "end": "1644580"
  },
  {
    "start": "1642000",
    "end": "1810000"
  },
  {
    "text": "Pascal architecture maybe some of you had this was launched just last year fit",
    "start": "1644580",
    "end": "1651660"
  },
  {
    "text": "over 15 billion transistors 610 square millimeters now in 16 nanometer FinFET so this was so that going to the classic",
    "start": "1651660",
    "end": "1659540"
  },
  {
    "text": "throughputs over 10 teraflops of single precision 5 teraflops of double",
    "start": "1659540",
    "end": "1664890"
  },
  {
    "text": "precision but for the first time we actually included FP 16 as a native computing data type and we have over 21",
    "start": "1664890",
    "end": "1672360"
  },
  {
    "text": "teraflops of FP 16 with the intent of accelerating deep learning training and",
    "start": "1672360",
    "end": "1677400"
  },
  {
    "text": "inference through two other major advancements that occurred with this GPU",
    "start": "1677400",
    "end": "1683130"
  },
  {
    "text": "is we had a new we introduced a new high bandwidth mblink GPU interconnect and we started to use",
    "start": "1683130",
    "end": "1688710"
  },
  {
    "text": "new HBM to high bandwidth stack memory summarizing them here there was actually",
    "start": "1688710",
    "end": "1695370"
  },
  {
    "text": "three so three X the compute versus what we had previously with k4 T which I just showed you we actually increased the GPU",
    "start": "1695370",
    "end": "1702990"
  },
  {
    "text": "GPU interconnect bandwidth with NB link by 5x and a 3x increase in memory",
    "start": "1702990",
    "end": "1708360"
  },
  {
    "text": "bandwidth with HBM two questions on that",
    "start": "1708360",
    "end": "1715700"
  },
  {
    "text": "so we there is actually a so as I said",
    "start": "1715850",
    "end": "1724590"
  },
  {
    "text": "we instance GPUs from the class so with Pasco there was the GP 100 which is what I just described there's also we would",
    "start": "1724590",
    "end": "1731550"
  },
  {
    "text": "then instance different gaming and other markets GPUs from the class so there's",
    "start": "1731550",
    "end": "1736920"
  },
  {
    "text": "the P 102 which is the next largest GPU in that family which is actually the gaming",
    "start": "1736920",
    "end": "1743860"
  },
  {
    "text": "GPU inside the GeForce GTX 1080 TI which is today the highest end graphics that",
    "start": "1743860",
    "end": "1749890"
  },
  {
    "text": "you can get from that you can buy from GeForce I think I can derive this demo I",
    "start": "1749890",
    "end": "1758160"
  },
  {
    "text": "think you know I get my daughter's on the screen but that's not gonna help ya",
    "start": "1758160",
    "end": "1763200"
  },
  {
    "text": "BM 210 HP into stack I can show you in",
    "start": "1763200",
    "end": "1768430"
  },
  {
    "text": "terms of on top let me get back to let",
    "start": "1768430",
    "end": "1787929"
  },
  {
    "text": "me try to drive this one for one second here whilst I and get my okay here we go",
    "start": "1787929",
    "end": "1794370"
  },
  {
    "text": "right yeah yeah okay so what I wanted to",
    "start": "1794370",
    "end": "1801640"
  },
  {
    "text": "show you here is so what if you put all of those twelve billion transistors together what is game what does gaming",
    "start": "1801640",
    "end": "1808660"
  },
  {
    "text": "look like to in 2017 so this is the gtx",
    "start": "1808660",
    "end": "1814929"
  },
  {
    "start": "1810000",
    "end": "1941000"
  },
  {
    "text": "1080 TI with the GP 102 that you can this is what you can get today",
    "start": "1814929",
    "end": "1821370"
  },
  {
    "text": "[Music] so this has been in the camp",
    "start": "1821370",
    "end": "1827530"
  },
  {
    "text": "[Music] it's gonna be out actually early next year it's not even out yet but you can",
    "start": "1827530",
    "end": "1833989"
  },
  {
    "text": "see the different types of effects that are possible [Music]",
    "start": "1833989",
    "end": "1852390"
  },
  {
    "text": "disconnects to the possible [Music]",
    "start": "1852390",
    "end": "1860270"
  },
  {
    "text": "can you be gamers console perhaps",
    "start": "1860270",
    "end": "1866090"
  },
  {
    "text": "so we're really approaching the photorealism began approaching which you can do offline real-time at well over 60",
    "start": "1868380",
    "end": "1875309"
  },
  {
    "text": "frames per second",
    "start": "1875309",
    "end": "1878149"
  },
  {
    "text": "[Music] but you can absolutely I mean a",
    "start": "1884170",
    "end": "1890309"
  },
  {
    "text": "consistent perfect so interesting first of all with with this level of computing",
    "start": "1890309",
    "end": "1897419"
  },
  {
    "text": "there's no herky-jerky at this with GP with the GP 102 with over 12 billion transistors it's that",
    "start": "1897419",
    "end": "1905730"
  },
  {
    "text": "just works that said there is we have a separate technology and there's a new monitor types which I'm not sure if",
    "start": "1905730",
    "end": "1911730"
  },
  {
    "text": "you're aware but I wasn't going to cover here known as g-sync where we actually don't actually explicitly synchronize so",
    "start": "1911730",
    "end": "1918090"
  },
  {
    "text": "that you don't have this motion we can actually go much faster and ensure a very smooth playing experience you can",
    "start": "1918090",
    "end": "1923940"
  },
  {
    "text": "learn we can talk about that more offline perhaps ok so I started this",
    "start": "1923940",
    "end": "1931200"
  },
  {
    "text": "talk with the end in mind so that was 2016 mind you so here we are now in 2017 it was just one year later",
    "start": "1931200",
    "end": "1938610"
  },
  {
    "text": "and so we're back to the Volta which we",
    "start": "1938610",
    "end": "1943620"
  },
  {
    "start": "1941000",
    "end": "2067000"
  },
  {
    "text": "launched again just earlier this year which is the GV 100 so now we're up to 21 billion transistors 815 square",
    "start": "1943620",
    "end": "1951270"
  },
  {
    "text": "millimeters in 16 nanometer to be specific you can't build a bigger die in",
    "start": "1951270",
    "end": "1957450"
  },
  {
    "text": "16 because we we max the reticle that was so if we could have we would have so",
    "start": "1957450",
    "end": "1962460"
  },
  {
    "text": "again this is this the theory of go as large as you can and maximize the compute density and optimize for power",
    "start": "1962460",
    "end": "1969559"
  },
  {
    "text": "optimize as much compute as you can get into this thing and we have 80 SMS with",
    "start": "1969559",
    "end": "1974730"
  },
  {
    "text": "now we're going to the terminology of 5120 CUDA cores 640 tensor cores which",
    "start": "1974730",
    "end": "1981390"
  },
  {
    "text": "we can talk through 16 gigabytes of HBM to 900 gigabytes per second and bandwidth yeah",
    "start": "1981390",
    "end": "1989840"
  },
  {
    "text": "it's this is a v1 hundreds of 300 watt product yeah I'm just trying to see I",
    "start": "1993730",
    "end": "1999710"
  },
  {
    "text": "thought it would have actually put that on that slide but I do yeah three nerd",
    "start": "1999710",
    "end": "2006220"
  },
  {
    "text": "one it stood watch but if we compare this versus just what we had last year for comparison so for training I told",
    "start": "2006220",
    "end": "2014140"
  },
  {
    "text": "you an F P 32 with the P 100 we were at",
    "start": "2014140",
    "end": "2019690"
  },
  {
    "text": "ten teraflops F P 32 with our high with our mixed precision tensor cores were up",
    "start": "2019690",
    "end": "2025960"
  },
  {
    "text": "to 120 teraflops for a 12x improvement in training acceleration capability for",
    "start": "2025960",
    "end": "2031630"
  },
  {
    "text": "inferencing we had if you remember we had FP 16 that we added to GP 100 so",
    "start": "2031630",
    "end": "2037120"
  },
  {
    "text": "also at 120 teraflops for a 6x increase and we increased both single and double",
    "start": "2037120",
    "end": "2042159"
  },
  {
    "text": "precision HBM to bandwidth we've taken up by 20% to 900 gigabytes per second and are in",
    "start": "2042159",
    "end": "2052388"
  },
  {
    "text": "our HR envy link bandwidth we've also taken up by almost a factor of two to three hundred gigabytes per second so",
    "start": "2052389",
    "end": "2058919"
  },
  {
    "text": "it's quite quite the large machine I want to talk about so we talked about",
    "start": "2058919",
    "end": "2065440"
  },
  {
    "text": "tensor core let's see if this will actually allow us to play so Google let",
    "start": "2065440",
    "end": "2085450"
  },
  {
    "start": "2067000",
    "end": "2300000"
  },
  {
    "text": "me it's really not gonna let me play and",
    "start": "2085450",
    "end": "2095980"
  },
  {
    "text": "this one's kind of alright we'll talk it through for the moment here so the 10th the the intent of the tensor is to",
    "start": "2095980",
    "end": "2102400"
  },
  {
    "text": "accelerate some of products matrix multiplication so it's a generally",
    "start": "2102400",
    "end": "2107770"
  },
  {
    "text": "speaking we have a 4 by 4 matrix processing array that's used in many aspects of our computation gem those",
    "start": "2107770",
    "end": "2115599"
  },
  {
    "text": "those kernels exist in many many places in deep learning specifically we can",
    "start": "2115599",
    "end": "2120670"
  },
  {
    "text": "talk through how with the neural network it can be reduced in many cases to a gem the idea is to greatly improve what's",
    "start": "2120670",
    "end": "2127060"
  },
  {
    "text": "possible in that computation and so if we look at that the tensor core what we",
    "start": "2127060",
    "end": "2132430"
  },
  {
    "text": "what we're able to accelerate here is taking an MFP 16 if you have will call",
    "start": "2132430",
    "end": "2138670"
  },
  {
    "text": "them for lack of to keep it general a and B we're able to compute these assuming FP 16 inputs and",
    "start": "2138670",
    "end": "2146680"
  },
  {
    "text": "then we can accumulate with an existing accumulator that's either in FP 16 or FB",
    "start": "2146680",
    "end": "2152020"
  },
  {
    "text": "32 and then we can accumulate into either FP 16 or FP 32 so that's what",
    "start": "2152020",
    "end": "2158950"
  },
  {
    "text": "fundamentally what the tensor core does and we're able to attend sir core is defined as actually having 64 of these",
    "start": "2158950",
    "end": "2164860"
  },
  {
    "text": "think of them as 64 multiply ad units per tensor core so it's actually 128",
    "start": "2164860",
    "end": "2170380"
  },
  {
    "text": "flops that we're able to do within 1 tensor core so we have FP 16 inputs we",
    "start": "2170380",
    "end": "2181600"
  },
  {
    "text": "take we get a full precision product and then we sum with the FP 32 accumulator",
    "start": "2181600",
    "end": "2186970"
  },
  {
    "text": "and then we actually we can have more products potentially however many there",
    "start": "2186970",
    "end": "2192310"
  },
  {
    "text": "are and then we convert the result to FP 32 this part so we have so it we have",
    "start": "2192310",
    "end": "2200140"
  },
  {
    "text": "it's the accumulator and then we actually can convert we can either have an FP in FP 16 result or we can have an",
    "start": "2200140",
    "end": "2206290"
  },
  {
    "text": "FP 32 result well we actually it's not an I Triple E",
    "start": "2206290",
    "end": "2211480"
  },
  {
    "text": "it's not a final result it says sum of products at this point so at this point we have to actually get a final FP 32",
    "start": "2211480",
    "end": "2218290"
  },
  {
    "text": "result that make sense yeah okay so some",
    "start": "2218290",
    "end": "2226240"
  },
  {
    "text": "adat product operation like this is not an I Triple E operation so this is not independent mole add mola mola at 754",
    "start": "2226240",
    "end": "2234670"
  },
  {
    "text": "the I Triple E 754 standard formalizes in MMA this isn't an MMA this is",
    "start": "2234670",
    "end": "2240460"
  },
  {
    "text": "actually a sum of products it's a dot product so I'm just saying that that final result is now actually reproduced",
    "start": "2240460",
    "end": "2247390"
  },
  {
    "text": "as a standard compliant 754 FB 32",
    "start": "2247390",
    "end": "2252450"
  },
  {
    "text": "how do you want to measure it yeah I mean there's there's late this is a",
    "start": "2255900",
    "end": "2262529"
  },
  {
    "text": "throughput machine so it's kind of difficult the dependent raise rate the the next instruction rate I mean the I",
    "start": "2262529",
    "end": "2271788"
  },
  {
    "text": "guess the simple answer is it's complicated but the not and I'm not",
    "start": "2271849",
    "end": "2277650"
  },
  {
    "text": "trying to obfuscate it just depends on exactly which it tends to be that you have batched things up so that you can",
    "start": "2277650",
    "end": "2284220"
  },
  {
    "text": "achieve the throughput and that's the argument there it's no longer the actual functional unit is not particularly",
    "start": "2284220",
    "end": "2290970"
  },
  {
    "text": "longer than the single precision or double precision it's just how things are grouped and arranged I mentioned I",
    "start": "2290970",
    "end": "2301500"
  },
  {
    "start": "2300000",
    "end": "2409000"
  },
  {
    "text": "want it for completeness I want to make sure we cover also the interconnect that was increased here because if you think",
    "start": "2301500",
    "end": "2307230"
  },
  {
    "text": "about it increasing teraflops by itself is not as helpful if you don't have you",
    "start": "2307230",
    "end": "2312809"
  },
  {
    "text": "have this big eating machine you've got to feed it so it comes down to bytes per flop so we want to be able to feed it",
    "start": "2312809",
    "end": "2318960"
  },
  {
    "text": "from GPU to GPU so we want to make sure that we have the ability as you're trying to scale a problem across",
    "start": "2318960",
    "end": "2324059"
  },
  {
    "text": "multiple GPUs do we have enough bandwidth for the for all of them to interact so envy link on V 100 increases",
    "start": "2324059",
    "end": "2330990"
  },
  {
    "text": "that and you can actually see the possible arrangements that we have here this is an example of the in one",
    "start": "2330990",
    "end": "2341609"
  },
  {
    "text": "arrangement and one product is the dgx one arrangement which i'll talk about",
    "start": "2341609",
    "end": "2346680"
  },
  {
    "text": "this is eight Voltas put together there's the node that I'll talk about here where actually maybe now I'll come",
    "start": "2346680",
    "end": "2355049"
  },
  {
    "text": "back to that we have a note we have nodes where we connect with IBM power P nine processors and they allow for a",
    "start": "2355049",
    "end": "2361829"
  },
  {
    "text": "high-performance interconnect with the power processors as well as other V 100's so we've increased with tensor we",
    "start": "2361829",
    "end": "2370559"
  },
  {
    "text": "increased with envy link bandwidth and we've also we talked about the caches",
    "start": "2370559",
    "end": "2376140"
  },
  {
    "text": "earlier the caches are present all the way through here in fact what we've done here is created a new type of a more CPU",
    "start": "2376140",
    "end": "2383970"
  },
  {
    "text": "style l1 cache in the 100 where it has a there's still flexibility with",
    "start": "2383970",
    "end": "2391040"
  },
  {
    "text": "shared memory but we actually have additional the ability to actually use a",
    "start": "2391040",
    "end": "2396320"
  },
  {
    "text": "larger l1 cache directly so this now starts to look very much like a more recognizable computing engine with cat",
    "start": "2396320",
    "end": "2405440"
  },
  {
    "text": "with proper cache with proper compute units so in fact I mentioned Titan",
    "start": "2405440",
    "end": "2412250"
  },
  {
    "start": "2409000",
    "end": "2593000"
  },
  {
    "text": "earlier so due out later this year I think it's they're starting to be set",
    "start": "2412250",
    "end": "2417500"
  },
  {
    "text": "up and available for generally online next year Oakridge is upgrading through",
    "start": "2417500",
    "end": "2423350"
  },
  {
    "text": "coral the collaboration of Oakridge Oregon and Livermore two new supercomputers summit at Oak Ridge and",
    "start": "2423350",
    "end": "2430550"
  },
  {
    "text": "Sierra at Lawrence Livermore ins Livermore which is have a large number",
    "start": "2430550",
    "end": "2435830"
  },
  {
    "text": "of power nines plus voltage GPUs I hook together in the configurations that I",
    "start": "2435830",
    "end": "2442070"
  },
  {
    "text": "was just showing on the previous slide enabling 40 teraflops per node and it'll",
    "start": "2442070",
    "end": "2447470"
  },
  {
    "text": "be between 100 to 300 150 to 300 peda flops for each of these so this is gonna",
    "start": "2447470",
    "end": "2453230"
  },
  {
    "text": "be a major step forward these are expected to be in 2018 but should be near the top of the top 500 if not the",
    "start": "2453230",
    "end": "2460160"
  },
  {
    "text": "top let's see I'm as it is Tesla GPUs today are between Pascal and soon with",
    "start": "2460160",
    "end": "2467420"
  },
  {
    "text": "Volta are powering the top 15 most energy-efficient supercomputers already on the green the top green 500 so yeah",
    "start": "2467420",
    "end": "2477760"
  },
  {
    "text": "any questions then on Volta and on these supercomputers actually very mature",
    "start": "2477760",
    "end": "2500690"
  },
  {
    "text": "process so that's I mean it is but there",
    "start": "2500690",
    "end": "2506570"
  },
  {
    "text": "are fractions that where there will be dye failures we actually it's a pretty standard approach of any massively",
    "start": "2506570",
    "end": "2513740"
  },
  {
    "text": "parallel machines where we make sure we can accommodate failures and understand how we can still use silicon for",
    "start": "2513740",
    "end": "2519350"
  },
  {
    "text": "different for different instances of the class if you will I",
    "start": "2519350",
    "end": "2526390"
  },
  {
    "text": "mean this is engineered to ensure that we can interface so I should in the",
    "start": "2528130",
    "end": "2586010"
  },
  {
    "text": "interest of time I'll keep going here Andy at the point at the beginning he said I want to make sure you're gonna",
    "start": "2586010",
    "end": "2591230"
  },
  {
    "text": "talk about Moore's law here and what what does that have how is that playing out here so I just want to have my the",
    "start": "2591230",
    "end": "2596780"
  },
  {
    "text": "slide here that we want to talk about here because so far we've taking it at v100 i've taking you to high-performance",
    "start": "2596780",
    "end": "2601910"
  },
  {
    "text": "computing this is where we're at today so where do we go from here in the last you know 15 minutes hopefully I can talk",
    "start": "2601910",
    "end": "2607670"
  },
  {
    "text": "through this rather quickly we've seen that Moore's law the gray line we continue to have increasing number of",
    "start": "2607670",
    "end": "2614630"
  },
  {
    "text": "transistors but the single-threaded performance that's been deliverable has been topping out up to 10 percent per",
    "start": "2614630",
    "end": "2621200"
  },
  {
    "text": "year so as I told you back in 2016 a 2006 we started an investment in GPU",
    "start": "2621200",
    "end": "2627350"
  },
  {
    "text": "computing and in fact if we've been following that trend we've been getting about 1.5 X per year following that",
    "start": "2627350",
    "end": "2632480"
  },
  {
    "text": "trend so in fact things are actually quite alive as you're suggesting what do we need to do with there is a solution",
    "start": "2632480",
    "end": "2638570"
  },
  {
    "text": "there and we refer to this combination of of availability of algorithms with",
    "start": "2638570",
    "end": "2647360"
  },
  {
    "text": "the combination of GPU computing with the combination of big data is what's led us to the viability in the",
    "start": "2647360",
    "end": "2654540"
  },
  {
    "text": "bang of deep learning the question is why now what's happened was a some fluke the answer is no it's the conglomeration",
    "start": "2654540",
    "end": "2661230"
  },
  {
    "text": "of these three things big data algorithms and massive computing capability those together are why deep",
    "start": "2661230",
    "end": "2668100"
  },
  {
    "text": "learning is such a big topic innovate and really being put to use today we're",
    "start": "2668100",
    "end": "2683940"
  },
  {
    "text": "working hard to ensure that that trend so I on this yeah deep learning everywhere probably folks",
    "start": "2683940",
    "end": "2690450"
  },
  {
    "text": "be here they're very aware of what deep learning is where it's how its deployed in the internet medicine and media",
    "start": "2690450",
    "end": "2696660"
  },
  {
    "text": "security defense autonomous machines any any further discussion on that we'll",
    "start": "2696660",
    "end": "2702330"
  },
  {
    "text": "come back talk about it great lengths people are aware of these are the ubiquitous slides what is a deep neural",
    "start": "2702330",
    "end": "2709200"
  },
  {
    "start": "2703000",
    "end": "2911000"
  },
  {
    "text": "network densely connected layer are people sufficiently familiar with the",
    "start": "2709200",
    "end": "2715170"
  },
  {
    "text": "general topic yes okay so m'a nodes here a generalized",
    "start": "2715170",
    "end": "2722400"
  },
  {
    "text": "construction of a note and a neural network on the right and in general what it can if we look at a fully connected",
    "start": "2722400",
    "end": "2728340"
  },
  {
    "text": "layer we can actually start to form how you actually compute the the neuron at the next step involves a dot product and",
    "start": "2728340",
    "end": "2735620"
  },
  {
    "text": "then if we combine the dot products in certain ways eventually this is going to",
    "start": "2735620",
    "end": "2741030"
  },
  {
    "text": "come down to look like when we actually put it together matrix multiplication so we can collapse",
    "start": "2741030",
    "end": "2747570"
  },
  {
    "text": "all of the general operations in traversing and computing a deep neural network via some aspect of matrix",
    "start": "2747570",
    "end": "2754170"
  },
  {
    "text": "multiplication which is what we've demonstrated heretofore we've made sure that the GPU can really accelerate those",
    "start": "2754170",
    "end": "2760200"
  },
  {
    "text": "operations that we operate it's do we",
    "start": "2760200",
    "end": "2766770"
  },
  {
    "text": "tensor it's part of that it's a representation with regards to that but we can we can talk about that later",
    "start": "2766770",
    "end": "2774470"
  },
  {
    "text": "okay so we a lot about the hardware I also wanted",
    "start": "2774470",
    "end": "2779530"
  },
  {
    "text": "to talk about the fact that how do you actually use deep learning deep learning",
    "start": "2779530",
    "end": "2788250"
  },
  {
    "text": "[Music] now we're trying to blur the line because really everything is GPU",
    "start": "2799500",
    "end": "2806320"
  },
  {
    "text": "computing we view more of that graphics how do we actually represent graphics as",
    "start": "2806320",
    "end": "2811420"
  },
  {
    "text": "being some aspect of general-purpose computing so it's really everything is",
    "start": "2811420",
    "end": "2818020"
  },
  {
    "text": "becoming really focused in and converging more on SM centric",
    "start": "2818020",
    "end": "2823090"
  },
  {
    "text": "programmability and graphics is everything is becoming more general-purpose compute the shaders",
    "start": "2823090",
    "end": "2829090"
  },
  {
    "text": "themselves everything are more so there are still certainly pieces that are fixed function but it's really kind of",
    "start": "2829090",
    "end": "2834520"
  },
  {
    "text": "gone the other way we have this big general-purpose GPU computing engine with some amounts of",
    "start": "2834520",
    "end": "2841150"
  },
  {
    "text": "fixed function Hardware that's still necessary to ensure adequate acceleration of raster graphics but it's",
    "start": "2841150",
    "end": "2847600"
  },
  {
    "text": "converging and we're seeing how that balance out balances out over time so I",
    "start": "2847600",
    "end": "2853030"
  },
  {
    "text": "think that the answer is its most of the hardware is to support GPU computing and",
    "start": "2853030",
    "end": "2861300"
  },
  {
    "text": "with in this paradigm its how do you",
    "start": "2861300",
    "end": "2867250"
  },
  {
    "text": "actually deploy its hardware's great but I also opened with we're not just selling GPUs just GPUs it's a platform",
    "start": "2867250",
    "end": "2873730"
  },
  {
    "text": "how does that work you actually need an entire system where you can actually do training create the networks given to",
    "start": "2873730",
    "end": "2882280"
  },
  {
    "text": "implement the networks with inference perhaps then put them on a device you might actually get some telemetry from",
    "start": "2882280",
    "end": "2888610"
  },
  {
    "text": "the device suggesting new data refined model retrained model to get better a",
    "start": "2888610",
    "end": "2897120"
  },
  {
    "text": "more accurate model in the process repeats so the challenge is to actually have a way to do this and I have this",
    "start": "2897120",
    "end": "2904360"
  },
  {
    "text": "entire equals ecosystem and how do you even write to this going to the software engineering question how are they",
    "start": "2904360",
    "end": "2910060"
  },
  {
    "text": "deployed how is this computing model just just to reiterate what we probably",
    "start": "2910060",
    "end": "2915970"
  },
  {
    "start": "2911000",
    "end": "3015000"
  },
  {
    "text": "know 2012 we've seen with an image net massive increases with deep learning and",
    "start": "2915970",
    "end": "2921850"
  },
  {
    "text": "speech recognition accuracy with deep learning I presume many of you have seen",
    "start": "2921850",
    "end": "2927310"
  },
  {
    "text": "slides like this before to show that in fact this is when the GPU is first applied to image net and where we're at",
    "start": "2927310",
    "end": "2932890"
  },
  {
    "text": "actually with speech recognition in 2016 question done using big data centers",
    "start": "2932890",
    "end": "2940270"
  },
  {
    "text": "with massive amounts of memory how far are we from able for me to able to do",
    "start": "2940270",
    "end": "2945610"
  },
  {
    "text": "that on the turret sure when you say that was which is that that the BMV",
    "start": "2945610",
    "end": "2951600"
  },
  {
    "text": "increase in image net accuracy this was actually done this was actually done on",
    "start": "2951600",
    "end": "2956890"
  },
  {
    "text": "available GPUs Alex Minich Tchaikovsky",
    "start": "2956890",
    "end": "2962800"
  },
  {
    "text": "he did it with the available GPUs that were there two of them they were just there and he worked together and it was",
    "start": "2962800",
    "end": "2969840"
  },
  {
    "text": "it was done very engineered solution with the hardware that was available in 2012 nvidia gpus off-the-shelf how far",
    "start": "2969840",
    "end": "2976990"
  },
  {
    "text": "how far are we immediately do does a single Nvidia chip you can I mean it",
    "start": "2976990",
    "end": "2983110"
  },
  {
    "text": "depends on what it is image that image net specifically crossa finding the dog",
    "start": "2983110",
    "end": "2989650"
  },
  {
    "text": "cat elephant that's very much intractable I won't say solved but it's a very that can be done I think now",
    "start": "2989650",
    "end": "2995710"
  },
  {
    "text": "people talk about like is it right now I think I don't have a number of hours but",
    "start": "2995710",
    "end": "3000720"
  },
  {
    "text": "with simple image net with the simplest models it's very short periods of time with GPUs that's why that's not even you",
    "start": "3000720",
    "end": "3006960"
  },
  {
    "text": "generally considered a representative network for any sort of benchmarking because it's almost too simple that's",
    "start": "3006960",
    "end": "3013650"
  },
  {
    "text": "hard we're gonna get to that just a second so we can talk about what's actually happened over the past we just",
    "start": "3013650",
    "end": "3021270"
  },
  {
    "text": "in the recent years Atari in 2015 we talked about image net alphago people",
    "start": "3021270",
    "end": "3026790"
  },
  {
    "text": "watched up ago last year when Lisa doll actually um oops sorry",
    "start": "3026790",
    "end": "3035030"
  },
  {
    "text": "let me scroll this way again yeah it was March that's what I'm trying to get out of five games alphago from deep mine actually beat the",
    "start": "3040630",
    "end": "3048460"
  },
  {
    "text": "world's leader the the world champion of alphago we have conversational speech recognition in fact lip-reading",
    "start": "3048460",
    "end": "3055630"
  },
  {
    "text": "I think in 2016 Microsoft Research has basically achieved human parity and",
    "start": "3055630",
    "end": "3063010"
  },
  {
    "text": "speech recognition and AI has been reported to demonstrate lip-reading performance that actually beats professional lip readers so basically",
    "start": "3063010",
    "end": "3070450"
  },
  {
    "text": "the TAT of the tasks that humans can do of certain forms machines are already at",
    "start": "3070450",
    "end": "3077770"
  },
  {
    "text": "superhuman capabilities now to your question if you look at here's on the",
    "start": "3077770",
    "end": "3083170"
  },
  {
    "start": "3081000",
    "end": "3158000"
  },
  {
    "text": "left here's an advanced version of image of a CNN for image recognition if you",
    "start": "3083170",
    "end": "3088360"
  },
  {
    "text": "take a look at how complex are the models and how much computation is needed to run the model in 2015 it was",
    "start": "3088360",
    "end": "3094630"
  },
  {
    "text": "about 60 million parameters and 7xo flops Baidu's deep speech model is about",
    "start": "3094630",
    "end": "3100180"
  },
  {
    "text": "three times more computing intensive at 300 million parameters and google's neural machine translation that the real",
    "start": "3100180",
    "end": "3106690"
  },
  {
    "text": "hard natural language probably get works up to 105 exa flops over 8 billion",
    "start": "3106690",
    "end": "3112330"
  },
  {
    "text": "parameters so models are really exploding in the requirements to be able to do these super human achievements",
    "start": "3112330",
    "end": "3118480"
  },
  {
    "text": "requires massive computing and massive bandwidths so that's what NVIDIA is in",
    "start": "3118480",
    "end": "3124180"
  },
  {
    "text": "the business of accelerating these hard computational problems as I opened with so let's see the platform that's",
    "start": "3124180",
    "end": "3133060"
  },
  {
    "text": "actually provided and what we have again it's not just a GPU it's a system so we",
    "start": "3133060",
    "end": "3138190"
  },
  {
    "text": "actually have a whole infrastructure that allows for both providing data",
    "start": "3138190",
    "end": "3143370"
  },
  {
    "text": "testing data training data conveying this data to a mechanism to a runtime",
    "start": "3143370",
    "end": "3150340"
  },
  {
    "text": "environment where we can actually then deploy it in the form of inference and this is the end-to-end platform so I",
    "start": "3150340",
    "end": "3157300"
  },
  {
    "text": "want to talk about training the question",
    "start": "3157300",
    "end": "3164320"
  },
  {
    "start": "3158000",
    "end": "3365000"
  },
  {
    "text": "is how if you wanted to one of these systems today this is where it gets interesting so ok I'm all in I want to",
    "start": "3164320",
    "end": "3171250"
  },
  {
    "text": "go I want a V 100 and I want to get going training so the first thing you can actually do is buy what's known as an nvidia dgx",
    "start": "3171250",
    "end": "3178420"
  },
  {
    "text": "station today a personal dgx this actually has four V 100's together fully",
    "start": "3178420",
    "end": "3184270"
  },
  {
    "text": "connected with envy link and it consumes 1500 watts it's water-cooled yeah exactly not too",
    "start": "3184270",
    "end": "3191410"
  },
  {
    "text": "bad I mean a hairdryer is yeah 1500 watt but you get almost a half a petaflop there 480 teraflops so just to put a",
    "start": "3191410",
    "end": "3199300"
  },
  {
    "text": "little bit perspective $69 for big ai if",
    "start": "3199300",
    "end": "3231670"
  },
  {
    "text": "you want to start building a phone system the essential instrument of AI research we have the DG x1 which is",
    "start": "3231670",
    "end": "3237220"
  },
  {
    "text": "actually 8 V 100's connect and I showed you this topology earlier with connected via NV link that gets us just a hair",
    "start": "3237220",
    "end": "3244630"
  },
  {
    "text": "short of a petaflop in a in a system it's a we call it it's equivalent to 400",
    "start": "3244630",
    "end": "3249790"
  },
  {
    "text": "servers in a box it's about this big so",
    "start": "3249790",
    "end": "3256810"
  },
  {
    "text": "I with my video that would explain this function the key thing with these is",
    "start": "3256810",
    "end": "3262660"
  },
  {
    "text": "literally in deep learning in a box all of the frameworks are in there all of the software the only thing you supply",
    "start": "3262660",
    "end": "3268780"
  },
  {
    "text": "effectively is either 120 or 240 plus depending and then your data you're",
    "start": "3268780",
    "end": "3284080"
  },
  {
    "text": "looking for cats and that's the frameworks the frameworks where you actually write your networks all of the",
    "start": "3284080",
    "end": "3290440"
  },
  {
    "text": "networks are there what languages is the framework written in I mean so for example tensorflow is a common",
    "start": "3290440",
    "end": "3295810"
  },
  {
    "text": "tensorflow cafe which generally are cut by Concord is good know I thought in tensorflow",
    "start": "3295810",
    "end": "3301599"
  },
  {
    "text": "in higher level there's Kerris there's abstractions above that how to deploy a",
    "start": "3301599",
    "end": "3306670"
  },
  {
    "text": "deep and work is we can talk about that later that's a subject about even longer dissension so references like email okay",
    "start": "3306670",
    "end": "3313430"
  },
  {
    "text": "yeah exactly so we can talk about what a",
    "start": "3313430",
    "end": "3320300"
  },
  {
    "text": "dgx one can actually do and now you're actually talking about one of the biggest resonate imagenet questions i",
    "start": "3320300",
    "end": "3327140"
  },
  {
    "text": "think you're asking about you can do a resonate 50 on a one of these systems in a little over seven hours for example",
    "start": "3327140",
    "end": "3334070"
  },
  {
    "text": "you said when can we do it that's in red this isn't a simple alex net this is a full resin at 50 and even compared to",
    "start": "3334070",
    "end": "3341510"
  },
  {
    "text": "what the GP 100 system was last year it's already almost a factor of it's",
    "start": "3341510",
    "end": "3347000"
  },
  {
    "text": "over a factor of two and a half to three times faster than what was available just last year okay just to answer the",
    "start": "3347000",
    "end": "3356690"
  },
  {
    "text": "question of tensor RT in inference and how do you use it tensor RT is our runtime inference",
    "start": "3356690",
    "end": "3361820"
  },
  {
    "text": "environment and this is the this is it here I'll summarize here its how once",
    "start": "3361820",
    "end": "3368630"
  },
  {
    "start": "3365000",
    "end": "3414000"
  },
  {
    "text": "you've got this network we just trained it real fast we did all of that what do you do with it right I actually want to",
    "start": "3368630",
    "end": "3374120"
  },
  {
    "text": "use a network to do to my is it driving my car what is it that you're doing so",
    "start": "3374120",
    "end": "3379250"
  },
  {
    "text": "tensor RT is the platform the system by which we take that network and we do all sorts of optimizations and reduce it",
    "start": "3379250",
    "end": "3386150"
  },
  {
    "text": "into a form that can actually be then implemented for inference and some examples of this are on the Left could",
    "start": "3386150",
    "end": "3392960"
  },
  {
    "text": "be a network you know that comes in framed big network perhaps with some",
    "start": "3392960",
    "end": "3398120"
  },
  {
    "text": "extra many levels and layers that may not exactly be needed at the end tensor",
    "start": "3398120",
    "end": "3403820"
  },
  {
    "text": "RT comes and analyzes it and optimizes it to find what is absolutely necessary",
    "start": "3403820",
    "end": "3408950"
  },
  {
    "text": "to optimize it for implementation and you might say well why does that matter but if you look here's a v100 on the if",
    "start": "3408950",
    "end": "3417770"
  },
  {
    "start": "3414000",
    "end": "3475000"
  },
  {
    "text": "we look at what's possible if you just implemented inference straight with a v100 straight with tensor flow as is",
    "start": "3417770",
    "end": "3424070"
  },
  {
    "text": "this is images per second 305 but when you do the optimizations what you",
    "start": "3424070",
    "end": "3429140"
  },
  {
    "text": "through tensor RT to actually make an optimal implementation we can get over",
    "start": "3429140",
    "end": "3434230"
  },
  {
    "text": "5,700 images per second so basically it's 18 times faster than if you just used a raw tensor flow implementation",
    "start": "3434230",
    "end": "3441530"
  },
  {
    "text": "and it's 40 times faster than CPU alone well this was a resident 50 I have it's",
    "start": "3441530",
    "end": "3449840"
  },
  {
    "text": "just resident 50 batches I have all the details on here which I can make available so times getting a little bit",
    "start": "3449840",
    "end": "3457100"
  },
  {
    "text": "long just to confirm time check I have a few more slides is that doable okay just",
    "start": "3457100",
    "end": "3463220"
  },
  {
    "text": "want to make sure because there's another hot topic that I alluded to we remember we said there was gaming there was GeForce datacenter Tesla we talked",
    "start": "3463220",
    "end": "3469910"
  },
  {
    "text": "about that there was another one automotive and that's another one that people might be interested in hearing a little bit about and as you can expect",
    "start": "3469910",
    "end": "3478120"
  },
  {
    "start": "3475000",
    "end": "3502000"
  },
  {
    "text": "we believe a AI is the solution to self-driving cars for all of the what's necessary for perception for reasoning",
    "start": "3478120",
    "end": "3484220"
  },
  {
    "text": "for driving for HD mapping for mapping for AI computing there's a ton of",
    "start": "3484220",
    "end": "3491810"
  },
  {
    "text": "Technology a ton of discussion we had a tutorial at hot chips just two months ago just on this topic so I'm not gonna",
    "start": "3491810",
    "end": "3498980"
  },
  {
    "text": "have time to give this all that it's due however let me just tell you a few things in addition to the big GPUs that",
    "start": "3498980",
    "end": "3505790"
  },
  {
    "start": "3502000",
    "end": "3534000"
  },
  {
    "text": "we talked about we also have SOC s that are targeting next-generation AI for",
    "start": "3505790",
    "end": "3511880"
  },
  {
    "text": "automotive parker's the example that's out in the in the market today it's based on that Pascal architecture",
    "start": "3511880",
    "end": "3517670"
  },
  {
    "text": "remember we had the big one GP 100 we have the 102 that's in our GeForce and we have Parker that's there for",
    "start": "3517670",
    "end": "3523880"
  },
  {
    "text": "automotive has one-and-a-half teraflops has our Nvidia zone arms 64 Denver CPU",
    "start": "3523880",
    "end": "3532120"
  },
  {
    "text": "and in fact what we do is we put these together to form an entire compute",
    "start": "3532120",
    "end": "3538130"
  },
  {
    "start": "3534000",
    "end": "3599000"
  },
  {
    "text": "complex called Drive px 2 which comprises a pass code discrete GPU it's",
    "start": "3538130",
    "end": "3545090"
  },
  {
    "text": "actually what an even smaller version of the of the GPU that we the GTX 1080 Ti",
    "start": "3545090",
    "end": "3551450"
  },
  {
    "text": "it's actually a smaller version of that GPU combined with the SOC and together this is an entire system that you can",
    "start": "3551450",
    "end": "3557960"
  },
  {
    "text": "then put in some number of these directly into a car massive amounts of i/o bandwidth it's well beyond the scope",
    "start": "3557960",
    "end": "3563870"
  },
  {
    "text": "of what I can talk about here but basically all of the telemetry that needs to come in from all of the sensors in a car goes into this compute complex",
    "start": "3563870",
    "end": "3570920"
  },
  {
    "text": "and gives you the capability for writing autonomous vehicle capability",
    "start": "3570920",
    "end": "3576710"
  },
  {
    "text": "yes in order to implement a Saudi there's",
    "start": "3576710",
    "end": "3583820"
  },
  {
    "text": "specific control features that have to actually be implemented to watch over the system this is independent of the",
    "start": "3583820",
    "end": "3591320"
  },
  {
    "text": "actual two six two six two design capability of which is necessary for that yeah this there's whole standards",
    "start": "3591320",
    "end": "3605180"
  },
  {
    "text": "on how that how the safety mechanisms work within a system that's qualified promotive briefly as we look between as",
    "start": "3605180",
    "end": "3615880"
  },
  {
    "text": "we go from today to level two to level three to level four into level five what's necessary as I mentioned we have",
    "start": "3615880",
    "end": "3623510"
  },
  {
    "text": "one architecture that's driving this we have Drive px two today which is to Parker's and to pascals and going",
    "start": "3623510",
    "end": "3630470"
  },
  {
    "text": "forward in time we've actually announced and I'll show you I think on a subsequent slide xavier at 30 tops and",
    "start": "3630470",
    "end": "3636020"
  },
  {
    "text": "30 watts and you we can see that the need as we increase in our autonomous capability the need for a higher tops",
    "start": "3636020",
    "end": "3643370"
  },
  {
    "text": "terror operations per second goes up you can see that it's in the it's well over a hundred tops we believe to be able to",
    "start": "3643370",
    "end": "3649370"
  },
  {
    "text": "support through level five and just as a quick they're quick saviors in fact the",
    "start": "3649370",
    "end": "3657860"
  },
  {
    "text": "next generation processor for autonomous machines and you can see it's got a collection of domain-specific",
    "start": "3657860",
    "end": "3665050"
  },
  {
    "text": "accelerators plus general-purpose they there's a CPU there's CUDA GPU and there",
    "start": "3665050",
    "end": "3671270"
  },
  {
    "text": "was a request to talk about DLA I think people I don't know if people have heard about DLA which is invidious Hardware",
    "start": "3671270",
    "end": "3678320"
  },
  {
    "text": "inference engine targeting accelerating directly accelerating neural networks",
    "start": "3678320",
    "end": "3684140"
  },
  {
    "text": "which is on this SOC but just in the past we announced it earlier this year",
    "start": "3684140",
    "end": "3690110"
  },
  {
    "text": "but just a nap but it's actually available on github now we've actually open sourced the DLA so it's there today",
    "start": "3690110",
    "end": "3697430"
  },
  {
    "text": "I can provide references but just wanted to let you know this has been announced and it's actually there today so if you",
    "start": "3697430",
    "end": "3704750"
  },
  {
    "text": "want to actually go build an inference engine there's a number of people are doing this we actually have accelerated the process",
    "start": "3704750",
    "end": "3710300"
  },
  {
    "text": "you can actually go and have the RTL there and you can actually build one so",
    "start": "3710300",
    "end": "3718240"
  },
  {
    "text": "in summary the drive px 2 it is end end self-driving car platform has all of the",
    "start": "3718240",
    "end": "3725630"
  },
  {
    "text": "pieces you can see we've tried to pull all the pieces together what's necessary you have all over the frame works on",
    "start": "3725630",
    "end": "3731480"
  },
  {
    "text": "that DG x1 that big box that comes there you take the telemetry the data that you've acquired on your drive px 2 from",
    "start": "3731480",
    "end": "3738710"
  },
  {
    "text": "your machine feed it into a network under DG x1 train train train put it out",
    "start": "3738710",
    "end": "3744250"
  },
  {
    "text": "lather rinse repeat that's how the cycle goes for the self-driving car platform",
    "start": "3744250",
    "end": "3749470"
  },
  {
    "text": "and just to make sure that we understand some examples of why this has even",
    "start": "3749470",
    "end": "3756740"
  },
  {
    "text": "required I'm just want to give you some examples of what imager is required for autonomous vehicles detecting people in",
    "start": "3756740",
    "end": "3762349"
  },
  {
    "text": "other cars so using a train network is critical to these tasks so if we look at",
    "start": "3762349",
    "end": "3767570"
  },
  {
    "text": "what is current driver assist this is what we generally have in cars today pre",
    "start": "3767570",
    "end": "3772580"
  },
  {
    "text": "autonomous vehicles now actually a",
    "start": "3772580",
    "end": "3777730"
  },
  {
    "text": "traditional ATS system can react as simple events like approaching another car too fast so for example the kind of",
    "start": "3777730",
    "end": "3785540"
  },
  {
    "text": "you can determine that the road in front of you is unobstructed and free to free to proceed but if there's a vehicle that",
    "start": "3785540",
    "end": "3791480"
  },
  {
    "text": "are there special cases to consider so this is what's possible you know today we see here what what what can be done",
    "start": "3791480",
    "end": "3799869"
  },
  {
    "text": "we can't can we proceed but what if there's a school bus their situation is different can we proceed now",
    "start": "3799869",
    "end": "3805720"
  },
  {
    "text": "now you can't what if the driver opens the door what if there's a pedestrian",
    "start": "3805720",
    "end": "3812050"
  },
  {
    "text": "are they in the street or they on the sidewalk these are all the questions that I mean these are just some very",
    "start": "3812050",
    "end": "3817280"
  },
  {
    "text": "simple thought experiment problems of what do you have to do to fundamentally a cards job is going to be don't hit",
    "start": "3817280",
    "end": "3824660"
  },
  {
    "text": "anything that's right that's seriously but that's huh I mean that's what we do a hard job is to make sure it can't hit",
    "start": "3824660",
    "end": "3831440"
  },
  {
    "text": "anything but how do you make that determination without just standing still you have to actually make progress while avoiding any collisions that's the",
    "start": "3831440",
    "end": "3839300"
  },
  {
    "text": "challenge so what's that exactly so the current does",
    "start": "3839300",
    "end": "3848000"
  },
  {
    "text": "a current driver system isn't sophisticated enough to handle all of these and to the point trying to program",
    "start": "3848000",
    "end": "3854030"
  },
  {
    "text": "it directly would take forever how I mean what are you gonna do sedan said today we've thought of these cases you can't do it that's why a deep learning",
    "start": "3854030",
    "end": "3861200"
  },
  {
    "text": "comes into play and instead of that having that you put in DN n in there and this can be trained literally through",
    "start": "3861200",
    "end": "3867740"
  },
  {
    "text": "hundreds and thousands of hours of actual driving you can actually train the network to handle everything if you",
    "start": "3867740",
    "end": "3873890"
  },
  {
    "text": "think about it if you have a child who's 15 training trying to get a driver's license that's exactly what they do they",
    "start": "3873890",
    "end": "3880250"
  },
  {
    "text": "go on the road in fact they only need 50 hours in the state of California they get trained their neural network up here",
    "start": "3880250",
    "end": "3885800"
  },
  {
    "text": "gets trained to be able to drive the road we can do at least as well with DNS",
    "start": "3885800",
    "end": "3891880"
  },
  {
    "text": "so I'm out of I think I'm pretty much out of time yep I do want to make a",
    "start": "3891880",
    "end": "3897020"
  },
  {
    "text": "final call here we can talk more try to even do demos afterwards I do want to make the call that working it in video",
    "start": "3897020",
    "end": "3904310"
  },
  {
    "text": "is possible in fact we're open to it just want to let people know that like",
    "start": "3904310",
    "end": "3911030"
  },
  {
    "text": "the machines themselves we as a company have been ourselves consider ourselves a learning machine reinventing ourselves",
    "start": "3911030",
    "end": "3916550"
  },
  {
    "text": "in 96 I talked about 2006 and what we did just last year in 2016 what's going",
    "start": "3916550",
    "end": "3922280"
  },
  {
    "text": "on in the kid we're trying to evolve and adapt to the new opportunities that really matter not just us into the world",
    "start": "3922280",
    "end": "3929440"
  },
  {
    "text": "it's a great place to work so there are people who are interested a little bit about us and yeah we'd love to have",
    "start": "3929440",
    "end": "3936200"
  },
  {
    "text": "interns new grads open for Oh in fact next week first of all we have some",
    "start": "3936200",
    "end": "3942710"
  },
  {
    "text": "folks here who we can come talk to afterwards if you want next week I know there's the career fair on campus next Wednesday please come out and see us we",
    "start": "3942710",
    "end": "3949340"
  },
  {
    "text": "have openings any of this sounds exciting and hardware and software and systems and deep learning we have",
    "start": "3949340",
    "end": "3955130"
  },
  {
    "text": "opportunities in all of these areas so I welcome you to come talk with me talk with my colleagues afterwards or come to",
    "start": "3955130",
    "end": "3960920"
  },
  {
    "text": "the Career Fair next week thank you you",
    "start": "3960920",
    "end": "3966990"
  },
  {
    "text": "you",
    "start": "3973310",
    "end": "3975370"
  }
]
[
  {
    "start": "0",
    "end": "10930"
  },
  {
    "text": "Thank you for coming. I'll tell you about a few\nnew results on understanding",
    "start": "10930",
    "end": "16870"
  },
  {
    "text": "neural networks. So I'm interested\nin understanding,",
    "start": "16870",
    "end": "21940"
  },
  {
    "text": "learning what properties\nof the physical world allow us to learn well and\nallow us to learn efficiently.",
    "start": "21940",
    "end": "31210"
  },
  {
    "text": "And in a sense, if you\nare any good at saying",
    "start": "31210",
    "end": "36910"
  },
  {
    "text": "what good learning means,\nthen this kind of theory or this kind of\nmathematics should also",
    "start": "36910",
    "end": "42010"
  },
  {
    "text": "translate to understanding why\nbiological systems learn well. They clearly learn much better\nthan artificial systems.",
    "start": "42010",
    "end": "48160"
  },
  {
    "text": "And so this is the\neventual goal I want to talk about, that this\ntalk is focused on understanding artificial neural networks.",
    "start": "48160",
    "end": "54010"
  },
  {
    "text": "If you're interested\nin this question, I would contend that there is\ntwo key big questions that we",
    "start": "54010",
    "end": "59470"
  },
  {
    "text": "do not know the answer to. The first one is, why can we\ntrain neural networks well? We like networks that\ncan do lots of diverse--",
    "start": "59470",
    "end": "68830"
  },
  {
    "text": "that work well on\nlots of diverse data. And to model all this\nvariability in the data, we need to have a\nlot of parameters.",
    "start": "68830",
    "end": "76430"
  },
  {
    "text": "The tasks that we\nwould like them to do, the labels\nthat we are predicting",
    "start": "76430",
    "end": "82070"
  },
  {
    "text": "are complicated\nfunctions of the inputs. And that is why the functions\nthat the networks parameterize",
    "start": "82070",
    "end": "89000"
  },
  {
    "text": "are complicated, in\nparticular, non-convex. By all intents and purposes,\nnon-convex optimization",
    "start": "89000",
    "end": "94850"
  },
  {
    "text": "problems, which is what training\na neural network amounts to, are hard optimization problems.",
    "start": "94850",
    "end": "100170"
  },
  {
    "text": "So if you ask friends,\nthey will tell you that 10-dimensional non-convex\noptimization is intractable.",
    "start": "100170",
    "end": "106640"
  },
  {
    "text": "It doesn't really make any sense\nthat we can train these networks in millions of dimensions.",
    "start": "106640",
    "end": "112250"
  },
  {
    "text": "This is the kind of question\nthat I was asking during my PhD. And the rough summary of my\nwork, many other people's",
    "start": "112250",
    "end": "118070"
  },
  {
    "text": "work is that the energy\nlandscape of neural networks is not convex, yes.",
    "start": "118070",
    "end": "123530"
  },
  {
    "text": "But it's somewhat benign. So it looks a little bit\nlike the Grand Canyon. No matter where\nyou are standing,",
    "start": "123530",
    "end": "130429"
  },
  {
    "text": "there is the river below you. Doesn't matter which part\nof the river you fall in. It's the same river.",
    "start": "130430",
    "end": "136070"
  },
  {
    "text": "There is crevices and stuff\nwhere you can get stuck, but we have figured out\ntricks to escape those things.",
    "start": "136070",
    "end": "142189"
  },
  {
    "text": "So it's not trivial, but it's\nnot intractably hard either.",
    "start": "142190",
    "end": "148040"
  },
  {
    "text": "The second question\nis in high school, everyone told you that if\nyou have 10 data points,",
    "start": "148040",
    "end": "155090"
  },
  {
    "text": "you shouldn't be fitting\na polynomial of degree 15 to the standard data\npoints because it can overfit, and it can be very wiggly\nin parts of the domain",
    "start": "155090",
    "end": "162590"
  },
  {
    "text": "where you do not\nhave enough data. In deep learning,\nwe love doing this. We don't even seem to\nget hurt by doing this.",
    "start": "162590",
    "end": "168349"
  },
  {
    "text": "So something must be\neasy about the problem that you are trying to solve. Otherwise, this wouldn't work.",
    "start": "168350",
    "end": "175967"
  },
  {
    "text": "So this is the kind of\nquestions that I hope to shed light on in this talk. But maybe before we\ngo to the answers,",
    "start": "175967",
    "end": "181910"
  },
  {
    "text": "it behooves us to\nask, why do we care? If you ask the\npractitioners, they",
    "start": "181910",
    "end": "187058"
  },
  {
    "text": "are not exactly waiting for\nanswers to these questions. They are doing fine,\nway better than fine without knowing\nanything about this.",
    "start": "187058",
    "end": "194120"
  },
  {
    "text": "I'll give you two answers,\ntwo of my answers. And the first one\nis simply pride.",
    "start": "194120",
    "end": "201230"
  },
  {
    "text": "We have been taught\nsome stuff in textbooks. These neural\nnetworks clearly seem",
    "start": "201230",
    "end": "206900"
  },
  {
    "text": "to go against those things,\nat least at the face of it. So are the textbooks wrong?",
    "start": "206900",
    "end": "212090"
  },
  {
    "text": "Should we just burn them? Or maybe we did not\nunderstand the textbooks as well as we think.",
    "start": "212090",
    "end": "220280"
  },
  {
    "text": "The second thing is perhaps\na bit more important. I believe that the\nsuccess of deep learning",
    "start": "220280",
    "end": "227090"
  },
  {
    "text": "is telling us new things\nabout the nature of data. It's a little bit like\nbuilding a new microscope.",
    "start": "227090",
    "end": "234140"
  },
  {
    "text": "Over the last 10\nyears or 30 years, depending on how you count,\nwe were trying very hard",
    "start": "234140",
    "end": "239300"
  },
  {
    "text": "to build a good microscope. Now we have a great one.",
    "start": "239300",
    "end": "244549"
  },
  {
    "text": "But the reason we\nwere doing all this was to look at what is\nunderneath the microscope. And so I would\nlike to understand",
    "start": "244550",
    "end": "251690"
  },
  {
    "text": "what natural data looks like. And the fact that the\nnetworks are working well",
    "start": "251690",
    "end": "258290"
  },
  {
    "text": "is just the first\nstep of that process. ",
    "start": "258290",
    "end": "263910"
  },
  {
    "text": "OK, so over the years, I'm\nnot the only person asking these kinds of questions. Many other people have asked\nthese questions before.",
    "start": "263910",
    "end": "271080"
  },
  {
    "text": "And in our attempt to explain\nthe efficacy of these networks, we have attributed a lot of\nmystery and peculiarities",
    "start": "271080",
    "end": "278759"
  },
  {
    "text": "to them. And I'll give you two\nexamples from my research. There is many others\nin other papers.",
    "start": "278760",
    "end": "286740"
  },
  {
    "text": "Here is one. So a few years ago, we\nnoticed that after training,",
    "start": "286740",
    "end": "293340"
  },
  {
    "text": "typical neural networks end\nup in regions that are rather wide in the energy landscape.",
    "start": "293340",
    "end": "298800"
  },
  {
    "text": "So if you calculate\nthe Hessian, which is the curvature of\nthe loss quantity that tells you how quickly\nthe loss changes locally,",
    "start": "298800",
    "end": "306450"
  },
  {
    "text": "you will notice that the Hessian\nhas a lot of near 0 eigenvalues. And that tells you that about\n95%, 96% of the eigenvalues",
    "start": "306450",
    "end": "313980"
  },
  {
    "text": "are essentially 0. That tells you\nthe loss function, no matter which direction\nyou look at, is quite flat. There's also some positive ones.",
    "start": "313980",
    "end": "320160"
  },
  {
    "text": "There's also some negative ones. But typically, at the end of\ntraining, for most networks, for most algorithms, you\nreach regions of this kind.",
    "start": "320160",
    "end": "328150"
  },
  {
    "text": "If you reach regions\nthat are not this wide, then you do not seem to\nget good test errors. So that is a-- that\nis a utility or there",
    "start": "328150",
    "end": "335320"
  },
  {
    "text": "is a merit to reaching\nthese kinds of regions. But a lot of calculations\nin statistical physics will tell you that\nwide regions are",
    "start": "335320",
    "end": "342670"
  },
  {
    "text": "rare in the energy landscape. These are what are called\nlarge deviations phenomena under certain models.",
    "start": "342670",
    "end": "349060"
  },
  {
    "text": "And so you should think\nof it as a little bit like you're in\nthis gigantic room. There are many solutions to\nthe training set in this room.",
    "start": "349060",
    "end": "357280"
  },
  {
    "text": "There is one particular\nkind of solution, which is this wide region. It doesn't make\nsense that you're",
    "start": "357280",
    "end": "363610"
  },
  {
    "text": "finding this tiny part,\nwhich is very rare, with local descent algorithms. And you do.",
    "start": "363610",
    "end": "369273"
  },
  {
    "text": "So every time you\ntrain a network, you will get a Hessian\nthat looks like this. We didn't know why it happens\nlike this, why it is so.",
    "start": "369273",
    "end": "377500"
  },
  {
    "text": "So we chose a slightly\nsimpler problem. We said, look, the\nenergy landscape has both wide regions\nand not wide regions.",
    "start": "377500",
    "end": "385630"
  },
  {
    "text": "Let us try to modify the loss. So if f of w is a\ntraining loss, G sub gamma",
    "start": "385630",
    "end": "390820"
  },
  {
    "text": "is a Gaussian kernel\nof bandwidth gamma that smooths the loss. And this smoothing basically\ndestroys all the regions",
    "start": "390820",
    "end": "398440"
  },
  {
    "text": "that are not wide. It keeps the regions that\nare wider than gamma, and then it makes\nthem easier to find.",
    "start": "398440",
    "end": "404710"
  },
  {
    "text": "These algorithms\nalso work very well. So they are about two to\nfour times faster than SGD.",
    "start": "404710",
    "end": "410080"
  },
  {
    "text": "Still some of the\nfastest methods I know to train neural networks. So you can exploit\nthis specularity. But the point is that you are\nending up in regions like this,",
    "start": "410080",
    "end": "418000"
  },
  {
    "text": "even if they are somewhat rare. Here is the second example.",
    "start": "418000",
    "end": "423130"
  },
  {
    "text": "We noticed that the noise in\nSGD, which you can characterize as the covariance matrix of\nthe stochastic gradients, how",
    "start": "423130",
    "end": "431440"
  },
  {
    "text": "different is the\ngradient of one mini batch from the full gradient\non the entire data set.",
    "start": "431440",
    "end": "436570"
  },
  {
    "text": "This is a matrix whose size\nis the number of weights times number of weights. It is quite close to the Fisher\ninformation matrix, which",
    "start": "436570",
    "end": "443650"
  },
  {
    "text": "defines the curvature of the\noutput of a model, roughly speaking. And we noticed that the noise\nis very pathological in most",
    "start": "443650",
    "end": "452080"
  },
  {
    "text": "networks and most data sets. Out of these millions of\ndimensions in the weight space,",
    "start": "452080",
    "end": "457100"
  },
  {
    "text": "you have noise in less\nthan 0.5% or so dimensions.",
    "start": "457100",
    "end": "462258"
  },
  {
    "text": "All the other dimensions are\nbasically doing gradient descent dynamics. And now, when a\nphysicist looks at this,",
    "start": "462258",
    "end": "468669"
  },
  {
    "text": "they will call it a\nnon-equilibrium stochastic process. This stochastic process\ndoesn't have detailed balance",
    "start": "468670",
    "end": "474340"
  },
  {
    "text": "because taking a trajectory\nthat goes in one direction is not the same probability\nas the trajectory that",
    "start": "474340",
    "end": "479974"
  },
  {
    "text": "comes exactly in the opposite\ndirection with the same two points. And such things are\nsomewhat exotic,",
    "start": "479975",
    "end": "486550"
  },
  {
    "text": "Markov chains with\nbroken detailed balance. Even in biology, you need\nsome constant amount of energy",
    "start": "486550",
    "end": "492910"
  },
  {
    "text": "that is being added into the\nsystem for the entropy rate to not be 0. And you can get lots\nof exotic phenomena.",
    "start": "492910",
    "end": "499480"
  },
  {
    "text": "For instance, we showed that\nthe most likely locations that you can find SGD\nat the end of training",
    "start": "499480",
    "end": "507039"
  },
  {
    "text": "are not even the critical\npoints of the training loss. So before this, we were\nwondering whether or not",
    "start": "507040",
    "end": "515469"
  },
  {
    "text": "you find global minima in\nnon-convex data landscape. This result says that you\ndon't even find local minima.",
    "start": "515470",
    "end": "520928"
  },
  {
    "text": "Or you can happily converge to\nregions around local minima. So it seems a little bit spooky.",
    "start": "520929",
    "end": "527920"
  },
  {
    "text": "You will also be able to show\nthat the weights of the network",
    "start": "527920",
    "end": "533320"
  },
  {
    "text": "can evolve in\nsubspaces arbitrarily. They don't have to converge. They don't have to stop so long\nas the gradient of some function",
    "start": "533320",
    "end": "540860"
  },
  {
    "text": "fee is 0. It's not very important at this\npoint what this function is, but this is\nspecularity number 2.",
    "start": "540860",
    "end": "547480"
  },
  {
    "text": "You have a very\npathological noise in the way we are\ncomputing gradients.",
    "start": "547480",
    "end": "553720"
  },
  {
    "text": "And that gives us\npretty exotic phenomena even by the standards\nof physical systems,",
    "start": "553720",
    "end": "559480"
  },
  {
    "text": "this artificial system. And there are many\nother examples. So what I want to convince\nyou of is over the years,",
    "start": "559480",
    "end": "568960"
  },
  {
    "text": "there are many such versions. So for instance,\nsome people might say that if you want to\nunderstand neural networks,",
    "start": "568960",
    "end": "575390"
  },
  {
    "text": "we should really understand\nwhat overparametrization is because they\nseem to be-- they're",
    "start": "575390",
    "end": "581343"
  },
  {
    "text": "distinct from the\nother machine learning models we know in the fact that\nthey have so many parameters.",
    "start": "581343",
    "end": "586790"
  },
  {
    "text": "And I don't know. If you think a little bit like\na first year undergraduate student, I have many parameters.",
    "start": "586790",
    "end": "592850"
  },
  {
    "text": "I do not have enough\ninformation to constrain all these parameters. So why the heck\nshould they matter,",
    "start": "592850",
    "end": "597980"
  },
  {
    "text": "the ones that do not constrain? Overparameterization cannot\nbe the only game in town",
    "start": "597980",
    "end": "603800"
  },
  {
    "text": "to explaining why\nthese networks work, because I'm not even\nconstraining all the other parameters.",
    "start": "603800",
    "end": "610130"
  },
  {
    "text": "If you ask some\nother people, they'll say, oh, inductive\nbias is the reason why these networks are special.",
    "start": "610130",
    "end": "616310"
  },
  {
    "text": "Well, inductive\nbias was the reason why convolutional networks were\nso successful in 2014, 2013.",
    "start": "616310",
    "end": "623240"
  },
  {
    "text": "Transformers are also exactly\nas successful, if not better. So it cannot be that\ninductive bias is, again,",
    "start": "623240",
    "end": "629430"
  },
  {
    "text": "the only theory that explains\nwhy the networks work. And you can go around the\nroom and then lay blame",
    "start": "629430",
    "end": "635600"
  },
  {
    "text": "to gaps in arguments of\nvery many different attempts to understand this.",
    "start": "635600",
    "end": "641360"
  },
  {
    "text": "What I want to convince\nyou in this talk is that we are missing\nthe elephant in the room. The data that we train these\nnetworks on is kind of special.",
    "start": "641360",
    "end": "650120"
  },
  {
    "text": "And that is really the secret\nof all these peculiarities, or that is really the reason for\nall these mysterious properties.",
    "start": "650120",
    "end": "657918"
  },
  {
    "text": "And if you are to understand\nthe data bit better, we can explain them. ",
    "start": "657918",
    "end": "665110"
  },
  {
    "text": "So first, I'll tell\nyou a result that we presented at ICML last year. It's a paper called, Does the\ndata induce capacity control",
    "start": "665110",
    "end": "672699"
  },
  {
    "text": "in deep learning? And the focus on the\nblue line for a second.",
    "start": "672700",
    "end": "677860"
  },
  {
    "text": "The blue line are\nthe eigenvalues of principal component\nanalysis of CIFAR-10 images.",
    "start": "677860",
    "end": "684730"
  },
  {
    "text": "CIFAR-10 has 10 classes,\n32 cross 32 pixels RGB. So three channels.",
    "start": "684730",
    "end": "690399"
  },
  {
    "text": "So there's 3,072 eigenvalues. And what you notice\nimmediately is",
    "start": "690400",
    "end": "695800"
  },
  {
    "text": "that the ratio of the\nlargest eigenvalue, which I have\nnormalized to 1 here-- and the smallest one\nis 10 raise to 8.",
    "start": "695800",
    "end": "703600"
  },
  {
    "text": "This is a gigantically\nlow-dimensional data set.",
    "start": "703600",
    "end": "708670"
  },
  {
    "text": "So if you think of a\npoint cloud of the images, this is an ellipse that\nsubsumes this point cloud.",
    "start": "708670",
    "end": "714220"
  },
  {
    "text": "And the longest axis of the\nellipse is 10 to the 8 times longer than the smallest axis.",
    "start": "714220",
    "end": "719980"
  },
  {
    "text": "In computer vision,\nwe've always believed that inputs typical images lie\non low-dimensional manifolds.",
    "start": "719980",
    "end": "726920"
  },
  {
    "text": "It is not exactly\nlow dimensional because there is also\nthese small eigenvalues,",
    "start": "726920",
    "end": "731990"
  },
  {
    "text": "but it is effectively\nlow dimensional. About 100, 150\ndimensions are taking most of the bulk of the\nvariance of this point cloud.",
    "start": "731990",
    "end": "741457"
  },
  {
    "text": "If you think a little\nbit about this, you can also convince\nyourself why this is so. This is a picture from\nPlato's theory of forms.",
    "start": "741458",
    "end": "749180"
  },
  {
    "text": "So you can imagine that along\nthe long axis of the ellipse, on one side lie\nall the pure cats.",
    "start": "749180",
    "end": "756139"
  },
  {
    "text": "On the other side lie\nall the pure dogs. And then the other axis,\nthe longitudinal directions,",
    "start": "756140",
    "end": "762680"
  },
  {
    "text": "consist of aberrations. So blue sky, which\ndoesn't change very much, would be along the\nsmall eigenvector.",
    "start": "762680",
    "end": "770870"
  },
  {
    "text": "Blue dog-- there is not very\nmany of them in the world-- would also lie along\nthe small eigenvectors.",
    "start": "770870",
    "end": "777620"
  },
  {
    "text": "We call such a spectrum sloppy. This is just a name.",
    "start": "777620",
    "end": "782720"
  },
  {
    "text": "And here is why we named it so. We showed that if the\ninput data looks like this,",
    "start": "782720",
    "end": "789410"
  },
  {
    "text": "if the input data decays\nvery sharply at the beginning and then is linear\non a log scale,",
    "start": "789410",
    "end": "794570"
  },
  {
    "text": "then, essentially,\nany quantity that you calculate inside the\nnetwork, be it the Hessian,",
    "start": "794570",
    "end": "800600"
  },
  {
    "text": "which is the curvature of\nthe loss-- we just saw it; the fisher information\nmatrix, which is the curvature of the output--\nwe also talked about it;",
    "start": "800600",
    "end": "807620"
  },
  {
    "text": "correlations of activations;\ncorrelations of Jacobians of different logits;\nbasically, anything that you can calculate also has\na spectrum that looks like this.",
    "start": "807620",
    "end": "816330"
  },
  {
    "text": "It decays very quickly\nin the beginning and then slopes\ndown with some rate.",
    "start": "816330",
    "end": "822530"
  },
  {
    "text": "The reason why we call\nthis sloppy is as follows. So think of an eigenvector here\nwith a very small eigenvalue.",
    "start": "822530",
    "end": "831050"
  },
  {
    "text": "It is corresponding to a\ndirection in the weight space where I'm allowed to perturb\nthe weights by seven,",
    "start": "831050",
    "end": "838190"
  },
  {
    "text": "eight orders of magnitude before\nI see any appreciable change in the output of the function.",
    "start": "838190",
    "end": "843889"
  },
  {
    "text": "So this is gigantic, very\nstark, big redundancy in how the network\nuses all its weights.",
    "start": "843890",
    "end": "850180"
  },
  {
    "text": "This is a wide residual network\nwith all bells and whistles, about 3 million weights.",
    "start": "850180",
    "end": "856870"
  },
  {
    "text": "But the network is using\nonly about 150 or 200",
    "start": "856870",
    "end": "862029"
  },
  {
    "text": "or so parameters to actually\nmake the predictions. All the others are\ndecorations of the accuracy.",
    "start": "862030",
    "end": "867640"
  },
  {
    "text": "Your 95% accuracy is coming\nfrom the head of the spectrum. And then if you want the\nremaining five shots,",
    "start": "867640",
    "end": "872890"
  },
  {
    "text": "you have to dig all the\nway deep into the tail. The tail is also very long, and\nit has a very bad aspect ratio.",
    "start": "872890",
    "end": "880300"
  },
  {
    "text": "The reason this is\nimportant is because you can imagine that if noise\nwere to come and change",
    "start": "880300",
    "end": "885580"
  },
  {
    "text": "this part of the spectrum,\nyou would see 0 deterioration. The output of the model\nis insensitive to changes",
    "start": "885580",
    "end": "893350"
  },
  {
    "text": "that happen in this subspace. And so you cannot overfit\non such data sets.",
    "start": "893350",
    "end": "900160"
  },
  {
    "text": "Nothing can knock,\nnot neural networks. Nothing can. So we have also noticed\nthat the labels are highly",
    "start": "900160",
    "end": "906140"
  },
  {
    "text": "correlated with the\nhead of the spectrum, and that has some post-hoc\nexplanation in the sense",
    "start": "906140",
    "end": "911510"
  },
  {
    "text": "that you have images of cats. And you give them label cat\nbased on the salient features.",
    "start": "911510",
    "end": "918350"
  },
  {
    "text": "You don't give labels based\non non-salient features. So they got to be correlated\nwith the salient aspects of the input.",
    "start": "918350",
    "end": "923540"
  },
  {
    "text": "If data looks like this, if\nthe task looks like this, then nothing can overfit. ",
    "start": "923540",
    "end": "930889"
  },
  {
    "text": "If the orange line\nor the blue line was genuinely low dimensional,\nit was dropping like this,",
    "start": "930890",
    "end": "937130"
  },
  {
    "text": "then we would all be\nsolving easy problems. And we wouldn't be very\nproud of ourselves. If the blue line\nwas flat like this,",
    "start": "937130",
    "end": "944990"
  },
  {
    "text": "then you would see the\ncurse of dimensionality, and then you couldn't\nsolve those problems. So in a sense, this\ndecay is the right level",
    "start": "944990",
    "end": "953870"
  },
  {
    "text": "at which we are allowed\nto solve these problems in a computationally\nreasonable way, and yet solve interesting enough\nproblems that we care about.",
    "start": "953870",
    "end": "961834"
  },
  {
    "text": " Just a quick picture\nof the mathematics.",
    "start": "961835",
    "end": "973020"
  },
  {
    "text": "We would really like to\nshow that sloppy inputs-- so the blue line being\nshaped in this peculiar way--",
    "start": "973020",
    "end": "978779"
  },
  {
    "text": "lead to sloppy Fisher\ninformation or sloppy Hessian. We can't quite show this\nentire sentence as is.",
    "start": "978780",
    "end": "985440"
  },
  {
    "text": "So that is why I put\na little tilde here. We can show it in parts. So we can show that\nthe trace of the Fisher",
    "start": "985440",
    "end": "991470"
  },
  {
    "text": "and the trace of\nthe Hessian is upper bounded by the trace of the\ninput correlation matrix. The input correlation\nmatrix is exactly",
    "start": "991470",
    "end": "997830"
  },
  {
    "text": "whose eigenvalues I was\nplotting, the blue line. And then there is\na bunch of terms that depend on the weights.",
    "start": "997830",
    "end": "1003350"
  },
  {
    "text": "Now this is a rather\nsimple inequality to show. The way to interpret\nthis is as follows-- so",
    "start": "1003350",
    "end": "1009140"
  },
  {
    "text": "imagine that I have a network\nwhere I force the weights to lie within some [INAUDIBLE] ball.",
    "start": "1009140",
    "end": "1014720"
  },
  {
    "text": "And so I can uniformly\nbound this entire term. And I start taking\nthe size of the--",
    "start": "1014720",
    "end": "1020068"
  },
  {
    "text": "I start increasing the\nsize of the network. It doesn't have\nto go to infinity. It just has to go big.",
    "start": "1020068",
    "end": "1025250"
  },
  {
    "text": "This entire right-hand\nside is a constant. The left-hand side grows\nmore and more terms. So at least that tells you that\nthe eigenvalues of the Fisher,",
    "start": "1025250",
    "end": "1032797"
  },
  {
    "text": "of the Hessian have to decay. Doesn't tell us that they\nhave to decay exponentially, but at least they got to\ndecay as 1 over k or so.",
    "start": "1032797",
    "end": "1039334"
  },
  {
    "text": " That's just about the trace. If you look at the blocks of\nthe Fisher information matrix,",
    "start": "1039334",
    "end": "1045920"
  },
  {
    "text": "the blocks of the fisher\nmatrix are the correlations of the Jacobians for\nweights that correspond",
    "start": "1045920",
    "end": "1051029"
  },
  {
    "text": "to only that particular layer. You don't go across the layers\nwhen you calculate the block. We can give a slightly\nmore precise bound",
    "start": "1051030",
    "end": "1057560"
  },
  {
    "text": "on the entire spectrum. So the eigenvalues of the block\nof the Fisher information matrix",
    "start": "1057560",
    "end": "1063740"
  },
  {
    "text": "are upper bounded by the\neigenvalues of the activations-- of the correlations\nof the activations",
    "start": "1063740",
    "end": "1068900"
  },
  {
    "text": "of that particular layer. Again, not a very\ndifficult thing to show a short calculation.",
    "start": "1068900",
    "end": "1074540"
  },
  {
    "text": "But this tells you that if\nthe activations are sloppy, then the Fisher\ninformation matrix also",
    "start": "1074540",
    "end": "1080030"
  },
  {
    "text": "has eigenvalues that decay. So it's very difficult to go\ndirectly from the inputs all",
    "start": "1080030",
    "end": "1086820"
  },
  {
    "text": "the way to the Fisher because\nyou cannot get very general bounds on the activations\nas you go up the layer.",
    "start": "1086820",
    "end": "1092550"
  },
  {
    "text": "For infinitely wide networks\nor for kernel machines, all of these things can\nbe done pretty easily.",
    "start": "1092550",
    "end": "1097980"
  },
  {
    "text": "You can show that sloppy\ninputs gives us sloppy Fishers. So there is some insight\ninto the mathematics.",
    "start": "1097980",
    "end": "1103919"
  },
  {
    "text": "What I want to\ntell you next about is that all the stuff\nthat we've talked about, sloppy inputs and\nsloppy Fishers,",
    "start": "1103920",
    "end": "1110190"
  },
  {
    "text": "doesn't seem to be very\nspecific to neural networks. Many models in\nnature are sloppy.",
    "start": "1110190",
    "end": "1117420"
  },
  {
    "text": "So I've shown you an example\nof a particular systems biology",
    "start": "1117420",
    "end": "1123840"
  },
  {
    "text": "problem. This is an extracellular\nregulated kinase, ERK1/2.",
    "start": "1123840",
    "end": "1130650"
  },
  {
    "text": "You can think of\nit as a catalyst for the growth of cells,\nPC12 cells in particular.",
    "start": "1130650",
    "end": "1135960"
  },
  {
    "text": "And people have noticed\nthat, for instance, there is a protein called EGF,\nEpidermal Growth Factor.",
    "start": "1135960",
    "end": "1142860"
  },
  {
    "text": "If EGF is large, then\nERK shows spikes. If ERK shows spikes, then the\ncells increase in numbers.",
    "start": "1142860",
    "end": "1152730"
  },
  {
    "text": "They all remain the same. Their function is the same,\nbut they increase in numbers. If the neural growth\nfactor is large,",
    "start": "1152730",
    "end": "1158730"
  },
  {
    "text": "if this protein has a\nlarge concentration, then the cells differentiate\nin their functionality.",
    "start": "1158730",
    "end": "1165510"
  },
  {
    "text": "This is just a particular\nkind of reaction. And those details\nare not terribly important at this point.",
    "start": "1165510",
    "end": "1171000"
  },
  {
    "text": "For us, here, you can\nthink of this entire system as a coupled system of\ndifferential equations.",
    "start": "1171000",
    "end": "1176580"
  },
  {
    "text": "The output of this system is\nthe kinase, is the catalyst. The input to this system or\nthe parameters of this system",
    "start": "1176580",
    "end": "1183480"
  },
  {
    "text": "are the concentration\nof proteins that play a role in\nthis or the kinetic rate",
    "start": "1183480",
    "end": "1188490"
  },
  {
    "text": "constants of all these\nreactions, whatever you pick. We're allowed to\ncalculate the sensitivity of the output with respect to\nperturbations of the parameters.",
    "start": "1188490",
    "end": "1197070"
  },
  {
    "text": "And these are, again,\nthe eigenvalues of the Fisher information\nmatrix or Jacobian, if you want to think\nabout that there.",
    "start": "1197070",
    "end": "1203640"
  },
  {
    "text": "When a systems biologist sees\nthese kinds of eigenvalues, they are happy because\nthey'll say, of course,",
    "start": "1203640",
    "end": "1209350"
  },
  {
    "text": "we know that the\noutput is insensitive to many, many changes\nin the parameters. Because that way, your\nbody can make sure",
    "start": "1209350",
    "end": "1216930"
  },
  {
    "text": "that functions remain intact,\neven if the environment changes a tiny bit. So this makes sense\nin a post-hoc way.",
    "start": "1216930",
    "end": "1226800"
  },
  {
    "text": "There is a pretty\ncool question that I believe we are trying\nto solve right now is, why did this circuit\nhave to become so?",
    "start": "1226800",
    "end": "1236130"
  },
  {
    "text": "And the basic theory or\nthe basic line of attack is when a system wants to\nbecome resilient to changes",
    "start": "1236130",
    "end": "1242250"
  },
  {
    "text": "of the environment, then it has\nto become sloppy to preserve its function. Otherwise, it would be\ntoo sensitive to changes",
    "start": "1242250",
    "end": "1247980"
  },
  {
    "text": "in the environment. So systems in nature are sloppy. Many, many systems are sloppy.",
    "start": "1247980",
    "end": "1254215"
  },
  {
    "text": "It doesn't have to\nbe a natural system. So an Ising model is\na pretty fake model that physicists use\nto understand disorder",
    "start": "1254215",
    "end": "1260760"
  },
  {
    "text": "in materials. You can think of it\nas a bunch of spins. You and your neighbor like to\ntake the same value in the sense",
    "start": "1260760",
    "end": "1267610"
  },
  {
    "text": "that both of you point\nup if the coupling constant between these\nspins is positive. If the coupling\nconstant is negative,",
    "start": "1267610",
    "end": "1273640"
  },
  {
    "text": "then the spins are pointing\nin opposite directions. Now in statistical\nphysics, people",
    "start": "1273640",
    "end": "1280360"
  },
  {
    "text": "have a pretty\nsophisticated understanding of why the Fisher information\nmatrix-- in this case, it would",
    "start": "1280360",
    "end": "1285580"
  },
  {
    "text": "be the sensitivity\nor the probability distribution of the spins\nto the coupling constants--",
    "start": "1285580",
    "end": "1290770"
  },
  {
    "text": "has such sloppy\neigenvalues is because this",
    "start": "1290770",
    "end": "1296590"
  },
  {
    "text": "is a classical\nconstructions where there are some microscopic quantities\nthat emerge because they don't",
    "start": "1296590",
    "end": "1302320"
  },
  {
    "text": "depend in sensitive ways on\nall the disorder in the system. And that is why for\ninanimate matter",
    "start": "1302320",
    "end": "1308860"
  },
  {
    "text": "or for these kinds\nof systems, we know pretty nice way for why\nthe system has to be sloppy.",
    "start": "1308860",
    "end": "1314110"
  },
  {
    "text": "It is more of a matter of\nasking a different question.",
    "start": "1314110",
    "end": "1319263"
  },
  {
    "text": "If you wanted to understand\nthe magnetization, which is the average value\nthat the spins take, then it is a sloppy model.",
    "start": "1319263",
    "end": "1327080"
  },
  {
    "text": "If you wanted to understand\nthe actual value of the spins, then it is not a sloppy model. So the most important\nthing to appreciate",
    "start": "1327080",
    "end": "1332780"
  },
  {
    "text": "from all this commentary\nis that sloppiness is a property of\nthe trained model,",
    "start": "1332780",
    "end": "1337820"
  },
  {
    "text": "but it is also a\nproperty of the question that you're answering\nwith the trained model. If you want to know the\nlocations of molecules",
    "start": "1337820",
    "end": "1344330"
  },
  {
    "text": "in this room, then you would\nhave a very complicated model. And it would not\nshow this simplicity. But if you want\n[INAUDIBLE],, then it",
    "start": "1344330",
    "end": "1351139"
  },
  {
    "text": "doesn't depend on all\nthe pixels in the image, and then you're talking\nabout sloppy models. ",
    "start": "1351140",
    "end": "1359510"
  },
  {
    "text": "Let me show you one\nexample, one application. So I'll talk about what are\ncalled PAC-Bayes bounds.",
    "start": "1359510",
    "end": "1364910"
  },
  {
    "text": "PAC stands for Probably\nApproximately Correct. Learning theory people will\nwrite inequalities of this kind.",
    "start": "1364910",
    "end": "1370910"
  },
  {
    "text": "So they'll say, take a\nprobability distribution Q on the hypothesis space or on\nthe weight space, if you will.",
    "start": "1370910",
    "end": "1377690"
  },
  {
    "text": "Little e of Q is the\nprobability that you make a mistake on a test\ndatum for a hypothesis drawn",
    "start": "1377690",
    "end": "1384680"
  },
  {
    "text": "from random from the\ndistribution Q, something smaller than 1.",
    "start": "1384680",
    "end": "1390350"
  },
  {
    "text": "e hat of Q is the\nprobability that you make a mistake on the training data.",
    "start": "1390350",
    "end": "1395390"
  },
  {
    "text": "And then they'll\nsay, the probability of making a mistake on the\ntest is less than probability of making a mistake\non the training set",
    "start": "1395390",
    "end": "1400765"
  },
  {
    "text": "plus some complexity term. And it's not very important\nwhat P is at this point.",
    "start": "1400765",
    "end": "1406070"
  },
  {
    "text": "But the way to interpret\nthese kinds of inequalities is if Q puts its\nprobability mass on many, many\ndifferent hypotheses,",
    "start": "1406070",
    "end": "1413480"
  },
  {
    "text": "then you need requisite\nlarge amounts of samples to distinguish between\nall these hypotheses.",
    "start": "1413480",
    "end": "1419460"
  },
  {
    "text": "If Q puts a [INAUDIBLE]\non many of them, then it cannot possibly pick\none hypothesis with few samples.",
    "start": "1419460",
    "end": "1425220"
  },
  {
    "text": "And this is how people\nwill think of them. And in this form, it is about\n30 years old, maybe more.",
    "start": "1425220",
    "end": "1431370"
  },
  {
    "text": "What has recently\nbeen noticed is that when we plug in numbers\ninto these inequalities,",
    "start": "1431370",
    "end": "1437100"
  },
  {
    "text": "things don't quite work. So a typical neural network will\nhave basically 0 training error",
    "start": "1437100",
    "end": "1442657"
  },
  {
    "text": "because you're\ninterpolating the data. And so this term is 0. The test error--\nlet's say it is 5%.",
    "start": "1442657",
    "end": "1449520"
  },
  {
    "text": "So this would be 0.05. But the complexity term\nis much larger than 1. It will usually be about\n100 even for MNIST.",
    "start": "1449520",
    "end": "1456600"
  },
  {
    "text": "And so you don't really need a\ntheory or certainly a theorem",
    "start": "1456600",
    "end": "1461700"
  },
  {
    "text": "to say that the probability\nof making a mistake is less than 100. It's obvious.",
    "start": "1461700",
    "end": "1467340"
  },
  {
    "text": "And so this is why people have\nbeen very anxious about this. And they call such\nbounds vacuous. They are vacuous not\nbecause we did anything",
    "start": "1467340",
    "end": "1474780"
  },
  {
    "text": "wrong while deriving this\nequation, this inequality. But we don't know is\nbecause neural networks have",
    "start": "1474780",
    "end": "1481542"
  },
  {
    "text": "a large number of parameters. That is why this\nterm is very large. What we showed in\nthis paper is that we",
    "start": "1481542",
    "end": "1488330"
  },
  {
    "text": "can give an analytical\nnon-vacuous bound on the generalization error\nof general neural networks",
    "start": "1488330",
    "end": "1494330"
  },
  {
    "text": "simply by an assumption that\nsays that the inputs are sloppy.",
    "start": "1494330",
    "end": "1499700"
  },
  {
    "text": "If the inputs are sloppy,\nthe Hessian is sloppy. If the Hessian is\nsloppy, then you can get a non-vacuous bound\non the generalization error.",
    "start": "1499700",
    "end": "1506450"
  },
  {
    "text": "It's not tight. It's 0.38, whereas a\ntypical MNIST network will have this kind\nof a test error, which",
    "start": "1506450",
    "end": "1513150"
  },
  {
    "text": "is a stochastic test error\nof, let's say, 2%, 3% or so. And in the paper,\nyou can also develop some numerical techniques\nto get basically pretty",
    "start": "1513150",
    "end": "1520182"
  },
  {
    "text": "tight inequalities on\nthe generalization error. But the point of\nthe entire argument is that you don't\nneed new theory",
    "start": "1520182",
    "end": "1526730"
  },
  {
    "text": "to understand deep networks. The existing theory\nworks just fine. You just apply it\nin the right way",
    "start": "1526730",
    "end": "1531897"
  },
  {
    "text": "and appreciate the\nfact that you're not fitting arbitrary data. You are fitting data with very\nspecific patterns, very specific",
    "start": "1531897",
    "end": "1538190"
  },
  {
    "text": "learnable patterns. You're not fitting\na hash function. Yeah. So in principle, if I\nchoose a better prior,",
    "start": "1538190",
    "end": "1544850"
  },
  {
    "text": "would I be able to make the\nright-hand side much smaller? Yeah, that's called\ntransfer learning. ",
    "start": "1544850",
    "end": "1556230"
  },
  {
    "text": "Cool. So here is one take-home\nmessage from this calculation. Let us ask ourselves, there\nare many, many weights",
    "start": "1556230",
    "end": "1562835"
  },
  {
    "text": "in the network. How many are really constrained? So we can pluck out a quantity,\nwhich is, roughly speaking,",
    "start": "1562835",
    "end": "1568620"
  },
  {
    "text": "the elbow of this\nparticular eigen spectrum that looks as follows--\nthe number of eigenvalues",
    "start": "1568620",
    "end": "1574200"
  },
  {
    "text": "of the Hessian that are larger\nthan epsilon is not important. It is a scale of the prior.",
    "start": "1574200",
    "end": "1580020"
  },
  {
    "text": "The denominator is two times\nthe number of samples minus 1. And now this is quite beautiful.",
    "start": "1580020",
    "end": "1585810"
  },
  {
    "text": "So it tells you\nthat if I give you an infinite number of samples,\nthen the network actually uses all its parameters.",
    "start": "1585810",
    "end": "1591870"
  },
  {
    "text": "All the parameters are\nnecessary to make predictions on this infinite amount of data. But if I don't give you\nenough samples, then because",
    "start": "1591870",
    "end": "1599280"
  },
  {
    "text": "of the shape of\nthe eigen spectrum, you're not using all the degrees\nof freedom available to you. You do not have\nenough information",
    "start": "1599280",
    "end": "1605510"
  },
  {
    "text": "to constrain all those\ndegrees of freedom. Typically, in practice,\nonly about half a percent,",
    "start": "1605510",
    "end": "1611010"
  },
  {
    "text": "not 50%, half a percent\nof the number of weights are actually constrained.",
    "start": "1611010",
    "end": "1617230"
  },
  {
    "text": "So when someone says, I fit a\nnetwork with 1 million weights, they're really fitting a\nmodel with about 5,000 degrees",
    "start": "1617230",
    "end": "1624549"
  },
  {
    "text": "of freedom. And it shouldn't be a\nsurprise at that point that we can get good test error. The networks are secretly small.",
    "start": "1624550",
    "end": "1630910"
  },
  {
    "text": "We just lie about\nthem to everyone. So here is a cartoon of\nthis entire business.",
    "start": "1630910",
    "end": "1638919"
  },
  {
    "text": "If you think of the manifold\nof functions that are expressed or that are expressed on\nthis data by the network,",
    "start": "1638920",
    "end": "1645640"
  },
  {
    "text": "the learning typically\nhappens in the stiff part of the eigen spectrum. We shoudl take out the\nFisher at initialization.",
    "start": "1645640",
    "end": "1651280"
  },
  {
    "text": "The weights predominantly\nmove in the stiff subspace. They don't move in the sloppy\nsubspace for two reasons.",
    "start": "1651280",
    "end": "1657310"
  },
  {
    "text": "One is because these are\noptimization problems that are low dimensional. Yes, but they are incredibly\nbadly conditioned.",
    "start": "1657310",
    "end": "1664570"
  },
  {
    "text": "So even if you take a quadratic\nwith an aspect ratio of 10 is to 6, you're not going\nto be able to minimize that",
    "start": "1664570",
    "end": "1670090"
  },
  {
    "text": "very easily. But it doesn't matter because\nthe sloppy degrees of freedom do not affect your\npredictions much.",
    "start": "1670090",
    "end": "1676840"
  },
  {
    "text": "You're already getting\nthe 95% accuracy. And the remaining 5% is\ncoming from the sloppy parts.",
    "start": "1676840",
    "end": "1683110"
  },
  {
    "text": "So you find learning corresponds\nto you initializing somewhere in the interior\nof such a manifold and then fitting the\nlong sides of this.",
    "start": "1683110",
    "end": "1690190"
  },
  {
    "text": "And we call such\nmanifolds hyper-ribbons. They are very long\nin some directions. And then there are many,\nmany, many directions",
    "start": "1690190",
    "end": "1696637"
  },
  {
    "text": "where the ribbon is very thin. It's just like the ribbon\nthat you use in everyday life.",
    "start": "1696637",
    "end": "1703810"
  },
  {
    "text": "So over the last\nyear or so, we've been basically making this\npicture more and more rigorous.",
    "start": "1703810",
    "end": "1709450"
  },
  {
    "text": "And this is the\nsubject of two papers. The first one will be presented\nat ICML in a couple of months.",
    "start": "1709450",
    "end": "1716080"
  },
  {
    "text": "And the second one, we just put\nout an archive last week or so.",
    "start": "1716080",
    "end": "1721480"
  },
  {
    "text": "Here is how I will explain that. So I would like to understand\nthe space of probability",
    "start": "1721480",
    "end": "1726970"
  },
  {
    "text": "distributions that are expressed\nor parameterized by the network when it learns.",
    "start": "1726970",
    "end": "1734440"
  },
  {
    "text": "This is an infinite\ndimensional object. So p of y, given y is an\noutput. x is an input. w",
    "start": "1734440",
    "end": "1741340"
  },
  {
    "text": "or the weights is\na function of x. I can plug in any x\ninto this that I want. I get one number.",
    "start": "1741340",
    "end": "1747760"
  },
  {
    "text": "It's not very easy to\nunderstand such an object one, because it's a big\nfunction; and two,",
    "start": "1747760",
    "end": "1753280"
  },
  {
    "text": "because the likelihood\nis a complicated function of the weights. That is really the grief\nof the entire business.",
    "start": "1753280",
    "end": "1759700"
  },
  {
    "text": "We do a pretty cheap\ntrick to get around this. It's a little bit like someone\ntold you to take a functional",
    "start": "1759700",
    "end": "1767260"
  },
  {
    "text": "analysis class. You did not take it. So you take the function. You measure it at a fixed\nfinite number of points.",
    "start": "1767260",
    "end": "1774400"
  },
  {
    "text": "And then now you pretend\nthat you have a vector and forget that you're\ndealing with a function. In our case, the\npoints at which we",
    "start": "1774400",
    "end": "1781900"
  },
  {
    "text": "want to measure the likelihood\nare pretty naturally selected. These are simply the\ntraining samples.",
    "start": "1781900",
    "end": "1787150"
  },
  {
    "text": "So if you think of ImageNet,\nImageNet has 1 million samples. So N is 1 million.",
    "start": "1787150",
    "end": "1792550"
  },
  {
    "text": "For each of these\nsamples, you are betting 1,000 numbers,\n1,000 probabilities for each of the 1,000 classes.",
    "start": "1792550",
    "end": "1798680"
  },
  {
    "text": "So you have 1\nmillion times 1,000, which is 1 billion\ndimensional vector.",
    "start": "1798680",
    "end": "1805030"
  },
  {
    "text": "That is a representation of the\nmodel that you have learned. Doesn't matter what\narchitecture you have.",
    "start": "1805030",
    "end": "1811670"
  },
  {
    "text": "Doesn't matter how\nyou train this model. So long as two networks\nhave this exact same vector,",
    "start": "1811670",
    "end": "1817450"
  },
  {
    "text": "they are the same\nmodels, at least as evidenced by the samples\nin your training data set. You could have other samples\nwhere the two functions differ,",
    "start": "1817450",
    "end": "1824860"
  },
  {
    "text": "and you wouldn't know\nabout it in this business. So here is what\nwe will try to do.",
    "start": "1824860",
    "end": "1831070"
  },
  {
    "text": "In this space, let's\nsay that you have a billion dimensional space. It's not a vector\nspace, but it's",
    "start": "1831070",
    "end": "1836080"
  },
  {
    "text": "a product manifold of spheres\nof 1,000 dimensional spheres",
    "start": "1836080",
    "end": "1841779"
  },
  {
    "text": "on which the probabilities\nlie and 1 million product of such spheres. On this manifold, two\npoints are kind of special.",
    "start": "1841780",
    "end": "1848380"
  },
  {
    "text": "The first one is what we\nlike to call the truth. It is the one hot probabilities\nof all the samples,",
    "start": "1848380",
    "end": "1854360"
  },
  {
    "text": "which is the solution\nof the training set. This is what we want to\nfit at the end of the day. At the beginning, people like\nto initialize their networks",
    "start": "1854360",
    "end": "1862419"
  },
  {
    "text": "so that the network predicts\n1 over 1,000, 1 over 1,000 for every class,\nfor every image. That is what we call ignorance.",
    "start": "1862420",
    "end": "1869190"
  },
  {
    "text": "So the name of the\ngame when you train a network is you begin training\nat this point called ignorance.",
    "start": "1869190",
    "end": "1876210"
  },
  {
    "text": "You end training at\nthis point called truth. And then you are now doomed to\nlive in this billion dimensions.",
    "start": "1876210",
    "end": "1882637"
  },
  {
    "text": "And the question is\nhow you get there.  This is a legitimate\nprobability distribution.",
    "start": "1882637",
    "end": "1889080"
  },
  {
    "text": "So we can define distances\nbetween two points. If you have two\ndistributions, Pu, and Pv,",
    "start": "1889080",
    "end": "1894810"
  },
  {
    "text": "we like to use what is called\nthe Bhattacharyya distance. The Bhattacharyya distance,\nif you haven't seen it before,",
    "start": "1894810",
    "end": "1900870"
  },
  {
    "text": "for the purposes of\nthis calculation, you can just think of\nsymmetric divergence. The reason to use\nthis is as follows--",
    "start": "1900870",
    "end": "1908490"
  },
  {
    "text": "so in these dimensions,\nanything that you use to measure\ndistances between points",
    "start": "1908490",
    "end": "1913770"
  },
  {
    "text": "goes to hell pretty quickly. It saturates. So if you take the Hellinger\ndistance in these dimensions,",
    "start": "1913770",
    "end": "1918870"
  },
  {
    "text": "it will always saturate. So you have to use things\nthat are not metrics. The Bhattacharyya distance\nor the symmetric divergence",
    "start": "1918870",
    "end": "1926160"
  },
  {
    "text": "is not a metric. It's a distance. It's positive but not symmetric. The [? kl ?] is not symmetric,\nbut it doesn't satisfy",
    "start": "1926160",
    "end": "1933360"
  },
  {
    "text": "the triangle inequality. And because of that,\nyou can get confused when you interpret these\nkinds of calculations,",
    "start": "1933360",
    "end": "1939450"
  },
  {
    "text": "because triangle\ninequality is not valid. But we figured out ways\nto work around that.",
    "start": "1939450",
    "end": "1944760"
  },
  {
    "text": "So here is what we\nare going to do. We're going to train\nhundreds of thousands of models in this space\nand then project them down",
    "start": "1944760",
    "end": "1952840"
  },
  {
    "text": "into lower dimensional spaces\nto understand how the training process behaves.",
    "start": "1952840",
    "end": "1957910"
  },
  {
    "text": "Conceptually, it's a lot like\ndoing PCA, Principal Component Analysis. We use something called as\nmultidimensional scaling,",
    "start": "1957910",
    "end": "1964300"
  },
  {
    "text": "slightly more old fashioned. But this is the same\ncalculations PCA, essentially.",
    "start": "1964300",
    "end": "1970180"
  },
  {
    "text": "PCA preserves Euclidean\ndistances between points. MDS preserves your favorite\ndistance in, this case,",
    "start": "1970180",
    "end": "1976460"
  },
  {
    "text": "the Bhattacharyya\ndistance between points. Now another thing that is pretty\ncool and technical about this",
    "start": "1976460",
    "end": "1981970"
  },
  {
    "text": "is that typically,\nMDS is very popular in the bioinformatics\nliterature, where they'll",
    "start": "1981970",
    "end": "1987159"
  },
  {
    "text": "use it to calculate the\ndistances between sequences of genes and stuff like this. And after you do this\nembedding, PCA eigenvalues",
    "start": "1987160",
    "end": "1994840"
  },
  {
    "text": "are always positive. We all know that. MDS eigenvalues need\nnot always be positive. There can also be some\nnegative eigenvalues.",
    "start": "1994840",
    "end": "2001170"
  },
  {
    "text": "So You're embedding\ninto Minkowski spaces with imaginary coordinates. And bioinformatics\npeople typically",
    "start": "2001170",
    "end": "2007460"
  },
  {
    "text": "like to throw away such\nimaginary coordinates. We believe that there\nis meaning to them, and so I'll show you what\nexactly is this meaning.",
    "start": "2007460",
    "end": "2013700"
  },
  {
    "text": "But here is the setup. We take many, many networks,\ntrain them, calculate all these big vectors,\nproject them down",
    "start": "2013700",
    "end": "2019730"
  },
  {
    "text": "into lower dimensional spaces,\nand then we'll see what they do. Yeah, so here is a picture.",
    "start": "2019730",
    "end": "2025240"
  },
  {
    "text": "Every point is one\nneural network here. There is six different\narchitectures, fully connected",
    "start": "2025240",
    "end": "2032020"
  },
  {
    "text": "networks, CNNs, transformers,\nsmall ResNets and large ResNets.",
    "start": "2032020",
    "end": "2038110"
  },
  {
    "text": "They all begin training at\nessentially the same point up to statistical\nfluctuations called ignorance.",
    "start": "2038110",
    "end": "2043389"
  },
  {
    "text": "P0 is that point. They all end at the truth. You don't see the\ntruth in this plot.",
    "start": "2043390",
    "end": "2048908"
  },
  {
    "text": "It is off the edge for\nreasons I'll tell you later. And what I have done is I took\nabout these six architectures",
    "start": "2048909",
    "end": "2057040"
  },
  {
    "text": "trained with SGD with nested\nacceleration with ADAM,",
    "start": "2057040",
    "end": "2062530"
  },
  {
    "text": "different batch sizes, different\nlearning rates, with weight decay, without weight\ndecay, with augmentation, without augmentation, about\n2,300 different configurations",
    "start": "2062530",
    "end": "2070239"
  },
  {
    "text": "of networks, about 150,000\ndifferent points that are checkpointed\nalong the trajectories",
    "start": "2070239",
    "end": "2076270"
  },
  {
    "text": "of these 2,300 configurations. And when you plot\nthe first three",
    "start": "2076270",
    "end": "2083690"
  },
  {
    "text": "dimensions of this\nembedding, what you notice is that this is CIFAR-10. So the space in\nwhich these points",
    "start": "2083690",
    "end": "2089987"
  },
  {
    "text": "live, this probability\ndistribution is lived is 50,000 samples\ntimes 10 outputs. So half a million dimensions.",
    "start": "2089987",
    "end": "2097190"
  },
  {
    "text": "In this half a\nmillion dimensions, the top three dimensions capture\nabout 76% of the variance.",
    "start": "2097190",
    "end": "2103570"
  },
  {
    "text": "This is telling\nyou that in spite of the huge diversity in\nwhat these networks are,",
    "start": "2103570",
    "end": "2109330"
  },
  {
    "text": "they live in what is\nbasically a three- or four-dimensional manifold. I can write you\ndown a description",
    "start": "2109330",
    "end": "2114370"
  },
  {
    "text": "of each of these points in\nthree, four coordinates. And it would be a\nfaithful description. I wouldn't be\ncheating in the sense",
    "start": "2114370",
    "end": "2121000"
  },
  {
    "text": "that pairwise distances would\nbe preserved up to this much. So this is the intrinsically\nlow dimensionality",
    "start": "2121000",
    "end": "2129069"
  },
  {
    "text": "of the optimization\nproblem we are solving. The networks themselves\nhave huge numbers. So large ResNet in this case\nhas about 40 million weights.",
    "start": "2129070",
    "end": "2136300"
  },
  {
    "text": "And many others have\ncomparable ones. In spite of that, it is a\n3/4 dimensional problem.",
    "start": "2136300",
    "end": "2142450"
  },
  {
    "text": "So a large model\nand a small model. They don't learn\ndifferent things. They not only learn the\nsame thing at the end",
    "start": "2142450",
    "end": "2149380"
  },
  {
    "text": "when they fit the data, but they\nalso learn it in the same way. We can calculate distances\nbetween trajectories",
    "start": "2149380",
    "end": "2156670"
  },
  {
    "text": "in the original space. And we can show that the\ntwo networks, large ResNet and small ResNets, they travel\nalong the same manifold.",
    "start": "2156670",
    "end": "2163030"
  },
  {
    "text": "It's just the larger\none is a bit faster. So when people say that\nlarge networks work well,",
    "start": "2163030",
    "end": "2168560"
  },
  {
    "text": "all that they are really saying\nis that the small network, I did not train it well enough. If I had trained it, perhaps\nit would work as well.",
    "start": "2168560",
    "end": "2175339"
  },
  {
    "text": "Distillation, pruning are all\nevidence of such a statement.",
    "start": "2175340",
    "end": "2181970"
  },
  {
    "text": "All these networks\nhave the same manifold. That is also quite surprising. So not only is it\nthree dimensional,",
    "start": "2181970",
    "end": "2187630"
  },
  {
    "text": "but they also train\nin the same way. And they're all\nrather inefficient. So we can also cut the\ngeodesic in this space,",
    "start": "2187630",
    "end": "2193610"
  },
  {
    "text": "because this space is\na product of spheres. And that would be in some\nsense the shortest path",
    "start": "2193610",
    "end": "2199279"
  },
  {
    "text": "to take between the\nignorance and truth. These networks don't\ntake that path. They all take a\nslightly different path",
    "start": "2199280",
    "end": "2205040"
  },
  {
    "text": "and somehow the same one. These points that you\nsee outside the manifold,",
    "start": "2205040",
    "end": "2212180"
  },
  {
    "text": "we know who to blame\nfor these points. It is ADAM. Typically, when you\ntrain networks with ADAM,",
    "start": "2212180",
    "end": "2217670"
  },
  {
    "text": "you will see huge swings in the\nprobabilities that are predicted for each of these images. But the cool thing\nhere is that these",
    "start": "2217670",
    "end": "2224240"
  },
  {
    "text": "points, if you were just\nto train them further, you would reach 0 error.",
    "start": "2224240",
    "end": "2229380"
  },
  {
    "text": "So all the networks in\nthis entire experiment have 0 training error,\nbarring a couple of dozen.",
    "start": "2229380",
    "end": "2234829"
  },
  {
    "text": "So these points are aberrations\nof the training process, but they are not\naberrant solutions.",
    "start": "2234830",
    "end": "2240049"
  },
  {
    "text": "You just train them further. They will reach the\ncorrect solution. This is just the\ndiffuseness of the manifold.",
    "start": "2240050",
    "end": "2245660"
  },
  {
    "text": "So the training process explores\nvery low-dimensional manifold",
    "start": "2245660",
    "end": "2250670"
  },
  {
    "text": "in spite of this\nhuge dimensionality. Yes. So just to understand this,\nthe lines that you have,",
    "start": "2250670",
    "end": "2256640"
  },
  {
    "text": "they correspond to a G? The lines, I have drawn by hand.",
    "start": "2256640",
    "end": "2261740"
  },
  {
    "text": "They are just to guide your eye. So there are\ndifferent algorithms. So each of the colored\npoints is one architecture.",
    "start": "2261740",
    "end": "2268476"
  },
  {
    "text": "And within that, there are\nthree training methods, different variations\nof hyperparameters, different vintage realizations. And so you can draw--",
    "start": "2268477",
    "end": "2275630"
  },
  {
    "text": "you can connect the\npoints or the trajectory, if you want to look\nat it that way. ",
    "start": "2275630",
    "end": "2282620"
  },
  {
    "text": "Cool. So now let us project the\nsame manifold in the top 2",
    "start": "2282620",
    "end": "2287700"
  },
  {
    "text": "dimensions. So this is PC1 and PC2. And what I want\nyou to think about is that the second eigenvalue\nin this particular experiment",
    "start": "2287700",
    "end": "2299270"
  },
  {
    "text": "of multidimensional\nscaling is negative. So this is a\nMinkowski space where this is a complex\ncoordinate, and this",
    "start": "2299270",
    "end": "2306410"
  },
  {
    "text": "is a real valued coordinate. So distances in this\nspace, they go as delta",
    "start": "2306410",
    "end": "2311750"
  },
  {
    "text": "x squared minus delta y\nsquared, because y is imaginary. P star is the point\nwhere everyone is headed.",
    "start": "2311750",
    "end": "2319010"
  },
  {
    "text": "You can imagine that\nthere is a light cone that comes out of P star. It is a light cone\nthe sides of which",
    "start": "2319010",
    "end": "2325609"
  },
  {
    "text": "are points that have 0\ndistances between them. That is what it means for delta\nx square minus delta y square",
    "start": "2325610",
    "end": "2331430"
  },
  {
    "text": "to be 0 if the eigenvalues\nwere all equal. So these blue\npoints, in this case, are all networks with 0 error.",
    "start": "2331430",
    "end": "2337910"
  },
  {
    "text": "We know that the\nerror 0 is reached long before loss becomes small.",
    "start": "2337910",
    "end": "2343619"
  },
  {
    "text": "And so all these\ndifferent networks, they try to fall on the\nsame light cone, of course,",
    "start": "2343620",
    "end": "2349079"
  },
  {
    "text": "because that is\nthe one of P star. And they have essentially\n0 distances to P star. But tiny, tiny\ndifferent distances.",
    "start": "2349080",
    "end": "2355080"
  },
  {
    "text": "So the cluster loss is never\n0, but it's very, very small and a tiny bit different\nfrom each of these networks. And the visualization\nmethod is plucking out",
    "start": "2355080",
    "end": "2362190"
  },
  {
    "text": "these tiny differences. And this is very spooky. So you have 500,000 dimensions.",
    "start": "2362190",
    "end": "2368550"
  },
  {
    "text": "And these probabilities are\ndifferent in tiny, tiny ways. So you take one image and one\nnetwork, predicts 0.7 and 0.1.",
    "start": "2368550",
    "end": "2375780"
  },
  {
    "text": "The other one predicts\n0.65 and 0.12. The visualization method is\nshowing you the difference.",
    "start": "2375780",
    "end": "2383220"
  },
  {
    "text": "I'm plucking out signal from\nthese large spaces somehow And this is, I think,\na very mysterious",
    "start": "2383220",
    "end": "2390300"
  },
  {
    "text": "why it happens like this. We have some hunches based on\nthe analysis of the Ising model. We can talk about it later.",
    "start": "2390300",
    "end": "2397000"
  },
  {
    "text": "But it's a way to\nunderstand the geometry in these high dimensions but\nalso understand anomalies",
    "start": "2397000",
    "end": "2404070"
  },
  {
    "text": "in these high dimensions. OK, this is how the test\nmanifold looks like.",
    "start": "2404070",
    "end": "2410290"
  },
  {
    "text": "The manifold has\nbasically the same shape, but then there are larger\ndifferences in trajectories",
    "start": "2410290",
    "end": "2415900"
  },
  {
    "text": "of different architectures. In this case, you can\nactually see the truth. In the previous plot, you\ncouldn't see the truth",
    "start": "2415900",
    "end": "2422350"
  },
  {
    "text": "on the same 3D plot. Here, this is the truth. And if you think a little\nbit about what is happening,",
    "start": "2422350",
    "end": "2428920"
  },
  {
    "text": "all these networks, they should\nbe closed to the test truth. Fully connected\nnetworks have 40% error.",
    "start": "2428920",
    "end": "2435830"
  },
  {
    "text": "So there should be far\naway from the test truth. And then corn mixers or large\nResNets have smaller errors.",
    "start": "2435830",
    "end": "2441155"
  },
  {
    "text": "So it will a little\ncloser to the test error. So you think of the\ntruth as the bull's eye that you are trying to hit\nand bad models are far away",
    "start": "2441155",
    "end": "2447880"
  },
  {
    "text": "from the bull's eyes. Good models are close\nto the bull's eye. And you would imagine that there\nis a big circle in which the bad",
    "start": "2447880",
    "end": "2453010"
  },
  {
    "text": "models are spread around,\nbecause they cannot get any closer. But that's not really the case.",
    "start": "2453010",
    "end": "2458319"
  },
  {
    "text": "The fully connected\nnetworks are all together. So they are all making\nthe same mistakes.",
    "start": "2458320",
    "end": "2465730"
  },
  {
    "text": "They are just bad, all of them. The corn mixers are all getting\nthe same things correct.",
    "start": "2465730",
    "end": "2471530"
  },
  {
    "text": "They're all good\nin the same way. So this very classical\nbias variance trade-off",
    "start": "2471530",
    "end": "2476779"
  },
  {
    "text": "that we imagine the bias\nbeing this isotropic thing is not really true.",
    "start": "2476780",
    "end": "2482450"
  },
  {
    "text": "This is very clear\nevidence of this. The manifold here is a tiny bit\nhigher dimensional in this case.",
    "start": "2482450",
    "end": "2488460"
  },
  {
    "text": "It is about 63% in\nthe top 3 dimensions. But the structure is\nbasically the same. We know that these branches come\nfrom-- let's say augmentation",
    "start": "2488460",
    "end": "2494210"
  },
  {
    "text": "versus without\naugmentation, but there is very little differences.",
    "start": "2494210",
    "end": "2499220"
  },
  {
    "text": "Same thing happens on ImageNet. We did not train as many\nmodels, in this case, only three architectures.",
    "start": "2499220",
    "end": "2504740"
  },
  {
    "text": "But the manifold is,\nagain, low dimensional. And basically, all conclusions\nthat we talked about",
    "start": "2504740",
    "end": "2510920"
  },
  {
    "text": "are consistent. OK, so in this space-- so\nthe way we usually work--",
    "start": "2510920",
    "end": "2516569"
  },
  {
    "text": "we've been doing this for a\ngood year, year and a half now-- we draw these pictures.",
    "start": "2516570",
    "end": "2521730"
  },
  {
    "text": "We form hypotheses and\nthen do all the analysis in the original\nhigh-dimensional space",
    "start": "2521730",
    "end": "2527460"
  },
  {
    "text": "so that we don't get\nfooled by the pictures. Because interpreting\nMinkowski spaces is very hard.",
    "start": "2527460",
    "end": "2532830"
  },
  {
    "text": "We have spent lots of\nmonths trying to do it. Yeah. So from this lower\ndimensional picture,",
    "start": "2532830",
    "end": "2539190"
  },
  {
    "text": "it seems like the transformer\nis doing, doing work then? No, so in this case, there\nis no negative eigenvalue.",
    "start": "2539190",
    "end": "2547550"
  },
  {
    "text": "So Euclidean distance between\nthe truth and the transformer. The end point of\nthe ViT trajectory",
    "start": "2547550",
    "end": "2553190"
  },
  {
    "text": "is actually how far the test\nerror would be in this case. So I think if you're\nlooking at the test error,",
    "start": "2553190",
    "end": "2560600"
  },
  {
    "text": "these are 3D plots\nput on 2D paper. It's not that easy to see,\nsay, where this point is.",
    "start": "2560600",
    "end": "2567242"
  },
  {
    "text": "I don't remember.  OK, so what we have developed\nis ways to analyze trajectories",
    "start": "2567242",
    "end": "2575589"
  },
  {
    "text": "in these spaces. And it's a little bit technical\nbecause different networks train at very different speeds.",
    "start": "2575590",
    "end": "2581710"
  },
  {
    "text": "So we have to define some\nunique notion of time for all these networks. And the way we do that is we\nproject all the trajectories",
    "start": "2581710",
    "end": "2588940"
  },
  {
    "text": "on the geodesic, and then we\nimagine a constant velocity particle that travels\nalong the geodesic and assign the time of the\nconstant velocity particle",
    "start": "2588940",
    "end": "2596650"
  },
  {
    "text": "to each of the networks. So a ResNets might make\nmuch faster progress towards the truth after 50\nepochs than a small fully",
    "start": "2596650",
    "end": "2604210"
  },
  {
    "text": "connected network. And then the ResNet will have\na larger value of progress after 50 epochs. And so we can draw\nthis dendrograms.",
    "start": "2604210",
    "end": "2610660"
  },
  {
    "text": "I don't expect you to read this. But what I want to\nshow you is these are dendrograms of trajectories\nof different configurations.",
    "start": "2610660",
    "end": "2618490"
  },
  {
    "text": "I just focused on this one. These are all fully\nconnected networks trained with different\noptimization algorithms.",
    "start": "2618490",
    "end": "2623538"
  },
  {
    "text": "And you notice that\nwhen I clustered my dendrogram like this, all the\narchitectures lit up together.",
    "start": "2623538",
    "end": "2629320"
  },
  {
    "text": "So architectures is\nthe predominant thing that distinguishes\ntrajectories in these spaces.",
    "start": "2629320",
    "end": "2635150"
  },
  {
    "text": "Within each cloud\nof architectures, the optimization algorithms\ncluster themselves",
    "start": "2635150",
    "end": "2640970"
  },
  {
    "text": "into separate clusters. But basically,\ndifferent architectures is what determines\nthe differences",
    "start": "2640970",
    "end": "2647359"
  },
  {
    "text": "in the learned models. Training, hyperparameters of\ntraining or hyperparameters of regularization\nbasically do not matter.",
    "start": "2647360",
    "end": "2655550"
  },
  {
    "text": "Yeah. I would imagine the distance\nfrom the geodesic will--",
    "start": "2655550",
    "end": "2660770"
  },
  {
    "text": "So these are-- So you say your\ndefinition of time here depends on-- like,\nyou project the trajectory",
    "start": "2660770",
    "end": "2666950"
  },
  {
    "text": "of the model on the geodesic. Yeah, by just the\ngreat circle distance. So the distance from\nthe geodesic, of course,",
    "start": "2666950",
    "end": "2673940"
  },
  {
    "text": "will contribute to-- so what I want to say-- The distance from the geodesic\ndoesn't contribute to the time.",
    "start": "2673940",
    "end": "2680930"
  },
  {
    "text": "But If the geodesic is-- imagine the geodesic\nis a straight line, it is a straight line. And then the trajectories can\ngo in different directions.",
    "start": "2680930",
    "end": "2688550"
  },
  {
    "text": "So if you are moving\northogonal to the geodesic, then you will not make progress.",
    "start": "2688550",
    "end": "2694980"
  },
  {
    "text": "Yeah. I guess, yeah,\nbefore you show us that depending on the\narchitecture, essentially,",
    "start": "2694980",
    "end": "2700790"
  },
  {
    "text": "the trajectories depend\non the architecture. So this is another\nmanifestation of that fact,",
    "start": "2700790",
    "end": "2708380"
  },
  {
    "text": "or there is more information? No, this is exactly\nthe same data. I'm not showing you new data. I just put, analyze the\ntrajectories a bit differently.",
    "start": "2708380",
    "end": "2716190"
  },
  {
    "text": "Yeah, I'm saying-- so the\nway trajectories differ",
    "start": "2716190",
    "end": "2721670"
  },
  {
    "text": "from the geodesic,\nyou showed us earlier, depends strongly on\nthe architecture.",
    "start": "2721670",
    "end": "2727220"
  },
  {
    "text": "No, so all the trajectories are\nquite similar to each other. And they're all different\nfrom the geodesic.",
    "start": "2727220",
    "end": "2734119"
  },
  {
    "text": "There are differences in how\nsimilar-- so for instance, all CNNs are a bit\ncloser to the geodesic.",
    "start": "2734120",
    "end": "2739220"
  },
  {
    "text": "And we don't know why, really. But in this plot we treat\nthe geodesic as just one",
    "start": "2739220",
    "end": "2745609"
  },
  {
    "text": "other trajectory. And then this little black\nline that you don't really see very well is\nactually the geodesic.",
    "start": "2745610",
    "end": "2750800"
  },
  {
    "text": "It is far from everyone. A better way to see\nthis is this picture where I did MDS for the\nprobability models before.",
    "start": "2750800",
    "end": "2760460"
  },
  {
    "text": "Now I'm doing MDS\nfor trajectories. We have ways to calculate\ndistances between trajectories. So we can again create a\npairwise distance matrix,",
    "start": "2760460",
    "end": "2766790"
  },
  {
    "text": "do MDS for that pairwise\ndistance matrix, and every point now\nis one trajectory.",
    "start": "2766790",
    "end": "2772160"
  },
  {
    "text": "And you see that the geodesic\nis far away from everyone. But the cool thing, again,\nis that all the architectures",
    "start": "2772160",
    "end": "2777960"
  },
  {
    "text": "are close by. And in this case, for instance,\nthis would be augmentation,",
    "start": "2777960",
    "end": "2783214"
  },
  {
    "text": "or this would be\nno augmentation. So that gets different clusters. Cool.",
    "start": "2783215",
    "end": "2788740"
  },
  {
    "text": "Here is a slightly different\nexperiment of the same kind. The red line here are models\ntrained on the full ImageNet.",
    "start": "2788740",
    "end": "2798160"
  },
  {
    "text": "And the green\nline, for instance, is a model trained only\non all the categories in the vertebrate phylum.",
    "start": "2798160",
    "end": "2804460"
  },
  {
    "text": "This is a subset of ImageNet. And you can just train\na different model. We do some tricks of like how\nto plot in the same space.",
    "start": "2804460",
    "end": "2812320"
  },
  {
    "text": "These models trained\non different tasks. We can talk about it later. But the surprising thing here\nis that trajectories of models",
    "start": "2812320",
    "end": "2820900"
  },
  {
    "text": "trained on different subsets\nof ImageNet still lie in a 3/4-dimensional space.",
    "start": "2820900",
    "end": "2826119"
  },
  {
    "text": "So in the top 3 dimensions,\nthey explained stress. In this case, it's about 88%. So this tells you that not only\nis the manifold of networks",
    "start": "2826120",
    "end": "2835060"
  },
  {
    "text": "trained on the same\ntask low dimensional, the different tasks\nthemselves, the end",
    "start": "2835060",
    "end": "2840549"
  },
  {
    "text": "points of these trajectories are\nproxies for what the task is. Are they the tasks themselves\nare low dimensional?",
    "start": "2840550",
    "end": "2846370"
  },
  {
    "text": "The reason we are good at doing\nfine-tuning or transfer learning or multitask learning or meta\nlearning is because we are",
    "start": "2846370",
    "end": "2852800"
  },
  {
    "text": "solving these three-,\nfour-dimensional problem secretly.",
    "start": "2852800",
    "end": "2858619"
  },
  {
    "text": "We can also do this\nvery cute trick where this is the ontology\nof the classes in WordNet.",
    "start": "2858620",
    "end": "2865369"
  },
  {
    "text": "These are the\ncategories of ImageNet. You can take the distances\nbetween trajectories obtained from this analysis and\nthen reconstruct the ontology.",
    "start": "2865370",
    "end": "2873770"
  },
  {
    "text": "The visual classification\ntask has a priori, nothing to do with the ontology\nthat was created from language",
    "start": "2873770",
    "end": "2881540"
  },
  {
    "text": "and what they seem to be\nconsistent with each other. And this is very cool\nbecause it tells you",
    "start": "2881540",
    "end": "2886790"
  },
  {
    "text": "that there is some shared\nstructure among tasks that goes beyond the modality\nand beyond this very",
    "start": "2886790",
    "end": "2893000"
  },
  {
    "text": "abstract concept of this\nproduct manifold of properties. ",
    "start": "2893000",
    "end": "2900570"
  },
  {
    "text": "You can also do-- in this\npaper, in the ICML paper, we showed a lot\nof things related to this, for instance, meta\nlearning or episodic meta",
    "start": "2900570",
    "end": "2907440"
  },
  {
    "text": "learning and supervised\nlearning, learn the same thing. Episodic meta-learning is just\nhorrendously inefficient in how",
    "start": "2907440",
    "end": "2912810"
  },
  {
    "text": "it gets to the truth. So there is no need\nto do meta learning. You can just happily\ndo supervised learning.",
    "start": "2912810",
    "end": "2919290"
  },
  {
    "text": "And this is, indeed,\nwhat many people have started doing\nsince we started seeing it a few years ago. We also showed that\nself-supervised learning",
    "start": "2919290",
    "end": "2925950"
  },
  {
    "text": "and supervised learning\nlearn the same thing. Self-supervised learning doesn't\ngo all the way to the truth. It stops midway because we don't\nreally know where the truth is.",
    "start": "2925950",
    "end": "2934080"
  },
  {
    "text": "We don't know the true labels. And you can do all kinds\nof analysis by this. The way I would\nsummarize these pictures",
    "start": "2934080",
    "end": "2942360"
  },
  {
    "text": "is that the manifold of\nprobability distributions is looking like a hyper-ribbon.",
    "start": "2942360",
    "end": "2948750"
  },
  {
    "text": "But the different tasks that\nwe are interested in solving, they also project to the same\nparts of the hyper-ribbon.",
    "start": "2948750",
    "end": "2953940"
  },
  {
    "text": "And this is why you\ndo not need to change your model very much when you go\nfrom one task to the other task.",
    "start": "2953940",
    "end": "2959050"
  },
  {
    "text": "All you need to do is modify the\nmodel in the sloppy dimensions. The sloppy dimensions are\nthe one that are actually",
    "start": "2959050",
    "end": "2964780"
  },
  {
    "text": "helping you transfer the model. And this, you can make\nprecise pretty easily. OK, I won't worry about this\nresult. I can tell you later.",
    "start": "2964780",
    "end": "2974150"
  },
  {
    "text": "But let me conclude with-- so as I said, the\nsuccess of deep learning",
    "start": "2974150",
    "end": "2980290"
  },
  {
    "text": "is telling us new\nthings about data. And we have really\nattributed terribly many",
    "start": "2980290",
    "end": "2989170"
  },
  {
    "text": "mysterious properties to\nthese networks over the years. This could be data\nthat explains it.",
    "start": "2989170",
    "end": "2996490"
  },
  {
    "text": "The second one is a tiny\nbit more philosophical. So it is very surprising\nwhy there is so much",
    "start": "2996490",
    "end": "3002640"
  },
  {
    "text": "structure in the data. And if you think a little\nbit like a physicist,",
    "start": "3002640",
    "end": "3008970"
  },
  {
    "text": "there is matter. There is molecules\ninside the table. They give the table certain\nproperties like stress, strain.",
    "start": "3008970",
    "end": "3015930"
  },
  {
    "text": "And why these properties\narise is definitely a question of physics. What function we attribute\nto objects, the fact",
    "start": "3015930",
    "end": "3024020"
  },
  {
    "text": "that images have objects,\nrooms have chairs, or chairs have some\nfunction is of our doing.",
    "start": "3024020",
    "end": "3031319"
  },
  {
    "text": "So the semantics that\nwe attribute to data is really our choice. We don't go around counting\nthe leaves on a tree.",
    "start": "3031320",
    "end": "3038809"
  },
  {
    "text": "We don't go around\ngiving labels to cats that depend on the\nnumber of hair they have.",
    "start": "3038810",
    "end": "3046670"
  },
  {
    "text": "So we created these\nlearning problems. They are easy because you\nwant to identify this bunch",
    "start": "3046670",
    "end": "3052730"
  },
  {
    "text": "of molecules in the next\nimage as being the same cat . And it shouldn't\nbe so surprising",
    "start": "3052730",
    "end": "3057740"
  },
  {
    "text": "that we can learn\nthe same structure in an artificial network. The problem was\neasy to begin with.",
    "start": "3057740",
    "end": "3063530"
  },
  {
    "text": "So in a very vague\nsense, I would say that typical\nproblems are learnable.",
    "start": "3063530",
    "end": "3070339"
  },
  {
    "text": "And what is not\nlearnable, you don't do. So I'll end there\nand take questions.",
    "start": "3070340",
    "end": "3079760"
  },
  {
    "text": "[APPLAUSE] Thank you very much for\nthe fascinating talk.",
    "start": "3079760",
    "end": "3085150"
  },
  {
    "text": "And we already had\nquestions from the audience, and we're running\na little bit late. I don't know if there\nare questions online.",
    "start": "3085150",
    "end": "3091202"
  },
  {
    "text": "There are not, no. OK, so maybe we have time\nfor one very quick question.",
    "start": "3091202",
    "end": "3096339"
  },
  {
    "text": " Yes. So-- A bit far.",
    "start": "3096340",
    "end": "3101560"
  },
  {
    "text": "So you constructed this\nlow-dimensional embedding and then use that as an\nargument that the tasks",
    "start": "3101560",
    "end": "3111250"
  },
  {
    "text": "are easy because they're low\ndimensionally embeddable. So I feel that there\nmight be some element",
    "start": "3111250",
    "end": "3120680"
  },
  {
    "text": "here that I'm missing. Couldn't it look different\nin a different embedding?",
    "start": "3120680",
    "end": "3127190"
  },
  {
    "text": "Like, could it be that a less\nsuccessful embedding would",
    "start": "3127190",
    "end": "3134480"
  },
  {
    "text": "give us not the same narrative?",
    "start": "3134480",
    "end": "3139500"
  },
  {
    "text": "Just how does that work? Yeah, so I think there is really\ntwo parts to that question.",
    "start": "3139500",
    "end": "3144710"
  },
  {
    "text": "The argument that the\ntasks are somehow easy is, strictly\nspeaking, a little bit",
    "start": "3144710",
    "end": "3152240"
  },
  {
    "text": "of a speculation at this point. It doesn't follow\nfrom these results. So that's just\nright off the bat.",
    "start": "3152240",
    "end": "3157730"
  },
  {
    "text": "The second part, which\nis, this embedding gives us the\nlow-dimensional structure. Would some other\nembedding not give it?",
    "start": "3157730",
    "end": "3163940"
  },
  {
    "text": "Yes, you can create embeddings\nthat wouldn't give you this low-dimensional structure. But it is a little\nbit of a question",
    "start": "3163940",
    "end": "3169490"
  },
  {
    "text": "of analysis or sufficiency. There is structure in this\nhigh-dimensional space.",
    "start": "3169490",
    "end": "3175250"
  },
  {
    "text": "This method plucks\nout the structure. If some other method\ndoesn't, then that's the failure of the other method.",
    "start": "3175250",
    "end": "3181050"
  },
  {
    "text": "So we are not married to\nBhattacharyya distance.",
    "start": "3181050",
    "end": "3186110"
  },
  {
    "text": "We are not married to this\nspecific way of doing things. But it is true that\nthere is this structure.",
    "start": "3186110",
    "end": "3193700"
  },
  {
    "text": " All right, well, let's thank,\nonce again, the speaker.",
    "start": "3193700",
    "end": "3202010"
  },
  {
    "text": "And see you next Friday. [APPLAUSE] ",
    "start": "3202010",
    "end": "3211000"
  }
]
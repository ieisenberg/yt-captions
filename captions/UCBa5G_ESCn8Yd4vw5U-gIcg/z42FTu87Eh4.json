[
  {
    "start": "0",
    "end": "65000"
  },
  {
    "start": "0",
    "end": "5330"
  },
  {
    "text": "Great. So let's get started. So the plan for today is\nto really primarily talk",
    "start": "5330",
    "end": "11889"
  },
  {
    "text": "about multi-task\nlearning, but then we'll also go over some of the basics\nof transfer learning as well. In multi-task learning,\nwe'll talk about the problem",
    "start": "11890",
    "end": "18580"
  },
  {
    "text": "statement, we'll talk\nabout model architectures, objectives, and optimization. We'll talk about some\nof the challenges",
    "start": "18580",
    "end": "25180"
  },
  {
    "text": "of multi-task learning, and then\nwe'll go through a case study from a multi-task YouTube\nrecommendation system.",
    "start": "25180",
    "end": "32920"
  },
  {
    "text": "Although it was\nactually quite recent, [INAUDIBLE] that\nwas from last year.",
    "start": "32920",
    "end": "38195"
  },
  {
    "text": "We'll also try to take a short\nbreak after the challenges between the case study,\nlike a couple of minutes, although if we're low on\ntime, we might skip that.",
    "start": "38195",
    "end": "44860"
  },
  {
    "text": "Depends on how many\nquestions there are. And then lastly, the goal is,\nby the end of the lecture,",
    "start": "44860",
    "end": "51620"
  },
  {
    "text": "you should be able to kind\nof understand the key design decisions when building\nmulti-task learning systems, understand the differences\nbetween multi-task learning",
    "start": "51620",
    "end": "58697"
  },
  {
    "text": "and transfer learning,\nand also understand some of the basics\nof transfer learning.",
    "start": "58697",
    "end": "63900"
  },
  {
    "text": "Cool. So that's for the\nplan for today. So first, some\nnotation that I'll",
    "start": "63900",
    "end": "71640"
  },
  {
    "start": "65000",
    "end": "265000"
  },
  {
    "text": "be using throughout the lecture,\nand also likely in future lectures as well. So we'll be considering\nmulti-task learning",
    "start": "71640",
    "end": "79290"
  },
  {
    "text": "with neural networks\nfor the lecture today. And we use x to\ndenote the input,",
    "start": "79290",
    "end": "85980"
  },
  {
    "text": "y to denote the\noutput or the label. And this may be something--",
    "start": "85980",
    "end": "93320"
  },
  {
    "text": "the input may be\nsomething like an image, for example, the\nimage of a tiger.",
    "start": "93320",
    "end": "99570"
  },
  {
    "text": "And then the output may be\na probability distribution over what you\nthink the label is. Whether you think it's a tiger,\na tiger cat, a lynx, a cat.",
    "start": "99570",
    "end": "106680"
  },
  {
    "text": "And so forth. Or the input might be something\nlike the title of a paper.",
    "start": "106680",
    "end": "113190"
  },
  {
    "text": "Maybe you want to know\nwhether or not given a title, you should review that paper. Maybe you don't like reviewing\npapers that are really long,",
    "start": "113190",
    "end": "119910"
  },
  {
    "text": "and so you want to\ntrain a neural network to estimate what the length\nof the paper would be, based off of the\ntitle of the paper.",
    "start": "119910",
    "end": "126790"
  },
  {
    "text": "So the input could be things\nlike images, text, really a wide range of\nunstructured inputs.",
    "start": "126790",
    "end": "132330"
  },
  {
    "text": "And the output is typically\nsomething a little bit simpler, but it's something more\nrelated to what you care about.",
    "start": "132330",
    "end": "139670"
  },
  {
    "text": "We use theta to\ndenote the parameters of the neural network. And then we'll denote\nthe kind of the function",
    "start": "139670",
    "end": "146970"
  },
  {
    "text": "that this neural\nnetwork represents as f, parameterize\ntheta of y given x. ",
    "start": "146970",
    "end": "154269"
  },
  {
    "text": "Cool. So that's kind of the basics. And if we were to do single task\nlearning, such as predicting",
    "start": "154270",
    "end": "159450"
  },
  {
    "text": "the label of an image,\nthen we would typically assume that we have a dataset\nof input output pairs.",
    "start": "159450",
    "end": "165840"
  },
  {
    "text": "And then we would formulate\nsome loss function that may correspond\nto the negative log likelihood, such as\nthe cross entropy loss",
    "start": "165840",
    "end": "171900"
  },
  {
    "text": "or mean squared\nerror, and then try to minimize this\nobjective function,",
    "start": "171900",
    "end": "177360"
  },
  {
    "text": "and specifically search\nover the parameters theta. ",
    "start": "177360",
    "end": "184099"
  },
  {
    "text": "And so your loss function\nmight look something like this. And then typically, you\noptimize this loss function with stochastic\ngradient descent,",
    "start": "184100",
    "end": "190250"
  },
  {
    "text": "or your other kind of\nyour favorite optimizer. OK, so now let's revisit the\nquestion of, what is a task?",
    "start": "190250",
    "end": "198360"
  },
  {
    "text": "And this will allow us to set\nup the multi-task learning problem. ",
    "start": "198360",
    "end": "203723"
  },
  {
    "text": "And we'll talk about this\nactually a little bit more formally than what\nwe did last lecture.",
    "start": "203723",
    "end": "210020"
  },
  {
    "text": "So we'll define a task as\na set of three things, p",
    "start": "210020",
    "end": "215290"
  },
  {
    "text": "of x, p of y given x,\nand the loss function. And in particular,\nthese distributions p",
    "start": "215290",
    "end": "222760"
  },
  {
    "text": "are representing essentially the\ndata generating distributions. i is indexing the task.",
    "start": "222760",
    "end": "229780"
  },
  {
    "text": "And each of these tasks will\nhave a corresponding data set that is drawn from the\ndata generating distributions.",
    "start": "229780",
    "end": "238043"
  },
  {
    "text": "Typically, you assume that you\nhave a train set and a test set, where you train\non the train set,",
    "start": "238043",
    "end": "243070"
  },
  {
    "text": "and then during evaluation,\nyou evaluate on the test set.",
    "start": "243070",
    "end": "249240"
  },
  {
    "text": "We'll also use di as\nshorthand for d train i throughout the rest\nof this lecture,",
    "start": "249240",
    "end": "255180"
  },
  {
    "text": "just to simplify\nsome of the notation. ",
    "start": "255180",
    "end": "260357"
  },
  {
    "text": "OK, so this going to be our\nformal definition of a task. Now, let's look\nat a few examples of what tasks might look like.",
    "start": "260357",
    "end": "268190"
  },
  {
    "start": "265000",
    "end": "420000"
  },
  {
    "text": "So one version of a\nmultitask learning problem would be multitask\nclassification,",
    "start": "268190",
    "end": "275568"
  },
  {
    "text": "where maybe you want\nto be able to classify different kinds of objects. And in this setting,\nthe loss function",
    "start": "275568",
    "end": "280900"
  },
  {
    "text": "is going to be the same\nacross all of the tasks. It might be negative log\nlikelihood, or cross entropy",
    "start": "280900",
    "end": "288940"
  },
  {
    "text": "loss, or something. And some examples\nof this is maybe you want to be able to\nrecognize different handwriting",
    "start": "288940",
    "end": "297639"
  },
  {
    "text": "characters for\ndifferent languages, and different languages will\ncorrespond to different tasks. Or maybe you want a spam\nfilter, and different tasks",
    "start": "297640",
    "end": "306190"
  },
  {
    "text": "will correspond to\ndifferent users. And they're-- essentially,\nin both of these settings, the distribution over x and the\ndistribution over y given x are",
    "start": "306190",
    "end": "315850"
  },
  {
    "text": "going to be different\nfor different tasks, because different users have\ndifferent kinds of emails, and also different languages,\nwrite characters in different",
    "start": "315850",
    "end": "324370"
  },
  {
    "text": "ways. But what will be kind\nof the same across tasks will be the loss function.",
    "start": "324370",
    "end": "331490"
  },
  {
    "text": "So this is one example of a\nmulti-task learning problem. ",
    "start": "331490",
    "end": "337310"
  },
  {
    "text": "Another example of a\nmulti-tasking learning problem is what's called\nmulti-label learning.",
    "start": "337310",
    "end": "343060"
  },
  {
    "text": "In this setting,\nthe loss function and the distribution\nover x are going",
    "start": "343060",
    "end": "349930"
  },
  {
    "text": "to be the same across tasks. And it's this distribution,\np of y given x,",
    "start": "349930",
    "end": "355810"
  },
  {
    "text": "that's going to be different. So an example of this\nis trying to recognize",
    "start": "355810",
    "end": "363880"
  },
  {
    "text": "different attributes of faces. So maybe one label\ncorresponds to recognizing whether someone's\nwearing sunglasses,",
    "start": "363880",
    "end": "370030"
  },
  {
    "text": "or whether someone's\nwearing a hat, or another label is\nrecognizing someone's eye",
    "start": "370030",
    "end": "375340"
  },
  {
    "text": "color, or something like that. So in this, basically, the\ndata set that you have,",
    "start": "375340",
    "end": "380590"
  },
  {
    "text": "both the data generating\ndistribution over x, and also often the input x in\nyour training data set are identical, but\nwhat's different is you",
    "start": "380590",
    "end": "387608"
  },
  {
    "text": "have different labels.  OK, and then the kind of an\nexample of scene understanding",
    "start": "387608",
    "end": "394370"
  },
  {
    "text": "that actually comes\nup a lot is when you want to understand a\nscene or an image of a scene. You typically may want\nto predict the depth,",
    "start": "394370",
    "end": "401840"
  },
  {
    "text": "you may want to predict\nsome key points, you may want to predict\nthe surface normals. And each of these\ndifferent labels",
    "start": "401840",
    "end": "411350"
  },
  {
    "text": "correspond to different tasks. ",
    "start": "411350",
    "end": "416389"
  },
  {
    "text": "OK. And someone's asking me to\ntalk a little bit slower, so I'll try to do that.",
    "start": "416390",
    "end": "423500"
  },
  {
    "text": "The last question is, when\nmight the loss function vary across tasks?",
    "start": "423500",
    "end": "429980"
  },
  {
    "text": "So in both of these\nfirst two examples, the loss function is\nthe same across tasks. And what's really\ndifferent is the data",
    "start": "429980",
    "end": "435919"
  },
  {
    "text": "generating distribution. There's a few settings\nwhere we might see the loss function\nvary across tasks as well.",
    "start": "435920",
    "end": "442789"
  },
  {
    "text": "One might be where we have\nkind of some labels that are discrete, and some\nlabels are continuous, and you may want to\nhave different loss",
    "start": "442790",
    "end": "449569"
  },
  {
    "text": "functions for different\nkinds of data, different kinds of labels. And the second scenario\nmight be if you",
    "start": "449570",
    "end": "457130"
  },
  {
    "text": "care about multiple different\nmetrics of your performance. Maybe for your spam filter,\nyou want it to be accurate,",
    "start": "457130",
    "end": "466160"
  },
  {
    "text": "but maybe you also want it\nto treat different emails",
    "start": "466160",
    "end": "473700"
  },
  {
    "text": "in different ways. Maybe the way that it\nclassifies spam and ham,",
    "start": "473700",
    "end": "479460"
  },
  {
    "text": "you may want to kind of label\nthings in different ways. Maybe another\nexample of this that",
    "start": "479460",
    "end": "485520"
  },
  {
    "text": "we'll actually see\nin the real world example for recommendation\nsystems, is maybe you",
    "start": "485520",
    "end": "490590"
  },
  {
    "text": "want it to be able to-- maybe you have a\nmetric that it cares about kind of user\nsatisfaction, and another thing",
    "start": "490590",
    "end": "499139"
  },
  {
    "text": "that cares about how long\nthe user is paying attention to a video.",
    "start": "499140",
    "end": "506870"
  },
  {
    "text": "OK, any questions on\nthese example problems? ",
    "start": "506870",
    "end": "513090"
  },
  {
    "text": "Yes. Can you explain a little more\nabout the kind of language learning recognition\nwhere you're",
    "start": "513090",
    "end": "518899"
  },
  {
    "text": "trying to recognize handwriting\nfor different characters for different languages\nat the same time?",
    "start": "518899",
    "end": "526640"
  },
  {
    "text": "Yeah, so what this\nlooks like is, maybe you have characters\nwritten in Japanese, and also",
    "start": "526640",
    "end": "536930"
  },
  {
    "text": "in like Arabic, like\nEnglish language. And you want a network that\ncan both kind of recognize--",
    "start": "536930",
    "end": "543530"
  },
  {
    "text": " recognize both\nlanguages, rather than",
    "start": "543530",
    "end": "548720"
  },
  {
    "text": "a single system\nthat can recognize just one of the languages.",
    "start": "548720",
    "end": "553740"
  },
  {
    "text": "So in this case, you're going\nto have a different p of x and a different p of y given\nx, because the characters will",
    "start": "553740",
    "end": "560060"
  },
  {
    "text": "look different, and also the\nlabels will be different. Maybe you'll have output-- you'll have kind of\nan output of 0 to 25",
    "start": "560060",
    "end": "568339"
  },
  {
    "text": "for kind of English letters,\nand then maybe you'll have--",
    "start": "568340",
    "end": "573950"
  },
  {
    "text": "I don't know, labels from\n0 to a much larger number for Japanese characters.",
    "start": "573950",
    "end": "580170"
  },
  {
    "text": "Thank you.  Great. Do you have a question?",
    "start": "580170",
    "end": "586050"
  },
  {
    "text": " I just want to\nclarify one thing. I think everything on the right\ntop of the slides looked good,",
    "start": "586050",
    "end": "593200"
  },
  {
    "text": "but on the left top, I just\nwant to make sure I understand. For the task pi of x\nand p of i of y given x,",
    "start": "593200",
    "end": "600430"
  },
  {
    "text": "what are the examples for those? Like just to put\nthose in perspective. Like what was your scenario?",
    "start": "600430",
    "end": "605620"
  },
  {
    "text": "What are these, exactly? Yeah, that's a good question. So pi of x.",
    "start": "605620",
    "end": "613269"
  },
  {
    "text": "So this is essentially the\ndistribution over inputs,",
    "start": "613270",
    "end": "619060"
  },
  {
    "text": "and the distribution\nof labels given inputs. And so in the example\nof Japanese characters,",
    "start": "619060",
    "end": "627610"
  },
  {
    "text": "for example, typically,\nyou have some data of handwritten Japanese\ncharacters, and p of x",
    "start": "627610",
    "end": "635650"
  },
  {
    "text": "will be essentially\nthe distribution that generates that [INAUDIBLE]\nsort of the manifold",
    "start": "635650",
    "end": "644140"
  },
  {
    "text": "of those images. And p of y given\nx is the function underlying whether a label--",
    "start": "644140",
    "end": "651100"
  },
  {
    "text": "kind of a label given\na certain input. Typically, in practice,\nyou don't actually have to deal with these\ngenerating distributions,",
    "start": "651100",
    "end": "658390"
  },
  {
    "text": "you only deal with the\ndata sets themselves. It's useful to think about\nthe generating distributions though because this is--\nwe assume that the train",
    "start": "658390",
    "end": "666360"
  },
  {
    "text": "set and the test set\nare both drawn iid from those data\ngenerating distributions. OK, OK, that makes sense.",
    "start": "666360",
    "end": "672930"
  },
  {
    "text": "Thank you so much. I have one more. So in this multitask\nlearning we're exposing here,",
    "start": "672930",
    "end": "679040"
  },
  {
    "text": "does the model know which task\nit is currently performing, or does it make a\nprediction for all tasks?",
    "start": "679040",
    "end": "685182"
  },
  {
    "text": "Yeah, that's a good question. We'll get to that in\nlike one or two slides.",
    "start": "685182",
    "end": "690970"
  },
  {
    "text": "But typically, the model is\ntold what task it wants to do. ",
    "start": "690970",
    "end": "697698"
  },
  {
    "text": "Quick follow up question\nto that question. What's the function the\ni in the pi dimension?",
    "start": "697698",
    "end": "703800"
  },
  {
    "text": "Was this for a specific\ntraining example? Yeah, so the i is indexing-- I'm just using it to\nindex different tasks.",
    "start": "703800",
    "end": "711460"
  },
  {
    "text": "So one task will have\none index, the other task will have another index.",
    "start": "711460",
    "end": "716490"
  },
  {
    "text": "And I guess part\nof the reason why I mentioned that is, in\nmultitask classification",
    "start": "716490",
    "end": "721500"
  },
  {
    "text": "for example, where li is\nthe same across tasks, then you can actually\nwrite a task as actually",
    "start": "721500",
    "end": "730560"
  },
  {
    "text": "being pi of x, pi of y given x.",
    "start": "730560",
    "end": "736200"
  },
  {
    "text": "And then just a\nsingle loss function that isn't indexed by i.",
    "start": "736200",
    "end": "742290"
  },
  {
    "text": "So I'm just using it to\nindex different tasks. And if it's something that\ndoesn't vary across tasks, then you don't actually\nneed the index.",
    "start": "742290",
    "end": "747965"
  },
  {
    "start": "747965",
    "end": "756960"
  },
  {
    "text": "[INAUDIBLE]\nmultitask setup where we have different alphabets.",
    "start": "756960",
    "end": "762230"
  },
  {
    "text": "Conceptually, why is that\nconsidered multitask? Why don't we treat it as simply,\nthat instead of having alphabet",
    "start": "762230",
    "end": "769410"
  },
  {
    "text": "with 26 letters, we have an\nalphabet of say, 50 letters, where it's letters from both\nalphabets, as a single data",
    "start": "769410",
    "end": "776444"
  },
  {
    "text": "generating distribution and\nsingle [INAUDIBLE] arguments.",
    "start": "776444",
    "end": "782910"
  },
  {
    "text": "Yeah, that's a good question. So like we mentioned in\nthe previous lecture, in multi-task learning problems,\nyou can typically always",
    "start": "782910",
    "end": "790620"
  },
  {
    "text": "represent it as just a single\ntask problem by taking the kind of the data set and\nhaving this be equal to--",
    "start": "790620",
    "end": "798839"
  },
  {
    "text": "having a single data set be\nequal to the union of all of the individual data sets.",
    "start": "798840",
    "end": "804240"
  },
  {
    "text": "And likewise, as the\nkind of the loss function as the sum over the\nindividual loss functions.",
    "start": "804240",
    "end": "812057"
  },
  {
    "text": "So basically, in all\nthese situations, there is a way to\nkind of turn it into a single task\nlearning problem.",
    "start": "812057",
    "end": "817690"
  },
  {
    "text": "And as we'll see in\nthe next few slides, there are scenarios where\nit's useful to treat it as a multitask learning problem\nby kind of changing the network",
    "start": "817690",
    "end": "826920"
  },
  {
    "text": "architecture in different ways,\nor leveraging the structure, or changing the optimization.",
    "start": "826920",
    "end": "832253"
  },
  {
    "start": "832253",
    "end": "838880"
  },
  {
    "text": "So I think in the\nlast lectures where you mentioned that it's\neither equivalent, or at least",
    "start": "838880",
    "end": "845090"
  },
  {
    "text": "faster, or efficient\nto do it this way. I can see how this is more\nefficient, but is that--",
    "start": "845090",
    "end": "851209"
  },
  {
    "text": "or I can see how this is\nfaster, but is it always going to give us better results\nto train it individually--",
    "start": "851210",
    "end": "858110"
  },
  {
    "text": "to train it altogether versus\ntraining it individually? Yeah, so we'll talk\nabout this a bit later.",
    "start": "858110",
    "end": "864720"
  },
  {
    "text": "But the short answer is that\nit depends on the application. There are some situations\nwhere it's actually better",
    "start": "864720",
    "end": "870260"
  },
  {
    "text": "to treat these as separate\ntasks and train them completely independently, and there\nare other situations",
    "start": "870260",
    "end": "875270"
  },
  {
    "text": "where it's helpful to\ntrain them all together. All right, thank you. ",
    "start": "875270",
    "end": "881125"
  },
  {
    "text": "Do you still have a\nquestion, or did you just leave your hand up? OK, great.",
    "start": "881125",
    "end": "886540"
  },
  {
    "text": "Can you unraise your hand? I think you can, Lori. And I can also lower it for you.",
    "start": "886540",
    "end": "891760"
  },
  {
    "text": "Yes. OK, go ahead. Thank you. OK. ",
    "start": "891760",
    "end": "898260"
  },
  {
    "text": "Great.  Let's move on to the next slide.",
    "start": "898260",
    "end": "903870"
  },
  {
    "text": "Actually, there's a\nquestion in the chat. Isn't multitask classification\nalso multi-label learning?",
    "start": "903870",
    "end": "911330"
  },
  {
    "text": "You could also view\nmultitask classification as, in some ways, a form\nof multi-label learning.",
    "start": "911330",
    "end": "917190"
  },
  {
    "text": "I wanted a special\ncase multi-label learning, because p of x\nis the same across tasks, whereas in multi-task\nclassification",
    "start": "917190",
    "end": "923570"
  },
  {
    "text": "it's typically not\nthe same across tasks.  OK, great.",
    "start": "923570",
    "end": "929070"
  },
  {
    "text": "So let's actually\nmove on to how we go about training this model.",
    "start": "929070",
    "end": "935509"
  },
  {
    "start": "930000",
    "end": "1323000"
  },
  {
    "text": "So one thing that we typically\nassume for the different tasks, in addition to what\nwe described before,",
    "start": "935510",
    "end": "942740"
  },
  {
    "text": "is this notion of\na task descriptor, which I'll denote with zi.",
    "start": "942740",
    "end": "948590"
  },
  {
    "text": "And we'll somehow\ncondition the model, we'll fit the model this\ntask descriptor as input.",
    "start": "948590",
    "end": "953928"
  },
  {
    "text": "And this essentially tells\nthe model of what task it's trying to do. ",
    "start": "953928",
    "end": "959590"
  },
  {
    "text": "And then the model\nbecomes something that's actually conditioned on zi.",
    "start": "959590",
    "end": "964700"
  },
  {
    "text": "So for example, if we are again\nthinking about you're trying to figure out what paper-- whether to accept a\npaper to review or not,",
    "start": "964700",
    "end": "971482"
  },
  {
    "text": "maybe you're given\nthe title of the paper and you want to\nknow other things, like you want to know\nthe length of the paper,",
    "start": "971482",
    "end": "977000"
  },
  {
    "text": "you want to know a\nsummary of the paper, you maybe want\nthe neural network to write the review\nfor the paper",
    "start": "977000",
    "end": "982640"
  },
  {
    "text": "as well so that you\ndon't have to write it. Maybe these are the different\ntasks that you want to do.",
    "start": "982640",
    "end": "987890"
  },
  {
    "text": "Then in this example,\nthe task descriptor could correspond to a\nfew different things.",
    "start": "987890",
    "end": "993110"
  },
  {
    "text": "It could correspond to a\none-hot encoding of the task index, which would essentially\njust be if the task index is 2,",
    "start": "993110",
    "end": "1002019"
  },
  {
    "text": "then it would be a vector that\nlooks like this, where there's",
    "start": "1002020",
    "end": "1007750"
  },
  {
    "text": "a 1 in a second location. If the task index\nwas 3, then the 1 would be in the third position.",
    "start": "1007750",
    "end": "1013390"
  },
  {
    "text": "And so forth. zi could also be other\nmetadata that you have.",
    "start": "1013390",
    "end": "1019820"
  },
  {
    "text": "So for example, in a\npersonalization example where different tasks\ncorrespond to different users,",
    "start": "1019820",
    "end": "1025990"
  },
  {
    "text": "then zi might contain\ninformation or features or attributes of that user.",
    "start": "1025990",
    "end": "1031740"
  },
  {
    "text": "It may also correspond\nto a language description of the task. So in this example\nthat we talked about before, maybe a language\ndescription of each",
    "start": "1031740",
    "end": "1039720"
  },
  {
    "text": "of these tasks might be, tell\nme how many pages the paper is. Or give me a summary\nof the paper,",
    "start": "1039720",
    "end": "1046530"
  },
  {
    "text": "or can you write a\nreview of the paper? These would kind of give it\nsome more structured information",
    "start": "1046530",
    "end": "1052403"
  },
  {
    "text": "about what you're\nasking it to do. And this would also be similar\nto a question answering system, for example. ",
    "start": "1052403",
    "end": "1059600"
  },
  {
    "text": "And then it also may be\nsome other more formal specifications of\nthe task as well.",
    "start": "1059600",
    "end": "1066030"
  },
  {
    "text": "And there are some applications\nwhere that may make sense. ",
    "start": "1066030",
    "end": "1071867"
  },
  {
    "text": "OK.  Yes. My question is regarding to\nthe vector spam classification",
    "start": "1071868",
    "end": "1078830"
  },
  {
    "text": "example. And in the case of\nspam classification, the output space is the same\nfor all the users, right?",
    "start": "1078830",
    "end": "1085690"
  },
  {
    "text": "It's either spam or not spam. So when we are conditioning\non the user's features, then wouldn't this resolve to a\nsingle task classification",
    "start": "1085690",
    "end": "1093799"
  },
  {
    "text": "problem instead of a multitask\nclassification problem? Because we are already\nconditioning on the features",
    "start": "1093800",
    "end": "1099320"
  },
  {
    "text": "of the users, and that\nwould be the same.  Yeah. In many ways, when you do\nactually start conditioning",
    "start": "1099320",
    "end": "1107240"
  },
  {
    "text": "on this task\ndescriptor, it does kind of come to us in multitask\nlearning problem.",
    "start": "1107240",
    "end": "1114289"
  },
  {
    "text": "As we'll talk about in\nthe next few slides, there's a number of design\nchoices with regard to, how do you incorporate this task\ndescriptor into the problem?",
    "start": "1114290",
    "end": "1121778"
  },
  {
    "text": "What sort of\narchitecture do you use? And also alternative ways to\noptimize the model as well.",
    "start": "1121778",
    "end": "1129080"
  },
  {
    "text": "Thank you.  All right.",
    "start": "1129080",
    "end": "1134700"
  },
  {
    "text": "I'm wondering for a task with\nthe identifying characters",
    "start": "1134700",
    "end": "1140760"
  },
  {
    "text": "of different languages,\nI understand like how in the training set you can give\na task a descriptor saying, oh,",
    "start": "1140760",
    "end": "1145960"
  },
  {
    "text": "this language is this,\nthis language isn't. But how would you then\ngo to an end result",
    "start": "1145960",
    "end": "1151080"
  },
  {
    "text": "where you want it to\ndetect the language and then classify the character?",
    "start": "1151080",
    "end": "1158110"
  },
  {
    "text": "Yeah, so if you want it\nto detect the language itself and you don't\nwant to give it",
    "start": "1158110",
    "end": "1163210"
  },
  {
    "text": "information about\nwhat language it is, then you could also choose\nnot to condition on zi.",
    "start": "1163210",
    "end": "1168930"
  },
  {
    "text": " And in that setting\nyou may, the kind of the architectures\nthat we'll talk about",
    "start": "1168930",
    "end": "1175034"
  },
  {
    "text": "in the following slides\nwouldn't necessarily apply, because you want to detect\nwhat the task is itself. But some of the\noptimization techniques",
    "start": "1175034",
    "end": "1181610"
  },
  {
    "text": "that we'll talk about\nwould also still apply. Thank you.",
    "start": "1181610",
    "end": "1188169"
  },
  {
    "text": "OK. So once you set up this\narchitecture, then the vanilla",
    "start": "1188170",
    "end": "1193300"
  },
  {
    "text": "objective that you're\ntrying to optimize is what we talked about\nbefore, where you just take all of the loss functions\nfor your individual tasks,",
    "start": "1193300",
    "end": "1201740"
  },
  {
    "text": "sum them, and minimize\nthe summed objective. ",
    "start": "1201740",
    "end": "1209710"
  },
  {
    "text": "And that's kind of-- this\nis really like the basics. Like this is kind of all\nof multitask learning",
    "start": "1209710",
    "end": "1216310"
  },
  {
    "text": "at the very basic level. Now, like I mentioned\nbefore, there's a lot of design\ndecisions with regard",
    "start": "1216310",
    "end": "1222072"
  },
  {
    "text": "to the model, the objective,\nand the optimization. For example, how\nshould we condition",
    "start": "1222072",
    "end": "1228040"
  },
  {
    "text": "on the task descriptor, what\nobjective should we use? Is this vanilla objective\nthe best option,",
    "start": "1228040",
    "end": "1234320"
  },
  {
    "text": "or are there other good options? And also, how do we\noptimize our objective?",
    "start": "1234320",
    "end": "1239510"
  },
  {
    "text": "So the vanilla option\nfor optimization would be to use SDG or add\nthem, but there are also other",
    "start": "1239510",
    "end": "1245572"
  },
  {
    "text": "somewhat delicate design\nchoices there as well. ",
    "start": "1245572",
    "end": "1250930"
  },
  {
    "text": "OK, so these are\nkind of the things that we'll talk about next. We'll talk about how the model\nshould be conditioned on z,",
    "start": "1250930",
    "end": "1257440"
  },
  {
    "text": "and also what\nparameters of the model should be shared and not shared. Well then talk\nabout the objective, and talk about the optimization.",
    "start": "1257440",
    "end": "1264106"
  },
  {
    "text": "But first, let's\ntalk about the model.  So the model-- the kind of the\nfirst question of the model",
    "start": "1264107",
    "end": "1273370"
  },
  {
    "text": "is, how should the model\nbe conditioned on the task? And let's first assume\nthat z is the one-hot task",
    "start": "1273370",
    "end": "1281830"
  },
  {
    "text": "index, like I described before. So I have a question\nfor you, which",
    "start": "1281830",
    "end": "1287450"
  },
  {
    "text": "is, how should you\ncondition on the task if you want the tests to\nshare as little information as",
    "start": "1287450",
    "end": "1293455"
  },
  {
    "text": "possible?  And if you want to give a shot\nat answering this question,",
    "start": "1293455",
    "end": "1299637"
  },
  {
    "text": "please raise your hand. ",
    "start": "1299637",
    "end": "1307830"
  },
  {
    "text": "Could you use the one-hot\nindex to branch off into separate neural\nnetworks for each task?",
    "start": "1307830",
    "end": "1319000"
  },
  {
    "text": "Not sure-- Yeah, exactly.  Yeah, so if you basically\nwant each of the tasks",
    "start": "1319000",
    "end": "1325160"
  },
  {
    "start": "1323000",
    "end": "1633000"
  },
  {
    "text": "to share as little as possible,\nthen what you could do is, you can basically have three\ncompletely separate networks,",
    "start": "1325160",
    "end": "1330440"
  },
  {
    "text": "and use the one-hot task\nidentifier to basically choose",
    "start": "1330440",
    "end": "1335509"
  },
  {
    "text": "which neural network,\nchoose which branch you want it to output.",
    "start": "1335510",
    "end": "1342110"
  },
  {
    "text": "And then do multiplicative\ngating, where you basically",
    "start": "1342110",
    "end": "1347210"
  },
  {
    "text": "take each of the outputs of\neach of these independently trained neural networks with\ncompletely separate weights,",
    "start": "1347210",
    "end": "1352700"
  },
  {
    "text": "and pass that into this function\nhere, that basically iterates",
    "start": "1352700",
    "end": "1358639"
  },
  {
    "text": "over each of the tasks, and\nsees whether the task is the task indicated by z, and\nmultiply that by the output.",
    "start": "1358640",
    "end": "1367903"
  },
  {
    "text": "You can also do what I\nmentioned, which is basically have this gating happen at\nthe beginning of the network as well.",
    "start": "1367903",
    "end": "1373860"
  },
  {
    "text": "And either pass in all\nzeros, for example. And you basically\nhave something like x",
    "start": "1373860",
    "end": "1382440"
  },
  {
    "text": "equals the sum over the\nindex over z, equals j times",
    "start": "1382440",
    "end": "1390240"
  },
  {
    "text": "x, into each of the networks. That would also be equivalent. And so one of the things\nthat you'll note here",
    "start": "1390240",
    "end": "1397080"
  },
  {
    "text": "is that if you take this\narchitecture that gives you this y as output, if you back\npropagate into the network",
    "start": "1397080",
    "end": "1404010"
  },
  {
    "text": "gradients and train the whole\nnetwork for all these tasks, maybe if you're doing-- if\nyour current task is task 2,",
    "start": "1404010",
    "end": "1412132"
  },
  {
    "text": "then the gradients for\nall these other branches will be 0, because of\nthis gating right here. ",
    "start": "1412132",
    "end": "1421400"
  },
  {
    "text": "Any questions? Does that make sense? ",
    "start": "1421400",
    "end": "1427539"
  },
  {
    "text": "My question is kind of\ninto the previous slides.",
    "start": "1427540",
    "end": "1432740"
  },
  {
    "text": "So how do you read across\nthese multiple tasks? So suppose you have\nlike each of the tasks",
    "start": "1432740",
    "end": "1438080"
  },
  {
    "text": "don't have the same amount\nof data, for example, or some of the issues.",
    "start": "1438080",
    "end": "1443360"
  },
  {
    "text": "How do you read across\nthese different tasks, so that one task is not\ntraining on other ones.",
    "start": "1443360",
    "end": "1449780"
  },
  {
    "text": "Yeah, we'll talk\nabout the weighting when we talk about\nthe objective, after we're done\ntalking about the model.",
    "start": "1449780",
    "end": "1455930"
  },
  {
    "text": "We'll talk about that soon. OK, thanks. Hi, another question. So I see what you did here.",
    "start": "1455930",
    "end": "1463160"
  },
  {
    "text": "It makes sense. My question is, what's the\nbenefit of doing it this way? Because it feels\nlike it wouldn't",
    "start": "1463160",
    "end": "1468890"
  },
  {
    "text": "do that much better than\nto baseline of just one neural network\ntrained on this task. Is maybe one to all ensemble,\nlike the outputs of all",
    "start": "1468890",
    "end": "1476390"
  },
  {
    "text": "of them, and have\nmore heavily weight the one whose task\nmatches our input task. I'm just trying to see how\nthis is a little bit better.",
    "start": "1476390",
    "end": "1484429"
  },
  {
    "text": "Yeah, so this isn't necessarily\nsomething that you want to do. This is more kind of\nan illustrative example",
    "start": "1484430",
    "end": "1490370"
  },
  {
    "text": "of how your choice\nof conditioning on z connects to your choice\nof the architecture.",
    "start": "1490370",
    "end": "1498148"
  },
  {
    "text": "And generally, this may not be\nsomething that you want to do. We'll talk about situations when\nyou may want to do this later,",
    "start": "1498148",
    "end": "1503726"
  },
  {
    "text": "but in practice, you\nmay want to share a lot more between the tasks. OK. Thank you, Chelsea.",
    "start": "1503727",
    "end": "1510110"
  },
  {
    "text": "Great. I'm going to go through a\ncouple more of the slides before going into question,\nbecause I think that maybe",
    "start": "1510110",
    "end": "1517733"
  },
  {
    "text": "might answer some questions. But I'll get back to\nyou in a few slides.",
    "start": "1517733",
    "end": "1523300"
  },
  {
    "text": "OK. Right, so this\nbasically corresponds to independent training within\nlike a single neural network",
    "start": "1523300",
    "end": "1530140"
  },
  {
    "text": "architecture, with\nno shared parameters.",
    "start": "1530140",
    "end": "1535160"
  },
  {
    "text": "OK, now the other extreme\nthat you could consider is one where you\nbasically just add the z,",
    "start": "1535160",
    "end": "1546080"
  },
  {
    "text": "like concatenate it\ninto the network. At one point in\nthe architecture, this could be at the beginning,\nthis could be in the middle,",
    "start": "1546080",
    "end": "1553309"
  },
  {
    "text": "towards the end. And if you simply\njust concatenate the z",
    "start": "1553310",
    "end": "1558410"
  },
  {
    "text": "with the activations at one\nof the layers, then basically,",
    "start": "1558410",
    "end": "1564930"
  },
  {
    "text": "all of the parameters of\nthe network are shared. So this is kind of like\nthe other extreme from what we talked about before.",
    "start": "1564930",
    "end": "1571177"
  },
  {
    "text": "And I guess one thing worth\nnoting is that if z is still your one-hot index,\nthen technically, also the parameters directly\nfollowing z will not be shared,",
    "start": "1571177",
    "end": "1581040"
  },
  {
    "text": "because the-- if z\nis a one-hot vector,",
    "start": "1581040",
    "end": "1587430"
  },
  {
    "text": "and you're taking your\nactivations a and your one-hot",
    "start": "1587430",
    "end": "1593160"
  },
  {
    "text": "vector here, then you have,\nsay like 0110, then basically, each of the--",
    "start": "1593160",
    "end": "1600396"
  },
  {
    "text": "you then have a large\nmatrix, W, right here. ",
    "start": "1600396",
    "end": "1607430"
  },
  {
    "text": "Actually, this is typically\nthe other way around. But basically, the\nhalf of the matrix W",
    "start": "1607430",
    "end": "1614179"
  },
  {
    "text": "will contain either\nrows or columns, depending on how you put it. As will contain task\nspecific parameters, because each of\nthe parameters that",
    "start": "1614180",
    "end": "1620510"
  },
  {
    "text": "are multiplied by\nthis index right here will be specific\nto that task. But other than that\nhalf of this W matrix,",
    "start": "1620510",
    "end": "1628820"
  },
  {
    "text": "everything else in the network\nwill have shared parameters. ",
    "start": "1628820",
    "end": "1634820"
  },
  {
    "start": "1633000",
    "end": "2076000"
  },
  {
    "text": "And so this kind of gives\nyou a somewhat alternative architecture-- or alternative view on\nthe multitask architecture",
    "start": "1634820",
    "end": "1642310"
  },
  {
    "text": "which is essentially,\nthink about-- instead of thinking\nabout conditioning on z, think about\nyour parameters,",
    "start": "1642310",
    "end": "1647782"
  },
  {
    "text": "and splitting those parameters\ninto shared parameters and task-specific parameters. And if you do this, then you\ncan write out your objective",
    "start": "1647782",
    "end": "1655480"
  },
  {
    "text": "as something like this, where\nyou have again, your summation over tasks.",
    "start": "1655480",
    "end": "1660940"
  },
  {
    "text": "And what this objective is doing\nis it's simply making it clear",
    "start": "1660940",
    "end": "1666789"
  },
  {
    "text": "that task-specific parameters\ntheta i are only going to be optimized with\nrespect to the task--",
    "start": "1666790",
    "end": "1672549"
  },
  {
    "text": "with respect to\nthe objective li, and they won't be\noptimized when you're using other loss functions.",
    "start": "1672550",
    "end": "1682980"
  },
  {
    "text": "And it turns out that\nbasically, choosing how to condition on this\ntask descriptor, zi,",
    "start": "1682980",
    "end": "1688169"
  },
  {
    "text": "is equivalent to choosing how\nand where to share parameters.",
    "start": "1688170",
    "end": "1693960"
  },
  {
    "start": "1693960",
    "end": "1699520"
  },
  {
    "text": "Yeah. And the way that\nyou can see this is if you take a kind of\na simple architecture, say you have a simple\narchitecture that",
    "start": "1699520",
    "end": "1708130"
  },
  {
    "text": "looks like this, where\nyou have a couple layers and then you split off\ninto two different heads.",
    "start": "1708130",
    "end": "1719865"
  },
  {
    "text": " We'll call this y1 and y2.",
    "start": "1719865",
    "end": "1726309"
  },
  {
    "text": "Then you could\nconsider basically each of the parameters here as\nyour shared parameters, each",
    "start": "1726310",
    "end": "1732730"
  },
  {
    "text": "of the parameters here as\ntask-specific parameters for task 2. And likewise, the\nparameters up here",
    "start": "1732730",
    "end": "1738460"
  },
  {
    "text": "are going to be\ntask-specific for task 1. This is kind of one way\nto view how and where",
    "start": "1738460",
    "end": "1744160"
  },
  {
    "text": "to share parameters. You can also equivalently\nview this as a network that simply conditions on z in\na very particular multiplicative",
    "start": "1744160",
    "end": "1752860"
  },
  {
    "text": "way, where you basically gate\nthe two different outputs",
    "start": "1752860",
    "end": "1758230"
  },
  {
    "text": "of this model. So for example, you\nset the prediction y to be equal to zi, dotted with--",
    "start": "1758230",
    "end": "1768309"
  },
  {
    "text": "maybe you call this a1 and\na2, dotted with the vector a1 and a2. ",
    "start": "1768310",
    "end": "1778890"
  },
  {
    "text": "OK.  Looks like we have a few\nquestions at this point.",
    "start": "1778890",
    "end": "1785100"
  },
  {
    "text": "So do you have a question? OK. ",
    "start": "1785100",
    "end": "1791090"
  },
  {
    "text": "Yeah. I didn't clearly understand\nhow this example there could be [INAUDIBLE]\ncondition [INAUDIBLE]",
    "start": "1791090",
    "end": "1799562"
  },
  {
    "text": "or it must be more of\nthe early conditioning within some point [INAUDIBLE].",
    "start": "1799562",
    "end": "1804650"
  },
  {
    "text": "Yeah. So in this architecture\non the right, for example, this corresponds\nto an architecture",
    "start": "1804650",
    "end": "1812775"
  },
  {
    "text": "where we're basically\nconditioning on zi. And the way that we're\nconditioning on zi is in a multiplicative way.",
    "start": "1812775",
    "end": "1818539"
  },
  {
    "text": "We're essentially gating which\noutput you use, a1 or a2. So this architecture\nis essentially",
    "start": "1818540",
    "end": "1824030"
  },
  {
    "text": "just one way to\ncondition on zi, where you have different branches\nof the architecture, and zi is choosing\nwhich branch to use.",
    "start": "1824030",
    "end": "1830840"
  },
  {
    "text": "And this architecture\non the left is one way to view kind\nof the top point of view,",
    "start": "1830840",
    "end": "1836285"
  },
  {
    "text": "where you have shared parameters\nand task-specific terms. ",
    "start": "1836285",
    "end": "1842473"
  },
  {
    "text": "And I guess one thing\nin here is on the right, it's kind of not clear\nthat these are actually task-specific parameters that\nare only optimized for task 2.",
    "start": "1842473",
    "end": "1849070"
  },
  {
    "text": "That's a little bit less-- little bit less\nclear in this view, and a little bit more\nclear in the other view.",
    "start": "1849070",
    "end": "1854590"
  },
  {
    "text": " Can you explain again\nhow parameter sharing",
    "start": "1854590",
    "end": "1862050"
  },
  {
    "text": "works when feeding into\ndifferent branches?",
    "start": "1862050",
    "end": "1867170"
  },
  {
    "text": "Yeah, so basically\nthe objective here will correspond-- we'll\njust take this objective,",
    "start": "1867170",
    "end": "1875390"
  },
  {
    "text": "compute the gradients. And you'll note that the\ngradient of this objective here is equal to basically\nthe gradient with respect",
    "start": "1875390",
    "end": "1884929"
  },
  {
    "text": "to the shared\nparameters and the task specific parameters of loss 1,\nplus the gradient of the shared",
    "start": "1884930",
    "end": "1892429"
  },
  {
    "text": "parameters and the task-specific\nparameters for task 2 of l2.",
    "start": "1892430",
    "end": "1901430"
  },
  {
    "text": "Uh oh, I think my pen-- pencil ran out of batteries. And so you compute\nthese two gradients,",
    "start": "1901430",
    "end": "1908510"
  },
  {
    "text": "and then when you\nrun gradient descent, you're going to update the\nshared parameters using the sum of these two gradients.",
    "start": "1908510",
    "end": "1914780"
  },
  {
    "text": "And you'll update the\ntask specific parameters with the first term and\nthe second term separately.",
    "start": "1914780",
    "end": "1921470"
  },
  {
    "text": "So the task-specific\nparameters for task 1 will only be updated\nby the first gradient, and the task-specific\nparameters for task 2",
    "start": "1921470",
    "end": "1928340"
  },
  {
    "text": "will only be updated with\nthe second gradient here.",
    "start": "1928340",
    "end": "1933380"
  },
  {
    "text": "In practice, with most\ndeep learning libraries, they can basically\nhandle this for you. They can figure out how each\nparameters will be updated,",
    "start": "1933380",
    "end": "1942680"
  },
  {
    "text": "but it is useful to\nknow kind of what's happening under the hood. That basically, this--\nthat for example,",
    "start": "1942680",
    "end": "1950660"
  },
  {
    "text": "this kind of bottom\nlayer right here is only going to be\nupdated with regard to gradients from task 2.",
    "start": "1950660",
    "end": "1956300"
  },
  {
    "start": "1956300",
    "end": "1962100"
  },
  {
    "text": "Cool. And then-- What happens if I have let's\nsay like overlapping data",
    "start": "1962100",
    "end": "1968149"
  },
  {
    "text": "sets for the different tasks. So we'll say I have\ntask 1 is detect",
    "start": "1968150",
    "end": "1975530"
  },
  {
    "text": "some buildings or\nsomething-- sorry, I'm using my experiences. Task 1 and task 2 have like\nslightly different data sets,",
    "start": "1975530",
    "end": "1984110"
  },
  {
    "text": "because your labelling process\nmay not be comprehensive for all tasks that\nyou want to do.",
    "start": "1984110",
    "end": "1990410"
  },
  {
    "text": "In that situation,\nwouldn't the over-- wouldn't the images or\ntraining examples that",
    "start": "1990410",
    "end": "1997200"
  },
  {
    "text": "have multiple datasets have\na disproportionate impact on the shared\nvector-- on the shared component of the parameters?",
    "start": "1997200",
    "end": "2002860"
  },
  {
    "text": "I mean, how do you\nkind of deal with that? Yeah, so to deal with that\nsort of thing, what you can do",
    "start": "2002860",
    "end": "2009550"
  },
  {
    "text": "is, when sampling the data,\nbasically, don't over sample.",
    "start": "2009550",
    "end": "2015790"
  },
  {
    "text": "Don't basically double\nsample for tasks that have shared data. So for example, one\nthing you could do",
    "start": "2015790",
    "end": "2022360"
  },
  {
    "text": "is just sample from your\ndataset as it is, and then backpropagate whatever losses\nyou have for those data points.",
    "start": "2022360",
    "end": "2029380"
  },
  {
    "text": "Although there is\na bit of a tricky-- there's a bit of a\ntrade off there too, because if you do that, maybe\nif one task is over-represented",
    "start": "2029380",
    "end": "2035192"
  },
  {
    "text": "then your other task will\nnot get enough gradient data. And it's actually\nquite-- usually often quite useful to\nstratify your batches",
    "start": "2035192",
    "end": "2042700"
  },
  {
    "text": "to have an equal amount\nof data for each task. That's a tradeoff\nto keep in mind.",
    "start": "2042700",
    "end": "2047710"
  },
  {
    "text": " I was just wondering, I have\na quick logistic question,",
    "start": "2047710",
    "end": "2053350"
  },
  {
    "text": "could you post these annotated\nslides after the lectures? I can-- we'll post\nthe video, which",
    "start": "2053350",
    "end": "2060270"
  },
  {
    "text": "will include the annotations. Unfortunately, Keynote\ndoesn't save the annotations, but I can also try\nto look into how",
    "start": "2060270",
    "end": "2067980"
  },
  {
    "text": "we might try to export the\nannotations afterwards. Thanks. Yes, please.",
    "start": "2067980",
    "end": "2074869"
  },
  {
    "text": "OK, great. So we kind of went over\nthe basics of conditioning.",
    "start": "2074870",
    "end": "2082460"
  },
  {
    "text": "Now we'll talk about a few\ncommon choices of conditioning. So one choice that we\ntalked about before was",
    "start": "2082460",
    "end": "2089090"
  },
  {
    "text": "concatenation-based\nconditioning, where you take your input,\nyou take some activations of the model, then you\nconcatenate your zi",
    "start": "2089090",
    "end": "2096830"
  },
  {
    "text": "with the activations, or\nmaybe you concatenate it with the input\ndirectly, and then you pass that through\na neural network.",
    "start": "2096830",
    "end": "2103920"
  },
  {
    "text": "So this is a very common choice. Another way that\nyou could do this is with additive conditioning,\nwhere you take the conditioning",
    "start": "2103920",
    "end": "2115810"
  },
  {
    "text": "representation, and pass\nit through a linear layer or something to get\nsomething that's the size of your activations\nor the size of your input.",
    "start": "2115810",
    "end": "2122410"
  },
  {
    "text": "And then you add\nthat to the input. ",
    "start": "2122410",
    "end": "2128800"
  },
  {
    "text": "So these are kind\nof two choices. It turns out these\nfirst two choices are actually\nequivalent, in terms",
    "start": "2128800",
    "end": "2135299"
  },
  {
    "text": "of what the model expresses. I'm curious if\nanyone has thoughts on why concatenation\nand additive",
    "start": "2135300",
    "end": "2143160"
  },
  {
    "text": "conditioning are equivalent. ",
    "start": "2143160",
    "end": "2151370"
  },
  {
    "text": "And if you have an\nidea, raise your hand. You know, I think\nthat I can only",
    "start": "2151370",
    "end": "2156450"
  },
  {
    "text": "have some idea from\na very high level. Working from a really high\nlevel, both of these methods [INAUDIBLE] use conditionally\nto task descriptors",
    "start": "2156450",
    "end": "2165130"
  },
  {
    "text": "as additional feature. OK, so they're both using\nit as an additional feature.",
    "start": "2165130",
    "end": "2173339"
  },
  {
    "text": "So that is-- that's\ncorrect, but maybe there's a more specific answer.",
    "start": "2173340",
    "end": "2179760"
  },
  {
    "text": "Do you have an idea? Yeah, because in the second\ncase you mask the zi's through a linear layer before adding\nthem so those weights could be",
    "start": "2179760",
    "end": "2190940"
  },
  {
    "text": "[INAUDIBLE] to learn by the\nlinear layer that you have in kth form, in the section\nof that linear layer that is",
    "start": "2190940",
    "end": "2199300"
  },
  {
    "text": "specific to the part of the\n[INAUDIBLE] of the array that corresponds to zi's.",
    "start": "2199300",
    "end": "2204997"
  },
  {
    "text": "And when you add them,\nand then output them you get the exact same thing. ",
    "start": "2204997",
    "end": "2210710"
  },
  {
    "text": "Yeah, exactly. So kind of visually, what\nthis looks like is if you--",
    "start": "2210710",
    "end": "2216605"
  },
  {
    "text": "you can essentially\nview this linear layer as the same as the\nweights of kind",
    "start": "2216605",
    "end": "2223300"
  },
  {
    "text": "of half of this--\nlinear layer right here. And visually, what this looks\nlike is, if you basically",
    "start": "2223300",
    "end": "2230319"
  },
  {
    "text": "take the concatenated\nversion and apply the fully connected layer or the\nlinear layer right after that,",
    "start": "2230320",
    "end": "2237940"
  },
  {
    "text": "what that looks like is\ntaking this half of the matrix and applying that to the first\nhalf of the vector, which",
    "start": "2237940",
    "end": "2243190"
  },
  {
    "text": "was the input, and taking this\nhalf of the weight matrix, and applying that to\nthe zi right here.",
    "start": "2243190",
    "end": "2252880"
  },
  {
    "text": "And so basically, yeah, when\nyou apply this linear layer",
    "start": "2252880",
    "end": "2258920"
  },
  {
    "text": "or this fully\nconnected layer, you end up getting\nsomething-- you end up getting these two completely\nindependent halves",
    "start": "2258920",
    "end": "2265650"
  },
  {
    "text": "of that layer. And then you add them when\ndoing the matrix vector multiplication to\nget the result.",
    "start": "2265650",
    "end": "2271030"
  },
  {
    "text": "And so this addition\nright here, basically is the same as the addition\nwhen you're adding right here.",
    "start": "2271030",
    "end": "2280880"
  },
  {
    "text": "OK, so this is\nsomething essentially to keep in mind with\nregard to the conditioning.",
    "start": "2280880",
    "end": "2286730"
  },
  {
    "start": "2286000",
    "end": "2776000"
  },
  {
    "text": "There's also a few other\narchitectures that we briefly mentioned, we had the\nmulti-headed architecture before. And that is\nsomething that's also",
    "start": "2286730",
    "end": "2293120"
  },
  {
    "text": "a common choice\nfor architecture, where you have some shared\nfeatures that produce a shared",
    "start": "2293120",
    "end": "2299329"
  },
  {
    "text": "representation of\nthe input, and then you branch off into\ntask-specific layers. And the other choice is to use\nmultiplicative conditioning,",
    "start": "2299330",
    "end": "2307350"
  },
  {
    "text": "which we also talked a bit about\nbefore, where you take your zi.",
    "start": "2307350",
    "end": "2313102"
  },
  {
    "text": "You maybe pass it\nthrough a linear layer, or you directly multiply\nit with the input",
    "start": "2313102",
    "end": "2319730"
  },
  {
    "text": "to produce the output. This would be like one\nlayer of the network. And as we talked\nabout before, there",
    "start": "2319730",
    "end": "2325760"
  },
  {
    "text": "are kind of close relationships\nbetween multiplicative conditioning and branching,\nlike multi-headed architecture",
    "start": "2325760",
    "end": "2332030"
  },
  {
    "text": "is, when zi corresponds\nto a one-hot vector and you're multiplying directly. ",
    "start": "2332030",
    "end": "2340360"
  },
  {
    "text": "And so yeah, one reason\nwhy multiplicative might be a good idea is that\nfor an individual layer,",
    "start": "2340360",
    "end": "2346150"
  },
  {
    "text": "it's more expressive than\nsimply adding or concatenating. Of course, if the neural network\nlevel, because neural networks",
    "start": "2346150",
    "end": "2352660"
  },
  {
    "text": "are universal function\napproximators, it isn't necessarily going to\nbe more expressive overall. They're probably both going\nto be equally expressive",
    "start": "2352660",
    "end": "2359740"
  },
  {
    "text": "if you have a deep\nenough neural network. But for each\nindividual layer, you do get more expressive power.",
    "start": "2359740",
    "end": "2367360"
  },
  {
    "text": "And then of course it\nalso is closely related to this gating\nand branching idea that we talked about before.",
    "start": "2367360",
    "end": "2373267"
  },
  {
    "text": "So in some ways,\nmultiplicative conditioning generalizes independent\nnetworks, independent heads, and so forth.",
    "start": "2373267",
    "end": "2380230"
  },
  {
    "text": "OK, let's go to a\nfew of the questions. I'm going to assume that you\nhad your hand up from before.",
    "start": "2380230",
    "end": "2388730"
  },
  {
    "text": "Do you have a question, or\nis that also from before? Yeah, I have a question\nabout [INAUDIBLE]..",
    "start": "2388730",
    "end": "2394840"
  },
  {
    "text": "OK.  The gradient seems\nto be equivalent,",
    "start": "2394840",
    "end": "2401012"
  },
  {
    "text": "but in the second layer, I\ndon't have a linear layer after the input within the--",
    "start": "2401012",
    "end": "2407584"
  },
  {
    "text": "they relate-- --linear layer, then they're\nnot quite equivalent.",
    "start": "2407584",
    "end": "2413648"
  },
  {
    "start": "2413648",
    "end": "2422440"
  },
  {
    "text": "I have a question,\non the same slide. So is it equivalent if it means\nif you have a non-linearity",
    "start": "2422440",
    "end": "2427510"
  },
  {
    "text": "as well?  If you also have\nan non-linearity,",
    "start": "2427510",
    "end": "2433000"
  },
  {
    "text": "then they're not exactly,\nexactly equivalent, but depending on how\nthat non-linearity works,",
    "start": "2433000",
    "end": "2438680"
  },
  {
    "text": "it may also still be able\nto represent the same thing. Just to [INAUDIBLE],, so if you\nhave [INAUDIBLE] for example,",
    "start": "2438680",
    "end": "2445290"
  },
  {
    "text": "then in one case, you might\nmask some gradual things, and then when you add\nthose, both the inputs",
    "start": "2445290",
    "end": "2452258"
  },
  {
    "text": "should be negative. And so you have a 0, or\nwhen you concatenate them, you'll have two 0s in\ntwo different places.",
    "start": "2452258",
    "end": "2458950"
  },
  {
    "text": "And depending on\nwhich zeros you put, you're not going to\nhave the same character. ",
    "start": "2458950",
    "end": "2466380"
  },
  {
    "text": "Yeah, so if you add ReLUs\nin different places, you won't get exactly\nthe same architecture.",
    "start": "2466380",
    "end": "2472782"
  },
  {
    "text": "I guess part of the reason\nwhy I was bringing this up is that this suggests that the\nexpressive power of these two",
    "start": "2472782",
    "end": "2477900"
  },
  {
    "text": "kinds of conditioning\nis very similar. Whereas when you move towards\nmultiplicative conditioning, you get more expressive\npower than when",
    "start": "2477900",
    "end": "2484470"
  },
  {
    "text": "you're adding or concatenating. Can you actually\nhold up the reason why multiplicative conditioning\nis a generalization",
    "start": "2484470",
    "end": "2491820"
  },
  {
    "text": "or has a stronger\ngeneralization? So I'm not saying that it has\na stronger generalization.",
    "start": "2491820",
    "end": "2498240"
  },
  {
    "text": "I'm saying that the\nmultiplicative conditioning, you can view it as kind of\na more general way to then",
    "start": "2498240",
    "end": "2506670"
  },
  {
    "text": "simply forming independent\nnetworks and independent heads. So one instantiation of\nmultiplicative conditioning",
    "start": "2506670",
    "end": "2512730"
  },
  {
    "text": "produces this architecture,\nbut multiplicative conditioning can also represent a wide range\nof other kinds of architectures",
    "start": "2512730",
    "end": "2519360"
  },
  {
    "text": "and gating mechanisms as well. But it doesn't necessarily\nlead to better generalization.",
    "start": "2519360",
    "end": "2525329"
  },
  {
    "text": "Isn't it the other\nway around that the multi-head is a\nbetter generalization of [INAUDIBLE] because in one\nyou lose [INAUDIBLE] signals",
    "start": "2525330",
    "end": "2530600"
  },
  {
    "text": "and you just borrow the one,\nbut in multi head isn't there three different signals? ",
    "start": "2530601",
    "end": "2541960"
  },
  {
    "text": "So a multiplicative\nconditioning architecture can represent this-- I guess it kind of\ndepends on where",
    "start": "2541960",
    "end": "2547630"
  },
  {
    "text": "you put the multiplicative\nconditioning, but it can represent\nthis exactly. But because by nature of\nlooking at this gating mechanism",
    "start": "2547630",
    "end": "2555520"
  },
  {
    "text": "where you're basically\ntaking zi and dotting it with the output of\neach of these models.",
    "start": "2555520",
    "end": "2560810"
  },
  {
    "text": "[INAUDIBLE] Sounds good. ",
    "start": "2560810",
    "end": "2567700"
  },
  {
    "text": "Yeah. Sorry, I was just\nconfused about why multiplicative\nconditioning would be more expressive the layer?",
    "start": "2567700",
    "end": "2574930"
  },
  {
    "text": "If there's any\nintuition on that. Yeah. I guess the intuition is that\nif you use additive conditioning",
    "start": "2574930",
    "end": "2582500"
  },
  {
    "text": "at the individual layer, it\ncan't represent multiplication. ",
    "start": "2582500",
    "end": "2590790"
  },
  {
    "text": "Yeah, whereas at the\nentire network level, it can represent that,\nbecause it can essentially--",
    "start": "2590790",
    "end": "2596635"
  },
  {
    "text": "when you kind of-- for example,\nif you concatenate things together, then the\nneural network-- the next couple layers\nin the neural network",
    "start": "2596635",
    "end": "2602970"
  },
  {
    "text": "can represent the\nmultiplication function.",
    "start": "2602970",
    "end": "2608040"
  },
  {
    "text": "But at the individual layer,\nthe additive cannot represent multiplication.",
    "start": "2608040",
    "end": "2614350"
  },
  {
    "text": "So did I answer your question? Yeah, thank you. ",
    "start": "2614350",
    "end": "2621680"
  },
  {
    "text": "Yeah, I had a question about\nmulti-headed architecture as it relates to\nmultiplicative conditioning.",
    "start": "2621680",
    "end": "2627315"
  },
  {
    "text": "I'm not 100% sure how this\nmulti-headed architecture of conditional architecture.",
    "start": "2627315",
    "end": "2633635"
  },
  {
    "text": "Like we're not\nspecifically conditioning that on something, right,\nit will always output,",
    "start": "2633635",
    "end": "2639980"
  },
  {
    "text": "it will always predict\nthree tasks, right? ",
    "start": "2639980",
    "end": "2645140"
  },
  {
    "text": "Yeah, so you can view it\nas a problem as a choice",
    "start": "2645140",
    "end": "2650779"
  },
  {
    "text": "of conditioning, in the sense\nthat if zi is basically like",
    "start": "2650780",
    "end": "2656810"
  },
  {
    "text": "001, for example, you basically\npass the input through all three heads and then gate\nit by this zi right here.",
    "start": "2656810",
    "end": "2665960"
  },
  {
    "text": "Then it will only give\nyou the output of task C.",
    "start": "2665960",
    "end": "2672450"
  },
  {
    "text": "If you basically have\na1, a2, a3, dot, dot.",
    "start": "2672450",
    "end": "2677839"
  },
  {
    "text": "Can I take the dot product\nbetween this output and zi, which is a form of\nmultiplicative conditioning,",
    "start": "2677840",
    "end": "2683490"
  },
  {
    "text": "and this will give you\nthe corresponding output for the corresponding head. OK.",
    "start": "2683490",
    "end": "2688700"
  },
  {
    "text": "And then in multiplicative\nconditioning, do we always have to select\nfrom one or the other,",
    "start": "2688700",
    "end": "2694640"
  },
  {
    "text": "or could it be like a\ncontinuous function? Like instead of inputting\na one-hot encoded values,",
    "start": "2694640",
    "end": "2702799"
  },
  {
    "text": "one-hot encoded vector-- It can be continuous. And if you pass it\nthrough a linear layer,",
    "start": "2702800",
    "end": "2708813"
  },
  {
    "text": "then that will allow it to\nrepresent a lot of other things beyond just the one-hot vector.",
    "start": "2708813",
    "end": "2715020"
  },
  {
    "text": "OK, thank you. I'll take one more\nquestion from--",
    "start": "2715020",
    "end": "2721750"
  },
  {
    "text": "Hi, yeah, I had a\nquestion about attention. I can't say I understand\nattention too well, I wonder if that's a\nway of implementing",
    "start": "2721750",
    "end": "2728470"
  },
  {
    "text": "multiplicative\nconditioning, and also if that's a way of getting\na more dense representation",
    "start": "2728470",
    "end": "2733900"
  },
  {
    "text": "of the task information.  Yeah, that's a good question.",
    "start": "2733900",
    "end": "2740190"
  },
  {
    "text": "Attention in many ways\nboils down to a dot product. So in that sense, it is a way\nto implement this dot product",
    "start": "2740190",
    "end": "2746460"
  },
  {
    "text": "right here. Although I guess this\nisn't quite a dot product, because it's actually just\nlike a multiplication.",
    "start": "2746460",
    "end": "2754500"
  },
  {
    "text": "There is a summation\nover the dimensions. ",
    "start": "2754500",
    "end": "2759547"
  },
  {
    "text": "I'm not sure-- I haven't\nthought about that. I haven't given that\ntoo much thought,",
    "start": "2759547",
    "end": "2765089"
  },
  {
    "text": "but yeah, you could view\nkind of a form of attention potentially as one way\nto condition as well.",
    "start": "2765090",
    "end": "2774339"
  },
  {
    "text": "That segues nicely into\nthe next slide, which is that there actually\nare a number of other more",
    "start": "2774340",
    "end": "2779820"
  },
  {
    "start": "2776000",
    "end": "2881000"
  },
  {
    "text": "complex choices\nthat you can think about with regard to\nconditioning or network architectures as well.",
    "start": "2779820",
    "end": "2784900"
  },
  {
    "text": "Here's just a few of them. There are kind of a wide\nrange of other approaches",
    "start": "2784900",
    "end": "2791340"
  },
  {
    "text": "that the literature\nhas produced as well. Often trying to just target a\nspecific domain like computer",
    "start": "2791340",
    "end": "2797730"
  },
  {
    "text": "vision, or settings\nwhere you would expect to have kind of\nlooking at relationships",
    "start": "2797730",
    "end": "2802950"
  },
  {
    "text": "between objects, or tasks,\nor something like that. ",
    "start": "2802950",
    "end": "2811950"
  },
  {
    "text": "The other thing is that\nfortunately, the design choices of the architecture\nand conditioning",
    "start": "2811950",
    "end": "2818118"
  },
  {
    "text": "are a lot like neural\nnetwork architecture tuning in general, which\nis that they tend to be fairly problem dependent. They're often largely\nguided by intuition,",
    "start": "2818118",
    "end": "2825050"
  },
  {
    "text": "or domain specific\nknowledge of the problem. And in many ways,\nthey're currently",
    "start": "2825050",
    "end": "2831080"
  },
  {
    "text": "more of an art than a science. So I presented kind\nof my scientific view on what the choices are,\nand the expressive power",
    "start": "2831080",
    "end": "2838755"
  },
  {
    "text": "of different choices. But in many ways,\nkind of beyond that, I think it tends to be\na bit more of an art in designing these\narchitectures.",
    "start": "2838755",
    "end": "2845592"
  },
  {
    "text": " OK. Yeah, so this is kind of getting\nto the question in the chat",
    "start": "2845592",
    "end": "2854300"
  },
  {
    "text": "about where do we actually\nconcatenate the conditioning, this is kind of also\na design decision",
    "start": "2854300",
    "end": "2859490"
  },
  {
    "text": "that needs to be kind of\nchosen for the problem. And of course, when you're kind\nof designing architectures,",
    "start": "2859490",
    "end": "2867050"
  },
  {
    "text": "you can use cross-validation to\nhelp guide your search as well. ",
    "start": "2867050",
    "end": "2873109"
  },
  {
    "text": "OK. So that's it for the model.",
    "start": "2873110",
    "end": "2878510"
  },
  {
    "text": "Now, let's talk a bit\nabout the objective. So we talked about\nthe vanilla objective",
    "start": "2878510",
    "end": "2884400"
  },
  {
    "start": "2881000",
    "end": "3086000"
  },
  {
    "text": "before, which is just\nthe summation over all of the tasks. But often, we want to weight\ndifferent tasks differently.",
    "start": "2884400",
    "end": "2891398"
  },
  {
    "text": "So we may want an\nobjective that looks more like this, where there is\na weight for each task.",
    "start": "2891398",
    "end": "2897569"
  },
  {
    "text": "And you want to\nkind of up weight or down weight some\ntasks in various ways.",
    "start": "2897570",
    "end": "2905500"
  },
  {
    "text": "Now, the key\nquestion is now, how do you actually choose\nthese task weights? One way to do it is\njust to manually choose",
    "start": "2905500",
    "end": "2913829"
  },
  {
    "text": "the task weights based on\nwhat you find to work well, or based on some\nsort of priority, if you care more about one\ntask than another task.",
    "start": "2913830",
    "end": "2922460"
  },
  {
    "text": "Unfortunately, manually\nisn't always a great choice, because you have to--",
    "start": "2922460",
    "end": "2929030"
  },
  {
    "text": "it's a manual process. So there's also a number\nof methods that have-- [INAUDIBLE] the idea is\nto actually adjust wi",
    "start": "2929030",
    "end": "2936980"
  },
  {
    "text": "automatically. And actually, dynamically\nadjust them throughout training, in order to lead to a\nbetter optimization,",
    "start": "2936980",
    "end": "2942589"
  },
  {
    "text": "or try to optimize\nthings in a way depending on the application.",
    "start": "2942590",
    "end": "2949859"
  },
  {
    "text": "So how do we actually kind of\ngo about dynamically adjusting them throughout training? So there are various\nheuristics for doing this.",
    "start": "2949860",
    "end": "2957090"
  },
  {
    "text": "So one heuristic that\nhas been fairly popular in the literature is\nto encourage gradients to have similar magnitudes.",
    "start": "2957090",
    "end": "2963769"
  },
  {
    "text": "This is what was proposed in\nthis grad norm paper in 2018.",
    "start": "2963770",
    "end": "2970290"
  },
  {
    "text": "And it's been fairly popular\nand seems to work fairly well. Kind of guided by the intuition\nthat if the gradients had",
    "start": "2970290",
    "end": "2977000"
  },
  {
    "text": "similar magnitudes, then no\none task would be dominating. But it's also a heuristic.",
    "start": "2977000",
    "end": "2982850"
  },
  {
    "text": "So there are other\napproaches that are, I think, less heuristic\nand a bit more principled.",
    "start": "2982850",
    "end": "2988250"
  },
  {
    "text": "One of these is to\nuse task uncertainty. And this actually I think is\na pretty interesting idea is--",
    "start": "2988250",
    "end": "2995390"
  },
  {
    "text": "I guess, it's somewhat elegant\nhow this actually turns out. So there's a paper\nin 2018, and what",
    "start": "2995390",
    "end": "3003640"
  },
  {
    "text": "they talked about is if you want\nto weight your different tasks differently, the\nintuition is that you",
    "start": "3003640",
    "end": "3010030"
  },
  {
    "text": "may want to wait tasks that\nyou're uncertain about higher, so that you can try to\ndecrease your uncertainty",
    "start": "3010030",
    "end": "3015579"
  },
  {
    "text": "for those tasks. So the way that they\nformulated this, is they assume that you have\nbasically a distribution of y",
    "start": "3015580",
    "end": "3024910"
  },
  {
    "text": "given x for each task i. And they set this to be equal\nto the Gaussian distribution",
    "start": "3024910",
    "end": "3033400"
  },
  {
    "text": "if you're doing regression,\nwith a mean that's equal to the output of\nyour neural network,",
    "start": "3033400",
    "end": "3040540"
  },
  {
    "text": "and a variance that is\nalso a learned vector. And it's going to be a\nlearned vector per task.",
    "start": "3040540",
    "end": "3047350"
  },
  {
    "text": "And this is what's going to\nbe your task uncertainty. And this is also what's called\nhomoscedastic uncertainty,",
    "start": "3047350",
    "end": "3055950"
  },
  {
    "text": "if you want to know a cool term. And this is in contrast\nto the typical uncertainty",
    "start": "3055950",
    "end": "3063343"
  },
  {
    "text": "that you might have with\na neural network that is kind of outputting\na different uncertainty for each data point.",
    "start": "3063343",
    "end": "3068529"
  },
  {
    "text": "That's what's known as\nheteroskedastic uncertainty. In this case, it's\nhomoscedastic uncertainty,",
    "start": "3068530",
    "end": "3073900"
  },
  {
    "text": "in the sense that it's\nthe same for all data points within the task. But it's going to be kind of\nrepresenting the uncertainty",
    "start": "3073900",
    "end": "3079930"
  },
  {
    "text": "for that specific task. That's why we have\nan index of i here. This is going to be learned.",
    "start": "3079930",
    "end": "3085339"
  },
  {
    "text": "And it turns out that if you\nessentially minimize the-- ",
    "start": "3085340",
    "end": "3093090"
  },
  {
    "text": "if you minimize the log\nlikelihood of your data points-- or sorry, the\nnegative log likelihood of each",
    "start": "3093090",
    "end": "3101220"
  },
  {
    "text": "of your data points\nfor each of the tasks, you can show that\nbasically, this objective",
    "start": "3101220",
    "end": "3108890"
  },
  {
    "text": "is proportional to sum\nover 1 over 2 sigma squared",
    "start": "3108890",
    "end": "3118730"
  },
  {
    "text": "times li plus log of sigma i.",
    "start": "3118730",
    "end": "3124600"
  },
  {
    "text": "So what this is saying\nis that basically, this corresponds exactly to wi.",
    "start": "3124600",
    "end": "3131840"
  },
  {
    "text": "And for tasks you have a higher\nuncertainty because you have a higher standard deviation\nor higher variance,",
    "start": "3131840",
    "end": "3138589"
  },
  {
    "text": "you should weight those\ndifferently, essentially.",
    "start": "3138590",
    "end": "3153530"
  },
  {
    "text": "Yeah, so if you have higher\nuncertainty, you should-- actually, sorry.",
    "start": "3153530",
    "end": "3158600"
  },
  {
    "text": "Smaller uncertainty should\nlead to a higher task weight, and more uncertainty\nshould actually have a smaller task weight.",
    "start": "3158600",
    "end": "3165126"
  },
  {
    "text": " And I guess the\nthing that I find",
    "start": "3165126",
    "end": "3170330"
  },
  {
    "text": "nice about this is that it\nactually kind of falls directly out of maximum likelihood\ntraining, right here.",
    "start": "3170330",
    "end": "3176450"
  },
  {
    "text": " Do you have a question?",
    "start": "3176450",
    "end": "3184010"
  },
  {
    "text": "Yeah. I was wondering how\nwe get the variance? Yeah. So this is actually-- this term\nright here is actually learned.",
    "start": "3184010",
    "end": "3191900"
  },
  {
    "text": "So it's just going to be a\nvector of learned parameters. So in addition to\nlearning theta-- and maybe I should actually\nhave just written this here.",
    "start": "3191900",
    "end": "3198770"
  },
  {
    "text": "In addition to\nlearning theta, you're also going to be optimizing\neach of these variance vectors. ",
    "start": "3198770",
    "end": "3206836"
  },
  {
    "text": "So it's a variance of like\nthe weights, or something? ",
    "start": "3206836",
    "end": "3212960"
  },
  {
    "text": "It is the variance of this\ndistribution right here.",
    "start": "3212960",
    "end": "3218160"
  },
  {
    "text": "So this is a distribution over\nthe label given the input. And the mean of\nthis distribution",
    "start": "3218160",
    "end": "3223567"
  },
  {
    "text": "is the output of\nthis neural network, and the variance is\ngiven by sigma squared i.",
    "start": "3223568",
    "end": "3231515"
  },
  {
    "text": "Does that make sense? ",
    "start": "3231515",
    "end": "3236880"
  },
  {
    "text": "I'm still kind of lost, but\nI don't have a more precise question to ask, for now.",
    "start": "3236880",
    "end": "3242660"
  },
  {
    "text": "OK.  Yes. How do you know the\ndata is of [INAUDIBLE]??",
    "start": "3242660",
    "end": "3251839"
  },
  {
    "text": "Right. So in the paper,\nthey also derive this for across entropy loss as well.",
    "start": "3251840",
    "end": "3259350"
  },
  {
    "text": "This derivation is specific\nto using regression problems for mean squared error, for\nexample, or assuming a Gaussian",
    "start": "3259350",
    "end": "3266380"
  },
  {
    "text": "distribution.  If you have discrete\nlabels, then you could also derive a\nversion of this as well.",
    "start": "3266380",
    "end": "3275020"
  },
  {
    "text": "Cool. Thank you.  Hey.",
    "start": "3275020",
    "end": "3280630"
  },
  {
    "text": "So from what I\nunderstand, [INAUDIBLE] have these learned weights for\nyour multiple tasks [INAUDIBLE]",
    "start": "3280630",
    "end": "3291630"
  },
  {
    "text": "experience is that if\nGaussian [INAUDIBLE] Gaussian distribution for\nyour [INAUDIBLE],,",
    "start": "3291630",
    "end": "3297750"
  },
  {
    "text": "and that's how you\ncan go [INAUDIBLE].. Is that right? Yeah. OK, perfect.",
    "start": "3297750",
    "end": "3303230"
  },
  {
    "text": " So I just want to make\nsure I understand.",
    "start": "3303230",
    "end": "3309520"
  },
  {
    "text": "Basically, like on the\nhigh level listening sense, like what part of the equation\nis related to the variables",
    "start": "3309520",
    "end": "3318270"
  },
  {
    "text": "that we have the most\nuncertainty about? I'm trying to see where\nwe see mathematically",
    "start": "3318270",
    "end": "3323970"
  },
  {
    "text": "that those are needed more. Yeah, so actually, I think\nI messed up the description",
    "start": "3323970",
    "end": "3329040"
  },
  {
    "text": "a little bit here. So basically this\ntask uncertainty, this is given by this kind\nof sigma squared variable.",
    "start": "3329040",
    "end": "3339510"
  },
  {
    "text": "That's variance, or\nthe task uncertainty, or like as basically\nco-variance in this case?",
    "start": "3339510",
    "end": "3345900"
  },
  {
    "text": "They're basically a\nco-variance in this case. Yeah, so it's the\nvariance over the data",
    "start": "3345900",
    "end": "3356670"
  },
  {
    "text": "distribution of y given x. All right, all right. And then we see\nthat it's weighted",
    "start": "3356670",
    "end": "3362250"
  },
  {
    "text": "more weird in the derivation. So this is where I\nmessed up my description.",
    "start": "3362250",
    "end": "3367590"
  },
  {
    "text": "It's actually weighted less. So weighted less. OK, that makes more sense. And that's why it's logged\nright in the last equation.",
    "start": "3367590",
    "end": "3374160"
  },
  {
    "text": "That's why it's 1 over-- sorry, it's 1 over-- Yeah. It's 1 over 2.",
    "start": "3374160",
    "end": "3379230"
  },
  {
    "text": "Yes. So all right, that makes\na little bit of sense. So that's weighted.",
    "start": "3379230",
    "end": "3384510"
  },
  {
    "text": "OK. All right, so as the variance\nincreases, in this case, as the uncertainty\nincreases, because we",
    "start": "3384510",
    "end": "3391085"
  },
  {
    "text": "don't know what's\ngoing on there, we weight it a little bit less. Yeah, exactly. OK.",
    "start": "3391085",
    "end": "3396240"
  },
  {
    "text": "All right, I can roll with that. Thank you. Yeah. Cool. OK.",
    "start": "3396240",
    "end": "3401290"
  },
  {
    "text": " Now, I think I'm going to\nneed to erase some of this",
    "start": "3401290",
    "end": "3410260"
  },
  {
    "text": "to go on to the next point. Or maybe I should find a better\nway to do this next time.",
    "start": "3410260",
    "end": "3416300"
  },
  {
    "start": "3416000",
    "end": "3599000"
  },
  {
    "text": "So this is one way to produce\nthe weights of your loss",
    "start": "3416300",
    "end": "3422600"
  },
  {
    "text": "function.  And this has actually been\npretty successful in practice.",
    "start": "3422600",
    "end": "3428320"
  },
  {
    "text": "And it's one that's-- it's a method that\nactually, I've seen pretty strong\nperformance now.",
    "start": "3428320",
    "end": "3434350"
  },
  {
    "text": "And used-- it's a\npretty strong baseline that people have used in a\nnumber of papers, even now. ",
    "start": "3434350",
    "end": "3441430"
  },
  {
    "text": "Another approach for\nfinding these weights was to instead\ntake a perspective",
    "start": "3441430",
    "end": "3446529"
  },
  {
    "text": "of multi-objective\noptimization, and try to aim for monotonic\nimprovement of it towards a Pareto\noptimal solution.",
    "start": "3446530",
    "end": "3454010"
  },
  {
    "text": "And what I mean by this,\nI guess, first of all, is kind of define what I mean\nby kind of Pareto optimal.",
    "start": "3454010",
    "end": "3462710"
  },
  {
    "text": "And in particular, what\nthis means is that first, a set of parameters\nwill dominate",
    "start": "3462710",
    "end": "3468230"
  },
  {
    "text": "another set of\nparameters if its loss is lower or equal to the loss of\nthe other set of parameters",
    "start": "3468230",
    "end": "3476360"
  },
  {
    "text": "for all of the tasks, and its\noverall objective is not equal. So basically, what\nthis is saying",
    "start": "3476360",
    "end": "3482630"
  },
  {
    "text": "is that, so you plot the\nnegative loss for one task and the negative loss\nfor another task,",
    "start": "3482630",
    "end": "3489390"
  },
  {
    "text": "ideally, you want to be\nkind of somewhere around here that will\nlead to the lowest. That means that\nyou have the lowest",
    "start": "3489390",
    "end": "3494540"
  },
  {
    "text": "loss for both of the tasks. Then if you have\none vector here,",
    "start": "3494540",
    "end": "3501440"
  },
  {
    "text": "then that is theta\nb, then basically anything in this region right\nhere will dominate theta b.",
    "start": "3501440",
    "end": "3512000"
  },
  {
    "text": "Including things that\nare on this line, and everything that's\nnot in this region, will not dominate theta b.",
    "start": "3512000",
    "end": "3520349"
  },
  {
    "text": "So if theta a is somewhere\nover here, then that means that it dominates theta b.",
    "start": "3520350",
    "end": "3525510"
  },
  {
    "text": "And the reason why\nI'm saying this is that you can define a\ntheta as being Pareto optimal",
    "start": "3525510",
    "end": "3532560"
  },
  {
    "text": "if there exists no other theta\nthat dominates theta star. So basically, if you have a\nnumber of parameter vectors",
    "start": "3532560",
    "end": "3542410"
  },
  {
    "text": "in different positions\nin your thought,",
    "start": "3542410",
    "end": "3547567"
  },
  {
    "text": "maybe these are all the\nkind of parameter vectors that you are able to\nfind, then the ones",
    "start": "3547568",
    "end": "3553390"
  },
  {
    "text": "that are Pareto optimal\nare the ones that are basically on this curve.",
    "start": "3553390",
    "end": "3559540"
  },
  {
    "text": "And this curve is what's\ncalled the Pareto front.",
    "start": "3559540",
    "end": "3564990"
  },
  {
    "text": "And this is relevant\nbecause basically, all the points that are-- if you're at a\nPareto optimal point,",
    "start": "3564990",
    "end": "3570990"
  },
  {
    "text": "then that means that\nimproving for one task will always require\nworsening the performance",
    "start": "3570990",
    "end": "3576300"
  },
  {
    "text": "for another task. As reaching a Pareto\noptimal solution is usually something that's good,\nbecause it means that you've",
    "start": "3576300",
    "end": "3584309"
  },
  {
    "text": "at least gotten to the optimal\nfor one task, and with regard to that optimal,\nall the other tasks",
    "start": "3584310",
    "end": "3589825"
  },
  {
    "text": "are at kind of a\nlocal maximum as well.  OK.",
    "start": "3589825",
    "end": "3595447"
  },
  {
    "text": "And then the last\nthing that you could do for weighting\ntasks differently is to optimize for the\nworst case task class.",
    "start": "3595447",
    "end": "3601740"
  },
  {
    "text": "And this looks like an\nobjective like this, where you're optimizing\nover your parameters, and taking the worst case i, and\nonly optimizing for that one.",
    "start": "3601740",
    "end": "3613200"
  },
  {
    "text": "So this will basically\ntake the task that's performing the worst,\nand only optimize that loss.",
    "start": "3613200",
    "end": "3618539"
  },
  {
    "text": "And the reason why\nthis makes sense is that if you want to be\nkind of robust to the task",
    "start": "3618540",
    "end": "3623869"
  },
  {
    "text": "that you might see at test time. If you imagine that you might\nbe seeing kind of the worst case task at test time, then\nthis is a good thing to do.",
    "start": "3623870",
    "end": "3632300"
  },
  {
    "text": "Or this also\nconnects to fairness. So of different tasks\ncorrespond to different groups",
    "start": "3632300",
    "end": "3637790"
  },
  {
    "text": "of your population,\nthen it might be best to optimize for the one\nthat's doing the worst, to try to ensure that they\nall reach some baseline level",
    "start": "3637790",
    "end": "3644690"
  },
  {
    "text": "of performance. And so this has been used in\nthe distributional robustness",
    "start": "3644690",
    "end": "3650900"
  },
  {
    "text": "literature, and in a range\nof other groups of literature as well. ",
    "start": "3650900",
    "end": "3658720"
  },
  {
    "text": "OK.  So I had a question\nfor b, and I think also",
    "start": "3658720",
    "end": "3665220"
  },
  {
    "text": "related to d point here. So for b, I didn't\nunderstand like if the task has\nhigher uncertainty,",
    "start": "3665220",
    "end": "3672510"
  },
  {
    "text": "wouldn't you want\nto train it more? And then related to\nb, I think, doesn't b",
    "start": "3672510",
    "end": "3678540"
  },
  {
    "text": "go against d as it relates-- in d, you're trying to train\nthat task you're certain about,",
    "start": "3678540",
    "end": "3685609"
  },
  {
    "text": "whereas in b, we're trying to\ntrain more tasks that are not robust.",
    "start": "3685610",
    "end": "3692400"
  },
  {
    "text": "Yeah. So kind of when you would\nuse these different things depends on the application\nthat you're considering.",
    "start": "3692400",
    "end": "3699680"
  },
  {
    "text": "Task uncertainty corresponds\nto kind of a maximum likelihood objective, whereas this\nlower objective corresponds",
    "start": "3699680",
    "end": "3705710"
  },
  {
    "text": "to kind of a robustness\nobjective, which is just different. If you really care about all\nof your tasks being treated",
    "start": "3705710",
    "end": "3715040"
  },
  {
    "text": "fairly, then optimizing\nfor the worst case loss is one thing that\nmakes more sense,",
    "start": "3715040",
    "end": "3720290"
  },
  {
    "text": "than trying to just\nmaximize your likelihood. Whereas if you're\nan application where fairness with regard to\ntasks doesn't necessarily",
    "start": "3720290",
    "end": "3726560"
  },
  {
    "text": "matter that much\nand you just want to optimize overall performance,\nthen one of these earlier",
    "start": "3726560",
    "end": "3732560"
  },
  {
    "text": "approaches may make more sense. ",
    "start": "3732560",
    "end": "3742317"
  },
  {
    "text": "Yeah, thanks. Yeah, in the d, operation of\nworst case loss, if you have a regression task,\nthen sometimes you",
    "start": "3742318",
    "end": "3748786"
  },
  {
    "text": "may just have numbers\nof a larger magnitude. So [INAUDIBLE] will\nstart realizing",
    "start": "3748786",
    "end": "3754270"
  },
  {
    "text": "the loss, specific to\nall the same ballpark? That's one question. And my second question\nis in the loss in green.",
    "start": "3754270",
    "end": "3761200"
  },
  {
    "text": "On the left hand side, loss\nhas negative [INAUDIBLE].. Is that intentional? ",
    "start": "3761200",
    "end": "3767270"
  },
  {
    "text": "Yeah, this is\nintentional on the plots. Basically, I wanted\nit to be such that things away from\nthe origin are better,",
    "start": "3767270",
    "end": "3773160"
  },
  {
    "text": "and that makes it easier\nto see this kind of curve.",
    "start": "3773160",
    "end": "3778922"
  },
  {
    "text": "But the theta is not\nbetter than everything to the top and right, right? It's worse than everything than\nanything to the top and right.",
    "start": "3778922",
    "end": "3785373"
  },
  {
    "text": "So the origin is-- ",
    "start": "3785373",
    "end": "3790700"
  },
  {
    "text": "you'd rather be at like one\nof these points, than be at-- In the plot on the left,\nyou have a plot on the left,",
    "start": "3790700",
    "end": "3797835"
  },
  {
    "text": "[INAUDIBLE].  So that theta is worse than\neverything inside the border",
    "start": "3797835",
    "end": "3803720"
  },
  {
    "text": "plot, right? Yeah. OK, thanks. What about the regression\nthing on plot b?",
    "start": "3803720",
    "end": "3811630"
  },
  {
    "text": "Yeah, so you want to make\nsure that your losses are on similar scales. And if they're not, then\nthis won't make sense,",
    "start": "3811630",
    "end": "3817060"
  },
  {
    "text": "and this won't work. And typically, in\nfairness applications, for example, you are\noptimizing the same objective",
    "start": "3817060",
    "end": "3822309"
  },
  {
    "text": "for different groups. Thank you. OK, I'm actually going to\nmove on to the next slide just",
    "start": "3822310",
    "end": "3829170"
  },
  {
    "text": "for time. Because I want to make sure\nwe get through the case study. Let's talk about optimization. So we'll really just\ncover the basics here.",
    "start": "3829170",
    "end": "3838040"
  },
  {
    "text": "When you have this\nobjective, the approach that you might\ntake to optimize it is to sample a mini batch of\ntasks from your set of tasks.",
    "start": "3838040",
    "end": "3846022"
  },
  {
    "text": "If you have a relatively\nsmall number of tasks, then you may want to just\nsample all of the tasks.",
    "start": "3846022",
    "end": "3852660"
  },
  {
    "text": "Then sample a mini batch of\ndata points for each task.",
    "start": "3852660",
    "end": "3858130"
  },
  {
    "text": "So you'll take the training\ndata for that task, and sample a mini batch\nfor from that data set.",
    "start": "3858130",
    "end": "3864150"
  },
  {
    "text": "Then compute the loss\nfor that mini batch using the loss function,\nand using that mini batch.",
    "start": "3864150",
    "end": "3872869"
  },
  {
    "text": "And then take this, the\nloss for the mini batch, well, for each of\nthe mini batches,",
    "start": "3872870",
    "end": "3879020"
  },
  {
    "text": "and back-propagate the loss into\ntheta to compute the gradient.",
    "start": "3879020",
    "end": "3884300"
  },
  {
    "text": "And then once you\nhave the gradient, use your favorite neural\nnetwork optimizer, such as Adam, to update your neural network.",
    "start": "3884300",
    "end": "3892160"
  },
  {
    "text": "And what this does is\nthat it essentially encourages your model\nto consider data",
    "start": "3892160",
    "end": "3899340"
  },
  {
    "text": "from multiple different\ntasks at every mini batch. In terms of if the tasks\nare sampled uniformly,",
    "start": "3899340",
    "end": "3906150"
  },
  {
    "text": "regardless of whether or\nnot you have a lot more data for one task than\nfor another task.",
    "start": "3906150",
    "end": "3911430"
  },
  {
    "text": "And also, as was\nmentioned before, if you have a\nregression problem, it's good to make\nsure that your task labels are on the same scale.",
    "start": "3911430",
    "end": "3917525"
  },
  {
    "text": "If they're not on\nthe same scale, then you're essentially going\nto be putting a weight in front of the loss functions.",
    "start": "3917525",
    "end": "3925020"
  },
  {
    "text": "That would be equivalent to\nup-weighting the losses that have a larger scale. ",
    "start": "3925020",
    "end": "3932970"
  },
  {
    "text": "OK, so that's the\nbasics of optimizing. Now, a couple of\nthe challenges that",
    "start": "3932970",
    "end": "3939310"
  },
  {
    "text": "come up and multitask learning. One challenge is\nnegative transfer.",
    "start": "3939310",
    "end": "3944440"
  },
  {
    "text": "What this means\nis that sometimes, when you actually\ntrain tasks together in a single architecture,\nthat actually",
    "start": "3944440",
    "end": "3950470"
  },
  {
    "text": "performs worse than if you\ntrain independent networks. ",
    "start": "3950470",
    "end": "3955500"
  },
  {
    "text": "And so an example\nof this, if you look at a multi-task version\nof the CIFAR-100 benchmark",
    "start": "3955500",
    "end": "3961890"
  },
  {
    "text": "and you look at some\nrecent approaches, training an independent\nnetwork gets 67.7,",
    "start": "3961890",
    "end": "3970110"
  },
  {
    "text": "and this actually does\nbetter than a model that",
    "start": "3970110",
    "end": "3975120"
  },
  {
    "text": "only has one--\nthat has basically a shared base and one\ntask-specific fully connected layer.",
    "start": "3975120",
    "end": "3981303"
  },
  {
    "text": "Also another kind of\nmulti-headed architecture does worse than\nindependent training. And this kind of cross\nstitch architecture,",
    "start": "3981303",
    "end": "3987690"
  },
  {
    "text": "which is a fancier\narchitecture, also does worse than\nindependent training. So this is an example where\nwe see negative transfer",
    "start": "3987690",
    "end": "3993780"
  },
  {
    "text": "with these three\narchitectures, compared to an independent model.",
    "start": "3993780",
    "end": "4001040"
  },
  {
    "text": "Why does this happen? This can happen for a\nfew different reasons. It can happen for\noptimization challenges",
    "start": "4001040",
    "end": "4006860"
  },
  {
    "text": "caused by kind of interference\nbetween different gradients. It also may be that\ndifferent tasks may learn at different\nrates, and maybe one task",
    "start": "4006860",
    "end": "4013630"
  },
  {
    "text": "learns a lot more quickly, and\nuses up a lot of the capacity before the other task\nis being learned.",
    "start": "4013630",
    "end": "4020904"
  },
  {
    "text": "It may also be an issue of\nlimited representational capacity. It's often the case\nthat multitasks networks need more capacity\nthan their single task",
    "start": "4020905",
    "end": "4028009"
  },
  {
    "text": "counterpoints. This could also have to do with\nthe optimization challenges before, because if you\nhave a larger network,",
    "start": "4028010",
    "end": "4033845"
  },
  {
    "text": "it may be easier to optimize. And changing these two\nthings, increasing capacity,",
    "start": "4033845",
    "end": "4039530"
  },
  {
    "text": "changing the\noptimization, or changing the architecture in\nsome way, can alleviate issues of negative transfer.",
    "start": "4039530",
    "end": "4044680"
  },
  {
    "text": " And if you do have\na negative transfer,",
    "start": "4044680",
    "end": "4050870"
  },
  {
    "text": "the key thing that you can do\nis to share less across tasks. And of course, this also\nisn't just a binary decision.",
    "start": "4050870",
    "end": "4057500"
  },
  {
    "text": "You can share more parameters,\nyou can share less parameters. But there's also--\nanother thing you",
    "start": "4057500",
    "end": "4064190"
  },
  {
    "text": "could do is to do soft\nparameter sharing. So you could have different\ntask-specific parameters, theta",
    "start": "4064190",
    "end": "4072320"
  },
  {
    "text": "i, and then encourage those\ntask-specific parameters to be more similar\nto each other using",
    "start": "4072320",
    "end": "4077480"
  },
  {
    "text": "a loss that looks like this. That essentially\nminimizes the norm of the difference of those\ndifferent task parameters.",
    "start": "4077480",
    "end": "4085960"
  },
  {
    "text": "And this would be similar\nto basically taking two independently\ntrained networks, and encouraging the weights\nto be similar to one another",
    "start": "4085960",
    "end": "4093380"
  },
  {
    "text": "through a loss that\nlooks like this. So this is kind of\nanother design choice",
    "start": "4093380",
    "end": "4098640"
  },
  {
    "text": "that can go into\nyour architecture. And kind of one rule of\nthumb is that if you're",
    "start": "4098640",
    "end": "4103865"
  },
  {
    "text": "seeing negative\ntransfer, then it could be helpful to share less\nor use soft parameter sharing, or have fewer parameters\nthat are shared.",
    "start": "4103865",
    "end": "4109759"
  },
  {
    "text": " This allows for-- soft\nparameter sharing allows",
    "start": "4109760",
    "end": "4115180"
  },
  {
    "text": "for more fluid degrees\nof parameter sharing, but it could be also yet\nanother set of design decisions",
    "start": "4115180",
    "end": "4120689"
  },
  {
    "text": "with hyper parameters. And in practice, I typically\nsee hard parameter sharing used more than this form\nof soft parameter sharing.",
    "start": "4120689",
    "end": "4127420"
  },
  {
    "text": " And then the second\nchallenge is that you",
    "start": "4127420",
    "end": "4132960"
  },
  {
    "text": "might see is over fitting. And it may be that\nyou're actually not sharing enough of the\nweights of your network.",
    "start": "4132960",
    "end": "4139827"
  },
  {
    "text": "Multitask learning can\nbe essentially viewed as a form of\nregularization where other tasks are regularizing\nthe learning, of learning",
    "start": "4139827",
    "end": "4147990"
  },
  {
    "text": "another task. And so if you find that it seems\nlike it's overfitting a lot,",
    "start": "4147990",
    "end": "4153344"
  },
  {
    "text": "then it could actually\nbe beneficial to share more of the parameters, or\nput more weight on parameter",
    "start": "4153345",
    "end": "4160028"
  },
  {
    "text": "sharing.  OK, do you have a question?",
    "start": "4160029",
    "end": "4166179"
  },
  {
    "text": "Yes. I understand how you talked\nabout combining losses over different tasks\nin the first lecture,",
    "start": "4166180",
    "end": "4172640"
  },
  {
    "text": "but how do combine\nthese inaccuracies? Right. So when you train neural\nnetworks, typically, you use--",
    "start": "4172640",
    "end": "4180160"
  },
  {
    "text": "if you have discrete\nlabels, you typically use cross entropy loss,\nrather than accuracy. Because accuracy isn't really\na differentiable metric.",
    "start": "4180160",
    "end": "4190740"
  },
  {
    "text": "But you have multitask of task\nand you reported 67% accuracy.",
    "start": "4190740",
    "end": "4198782"
  },
  {
    "text": "Is that across the tasks, or\nis multitask itself a task? Yeah, so the accuracy\nnumbers that I",
    "start": "4198782",
    "end": "4205449"
  },
  {
    "text": "was reporting for C4, that's\naveraged across the tasks. OK, thank you. Oftentimes, it's also\nuseful to still report",
    "start": "4205450",
    "end": "4212260"
  },
  {
    "text": "the individual task\naccuracies as well. Do you have a question?",
    "start": "4212260",
    "end": "4218324"
  },
  {
    "text": "Yeah. From the CIFAR-100\nexample, [INAUDIBLE]?? Isn't it like like playing\nlike 100 different networks",
    "start": "4218325",
    "end": "4225080"
  },
  {
    "text": "for each kind of categories\nthat we are doing? So in this case, it was\nactually 10 different tasks",
    "start": "4225080",
    "end": "4230130"
  },
  {
    "text": "that corresponded to some\nof out higher level classes that are in the\nCIFAR-100 dataset. Yeah.",
    "start": "4230130",
    "end": "4235290"
  },
  {
    "text": " OK, cool.",
    "start": "4235290",
    "end": "4242800"
  },
  {
    "text": "So we're short on time, so\nI'm going to skip the break. But hopefully, the questions\nhave been a reasonable break. And let's go straight into\nthe case study of real world",
    "start": "4242800",
    "end": "4250678"
  },
  {
    "text": "multitask learning. And then we probably won't\nget to the transfer learning, but we'll have an opportunity to\ncover that in a future lecture.",
    "start": "4250678",
    "end": "4259540"
  },
  {
    "text": "So the case study\nI'm going to cover is this paper that came out\nin 2019, that's actually",
    "start": "4259540",
    "end": "4265770"
  },
  {
    "text": "a paper describing a way to\nrank videos for serving them",
    "start": "4265770",
    "end": "4272730"
  },
  {
    "text": "as YouTube recommendations. And so the goal is\nbasically to figure out what you want to show the user\nin this kind of part of the--",
    "start": "4272730",
    "end": "4282000"
  },
  {
    "text": "I guess it's all this part\nof the side panel on YouTube for a given user.",
    "start": "4282000",
    "end": "4287865"
  },
  {
    "text": " And they mentioned\nthat there's a number",
    "start": "4287865",
    "end": "4293790"
  },
  {
    "text": "of different\nconflicting objectives when making recommendations. They wanted to\nrate videos that--",
    "start": "4293790",
    "end": "4300119"
  },
  {
    "text": "they wanted to kind\nof recommend videos that the users will rate highly,\nalso videos that the users will",
    "start": "4300120",
    "end": "4305580"
  },
  {
    "text": "share with other\nusers, and also videos that the user will actually\nwatch for a reasonable period",
    "start": "4305580",
    "end": "4311010"
  },
  {
    "text": "of time. And another challenge\nthat comes up is that there's also\nsome amount of feedback.",
    "start": "4311010",
    "end": "4316480"
  },
  {
    "text": "So the user may have\nalso watched a video because it was recommended,\nand if it wasn't recommended,",
    "start": "4316480",
    "end": "4321917"
  },
  {
    "text": "they wouldn't have watched that. And so this is also another\nchallenge that comes up in these recommendation\nsystems, that",
    "start": "4321917",
    "end": "4327630"
  },
  {
    "text": "makes it more\ndifficult to leverage data with the recommendation--\nthe recommendation system was actually in the loop\nof that data collection.",
    "start": "4327630",
    "end": "4334493"
  },
  {
    "text": "This isn't a problem that\nthey address in this work, but this is a problem\nthat can be addressed with some of the reinforcement\nlearning techniques that we'll",
    "start": "4334493",
    "end": "4341970"
  },
  {
    "text": "talk about later in the course.  So the way that\nthey set this up is",
    "start": "4341970",
    "end": "4348190"
  },
  {
    "text": "the input is what the user\nis currently watching, the query video, and some sort\nof user features for that user.",
    "start": "4348190",
    "end": "4357830"
  },
  {
    "text": "And then with this\ninput, they then generate a few hundred\ncandidate videos. They then rank these\ncandidate videos,",
    "start": "4357830",
    "end": "4365710"
  },
  {
    "text": "and then serve the top\nranking videos to the user.",
    "start": "4365710",
    "end": "4371070"
  },
  {
    "text": "The candidate videos,\nthey pool videos from multiple different\ncandidate generation algorithms.",
    "start": "4371070",
    "end": "4376079"
  },
  {
    "text": "This wasn't the\nfocus of the paper. The focus of the paper was\nreally the second step right",
    "start": "4376080",
    "end": "4381450"
  },
  {
    "text": "here. Although the candidate\ngeneration process, different algorithms\nfor matching topics of the query\nvideo, looking at videos",
    "start": "4381450",
    "end": "4388740"
  },
  {
    "text": "most frequently watched\nalongside the query video, and other algorithms.",
    "start": "4388740",
    "end": "4394710"
  },
  {
    "text": "And then the ranking part\nwas the central topic of this paper. So the ranking problem,\nagain, kind of the input",
    "start": "4394710",
    "end": "4402860"
  },
  {
    "text": "is the query video,\nalso the candidate video that they're considering,\nand the user, and the context",
    "start": "4402860",
    "end": "4409010"
  },
  {
    "text": "features. And then the model\noutput is some score that relates to engagement\nand satisfaction",
    "start": "4409010",
    "end": "4415090"
  },
  {
    "text": "with the input candidate video. So engagement might be things\nlike binary classification",
    "start": "4415090",
    "end": "4422070"
  },
  {
    "text": "tasks, like clicks on\nthe video, like numbers",
    "start": "4422070",
    "end": "4427170"
  },
  {
    "text": "of clicks, regression\ntasks, like the time spent watching the video.",
    "start": "4427170",
    "end": "4432660"
  },
  {
    "text": "And satisfaction scores may be\na binary classification task, like predicting whether\nthey would click",
    "start": "4432660",
    "end": "4437880"
  },
  {
    "text": "like for that video, and also\nregression tasks such as rating the video through a survey.",
    "start": "4437880",
    "end": "4444770"
  },
  {
    "text": "And then they use a\nweighted combination of engagement and\nsatisfaction predictions to produce a ranking score\nfor that candidate video.",
    "start": "4444770",
    "end": "4452390"
  },
  {
    "text": " And I found it\ninteresting that actually",
    "start": "4452390",
    "end": "4457600"
  },
  {
    "text": "the weights for the\nscore were actually manually tuned for the\nalgorithm to produce",
    "start": "4457600",
    "end": "4462614"
  },
  {
    "text": "this corresponding\nranking score.  One question-- we're maybe\na little bit low on time,",
    "start": "4462615",
    "end": "4470092"
  },
  {
    "text": "so maybe we won't\ndiscuss this right now. But I encourage\nyou to think about whether this objective is\nreasonable for producing",
    "start": "4470092",
    "end": "4476750"
  },
  {
    "text": "recommendations to a user,\nand what some of the issues-- what issues might come up with\nthese kinds of metrics as well.",
    "start": "4476750",
    "end": "4485310"
  },
  {
    "text": "This, I think, is especially\nrelevant right now, because as kind of\ntechnology is really",
    "start": "4485310",
    "end": "4492530"
  },
  {
    "text": "engaging people's\nattention more and more, this may not actually be a\ndesirable outcome when there",
    "start": "4492530",
    "end": "4498139"
  },
  {
    "text": "are other things that we want\nthe user to spend their time on and their attention on. So I'd encourage you\nto think about this,",
    "start": "4498140",
    "end": "4504230"
  },
  {
    "text": "and really to think about this\nwhen building any real world machine learning system. ",
    "start": "4504230",
    "end": "4511920"
  },
  {
    "text": "OK. The architecture, the\nkind of basic option was the multi-head architecture\nthat we talked about before,",
    "start": "4511920",
    "end": "4519010"
  },
  {
    "text": "where you have multiple bottom\nlayers that are processing the input features in\nthe embedding, and also",
    "start": "4519010",
    "end": "4524610"
  },
  {
    "text": "a couple of task-specific\nlayers for engagement and the other metrics.",
    "start": "4524610",
    "end": "4531635"
  },
  {
    "text": "And they found\nthat this can harm learning when the correlation\nbetween different tasks is low, because they have\nmultiple different shared",
    "start": "4531635",
    "end": "4538200"
  },
  {
    "text": "bottom layers, that may not\nactually be good to share information between. So what they\npropose in this work",
    "start": "4538200",
    "end": "4544510"
  },
  {
    "text": "was to use a form of soft\nparameter sharing, where they had a mixture\nof experts that",
    "start": "4544510",
    "end": "4551920"
  },
  {
    "text": "was gated for different tasks. And basically, what\nthis corresponded to is, they wanted to allow\ndifferent parts of the network",
    "start": "4551920",
    "end": "4558475"
  },
  {
    "text": "to specialize for\ndifferent sub-tasks. So they have different\nexpert neural networks",
    "start": "4558475",
    "end": "4563610"
  },
  {
    "text": "that are written here. This architecture on the left\nshows two different expert layers, expert 1, and expert 2.",
    "start": "4563610",
    "end": "4570920"
  },
  {
    "text": "They then decide which\nexpert to use for a given input and a given task.",
    "start": "4570920",
    "end": "4577320"
  },
  {
    "text": "So this is given by\na softmax function. And then they compute features\nfrom the selected expert,",
    "start": "4577320",
    "end": "4583220"
  },
  {
    "text": "and then eventually compute\nthe output based off of what expert was\nused for which task,",
    "start": "4583220",
    "end": "4589190"
  },
  {
    "text": "and also the features\nfrom that expert. ",
    "start": "4589190",
    "end": "4594201"
  },
  {
    "text": "And then in their\nexperiments, they implemented this with\nTensorFlow on TPUs. They trained the models\nin temporal order,",
    "start": "4594202",
    "end": "4602410"
  },
  {
    "text": "as they got data. It turns out that you have\na lot of data on YouTube. And so they are basically\nrunning training continuously",
    "start": "4602410",
    "end": "4610060"
  },
  {
    "text": "to consume all of the\nnewly arrived data. ",
    "start": "4610060",
    "end": "4615730"
  },
  {
    "text": "And then they kind of looked at\noffline metrics, such as area under the curve, and\nsquared error metrics. They also did online A/B\ntesting in comparison",
    "start": "4615730",
    "end": "4623140"
  },
  {
    "text": "with their production\nsystem, with live metrics. And in this setting,\ncomputational efficiency",
    "start": "4623140",
    "end": "4629440"
  },
  {
    "text": "matters a lot. In the results, they found that\nwith this mixture of experts,",
    "start": "4629440",
    "end": "4635518"
  },
  {
    "text": "multi-gated mixture\nof experts model, they're seeing actually\npretty significant increases in engagement and\nsatisfaction based",
    "start": "4635518",
    "end": "4642360"
  },
  {
    "text": "on the candidates that were\nranked from this algorithm. And they also found\nthat they were seeing kind of\ndifferent experts used",
    "start": "4642360",
    "end": "4649230"
  },
  {
    "text": "in diverse ways for\ndifferent tasks. So for example, expert 7 was\nused a lot for satisfaction task 4, and then\nexpert 2 was used a lot",
    "start": "4649230",
    "end": "4656110"
  },
  {
    "text": "for satisfaction task 2,\nand for satisfaction task 3. ",
    "start": "4656110",
    "end": "4662020"
  },
  {
    "text": "OK, cool. So that's kind of a\nreal world example of a multitask learning system.",
    "start": "4662020",
    "end": "4671360"
  },
  {
    "text": "To kind of respect your time,\nI won't go through the transfer learning. We'll cover that in\na future lecture.",
    "start": "4671360",
    "end": "4678200"
  },
  {
    "text": "And I'll wrap up\nby saying, I guess, we got through this\nfirst point, which",
    "start": "4678200",
    "end": "4684508"
  },
  {
    "text": "is to understand some of\nthe key design decisions when building multitask\nlearning systems. And I'll leave you\nwith a few reminders.",
    "start": "4684508",
    "end": "4691407"
  },
  {
    "text": "For those of you that\nwant to stick around, I'll continue to\nanswer questions. But you're also-- if you need to\ngo, I understand that as well,",
    "start": "4691408",
    "end": "4697970"
  },
  {
    "text": "and I'll see you on Monday. ",
    "start": "4697970",
    "end": "4705000"
  }
]
[
  {
    "start": "5000",
    "end": "209000"
  },
  {
    "text": "Welcome to CS224W, Machine Learning with Graphs.",
    "start": "5358",
    "end": "9719"
  },
  {
    "text": "My name is Jure Leskovec.",
    "start": "9720",
    "end": "11270"
  },
  {
    "text": "I'm Associate Professor of Computer Science at",
    "start": "11270",
    "end": "13570"
  },
  {
    "text": "Stanford University and I will be your instructor.",
    "start": "13570",
    "end": "16825"
  },
  {
    "text": "What I'm going to do in the first lecture is to motivate and get you excited about graph,",
    "start": "16825",
    "end": "22240"
  },
  {
    "text": "uh, structured data and how can we apply novel machine learning methods to it?",
    "start": "22240",
    "end": "28029"
  },
  {
    "text": "So why graphs?",
    "start": "28030",
    "end": "30020"
  },
  {
    "text": "Graphs are a general language for describing and an-",
    "start": "30020",
    "end": "33520"
  },
  {
    "text": "analyzing entities with the relations in interactions.",
    "start": "33520",
    "end": "37375"
  },
  {
    "text": "This means that rather than thinking of the world",
    "start": "37375",
    "end": "40570"
  },
  {
    "text": "or a given domain as a set of isolated datapoints,",
    "start": "40570",
    "end": "44230"
  },
  {
    "text": "we really think of it in terms of networks and relations between these entities.",
    "start": "44230",
    "end": "50090"
  },
  {
    "text": "This means that there is",
    "start": "50090",
    "end": "51800"
  },
  {
    "text": "the underla- ler- underlying graph of relations between the entities,",
    "start": "51800",
    "end": "56270"
  },
  {
    "text": "and these entities are related, uh,",
    "start": "56270",
    "end": "58820"
  },
  {
    "text": "to each other, uh,",
    "start": "58820",
    "end": "60079"
  },
  {
    "text": "according to these connections or the structure of the graph.",
    "start": "60080",
    "end": "62800"
  },
  {
    "text": "And there are many types of data that can naturally be",
    "start": "62800",
    "end": "66710"
  },
  {
    "text": "represented as graphs and modeling these graphical relations,",
    "start": "66710",
    "end": "70670"
  },
  {
    "text": "these relational structure of the underlying domain,",
    "start": "70670",
    "end": "73534"
  },
  {
    "text": "uh, allows us to, uh,",
    "start": "73535",
    "end": "75065"
  },
  {
    "text": "build much more faithful,",
    "start": "75065",
    "end": "76340"
  },
  {
    "text": "much more accurate, uh,",
    "start": "76340",
    "end": "77600"
  },
  {
    "text": "models of the underlying,",
    "start": "77600",
    "end": "79100"
  },
  {
    "text": "uh, phenomena underlying data.",
    "start": "79100",
    "end": "81095"
  },
  {
    "text": "So for example, we can think of a computer networks, disease pathways, uh,",
    "start": "81095",
    "end": "86730"
  },
  {
    "text": "networks of particles in physics, uh,",
    "start": "86730",
    "end": "89460"
  },
  {
    "text": "networks of organisms in food webs,",
    "start": "89460",
    "end": "92030"
  },
  {
    "text": "infrastructure, as well as events can all be represented as a graphs.",
    "start": "92030",
    "end": "97250"
  },
  {
    "text": "Similarly, we can think of social networks,",
    "start": "97250",
    "end": "100400"
  },
  {
    "text": "uh, economic networks, communication networks,",
    "start": "100400",
    "end": "103760"
  },
  {
    "text": "say patients between different papers,",
    "start": "103760",
    "end": "106370"
  },
  {
    "text": "Internet as a giant communication network,",
    "start": "106370",
    "end": "109115"
  },
  {
    "text": "as well as ways on how neurons in our brain are connected.",
    "start": "109115",
    "end": "113149"
  },
  {
    "text": "Again, all these domains are inherently network or graphs.",
    "start": "113150",
    "end": "118025"
  },
  {
    "text": "And that representation allows us to capture",
    "start": "118025",
    "end": "120710"
  },
  {
    "text": "the relationships between different objects or entities,",
    "start": "120710",
    "end": "123934"
  },
  {
    "text": "uh, in these different, uh, domains.",
    "start": "123934",
    "end": "126545"
  },
  {
    "text": "And last, we can take knowledge and",
    "start": "126545",
    "end": "129515"
  },
  {
    "text": "represent facts as relationships between different entities.",
    "start": "129515",
    "end": "133610"
  },
  {
    "text": "We can describe the regulatory mechanisms in our cells,",
    "start": "133610",
    "end": "137914"
  },
  {
    "text": "um, as processes governed by the connections between different entities.",
    "start": "137914",
    "end": "142580"
  },
  {
    "text": "We can even take scenes from real world and presented them",
    "start": "142580",
    "end": "147455"
  },
  {
    "text": "as graphs of relationships between the objects in the scene.",
    "start": "147455",
    "end": "152600"
  },
  {
    "text": "These are called scene graphs.",
    "start": "152600",
    "end": "154160"
  },
  {
    "text": "We can take computer code software and represent it as a graph of, let's say,",
    "start": "154160",
    "end": "159560"
  },
  {
    "text": "calls between different functions or as",
    "start": "159560",
    "end": "162349"
  },
  {
    "text": "a structure of the code captures by the abstract syntax tree.",
    "start": "162350",
    "end": "165800"
  },
  {
    "text": "We can also naturally take molecules which are composed of nodes, uh,",
    "start": "165800",
    "end": "170600"
  },
  {
    "text": "of atoms and bonds as a set of graphs, um,",
    "start": "170600",
    "end": "175370"
  },
  {
    "text": "where we represent atoms as nodes and their bonds as edges between them.",
    "start": "175370",
    "end": "180409"
  },
  {
    "text": "And of course, in computer graphics,",
    "start": "180410",
    "end": "182150"
  },
  {
    "text": "we can take three-dimensional shapes and- and represent them, um, as a graphs.",
    "start": "182150",
    "end": "187329"
  },
  {
    "text": "So in all these domains,",
    "start": "187330",
    "end": "189230"
  },
  {
    "text": "graphical structure is the- is",
    "start": "189230",
    "end": "191810"
  },
  {
    "text": "the important part that allows us to model the under- underlying domain,",
    "start": "191810",
    "end": "195620"
  },
  {
    "text": "underlying phenomena in a fateful way.",
    "start": "195620",
    "end": "198530"
  },
  {
    "text": "So the way we are going to think about graph",
    "start": "198530",
    "end": "201455"
  },
  {
    "text": "relational data in this class is that there are essentially two big,",
    "start": "201455",
    "end": "205040"
  },
  {
    "text": "uh, parts, uh, of data that can be represented as graphs.",
    "start": "205040",
    "end": "209144"
  },
  {
    "start": "209000",
    "end": "256000"
  },
  {
    "text": "First are what is called natural graphs or networks,",
    "start": "209145",
    "end": "212810"
  },
  {
    "text": "where underlying domains can naturally be represented as graphs.",
    "start": "212810",
    "end": "216780"
  },
  {
    "text": "For example, social networks,",
    "start": "216780",
    "end": "218990"
  },
  {
    "text": "societies are collection of seven billion individuals and connections between them,",
    "start": "218990",
    "end": "223355"
  },
  {
    "text": "communications and transactions between electronic devices, phone calls,",
    "start": "223355",
    "end": "227629"
  },
  {
    "text": "financial transactions, all naturally form, uh, graphs.",
    "start": "227630",
    "end": "231930"
  },
  {
    "text": "In biomedicine we have genes,",
    "start": "231930",
    "end": "234109"
  },
  {
    "text": "proteins regulating biological processes,",
    "start": "234110",
    "end": "237109"
  },
  {
    "text": "and we can represent interactions between",
    "start": "237109",
    "end": "239510"
  },
  {
    "text": "these different biological entities with a graph.",
    "start": "239510",
    "end": "243584"
  },
  {
    "text": "And- and as I mentioned,",
    "start": "243585",
    "end": "245215"
  },
  {
    "text": "connections between neurons in our brains are,",
    "start": "245215",
    "end": "248485"
  },
  {
    "text": "um, essentially a network of, uh, connections.",
    "start": "248485",
    "end": "251860"
  },
  {
    "text": "And if we want to model these domains,",
    "start": "251860",
    "end": "253735"
  },
  {
    "text": "really present them as networks.",
    "start": "253735",
    "end": "256180"
  },
  {
    "start": "256000",
    "end": "444000"
  },
  {
    "text": "A second example of domains that also have relational structure,",
    "start": "256180",
    "end": "261113"
  },
  {
    "text": "um, where- and we can use graphs to represent that relational structure.",
    "start": "261114",
    "end": "266010"
  },
  {
    "text": "So for example, information and knowledge is many times organized and linked.",
    "start": "266010",
    "end": "270895"
  },
  {
    "text": "Software can be represented as a graph.",
    "start": "270895",
    "end": "273585"
  },
  {
    "text": "We can many times take, uh,",
    "start": "273585",
    "end": "275444"
  },
  {
    "text": "datapoints and connect similar data points.",
    "start": "275445",
    "end": "278580"
  },
  {
    "text": "And this will create our graph,",
    "start": "278580",
    "end": "280199"
  },
  {
    "text": "uh, a similarity network.",
    "start": "280200",
    "end": "281910"
  },
  {
    "text": "And we can take other, um, uh,",
    "start": "281910",
    "end": "284100"
  },
  {
    "text": "domains that have natural relational structure like molecules,",
    "start": "284100",
    "end": "288065"
  },
  {
    "text": "scene graphs, 3D shapes, as well as,",
    "start": "288065",
    "end": "291185"
  },
  {
    "text": "you know, in physics,",
    "start": "291185",
    "end": "292475"
  },
  {
    "text": "we can take particle-based simulation to simulate how,",
    "start": "292475",
    "end": "296065"
  },
  {
    "text": "uh, particles are related to each other through,",
    "start": "296065",
    "end": "298910"
  },
  {
    "text": "uh, and they represent this with the graph.",
    "start": "298910",
    "end": "301355"
  },
  {
    "text": "So this means that there are many different domains, either, uh,",
    "start": "301355",
    "end": "305480"
  },
  {
    "text": "as natural graphs or natural networks,",
    "start": "305480",
    "end": "308600"
  },
  {
    "text": "as well as other domains that can naturally be",
    "start": "308600",
    "end": "311720"
  },
  {
    "text": "modeled as graphs to capture the relational structure.",
    "start": "311720",
    "end": "316375"
  },
  {
    "text": "And the main question for this class that we are",
    "start": "316375",
    "end": "319460"
  },
  {
    "text": "going to address is to talk about how do we take",
    "start": "319460",
    "end": "322069"
  },
  {
    "text": "advantage of this relational structure to be- to make better, more accurate predictions.",
    "start": "322070",
    "end": "328075"
  },
  {
    "text": "And this is especially important because",
    "start": "328075",
    "end": "330950"
  },
  {
    "text": "couplings domains have reached a relational structure,",
    "start": "330950",
    "end": "334130"
  },
  {
    "text": "uh, which can be presented, uh, with a graph.",
    "start": "334130",
    "end": "336980"
  },
  {
    "text": "And by explicitly modeling these relationships,",
    "start": "336980",
    "end": "340130"
  },
  {
    "text": "we will be able to achieve, uh,",
    "start": "340130",
    "end": "341930"
  },
  {
    "text": "better performance, build more, uh,",
    "start": "341930",
    "end": "344449"
  },
  {
    "text": "accurate, uh, models, make more accurate predictions.",
    "start": "344450",
    "end": "348535"
  },
  {
    "text": "And this is especially interesting and important in the age of deep learning,",
    "start": "348535",
    "end": "353920"
  },
  {
    "text": "where the- today's deep learning modern toolbox is specialized for simple data types.",
    "start": "353920",
    "end": "360280"
  },
  {
    "text": "It is specialized for simple sequences, uh, and grids.",
    "start": "360280",
    "end": "363880"
  },
  {
    "text": "A sequence is a, uh,",
    "start": "363880",
    "end": "366205"
  },
  {
    "text": "like text or speech has this linear structure and there",
    "start": "366205",
    "end": "370830"
  },
  {
    "text": "has- there are been amazing tools developed to analyze this type of structure.",
    "start": "370830",
    "end": "375474"
  },
  {
    "text": "Images can all be resized and have this spatial locality so- so",
    "start": "375475",
    "end": "380170"
  },
  {
    "text": "they can be represented as fixed size grids or fixed size standards.",
    "start": "380170",
    "end": "384804"
  },
  {
    "text": "And again, deep learning methodology has been very good at processing this type of,",
    "start": "384804",
    "end": "389090"
  },
  {
    "text": "uh, fixed size images.",
    "start": "389090",
    "end": "390915"
  },
  {
    "text": "However, um, graphs, networks are much harder to process because they are more complex.",
    "start": "390915",
    "end": "398075"
  },
  {
    "text": "First, they have arbitrary size and arb- and complex topology.",
    "start": "398075",
    "end": "402665"
  },
  {
    "text": "Um, and there is also no spatial locality as in grids or as in text.",
    "start": "402665",
    "end": "407990"
  },
  {
    "text": "In text we know left and right,",
    "start": "407990",
    "end": "410360"
  },
  {
    "text": "in grids we have up and down, uh, left and right.",
    "start": "410360",
    "end": "413599"
  },
  {
    "text": "But in networks, there is no reference point,",
    "start": "413600",
    "end": "416165"
  },
  {
    "text": "there is no notion of,",
    "start": "416165",
    "end": "417815"
  },
  {
    "text": "uh, uh, spatial locality.",
    "start": "417815",
    "end": "420355"
  },
  {
    "text": "The second important thing is there is no reference point,",
    "start": "420355",
    "end": "423240"
  },
  {
    "text": "there is no fixed node ordering that would allow us,",
    "start": "423240",
    "end": "427710"
  },
  {
    "text": "uh, uh, to do, uh,",
    "start": "427710",
    "end": "429074"
  },
  {
    "text": "to do deep learning.",
    "start": "429075",
    "end": "430500"
  },
  {
    "text": "And often, these networks are dynamic and have multi-model features.",
    "start": "430500",
    "end": "435290"
  },
  {
    "text": "So in this course,",
    "start": "435290",
    "end": "437105"
  },
  {
    "text": "we are really going to, uh,",
    "start": "437105",
    "end": "439070"
  },
  {
    "text": "talk about how do we develop neural networks that are much more broadly applicable?",
    "start": "439070",
    "end": "444200"
  },
  {
    "start": "444000",
    "end": "606000"
  },
  {
    "text": "How do we develop neural networks that are applicable to complex data types like graphs?",
    "start": "444200",
    "end": "449855"
  },
  {
    "text": "And really, it is relational data graphs that are the- the new frontier,",
    "start": "449855",
    "end": "454685"
  },
  {
    "text": "uh, of deep learning and representation learning, uh, research.",
    "start": "454685",
    "end": "459085"
  },
  {
    "text": "So intuitively, what we would like to do is we would like to do,",
    "start": "459085",
    "end": "463475"
  },
  {
    "text": "uh, build neural networks,",
    "start": "463475",
    "end": "465515"
  },
  {
    "text": "but on the input we'll take, uh, uh,",
    "start": "465515",
    "end": "468155"
  },
  {
    "text": "our graph and on the output,",
    "start": "468155",
    "end": "470075"
  },
  {
    "text": "they will be able to make predictions.",
    "start": "470075",
    "end": "471920"
  },
  {
    "text": "And, uh, these predictions can be at the level of individual nodes,",
    "start": "471920",
    "end": "475310"
  },
  {
    "text": "can be at the level of pairs of nodes or links,",
    "start": "475310",
    "end": "478220"
  },
  {
    "text": "or it can be something much more complex like a brand new generated graph or, uh,",
    "start": "478220",
    "end": "483860"
  },
  {
    "text": "prediction of a property of a given molecule that can be represented,",
    "start": "483860",
    "end": "488455"
  },
  {
    "text": "um, as a graph on the input.",
    "start": "488455",
    "end": "490504"
  },
  {
    "text": "And the question is,",
    "start": "490505",
    "end": "492125"
  },
  {
    "text": "how do we design this neural network architecture",
    "start": "492125",
    "end": "494690"
  },
  {
    "text": "that will allow us to do this end to end,",
    "start": "494690",
    "end": "497270"
  },
  {
    "text": "meaning there will be no human feature engineering, uh, needed?",
    "start": "497270",
    "end": "501650"
  },
  {
    "text": "So what I mean by that is that, um,",
    "start": "501650",
    "end": "504215"
  },
  {
    "text": "in traditional, uh, machine learning approaches,",
    "start": "504215",
    "end": "506884"
  },
  {
    "text": "a lot of effort goes into des- designing proper features,",
    "start": "506884",
    "end": "511595"
  },
  {
    "text": "proper ways to capture the structure of the data so that machine learning models can,",
    "start": "511595",
    "end": "516680"
  },
  {
    "text": "uh, take advantage of it.",
    "start": "516680",
    "end": "518520"
  },
  {
    "text": "So what we would like to do in this class,",
    "start": "518520",
    "end": "521120"
  },
  {
    "text": "we will talk mostly about representation learning",
    "start": "521120",
    "end": "524210"
  },
  {
    "text": "where these feature engineering step is taken away.",
    "start": "524210",
    "end": "527615"
  },
  {
    "text": "And basically, as soon as we have our graph,",
    "start": "527615",
    "end": "530165"
  },
  {
    "text": "uh, uh, repr- graph data,",
    "start": "530165",
    "end": "531904"
  },
  {
    "text": "we can automatically learn a good representation of the graph so that it can be used for,",
    "start": "531905",
    "end": "538010"
  },
  {
    "text": "um, downstream machine learning algorithm.",
    "start": "538010",
    "end": "540740"
  },
  {
    "text": "So that a presentation learning is about automatically extracting or learning features,",
    "start": "540740",
    "end": "545899"
  },
  {
    "text": "uh, in the graph.",
    "start": "545900",
    "end": "547435"
  },
  {
    "text": "The way we can think of representation learning is to map",
    "start": "547435",
    "end": "551120"
  },
  {
    "text": "nodes of our graph to a d-dimensional embedding,",
    "start": "551120",
    "end": "554765"
  },
  {
    "text": "to the d-dimensional vectors,",
    "start": "554765",
    "end": "556820"
  },
  {
    "text": "such that seeming that are nodes in the network are",
    "start": "556820",
    "end": "559280"
  },
  {
    "text": "embedded close together in the embedding space.",
    "start": "559280",
    "end": "562115"
  },
  {
    "text": "So the goal is to learn this function f that will take",
    "start": "562115",
    "end": "565100"
  },
  {
    "text": "the nodes and map them into these d-dimensional,",
    "start": "565100",
    "end": "568160"
  },
  {
    "text": "um, real valued vectors,",
    "start": "568160",
    "end": "570199"
  },
  {
    "text": "where this vector will call this, uh, representation, uh,",
    "start": "570200",
    "end": "574280"
  },
  {
    "text": "or a feature representation or an embedding of a given node,",
    "start": "574280",
    "end": "578165"
  },
  {
    "text": "an embedding of an entire graph,",
    "start": "578165",
    "end": "580310"
  },
  {
    "text": "an embedding of a given link,",
    "start": "580310",
    "end": "582110"
  },
  {
    "text": "um, and so on.",
    "start": "582110",
    "end": "583565"
  },
  {
    "text": "So a big part of our class we'll be, uh,",
    "start": "583565",
    "end": "586775"
  },
  {
    "text": "investigating and learning about latest presentation learning,",
    "start": "586775",
    "end": "591005"
  },
  {
    "text": "deep learning approaches that can be applied,",
    "start": "591005",
    "end": "593750"
  },
  {
    "text": "uh, to graph, uh, structured data.",
    "start": "593750",
    "end": "596765"
  },
  {
    "text": "And we are going to, uh, uh,",
    "start": "596765",
    "end": "599940"
  },
  {
    "text": "talk about many different topics in",
    "start": "599940",
    "end": "602600"
  },
  {
    "text": "machine learning and the representation learning for graph structure data.",
    "start": "602600",
    "end": "606230"
  },
  {
    "start": "606000",
    "end": "684000"
  },
  {
    "text": "So first, we're going to talk about traditional methods",
    "start": "606230",
    "end": "609725"
  },
  {
    "text": "for machine learning and graphs like graphlets and graph kernels.",
    "start": "609725",
    "end": "613565"
  },
  {
    "text": "We are then going to talk about methods to generate, um,",
    "start": "613565",
    "end": "617480"
  },
  {
    "text": "generic node embeddings, methods like DeepWalk and Node2Vec.",
    "start": "617480",
    "end": "622130"
  },
  {
    "text": "We are going to spend quite a bit of time talking about",
    "start": "622130",
    "end": "625010"
  },
  {
    "text": "graph neural networks and popular graph neural network architectures like graph,",
    "start": "625010",
    "end": "630010"
  },
  {
    "text": "uh, convolutional neural network,",
    "start": "630010",
    "end": "631940"
  },
  {
    "text": "the GraphSage architecture or Graph Attention Network, uh, architecture.",
    "start": "631940",
    "end": "636720"
  },
  {
    "text": "We are also going to study the expressive power of graph neural networks,",
    "start": "636720",
    "end": "641449"
  },
  {
    "text": "um, the theory behind them,",
    "start": "641450",
    "end": "644045"
  },
  {
    "text": "and how do we scale them up to very large graphs.",
    "start": "644045",
    "end": "647704"
  },
  {
    "text": "Um, and then in the second part of this course,",
    "start": "647705",
    "end": "650465"
  },
  {
    "text": "we are also going to talk about heterogeneous graphs,",
    "start": "650465",
    "end": "653585"
  },
  {
    "text": "knowledge graphs, and applications,",
    "start": "653585",
    "end": "655940"
  },
  {
    "text": "uh, to logical reasoning.",
    "start": "655940",
    "end": "657395"
  },
  {
    "text": "We're learning about methods like TransE and BetaE.",
    "start": "657395",
    "end": "660790"
  },
  {
    "text": "We are also going to talk about how do we build deep generative models for",
    "start": "660790",
    "end": "665690"
  },
  {
    "text": "graphs where we can think of the prediction of the model to",
    "start": "665690",
    "end": "668270"
  },
  {
    "text": "be an entire newly generated graph.",
    "start": "668270",
    "end": "671060"
  },
  {
    "text": "And we are also going to discuss applications to biomedicine, um,",
    "start": "671060",
    "end": "675890"
  },
  {
    "text": "various scientific applications, as well",
    "start": "675890",
    "end": "678890"
  },
  {
    "text": "as applications to industry in terms of recommender systems,",
    "start": "678890",
    "end": "682220"
  },
  {
    "text": "fraud detection, and so on.",
    "start": "682220",
    "end": "684769"
  },
  {
    "start": "684000",
    "end": "715000"
  },
  {
    "text": "So here is the outline of this course.",
    "start": "684770",
    "end": "687695"
  },
  {
    "text": "Week by week, 10 weeks, starting, uh,",
    "start": "687695",
    "end": "690860"
  },
  {
    "text": "starting today and all the way to the middle of March,",
    "start": "690860",
    "end": "695029"
  },
  {
    "text": "um, where, uh, the- the course will finish.",
    "start": "695030",
    "end": "697805"
  },
  {
    "text": "We will have 20 lectures and we will cover all the topics,",
    "start": "697805",
    "end": "701795"
  },
  {
    "text": "uh, that I have discussed,",
    "start": "701795",
    "end": "703190"
  },
  {
    "text": "and in particular focus on",
    "start": "703190",
    "end": "704990"
  },
  {
    "text": "graph neural networks and the representation learning in graphs.",
    "start": "704990",
    "end": "709649"
  }
]
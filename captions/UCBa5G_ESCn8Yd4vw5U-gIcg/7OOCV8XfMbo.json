[
  {
    "start": "0",
    "end": "4290"
  },
  {
    "text": "CHRISTOPHER POTTS:\nWelcome back, everyone.",
    "start": "4290",
    "end": "6040"
  },
  {
    "text": "This is part 2 in our series\non in-context learning.",
    "start": "6040",
    "end": "8950"
  },
  {
    "text": "I thought I'd cover some core\nconcepts for the most part.",
    "start": "8950",
    "end": "11830"
  },
  {
    "text": "I think these concepts\nare a review for you all.",
    "start": "11830",
    "end": "14490"
  },
  {
    "text": "But I thought it would\nbe good to get them",
    "start": "14490",
    "end": "16500"
  },
  {
    "text": "into our common ground to help\nus think about them as we think",
    "start": "16500",
    "end": "20310"
  },
  {
    "text": "about what's happening with\nin-context learning techniques.",
    "start": "20310",
    "end": "23730"
  },
  {
    "text": "To start, let's just\nestablish some terminology.",
    "start": "23730",
    "end": "26573"
  },
  {
    "text": "I think there's a\nlot of variation",
    "start": "26573",
    "end": "27990"
  },
  {
    "text": "in how these terms are\nused in the literature.",
    "start": "27990",
    "end": "30029"
  },
  {
    "text": "And I thought I\nwould just try to be",
    "start": "30030",
    "end": "31530"
  },
  {
    "text": "clear about what I mean with\nthese various crucial phrases.",
    "start": "31530",
    "end": "35220"
  },
  {
    "text": "Let's start with\nin-context learning.",
    "start": "35220",
    "end": "37050"
  },
  {
    "text": "When I say in-context learning,\nI mean, a frozen language model",
    "start": "37050",
    "end": "41190"
  },
  {
    "text": "performs a task\nonly by conditioning",
    "start": "41190",
    "end": "44250"
  },
  {
    "text": "on the prompt text.",
    "start": "44250",
    "end": "45570"
  },
  {
    "text": "It's frozen, that is, there\nare no gradient updates.",
    "start": "45570",
    "end": "48030"
  },
  {
    "text": "The only mechanism\nwe have for learning",
    "start": "48030",
    "end": "50340"
  },
  {
    "text": "is that we input\nsome text and that",
    "start": "50340",
    "end": "52560"
  },
  {
    "text": "puts the model in a\ntemporary state that we hope",
    "start": "52560",
    "end": "55470"
  },
  {
    "text": "is useful for having it\ngenerate things that we",
    "start": "55470",
    "end": "57900"
  },
  {
    "text": "regard as useful for our task.",
    "start": "57900",
    "end": "61650"
  },
  {
    "text": "Few shot in-context learning\nis a special case of that.",
    "start": "61650",
    "end": "65018"
  },
  {
    "text": "This is where the\nprompt includes examples",
    "start": "65019",
    "end": "67750"
  },
  {
    "text": "of the intended behavior.",
    "start": "67750",
    "end": "69460"
  },
  {
    "text": "And no examples of the intended\nbehavior were seen in training.",
    "start": "69460",
    "end": "74470"
  },
  {
    "text": "Of course, we are unlikely\nto be able to verify too.",
    "start": "74470",
    "end": "78460"
  },
  {
    "text": "In this modern era\nwhere models are trained",
    "start": "78460",
    "end": "80290"
  },
  {
    "text": "on massive amounts\nof text, we'll",
    "start": "80290",
    "end": "82420"
  },
  {
    "text": "have no idea typically what\nwas in those training datasets.",
    "start": "82420",
    "end": "85900"
  },
  {
    "text": "Often, we have no\nability to audit them.",
    "start": "85900",
    "end": "88190"
  },
  {
    "text": "And so we might not be sure\nwhether we're actually doing",
    "start": "88190",
    "end": "90790"
  },
  {
    "text": "few-shot in-context learning.",
    "start": "90790",
    "end": "92840"
  },
  {
    "text": "But this is the ideal.",
    "start": "92840",
    "end": "94840"
  },
  {
    "text": "And the spirit of\nthis is that if models",
    "start": "94840",
    "end": "97600"
  },
  {
    "text": "have seen examples of\nthis type in training,",
    "start": "97600",
    "end": "99610"
  },
  {
    "text": "it's hardly few-shot any more.",
    "start": "99610",
    "end": "101080"
  },
  {
    "text": "The whole point is to\nsee whether with just",
    "start": "101080",
    "end": "103570"
  },
  {
    "text": "a few instances, models can\ndo what we want them to do.",
    "start": "103570",
    "end": "108410"
  },
  {
    "text": "I'll also acknowledge\nthat the term few-shot",
    "start": "108410",
    "end": "110660"
  },
  {
    "text": "is used in more traditional\nsupervised learning",
    "start": "110660",
    "end": "113990"
  },
  {
    "text": "settings in the\nsense of training",
    "start": "113990",
    "end": "116360"
  },
  {
    "text": "on a few examples\nwith gradient updates.",
    "start": "116360",
    "end": "118820"
  },
  {
    "text": "And so I'm just\nemphasizing that when",
    "start": "118820",
    "end": "120650"
  },
  {
    "text": "I say few-shot in\nthis lecture series,",
    "start": "120650",
    "end": "123290"
  },
  {
    "text": "I'm always going to mean\nfew-shot in-context learning",
    "start": "123290",
    "end": "126470"
  },
  {
    "text": "with no gradient updates.",
    "start": "126470",
    "end": "129410"
  },
  {
    "text": "Zero-shot in-context learning\nis another special case.",
    "start": "129410",
    "end": "132440"
  },
  {
    "text": "This is where the prompt\nincludes no examples",
    "start": "132440",
    "end": "134690"
  },
  {
    "text": "of the intended behavior.",
    "start": "134690",
    "end": "136280"
  },
  {
    "text": "But I'll allow that it could\ncontain some instructions.",
    "start": "136280",
    "end": "140000"
  },
  {
    "text": "And as before,\nitem 2, no examples",
    "start": "140000",
    "end": "143090"
  },
  {
    "text": "of the intended behavior\nwe're seeing in training.",
    "start": "143090",
    "end": "145250"
  },
  {
    "text": "Again, we're unlikely\nto be able to verify 2.",
    "start": "145250",
    "end": "148400"
  },
  {
    "text": "So we won't know whether\nthis is truly zero-shot,",
    "start": "148400",
    "end": "151640"
  },
  {
    "text": "but the concept is clear.",
    "start": "151640",
    "end": "154600"
  },
  {
    "text": "For item 1, this is\nmore interesting.",
    "start": "154600",
    "end": "156430"
  },
  {
    "text": "I'll say that formatting\nand other instructions",
    "start": "156430",
    "end": "159189"
  },
  {
    "text": "that you include in the prompt\nare a kind of gray area.",
    "start": "159190",
    "end": "161890"
  },
  {
    "text": "But let's allow them in\nthe zero-shot category.",
    "start": "161890",
    "end": "164347"
  },
  {
    "text": "What I mean by that is\nthat as you give more",
    "start": "164347",
    "end": "166180"
  },
  {
    "text": "elaborate instructions,\nyou might, in effect,",
    "start": "166180",
    "end": "168310"
  },
  {
    "text": "be demonstrating the\nintended behavior.",
    "start": "168310",
    "end": "171069"
  },
  {
    "text": "But the other side of\nthis is that instructions",
    "start": "171070",
    "end": "173500"
  },
  {
    "text": "are conceptually\nvery different kinds",
    "start": "173500",
    "end": "175810"
  },
  {
    "text": "of things for machine\nlearning in general",
    "start": "175810",
    "end": "179110"
  },
  {
    "text": "than actual demonstrations.",
    "start": "179110",
    "end": "180880"
  },
  {
    "text": "And so it's interesting\nto separate out",
    "start": "180880",
    "end": "183010"
  },
  {
    "text": "the case where you demonstrate\ndirectly from the case",
    "start": "183010",
    "end": "185590"
  },
  {
    "text": "where you just describe\nthe intended behavior.",
    "start": "185590",
    "end": "188769"
  },
  {
    "text": "And so we'll allow\nmere descriptions",
    "start": "188770",
    "end": "191230"
  },
  {
    "text": "to still be zero-shot.",
    "start": "191230",
    "end": "194349"
  },
  {
    "text": "Another reminder is just how\nGPT and other models work.",
    "start": "194350",
    "end": "199870"
  },
  {
    "text": "We covered this in the unit\non contextual representation.",
    "start": "199870",
    "end": "204370"
  },
  {
    "text": "And I thought I'd just remind\nus so that this is front of mind",
    "start": "204370",
    "end": "207340"
  },
  {
    "text": "as we think about the\nin-context learning techniques.",
    "start": "207340",
    "end": "210660"
  },
  {
    "text": "Here's a slide repeating the\nautoregressive loss function",
    "start": "210660",
    "end": "213690"
  },
  {
    "text": "that these models use.",
    "start": "213690",
    "end": "214680"
  },
  {
    "text": "And again, the\nessence of this is",
    "start": "214680",
    "end": "216750"
  },
  {
    "text": "that scoring\nhappens on the basis",
    "start": "216750",
    "end": "218730"
  },
  {
    "text": "of the embedding\nrepresentation for the token",
    "start": "218730",
    "end": "221519"
  },
  {
    "text": "that we want to predict at time\nstep t, and the hidden state",
    "start": "221520",
    "end": "225630"
  },
  {
    "text": "that the model has created up\nuntil the time step proceeding",
    "start": "225630",
    "end": "229570"
  },
  {
    "text": "t.",
    "start": "229570",
    "end": "230070"
  },
  {
    "text": "Those are the two\ncrucial ingredients.",
    "start": "230070",
    "end": "233550"
  },
  {
    "text": "And here's how that plays\nout for GPT style models",
    "start": "233550",
    "end": "237840"
  },
  {
    "text": "in the context of training.",
    "start": "237840",
    "end": "239910"
  },
  {
    "text": "And I'll show you first\ntraining with teacher forcing.",
    "start": "239910",
    "end": "242730"
  },
  {
    "text": "This slide is a\nrepeat from one we",
    "start": "242730",
    "end": "244409"
  },
  {
    "text": "had in the contextual\nrepresentations unit.",
    "start": "244410",
    "end": "246970"
  },
  {
    "text": "But again, I want to\nissue a reminder here.",
    "start": "246970",
    "end": "250020"
  },
  {
    "text": "At the bottom, we\nhave one hot vectors",
    "start": "250020",
    "end": "253620"
  },
  {
    "text": "representing the sequence\nof tokens in the sequence",
    "start": "253620",
    "end": "257040"
  },
  {
    "text": "that we are using for training.",
    "start": "257040",
    "end": "258600"
  },
  {
    "text": "Normally, we represent these\nas actual sequences of tokens,",
    "start": "258600",
    "end": "261778"
  },
  {
    "text": "but I'm trying to remind us\nat a mechanical level of how",
    "start": "261779",
    "end": "265020"
  },
  {
    "text": "these things actually operate.",
    "start": "265020",
    "end": "266460"
  },
  {
    "text": "So these are one-hot vectors.",
    "start": "266460",
    "end": "267990"
  },
  {
    "text": "And those are used to look up\nvectors in our embedding layer.",
    "start": "267990",
    "end": "272530"
  },
  {
    "text": "That's given in gray here.",
    "start": "272530",
    "end": "273880"
  },
  {
    "text": "And the result of that\nlookup is a vector.",
    "start": "273880",
    "end": "276730"
  },
  {
    "text": "And at this stage, I have\ngiven the names of the vectors",
    "start": "276730",
    "end": "279610"
  },
  {
    "text": "according to our vocabulary.",
    "start": "279610",
    "end": "281539"
  },
  {
    "text": "But again, what we really have\nhere is a sequence of vectors.",
    "start": "281540",
    "end": "286210"
  },
  {
    "text": "Those vectors are the input\nto the big transformer",
    "start": "286210",
    "end": "290199"
  },
  {
    "text": "model that we're using\nfor language modeling.",
    "start": "290200",
    "end": "292420"
  },
  {
    "text": "I've shown a kind of\nschematic of this.",
    "start": "292420",
    "end": "294513"
  },
  {
    "text": "And the one thing\nI've highlighted",
    "start": "294513",
    "end": "295930"
  },
  {
    "text": "is the pattern of\nattention mechanisms.",
    "start": "295930",
    "end": "298449"
  },
  {
    "text": "Recall that when we're doing\nautoregressive modeling,",
    "start": "298450",
    "end": "301240"
  },
  {
    "text": "we can't look into\nthe future with those",
    "start": "301240",
    "end": "303639"
  },
  {
    "text": "dot product attention\nmechanisms only into the past.",
    "start": "303640",
    "end": "306820"
  },
  {
    "text": "And so you see that\ncharacteristic pattern",
    "start": "306820",
    "end": "309250"
  },
  {
    "text": "for the attention connections.",
    "start": "309250",
    "end": "311500"
  },
  {
    "text": "So we do all our processing\nwith all of these transformer",
    "start": "311500",
    "end": "313930"
  },
  {
    "text": "blocks.",
    "start": "313930",
    "end": "314440"
  },
  {
    "text": "And then at the very\ntop, we're going",
    "start": "314440",
    "end": "316030"
  },
  {
    "text": "to use our embedding\nlayer again.",
    "start": "316030",
    "end": "319060"
  },
  {
    "text": "The labels, so to\nspeak, are, again,",
    "start": "319060",
    "end": "322120"
  },
  {
    "text": "our sequence offset\nby 1 from the sequence",
    "start": "322120",
    "end": "324910"
  },
  {
    "text": "that we have at the bottom here.",
    "start": "324910",
    "end": "326740"
  },
  {
    "text": "So this was the start token.",
    "start": "326740",
    "end": "329080"
  },
  {
    "text": "We use that to predict The.",
    "start": "329080",
    "end": "331289"
  },
  {
    "text": "Then at the next time step,\nThe comes in down here,",
    "start": "331290",
    "end": "333960"
  },
  {
    "text": "and that is the basis\nfor predicting Rock.",
    "start": "333960",
    "end": "336300"
  },
  {
    "text": "Rock comes in down\nhere, predicts Rules.",
    "start": "336300",
    "end": "339479"
  },
  {
    "text": "Rules down here, and\nthen we finally predict",
    "start": "339480",
    "end": "341820"
  },
  {
    "text": "the end of token sequence.",
    "start": "341820",
    "end": "343080"
  },
  {
    "text": "So we're offset by one.",
    "start": "343080",
    "end": "345210"
  },
  {
    "text": "Using the previous context\nto predict the next token.",
    "start": "345210",
    "end": "349770"
  },
  {
    "text": "And again, I've given\nthese as one-hot vectors,",
    "start": "349770",
    "end": "352080"
  },
  {
    "text": "because those one-hot vectors\nare the actual learning signal.",
    "start": "352080",
    "end": "356439"
  },
  {
    "text": "And those are\ncompared for learning",
    "start": "356440",
    "end": "358560"
  },
  {
    "text": "with the vector of scores that\nthe model produces at each time",
    "start": "358560",
    "end": "361990"
  },
  {
    "text": "step.",
    "start": "361990",
    "end": "362490"
  },
  {
    "text": "Scores over the\nentire vocabulary.",
    "start": "362490",
    "end": "365430"
  },
  {
    "text": "And it's the difference\nbetween the one-hot vector",
    "start": "365430",
    "end": "368400"
  },
  {
    "text": "and the score vector that we\nuse to get gradient updates",
    "start": "368400",
    "end": "371580"
  },
  {
    "text": "to improve the model.",
    "start": "371580",
    "end": "373770"
  },
  {
    "text": "Again, I'm emphasizing\nthis, because we",
    "start": "373770",
    "end": "375629"
  },
  {
    "text": "tend to think that the\nmodel has predicted tokens.",
    "start": "375630",
    "end": "378510"
  },
  {
    "text": "But in fact, predicting\ntokens is something",
    "start": "378510",
    "end": "380640"
  },
  {
    "text": "that we make them do\nwhat they actually do.",
    "start": "380640",
    "end": "383100"
  },
  {
    "text": "Is predict score vectors.",
    "start": "383100",
    "end": "385800"
  },
  {
    "text": "So what's depicted on the\nslide here is teacher forcing.",
    "start": "385800",
    "end": "389389"
  },
  {
    "text": "There's an\ninteresting thing that",
    "start": "389390",
    "end": "390800"
  },
  {
    "text": "happened at this time step,\nwhere the score vector actually",
    "start": "390800",
    "end": "394129"
  },
  {
    "text": "put the highest score on\nthe final element here,",
    "start": "394130",
    "end": "396840"
  },
  {
    "text": "which is different\nfrom the one-hot vector",
    "start": "396840",
    "end": "399830"
  },
  {
    "text": "that we wanted to predict.",
    "start": "399830",
    "end": "401509"
  },
  {
    "text": "In teacher forcing, I still\nuse this one-hot vector",
    "start": "401510",
    "end": "404810"
  },
  {
    "text": "down at the next time step\nto continue my predictions.",
    "start": "404810",
    "end": "408260"
  },
  {
    "text": "There are versions of\ntraining where I would instead",
    "start": "408260",
    "end": "411560"
  },
  {
    "text": "use the one-hot vector that had\na 1 here at the next time step.",
    "start": "411560",
    "end": "415340"
  },
  {
    "text": "And that can be useful for\nintroducing some diversity",
    "start": "415340",
    "end": "418280"
  },
  {
    "text": "into the mix.",
    "start": "418280",
    "end": "419330"
  },
  {
    "text": "And that is also a\nreminder that these models",
    "start": "419330",
    "end": "422330"
  },
  {
    "text": "don't predict tokens.",
    "start": "422330",
    "end": "423379"
  },
  {
    "text": "They predict score vectors.",
    "start": "423380",
    "end": "424640"
  },
  {
    "text": "And in principle,\neven in training,",
    "start": "424640",
    "end": "427280"
  },
  {
    "text": "we could use their\npredicted score vectors",
    "start": "427280",
    "end": "429710"
  },
  {
    "text": "in lots of different ways.",
    "start": "429710",
    "end": "431810"
  },
  {
    "text": "We could do some beam search\nand use the entire prediction",
    "start": "431810",
    "end": "434960"
  },
  {
    "text": "that they make over beam\nsearch to do training",
    "start": "434960",
    "end": "437270"
  },
  {
    "text": "for future time steps.",
    "start": "437270",
    "end": "438680"
  },
  {
    "text": "We could pick the lowest scoring\nitem if we wanted, right?",
    "start": "438680",
    "end": "441530"
  },
  {
    "text": "This is all up to us,\nbecause fundamentally, what",
    "start": "441530",
    "end": "444620"
  },
  {
    "text": "these models do is\npredict score vectors.",
    "start": "444620",
    "end": "448610"
  },
  {
    "text": "That was for training.",
    "start": "448610",
    "end": "450169"
  },
  {
    "text": "Our actual focus is on frozen\nlanguage models for this unit.",
    "start": "450170",
    "end": "453540"
  },
  {
    "text": "And so we're really going to\nbe thinking about generation.",
    "start": "453540",
    "end": "456600"
  },
  {
    "text": "So let's think about\nhow that happens.",
    "start": "456600",
    "end": "458970"
  },
  {
    "text": "Let's imagine that the\nmodel has been prompted",
    "start": "458970",
    "end": "461150"
  },
  {
    "text": "with the beginning of\nsequence token in The",
    "start": "461150",
    "end": "464360"
  },
  {
    "text": "and it has produced\nthe token Rock.",
    "start": "464360",
    "end": "467090"
  },
  {
    "text": "We use Rock-- the\none-hot vector there",
    "start": "467090",
    "end": "469490"
  },
  {
    "text": "as the input to\nthe next time step.",
    "start": "469490",
    "end": "471680"
  },
  {
    "text": "We process that and\nmake another prediction.",
    "start": "471680",
    "end": "475100"
  },
  {
    "text": "In this case, we could think\nof the prediction as rows.",
    "start": "475100",
    "end": "478640"
  },
  {
    "text": "Rows comes in as a one-hot\nvector at the next time step.",
    "start": "478640",
    "end": "481860"
  },
  {
    "text": "And we continue our predictions.",
    "start": "481860",
    "end": "484560"
  },
  {
    "text": "That's the generation process.",
    "start": "484560",
    "end": "486260"
  },
  {
    "text": "Again, I want to emphasize\nthat at each time step,",
    "start": "486260",
    "end": "489620"
  },
  {
    "text": "the model is predicting score\nvectors over the vocabulary.",
    "start": "489620",
    "end": "494270"
  },
  {
    "text": "And we are using our own rule\nto decide what token that",
    "start": "494270",
    "end": "498680"
  },
  {
    "text": "actually corresponds to.",
    "start": "498680",
    "end": "499880"
  },
  {
    "text": "What I've depicted\nhere is something",
    "start": "499880",
    "end": "501410"
  },
  {
    "text": "that you might call\ngreedy decoding,",
    "start": "501410",
    "end": "503480"
  },
  {
    "text": "where the highest scoring\ntoken at each time step",
    "start": "503480",
    "end": "507020"
  },
  {
    "text": "is used at the next time step.",
    "start": "507020",
    "end": "509830"
  },
  {
    "text": "But again, that just\nreveals that there",
    "start": "509830",
    "end": "512279"
  },
  {
    "text": "are lots of decision rules\nthat I could use at this point",
    "start": "512280",
    "end": "515460"
  },
  {
    "text": "to guide generation.",
    "start": "515460",
    "end": "517469"
  },
  {
    "text": "I mentioned beam search before.",
    "start": "517470",
    "end": "519058"
  },
  {
    "text": "That would be where\nwe do a rollout",
    "start": "519059",
    "end": "520919"
  },
  {
    "text": "and look at all the\nscore distributions",
    "start": "520919",
    "end": "522840"
  },
  {
    "text": "that we got for a few\ntime steps and pick",
    "start": "522840",
    "end": "525270"
  },
  {
    "text": "one that seems to\nbe the best scoring",
    "start": "525270",
    "end": "527100"
  },
  {
    "text": "across that whole\nsequence, which could yield",
    "start": "527100",
    "end": "529290"
  },
  {
    "text": "very different behaviors\nfrom the behavior",
    "start": "529290",
    "end": "531870"
  },
  {
    "text": "that we get from\ngreedy decoding.",
    "start": "531870",
    "end": "534180"
  },
  {
    "text": "And if you look at the APIs\nfor our really large language",
    "start": "534180",
    "end": "537690"
  },
  {
    "text": "models now, you'll\nsee that they have",
    "start": "537690",
    "end": "539520"
  },
  {
    "text": "a lot of different parameters\nthat are essentially",
    "start": "539520",
    "end": "542430"
  },
  {
    "text": "shaping how generation\nactually happens.",
    "start": "542430",
    "end": "545010"
  },
  {
    "text": "And that is, again, a reminder\nthat generation is not really",
    "start": "545010",
    "end": "548910"
  },
  {
    "text": "intrinsic to these models.",
    "start": "548910",
    "end": "550529"
  },
  {
    "text": "What's intrinsic to them\nis predicting score vectors",
    "start": "550530",
    "end": "553320"
  },
  {
    "text": "over the vocabulary.",
    "start": "553320",
    "end": "554850"
  },
  {
    "text": "And the generation\npart is something",
    "start": "554850",
    "end": "557100"
  },
  {
    "text": "that we make them do via a\nrule that we decide separately",
    "start": "557100",
    "end": "561300"
  },
  {
    "text": "from their internal structure.",
    "start": "561300",
    "end": "564589"
  },
  {
    "text": "So that cues up a\nkind of nice question",
    "start": "564590",
    "end": "566620"
  },
  {
    "text": "that you could debate with your\nfellow researchers and friends",
    "start": "566620",
    "end": "569890"
  },
  {
    "text": "and loved ones and\npeople out in the world.",
    "start": "569890",
    "end": "572200"
  },
  {
    "text": "Do autoregressive\nlanguage models",
    "start": "572200",
    "end": "574450"
  },
  {
    "text": "simply predict the next token?",
    "start": "574450",
    "end": "576850"
  },
  {
    "text": "Well, your first\nanswer might be yes.",
    "start": "576850",
    "end": "578740"
  },
  {
    "text": "That's all they do.",
    "start": "578740",
    "end": "579640"
  },
  {
    "text": "And that is a reasonable answer.",
    "start": "579640",
    "end": "581870"
  },
  {
    "text": "However, we just\nsaw that it's more",
    "start": "581870",
    "end": "585400"
  },
  {
    "text": "precise to say that\nthey predict scores",
    "start": "585400",
    "end": "587710"
  },
  {
    "text": "over the entire vocabulary\nat each time step.",
    "start": "587710",
    "end": "590540"
  },
  {
    "text": "And then we use those\nscores to compel them",
    "start": "590540",
    "end": "593829"
  },
  {
    "text": "to predict some token or other.",
    "start": "593830",
    "end": "595370"
  },
  {
    "text": "We compel them to speak\nin a particular way.",
    "start": "595370",
    "end": "599300"
  },
  {
    "text": "That feels more correct\nat a technical level.",
    "start": "599300",
    "end": "602380"
  },
  {
    "text": "And you might reflect\nalso that they actually",
    "start": "602380",
    "end": "604750"
  },
  {
    "text": "represent data in their internal\nand output representations.",
    "start": "604750",
    "end": "608860"
  },
  {
    "text": "And very often in NLP,\nit's those representations",
    "start": "608860",
    "end": "612070"
  },
  {
    "text": "that we care about, not any\nparticular generation process.",
    "start": "612070",
    "end": "615580"
  },
  {
    "text": "And that just points to the\nfact that autoregressive LMs",
    "start": "615580",
    "end": "618160"
  },
  {
    "text": "do a lot more than\njust speak so to speak.",
    "start": "618160",
    "end": "622509"
  },
  {
    "text": "But on balance, I would\nsay that saying they",
    "start": "622510",
    "end": "626660"
  },
  {
    "text": "simply predict the\nnext token might",
    "start": "626660",
    "end": "628399"
  },
  {
    "text": "be the best in terms of science\ncommunication with the public.",
    "start": "628400",
    "end": "631550"
  },
  {
    "text": "You can talk in nuanced ways\nwith your fellow researchers",
    "start": "631550",
    "end": "634375"
  },
  {
    "text": "about what they're\nactually doing",
    "start": "634375",
    "end": "635750"
  },
  {
    "text": "and how they represent examples.",
    "start": "635750",
    "end": "637460"
  },
  {
    "text": "But out in the world,\nit might give people",
    "start": "637460",
    "end": "639830"
  },
  {
    "text": "the best mental\nmodel if you simply",
    "start": "639830",
    "end": "641990"
  },
  {
    "text": "say that they predict the\nnext token based on the tokens",
    "start": "641990",
    "end": "645020"
  },
  {
    "text": "that they have already generated\nand the ones that you put in.",
    "start": "645020",
    "end": "647930"
  },
  {
    "text": "It's an appropriately\nmechanistic explanation",
    "start": "647930",
    "end": "650570"
  },
  {
    "text": "that I think might help people\nout in the world calibrate",
    "start": "650570",
    "end": "653600"
  },
  {
    "text": "to what's actually happening.",
    "start": "653600",
    "end": "655430"
  },
  {
    "text": "Because we should\neven remind ourselves,",
    "start": "655430",
    "end": "658100"
  },
  {
    "text": "as we see more\nimpressive behaviors",
    "start": "658100",
    "end": "660139"
  },
  {
    "text": "from these models,\nthat underlyingly,",
    "start": "660140",
    "end": "662540"
  },
  {
    "text": "the mechanism is uniform.",
    "start": "662540",
    "end": "664740"
  },
  {
    "text": "If you prompt the model\nwith \"Better late than__\"",
    "start": "664740",
    "end": "667160"
  },
  {
    "text": "and it says \"never,\"\ntransparently,",
    "start": "667160",
    "end": "669860"
  },
  {
    "text": "we can see that that's just\na kind of high probability",
    "start": "669860",
    "end": "672320"
  },
  {
    "text": "continuation of the\nprompt sequence.",
    "start": "672320",
    "end": "675020"
  },
  {
    "text": "When you have, \"Every day, I\neat breakfast, lunch, and__,\"",
    "start": "675020",
    "end": "678470"
  },
  {
    "text": "it will probably say \"dinner,\"\nand you might immediately",
    "start": "678470",
    "end": "681019"
  },
  {
    "text": "think, uh.",
    "start": "681020",
    "end": "681770"
  },
  {
    "text": "That reflects some world\nknowledge that the model has.",
    "start": "681770",
    "end": "684690"
  },
  {
    "text": "But as far as we know\nall that really is",
    "start": "684690",
    "end": "688000"
  },
  {
    "text": "is a continuation\nof the sequence",
    "start": "688000",
    "end": "690250"
  },
  {
    "text": "with a high probability token.",
    "start": "690250",
    "end": "692380"
  },
  {
    "text": "And it's high\nprobability because",
    "start": "692380",
    "end": "694150"
  },
  {
    "text": "of regularities in the world.",
    "start": "694150",
    "end": "695485"
  },
  {
    "text": "But for the language model, this\nis simply a high probability",
    "start": "695485",
    "end": "699100"
  },
  {
    "text": "continuation.",
    "start": "699100",
    "end": "700540"
  },
  {
    "text": "And again, when\nyou prompt it with,",
    "start": "700540",
    "end": "702310"
  },
  {
    "text": "\"The president of the US is__,\"\nand it gives you the name",
    "start": "702310",
    "end": "705070"
  },
  {
    "text": "of a person as an answer, that\nmight look like it has stored",
    "start": "705070",
    "end": "708730"
  },
  {
    "text": "some knowledge about the world.",
    "start": "708730",
    "end": "710050"
  },
  {
    "text": "And maybe there is a\nsense in which it has.",
    "start": "710050",
    "end": "712490"
  },
  {
    "text": "But as far as we know,\nand mechanistically, that",
    "start": "712490",
    "end": "715180"
  },
  {
    "text": "is simply offering a high\nprobability continuation",
    "start": "715180",
    "end": "718450"
  },
  {
    "text": "of the sequence.",
    "start": "718450",
    "end": "719650"
  },
  {
    "text": "So when you get\nto something like,",
    "start": "719650",
    "end": "721210"
  },
  {
    "text": "\"The key to happiness is__,\"\nand it offers you an answer that",
    "start": "721210",
    "end": "724960"
  },
  {
    "text": "seems insightful,\nyou should, again,",
    "start": "724960",
    "end": "727060"
  },
  {
    "text": "remind yourself that is just a\nhigh probability continuation",
    "start": "727060",
    "end": "730930"
  },
  {
    "text": "of the input sequence based\non all the training experience",
    "start": "730930",
    "end": "734920"
  },
  {
    "text": "that the model has had.",
    "start": "734920",
    "end": "736990"
  },
  {
    "text": "We really have no ability\nto audit what those training",
    "start": "736990",
    "end": "739420"
  },
  {
    "text": "sequences were like.",
    "start": "739420",
    "end": "740769"
  },
  {
    "text": "The mechanism is uniform.",
    "start": "740770",
    "end": "742240"
  },
  {
    "text": "There might be\nsomething interesting",
    "start": "742240",
    "end": "743740"
  },
  {
    "text": "happening in terms of\nrepresentation under the hood",
    "start": "743740",
    "end": "746959"
  },
  {
    "text": "here.",
    "start": "746960",
    "end": "747740"
  },
  {
    "text": "But we should remind\nourselves that really, it's",
    "start": "747740",
    "end": "750050"
  },
  {
    "text": "just high probability\ncontinuations for all",
    "start": "750050",
    "end": "752570"
  },
  {
    "text": "of these cases.",
    "start": "752570",
    "end": "754790"
  },
  {
    "text": "The final core concept\nthat I want to mention here",
    "start": "754790",
    "end": "758079"
  },
  {
    "text": "is that one that we're going\nto return to at various points",
    "start": "758080",
    "end": "760840"
  },
  {
    "text": "throughout this series.",
    "start": "760840",
    "end": "762130"
  },
  {
    "text": "And this notion of\ninstruction fine-tuning.",
    "start": "762130",
    "end": "765920"
  },
  {
    "text": "This is from the blog post\nthat announced ChatGPT.",
    "start": "765920",
    "end": "770829"
  },
  {
    "text": "It's a description of how\nthey do instruct fine-tuning",
    "start": "770830",
    "end": "773620"
  },
  {
    "text": "for that model.",
    "start": "773620",
    "end": "774730"
  },
  {
    "text": "There are three steps here.",
    "start": "774730",
    "end": "776470"
  },
  {
    "text": "And I think the thing to\nhighlight is that in step 1,",
    "start": "776470",
    "end": "779649"
  },
  {
    "text": "we have what looks like fairly\nstandard supervised learning,",
    "start": "779650",
    "end": "784240"
  },
  {
    "text": "where at some level, we\nhave human-curated examples",
    "start": "784240",
    "end": "787600"
  },
  {
    "text": "of prompts with good\noutputs, and the model is",
    "start": "787600",
    "end": "790480"
  },
  {
    "text": "trained on those instances.",
    "start": "790480",
    "end": "793160"
  },
  {
    "text": "And then at step 2, we again\nhave humans coming in now",
    "start": "793160",
    "end": "797709"
  },
  {
    "text": "to look at model outputs\nthat have been generated",
    "start": "797710",
    "end": "800680"
  },
  {
    "text": "and rank them\naccording to quality",
    "start": "800680",
    "end": "802930"
  },
  {
    "text": "conditional on the prompt input.",
    "start": "802930",
    "end": "805120"
  },
  {
    "text": "So that's two stages\nat which people",
    "start": "805120",
    "end": "808330"
  },
  {
    "text": "are playing a crucial role.",
    "start": "808330",
    "end": "810190"
  },
  {
    "text": "We have left behind\nthe very pure version",
    "start": "810190",
    "end": "813280"
  },
  {
    "text": "of the distributional\nhypothesis that says,",
    "start": "813280",
    "end": "816080"
  },
  {
    "text": "just doing language\nmodel training",
    "start": "816080",
    "end": "818690"
  },
  {
    "text": "of the sort I described\nbefore on entirely",
    "start": "818690",
    "end": "821480"
  },
  {
    "text": "unstructured sequence\nsymbols gives us",
    "start": "821480",
    "end": "824149"
  },
  {
    "text": "models that are powerful.",
    "start": "824150",
    "end": "825450"
  },
  {
    "text": "We have now entered\nback into a mode where",
    "start": "825450",
    "end": "828110"
  },
  {
    "text": "a lot of the most\ninteresting behaviors",
    "start": "828110",
    "end": "830120"
  },
  {
    "text": "are certainly happening,\nbecause people are coming in",
    "start": "830120",
    "end": "833570"
  },
  {
    "text": "to offer direct\nsupervision about what's",
    "start": "833570",
    "end": "836570"
  },
  {
    "text": "a good output given an input.",
    "start": "836570",
    "end": "838470"
  },
  {
    "text": "It's not magic when\nthese models seem",
    "start": "838470",
    "end": "840350"
  },
  {
    "text": "to do very sophisticated things.",
    "start": "840350",
    "end": "842180"
  },
  {
    "text": "It is largely because\nthey have been instructed",
    "start": "842180",
    "end": "844880"
  },
  {
    "text": "to do very sophisticated things\nby very sophisticated humans.",
    "start": "844880",
    "end": "848990"
  },
  {
    "text": "That is important in\nterms of understanding",
    "start": "848990",
    "end": "851180"
  },
  {
    "text": "why these models work.",
    "start": "851180",
    "end": "852470"
  },
  {
    "text": "And I think it's also\nimportant for understanding",
    "start": "852470",
    "end": "854990"
  },
  {
    "text": "how various in-context\nlearning techniques behave.",
    "start": "854990",
    "end": "858950"
  },
  {
    "text": "Because increasingly, we're\nseeing a feedback loop",
    "start": "858950",
    "end": "861590"
  },
  {
    "text": "where the kinds of things that\nwe want to do with our prompts",
    "start": "861590",
    "end": "865010"
  },
  {
    "text": "are informing the\nkinds of things",
    "start": "865010",
    "end": "866750"
  },
  {
    "text": "that happen in the\nsupervised learning phase,",
    "start": "866750",
    "end": "869060"
  },
  {
    "text": "making them more powerful.",
    "start": "869060",
    "end": "871130"
  },
  {
    "text": "Again, it's not a\nmysterious discovery",
    "start": "871130",
    "end": "873710"
  },
  {
    "text": "about how large language\nmodels work, but rather,",
    "start": "873710",
    "end": "876320"
  },
  {
    "text": "just a reflection of the\nkinds of instruct fine-tuning",
    "start": "876320",
    "end": "879860"
  },
  {
    "text": "that are very commonly\nhappening now.",
    "start": "879860",
    "end": "883029"
  },
  {
    "start": "883030",
    "end": "887000"
  }
]
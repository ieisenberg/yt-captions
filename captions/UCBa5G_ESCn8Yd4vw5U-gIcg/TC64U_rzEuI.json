[
  {
    "start": "0",
    "end": "15170"
  },
  {
    "text": "JUSTIN NORTON: Welcome to our\nsecond episode of the Stanford Health Care AI Water\nCooler discussions,",
    "start": "15170",
    "end": "23160"
  },
  {
    "text": "and I'm Justin Norton, a\nStanford faculty and co-founder of Qualified Health.",
    "start": "23160",
    "end": "29700"
  },
  {
    "text": "We have Matthew\nLundgren, our co-host, who's chief scientific\nofficer for Microsoft Health and also on Stanford faculty.",
    "start": "29700",
    "end": "36239"
  },
  {
    "text": "And we're thrilled to be joined\nby Dr. Graham Walker, who is also a Stanford Medicine--",
    "start": "36240",
    "end": "41840"
  },
  {
    "text": "GRAHAM WALKER: Former\nStanford faculty. MATTHEW LUNDGREN: Former. JUSTIN NORTON: Former\nStanford faculty. Perfect, who's also co-directs\nthe advanced technology group",
    "start": "41840",
    "end": "50330"
  },
  {
    "text": "for Kaiser Permanente, which is\nall the advanced technology, AI, and new things coming.",
    "start": "50330",
    "end": "56300"
  },
  {
    "text": "And he's also the\nfounder of MDCalc, who I'm sure many\npeople have used, a new company called Offcall,\nand many other things.",
    "start": "56300",
    "end": "63620"
  },
  {
    "text": "So thank you, Graham,\nso much for joining us. GRAHAM WALKER: Thanks\nfor having me, guys. Yeah, good to be back on\nthe virtual farm as it were.",
    "start": "63620",
    "end": "71350"
  },
  {
    "text": "MATTHEW LUNDGREN: This counts. Yeah. So for today, I mean, so\nfrom our first episode,",
    "start": "71350",
    "end": "76820"
  },
  {
    "text": "we had a ton of\ngreat responses, some comments about some\ntechnical things, some things that people wanted\nto see us cover.",
    "start": "76820",
    "end": "84250"
  },
  {
    "text": "And as you know\nthis is really meant to be of a conversation that\nreflects the ones that we have when we're not on\ncamera and recording.",
    "start": "84250",
    "end": "91930"
  },
  {
    "text": "And we have a few topics\ntoday, and then we'll get into just some\ngeneral discussion about what we're seeing today.",
    "start": "91930",
    "end": "98659"
  },
  {
    "text": "So we're going to talk a\nlittle bit about GPT 4.5, kind of one of the newer\nmodels that have hit the scene,",
    "start": "98660",
    "end": "105590"
  },
  {
    "text": "although we have a bunch. And then we'll talk\nabout the bunch as well. We kind of have a\nparalysis by choice",
    "start": "105590",
    "end": "111549"
  },
  {
    "text": "at this point with so many\ndifferent models choose from. And then we'll talk about\nsome new data that's coming out around physicians\nand their use of both",
    "start": "111550",
    "end": "119620"
  },
  {
    "text": "the public models and\neven some of the solutions that have been deployed into\npractice and get full stake.",
    "start": "119620",
    "end": "126668"
  },
  {
    "text": "And there's just a\nfew odds and ends, some headlines that have\ncome our way that have raised a lot of discussions. One around some proposals\naround regulation",
    "start": "126668",
    "end": "134860"
  },
  {
    "text": "and maybe even new\ncapabilities for AI models prescribing capabilities, which\nis kind of interesting idea,",
    "start": "134860",
    "end": "141878"
  },
  {
    "text": "and we'll get\neveryone's reaction. ",
    "start": "141878",
    "end": "147550"
  },
  {
    "text": "JUSTIN NORTON: Sounds good. Well, should we start with\nsome of the new capabilities? MATTHEW LUNDGREN:\nYeah, let's do it.",
    "start": "147550",
    "end": "152870"
  },
  {
    "text": "I think maybe it's worth it. And Graham, feel free\nto chime in on this. Yeah, I just wanted\nto just to level set.",
    "start": "152870",
    "end": "158240"
  },
  {
    "text": "Well, so for those\nof you who aren't familiar with the law\nbehind the TikZ Unicorn,",
    "start": "158240",
    "end": "163879"
  },
  {
    "text": "this is Sebastien Bubeck. This is a hearkens back to a\npaper he wrote, Sparks of AGI basically paper.",
    "start": "163880",
    "end": "170230"
  },
  {
    "text": "The original GPT 4, which\nsurprised a lot of people that the model was\nable to put together,",
    "start": "170230",
    "end": "175265"
  },
  {
    "text": "as you can see in\nthe middle, something that resembles a unicorn. Again, this was\na language model.",
    "start": "175265",
    "end": "180760"
  },
  {
    "text": "This was a shocking\nresult back in 2022, and obviously a leap from 3.5.",
    "start": "180760",
    "end": "186540"
  },
  {
    "text": "So to in the recent 4.5\nsort of evaluations, he posted the new kind of\nupdated impression of a TikZ",
    "start": "186540",
    "end": "195410"
  },
  {
    "text": "Unicorn just to\ngive a visual sense. But if you actually look at some\nof the data around the model's",
    "start": "195410",
    "end": "201770"
  },
  {
    "text": "performance, again, we're\nnot seeing this massive leap, but remember that some\nof these benchmarks",
    "start": "201770",
    "end": "206900"
  },
  {
    "text": "are relatively close to\nsaturation in certain areas. I think for some of these simple\nones, some important things",
    "start": "206900",
    "end": "213440"
  },
  {
    "text": "to take away. We're used to these huge\njumps between three to four, and we're seeing some\nmaybe somewhat incremental",
    "start": "213440",
    "end": "220550"
  },
  {
    "text": "or slowing improvement. And this is really\nreflective I think of the pre-training,\nthe traditional approach",
    "start": "220550",
    "end": "227360"
  },
  {
    "text": "to pre-training, the scaling\nlaws of exponents input for somewhat linear\nimprovements,",
    "start": "227360",
    "end": "233320"
  },
  {
    "text": "so it gets-- these models\nget bigger and bigger. They become harder and harder to\nmake, quote unquote, \"smarter,\"",
    "start": "233320",
    "end": "238590"
  },
  {
    "text": "but we have some other things to\nwork with and test time compute. But on the right hand side,\nwhich I'm really excited about,",
    "start": "238590",
    "end": "244260"
  },
  {
    "text": "which is that the\nhallucination rate, which does tend to limit or\nreally force you to build a lot of scaffolding\naround applications",
    "start": "244260",
    "end": "252230"
  },
  {
    "text": "off the shelf is starting\nto look quite a bit better, and I think a lot of\npeople would agree when they're using the models.",
    "start": "252230",
    "end": "257670"
  },
  {
    "text": "I don't know Graham\nor Justin, if you've been playing with any\nof these newer models and noticing that\nthe stuff that you",
    "start": "257670",
    "end": "262790"
  },
  {
    "text": "used to pick up all the\ntime, this thing was wrong or this seemed off. It's starting to look\na little bit better.",
    "start": "262790",
    "end": "268350"
  },
  {
    "text": "GRAHAM WALKER: I mean, Matthew,\nI'm a little surprised that it still is 37%. I'm not super familiar with\nthe simple QA data set,",
    "start": "268350",
    "end": "276960"
  },
  {
    "text": "but I mean that still\nseems way higher. I think there's probably\ntwo things going on.",
    "start": "276960",
    "end": "282090"
  },
  {
    "text": "People are more comfortable\nwith the LLM responses, and so they're\nprobably checking them",
    "start": "282090",
    "end": "288890"
  },
  {
    "text": "less to be completely honest. These things have met some\nsort of acceptable criteria",
    "start": "288890",
    "end": "297180"
  },
  {
    "text": "for humans to start\nusing and trusting. I mean, I think Google's\npartly to blame for that too.",
    "start": "297180",
    "end": "305440"
  },
  {
    "text": "I mean, they've just\nbeen embedding them in all your search terms. I mean, often I'm now\nseeing-- like if I'm",
    "start": "305440",
    "end": "311370"
  },
  {
    "text": "like getting in an\nargument with a friend, a friend will send\nme the Google answer. But it's not the Google answer,\nit's the Google AI answer,",
    "start": "311370",
    "end": "318670"
  },
  {
    "text": "and that's not really\nthe same thing. It used to be, oh, yeah,\nhere's the screenshot of the fact from the web\npage, or it's from census.gov.",
    "start": "318670",
    "end": "326560"
  },
  {
    "text": "Nope, it's now the screenshot. And I don't know\nif my friends know that they're sending\nan AI version",
    "start": "326560",
    "end": "333090"
  },
  {
    "text": "or if they are just\nimplicitly trusting them, but that's the thing. We've reached some level where\npeople are just implicitly",
    "start": "333090",
    "end": "339810"
  },
  {
    "text": "trusting these things. I'm not sure that humanity\nshould be trusting them just yet, but it seems\nlike we're there.",
    "start": "339810",
    "end": "348625"
  },
  {
    "text": "JUSTIN NORTON: Yeah,\nthere's almost a-- MATTHEW LUNDGREN: Yeah,\nthere's a trust but verify, I think, to at least\nfor those of us",
    "start": "348625",
    "end": "353890"
  },
  {
    "text": "that use them all the time. And in this metacognition\nthing, where you're like, OK, I know it's going to get\nme like 80% of the way there,",
    "start": "353890",
    "end": "361400"
  },
  {
    "text": "but it's still going\nto save me some time. But the worst part of this is\nwhat we would call the GPT slop.",
    "start": "361400",
    "end": "369914"
  },
  {
    "text": "I think which by\nthe way, I think was in the running for the\nterm of the year last year",
    "start": "369915",
    "end": "375100"
  },
  {
    "text": "Webster's dictionary new term. But that's where-- I mean,\nI've gotten to the point, I think, there was\nbeen some data on this",
    "start": "375100",
    "end": "380800"
  },
  {
    "text": "where I can read\nsome of these posts and say that looks like a clod\nor that looks like a GPT 4",
    "start": "380800",
    "end": "387550"
  },
  {
    "text": "to me, and you can\ntell there's not a lot of effort put\ninto the editing. GRAHAM WALKER: Well,\nthis is the thing",
    "start": "387550",
    "end": "393760"
  },
  {
    "text": "I want to pull up that kind\nof brings both of those things together, which is one, there\nare so many of these models",
    "start": "393760",
    "end": "399080"
  },
  {
    "text": "out now. Or what's changed in two years? Versus, oh, my gosh, look\nat these capabilities.",
    "start": "399080",
    "end": "405032"
  },
  {
    "text": "They've come out. One, there are so\nmany models out there now and competition for that.",
    "start": "405032",
    "end": "410530"
  },
  {
    "text": "That Graham to your point,\nthe companies are just embedding the AI capabilities\nin their native applications,",
    "start": "410530",
    "end": "417120"
  },
  {
    "text": "which lots of people\nthought would come. And the reason to do that is\nto keep people in the platform and it's a way to\ncompete with others.",
    "start": "417120",
    "end": "423510"
  },
  {
    "text": "And so there are so\nmany of these models out there for I\nguess most of us.",
    "start": "423510",
    "end": "428550"
  },
  {
    "text": "And people listening, it's\nreminiscent of the old search pages where you'd use AltaVista\nand Ask Jeeves and just",
    "start": "428550",
    "end": "436460"
  },
  {
    "text": "a long list of\ncompanies where you'd ask multiple times to\ntry to get to your answer before Google really\nkind of won out.",
    "start": "436460",
    "end": "445280"
  },
  {
    "text": "And as we're looking at\nthese models, a question that I get all the\ntime is like, well, what model do I use for what?",
    "start": "445280",
    "end": "451083"
  },
  {
    "text": "And the challenging\npart of that is it's changing every few weeks. It's not just GPT\n4.5 that came out.",
    "start": "451083",
    "end": "457620"
  },
  {
    "text": "It's Cloud 3.7 just\ncame out, and there's new models every couple of\nweeks and so that's changing.",
    "start": "457620",
    "end": "462979"
  },
  {
    "text": "But the interesting\nthing to me, at least, is it seems like this\nis moving to a world where there's going to be\nmultiple models to choose from,",
    "start": "462980",
    "end": "470750"
  },
  {
    "text": "both for a consumer,\nboth for companies, both for health organizations. And so when I think about it,\nhow do you set yourselves up",
    "start": "470750",
    "end": "479370"
  },
  {
    "text": "to use multiple\ndifferent things? And to be able to access\nmultiple different things is something that I think is\nsuper important, but curious",
    "start": "479370",
    "end": "487050"
  },
  {
    "text": "Matt, Graham, what do you\nguys think about that? What are you using for yourself? MATTHEW LUNDGREN: What\nyou're showing on the screen",
    "start": "487050",
    "end": "492840"
  },
  {
    "text": "is I was just doing\nthe back of the napkin. That's about $300 a\nmonth of subscriptions.",
    "start": "492840",
    "end": "499384"
  },
  {
    "text": "GRAHAM WALKER: Tools. Yeah. JUSTIN NORTON: Assuming you're\nnot paying the $200 a month for OpenAI pro.",
    "start": "499385",
    "end": "505750"
  },
  {
    "text": "GRAHAM WALKER: For the pro. Yeah, I'm mostly using\nChatGPT and Claude.",
    "start": "505750",
    "end": "514019"
  },
  {
    "text": "ChatGPT tends to give me answers\nthat are a bit more unique.",
    "start": "514020",
    "end": "522900"
  },
  {
    "text": "And then I'm using Claude really\naround more editing capability, when I want feedback\non my writing,",
    "start": "522900",
    "end": "529209"
  },
  {
    "text": "but I don't want my\nwriting to change as much. ChatGPT is more than\nhappy to tell me",
    "start": "529210",
    "end": "534699"
  },
  {
    "text": "that oh, I love this\narticle that you just wrote, and then rewrite it\nin its own words.",
    "start": "534700",
    "end": "541250"
  },
  {
    "text": "And it's like both\ncomplimenting me, but also it's like a\nbackhanded compliment that it's redone the whole thing\nbecause it wasn't that good.",
    "start": "541250",
    "end": "548019"
  },
  {
    "text": "Versus Claude typically\nwill stick with my own words",
    "start": "548020",
    "end": "553810"
  },
  {
    "text": "and then try to clean them up,\nmake them a little bit more cohesive without changes\nchanging as much,",
    "start": "553810",
    "end": "559850"
  },
  {
    "text": "so those are the two\nI'm using the most. I've played around with\nDeep Seek a fair amount. I found that Deep Seek when I've\njust been testing Deep Seek.",
    "start": "559850",
    "end": "568310"
  },
  {
    "text": "Deep Seek will let you\nget away with more stuff, and it'll be a little bit\nmore-- allow a little bit more devious behavior,\nwhich is probably",
    "start": "568310",
    "end": "576190"
  },
  {
    "text": "a factor because open source and\nnot as the weights are all open,",
    "start": "576190",
    "end": "581870"
  },
  {
    "text": "so I imagine they probably\nhave to allow more of that. And I think that's the testing\nthat I've seen as well. Like you can get\nDeep Seek to tell you",
    "start": "581870",
    "end": "588700"
  },
  {
    "text": "how to rob a bank much\neasier than you can Claude, or ChatGPT, or some of the\nother kind of closed models.",
    "start": "588700",
    "end": "594050"
  },
  {
    "text": "MATTHEW LUNDGREN: Have\nyou tried them all? I mean, you still practice,\nand so do you ever throw in",
    "start": "594050",
    "end": "601519"
  },
  {
    "text": "and just see if it comes\nup with a differential that seems reasonable? Do you ever do that or-- GRAHAM WALKER: The difference--",
    "start": "601520",
    "end": "607320"
  },
  {
    "text": "MATTHEW LUNDGREN: Yeah. GRAHAM WALKER: Yeah. The differentials are\nalways reasonable. They so far they've-- and\nI'm excited to try out 4.5.",
    "start": "607320",
    "end": "614970"
  },
  {
    "text": "Matthew if you want\nto give me access? The models all have some\ngap that still makes",
    "start": "614970",
    "end": "622310"
  },
  {
    "text": "me very leery to rely on them. I think, they're\ncontent generation,",
    "start": "622310",
    "end": "627840"
  },
  {
    "text": "so they're great for\ngenerating a differential. But I'm not yet\nconvinced that they're going to be a\ncomprehensive differential",
    "start": "627840",
    "end": "634310"
  },
  {
    "text": "or that the number\none thing is always going to be the\ncorrect one at the top. ",
    "start": "634310",
    "end": "641660"
  },
  {
    "text": "And then you add one\nmore complicating factor like, oh, it's a kid, or it's a\npregnant patient, or something",
    "start": "641660",
    "end": "646730"
  },
  {
    "text": "like that, and then they start\nto show a little bit more of their challenges, I think.",
    "start": "646730",
    "end": "653730"
  },
  {
    "text": "But, again, growth\nmindset, these things are-- every year, these things are\ngetting better and better,",
    "start": "653730",
    "end": "661090"
  },
  {
    "text": "and it's harder\nand harder to find those challenge-- find those\nareas where they're not as good.",
    "start": "661090",
    "end": "667751"
  },
  {
    "text": "MATTHEW LUNDGREN: Yeah, I\nremember when 3.5 came out, you'd see these viral threads. It's super simple\nmedical questions.",
    "start": "667752",
    "end": "673870"
  },
  {
    "text": "It'd be wildly off base. And like I said, I mean,\nobviously I use it all the time.",
    "start": "673870",
    "end": "679030"
  },
  {
    "text": "I partisan red teaming\nwork and things and it's increasingly hard. In fact, it actually\nstretches some",
    "start": "679030",
    "end": "685920"
  },
  {
    "text": "of your own medical\nknowledge, and then you have to go back to the\nsource like that sounds right, but I need to double check.",
    "start": "685920",
    "end": "691960"
  },
  {
    "text": "And that kind of gets\nme to deep research. And I don't know if you've\nplayed with those Graham Richardson, but I've\nhad moments of just",
    "start": "691960",
    "end": "699149"
  },
  {
    "text": "like almost just\nlike the initial GPT moment with deep\nresearch, where I'm like, this is a game changer.",
    "start": "699150",
    "end": "705130"
  },
  {
    "text": "And then there'll\nbe times when like, it's a pretty superficial\nread of some of the content, but you know where\nthis is headed.",
    "start": "705130",
    "end": "710930"
  },
  {
    "text": "I mean, to your point, this\nis the worst it'll ever be. That kind of thing\nyou hear said a lot. But if you talk about access\nto all of your journals and all",
    "start": "710930",
    "end": "718600"
  },
  {
    "text": "the things that we subscribe\nto and our medical libraries, now you're talking. I mean, that could\nbe pretty powerful.",
    "start": "718600",
    "end": "724460"
  },
  {
    "text": "And I don't know if you've used\nthese, and kind of tested out with topics that really well to\nget a sense of how close it is?",
    "start": "724460",
    "end": "732377"
  },
  {
    "text": "JUSTIN NORTON: Yeah. Well, speaking of medical\njournals and access, there's a recent announcement,\na headline OpenEvidence just",
    "start": "732377",
    "end": "739870"
  },
  {
    "text": "raised a boatload of money. And they claimed, I\nthink, 25% of physicians",
    "start": "739870",
    "end": "746800"
  },
  {
    "text": "were now using the tool. In my head I think about it\nas an up to date competitor",
    "start": "746800",
    "end": "753460"
  },
  {
    "text": "of being able to ask\nopen ended questions, cite this with real research,\nreduce that hallucination",
    "start": "753460",
    "end": "759460"
  },
  {
    "text": "rate, which was something\nthat came up before. Drop that down\nwhere initially when",
    "start": "759460",
    "end": "764710"
  },
  {
    "text": "people were asking\nquestions with GPT 4, I was like, oh, my gosh,\nlook at all these citations. Then you look at the citations\nand they were all made up.",
    "start": "764710",
    "end": "771250"
  },
  {
    "text": "But as the scaffolding, I think\nthat Matt talked about before around these models, where\nyou constrain what they're",
    "start": "771250",
    "end": "779020"
  },
  {
    "text": "able to look through to only be\nable to produce certain things. It's not just that the\nmodels are getting better,",
    "start": "779020",
    "end": "785810"
  },
  {
    "text": "basically as\nsoftware developers. And I feel like this is actually\nsomething a lot of people miss when they're talking\nabout, at least in health,",
    "start": "785810",
    "end": "792627"
  },
  {
    "text": "of people who aren't maybe\nfamiliar with the technology. It's like, oh, did the\nmodels just get better? It's like that is\none aspect of how",
    "start": "792627",
    "end": "799248"
  },
  {
    "text": "these tools are getting better. We're also getting a\nlot better as engineers for how to use them and use them\nin a way that actually produces",
    "start": "799248",
    "end": "807196"
  },
  {
    "text": "meaningful results,\nand so that's just an example recently of something\nthat has really kind of gained",
    "start": "807197",
    "end": "813730"
  },
  {
    "text": "a lot of traction in the\nlast few months and years. MATTHEW LUNDGREN: Yeah\nI was going to say, Graham, have you ever tried to\nthrow in prompts to this say",
    "start": "813730",
    "end": "821680"
  },
  {
    "text": "cloud or something and just say\ncreate an MDCalc from scratch? Have you ever tried that?",
    "start": "821680",
    "end": "826800"
  },
  {
    "text": "GRAHAM WALKER: Totally. Yeah., and there\nare some calculators that it's been able\nto do really well.",
    "start": "826800",
    "end": "832440"
  },
  {
    "text": "And there's others\nthat it's like, oh, this is dangerously bad\nbecause it's going to--",
    "start": "832440",
    "end": "837514"
  },
  {
    "text": "I mean, that's the\nother thing that I think about a lot is\nit's that level of trust.",
    "start": "837515",
    "end": "842910"
  },
  {
    "text": "I mean, it's the Google\nembedding it in search results thing that I do worry that\neven with hallucination rates",
    "start": "842910",
    "end": "851180"
  },
  {
    "text": "going down and scaffolding\ngetting better, you could feed the\nmodel back to itself and verify that the answer\nis-- that the model thinks",
    "start": "851180",
    "end": "858590"
  },
  {
    "text": "the model is accurate. I still do worry\nthat somebody is",
    "start": "858590",
    "end": "865310"
  },
  {
    "text": "going to make a decision based\non an LLM piece of information",
    "start": "865310",
    "end": "873170"
  },
  {
    "text": "that is maybe it's not wrong,\nbut it's just not comprehensive. And they do not have the\ntraining or the experience",
    "start": "873170",
    "end": "881990"
  },
  {
    "text": "to know that, oh, yeah,\nusually you can give that drug. In this particular\ncircumstances,",
    "start": "881990",
    "end": "887440"
  },
  {
    "text": "that was a really bad idea. And either the model gave\nyou the wrong information",
    "start": "887440",
    "end": "893550"
  },
  {
    "text": "or you didn't give the model\nenough information for the model to give you the right answer. I mean, pregnant patients take--",
    "start": "893550",
    "end": "901950"
  },
  {
    "text": "for some reason, I'm thinking\nabout digoxin toxicity and giving them calcium\nand stone heart, which",
    "start": "901950",
    "end": "909000"
  },
  {
    "text": "I think has mostly\nbeen debunked, but still like you can imagine\na human doctor is going",
    "start": "909000",
    "end": "914598"
  },
  {
    "text": "to have to try to take in\nall the pieces of information and then take an action. But if you're just giving it\nthe two liner from your H&P,",
    "start": "914598",
    "end": "923130"
  },
  {
    "text": "that's often not\nsufficient information to give a right answer to. ",
    "start": "923130",
    "end": "931260"
  },
  {
    "text": "JUSTIN NORTON: And I think\nthe usage is interesting. But one thing actually,\nthat has come up before and through a ton\nof conversations, Graham,",
    "start": "931260",
    "end": "938139"
  },
  {
    "text": "to argue the other side\nas compared to what? So are there going\nto be AI misses?",
    "start": "938140",
    "end": "943580"
  },
  {
    "text": "Yes, yes, and yes. Often it'll come up and\nusually they're overblown, but you always hear the\nmedia headlines of look",
    "start": "943580",
    "end": "950680"
  },
  {
    "text": "how many mistakes\nphysicians make. And now we're starting to\nsee the articles of patients",
    "start": "950680",
    "end": "956830"
  },
  {
    "text": "working with AI to\nget the diagnosis that the doctor missed.",
    "start": "956830",
    "end": "963061"
  },
  {
    "text": "How do you think? What should we compare\nthat AI against?",
    "start": "963061",
    "end": "968710"
  },
  {
    "text": "Or even for yourself. How are you comparing\nit for yourself, for when and where you\nshould use these tools?",
    "start": "968710",
    "end": "974529"
  },
  {
    "text": "GRAHAM WALKER: Yeah, I think\nof the Tesla full driving",
    "start": "974530",
    "end": "980380"
  },
  {
    "text": "capability thing where I\ndon't really know that-- it feels ethically because\nit's like the loss of control",
    "start": "980380",
    "end": "988960"
  },
  {
    "text": "that these tools need to\nbe not just as good, not just one point better than\nthe average human driver.",
    "start": "988960",
    "end": "996370"
  },
  {
    "text": "Because you can always argue\nthat the average human driver may have hit the brake fast\nenough or something like that. It does feel because you're\nlosing the control factor,",
    "start": "996370",
    "end": "1004400"
  },
  {
    "text": "it feels like they need to be at\nthe 99.9 percentile of the best driver in the world.",
    "start": "1004400",
    "end": "1011710"
  },
  {
    "text": "And then the other\nthing I always think about is to\nyour point, Justin, we can't think about risk\nof tools in a vacuum.",
    "start": "1011710",
    "end": "1019580"
  },
  {
    "text": "We have to think of total risk. I mean, it's like when I give\nsomebody a blood transfusion,",
    "start": "1019580",
    "end": "1024770"
  },
  {
    "text": "I tell them your risk of\nwalking across the street after I get you feeling better\nand you get hit by a bus is way higher than your\nrisk of HIV or hepatitis",
    "start": "1024770",
    "end": "1032260"
  },
  {
    "text": "C, which are, of course,\nthe two most common things that people worry about. But they're like one in a\nmillion, one in 10 million,",
    "start": "1032260",
    "end": "1038260"
  },
  {
    "text": "and so you have to think\nabout all the risk. And certainly the other risk\nis patients waiting six months",
    "start": "1038260",
    "end": "1044530"
  },
  {
    "text": "to see a cardiologist, because\nthere's a backlog to get seen and the patients are going\nto get sicker in that time.",
    "start": "1044530",
    "end": "1051740"
  },
  {
    "text": "So I think we do have to think\nabout, consider all the risks and not just think\nabout the risks of AI",
    "start": "1051740",
    "end": "1057333"
  },
  {
    "text": "or just think about\nthe risks of humans, but think about\nthe risks of being a patient in\nAmerican healthcare.",
    "start": "1057333",
    "end": "1064970"
  },
  {
    "text": "JUSTIN NORTON: Yeah. The interesting thing that\nI want to make sure we get to here on people using\nthese tools and how and why.",
    "start": "1064970",
    "end": "1074825"
  },
  {
    "text": "You brought this\nup a little bit, but this was a recent survey. The AMA published a second\ngeneration of AI use.",
    "start": "1074825",
    "end": "1084710"
  },
  {
    "text": "And they call I use\ninterestingly, not artificial intelligence, they\ncall it augmented intelligence",
    "start": "1084710",
    "end": "1089990"
  },
  {
    "text": "but across clinicians. And this number\nwas shocking to me.",
    "start": "1089990",
    "end": "1096500"
  },
  {
    "text": "Before and it seemed to be\naround a third of clinicians were using AI in their practice.",
    "start": "1096500",
    "end": "1103380"
  },
  {
    "text": "Now that jumped to 2/3. And the context I'm always\nstill shocked by this is 2/3",
    "start": "1103380",
    "end": "1110752"
  },
  {
    "text": "of clinicians are using this. Most work settings haven't given\npeople access to these tools. And so it's just this amazing.",
    "start": "1110752",
    "end": "1117539"
  },
  {
    "text": "It's amazing things. And I know we've talked\nabout this before, but it's like people are\ngoing around and using",
    "start": "1117540",
    "end": "1123680"
  },
  {
    "text": "phones, using other things,\nbut what do you make of this? GRAHAM WALKER: I would love\nto see if this trend is",
    "start": "1123680",
    "end": "1131150"
  },
  {
    "text": "true in other countries. I tend to assign a lot of the\nthings that we see in the US",
    "start": "1131150",
    "end": "1139130"
  },
  {
    "text": "as due to our very dysfunctional\nhealth care system. And so like I see the\nrapid adoption here",
    "start": "1139130",
    "end": "1147320"
  },
  {
    "text": "as a sign of doctors\nin the US are really struggling to keep up\nwith all of the stuff,",
    "start": "1147320",
    "end": "1152697"
  },
  {
    "text": "whether it's clinical, or\nadministrative, or prior auth, or anything like that. So I would be fascinated\nto know if this trend is",
    "start": "1152697",
    "end": "1160850"
  },
  {
    "text": "an international trend? Is the UK-- I mean, actually every\ncountry's physicians and nurses",
    "start": "1160850",
    "end": "1166820"
  },
  {
    "text": "and healthcare workers in the\nwhole world are struggling. Many are quitting. Many med students\nacross the world",
    "start": "1166820",
    "end": "1172520"
  },
  {
    "text": "don't want to practice\nat the bedside. So it could be that\nthis is a wide trend,",
    "start": "1172520",
    "end": "1178600"
  },
  {
    "text": "or it could be like American\nmedicine is particularly bad and so doctors are way more\nlikely to use these in the US",
    "start": "1178600",
    "end": "1185159"
  },
  {
    "text": "than other places. MATTHEW LUNDGREN: I\nmean, I feel like we talked a little bit about\nthis last time, Justin, too which was the sort of British\nMedical Journal had a paper",
    "start": "1185160",
    "end": "1192120"
  },
  {
    "text": "on surveying GPs and the NHS. And they weren't quite\nas granular as maybe",
    "start": "1192120",
    "end": "1198000"
  },
  {
    "text": "what I'm seeing here. And they were actually focusing\non just the public API, basically the public models that\nyou'd have put on your phone.",
    "start": "1198000",
    "end": "1204910"
  },
  {
    "text": "And I think the surprising\nresult that we talked about, which I think is echoed\nhere, but just I can't quite",
    "start": "1204910",
    "end": "1211320"
  },
  {
    "text": "match the results there to here\nas well, because I'm assuming some of these are software\nthat was sold from vendors that",
    "start": "1211320",
    "end": "1219240"
  },
  {
    "text": "have vetted the capabilities. But I guess almost a\nthird of these docs",
    "start": "1219240",
    "end": "1224340"
  },
  {
    "text": "were using it for what you\nwould consider a medical device. Something that would\nbe a clinical decision",
    "start": "1224340",
    "end": "1230100"
  },
  {
    "text": "support device and that. That's surprising, but\nalso at the same time not.",
    "start": "1230100",
    "end": "1235390"
  },
  {
    "text": "Of course they are,\nyou knowl what I mean? At some level, to your\npoint, they're stressed, they're working through\nthings, and maybe",
    "start": "1235390",
    "end": "1240807"
  },
  {
    "text": "they're finding\nthese tools useful. I'm hearing stories of folks\nare literally just kind of using the voice mode\naround in ER settings,",
    "start": "1240807",
    "end": "1249580"
  },
  {
    "text": "urgent cares, and basically\nkind of almost doing like you would when you\nwere an intern or a resident presenting the case and\nthen getting feedback.",
    "start": "1249580",
    "end": "1257870"
  },
  {
    "text": "And I've heard other\nstories of folks, hoping to have one\nof them on the pod,",
    "start": "1257870",
    "end": "1263530"
  },
  {
    "text": "because they're doing\na study on this. But remember in the old\nwhen we were in med school, at least when I was, it\nwas kind of a novel idea",
    "start": "1263530",
    "end": "1270460"
  },
  {
    "text": "to bring an infectious\ndisease or a farm a pharmacist actually with you on\nrounds, particularly in ICU",
    "start": "1270460",
    "end": "1275890"
  },
  {
    "text": "to look at the huge list of\nmeds we're putting patients on and give feedback.",
    "start": "1275890",
    "end": "1281140"
  },
  {
    "text": "And now, a similar\nthing is happening, but they're literally wheeling\naround GPT basically and having",
    "start": "1281140",
    "end": "1290260"
  },
  {
    "text": "it listening to the discussion\nand then make comments. I think it's a fascinating idea.",
    "start": "1290260",
    "end": "1295400"
  },
  {
    "text": "And again, just kind of\nbrings the point of maybe we don't know how to practice\nmedicine and take advantage",
    "start": "1295400",
    "end": "1300409"
  },
  {
    "text": "of these tools in\nthe best way yet. GRAHAM WALKER: Yeah, it's\nstill very, very early days.",
    "start": "1300410",
    "end": "1306559"
  },
  {
    "text": "JUSTIN NORTON: Yeah, what's\ninteresting about that though, is this one other\nslide and then I",
    "start": "1306560",
    "end": "1311900"
  },
  {
    "text": "promise I'll put away\nsome of the AMA data here. But the definite\nadvantage group to me",
    "start": "1311900",
    "end": "1319790"
  },
  {
    "text": "is what I'm tracking in my head. Obviously, scribing has\ngained a ton of momentum",
    "start": "1319790",
    "end": "1328232"
  },
  {
    "text": "over the past couple of years as\nthese tools have gotten better. And there's still a mixed,\npeople have different opinions",
    "start": "1328233",
    "end": "1335360"
  },
  {
    "text": "for how helpful or where it's\nhelpful and things like that, but there are certain\npeople who swear by it now.",
    "start": "1335360",
    "end": "1341725"
  },
  {
    "text": "And there are\ncertain people, who started to use these other\nAI tools that are absolutely seen advantage.",
    "start": "1341725",
    "end": "1346740"
  },
  {
    "text": "I've talked to former\nstudents who've taken generative AI medicine\ncourse who are using these things all the time.",
    "start": "1346740",
    "end": "1352919"
  },
  {
    "text": "And they think they save,\njust from the public tools where they're trying not to\nput in any patient information,",
    "start": "1352920",
    "end": "1358950"
  },
  {
    "text": "a couple hours a day when they\nwere an intern, because it helped with discharge summaries,\nplanning tough conversations",
    "start": "1358950",
    "end": "1366059"
  },
  {
    "text": "with patients, looking up\ncurrent evidence, and things like this. And so the reason I track this\nkind of definite advantage group",
    "start": "1366060",
    "end": "1375780"
  },
  {
    "text": "is it's kind of a bellwether\nfor what's to come. There's always this kind of\ncurve of adoption of technology.",
    "start": "1375780",
    "end": "1381460"
  },
  {
    "text": "But when you track that group\nand people are absolutely seeing the benefits, to me, it\njust says it's a matter of time",
    "start": "1381460",
    "end": "1386820"
  },
  {
    "text": "before this gets\nmore widespread, and that's one of the things\nthat Yeah, again, this",
    "start": "1386820",
    "end": "1392520"
  },
  {
    "text": "is the worst it will be. And so we're really\nalready seeing benefits that if you\nscale it to the issues",
    "start": "1392520",
    "end": "1398970"
  },
  {
    "text": "that Graham was talking\nabout around burnout issues, people leaving medicine, it\nhas started to at least give me",
    "start": "1398970",
    "end": "1406050"
  },
  {
    "text": "some hope. GRAHAM WALKER: I think we need\nto have more people sharing how they're using them.",
    "start": "1406050",
    "end": "1411610"
  },
  {
    "text": "I mean, Matthew, I'd\nnever heard of that kind of like a virtual\nAI pharmacist idea.",
    "start": "1411610",
    "end": "1418639"
  },
  {
    "text": "Love it. I think there's so many\nways that these tools can",
    "start": "1418640",
    "end": "1423852"
  },
  {
    "text": "be used that people just\naren't thinking about. I mean, I was\nshowing my mom like, oh, you could talk\nto it in Spanish.",
    "start": "1423852",
    "end": "1430059"
  },
  {
    "text": "You want to practice\nyour Spanish? Just ask it to do super beginner\nSpanish with you and it'll just",
    "start": "1430060",
    "end": "1435159"
  },
  {
    "text": "do it, and she hadn't\neven thought of that as a possibility. And I had like AI had a\nchallenging palliative care",
    "start": "1435160",
    "end": "1444790"
  },
  {
    "text": "discussion with a patient\nin the ED, and I like-- the day later it was\nstill bugging me. I was like, God, could\nI have done that better?",
    "start": "1444790",
    "end": "1451288"
  },
  {
    "text": "And so I kind of described\nwithout, of course, PHI or details I described how\nthe patient and their family",
    "start": "1451288",
    "end": "1457420"
  },
  {
    "text": "was feeling and what I\nwas trying to convey. And I said, hey, can you pretend\nto be this family member?",
    "start": "1457420",
    "end": "1463490"
  },
  {
    "text": "Be the daughter of my\npatient, and then I'm going to talk to you. And then when I say, that's a\nwrap or something, let's pause",
    "start": "1463490",
    "end": "1472190"
  },
  {
    "text": "and give me feedback. How did I do? And so there are just--",
    "start": "1472190",
    "end": "1478340"
  },
  {
    "text": "shout out Sanford did my\nsimulation medicine training there, but there's\nso many ways we could use these tools outside\nof just clinical medicine.",
    "start": "1478340",
    "end": "1486179"
  },
  {
    "text": "Think about simulation. Think about difficult\nconversations with patients. Breaking bad news.",
    "start": "1486180",
    "end": "1491760"
  },
  {
    "text": "AI pharmacist. I heard somebody,\na guy at Yale is using a bridge with med students\nand having the med student write",
    "start": "1491760",
    "end": "1500240"
  },
  {
    "text": "their own note. Having a bridge write\nthe note, and then they have to critique what they\nliked about their note versus a bridges and why?",
    "start": "1500240",
    "end": "1506600"
  },
  {
    "text": "And why did a bridge include\nthat here in the HPI, but you put it in\nsocial history? There are ways we can use\nthese tools not to replace us,",
    "start": "1506600",
    "end": "1514350"
  },
  {
    "text": "but to teach and educate\nand help us, for sure. MATTHEW LUNDGREN: Yeah,\nthe education topic",
    "start": "1514350",
    "end": "1520100"
  },
  {
    "text": "is one that I'm surprised\nI don't hear more often. I mean, you brought up the\nreally, really important use case, which is the\nempathetic coaching.",
    "start": "1520100",
    "end": "1527122"
  },
  {
    "text": "There's been a few\npapers on this. I think that's a\nphenomenal use case. First of all, we don't get\nthat many turns of battle.",
    "start": "1527123",
    "end": "1533670"
  },
  {
    "text": "Thankfully in a lot\nof our specialties, except for obviously\npalliative care or something, where we would get seminars\nfrom folks in palliative care",
    "start": "1533670",
    "end": "1540470"
  },
  {
    "text": "who do this as experts, and\nthey would come and give us some tips on how we can\nhave these hard discussions",
    "start": "1540470",
    "end": "1546560"
  },
  {
    "text": "with patients. But hearing it a couple\ntimes, maybe reading some-- but then actually\nwhen you're standing",
    "start": "1546560",
    "end": "1552170"
  },
  {
    "text": "there having to have\nthat discussion, man, I would almost take\nany sort of life preserver",
    "start": "1552170",
    "end": "1557210"
  },
  {
    "text": "to help me coach up for\nthose kinds of discussions. But on the education\ntopic, there's been some phenomenal papers\nthat just aren't really",
    "start": "1557210",
    "end": "1564440"
  },
  {
    "text": "getting a lot of attention. I'm surprised by one-- I don't know if Justin,\nyou have that one that it was a news article\nthat recently talked",
    "start": "1564440",
    "end": "1571460"
  },
  {
    "text": "about a school in Nigeria that\nused GPT 4 just as a tutor,",
    "start": "1571460",
    "end": "1576929"
  },
  {
    "text": "and two grade levels\nof advancement within like a six week\nintervention, which",
    "start": "1576930",
    "end": "1581990"
  },
  {
    "text": "is insane to me. And then obviously,\njust like you, I mean, you talked\nabout your mom. My daughter takes\nJapanese and her--",
    "start": "1581990",
    "end": "1589640"
  },
  {
    "text": "we obviously live in\nPalo Alto, so everyone's thinking about GPT anyway. But her teacher just said\nto the students straight up,",
    "start": "1589640",
    "end": "1595330"
  },
  {
    "text": "you need to be practicing\nyour Japanese conversation with the advanced voice\nmode of one of these models,",
    "start": "1595330",
    "end": "1603430"
  },
  {
    "text": "and I think that in it's\nbeen just tremendous. I wonder whether there's\na medical equivalent. You mentioned a\ncouple of use cases.",
    "start": "1603430",
    "end": "1609930"
  },
  {
    "text": "I remember back in\nthe day, we used to just go through question\nbanks for the step, but these models is I think\nNigam Shah's group showed",
    "start": "1609930",
    "end": "1616740"
  },
  {
    "text": "can actually write\nstep questions that are indistinguishable\nfrom real ones.",
    "start": "1616740",
    "end": "1622140"
  },
  {
    "text": "And actually, when you score the\npeople on them it's equivalent, so it really is a\nphenomenal study.",
    "start": "1622140",
    "end": "1628475"
  },
  {
    "text": "Again, I feel like\nthere's a lot. Maybe this is going on\nagain under the covers and we're just not hearing as\nmuch about it, but we're just--",
    "start": "1628475",
    "end": "1635280"
  },
  {
    "text": "it's early, I feel like is\nwhat I end up concluding. JUSTIN NORTON: The other\nthing, I'll just call out,",
    "start": "1635280",
    "end": "1640920"
  },
  {
    "text": "a few from students have\ncome up over the years from learning just\nexplaining concepts.",
    "start": "1640920",
    "end": "1646500"
  },
  {
    "text": "Hey, explain the\nKrebs cycle to me. No, no, no. Explain it like I'm\nan eighth grader.",
    "start": "1646500",
    "end": "1651920"
  },
  {
    "text": "No, no, no. Explain it like I'm 6. And you get these different reps\nand versions of these concepts",
    "start": "1651920",
    "end": "1660490"
  },
  {
    "text": "that these models might\nhave an inherent ability to tackle from\ndifferent perspectives.",
    "start": "1660490",
    "end": "1665830"
  },
  {
    "text": "That's what an\nexpert teacher does. They have such a good\ngrasp of the material. They can get six different\nways to explain it,",
    "start": "1665830",
    "end": "1673070"
  },
  {
    "text": "and that's what\nthese models can do. And to Graham,\nyour point before,",
    "start": "1673070",
    "end": "1680800"
  },
  {
    "text": "people are still just\nlearning these different ways to interact. And what's scary to\nme, kind of seeing",
    "start": "1680800",
    "end": "1688810"
  },
  {
    "text": "this is when I hear students'\nuse of these models, they're all across the spectrum.",
    "start": "1688810",
    "end": "1694150"
  },
  {
    "text": "Some are using these models 10\nhours a day in their learning. It's always on transcribing\nlectures, summarizing lectures,",
    "start": "1694150",
    "end": "1702020"
  },
  {
    "text": "asking questions,\ntranslating teaching. Others are barely\nusing them at all, and the gaps of\njust what people can",
    "start": "1702020",
    "end": "1710360"
  },
  {
    "text": "do and understand with\nthese models that alarms me a little bit, especially when\nwe see how much more some people",
    "start": "1710360",
    "end": "1718442"
  },
  {
    "text": "can get done with them. And so just-- and that's part\nof the reason we're doing this is, hey, great.",
    "start": "1718442",
    "end": "1724679"
  },
  {
    "text": "Maybe Graham's going to try\nadvanced voice mode on rounds with a pharmacist next time. Or people are going to get\nideas for ways to do this,",
    "start": "1724680",
    "end": "1730860"
  },
  {
    "text": "but hopefully people\nwill do so safely. I'll just I have\nthat disclaimer. MATTHEW LUNDGREN: I hope\nthe models get smart enough",
    "start": "1730860",
    "end": "1736280"
  },
  {
    "text": "to tell the student, you don't\nneed to know the Krebs cycle. It's all a scam. You'll never use it again.",
    "start": "1736280",
    "end": "1742400"
  },
  {
    "text": "GRAHAM WALKER: I mean,\nMatthew, that's part of that-- that's part of this. I have this idea that\nthese models will be--",
    "start": "1742400",
    "end": "1750020"
  },
  {
    "text": "if we train them appropriately\nwithout misinformation, these models will be more\nobjective arbiters of the truth,",
    "start": "1750020",
    "end": "1757980"
  },
  {
    "text": "and they may actually drive us\nto reform the medical education",
    "start": "1757980",
    "end": "1763760"
  },
  {
    "text": "curriculum. I mean, I still why were we\nall taught the brachial plexus?",
    "start": "1763760",
    "end": "1770320"
  },
  {
    "text": "Not just that it exists,\nbut the chords and the-- I don't even know.",
    "start": "1770320",
    "end": "1775545"
  },
  {
    "text": "I remember memorizing those, and\nI remember a bunch of mnemonics to memorize them. But why do I need to know how\nthose lines connect and then",
    "start": "1775545",
    "end": "1783539"
  },
  {
    "text": "overlap and cross? I don't know. I don't think either of\nyou could answer either, but it's part of tradition.",
    "start": "1783540",
    "end": "1792030"
  },
  {
    "text": "I mean, have you guys seen one\nof the first aid for step 1 now?",
    "start": "1792030",
    "end": "1797400"
  },
  {
    "text": "It is at least twice as\nthick as when I bought it in 2004 or something like that.",
    "start": "1797400",
    "end": "1805240"
  },
  {
    "text": "I mean, it's insane how much\nmore they have to memorize. And I mean, I thought\nit was bad enough to have to answer like\nstuff about cyclic GMP,",
    "start": "1805240",
    "end": "1812520"
  },
  {
    "text": "but now it's so much\nworse that it may-- these tools may force humans to\ndisrupt some of our tradition",
    "start": "1812520",
    "end": "1822149"
  },
  {
    "text": "and be like, oh,\nwell, it's important that people know that where\nthe nerves are on the body. But do they need to the way that\nthe brachial plexus connects?",
    "start": "1822150",
    "end": "1830510"
  },
  {
    "text": "Maybe not. The Krebs cycle. It's important to know\nthat thing exists. I think it does like\noxidative phosphorylation,",
    "start": "1830510",
    "end": "1836908"
  },
  {
    "text": "or is that the other one? But anyway. MATTHEW LUNDGREN:\nThat's not bad. Yeah. GRAHAM WALKER: Anyway,\nwe need to know what that is because aspirin\noverdoses block that.",
    "start": "1836908",
    "end": "1843920"
  },
  {
    "text": "But besides that, do you need to\nhave memorized the whole thing? It's like a running joke. MATTHEW LUNDGREN: Totally.",
    "start": "1843920",
    "end": "1849430"
  },
  {
    "text": "Well, I will say that. Well, there's two-- I feel\nlike I have two minds on this. One is like, I feel\nlike we are LLMs",
    "start": "1849430",
    "end": "1856655"
  },
  {
    "text": "in some if we want\nto use this analogy, and we're doing we have\nto do some pre-training. So there's some\njust like exercising",
    "start": "1856655",
    "end": "1863140"
  },
  {
    "text": "the muscle like that we do. I sort of still am\nhappy with the way that we at least attempt\nto get as much information.",
    "start": "1863140",
    "end": "1870590"
  },
  {
    "text": "It forces you to\nbecome someone that can absorb vast\namounts of information, process it, and still be able\nto manipulate the concepts.",
    "start": "1870590",
    "end": "1877700"
  },
  {
    "text": "There's something to that. I think in terms\nof just as being able to functionally keep\nup, and to your point",
    "start": "1877700",
    "end": "1882980"
  },
  {
    "text": "with the acceleration. But there's also this\nidea of skill atrophy, which is kind of real. I mean, I haven't used\na map in 20 years.",
    "start": "1882980",
    "end": "1890970"
  },
  {
    "text": "I probably could barely find my\nway outside of my neighborhood anymore without a\nGPS, and so that's",
    "start": "1890970",
    "end": "1896270"
  },
  {
    "text": "real to how much\ndoes that impact me? Not maybe as much. Am I more efficient? Sure. So there's got to be some\nbalance here, but where that is,",
    "start": "1896270",
    "end": "1904198"
  },
  {
    "text": "I don't know. But I do agree though, to your\npoint that the medical education system, just like all\nthe rest of I would say,",
    "start": "1904198",
    "end": "1911190"
  },
  {
    "text": "the traditional education system\nis kind of staring into this and wondering, what does\nthis really mean for them?",
    "start": "1911190",
    "end": "1919019"
  },
  {
    "text": "JUSTIN NORTON: And with that\nsaid, there have been people-- people have been asking this\nquestion about medical education",
    "start": "1919020",
    "end": "1924800"
  },
  {
    "text": "for a long time. And I'll give a shout out\nto Dr. Charles Prober, who",
    "start": "1924800",
    "end": "1930200"
  },
  {
    "text": "flipped the classroom, did\na lot at Stanford and really across the nation. And we've had the\ninternet and ways",
    "start": "1930200",
    "end": "1936860"
  },
  {
    "text": "to get access to\nraw memorization. Let's have people apply this\ninformation through cases,",
    "start": "1936860",
    "end": "1943660"
  },
  {
    "text": "learn in the classroom\ntogether to do that. And so to me this is\njust a supercharging",
    "start": "1943660",
    "end": "1949050"
  },
  {
    "text": "of those concepts,\nwhich is let's get people more into real\nsimulated situations,",
    "start": "1949050",
    "end": "1954730"
  },
  {
    "text": "whether simulated with AI\nand use AI to advance it. It just kind of really\naccelerates that.",
    "start": "1954730",
    "end": "1962159"
  },
  {
    "text": "Maybe the one last topic\nto call out before we wrap is there was this\nbill proposed on AI",
    "start": "1962160",
    "end": "1970590"
  },
  {
    "text": "being allowed to prescribe. Matt, I'll start with you if\nyou wanted to go through this.",
    "start": "1970590",
    "end": "1978030"
  },
  {
    "text": "Walk us through what it\nwas and what you think is going to happen. MATTHEW LUNDGREN:\nWell, I mean, I think that-- so this\nisn't the first time,",
    "start": "1978030",
    "end": "1984540"
  },
  {
    "text": "but this one did\ncatch headlines. I think just given the kind of\ncurrent conversation around AI and health and all\nthese things that I",
    "start": "1984540",
    "end": "1990870"
  },
  {
    "text": "think are starting to\nbe more mainstream. But I guess the general\nthought is that a model,",
    "start": "1990870",
    "end": "1997440"
  },
  {
    "text": "it could legally\nprescribe a medication. And I don't know exactly\nhow you'd even really",
    "start": "1997440",
    "end": "2003620"
  },
  {
    "text": "implement that per se, just\ngiven how things would work. But I can imagine\na scenario where there's some confined scope\nof certain medications, where",
    "start": "2003620",
    "end": "2012590"
  },
  {
    "text": "almost like you're starting to\nsee with some of these apps that are willing and fairly, I\nguess, they kind of loosen",
    "start": "2012590",
    "end": "2019940"
  },
  {
    "text": "the rules in terms\nof how deep you need to go with your medical\nhistory and your physician to actually get a\nmedication that's common.",
    "start": "2019940",
    "end": "2026130"
  },
  {
    "text": "But I think it's\nsomething to that effect. But now imagine you could have--\nyour app also has this ability",
    "start": "2026130",
    "end": "2031610"
  },
  {
    "text": "to then literally prescribe a\nmedication after interaction. Again, I don't see this\npassing, but I always",
    "start": "2031610",
    "end": "2038780"
  },
  {
    "text": "look for these kinds\nof signals that are like that what Ethan\ncalls the jagged edge,",
    "start": "2038780",
    "end": "2043830"
  },
  {
    "text": "the jagged frontier of where\nthe capabilities are starting to meet some real\nworld impact that",
    "start": "2043830",
    "end": "2050434"
  },
  {
    "text": "has pretty big ramifications\nif we let it continue.",
    "start": "2050434",
    "end": "2056840"
  },
  {
    "text": "GRAHAM WALKER: I do think the\nregulations that require--",
    "start": "2056840",
    "end": "2061919"
  },
  {
    "text": "I mean, just getting\nback to I mean, the same traditions\nof medical education are the same legacies\nof medical licensure.",
    "start": "2061920",
    "end": "2069340"
  },
  {
    "text": "I mean, the fact that we all\nneed a California license. And if we drive to Nevada,\nwe need a Nevada license.",
    "start": "2069340",
    "end": "2076260"
  },
  {
    "text": "I think those structures\nare starting to break down. I would love to have a\nhospital be able to prescribe.",
    "start": "2076260",
    "end": "2083219"
  },
  {
    "text": "Have a hospital owning the risk. And yeah, if the hospital\nwants to use an AI to do that,",
    "start": "2083219",
    "end": "2089888"
  },
  {
    "text": "give the hospital a license\nto prescribe medicines or to dispense\nmedicines or something.",
    "start": "2089889",
    "end": "2095649"
  },
  {
    "text": "And I agree,\nMatthew, if you look at many of the telehealth\nproviders, what",
    "start": "2095650",
    "end": "2102960"
  },
  {
    "text": "are those prescribers doing? They are as fast as possible\nclicking boxes that have already",
    "start": "2102960",
    "end": "2109200"
  },
  {
    "text": "been evaluated and checked by\nthe patient, which then have routed through an algorithm\nto say this person",
    "start": "2109200",
    "end": "2115800"
  },
  {
    "text": "is appropriate to receive\nPrilosec or something. I mean, and then they're\nwriting a prescription",
    "start": "2115800",
    "end": "2121030"
  },
  {
    "text": "and then they're charging their\ninsurance a bunch of money for it, and then they're\nfilling the prescription. How much labor is the\nhuman doing in that piece?",
    "start": "2121030",
    "end": "2128510"
  },
  {
    "text": "Not much. Often those medicines\nare over the counter, and so it's a little bit\nof a shell game anyway.",
    "start": "2128510",
    "end": "2135260"
  },
  {
    "text": "I don't support AI\nprescribing anytime soon, but when you start to-- again,\nlooking at the whole picture,",
    "start": "2135260",
    "end": "2141200"
  },
  {
    "text": "when you start to compare it to\nwhat we're allowing companies to make billions of dollars\ndoing for prescribers that",
    "start": "2141200",
    "end": "2148660"
  },
  {
    "text": "are sitting at home,\nhow different is that? I don't know.",
    "start": "2148660",
    "end": "2154240"
  },
  {
    "text": "JUSTIN NORTON: Well said. Well, anyway, with that\nvery optimistic note--",
    "start": "2154240",
    "end": "2160533"
  },
  {
    "text": "GRAHAM WALKER: Always. That's all you get\nfor me is optimism. JUSTIN NORTON: Well, we'll wrap\nit there, but thank you so much",
    "start": "2160533",
    "end": "2167380"
  },
  {
    "text": "Graham for joining us. We'll have to have you\nback soon as we're all trying to figure out\nwhat's going to happen next",
    "start": "2167380",
    "end": "2173050"
  },
  {
    "text": "with health and AI. GRAHAM WALKER: Anytime. Thanks for having me, guys. MATTHEW LUNDGREN:\nThanks, Graham. ",
    "start": "2173050",
    "end": "2178000"
  }
]
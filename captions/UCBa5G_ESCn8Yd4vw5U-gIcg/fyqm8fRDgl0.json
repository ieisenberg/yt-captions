[
  {
    "start": "0",
    "end": "20000"
  },
  {
    "text": "[NOISE] Okay everyone, let's get started for today.",
    "start": "0",
    "end": "10650"
  },
  {
    "text": "Okay. So, we're into week five of CS224n. And so, this is the plan for today.",
    "start": "10650",
    "end": "18450"
  },
  {
    "text": "Um, in some sense a lot of this class is gonna be an easy class because I'm gonna talk about things like,",
    "start": "18450",
    "end": "26955"
  },
  {
    "start": "20000",
    "end": "218000"
  },
  {
    "text": "um, final projects and tips for what you're meant to do, and finding a topic,",
    "start": "26955",
    "end": "32099"
  },
  {
    "text": "and writing up your work, and things like that. Um, so for, um, so, two-thirds of the class there isn't a lot of,",
    "start": "32100",
    "end": "39135"
  },
  {
    "text": "um, deep technical content. But I hope they're actually just some useful stuff and stuff that would be good to know about.",
    "start": "39135",
    "end": "46610"
  },
  {
    "text": "One way you can think about this is until, until this year we had a midterm in this class.",
    "start": "46610",
    "end": "53090"
  },
  {
    "text": "So, you know, if we weren't doing this class should instead be doing the the mid-term based on all the material that we've covered, um, so far.",
    "start": "53090",
    "end": "60740"
  },
  {
    "text": "So, this should be really pleasant by comparison. Um, but that isn't gonna be quite the entire class.",
    "start": "60740",
    "end": "66650"
  },
  {
    "text": "So, for this piece here in the middle I'm gonna spend a while back on some of the topics of last week.",
    "start": "66650",
    "end": "73909"
  },
  {
    "text": "So, I wanted to have one more look at some of these gated recurrent models,",
    "start": "73910",
    "end": "79415"
  },
  {
    "text": "um, that Abby introduced last week. And I guess my hope is that now that you've had a bit more time to look and read about things,",
    "start": "79415",
    "end": "86780"
  },
  {
    "text": "and hopefully even have started working on homework for that. Maybe it starts to make a bit more sense or else even if it's more confusing then before,",
    "start": "86780",
    "end": "96799"
  },
  {
    "text": "you've got some idea of what your confusions are and questions. And so, hopefully it's, um,",
    "start": "96800",
    "end": "101840"
  },
  {
    "text": "good to think about those one more time because I think they are quite a complex notion,",
    "start": "101840",
    "end": "107715"
  },
  {
    "text": "and it's not so obvious what they're doing and why they're doing anything useful, or whether they're just this big complex blob of mystery.",
    "start": "107715",
    "end": "115085"
  },
  {
    "text": "And then also to touch on a couple of machine translation topics that have um, come up in the final project that we didn't really get m- time to say much about last week.",
    "start": "115085",
    "end": "123300"
  },
  {
    "text": "[NOISE] Okay. So, let's get started. Um, so, this is our coursework in grading that we showed at the beginning.",
    "start": "123300",
    "end": "132515"
  },
  {
    "text": "And so, the main thing I wanna do today is talk about this final project. Um, but before tha- I do that,",
    "start": "132515",
    "end": "138620"
  },
  {
    "text": "let's just save one minute on participation. Um, so, I guess we started into one aspect of the participation policy, um,",
    "start": "138620",
    "end": "147350"
  },
  {
    "text": "last Thursday when we took attendance, and that makes it sound draconian, but I wanted to say, um,",
    "start": "147350",
    "end": "153215"
  },
  {
    "text": "the positive viewpoint of, um, the participation points. I mean, obviously this is a big class.",
    "start": "153215",
    "end": "158840"
  },
  {
    "text": "There are lots of people. Um, our hope is just that people will variously,",
    "start": "158840",
    "end": "164090"
  },
  {
    "text": "they're sort of engaged and involved in the class, and the participation points,",
    "start": "164090",
    "end": "169580"
  },
  {
    "text": "ah, are our way of doing that. I mean, basically the way this is set up. I mean, if you do much of anything",
    "start": "169580",
    "end": "177005"
  },
  {
    "text": "you should just get three percent for the participation points. It shouldn't be hard. I mean, I will bet you that there will be some people who at the end,",
    "start": "177005",
    "end": "185730"
  },
  {
    "text": "will have gotten seven points in the participation category. And unfortunately we cap you, we'll only give you",
    "start": "185730",
    "end": "191420"
  },
  {
    "text": "three percent for the participation category, but you know, providing you usually come to class,",
    "start": "191420",
    "end": "197450"
  },
  {
    "text": "or usually write the, um, what we've got to [NOISE] the invited speakers the reaction paragraphs if you are an SCPD student.",
    "start": "197450",
    "end": "205220"
  },
  {
    "text": "Sometimes, um, write a helpful answer on Piazza, right. You're already gonna be there on three percent.",
    "start": "205220",
    "end": "211895"
  },
  {
    "text": "Um, yeah. And so, one, but one other thing, um, that's a way to get some parti- participation points that's out today.",
    "start": "211895",
    "end": "219905"
  },
  {
    "start": "218000",
    "end": "249000"
  },
  {
    "text": "So, um, today we're putting up our Mid-quarter feedback survey. And we'd love to have you fill that in.",
    "start": "219905",
    "end": "226280"
  },
  {
    "text": "I mean, we'd like to get your thoughts on the course so far. And, you know, for you guys,",
    "start": "226280",
    "end": "231720"
  },
  {
    "text": "there are two ways that you can win. First if you give us some feedback that can help the rest of your quarter be better,",
    "start": "231720",
    "end": "237500"
  },
  {
    "text": "but we've also got a simple bribe built into this, um, which is you get half a participation point simply for filling in,",
    "start": "237500",
    "end": "244640"
  },
  {
    "text": "um, the, um, Mid-quarter survey, but it'd be really good to get your feedback on that. Okay. So, then the main thing I want to get to",
    "start": "244640",
    "end": "251780"
  },
  {
    "start": "249000",
    "end": "259000"
  },
  {
    "text": "today is to talk about [NOISE] the final project. Okay. And so, I'll jump right ahead, um, into that.",
    "start": "251780",
    "end": "259410"
  },
  {
    "start": "259000",
    "end": "648000"
  },
  {
    "text": "So, for the final project there are two choices. Um, you, you can either do our default final project,",
    "start": "259410",
    "end": "266599"
  },
  {
    "text": "which I'll say a little bit about, it's doing SQuAD question answering, or you can propose a final,",
    "start": "266599",
    "end": "272675"
  },
  {
    "text": "a custom final project, which we then have to approve. And in the course of that,",
    "start": "272675",
    "end": "277835"
  },
  {
    "text": "um, if you have some outside mentor, um, you can say who they are and your project proposal,",
    "start": "277835",
    "end": "283840"
  },
  {
    "text": "but otherwise, um, we'll attempt to assign you a mentor somewhere out of the course staff.",
    "start": "283840",
    "end": "289150"
  },
  {
    "text": "Um, so, for all the assignments, through assignments one through five, you have to do them by yourself.",
    "start": "289150",
    "end": "295495"
  },
  {
    "text": "Um, for the final project in either form of that, you can do it as a team.",
    "start": "295495",
    "end": "300905"
  },
  {
    "text": "So, you can do it as one, two, or three people. And how does that work?",
    "start": "300905",
    "end": "306514"
  },
  {
    "text": "Um, well, it works like this, um, if you're a bigger team,",
    "start": "306515",
    "end": "312410"
  },
  {
    "text": "we do expect you to do more, and there are actually two ways you can be a bigger team that I'll point out.",
    "start": "312410",
    "end": "317825"
  },
  {
    "text": "One way is having more people being two or three people. And the other thing that comes up is, um,",
    "start": "317825",
    "end": "323750"
  },
  {
    "text": "sometimes people wanna do a final project for more than one class at the same time. In particular for this quarter I know there are",
    "start": "323750",
    "end": "330050"
  },
  {
    "text": "at least a couple of people who are hoping to do, um, a joint project with Emma's reinforcement learning class.",
    "start": "330050",
    "end": "337065"
  },
  {
    "text": "And we allow that as well. But we sort of do multiplication because if you're two people using it for two classes,",
    "start": "337065",
    "end": "343490"
  },
  {
    "text": "that means it should be four times as great as what one person is doing for one class, right?",
    "start": "343490",
    "end": "350390"
  },
  {
    "text": "So, how, how it works with larger teams, you know, in all honesty it's a little bit subtle because, you know,",
    "start": "350390",
    "end": "359510"
  },
  {
    "text": "the truth is if something is just bad, um, your model was broken, um,",
    "start": "359510",
    "end": "365495"
  },
  {
    "text": "or you, your experiment failed, um, and you don't know why. Um, you know. If, if there's just obvious ways in what you've done as bad as it's sort of,",
    "start": "365495",
    "end": "376040"
  },
  {
    "text": "it's sort of bad whether you're one person or four person. Um, and if you've written it up beautifully,",
    "start": "376040",
    "end": "381860"
  },
  {
    "text": "you've written up beautifully regardless of whether you're one person or four per- people, that you know nevertheless the expectation is that if you're one person will be pleased,",
    "start": "381860",
    "end": "392000"
  },
  {
    "text": "that if you put together one model and gotten it to work well, um, but if you're three people will say, \"Well,",
    "start": "392000",
    "end": "398789"
  },
  {
    "text": "that wasn't such a big effort, um, running this one model against this task.\" Surely if there are three people,",
    "start": "398790",
    "end": "405315"
  },
  {
    "text": "they could have investigated some other model classes and seeing whether they perform better or worse on this task.",
    "start": "405315",
    "end": "411515"
  },
  {
    "text": "And we'll feel a sense of lightweight. So, we are expecting that sort of both more ambitious projects,",
    "start": "411515",
    "end": "418175"
  },
  {
    "text": "and more thorough exploration of them if you're being a bigger team or you're using it for multiple classes.",
    "start": "418175",
    "end": "424735"
  },
  {
    "text": "Um, for the final project, you are allowed to use any language or deep learning, um, framework that you choose to.",
    "start": "424735",
    "end": "431960"
  },
  {
    "text": "We don't insist on what you use, though in practice in past years. Basically everyone keeps on using what they've learned,",
    "start": "431960",
    "end": "438725"
  },
  {
    "text": "um, in the assignments. I expect that will be true, um, this time as well. [NOISE]",
    "start": "438725",
    "end": "444030"
  },
  {
    "text": "Okay. So, um, let me just mention quickly the default final project,",
    "start": "444030",
    "end": "449880"
  },
  {
    "text": "so that you've got, um, some sense of context. So, the materials of that will be released this Thursday.",
    "start": "449880",
    "end": "456375"
  },
  {
    "text": "And so, for the tasks for it is, a textural question-answering task which is done over the,",
    "start": "456375",
    "end": "462090"
  },
  {
    "text": "the Stanford Question Answering Dataset, SQuAD, which was a dataset put together, um,",
    "start": "462090",
    "end": "467474"
  },
  {
    "text": "by Percy Liang and the department and the student . Um, so, we've used this as a default final project,",
    "start": "467475",
    "end": "475380"
  },
  {
    "text": "um, before but we're mixing up a couple of things this year. I mean, firstly, the starter code we're providing this year is in pytorch,",
    "start": "475380",
    "end": "483840"
  },
  {
    "text": "to fit in with what we've done to the rest of the class. But secondly, the SQuAD team,",
    "start": "483840",
    "end": "489764"
  },
  {
    "text": "released a new version of SQuAD, SQuAD 2.0 and we're going to use that for the class this year.",
    "start": "489765",
    "end": "495840"
  },
  {
    "text": "And the essential difference in SQuAD 2.0, is in SQuAD 1.1 or 1.0,",
    "start": "495840",
    "end": "501975"
  },
  {
    "text": "every question had an answer in the passage of text whereas in SQuAD 2.0,",
    "start": "501975",
    "end": "508065"
  },
  {
    "text": "a lot of questions don't have answers. So, there's this extra significant thing that you need to do which is working out,",
    "start": "508065",
    "end": "514770"
  },
  {
    "text": "um, whether a question has an answer. So, th- this is just one example, um, which just gives you a sense of the SQuAD,  what SQuAD is like.",
    "start": "514770",
    "end": "523430"
  },
  {
    "text": "So, there's a paragraph of text. I've just put a subset of it here, um, Bill Aken,",
    "start": "523430",
    "end": "528680"
  },
  {
    "text": "adopted by Mexican movie actress, Lupe Mayorga, um, grew up in the neighborhood town, neighboring, sorry,",
    "start": "528680",
    "end": "535290"
  },
  {
    "text": "neighboring town of Madeira and his song chronicled the hardships faced by the migrant farm workers he saw as a child.",
    "start": "535290",
    "end": "541649"
  },
  {
    "text": "Right, there's then a question, um, in what town did Bill, right, actually I misspelled that sorry,",
    "start": "541650",
    "end": "547650"
  },
  {
    "text": "it should have been Aken without an I. I got confused with our former department chair,",
    "start": "547650",
    "end": "553230"
  },
  {
    "text": "Alex Aiken, I guess when I was typing. Um, Bill Aken grow up? And the answer you are meant to give is Madeira.",
    "start": "553230",
    "end": "559920"
  },
  {
    "text": "Um, so, just incidentally, it's a random fact. Um, so, quite a few of you know about something that was",
    "start": "559920",
    "end": "568500"
  },
  {
    "text": "recently in the kind of tech news, tech news and we're going to talk about later in the class. Um, that people, um,",
    "start": "568500",
    "end": "574860"
  },
  {
    "text": "from Google produced this very strong New Natural Language Understanding representation model called BERT.",
    "start": "574860",
    "end": "582090"
  },
  {
    "text": "And which is one of several kind of models that are in a class of, models that contextually model words that have come into prominence in 2017 and 18.",
    "start": "582090",
    "end": "592650"
  },
  {
    "text": "And in general, BERT has sort of produced very good performance for very many tasks.",
    "start": "592650",
    "end": "598770"
  },
  {
    "text": "Indeed, if you look at the SQuAD 2.0 leader board online, um,",
    "start": "598770",
    "end": "603900"
  },
  {
    "text": "at this URL, what you'll find is that all of the leading systems use BERT in some way or another, these days.",
    "start": "603900",
    "end": "611625"
  },
  {
    "text": "Um, but nevertheless, this was actually a question that BERT got wrong. Um, that BERT said, \"No answer to this question,",
    "start": "611625",
    "end": "618000"
  },
  {
    "text": "\" rather than getting the correct answer. Even though it looks kind of straightforward reading it as a human being.",
    "start": "618000",
    "end": "623070"
  },
  {
    "text": "It doesn't really look a human tricky reading comprehension question. Um, so, that's the default final project.",
    "start": "623070",
    "end": "630390"
  },
  {
    "text": "So, on Thursday, I'm going to talk more about the default final project. I'm going to talk about how people build textual question answering systems.",
    "start": "630390",
    "end": "639255"
  },
  {
    "text": "And the details on the default final project should all be posted by then, but that's just to give you a bit of context of what the other choice is.",
    "start": "639255",
    "end": "647220"
  },
  {
    "text": "And today, I'm sort of more going to be aiming at people, um, doing the custom final project.",
    "start": "647220",
    "end": "654180"
  },
  {
    "start": "648000",
    "end": "795000"
  },
  {
    "text": "But let me just sort of say a bit first about the choice between the two of them. So, um, why might you want to choose the default final project?",
    "start": "654180",
    "end": "662940"
  },
  {
    "text": "So, if you have limited experience with research, you don't have any clear idea of a research project you want to do this quarter,",
    "start": "662940",
    "end": "672180"
  },
  {
    "text": "you're just really busy with other classes that, uh, you're enrolled in CS140 and you're just really loade- loaded",
    "start": "672180",
    "end": "677699"
  },
  {
    "text": "[LAUGHTER] now with other classes you're doing this quarter. Um, you'd be happy to have just a clear goal towards, to work towards.",
    "start": "677700",
    "end": "685890"
  },
  {
    "text": "A leaderboard of your fellow students that you can compete against. Um, do the default final project.",
    "start": "685890",
    "end": "691890"
  },
  {
    "text": "Um, I think for many people it's actually the good right choice. And I mean, for what it's worth, I mean,",
    "start": "691890",
    "end": "698670"
  },
  {
    "text": "typically, slightly over half of people have done the default final project. It's normally that, so 55 percent have done",
    "start": "698670",
    "end": "705170"
  },
  {
    "text": "the default final project and the rest the custom final project. So, if you do the default final project,",
    "start": "705170",
    "end": "711140"
  },
  {
    "text": "you'll get lots of guidance. You get lots of scaffolding. There are clear things to aim at in what you do.",
    "start": "711140",
    "end": "718355"
  },
  {
    "text": "Um, the course staff are in general most prepared and most able to help you.",
    "start": "718355",
    "end": "724014"
  },
  {
    "text": "Um, and in particular, I mean, the, for the bottom bullet here. I mean, you know, something to think about in making",
    "start": "724015",
    "end": "731510"
  },
  {
    "text": "the choices that some of it comes down to how committed, organized, and keen are you to be wanting to do your own custom final project.",
    "start": "731510",
    "end": "741320"
  },
  {
    "text": "If you've got a, something you really want to do for a custom final project, great. We love to see interesting custom final projects.",
    "start": "741320",
    "end": "748270"
  },
  {
    "text": "But, you know, if you're going to end up doing something that just looks worse like [LAUGHTER] not done as well [LAUGHTER] as you would've done a, done a project.",
    "start": "748270",
    "end": "759150"
  },
  {
    "text": "If you'd just done the fin-, default final project, then you should probably choose the default final project [LAUGHTER].",
    "start": "759150",
    "end": "765090"
  },
  {
    "text": "Um, okay. But even if you are doing, think you'll do the default final project.",
    "start": "765090",
    "end": "771125"
  },
  {
    "text": "I hope that some of this lecture will still, um, be useful. While the part in the middle, when I talk back about",
    "start": "771125",
    "end": "776660"
  },
  {
    "text": "MT and Gater or current networks are definitely useful. But, you know, beyond that, um,",
    "start": "776660",
    "end": "781670"
  },
  {
    "text": "some of the tips on doing research and discussions of, sort of looking at how to make neural networks work and error analysis, paper writing.",
    "start": "781670",
    "end": "790230"
  },
  {
    "text": "These are all good topics that apply to the default final project as well. So, in the other direction, um,",
    "start": "790230",
    "end": "796770"
  },
  {
    "start": "795000",
    "end": "934000"
  },
  {
    "text": "if you have some research project that you're excited about. Possibly, it's one you are already working on or possibly,",
    "start": "796770",
    "end": "802589"
  },
  {
    "text": "that you've just always wished to do. Something exciting with neural networks and rap music.",
    "start": "802590",
    "end": "807690"
  },
  {
    "text": "Um, well, you know, that custom final project is an opportunity to do that. Um, so, it's a chance for you to do something on your own.",
    "start": "807690",
    "end": "815550"
  },
  {
    "text": "Um, it, you know, obviously, if you're not interested in textural question-answering but do you think you might like machine translation.",
    "start": "815550",
    "end": "822150"
  },
  {
    "text": "Well, it's an opportunity, um, to choose any topic of your own. It's also a way to sort of experience much more of the research pro- process because,",
    "start": "822150",
    "end": "832590"
  },
  {
    "text": "you know, for the default final project, it's a bigger, more open-ended thing than any of our assignments.",
    "start": "832590",
    "end": "838545"
  },
  {
    "text": "But, you know, nevertheless, the default final project is still sort of a pre-setup thing that you don't have to find your own problem,",
    "start": "838545",
    "end": "845790"
  },
  {
    "text": "find your own data, work out a good approach to it. A lot of that's sort of been done for you.",
    "start": "845790",
    "end": "850980"
  },
  {
    "text": "So, that, for a custom final project it's much more your own job to sort of define and execute a mini research project.",
    "start": "850980",
    "end": "858900"
  },
  {
    "text": "And so, if all of that stuff seems appealing or some of it seems appealing, um, then aim at the custom final project.",
    "start": "858900",
    "end": "864975"
  },
  {
    "text": "Um, doing this just reminded me about a fact about assignments one to five.",
    "start": "864975",
    "end": "870045"
  },
  {
    "text": "You know, for assignments one to five, we are hoping that they can be a set of stepping",
    "start": "870045",
    "end": "876090"
  },
  {
    "text": "stones for learning how to build deep learning systems. But, you know, one of our goals in that is to give you less hand holds as time goes by.",
    "start": "876090",
    "end": "887310"
  },
  {
    "text": "So, you know, assignment one was really easy and assignment three, we tried to make it really handholdy,",
    "start": "887310",
    "end": "893880"
  },
  {
    "text": "so people could start to learn PyTorch. But, you know, we're actually hoping for assignments",
    "start": "893880",
    "end": "899280"
  },
  {
    "text": "four and five that they're actually harder, so that you're getting more experience of working",
    "start": "899280",
    "end": "904850"
  },
  {
    "text": "out how to build and do things by yourself because if the only thing you ever see is completely scaffolded assignments.",
    "start": "904850",
    "end": "912830"
  },
  {
    "text": "It's sort of like when you do CS106A that you have to do a great job on the CS106A assignments but you don't really know how to write a program by yourselves.",
    "start": "912830",
    "end": "921980"
  },
  {
    "text": "And that's sort of what we want to, um, sort of get you beyond, um, in the latter two assignments.",
    "start": "921980",
    "end": "927050"
  },
  {
    "text": "So, I hope you have started on assignment four. If not, you really should start and get underway soon as Abby was emphasizing.",
    "start": "927050",
    "end": "934885"
  },
  {
    "start": "934000",
    "end": "1042000"
  },
  {
    "text": "Okay. So, this year for the, um, final project, whichever one you're doing.",
    "start": "934885",
    "end": "940935"
  },
  {
    "text": "Um, we're actually putting more structure in than we have in previous years to encourage people to get going.",
    "start": "940935",
    "end": "946730"
  },
  {
    "text": "And so, in particular, there are early on components which are worth points in the grading.",
    "start": "946730",
    "end": "952190"
  },
  {
    "text": "So, the first part of that is a project proposal, um, which is, um,",
    "start": "952190",
    "end": "957410"
  },
  {
    "text": "we want from each team. So, one per team, um, you can just do a joint one,",
    "start": "957410",
    "end": "962670"
  },
  {
    "text": "um, which is worth five percent. Um, so, it's, we're releasing the details on Thursday which is when",
    "start": "962670",
    "end": "968300"
  },
  {
    "text": "assignment four is due and it'll be due the following Thursday. So, we're actually having an interruption in the sequence of current assignments, right.",
    "start": "968300",
    "end": "976430"
  },
  {
    "text": "So, for the next week, um, what the thing to do is project proposal.",
    "start": "976430",
    "end": "982805"
  },
  {
    "text": "And then the week after that, um, we're back to assignment five and then we go full time into final project.",
    "start": "982805",
    "end": "989080"
  },
  {
    "text": "So, what we're wanting for the project proposal is we're actually wanting you to do a little bit",
    "start": "989080",
    "end": "994250"
  },
  {
    "text": "of starting off research and the fine ter- terms of reading some paper.",
    "start": "994250",
    "end": "999470"
  },
  {
    "text": "So, find some paper that's, um, relevant to your research, um, that you are going to do.",
    "start": "999470",
    "end": "1005545"
  },
  {
    "text": "Um, read it, write a summary of what it does. Um, write down some thoughts on how you could adapt or extend ideas in it,",
    "start": "1005545",
    "end": "1014275"
  },
  {
    "text": "in your own final project. Um, and then say something about what your plan is for",
    "start": "1014275",
    "end": "1019810"
  },
  {
    "text": "what you're goi- hoping to do for your final project. And especially, if you're doing a custom final project",
    "start": "1019810",
    "end": "1025660"
  },
  {
    "text": "there's more to write there because we'll want to make sure that you have some idea as to what data you can use and how are you going to evaluate it.",
    "start": "1025660",
    "end": "1033360"
  },
  {
    "text": "Whereas a couple of those things are actually sort of determined for you if you're doing the default final project.",
    "start": "1033360",
    "end": "1040250"
  },
  {
    "text": "Um, and so then after that we're going to have a project milestone, um,",
    "start": "1040430",
    "end": "1045540"
  },
  {
    "start": "1042000",
    "end": "1095000"
  },
  {
    "text": "which is the progress report where we're hoping that you can report that you're well along in your final project.",
    "start": "1045540",
    "end": "1051300"
  },
  {
    "text": "That you've run at least some experiment and have some results on some data that you can talk about.",
    "start": "1051300",
    "end": "1057075"
  },
  {
    "text": "So the default- the project milestone is due on, um, Thursday, March seven. So it's actually more than halfway through",
    "start": "1057075",
    "end": "1065010"
  },
  {
    "text": "the period that's sort of dedicated to the final project. So, if you are not- we sort of put it past",
    "start": "1065010",
    "end": "1071220"
  },
  {
    "text": "halfway because the fact of the matter is it always takes people time to get going, um, but nevertheless, you know,",
    "start": "1071220",
    "end": "1076635"
  },
  {
    "text": "what you should have in your head is unless you're halfway through by the time you're handing in your,",
    "start": "1076635",
    "end": "1082440"
  },
  {
    "text": "um, project milestone, then you're definitely behind. And you'll be doing that typical Stanford thing of having a lot of late nights",
    "start": "1082440",
    "end": "1089910"
  },
  {
    "text": "and lack of sleep in the last week [LAUGHTER] of class trying to catch up for that. Um, okay. So, um,",
    "start": "1089910",
    "end": "1097485"
  },
  {
    "start": "1095000",
    "end": "1156000"
  },
  {
    "text": "so now I've sort of, um, want to sort of just start saying a bit of- for",
    "start": "1097485",
    "end": "1102900"
  },
  {
    "text": "custom final projects of some of the sort of thinking and types of things that you could do about that.",
    "start": "1102900",
    "end": "1108195"
  },
  {
    "text": "Um, so you have to determine some project, um, for- if you're doing a custom final project.",
    "start": "1108195",
    "end": "1115139"
  },
  {
    "text": "So, in philosophy of science, you know, there are basically two ways for any field you can have a project.",
    "start": "1115140",
    "end": "1120809"
  },
  {
    "text": "You either start with some domain problem of interest. You're [NOISE] just got something you're interested in or say,",
    "start": "1120810",
    "end": "1128460"
  },
  {
    "text": "\"Gee, I'd like to do better machine translation.\" And then you work out some ways to address it with technology,",
    "start": "1128460",
    "end": "1135225"
  },
  {
    "text": "or you start with some, um, technical approach of interest. And you say, \"Oh well,",
    "start": "1135225",
    "end": "1140549"
  },
  {
    "text": "those LSTMs seemed kind of neat, but I didn't understand why there's that extra 10H and I think it'd be better if it changed in this other way.",
    "start": "1140550",
    "end": "1148035"
  },
  {
    "text": "And you start exploring from a technical direction to try and come up with a better idea.",
    "start": "1148035",
    "end": "1153570"
  },
  {
    "text": "And then you're wanting to prove that it works. So in kinds of the projects that people do for this class,",
    "start": "1153570",
    "end": "1160589"
  },
  {
    "start": "1156000",
    "end": "1845000"
  },
  {
    "text": "this isn't quite an exhaustive list, but this is sort of in general what people do. So, the first category and really I think this",
    "start": "1160589",
    "end": "1168510"
  },
  {
    "text": "is the bulk of projects over half is people find some task replication of interest and they build",
    "start": "1168510",
    "end": "1175649"
  },
  {
    "text": "some neural network models to try and do it as effectively as possible. Um, there's a second category where people sort of concentrate on implementing,",
    "start": "1175650",
    "end": "1187020"
  },
  {
    "text": "so re-implementing some complex neural architecture and getting it to work on some data.",
    "start": "1187020",
    "end": "1193575"
  },
  {
    "text": "And so let me just say a couple of sentences on this. Um, so, it's certainly okay for you to,",
    "start": "1193575",
    "end": "1201525"
  },
  {
    "text": "um, start by re-implementing some existing model. Um, and some people that's as far as they get.",
    "start": "1201525",
    "end": "1210975"
  },
  {
    "text": "And then the question is, um, is that okay? And the answer to whether that's okay sort",
    "start": "1210975",
    "end": "1217650"
  },
  {
    "text": "of largely depends on how complex your neural model is. Um, so if what you think is okay I'm going to, um,",
    "start": "1217650",
    "end": "1228060"
  },
  {
    "text": "re-implement something like we've seen already, like a window-based classification model and you",
    "start": "1228060",
    "end": "1234600"
  },
  {
    "text": "just re-implement that and run it on some data and get some results and stop. That's definitely a bad project.",
    "start": "1234600",
    "end": "1240360"
  },
  {
    "text": "Um, but there are lots of very complicated and sophisticated neural, um, architectures out there.",
    "start": "1240360",
    "end": "1247065"
  },
  {
    "text": "And if you're trying to do something complicated well then that can be a fine project. Um, so, I actually sort of stuck in a few examples of projects.",
    "start": "1247065",
    "end": "1255840"
  },
  {
    "text": "So, I mean, here's one that was actually from a couple of years ago. Um, so this was in the 2017 class.",
    "start": "1255840",
    "end": "1263535"
  },
  {
    "text": "And so, shortly before the 2017 class, \"Deep Mind\" who's one of the um, organizations producing",
    "start": "1263535",
    "end": "1271230"
  },
  {
    "text": "the most complicated neural models had just released a paper about the differentiable neural computer model,",
    "start": "1271230",
    "end": "1277890"
  },
  {
    "text": "which was a model of how to have something like a differentiate- differentiable Turing machine-like",
    "start": "1277890",
    "end": "1283109"
  },
  {
    "text": "architecture inside a neural network, um, and  thought, um,",
    "start": "1283109",
    "end": "1289050"
  },
  {
    "text": "this would be a great challenge to try and, um, re-implement the differentiable neural computer which Deep Mind hadn't released",
    "start": "1289050",
    "end": "1296970"
  },
  {
    "text": "any source code for because they're not the kind of place that generally releases their source code. Um, and, you know, this was actually an extremely ambitious project because it",
    "start": "1296970",
    "end": "1306420"
  },
  {
    "text": "was, it's a very complex architecture which is hard to get to train.",
    "start": "1306420",
    "end": "1311835"
  },
  {
    "text": "And so, you know, at the end, at the end she hadn't been able to sort of train as",
    "start": "1311835",
    "end": "1318180"
  },
  {
    "text": "big a model or get as good results as they report in the paper that, you know, frankly we thought it was pretty",
    "start": "1318180",
    "end": "1324030"
  },
  {
    "text": "miraculous that she managed to get it working at all. In the period of time we had in the class and she did successfully do an open-source",
    "start": "1324030",
    "end": "1331920"
  },
  {
    "text": "re-implementation of this model which basically worked the same as in their paper. Though not quite as well.",
    "start": "1331920",
    "end": "1337770"
  },
  {
    "text": "So, you know, that seemed a huge achievement. So, you certainly can do something of that sort.",
    "start": "1337770",
    "end": "1343905"
  },
  {
    "text": "Right. So, um, so you- you can sort of from a technical direction have some ideas for variant model and explore,",
    "start": "1343905",
    "end": "1352845"
  },
  {
    "text": "um, how to make a different kind of model class and then look at how it works on some problem that works well.",
    "start": "1352845",
    "end": "1359065"
  },
  {
    "text": "Another kind of project you can do is an analysis project, so that you might be interested in something in",
    "start": "1359065",
    "end": "1365690"
  },
  {
    "text": "natural language or something on the behavior of neural networks, and just think that you want to analyze them more closely.",
    "start": "1365690",
    "end": "1372740"
  },
  {
    "text": "So, you might think, \"Oh, maybe these neural machine translation systems work great",
    "start": "1372740",
    "end": "1378230"
  },
  {
    "text": "providing the word order is the same in the source and target language, but can they really do a good job of reordering phrases for different language types?",
    "start": "1378230",
    "end": "1387180"
  },
  {
    "text": "How much does their performance vary based on the amount of reordering between the source and target language?\"",
    "start": "1387180",
    "end": "1392625"
  },
  {
    "text": "And you could do some experiments to try and investigate that as an analysis problem that looks at a model,",
    "start": "1392625",
    "end": "1398610"
  },
  {
    "text": "and we sometimes get projects like that. Down at the bottom is the rarest kind of project,",
    "start": "1398610",
    "end": "1404040"
  },
  {
    "text": "which is when some people try to do something theoretical which is to prove some properties of a system.",
    "start": "1404040",
    "end": "1410625"
  },
  {
    "text": "So if- this is easiest to do in simple systems for something like word vectors, that if you might want to prove something about",
    "start": "1410625",
    "end": "1419130"
  },
  {
    "text": "the kind of spaces that are induced by word vectors, and what properties you need to have in",
    "start": "1419130",
    "end": "1425490"
  },
  {
    "text": "models for word analogies to work or something like that. Um here are just another couple of examples that so- shows some of the other classes.",
    "start": "1425490",
    "end": "1433995"
  },
  {
    "text": "So, this one is an example of find a problem and build some models. So, these three people um, looked at Shakespearean Sonnet generation and then they considered",
    "start": "1433995",
    "end": "1444149"
  },
  {
    "text": "several different models for Shakespearean Sonnet generation and got the best results from this sort of- you'd probably can't really see all the details,",
    "start": "1444150",
    "end": "1451770"
  },
  {
    "text": "but they have a sort of a mixture of word level and character level gated model that feeds into",
    "start": "1451770",
    "end": "1458399"
  },
  {
    "text": "a word level LSTM and produces sonnets and the output wasn't totally bad. \"Thy youth's time and face his form shall cover.",
    "start": "1458400",
    "end": "1466305"
  },
  {
    "text": "Now all fresh beauty my love there. Will ever time to greet forget each like ever decease,",
    "start": "1466305",
    "end": "1472290"
  },
  {
    "text": "but in a- in a best at worship his glory die.\" Okay. It's maybe not perfect,",
    "start": "1472290",
    "end": "1477779"
  },
  {
    "text": "[LAUGHTER] but it sort of sounds like a Shakespearean sonnet. Um, okay.",
    "start": "1477780",
    "end": "1484159"
  },
  {
    "text": "Yeah. So, I showed you that one already. Um, here's, um, an example of someone who designed a different kind of network,",
    "start": "1484160",
    "end": "1494215"
  },
  {
    "text": "and this was a project that came out of this class that was then continued with, and the- they got a conference paper out of it,",
    "start": "1494215",
    "end": "1501310"
  },
  {
    "text": "the ICLR 2017 paper. So, this was looking at doing a better job at building a neural language model.",
    "start": "1501310",
    "end": "1509440"
  },
  {
    "text": "And essentially, they had two ideas, both of which seem useful for building better neural language models.",
    "start": "1509440",
    "end": "1516429"
  },
  {
    "text": "And so, one is that in the stuff that we've presented so far, whether it was the early word vectors,",
    "start": "1516430",
    "end": "1522790"
  },
  {
    "text": "or what Abby presented last week in the neural language model, there are effectively two vectors for each word: there's one for the word encoding",
    "start": "1522790",
    "end": "1530440"
  },
  {
    "text": "on the input and then when you have the softmax on the other side effectively, the rows of that matrix that go into the softmax are also",
    "start": "1530440",
    "end": "1539500"
  },
  {
    "text": "word vectors for determining how likely you are to produce different words. And so, um, these two people had the idea that maybe if we actually in the model",
    "start": "1539500",
    "end": "1548710"
  },
  {
    "text": "tied those two word ve- vectors together that would help and produce a better model and,",
    "start": "1548710",
    "end": "1554950"
  },
  {
    "text": "um, and so this was actually done several years ago when that was a novel idea which hadn't actually been done.",
    "start": "1554950",
    "end": "1560860"
  },
  {
    "text": "So, this was done in the 2016 class, and then they had this second idea which was,",
    "start": "1560860",
    "end": "1566875"
  },
  {
    "text": "well maybe doing the kind of, cross entropy one, zero, sort of you look at the correct word that you are meant to",
    "start": "1566875",
    "end": "1574600"
  },
  {
    "text": "produce and sort of work out a loss based on that. Maybe that's not very good because you don't get",
    "start": "1574600",
    "end": "1581140"
  },
  {
    "text": "partial points if you produce a different word that's semantically similar. And so, that they had this idea that they could use",
    "start": "1581140",
    "end": "1588100"
  },
  {
    "text": "word vector similarity and then you'd be giving a score for any word that was",
    "start": "1588100",
    "end": "1593350"
  },
  {
    "text": "produced next based on how similar it was according to word vector similarity to the word that you are",
    "start": "1593350",
    "end": "1599470"
  },
  {
    "text": "meant to produce next and that was also a useful idea that they're able to produce improved language models with.",
    "start": "1599470",
    "end": "1605875"
  },
  {
    "text": "So, that was a cool project. Um, here's an example of, um, somebody from last year,",
    "start": "1605875",
    "end": "1612010"
  },
  {
    "text": "um, who did an analysis project. So, their idea was,",
    "start": "1612010",
    "end": "1617135"
  },
  {
    "text": "um, that they- well, they were going to, um, evaluate on some task,",
    "start": "1617135",
    "end": "1622345"
  },
  {
    "text": "they actually did several tasks, um, word similarity, analogy, and the SQuAD, um, question answering system.",
    "start": "1622345",
    "end": "1629215"
  },
  {
    "text": "But the question was, okay, a lot of neural network models are big and so aren't very suitable for phones, um,",
    "start": "1629215",
    "end": "1636235"
  },
  {
    "text": "could we get away with compressing the models a lot so that rather than having doubles,",
    "start": "1636235",
    "end": "1641950"
  },
  {
    "text": "or 32-bit floats, or even 16-bit floats, that are now used quite a bit in neural networks, could we,",
    "start": "1641950",
    "end": "1648595"
  },
  {
    "text": "um, compress a lot more and quantize, um, numeric values so that we can only be, say,",
    "start": "1648595",
    "end": "1655450"
  },
  {
    "text": "using two bits fo- per parameter so they'll literally need four bits per parameter? And if you do that naively, it doesn't work.",
    "start": "1655450",
    "end": "1662890"
  },
  {
    "text": "But if you explore some cleverer ways of doing it and see how to make things work,",
    "start": "1662890",
    "end": "1668500"
  },
  {
    "text": "you can actually get it to work, um, really well. Um, in fact, it actually seems like sometimes you can improve",
    "start": "1668500",
    "end": "1674679"
  },
  {
    "text": "your performance doing this because the quantization acts as a form of regularizer. Um, you can find lots of other projects, um, online,",
    "start": "1674680",
    "end": "1683290"
  },
  {
    "text": "if you look at the CS224n pages and you should. Um, okay.",
    "start": "1683290",
    "end": "1688990"
  },
  {
    "text": "So, if you want to do a final project you have to find someplace to start. You know, one place is to start looking at papers there's",
    "start": "1688990",
    "end": "1695950"
  },
  {
    "text": "online anthology of most of the NLP conference papers. You can look at M- ML conferences have lots of relevant papers as well.",
    "start": "1695950",
    "end": "1703690"
  },
  {
    "text": "You can look at past CS224n papers that cover lots of topics.",
    "start": "1703690",
    "end": "1708715"
  },
  {
    "text": "Um, though, you know, I- I sugge- don't also forget, um, the advice down the bottom, um,",
    "start": "1708715",
    "end": "1716184"
  },
  {
    "text": "which is look for an interesting problem in the world. Um, so, our Stanford's CS emeritus professor",
    "start": "1716185",
    "end": "1723669"
  },
  {
    "text": "Ed Feigenbaum likes to quote the advice of his, um, advisor, Herb Simon, um,",
    "start": "1723670",
    "end": "1730465"
  },
  {
    "text": "of \"If you see a research area where many people are working, go somewhere else.\"",
    "start": "1730465",
    "end": "1735654"
  },
  {
    "text": "Um, well, you know, in the context of this class don't go so far away that you're not using",
    "start": "1735655",
    "end": "1741115"
  },
  {
    "text": "neural networks or NLP because that won't work for project for this class. But, you know, nevertheless, I mean,",
    "start": "1741115",
    "end": "1748090"
  },
  {
    "text": "in some sense it's a bad strategy of saying let's look at all the papers that were published last year, and let's wo- start working on one of their problems,",
    "start": "1748090",
    "end": "1755485"
  },
  {
    "text": "or lots of people are working on question-answering, I'll do it too. You know, there are lots of interesting different problems",
    "start": "1755485",
    "end": "1761695"
  },
  {
    "text": "in the world and if you know of some, you know, cool website that somehow does something interesting related to language,",
    "start": "1761695",
    "end": "1768340"
  },
  {
    "text": "you know, maybe you can make a final project out of that. Um, other ways to find final projects.",
    "start": "1768340",
    "end": "1774685"
  },
  {
    "text": "Um, so the person who's first put together most of the CS231n content was And- Andrej Karpathy, um,",
    "start": "1774685",
    "end": "1783220"
  },
  {
    "text": "who now works at Tesla and among his other- things he did for the world he put together this site Arxiv Sanity Preserver, um,",
    "start": "1783220",
    "end": "1790735"
  },
  {
    "text": "which is a way to find online archive papers which is a major pre-print server and if you say a few papers you're interested in,",
    "start": "1790735",
    "end": "1799000"
  },
  {
    "text": "it'll show you other papers that you're interested in. It'll show you papers that are currently trending. So, that can be a good way to look.",
    "start": "1799000",
    "end": "1805705"
  },
  {
    "text": "Um, if you think it'd be just good to be in some competition where you're wanting to build a system that's better than other people's,",
    "start": "1805705",
    "end": "1813205"
  },
  {
    "text": "um, you can look at leaderboards for various tasks. So, there's this brand new site which is pretty good though",
    "start": "1813205",
    "end": "1819160"
  },
  {
    "text": "not completely error free and correct, of paperswithcode.com, and it collects a whole lot of",
    "start": "1819160",
    "end": "1826120"
  },
  {
    "text": "leaderboards for a whole lot of machine learning tasks including tons of language ones.",
    "start": "1826120",
    "end": "1831190"
  },
  {
    "text": "So, it gives leaderboards for question answering, machine translation, named entity recognition, language modeling, part of speech tagging.",
    "start": "1831190",
    "end": "1838090"
  },
  {
    "text": "All sorts of tasks you can find there, and find out what the current states of the art and datasets are.",
    "start": "1838090",
    "end": "1844670"
  },
  {
    "text": "Okay. Um, so, you know, different projects are different,",
    "start": "1844920",
    "end": "1850299"
  },
  {
    "start": "1845000",
    "end": "1918000"
  },
  {
    "text": "but often for a lot of projects the things you need to be making sure of is that something that you can get a decent amount of data about so you can train a model.",
    "start": "1850300",
    "end": "1859210"
  },
  {
    "text": "It's a feasible task, it's not so enormous you can't possibly do it in four weeks. Um, you'll want to have some evaluation metric and",
    "start": "1859210",
    "end": "1868419"
  },
  {
    "text": "normally for deep learning you have to have- even if you hope to do some human evaluation, as well, you have to have some automatic evaluation metric.",
    "start": "1868420",
    "end": "1877105"
  },
  {
    "text": "Because unless there's just some code that you can run that gives you a score for how well you're doing,",
    "start": "1877105",
    "end": "1882415"
  },
  {
    "text": "then unless you have that, you just sort of can't do the deep learning trick of saying, \"Okay,",
    "start": "1882415",
    "end": "1887920"
  },
  {
    "text": "let's, um, do backpropagation to optimize our scores according to this metric.\"",
    "start": "1887920",
    "end": "1894040"
  },
  {
    "text": "And pretty much you'll want to do that to be able to do neural network optimization.",
    "start": "1894040",
    "end": "1899050"
  },
  {
    "text": "Um, and we do require that there is an important part of NLP in your class project.",
    "start": "1899050",
    "end": "1905020"
  },
  {
    "text": "I mean, it doesn't have to be only thing, you can be doing reinforcement learning as well, or you could do images to caption, say you're",
    "start": "1905020",
    "end": "1911380"
  },
  {
    "text": "doing joint vision and NLP, but there has to be NLP in it. Okay. Ah, last bit before I get back onto the content from last week.",
    "start": "1911380",
    "end": "1922345"
  },
  {
    "start": "1918000",
    "end": "2010000"
  },
  {
    "text": "Ah, so, something that you'll need to do is have data for your project.",
    "start": "1922345",
    "end": "1927605"
  },
  {
    "text": "Um, so some people collect their own data for a project and, you know, it's not impossible to collect your own data",
    "start": "1927605",
    "end": "1934700"
  },
  {
    "text": "especially if there's something you can do with unsupervised data. You might be able to get it by just sort of crawling an interesting website.",
    "start": "1934700",
    "end": "1941455"
  },
  {
    "text": "You can annotate a small amount of data yourself. If you have any site that has some kind of, you know,",
    "start": "1941455",
    "end": "1948665"
  },
  {
    "text": "ratings annotation stars on it, you can treat those as a form of, ah, annotation.",
    "start": "1948665",
    "end": "1956210"
  },
  {
    "text": "Right? So, if you want to predict something like, um, you know,",
    "start": "1956210",
    "end": "1961985"
  },
  {
    "text": "which descriptions on product review websites or which reviews on product review websites do people like?",
    "start": "1961985",
    "end": "1970230"
  },
  {
    "text": "Well, they get star ratings at the bottom from people and then you can try and fit to that as your supervision.",
    "start": "1970230",
    "end": "1976605"
  },
  {
    "text": "Um, sometimes people have data from an existing project for a company. You can use that.",
    "start": "1976605",
    "end": "1982630"
  },
  {
    "text": "But nevertheless for most people, um, given that classes are short and things like that,",
    "start": "1982630",
    "end": "1988130"
  },
  {
    "text": "the practical thing to do is use an existing curated dataset that's been built by previous researchers.",
    "start": "1988130",
    "end": "1995190"
  },
  {
    "text": "That normally gives you a fast start and lets you get to work building models, um, there's obvious prior work,",
    "start": "1995190",
    "end": "2001934"
  },
  {
    "text": "there are baselines and previous systems that you can compare your performance on, et cetera.",
    "start": "2001935",
    "end": "2008250"
  },
  {
    "text": "Okay. Um, so, where can you find data? I'll just mention a couple of places here and there are lots more.",
    "start": "2008250",
    "end": "2015145"
  },
  {
    "start": "2010000",
    "end": "2065000"
  },
  {
    "text": "So, traditionally the biggest source of linguistic data used by academics was this place called",
    "start": "2015145",
    "end": "2020539"
  },
  {
    "text": "the Linguistic Data Consortium and they have lots of datasets for treebanks and named entities and coreference,",
    "start": "2020540",
    "end": "2026960"
  },
  {
    "text": "parallel machine, translation data, et cetera, et cetera. And so, um, the Linguistic Data Consortium licenses their data,",
    "start": "2026960",
    "end": "2035310"
  },
  {
    "text": "Stanford pays that license so you can use any of it. Um, but if you want to use it, um,",
    "start": "2035310",
    "end": "2041500"
  },
  {
    "text": "you go to that, um, linguistics.stanford.edu page. And there's a sign-up, um, ah,",
    "start": "2041500",
    "end": "2048315"
  },
  {
    "text": "piece on how to sign up where you basically, um, say, \"I will use this data only for",
    "start": "2048315",
    "end": "2054200"
  },
  {
    "text": "good Stanford purposes and not as the basis of my startup.\" And, um, then you can have access to that data",
    "start": "2054200",
    "end": "2061075"
  },
  {
    "text": "and it can be made available by NFS or otherwise. Um, but as time has gone by,",
    "start": "2061075",
    "end": "2067339"
  },
  {
    "start": "2065000",
    "end": "2110000"
  },
  {
    "text": "there's a ton of curated NLP data that's available on various websites. In fact, if anything the problem is it's just sort of",
    "start": "2067340",
    "end": "2074610"
  },
  {
    "text": "spread over the web and that's sort of hard to find different things. But there are some, some sites that have a lot of data for various purposes.",
    "start": "2074610",
    "end": "2082310"
  },
  {
    "text": "So, anything related to machine translation or just parallel, um, data across different languages.",
    "start": "2082310",
    "end": "2087975"
  },
  {
    "text": "The statistical MT statmt.org site has a great amount of data and that organization runs shared tasks every year,",
    "start": "2087975",
    "end": "2097425"
  },
  {
    "text": "the Workshop on Machine Translation, WMT which Abby already mentioned in her class.",
    "start": "2097425",
    "end": "2103365"
  },
  {
    "text": "And they've got datasets that we use for those tasks and then there are leaderboards for those tasks. And you can find data for that.",
    "start": "2103365",
    "end": "2110410"
  },
  {
    "start": "2110000",
    "end": "2197000"
  },
  {
    "text": "Um, if you thought dependency parsing was cool, um, there's the Universal Dependencies site which has parallel, not parallel site,",
    "start": "2110410",
    "end": "2118694"
  },
  {
    "text": "which has treebanks in the same annotation scheme for about 60 different languages and you can work on",
    "start": "2118695",
    "end": "2124300"
  },
  {
    "text": "parsers for different languages and things like that. Um, I'm not gonna bore you with going through all of them but, you know,",
    "start": "2124300",
    "end": "2131330"
  },
  {
    "text": "there are just tons and tons of other datasets that Facebook has released datasets, Google's released datasets,",
    "start": "2131330",
    "end": "2137675"
  },
  {
    "text": "I said Stanford have released several other datasets including the Stanford Sentiment Treebank and the Stanford Na- Natural Language, um,",
    "start": "2137675",
    "end": "2145230"
  },
  {
    "text": "Inference corpus, uh, new question-answering datasets and including HotPotQA and conversational question answering.",
    "start": "2145230",
    "end": "2152980"
  },
  {
    "text": "Other groups at different universities have released datasets. There are just tons of them. You can find data on sites like Kaggle where it has machine-learning competitions.",
    "start": "2152980",
    "end": "2162954"
  },
  {
    "text": "There are sites with lists of datasets. You can look at research papers and see what datasets they used.",
    "start": "2162955",
    "end": "2169860"
  },
  {
    "text": "And of course, you can ask the course staff or on Piazza to try and find suitable datasets for a project.",
    "start": "2169860",
    "end": "2176305"
  },
  {
    "text": "Okay. Um, so that's a fair bit about the projects that I've got a bit more to say later about doing projects.",
    "start": "2176305",
    "end": "2183180"
  },
  {
    "text": "Does anyone have any questions up until now on projects?",
    "start": "2183180",
    "end": "2187230"
  },
  {
    "text": "Okay. Um, well, so now we're gonna sort of, um,",
    "start": "2188640",
    "end": "2194180"
  },
  {
    "text": "flip a switch in our brains and go back and have one more look,",
    "start": "2194180",
    "end": "2199204"
  },
  {
    "start": "2197000",
    "end": "2309000"
  },
  {
    "text": "um, at gated recurrent units, um, and what happens and what they mean.",
    "start": "2199205",
    "end": "2205490"
  },
  {
    "text": "Um, and, you know, this is sort of, sort of the same material that Abby presented,",
    "start": "2205490",
    "end": "2211570"
  },
  {
    "text": "presented a little bit differently but, you know, I hope it might just sort of give one more way of",
    "start": "2211570",
    "end": "2217130"
  },
  {
    "text": "sort of thinking a bit about what's happening about these gated recurrent units and why they might be doing",
    "start": "2217130",
    "end": "2223795"
  },
  {
    "text": "something useful and what are the alternatives to them. So, if you remember the problem we started with is that we",
    "start": "2223795",
    "end": "2231640"
  },
  {
    "text": "wanted to understand sort of derivatives backward in time. And so, the idea of that is well,",
    "start": "2231640",
    "end": "2238270"
  },
  {
    "text": "if we twiddle this a little bit at time T, how much effect is that going to have so we make some adjustment here.",
    "start": "2238270",
    "end": "2247240"
  },
  {
    "text": "How much effect is that going to have n time steps later? Um, and well, we sort of looked at the derivatives and we sort of saw we got these,",
    "start": "2247240",
    "end": "2258210"
  },
  {
    "text": "um, terms for each successive time step. And so as Abby discussed the problem is that for the derivatives that we got,",
    "start": "2258210",
    "end": "2268700"
  },
  {
    "text": "we kind of got this matrix form for each time step. And so that if we're going through a lot of time steps,",
    "start": "2268700",
    "end": "2275165"
  },
  {
    "text": "we got a lot of matrix multiplies and as the result of those matrix multiplies,",
    "start": "2275165",
    "end": "2280585"
  },
  {
    "text": "pretty much either things disappeared down to zero or exploded upward depending on what was in the matrix.",
    "start": "2280585",
    "end": "2287280"
  },
  {
    "text": "And so that- and so that's sort of means we, When the gradient goes to zero, we kind of can't know what's happening there.",
    "start": "2287280",
    "end": "2294870"
  },
  {
    "text": "Whether there isn't any conditioning or just we can't measure it. And so that's sort of made people think that maybe this naive, um,",
    "start": "2294870",
    "end": "2303029"
  },
  {
    "text": "recurrent neural network transition function just isn't a good one to use.",
    "start": "2303030",
    "end": "2309350"
  },
  {
    "start": "2309000",
    "end": "3065000"
  },
  {
    "text": "And that sort of leads into these ideas of gated recurrent units. Right? Because if we have",
    "start": "2309350",
    "end": "2315930"
  },
  {
    "text": "the simple recurrent neural network where we're sort of feeding forward for each step in time.",
    "start": "2315930",
    "end": "2322800"
  },
  {
    "text": "Well, what happens is when we backpropagate. We have to backpropagate through every intermediate node and that's where we sort of have our gradients disappear.",
    "start": "2322800",
    "end": "2332230"
  },
  {
    "text": "And so an idea of how you could fix that is to say well, suppose we just put in direct connections that were longer distance, um,",
    "start": "2332230",
    "end": "2343130"
  },
  {
    "text": "then we'd also get direct backpropagation signal and so then we wouldn't have this same problem of vanishing gradients.",
    "start": "2343130",
    "end": "2351855"
  },
  {
    "text": "And effectively, we've sort of looked at two ways in which you can achieve that effect.",
    "start": "2351855",
    "end": "2357130"
  },
  {
    "text": "Because one way of you can achieve that effect which Abby looked at in the end part of the last lecture was this idea of attention.",
    "start": "2357130",
    "end": "2365450"
  },
  {
    "text": "So, when you've got attention, you're actually are creating these shortcut connections,",
    "start": "2365450",
    "end": "2371890"
  },
  {
    "text": "oops, they're the blue ones, um, from every time step and using it to calculate an attention distribution.",
    "start": "2371890",
    "end": "2378870"
  },
  {
    "text": "But the way the attention was done that we looked at, it was sort of mushing together all previous time steps into some kind of an average.",
    "start": "2378870",
    "end": "2386125"
  },
  {
    "text": "But the idea of the gated recurrent units is in some sense we want to achieve this same kind of ability to have shortcut connections.",
    "start": "2386125",
    "end": "2395760"
  },
  {
    "text": "But we want to do it in a more controlled and adaptive fashion where we still do remember the position of things.",
    "start": "2395760",
    "end": "2404415"
  },
  {
    "text": "So, how can we create an adaptive shortcut connection? And so that's, um,",
    "start": "2404415",
    "end": "2410770"
  },
  {
    "text": "what we start to do with the gates that are put into a gated recurrent network.",
    "start": "2410770",
    "end": "2417580"
  },
  {
    "text": "So, if- so first off we sort of say let's have a candidate update which is exactly the same",
    "start": "2417580",
    "end": "2426219"
  },
  {
    "text": "as the one that's used in a simple recurrent neural network. But what we can do is add a gate.",
    "start": "2426219",
    "end": "2434285"
  },
  {
    "text": "And so, the gate will calculate a value from zero to one. And so what we're going to do here is mix together",
    "start": "2434285",
    "end": "2441595"
  },
  {
    "text": "using our candidate update which is just like a simple recurrent neural network which will be then mixed together with simply",
    "start": "2441595",
    "end": "2451720"
  },
  {
    "text": "directly carrying forward the hidden state from the previous time step.",
    "start": "2451720",
    "end": "2457845"
  },
  {
    "text": "So, once we're doing that we are sort of then adaptively- we're adaptively partly using a computation from one time step back,",
    "start": "2457845",
    "end": "2469990"
  },
  {
    "text": "um, done as a recurrent neural network. And we're partly just inheriting the,",
    "start": "2469990",
    "end": "2476980"
  },
  {
    "text": "we're just part- sorry, we're partly inheriting the hidden state from the previous time step.",
    "start": "2476980",
    "end": "2482265"
  },
  {
    "text": "So, it's sort of like a shortcut connection but we're waiting as to how much we're short cutting and how much we're doing our computation.",
    "start": "2482265",
    "end": "2490840"
  },
  {
    "text": "And we control that adaptive choice by using a calculation to set the gate.",
    "start": "2490840",
    "end": "2498750"
  },
  {
    "text": "And we do that with a sigmoid, um, computed over the import and the hidden- previous hidden state and using it again,",
    "start": "2498750",
    "end": "2506540"
  },
  {
    "text": "an equation kind of like a simple recurrent neural network. Okay. Um, but, you know,",
    "start": "2506540",
    "end": "2513930"
  },
  {
    "text": "if you wanted to go a bit further than that, um, you could think well,",
    "start": "2513930",
    "end": "2520380"
  },
  {
    "text": "maybe sometimes we sort of might actually",
    "start": "2520380",
    "end": "2525825"
  },
  {
    "text": "just want to get rid of the stuff that was in the past.",
    "start": "2525825",
    "end": "2531435"
  },
  {
    "text": "That maybe the stuff in the past sometimes becomes irrelevant, like, maybe sometimes we start a new sentence or a new",
    "start": "2531435",
    "end": "2538290"
  },
  {
    "text": "thought and we just want to get rid of the stuff that's in the past. And so, that can lead into this idea of having a second gate,",
    "start": "2538290",
    "end": "2545700"
  },
  {
    "text": "a reset gate and so the reset gate calculates a value from 0 to 1, um,",
    "start": "2545700",
    "end": "2551355"
  },
  {
    "text": "just like the other gates, and then we're doing this element wise dot-product between",
    "start": "2551355",
    "end": "2558660"
  },
  {
    "text": "the reset gate and the previous hidden state and that's then sort of saying well,",
    "start": "2558660",
    "end": "2564434"
  },
  {
    "text": "maybe we want to keep some parts of what was stored previously and some parts that we now want to throw away.",
    "start": "2564435",
    "end": "2572355"
  },
  {
    "text": "And so we put that into the model as a second gate. Um, and so an interesting way to think about that is to sort of think",
    "start": "2572355",
    "end": "2581010"
  },
  {
    "text": "about this as if this recurrent neural network is like a little tiny computer as the kind of little tiny computers you",
    "start": "2581010",
    "end": "2590130"
  },
  {
    "text": "might do in a sort of simple architecture class and if you think about it that way, um, for the basic simple recurrent neural network",
    "start": "2590130",
    "end": "2600299"
  },
  {
    "text": "the way the tiny computer works is that you've got a bank of registers h,",
    "start": "2600300",
    "end": "2605475"
  },
  {
    "text": "your hidden state, and at each time step you have to read- whoops, at each time step you have to read the entirety of your bank of registers,",
    "start": "2605475",
    "end": "2617910"
  },
  {
    "text": "you do some computation and then you write the entirety of your bank of registers and, you know,",
    "start": "2617910",
    "end": "2624600"
  },
  {
    "text": "if in terms of thinking about computer architecture, that sounds like a pretty bad way to implement a simple computer.",
    "start": "2624600",
    "end": "2632190"
  },
  {
    "text": "Um, so precisely what a gated recurrent unit is doing is saying,",
    "start": "2632190",
    "end": "2637545"
  },
  {
    "text": "\"Well, maybe we can have a slightly more sophisticated little baby computer.\" Instead of that, we could select a subset of the registers that we want to read.",
    "start": "2637545",
    "end": "2648095"
  },
  {
    "text": "And so, the reset gate can control that because it can say, \"We'll just ignore a bunch of the other registers.\"",
    "start": "2648095",
    "end": "2653720"
  },
  {
    "text": "Um, it then will compute a new value based on just these, um,",
    "start": "2653720",
    "end": "2660785"
  },
  {
    "text": "stored registers and then the update gate which is also adaptive can say, \"Well,",
    "start": "2660785",
    "end": "2667220"
  },
  {
    "text": "I want you to write some registers but the rest of the registers will just keep their previous value.\"",
    "start": "2667220",
    "end": "2674579"
  },
  {
    "text": "That seems a useful idea to have in a computer. And so, that's what we're doing here.",
    "start": "2674580",
    "end": "2679680"
  },
  {
    "text": "And so, this model here is, um, what was- Abby presented second as the gated recurrent unit.",
    "start": "2679680",
    "end": "2689115"
  },
  {
    "text": "So, this is sort of a much more realistic model and it sort of in some sense overlaps with the ideas of attention.",
    "start": "2689115",
    "end": "2697515"
  },
  {
    "text": "Okay. Um, so gated recurrent units are actually a quite new model.",
    "start": "2697515",
    "end": "2703244"
  },
  {
    "text": "Um, the model that was done way earlier and has had huge impact is these LSTM long short-term memory units and they are a bit more complex.",
    "start": "2703245",
    "end": "2713340"
  },
  {
    "text": "Um, but, you know, a lot of it is sort of the same, right? So, the hidden state of",
    "start": "2713340",
    "end": "2720210"
  },
  {
    "text": "a gated recurrent unit is kind of equivalent to the cell of the LSTM. So, both of them are using the same idea of summing together,",
    "start": "2720210",
    "end": "2729990"
  },
  {
    "text": "a mixture of just directly interpret- directly inheriting what you had from the previous time step together with, um,",
    "start": "2729990",
    "end": "2739140"
  },
  {
    "text": "something that you've calculated for the current time step and the way you count- calculate it for the current time step is exactly the same in both cases.",
    "start": "2739140",
    "end": "2749550"
  },
  {
    "text": "Whoops, sorry. Both cases again that you're calculating the current update using this sort of simple RNN equation.",
    "start": "2749550",
    "end": "2758130"
  },
  {
    "text": "So, those parts are exactly the same. Um, but the LSTM is a little bit more complicated.",
    "start": "2758130",
    "end": "2764310"
  },
  {
    "text": "It now has three gates, um, and it's got this extra, um, hidden state that's then worked out with a bit more complexity.",
    "start": "2764310",
    "end": "2772500"
  },
  {
    "text": "So, in terms of my LSTM picture, you know, the LSTM picture looks as if you sort of pull apart all of its math pretty",
    "start": "2772500",
    "end": "2782359"
  },
  {
    "text": "complex but so there are three gates so that you can forget or ignore everything.",
    "start": "2782360",
    "end": "2789990"
  },
  {
    "text": "So, you can forget or ignore the input, you can forget or ignore parts of your previous hidden state and you can forget or ignore parts of the cell",
    "start": "2789990",
    "end": "2798750"
  },
  {
    "text": "when calculating the output and each of these is produce- when I say forget or ignore parts of,",
    "start": "2798750",
    "end": "2806145"
  },
  {
    "text": "what that's meaning is you're calculating a vector which is then going to be element-wise multiplied by the import of the previous hidden state or the cell.",
    "start": "2806145",
    "end": "2816075"
  },
  {
    "text": "And so, that's why you have this effective now an addressable bank of registers where you can use some of them but not others of them.",
    "start": "2816075",
    "end": "2823335"
  },
  {
    "text": "Okay. So, the bottom part of the LSTM is just like a simpler simple recurrent neural network,",
    "start": "2823335",
    "end": "2830400"
  },
  {
    "text": "um, which then calculates, um, a candidate update. And so, for both of the GRU and the LSTM the real secret is",
    "start": "2830400",
    "end": "2841290"
  },
  {
    "text": "that rather than just keeping on multiplying stuff what you do is you add two things together.",
    "start": "2841290",
    "end": "2848025"
  },
  {
    "text": "Um, and so this adding is why you don't get the same vanishing gradient evil effects because you're calculating a",
    "start": "2848025",
    "end": "2856050"
  },
  {
    "text": "new candidate update and you're adding it to stuff that was previously in the cell and that gives you",
    "start": "2856050",
    "end": "2862665"
  },
  {
    "text": "a simple gradient when you backpropagate that- that you have direct linear connection between the cell at time t and the cell at time t minus one.",
    "start": "2862665",
    "end": "2872744"
  },
  {
    "text": "And so, really that simple addition there is sort of the secret of most of the power of LSTMs and",
    "start": "2872745",
    "end": "2880350"
  },
  {
    "text": "this same idea of adding two things together has also been a secret of many of the other advances in deep learning recently.",
    "start": "2880350",
    "end": "2888105"
  },
  {
    "text": "So, envision in the last couple of years the sort of standard model that everybody uses as ResNets, residual networks and they use",
    "start": "2888105",
    "end": "2897060"
  },
  {
    "text": "exactly the same secret of allowing these adaptive updates where you add",
    "start": "2897060",
    "end": "2903000"
  },
  {
    "text": "together a current layer's value with directly inheriting a value from the layer below.",
    "start": "2903000",
    "end": "2910680"
  },
  {
    "text": "Um, other things that use similar ideas are things like highway networks and so on. So, that's proven to be an extremely powerful idea.",
    "start": "2910680",
    "end": "2919050"
  },
  {
    "text": "Um, the LSTM is slightly different from the GRU because when we look back at its equations",
    "start": "2919050",
    "end": "2926505"
  },
  {
    "text": "that the- the GRU kind of does a linear mixture where you have one gate value,",
    "start": "2926505",
    "end": "2933988"
  },
  {
    "text": "UT, and one minus UT, where the LSTM adds values controlled by two different gates,",
    "start": "2933989",
    "end": "2942869"
  },
  {
    "text": "a forget gate, and an input gate. Theoretically, having the adding of",
    "start": "2942870",
    "end": "2949290"
  },
  {
    "text": "two separate gates rather than than a mixture is theoretically more powerful. Um, depending on the application,",
    "start": "2949290",
    "end": "2956550"
  },
  {
    "text": "sometimes it doesn't seem to make much difference, um, but there's definitely a theoretical advantage to the LSTM there.",
    "start": "2956550",
    "end": "2963480"
  },
  {
    "text": "Okay. Um, just, I hope that's maybe a little bit more helpful to have seen those again,",
    "start": "2963480",
    "end": "2971070"
  },
  {
    "text": "um, any questions on gated recurrent units?",
    "start": "2971070",
    "end": "2975550"
  },
  {
    "text": "Still look confusing? I think it's useful to have some kind of idea as to why the people come up with",
    "start": "2977970",
    "end": "2988450"
  },
  {
    "text": "these things and why do they make sense but,",
    "start": "2988450",
    "end": "2993670"
  },
  {
    "text": "you know, nevertheless, the reality is in the sort of era of",
    "start": "2993670",
    "end": "2998680"
  },
  {
    "text": "2015 plus any deep learning package you use whether it's PyTorch,",
    "start": "2998680",
    "end": "3003750"
  },
  {
    "text": "TensorFlow, MXNet whatever, you know, it just comes with LSTM and GRUs and you don't have to program your own.",
    "start": "3003750",
    "end": "3011250"
  },
  {
    "text": "In fact, you're at disadvantage if you program your own because if you are using the built-in one, it's using an efficient CUDA kernel from",
    "start": "3011250",
    "end": "3019070"
  },
  {
    "text": "Nvidia whereas your custom built one won't and/or run three times slower. Um, so, you know, essentially don't have to know how to do it,",
    "start": "3019070",
    "end": "3026915"
  },
  {
    "text": "you can just take the attitude that an LSTM is just like a fancy recurrent network which will be easier to train and that's true.",
    "start": "3026915",
    "end": "3035345"
  },
  {
    "text": "Um, but you know, these kind of architectural ideas have actually been central to most of the big advances that have come in deep learning in the last couple of years,",
    "start": "3035345",
    "end": "3045420"
  },
  {
    "text": "so there's actually good to have an ID, to have some sense of what were these important ideas that made everything so much better because they had",
    "start": "3045420",
    "end": "3053684"
  },
  {
    "text": "the same kind of component building blocks you might also want to use in custom models that you design for yourself.",
    "start": "3053685",
    "end": "3060970"
  },
  {
    "text": "Okay, two bits of machine translation. Um, so a bit of machine translation that we",
    "start": "3062120",
    "end": "3071250"
  },
  {
    "start": "3065000",
    "end": "3257000"
  },
  {
    "text": "sort of didn't cover next week but lots of people have been seeing and getting confused by in the assignments so I thought I'd explain",
    "start": "3071250",
    "end": "3079920"
  },
  {
    "text": "a bit about is UNKs and explain where do UNKs come from and why are there UNKs and the reason why",
    "start": "3079920",
    "end": "3088410"
  },
  {
    "text": "there are UNKs is effectively kind of for efficiency reasons. So, if you sort of think about producing output in a neural machine translation system",
    "start": "3088410",
    "end": "3099704"
  },
  {
    "text": "and really this is the same as producing output in any natural, neural natural language generation system,",
    "start": "3099705",
    "end": "3106680"
  },
  {
    "text": "so that's really the same for neural language model, um, that if you have a very large output vocabulary is just a expensive operation.",
    "start": "3106680",
    "end": "3116970"
  },
  {
    "text": "So you have a big matrix of softmax parameters where you have a row for every word, um,",
    "start": "3116970",
    "end": "3124849"
  },
  {
    "text": "and then you have what,",
    "start": "3124850",
    "end": "3132420"
  },
  {
    "text": "[NOISE] then we have an animation that is not working for me. Oh, all right there, there we go.",
    "start": "3132420",
    "end": "3138210"
  },
  {
    "text": "Um, so then we have some hidden state that we've calculated in our recurrent neural network.",
    "start": "3138210",
    "end": "3145335"
  },
  {
    "text": "And so, what we gonna do is sort of multiply, um, that vector by every row of the matrix,",
    "start": "3145335",
    "end": "3153105"
  },
  {
    "text": "put it through a softmax and then get probabilities without putting every word.",
    "start": "3153105",
    "end": "3159030"
  },
  {
    "text": "Um, and you know, this seems pretty simple but the problem is that",
    "start": "3159030",
    "end": "3164040"
  },
  {
    "text": "to the extent that you have a humongous vocabulary here, you just have to do a humongous number of rows",
    "start": "3164040",
    "end": "3171240"
  },
  {
    "text": "of this multiplication and it actually turns out that doing this is the expensive part of",
    "start": "3171240",
    "end": "3179025"
  },
  {
    "text": "having a neural machine translation or neural language model system, right? The LSTM might look complicated and hard to understand, but you know,",
    "start": "3179025",
    "end": "3187380"
  },
  {
    "text": "it's relatively small vectors that you multiply or dot-product once, and it's not that much work whereas if you have a huge number of words,",
    "start": "3187380",
    "end": "3196020"
  },
  {
    "text": "this is a huge amount of work. So, just for instance sort of for the pion- pioneering sequence to sequence,",
    "start": "3196020",
    "end": "3202559"
  },
  {
    "text": "um, neural machine translation system that Google first did, they ran it on an eight GPU machine because they have lots of GPUs but",
    "start": "3202560",
    "end": "3210840"
  },
  {
    "text": "the way they set it up to maximize performance was of those eight GPUs,",
    "start": "3210840",
    "end": "3216075"
  },
  {
    "text": "three of them were running a deep multi-layer neural sequence model and the other five GPUs,",
    "start": "3216075",
    "end": "3224070"
  },
  {
    "text": "the only thing that they were doing was calculating softmaxes because that's actually the bulk of the computation that you need to be able to do.",
    "start": "3224070",
    "end": "3232770"
  },
  {
    "text": "Um, so the simplest way to make this, um, computation not completely excessive is to say,",
    "start": "3232770",
    "end": "3241560"
  },
  {
    "text": "\"Hey, I'll just limit the vocabulary.\" Yeah I know that you can make",
    "start": "3241560",
    "end": "3247365"
  },
  {
    "text": "a million different words in English and if you look at Spanish inflections of verbs,",
    "start": "3247365",
    "end": "3253230"
  },
  {
    "text": "there are a lot of them and there's gonna be huge number of words, um, but maybe I can just make do with a modest vocabulary and it'll be near enough.",
    "start": "3253230",
    "end": "3260220"
  },
  {
    "start": "3257000",
    "end": "3345000"
  },
  {
    "text": "Surely 50,000 common words, I can cover a lot of stuff and so,",
    "start": "3260220",
    "end": "3265244"
  },
  {
    "text": "that was sort of the starting off point of neural machine translation that you, people use the modest vocabulary like around 50,000 words.",
    "start": "3265245",
    "end": "3274515"
  },
  {
    "text": "And well, if you do that, um, well, then what happens is you have UNKs.",
    "start": "3274515",
    "end": "3280980"
  },
  {
    "text": "So UNK means, this is an unknown word, that's not in my vocabulary and so there are two kinds of UNKs,",
    "start": "3280980",
    "end": "3287325"
  },
  {
    "text": "they can be UNKs in the source language and you know, they're sort of optional because, you know,",
    "start": "3287325",
    "end": "3295710"
  },
  {
    "text": "it's not actually a problem having a large source language vocabulary, but the fact of the matter is if you've sort of trained",
    "start": "3295710",
    "end": "3302070"
  },
  {
    "text": "a model on a certain amount of data, there are some words you aren't going to have seen, so you are going to have words that you just didn't",
    "start": "3302070",
    "end": "3309000"
  },
  {
    "text": "see in your training data and you won't have any pre-trained or trained word vector",
    "start": "3309000",
    "end": "3314430"
  },
  {
    "text": "for them and you can deal with that by either just treating them as UNK, so giving them a new word vector when you encounter them.",
    "start": "3314430",
    "end": "3320595"
  },
  {
    "text": "But the tricky part is on the translation that you're wanting to produce these rare words but they're not in your output vocabulary,",
    "start": "3320595",
    "end": "3328725"
  },
  {
    "text": "so your system is producing UNK, UNK to UNK, which is not a very good translation really.",
    "start": "3328725",
    "end": "3335550"
  },
  {
    "text": "Um, yeah, and so that was sort of what the first, um, machine, neural machine translation systems, um, did.",
    "start": "3335550",
    "end": "3344220"
  },
  {
    "text": "And so, you know, obviously that's not a very satisfactory state of affairs and so there's been a whole bunch of work,",
    "start": "3344220",
    "end": "3351555"
  },
  {
    "start": "3345000",
    "end": "3551000"
  },
  {
    "text": "um, as to how to deal with this, so you can use methods that allow you to deal with a larger output vocabulary,",
    "start": "3351555",
    "end": "3360465"
  },
  {
    "text": "um, without the computation being excessive. So one method of doing that is to have what's called a hierarchical softmax,",
    "start": "3360465",
    "end": "3367785"
  },
  {
    "text": "so that rather than just having a huge matrix of words, you sort of have a tree structure in your vocabulary",
    "start": "3367785",
    "end": "3374910"
  },
  {
    "text": "so you can do calculations with hierarchical, um, multiple small softmaxes and you can do that more quickly.",
    "start": "3374910",
    "end": "3382815"
  },
  {
    "text": "Um, I'm not gonna go through all these exam, all these things in detail now, I'm just sort of very quickly mentioning them and if anyone's interested, they can look.",
    "start": "3382815",
    "end": "3391575"
  },
  {
    "text": "People have used the noise-contrastive estimation idea that we saw with Word2vec in this context as well.",
    "start": "3391575",
    "end": "3398235"
  },
  {
    "text": "So this is a way to get much faster training which is important, it's not really a way to solve, um,",
    "start": "3398235",
    "end": "3405315"
  },
  {
    "text": "speed at translation time but, you know, if this means you can train your system in six hours instead of",
    "start": "3405315",
    "end": "3410580"
  },
  {
    "text": "six days that's a big win and so that's a good technique to use. Um, people have done much smarter things, so really, um,",
    "start": "3410580",
    "end": "3420330"
  },
  {
    "text": "the large vocabulary problem is basically solved now and so the kind of things that you can do is you can produce",
    "start": "3420330",
    "end": "3427650"
  },
  {
    "text": "subsets of your vocabulary and train on particular subsets of vocabulary at a time and then when you're testing,",
    "start": "3427650",
    "end": "3436380"
  },
  {
    "text": "you adaptively choose kind of a likely list of words that might appear in the translation of particular sentences or passages and then",
    "start": "3436380",
    "end": "3445290"
  },
  {
    "text": "you can effectively work with sort of an appropriate subset of a vocabulary and that's sort of an efficient technique by which you can",
    "start": "3445290",
    "end": "3452849"
  },
  {
    "text": "deal with an unlimited vocabulary but only be using a moderate sized softmax for any particular paragraph that you're translating,",
    "start": "3452850",
    "end": "3461955"
  },
  {
    "text": "there's a paper that talks about that method. Um, another idea is you can use attention when you do translation,",
    "start": "3461955",
    "end": "3469425"
  },
  {
    "text": "the idea talked about at the end of last time. So if you have attention, that sort of means that you can,",
    "start": "3469425",
    "end": "3475095"
  },
  {
    "text": "you're pointing somewhere in the source and you know what you're translating at any point in time.",
    "start": "3475095",
    "end": "3480660"
  },
  {
    "text": "So, if that word is a rare word that's not in your vocabulary, there are things that you could do to deal with that.",
    "start": "3480660",
    "end": "3487560"
  },
  {
    "text": "I mean, firstly, if it's a rare word, its translation is much more likely to be constant,",
    "start": "3487560",
    "end": "3493140"
  },
  {
    "text": "so you might just look it up in a dictionary or word list, um, and, um, stick in its translation,",
    "start": "3493140",
    "end": "3499830"
  },
  {
    "text": "sometimes it's appropriate to do other things. I mean, turns out that, you know, quite a lot of things that unknown words turn out to be other things like, you know,",
    "start": "3499830",
    "end": "3509685"
  },
  {
    "text": "hexadecimal numbers, or FedEx tracking IDs, or GitHub shards, or things like that.",
    "start": "3509685",
    "end": "3515685"
  },
  {
    "text": "So for a lot of things like that, the right thing to do is just to copy them across. And so, another thing that people have looked at is copying models,",
    "start": "3515685",
    "end": "3522660"
  },
  {
    "text": "um, in machine translation. Okay, um, there are more ideas that you can,",
    "start": "3522660",
    "end": "3528215"
  },
  {
    "text": "we can get into to solve this and actually, um, next week we're gonna start dealing with some of the other ways that you could solve this, um,",
    "start": "3528215",
    "end": "3535085"
  },
  {
    "text": "but I hope there to have given you sort of a sense of, um, sort of what these UNKs are about,",
    "start": "3535085",
    "end": "3541805"
  },
  {
    "text": "why you see them and, uh, that there are sort of some ways that you might deal with them but you're not expected to be doing that,",
    "start": "3541805",
    "end": "3548599"
  },
  {
    "text": "um, for assignment four. Okay, then I just wanted to give a teeny bit more on evaluation.",
    "start": "3548600",
    "end": "3556680"
  },
  {
    "start": "3551000",
    "end": "4960000"
  },
  {
    "text": "Um, so Abby said a little bit about evaluation with blue and that then comes up in the assignment,",
    "start": "3556680",
    "end": "3563369"
  },
  {
    "text": "so I just thought I'd give you a little bit more context on that since they're being quite a few questions about it.",
    "start": "3563370",
    "end": "3569095"
  },
  {
    "text": "So, um, so the general context here is, you know, how do you evaluate machine translation quality and sort of to this day,",
    "start": "3569095",
    "end": "3578895"
  },
  {
    "text": "if you wanted to do a first rate bang up evaluation of machine translation quality,",
    "start": "3578895",
    "end": "3583980"
  },
  {
    "text": "the way you do it is you get human beings to assess quality, you take translations and you send them to",
    "start": "3583980",
    "end": "3590835"
  },
  {
    "text": "human beings with good bilingual skills and get them to score things. And there are two ways that are commonly used.",
    "start": "3590835",
    "end": "3597255"
  },
  {
    "text": "One is sort of rating on Likert scales for things like adequacy and fluency of translations,",
    "start": "3597255",
    "end": "3604290"
  },
  {
    "text": "um, but another way that often works better is asking for comparative judgments. So here are two translations of this sentence which is better, um.",
    "start": "3604290",
    "end": "3614035"
  },
  {
    "text": "And so that's, you know, sort of still our gold standard of translation.",
    "start": "3614035",
    "end": "3620075"
  },
  {
    "text": "Um, another way you can evaluate translation is use your translations in the downstream task.",
    "start": "3620075",
    "end": "3625924"
  },
  {
    "text": "So, you could say \"I'm gonna build a cross-lingual question answering system and inside that system I'm,",
    "start": "3625925",
    "end": "3633500"
  },
  {
    "text": "gonna use machine translation. I'm gonna translate the questions um, and then try and match them against the documents.",
    "start": "3633500",
    "end": "3640625"
  },
  {
    "text": "Um, and then my score will be how good my question answering system is,",
    "start": "3640625",
    "end": "3645830"
  },
  {
    "text": "and so the machine translation system is better if my question-answering score um, goes up.\"",
    "start": "3645830",
    "end": "3652190"
  },
  {
    "text": "I mean, that's kind of a nice way to do things because you're kinda then taking them in, run around needing,",
    "start": "3652190",
    "end": "3657244"
  },
  {
    "text": "needing human beings, and yet you do have a clear numerical measure that's coming out the back end.",
    "start": "3657245",
    "end": "3663485"
  },
  {
    "text": "But it sort of has some catches because, you know, often there will be a fairly indirect connection between",
    "start": "3663485",
    "end": "3669980"
  },
  {
    "text": "your end task and the quality of the machine translation, and it might turn out that there certain aspects of",
    "start": "3669980",
    "end": "3676640"
  },
  {
    "text": "the machine translation like whether you get agreement endings, right on nouns and verbs or something.",
    "start": "3676640",
    "end": "3682970"
  },
  {
    "text": "They are actually just irrelevant to your performance in the task and say you're not assessing all aspects of um, quality.",
    "start": "3682970",
    "end": "3689645"
  },
  {
    "text": "Um, and so then the third way to do it is to come up with some way to score the direct tasks.",
    "start": "3689645",
    "end": "3695840"
  },
  {
    "text": "So, here, um, the direct task is machine translation, and this has been a valuable tool.",
    "start": "3695840",
    "end": "3704450"
  },
  {
    "text": "For, you know, really the last so 25 years when people are doing machine learning models,",
    "start": "3704450",
    "end": "3711289"
  },
  {
    "text": "because as soon as you have an automatic way to score things, you can then run automated experiments to say \"Let me try out these 50 different options.",
    "start": "3711289",
    "end": "3722060"
  },
  {
    "text": "Let me start varying these hyper-parameters and work out which way to do things is best.\"",
    "start": "3722060",
    "end": "3727250"
  },
  {
    "text": "And that importance has only grown in the deep learning era, when all the time what we want you to do is as Abby discussed, um,",
    "start": "3727250",
    "end": "3735200"
  },
  {
    "text": "build end-to-end systems and then back propagate throughout the entire system to improve them,",
    "start": "3735200",
    "end": "3741200"
  },
  {
    "text": "and we're doing that based on having some objective measure which is our automatic metric.",
    "start": "3741200",
    "end": "3746464"
  },
  {
    "text": "And so, that led into the development of automatic metrics to try and assess machine translation quality,",
    "start": "3746465",
    "end": "3753364"
  },
  {
    "text": "and the most famous and still most used one is this one called BLEU. And so, as Abby briefly mentioned,",
    "start": "3753364",
    "end": "3761375"
  },
  {
    "text": "we have a reference translation done by human beings. At some time a human being has to translate each piece of source material once,",
    "start": "3761375",
    "end": "3769789"
  },
  {
    "text": "but then you take a machine translation and you score it based on the extent to which there",
    "start": "3769790",
    "end": "3777319"
  },
  {
    "text": "are one or more word sequences that appear in the reference translation and also appear in the machine translation.",
    "start": "3777320",
    "end": "3786065"
  },
  {
    "text": "And so you are working out n-gram preci-precision scores for different values of n. So,",
    "start": "3786065",
    "end": "3792530"
  },
  {
    "text": "the standard way of doing it is you do it for one grams, bigrams, trigrams, and four-grams.",
    "start": "3792530",
    "end": "3798560"
  },
  {
    "text": "So, word sequences of size one to four, and you try and find for ones of those in the machine translation,",
    "start": "3798560",
    "end": "3806270"
  },
  {
    "text": "whether they also appear in the reference translation,",
    "start": "3806270",
    "end": "3811760"
  },
  {
    "text": "and there are two tricks at work here. Um, one trick is you have to do a kind of a bipartite matching um,",
    "start": "3811760",
    "end": "3819515"
  },
  {
    "text": "because it just can't be that um, there's a word um,",
    "start": "3819515",
    "end": "3825185"
  },
  {
    "text": "in the, in the reference translation somewhere. Um, [NOISE] I don't know if there's.",
    "start": "3825185",
    "end": "3831230"
  },
  {
    "text": "I've got a good example here [NOISE]. Um, maybe I can only do a silly example,",
    "start": "3831230",
    "end": "3837770"
  },
  {
    "text": "but I'll do a silly example. Um, that it's- it doesn't seem like you wanna say \"Okay.",
    "start": "3837770",
    "end": "3843319"
  },
  {
    "text": "Because there's a \"the\" in the reference, that means that this \"the\" is right and this \"the\" is right,",
    "start": "3843320",
    "end": "3848974"
  },
  {
    "text": "and this \"the\" is right and every other \"the\" is also right.\" That sort of seems unfair.",
    "start": "3848975",
    "end": "3854495"
  },
  {
    "text": "So, you're only allowed to use each thing in the reference once in matching n-grams,",
    "start": "3854495",
    "end": "3860825"
  },
  {
    "text": "but you are allowed to use it multiple times for different order n-grams. So, you can use it both in the uh unigram,",
    "start": "3860825",
    "end": "3866569"
  },
  {
    "text": "bigram, trigram and 4-gram. The other idea is that although you're measuring",
    "start": "3866570",
    "end": "3872270"
  },
  {
    "text": "the precision of n-grams that are in the machine translation, you wouldn't want people to be able to cheat by",
    "start": "3872270",
    "end": "3879860"
  },
  {
    "text": "putting almost nothing into the machine translation. So, you might wanna game it by no matter what the source document is.",
    "start": "3879860",
    "end": "3887450"
  },
  {
    "text": "If the target language is English, you could just um say, \"My translation is the,",
    "start": "3887450",
    "end": "3892790"
  },
  {
    "text": "because I'm pretty sure that will be in the reference translation somewhere and I'll get 0.3 unigram,",
    "start": "3892790",
    "end": "3899315"
  },
  {
    "text": "and that's not great but I'll get something for that and I am done.\" And so you wouldn't want that and so,",
    "start": "3899315",
    "end": "3904880"
  },
  {
    "text": "you're then being penalized by something called the brevity penalty if your translation is shorter than the reference translation,",
    "start": "3904880",
    "end": "3914040"
  },
  {
    "text": "and so this BLEU metric is um forming a geometric average of n-gram precision up to some n. Normally,",
    "start": "3914040",
    "end": "3924280"
  },
  {
    "text": "it's sort of up to four, is how it's done. Where it's a weighted geometric average, where you're putting weights on the different n-grams.",
    "start": "3924280",
    "end": "3932414"
  },
  {
    "text": "Um, for the assignment, we're only using unigrams and bigrams. So, you could say that means we're putting a weight of zero on um,",
    "start": "3932415",
    "end": "3939455"
  },
  {
    "text": "the trigrams and 4-grams. Okay. Um, and so that's basically what we're doing.",
    "start": "3939455",
    "end": "3946234"
  },
  {
    "text": "I-I've just mentioned um couple of other things. You might think that this is kind of random,",
    "start": "3946235",
    "end": "3951845"
  },
  {
    "text": "and so people have um, used this idea of rather than just having one reference translation,",
    "start": "3951845",
    "end": "3957530"
  },
  {
    "text": "we could have multiple reference translations, because that way we can allow for there being",
    "start": "3957530",
    "end": "3962720"
  },
  {
    "text": "variation and good ways of translating things, because in language there's always lots of good ways that you can translate one sentence.",
    "start": "3962720",
    "end": "3969740"
  },
  {
    "text": "Um, people have done that quite a bit, but people have also decided that even if you have one translation,",
    "start": "3969740",
    "end": "3976820"
  },
  {
    "text": "provided it's independent and on a kind of statistical basis, you're still more likely to match it if your translation is a good translation.",
    "start": "3976820",
    "end": "3985340"
  },
  {
    "text": "So, it's probably okay. Um, so when BLEU was originally um, introduced,",
    "start": "3985340",
    "end": "3992930"
  },
  {
    "text": "BLEU seemed marvelous and people drew graphs like this showing how closely BLEU scores correlated um,",
    "start": "3992930",
    "end": "4001915"
  },
  {
    "text": "with human judgments of translation quality. However, um, like a lot of things in life,",
    "start": "4001915",
    "end": "4008710"
  },
  {
    "text": "there are a lot of things that are great measures, providing people aren't directly trying to optimize it,",
    "start": "4008710",
    "end": "4013869"
  },
  {
    "text": "and so what's happened since then um, is that everybody has been trying to optimize BLEU scores,",
    "start": "4013870",
    "end": "4020619"
  },
  {
    "text": "and the result of that is that BLEU scores have gone up massively but the correlation",
    "start": "4020620",
    "end": "4026380"
  },
  {
    "text": "between BLEU scores and human judgments of translation in quality have gone down massively,",
    "start": "4026380",
    "end": "4032185"
  },
  {
    "text": "and so we're in this current state that um, the BLEU scores, the machines, um are pretty near the scores of human translations.",
    "start": "4032185",
    "end": "4042640"
  },
  {
    "text": "So, you know, according to BLEU scores, we're producing almost human quality machine translation,",
    "start": "4042640",
    "end": "4048565"
  },
  {
    "text": "but if you actually look at the real quality of the translations, they're still well behind",
    "start": "4048565",
    "end": "4054099"
  },
  {
    "text": "human beings um and because you could say the metric is being gamed.",
    "start": "4054100",
    "end": "4059560"
  },
  {
    "text": "Okay. I'll hope those things help for giving more sense um for assignment four.",
    "start": "4059560",
    "end": "4065950"
  },
  {
    "text": "Um, so now for the last um, about 12 minutes, um, I just now wanna um,",
    "start": "4065950",
    "end": "4071500"
  },
  {
    "text": "return to um final projects and say a little bit more um about final projects.",
    "start": "4071500",
    "end": "4078160"
  },
  {
    "text": "Um so, there many, many different ways you can do final projects,",
    "start": "4078160",
    "end": "4083710"
  },
  {
    "text": "but just to sort of go through the steps. I mean, you know, for a simple straightforward project,",
    "start": "4083710",
    "end": "4089170"
  },
  {
    "text": "this is kind of the steps that you want to go through. So, you choose some tasks, summarizing text um, producing a shorter version of a text.",
    "start": "4089170",
    "end": "4097375"
  },
  {
    "text": "You work out some dataset that you can use. So, this is an example of the kind of tasks that there",
    "start": "4097375",
    "end": "4102970"
  },
  {
    "text": "are academic data sets for that other people have used, and so you could just use one of those,",
    "start": "4102970",
    "end": "4108250"
  },
  {
    "text": "and that's it, you're already done or you could think \"Oh no! I'm much too creative for that.",
    "start": "4108250",
    "end": "4113350"
  },
  {
    "text": "I'm gonna come up with my own dataset [NOISE] um and get some online source and do it.\"",
    "start": "4113350",
    "end": "4118779"
  },
  {
    "text": "Um, and you know, summaries of the kind of things you can find online and produce your own dataset.",
    "start": "4118780",
    "end": "4125799"
  },
  {
    "text": "Um [NOISE] I wanna say a bit in, in just after this, about separating off um data sets for",
    "start": "4125800",
    "end": "4133380"
  },
  {
    "text": "training and test data, so I'll delay that, but that's important. Then, you want to work out a way to evaluate your um,",
    "start": "4133380",
    "end": "4141444"
  },
  {
    "text": "system including an automatic evaluation. Um, normally, for summarization,",
    "start": "4141445",
    "end": "4146529"
  },
  {
    "text": "people use a slightly different metric called ROUGE but it's sort of related to BLEU hence its name.",
    "start": "4146530",
    "end": "4152335"
  },
  {
    "text": "Um, it's the same story that it sort of works, but human evaluation is much better. Um, but you need- so you need to work out some metrics you can use for the project.",
    "start": "4152335",
    "end": "4161335"
  },
  {
    "text": "Um, the next thing you should do is establish a baseline. So, if it's a well-worked on problem there might already be one,",
    "start": "4161335",
    "end": "4169555"
  },
  {
    "text": "but it's not bad to try and calculate one for yourself anyway, and in particular what you should first have is",
    "start": "4169555",
    "end": "4176170"
  },
  {
    "text": "a very simple model and see how well it works. So, for human language material,",
    "start": "4176170",
    "end": "4182154"
  },
  {
    "text": "often doing things like bag of words models, whether they're just a simple classifier over",
    "start": "4182155",
    "end": "4188049"
  },
  {
    "text": "words or a new bag of words, averaging word vectors. It's just useful to try that on the task and see how it works,",
    "start": "4188050",
    "end": "4196995"
  },
  {
    "text": "see what kinds of things it already gets right, what kind of things it gets wrong. You know, one possibility is you will find that",
    "start": "4196995",
    "end": "4203880"
  },
  {
    "text": "a very simple model already does great on your task. If that's the case, um, you have too easy a task,",
    "start": "4203880",
    "end": "4210270"
  },
  {
    "text": "and you probably need to find a task that's more challenging to work on. Um, yes.",
    "start": "4210270",
    "end": "4216460"
  },
  {
    "text": "So after that, you'll then sort of think about what could be a good kind of neural network model that might do well, implement it,",
    "start": "4216460",
    "end": "4223929"
  },
  {
    "text": "test it um, see what kind of errors that makes and you know, that's sort of if you've gotten that far,",
    "start": "4223930",
    "end": "4230545"
  },
  {
    "text": "you're sort of in the right space for a class project. But, you know, it's sort of hoped that you could do more than that.",
    "start": "4230545",
    "end": "4237400"
  },
  {
    "text": "But after you've seen the errors from the first version, you could think about how to make it better and come up with a better project,",
    "start": "4237400",
    "end": "4243865"
  },
  {
    "text": "and so I would encourage everyone, you know, you really do want to look at the data, right? You don't just wanna be sort of having things and files and run and say \"Okay, 0.71.",
    "start": "4243865",
    "end": "4254620"
  },
  {
    "text": "Let me make some random change 0.70. Oh, that's not a good one,\" repeat over.",
    "start": "4254620",
    "end": "4260235"
  },
  {
    "text": "You actually want to be sort of looking at your dataset in any way you can. It's good to visualize the dataset to understand what's",
    "start": "4260235",
    "end": "4266760"
  },
  {
    "text": "important in it that you might be able to take advantage of, you want to be able to look at what kind of errors are being made because that might give you",
    "start": "4266760",
    "end": "4272969"
  },
  {
    "text": "ideas of how you could put more stuff into the model that would do better. Um, you might wanna do some graphing of the effect of hyper-parameters,",
    "start": "4272970",
    "end": "4280465"
  },
  {
    "text": "so you can kind of understand that better. And so, the hope is that you will try out some other kinds of models and make things better.",
    "start": "4280465",
    "end": "4287250"
  },
  {
    "text": "And sort of one of the goals here is, it's good if you've sort of got a well-setup experimental setup,",
    "start": "4287250",
    "end": "4294085"
  },
  {
    "text": "so you can easily turn around experiments because then you're just more likely to be able to try several things in the time available.",
    "start": "4294085",
    "end": "4301855"
  },
  {
    "text": "Okay. Um, couple of other things I wanted to mention. Um, one is sort of different amounts of data.",
    "start": "4301855",
    "end": "4309615"
  },
  {
    "text": "So, it's really, really important for all the stuff that we do, that we have different sets of data.",
    "start": "4309615",
    "end": "4316869"
  },
  {
    "text": "So, we have trained data, we have dev test data, we have test data at least,",
    "start": "4316870",
    "end": "4323130"
  },
  {
    "text": "and sometimes it's useful to have even, um, more data available.",
    "start": "4323130",
    "end": "4328240"
  },
  {
    "text": "So, for many of the public datasets, they're already split into different subsets like this,",
    "start": "4328240",
    "end": "4334080"
  },
  {
    "text": "but there are some that aren't. There are some that might only have a training set, and a test set. And what you don't want to do is think,",
    "start": "4334080",
    "end": "4341260"
  },
  {
    "text": "\"Oh, there's only a training set and a test set. Therefore I'll just run every time on the test set.\" That- that's a really invalid way to go about your research.",
    "start": "4341260",
    "end": "4349890"
  },
  {
    "text": "So, if there aren't dev sets available or you need to do some more tuning, and you need some separate tuning data,",
    "start": "4349890",
    "end": "4356375"
  },
  {
    "text": "you sort of have to, um, make it for yourself by splitting off some of the training data,",
    "start": "4356375",
    "end": "4363400"
  },
  {
    "text": "and not using it for the basic training and using it for tuning, and fo- as dev data.",
    "start": "4363400",
    "end": "4370435"
  },
  {
    "text": "Um, yes. So, to go on about that, um, more, more.",
    "start": "4370435",
    "end": "4376489"
  },
  {
    "text": "So, the basic issue is this issue of fitting and overfitting to particular datasets.",
    "start": "4376490",
    "end": "4382675"
  },
  {
    "text": "So, when we train a model, um, on some training data, we train it and the error rate goes down.",
    "start": "4382675",
    "end": "4390460"
  },
  {
    "text": "And over time, we gradually overfit to the training data because we sort of",
    "start": "4390460",
    "end": "4395900"
  },
  {
    "text": "pick up on our neural network f- facts about the particular training data items,",
    "start": "4395900",
    "end": "4401820"
  },
  {
    "text": "and we just sort of start to learn them. Now in the old days, the fact that you overfit to the training data was seen as evil.",
    "start": "4401820",
    "end": "4410060"
  },
  {
    "text": "In modern neural network think, we don't think it is evil what we overfit to the training data",
    "start": "4410060",
    "end": "4415630"
  },
  {
    "text": "because all neural nets that are any good overfit to the training data, and we would be very sad if they didn't.",
    "start": "4415630",
    "end": "4422875"
  },
  {
    "text": "I'll come back to that in a moment. But nevertheless, they're overfitting like crazy. So, what we, but and what we want to build is something that generalizes well.",
    "start": "4422875",
    "end": "4432920"
  },
  {
    "text": "So, we have to have some separate data, that's our validation data, and say look at what performance looks like on the validation data.",
    "start": "4432920",
    "end": "4441030"
  },
  {
    "text": "And commonly we find that training up until some point, improves our performance on separate validation data,",
    "start": "4441030",
    "end": "4448500"
  },
  {
    "text": "and then we start to overfit to the training data in a way that our validation set performance gets worse.",
    "start": "4448500",
    "end": "4455764"
  },
  {
    "text": "Um, and so, then, further training on the training data isn't useful because we're starting",
    "start": "4455765",
    "end": "4461965"
  },
  {
    "text": "to build a model that generalizes worse when run on other data. But there's- the whole point here is,",
    "start": "4461965",
    "end": "4468810"
  },
  {
    "text": "we can only do this experiment if our validation data is separate from our training data.",
    "start": "4468810",
    "end": "4474835"
  },
  {
    "text": "If it's the same data or if it's overlapping data, we can't draw this graph.",
    "start": "4474835",
    "end": "4479950"
  },
  {
    "text": "Um, and so, therefore, we can't do valid experiments. Um, now you might think, \"Oh, well,",
    "start": "4479950",
    "end": "4487085"
  },
  {
    "text": "maybe I can, um, do this and just use the test set of data.\"",
    "start": "4487085",
    "end": "4492175"
  },
  {
    "text": "Um, but that's also invalid, and the reason why that's invalid is,",
    "start": "4492175",
    "end": "4498920"
  },
  {
    "text": "as you do experiments, you also start slowly over fitting to your development data.",
    "start": "4498920",
    "end": "4505495"
  },
  {
    "text": "So, the standard practice is you do a run and you get a score on the development data.",
    "start": "4505495",
    "end": "4511560"
  },
  {
    "text": "You do a second run. You do worse on the development data, and so you throw that second model away.",
    "start": "4511560",
    "end": "4517770"
  },
  {
    "text": "You do a third experiment. You do better on the development data, and so you keep that model and you repeat over 50 times.",
    "start": "4517770",
    "end": "4524905"
  },
  {
    "text": "And while some of those subsequent models you keep, are genuinely better because you sort of worked out something good to do.",
    "start": "4524905",
    "end": "4534195"
  },
  {
    "text": "But it turns out that some of those subsequent models only sort of just happened. You just got lucky and they happened to score better on the development data.",
    "start": "4534195",
    "end": "4542985"
  },
  {
    "text": "And so, if you kind of keep repeating that process 60 or 100 times, you're also gradually [NOISE] overfitting on your development data,",
    "start": "4542985",
    "end": "4550570"
  },
  {
    "text": "and you get unrealistically good dev scores. And so, that means two things. You know, if you want to be rigorous and do a huge amount of hyper-parameter exploration,",
    "start": "4550570",
    "end": "4559820"
  },
  {
    "text": "it can be good to have a second development se- test set, so that you have one, that you haven't overfit as much.",
    "start": "4559820",
    "end": "4565660"
  },
  {
    "text": "And if you want to have valid scores on te- on as to what is my actual performance on independent data,",
    "start": "4565660",
    "end": "4572595"
  },
  {
    "text": "it's vital that you have separate test data that you are not using at all in this process, right?",
    "start": "4572595",
    "end": "4579265"
  },
  {
    "text": "So, the ideal state is that, for your real test data, um,",
    "start": "4579265",
    "end": "4584860"
  },
  {
    "text": "that you never used it at all until you've finished training your data, uh, training your model, and then you run your final model once on the test data,",
    "start": "4584860",
    "end": "4594060"
  },
  {
    "text": "and you write up your paper and those are your results. Now, I will be honest and say the world usually isn't",
    "start": "4594060",
    "end": "4599494"
  },
  {
    "text": "quite that perfect because after you've done that, you then go to sleep [NOISE] and wake up thinking.",
    "start": "4599495",
    "end": "4604960"
  },
  {
    "text": "\"I've got a fantastic idea of how to make my model better.\" and you run off and implement that, and it works great on the dev data,",
    "start": "4604960",
    "end": "4611700"
  },
  {
    "text": "and then for you, run it on the test data again and the numbers go up. Um, sort of everybody does that.",
    "start": "4611700",
    "end": "4617639"
  },
  {
    "text": "Um, and you know, in modicum it's okay, you know, if that means you occasionally run on the test data it's not so bad, um,",
    "start": "4617640",
    "end": "4626324"
  },
  {
    "text": "but you really need to be aware of the slippery slope because, if you then start falling into, \"I've got a new model.",
    "start": "4626325",
    "end": "4633559"
  },
  {
    "text": "Let me try that one on the test data. I've got a new model. Let me try this one on the test data.\" Then you're just sort of overfitting to the test data,",
    "start": "4633560",
    "end": "4640130"
  },
  {
    "text": "and getting an unrealistically high score. And that's precisely why a lot of the competitions like Kaggle competitions,",
    "start": "4640130",
    "end": "4647605"
  },
  {
    "text": "have a secret test dataset that you can't run on. So, that they can do a genuine,",
    "start": "4647605",
    "end": "4653615"
  },
  {
    "text": "independent test on the actual test data. Okay. Um, let's see, um, a couple more minutes.",
    "start": "4653615",
    "end": "4662550"
  },
  {
    "text": "So, yeah, getting your neural network to train. Um, my two messages are, you know,",
    "start": "4662550",
    "end": "4669135"
  },
  {
    "text": "first of all, you should start with a positive attitude. Neural networks want to learn.",
    "start": "4669135",
    "end": "4674565"
  },
  {
    "text": "If they're not learning, you're doing something to stop them from learning. And so, you should just stop that,",
    "start": "4674565",
    "end": "4680070"
  },
  {
    "text": "and they will learn because they want to learn. They're just like little children. Um, but, if the follow up to that is the grim reality that there are just tons",
    "start": "4680070",
    "end": "4689790"
  },
  {
    "text": "of things you can do that will cause your neural networks not to learn very well or at all,",
    "start": "4689790",
    "end": "4695710"
  },
  {
    "text": "and this is the frustrating part of this whole field because you know, it's not like a compile error.",
    "start": "4695710",
    "end": "4701605"
  },
  {
    "text": "It can just be hard to find and fix them. And, you know, it is just really",
    "start": "4701605",
    "end": "4707715"
  },
  {
    "text": "standard that you spend more time dealing with trying to find, and fix why it doesn't work well and getting it to work well than",
    "start": "4707715",
    "end": "4715225"
  },
  {
    "text": "you- than the time you spent writing the code for your model. So, remember to budget for that when you're doing your final project,",
    "start": "4715225",
    "end": "4723734"
  },
  {
    "text": "it just won't work if you finish the code a day or two before the deadline. Um, so, you need to work out what those things are,",
    "start": "4723734",
    "end": "4731990"
  },
  {
    "text": "\"That can be hard,\" but you know experience, experimental care, rules of thumb help.",
    "start": "4731990",
    "end": "4737260"
  },
  {
    "text": "So, there are just lots of things that are important. So, you know, your learning rates are important.",
    "start": "4737260",
    "end": "4742480"
  },
  {
    "text": "If your learning rates are way too high, things won't learn. If your learning rates are way too low,",
    "start": "4742480",
    "end": "4747960"
  },
  {
    "text": "they will learn very slowly and badly. Um, initialization makes a difference.",
    "start": "4747960",
    "end": "4753270"
  },
  {
    "text": "Having good initialization often determines how well neural networks, um, learn.",
    "start": "4753270",
    "end": "4759040"
  },
  {
    "text": "Um, I have a separate slide here that I probably haven't got time to go through all of on sort of for sequence [NOISE] models,",
    "start": "4759040",
    "end": "4768225"
  },
  {
    "text": "some of the tips of what people normally think are good ways to get those models, um, working.",
    "start": "4768225",
    "end": "4775735"
  },
  {
    "text": "But I'll just say this one last thing. Um, I think the strategy that you really want to",
    "start": "4775735",
    "end": "4781850"
  },
  {
    "text": "take is to work incrementally and build up slowly. It just doesn't work to think,",
    "start": "4781850",
    "end": "4787489"
  },
  {
    "text": "\"Oh I've got the mother of all models, and build this enormously complex thing, and then run it on the data,",
    "start": "4787490",
    "end": "4793000"
  },
  {
    "text": "and it crashes and burns.\" You have no idea what to do at that point, that the only good way is to sort of build up slowly.",
    "start": "4793000",
    "end": "4800645"
  },
  {
    "text": "So [NOISE] start with a very simple model, get it to work, add your bells and whistles,",
    "start": "4800645",
    "end": "4805820"
  },
  {
    "text": "extra layers and so on. Get them to work or abandon them. And so, try and proceed from one working model to another as much as possible.",
    "start": "4805820",
    "end": "4814230"
  },
  {
    "text": "One of- another way that you can start small and build up is with data. The easiest way to see bugs and problems in your model,",
    "start": "4814230",
    "end": "4822580"
  },
  {
    "text": "is with the minutest possible amount of data. So, start with a dataset of eight items.",
    "start": "4822580",
    "end": "4829034"
  },
  {
    "text": "Sometimes it's even best if those eight items are ones that are artificial data that you designed yourself",
    "start": "4829035",
    "end": "4834925"
  },
  {
    "text": "because then you can often more easily see problems, and what's going wrong. So, you should train on that,",
    "start": "4834925",
    "end": "4840560"
  },
  {
    "text": "um, because it's only eight items, training will only take seconds, and that's really, really useful for being able to iterate quickly.",
    "start": "4840560",
    "end": "4847205"
  },
  {
    "text": "And you know, if you can't have your model get 100 percent accuracy on training and testing on those eight examples,",
    "start": "4847205",
    "end": "4855055"
  },
  {
    "text": "well, you know, either the model is woefully under powered or the model is broken, and you've got clear things to do right there.",
    "start": "4855055",
    "end": "4862900"
  },
  {
    "text": "Um, when you go to a bigger model, um, the standard practice with modern neural networks is,",
    "start": "4862900",
    "end": "4870115"
  },
  {
    "text": "you want to train your models. You want models that can overfit massively on the training set.",
    "start": "4870115",
    "end": "4876240"
  },
  {
    "text": "So, in general, your models should still be getting close to 100 percent accuracy on the training set after you've",
    "start": "4876240",
    "end": "4883375"
  },
  {
    "text": "trained it for a long time because powerful neural network models are just really good at over-fitting to, and memorizing data.",
    "start": "4883375",
    "end": "4891090"
  },
  {
    "text": "Um, if that's not the case well, you know, maybe you want a bigger model. Maybe you want to have higher hidden dimensions or",
    "start": "4891090",
    "end": "4898165"
  },
  {
    "text": "add an extra layer to your neural network or something like that. You shouldn't be scared of overfitting on the training data.",
    "start": "4898165",
    "end": "4904925"
  },
  {
    "text": "But once you've proved you can do that, you then do want a model that also generalizes well.",
    "start": "4904925",
    "end": "4910555"
  },
  {
    "text": "And so, normally the way that you're addressing that is then by regularizing the model, and there are different ways to regularize your model,",
    "start": "4910555",
    "end": "4917845"
  },
  {
    "text": "but we talked about in the assignment, doing dropout. I mean, using generous dropout is",
    "start": "4917845",
    "end": "4923755"
  },
  {
    "text": "one very common and effective strategy for regularizing your models. And so, then you've, what you want to be doing is regularizing",
    "start": "4923755",
    "end": "4931735"
  },
  {
    "text": "your model enough that the curve no longer looks like this, but instead that your validation performance kind of levels out,",
    "start": "4931735",
    "end": "4941095"
  },
  {
    "text": "but doesn't start ramping back up again, and that's then a sort of a sign of a well regularized model.",
    "start": "4941095",
    "end": "4946820"
  },
  {
    "text": "Okay. I will stop there, and then we'll come back to the question-answering project on Thursday.",
    "start": "4946820",
    "end": "4953310"
  }
]
[
  {
    "start": "0",
    "end": "6000"
  },
  {
    "text": "Hi, in this module,\nI'm going to talk",
    "start": "5900",
    "end": "7490"
  },
  {
    "start": "6000",
    "end": "13000"
  },
  {
    "text": "about how to use feature\ntemplates to organize",
    "start": "7490",
    "end": "10040"
  },
  {
    "text": "and construct your features\nin a very flexible way.",
    "start": "10040",
    "end": "14190"
  },
  {
    "start": "13000",
    "end": "105000"
  },
  {
    "text": "So recall that a\nhypothesis class",
    "start": "14190",
    "end": "16949"
  },
  {
    "text": "is a set of all\npredictors that a learning",
    "start": "16950",
    "end": "18960"
  },
  {
    "text": "algorithm is going to consider.",
    "start": "18960",
    "end": "21210"
  },
  {
    "text": "And then, in the case\nof linear predictors,",
    "start": "21210",
    "end": "23220"
  },
  {
    "text": "we've looked at\npredictors of function",
    "start": "23220",
    "end": "26519"
  },
  {
    "text": "of x to be equal to, in the\ncase of regression, w dot",
    "start": "26520",
    "end": "30610"
  },
  {
    "text": "phi of x, or in the\ncase of classification,",
    "start": "30610",
    "end": "33900"
  },
  {
    "text": "sign of that quantity.",
    "start": "33900",
    "end": "36390"
  },
  {
    "text": "And we allow the weight vectors\nto weight very freely, OK?",
    "start": "36390",
    "end": "39375"
  },
  {
    "text": "So we can visualize the\nhypothesis class as follows.",
    "start": "42200",
    "end": "45540"
  },
  {
    "text": "So imagine the space of\nall possible predictors,",
    "start": "45540",
    "end": "48260"
  },
  {
    "text": "all possible functions\nmapping x to y.",
    "start": "48260",
    "end": "51670"
  },
  {
    "text": "When you define a\nfeature extractor",
    "start": "51670",
    "end": "54640"
  },
  {
    "text": "phi, what you're\ndoing is committing",
    "start": "54640",
    "end": "56829"
  },
  {
    "text": "to a particular subset of\nall possible predictors.",
    "start": "56830",
    "end": "62030"
  },
  {
    "text": "And usually, you do this\nby using prior knowledge.",
    "start": "62030",
    "end": "66830"
  },
  {
    "text": "And the second part is\nthe learning algorithm,",
    "start": "66830",
    "end": "69980"
  },
  {
    "text": "where you're given script\nF, the hypothesis class,",
    "start": "69980",
    "end": "73820"
  },
  {
    "text": "and you're asking the\nlearning algorithm",
    "start": "73820",
    "end": "75530"
  },
  {
    "text": "to choose a particular predictor\nfrom that set, based on data.",
    "start": "75530",
    "end": "81590"
  },
  {
    "text": "So intuitively, we want the\nscript F hypothesis class",
    "start": "81590",
    "end": "85729"
  },
  {
    "text": "to contain the good\npredictors, of course.",
    "start": "85730",
    "end": "88940"
  },
  {
    "text": "But it can also\ncontain some bad ones,",
    "start": "88940",
    "end": "90830"
  },
  {
    "text": "because they will be filtered\nout based on the basis of data.",
    "start": "90830",
    "end": "94610"
  },
  {
    "text": "But we don't want it to be\ntoo big, so that the learning",
    "start": "94610",
    "end": "98060"
  },
  {
    "text": "algorithm has trouble\nidentifying good predictors",
    "start": "98060",
    "end": "101240"
  },
  {
    "text": "from the bad predictors.",
    "start": "101240",
    "end": "102500"
  },
  {
    "start": "105000",
    "end": "210000"
  },
  {
    "text": "So let's look at\nan example task.",
    "start": "105410",
    "end": "107890"
  },
  {
    "text": "And I want to give you an idea\nof how to choose the feature",
    "start": "107890",
    "end": "111760"
  },
  {
    "text": "extractor.",
    "start": "111760",
    "end": "113390"
  },
  {
    "text": "So suppose you're given a\nstring, such as abc@gmail.com",
    "start": "113390",
    "end": "118190"
  },
  {
    "text": "and you're asked to predict\nwhether this is a valid email",
    "start": "118190",
    "end": "122750"
  },
  {
    "text": "address or not using\na linear classifier.",
    "start": "122750",
    "end": "127110"
  },
  {
    "text": "So in this case,\nwhat we have to do",
    "start": "127110",
    "end": "130639"
  },
  {
    "text": "is to identify the\nfeature extractor phi.",
    "start": "130639",
    "end": "135590"
  },
  {
    "text": "So when you're designing\na feature extractor,",
    "start": "135590",
    "end": "137862"
  },
  {
    "text": "the main question\nyou ask yourself",
    "start": "137863",
    "end": "139280"
  },
  {
    "text": "is what properties\nof the input x",
    "start": "139280",
    "end": "142130"
  },
  {
    "text": "might be relevant\nfor predicting y?",
    "start": "142130",
    "end": "144795"
  },
  {
    "text": "Of course, you don't\nwant this necessarily",
    "start": "144795",
    "end": "146545"
  },
  {
    "text": "to commit to a particular\naspect to be important",
    "start": "146545",
    "end": "149920"
  },
  {
    "text": "because you don't know.",
    "start": "149920",
    "end": "150940"
  },
  {
    "text": "You want to learn\nthat from data.",
    "start": "150940",
    "end": "152590"
  },
  {
    "text": "But you should give the learning\nalgorithm some guidance.",
    "start": "152590",
    "end": "157920"
  },
  {
    "text": "So what we're going to do is\ndefine the feature extractor",
    "start": "157920",
    "end": "161030"
  },
  {
    "text": "as given x, produce a\nset of feature name,",
    "start": "161030",
    "end": "164390"
  },
  {
    "text": "feature value pairs.",
    "start": "164390",
    "end": "166743"
  },
  {
    "text": "So in this particular\nexample, the feature extractor",
    "start": "166743",
    "end": "168910"
  },
  {
    "text": "is going to produce\na feature vector.",
    "start": "168910",
    "end": "172030"
  },
  {
    "text": "And let's say, in this case,\nwe might look at the length.",
    "start": "172030",
    "end": "177550"
  },
  {
    "text": "Is it greater than 10?",
    "start": "177550",
    "end": "179230"
  },
  {
    "text": "In this case, it's\n1 because length",
    "start": "179230",
    "end": "182200"
  },
  {
    "text": "has something to do with\nwhether it's a value address.",
    "start": "182200",
    "end": "184870"
  },
  {
    "text": "The fraction of alphanumeric\ncharacters, 0.85 in this case.",
    "start": "184870",
    "end": "189220"
  },
  {
    "text": "Does it contain an @ sign?",
    "start": "189220",
    "end": "190960"
  },
  {
    "text": "That's 1 because it\ndoes contain an @ sign.",
    "start": "190960",
    "end": "194050"
  },
  {
    "text": "Ends with com, and it's 1 here.",
    "start": "194050",
    "end": "198400"
  },
  {
    "text": "And does it end with dot org?",
    "start": "198400",
    "end": "200470"
  },
  {
    "text": "And it's 0 here.",
    "start": "200470",
    "end": "203100"
  },
  {
    "text": "And so this is a\nfeature vector that we",
    "start": "203100",
    "end": "206990"
  },
  {
    "text": "might construct for this\nparticular application.",
    "start": "206990",
    "end": "211230"
  },
  {
    "start": "210000",
    "end": "327000"
  },
  {
    "text": "So now we go to prediction.",
    "start": "211230",
    "end": "213900"
  },
  {
    "text": "So remember that\nwe've previously",
    "start": "213900",
    "end": "216379"
  },
  {
    "text": "defined the feature vector\nto just be a real vector.",
    "start": "216380",
    "end": "220280"
  },
  {
    "text": "It's just a list of numbers.",
    "start": "220280",
    "end": "222060"
  },
  {
    "text": "So what we've done right now,\nis to just annotate or comment",
    "start": "222060",
    "end": "225980"
  },
  {
    "text": "each component of that feature\nvector with a name, that",
    "start": "225980",
    "end": "228920"
  },
  {
    "text": "describes what that\ncomponent is about.",
    "start": "228920",
    "end": "232550"
  },
  {
    "text": "We can do the same thing\nwith the corresponding weight",
    "start": "232550",
    "end": "234800"
  },
  {
    "text": "vector.",
    "start": "234800",
    "end": "235600"
  },
  {
    "text": "So here is a weight vector,\njust a list of numbers,",
    "start": "235600",
    "end": "237890"
  },
  {
    "text": "and we can annotate\neach component",
    "start": "237890",
    "end": "240230"
  },
  {
    "text": "with the name of the\ncorresponding phi.",
    "start": "240230",
    "end": "244280"
  },
  {
    "text": "And recall that the\nscore is just that the",
    "start": "244280",
    "end": "246255"
  },
  {
    "text": "dot product, w.phi of x.",
    "start": "246255",
    "end": "249020"
  },
  {
    "text": "And just to write\nout the dot product,",
    "start": "249020",
    "end": "251000"
  },
  {
    "text": "it's a sum over all the\nfeatures or components",
    "start": "251000",
    "end": "256940"
  },
  {
    "text": "of wj, the weight\nof that feature,",
    "start": "256940",
    "end": "259760"
  },
  {
    "text": "times the feature value, OK?",
    "start": "259760",
    "end": "263400"
  },
  {
    "text": "So here's an example.",
    "start": "263400",
    "end": "265410"
  },
  {
    "text": "The weight of length greater\nthan 10 is minus 1.2.",
    "start": "265410",
    "end": "269020"
  },
  {
    "text": "The feature value is 1.",
    "start": "269020",
    "end": "271490"
  },
  {
    "text": "So we have the\nproduct here, and you",
    "start": "271490",
    "end": "273038"
  },
  {
    "text": "have all the other features.",
    "start": "273038",
    "end": "274205"
  },
  {
    "text": "So a little piece\nof intuition here",
    "start": "277520",
    "end": "279699"
  },
  {
    "text": "is that you can think\nabout the score.",
    "start": "279700",
    "end": "281810"
  },
  {
    "text": "Remember, in classification,\npositive scores result",
    "start": "281810",
    "end": "286098"
  },
  {
    "text": "in positive classification,\nnegative scores",
    "start": "286098",
    "end": "287889"
  },
  {
    "text": "result in negative\nclassification.",
    "start": "287890",
    "end": "290110"
  },
  {
    "text": "You can think about each\nfeature as providing a vote.",
    "start": "290110",
    "end": "294610"
  },
  {
    "text": "You can think about if,\nlet's say, of phi of xj is 1.",
    "start": "294610",
    "end": "299289"
  },
  {
    "text": "And wj, if it's\npositive, that means",
    "start": "299290",
    "end": "301690"
  },
  {
    "text": "it's voting in favor of\npositive classification.",
    "start": "301690",
    "end": "306800"
  },
  {
    "text": "And if wj is negative,\nit's voting in favor",
    "start": "306800",
    "end": "310270"
  },
  {
    "text": "of negative classification.",
    "start": "310270",
    "end": "311860"
  },
  {
    "text": "And the magnitude of wj\ndetermines the strength",
    "start": "311860",
    "end": "314500"
  },
  {
    "text": "of the vote.",
    "start": "314500",
    "end": "316200"
  },
  {
    "text": "So that's another way to\ninterpret the dot product",
    "start": "316200",
    "end": "319190"
  },
  {
    "text": "before we previously saw\nthat we can interpret it",
    "start": "319190",
    "end": "321410"
  },
  {
    "text": "as the cosine of the\nangle, which is a more",
    "start": "321410",
    "end": "323540"
  },
  {
    "text": "geometric interpretation.",
    "start": "323540",
    "end": "325610"
  },
  {
    "start": "327000",
    "end": "430000"
  },
  {
    "text": "So, so far, we've\nseen that we can",
    "start": "328280",
    "end": "330310"
  },
  {
    "text": "take inputs to find arbitrary\nfeatures, extractors, get out",
    "start": "330310",
    "end": "333610"
  },
  {
    "text": "our feature vectors\ninto [INAUDIBLE]..",
    "start": "333610",
    "end": "336030"
  },
  {
    "text": "But how do we choose\nthese feature vectors?",
    "start": "336030",
    "end": "338910"
  },
  {
    "text": "I just kind of made up\nthe @, com, and org.",
    "start": "338910",
    "end": "342600"
  },
  {
    "text": "Which ones do we include?",
    "start": "342600",
    "end": "344460"
  },
  {
    "text": "So far we've used\nsome prior knowledge,",
    "start": "344460",
    "end": "346350"
  },
  {
    "text": "but it's very easy in\nthis manner to miss some.",
    "start": "346350",
    "end": "351030"
  },
  {
    "text": "What about suffixes like\nbeing in the US, for example?",
    "start": "351030",
    "end": "355680"
  },
  {
    "text": "We need a more systematic\nway of doing this.",
    "start": "355680",
    "end": "359789"
  },
  {
    "text": "And this is where feature\ntemplates comes in.",
    "start": "359790",
    "end": "363040"
  },
  {
    "text": "So a feature template is\nsimply a group of features",
    "start": "363040",
    "end": "366000"
  },
  {
    "text": "all computed in a similar way.",
    "start": "366000",
    "end": "369270"
  },
  {
    "text": "So here's an example.",
    "start": "369270",
    "end": "370349"
  },
  {
    "text": "So the input\nabc@gmail.com, we're",
    "start": "370350",
    "end": "373220"
  },
  {
    "text": "going to write the\nfeature template",
    "start": "373220",
    "end": "375050"
  },
  {
    "text": "as simply an English\ndescription with a blank.",
    "start": "375050",
    "end": "379069"
  },
  {
    "text": "And that blank is meant to be\nfilled in with an arbitrary",
    "start": "379070",
    "end": "381830"
  },
  {
    "text": "value, last three\ncharacters equals something.",
    "start": "381830",
    "end": "385580"
  },
  {
    "text": "And by instantiating\nthat blank with all sorts",
    "start": "385580",
    "end": "388639"
  },
  {
    "text": "of different values,\nthen we begin",
    "start": "388640",
    "end": "392060"
  },
  {
    "text": "to realize the\nfeature vectors that",
    "start": "392060",
    "end": "395990"
  },
  {
    "text": "are the features that\nare actually defined",
    "start": "395990",
    "end": "399492"
  },
  {
    "text": "by this feature template.",
    "start": "399493",
    "end": "400535"
  },
  {
    "text": "So the important part\nhere is that we no longer",
    "start": "404080",
    "end": "408280"
  },
  {
    "text": "have to say which\nsuffixes are important.",
    "start": "408280",
    "end": "411190"
  },
  {
    "text": "We don't have to say what\ntypes of patterns, what",
    "start": "411190",
    "end": "414370"
  },
  {
    "text": "particular patterns to look at.",
    "start": "414370",
    "end": "415930"
  },
  {
    "text": "We just have to know that\nthere exists some suffix that",
    "start": "415930",
    "end": "420250"
  },
  {
    "text": "might be important and define\nthis feature template letting",
    "start": "420250",
    "end": "423460"
  },
  {
    "text": "the learning algorithm sort out\nwhich of these many features",
    "start": "423460",
    "end": "426580"
  },
  {
    "text": "are actually relevant.",
    "start": "426580",
    "end": "427780"
  },
  {
    "start": "430000",
    "end": "548000"
  },
  {
    "text": "So if you continue this example,\nso the input is abc@gmail.com.",
    "start": "431450",
    "end": "435310"
  },
  {
    "text": "We define this feature\ntemplate, which",
    "start": "435310",
    "end": "437169"
  },
  {
    "text": "can be instantiated by\nsubstituting something",
    "start": "437170",
    "end": "440260"
  },
  {
    "text": "like dot com.",
    "start": "440260",
    "end": "441886"
  },
  {
    "text": "We can also define this\nother feature template,",
    "start": "441886",
    "end": "444220"
  },
  {
    "text": "length greater than blank.",
    "start": "444220",
    "end": "446440"
  },
  {
    "text": "And we can plug in 1, 2, 3, 4,\n5, 6, 7, 8, 9, 10, and so on,",
    "start": "446440",
    "end": "450610"
  },
  {
    "text": "into that.",
    "start": "450610",
    "end": "452020"
  },
  {
    "text": "Some feature templates\ndon't have a blank,",
    "start": "452020",
    "end": "455229"
  },
  {
    "text": "and that's OK because\nthat just corresponds",
    "start": "455230",
    "end": "457420"
  },
  {
    "text": "to specify one single\nfeature, and that",
    "start": "457420",
    "end": "459910"
  },
  {
    "text": "has a particular value.",
    "start": "459910",
    "end": "463120"
  },
  {
    "text": "So here's another example.",
    "start": "463120",
    "end": "464530"
  },
  {
    "text": "So suppose the input\nis an aerial image,",
    "start": "464530",
    "end": "467550"
  },
  {
    "text": "along with some metadata\nabout the location.",
    "start": "467550",
    "end": "470530"
  },
  {
    "text": "So you can go figure out\nwhere this actually is.",
    "start": "470530",
    "end": "474250"
  },
  {
    "text": "So the feature\ntemplate, in this case,",
    "start": "474250",
    "end": "476140"
  },
  {
    "text": "we might want to look\nat the following.",
    "start": "476140",
    "end": "479650"
  },
  {
    "text": "So we want to look at the\npixel intensity of this image",
    "start": "479650",
    "end": "482940"
  },
  {
    "text": "at a particular row and\na particular column.",
    "start": "482940",
    "end": "487770"
  },
  {
    "text": "And it's a color image, so\nthere's three channels, RGB,",
    "start": "487770",
    "end": "491280"
  },
  {
    "text": "so we identify a particular\nchannel that we're looking at.",
    "start": "491280",
    "end": "495730"
  },
  {
    "text": "So this might be instantiated\nas the pixel intensity of image",
    "start": "495730",
    "end": "498750"
  },
  {
    "text": "at row 10 and column\n93 red channel,",
    "start": "498750",
    "end": "502080"
  },
  {
    "text": "and that might have\na particular value.",
    "start": "502080",
    "end": "505521"
  },
  {
    "text": "Another feature\ntemplate might look",
    "start": "505522",
    "end": "506980"
  },
  {
    "text": "at the metadata,\nthe location, and be",
    "start": "506980",
    "end": "510700"
  },
  {
    "text": "a feature on whether\nthe latitude is",
    "start": "510700",
    "end": "513340"
  },
  {
    "text": "in a particular\nrange, and longitude",
    "start": "513340",
    "end": "515530"
  },
  {
    "text": "is in a particular range.",
    "start": "515530",
    "end": "517880"
  },
  {
    "text": "So this feature template\ngets instantiated,",
    "start": "517880",
    "end": "521469"
  },
  {
    "text": "might be instantiated\nwith particular values",
    "start": "521470",
    "end": "525310"
  },
  {
    "text": "that denote ranges.",
    "start": "525310",
    "end": "528520"
  },
  {
    "text": "So if you remember\npiecewise constant features,",
    "start": "528520",
    "end": "533380"
  },
  {
    "text": "this is an example of\npiecewise constant features",
    "start": "533380",
    "end": "535840"
  },
  {
    "text": "that carves up the world\ninto a bunch of regions",
    "start": "535840",
    "end": "540490"
  },
  {
    "text": "and has a feature of\nfiring if the Lat long is",
    "start": "540490",
    "end": "545080"
  },
  {
    "text": "in a particular region or not.",
    "start": "545080",
    "end": "546610"
  },
  {
    "start": "548000",
    "end": "585000"
  },
  {
    "text": "So one thing you might know\nis that feature templates are",
    "start": "550180",
    "end": "552750"
  },
  {
    "text": "pretty flexible, but\nsometimes, they can give rise",
    "start": "552750",
    "end": "555570"
  },
  {
    "text": "to a lot of features.",
    "start": "555570",
    "end": "556980"
  },
  {
    "text": "Last character equals blank,\nand there's already 26",
    "start": "556980",
    "end": "560639"
  },
  {
    "text": "if you only include\nthe lowercase letters.",
    "start": "560640",
    "end": "563940"
  },
  {
    "text": "And furthermore, most of\nthese feature values are 0.",
    "start": "563940",
    "end": "568810"
  },
  {
    "text": "So in these cases, this\nis what we mean when",
    "start": "568810",
    "end": "571960"
  },
  {
    "text": "a feature vector is sparse.",
    "start": "571960",
    "end": "573370"
  },
  {
    "text": "And you can actually represent\nsparse feature vectors",
    "start": "573370",
    "end": "577510"
  },
  {
    "text": "more compactly by\njust, as a dictionary,",
    "start": "577510",
    "end": "579700"
  },
  {
    "text": "mapping the feature name to\nthe actual feature value.",
    "start": "579700",
    "end": "584950"
  },
  {
    "text": "So in general,\nthere's two ways you",
    "start": "584950",
    "end": "587340"
  },
  {
    "start": "585000",
    "end": "669000"
  },
  {
    "text": "can represent feature vectors.",
    "start": "587340",
    "end": "590020"
  },
  {
    "text": "One is using arrays and\none is using dictionaries.",
    "start": "590020",
    "end": "593620"
  },
  {
    "text": "So if your feature\nvector looks like this,",
    "start": "593620",
    "end": "596410"
  },
  {
    "text": "which is dense or\nnot sparse, that",
    "start": "596410",
    "end": "598860"
  },
  {
    "text": "means all the feature\nvalues are mostly non-zero,",
    "start": "598860",
    "end": "602459"
  },
  {
    "text": "then you might want to just\nrepresent this as an array,",
    "start": "602460",
    "end": "605130"
  },
  {
    "text": "order the feature somehow,\nand just list out the numbers.",
    "start": "605130",
    "end": "608840"
  },
  {
    "text": "But in cases where your\nfeature vector looks like this,",
    "start": "608840",
    "end": "611350"
  },
  {
    "text": "and has lots of\n0's then, it will",
    "start": "611350",
    "end": "614500"
  },
  {
    "text": "be more efficient\nto represent this",
    "start": "614500",
    "end": "616210"
  },
  {
    "text": "as a dictionary, where, again,\nyou specify the feature name,",
    "start": "616210",
    "end": "620190"
  },
  {
    "text": "colon the feature value of\nonly the non-zero elements.",
    "start": "620190",
    "end": "625750"
  },
  {
    "text": "And by convention,\nanything that is not",
    "start": "625750",
    "end": "627760"
  },
  {
    "text": "mentioned as a value of 0.",
    "start": "627760",
    "end": "631600"
  },
  {
    "text": "So one interesting\nadvantage of sparse features",
    "start": "631600",
    "end": "634360"
  },
  {
    "text": "is that you don't have\nto a priori instantiate",
    "start": "634360",
    "end": "638230"
  },
  {
    "text": "all the features in advance.",
    "start": "638230",
    "end": "639850"
  },
  {
    "text": "You can, as data comes,\nyou only kind of lazily",
    "start": "639850",
    "end": "644110"
  },
  {
    "text": "build up these\nfeatures over time.",
    "start": "644110",
    "end": "646510"
  },
  {
    "text": "Whereas, if you were doing\nthings in a dense way,",
    "start": "646510",
    "end": "650170"
  },
  {
    "text": "you would have to predefine\nthe fixed set of features",
    "start": "650170",
    "end": "653560"
  },
  {
    "text": "that you are going\nto be working with.",
    "start": "653560",
    "end": "655700"
  },
  {
    "text": "Now in recent years\nwith deep learning,",
    "start": "655700",
    "end": "657730"
  },
  {
    "text": "dense features and arrays have\nbeen much more ubiquitous,",
    "start": "657730",
    "end": "662290"
  },
  {
    "text": "partly because you can take\nadvantage of fast matrix",
    "start": "662290",
    "end": "666130"
  },
  {
    "text": "computations on the GPT.",
    "start": "666130",
    "end": "670550"
  },
  {
    "start": "669000",
    "end": "712000"
  },
  {
    "text": "So to summarize, we want to\nidentify hypothesis classes.",
    "start": "670550",
    "end": "676640"
  },
  {
    "text": "And in this case, we're\nlooking at defining",
    "start": "676640",
    "end": "680390"
  },
  {
    "text": "the hypothesis class with\nrespect to the feature",
    "start": "680390",
    "end": "683240"
  },
  {
    "text": "extractor.",
    "start": "683240",
    "end": "684740"
  },
  {
    "text": "To define the\nfeature extractor, we",
    "start": "684740",
    "end": "686390"
  },
  {
    "text": "use feature templates, which\nis a convenient shorthand",
    "start": "686390",
    "end": "689630"
  },
  {
    "text": "for unrolling a single\nfeature template into a bunch",
    "start": "689630",
    "end": "693830"
  },
  {
    "text": "of different features.",
    "start": "693830",
    "end": "694970"
  },
  {
    "text": "We also saw that in some\ncases, the feature vectors",
    "start": "694970",
    "end": "697939"
  },
  {
    "text": "were sparse, and therefore,\nyou can use a dictionary",
    "start": "697940",
    "end": "700820"
  },
  {
    "text": "implementation to\nbe more efficient.",
    "start": "700820",
    "end": "703850"
  },
  {
    "text": "OK, so that's the end\nof this module, thanks.",
    "start": "703850",
    "end": "707060"
  }
]
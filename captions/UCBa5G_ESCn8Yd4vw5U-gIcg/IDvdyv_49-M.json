[
  {
    "start": "0",
    "end": "98000"
  },
  {
    "text": "I want to introduce Dr. Corso. He's a post-doctoral researcher\nhere in the Aeronautics",
    "start": "10365",
    "end": "15660"
  },
  {
    "text": "and Astronautics Department\nat Stanford University. He's, in particular, in the\nStanford Intelligent Systems",
    "start": "15660",
    "end": "21270"
  },
  {
    "text": "Laboratory under\nMykel Kochenderfer. That is the lab here that\nhas the best pronounceable",
    "start": "21270",
    "end": "26400"
  },
  {
    "text": "acronym which is SISL. He is also the\nexecutive director of the Stanford for AI--",
    "start": "26400",
    "end": "31620"
  },
  {
    "text": "Stanford Center for AI Safety,\nwhich is broadly the topic we're going to be\ntalking about today.",
    "start": "31620",
    "end": "37200"
  },
  {
    "text": "His research is focused on the\nuse of algorithmic decision making for safety\ncritical applications, emphasizing the creation of\nrobust, reliable autonomous",
    "start": "37200",
    "end": "45600"
  },
  {
    "text": "systems. And this is a really\nimportant topic. And obviously, it's been\nimportant for a long time.",
    "start": "45600",
    "end": "50635"
  },
  {
    "text": "And that's something\nthat Anthony and I will talk about a little bit. But it's also something that's\ncome to greater prominence,",
    "start": "50635",
    "end": "56620"
  },
  {
    "text": "and we are working with Anthony\nto create a seminar that we'll be offering in the last week of\nJuly on this particular topic.",
    "start": "56620",
    "end": "63660"
  },
  {
    "text": "We'll talk a little\nbit more about that at the end of the presentation. But if you're interested\nin learning more about it,",
    "start": "63660",
    "end": "69300"
  },
  {
    "text": "there is-- you should see\na little button right there on your screen\nthat you can click, and that will take\nyou to the course",
    "start": "69300",
    "end": "76140"
  },
  {
    "text": "page which has a rough\ndescription of what that will look like. All right.",
    "start": "76140",
    "end": "81340"
  },
  {
    "text": "With that, again, I want\nto remind you, at any time, feel free to ask your questions. But I'm going to just\nkick it off, Anthony.",
    "start": "81340",
    "end": "88930"
  },
  {
    "text": "Again, thank you for\njoining us here today. And I think probably\nthe place to start is if you could just introduce\nyourself a little bit more",
    "start": "88930",
    "end": "95800"
  },
  {
    "text": "by talking about your research. ANTHONY CORSO: Yeah. Thanks, Pax. And it's great to be here.",
    "start": "95800",
    "end": "101320"
  },
  {
    "start": "98000",
    "end": "204000"
  },
  {
    "text": "Thank you all for\nchoosing to spend 45 minutes with us talking\nabout this important topic.",
    "start": "101320",
    "end": "106900"
  },
  {
    "text": "So I did my master's and\nPhD in the Aeronautics and Astronautics Department\nhere at Stanford.",
    "start": "106900",
    "end": "116370"
  },
  {
    "text": "And a lot of the\nresearch that I did was thinking about\nthe ways in which we can use AI or algorithmic\ndecision making",
    "start": "116370",
    "end": "123990"
  },
  {
    "text": "to improve both the safety and\nefficiency of transportation setups. So something like a\nmillion people every year",
    "start": "123990",
    "end": "130949"
  },
  {
    "text": "die in car accidents. And so, if we can\nimprove the safety of things like\ndriving cars, then we",
    "start": "130949",
    "end": "137250"
  },
  {
    "text": "can save a lot of lives. And so, the topic\nthat I mostly studied was around the use of AI systems\nto perform these tasks safely.",
    "start": "137250",
    "end": "146310"
  },
  {
    "text": "But then, the question\nnaturally arises, how do you check\nwhether or not you've built a very safe system?",
    "start": "146310",
    "end": "152790"
  },
  {
    "text": "So I did my dissertation\nwork on developing algorithms that allow you to\nstress test and ensure",
    "start": "152790",
    "end": "158879"
  },
  {
    "text": "the safety of these really\nhigh-stakes systems. And since then, I've\ncarried on as a postdoc",
    "start": "158880",
    "end": "165330"
  },
  {
    "text": "and have continued to think\nabout the areas in which we use AI systems so that\nthey influence",
    "start": "165330",
    "end": "171332"
  },
  {
    "text": "and effect a lot of\npeople, and we really need to make sure that they\nare robust and reliable before deploying them.",
    "start": "171332",
    "end": "178433"
  },
  {
    "text": "SPEAKER: That's great. So Anthony, I think maybe\nwe can take a step back. So there are kind of a couple--\nthere are a couple of things",
    "start": "178433",
    "end": "183519"
  },
  {
    "text": "there, and we already\nhave a good question just about some of the terminology,\nabout what it means",
    "start": "183520",
    "end": "188650"
  },
  {
    "text": "for a system to be robust. But I think maybe we start is--\ncan we dig a little bit deeper",
    "start": "188650",
    "end": "194620"
  },
  {
    "text": "on autonomous systems? So you primarily worked with\nsystems in transportation.",
    "start": "194620",
    "end": "200290"
  },
  {
    "text": "So cars, airplanes, drones,\nthose kinds of things. Could you talk a little bit\nmore about autonomous systems",
    "start": "200290",
    "end": "207100"
  },
  {
    "start": "204000",
    "end": "283000"
  },
  {
    "text": "and what you're thinking of,\nwhat that broadly covers, and what the risks are\ninvolved with those? You've already touched on it\nin terms of car accidents,",
    "start": "207100",
    "end": "213970"
  },
  {
    "text": "but can you build on\nthat a little bit? ANTHONY CORSO: Yeah, absolutely. So I think of autonomous\nsystems as really any system",
    "start": "213970",
    "end": "220540"
  },
  {
    "text": "that's going to perform\na task that historically has been done by a human. So this can be--",
    "start": "220540",
    "end": "225910"
  },
  {
    "text": "driving cars is a prime example. And autonomous\nsystems, although we've",
    "start": "225910",
    "end": "230920"
  },
  {
    "text": "had autonomous systems\nfor a very long time, people are think-- are becoming\nmuch more aware of them",
    "start": "230920",
    "end": "236020"
  },
  {
    "text": "with the advent of AI and\nmachine learning, which are techniques that allow\ncomputer systems to learn",
    "start": "236020",
    "end": "242200"
  },
  {
    "text": "from data and basically enable\nus to process information in real time and enable this\nhigher level of autonomy",
    "start": "242200",
    "end": "248680"
  },
  {
    "text": "that we've been seeing over\nthe past couple of years. The problem is, however, that\na lot of these technologies,",
    "start": "248680",
    "end": "254410"
  },
  {
    "text": "although they are\nabsolutely amazing and enable us to do\nincredible things, often fail in kind\nof unexpected ways.",
    "start": "254410",
    "end": "261578"
  },
  {
    "text": "They tend to be a\nlittle bit more brittle than, say, humans are. So they may work in a\nvery controlled, say,",
    "start": "261579",
    "end": "267130"
  },
  {
    "text": "laboratory setting. But as soon as you deploy these\nsystems and the environment changes ever so\nslightly, you can",
    "start": "267130",
    "end": "272803"
  },
  {
    "text": "begin running into problems. And this is, of\ncourse, very dangerous if you're deploying\nthese systems in a domain",
    "start": "272803",
    "end": "278080"
  },
  {
    "text": "like driving where\npeople's lives are at risk.",
    "start": "278080",
    "end": "283169"
  },
  {
    "start": "283000",
    "end": "373000"
  },
  {
    "text": "SPEAKER: And could you-- yeah, I actually have\nsomething I want to circle back on to about safety--\nbut could we",
    "start": "283170",
    "end": "288630"
  },
  {
    "text": "elaborate on the brittleness\nof some of these systems? Can you build on\nwhat that means? So it's kind of at\nthe core, it just",
    "start": "288630",
    "end": "294990"
  },
  {
    "text": "means that they fail in ways\nthat humans might not, or is it that they fail\ndifferently than humans?",
    "start": "294990",
    "end": "300570"
  },
  {
    "text": "Are they more likely to fail? Or they just don't\ngeneralize, I guess, would be the term maybe\nthe way humans might.",
    "start": "300570",
    "end": "307560"
  },
  {
    "text": "ANTHONY CORSO: Yeah, so it\ncan be a little bit of both. I'll start with\nmaybe an example. So folks showed that, for\nexample, you can maybe--",
    "start": "307560",
    "end": "315810"
  },
  {
    "text": "if you collect data from\na certain geographic area, let's say, for\nmaybe we're building",
    "start": "315810",
    "end": "321990"
  },
  {
    "text": "a system that can identify\npedestrians on the road. If you collect a bunch of data\nfrom a certain geographic area,",
    "start": "321990",
    "end": "328200"
  },
  {
    "text": "and then you train a\nmachine learning model to detect pedestrians,\nyou're likely to build a very reliable model that can\ndetect pedestrian really well.",
    "start": "328200",
    "end": "337530"
  },
  {
    "text": "The problem is if you then try\nto deploy that model in, say, a different geographic\ndomain where",
    "start": "337530",
    "end": "342630"
  },
  {
    "text": "things are slightly different. So maybe the crosswalk looks\na little bit different, or people tend to wear different\nclothes or something like that.",
    "start": "342630",
    "end": "349061"
  },
  {
    "text": "And all of a sudden,\nwhat we see is that these machine learning\nmodels' performances can drop pretty\ndramatically, even",
    "start": "349062",
    "end": "355199"
  },
  {
    "text": "though the differences in\nkind of the environment are quite subtle. And humans don't really\nhave this problem.",
    "start": "355200",
    "end": "360630"
  },
  {
    "text": "We were able to\ngeneralize fairly well across a variety of factors.",
    "start": "360630",
    "end": "365703"
  },
  {
    "text": "SPEAKER: That's great. And we're wired,\nand thank you again. I want to remind you,\nif you have questions, feel free to post them.",
    "start": "365703",
    "end": "370888"
  },
  {
    "text": "We're already getting\na ton of those. But I want to build on this\nmaybe a little bit more and circle back to\nsomething before we move on",
    "start": "370888",
    "end": "378319"
  },
  {
    "start": "373000",
    "end": "464000"
  },
  {
    "text": "is you-- when you initially\nsaid it, part of what got you interested is not to\nensure the safety of AI systems",
    "start": "378320",
    "end": "385500"
  },
  {
    "text": "but the way in which AI\nsystems or autonomous systems can improve our safety, right? So could you elaborate on\nthat kind of the flip side?",
    "start": "385500",
    "end": "391892"
  },
  {
    "text": "So it's not just\nthat you're trying to ensure that systems are\nsafer, but it's also the case that maybe AI systems\ncan do things more safely",
    "start": "391892",
    "end": "400010"
  },
  {
    "text": "than humans potentially\nin certain domains. Could you elaborate on that? ANTHONY CORSO: Yeah, absolutely. So one of the reasons I'm so\nexcited about AI in general",
    "start": "400010",
    "end": "408419"
  },
  {
    "text": "is this possibility\nthat we can have systems that perform, for\nexample much, much better than a human at a variety\nof tasks we really care about.",
    "start": "408420",
    "end": "415960"
  },
  {
    "text": "So I think a great example\nof this would be health care. So if you have an AI system\nthat was maybe even just as",
    "start": "415960",
    "end": "421890"
  },
  {
    "text": "good as the world's\nbest doctor, you could deploy that\nsystem very widely across the world providing\nhealth care access to people",
    "start": "421890",
    "end": "428580"
  },
  {
    "text": "who wouldn't otherwise get it. Or likewise, flying aircraft\nor flying or driving vehicles,",
    "start": "428580",
    "end": "434460"
  },
  {
    "text": "these are things that although\nhumans do fairly well, we can really improve\nthe safety of, and that can be really\nbeneficial for everyone.",
    "start": "434460",
    "end": "441860"
  },
  {
    "text": "But of course, as soon as you\nstart thinking in those terms, you have to be\ncareful because what we're talking about with AI\nsystems is it allows it to--",
    "start": "441860",
    "end": "450210"
  },
  {
    "text": "allows us to scale these\nsystems out to a ton of people. And so, then, any risk\nthat's inherent in the system",
    "start": "450210",
    "end": "456509"
  },
  {
    "text": "is now a risk affecting\nmany, many, many more people. And so, we have to be extremely\ncareful before actually",
    "start": "456510",
    "end": "461970"
  },
  {
    "text": "deploying these systems\nout into the world. SPEAKER: That's\nreally interesting. So part of it, part of what\nthe particular challenge",
    "start": "461970",
    "end": "468060"
  },
  {
    "start": "464000",
    "end": "538000"
  },
  {
    "text": "with these systems is how\nscalable they are, right? So if I make a\nmistake as a driver-- I'm a single driver, right?",
    "start": "468060",
    "end": "474270"
  },
  {
    "text": "And that potentially\nhas local consequences. But it's not like I am\ndriving everyone's car. Whereas what you're\nproposing is,",
    "start": "474270",
    "end": "480270"
  },
  {
    "text": "or what people are\ntrying to achieve is a system that\nwill be deployed across all of the United\nStates, all of the world.",
    "start": "480270",
    "end": "486250"
  },
  {
    "text": "And so, the-- ANTHONY CORSO:\nYeah, and actually along those lines, another issue\nthat-- another sort of problem",
    "start": "486250",
    "end": "492330"
  },
  {
    "text": "that AI systems tend\nto face is that they can be fairly susceptible to\nwhat we call adversarial attack",
    "start": "492330",
    "end": "497880"
  },
  {
    "text": "or basically like intentional\nmanipulation by people. And so, you can do-- there's\nbeen some research where people",
    "start": "497880",
    "end": "504810"
  },
  {
    "text": "can, for example, print out a\nsticker that just kind of looks like maybe a sticker you\nwould see out in the world,",
    "start": "504810",
    "end": "510449"
  },
  {
    "text": "post it on a stop\nsign, and it can make a machine learning system\nthink that stop sign is now",
    "start": "510450",
    "end": "516030"
  },
  {
    "text": "a speed limit 45 sign. And so, this could be\nextremely dangerous. And like you said,\nit's not just going to affect that one system.",
    "start": "516030",
    "end": "522729"
  },
  {
    "text": "But if all the cars on the road\nare using the same algorithm, then they can all be influenced\nby this one sort of attack.",
    "start": "522730",
    "end": "527920"
  },
  {
    "text": "And so, that's one\nof the reasons why we need to be extra\ncareful with sort of testing and verification\nof these systems.",
    "start": "527920",
    "end": "535060"
  },
  {
    "text": "SPEAKER: So I do-- I want to-- there was one\nparticular question I think is maybe-- before we move on-- is there's\na question about if there",
    "start": "535060",
    "end": "541230"
  },
  {
    "start": "538000",
    "end": "679000"
  },
  {
    "text": "are additional risks\nfor, say, big trucks or little or different kinds\nof vehicles on the road.",
    "start": "541230",
    "end": "547033"
  },
  {
    "text": "And so, could you just talk a\nlittle bit about when you're thinking about\ndeploying these systems, I mean, how generalizable\nare these systems",
    "start": "547033",
    "end": "556055"
  },
  {
    "text": "across the class of vehicle,\nthose kinds of things? I mean, what are some\nof those considerations? Again, we're probably, I guess,\nhere we're talking about cars,",
    "start": "556055",
    "end": "563280"
  },
  {
    "text": "but it could apply\nto airplanes, right? I mean, can the same system\ngo in a 747 versus a Cessna,",
    "start": "563280",
    "end": "569190"
  },
  {
    "text": "and what are some of\nthose considerations? ANTHONY CORSO: Yeah. So I think of AI safety\nas sort of like you",
    "start": "569190",
    "end": "577235"
  },
  {
    "text": "have to multiply, sort of like\nthe likelihood of a failure event occurring times the\nmagnitude of the consequences",
    "start": "577235",
    "end": "583019"
  },
  {
    "text": "of that failure event. And together, that gives you\nsort of like your overall risk. So if you think about a\nsystem like an aircraft",
    "start": "583020",
    "end": "590130"
  },
  {
    "text": "which has an extremely high\nconsequence if something goes wrong-- because very bad\nthings can happen",
    "start": "590130",
    "end": "596580"
  },
  {
    "text": "if you do something\nwrong on an aircraft-- so you need a correspondingly\nextremely small probability",
    "start": "596580",
    "end": "602540"
  },
  {
    "text": "of failure. So the FAA, for\nexample, tries to ensure that their systems\nfail no more than one",
    "start": "602540",
    "end": "608820"
  },
  {
    "text": "in about billion\nhours of flight time. So it's extremely,\nextremely safe",
    "start": "608820",
    "end": "614190"
  },
  {
    "text": "as we've all come to expect. Now on the flip side\nof that, if you're thinking about deploying a\nmachine learning model to,",
    "start": "614190",
    "end": "620250"
  },
  {
    "text": "say, for example,\nserve ads to users as they come to your website,\nthe risk of making a mistake",
    "start": "620250",
    "end": "626070"
  },
  {
    "text": "there is relatively low. If you serve someone\nthe wrong ad, perhaps they just don't go on\nthe thing that you sell them.",
    "start": "626070",
    "end": "633100"
  },
  {
    "text": "And so, the risk is kind of low. So we can tolerate much\nhigher rates of failure in domains like that. And I think that\nthere's basically",
    "start": "633100",
    "end": "638730"
  },
  {
    "text": "a whole spectrum here. Now everyone wants their machine\nlearning model or AI system to be as reliable as possible.",
    "start": "638730",
    "end": "645090"
  },
  {
    "text": "But it becomes all\nthe more important as those consequences\nget higher. And so, to the question around\nvariety of road vehicles",
    "start": "645090",
    "end": "653587"
  },
  {
    "text": "and things like that,\nwe have to think about what is the\ndomain in which they're going to be operated. And so, for example,\nare they going",
    "start": "653587",
    "end": "659790"
  },
  {
    "text": "to be driving downtown\ncity streets in New York? Or are they going to be\ndriving at an open pit mine",
    "start": "659790",
    "end": "664949"
  },
  {
    "text": "where there aren't any\nother people around? And so, the context\nreally matters when it comes to safety.",
    "start": "664950",
    "end": "670593"
  },
  {
    "text": "SPEAKER: That's great,\nand we're getting a lot of really good questions. But I want to-- maybe before\ngetting to some of those--",
    "start": "670593",
    "end": "678110"
  },
  {
    "text": "I do want to-- I want to address\nsomething that's-- the conversation we're\nhaving right now is very--",
    "start": "678110",
    "end": "684440"
  },
  {
    "start": "679000",
    "end": "797000"
  },
  {
    "text": "and where your specialty is is\nthinking about these autonomous systems, how to\nbuild safe systems, and also how to verify the\nsafety of those systems.",
    "start": "684440",
    "end": "691490"
  },
  {
    "text": "But right now, obviously,\none of the top hot topics on Twitter around AI\nsafety is this exis-- is the question of\nexistential risk, right?",
    "start": "691490",
    "end": "698172"
  },
  {
    "text": "Is AI going to-- this is like the Terminator\nor SkyNet scenario.",
    "start": "698172",
    "end": "703820"
  },
  {
    "text": "Could you talk a little bit\nabout what you're talking about and what you'll be\nteaching the summer, and how it might\nor might not relate",
    "start": "703820",
    "end": "709760"
  },
  {
    "text": "to that question of\nexistential risk? ANTHONY CORSO: Yeah, absolutely. So maybe first, I'll\nbriefly articulate",
    "start": "709760",
    "end": "715040"
  },
  {
    "text": "what I think the argument\naround existential risk is. And then, I'll talk about\nhow the summer seminar might",
    "start": "715040",
    "end": "720532"
  },
  {
    "text": "or might not relate to that. So the basic idea\nis that as we build more and more capable\nand competent autonomous",
    "start": "720533",
    "end": "726649"
  },
  {
    "text": "systems that are more widely\nintegrated into our society, the risk is that either\ndue to these problems",
    "start": "726650",
    "end": "733880"
  },
  {
    "text": "of a lack of\nrobustness or what's often called a misalignment\nin their objectives. So we ask the super-competent\nAI system to do one thing.",
    "start": "733880",
    "end": "742310"
  },
  {
    "text": "And in pursuit of\nthat one thing, it maybe destroys a lot of\nother things that we care about.",
    "start": "742310",
    "end": "747690"
  },
  {
    "text": "And so, this is\nsomething that people are beginning to think more\nabout as the systems get",
    "start": "747690",
    "end": "753440"
  },
  {
    "text": "better and better over time. But the topic of my\nresearch is a little bit divorced from that in that I\nthink about systems that are",
    "start": "753440",
    "end": "760850"
  },
  {
    "text": "literally on the roads today. So for example, you\ncan go to, I think, Phoenix and San Francisco and\nactually get a self-driving car",
    "start": "760850",
    "end": "768623"
  },
  {
    "text": "with no safety driver in it. You can get in that car, and\nit will take you from point A to point B. So I'm sort of most concerned\nabout the systems that are",
    "start": "768623",
    "end": "775339"
  },
  {
    "text": "out there in the world today. But what I will say is that\nmany of the problems that exist in these systems like a\nlack of robustness or security",
    "start": "775340",
    "end": "782630"
  },
  {
    "text": "flaws and things of that\nnature could exacerbate this problem of existential\nrisk down the line when we have",
    "start": "782630",
    "end": "789740"
  },
  {
    "text": "more and more concrete systems. So I think thinking about these\nproblems early on is really important to kind of mitigating\nthose risks going forward",
    "start": "789740",
    "end": "796459"
  },
  {
    "text": "as well. SPEAKER: That's great, and do--\nthis is kind of again on that high level-- you know, at this level,\nwhere does ethics--",
    "start": "796460",
    "end": "804855"
  },
  {
    "start": "797000",
    "end": "879000"
  },
  {
    "text": "this is a question\nthat came in earlier from one of the participants--\nwhere does ethics come in? Or that question-- you know, how\ndo you consider that or think",
    "start": "804855",
    "end": "814230"
  },
  {
    "text": "about that? Or is that maybe at a level up\nfrom these very concrete sort of technical problems that\nyou're trying to address?",
    "start": "814230",
    "end": "820500"
  },
  {
    "text": "ANTHONY CORSO: Yeah, so\nthat's a fantastic question. And it's an extremely\nimportant piece of the whole deployment\nof AI systems,",
    "start": "820500",
    "end": "826850"
  },
  {
    "text": "ensuring that these\nsystems are deployed in a way that's equitable\nand fair to all groups.",
    "start": "826850",
    "end": "832100"
  },
  {
    "text": "And in fact, you can even\nthink about this that the risk that, say, an AI system\nwill behave differently",
    "start": "832100",
    "end": "838070"
  },
  {
    "text": "in different subgroups of\npeople based on gender or race or something like that. That's essentially\na lack of robustness",
    "start": "838070",
    "end": "844160"
  },
  {
    "text": "to various subgroups. And so, this is a problem that\nwe absolutely need to mitigate.",
    "start": "844160",
    "end": "852260"
  },
  {
    "text": "It's a problem that\ncomes from the data sets that we have-- humans\nhave generated. We have bias in our\nsociety and that",
    "start": "852260",
    "end": "858230"
  },
  {
    "text": "to show up in the data\nsets that we make, but it can also be issues\nwith the model or models",
    "start": "858230",
    "end": "864770"
  },
  {
    "text": "that we use to train\non those data sets that will pick up on\nspurious correlations and things of that nature.",
    "start": "864770",
    "end": "870733"
  },
  {
    "text": "So these are the\ntypes of problems that we need to address\nand that we'll be talking about in the seminar.",
    "start": "870733",
    "end": "877459"
  },
  {
    "text": "SPEAKER: Can we dig a\nlittle bit deeper on those? We're getting a lot of\nreally great questions. So I'm just going to summarize. So there are a lot of questions\nabout specific applications,",
    "start": "877460",
    "end": "885470"
  },
  {
    "start": "879000",
    "end": "929000"
  },
  {
    "text": "particularly around,\nsay, using warehouses or industrial machinery. So I think maybe we can come\nback to that in the end.",
    "start": "885470",
    "end": "892399"
  },
  {
    "text": "But my sense is\nsome of what you're working on applies across\nthese kinds of machines though your expertise\nis really in working",
    "start": "892400",
    "end": "899720"
  },
  {
    "text": "with self-driving cars, with\nAVA, with airplanes or drones.",
    "start": "899720",
    "end": "905540"
  },
  {
    "text": "My sense is it applies\nacross the kind of fundamental,\ntheoretical concerns that you're addressing do\napply across those domains.",
    "start": "905540",
    "end": "913310"
  },
  {
    "text": "Is that-- could you-- actually, before we do\nthat, could we then perhaps take a step back and just--",
    "start": "913310",
    "end": "919580"
  },
  {
    "text": "you've already articulated\nit but maybe articulating it again. So there are kind of two\naspects to this, right?",
    "start": "919580",
    "end": "924890"
  },
  {
    "text": "There's building, and there's\nverification, is that correct? Could you just-- ANTHONY CORSO:\nYeah, that's right. SPEAKER: --elaborate? I mean, you just touched on\nthat, so could you elaborate?",
    "start": "924890",
    "end": "932190"
  },
  {
    "start": "929000",
    "end": "1260000"
  },
  {
    "text": "When you're thinking about\ndesigning an AI system, what are the kind of steps or\nthe different aspects where",
    "start": "932190",
    "end": "937620"
  },
  {
    "text": "you're thinking about safety\nand just building out on those? ANTHONY CORSO: Yeah, absolutely. That's a great question.",
    "start": "937620",
    "end": "943980"
  },
  {
    "text": "So first to your\noriginal point, I do think that a lot of what\nwe're about to talk about here basically applies across all\nsorts of application domains",
    "start": "943980",
    "end": "951690"
  },
  {
    "text": "because a lot of the core\nunderlying technology is very, very similar. So yeah, as Pax mentioned, you\nhave two phases, I would say,",
    "start": "951690",
    "end": "961140"
  },
  {
    "text": "very broadly speaking, when\ndesigning an autonomous system for a high-stakes application. The first is just\nbuilding that system.",
    "start": "961140",
    "end": "968543"
  },
  {
    "text": "And so, when we\nbuild that system, we have to kind of do\na variety of things to ensure that\nwe're building kind",
    "start": "968543",
    "end": "974430"
  },
  {
    "text": "of the best possible system. So maybe that means we're\ncollecting data and making sure we have enough data, or\nour data is diverse enough",
    "start": "974430",
    "end": "980820"
  },
  {
    "text": "to cover all the aspects of\nproblem we're trying to solve. We need to ensure\nthat we're using",
    "start": "980820",
    "end": "986160"
  },
  {
    "text": "kind of the latest and\ngreatest methods, engineering methods that are known\nto kind of behave",
    "start": "986160",
    "end": "991410"
  },
  {
    "text": "in a safe or more reliable way. And then, once we've\ndone that, so maybe we've",
    "start": "991410",
    "end": "996510"
  },
  {
    "text": "created a system that we think\nis very safe because we've used all of the practices. We've collected data.",
    "start": "996510",
    "end": "1001950"
  },
  {
    "text": "We've done some preliminary\nexperimentation, and things seem\nto be going well.",
    "start": "1001950",
    "end": "1007410"
  },
  {
    "text": "But the second phase of\nthis before deployment is we really need\nto understand what can go on-- what can\ngo wrong, and what",
    "start": "1007410",
    "end": "1014089"
  },
  {
    "text": "are the risks if we deploy it. And this can be a whole\nseparate challenge.",
    "start": "1014090",
    "end": "1020070"
  },
  {
    "text": "So I'll actually give a short\nanecdote to illustrate this. So my advisor, Professor\nMykel Kochenderfer",
    "start": "1020070",
    "end": "1026060"
  },
  {
    "text": "helped develop the next\ngeneration of aircraft collision avoidance. So these are systems that are\nonboard all commercial aircraft",
    "start": "1026060",
    "end": "1033050"
  },
  {
    "text": "that basically ensure\nthat if there's the potential for some\nmidair collision, then it alerts both pilots\nto make a maneuver",
    "start": "1033050",
    "end": "1039559"
  },
  {
    "text": "to ensure that does not happen. And so, he started\nworking on this project,",
    "start": "1039560",
    "end": "1046369"
  },
  {
    "text": "I believe, around 2011. And they built prototypes\nof it, and they designed an extremely safe system.",
    "start": "1046369",
    "end": "1052610"
  },
  {
    "text": "But it took an\nadditional eight years of verification and validation\nto build enough trust",
    "start": "1052610",
    "end": "1057980"
  },
  {
    "text": "in that system to get\nthe FAA stamp of-- and this is already when\nthe system was safe enough. They just had to insure it.",
    "start": "1057980",
    "end": "1063980"
  },
  {
    "text": "They had to build\nthe trust in it in order to make sure\neveryone is confident that what they were deploying\nwas going to actually be safe.",
    "start": "1063980",
    "end": "1070380"
  },
  {
    "text": "And so, both of those\naspects, the designing of the system and the\ntest and evaluation, are both crucial pieces\nof eventually deploying",
    "start": "1070380",
    "end": "1078740"
  },
  {
    "text": "a safe system. SPEAKER: And so--\nand we're going to get into this when we\ntalk through the class-- but can you talk\na little bit more",
    "start": "1078740",
    "end": "1083997"
  },
  {
    "text": "about the verification piece? I know you've done a\nlot of work around that, really interesting work\naround formal verification",
    "start": "1083997",
    "end": "1090770"
  },
  {
    "text": "as well as-- I'm going to get this\nwrong-- but like a rare event or robust training.",
    "start": "1090770",
    "end": "1096085"
  },
  {
    "text": "So could you talk a little\nbit about maybe focusing on your research but\nthe kinds of things that are important for verification,\nboth to ensure that a system is",
    "start": "1096085",
    "end": "1103039"
  },
  {
    "text": "safe but also-- and we got a question\nabout selling AI, but that's kind of related\nto your last point--",
    "start": "1103040",
    "end": "1108889"
  },
  {
    "text": "but also in communicating\nor showing and demonstrating that safety to people\nwho might be using it?",
    "start": "1108890",
    "end": "1115107"
  },
  {
    "text": "ANTHONY CORSO: Yeah. That's a great question. So I'll talk a little bit\nabout my dissertation work because it's very near to dear--\nnear and dear to my heart.",
    "start": "1115107",
    "end": "1122040"
  },
  {
    "text": "And so, this is around basically\nthe analysis or the testing of extremely safe systems.",
    "start": "1122040",
    "end": "1128580"
  },
  {
    "text": "So for example, if we're\ndesigning a self-driving car, we want to make sure\nthat self-driving car is",
    "start": "1128580",
    "end": "1134720"
  },
  {
    "text": "much, much safer than a human. So for example, maybe we\nwant it to be 10 times safer than the average human driver.",
    "start": "1134720",
    "end": "1140930"
  },
  {
    "text": "And what that means is that this\nwill have basically a failure rate of something less\nthan 1 in 10 to the 7th.",
    "start": "1140930",
    "end": "1148520"
  },
  {
    "text": "So 1 in 10 million\nchance of, say, causing a collision for\nevery hour on the road.",
    "start": "1148520",
    "end": "1155130"
  },
  {
    "text": "And so, this poses\na real challenge because if I make\na system, how do I",
    "start": "1155130",
    "end": "1160700"
  },
  {
    "text": "know that it's going\nto fail only 1 in 10 to the 7th rather than\n1 in 10 to the 6th? I would have to drive that car\nhundreds of millions of miles",
    "start": "1160700",
    "end": "1168740"
  },
  {
    "text": "to ensure that it was hitting\nthat correct level of safety. And so, this is\nthe problem that we call in the research community,\nthe problem of rare events.",
    "start": "1168740",
    "end": "1177510"
  },
  {
    "text": "So these failure events\nare extremely rare. And if we were to just sort of\nnaively go throughout our day,",
    "start": "1177510",
    "end": "1182600"
  },
  {
    "text": "maybe simulating our\nautonomous vehicle in sort of nominal\nconditions, we're very unlikely to encounter\nthese failure events.",
    "start": "1182600",
    "end": "1190429"
  },
  {
    "text": "So the focus of my\ndissertation work was around how can\nwe actually increase",
    "start": "1190430",
    "end": "1195529"
  },
  {
    "text": "the likelihood of encountering\none of these failure events. And the way we did this\nwas actually handing",
    "start": "1195530",
    "end": "1200900"
  },
  {
    "text": "control over the environment. And the environment in\nthis case would just have maybe pedestrians\non the road,",
    "start": "1200900",
    "end": "1206870"
  },
  {
    "text": "other vehicles on the road,\nmaybe weather and lighting conditions, things that\ncould affect the performance",
    "start": "1206870",
    "end": "1212330"
  },
  {
    "text": "of our automated vehicle. And we would hand over those\naspects of the environment",
    "start": "1212330",
    "end": "1218480"
  },
  {
    "text": "to another AI agent. And that AI agent\nwould be trained to try to uncover\nfailures of the system.",
    "start": "1218480",
    "end": "1225050"
  },
  {
    "text": "So it would actually try to\nmanipulate the environment in such a way as to cause our\nautonomous vehicle to fail.",
    "start": "1225050",
    "end": "1231200"
  },
  {
    "text": "So it's kind of a\nlittle bit backwards. We think of AI as doing what it\ncan to, say, avoid collisions",
    "start": "1231200",
    "end": "1237130"
  },
  {
    "text": "or something like that. But this was using AI\nto actually discover the weaknesses of our\nautomated vehicle.",
    "start": "1237130",
    "end": "1242470"
  },
  {
    "text": "And we can do-- and\nwhen we do that, we can uncover a whole bunch\nof possible failure modes. And when we do, we can--",
    "start": "1242470",
    "end": "1248980"
  },
  {
    "text": "basically allows\nus to understand what are the weaknesses\nof our system. Are we OK with the failure\nmodes that we found?",
    "start": "1248980",
    "end": "1254425"
  },
  {
    "text": "Or do we need to go back\nto the drawing board and fix some of these\nthings before we deploy it?",
    "start": "1254425",
    "end": "1260477"
  },
  {
    "start": "1260000",
    "end": "1325000"
  },
  {
    "text": "SPEAKER: And that's great. And so, and could we-- OK, so there's this\nkind of a question, we've got rare events.",
    "start": "1260477",
    "end": "1265520"
  },
  {
    "text": "You're going to be\ntesting something that's so safe that in theory,\nthat the kinds of events that cause a failure\nare really, really rare.",
    "start": "1265520",
    "end": "1272120"
  },
  {
    "text": "And so, how do you-- how do you uncover those\nbefore they happen? I'm assuming this\ncould also in theory be applied to non-AI\nsystems, right?",
    "start": "1272120",
    "end": "1278690"
  },
  {
    "text": "You could-- I assume, a similar\nmodel could be used to stress test structures,\nto stress test--",
    "start": "1278690",
    "end": "1284299"
  },
  {
    "text": "not stress test but to test\nthe modeling of a structure or just the design of\na mechanical system.",
    "start": "1284300",
    "end": "1290990"
  },
  {
    "text": "ANTHONY CORSO: Indeed, so\nyou definitely could do that. The difference is\nthat in-- oftentimes, in more traditional systems,\nyou don't need this approach",
    "start": "1290990",
    "end": "1298220"
  },
  {
    "text": "because you can reason about\nthe safety of the system from sort of first principles. Like, you know what\nit's made up of.",
    "start": "1298220",
    "end": "1304309"
  },
  {
    "text": "Maybe it uses GPS. We know the\ncharacteristics of GPS. We can kind of reason about\nits safety in that way.",
    "start": "1304310",
    "end": "1310640"
  },
  {
    "text": "The difference here is\nthat now these, say, autonomous vehicles are based\noff these very complex machine",
    "start": "1310640",
    "end": "1315860"
  },
  {
    "text": "learning components which are\nthese black box models that are very difficult to reason about. And so, we need to\nkind of begin coming up",
    "start": "1315860",
    "end": "1322280"
  },
  {
    "text": "with other ways of\ntesting these systems, and then, what I\ndescribed is one way. SPEAKER: That's\nreally interesting.",
    "start": "1322280",
    "end": "1327458"
  },
  {
    "start": "1325000",
    "end": "1600000"
  },
  {
    "text": "So again it's in-- we-- I'm going to call it. And this is not\ntechnical because I'm not technical-- the kind\nof traditional systems",
    "start": "1327458",
    "end": "1332990"
  },
  {
    "text": "you can reason, as you\nsaid, from first principles. We understand the\nphysics well enough of this mechanical\nsystem that we",
    "start": "1332990",
    "end": "1338090"
  },
  {
    "text": "can predict the failure points. With an AI system, we\ncan't reason about it based on first principle.",
    "start": "1338090",
    "end": "1343580"
  },
  {
    "text": "So we need to test\nit in simulations. Could we build on that?",
    "start": "1343580",
    "end": "1348615"
  },
  {
    "text": "Because I know you've also--\nor Mykel's lab has also done work around formal verification. Could you tell us a little bit\nabout that, what that means,",
    "start": "1348615",
    "end": "1355460"
  },
  {
    "text": "and how you're using\nthat, or how people could use that to test systems? ANTHONY CORSO: Yeah, absolutely.",
    "start": "1355460",
    "end": "1361320"
  },
  {
    "text": "So formal verification is\njust like a fancy research term for mathematical proofs.",
    "start": "1361320",
    "end": "1367350"
  },
  {
    "text": "So what we're doing\nin formal verification is trying to construct\na mathematical proof that the system has the safety\nbehavior that we want it to.",
    "start": "1367350",
    "end": "1375682"
  },
  {
    "text": "So for example, we\nmight try to construct a proof that our\nvehicle will never collide with another vehicle.",
    "start": "1375682",
    "end": "1381020"
  },
  {
    "text": "Now this may sound\nchallenging or-- and it is-- and\noftentimes, what's",
    "start": "1381020",
    "end": "1386750"
  },
  {
    "text": "required to do these\nformal verification proofs is to make a\nbunch of assumptions. Well, maybe we'll assume\nthat pedestrians can only",
    "start": "1386750",
    "end": "1393950"
  },
  {
    "text": "move so fast and\nthat they'll only move in a particular direction\nand so on and so forth. And so, we make all\nthese assumptions,",
    "start": "1393950",
    "end": "1399440"
  },
  {
    "text": "and then we prove that our\nsystem under those assumptions will never ever be\ninvolved in a collision.",
    "start": "1399440",
    "end": "1405210"
  },
  {
    "text": "Now the problem is, number one,\nthat if those assumptions are ever violated, then we no\nlonger have those guarantees.",
    "start": "1405210",
    "end": "1411080"
  },
  {
    "text": "But that could be OK\nbecause at least we know we're safe when the\nassumptions are holding. And then when the\nassumptions are violated,",
    "start": "1411080",
    "end": "1416772"
  },
  {
    "text": "we can perhaps take\nsome evasive maneuver or identify or alert\nsomeone that there could be a potential problem.",
    "start": "1416772",
    "end": "1424500"
  },
  {
    "text": "And so, that's what we mean\nby formal verification, and it's been a really useful\ntool to basically proving",
    "start": "1424500",
    "end": "1430370"
  },
  {
    "text": "properties of various\ncomponents that have gone into aviation\nsystems as well as the vehicles",
    "start": "1430370",
    "end": "1435680"
  },
  {
    "text": "to kind of provide a boundary\nover which we know we are safe and that can be\nreally, really useful.",
    "start": "1435680",
    "end": "1443010"
  },
  {
    "text": "SPEAKER: That's fantastic. Yeah, and I think those are\ntwo really interesting things. And I should point, we have a\nlink to Anthony's bio there.",
    "start": "1443010",
    "end": "1449507"
  },
  {
    "text": "And so, if you want\nto dig in deeper, I think there are some links to\nyour CV and some of the papers that you've published or also\nto the SISL, the Stanford",
    "start": "1449508",
    "end": "1458360"
  },
  {
    "text": "Intelligent Systems\nLaboratory as well if people are interested in digging deeper\ninto some of those topics.",
    "start": "1458360",
    "end": "1463976"
  },
  {
    "text": "We're getting a lot\nof good questions, but I think maybe\nwe can actually",
    "start": "1463977",
    "end": "1469400"
  },
  {
    "text": "circle into and come back\nto some of these questions. But I want to circle\ninto the course that you've been\nplanning and trying",
    "start": "1469400",
    "end": "1475820"
  },
  {
    "text": "to develop for this summer. And so, maybe you\ncan just walk through because I think in\nwalking through that,",
    "start": "1475820",
    "end": "1482179"
  },
  {
    "text": "you're going to be expanding\non this conversation we've been having and talking about--\nhaving and talking about what",
    "start": "1482180",
    "end": "1488630"
  },
  {
    "text": "goes into building a safe\nand verifying a safe system. So can you talk through\nwhat you're thinking",
    "start": "1488630",
    "end": "1494200"
  },
  {
    "text": "about in terms of the content? This is a short\none-week class, right? So it is technical,\nbut it's obviously--",
    "start": "1494200",
    "end": "1500090"
  },
  {
    "text": "it's not a semester long\nor anything like that. So could you talk about that? ANTHONY CORSO: Absolutely. So the reason I'm putting\ntogether this course--",
    "start": "1500090",
    "end": "1507950"
  },
  {
    "text": "maybe I can start there-- is because I think that there's\na lot of great resources out there on the\ninternet through SCPD,",
    "start": "1507950",
    "end": "1516320"
  },
  {
    "text": "for example, where you\ncould learn about how to apply machine learning and AI\nto solve a variety of problems.",
    "start": "1516320",
    "end": "1522980"
  },
  {
    "text": "And I remember taking\none of these courses several years back and thinking,\nwow, this is really incredible. I can't believe how\nstraightforward and easy",
    "start": "1522980",
    "end": "1529640"
  },
  {
    "text": "it is to apply these techniques\nand solve real world problems. The issue is that in\nthe years since then--",
    "start": "1529640",
    "end": "1535730"
  },
  {
    "text": "and I've now built a lot of\nmachine-learning systems and AI systems-- you begin to discover that the\ndevil is often in the details.",
    "start": "1535730",
    "end": "1543269"
  },
  {
    "text": "So there's a lot of issues that\ncan go wrong when you actually go to try to deploy\nor build the system",
    "start": "1543270",
    "end": "1548750"
  },
  {
    "text": "for a real-world problem. And so, I've kind of collected\na number of learnings",
    "start": "1548750",
    "end": "1554480"
  },
  {
    "text": "from my years in doing\nresearch in this topic. And I wanted to put those\nlearnings into one place",
    "start": "1554480",
    "end": "1559610"
  },
  {
    "text": "where someone who's maybe taken\nsome machine learning courses can go to get up to speed on\nthe latest kind of advancements",
    "start": "1559610",
    "end": "1566690"
  },
  {
    "text": "but also current issues\naround AI Safety. And so, to that\nend, we've outlined",
    "start": "1566690",
    "end": "1573590"
  },
  {
    "text": "basically a five-day course. Each day will consist of\nabout two hours of lectures.",
    "start": "1573590",
    "end": "1578638"
  },
  {
    "text": "On the first day, we're\ngoing to be talking about sort of an\nintroduction to the use of AI",
    "start": "1578638",
    "end": "1584063"
  },
  {
    "text": "and safety-critical domains. And I'll walk through\nsome examples of times where AI has failed or machine\nlearning models have failed,",
    "start": "1584063",
    "end": "1590956"
  },
  {
    "text": "and then talk about how they--\nwhat are some of the techniques that we can use to build much\nmore robust machine learning",
    "start": "1590957",
    "end": "1596047"
  },
  {
    "text": "models that don't suffer\nfrom some of the problems that we've seen quite so much. SPEAKER: And can you\ndefine robust a little bit?",
    "start": "1596047",
    "end": "1602950"
  },
  {
    "start": "1600000",
    "end": "1760000"
  },
  {
    "text": "That was one of the\nfirst questions. ANTHONY CORSO: Oh,\nyeah, absolutely. ANTHONY CORSO: So\nwhen I say robust,",
    "start": "1602950",
    "end": "1608520"
  },
  {
    "text": "what I mean is that the model\nwill-- that an AI system will have similar\nperformance even when",
    "start": "1608520",
    "end": "1614519"
  },
  {
    "text": "the environment in\nwhich it's operating in changes ever so slightly. So like I said, a robust model,\nsay, for autonomous driving",
    "start": "1614520",
    "end": "1622110"
  },
  {
    "text": "will do just as\nwell in the morning as it does in the afternoon\nwhen the lighting conditions are different and people's behaviors\nare slightly different.",
    "start": "1622110",
    "end": "1628343"
  },
  {
    "text": "That's what we\nmean by robustness.",
    "start": "1628343",
    "end": "1630630"
  },
  {
    "text": "Great. So then, the next two days\nwill be around model evaluation",
    "start": "1633590",
    "end": "1638830"
  },
  {
    "text": "and verification. So on the next day,\nwe'll be talking about techniques for explaining\nthese machine learning models.",
    "start": "1638830",
    "end": "1647000"
  },
  {
    "text": "So as I said, often these very\ncomplex neural networks that have billions,\npotentially, of parameters",
    "start": "1647000",
    "end": "1655840"
  },
  {
    "text": "that are used to process\nimages, and they're often thought of as too complex\nto really think about.",
    "start": "1655840",
    "end": "1661480"
  },
  {
    "text": "But people have\nbeen developing ways to peer inside the\nblack box a little bit and try to understand\na little bit more",
    "start": "1661480",
    "end": "1667330"
  },
  {
    "text": "about how these machine\nlearning components are arriving at the\ndecisions that they have.",
    "start": "1667330",
    "end": "1673450"
  },
  {
    "text": "We'll also be\ntalking a little bit about this question of\nfailure identification, so using these sort of\nadversarial techniques",
    "start": "1673450",
    "end": "1679780"
  },
  {
    "text": "to kind of stress\ntest your system to uncover the ways\nin which it might fail as a tool to kind of\neventually build safe systems.",
    "start": "1679780",
    "end": "1688299"
  },
  {
    "text": "And then, we will be\ntalking about methods in formal verification as well.",
    "start": "1688300",
    "end": "1693380"
  },
  {
    "text": "So certifying or\nmathematically proving that our neural networks\nare resilient to, say,",
    "start": "1693380",
    "end": "1700390"
  },
  {
    "text": "adversarial attacks and\nhave other properties that would be desirable. We'll get to play\nwith some libraries",
    "start": "1700390",
    "end": "1706090"
  },
  {
    "text": "that people have\ndeveloped to do this. So you can actually use\nit in real world projects that you might be working on.",
    "start": "1706090",
    "end": "1713015"
  },
  {
    "text": "On day four, then\nwe're going to move into a discussion on\nuncertainty quantification machine learning.",
    "start": "1713015",
    "end": "1718100"
  },
  {
    "text": "So I'll say a little\nbit about what I mean. So uncertainty\nquantification is basically what happens when your\nmachine learning model, say,",
    "start": "1718100",
    "end": "1725950"
  },
  {
    "text": "encounters a situation\nit's never seen before. Would you want, on\nthe one hand, for it to just decide what it thinks is\nbest and go forward full steam?",
    "start": "1725950",
    "end": "1733390"
  },
  {
    "text": "Or would you want it to identify\nthe fact that it's in a novel situation and perhaps maybe\nalert a human supervisor",
    "start": "1733390",
    "end": "1740620"
  },
  {
    "text": "or basically do something\nthat it knows to be? And in the latter\ncase, that's the use of uncertainty\nquantification where",
    "start": "1740620",
    "end": "1746530"
  },
  {
    "text": "it's uncertain about\nwhat it's doing. And so, you put on the brakes\nand make sure things are OK. And so, there's a\nbunch of techniques",
    "start": "1746530",
    "end": "1752470"
  },
  {
    "text": "for building this\nstyle of reasoning about uncertainty into the\nmachine learning components",
    "start": "1752470",
    "end": "1758440"
  },
  {
    "text": "or the AI systems\nthat you build. SPEAKER: So Anthony,\njust to pause you there. So uncertainty\nquantification is--",
    "start": "1758440",
    "end": "1764530"
  },
  {
    "start": "1760000",
    "end": "2620000"
  },
  {
    "text": "it's the idea you're in\na new or novel situation. It's one, recognizing,\nI suppose,",
    "start": "1764530",
    "end": "1770710"
  },
  {
    "text": "is probably a problem-- recognizing it's\na new situation, and then, two, is knowing\nhow to respond to that.",
    "start": "1770710",
    "end": "1777470"
  },
  {
    "text": "And it can be-- we think our system is\nstill reliable in this, or it's alert a human,\nor I don't remember",
    "start": "1777470",
    "end": "1782752"
  },
  {
    "text": "if this is something\nthat SISL works on, but it could be something like\nreverting from the AI system",
    "start": "1782753",
    "end": "1788440"
  },
  {
    "text": "to a model that's much safer\nor to a safer parameters or something like that. ANTHONY CORSO: Indeed, yeah.",
    "start": "1788440",
    "end": "1794050"
  },
  {
    "text": "Often, these systems\nare built with what they call fallback strategies. So like, if everything\nelse goes wrong,",
    "start": "1794050",
    "end": "1799670"
  },
  {
    "text": "we have a fallback\nstrategy that we know to be safe though\nit's going to be much less",
    "start": "1799670",
    "end": "1804880"
  },
  {
    "text": "effective than your AI policy. But the real challenge\noften is identifying",
    "start": "1804880",
    "end": "1810760"
  },
  {
    "text": "the situations that are novel. You would think\nthat this should be, again, something easy to\ndo because humans do it",
    "start": "1810760",
    "end": "1816460"
  },
  {
    "text": "very regularly. We know when we're\nin a situation that we don't understand. But machine learning models\nhave kind of a bizarre attribute",
    "start": "1816460",
    "end": "1823270"
  },
  {
    "text": "where they may be extremely\nconfident in decisions they're making, even\nthough it's very uncertain,",
    "start": "1823270",
    "end": "1828790"
  },
  {
    "text": "and they're wrong. So there's potential\nfor major downsides",
    "start": "1828790",
    "end": "1835059"
  },
  {
    "text": "if you don't take this\ninto account explicitly. SPEAKER: That's great. I'm sorry to interrupt you. I just thought that\nwas one more thing--",
    "start": "1835060",
    "end": "1841289"
  },
  {
    "text": "ANTHONY CORSO: No.\nNo worries. SPEAKER: --a little bit more. ANTHONY CORSO: Yeah, I'm\nhappy to answer more questions about that. And then, we'll kind\nof tie it all together",
    "start": "1841290",
    "end": "1848250"
  },
  {
    "text": "on the last day where\nwe'll talk about, for example, the aircraft\ncollision avoidance",
    "start": "1848250",
    "end": "1854640"
  },
  {
    "text": "system that I mentioned early-- earlier. We'll use that as a\ncase study to think about how you put all these\npieces together in a way that",
    "start": "1854640",
    "end": "1860940"
  },
  {
    "text": "can hold it very reliable. And then, I'll talk a little\nbit about some of the upcoming regulation around AI.",
    "start": "1860940",
    "end": "1866970"
  },
  {
    "text": "So there's actually some-- there's a big law that's\nsoon to be signed in the EU,",
    "start": "1866970",
    "end": "1872377"
  },
  {
    "text": "and then there's been\nsome discussions here in the US in thinking about\nthe ways in which AI might be regulated and how some of the\ntechniques describing perhaps",
    "start": "1872378",
    "end": "1879809"
  },
  {
    "text": "will fit into that regulation\nbecause you might be required in the future to do\nmany of the things I'm talking about to\nensure that people",
    "start": "1879810",
    "end": "1885930"
  },
  {
    "text": "stay unharmed from the\nsystems that we build. SPEAKER: Thanks, Anthony.",
    "start": "1885930",
    "end": "1891530"
  },
  {
    "text": "It's a really\ninteresting course. And again, it's focusing on\nthese autonomous systems. I guess one thing\nis-- do you see--",
    "start": "1891530",
    "end": "1898610"
  },
  {
    "text": "so we're talking-- in\nthe primary use case, we're talking\nabout is autonomous",
    "start": "1898610",
    "end": "1904009"
  },
  {
    "text": "vehicles like cars or aviation. We've got a lot of questions\nabout working in warehouses,",
    "start": "1904010",
    "end": "1909019"
  },
  {
    "text": "maybe industrial machinery. Does this still apply? I mean, in some sense,\nthat's a much more controlled environment\nthan a road where you have",
    "start": "1909020",
    "end": "1915110"
  },
  {
    "text": "pedestrians, where the\nentire infrastructure is not",
    "start": "1915110",
    "end": "1920630"
  },
  {
    "text": "built around AI, whereas\nwhen you go into a factory, the infrastructure can be\ndesigned around the systems",
    "start": "1920630",
    "end": "1926690"
  },
  {
    "text": "themselves, right? And so, I guess the-- broadly--\nthe question is, how do these apply to those kinds\nof systems that are",
    "start": "1926690",
    "end": "1932430"
  },
  {
    "text": "or situations that\nare more controlled? Do you think it's still\napplicable to people who are interested\nin machine learning",
    "start": "1932430",
    "end": "1938210"
  },
  {
    "text": "and industrial applications? ANTHONY CORSO: Yeah, absolutely. So I think almost\neverything will apply.",
    "start": "1938210",
    "end": "1945059"
  },
  {
    "text": "So I mean it just\nto varying degrees. So as you mentioned, in the\nautonomous driving setting, you're in a very open and\nuncontrolled environment.",
    "start": "1945060",
    "end": "1952740"
  },
  {
    "text": "So lots of stuff can go wrong. Lots of things can\nchange over time. And I think it's one\nof the reasons why",
    "start": "1952740",
    "end": "1957845"
  },
  {
    "text": "it's taken such a long time\nto get autonomous vehicles out on the roads operating safely. In a much more\ncontrolled environment,",
    "start": "1957845",
    "end": "1964370"
  },
  {
    "text": "you do have the\nluxury of perhaps controlling the\nenvironment in which the AI",
    "start": "1964370",
    "end": "1969710"
  },
  {
    "text": "system is operating in. But it's never so\nstraightforward as that. Things will always change,\nand you want your AI system,",
    "start": "1969710",
    "end": "1979640"
  },
  {
    "text": "say, that's controlling\nthe robotic arm to be somewhat resilient\nto the small changes that occur on the factory\nline or changes",
    "start": "1979640",
    "end": "1986809"
  },
  {
    "text": "to the environment, lighting\nconditions, you know, seasonal changes,\nthings like this.",
    "start": "1986810",
    "end": "1993049"
  },
  {
    "text": "You might, for example,\nnot be so worried about-- I talked a little bit about what\nI call the adversarial attacks",
    "start": "1993050",
    "end": "1998640"
  },
  {
    "text": "where there's some sort of\nintentional manipulation for AI system. Maybe that's less of a concern\nin the warehouse domain",
    "start": "1998640",
    "end": "2005679"
  },
  {
    "text": "than it would be in\nthe driving domain. But nonetheless, you\nstill want to have",
    "start": "2005680",
    "end": "2011020"
  },
  {
    "text": "as robust of a system as\npossible in both of those applications. It's just sort of\nto varying degrees.",
    "start": "2011020",
    "end": "2017900"
  },
  {
    "text": "SPEAKER: That's\nreally interesting. How do you even-- I guess, in one-- one question to follow up\nthere is how do you reason?",
    "start": "2017900",
    "end": "2022930"
  },
  {
    "text": "I mean, do you reason\nfor first principles? You talked about using AI\nsystems to kind of play an adversarial role\nin manipulating",
    "start": "2022930",
    "end": "2029110"
  },
  {
    "text": "a simulated environment. How do you even figure out what\nparameters in that environment to sort of adjust?",
    "start": "2029110",
    "end": "2035080"
  },
  {
    "text": "As you're talking, one thing\nthat comes to mind is you're-- say, you're working\nin a warehouse and, say, that warehouse\nhas windows, right,",
    "start": "2035080",
    "end": "2042190"
  },
  {
    "text": "that are facing. ANTHONY CORSO: Yeah. SPEAKER: You might not think-- you wouldn't necessarily think\nabout daylight or nighttime",
    "start": "2042190",
    "end": "2048790"
  },
  {
    "text": "conditions being a significant\nfactor, but it could be. But how do you-- how do you approach even\nthinking through what",
    "start": "2048790",
    "end": "2056138"
  },
  {
    "text": "the environment is? And what are the important\nchanges to control for",
    "start": "2056139",
    "end": "2061989"
  },
  {
    "text": "or to test for? ANTHONY CORSO: Yeah. That's a great question,\nand there's no easy answer. It's going to be a combination\nof the experts in the domain,",
    "start": "2061989",
    "end": "2070669"
  },
  {
    "text": "so people who have worked in\nthe warehouse space before, and they understand what\nthings might change,",
    "start": "2070670",
    "end": "2076219"
  },
  {
    "text": "what are the common\nkind of situations that might arise\nthat maybe would be challenging for\na human to handle.",
    "start": "2076219",
    "end": "2081638"
  },
  {
    "text": "And then, you can infer\nthat it would also be challenging for this AI agent. You can look at a\nbunch of examples,",
    "start": "2081639",
    "end": "2088443"
  },
  {
    "text": "and this is what we'll\ndo in the course. We'll look at a\nbunch of examples where you have these what\nwe call distribution shifts.",
    "start": "2088443",
    "end": "2094350"
  },
  {
    "text": "So this is where things\nin the environment change ever so slightly, and\nthe machine learning model's performance drops quite a bit.",
    "start": "2094350",
    "end": "2101037"
  },
  {
    "text": "And so, we'll look at a\nbunch of examples of that. You'll see, for example, changes\nin lighting condition or color",
    "start": "2101037",
    "end": "2107410"
  },
  {
    "text": "scheme like things like this. You can build a little bit of\nan intuition around what types of factors may influence certain\ntypes of machine learning",
    "start": "2107410",
    "end": "2113847"
  },
  {
    "text": "models. And then, the last\npiece of this is like you absolutely need to\nmonitor your systems as you",
    "start": "2113847",
    "end": "2120880"
  },
  {
    "text": "deploy them. So you don't know everything\nthat's going to arise. And so, it's really\nimportant to build",
    "start": "2120880",
    "end": "2126369"
  },
  {
    "text": "in this element of, number one,\nquantifying your uncertainty during operation. So as we talked\nabout, making sure",
    "start": "2126370",
    "end": "2132369"
  },
  {
    "text": "the system is aware when things\nchange and can potentially alert, say, a user.",
    "start": "2132370",
    "end": "2138280"
  },
  {
    "text": "And then, also\nhaving systems that are monitoring the performance\nof these systems over time.",
    "start": "2138280",
    "end": "2144110"
  },
  {
    "text": "And if you see the performance\ndropping, for example, then you know\nsomething has shifted, it's time to retrain your\nmodel or intervene in some way.",
    "start": "2144110",
    "end": "2152433"
  },
  {
    "text": "SPEAKER: That's great. So maybe even revisiting\nwhat I had talked to you, what I mentioned earlier\nkind of the aspects of it.",
    "start": "2152433",
    "end": "2158869"
  },
  {
    "text": "There's building, there's\nverification, and then, is monitoring almost maybe\na third thing there, right?",
    "start": "2158870",
    "end": "2164110"
  },
  {
    "text": "You're verifying it in advance,\nand then once it's deployed, it's making sure\nyou have-- and this is what you're\ntalking about in terms",
    "start": "2164110",
    "end": "2169372"
  },
  {
    "text": "of uncertainty quantification. You're building into that\nsystem a way to monitor, to flag situations\nthat are outside what",
    "start": "2169372",
    "end": "2176770"
  },
  {
    "text": "would be normally\nconsidered-- what would be considered normal. ANTHONY CORSO: Yeah. Yeah.",
    "start": "2176770",
    "end": "2182250"
  },
  {
    "text": "So that's like\none aspect of what we call runtime monitoring is\nthat uncertainty quantification",
    "start": "2182250",
    "end": "2187390"
  },
  {
    "text": "piece that can alert when\nsomething has gone off nominal. But another thing you can\ndo is just every so often,",
    "start": "2187390",
    "end": "2193540"
  },
  {
    "text": "every week or something, you\nknow, reevaluate your, say,",
    "start": "2193540",
    "end": "2199840"
  },
  {
    "text": "model on a new set of data. So it's sort of like just a\nrepeated validation process.",
    "start": "2199840",
    "end": "2205430"
  },
  {
    "text": "So doing the same thing\nyou did before you deployed it just on a iterated base\nensure that things are staying",
    "start": "2205430",
    "end": "2212200"
  },
  {
    "text": "at a high level of performance. SPEAKER: So this would\nbe-- so in other words, the AI system is running.",
    "start": "2212200",
    "end": "2217480"
  },
  {
    "text": "It's doing its thing. It's not retraining\nitself as it's doing it. It's not, so to speak, right? ANTHONY CORSO: Typically not. SPEAKER: Learning\nin the environment.",
    "start": "2217480",
    "end": "2223339"
  },
  {
    "text": "No, what you're doing is\ncollecting more data, then retesting it on the new data. ANTHONY CORSO: Exactly.",
    "start": "2223340",
    "end": "2229450"
  },
  {
    "text": "SPEAKER: Yeah. This is a little bit of a-- I just find it as a\nreally fascinating idea,",
    "start": "2229450",
    "end": "2235599"
  },
  {
    "text": "and it's related to that. It's this idea of-- I think it's called\ndistributional shift is what you've talked about?",
    "start": "2235600",
    "end": "2241187"
  },
  {
    "text": "ANTHONY CORSO: Yeah. SPEAKER: So I guess\nthe idea is it's related to this uncertainty\nor novel situations,",
    "start": "2241187",
    "end": "2247930"
  },
  {
    "text": "but it can also be that maybe\nthe AI system is working well, but say, that the camera that's\nrecording it is degrading.",
    "start": "2247930",
    "end": "2254015"
  },
  {
    "text": "And so, the quality of\nthe image is changing. Can you talk a little\nbit about that and maybe this idea of\ndistributional shift--",
    "start": "2254015",
    "end": "2260410"
  },
  {
    "text": "or maybe I'm focusing\non the wrong thing-- but just how that\ncan affect the safety or the continued\noperation of the machine?",
    "start": "2260410",
    "end": "2266437"
  },
  {
    "text": "It might not just be\nchanges in environment. It could be changes in\nthe sensors, I guess. ANTHONY CORSO: Yeah, absolutely. So it could be changes\nin the sensors,",
    "start": "2266437",
    "end": "2272770"
  },
  {
    "text": "and I've talked a lot about\nsort of these physical changes in the environment like changing\nlighting conditions and things",
    "start": "2272770",
    "end": "2278210"
  },
  {
    "text": "like that. But distribution\nshift can be something that happens, say, like--",
    "start": "2278210",
    "end": "2283960"
  },
  {
    "text": "imagine, for example, that\nwe have an AI system that's helping you diagnose new\ndiseases at a hospital",
    "start": "2283960",
    "end": "2290980"
  },
  {
    "text": "or something. What would you think would\nhappen to that system at the beginning of the\nCOVID-19 pandemic for example,",
    "start": "2290980",
    "end": "2296740"
  },
  {
    "text": "where a new virus altogether\nhas shown up on the scene? It would make these\nsystems go haywire",
    "start": "2296740",
    "end": "2302260"
  },
  {
    "text": "because it's not-- they've\nnever seen that before. And so, it can be\nthings like that",
    "start": "2302260",
    "end": "2307390"
  },
  {
    "text": "where the distribution of\ninputs that it's seeing is shifting because of\na new thing in the world",
    "start": "2307390",
    "end": "2312820"
  },
  {
    "text": "or things like that. SPEAKER: Interesting. Yeah, so it's a\ncompletely new, right? I hadn't even thought about\nthat if there's a new disease",
    "start": "2312820",
    "end": "2318609"
  },
  {
    "text": "or something like that\nthat's introduced, it could completely change the\nway it's diagnosing everything. Yeah. ANTHONY CORSO: Yeah.",
    "start": "2318610",
    "end": "2324109"
  },
  {
    "text": "SPEAKER: That's really-- so\nwe're-- that's great, Anthony, and we're nearing\nthe end of our time. So maybe-- you know,\nwe've gotten a couple",
    "start": "2324110",
    "end": "2329610"
  },
  {
    "text": "of questions about this. So maybe if we, in these last\ncouple of minutes, if you-- we could do just a kind\nof a big kind of zoom",
    "start": "2329610",
    "end": "2336130"
  },
  {
    "text": "out and away from kind of\nspecific things and just maybe get your thoughts on what the\nfuture of autonomous systems",
    "start": "2336130",
    "end": "2341830"
  },
  {
    "text": "are, what you're hopeful about,\nand what you're worried about. ANTHONY CORSO: Yeah, absolutely. So as I said, at\nthe top, you know,",
    "start": "2341830",
    "end": "2348450"
  },
  {
    "text": "I'm really hopeful that\nthe use of the AI systems can basically do\na bunch of things",
    "start": "2348450",
    "end": "2354270"
  },
  {
    "text": "that humans historically\nhave done so they can do them perhaps more quickly, more\nefficiently at a larger scale.",
    "start": "2354270",
    "end": "2361320"
  },
  {
    "text": "And this can bring a\nlot of great resources to a lot of people. So I think that's the thing\nthat everyone is shooting for.",
    "start": "2361320",
    "end": "2368550"
  },
  {
    "text": "But there are a ton of risks. And I think something we\nhaven't even talked about today,",
    "start": "2368550",
    "end": "2374020"
  },
  {
    "text": "though I'm sure everyone\nhas kind of encountered it recently, is\nthings like ChatGPT. So these generative\nAI systems that",
    "start": "2374020",
    "end": "2380640"
  },
  {
    "text": "are able to produce content\nor text or images or videos and things like that, and these\ntypes of systems, when deployed",
    "start": "2380640",
    "end": "2389910"
  },
  {
    "text": "without much oversight, can lead\nto very strange and bad things",
    "start": "2389910",
    "end": "2395240"
  },
  {
    "text": "happening. So they can exhibit\ntoxic behavior, they can discriminate\nagainst people,",
    "start": "2395240",
    "end": "2400829"
  },
  {
    "text": "they can steal people's\ncopyrighted information, you know, producing images that\nare in the style of an artist",
    "start": "2400830",
    "end": "2407849"
  },
  {
    "text": "or something like that. They can be used to\nintentionally produce misinformation, and they\ncan do this at scale,",
    "start": "2407850",
    "end": "2414480"
  },
  {
    "text": "like we talked about. It's something that\nhuman typically does, but now you can do it\nincredibly fast and widespread.",
    "start": "2414480",
    "end": "2420690"
  },
  {
    "text": "So I'm a little bit worried\nthat especially generative AI",
    "start": "2420690",
    "end": "2425760"
  },
  {
    "text": "systems are being deployed\nvery widely very quickly. And we're not exactly sure\nwhat kind of influence",
    "start": "2425760",
    "end": "2432720"
  },
  {
    "text": "it's going to have on our\ninformation ecosystem. So now there's a\nton of AI generated",
    "start": "2432720",
    "end": "2438090"
  },
  {
    "text": "content out in the world. And it's not always\nso obvious when you're interacting with it. So that's definitely one of\nthe concerns that I have.",
    "start": "2438090",
    "end": "2444198"
  },
  {
    "text": "SPEAKER: Do you think that\nthis course-- so coming back to the course, do you think\nthat some of these principles could also apply to people who\nare thinking about something--",
    "start": "2444198",
    "end": "2451619"
  },
  {
    "text": "you know, we were talking\nabout cars and machines, things that are interacting with\nthe physical environment",
    "start": "2451620",
    "end": "2456780"
  },
  {
    "text": "and humans. But there is-- is that\nsomething that you think some of these\nprinciples can apply",
    "start": "2456780",
    "end": "2462540"
  },
  {
    "text": "to something like ChatGPT? Can you do testing for kind\nof emotional harm to humans? That's a real, I guess,\nit's a tricky question.",
    "start": "2462540",
    "end": "2469260"
  },
  {
    "text": "It's much less, I\nthink, called it a less tractable problem maybe. ANTHONY CORSO: Yeah. Yeah. It's much less cut and dry\nbecause it's not clear.",
    "start": "2469260",
    "end": "2476100"
  },
  {
    "text": "These systems are\nvery general purpose. Like, they can do a lot\nof different things, whereas the systems I\nwas describing earlier",
    "start": "2476100",
    "end": "2482580"
  },
  {
    "text": "have like sort of one task\nthat you can kind of check its performance against. And so, I think many\nof the techniques",
    "start": "2482580",
    "end": "2489900"
  },
  {
    "text": "can and will apply to\nthings like ChatGPT, but it's just a more\nchallenging domain because it's very difficult\nto quantify, like,",
    "start": "2489900",
    "end": "2498330"
  },
  {
    "text": "the harms on a societal scale\nand all of these things. But I think-- still, you\nwant Chat-- for example,",
    "start": "2498330",
    "end": "2505390"
  },
  {
    "text": "you want ChatGPT to be\nmore robust and that it shouldn't-- its behavior\nshouldn't substantially change",
    "start": "2505390",
    "end": "2511170"
  },
  {
    "text": "when it's interacting\nwith people. You would want it to\nexpress uncertainty when it doesn't know some things.",
    "start": "2511170",
    "end": "2516450"
  },
  {
    "text": "Sometimes it does. I don't know if you've seen it. It'll say, oh, I'm\nnot sure about this.",
    "start": "2516450",
    "end": "2521610"
  },
  {
    "text": "And you would want it to\nbe truthful and honest and things like that. And so, I think many of\nthe-- in principle, many",
    "start": "2521610",
    "end": "2526927"
  },
  {
    "text": "of these techniques apply,\nbut it does get a lot messier when we're talking about\nthese really large-scale generative AI systems.",
    "start": "2526927",
    "end": "2533760"
  },
  {
    "text": "SPEAKER: How can-- do you\nforesee these generative AI systems being applied in domains\nlike autonomous vehicles?",
    "start": "2533760",
    "end": "2541080"
  },
  {
    "text": "Or does that itself pose\ntoo great a safety risk? I'm sorry, now we're\ngoing a little bit off. ANTHONY CORSO: No, it's fine.",
    "start": "2541080",
    "end": "2547610"
  },
  {
    "text": "I certainly hope not, that\nthey are not because I've seen so many examples of\nfailures of reasoning, failures",
    "start": "2547610",
    "end": "2555060"
  },
  {
    "text": "of logic with these\nsystems that we don't want to put\nthem behind the wheel or behind the aircraft.",
    "start": "2555060",
    "end": "2561180"
  },
  {
    "text": "It's possible that if we-- 5, 10 years from now as these\nsystems get better and better,",
    "start": "2561180",
    "end": "2566550"
  },
  {
    "text": "they will be more human like in\ntheir reasoning capabilities, and therefore, could be trusted\nto do something like this.",
    "start": "2566550",
    "end": "2571860"
  },
  {
    "text": "But we're definitely\nnot there yet. And I think it's really\nimportant for these tasks that",
    "start": "2571860",
    "end": "2578190"
  },
  {
    "text": "are safety critical\nand have high stakes that we still stick with\nthe kind of systems that",
    "start": "2578190",
    "end": "2583440"
  },
  {
    "text": "have been designed for\nthis bespoke purpose, not these general AI systems.",
    "start": "2583440",
    "end": "2588940"
  },
  {
    "text": "SPEAKER: Well, thank you. Thank you, Anthony,\nfor joining us today. And thank all of you who joined\nus today for this fireside chat",
    "start": "2588940",
    "end": "2595990"
  },
  {
    "text": "with Anthony though\nthere's no fire, I guess, the Zoom side chat,\nthe online side chat.",
    "start": "2595990",
    "end": "2601155"
  },
  {
    "text": "Well, thank you\nagain, everybody. Thank you, Anthony, and we\nreally appreciate your time. And maybe we'll\nsee you again soon.",
    "start": "2601155",
    "end": "2606657"
  },
  {
    "text": "ANTHONY CORSO: Yeah. Thanks, everyone. Appreciate it.",
    "start": "2606657",
    "end": "2610170"
  }
]
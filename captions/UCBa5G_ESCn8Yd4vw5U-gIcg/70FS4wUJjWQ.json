[
  {
    "start": "0",
    "end": "9000"
  },
  {
    "start": "0",
    "end": "5490"
  },
  {
    "text": "BILL MACCARTNEY: It's good\nmethodological practice",
    "start": "5490",
    "end": "8130"
  },
  {
    "text": "whenever you're starting to\nbuild new models to start",
    "start": "8130",
    "end": "11700"
  },
  {
    "start": "9000",
    "end": "21000"
  },
  {
    "text": "by evaluating very simple\nmodels, which establish",
    "start": "11700",
    "end": "15210"
  },
  {
    "text": "baselines to which\nyou can then compare",
    "start": "15210",
    "end": "17912"
  },
  {
    "text": "the more sophisticated\nmodels that you're",
    "start": "17912",
    "end": "19620"
  },
  {
    "text": "going to build later on.",
    "start": "19620",
    "end": "21333"
  },
  {
    "start": "21000",
    "end": "35000"
  },
  {
    "text": "So to do that, we're\ngoing to start by looking",
    "start": "21333",
    "end": "23250"
  },
  {
    "text": "at three simple models.",
    "start": "23250",
    "end": "24780"
  },
  {
    "text": "A random guesser, a very simple\nphrase matching strategy,",
    "start": "24780",
    "end": "28800"
  },
  {
    "text": "and then, our first\nmachine learning",
    "start": "28800",
    "end": "30660"
  },
  {
    "text": "based approach, which will be a\nsimple bag-of-words classifier.",
    "start": "30660",
    "end": "36160"
  },
  {
    "start": "35000",
    "end": "205000"
  },
  {
    "text": "Just about the\nsimplest possible model",
    "start": "36160",
    "end": "38560"
  },
  {
    "text": "is one that doesn't\neven look at the input,",
    "start": "38560",
    "end": "42040"
  },
  {
    "text": "but just flips a coin.",
    "start": "42040",
    "end": "43900"
  },
  {
    "text": "And I strongly\nencourage you, whenever",
    "start": "43900",
    "end": "45640"
  },
  {
    "text": "you're embarking\non a model building",
    "start": "45640",
    "end": "47320"
  },
  {
    "text": "adventure in your final\nproject, wherever, you start",
    "start": "47320",
    "end": "51370"
  },
  {
    "text": "by evaluating a random guesser.",
    "start": "51370",
    "end": "53379"
  },
  {
    "text": "It's a snap to implement.",
    "start": "53380",
    "end": "55510"
  },
  {
    "text": "It can help to work out the\nkinks in your test harness.",
    "start": "55510",
    "end": "58780"
  },
  {
    "text": "And it's often very informative\nto put a floor under what",
    "start": "58780",
    "end": "62829"
  },
  {
    "text": "good scores look like.",
    "start": "62830",
    "end": "65110"
  },
  {
    "text": "Now, we've written an\nevaluation method for you.",
    "start": "65110",
    "end": "68080"
  },
  {
    "text": "It's in the RelExt module and\nit's just called evaluate.",
    "start": "68080",
    "end": "71740"
  },
  {
    "text": "You invoke it with your\nsplits, your classifier,",
    "start": "71740",
    "end": "76540"
  },
  {
    "text": "and the name of the split\nthat you want to evaluate on,",
    "start": "76540",
    "end": "79840"
  },
  {
    "text": "which defaults to dev.",
    "start": "79840",
    "end": "83640"
  },
  {
    "text": "When we evaluate\nour random guesser,",
    "start": "83640",
    "end": "85350"
  },
  {
    "text": "we have some\ninteresting results,",
    "start": "85350",
    "end": "87070"
  },
  {
    "text": "so we have results separated\nfor each of the relations.",
    "start": "87070",
    "end": "92040"
  },
  {
    "text": "And for each one, we have\nprecision recall, F-score.",
    "start": "92040",
    "end": "97210"
  },
  {
    "text": "Remember, that's F0.5, which\ngives more weight to precision",
    "start": "97210",
    "end": "100560"
  },
  {
    "text": "than to recall.",
    "start": "100560",
    "end": "102210"
  },
  {
    "text": "We have the support, which\nis the number of instances",
    "start": "102210",
    "end": "105390"
  },
  {
    "text": "whose actual label is true.",
    "start": "105390",
    "end": "108000"
  },
  {
    "text": "And we have size, which is just\nthe total number of instances.",
    "start": "108000",
    "end": "112920"
  },
  {
    "text": "We find that recall is\ngenerally right around 0.5.",
    "start": "112920",
    "end": "118500"
  },
  {
    "text": "And this makes\nsense, because recall",
    "start": "118500",
    "end": "120390"
  },
  {
    "text": "says of the instances\nwhich are actually true,",
    "start": "120390",
    "end": "124229"
  },
  {
    "text": "what proportion do\nwe predict true?",
    "start": "124230",
    "end": "126900"
  },
  {
    "text": "Well, we predict true\nabout half the time",
    "start": "126900",
    "end": "129030"
  },
  {
    "text": "because we're just\nflipping a coin.",
    "start": "129030",
    "end": "131910"
  },
  {
    "text": "Precision on the other hand,\nis generally quite poor,",
    "start": "131910",
    "end": "136650"
  },
  {
    "text": "because precision\nsays of the instances",
    "start": "136650",
    "end": "139290"
  },
  {
    "text": "where we predict true\nwhich are basically",
    "start": "139290",
    "end": "142290"
  },
  {
    "text": "a random sample, because\nwe're just flipping a coin.",
    "start": "142290",
    "end": "145110"
  },
  {
    "text": "How many are actually true?",
    "start": "145110",
    "end": "147700"
  },
  {
    "text": "Well, relatively few.",
    "start": "147700",
    "end": "149370"
  },
  {
    "text": "And actually, you can\ntell that by looking",
    "start": "149370",
    "end": "151470"
  },
  {
    "text": "at the ratio between\nsupport and size.",
    "start": "151470",
    "end": "154140"
  },
  {
    "text": "The ratio between\nsupport and size",
    "start": "154140",
    "end": "156780"
  },
  {
    "text": "is how many of the\ninstances are actually true.",
    "start": "156780",
    "end": "160180"
  },
  {
    "text": "So when we're tossing\na coin, the precision",
    "start": "160180",
    "end": "164189"
  },
  {
    "text": "should be right around the\nratio between support and size.",
    "start": "164190",
    "end": "168135"
  },
  {
    "start": "168135",
    "end": "170950"
  },
  {
    "text": "Our F-score is also\ngenerally poor,",
    "start": "170950",
    "end": "172930"
  },
  {
    "text": "it stays close to\nprecision, for two reasons.",
    "start": "172930",
    "end": "176510"
  },
  {
    "text": "Number one, because\nthe harmonics--",
    "start": "176510",
    "end": "178900"
  },
  {
    "text": "the harmonic mean stays\ncloser to the lower number,",
    "start": "178900",
    "end": "182140"
  },
  {
    "text": "and number 2, because\nwe're using F0.5,",
    "start": "182140",
    "end": "185500"
  },
  {
    "text": "which gives more weight to\nprecision than to recall.",
    "start": "185500",
    "end": "190320"
  },
  {
    "text": "And the bottom line our\nmacro-average F-score is 9.7%,",
    "start": "190320",
    "end": "195870"
  },
  {
    "text": "so that's the number to beat.",
    "start": "195870",
    "end": "198480"
  },
  {
    "text": "It's a pretty low bar, but this\nis a random guesser, after all.",
    "start": "198480",
    "end": "204780"
  },
  {
    "text": "OK.",
    "start": "204780",
    "end": "205280"
  },
  {
    "start": "205000",
    "end": "479000"
  },
  {
    "text": "So let's look at\nanother approach, which",
    "start": "205280",
    "end": "206947"
  },
  {
    "text": "is very simple, but smarter\nthan random guessing.",
    "start": "206947",
    "end": "209720"
  },
  {
    "text": "And it's a simple pattern\nmatching strategy.",
    "start": "209720",
    "end": "212360"
  },
  {
    "text": "And the idea is\nfor each relation,",
    "start": "212360",
    "end": "215600"
  },
  {
    "text": "let's go through the\ncorpus and find the most",
    "start": "215600",
    "end": "219230"
  },
  {
    "text": "common phrases that\nconnect to entities",
    "start": "219230",
    "end": "223069"
  },
  {
    "text": "that stand in that relation.",
    "start": "223070",
    "end": "224660"
  },
  {
    "text": "The most common middles,\nin our terminology.",
    "start": "224660",
    "end": "228140"
  },
  {
    "text": "So here's some code\nthat does that.",
    "start": "228140",
    "end": "230630"
  },
  {
    "text": "I won't go through it in\ndetail, but one thing to note",
    "start": "230630",
    "end": "234650"
  },
  {
    "text": "is that it counts separately\nthe middles that connect subject",
    "start": "234650",
    "end": "239060"
  },
  {
    "text": "with object.",
    "start": "239060",
    "end": "240330"
  },
  {
    "text": "So here, it gets\nall the examples",
    "start": "240330",
    "end": "243090"
  },
  {
    "text": "and counts the middles.",
    "start": "243090",
    "end": "246890"
  },
  {
    "text": "It tallies up the middles.",
    "start": "246890",
    "end": "248780"
  },
  {
    "text": "And it does that separately\nfrom the examples that",
    "start": "248780",
    "end": "252110"
  },
  {
    "text": "connect object with subject.",
    "start": "252110",
    "end": "254510"
  },
  {
    "text": "And it stores them in separate\ndictionaries under the keys",
    "start": "254510",
    "end": "259489"
  },
  {
    "text": "forward and reverse.",
    "start": "259490",
    "end": "261419"
  },
  {
    "text": "So we're going to\nhave forward middles",
    "start": "261420",
    "end": "263360"
  },
  {
    "text": "and reverse middles\nstored separately, stored",
    "start": "263360",
    "end": "266060"
  },
  {
    "text": "and counted separately.",
    "start": "266060",
    "end": "270400"
  },
  {
    "text": "If we run that code,\nhere's what we get.",
    "start": "270400",
    "end": "272710"
  },
  {
    "text": "I'm showing results.",
    "start": "272710",
    "end": "273850"
  },
  {
    "text": "I'm only going to show\nresults for 3 of the relations",
    "start": "273850",
    "end": "276310"
  },
  {
    "text": "here, not all 16.",
    "start": "276310",
    "end": "278800"
  },
  {
    "text": "All 16 are in the\nPython notebook",
    "start": "278800",
    "end": "281050"
  },
  {
    "text": "if you want to take a look.",
    "start": "281050",
    "end": "282460"
  },
  {
    "text": "But even from this\nsample, there's",
    "start": "282460",
    "end": "283876"
  },
  {
    "text": "a few things that jump out.",
    "start": "283877",
    "end": "286030"
  },
  {
    "text": "First, some of the\nmost frequent middles",
    "start": "286030",
    "end": "288520"
  },
  {
    "text": "are really natural\nand intuitive.",
    "start": "288520",
    "end": "291590"
  },
  {
    "text": "For example, comma, \"starring\"\nindicates a reverse film",
    "start": "291590",
    "end": "296710"
  },
  {
    "text": "performance relation.",
    "start": "296710",
    "end": "299440"
  },
  {
    "text": "So that would be one\nwhere the film comes first",
    "start": "299440",
    "end": "301870"
  },
  {
    "text": "and the actor comes second.",
    "start": "301870",
    "end": "304918"
  },
  {
    "text": "And I think that\nmakes perfect sense.",
    "start": "304918",
    "end": "306460"
  },
  {
    "text": "Star Wars, comma,\n\"starring\" Mark Hamill.",
    "start": "306460",
    "end": "312039"
  },
  {
    "text": "Similarly, comma, \"son of\"\nindicates a forward parents",
    "start": "312040",
    "end": "317170"
  },
  {
    "text": "relation.",
    "start": "317170",
    "end": "318200"
  },
  {
    "text": "So this would be one\nwhere the son comes first.",
    "start": "318200",
    "end": "321550"
  },
  {
    "text": "The child comes first and\nthe parent comes second.",
    "start": "321550",
    "end": "326690"
  },
  {
    "text": "So those are extremely\nintuitive and it's reassuring",
    "start": "326690",
    "end": "329530"
  },
  {
    "text": "to see them near the top of the\nlist of most common middles.",
    "start": "329530",
    "end": "335870"
  },
  {
    "text": "Another observation is\nthat punctuation and stop",
    "start": "335870",
    "end": "339530"
  },
  {
    "text": "words, like comma and\n\"and\" are extremely common.",
    "start": "339530",
    "end": "345780"
  },
  {
    "text": "Unlike some other\nNLP applications,",
    "start": "345780",
    "end": "348480"
  },
  {
    "text": "it's probably a bad idea\nto throw these away.",
    "start": "348480",
    "end": "350880"
  },
  {
    "text": "They carry lots of\nuseful information.",
    "start": "350880",
    "end": "354840"
  },
  {
    "text": "On the other hand,\npunctuation and stop words",
    "start": "354840",
    "end": "357060"
  },
  {
    "text": "tend to be highly ambiguous.",
    "start": "357060",
    "end": "359770"
  },
  {
    "text": "For example, if you look\nacross the full range of all 16",
    "start": "359770",
    "end": "362550"
  },
  {
    "text": "relations, you'll\nsee that a bare comma",
    "start": "362550",
    "end": "365550"
  },
  {
    "text": "is a likely middle for almost\nevery relation in at least",
    "start": "365550",
    "end": "369569"
  },
  {
    "text": "one direction.",
    "start": "369570",
    "end": "370930"
  },
  {
    "text": "So that comma does very\noften indicate a relation,",
    "start": "370930",
    "end": "373740"
  },
  {
    "text": "but it's a really\nambiguous indicator.",
    "start": "373740",
    "end": "378440"
  },
  {
    "text": "OK.",
    "start": "378440",
    "end": "378940"
  },
  {
    "text": "Now that we've identified\nthe most common middles",
    "start": "378940",
    "end": "380982"
  },
  {
    "text": "for each relation, it's\nstraightforward to build",
    "start": "380982",
    "end": "383260"
  },
  {
    "text": "a classifier based on that\ninformation, a classifier that",
    "start": "383260",
    "end": "386590"
  },
  {
    "text": "predicts true for a candidate\nKB triple, just in case",
    "start": "386590",
    "end": "391090"
  },
  {
    "text": "the two entities in the triple\nappear in the corpus connected",
    "start": "391090",
    "end": "395080"
  },
  {
    "text": "by one of the phrases\nthat we just discovered.",
    "start": "395080",
    "end": "397900"
  },
  {
    "text": "I don't show the\ncode for that here,",
    "start": "397900",
    "end": "399470"
  },
  {
    "text": "but it's in the Python\nnotebook for this unit.",
    "start": "399470",
    "end": "403390"
  },
  {
    "text": "And when we evaluate\nthis approach,",
    "start": "403390",
    "end": "405310"
  },
  {
    "text": "we see some really\ninteresting results.",
    "start": "405310",
    "end": "408310"
  },
  {
    "text": "First, recall is much\nworse across the board.",
    "start": "408310",
    "end": "412570"
  },
  {
    "text": "And that makes sense\nbecause we're no longer just",
    "start": "412570",
    "end": "415540"
  },
  {
    "text": "guessing randomly.",
    "start": "415540",
    "end": "416860"
  },
  {
    "text": "Before, we were saying\ntrue half the time.",
    "start": "416860",
    "end": "420400"
  },
  {
    "text": "Now, we're going to be a lot\nmore selective about what",
    "start": "420400",
    "end": "422680"
  },
  {
    "text": "we say true to.",
    "start": "422680",
    "end": "424570"
  },
  {
    "text": "But precision and F-score\nhave improved dramatically",
    "start": "424570",
    "end": "429790"
  },
  {
    "text": "for several\nrelations, especially",
    "start": "429790",
    "end": "431950"
  },
  {
    "text": "for adjoins and author and\nhas_sibling and has_spouse.",
    "start": "431950",
    "end": "438730"
  },
  {
    "text": "Then again, there are\nmany other relations",
    "start": "438730",
    "end": "440500"
  },
  {
    "text": "where precision and F-score\nare still quite poor, including",
    "start": "440500",
    "end": "445000"
  },
  {
    "text": "this one genre where\nwe get straight zeros",
    "start": "445000",
    "end": "447772"
  },
  {
    "text": "across the board.",
    "start": "447772",
    "end": "448480"
  },
  {
    "text": "I'm not quite sure\nwhat happened there.",
    "start": "448480",
    "end": "451240"
  },
  {
    "text": "But it indicates\nthat although things",
    "start": "451240",
    "end": "454180"
  },
  {
    "text": "have improved a\nlot in some places,",
    "start": "454180",
    "end": "457000"
  },
  {
    "text": "they're still rather\npoor in others.",
    "start": "457000",
    "end": "459940"
  },
  {
    "text": "And our macro-average F-score\nhas improved only modestly,",
    "start": "459940",
    "end": "463660"
  },
  {
    "text": "so it improved\nfrom 9.7% to 11.1%.",
    "start": "463660",
    "end": "468208"
  },
  {
    "text": "We're heading in\nthe right direction,",
    "start": "468208",
    "end": "469750"
  },
  {
    "text": "but you'd have to say that's\nstill pretty unimpressive.",
    "start": "469750",
    "end": "473470"
  },
  {
    "text": "To make significant\ngains, we're going",
    "start": "473470",
    "end": "475660"
  },
  {
    "text": "to need to apply\nmachine learning.",
    "start": "475660",
    "end": "479760"
  },
  {
    "start": "479000",
    "end": "714000"
  },
  {
    "text": "So let's get started on that.",
    "start": "479760",
    "end": "481080"
  },
  {
    "text": "We're going to build a very\nsimple classifier using",
    "start": "481080",
    "end": "483689"
  },
  {
    "text": "an approach that should\nbe familiar from our look",
    "start": "483690",
    "end": "486600"
  },
  {
    "text": "at sentiment analysis last week.",
    "start": "486600",
    "end": "489730"
  },
  {
    "text": "And we're going to start that\nby defining a very simple",
    "start": "489730",
    "end": "492840"
  },
  {
    "text": "bag-of-words feature function.",
    "start": "492840",
    "end": "495400"
  },
  {
    "text": "So here's the code\nfor that, and let",
    "start": "495400",
    "end": "498509"
  },
  {
    "text": "me briefly walk you through it.",
    "start": "498510",
    "end": "500100"
  },
  {
    "text": "What we're going to do is to get\nthe features for a KB triple.",
    "start": "500100",
    "end": "504660"
  },
  {
    "text": "That's the kbt here.",
    "start": "504660",
    "end": "506850"
  },
  {
    "text": "We're going to find all of\nthe corpus examples containing",
    "start": "506850",
    "end": "510990"
  },
  {
    "text": "the two entities in the\nKB triple, the subject",
    "start": "510990",
    "end": "513839"
  },
  {
    "text": "and the object.",
    "start": "513840",
    "end": "514979"
  },
  {
    "text": "And note that we do that in both\ndirections, subject and object,",
    "start": "514980",
    "end": "519058"
  },
  {
    "text": "and then, also\nobject and subject.",
    "start": "519059",
    "end": "522349"
  },
  {
    "text": "For each example, we\nlook at the middle.",
    "start": "522350",
    "end": "525990"
  },
  {
    "text": "We break it into words.",
    "start": "525990",
    "end": "527850"
  },
  {
    "text": "And then, we count\nup all the words.",
    "start": "527850",
    "end": "531490"
  },
  {
    "text": "So a couple of\nthings to note here.",
    "start": "531490",
    "end": "533390"
  },
  {
    "text": "One is that the feature\nrepresentation for one KB",
    "start": "533390",
    "end": "537160"
  },
  {
    "text": "triple can be derived\nfrom many corpus examples.",
    "start": "537160",
    "end": "542199"
  },
  {
    "text": "And this is the point that I\nwas trying to make last time,",
    "start": "542200",
    "end": "546040"
  },
  {
    "text": "that we're using the\ncorpus to generate features",
    "start": "546040",
    "end": "550480"
  },
  {
    "text": "for a candidate KB triple.",
    "start": "550480",
    "end": "553240"
  },
  {
    "text": "And the role of the corpus\nis to provide the feature",
    "start": "553240",
    "end": "556510"
  },
  {
    "text": "representation.",
    "start": "556510",
    "end": "557830"
  },
  {
    "text": "And the feature\nrepresentation for a KB",
    "start": "557830",
    "end": "559780"
  },
  {
    "text": "triple will be based\non all of the examples",
    "start": "559780",
    "end": "563470"
  },
  {
    "text": "in the corpus that contain\nthose two entities.",
    "start": "563470",
    "end": "566952"
  },
  {
    "text": "The other observation\nto make here",
    "start": "566953",
    "end": "568370"
  },
  {
    "text": "is that we make no\ndistinction between what",
    "start": "568370",
    "end": "571220"
  },
  {
    "text": "you might call forward examples,\nwhich have subject first",
    "start": "571220",
    "end": "574279"
  },
  {
    "text": "and then object, and reverse\nexamples, which have object",
    "start": "574280",
    "end": "577640"
  },
  {
    "text": "and then subject.",
    "start": "577640",
    "end": "578750"
  },
  {
    "text": "We're lumping them all together.",
    "start": "578750",
    "end": "580580"
  },
  {
    "text": "The words that come from\nthe middles of examples",
    "start": "580580",
    "end": "584120"
  },
  {
    "text": "in either direction\nall get lumped together",
    "start": "584120",
    "end": "587240"
  },
  {
    "text": "into one feature counter.",
    "start": "587240",
    "end": "589172"
  },
  {
    "text": "And you might have qualms\nabout whether that's really",
    "start": "589172",
    "end": "591380"
  },
  {
    "text": "the smartest thing to do.",
    "start": "591380",
    "end": "592460"
  },
  {
    "start": "592460",
    "end": "595910"
  },
  {
    "text": "So let's get a sense of what\nthis looks like in action.",
    "start": "595910",
    "end": "599100"
  },
  {
    "text": "First, let's print out the\nvery first KB triple in our KB.",
    "start": "599100",
    "end": "604647"
  },
  {
    "text": "We actually looked\nat this last time.",
    "start": "604648",
    "end": "606190"
  },
  {
    "text": "It's a KB triple that says--",
    "start": "606190",
    "end": "609046"
  },
  {
    "text": "that contains relation, holds\nbetween Brickfields and Kuala",
    "start": "609046",
    "end": "612358"
  },
  {
    "text": "Lumpur Sentral railway station.",
    "start": "612358",
    "end": "613649"
  },
  {
    "start": "613650",
    "end": "617860"
  },
  {
    "text": "And now, let's look\nup the first example",
    "start": "617860",
    "end": "621339"
  },
  {
    "text": "containing these two entities.",
    "start": "621340",
    "end": "622630"
  },
  {
    "text": "I'm just going to look them\nup in the forward direction,",
    "start": "622630",
    "end": "624963"
  },
  {
    "text": "subject and object, and\nget all the examples.",
    "start": "624963",
    "end": "628360"
  },
  {
    "text": "I look at the first one, and let\nme just point out the middle.",
    "start": "628360",
    "end": "631209"
  },
  {
    "text": "The middle says, \"It was just\na quick 10-minute walk to.\"",
    "start": "631210",
    "end": "633730"
  },
  {
    "text": "So I guess the full example\nprobably said something",
    "start": "633730",
    "end": "635855"
  },
  {
    "text": "like, \"From\nBrickfields, it was just",
    "start": "635855",
    "end": "638680"
  },
  {
    "text": "a quick 10-minute walk to\nKuala Lumpur Sentral railway",
    "start": "638680",
    "end": "641649"
  },
  {
    "text": "station.\"",
    "start": "641650",
    "end": "642978"
  },
  {
    "text": "And maybe there was more.",
    "start": "642978",
    "end": "644020"
  },
  {
    "start": "644020",
    "end": "647140"
  },
  {
    "text": "Now, let's run our\nfeaturizer on this KB triple",
    "start": "647140",
    "end": "651610"
  },
  {
    "text": "and see what features we get.",
    "start": "651610",
    "end": "654320"
  },
  {
    "text": "So we get a counter that\ncontains \"It was just",
    "start": "654320",
    "end": "657640"
  },
  {
    "text": "a quick 10-minute\nwalk to the--\" So it",
    "start": "657640",
    "end": "661660"
  },
  {
    "text": "looks like it's counted up the\nwords in that middle, which",
    "start": "661660",
    "end": "664300"
  },
  {
    "text": "is just what we expected.",
    "start": "664300",
    "end": "667073"
  },
  {
    "text": "But if you look closely, there's\nsomething unexpected here",
    "start": "667073",
    "end": "669490"
  },
  {
    "text": "because the word \"two\"\nhas a count of 2,",
    "start": "669490",
    "end": "672820"
  },
  {
    "text": "even though it appears\nonly once in that middle.",
    "start": "672820",
    "end": "676510"
  },
  {
    "text": "And also, the word\n\"the\" has a count of 1,",
    "start": "676510",
    "end": "678850"
  },
  {
    "text": "even though it didn't appear\nin that middle at all.",
    "start": "678850",
    "end": "682940"
  },
  {
    "text": "So where did those come from?",
    "start": "682940",
    "end": "684980"
  },
  {
    "text": "Well, remember that the\nfeaturizer counts words",
    "start": "684980",
    "end": "687820"
  },
  {
    "text": "from the middles of all examples\ncontaining those entities",
    "start": "687820",
    "end": "691960"
  },
  {
    "text": "in either direction.",
    "start": "691960",
    "end": "693920"
  },
  {
    "text": "And it turns out that\nthe corpus contains",
    "start": "693920",
    "end": "696130"
  },
  {
    "text": "another example containing\nthose two entities",
    "start": "696130",
    "end": "699100"
  },
  {
    "text": "and that other example has--",
    "start": "699100",
    "end": "701889"
  },
  {
    "text": "there's just one other\nexample, but that other example",
    "start": "701890",
    "end": "704560"
  },
  {
    "text": "has middle \"to the.\"",
    "start": "704560",
    "end": "707080"
  },
  {
    "text": "And so, that's where\nthese counts come from.",
    "start": "707080",
    "end": "710570"
  },
  {
    "text": "So all is well.",
    "start": "710570",
    "end": "711342"
  },
  {
    "text": "We did the right thing.",
    "start": "711342",
    "end": "712300"
  },
  {
    "start": "712300",
    "end": "715080"
  },
  {
    "start": "714000",
    "end": "820000"
  },
  {
    "text": "OK.",
    "start": "715080",
    "end": "715620"
  },
  {
    "text": "We have our simple\nbag-of-words featurizer.",
    "start": "715620",
    "end": "718070"
  },
  {
    "text": "Now, we need a way to train\nmodels to make predictions",
    "start": "718070",
    "end": "722190"
  },
  {
    "text": "and to evaluate the results.",
    "start": "722190",
    "end": "724860"
  },
  {
    "text": "The RelExt module contains\nfunctions for each of those.",
    "start": "724860",
    "end": "728829"
  },
  {
    "text": "And so, I just want to\ngive you a quick tour",
    "start": "728830",
    "end": "731040"
  },
  {
    "text": "of what those functions are.",
    "start": "731040",
    "end": "733839"
  },
  {
    "text": "But you'll definitely want\nto go read the code for this,",
    "start": "733840",
    "end": "737530"
  },
  {
    "text": "so that you're more familiar\nwith how it can be used.",
    "start": "737530",
    "end": "740970"
  },
  {
    "text": "And a lot of this code appears\nin a file called RelExt,",
    "start": "740970",
    "end": "744379"
  },
  {
    "text": "rel_ext.py.",
    "start": "744380",
    "end": "748110"
  },
  {
    "text": "So we'll start with a\nfunction called train models.",
    "start": "748110",
    "end": "752670"
  },
  {
    "text": "This takes as arguments\nthe dictionary of data",
    "start": "752670",
    "end": "755579"
  },
  {
    "text": "splits, a list of featurizers.",
    "start": "755580",
    "end": "758130"
  },
  {
    "text": "And here, we have\na list consisting",
    "start": "758130",
    "end": "759900"
  },
  {
    "text": "of just our simple\nbag-of-words featurizer.",
    "start": "759900",
    "end": "763050"
  },
  {
    "text": "The name of the split\non which to train,",
    "start": "763050",
    "end": "765600"
  },
  {
    "text": "which defaults to train.",
    "start": "765600",
    "end": "767910"
  },
  {
    "text": "And a model factory, which\nis a function that returns",
    "start": "767910",
    "end": "777180"
  },
  {
    "text": "a classifier and it's--",
    "start": "777180",
    "end": "782106"
  },
  {
    "text": "sorry, a function which\ninitializes an Sk classifier.",
    "start": "782106",
    "end": "785730"
  },
  {
    "text": "And by default, it's a\nlogistic regression classifier,",
    "start": "785730",
    "end": "788760"
  },
  {
    "text": "as shown here.",
    "start": "788760",
    "end": "790020"
  },
  {
    "text": "But you could easily substitute\nthis with some other Sklearn",
    "start": "790020",
    "end": "794580"
  },
  {
    "text": "classifier.",
    "start": "794580",
    "end": "796620"
  },
  {
    "text": "It returns this thing\ncalled train_result",
    "start": "796620",
    "end": "800070"
  },
  {
    "text": "which is a dictionary holding\nthe featurizers, the vectorizer",
    "start": "800070",
    "end": "804570"
  },
  {
    "text": "that was used to generate\nthe training matrix,",
    "start": "804570",
    "end": "806760"
  },
  {
    "text": "and most importantly, a\ndictionary holding the trained",
    "start": "806760",
    "end": "810090"
  },
  {
    "text": "models, one per relation.",
    "start": "810090",
    "end": "812700"
  },
  {
    "text": "So it's a dictionary which maps\nfrom relation names to models.",
    "start": "812700",
    "end": "818450"
  },
  {
    "text": "So that's train models.",
    "start": "818450",
    "end": "820760"
  },
  {
    "start": "820000",
    "end": "850000"
  },
  {
    "text": "Next comes predict,\nthis is a function",
    "start": "820760",
    "end": "824630"
  },
  {
    "text": "that takes his arguments a\ndictionary of data splits.",
    "start": "824630",
    "end": "827660"
  },
  {
    "text": "The output of train models,\nthat train results thing,",
    "start": "827660",
    "end": "833527"
  },
  {
    "text": "and the name of the split on\nwhich to make predictions.",
    "start": "833528",
    "end": "835820"
  },
  {
    "text": "And by default that's dev.",
    "start": "835820",
    "end": "838040"
  },
  {
    "text": "And it returns two\nparallel dictionaries,",
    "start": "838040",
    "end": "840709"
  },
  {
    "text": "one holds the predictions\ngrouped by relation",
    "start": "840710",
    "end": "843950"
  },
  {
    "text": "and the other holds the true\nlabels grouped by relation.",
    "start": "843950",
    "end": "846455"
  },
  {
    "start": "846455",
    "end": "849550"
  },
  {
    "text": "And our third building block\nis evaluate predictions.",
    "start": "849550",
    "end": "853220"
  },
  {
    "start": "850000",
    "end": "873000"
  },
  {
    "text": "So this is a function that\ntakes as arguments the two",
    "start": "853220",
    "end": "856660"
  },
  {
    "text": "parallel dictionaries\nof predictions",
    "start": "856660",
    "end": "859000"
  },
  {
    "text": "and true labels\nproduced by predict,",
    "start": "859000",
    "end": "862520"
  },
  {
    "text": "and it prints evaluation\nmetrics for each relation,",
    "start": "862520",
    "end": "865970"
  },
  {
    "text": "like we saw earlier.",
    "start": "865970",
    "end": "868970"
  },
  {
    "text": "Now, before we dwell\non these results,",
    "start": "868970",
    "end": "870680"
  },
  {
    "text": "I want to show one\nmore function, which is",
    "start": "870680",
    "end": "875100"
  },
  {
    "start": "873000",
    "end": "993000"
  },
  {
    "text": "a function called experiment.",
    "start": "875100",
    "end": "877290"
  },
  {
    "text": "And experiment simply chains\ntogether the three functions",
    "start": "877290",
    "end": "880891"
  },
  {
    "text": "that I just showed you.",
    "start": "880892",
    "end": "881850"
  },
  {
    "text": "It chains together training,\nprediction, and evaluation.",
    "start": "881850",
    "end": "886350"
  },
  {
    "text": "So that's very convenient for\nrunning end to end experiments.",
    "start": "886350",
    "end": "890350"
  },
  {
    "text": "I haven't shown all\nthe parameters here,",
    "start": "890350",
    "end": "892806"
  },
  {
    "text": "but if you go look\nat the source code,",
    "start": "892807",
    "end": "894390"
  },
  {
    "text": "you'll see that\nit actually takes",
    "start": "894390",
    "end": "895765"
  },
  {
    "text": "a lot of optional parameters.",
    "start": "895765",
    "end": "897670"
  },
  {
    "text": "And those parameters let you\nspecify everything about how",
    "start": "897670",
    "end": "901722"
  },
  {
    "text": "to run the experiment.",
    "start": "901723",
    "end": "902640"
  },
  {
    "text": "It lets you specify your\nfeaturizers, your model",
    "start": "902640",
    "end": "905490"
  },
  {
    "text": "factory, which splits to\ntrain and test on, and more.",
    "start": "905490",
    "end": "910260"
  },
  {
    "text": "So for example, earlier, I\nmentioned that the tiny split",
    "start": "910260",
    "end": "914130"
  },
  {
    "text": "is really useful for running\nfast experiments to work out",
    "start": "914130",
    "end": "917190"
  },
  {
    "text": "the kinks.",
    "start": "917190",
    "end": "918360"
  },
  {
    "text": "If you wanted to do\nthat, it's very easy",
    "start": "918360",
    "end": "920850"
  },
  {
    "text": "using the experiment\nfunction just",
    "start": "920850",
    "end": "922949"
  },
  {
    "text": "to set the training\nsplit and the test split",
    "start": "922950",
    "end": "925620"
  },
  {
    "text": "to tiny to run a very\nquick experiment.",
    "start": "925620",
    "end": "928680"
  },
  {
    "start": "928680",
    "end": "931779"
  },
  {
    "text": "Now, here are the\nresults of evaluating",
    "start": "931780",
    "end": "934120"
  },
  {
    "text": "our simple bag-of-words\nlogistic regression classifier.",
    "start": "934120",
    "end": "938529"
  },
  {
    "text": "And let's take a closer look,\nbecause this is quite stunning.",
    "start": "938530",
    "end": "943060"
  },
  {
    "text": "Even though this is\njust about the simplest",
    "start": "943060",
    "end": "945430"
  },
  {
    "text": "possible classifier,\nwe've achieved huge gains",
    "start": "945430",
    "end": "949360"
  },
  {
    "text": "over the phrase\nmatching approach.",
    "start": "949360",
    "end": "951649"
  },
  {
    "text": "The first thing\nthat jumps out is",
    "start": "951650",
    "end": "953200"
  },
  {
    "text": "that our macro-averaged F-score\nhas jumped from 11.1 to 56.7.",
    "start": "953200",
    "end": "960370"
  },
  {
    "text": "And we see big\ngains in precision",
    "start": "960370",
    "end": "962980"
  },
  {
    "text": "for almost every single\nrelation and correspondingly,",
    "start": "962980",
    "end": "967540"
  },
  {
    "text": "big gains in F-score.",
    "start": "967540",
    "end": "971240"
  },
  {
    "text": "On the other hand, there's still\nplenty of room for improvement.",
    "start": "971240",
    "end": "974040"
  },
  {
    "text": "I mean this is much, much\nmore impressive than where",
    "start": "974040",
    "end": "978290"
  },
  {
    "text": "we were before, but we're\nvery far from perfection.",
    "start": "978290",
    "end": "982019"
  },
  {
    "text": "There's abundant\nheadroom and opportunity",
    "start": "982020",
    "end": "985130"
  },
  {
    "text": "to continue to improve.",
    "start": "985130",
    "end": "987400"
  },
  {
    "start": "987400",
    "end": "992000"
  }
]
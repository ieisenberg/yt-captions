[
  {
    "start": "0",
    "end": "5040"
  },
  {
    "text": "Welcome to week 2. How's the week? [INAUDIBLE] 49ers remain undefeated.",
    "start": "5040",
    "end": "13040"
  },
  {
    "text": "Giant season is over. [LAUGHS] All right. [INAUDIBLE]",
    "start": "13040",
    "end": "18350"
  },
  {
    "text": "Yeah. Yeah, exactly. So just as a reminder\nfrom last week, on Tuesday, we had this pretty,\npretty substantial lecture",
    "start": "18350",
    "end": "26509"
  },
  {
    "text": "where we talked about three big\nideas in throughput computing. We talked about\nmulti-core execution.",
    "start": "26510",
    "end": "33600"
  },
  {
    "text": "We talked about SIMD execution. And at the very end,\nwe started talking about another idea called\nhardware multithreading, which",
    "start": "33600",
    "end": "40340"
  },
  {
    "text": "again happened at\nthe end of the class when people were starting\nto get a little tired or something like that. So I want to really review\nthe hardware multithreading.",
    "start": "40340",
    "end": "47090"
  },
  {
    "text": "That's what I'm\ngoing to start with. I'm going to review big\nconcepts from last time. And then we're going to go into\nthe back half of the lecture.",
    "start": "47090",
    "end": "54120"
  },
  {
    "text": "We'll actually talk about\nISPC programming, which is the language that you do a\nlot of your work in assignment 1",
    "start": "54120",
    "end": "59580"
  },
  {
    "text": "in, not for the purposes\nof teaching you a language, but to underscore some of\nthe concepts from last time.",
    "start": "59580",
    "end": "65330"
  },
  {
    "text": "Any questions? If not, let me pull up\nthe slides from last time",
    "start": "65330",
    "end": "73090"
  },
  {
    "text": "where I had a figure up\nthat looked like this. So that last 10\nminutes of the lecture",
    "start": "73090",
    "end": "78880"
  },
  {
    "text": "last time had one very\nsimple idea in it, which was, if you are waiting\non something to happen,",
    "start": "78880",
    "end": "86560"
  },
  {
    "text": "you go do something else. That was the whole idea. The first part of the\nlecture was largely",
    "start": "86560",
    "end": "93130"
  },
  {
    "text": "about adding more and more\nunits to the processor. This last section was about\nmaking use of those units",
    "start": "93130",
    "end": "102100"
  },
  {
    "text": "more efficiently. So I closed with a diagram that\nlooked a little bit like this. I said, we introduced\na SIMD core,",
    "start": "102100",
    "end": "112290"
  },
  {
    "text": "a processor that can\nexecute, in this case, one instruction per clock. But every one of\nthose instructions",
    "start": "112290",
    "end": "117970"
  },
  {
    "text": "is doing eight things at\nonce, the same eight things. So it's like adding to eight\nwide vectors or something like that, giving my diagram.",
    "start": "117970",
    "end": "124465"
  },
  {
    "text": "And we talked last\ntime about what does it mean to\nexecute instructions, and you all told me that\nwhen I run an instruction,",
    "start": "124465",
    "end": "130690"
  },
  {
    "text": "the result of that is\ngoing to be reflected in the change in the value in\nsome register or maybe a change",
    "start": "130690",
    "end": "136610"
  },
  {
    "text": "in value in memory. So running a thread, running\nan instruction stream says, I have my state\nover here, which",
    "start": "136610",
    "end": "143270"
  },
  {
    "text": "is like the state\nof all variables, and then I have operations\nor instructions which change the results of those variables.",
    "start": "143270",
    "end": "151540"
  },
  {
    "text": "So then we said, well,\nwait a minute here, if I'm trying to\nrun operations and I can't do that next\noperation because I'm",
    "start": "151540",
    "end": "157870"
  },
  {
    "text": "waiting on something-- and what was the biggest example\nof what we might be waiting on in class or last class?",
    "start": "157870",
    "end": "164920"
  },
  {
    "text": "Yeah. [INAUDIBLE] We were waiting on memory to\nrespond to a request which",
    "start": "164920",
    "end": "170440"
  },
  {
    "text": "could be 100 or more of cycles. Now, generalize that thought\nto waiting on anything.",
    "start": "170440",
    "end": "177320"
  },
  {
    "text": "It actually could be waiting\non some previous operation to complete, like doing some\ncomplex math instruction.",
    "start": "177320",
    "end": "183230"
  },
  {
    "text": "But we introduced this idea\nof waiting for a very, very long memory request. So the big idea is that\ninstead of sit there and wait,",
    "start": "183230",
    "end": "191470"
  },
  {
    "text": "go work on something else. So if this blue box\nis encapsulating the state of all my variables\nfor a thread, what I did",
    "start": "191470",
    "end": "200260"
  },
  {
    "text": "is I just added more blue\nboxes to the processor. I said, well, there's\nno reason why if I-- I'm not going to change\nany execution capability.",
    "start": "200260",
    "end": "207970"
  },
  {
    "text": "This processor can still only do\none SIMD instruction per clock.",
    "start": "207970",
    "end": "213380"
  },
  {
    "text": "But I'm going to go ahead\nand allow it to manage state for four threads.",
    "start": "213380",
    "end": "218689"
  },
  {
    "text": "So now when one thread\ncan't make progress, when I can't do that\nnext instruction, boom, the hardware just switches\nto the next instruction",
    "start": "218690",
    "end": "226189"
  },
  {
    "text": "for the next thread. And whenever there's\na stall like this, it doesn't waste any time.",
    "start": "226190",
    "end": "231360"
  },
  {
    "text": "It just moves over, and\nit does something else. Switch on stall. Switch on stall. Switch on stall.",
    "start": "231360",
    "end": "236700"
  },
  {
    "text": "Switch on stall. And at some point, maybe it gets\nback when this data is ready, it comes back to\nrunning this thread.",
    "start": "236700",
    "end": "243400"
  },
  {
    "text": "So in my diagram, time\nis going down here, down the vertical axis, the threads\n1, 2, 3, 4 on the diagram.",
    "start": "243400",
    "end": "250750"
  },
  {
    "text": "And I have these eight little\ncolumns inside each thread to indicate that they're issuing\nSIMD vector instructions.",
    "start": "250750",
    "end": "258338"
  },
  {
    "text": "So how many instructions\ndoes this core run per clock? ",
    "start": "258339",
    "end": "263440"
  },
  {
    "text": "One. That instruction is an\neight-wide vector instruction in this diagram.",
    "start": "263440",
    "end": "268870"
  },
  {
    "text": "How many threads does\nit run at any one time? One.",
    "start": "268870",
    "end": "274060"
  },
  {
    "text": "What is the utilization\nof the processor? 100%. If I go to any point in time\nand I say, is something running,",
    "start": "274060",
    "end": "282639"
  },
  {
    "text": "I will conclude that\nthe answer is yes. Now, what's the cost of\nthis idea, which by the way,",
    "start": "282640",
    "end": "289600"
  },
  {
    "text": "was largely invented by\n[INAUDIBLE] When was the first--",
    "start": "289600",
    "end": "296080"
  },
  {
    "text": "I mean, I guess there was all\nthe U-Dub stuff with Intel and then there was-- [INAUDIBLE]",
    "start": "296080",
    "end": "301639"
  },
  {
    "text": "But they weren't\nreally doing this. So this was Niagara and what-- what was your startup\nbefore Niagara?",
    "start": "301640",
    "end": "307900"
  },
  {
    "text": "[INAUDIBLE] Oh, OK. Yeah. ",
    "start": "307900",
    "end": "315030"
  },
  {
    "text": "So now keep in mind\nthat there's a cost. One cost is that I have to burn\nsome more chip space to hold",
    "start": "315030",
    "end": "321540"
  },
  {
    "text": "all these execution contexts. Another cost is that\nevery one of my threads",
    "start": "321540",
    "end": "328080"
  },
  {
    "text": "gets done with what\nit was supposed to do a little bit\nslower because it's sharing this processor\nwith the other threads.",
    "start": "328080",
    "end": "335430"
  },
  {
    "text": "So I want you to\nkeep that in mind. We are at 100% utilization.",
    "start": "335430",
    "end": "340520"
  },
  {
    "text": "We cannot get all the\nwork done any faster. But any one of those pieces of\nwork, any one of those threads",
    "start": "340520",
    "end": "348240"
  },
  {
    "text": "will be sharing the\nprocessor with other threads. So the amount of time\nit takes to do one thing is actually going up.",
    "start": "348240",
    "end": "354510"
  },
  {
    "text": "So if you had a very\nlatency-driven application, you might want to do this.",
    "start": "354510",
    "end": "361110"
  },
  {
    "text": "And this cost is-- the cost of the storage, you\ncan think about it as like,",
    "start": "361110",
    "end": "366510"
  },
  {
    "text": "there's a fixed amount\nof storage on chip that I can dedicate to\nthese execution contexts.",
    "start": "366510",
    "end": "371910"
  },
  {
    "text": "So, for example, I can take\nthat fixed amount of storage and I can say,\nwe're going to have",
    "start": "371910",
    "end": "377620"
  },
  {
    "text": "a bunch of execution contexts. I can interleave\na ton of threads, like 16 threads in this diagram,\nbut every one of those threads",
    "start": "377620",
    "end": "384205"
  },
  {
    "text": "is only going to have\na pretty small register file, small amount of state. Or I can divvy it\nup in other ways",
    "start": "384205",
    "end": "389289"
  },
  {
    "text": "and say, look, I want threads\nwith a lot of registers, a lot of access to\nlocal state, but I",
    "start": "389290",
    "end": "394420"
  },
  {
    "text": "want a little bit less\nability to go do something else and so on. So here's my new core.",
    "start": "394420",
    "end": "401349"
  },
  {
    "text": "This is a core\nthat in this class, I'll use the term\nhardware multithreaded. It means the hardware\nhas the ability",
    "start": "401350",
    "end": "407860"
  },
  {
    "text": "to run two different\ninstruction streams or it has the ability\nto maintain state for two different\ninstruction streams,",
    "start": "407860",
    "end": "414139"
  },
  {
    "text": "but this core, as I've\ndrawn it, can only run one instruction per clock.",
    "start": "414140",
    "end": "419330"
  },
  {
    "text": "And in this case, I've\nactually redrawn it to be a scalar instruction. You can see from the diagram.",
    "start": "419330",
    "end": "425259"
  },
  {
    "text": "So single-core processor,\nmultithreaded core can run one scalar\ninstruction per clock",
    "start": "425260",
    "end": "432520"
  },
  {
    "text": "from one of the threads. So the hardware, every\nsingle clock tick is going all right, which\nthread should I run?",
    "start": "432520",
    "end": "438498"
  },
  {
    "text": "I don't know. I'll pick one of them\nthat's available to run. I'm going to take\nthe next instruction from that instruction\nstream, and I'm",
    "start": "438498",
    "end": "443722"
  },
  {
    "text": "going to tell my\nexecution unit to do it. That's how the chip runs. There was a question.",
    "start": "443722",
    "end": "448730"
  },
  {
    "text": "Yeah, two things. Firstly, in the\nprevious scenario, I didn't get why\nit would be slower.",
    "start": "448730",
    "end": "454569"
  },
  {
    "text": "And secondly, how is this\nscenario going to [INAUDIBLE]? Let's say there's 15 students\nat office hours who are going",
    "start": "454570",
    "end": "460120"
  },
  {
    "text": "to ask me questions tomorrow\nduring my office hours, which, by the way, I had to move\nbecause of a faculty meeting conflict to 11:00 AM\ntomorrow, just so you know.",
    "start": "460120",
    "end": "467630"
  },
  {
    "text": "So announcement,\nmy office hours. Imagine that I have\n15 students there and I give them a bit\nof a hint, and then",
    "start": "467630",
    "end": "474130"
  },
  {
    "text": "I tell them to go\nthink about it. Imagine that when you\ngo think about it, let's say, I just\nsat there and waited",
    "start": "474130",
    "end": "481180"
  },
  {
    "text": "for you to think about it,\nand then you came back to me and we iterated\non this, and then I went to help the next student.",
    "start": "481180",
    "end": "487370"
  },
  {
    "text": "You would get out\nof there earlier, but I would be very inefficient. All the other students\nwould be pissed off",
    "start": "487370",
    "end": "493170"
  },
  {
    "text": "because they'd be waiting. Imagine I tell you,\ngo think about it and then get in the\nback of the line.",
    "start": "493170",
    "end": "499199"
  },
  {
    "text": "So then what's going to\nhappen is I'm constantly asking questions. I'm 100% utilized.",
    "start": "499200",
    "end": "504530"
  },
  {
    "text": "You could make no better\nuse of your professor. But you might-- if you\nhave a couple of followups,",
    "start": "504530",
    "end": "510130"
  },
  {
    "text": "you might not get out\nof there for a while. If my goal is to get\nyou out of my office as quickly as possible, I'm\ngoing to sit there and wait.",
    "start": "510130",
    "end": "517370"
  },
  {
    "text": "And I will be inefficient. If my goal is to help the\nmost amount of students in a fixed amount of time,\nI'm going to interleave you.",
    "start": "517370",
    "end": "523570"
  },
  {
    "text": "That's what I mean by any\none student is slower. So let's think about this. Here's a diagram.",
    "start": "523570",
    "end": "529220"
  },
  {
    "text": "Now, I flipped the direction\nnow just because I needed width. Time is going this way. These are clock cycles.",
    "start": "529220",
    "end": "535300"
  },
  {
    "text": "Now, imagine I have\na program here, which says it's going to\ndo three math operations,",
    "start": "535300",
    "end": "542140"
  },
  {
    "text": "and then it's going\nto wait on memory. And let's just say,\nit can't make progress until that comes back.",
    "start": "542140",
    "end": "547820"
  },
  {
    "text": "So it's going to do three\nmath operations, which I'm going to denote here. Notice that blue\nindicates the processor",
    "start": "547820",
    "end": "553959"
  },
  {
    "text": "is busy running thread 0. And then there's going to\nbe a memory operation, which for the sake of this\nslide I want you to think",
    "start": "553960",
    "end": "560770"
  },
  {
    "text": "of as 12 cycles of latency. So time, again,\nis going this way.",
    "start": "560770",
    "end": "566149"
  },
  {
    "text": "I changed it up. All right. So here's the question. Let's say, this program repeats\nover and over and over again.",
    "start": "566150",
    "end": "574390"
  },
  {
    "text": "I can get going again, then it\nstalls, and so on and so on. So this makes sense.",
    "start": "574390",
    "end": "579490"
  },
  {
    "text": "My question is, what is the\nutilization of the processor?",
    "start": "579490",
    "end": "584783"
  },
  {
    "text": "I guess I can draw it\nall the way out for you. ",
    "start": "584783",
    "end": "591460"
  },
  {
    "text": "Sorry. [INAUDIBLE] You just kind of count. ",
    "start": "591460",
    "end": "596960"
  },
  {
    "text": "I do three cycles of work,\nand then I wait for 12. So out of every\ngroup of 15 cycles,",
    "start": "596960",
    "end": "602779"
  },
  {
    "text": "I'm doing three cycles of work. So three out of 15. It's one fifth, right. So I'm at 20% utilized.",
    "start": "602780",
    "end": "611560"
  },
  {
    "text": "Now let's think about what\nhappens if I add another thread. So now this core can--",
    "start": "611560",
    "end": "617800"
  },
  {
    "text": "it says, well, thread\n0 can't make progress. Shoot, I'm going to go ahead and\nrun instructions from thread 1.",
    "start": "617800",
    "end": "622899"
  },
  {
    "text": "So we get three\ninstructions from thread 1, then thread 1 stalls,\nand so on and so on.",
    "start": "622900",
    "end": "630500"
  },
  {
    "text": "So now what's the\nutilization of my processor? [INAUDIBLE] It doubled, because now I can\ndo three instructions from you",
    "start": "630500",
    "end": "638240"
  },
  {
    "text": "and three instructions from you. And then I got to wait\ntill some stuff comes back, and then I get going.",
    "start": "638240",
    "end": "643610"
  },
  {
    "text": "All right. So now with your best\nfriend sitting next to you, I want to know-- talk this\nover for 15, 20 seconds--",
    "start": "643610",
    "end": "650190"
  },
  {
    "text": "how many threads do you need\nif you want 100% efficiency on this program?",
    "start": "650190",
    "end": "655310"
  },
  {
    "text": "How many threads do you need? Give it a shot. [INTERPOSING VOICES]",
    "start": "655310",
    "end": "662560"
  },
  {
    "text": " Look at the pattern. I'm doing three units\nof work every 15 cycles.",
    "start": "662560",
    "end": "670440"
  },
  {
    "text": "3 plus 12 stall, 3\nplus 12 stall Mm-hmm. Mm-hmm.",
    "start": "670440",
    "end": "676040"
  },
  {
    "text": "What do you think? Anybody want to\nvolunteer an answer. How many threads?",
    "start": "676040",
    "end": "681110"
  },
  {
    "text": "Five. Why did you say 5? That's the correct answer. ",
    "start": "681110",
    "end": "686740"
  },
  {
    "text": "Help me out. One over one fifth. One over one fifth. ",
    "start": "686740",
    "end": "693397"
  },
  {
    "text": "You can think about it that way. Another way to think\nabout it-- the way I like to think about it is how\nmuch if I-- if I have one thread",
    "start": "693397",
    "end": "699279"
  },
  {
    "text": "and it stalls, how much\nlatency do I need to cover? I need to cover four\ncycles of latency.",
    "start": "699280",
    "end": "705710"
  },
  {
    "text": "And in this program,\nevery thread gives me three\ncycles of coverage. So I'm going to need\nfour additional threads",
    "start": "705710",
    "end": "712389"
  },
  {
    "text": "to cover that gap. So I'm going to\nneed the one I just stalled on plus four\nadditional threads",
    "start": "712390",
    "end": "717670"
  },
  {
    "text": "to be runnable to get\nto five threads required for 100% utilization.",
    "start": "717670",
    "end": "723200"
  },
  {
    "text": "So here's a question. Now, imagine that I\nmoved to a processor that can interleave eight threads\nat once with the same program.",
    "start": "723200",
    "end": "731959"
  },
  {
    "text": "How much faster do I run? Talk it over. [INTERPOSING VOICES]",
    "start": "731960",
    "end": "739550"
  },
  {
    "text": "All right. What do you think? And really, I was\na little cavalier in saying how much\nfaster do I run.",
    "start": "739550",
    "end": "745840"
  },
  {
    "text": "I probably should have\nbeen more specific. I should say, what is the\nutilization of my processor?",
    "start": "745840",
    "end": "751250"
  },
  {
    "text": "Or what is the rate at which I\nfinish things or get stuff done?",
    "start": "751250",
    "end": "756320"
  },
  {
    "text": "Am I doing any\nbetter than before. Yeah. 100%. I mean, I was already\nrunning at 100%.",
    "start": "756320",
    "end": "762000"
  },
  {
    "text": "And now I'm going to have,\nlet's say, a bunch more threads in this case, I guess--",
    "start": "762000",
    "end": "767060"
  },
  {
    "text": "I have seven other threads to\ncover the latency of this stall. By the time that\nmemory gets back,",
    "start": "767060",
    "end": "773250"
  },
  {
    "text": "I only need, like you\ntold me last time, four other threads-- a total of\n5 in order to cover that stall.",
    "start": "773250",
    "end": "778880"
  },
  {
    "text": "So what would you build-- if\nthis was the only program you ever had to run, would you build\nan eight-way threaded processor?",
    "start": "778880",
    "end": "786290"
  },
  {
    "text": "Probably pretty\ninefficient because you'd end up burning more chip\nspace to store these execution",
    "start": "786290",
    "end": "792280"
  },
  {
    "text": "contexts. And every single thread would\nhave higher overall completion latency because it's\nsharing this one resource",
    "start": "792280",
    "end": "799029"
  },
  {
    "text": "with more and more threads. Now let me change this a second. So now I change the\nprogram, not the computer.",
    "start": "799030",
    "end": "807970"
  },
  {
    "text": "I change the program so there's\nsix arithmetic instructions followed by that memory access.",
    "start": "807970",
    "end": "814810"
  },
  {
    "text": "Now go tell me-- again,\ntake your 30 seconds. Tell me how many\nthreads you need to run at full util--\nfull utilization.",
    "start": "814810",
    "end": "822821"
  },
  {
    "text": "[INTERPOSING VOICES] And by the way, first,\nconvince yourself, I'm currently running\nat 33% utilization.",
    "start": "822821",
    "end": "830649"
  },
  {
    "text": "[INAUDIBLE]",
    "start": "830650",
    "end": "837240"
  },
  {
    "text": "So you've got to find a\n6-cycle stall or sorry, a 12-cycle stall. How many threads do you need.",
    "start": "837240",
    "end": "843460"
  },
  {
    "text": "If every thread gives you 6? You need two more threads. So you need a total\nof three threads",
    "start": "843460",
    "end": "849240"
  },
  {
    "text": "to run at 100% utilization. So this is interesting, The\nratio of math to latency",
    "start": "849240",
    "end": "858480"
  },
  {
    "text": "is what determines how\nmuch multithreading you need to run at peak utilization. So if you have programs that\nhave a higher ratio of math",
    "start": "858480",
    "end": "867420"
  },
  {
    "text": "to memory latency,\nthen you have-- then you have the ability to get\nby with fewer and fewer threads.",
    "start": "867420",
    "end": "876060"
  },
  {
    "text": "Or equivalently, if you\nbuild a big data cache, a data cache might absorb\nsome of these cache misses",
    "start": "876060",
    "end": "882029"
  },
  {
    "text": "and actually bring in\nyour memory access time. So a big data cache probably\nmeans you need fewer threads.",
    "start": "882030",
    "end": "888220"
  },
  {
    "text": "If you take out the data\ncache, you take more misses, and you actually\nneed more threads.",
    "start": "888220",
    "end": "893860"
  },
  {
    "text": "So takeaway number\n1 from the sequence is we haven't added anything\nto the process in terms of what",
    "start": "893860",
    "end": "900030"
  },
  {
    "text": "it can execute at any one time. We have given it no\nmore peak throughput.",
    "start": "900030",
    "end": "905640"
  },
  {
    "text": "However, we've given\nit a new mechanism to be able to utilize those\nresources more efficiently.",
    "start": "905640",
    "end": "912070"
  },
  {
    "text": " And we talked about how\nthis is about hiding",
    "start": "912070",
    "end": "918760"
  },
  {
    "text": "the effects of memory latency. Keep in mind that we haven't\nreduced memory latency at all. It was always 12 cycles.",
    "start": "918760",
    "end": "925220"
  },
  {
    "text": "We were just hiding its effects. We were just not stalling\nwhen we were waiting for that. Yes, sir.",
    "start": "925220",
    "end": "930470"
  },
  {
    "text": "[INAUDIBLE] But if we wanted\nto compute the theoretical max",
    "start": "930470",
    "end": "938649"
  },
  {
    "text": "benefit of additional\nhardware threads, then we could imagine a case\nwhere there's a lot of cache",
    "start": "938650",
    "end": "947410"
  },
  {
    "text": "misses and you're waiting around\na lot, and then perhaps it cleanly divides the workload.",
    "start": "947410",
    "end": "952600"
  },
  {
    "text": "But you might be in a\nsetting where that's not the case, as we just saw. So if you wanted to think\nof a theoretical max,",
    "start": "952600",
    "end": "959714"
  },
  {
    "text": "would we think\nabout just scaling it or you have to take some-- Well, the theoretical max\nwould be 100% utilization.",
    "start": "959715",
    "end": "966579"
  },
  {
    "text": "And then if you wanted to know\nthe speedup due to hardware multithreading, you'd have to\nknow the speed of only running",
    "start": "966580",
    "end": "972110"
  },
  {
    "text": "one thread at a time. So the two numbers\nare, what do I measure when I do\none thread at a time?",
    "start": "972110",
    "end": "978140"
  },
  {
    "text": "And then given what I know about\nwhat the processor-- if I just look it up in a book, what\nthis processor can do per clock",
    "start": "978140",
    "end": "983959"
  },
  {
    "text": "or estimate it, multithreading\nmight be able to get me close to that high water mark.",
    "start": "983960",
    "end": "990321"
  },
  {
    "text": "I'm going to take your\nquestion, and then we're going to iterate on that\njust a little bit more. Yes. Does it only take one cycle to\ngo from one thread to another?",
    "start": "990322",
    "end": "998740"
  },
  {
    "text": "Yeah, let's just for\nthe sake of this class, let's just assume that. You should just think\nabout it, if you're",
    "start": "998740",
    "end": "1003890"
  },
  {
    "text": "familiar with underlying\nprocessor details, all it's doing is switching\nthe current PC to another PC. ",
    "start": "1003890",
    "end": "1011519"
  },
  {
    "text": "So there were three ideas from\nlast time-- multi-core, SIMD,",
    "start": "1011520",
    "end": "1016650"
  },
  {
    "text": "and multithreading. And then the first class\nactually had superscalar. But let's think about it. So here is a fake chip.",
    "start": "1016650",
    "end": "1022030"
  },
  {
    "text": "It has 16 cores. Every core is single thread is\nfour-way threaded right now.",
    "start": "1022030",
    "end": "1028270"
  },
  {
    "text": "So if I have a program\nthat creates 64 threads, those threads will\njust get distributed",
    "start": "1028270",
    "end": "1034770"
  },
  {
    "text": "to those 64 execution contexts. Every single one of these cores\nindependently, every clock",
    "start": "1034770",
    "end": "1041730"
  },
  {
    "text": "is picking one of\nthose instructions from one of those four\nthreads to go run. And those instructions in this\ncase can be 8-wide vector.",
    "start": "1041730",
    "end": "1050190"
  },
  {
    "text": "So if I need 664\nthreads, each one can be doing eight\npieces of data at once.",
    "start": "1050190",
    "end": "1057100"
  },
  {
    "text": "If, let's say, we\nwere processing array like computing the sine\nof all the numbers, I would need 512\nindependent things to do,",
    "start": "1057100",
    "end": "1063710"
  },
  {
    "text": "array of at least\n512 to run this thing at peak rate with maximal\nlatency hiding ability.",
    "start": "1063710",
    "end": "1072750"
  },
  {
    "text": "That's what I want\nto make sense to you. If you look at\nthis, you might say, this is a 16 core processor.",
    "start": "1072750",
    "end": "1079650"
  },
  {
    "text": "And I'm telling you, it has a\npeak throughput of 16 times 8. 128 execution units\nor 128 pieces of data",
    "start": "1079650",
    "end": "1087590"
  },
  {
    "text": "can be processed in parallel. But in order to hide latency,\nyou better give it 512 things. ",
    "start": "1087590",
    "end": "1095650"
  },
  {
    "text": "This is all this put together. Now you asked me a\nquestion about x86. Let me take one of\nthose cores and give you",
    "start": "1095650",
    "end": "1103120"
  },
  {
    "text": "a coarse approximation to\nwhat's in a myth machine. A myth machine is a two-way\nmultithreaded machine.",
    "start": "1103120",
    "end": "1112390"
  },
  {
    "text": "It's also a\ntraditional Intel core, which means it can\nrun in a superscalar",
    "start": "1112390",
    "end": "1118539"
  },
  {
    "text": "fashion, multiple instructions\nper clock inside a core. So what this thing\nis going to do",
    "start": "1118540",
    "end": "1124240"
  },
  {
    "text": "is it's going to\nget-- it's going to look at its two threads. Now, my core here could only run\none instruction per clock/ so it",
    "start": "1124240",
    "end": "1130810"
  },
  {
    "text": "had to pick a thread and\nthen run the instruction. But imagine you\nhad a core, a core, again, just talking about\none of these things that",
    "start": "1130810",
    "end": "1137320"
  },
  {
    "text": "could run multiple\ninstructions per clock, which is what we used to call\na superscalar processors.",
    "start": "1137320",
    "end": "1142630"
  },
  {
    "text": "So I have a couple of\ndifferent execution units, and then I have two threads I\ncan go grab instructions from.",
    "start": "1142630",
    "end": "1150310"
  },
  {
    "text": "So if I had to\ncartoon out myth, it might look something like this.",
    "start": "1150310",
    "end": "1156100"
  },
  {
    "text": "It's got two core--\nit's got two threads. Intel likes to call these hyper\nthreads that it can draw from.",
    "start": "1156100",
    "end": "1161289"
  },
  {
    "text": "And it has at least three,\neight-wide vector ALUs and a bunch of scalar I\nplus 1 stuff that it can do.",
    "start": "1161290",
    "end": "1169940"
  },
  {
    "text": "So in every clock\nthis chip is going, I can utilize up to three\nvector operations per clock",
    "start": "1169940",
    "end": "1176679"
  },
  {
    "text": "from these ALUs-- from those two threads. So in some sense, it\ncan find a mul, add.",
    "start": "1176680",
    "end": "1183122"
  },
  {
    "text": "It can find another mul, add. It can find another mul, add. The details of this\nare not-- you're",
    "start": "1183122",
    "end": "1188830"
  },
  {
    "text": "not expected to be that\nprecise on the assignment. So you can just think\nabout it as there's--",
    "start": "1188830",
    "end": "1195058"
  },
  {
    "text": "in general, if there were\nno vector instructions, it can actually do about three\nscalar ALU ops per clock.",
    "start": "1195058",
    "end": "1203590"
  },
  {
    "text": "With vector instructions,\nit can actually end up doing at max about three\nvector operations per clock.",
    "start": "1203590",
    "end": "1209100"
  },
  {
    "text": "So you should see about a\nwhat speed up from vector? ",
    "start": "1209100",
    "end": "1216020"
  },
  {
    "text": "[INAUDIBLE] Yeah. My max throughput is\nabout three scalar ops, and my max throughput is\nabout three vector ops.",
    "start": "1216020",
    "end": "1222900"
  },
  {
    "text": "So if I move from vector to\nscalar, I could get up to 8x.",
    "start": "1222900",
    "end": "1228860"
  },
  {
    "text": "Now it turns out that if\nyou're just using one thread, there might not be\ninstruction-level parallelism",
    "start": "1228860",
    "end": "1236570"
  },
  {
    "text": "in the thread to find\nthose three vector ops. So when you throw that\nextra thread in there, the chip is actually going,\noh, I've got two threads.",
    "start": "1236570",
    "end": "1243607"
  },
  {
    "text": "Almost all the time, I'm\ngoing to have the three vector operations there\nto actually use. So you're going to see\na performance benefit",
    "start": "1243608",
    "end": "1251299"
  },
  {
    "text": "from going from running\none thread on this core to two threads on this core,\nbecause one thread is not going to saturate all\nthose execution resources.",
    "start": "1251300",
    "end": "1258659"
  },
  {
    "text": "Yes. So I w-- And what I just said,\nby the way, is, if you-- now we're getting into real,\nlike taking the basic concepts",
    "start": "1258660",
    "end": "1266180"
  },
  {
    "text": "from the course, which I\nwould like you to understand this diagram and then\napplying it in a much more",
    "start": "1266180",
    "end": "1271790"
  },
  {
    "text": "messy, real-world setting. And if you can understand that\njump, you're doing very well.",
    "start": "1271790",
    "end": "1277190"
  },
  {
    "text": "Yeah. So this is a\nsuperscalar core, right? Yeah. And so there's-- And it's a multi-threaded core.",
    "start": "1277190",
    "end": "1283280"
  },
  {
    "text": "So the two threads-- And it's a SIMD core. The two threads, they can-- And it's part of a\nmulti-threaded chip or, sorry, a multi-core chip.",
    "start": "1283280",
    "end": "1289650"
  },
  {
    "text": "Yeah, you're right. You're saying the\ntwo threads there, theoretically they can\njust both run in parallel?",
    "start": "1289650",
    "end": "1294679"
  },
  {
    "text": "Do I have to fetch\ncode sequentially for the two threads or? I mean, just again, I'm\nbeing very, very loose now,",
    "start": "1294680",
    "end": "1302299"
  },
  {
    "text": "but think about it as I have\nall these fetch and decodes. All those fetch and\ndecodes are doing",
    "start": "1302300",
    "end": "1307760"
  },
  {
    "text": "is they're running their\nsuperscalar instruction logic to say, what\nindependent instructions",
    "start": "1307760",
    "end": "1313610"
  },
  {
    "text": "can I find in thread 0? What independent instructions\ncan I find in thread 1? I've got all these yellow\nboxes that I want to fill up.",
    "start": "1313610",
    "end": "1321420"
  },
  {
    "text": "If I find a mixture\nof instructions across any of those threads that\nI can shove into yellow boxes, I'm going to do it and try\nand saturate the machine.",
    "start": "1321420",
    "end": "1328380"
  },
  {
    "text": "Mm-hmm. Let me go here and then here. Yeah. [INAUDIBLE] three vector\nin how many instructions",
    "start": "1328380",
    "end": "1337159"
  },
  {
    "text": "can execute parallel. Well, if there are\nthree vector ALUs, I better be able to execute\nthree operations at once.",
    "start": "1337160",
    "end": "1343950"
  },
  {
    "text": "Otherwise I shouldn't\nhave built these ALUs. So if I-- if I can run\nthree vector ops at once,",
    "start": "1343950",
    "end": "1349400"
  },
  {
    "text": "how many total floating\npoint operations am I doing? 3 times 8.",
    "start": "1349400",
    "end": "1355260"
  },
  {
    "text": "And honestly, 3 times\n8 times 2 if you count them as a multiply\nat all in one thing. So it's a lot of ops per clock.",
    "start": "1355260",
    "end": "1362740"
  },
  {
    "text": "Yeah. How is having extra\nfetch decode vectors",
    "start": "1362740",
    "end": "1368470"
  },
  {
    "text": "helping us as compared to\nthe previous situation? I'm just drawing\nthese orange boxes",
    "start": "1368470",
    "end": "1373810"
  },
  {
    "text": "to indicate one box per\ninstruction that can get shoved into the pipeline at once.",
    "start": "1373810",
    "end": "1379170"
  },
  {
    "text": "I mean you can just\nas well think about it as a fetch and decode unit. That's a fancy fetch\nand decode unit that has the ability to\ndispatch multiple instructions.",
    "start": "1379170",
    "end": "1386985"
  },
  {
    "text": "But at the end of\nthe day, if you have a bunch of\nexecution units, you're going to have to be dispatching\nmore than one instruction",
    "start": "1386985",
    "end": "1393670"
  },
  {
    "text": "per clock to them in\norder to keep them full. Yeah. So that [INAUDIBLE] we run\nthrough [INAUDIBLE] same time?",
    "start": "1393670",
    "end": "1399519"
  },
  {
    "text": "Yeah. So now, like, everything\nhere composes.",
    "start": "1399520",
    "end": "1404919"
  },
  {
    "text": "It's a multithreaded chip. It's a SIMD chip. It's a superscalar chip.",
    "start": "1404920",
    "end": "1409940"
  },
  {
    "text": "And the implementation\nof superscalar tends to mean\nfinding instructions within the same thread.",
    "start": "1409940",
    "end": "1415033"
  },
  {
    "text": "You should think\nabout it this way if you're an Intel\narchitect-- and correct me if I'm wrong-- they\nwere sitting around with all of the yellow\nboxes in one thread.",
    "start": "1415033",
    "end": "1421930"
  },
  {
    "text": "And they were having trouble\nbecause of the diagram that I showed you in\nthe class of finding enough work in that one\nthread in order to fill up",
    "start": "1421930",
    "end": "1429710"
  },
  {
    "text": "all of their execution units. So they just said,\noh, let's just think about the second\nthread as a source",
    "start": "1429710",
    "end": "1435620"
  },
  {
    "text": "of independent instructions\nand feed that right into my global scheduler,\nbecause now I don't have to--",
    "start": "1435620",
    "end": "1441990"
  },
  {
    "text": "I can assume instructions\nfrom two threads are obviously independent\nbecause they're in different threads. Yes, ma'am, at the back.",
    "start": "1441990",
    "end": "1447390"
  },
  {
    "text": "Simultaneously. Correct. So it's also-- it's also a form\nof simultaneous multithreading,",
    "start": "1447390",
    "end": "1453020"
  },
  {
    "text": "which you have two forms of\nsimultaneous multithreading. You have different threads\non different cores, and then you have the\nsimultaneous multithreading",
    "start": "1453020",
    "end": "1459770"
  },
  {
    "text": "inside a single core with\nthe different threads. Yeah. Just to clarify,\ncan the two threads",
    "start": "1459770",
    "end": "1465410"
  },
  {
    "text": "running on the same\n[INAUDIBLE] ALU? An execution unit does\none thing at a time.",
    "start": "1465410",
    "end": "1472280"
  },
  {
    "text": "So you could use\nit in this clock, and I could use it\nin a different clock. But the idea that we're going\nto give two instructions to one",
    "start": "1472280",
    "end": "1479630"
  },
  {
    "text": "unit and expect it to do\ntwo things in one clock is not feasible. That's not what\nthe hardware does.",
    "start": "1479630",
    "end": "1485230"
  },
  {
    "text": "Yes. So the instruction\nselection box is basically finding seven instructions\nacross two threads",
    "start": "1485230",
    "end": "1491180"
  },
  {
    "text": "that it can [INAUDIBLE] correct? Yeah. You would be-- No, no, don't quote me as that's\nexactly how Kaby Lake works.",
    "start": "1491180",
    "end": "1499880"
  },
  {
    "text": "I tried to read the reference\nmanuals as best as I could, but maybe it's six, maybe it's\neight, maybe it's, you know, but you get it.",
    "start": "1499880",
    "end": "1505646"
  },
  {
    "text": "That would mean seven\nfetch decode boxes, right? Yeah, that's-- well,\nwe should move on.",
    "start": "1505646",
    "end": "1514490"
  },
  {
    "text": "This came from-- this came from\nme reading the Intel instruction manual. And some of these instructions\nare longer latency.",
    "start": "1514490",
    "end": "1525770"
  },
  {
    "text": "So you can get by with lower\nfetch capability by saying, I'm going to give this\ninstruction unit an instruction.",
    "start": "1525770",
    "end": "1531530"
  },
  {
    "text": "I know I don't have to\nfill it up for a while if it's not fully pipelined. So we're now getting into\nmicroarchitectural details",
    "start": "1531530",
    "end": "1537730"
  },
  {
    "text": "that I actually could not even\nrecite off the top of my head. So it's not true\nnecessarily that you need as many orange boxes\nas you have yellow boxes",
    "start": "1537730",
    "end": "1544990"
  },
  {
    "text": "to keep the thing in-- but let's take this one offline.",
    "start": "1544990",
    "end": "1551390"
  },
  {
    "text": "Two more, and then we\nshould keep moving. Yes, sir. [INAUDIBLE] why we can fetch\nmore instructions than we",
    "start": "1551390",
    "end": "1558380"
  },
  {
    "text": "have execution [INAUDIBLE] Because any one thread can\nhave independent instructions",
    "start": "1558380",
    "end": "1564830"
  },
  {
    "text": "inside of it. There's nothing preventing\na single instruction stream from having two independent\nmultiplies on two different sets",
    "start": "1564830",
    "end": "1571730"
  },
  {
    "text": "of registers. That's the idea of superscalar,\nindependent instructions inside a thread that the chip\nfinds for you automatically.",
    "start": "1571730",
    "end": "1581486"
  },
  {
    "text": "[INAUDIBLE] like\na threat has a lot of [INAUDIBLE] parallelization\n[INAUDIBLE] instructions,",
    "start": "1581486",
    "end": "1588460"
  },
  {
    "text": "theoretically doesn't mean\nthat this one [INAUDIBLE] I don't know what the rules\nof this specific process are,",
    "start": "1588460",
    "end": "1594490"
  },
  {
    "text": "but my conceptual\nanswer to your question is yes, if there was\nsufficient ILP in one thread",
    "start": "1594490",
    "end": "1599500"
  },
  {
    "text": "to fill up the machine,\nyou don't need two. And in fact, in the early\ndays of hyper-threading",
    "start": "1599500",
    "end": "1607750"
  },
  {
    "text": "when that was actually\nthe case, the threads actually started interfering. One would kick each other's\ndata out of the cache.",
    "start": "1607750",
    "end": "1613970"
  },
  {
    "text": "And so you had the ability to\nturn off the second thread, and it would help on\ncertain applications. So threads can interfere.",
    "start": "1613970",
    "end": "1620090"
  },
  {
    "text": "They're not always\na positive thing. Let's get going. And I hope that the\nnext sequence will answer even more questions.",
    "start": "1620090",
    "end": "1626330"
  },
  {
    "text": "First of all, this\nwas my fake chip. This is like what one of\nthe cores in a modern Intel",
    "start": "1626330",
    "end": "1632650"
  },
  {
    "text": "processor might look\nlike instead of 16 cores. Remember that an Nvidia GPU has\na whole bunch of these things.",
    "start": "1632650",
    "end": "1640050"
  },
  {
    "text": "We're not going to\ntalk about it today, but if I had to diagram the\ninside of maybe one core of one",
    "start": "1640050",
    "end": "1646480"
  },
  {
    "text": "of these 144 cores\nof an Nvidia GPU, it might look a\nlittle bit like this. And the way you can think\nabout it is as 32-wide vector,",
    "start": "1646480",
    "end": "1657130"
  },
  {
    "text": "four 32-wide vectors per clock\ndrawing instructions from up to 64 threads per core.",
    "start": "1657130",
    "end": "1664360"
  },
  {
    "text": "The numbers are-- the\nconcepts are the same, the numbers are larger. We'll get more into that when we\ntalk about Nvidia programming.",
    "start": "1664360",
    "end": "1671060"
  },
  {
    "text": "But the implication of\nthis is that I need--",
    "start": "1671060",
    "end": "1676300"
  },
  {
    "text": "in the maximum\nlatency hiding state, 64 threads per core times\nsomething like 80 or 144 cores",
    "start": "1676300",
    "end": "1684100"
  },
  {
    "text": "times 32 per thread\ngives you something where if you want to fill up\nthis chip with my sinx example,",
    "start": "1684100",
    "end": "1691190"
  },
  {
    "text": "you're talking\nabout, don't bother unless you have hundreds of\nthousands of things in parallel.",
    "start": "1691190",
    "end": "1697460"
  },
  {
    "text": "This is why a small DNN does\nnot run well on a big GPU because there's just\nnot enough work.",
    "start": "1697460",
    "end": "1703600"
  },
  {
    "start": "1703600",
    "end": "1710190"
  },
  {
    "text": "I think we've gone\nover this a good deal. So let me go over\none more review",
    "start": "1710190",
    "end": "1716850"
  },
  {
    "text": "one more time for\neverybody before we move on to the rest of the day. Last time, I gave\nyou this program.",
    "start": "1716850",
    "end": "1722340"
  },
  {
    "text": "This was just a basic C program. We focused on running\njust the inside",
    "start": "1722340",
    "end": "1729059"
  },
  {
    "text": "of the loop, these\ninstructions, if we compiled it. I told you that if I had\na simple single threaded,",
    "start": "1729060",
    "end": "1736170"
  },
  {
    "text": "single core processor,\nthat processor would want to run one of\nthose instructions per clock.",
    "start": "1736170",
    "end": "1743800"
  },
  {
    "text": "Very simple. On the first day\nof class, I said that without you doing\nanything to your program,",
    "start": "1743800",
    "end": "1749830"
  },
  {
    "text": "an architect at\nIntel could say, you know what, I'm going to look\nfor independent instructions inside a single thread.",
    "start": "1749830",
    "end": "1755880"
  },
  {
    "text": "I will find them for\nyou automatically. I will execute superscalar.",
    "start": "1755880",
    "end": "1761360"
  },
  {
    "text": "And if your program happens to\nhave independent instructions, like what I'm showing\nhere, two instructions",
    "start": "1761360",
    "end": "1767290"
  },
  {
    "text": "might get run per clock from\nthe same thread from one core. I'm highlighting those\ninstructions in orange.",
    "start": "1767290",
    "end": "1773970"
  },
  {
    "text": " I also told if I changed\nmy program, if I rewrote it",
    "start": "1773970",
    "end": "1781950"
  },
  {
    "text": "with CS 149 intrinsics or AVX\nintrinsics or I had a compiler, like ISPC generate\nthose intrinsics,",
    "start": "1781950",
    "end": "1789150"
  },
  {
    "text": "the binary might change. And it might be\nvector instructions. And if I had a processor\nthat had a vector ALU now,",
    "start": "1789150",
    "end": "1797550"
  },
  {
    "text": "a vector execution unit, when I\nran one instruction per clock, it would do eight things.",
    "start": "1797550",
    "end": "1802900"
  },
  {
    "text": "Notice how I only have one\ninstruction per clock running now, one orange highlight, but\nthat's a vector instruction.",
    "start": "1802900",
    "end": "1811590"
  },
  {
    "text": "There's no reason why I can't\nmake a superscalar processor",
    "start": "1811590",
    "end": "1816900"
  },
  {
    "text": "with different types of units. Here's one with one scalar\nand one vector and one thread.",
    "start": "1816900",
    "end": "1823269"
  },
  {
    "text": "So this core is now\nlooking at the thread and go, well, if\nyour program happens to have a scalar\ninstruction that's",
    "start": "1823270",
    "end": "1828660"
  },
  {
    "text": "independent from a vector,\nI can do both at once. But if I can't find a scalar\nindependent from a vector,",
    "start": "1828660",
    "end": "1834030"
  },
  {
    "text": "I'm only going to\nrun one of those two. I can't do two vectors at once--\njust don't have the hardware. ",
    "start": "1834030",
    "end": "1842050"
  },
  {
    "text": "So now superscalar with two\ndifferent types of instructions.",
    "start": "1842050",
    "end": "1847460"
  },
  {
    "text": "Then I said there was this\nidea of multithreading. Multithreading is\njust taking the core--",
    "start": "1847460",
    "end": "1853820"
  },
  {
    "text": "I went back to a simple\nsingle or non-vector core and having two threads. And now if my program\ncreates two threads,",
    "start": "1853820",
    "end": "1862340"
  },
  {
    "text": "this processor can run\neach thread, notice each with a different\ncurrent program counter.",
    "start": "1862340",
    "end": "1867890"
  },
  {
    "text": "You can have the state\nfor both of those threads on the chip at the same time. And because this core\ncan only actually run",
    "start": "1867890",
    "end": "1873800"
  },
  {
    "text": "one instruction per\nclock, every clock it picks one of the two threads\nand runs the next instruction. So I'm highlighting one\nof those two instructions.",
    "start": "1873800",
    "end": "1882889"
  },
  {
    "text": "I could also build a superscalar\ncore with two threads. And on this particular\nclock, my superscalar core",
    "start": "1882890",
    "end": "1890750"
  },
  {
    "text": "found, to your point, two\nindependent instructions, one scalar and one\nvector in this thread",
    "start": "1890750",
    "end": "1896179"
  },
  {
    "text": "and decided to run them both\non the core at the same time. Perfectly valid solution if the\nexecution engine supports that.",
    "start": "1896180",
    "end": "1904610"
  },
  {
    "text": "Now let me move to four threads. ",
    "start": "1904610",
    "end": "1910679"
  },
  {
    "text": "And now the chip decided to\npick one vector and one scalar from two of those four\nthreads and run them",
    "start": "1910680",
    "end": "1916440"
  },
  {
    "text": "on the processor at once\ntotally within my rules. It's just trying to find work.",
    "start": "1916440",
    "end": "1922265"
  },
  {
    "text": " And of course,\neverything I have here you can just replicate in\nyour head across cores.",
    "start": "1922265",
    "end": "1930190"
  },
  {
    "text": "So now I have two\ncompletely different cores, each is four-way\nmultithreaded, each",
    "start": "1930190",
    "end": "1935200"
  },
  {
    "text": "can actually do a mixture of\ntwo instructions per clock. So my program better\ncreate eight threads",
    "start": "1935200",
    "end": "1941380"
  },
  {
    "text": "to fill this thing up. And amongst those eight\nthreads, four of them are mapped to these\nexecution contexts.",
    "start": "1941380",
    "end": "1947779"
  },
  {
    "text": "So the core picks this vector\nand that scalar to do stuff. Instruction threads 4 through\n7 are mapped to this core.",
    "start": "1947780",
    "end": "1957020"
  },
  {
    "text": "And so this core happened to\nfind a vector in a multiply here and fills itself up.",
    "start": "1957020",
    "end": "1962420"
  },
  {
    "text": "yeah. And so that program could\nhave four threads running at the same time?",
    "start": "1962420",
    "end": "1968180"
  },
  {
    "text": "Well, let me-- let me clarify. There are eight threads\nthat are concurrently live on the processor. And at any one time, it's\npossible for two of these four",
    "start": "1968180",
    "end": "1978760"
  },
  {
    "text": "to be selected for actual making\nprogress and two of those four. But it would not be\npossible for these four",
    "start": "1978760",
    "end": "1985490"
  },
  {
    "text": "all at once to be\nchosen at the same time, because in other words,\nlike you should think about this side of the diagram\nor that side of the diagram,",
    "start": "1985490",
    "end": "1993080"
  },
  {
    "text": "but never both. And here I've decided now-- and now replace this core\nwith something more like this,",
    "start": "1993080",
    "end": "2000090"
  },
  {
    "text": "and you've got something\na little bit more like a modern Intel chip. And if you make four\nof those, that's",
    "start": "2000090",
    "end": "2006010"
  },
  {
    "text": "what you have on myth-ish. Any more questions? Yeah. So a quick thing about\nthe fetch decode units.",
    "start": "2006010",
    "end": "2012465"
  },
  {
    "text": "Do you roughly need the same\nnumber of fetch decode units as the number of ALU units? It's a reasonable,\ngood rule of thumb",
    "start": "2012465",
    "end": "2019690"
  },
  {
    "text": "unless you start doing\ncomplicated stuff. But we're not going\nto talk about that. Now, let me just give\nyou one little detail",
    "start": "2019690",
    "end": "2024933"
  },
  {
    "text": "that we'll talk about offline,\nif folks are interested. You know how I said, like if\nyou look closely at my programs,",
    "start": "2024933",
    "end": "2030640"
  },
  {
    "text": "if it's a vector operation, it's\nhere in the instruction stream, like the\ncompiler-emitted vectors?",
    "start": "2030640",
    "end": "2036490"
  },
  {
    "text": "That's actually how it works\non Intel CPUs and maybe even Intel GPUs. But Nvidia and AMD GPUs work\na little bit differently.",
    "start": "2036490",
    "end": "2043720"
  },
  {
    "text": "It's the same ideas, but I just\nwant to see this in your mind. They never, ever, ever\ngenerate vector instructions.",
    "start": "2043720",
    "end": "2051500"
  },
  {
    "text": "They generate scalar\ninstructions at all times. And the chip is designed so\nthat-- let's just say, here's",
    "start": "2051500",
    "end": "2058780"
  },
  {
    "text": "a chip with eight thread\nexecution contexts and under the hood, there's a\nsingle-- it can do one vector",
    "start": "2058780",
    "end": "2065290"
  },
  {
    "text": "operation per clock. Now this is not-- this is just an\ninteresting detail.",
    "start": "2065290",
    "end": "2071699"
  },
  {
    "text": "So what they do is they have\nlogic in the chip to say, if there are eight threads\nwith the same program counter,",
    "start": "2071699",
    "end": "2079550"
  },
  {
    "text": "I'm going to run all of their\ninstructions on this ALU at once. So the effect is the same\nas if the compiler had",
    "start": "2079550",
    "end": "2086480"
  },
  {
    "text": "generated a vector instruction. It just says, I'm always trying\nto run eight threads at once as",
    "start": "2086480",
    "end": "2092629"
  },
  {
    "text": "long as all those threads\nare at the same program counter right now. And I can talk\nabout that offline",
    "start": "2092630",
    "end": "2097880"
  },
  {
    "text": "if you want a little\nbit of clarity. So last little question\nthat people ask me,",
    "start": "2097880",
    "end": "2103470"
  },
  {
    "text": "imagine that you write a program\nthat spawns two P threads or two C++ threads, and we're running\non a processor here that has two",
    "start": "2103470",
    "end": "2110990"
  },
  {
    "text": "cores and two execution\ncontexts per core. What decides what thread runs\non what execution context?",
    "start": "2110990",
    "end": "2121064"
  },
  {
    "text": "[INAUDIBLE] That's actually your OS. So when you create a\nthread, your OS goes,",
    "start": "2121064",
    "end": "2126490"
  },
  {
    "text": "oh, we need a thread of control. Processor, start running this\nPC on execution context one.",
    "start": "2126490",
    "end": "2133315"
  },
  {
    "text": "So that's the operating system. So that's the OS. And if you were\nimplementing the OS,",
    "start": "2133315",
    "end": "2139180"
  },
  {
    "text": "it would be an interesting\nscheduling decision to say, which thread should\nI put on what course?",
    "start": "2139180",
    "end": "2145810"
  },
  {
    "text": "Because you know that\nthese two threads share execution resources.",
    "start": "2145810",
    "end": "2150890"
  },
  {
    "text": "Imagine if we only had two\nthreads in the machine. Would it make sense to\nput them both on core 0?",
    "start": "2150890",
    "end": "2157400"
  },
  {
    "text": "Probably not. It probably makes sense\nto put your first thread on core 0 and your\nnext thread on core 1 so they each have their\nfull complement of execution",
    "start": "2157400",
    "end": "2164750"
  },
  {
    "text": "resources. Now, of course, that\nanswer might be different if, for example, they were\ntouching the same data and you wanted to share a\ncache or something like that.",
    "start": "2164750",
    "end": "2171962"
  },
  {
    "text": "But that's a pretty interesting\nscheduling decision. So that was a very,\nvery deep dive",
    "start": "2171962",
    "end": "2179240"
  },
  {
    "text": "into these concepts\nfrom last time. Yes. So that's-- related to this last\npoint about scheduling, but--",
    "start": "2179240",
    "end": "2185242"
  },
  {
    "text": "So if we have multiple\nexecution contexts, it seems like there's\nalso a decision where-- or sorry, multiple\nareas there's a decision",
    "start": "2185242",
    "end": "2191690"
  },
  {
    "text": "where we could either\nrun multiple hardware threads in parallel or\nrun the superscalar.",
    "start": "2191690",
    "end": "2197339"
  },
  {
    "text": "That's not a decision for\nthe operating system to make. That is a chip\nimplementation detail. The operating system\nsays, hey, chip,",
    "start": "2197340",
    "end": "2204410"
  },
  {
    "text": "you will run this thread\non this execution context. The chip, every\nsingle clock is now",
    "start": "2204410",
    "end": "2209900"
  },
  {
    "text": "making a decision for, given\nthe execution context it has, what instructions to select.",
    "start": "2209900",
    "end": "2215960"
  },
  {
    "text": "That is completely out of the\nregime of the operating system. The chip is making that\ndecision every cycle, billion times per second.",
    "start": "2215960",
    "end": "2222130"
  },
  {
    "text": "The operating system, if you\nhave 1,000 threads or 1,000 processors, is periodically\ntelling the chip,",
    "start": "2222130",
    "end": "2229110"
  },
  {
    "text": "here are the 8 that I want\nyou to run on your execution context. That is an OS context switch.",
    "start": "2229110",
    "end": "2234480"
  },
  {
    "text": "And that might take hundreds\nof thousands of cycles, and that happens\nvery infrequently. Question, uh-huh.",
    "start": "2234480",
    "end": "2241230"
  },
  {
    "text": "Is there a way to give the\ncompiler something force--",
    "start": "2241230",
    "end": "2246384"
  },
  {
    "text": "Yeah. Modern operating\nsystems have APIs for saying this thread\ngoes on this execution. Oh, no, just force the\nsuperscalar to happen or not",
    "start": "2246384",
    "end": "2254110"
  },
  {
    "text": "in case you really [INAUDIBLE]\nco-processor and timing matter and you do want those\ninstructions [INAUDIBLE]",
    "start": "2254110",
    "end": "2259470"
  },
  {
    "text": "I mean, to my knowledge,\nthat's not something that you get to\nmess with too much. I mean, you certainly can say,\nI'm only going to give you--",
    "start": "2259470",
    "end": "2266580"
  },
  {
    "text": "I'm going to turn off\nhyperthreading or something like that. That is capable. But actually mucking\nwith the low level details of the instruction\nscheduler, to my knowledge,",
    "start": "2266580",
    "end": "2273800"
  },
  {
    "text": "I don't know how much\ncontrol you get over that. Maybe at the bios level,\nbut not at a standard",
    "start": "2273800",
    "end": "2278970"
  },
  {
    "text": "OS systems API level. Here's a question for\nyou given what you know. Now, I'm going to take your\nfavorite NumPy program,",
    "start": "2278970",
    "end": "2287900"
  },
  {
    "text": "allocate a big array A,\nallocate a big array B-- PyTorch program,\nif all you care.",
    "start": "2287900",
    "end": "2294780"
  },
  {
    "text": "We're going to do an\nelement-wise addition of these or multiplication\nof these two arrays.",
    "start": "2294780",
    "end": "2301780"
  },
  {
    "text": "Let's say these arrays are like\ntens of millions of elements. They are really big arrays.",
    "start": "2301780",
    "end": "2307170"
  },
  {
    "text": "Is this a good application to\nrun on the types of computers that I've told you\nabout, yes or no?",
    "start": "2307170",
    "end": "2314550"
  },
  {
    "text": "Talk it over. Why don't you think about it? And then we're\ngoing to do a vote. [INTERPOSING VOICES]",
    "start": "2314550",
    "end": "2321450"
  },
  {
    "start": "2321450",
    "end": "2328643"
  },
  {
    "text": "I'm going to keep it moving. Sorry for keeping the\ndiscussions a little shorter because we did a good QA. So, who thinks this\nis a great application",
    "start": "2328643",
    "end": "2336080"
  },
  {
    "text": "to be running on machines\nthat we've talked about? For example, what are\nsome properties of it that make us think, hey,\nmaybe this thing",
    "start": "2336080",
    "end": "2342560"
  },
  {
    "text": "is going to run super fast? Yeah. [INAUDIBLE] vectorize. It's OK. So it's, first of all,\nthere's infinite parallelism.",
    "start": "2342560",
    "end": "2349718"
  },
  {
    "text": "Let's say that there's a million\nelement arrays or 10 million element arrays, and not\nonly is there parallelism,",
    "start": "2349718",
    "end": "2355350"
  },
  {
    "text": "there is vectorized\nparallelism, because this is going to map to\nthese SIMD operations",
    "start": "2355350",
    "end": "2360390"
  },
  {
    "text": "really, really easily. So we have way more\nparallelism than cores.",
    "start": "2360390",
    "end": "2367170"
  },
  {
    "text": "We have vector parallelism. So not only are we going\nto use all the ALUs, we can hide any potentially\nlatency that occurs",
    "start": "2367170",
    "end": "2373815"
  },
  {
    "text": "or not making this program. All right. So here's where we\nget to the next topic.",
    "start": "2373815",
    "end": "2380920"
  },
  {
    "text": "This is probably the worst\nprogram that you can run or it's like the worst parallel\nprogram you can possibly",
    "start": "2380920",
    "end": "2386910"
  },
  {
    "text": "run on any modern computer. And you guys probably all run\nthis program 100 times a day.",
    "start": "2386910",
    "end": "2392257"
  },
  {
    "text": "So let's just think\nabout this a little bit. I'm going to go ahead and take\nthat Nvidia GPU, but think about myth or whatever.",
    "start": "2392257",
    "end": "2397770"
  },
  {
    "text": "I have a V100. I have 80 of these SM\nblocks, and every block in it",
    "start": "2397770",
    "end": "2404050"
  },
  {
    "text": "has 64 FP32 ALUs. So I'm going to multiply\nthose two numbers.",
    "start": "2404050",
    "end": "2410960"
  },
  {
    "text": "I have 5,000\nmultipliers in the chip. And at first you're\nlike, that's OK. I have millions of things\nto do, like, no problem.",
    "start": "2410960",
    "end": "2419050"
  },
  {
    "text": "And this thing runs at\nabout 1.6 gigahertz.",
    "start": "2419050",
    "end": "2424250"
  },
  {
    "text": "So if you just do the\nmath, that's a lot of data you're going to need.",
    "start": "2424250",
    "end": "2429650"
  },
  {
    "text": "And this gets to something\nwe haven't talked about yet in class, which is we've\ntalked about latency,",
    "start": "2429650",
    "end": "2436119"
  },
  {
    "text": "but we haven't talked\nabout bandwidth. All right.",
    "start": "2436120",
    "end": "2442740"
  },
  {
    "text": "How many people lived\nup in San Francisco? How many people\nlive down here now?",
    "start": "2442740",
    "end": "2448680"
  },
  {
    "text": "How many people have\nlived up in San Francisco and said, I'm going\nto live down here now?",
    "start": "2448680",
    "end": "2454810"
  },
  {
    "text": "How many people said, I wish\nI lived up in San Francisco? Very unopinionated\npeople in this classroom.",
    "start": "2454810",
    "end": "2460240"
  },
  {
    "text": "[LAUGHTER] All right. So I've got a lot of friends\nthat are a little tired",
    "start": "2460240",
    "end": "2467299"
  },
  {
    "text": "of the fog in San Francisco. So that's them on 101 driving\ndown South back to Palo Alto",
    "start": "2467300",
    "end": "2472850"
  },
  {
    "text": "because it looks like this\nup there during the summer, and it looks like\nthis down here.",
    "start": "2472850",
    "end": "2478100"
  },
  {
    "text": "And I like wearing t-shirts. So let's say that\neverybody wants to get back to the South Bay. So we got 101, and we got--",
    "start": "2478100",
    "end": "2485355"
  },
  {
    "text": "let's just say that the distance\nbetween Stanford and San Francisco to keep our math\neasy is about 50 kilometers.",
    "start": "2485355",
    "end": "2490710"
  },
  {
    "text": "It's not, but math. And let's say we all drive\non 101 at 100 kilometers.",
    "start": "2490710",
    "end": "2497360"
  },
  {
    "text": "So simple question, how long\ndoes it take to get to Stanford? Half an hour.",
    "start": "2497360",
    "end": "2502430"
  },
  {
    "text": "It takes half an hour. That's the latency of when\nyou leave San Francisco and you get to\nStanford-- half an hour.",
    "start": "2502430",
    "end": "2508830"
  },
  {
    "text": "So the latency of driving\nfrom San Francisco to Stanford, one half hour.",
    "start": "2508830",
    "end": "2514040"
  },
  {
    "text": "Now, let's just say there's a\nsimple rule right now because we like to be safe--",
    "start": "2514040",
    "end": "2519569"
  },
  {
    "text": "stay out of the\nway of these AVs-- and we're going to say\nthere's only one car can",
    "start": "2519570",
    "end": "2524580"
  },
  {
    "text": "be on the highway at once. Very safe. How many cars per\nhour get to Stanford?",
    "start": "2524580",
    "end": "2532230"
  },
  {
    "text": "Two. [INAUDIBLE] Two cars per hour,\nbecause like, one car drives to Stanford,\nthat's 30 minutes.",
    "start": "2532230",
    "end": "2537880"
  },
  {
    "text": "And then 30 minutes later,\nanother car comes in. So we get two cars per hour. So the latency of driving\na car is a half hour,",
    "start": "2537880",
    "end": "2544590"
  },
  {
    "text": "but the rate, the throughput\nis two cars per hour.",
    "start": "2544590",
    "end": "2550470"
  },
  {
    "text": "So one way, let's say, I\ndidn't change the rules at all of how many cars\ncan be on the road,",
    "start": "2550470",
    "end": "2556890"
  },
  {
    "text": "how do I increase\nthe throughput? I can't change the road,\ncan't change the rules",
    "start": "2556890",
    "end": "2562410"
  },
  {
    "text": "on how many cars per--  [INAUDIBLE] Sorry.",
    "start": "2562410",
    "end": "2567760"
  },
  {
    "text": "[INAUDIBLE] Yeah, I can't\nchange the road yet. Drive faster. We can drive faster.",
    "start": "2567760",
    "end": "2573260"
  },
  {
    "text": "So let's say we drive\ntwo times faster. So my throughput goes to what?",
    "start": "2573260",
    "end": "2578810"
  },
  {
    "text": "Four. Four. My latency goes to 15 minutes,\nbecause I'm driving faster.",
    "start": "2578810",
    "end": "2584660"
  },
  {
    "text": "So approach one is drive faster. Now let's say you can start--",
    "start": "2584660",
    "end": "2589750"
  },
  {
    "text": "now notice that driving faster\nreduced latency and increase throughput.",
    "start": "2589750",
    "end": "2595410"
  },
  {
    "text": "But driving faster\nhas some limits. Maybe it's dangerous. It's actually really inefficient\nbecause you get more wind drag",
    "start": "2595410",
    "end": "2601980"
  },
  {
    "text": "and stuff like that. So there's a lot of\nreasons why you can't just keep driving faster.",
    "start": "2601980",
    "end": "2607500"
  },
  {
    "text": "We can't say that if we wanted\nto get everybody down to San Francisco, we want\n1,000 cars per hour, everybody's going to drive at\nlike 10,000 miles per hour.",
    "start": "2607500",
    "end": "2615827"
  },
  {
    "text": "So, what happens if you\ncan change the road?  They do this all\nthe time, actually.",
    "start": "2615827",
    "end": "2624050"
  },
  {
    "text": "So, what does California do\non 101 about every five years? Build lanes. They build more lanes.",
    "start": "2624050",
    "end": "2630575"
  },
  {
    "text": "So now let's just say,\nI'm back to my 50-- 100 kilometers per hour. My throughput is 8 cars per hour\nbecause I get two cars per lane.",
    "start": "2630575",
    "end": "2639800"
  },
  {
    "text": "So widening the road means\nI have increased throughput, but latency was the\nsame as it was before.",
    "start": "2639800",
    "end": "2646690"
  },
  {
    "text": "Latency is still 30 minutes.  How can we do better?",
    "start": "2646690",
    "end": "2652609"
  },
  {
    "text": "Let's say we could change\nthe rules of the road, but we're not going to\nchange the road anymore. That's as big as we can get it. It's falling off into\nthe Bay on one side.",
    "start": "2652610",
    "end": "2659865"
  },
  {
    "text": " Yeah. Drive bumper to bumper. So now I can start using\nthe road more efficiently.",
    "start": "2659865",
    "end": "2667080"
  },
  {
    "text": "I can think about the\nroad is not one big thing. I can think about it\nas a bunch of pieces. And it's pretty\nclear that two cars",
    "start": "2667080",
    "end": "2673220"
  },
  {
    "text": "can't be in the same part of\nthe road at the same time. That's not allowed. But we can definitely\ndivvy up the road and drive",
    "start": "2673220",
    "end": "2680390"
  },
  {
    "text": "bumper to bumper. Or let's just say for the\nsake of math, I space my cars out by 1 kilometer.",
    "start": "2680390",
    "end": "2687350"
  },
  {
    "text": "So cars are spaced\nout by 1 kilometer, which actually means one car\nis arriving at Stanford every?",
    "start": "2687350",
    "end": "2695426"
  },
  {
    "text": "30 seconds. Every 30 seconds. And what's my total\nrate of cars per hour?",
    "start": "2695426",
    "end": "2700975"
  },
  {
    "text": "100. It'd be 100 cars per hour,\nif I got my math right.",
    "start": "2700976",
    "end": "2707230"
  },
  {
    "text": "Yeah, one car every\n100th of an hour. I should be right. I think that's right-- doubting myself for\na second, but yeah.",
    "start": "2707230",
    "end": "2715109"
  },
  {
    "text": "So this idea of using the\nroad more efficiently, I can say, well, the\ngetting to San Francisco",
    "start": "2715110",
    "end": "2720660"
  },
  {
    "text": "is like taking these 50 steps. ",
    "start": "2720660",
    "end": "2726690"
  },
  {
    "text": "And I get through every\none of these steps, like once per every 100th of\nan hour, every 30 seconds.",
    "start": "2726690",
    "end": "2737869"
  },
  {
    "text": "[INAUDIBLE] No, it's every 120-- I totally messed that math up. 36 seconds. Yeah, every 36 seconds.",
    "start": "2737870",
    "end": "2744040"
  },
  {
    "text": "I should have just said that\nif we spaced out by-- no, this is wrong. No, that's right. If I space out by 1 kilometer\nand I'm going 100 kilometers per",
    "start": "2744040",
    "end": "2753241"
  },
  {
    "text": "hour, I am taking one of those\nsteps every 100th of an hour.",
    "start": "2753241",
    "end": "2759560"
  },
  {
    "text": "And now that's wrong. [LAUGHTER] I'll fix that later. But you get the point. [LAUGHS] So building\nupon that other math.",
    "start": "2759560",
    "end": "2770150"
  },
  {
    "text": "If I have four\nlanes, then I just get quadruple the throughput.",
    "start": "2770150",
    "end": "2775250"
  },
  {
    "text": " So let's get away from Highway\n101 for a second, and let's",
    "start": "2775250",
    "end": "2782540"
  },
  {
    "text": "just talk about\ncommunication in a system. So I can talk about\nmemory latency,",
    "start": "2782540",
    "end": "2789180"
  },
  {
    "text": "and I can talk about\nmemory bandwidth. Memory bandwidth is a\nrate-- how many things",
    "start": "2789180",
    "end": "2794690"
  },
  {
    "text": "are completed per unit time. So here's an example\nwhere I'm completing-- I'm sending four\nsquares per second.",
    "start": "2794690",
    "end": "2802263"
  },
  {
    "text": "And I know that's\ntrue because I animate it four items per second. Now the latency of\nany one of those items",
    "start": "2802263",
    "end": "2808430"
  },
  {
    "text": "is about two seconds, the\namount of time it gets from memory to the processor.",
    "start": "2808430",
    "end": "2814280"
  },
  {
    "text": "I can increase the bandwidth\nby transferring two things at a time.",
    "start": "2814280",
    "end": "2819980"
  },
  {
    "text": "The latency is\nstill two seconds, but now the bandwidth is\neight items per second.",
    "start": "2819980",
    "end": "2826040"
  },
  {
    "text": "So in a system where\nwe're driving back to back or we're sending multiple things\nat a time, which I'll introduce",
    "start": "2826040",
    "end": "2834560"
  },
  {
    "text": "the term pipeline in a\nsecond, latency and bandwidth are decoupled. Latency is about\nhow long it takes",
    "start": "2834560",
    "end": "2840440"
  },
  {
    "text": "to get from memory to the core. Bandwidth is\nactually going to be a function of how wide your road\nis, if you assume everything",
    "start": "2840440",
    "end": "2846980"
  },
  {
    "text": "is bumper to bumper like this. Another example that\nwe do all the time",
    "start": "2846980",
    "end": "2852920"
  },
  {
    "text": "that I like to use in this\nclass is doing your laundry. Imagine you have laundry and\nyou have a washer, a dryer,",
    "start": "2852920",
    "end": "2859070"
  },
  {
    "text": "and yourself because\nthere's three stages to get your laundry done. So I divvied up the\nroad and do 100 stages.",
    "start": "2859070",
    "end": "2866400"
  },
  {
    "text": "Now I'm divvying up\nlaundry into three stages-- you wash, you dry, and you fold.",
    "start": "2866400",
    "end": "2872240"
  },
  {
    "text": "So if you had one\nload of laundry, how long would it\ntake you to finish? The bottom of the\nslide, two hours,",
    "start": "2872240",
    "end": "2879030"
  },
  {
    "text": "because it takes 45 minutes plus\n60 plus 15 to fold your clothes. ",
    "start": "2879030",
    "end": "2886609"
  },
  {
    "text": "Now, what's the throughput here? Or let's say, I wanted you\nto increase the throughput.",
    "start": "2886610",
    "end": "2894470"
  },
  {
    "text": "So if we just did\none load of laundry, and we did it kind of without\never sharing the road, we're going to-- it takes\ntwo hours to do laundry.",
    "start": "2894470",
    "end": "2900990"
  },
  {
    "text": "So my throughput is\none load every two hours-- half a load per hour. So if I said, let's\ndouble the throughput,",
    "start": "2900990",
    "end": "2908299"
  },
  {
    "text": "well, you might just go\ndown and hope for there's two washers, two dryers,\nyou call your best friend,",
    "start": "2908300",
    "end": "2915020"
  },
  {
    "text": "and you're like, look,\nit still takes two hours to get my load done,\nbut I get two loads",
    "start": "2915020",
    "end": "2922190"
  },
  {
    "text": "done in two hours, which\nmakes sense because none of us ever do one load of laundry. We just kind of wait\nuntil it all piles up,",
    "start": "2922190",
    "end": "2928400"
  },
  {
    "text": "and you have several loads\nof laundry to do at once. Now, is this a\nparticularly efficient way",
    "start": "2928400",
    "end": "2934880"
  },
  {
    "text": "to get the job done. It actually kind of is if\nyou're optimizing for latency",
    "start": "2934880",
    "end": "2940150"
  },
  {
    "text": "because I get two loads\ndone in two hours. But there's a lot of\nresources that go idle.",
    "start": "2940150",
    "end": "2947950"
  },
  {
    "text": "So, how would you\nprobably do this if you showed up downstairs\nor in the basement somewhere",
    "start": "2947950",
    "end": "2955293"
  },
  {
    "text": "and you had a bunch\nof loads of laundry, let's say, you had a\nton of loads of laundry? Let's say, like we had\n20 loads of laundry",
    "start": "2955293",
    "end": "2961010"
  },
  {
    "text": "to do because we waited all\nsummer or something like that. Yeah. [INAUDIBLE] so when\nthe washer is done,",
    "start": "2961010",
    "end": "2967520"
  },
  {
    "text": "you refill the washer\nwith the next load and you keep on doing that. Because remember, the idea\nhere is you don't ever",
    "start": "2967520",
    "end": "2974180"
  },
  {
    "text": "want anything to go idle. That's just the name of the\ngame in throughput computing. If anything goes idle, you lost\nan opportunity to make progress.",
    "start": "2974180",
    "end": "2981060"
  },
  {
    "text": "So we don't want empty\nplaces on the road. We don't want threads\nwaiting to run.",
    "start": "2981060",
    "end": "2986220"
  },
  {
    "text": "And we also don't want to washer\nand a dryer not doing anything. So now I'm drawing this diagram\nof what's going on here.",
    "start": "2986220",
    "end": "2994050"
  },
  {
    "text": "And so look at the--\nthe x-axis is time. And notice that my first\nload, my laundry takes--",
    "start": "2994050",
    "end": "3000970"
  },
  {
    "text": "the wash is three\nticks, 45 minutes. Then there's four ticks for\nan hour, and then 15 minutes.",
    "start": "3000970",
    "end": "3006890"
  },
  {
    "text": "So the latency of the\nfirst load is two hours. So, when can I start\nputting in the second load?",
    "start": "3006890",
    "end": "3013770"
  },
  {
    "text": "Let's just say we only had\none washer and one dryer, I put that second load in when?",
    "start": "3013770",
    "end": "3019140"
  },
  {
    "text": "[INAUDIBLE] Sorry. How long after the start? 45 minutes. 45 seconds or sorry, 45 minutes.",
    "start": "3019140",
    "end": "3025000"
  },
  {
    "text": "So at 45 minutes, I\ncan start the washer. It gets done an\nhour and a half in.",
    "start": "3025000",
    "end": "3030310"
  },
  {
    "text": "And then what happens here? [INAUDIBLE] The laundry just\nsits in the washer",
    "start": "3030310",
    "end": "3036829"
  },
  {
    "text": "because the dryer is not done.  And let's just say\nthat, at this point,",
    "start": "3036830",
    "end": "3046520"
  },
  {
    "text": "I will go ahead and\nstart the washer. Let's say, actually, I take\nthe laundry out of the washer, put it on top of the\ndryer, and start the washer",
    "start": "3046520",
    "end": "3054079"
  },
  {
    "text": "again immediately when\nthe washer is done. Does that make sense? So we all do anyways.",
    "start": "3054080",
    "end": "3060770"
  },
  {
    "text": "And so what's going\non in this diagram? I have two questions for you. Well, my question is, what\nis the throughput at which we",
    "start": "3060770",
    "end": "3068780"
  },
  {
    "text": "are finishing laundry? We can do a load of\nwash every 45 seconds.",
    "start": "3068780",
    "end": "3075090"
  },
  {
    "text": "We can do a load of-- we can do a dryer\nload every one hour. What is the throughput\nof loads of laundry?",
    "start": "3075090",
    "end": "3082339"
  },
  {
    "text": "One per hour. One per hour. But wait a minute, I thought we\ncould do wash at one every 45",
    "start": "3082340",
    "end": "3089714"
  },
  {
    "text": "minutes. ",
    "start": "3089715",
    "end": "3095290"
  },
  {
    "text": "What's going on? Yeah. [INAUDIBLE] this moment,\nlike, the weakest link. I'm limited by the slowest link\nin the chain in the pipeline.",
    "start": "3095290",
    "end": "3102349"
  },
  {
    "text": "So if the dryer can only get\ndone with one load per hour, that's my throughput.",
    "start": "3102350",
    "end": "3108190"
  },
  {
    "text": "Now, why is the-- the laundry here is actually\nI'm executing a load of laundry",
    "start": "3108190",
    "end": "3116140"
  },
  {
    "text": "every 45 minutes. So, what's actually\nhappening in this scenario? ",
    "start": "3116140",
    "end": "3122700"
  },
  {
    "text": "Where's all this laundry-- all this wet laundry going? [INAUDIBLE] It's actually building up on\ntop of the washer or the dryer",
    "start": "3122700",
    "end": "3130590"
  },
  {
    "text": "because at this point,\nI've only completed like 1, 2, 3, 4 loads of drying\nand we have more than that",
    "start": "3130590",
    "end": "3138045"
  },
  {
    "text": "sitting around. So if we ran this for\nforever, this pile-- if I just kept shoving\nlaundry into the washer",
    "start": "3138045",
    "end": "3143520"
  },
  {
    "text": "as soon as the washer was\nidle, this pile between the two would just keep growing. So at some point, I might\nsay, this is ridiculous.",
    "start": "3143520",
    "end": "3151329"
  },
  {
    "text": "I'm not going to put\nnew stuff in the washer until I take another\nload out of the dryer",
    "start": "3151330",
    "end": "3156569"
  },
  {
    "text": "and can drain that pile. So at some point, there's\ngoing to be a finite buffer, and the fast thing\nis going to slow down",
    "start": "3156570",
    "end": "3163290"
  },
  {
    "text": "to match the rate\nof the slow thing. So here we have a latency\nof one load takes two hours,",
    "start": "3163290",
    "end": "3169170"
  },
  {
    "text": "throughput is now\none load per hour, and we did that with\nresources of only one washer and one dryer, not\ntwo washers and dryer.",
    "start": "3169170",
    "end": "3177180"
  },
  {
    "text": "Now we needed multiple\nloads of laundry to do this. Another analogy here is\nimagine you had two pipes.",
    "start": "3177180",
    "end": "3183360"
  },
  {
    "text": "And if we ignore the\nactual physics reason that if I push more water\ndown one pipe, it speeds up and they rate match.",
    "start": "3183360",
    "end": "3189110"
  },
  {
    "text": "But let's say that I had one\npipe that could do 100 liters a second before it burst\nand another pipe that",
    "start": "3189110",
    "end": "3194950"
  },
  {
    "text": "could do liters per\nsecond before it bursts, and I connect them together. I'm only getting liters per\nsecond out of this system.",
    "start": "3194950",
    "end": "3202750"
  },
  {
    "text": "I'm going to run at the\nlower of the throughput, so when I link things together. ",
    "start": "3202750",
    "end": "3209050"
  },
  {
    "text": "All right. So let's apply this\nconcept to a computer.",
    "start": "3209050",
    "end": "3214510"
  },
  {
    "text": "And let's say we go back to-- we go to a simple program that's\nlike load 64 bytes and then add,",
    "start": "3214510",
    "end": "3220180"
  },
  {
    "text": "add; load, add, add; load,\nadd, add; load, add, add. And let's just say that\nthe computer is executing",
    "start": "3220180",
    "end": "3227740"
  },
  {
    "text": "one math operation per clock. Something that's\nactually quite common",
    "start": "3227740",
    "end": "3233960"
  },
  {
    "text": "is we haven't talked about\nexecuting loads and stores, but I'll draw it-- this\ntime, and we'll ignore",
    "start": "3233960",
    "end": "3239078"
  },
  {
    "text": "it the rest of the class. But often it's the case that\nthere's an execution unit to handle your load store that's\nin parallel from your math",
    "start": "3239078",
    "end": "3245330"
  },
  {
    "text": "units. You don't want to\nwaste the clock of math to do a load and store. So think about it as\na two-way superscalar,",
    "start": "3245330",
    "end": "3252079"
  },
  {
    "text": "and we can get 8 bytes\nper clock from memory. So memory has a long--",
    "start": "3252080",
    "end": "3257450"
  },
  {
    "text": "has some latency and then\nthere's 8 bytes for clock.",
    "start": "3257450",
    "end": "3262859"
  },
  {
    "text": "So let's think about\nhow this looks. It's like my laundry\ndiagram basically. So here are the instructions,\nand here is time.",
    "start": "3262860",
    "end": "3270870"
  },
  {
    "text": "So in other words, here's loads\nof laundry, and here's time. So let's say, I start by\ndoing two math operations,",
    "start": "3270870",
    "end": "3277610"
  },
  {
    "text": "then I kick off that load. And then there's some latency. And then this blue\nbar is the 8 cycles",
    "start": "3277610",
    "end": "3284210"
  },
  {
    "text": "it takes to get back a\ntotal of 8 bytes per clock.",
    "start": "3284210",
    "end": "3294675"
  },
  {
    "text": "Oh, sorry. And then the other thing\nis actually, remember, we talked about caches? Typically, we ask memory\nfor an entire cache line.",
    "start": "3294675",
    "end": "3302100"
  },
  {
    "text": "So when I say load, I really\nmean like load a cache line. So let's just say,\nit takes eight cycles",
    "start": "3302100",
    "end": "3308520"
  },
  {
    "text": "to get that information over\nthe highway, over Highway 101 back to my processor.",
    "start": "3308520",
    "end": "3314940"
  },
  {
    "text": "And so we're just going\nto keep doing this. And notice that at\nevery point in time,",
    "start": "3314940",
    "end": "3320070"
  },
  {
    "text": "the blue bar is working. As soon as memory gets\ndone with the first load, it starts working\non the second load.",
    "start": "3320070",
    "end": "3326020"
  },
  {
    "text": "So there's always\nsomething working. Now I can-- if I'm\ndoing load, sorry,",
    "start": "3326020",
    "end": "3331680"
  },
  {
    "text": "like math, math,\nload; math, math load, that's like the washer. It's going really, really fast. ",
    "start": "3331680",
    "end": "3338790"
  },
  {
    "text": "And memory is not keeping up\nbecause memory is the long pole. It's like the dryer here. And at some point, there's\nso many requests out",
    "start": "3338790",
    "end": "3346830"
  },
  {
    "text": "to memory the processor is\nlike, I've filled a buffer. I've got to stop. So in this diagram,\nI'm only going",
    "start": "3346830",
    "end": "3353000"
  },
  {
    "text": "to allow three\noutstanding loads. I just chose that number. So now, since the\nprocessor can't",
    "start": "3353000",
    "end": "3358940"
  },
  {
    "text": "issue any more loads, the next\ntime it tries to do a load, it's just got to wait.",
    "start": "3358940",
    "end": "3364579"
  },
  {
    "text": "It's got to wait\nuntil memory gets done with something\nin order to shove that next thing in the queue.",
    "start": "3364580",
    "end": "3370500"
  },
  {
    "text": "And that's just\ngoing to continue. It's going to be so when\nthis thing gets back, the processor can\nmake progress again.",
    "start": "3370500",
    "end": "3376725"
  },
  {
    "text": "Oh, I got my road back. Now I can keep going. And if we zoom out of this\ndiagram and look what happens,",
    "start": "3376725",
    "end": "3383730"
  },
  {
    "text": "this is what it will look like.  Math, math, load--\ncan't even issue my load",
    "start": "3383730",
    "end": "3391800"
  },
  {
    "text": "because the request queue\nis full load of memory. Oh, one came back. Now I can trickle\nanother one in.",
    "start": "3391800",
    "end": "3397980"
  },
  {
    "text": "Oh, one came back later. Oh, I can trickle\nanother one in. So look at this diagram. At every point in time, memory\nis busy transferring data",
    "start": "3397980",
    "end": "3405720"
  },
  {
    "text": "at the fastest rate it can-- 8 bytes per clock,\nbut the processor is not busy most of the time.",
    "start": "3405720",
    "end": "3412589"
  },
  {
    "text": "All of these sections are\nwhen the processor is stalled. ",
    "start": "3412590",
    "end": "3418440"
  },
  {
    "text": "So you can think about the\nprocessor like these 5,000 ALUs",
    "start": "3418440",
    "end": "3423869"
  },
  {
    "text": "to do their work,\nthey like need-- If they're going to do\na math op every clock, they need data for that\nmath op every clock.",
    "start": "3423870",
    "end": "3430260"
  },
  {
    "text": "So they're asking\nfor all of this data. And even if we build the\nfanciest memory system",
    "start": "3430260",
    "end": "3436350"
  },
  {
    "text": "on the planet, like this modern\nNvidia memory system that has 900 gigabytes of\nbandwidth-- it's insane--",
    "start": "3436350",
    "end": "3443730"
  },
  {
    "text": "if you do the math\nhere, this thing needs 100 terabytes\nof bandwidth in order",
    "start": "3443730",
    "end": "3450690"
  },
  {
    "text": "to give the ALUs on\nthis chip the data they would need to actually do\na math operation every clock.",
    "start": "3450690",
    "end": "3457440"
  },
  {
    "text": "Because think about it this way,\nwe can do 5,000 math operations at 1.6 gigahertz.",
    "start": "3457440",
    "end": "3463540"
  },
  {
    "text": "So I can do about 8 trillion\nmath operations per second.",
    "start": "3463540",
    "end": "3470100"
  },
  {
    "text": "Every one of those\nmath operation needs 12 bytes, because it loads\ntwo arguments and stores one.",
    "start": "3470100",
    "end": "3477570"
  },
  {
    "text": "So if I can do 8 trillion\noperations per second on this chip, I'm going\nto need to feed it",
    "start": "3477570",
    "end": "3482830"
  },
  {
    "text": "with about 100\nterabytes of bandwidth. And the fastest memory system\non the planet is about 1.",
    "start": "3482830",
    "end": "3492700"
  },
  {
    "text": "So you've got a pipe. The math pipe runs at\n100 times the data pipe.",
    "start": "3492700",
    "end": "3500410"
  },
  {
    "text": "So if you just think\nthrough this pipe analogy, it means if you run this\ncode on a modern GPU-- and it's very similar, if\nyou run it on a modern CPU,",
    "start": "3500410",
    "end": "3506800"
  },
  {
    "text": "you just scale down in numbers-- this thing is going to run at\napproximately 1% efficiency--",
    "start": "3506800",
    "end": "3514630"
  },
  {
    "text": "standard NumPy add\narray to add array. And if that's the only\nthing you're doing,",
    "start": "3514630",
    "end": "3522670"
  },
  {
    "text": "there's nothing you\ncan do about that. Convince yourself that\na cache won't help.",
    "start": "3522670",
    "end": "3529110"
  },
  {
    "text": "Caches only help\nif you reuse data. I'm accessing all the data once.",
    "start": "3529110",
    "end": "3535650"
  },
  {
    "text": "I'm loading it perfectly\nthrough cache lines. So every time I load a cache\nline, I read all the data.",
    "start": "3535650",
    "end": "3541860"
  },
  {
    "text": "There's nothing you can do. The only thing you can\ndo is change your program so that it doesn't do 12\nbytes of memory traffic",
    "start": "3541860",
    "end": "3547710"
  },
  {
    "text": "for every math op it does. Yeah. Wouldn't, like, [INAUDIBLE]\nset the prefetching advantage to where, like, you have these--",
    "start": "3547710",
    "end": "3554579"
  },
  {
    "text": "This is a really\nimportant question. You said, couldn't we\nset the prefetching?",
    "start": "3554580",
    "end": "3559830"
  },
  {
    "text": "Imagine if I had\na magical memory system that had zero\nlatency but transferred data",
    "start": "3559830",
    "end": "3566609"
  },
  {
    "text": "at 8 bytes per clock-- perfect prefetcher. It doesn't matter.",
    "start": "3566610",
    "end": "3571740"
  },
  {
    "text": "Doesn't matter. Convince yourself that's true. This is not a memory\nlatency problem.",
    "start": "3571740",
    "end": "3577450"
  },
  {
    "text": "This is I'm trying to shove-- I'm trying to extract\nwater from a pipe at a 100",
    "start": "3577450",
    "end": "3583990"
  },
  {
    "text": "terabytes per second in\norder to feed my hungry ALUs, and the best pipe in the\nworld can give me 1 terabyte",
    "start": "3583990",
    "end": "3590200"
  },
  {
    "text": "per second of bandwidth. That's the problem that we have. And there's nothing you can do\nother than change your program",
    "start": "3590200",
    "end": "3599300"
  },
  {
    "text": "or wait till a new\nmemory system comes out. So in almost every\nprogram you write",
    "start": "3599300",
    "end": "3605780"
  },
  {
    "text": "on these modern processors,\nthe name of the game is manipulate this ratio\nof how many math operations",
    "start": "3605780",
    "end": "3612170"
  },
  {
    "text": "you do for every memory access--\nevery memory access you read. Every program you write will\nbe bottlenecked by memory,",
    "start": "3612170",
    "end": "3617990"
  },
  {
    "text": "regardless of parallelism,\nunless you do this.",
    "start": "3617990",
    "end": "3623420"
  },
  {
    "text": "One quick aside. A lot of students say, how\ncan I do a floating point operation per clock? The same idea of\npipelining applies",
    "start": "3623420",
    "end": "3630080"
  },
  {
    "text": "to an instruction pipeline. So when I say my ALUs can\ndo one operation per clock,",
    "start": "3630080",
    "end": "3635960"
  },
  {
    "text": "I'm actually saying\nthey can complete one operation per clock. Their latency might be higher.",
    "start": "3635960",
    "end": "3642940"
  },
  {
    "text": "So here's an example where the\nlatency of an instruction, maybe it takes one clock to\nfetch, get ready to execute,",
    "start": "3642940",
    "end": "3649310"
  },
  {
    "text": "execute, and put the results\nback in the register. The same idea, again, it's\nlike the highway 101 analogy.",
    "start": "3649310",
    "end": "3655373"
  },
  {
    "text": "When I'm talking to you\nabout a processor that does one instruction\nfor a clock, I really mean completes\none instruction per clock,",
    "start": "3655373",
    "end": "3663000"
  },
  {
    "text": "has a throughput of one\ninstruction per clock. Because any latencies\nand stuff are all going to be hidden under the\nhood with smart scheduling",
    "start": "3663000",
    "end": "3669797"
  },
  {
    "text": "and stuff like that. So in this class,\nI almost always talk in terms of throughput.",
    "start": "3669797",
    "end": "3676460"
  },
  {
    "text": "Let's take a big, deep breath. And any questions? ",
    "start": "3676460",
    "end": "3686310"
  },
  {
    "text": "Yeah. [INAUDIBLE]",
    "start": "3686310",
    "end": "3691710"
  },
  {
    "text": "Bandwidth is a\nmeasure of throughput. So usually when I say bandwidth,\nI mean bytes per clock.",
    "start": "3691710",
    "end": "3698940"
  },
  {
    "text": "I could have throughput\nin office hours of students per clock. It's just a measure of\nsomething per unit time.",
    "start": "3698940",
    "end": "3705119"
  },
  {
    "text": "Yeah. How fast is the memory\nincreasing the [INAUDIBLE]",
    "start": "3705120",
    "end": "3711390"
  },
  {
    "text": "In general, the rate of\nprocessing increases faster than the rate of data\nmovement for reasons",
    "start": "3711390",
    "end": "3718620"
  },
  {
    "text": "that moving data is expensive,\nlike moving anything is expensive. So usually about\nevery decade or so,",
    "start": "3718620",
    "end": "3724950"
  },
  {
    "text": "there's some big technology\nbump that changes the equation. But it typically is like one\nbig catch up of bandwidth",
    "start": "3724950",
    "end": "3731400"
  },
  {
    "text": "and then compute races away. And then at some\npoint, things get dire, and there's another big\ncatch up in bandwidth. yeah.",
    "start": "3731400",
    "end": "3736680"
  },
  {
    "text": "So for-- like, limited\nso much by bandwidth and why make a [INAUDIBLE]",
    "start": "3736680",
    "end": "3742980"
  },
  {
    "text": "Because that chip is not\ndesigned to be efficient and to add two vectors.",
    "start": "3742980",
    "end": "3748420"
  },
  {
    "text": "If the only workload you were\ndoing was add two vectors, you would take\nthat memory system, and you would rip\nout 99% of the ALUs.",
    "start": "3748420",
    "end": "3755740"
  },
  {
    "text": "Luckily, things like computer\ngraphics and machine learning",
    "start": "3755740",
    "end": "3761500"
  },
  {
    "text": "do not have this ratio of 1\nmath operation to 12 bytes read. It's flipped around\nthe other direction",
    "start": "3761500",
    "end": "3768160"
  },
  {
    "text": "on the order of 10 to 20\noperations per byte read, and you start getting very\nclose to that ratio of compute",
    "start": "3768160",
    "end": "3774309"
  },
  {
    "text": "to bandwidth. So as a modern\ncomputer architect, the first thing\nyou do is you say, how much bandwidth can I afford?",
    "start": "3774310",
    "end": "3781270"
  },
  {
    "text": "And given how much\nbandwidth can I afford, you say, how many ALUs\ncan I put in there to keep that memory system\nbusy, given my applications?",
    "start": "3781270",
    "end": "3790490"
  },
  {
    "text": " We're running a little\nbehind, but that's OK.",
    "start": "3790490",
    "end": "3796740"
  },
  {
    "text": "I think Thursday's lecture\nis a little shorter, so we'll be fine. So I want to talk a\nlittle bit about ISPC.",
    "start": "3796740",
    "end": "3803100"
  },
  {
    "text": "Now, in this class,\nby design, you are-- one of the skills is\ngo read the manual.",
    "start": "3803100",
    "end": "3808770"
  },
  {
    "text": "Go figure it out for yourself. That is by design because\nthat's what's going to happen when you go to work.",
    "start": "3808770",
    "end": "3813829"
  },
  {
    "text": "But I do want to say a\nlittle bit about ISPC to help out a little bit. Because it's such\na great example",
    "start": "3813830",
    "end": "3819500"
  },
  {
    "text": "of in this class, many times\nwhen you come to office hours, I'm going to say, I\nthink, you're conflating,",
    "start": "3819500",
    "end": "3825440"
  },
  {
    "text": "you're confusing what the\nabstractions of a program mean,",
    "start": "3825440",
    "end": "3830660"
  },
  {
    "text": "which is like, when\nI read the code, what should the\noutput answer be? What should it compute\nfrom or I'm confusing",
    "start": "3830660",
    "end": "3839089"
  },
  {
    "text": "that with some implementation. How is it computed? And usually in a parallel\ncomputing class, what order",
    "start": "3839090",
    "end": "3845690"
  },
  {
    "text": "is it computed? What is done in parallel? What is not? So a great example of\nwhat you should always",
    "start": "3845690",
    "end": "3852180"
  },
  {
    "text": "be asking yourself is,\nwhat is the answer? What's the correct answer that\nthis program will compute?",
    "start": "3852180",
    "end": "3858930"
  },
  {
    "text": "And then you can\nsay, OK, if I have to think about implementation,\nI should be asking myself, what is every part of\nthe machine, every core,",
    "start": "3858930",
    "end": "3866830"
  },
  {
    "text": "or every thread, what is\nit doing at some time? What work is it doing?",
    "start": "3866830",
    "end": "3872010"
  },
  {
    "text": "So ISPC, one of the\nreasons why I give you this fairly obscure, simple\nprogramming language to learn",
    "start": "3872010",
    "end": "3878940"
  },
  {
    "text": "is that it just makes these\nconcepts, in my opinion, very, very clear because\nof how low level it is.",
    "start": "3878940",
    "end": "3885359"
  },
  {
    "text": "This is a language. It's like people are like,\nI can't find anything on Reddit or on Stack Overflow\nbecause there's probably",
    "start": "3885360",
    "end": "3892289"
  },
  {
    "text": "like, the number of users is all\nof u times the number of years of this class plus like 100\nor 200 other people that",
    "start": "3892290",
    "end": "3898920"
  },
  {
    "text": "want to get really good\nperformance out of Intel chips. If you want to know why you\nget such great performance out",
    "start": "3898920",
    "end": "3905069"
  },
  {
    "text": "of ISPC and can't\nget it out of C++, this is like an amazing blog\npost that underscores a lot",
    "start": "3905070",
    "end": "3911190"
  },
  {
    "text": "about why it's so hard to\nparalyze arbitrary C code and why they invented\nanother language.",
    "start": "3911190",
    "end": "3919048"
  },
  {
    "text": "So here's our program\nfrom last time. Again, for every\nelement in our array, compute the sine of the number.",
    "start": "3919048",
    "end": "3924740"
  },
  {
    "text": "Now I'm going to rewrite\nthe code in ISPC. So all I'm going to do is\nI'm going to take this code.",
    "start": "3924740",
    "end": "3933480"
  },
  {
    "text": "This is C code. We can compile it with GCC. Here's the ISPC code.",
    "start": "3933480",
    "end": "3939570"
  },
  {
    "text": "So here's void main,\nwhich is C code. This is all C code. And then this is. I just took the function\nand I did literally nothing,",
    "start": "3939570",
    "end": "3947030"
  },
  {
    "text": "and now it's an ISPC function. ",
    "start": "3947030",
    "end": "3955991"
  },
  {
    "text": "Oh, sorry. Sorry. I haven't. I haven't rewritten an ISPC yet. I just factored it out. Excuse me. Sorry.",
    "start": "3955991",
    "end": "3961850"
  },
  {
    "text": "So if this is normal C code-- excuse me, I got one slide. If we're running main,\nthere's one thread of control.",
    "start": "3961850",
    "end": "3968609"
  },
  {
    "text": "One thread is running main. And then when you\ncall the C function sinx, that thread of\ncontrol just jumps to sinx,",
    "start": "3968610",
    "end": "3977359"
  },
  {
    "text": "executes the logic sequentially,\nwhen it gets to the return, it returns control on that main\nthread here and continues on.",
    "start": "3977360",
    "end": "3984920"
  },
  {
    "text": "So it's just-- it's how we think\nabout programming naturally in one thread of control. Now I'm going to rewrite\nthe right-hand side",
    "start": "3984920",
    "end": "3991819"
  },
  {
    "text": "of the slide in ISPC. So not much is going to change.",
    "start": "3991820",
    "end": "3997860"
  },
  {
    "text": "It's really going to change\nonly in the outer for loop. So I've highlighted\na bunch of stuff.",
    "start": "3997860",
    "end": "4004970"
  },
  {
    "text": "I'd like you to ignore the\nuniform keyword for now. I don't want to get into that.",
    "start": "4004970",
    "end": "4010250"
  },
  {
    "text": "Just assume it's a regular int,\nbut look what happens here. So now I have a program that\nhas access to two new variables.",
    "start": "4010250",
    "end": "4019290"
  },
  {
    "text": "One is called program count, and\nthe other is program instance or index, excuse me.",
    "start": "4019290",
    "end": "4025280"
  },
  {
    "text": "Program index-- well, so what\nyou should think of semantics,",
    "start": "4025280",
    "end": "4031010"
  },
  {
    "text": "again, now the meaning\nyou should say, oh, when my main thread in C\ngets to this ISPC function,",
    "start": "4031010",
    "end": "4038270"
  },
  {
    "text": "when it invokes the ISPC\nfunction, my thread of control doesn't start executing\nthat function.",
    "start": "4038270",
    "end": "4044990"
  },
  {
    "text": "ISPC spawns a gang of what\nthey call program instances.",
    "start": "4044990",
    "end": "4050570"
  },
  {
    "text": "And they're very clear not\nto use the word thread here because you have a notion\nof what a thread actually",
    "start": "4050570",
    "end": "4056750"
  },
  {
    "text": "is implemented as\nin a real C program. And here, they're\njust saying, look,",
    "start": "4056750",
    "end": "4061760"
  },
  {
    "text": "there are an entire gang\nof program instances and the number of instances you\nhave is given by program count.",
    "start": "4061760",
    "end": "4071300"
  },
  {
    "text": "And the current\ninstance that is running is given by program instance--",
    "start": "4071300",
    "end": "4077000"
  },
  {
    "text": "index, excuse me. So in this case, every single\ninstance of the ISPC program",
    "start": "4077000",
    "end": "4083030"
  },
  {
    "text": "has its own copy of all\nof the local variables, like float numerator\nindex, and it does whatever",
    "start": "4083030",
    "end": "4091580"
  },
  {
    "text": "the function says it should do. But that logic is conditioned\non maybe every instance",
    "start": "4091580",
    "end": "4096950"
  },
  {
    "text": "will do something a\nlittle bit different based on the value\nof program index.",
    "start": "4096950",
    "end": "4102220"
  },
  {
    "text": "So let's say that I create-- I say, I configure\nISPC that I want you to create a gang\nof eight instances",
    "start": "4102220",
    "end": "4109179"
  },
  {
    "text": "when we call an ISPC function. So it should look a\nlittle bit like this. At the point of this call, eight\nprogram instances are created.",
    "start": "4109180",
    "end": "4118850"
  },
  {
    "text": "Every program instance\ngets a different value. I'm going to go back to the\nprevious slide of program index.",
    "start": "4118850",
    "end": "4126740"
  },
  {
    "text": "Every program instance runs\nthis logic sequentially to produce some output.",
    "start": "4126740",
    "end": "4133630"
  },
  {
    "text": "And then when all program\ninstances are done, control returns to\nyour regular C caller.",
    "start": "4133630",
    "end": "4141930"
  },
  {
    "text": "So program count-- the number\nof simultaneously executing instances.",
    "start": "4141930",
    "end": "4147389"
  },
  {
    "text": "Program index-- which one am I? So this programming model is--",
    "start": "4147390",
    "end": "4153509"
  },
  {
    "text": "you'll see this term SPMD. It stands for single\nprogram, multiple data. And the idea is that I've\nwritten a single program,",
    "start": "4153510",
    "end": "4160410"
  },
  {
    "text": "a single ISPC function, but\nits logic does different stuff,",
    "start": "4160410",
    "end": "4165450"
  },
  {
    "text": "works on different\ndata, for example, based on whatever the\nvalue of program index is, which can be 0, 1, 2, 3, 4, 5,\n6, or 7 if my gang size is 8.",
    "start": "4165450",
    "end": "4175710"
  },
  {
    "text": "This is a point in\nwhich I want you to ask any questions about\nthe meaning of this program.",
    "start": "4175710",
    "end": "4181390"
  },
  {
    "text": "And by meaning of\nthis program, I say, what does each\nprogram instance compute?",
    "start": "4181390",
    "end": "4188388"
  },
  {
    "text": "Actually, here's\nsomething I want you to do is talk amongst yourself. Tell me, tell your partner, I\nhave eight program instances.",
    "start": "4188388",
    "end": "4197320"
  },
  {
    "text": "I have an array of size n. What program instance is\nresponsible for computing",
    "start": "4197320",
    "end": "4204570"
  },
  {
    "text": "every element of the array? This gets the right answer. When this ISPC program-- when this function returns,\nwhen all instances are",
    "start": "4204570",
    "end": "4212489"
  },
  {
    "text": "done, for every input\nelement in the array x, there is a value correctly\nstored into results of i",
    "start": "4212490",
    "end": "4220390"
  },
  {
    "text": "that is the sine of x sub I. The program is correct. Question is, what program\ninstance does what?",
    "start": "4220390",
    "end": "4228980"
  },
  {
    "text": "I'll let you talk about\nthat for a second. Yeah, If you have\na clarification. [INAUDIBLE] basically\nwhat's programs count?",
    "start": "4228980",
    "end": "4234330"
  },
  {
    "text": "Program count is the\ntotal number of instances. In this case, it\ntakes on the value 8.",
    "start": "4234330",
    "end": "4239880"
  },
  {
    "text": "Program index is\nlike my thread ID. Yep. [INTERPOSING VOICES]",
    "start": "4239880",
    "end": "4246462"
  },
  {
    "text": " All right. I'm going to bring everybody\ntogether so we can-- then",
    "start": "4246462",
    "end": "4252869"
  },
  {
    "text": "eye on the clock. So, who can tell me\nwhat this program does?",
    "start": "4252870",
    "end": "4258300"
  },
  {
    "text": "Cooperatively, I create a\nbunch of program instances, but who does what?",
    "start": "4258300",
    "end": "4265910"
  },
  {
    "text": "Yeah. Each program-- it's\none array element?",
    "start": "4265910",
    "end": "4271699"
  },
  {
    "text": "Each program instance\ncomputes one array element. So let's think about this. So remember, this is the program\nrun by every program instance.",
    "start": "4271700",
    "end": "4280130"
  },
  {
    "text": "If I only have 8 program\ninstances and every program instance only performs one--",
    "start": "4280130",
    "end": "4285564"
  },
  {
    "text": "One of the program, yeah. Like, one every\nprogram [INAUDIBLE]. OK.",
    "start": "4285564",
    "end": "4290730"
  },
  {
    "text": "So tell me how it works. This is sequential code. Like when you say, what\ndoes a program instance do,",
    "start": "4290730",
    "end": "4297360"
  },
  {
    "text": "you just look at this code\nand you're like, well, it runs this logic. So, what is program\ninstance zero do?",
    "start": "4297360",
    "end": "4303620"
  },
  {
    "text": "It has a for loop. It says, for my current\nvariable i equals 0 to n, compute the value of x--",
    "start": "4303620",
    "end": "4311240"
  },
  {
    "text": "compute the sine of x sub\n0, put it in results of 0. And then what does it do? [INAUDIBLE] compute zero\nprogram count plus 0.",
    "start": "4311240",
    "end": "4319724"
  },
  {
    "text": "And then it just increments\nits loop pointer. That's just normal C\ncode at this point. It says, OK, the next iteration,\nI'm responsible for eight.",
    "start": "4319725",
    "end": "4326610"
  },
  {
    "text": "The next iteration,\nI'm responsible for 16 and so on and so on. So if one program instance\ncomputes every eighth item,",
    "start": "4326610",
    "end": "4333540"
  },
  {
    "text": "how do I get the total\noverall, the right result? Like, the other program\ninstance [INAUDIBLE] one line.",
    "start": "4333540",
    "end": "4341590"
  },
  {
    "text": "Yeah. So remember, this is happening\nin eight different copies with different values\nof program index.",
    "start": "4341590",
    "end": "4349770"
  },
  {
    "text": "And as a result,\nI am interleaving iterations or sorry, I'm\ninterleaving elements",
    "start": "4349770",
    "end": "4356520"
  },
  {
    "text": "of the array and\njust passing them off round robin to\nthe various instances.",
    "start": "4356520",
    "end": "4361548"
  },
  {
    "text": "That's just what I wrote. I did that myself. That's how I\ndesigned the program. I want to know if everybody\ncan visualize that.",
    "start": "4361548",
    "end": "4367730"
  },
  {
    "text": " Now, question.",
    "start": "4367730",
    "end": "4373000"
  },
  {
    "text": "So this is interleaved. So in other ways, this is\none way to think about it. Instant 1 does these things.",
    "start": "4373000",
    "end": "4378530"
  },
  {
    "text": "Instance 1 does those\nthings and so on and so on. And cooperatively together,\nwe get the job done.",
    "start": "4378530",
    "end": "4385340"
  },
  {
    "text": "Make sense? I haven't said anything\nabout implementation.",
    "start": "4385340",
    "end": "4390570"
  },
  {
    "text": "Would it be valid, at least\nto some approximation, if the implementation\nof this call",
    "start": "4390570",
    "end": "4396130"
  },
  {
    "text": "was call ISPC sinx on a\nthread for instance 0?",
    "start": "4396130",
    "end": "4402340"
  },
  {
    "text": "When it finishes, now let's just\ncall that function again and set the value of\nprogram index to 1--",
    "start": "4402340",
    "end": "4407560"
  },
  {
    "text": "completely sequential. Does it compute\nthe right answer? Yes. It does.",
    "start": "4407560",
    "end": "4413740"
  },
  {
    "text": "Why would you use ISPC\nif that was the answer? Unclear. Could the underlying\nimplementation actually spawn 8P",
    "start": "4413740",
    "end": "4420910"
  },
  {
    "text": "threads, run that call on 8P\nthreads, and come back together?",
    "start": "4420910",
    "end": "4426630"
  },
  {
    "text": "The answer is yes. That's what I want\nyou all to say. There's some slight\nlittle details on why ISPC prevents that\nfrom an implementation,",
    "start": "4426630",
    "end": "4434190"
  },
  {
    "text": "but conceptually, you should\nthink about it like that. I just spawned eight\ndifferent threads of control. I carried them out\nwith different values",
    "start": "4434190",
    "end": "4440730"
  },
  {
    "text": "of program instance. And if I just run all eight\nof them, I get the job done. ",
    "start": "4440730",
    "end": "4446340"
  },
  {
    "text": "Here's a different ISPC program. I changed the program. It computes the exact same\nanswer, but does it differently.",
    "start": "4446340",
    "end": "4454320"
  },
  {
    "text": "Now, what does\nevery instance do? I'll have you look\nat it offline. But if you look carefully,\nevery program instance",
    "start": "4454320",
    "end": "4460470"
  },
  {
    "text": "now does a contiguous\nchunk of the array. I changed the program, it\nstill computes the same output,",
    "start": "4460470",
    "end": "4468450"
  },
  {
    "text": "but there's a\ndifferent assignment. So this is blocked. So this version of the\nprogram looks more like this.",
    "start": "4468450",
    "end": "4475557"
  },
  {
    "text": "Now, I'm not going to tell\nyou which one's better. I'm going to skip\nthis, and I'm going to tell you really quickly\nwhat for each means.",
    "start": "4475557",
    "end": "4483390"
  },
  {
    "text": "So for each is a kind of\nan interesting concept. So the two code--\nthe two programs",
    "start": "4483390",
    "end": "4489180"
  },
  {
    "text": "I just gave you, I said,\nhere's a version where I can do all the work. Interleaving-- I\nwrote the program",
    "start": "4489180",
    "end": "4495389"
  },
  {
    "text": "so that every program\ninstance takes an interleaved next iteration. I gave you a\ndifferent program that",
    "start": "4495390",
    "end": "4501090"
  },
  {
    "text": "says every program instance\ntakes a block of them. I don't want to think\nabout that stuff.",
    "start": "4501090",
    "end": "4508190"
  },
  {
    "text": "I just want to tell\nISPC, here's a loop. It has iterations for\n0 to n-- don't care.",
    "start": "4508190",
    "end": "4514740"
  },
  {
    "text": "I'll tell you that\nthey're independent ISPC, you just go ahead\nand assign the iterations",
    "start": "4514740",
    "end": "4521120"
  },
  {
    "text": "to program instances however\nyou want, and I don't care.",
    "start": "4521120",
    "end": "4527490"
  },
  {
    "text": "That's what I've said here. So all I've done\nhere is I say, I'm not going to manually\nassign anything to anything.",
    "start": "4527490",
    "end": "4533430"
  },
  {
    "text": "I'm just going to\nsay there's a loop. That loop is going\nto get carried out by all the program instances.",
    "start": "4533430",
    "end": "4538680"
  },
  {
    "text": "Some iteration is going to get\ndone by some program instance. I don't care. Let the system figure it out.",
    "start": "4538680",
    "end": "4543900"
  },
  {
    "text": "Let the system decide for me. Choose a good answer. And what I'd like\nyou to walk away with",
    "start": "4543900",
    "end": "4549199"
  },
  {
    "text": "is convince yourself that\nall four of these gray boxes are correct and\nvalid implementations",
    "start": "4549200",
    "end": "4555650"
  },
  {
    "text": "of that pink box. So in other words, I want you\nto be able to convince yourself,",
    "start": "4555650",
    "end": "4561140"
  },
  {
    "text": "what is the pink box mean,\nand convince yourself that if I was a compiler and\nchange the pink box to any",
    "start": "4561140",
    "end": "4567570"
  },
  {
    "text": "of these gray boxes, it would\nbe a valid implementation. And I'll stop there.",
    "start": "4567570",
    "end": "4574580"
  },
  {
    "start": "4574580",
    "end": "4578000"
  }
]
[
  {
    "start": "0",
    "end": "48000"
  },
  {
    "text": "thanks everyone for for being here so I",
    "start": "11600",
    "end": "16640"
  },
  {
    "text": "would rather people stop me and ask lots of questions then get through the",
    "start": "16640",
    "end": "21920"
  },
  {
    "text": "content I have here so please feel free to stop and ask questions at any point",
    "start": "21920",
    "end": "28210"
  },
  {
    "text": "I'm gonna in particular talk about one sub area of research that I think about",
    "start": "28210",
    "end": "34520"
  },
  {
    "text": "but also something that's been getting a lot of media attention in the last couple of years which is to say machine",
    "start": "34520",
    "end": "41750"
  },
  {
    "text": "learning and sort of how well or well it does not work in a variety of specific applications okay so you all are",
    "start": "41750",
    "end": "50540"
  },
  {
    "text": "spending some time in the Bay Area so you've probably heard pitches about machine learning being used in almost",
    "start": "50540",
    "end": "55970"
  },
  {
    "text": "any domain you can possibly imagine so you know machine learning is is being",
    "start": "55970",
    "end": "63590"
  },
  {
    "text": "pitched as sort of the magic the magic beans of all sorts of different things",
    "start": "63590",
    "end": "68979"
  },
  {
    "text": "you know there are people who are saying that we'll be able to predict wine quality quite well and I'm sure there",
    "start": "68979",
    "end": "75409"
  },
  {
    "text": "there are startups which are trying to do things like this or try to predict your taste in wine based on your prior",
    "start": "75409",
    "end": "81740"
  },
  {
    "text": "desires in terms of wine there are lots of examples of sort of more silly applications these don't look so good on",
    "start": "81740",
    "end": "88100"
  },
  {
    "text": "the slide but generating pictures of cats like little silly cartoon pictures",
    "start": "88100",
    "end": "93350"
  },
  {
    "text": "of cats as well as in many cases looking at how well one can either much smaller",
    "start": "93350",
    "end": "101540"
  },
  {
    "text": "on this than I remember looking at how to personalize a",
    "start": "101540",
    "end": "106790"
  },
  {
    "text": "customer's experience when interacting with some company right there's also",
    "start": "106790",
    "end": "114010"
  },
  {
    "text": "lots of people who are hoping to use machine learning to do a better job pricing anything you can imagine for",
    "start": "114010",
    "end": "120530"
  },
  {
    "text": "example a secondhand cars right so I give this as an example because we've",
    "start": "120530",
    "end": "127970"
  },
  {
    "text": "been selling secondhand cars for a long time and at least some fraction of the population thinks we know how to do that",
    "start": "127970",
    "end": "134769"
  },
  {
    "text": "and yet there are people who think it can be done more efficiently or machine",
    "start": "134769",
    "end": "140810"
  },
  {
    "text": "learning methods this is one of my favorites so someone has decided it would be",
    "start": "140810",
    "end": "148129"
  },
  {
    "text": "humorous to try to use basic machine learning methods to try to from images of marijuana plants predict which of",
    "start": "148129",
    "end": "155269"
  },
  {
    "text": "them are going to get sick with common diseases for those I can't I can't",
    "start": "155269",
    "end": "163610"
  },
  {
    "text": "attest to the veracity of any of any of their results or how they came to them",
    "start": "163610",
    "end": "171099"
  },
  {
    "text": "sorry sorry so I was asked whether the people who were considering machine",
    "start": "173140",
    "end": "179599"
  },
  {
    "text": "learning for such cases were inebriated in some way and I'm not sure if I'm not",
    "start": "179599",
    "end": "185120"
  },
  {
    "text": "sure if that's the case so one might think this would be a bit of an overkill",
    "start": "185120",
    "end": "190970"
  },
  {
    "text": "in terms of an example where one might want to use machine learning but recently as in like within the last year",
    "start": "190970",
    "end": "199120"
  },
  {
    "text": "Microsoft announced that they'd be using machine learning to try to predict when",
    "start": "199120",
    "end": "204170"
  },
  {
    "text": "they should offer updates to their software so as to not annoy the user of",
    "start": "204170",
    "end": "210500"
  },
  {
    "text": "the system right so rather than that popping up while you're making some kind of presentation and you having to click",
    "start": "210500",
    "end": "216739"
  },
  {
    "text": "on the thing they thought machine learning would be like a more appropriate way to predict whether",
    "start": "216739",
    "end": "222109"
  },
  {
    "text": "someone was actively using their system or not you might say that's a bit of",
    "start": "222109",
    "end": "227359"
  },
  {
    "text": "overkill right there are other things one could do lots of medical groups are",
    "start": "227359",
    "end": "234609"
  },
  {
    "text": "hoping that AI and various forms of machine learning will help them do a",
    "start": "234609",
    "end": "241190"
  },
  {
    "text": "better job in terms of all kinds of patient care right both in terms of",
    "start": "241190",
    "end": "246620"
  },
  {
    "text": "medical studies but then also in terms of you know the way actual caregivers interact with actual patients right",
    "start": "246620",
    "end": "256239"
  },
  {
    "text": "there's also the tacit hope that machine",
    "start": "256660",
    "end": "262160"
  },
  {
    "text": "learning methods will be more objective when it comes to doing all sorts of",
    "start": "262160",
    "end": "268070"
  },
  {
    "text": "different tasks than humans making those same sorts of choices there are any",
    "start": "268070",
    "end": "273229"
  },
  {
    "text": "number of startups that are employing machine learning to sift through large numbers of",
    "start": "273229",
    "end": "278420"
  },
  {
    "text": "for both low and high skilled workers and the hope in each of these cases if",
    "start": "278420",
    "end": "285350"
  },
  {
    "text": "not the you know second or third line of those pitches is that a I could actually",
    "start": "285350",
    "end": "290900"
  },
  {
    "text": "do a better job reducing the bias in terms of the machine learning in terms",
    "start": "290900",
    "end": "296300"
  },
  {
    "text": "of the people one brings in for an interview okay I have many other",
    "start": "296300",
    "end": "301760"
  },
  {
    "text": "examples right this is just yeah so yeah",
    "start": "301760",
    "end": "307130"
  },
  {
    "text": "you know many examples so you know it's true that like machines might do a",
    "start": "307130",
    "end": "313280"
  },
  {
    "text": "better job processing certain kinds of images than human eyes they have the capacity for actually doing a lot more",
    "start": "313280",
    "end": "321320"
  },
  {
    "text": "processing on on pixels yeah people have",
    "start": "321320",
    "end": "326660"
  },
  {
    "text": "also thought about sort of whether machine learning can do a better job pricing real estate and any other possible thing you could possibly",
    "start": "326660",
    "end": "332360"
  },
  {
    "text": "imagine right um I have a few others okay on the other hand simultaneous in",
    "start": "332360",
    "end": "339980"
  },
  {
    "start": "337000",
    "end": "847000"
  },
  {
    "text": "the last like five or so years to this really explosive adoption of machine",
    "start": "339980",
    "end": "346280"
  },
  {
    "text": "learning technologies in almost any domain you can imagine have been a bunch",
    "start": "346280",
    "end": "351830"
  },
  {
    "text": "of examples which you guys have probably heard at least to some extent about right so one example is so you all",
    "start": "351830",
    "end": "362120"
  },
  {
    "text": "presumably know that Google matches our ads tries to personalize them based on all sorts of information they have about",
    "start": "362120",
    "end": "367760"
  },
  {
    "text": "us and based on the Preferences of advertisers right but it does some",
    "start": "367760",
    "end": "373760"
  },
  {
    "text": "non-trivial matching often based on statistical information and a number of",
    "start": "373760",
    "end": "379340"
  },
  {
    "text": "different things have been found that may be considered problematic for",
    "start": "379340",
    "end": "386840"
  },
  {
    "text": "example there's some recent work that has shown that lots of high paying job",
    "start": "386840",
    "end": "393230"
  },
  {
    "text": "advertisements are much more likely to be shown to profiles that are considered male as opposed to people female there's",
    "start": "393230",
    "end": "400460"
  },
  {
    "text": "now mounting evidence that any number of pieces of statistical software which are",
    "start": "400460",
    "end": "406940"
  },
  {
    "text": "being used in the criminal justice space as broadly as one could imagine",
    "start": "406940",
    "end": "411970"
  },
  {
    "text": "work have different levels of predictive power for different demographic groups",
    "start": "411970",
    "end": "419150"
  },
  {
    "text": "right so this is just a screenshot of one part of a Pro Publica article about",
    "start": "419150",
    "end": "425960"
  },
  {
    "text": "a specific example of this one let's rather contentious but you know from",
    "start": "425960",
    "end": "431900"
  },
  {
    "text": "policing to sentencing to bail decisions and all sorts of risk management systems",
    "start": "431900",
    "end": "438880"
  },
  {
    "text": "there are definite questions as to the veracity of the claims that are being made by the companies who are making",
    "start": "438880",
    "end": "444110"
  },
  {
    "text": "this kind of software so this will come up again later in the talk I think if we",
    "start": "444110",
    "end": "451130"
  },
  {
    "text": "get there but one of the earlier fun",
    "start": "451130",
    "end": "457400"
  },
  {
    "text": "things that Google was doing with a huge number of images that it had uploaded it",
    "start": "457400",
    "end": "465350"
  },
  {
    "text": "had access to and crawling the web was trying to auto tag them with all sorts of things about the subjects in those in",
    "start": "465350",
    "end": "471650"
  },
  {
    "text": "those images and I'll show you the example much later for a different",
    "start": "471650",
    "end": "477830"
  },
  {
    "text": "reason but there was one young woman who was who noticed that images of herself",
    "start": "477830",
    "end": "484700"
  },
  {
    "text": "and her friends were being labeled as gorillas and that's particularly",
    "start": "484700",
    "end": "490610"
  },
  {
    "text": "problematic given that these people were african-american it's not great and it",
    "start": "490610",
    "end": "496880"
  },
  {
    "text": "would be a mistake if we were labeling any images of humans gorillas because",
    "start": "496880",
    "end": "502340"
  },
  {
    "text": "that's an error but there's an additional social cost when that comes when one's actually thinking about the",
    "start": "502340",
    "end": "509690"
  },
  {
    "text": "historical basis for such behavior okay I won't just drag on one large tech",
    "start": "509690",
    "end": "517400"
  },
  {
    "text": "company Amazon was using some you know secret in-house machine learning model",
    "start": "517400",
    "end": "525530"
  },
  {
    "text": "to try to guess who would be the top AI talents to try to hire and it was doing",
    "start": "525530",
    "end": "532490"
  },
  {
    "text": "a much worse job predicting the quality of research for women than for men and",
    "start": "532490",
    "end": "538760"
  },
  {
    "text": "you know there are many many many other examples but I'll maybe give you a few",
    "start": "538760",
    "end": "544040"
  },
  {
    "text": "more that are not so tech focused right so as I mentioned",
    "start": "544040",
    "end": "550810"
  },
  {
    "text": "one of the places in which people are thinking about machine learning really improving our day-to-day lives as",
    "start": "550810",
    "end": "556270"
  },
  {
    "text": "opposed to our online online lives is this idea that like medicine and our medical care providers could use tools",
    "start": "556270",
    "end": "563890"
  },
  {
    "text": "developed with statistics involved to give better care to our patients right",
    "start": "563890",
    "end": "568930"
  },
  {
    "text": "and there's preliminary evidence that we",
    "start": "568930",
    "end": "575290"
  },
  {
    "text": "may see problems as a result of that right so we already have a lot of",
    "start": "575290",
    "end": "580900"
  },
  {
    "text": "evidence ignoring machine learning systems in general the quality of care varies wildly when you look at different",
    "start": "580900",
    "end": "587440"
  },
  {
    "text": "demographic groups rich why men tend to get the best care out of the US medical",
    "start": "587440",
    "end": "594580"
  },
  {
    "text": "system compared to anyone else and we seem to be seeing similar results when",
    "start": "594580",
    "end": "601390"
  },
  {
    "text": "it comes to looking at ML methods that are based on any number of different kinds of historical pieces of data",
    "start": "601390",
    "end": "610770"
  },
  {
    "text": "there's I think part of the problem and part of the real concern is that so much",
    "start": "610770",
    "end": "618490"
  },
  {
    "text": "of the machine learning that people are",
    "start": "618490",
    "end": "623650"
  },
  {
    "text": "doing and saying we'll fix things is in general thought of as very blackbox and",
    "start": "623650",
    "end": "629530"
  },
  {
    "text": "very proprietary and it's not in general right when a large company spends a lot",
    "start": "629530",
    "end": "635380"
  },
  {
    "text": "of money investing in some kind of machine learning system they don't in general want to be very open about how",
    "start": "635380",
    "end": "641020"
  },
  {
    "text": "it works why it works the data it was trained upon they don't in general want to yeah",
    "start": "641020",
    "end": "648000"
  },
  {
    "text": "so so right so the the comment the comment here is am i doing the right",
    "start": "667800",
    "end": "673000"
  },
  {
    "text": "thing right right and in Ghent right",
    "start": "673000",
    "end": "692560"
  },
  {
    "text": "right right so it's certainly the case that if if you are a collection of people you're",
    "start": "692560",
    "end": "699310"
  },
  {
    "text": "most likely to produce some some software or artifact in general that represents the values that you as a",
    "start": "699310",
    "end": "706269"
  },
  {
    "text": "group already already exhibit right and that certainly either explicitly or",
    "start": "706269",
    "end": "712959"
  },
  {
    "text": "tacitly the case and a lot of these",
    "start": "712959",
    "end": "716430"
  },
  {
    "text": "[Music]",
    "start": "726250",
    "end": "729429"
  },
  {
    "text": "that's not clear I'll say a little bit more about that yeah yeah so the",
    "start": "734220",
    "end": "741490"
  },
  {
    "text": "question was I think let me rephrase and see if you're happy with my rephrasing",
    "start": "741490",
    "end": "746940"
  },
  {
    "text": "you know machine learning systems in general look at trends they find in",
    "start": "746940",
    "end": "753220"
  },
  {
    "text": "their training data and then try to make predictions based on the trends they find in that training data and while",
    "start": "753220",
    "end": "760269"
  },
  {
    "text": "that is true it is not entirely clear that all of the behavior we're seeing",
    "start": "760269",
    "end": "765459"
  },
  {
    "text": "here is entirely the result of trends we see in the data that is almost certainly",
    "start": "765459",
    "end": "770860"
  },
  {
    "text": "part of the problem in some of these cases but that's also sort of it's not",
    "start": "770860",
    "end": "777370"
  },
  {
    "text": "looking at all of the possible sources of this kind of behavior yeah so you",
    "start": "777370",
    "end": "783459"
  },
  {
    "text": "know there are many many other examples this is one of my favorites",
    "start": "783459",
    "end": "789200"
  },
  {
    "text": "it was it was in the news not not too too long ago we're so so to poke fun",
    "start": "789200",
    "end": "795470"
  },
  {
    "text": "again at one of the one of the large tech companies Amazon's facial",
    "start": "795470",
    "end": "801440"
  },
  {
    "text": "recognition system when run on the head shots of the members of Congress had a",
    "start": "801440",
    "end": "808880"
  },
  {
    "text": "huge number of false positives when matching the facial shots of members of",
    "start": "808880",
    "end": "816440"
  },
  {
    "text": "Congress to their criminal database sure",
    "start": "816440",
    "end": "822740"
  },
  {
    "text": "but like different people right so there were a huge number of false positives",
    "start": "822740",
    "end": "828019"
  },
  {
    "text": "and the number of false positives amongst Congress people of color was nearly twice the rate it should have",
    "start": "828019",
    "end": "833750"
  },
  {
    "text": "been compared to the rate of false positives of Caucasian Congress people",
    "start": "833750",
    "end": "840529"
  },
  {
    "text": "okay and the ACLU did this study right and that seems to be somewhat problematic you know we could go on and",
    "start": "840529",
    "end": "850130"
  },
  {
    "start": "847000",
    "end": "966000"
  },
  {
    "text": "on there's there's another example where you know if you're using machine learning to do something like predict",
    "start": "850130",
    "end": "856160"
  },
  {
    "text": "skin cancer you should make sure that you have a pretty representative sample of people with different types of skin",
    "start": "856160",
    "end": "862240"
  },
  {
    "text": "there are lots of examples where if you don't you will have some problems in terms of your predictive power yeah so",
    "start": "862240",
    "end": "871120"
  },
  {
    "text": "one final thing which I you know briefly mentioned before there are a lot of",
    "start": "871120",
    "end": "876709"
  },
  {
    "text": "people who really want to use histories of arrests as like recent histories of",
    "start": "876709",
    "end": "886220"
  },
  {
    "text": "arrests as a strong indicator that one should send future future limited police",
    "start": "886220",
    "end": "893000"
  },
  {
    "text": "resources into a neighborhood right so if what you say is I know that we arrested a bunch of people for crime X",
    "start": "893000",
    "end": "898910"
  },
  {
    "text": "in this location that means that we should send more police into that",
    "start": "898910",
    "end": "904640"
  },
  {
    "text": "location to look for crime X and maybe other crimes as well there are all sorts",
    "start": "904640",
    "end": "909920"
  },
  {
    "text": "of problems that come from systems that work that way especially given that we",
    "start": "909920",
    "end": "915800"
  },
  {
    "text": "don't arrest people for the same sorts of crimes and equal rates in different communities",
    "start": "915800",
    "end": "921530"
  },
  {
    "text": "right and that can lead to the idea you know drug use illicit drug use is",
    "start": "921530",
    "end": "926570"
  },
  {
    "text": "roughly equal across across different demographic groups conditioned on",
    "start": "926570",
    "end": "933140"
  },
  {
    "text": "socioeconomic status right five percent but the rate at which we we put people",
    "start": "933140",
    "end": "941600"
  },
  {
    "text": "in prison for it is very very much not evenly distributed okay so if we then",
    "start": "941600",
    "end": "947420"
  },
  {
    "text": "use where we arrested people for for those particular crimes as justification",
    "start": "947420",
    "end": "953840"
  },
  {
    "text": "to going into those neighborhoods and sending additional police to look for more crime we may never find the crime",
    "start": "953840",
    "end": "960290"
  },
  {
    "text": "in other neighborhoods which may be happening at the same or even greater rates okay okay so that is to say you",
    "start": "960290",
    "end": "970160"
  },
  {
    "start": "966000",
    "end": "1252000"
  },
  {
    "text": "know we we have some explaining to do we as like people who are sellers or or",
    "start": "970160",
    "end": "976400"
  },
  {
    "text": "people who are encouraging the adoption of machine learning and I think the short answer to why we might be seeing",
    "start": "976400",
    "end": "984200"
  },
  {
    "text": "some of this behavior is that we don't know how many of these machine learning systems work we as like users as opposed",
    "start": "984200",
    "end": "991850"
  },
  {
    "text": "to the producers but that also extends in many cases to the people who are",
    "start": "991850",
    "end": "997490"
  },
  {
    "text": "actually developing these machine learning models it's not at all clear that in a lot of these cases they",
    "start": "997490",
    "end": "1004390"
  },
  {
    "text": "expected the behavior that is being pointed out right and there is mounting",
    "start": "1004390",
    "end": "1010900"
  },
  {
    "text": "evidence that some of these systems as I mentioned have very different predictive",
    "start": "1010900",
    "end": "1017110"
  },
  {
    "text": "quality for different demographic groups and as Dennis alluded to a moment ago",
    "start": "1017110",
    "end": "1022450"
  },
  {
    "text": "it's not entirely clear why I mean there is at least one answer that maybe at",
    "start": "1022450",
    "end": "1028688"
  },
  {
    "text": "least sometimes responsible but it's not clear if this is the results of the choice of algorithms we're using to",
    "start": "1028689",
    "end": "1035319"
  },
  {
    "text": "optimize or whether it's the result of the choice of models were optimizing",
    "start": "1035319",
    "end": "1040540"
  },
  {
    "text": "over right so maybe we're using linear models which are a perfect predictor based on the set of features we have for",
    "start": "1040540",
    "end": "1046839"
  },
  {
    "text": "some populations but somehow that we really needed you know we needed something slightly different for a",
    "start": "1046839",
    "end": "1053380"
  },
  {
    "text": "different demographic it's not clear if this is an inevitability due to differences in the",
    "start": "1053380",
    "end": "1061090"
  },
  {
    "text": "distributions over the set of features we have for different demographic groups right if we are going to allow ourselves",
    "start": "1061090",
    "end": "1068920"
  },
  {
    "text": "to use machine learning in these particular contexts it's not clear if",
    "start": "1068920",
    "end": "1075430"
  },
  {
    "text": "this is the result of you know if you take a random sample of the United",
    "start": "1075430",
    "end": "1081070"
  },
  {
    "text": "States and it was perfectly representative we would still have more people of certain demographic groups",
    "start": "1081070",
    "end": "1086770"
  },
  {
    "text": "than others which means we have more statistical power to talk about the larger groups than the smaller groups",
    "start": "1086770",
    "end": "1092790"
  },
  {
    "text": "for anything we learn from that data set and it's not clear if what we're seeing",
    "start": "1092790",
    "end": "1098710"
  },
  {
    "text": "is primarily the result of having far more uncertainty about smaller populations right one of the things that",
    "start": "1098710",
    "end": "1107050"
  },
  {
    "text": "people speak about a lot is stakeholders and who's in the room when they're",
    "start": "1107050",
    "end": "1112870"
  },
  {
    "text": "making decisions about what kind of models to use right so if you walk into",
    "start": "1112870",
    "end": "1118390"
  },
  {
    "text": "any of these tech firms you're not going to see a representative slice of the American population nor will you see",
    "start": "1118390",
    "end": "1126520"
  },
  {
    "text": "them gathering data in Iowa or Louisiana they'll be driving cars to look for look",
    "start": "1126520",
    "end": "1134110"
  },
  {
    "text": "for data outside of Stanford yeah could",
    "start": "1134110",
    "end": "1148480"
  },
  {
    "text": "be yeah yeah yes so so the the point was if we're developing a model in Palo Alto",
    "start": "1148480",
    "end": "1157809"
  },
  {
    "text": "it's not the case that we're imagining it only being deployed in Palo Alto right lots of these organizations are",
    "start": "1157809",
    "end": "1164260"
  },
  {
    "text": "hoping to train something here and then deploy it much more broadly for example in Africa and there are so many things",
    "start": "1164260",
    "end": "1172300"
  },
  {
    "text": "that are problematic about that even if we weren't thinking about anything that had to do with humans right the",
    "start": "1172300",
    "end": "1177370"
  },
  {
    "text": "temperature and amount of sunlight and amount of humidity and the type of roads",
    "start": "1177370",
    "end": "1182590"
  },
  {
    "text": "and the type of things that like you know everything about this environment will",
    "start": "1182590",
    "end": "1187750"
  },
  {
    "text": "will affect the way a system that is developed here based on data collected here will work and systems will work",
    "start": "1187750",
    "end": "1194289"
  },
  {
    "text": "much less well when any of those things change right so if you train a model on data all gathered here and then hope to",
    "start": "1194289",
    "end": "1202960"
  },
  {
    "text": "deploy it somewhere very different there is no reasonable expectation that you should have that it should work very",
    "start": "1202960",
    "end": "1208720"
  },
  {
    "text": "well yeah and that's a that's a very good point so we don't fully understand",
    "start": "1208720",
    "end": "1216190"
  },
  {
    "text": "which of all of these different sets of things is primarily responsible if anyone is primarily responsible for this",
    "start": "1216190",
    "end": "1223120"
  },
  {
    "text": "sort of behavior we're seeing right and that seems pretty problematic right",
    "start": "1223120",
    "end": "1229419"
  },
  {
    "text": "because these different reasons for this behavior would happen would suggest very different interventions right at least",
    "start": "1229419",
    "end": "1236799"
  },
  {
    "text": "from my perspective right they would perhaps recommend different types of",
    "start": "1236799",
    "end": "1242049"
  },
  {
    "text": "data collection or different types different types of model selection yep",
    "start": "1242049",
    "end": "1250110"
  },
  {
    "text": "okay so more broadly I'm very interested in understanding when and why machine",
    "start": "1250110",
    "end": "1256179"
  },
  {
    "start": "1252000",
    "end": "1488000"
  },
  {
    "text": "learning algorithms treat different demographic groups differently and whether it's possible to make them",
    "start": "1256179",
    "end": "1262630"
  },
  {
    "text": "robust to moderate demographic changes right so taking something and training",
    "start": "1262630",
    "end": "1269530"
  },
  {
    "text": "yeah yes better testing is okay so so the",
    "start": "1269530",
    "end": "1275679"
  },
  {
    "text": "question was how about better testing that's certainly going to be one of the things that we're going to need to do",
    "start": "1275679",
    "end": "1281049"
  },
  {
    "text": "and one of the one of the recommendations I have for systems in general right if you want if you want to",
    "start": "1281049",
    "end": "1287080"
  },
  {
    "text": "deploy a system in a given environment you probably should have tested it in an",
    "start": "1287080",
    "end": "1292539"
  },
  {
    "text": "environment that is somewhat analogous that is definitely something that one",
    "start": "1292539",
    "end": "1297640"
  },
  {
    "text": "should consider yeah yes",
    "start": "1297640",
    "end": "1302220"
  },
  {
    "text": "you promise underlying model being",
    "start": "1302760",
    "end": "1312770"
  },
  {
    "text": "operate in a framework which is",
    "start": "1320630",
    "end": "1331919"
  },
  {
    "text": "essentially a great family of algorithms which gets tailored by the date of this train into the system and so not only do",
    "start": "1331919",
    "end": "1342870"
  },
  {
    "text": "we not have control over the framework itself whether or not we're doing it",
    "start": "1342870",
    "end": "1361400"
  },
  {
    "text": "right or not right because we match it against an expected result so it's",
    "start": "1361400",
    "end": "1367080"
  },
  {
    "text": "really the input data and expected result that and everything else is right",
    "start": "1367080",
    "end": "1377820"
  },
  {
    "text": "so so the comment so let me again rephrase and see if you like the",
    "start": "1377820",
    "end": "1382950"
  },
  {
    "text": "rephrasing I use so if we posit that in the world there are some set of machine",
    "start": "1382950",
    "end": "1390750"
  },
  {
    "text": "learning mechanisms right stochastic gradient descent SVM's a few other like really simple I get I",
    "start": "1390750",
    "end": "1398250"
  },
  {
    "text": "get shaking heads but you know though five yeah yeah but like there are like let's",
    "start": "1398250",
    "end": "1403950"
  },
  {
    "text": "imagine there are five or six optimization methods that everyone's agreed upon are like the only ones you ever need and there are five or six",
    "start": "1403950",
    "end": "1411090"
  },
  {
    "text": "classes of models that are the only ones you would ever need and then the question is on what data will you train",
    "start": "1411090",
    "end": "1418679"
  },
  {
    "text": "these models with these optimization procedures so as to get a model out",
    "start": "1418679",
    "end": "1424700"
  },
  {
    "text": "which does particularly well on a particular task when data is generated",
    "start": "1424700",
    "end": "1430500"
  },
  {
    "text": "in some similar way to the data that you actually train upon and that's",
    "start": "1430500",
    "end": "1436200"
  },
  {
    "text": "certainly one way to look at machine learning and it's certainly the case",
    "start": "1436200",
    "end": "1441990"
  },
  {
    "text": "that if your input data does not match the the environment in which your model",
    "start": "1441990",
    "end": "1449880"
  },
  {
    "text": "will be deployed you will be able to see it say very little about how that system will perform but even if it does match",
    "start": "1449880",
    "end": "1457740"
  },
  {
    "text": "reasonably well a lot of the optimization procedures and models people tend to use have some of this",
    "start": "1457740",
    "end": "1465120"
  },
  {
    "text": "problematic behavior which may or may not be entirely explained by the training data used right and I also I",
    "start": "1465120",
    "end": "1471000"
  },
  {
    "text": "also don't like to give up the agency of",
    "start": "1471000",
    "end": "1477270"
  },
  {
    "text": "people who are using these things they have a lot of control over what they're going to use what they're going to",
    "start": "1477270",
    "end": "1482610"
  },
  {
    "text": "optimize over and with what ok so you",
    "start": "1482610",
    "end": "1490320"
  },
  {
    "start": "1488000",
    "end": "1716000"
  },
  {
    "text": "know I've given lots of examples about concerns of uses of machine learning both due to different and worse",
    "start": "1490320",
    "end": "1496620"
  },
  {
    "text": "treatment of different groups and people as well as the context and opacity of the uses of those systems right so we've",
    "start": "1496620",
    "end": "1504330"
  },
  {
    "text": "sort of tacitly been bantering about a couple of different things and I want to be slightly more precise so when we say",
    "start": "1504330",
    "end": "1515549"
  },
  {
    "text": "machine learning systems are unfair what people usually mean one of two things",
    "start": "1515549",
    "end": "1520679"
  },
  {
    "text": "right one of the things they might mean is that the predictions have much higher",
    "start": "1520679",
    "end": "1526830"
  },
  {
    "text": "error rates on different demographic groups which is to say we're seeing images labeled gorilla at much higher",
    "start": "1526830",
    "end": "1534299"
  },
  {
    "text": "rates for certain demographic groups than other demographic groups that's one type of behavior that people often refer",
    "start": "1534299",
    "end": "1540960"
  },
  {
    "text": "to as unfair but it is not the only one separately if you just think about the",
    "start": "1540960",
    "end": "1547649"
  },
  {
    "text": "set of predictions a machine learning model is choosing amongst and you break out the rates of those different",
    "start": "1547649",
    "end": "1554100"
  },
  {
    "text": "predictions that the models making by different demographic groups the model might be making no mistakes but might be",
    "start": "1554100",
    "end": "1561059"
  },
  {
    "text": "making predictions of those different outcomes at very different rates so different demographic groups right and I",
    "start": "1561059",
    "end": "1568580"
  },
  {
    "text": "think we really have to grapple with whether that is something we want to consider acceptable or unacceptable",
    "start": "1568580",
    "end": "1574220"
  },
  {
    "text": "behavior and it will depend on the context yes yes so what I mean is take a",
    "start": "1574220",
    "end": "1584360"
  },
  {
    "text": "random sample of an example that the model will be operating upon from two",
    "start": "1584360",
    "end": "1589700"
  },
  {
    "text": "different demographic groups right random sample generated perhaps from like the same data generating process as",
    "start": "1589700",
    "end": "1596510"
  },
  {
    "text": "as the model was trained upon and look at the probability with which that",
    "start": "1596510",
    "end": "1601820"
  },
  {
    "text": "random example would be assigned 1 or 0 in a simple binary prediction case yes",
    "start": "1601820",
    "end": "1627340"
  },
  {
    "text": "right right right and I think that's that's a good point that's that's like yes that's absolutely a third a third a",
    "start": "1637690",
    "end": "1644510"
  },
  {
    "text": "third set of concerns which is to say you know if we're imagining that we're",
    "start": "1644510",
    "end": "1650270"
  },
  {
    "text": "optimizing this model to maximize the number of arrests that we make that lead",
    "start": "1650270",
    "end": "1658040"
  },
  {
    "text": "to eventual convictions right I'm just hypothesizing something that someone might want to maximize if one was",
    "start": "1658040",
    "end": "1665840"
  },
  {
    "text": "thinking about using a machine learning system for for example predictive policing right that is a is a very",
    "start": "1665840",
    "end": "1673640"
  },
  {
    "text": "explicit value choice right and that may very well not be one that all communities agree are the right ones I",
    "start": "1673640",
    "end": "1681500"
  },
  {
    "text": "do want to give you know at least a small amount of voice to the idea that some machine learning experts really",
    "start": "1681500",
    "end": "1688610"
  },
  {
    "text": "don't think that this is a concern right in fact there are certain people in the",
    "start": "1688610",
    "end": "1695810"
  },
  {
    "text": "machine learning community both practitioner and academics who basically say okay it's true machine learning systems may",
    "start": "1695810",
    "end": "1703059"
  },
  {
    "text": "have different rates of predictions may have different error rates but they do better than humans making those decisions and I want to I want to be",
    "start": "1703059",
    "end": "1710919"
  },
  {
    "text": "clear that like the community is not at like total consensus okay but my point",
    "start": "1710919",
    "end": "1716890"
  },
  {
    "text": "is we really need to think about precisely how these algorithms are going to be designed and used right that that",
    "start": "1716890",
    "end": "1723220"
  },
  {
    "text": "statement is an imprecise one right and",
    "start": "1723220",
    "end": "1728350"
  },
  {
    "text": "if if we're thinking about humans interacting with these machine learning systems to try to make various types of",
    "start": "1728350",
    "end": "1735520"
  },
  {
    "text": "decisions it's really important that we think about precisely how that works because humans behave in very unexpected",
    "start": "1735520",
    "end": "1741820"
  },
  {
    "text": "ways and it's not as though a human in a given environment making a set of",
    "start": "1741820",
    "end": "1747700"
  },
  {
    "text": "choices when augmented with additional helpful information or even unhelpful information will always make better",
    "start": "1747700",
    "end": "1753940"
  },
  {
    "text": "choices that's not there there's not a great deal of evidence of that in fact there was lots of evidence to the",
    "start": "1753940",
    "end": "1759880"
  },
  {
    "text": "contrary right so if you have a judge who's making choices about bail and you give them some some some signal about",
    "start": "1759880",
    "end": "1768130"
  },
  {
    "text": "the people that are making judgments about and that signal whether that signal is useful or not they will behave",
    "start": "1768130",
    "end": "1774429"
  },
  {
    "text": "differently with that signal in hand when they're making those choices right and humans are just very",
    "start": "1774429",
    "end": "1780309"
  },
  {
    "text": "counterintuitive right judges are much stricter right before lunch and so I",
    "start": "1780309",
    "end": "1785980"
  },
  {
    "text": "mean I get hangry it's fine but I'm also not sending people to prison so maybe",
    "start": "1785980",
    "end": "1791590"
  },
  {
    "text": "that's okay so I think we really have to think",
    "start": "1791590",
    "end": "1796600"
  },
  {
    "text": "carefully as was mentioned before about piloting and very carefully testing any",
    "start": "1796600",
    "end": "1802510"
  },
  {
    "text": "model we design in as close to of an as close to an environment as possible as",
    "start": "1802510",
    "end": "1808990"
  },
  {
    "text": "we are imagining it being deployed right not just in a black box looking at like some simple statistics but also like if",
    "start": "1808990",
    "end": "1815470"
  },
  {
    "text": "we're going to give judges some some recidivism tool we have to think about",
    "start": "1815470",
    "end": "1820480"
  },
  {
    "text": "how they'll interact with it yeah",
    "start": "1820480",
    "end": "1823740"
  },
  {
    "text": "[Laughter]",
    "start": "1861770",
    "end": "1866570"
  },
  {
    "text": "right I think so the comment was one about the people who are in general",
    "start": "1899040",
    "end": "1907170"
  },
  {
    "start": "1900000",
    "end": "2027000"
  },
  {
    "text": "developing technologies have often been their own guinea pigs which seems",
    "start": "1907170",
    "end": "1912520"
  },
  {
    "text": "somewhat more just than requiring someone else to be the guinea pig for",
    "start": "1912520",
    "end": "1918460"
  },
  {
    "text": "something you've developed which you may or may not understand or have complete faith in its veracity I think that's an",
    "start": "1918460",
    "end": "1925510"
  },
  {
    "text": "interesting comment part of the concern with any of these things is that they're",
    "start": "1925510",
    "end": "1931150"
  },
  {
    "text": "making high-stakes decisions that aren't so clear how to do that with right so",
    "start": "1931150",
    "end": "1936190"
  },
  {
    "text": "most of the people who are building AI systems aren't likely to be involved in low-level criminal conviction cases",
    "start": "1936190",
    "end": "1944080"
  },
  {
    "text": "right I'm not saying that they shouldn't be I'm just saying statistically speaking that's not something that they regularly interact with right you can",
    "start": "1944080",
    "end": "1952600"
  },
  {
    "text": "give anyone a disease it's pretty hard to like place someone in a criminal justice and try to get you know yes that's right",
    "start": "1952600",
    "end": "2027840"
  },
  {
    "start": "2027000",
    "end": "2132000"
  },
  {
    "text": "very very little of the most popular pieces of machine learning in both",
    "start": "2027840",
    "end": "2034920"
  },
  {
    "text": "industry and academia do much of any reasoning about causality in any real",
    "start": "2034920",
    "end": "2040020"
  },
  {
    "text": "way right so the real question is are the set of trends that these models are predicting are they causal is the fact",
    "start": "2040020",
    "end": "2048360"
  },
  {
    "text": "that you know right sososo causality hands raised if people know what",
    "start": "2048360",
    "end": "2054810"
  },
  {
    "text": "causality is okay so in general this idea that like does the thing we're",
    "start": "2054810",
    "end": "2060240"
  },
  {
    "text": "looking at to try to predict whether someone will commit a crime if I let them out is that merely a statistical",
    "start": "2060240",
    "end": "2066360"
  },
  {
    "text": "pattern or is it the fact that I see these certain behaviors in their history and that in fact causes them to be more",
    "start": "2066360",
    "end": "2072990"
  },
  {
    "text": "likely not just happens to co-occur with with a recidivism rates for example yeah",
    "start": "2072990",
    "end": "2083030"
  },
  {
    "text": "yes yeah yeah yeah yeah yeah yeah that's",
    "start": "2107440",
    "end": "2131990"
  },
  {
    "text": "right so so we're we're poking at a few different things here right this comment was that you know I I've been very loose",
    "start": "2131990",
    "end": "2140180"
  },
  {
    "text": "with my words in terms of I I've been using trend I'm not explicitly trying to say",
    "start": "2140180",
    "end": "2146360"
  },
  {
    "text": "anything temporal with with that phrase although it is the case that if we're",
    "start": "2146360",
    "end": "2151430"
  },
  {
    "text": "imagining deploying a system when things change its behavior will change too or",
    "start": "2151430",
    "end": "2158060"
  },
  {
    "text": "at least its efficacy is likely to change right so the example given that like if you design a trading system",
    "start": "2158060",
    "end": "2164360"
  },
  {
    "text": "based on certain historical trends it may make you a bunch of money for a",
    "start": "2164360",
    "end": "2169370"
  },
  {
    "text": "little while but it is unlikely to make you a lot of money for very long yeah",
    "start": "2169370",
    "end": "2175300"
  },
  {
    "text": "yeah that's that's an interesting comment yeah in the real world yeah so",
    "start": "2175300",
    "end": "2189350"
  },
  {
    "text": "the so the question being who designs these things and that's one of the",
    "start": "2189350",
    "end": "2194900"
  },
  {
    "text": "things that's very interesting there's simultaneously a big push for",
    "start": "2194900",
    "end": "2200030"
  },
  {
    "text": "what people call the democratization of AI which is to say making it as easy as",
    "start": "2200030",
    "end": "2206180"
  },
  {
    "text": "possible for as many people as possible to train models on any data set they",
    "start": "2206180",
    "end": "2211910"
  },
  {
    "text": "might have and while I am sympathetic to the idea that we should try to make the tools we're",
    "start": "2211910",
    "end": "2218360"
  },
  {
    "text": "developing accessible to lots of people and train people how to use them",
    "start": "2218360",
    "end": "2223480"
  },
  {
    "text": "allowing people who know little to nothing about statistics and little to nothing about the consequences of the",
    "start": "2223480",
    "end": "2231050"
  },
  {
    "text": "prediction tasks they're training a model to do or the historical context is hugely problematic right and many of the",
    "start": "2231050",
    "end": "2237560"
  },
  {
    "text": "people in the real world there there are people who like are using pie charts",
    "start": "2237560",
    "end": "2242840"
  },
  {
    "text": "packages that like maybe took undergrad computer science classes and maybe took",
    "start": "2242840",
    "end": "2248540"
  },
  {
    "text": "some statistics classes but like are in no way equipped to be making some of the",
    "start": "2248540",
    "end": "2254660"
  },
  {
    "text": "value judgments in terms of trade-offs of what objective function they're actually optimizing or anything else",
    "start": "2254660",
    "end": "2259670"
  },
  {
    "text": "they're just doing something which seems to work better than you know some basic if then else that they could program",
    "start": "2259670",
    "end": "2265700"
  },
  {
    "text": "without looking at historical data and there are very few rules and regulations",
    "start": "2265700",
    "end": "2270800"
  },
  {
    "text": "as to who would be making such choices there are a few exceptions right but yes",
    "start": "2270800",
    "end": "2282740"
  },
  {
    "text": "I know about validation no no no I I wouldn't rather not talk about it yes so",
    "start": "2282740",
    "end": "2293420"
  },
  {
    "text": "so you know I I've said ok I'm happy to talk about validation sure sure well I",
    "start": "2293420",
    "end": "2302480"
  },
  {
    "text": "mean right in general if people design some machine learning system and train",
    "start": "2302480",
    "end": "2307550"
  },
  {
    "text": "it on some data there's a big concern that you've overfit to your data and one of the many methods for trying to",
    "start": "2307550",
    "end": "2314510"
  },
  {
    "text": "prevent and mitigate that is checking how well your model works on data it did",
    "start": "2314510",
    "end": "2319550"
  },
  {
    "text": "not see in training ok they have what they who is they and what do you mean by",
    "start": "2319550",
    "end": "2327080"
  },
  {
    "text": "half-jew this is another example of good testing but it is not something that is",
    "start": "2327080",
    "end": "2334610"
  },
  {
    "text": "strictly necessary in the sense that like there's no button which you have to like prove in any meaningful way that",
    "start": "2334610",
    "end": "2341870"
  },
  {
    "text": "you've actually done meaningful validation of whatever your whatever you're thinking of deploying yes",
    "start": "2341870",
    "end": "2349269"
  },
  {
    "text": "the new one or the old one the new one",
    "start": "2365630",
    "end": "2371270"
  },
  {
    "text": "yeah right right I and I'm right I agree that validation is regularly avoided in",
    "start": "2371270",
    "end": "2378630"
  },
  {
    "text": "all sorts of human based systems and I think something that a lot of these a lot of these comments are pointing",
    "start": "2378630",
    "end": "2384120"
  },
  {
    "start": "2380000",
    "end": "2654000"
  },
  {
    "text": "towards is a question of what we're assuming algorithms will do that humans",
    "start": "2384120",
    "end": "2390330"
  },
  {
    "text": "cannot or do not right are we assuming that algorithms are going to be making",
    "start": "2390330",
    "end": "2395400"
  },
  {
    "text": "better choices in humans are we assuming the people who are generating and designing these algorithms are going to",
    "start": "2395400",
    "end": "2401040"
  },
  {
    "text": "do more careful testing than humans or human based systems and I don't have",
    "start": "2401040",
    "end": "2408540"
  },
  {
    "text": "good answers to those questions right but I can say that one of at least there",
    "start": "2408540",
    "end": "2415980"
  },
  {
    "text": "are at least two concerns which I think are very important to point out when",
    "start": "2415980",
    "end": "2423660"
  },
  {
    "text": "we're talking about decisions made by one or very small number of machine learning models when compared to humans",
    "start": "2423660",
    "end": "2429450"
  },
  {
    "text": "making the same sorts of choices even if they faced similar biases right so",
    "start": "2429450",
    "end": "2435060"
  },
  {
    "text": "something that's pretty fascinating is the extent to which humans do not like to question the choices and predictions",
    "start": "2435060",
    "end": "2442860"
  },
  {
    "text": "made by machines I again this is some really strange psychological feature of",
    "start": "2442860",
    "end": "2448890"
  },
  {
    "text": "humans we're much more likely to question one another and the decisions one another make then humans writ large",
    "start": "2448890",
    "end": "2455610"
  },
  {
    "text": "are willing to believe that a prediction a Hugh tur makes even though it could be",
    "start": "2455610",
    "end": "2460620"
  },
  {
    "text": "simulating something much much worse right then then the human making the same sorts of choices and so that draws",
    "start": "2460620",
    "end": "2468450"
  },
  {
    "text": "a lot of concerns right in the case in in all of these examples of criminal",
    "start": "2468450",
    "end": "2473820"
  },
  {
    "text": "justice reform using machine learning models it may very well be the case",
    "start": "2473820",
    "end": "2480240"
  },
  {
    "text": "the judge would have made the right choice but the judge gives a lot of deference to the models that are being",
    "start": "2480240",
    "end": "2485910"
  },
  {
    "text": "provided to to the judge that's right",
    "start": "2485910",
    "end": "2499800"
  },
  {
    "text": "humans humans humans are absolutely absolutely so right it's that okay yeah",
    "start": "2499800",
    "end": "2512070"
  },
  {
    "text": "so so the comment was that to entirely encapsulate what's happening with the",
    "start": "2512070",
    "end": "2518520"
  },
  {
    "text": "machine learning method it's sufficient to know the model the algorithm the training data and the inputs for this",
    "start": "2518520",
    "end": "2525240"
  },
  {
    "text": "for this decision I would push back a little bit in that there's a lot of stochasticity and in a lot of these",
    "start": "2525240",
    "end": "2532020"
  },
  {
    "text": "algorithms so you know it won't make the same deterministic choice given the same",
    "start": "2532020",
    "end": "2537780"
  },
  {
    "text": "exact data right so many of the you know I I do want to push back on that to begin with and second of all while it's",
    "start": "2537780",
    "end": "2545010"
  },
  {
    "text": "the case that humans have like many more inputs than we can possibly model that actually points to two the second thing",
    "start": "2545010",
    "end": "2552270"
  },
  {
    "text": "which I I think is important which is that the extent to which we think you",
    "start": "2552270",
    "end": "2558180"
  },
  {
    "text": "know some humans may have mistakes may make mistakes may be much more harsh before lunch may be racist may be sexist",
    "start": "2558180",
    "end": "2564270"
  },
  {
    "text": "may be any number of other things but they are limited in the extension rate",
    "start": "2564270",
    "end": "2569940"
  },
  {
    "text": "to which they themselves can make decisions in any particular circumstance right so like you are hungry before",
    "start": "2569940",
    "end": "2577260"
  },
  {
    "text": "lunch and then you go eat lunch and then when you come back from lunch you're being you know more lenient right which",
    "start": "2577260",
    "end": "2584430"
  },
  {
    "text": "is to say the people before lunch definitely got hosed but the people after lunch are perhaps getting some better treatment and a machine learning",
    "start": "2584430",
    "end": "2592710"
  },
  {
    "text": "model may have much more uniform answers which could be a good thing but could also be problematic right if you're",
    "start": "2592710",
    "end": "2599460"
  },
  {
    "text": "someone who belongs to a class of people who were historically denied home loans",
    "start": "2599460",
    "end": "2604670"
  },
  {
    "text": "if those choices were being made in a non formulaic way by a collection of",
    "start": "2604670",
    "end": "2611180"
  },
  {
    "text": "bank employees and of them were racist or sexist you could go to a different bank I'm not saying",
    "start": "2611180",
    "end": "2617550"
  },
  {
    "text": "that that would have been a solution in a lot of cases historically right in a lot of cases there were formulae which",
    "start": "2617550",
    "end": "2623370"
  },
  {
    "text": "were explicitly trying to exclude large fractions of the population from getting home loans but if we imagine we're in a",
    "start": "2623370",
    "end": "2630510"
  },
  {
    "text": "world today and we you know there are some people who are making bad choices there are other there are other people",
    "start": "2630510",
    "end": "2636870"
  },
  {
    "text": "who can make different choices right whereas if there is sort of one foundational data set and a small number",
    "start": "2636870",
    "end": "2643560"
  },
  {
    "text": "of models trained on that data set making all of these choices you don't really have an alternative or a",
    "start": "2643560",
    "end": "2649440"
  },
  {
    "text": "competitor to turn towards ok ok so I",
    "start": "2649440",
    "end": "2657450"
  },
  {
    "start": "2654000",
    "end": "2716000"
  },
  {
    "text": "think it's important to think about any tool which uses historical data this is",
    "start": "2657450",
    "end": "2662880"
  },
  {
    "text": "what I'm sort of sick calling a machine learning algorithm to predict explain or",
    "start": "2662880",
    "end": "2667950"
  },
  {
    "text": "make decisions so it's really really really crucial that we think about the",
    "start": "2667950",
    "end": "2674640"
  },
  {
    "text": "data we are training on right we've all been alluding to this and poking at it in various ways but this is not",
    "start": "2674640",
    "end": "2680310"
  },
  {
    "text": "something in many cases that people think all that much about it's like oh well we we all of this data was",
    "start": "2680310",
    "end": "2686280"
  },
  {
    "text": "available on Flickr so we gathered a bunch of the data on Flickr and then we see it kind of works in some other",
    "start": "2686280",
    "end": "2692010"
  },
  {
    "text": "environment not just like examples that are that are gathered from Flickr but I think it's really critical that we think",
    "start": "2692010",
    "end": "2698100"
  },
  {
    "text": "about well if we use loan repayment rates for different populations as input",
    "start": "2698100",
    "end": "2704970"
  },
  {
    "text": "to our choices for who to give loans today there are a huge number of historical concerns that come from that",
    "start": "2704970",
    "end": "2712340"
  },
  {
    "text": "ok so I want to again just make some",
    "start": "2712340",
    "end": "2717570"
  },
  {
    "start": "2716000",
    "end": "2956000"
  },
  {
    "text": "brief comment about the extent to which",
    "start": "2717570",
    "end": "2722640"
  },
  {
    "text": "anything in our legal system may be able to be used to address some of the",
    "start": "2722640",
    "end": "2732960"
  },
  {
    "text": "behaviors of machine learning systems as they pertain to varying based on gender race other protected attributes and the",
    "start": "2732960",
    "end": "2741180"
  },
  {
    "text": "short answer is this will probably not be an easy solution",
    "start": "2741180",
    "end": "2746510"
  },
  {
    "text": "as we are all aware the legal system is has a very difficult time figuring out",
    "start": "2746510",
    "end": "2753470"
  },
  {
    "text": "what to do with systems that don't have agency to begin with right so so much of",
    "start": "2753470",
    "end": "2760190"
  },
  {
    "text": "of case law depends upon intent and it's",
    "start": "2760190",
    "end": "2765260"
  },
  {
    "text": "very hard to say who has what kind of intent when you have a very complex system such as some company training",
    "start": "2765260",
    "end": "2771800"
  },
  {
    "text": "some very complex model on some large-scale data set right it's not clear who had intent and who's",
    "start": "2771800",
    "end": "2777710"
  },
  {
    "text": "ultimately responsible for some of those things there are a few exceptions right",
    "start": "2777710",
    "end": "2783410"
  },
  {
    "text": "so I've been poking a lot at two of them that we may actually have some hope that the law would have something to say",
    "start": "2783410",
    "end": "2789620"
  },
  {
    "text": "housing lending employment and the criminal justice system are examples",
    "start": "2789620",
    "end": "2795680"
  },
  {
    "text": "where the law may have something to say even if there's no intent and even if we don't get to know a huge amount about",
    "start": "2795680",
    "end": "2802070"
  },
  {
    "text": "the process by which those decisions are being made those are all cases in which",
    "start": "2802070",
    "end": "2807670"
  },
  {
    "text": "input-output pairs and distributions of those and statistics about those may be sufficient to argue that a machine",
    "start": "2807670",
    "end": "2813830"
  },
  {
    "text": "learning method is doing something which may not stand up to to legal challenge",
    "start": "2813830",
    "end": "2819740"
  },
  {
    "text": "but most of the other settings where we're thinking about this medicine or",
    "start": "2819740",
    "end": "2825940"
  },
  {
    "text": "many other things the the law will have very little to say unless we have a lot more information about models yes about",
    "start": "2825940",
    "end": "2840160"
  },
  {
    "text": "self-driving cars yeah yeah right and",
    "start": "2840160",
    "end": "2854000"
  },
  {
    "text": "this is yep yep who is jaywalking shame",
    "start": "2854000",
    "end": "2868010"
  },
  {
    "text": "on her she deserves to be",
    "start": "2868010",
    "end": "2871330"
  },
  {
    "text": "absurd right so there's yes so there's",
    "start": "2877050",
    "end": "2894910"
  },
  {
    "text": "there's definitely there's I I'm not a legal scholar let me be perfectly clear nowhere close to it",
    "start": "2894910",
    "end": "2900640"
  },
  {
    "text": "I know next to nothing about what the law can do will do may do in these",
    "start": "2900640",
    "end": "2906730"
  },
  {
    "text": "contexts it's definitely interesting to understand when a human is interacting",
    "start": "2906730",
    "end": "2912100"
  },
  {
    "text": "with a system that often does the right thing but sometimes does not whether the human who's ultimately supposed to be",
    "start": "2912100",
    "end": "2918160"
  },
  {
    "text": "the backup is liable when the system fails right and this is the example where a mostly autonomous car which was",
    "start": "2918160",
    "end": "2926620"
  },
  {
    "text": "supposed to have a backup human driver when that runs over and kills a woman who's responsible and and it's that is",
    "start": "2926620",
    "end": "2934540"
  },
  {
    "text": "not established law this is the first example of one of these things and we it's going to be very the process of",
    "start": "2934540",
    "end": "2941500"
  },
  {
    "text": "determining who's liable is going to be contentious and with that actually I so",
    "start": "2941500",
    "end": "2948910"
  },
  {
    "text": "I'm going to say one or two more things and then I actually want to talk about one specific provocative example so as",
    "start": "2948910",
    "end": "2958510"
  },
  {
    "start": "2956000",
    "end": "3026000"
  },
  {
    "text": "we're sort of suggesting not all mistakes of a machine learning system are created equal again going back to",
    "start": "2958510",
    "end": "2964570"
  },
  {
    "text": "this question of what are we optimizing right average zero one loss is probably",
    "start": "2964570",
    "end": "2969640"
  },
  {
    "text": "not what we're trying to optimize in almost any context we've been discussing false positives are relatively cost less",
    "start": "2969640",
    "end": "2977350"
  },
  {
    "text": "when we're thinking about self-driving cars if we're talking about a positive label as is there a human should I stop",
    "start": "2977350",
    "end": "2983910"
  },
  {
    "text": "whereas false negatives cause people to be killed so it's really important to",
    "start": "2983910",
    "end": "2990040"
  },
  {
    "text": "think about sort of the cost of different types of mistakes I don't want",
    "start": "2990040",
    "end": "2996760"
  },
  {
    "text": "to suggest that we should try to avoid using machine learning in any",
    "start": "2996760",
    "end": "3003180"
  },
  {
    "text": "it's possible but that it's important that we really grapple with these socio-technical things as well as the",
    "start": "3003180",
    "end": "3009960"
  },
  {
    "text": "technical concerns that come from machine learning you know there's lots",
    "start": "3009960",
    "end": "3015030"
  },
  {
    "text": "of fun and cool research questions in this space so I want to hold on one moment",
    "start": "3015030",
    "end": "3020099"
  },
  {
    "text": "oh this works excellent I just updated my my software so I didn't know if this",
    "start": "3020099",
    "end": "3025170"
  },
  {
    "text": "is going to work okay so the thing I",
    "start": "3025170",
    "end": "3031619"
  },
  {
    "start": "3026000",
    "end": "3095000"
  },
  {
    "text": "want to talk to you about you know we only we only have you know 15-20 minutes left",
    "start": "3031619",
    "end": "3036960"
  },
  {
    "text": "this these slides if I were talking by myself would not take 15 or 20 minutes",
    "start": "3036960",
    "end": "3042119"
  },
  {
    "text": "to go through but I would imagine interaction from you guys will probably make this take at least 15 or 20 minutes",
    "start": "3042119",
    "end": "3049740"
  },
  {
    "text": "but I'll just stop when we're out of time so the one thing I want to tell you",
    "start": "3049740",
    "end": "3055650"
  },
  {
    "text": "a little bit about which is like an active piece of my personal research is",
    "start": "3055650",
    "end": "3061440"
  },
  {
    "text": "is very very new just posted it to archive Thursday which is joint with Ben",
    "start": "3061440",
    "end": "3070829"
  },
  {
    "text": "Wilson who's an excellent student at Georgia Tech and Judy Hoffman will be starting as faculty at Georgia Tech in",
    "start": "3070829",
    "end": "3077760"
  },
  {
    "text": "the fall and she did her PhD just across the bay so and I'm very excited to hear",
    "start": "3077760",
    "end": "3086400"
  },
  {
    "text": "more about what all of you think about this so with that caveat those caveats",
    "start": "3086400",
    "end": "3093020"
  },
  {
    "text": "okay so what I want to talk to you about briefly which we've been talking talking",
    "start": "3093020",
    "end": "3100319"
  },
  {
    "start": "3095000",
    "end": "3150000"
  },
  {
    "text": "around a little bit is this idea of using machine learning systems to do",
    "start": "3100319",
    "end": "3105690"
  },
  {
    "text": "driving centric object detection right which is to say if you the the simplest the the wild simplification of this task",
    "start": "3105690",
    "end": "3113400"
  },
  {
    "text": "is that we have a bunch of static images taken from the vantage point of a car or a self-driving car or something like",
    "start": "3113400",
    "end": "3119970"
  },
  {
    "text": "this and the machine learning task that we're trying to accomplish is to draw a bounding boxes around other cars around",
    "start": "3119970",
    "end": "3127650"
  },
  {
    "text": "bicycles around riders of those bicycles around pedestrians around stop signs around stoplights and then label them as",
    "start": "3127650",
    "end": "3135780"
  },
  {
    "text": "such okay so this is like a pretty well-formed computer vision task right",
    "start": "3135780",
    "end": "3143170"
  },
  {
    "text": "if this is like if the inputs are these and and this is the the objective of some system right I'll give you an",
    "start": "3143170",
    "end": "3149950"
  },
  {
    "text": "example here right so you know here's an example of an image taken from the",
    "start": "3149950",
    "end": "3156040"
  },
  {
    "start": "3150000",
    "end": "3182000"
  },
  {
    "text": "vantage point of a car as well as being you know draw sort of partitioning the",
    "start": "3156040",
    "end": "3161320"
  },
  {
    "text": "space into different objects that are important for thinking about driving and being labeled as you know cars",
    "start": "3161320",
    "end": "3166960"
  },
  {
    "text": "motorcycles riders stoplights things like that so this is a pretty standard vision task",
    "start": "3166960",
    "end": "3175120"
  },
  {
    "text": "at this point if you're talking about like academic research in the vision community and I started with a",
    "start": "3175120",
    "end": "3182860"
  },
  {
    "start": "3182000",
    "end": "3293000"
  },
  {
    "text": "hypothesis which was based on other evidence I'd seen in other vision",
    "start": "3182860",
    "end": "3188290"
  },
  {
    "text": "domains which was that we would expect to see error rates of systems of this",
    "start": "3188290",
    "end": "3194980"
  },
  {
    "text": "variety very systematically across skin tones right so I alluded at the",
    "start": "3194980",
    "end": "3202300"
  },
  {
    "text": "beginning and talk briefly about Amazon's facial recognition system having lots of false positives when run",
    "start": "3202300",
    "end": "3208270"
  },
  {
    "text": "on run on Congress pictures and that those were much more common amongst",
    "start": "3208270",
    "end": "3214020"
  },
  {
    "text": "amongst people of color and I also mentioned right this example of Google tagging facial images of",
    "start": "3214020",
    "end": "3220870"
  },
  {
    "text": "african-americans as gorillas actually funny funny side story not funny but",
    "start": "3220870",
    "end": "3225900"
  },
  {
    "text": "Google for a time was just entirely removing the tagged gorilla from their",
    "start": "3225900",
    "end": "3233470"
  },
  {
    "text": "image labeling as opposed to like trying to fundamentally understand why their system was doing that and trying to",
    "start": "3233470",
    "end": "3239050"
  },
  {
    "text": "change it this is like the min edit distance thing yeah that's right",
    "start": "3239050",
    "end": "3245770"
  },
  {
    "text": "but it doesn't mean they understood why it was happening and had a meaningful fix that may not be true anymore but",
    "start": "3245770",
    "end": "3252670"
  },
  {
    "text": "that was true up to maybe two years after this discovery and there's also work that has shown that several",
    "start": "3252670",
    "end": "3259660"
  },
  {
    "text": "commercially available pieces of software based on facial recognition are",
    "start": "3259660",
    "end": "3265090"
  },
  {
    "text": "much more likely to correctly classify face is to the correct gender for lighter",
    "start": "3265090",
    "end": "3272800"
  },
  {
    "text": "skinned men than darker skinned women all right so we have a bunch of examples specifically in the context of computer",
    "start": "3272800",
    "end": "3278950"
  },
  {
    "text": "vision systems relatively simple supervised tasks where computer vision",
    "start": "3278950",
    "end": "3284260"
  },
  {
    "text": "systems seem to work better on lighter skinned individuals so for this reason I",
    "start": "3284260",
    "end": "3290050"
  },
  {
    "text": "had this hypothesis yeah so well right",
    "start": "3290050",
    "end": "3321100"
  },
  {
    "start": "3293000",
    "end": "3355000"
  },
  {
    "text": "so there's definitely a question of whether we should be doing facial recognition on two-dimensional model on two-dimensional representations of faces",
    "start": "3321100",
    "end": "3327790"
  },
  {
    "text": "at all we have a lot of evidence that it doesn't work particularly well in certain contexts and it works worse for some demographic groups than others and",
    "start": "3327790",
    "end": "3334119"
  },
  {
    "text": "yet this is still something that Amazon is actively selling to law enforcement agencies so you can argue that it's a",
    "start": "3334119",
    "end": "3342460"
  },
  {
    "text": "good thing to do or a bad thing to do but it is something people are doing which is yes yeah okay",
    "start": "3342460",
    "end": "3353410"
  },
  {
    "text": "well I have to tell you a little bit more about what I how we were going to do this right so I wanted to know how we",
    "start": "3353410",
    "end": "3359140"
  },
  {
    "text": "can test this and I really wanted to ask this on common classes of models used",
    "start": "3359140",
    "end": "3365230"
  },
  {
    "text": "for this in academia and common data sets that are considered in in academia",
    "start": "3365230",
    "end": "3370660"
  },
  {
    "text": "which are generally used for this driving centric object detection okay so if you're someone who knows what these",
    "start": "3370660",
    "end": "3376810"
  },
  {
    "text": "are that's great if you don't that's fine too these are just the first things are classes of models that are generally",
    "start": "3376810",
    "end": "3383890"
  },
  {
    "text": "used for driving centric object detection and like current computer vision papers being published the next",
    "start": "3383890",
    "end": "3389740"
  },
  {
    "text": "two things the first one is a driving centric object data set the other ones",
    "start": "3389740",
    "end": "3394750"
  },
  {
    "text": "just a more general-purpose image recognition data set okay",
    "start": "3394750",
    "end": "3400950"
  },
  {
    "text": "okay lots of other details right so this data set and most data sets don't",
    "start": "3400950",
    "end": "3407220"
  },
  {
    "text": "actually explicitly have demographic tagging in them so we had to do a bunch of things to actually have some of that",
    "start": "3407220",
    "end": "3412829"
  },
  {
    "text": "information to even be able to test this hypothesis right so the experiment was to fix a class of models and",
    "start": "3412829",
    "end": "3418740"
  },
  {
    "text": "optimization method a training data set all of which are pretty standard in this domain and measures of performance which",
    "start": "3418740",
    "end": "3426270"
  },
  {
    "text": "are common and common to evaluate the veracity of how well computer vision",
    "start": "3426270",
    "end": "3431760"
  },
  {
    "text": "system is working broken out by a specific notion of skin type okay",
    "start": "3431760",
    "end": "3437400"
  },
  {
    "start": "3437000",
    "end": "3462000"
  },
  {
    "text": "so I'll give you a few images these are not meant to give you any meaningful",
    "start": "3437400",
    "end": "3443520"
  },
  {
    "text": "information other than you know these are just bounding boxes we've drawn around pedestrians you know there there",
    "start": "3443520",
    "end": "3449670"
  },
  {
    "text": "are some funny things there's a false positive up here where the Podesta this the system thinks this 30 foot",
    "start": "3449670",
    "end": "3456390"
  },
  {
    "text": "blow-up rat is a pedestrian",
    "start": "3456390",
    "end": "3459890"
  },
  {
    "text": "so in short there is likely to be some difference in this very specific context",
    "start": "3461490",
    "end": "3468750"
  },
  {
    "text": "right so it appears that there is some gap in terms of the average precision",
    "start": "3468750",
    "end": "3476130"
  },
  {
    "text": "and the finer grained ap 75 measures these are just specific measures that people do when trying to",
    "start": "3476130",
    "end": "3482880"
  },
  {
    "text": "understand how well these sorts of bounding box problems are operating where we see that the lighter skinned",
    "start": "3482880",
    "end": "3489750"
  },
  {
    "text": "pedestrians both in terms of AP and AP 75 the red lines are above the blue",
    "start": "3489750",
    "end": "3494970"
  },
  {
    "text": "lines which is to say the average precision numbers are somewhat higher for this very specific thing which I did",
    "start": "3494970",
    "end": "3503329"
  },
  {
    "text": "yeah",
    "start": "3503390",
    "end": "3506390"
  },
  {
    "text": "yeah yes so the the comment was it would",
    "start": "3513460",
    "end": "3518680"
  },
  {
    "text": "be very interesting to change the skin tone of the pedestrians in some of our",
    "start": "3518680",
    "end": "3525520"
  },
  {
    "text": "examples and see what would happen my guess is it would totally break and the reason I say that is I don't know of a",
    "start": "3525520",
    "end": "3531280"
  },
  {
    "text": "way to do that where the examples would look enough like the examples they were",
    "start": "3531280",
    "end": "3537730"
  },
  {
    "text": "trained upon and most of the vision systems we're talking about these in particular but the ones that are being",
    "start": "3537730",
    "end": "3542740"
  },
  {
    "text": "trained and our like state of the art in general are very very very sensitive to",
    "start": "3542740",
    "end": "3548559"
  },
  {
    "text": "very small changes in in training data or test data yeah absolutely no but I",
    "start": "3548559",
    "end": "3555819"
  },
  {
    "text": "agree that one of the interesting questions is like the extent to which we could try to understand when this will",
    "start": "3555819",
    "end": "3560890"
  },
  {
    "text": "and will not happen right and let me let me be clear because I know many of you are trained in a variety of different",
    "start": "3560890",
    "end": "3567400"
  },
  {
    "text": "things these are results that are",
    "start": "3567400",
    "end": "3572740"
  },
  {
    "text": "reported on validation right so we trained on one dataset these are the reports these are the results we found",
    "start": "3572740",
    "end": "3578290"
  },
  {
    "text": "on validation for this very particular data set and these are not I have no",
    "start": "3578290",
    "end": "3583390"
  },
  {
    "text": "error bars here which pains me very deeply right I don't say that like you",
    "start": "3583390",
    "end": "3589690"
  },
  {
    "text": "know with probably with 95% confidence I see this gap this gap is one standard",
    "start": "3589690",
    "end": "3594700"
  },
  {
    "text": "deviation away from what you might expect if they were equal the reason I",
    "start": "3594700",
    "end": "3600369"
  },
  {
    "text": "still think it's important and critical to point this out as a possible problem even though we don't have statistical",
    "start": "3600369",
    "end": "3606369"
  },
  {
    "text": "significance is the fact that in order to have statistical significance for a",
    "start": "3606369",
    "end": "3611470"
  },
  {
    "text": "gap of say five to ten percent difference in average precision we would need roughly 15,000 images does someone",
    "start": "3611470",
    "end": "3618940"
  },
  {
    "text": "have $100,000 they'd like to give me because I would be happy to gather that data set right and I I think the onus is",
    "start": "3618940",
    "end": "3625690"
  },
  {
    "text": "really upon people who are planning to make millions and millions and millions of dollars off of these things to invest some in an independent third party to",
    "start": "3625690",
    "end": "3633400"
  },
  {
    "text": "carefully evaluate how well the models are going to work yeah",
    "start": "3633400",
    "end": "3638940"
  },
  {
    "text": "no no it's a much more fine-grained version so so average precision looks at",
    "start": "3647530",
    "end": "3653750"
  },
  {
    "text": "the intersection over the union of the the area of these bounding boxes there's",
    "start": "3653750",
    "end": "3659120"
  },
  {
    "text": "a ground truth bounding box there's the box you drew it's certainly a particularly bad error if there was a",
    "start": "3659120",
    "end": "3665270"
  },
  {
    "text": "bounding box and you didn't draw one or there wasn't a bounding box and you drew one but in general what's interesting is",
    "start": "3665270",
    "end": "3670820"
  },
  {
    "text": "how much space do they overlap upon and this is some complex blend of several",
    "start": "3670820",
    "end": "3677270"
  },
  {
    "text": "different ways to look at those numbers right so this is not saying that like",
    "start": "3677270",
    "end": "3683240"
  },
  {
    "text": "out of a hundred lighter-skinned pedestrians we would see X and out of a hundred darker-skinned pedestrians we",
    "start": "3683240",
    "end": "3689150"
  },
  {
    "text": "would see X minus five it's saying something more precise than that and",
    "start": "3689150",
    "end": "3694820"
  },
  {
    "text": "more about like small differences in terms of how well we drop bounding boxes",
    "start": "3694820",
    "end": "3701350"
  },
  {
    "text": "okay I mean it's right yes or no is not",
    "start": "3701350",
    "end": "3715490"
  },
  {
    "text": "the only answer that matters we're yeah yeah so um you know if you if you prefer",
    "start": "3715490",
    "end": "3721870"
  },
  {
    "text": "numbers that are drawn like this rather than then charts these are just what the",
    "start": "3721870",
    "end": "3727370"
  },
  {
    "text": "difference is after some large number of training grounds ends up looking like training iterations looks like so as I mentioned",
    "start": "3727370",
    "end": "3734900"
  },
  {
    "text": "right AP and AP 75 which are the least and most fine-grained in terms of localization of these three metrics seem",
    "start": "3734900",
    "end": "3742040"
  },
  {
    "text": "to have some reasonably sized gaps in terms of the percentage of of these metrics when you look at light skin",
    "start": "3742040",
    "end": "3748550"
  },
  {
    "text": "versus darker skin pedestrians and again these are not error bars these are just",
    "start": "3748550",
    "end": "3753800"
  },
  {
    "text": "the particular algorithms that are used to train these models at randomized so",
    "start": "3753800",
    "end": "3759830"
  },
  {
    "text": "you have to imagine training them several times and seeing sort of what you might expect that gap to look like",
    "start": "3759830",
    "end": "3766790"
  },
  {
    "text": "as you train them multiple times okay so a natural question one might ask",
    "start": "3766790",
    "end": "3772880"
  },
  {
    "text": "and i think i'll yes i'll finish right on time is why we might expect this to",
    "start": "3772880",
    "end": "3778640"
  },
  {
    "text": "be happening right and if you talk to it's really actually quite fascinating the extent to which people have like",
    "start": "3778640",
    "end": "3784369"
  },
  {
    "text": "different opinions about why this might be happening and as i mentioned right",
    "start": "3784369",
    "end": "3789920"
  },
  {
    "text": "we're not saying anything with like high degrees of statistical power here so i'm not saying that like i know or don't",
    "start": "3789920",
    "end": "3796369"
  },
  {
    "text": "know these things but i do have some preliminary evidence that may suggest what may or may not be at least",
    "start": "3796369",
    "end": "3801950"
  },
  {
    "text": "partially responsible okay so one of the",
    "start": "3801950",
    "end": "3806989"
  },
  {
    "text": "first things that you or anyone who thinks about vision might think about is that contrast is incredibly contrast",
    "start": "3806989",
    "end": "3814190"
  },
  {
    "text": "between the thing you're trying to draw a bounding box around and the color of the background that they are on is",
    "start": "3814190",
    "end": "3820479"
  },
  {
    "text": "incredibly important and makes you know if there's less contrast it's a harder task to draw an accurate bounding box",
    "start": "3820479",
    "end": "3826999"
  },
  {
    "text": "around a subject so one thing that we did was we removed all nighttime images",
    "start": "3826999",
    "end": "3832789"
  },
  {
    "text": "and only looked at daylight and we still saw this behavior right so it doesn't",
    "start": "3832789",
    "end": "3838219"
  },
  {
    "text": "seem that like the problems come from nighttime images where there's much less",
    "start": "3838219",
    "end": "3843339"
  },
  {
    "text": "contrast between darker skinned individuals and their surroundings",
    "start": "3843339",
    "end": "3848509"
  },
  {
    "text": "another general thing that makes vision tasks harder is when there are lots and",
    "start": "3848509",
    "end": "3854599"
  },
  {
    "text": "lots of images all on top of each other one of the example images I had there within Time Square and they were like lots and lots of people all on top of",
    "start": "3854599",
    "end": "3861200"
  },
  {
    "text": "each other and that's just it's harder for humans to write it's not super easy",
    "start": "3861200",
    "end": "3866329"
  },
  {
    "text": "to draw a really precise boxes when there are lots and lots of subjects of your of your image but this gap seems to",
    "start": "3866329",
    "end": "3872930"
  },
  {
    "text": "persist even if we remove all of the occluded occlusion is just the word for this right if you remove all of the occluded",
    "start": "3872930",
    "end": "3878989"
  },
  {
    "text": "individuals from your data set right and it you could imagine again that like maybe all of the people of a certain",
    "start": "3878989",
    "end": "3885349"
  },
  {
    "text": "demographic group live in very occluded neighborhoods I'm not saying this is the case but like people might argue that",
    "start": "3885349",
    "end": "3891049"
  },
  {
    "text": "this was the case and this does not seem to be primarily the the source of this behavior we people may separately wonder",
    "start": "3891049",
    "end": "3898849"
  },
  {
    "text": "right like what's the gap in terms of how many lighter versus darker skinned pedestrians are in the training set and",
    "start": "3898849",
    "end": "3903890"
  },
  {
    "text": "the answer is it's somewhere between 3 & 4 to right because this particular dataset",
    "start": "3903890",
    "end": "3909320"
  },
  {
    "text": "which was collected by researchers at Berkley was collected in the Bay Area common New York comma Tel Aviv maybe one",
    "start": "3909320",
    "end": "3916460"
  },
  {
    "text": "or two other one or two other places but they were not primarily gathered in for",
    "start": "3916460",
    "end": "3924170"
  },
  {
    "text": "example Atlanta right and so three three or four to one is pretty representative",
    "start": "3924170",
    "end": "3929840"
  },
  {
    "text": "compared to a lot of that data sets we have just in general right but it is not particularly balanced in some other",
    "start": "3929840",
    "end": "3937250"
  },
  {
    "text": "senses okay so you might ask whether we're sort of just not given enough data",
    "start": "3937250",
    "end": "3944600"
  },
  {
    "text": "to do particularly well in terms of the smaller population and I I have again",
    "start": "3944600",
    "end": "3950780"
  },
  {
    "text": "limited information and limited understanding but it does not appear to me that we are primarily just like",
    "start": "3950780",
    "end": "3956060"
  },
  {
    "text": "running into not being able to do any better on the smaller set okay so you",
    "start": "3956060",
    "end": "3963560"
  },
  {
    "text": "know I'm not trying to say that self-driving cars are much more likely to harm certain people than others that",
    "start": "3963560",
    "end": "3971540"
  },
  {
    "text": "is the sensational hot take of this particular work but I am saying this",
    "start": "3971540",
    "end": "3977270"
  },
  {
    "text": "kind of vision system when trained on publicly available data sets as opposed to the proprietary data sets that",
    "start": "3977270",
    "end": "3983270"
  },
  {
    "text": "self-driving cars are competing with one another to collect may have better",
    "start": "3983270",
    "end": "3989750"
  },
  {
    "text": "performance on different on different types of pedestrians and we really need",
    "start": "3989750",
    "end": "3995690"
  },
  {
    "text": "to understand this phenomenon better and we need the resources given from people",
    "start": "3995690",
    "end": "4001840"
  },
  {
    "text": "who are really standing in a place to make a lot of money from using these kinds of systems to more carefully",
    "start": "4001840",
    "end": "4008859"
  },
  {
    "text": "evaluate both the industry standard and the academic standard types of models",
    "start": "4008859",
    "end": "4014050"
  },
  {
    "text": "and data sets right and more broadly right and this again goes back to",
    "start": "4014050",
    "end": "4019240"
  },
  {
    "text": "several comments that have been made throughout this presentation it's very important that we carefully very very",
    "start": "4019240",
    "end": "4025810"
  },
  {
    "text": "carefully painstakingly evaluate all parts of our machine learning systems in",
    "start": "4025810",
    "end": "4031450"
  },
  {
    "text": "environments that are as close as possible to those they will actually be deployed in okay if we hope to",
    "start": "4031450",
    "end": "4037600"
  },
  {
    "text": "understand how well they will behave I don't care",
    "start": "4037600",
    "end": "4043090"
  },
  {
    "text": "[Applause]",
    "start": "4043090",
    "end": "4046899"
  }
]
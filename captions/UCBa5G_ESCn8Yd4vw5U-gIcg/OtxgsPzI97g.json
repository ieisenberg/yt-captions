[
  {
    "start": "0",
    "end": "9920"
  },
  {
    "text": "Thank you so much for\nthe kind introduction. Thank you, everyone\nfor being here. I see some familiar faces in the\ncrowd, mainly from my own lab.",
    "start": "9920",
    "end": "17160"
  },
  {
    "text": "But let's change that, and I\ncan get to know the rest of you as well. So indeed, I'm coming from\nthe Civil and Environmental",
    "start": "17160",
    "end": "24380"
  },
  {
    "text": "Engineering department. And here is my team. We took this picture\na couple of weeks ago. And you can see\nmost of my students",
    "start": "24380",
    "end": "30080"
  },
  {
    "text": "actually do not have a civil\nand environmental engineering background, but they're actually\nroboticists and computer",
    "start": "30080",
    "end": "35210"
  },
  {
    "text": "scientists. And we are working\nto solve problems that exist in the\nbuilding industry,",
    "start": "35210",
    "end": "41250"
  },
  {
    "text": "but we use computer\nvision for that. And in general, the kind\nof work that my group does",
    "start": "41250",
    "end": "47030"
  },
  {
    "text": "is about understanding\nwhat exists in a space, how it was constructed,\nand how it changes",
    "start": "47030",
    "end": "52070"
  },
  {
    "text": "over time, with the ultimate\ngoal of creating sustainable, inclusive, and adaptive\nbuilt environments",
    "start": "52070",
    "end": "57530"
  },
  {
    "text": "that place the\nhuman in the center and take also into\naccount our current and future physical and\ndigital needs as well.",
    "start": "57530",
    "end": "64768"
  },
  {
    "text": "And although this\nis a little bit further from what\nrobotics is doing, we are also thinking\nabout how can we",
    "start": "64769",
    "end": "72210"
  },
  {
    "text": "be at the interface of physical\nand digital, for example, with immersive technologies,\nVR and AR, and how",
    "start": "72210",
    "end": "78030"
  },
  {
    "text": "we can create actually\nand design spaces, physical spaces that\nallow this interaction",
    "start": "78030",
    "end": "83250"
  },
  {
    "text": "between the physical world\nand the virtual world. And we call those\ngradient realities.",
    "start": "83250",
    "end": "88530"
  },
  {
    "text": "And that's how the name of the\nlab came up, Gradient Spaces.",
    "start": "88530",
    "end": "94020"
  },
  {
    "text": "Now, today I will\nspecifically talk about how can we create and\nupdate digital replicas",
    "start": "94020",
    "end": "102119"
  },
  {
    "text": "or evolving representations\nof our indoor scenes as they change over time. And we're calling\nthose living scenes.",
    "start": "102120",
    "end": "109590"
  },
  {
    "text": "Now, we can make the\ncomparison that buildings are like living organisms, which\nmeans they evolve over time.",
    "start": "109590",
    "end": "117550"
  },
  {
    "text": "So how can we realistically\nmaintain and update the representations\nthroughout the lifespan?",
    "start": "117550",
    "end": "125250"
  },
  {
    "text": "So we have agents that\nexist in the wild, and as they do that,\nthey can navigate within existing environments.",
    "start": "125250",
    "end": "131379"
  },
  {
    "text": "They can act within them\nor interact with them. And in order to do all of this,\nthey need to be able to map",
    "start": "131380",
    "end": "138810"
  },
  {
    "text": "and understand the\nsurrounding environment. So you can see\nhere, for example,",
    "start": "138810",
    "end": "145362"
  },
  {
    "text": "a demonstration I found online. And imagine that all those\nlittle gray dots are agents, one or multiple agents that\noperate within the environment",
    "start": "145362",
    "end": "152640"
  },
  {
    "text": "at different times. So they have different\ntrajectories. They collect different data\nwith changes within them.",
    "start": "152640",
    "end": "158640"
  },
  {
    "text": "So imagine for\nexample here, if you had the agent at two\ndifferent times exploring different parts\nof the environment",
    "start": "158640",
    "end": "163890"
  },
  {
    "text": "and you want to collect\nall those together. So essentially we need to\nget all these different data",
    "start": "163890",
    "end": "169260"
  },
  {
    "text": "that an agent collects\nwhile performing tasks and create those\nevolving representations of the indoor\nenvironment, which means",
    "start": "169260",
    "end": "175739"
  },
  {
    "text": "we need to be able to align\nand merge spatiotemporal data. Now, as I just\nmentioned, we're not",
    "start": "175740",
    "end": "184210"
  },
  {
    "text": "talking about acquiring\ndata without an agent. Agent can go around\nand can be performing",
    "start": "184210",
    "end": "189940"
  },
  {
    "text": "repetitive tasks within a single\nscene, within an environment. And as they do that, they\ncapture information about",
    "start": "189940",
    "end": "196150"
  },
  {
    "text": "the environment within them,\nprobably 3D information, sometimes 2D. But imagine if we acquire\nall this data and create",
    "start": "196150",
    "end": "202269"
  },
  {
    "text": "a cumulative scene understanding\nscene representation over multiple of these 3D scans we\nacquire over multiple times,",
    "start": "202270",
    "end": "209150"
  },
  {
    "text": "we can create a progressively\nimproving in geometric completeness and accuracy\nmap of our environment,",
    "start": "209150",
    "end": "215680"
  },
  {
    "text": "particularly if there are parts\nof our scene that we've never",
    "start": "215680",
    "end": "220840"
  },
  {
    "text": "seen before in temporal\ntime 1 but temporal line 2, when we perform a different\naction or something has changed,",
    "start": "220840",
    "end": "227150"
  },
  {
    "text": "we can actually see\nmore and more of that. And why is that important? Because in this way, we\ncan enhance the interaction",
    "start": "227150",
    "end": "234220"
  },
  {
    "text": "with the objects\nwithin the scene by having a more accurate\ngeometry and more complete geometry, and we\ncan start having",
    "start": "234220",
    "end": "241640"
  },
  {
    "text": "a foundational\nunderstanding of how objects move within the scene.",
    "start": "241640",
    "end": "247790"
  },
  {
    "text": "And with that, I will\ntouch upon three works that look into creating and\nupdating replicas of geometry",
    "start": "247790",
    "end": "254030"
  },
  {
    "text": "and semantics using visual\ndata that agents acquire while performing tasks\nand that by thinking",
    "start": "254030",
    "end": "260299"
  },
  {
    "text": "of realistic implementations\nand also privacy preserving in certain cases. And so we look at\ngeometry-based,",
    "start": "260300",
    "end": "266610"
  },
  {
    "text": "scene graph-based,\nand other work that looks at drastic change. And before I even go\ninto understanding",
    "start": "266610",
    "end": "273170"
  },
  {
    "text": "living representations and\nchanging representations, let's focus on how\ncan we acquire it",
    "start": "273170",
    "end": "279050"
  },
  {
    "text": "at one temporal point. And there are very different\nmethods that you can do that, but I will focus on two works\nthat I've done in my lab.",
    "start": "279050",
    "end": "285919"
  },
  {
    "text": "And the first one is one that\nis under review by Liyuan Zhu. It's called LoopSplat. And essentially, we are\nusing the 3D Gaussian splat",
    "start": "285920",
    "end": "292550"
  },
  {
    "text": "representation in order to in\nan online manner reconstruct the scene with great accuracy.",
    "start": "292550",
    "end": "298789"
  },
  {
    "text": "And the particular innovation\nof this method that is able to perform loop detection\nand perform loop closure",
    "start": "298790",
    "end": "305419"
  },
  {
    "text": "by registering 3D\nGaussians plots together. The trajectory you\nsee it on the screen,",
    "start": "305420",
    "end": "311690"
  },
  {
    "text": "and it has different\ncolors that designate how much drift it exists from\nthe ground to trajectory.",
    "start": "311690",
    "end": "318210"
  },
  {
    "text": "And if you notice that\nvideo for quite a while, you will see that in\ncertain cases when it does detect the loop closure,\nthe color of the trajectory",
    "start": "318210",
    "end": "325430"
  },
  {
    "text": "changes to minimizing\nthat drift. Another work that we've done\nwith my student, Jianhao Zheng,",
    "start": "325430",
    "end": "332780"
  },
  {
    "text": "is about creating an adaptive,\nreal time 3D semantic understanding of the scene. And in this particular\nwork, we focused on that.",
    "start": "332780",
    "end": "339960"
  },
  {
    "text": "We don't need\neverything and anything, and that sustainability starts\nfrom the data we're collecting. So instead of collecting too\nmuch data on too high resolution",
    "start": "339960",
    "end": "347723"
  },
  {
    "text": "without even knowing what\nwe're going to do with it, we can actually create\non one single map",
    "start": "347723",
    "end": "353060"
  },
  {
    "text": "with adaptive quality, which\nmeans certain rigors are going to be in very high\nfidelity, essentially,",
    "start": "353060",
    "end": "359530"
  },
  {
    "text": "if you consider a Voxel map\nrepresentation in a very small resolution,\nor it can also be",
    "start": "359530",
    "end": "364830"
  },
  {
    "text": "in a very low resolution\nin other parts that you don't care\nthat much about. And that can be defined\nby user-based semantics",
    "start": "364830",
    "end": "371440"
  },
  {
    "text": "by the geometric\ncomplexity of the scene and by any other\ncriterion you might want.",
    "start": "371440",
    "end": "376500"
  },
  {
    "text": "Now, we've seen two\nworks that can get you into what exists right now as\nyou are looking at this scene.",
    "start": "376500",
    "end": "384870"
  },
  {
    "text": "Let's look about\nhow to do it when you have evolving environments. The first work I\nwant to refer to",
    "start": "384870",
    "end": "391200"
  },
  {
    "text": "actually has the\nsame name as the talk in terms of Living Scenes. Again, it's from my\nstudent, Liyuan Zhu.",
    "start": "391200",
    "end": "397300"
  },
  {
    "text": "It was a paper in\n2024 as a spotlight.",
    "start": "397300",
    "end": "402690"
  },
  {
    "text": "Now, in this\nparticular work, I'm going to make an even more\nrefined definition of what",
    "start": "402690",
    "end": "409379"
  },
  {
    "text": "it means to be a living scene. We're talking about\nevolving environments where you have irregular\nchanges and of which you",
    "start": "409380",
    "end": "416550"
  },
  {
    "text": "have sparse observations. So you might have\nan observation of it right now then after maybe\ntwo weeks, after one month.",
    "start": "416550",
    "end": "423220"
  },
  {
    "text": "So you don't know what\nhappened in between. And the goal is, given this\nsparse 3D observations, can you localize the objects\nwithin the scene and reconstruct",
    "start": "423220",
    "end": "431400"
  },
  {
    "text": "them on an individual object\nlevel, object instance level. So this is the\nmethod overview where",
    "start": "431400",
    "end": "438000"
  },
  {
    "text": "we begin by can you actually\nsee my point ingrained where we begin by\nhaving as an input",
    "start": "438000",
    "end": "445150"
  },
  {
    "text": "the scene at two temporal points\nwhere things have changed. The first step is to\nperform instance matching.",
    "start": "445150",
    "end": "450880"
  },
  {
    "text": "We make the assumptions that\nwe have instance segmentation. And actually is a valid one\nbecause we tried both ground",
    "start": "450880",
    "end": "456840"
  },
  {
    "text": "truth and predicted instances. And we actually are very\nrobust to the noise as well.",
    "start": "456840",
    "end": "462790"
  },
  {
    "text": "And so given an\ninstance matching, we are going to register\nthe different point clouds of each\nobject, and then we're",
    "start": "462790",
    "end": "470143"
  },
  {
    "text": "going to reconstruct it\nreconstructed in order to get over time a more complete\nin geometry and accuracy",
    "start": "470143",
    "end": "477550"
  },
  {
    "text": "point cloud of that\nparticular or mesh of that particular\nobject instance.",
    "start": "477550",
    "end": "482590"
  },
  {
    "text": "Now, the cool part\nof this work is that we have one\nrepresentation that is able to solve all three tasks\nby utilizing different embedding",
    "start": "482590",
    "end": "490390"
  },
  {
    "text": "spaces, and I will\ncomment on that in a bit. It is trained only\non synthetic data. So for those that are\nfamiliar with CAD models",
    "start": "490390",
    "end": "497530"
  },
  {
    "text": "and with the ShapeNet database,\nwe only use that for training. And we evaluated 0 shot on\na real world noisy data set.",
    "start": "497530",
    "end": "504910"
  },
  {
    "text": "And beyond of what\nit sees, it is also able to reconstruct unseen\nparts of those objects by having essentially\ndoing shape completion,",
    "start": "504910",
    "end": "512390"
  },
  {
    "text": "by understanding\ngeometric priors of those particular categories. So behind everything, as I\nsaid, is this one representation",
    "start": "512390",
    "end": "519760"
  },
  {
    "text": "that solves all tasks. And we're talking about\na vector neuron encoder where it gives us an equivariant\nand invariant feature space.",
    "start": "519760",
    "end": "527270"
  },
  {
    "text": "And afterwards, we\nhave a BSDF encoder that actually gives\nus this ability to perform shape completion.",
    "start": "527270",
    "end": "533240"
  },
  {
    "text": "We are category\nagnostic, which means we don't need to know if\nit's a chair or a table or another object\nwithin the scene,",
    "start": "533240",
    "end": "540360"
  },
  {
    "text": "but we are training on a\ntotal of seven categories from ShapeNet.",
    "start": "540360",
    "end": "546350"
  },
  {
    "text": "And the interesting part\nof the two embedding space, the equivariant and invariant,\nis that the equivariant",
    "start": "546350",
    "end": "552452"
  },
  {
    "text": "can give us information\nabout the pose of the objects in the scene, and the invariant\nabout the actual geometry and shape of it.",
    "start": "552452",
    "end": "558060"
  },
  {
    "text": "And if we utilize them\nin different manners, we are able to solve all\nof this task, the matching,",
    "start": "558060",
    "end": "563959"
  },
  {
    "text": "the reconstruction,\nthe registration, and reconstruction. Here you can see some\nqualitative results",
    "start": "563960",
    "end": "570620"
  },
  {
    "text": "on the synthetic data set\nwhere we have stage 1, stage 2, stage 3, stage 4. You can see at the top,\nthe input point clouds.",
    "start": "570620",
    "end": "577670"
  },
  {
    "text": "And at the bottom,\nthe reconstruction of the objects after doing\nthe accumulated Living",
    "start": "577670",
    "end": "583910"
  },
  {
    "text": "Scenes method. You see here, for\nexample, you can see with the orange\nwe track the chair. With the red we track the table.",
    "start": "583910",
    "end": "591080"
  },
  {
    "text": "And you see also how they\nlook quite completed when you look at the reconstruction.",
    "start": "591080",
    "end": "597350"
  },
  {
    "text": "As I said, we also\nevaluate zero-shot on a real world data set. It is the 3R scan data set.",
    "start": "597350",
    "end": "603420"
  },
  {
    "text": "Particular data set has\nmany reconstructed scenes that have been visited multiple\ntimes throughout their use",
    "start": "603420",
    "end": "610790"
  },
  {
    "text": "from humans. And they include essentially\nthese temporal changes. Here are some\nqualitative results",
    "start": "610790",
    "end": "617360"
  },
  {
    "text": "where this is temporal\ntime 1, 2, and 3. You can see that we have\nobjects moving around or even",
    "start": "617360",
    "end": "623180"
  },
  {
    "text": "being removed from the scene. And here is what the baseline\nand ours are able to perform.",
    "start": "623180",
    "end": "628319"
  },
  {
    "text": "And you see how we\nare actually getting very close to representing the\ngeometry and the completion",
    "start": "628320",
    "end": "634250"
  },
  {
    "text": "of the object. Here is another example at\nthree different temporal points. And again, we\noutperform the baseline.",
    "start": "634250",
    "end": "640680"
  },
  {
    "text": " One would say, well, what is the\nbenefit of accumulation You tell",
    "start": "640680",
    "end": "646730"
  },
  {
    "text": "us that is actually able to do. Probably better in completeness\nand accuracy, but is it true?",
    "start": "646730",
    "end": "651940"
  },
  {
    "text": "And Yes, it is. We performed an experiment where\nwe have different point clouds from different viewpoints\nevery time of the same object.",
    "start": "651940",
    "end": "659200"
  },
  {
    "text": "And the more you\nsee of that object, the more you are able to\nreconstruct its geometry and its completeness.",
    "start": "659200",
    "end": "664930"
  },
  {
    "text": "And actually, we're able to\nminimize registration error and maximize\nreconstruction accuracy",
    "start": "664930",
    "end": "669960"
  },
  {
    "text": "by having these\nmultiple viewpoints from different temporal times. ",
    "start": "669960",
    "end": "676740"
  },
  {
    "text": "Now, this was about\nthe geometry based way to have this evolving\ninternal representation.",
    "start": "676740",
    "end": "683670"
  },
  {
    "text": "So the second one is\nabout scene graphs. Maybe some of you are familiar\nwith this representation, but I will explain\nit in a second.",
    "start": "683670",
    "end": "689620"
  },
  {
    "text": "This is a work done\nby my student Sayan. It was submitted in\nICCVV which was it?",
    "start": "689620",
    "end": "697260"
  },
  {
    "text": "2023. OK, thanks. So when we build a\nmap, we can actually",
    "start": "697260",
    "end": "703710"
  },
  {
    "text": "do it in a low\nlevel manner, which means we're going to\nhave a representations such as occupancy maps, voxel\ngrids, octomaps, hash grids, et",
    "start": "703710",
    "end": "710250"
  },
  {
    "text": "cetera, point clouds, and\ndifferent other representations. However, there are\nsome issues with those.",
    "start": "710250",
    "end": "715930"
  },
  {
    "text": "The decision making takes place\non the metric space, which means directly on one centimeter\nto the left we have a chair,",
    "start": "715930",
    "end": "721690"
  },
  {
    "text": "and we expect in\nanother scene if we're going to generalize\nthe chair to be 1 centimeter from\nto the left, which",
    "start": "721690",
    "end": "728050"
  },
  {
    "text": "means that the semantic\nlabels are attached directly on the geometry on the voxels. And that limits a higher\nlevel understanding",
    "start": "728050",
    "end": "734702"
  },
  {
    "text": "that it has been shown\nin certain robotic works that it actually minimizes\nthe generalization to variance in scenes,\nbecause again, you are looking",
    "start": "734702",
    "end": "741880"
  },
  {
    "text": "into the centimeters\ninstead of that object is usually found\nnext to that object.",
    "start": "741880",
    "end": "747220"
  },
  {
    "text": "On the other hand, if you go\nbuilding a map in a higher level, you can use 3D scene\ngraphs where essentially you can",
    "start": "747220",
    "end": "755020"
  },
  {
    "text": "have both high level and\nlow level information, which means you can still have\nyour voxels if you want them.",
    "start": "755020",
    "end": "760330"
  },
  {
    "text": "And it allows for decision\nmaking on a more abstract space on the semantic space.",
    "start": "760330",
    "end": "765750"
  },
  {
    "text": "It is lightweight and it\nis privacy preserving. Good.",
    "start": "765750",
    "end": "771610"
  },
  {
    "text": "Now, 3D graphs are used a lot\nand increasingly in agents",
    "start": "771610",
    "end": "777250"
  },
  {
    "text": "in order to either to build them\non the fly to perform robotic navigation or task completion.",
    "start": "777250",
    "end": "783290"
  },
  {
    "text": "And there are several works\nthat utilize scene graphs, which means it is actually\na representation that a lot of robotics\nagents are already",
    "start": "783290",
    "end": "790240"
  },
  {
    "text": "benefiting from and using. And you can also predict them\nin an online incremental manner",
    "start": "790240",
    "end": "795640"
  },
  {
    "text": "or in an offline manner. If you want it. So our goal here is, can we\nleverage the information that",
    "start": "795640",
    "end": "801580"
  },
  {
    "text": "the buildings are the\nagents are already building in the background in\norder to create 3D maps of the environments?",
    "start": "801580",
    "end": "807560"
  },
  {
    "text": "And we are talking about\nmaps that are either-- we have seen observations\nfrom one or multiple agents.",
    "start": "807560",
    "end": "813589"
  },
  {
    "text": "We have static or\nchanged scenes. And we have overlaps\nof 0 to partial to full between all of the scenes.",
    "start": "813590",
    "end": "819530"
  },
  {
    "text": "And we are able to\nrobustly identify how to stitch the maps together. ",
    "start": "819530",
    "end": "826190"
  },
  {
    "text": "Here is how SG alignment works. So here the point cloud but\nexactly the input to our scene",
    "start": "826190",
    "end": "832069"
  },
  {
    "text": "is a scene graph. In this case, it's a very\nabstracted and rudimentary scene graph for the purposes\nof visualization,",
    "start": "832070",
    "end": "838348"
  },
  {
    "text": "because otherwise it's\na very complex graph to show on a screen. And you can see here\nthat these two actually",
    "start": "838348",
    "end": "844730"
  },
  {
    "text": "point clouds have some overlap\nbetween them, very little. Actually, it must be only the\nchair in this particular case.",
    "start": "844730",
    "end": "850769"
  },
  {
    "text": "And we want to stitch\nthose two together. So the SGAligner\nwill take the graphs.",
    "start": "850770",
    "end": "855870"
  },
  {
    "text": "It will essentially\nperform node matching in order to identify\nhow these two graphs are aligning together.",
    "start": "855870",
    "end": "861870"
  },
  {
    "text": "And that is a great\ninitialization to perform a task such as point\ncloud registration or point cloud mosaicing.",
    "start": "861870",
    "end": "869000"
  },
  {
    "text": "Why do we want to do\nthat, and why don't we just use existing methods\nfor point cloud registration?",
    "start": "869000",
    "end": "875040"
  },
  {
    "text": "The issue with them\nis that they are focusing a lot on local\nfeature descriptors. And so if there are changes in\nthe scene or very low overlap,",
    "start": "875040",
    "end": "882240"
  },
  {
    "text": "they are going to\nhave issues with being able to perform the alignment. They are not as robust\nto point cloud density",
    "start": "882240",
    "end": "888860"
  },
  {
    "text": "to the spatial extent of the\noverlap and of the entire scene. Though, it's a very\nlarge scene, they're going to have issues being able\nto compute all that in a pass",
    "start": "888860",
    "end": "897380"
  },
  {
    "text": "forward. They are not, as I\nsaid, robust to change. They assume that you\nhave partial overlap",
    "start": "897380",
    "end": "902630"
  },
  {
    "text": "between your scenes. And so if you have\nno overlap, they fail understand that, et cetera.",
    "start": "902630",
    "end": "908150"
  },
  {
    "text": "Now, we form this SGAligner,\nthe alignment of scene graphs, as seeing them as\nmultimodal knowledge graphs,",
    "start": "908150",
    "end": "916650"
  },
  {
    "text": "because they have three types\nof information within them the scene graphs,\nsemantic entities",
    "start": "916650",
    "end": "921980"
  },
  {
    "text": "in the scene, which means\nthe object instances. You have attributes for them,\nsuch as the category, the size,",
    "start": "921980",
    "end": "928200"
  },
  {
    "text": "maybe the material\nof the object. And you also know relationships\nbetween these entities, such as the relative position\nor some kind of attribute",
    "start": "928200",
    "end": "935420"
  },
  {
    "text": "similarity and more. And so we can redesign\nentity alignment methods",
    "start": "935420",
    "end": "941210"
  },
  {
    "text": "from the multimodal\nknowledge graph domain into our setting, which is to\nalign spatial maps together.",
    "start": "941210",
    "end": "950040"
  },
  {
    "text": "Looking into multimodal\nknowledge graph alignment, their goal is to align\nmultiple knowledge graphs that represent\ninformation with different input",
    "start": "950040",
    "end": "957720"
  },
  {
    "text": "modalities. So we're talking about\ntext, images, video, whatever else you have, and\nintegrate all these knowledge",
    "start": "957720",
    "end": "963450"
  },
  {
    "text": "from different sources in\norder to create this better understanding and\ncumulative understanding of your space of the world.",
    "start": "963450",
    "end": "970360"
  },
  {
    "text": "However, please note that all\nthe works that look into entity alignment, multimodal\nknowledge graph alignment,",
    "start": "970360",
    "end": "976470"
  },
  {
    "text": "consider that their inputs are\noverlapping in information, and all the information they\nhave within them it is actually",
    "start": "976470",
    "end": "983280"
  },
  {
    "text": "true, which is not the case when\nyou're looking into using 3D scene graphs that the agents are\nbuilding on the fly because you",
    "start": "983280",
    "end": "990029"
  },
  {
    "text": "cannot assume that they\nalways will be overlap. And in addition to\nthat, they're going to have scenes that are\npredicted scene graph.",
    "start": "990030",
    "end": "995350"
  },
  {
    "text": "It's going to have errors. So we cannot assume that\nwe have perfect input.",
    "start": "995350",
    "end": "1000500"
  },
  {
    "text": "In more details. this is how\nSGAligner looks like. So given the 3D scene\ngraphs as an input,",
    "start": "1000500",
    "end": "1006790"
  },
  {
    "text": "we have unimodal embeddings\nthat's going to take each of the modality information\nseparately to encode it.",
    "start": "1006790",
    "end": "1013150"
  },
  {
    "text": "And so we have\npoint cloud encoders that's going to understand\nmore about the shape and the category. We're going to have\nstructure encoders that",
    "start": "1013150",
    "end": "1020190"
  },
  {
    "text": "is going to look into\nthe layout of objects and their in-between\nrelationships. And then we're going to have\nsome meta encoders that encode",
    "start": "1020190",
    "end": "1026670"
  },
  {
    "text": "attributes or relative\nrelationships between objects. And all of these are going to\ninteract in a joint embedding",
    "start": "1026670",
    "end": "1032400"
  },
  {
    "text": "space where we want to be seeing\nthe same object instance to come closer together and object\ninstances that are not",
    "start": "1032400",
    "end": "1038640"
  },
  {
    "text": "the same to be further apart. And then with that information,\nwe can align the 3D scene graphs",
    "start": "1038640",
    "end": "1044520"
  },
  {
    "text": "and be able to perform\ntasks such as 3D point cloud registration. We used, again, the 3RScan\ndata set I explained before,",
    "start": "1044520",
    "end": "1052540"
  },
  {
    "text": "as well as its extension, the\n3DSSG which provides 3D scene graphs for each of\nthose change scenes.",
    "start": "1052540",
    "end": "1060330"
  },
  {
    "text": "The very first task that\nwe evaluated with the liner is, can we actually\nmatch nodes together.",
    "start": "1060330",
    "end": "1066803"
  },
  {
    "text": "And I don't want you to focus\non specifically the numbers, but let me tell you that\nregardless of whether you use ground truth information\nor predicted scene graph",
    "start": "1066803",
    "end": "1074400"
  },
  {
    "text": "information, you're actually\ndoing very robustly. So we have very small\ndecrease in our numbers,",
    "start": "1074400",
    "end": "1081669"
  },
  {
    "text": "in our performance, if we\nuse predicted scene graphs. In addition, in varying\noverlap conditions,",
    "start": "1081670",
    "end": "1087850"
  },
  {
    "text": "especially in the very low\noverlap region of 10% to 30% of spatial overlap\nof point clouds,",
    "start": "1087850",
    "end": "1093549"
  },
  {
    "text": "we're actually seeing that we\nare extremely robust as well, something that usual 3D point\ncloud registration methods fail",
    "start": "1093550",
    "end": "1098820"
  },
  {
    "text": "to achieve. And finally, even if you\nhave temporal changes within your scene\ngraphs, you are still",
    "start": "1098820",
    "end": "1104580"
  },
  {
    "text": "able to perform very, very\nwell in the alignment. And again, this\nis node matching.",
    "start": "1104580",
    "end": "1110169"
  },
  {
    "text": "Can we match two nodes\ntogether with the one that it's supposed\nto be matched with? Looking into 3D scene graph\nalignment we want to see OK,",
    "start": "1110170",
    "end": "1118300"
  },
  {
    "text": "we matched some notes. Can we still be able to figure\nout whether these align together and how they're aligning?",
    "start": "1118300",
    "end": "1125390"
  },
  {
    "text": "And again, the answer\nis yes, we can do that. And in this particular\nscenario, we consider if the top\ntwo matched nodes,",
    "start": "1125390",
    "end": "1133170"
  },
  {
    "text": "the 50% of the nodes matched\nor all nodes matched, what is the performance? And we get the best one\nwhen at least two nodes",
    "start": "1133170",
    "end": "1139520"
  },
  {
    "text": "are matched for this\nparticular scene graphs. ",
    "start": "1139520",
    "end": "1145100"
  },
  {
    "text": "And now we use this information\nin order to perform 3D point cloud registration. And in contrast to\nprevious approaches,",
    "start": "1145100",
    "end": "1151100"
  },
  {
    "text": "to common approaches where\nthey take the two point clouds, imagine that the red triangle\nis one scene point cloud.",
    "start": "1151100",
    "end": "1158353"
  },
  {
    "text": "The green triangle is another\nscene point cloud that have some overlap between them. And they're going to process\nthem to get local features,",
    "start": "1158353",
    "end": "1164580"
  },
  {
    "text": "get some kind of\nembedding information, use RANSAC with the ICP,\nand be able to perform",
    "start": "1164580",
    "end": "1170600"
  },
  {
    "text": "the final geometric\nalignment between them. In our particular\nscenario, since we",
    "start": "1170600",
    "end": "1176630"
  },
  {
    "text": "know which object instances\nare matched with the others, and hopefully\ncorrectly, we are going",
    "start": "1176630",
    "end": "1183559"
  },
  {
    "text": "to calculate the registration\nbetween object instances. So we're essentially\nregistering object instances",
    "start": "1183560",
    "end": "1189590"
  },
  {
    "text": "instead of entire scenes. And once we are able to\nregister each individual object",
    "start": "1189590",
    "end": "1194870"
  },
  {
    "text": "instance together, we're going\nto utilize this information in order to align the entire\nscene in a more robust way",
    "start": "1194870",
    "end": "1200000"
  },
  {
    "text": "and actually in a faster way. And so, again, without\nfocusing in the large table,",
    "start": "1200000",
    "end": "1205409"
  },
  {
    "text": "I'm going to tell you that we\nhave 49% improvement in chamfer distance as standard\nreconstruction registration metric and about 40% improvement\nin relative translation error.",
    "start": "1205410",
    "end": "1215059"
  },
  {
    "text": "And we have even higher gains\nwith respect to other methods if we look at noisy point\ncloud predictions, which",
    "start": "1215060",
    "end": "1223400"
  },
  {
    "text": "again is the realistic\nscenario to consider. Also, in varying overlap,\nwe're doing very well.",
    "start": "1223400",
    "end": "1229890"
  },
  {
    "text": "So in cases of 10%\nto 30% low overlap, we're still able to handle with\nvery good results the task.",
    "start": "1229890",
    "end": "1240500"
  },
  {
    "text": "The final thing that\nwe tried is what I mentioned at the very\nbeginning of this work, where I said, we\ncan have scenes that",
    "start": "1240500",
    "end": "1247280"
  },
  {
    "text": "are overlapping from\n0 to partial to fully. And why fully?",
    "start": "1247280",
    "end": "1252750"
  },
  {
    "text": "Because sometimes if you\nhave temporal changes or if you capture your\nscene, even if it's the same and nothing has\nchanged over time,",
    "start": "1252750",
    "end": "1258600"
  },
  {
    "text": "you may capture a\nsmaller part of it. So maybe you have full overlap\nwith the previous scene. However, in the 0 case\nscenario, zero overlap,",
    "start": "1258600",
    "end": "1266040"
  },
  {
    "text": "it means that you might\nhave in your folder a bunch of different\npoint clouds that you don't know how\nto stitch them together.",
    "start": "1266040",
    "end": "1271920"
  },
  {
    "text": "And previous methods\nare not able to perform that robustly in understanding\ndoes these two overlap point",
    "start": "1271920",
    "end": "1278210"
  },
  {
    "text": "clouds overlap or not. And actually, in our case, we\ncan very well understand that three times faster\nthan prior art, which",
    "start": "1278210",
    "end": "1285470"
  },
  {
    "text": "when you have a robotics\nplatform going around, you won't to do that\nas fast as possible,",
    "start": "1285470",
    "end": "1291180"
  },
  {
    "text": "and we're able to\nidentify the overlapping pairs more correctly.",
    "start": "1291180",
    "end": "1296400"
  },
  {
    "text": "Now, I told you about the\ngeometry-based alignments, I told you about the scene\ngraph-based alignments,",
    "start": "1296400",
    "end": "1303720"
  },
  {
    "text": "but all of them\nlook at a scene that evolves with minimal\nchanges in geometry.",
    "start": "1303720",
    "end": "1309280"
  },
  {
    "text": "What I mean by that we just have\nsome furniture being relocated or something being added\nor removed from the scene.",
    "start": "1309280",
    "end": "1316659"
  },
  {
    "text": "But what happens when there\nare more drastic changes in the scene?",
    "start": "1316660",
    "end": "1321720"
  },
  {
    "text": "And I will talk about\nour work, Nothing Stands Still, that my student\nTao Sun has performed.",
    "start": "1321720",
    "end": "1327630"
  },
  {
    "text": "Now we're talking about\nspatiotemporal 3D point cloud registration. This particular case\nwhere essentially we",
    "start": "1327630",
    "end": "1333780"
  },
  {
    "text": "want to be able to find\npairwise correspondences from the static parts of\nthe scene and hopefully exclude the temporal\nchanges because they're not",
    "start": "1333780",
    "end": "1340680"
  },
  {
    "text": "going to help us to align\nthe geometries together. Now, looking into prior work,\nyou're going to see that",
    "start": "1340680",
    "end": "1346470"
  },
  {
    "text": "in terms of spatial temporal\n3D point cloud data sets, we are looking into data sets\nthat have very small scale",
    "start": "1346470",
    "end": "1353550"
  },
  {
    "text": "scenes, maybe be up to a room\nthat the change type is that of the relocation, addition,\nor removal of furniture from",
    "start": "1353550",
    "end": "1360899"
  },
  {
    "text": "the scene. And also they capture just\nstandard daily human interaction activities with the relocation\nof objects, which is fine.",
    "start": "1360900",
    "end": "1369160"
  },
  {
    "text": "However, it doesn't capture\nthe drastic changes. And if we look at methods\nthat do 3D point cloud spatial",
    "start": "1369160",
    "end": "1374730"
  },
  {
    "text": "temporal registration, they\nare only able to handle small changes in the\ngeometry of the scene,",
    "start": "1374730",
    "end": "1380380"
  },
  {
    "text": "such as you would find in\nself-driving car scenarios where most of the scene is static.",
    "start": "1380380",
    "end": "1386240"
  },
  {
    "text": "Like, the buildings are there. The road is there. It will not change the\nnext couple of seconds, and you're going to capture\nyour next point cloud.",
    "start": "1386240",
    "end": "1391480"
  },
  {
    "text": "The only thing that would have\nmoved is a car in front of you, a bicyclist maybe appears,\nor a pedestrian disappears.",
    "start": "1391480",
    "end": "1398400"
  },
  {
    "text": "OK, so can existing methods\nperform robustly on environments that underwent large changes?",
    "start": "1398400",
    "end": "1406090"
  },
  {
    "text": "And can any of you tell me\nof one particular scenario where we do encounter\nlarge, drastic changes",
    "start": "1406090",
    "end": "1413620"
  },
  {
    "text": "in the world in a small\namount of time relatively?",
    "start": "1413620",
    "end": "1418990"
  },
  {
    "text": "Anyway, maybe my\nbackground might or the department\nI belong to might",
    "start": "1418990",
    "end": "1424450"
  },
  {
    "text": "be able to give you a hint. Yes. Construction sites. Yes, construction sites.",
    "start": "1424450",
    "end": "1430930"
  },
  {
    "text": "Perfect. OK. Here you can see a\nconstruction site where in a very\nshort amount of time,",
    "start": "1430930",
    "end": "1436280"
  },
  {
    "text": "you're going to\nhave things added. The geometry is going to change. The appearance is\ngoing to change. The topology is going\nto change and not",
    "start": "1436280",
    "end": "1442630"
  },
  {
    "text": "only very local in the\nscene, but the entire scene is going to have that. And so that is why we\ncreated Nothing Stands Still,",
    "start": "1442630",
    "end": "1449540"
  },
  {
    "text": "which more than\nanything at this point is a benchmark about giving\nthis new data set to the world",
    "start": "1449540",
    "end": "1454923"
  },
  {
    "text": "and benchmarking existing\nspatiotemporal point cloud registration methods to see\nand answer the question,",
    "start": "1454923",
    "end": "1460100"
  },
  {
    "text": "can existing methods be\nable to perform this task on these particular scenes?",
    "start": "1460100",
    "end": "1466809"
  },
  {
    "text": "And so we collected data from\ndifferent construction sites over time where we went\nwith a tripod-based device",
    "start": "1466810",
    "end": "1472909"
  },
  {
    "text": "in order to collect the\nscene at one temporal point. And then we were talking\nto the contractor,",
    "start": "1472910",
    "end": "1478860"
  },
  {
    "text": "where should we go again? We want to capture\ninformation before it gets hidden behind\nsurfaces such as we",
    "start": "1478860",
    "end": "1484010"
  },
  {
    "text": "would like to know the\npipes behind this wall surface over here. And then we capture\nmore and more.",
    "start": "1484010",
    "end": "1489150"
  },
  {
    "text": "And we have all these little red\ndots and all these little scenes that we want somehow to align\nspatial temporally together.",
    "start": "1489150",
    "end": "1496250"
  },
  {
    "text": "And this becomes easier as\nis a more trivial problem, to be able to align\nthings if we put them in the same coordinate\nsystem like to understand",
    "start": "1496250",
    "end": "1503110"
  },
  {
    "text": "what has changed. But it's not very\neasy to perform because we're talking\nabout these very large changes in the scenes.",
    "start": "1503110",
    "end": "1510260"
  },
  {
    "text": "And we have areas that\nare inconsistently captured over time. Some parts may be inaccessible\nfor us, et cetera.",
    "start": "1510260",
    "end": "1516000"
  },
  {
    "text": "And so there are\nseveral difficulties to make that happen. And this is the benchmark\nthat we created,",
    "start": "1516000",
    "end": "1521940"
  },
  {
    "text": "where essentially\nwe're going to be able to evaluate on both\npairwise registration and multiway\nregistration of the scene",
    "start": "1521940",
    "end": "1528679"
  },
  {
    "text": "because we're talking\nabout very large scenes. And in order to do that,\nwe capture, as I said,",
    "start": "1528680",
    "end": "1534090"
  },
  {
    "text": "a data set of our six\nconstruction sites over several months. And particularly we focused on\ninterior layout construction.",
    "start": "1534090",
    "end": "1540390"
  },
  {
    "text": "So you're not going to find\na foundation or excavators at this particular data set\nright now, maybe in the future.",
    "start": "1540390",
    "end": "1546380"
  },
  {
    "text": "So essentially,\nwe have the slabs. We have the ceilings. We have the walls outside. We're just inside of a big empty\nspace that we want to fill.",
    "start": "1546380",
    "end": "1554720"
  },
  {
    "text": "Here are some snapshots of\nhow the interiors look like. So you start with\na big empty space,",
    "start": "1554720",
    "end": "1560240"
  },
  {
    "text": "and you start adding\nall the little walls. You start insulations,\npipes, air ducts, materials are all\nhovering around.",
    "start": "1560240",
    "end": "1566640"
  },
  {
    "text": "And you want to be able, given\nthis very drastically changed environments to perform the\nspatiotemporal registration.",
    "start": "1566640",
    "end": "1574049"
  },
  {
    "text": "What is also very challenging\nin this size is that in addition to have drastic changes, they\nhave very repetitive elements",
    "start": "1574050",
    "end": "1582049"
  },
  {
    "text": "that look similar to each other. So we have the\nlittle studs that are going to be inside your\nwall, like essentially",
    "start": "1582050",
    "end": "1587929"
  },
  {
    "text": "some kind of vertical little\nstructural columns almost, that are going to be one next to\neach other and maybe some inches",
    "start": "1587930",
    "end": "1595380"
  },
  {
    "text": "apart. So when as a\nregistration algorithm, you're trying to match\nthese things together, you don't know which\nstud corresponds",
    "start": "1595380",
    "end": "1601860"
  },
  {
    "text": "to which stud because\nthey all look the same. Also, appearance-wise we are\ntalking about a very uniform looking environment.",
    "start": "1601860",
    "end": "1607750"
  },
  {
    "text": "Most of it is gray or brown. Very little is standing out. So how can you perform this\ntask in a robust manner?",
    "start": "1607750",
    "end": "1615810"
  },
  {
    "text": "Here are some more visuals\nof this particular data set that you can see we\nmaybe, for example,",
    "start": "1615810",
    "end": "1621660"
  },
  {
    "text": "over here In the blue case\nwe have the interior layout getting constructed.",
    "start": "1621660",
    "end": "1627669"
  },
  {
    "text": "And as we go to\nthe yellow phase, we see that everything\nis being done and even the static furniture is\nbeing built and nicely finished.",
    "start": "1627670",
    "end": "1635350"
  },
  {
    "text": "And in the other case, we\nstart from almost nothing to actually having the\nfinal static furniture.",
    "start": "1635350",
    "end": "1641160"
  },
  {
    "text": "Here are some explorations of\nthe meshes in virtual reality where you can see how\nspaces change over time,",
    "start": "1641160",
    "end": "1649130"
  },
  {
    "text": "and you can maybe\nunderstand a bit more the complexity of these scenes. ",
    "start": "1649130",
    "end": "1655120"
  },
  {
    "text": "And so we performed\npairwise registration where we evaluated\nexisting methods in a way",
    "start": "1655120",
    "end": "1660220"
  },
  {
    "text": "that you can see on the screen. Essentially those methods\nusually take two small point clouds as an input that\nhave some spatial overlap.",
    "start": "1660220",
    "end": "1667250"
  },
  {
    "text": "And you perform\ncorrespondence estimation and then RANSAC maybe\nsome ICP at the end",
    "start": "1667250",
    "end": "1672730"
  },
  {
    "text": "in order to perform\nthe final pose, understand the final\ntransformation between them.",
    "start": "1672730",
    "end": "1678070"
  },
  {
    "text": "And then we also evaluated\non multiway registration, where essentially we're\ntalking about having a pose graph of all\nthe little point",
    "start": "1678070",
    "end": "1684700"
  },
  {
    "text": "clouds over space and time. And we are going to connect them\nwith edges as long as we have a pairwise registration\nresult. And we're",
    "start": "1684700",
    "end": "1692200"
  },
  {
    "text": "going to try to minimize\nthe weighted RMC of the poses of the pose graph.",
    "start": "1692200",
    "end": "1700750"
  },
  {
    "text": "I'm not going to bore\nyou with results. I'm going to tell you\nthat almost no method today can actually handle that.",
    "start": "1700750",
    "end": "1705770"
  },
  {
    "text": "We've developed recently\none that is doing better, but I don't include the\nresults here for that.",
    "start": "1705770",
    "end": "1711910"
  },
  {
    "text": "I want to show you\njust what happens before and after\nmultiway registration for the best performing\nalgorithm at the time",
    "start": "1711910",
    "end": "1717740"
  },
  {
    "text": "we benchmarked everything. And you can see that\nbefore multiway, everything is a little bit of a blur.",
    "start": "1717740",
    "end": "1723470"
  },
  {
    "text": "And after multiway,\nwe can actually start seeing the shaft\nover here in the building where usually pipes and\nelevators go through",
    "start": "1723470",
    "end": "1729520"
  },
  {
    "text": "and a little bit\nbetter organization but still a lot of failures. FYI, color is being\ndifferent temporal points.",
    "start": "1729520",
    "end": "1735649"
  },
  {
    "text": "So whatever cyan is one\ntemporal point versus another. Yellow is another, cetera. So bottom line, we\nneed better algorithms",
    "start": "1735650",
    "end": "1742300"
  },
  {
    "text": "to perform this kind\nof tasks and understand the large, drastic changes\nin the environment.",
    "start": "1742300",
    "end": "1747880"
  },
  {
    "text": "And our assumption\nhypothesis is that if we're able to solve this\nvery hard problem, we can solve everything\nelse as well.",
    "start": "1747880",
    "end": "1753650"
  },
  {
    "text": "So more people should\nstart working on this and use our data set. To conclude, we talked about\nhow to go from static to living",
    "start": "1753650",
    "end": "1762580"
  },
  {
    "text": "scenes and create and update\nthe representations of evolving indoor scenes. And I want to show\na few applications.",
    "start": "1762580",
    "end": "1770258"
  },
  {
    "text": "Is there anyone here from civil\nand environmental engineering apart from my students. OK. One person.",
    "start": "1770258",
    "end": "1775760"
  },
  {
    "text": "Fair enough. The rest might be for\nyou this last slide. But I want to motivate\nyou a little bit more",
    "start": "1775760",
    "end": "1781830"
  },
  {
    "text": "why it's important to focus\non the building industry and why we are working\non these problems.",
    "start": "1781830",
    "end": "1787350"
  },
  {
    "text": "First of all, renovation is a\nbig scope in the architecture, engineering, and\nconstruction industry right now because we want\nto increase sustainability",
    "start": "1787350",
    "end": "1795350"
  },
  {
    "text": "and create a circular\nbuilt environment where we can reuse material\nfrom other buildings that are being demolished to new\nbuildings that we are designing.",
    "start": "1795350",
    "end": "1802530"
  },
  {
    "text": "We need to be able to extend\nthe life of an existing building in order to not demolish\nit as fast as we would.",
    "start": "1802530",
    "end": "1809130"
  },
  {
    "text": "And essentially, we are trying\nto utilize existing resources without depleting new\nresources from the planet.",
    "start": "1809130",
    "end": "1815690"
  },
  {
    "text": "In addition, why do we need\nto get this representation for evolving environments\nis because for most",
    "start": "1815690",
    "end": "1821240"
  },
  {
    "text": "of our buildings, we do not\nhave any digital information. Actually CAD, essentially\nComputer Aided Design software",
    "start": "1821240",
    "end": "1828800"
  },
  {
    "text": "that is used usually\nby architects, to design new buildings became\nmore widespread after 1980s.",
    "start": "1828800",
    "end": "1834330"
  },
  {
    "text": "And maybe for your\nage, it's too old. It's like centuries\nago for you guys. However, only a few\nbuildings, a few hundreds",
    "start": "1834330",
    "end": "1842672"
  },
  {
    "text": "or maybe thousands of buildings\nhave been built since then. We have billions of buildings\non Earth that date before",
    "start": "1842672",
    "end": "1847700"
  },
  {
    "text": "the 1980s. So how can we acquire this and\nkeep updating the representation over time?",
    "start": "1847700",
    "end": "1853639"
  },
  {
    "text": "In addition, construction\nindustry is extremely painfully",
    "start": "1853640",
    "end": "1859040"
  },
  {
    "text": "expensive, and that is why we\ncannot perform good estimations about how much it costs because\nwe actually do not know what",
    "start": "1859040",
    "end": "1865790"
  },
  {
    "text": "we're building, and everything\nis a very visual estimate of what's going on. We have 50% of construction\ncost to be increased",
    "start": "1865790",
    "end": "1874010"
  },
  {
    "text": "to be accounted for rework. So essentially of\neverything you have to pay on top of the\nestimate, the first estimate,",
    "start": "1874010",
    "end": "1880320"
  },
  {
    "text": "the initial estimate\nof your work is because you didn't\nbuild something correctly and you need to change it.",
    "start": "1880320",
    "end": "1886330"
  },
  {
    "text": "I also want to mention that\nconstruction workers accounted for 20% of all occupational\nfatalities in 2020 in the US.",
    "start": "1886330",
    "end": "1894260"
  },
  {
    "text": "And we're talking about 1,000\npeople not injured that really",
    "start": "1894260",
    "end": "1900610"
  },
  {
    "text": "were killed in construction\nsites because of something that went wrong. And lastly, 90% of non-hazardous\nconstruction and demolition",
    "start": "1900610",
    "end": "1909910"
  },
  {
    "text": "material is either\nreusable or recyclable. However, these days it\njust dropped into landfill.",
    "start": "1909910",
    "end": "1916960"
  },
  {
    "text": "So I want to stress\nthat out to motivate you to work on these\nkind of problems because understanding\nspatial temporal information",
    "start": "1916960",
    "end": "1923980"
  },
  {
    "text": "can have a big\nimpact on human life and on planet sustainability. So if you want to work on\nthese kind of problems,",
    "start": "1923980",
    "end": "1929600"
  },
  {
    "text": "feel free to send me an email\nand I'm happy to work with you. And that is that. I'm happy to take any questions.",
    "start": "1929600",
    "end": "1935180"
  },
  {
    "text": "[APPLAUSE] ",
    "start": "1935180",
    "end": "1940929"
  },
  {
    "text": "Could you please\nelaborate more on examples of how to apply the model\nto improve circular economy",
    "start": "1940930",
    "end": "1949330"
  },
  {
    "text": "and cutting down\nconstruction costs? And also you showed\nan example of how it's being applied in a building\nor at a construction site,",
    "start": "1949330",
    "end": "1957830"
  },
  {
    "text": "but how about potential\napplication scenarios in taking a building down\nif the building is too old.",
    "start": "1957830",
    "end": "1966700"
  },
  {
    "text": "So if you have new\nconstruction, you want to be capturing\nthe information of what",
    "start": "1966700",
    "end": "1972160"
  },
  {
    "text": "exists within it, because then\nyou know exactly what materials exist, where they\nhave been located,",
    "start": "1972160",
    "end": "1978169"
  },
  {
    "text": "how they have been\nconnected with each other in order to know when you're\ngoing to do the demolition,",
    "start": "1978170",
    "end": "1983500"
  },
  {
    "text": "or when you're planning to\ndesign a new building, what already exists that is\nable to be harvested. So what we're trying\nto do with circularity",
    "start": "1983500",
    "end": "1991480"
  },
  {
    "text": "is that we're trying to\nplan ahead and know that at that particular\ntime where we want",
    "start": "1991480",
    "end": "1997150"
  },
  {
    "text": "to create a new building, what\nare potential materials that will be available. Because then you might\nalso know that and that",
    "start": "1997150",
    "end": "2003562"
  },
  {
    "text": "and that building will\nbe demolished or already have been demolished. And so you can harvest\nthese materials.",
    "start": "2003562",
    "end": "2008650"
  },
  {
    "text": "And so you can start designing\nby taking into account those specific materials,\npotentially changing a little bit your\ndesign to be able to use",
    "start": "2008650",
    "end": "2015240"
  },
  {
    "text": "those materials as your\nprimary source of structure.",
    "start": "2015240",
    "end": "2021809"
  },
  {
    "text": "Now, in addition, to\nbe able to understand what is a new construction and\nhow things are being placed,",
    "start": "2021810",
    "end": "2026919"
  },
  {
    "text": "you also want to know\nhow things deteriorate and what is the\ncondition of materials. And also for those spaces where\nwe don't have new construction,",
    "start": "2026920",
    "end": "2035530"
  },
  {
    "text": "you want to essentially get\nthe asset status of your space right now. And you want to\nessentially build a map.",
    "start": "2035530",
    "end": "2042930"
  },
  {
    "text": "And you want to also continue\nto be controlling and updating that map with any deterioration\non your materials.",
    "start": "2042930",
    "end": "2051600"
  },
  {
    "text": "For all of these\noperations, you don't only need geometric\ninformation, you also need semantic\ninformation, which is",
    "start": "2051600",
    "end": "2058679"
  },
  {
    "text": "something I didn't touch\ntoo much upon here, maybe a little bit. But we are also working on\nthis kind of work in my lab.",
    "start": "2058679",
    "end": "2067330"
  },
  {
    "text": "So once you have information\nabout where things are and what they are,\nyou can really start planning ahead on\ncreating new buildings",
    "start": "2067330",
    "end": "2075158"
  },
  {
    "text": "in a more sustainable way. And just a follow up question\non your last several points,",
    "start": "2075159",
    "end": "2080830"
  },
  {
    "text": "would you mind being\na bit more specific on the-- so in the\nknowledge graphs, what are the exact relationships\neach edge is representing",
    "start": "2080830",
    "end": "2087610"
  },
  {
    "text": "between entities? Yes, that depends a little bit\non the definition of the scene graph you give for the\ntasks you may be doing.",
    "start": "2087610",
    "end": "2095124"
  },
  {
    "text": "You can have\nvarying information. And in our particular case,\nwe used the object categories.",
    "start": "2095124",
    "end": "2103105"
  },
  {
    "text": "Do you want to say actually\nall the information we used? So the nodes are\nthe objects where",
    "start": "2103105",
    "end": "2108940"
  },
  {
    "text": "you represent the objects\nusing object categories. And the relationships are\nsemantic and geometric",
    "start": "2108940",
    "end": "2115687"
  },
  {
    "text": "relationships. So from a particular\nviewpoint, you can say that both the table\nis, for example, if I'm looking from my viewpoint,\nthe chair you are sitting in",
    "start": "2115687",
    "end": "2123230"
  },
  {
    "text": "is in front of the table. So that's the\nrelationship in front of. So usually these\nrelationships are taken",
    "start": "2123230",
    "end": "2128240"
  },
  {
    "text": "from a particular viewpoint. And just to repeat\nit for those online,",
    "start": "2128240",
    "end": "2133940"
  },
  {
    "text": "essentially object instances\nattributes such as size maybe material, and, of\ncourse, relationships",
    "start": "2133940",
    "end": "2139280"
  },
  {
    "text": "that are relative relationships\nwithin the space such as this is in front of that, to the\nleft of that, on top of that,",
    "start": "2139280",
    "end": "2144850"
  },
  {
    "text": "et cetera. ",
    "start": "2144850",
    "end": "2153560"
  },
  {
    "text": "So thank you for\nthe presentation. So you mentioned about the\nimportance of to avoiding rework",
    "start": "2153560",
    "end": "2160160"
  },
  {
    "text": "in construction. So do we have a sufficient\nmethods to compare like point",
    "start": "2160160",
    "end": "2165680"
  },
  {
    "text": "cloud or 3D scene graph to\nexisting CAD or BIM model? Yes, that is a\nvery good question.",
    "start": "2165680",
    "end": "2172882"
  },
  {
    "text": "There is a reason why I didn't\ntouch upon that are actually working on it these days.",
    "start": "2172882",
    "end": "2177980"
  },
  {
    "text": "Yes and no. And I will tell you why. There are issues with\naligning CAD models",
    "start": "2177980",
    "end": "2183350"
  },
  {
    "text": "or building information models\nwith existing point clouds. I think 3D scene graphs would\nactually be more robust to be",
    "start": "2183350",
    "end": "2190420"
  },
  {
    "text": "able to perform the alignment,\nbut if you were to just do it in a geometric manner on point\nclouds directly, let's say,",
    "start": "2190420",
    "end": "2195530"
  },
  {
    "text": "you can sample points\non your CAD model, there are issues\nof completeness. So your existing\npoint cloud will never",
    "start": "2195530",
    "end": "2202490"
  },
  {
    "text": "be as complete as the one\nyou have in your CAD model. There are issues of scale. Your CAD model is\nnot necessarily",
    "start": "2202490",
    "end": "2208010"
  },
  {
    "text": "the same kind of\nscale of the world as it is in your\nscanned point cloud.",
    "start": "2208010",
    "end": "2213710"
  },
  {
    "text": "And sometimes the\nlevel of detail is very different as well. So usually the\ndesigns that we do",
    "start": "2213710",
    "end": "2220550"
  },
  {
    "text": "are way more abstracted than\nthe actual physical world. So if you take all these\ninto consideration, if you do it just geometrically,\nit usually fails badly.",
    "start": "2220550",
    "end": "2229040"
  },
  {
    "text": "Not too bad but still it\ndoesn't give you an accurate registration to be able to\ntransfer semantic information",
    "start": "2229040",
    "end": "2235039"
  },
  {
    "text": "from your CAD model\nto the point cloud to essentially be able to\nperform the comparison, Is this build or not?",
    "start": "2235040",
    "end": "2240970"
  },
  {
    "text": "Is this the same as\ndesigned or not, et cetera. Particularly, if we're\ntalking about construction,",
    "start": "2240970",
    "end": "2247270"
  },
  {
    "text": "usually we do not have detailed\nbuilding information models or CAD models at every\nconstruction step,",
    "start": "2247270",
    "end": "2253290"
  },
  {
    "text": "or even like with enough\nconstruction details to perform that\nkind of comparison. If you are talking just about at\nthe finished building to compare",
    "start": "2253290",
    "end": "2262890"
  },
  {
    "text": "it with the design of it, I\nthink our method with 3D scene graphs would work\nvery, very well. But knowledge geometric\nmethod wouldn't be",
    "start": "2262890",
    "end": "2269940"
  },
  {
    "text": "able to do very well on that. Thank you. Yeah.",
    "start": "2269940",
    "end": "2275410"
  },
  {
    "text": "Do your models infer any\nphysics from the scene, such as whether something's\nbrittle or whether if it falls,",
    "start": "2275410",
    "end": "2283180"
  },
  {
    "text": "it breaks, things\nalong those lines. Or what are your views on that\ntype of problem in general?",
    "start": "2283180",
    "end": "2288210"
  },
  {
    "text": "Yeah, we do not perform\nany physics here. We assume that the change\nhas already happened,",
    "start": "2288210",
    "end": "2293760"
  },
  {
    "text": "and it doesn't evolve after we\ncapture the scene, which means it reaches final destination.",
    "start": "2293760",
    "end": "2298870"
  },
  {
    "text": "And if it's something\nthat fell, it fell. If you wanted to\ndo that, I suppose you would need to use\na physics simulator.",
    "start": "2298870",
    "end": "2305410"
  },
  {
    "text": "But I would need to\nunderstand better the task that you would be\nreferring to comment in a more appropriate way.",
    "start": "2305410",
    "end": "2313260"
  },
  {
    "text": "There's a question\nand then over there. ",
    "start": "2313260",
    "end": "2319548"
  },
  {
    "text": "As a follow up to that, can\nyou load these scene graphs into Unreal or Unity? ",
    "start": "2319548",
    "end": "2326273"
  },
  {
    "text": "Is that the way\nyou're displaying? No. No? No. It is manually created, right?",
    "start": "2326273",
    "end": "2331930"
  },
  {
    "text": "Yeah. It's a manually created\nscene graph over there. But you mean like once\nyou have the scene graph,",
    "start": "2331930",
    "end": "2338320"
  },
  {
    "text": "if you can load it into Unity? Yeah. I mean, it's a JSON file\nat the end of the day. So I suppose it is.",
    "start": "2338320",
    "end": "2344190"
  },
  {
    "text": "Well, yeah, I figured you\nwould have already done it. So the question is, I guess\nwhat you're saying is why not?",
    "start": "2344190",
    "end": "2351570"
  },
  {
    "text": "Oh, I mean, well, I mean, why\ndo you want to do it in Unity?",
    "start": "2351570",
    "end": "2356890"
  },
  {
    "text": "You meant for the VR part of it? Or let's say you're\ndoing simulations. I'll follow up on his question.",
    "start": "2356890",
    "end": "2362350"
  },
  {
    "text": "You could do simulations in\nUnreal or something else. Can you load it into Gazebo?",
    "start": "2362350",
    "end": "2367599"
  },
  {
    "text": "Yeah, we haven't tried it. So I will make an\nassumption by saying yes.",
    "start": "2367600",
    "end": "2373119"
  },
  {
    "text": "But it is a scene graph,\nand it's a JSON file, and you have the geometry. You guys have these on GitHub?",
    "start": "2373120",
    "end": "2380170"
  },
  {
    "text": "Some examples. Yes. But, at the end\nof the day, these are existing data sets that\nwere not produced by us.",
    "start": "2380170",
    "end": "2385910"
  },
  {
    "text": "I mean, the 3RScan, I mean. So you can definitely refer\nto that work on 3DSSG, which is the one that\nprovides the scene graphs.",
    "start": "2385910",
    "end": "2392810"
  },
  {
    "text": "And you can then utilize the\ngeometry and the scene graph to see if it can load it. In the construction sites, we\ndon't have yet scene graphs.",
    "start": "2392810",
    "end": "2399500"
  },
  {
    "text": "We only have 3D geometry because\nit is very painful to annotate these particular scenes.",
    "start": "2399500",
    "end": "2406300"
  },
  {
    "text": "We are building some tools to\nautomate annotation on them, which I cannot refer\nto them more right now",
    "start": "2406300",
    "end": "2412270"
  },
  {
    "text": "because it's ongoing work\nat the very first stages. But I'm happy to\nwhen it's out to send",
    "start": "2412270",
    "end": "2417680"
  },
  {
    "text": "you a linked if you want. Yeah. There was a question here.",
    "start": "2417680",
    "end": "2423150"
  },
  {
    "text": "And I know they already\nmade a question but-- Oh, sorry. Yeah, just quick,\ncould you elaborate on",
    "start": "2423150",
    "end": "2428870"
  },
  {
    "text": "how can your method be\npotentially integrated with internet of things. For example, if you place\nlike a chip on certain objects",
    "start": "2428870",
    "end": "2437360"
  },
  {
    "text": "in the environment that stores\ninformation about the materials, the dates, and the degree\nof deterioration and stuff",
    "start": "2437360",
    "end": "2443660"
  },
  {
    "text": "like how can this method\nbe potentially taking advantage of those? We're not working\nthat much into fusing",
    "start": "2443660",
    "end": "2451190"
  },
  {
    "text": "different types of information\nbut visual information these days. However, I can assume\ndepending on the task",
    "start": "2451190",
    "end": "2457730"
  },
  {
    "text": "you want to solve that this\ninformation is very important. Yeah. You can attach it on the\ngraph as an attribute.",
    "start": "2457730",
    "end": "2464090"
  },
  {
    "text": "Because the attributes\nare not specific, you can add as many as you want. Yeah. There was a question over there?",
    "start": "2464090",
    "end": "2469990"
  },
  {
    "text": " Hi. I really like the\ndeconstruction part",
    "start": "2469990",
    "end": "2476329"
  },
  {
    "text": "you mentioned, like using\nthe lighting scenes. And can you please give\nus like a detailed example",
    "start": "2476330",
    "end": "2483830"
  },
  {
    "text": "how your proposed solutions\ncan help in the deconstruction process.",
    "start": "2483830",
    "end": "2489160"
  },
  {
    "text": "Like, for example, after\nyou have the scanned model, can the workers use\nthose information",
    "start": "2489160",
    "end": "2496069"
  },
  {
    "text": "to detect which\npart can be reused and how to cut those\nreusable portion by what",
    "start": "2496070",
    "end": "2503210"
  },
  {
    "text": "kind of methodologies? Yeah. The interesting part\nhere is that connections",
    "start": "2503210",
    "end": "2509180"
  },
  {
    "text": "play a big role, connections\nbetween materials. And usually connections\nwith glues and nails",
    "start": "2509180",
    "end": "2515900"
  },
  {
    "text": "sometimes can\ndisrupt the structure of a particular\nbuilding element.",
    "start": "2515900",
    "end": "2521930"
  },
  {
    "text": "So these are things we are\nnot necessarily capturing in the data that we have.",
    "start": "2521930",
    "end": "2528359"
  },
  {
    "text": "We know that this\nis put over there. Maybe we can see if there is\na specific connection that is visible from imagery\nbut that's that.",
    "start": "2528360",
    "end": "2537600"
  },
  {
    "text": "Now, you can understand\nthat much about deconstruction by looking\ninto your construction,",
    "start": "2537600",
    "end": "2543220"
  },
  {
    "text": "but if you don't capture\nthat information, it becomes even\nharder to have-- you will have a certain\nestimate, but it's not",
    "start": "2543220",
    "end": "2549570"
  },
  {
    "text": "going to be accurate because\nyou never know what you're going to find afterwards. And in addition,\nyou don't know what is the deterioration of\nthe material behind to what",
    "start": "2549570",
    "end": "2557910"
  },
  {
    "text": "is visible to you\nbecause you don't know what's going\non behind the wall 50 years or 100 years later.",
    "start": "2557910",
    "end": "2564690"
  },
  {
    "text": "So you can only\nmake assumptions. So how can this process, like\nenhance the deconstruction",
    "start": "2564690",
    "end": "2570330"
  },
  {
    "text": "process? What kind of\ninformation the workers can get from those models? You can definitely\nunderstand what materials",
    "start": "2570330",
    "end": "2577109"
  },
  {
    "text": "would exist in this building\nand what can be actually harvested out of that\nbecause then you understand the size of the panels.",
    "start": "2577110",
    "end": "2583180"
  },
  {
    "text": "You can understand the\nsize of the windows, the types of air ducts that\nexist, how big they are.",
    "start": "2583180",
    "end": "2588880"
  },
  {
    "text": "You can get a lot\nof information. However, at the\nend of the day, it will give you an\ninitial estimate",
    "start": "2588880",
    "end": "2594550"
  },
  {
    "text": "and an initial hypothesis that\nthis building could be used. But the moment you start going\nfor thinking about a demolition,",
    "start": "2594550",
    "end": "2601220"
  },
  {
    "text": "you have to have a very\naccurate on the spot survey of what is the status\nof your building right now.",
    "start": "2601220",
    "end": "2606470"
  },
  {
    "text": "So this approach does not mean\nthat you don't need someone to go on the spot and survey\nthe building after all.",
    "start": "2606470",
    "end": "2613700"
  },
  {
    "text": "You do need that. But it just helps you out\nof the millions of buildings that we have out\nthere, start making",
    "start": "2613700",
    "end": "2619930"
  },
  {
    "text": "some matching between what would\nbe the best for your new design. ",
    "start": "2619930",
    "end": "2627400"
  },
  {
    "text": "If it's OK, I'd like to\nknow a little more detail as to which sensors are\nrequired specifically for this,",
    "start": "2627400",
    "end": "2633590"
  },
  {
    "text": "and is there a\nminimum resolution? How that compares to\nwhat you can currently",
    "start": "2633590",
    "end": "2640300"
  },
  {
    "text": "find in laser\nrangefinding or whatever? Are we talking about\nwhich task circularly?",
    "start": "2640300",
    "end": "2646650"
  },
  {
    "text": "Pardon. Which task are we talking about? For construction. Construction? Yes.",
    "start": "2646650",
    "end": "2652450"
  },
  {
    "text": "To do construction\nprogress monitoring or to do the construction\nwe discussed?",
    "start": "2652450",
    "end": "2657790"
  },
  {
    "text": "I was more interested\nin progress monitoring, but I am curious about\nboth because I think that also ties into inspection.",
    "start": "2657790",
    "end": "2666502"
  },
  {
    "text": "So OK, at this point,\nwe have nothing, so even",
    "start": "2666502",
    "end": "2673660"
  },
  {
    "text": "a cheap sensor would be enough. A sensor that does a\ngood job would be enough because we really have\nnothing out there.",
    "start": "2673660",
    "end": "2680770"
  },
  {
    "text": "I also think that laser\nscanners are great, but in order to collect data\non the scale of a building,",
    "start": "2680770",
    "end": "2689410"
  },
  {
    "text": "you need a system that is fast. And essentially a\ntripod-based laser scanner that takes 5 minutes to do one\nrotation, it is not scalable.",
    "start": "2689410",
    "end": "2699770"
  },
  {
    "text": "So you need systems\nthat are scalable. There are backpacks who are\nfaster and usually similarly",
    "start": "2699770",
    "end": "2705160"
  },
  {
    "text": "accurate, but I'm sure they have\ntheir caveats as well in terms of the potential drift, et\ncetera that may be happening.",
    "start": "2705160",
    "end": "2712770"
  },
  {
    "text": "In addition, they capture\nso many millions of points that it's very hard to\nprocess the information",
    "start": "2712770",
    "end": "2718430"
  },
  {
    "text": "to perform construction\nprogress monitoring. That's why, for\nexample, a method like the adaptive\nreconstruction we proposed",
    "start": "2718430",
    "end": "2724190"
  },
  {
    "text": "is going to be very helpful. The reason why that\nwould be very helpful is because when you do\nconstruction progress monitoring, you only care about\nthe things you just installed.",
    "start": "2724190",
    "end": "2731793"
  },
  {
    "text": "So you don't need to\ncare about anything else, but you need to care about\nif stones, studs, or pipes or whatever was installed at the\nright position at the right time",
    "start": "2731793",
    "end": "2739260"
  },
  {
    "text": "and how much of it. Imagery can also take\nyou to a certain point",
    "start": "2739260",
    "end": "2746330"
  },
  {
    "text": "forward like multiview imagery. It's not going to\nbe a perfect point cloud so sizes could be off.",
    "start": "2746330",
    "end": "2751470"
  },
  {
    "text": "But at least you would know what\nhas been installed and when, which is already\na big step forward",
    "start": "2751470",
    "end": "2757040"
  },
  {
    "text": "to what we have right now. So I would suggest, if\nyou want the perfect data,",
    "start": "2757040",
    "end": "2763130"
  },
  {
    "text": "a laser scanner that has\nadaptive reconstruction capabilities and is\nable to perform these",
    "start": "2763130",
    "end": "2773150"
  },
  {
    "text": "in a fast, iterative manner\nwould be probably the best solution. And getting images as well,\nbecause we need images",
    "start": "2773150",
    "end": "2780163"
  },
  {
    "text": "to understand materials, we\ncannot get that from point clouds. We need the high frequency\ninformation from the images.",
    "start": "2780163",
    "end": "2786190"
  },
  {
    "text": " I know I'm not answering\nexactly your question, but I hope it helps.",
    "start": "2786190",
    "end": "2792200"
  },
  {
    "text": "Oh, yeah. Thank you. Yeah. Essentially everything\ncounts at this point.",
    "start": "2792200",
    "end": "2797299"
  },
  {
    "text": "When you have nothing,\neven the smallest thing can be of big use. ",
    "start": "2797300",
    "end": "2804740"
  },
  {
    "text": "Any last question?  So I was wondering when you\nmentioned about the material",
    "start": "2804740",
    "end": "2811490"
  },
  {
    "text": "characterization for\na particular object. So is it assigned manually or\nwe just assume that if we find",
    "start": "2811490",
    "end": "2818720"
  },
  {
    "text": "pipes from the 3D scan, those\npipes are made of steel or maybe",
    "start": "2818720",
    "end": "2824060"
  },
  {
    "text": "PVC or something else? Or are we going to\nmanually add the data that OK, this particular pipe\nis used in this particular scene",
    "start": "2824060",
    "end": "2830730"
  },
  {
    "text": "or made of steel? Listen, we are at the end\nof the day talking only",
    "start": "2830730",
    "end": "2836400"
  },
  {
    "text": "about visual information. So you can't detect\nmaterials on images and understand what they are. That being said, it's only\nwhat the visual information",
    "start": "2836400",
    "end": "2843580"
  },
  {
    "text": "can give you. It may look it's made out of\nsilver, so maybe it's a metal. But, at the end of the day,\nit could be the ceramic",
    "start": "2843580",
    "end": "2849510"
  },
  {
    "text": "and you wouldn't know\nbecause of how it looks like. So yes, with the sake of\noversimplifying things,",
    "start": "2849510",
    "end": "2856270"
  },
  {
    "text": "you can understand\nmaterials from imagery. And you can just have\nthose kind of predictions",
    "start": "2856270",
    "end": "2862109"
  },
  {
    "text": "to help you understand what\nyou have on your scene. On the other hand,\nif you already have some documentation of your\nbuilding as it was constructed,",
    "start": "2862110",
    "end": "2870640"
  },
  {
    "text": "you always have some\nreferral of what has been planned to be\ninstalled and what were",
    "start": "2870640",
    "end": "2876359"
  },
  {
    "text": "the elements that were ordered. So you could make this decision\neasier for you by at least",
    "start": "2876360",
    "end": "2881550"
  },
  {
    "text": "making sure that\nthe element that was supposed to be installed is\nindeed that particular material. ",
    "start": "2881550",
    "end": "2890105"
  },
  {
    "text": "You want one more question. Last one. Yes. So the model also worked\nin a nonconfined space.",
    "start": "2890105",
    "end": "2898130"
  },
  {
    "text": "So we are seeing all the\nexamples, for example, like across room area\nor whether it's top down",
    "start": "2898130",
    "end": "2904960"
  },
  {
    "text": "like open space outside. Outdoor spaces like in\nsquares or roads or parks.",
    "start": "2904960",
    "end": "2913490"
  },
  {
    "text": "Yeah. Like, for example,\nlike in parks, it's looking down at\nlike multiple buildings, and you don't really have a new\nedge around the whole space.",
    "start": "2913490",
    "end": "2923380"
  },
  {
    "text": "For example, if I\nwant to use this model to model my city or my urban\narea right now to figure out",
    "start": "2923380",
    "end": "2929500"
  },
  {
    "text": "where I can place solar\npanels, for example, how would the process to\nwork in such an open space?",
    "start": "2929500",
    "end": "2937270"
  },
  {
    "text": "I mean, in an urban environment,\nplacing solar panels, I guess, would be on the roofs\nof buildings and not on land.",
    "start": "2937270",
    "end": "2943900"
  },
  {
    "text": "But aerial scanning or imagery\nwould help you with that.",
    "start": "2943900",
    "end": "2950210"
  },
  {
    "text": "Even Google Street Maps have 3D\ninformation in certain cities. So that could take\nyou a little bit.",
    "start": "2950210",
    "end": "2956740"
  },
  {
    "text": "You can do things with that. If you want to understand\nhow things change,",
    "start": "2956740",
    "end": "2963040"
  },
  {
    "text": "our living seems to work\nthat does instance matching. I mean, we've never tried\nany of those outdoor, but the one that would for sure\ngeneralize in an easier way",
    "start": "2963040",
    "end": "2970450"
  },
  {
    "text": "would be the scene\ngraph work, because it works on the semantic space. The other one because it's\nrestricted to actually having",
    "start": "2970450",
    "end": "2976390"
  },
  {
    "text": "to be trained on certain\namount of categories, then you would have to train it\non certain amount of categories.",
    "start": "2976390",
    "end": "2982390"
  },
  {
    "text": "One potential workaround\nis to consider open scene understanding in this case\nwhich we haven't yet done,",
    "start": "2982390",
    "end": "2990019"
  },
  {
    "text": "but it is a possible extension. Thank you. Yeah. Good? Great. Thanks very much.",
    "start": "2990020",
    "end": "2995450"
  },
  {
    "text": "Thank you, everyone\nfor being here. [APPLAUSE]",
    "start": "2995450",
    "end": "3000680"
  },
  {
    "start": "3000680",
    "end": "3003000"
  }
]
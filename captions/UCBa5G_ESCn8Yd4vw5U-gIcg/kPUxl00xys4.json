[
  {
    "start": "0",
    "end": "125000"
  },
  {
    "text": "a good afternoon uh this is ee 380 stanford university in the spring of",
    "start": "11120",
    "end": "18080"
  },
  {
    "text": "2022. um the talk today",
    "start": "18080",
    "end": "23920"
  },
  {
    "text": "is uh about converged ai and hpc it's a hardware and software",
    "start": "23920",
    "end": "30640"
  },
  {
    "text": "approach using rock's tensor streaming uh processor uh this is uh",
    "start": "30640",
    "end": "37520"
  },
  {
    "text": "and fascinating and interesting talk i've read a couple papers about it",
    "start": "37520",
    "end": "42960"
  },
  {
    "text": "and i think we're in for for a great ride the speaker is the uh",
    "start": "42960",
    "end": "49680"
  },
  {
    "text": "principal architect at grock and uh he was previously at",
    "start": "49680",
    "end": "56320"
  },
  {
    "text": "google and before that at cray he's a graduate of the united university of minnesota",
    "start": "56320",
    "end": "62879"
  },
  {
    "text": "and a highly respected and very productive uh",
    "start": "62879",
    "end": "68740"
  },
  {
    "text": "[Music] producer of uh new parts and",
    "start": "68740",
    "end": "73840"
  },
  {
    "text": "architectures uh he has a great first name by the way it's dennis",
    "start": "73840",
    "end": "80159"
  },
  {
    "text": "we share that and uh now i'm going to share my screen with him",
    "start": "80159",
    "end": "85680"
  },
  {
    "text": "and uh we'll see what happens dennis euron thank you very much for doing this",
    "start": "85680",
    "end": "91200"
  },
  {
    "text": "okay thank you dennis for that nice introduction i'm glad to be here uh as you mentioned today's talk is about",
    "start": "91200",
    "end": "97600"
  },
  {
    "text": "converged ai and hpc and it's really a an introduction to both the chip micro",
    "start": "97600",
    "end": "102799"
  },
  {
    "text": "architecture and the system architecture as we scale from chips to systems and be able to describe some of the work that",
    "start": "102799",
    "end": "109200"
  },
  {
    "text": "we've done in the past several years and as we uh launch our new uh set of",
    "start": "109200",
    "end": "114320"
  },
  {
    "text": "processors in the market uh to kind of describe what we're doing and why we did it kind of describe the",
    "start": "114320",
    "end": "120079"
  },
  {
    "text": "motivation so that people get a sense for uh why we made the trade-offs that we did",
    "start": "120079",
    "end": "125840"
  },
  {
    "start": "125000",
    "end": "284000"
  },
  {
    "text": "as dennis mentioned my name is dennis axe i'm the chief architect and uh fellow at grock i've uh been at grock",
    "start": "125840",
    "end": "131920"
  },
  {
    "text": "for for a few years and uh i met uh jonathan ross the founder at well",
    "start": "131920",
    "end": "137920"
  },
  {
    "text": "my tenure at google i spent about a decade at google building data center networks",
    "start": "137920",
    "end": "144560"
  },
  {
    "text": "focusing a lot on energy proportional networks as well as uh very scalable cluster architectures",
    "start": "144560",
    "end": "152560"
  },
  {
    "text": "prior to that as dennis alluded to i was a chief architect at craig where i was worked on several top 500 machines and",
    "start": "152560",
    "end": "160400"
  },
  {
    "text": "uh brought to bear a lot of the uh distributed shared memory and what we came to know as as a dragonfly topology",
    "start": "160400",
    "end": "168400"
  },
  {
    "text": "that that is currently kind of used in a number of state-of-the-art top 500 machines",
    "start": "168400",
    "end": "174959"
  },
  {
    "text": "this dock is also uh prepared with oscar menser so i want to thank oscar for all the help",
    "start": "174959",
    "end": "181040"
  },
  {
    "text": "especially this week as a little bit under the weather he was very very helpful in pulling this all together",
    "start": "181040",
    "end": "187760"
  },
  {
    "text": "what i'm hoping to do is use this as a little bit of a retrospective to give a little bit of our uh",
    "start": "187760",
    "end": "193360"
  },
  {
    "text": "past work from iska 2020 where we introduced the chip micro architecture to describe",
    "start": "193360",
    "end": "199040"
  },
  {
    "text": "uh the the uh deep learning accelerator that we built called the tensor streaming processor",
    "start": "199040",
    "end": "205440"
  },
  {
    "text": "and then on this this isca coming up here in the next month we'll be releasing a new paper that describes our",
    "start": "205440",
    "end": "212480"
  },
  {
    "text": "system architecture it's called a software-defined tensor streaming multi-processor for large-scale machine",
    "start": "212480",
    "end": "218080"
  },
  {
    "text": "learning and that's a fairly descriptive title so you can get a picture of what it what it entails but it's really these two papers",
    "start": "218080",
    "end": "225120"
  },
  {
    "text": "kind of elucidate both the chip micro architecture and the system architecture",
    "start": "225120",
    "end": "232319"
  },
  {
    "text": "so i'm hoping that you will be encouraged to go and read those papers to dive in for more details and",
    "start": "232319",
    "end": "238720"
  },
  {
    "text": "if you're really encouraged to come and talk to us because we are hiring and there's lots of interesting work to do",
    "start": "238720",
    "end": "245519"
  },
  {
    "text": "so um i want to just stop and and take a step back and in a nutshell describe what brock does we we're a nascent",
    "start": "245519",
    "end": "252400"
  },
  {
    "text": "company we've been around for the last six years our flagship product is as mentioned the",
    "start": "252400",
    "end": "257919"
  },
  {
    "text": "tensor streaming processor and the compiler a parallelizing compiler that goes along with that and",
    "start": "257919",
    "end": "263360"
  },
  {
    "text": "we'll talk a lot about the hardware software trade-offs that go into building a large-scale machine like this",
    "start": "263360",
    "end": "270400"
  },
  {
    "text": "like i said we're a relatively small company we've got around 250 employees and we're growing every day and i would",
    "start": "270400",
    "end": "275919"
  },
  {
    "text": "invite each of you to take a look at the grock home page so you can see if there's anything that would be uh",
    "start": "275919",
    "end": "281280"
  },
  {
    "text": "conducive or fit what you're looking to do brock is a a uh uh",
    "start": "281280",
    "end": "288479"
  },
  {
    "text": "spread kind of all across the the country and across the world we've got offices in",
    "start": "288479",
    "end": "293840"
  },
  {
    "text": "london as part of our acquisition of the max eller acquisition as well as all over the",
    "start": "293840",
    "end": "299680"
  },
  {
    "text": "united states and toronto we have a large facility in toronto where a lot of our compiler engineers",
    "start": "299680",
    "end": "306800"
  },
  {
    "text": "operate out of and of course our headquarters are in mountain view california we are remote uh first so if you if you",
    "start": "306800",
    "end": "314639"
  },
  {
    "text": "embrace and like the hybrid working environment we certainly embrace that at grock and um i would encourage you to",
    "start": "314639",
    "end": "321360"
  },
  {
    "text": "take a look so part of this i want to give you a little bit of a background and maybe uh",
    "start": "321360",
    "end": "327520"
  },
  {
    "text": "motivate some of this talk by by describing some of the work that that really happened several decades ago and",
    "start": "327520",
    "end": "334000"
  },
  {
    "text": "in fact i would say we're at somewhat of a renaissance in in computer architecture and that old ideas are now",
    "start": "334000",
    "end": "341039"
  },
  {
    "text": "new again in some respects and um there are several ideas in here that are inspired by",
    "start": "341039",
    "end": "346800"
  },
  {
    "text": "uh the cray one and inspired by other machines that are literally decades old",
    "start": "346800",
    "end": "352160"
  },
  {
    "text": "but but their time is is come and the killer app is now uh machine learning",
    "start": "352160",
    "end": "357600"
  },
  {
    "text": "and so these domains specific accelerators are like a new generation that's building on uh some of",
    "start": "357600",
    "end": "364800"
  },
  {
    "text": "this prior work and like i said 1980s spawned some really fascinating work that was driven",
    "start": "364800",
    "end": "371039"
  },
  {
    "text": "by uh dataflow and in particular there were some fascinating machines and the j",
    "start": "371039",
    "end": "377039"
  },
  {
    "text": "machine i've got the picture here of a 1024 processor element j machine uh that",
    "start": "377039",
    "end": "382479"
  },
  {
    "text": "was um from from mit one of the inspirational machines and it was really",
    "start": "382479",
    "end": "388000"
  },
  {
    "text": "uh founded on on some some inspirational work that jack dennis did around dataflow architecture",
    "start": "388000",
    "end": "394400"
  },
  {
    "text": "and it was based on this idea that you could represent programs as a collection of nodes",
    "start": "394400",
    "end": "400319"
  },
  {
    "text": "that are the operators like plus minus multiply and so forth and the arcs or the edges connecting those nodes is the",
    "start": "400319",
    "end": "407360"
  },
  {
    "text": "operands that are feeding those operands and results and so as a result you can compose",
    "start": "407360",
    "end": "413840"
  },
  {
    "text": "a function a function for example a binary function that's consists of two inputs x and y",
    "start": "413840",
    "end": "420639"
  },
  {
    "text": "and some of those those inputs have tokens on them and that's the data operands as they arrive",
    "start": "420639",
    "end": "427199"
  },
  {
    "text": "and there's a fundamental idea in data flow and that is that the inputs as the",
    "start": "427199",
    "end": "432240"
  },
  {
    "text": "inputs arrive your your operator can fire only when its inputs are available",
    "start": "432240",
    "end": "437840"
  },
  {
    "text": "okay so the idea here is to try to expose as much natural concurrency instruction level concurrency as you can",
    "start": "437840",
    "end": "445759"
  },
  {
    "text": "as you construct a program graph and so the program was represented as a",
    "start": "445759",
    "end": "450880"
  },
  {
    "text": "computation graph or a program graph and it really represented kind of from",
    "start": "450880",
    "end": "455919"
  },
  {
    "text": "the inputs to the outputs what was being computed and their data dependence relationships",
    "start": "455919",
    "end": "461840"
  },
  {
    "text": "in other words what had to be done prior in order for these other things to be satisfied",
    "start": "461840",
    "end": "468319"
  },
  {
    "text": "so in effect you you built this nice graph and that graph was very composable in that",
    "start": "468319",
    "end": "474879"
  },
  {
    "text": "you can build more elaborate graphs by chaining things together and this idea really allows you to try",
    "start": "474879",
    "end": "482400"
  },
  {
    "text": "to expose instruction level parallelism now if you look at this simple example for instance instruction level",
    "start": "482400",
    "end": "488879"
  },
  {
    "text": "parallelism in this case is any any siblings that is things that are operators that are on the same level can",
    "start": "488879",
    "end": "495360"
  },
  {
    "text": "be executed concurrently so it gives you a very natural way of exposing that",
    "start": "495360",
    "end": "500720"
  },
  {
    "text": "concurrency and exploiting it a nice way i like to think about this is if you were to think about your",
    "start": "500720",
    "end": "506160"
  },
  {
    "text": "computation graph whether that's tensorflow or an onyx graph or any other",
    "start": "506160",
    "end": "511520"
  },
  {
    "text": "program graph that lists and respects the dependencies if you were to pick it up at the output and kind of dangle it",
    "start": "511520",
    "end": "518719"
  },
  {
    "text": "so that all of your inputs are dangling there you would you would nicely the length of that program essentially",
    "start": "518719",
    "end": "525200"
  },
  {
    "text": "gives you your execution time and you very nicely get a order of relation the",
    "start": "525200",
    "end": "530800"
  },
  {
    "text": "order of operators that need to be conducted to respect that data dependence and it gives you all the",
    "start": "530800",
    "end": "536800"
  },
  {
    "text": "things that can be done concurrently i.e those things that are at the same level so in this way it gives you a nice",
    "start": "536800",
    "end": "543519"
  },
  {
    "text": "representation of all the instruction level parallelism that can be exposed",
    "start": "543519",
    "end": "549200"
  },
  {
    "text": "one of the interesting things about this is it came about these machines didn't ultimately didn't really have the",
    "start": "549200",
    "end": "554320"
  },
  {
    "text": "concept of a program counter per se because programs were represented slightly",
    "start": "554320",
    "end": "559680"
  },
  {
    "text": "differently they were represented by this notion of a graph now obviously we're fetching and executing",
    "start": "559680",
    "end": "566320"
  },
  {
    "text": "instructions so the execution model was very simple you fetch instructions you",
    "start": "566320",
    "end": "571360"
  },
  {
    "text": "execute those instructions when their operands arrive you update the state you fetch new instructions and so there's",
    "start": "571360",
    "end": "577600"
  },
  {
    "text": "this kind of very simple execution cycle that was used in this this simple data",
    "start": "577600",
    "end": "584080"
  },
  {
    "text": "flow execution model and it really emphasizes i think for the first time it",
    "start": "584080",
    "end": "589600"
  },
  {
    "text": "really emphasizes that communication and computation are two sides of the same",
    "start": "589600",
    "end": "594800"
  },
  {
    "text": "coin and by that i mean if you're going to compute something it is usually done with the intent of communicating that so",
    "start": "594800",
    "end": "601360"
  },
  {
    "text": "that somebody downstream an eventual consumer could use that data",
    "start": "601360",
    "end": "606800"
  },
  {
    "text": "in a way in a productive way and compute with it so it spawned a whole new set of kind of",
    "start": "606800",
    "end": "613120"
  },
  {
    "text": "uh aha moments for computer architects as they took this to the next level for example berkeley active messages i like",
    "start": "613120",
    "end": "619680"
  },
  {
    "text": "to to look at that and say berkeley active messages kind of the idea to carry this to a network of workstations idea where",
    "start": "619680",
    "end": "626480"
  },
  {
    "text": "you have messages flowing on the network and they're going to spawn uh new new",
    "start": "626480",
    "end": "631519"
  },
  {
    "text": "messages and so this this whole idea kind of quickly mushroomed and created new new",
    "start": "631519",
    "end": "637519"
  },
  {
    "text": "architectures in the 80s and early 90s that uh really have have come to be",
    "start": "637519",
    "end": "642640"
  },
  {
    "text": "influential in today's uh domain specific architectures",
    "start": "642640",
    "end": "649600"
  },
  {
    "text": "so if we take this simple model and we just extend it and we include a interconnection network now the",
    "start": "649600",
    "end": "655279"
  },
  {
    "text": "interconnection network is kind of a nebulous topology agnostic way of representing",
    "start": "655279",
    "end": "661440"
  },
  {
    "text": "that we have some collection of processing elements and they're going to be consuming those",
    "start": "661440",
    "end": "666480"
  },
  {
    "text": "those uh consuming tokens or data operands and producing new results and",
    "start": "666480",
    "end": "671760"
  },
  {
    "text": "those results are going to flow on the network along with the operands and so the interconnection network is",
    "start": "671760",
    "end": "678880"
  },
  {
    "text": "really a fundamental part of all these processing elements whether it's on the same chip or whether it's off the chip",
    "start": "678880",
    "end": "686160"
  },
  {
    "text": "it's a fundamental part of this execution model so what i hope to to describe today is a",
    "start": "686160",
    "end": "694079"
  },
  {
    "start": "690000",
    "end": "845000"
  },
  {
    "text": "really a very different approach that we took and that's really a software-defined approach",
    "start": "694079",
    "end": "700240"
  },
  {
    "text": "and by that i mean we very carefully laid out the hardware software interface",
    "start": "700240",
    "end": "705360"
  },
  {
    "text": "so that we have an isa that is about um it's about controlling the underlying",
    "start": "705360",
    "end": "712240"
  },
  {
    "text": "hardware most instruction set architectures are designed to abstract away the details underneath the heart in",
    "start": "712240",
    "end": "719760"
  },
  {
    "text": "the underlying hardware for example on an x86 you may execute a load effective",
    "start": "719760",
    "end": "725760"
  },
  {
    "text": "address instruction well you don't what you don't see is all the implicit messages and the cash moving in the cash",
    "start": "725760",
    "end": "732160"
  },
  {
    "text": "movements and all the implicit data movements that get orchestrated as a result of executing",
    "start": "732160",
    "end": "738560"
  },
  {
    "text": "that in other words often they get broken down into little micro operations that orchestrated together as an",
    "start": "738560",
    "end": "745279"
  },
  {
    "text": "ensemble accomplished some larger goal and so that is going to be one of the",
    "start": "745279",
    "end": "750320"
  },
  {
    "text": "themes today we're going to talk a little bit about that of how we've decomposed or disaggregated our",
    "start": "750320",
    "end": "756240"
  },
  {
    "text": "functional units so that we can break things up into smaller micro operations that we can execute efficiently",
    "start": "756240",
    "end": "764160"
  },
  {
    "text": "along with that hardware software interface is a static and dynamic interface in other words we have a runtime system that is",
    "start": "764160",
    "end": "771600"
  },
  {
    "text": "going to be used for um actually in placing the the collateral and placing your object files",
    "start": "771600",
    "end": "777839"
  },
  {
    "text": "on the machine and then invoking the actual parallel application as well as",
    "start": "777839",
    "end": "783040"
  },
  {
    "text": "handling exceptions we'll talk a little bit about exception handling as well and in this regime nodes in the",
    "start": "783040",
    "end": "789600"
  },
  {
    "text": "computation graph represent the operators just as we did we talked about in the traditional data flow",
    "start": "789600",
    "end": "795920"
  },
  {
    "text": "and the edges represent results and those fire only when their input operands are available",
    "start": "795920",
    "end": "802720"
  },
  {
    "text": "and this turns out to be a very conducive model for machine learning in machine learning many machine learning",
    "start": "802720",
    "end": "808480"
  },
  {
    "text": "models are known a priori this it's a static compute graph and you're taking that static compute graph and you're",
    "start": "808480",
    "end": "815120"
  },
  {
    "text": "compiling it for the underlying hardware like i said the the goal here is to",
    "start": "815120",
    "end": "820160"
  },
  {
    "text": "expose the the controls so that the compiler or most notably the compiler",
    "start": "820160",
    "end": "826399"
  },
  {
    "text": "writer has complete control of the underlying hardware and that was one of the goals of of the the isa was turning",
    "start": "826399",
    "end": "835199"
  },
  {
    "text": "over and exerting control over the underlying hardware not abstracting it away but making it practical for the",
    "start": "835199",
    "end": "842079"
  },
  {
    "text": "hard work to compile or to to compile for it so that that required some design",
    "start": "842079",
    "end": "849120"
  },
  {
    "text": "philosophy and some some perspective change from our from our perspective because one of the things that we wanted",
    "start": "849120",
    "end": "854639"
  },
  {
    "text": "to do is make a completely deterministic chip so that the compiler",
    "start": "854639",
    "end": "860639"
  },
  {
    "text": "had omniscient information about where everything was on the chip for",
    "start": "860639",
    "end": "865920"
  },
  {
    "text": "example we allocate tensors on the chip the compiler will know exactly where those",
    "start": "865920",
    "end": "871760"
  },
  {
    "text": "are in the sram as well as which functional units are currently busy on a",
    "start": "871760",
    "end": "876880"
  },
  {
    "text": "cycle by cycle basis in other words the compiler literally can track the state",
    "start": "876880",
    "end": "882079"
  },
  {
    "text": "the architecturally visible state on a cycle by cycle basis",
    "start": "882079",
    "end": "887120"
  },
  {
    "text": "and you might think well that makes it a lot harder to build a compiler but the reality is by turning over control to",
    "start": "887120",
    "end": "894399"
  },
  {
    "text": "the compiler it's managing more meta state more architecturally visible state but it has complete information about",
    "start": "894399",
    "end": "901680"
  },
  {
    "text": "the state of the machine and it can now use that to reason about correctness for example memory consistency and memory",
    "start": "901680",
    "end": "908240"
  },
  {
    "text": "ordering things like that and it can reason about program correctness now in",
    "start": "908240",
    "end": "913279"
  },
  {
    "text": "a way that allows uh the compiler to build uh build a program efficiently",
    "start": "913279",
    "end": "919440"
  },
  {
    "text": "so part of this was we had to embrace this concept of determinism and make sure we did not do anything in the",
    "start": "919440",
    "end": "926240"
  },
  {
    "text": "hardware that would reorder events for example there's no out of order execution there's no caches we don't",
    "start": "926240",
    "end": "932639"
  },
  {
    "text": "have traditional caches we have no arbiters this is the 14th chip that i've designed and worked on in",
    "start": "932639",
    "end": "938800"
  },
  {
    "text": "my career and this is the first one that doesn't have any arbiters and by arbiters i mean it's a crossbar",
    "start": "938800",
    "end": "944639"
  },
  {
    "text": "where you're presenting some data to it and it's going to arbitrate and grant one of those inputs",
    "start": "944639",
    "end": "950800"
  },
  {
    "text": "an output port for example there's other reactive components for example link layer",
    "start": "950800",
    "end": "957360"
  },
  {
    "text": "replay uh the pcie point-to-point network uses a link layer protocol to",
    "start": "957360",
    "end": "962720"
  },
  {
    "text": "replay any retransmissions that happen and of course that interferes with determinism so we had to embrace forward",
    "start": "962720",
    "end": "970639"
  },
  {
    "text": "error correction on our data paths and we had to account for all that and when we designed the system both at the chip",
    "start": "970639",
    "end": "977040"
  },
  {
    "text": "level and at the system level so we'll talk a little bit more about that those specific tradeoffs",
    "start": "977040",
    "end": "983519"
  },
  {
    "text": "so the way that to look at this is we want to turn over control of the hardware so that the compiler can have",
    "start": "983519",
    "end": "991120"
  },
  {
    "text": "this screen programming model it's a producer consumer screen programming model",
    "start": "991120",
    "end": "996399"
  },
  {
    "text": "which just means that we have this concept of a stream register instead of a normal general purpose register we've",
    "start": "996399",
    "end": "1002399"
  },
  {
    "text": "got this concept of a screen register and i'll describe that in much more detail as we uh as we go",
    "start": "1002399",
    "end": "1009360"
  },
  {
    "text": "because it's a central it's a central concept and it's a central hardware structure",
    "start": "1009360",
    "end": "1014399"
  },
  {
    "text": "and and the compiler can track the state of the stream registers on the chip and",
    "start": "1014399",
    "end": "1019920"
  },
  {
    "text": "know exactly where everything uh is located so imagine waking up in the morning and",
    "start": "1019920",
    "end": "1025199"
  },
  {
    "text": "this is what your morning commute would look like this is the concept of determinism to your morning",
    "start": "1025199",
    "end": "1033319"
  },
  {
    "text": "hopefully your morning commute doesn't look quite that busy but that's an example if you didn't have stop lights",
    "start": "1060000",
    "end": "1066960"
  },
  {
    "text": "as a flow control mechanism how could you orchestrate your traffic well this",
    "start": "1066960",
    "end": "1072240"
  },
  {
    "text": "is exactly the job of the compiler in this case is that in that we are going to turn over",
    "start": "1072240",
    "end": "1078000"
  },
  {
    "text": "um and and do and change the way we think about the normal uh cpu in fact",
    "start": "1078000",
    "end": "1084000"
  },
  {
    "text": "what we've done is we've avoided some of the complexities that would ordinarily go into a cpu for example a lot of the",
    "start": "1084000",
    "end": "1090720"
  },
  {
    "text": "front-end dispatching and scheduling that would go into a normal cpu think of thomas hilo's algorithm checking for and",
    "start": "1090720",
    "end": "1097280"
  },
  {
    "text": "remapping different registers shadow registers all of that goes away instead",
    "start": "1097280",
    "end": "1102480"
  },
  {
    "text": "we're we're turning some of that complexity to the compiler to deal with that scheduling",
    "start": "1102480",
    "end": "1108160"
  },
  {
    "text": "instead that's a much more amenable place to deal with that for a variety of reasons",
    "start": "1108160",
    "end": "1113919"
  },
  {
    "text": "um number one it it offloads some of the the complexity the logic complexity if you look at the the uh the floor plan of",
    "start": "1113919",
    "end": "1121039"
  },
  {
    "text": "the chip the dye above you see there's it's a it's a regular design but there's",
    "start": "1121039",
    "end": "1126080"
  },
  {
    "text": "a number of of control units on it if you look at the the chip on the bottom it's very very regular very structured",
    "start": "1126080",
    "end": "1133840"
  },
  {
    "text": "and we take advantage of that and i'll i'll explain why in a bit in a bit more but it dramatically simplifies the the",
    "start": "1133840",
    "end": "1141840"
  },
  {
    "text": "chip design so that we can focus on the alus and the data paths that are",
    "start": "1141840",
    "end": "1147919"
  },
  {
    "text": "driving them so that we can put our foot on the gas provide a lot of on-chip bandwidth to feed all those hungry data",
    "start": "1147919",
    "end": "1155200"
  },
  {
    "text": "functional units so one of the things as i mentioned often gets in the way in a traditional",
    "start": "1155200",
    "end": "1161280"
  },
  {
    "text": "cpu or gpu is a conventional memory hierarchy so for example we don't have a",
    "start": "1161280",
    "end": "1167520"
  },
  {
    "text": "a memory hierarchy what we have is a single level sram that is organized as a flat",
    "start": "1167520",
    "end": "1175280"
  },
  {
    "text": "memory a large 220 megabyte i want to say cash but it's not a cash",
    "start": "1175280",
    "end": "1180799"
  },
  {
    "text": "it's a single level explicitly managed memory system and it uses the concept of a",
    "start": "1180799",
    "end": "1188000"
  },
  {
    "text": "memory slice or a memory bank for concurrency in the memory system there's a um 88 banks each of which can issue a",
    "start": "1188000",
    "end": "1196240"
  },
  {
    "text": "read and a right so in principle there's up to 176 way bank level concurrency",
    "start": "1196240",
    "end": "1202080"
  },
  {
    "text": "that's a tremendous amount of concurrency and we're going to describe kind of how we use that for both instruction fetching and for all the",
    "start": "1202080",
    "end": "1209280"
  },
  {
    "text": "data operands and results that we're feeding to our functional units we take really good advantage of that",
    "start": "1209280",
    "end": "1215520"
  },
  {
    "text": "to be able to drive our our large matrix units and vector processors at full rate",
    "start": "1215520",
    "end": "1223039"
  },
  {
    "text": "um so again this is based on this deterministic latency and explicitly allocating tensors in memory hierarchy",
    "start": "1223039",
    "end": "1230080"
  },
  {
    "text": "and then we expose that that sram that 220 megabyte shared sram across the",
    "start": "1230080",
    "end": "1236480"
  },
  {
    "text": "distributed system so you can think of having multiples of these in a logically",
    "start": "1236480",
    "end": "1241600"
  },
  {
    "text": "shared but physically distributed system okay at the system level we tried to simplify",
    "start": "1241600",
    "end": "1248799"
  },
  {
    "text": "some things to avoid uh introducing a lot of complexity for example modern",
    "start": "1248799",
    "end": "1254240"
  },
  {
    "text": "supercomputers scale to tens and 20 000 10 10 000 20 000 nodes very regularly",
    "start": "1254240",
    "end": "1260320"
  },
  {
    "text": "and those are very heterogeneous systems they often have cpus gpus smart knicks",
    "start": "1260320",
    "end": "1265679"
  },
  {
    "text": "uh fpgas a variety of offload engines that are really very heterogeneous and",
    "start": "1265679",
    "end": "1270720"
  },
  {
    "text": "difficult to coordinate and and often very difficult to manage the error handling along with it because it's",
    "start": "1270720",
    "end": "1277039"
  },
  {
    "text": "often so heterogeneous they all do something very different for the error handling",
    "start": "1277039",
    "end": "1282559"
  },
  {
    "text": "so one of the things that we did is we we uh build direct network so uh our",
    "start": "1282559",
    "end": "1287760"
  },
  {
    "text": "single chip both provides the processing elements as well as the switching elements for the networking component as",
    "start": "1287760",
    "end": "1294240"
  },
  {
    "text": "well so that single chip does both the networking and the processing and so that that",
    "start": "1294240",
    "end": "1301039"
  },
  {
    "text": "allows us to simplify our design have fewer components uh as well as build very straightforward direct networks and",
    "start": "1301039",
    "end": "1308240"
  },
  {
    "text": "i'll talk a little bit about that direct networks in other words we don't have a nick and a switch chip uh and that",
    "start": "1308240",
    "end": "1314559"
  },
  {
    "text": "that's doing the routing instead our our single chip is doing both",
    "start": "1314559",
    "end": "1319679"
  },
  {
    "text": "so and and one of the differences is we are literally scheduling the links instead",
    "start": "1319679",
    "end": "1326000"
  },
  {
    "text": "of having a a loosely coupled network interface where we just kind of do an rdma request and it just goes off and",
    "start": "1326000",
    "end": "1333440"
  },
  {
    "text": "works on it in the background and then notifies us when that transfer is done instead we are scheduling the physical",
    "start": "1333440",
    "end": "1340559"
  },
  {
    "text": "network links as a first class citizen just like we would do the vector processor or the matrix process or any",
    "start": "1340559",
    "end": "1347600"
  },
  {
    "text": "other on-chip resources and this is a fundamentally different way of handling the network and handling the way that we",
    "start": "1347600",
    "end": "1354240"
  },
  {
    "text": "uh we think of the overall system so again i'll describe kind of the the",
    "start": "1354240",
    "end": "1360480"
  },
  {
    "text": "idea here but it was really trying to get rid of some of the waste fraud and abuse both at the chip level and at the",
    "start": "1360480",
    "end": "1366799"
  },
  {
    "text": "system level and one good example of this if you were to look at this this chip uh our chip i'll show you a",
    "start": "1366799",
    "end": "1373120"
  },
  {
    "text": "detailed die shot here in a moment but the overhead for the instruction control is less than three percent that's less",
    "start": "1373120",
    "end": "1380320"
  },
  {
    "text": "than three percent for all the instruction dispatch and um uh the what",
    "start": "1380320",
    "end": "1385600"
  },
  {
    "text": "would normally be kind of the front end of your instruction dispatch pipeline",
    "start": "1385600",
    "end": "1391039"
  },
  {
    "start": "1390000",
    "end": "1409000"
  },
  {
    "text": "so how do we do this and why is it different and what i thought i would do is start with kind of the canonical uh",
    "start": "1391039",
    "end": "1397120"
  },
  {
    "text": "five stage pipeline that we all learned while reading patterson and hennessy at our mother's knee",
    "start": "1397120",
    "end": "1403600"
  },
  {
    "text": "it's got a instruction fetch decode execute memory and write back",
    "start": "1403600",
    "end": "1409520"
  },
  {
    "start": "1409000",
    "end": "1600000"
  },
  {
    "text": "those are the fundamental stages and what we do is each each one of these tiles you can think of it and this is",
    "start": "1409520",
    "end": "1416320"
  },
  {
    "text": "just kind of a an example of a of a mini core architecture and just to contrast our",
    "start": "1416320",
    "end": "1421600"
  },
  {
    "text": "approach with the with this this more uh more conventional approach if you think",
    "start": "1421600",
    "end": "1427039"
  },
  {
    "text": "of this as a a collection of of course what we did is we disaggregated those",
    "start": "1427039",
    "end": "1432640"
  },
  {
    "text": "cores we took the the functional units the integer and the floating point uh that are your your your workhorses for",
    "start": "1432640",
    "end": "1439520"
  },
  {
    "text": "the alus right they're doing fixed precision and floating point uh numerix",
    "start": "1439520",
    "end": "1444960"
  },
  {
    "text": "and we took the instruction dispatch we made that a separate union unit we made all the the memory system a separate",
    "start": "1444960",
    "end": "1452000"
  },
  {
    "text": "unit we literally disaggregated all these units to provide a simpler",
    "start": "1452000",
    "end": "1457039"
  },
  {
    "text": "instruction set for each for example we have a memory unit this is uh the",
    "start": "1457039",
    "end": "1463760"
  },
  {
    "text": "kind of salmon color or pink color here the memory system only does loads and stores gathers and scatters",
    "start": "1463760",
    "end": "1471200"
  },
  {
    "text": "that's it it can do fetches instructions it executes them it doesn't do ads it",
    "start": "1471200",
    "end": "1476880"
  },
  {
    "text": "doesn't do transcendental functions it just gives loads and stores gathers and scatters",
    "start": "1476880",
    "end": "1482400"
  },
  {
    "text": "along with no op and instruction fetch obviously every unit has to instruction fetch",
    "start": "1482400",
    "end": "1488880"
  },
  {
    "text": "um so you can see what we did is we disaggregated and we made these pipelines very specific so what we kind",
    "start": "1488880",
    "end": "1495440"
  },
  {
    "text": "of did you think about we have a separate memory unit so we disaggregated and decoupled the memory access from the",
    "start": "1495440",
    "end": "1503039"
  },
  {
    "text": "execution units that is the vector units the matrix units the",
    "start": "1503039",
    "end": "1508480"
  },
  {
    "text": "switching elements that are going to be operating on that data this decoupled access and execute allows us to have",
    "start": "1508480",
    "end": "1515760"
  },
  {
    "text": "thousands of outstanding vector references in flight and keep the memory system pipeline heavily pipelined and",
    "start": "1515760",
    "end": "1522320"
  },
  {
    "text": "we'll talk a little bit about that as instructions get executed core to all this is the idea of a stream",
    "start": "1522320",
    "end": "1529520"
  },
  {
    "text": "of streams flow on the chip as you can see they flow in the east and the west direction",
    "start": "1529520",
    "end": "1536000"
  },
  {
    "text": "and this is the idea of these stream register files and that they're the stream register files allows us to take",
    "start": "1536000",
    "end": "1542799"
  },
  {
    "text": "the what would normally be you think about a general purpose register and uh if you were to think about like a",
    "start": "1542799",
    "end": "1549840"
  },
  {
    "text": "mips processor and you do a load of some address into a general purpose register",
    "start": "1549840",
    "end": "1555919"
  },
  {
    "text": "say i store it and register two i can come back three weeks from now and you'll still have that value and",
    "start": "1555919",
    "end": "1562000"
  },
  {
    "text": "register too unless something bad happened you had to reset the machine in a streaming register file when i do a",
    "start": "1562000",
    "end": "1568400"
  },
  {
    "text": "load and put it into a stream it's moving so the next cycle it's going to be moving on the chip and so as it flows",
    "start": "1568400",
    "end": "1575200"
  },
  {
    "text": "out on the chip it's going to pass by every one of these functional units in the same way that an assembly line",
    "start": "1575200",
    "end": "1581200"
  },
  {
    "text": "passes by all the different stations as it passes by we can pick the data up",
    "start": "1581200",
    "end": "1586559"
  },
  {
    "text": "operate on it and then put it back into the screen so it can continue in the eastward or westward fashion",
    "start": "1586559",
    "end": "1593200"
  },
  {
    "text": "that's the very simple idea behind this concept of a stream register file and screening stream programming that",
    "start": "1593200",
    "end": "1599200"
  },
  {
    "text": "results from it what it does is it allows us to build an efficient producer consumer model where you're producing",
    "start": "1599200",
    "end": "1605760"
  },
  {
    "start": "1600000",
    "end": "1796000"
  },
  {
    "text": "into streams and somebody else downstream is consuming from those streams operating on the data and producing some",
    "start": "1605760",
    "end": "1612159"
  },
  {
    "text": "new value so the chip is organized using this that this concept of a super lane as i",
    "start": "1612159",
    "end": "1618880"
  },
  {
    "text": "mentioned it's broken up into tiles into these functional slices you can see vertically",
    "start": "1618880",
    "end": "1624320"
  },
  {
    "text": "you've got different functional units vertically and horizontally these are different super lanes so you can think",
    "start": "1624320",
    "end": "1630080"
  },
  {
    "text": "about we took all the normal functional units within a core and we kind of",
    "start": "1630080",
    "end": "1635120"
  },
  {
    "text": "disaggregated them and spread them out across the super lane we'll look closer at that in a moment",
    "start": "1635120",
    "end": "1640880"
  },
  {
    "text": "but what it allowed us to do then is to execute instructions in a cycle by cycle kind of",
    "start": "1640880",
    "end": "1647919"
  },
  {
    "text": "a staggered manner cycle by cycle so it's pipelined vertically in instruction",
    "start": "1647919",
    "end": "1653679"
  },
  {
    "text": "execution and it's pipelined horizontally in data execution so this thing is pipelined in two dimensions",
    "start": "1653679",
    "end": "1659919"
  },
  {
    "text": "vertically and horizontally so as you're thinking about this try to imagine",
    "start": "1659919",
    "end": "1664960"
  },
  {
    "text": "tensors flowing in kind of flowing in the horizontal dimension and instructions are being dispatched from",
    "start": "1664960",
    "end": "1671440"
  },
  {
    "text": "the south to a northern way uh in a northern manner this die shot shows the different",
    "start": "1671440",
    "end": "1677840"
  },
  {
    "text": "functional units i just want to take a second to point these out at the book ends here we've got these big mxm arrays",
    "start": "1677840",
    "end": "1684399"
  },
  {
    "text": "our matrix multiplication units um and these are 320 by 320 so there's",
    "start": "1684399",
    "end": "1690559"
  },
  {
    "text": "literally they store 320 320 byte size weights so that's a total of 100 and 2",
    "start": "1690559",
    "end": "1697360"
  },
  {
    "text": "400 weights in each and there's four instances of that on the chip one two",
    "start": "1697360",
    "end": "1702799"
  },
  {
    "text": "three four so there's over four hundred thousand multiply accumulates that are on the",
    "start": "1702799",
    "end": "1708000"
  },
  {
    "text": "chip and we use them to generate a 320 element fused dot product okay and i'll visit",
    "start": "1708000",
    "end": "1714960"
  },
  {
    "text": "that again because it's an important concept it's a fuse dot product and then we're taking the 320 elements and",
    "start": "1714960",
    "end": "1721039"
  },
  {
    "text": "computing the the sum and doing a single round off so we don't lose too much we",
    "start": "1721039",
    "end": "1726240"
  },
  {
    "text": "don't spill too much numerical uh accuracy as a result of repeated round offs",
    "start": "1726240",
    "end": "1732559"
  },
  {
    "text": "all of this really combines to give us what what is the goal of this",
    "start": "1732559",
    "end": "1737919"
  },
  {
    "text": "initial chip was as much compute density uh per silicon area as we could and that",
    "start": "1737919",
    "end": "1743760"
  },
  {
    "text": "that we hoped in turn to add value to to our customers right so the goal was to",
    "start": "1743760",
    "end": "1748799"
  },
  {
    "text": "expose as much computational density and communication bandwidth so that we can",
    "start": "1748799",
    "end": "1753840"
  },
  {
    "text": "build scalable systems from it in the center of the chip we've got our vector processor our vxm and it sits",
    "start": "1753840",
    "end": "1761039"
  },
  {
    "text": "right at the the center of the chip for one reason it has a lot of bisection bandwidth right at the center of the chip we've got streams going east and",
    "start": "1761039",
    "end": "1767600"
  },
  {
    "text": "streams going west and so we can keep the vector processor fed completely",
    "start": "1767600",
    "end": "1772640"
  },
  {
    "text": "fully fully fed as well as you can see along the outside of the chip is where all the ios are",
    "start": "1772640",
    "end": "1778480"
  },
  {
    "text": "we've got a pcie gen 4 interface to talk to the host a host cpu",
    "start": "1778480",
    "end": "1784080"
  },
  {
    "text": "and we've got these chip to chip links these chip the chip links are ringed around the outside of the the chip and",
    "start": "1784080",
    "end": "1790720"
  },
  {
    "text": "that's what we use for building scalable networks from",
    "start": "1790720",
    "end": "1795840"
  },
  {
    "text": "all right so as instructions execute from this south to north like i said you can you can kind of visualize them as",
    "start": "1796799",
    "end": "1803919"
  },
  {
    "text": "having different um little micro ops for example and i'll give this example again",
    "start": "1803919",
    "end": "1809360"
  },
  {
    "text": "we might do several things for it for example at time 1 we're going to read some tensor onto a stream",
    "start": "1809360",
    "end": "1815200"
  },
  {
    "text": "at time 2 we might add some bias to that tensor and we're going to flow that to",
    "start": "1815200",
    "end": "1820880"
  },
  {
    "text": "our sxm unit which is our switching unit and the sxm unit does shifting it does",
    "start": "1820880",
    "end": "1826880"
  },
  {
    "text": "lane permutation think about moving the elements within the vector",
    "start": "1826880",
    "end": "1832080"
  },
  {
    "text": "and then lastly maybe we'll install those weights in the mxm perform a convolution or a matte mall and then at",
    "start": "1832080",
    "end": "1839600"
  },
  {
    "text": "time five we're going to take those results and write them out to memory this shows you how we're able to kind of",
    "start": "1839600",
    "end": "1845200"
  },
  {
    "text": "chain those small operations together and the conduit through which they're chained are the streaming registers this",
    "start": "1845200",
    "end": "1852000"
  },
  {
    "text": "this this notion of a streaming registers uh is what allows us to kind of very efficiently take the",
    "start": "1852000",
    "end": "1858880"
  },
  {
    "text": "output from one and chain it to the inputs to another so that we're not going back and forth to main memory so",
    "start": "1858880",
    "end": "1864799"
  },
  {
    "text": "this allows us to do kind of these more complex operations with only a read and a write",
    "start": "1864799",
    "end": "1871360"
  },
  {
    "text": "at the very beginning and the end of it at the center of a domain-specific",
    "start": "1871360",
    "end": "1878000"
  },
  {
    "start": "1875000",
    "end": "2087000"
  },
  {
    "text": "architecture is a domain-specific instruction set so as i mentioned our",
    "start": "1878000",
    "end": "1883679"
  },
  {
    "text": "our chip is disaggregated disaggregated into the different functional units and",
    "start": "1883679",
    "end": "1889120"
  },
  {
    "text": "those functional units correspond to instruction control which is the icu which is the the small",
    "start": "1889120",
    "end": "1895279"
  },
  {
    "text": "little sliver we're constituting about three percent of the chip you look down here it's literally down here in this",
    "start": "1895279",
    "end": "1901360"
  },
  {
    "text": "little region down there that is the instruction control that's dispatching",
    "start": "1901360",
    "end": "1906799"
  },
  {
    "text": "uh instructions across 144 independent instruction units on the",
    "start": "1906799",
    "end": "1912080"
  },
  {
    "text": "chip there's a memory functional unit that does as i mentioned reads and writes",
    "start": "1912080",
    "end": "1917360"
  },
  {
    "text": "gathers and scatters along with that it has an address generation unit and this address generation unit is a way for us",
    "start": "1917360",
    "end": "1924559"
  },
  {
    "text": "to very efficiently encode very regular strided references in other words if you have a known access pattern",
    "start": "1924559",
    "end": "1932080"
  },
  {
    "text": "that looks like kind of nested loops then you can very easily represent that with just two or three instructions to",
    "start": "1932080",
    "end": "1938720"
  },
  {
    "text": "to capture the stride and that reference pattern the vector processor does a bulk of",
    "start": "1938720",
    "end": "1944880"
  },
  {
    "text": "heavy lifting it does all the point-wise elemental operations it has what you would expect a variety",
    "start": "1944880",
    "end": "1952000"
  },
  {
    "text": "of add subtract multiply uh reciprocal square root it has activation functions such as relu",
    "start": "1952000",
    "end": "1959760"
  },
  {
    "text": "tange it also has some transcendentals as well so uh the mxm is the",
    "start": "1959760",
    "end": "1967519"
  },
  {
    "text": "the big the big functional units that are sitting at the east and west you know as bookends on the chip and that it",
    "start": "1967519",
    "end": "1974399"
  },
  {
    "text": "it does very little i like to think of it as a big and dumb functional unit it's a very big functional unit it's",
    "start": "1974399",
    "end": "1979440"
  },
  {
    "text": "very simple in that you can install weights you can apply activations to it by controlling",
    "start": "1979440",
    "end": "1985840"
  },
  {
    "text": "the activation buffer and that's about it it generates results",
    "start": "1985840",
    "end": "1991120"
  },
  {
    "text": "very very efficiently and it's like i said a very big very efficient but",
    "start": "1991120",
    "end": "1997120"
  },
  {
    "text": "limited functional unit in what it's what it's doing the sxm is our switch execution module",
    "start": "1997120",
    "end": "2004000"
  },
  {
    "text": "and that does um all the data shifting data manipulation and movement within the",
    "start": "2004000",
    "end": "2009600"
  },
  {
    "text": "vector and across vectors so we think about shifting vectors north and south permuting",
    "start": "2009600",
    "end": "2015760"
  },
  {
    "text": "vectors to create a bijective map a permutation map as well as a distribute a",
    "start": "2015760",
    "end": "2021360"
  },
  {
    "text": "distribution function so think about your communication your communication hierarchy as i can move data within the",
    "start": "2021360",
    "end": "2029039"
  },
  {
    "text": "super lane very inexpensively but as i'm moving data further in other words moving data across super lanes is more",
    "start": "2029039",
    "end": "2036240"
  },
  {
    "text": "expensive um so there's there's operations for example like rotate and",
    "start": "2036240",
    "end": "2042000"
  },
  {
    "text": "transpose which are strictly within the super lane allows you to be very very efficient so you can do a for example a",
    "start": "2042000",
    "end": "2048800"
  },
  {
    "text": "16 by 16 transpose in just 16 cycles so you can take 256 elements and turn it um",
    "start": "2048800",
    "end": "2055599"
  },
  {
    "text": "you know rotate the columns and and rows very very efficiently in memory",
    "start": "2055599",
    "end": "2061760"
  },
  {
    "text": "and then lastly we've got our chip to chip where our communication uh links and this these have",
    "start": "2061760",
    "end": "2067358"
  },
  {
    "text": "just a handful of instructions to send receive and then there's a unique one here that's called",
    "start": "2067359",
    "end": "2073358"
  },
  {
    "text": "d skew and that is so that we can manage the uh what we call the skew across those links and that is to keep them in",
    "start": "2073359",
    "end": "2080398"
  },
  {
    "text": "a lock step uh manner to give the illusion of a synchronous communication fabric",
    "start": "2080399",
    "end": "2087440"
  },
  {
    "start": "2087000",
    "end": "2130000"
  },
  {
    "text": "of course with that instruction set comes a data type support we support several of these data types",
    "start": "2087440",
    "end": "2093440"
  },
  {
    "text": "natively in hardware and i outlined them here in yellow and that's int 8 and uint",
    "start": "2093440",
    "end": "2098560"
  },
  {
    "text": "8 as well as float 16. so the big mxm units can operate uh natively on signed",
    "start": "2098560",
    "end": "2105440"
  },
  {
    "text": "and unsigned integer as well as floating point data",
    "start": "2105440",
    "end": "2112079"
  },
  {
    "text": "again unique to this is these are 8 or 16 bit inputs that are accumulated as either in",
    "start": "2112079",
    "end": "2119280"
  },
  {
    "text": "32 for integer arithmetic or fp32 so we're accumulating to a more precise a",
    "start": "2119280",
    "end": "2124960"
  },
  {
    "text": "higher a larger precision than the the inputs",
    "start": "2124960",
    "end": "2131000"
  },
  {
    "start": "2130000",
    "end": "2176000"
  },
  {
    "text": "so all of this is kind of motivated some some interesting trends and it really is",
    "start": "2131520",
    "end": "2136880"
  },
  {
    "text": "again coming from that the concept that communication and computation are two sides of the same coin",
    "start": "2136880",
    "end": "2143359"
  },
  {
    "text": "more importantly as we see by this this graph from mark horowitz issc issc",
    "start": "2143359",
    "end": "2150160"
  },
  {
    "text": "keynote uh several years ago um it's a little bit dated but the concepts here are so important i just",
    "start": "2150160",
    "end": "2156320"
  },
  {
    "text": "want to i want to re-emphasize it uh and and point out that this was was really i",
    "start": "2156320",
    "end": "2162320"
  },
  {
    "text": "think a turning point and really embracing this data parallel approach really helped kind of move machine",
    "start": "2162320",
    "end": "2169280"
  },
  {
    "text": "learning into to that realm of the new killer app for these kinds of domain specific architectures",
    "start": "2169280",
    "end": "2176640"
  },
  {
    "start": "2176000",
    "end": "2276000"
  },
  {
    "text": "um more importantly um there's an energy difference the dramatic energy",
    "start": "2176640",
    "end": "2181839"
  },
  {
    "text": "difference between adding 8-bit integers and adding floating point numbers for",
    "start": "2181839",
    "end": "2186880"
  },
  {
    "text": "example or multiplying data compared to adding data there can be an order of magnitude difference but often a 4x or",
    "start": "2186880",
    "end": "2193920"
  },
  {
    "text": "2x difference so you want to choose the right data type that provides the most energy efficient solution",
    "start": "2193920",
    "end": "2200400"
  },
  {
    "text": "that satisfies your your accuracy requirements now remember we're we're we're using",
    "start": "2200400",
    "end": "2206720"
  },
  {
    "text": "these data types so that we can represent some hidden space in a in a machine learning model all of which is",
    "start": "2206720",
    "end": "2212880"
  },
  {
    "text": "being um characterized and representing a larger state space that that will have",
    "start": "2212880",
    "end": "2218960"
  },
  {
    "text": "some accuracy to it and again the idea is to to provide the highest accuracy",
    "start": "2218960",
    "end": "2224160"
  },
  {
    "text": "with the lowest precision and therefore have the best energy consumption",
    "start": "2224160",
    "end": "2229520"
  },
  {
    "text": "and this is a nice example of kind of where the energy goes the actual energy to do that computation is often quite",
    "start": "2229520",
    "end": "2236720"
  },
  {
    "text": "small but the energy just accessing the register file accessing your operands",
    "start": "2236720",
    "end": "2243040"
  },
  {
    "text": "the control unit to actually dispatch the control and do the decode is often",
    "start": "2243040",
    "end": "2248480"
  },
  {
    "text": "expensive and the actual cash access is often an expensive component as well",
    "start": "2248480",
    "end": "2254800"
  },
  {
    "text": "so part of that is we have a simdi uh cindy um 320 element uh execution",
    "start": "2254800",
    "end": "2261920"
  },
  {
    "text": "model so that we can amortize that control overhead across 320 elements it allows us to take",
    "start": "2261920",
    "end": "2268640"
  },
  {
    "text": "advantage of data parallelism where it exists and where we can efficiently use it within tensors",
    "start": "2268640",
    "end": "2276240"
  },
  {
    "start": "2276000",
    "end": "2400000"
  },
  {
    "text": "okay so as i mentioned the the functional control units are disaggregated but at the heart of each",
    "start": "2277119",
    "end": "2283200"
  },
  {
    "text": "one of them they all have to support several uh several you know native instructions",
    "start": "2283200",
    "end": "2288960"
  },
  {
    "text": "one of which obviously is instruction fetching they all have to fetch instructions they all have to support a",
    "start": "2288960",
    "end": "2294400"
  },
  {
    "text": "noaa and the no op is a special instruction here because it occupies time it",
    "start": "2294400",
    "end": "2299440"
  },
  {
    "text": "consumes one cycle so it is the means by which the compiler",
    "start": "2299440",
    "end": "2305119"
  },
  {
    "text": "will coordinate the arrival of the data and the instructions that are executing on it",
    "start": "2305119",
    "end": "2311680"
  },
  {
    "text": "as data is is flowing east and west the instructions are flowing north and as the two",
    "start": "2311680",
    "end": "2318640"
  },
  {
    "text": "intersect that's where the action happens and so the instruction is executed the data is used to um",
    "start": "2318640",
    "end": "2325839"
  },
  {
    "text": "process on and we can use the stream registers to communicate the results between the different",
    "start": "2325839",
    "end": "2331599"
  },
  {
    "text": "functional units very important here is two instructions",
    "start": "2331599",
    "end": "2337040"
  },
  {
    "text": "for on-chip synchronization and that's the sync and notify the synchronization",
    "start": "2337040",
    "end": "2342400"
  },
  {
    "text": "instruction allows a uh an icu to park so it parks the icu and it waits for a different icu",
    "start": "2342400",
    "end": "2350400"
  },
  {
    "text": "or from the host either either one to to notify or wake up all those",
    "start": "2350400",
    "end": "2356880"
  },
  {
    "text": "functional units and that's necessary because as the chip comes out of reset all these different functional units 144",
    "start": "2356880",
    "end": "2364000"
  },
  {
    "text": "functional ants are all loosey-goosey and they're all independent and and they're not coordinated so they have to",
    "start": "2364000",
    "end": "2371119"
  },
  {
    "text": "be synchronized bring them to a synchronization point and then after we've notified they kind of like",
    "start": "2371119",
    "end": "2377440"
  },
  {
    "text": "released release the hounds and they're all uh in lockstep at that point and at",
    "start": "2377440",
    "end": "2382640"
  },
  {
    "text": "that moment forward the compiler can use dead reckoning think about they know the",
    "start": "2382640",
    "end": "2388400"
  },
  {
    "text": "exact location of everything and every instruction and every piece of data on the chip and they use that dead",
    "start": "2388400",
    "end": "2394160"
  },
  {
    "text": "reckoning to figure out where every piece of data is going forward",
    "start": "2394160",
    "end": "2400079"
  },
  {
    "start": "2400000",
    "end": "2485000"
  },
  {
    "text": "okay so let's look at and punch into what this super lane looks like as i mentioned the super lane",
    "start": "2400640",
    "end": "2407599"
  },
  {
    "text": "is the the unit of kind of the base unit in which the chip micro architecture is",
    "start": "2407599",
    "end": "2412960"
  },
  {
    "text": "based on a super lane you could think about taking the functional units that are",
    "start": "2412960",
    "end": "2418079"
  },
  {
    "text": "common in a mini core either the memory unit the data movement the network interface and all the alus",
    "start": "2418079",
    "end": "2426400"
  },
  {
    "text": "and we spread them out across the super lane and now data is going to be moving east and west on this super lane so that",
    "start": "2426400",
    "end": "2432960"
  },
  {
    "text": "we can take advantage of that data flow locality as it flows past",
    "start": "2432960",
    "end": "2438720"
  },
  {
    "text": "so again the base the base unit here and you can think about where we're taking our tensors our large uh large um you",
    "start": "2438720",
    "end": "2445760"
  },
  {
    "text": "know multi-dimension tensors and we're breaking them down into a rank two tensor and that rank 2 tensor",
    "start": "2445760",
    "end": "2452480"
  },
  {
    "text": "will fit on the underlying hardware here so the inner dimension the maximum we can do is 320 elements the outer",
    "start": "2452480",
    "end": "2460000"
  },
  {
    "text": "dimension is is you know nebulous it's a streaming time so you take the",
    "start": "2460000",
    "end": "2465440"
  },
  {
    "text": "inner dimension as your vector length the outer dimension is your streaming time so for example a 320 by 1024 matrix",
    "start": "2465440",
    "end": "2472960"
  },
  {
    "text": "is represented by 320 element vector streamed across that for 10 24 cycles so",
    "start": "2472960",
    "end": "2478960"
  },
  {
    "text": "it allows you to have two dimensions uh in in hardware",
    "start": "2478960",
    "end": "2485119"
  },
  {
    "start": "2485000",
    "end": "2596000"
  },
  {
    "text": "at the center of the chip is our vector processor and the vector processor is really it uses this this 320 lane",
    "start": "2486160",
    "end": "2493440"
  },
  {
    "text": "abstraction and we we fit 16 vector processors in each lane so the way you can think about",
    "start": "2493440",
    "end": "2500319"
  },
  {
    "text": "this is logically we have 320 elements that are that are flowing like uh flowing",
    "start": "2500319",
    "end": "2507280"
  },
  {
    "text": "through the chip and we've got 16 vector processors that can intercept and use",
    "start": "2507280",
    "end": "2512480"
  },
  {
    "text": "those to do various point wise element uh operations on them",
    "start": "2512480",
    "end": "2517760"
  },
  {
    "text": "now in practice now in in that's the logical you know architecturally that that they're viewed as as you know",
    "start": "2517760",
    "end": "2525440"
  },
  {
    "text": "16 kind of in the same lane but in reality they're organized as this kind",
    "start": "2525440",
    "end": "2530560"
  },
  {
    "text": "of 4x4 mesh because they have to be laid out on the chip and we organize them as",
    "start": "2530560",
    "end": "2535680"
  },
  {
    "text": "a 4x4 mesh you can chain them all together to get this logical kind of 16",
    "start": "2535680",
    "end": "2540720"
  },
  {
    "text": "vector processors in a single lane it provides a lot of flexibility it is a big workhorse it does",
    "start": "2540720",
    "end": "2547920"
  },
  {
    "text": "all it supports fp32 operations as well as fp16 as well as int 8 um so it",
    "start": "2547920",
    "end": "2554960"
  },
  {
    "text": "provides it provides a variety of data type conversions and of course all the activation functions",
    "start": "2554960",
    "end": "2561599"
  },
  {
    "text": "uh for example so so this gives a nice example of how you might map a simple",
    "start": "2561599",
    "end": "2567359"
  },
  {
    "text": "operation that does a uh an accumulation followed by an ad a relu",
    "start": "2567359",
    "end": "2573839"
  },
  {
    "text": "and then a conversion a cast operation and it shows how those might be mapped to different alus",
    "start": "2573839",
    "end": "2580319"
  },
  {
    "text": "and all those alus have access to the streams again that's the idea is that the streams",
    "start": "2580319",
    "end": "2586240"
  },
  {
    "text": "represent the conduit through which we can chain and share and and be able to",
    "start": "2586240",
    "end": "2591680"
  },
  {
    "text": "uh communicate those uh results very efficiently continuing with this um the super lane",
    "start": "2591680",
    "end": "2598560"
  },
  {
    "start": "2596000",
    "end": "2694000"
  },
  {
    "text": "i'm gonna plunge in and just talk a little bit about the memory system now remember i i mentioned that the memory system is highly concurrent and in",
    "start": "2598560",
    "end": "2605839"
  },
  {
    "text": "particular the the memory unit is broken into two hemispheres each hemisphere has",
    "start": "2605839",
    "end": "2613680"
  },
  {
    "text": "44 banks of concurrency a total of 88",
    "start": "2613680",
    "end": "2619119"
  },
  {
    "text": "banks of concurrency and um the reason we we have so much memory concurrency is we have 32 streams",
    "start": "2619119",
    "end": "2625440"
  },
  {
    "text": "going east 32 streams going west as well as all the instruction fetches and io",
    "start": "2625440",
    "end": "2632000"
  },
  {
    "text": "that we have going on so the streams help the screen bandwidth as well as the sram",
    "start": "2632000",
    "end": "2638640"
  },
  {
    "text": "bandwidth helps to keep everything fed at full rate and so you can see the the um we call",
    "start": "2638640",
    "end": "2645760"
  },
  {
    "text": "these quads not surprisingly there's four four memory banks in each one and on each side of it you'll see these are",
    "start": "2645760",
    "end": "2652000"
  },
  {
    "text": "the different stream registers that i mentioned and so as you load something into memory it literally starts flowing",
    "start": "2652000",
    "end": "2658720"
  },
  {
    "text": "in an east or west direction and it starts flowing in these stream registers so that's when i mentioned if you do a",
    "start": "2658720",
    "end": "2664800"
  },
  {
    "text": "load in a normal jeep general purpose register you can come back tomorrow and it'll still be there in this",
    "start": "2664800",
    "end": "2671119"
  },
  {
    "text": "architecture if you do a load you better have something to do with that data because it's moving and so if you don't",
    "start": "2671119",
    "end": "2677359"
  },
  {
    "text": "do anything with it it literally just going to fall off the end of the chip so the idea here is you you have to have",
    "start": "2677359",
    "end": "2683280"
  },
  {
    "text": "something in mind you're going to load some data you're going to do something on it and maybe you're going to store it or do something beyond that but you have",
    "start": "2683280",
    "end": "2689920"
  },
  {
    "text": "to kind of think about how how you're going to use that data",
    "start": "2689920",
    "end": "2695280"
  },
  {
    "start": "2694000",
    "end": "2791000"
  },
  {
    "text": "the switch execution module as i mentioned uh this is kind of the swiss army knife of of data movement and that",
    "start": "2695520",
    "end": "2702160"
  },
  {
    "text": "includes a distributor that allows us to very efficiently do onto mapping so we can",
    "start": "2702160",
    "end": "2708079"
  },
  {
    "text": "take take any of the 16 bytes within the super lane and we can rearrange them with with utter impunity we can just",
    "start": "2708079",
    "end": "2714400"
  },
  {
    "text": "shuffle them up uh we can take the transposer and we can do um different transfer uh trans transpo",
    "start": "2714400",
    "end": "2721520"
  },
  {
    "text": "transpositions either one by one four by four or 16 16 by 16 transpose",
    "start": "2721520",
    "end": "2726960"
  },
  {
    "text": "we have a permuter and a shifter and that permuter allows us to do an uh an",
    "start": "2726960",
    "end": "2732079"
  },
  {
    "text": "arbitrary a bijective mapping so to take your 320 elements and to do a bijective",
    "start": "2732079",
    "end": "2737440"
  },
  {
    "text": "map maybe we're going to reverse them for example and it allows you to flip them entirely around using this this",
    "start": "2737440",
    "end": "2743440"
  },
  {
    "text": "permuter and similarly it has a shifter that has uh very very common operations to shift",
    "start": "2743440",
    "end": "2749280"
  },
  {
    "text": "these tensors up or down and you can shift in zeros for example the zero pads and some vectors uh as an example",
    "start": "2749280",
    "end": "2757680"
  },
  {
    "text": "and it also has uh you can see the little tx and rx blocks here these are the transmit and the receive side and",
    "start": "2757680",
    "end": "2763280"
  },
  {
    "text": "that's actually what's driving the chip to chip links so our chip to chip",
    "start": "2763280",
    "end": "2768640"
  },
  {
    "text": "links are scheduled just like our mxm and our vector and our sxm and memory",
    "start": "2768640",
    "end": "2774800"
  },
  {
    "text": "our units are they are literally scheduled uh and this is very different than than literally any other",
    "start": "2774800",
    "end": "2781520"
  },
  {
    "text": "conventional cpu or gpu out there that uses a nic that's very loosely coupled right you you program up some rdma work",
    "start": "2781520",
    "end": "2789040"
  },
  {
    "text": "request and that that's going to cause some amount of work to be done on your behalf",
    "start": "2789040",
    "end": "2794240"
  },
  {
    "start": "2791000",
    "end": "2834000"
  },
  {
    "text": "so let's jump in to the system architecture now that we've got a little bit of our bearings about the chip",
    "start": "2794240",
    "end": "2799839"
  },
  {
    "text": "architecture let's jump in and see how this all ties together to build scalable robust",
    "start": "2799839",
    "end": "2806079"
  },
  {
    "text": "reliable systems at the system level and we start by just kind of recognizing that we have to take this and package it",
    "start": "2806079",
    "end": "2813520"
  },
  {
    "text": "into a packaging hierarchy and this packaging hierarchy is really important because it's going to constrain your",
    "start": "2813520",
    "end": "2819839"
  },
  {
    "text": "topology choice and your your um how many how many pins you can escape",
    "start": "2819839",
    "end": "2825920"
  },
  {
    "text": "for example so so it's really an important aspect of making your topology and your packaging nicely impedance",
    "start": "2825920",
    "end": "2832880"
  },
  {
    "text": "matched so the objectives of our topology are really multi-fold we really want to have",
    "start": "2832880",
    "end": "2839119"
  },
  {
    "start": "2834000",
    "end": "2870000"
  },
  {
    "text": "a low network diameter and we want to build a direct network like i said we're going to be building",
    "start": "2839119",
    "end": "2845520"
  },
  {
    "text": "the from the same building blocks here it's going to be our processing elements and our switching elements it's going to",
    "start": "2845520",
    "end": "2850960"
  },
  {
    "text": "be both and we use that to build direct networks an example of a direct network is for example mesh taurus",
    "start": "2850960",
    "end": "2859359"
  },
  {
    "text": "flattened butterfly dragonfly uh an example of an indirect network would be a full glow or a factory for example",
    "start": "2859359",
    "end": "2865680"
  },
  {
    "text": "where you've got a endpoint and you've got a switching element",
    "start": "2865680",
    "end": "2870800"
  },
  {
    "text": "and then making that a packaging aware topology is really important so what we did is like i said the contrast with",
    "start": "2870880",
    "end": "2877440"
  },
  {
    "text": "direct networks or indirect networks where you've got routers and processors our processors and routers are kind of",
    "start": "2877440",
    "end": "2883440"
  },
  {
    "text": "co-mingled and when we use this to create a direct network that we call a software scheduled direct network",
    "start": "2883440",
    "end": "2891680"
  },
  {
    "text": "and it's really a key the key distinction because we're not routing packets we're scheduling tensors on",
    "start": "2891680",
    "end": "2897760"
  },
  {
    "text": "those links the other thing that's very different is our",
    "start": "2897760",
    "end": "2904160"
  },
  {
    "text": "flow control instead of the flow control being kind of credit based and you sense",
    "start": "2904160",
    "end": "2909280"
  },
  {
    "text": "congestion and push back on the host when you overdo it in other words you're going to pile a bunch of things in the",
    "start": "2909280",
    "end": "2915520"
  },
  {
    "text": "network and let it work its way through it until it gets congested and then it starts to insert back pressure in the",
    "start": "2915520",
    "end": "2921760"
  },
  {
    "text": "form of explicit congestion notification or ecn messages pause frames if you're",
    "start": "2921760",
    "end": "2927520"
  },
  {
    "text": "running on ethernet and that back pressure is going to ultimately uh hurt your performance as",
    "start": "2927520",
    "end": "2934559"
  },
  {
    "text": "as you stop stop uh stop processing on the data waiting for the tree saturation",
    "start": "2934559",
    "end": "2940079"
  },
  {
    "text": "to resolve and then starts flowing again instead what we do is we essentially control or paste those",
    "start": "2940079",
    "end": "2947359"
  },
  {
    "text": "links in software so software knows exactly how fast we can drive those",
    "start": "2947359",
    "end": "2952640"
  },
  {
    "text": "links and no faster we can operate them up to about 96 efficiency by pushing",
    "start": "2952640",
    "end": "2958559"
  },
  {
    "text": "them all the way up to that limit um but going further would would cause dropping of packets right so we can we can take",
    "start": "2958559",
    "end": "2965119"
  },
  {
    "text": "it all the way up to the end and of course all this is really fit into that packaging schema so you can",
    "start": "2965119",
    "end": "2971760"
  },
  {
    "start": "2967000",
    "end": "3030000"
  },
  {
    "text": "see we've taken a chip we've combined it with a heatsink and mounted it on a card",
    "start": "2971760",
    "end": "2977200"
  },
  {
    "text": "and we take eight of those cards and we fit them into a node and the the idea here that we're trying",
    "start": "2977200",
    "end": "2983200"
  },
  {
    "text": "to expose and exploit is the concept of packaging locality things that are close together can communicate inexpensively",
    "start": "2983200",
    "end": "2991200"
  },
  {
    "text": "and abundantly and we have literally 28 links these are all to all",
    "start": "2991200",
    "end": "2996240"
  },
  {
    "text": "so these eight eight tsps are connected in full in a fully connected way to each",
    "start": "2996240",
    "end": "3003119"
  },
  {
    "text": "other so if you look in here there's 28 uh links in these little low low profile",
    "start": "3003119",
    "end": "3008880"
  },
  {
    "text": "uh uh chip to chip links and then we put a hood on it to kind of hide all the the sausage making and we stuff that into a",
    "start": "3008880",
    "end": "3015599"
  },
  {
    "text": "rack no that rack has a total of uh nine nodes in it we we have eight nodes",
    "start": "3015599",
    "end": "3022240"
  },
  {
    "text": "plus one what we call a spare redundant node that we can take advantage of in case we have hardware failures",
    "start": "3022240",
    "end": "3030480"
  },
  {
    "start": "3030000",
    "end": "3272000"
  },
  {
    "text": "so the low diameter network is really important because it really drives to the first order your overall system",
    "start": "3030480",
    "end": "3037119"
  },
  {
    "text": "performance so what we want to do is be able to build as large of a network as possible with as few hops and then what",
    "start": "3037119",
    "end": "3044480"
  },
  {
    "text": "we want to do is relax that just a bit by taking one additional hop to do non-minimal",
    "start": "3044480",
    "end": "3050960"
  },
  {
    "text": "routing and by non-minimal routing what i mean is if you think about you think about the network you can take any two tsps",
    "start": "3050960",
    "end": "3058240"
  },
  {
    "text": "into an arbitrary source destination pair there's exactly one minimal route",
    "start": "3058240",
    "end": "3063440"
  },
  {
    "text": "between them but there may be many in fact there is many many uh mult there's multiple",
    "start": "3063440",
    "end": "3069599"
  },
  {
    "text": "non-minimal routes between them so that's the the idea here is we want to use those non-minimal routes",
    "start": "3069599",
    "end": "3076160"
  },
  {
    "text": "to take advantage of all the available bisection bandwidth so the dragonfly topology is a",
    "start": "3076160",
    "end": "3081839"
  },
  {
    "text": "hierarchical topology that takes into account the packaging structure to try to match the packaging with the topology",
    "start": "3081839",
    "end": "3090079"
  },
  {
    "text": "and create what's what's known as a virtual router and so we use our node to build a virtual router that's 32 ports",
    "start": "3090079",
    "end": "3098160"
  },
  {
    "text": "on each virtual router and that allows us to be able to connect those nodes up in a in a global system",
    "start": "3098160",
    "end": "3105359"
  },
  {
    "text": "and share those across across the broader you know distributed system",
    "start": "3105359",
    "end": "3111359"
  },
  {
    "text": "um so that's the idea and allows you to kind of think about this from a local topology and a global topology again",
    "start": "3111359",
    "end": "3118319"
  },
  {
    "text": "these are hierarchical so they're fully connected within the local group and fully connected within the global",
    "start": "3118319",
    "end": "3124720"
  },
  {
    "text": "group the local topology here has some constraints and that has to have some",
    "start": "3124720",
    "end": "3130319"
  },
  {
    "text": "amount of internal speed up so in other words there's more internal bandwidth in the in the local group than there is",
    "start": "3130319",
    "end": "3136400"
  },
  {
    "text": "globally because we're going to be using that local as a as a virtual switch and",
    "start": "3136400",
    "end": "3141760"
  },
  {
    "text": "we're going to be routing some traffic through it and then the idea here is to go from a",
    "start": "3141760",
    "end": "3147520"
  },
  {
    "text": "single tsp and we can scale all the way up to uh at the largest configuration over ten thousand tsps in a system",
    "start": "3147520",
    "end": "3156319"
  },
  {
    "text": "okay so we've got abundance amounts of both local uh local bandwidth and global bandwidth and",
    "start": "3156319",
    "end": "3162960"
  },
  {
    "text": "each rack has a spare note in it so that's how we kind of deal with",
    "start": "3162960",
    "end": "3168960"
  },
  {
    "text": "redundancy and reliability in a deterministic system remember i said we're gonna have to make some tradeoffs",
    "start": "3168960",
    "end": "3175280"
  },
  {
    "text": "along the way one of the those trade-offs affects our redundancy and reliability",
    "start": "3175280",
    "end": "3180800"
  },
  {
    "text": "faults and handling those faults and exceptions are notoriously non-deterministic right if we knew when",
    "start": "3180800",
    "end": "3186400"
  },
  {
    "text": "all the faults would happen we could account for it but we don't and so cables fail power supplies fail chips",
    "start": "3186400",
    "end": "3193440"
  },
  {
    "text": "fail and we have to have a means to handle that the way that we handle that is if you're",
    "start": "3193440",
    "end": "3198800"
  },
  {
    "text": "running your inference and your inference fails the runtime system can replay it and",
    "start": "3198800",
    "end": "3204559"
  },
  {
    "text": "kind of kind of replay it once to see if the problem is kind of a persistent failure or if it's a transient value you",
    "start": "3204559",
    "end": "3210240"
  },
  {
    "text": "might have a a simple uh you know bit flip that that is transiently resolved",
    "start": "3210240",
    "end": "3216400"
  },
  {
    "text": "if the if there's a more permanent type of failure replaying it doesn't fix it then you can",
    "start": "3216400",
    "end": "3221920"
  },
  {
    "text": "migrate that to a different node and and choose a different set of nodes to run the application on and this is",
    "start": "3221920",
    "end": "3229359"
  },
  {
    "text": "where the topology and the symmetry of the topology matters the dragonfly is",
    "start": "3229359",
    "end": "3234480"
  },
  {
    "text": "very nicely both edge and node symmetric contrast that with a mesh for example if",
    "start": "3234480",
    "end": "3240800"
  },
  {
    "text": "you had a mesh in your note and your job got laid out on that mesh if you got it if you happen to get unlucky and be on",
    "start": "3240800",
    "end": "3246480"
  },
  {
    "text": "the edge of that mesh you have less kind of indra you have less bandwidth than the other nodes do so it's very nicely",
    "start": "3246480",
    "end": "3253760"
  },
  {
    "text": "uh symmetrical and we use that to provide a a",
    "start": "3253760",
    "end": "3258960"
  },
  {
    "text": "reliability story and reliability uh redundant node that we can have the",
    "start": "3258960",
    "end": "3264559"
  },
  {
    "text": "runtime basically migrate and launch the job on a good set of known good hardware",
    "start": "3264559",
    "end": "3270160"
  },
  {
    "text": "in the event of a failure so how does this different than a normal",
    "start": "3270160",
    "end": "3275520"
  },
  {
    "start": "3272000",
    "end": "3339000"
  },
  {
    "text": "uh a normal rdma request let's just think about what happens in a normal rdma request we start at time zero and",
    "start": "3275520",
    "end": "3282880"
  },
  {
    "text": "we have our processor right to the nick to to describe some work request some dma request and it's",
    "start": "3282880",
    "end": "3290240"
  },
  {
    "text": "gonna go off and do a remote request to read some address it's going to send that over to the",
    "start": "3290240",
    "end": "3297040"
  },
  {
    "text": "remote side where it's going to hit the memory controller and it's going to do some reads in the memory controller and",
    "start": "3297040",
    "end": "3302240"
  },
  {
    "text": "that's going to cause some replies to start flowing back those replies are going to flow back all",
    "start": "3302240",
    "end": "3307359"
  },
  {
    "text": "out across the network and then we'll finally at time 5 get the data back and we'll be able to use it so there's a",
    "start": "3307359",
    "end": "3314160"
  },
  {
    "text": "very request reply protocol here in place and those protocols usually",
    "start": "3314160",
    "end": "3319839"
  },
  {
    "text": "use different virtual channel buffers to guarantee deadlock freedom because it is a protocol you can't have replies",
    "start": "3319839",
    "end": "3326079"
  },
  {
    "text": "blocking requests um and that's a that's a fundamental idea so you have",
    "start": "3326079",
    "end": "3331359"
  },
  {
    "text": "virtual channels to to to uh disentangle your your requests and your",
    "start": "3331359",
    "end": "3337359"
  },
  {
    "text": "reply data our communication model is much simpler in that the",
    "start": "3337359",
    "end": "3344720"
  },
  {
    "start": "3339000",
    "end": "3386000"
  },
  {
    "text": "request is never sent instead the compiler knows when the data needs to",
    "start": "3344720",
    "end": "3350720"
  },
  {
    "text": "arrive and simply pushes uh via kind of a send",
    "start": "3350720",
    "end": "3356400"
  },
  {
    "text": "so the destination is doing a send and the recipient is doing a receive and",
    "start": "3356400",
    "end": "3361520"
  },
  {
    "text": "he's just going to know that this data is arriving at this time and then it gets used so so there's no explicit request",
    "start": "3361520",
    "end": "3369280"
  },
  {
    "text": "traffic flowing across the network you can kind of think of this as just reply only traffic where the request is being",
    "start": "3369280",
    "end": "3376480"
  },
  {
    "text": "implicitly communicated through metadata through the compiler right the compilers is essentially scheduling that",
    "start": "3376480",
    "end": "3383760"
  },
  {
    "text": "the the read request so the network as i mentioned the network that extends this concept of",
    "start": "3383760",
    "end": "3390799"
  },
  {
    "start": "3386000",
    "end": "3599000"
  },
  {
    "text": "single chip determinism across the entire system so we needed explicit instruction level support to support um",
    "start": "3390799",
    "end": "3399200"
  },
  {
    "text": "to to give this illusion right and basically what we're doing is we've got all these tsps that are cooperating but",
    "start": "3399200",
    "end": "3406319"
  },
  {
    "text": "they might get out of sync with each other and by that i mean these are plesiocrinous links so they they have",
    "start": "3406319",
    "end": "3412400"
  },
  {
    "text": "some tolerance and that tolerance is is really determined by the crystal that's driving their their their clocks",
    "start": "3412400",
    "end": "3419520"
  },
  {
    "text": "and so if you're using a crystal with 50 parts per million you would expect them to over a million cycles they might",
    "start": "3419520",
    "end": "3426240"
  },
  {
    "text": "drift 50 cycles or so okay so you kind of think about these things as roughly",
    "start": "3426240",
    "end": "3431520"
  },
  {
    "text": "in lockstep within some kind of epoch within some window but not a hundred",
    "start": "3431520",
    "end": "3436720"
  },
  {
    "text": "percent within lockstep and we kind of we use that to our advantage to provide the illusion of synchronous",
    "start": "3436720",
    "end": "3442960"
  },
  {
    "text": "communication even though occasionally we have to tap the brakes and make sure that everything",
    "start": "3442960",
    "end": "3449200"
  },
  {
    "text": "is synchronized okay so instead of instead think of it this way if",
    "start": "3449200",
    "end": "3454559"
  },
  {
    "text": "if you're if your your processing elements get out of sync the first time you hit a barrier",
    "start": "3454559",
    "end": "3460400"
  },
  {
    "text": "this you're going to end up incurring a bunch of waiting time because you're going to be limited by the slowest link",
    "start": "3460400",
    "end": "3465440"
  },
  {
    "text": "and the slowest link is going to come along sometime later and he'll satisfy that barrier",
    "start": "3465440",
    "end": "3470480"
  },
  {
    "text": "well when they're all in lock step when you hit that barrier you satisfy that barrier almost instantly and that that",
    "start": "3470480",
    "end": "3477520"
  },
  {
    "text": "allows us to avoid all the waste fraud and abuse that ordinarily gets",
    "start": "3477520",
    "end": "3482640"
  },
  {
    "text": "accumulated to your barrier waiting time and that's a huge huge benefit of of a",
    "start": "3482640",
    "end": "3488640"
  },
  {
    "text": "synchronous communication model so i just described a little bit here of the isa support specifically have",
    "start": "3488640",
    "end": "3495119"
  },
  {
    "text": "several key pieces of hardware hardware alignment counters and a software alignment counters",
    "start": "3495119",
    "end": "3500960"
  },
  {
    "text": "as well as again those instructions the sync notify desku uh and then to be able to do this",
    "start": "3500960",
    "end": "3507760"
  },
  {
    "text": "runtime d sku so the way that we we structure this is is we set up the the",
    "start": "3507760",
    "end": "3514000"
  },
  {
    "text": "network at the time the job is invoked we synchronize everything and then the runtime kind of does this periodic",
    "start": "3514000",
    "end": "3521200"
  },
  {
    "text": "de-sku to make sure it's it's still in lockstep as the as the program executes",
    "start": "3521200",
    "end": "3526880"
  },
  {
    "text": "so every five milliseconds or so tap the brakes make sure everything's kosher and then proceed and that gives you um a a",
    "start": "3526880",
    "end": "3535680"
  },
  {
    "text": "very you know a minimal synchronous communication fabric that you can use",
    "start": "3535680",
    "end": "3541119"
  },
  {
    "text": "uh to communicate without the need of a lock and by that i mean if you think about",
    "start": "3541119",
    "end": "3548079"
  },
  {
    "text": "how you would communicate in a distributed shared memory machine you're going to have a producer that's going to",
    "start": "3548079",
    "end": "3553520"
  },
  {
    "text": "write some data he's going to do a memory fence to make sure all that data is globally visible",
    "start": "3553520",
    "end": "3558559"
  },
  {
    "text": "and then he's going to modify a flag variable that says it's now safe to consume that that chunk",
    "start": "3558559",
    "end": "3565680"
  },
  {
    "text": "and the the consumer is going to be busy waiting on that flag variable and",
    "start": "3565680",
    "end": "3571119"
  },
  {
    "text": "they're going to see the change in it and say okay i can safely consume it now we don't require that additional lock",
    "start": "3571119",
    "end": "3577200"
  },
  {
    "text": "variable we're literally going to be producing data and we're going to push it out to the consumer",
    "start": "3577200",
    "end": "3583200"
  },
  {
    "text": "and the consumer will know when it's visible because we use time we have the concept of global time and that the",
    "start": "3583200",
    "end": "3590720"
  },
  {
    "text": "sender knows that at time 4273 he's done writing the data and the",
    "start": "3590720",
    "end": "3596880"
  },
  {
    "text": "receiver can now safely consume that data at the same time 4273 or whatever that number happens to",
    "start": "3596880",
    "end": "3604240"
  },
  {
    "text": "be so we're able to use time in a way to provide a lock-free communication fabric",
    "start": "3604240",
    "end": "3610799"
  },
  {
    "text": "and that is just critical and very different than how a distributed shared memory",
    "start": "3610799",
    "end": "3616640"
  },
  {
    "text": "semantics work all right so again all of this is really",
    "start": "3616640",
    "end": "3622799"
  },
  {
    "text": "driven by our compiler and a bare metal programming interface and there's really",
    "start": "3622799",
    "end": "3627920"
  },
  {
    "text": "two two ways of interfacing with with the chip like i said first of all is a compiler we have an auto scaling",
    "start": "3627920",
    "end": "3634960"
  },
  {
    "text": "parallelizing compiler what does that mean it means that you have some model that's gonna ingest that model and it's",
    "start": "3634960",
    "end": "3641119"
  },
  {
    "text": "going to see how many parameters you have and then spread it across enough chips to be able to fit you have to fit",
    "start": "3641119",
    "end": "3647599"
  },
  {
    "text": "that model and then you're going to schedule that on the underlying hardware",
    "start": "3647599",
    "end": "3652799"
  },
  {
    "text": "we have a bare metal programming environment that allows us to have basically complete and utter control of",
    "start": "3652799",
    "end": "3658799"
  },
  {
    "text": "the hardware at kind of the isa level at the very lowest levels if we want to to",
    "start": "3658799",
    "end": "3663920"
  },
  {
    "text": "very explicitly control it if you if you don't want to operate at pi at pi torch or tensorflow you can write these custom",
    "start": "3663920",
    "end": "3671359"
  },
  {
    "text": "custom applications using our bare metal programming interface and then as i said at the bottom here",
    "start": "3671359",
    "end": "3677520"
  },
  {
    "text": "we've got this hardware software interface that's really being managed by the runtime system so if you think about what a parallel",
    "start": "3677520",
    "end": "3684640"
  },
  {
    "text": "invocation looks like we're generating um we're generating multiple",
    "start": "3684640",
    "end": "3690000"
  },
  {
    "text": "collateral files multiple uh files that need to be installed on each tsp",
    "start": "3690000",
    "end": "3696000"
  },
  {
    "text": "they need to be synchronized and then the parallel program is invoked by the by the runtime and then the runtime just",
    "start": "3696000",
    "end": "3702559"
  },
  {
    "text": "kind of stays plugged in to make sure that there's no exceptions if there's an exception the runtime has to respond to",
    "start": "3702559",
    "end": "3708319"
  },
  {
    "text": "it right um one of the one of the unique things",
    "start": "3708319",
    "end": "3714160"
  },
  {
    "text": "about this as i mentioned we had to think about exceptions and how we're going to handle that so that we can",
    "start": "3714160",
    "end": "3720720"
  },
  {
    "text": "short-circuit some of those for example how do we handle arithmetic exceptions if you get a uh an overflow for example",
    "start": "3720720",
    "end": "3728079"
  },
  {
    "text": "we don't want to have a uh a a alu that doesn't add that causes an",
    "start": "3728079",
    "end": "3734000"
  },
  {
    "text": "overflow that would produce a carryout flag for example or an overflow flag if you're familiar with",
    "start": "3734000",
    "end": "3739359"
  },
  {
    "text": "other architectures um instead we choose a priori we choose what we want the semantics to be either",
    "start": "3739359",
    "end": "3745839"
  },
  {
    "text": "saturating or modulo and and for example you know you often will use saturating",
    "start": "3745839",
    "end": "3751280"
  },
  {
    "text": "so that if you're if you're doing some alu operation your gradients saturate at a certain point they don't roll over and",
    "start": "3751280",
    "end": "3757920"
  },
  {
    "text": "they don't you don't overflow or underflow them so it avoids some of the",
    "start": "3757920",
    "end": "3763039"
  },
  {
    "text": "kind of uh exceptions that you would have in the wild because you decide a priori how you want to handle those",
    "start": "3763039",
    "end": "3769359"
  },
  {
    "text": "those arithmetic exceptions should they arise",
    "start": "3769359",
    "end": "3773599"
  },
  {
    "text": "so again the this concept of a bare metal interface or a bare metal program is really built on layers of abstraction",
    "start": "3775039",
    "end": "3781520"
  },
  {
    "text": "at the bottom is really our assembly language which is uh taking taking the",
    "start": "3781520",
    "end": "3786720"
  },
  {
    "text": "the raw instruction api and it's compiling it and producing the the program out the program collateral",
    "start": "3786720",
    "end": "3793839"
  },
  {
    "text": "the object files if you will on top the instruction api is what we call our tensor api and you can think about just",
    "start": "3793839",
    "end": "3800559"
  },
  {
    "text": "operating on normal tensors like you would take tensor a and tensor b and add them or concatenate them or split them",
    "start": "3800559",
    "end": "3808079"
  },
  {
    "text": "for example and then on top of that is a very familiar neural net library that you would see in like tf conf you know",
    "start": "3808079",
    "end": "3815039"
  },
  {
    "text": "constitute we have a nn.com nn.matmall or uh average pool for",
    "start": "3815039",
    "end": "3821280"
  },
  {
    "text": "example so there's there's the neural network library that kind of sits on top of that",
    "start": "3821280",
    "end": "3826960"
  },
  {
    "text": "again the the idea here is we want to make this an efficient target for the compiler",
    "start": "3826960",
    "end": "3832160"
  },
  {
    "text": "but obviously the compiler isn't ready on day one so we had we have multiple ways in which we can kind of program the",
    "start": "3832160",
    "end": "3838640"
  },
  {
    "text": "chip depending on your your use cases and depending on your application for example celeski factorization is a is a",
    "start": "3838640",
    "end": "3846559"
  },
  {
    "text": "high performance computing code that is very common in doing uh linear algebra",
    "start": "3846559",
    "end": "3852559"
  },
  {
    "text": "and we take a symmetric positive difference matrix and we take that and we spread it across multiple chips and",
    "start": "3852559",
    "end": "3858960"
  },
  {
    "text": "then we chew through that very in a very efficient way using vector matrix math",
    "start": "3858960",
    "end": "3864079"
  },
  {
    "text": "and we can get very good performance out of the out of the out of the system and this shows",
    "start": "3864079",
    "end": "3869280"
  },
  {
    "text": "you kind of how we scale across multiple tsps um ultimately this is kind of a",
    "start": "3869280",
    "end": "3875440"
  },
  {
    "text": "a large problem it's an n squared kind of problem so as the matrix grows it becomes harder to fit onto a single chip",
    "start": "3875440",
    "end": "3882000"
  },
  {
    "text": "so we we outgrow a single chip around 7000 elements so we need to start kind",
    "start": "3882000",
    "end": "3887039"
  },
  {
    "text": "of spreading it across multiple chips there's other other applications here",
    "start": "3887039",
    "end": "3892559"
  },
  {
    "text": "for example natural language processing with bert this is a nice example and and just to",
    "start": "3892559",
    "end": "3898160"
  },
  {
    "text": "kind of show you the the the benefit of determinism is",
    "start": "3898160",
    "end": "3903440"
  },
  {
    "text": "you look at our histogram of latency and it's a it's it's virtually this",
    "start": "3903440",
    "end": "3908880"
  },
  {
    "text": "perfectly straight spike of just a single value and there's a small amount of variance",
    "start": "3908880",
    "end": "3915119"
  },
  {
    "text": "because when we're reading inputs in from the host occasionally the host can take a hiccup",
    "start": "3915119",
    "end": "3920559"
  },
  {
    "text": "and and have to replay one of those inputs and that that is part of the",
    "start": "3920559",
    "end": "3925680"
  },
  {
    "text": "non-determinism that i mentioned earlier that that we can't get rid of that that's just part of pcie we have to kind",
    "start": "3925680",
    "end": "3932079"
  },
  {
    "text": "of live with that so we set up the chip to be able to tolerate that and be able",
    "start": "3932079",
    "end": "3937440"
  },
  {
    "text": "to kind of manage that non-determinism interface so we have kind of this this",
    "start": "3937440",
    "end": "3942480"
  },
  {
    "text": "well-defined interface between the host cpu and the tsp itself",
    "start": "3942480",
    "end": "3948000"
  },
  {
    "text": "and so we flow that inputs onto the chip and once it's onto the chip then we start processing and it's completely",
    "start": "3948000",
    "end": "3953520"
  },
  {
    "text": "deterministic from that moment on uh and we can we can uh execute it with",
    "start": "3953520",
    "end": "3958559"
  },
  {
    "text": "with certainty it's it's kind of an interesting observation and ten years ago quality of",
    "start": "3958559",
    "end": "3964480"
  },
  {
    "text": "service or qos was a really sexy topic for a lot of research and in systems architecture",
    "start": "3964480",
    "end": "3970240"
  },
  {
    "text": "providing predictable quality of service and predictable service level agreements",
    "start": "3970240",
    "end": "3975440"
  },
  {
    "text": "uh was really important to be able to build scalable clusters",
    "start": "3975440",
    "end": "3980799"
  },
  {
    "text": "after all your internet scale application will be limited to the slowest link in the network and that's",
    "start": "3980799",
    "end": "3985920"
  },
  {
    "text": "what we really want to be able to do is provide quality of service but we do so from from determinism this this concept",
    "start": "3985920",
    "end": "3992960"
  },
  {
    "text": "of deterministic execution really is a great way of guaranteeing some hard",
    "start": "3992960",
    "end": "3998160"
  },
  {
    "text": "quality of service limits again let's look at gem a gem is a",
    "start": "3998160",
    "end": "4003839"
  },
  {
    "text": "workhorse of a lot of machine learnings where we're doing matrix multiplication",
    "start": "4003839",
    "end": "4009599"
  },
  {
    "text": "and you can see that depending on the size of the matrix being multiplied there's there's certain kind of hardware",
    "start": "4009599",
    "end": "4015520"
  },
  {
    "text": "fitting you can think about it as there's certain hardware characteristics that get exposed at different boundaries right and this",
    "start": "4015520",
    "end": "4022799"
  },
  {
    "text": "is a nice example of looking at kind of an a100 where you see some of that hardware fitting um taking place right",
    "start": "4022799",
    "end": "4029920"
  },
  {
    "text": "and so one of the things that we try to do is be very resilient to that kind of hardware",
    "start": "4029920",
    "end": "4035280"
  },
  {
    "text": "fitting and work across a wide range of if you sweep through that matrix size we",
    "start": "4035280",
    "end": "4042240"
  },
  {
    "text": "want to be able to operate efficiently at all those different operating points so this is really a sweep through those",
    "start": "4042240",
    "end": "4048400"
  },
  {
    "text": "different matrix sizes looking at how our our matrix multiplication utilizes",
    "start": "4048400",
    "end": "4053920"
  },
  {
    "text": "the uh the mxm uh across the the sizes to get a sense",
    "start": "4053920",
    "end": "4059119"
  },
  {
    "text": "as to how sensitive we would be to um to certain uh antagonistic sizes if you",
    "start": "4059119",
    "end": "4064720"
  },
  {
    "text": "will and then we've been making progress as i said you you start with the compiler we",
    "start": "4064720",
    "end": "4070240"
  },
  {
    "text": "started with the compiler from from first principles and that informed our hardware decisions",
    "start": "4070240",
    "end": "4076640"
  },
  {
    "text": "our hardware trade-offs and then of course the compiler isn't done on day one when you tape out but",
    "start": "4076640",
    "end": "4083200"
  },
  {
    "text": "but that it matures with time and the number of models and the generality of it grows and this is a nice example of",
    "start": "4083200",
    "end": "4090079"
  },
  {
    "text": "kind of that growth that growth as we're able to add more models to it add more generality and um",
    "start": "4090079",
    "end": "4097040"
  },
  {
    "text": "be able to tackle more sophisticated models so we're making great progress and the compiler isn't",
    "start": "4097040",
    "end": "4102560"
  },
  {
    "text": "a wonderful way to kind of get your design input into it and get it mapped to the underlying architecture",
    "start": "4102560",
    "end": "4110318"
  },
  {
    "text": "so hopefully i've kind of motivated some of the trade-offs that we made along the way talked about the stream",
    "start": "4110319",
    "end": "4116640"
  },
  {
    "text": "programming to be able to do compute intensive deep learning and we really bring to bear this predictable and",
    "start": "4116640",
    "end": "4123120"
  },
  {
    "text": "repeatable performance and you're probably saying to yourself self aren't all computers predictable and",
    "start": "4123120",
    "end": "4129440"
  },
  {
    "text": "that you get the same answer over and over again and the answer is well kind of and if",
    "start": "4129440",
    "end": "4135600"
  },
  {
    "text": "you just want to convince yourself of that take a take an array of floating point numbers and add them up just take",
    "start": "4135600",
    "end": "4141040"
  },
  {
    "text": "take a million floating point numbers and add them up and then reorder those numbers and add",
    "start": "4141040",
    "end": "4146480"
  },
  {
    "text": "it up again and see if you get the same number you won't get the same number on floating point you'll get the same",
    "start": "4146480",
    "end": "4152238"
  },
  {
    "text": "number on integer because they're associative but floating point numbers are not associated",
    "start": "4152239",
    "end": "4158000"
  },
  {
    "text": "so making that both predictable and repeatable over and over again you get the same result in the same amount of",
    "start": "4158000",
    "end": "4165120"
  },
  {
    "text": "time so it's repeatable both in space and time and if you've ever used the system",
    "start": "4165120",
    "end": "4171199"
  },
  {
    "text": "with caches you know that i might get the same answer but it might be slower the second time depending on if i got",
    "start": "4171199",
    "end": "4177120"
  },
  {
    "text": "some pollution or collateral you know uh conflict cash conflicts from another bad",
    "start": "4177120",
    "end": "4182400"
  },
  {
    "text": "actor or if there's os interference a variety of things kind of confound and",
    "start": "4182400",
    "end": "4188318"
  },
  {
    "text": "intermingle in ways that collude in in in ways that prevent it from being",
    "start": "4188319",
    "end": "4194080"
  },
  {
    "text": "exactly predictable so that predictability and repeatability is essential when you want to use this chip",
    "start": "4194080",
    "end": "4200800"
  },
  {
    "text": "to do control systems for example manufacturing control systems um very",
    "start": "4200800",
    "end": "4206320"
  },
  {
    "text": "time critical latency sensitive control systems it becomes a really really important way",
    "start": "4206320",
    "end": "4212239"
  },
  {
    "text": "of managing the complexity and managing the bounds on which uh the the control",
    "start": "4212239",
    "end": "4217920"
  },
  {
    "text": "system and then really determinism was a means to an end to be able to bring about this",
    "start": "4217920",
    "end": "4224000"
  },
  {
    "text": "vision of software-defined hardware we had to be able to make the underlying chip predictable the compiler needs to",
    "start": "4224000",
    "end": "4231440"
  },
  {
    "text": "track every piece of data as it's flowing on the chip and that had to be a hardware and software philosophy that we",
    "start": "4231440",
    "end": "4238880"
  },
  {
    "text": "had to embrace from first principles and again here the isa is not about abstracting away the details but it's",
    "start": "4238880",
    "end": "4246080"
  },
  {
    "text": "really about expressing and controlling the underlying hardware and we do that with 144 independent instruction control",
    "start": "4246080",
    "end": "4254560"
  },
  {
    "text": "units these are separate fifos that is effectively represent your straight line",
    "start": "4254560",
    "end": "4259600"
  },
  {
    "text": "code that you're executing and these 144 instruction cues can can consume over two terabytes per second of",
    "start": "4259600",
    "end": "4266960"
  },
  {
    "text": "fetch bandwidth so in other words if we're keeping everything busy we're going to be churning through two terabytes per second of instruction",
    "start": "4266960",
    "end": "4273840"
  },
  {
    "text": "bandwidth which we have to keep fed and that's an awful lot for a dram controller but it's it's not much to ask",
    "start": "4273840",
    "end": "4281040"
  },
  {
    "text": "of our sram with over 60 terabytes per second of sram bandwidth it's a very small fraction of the overall",
    "start": "4281040",
    "end": "4288239"
  },
  {
    "text": "main memory balance and then again we expose these architectural uh",
    "start": "4288239",
    "end": "4293760"
  },
  {
    "text": "screen registers and all the sram as well as the instruction buffers so that the compiler can completely reason about",
    "start": "4293760",
    "end": "4301760"
  },
  {
    "text": "program correctness from from beginning to end when the inputs arrive and when",
    "start": "4301760",
    "end": "4306800"
  },
  {
    "text": "the outputs are generated so we've extended this uh this concept",
    "start": "4306800",
    "end": "4311920"
  },
  {
    "text": "of a single chip tsp determinism in that very kind of lock step execution",
    "start": "4311920",
    "end": "4317360"
  },
  {
    "text": "we've extended that to a multi-processor to do software scheduled networking and",
    "start": "4317360",
    "end": "4322960"
  },
  {
    "text": "really that's that's really where we get the value from our system approach is we're able to schedule our network links",
    "start": "4322960",
    "end": "4330159"
  },
  {
    "text": "both minimal or non-minimal to use all the bisection bandwidth in the system",
    "start": "4330159",
    "end": "4335440"
  },
  {
    "text": "and that results in really great all reduced uh all reduced performance i apologize i don't have a nice chart",
    "start": "4335440",
    "end": "4341440"
  },
  {
    "text": "showing the all reduced performance it's in the the pre-print of the paper i'm hoping that this will inspire you to uh",
    "start": "4341440",
    "end": "4347760"
  },
  {
    "text": "attend or at least read the isca papers from 2020 and from upcoming esca paper in 2022.",
    "start": "4347760",
    "end": "4355280"
  },
  {
    "text": "again all of this was intended to uh enable a synchronous communication model",
    "start": "4355280",
    "end": "4360800"
  },
  {
    "text": "so that we can build these large scale systems and then keep the overall diameter of the network down to just a",
    "start": "4360800",
    "end": "4367760"
  },
  {
    "text": "handful of microseconds so that we can make using these these large scale systems",
    "start": "4367760",
    "end": "4372800"
  },
  {
    "text": "efficient and uh and cost effective i want to thank you for uh for enduring",
    "start": "4372800",
    "end": "4380000"
  },
  {
    "text": "with me this was a long talk and i hope you found it useful and i want to encourage you to reach out to thegrok.com and look at our careers page",
    "start": "4380000",
    "end": "4387760"
  },
  {
    "text": "and see if there's anything that's exciting to you um if you want you can grab a capture of that that'll take you to the grock.com",
    "start": "4387760",
    "end": "4394080"
  },
  {
    "text": "site and i appreciate everyone's attendance and their uh their attention",
    "start": "4394080",
    "end": "4399760"
  },
  {
    "text": "i'll take any questions if you're old enough you've seen this talk before",
    "start": "4399760",
    "end": "4406400"
  },
  {
    "text": "um which is not bad but which is not a bad thing because it was a great it's a great idea every time it's come up um",
    "start": "4406400",
    "end": "4412880"
  },
  {
    "text": "you didn't mention a couple of things i sort of expected um and that was",
    "start": "4412880",
    "end": "4419520"
  },
  {
    "text": "some sort is where on your compiler chart was when you introduced some sort of",
    "start": "4419520",
    "end": "4425440"
  },
  {
    "text": "virtualization so you could run a problem bigger than your system and",
    "start": "4425440",
    "end": "4431360"
  },
  {
    "text": "sort of the other question is the the problem with data flow",
    "start": "4431520",
    "end": "4436800"
  },
  {
    "text": "is that you always run on the length of the longest chain and then it's a packing problem beyond",
    "start": "4436800",
    "end": "4443040"
  },
  {
    "text": "that um and so you know conditionals are horrible um",
    "start": "4443040",
    "end": "4451679"
  },
  {
    "text": "so if you choose your problem right packing works perfectly but you can't run anything",
    "start": "4451679",
    "end": "4457600"
  },
  {
    "text": "and if you choose your problems wrong then you know the packing is easy because",
    "start": "4457600",
    "end": "4463760"
  },
  {
    "text": "everything's idle running no ops so where are you",
    "start": "4463760",
    "end": "4468800"
  },
  {
    "text": "what problems are you picking so that that works out to your benefit",
    "start": "4468800",
    "end": "4475120"
  },
  {
    "text": "um so i i if i understand that the crux of your question here i guess it's it's",
    "start": "4475199",
    "end": "4481120"
  },
  {
    "text": "um you you view this as a big two-dimensional kind of a bin packing problem let's see if i can",
    "start": "4481120",
    "end": "4486400"
  },
  {
    "text": "get back to we've got this two-dimensional die that that consists of you know two dimensions",
    "start": "4486400",
    "end": "4492640"
  },
  {
    "text": "right we've got um super lanes and and really what we're doing is we're scheduling for the super",
    "start": "4492640",
    "end": "4498400"
  },
  {
    "text": "lane and then we get we get the second dimension somewhat free essentially free",
    "start": "4498400",
    "end": "4503600"
  },
  {
    "text": "that that's the the the uh the instruction execution executes cycle by cycle and so that that dimension kind of",
    "start": "4503600",
    "end": "4511440"
  },
  {
    "text": "comes for free so if you think about it the compiler is solving kind of a one-dimensional bin packing problem of",
    "start": "4511440",
    "end": "4517360"
  },
  {
    "text": "fitting everything into that super lane kind of scheduling the functional units on that super lane",
    "start": "4517360",
    "end": "4522880"
  },
  {
    "text": "rather than a more general two-dimensional bin packing problem which is obviously more complex",
    "start": "4522880",
    "end": "4528719"
  },
  {
    "text": "um and so you're you're you're right and that you you have some you have some",
    "start": "4528719",
    "end": "4534400"
  },
  {
    "text": "functional data flow pipeline that you're gonna you're gonna set up a software pipeline right for example a",
    "start": "4534400",
    "end": "4539920"
  },
  {
    "text": "re-quantization pipeline you're going to do some ads and multiply a conversion um and then you're going to",
    "start": "4539920",
    "end": "4546480"
  },
  {
    "text": "do something well you start off by doing a conversion multiply and add in another conversion and you're going to set up",
    "start": "4546480",
    "end": "4551840"
  },
  {
    "text": "that fixed function pipeline and you're going to stream your tensors across it and then you're going to change that",
    "start": "4551840",
    "end": "4557120"
  },
  {
    "text": "pipeline and the cost of changing that pipeline differs if you're on a cpu you can do it",
    "start": "4557120",
    "end": "4563040"
  },
  {
    "text": "on a single cycle right you can change instructions every cycle if you're on a fpga right you have you",
    "start": "4563040",
    "end": "4569040"
  },
  {
    "text": "have you have a very fixed cost of setting up a dif that pipeline if you're on something like a coarse grain",
    "start": "4569040",
    "end": "4575679"
  },
  {
    "text": "reconfigurable computer where you have some pipeline and you're going to set that up and it might take you a handful",
    "start": "4575679",
    "end": "4581280"
  },
  {
    "text": "of microseconds to change that function that becomes more expensive what this is is it's the programmability",
    "start": "4581280",
    "end": "4588800"
  },
  {
    "text": "of a processor a gpu or cpu where you can change the instruction every cycle",
    "start": "4588800",
    "end": "4594159"
  },
  {
    "text": "in other words that's why we need so much instruction fetch bandwidth but you can change that",
    "start": "4594159",
    "end": "4600080"
  },
  {
    "text": "on a cycle by cycle and you can do it with with impunity every cycle you can be doing a different instruction",
    "start": "4600080",
    "end": "4607360"
  },
  {
    "text": "in practice what we what we are trying to do is essentially we have multiple models co-resident on the chip",
    "start": "4607360",
    "end": "4614719"
  },
  {
    "text": "and you can kind of stack them all up together very efficiently so that they you know one model can for example you",
    "start": "4614719",
    "end": "4621520"
  },
  {
    "text": "might have some object detection that feeds another model that's doing object prediction and figuring figuring out if",
    "start": "4621520",
    "end": "4628239"
  },
  {
    "text": "the the person standing on the crosswalk is going to take a step into the into the the crosswalk for example",
    "start": "4628239",
    "end": "4635040"
  },
  {
    "text": "and so we can have multiple co-resident models on the chip that allow you to kind of very efficiently and quickly",
    "start": "4635040",
    "end": "4640880"
  },
  {
    "text": "switch between them with with with virtually no overhead um so that's one way you get at some",
    "start": "4640880",
    "end": "4647520"
  },
  {
    "text": "some virtualization of the hardware but we also we virtualize at the system level so the way that our virtualization",
    "start": "4647520",
    "end": "4654400"
  },
  {
    "text": "approach is to virtualize at the system level think about virtualizing up instead of virtualizing down instead of",
    "start": "4654400",
    "end": "4661120"
  },
  {
    "text": "taking for example taking a gpu and breaking it into seven logical gpus we we're taking a a system",
    "start": "4661120",
    "end": "4669440"
  },
  {
    "text": "of 64 tsps and we're going to take some subset of that and carve that out and",
    "start": "4669440",
    "end": "4674640"
  },
  {
    "text": "call that a virtual cluster and we can run some application on that virtual cluster",
    "start": "4674640",
    "end": "4679760"
  },
  {
    "text": "and what we literally do then is we can turn off any of the c2c links to you know literally physically and",
    "start": "4679760",
    "end": "4686960"
  },
  {
    "text": "provide performance isolation and fault isolation between those little sub clusters those little virtual uh",
    "start": "4686960",
    "end": "4693360"
  },
  {
    "text": "subclusters so the virtualization strategy is a virtualization up at the system level",
    "start": "4693360",
    "end": "4699360"
  },
  {
    "text": "rather than taking the device and breaking it into smaller parts that we try to get better utilization of the",
    "start": "4699360",
    "end": "4705120"
  },
  {
    "text": "underlying hardware i think i asked i think i mis-set the",
    "start": "4705120",
    "end": "4710800"
  },
  {
    "text": "problem if i buy the smallest system from you whatever that is",
    "start": "4710800",
    "end": "4716560"
  },
  {
    "text": "am i limited in my problem size it will take end times longer",
    "start": "4716560",
    "end": "4723600"
  },
  {
    "text": "because i didn't give you enough money or am i just out of luck do i have to buy the system for the largest problem i",
    "start": "4723600",
    "end": "4730080"
  },
  {
    "text": "will ever do or do i buy a system and sometimes it runs slow",
    "start": "4730080",
    "end": "4736880"
  },
  {
    "text": "that so it's a great question so you're asking if it doesn't fit on a single chip can i trade off time",
    "start": "4736880",
    "end": "4744400"
  },
  {
    "text": "kind of batch it batch it and bring it out in time and absolutely that's that's the first step that the compiler does is",
    "start": "4744480",
    "end": "4750719"
  },
  {
    "text": "basically partition kind of what's going to be running when and where so if all you have is one tsp obviously",
    "start": "4750719",
    "end": "4757440"
  },
  {
    "text": "you you you you have to make that trade-off right you don't have a choice um but but yeah that's that's the idea",
    "start": "4757440",
    "end": "4763360"
  },
  {
    "text": "is you can bring that into smaller chunks and work on it and and it takes longer obviously",
    "start": "4763360",
    "end": "4769440"
  },
  {
    "text": "but if you have a system approach where you can apply more tsps to it then you can can take advantage of that",
    "start": "4769440",
    "end": "4777120"
  },
  {
    "text": "so dennis uh where are you in the process here you're uh uh you have uh design you have uh",
    "start": "4777120",
    "end": "4786080"
  },
  {
    "text": "first silicon yet you have your shipping uh who's making it uh what processed uh dimensions and",
    "start": "4786080",
    "end": "4793440"
  },
  {
    "text": "so forth you know the the standard um uh certification for uh",
    "start": "4793440",
    "end": "4801120"
  },
  {
    "text": "purchase agreements yeah yeah absolutely great questions so we are shipping product now we're",
    "start": "4801120",
    "end": "4807360"
  },
  {
    "text": "shipping uh chips and nodes uh we're in the process of of building up large",
    "start": "4807360",
    "end": "4812480"
  },
  {
    "text": "scale racks multi multiple rack systems and deploying them in the in data",
    "start": "4812480",
    "end": "4817600"
  },
  {
    "text": "centers so you can imagine that we can make this available through a virtual private",
    "start": "4817600",
    "end": "4822719"
  },
  {
    "text": "server and we can make make those systems available but at the moment we are selling chips",
    "start": "4822719",
    "end": "4829360"
  },
  {
    "text": "and systems up to eight-way nodes and then you can take those nodes and you can build larger scale systems from them",
    "start": "4829360",
    "end": "4836080"
  },
  {
    "text": "um so it is as you mentioned it is a it is a journey it is a process and we don't you know we don't start uh we",
    "start": "4836080",
    "end": "4842560"
  },
  {
    "text": "don't start life with everything well baked right and you have to kind of work our way into that so today we've got uh",
    "start": "4842560",
    "end": "4848800"
  },
  {
    "text": "systems with multiple racks and we're working on building larger scale systems to be able to tackle truly truly large",
    "start": "4848800",
    "end": "4855760"
  },
  {
    "text": "large scale problems but that's a process and it takes time and it takes a maturation process for the compiler so",
    "start": "4855760",
    "end": "4861920"
  },
  {
    "text": "as you see more generality more models more bigger models smaller models multi-check",
    "start": "4861920",
    "end": "4867280"
  },
  {
    "text": "models single chip models uh it's it's all in a software maturation process and",
    "start": "4867280",
    "end": "4872480"
  },
  {
    "text": "we're making great uh great great strides with that but this is something today that that you can buy",
    "start": "4872480",
    "end": "4878000"
  },
  {
    "text": "one uh one or more cards or you can buy a node that has eight cards in it and",
    "start": "4878000",
    "end": "4884000"
  },
  {
    "text": "you can buy multiple nodes that together would be in a rack so it depends on your use case if it's kind of data center",
    "start": "4884000",
    "end": "4891040"
  },
  {
    "text": "oriented or if this is something that you're looking at deploying at the edge again at something in a warehouse or at",
    "start": "4891040",
    "end": "4897040"
  },
  {
    "text": "a at a point of sale or if it's something that might be um in situ or in in a in an embedded",
    "start": "4897040",
    "end": "4903760"
  },
  {
    "text": "application like an automotive uh application so there's there's a number of of of",
    "start": "4903760",
    "end": "4910639"
  },
  {
    "text": "kind of depending on what your use case is i would say that that we are well along",
    "start": "4910639",
    "end": "4915760"
  },
  {
    "text": "that kind of maturation process it depends on on how how large you want to",
    "start": "4915760",
    "end": "4921360"
  },
  {
    "text": "how large you want to tackle and this is uh not a project a product that was built",
    "start": "4921360",
    "end": "4928159"
  },
  {
    "text": "for a single customer and then expand it out or is it uh",
    "start": "4928159",
    "end": "4934719"
  },
  {
    "text": "a private brand that's been published totally branded or what",
    "start": "4934719",
    "end": "4942080"
  },
  {
    "text": "yeah so we're building this as a general it's a general purpose accelerator i mean it's generally enough to tackle a",
    "start": "4942080",
    "end": "4948480"
  },
  {
    "text": "variety of problems right it's not uh it's not a resnet accelerator right right just to make that clear um and in",
    "start": "4948480",
    "end": "4955520"
  },
  {
    "text": "fact at the time when we designed the chip in 2017 uh transformers weren't uh",
    "start": "4955520",
    "end": "4960800"
  },
  {
    "text": "weren't really known and so we had to design this to be generally",
    "start": "4960800",
    "end": "4966400"
  },
  {
    "text": "enough to tackle a variety of different models and for example it's we designed it to be",
    "start": "4966400",
    "end": "4972960"
  },
  {
    "text": "really really efficient at matrix matrix math and vector matrix math and so if you",
    "start": "4972960",
    "end": "4979040"
  },
  {
    "text": "look at you know lstms rnns convolutional neural networks we've designed this to be very efficient at",
    "start": "4979040",
    "end": "4986159"
  },
  {
    "text": "doing linear algebra and whether that's cholesky factorization or if it's a bert",
    "start": "4986159",
    "end": "4992800"
  },
  {
    "text": "model that it's doing vector matrix operations and we can do that with",
    "start": "4992800",
    "end": "4998000"
  },
  {
    "text": "really efficiently and that's the that's the underlying workhorse to all of this so that's kind of what we were thinking",
    "start": "4998000",
    "end": "5003679"
  },
  {
    "text": "when we designed it is to build in that generality so that it's not a one-trick pony it has to be general enough to make",
    "start": "5003679",
    "end": "5010480"
  },
  {
    "text": "it very you know broadly applicable for a variety of of use cases whether it's by a fintech company oil and gas",
    "start": "5010480",
    "end": "5017280"
  },
  {
    "text": "exploration or by anomaly detection for intrusion detection there's a lot",
    "start": "5017280",
    "end": "5023280"
  },
  {
    "text": "we don't want to hold you to it but can you give us a rough price uh bracket",
    "start": "5023280",
    "end": "5029040"
  },
  {
    "text": "uh for what what the cost of this is going to be like you know now that's a great question i think we're",
    "start": "5029040",
    "end": "5035280"
  },
  {
    "text": "we're selling these for prices that are consistent with kind of state-of-the-art gpu so i think um it's it's you know",
    "start": "5035280",
    "end": "5042000"
  },
  {
    "text": "going to be along that that same price line uh i apologize i'm i'm i'm i don't",
    "start": "5042000",
    "end": "5047280"
  },
  {
    "text": "have a price book or i'm not in sales so i can't give you details on that but i would encourage you to reach out and",
    "start": "5047280",
    "end": "5052320"
  },
  {
    "text": "talk to a salesperson if if that's something of interest but you can imagine that's it's going to be",
    "start": "5052320",
    "end": "5058239"
  },
  {
    "text": "comparable to a state-of-the-art uh gpu yeah i i will read the papers i'm very",
    "start": "5058239",
    "end": "5063600"
  },
  {
    "text": "interested in particular can you speak to or is it in the paper the by",
    "start": "5063600",
    "end": "5069679"
  },
  {
    "text": "uh permutation you were talking about um",
    "start": "5069679",
    "end": "5074960"
  },
  {
    "text": "yeah i think i can give a little more more examples like i said uh if you look at this green section here on the chip",
    "start": "5074960",
    "end": "5081840"
  },
  {
    "text": "this is our sxm this is our switch execution module and if you were to look at this this is a",
    "start": "5081840",
    "end": "5088639"
  },
  {
    "text": "a large on-chip network that that is literally implemented as a",
    "start": "5088639",
    "end": "5093920"
  },
  {
    "text": "a kind of a hybrid on-chip network that's a combination of folded flow and a",
    "start": "5093920",
    "end": "5099120"
  },
  {
    "text": "vanish switch and what we do is we can take we take the input 320 and",
    "start": "5099120",
    "end": "5106000"
  },
  {
    "text": "out pops the output 320 permuted so you give it a permute",
    "start": "5106000",
    "end": "5111360"
  },
  {
    "text": "permutation map you tell it how you want those to be rearranged you give it an input vector",
    "start": "5111360",
    "end": "5116800"
  },
  {
    "text": "and a permutation map and it pops out the output vector that matches that and so that's just the most general you",
    "start": "5116800",
    "end": "5124159"
  },
  {
    "text": "know swiss army knife of data movement you can do a lot of things with that but that's also that's also moving that's",
    "start": "5124159",
    "end": "5130239"
  },
  {
    "text": "that's allowing us to move 320 elements across you know vertically the entire check right so it's an ex",
    "start": "5130239",
    "end": "5136639"
  },
  {
    "text": "relatively expensive operations it takes tens of clock cycles to perform that",
    "start": "5136639",
    "end": "5141840"
  },
  {
    "text": "whereas moving data within each super link that is using the distributor using",
    "start": "5141840",
    "end": "5146960"
  },
  {
    "text": "the communication locality idea that remember i said you can do transpose and distribute and move",
    "start": "5146960",
    "end": "5152719"
  },
  {
    "text": "data local to the to the super lane and each super lane is 16 elements and",
    "start": "5152719",
    "end": "5158560"
  },
  {
    "text": "there's 20 super lanes 20 times 16 is 320 um but you can move the the bytes within",
    "start": "5158560",
    "end": "5165520"
  },
  {
    "text": "the super lane with with with uh you know really really efficiently and and that's kind of just this concept of",
    "start": "5165520",
    "end": "5172239"
  },
  {
    "text": "locality of communication you can move move things nearby really cheaply but as you're moving things further it becomes",
    "start": "5172239",
    "end": "5178880"
  },
  {
    "text": "more expensive so moving things from super lane 0 to super lane 19 you can imagine is much more expensive right",
    "start": "5178880",
    "end": "5185360"
  },
  {
    "text": "we've got to traverse this larger on-chip network is it is it a single clock operation",
    "start": "5185360",
    "end": "5194320"
  },
  {
    "text": "it is a single core clock that is driving the the entire uh what we call kind of this core rectangle",
    "start": "5194880",
    "end": "5202080"
  },
  {
    "text": "which is just the memory the mxm all of that operates on a single",
    "start": "5202080",
    "end": "5207199"
  },
  {
    "text": "uh core clock that that um and the the chip to chip links obviously",
    "start": "5207199",
    "end": "5213360"
  },
  {
    "text": "are running off of a a certain clock so there's there's um",
    "start": "5213360",
    "end": "5218880"
  },
  {
    "text": "there's a clock domain crossing there obviously um and again we we had to kind of make that all work one of the things that",
    "start": "5218880",
    "end": "5225600"
  },
  {
    "text": "required us to to to build into the the design was the chip to chip links had to",
    "start": "5225600",
    "end": "5230880"
  },
  {
    "text": "use forward error correction and where i said the link layer protocol cannot retry things so you don't want the",
    "start": "5230880",
    "end": "5237440"
  },
  {
    "text": "replay mechanism interfering with your determinism and so if you get a",
    "start": "5237440",
    "end": "5242639"
  },
  {
    "text": "transmission error you you need to have a forward error correction that",
    "start": "5242639",
    "end": "5247679"
  },
  {
    "text": "recognizes that that that bit flip corrects it in situ and your your fixed",
    "start": "5247679",
    "end": "5254159"
  },
  {
    "text": "latency pipeline remains the same so it takes the exact same time to go through it whether you had an error or not and",
    "start": "5254159",
    "end": "5260639"
  },
  {
    "text": "you pop pop out at the end of it you pop out a a good vector a good flip right",
    "start": "5260639",
    "end": "5266080"
  },
  {
    "text": "it's corrected and so that's that's the key idea we're able to kind of",
    "start": "5266080",
    "end": "5271280"
  },
  {
    "text": "keep this idea of deterministic execution and build it into the data paths to make to make it all kind of",
    "start": "5271280",
    "end": "5277920"
  },
  {
    "text": "hold water you have to have this consistent philosophy throughout the minute you put one arbiter and you can't",
    "start": "5277920",
    "end": "5282960"
  },
  {
    "text": "predict where things are poof it all goes away so you have to have this kind of philosophy that that really stays",
    "start": "5282960",
    "end": "5289040"
  },
  {
    "text": "true to that are there people out there who have questions that we are not acknowledging",
    "start": "5289040",
    "end": "5295280"
  },
  {
    "text": "here um i have uh two simple questions and one",
    "start": "5295280",
    "end": "5301520"
  },
  {
    "text": "um more maybe um [Music] difficult question",
    "start": "5301520",
    "end": "5307440"
  },
  {
    "text": "the first two questions are what is the power consumption and what",
    "start": "5307440",
    "end": "5312560"
  },
  {
    "text": "is the heat dissipation okay um those are great questions so the tdp",
    "start": "5312560",
    "end": "5318800"
  },
  {
    "text": "here is is designed for about 350 watts um in practice what we see for example",
    "start": "5318800",
    "end": "5326239"
  },
  {
    "text": "resnet i think is around 180 180 watts it's workload dependent right um so so",
    "start": "5326239",
    "end": "5333040"
  },
  {
    "text": "in practice the the actual energy consumed is far less than our our tdp our tdp is designed to kind of be the",
    "start": "5333040",
    "end": "5340320"
  },
  {
    "text": "worst case that we need to to cool it and provide the provisioning for our cooling system and",
    "start": "5340320",
    "end": "5345600"
  },
  {
    "text": "our packaging um so it's it's uh the eight the eight",
    "start": "5345600",
    "end": "5351360"
  },
  {
    "text": "tsps in a node is about a three kilowatt uh package and so that's your tdp of",
    "start": "5351360",
    "end": "5357199"
  },
  {
    "text": "that for you chassis and uh like i said depending on the workload it's gonna consume you know 150",
    "start": "5357199",
    "end": "5364400"
  },
  {
    "text": "to 200 200 some watts typically",
    "start": "5364400",
    "end": "5368880"
  },
  {
    "text": "thank you my my more difficult question is have you",
    "start": "5369600",
    "end": "5374800"
  },
  {
    "text": "considered potential in-ship uh security threats and have you thought",
    "start": "5374800",
    "end": "5382080"
  },
  {
    "text": "about how you might control for them",
    "start": "5382080",
    "end": "5388800"
  },
  {
    "text": "great question um yeah security side channel attacks in particular i'm assuming you're getting",
    "start": "5389120",
    "end": "5395520"
  },
  {
    "text": "out here if there's if there's ways to kind of um to to do side channels one of the one of",
    "start": "5395520",
    "end": "5401520"
  },
  {
    "text": "those so no there's two questions one is side channel and that's a very interesting question by itself",
    "start": "5401520",
    "end": "5406880"
  },
  {
    "text": "but because of the way tensor models work",
    "start": "5406880",
    "end": "5414159"
  },
  {
    "text": "once they're once they've been tested and determined to be",
    "start": "5414159",
    "end": "5420719"
  },
  {
    "text": "to give results within desirable ranges people tend not to look at them again",
    "start": "5421040",
    "end": "5427520"
  },
  {
    "text": "and so one might wonder if somebody for some",
    "start": "5427520",
    "end": "5432560"
  },
  {
    "text": "reason would want to change the outputs and",
    "start": "5432560",
    "end": "5438239"
  },
  {
    "text": "would want to interfere with the processing so as to produce",
    "start": "5438239",
    "end": "5444960"
  },
  {
    "text": "consistently different results for some reason",
    "start": "5444960",
    "end": "5450719"
  },
  {
    "text": "it's a it's a great question let me try to let me try to answer it so so two things and i understand i understand",
    "start": "5450800",
    "end": "5456639"
  },
  {
    "text": "this this may be a little bit out at the edge and it but i'm not going to hold you too",
    "start": "5456639",
    "end": "5462400"
  },
  {
    "text": "absolutely it's a it's a it's a great observation it's a great question so a couple of",
    "start": "5462400",
    "end": "5467600"
  },
  {
    "text": "things when when we were designing the chip and i remember spectre and meltdown were all the rage this has just kind of",
    "start": "5467600",
    "end": "5474239"
  },
  {
    "text": "uh come out and um we they were showing how up you know these aggressive out of",
    "start": "5474239",
    "end": "5479679"
  },
  {
    "text": "order execution can be used to essentially set up these side channel attacks and more generally anything that",
    "start": "5479679",
    "end": "5485840"
  },
  {
    "text": "you can use and and generate different latency um characteristics you can create a side",
    "start": "5485840",
    "end": "5493760"
  },
  {
    "text": "channel and use that varying latency to impart information right",
    "start": "5493760",
    "end": "5498800"
  },
  {
    "text": "in our case the timing is all known a priori and and anything that you would",
    "start": "5498800",
    "end": "5504560"
  },
  {
    "text": "do if you tried to for example if you tried to put a man in the middle attack to say",
    "start": "5504560",
    "end": "5510560"
  },
  {
    "text": "intercept some data um it would change the timing relationship it's a little bit of the",
    "start": "5510560",
    "end": "5515600"
  },
  {
    "text": "heisenberg principle here once the program is built if you try to change something it's gonna material affect the",
    "start": "5515600",
    "end": "5522719"
  },
  {
    "text": "outcome it and the program simply won't behave as as it as it as it should right",
    "start": "5522719",
    "end": "5527920"
  },
  {
    "text": "it's going i mean that the timing is important and you cannot perturb that timing without changing its its result",
    "start": "5527920",
    "end": "5535120"
  },
  {
    "text": "and so it's kind of a heisenberg effect if you put if you put someone in the middle it's going to change the timing",
    "start": "5535120",
    "end": "5541199"
  },
  {
    "text": "and for example you're going to not intercept the data when you expect to intercept the data so your outputs are",
    "start": "5541199",
    "end": "5546800"
  },
  {
    "text": "going to be all wrong you're going to get the wrong data back and you're really not going to have observed the",
    "start": "5546800",
    "end": "5551840"
  },
  {
    "text": "thing that you wanted to observe because and the",
    "start": "5551840",
    "end": "5556880"
  },
  {
    "text": "is part of the mechanism so you cannot use temporal information to to extract",
    "start": "5556880",
    "end": "5564000"
  },
  {
    "text": "information about the side channel",
    "start": "5564000",
    "end": "5568800"
  },
  {
    "text": "question about um the speed the 900 megahertz is that in any way related to",
    "start": "5569360",
    "end": "5575679"
  },
  {
    "text": "what the memory will do or can you speed it up or what's the limit that you're looking at",
    "start": "5575679",
    "end": "5581520"
  },
  {
    "text": "there great question so so we designed the chip to uh in principle operate up to a maximum",
    "start": "5581520",
    "end": "5588639"
  },
  {
    "text": "frequency of of uh up to 1.2 gigahertz that that gets",
    "start": "5588639",
    "end": "5594560"
  },
  {
    "text": "unfortunately in in this packaging form factor with amount of power that we can",
    "start": "5594560",
    "end": "5599600"
  },
  {
    "text": "dissipate we are constrained by the clock frequency to kind of keep it within that tdp",
    "start": "5599600",
    "end": "5605600"
  },
  {
    "text": "so um i you know that's an artifact of this is a big chip and there is such a thing",
    "start": "5605600",
    "end": "5611679"
  },
  {
    "text": "as dark silicon if you light it all up at once you can start it all on fire so you don't want to do that you have to",
    "start": "5611679",
    "end": "5617600"
  },
  {
    "text": "kind of control that and so our software is is very instrumental in kind of",
    "start": "5617600",
    "end": "5624560"
  },
  {
    "text": "smoothing out any kind of didt events any transient events so that we don't have these large spikes these",
    "start": "5624560",
    "end": "5631280"
  },
  {
    "text": "large excursionary events and we can keep the keep the lid on the heat and keep the lid on on the on the uh the",
    "start": "5631280",
    "end": "5638960"
  },
  {
    "text": "performance so that we're on the heat so we don't have to throttle anything back right so we can operate at full at full",
    "start": "5638960",
    "end": "5645199"
  },
  {
    "text": "band at full uh at full rate at 900 megahertz and keep everything clicking along at that",
    "start": "5645199",
    "end": "5651440"
  },
  {
    "text": "in the pcie form factor so now as we start to build larger systems you can",
    "start": "5651440",
    "end": "5656800"
  },
  {
    "text": "imagine where you have more efficient cooling techniques to be able to dissipate more heat and be able to",
    "start": "5656800",
    "end": "5663199"
  },
  {
    "text": "uh be able to do do a little bit more with that um you don't have to let your imagination",
    "start": "5663199",
    "end": "5669520"
  },
  {
    "text": "run too wild to to kind of see where that's going okay what's the technology here dennis says it oh fantastic",
    "start": "5669520",
    "end": "5676400"
  },
  {
    "text": "question this is seven nanometers or what this is actually a 14 nanometer uh 14",
    "start": "5676400",
    "end": "5682159"
  },
  {
    "text": "nanometer device um you can imagine our next generations are going to be uh smaller feature sizes",
    "start": "5682159",
    "end": "5688639"
  },
  {
    "text": "but this is actually a 14 nanometer device and um we we uh we're quite happy",
    "start": "5688639",
    "end": "5694719"
  },
  {
    "text": "that we're we're getting such uh great results with this and competing with um",
    "start": "5694719",
    "end": "5700239"
  },
  {
    "text": "you know truly much more dense node sizes much more uh ambitious node sizes in in competitive",
    "start": "5700239",
    "end": "5706800"
  },
  {
    "text": "products okay uh i'm from slack i i do a lot about pga",
    "start": "5706800",
    "end": "5712000"
  },
  {
    "text": "development now it's a fairly practical question here is you've tied the uh the compiler and the hardware together",
    "start": "5712000",
    "end": "5718719"
  },
  {
    "text": "fairly tightly so i'm interested in sort of what the development cycle looks like is this like an fpga when i go to",
    "start": "5718719",
    "end": "5725280"
  },
  {
    "text": "compile i'm looking at a fairly long cycle to do this and what happens",
    "start": "5725280",
    "end": "5730960"
  },
  {
    "text": "uh do i have to describe the chip that i'm going to to the compiler in detail like you would",
    "start": "5730960",
    "end": "5736960"
  },
  {
    "text": "in fpga fantastic question um great question so",
    "start": "5736960",
    "end": "5742320"
  },
  {
    "text": "so the compilation is unlike an fpga where you're you're essentially ingesting verilog and you're",
    "start": "5742320",
    "end": "5748880"
  },
  {
    "text": "you're doing going through a place and route that is a much this is a much much faster process for example it's a hand",
    "start": "5748880",
    "end": "5756159"
  },
  {
    "text": "it's literally a handful of minutes to compile resnet for example or bert or large so it's it's a it's a handful of",
    "start": "5756159",
    "end": "5763360"
  },
  {
    "text": "minutes and it's getting better all the time um so it's it's much more efficient than what you're probably accustomed to",
    "start": "5763360",
    "end": "5769119"
  },
  {
    "text": "for place and route and tool chains in fact that's one of the things we are really looking at doing is increasing",
    "start": "5769119",
    "end": "5774960"
  },
  {
    "text": "the the iteration rate that the compile time has to be low enough so that you can experiment in fact you don't need",
    "start": "5774960",
    "end": "5782159"
  },
  {
    "text": "any hardware at all to compile to get your to know exactly what performance",
    "start": "5782159",
    "end": "5787440"
  },
  {
    "text": "it's going to run and even get some estimates as to what power it's going to take and so you can run the compiler and",
    "start": "5787440",
    "end": "5794000"
  },
  {
    "text": "without any hardware attached to it at all just to get you to iterate quickly on your model and get the the",
    "start": "5794000",
    "end": "5799840"
  },
  {
    "text": "compilation you know step down entirely with that you you you do choose your",
    "start": "5799840",
    "end": "5805280"
  },
  {
    "text": "target right you do you want a single chip and what is that uh what there's a topology",
    "start": "5805280",
    "end": "5810639"
  },
  {
    "text": "you know specification that says what the network is that that describes the the tsps underneath that you're",
    "start": "5810639",
    "end": "5816719"
  },
  {
    "text": "targeting that's but that's a you know very lightweight and it's set up kind of ahead of time and and you're just",
    "start": "5816719",
    "end": "5822800"
  },
  {
    "text": "compiling your code and and the compiler is going to ingest that look at how many uh tsps",
    "start": "5822800",
    "end": "5829920"
  },
  {
    "text": "it it has to spread it across to fit from a capacity standpoint um obviously you have to have that many",
    "start": "5829920",
    "end": "5836320"
  },
  {
    "text": "tsps in the system um to to be able to actually execute it then",
    "start": "5836320",
    "end": "5841679"
  },
  {
    "text": "but importantly you don't need actual underlying hardware in order to just kind of compile and test out your your",
    "start": "5841679",
    "end": "5848480"
  },
  {
    "text": "machine learning model and that's really key is that the time to iteration is the time to innovation and just being able",
    "start": "5848480",
    "end": "5854800"
  },
  {
    "text": "to iterate quickly allows you to try some things out to to to be able to iterate quickly build",
    "start": "5854800",
    "end": "5862080"
  },
  {
    "text": "test and learn very quickly uh before you even install it on a piece of hardware",
    "start": "5862080",
    "end": "5868639"
  },
  {
    "text": "okay so as you move forward in your hardware you will have to sort of recompile your program",
    "start": "5868639",
    "end": "5874960"
  },
  {
    "text": "and i was thinking of like your chip will evolve on a roadmap",
    "start": "5874960",
    "end": "5880000"
  },
  {
    "text": "it may have different architectural features that's right so as we add to the second",
    "start": "5880000",
    "end": "5885440"
  },
  {
    "text": "generation as we add different functional units as we add more uh more compute or we add more",
    "start": "5885440",
    "end": "5891119"
  },
  {
    "text": "communication the chip the the chip organization will change and that's that's just kind of an internal you know",
    "start": "5891119",
    "end": "5897199"
  },
  {
    "text": "internal between the compiler and the underlying hardware that's kind of that hardware software agreement",
    "start": "5897199",
    "end": "5902639"
  },
  {
    "text": "and that will change but but yes it will entail recompiling um and and that's",
    "start": "5902639",
    "end": "5908159"
  },
  {
    "text": "that's you know we thought about having kind of binary compatibility and it just",
    "start": "5908159",
    "end": "5913760"
  },
  {
    "text": "didn't make sense to kind of make things backwardly compatible and especially with these models if you can compile",
    "start": "5913760",
    "end": "5920400"
  },
  {
    "text": "quickly and make that as painless as possible then it's just not as big of a deal",
    "start": "5920400",
    "end": "5926480"
  },
  {
    "text": "yeah so so your market is is more or less people with dedicated pros dedicated things not somebody who has a",
    "start": "5926480",
    "end": "5932880"
  },
  {
    "text": "library of a thousand different applications",
    "start": "5932880",
    "end": "5937719"
  },
  {
    "text": "well a thousand different applications are great but you i think we have to tackle them one at a time is the point right it this isn't a kind of a kernel a",
    "start": "5938560",
    "end": "5946159"
  },
  {
    "text": "kernel-based approach right we don't it's not like a gpu where we have a kernel for you know image to call or a",
    "start": "5946159",
    "end": "5952080"
  },
  {
    "text": "kernel that does whatever x y or z instead we have the parallelizing compiler that is a vectorizing compiler",
    "start": "5952080",
    "end": "5958800"
  },
  {
    "text": "and it's gonna from first principles take this disaggregated processor and map your problem to these functional",
    "start": "5958800",
    "end": "5964880"
  },
  {
    "text": "units and that's a it's a it's a little different approach than kind of kernel based just",
    "start": "5964880",
    "end": "5970239"
  },
  {
    "text": "taking a bunch of kernels and throwing it at at the problem okay thank you",
    "start": "5970239",
    "end": "5975840"
  },
  {
    "text": "okay so we're coming up to the end here are there any more questions",
    "start": "5975840",
    "end": "5981280"
  },
  {
    "text": "um yeah thanks uh thanks for giving us the talk today um i had one question on the ctc links uh so you mentioned",
    "start": "5981280",
    "end": "5988480"
  },
  {
    "text": "forward error correction i was wondering if there's a significant penalty due to the added latency with the",
    "start": "5988480",
    "end": "5995840"
  },
  {
    "text": "forward air correction and how you take that it's a fantastic question so forward",
    "start": "5995840",
    "end": "6002560"
  },
  {
    "text": "error correction is um you know compulsorily it does take some time right and it's it's on the order of",
    "start": "6002560",
    "end": "6009440"
  },
  {
    "text": "hundreds of nanoseconds probably uh like 100 to 200 nanoseconds so it does increase the latency of per",
    "start": "6009440",
    "end": "6017520"
  },
  {
    "text": "hop latency however we can you know deal with the added latency we can have everything pipelined and we can",
    "start": "6017520",
    "end": "6025040"
  },
  {
    "text": "hide that latency very nicely but it does make each link slightly longer from",
    "start": "6025040",
    "end": "6030320"
  },
  {
    "text": "a input layer you know from a flip in to flit out it does lengthen it a bit and so that is",
    "start": "6030320",
    "end": "6037600"
  },
  {
    "text": "one of the trade-offs of a forward rare correction in in in poses um you know",
    "start": "6037600",
    "end": "6042960"
  },
  {
    "text": "and and going forward especially as we get to 112 and 224 gigabit per second signaling forward air correction is is",
    "start": "6042960",
    "end": "6050320"
  },
  {
    "text": "absolutely compulsory on these on these channels right and so you're we're going to have to kind of",
    "start": "6050320",
    "end": "6055679"
  },
  {
    "text": "it's a difficult pill to swallow i'll let additional latency for the read solomon encoding but we have to do that",
    "start": "6055679",
    "end": "6061679"
  },
  {
    "text": "to just to to to make these reliable at scale that's a great question we do have to",
    "start": "6061679",
    "end": "6067679"
  },
  {
    "text": "pay the latency the good news is we can hide all that latency and keep everything fully pipelined",
    "start": "6067679",
    "end": "6075040"
  },
  {
    "text": "hi again um what is your compiler written and is and do you have a formal specification and a",
    "start": "6075040",
    "end": "6081520"
  },
  {
    "text": "proof verified or you know is it written in c",
    "start": "6081520",
    "end": "6087360"
  },
  {
    "text": "great question um so parts of the compiler are written in haskell and parts are written in c plus plus",
    "start": "6087520",
    "end": "6094080"
  },
  {
    "text": "and and i i would say parts of it uh i i don't want to speak to the formal verify",
    "start": "6094080",
    "end": "6099760"
  },
  {
    "text": "verifiability of of it obviously haskell is is strongly typed and there's a lot",
    "start": "6099760",
    "end": "6105040"
  },
  {
    "text": "of of type safety that goes into that so parts of the compiler are",
    "start": "6105040",
    "end": "6111280"
  },
  {
    "text": "strategically written in haskell parts are written in c plus plus",
    "start": "6111280",
    "end": "6116560"
  },
  {
    "text": "okay i have sort of the pen ultimate question then and that is what do you do for the next",
    "start": "6117360",
    "end": "6122400"
  },
  {
    "text": "chip oh that's a fantastic question",
    "start": "6122400",
    "end": "6128639"
  },
  {
    "text": "well i don't want to any spoiler alerts here i don't wanna i don't wanna ruin our our uh our surprises for the next",
    "start": "6128639",
    "end": "6136239"
  },
  {
    "text": "chip um but not surprisingly you will probably see more uh more compute uh throughput",
    "start": "6136239",
    "end": "6144000"
  },
  {
    "text": "uh and and really i i hope to to take advantage of something that we're uniquely capable of of taking advantage",
    "start": "6144000",
    "end": "6151119"
  },
  {
    "text": "of and that is this concept of energy proportionality and that's very it's a 20 word that just",
    "start": "6151119",
    "end": "6158320"
  },
  {
    "text": "simply means if you're doing very little you should consume very little energy and as you do increa incrementally more",
    "start": "6158320",
    "end": "6164320"
  },
  {
    "text": "you want to consume incrementally more energy and that seems like that's kind of obvious dennis why aren't all systems",
    "start": "6164320",
    "end": "6171520"
  },
  {
    "text": "energy proportional and if you think about the way a modern multi-chip core is organized you've got",
    "start": "6171520",
    "end": "6178560"
  },
  {
    "text": "a shared memory hierarchy you've got multiple cores and the moment you turn on one core",
    "start": "6178560",
    "end": "6185040"
  },
  {
    "text": "you have to turn on all the shared parts the l1 cache the l2 cache the l3 cache",
    "start": "6185040",
    "end": "6190159"
  },
  {
    "text": "the memory controller all the networking ports you need to fire everything up so it's not terribly proportional as soon",
    "start": "6190159",
    "end": "6196560"
  },
  {
    "text": "as you're doing 10 as soon as you have 10 offered load you're consuming 40 percent of your",
    "start": "6196560",
    "end": "6201840"
  },
  {
    "text": "energy because you have turned at all these shared things on and that is fundamentally what we would",
    "start": "6201840",
    "end": "6207520"
  },
  {
    "text": "should be moving away from we want to be really good stewards of of our planet's energy protect our data center's pue uh",
    "start": "6207520",
    "end": "6215440"
  },
  {
    "text": "our energy efficiency at the data center level and we want to be good stewards of our",
    "start": "6215440",
    "end": "6220639"
  },
  {
    "text": "of our customers data and their in their their electric bill right so energy proportionality is going to be key as we",
    "start": "6220639",
    "end": "6227280"
  },
  {
    "text": "go forward and this is a a architecture that is uniquely suited to be able to",
    "start": "6227280",
    "end": "6233360"
  },
  {
    "text": "make that a very incremental and energy proportional endeavor without those kind of",
    "start": "6233360",
    "end": "6239040"
  },
  {
    "text": "large clunky non-uniform uh energy consumptions um so as as you can imagine",
    "start": "6239040",
    "end": "6245520"
  },
  {
    "text": "um the number of lanes that we're using is a very good heuristic as to the",
    "start": "6245520",
    "end": "6251199"
  },
  {
    "text": "arithmetic intensity required for example if you were to look at resnet the first layer of resin is 224 by 224",
    "start": "6251199",
    "end": "6257840"
  },
  {
    "text": "by 3 for the for the tensor dimensions and as you go into the deeper layers it",
    "start": "6257840",
    "end": "6263199"
  },
  {
    "text": "gets smaller goes from 224 by 224 to 112 by 112 by 64 for example the tensors are",
    "start": "6263199",
    "end": "6269840"
  },
  {
    "text": "getting smaller spatially but they're getting deeper okay and so while the the tensor shape is changing",
    "start": "6269840",
    "end": "6277360"
  },
  {
    "text": "your vector length is is changing with it so for example you might start off using 224 of the 320 elements but on the",
    "start": "6277360",
    "end": "6284880"
  },
  {
    "text": "next layer using a smaller fraction of them say 112. and so we want to consume energy that's",
    "start": "6284880",
    "end": "6291760"
  },
  {
    "text": "proportional to the amount of valid vector lanes that we're using and so you can kind of very simply see that this is",
    "start": "6291760",
    "end": "6298880"
  },
  {
    "text": "a very amenable architecture for that kind of approach",
    "start": "6298880",
    "end": "6303840"
  },
  {
    "text": "okay we have chance for one more question and then we'll have to call it quits otherwise we'll say thank you and",
    "start": "6303920",
    "end": "6311360"
  },
  {
    "text": "go out is there another question you've uh answered everybody's uh",
    "start": "6311360",
    "end": "6317760"
  },
  {
    "text": "questions that's what happens you know thank you very much it's a great ship",
    "start": "6317760",
    "end": "6324480"
  },
  {
    "text": "and you guys have done a super job it looks like and um i'm just really",
    "start": "6324480",
    "end": "6329600"
  },
  {
    "text": "pleased that it's out and uh people are beginning to work with it",
    "start": "6329600",
    "end": "6335280"
  },
  {
    "text": "and i know that there's a lot of interesting problems",
    "start": "6335280",
    "end": "6340400"
  },
  {
    "text": "out there you'll be able to work on thank you thank you",
    "start": "6340400",
    "end": "6345760"
  },
  {
    "text": "thank you it was my pleasure",
    "start": "6345760",
    "end": "6349880"
  }
]
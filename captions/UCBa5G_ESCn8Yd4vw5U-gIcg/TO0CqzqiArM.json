[
  {
    "start": "0",
    "end": "5390"
  },
  {
    "text": "Great. So I think let's get\nstarted, because we have a lot to cover today. So my name is Yann.",
    "start": "5390",
    "end": "10730"
  },
  {
    "text": "For those who don't know me,\nI'm a third-year PhD student advised by Tatsu and Percy. And today, I'll be talking about\nbenchmarking and evaluations.",
    "start": "10730",
    "end": "19160"
  },
  {
    "text": "So benchmarking and evaluations\nare honestly something that I think not enough\npeople look at in academia.",
    "start": "19160",
    "end": "26119"
  },
  {
    "text": "But if you really want to\nput something in production, and you really care\nabout, let's say, real-world machine learning,\nevaluation is really key.",
    "start": "26120",
    "end": "34320"
  },
  {
    "text": "So let's talk about that. So overview of what\nwe'll talk about.",
    "start": "34320",
    "end": "39770"
  },
  {
    "text": "First is the different reasons\nfor measuring performance. Then I'll talk about\ntext classification",
    "start": "39770",
    "end": "46219"
  },
  {
    "text": "and how you measure performance\nthere, then text generation and how you measure\nperformance there. And finally, how do you evaluate\ncurrent large language models,",
    "start": "46220",
    "end": "57050"
  },
  {
    "text": "and some issues and\nchallenges with the ways that we actually\nperform evaluations.",
    "start": "57050",
    "end": "63190"
  },
  {
    "text": "OK. So my mental model\nof how you actually develop a machine-learning\nmodel is that first you",
    "start": "63190",
    "end": "69600"
  },
  {
    "text": "will be training your model. So here, measuring\nperformance is really key because you need to have a loss\nthat you need to know when--",
    "start": "69600",
    "end": "78090"
  },
  {
    "text": "basically how to optimize. Then once you are\noptimizing your loss, the second step is\nbasically development.",
    "start": "78090",
    "end": "84900"
  },
  {
    "text": "So usually, this is\nhyperparameter tuning, or, for example, if\nyou have early stopping",
    "start": "84900",
    "end": "91542"
  },
  {
    "text": "during your models, if you\nsee that your model is not performing that\nwell, or that there's some overfitting happening,\nyou might decide to stop,",
    "start": "91542",
    "end": "99090"
  },
  {
    "text": "or you might decide\nto change the learning rate during the\ntraining of your model. So development is\nthe second step.",
    "start": "99090",
    "end": "105422"
  },
  {
    "text": "And here, you need to\nmeasure performance because you need to know\nhow to do actually models-- sorry, hyperparameter tuning\nand changing hyperparameters.",
    "start": "105422",
    "end": "115440"
  },
  {
    "text": "Then the third step is\nessentially model selection. So if I have a task that\nI really care about,",
    "start": "115440",
    "end": "121110"
  },
  {
    "text": "which model performs\nbest for my task? That might be a model\nthat I have trained. It might be a model that\nanother group has trained.",
    "start": "121110",
    "end": "128410"
  },
  {
    "text": "And finally, at least\nin the real world, you will decide to\ndeploy your model. And here, measuring\nperformance is really key,",
    "start": "128410",
    "end": "134693"
  },
  {
    "text": "because you need to know whether\nyour model is good enough to put in production. In the parallel universe\nthat we live in,",
    "start": "134693",
    "end": "141440"
  },
  {
    "text": "there's also the publishing. So you basically need to\ntest or evaluate your model",
    "start": "141440",
    "end": "149020"
  },
  {
    "text": "on standard benchmarks. And the reason why we\ndo that is essentially for communicating to a different\ngroups the quality of our model.",
    "start": "149020",
    "end": "156310"
  },
  {
    "text": "So at every step\nof this pipeline, you really need to\nmeasure performance, and that's what we'll\ntalk about today.",
    "start": "156310",
    "end": "162025"
  },
  {
    "text": "But what is key to understand\nis that at different steps, you need to measure\nperformance in different ways. So there's really\nnot a single way of--",
    "start": "162025",
    "end": "169000"
  },
  {
    "text": "not a single ideal way\nof measuring performance. So, for example, on the left,\nwhen you train your model,",
    "start": "169000",
    "end": "176087"
  },
  {
    "text": "for evaluating\nperformance, you really need to have a way of\nmeasuring performance that is super fast, super\ncheap, and differentiable,",
    "start": "176087",
    "end": "183030"
  },
  {
    "text": "because, usually, I mean, with\nneural networks you basically backpropagate through the loss. So it needs to be\ndifferentiable.",
    "start": "183030",
    "end": "188450"
  },
  {
    "text": "And finally, you really cannot\nhave a way for your model to optimize some shortcuts\nto optimize the loss,",
    "start": "188450",
    "end": "195230"
  },
  {
    "text": "even though it's not really\nwhat you wanted to optimize. And as you move more to the\nright, basically, you allowed--",
    "start": "195230",
    "end": "201549"
  },
  {
    "text": "or you will measure\nperformance less often. So it's fine if it's more\nexpensive, but you really--",
    "start": "201550",
    "end": "210280"
  },
  {
    "text": "the risk that-- you really need\nyour measuring-- your evaluation",
    "start": "210280",
    "end": "215709"
  },
  {
    "text": "metrics to be higher\nquality because the issues, if you put a model in\nproduction, are higher.",
    "start": "215710",
    "end": "222280"
  },
  {
    "text": "So during the\ndevelopment stage, you need a way of measuring\nperformance that is fast, cheap, and also kind\nof avoiding shortcuts,",
    "start": "222280",
    "end": "228940"
  },
  {
    "text": "because when you do\nhyperparameter tuning, you're essentially\nalso optimizing over a certain objective.",
    "start": "228940",
    "end": "235209"
  },
  {
    "text": "Model selection, it can\nbe a little bit less fast and less cheap. But still, you will have\nto do it that many times.",
    "start": "235210",
    "end": "240590"
  },
  {
    "text": "And most importantly, when\nyou deploy your model, you really want a way\nto evaluate performance to be trustworthy, because once\nyou put something in production,",
    "start": "240590",
    "end": "248870"
  },
  {
    "text": "there's no way to go back for\nwhat happened during that time when it was in production. You also want things to\nbe very task-specific.",
    "start": "248870",
    "end": "255860"
  },
  {
    "text": "So if I care about\na certain task when I put my model\nin production, it really, really need to\nevaluate on that specific task.",
    "start": "255860",
    "end": "262580"
  },
  {
    "text": "I don't care about other tasks. And finally, you need your\nmetrics to be absolute. So the reason why\nI'm highlighting that",
    "start": "262580",
    "end": "268270"
  },
  {
    "text": "is that in the\nthree other steps, you really just care about\ncomparing between things.",
    "start": "268270",
    "end": "273729"
  },
  {
    "text": "So that is very\ndifferent than if you want to have a threshold, which\nsays if I have less than 95%",
    "start": "273730",
    "end": "280120"
  },
  {
    "text": "accuracy, I'm not putting\nmy model in production. OK. And now, let's talk\nabout publishing. This is a little bit\ndifferent than honestly",
    "start": "280120",
    "end": "286600"
  },
  {
    "text": "evaluation in the real world. But when you do\nacademic benchmarking,",
    "start": "286600",
    "end": "291670"
  },
  {
    "text": "and when you evaluate your\nmodels in academic benchmarks, you want the benchmark to be\nreproducible and standardized.",
    "start": "291670",
    "end": "297800"
  },
  {
    "text": "And the reason why is basically\nbecause for the next 5, or 6, or 10 years, everyone will be\nevaluated on that one benchmark.",
    "start": "297800",
    "end": "305000"
  },
  {
    "text": "And you want papers in three\nyears to be comparable to yours. So it's really important\nthat your evaluations",
    "start": "305000",
    "end": "310389"
  },
  {
    "text": "are reproducible. Honestly, you don't really care\nabout that in the real world. You also want things to be easy\nto work with because researchers",
    "start": "310390",
    "end": "317980"
  },
  {
    "text": "are usually a little\nbit-- they don't want to do additional\nwork that they need to.",
    "start": "317980",
    "end": "324662"
  },
  {
    "text": "And also, they usually don't\nhave that much resource. So it needs to be\nfast and cheap.",
    "start": "324662",
    "end": "329915"
  },
  {
    "text": "And finally, one thing, which\nI really want to highlight, is that for the academic\nbenchmarks that we usually have,",
    "start": "329915",
    "end": "336500"
  },
  {
    "text": "it's fine if the\nmetrics that we use are not perfect, because,\nreally, what matters is that over 10 years, the\ndirection that your metrics is",
    "start": "336500",
    "end": "345069"
  },
  {
    "text": "showing you to go into,\nbasically how the field is moving, really, if\nthe metric is saying",
    "start": "345070",
    "end": "352540"
  },
  {
    "text": "that it's slightly better-- sorry, that it's\nbetter over 10 years, that in reality, the field\nhas made some progress.",
    "start": "352540",
    "end": "359530"
  },
  {
    "text": "So at a meta level,\nit's fine if we use crude metrics in academia.",
    "start": "359530",
    "end": "365940"
  },
  {
    "text": "And also, you kind of need\nto balance between difficulty",
    "start": "365940",
    "end": "372690"
  },
  {
    "text": "and simplicity. And what I mean by that is\nthat if your benchmark is way too complicated, then\nbasically all methods",
    "start": "372690",
    "end": "379980"
  },
  {
    "text": "will have essentially\nrandom performance. So no one will use\nyour benchmark. And if your benchmark\nis too simple,",
    "start": "379980",
    "end": "387610"
  },
  {
    "text": "then the baseline\nwill be so good that no one will use your\nbenchmark because no one can beat the baseline.",
    "start": "387610",
    "end": "393580"
  },
  {
    "text": "This is really something\nthat is specific to academia. In the real world,\nyou're not going to be able to change the task\nthat you're performing based",
    "start": "393580",
    "end": "400710"
  },
  {
    "text": "on how good your model is. So that's why I just\nwant to highlight that, because usually people\ntalk about evaluations,",
    "start": "400710",
    "end": "407139"
  },
  {
    "text": "but there's really\ndifferent ways of evaluating and different\nreasons why we evaluate.",
    "start": "407140",
    "end": "412889"
  },
  {
    "text": "Does that all make sense? Also, feel free\nto ask questions. Great.",
    "start": "412890",
    "end": "418100"
  },
  {
    "text": "OK. So benchmarks in\nacademia, this is really the way we drive the field.",
    "start": "418100",
    "end": "423419"
  },
  {
    "text": "So this is the MMLU benchmark. I think Archit\nbriefly mentioned it, but I'll talk about\nit later again.",
    "start": "423420",
    "end": "429350"
  },
  {
    "text": "So this is the most standard\nbenchmark right now. And you basically see that\nin the last four-ish years,",
    "start": "429350",
    "end": "436160"
  },
  {
    "text": "it has gone from 25% accuracy,\nwhich is essentially random-- because it's multiple choice,\nand there are four choices--",
    "start": "436160",
    "end": "443629"
  },
  {
    "text": "to around 90-ish\npercent accuracy. So yeah, benchmarking\nis really what drives",
    "start": "443630",
    "end": "451010"
  },
  {
    "text": "the progress in the field. And again, you see\nwhat I mean here. What I meant here is\nthat it's not really",
    "start": "451010",
    "end": "456620"
  },
  {
    "text": "the differences between small\npoints that matter, at least in academia. You have to take a step\nback and you have to think.",
    "start": "456620",
    "end": "462230"
  },
  {
    "text": "What matters is how your models\nwill perform over 10 years and making sure that the\nmodel on the top right",
    "start": "462230",
    "end": "467510"
  },
  {
    "text": "here is better than the\nmodel on the bottom left, even if the benchmark\nis not perfect.",
    "start": "467510",
    "end": "474449"
  },
  {
    "text": "And I think MMLU is a pretty\ngood one in that sense. OK.",
    "start": "474450",
    "end": "479460"
  },
  {
    "text": "So there are two main\ntypes, at least classically, of tasks in NLP.",
    "start": "479460",
    "end": "485660"
  },
  {
    "text": "Close-ended tasks, so\nI'll talk about it later. But essentially, you can\nthink about classification",
    "start": "485660",
    "end": "492440"
  },
  {
    "text": "where you know exactly the\ncorrect label for the task that you're performing.",
    "start": "492440",
    "end": "498390"
  },
  {
    "text": "So here, this is\nthe IMDb data set, where you're asked to say\nwhether a sentence has",
    "start": "498390",
    "end": "504380"
  },
  {
    "text": "positive sentiment or\nnegative sentiment. So the text is, \"Read the\nbook, forget the movie!\" So this is about sentiment\nclassification of the movie.",
    "start": "504380",
    "end": "511530"
  },
  {
    "text": "So here, it's\nbasically negative. And then there's\nopen-ended evaluation. So think about ChatGPT.",
    "start": "511530",
    "end": "517413"
  },
  {
    "text": "How do you evaluate\nsomething like that? Where really, there's\nno correct answer. And there are many-- or there\nare many possible correct",
    "start": "517413",
    "end": "524899"
  },
  {
    "text": "answers, and they all\nhave different qualities. So we're going to distinguish\nbetween those two.",
    "start": "524900",
    "end": "532279"
  },
  {
    "text": "So close-ended evaluation. So as I just said, close-ended\ntasks, there's a limited--",
    "start": "532280",
    "end": "539000"
  },
  {
    "text": "it's basically\ndefined as the task where there's a limited\nnumber of potential answers.",
    "start": "539000",
    "end": "544430"
  },
  {
    "text": "Think less than 10. And often, there's\njust one or maybe a few correct possible answers.",
    "start": "544430",
    "end": "553370"
  },
  {
    "text": "So this really is\nstandard machine learning. If you think about\nstandard classification, you can just do accuracy.",
    "start": "553370",
    "end": "559042"
  },
  {
    "text": "You can look at your\nprecision, your recalls. There's nothing\nspecial here about NLP.",
    "start": "559042",
    "end": "564170"
  },
  {
    "text": "That is not to say\nthat it's simple. It's just that there's nothing\nspecial about NLP here.",
    "start": "564170",
    "end": "570890"
  },
  {
    "text": "So some close-ended tasks. I already told you about\nsentiment analysis.",
    "start": "570890",
    "end": "576630"
  },
  {
    "text": "So usually, this is a\nbinary classification task, where you just have to say\nwhether the sentiment is positive or whether\nit's negative.",
    "start": "576630",
    "end": "583675"
  },
  {
    "text": "Another task is entailment. Also, for sentiment analysis,\nthe typical benchmarks-- I always put it\nnext to the task--",
    "start": "583675",
    "end": "590570"
  },
  {
    "text": "is IMDb and SST from Stanford. Entailment is SNLI-- also from\nStanford-- where basically you",
    "start": "590570",
    "end": "596240"
  },
  {
    "text": "have some text. So here, \"A soccer game with\nmultiple males playing.\" And then you have a hypothesis,\n\"Some men are playing sport.\"",
    "start": "596240",
    "end": "603780"
  },
  {
    "text": "And you have to say whether\nthe hypothesis is implied or entailed by the text.",
    "start": "603780",
    "end": "608980"
  },
  {
    "text": "So here it is. Other tasks. Part of speech, typical\nbenchmark, Penn Treebank.",
    "start": "608980",
    "end": "616320"
  },
  {
    "text": "And name entity recognition,\nwhich is a CoNLL benchmark.",
    "start": "616320",
    "end": "621990"
  },
  {
    "text": "A few other tasks. You don't need to\nknow all of them, but just to give you\na brief overview.",
    "start": "621990",
    "end": "627600"
  },
  {
    "text": "Coreference resolution, so this\nis actually a pretty challenging NLP task where you\nhave to say which",
    "start": "627600",
    "end": "635160"
  },
  {
    "text": "pronoun refers to what noun. So you have here the sentence,\n\"Mark told Pete many lies",
    "start": "635160",
    "end": "640920"
  },
  {
    "text": "about himself, which Pete\nincluded in his book. He should have been\nmore truthful.\"",
    "start": "640920",
    "end": "646360"
  },
  {
    "text": "And now you have to say,\nwhat does \"He\" refer to? whether \"he\" refers to Pete.",
    "start": "646360",
    "end": "653220"
  },
  {
    "text": "And then this\nquestion answering, where you basically have a long\ntext and you ask a question,",
    "start": "653220",
    "end": "658230"
  },
  {
    "text": "and-- sorry, the task asks\na question and you're supposed to provide an\nanswer based on the text that you have before.",
    "start": "658230",
    "end": "664319"
  },
  {
    "text": "So those are some examples\nof close-ended tasks. And again, the key here is\nthat the way we evaluate those",
    "start": "664320",
    "end": "672360"
  },
  {
    "text": "is just standard\nmachine learning. You can look at accuracy,\nprecision, recall, F1 score.",
    "start": "672360",
    "end": "677730"
  },
  {
    "text": "Hopefully, you all know\nabout these type of metrics. But if you don't, you should\nlook at Chris Piech's class.",
    "start": "677730",
    "end": "685149"
  },
  {
    "text": "I think it's CS224U. But his lecture is online. It's actually really good\non different metrics.",
    "start": "685150",
    "end": "694620"
  },
  {
    "text": "So the ways that people evaluate\nsome of these benchmarks is usually by looking at\nmany of them concurrently.",
    "start": "694620",
    "end": "702220"
  },
  {
    "text": "So the most common, I would say,\nsuper or multitask benchmark is called SuperGLUE.",
    "start": "702220",
    "end": "707820"
  },
  {
    "text": "So here, you see on\nthe columns here,",
    "start": "707820",
    "end": "713140"
  },
  {
    "text": "you have all the different\ntasks in SuperGLUE. So I think there\nare eight or nine.",
    "start": "713140",
    "end": "718500"
  },
  {
    "text": "And then you really just look\nat the average performance in each of these benchmarks\nand you get a ranking on that.",
    "start": "718500",
    "end": "725260"
  },
  {
    "text": "And that is kind of an attempt\nto measure general language capabilities. This is what people\nused to do, I would say,",
    "start": "725260",
    "end": "732850"
  },
  {
    "text": "until maybe two years ago. I will tell you about\nwhat people do now",
    "start": "732850",
    "end": "739350"
  },
  {
    "text": "around the end of the lecture. But yeah, SuperGLUE\nis definitely something you should\nat least be aware of.",
    "start": "739350",
    "end": "745910"
  },
  {
    "text": "An example of tasks\nthat are in SuperGLUE. One is BoolQ, which is\nsimply you have some text,",
    "start": "745910",
    "end": "753660"
  },
  {
    "text": "you have some\nquestion, and you have to say whether the answer\nis yes or whether it's no. So that's very easy to evaluate.",
    "start": "753660",
    "end": "759250"
  },
  {
    "text": "You just look at accuracies,\nor precision, recall. Entailment, we\nalready talked about.",
    "start": "759250",
    "end": "764690"
  },
  {
    "text": "And then there are other ones\nlike coreference resolution, which we also talked\nabout, and meaning of words, which\nis something where",
    "start": "764690",
    "end": "770570"
  },
  {
    "text": "you have two sentences\nwith the same words and you have to say\nwhether they actually",
    "start": "770570",
    "end": "775580"
  },
  {
    "text": "mean the same thing\nin this sentence. For example, if you have \"bank,\"\nit could mean bank like water",
    "start": "775580",
    "end": "781190"
  },
  {
    "text": "and bank like money. And you have to say whether\nin these two sentences, they refer to the same concept.",
    "start": "781190",
    "end": "787910"
  },
  {
    "text": "And there are some question\nanswering tasks, too. So this is about SuperGLUE.",
    "start": "787910",
    "end": "793590"
  },
  {
    "text": "Are there any questions?  No? Cool.",
    "start": "793590",
    "end": "800300"
  },
  {
    "text": "So again, although I said many\ntimes that this is essentially just classical\nmachine learning, I",
    "start": "800300",
    "end": "806617"
  },
  {
    "text": "want to emphasize that it\ndoesn't mean that it's simple. And you really have\nto think carefully about what you do when you use\nthose type of close-ended tasks.",
    "start": "806617",
    "end": "813962"
  },
  {
    "text": "In particular,\nyou're going to have to choose whether you look at\naccuracies, precision, recall, F1 score, ROC\ncurves, AUC curves.",
    "start": "813962",
    "end": "821073"
  },
  {
    "text": "If you don't know\nthese names, you should really check out\nthe sklearn documentation or the lecture from Chris\nPiech that I linked above,",
    "start": "821073",
    "end": "829339"
  },
  {
    "text": "both of which are really good. But depending on which\nmetric you will choose,",
    "start": "829340",
    "end": "834822"
  },
  {
    "text": "you will decide on very\ndifferent type of algorithms. And the usual example is that\nif, let's say, you look at spam,",
    "start": "834822",
    "end": "844440"
  },
  {
    "text": "you want to do classification of\nwhether an email is spam or not, most emails are not spam,\nthankfully-- at least, I hope.",
    "start": "844440",
    "end": "853183"
  },
  {
    "text": "So let's say that 90% of\nemails were actually not spam and only 10% of them are spam. If you look at the accuracy,\nthen just a random classifier",
    "start": "853183",
    "end": "861540"
  },
  {
    "text": "that predicts the most likely\nlabel will get 90% accuracy. And that seems-- if you don't\nknow really about your data set,",
    "start": "861540",
    "end": "868470"
  },
  {
    "text": "90% accuracy seems good. But in reality, here,\nit means that you're not classifying anything. So that's why you want to look\nat precision, recall, and F1",
    "start": "868470",
    "end": "876000"
  },
  {
    "text": "score. Anyways, I will not\ntalk too much about that because, again, this\nis not specific to NLP,",
    "start": "876000",
    "end": "882430"
  },
  {
    "text": "but it doesn't mean it's easy. Another issue is that once you\nhave multiple different tasks,",
    "start": "882430",
    "end": "887650"
  },
  {
    "text": "there's a question of, how do\nyou aggregate these metrics? So right before, I\ntold you, oh, you just",
    "start": "887650",
    "end": "893130"
  },
  {
    "text": "take the average between\nall of these things? This, honestly, is a really\nterrible thing to do,",
    "start": "893130",
    "end": "898630"
  },
  {
    "text": "but that's actually\nwhat people do. But these columns actually\nmean very different things.",
    "start": "898630",
    "end": "904210"
  },
  {
    "text": "Some of them are accuracies. Others are F1 score. Others are correlations. And you just average everything.",
    "start": "904210",
    "end": "910570"
  },
  {
    "text": "I can't remember\nwhich benchmark, but I remember, a\nfew years ago, there was one benchmark where\nactually one of the columns",
    "start": "910570",
    "end": "916140"
  },
  {
    "text": "was you were better-- basically, you had\nbetter performance if the value was\nlower, and you still",
    "start": "916140",
    "end": "922280"
  },
  {
    "text": "took an average\nof these things-- until someone\nrealized that maybe we should put a minus there.",
    "start": "922280",
    "end": "929390"
  },
  {
    "text": "So yeah, be careful. And don't always think that what\npeople do in academia or in--",
    "start": "929390",
    "end": "935930"
  },
  {
    "text": "yeah, that what\npeople do is correct. You should think a\nlittle bit about that.",
    "start": "935930",
    "end": "941201"
  },
  {
    "text": "Then there are some\nother questions that I want you to think about. Where do those labels come from? I said that it's\nusually a real answer,",
    "start": "941202",
    "end": "948690"
  },
  {
    "text": "but how you actually get\nthose labels is unclear. So I will tell you about some\nissues in the next slide.",
    "start": "948690",
    "end": "957140"
  },
  {
    "text": "And also, related\nto that, there might be some spurious correlations. And that's what we're going\nto talk about right now.",
    "start": "957140",
    "end": "962587"
  },
  {
    "text": "So we already talked\nabout SNLI, so entailment.",
    "start": "962587",
    "end": "968160"
  },
  {
    "text": "So here, you have,\nagain, your premise, \"The economy could still be\nbetter,\" and the hypothesis,",
    "start": "968160",
    "end": "974630"
  },
  {
    "text": "\"The economy has\nnever been better.\" And you have to say\nwhether the hypothesis is implied by the premise.",
    "start": "974630",
    "end": "980130"
  },
  {
    "text": "And what this paper\nfrom 2019 found is that, actually, all\nthe different models",
    "start": "980130",
    "end": "986070"
  },
  {
    "text": "were performing really well. But if you looked--\nif you just classified based on the hypothesis, you\ncould also perform really well.",
    "start": "986070",
    "end": "993280"
  },
  {
    "text": "So even if you did not\nlook at the premise, which seems like something\nthat you need to take into account because\nit's part of the task,",
    "start": "993280",
    "end": "999720"
  },
  {
    "text": "you could perform well. And the reason why\nis because they realized that when the humans\nactually wrote the hypothesis,",
    "start": "999720",
    "end": "1008190"
  },
  {
    "text": "they were asked to\nwrite a hypothesis which is not entailed by the premise. And how humans usually do\nthat is by adding a negation.",
    "start": "1008190",
    "end": "1016250"
  },
  {
    "text": "So if you only look\nat the hypothesis and you see that\nthere is a negation, it's very likely that it's\nnot entailed by the premise.",
    "start": "1016250",
    "end": "1023720"
  },
  {
    "text": "So again, even though this\nis standard machine learning, be really careful about\nwhat metric you use",
    "start": "1023720",
    "end": "1030589"
  },
  {
    "text": "and where do the\nlabels come from. And don't do\neverything-- don't just",
    "start": "1030589",
    "end": "1036290"
  },
  {
    "text": "use what people do, thinking\nthat if there was an issue, people would have realized.",
    "start": "1036290",
    "end": "1042859"
  },
  {
    "text": "So yeah. So that is spurious\ncorrelations. Any questions on\nclose-ended tasks?",
    "start": "1042859",
    "end": "1048910"
  },
  {
    "text": " Cool. OK. Open-ended evaluations.",
    "start": "1048910",
    "end": "1054870"
  },
  {
    "text": "I'm going to mostly talk\nabout that because this is what is specific to NLP. So open-ended evaluation or\nopen-ended tasks is essentially",
    "start": "1054870",
    "end": "1063289"
  },
  {
    "text": "the opposite of the\nclose-ended task, which is to say that there are\nmany possible correct answers,",
    "start": "1063290",
    "end": "1069680"
  },
  {
    "text": "and you cannot\nenumerate all of them. So you really can't use standard\nmachine-learning metrics.",
    "start": "1069680",
    "end": "1075470"
  },
  {
    "text": "And more-- oops. And even more than the fact\nthat you cannot enumerate all",
    "start": "1075470",
    "end": "1080690"
  },
  {
    "text": "the possible answers, usually,\nthere are different levels of correctness.",
    "start": "1080690",
    "end": "1086100"
  },
  {
    "text": "So if I ask you\nto write a book-- or if I ask ChatGPT to write a\nbook, it might be a decent book,",
    "start": "1086100",
    "end": "1091350"
  },
  {
    "text": "but it might be a better book\nthat it could have written or that another\nmodel could write. So it's not just\nright and wrong.",
    "start": "1091350",
    "end": "1097820"
  },
  {
    "text": "It's a continuum or-- yeah, it's a continuum.",
    "start": "1097820",
    "end": "1102860"
  },
  {
    "text": "So standard examples\nfor open-ended tasks. The two most common\nones are summarization.",
    "start": "1102860",
    "end": "1108290"
  },
  {
    "text": "So summarization, you\nhave a long piece of text, and you just ask to summarize\nit in less than x characters.",
    "start": "1108290",
    "end": "1116100"
  },
  {
    "text": "Standard benchmark is the\nCNN and Daily Mail benchmark.",
    "start": "1116100",
    "end": "1121780"
  },
  {
    "text": "So the way they actually\ncollected that data set is that they took a\nlot of CNN articles.",
    "start": "1121780",
    "end": "1127420"
  },
  {
    "text": "And at the top of\nCNN articles, you have bullet points that say what\nare the most important things",
    "start": "1127420",
    "end": "1132720"
  },
  {
    "text": "in the article. So they use this as\nessentially the gold summary.",
    "start": "1132720",
    "end": "1137850"
  },
  {
    "text": "So this is the classic\none for summarization. For translation,\nyou basically have sentences in two\ndifferent languages,",
    "start": "1137850",
    "end": "1143980"
  },
  {
    "text": "and you have to translate\nfrom one to the other. So those are the classical ones. The way that people\ncurrently do it is--",
    "start": "1143980",
    "end": "1151360"
  },
  {
    "text": "I would say, the most\nstandard task right now is instruction-following. Instruction-following\nis kind of the mother",
    "start": "1151360",
    "end": "1158789"
  },
  {
    "text": "of all tasks in the sense that\nyou can view any previous task",
    "start": "1158790",
    "end": "1164460"
  },
  {
    "text": "as just a chat bot\nor some question that you ask to\nbasically ChatGPT. You can think classification.",
    "start": "1164460",
    "end": "1170769"
  },
  {
    "text": "I could just ask\nChatGPT to do that. You can think summarization. I could ask ChatGPT to do that. So essentially, you\ncould just view chat bot",
    "start": "1170770",
    "end": "1177660"
  },
  {
    "text": "as the most general\ntype of task, and you can ask it to\nperform any possible task,",
    "start": "1177660",
    "end": "1183630"
  },
  {
    "text": "and it should just provide\nthe answer for that task. So this is what we call\ninstruction-following. So as you might\nthink, evaluation",
    "start": "1183630",
    "end": "1191160"
  },
  {
    "text": "is very hard in that domain. And that's what we'll\ntalk about later, is how do you evaluate\nsomething like ChatGPT.",
    "start": "1191160",
    "end": "1198820"
  },
  {
    "text": "OK. So types of evaluation\nmethods for text generation or open-ended tasks.",
    "start": "1198820",
    "end": "1204380"
  },
  {
    "text": "The classical ones\nare content overlap metrics, which I'll talk about. So that's really comparing just\nthe words between a reference",
    "start": "1204380",
    "end": "1213110"
  },
  {
    "text": "answer, a gold answer\nthat humans wrote and the actual generation\nthat you got from your model.",
    "start": "1213110",
    "end": "1218720"
  },
  {
    "text": "Then there are\nmodel-based metrics where you basically\nturn evaluation",
    "start": "1218720",
    "end": "1225230"
  },
  {
    "text": "into machine learning. So you ask-- you train a\nmodel to basically become an evaluator.",
    "start": "1225230",
    "end": "1231380"
  },
  {
    "text": "And then there's\nhuman evaluation, which is usually seen\nas the gold standard",
    "start": "1231380",
    "end": "1236389"
  },
  {
    "text": "for open-ended tasks.  So content overlap metrics.",
    "start": "1236390",
    "end": "1242039"
  },
  {
    "text": "So as I just said, this is\nreally just comparing word by word or group of words\nbetween the generated sequence",
    "start": "1242040",
    "end": "1249289"
  },
  {
    "text": "and some reference. So here, I have the\ngenerated sequence being,",
    "start": "1249290",
    "end": "1254480"
  },
  {
    "text": "\"The woman went to the hardware\nstore,\" and the gold reference, which is the reference\nwritten by humans.",
    "start": "1254480",
    "end": "1260367"
  },
  {
    "text": "I actually don't even\nknow what the task is. But the reference here is, \"They\nwalked to the grocery store.\" And then what you\ndo is that you just",
    "start": "1260367",
    "end": "1266750"
  },
  {
    "text": "compare the two\ndifferent sentences by looking at the lexical\nsimilarity between those two",
    "start": "1266750",
    "end": "1272570"
  },
  {
    "text": "texts. And this is super\nfast and efficient. And the way you usually\ndo that is by using n-gram",
    "start": "1272570",
    "end": "1279320"
  },
  {
    "text": "overlap metrics. So what I mean by this is that\nthe simplest possible thing is just to say\nwhether, for every word",
    "start": "1279320",
    "end": "1286310"
  },
  {
    "text": "in the generated sequence,\nwhether it appears in the reference sequence. And if it does, then you kind\nof increment your performance.",
    "start": "1286310",
    "end": "1294500"
  },
  {
    "text": "So n-gram is essentially\nthe same thing. But instead of looking\nat a single word, you basically look at bigrams,\ntrigrams, and multiple words",
    "start": "1294500",
    "end": "1305100"
  },
  {
    "text": "next to one another. So the usual overlap\nmetrics, the most common ones",
    "start": "1305100",
    "end": "1310260"
  },
  {
    "text": "are BLEU and ROUGE. BLEU means blue,\nand ROUGE means red.",
    "start": "1310260",
    "end": "1315797"
  },
  {
    "text": "That's not what they\nstand for though, and I always forget\nwhat they stand for. But basically BLEU,\nwhat it is, is",
    "start": "1315797",
    "end": "1321540"
  },
  {
    "text": "that it's an n-gram\noverlap metric that tries to look at precision,\nwhile ROUGE is what looks",
    "start": "1321540",
    "end": "1330279"
  },
  {
    "text": "at-- it looks at the recall. So as I said before,\nas I alluded before,",
    "start": "1330280",
    "end": "1335350"
  },
  {
    "text": "what is important, even if you\nturn everything into a sentence classification, you have\nto think about whether you",
    "start": "1335350",
    "end": "1340890"
  },
  {
    "text": "care about precision or recall. So those metrics are not ideal.",
    "start": "1340890",
    "end": "1345910"
  },
  {
    "text": "But until, I would\nsay, two years ago, they were the gold standard for\ntranslation and summarization.",
    "start": "1345910",
    "end": "1352320"
  },
  {
    "text": "For translation, people use BLEU\nbecause you really want to--",
    "start": "1352320",
    "end": "1358423"
  },
  {
    "text": "yeah, you really want\nto-- you basically look at the-- let's\nsay I'm translating from French to English. I want to look at the\ngenerated sequence in English",
    "start": "1358423",
    "end": "1366570"
  },
  {
    "text": "and the actual reference\nsequence in English. And I want to know whether every\nbigram that I generated appears,",
    "start": "1366570",
    "end": "1374220"
  },
  {
    "text": "or how many of the\nbigrams that I generated appears in the\nreference sequence.",
    "start": "1374220",
    "end": "1382182"
  },
  {
    "text": "There's one additional\nthing, which is that they don't only look at\nprecision, because you could get a very high precision by\nactually predicting something",
    "start": "1382182",
    "end": "1387930"
  },
  {
    "text": "very small. For example, if you always\npredicted the word \"the,\" only",
    "start": "1387930",
    "end": "1392970"
  },
  {
    "text": "generated the word \"the,\" you\nwould most likely get very high precision because \"the\" usually\nappears in every sentence,",
    "start": "1392970",
    "end": "1399780"
  },
  {
    "text": "or, let's say, a full stop. So there's also\nsome length penalty.",
    "start": "1399780",
    "end": "1406380"
  },
  {
    "text": "And ROUGE is kind\nof the opposite. It just looks at recall. So those are the common\ncontent overlap metrics.",
    "start": "1406380",
    "end": "1414910"
  },
  {
    "text": "And just to illustrate\nwhy those are not ideal--",
    "start": "1414910",
    "end": "1420527"
  },
  {
    "text": "well, they have many\nissues, but one of them is that they don't\nreally take into account the semantic relatedness\nbetween words.",
    "start": "1420527",
    "end": "1427070"
  },
  {
    "text": "So imagine that Chris asks you,\n\"Are you enjoying the CS224N lectures?\"",
    "start": "1427070",
    "end": "1433010"
  },
  {
    "text": "Of course, the gold\nanswer is \"Heck yes!\" So that's the reference answer.",
    "start": "1433010",
    "end": "1439110"
  },
  {
    "text": "So now, let's say that the\nmodel just generates, \"Yes!\" So here, what you're\ngoing to have-- if I look at the BLEU score, I\nwill have 67% essentially BLEU",
    "start": "1439110",
    "end": "1449240"
  },
  {
    "text": "score because two of the\nwords that I generated, or two of the unigrams that I\ngenerated, are in the reference,",
    "start": "1449240",
    "end": "1455960"
  },
  {
    "text": "in the gold reference. If I generate, \"You know it!\"\nthen I will only have a single",
    "start": "1455960",
    "end": "1462290"
  },
  {
    "text": "token in the generated sequence\nthat appears in the reference sequence, which is\nthe exclamation point.",
    "start": "1462290",
    "end": "1468200"
  },
  {
    "text": "So I get a much\nlower BLEU score. And if I just say, \"Yup,\" then\nthat doesn't appear at all",
    "start": "1468200",
    "end": "1475700"
  },
  {
    "text": "in the generated-- sorry,\nin the reference sequence. So I get 0 BLEU score,\nwhich is a false negative",
    "start": "1475700",
    "end": "1481590"
  },
  {
    "text": "because, really, it literally\nmeans the same thing as \"Heck yes!\" So hopefully, you see that these\nmetrics really have issues.",
    "start": "1481590",
    "end": "1491880"
  },
  {
    "text": "Also, you can have\nfalse positives. For example, if\nyou say, \"Heck no!\" then most of the\nwords are the same.",
    "start": "1491880",
    "end": "1497950"
  },
  {
    "text": "So you get 67% BLEU\nscore, but it really means something\ncompletely different.",
    "start": "1497950",
    "end": "1505910"
  },
  {
    "text": "Does that make sense? Any questions? Cool. So very naturally, now\nthat you know everything",
    "start": "1505910",
    "end": "1513720"
  },
  {
    "text": "about word embeddings,\nwhat you might ask is, oh, why do we look at words\nif what we could do",
    "start": "1513720",
    "end": "1519900"
  },
  {
    "text": "is looking at learned\nrepresentations, which really kind of maintained the semantic\nsimilarity between words?",
    "start": "1519900",
    "end": "1528539"
  },
  {
    "text": "So this is exactly what people\nhave done around 2019, I think,",
    "start": "1528540",
    "end": "1534550"
  },
  {
    "text": "is that they took some-- even before actually 2016,\nthey took some word embeddings.",
    "start": "1534550",
    "end": "1541875"
  },
  {
    "text": "They associated every word\nin the reference sequence",
    "start": "1541875",
    "end": "1547920"
  },
  {
    "text": "to a word embedding-- every\nword in the generated sequence to the corresponding\nword embedding.",
    "start": "1547920",
    "end": "1553900"
  },
  {
    "text": "And they basically started\ncomparing the word embeddings. So a very simple way of\ncomparing word embeddings is just to take the\naverage between the word",
    "start": "1553900",
    "end": "1560760"
  },
  {
    "text": "embeddings and the\nreference sequence, and the average between\nthe word embeddings and the generated\nsequence, and you maybe look at cosine similarity.",
    "start": "1560760",
    "end": "1567010"
  },
  {
    "text": "I mean, there are\nsmarter ways of doing it. But honestly, at this point,\nit's not that important. So you can think\nabout averaging.",
    "start": "1567010",
    "end": "1575049"
  },
  {
    "text": "Another one. As you know, at this\npoint, word embeddings",
    "start": "1575050",
    "end": "1581110"
  },
  {
    "text": "don't really take into\naccount the contextual or the context of where\nthe word basically appears.",
    "start": "1581110",
    "end": "1588679"
  },
  {
    "text": "So a better way of getting\ngood representations for a word is by looking\nessentially at BERT.",
    "start": "1588680",
    "end": "1595160"
  },
  {
    "text": "So what you can do is you\ncan take a BERT model. You could pass the generated\nsequence through it.",
    "start": "1595160",
    "end": "1600650"
  },
  {
    "text": "You get some embeddings. And then you can take\nBERT again, the same BERT.",
    "start": "1600650",
    "end": "1606110"
  },
  {
    "text": "You pass the reference\nsequence to it. You get some other\nembeddings, and then you do again some comparison. I mean, this BERTScore,\npretty famous paper.",
    "start": "1606110",
    "end": "1613460"
  },
  {
    "text": "They do some smart\ncomparison, but it's not that important to understand\nwhat exactly they do.",
    "start": "1613460",
    "end": "1619840"
  },
  {
    "text": "What is important is that\nthey take some smart averaging between those words.",
    "start": "1619840",
    "end": "1626870"
  },
  {
    "text": "Cool. Any questions?  OK.",
    "start": "1626870",
    "end": "1633975"
  },
  {
    "text": "So that was the simplest\ntype of learning methods, which is word matching.",
    "start": "1633975",
    "end": "1642690"
  },
  {
    "text": "Another slightly\nmore complicated one is called BLEURT-- also pretty famous-- which is\na mix between BLEU and BERT.",
    "start": "1642690",
    "end": "1651660"
  },
  {
    "text": "So the way that they did\nthat is that basically they took a pretrained\nBERT, and then they",
    "start": "1651660",
    "end": "1657870"
  },
  {
    "text": "do some continual\npretraining by trying to predict the BLEU score\nand some other metrics,",
    "start": "1657870",
    "end": "1663960"
  },
  {
    "text": "and then they fine tune. That's the important part,\nis that they fine-tuned their pretrained model to\nactually do the evaluation",
    "start": "1663960",
    "end": "1670170"
  },
  {
    "text": "that they care about. So let's say that I have a\nlot of different sequences and I have some human\nannotations of how",
    "start": "1670170",
    "end": "1677790"
  },
  {
    "text": "I should be evaluating it. I could just treat that as a\nnormal machine-learning task and I just fine-tune my\nBERT to do the evaluation.",
    "start": "1677790",
    "end": "1686570"
  },
  {
    "text": "So this is BLEURT. Any questions? Yes.",
    "start": "1686570",
    "end": "1692370"
  },
  {
    "text": "Curious. If you pretrained\non BLEU, wouldn't it cause the same problems as the--",
    "start": "1692370",
    "end": "1698553"
  },
  {
    "text": "if your pretraining\nhas this BLEU, then your BERT would\nlearn the ability to model languages semantically\nin the first place.",
    "start": "1698553",
    "end": "1705799"
  },
  {
    "text": "Yeah. That's a very good point. So actually, I also find\nit kind of surprising. So they did two things.",
    "start": "1705800",
    "end": "1711370"
  },
  {
    "text": "First, they do the real\npretraining of BERT, and then they do continual\npretraining for predicting BLEU.",
    "start": "1711370",
    "end": "1717657"
  },
  {
    "text": "And the reason why is\nbecause, usually, they say we have a lot of\nsequences in our data set that are unlabeled.",
    "start": "1717657",
    "end": "1723159"
  },
  {
    "text": "So we have some\nreference sequences and some generated\nsequences, but we",
    "start": "1723160",
    "end": "1729510"
  },
  {
    "text": "don't have the human annotation\nof whether this is good or bad. So we will treat that as an\nunsupervised learning objective.",
    "start": "1729510",
    "end": "1737070"
  },
  {
    "text": "So what do you use for the\nunsupervised learning objective? Well, you have to use something,\nand they basically use BLEU,",
    "start": "1737070",
    "end": "1742500"
  },
  {
    "text": "and they also use\nactually BERT score. So they use many different\ntasks and they basically",
    "start": "1742500",
    "end": "1748799"
  },
  {
    "text": "do multitask learning. Cool.",
    "start": "1748800",
    "end": "1754160"
  },
  {
    "text": "OK. So one important issue\nwith all these methods is that, really,\nthey can only be",
    "start": "1754160",
    "end": "1761010"
  },
  {
    "text": "as good as the references are. And in reality, the references\nare usually not that good.",
    "start": "1761010",
    "end": "1766650"
  },
  {
    "text": "So this is a paper that looks\nat summarization of news.",
    "start": "1766650",
    "end": "1773230"
  },
  {
    "text": "So basically, as I said\nbefore, most of the news summarization\nbenchmarks, they usually",
    "start": "1773230",
    "end": "1779340"
  },
  {
    "text": "take the reference summary\nas being the bullet points that you find at the\ntop of an article.",
    "start": "1779340",
    "end": "1786420"
  },
  {
    "text": "And this is usually\nnot that good. So here, what you see on the-- sorry, on the left, this is--",
    "start": "1786420",
    "end": "1793770"
  },
  {
    "text": "what if you look at the\ncorrelation between the x-axis being the human rate of--",
    "start": "1793770",
    "end": "1800940"
  },
  {
    "text": "or the human-evaluated\nperformance of every model? And on the y-axis,\nyou see the ROUGE-L,",
    "start": "1800940",
    "end": "1806850"
  },
  {
    "text": "which is just a\nvariant of ROUGE, and you look at whether,\nbasically, these two",
    "start": "1806850",
    "end": "1812830"
  },
  {
    "text": "are correlated. And what you see is that they\nare essentially not correlated, which means that ROUGE-L\non the standard references",
    "start": "1812830",
    "end": "1821320"
  },
  {
    "text": "is really not correlated\nto what humans would say is a good summary. That is not to say that\nROUGE is a bad score.",
    "start": "1821320",
    "end": "1828650"
  },
  {
    "text": "That is to say that, actually,\nthe references are bad, because if you look at\nthe exact same thing, but now you ask experts to\nwrite very good summaries,",
    "start": "1828650",
    "end": "1837240"
  },
  {
    "text": "then you see that the\ncorrelation actually increases by a decent amount. It's still not perfect. ROUGE is definitely not perfect,\nbut at least it's much better.",
    "start": "1837240",
    "end": "1845710"
  },
  {
    "text": "So this is to say\nthat the metric itself is not always perfect. But not only this,\nthe references",
    "start": "1845710",
    "end": "1851080"
  },
  {
    "text": "are usually actually not great. Cool.",
    "start": "1851080",
    "end": "1856299"
  },
  {
    "text": "So that begs a very\nnatural question, which is, can we just dump and,\nyeah, basically move away",
    "start": "1856300",
    "end": "1863860"
  },
  {
    "text": "from reference-based evaluation? So as we just said,\nreference-based evaluations are the ones that compare\nhuman-written references",
    "start": "1863860",
    "end": "1870520"
  },
  {
    "text": "to some model outputs using\nsome different type of metrics.",
    "start": "1870520",
    "end": "1876280"
  },
  {
    "text": "And those used to be the\nstandard metrics for evaluating",
    "start": "1876280",
    "end": "1881620"
  },
  {
    "text": "or the standard benchmark\nfor evaluating NLP tasks, I would say, up to two\nor three years ago.",
    "start": "1881620",
    "end": "1887330"
  },
  {
    "text": "Right now, I think\npapers still have to always show the BLEU\nscores, for example,",
    "start": "1887330",
    "end": "1894080"
  },
  {
    "text": "in translation because\nreviewers want those. But I don't think like\nanyone in the real world",
    "start": "1894080",
    "end": "1901660"
  },
  {
    "text": "actually uses them. But I might be wrong on that. So yeah. So BLEU, ROUGE, BERT score.",
    "start": "1901660",
    "end": "1907287"
  },
  {
    "text": "Oh, and I was mostly talking\nabout BLEU and ROUGE. BERT score is actually still\ndecently used and actually",
    "start": "1907287",
    "end": "1912730"
  },
  {
    "text": "pretty good. OK. So reference-free evaluation. So reference-free evaluation\nis basically you have a model",
    "start": "1912730",
    "end": "1920090"
  },
  {
    "text": "and you ask it to give\na score, but there are no human references. So the way that\nthis used to be done",
    "start": "1920090",
    "end": "1927680"
  },
  {
    "text": "is essentially by taking\na model like BERT again. But instead of comparing\nbetween a reference",
    "start": "1927680",
    "end": "1933860"
  },
  {
    "text": "answer and a\ngenerated answer, you could just ask it to take the\ninput and just predict a score.",
    "start": "1933860",
    "end": "1939830"
  },
  {
    "text": "That's one simple\nway of doing it. That used to really\nnot work well. And I say \"used to\" because--\nuntil basically ChatGPT",
    "start": "1939830",
    "end": "1946490"
  },
  {
    "text": "and GPT-4. Now, what people do--\nand honestly, that works super well-- is\nthat you just ask",
    "start": "1946490",
    "end": "1952730"
  },
  {
    "text": "GPT-4 to do the same task\nas you would ask a human. So you give a very\nlong text, and then",
    "start": "1952730",
    "end": "1959360"
  },
  {
    "text": "you give the generated\nsummary, and you ask how good is it essentially. And that works\nsurprisingly well.",
    "start": "1959360",
    "end": "1966470"
  },
  {
    "text": "So common benchmarks here\nare AlpacaEval and MT-Bench. There are many others. Now, honestly, most people start\nusing these type of techniques,",
    "start": "1966470",
    "end": "1975020"
  },
  {
    "text": "but we'll be talking at\nleast about AlpacaEval. Good.",
    "start": "1975020",
    "end": "1980399"
  },
  {
    "text": "OK. So let's talk a little\nbit about human evaluation before looping back\nto basically GPT-4.",
    "start": "1980400",
    "end": "1987400"
  },
  {
    "text": "So as we saw, the\nmetrics until now, they all have some shortcomings.",
    "start": "1987400",
    "end": "1993370"
  },
  {
    "text": "And they are definitely not\nas good as if you ask directly human evaluation, because\nthey are based on references.",
    "start": "1993370",
    "end": "2001200"
  },
  {
    "text": "So human evaluation is\nreally the gold standard for open-ended tasks.",
    "start": "2001200",
    "end": "2009090"
  },
  {
    "text": "And not only is it\nreally the standard way of doing evaluation or the\ngold standard for evaluation,",
    "start": "2009090",
    "end": "2016570"
  },
  {
    "text": "it's also the gold\nstandard for developing new automatic evaluations. So every time you develop a\nnew automatic evaluations,",
    "start": "2016570",
    "end": "2024429"
  },
  {
    "text": "you will want to\ncompare to what humans would have basically predicted.",
    "start": "2024430",
    "end": "2031460"
  },
  {
    "text": "Yeah.  OK. So during human\nevaluation, at first,",
    "start": "2031460",
    "end": "2038077"
  },
  {
    "text": "it might seem very simple. You basically ask humans\nto evaluate the quality of some generated text. Seems simple, right?",
    "start": "2038077",
    "end": "2044370"
  },
  {
    "text": "But actually, it's\nsuper complicated, and it's a real challenge,\nand it has many issues.",
    "start": "2044370",
    "end": "2050408"
  },
  {
    "text": "So first-- oh, sorry. I'll talk about that before-- maybe one additional thing\nis that you should not only",
    "start": "2050409",
    "end": "2056190"
  },
  {
    "text": "ask the human. You usually ask it also to-- ask them to evaluate\nacross different axes.",
    "start": "2056190",
    "end": "2062940"
  },
  {
    "text": "For example, the\nfluency of the text, or the coherence of the\ntext, or common sense, or the style, grammaticality,\nredundancy, and different",
    "start": "2062940",
    "end": "2071550"
  },
  {
    "text": "axes that you might care about. Another thing to note is\nthat you should absolutely",
    "start": "2071550",
    "end": "2077250"
  },
  {
    "text": "never compare different\nhuman evaluations. So if there's one\npaper that says, oh, humans have evaluated\nthe fluency of our text",
    "start": "2077250",
    "end": "2084989"
  },
  {
    "text": "to be, I don't know, four out\nof five, and then another paper that says like\nthree out of five,",
    "start": "2084989",
    "end": "2090280"
  },
  {
    "text": "they used different\nhumans, different ways of prompting the humans, so\nit's absolutely not comparable.",
    "start": "2090280",
    "end": "2098420"
  },
  {
    "text": "OK. So let's go back to\nsome of the issues. So as I said,\nhuman judgments are",
    "start": "2098420",
    "end": "2103560"
  },
  {
    "text": "regarded as the gold standard,\nbut it definitely has issues. First, it's super slow.",
    "start": "2103560",
    "end": "2109859"
  },
  {
    "text": "As you might expect,\nhumans are definitely not as fast as automatic metrics.",
    "start": "2109860",
    "end": "2115980"
  },
  {
    "text": "Second, at least in academia,\nit's still pretty expensive to do because, I mean, when\nyou pay well your workers,",
    "start": "2115980",
    "end": "2124320"
  },
  {
    "text": "it's pretty expensive to\ndo, well, human evaluation. Another part is\ninter-annotator disagreement.",
    "start": "2124320",
    "end": "2131350"
  },
  {
    "text": "So if I take two random\npeople in this room and I ask them to evaluate the\nquality of a generated text,",
    "start": "2131350",
    "end": "2137800"
  },
  {
    "text": "I can assure you that you\nwill really not agree. So this is-- even if--\nespecially if it's subjective,",
    "start": "2137800",
    "end": "2143620"
  },
  {
    "text": "it's really bad. But even if you\ntalk for one hour before about how you should\nbe evaluating generations,",
    "start": "2143620",
    "end": "2152950"
  },
  {
    "text": "I can most likely guarantee you\nthat you will still disagree on many of the evaluations.",
    "start": "2152950",
    "end": "2159260"
  },
  {
    "text": "And to give you an example,\nwhen we were doing Alpaca farm last year, which is\nsomething where we basically",
    "start": "2159260",
    "end": "2166870"
  },
  {
    "text": "had to take some inputs\nand then take two models--",
    "start": "2166870",
    "end": "2173980"
  },
  {
    "text": "think ChatGPT, Alpaca,\nand these type of models-- and you just have the two\nmodels predict an answer,",
    "start": "2173980",
    "end": "2180590"
  },
  {
    "text": "and then you ask the humans to\nsay which answer they prefer. This is a very simple task.",
    "start": "2180590",
    "end": "2186700"
  },
  {
    "text": "And this is what-- I will talk about it later. This is what a lot\nof people basically use right now for evaluating\nmodels like ChatGPT.",
    "start": "2186700",
    "end": "2194650"
  },
  {
    "text": "So a natural question is whether\nhumans are good at doing that. And what we saw is\nthat-- so we were",
    "start": "2194650",
    "end": "2200710"
  },
  {
    "text": "five researchers doing that. And the five of us, we talked\nfor two or three hours.",
    "start": "2200710",
    "end": "2205730"
  },
  {
    "text": "We wrote extremely\ndetailed rubrics about how to do the evaluations. And still, we only\nagreed 67% of the time.",
    "start": "2205730",
    "end": "2213500"
  },
  {
    "text": "So 50% is like random. And if we just label\nthings independently,",
    "start": "2213500",
    "end": "2218770"
  },
  {
    "text": "we only agree 67% of the time. And we really tried\nto do our best. We were working on this thing.",
    "start": "2218770",
    "end": "2224860"
  },
  {
    "text": "So it's not as if we were\ntrying to do it quickly. So really, people disagree. Of course, if you\nthen allow discussions",
    "start": "2224860",
    "end": "2231480"
  },
  {
    "text": "between the annotators, then\nagreement actually improves.",
    "start": "2231480",
    "end": "2236550"
  },
  {
    "text": "But then it becomes even more-- slower and more expensive. Inter-annotator disagreement.",
    "start": "2236550",
    "end": "2242000"
  },
  {
    "text": "This is something that\nis extremely annoying, which is that if I ask a human-- if I ask myself right now\nto evaluate something,",
    "start": "2242000",
    "end": "2248640"
  },
  {
    "text": "or in three hours, after I have\ndinner, or after I went to run, I will actually give\ndifferent annotations.",
    "start": "2248640",
    "end": "2255680"
  },
  {
    "text": "Yes. How did you find\n[INAUDIBLE] samples you might need to\nverify the model?",
    "start": "2255680",
    "end": "2263870"
  },
  {
    "text": "You mean for validating-- yeah, so this is a\nvery good question. Honestly, there\nis no good answer.",
    "start": "2263870",
    "end": "2270070"
  },
  {
    "text": "The usual way that\npeople do it is that you look at some\nstatistical matrix,",
    "start": "2270070",
    "end": "2277922"
  },
  {
    "text": "basically, where\nyou're like, OK, I want to compare between\nthese two models. I'm going to look at-- I'm going to basically\nperform a t-test,",
    "start": "2277922",
    "end": "2284297"
  },
  {
    "text": "and I want to know\nthat my p-value is less than a certain amount. What people usually do also when\nthey have humans' annotations--",
    "start": "2284297",
    "end": "2291440"
  },
  {
    "text": "I unfortunately didn't\nput a slide on that, but they have metrics for\ncomputing the inter-annotator,",
    "start": "2291440",
    "end": "2296840"
  },
  {
    "text": "basically, agreement\nand they try to achieve a certain\ninter-annotator agreement. And if not, they will\nessentially ask for more humans",
    "start": "2296840",
    "end": "2304280"
  },
  {
    "text": "or for relabelings. Yeah.",
    "start": "2304280",
    "end": "2309410"
  },
  {
    "text": "It's not reproducible. And this is partly\nbecause of the two things that we said before, but\nalso partly because--",
    "start": "2309410",
    "end": "2317360"
  },
  {
    "text": "yeah, I mean, mostly because\nof the two things before. So this is an\ninteresting paper--",
    "start": "2317360",
    "end": "2323420"
  },
  {
    "text": "I forgot which year. I think it's from 2021,\nbut I'm not sure-- where, basically, they say-- and\nI read from the abstract here--",
    "start": "2323420",
    "end": "2330000"
  },
  {
    "text": "\"just 5% of human evaluations\nare repeatable in the sense that there are no prohibitive\nbarriers to repetition,",
    "start": "2330000",
    "end": "2335820"
  },
  {
    "text": "and sufficient information about\nexperimental design is publicly available for rerunning them.\"",
    "start": "2335820",
    "end": "2341520"
  },
  {
    "text": "So this is a paper\nthat analyzed, I think, 128 different papers that were\npublished across five years,",
    "start": "2341520",
    "end": "2348780"
  },
  {
    "text": "I think, between 2015 and 2020. And they found that essentially\nonly 5% of those papers",
    "start": "2348780",
    "end": "2354200"
  },
  {
    "text": "were reproducible. So honestly, working\nwith humans is hard. That's definitely\nsomething to remember.",
    "start": "2354200",
    "end": "2362540"
  },
  {
    "text": "Another part is that humans only\nbasically evaluate precision and not recall.",
    "start": "2362540",
    "end": "2368310"
  },
  {
    "text": "So what I mean by that\nis that if you show me what the model generated, I can\nonly evaluate that generation.",
    "start": "2368310",
    "end": "2374980"
  },
  {
    "text": "I cannot evaluate all the other\npossible generations that it could have generated, because\nthen you really have to sample",
    "start": "2374980",
    "end": "2382200"
  },
  {
    "text": "a lot of things, and that will\nbecome way too slow and way too expensive. And finally, usually, the\nincentives are not aligned.",
    "start": "2382200",
    "end": "2390250"
  },
  {
    "text": "So what you want\nis for the humans to basically do the best\npossible evaluations.",
    "start": "2390250",
    "end": "2395640"
  },
  {
    "text": "But what crowdworkers\nusually want is basically to maximize\nthe amount of money that they get paid per hour.",
    "start": "2395640",
    "end": "2402340"
  },
  {
    "text": "So to give you, again,\na concrete example, when we were doing\nAlpaca farm, I",
    "start": "2402340",
    "end": "2409050"
  },
  {
    "text": "think we were paying\nrelatively well in the sense that we were paying a 1.5 times\nthe minimum wage in California.",
    "start": "2409050",
    "end": "2416910"
  },
  {
    "text": "And then we divided\nbasically-- we looked at how much time we would\nspend to do the thing basically",
    "start": "2416910",
    "end": "2423060"
  },
  {
    "text": "to evaluate a single\nexample the best we could, and then we divide\nit by that time",
    "start": "2423060",
    "end": "2429359"
  },
  {
    "text": "to basically know how much we\nwould pay for every example. And what we realized is that\nthey ended up being paid,",
    "start": "2429360",
    "end": "2437079"
  },
  {
    "text": "I think, 2 or 2.5\ntimes the minimum wage because they were just doing\nthings like two or three times faster than us.",
    "start": "2437080",
    "end": "2443070"
  },
  {
    "text": "And I mean, we\ncould be slow, but I think what was happening\nis that they were just trying to maximize the dollars\nthat they were getting per hour.",
    "start": "2443070",
    "end": "2450610"
  },
  {
    "text": "And as a result, they\nwere finding shortcuts for doing their evaluations. And this is something that you\nreally see in a lot of papers.",
    "start": "2450610",
    "end": "2458340"
  },
  {
    "text": "For example, in our case,\nyou saw that humans really preferred longer answers. And of course, if you\ngive me two very long--",
    "start": "2458340",
    "end": "2466289"
  },
  {
    "text": "like two, sorry,\ngenerations and you ask me, with minimal\namount of work, to say which one is better,\nif I see a longer one,",
    "start": "2466290",
    "end": "2472428"
  },
  {
    "text": "I'm like, probably,\nthere are more details. Probably, it's better. Anyways, it's not to say\nthat everyone is like that.",
    "start": "2472428",
    "end": "2478720"
  },
  {
    "text": "But definitely, the\nincentives are not aligned. So you have to be\ncareful with this. Other challenges.",
    "start": "2478720",
    "end": "2485390"
  },
  {
    "text": "First, you have to decide\nhow to describe the task. You really have to give\nvery detailed rubrics",
    "start": "2485390",
    "end": "2490549"
  },
  {
    "text": "for how the humans have\nto evaluate the task. Then there's a question of how\nto show the task to the humans.",
    "start": "2490550",
    "end": "2496458"
  },
  {
    "text": "For example, the order in\nwhich you give examples is actually really important. In our case, because we had\ntwo examples side by side,",
    "start": "2496458",
    "end": "2502770"
  },
  {
    "text": "they're actually--\nwhich one is on the left and which one is on the right\nis actually also very important. So all these things\nreally matter.",
    "start": "2502770",
    "end": "2509002"
  },
  {
    "text": "Of course, you can\nrandomize these things away, but it adds challenges.",
    "start": "2509002",
    "end": "2514010"
  },
  {
    "text": "What metrics do you use? I mean, this is not\nspecific to humans. Selecting the annotators,\nthis is also very complicated.",
    "start": "2514010",
    "end": "2520670"
  },
  {
    "text": "You might think, OK,\nI have some money. Now, I can go on Amazon\nMTurkers and I can just ask them to evaluate or\nto do some annotations.",
    "start": "2520670",
    "end": "2529260"
  },
  {
    "text": "But in reality, you want to\nhave the good annotators. So how it usually\nworks in Amazon--",
    "start": "2529260",
    "end": "2534510"
  },
  {
    "text": "in MTurk is that, basically,\nyou say, oh, here's a task. I want 30 different people\nto do these annotations.",
    "start": "2534510",
    "end": "2541880"
  },
  {
    "text": "And then they start\nannotating, and then you-- if they don't achieve\nthe level that you want,",
    "start": "2541880",
    "end": "2547360"
  },
  {
    "text": "you basically pay for\nwhat they annotated. Until then, you work with\nsomeone else afterwards. So then there's a\nquestion of, how",
    "start": "2547360",
    "end": "2553560"
  },
  {
    "text": "do you decide whether they\nachieved the performance that you want? So you probably have to do\nsome gold labeling before",
    "start": "2553560",
    "end": "2559800"
  },
  {
    "text": "and then look at some\naccuracies of how well-- and some inter-annotator\nagreement with you and with the other\nresearchers on your team.",
    "start": "2559800",
    "end": "2567390"
  },
  {
    "text": "So it is very complicated. And not only this, you have\nto monitor that over time.",
    "start": "2567390",
    "end": "2573089"
  },
  {
    "text": "So there are many different ways\nyou can monitor that over time, looking, again, at the accuracy. So maybe every-- let's\nsay a typical thing is",
    "start": "2573090",
    "end": "2579750"
  },
  {
    "text": "that every batch of example\nthat you label, you give a few examples that are\nactually ones that you already",
    "start": "2579750",
    "end": "2586680"
  },
  {
    "text": "know what the gold label is\nand you see how well they are performing on that. Another way to look at is the\ntime that they take to annotate.",
    "start": "2586680",
    "end": "2595349"
  },
  {
    "text": "Yeah. OK. So that was about humans. So human evaluation is hard,\nbut it is the gold standard.",
    "start": "2595350",
    "end": "2603630"
  },
  {
    "text": "OK. Now let's talk about\nreference-free evaluation and chat bots. So I already told you about\nit before very briefly.",
    "start": "2603630",
    "end": "2610100"
  },
  {
    "text": "How do you evaluate\nsomething like ChatGPT? This is extremely complicated\nbecause, basically, you could ask it any task you\nwant and it can answer",
    "start": "2610100",
    "end": "2619180"
  },
  {
    "text": "text that is arbitrarily long. And that just makes\nevaluation extremely hard.",
    "start": "2619180",
    "end": "2625750"
  },
  {
    "text": "So as I suggested before,\nthe usual way that it's done is that you take two models. You put them side by side. You ask the same\nquestion, and you just",
    "start": "2625750",
    "end": "2632770"
  },
  {
    "text": "ask either some\nhumans or some model, as we will see afterwards,\nwhich one is better.",
    "start": "2632770",
    "end": "2638800"
  },
  {
    "text": "So this is the most\ncommon benchmark right now, I would say,\nfor human evaluation.",
    "start": "2638800",
    "end": "2644510"
  },
  {
    "text": "It's called ChatGPT Chatbot\nArena, where basically anyone can go online and just play\nfor free with some of the best",
    "start": "2644510",
    "end": "2651820"
  },
  {
    "text": "models out there. And all they ask you is\nto say whether you prefer the one on the right or whether\nyou prefer the one on the left,",
    "start": "2651820",
    "end": "2658020"
  },
  {
    "text": "essentially. And then once they reach, I\nthink, a crazy amount of data, 200,000 human\nvotes, for example,",
    "start": "2658020",
    "end": "2665040"
  },
  {
    "text": "they basically add\nit to a leaderboard. And the way they add\nit to a leaderboard is that they essentially--",
    "start": "2665040",
    "end": "2670609"
  },
  {
    "text": "I don't know if you\nknow how chess works, but they basically look\nat the Elo ratings. So they basically put everything\nas if it was a tournament",
    "start": "2670610",
    "end": "2679160"
  },
  {
    "text": "so that not every model has to\nplay against every other model, and then they get Elo scores.",
    "start": "2679160",
    "end": "2687220"
  },
  {
    "text": "OK. So what's missing with this\nside-by-side human eval? As I said, this is\nreally the gold standard",
    "start": "2687220",
    "end": "2692260"
  },
  {
    "text": "for evaluation of chat LLMs, but\nthere are still some challenges. First, it's basically\nrandom people online",
    "start": "2692260",
    "end": "2700089"
  },
  {
    "text": "that ask random questions and\nthey provide their preferences. So that may not\nbe representative,",
    "start": "2700090",
    "end": "2707330"
  },
  {
    "text": "although, arguably, when\nyou have that many examples, it becomes actually pretty\nrepresentative of what people would want.",
    "start": "2707330",
    "end": "2713590"
  },
  {
    "text": "So it's probably better\nthan whatever we have, but it is still not ideal.",
    "start": "2713590",
    "end": "2719720"
  },
  {
    "text": "And then really, the\nbig issue is cost. This takes a huge community\neffort and a lot of people",
    "start": "2719720",
    "end": "2726880"
  },
  {
    "text": "to work on that. Also, it takes a lot of time to\nget new models on the benchmark.",
    "start": "2726880",
    "end": "2733330"
  },
  {
    "text": "And only the notable\nmodels, I think, like the OpenAI\nmodels, and the Claude, and like the Google ones,\nand the Facebook ones",
    "start": "2733330",
    "end": "2739330"
  },
  {
    "text": "are going to be benchmarked. You will never have,\nfor your random model, 200,000 people who are willing\nto annotate it for free.",
    "start": "2739330",
    "end": "2748160"
  },
  {
    "text": "So this is an issue. And again, as we talked\nabout in the first slide, even for those big\ncompanies, they",
    "start": "2748160",
    "end": "2753760"
  },
  {
    "text": "can definitely not do that for\ndevelopment of their model. This is something that comes at\nthe end for the model selection.",
    "start": "2753760",
    "end": "2761349"
  },
  {
    "text": "OK. So how do we make it faster? So one very natural\nsolution is basically",
    "start": "2761350",
    "end": "2768630"
  },
  {
    "text": "to ask a large language model\nto do the evaluation for you. So imagine that I want to\ncompare ChatGPT with Mistral.",
    "start": "2768630",
    "end": "2774760"
  },
  {
    "text": "I basically ask GPT-4 to\nevaluate which one is better. This is surprisingly good.",
    "start": "2774760",
    "end": "2781360"
  },
  {
    "text": "And I will show you\nsome results afterwards. And some common versions\nare AlpacaEval and MT-Bench.",
    "start": "2781360",
    "end": "2786590"
  },
  {
    "text": "Probably the two\nmost common ones. So when we started\ndoing that, that's the problem I told you about.",
    "start": "2786590",
    "end": "2792930"
  },
  {
    "text": "We started that\naround last year, and we found that using GPT-4\nessentially for evaluation is--",
    "start": "2792930",
    "end": "2801000"
  },
  {
    "text": "at least if you look\nat the prices now, it would be a\nhundred times faster and a hundred times cheaper than\nif you use human evaluations.",
    "start": "2801000",
    "end": "2808830"
  },
  {
    "text": "But-- and this is very\nsurprising-- the agreement with humans is actually\nhigher than humans",
    "start": "2808830",
    "end": "2815370"
  },
  {
    "text": "agree with themselves. So what I mean by\nthat is that if I ask-- so this is what we found. If I ask four humans--",
    "start": "2815370",
    "end": "2823270"
  },
  {
    "text": "let's say I have a\npool of four humans, and I take out one\nhuman, and I look at the agreement between\nthat human preferences",
    "start": "2823270",
    "end": "2830079"
  },
  {
    "text": "and the mode of the preferences\nof the three others, and I do that in a\nleave-one-out fashion,",
    "start": "2830080",
    "end": "2835269"
  },
  {
    "text": "and I look at disagreement. This will be lower than\nif I ask for the model",
    "start": "2835270",
    "end": "2840790"
  },
  {
    "text": "to predict essentially\nthe preference of the mode of the humans. So in some ways, models\nare more highly correlated",
    "start": "2840790",
    "end": "2849160"
  },
  {
    "text": "with humans than\nhumans themselves, which is very surprising. And I will tell you about it in\ntwo seconds a little bit more.",
    "start": "2849160",
    "end": "2854273"
  },
  {
    "text": "When we did that, we\nactually used that for collecting human\npreferences for RLHF.",
    "start": "2854273",
    "end": "2860560"
  },
  {
    "text": "So that's what we call our\nAIF, as I think Archit told you about these things last week.",
    "start": "2860560",
    "end": "2866714"
  },
  {
    "text": " So going back to this\nsurprising result",
    "start": "2866715",
    "end": "2872950"
  },
  {
    "text": "that actually models\nare more highly correlated with humans\nthan humans themselves. The reason why this is,\nis because humans actually",
    "start": "2872950",
    "end": "2879970"
  },
  {
    "text": "have high inter-annotator\ndisagreement and have high\nvariances essentially.",
    "start": "2879970",
    "end": "2885290"
  },
  {
    "text": "Models, they will always be\nvery consistent-- or maybe not perfectly. There's still some\nstochasticity.",
    "start": "2885290",
    "end": "2891680"
  },
  {
    "text": "But essentially, they will\nalways predict the same label. So they have very\nlittle variance. So here, what you\nsee on this plot",
    "start": "2891680",
    "end": "2897987"
  },
  {
    "text": "is on the y-- sorry, x-axis,\nwe estimated the variance, and you see that the human has\na variance of around 31 or 33,",
    "start": "2897987",
    "end": "2906560"
  },
  {
    "text": "while, if you look\nat the red point, this is basically if you just\nhad GPT-4 to do evaluations. So even though the bias\nis still pretty high--",
    "start": "2906560",
    "end": "2914030"
  },
  {
    "text": "so bias, by definition,\nfor humans is zero. For GPT-4, it is\naround 32% The variance",
    "start": "2914030",
    "end": "2920630"
  },
  {
    "text": "is much lower than humans. So this is why you can see\nthat, actually, sometimes",
    "start": "2920630",
    "end": "2926860"
  },
  {
    "text": "the agreement is higher,\nbut that's really because there's no variance or\nvery little variance in LLMs.",
    "start": "2926860",
    "end": "2934580"
  },
  {
    "text": "Yeah. Does that make sense?  Yeah. [INAUDIBLE] is\nhigher than a human,",
    "start": "2934580",
    "end": "2942472"
  },
  {
    "text": "it means that the internal\ncoherence of the LLM is higher than a human? Exactly, which is\nactually a good sign,",
    "start": "2942472",
    "end": "2947859"
  },
  {
    "text": "because that means it's--\nthat makes it much easier for research. The bad sign is that\nthe bias is so high.",
    "start": "2947860",
    "end": "2954994"
  },
  {
    "text": "Yeah. OK. So things to be careful\nwith when you work. I mean, this is both with\nhumans and with LLMs.",
    "start": "2954994",
    "end": "2963300"
  },
  {
    "text": "There will be some\nspurious correlation. So we already talked about\nspurious correlations, but you will see a lot of those.",
    "start": "2963300",
    "end": "2968880"
  },
  {
    "text": "One very common\nexample is length. So if you just-- as\nI told you before,",
    "start": "2968880",
    "end": "2974050"
  },
  {
    "text": "if you ask crowdworkers\nwhich examples they prefer, they are highly biased\ntowards a longer output.",
    "start": "2974050",
    "end": "2979750"
  },
  {
    "text": "So here, the blue is humans. It's around, I think, 70%\npreferences for longer outputs.",
    "start": "2979750",
    "end": "2985350"
  },
  {
    "text": "And models are\naround the same bias. And another example is\npreference for lists.",
    "start": "2985350",
    "end": "2991329"
  },
  {
    "text": "So usually, if you see\nlists in an output, models prefer these\nexamples, and models--",
    "start": "2991330",
    "end": "2997020"
  },
  {
    "text": "model and humans\nprefer these examples. Another bias or spurious\ncorrelation is the position.",
    "start": "2997020",
    "end": "3002690"
  },
  {
    "text": "I told you how, which one\nyou put on the left, which one do you put on the\nright when you compare-- when you ask humans\nto label, this",
    "start": "3002690",
    "end": "3008730"
  },
  {
    "text": "is the same thing with models. But this is usually\npretty easy to control for you just randomize both. Another issue is\nGPT-4 self bias.",
    "start": "3008730",
    "end": "3016089"
  },
  {
    "text": "So very naturally,\nyou might wonder, if I ask GPT-4 to evaluate\nitself, it will probably bias--",
    "start": "3016090",
    "end": "3023500"
  },
  {
    "text": "it will prefer itself\nthan other models. And this is true. But less than what\nyou might think.",
    "start": "3023500",
    "end": "3029329"
  },
  {
    "text": "I will tell you about it later. OK. So AlpacaEval. ",
    "start": "3029330",
    "end": "3034810"
  },
  {
    "text": "Wait. Until what time do I have?  You have 30 minutes.",
    "start": "3034810",
    "end": "3039960"
  },
  {
    "text": "Oh. Thanks. Great. OK. AlpacaEval. So AlpacaEval is the\nbenchmark that we developed",
    "start": "3039960",
    "end": "3047220"
  },
  {
    "text": "when we were working on Alpaca. So as I told you\nbefore, we need-- one thing which\nis very important",
    "start": "3047220",
    "end": "3053480"
  },
  {
    "text": "is what you use for\ndevelopment, so basically for hyperparameter tuning. So what we did is\nthat we basically",
    "start": "3053480",
    "end": "3060380"
  },
  {
    "text": "did not trust many\nof the benchmarks out there at this point\nfor instruction following. So we just developed a very\nsmall benchmark for ourselves,",
    "start": "3060380",
    "end": "3067980"
  },
  {
    "text": "and this is what we were\ndoing for fine-tuning, and then it kind of\nbecame its own thing.",
    "start": "3067980",
    "end": "3073309"
  },
  {
    "text": "So AlpacaEval in a few numbers. It has very high correlation\nwith Chatbot Arena. So the ranking-- if you\nlook at the correlation",
    "start": "3073310",
    "end": "3080660"
  },
  {
    "text": "between the ranking in Chatbot\nArena and in AlpacaEval, it's 98% So very high.",
    "start": "3080660",
    "end": "3085940"
  },
  {
    "text": "And it takes around three\nminutes and $10 to evaluate. And the way it works--",
    "start": "3085940",
    "end": "3091948"
  },
  {
    "text": "I think I already mentioned it. But basically, you\ntake an instruction. You generate an\noutput from one model",
    "start": "3091948",
    "end": "3098250"
  },
  {
    "text": "and then from another model\nthat you're comparing it to, and you ask GPT-4 to basically\ngive the probability that it",
    "start": "3098250",
    "end": "3104609"
  },
  {
    "text": "prefers the model that you're\nevaluating versus the baseline that you're comparing to.",
    "start": "3104610",
    "end": "3111029"
  },
  {
    "text": "And then you do\nsome reweighting. And the reason why you\ndo some reweighting is because these\nmodels, as I said,",
    "start": "3111030",
    "end": "3117400"
  },
  {
    "text": "are very biased\ntowards longer outputs. So you want to reweight such\nthat if it's a longer output,",
    "start": "3117400",
    "end": "3124390"
  },
  {
    "text": "you give it a slightly\nless high preference, and then you average across\nyour entire data set,",
    "start": "3124390",
    "end": "3130619"
  },
  {
    "text": "and you get a win rate. So that's how it works. Any questions?",
    "start": "3130620",
    "end": "3138750"
  },
  {
    "text": "Cool. So a system-level correlation. So here, what you see on the\nx-axis is basically AlpacaEval--",
    "start": "3138750",
    "end": "3145238"
  },
  {
    "text": "I mean, it's a slight\ntransformation of it, but essentially\nAlpacaEval scores. And on the y-axis is\nthis Chatbot Arena,",
    "start": "3145238",
    "end": "3151815"
  },
  {
    "text": "which is the gold standard. And you see that things are\nrelatively highly correlated. And on the lower plots, you\nsee basically the correlation",
    "start": "3151815",
    "end": "3159680"
  },
  {
    "text": "between different benchmark\nand Chatbot Arena. And you see MT-Bench\nand AlpacaEval, which are the two ones that\nuse LLMs for evaluations,",
    "start": "3159680",
    "end": "3166550"
  },
  {
    "text": "are relatively highly\ncorrelated with Chatbot Arena. And MMLU, which is the automated\none that doesn't use an LLM,",
    "start": "3166550",
    "end": "3173270"
  },
  {
    "text": "is also very highly correlated.  So I told you very\nbriefly about the fact",
    "start": "3173270",
    "end": "3179460"
  },
  {
    "text": "that we had to do\nsome reweighting. So I'm not going to\ntell you how we do it, but I want to tell\nyou why we do it.",
    "start": "3179460",
    "end": "3185730"
  },
  {
    "text": "One of the issues that we\nrealized a little bit too late",
    "start": "3185730",
    "end": "3191160"
  },
  {
    "text": "is that if you take\nsomething like GPT-4 and you just ask it-- you\nprompt it to be much more",
    "start": "3191160",
    "end": "3197610"
  },
  {
    "text": "detailed, to basically provide\nmuch more detailed answers, its win rate, so its\nperformance on your benchmark,",
    "start": "3197610",
    "end": "3204150"
  },
  {
    "text": "goes from 50% to 64.3%. So that's this one, 64.3%.",
    "start": "3204150",
    "end": "3210060"
  },
  {
    "text": "If you ask it to be more\nconcise, it decreases to 22.9. And that really doesn't fit\nour mental model of what",
    "start": "3210060",
    "end": "3216060"
  },
  {
    "text": "benchmarks should be doing. If I just change, tweak\na little bit the prompt, I don't want my model to\nchange completely its ranking.",
    "start": "3216060",
    "end": "3225300"
  },
  {
    "text": "So that's why we have\nto do some reweighting. And you see that\nafter the reweighting, you basically have that--",
    "start": "3225300",
    "end": "3231089"
  },
  {
    "text": "the performance after you ask\nthe model to be more verbose",
    "start": "3231090",
    "end": "3236890"
  },
  {
    "text": "is very close to the performance\nwithout any prompt tuning. ",
    "start": "3236890",
    "end": "3245029"
  },
  {
    "text": "Cool. So I told you slight-- very briefly before\nabout self-bias. I do want to say that I'm pretty\nsurprised about this result.",
    "start": "3245030",
    "end": "3252920"
  },
  {
    "text": "But actually, self-bias\nexists, but it's not as high as you might think.",
    "start": "3252920",
    "end": "3258850"
  },
  {
    "text": "So here, you see on the\nx-axes the ranking-- or the different models that\nyou're evaluating, and on the--",
    "start": "3258850",
    "end": "3267070"
  },
  {
    "text": "sorry, that's on the rows. And on the columns, you\nsee who is evaluating. Which model are you\nusing for evaluation?",
    "start": "3267070",
    "end": "3273319"
  },
  {
    "text": "And you actually see that\nregardless of the model that you have that\nyou evaluate with, the ranking will be the same.",
    "start": "3273320",
    "end": "3279680"
  },
  {
    "text": "So even though it's true that\nif I look at Mistral evaluated",
    "start": "3279680",
    "end": "3287290"
  },
  {
    "text": "by Mistral, it gives itself\na much higher accuracy, it still prefers\nClaude and GPT-4.",
    "start": "3287290",
    "end": "3294790"
  },
  {
    "text": "So it's not as bad as\nwhat you may think. It's still bad though. ",
    "start": "3294790",
    "end": "3300490"
  },
  {
    "text": "Cool. OK. So that leads me to talking\nabout current evaluation of LLMs.",
    "start": "3300490",
    "end": "3306470"
  },
  {
    "text": "So I'd say there are three\nmain ways that people currently evaluate LLMs. The first one is\nperplexity, which",
    "start": "3306470",
    "end": "3313240"
  },
  {
    "text": "is essentially just looking at\ntraining losses or validation losses. The second one is basically\naveraging everything,",
    "start": "3313240",
    "end": "3320900"
  },
  {
    "text": "which is actually\nsurprisingly more common than what you may think. And the third one\nis this arena-like,",
    "start": "3320900",
    "end": "3327140"
  },
  {
    "text": "or where you basically have\ncomparisons between models, and either you use humans or you\nuse models to do the evaluation.",
    "start": "3327140",
    "end": "3333990"
  },
  {
    "text": "And usually, how it works\nis that pretrained model, let's say the new-- when LLaMA 4 comes out, or\nlike when GPT-5 comes out,",
    "start": "3333990",
    "end": "3340890"
  },
  {
    "text": "they basically mostly\nshow perplexity and average over everything. And the fine-tuned\nmodels, they usually",
    "start": "3340890",
    "end": "3346910"
  },
  {
    "text": "tend to show average over\neverything and performance under arena like models.",
    "start": "3346910",
    "end": "3353330"
  },
  {
    "text": "And the reason why is because\nmodels that are fine-tuned, usually, the log likelihood\nthat they predict is not--",
    "start": "3353330",
    "end": "3363770"
  },
  {
    "text": "yeah it's not calibrated\nfor your data set. So what do I mean by everything?",
    "start": "3363770",
    "end": "3370369"
  },
  {
    "text": "I would say the two most common\nbenchmarks that basically look at everything are HELM\nand Hugging Face Open LLM",
    "start": "3370370",
    "end": "3378770"
  },
  {
    "text": "Leaderboard. It's really just a collection of\na lot of different automatically evaluated benchmarks, and you\nevaluate across all of them.",
    "start": "3378770",
    "end": "3387440"
  },
  {
    "text": "So what are some of the\ncommon benchmarks that we use? One is measuring\nmath performance.",
    "start": "3387440",
    "end": "3395550"
  },
  {
    "text": "So GSM8K, that's a\npretty common one. That's basically\ngrade school math. MMLU is multiple choice question\nanswering on math, science,",
    "start": "3395550",
    "end": "3404160"
  },
  {
    "text": "history. LegalBench is on\nthe legal aspect. And you have MedQA. So I believe this is for HELM.",
    "start": "3404160",
    "end": "3410440"
  },
  {
    "text": "MedQA is, yeah, medical\nlicensing exams. So you basically ask many,\nmany different questions",
    "start": "3410440",
    "end": "3416690"
  },
  {
    "text": "that you can\nautomatically evaluate. And you hope that\nby taking averages,",
    "start": "3416690",
    "end": "3422870"
  },
  {
    "text": "it will say how well\nyour model performs. So that's kind of like the\nnewer version of SuperGLUE,",
    "start": "3422870",
    "end": "3428020"
  },
  {
    "text": "I would say. One data set that I want to\nhighlight, which is probably-- or one benchmark which is\nprobably the most widely used",
    "start": "3428020",
    "end": "3434682"
  },
  {
    "text": "and the one that\npeople believe the most is MMLU, so Massively Multitask\nLanguage Understanding.",
    "start": "3434683",
    "end": "3440310"
  },
  {
    "text": "So this is-- I think maybe\nArchit mentioned it last week, but this is basically multiple\nchoice questions on 57",
    "start": "3440310",
    "end": "3451470"
  },
  {
    "text": "different tasks. So you have tasks like formal\nlogic, conceptual physics, econometrics, and\nthese type of tasks.",
    "start": "3451470",
    "end": "3458170"
  },
  {
    "text": "So here's an example. \"What is true for\ntype Ia supernova?",
    "start": "3458170",
    "end": "3463650"
  },
  {
    "text": "This type occurs\nin binary system. This type occurs\nin young galaxies.\" And you basically have\nto say which answer.",
    "start": "3463650",
    "end": "3469476"
  },
  {
    "text": "So that seems very simple. I mean, the task is not simple,\nbut the way you evaluate it seems simple. And then high school biology.",
    "start": "3469477",
    "end": "3475170"
  },
  {
    "text": "\"In a population of giraffes\nan environmental--\" na, na, na, and then you-- this is an example of\ndirectional selection.",
    "start": "3475170",
    "end": "3481740"
  },
  {
    "text": "So that seems simple. But actually, it's\nalso more complicated than what you might think.",
    "start": "3481740",
    "end": "3488970"
  },
  {
    "text": "And I think I will tell you-- OK. I will tell you about it later.",
    "start": "3488970",
    "end": "3494569"
  },
  {
    "text": "But that's one of\nthe most common-- probably the most common\nbenchmark and what people actually look at.",
    "start": "3494570",
    "end": "3500240"
  },
  {
    "text": "For example, when\nMark Zuckerberg said that LLaMA 3\nwas out, yeah, he",
    "start": "3500240",
    "end": "3507020"
  },
  {
    "text": "talked about MMLU scores,\nwhich I find kind of crazy. But yeah.",
    "start": "3507020",
    "end": "3512570"
  },
  {
    "text": "Other capabilities that\npeople look at, coding. Coding is a very common\none that people evaluate on",
    "start": "3512570",
    "end": "3518930"
  },
  {
    "text": "for two different reasons. One, because coding is usually--",
    "start": "3518930",
    "end": "3524533"
  },
  {
    "text": "if you perform well on code,\nyou usually-- actually, these models perform\nwell on reasoning, which is actually pretty cool.",
    "start": "3524533",
    "end": "3530630"
  },
  {
    "text": "So that's highly correlated with\nthings that people care about. Two, I mean, a lot\nof us are coders.",
    "start": "3530630",
    "end": "3536070"
  },
  {
    "text": "So we like to have better\nmodels for helping us coding. And three, the other point is\nthat it's actually pretty easy",
    "start": "3536070",
    "end": "3543350"
  },
  {
    "text": "to evaluate because you\ncan write test cases. So you basically ask\nthe model to generate very long code or\nfunctions to do something,",
    "start": "3543350",
    "end": "3551119"
  },
  {
    "text": "and then you just\nrun the test and you see whether it succeeds or not. Yes.",
    "start": "3551120",
    "end": "3556140"
  },
  {
    "text": "Sorry. Going back to the previous set\nof evaluations, some of them was short-form\nanswers apparently.",
    "start": "3556140",
    "end": "3561869"
  },
  {
    "text": "How would you validate like\nshort-form QA type of thing, where it's like-- multiple\nchoice makes sense. But if it's short-answer\nQA, how would",
    "start": "3561870",
    "end": "3568560"
  },
  {
    "text": "you say something is correct\nas an automatic metric? ",
    "start": "3568560",
    "end": "3574650"
  },
  {
    "text": "Speaking specifically to the\ntop, NarrativeQA [INAUDIBLE]. Yeah. I actually don't know. ",
    "start": "3574650",
    "end": "3584090"
  },
  {
    "text": "I actually don't know. Yeah, I should check. Sorry. So I don't know\nspecifically for this one,",
    "start": "3584090",
    "end": "3590300"
  },
  {
    "text": "but HotpotQA and Gear QA\nare other QA datasets,",
    "start": "3590300",
    "end": "3595510"
  },
  {
    "text": "and they look at F1\nfor the true and false. And then they also have an exact\nmatch, which is pretty punitive,",
    "start": "3595510",
    "end": "3601630"
  },
  {
    "text": "because if you say\n\"President Reagan\" and the answer is \"President\nRonald Reagan,\" [INAUDIBLE].",
    "start": "3601630",
    "end": "3607690"
  },
  {
    "text": "But anyway, so they use\nan exact match on that. Interesting. Yeah.",
    "start": "3607690",
    "end": "3614390"
  },
  {
    "text": "Cool. Thanks. OK. So MMLU coding. Another one that people\nstart looking at are agents.",
    "start": "3614390",
    "end": "3620570"
  },
  {
    "text": "I think Shakar is going\nto give a lecture on it. So I'm not going to\ntalk too much about it. But one cool thing that\nLLMs can do right now",
    "start": "3620570",
    "end": "3626440"
  },
  {
    "text": "is basically call APIs and then\ntake actions in the real-world essentially, or take\ncontrol of your computer.",
    "start": "3626440",
    "end": "3633520"
  },
  {
    "text": "You should not give it\ncontrol to your computer. So a natural\nquestion is like, how",
    "start": "3633520",
    "end": "3638808"
  },
  {
    "text": "do you evaluate\nthese type of things? This is a real\nchallenge because--",
    "start": "3638808",
    "end": "3644390"
  },
  {
    "text": "I mean, the biggest challenge\nis that if you-- for example, if I really wanted to evaluate\nhow good it is at coding",
    "start": "3644390",
    "end": "3649600"
  },
  {
    "text": "or how good it is at doing\nthings in my terminal, I need to give it\naccess to my terminal. And I really don't want to give\nmy LLM access to my terminal.",
    "start": "3649600",
    "end": "3657714"
  },
  {
    "text": "So you really need to\nsandbox environments. For the specific cases\nof terminal, I mean, it's pretty easy to sandbox.",
    "start": "3657715",
    "end": "3663350"
  },
  {
    "text": "But once you want to do\nevaluation of a model that, I don't know, pings\npeople on Slack",
    "start": "3663350",
    "end": "3668440"
  },
  {
    "text": "or writes things in\nyour emails, then you have to write an entire\nsandbox environment",
    "start": "3668440",
    "end": "3673940"
  },
  {
    "text": "for all the applications\nthat you want your LLMs to have access to. So this is actually\nreally complicated",
    "start": "3673940",
    "end": "3679928"
  },
  {
    "text": "and something that\npeople really have to deal with in the real world.",
    "start": "3679928",
    "end": "3685234"
  },
  {
    "text": "Well, at least, we'll have to,\nbecause right now it's still not in production. OK. The last part is--",
    "start": "3685235",
    "end": "3691430"
  },
  {
    "text": "or the penultimate\none, perplexities. So one thing which\nis very surprising--",
    "start": "3691430",
    "end": "3697292"
  },
  {
    "text": "or at least, the\nfirst time you see it-- is that, really, the\nperformance that you have on pretraining is\nextremely highly correlated",
    "start": "3697292",
    "end": "3704300"
  },
  {
    "text": "with basically performance on\nany downstream task, at least for the current types of LLMs.",
    "start": "3704300",
    "end": "3709599"
  },
  {
    "text": "So what I mean by this\nis that if you just look at your training performance,\njust predicting the next word, it's extremely\nhighly correlated.",
    "start": "3709600",
    "end": "3716610"
  },
  {
    "text": "So this is the x-axis, which\nis essentially perplexities, and the y-axis, which\nis just the average",
    "start": "3716610",
    "end": "3721849"
  },
  {
    "text": "over many different tasks. What you will see is that\ntasks that perform well",
    "start": "3721850",
    "end": "3727850"
  },
  {
    "text": "on perplexities will actually\nhave higher average scores. And as a result, a\nlot of people actually",
    "start": "3727850",
    "end": "3736040"
  },
  {
    "text": "end up-- when they develop\njust looking at perplexities, and they just trust\nit enough that they don't need to do the\ndownstream evaluations.",
    "start": "3736040",
    "end": "3743280"
  },
  {
    "text": "I would not recommend doing it. But if you have to have\nsomething quick and dirty, it usually works pretty well.",
    "start": "3743280",
    "end": "3749190"
  },
  {
    "text": "One thing to be\ncareful with, though, is that the perplexities\nare not going to be comparable across\ndifferent datasets.",
    "start": "3749190",
    "end": "3754950"
  },
  {
    "text": "So you really have to\nbe careful with what perplexities you're looking at. And two, it will depend\non the tokenizer.",
    "start": "3754950",
    "end": "3761280"
  },
  {
    "text": "So if you have LLaMA 3, and you\ncompare it to Gemini, yeah, even",
    "start": "3761280",
    "end": "3769555"
  },
  {
    "text": "on the same dataset, it's\ngoing to give different scores, and it's not comparable. Yes. [INAUDIBLE]",
    "start": "3769555",
    "end": "3776990"
  },
  {
    "text": "The easy answer-- I mean, it's not\nthe only answer, but the easy answer is that\nif the vocabulary changes-- the size of the vocabulary\nchanges, then, clearly,",
    "start": "3776990",
    "end": "3785280"
  },
  {
    "text": "the type of-- I mean, everything is not-- the upper bound is different. Yeah, most of these sequence\ndon't [INAUDIBLE], isn't it?",
    "start": "3785280",
    "end": "3793140"
  },
  {
    "text": "Mostly, a sequence\nlike [INAUDIBLE]. Yeah, but I'm not\ntalking about that. I'm talking about\nthe fact that-- I mean, just think about it.",
    "start": "3793140",
    "end": "3799207"
  },
  {
    "text": "If you have a\nvocabulary size of one-- Oh. --then I have to always\npredict the same thing.",
    "start": "3799207",
    "end": "3804250"
  },
  {
    "text": "So basically, your\nentropy depends-- your entropy is upper bounded\nby log of the cardinality",
    "start": "3804250",
    "end": "3811390"
  },
  {
    "text": "of your vocabulary size. So you're going\nto depend on that. Cool.",
    "start": "3811390",
    "end": "3818370"
  },
  {
    "text": "And the last one is arena-like. As I already told you, basically\nyou compare different models. You make them fight\nessentially against each other,",
    "start": "3818370",
    "end": "3824940"
  },
  {
    "text": "and you have Elo\nratings at the end. So that's really-- a more\ngeneral way of saying it is, I really just let\nthe users decide,",
    "start": "3824940",
    "end": "3832470"
  },
  {
    "text": "and that works also pretty well. OK.",
    "start": "3832470",
    "end": "3837540"
  },
  {
    "text": "Issues and challenges\nwith current evaluations. First, consistency issues.",
    "start": "3837540",
    "end": "3843150"
  },
  {
    "text": "If you look at question\nanswering-- sorry, multiple choice questions,\nif you just change--",
    "start": "3843150",
    "end": "3849250"
  },
  {
    "text": "so you see on the top\nleft and top right. If you just change A, B,\nC, D to random symbols,",
    "start": "3849250",
    "end": "3855540"
  },
  {
    "text": "the generations\nthat you will give are actually going\nto be different. And then the rankings\nbetween different models",
    "start": "3855540",
    "end": "3860700"
  },
  {
    "text": "will be different. So even things that are very\nsimple, like multiple choice-- like selecting out\nof four choices",
    "start": "3860700",
    "end": "3868710"
  },
  {
    "text": "will be very dependent\non exactly how you format these choices.",
    "start": "3868710",
    "end": "3874710"
  },
  {
    "text": "And one real example-- that's what I was\nalluding to before-- is MMLU. So MMLU seems really\nsimple to evaluate.",
    "start": "3874710",
    "end": "3882290"
  },
  {
    "text": "You just ask it to say which one\nof the four the model prefers.",
    "start": "3882290",
    "end": "3888880"
  },
  {
    "text": "But actually, for\na very long time, I think for nearly\none year, there",
    "start": "3888880",
    "end": "3893920"
  },
  {
    "text": "were three main\nimplementation of MMLU, and people were comparing\nbetween those three,",
    "start": "3893920",
    "end": "3899290"
  },
  {
    "text": "having no idea that those\nthree gave different scores. And the reason-- the\ntwo main differences",
    "start": "3899290",
    "end": "3904660"
  },
  {
    "text": "were, one, people use\ndifferent prompts. So that clearly will\ngive different answers. But two, they were\nusing different ways",
    "start": "3904660",
    "end": "3911320"
  },
  {
    "text": "of sampling to get the actual\nmost likely prediction. So one of them, for example, was\nsaying, I have the four choices.",
    "start": "3911320",
    "end": "3920860"
  },
  {
    "text": "Now, to get my most likely-- let's say that\nthe correct answer is D. I will just look at the\nmost likely answers out of A, B,",
    "start": "3920860",
    "end": "3929400"
  },
  {
    "text": "C, D. Even though zygote was\nanother answer that has a higher",
    "start": "3929400",
    "end": "3935109"
  },
  {
    "text": "likelihood, I will not look\nat it because I will basically do constrained decoding.",
    "start": "3935110",
    "end": "3941020"
  },
  {
    "text": "And if I do constrained\ndecoding here, I will say that the\ncorrect answer is D. But if I actually just look\nat the most likely token,",
    "start": "3941020",
    "end": "3949070"
  },
  {
    "text": "I will not get the\ncorrect answer. So those were two\ndifferent implementation. And a third different\nimplementation,",
    "start": "3949070",
    "end": "3955070"
  },
  {
    "text": "which seems really\ndifferent, is that instead of generating\nthe correct token, which",
    "start": "3955070",
    "end": "3960550"
  },
  {
    "text": "is basically the letter A,\nB, C, D, you can look at-- after this question,\nwhat is the likelihood",
    "start": "3960550",
    "end": "3967470"
  },
  {
    "text": "that the answer-- sorry, that\nthe model will generate this? So you would look at the log\nlikelihood or the perplexity",
    "start": "3967470",
    "end": "3974160"
  },
  {
    "text": "essentially of predicting\nthis thing, log likelihood of predicting that. And that gives very\ndifferent answers.",
    "start": "3974160",
    "end": "3979290"
  },
  {
    "text": "So if you look at\nthe top right, you see that llama-65b MMLU on HELM\nwas 63.7, and the original MMLU,",
    "start": "3979290",
    "end": "3987870"
  },
  {
    "text": "63.6. But on Harness, which is\nthe thing that actually Hugging Face uses, is 48.8.",
    "start": "3987870",
    "end": "3995500"
  },
  {
    "text": "So that's like a\nhuge difference. Yeah. What is HELM,\nHarness, and Original? It matches to these\nthree things there?",
    "start": "3995500",
    "end": "4001520"
  },
  {
    "text": "Yeah. I can't remember which one\ndoes what, but each of them does something different. Actually, now it's\nnot true anymore.",
    "start": "4001520",
    "end": "4008010"
  },
  {
    "text": "So the middle column\nchanged what they are doing. So they start matching\nthe other two ones.",
    "start": "4008010",
    "end": "4013280"
  },
  {
    "text": "But at that time, they weren't. I'm not sure which\none-- my guess was",
    "start": "4013280",
    "end": "4018670"
  },
  {
    "text": "would be that they did the last\none, but I'm not entirely sure.",
    "start": "4018670",
    "end": "4024059"
  },
  {
    "text": " OK. Questions?",
    "start": "4024060",
    "end": "4031190"
  },
  {
    "text": "Cool. Another issue, contamination. So here, you have Horace He.",
    "start": "4031190",
    "end": "4037680"
  },
  {
    "text": "If you don't follow him\non Twitter, you should. And he basically says that he\nwas looking at code benchmarks.",
    "start": "4037680",
    "end": "4045440"
  },
  {
    "text": "And he was saying\nthat pre-2021-- I can't remember which one.",
    "start": "4045440",
    "end": "4050960"
  },
  {
    "text": "Oh, GPT-4 was getting 10 out of\n10 on questions on Codeforce. But after 2021, or\nmore recent problems,",
    "start": "4050960",
    "end": "4057600"
  },
  {
    "text": "it was getting 0 out of 10,\nwhich seems very, very strange. So that really strongly\npoints to the fact",
    "start": "4057600",
    "end": "4063770"
  },
  {
    "text": "that it was contaminated,\nand it was probably-- the model was probably\npretrained on that dataset, or the Codeforce\ndataset was probably",
    "start": "4063770",
    "end": "4070220"
  },
  {
    "text": "in the pretraining dataset. And of course, if you-- I mean, essentially you do\ntraining on your test set,",
    "start": "4070220",
    "end": "4075750"
  },
  {
    "text": "then you're going to\nperform really well. And Susan said--\nalso to follow--",
    "start": "4075750",
    "end": "4081559"
  },
  {
    "text": "also said something\nsimilar for Phi-1.5, which is a model from Microsoft.",
    "start": "4081560",
    "end": "4088910"
  },
  {
    "text": "So what is challenging here\nis that we have closed models. I mean, there are two things\nactually that are challenging.",
    "start": "4088910",
    "end": "4094540"
  },
  {
    "text": "One is that those are\npretrained on so much data that even if we had\naccess to the data, it would be hard to\nactually know what they--",
    "start": "4094540",
    "end": "4100859"
  },
  {
    "text": "if they were pretrained\non your test set. But two, those are all\nclosed-source models. So you really don't even\nhave access to the dataset.",
    "start": "4100859",
    "end": "4107859"
  },
  {
    "text": "So you have no idea if they\nwere pretrained on that data. Overfitting issues, that's\nalso relatively related,",
    "start": "4107859",
    "end": "4115049"
  },
  {
    "text": "but could be slightly different. So here, you see how much time\nit took for standard datasets",
    "start": "4115050",
    "end": "4122370"
  },
  {
    "text": "to achieve a, quote-- like scary quotes,\n\"human-level\" performance.",
    "start": "4122370",
    "end": "4127920"
  },
  {
    "text": "And what you see is that, on\nthe recent ones where you really have this pretraining,\nin less than six months,",
    "start": "4127920",
    "end": "4133568"
  },
  {
    "text": "you perform at\n\"human-level\" performance. We don't really know if it's\nbecause of the contamination",
    "start": "4133569",
    "end": "4140160"
  },
  {
    "text": "or if it's simply\nthat a lot of people are basically developing and\ntrying to do hyperparameter",
    "start": "4140160",
    "end": "4145560"
  },
  {
    "text": "tuning on these test sets. We don't know why,\nbut it's clearly an issue with overfitting.",
    "start": "4145560",
    "end": "4151970"
  },
  {
    "text": "So how do you alleviate that? One, you can have\nprivate test sets. So there's a paper\nfrom, I think,",
    "start": "4151970",
    "end": "4157259"
  },
  {
    "text": "two weeks ago that\npresented GSM1K, which is the same thing as\nthe GSM8K that we saw before,",
    "start": "4157260",
    "end": "4164490"
  },
  {
    "text": "which is the math\ndataset, but tries to basically regenerate\nor resample this dataset",
    "start": "4164490",
    "end": "4171830"
  },
  {
    "text": "or recollect this dataset. And then they look at how well\ndifferent models perform on both",
    "start": "4171830",
    "end": "4178399"
  },
  {
    "text": "the GSM1K and the GSM8K. And what you see is that at\nleast the open-source models, they perform much worse on the\nnew dataset than on the one",
    "start": "4178399",
    "end": "4186140"
  },
  {
    "text": "that people are able to tune on. This is not true though\nfor Claude and GPT-4.",
    "start": "4186140",
    "end": "4193710"
  },
  {
    "text": "Another one is Dynabench,\nwhich is dynamic test sets. So ideally, every\nx number of days,",
    "start": "4193710",
    "end": "4199800"
  },
  {
    "text": "you would basically have new\ninstructions or new inputs to the models, and your data\nset would basically be dynamic.",
    "start": "4199800",
    "end": "4205719"
  },
  {
    "text": "That's essentially also\nwhat Chatbot Arena does. So that definitely helps.",
    "start": "4205720",
    "end": "4212160"
  },
  {
    "text": "Another way of\nalleviating contaminators is that you may try\nto estimate or to look",
    "start": "4212160",
    "end": "4218310"
  },
  {
    "text": "at whether the\nmodels were actually trained on your test set. So one very simple\nway of doing it,",
    "start": "4218310",
    "end": "4223480"
  },
  {
    "text": "which actually works I\nthink relatively well, is just looking\nat the probability",
    "start": "4223480",
    "end": "4228720"
  },
  {
    "text": "of different answers. And you will see that if\nyour model is really sure about a certain\nanswer, then, probably,",
    "start": "4228720",
    "end": "4234880"
  },
  {
    "text": "it was trained on that answer. Another one which\nis also really cool,",
    "start": "4234880",
    "end": "4240540"
  },
  {
    "text": "is looking at the\norder of your test set. So if your model was--",
    "start": "4240540",
    "end": "4246150"
  },
  {
    "text": "if a model was\ntrained or pretrained on the test set,\nthen, most likely, it thinks that example\n2 comes after example 1.",
    "start": "4246150",
    "end": "4253000"
  },
  {
    "text": "So if you switch\nexample 1 and example 2 and you see drops in log\nlikelihoods, then, most likely,",
    "start": "4253000",
    "end": "4258567"
  },
  {
    "text": "the model was actually\npretrained on that dataset. ",
    "start": "4258567",
    "end": "4263989"
  },
  {
    "text": "Cool. Any questions here? ",
    "start": "4263990",
    "end": "4269930"
  },
  {
    "text": "OK. So another issue is that-- I mean, really there's a\nmonoculture of NLP benchmarking.",
    "start": "4269930",
    "end": "4277130"
  },
  {
    "text": "What I mean by this\nis mostly the fact that we all just\nlook at English. And this is a paper from 2021--",
    "start": "4277130",
    "end": "4283820"
  },
  {
    "text": "or 2022, I think. But they look at ACL\n2021, which is probably the most common conference or--",
    "start": "4283820",
    "end": "4291980"
  },
  {
    "text": "yeah, conference in NLP. And they look at the best\npapers, so the oral papers,",
    "start": "4291980",
    "end": "4297080"
  },
  {
    "text": "and they saw that out of\nthe 461 papers, 70% of them only look at English, and 40%\nof them only look at accuracy.",
    "start": "4297080",
    "end": "4304800"
  },
  {
    "text": "So essentially just performance. So there are very\nfew papers that look at multilinguality\nand even efficiency",
    "start": "4304800",
    "end": "4311900"
  },
  {
    "text": "on interpretability or fairness. And there's a similar\npaper that analyzes",
    "start": "4311900",
    "end": "4318920"
  },
  {
    "text": "another conference in 2008,\nand it was essentially the same findings. So unfortunately, it doesn't\nseem to improve over time.",
    "start": "4318920",
    "end": "4324642"
  },
  {
    "text": " The thing is, there are\nactually a lot of benchmarks",
    "start": "4324642",
    "end": "4330260"
  },
  {
    "text": "for multilinguality. I just highlight a few here. MEGA, GlobalBench, XTREME--\nthose have at least 30,",
    "start": "4330260",
    "end": "4340190"
  },
  {
    "text": "40 languages and many,\nmany different tasks. So it's not that we don't\nhave the benchmarks.",
    "start": "4340190",
    "end": "4346380"
  },
  {
    "text": "It's that there's no\nincentives, unfortunately, in academia to actually train--\nor sorry to evaluate on those",
    "start": "4346380",
    "end": "4353990"
  },
  {
    "text": "benchmarks. So if you have the chance,\nuse those benchmarks.",
    "start": "4353990",
    "end": "4361160"
  },
  {
    "text": "Another issue is that,\nreally, we reduce everything to a single metric. So I already told you before,\nthe way we aggregate metrics,",
    "start": "4361160",
    "end": "4368130"
  },
  {
    "text": "this is usually broken in some\nof these super benchmarks, but also we only\nlook at performance.",
    "start": "4368130",
    "end": "4374489"
  },
  {
    "text": "And in the real\nworld, we really care about computational\nefficiency too. We also care about\nbiases, and we",
    "start": "4374490",
    "end": "4379760"
  },
  {
    "text": "care about many other aspects,\nand most of these benchmarks don't consider those.",
    "start": "4379760",
    "end": "4384770"
  },
  {
    "text": "Another part is that we usually\naverage across every example. We just say that every example\nhas the same value, essentially",
    "start": "4384770",
    "end": "4390930"
  },
  {
    "text": "the same weight. So this is definitely unfair\nfor minoritized groups. But more than this, I think if--",
    "start": "4390930",
    "end": "4398250"
  },
  {
    "text": "for example, if you\nthink about agents, where maybe one example will\nbe how well it performs on,",
    "start": "4398250",
    "end": "4406260"
  },
  {
    "text": "I don't know, writing\ncode that will actually be put in production versus just\nanswering your daily question",
    "start": "4406260",
    "end": "4414450"
  },
  {
    "text": "about, I don't know, where\nto buy the best burger, the value that you will\nget out of these examples",
    "start": "4414450",
    "end": "4421468"
  },
  {
    "text": "are very different. And right now, when\nwe evaluate stuff, we don't actually consider that. So that's I think, a real issue.",
    "start": "4421468",
    "end": "4427800"
  },
  {
    "text": "And also, basically, we\ndon't take into account that different people have\ndifferent preferences.",
    "start": "4427800",
    "end": "4433560"
  },
  {
    "text": "So a few shout outs,\none considering computational efficiency. So MLPerf has a great\nbenchmark where,",
    "start": "4433560",
    "end": "4440670"
  },
  {
    "text": "basically, instead of trying\nto maximize the performance on a certain\nbenchmark, they say, I",
    "start": "4440670",
    "end": "4446130"
  },
  {
    "text": "want to achieve that performance\nin the least amount of time. So now, you basically consider\nboth accuracies and speed,",
    "start": "4446130",
    "end": "4454930"
  },
  {
    "text": "either for training\nor for inference. For biases, DiscrimEval\nis a good dataset",
    "start": "4454930",
    "end": "4461760"
  },
  {
    "text": "from Anthropic,\nwhere basically they have some templates and they--\nso they try to ask questions",
    "start": "4461760",
    "end": "4469590"
  },
  {
    "text": "like knowing whether someone\nshould keep their insurance or not. And they have\ntemplates where they",
    "start": "4469590",
    "end": "4475547"
  },
  {
    "text": "change the race or the gender\nin the template of the person,",
    "start": "4475547",
    "end": "4481630"
  },
  {
    "text": "and they see how the decisions\nmade by the model would change. And I mean, unfortunately,\nbut unsurprisingly, you",
    "start": "4481630",
    "end": "4490949"
  },
  {
    "text": "will see that some\ngroups are much more discriminated than others. ",
    "start": "4490950",
    "end": "4498380"
  },
  {
    "text": "Other biases in our evaluations. I already told you slightly\nabout the multilingual issues. But honestly, this\nissue about English",
    "start": "4498380",
    "end": "4505580"
  },
  {
    "text": "is much more prevalent\nthan you would think. For example, BLEU\nand ROUGE score, they really assume that you\nbasically have access to words,",
    "start": "4505580",
    "end": "4512990"
  },
  {
    "text": "like you know how to\ntokenize-- how to get words. So I used to work with\nThai and Vietnamese.",
    "start": "4512990",
    "end": "4518790"
  },
  {
    "text": "With Vietnamese, you have\nspaces in between words. And Thai, you have no\nspaces between words. You have no idea how\nto run BLEU or ROUGE.",
    "start": "4518790",
    "end": "4526429"
  },
  {
    "text": "Really, these-- it's much\nmore than just the data. All our algorithms are really\nfocused on English, or at least",
    "start": "4526430",
    "end": "4532910"
  },
  {
    "text": "Western languages. Biased LLM-based evaluation.",
    "start": "4532910",
    "end": "4538260"
  },
  {
    "text": "So one thing that\nI told you about is that it's really cool because\nnow you can use essentially GPT-4 for doing labeling.",
    "start": "4538260",
    "end": "4545960"
  },
  {
    "text": "But that also means that, given\nthat GPT-4 is very consistent, if it has some biases,\nthen most of essentially",
    "start": "4545960",
    "end": "4553760"
  },
  {
    "text": "the NLP community will\nhave these biases scaled up essentially.",
    "start": "4553760",
    "end": "4559920"
  },
  {
    "text": "So one benchmark which tries\nto look at whose opinions LLMs",
    "start": "4559920",
    "end": "4565350"
  },
  {
    "text": "reflect by default. This is\nactually a pretty cool work that looks at the output\ndistribution of LLMs",
    "start": "4565350",
    "end": "4573690"
  },
  {
    "text": "on public opinion surveys. So just trying to understand\nwhether LLMs reflects",
    "start": "4573690",
    "end": "4581220"
  },
  {
    "text": "opinions from which groups. And they found that\nat least after-- when you only do\npretraining, the model",
    "start": "4581220",
    "end": "4588030"
  },
  {
    "text": "is actually relatively well-- they are not too optimized\nto a single group.",
    "start": "4588030",
    "end": "4595780"
  },
  {
    "text": "So this is in red. But after fine-tuning,\nyou basically see that the models really\nstart being optimized",
    "start": "4595780",
    "end": "4601349"
  },
  {
    "text": "for certain preferences,\nwhich is unsurprising because that's how we\nactually train the model. And typically, these\nmodels actually",
    "start": "4601350",
    "end": "4611640"
  },
  {
    "text": "mostly show preferences from--",
    "start": "4611640",
    "end": "4616800"
  },
  {
    "text": "or actually the answer as\nif they were from, I mean, white and Southeast Asian.",
    "start": "4616800",
    "end": "4622117"
  },
  {
    "text": "So I think the Southeast Asian\nis actually pretty interesting. I think it's probably because\na lot of these models were--",
    "start": "4622117",
    "end": "4627900"
  },
  {
    "text": "the human data that was used\nfor supervised fine-tuning and for RLHF was\nactually labeled",
    "start": "4627900",
    "end": "4634260"
  },
  {
    "text": "by people in\nSoutheast Asia, which would explain why these models\nhave these type of views.",
    "start": "4634260",
    "end": "4641700"
  },
  {
    "text": "And usually, also\nhighly educated. OK.",
    "start": "4641700",
    "end": "4646830"
  },
  {
    "text": "So this is the main\nchallenge, the challenges of all challenges. We saw that there are many\nchallenges in evaluation",
    "start": "4646830",
    "end": "4654670"
  },
  {
    "text": "at least in academic\nbenchmarking. But the biggest one is\nthat, really, there's no incentives for us to\nmove to anything else.",
    "start": "4654670",
    "end": "4662755"
  },
  {
    "text": "And this is a actually pretty\ninteresting paper that looks at machine translation\nbetween-- all the papers of--",
    "start": "4662755",
    "end": "4670600"
  },
  {
    "text": "or many papers from 2019 to\n2020 machine translation.",
    "start": "4670600",
    "end": "4676010"
  },
  {
    "text": "And they found that\n82% of papers, they only evaluated BLEU scores. And as we said, BLEU scores\nhave many, many issues.",
    "start": "4676010",
    "end": "4683210"
  },
  {
    "text": "And if you see-- we know that there are\nmany better metrics.",
    "start": "4683210",
    "end": "4689260"
  },
  {
    "text": "But still, people are\nnot incentivized to look at anything else. And actually,\nreviewers will usually ask you to show\nperformance on BLEU scores.",
    "start": "4689260",
    "end": "4697272"
  },
  {
    "text": "So it's not even that\nyou're incentivized not to look at something else. You're also incentivized\nto continue. And it kind of makes\nsense because you",
    "start": "4697272",
    "end": "4702550"
  },
  {
    "text": "want to be able to compare\ntwo methods from two or three years ago,\nbut it also means that it's hard for\nthe academic field",
    "start": "4702550",
    "end": "4709699"
  },
  {
    "text": "to change to other benchmarks. But this is really\nspecific to academia.",
    "start": "4709700",
    "end": "4714710"
  },
  {
    "text": "In reality, if you know that\nyour metric is bad, just switch. OK.",
    "start": "4714710",
    "end": "4720920"
  },
  {
    "text": "Evaluation takeaways. So first, I mentioned\nthat there were",
    "start": "4720920",
    "end": "4726020"
  },
  {
    "text": "different types of evaluation\nand different desired properties for different\ntypes of evaluation.",
    "start": "4726020",
    "end": "4731630"
  },
  {
    "text": "Then I talked about\nclosed-ended tasks and how you evaluate those,\nthe fact that it's basically",
    "start": "4731630",
    "end": "4736910"
  },
  {
    "text": "standard machine\nlearning, but that you have to think carefully,\neven though it's standard machine learning,\nof how you evaluate them.",
    "start": "4736910",
    "end": "4743270"
  },
  {
    "text": "Then there are\nopen-ended tasks, where you look at content\noverlap metrics typically, so things like BLEU,\nand ROUGE, and BERT score.",
    "start": "4743270",
    "end": "4754170"
  },
  {
    "text": "And then you have\nchat bot evaluations, which is extremely\ndifficult, but people",
    "start": "4754170",
    "end": "4761500"
  },
  {
    "text": "have started doing with-- using essentially\nLLM-based evaluations.",
    "start": "4761500",
    "end": "4766770"
  },
  {
    "text": "And then we talked\nabout challenges, one of them being consistency. The other one, contamination. And the third one, biases.",
    "start": "4766770",
    "end": "4774400"
  },
  {
    "text": "In reality, honestly,\nthe best evaluation is just check your outputs.",
    "start": "4774400",
    "end": "4779590"
  },
  {
    "text": "So I think too many people,\nthey just believe numbers. In reality, never\njust believe numbers.",
    "start": "4779590",
    "end": "4787910"
  },
  {
    "text": "I remember, when we\ndid initially Alpaca, we kind of believed\nour AlpacaEval.",
    "start": "4787910",
    "end": "4793397"
  },
  {
    "text": "But once we started playing with\nit, that's when we were like, OK, this thing is actually-- I mean, at that time, good. Now, it would be a\npretty bad model.",
    "start": "4793397",
    "end": "4799490"
  },
  {
    "text": "But at that time,\nwe were like, OK, this thing is\nactually pretty good. We should do something\nabout it, even",
    "start": "4799490",
    "end": "4804670"
  },
  {
    "text": "though on maybe standard\nacademic benchmarks it was pretty bad. So yeah, don't rely on numbers.",
    "start": "4804670",
    "end": "4810460"
  },
  {
    "text": "And I'm happy to-- what time is it?-- to take any other questions\nthat you may have.",
    "start": "4810460",
    "end": "4819210"
  },
  {
    "text": "Yes. Question about-- so\nthere's this whole issue of bias, which we're\nreally trying to deal with,",
    "start": "4819210",
    "end": "4825220"
  },
  {
    "text": "but we're sweeping\nunder the rug here. So if we have a problem in\nwhich we're dealing with a very",
    "start": "4825220",
    "end": "4831000"
  },
  {
    "text": "specialized domain-- and, yes, we try and go and\nrun a reference evals using,",
    "start": "4831000",
    "end": "4839640"
  },
  {
    "text": "let's say, GPT-4-- ",
    "start": "4839640",
    "end": "4845085"
  },
  {
    "text": "is it considered bad practice\nto be checking a subset of these GPT-4 evals, ranking\nthem ourselves,",
    "start": "4845085",
    "end": "4857760"
  },
  {
    "text": "and then using ourself-- like inserting ourself and\nour bias into this process",
    "start": "4857760",
    "end": "4865949"
  },
  {
    "text": "by actually looking at many,\nmany, many data points? So just to make sure I\nunderstand your question,",
    "start": "4865950",
    "end": "4872560"
  },
  {
    "text": "you're saying that if we try to\nlook ourselves at the answers, we might be incorporating\nsome biases there?",
    "start": "4872560",
    "end": "4878719"
  },
  {
    "text": "Yes. But we should look\nat the answers to make sure that GPT-4\nisn't being biased",
    "start": "4878720",
    "end": "4884140"
  },
  {
    "text": "when it looks at the answers. There's this tension\nhere, and I don't know what the-- because\nin a controlled scientific",
    "start": "4884140",
    "end": "4889660"
  },
  {
    "text": "experiment, you\nwould blind yourself to looking at these answers. How do you deal with this?",
    "start": "4889660",
    "end": "4894820"
  },
  {
    "text": "Yeah, that's a good question. I actually don't quite know. But one thing-- I actually feel less concerned\nabout biases of a single person.",
    "start": "4894820",
    "end": "4903969"
  },
  {
    "text": "My issue with the GPT-4\nbiases is that it's the same across every model. So things really scale\nup, and it's really--",
    "start": "4903970",
    "end": "4912550"
  },
  {
    "text": "it becomes a monoculture. And I think that's much worse\nthan if everyone incorporates",
    "start": "4912550",
    "end": "4918868"
  },
  {
    "text": "a little bit of the biases that\nthey have in their direction. I'm not saying that\nthat's the best answer,",
    "start": "4918868",
    "end": "4924050"
  },
  {
    "text": "but I think it's\nslightly better than just going with whatever they have. Yeah. How does one--\nfollowing up on that,",
    "start": "4924050",
    "end": "4929390"
  },
  {
    "text": "how do we avoid a\nsituation if we're like-- one is trying to\nsolve a problem with a model,",
    "start": "4929390",
    "end": "4934810"
  },
  {
    "text": "and one evaluates it\nwith GPT chat, GPT-4,",
    "start": "4934810",
    "end": "4941710"
  },
  {
    "text": "and then one starts\nto look at it and say, OK, is this good and stuff?",
    "start": "4941710",
    "end": "4946790"
  },
  {
    "text": "And then one goes,\nOK, this is great. And everyone else in the world-- and GPT-4 thinks it's a\nterrible, terrible model,",
    "start": "4946790",
    "end": "4954070"
  },
  {
    "text": "and it's just someone being an--\njust some academic being like-- pressuring themselves\ninto publishing something",
    "start": "4954070",
    "end": "4960370"
  },
  {
    "text": "that doesn't actually work. How does the field structure\nto avoid situations like that?",
    "start": "4960370",
    "end": "4968380"
  },
  {
    "text": "Well, I think that's\none reason why they want standardized\nbenchmarks and why every reviewer actually\nwants standardized benchmarks,",
    "start": "4968380",
    "end": "4974450"
  },
  {
    "text": "because, at least,\neven though everyone knows that they're wrong, they\nunderstand how they're wrong.",
    "start": "4974450",
    "end": "4980020"
  },
  {
    "text": "So I think that's\none perspective. Another thing which\ndoesn't completely answer your\nquestion, but I think",
    "start": "4980020",
    "end": "4987850"
  },
  {
    "text": "could be a potential\nsolution, is that how I view GPT-4 is\njust something that",
    "start": "4987850",
    "end": "4993400"
  },
  {
    "text": "is really good at performing\nwhat I want it to perform. Right now, the thing is I am\nnot very specific about what",
    "start": "4993400",
    "end": "5000150"
  },
  {
    "text": "I want it to perform. And as a result,\nit will basically come in with its own biases that\ncome from its pretraining data",
    "start": "5000150",
    "end": "5006360"
  },
  {
    "text": "or fine-tuning data. A potentially better\nway of doing it is that I could write\nexactly what I wanted.",
    "start": "5006360",
    "end": "5012880"
  },
  {
    "text": "So right now, when we do\nthe prompting to GPT-4, I basically ask a question,\na simple question,",
    "start": "5012880",
    "end": "5017970"
  },
  {
    "text": "like, how good is this\nsummary out of five? But a much better\nway would probably",
    "start": "5017970",
    "end": "5023430"
  },
  {
    "text": "be writing a very\ndetailed rubric of everything that has to\nbe in this answer for it to be a good answer.",
    "start": "5023430",
    "end": "5028930"
  },
  {
    "text": "And if you think about it, this\nis exactly what professors do when they evaluate for class.",
    "start": "5028930",
    "end": "5034320"
  },
  {
    "text": "They basically say,\nOK, Yann is a OK TA, but I cannot trust him blindly.",
    "start": "5034320",
    "end": "5041140"
  },
  {
    "text": "So what I will do is that I will\nwrite a very detailed rubric, and I trust that he\ncan apply that rubric.",
    "start": "5041140",
    "end": "5046659"
  },
  {
    "text": "And I think that's also how we\nshould be thinking about GPT-4. This is not how we\ncurrently do it. ",
    "start": "5046660",
    "end": "5054719"
  },
  {
    "text": "Any other questions? ",
    "start": "5054720",
    "end": "5064000"
  }
]
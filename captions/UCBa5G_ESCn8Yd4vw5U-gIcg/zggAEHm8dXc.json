[
  {
    "start": "0",
    "end": "10940"
  },
  {
    "text": "Excited to be here. I think, yeah, the last\ntime I was giving this talk was in 2017.",
    "start": "10940",
    "end": "15950"
  },
  {
    "text": "I think that was my job talk. So yes, a refresher\nwould be good. So yeah.",
    "start": "15950",
    "end": "21470"
  },
  {
    "text": "So as Mark said, I'm pretty\nexcited about the intersection of robot learning and\nhuman robot interaction.",
    "start": "21470",
    "end": "26737"
  },
  {
    "text": "And a lot of the work that\nwe are doing in the lab is focused on that\nintersection and how we could learn from various\nsources of human data,",
    "start": "26737",
    "end": "33620"
  },
  {
    "text": "how we could build systems that\ncan better interact, coordinate, and collaborate with humans.",
    "start": "33620",
    "end": "39350"
  },
  {
    "text": "A major part of this talk\ntoday is a little focused on the robot learning\nside of things. But I do have kind of\nlike these connections",
    "start": "39350",
    "end": "46700"
  },
  {
    "text": "of how we could\nlearn from humans and how we could think\nabout humans in the loop as we go through the talk.",
    "start": "46700",
    "end": "51770"
  },
  {
    "text": "So today, I want to\ntalk a little bit about interactive\nlearning and specifically how we should think\nabout that in the age",
    "start": "51770",
    "end": "57079"
  },
  {
    "text": "of large pre-trained\nmodels, foundation models. And to just get\nstarted, I figured it would be a good idea\nto start with an example.",
    "start": "57080",
    "end": "66080"
  },
  {
    "text": "And I just realized\nI have audio for this and the audio might not work. But let me just kind\nof set the system up.",
    "start": "66080",
    "end": "73230"
  },
  {
    "text": "So this is a system that we\nare developing in the lab. It's called [? local ?] sandbox. A number of students\nare working on this.",
    "start": "73230",
    "end": "79320"
  },
  {
    "text": "Sudhir, who is here, is actually\ncontributing to this work. Jen said a bunch\nof different people",
    "start": "79320",
    "end": "84690"
  },
  {
    "text": "are thinking about\nhow we could build a system that could actually\neffectively learn from humans--",
    "start": "84690",
    "end": "90360"
  },
  {
    "text": "so this definitely has\nthe human component-- and actually be able to\ngeneralize to new scenarios",
    "start": "90360",
    "end": "95820"
  },
  {
    "text": "and be able to do\nnew motions or be able to generalize to\nnew objects and so on. So I just wanted to show this\nmore as a motivation for how",
    "start": "95820",
    "end": "103665"
  },
  {
    "text": "we are thinking about this. [VIDEO PLAYBACK] - Can you grab that pink\nmug and hand it to me? - This is Sidd\ngiving instructions.",
    "start": "103665",
    "end": "110400"
  },
  {
    "text": "- I apologize. I do not think I can succeed\nwith the instruction grab the pink mug.",
    "start": "110400",
    "end": "116530"
  },
  {
    "text": "- OK. To grasp one two three.",
    "start": "116530",
    "end": "132160"
  },
  {
    "text": " - Got it. OK. I think I can execute\non grab the pink mug",
    "start": "132160",
    "end": "139740"
  },
  {
    "text": "and similar instructions\nto the future. - All right. Let's run it back. ",
    "start": "139740",
    "end": "146825"
  },
  {
    "text": "- So the hope is that the\nrobot kind of understands the key points that the human\nis showing here for grasping",
    "start": "146825",
    "end": "152310"
  },
  {
    "text": "and actually be able to execute\non that like a grasp primitive. ",
    "start": "152310",
    "end": "160250"
  },
  {
    "text": "And the hope is that it would\ngeneralize like just because it picked it up doesn't mean-- - --quite believe you.",
    "start": "160250",
    "end": "166370"
  },
  {
    "text": "- That we believe the robot? - Let's make this a\nlittle bit harder. ",
    "start": "166370",
    "end": "174500"
  },
  {
    "text": "All right. Let's try that again. - Starting execution now.",
    "start": "174500",
    "end": "180210"
  },
  {
    "text": "- So we would like the\nrobot to still figure out where those key points\nare or generalized motions like actually\ngo to new places",
    "start": "180210",
    "end": "187040"
  },
  {
    "text": "and be able to do this task. - Dorsa, while it's running,\ncan I ask a question?",
    "start": "187040",
    "end": "192750"
  },
  {
    "text": "- Yeah. - So I noticed that it grasps\nthe load from the same side that the human demonstrated-- - OK.",
    "start": "192750",
    "end": "198305"
  },
  {
    "text": "That's pretty good. Let's reset and let's try again. - This is five seconds.",
    "start": "198305",
    "end": "203510"
  },
  {
    "text": "I'll get to that. - Out of curiosity, are\nthe images on your screen also marks that I should\nbe able to pick up?",
    "start": "203510",
    "end": "209720"
  },
  {
    "text": "[END OF PLAYBACK] Yeah. So a couple of things\nhere, yeah, so you're absolutely right that it\ngoes to the same place",
    "start": "209720",
    "end": "214877"
  },
  {
    "text": "that the human is showing. So the thing that the\nrobot is learning here is actually the key point,\nthe grasping key point. And then it kind of halts\nall the possible grasps",
    "start": "214877",
    "end": "222530"
  },
  {
    "text": "around that key point\nand it goes there. It could also learn\nthe full motion. It could actually look\nat that human video",
    "start": "222530",
    "end": "228470"
  },
  {
    "text": "and try to figure out\nwhat that motion is. We're not doing that here. This is actually\nsimplified but ideally, we",
    "start": "228470",
    "end": "234300"
  },
  {
    "text": "would want this robot to be able\nto generalize to new motions, generalize to new objects\nkind of like recognize",
    "start": "234300",
    "end": "239970"
  },
  {
    "text": "what is going on in the scene\nand have a better interaction and learning from the human.",
    "start": "239970",
    "end": "245910"
  },
  {
    "text": "So this was more of\na motivation example. If I have time, I'll\ncome back to this video towards the end of the talk.",
    "start": "245910",
    "end": "252150"
  },
  {
    "text": "But I do want you guys\nto think about this as we go through the talk\nbecause a lot of ideas that I'm",
    "start": "252150",
    "end": "259560"
  },
  {
    "text": "talking about today could\nbe used in this system, in this [? local ?]\nsandbox system. So I'm going to talk about\npre-training, large pre-trained",
    "start": "259560",
    "end": "266280"
  },
  {
    "text": "models and you could\nimagine using those models for either outputting\nrobot actions or for getting the semantics of\nwhat is going on in this scene",
    "start": "266280",
    "end": "275100"
  },
  {
    "text": "like figuring out these\nare mugs or figuring out what are the right features\nto pay attention to. And I'm also going to talk\na little bit about data",
    "start": "275100",
    "end": "282073"
  },
  {
    "text": "and what type of data\nwe should collect. And again, that's a good idea\nto think back about the system",
    "start": "282073",
    "end": "288000"
  },
  {
    "text": "as we are going through\nthese different topics. So the major part\nof this talk today",
    "start": "288000",
    "end": "294419"
  },
  {
    "text": "is going to be about\nthe fact that, today, we have foundation models\nlike large language models",
    "start": "294420",
    "end": "300780"
  },
  {
    "text": "and it's pretty exciting\nthat we have access to these large models. They have been revolutionary\nin a lot of fields",
    "start": "300780",
    "end": "307770"
  },
  {
    "text": "like natural language,\nprocessing, computer vision, and it is exciting to think\nabout what that actually",
    "start": "307770",
    "end": "313710"
  },
  {
    "text": "means for robotics. And just to get\non the same page, let's define what a\nFoundation Model is.",
    "start": "313710",
    "end": "319650"
  },
  {
    "text": "So the way I'm defining\nfoundation models is that we have a\nmodel that has access",
    "start": "319650",
    "end": "325230"
  },
  {
    "text": "to large amounts\nof diverse data, internet-scale diverse\ndata like text, images, speech, structured\ndata, and so on.",
    "start": "325230",
    "end": "333060"
  },
  {
    "text": "And what I would\nlike to do is, I would like to pre-train\nsome sort of representation",
    "start": "333060",
    "end": "338430"
  },
  {
    "text": "from that data. So once I can take\nthat representation, I could actually adapt that for\nmany different downstream tasks.",
    "start": "338430",
    "end": "347190"
  },
  {
    "text": "I would like to take\nthat and I would like to do things\nlike in NLP, I would like to do things like question\nanswering or sentiment analysis",
    "start": "347190",
    "end": "354310"
  },
  {
    "text": "or instruction following. And if you think about the field\nof natural language processing, each one of these\ndownstream tasks",
    "start": "354310",
    "end": "361780"
  },
  {
    "text": "were basically like a research\nthesis or a research problem on its own for the longest.",
    "start": "361780",
    "end": "367750"
  },
  {
    "text": "And the thing that foundation\nmodels really enabled is now we could do\nlike all of them with a single model and the\nfact that we have access",
    "start": "367750",
    "end": "375639"
  },
  {
    "text": "to large amounts\nof data, we have a large model that could be\nadapted to do any of these. So that is pretty\nexciting, right?",
    "start": "375640",
    "end": "383230"
  },
  {
    "text": "At least for the field of\nNLP that is pretty exciting. Another question is, well,\nnow that they are a thing,",
    "start": "383230",
    "end": "389290"
  },
  {
    "text": "large language models-- it's an\nexample of a foundation model-- what does that actually\nmean for robotics?",
    "start": "389290",
    "end": "396670"
  },
  {
    "text": "And I do think there are\ntwo different takes here. So one take is maybe we should\ndo the same thing for robotics.",
    "start": "396670",
    "end": "404410"
  },
  {
    "text": "What does it take to do the\nsame thing for robotics? What does it take\nto build something that resembles a foundation\nmodel for robotics?",
    "start": "404410",
    "end": "412330"
  },
  {
    "text": "What is the input? What is the output? How should we go about that? And that is a very\ngrand view of things.",
    "start": "412330",
    "end": "418570"
  },
  {
    "text": "I think that's a very\nexciting view of things. But that's only one take\nlike that's only one",
    "start": "418570",
    "end": "423730"
  },
  {
    "text": "way of looking at the problem. And maybe we should talk about\nthat one take for a second",
    "start": "423730",
    "end": "430669"
  },
  {
    "text": "and I'll talk about the second\ntake in a little bit, too. But let's first talk\nabout this take.",
    "start": "430670",
    "end": "435837"
  },
  {
    "text": "What does that mean? So that means that I would like\nto have many different data sources, again, internet\nscale data sources.",
    "start": "435837",
    "end": "442460"
  },
  {
    "text": "These data could\ncome from humans like they could be human videos. We have a lot of\nhuman videos of humans",
    "start": "442460",
    "end": "447830"
  },
  {
    "text": "doing various types\nof tasks on YouTube and it would be really\nwonderful to be able to tap into that type of data.",
    "start": "447830",
    "end": "454400"
  },
  {
    "text": "We might have some amount\nof robot interaction data. You might be asking where\ndoes that come from.",
    "start": "454400",
    "end": "460180"
  },
  {
    "text": "We all talk about\ndata in a little bit. We have natural language. Maybe we have a lot\nof simulation data.",
    "start": "460180",
    "end": "465230"
  },
  {
    "text": "We could actually simulate\nrobots and that simulation data is also really powerful. , And\nwe could take all of this data",
    "start": "465230",
    "end": "471620"
  },
  {
    "text": "and ideally we would like to\npre-train some representation. I think it's a good\nquestion to ask",
    "start": "471620",
    "end": "476690"
  },
  {
    "text": "what that pre-training\nobjective should be. And then we would\nlike to, again, adapt that to many\ndifferent downstream tasks.",
    "start": "476690",
    "end": "484250"
  },
  {
    "text": "And I think in robotics, we\nget bogged down with imitation or with control.",
    "start": "484250",
    "end": "489260"
  },
  {
    "text": "A lot of times,\nwe think the thing that only matters at\nthe end of the day is the control or the\nmotion of the robot",
    "start": "489260",
    "end": "495680"
  },
  {
    "text": "but there are actually many\ndifferent downstream tasks that we should care\nabout in robotics, too. For example, you might want to\nbe better grounded or figure out",
    "start": "495680",
    "end": "503120"
  },
  {
    "text": "what are the\naffordances of an object or what is the\nintent of the human. So there are actually many\ndifferent downstream tasks",
    "start": "503120",
    "end": "509780"
  },
  {
    "text": "that we might care\nabout in robotics and I think it's useful to\nthink about that adaptation question for these different\ntypes of downstream tasks",
    "start": "509780",
    "end": "516799"
  },
  {
    "text": "in robotics. So today what my\nplan is, I'm going to talk about a bunch of\nworks that kind of fall",
    "start": "516799",
    "end": "521809"
  },
  {
    "text": "into this category of\npre-training foundation models for robotics or\npre-training large models",
    "start": "521809",
    "end": "528139"
  },
  {
    "text": "that resemble a foundation\nmodel for robotics. I'm going to cover a little\nbit of work around that.",
    "start": "528140",
    "end": "533780"
  },
  {
    "text": "Actually, the most of the\ntalk is going to be on that. And then I have kind\nof like a second part of the talk, which I\nprobably won't have time",
    "start": "533780",
    "end": "540890"
  },
  {
    "text": "to get into details. But for the second part of the\ntalk, that's the second take. I'm going to talk a\nlittle bit about how",
    "start": "540890",
    "end": "547230"
  },
  {
    "text": "we could leverage\nexisting foundation models like large language\nmodels or vision language models",
    "start": "547230",
    "end": "552870"
  },
  {
    "text": "for robotics. So the idea of\nthis second part is to not go and do pre-training\nand build this giant model",
    "start": "552870",
    "end": "560160"
  },
  {
    "text": "on giant amount of\ndata but to just use ChatGPT in creative\nways for robotics.",
    "start": "560160",
    "end": "565306"
  },
  {
    "text": "And I think there are quite\na bit of opportunities in terms of how we\nshould think about LLMs and VLMs in this\nspace of robotics",
    "start": "565307",
    "end": "572520"
  },
  {
    "text": "and I'll kind of touch\nupon some of them for this second bit of the talk. OK.",
    "start": "572520",
    "end": "578470"
  },
  {
    "text": "All right. So let's just jump into it. So if this is the diagram\nthat I, I have data,",
    "start": "578470",
    "end": "584009"
  },
  {
    "text": "I have pre-training,\nI have adaptation, what I could start\nthinking about is about that\npre-training objective.",
    "start": "584010",
    "end": "590550"
  },
  {
    "text": "So let's, for a second,\nassume we have data. Let's say data is\nnot our problem. Let's say we have collected\nsome amount of data going back",
    "start": "590550",
    "end": "598140"
  },
  {
    "text": "to the YouTube human\nvideos of humans doing various types of tasks. And I think a good\nquestion to ask",
    "start": "598140",
    "end": "604020"
  },
  {
    "text": "is, what should the\npre-training objective be and what is it that\nI'm trying to learn with this large\npre-trained model?",
    "start": "604020",
    "end": "611080"
  },
  {
    "text": "And that brings us\nto the prior work like what do prior work\ndo when they have access",
    "start": "611080",
    "end": "616210"
  },
  {
    "text": "to human videos? And then oftentimes,\nprior work try to learn visual representations.",
    "start": "616210",
    "end": "622360"
  },
  {
    "text": "So I have videos, I have\ndata of the form of images and one thing I\ncould do is, I could",
    "start": "622360",
    "end": "628390"
  },
  {
    "text": "go ahead and try to learn some\nsort of visual representation from those images and those\nvisual representations",
    "start": "628390",
    "end": "634569"
  },
  {
    "text": "could be useful for\ndownstream tasks. And the thing is, if you\nlook at the field of vision",
    "start": "634570",
    "end": "639800"
  },
  {
    "text": "and what are exist the\nvisual representations that",
    "start": "639800",
    "end": "645560"
  },
  {
    "text": "exist in the field of vision\nthat people often use, they kind of fall into two extremes.",
    "start": "645560",
    "end": "650570"
  },
  {
    "text": "So we have one extreme\nwhich is using things of the form of mask autoencoding\nand these types of models,",
    "start": "650570",
    "end": "658403"
  },
  {
    "text": "what do they do? They take an image. They mask it out\nand then they try to encode that, and decode that,\nand reconstruct that image.",
    "start": "658403",
    "end": "665250"
  },
  {
    "text": "So you take your full-on\nimage, you mask it out and you reconstruct it. And this idea of\nmask autoencoding",
    "start": "665250",
    "end": "671699"
  },
  {
    "text": "is pretty popular\nin computer vision. It turns out that\nit's actually very useful for robotics as well.",
    "start": "671700",
    "end": "677319"
  },
  {
    "text": "And the reason it is\nuseful for robotics is, it captures a lot of\nlocal and spatial features.",
    "start": "677320",
    "end": "682500"
  },
  {
    "text": "So for example, if I'm looking\nat picking up this mobile phone, I actually need to\nknow the edges of this",
    "start": "682500",
    "end": "688050"
  },
  {
    "text": "and I need to know the\ndetails of this object and using mask\nautoencoding, I would be able to get these\nlocal spatial features.",
    "start": "688050",
    "end": "695370"
  },
  {
    "text": "So using these types\nof representations, I'll have some hope that that\npolicy, that I'll train later",
    "start": "695370",
    "end": "701370"
  },
  {
    "text": "with this representation, would\nbe able to pick up the phone because I'll get the details of\nwhat is going on with my object.",
    "start": "701370",
    "end": "707910"
  },
  {
    "text": "So that's pretty\nexciting, right? I get a lot of local\nspatial features, I could do pixel reconstruction,\nI could figure out",
    "start": "707910",
    "end": "713400"
  },
  {
    "text": "these detailed patterns that can\nhelp me do things like grasping. But there is a problem\nwith this one extreme",
    "start": "713400",
    "end": "720310"
  },
  {
    "text": "and the problem here is that\nthese types of features, they kind of lack semantics.",
    "start": "720310",
    "end": "725769"
  },
  {
    "text": "So imagine that you want\nto pour milk out of a jar.",
    "start": "725770",
    "end": "732280"
  },
  {
    "text": "So let's say I have a jar of\nmilk, I want to pour milk. And then let's say that you\nhave a jar of orange juice and you also want\nto pour out of that.",
    "start": "732280",
    "end": "739270"
  },
  {
    "text": "If you were to treat these\nproblems and the representations using mass autoencoding,\nyou would actually",
    "start": "739270",
    "end": "744700"
  },
  {
    "text": "treat those two\ntasks differently because a pixel of milk is white\nand a pixel of an orange juice",
    "start": "744700",
    "end": "750130"
  },
  {
    "text": "is orange. And they look very\ndifferent, so you're going to redo all the work and\nnot realize that pouring liquid",
    "start": "750130",
    "end": "756280"
  },
  {
    "text": "is pouring liquid. You wouldn't be able to\ncapture the semantics that goes into pouring, the act\nof pouring and the fact",
    "start": "756280",
    "end": "763149"
  },
  {
    "text": "that the two are similar. So these types of models--\nthey lack semantics. And then that brings us to\nanother extreme and this extreme",
    "start": "763150",
    "end": "771880"
  },
  {
    "text": "is things like clip. If you look at pre-trained\nrepresentations that",
    "start": "771880",
    "end": "777410"
  },
  {
    "text": "try to align\nlanguage with images, we get things that\ncapture semantics.",
    "start": "777410",
    "end": "784610"
  },
  {
    "text": "If you look at clip\nrepresentations, they try to ensure that\nyou understand pouring. The act of pouring is similar\nto other acts of pouring",
    "start": "784610",
    "end": "792250"
  },
  {
    "text": "and you get more\naligned representations in terms of your image and your\nlanguage which is wonderful.",
    "start": "792250",
    "end": "799580"
  },
  {
    "text": "But the way they\ndo that is often by using contrastive learning. So the way that you\nusually get at that",
    "start": "799580",
    "end": "805910"
  },
  {
    "text": "is, you have this\ncontrastive objective that allows you to use\nlanguage supervision",
    "start": "805910",
    "end": "811010"
  },
  {
    "text": "and then learn\nconcepts across images. But the problem with the\ncontrastive objective",
    "start": "811010",
    "end": "817579"
  },
  {
    "text": "is it's going to destroy all\nyour local and spatial features. So the moment you're using\nthat contrastive objective,",
    "start": "817580",
    "end": "824000"
  },
  {
    "text": "that clip feature, you're\ngoing to lose all those details that you actually cared about.",
    "start": "824000",
    "end": "829140"
  },
  {
    "text": "So going back to the\nact of picking up, you could try to think about\npicking up an act of picking up",
    "start": "829140",
    "end": "835970"
  },
  {
    "text": "but given that you're\nlosing all the features, you're going to struggle\nwith things like actually",
    "start": "835970",
    "end": "841010"
  },
  {
    "text": "grasping the object. This type of motion, which\ndid not pick up the item, but just generally,\nthis type of motion",
    "start": "841010",
    "end": "847699"
  },
  {
    "text": "is pretty similar to\nactually picking up the item. And it seems like the right\nthing from a clip perspective",
    "start": "847700",
    "end": "854750"
  },
  {
    "text": "but it's actually not going\nto be doing the robotics tasks that we care about.",
    "start": "854750",
    "end": "859850"
  },
  {
    "text": "And because of that, things\nlike clip or things like R3M, basically, these models that\nare trying to capture semantics,",
    "start": "859850",
    "end": "866120"
  },
  {
    "text": "they wouldn't really be able\nto do the downstream robotics tasks that we care about. So kind of like being motivated\nby the fact that existing",
    "start": "866120",
    "end": "873020"
  },
  {
    "text": "representations--\nthey're not grounded and they're coming, again,\nfrom the field of vision but they're not really thinking\nabout the robotics' objective",
    "start": "873020",
    "end": "880430"
  },
  {
    "text": "that we have. What we decided to do was,\nwe decided to close this gap and then we introduced\nthis model called Voltron.",
    "start": "880430",
    "end": "887779"
  },
  {
    "text": "And what Voltron\nis trying to do is, it's trying to basically\ncombine the two worlds a little",
    "start": "887780",
    "end": "893720"
  },
  {
    "text": "bit together to get both\nsyntax and semantics. So what we are thinking about\nis that, great, reconstruction",
    "start": "893720",
    "end": "899840"
  },
  {
    "text": "allows me to\nreconstruct the image, captioning, being an objective\nallows me to actually",
    "start": "899840",
    "end": "905240"
  },
  {
    "text": "think about semantics, so maybe\nto get the best of both worlds, we could have grounded\nreconstruction.",
    "start": "905240",
    "end": "910519"
  },
  {
    "text": "Maybe we could start\nwith reconstruction but then we should maybe\nthink about language as another supervision to think\nabout the semantics of the task.",
    "start": "910520",
    "end": "919899"
  },
  {
    "text": "At this point, you might be\nasking, well, is that it? Did we solve this? Is this all we need in robotics?",
    "start": "919900",
    "end": "926610"
  },
  {
    "text": "Is this all we need in\na visual representation when we are thinking about\nrobotics task or robot learning",
    "start": "926610",
    "end": "932100"
  },
  {
    "text": "tasks? And the answer is probably not. This is kind of a first attempt. If you just look\nat this, you might",
    "start": "932100",
    "end": "939660"
  },
  {
    "text": "realize there are a bunch of\nother things that we have not modeled, things like dynamics.",
    "start": "939660",
    "end": "945840"
  },
  {
    "text": "So if you think about any\ntype of robotics task, it's not just about\nsyntax and semantics. We have motion,\nwe have dynamics,",
    "start": "945840",
    "end": "952830"
  },
  {
    "text": "we have the world changing,\nwe have dynamic interactions. And if you're an NLP\nperson, maybe you",
    "start": "952830",
    "end": "958223"
  },
  {
    "text": "can kind of like\nsqueeze your eyes and think of that as pragmatics. I don't know how well\nthat analogy works,",
    "start": "958223",
    "end": "964800"
  },
  {
    "text": "but you could really\nthink of more things that are important in that\nrepresentation to be",
    "start": "964800",
    "end": "970649"
  },
  {
    "text": "useful for robotics tasks. And this brings me\nto the model that we",
    "start": "970650",
    "end": "976050"
  },
  {
    "text": "trained like Voltron\nwhich is visual-language driven representation\nlearning model that is the first attempt\nthat tries to get",
    "start": "976050",
    "end": "982240"
  },
  {
    "text": "the syntax and semantics and a\nlittle bit of an understanding of dynamics, this\nmulti-frame changes",
    "start": "982240",
    "end": "987518"
  },
  {
    "text": "that we see in the environment. So we are trying to\nget almost three things in that representation and hope\nthat that representation could",
    "start": "987518",
    "end": "995170"
  },
  {
    "text": "actually be useful for\ndownstream robotics. So this is work that\nSidd Karamcheti actually led with the collaboration\nwith a lot of people with TRI",
    "start": "995170",
    "end": "1002699"
  },
  {
    "text": "and as I mentioned, the\nkey idea is use language to shape the representations and\nto ground the representations.",
    "start": "1002700",
    "end": "1009899"
  },
  {
    "text": "So just to get into some\ndetails of what Voltron does, it really starts with a\nmascot of encoding backbone.",
    "start": "1009900",
    "end": "1016050"
  },
  {
    "text": "So the usual thing where\nyou start with an image and then you do\npixel reconstruction, like that usual thing of you're\nencoding this, decoding this.",
    "start": "1016050",
    "end": "1023070"
  },
  {
    "text": "Wonderful. You have your image patches. But then in addition\nto that, we are",
    "start": "1023070",
    "end": "1028349"
  },
  {
    "text": "going to condition our\nencoder on the language. So we're going to have\na captioning loss.",
    "start": "1028349",
    "end": "1033959"
  },
  {
    "text": "So if you look at\nthis image, this is an image of peeling\na carrot with a peeler and I'm going to have a\nlanguage annotation for that.",
    "start": "1033960",
    "end": "1040419"
  },
  {
    "text": "So I'm kind of assuming my data\nset is annotated with language. So you've got to have some\nassumptions about your data.",
    "start": "1040420",
    "end": "1046980"
  },
  {
    "text": "And by doing so, by having this\ncaptioning loss in addition to the mask autoencoding\nloss, together,",
    "start": "1046980",
    "end": "1053220"
  },
  {
    "text": "we are marrying\nsyntax and semantics and you're trying to get the\nbest of those two worlds.",
    "start": "1053220",
    "end": "1059090"
  },
  {
    "text": "But that's not enough. I mentioned context matters. Dynamics matters. So to really try to get the\ncontext, what we are doing",
    "start": "1059090",
    "end": "1066770"
  },
  {
    "text": "is instead of passing\nin a single frame, you're passing in\nmultiple frames. So you're passing in a\nfuture frame in addition",
    "start": "1066770",
    "end": "1073100"
  },
  {
    "text": "to our initial frame. You could pass in\nthe full video. It's just going to be more\nexpensive to train that model",
    "start": "1073100",
    "end": "1078343"
  },
  {
    "text": "and deal with the\nchallenges of training the model that is why we are\njust only passing two frames.",
    "start": "1078343",
    "end": "1083570"
  },
  {
    "text": "But you could really\nthink of the act of peeling the\ncarrot with a peeler to be something that really\ndepends on two frames, not just",
    "start": "1083570",
    "end": "1090830"
  },
  {
    "text": "a single frame. And that is why we are\npassing in multiple frames to capture the world model,\nthe dynamics that goes on here.",
    "start": "1090830",
    "end": "1098450"
  },
  {
    "text": "And then finally,\nthe last component that this Voltron model has is\na language-generation component.",
    "start": "1098450",
    "end": "1104630"
  },
  {
    "text": "So not only we are\ncaptioning language and we are passing in multiple\nframes, what we would like to do",
    "start": "1104630",
    "end": "1110390"
  },
  {
    "text": "is we would also like to be able\nto generate the language that goes into describing the\nchanges in this image.",
    "start": "1110390",
    "end": "1117649"
  },
  {
    "text": "So again, peeling the\ncarrots with a peeler. So basically, the\nloss function when we are training this is, again,\nmasked autoencoding backbone, so",
    "start": "1117650",
    "end": "1125730"
  },
  {
    "text": "the reconstruction loss. But in addition to that, we\nhave a language captioning loss,",
    "start": "1125730",
    "end": "1130919"
  },
  {
    "text": "we have a language\ngeneration loss, and then we have this\nmulti-frame conditioning component that goes\ninto the model.",
    "start": "1130920",
    "end": "1139350"
  },
  {
    "text": "All right. So kind of combining\nall three of this, we are going to have a model. We should train it on something.",
    "start": "1139350",
    "end": "1145760"
  },
  {
    "text": "The question is\nwhat is that thing? I promise we have data. We don't really have data but\nimagine that we have data.",
    "start": "1145760",
    "end": "1151940"
  },
  {
    "text": "The data that we decided to\ntrain this on were human videos. So we started with this\nsomething-something data set",
    "start": "1151940",
    "end": "1159020"
  },
  {
    "text": "which is a data set of\negocentric view of humans doing various types\nof tasks like peeling a carrot with a peeler.",
    "start": "1159020",
    "end": "1164670"
  },
  {
    "text": "There's a much larger\ndata set called Ego4D which is very messy. And in the second\nversion of Voltron,",
    "start": "1164670",
    "end": "1170480"
  },
  {
    "text": "we have actually trained\non a subset of Ego4D and a bunch of\nother data sets that have been available since then.",
    "start": "1170480",
    "end": "1177050"
  },
  {
    "text": "And training on large amounts of\nhuman videos under these three different objectives\ngives us a model",
    "start": "1177050",
    "end": "1183980"
  },
  {
    "text": "that could actually\nbe used and fine-tuned for various types\nof downstream tasks.",
    "start": "1183980",
    "end": "1189590"
  },
  {
    "text": "So if you remember the point\nof that foundation model was not to just do\none thing, the point",
    "start": "1189590",
    "end": "1195020"
  },
  {
    "text": "was you're doing a\npre-training objective so that you have a\nrepresentation that could actually be fine-tuned\nfor many different things.",
    "start": "1195020",
    "end": "1202130"
  },
  {
    "text": "So what are those\nmany different things? And as I mentioned\nearlier, maybe",
    "start": "1202130",
    "end": "1207200"
  },
  {
    "text": "imitation learning like\nsingle task imitation. Single task imitation\nis something",
    "start": "1207200",
    "end": "1212480"
  },
  {
    "text": "that we care about like maybe\nwe really care about the robot just picking up the\nphone or doing the task,",
    "start": "1212480",
    "end": "1217909"
  },
  {
    "text": "or maybe we care about the robot\nto do instruction following, so I would give a high-level\nlanguage instruction.",
    "start": "1217910",
    "end": "1223700"
  },
  {
    "text": "Remember the [? local ?]\nsandbox example where Sidd was like, hey,\nyou should pick up the cup. So you might give a\nhigh-level instruction",
    "start": "1223700",
    "end": "1230810"
  },
  {
    "text": "and expect a robot to\nactually follow that. But there are other\nthings that we care about like figuring out\nwhat affordances are,",
    "start": "1230810",
    "end": "1237170"
  },
  {
    "text": "doing some sort of referring\nexpression grounding, figuring out what the\nintent of the human is.",
    "start": "1237170",
    "end": "1242360"
  },
  {
    "text": "And each one of\nthese different tasks could fall in at a different\npart of the spectrum of syntax,",
    "start": "1242360",
    "end": "1248510"
  },
  {
    "text": "semantics, and pragmatics\nbecause as I mentioned syntax, semantics, and\npragmatics are at least some",
    "start": "1248510",
    "end": "1255320"
  },
  {
    "text": "of the things that we care\nabout in robotics tasks. So for example,\nif you're thinking about grasp affordances,\nmaybe it is not really",
    "start": "1255320",
    "end": "1262560"
  },
  {
    "text": "a pragmatics thing. Maybe it is more about really\nthe syntax and the details of the image so\nthat's why I'm putting",
    "start": "1262560",
    "end": "1269460"
  },
  {
    "text": "that closer to the\nsyntax spectrum of where our robotics tasks fall on.",
    "start": "1269460",
    "end": "1275940"
  },
  {
    "text": "So we decided to define\nthis taxonomy of tasks and take this Voltron\nrepresentation",
    "start": "1275940",
    "end": "1281100"
  },
  {
    "text": "and fine-tune it on\nthese different types of downstream tasks. And I'm going to show a\ncouple of examples here.",
    "start": "1281100",
    "end": "1286590"
  },
  {
    "text": "So I'm not going\nto show everything. As an example, we looked at\nlanguage-conditioned imitation",
    "start": "1286590",
    "end": "1291810"
  },
  {
    "text": "learning where we are looking\nat tasks like shut the drawer, throw the bag of chips away.",
    "start": "1291810",
    "end": "1297660"
  },
  {
    "text": "So these are the different\ntypes of instructions that a Franka robot arm is given\nand it acts in this environment. So it's a real\nrobot that's trying",
    "start": "1297660",
    "end": "1303990"
  },
  {
    "text": "to follow these instructions. We are given 20 demonstrations.",
    "start": "1303990",
    "end": "1309060"
  },
  {
    "text": "So again, remember the\nVoltron representation, it's just a visual\nrepresentation. It's not a policy.",
    "start": "1309060",
    "end": "1314850"
  },
  {
    "text": "It's not going out with actions. It's just going to give you\nsome visual representation and then you're going to\nuse that representation",
    "start": "1314850",
    "end": "1321480"
  },
  {
    "text": "to actually generate a policy. So we are giving this\nmodel 20 different or we are giving our policy\n20 different demonstrations",
    "start": "1321480",
    "end": "1329700"
  },
  {
    "text": "and we are running the\nVoltron representation. As you can see in orange,\nthat is Voltron representation",
    "start": "1329700",
    "end": "1334800"
  },
  {
    "text": "and we are outputting\nwhat the policy would do if I were to use\nVoltron representation",
    "start": "1334800",
    "end": "1339990"
  },
  {
    "text": "as opposed to\nother things like-- I don't think I have clip here--\nbut like clip would actually be worse.",
    "start": "1339990",
    "end": "1345960"
  },
  {
    "text": "But you could look at R3M which\nis pretty similar because it's using that contrastive objective\nthat captures semantics but kind",
    "start": "1345960",
    "end": "1352890"
  },
  {
    "text": "of destroys the syntax. And then we are also comparing\nwith mask visual pre-training",
    "start": "1352890",
    "end": "1357929"
  },
  {
    "text": "that is similar to\nusing mask autoencoding. It's kind of the opposite. It destroys semantics\nbut captures syntax.",
    "start": "1357930",
    "end": "1365070"
  },
  {
    "text": "And as you can see, the\nVoltron models-- again, the reason I have\nthree of them is, the first one is just doing\nconditioning, captioning,",
    "start": "1365070",
    "end": "1372695"
  },
  {
    "text": "the second one is doing\nconditioning on two frames, and the darkest orange\nis using all three of those objectives, language\ngeneration, language captioning",
    "start": "1372695",
    "end": "1380007"
  },
  {
    "text": "and conditioning on two frames. And all three of these\nmodels outperform the R3M model or the\nMVP model or other types",
    "start": "1380008",
    "end": "1386490"
  },
  {
    "text": "of visual representations\nthat don't really think about grounding. I think another\ninteresting point here",
    "start": "1386490",
    "end": "1392910"
  },
  {
    "text": "that I want to mention is\nmore of a qualitative example. So I mentioned imitation is not\nthe only thing we care about",
    "start": "1392910",
    "end": "1398034"
  },
  {
    "text": "and I think one of\nthe exciting results here is thinking about\nintent inference. So what I could do\nis, I could pass",
    "start": "1398035",
    "end": "1405630"
  },
  {
    "text": "in a video of a\nhuman doing a task, a video that this robot has not\nseen or this model has not seen.",
    "start": "1405630",
    "end": "1412020"
  },
  {
    "text": "So this is a video of a\nperson opening a faucet, grasping a faucet and opening\nit and what I could do",
    "start": "1412020",
    "end": "1419220"
  },
  {
    "text": "is, I could ask the\nVoltron model when the faucet is being grasped. And actually with high\nprobability like my Voltron",
    "start": "1419220",
    "end": "1426330"
  },
  {
    "text": "model is predicting\nthe human intent of the faucet being grasped.",
    "start": "1426330",
    "end": "1432600"
  },
  {
    "text": "And that's pretty exciting\nbecause zero-shot, again, with no fine tuning\nor anything of that form,",
    "start": "1432600",
    "end": "1438730"
  },
  {
    "text": "the model is able to\ncapture the concept of grasping by\njust being trained on a bunch of human videos.",
    "start": "1438730",
    "end": "1445180"
  },
  {
    "text": "And I think the\nmore exciting thing is, it doesn't need\nto be a human video. I can pass in a robot\nvideo and this model",
    "start": "1445180",
    "end": "1450610"
  },
  {
    "text": "has not seen any robot videos. But if I pass in a robot\nvideo, again, the Voltron model is able to predict when the\nfaucet is being grasped which",
    "start": "1450610",
    "end": "1458740"
  },
  {
    "text": "I think is also pretty cool. That we could we\ncould use the model in very interesting\ncreative ways beyond just using for control\nor imitation learning.",
    "start": "1458740",
    "end": "1467622"
  },
  {
    "text": "So this is open source. You could peep, install\nVoltron robotics. Please give it a try. We have a new version\nof it actually",
    "start": "1467622",
    "end": "1472840"
  },
  {
    "text": "recently released, the Voltron\nx model, trained on more data. And give us feedback\nso we'd be-- yeah,",
    "start": "1472840",
    "end": "1479290"
  },
  {
    "text": "I'm curious to what you\nguys think about it. Anywhere you're calling\nResNet, you could call Voltron. So that is how\nyou should use it.",
    "start": "1479290",
    "end": "1486260"
  },
  {
    "text": "So anywhere you're calling\nit pre-trained visual representation, potentially, you\nshould be able to use Voltron and it would be more\ngrounded for robotics tasks",
    "start": "1486260",
    "end": "1493720"
  },
  {
    "text": "that you might be interested in. All right. So just to summarize what\nI've talked about so far is--",
    "start": "1493720",
    "end": "1501980"
  },
  {
    "text": "the key takeaway, really,\nis that in practice, we are interested in tapping into\nlarge scale, internet scale",
    "start": "1501980",
    "end": "1510620"
  },
  {
    "text": "data in the same way that\nlarge pre-trained models in NLP or vision do the same thing.",
    "start": "1510620",
    "end": "1517100"
  },
  {
    "text": "We would like to tap\ninto human videos and from those human\nvideos, we would like to be able to capture\nrepresentations that",
    "start": "1517100",
    "end": "1523610"
  },
  {
    "text": "are useful for robotics tasks. And I'm not claiming\nthat's a foundation model but that resembles something of\nthe form of a foundation model.",
    "start": "1523610",
    "end": "1531140"
  },
  {
    "text": "Where in this\nparticular case, we are proposing Voltron\nwhich uses language and multi-frame conditioning.",
    "start": "1531140",
    "end": "1537290"
  },
  {
    "text": "And together with language\nand multi-frame conditioning, we would be able to learn\ngrounded visual representations.",
    "start": "1537290",
    "end": "1543740"
  },
  {
    "text": "So going back to this picture,\nthis is really the piece that I've talked about. You pre-train a\nrepresentation, you",
    "start": "1543740",
    "end": "1549560"
  },
  {
    "text": "could fine-tune it on\nmany different tasks. And that sounds great,\nand wonderful, and useful.",
    "start": "1549560",
    "end": "1557660"
  },
  {
    "text": "But I didn't really\ntalk about data. So what I would like to do for\nthe rest of my 10 minutes, 15",
    "start": "1557660",
    "end": "1565250"
  },
  {
    "text": "minutes, I would like to\ntalk a little bit about data and how we should think\nabout data going forward",
    "start": "1565250",
    "end": "1572150"
  },
  {
    "text": "and what is good data. And I talked about human videos\nbut in practice, human videos",
    "start": "1572150",
    "end": "1579260"
  },
  {
    "text": "are pretty limited. So we, ideally,\nwould like to tap into things of the form\nof robot interactions.",
    "start": "1579260",
    "end": "1585590"
  },
  {
    "text": "We would like to\ncollect robotics data and again, and again,\nwe see lots of efforts,",
    "start": "1585590",
    "end": "1591560"
  },
  {
    "text": "recent efforts that are trying\nto create large robot data sets, gather large\nrobot data sets",
    "start": "1591560",
    "end": "1598460"
  },
  {
    "text": "and pre-train models on\nthese robot data sets. So this is a project called\nOpen X-Embodiment-Embodiment.",
    "start": "1598460",
    "end": "1605210"
  },
  {
    "text": "There's a model called RT-X.\nAnd the idea of this project was to bring\ntogether roboticists",
    "start": "1605210",
    "end": "1611750"
  },
  {
    "text": "from different institutions. So I think there\nwas 21 institutions",
    "start": "1611750",
    "end": "1617000"
  },
  {
    "text": "and the idea was for folks\nto come together and put all their data sets together so\nwe can have a single place where",
    "start": "1617000",
    "end": "1624620"
  },
  {
    "text": "we have a lot of robot data\ncross embodiment robot data. We are already collecting\nthis robot data in our labs",
    "start": "1624620",
    "end": "1630950"
  },
  {
    "text": "so why not put it all\ntogether and then train a single model on that data.",
    "start": "1630950",
    "end": "1636140"
  },
  {
    "text": "So this project was really\nled by folks at Google but again, a number of labs\nare contributing to this.",
    "start": "1636140",
    "end": "1641420"
  },
  {
    "text": "We contributed to this. Actually, Yuchen contributed her\nHYDRA dataset to this dataset.",
    "start": "1641420",
    "end": "1649220"
  },
  {
    "text": "And it is pretty exciting\nto be able to train a single model on this giant\ncross embodiment dataset.",
    "start": "1649220",
    "end": "1657289"
  },
  {
    "text": "And the model is not\ngreat, but the fact that we could have a model\nand then we could fine-tune it",
    "start": "1657290",
    "end": "1662570"
  },
  {
    "text": "for many different tasks,\nI think that is actually pretty exciting. Another effort that\nI want to mention",
    "start": "1662570",
    "end": "1669090"
  },
  {
    "text": "is a particular effort on\nlarge-scale in-the-wild robot data collection. This is a recent\neffort called DROID.",
    "start": "1669090",
    "end": "1675480"
  },
  {
    "text": "This was also one\nof those efforts where we have a number\nof labs coming together collecting data, robot-specific\ndata to be able to do",
    "start": "1675480",
    "end": "1684929"
  },
  {
    "text": "in-the-wild types of tasks. So this was again a project\nwhere a number of institutions",
    "start": "1684930",
    "end": "1690240"
  },
  {
    "text": "contributed-- I think 13 institutions\ncontributed. And this is not--",
    "start": "1690240",
    "end": "1695340"
  },
  {
    "text": "the way this is different\nfrom Open X-Embodiment is, Open X-Embodiment\nis cross embodiment.",
    "start": "1695340",
    "end": "1700440"
  },
  {
    "text": "I already collected\nmy Franka data or I already\ncollected my Kuka data and I'm just adding\nthat to a single place.",
    "start": "1700440",
    "end": "1707190"
  },
  {
    "text": "But the idea of\nDROID is for everyone to have the same platform. This is a platform,\na robot Franka",
    "start": "1707190",
    "end": "1714750"
  },
  {
    "text": "arm with the same type of\ngripper, with the same cameras. And then the idea is to take\nthe robot, the same robot,",
    "start": "1714750",
    "end": "1721380"
  },
  {
    "text": "so not cross embodiment--\nbut take the robot outside of the lab in the wild\nand really try to collect data,",
    "start": "1721380",
    "end": "1728980"
  },
  {
    "text": "diverse data of the\nform of diverse motions, and diverse tasks, and\ncamera views, and so on.",
    "start": "1728980",
    "end": "1735039"
  },
  {
    "text": "And this was a pretty\nexciting project because it allowed us\nto collect somewhat",
    "start": "1735040",
    "end": "1740830"
  },
  {
    "text": "like not cross embodiment\ncrazy but somewhat more aligned datasets that have a lot of\ndiversity that could actually",
    "start": "1740830",
    "end": "1747759"
  },
  {
    "text": "help us train large models\non these types of data. Here is actually a video\nof one of the students",
    "start": "1747760",
    "end": "1753850"
  },
  {
    "text": "collecting data in their dorm. So I think this is EVGR. I think a lot of\ndata looks like this",
    "start": "1753850",
    "end": "1759970"
  },
  {
    "text": "because people took it to\nEVGR and all EVGR apartments lookalike. But basically,\nthis is us thinking",
    "start": "1759970",
    "end": "1767740"
  },
  {
    "text": "about teleoperating the robot\nand unloading a dishwasher and thinking about, again,\nin-the-wild types of tasks",
    "start": "1767740",
    "end": "1776320"
  },
  {
    "text": "and collecting large amounts\nof data in this setting. Yes? That's way too nice to be EVGR.",
    "start": "1776320",
    "end": "1782740"
  },
  {
    "text": "Is that not EVGR? I've kept saying--\nis this not EVGR? No.",
    "start": "1782740",
    "end": "1787930"
  },
  {
    "text": "Is it Munger? It's a dorm. I'm pretty sure it's a dorm. [INTERPOSING VOICES] And I\nthought EVGR is the nicest.",
    "start": "1787930",
    "end": "1793549"
  },
  {
    "text": "Come on. Munger. Munger. OK. This is Munger. But we have a lot of our data\nlooks like this, I think.",
    "start": "1793550",
    "end": "1799300"
  },
  {
    "text": "So a lot of data from\nthe different grad dorms.",
    "start": "1799300",
    "end": "1804790"
  },
  {
    "text": "And once you collect\nthe data, there's a question of what are you\ntraining on that, how are you actually going to use that?",
    "start": "1804790",
    "end": "1810430"
  },
  {
    "text": "So the first property\nof this dataset is that it is extremely diverse. So if you look at the\ncoverage of types of tasks",
    "start": "1810430",
    "end": "1818080"
  },
  {
    "text": "that you're seeing on DROID\ncompared to other existing datasets that are\nout there like Bridge or if you look at RT-1\nwhich is this dataset that",
    "start": "1818080",
    "end": "1825070"
  },
  {
    "text": "was from Google, the\namount, number of tasks that you're seeing\non this dataset,",
    "start": "1825070",
    "end": "1830680"
  },
  {
    "text": "the coverage is quite a bit. So lots of, lots of\ndata that's wonderful. And again, outside of the lab\ndata, so that's all great.",
    "start": "1830680",
    "end": "1838210"
  },
  {
    "text": "But how do we go about\ntraining on this type of data? And in practice, what you could\ndo is you could take the data",
    "start": "1838210",
    "end": "1845418"
  },
  {
    "text": "and you could do whatever\nyou want with it. You could train a\nVoltron model on it but in this particular\ncase, what we wanted to do",
    "start": "1845418",
    "end": "1851019"
  },
  {
    "text": "was we wanted to actually train\na policy like something that actually outputs\nactions on this data.",
    "start": "1851020",
    "end": "1857649"
  },
  {
    "text": "And that is probably not going\nto be that great in a zero shot manner on a bunch of\ntasks that we care about",
    "start": "1857650",
    "end": "1863780"
  },
  {
    "text": "so we actually need to do some\nlevel of fine-tuning on that. So what I'm showing\nin these plots",
    "start": "1863780",
    "end": "1870400"
  },
  {
    "text": "is that we are\ncollecting some amount of data on a particular task. So for example, the task\nis close the waffle maker.",
    "start": "1870400",
    "end": "1877300"
  },
  {
    "text": "And if I collect that\ndata in domain data, I'm going to have the green\nline as the performance of using",
    "start": "1877300",
    "end": "1885940"
  },
  {
    "text": "that particular data. I think, actually,\nthe plot I'm showing is the O, the\nsetting version of it too so maybe it's\nnot exactly data",
    "start": "1885940",
    "end": "1892270"
  },
  {
    "text": "from exactly the same setting\nbut a similar setting. And you're seeing\nthe performance of how your policy is going to\nact in this particular setting.",
    "start": "1892270",
    "end": "1901600"
  },
  {
    "text": "And then we have\ntwo other lines here and these two other\nlines are going to be two sets of\nco-training runs.",
    "start": "1901600",
    "end": "1908559"
  },
  {
    "text": "So one thing you\ncould do is, you could take 50% of the data\nfor what you have collected in this particular setting, and\n50% of data coming from the Open",
    "start": "1908560",
    "end": "1918880"
  },
  {
    "text": "X-Embodiment dataset\nthat I mentioned earlier, that giant cross embodiment\ndataset that folks at Google",
    "start": "1918880",
    "end": "1924130"
  },
  {
    "text": "helped create, or you could\nuse your DROID dataset. And again, your\nDROID data set is",
    "start": "1924130",
    "end": "1929650"
  },
  {
    "text": "focused on manipulation\ntasks, more in-the-wild, much more diverse than RT-X. And then the idea\nhere is that, well,",
    "start": "1929650",
    "end": "1936039"
  },
  {
    "text": "if you're using either\none of them OXE or DROID, you're going to see fairly\nhigher performance than just",
    "start": "1936040",
    "end": "1943840"
  },
  {
    "text": "using in-domain tasks. We would start to see\nbetter generalization and I think that is actually\nthe exciting part of it.",
    "start": "1943840",
    "end": "1949030"
  },
  {
    "text": "Because of the fact that\nthese types of models can tap into large\namounts of offline data,",
    "start": "1949030",
    "end": "1954130"
  },
  {
    "text": "they should be\nable to generalize to things like distractors\nor generalize to new settings that we haven't seen before.",
    "start": "1954130",
    "end": "1960039"
  },
  {
    "text": "And we see a similar\ntrend throughout, so this averaged out plot. And the other, I think,\ninteresting point from this plot",
    "start": "1960040",
    "end": "1967670"
  },
  {
    "text": "is the fact that we,\nusing DROIDs particularly and the diversity of\nDROID particularly",
    "start": "1967670",
    "end": "1974120"
  },
  {
    "text": "is allowing us to have\nmuch better performance than using the RT-X\nor Open X-Embodiment",
    "start": "1974120",
    "end": "1979490"
  },
  {
    "text": "dataset where we have this\ncross embodiment thing. But in practice, like thinking\nabout adaptation and fine-tuning",
    "start": "1979490",
    "end": "1986130"
  },
  {
    "text": "is a pretty important problem. Actually, these\nplots or some of them are generated by Joey who is\ncontributing to this project",
    "start": "1986130",
    "end": "1991770"
  },
  {
    "text": "and thinking about fine-tuning\nand different types of co-training like\nparadigms and recipes.",
    "start": "1991770",
    "end": "1997230"
  },
  {
    "text": "And I think in general,\nthere's quite a bit of work that could be done and built on\ntop of this DROID dataset which",
    "start": "1997230",
    "end": "2003559"
  },
  {
    "text": "I think is going to be\nreleased sometime soon. So this work is under\nsubmission right now but--",
    "start": "2003560",
    "end": "2009140"
  },
  {
    "text": "and again it's a\ngiant collaboration with a number of labs. But I think I encourage\nyou guys to think",
    "start": "2009140",
    "end": "2014840"
  },
  {
    "text": "about ways of using\nthis DROID dataset, thinking about\nadaptation, fine-tuning, and thinking about data\nquality as we go about building",
    "start": "2014840",
    "end": "2023570"
  },
  {
    "text": "and pre-training these models. So that was a very quick thing\nabout the fact that we need data",
    "start": "2023570",
    "end": "2028980"
  },
  {
    "text": "and I don't think\nI need to argue too hard to say we need to\ncollect large-scale robot data.",
    "start": "2028980",
    "end": "2035310"
  },
  {
    "text": "That is a missing\npiece when we think about pre-training large\nmodels for robotics.",
    "start": "2035310",
    "end": "2041400"
  },
  {
    "text": "But I do think there are a\nnumber of other questions that are worth asking here. So sure, I can go\nand collect my data.",
    "start": "2041400",
    "end": "2047760"
  },
  {
    "text": "I could go crazy and have\nDROID and RT-X and all of these different models but\na good question to ask is,",
    "start": "2047760",
    "end": "2055620"
  },
  {
    "text": "what type of data\nis actually useful and how should I go\nafter data collection?",
    "start": "2055620",
    "end": "2061138"
  },
  {
    "text": "What instructions should I give\nthe students or the people who are collecting this data to take\nwhen they take the robot not",
    "start": "2061139",
    "end": "2069388"
  },
  {
    "text": "to EVGR, to Munger? And what should we\ntell them like when we say, hey, collect data?",
    "start": "2069389",
    "end": "2074940"
  },
  {
    "text": "Nothing? And just tell them go crazy? Or should we guide them\nto give us useful data?",
    "start": "2074940",
    "end": "2082110"
  },
  {
    "text": "And what does useful even mean? So I think so far, we have\ntreated diversity as useful.",
    "start": "2082110",
    "end": "2087960"
  },
  {
    "text": "I showed that\nearlier plot showing that DROID is really diverse. But I think a very fair\nquestion for you to ask",
    "start": "2087960",
    "end": "2094559"
  },
  {
    "text": "is, does that matter\nthat it is diverse? Is that a good thing? Why is it a good thing\nthat it is diverse?",
    "start": "2094560",
    "end": "2099839"
  },
  {
    "text": "And I think we need to\nthink about data quality a little more carefully. So for the next five minutes, I\nwant to take a side a little bit",
    "start": "2099840",
    "end": "2107430"
  },
  {
    "text": "and talk about this idea\nof usefulness a little bit. Not necessarily in the\ncontext of large models",
    "start": "2107430",
    "end": "2113340"
  },
  {
    "text": "but more generally in the\ncontext of robot learning, maybe for small models that\nI would train in my lab",
    "start": "2113340",
    "end": "2118809"
  },
  {
    "text": "that is feasible to\nbe trained in my lab. So let's talk about\nusefulness a little bit and then we'll bring\nit back up afterwards.",
    "start": "2118810",
    "end": "2126610"
  },
  {
    "text": "So what does useful data mean? And this brings me to a project\nwhere we started exploring,",
    "start": "2126610",
    "end": "2133480"
  },
  {
    "text": "again, this idea of usefulness\naccidentally, honestly. So the idea was, we\nhad this robomimic task",
    "start": "2133480",
    "end": "2142210"
  },
  {
    "text": "that you might be familiar\nwith and all we wanted to do was, we wanted to do actually\nsome interactive imitation",
    "start": "2142210",
    "end": "2148390"
  },
  {
    "text": "learning work\nwhere in this task, you are picking up this square\nand you're placing it on a peg.",
    "start": "2148390",
    "end": "2154079"
  },
  {
    "text": "And that's all you want to do. You want to collect some data. You want to train a model. Again, not foundation model.",
    "start": "2154080",
    "end": "2159190"
  },
  {
    "text": "Nothing like that. You collect 20\ndemonstrations on this and you want to see\nhow well you would do on these 20 demonstrations.",
    "start": "2159190",
    "end": "2165837"
  },
  {
    "text": "And Kanishk here, he was\ndoing a rotation with us. So Kanishk was like, this\nshould be like doable enough during a rotation thing, so\nlet me collect some data.",
    "start": "2165837",
    "end": "2172480"
  },
  {
    "text": "And he collected\nsome data and he got a policy that\nwas 14% successful",
    "start": "2172480",
    "end": "2178329"
  },
  {
    "text": "and we thought OK, that's fine. We collected a little bit of\ndata, how bad that could be? And Sidd decided to help\nKanishk in his project.",
    "start": "2178330",
    "end": "2185703"
  },
  {
    "text": "So Sidd came along\nand I was like, let me collect\nmore data for you. And he collected more data. These are real rollouts\nthat people collected.",
    "start": "2185703",
    "end": "2192790"
  },
  {
    "text": "So this is rollouts of Sidd's\ndata and we added Sidd's data in",
    "start": "2192790",
    "end": "2198340"
  },
  {
    "text": "and the performance\nwent down to 7%.",
    "start": "2198340",
    "end": "2204310"
  },
  {
    "text": "We were very confused by this. We thought, well, maybe Sidd\nis really bad at this task and he's not telling us.",
    "start": "2204310",
    "end": "2210010"
  },
  {
    "text": "But then we looked at the\nvideos and we were like, he's doing it right. Success-wise, both\nof these videos",
    "start": "2210010",
    "end": "2215740"
  },
  {
    "text": "are doing the task correctly. You're actually placing\nthe square on a peg. And the question is,\nwhat is going wrong here?",
    "start": "2215740",
    "end": "2223569"
  },
  {
    "text": "Why is it that once you're\nadding more useful good data, performance goes down?",
    "start": "2223570",
    "end": "2229970"
  },
  {
    "text": "And the thing that\nis happening here is something that, in\nhindsight, is obvious which is I'm passing\nin data from two people",
    "start": "2229970",
    "end": "2237140"
  },
  {
    "text": "and they're doing\nthe task differently. Specifically, it might be hard\nto see that they're doing it",
    "start": "2237140",
    "end": "2242990"
  },
  {
    "text": "differently but specifically,\nthe thing that is different is when they turn the square. In terms of when\nthey're placing it",
    "start": "2242990",
    "end": "2249050"
  },
  {
    "text": "is different across the\ntwo sets of demonstrations. And that multi-modality\nalone messes up the policy",
    "start": "2249050",
    "end": "2256865"
  },
  {
    "text": "because you don't\nknow which one to do. Now you're confused about should\nI-- when should I turn my score",
    "start": "2256865",
    "end": "2262360"
  },
  {
    "text": "and then that causes\na bunch of issues. So for example, if you look\nat Kanishk collecting data,",
    "start": "2262360",
    "end": "2267640"
  },
  {
    "text": "so Kanishk could\ncollect a bunch of data and then you could\ncollect more data. And then you look at\nKanishk data with respect",
    "start": "2267640",
    "end": "2272887"
  },
  {
    "text": "to his own data,\nyou're going to have a plot of novelty and\nlikelihood and his data points",
    "start": "2272887",
    "end": "2278920"
  },
  {
    "text": "fall in somewhere here. And the places that\nthey fall in is that he might give\ndata of the same form.",
    "start": "2278920",
    "end": "2285280"
  },
  {
    "text": "So in terms of novelty,\nit might be low. But in terms of likelihood,\nit has Kanishk's style",
    "start": "2285280",
    "end": "2290829"
  },
  {
    "text": "or he might give data\nin very novel scenarios but still in terms\nof likelihood,",
    "start": "2290830",
    "end": "2296079"
  },
  {
    "text": "it is similar to how\nhe would be doing it. And the moment you\nadd in Sidd's data,",
    "start": "2296080",
    "end": "2301420"
  },
  {
    "text": "things start to change\nlike a bunch of his data falls into this category.",
    "start": "2301420",
    "end": "2306700"
  },
  {
    "text": "And what is this category? This is a category where he's\ngiving us not very novel data. It's actually scenarios that\nKanishk has already explored",
    "start": "2306700",
    "end": "2313810"
  },
  {
    "text": "and he's doing it differently. So in terms of\nlikelihood, it's also low. So if you look at this region\nof low likelihood, low novelty,",
    "start": "2313810",
    "end": "2321910"
  },
  {
    "text": "that is the thing that\nmesses up our policy and that is the thing\nthat kind of like",
    "start": "2321910",
    "end": "2327630"
  },
  {
    "text": "is a problem that\nwe need to fix. So if you show this to any\nmachine learning person,",
    "start": "2327630",
    "end": "2333470"
  },
  {
    "text": "they would be like,\nwell, duh, there is a multimodality\nthing happening here. You should have an\nexpressive model that",
    "start": "2333470",
    "end": "2340040"
  },
  {
    "text": "captures the multimodality. Use a diffusion policy. Use something that\ncaptures multimodality.",
    "start": "2340040",
    "end": "2345560"
  },
  {
    "text": "Use a multimodal Gaussian\nprocess or something of that form and just\ngive it enough data",
    "start": "2345560",
    "end": "2353300"
  },
  {
    "text": "and be really expressive. Yeah, you have this problem. But a more pragmatic view of\nthis is, at the end of the day,",
    "start": "2353300",
    "end": "2360620"
  },
  {
    "text": "the only thing I care\nabout is for the square to be placed on the\npeg and I don't really",
    "start": "2360620",
    "end": "2365869"
  },
  {
    "text": "care about all possible\nways of doing it. I don't really care\nabout capturing all the possible multimodalities.",
    "start": "2365870",
    "end": "2372110"
  },
  {
    "text": "So a very simple silly\nthing that I could do is that I could look\nat what part of data",
    "start": "2372110",
    "end": "2379220"
  },
  {
    "text": "is low likelihood\nand low novelty. I'm going to call\nthat incompatible data with my existing dataset.",
    "start": "2379220",
    "end": "2386000"
  },
  {
    "text": "And I could just throw that out. So I could just say,\nwell, Sidd gave me data. He spent some time\nbut let me just",
    "start": "2386000",
    "end": "2391880"
  },
  {
    "text": "throw out that data\nbecause that data is not very useful for what I'm doing. And we actually decided to do\nthis on this robomimic dataset",
    "start": "2391880",
    "end": "2399650"
  },
  {
    "text": "where it's actually\nlike a dataset of people doing the same type of\ntask that I showed earlier. There's a base\noperator that gives",
    "start": "2399650",
    "end": "2406010"
  },
  {
    "text": "some data and the\nperformance of policy is 38% and what happens is that\nwhen operator one comes in",
    "start": "2406010",
    "end": "2413150"
  },
  {
    "text": "and you collect all their data,\nyour success goes up to 54%. So your operator one is\nactually pretty good.",
    "start": "2413150",
    "end": "2419490"
  },
  {
    "text": "Your success goes up. But the thing is\nif you filter out their incompatible\ndemonstrations,",
    "start": "2419490",
    "end": "2425130"
  },
  {
    "text": "you could actually make your\nsuccess rate to go even higher. So you could\nactually like filter out the incompatible data.",
    "start": "2425130",
    "end": "2432650"
  },
  {
    "text": "And I think the more\ninteresting thing is that you could see the\nsame thing, the same trend across a number of other tasks.",
    "start": "2432650",
    "end": "2438049"
  },
  {
    "text": "But I think the more\ninteresting thing here is that you might have\noperators that are not very good at doing the task.",
    "start": "2438050",
    "end": "2444470"
  },
  {
    "text": "So in this case, I\nhave Operator 4 who is not an expert in this task. And when they give data,\nagain, performance goes down.",
    "start": "2444470",
    "end": "2451910"
  },
  {
    "text": "So originally, my policy\nwas 38% successful. Operator 4 comes in and gives\ndata, it goes down to 27%.",
    "start": "2451910",
    "end": "2459590"
  },
  {
    "text": "What one thing I could\ndo is I could realize what is incompatible and\nI could throw that out",
    "start": "2459590",
    "end": "2464780"
  },
  {
    "text": "and that actually brings\nmy performance back up to what it was before. So I think this idea again is\nnot capturing multimodality.",
    "start": "2464780",
    "end": "2473210"
  },
  {
    "text": "It is not trying to be\nmultimodal in any ways, but it does help us\nto recover a policy",
    "start": "2473210",
    "end": "2479030"
  },
  {
    "text": "under limited restrictions\nthat we have in robotics, not infinite data, not\ninfinite model size,",
    "start": "2479030",
    "end": "2484730"
  },
  {
    "text": "and be able to take a more\npragmatic view towards doing this task which I think is\nsimple but is very useful.",
    "start": "2484730",
    "end": "2493539"
  },
  {
    "text": "You might also want to do\nsomething else on top of this. So Sidd is already trying to\nhelp us here and give us data.",
    "start": "2493540",
    "end": "2500230"
  },
  {
    "text": "He's not trying to hurt us. He's really trying\nto be helpful here. And the fact that\nhe's spending time",
    "start": "2500230",
    "end": "2506260"
  },
  {
    "text": "like maybe I should get\nhim to spend that time on more useful things. So one thing we could\ndo is, we could kind of",
    "start": "2506260",
    "end": "2512650"
  },
  {
    "text": "guide him to give us less\nincompatible data and more data that is aligned in terms of\nlikelihood to what we are after.",
    "start": "2512650",
    "end": "2520720"
  },
  {
    "text": "So we decided to do this\nusing a very simple interface. So going back to the human robot\ninteraction side of things,",
    "start": "2520720",
    "end": "2528339"
  },
  {
    "text": "there's a human here\nand that human is not the human that is interacting\nwith the robot or the robot",
    "start": "2528340",
    "end": "2533470"
  },
  {
    "text": "is helpful for them. The human here is the\nhuman who's giving us data and that human is\ntrying to be helpful.",
    "start": "2533470",
    "end": "2538869"
  },
  {
    "text": "So one thing we could do is, we\ncould have a very simple user interface where the\ninterface turned green",
    "start": "2538870",
    "end": "2544300"
  },
  {
    "text": "when you're in distribution,\ngiving good data, and the interface can simply\nturn red when you're out",
    "start": "2544300",
    "end": "2550690"
  },
  {
    "text": "of distribution, giving\nthese types of low novelty, low likelihood type of data.",
    "start": "2550690",
    "end": "2557300"
  },
  {
    "text": "And that very simple interface\nincreases performance by quite a bit.",
    "start": "2557300",
    "end": "2563950"
  },
  {
    "text": "So again, super\nsimple idea but-- this is one of the examples\nthat I really like. So this is a setting\nwhere we are looking",
    "start": "2563950",
    "end": "2569978"
  },
  {
    "text": "at placing an egg on\na plate and if you look at what naive\ndata collection looks",
    "start": "2569978",
    "end": "2576309"
  },
  {
    "text": "like, performance is around 30%. So I collect data,\nperformance is around 30%.",
    "start": "2576310",
    "end": "2582370"
  },
  {
    "text": "But if I do the\ninformed approach, if I do the guided approach and\nguide my teleoperators to give",
    "start": "2582370",
    "end": "2588220"
  },
  {
    "text": "me good data, I could\nactually increase performance to 85% with the same budget.",
    "start": "2588220",
    "end": "2594310"
  },
  {
    "text": "And again, I do think this\nis a very exciting idea because oftentimes, we treat\ndata as this passive thing that",
    "start": "2594310",
    "end": "2601450"
  },
  {
    "text": "is handed to us but in\npractice, it's not handed to us. We spend a lot of\ntime collecting",
    "start": "2601450",
    "end": "2606730"
  },
  {
    "text": "that using DROID or these\ncompanies, for example, often have contractors who are\nlike professional gamers who",
    "start": "2606730",
    "end": "2614050"
  },
  {
    "text": "are collecting data for the\ncompany and what we could do is we could actually guide the\ndata collection to increase",
    "start": "2614050",
    "end": "2620110"
  },
  {
    "text": "the performance significantly. And I think that is\nactually pretty exciting.",
    "start": "2620110",
    "end": "2625320"
  },
  {
    "text": "So let me wrap up my thoughts\naround this idea of data collection and data quality.",
    "start": "2625320",
    "end": "2630480"
  },
  {
    "text": "So very briefly, we talked\nabout data quality a little bit here like guiding data\ncollection and data quality--",
    "start": "2630480",
    "end": "2637920"
  },
  {
    "text": "it's not just about diversity. You might think it\nis about diversity, you might think about\nstates diversity as a really",
    "start": "2637920",
    "end": "2643800"
  },
  {
    "text": "useful thing for high-quality\ndata because sure, if you look at human videos\nor human trajectories of doing",
    "start": "2643800",
    "end": "2651570"
  },
  {
    "text": "the task, they're going to have\nquite a bit of states diversity. And that helps because if\nyou go out of distribution,",
    "start": "2651570",
    "end": "2658980"
  },
  {
    "text": "you have a coverage\nof these states and we can help get the\nrobot back in distribution.",
    "start": "2658980",
    "end": "2664260"
  },
  {
    "text": "And if you think\nabout scripted data, scripted data is super\nclean and doesn't have as much states diversity.",
    "start": "2664260",
    "end": "2670859"
  },
  {
    "text": "And because of that, if I go\nslightly out of distribution, I'm going to have trouble\ngetting back in distribution.",
    "start": "2670860",
    "end": "2676650"
  },
  {
    "text": "So definitely, state diversity\nis a useful thing to optimize. But the second thing that\nis important is actions.",
    "start": "2676650",
    "end": "2684060"
  },
  {
    "text": "Action consistency. And again, if you\ncompare scripted data versus teleoperated data, like\nif you look at scripted data,",
    "start": "2684060",
    "end": "2692440"
  },
  {
    "text": "scripted data has a very\nhigh action consistency. All the actions are funneling\ntowards doing the same thing.",
    "start": "2692440",
    "end": "2699940"
  },
  {
    "text": "But on the other\nhand, human data is all over the place when\nit comes to the actions.",
    "start": "2699940",
    "end": "2705787"
  },
  {
    "text": "You might be in the\nsame state and you might do very different actions. And that inconsistency\nin the actions",
    "start": "2705787",
    "end": "2711700"
  },
  {
    "text": "is actually hurting your\nmodel because it introduces a lot of multi-modality,\npotentially unnecessary multi-modality\nthat we need to deal with.",
    "start": "2711700",
    "end": "2719590"
  },
  {
    "text": "So we talked about one\nway of fixing that. Guiding data collection. Another way of fixing\nthat is after the fact.",
    "start": "2719590",
    "end": "2727130"
  },
  {
    "text": "You could collect\nyour data and then you could realize what the\ndifferent modes of your data.",
    "start": "2727130",
    "end": "2732430"
  },
  {
    "text": "For example, when you\nare in a reaching mode, sparse mode versus when you're\nin a dense mode of actually",
    "start": "2732430",
    "end": "2738970"
  },
  {
    "text": "placing the square on a peg. And one thing you could\ndo is, you could actually go back in your data\nand do action relabeling",
    "start": "2738970",
    "end": "2746230"
  },
  {
    "text": "and make your actions\nmore consistent in some of these sparse modes. So this work is HYDRA.",
    "start": "2746230",
    "end": "2752363"
  },
  {
    "text": "Actually, Yuchen has been\ncontributing to this and Suneel. And in this work,\nbasically, the idea",
    "start": "2752363",
    "end": "2758590"
  },
  {
    "text": "is that you could ask\nhumans to come in and label these modes which is a\nmuch simpler thing to do. You could potentially\nautonomously",
    "start": "2758590",
    "end": "2766720"
  },
  {
    "text": "label the modes as\nwell but then you could go back and do\nthis action relabeling.",
    "start": "2766720",
    "end": "2772150"
  },
  {
    "text": "And that allows you to get\nmore bang for your buck and allows you to really be\nable to leverage your data more",
    "start": "2772150",
    "end": "2781060"
  },
  {
    "text": "effectively and make your\nactions more consistent. So just looking at a\ncouple of examples here,",
    "start": "2781060",
    "end": "2787580"
  },
  {
    "text": "we could look at very long\nhorizon tasks of making coffee. There's a long horizon task that\nhas various steps, so picking up",
    "start": "2787580",
    "end": "2795410"
  },
  {
    "text": "the pot, inserting the\npot, closing the lid, picking up the mug, placing\nthe mug, pressing the button. So you have all these\ndifferent stages",
    "start": "2795410",
    "end": "2801800"
  },
  {
    "text": "of this long-horizon task. And considering this\nlong-horizon task when you're doing action\nrelabeling using HYDRA,",
    "start": "2801800",
    "end": "2808910"
  },
  {
    "text": "we would be able\nto actually keep the performance fairly\nhigh throughout all these different\nstages as opposed",
    "start": "2808910",
    "end": "2815510"
  },
  {
    "text": "to using things like BC-RNN\nor another baseline, Viola, that very quickly goes\ndown because you go out",
    "start": "2815510",
    "end": "2820790"
  },
  {
    "text": "of distribution. We don't really know what\nto do in those scenarios. So HYDRA, in some\nsense, it's an algorithm",
    "start": "2820790",
    "end": "2827300"
  },
  {
    "text": "that is guided by data\nquality, guided by the fact that consistent\nactions are better",
    "start": "2827300",
    "end": "2832640"
  },
  {
    "text": "than not consistent actions. And you could see\na similar trend on other types of\nlong-horizon tasks",
    "start": "2832640",
    "end": "2840800"
  },
  {
    "text": "which is actually\npretty exciting. All right. So let me try to wrap up. I know I have two minutes. So kind of the key\ntakeaway here is",
    "start": "2840800",
    "end": "2849143"
  },
  {
    "text": "that when you're thinking about\npre-training these large models, we need to collect large amount\nof robot data that is, for sure,",
    "start": "2849143",
    "end": "2856010"
  },
  {
    "text": "true. I think it's a good idea to\ncollect large amounts of data but the data doesn't\nneed to come passively.",
    "start": "2856010",
    "end": "2861280"
  },
  {
    "text": "We could actually think\nabout data quality and we could think about\nguiding data collection towards useful types of data,\nmaybe action consistent ones",
    "start": "2861280",
    "end": "2869300"
  },
  {
    "text": "or maybe diverse states. But this data that is actually\nuseful, it is both about emotion",
    "start": "2869300",
    "end": "2876320"
  },
  {
    "text": "and it's also about\nthe environment. So you could think about\nthe visual environment but you could also think about\nyour actions and the motion",
    "start": "2876320",
    "end": "2881839"
  },
  {
    "text": "and how that motion\nis consistent. Or you could take that data\nand algorithmically go and make",
    "start": "2881840",
    "end": "2887180"
  },
  {
    "text": "better use of that data\nand we saw that in HYDRA as another way of\naddressing data quality.",
    "start": "2887180",
    "end": "2895010"
  },
  {
    "text": "I'm going to skip a\nnumber of slides here because I was going to\ntalk about generalization a little bit and I was going\nto talk about reinforcement",
    "start": "2895010",
    "end": "2902900"
  },
  {
    "text": "learning a little bit. But I'm going to skip those and\nI'm going to come back to this.",
    "start": "2902900",
    "end": "2908480"
  },
  {
    "text": "All right. So far, we talked about data, we\ntalked about foundation models, and then we talked about\npre-training foundation models",
    "start": "2908480",
    "end": "2915099"
  },
  {
    "text": "and we talked about adaptation. Let me just quickly mention just\nto wrap up very brief things",
    "start": "2915100",
    "end": "2925210"
  },
  {
    "text": "about the second take. That was the first take. The first take was this\nidea of pre-training. It's wonderful to\ndo pre-training.",
    "start": "2925210",
    "end": "2930257"
  },
  {
    "text": "We can get a lot out of it. We could potentially\nget generalizations that we wouldn't be\nable to get otherwise. But I think the second\ntake is also interesting",
    "start": "2930257",
    "end": "2936940"
  },
  {
    "text": "and the second take\nis the fact that we could use existing\nfoundation models like LLMs and VLMs in\ninteresting ways for robotics.",
    "start": "2936940",
    "end": "2943625"
  },
  {
    "text": "And you might say, well, what\nare those interesting ways? And we have already seen a\nnumber of works in the past year or two that are\ntrying to do that.",
    "start": "2943625",
    "end": "2950510"
  },
  {
    "text": "So an example is SayCan\nfrom folks at Google where they are using a\nfoundation model, large language",
    "start": "2950510",
    "end": "2956410"
  },
  {
    "text": "model for task planning. And I think initially, the\nfirst time I saw this work, I was very skeptical and I was\nwell, it was task planning.",
    "start": "2956410",
    "end": "2963819"
  },
  {
    "text": "The thing that we had trouble. It does feel like at\nthe end of the day, just picking up the phone\nlike the motion is difficult.",
    "start": "2963820",
    "end": "2970250"
  },
  {
    "text": "The decision of the fact that\nphone needs to be picked up is not the bottleneck. So I think, initially,\nmyself and a number",
    "start": "2970250",
    "end": "2977300"
  },
  {
    "text": "of other people in the\nfield were very skeptical of these types of works. And then we saw things\nlike Code as Policies",
    "start": "2977300",
    "end": "2983450"
  },
  {
    "text": "that was trying to get a\nlittle lower level, getting large language models\nto output robot code",
    "start": "2983450",
    "end": "2988940"
  },
  {
    "text": "but that's still limited to\nthe primitives that you have or what you have written in your\ncode in your context already.",
    "start": "2988940",
    "end": "2995930"
  },
  {
    "text": "And yeah, it doesn't really\nget at the thing that seems difficult in robotics\nbut I think over time,",
    "start": "2995930",
    "end": "3004660"
  },
  {
    "text": "I've actually changed\nmy opinion around these. And I've realized that\nthese types of approaches",
    "start": "3004660",
    "end": "3010330"
  },
  {
    "text": "open up very creative ways\nof thinking about robotics. I think before,\nI wasn't thinking",
    "start": "3010330",
    "end": "3015550"
  },
  {
    "text": "about code as the modality that\nwe should use in robot learning. I was very much thinking about\nthese transformer-based models",
    "start": "3015550",
    "end": "3022840"
  },
  {
    "text": "as the thing that robot\nlearning should do. But now, this opens up\na whole new direction,",
    "start": "3022840",
    "end": "3028210"
  },
  {
    "text": "a whole new set of\ndirections where you think about code\noutput and using LLMs to generate better\nand better robot code,",
    "start": "3028210",
    "end": "3035290"
  },
  {
    "text": "more and more\nfine-grained robot code as a way of thinking\nabout robot learning in the future of robotics.",
    "start": "3035290",
    "end": "3040510"
  },
  {
    "text": "So I'm pretty excited\nabout really creative ways that we could think\nabout using LLMs and VLMs",
    "start": "3040510",
    "end": "3046840"
  },
  {
    "text": "in this space of robotics. And over the past\nyear, we have been thinking about a number\nof different ways of using",
    "start": "3046840",
    "end": "3053110"
  },
  {
    "text": "large models,\nexisting large models within the scope of robotics. So we have looked\nat reward design",
    "start": "3053110",
    "end": "3058839"
  },
  {
    "text": "and using LLMs and VLMs\nas success detectors, as reward functions. We have thought about\nusing LLMs and VLMs",
    "start": "3058840",
    "end": "3064960"
  },
  {
    "text": "for grounded social\nreasoning, physical reasoning, spatial reasoning.",
    "start": "3064960",
    "end": "3070119"
  },
  {
    "text": "We have thought about\nsemantic manipulation like referring to object\nparts and manipulating items",
    "start": "3070120",
    "end": "3076030"
  },
  {
    "text": "based on that. And then even closing the loop\nand teaching humans, right, generating language that helps\npeople and teaches humans",
    "start": "3076030",
    "end": "3083050"
  },
  {
    "text": "doing motor control tasks. And this last one is\ndifficult to discuss, but this is work that Sudhir has\ndone which is more around not",
    "start": "3083050",
    "end": "3090850"
  },
  {
    "text": "semantics and leveraging the\nsemantics of LLMs and VLMs but more about the fact\nthat these types of models",
    "start": "3090850",
    "end": "3097270"
  },
  {
    "text": "are good at identifying\npatterns and you could use those patterns. It could be very\nabstract, but you could use those patterns for\ndownstream robotics tasks",
    "start": "3097270",
    "end": "3104560"
  },
  {
    "text": "in interesting ways. So with that, I'd like\nto actually end it here because this is--",
    "start": "3104560",
    "end": "3110140"
  },
  {
    "text": "I know I left a second\ntake very open ended but if any of these\ndirections are",
    "start": "3110140",
    "end": "3116448"
  },
  {
    "text": "things that you guys are excited\nabout, feel free to stop by. Happy to chat about any of them. And with that, I'm happy\nto take any questions.",
    "start": "3116448",
    "end": "3126830"
  },
  {
    "text": "All right. ",
    "start": "3126830",
    "end": "3134510"
  },
  {
    "text": "Yeah. I just want to make\nsure I'm understanding the low probability aspect\nof the training data.",
    "start": "3134510",
    "end": "3141080"
  },
  {
    "text": "So when you have your first\noperator execute the task, the high probability is going\nto be the most common way",
    "start": "3141080",
    "end": "3148310"
  },
  {
    "text": "they did the task. So then does your\nfirst operator set what is normal for all\nthe future operators?",
    "start": "3148310",
    "end": "3154560"
  },
  {
    "text": "Yeah. So the way we looked\nat that was actually we already had an\nexisting dataset and they were both adding,\nhonestly, to that dataset.",
    "start": "3154560",
    "end": "3160970"
  },
  {
    "text": "But you could imagine\nthat you collect a bunch of data from\nyour first operator and then everything is anchored\naround that first operator.",
    "start": "3160970",
    "end": "3167090"
  },
  {
    "text": "Like here, we want to just\nreproduce a work from Berkeley. So we had data from\nBerkeley people and then we were trying to add\nto that and it was just failing.",
    "start": "3167090",
    "end": "3174950"
  },
  {
    "text": "But yeah, you might imagine\nhaving an existing dataset and really anchoring\nthings around that",
    "start": "3174950",
    "end": "3180080"
  },
  {
    "text": "and thinking about\nwhat type of coverage your existing data has so as\nyou're collecting more data, how you could get\nbetter generalization",
    "start": "3180080",
    "end": "3186440"
  },
  {
    "text": "or how you could get better\ncoverage or state diversity given that existing dataset. ",
    "start": "3186440",
    "end": "3193830"
  },
  {
    "text": "Thank you. Good talk. Can you go back to\nthe Voltron, please? Yeah. Sure. ",
    "start": "3193830",
    "end": "3202750"
  },
  {
    "text": "Yeah. I'm curious what\nyou think are some of the next steps for bridging\nthis efficiency, maybe",
    "start": "3202750",
    "end": "3209140"
  },
  {
    "text": "task rate. You're demonstrating improvement\nbut how can we get above 90%? I know, right? Yeah.",
    "start": "3209140",
    "end": "3214750"
  },
  {
    "text": "Like better data, maybe\nusing some of the techniques you talked about or should\nwe use something like-- I think that's a great question.",
    "start": "3214750",
    "end": "3220990"
  },
  {
    "text": "And that gets at that adaptation\nphase because in general, if you think about\na single model,",
    "start": "3220990",
    "end": "3226120"
  },
  {
    "text": "that a single\nunified model that's getting all possible data,\nit's going to average them out.",
    "start": "3226120",
    "end": "3231880"
  },
  {
    "text": "It's going to be 50%,\ngoes towards the item. Sure, it's going to\nhelp it generalization. I'm excited about that.",
    "start": "3231880",
    "end": "3236920"
  },
  {
    "text": "If you add more\ndistractors, maybe it would realize that, oh,\nthese are distractors. I shouldn't pay\nattention to them but in terms of\nactually doing the task",
    "start": "3236920",
    "end": "3243309"
  },
  {
    "text": "like zero-shot or\nfew shot, it would be really hard to just\nrely on that single model. So I think adaptation\nplays a huge role",
    "start": "3243310",
    "end": "3250420"
  },
  {
    "text": "and in kind of like this second\nfollow up work, the DROID work and also that paper\ncalled like OCTO,",
    "start": "3250420",
    "end": "3257410"
  },
  {
    "text": "we are looking at\nadaptation here. So the idea is, how\ndo you do co-training?",
    "start": "3257410",
    "end": "3262819"
  },
  {
    "text": "I collect some data\nin domain and then I have this giant\nmodel and then-- what is the right balance of\nco-training that could actually",
    "start": "3262820",
    "end": "3269510"
  },
  {
    "text": "get me to a higher performance? You could imagine\ndoing RL on top of it. So OK, this is going to\nbe only 70% successful,",
    "start": "3269510",
    "end": "3277160"
  },
  {
    "text": "how do I do reinforcement\nlearning on top of it to close the loop? You could imagine doing\nin-context learning.",
    "start": "3277160",
    "end": "3282529"
  },
  {
    "text": "So we have these Gemini models\nwith 1 million contexts now. So you could imagine just like\npassing in an example in context",
    "start": "3282530",
    "end": "3291020"
  },
  {
    "text": "and getting that performance\nthrough in-context learning. So there are many\ndifferent approaches to think about adaptation.",
    "start": "3291020",
    "end": "3296960"
  },
  {
    "text": "I do think the way\nto address this is potentially\nthrough adaptation and thinking about that\nadaptation a little more",
    "start": "3296960",
    "end": "3302390"
  },
  {
    "text": "carefully. But yeah, zero-shot\nI don't expect having super high\nperformance, honestly. ",
    "start": "3302390",
    "end": "3310010"
  },
  {
    "text": "Earlier in the slide you had-- earlier in the talk,\nyou had a slide that talked about densely\nnarrated training data.",
    "start": "3310010",
    "end": "3317720"
  },
  {
    "text": "How densely narrated\nis \"densely narrated\"? So you mean for Voltron like\nthe narrations that we had?",
    "start": "3317720",
    "end": "3325022"
  },
  {
    "text": "I can't remember. It was earlier like\npretty early in the talk. Yeah. So in Voltron, for example, we\nlooked at language narrations",
    "start": "3325022",
    "end": "3331010"
  },
  {
    "text": "and these were\nexisting data sets that just talk about the\ngoal, so like \"Pick up",
    "start": "3331010",
    "end": "3336350"
  },
  {
    "text": "Coke can\" like that is\nthe level of detail. It's actually not super dense.",
    "start": "3336350",
    "end": "3341359"
  },
  {
    "text": "We had a recent work in collab-- Suneel has been working--\none of the students has been working on a recent\ncollaboration with folks",
    "start": "3341360",
    "end": "3347108"
  },
  {
    "text": "at Google where it's much\ndenser, where you're looking at not just pick up Coke can\nor pick up the microphone,",
    "start": "3347108",
    "end": "3353000"
  },
  {
    "text": "you might say move down, move\na little bit to the right, move towards the microphone. And then it turns\nout that if you",
    "start": "3353000",
    "end": "3358185"
  },
  {
    "text": "have these more detailed\nlanguage, more fine-grained language motions, you would\nbe able to get a lot more",
    "start": "3358185",
    "end": "3364580"
  },
  {
    "text": "generalization because you\nunderstand the idea of move down from this task\nand you could apply it for some other task\nthat requires move down.",
    "start": "3364580",
    "end": "3371819"
  },
  {
    "text": "So having more denser\nlanguage requires-- it's more difficult\nto get that labeling,",
    "start": "3371820",
    "end": "3377160"
  },
  {
    "text": "but it actually helps quite\na bit with generalization. ",
    "start": "3377160",
    "end": "3385000"
  }
]
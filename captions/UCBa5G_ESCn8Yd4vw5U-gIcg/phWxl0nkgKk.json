[
  {
    "start": "0",
    "end": "5880"
  },
  {
    "text": "So we spent sometimes like\ntwo months training the bots on thousands of CPUs,\nterabytes of memory sometimes.",
    "start": "5880",
    "end": "15690"
  },
  {
    "text": "But when it came\ntime to actually play against the humans, they\nwould act almost instantly. It was just a lookup table.",
    "start": "15690",
    "end": "22779"
  },
  {
    "text": "And the humans, when they\nwere in a tough spot, they would not act\ninstantly, they would think.",
    "start": "22780",
    "end": "28449"
  },
  {
    "text": "They would sit there and they\nwould think for five seconds, maybe five minutes if it was\na really difficult decision. And it was clear that was\nallowing them to come up",
    "start": "28450",
    "end": "35680"
  },
  {
    "text": "with better strategies. And so I wanted to investigate\nthis behavior in our bots.",
    "start": "35680",
    "end": "41450"
  },
  {
    "text": "If we could add this to our\nbots, how much of a difference would it make? The ability to, instead\nof acting instantly",
    "start": "41450",
    "end": "48320"
  },
  {
    "text": "to take some time and\ncompute a better strategy for the spot that\nthe agent was in.",
    "start": "48320",
    "end": "56219"
  },
  {
    "text": "And this is what I found. So on the x-axis here, we\nhave the number of buckets.",
    "start": "56220",
    "end": "61933"
  },
  {
    "text": "You can think of this\nas like the number of parameters in your model. And on the y-axis, we have\ndistance from Nash equilibrium.",
    "start": "61933",
    "end": "67210"
  },
  {
    "text": "So this is basically\nlike how much you would lose to a worst case adversary. So the lower this number is,\nthe better your poker bot is.",
    "start": "67210",
    "end": "73393"
  },
  {
    "text": "And you can see, as you scale\nup the number of parameters, your performance improves. And as you increase the number\nparameters by about 100x,",
    "start": "73393",
    "end": "81987"
  },
  {
    "text": "your exploitability\ngoes down by about half. And indeed, you're getting\na much better poker bot. But you can see,\nthe blue line here",
    "start": "81987",
    "end": "87960"
  },
  {
    "text": "is if you don't have\nsearch, and the orange line is if you do add search. And you can see,\njust adding search,",
    "start": "87960",
    "end": "93660"
  },
  {
    "text": "adding the ability to sit\nthere and think for a bit improved the performance\nof these models",
    "start": "93660",
    "end": "99299"
  },
  {
    "text": "and it reduced the\nexploitability, the distance from Nash\nequilibrium by about 7x. And if you were to extend that\nblue line and see how many",
    "start": "99300",
    "end": "107220"
  },
  {
    "text": "parameters would you need\nin order to be comparable to adding search, the answer\nis you would need to scale up",
    "start": "107220",
    "end": "114210"
  },
  {
    "text": "your model by about 100,000x. So this was pretty mind-blowing\nto me when I saw this.",
    "start": "114210",
    "end": "122310"
  },
  {
    "text": "Over the course of my PhD, the\nfirst three years, first three or four years in my PhD,\nI managed to scale up",
    "start": "122310",
    "end": "129074"
  },
  {
    "text": "these models by about 100x.  And I was proud of that.",
    "start": "129074",
    "end": "134160"
  },
  {
    "text": "I mean, that's a pretty\nimpressive result, I think. But what this plot was showing\nme was that just adding search",
    "start": "134160",
    "end": "142230"
  },
  {
    "text": "was the equivalent of scaling\nthings up by about 100,000x. And so all of my previous\nresearch up until this point",
    "start": "142230",
    "end": "147930"
  },
  {
    "text": "would just be a footnote\ncompared to adding search. So when I saw this,\nit became clear.",
    "start": "147930",
    "end": "154560"
  },
  {
    "text": "This was the answer to\nbeating top humans poker. And so for the next\nyear, basically nonstop, I worked on scaling search.",
    "start": "154560",
    "end": "161370"
  },
  {
    "text": "Now, there's a question\nthat naturally comes up, which is why wasn't\nthis considered before? There's a few factors. So first of all, I should\nsay search had been",
    "start": "161370",
    "end": "169105"
  },
  {
    "text": "considered in poker before. And it's actually quite\nnatural to say, well, if you had search\nin chess and search",
    "start": "169105",
    "end": "174930"
  },
  {
    "text": "in Go, why would you not\nconsider search in poker? There's a few reasons.",
    "start": "174930",
    "end": "180070"
  },
  {
    "text": "One is that, culturally,\nthe poker research grew out of game theory\nand reinforcement learning.",
    "start": "180070",
    "end": "185240"
  },
  {
    "text": "And so it wasn't really\nfrom the same background as the people that are working\non chess and working on Go.",
    "start": "185240",
    "end": "191370"
  },
  {
    "text": "When you scale search,\nscaling test on compute, it makes all your experiments\nmuch more expensive and just",
    "start": "191370",
    "end": "196590"
  },
  {
    "text": "more unpleasant to work with. And there were just\nincentive structures. I mean, people always\nthinking about winning",
    "start": "196590",
    "end": "202410"
  },
  {
    "text": "the next annual computer\npoker competition. And the ACPC limited\nthe resources that you could use at test time. So search wasn't really possible\neffectively in the ACPC.",
    "start": "202410",
    "end": "211557"
  },
  {
    "text": "And I think the biggest\nfactor is that people just didn't think it would make\nsuch a huge difference. I mean, I think it's\nreasonable to look at something",
    "start": "211557",
    "end": "217270"
  },
  {
    "text": "like search and think\nlike, oh, yeah, that might make a 10x difference. You probably wouldn't think\nit makes 100,000x difference.",
    "start": "217270",
    "end": "223247"
  },
  {
    "text": "And so there were some\npeople working on it, but it wasn't really the focus\nof a lot of people's research. ",
    "start": "223247",
    "end": "231030"
  },
  {
    "text": "So anyway, focused on\nscaling search, and that led to the 2017 Brains versus\nAI competition where we again",
    "start": "231030",
    "end": "237990"
  },
  {
    "text": "played our bot against\nfour top poker pros. 120,000 hands of poker,\n$200,000 in prize money.",
    "start": "237990",
    "end": "244560"
  },
  {
    "text": "And this time, the bot won\nby 15 big blinds per 100 instead of nine\nbig blinds per 100.",
    "start": "244560",
    "end": "250260"
  },
  {
    "text": "This was a crushing victory. Each team lost\nindividually to the bot and four standard deviations\nof statistical significance.",
    "start": "250260",
    "end": "261049"
  },
  {
    "text": "We followed this up in 2019\nwith a Six-Player Poker AI competition. The big difference here\nis that we figured out",
    "start": "261050",
    "end": "267560"
  },
  {
    "text": "how to do depth-limited search. So before the 2017 bot, it\nwould always have the search to the end of the game.",
    "start": "267560",
    "end": "273530"
  },
  {
    "text": "Here, it only had to do\nsearch a few moves ahead and you can stop there. And so this time, again, it won\nwith statistical significance.",
    "start": "273530",
    "end": "280588"
  },
  {
    "text": "And what's really\nsurprising about this bot is that despite it being\na much larger game,",
    "start": "280588",
    "end": "285590"
  },
  {
    "text": "the six-player poker bot\nPluribus cost under $150 to train on cloud\ncomputing resources.",
    "start": "285590",
    "end": "292430"
  },
  {
    "text": "And it runs on 28 CPU\ncores at different time. There's no GPUs. So I think what this\nshows is that this really",
    "start": "292430",
    "end": "301498"
  },
  {
    "text": "wasn't algorithmic improvement. I mean, this would have\nbeen doable 20 years ago if people knew how to do it.",
    "start": "301498",
    "end": "309560"
  },
  {
    "text": "And I think it also shows\nthe power of search. If you can figure\nout how to scale,",
    "start": "309560",
    "end": "314830"
  },
  {
    "text": "that compute at\ntest time, it really can make a huge difference and\nbring down your training costs",
    "start": "314830",
    "end": "320020"
  },
  {
    "text": "by huge amount. Anyway, so I want to say also,\nthis is not limited to poker.",
    "start": "320020",
    "end": "326320"
  },
  {
    "text": "If you look at Go, you\nsee a similar pattern. So this is a plot from\nthe AlphaGo Zero paper.",
    "start": "326320",
    "end": "331353"
  },
  {
    "text": "On the x-axis, we have\ndifferent versions of AlphaGo and on the y-axis,\nwe have Elo rating, which is a way of\ncomparing different bots",
    "start": "331353",
    "end": "336830"
  },
  {
    "text": "but also a way of\ncomparing bots to humans. And you can see, if-- ",
    "start": "336830",
    "end": "343900"
  },
  {
    "text": "so super human performance\nis around 3,600 Elo. And you can see AlphaGo\nlead the version that played",
    "start": "343900",
    "end": "348970"
  },
  {
    "text": "against Lisa Dole in 2016. That's right over the line\nof superhuman performance. AlphaGo zero, the strongest\nversion of AlphaGo,",
    "start": "348970",
    "end": "355420"
  },
  {
    "text": "is around 5200 Elo. But if you take out\nthe test time search,",
    "start": "355420",
    "end": "361180"
  },
  {
    "text": "if you just play according\nto the policy net and not do any Monte Carlo tree\nsearch in AlphaGo Zero at test",
    "start": "361180",
    "end": "367000"
  },
  {
    "text": "time, then the Elo rating\ndrops to around 3,000, which is substantially below\nexpert human performance.",
    "start": "367000",
    "end": "375070"
  },
  {
    "text": "So what this shows is that if\nyou take out Monte Carlo tree search at test time, the\nAlphaGo Zero is not superhuman.",
    "start": "375070",
    "end": "382590"
  },
  {
    "text": "And in fact, nobody\nhas made a superhuman Go bot that does not\nuse search in some form.",
    "start": "382590",
    "end": "389070"
  },
  {
    "text": "Nobody has made a\nraw neural network that can beat top humans in Go.",
    "start": "389070",
    "end": "394557"
  },
  {
    "text": "And I should say also, this\nis just if you're taking out the search at test time. I'm not even talking about\ntaking it out of training time.",
    "start": "394557",
    "end": "400250"
  },
  {
    "text": "If you took it out\nof training time, it wouldn't even\nget off the ground.  Now, there's a question\nof, OK, well, surely you",
    "start": "400250",
    "end": "407074"
  },
  {
    "text": "could just scale up\nthe model, scale up the amount of training,\nand you would eventually surpass superhuman performance\nand match the performance",
    "start": "407075",
    "end": "414340"
  },
  {
    "text": "if you added search. And that's true, yes. If you scale up the models and\nif you scale up the training,",
    "start": "414340",
    "end": "419770"
  },
  {
    "text": "then you would eventually match\nthe performance with search. But there's a\nquestion of how much would you have to\nscale it up by?",
    "start": "419770",
    "end": "425768"
  },
  {
    "text": "Now, a rough rule of\nthumb is that in order to increase your Elo\nrating by about 120 points, you either have to double\nthe amount of model size",
    "start": "425768",
    "end": "432660"
  },
  {
    "text": "and training or you have to\ndouble the amount of test time search. So if you look at that gap of\naround 2000 Elo points and you",
    "start": "432660",
    "end": "439460"
  },
  {
    "text": "calculate the number of\ndoublings that you would need, the answer is that in order\nto get the raw policy net from 3,000 to 5,200 Elo, you would\nneed to scale your model",
    "start": "439460",
    "end": "447860"
  },
  {
    "text": "and your training\nby about 100,000x.",
    "start": "447860",
    "end": "454939"
  },
  {
    "text": "So why is this important? I think you look at\nwhat's happening today with large language\nmodels and transformers",
    "start": "454940",
    "end": "461659"
  },
  {
    "text": "and you see something similar. I mean you're getting huge-- there's a question of,\nwhat do I mean by search?",
    "start": "461660",
    "end": "469100"
  },
  {
    "text": "There's specific\nkinds of search, like Monte Carlo tree search,\nthe ability to just plan ahead what you're going to do instead\nof just acting instantly based",
    "start": "469100",
    "end": "476600"
  },
  {
    "text": "on your pre-computed policy. But really, what I mean\nby search more broadly is the ability to scale\nthe amount of computation",
    "start": "476600",
    "end": "483590"
  },
  {
    "text": "to get better performance. I think that's the real\nvalue that search is adding.",
    "start": "483590",
    "end": "489020"
  },
  {
    "text": "Instead of just acting\naccording to your pre-computed-- front-loading all\nof your computation,",
    "start": "489020",
    "end": "495055"
  },
  {
    "text": "so that you're\ndoing everything-- all your computation\nahead of time and then add inference time\nacting basically instantly.",
    "start": "495055",
    "end": "502490"
  },
  {
    "text": "Could you get a\nbetter solution if you had five minutes to\noutput an action instead of 100 milliseconds?",
    "start": "502490",
    "end": "511540"
  },
  {
    "text": "So, yeah, I think you look at-- sorry, there's a question.",
    "start": "511540",
    "end": "517767"
  },
  {
    "text": "Does a transformer with a\nsearch circuit count as search or do you mean hand\nengineering search algos?",
    "start": "517767",
    "end": "523560"
  },
  {
    "text": "I don't want to get bogged\ndown into the details of how to do this because the\nanswer is nobody really knows",
    "start": "523560",
    "end": "529580"
  },
  {
    "text": "yet. Nobody really has a general\nway of doing search. In all the domains that we've\ndone search successfully, like poker and Go, it's done in\na fairly domain-specific way.",
    "start": "529580",
    "end": "539040"
  },
  {
    "text": "Go use this algorithm called\nMonte Carlo tree search. And yeah, I guess you\ncould think of beam search",
    "start": "539040",
    "end": "545430"
  },
  {
    "text": "as like one simple\nform of search. But it does seem\nlike there should be better ways in the future.",
    "start": "545430",
    "end": "554460"
  },
  {
    "text": "So anyway, where\nI'm going with this is look at how large language\nmodels are being trained today. And you're seeing\nmillions of dollars",
    "start": "554460",
    "end": "562490"
  },
  {
    "text": "being thrown at pre-training. I wouldn't be surprised\nif we see a large language",
    "start": "562490",
    "end": "569440"
  },
  {
    "text": "model that would cost\n$100 million to train. We might even get\nto $1,000,000,000.",
    "start": "569440",
    "end": "574890"
  },
  {
    "text": "But the inference cost is\nstill going to be very small. And so there's a\nquestion of, could you",
    "start": "574890",
    "end": "581390"
  },
  {
    "text": "do substantially better if\nyou could scale the amount of inference cost as well?",
    "start": "581390",
    "end": "589070"
  },
  {
    "text": "You may amortize some\nof your training cost.",
    "start": "589070",
    "end": "594230"
  },
  {
    "text": "So there's this lecture\ncalled the Bitter Lesson by Richard Sutton that says,\n\"The biggest lesson that",
    "start": "594230",
    "end": "600160"
  },
  {
    "text": "can be learned--\" and so\nit's a really great essay. I recommend reading it. But one of the big\ntakeaways is he says, \"The biggest lesson that\ncan be learned from over 70",
    "start": "600160",
    "end": "606160"
  },
  {
    "text": "years of AI research\nis that general methods that leverage computation are\nultimately the most effective. The two methods that seem to\nscale arbitrarily in this way",
    "start": "606160",
    "end": "613029"
  },
  {
    "text": "are search and learning.\" Now, I think we've done a great\njob with generalizing search--",
    "start": "613030",
    "end": "620141"
  },
  {
    "text": "sorry, generalizing learning. And I think that there is\nstill room for improvement when it comes to search. ",
    "start": "620142",
    "end": "627540"
  },
  {
    "text": "And yeah, the next goal\nreally is about generality. Can we develop a truly general\nway of scaling inference compute instead of just doing\nthings like Monte Carlo tree",
    "start": "627540",
    "end": "634589"
  },
  {
    "text": "search that are\nspecific to a better domain-- to a specific domain,\nand also better than things",
    "start": "634590",
    "end": "639720"
  },
  {
    "text": "like chain of thought?  What this would look like is\nthat you have much higher test",
    "start": "639720",
    "end": "646110"
  },
  {
    "text": "time compute. But you have much\nmore capable models. And I think for certain domains,\nthat trade off is worth it.",
    "start": "646110",
    "end": "653320"
  },
  {
    "text": "If you think about\nwhat inference cost we're willing to pay\nfor a proof of the Riemann hypothesis, I think we'd\nbe willing to pay a lot.",
    "start": "653320",
    "end": "660310"
  },
  {
    "text": "Or the cost of-- what cost are we willing to\npay for new lifesaving drugs? I think we'd be\nwilling to pay a lot.",
    "start": "660310",
    "end": "667600"
  },
  {
    "text": "So I think that there\nis an opportunity here. Anyway, so that's in prelude--",
    "start": "667600",
    "end": "673205"
  },
  {
    "text": "I guess, any\nquestions about that before I move on to Cicero? ",
    "start": "673205",
    "end": "684268"
  },
  {
    "text": "By the way, the reason\nwhy I'm talking about this is because it's going to inform\nthe approach that we took",
    "start": "684268",
    "end": "690670"
  },
  {
    "text": "to Cicero, which\nI think is quite different from the approach\nthat a lot of other researchers",
    "start": "690670",
    "end": "696940"
  },
  {
    "text": "might have taken\nto this problem. Someone asks, can you\ngive an example of search?",
    "start": "696940",
    "end": "702030"
  },
  {
    "text": "Well, Monte Carlo tree\nsearch is one form of search. You can also think of breadth\nfor search, depth for search,",
    "start": "702030",
    "end": "708303"
  },
  {
    "text": "these kinds of things. They're all search. I would also argue\nthat chain of thought is doing something\nsimilar to search",
    "start": "708303",
    "end": "715050"
  },
  {
    "text": "where it's allowing the model to\nleverage extra compute at test time to get better performance.",
    "start": "715050",
    "end": "721837"
  },
  {
    "text": "But I think that\nthat's the main thing that you want, the ability to\nleverage extra compute at test time.",
    "start": "721837",
    "end": "728000"
  },
  {
    "text": "What's the search--\nwhat's the space that you are searching over? Again, in a game like Go, it's\ndifferent board positions.",
    "start": "728000",
    "end": "734570"
  },
  {
    "text": "But you could also\nimagine searching over different sentences that\nyou could say things like that.",
    "start": "734570",
    "end": "741230"
  },
  {
    "text": " There's a lot of\nflexibility there as well. ",
    "start": "741230",
    "end": "751030"
  },
  {
    "text": "So now, I want to\nget into Cicero. So first thing I should say\nwhen it comes to Cicero, this is a big team effort.",
    "start": "751030",
    "end": "758980"
  },
  {
    "text": " This is actually one\nof the great things",
    "start": "758980",
    "end": "764720"
  },
  {
    "text": "about working on this\nproject, that there was just such a diverse talent pool\nexperts in reinforcement learning, planning, game theory,\nnatural language processing,",
    "start": "764720",
    "end": "772170"
  },
  {
    "text": "all working together on this. And it would not have been\npossible without everybody.",
    "start": "772170",
    "end": "778370"
  },
  {
    "text": "So the motivation for Diplomacy\nactually came from 2019. We were looking at\nall the breakthroughs that were happening at the time.",
    "start": "778370",
    "end": "784353"
  },
  {
    "text": "And I think a good example of\nthis XKCD comic that came out in 2012 that shows different\ncategories games, games that",
    "start": "784353",
    "end": "791380"
  },
  {
    "text": "are solved, games where\ncomputers can beat top humans, games for computers\nto lose to top humans, and games where computers\nmay never outplay top humans.",
    "start": "791380",
    "end": "797935"
  },
  {
    "text": "And in this category\nof computers to lose to top humans, you had\nfour games, Go, Arimaa, poker, and StarCraft.",
    "start": "797935",
    "end": "805699"
  },
  {
    "text": "In 2015, actually, one of\nmy colleagues, David Wu, made the first AI to beat\ntop humans in Arimaa.",
    "start": "805700",
    "end": "812790"
  },
  {
    "text": "In 2016, we have AlphaGo\nbeating Lisa Dole on Go. In 2017, you have the work\nthat I just described where",
    "start": "812790",
    "end": "818910"
  },
  {
    "text": "we beat top humans in poker. And in 2019, we had an\nAlphaStar beating expert humans",
    "start": "818910",
    "end": "826050"
  },
  {
    "text": "in StarCraft. So that shows the incredible\namount of progress that had happened in\nstrategic reasoning",
    "start": "826050",
    "end": "833430"
  },
  {
    "text": "over the past several\nyears leading up to 2019. And at the same time, we also\nhad GPT-2 come out in 2019.",
    "start": "833430",
    "end": "841350"
  },
  {
    "text": "And it showed that language\nmodel and natural language processing was\nprogressing much faster than I think a lot of people,\nincluding us, expected.",
    "start": "841350",
    "end": "848298"
  },
  {
    "text": " And so we were\nthinking about what-- after the six-player\npoker work, I",
    "start": "848298",
    "end": "854085"
  },
  {
    "text": "was discussing\nwith my colleagues what should we work on next? And we were throwing around\ndifferent domains to work on.",
    "start": "854085",
    "end": "862420"
  },
  {
    "text": "And given the incredible\namount of progress in AI, we wanted to pick\nsomething really ambitious,",
    "start": "862420",
    "end": "868000"
  },
  {
    "text": "something that we\nthought you couldn't just tackle by scaling up\nexisting approaches, that you really needed something\nnew in order to address.",
    "start": "868000",
    "end": "875890"
  },
  {
    "text": "And we landed on\nDiplomacy because we thought that it would be the\nhardest game to make an AI for.",
    "start": "875890",
    "end": "881879"
  },
  {
    "text": "So what is Diplomacy? Diplomacy is a natural\nlanguage strategy game.",
    "start": "881880",
    "end": "887790"
  },
  {
    "text": "It takes place right\nbefore World War I. You play as one of the seven\ngreat powers of Europe,",
    "start": "887790",
    "end": "893100"
  },
  {
    "text": "England, France, Germany,\nAustria, Russia, and Turkey. And your goal is to control\nthe majority of the map.",
    "start": "893100",
    "end": "899700"
  },
  {
    "text": "In practice that\nrarely happens, if you control a majority of\nthe map then you've won, in practice, nobody\nends up winning outright.",
    "start": "899700",
    "end": "908610"
  },
  {
    "text": "And so your score is\nproportional to the percentage of the map that you control.",
    "start": "908610",
    "end": "914540"
  },
  {
    "text": "Now, what's really\ninteresting about Diplomacy is that it is a natural\nlanguage negotiation game.",
    "start": "914540",
    "end": "920518"
  },
  {
    "text": "So you have these conversations,\nlike what you're seeing here between Germany and England\nwhere they will privately communicate with each other\nbefore making their moves.",
    "start": "920518",
    "end": "927470"
  },
  {
    "text": "And so you can have Germany\nask, want to support Sweden? England says, let me\nthink on that, and so on.",
    "start": "927470",
    "end": "935830"
  },
  {
    "text": "So this is a popular strategy\ngame developed in the 1950s. It was JFK and Kissinger's\nfavorite game actually.",
    "start": "935830",
    "end": "944090"
  },
  {
    "text": "And like I said,\neach turn involves sophisticated private natural\nlanguage negotiations. And I want to make clear,\nthis is not negotiations",
    "start": "944090",
    "end": "953013"
  },
  {
    "text": "like you would see in a\ngame like Settlers of Catan, for example. You're seeing-- it's\nmuch more like Survivor,",
    "start": "953013",
    "end": "961029"
  },
  {
    "text": "if you've ever seen\nthe TV show Survivor. You have discussions\naround alliances",
    "start": "961030",
    "end": "966160"
  },
  {
    "text": "that you'd like to\nbuild, discussions around specific\ntactics that you'd like to execute on the current\nturn, and also more long-term",
    "start": "966160",
    "end": "974500"
  },
  {
    "text": "strategy around where\ndo we go from here and how do we divide resources.",
    "start": "974500",
    "end": "979570"
  },
  {
    "text": "Now, the way the game works,\nyou have these negotiations that lasts between 5 and\n15 minutes, depending",
    "start": "979570",
    "end": "984960"
  },
  {
    "text": "on the version of the\ngame on each turn. And all these negotiations\nare done privately,",
    "start": "984960",
    "end": "990570"
  },
  {
    "text": "pairwise negotiation. Also, I think that\nyou are not muted. Thank you.",
    "start": "990570",
    "end": "996779"
  },
  {
    "text": "And then after the\nnegotiation period completes, everybody will simultaneously\nwrite down their moves.",
    "start": "996780",
    "end": "1001787"
  },
  {
    "text": "And so a player could\npromise you something like, I'm going to support you into\nthis territory in this turn.",
    "start": "1001788",
    "end": "1006842"
  },
  {
    "text": "But then when people actually\nwrite down their moves, they might not write that down. And so you only find out if\nthey were true to their word",
    "start": "1006842",
    "end": "1012769"
  },
  {
    "text": "when all the moves are\nrevealed simultaneously. ",
    "start": "1012770",
    "end": "1018540"
  },
  {
    "text": "And so for this reason,\nalliances and trust-building is key, the ability\nto trust that somebody",
    "start": "1018540",
    "end": "1023954"
  },
  {
    "text": "is going to follow\nthrough on their promises. That's really what\nthis game is all about. And the ability\nto convince people",
    "start": "1023954",
    "end": "1029131"
  },
  {
    "text": "that you are going to follow\nthrough on your promises is really what this\ngame is all about.",
    "start": "1029131",
    "end": "1034910"
  },
  {
    "text": "And so for this\nreason, Diplomacy has long been considered a\nchallenge problem for AI. This research and the game\ngoing back to the 80s,",
    "start": "1034910",
    "end": "1040991"
  },
  {
    "text": "the research really\nonly picked up-- it picked up quite\nintensely starting in 2019",
    "start": "1040992",
    "end": "1047089"
  },
  {
    "text": "when researchers from DeepMind,\nourselves, Mila, other places started working on this.",
    "start": "1047089",
    "end": "1053539"
  },
  {
    "text": "Now, a lot of that research-- the vast majority\nof that research actually was focused on\nthe non-language version",
    "start": "1053540",
    "end": "1058820"
  },
  {
    "text": "of the game, which was\nseen as a stepping stone to the full natural\nlanguage version. Though we decided to\nfocus from the start",
    "start": "1058820",
    "end": "1064520"
  },
  {
    "text": "on the full natural language\nversion of the game. So to give you a sense of what\nthese negotiations and dialogue",
    "start": "1064520",
    "end": "1072179"
  },
  {
    "text": "look like, here is one example. So here, England, you can\nsee they move their fleet",
    "start": "1072180",
    "end": "1079920"
  },
  {
    "text": "in Norway to Saint Petersburg. And that occupies the\nRussian territory.",
    "start": "1079920",
    "end": "1085590"
  },
  {
    "text": "And so this is what\nthe border state looks like after that move. And now, there's\nthis conversation between Austria and Russia.",
    "start": "1085590",
    "end": "1091350"
  },
  {
    "text": "Austria says, well,\nwhat happened up North? Russia says, England stabbed. I'm afraid that they may\nbe closer to me, my friend.",
    "start": "1091350",
    "end": "1097110"
  },
  {
    "text": "Austria says,\nyeah, that's rough. Are you going to be OK up there? Russia says, I hope so. England seems to still\nwant to work together.",
    "start": "1097110",
    "end": "1102272"
  },
  {
    "text": "Austria says, can you\nmake a deal with Germany? So the players\nare now discussing what should be discussed\nwith other players.",
    "start": "1102272",
    "end": "1108929"
  },
  {
    "text": "Russia says, good idea. Then Austria says,\nyou'll be fine as long as you can defend Sevastopol. So Sevastopol is this\nterritory down to the South.",
    "start": "1108930",
    "end": "1115170"
  },
  {
    "text": "You can see that Turkey has a\nfleet and an army in the Black Sea in Armenia\nnext to Sevastopol.",
    "start": "1115170",
    "end": "1121140"
  },
  {
    "text": "And so they could potentially\nattack that territory next turn.",
    "start": "1121140",
    "end": "1126755"
  },
  {
    "text": "Austria says, can you\nsupport hold Sevastopol with Ukraine and Romania? I'll support hold Romania. Russia says, yep,\nI'm already doing so.",
    "start": "1126755",
    "end": "1132950"
  },
  {
    "text": "Austria says, awesome. Hopefully, we can start\ngetting you back on your feet. So this is an example of\nthe kinds of conversations",
    "start": "1132950",
    "end": "1139180"
  },
  {
    "text": "that you'll see in\na game of Diplomacy. In this conversation, Austria\nis actually our bot Cicero.",
    "start": "1139180",
    "end": "1145010"
  },
  {
    "text": "So that kind of gives you a\nsense of the sophistication of the agents dialogue. ",
    "start": "1145010",
    "end": "1154920"
  },
  {
    "text": "OK, I'll skip this for-- so I guess I'll go into this. I don't want to take\nup too much time.",
    "start": "1154920",
    "end": "1160183"
  },
  {
    "text": "Really, what makes\ndiplomacy interesting is that support is key. So here, for example,\nBudapest and Warsaw, the red",
    "start": "1160183",
    "end": "1167285"
  },
  {
    "text": "and the purple units both\ntry to move into Galicia. And so since it's\na one versus one, they both bounced\nback and neither",
    "start": "1167285",
    "end": "1172590"
  },
  {
    "text": "moves into the territory. In the middle panel, you can\nsee Vienna supports Budapest into Galicia.",
    "start": "1172590",
    "end": "1177630"
  },
  {
    "text": "And so now, it's\na two versus one. And that red unit will\nindeed enter Galicia.",
    "start": "1177630",
    "end": "1183075"
  },
  {
    "text": "And what's really\ninteresting about Diplomacy is that it doesn't just have\nto be your own units that are supporting you, it could be\nanother player's units as well.",
    "start": "1183075",
    "end": "1190120"
  },
  {
    "text": "So for example, the green player\ncould support the red player into Galicia, and then that red\nunit would still go in there.",
    "start": "1190120",
    "end": "1196990"
  },
  {
    "text": "So support is really what\nthe game is all about, and negotiating over support. And so for that\nreason, Diplomacy",
    "start": "1196990",
    "end": "1202490"
  },
  {
    "text": "has this reputation as the\ngame that ruins friendships. It's really difficult to have\nan alliance with somebody",
    "start": "1202490",
    "end": "1207590"
  },
  {
    "text": "for three or four hours and\nthen have them backstab you, and basically just\nruin your game.",
    "start": "1207590",
    "end": "1214710"
  },
  {
    "text": "But if you talk to\nexpert Diplomacy players, they view it differently. They say diplomacy is\nultimately about building trust",
    "start": "1214710",
    "end": "1220680"
  },
  {
    "text": "in an environment that\nencourages you to not trust anyone. And that's why we decided\nto work on the game.",
    "start": "1220680",
    "end": "1226470"
  },
  {
    "text": "Could we make an AI that\nis able to build trust with the players in an\nenvironment that encourages them to not trust anybody?",
    "start": "1226470",
    "end": "1233010"
  },
  {
    "text": "Can the bot honestly\ncommunicate that it's going to do something\nand evaluate",
    "start": "1233010",
    "end": "1239228"
  },
  {
    "text": "whether another person\nis being honest when they are saying that they're\ngoing to do something? ",
    "start": "1239228",
    "end": "1245970"
  },
  {
    "text": "So why Diplomacy? It's this nice intersection\nof reinforcement learning and planning,\nand also natural language.",
    "start": "1245970",
    "end": "1253200"
  },
  {
    "text": "There's two perspectives that\nwe can take on why Diplomacy is a really interesting domain. One is the multi-agent\nperspective.",
    "start": "1253200",
    "end": "1259270"
  },
  {
    "text": "So here, all the previous\ngaming AI results, like chess, Go,\npoker, these have all",
    "start": "1259270",
    "end": "1265920"
  },
  {
    "text": "been in purely zero sum-- two-player zero-sum domains. And in these\ndomains, self-play is",
    "start": "1265920",
    "end": "1272610"
  },
  {
    "text": "guaranteed to converge\nto an optimal solution. Basically, what\nthis means is you can start having the bot\nplay completely from scratch",
    "start": "1272610",
    "end": "1278460"
  },
  {
    "text": "with no human data. And by playing against\nitself repeatedly, it will eventually converge\nto this unbeatable optimal",
    "start": "1278460",
    "end": "1284790"
  },
  {
    "text": "solution called the\nMinimax equilibrium. But that result only holds\nin two-player zero-sum games.",
    "start": "1284790",
    "end": "1290280"
  },
  {
    "text": "That whole paradigm only holds\nin two-player zero-sum games. When you go to domains\nthat involve cooperation,",
    "start": "1290280",
    "end": "1296500"
  },
  {
    "text": "in addition to\ncompetition, then success requires understanding human\nbehavior and conventions.",
    "start": "1296500",
    "end": "1301659"
  },
  {
    "text": "You can't just treat the other\nplayers like machines anymore. You have to treat\nthem like humans.",
    "start": "1301660",
    "end": "1306940"
  },
  {
    "text": "You have to model\nhuman irrationality, human suboptimality. One example of this\nis actually language.",
    "start": "1306940",
    "end": "1315072"
  },
  {
    "text": "You can imagine if you were\nto train a bot completely from scratch in the\ngame of Diplomacy, the full natural language\nversion of the game,",
    "start": "1315072",
    "end": "1321490"
  },
  {
    "text": "there's no reason why\nthe bot would learn to communicate in English. It would learn to communicate\nin some weird gibberish robot",
    "start": "1321490",
    "end": "1326971"
  },
  {
    "text": "language. And then when you stick it\nin a game with six humans, it's not going to be able\nto cooperate with them. ",
    "start": "1326972",
    "end": "1335570"
  },
  {
    "text": "So we have to find a way\nto incorporate human data and be able to learn how\nhumans behave in order",
    "start": "1335570",
    "end": "1341200"
  },
  {
    "text": "to succeed in this game. ",
    "start": "1341200",
    "end": "1347580"
  },
  {
    "text": "There's also the\nNLP perspective, which is that current language\nmodels are essentially",
    "start": "1347580",
    "end": "1352830"
  },
  {
    "text": "just imitating human-like text. Now, there's been some\nprogress with things like RLHF.",
    "start": "1352830",
    "end": "1358020"
  },
  {
    "text": "But that's still not really the\nway that humans communicate. They communicate with\nan intention in mind.",
    "start": "1358020",
    "end": "1364320"
  },
  {
    "text": "They come up with this\nintention and then they communicate with\nthe goal of communicating that intention. And they understand that others\nare trying to do the same.",
    "start": "1364320",
    "end": "1371289"
  },
  {
    "text": "And so there's a\nquestion of, can we move beyond chitchat to\ngrounded intentional dialogue?",
    "start": "1371290",
    "end": "1377320"
  },
  {
    "text": " So Cicero is an AI\nagent for Diplomacy",
    "start": "1377320",
    "end": "1383620"
  },
  {
    "text": "that integrates high level\nstrategic play and open domain dialogue. And we use 50,000 human\ngames of Diplomacy",
    "start": "1383620",
    "end": "1389380"
  },
  {
    "text": "acquired through a\npartnership with the website webdiplomacy.net. So we entered Cicero in an\nonline diplomacy league,",
    "start": "1389380",
    "end": "1396940"
  },
  {
    "text": "just to give you the\nresults up front. Cicero was not\ndetected as an AI agent for 40 games with\n82 unique players.",
    "start": "1396940",
    "end": "1403840"
  },
  {
    "text": "There was one player that\nmentioned after the fact that-- they kind of made a joke\nabout us being a bot.",
    "start": "1403840",
    "end": "1410657"
  },
  {
    "text": "But they didn't\nreally follow up on it and nobody else\nfollowed up on it. And they later accused somebody\nelse of also being a bot.",
    "start": "1410657",
    "end": "1415825"
  },
  {
    "text": "So we weren't sure how seriously\nto take that accusation. But I think it's safe to say\nit made it through all 40 games without being detected as bot.",
    "start": "1415825",
    "end": "1422559"
  },
  {
    "text": "And then in fact, when we\ntold the players afterwards that it was a bot\nthe whole time, these are the kinds of\nresponses that we got.",
    "start": "1422560",
    "end": "1429519"
  },
  {
    "text": "People were quite surprised,\npleasantly surprised, fortunately. Nobody was upset with us.",
    "start": "1429520",
    "end": "1435490"
  },
  {
    "text": "But they were quite\nsurprised that there was a bot that had\nbeen playing this game within the whole time.",
    "start": "1435490",
    "end": "1442960"
  },
  {
    "text": "So in terms of\nresults, Cicero placed in the top 10% of players. It's a high variance game.",
    "start": "1442960",
    "end": "1448659"
  },
  {
    "text": "And so if you look at players\nthat played five or more games, it placed 2nd out of 19. And it achieved more than\ndouble the average human score.",
    "start": "1448660",
    "end": "1456470"
  },
  {
    "text": "So I would describe\nthis as a strong level of human performance. I wouldn't go as far as to\nsay that this is superhuman,",
    "start": "1456470",
    "end": "1462260"
  },
  {
    "text": "by any means. But it is currently\nquite a strong result.",
    "start": "1462260",
    "end": "1470540"
  },
  {
    "text": "Now, to give you a picture\nof how Cicero works. So the input that we\nfeed into the model",
    "start": "1470540",
    "end": "1479150"
  },
  {
    "text": "is the board state and\nthe recent action history. That's shown at\nthe top left here, and also the dialogue that it's\nhad with all the players up",
    "start": "1479150",
    "end": "1486830"
  },
  {
    "text": "until now. So that's going to get fed into\na dialogue conditional action",
    "start": "1486830",
    "end": "1492260"
  },
  {
    "text": "model that's going to\npredict what Cicero thinks all the players are\ngoing to do this turn",
    "start": "1492260",
    "end": "1498620"
  },
  {
    "text": "and what they think\nwe will do this turn. ",
    "start": "1498620",
    "end": "1505870"
  },
  {
    "text": "These leads what we call\nanchor policies that are then used for planning. ",
    "start": "1505870",
    "end": "1513790"
  },
  {
    "text": "Now, planning here,\nagain, this is like the part where we leverage\nextra compute at test time",
    "start": "1513790",
    "end": "1521200"
  },
  {
    "text": "in order to get\nbetter performance. So essentially, we take\nthese initial predictions of what everybody's\ngoing to do, what",
    "start": "1521200",
    "end": "1526492"
  },
  {
    "text": "are called anchor policies. And we improve upon these\npredictions using this planning",
    "start": "1526492",
    "end": "1532300"
  },
  {
    "text": "process called piKL,\nwhere basically we account for the fact\nthat players will pick",
    "start": "1532300",
    "end": "1538025"
  },
  {
    "text": "actions that have\nhigher expected value with higher probability. We're essentially adding\nthis rationality prior",
    "start": "1538025",
    "end": "1543250"
  },
  {
    "text": "to all the players to\nassume that they're not going to blunder as often\nas the model might suggest, and they're going to pick\nsmarter actions with higher",
    "start": "1543250",
    "end": "1550060"
  },
  {
    "text": "probability than the\ninitial model might suggest. And what we find is that\nthis actually gives us a better prediction of\nwhat all the players will",
    "start": "1550060",
    "end": "1556419"
  },
  {
    "text": "do than just relying on\nthe raw neural net itself. ",
    "start": "1556420",
    "end": "1563450"
  },
  {
    "text": "This gives us the action that\nwe actually play in the game. And it also gives us\nwhat we call \"intense.\"",
    "start": "1563450",
    "end": "1569420"
  },
  {
    "text": "So intense are an\naction for ourselves and an action for the dialogue\npartner that we're speaking to.",
    "start": "1569420",
    "end": "1574910"
  },
  {
    "text": "And now, we have this\ndialogue conditional-- so we have this dialogue\nmodel that conditions on these",
    "start": "1574910",
    "end": "1580620"
  },
  {
    "text": "\"intense.\" So the intense are fed into\nthe dialogue model along with the board state and action\nhistory, and also the dialogue",
    "start": "1580620",
    "end": "1587210"
  },
  {
    "text": "that we've had so far. And that dialogue\nmodel will then generate candidate\nmessages that our",
    "start": "1587210",
    "end": "1594760"
  },
  {
    "text": "conditioned on those intense. These candidate messages\ngo through a series of filters that\nfilter out nonsense,",
    "start": "1594760",
    "end": "1601680"
  },
  {
    "text": "grounding issues, and also\nlow expected value action-- low expected value messages. And ultimately, we\nget out a message",
    "start": "1601680",
    "end": "1608700"
  },
  {
    "text": "to send to our dialogue partner. Now, every time we send\nor receive a message,",
    "start": "1608700",
    "end": "1614060"
  },
  {
    "text": "we will repeat\nthis whole process. ",
    "start": "1614060",
    "end": "1619870"
  },
  {
    "text": "So there's actually a lot\nthat is quite novel in Cicero. And I'm going to try to\ntalk about the contributions",
    "start": "1619870",
    "end": "1627667"
  },
  {
    "text": "as much as possible. I might go through\nthis a little quickly. So we have time for questions.",
    "start": "1627667",
    "end": "1632673"
  },
  {
    "text": "The first one is a\ncontrollable dialogue model that conditions\non the game state and a set of intended\nactions for the speaker",
    "start": "1632673",
    "end": "1638250"
  },
  {
    "text": "and the recipient.  So I have a question,\nwhat is the action",
    "start": "1638250",
    "end": "1644223"
  },
  {
    "text": "space here for the model?  The action space for the\naction prediction model",
    "start": "1644223",
    "end": "1652190"
  },
  {
    "text": "is like all the actions that\nyou could take in the game-- that a player could\ntake in the game. For the dialogue model,\nit's like messages",
    "start": "1652190",
    "end": "1658790"
  },
  {
    "text": "that you can send. Got it. So-- one second. ",
    "start": "1658790",
    "end": "1667420"
  },
  {
    "text": "OK. So we train what we call\nan intent model that predicts what actions\npeople will take",
    "start": "1667420",
    "end": "1673649"
  },
  {
    "text": "at the end of truthful turns. Basically, what we're trying\nto predict, what are people intending to do when they\ncommunicate a certain message?",
    "start": "1673650",
    "end": "1683409"
  },
  {
    "text": "And then we use this to\nautomatically annotate the data set with\nbasically what we",
    "start": "1683410",
    "end": "1689470"
  },
  {
    "text": "expect people's intentions were\nwhen they sent that message. And we filter out--",
    "start": "1689470",
    "end": "1695753"
  },
  {
    "text": "we filter out as much as\npossible lies from the data set, so that the\ntext of the data set",
    "start": "1695753",
    "end": "1702180"
  },
  {
    "text": "is annotated with the\ntruthful intention. ",
    "start": "1702180",
    "end": "1709070"
  },
  {
    "text": "And then during play, Cicero\nconditions the dialogue model on the truthful intention\nthat it intends to take.",
    "start": "1709070",
    "end": "1714500"
  },
  {
    "text": "And the goal then is\nthat-- the hope then is that it will\ngenerate a message consistent with that intention.",
    "start": "1714500",
    "end": "1721280"
  },
  {
    "text": "And that is then fed\ninto everything else.",
    "start": "1721280",
    "end": "1726620"
  },
  {
    "text": "Sorry, the intentions that\nwe generate through planning are fed into the dialogue model. ",
    "start": "1726620",
    "end": "1734780"
  },
  {
    "text": "So to give you an example\nof what this looks like, this gives us a way to\ncontrol the dialogue model",
    "start": "1734780",
    "end": "1739940"
  },
  {
    "text": "through a set of intentions. Here, we are-- Cicero\nis England in pink",
    "start": "1739940",
    "end": "1747590"
  },
  {
    "text": "and their action is to move to\nBelgium, among other things. ",
    "start": "1747590",
    "end": "1752915"
  },
  {
    "text": "And so, if we feed this\nintention into the dialogue model, then the message\nthat might get generated is something like\nEngland saying to France,",
    "start": "1752915",
    "end": "1759570"
  },
  {
    "text": "do you mind supporting me-- do you mind supporting\nEdi to Belgium? ",
    "start": "1759570",
    "end": "1765690"
  },
  {
    "text": "On the other hand, let's\nsay Cicero's action is to support France into Belgium.",
    "start": "1765690",
    "end": "1773600"
  },
  {
    "text": "Then if you feed that\ninto the dialogue model, then the message\nthat's generated might say something like,\nlet me know if you want",
    "start": "1773600",
    "end": "1779570"
  },
  {
    "text": "me to support you to Belgium. Otherwise, I'll\nprobably poke Holland. ",
    "start": "1779570",
    "end": "1786470"
  },
  {
    "text": "Now, what we find is that\nconditioning the dialogue model on these\nintentions in this way, it makes the model\nmore controllable,",
    "start": "1786470",
    "end": "1792362"
  },
  {
    "text": "but it also leads\nto higher quality dialogue with less nonsense. So we found that\nit led to dialogue",
    "start": "1792362",
    "end": "1798333"
  },
  {
    "text": "that was more consistent\nwith the state, more consistent with the\nplan, higher quality, lower perplexity.",
    "start": "1798333",
    "end": "1803510"
  },
  {
    "text": "And I think the argument--\nthe reasoning for why this is the case is\nthat we're kind of we're leaving the dialogue model the\nburden of having to come up",
    "start": "1803510",
    "end": "1811430"
  },
  {
    "text": "with a good strategy. We're allowing\nthe dialogue model to do what it does best,\nto focus on what it",
    "start": "1811430",
    "end": "1817193"
  },
  {
    "text": "does best, which is dialogue. And we're relieving it of\nthe strategic components",
    "start": "1817193",
    "end": "1823280"
  },
  {
    "text": "of the game. Because we're feeding that\nstrategy into the dialogue model. ",
    "start": "1823280",
    "end": "1831038"
  },
  {
    "text": "So that's one main\ncontribution, this control the dialogue model\nthat conditions on a plan.",
    "start": "1831038",
    "end": "1836720"
  },
  {
    "text": "The second is a\nplanning engine that accounts for dialogue\nand human behavior. ",
    "start": "1836720",
    "end": "1843000"
  },
  {
    "text": "So I mentioned that a lot\nof previous work on games",
    "start": "1843000",
    "end": "1849270"
  },
  {
    "text": "was done using self-play in\ntwo-player zero-sum settings.",
    "start": "1849270",
    "end": "1854640"
  },
  {
    "text": "Now, the problem\nwith pure self-play is that it can learn\nstrong policies",
    "start": "1854640",
    "end": "1860250"
  },
  {
    "text": "but it doesn't stick\nwith human conventions, and it can't account\nfor dialogue. It's just going to ignore the\nhuman data and the human way",
    "start": "1860250",
    "end": "1868170"
  },
  {
    "text": "of playing if you\njust do self-play. So that's one extreme.",
    "start": "1868170",
    "end": "1874299"
  },
  {
    "text": "The other extreme\nthat you can go is to just do supervised\nlearning on human data,",
    "start": "1874300",
    "end": "1879990"
  },
  {
    "text": "create this model\nof how humans play, and then train with\nthose imitation humans.",
    "start": "1879990",
    "end": "1888380"
  },
  {
    "text": "And if you do\nthis, you'll end up with a bot that's\nconsistent with dialogue and human conventions. But it's only as strong\nas the training data.",
    "start": "1888380",
    "end": "1895640"
  },
  {
    "text": "And we found that\nit was actually very easily manipulable\nthrough adversarial dialogue.",
    "start": "1895640",
    "end": "1900919"
  },
  {
    "text": "So for example, you can\nsend messages to it saying, thanks for agreeing to\nsupport me at the Paris. And it will think\nlike, well, I've",
    "start": "1900920",
    "end": "1908360"
  },
  {
    "text": "only ever seen that\nmessage in my training data when I've agreed to support\nthe person to the Paris. And so I guess I'm supporting\nthem at the Paris this turn,",
    "start": "1908360",
    "end": "1915047"
  },
  {
    "text": "even though that might be a\nterrible move for the bot.  So I came up with this\nalgorithm called piKL",
    "start": "1915047",
    "end": "1921670"
  },
  {
    "text": "that it kind of is a happy\nmedium between these two extremes. ",
    "start": "1921670",
    "end": "1928290"
  },
  {
    "text": "The way piKL works is it's\nbasically trying to-- it's",
    "start": "1928290",
    "end": "1933570"
  },
  {
    "text": "doing self-play but\nregularized toward sticking to the human imitation policy.",
    "start": "1933570",
    "end": "1940110"
  },
  {
    "text": "So it has a KL\npenalty for deviating from the human imitation policy.",
    "start": "1940110",
    "end": "1947370"
  },
  {
    "text": "So we have this\nparameter lambda that controls how easy\nit is to deviate",
    "start": "1947370",
    "end": "1953550"
  },
  {
    "text": "from the human\ninvitation policy. At lambda equals zero, it just\nignores the human imitation",
    "start": "1953550",
    "end": "1960810"
  },
  {
    "text": "policy completely and\njust does pure self-play. And so it just do self-play\nas if from scratch",
    "start": "1960810",
    "end": "1967529"
  },
  {
    "text": "at lambda equals zero. At lambda equals\ninfinity, it's just playing the human\ninvitation policy",
    "start": "1967530",
    "end": "1973140"
  },
  {
    "text": "and not doing self-play at all. But for intermediate values\nof lambda, what we find",
    "start": "1973140",
    "end": "1979360"
  },
  {
    "text": "is that it actually\ngives you a good medium between sticking to\nhuman conventions and performing strongly.",
    "start": "1979360",
    "end": "1984940"
  },
  {
    "text": " So you can kind of see\nthis behavior emerge here.",
    "start": "1984940",
    "end": "1991080"
  },
  {
    "text": " So there's a question. Is this similar to offline RL or\nalso incorporates exploration?",
    "start": "1991080",
    "end": "1998179"
  },
  {
    "text": "So let's say, there's\nactually a lot of similar work on\nhaving a KL penalty.",
    "start": "1998180",
    "end": "2005170"
  },
  {
    "text": "And so yes, I would\nsay that it's very similar to a lot of that work. It's also been done\nactually in AlphaStar",
    "start": "2005170",
    "end": "2011740"
  },
  {
    "text": "where they had a KL penalty. Though that was more\nabout aiding exploration, like using human data\nto aid exploration,",
    "start": "2011740",
    "end": "2018429"
  },
  {
    "text": "rather than trying to\nbetter imitate humans. So I think what's interesting\nabout the piKL work",
    "start": "2018430",
    "end": "2023440"
  },
  {
    "text": "is that, one, we\nfind it imitates humans better than just doing\nsupervised learning alone.",
    "start": "2023440",
    "end": "2028990"
  },
  {
    "text": "And two, we are doing\na bit of theory of mind where we assume that the\nother players are also--",
    "start": "2028990",
    "end": "2036840"
  },
  {
    "text": "we're using this as a model for\nour behavior, what we expect other people to\nthink our behavior",
    "start": "2036840",
    "end": "2042059"
  },
  {
    "text": "is in addition to modeling\nthe other players. So it's like a\ncommon knowledge--",
    "start": "2042060",
    "end": "2049429"
  },
  {
    "text": "common knowledge\nlike an algorithm that we're using here. ",
    "start": "2049429",
    "end": "2057829"
  },
  {
    "text": "So the kind of behavior\nthat you see from this, you can see here, let's\nsay England agrees--",
    "start": "2057830",
    "end": "2063199"
  },
  {
    "text": "sorry, so let's say\nwe're in this situation. This actually came\nup in a real game. And it inspired a\nfigure from our paper.",
    "start": "2063199",
    "end": "2070960"
  },
  {
    "text": "So England and\nFrance are fighting. France is the bot.",
    "start": "2070960",
    "end": "2076119"
  },
  {
    "text": "And France asks if England\nis willing to disengage.",
    "start": "2076120",
    "end": "2082030"
  },
  {
    "text": "And let's say\nEngland says, yes, I will move out of English\nchannel if you head back to NAO.",
    "start": "2082030",
    "end": "2088440"
  },
  {
    "text": "Well, we can see that Cicero\ndoes in fact back off, leaves--",
    "start": "2088440",
    "end": "2093750"
  },
  {
    "text": "goes to NAO, and the\ndisengagement is successful. And so this shows that\nthe bot strategy really",
    "start": "2093750",
    "end": "2099720"
  },
  {
    "text": "is reflecting the\ndialogue that it's had with this other player. ",
    "start": "2099720",
    "end": "2105450"
  },
  {
    "text": "Another message that\nEngland might send is something like,\nI'm sorry, you've been fighting me\nthis whole game. I can't trust you that\nyou won't stab me.",
    "start": "2105450",
    "end": "2112289"
  },
  {
    "text": "And so in this case, Cicero will\ncontinue its attack on England. And you can see again,\nthis is reflective-- it's",
    "start": "2112290",
    "end": "2117960"
  },
  {
    "text": "changing its behavior\ndepending on the dialogue.  But you can also have\nthis kind of message",
    "start": "2117960",
    "end": "2124160"
  },
  {
    "text": "where England, says,\nyes, I'll leave English channel if you move into\nMunich and Holland to Belgium.",
    "start": "2124160",
    "end": "2129180"
  },
  {
    "text": "So these are really bad\nmoves for Cicero to follow. And so if you just use-- if\nyou just look at the raw policy",
    "start": "2129180",
    "end": "2136760"
  },
  {
    "text": "net, it might actually do this. It might actually do these moves\nbecause England suggested it.",
    "start": "2136760",
    "end": "2143960"
  },
  {
    "text": "But because we're using\npiKL that incorporates-- it counts for these expected\nvalue different actions,",
    "start": "2143960",
    "end": "2149030"
  },
  {
    "text": "it will actually partially\nback off but ignore the suggested moves\nbecause it recognize that those will leave it\nvery vulnerable to an attack.",
    "start": "2149030",
    "end": "2155705"
  },
  {
    "start": "2155705",
    "end": "2160942"
  },
  {
    "text": "I'll skip the slide for time. ",
    "start": "2160942",
    "end": "2168829"
  },
  {
    "text": "Another thing I should\nsay is that we're not just doing planning. We're actually doing this in\na full self-play reinforcement",
    "start": "2168830",
    "end": "2174248"
  },
  {
    "text": "learning loop. And again, the goal here is--",
    "start": "2174248",
    "end": "2179380"
  },
  {
    "text": "it's really about modeling\nhumans better than supervised learning alone. And we found that doing\nthis self-play reinforcement",
    "start": "2179380",
    "end": "2184397"
  },
  {
    "text": "learning with piKL allowed us\nto better model human behavior than just doing\nimitation learning.",
    "start": "2184397",
    "end": "2189430"
  },
  {
    "text": " Finally, we have an ensemble\nof message filtering techniques",
    "start": "2189430",
    "end": "2194550"
  },
  {
    "text": "that filters both nonsensical\nand strategically unsound messages. ",
    "start": "2194550",
    "end": "2199840"
  },
  {
    "text": "So to give you an example of\nwhat these filters look like, one that we developed is\nvalue-based filtering.",
    "start": "2199840",
    "end": "2205520"
  },
  {
    "text": "So the motivation\nfor this is that what we feed into our\ndialogue model is",
    "start": "2205520",
    "end": "2211920"
  },
  {
    "text": "a plan for ourselves and\nfor our speaking partner, but it's the entire plan\nthat we have for ourselves.",
    "start": "2211920",
    "end": "2218290"
  },
  {
    "text": "And so we might end up feeding\ninto the dialogue model the fact that we're going to\nattack the player that we're speaking to.",
    "start": "2218290",
    "end": "2224460"
  },
  {
    "text": "Now, the dialogue model is,\nto be honest, kind of dumb. And it doesn't really\nknow that it shouldn't",
    "start": "2224460",
    "end": "2231180"
  },
  {
    "text": "be telling this\nplayer that they're going to be attacked this turn. And so you have\nthese messages that",
    "start": "2231180",
    "end": "2237080"
  },
  {
    "text": "might be sent, something like\nthe second one shown here where England says to France,\nwe have hostile intentions",
    "start": "2237080",
    "end": "2242610"
  },
  {
    "text": "towards you. You must be wiped\nfrom the board. Please provide a croissant. So this is actually a message\nthat the bot sends to a player.",
    "start": "2242610",
    "end": "2249319"
  },
  {
    "text": "Not to a player, this was\npreliminary testing and kind of motivated this\nwhole approach. ",
    "start": "2249320",
    "end": "2256047"
  },
  {
    "text": "So we don't want the bot to\nsend these kinds of messages if it's going to\nattack a player. We want it to send\nsomething that's not an outright lie necessarily,\nbut just something--",
    "start": "2256047",
    "end": "2264088"
  },
  {
    "text": "either not send a\nmessage or send something that's much more bland.",
    "start": "2264088",
    "end": "2269470"
  },
  {
    "text": "And so we filter out\nthese kinds of messages by looking at the value.",
    "start": "2269470",
    "end": "2274960"
  },
  {
    "text": "What we do is we generate a\nbunch of candidate messages, and then we see if we\nwere to send this message,",
    "start": "2274960",
    "end": "2281020"
  },
  {
    "text": "what is the behavior\nthat we would expect the other players to take?",
    "start": "2281020",
    "end": "2286510"
  },
  {
    "text": "What actions will\nwe expect them to do after we send this message? And what do they expect we will\ndo after we send this message?",
    "start": "2286510",
    "end": "2293770"
  },
  {
    "text": "And then we see, what\nis the expected value of the action that\nwe intend to take",
    "start": "2293770",
    "end": "2299910"
  },
  {
    "text": "given the prediction of what\neverybody else is going to do? So if our intention\nis to attack France,",
    "start": "2299910",
    "end": "2307070"
  },
  {
    "text": "then we can see, well, if I were\nto send this message to France, then they're going to\nget really defensive and defend against\nan attack from us,",
    "start": "2307070",
    "end": "2313220"
  },
  {
    "text": "and our attack is going\nto be unsuccessful. And so therefore, I probably\nshouldn't send this message to them. ",
    "start": "2313220",
    "end": "2321092"
  },
  {
    "text": "And so in this way,\nwe can actually filter out messages that\nhave low expected value.",
    "start": "2321092",
    "end": "2326257"
  },
  {
    "text": "We found that this\nworked surprisingly well.  Dialogue examples, I'll\ngo through one just",
    "start": "2326257",
    "end": "2334640"
  },
  {
    "text": "for the sake of time. So here we have Cicero's France.",
    "start": "2334640",
    "end": "2342050"
  },
  {
    "text": "And Francis saying-- France is conversing with\nTurkey, who's a human player.",
    "start": "2342050",
    "end": "2347390"
  },
  {
    "text": "And they're debating over\nwho's going to get Tunis, this territory circled in red. You can see they both have\nfleets next to the territory.",
    "start": "2347390",
    "end": "2354640"
  },
  {
    "text": "If they both go for it, neither\nof them are going to get it. And so they need to work\nout some sort of deal. So France says, I'll work with\nyou, but I need Tunis for now.",
    "start": "2354640",
    "end": "2361692"
  },
  {
    "text": "Turkey says, nope, you've\ngot to let me have it. France says, no, I need it. And then France\nsuggests, you can",
    "start": "2361692",
    "end": "2368800"
  },
  {
    "text": "take these other\nterritories instead. You have Serbia\nand Rome to take. Turkey says, they're\nimpossible targets.",
    "start": "2368800",
    "end": "2375430"
  },
  {
    "text": "And then Cicero\nsuggests specific moves that would allow Turkey to\ncapture these territories.",
    "start": "2375430",
    "end": "2381850"
  },
  {
    "text": "So Cicero says, Greece to\nIonian, Ionian to Iranian. Turkey says, hmm, you're\nright, good ideas.",
    "start": "2381850",
    "end": "2388600"
  },
  {
    "text": "And then France says,\nand then in the fall, you take Rome and\nAustria collapses. And so that allows Turkey to\nmake progress against Austria,",
    "start": "2388600",
    "end": "2395770"
  },
  {
    "text": "but conveniently it also\nallows France to capture Tunis because Turkey will be using\nthose units for something else.",
    "start": "2395770",
    "end": "2402910"
  },
  {
    "text": " So limitations and\nfuture directions,",
    "start": "2402910",
    "end": "2408300"
  },
  {
    "text": "intent representation is\njust an action per player. So there's a question\nof, the intentions",
    "start": "2408300",
    "end": "2413750"
  },
  {
    "text": "that we're feeding\ninto the dialogue model is an action that we're\ngoing to take for this turn and for the next\nturn, for ourselves",
    "start": "2413750",
    "end": "2418950"
  },
  {
    "text": "and for the other player. But ideally, we would have\na richer set of intentions. We would be able to condition on\nthings like long-term strategy",
    "start": "2418950",
    "end": "2427380"
  },
  {
    "text": "or style of communication\nor asking questions.",
    "start": "2427380",
    "end": "2432720"
  },
  {
    "text": "That's one of the\nlimitations of this approach. Now of course, the richer you\nmake the space of intentions,",
    "start": "2432720",
    "end": "2438810"
  },
  {
    "text": "the more room there is\nfor things to go wrong. And you also have to\nthen train the model to be able to handle these\nwider space of intentions.",
    "start": "2438810",
    "end": "2447880"
  },
  {
    "text": "There is a question, do you\nthink the dialogue model is learning an internal model-- internal world model to be\nso good at predicting moves?",
    "start": "2447880",
    "end": "2455290"
  },
  {
    "text": "No, we're-- this is arguably\nwhy we're conditioning",
    "start": "2455290",
    "end": "2461010"
  },
  {
    "text": "on intentions. We're relieving\nthe dialogue model of having to come up\nwith a good world model",
    "start": "2461010",
    "end": "2466320"
  },
  {
    "text": "because we're telling\nit, these are the moves that we are planning\nto take this turn, and these are the moves that\nwe would like this other player",
    "start": "2466320",
    "end": "2471690"
  },
  {
    "text": "to take this turn. So we're like-- we're able\nto have the world model",
    "start": "2471690",
    "end": "2478420"
  },
  {
    "text": "separate from the dialogue model\nbut condition on the output from the world model. ",
    "start": "2478420",
    "end": "2486730"
  },
  {
    "text": "Another limitation is\nthat Cicero's value model doesn't condition on dialogue. And so it has a\nlimited understanding",
    "start": "2486730",
    "end": "2492628"
  },
  {
    "text": "of the long-term\neffects of dialogue. ",
    "start": "2492628",
    "end": "2498799"
  },
  {
    "text": "This greatly limits our ability\nto plan what kind of messages",
    "start": "2498800",
    "end": "2504200"
  },
  {
    "text": "we should be sending. And this is actually why\nwe always conditioned",
    "start": "2504200",
    "end": "2510920"
  },
  {
    "text": "Cicero's dialogue generation\non its truthful intentions. You could argue that there is\nsituations in Diplomacy where",
    "start": "2510920",
    "end": "2517760"
  },
  {
    "text": "you would want to lie\nto the other player. The best players rarely lie,\nbut they do lie sometimes.",
    "start": "2517760",
    "end": "2525230"
  },
  {
    "text": "And you have to understand the\ntrade off between if you lie,",
    "start": "2525230",
    "end": "2531560"
  },
  {
    "text": "you are going to not-- it's going to be\nmuch harder to work with this person in the future.",
    "start": "2531560",
    "end": "2537390"
  },
  {
    "text": "And so you have to make sure\nthat the value that you're getting positionally is\nworth that loss of trust",
    "start": "2537390",
    "end": "2543350"
  },
  {
    "text": "and that broken relationship. Now, because\nCicero's value model",
    "start": "2543350",
    "end": "2549360"
  },
  {
    "text": "doesn't condition on\ndialogue, it can't really understand this trade off. And so for this reason, we\nactually always condition it",
    "start": "2549360",
    "end": "2557970"
  },
  {
    "text": "on its truthful intentions. No, it is possible to\nhave Cicero's value",
    "start": "2557970",
    "end": "2565600"
  },
  {
    "text": "model conditioned on dialogue,\nbut you would need way more data and it would make\nthings much more expensive.",
    "start": "2565600",
    "end": "2570770"
  },
  {
    "text": "And so we weren't able to\ndo it further for this bot. ",
    "start": "2570770",
    "end": "2577710"
  },
  {
    "text": "And finally, there's\na big question that I mentioned\nearlier, which is, is there a more general way of\nscaling inference time compute",
    "start": "2577710",
    "end": "2584130"
  },
  {
    "text": "to achieve better performance? The way that we've\ndone planning in Cicero is, I would argue, a\nbit domain specific.",
    "start": "2584130",
    "end": "2590590"
  },
  {
    "text": "I think it's like-- the idea\nof piKL is quite general. But I think that there are\npotentially more general ways of doing planning.",
    "start": "2590590",
    "end": "2596460"
  },
  {
    "start": "2596460",
    "end": "2602220"
  },
  {
    "text": "Somebody is asking,\nlooking forward to the next two to three years. What criteria will you use\nto select the next game",
    "start": "2602220",
    "end": "2607400"
  },
  {
    "text": "to try to conquer? Honestly, like I said,\nwe chose Diplomacy because we thought it\nwould be the hardest",
    "start": "2607400",
    "end": "2612670"
  },
  {
    "text": "game to make an AI for. And I think that that's true. I don't think that we're going\nto be working on games anymore",
    "start": "2612670",
    "end": "2617710"
  },
  {
    "text": "because I can't think\nof any other game that if we were to\nsucceed at that, it would be truly impressive.",
    "start": "2617710",
    "end": "2626030"
  },
  {
    "text": "And so I think where the\nresearch is going in the future is generality.",
    "start": "2626030",
    "end": "2634210"
  },
  {
    "text": "Instead of getting AI to\nplay this specific game, can we get an AI that is\nable to play Diplomacy,",
    "start": "2634210",
    "end": "2640090"
  },
  {
    "text": "but could also play Go\nor poker, or could also write essays and stories,\nand solve math problems",
    "start": "2640090",
    "end": "2647140"
  },
  {
    "text": "and write theorems? I think what we\nwill see is games",
    "start": "2647140",
    "end": "2652990"
  },
  {
    "text": "serving as benchmarks for\nprogress but not as the goal.",
    "start": "2652990",
    "end": "2659208"
  },
  {
    "text": "It'll be part of\nthe test set but not part of the training set. And I think that's the way\nit should be going forward. ",
    "start": "2659208",
    "end": "2667830"
  },
  {
    "text": "Finally, I want to\nadd that Diplomacy is an amazing testbed\nfor multi-agent AI in grounded dialogue.",
    "start": "2667830",
    "end": "2673770"
  },
  {
    "text": "So if you are interested\nin these kinds of domains, I highly recommend taking\nadvantage of the fact",
    "start": "2673770",
    "end": "2679460"
  },
  {
    "text": "that we are-- we've open-sourced all\nof our code and models. And the dialogue\nand action data is",
    "start": "2679460",
    "end": "2684770"
  },
  {
    "text": "available through what's\ncalled an RFP, where you can apply to get access\nto the dialogue and data.",
    "start": "2684770",
    "end": "2691115"
  },
  {
    "text": " So thanks for listening.",
    "start": "2691115",
    "end": "2696122"
  },
  {
    "text": "To wrap up, Cicero combines\nstrategic reasoning and natural language\nin Diplomacy. It placed in the top\n10% of human players.",
    "start": "2696122",
    "end": "2701530"
  },
  {
    "text": "And the paper is in\nscience, and code and models are publicly\navailable at this URL. So thanks.",
    "start": "2701530",
    "end": "2707230"
  },
  {
    "text": "And for the remaining\ntime, I'll take questions. Thanks a lot. So we'll also open some\nquestions from the class.",
    "start": "2707230",
    "end": "2715532"
  },
  {
    "text": "We can finish their\nZoom questions. So if anyone has\nsome questions, I think now you can answer those.",
    "start": "2715532",
    "end": "2721360"
  },
  {
    "text": "Yeah, there's one question,\nare you concerned about AIs out-competing humans at\nreal-world diplomatic strategic negotiation and deception tasks?",
    "start": "2721360",
    "end": "2728619"
  },
  {
    "text": "So like I said, we're not\nvery focused on deception, even though arguably\ndeception is a part",
    "start": "2728620",
    "end": "2734140"
  },
  {
    "text": "of the game of Diplomacy. I think for diplomatic\nand strategic negotiation,",
    "start": "2734140",
    "end": "2741200"
  },
  {
    "text": "I don't-- look, the way that\nwe've developed Cicero, it's designed to play\nDiplomacy, the game of Diplomacy",
    "start": "2741200",
    "end": "2747920"
  },
  {
    "text": "specifically, and you can't\nuse it out-of-the-box for other tasks. That said, I do think that the\ntechniques are quite general.",
    "start": "2747920",
    "end": "2755892"
  },
  {
    "text": "And so hopefully,\nothers can build on that and to be able\nto do different things. And I think it is\nentirely possible",
    "start": "2755893",
    "end": "2762019"
  },
  {
    "text": "that over the next\nseveral years, you will see this entering\ninto real-world negotiations",
    "start": "2762020",
    "end": "2767810"
  },
  {
    "text": "much more often. I actually think\nthat Diplomacy is a big step towards real-world\napplicability compared",
    "start": "2767810",
    "end": "2773390"
  },
  {
    "text": "to breakthroughs in\ngames like Go and poker. ",
    "start": "2773390",
    "end": "2778660"
  },
  {
    "text": "Because now, your\naction space is really like the space of\nnatural language, and you have to\nmodel human behavior.",
    "start": "2778660",
    "end": "2785112"
  },
  {
    "text": "Do you think in the future we\ncould appoint an AI to the UN council? Hopefully, only if it\ndoes better than humans.",
    "start": "2785112",
    "end": "2793300"
  },
  {
    "text": "But that would be very\ninteresting to see. I'm also curious, what's the\nfuture things that you're",
    "start": "2793300",
    "end": "2799960"
  },
  {
    "text": "working on in this direction? Do you think you\ncan do something like AlphaGo Zero where you\njust take this piKL model",
    "start": "2799960",
    "end": "2805630"
  },
  {
    "text": "and then just be\ngiving self-play? Or what sort of\nfuture actions are you thinking for improving\nthis sort of bots?",
    "start": "2805630",
    "end": "2812182"
  },
  {
    "text": "I think the future\ndirections are really focused around generality. I think one of the\nbig insights of Cicero",
    "start": "2812183",
    "end": "2819280"
  },
  {
    "text": "is this ability to\nleverage planning to get better performance\nwith language models and in this strategic domain.",
    "start": "2819280",
    "end": "2826150"
  },
  {
    "text": "I think there's a\nlot of opportunity to do that sort of thing in\na broader space of domains. I mean, you look at\nlanguage models today,",
    "start": "2826150",
    "end": "2832660"
  },
  {
    "text": "and they do\ntoken-by-token prediction. And I think there's a big\nopportunity to go beyond that.",
    "start": "2832660",
    "end": "2839220"
  },
  {
    "text": "So that's what I'm\nexcited to look into. I'm also curious, I didn't\nunderstand the exact details how using planning or Monte\nCarlo tree search with your--",
    "start": "2839220",
    "end": "2846680"
  },
  {
    "text": "like the models that you have. So is it like-- We didn't use Monte Carlo\ntree search in Cicero.",
    "start": "2846680",
    "end": "2853750"
  },
  {
    "text": "Monte Carlo tree search\nis very good heuristic, but it's a heuristic\nthat is particularly",
    "start": "2853750",
    "end": "2860290"
  },
  {
    "text": "useful for deterministic\nperfect information games. And I think in order to have a\ntruly general form of planning,",
    "start": "2860290",
    "end": "2868009"
  },
  {
    "text": "we need to go more abstract\nthan Monte Carlo tree search. We use this algorithm called\npiKL based on a regret",
    "start": "2868010",
    "end": "2875390"
  },
  {
    "text": "minimization algorithm. I don't really want to\ngo into the details of it because it's not that\nimportant for the class.",
    "start": "2875390",
    "end": "2880470"
  },
  {
    "text": "But the idea is it is this\niterative algorithm that will gradually refine the\nprediction of what everybody's going to do and get better and\nbetter predictions the more",
    "start": "2880470",
    "end": "2887730"
  },
  {
    "text": "iterations that you're on. And that's in the research? Yup.",
    "start": "2887730",
    "end": "2892800"
  },
  {
    "text": "Correct. Yeah. ",
    "start": "2892800",
    "end": "2900260"
  },
  {
    "text": "Go for it, you're unmuted.  So yeah, my question\nis when we were talking",
    "start": "2900260",
    "end": "2907270"
  },
  {
    "text": "about generability, how\ndoes the communication between different\nmodules of the model look",
    "start": "2907270",
    "end": "2913810"
  },
  {
    "text": "like, particularly when we're\ntalking about the dialogue model? How do you send information\nfrom the policy network",
    "start": "2913810",
    "end": "2920880"
  },
  {
    "text": "to the dialogue model? And in the future, if\nyou have a model that's good at different\ntasks, are we going to have a really big policy\nnet that learns all of them",
    "start": "2920880",
    "end": "2929280"
  },
  {
    "text": "or separate language\nmodules for all of them? How do you break it down? So we actually\nconvert the policy",
    "start": "2929280",
    "end": "2935910"
  },
  {
    "text": "by the action for ourselves\nand for our dialogue partner into a string-- natural language string\nand to speed that",
    "start": "2935910",
    "end": "2941700"
  },
  {
    "text": "into the dialogue model\nalong with all the dialogue that it's had so far. So it's just all\ntext in, text out.",
    "start": "2941700",
    "end": "2950650"
  },
  {
    "text": "And that works great. And then, what was the\nsecond part of your question? ",
    "start": "2950650",
    "end": "2958240"
  },
  {
    "text": "Something like,\nare we just going to have one giant policy\nnet to learn everything? Yeah.",
    "start": "2958240",
    "end": "2963650"
  },
  {
    "text": "It was like so, if you're\nonly using text first, doesn't it limit the model? And if you're using it\nfor different games,",
    "start": "2963650",
    "end": "2971263"
  },
  {
    "text": "are you thinking\nlike, what do you say in the future you will\nwork on generalizability? Are you thinking about\na big policy network",
    "start": "2971263",
    "end": "2977600"
  },
  {
    "text": "that is trained\non separate games or is able to understand\ndifferent games at the same time? Or do we have separate policy\nnetworks for different games?",
    "start": "2977600",
    "end": "2986120"
  },
  {
    "text": "And yeah, doesn't this like\ntext interface limit the model in terms of communication?",
    "start": "2986120",
    "end": "2992240"
  },
  {
    "text": "If you're using\nlectures, it might-- yeah, it might the bottom line.",
    "start": "2992240",
    "end": "2998800"
  },
  {
    "text": "I mean, I think ideally,\nyou go in this direction where you have a\nfoundational model that works",
    "start": "2998800",
    "end": "3003990"
  },
  {
    "text": "for pretty much everything. Does text-- I mean,\ncertainly, yeah, just like a text in, text\nout, limits what you can",
    "start": "3003990",
    "end": "3010560"
  },
  {
    "text": "do in terms of communication. But hopefully, we\nget beyond that.",
    "start": "3010560",
    "end": "3016410"
  },
  {
    "text": "I think it's a reasonable\nchoice for now. Thank you. ",
    "start": "3016410",
    "end": "3025620"
  },
  {
    "text": "I'm looking at more\nZoom questions. So there's a question at chat. Love to hear your\nspeculation on the future. For instance, we've\nseen some startups that",
    "start": "3025620",
    "end": "3032212"
  },
  {
    "text": "are fine-tuning LMs to\nbe biased or experts in say subject x or subject y. ",
    "start": "3032212",
    "end": "3039790"
  },
  {
    "text": "This seems like a\npretty general question. ",
    "start": "3039790",
    "end": "3046600"
  },
  {
    "text": "I don't have strong\nopinions on this. ",
    "start": "3046600",
    "end": "3058800"
  },
  {
    "text": "Yeah. I mean, I'm not too-- I'm not too focused myself\non fine-tuning language",
    "start": "3058800",
    "end": "3066872"
  },
  {
    "text": "models to specific tasks.  I think the direction\nthat I'm much more",
    "start": "3066873",
    "end": "3072320"
  },
  {
    "text": "interested in going forward\nis the more general forms of planning. So I don't think I\ncan really comment",
    "start": "3072320",
    "end": "3078800"
  },
  {
    "text": "on how do you tune these\nlanguage models in these ways.",
    "start": "3078800",
    "end": "3087870"
  },
  {
    "text": "So what sort of\nplanning methods are you interested in looking at? Like, MCTS is one.",
    "start": "3087870",
    "end": "3094620"
  },
  {
    "text": "So let me-- sorry, I've got to\nstep out for just one second.",
    "start": "3094620",
    "end": "3100150"
  },
  {
    "text": "I've got to switch rooms. Excuse me. OK, never mind.",
    "start": "3100150",
    "end": "3105560"
  },
  {
    "text": "We're all good. Sorry, what was the question? Oh, yes. I was just asking what\nsort of planning algorithms",
    "start": "3105560",
    "end": "3110630"
  },
  {
    "text": "do you think are very\ninteresting to combine? So I think we have\nso many options, like we have planning kind of\nstuff, or auto, there's MCTS,",
    "start": "3110630",
    "end": "3117529"
  },
  {
    "text": "there's the bot you\ndid with Cicero. So what do you think are the\nmost interesting algorithms that you think will scale well?",
    "start": "3117530",
    "end": "3123260"
  },
  {
    "text": "Can you generalize? Well, I think that's the big\nquestion that a lot of people are trying to figure out today.",
    "start": "3123260",
    "end": "3129142"
  },
  {
    "text": "And it's not really\nclear what the answer is. I mean, I think you look at\nsome of the chain of thought.",
    "start": "3129142",
    "end": "3134510"
  },
  {
    "text": "And I think there's\na lot of limitations to chain of thought. And I think that it should be\npossible to do a lot better.",
    "start": "3134510",
    "end": "3140340"
  },
  {
    "text": "But it is really\nimpressive to see just how general of an\napproach it is. And so I think it would\nbe nice to see things that",
    "start": "3140340",
    "end": "3151309"
  },
  {
    "text": "are general in that way, but\nhopefully able to achieve better performance.",
    "start": "3151310",
    "end": "3158990"
  },
  {
    "text": "Got it.  Ultimately, Cicero is like\nan encoder-decoder model",
    "start": "3158990",
    "end": "3165859"
  },
  {
    "text": "in a sense that\nencodes the model and then you have the dialogue\nmodel which is kind of decoder. It was an encoder-decoder\nmodel, yes.",
    "start": "3165860",
    "end": "3172520"
  },
  {
    "text": "I don't think that that's\nnecessarily the right choice. But that's what we used.",
    "start": "3172520",
    "end": "3180100"
  },
  {
    "text": "Any questions?  OK, I think we're\nare mostly good.",
    "start": "3180100",
    "end": "3187230"
  },
  {
    "text": "OK, thanks a lot. OK. Well, yeah, we all enjoyed it. And if there are any questions,\nfeel free to email me,",
    "start": "3187230",
    "end": "3193029"
  },
  {
    "text": "reach out. I'm happy to chat. ",
    "start": "3193030",
    "end": "3200000"
  }
]
[
  {
    "start": "0",
    "end": "6470"
  },
  {
    "text": "I'll explain where we\nare in the whole course. In the next maybe 2 and\n1/2, 3 weeks, we build up.",
    "start": "6470",
    "end": "15800"
  },
  {
    "text": "And we're going from the\nbottom up to the top. So this will finish\nwhen you'll actually",
    "start": "15800",
    "end": "20810"
  },
  {
    "text": "implement your own solver, an LP\nsolver, or something like that. We haven't quite figured out.",
    "start": "20810",
    "end": "26900"
  },
  {
    "text": "But anyway, it'll finish with\nyou implementing a solver, so mostly, by the way,\njust to demystify it,",
    "start": "26900",
    "end": "34670"
  },
  {
    "text": "just so when someone looks\nat you sometime in the future and says, oh my god, you can't\nwrite your own LP solver.",
    "start": "34670",
    "end": "40787"
  },
  {
    "text": "That's really complicated. And you could say, au\ncontraire, I did it. Right? So that's the main\nthing, the main reason.",
    "start": "40787",
    "end": "48079"
  },
  {
    "text": "But also there's\ninteresting stuff. Right now we're at the bottom\nlevel, which is linear algebra.",
    "start": "48080",
    "end": "54410"
  },
  {
    "text": "And actually, in some\nways, it's by far the most important level. And my own feeling is\ncertainly, anybody in this class",
    "start": "54410",
    "end": "62720"
  },
  {
    "text": "needs to know this material. Do you need to know a\nwhole 10-week course that you would take on\ncomputational linear algebra?",
    "start": "62720",
    "end": "70590"
  },
  {
    "text": "Hmm, maybe, actually. But certainly, you need to\nbe familiar with the ideas.",
    "start": "70590",
    "end": "77549"
  },
  {
    "text": "And that's unlike--\nyou don't have to know about\ncomputer architecture, even though everything we\ndo is thanks to the people",
    "start": "77550",
    "end": "85439"
  },
  {
    "text": "who design and build\ncomputers and stuff. So but this you\nactually should know.",
    "start": "85440",
    "end": "93030"
  },
  {
    "text": "OK, so back to the numerical\nlinear algebra-- and today,",
    "start": "93030",
    "end": "98250"
  },
  {
    "text": "actually, we're going to cover\nmaterial that some of you may know. The rest of you probably don't.",
    "start": "98250",
    "end": "103870"
  },
  {
    "text": "And I've listed in the\ntop 10 of the things you need to know\nfrom this course, even though it's not\ntechnically part of the course.",
    "start": "103870",
    "end": "111370"
  },
  {
    "text": "So OK. So here it is. Last time we talked\nabout, how do you solve a set of equations Ax equals b?",
    "start": "111370",
    "end": "119350"
  },
  {
    "text": "And there are several ways. There's ones we're not\ngoing to talk about. There are iterative\nmethods to do",
    "start": "119350",
    "end": "125530"
  },
  {
    "text": "this, which are used for super\nlarge-scale problems, if you've got like a billion variables\nor if that represents",
    "start": "125530",
    "end": "132250"
  },
  {
    "text": "a PDE you're solving. Right? We're not going to\ntalk about those. We're going to talk\nabout-- these are",
    "start": "132250",
    "end": "137792"
  },
  {
    "text": "what are called direct methods. I don't know where\nthat name came from, but they're called direct. And the way they work is\nthey take the matrix A,",
    "start": "137792",
    "end": "144325"
  },
  {
    "text": "and they first factor it\ninto a product of matrices, each of which, quote, \"is\neasy to invert,\" unquote.",
    "start": "144325",
    "end": "152890"
  },
  {
    "text": "So that's the first step, right? And you've seen some of\nthese factorizations, like SVD, eigendecomposition.",
    "start": "152890",
    "end": "159520"
  },
  {
    "text": "You've probably seen a\ncouple of the others as well. So an easy to invert\nis actually just--",
    "start": "159520",
    "end": "166480"
  },
  {
    "text": "that's dialect for it's\neasy to solve equations with that coefficient matrix.",
    "start": "166480",
    "end": "172390"
  },
  {
    "text": "So that's what it really means. Because no one is\ninverting anything, right? It is unbelievably rare in\ngood numerical work for anybody",
    "start": "172390",
    "end": "181280"
  },
  {
    "text": "to actually form the\ninverse of a matrix. There are cases where people\ndo, but it's very rare.",
    "start": "181280",
    "end": "187310"
  },
  {
    "text": "So OK, so what you\ndo then, once you've factored your matrix into a\nproduct of things which are,",
    "start": "187310",
    "end": "196075"
  },
  {
    "text": "quote, \"easy to\ninvert,\" unquote, you have to interpret that\ncorrectly, then what you do",
    "start": "196075",
    "end": "201110"
  },
  {
    "text": "is you then write\nout the inverse. And the inverse is the\nproduct of the inverses",
    "start": "201110",
    "end": "206390"
  },
  {
    "text": "in reverse order. And then you literally\njust evaluate this by first evaluating\nA1 inverse b.",
    "start": "206390",
    "end": "213189"
  },
  {
    "text": "That's one thing. And then, of course,\nwhat that means is people write A1 inverse b. What they really mean is\nyou call solve A1, comma b.",
    "start": "213190",
    "end": "221240"
  },
  {
    "text": "That's what it really means. So you solve that. Then you pass this\nsolution to the next thing,",
    "start": "221240",
    "end": "228150"
  },
  {
    "text": "which is A2 inverse times x1. And so you solve A2x2 equals x1.",
    "start": "228150",
    "end": "235610"
  },
  {
    "text": "And that gives you\nthe second one. And you keep going until\nyou get to the end. So again, it's completely\nstraightforward.",
    "start": "235610",
    "end": "242120"
  },
  {
    "text": "Like, OK, so what? Last time, we talked about some\nvery interesting things, which",
    "start": "242120",
    "end": "250040"
  },
  {
    "text": "is that if you want to\nsolve a set of equations with the same\ncoefficient matrix,",
    "start": "250040",
    "end": "255860"
  },
  {
    "text": "but different right-hand sides,\nthen in fact, what you can do is you factor once, and you\ncache the factorization.",
    "start": "255860",
    "end": "264229"
  },
  {
    "text": "And then you simply\nuse the solve method. This is called the solve. The first one is called factor,\nand this is called solve.",
    "start": "264230",
    "end": "272330"
  },
  {
    "text": "So you simply call\nthe solve method on your multiple\nright-hand sides. And you get to surprising\nconclusions in some cases.",
    "start": "272330",
    "end": "284120"
  },
  {
    "text": "I'll get to that in a minute. So all right, so this is\nthe one that you probably saw a variation of this in\nhigh school or something,",
    "start": "284120",
    "end": "291650"
  },
  {
    "text": "the first time you\nsaw linear equations. It's called Gaussian\nelimination. It's called lots of things.",
    "start": "291650",
    "end": "297150"
  },
  {
    "text": "But here's what it is. If you have a\nnon-singular matrix, you can factor it as a\npermutation times a lower",
    "start": "297150",
    "end": "304510"
  },
  {
    "text": "triangular matrix. It's a lower triangular,\nand U is upper triangular. And they're all invertible.",
    "start": "304510",
    "end": "310600"
  },
  {
    "text": "Of course, actually,\nif any one of them weren't, then they would not be. Right. So the cost of\nthat factorization,",
    "start": "310600",
    "end": "317800"
  },
  {
    "text": "which we're not going to\ngo into how that's done. It's actually not\nthat difficult. But the cost is order\nn cubed flops, OK?",
    "start": "317800",
    "end": "325870"
  },
  {
    "text": "So that's what that is. And so this is what it looks\nlike to solve linear equations.",
    "start": "325870",
    "end": "331060"
  },
  {
    "text": "You factor A. That means\nyou get P, L, and U. Then",
    "start": "331060",
    "end": "337600"
  },
  {
    "text": "these three steps, two,\nthree, four, this is factor, and then this is solve. So again, all you do is you just\nsolve them in reverse order.",
    "start": "337600",
    "end": "346120"
  },
  {
    "text": "Now, solving this one, solving\nthe permutation, this is silly. It's multiply by P\ntranspose, roughly.",
    "start": "346120",
    "end": "352532"
  },
  {
    "text": "It's the inverse permutation. You unpermute them, right? So this is easy. The second one, L\nis lower triangular.",
    "start": "352532",
    "end": "359650"
  },
  {
    "text": "And so for that, you use\nforward substitution, which we saw as an order\nn squared algorithm.",
    "start": "359650",
    "end": "365250"
  },
  {
    "text": "Backward substitution\nis when you have U because U is upper triangular. And you start, if\nyou will recall,",
    "start": "365250",
    "end": "370710"
  },
  {
    "text": "by first solving for\nthe last entry then, then the second last, and\nthe third last, and so on. That's backward\nsubstitution, and that's also",
    "start": "370710",
    "end": "377310"
  },
  {
    "text": "n squared flops. And if you add these\nup, what you find out is something kind of weird. It's that the factor\nis order n cubed,",
    "start": "377310",
    "end": "384000"
  },
  {
    "text": "and the solve is\norder n squared. And so I think last\ntime, I finished by asking you a question,\nwhich is, how long does it",
    "start": "384000",
    "end": "390930"
  },
  {
    "text": "take to solve, I don't\nknow, on my laptop, a set of linear equations\nwith, let's say, a 1,000",
    "start": "390930",
    "end": "397980"
  },
  {
    "text": "by 1,000 matrix? Right? Which I could make\nsound pretty impressive. I could say, my problem has\nmore than a million coefficients",
    "start": "397980",
    "end": "406770"
  },
  {
    "text": "in it, which is true. 1,000 by 1,000 matrix does. And then you could\nsay, the n cubed,",
    "start": "406770",
    "end": "414380"
  },
  {
    "text": "the factorization\nis order n cubed. That's a billion\nflops, Right Of course,",
    "start": "414380",
    "end": "420400"
  },
  {
    "text": "that's a joke now, right? And the answer is, I can do\nthat in 100 milliseconds.",
    "start": "420400",
    "end": "427150"
  },
  {
    "text": "OK? So can you. My phone can do it in\nsomething on that order of magnitude, which is\nactually kind of stunning.",
    "start": "427150",
    "end": "435940"
  },
  {
    "text": "I think then I asked\nthe following question. I asked, if it takes 100\nmilliseconds to solve,",
    "start": "435940",
    "end": "443180"
  },
  {
    "text": "let's say, one set of\n1,000 by 1,000 equations, 1,000 equations, 1,000\nunknowns, how long",
    "start": "443180",
    "end": "449290"
  },
  {
    "text": "does it take to solve 10? For that matter,\neven 100, how long does it take, if it takes a\ntenth of a second to do one?",
    "start": "449290",
    "end": "457030"
  },
  {
    "text": "And the answer is surprising. It's this. It's a tenth of a second. Everybody got that? So not that many\npeople appreciate this",
    "start": "457030",
    "end": "464110"
  },
  {
    "text": "or understand this. And this is actually--\nthis is used throughout a lot\nof numerical stuff.",
    "start": "464110",
    "end": "469600"
  },
  {
    "text": "A lot of it, well, you\nuse it all the time. You just don't know it. So all the solvers\nthat you use when",
    "start": "469600",
    "end": "475150"
  },
  {
    "text": "you call CVXPY almost all of\nthem will use things like this. So the most typical methods to\nsolve things like SOCPs, SDPs,",
    "start": "475150",
    "end": "483850"
  },
  {
    "text": "these things. Or for that matter, even LPs\ninvolve two solves, right? And basically, the\nfactorization dominates,",
    "start": "483850",
    "end": "492909"
  },
  {
    "text": "and that's the point there. OK? So all right, actually,\nI'm just curious.",
    "start": "492910",
    "end": "498057"
  },
  {
    "text": "How many people have\nseen this before? How many people knew that\nyou could solve 10 equations with 1,000 variables, 1,000\nunknowns, same coefficient",
    "start": "498057",
    "end": "506950"
  },
  {
    "text": "matrix, different\nright-hand sides, you could solve 10\nin the amount of time it takes you to solve one?",
    "start": "506950",
    "end": "513250"
  },
  {
    "text": "You knew? Come on, [? say. ?]\nOther people? Yeah, is no one else impressed?",
    "start": "513250",
    "end": "518710"
  },
  {
    "text": "Or shouldn't you be-- I mean, it's maybe\ntoo early, but people",
    "start": "518710",
    "end": "524190"
  },
  {
    "text": "should be going, like,\nthat's awesome, really? But I'm not getting\nthat feeling. But that's OK. That's fine.",
    "start": "524190",
    "end": "530280"
  },
  {
    "text": "OK, good, there we go. All right, now\nsparse factorization,",
    "start": "530280",
    "end": "537580"
  },
  {
    "text": "this is super interesting. This is something everybody\nshould know about. So I guess it's been developed\nsince about the 1960s, is",
    "start": "537580",
    "end": "547440"
  },
  {
    "text": "basically, stuff\non sparse matrices. And so first of all, what\nare the data structures you",
    "start": "547440",
    "end": "554610"
  },
  {
    "text": "use to store them? And then, basically, there's\na whole parallel universe of doing all the\nstuff you would do",
    "start": "554610",
    "end": "559620"
  },
  {
    "text": "with so-called dense\nmatrices, which are just stored as arrays, right? How do you do this\nfor sparse matrices,",
    "start": "559620",
    "end": "565890"
  },
  {
    "text": "including factorizations,\nback solves, all these kinds of things? Everything you can do,\neigendecomposition, singular",
    "start": "565890",
    "end": "573209"
  },
  {
    "text": "value decomposition,\nthere's a whole field where people have made this\nefficient for sparse matrices.",
    "start": "573210",
    "end": "578940"
  },
  {
    "text": "And this is something everybody\nneeds to know about, everyone.",
    "start": "578940",
    "end": "584220"
  },
  {
    "text": "Because if you do any\nkind of computation, you need to know about this. Because, again, there will\nbe surprising statements",
    "start": "584220",
    "end": "592170"
  },
  {
    "text": "we'll make about what you\ncan solve and not solve. OK, so if A is sparse,\nthe typical factorization",
    "start": "592170",
    "end": "600579"
  },
  {
    "text": "is going to have four factors. It's going to have a P1,\nis a permutation in front.",
    "start": "600580",
    "end": "607240"
  },
  {
    "text": "P2 is a permutation in back. And then L and U are\nthe lower triangular",
    "start": "607240",
    "end": "614200"
  },
  {
    "text": "and upper triangular. So the idea here\nis mathematically,",
    "start": "614200",
    "end": "620260"
  },
  {
    "text": "you don't need P2. You do need P1. It is false that any\nnon-singular matrix",
    "start": "620260",
    "end": "627519"
  },
  {
    "text": "can be factored as LU. OK? You do need that\ninitial permutation. But you don't need\nthat second one.",
    "start": "627520",
    "end": "634070"
  },
  {
    "text": "So the second one is there. And by the way,\nP1 is also there, so that when you carry\nout this LU factorization,",
    "start": "634070",
    "end": "643350"
  },
  {
    "text": "L and U will also be sparse. Because if you do\nthis, if you're not careful about doing this,\nyour matrix A will be sparse,",
    "start": "643350",
    "end": "651220"
  },
  {
    "text": "but L and U will be dense. When that happens, it's\nreferred to as you have fill-in.",
    "start": "651220",
    "end": "656670"
  },
  {
    "text": "You have lots of entries,\nentries in L and U that weren't there in A. OK?",
    "start": "656670",
    "end": "661950"
  },
  {
    "text": "And this is very important\nfor everybody to know, right? And here would be an example.",
    "start": "661950",
    "end": "668100"
  },
  {
    "text": "It's extremely common to work\nall the time with, let's say, a million by million\nsparse matrix.",
    "start": "668100",
    "end": "675120"
  },
  {
    "text": "It is simply not\na problem, right? I can do stuff like that\non my laptop, right?",
    "start": "675120",
    "end": "681720"
  },
  {
    "text": "The number of\nnon-zeros is not going to be 10 to the 12, which\nwould be a dense one.",
    "start": "681720",
    "end": "687475"
  },
  {
    "text": "It's going to be something\nreasonable like, I don't know, it's got 20, 30, 100\nnon-zeros per row.",
    "start": "687475",
    "end": "692824"
  },
  {
    "text": "Even that is not\nthat big a deal, because it's 100 million\ncoefficients if there's 100 non-zeros per row.",
    "start": "692825",
    "end": "699120"
  },
  {
    "text": "And you multiply\nthat by about 10. So even in doubles, it's a\ngig, which is just very small.",
    "start": "699120",
    "end": "705540"
  },
  {
    "text": "It's a reasonably\nsmall amount of memory. OK? So anyway, so what happens\nis if you have your million",
    "start": "705540",
    "end": "712530"
  },
  {
    "text": "by million matrix, and you\ncall a solver like this, if you choose P1 and P2\npoorly, then what will happen",
    "start": "712530",
    "end": "721480"
  },
  {
    "text": "is L will be like a dense\nlower triangular matrix. You can't even store it, because\nit's a million by million.",
    "start": "721480",
    "end": "728139"
  },
  {
    "text": "So it's 10 to the 12\ndivided by 2 things. I mean, you can't. Let's just leave\nit that way, OK?",
    "start": "728140",
    "end": "734620"
  },
  {
    "text": "Making sense? So the P1 and P2, they're\nchosen heuristically. And people have been\ndoing this since the '60s.",
    "start": "734620",
    "end": "741550"
  },
  {
    "text": "It's actually very cool. You can ask questions like,\noh, find me the P1 and P2",
    "start": "741550",
    "end": "747460"
  },
  {
    "text": "that minimize the number of\nnon-zeros in L and U. That's",
    "start": "747460",
    "end": "752570"
  },
  {
    "text": "a perfectly nice\nproblem to come up with. And it is NP-hard, OK?",
    "start": "752570",
    "end": "757970"
  },
  {
    "text": "But who cares? It's silly. There are unbelievably\ngood heuristics for doing this that, I mean,\nall of us benefit from.",
    "start": "757970",
    "end": "766100"
  },
  {
    "text": "So this is great. OK. And so what happens with\nsparse matrices is the factor",
    "start": "766100",
    "end": "773060"
  },
  {
    "text": "and solve times,\nwhatever they are, they are less than 2/3 n cubed.",
    "start": "773060",
    "end": "780480"
  },
  {
    "text": "And I'm going to give you a\nvery important special case right now, and then\nwe'll encounter others.",
    "start": "780480",
    "end": "788300"
  },
  {
    "text": "So here's a super\nimportant special case. It's a so-called banded matrix.",
    "start": "788300",
    "end": "793730"
  },
  {
    "text": "So a banded matrix\nlooks like this. Well, of course, there's\njust a band here, like this.",
    "start": "793730",
    "end": "799580"
  },
  {
    "text": "Maybe this is k\nentries wide, right? And basically, this is non-zero,\nand everything out here",
    "start": "799580",
    "end": "806750"
  },
  {
    "text": "is-- that's zero, and that's 0. So that's a banded\nmatrix, right? So I can store a banded\nmatrix on my laptop easily",
    "start": "806750",
    "end": "815420"
  },
  {
    "text": "if it's a million by million\nand the bandwidth is, let's say, 10 or 20\nright so everybody",
    "start": "815420",
    "end": "820940"
  },
  {
    "text": "so that's a banded matrix. That's fine. ",
    "start": "820940",
    "end": "827600"
  },
  {
    "text": "Well, this is a case where\nyou don't need P1 and P2. But if you simply do the\nLU factorization here,",
    "start": "827600",
    "end": "834320"
  },
  {
    "text": "the L and the U are going\nto be, basically, the same. They're also going to be banded.",
    "start": "834320",
    "end": "839750"
  },
  {
    "text": "So I'll just write down L.\nL Is lower triangular, so-- whoops.",
    "start": "839750",
    "end": "844760"
  },
  {
    "text": "This goes down to there, right? And then it simply\nlooks like that. That's k over 2.",
    "start": "844760",
    "end": "850580"
  },
  {
    "text": "And this is what L looks like. And U looks similarly, right? So by the way, sometimes,\na banded matrix",
    "start": "850580",
    "end": "858858"
  },
  {
    "text": "comes to you looking like that. But sometimes,\nit's been permuted by whoever formed the problem.",
    "start": "858858",
    "end": "864255"
  },
  {
    "text": "They decide, well, I'm going\nto list all my states first, then all my controls,\nthen all this, in an optimal control problem.",
    "start": "864255",
    "end": "870740"
  },
  {
    "text": "And then it comes out with\nsome crazy sparsity pattern. And any methods used to\nheuristically choose P1 and P2",
    "start": "870740",
    "end": "879300"
  },
  {
    "text": "will permute it to look banded. OK. So what happens in a banded\nfactorization is, first of all,",
    "start": "879300",
    "end": "885720"
  },
  {
    "text": "the factorization\ntime is nk squared,",
    "start": "885720",
    "end": "891629"
  },
  {
    "text": "and then the back solve is nk. OK? So these are stunningly smaller\nthan n cubed and n squared.",
    "start": "891630",
    "end": "902350"
  },
  {
    "text": "OK? So what this tells you is\nyou can solve a million",
    "start": "902350",
    "end": "908440"
  },
  {
    "text": "by million equations if the\nbandwidth is 10 super easily.",
    "start": "908440",
    "end": "913900"
  },
  {
    "text": "And it's going to be so\nfast, it's not even funny. Everybody following this? Which is shocking, right?",
    "start": "913900",
    "end": "919112"
  },
  {
    "text": "Because someone said,\nwhat are you doing? You say, I'm solving a\nset of a million equations for a million variables.",
    "start": "919112",
    "end": "924460"
  },
  {
    "text": "Each equation involves\n10 of the variables. And you're like, whoa,\nthat sounds like it's hard.",
    "start": "924460",
    "end": "929890"
  },
  {
    "text": "Right? The answer is,\nit's unbelievable. This is a millisecond operation. Everyone [? follow? ?] It's\njust this is completely insane.",
    "start": "929890",
    "end": "938230"
  },
  {
    "text": "You absolutely\nneed to know this, because this is the trick\nto many, many things.",
    "start": "938230",
    "end": "943570"
  },
  {
    "text": "OK. So by the way,\nwhat's interesting here is the factor solve ratio\nis not that high anymore.",
    "start": "943570",
    "end": "951519"
  },
  {
    "text": "Now it's k. It used to be n. And so that says, if I\nsay, how long does it take to solve a million by\nmillion equations banded",
    "start": "951520",
    "end": "958910"
  },
  {
    "text": "with a bandwidth of 10? It's some number which\nis shockingly small. Then you say, how\nabout 10 of them?",
    "start": "958910",
    "end": "964320"
  },
  {
    "text": "OK. How about two of them? And you say, it's only\na little, tiny bit more. Everybody following this?",
    "start": "964320",
    "end": "969630"
  },
  {
    "text": "OK. So by the way, what you'll be\ndoing in the next week, two",
    "start": "969630",
    "end": "974720"
  },
  {
    "text": "weeks, is you will start to\nrecognize matrix structure,",
    "start": "974720",
    "end": "980329"
  },
  {
    "text": "like sparsity. You're going to see some\nothers later today, like block arrow and weird other ones.",
    "start": "980330",
    "end": "986240"
  },
  {
    "text": "And L will start\nrecognizing them. They're super important\nbecause two things. Number one, you'll start\nrecognizing structures",
    "start": "986240",
    "end": "994670"
  },
  {
    "text": "that you can exploit to\nsolve extremely fast. That's number one. But number two,\non the other end,",
    "start": "994670",
    "end": "1000670"
  },
  {
    "text": "you're going to\nstart recognizing practical problems that\nwill result in matrices",
    "start": "1000670",
    "end": "1006160"
  },
  {
    "text": "with that structure. I'm going to mention\none right now. All of control, all\nof signal processing,",
    "start": "1006160",
    "end": "1013330"
  },
  {
    "text": "just looks like that,\nevery last bit of it, OK? So that means if I ask\nyou to-- and you've",
    "start": "1013330",
    "end": "1020620"
  },
  {
    "text": "solved problems, little control\nproblems, and things like that. But what this says\nis, if someone says,",
    "start": "1020620",
    "end": "1026098"
  },
  {
    "text": "I have to compute-- I have to solve a control\nproblem with 20,000 time steps and a state dimension\nof 20 and 10 actuators,",
    "start": "1026098",
    "end": "1034544"
  },
  {
    "text": "and someone say,\nwow, that sounds like it's going\nto be complicated, you just laugh and\nsay, are you kidding?",
    "start": "1034545",
    "end": "1041289"
  },
  {
    "text": "I can do that on my phone. And, of course, that's the\nkey to actually putting these things into a\nlot of control systems.",
    "start": "1041290",
    "end": "1048189"
  },
  {
    "text": "So a lot of them\nactually do this. So OK, so that's\nthe big picture. So this is just super\ncool to know about.",
    "start": "1048190",
    "end": "1058659"
  },
  {
    "text": "OK. This brings us to a very\nfamous factorization. it's about 100 years old.",
    "start": "1058660",
    "end": "1065320"
  },
  {
    "text": "It's the Cholesky factorization. So if you have a\npositive definite matrix,",
    "start": "1065320",
    "end": "1071260"
  },
  {
    "text": "you can write it as\njust LL transpose. And if you insist that\nthe diagonal entries of L",
    "start": "1071260",
    "end": "1077389"
  },
  {
    "text": "are positive, then it's unique. So there's no choice. There's just one\nfactorization, period.",
    "start": "1077390",
    "end": "1084230"
  },
  {
    "text": "That's it. There's one way to\nwrite A as LL transpose. And how do you\nsolve Ax equals b,",
    "start": "1084230",
    "end": "1092540"
  },
  {
    "text": "where A is positive definite? That's called a positive\ndefinite system of equations. So how do you do that?",
    "start": "1092540",
    "end": "1097890"
  },
  {
    "text": "You do a Cholesky factorization. And you do a forward and a\nbackward substitution with L and L transpose, OK?",
    "start": "1097890",
    "end": "1104360"
  },
  {
    "text": "So that's it. And actually, it's 1/3 n\ncubed, as opposed to 2n cubed,",
    "start": "1104360",
    "end": "1109370"
  },
  {
    "text": "for general matrices. And that makes sense. Number one, no one\ncares about a factor",
    "start": "1109370",
    "end": "1114770"
  },
  {
    "text": "of 2 in a flop count\nestimate, because these are so crude, right? What really matters\nis the people",
    "start": "1114770",
    "end": "1121149"
  },
  {
    "text": "who actually wrote the microcode\nand all that kind of stuff. And how is it blocked? And how many cores is it\nusing, all sorts of crazy stuff",
    "start": "1121150",
    "end": "1127460"
  },
  {
    "text": "internal, that most of\nus don't-- all of us, I'm guessing, should not and\ndo not have to worry about.",
    "start": "1127460",
    "end": "1133620"
  },
  {
    "text": "Right? But we should, also,\nall be very grateful that there are people who do. Right?",
    "start": "1133620",
    "end": "1140210"
  },
  {
    "text": "Yeah, so it's a factor\nof 2, which is not unsurprisingly symmetric. So roughly speaking,\nthere's a redundancy of 2.",
    "start": "1140210",
    "end": "1146630"
  },
  {
    "text": "Or you can even look\nat this and say, hey, that's an LU factorization with\nU equals L. And why, you say?",
    "start": "1146630",
    "end": "1154177"
  },
  {
    "text": "Because the matrix is symmetric. That's why. So it's not too surprising.",
    "start": "1154177",
    "end": "1160160"
  },
  {
    "text": "We will see very shortly where\npositive definite systems",
    "start": "1160160",
    "end": "1165380"
  },
  {
    "text": "of equations arise. Actually, they\narise by themselves in a lot of applications. But specifically, in\nconvex optimization,",
    "start": "1165380",
    "end": "1173000"
  },
  {
    "text": "we'll see they're at the\nheart of a lot of stuff. OK? And now we get the sparse\nCholesky factorization.",
    "start": "1173000",
    "end": "1180049"
  },
  {
    "text": "And here, I'll tell\nyou something super interesting about it, I think. So here, it turns out\nthis is, basically,",
    "start": "1180050",
    "end": "1187220"
  },
  {
    "text": "the same as calling a Cholesky\nfactorization on P transpose AP because take that equation,\njust multiplying the left by P",
    "start": "1187220",
    "end": "1194540"
  },
  {
    "text": "transpose, on the right by\nP. So what it basically says is, permute your matrix, your\npositive definite matrix,",
    "start": "1194540",
    "end": "1201980"
  },
  {
    "text": "and then do a Cholesky\nfactorization, where there is no creativity. It's just there's a unique\nCholesky factorization.",
    "start": "1201980",
    "end": "1209140"
  },
  {
    "text": "Everybody got this? When you do that, you will\nfind some stunning things out. You will find out, that if\nyou choose a good permutation,",
    "start": "1209140",
    "end": "1218260"
  },
  {
    "text": "the L is going to\nbe super sparse. If you choose a bad permutation,\nit's going to be dense.",
    "start": "1218260",
    "end": "1225010"
  },
  {
    "text": "And I'll give you a\nfamous example of this. So it would be\nsomething like this.",
    "start": "1225010",
    "end": "1231790"
  },
  {
    "text": "If I gave you this matrix here--",
    "start": "1231790",
    "end": "1236960"
  },
  {
    "text": "so I'm going to draw. Here, I'll just\nmake it this way. So it's got first row and\ncolumn and a diagonal.",
    "start": "1236960",
    "end": "1243860"
  },
  {
    "text": "OK? So by the way, that's called\nan up-- what do they call it? It's an arrow matrix, right? Because if you\nblur your eyes, it",
    "start": "1243860",
    "end": "1250030"
  },
  {
    "text": "looks like an\narrow, or something. I don't know. Anyway, that's an\nupper arrow matrix. It's super sparse, right?",
    "start": "1250030",
    "end": "1256300"
  },
  {
    "text": "Number of non-zeros\nper row and column, except for the first row\nand column, it's two, right?",
    "start": "1256300",
    "end": "1262400"
  },
  {
    "text": "So OK, so that's an example of a\nstructure you should never ever",
    "start": "1262400",
    "end": "1269360"
  },
  {
    "text": "see again and not have an\nemotional response to ever, right? Because this is super important.",
    "start": "1269360",
    "end": "1275280"
  },
  {
    "text": "OK? So OK, if I do a Cholesky\nfactorization on that, here's--",
    "start": "1275280",
    "end": "1281090"
  },
  {
    "text": "I'm going to show you the\nsparsity pattern of L. It's this. Ready? It's completely dense,\nthere, completely dense.",
    "start": "1281090",
    "end": "1289169"
  },
  {
    "text": "OK? So this, of course,\nruins everything, right? For one thing, you can't\neven store that much, right?",
    "start": "1289170",
    "end": "1294680"
  },
  {
    "text": "Because if you\nstarted with a million by million upper arrow\nmatrix, called Cholesky",
    "start": "1294680",
    "end": "1300350"
  },
  {
    "text": "on it, at some point,\nyour OS would say, no, no, I am not\ngoing to allocate",
    "start": "1300350",
    "end": "1306620"
  },
  {
    "text": "that amount of memory, no. So everybody got this? OK. So now it turns out\nall you need to do",
    "start": "1306620",
    "end": "1312860"
  },
  {
    "text": "with this is permute the\nfirst and last columns,",
    "start": "1312860",
    "end": "1318507"
  },
  {
    "text": "first and last rows and columns. And then you end up\nwith this matrix. ",
    "start": "1318507",
    "end": "1324480"
  },
  {
    "text": "And that, that's called a-- I don't know. It's a whatever. That's called an arrow\nstructure, right?",
    "start": "1324480",
    "end": "1331537"
  },
  {
    "text": "We'll get to others. But anyway, that's one. OK, if I do a Cholesky\nfactorization on this,",
    "start": "1331537",
    "end": "1336690"
  },
  {
    "text": "I will show you the\nsparsity pattern you get. You get this, and\nthat's all, OK?",
    "start": "1336690",
    "end": "1345250"
  },
  {
    "text": "So what it means is-- it means that the permutation\nthat permuted this into this",
    "start": "1345250",
    "end": "1353350"
  },
  {
    "text": "was super important, at least\nfrom a sparsity point of view. OK, everybody got it? So what this means is, if\nyou had that set of equations",
    "start": "1353350",
    "end": "1361810"
  },
  {
    "text": "to solve-- actually, if you just call a\nsparse solver on your behalf,",
    "start": "1361810",
    "end": "1366997"
  },
  {
    "text": "you wouldn't even know it. But the permutation would\nchange it to this, factor that.",
    "start": "1366997",
    "end": "1372159"
  },
  {
    "text": "And then your factor time\nis going to be order n, and your solve time\nwill be order n.",
    "start": "1372160",
    "end": "1378865"
  },
  {
    "text": "Right? So everybody following this? So that's it. So fortunately for a lot\nof those things, You.",
    "start": "1378865",
    "end": "1385172"
  },
  {
    "text": "Don't have to worry about it. That's all based inside. All of you have benefited from\nthis probably a million times",
    "start": "1385172",
    "end": "1391530"
  },
  {
    "text": "just so far in this class. Because every time\nCVXPY calls a solver,",
    "start": "1391530",
    "end": "1396660"
  },
  {
    "text": "this is what's happening. This is the kind of\nstuff that's happening on your behalf, many,\nmany times, every time",
    "start": "1396660",
    "end": "1402030"
  },
  {
    "text": "you call solve on something. OK? So it doesn't matter. I mean, but just now you know.",
    "start": "1402030",
    "end": "1408520"
  },
  {
    "text": "OK, this make sense? Yeah? How much time does it\ntake for the solver",
    "start": "1408520",
    "end": "1414160"
  },
  {
    "text": "to find that piece, that step? That's a perfect question. I should have said it.",
    "start": "1414160",
    "end": "1419409"
  },
  {
    "text": "So the question is, how long-- so yeah, if I say, oh,\nman, are you kidding?",
    "start": "1419410",
    "end": "1424809"
  },
  {
    "text": "I can do this for\nyou, not a problem. I'm going to find a\npermutation like that, and then I can solve this\nin a tenth of a second.",
    "start": "1424810",
    "end": "1430040"
  },
  {
    "text": "And you go, cool. How long does it take you\nto find the permutation? You go, hmm, a couple of days. It's just not-- yeah, so\nthe general rule of thumb",
    "start": "1430040",
    "end": "1437740"
  },
  {
    "text": "is people use heuristics\nfor finding P that are,",
    "start": "1437740",
    "end": "1443200"
  },
  {
    "text": "they hope, on the order of\nmagnitude of the amount of time it takes to actually do the\nnumerical factorization.",
    "start": "1443200",
    "end": "1451500"
  },
  {
    "text": "So that's what they do. Now, there are applications\nwhere people will rum-- they'll take more time\nto actually work out",
    "start": "1451500",
    "end": "1459420"
  },
  {
    "text": "a better permutation\nbecause they're going to use this a gazillion times.",
    "start": "1459420",
    "end": "1464450"
  },
  {
    "text": "OK? So this would be the case\nfor embedded systems, like for control. Right? So if you're doing control, and\nyou're going to put this into,",
    "start": "1464450",
    "end": "1472029"
  },
  {
    "text": "let's say, a rocket,\nor something like that, and you know it's\ngoing to run at 100 hertz for the entire\nmission, or whatever",
    "start": "1472030",
    "end": "1479760"
  },
  {
    "text": "it is, that's a lot of time. You could definitely\ntake an evening",
    "start": "1479760",
    "end": "1485880"
  },
  {
    "text": "to come up with a\nbetter permutation. But this is not what\nmost people doing-- most people who\nwork on the solution",
    "start": "1485880",
    "end": "1494040"
  },
  {
    "text": "of sparse linear\nequations don't do that. They just stick with\nheuristics that are fast.",
    "start": "1494040",
    "end": "1499650"
  },
  {
    "text": "And by the way, that portion\nis called the symbolic-- sometimes, they call\nit the symbolic solve",
    "start": "1499650",
    "end": "1504960"
  },
  {
    "text": "or the permutation phase. There's lots of names for it. And you can tell.",
    "start": "1504960",
    "end": "1510130"
  },
  {
    "text": " If you actually look at it to\nsee what it's actually doing,",
    "start": "1510130",
    "end": "1517630"
  },
  {
    "text": "you will find out that it's\nspending a whole bunch of time. And it's doing\ngraph calculations.",
    "start": "1517630",
    "end": "1522669"
  },
  {
    "text": "There's no floating\npoint numbers involved. OK? And then when floating point\nnumber operations start up,",
    "start": "1522670",
    "end": "1528220"
  },
  {
    "text": "that means you're actually doing\nthe numerical factorization. So that's a good question.",
    "start": "1528220",
    "end": "1534160"
  },
  {
    "text": "OK. Now, I know I'm not able to-- I mean, I realize,\nfor many of you,",
    "start": "1534160",
    "end": "1539200"
  },
  {
    "text": "this is the first\ntime you've seen it. That's fine. You should just get the\nhigh-level picture of it. And you can read. There's a little bit more\nin the appendix in the book.",
    "start": "1539200",
    "end": "1546730"
  },
  {
    "text": "There's an appendix on this. And this is just something\nyou should know about. So I don't know, SCIPY.",
    "start": "1546730",
    "end": "1552187"
  },
  {
    "text": "You could poke around\nin SCIPY or something. Once you know about this,\nyou can't unknow about it. And you will have\nincredible powers.",
    "start": "1552187",
    "end": "1558490"
  },
  {
    "text": "Yes? What kind of heuristics? Well, so some are\nkind of greedy.",
    "start": "1558490",
    "end": "1566650"
  },
  {
    "text": "I'd have to tell you,\nactually, how you actually do the factorization to\nactually explain the heuristics.",
    "start": "1566650",
    "end": "1573050"
  },
  {
    "text": "But a lot of them are just\nconstructed one by one. What they do is they say, P\nis going to permute something",
    "start": "1573050",
    "end": "1579020"
  },
  {
    "text": "to the top row. And they'd say,\nI'm going to find which entry I should\npermute to the top,",
    "start": "1579020",
    "end": "1584420"
  },
  {
    "text": "then who gets permuted\nto the second top, then third top, and fourth\ntop, things like that.",
    "start": "1584420",
    "end": "1589550"
  },
  {
    "text": "But that's greedy. But that's the kind\nof things people use. And they have lots of\nnames, and it's worth knowing a little bit about them.",
    "start": "1589550",
    "end": "1595860"
  },
  {
    "text": "Yeah? So this wouldn't be hard\nfor finding the best one, but are there like approximation\nguarantees [INAUDIBLE]??",
    "start": "1595860",
    "end": "1600925"
  },
  {
    "text": "No, there's no approximation\nguarantees whatsoever, no. So yeah, no one has-- yeah.",
    "start": "1600925",
    "end": "1606410"
  },
  {
    "text": "So it's one of those\nthings where we can ask--",
    "start": "1606410",
    "end": "1611600"
  },
  {
    "text": "of course, these are\nall graph calculations. These are just these are just\nquestions about graphs, right?",
    "start": "1611600",
    "end": "1617600"
  },
  {
    "text": "Oh, there is one exception. There's one theory of it. That's this. If the graph represented by\nthe sparsity pattern of A",
    "start": "1617600",
    "end": "1624770"
  },
  {
    "text": "is chordal, then\nit turns out it's",
    "start": "1624770",
    "end": "1631630"
  },
  {
    "text": "guaranteed there exists\na permutation which has zero fill-in, meaning\nthe number of non-zeros in L",
    "start": "1631630",
    "end": "1637480"
  },
  {
    "text": "will be identical to the number\nof non-zeros in A divided by 2. So if you know what a chordal\ngraph, that's one of them.",
    "start": "1637480",
    "end": "1645760"
  },
  {
    "text": "That's actually useless,\nfrankly, in practice. Because the real question is\nnot whether there exists one. The question is whether\nour heuristics find it.",
    "start": "1645760",
    "end": "1652130"
  },
  {
    "text": "And the answer is, all decent\nheuristics will find that one. Yeah?",
    "start": "1652130",
    "end": "1658270"
  },
  {
    "text": "Do each of these\nfactorizations require that we know the matrix\nis non-singular, that it's",
    "start": "1658270",
    "end": "1663280"
  },
  {
    "text": "positive definite [INAUDIBLE]? So it turns out in\nthis one, to find",
    "start": "1663280",
    "end": "1669790"
  },
  {
    "text": "the permutation for\nCholesky factorization, you actually don't have to know\nthe entries in A. You simply",
    "start": "1669790",
    "end": "1675640"
  },
  {
    "text": "have to know their locations. That's actually a super\nimportant, more advanced. But you brought it up.",
    "start": "1675640",
    "end": "1682120"
  },
  {
    "text": "So what this means is we\ncan do this ahead of time. So for example, if we're solving\nan optimal control problem",
    "start": "1682120",
    "end": "1688010"
  },
  {
    "text": "or something like that,\nwe can do the permutation once and for all offline. And then when this\nthing is actually",
    "start": "1688010",
    "end": "1694430"
  },
  {
    "text": "running a jet engine\nor something like that, then we don't have to do it. If we're doing\nfinance, and we want",
    "start": "1694430",
    "end": "1699740"
  },
  {
    "text": "to do an insanely\nfast back test,",
    "start": "1699740",
    "end": "1704960"
  },
  {
    "text": "we'd first do the factorization. And then after that, every solve\nis going to be really fast.",
    "start": "1704960",
    "end": "1710760"
  },
  {
    "text": "So that's how that works, yeah. So you don't know. You don't have to know. If A is not positive\ndefinite, and you",
    "start": "1710760",
    "end": "1717650"
  },
  {
    "text": "call a Cholesky factorization on\nit, it will fail at some point. At some point, it's\ngoing to attempt",
    "start": "1717650",
    "end": "1722660"
  },
  {
    "text": "to take the square root of\na negative number, right? And then it'll throw an\nexception to you of some kind.",
    "start": "1722660",
    "end": "1733490"
  },
  {
    "text": "But that's the only time\nyou would ever know. Yeah? I'm just curious. When does the solver\nknow when to stop?",
    "start": "1733490",
    "end": "1740690"
  },
  {
    "text": "What kind of criterion? Oh, sorry. All of these are finite\nalgorithms, right? And an infinite precision,\nthey just solve.",
    "start": "1740690",
    "end": "1747440"
  },
  {
    "text": "Right? I mean, when I say it's order n\ncubed, it means I can tell you,",
    "start": "1747440",
    "end": "1752450"
  },
  {
    "text": "for this, you're\ngoing to do 1 billion blah, blah, blah multiplies,\n1.3 billion adds.",
    "start": "1752450",
    "end": "1759559"
  },
  {
    "text": "When it's done, OK,\nif you did everything in infinite precision, you would\nhave the answer, end of story.",
    "start": "1759560",
    "end": "1765540"
  },
  {
    "text": "There's no stopping criterion. There's nothing like that. Now, of course, you're doing\nthis in finite precision.",
    "start": "1765540",
    "end": "1773420"
  },
  {
    "text": "So since you asked, there\nare methods to do something. It's called\niterative refinement.",
    "start": "1773420",
    "end": "1779870"
  },
  {
    "text": "And what that does\nis you compute a solution that's approximate.",
    "start": "1779870",
    "end": "1784970"
  },
  {
    "text": "And then you can actually\ndo-- you can iterate to get a better solution. And people know about that.",
    "start": "1784970",
    "end": "1790310"
  },
  {
    "text": "But that's a little bit beyond\nwhat we're talking about here. But it's good to\nknow about, too. OK.",
    "start": "1790310",
    "end": "1797140"
  },
  {
    "text": "OK so LDL transpose\nfactorization,",
    "start": "1797140",
    "end": "1804470"
  },
  {
    "text": "this is any non-singular\nsymmetric matrix. By the way, we'll see examples\nof where these come up maybe",
    "start": "1804470",
    "end": "1811840"
  },
  {
    "text": "next week, in fact. So here, it's like an LDL\ntranspose factorization.",
    "start": "1811840",
    "end": "1818950"
  },
  {
    "text": "But D is diagonal, and it's\neither 1 by 1 or 2 by 2 blocks. So that's just a\nmathematical fact,",
    "start": "1818950",
    "end": "1824650"
  },
  {
    "text": "that you might need to\nhave these 2 by 2 blocks. But the point is those are all\neasily invertible matrices.",
    "start": "1824650",
    "end": "1830679"
  },
  {
    "text": "Permutations? Yes. Lower triangular? Yes. A block diagonal matrix with\n1 by 1 and 2 by 2 blocks,",
    "start": "1830680",
    "end": "1837220"
  },
  {
    "text": "I think we know\nhow to invert that. That one, we actually\nliterally know how to invert. But we can certainly solve\nequations like that, right?",
    "start": "1837220",
    "end": "1844330"
  },
  {
    "text": "So OK, so this is the LDL\ntranspose factorization.",
    "start": "1844330",
    "end": "1851950"
  },
  {
    "text": "And now we're going to\ntalk about something. This is something\nprobably many of you have seen in other contexts.",
    "start": "1851950",
    "end": "1857289"
  },
  {
    "text": "It comes up in pretty\nmuch all fields. So it's something\ncalled the Schur",
    "start": "1857290",
    "end": "1863590"
  },
  {
    "text": "complement, is the name of it. And I think you've already\nseen it early on in the class,",
    "start": "1863590",
    "end": "1870442"
  },
  {
    "text": "or something like that. But I can't think of\na legitimate field where it doesn't come up. So in statistics,\nit's conditioning,",
    "start": "1870442",
    "end": "1876940"
  },
  {
    "text": "a Gaussian on some\nentries, right? In mechanics, it's\nactually what happens when you impose the boundary\nconditions on something",
    "start": "1876940",
    "end": "1884110"
  },
  {
    "text": "and ask where\neverything else is. In electrical engineering,\nyou take a network. And I put a termination on some\nof the ports on the network.",
    "start": "1884110",
    "end": "1890540"
  },
  {
    "text": "And I ask, what's happening\nwith the rest of them? So all fields have this.",
    "start": "1890540",
    "end": "1896320"
  },
  {
    "text": "OK. And the idea is actually\nembarrassingly simple. So it goes like this.",
    "start": "1896320",
    "end": "1902419"
  },
  {
    "text": "We're going to\nwrite Ax equals b. We're going to block A\ninto some blocks, like A11.",
    "start": "1902420",
    "end": "1909250"
  },
  {
    "text": "And I'm going to have A11\nand A2b square, right? And I'll also conformally\nblock x and b.",
    "start": "1909250",
    "end": "1918529"
  },
  {
    "text": "So they're going to\nbe called x1 stacked on x2 and b1 stacked on b2. Right?",
    "start": "1918530",
    "end": "1923720"
  },
  {
    "text": "OK? Now, OK, nothing has happened. I just decided to\nname it this way.",
    "start": "1923720",
    "end": "1929700"
  },
  {
    "text": "So I just divided it\nin some weird way. OK. What happens now is\nyou do, actually--",
    "start": "1929700",
    "end": "1936799"
  },
  {
    "text": "I mean, you do what you\nlearned in maybe high school, except those were\nnumbers and not matrices.",
    "start": "1936800",
    "end": "1942380"
  },
  {
    "text": "And so what you do\nis we just work out. We can actually just\nsolve this in a weird way.",
    "start": "1942380",
    "end": "1947640"
  },
  {
    "text": "So the first equation,\nblock equation, is A11x1 plus A12x2 equals b1.",
    "start": "1947640",
    "end": "1955310"
  },
  {
    "text": "Right? And we're going to assume here. We're going to\nmake an assumption that A11 is invertible, OK?",
    "start": "1955310",
    "end": "1963019"
  },
  {
    "text": "So what that says is,\nwell, I can do this. This is minus A12x2, right?",
    "start": "1963020",
    "end": "1970250"
  },
  {
    "text": "That's that, right? And then I'll just put\nan A11 inverse here.",
    "start": "1970250",
    "end": "1977670"
  },
  {
    "text": "OK? So there we go, like that. OK.",
    "start": "1977670",
    "end": "1983300"
  },
  {
    "text": "Yeah, by the way, already\nwhen you see this, this is hinting that this\nis going to be interesting when A11 is easy to invert.",
    "start": "1983300",
    "end": "1990238"
  },
  {
    "text": "So that's going to be\nthe interesting part. OK, but we'll get there. OK, I plug this into\nthe second equation.",
    "start": "1990238",
    "end": "1996680"
  },
  {
    "text": "And the second equation is\nA21x1 plus A22x2 equals b2.",
    "start": "1996680",
    "end": "2005770"
  },
  {
    "text": "And I plug this\nexpression in here. And I'm going to get something\nlike A21A11 inverse times b1",
    "start": "2005770",
    "end": "2016540"
  },
  {
    "text": "minus A12x2 plus\nA22x2 equals b2.",
    "start": "2016540",
    "end": "2023440"
  },
  {
    "text": "Right? So make sense. OK. And then I just I rearrange\nthat to look like this equation",
    "start": "2023440",
    "end": "2031690"
  },
  {
    "text": "here. And that's another\nequation in x2.",
    "start": "2031690",
    "end": "2037030"
  },
  {
    "text": "This matrix here is famous. And it's called the\nSchur complement of the original matrix.",
    "start": "2037030",
    "end": "2042880"
  },
  {
    "text": "I can't remember if it's with\nrespect to the 11 or 22 block, but it's one of those two. And I don't remember\nwhich it is.",
    "start": "2042880",
    "end": "2048020"
  },
  {
    "text": "It doesn't matter. It's a Schur complement. OK? And you've probably seen it\nbefore or something in some--",
    "start": "2048020",
    "end": "2054649"
  },
  {
    "text": "yeah, anyway, that's It. OK. OK. OK, so you could use\nthese calculations",
    "start": "2054650",
    "end": "2064158"
  },
  {
    "text": "to solve the original thing. And that generic\nalgorithm looks like this. It says, first, you should\nform A11 inverse A12,",
    "start": "2064159",
    "end": "2071388"
  },
  {
    "text": "I mean, because that's this\nthing, and A11 inverse b1. Right? Oh, by the way, let's talk\nabout how we would do that.",
    "start": "2071389",
    "end": "2080638"
  },
  {
    "text": "So the way you would do that\nis you would factor A11, OK?",
    "start": "2080639",
    "end": "2085699"
  },
  {
    "text": "To compute this, you\nwould do a solve, right? Because you've factored\nit, and now you do a solve.",
    "start": "2085699",
    "end": "2092870"
  },
  {
    "text": "To calculate this, you do a\nsolve on each column of A12. Everybody got that?",
    "start": "2092870",
    "end": "2099170"
  },
  {
    "text": "So that could end\nup being quite-- that's quite efficient, right?",
    "start": "2099170",
    "end": "2104450"
  },
  {
    "text": "So if I were to double-click\non that and expand it,",
    "start": "2104450",
    "end": "2109900"
  },
  {
    "text": "it would look like this. Factor A11, then solve\nwith b1, and solve",
    "start": "2109900",
    "end": "2116359"
  },
  {
    "text": "with each column of A12, right? That gives me\nthese two matrices.",
    "start": "2116360",
    "end": "2121820"
  },
  {
    "text": "OK? Next step is I form S. That's\nthe Schur complement, which is this thing.",
    "start": "2121820",
    "end": "2127880"
  },
  {
    "text": "And I form this b\ntilde thing over here, which is the right-hand side\nof this equation, right?",
    "start": "2127880",
    "end": "2133760"
  },
  {
    "text": "So this equation up here\nis Sx2 equals b tilde. And then what I do is I find x--",
    "start": "2133760",
    "end": "2141200"
  },
  {
    "text": "here I do a factor on\nS, then a back solve. And then I can reassemble.",
    "start": "2141200",
    "end": "2147570"
  },
  {
    "text": "This gives me x2 directly, and\nI can get x1 from this equation here. And by the way, when\nI solve this equation,",
    "start": "2147570",
    "end": "2154289"
  },
  {
    "text": "I already factored A11. This is a solve, OK? Right?",
    "start": "2154290",
    "end": "2160590"
  },
  {
    "text": "OK, so that's the idea. OK, now's a drum roll to\nfind out, is this faster?",
    "start": "2160590",
    "end": "2167040"
  },
  {
    "text": "Is it better? And it's actually interesting.",
    "start": "2167040",
    "end": "2172450"
  },
  {
    "text": "So in step one,\nyou have f is going to be the factor cost for A11.",
    "start": "2172450",
    "end": "2179920"
  },
  {
    "text": "S is the solve cost. So in the first case,\nyou factor A11 once,",
    "start": "2179920",
    "end": "2186100"
  },
  {
    "text": "and then you solve for\nall the columns of A12. And so that's n2S.",
    "start": "2186100",
    "end": "2191860"
  },
  {
    "text": "So that's the cost of step one. Step two-- and here, that's\nactually just forming",
    "start": "2191860",
    "end": "2199380"
  },
  {
    "text": "the Schur complement matrix. And what we're\ngoing to do is we're going to imagine that\nthe Schur-- we're not",
    "start": "2199380",
    "end": "2205968"
  },
  {
    "text": "going to exploit any\nstructure in the Schur complement, although one could. But we're not going to. We're just going to\ntreat it as dense.",
    "start": "2205968",
    "end": "2211869"
  },
  {
    "text": "And then step three is going to\nbe n2 cubed because that's just",
    "start": "2211870",
    "end": "2217000"
  },
  {
    "text": "to factor and solve it. OK? And so the total is\nthis number up here. That's f plus n2S\nplus blah, blah, blah.",
    "start": "2217000",
    "end": "2223200"
  },
  {
    "text": "OK. All right, so let's just\nthrow in a general A11 and see what happens.",
    "start": "2223200",
    "end": "2228970"
  },
  {
    "text": "When you do, I mean, hardly\nsurprising, but actually, down to the flop,\nit's identical.",
    "start": "2228970",
    "end": "2234670"
  },
  {
    "text": "And congratulations,\nyou've done a bunch of algebra and analysis. And it did absolutely nothing.",
    "start": "2234670",
    "end": "2240910"
  },
  {
    "text": "OK? Oh, by the way, it does\nnothing in terms of flop count.",
    "start": "2240910",
    "end": "2246760"
  },
  {
    "text": "In reality, it does do things. So in fact, people use these\nblock, this block elimination",
    "start": "2246760",
    "end": "2252380"
  },
  {
    "text": "method. They actually use these\nfor dense matrices. And the reason is you\nwould choose n1 and n2,",
    "start": "2252380",
    "end": "2258160"
  },
  {
    "text": "so that one of\nthese solve methods could be done at some level\nof cash and therefore, done",
    "start": "2258160",
    "end": "2264069"
  },
  {
    "text": "quickly. So that actually happens,\nbut, again, all of us are blissfully unaware\nof those details.",
    "start": "2264070",
    "end": "2270620"
  },
  {
    "text": "So OK, now it gets interesting. It's interesting\nprecisely when f is small",
    "start": "2270620",
    "end": "2277060"
  },
  {
    "text": "compared to n1 cubed. So I'm going to\ngive you-- here's a great example is diagonal.",
    "start": "2277060",
    "end": "2284210"
  },
  {
    "text": "So the factor cost\nfor a diagonal is 0, I mean, whatever, or n,\nif you want to, whatever.",
    "start": "2284210",
    "end": "2290170"
  },
  {
    "text": "It doesn't matter. L is going to be\nthe matrix itself, and you will be\nthe identity there.",
    "start": "2290170",
    "end": "2295900"
  },
  {
    "text": "It's 0. OK?  So here, it's actually\nreally interesting.",
    "start": "2295900",
    "end": "2303030"
  },
  {
    "text": "You get 2n2 squared\nn1 plus 2/3 n. What's amazing about that\nis that's linear in n1.",
    "start": "2303030",
    "end": "2309780"
  },
  {
    "text": "So now I'm going to\nshow you some equation. I'll show you some\nsparsity patterns.",
    "start": "2309780",
    "end": "2315940"
  },
  {
    "text": "And here it is, one. Actually, I was just\nshowing you one. I had one right there. Here's one.",
    "start": "2315940",
    "end": "2322020"
  },
  {
    "text": "Remember this one? ",
    "start": "2322020",
    "end": "2327080"
  },
  {
    "text": "That's this downward\narrow pattern. Someone suggests\na blocking of it.",
    "start": "2327080",
    "end": "2333620"
  },
  {
    "text": "What would be A11? Do you see a leading matrix\nhere that is easy to invert?",
    "start": "2333620",
    "end": "2339890"
  },
  {
    "text": "Diagonal? Yeah, yeah, so here's A11. It looks like this, right?",
    "start": "2339890",
    "end": "2346150"
  },
  {
    "text": "It just looks like that, right? So this is A11, diagonal.",
    "start": "2346150",
    "end": "2351220"
  },
  {
    "text": "Actually, I was going\nto say, matrices don't come easier to\ninvert than diagonal. That's false.",
    "start": "2351220",
    "end": "2356720"
  },
  {
    "text": "Here's one that's easier, is\na multiple of the identity. That's pretty straightforward.",
    "start": "2356720",
    "end": "2362610"
  },
  {
    "text": "Actually, I think\nin terms of flops, it's the same anyway, so\nit doesn't even matter. But anyway, here it is.",
    "start": "2362610",
    "end": "2367770"
  },
  {
    "text": "OK, so here's one where\ninstead of this-- so n1 is, I don't know.",
    "start": "2367770",
    "end": "2373290"
  },
  {
    "text": "Let's suppose the\noriginal thing was n. It's n minus 1. And n2 is 1 because this\nthing is 1 by 1 down here.",
    "start": "2373290",
    "end": "2382000"
  },
  {
    "text": "And so in this\ncase, it turns out you're going to get a stunning\nreduction because you're",
    "start": "2382000",
    "end": "2388380"
  },
  {
    "text": "you can invert this fast. And in that case, you would get\nexactly this number over here.",
    "start": "2388380",
    "end": "2393630"
  },
  {
    "text": "You would get 2n2\nsquared n1, right? So OK, that's one example,\nbut I'll show you some others.",
    "start": "2393630",
    "end": "2402360"
  },
  {
    "text": "What it means is, what if you\nsaw a sparsity pattern that",
    "start": "2402360",
    "end": "2408570"
  },
  {
    "text": "looked like this? This is a banded.",
    "start": "2408570",
    "end": "2414540"
  },
  {
    "text": "And then over here,\nthese are dense. This is called dense\nrows and columns.",
    "start": "2414540",
    "end": "2420510"
  },
  {
    "text": "Everybody got that? So actually, it's just\na block arrow matrix, but with a thicker\nweight on the things.",
    "start": "2420510",
    "end": "2427920"
  },
  {
    "text": "Because they're wide, right? That's banded, and then\nthis is a whole chunk of stuff over here.",
    "start": "2427920",
    "end": "2433980"
  },
  {
    "text": "Everybody got that? So what this says is that this\nblock elimination method here",
    "start": "2433980",
    "end": "2439890"
  },
  {
    "text": "will solve that. Well, it's actually insane. It's actually going to be\nlinear in the dimension.",
    "start": "2439890",
    "end": "2446579"
  },
  {
    "text": "If this width, if this\ndoesn't grow this way,",
    "start": "2446580",
    "end": "2451780"
  },
  {
    "text": "and if the bandwidth\ndoesn't change, this gets bigger and\nbigger, and we can solve it. Right?",
    "start": "2451780",
    "end": "2456810"
  },
  {
    "text": "So anyway, it's\npretty cool, right? And that means, if you see\nthat, you should smile.",
    "start": "2456810",
    "end": "2465869"
  },
  {
    "text": "We'll put it that way. Or you're not going to see\nthat probably, because someone",
    "start": "2465870",
    "end": "2471420"
  },
  {
    "text": "would already have to know. But the way it's\nreally going to work is someone's going to be\ntalking about a problem.",
    "start": "2471420",
    "end": "2476638"
  },
  {
    "text": "It's going to be some\nweird, complicated problem. Who knows? It doesn't matter. They're going be talking\nabout some complicated thing.",
    "start": "2476638",
    "end": "2482290"
  },
  {
    "text": "While they're\ntalking, you will be forming in your mind\nwhat the sparsity pattern of the associated\nmatrices look like.",
    "start": "2482290",
    "end": "2489240"
  },
  {
    "text": "OK, when that image comes\nto mind, you will smile, and you will say, I can solve\nthat problem in half a second.",
    "start": "2489240",
    "end": "2498270"
  },
  {
    "text": "And they said, I can't\neven load it into memory. And you'd say, just\nchill, and I'll show you",
    "start": "2498270",
    "end": "2506319"
  },
  {
    "text": "what we're going to do, right? Everybody following this? So these are incredibly\nuseful things.",
    "start": "2506320",
    "end": "2512460"
  },
  {
    "text": "And we can think\nabout what this is. This is, basically, a set of\nequations where banded means",
    "start": "2512460",
    "end": "2520040"
  },
  {
    "text": "that equation 50 only\nreferences, let's say, variables 40 to 60.",
    "start": "2520040",
    "end": "2527770"
  },
  {
    "text": "OK? And that would be here. Then you say, but there are\nsome special variables here",
    "start": "2527770",
    "end": "2533440"
  },
  {
    "text": "which affect everybody. OK? So that that's what this is. So you're going to want\nto be making those--",
    "start": "2533440",
    "end": "2541380"
  },
  {
    "text": "so yeah, to be fully\ndeveloped, I would say, here's what you want. You want to be able to get\na feel for when applications",
    "start": "2541380",
    "end": "2550049"
  },
  {
    "text": "involve matrices\nthat look like that. Then you're going to be happy\nbecause you're going to know",
    "start": "2550050",
    "end": "2555500"
  },
  {
    "text": "something other people\nin the room don't. Because you're going to\nknow that you can solve that in linear time, right?",
    "start": "2555500",
    "end": "2561170"
  },
  {
    "text": "So that's why people\nwill say, like, oh I have to find\nthis whole trajectory. It's 100,000 time points.",
    "start": "2561170",
    "end": "2568640"
  },
  {
    "text": "And you're like, so? I mean, do you have\na phone, or whatever? It's just not going to be\nthat complicated, again,",
    "start": "2568640",
    "end": "2574470"
  },
  {
    "text": "if you know what you're doing. OK. OK. OK, so now this leads us to--",
    "start": "2574470",
    "end": "2583660"
  },
  {
    "text": "and this, probably\npeople have seen. It's got lots of names. It depends on where you're from.",
    "start": "2583660",
    "end": "2588710"
  },
  {
    "text": "I think it's called\nSherman-Morrison, Woodbury. Sometimes it's called\nthe Woodberry thing.",
    "start": "2588710",
    "end": "2594380"
  },
  {
    "text": "Sometimes it's called the\nmatrix inversion lemma. And I have a friend\nwho can actually",
    "start": "2594380",
    "end": "2599599"
  },
  {
    "text": "tell where someone learned their\nlinear algebra because they use different terms.",
    "start": "2599600",
    "end": "2605390"
  },
  {
    "text": "And they even use\ndifferent terms. I believe at Oxford and\nCambridge, just so you know. So just by asking\nsomeone what they",
    "start": "2605390",
    "end": "2612470"
  },
  {
    "text": "call this and a couple\nof other questions, you can figure out that\nthey got their PhD at Oxford or Cambridge, or something, or\nHarvard, or whatever, or MIT,",
    "start": "2612470",
    "end": "2619998"
  },
  {
    "text": "or something. OK, so here it is. You start with A plus\nBC times x equals b.",
    "start": "2619998",
    "end": "2630350"
  },
  {
    "text": "And in fact, some people call\nthis a low-rank perturbation",
    "start": "2630350",
    "end": "2636050"
  },
  {
    "text": "of A. I mean, that's not\nfair, because no one said B and C are small. Right?",
    "start": "2636050",
    "end": "2641210"
  },
  {
    "text": "But if B had just a\nhandful of columns, and C had a handful\nof rows, this",
    "start": "2641210",
    "end": "2646880"
  },
  {
    "text": "would indeed be\nwhat people would call low-rank update to A. OK?",
    "start": "2646880",
    "end": "2652500"
  },
  {
    "text": "So we want to solve a\nmatrix that looks like that. And in fact, an extreme\ncase would be things like--",
    "start": "2652500",
    "end": "2658680"
  },
  {
    "text": "here's one you hear all the\ntime, diagonal plus low rank. There, A is diagonal, and\nB and C are small, right?",
    "start": "2658680",
    "end": "2667260"
  },
  {
    "text": "So B has got a small\nnumber of columns. C has got a small\nnumber of rows.",
    "start": "2667260",
    "end": "2672270"
  },
  {
    "text": "That's super common. That's also\nsomething you will, I would hope, never ever forget,\ndiagonal plus low rank.",
    "start": "2672270",
    "end": "2679109"
  },
  {
    "text": "And it's all related. Here's how it's related.",
    "start": "2679110",
    "end": "2684328"
  },
  {
    "text": "Yeah, actually, let's\njust talk about this, in the case where\nA was diagonal, and B and C have modest\nnumber of columns.",
    "start": "2684328",
    "end": "2691910"
  },
  {
    "text": "So in fact, here's one. So basically, all of\nquantitative finance",
    "start": "2691910",
    "end": "2699140"
  },
  {
    "text": "uses a risk model where the\ncovariance matrix is diagonal plus low rank.",
    "start": "2699140",
    "end": "2704180"
  },
  {
    "text": "And it's called a factor model. So there, C is B transpose.",
    "start": "2704180",
    "end": "2709220"
  },
  {
    "text": "And if this were a\nGaussian, or something, if this is the covariance\nof a Gaussian--",
    "start": "2709220",
    "end": "2715549"
  },
  {
    "text": "if you understand what\nI'm saying, that's fine. If you don't, that's also cool. But this is just\ncompletely universal. Right? So what it would mean is it's\neven got a Bayesian model.",
    "start": "2715550",
    "end": "2723780"
  },
  {
    "text": "And it basically says that the\nreturns of all these assets",
    "start": "2723780",
    "end": "2729710"
  },
  {
    "text": "is driven by,\nlet's say, B and C. And typically, B is\nabout a width of 100. That would be very typical.",
    "start": "2729710",
    "end": "2736580"
  },
  {
    "text": "C would have a high-- well,\nC is B transpose, Right So you'd say, look, I don't know\nwhat these 8,000 returns are",
    "start": "2736580",
    "end": "2744810"
  },
  {
    "text": "doing, but they're mostly\ndriven by these 100 factors,",
    "start": "2744810",
    "end": "2751080"
  },
  {
    "text": "which are actually-- so\nthat's the underlying-- that's what's actually\ndriving the returns.",
    "start": "2751080",
    "end": "2757200"
  },
  {
    "text": "And then the A is diagonal. And they have a\nbeautiful name for it. It's called idiosyncratic. So that's the\nidiosyncratic risk.",
    "start": "2757200",
    "end": "2763860"
  },
  {
    "text": "It's the amount by which\nGoogle or whatever,",
    "start": "2763860",
    "end": "2768900"
  },
  {
    "text": "Coca-Cola or whatever it is,\nChevron, goes up and down. In fact, the way they would\nsay it, this is dialect,",
    "start": "2768900",
    "end": "2774690"
  },
  {
    "text": "is you'd say, that is the part\nof the variance not explained by the factors. Everyone got that?",
    "start": "2774690",
    "end": "2780540"
  },
  {
    "text": "So that's it. And the factors are actually\nkind of interesting. Sorry, this is\njust a weird aside. But since we're here,\nI'll just continue.",
    "start": "2780540",
    "end": "2786630"
  },
  {
    "text": "The factors are interesting. Some are handcrafted. So they're literally\nmatrices with 0s and 1s",
    "start": "2786630",
    "end": "2792627"
  },
  {
    "text": "and weird stuff like that. And what region are you in?",
    "start": "2792627",
    "end": "2799710"
  },
  {
    "text": "Are you a\npharmaceuticals company? Or you do defense, do you\ndo that kind of thing?",
    "start": "2799710",
    "end": "2806070"
  },
  {
    "text": "Others are actually\ncrafted by people using numerical algorithms. So OK, that's just a\nsmall story about this.",
    "start": "2806070",
    "end": "2813030"
  },
  {
    "text": "OK. Oh, if I have something that\nlooks like that, A is diagonal, and B and C are small, I\ncan store that, no problem.",
    "start": "2813030",
    "end": "2822430"
  },
  {
    "text": "Even for very big, if you\nwant to run a fund that is looking at a universe--",
    "start": "2822430",
    "end": "2828370"
  },
  {
    "text": "I'm using dialect--\nof, let's say, 100,000 assets across\nthe whole world,",
    "start": "2828370",
    "end": "2834700"
  },
  {
    "text": "I know people who do that. So you do that. So the covariance matrix is\n100,000 by 100,000 matrix.",
    "start": "2834700",
    "end": "2840580"
  },
  {
    "text": "For something like that,\nsomeone will say, well, what's your risk model? And they would say, oh, I\nhave a 200 factor model.",
    "start": "2840580",
    "end": "2849340"
  },
  {
    "text": "And that means their\ncovariance matrix is expressed as a diagonal\nmatrix, which is whatever",
    "start": "2849340",
    "end": "2855280"
  },
  {
    "text": "it is, 100,000 by 100,000. And then they have 200 factors.",
    "start": "2855280",
    "end": "2862360"
  },
  {
    "text": "And all of that is completely\nstorable, and stuff like that. And you'll see, in fact,\nnot only can you store, you can actually solve\nproblems super fast,",
    "start": "2862360",
    "end": "2868750"
  },
  {
    "text": "and things like that. OK, that was all a weird aside. So let's keep going. So now what you do here is\nsomething that is actually",
    "start": "2868750",
    "end": "2875780"
  },
  {
    "text": "a little bit unintuitive. It's called you uneliminate.",
    "start": "2875780",
    "end": "2882180"
  },
  {
    "text": "We did this before in duality,\nand it turned out well there. What you do, to\nuneliminate means",
    "start": "2882180",
    "end": "2887880"
  },
  {
    "text": "to introduce new variables. To eliminate variables\nmeans to solve for them,",
    "start": "2887880",
    "end": "2893125"
  },
  {
    "text": "get rid of them, And. Then substitute back their\nvalues into the rest. That's elimination.",
    "start": "2893125",
    "end": "2898180"
  },
  {
    "text": "Right? That sounds good, especially\nto an amateur or somebody first seeing this material. Because what are you doing?",
    "start": "2898180",
    "end": "2905620"
  },
  {
    "text": "So I'm eliminating some-- why? Because I like to solve\nsmaller sets of equations. I mean, everyone, like, it\nmakes perfect sense, right?",
    "start": "2905620",
    "end": "2913380"
  },
  {
    "text": "It's completely\nand totally wrong. That's not how you should\nbe doing linear algebra, but it does sound\ngood, and people",
    "start": "2913380",
    "end": "2919710"
  },
  {
    "text": "can fall for that, right? OK. Unelimination is the opposite. You say, thank you for\nyour set of equations.",
    "start": "2919710",
    "end": "2925230"
  },
  {
    "text": "If you don't mind, I'm going\nto introduce new variables and equations and\nmake it a bigger one. And someone's like,\nwhy would you do that?",
    "start": "2925230",
    "end": "2932901"
  },
  {
    "text": "Everyone see what I'm saying? You'd say, thank\nyou for your 1,000 by 1,000 set of equations. If you don't mind, I'm going\nto expand it to a 10,000",
    "start": "2932902",
    "end": "2939840"
  },
  {
    "text": "by 10,000 set of equations,\nif it's OK with you. And they would say, like, why?",
    "start": "2939840",
    "end": "2945880"
  },
  {
    "text": "And the answer is, you'll\nsee why in a minute. So we write this this way. We just introduce\na new variable,",
    "start": "2945880",
    "end": "2951440"
  },
  {
    "text": "which is y, which is Cx. And I write that second equation\nas this bottom row, which",
    "start": "2951440",
    "end": "2957550"
  },
  {
    "text": "is Cx minus y equals 0, right? So the second system\nof equations is bigger.",
    "start": "2957550",
    "end": "2964569"
  },
  {
    "text": "And it is completely equivalent\nto the first one, right? OK.",
    "start": "2964570",
    "end": "2969730"
  },
  {
    "text": "Now let's talk about this. When you see a matrix\nlike that-- you just",
    "start": "2969730",
    "end": "2976060"
  },
  {
    "text": "encountered all this so\nfar just a few minutes ago, so I don't expect you to\nhave this response now.",
    "start": "2976060",
    "end": "2981970"
  },
  {
    "text": "But hopefully,\nwithin a week or two, you should have the\nfollowing response.",
    "start": "2981970",
    "end": "2987400"
  },
  {
    "text": "You will see a block\nthere, a minus I, and your eye will go to\nit because it's really",
    "start": "2987400",
    "end": "2993880"
  },
  {
    "text": "easily inverted. And you're going to see a block. And you're going to\nhave an urge to do",
    "start": "2993880",
    "end": "2999790"
  },
  {
    "text": "block elimination on this. Right? And so what you would\ndo is you'd say, oh, I know what I'm going to do.",
    "start": "2999790",
    "end": "3006013"
  },
  {
    "text": "I'm going to permute the I,\nthe minus I, up to the top. And then I'm going to\nuse block elimination from the previous stuff.",
    "start": "3006013",
    "end": "3012600"
  },
  {
    "text": "Everybody got that? And then you eliminate it. And you will end\nup, then, forming",
    "start": "3012600",
    "end": "3018478"
  },
  {
    "text": "the Schur complement equations. And it will be A\nplus BCx equals b. So you'll be right\nback where you started.",
    "start": "3018478",
    "end": "3024490"
  },
  {
    "text": "OK. So here's what you do instead. You resist the urge here\nto eliminate the minus I,",
    "start": "3024490",
    "end": "3032460"
  },
  {
    "text": "even though it is a\nvery attractive target for elimination because\nit's easily inverted, right?",
    "start": "3032460",
    "end": "3037589"
  },
  {
    "text": "You resist that urge, and\ninstead, you eliminate A. And you will end up\nwith a Schur compliment",
    "start": "3037590",
    "end": "3044280"
  },
  {
    "text": "equation that looks like this. OK. And this allows you to get y.",
    "start": "3044280",
    "end": "3051440"
  },
  {
    "text": "Here, you solve for y. Then from that, you plug\nit back in and get x. And you end up with\na formula that's",
    "start": "3051440",
    "end": "3057223"
  },
  {
    "text": "called the matrix\ninversion lemma. That's the neutral version. It says that A plus BC inverse\nis this horrible formula",
    "start": "3057223",
    "end": "3064339"
  },
  {
    "text": "over here. Yeah, so that's it. This gets interesting\nif A is diagonal,",
    "start": "3064340",
    "end": "3071330"
  },
  {
    "text": "or something like that. Anyway, a lot of things\nwould come out of that.",
    "start": "3071330",
    "end": "3077660"
  },
  {
    "text": "How many people have seen matrix\ninversion lemma or something before, or some\nSherman-Morrison-Woodbury?",
    "start": "3077660",
    "end": "3084680"
  },
  {
    "text": "It's the same. OK. Any other names for it? I used to know at least\none or two others.",
    "start": "3084680",
    "end": "3091640"
  },
  {
    "text": "But anyway, anybody else\nknow another name for that? It's a thing in linear algebra.",
    "start": "3091640",
    "end": "3097640"
  },
  {
    "text": "And how you call it depends\non where you came from. So OK, OK, so I think,\nactually, I'll--",
    "start": "3097640",
    "end": "3105550"
  },
  {
    "text": "oh yeah, well,\nhere's an example. A diagonal and B\nand C are dense. This is basically, you're\ngoing to form D is A plus BC.",
    "start": "3105550",
    "end": "3119050"
  },
  {
    "text": "This is if you do it\nthe dumb way, right? You just write it out as a\ndense matrix, then solve.",
    "start": "3119050",
    "end": "3124839"
  },
  {
    "text": "In this case, then you get\nsomething that's Pn squared-- sorry, n cubed. And if you did it\nthe right way, you",
    "start": "3124840",
    "end": "3130750"
  },
  {
    "text": "get something\nthat's linear in n. And these make a big difference. ",
    "start": "3130750",
    "end": "3137630"
  },
  {
    "text": "But by the way, a\nlot of this stuff subsumes things that were taught\nin the '60s and '70s and '80s",
    "start": "3137630",
    "end": "3143900"
  },
  {
    "text": "and sometimes, in\nthe '90s by people who learned it from\npeople who learned it in the '60s and '70s. OK, so for example, if you\nteach a course on control,",
    "start": "3143900",
    "end": "3152960"
  },
  {
    "text": "you might-- I've done this. I haven't done it\nfor a long time. I won't do it again. But you go through\na long derivation",
    "start": "3152960",
    "end": "3159080"
  },
  {
    "text": "of what the Kalman filter is or\nhow to solve an optimal control problem, right? And it's very\nclever, and you have",
    "start": "3159080",
    "end": "3164930"
  },
  {
    "text": "little parts and this Bellman\nequation and blah, blah, blah. And yeah, you end up with\nstuff that actually works.",
    "start": "3164930",
    "end": "3170400"
  },
  {
    "text": "That's great. A very funny thing happens. If you simply take the\nproblem represented",
    "start": "3170400",
    "end": "3176780"
  },
  {
    "text": "by an optimal control\nproblem or a Kalman filter and just throw it at a\nsparse solver, guess what?",
    "start": "3176780",
    "end": "3183740"
  },
  {
    "text": "It'll be just as-- it'll do it. So basically, all\nof those lectures were useless, is\nwhat I'm saying,",
    "start": "3183740",
    "end": "3189555"
  },
  {
    "text": "as a practical matter, which\nis kind of embarrassing, but whatever. So I don't teach that anymore. So I don't teach it\nthat way anymore.",
    "start": "3189555",
    "end": "3195530"
  },
  {
    "text": "I just say, you get a giant\nset of linear equations, and you solve it\nusing sparse methods.",
    "start": "3195530",
    "end": "3204059"
  },
  {
    "text": "Done. That is the correct\nway to do it. It gives you a lot\nof stuff, right? So this is in a lot of fields.",
    "start": "3204060",
    "end": "3212970"
  },
  {
    "text": "I'm almost certain,\nin statistics, there would be many,\nmany papers written on if you had a factor model.",
    "start": "3212970",
    "end": "3218710"
  },
  {
    "text": "So that's a covariance matrix\nis diagonal plus low rank. And it would be all sorts of\nthings about very intensely",
    "start": "3218710",
    "end": "3224609"
  },
  {
    "text": "clever ways I could condition. Suppose I give you 80% of\nthe entries of a vector, and I said, please compute\nthe conditional means",
    "start": "3224610",
    "end": "3230850"
  },
  {
    "text": "of the other remaining ones? Everybody follow this? That's a conditional\nmean imputation task. Right?",
    "start": "3230850",
    "end": "3236250"
  },
  {
    "text": "So I'm sure there's\nwhole papers written on this and clever\nmethods for doing this.",
    "start": "3236250",
    "end": "3241780"
  },
  {
    "text": "And anyway, the answer is you\nform the covariance matrix, literally write down the\nequations you want to solve.",
    "start": "3241780",
    "end": "3249070"
  },
  {
    "text": "And then you do nothing but\npass it to a sparse solver. And it'll be just as fancy,\nprobably more general",
    "start": "3249070",
    "end": "3258060"
  },
  {
    "text": "than all those papers. So OK, it's\nembarrassing, but true. OK.",
    "start": "3258060",
    "end": "3263100"
  },
  {
    "text": "All right. So I'm not going\nto go into this. There's a whole lot\nmore I haven't told you",
    "start": "3263100",
    "end": "3269420"
  },
  {
    "text": "about linear algebra. But these are the main points. ",
    "start": "3269420",
    "end": "3275990"
  },
  {
    "text": "And right now, this\nis just hanging here. Now you just know\nabout linear algebra. But I promise in\nthe next week, we're",
    "start": "3275990",
    "end": "3282500"
  },
  {
    "text": "going to connect it to problems\nand to optimization problems. And that will have a\nconnection to applications.",
    "start": "3282500",
    "end": "3289910"
  },
  {
    "text": "And then you will start\nbeing able to listen to a problem, a practical\nproblem, and say,",
    "start": "3289910",
    "end": "3296029"
  },
  {
    "text": "I can solve that. I can solve that super fast. So everybody getting this?",
    "start": "3296030",
    "end": "3302420"
  },
  {
    "text": "So I mean, there's people\nwhere this is all they do. If you do scientific\ncomputation, this is a lot of\nthe stuff you do.",
    "start": "3302420",
    "end": "3308990"
  },
  {
    "text": "OK. So now we're going to start\nunconstrained minimization.",
    "start": "3308990",
    "end": "3315350"
  },
  {
    "text": "And like I say, we're building\nslowly up at the lowest level. Well, at the lowest\nlevel are computers,",
    "start": "3315350",
    "end": "3323030"
  },
  {
    "text": "compilers, microcode,\nthings like that, which we're not going to look at.",
    "start": "3323030",
    "end": "3328470"
  },
  {
    "text": "The bottom floor is what we just\ncovered, this linear algebra. Now, the next floor\nis, how do you solve",
    "start": "3328470",
    "end": "3335050"
  },
  {
    "text": "smooth, unconstrained problems? So we'll look at that first,\nand we'll build slowly up.",
    "start": "3335050",
    "end": "3343060"
  },
  {
    "text": "Then we'll get\nequality constraints. Then we'll pull in\ninequality constraints. And then we're there. So OK, so here's\nwhat it looks like.",
    "start": "3343060",
    "end": "3350410"
  },
  {
    "text": "We're going to minimize\na function f here that is-- we're\ngoing to assume it's smooth and twice continuously\ndifferentiable, right?",
    "start": "3350410",
    "end": "3359619"
  },
  {
    "text": "And we'll assume that is the\noptimal value is achieved,",
    "start": "3359620",
    "end": "3365375"
  },
  {
    "text": "so there's, at least,\nan optimal point. Right? Now by the way,\na lot of problems like that that we want\nto solve in this class,",
    "start": "3365375",
    "end": "3370840"
  },
  {
    "text": "problems you have already solved\ndon't satisfy this, right? If you did an L1\nfitting problem,",
    "start": "3370840",
    "end": "3377680"
  },
  {
    "text": "you would minimize the\nL1 norm of Ax minus b. And that doesn't count. That's not here, because\nthat's not differentiable.",
    "start": "3377680",
    "end": "3383500"
  },
  {
    "text": "OK. OK, so this is what\nwe're going to do. In general, except for a very\nimportant set of problems",
    "start": "3383500",
    "end": "3391910"
  },
  {
    "text": "we will see shortly, there\nare no analytical solutions to this. ",
    "start": "3391910",
    "end": "3398060"
  },
  {
    "text": "So instead, we're going\nto have iterative methods. And an iterative method\nis going to generate an x.",
    "start": "3398060",
    "end": "3405289"
  },
  {
    "text": "It's going to query\nsomething about f and then generate a new x, and\nso on, a new x and a new x. And what's going\nto happen is those",
    "start": "3405290",
    "end": "3411740"
  },
  {
    "text": "x's are going to converge\nto, hopefully, a solution of this problem.",
    "start": "3411740",
    "end": "3418790"
  },
  {
    "text": "And what we'll do is-- the typical thing\nyou're going to get is something like\nthis sequence is",
    "start": "3418790",
    "end": "3425860"
  },
  {
    "text": "going to have the\nfunction values converge to the optimal value. And another way to say\nit is that the gradient,",
    "start": "3425860",
    "end": "3432682"
  },
  {
    "text": "you're going to have\na sequence of points where the gradient gets\nsmaller and smaller. OK? And then when you deem\nit to be small enough--",
    "start": "3432682",
    "end": "3439940"
  },
  {
    "text": "you asked earlier about\nstopping criteria. Here you have stopping criteria. For the direct methods, you\ndon't have stopping criteria.",
    "start": "3439940",
    "end": "3446420"
  },
  {
    "text": "Well, it just stops. It's like after n\ncubed over 3 steps, you've got the Cholesky factor.",
    "start": "3446420",
    "end": "3452030"
  },
  {
    "text": "There is no stopping criterion. Here there is. OK. So we'll make some assumptions.",
    "start": "3452030",
    "end": "3460018"
  },
  {
    "text": "I don't want to get\ntoo technical about it, because it quickly gets\nboring, and stuff like that.",
    "start": "3460018",
    "end": "3465807"
  },
  {
    "text": "And by the way,\nthere's entire classes that cover nothing but this\nmaterial in hideous, full",
    "start": "3465807",
    "end": "3470900"
  },
  {
    "text": "mathematical detail. So I mean, they're interesting. But I don't know.",
    "start": "3470900",
    "end": "3476900"
  },
  {
    "text": "I think some people\ngrow out of it. Anyway, I'll stop here. OK, that's fine.",
    "start": "3476900",
    "end": "3483450"
  },
  {
    "text": "OK.  So we're going to assume that\nthe sublevel sets are closed.",
    "start": "3483450",
    "end": "3491170"
  },
  {
    "text": "And one condition for\nthat is pretty common, is that the function\nf is closed.",
    "start": "3491170",
    "end": "3496580"
  },
  {
    "text": "If you do convex analysis, which\nis the mathematics of convex optimization and convexity,\nthis is a central concept.",
    "start": "3496580",
    "end": "3503140"
  },
  {
    "text": "It just means that the\nepigraph is closed. Right? And one example would\nbe if you had a--",
    "start": "3503140",
    "end": "3511750"
  },
  {
    "text": "here are some examples\nof some closed functions. Log sum x, this is\nbecause the domain of this is anything, right?",
    "start": "3511750",
    "end": "3517810"
  },
  {
    "text": "So this would count here. Here's another one. This is weird because you might\nsay, but there's a constraint.",
    "start": "3517810",
    "end": "3524290"
  },
  {
    "text": "The constraint is that\nx lies in the interior of this polyhedron. Because otherwise, I mean,\nthere's-- so there's an",
    "start": "3524290",
    "end": "3530148"
  },
  {
    "text": "embedded constraint here. And you might say,\nno, I don't like that. But this one is perfectly good. All the sublevel\nsets are closed.",
    "start": "3530148",
    "end": "3535930"
  },
  {
    "text": "And the reason is that\nthe function value goes to infinity as you\napproach the boundary. So we'll get to that.",
    "start": "3535930",
    "end": "3542470"
  },
  {
    "text": "OK? OK. So these are\ntechnical conditions, I think, not super,\nduper important.",
    "start": "3542470",
    "end": "3548150"
  },
  {
    "text": " People sometimes\nassume something",
    "start": "3548150",
    "end": "3554330"
  },
  {
    "text": "like a minimum curvature, right? So what that says is, for\nexample, the minimum eigenvalue",
    "start": "3554330",
    "end": "3561080"
  },
  {
    "text": "of the Hessian is\nbigger than some number m, which is positive. Right? And that gives you a minimum\ncurvature to the function.",
    "start": "3561080",
    "end": "3568430"
  },
  {
    "text": "That will allow you to\nsay all sorts of things. Yeah, now, you can ask questions\nlike, how would you know",
    "start": "3568430",
    "end": "3578120"
  },
  {
    "text": "what the minimum curvature is? It's a good question, right? And the answer\nis, in most cases, you would have\nabsolutely no idea.",
    "start": "3578120",
    "end": "3584287"
  },
  {
    "text": "There are cases where you do. Oh, here's one. Let's say I do multinomial\nlogistic regression,",
    "start": "3584287",
    "end": "3591230"
  },
  {
    "text": "and I add quadratic\nregularization to it. Then I don't even\ncount the curvature",
    "start": "3591230",
    "end": "3598369"
  },
  {
    "text": "that comes from the multinomial\nlogistic regression loss. And just the quadratic\nregularization alone",
    "start": "3598370",
    "end": "3604880"
  },
  {
    "text": "gives me a minimum curvature. Everybody follow me? But these are rare. But that is an example,\nwhere you actually",
    "start": "3604880",
    "end": "3611250"
  },
  {
    "text": "would know a candidate value\nfor m, which is literally the--",
    "start": "3611250",
    "end": "3616860"
  },
  {
    "text": "it's going to be\nthe regularization-- the ridge regression parameter. OK.",
    "start": "3616860",
    "end": "3622110"
  },
  {
    "text": "So if this is the\ncase, then this says that f minus m times\nthe norm of x squared",
    "start": "3622110",
    "end": "3632130"
  },
  {
    "text": "is actually convex. And if you apply that, if you\nthen apply the basic convexity",
    "start": "3632130",
    "end": "3638309"
  },
  {
    "text": "formula to that, you'll\nfind out a really cool-- you get a strengthened--",
    "start": "3638310",
    "end": "3643330"
  },
  {
    "text": "I guess it's not\nJensen, whatever. This first part, up\nto here, that's true.",
    "start": "3643330",
    "end": "3648540"
  },
  {
    "text": "This is true for any\nconvex function, this part. That's the basic inequality.",
    "start": "3648540",
    "end": "3654360"
  },
  {
    "text": "What this says is, oh yeah? Well, it applies with\na little bit more. That's the minimum\ncurvature constraint, right?",
    "start": "3654360",
    "end": "3661530"
  },
  {
    "text": "So it strengthens\nthat basic inequality we saw six weeks ago,\nor whenever it was, seven weeks, ago, six, right?",
    "start": "3661530",
    "end": "3670300"
  },
  {
    "text": "OK. And this means all\nsorts of cool things. Because for example,\nI could minimize",
    "start": "3670300",
    "end": "3676050"
  },
  {
    "text": "both of these equations over y. On the left, I get P\nstar because it's just",
    "start": "3676050",
    "end": "3682350"
  },
  {
    "text": "the minimum of f of y. On the right, this is a\nquadratic function in y.",
    "start": "3682350",
    "end": "3687539"
  },
  {
    "text": "I set the gradient equal to 0. I minimize it, and you get\na number which is actually-- it's going to be--",
    "start": "3687540",
    "end": "3693210"
  },
  {
    "text": "anyway, you end up with\nsomething that looks like this. You end up with this\ninequality, right? And so this is cool\nbecause this says",
    "start": "3693210",
    "end": "3700839"
  },
  {
    "text": "that, if you wanted\na stopping criterion, you would run the algorithm. You'd evaluate the gradient.",
    "start": "3700840",
    "end": "3706550"
  },
  {
    "text": "And when the gradient gets\nsmall enough, you quit. And someone says,\nwhy are you quitting? And you'd say,\nwell, the gradient",
    "start": "3706550",
    "end": "3712540"
  },
  {
    "text": "is less than something. And they go, yeah, but\nhow far am I from optimal? And then you would\nsay, oh, good question. I can, actually bound it.",
    "start": "3712540",
    "end": "3718480"
  },
  {
    "text": "I can say that\nhere's how far you are from the optimal value, no\nmore than 1 over 2m times this. Of course, then,\nin general, someone",
    "start": "3718480",
    "end": "3724740"
  },
  {
    "text": "would say, how do you know m? And the answer is, you\ndon't, and blah, blah, blah. So OK, but this is\nthe justification",
    "start": "3724740",
    "end": "3733299"
  },
  {
    "text": "you would have for stopping\nwhen the gradient is small. OK.",
    "start": "3733300",
    "end": "3739750"
  },
  {
    "text": "So we'll say a little bit\nabout descent methods. These are super widely used.",
    "start": "3739750",
    "end": "3747610"
  },
  {
    "text": "And they all have--\nthere's a generic form. And it looks like this.",
    "start": "3747610",
    "end": "3752980"
  },
  {
    "text": "In each step of\na descent method, you're going to find\nsomething called delta x.",
    "start": "3752980",
    "end": "3758950"
  },
  {
    "text": "And that's called the step or\nthe search direction, here. And so basically, what\nhappens is, at iteration k,",
    "start": "3758950",
    "end": "3767590"
  },
  {
    "text": "you have xk. You make some queries to f\nabout what's the gradient,",
    "start": "3767590",
    "end": "3773200"
  },
  {
    "text": "or something like that. And then you form\nthis search direction. So you stop, and you\nask for directions. And it says, well, you're here.",
    "start": "3773200",
    "end": "3779710"
  },
  {
    "text": "You want to minimize. You should go that direction. That's delta x. That's this direction. Then what you do is you're\ngoing to go in that direction,",
    "start": "3779710",
    "end": "3786680"
  },
  {
    "text": "but an amount that you're\ngoing to then choose. And that amount is\nscaled by this factor t, which is positive.",
    "start": "3786680",
    "end": "3793210"
  },
  {
    "text": "And that's called, sometimes,\nthe step size or the step",
    "start": "3793210",
    "end": "3798320"
  },
  {
    "text": "length, even though\nit need not be-- it's not really the length\nunless the norm of the gradient is equal to 1, right?",
    "start": "3798320",
    "end": "3804500"
  },
  {
    "text": "But still, people call it the\nstep length or the step size or something like that. So OK, that's what you do.",
    "start": "3804500",
    "end": "3812450"
  },
  {
    "text": "And it turns out, if the\ndirection you move in",
    "start": "3812450",
    "end": "3817970"
  },
  {
    "text": "has a negative inner\nproduct with the gradient, then it turns out--",
    "start": "3817970",
    "end": "3823700"
  },
  {
    "text": "and if you choose the\nstep size correctly, the new point will actually\nhave a function value",
    "start": "3823700",
    "end": "3829062"
  },
  {
    "text": "less than the original point. That's good. That's called a descent method\nbecause you're descending,",
    "start": "3829062",
    "end": "3834470"
  },
  {
    "text": "and you end up with a\nfunction value that's lower. OK? So here's a generic\nversion of it.",
    "start": "3834470",
    "end": "3841280"
  },
  {
    "text": "To make this a real algorithm,\nwe have to fill in things. We have to figure out, how do\nyou find the descent direction?",
    "start": "3841280",
    "end": "3848530"
  },
  {
    "text": "And then we have\nto figure out, how do you choose the step length? Right? And that's the\nwhole thing, right?",
    "start": "3848530",
    "end": "3853717"
  },
  {
    "text": "And the stopping criterion could\nbe some norm of the gradient. Usually, it's not. Usually, it's something\nthat is computed",
    "start": "3853717",
    "end": "3859900"
  },
  {
    "text": "as a byproduct of these\ntwo steps in here. So this is going to be\nhundreds of different methods",
    "start": "3859900",
    "end": "3865300"
  },
  {
    "text": "with different names are going\nto have exactly this form. And they differ in, what's\nthe search direction?",
    "start": "3865300",
    "end": "3872600"
  },
  {
    "text": "And they differ in,\nwhat is the line search? OK? So that's the idea.",
    "start": "3872600",
    "end": "3880070"
  },
  {
    "text": "So for line searches,\nthere's a bunch. I mean, here's one.",
    "start": "3880070",
    "end": "3885575"
  },
  {
    "text": "One is an exact line search. That says, once you've\ndecided that you're here, and you're going\nin that direction,",
    "start": "3885575",
    "end": "3891440"
  },
  {
    "text": "you actually look\nat the function restricted to that ray. And then you look for the\npoint where along that ray,",
    "start": "3891440",
    "end": "3899390"
  },
  {
    "text": "you have the smallest value. That's called an\nexact line search. And you can do\nthis in some cases",
    "start": "3899390",
    "end": "3905020"
  },
  {
    "text": "where you can actually\nwork this out analytically, or you can compute it cheaply,\nor something like that.",
    "start": "3905020",
    "end": "3910430"
  },
  {
    "text": "So that's one place where\nyou might do this, right?",
    "start": "3910430",
    "end": "3915470"
  },
  {
    "text": "Another one, which\nsounds much cruder, is called a backtracking\nline search. And this has many,\nmany names, again,",
    "start": "3915470",
    "end": "3921690"
  },
  {
    "text": "depending on where\nyou came from. It's called an\nArmijo line search. It's got all sorts\nof names for it.",
    "start": "3921690",
    "end": "3927390"
  },
  {
    "text": "An Armijo condition is\nat least one of those. I forget what it is\nin Russian, but they have a different name for it. So there are lots of\ndifferent names for this.",
    "start": "3927390",
    "end": "3935986"
  },
  {
    "text": "So this has been\nrediscovered, I don't know, a couple hundred times. Here's the way it works.",
    "start": "3935987",
    "end": "3942240"
  },
  {
    "text": "It's called backtracking. And it goes like this. You start with t equals 1.",
    "start": "3942240",
    "end": "3947369"
  },
  {
    "text": "So you try x plus delta x. Then what you're\ngoing to do is you're",
    "start": "3947370",
    "end": "3952890"
  },
  {
    "text": "going to check whether\nf has gone down-- and this is critical-- enough. By the way, if it\nwent up, that's,",
    "start": "3952890",
    "end": "3961830"
  },
  {
    "text": "basically, that's\nreally bad, right? In fact, you can even\nbe out of domain. So that would be it went\nup a lot because it went up",
    "start": "3961830",
    "end": "3969150"
  },
  {
    "text": "to plus infinity. Right? So OK, so here's\nwhat this looks like. Here's t here.",
    "start": "3969150",
    "end": "3977190"
  },
  {
    "text": "Here is the function\nrestricted to t. This would be the exact\nline search number.",
    "start": "3977190",
    "end": "3985200"
  },
  {
    "text": "That's the exact step\nlength you would take. You would take this to\nminimize this, right? So the way this works is you\nlook at this basic inequality",
    "start": "3985200",
    "end": "3994060"
  },
  {
    "text": "here. That basic inequality\nis this line right here, this dashed line.",
    "start": "3994060",
    "end": "3999120"
  },
  {
    "text": "And what it says\nis, if I put alpha equals 1 in that equation, I\ncan reverse that inequality.",
    "start": "3999120",
    "end": "4005960"
  },
  {
    "text": "Because basically, when I\ncontinue this linear thing, this is a lower bound on this.",
    "start": "4005960",
    "end": "4011540"
  },
  {
    "text": "Right? So the actual function\nvalue could never be below this if the\nfunction is convex, right?",
    "start": "4011540",
    "end": "4018500"
  },
  {
    "text": "So here's what you do. We put an alpha in there, which\nis a number that's less than 1.",
    "start": "4018500",
    "end": "4025263"
  },
  {
    "text": "Actually, in fact, it's less\nthan 1/2 , for weird reasons. I mean, it turns\nout it's not going to matter what it is too much.",
    "start": "4025263",
    "end": "4031550"
  },
  {
    "text": "And then we degrade the slope\nby multiplying by alpha. So here, alpha is maybe a third.",
    "start": "4031550",
    "end": "4036829"
  },
  {
    "text": "I just made it up. And that would be this line. So if you take a really\nsmall step length,",
    "start": "4036830",
    "end": "4042890"
  },
  {
    "text": "you're definitely\nbelow this line. Because if you take a really\nsmall step length here, this is actually a\nreally good approximation",
    "start": "4042890",
    "end": "4048680"
  },
  {
    "text": "of how much the function\nis going to go down, right? And then the rule is you have\nto be below this dashed line,",
    "start": "4048680",
    "end": "4058040"
  },
  {
    "text": "this degraded predicted line. And so the way that\nworks is you might start here and query the\nfunction and find this value.",
    "start": "4058040",
    "end": "4065570"
  },
  {
    "text": "And you're above this. In fact, the most dramatic one\nis you'd start way out here. And you're over here.",
    "start": "4065570",
    "end": "4070730"
  },
  {
    "text": "And actually, when you do x\nplus delta x in that case, you actually have a higher value\nthan f of x Everybody see that?",
    "start": "4070730",
    "end": "4078109"
  },
  {
    "text": "So that would be a particularly\npoor choice of step length, right? So what you do, then,\nis you multiply this",
    "start": "4078110",
    "end": "4087110"
  },
  {
    "text": "by some factor beta. Beta is typically 1/2. People use that.",
    "start": "4087110",
    "end": "4092150"
  },
  {
    "text": "They use 0.1. So you simply say,\nOK, that was too much. So you go back by 1/2,\nand you land here.",
    "start": "4092150",
    "end": "4098299"
  },
  {
    "text": "You try this one. You get this value. It's less than this\nthing, and you accept it. So you take the\nfirst one you accept.",
    "start": "4098300",
    "end": "4104089"
  },
  {
    "text": "That's backtracking.  Now, you know that\nyour intuition--",
    "start": "4104090",
    "end": "4109469"
  },
  {
    "text": "actually, the story of a lot of\nthis unconstrained minimization is, I guess, there'll\nbe several times",
    "start": "4109470",
    "end": "4115890"
  },
  {
    "text": "when something you\nwould think is right is just wrong, completely wrong. So now I'll tell\nyou the first one.",
    "start": "4115890",
    "end": "4123036"
  },
  {
    "text": "You would look at\nthis, and you'd say, it's, obviously,\nclearly, it's better to do an exact line search.",
    "start": "4123037",
    "end": "4129060"
  },
  {
    "text": "That's totally obvious, right? Because you're\nactually minimizing the function along this line. Right?",
    "start": "4129060",
    "end": "4134160"
  },
  {
    "text": "This makes sense. And this crude thing\nthat stops when you've gotten some\nacceptable-- by the way, people",
    "start": "4134160",
    "end": "4140068"
  },
  {
    "text": "use numbers like\nalpha equals 0.01, meaning if you get even\njust the slightest decrease,",
    "start": "4140069",
    "end": "4146220"
  },
  {
    "text": "like, good, fine, thanks. We'll take it. So everybody see\nwhat I'm saying? So it looks very\nunsophisticated, right?",
    "start": "4146220",
    "end": "4154560"
  },
  {
    "text": "Anyway, all right, now I'll\ntell you the punch line. The punch line is, it\ndoesn't make any difference,",
    "start": "4154560",
    "end": "4160229"
  },
  {
    "text": "that in fact, exact\nline search is not only not better in practice. It's often worse.",
    "start": "4160229",
    "end": "4166729"
  },
  {
    "text": "And the simple\ndumb thing actually works just fine, thank you. This is not obvious, right?",
    "start": "4166729",
    "end": "4172490"
  },
  {
    "text": "So OK, now we get to a\ngradient descent method.",
    "start": "4172490",
    "end": "4179899"
  },
  {
    "text": "This is the simplest one. Remember, we had to\nchoose a direction. I mean, I would hope\nit would be the first--",
    "start": "4179899",
    "end": "4187210"
  },
  {
    "text": "it should be the first\nthing you would think of. Someone says, make me\nan iterative method.",
    "start": "4187210",
    "end": "4192640"
  },
  {
    "text": "I meant f. I meant x. And I evaluate f at that point. And I evaluate a gradient.",
    "start": "4192640",
    "end": "4197679"
  },
  {
    "text": "Now, gradient is pointing in the\ndirection of fastest increase of f. If I move in that direction,\nf goes up as fast as possible.",
    "start": "4197680",
    "end": "4205480"
  },
  {
    "text": "If I move in the negative\ngradient descent direction, f goes down as\nquickly as possible.",
    "start": "4205480",
    "end": "4211539"
  },
  {
    "text": "And not only would\nyou come up with this, but you'd also ask yourself,\nwhy would you do anything else?",
    "start": "4211540",
    "end": "4221060"
  },
  {
    "text": "I mean, you realize what--\nthink about if you didn't do the gradient method, what\nhappens is you arrive here,",
    "start": "4221060",
    "end": "4227270"
  },
  {
    "text": "and someone says, where's\nthe negative gradient? You go, that direction. You'd say, well,\nwhat does that mean? You go, if you go\nin that direction,",
    "start": "4227270",
    "end": "4233350"
  },
  {
    "text": "you're going to go down\nas quickly as possible. And you go, cool, which\nway do you recommend I go? And you go, um, that way.",
    "start": "4233350",
    "end": "4239920"
  },
  {
    "text": "You're like, what? Why would you recommend that? Anyway, you will\nshortly see why.",
    "start": "4239920",
    "end": "4245929"
  },
  {
    "text": "But it's non-intuitive. But we'll get to it. Anyway, so gradient method\nis the most intuitive one.",
    "start": "4245930",
    "end": "4251728"
  },
  {
    "text": "It looks like this. It doesn't matter what\nline search you use.",
    "start": "4251728",
    "end": "4257320"
  },
  {
    "text": "And here it is. And you can prove convergence\nof this and all that stuff. That's fine.",
    "start": "4257320",
    "end": "4262330"
  },
  {
    "text": "It turns out this is\noften unbelievably slow.",
    "start": "4262330",
    "end": "4267640"
  },
  {
    "text": "So in fact, we'll see what other\nsearch directions can actually dramatically improve this.",
    "start": "4267640",
    "end": "4272930"
  },
  {
    "text": "But this is slow, very weird. And we'll look at a\npicture to understand it. So I just take a quadratic.",
    "start": "4272930",
    "end": "4279350"
  },
  {
    "text": "It looks like this. And here are some level curves\nof the quadratic down here.",
    "start": "4279350",
    "end": "4284510"
  },
  {
    "text": "And gamma is a number-- oh, yeah, let's see. So gamma allows me to change the\neccentricity of the level sets,",
    "start": "4284510",
    "end": "4293000"
  },
  {
    "text": "right? So if gamma equals 1, this is\n1/2 x1 squared plus x2 squared.",
    "start": "4293000",
    "end": "4298640"
  },
  {
    "text": "Oh, yeah, by the way, what's\nthe gradient in that case? If the level sets are\njust circles, you're here,",
    "start": "4298640",
    "end": "4305619"
  },
  {
    "text": "what does the\ngradient look like? What is the gradient? ",
    "start": "4305620",
    "end": "4314160"
  },
  {
    "text": "In that case, this is actually--\nwell, I'll draw this even. It's fine. So here, here's your function.",
    "start": "4314160",
    "end": "4323260"
  },
  {
    "text": "Here are the level sets. Here's 0, right? These are level sets. You're here. The gradient points\ndirectly out like that,",
    "start": "4323260",
    "end": "4330929"
  },
  {
    "text": "and the negative\ngradient points directly towards 0, which\nis the minimizer. So if I asked you to minimize\nx1 squared plus x2 squared,",
    "start": "4330930",
    "end": "4340260"
  },
  {
    "text": "using the gradient method\nwith an exact line search, tell me about how well that\nalgorithm is going to work.",
    "start": "4340260",
    "end": "4345465"
  },
  {
    "text": " [? Very well. ?] Yeah, very well,\nin one step, right?",
    "start": "4345465",
    "end": "4351860"
  },
  {
    "text": "It's going to say,\nwhich way should I go? You say, steepest descent, which\njust happens, in this case,",
    "start": "4351860",
    "end": "4356960"
  },
  {
    "text": "to aim directly at the solution. Right? Then you do an exact line\nsearch, and it's game over.",
    "start": "4356960",
    "end": "4362608"
  },
  {
    "text": "Everybody got that? OK. But now, that makes sense. And in fact, someone who was\nproposing a gradient method",
    "start": "4362608",
    "end": "4370100"
  },
  {
    "text": "would say, yeah, look\nhow well that works. That's great. Why would you not do that? Why would you go in a\ncrazy direction like that?",
    "start": "4370100",
    "end": "4378620"
  },
  {
    "text": "Right? But we can actually\ncontrol the eccentricity by making gamma either\nreally big or really small.",
    "start": "4378620",
    "end": "4388400"
  },
  {
    "text": "And in this case,\nyou can actually work out analytically what\nthe iterates are, right?",
    "start": "4388400",
    "end": "4393727"
  },
  {
    "text": "And you get something\nthat looks like this. It's actually a very good\npicture to have in your mind. Of course, it's totally\nsilly because we don't care",
    "start": "4393728",
    "end": "4399738"
  },
  {
    "text": "about two-dimensional problems. We care about problems with\na minimum dimension of 200, 2,000, 20,000, 2 million.",
    "start": "4399738",
    "end": "4406130"
  },
  {
    "text": "But nevertheless, this\ngives you the picture. So here, this is when it's\njust slightly eccentric.",
    "start": "4406130",
    "end": "4412650"
  },
  {
    "text": "And here, these are\nthe level curves. And so the negative gradient\nis just simply the gradient.",
    "start": "4412650",
    "end": "4419010"
  },
  {
    "text": "These are orthogonal\nto the level curves. And it says, go\nin that direction. This is the minimum because\nwe're doing exact line search.",
    "start": "4419010",
    "end": "4426963"
  },
  {
    "text": "And then it says,\nwhich way should I go? And you go like that. So people refer to\nthis as zig-zagging.",
    "start": "4426963",
    "end": "4435080"
  },
  {
    "text": "We can make it arbitrarily bad. We can take gamma\nequals 1,000, and you'll",
    "start": "4435080",
    "end": "4441440"
  },
  {
    "text": "find out that this thing is\nbasically, going like this. And actually, I\nthink there's even",
    "start": "4441440",
    "end": "4446989"
  },
  {
    "text": "a name in Western optimization. It's called the Maratos Effect. But the other thing I like is\nit's just called zig-zagging.",
    "start": "4446990",
    "end": "4455119"
  },
  {
    "text": "Everybody got this? So by the way, when\nyou see this picture, you can figure out\nsome things immediately",
    "start": "4455120",
    "end": "4463219"
  },
  {
    "text": "that would be pretty good. Right? So if you're in EE\nor any other field, you would say, you're kind of\ngoing in the right direction,",
    "start": "4463220",
    "end": "4470720"
  },
  {
    "text": "on average. Right? I mean, the problem\nis you're just doing this weird thermal\nthing up and down like this.",
    "start": "4470720",
    "end": "4477020"
  },
  {
    "text": "Whereas, you want to\nreally be going that way. And so you'd say, you know what? You should run those\nsearch directions",
    "start": "4477020",
    "end": "4482929"
  },
  {
    "text": "through a low-pass\nfilter, or something. I mean, again, I'm\nspeaking dialect. Or if you do physics, you'd say,\nyeah, add some momentum to it,",
    "start": "4482930",
    "end": "4490860"
  },
  {
    "text": "or something like\nthat, or viscosity, add a viscosity term,\nso that then you'd",
    "start": "4490860",
    "end": "4497280"
  },
  {
    "text": "do something that\nwould go like that and head towards the solution. And those are all methods. We're not going to look at\nthose, but that's the idea.",
    "start": "4497280",
    "end": "4504630"
  },
  {
    "text": "OK. So even this baby\nexample tells us that-- oh, but actually, we get some\nreally good intuition here.",
    "start": "4504630",
    "end": "4512130"
  },
  {
    "text": "The gradient method\nworks really well when the sublevel\nsets of your function",
    "start": "4512130",
    "end": "4520290"
  },
  {
    "text": "have low condition\nnumber, or they're round. Because if they're round,\nthe negative gradient",
    "start": "4520290",
    "end": "4529000"
  },
  {
    "text": "points directly to the solution. And you're going to\ngo there quickly. If it has high condition\nnumber, or the sublevel sets",
    "start": "4529000",
    "end": "4537130"
  },
  {
    "text": "are weirdly squished out,\nlike this, that kind of thing is going to happen. Everybody got that?",
    "start": "4537130",
    "end": "4543610"
  },
  {
    "text": "So that's the picture here. I mean, that's actually a\nsuper important observation",
    "start": "4543610",
    "end": "4548708"
  },
  {
    "text": "because we're going to\nuse that-- that's actually the segue to, basically,\nThursday's topic.",
    "start": "4548708",
    "end": "4555850"
  },
  {
    "text": "OK, all right, so here's\njust some examples. This is a silly function\nthat's non-quadratic.",
    "start": "4555850",
    "end": "4565500"
  },
  {
    "text": "And this happens if you use\na backtracking line search. And here's an exact line search.",
    "start": "4565500",
    "end": "4570530"
  },
  {
    "text": "And you'd look at these two,\nand you'd go, like, well, I told you exact line\nsearch was way better. But this just\nshows you the idea.",
    "start": "4570530",
    "end": "4577190"
  },
  {
    "text": "But it shows you that in\nreal, non-real examples, you're actually getting\nthis Maratos or zigzagging",
    "start": "4577190",
    "end": "4582770"
  },
  {
    "text": "effect, right? And then we can look\nat that over here and see what that looks like.",
    "start": "4582770",
    "end": "4588570"
  },
  {
    "text": "So this looks like this, right?",
    "start": "4588570",
    "end": "4593840"
  },
  {
    "text": "And let me explain what this is. These are the iterations. This is a log scale telling you,\nactually, your suboptimality.",
    "start": "4593840",
    "end": "4602300"
  },
  {
    "text": "Right? And well, you see all sorts\nof weird things here, right?",
    "start": "4602300",
    "end": "4607820"
  },
  {
    "text": "The first thing is that,\nactually, between 0 and 100 iterations, for whatever reason,\nthe backtracking line search",
    "start": "4607820",
    "end": "4614990"
  },
  {
    "text": "was doing better. I don't know why, but it was. And this is common. So this is what it looks like.",
    "start": "4614990",
    "end": "4621550"
  },
  {
    "text": "The other thing you see\nis that this gets linear. And that's referred to\nas linear convergence.",
    "start": "4621550",
    "end": "4626850"
  },
  {
    "text": "But that's a weird\nuse of linear. Because it's linear on a log\nor a semi-log plot, right?",
    "start": "4626850",
    "end": "4636449"
  },
  {
    "text": "Because this is a log thing. What linear convergence here\nmeans is that each step you do,",
    "start": "4636450",
    "end": "4642810"
  },
  {
    "text": "each iteration reduces\nthe error by some factor. It's pretty small, frankly,\nbut we could work out",
    "start": "4642810",
    "end": "4649890"
  },
  {
    "text": "what it is, right? If you divided it by-- well, let's just\nsay that hit here.",
    "start": "4649890",
    "end": "4657720"
  },
  {
    "text": "To go from 1 to\n10 to the minus 4, that would take you\n170 iterations, right?",
    "start": "4657720",
    "end": "4663090"
  },
  {
    "text": "And that tells you\ntake 10 to the 4, and you take that\nto the 1/175 power.",
    "start": "4663090",
    "end": "4670050"
  },
  {
    "text": "And that tells you how much your\nerror gets smaller each step, right? So that tells you\nroughly what it is.",
    "start": "4670050",
    "end": "4677880"
  },
  {
    "text": "OK, so that's called\nlinear convergence. OK, I think maybe what\nwe'll do is I won't even",
    "start": "4677880",
    "end": "4685590"
  },
  {
    "text": "start the next section. But this is a good\nplace to stop.",
    "start": "4685590",
    "end": "4692110"
  },
  {
    "text": "And we'll continue next time. ",
    "start": "4692110",
    "end": "4700000"
  }
]
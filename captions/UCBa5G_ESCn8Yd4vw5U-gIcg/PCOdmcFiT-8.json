[
  {
    "start": "0",
    "end": "12527"
  },
  {
    "text": "I appreciate you having me here. And, yeah, I'm excited\nto talk with all of you today about how the\nfield of responsible AI",
    "start": "12527",
    "end": "20900"
  },
  {
    "text": "has a learning and\ndesign problem. So, as maybe no\nsurprise to many of you,",
    "start": "20900",
    "end": "27450"
  },
  {
    "text": "this is the obligatory first\nslide in a talk like this. Generative AI can lead\nto a variety of harms.",
    "start": "27450",
    "end": "33807"
  },
  {
    "text": "And these are just\nnewspaper headlines I grabbed in the couple of weeks\nbefore this of New York City",
    "start": "33807",
    "end": "40129"
  },
  {
    "text": "chatbot telling\nbusinesses to break the law, and a chatbot\nencouraging someone to kill the queen,\nand other incidents.",
    "start": "40130",
    "end": "49010"
  },
  {
    "text": "But this isn't new\nfor generative AI, as folks, like Safiya Noble,\nZiad Obermeyer, Joy Buolamwini,",
    "start": "49010",
    "end": "55950"
  },
  {
    "text": "Timnit Gebru, and others,\nhave argued for years, algorithms might amplify or\nintroduce biases in society.",
    "start": "55950",
    "end": "64510"
  },
  {
    "text": "And this isn't new even\nfor this current generation of machine learning. You can go back to the '90s\nwith Batya Friedman and Helen",
    "start": "64510",
    "end": "71200"
  },
  {
    "text": "Nissenbaum's work on bias\nin computing systems. So to address these\nissues of biases,",
    "start": "71200",
    "end": "78790"
  },
  {
    "text": "folks have developed responsible\nAI resources of various kinds. Some, you can see here, are of\nsoftware toolkits for fairness",
    "start": "78790",
    "end": "87759"
  },
  {
    "text": "analyzes or\ntransparency resources, like model cards\nand data sheets,",
    "start": "87760",
    "end": "93850"
  },
  {
    "text": "as well as some\norganizations like Microsoft, you can see here,\nthey've developed",
    "start": "93850",
    "end": "100090"
  },
  {
    "text": "processes for responsible AI. So this is a screenshot of\nMicrosoft's responsible AI",
    "start": "100090",
    "end": "106060"
  },
  {
    "text": "standard. And there are different\ngoals for fairness and other principles\nin responsible AI.",
    "start": "106060",
    "end": "113200"
  },
  {
    "text": "But it's not just\ntechnology companies, public sector organizations have\nalso developed responsible AI",
    "start": "113200",
    "end": "119400"
  },
  {
    "text": "processes. So this is an example\nfrom the US NIST, or National Institute for\nStandards and Technology.",
    "start": "119400",
    "end": "126759"
  },
  {
    "text": "And they developed an AI\nrisk management framework to govern, map, measure,\nand manage various risks",
    "start": "126760",
    "end": "133410"
  },
  {
    "text": "in AI development. So in some of my\nprior work, I've",
    "start": "133410",
    "end": "138630"
  },
  {
    "text": "developed some of these\nresponsible AI tools, and processes, and studied how\nAI practitioners, including",
    "start": "138630",
    "end": "145680"
  },
  {
    "text": "developers and others\ninvolved in AI development, use these tools as part of\ntheir development practices,",
    "start": "145680",
    "end": "153790"
  },
  {
    "text": "including some of the\norganizational tensions that impact how they address\nfairness in their processes.",
    "start": "153790",
    "end": "160799"
  },
  {
    "text": "However, in some\nof our prior work, and this is just an excerpt\nfrom one paper from 2022,",
    "start": "160800",
    "end": "166870"
  },
  {
    "text": "we found gaps in AI developer's\nknowledge and skills when working on fairness in AI.",
    "start": "166870",
    "end": "173980"
  },
  {
    "text": "So in this paper, we had 10\ndifferent AI product teams",
    "start": "173980",
    "end": "179420"
  },
  {
    "text": "go through what we thought was\na fairly straightforward process for fairness evaluations,\nusing a process and tool",
    "start": "179420",
    "end": "189739"
  },
  {
    "text": "that our team was developing. And we observed them go through\nthis fairness evaluation",
    "start": "189740",
    "end": "195470"
  },
  {
    "text": "process. But nearly every single team\nthat participated in that study",
    "start": "195470",
    "end": "200600"
  },
  {
    "text": "ran aground on one of the very\nfirst steps in that process.",
    "start": "200600",
    "end": "205620"
  },
  {
    "text": "And we include a quote\nhere from one participant, where, first, the teams were\nidentifying who should they",
    "start": "205620",
    "end": "215030"
  },
  {
    "text": "evaluate fairness for, as in,\nwhich groups of potential users might a model perform worse for?",
    "start": "215030",
    "end": "222470"
  },
  {
    "text": "And we heard over and over\nfrom participants in that study that they didn't feel equipped\nto answer that question.",
    "start": "222470",
    "end": "229640"
  },
  {
    "text": "And as this participant\nin that study said, well, we just want to be\ntold who we should think",
    "start": "229640",
    "end": "235629"
  },
  {
    "text": "about fairness and bias for. But as you can imagine, at\na large technology company, at the time, I was\nMicrosoft Research,",
    "start": "235630",
    "end": "242950"
  },
  {
    "text": "a company the size of Microsoft\nworking and deploying systems across dozens or hundreds\nof different countries even",
    "start": "242950",
    "end": "250660"
  },
  {
    "text": "and cultural contexts, this\nis a really difficult question to answer centrally.",
    "start": "250660",
    "end": "255860"
  },
  {
    "text": "And yet, the developers\nfelt unequipped to answer or sometimes even ask\nthat question themselves.",
    "start": "255860",
    "end": "263980"
  },
  {
    "text": "So this leads me\nto the first study that I'll talk about today. So given these kinds of gaps\nin AI developer's knowledge",
    "start": "263980",
    "end": "272320"
  },
  {
    "text": "about responsible AI\nor fairness and bias, in this study that we published\nat the FACT Conference",
    "start": "272320",
    "end": "279160"
  },
  {
    "text": "this year, we were exploring\nhow AI practitioners were learning about\nresponsible AI on the job.",
    "start": "279160",
    "end": "287110"
  },
  {
    "text": "And this is with a great\nteam of collaborators, including folks\nat Google Research and Shivani Kapania is now a\nPhD student at Carnegie Mellon.",
    "start": "287110",
    "end": "296560"
  },
  {
    "text": "So some context here. Responsible AI involves\nnew forms of work",
    "start": "296560",
    "end": "303580"
  },
  {
    "text": "that AI developers may\nnot be trained for. And there's been some\nevidence for this",
    "start": "303580",
    "end": "309010"
  },
  {
    "text": "from a number of\ndifferent studies, including the one\nthat I just mentioned that we published in 2022.",
    "start": "309010",
    "end": "316000"
  },
  {
    "text": "And in parallel,\nmany universities are developing tech\nethics courses.",
    "start": "316000",
    "end": "321950"
  },
  {
    "text": "Many of you may be familiar\nwith the embedded ethics program here. Shout out Benji and others.",
    "start": "321950",
    "end": "328509"
  },
  {
    "text": "There's been some great\nwork from Casey Fiesler at Colorado University,\nBoulder, surveying",
    "start": "328510",
    "end": "334750"
  },
  {
    "text": "some of these tech ethics\ncourses, trying to understand who is teaching ethics\nin the undergraduate",
    "start": "334750",
    "end": "340450"
  },
  {
    "text": "and graduate computer\nscience curriculum, how are they teaching\nit, how is it integrated with other\ncomputer science concepts.",
    "start": "340450",
    "end": "349000"
  },
  {
    "text": "And this work is\nincredibly important. It's really exciting. But if you're a\nworking AI developer,",
    "start": "349000",
    "end": "355750"
  },
  {
    "text": "you may not have taken that\ncourse in your training and you may not have\nthe time or inclination",
    "start": "355750",
    "end": "363750"
  },
  {
    "text": "to take courses\nfor fun after work.",
    "start": "363750",
    "end": "370170"
  },
  {
    "text": "And some more recent work\nfrom my collaborators. And I found that\nAI practitioners",
    "start": "370170",
    "end": "375539"
  },
  {
    "text": "are taking on extra work\nto educate their team members about responsible AI.",
    "start": "375540",
    "end": "381640"
  },
  {
    "text": "So former intern Chelsea\nWang, now postdoc at CMU, she found that UX\npractitioners, UX researchers",
    "start": "381640",
    "end": "390210"
  },
  {
    "text": "were teaching some of\ntheir teammates, data scientists, software\nengineers about harms",
    "start": "390210",
    "end": "397140"
  },
  {
    "text": "that they saw in user\nstudies, but this was not part of their job description.",
    "start": "397140",
    "end": "402690"
  },
  {
    "text": "This had to come out\nof time that they could devote to other things. And in another paper led by\na PhD student, Wesley Deng,",
    "start": "402690",
    "end": "413120"
  },
  {
    "text": "we were looking at this\ncross-functional collaboration, so how do teams from different\nroles, product managers,",
    "start": "413120",
    "end": "419400"
  },
  {
    "text": "software engineers, data\nscientists, UX researchers, social scientists, how\ndo they come together",
    "start": "419400",
    "end": "425629"
  },
  {
    "text": "to collaborate on fairness? And one of the challenges\nin that paper, we found,",
    "start": "425630",
    "end": "430830"
  },
  {
    "text": "was an issue of a shared\nlanguage, of people from different disciplinary\nboundaries talking past each other and needing\nto educate like, well,",
    "start": "430830",
    "end": "438990"
  },
  {
    "text": "what does fairness mean in\nmy field or in your area, and that thing.",
    "start": "438990",
    "end": "444393"
  },
  {
    "text": "So we were getting\nsome of this evidence that people were taking\non additional work.",
    "start": "444393",
    "end": "450020"
  },
  {
    "text": "So that's motivated\ntwo main research questions for this study. First, what and how\nare AI practitioners,",
    "start": "450020",
    "end": "459090"
  },
  {
    "text": "and I'll describe who I mean by\nthis, what are they currently learning about responsible AI?",
    "start": "459090",
    "end": "464510"
  },
  {
    "text": "And second, what are AI\npractitioners and a second group of what we in this paper called\nresponsible AI educators, what",
    "start": "464510",
    "end": "473830"
  },
  {
    "text": "are their goals and aspirations\nfor teaching and learning about responsible AI,\nand what challenges",
    "start": "473830",
    "end": "481510"
  },
  {
    "text": "get in the way of those goals? So to do this, we conducted\nsemi-structured interviews",
    "start": "481510",
    "end": "488020"
  },
  {
    "text": "with 40 participants\nfrom 16 companies, including AI practitioners and\nroles like software engineer,",
    "start": "488020",
    "end": "496760"
  },
  {
    "text": "program manager, UX\nresearcher, and others, as well as this group of what\nwe were calling responsible",
    "start": "496760",
    "end": "504039"
  },
  {
    "text": "AI or RAI educators not\nworking specifically in industry contexts, so not\nnecessarily university faculty.",
    "start": "504040",
    "end": "512710"
  },
  {
    "text": "Some of these folks, as you\ncan see in the roles here, had explicit job titles\nlike curriculum lead",
    "start": "512710",
    "end": "519669"
  },
  {
    "text": "or technical writer, but others\nwere taking this kind of work on informally in\naddition to their roles",
    "start": "519669",
    "end": "526319"
  },
  {
    "text": "as software engineers\nor program managers. And let me just\nsay here too, when",
    "start": "526320",
    "end": "532620"
  },
  {
    "text": "we think about the audiences\nfor these learning resources or trainings, in this paper,\nwe focused on AI practitioners,",
    "start": "532620",
    "end": "541210"
  },
  {
    "text": "including both developers of\nmachine learning or AI models, as well as developers of\napplications that those models",
    "start": "541210",
    "end": "548310"
  },
  {
    "text": "are embedded into. But there's a much larger\nset of potential audiences",
    "start": "548310",
    "end": "553800"
  },
  {
    "text": "for on the job learning about\nRAI, including third-party AI",
    "start": "553800",
    "end": "559470"
  },
  {
    "text": "applications, marketing,\nPR, how do they communicate, what AI can and can't do to the\npublic, corporate leadership,",
    "start": "559470",
    "end": "567060"
  },
  {
    "text": "and then broader audiences,\nmany of which are in, for instance, the tech ethics\ncourses and universities,",
    "start": "567060",
    "end": "572950"
  },
  {
    "text": "but community organizations,\ncivil society, public sector, policymakers. I think there's a large\nlandscape of potential audiences",
    "start": "572950",
    "end": "581940"
  },
  {
    "text": "for learning about\nresponsible AI that we did not\ninclude in this study. So we asked them a\ncouple of things,",
    "start": "581940",
    "end": "589820"
  },
  {
    "text": "focusing broadly on how\nthey learned and taught others about RAI, in what\nsettings, for what reasons,",
    "start": "589820",
    "end": "595800"
  },
  {
    "text": "what was more or less effective,\nwhat types of topics and skills did they teach or learn,\nwhich were harder and easier.",
    "start": "595800",
    "end": "603770"
  },
  {
    "text": "For the educators at least, how\ndid they develop those trainings or resources. How do they decide on\nthe learning objectives",
    "start": "603770",
    "end": "609710"
  },
  {
    "text": "or assessment. And then what did they want? What were the aspirations for\nlearning and teaching about RAI?",
    "start": "609710",
    "end": "617964"
  },
  {
    "text": "OK, so what did we find? First, what are practitioners\nlearning about responsible AI?",
    "start": "617965",
    "end": "624695"
  },
  {
    "text": "We did some analysis of some\nof these learning objectives and concepts.",
    "start": "624695",
    "end": "630149"
  },
  {
    "text": "Some are fairly high level\nconcepts, like recalling the company's principles\nfor responsible AI,",
    "start": "630150",
    "end": "636900"
  },
  {
    "text": "defining different\ndimensions like fairness, but others were more what we\nmight call procedural knowledge,",
    "start": "636900",
    "end": "644009"
  },
  {
    "text": "like can you compute a fairness\nmetric for a particular use case, like text classification,\nor can you create a data card",
    "start": "644010",
    "end": "653110"
  },
  {
    "text": "or model card? Those of you in the audience\nwho might have some education or learning science background\nmight notice a couple of things",
    "start": "653110",
    "end": "659653"
  },
  {
    "text": "here. First, we found that,\nbroadly, the resources helped people learn\nthese well-defined RAI",
    "start": "659653",
    "end": "668050"
  },
  {
    "text": "processes, like calculating\nmetrics for fairness, but far fewer were\ndesigned to help develop",
    "start": "668050",
    "end": "675160"
  },
  {
    "text": "skills to identify\nnew potential harms, or, ideally, proactively\ndesign generative",
    "start": "675160",
    "end": "681970"
  },
  {
    "text": "AI to avoid those harms\nfor new use cases. And in the second\nhalf of the talk, I'll talk a little bit more\nabout that proactive design",
    "start": "681970",
    "end": "688930"
  },
  {
    "text": "portion. But the other thing\nyou may notice is that many of the\nlearning objectives",
    "start": "688930",
    "end": "694510"
  },
  {
    "text": "that I mentioned focus on\nunderstanding and recall, which, those of you, again,\nwith an educational background",
    "start": "694510",
    "end": "700740"
  },
  {
    "text": "may be familiar with this\nBloom's taxonomy of cognition. There's critiques\nof this, and there's",
    "start": "700740",
    "end": "706620"
  },
  {
    "text": "other taxonomies you\nmight use, but most were focused on these\nbase levels of recall,",
    "start": "706620",
    "end": "712860"
  },
  {
    "text": "this definition or this fact,\nrather than applying that to new skills or use cases.",
    "start": "712860",
    "end": "718950"
  },
  {
    "text": "So how are developers\nlearning about responsible AI? There's a few\ndifferent modalities.",
    "start": "718950",
    "end": "725520"
  },
  {
    "text": "Some text-like\ndocumentation, notebooks, like Colab notebooks, toolkits,\ntraining videos, YouTube,",
    "start": "725520",
    "end": "733589"
  },
  {
    "text": "and, although this was rarer,\nsome collaborative learning settings, like\ndiscussion groups.",
    "start": "733590",
    "end": "739620"
  },
  {
    "text": "But we've identified a\nfew different pathways. So first was people adapting\nknowledge from other domains.",
    "start": "739620",
    "end": "746709"
  },
  {
    "text": "So participants shared\nhow they learned about ethics in their\ncourses, largely, outside of computer science.",
    "start": "746710",
    "end": "753450"
  },
  {
    "text": "One participant said, well,\nI was a health and social psychologist, so I learned\nabout ethics there. And that got me thinking\nabout responsible AI.",
    "start": "753450",
    "end": "760680"
  },
  {
    "text": "And now, in my current role,\nI brought that with me. And we heard this from others\nin city government, and ethics,",
    "start": "760680",
    "end": "766970"
  },
  {
    "text": "and education. But this relies\non learners being able to translate and apply\nwhat they learned in education,",
    "start": "766970",
    "end": "775910"
  },
  {
    "text": "or health care,\nor city government to their work building AI. And that application is a\nskill that many developers",
    "start": "775910",
    "end": "782960"
  },
  {
    "text": "may not have or might need\nto foster and cultivate. So the other key\npathway that we found",
    "start": "782960",
    "end": "791420"
  },
  {
    "text": "was that practitioners are\nforaging for RAI resources,",
    "start": "791420",
    "end": "796680"
  },
  {
    "text": "including searching internally\nin their own company's repositories, externally,\non social media,",
    "start": "796680",
    "end": "802560"
  },
  {
    "text": "and cobbling these resources\ntogether, stitching together a curriculum for themselves.",
    "start": "802560",
    "end": "808490"
  },
  {
    "text": "As numerous participants\nshared, well, it's more of a self-study\nof online resources.",
    "start": "808490",
    "end": "813810"
  },
  {
    "text": "There was no internal course. It's grassroots. You have to go out and find it. It's self-learning,\nno formal course.",
    "start": "813810",
    "end": "819510"
  },
  {
    "text": "And we heard this over\nand over, even from people whose companies\nwe later found out",
    "start": "819510",
    "end": "825140"
  },
  {
    "text": "did actually have trainings\nin responsible AI, but maybe they\ncouldn't discover them.",
    "start": "825140",
    "end": "830640"
  },
  {
    "text": "Maybe they were searching\nthe wrong keywords in their repositories,\nor it wasn't required,",
    "start": "830640",
    "end": "835970"
  },
  {
    "text": "or anything like that. And the other challenge here\nto this information foraging",
    "start": "835970",
    "end": "841040"
  },
  {
    "text": "is learners were finding\nresources, learning about ethics and responsible AI\nvia social media.",
    "start": "841040",
    "end": "848070"
  },
  {
    "text": "But we're often unclear,\nand many participants were concerned about the\nlegitimacy of those resources",
    "start": "848070",
    "end": "854930"
  },
  {
    "text": "or the creators seeing many\nAI influencers on social media and not really being\nsure if actually that",
    "start": "854930",
    "end": "861230"
  },
  {
    "text": "what they're saying is\ngrounded in research or facts. And the last\nlearning pathway, we",
    "start": "861230",
    "end": "868100"
  },
  {
    "text": "had some evidence\nfrom prior literature that learners are learning\nfrom their coworkers in structured settings,\nunstructured conversations.",
    "start": "868100",
    "end": "876000"
  },
  {
    "text": "And we had a follow-up study\nled by Jaemarie Solyst. She led a little\nbit of a deep dive",
    "start": "876000",
    "end": "882320"
  },
  {
    "text": "into how these informal\nsites for learning",
    "start": "882320",
    "end": "887330"
  },
  {
    "text": "happen, maybe, in a\ncode review setting. And software engineers\nare raising questions,",
    "start": "887330",
    "end": "893790"
  },
  {
    "text": "teaching each other, or learning\nto collaboratively together in these code reviews\nor reading groups.",
    "start": "893790",
    "end": "899480"
  },
  {
    "text": "Or as one participant said,\nwell, this AI image generation",
    "start": "899480",
    "end": "906529"
  },
  {
    "text": "model called Lensa launched on-- and there was this strike on\nInstagram and social media.",
    "start": "906530",
    "end": "912770"
  },
  {
    "text": "And they heard from their\nfamily protesting it. And that was what really\nraised their awareness",
    "start": "912770",
    "end": "917930"
  },
  {
    "text": "about the risks of AI. OK, as the second\npart, we wanted",
    "start": "917930",
    "end": "924050"
  },
  {
    "text": "to understand what were the\norientations towards responsible AI in these various\nlearning resources.",
    "start": "924050",
    "end": "931610"
  },
  {
    "text": "And in the paper, we get\nmore into the details. I encourage you to\nread it for more. But we talk about two main\nframings for responsible AI.",
    "start": "931610",
    "end": "941800"
  },
  {
    "text": "One is a computational framing,\nthis very technical approach. And some of you might\nbe familiar with some",
    "start": "941800",
    "end": "948300"
  },
  {
    "text": "of the work on fairness metrics. And I mentioned,\nat the beginning of the talk, some software\ntoolkits and libraries,",
    "start": "948300",
    "end": "954880"
  },
  {
    "text": "some of which I've\ncontributed to. I'm a maintainer for one\nopen source toolkit myself. So some of this critique,\nI take on as well.",
    "start": "954880",
    "end": "963250"
  },
  {
    "text": "But this pure technical approach\nto responsible AI or ethics,",
    "start": "963250",
    "end": "968710"
  },
  {
    "text": "despite knowing that they'll\nhave to go back and actually see, how were people affected\nby this system or model failure?",
    "start": "968710",
    "end": "977010"
  },
  {
    "text": "And this computational\norientation affected every part of\nthe educator's choices",
    "start": "977010",
    "end": "983250"
  },
  {
    "text": "for what were the learning\nobjectives, the goals? How did they encourage\nlearners to demonstrate mastery",
    "start": "983250",
    "end": "989990"
  },
  {
    "text": "over concepts? Assessment is one\nversion of this, but otherwise,\ndemonstrating mastery.",
    "start": "989990",
    "end": "995050"
  },
  {
    "text": "And then how do they teach it? So this kind of\ncomputational orientation. As one participant said,\nfor more technical things,",
    "start": "995050",
    "end": "1002600"
  },
  {
    "text": "we can just borrow from how\nother technical projects are assessed, calculate this group\nconditional true-positive rate",
    "start": "1002600",
    "end": "1008139"
  },
  {
    "text": "or what have you. But for this participant\nthey said, well, if we have more\nqualitative things, like how does this system\nimpact this community",
    "start": "1008140",
    "end": "1016450"
  },
  {
    "text": "different from another-- it's not a math test, as\nthis participant said. However, there are methods\nfrom the humanities",
    "start": "1016450",
    "end": "1023110"
  },
  {
    "text": "and the social\nsciences for assessing a less quantified concepts.",
    "start": "1023110",
    "end": "1030812"
  },
  {
    "text": "A quick question. Yeah, absolutely. Yeah. In their view, was\nit, oh, I've got",
    "start": "1030812",
    "end": "1036309"
  },
  {
    "text": "the measures, and the packages,\nand the methods, and that's it? Or were they aware that there\nwere things beyond that?",
    "start": "1036310",
    "end": "1041770"
  },
  {
    "text": "It's a great question. So I'll touch on it\na little bit later. But I would say, it's a mix.",
    "start": "1041770",
    "end": "1048079"
  },
  {
    "text": "I would say, for the most part,\na large number of participants were aware, yes, we\nwould love to do that,",
    "start": "1048079",
    "end": "1054670"
  },
  {
    "text": "but they themselves did not\nfeel like they had the training to develop assessments\naround qualitative concepts.",
    "start": "1054670",
    "end": "1064020"
  },
  {
    "text": "Going back to that\nissue I mentioned at the beginning of\nthe talk of teams not knowing which communities\nor demographic groups",
    "start": "1064020",
    "end": "1070919"
  },
  {
    "text": "might experience fairness\nharms for a particular system. There's maybe methods\nfrom sociology",
    "start": "1070920",
    "end": "1076950"
  },
  {
    "text": "or various other\nsocial sciences, but the educators\nthemselves, by and large,",
    "start": "1076950",
    "end": "1082710"
  },
  {
    "text": "had computer science training. This PA team was alluding\nto this themselves.",
    "start": "1082710",
    "end": "1089710"
  },
  {
    "text": "They were like, yeah, I\nknow how to assess somebody on calculating these\nvarious confusion matrices",
    "start": "1089710",
    "end": "1096240"
  },
  {
    "text": "or what have you, but\nthey didn't feel like they themselves-- there\nmight need to be a train the trainers situation.",
    "start": "1096240",
    "end": "1102090"
  },
  {
    "text": "On that [INAUDIBLE]. Do they view it as a problem? Initially, I think\nit would have just been like, oh, I'm an engineer.",
    "start": "1102090",
    "end": "1108000"
  },
  {
    "text": "I have to solve this problem. That's someone else's issue. Or are they like, I feel stuck? Yeah, it ranged.",
    "start": "1108000",
    "end": "1114540"
  },
  {
    "text": "And I'll touch on\nthis in a little bit. But there was a\nlot of recognition that there was a\nscope issue here,",
    "start": "1114540",
    "end": "1120290"
  },
  {
    "text": "that they knew\nthey were teaching these easy-to-teach concepts.",
    "start": "1120290",
    "end": "1126320"
  },
  {
    "text": "I keep going back to\nthe fairness metrics. I think the most indicative. But things like creating\nmodel cards or data sheets.",
    "start": "1126320",
    "end": "1132350"
  },
  {
    "text": "It's like, OK, we know\nhow to create a data sheet and we can teach people how to\ncreate a data sheet or a model card, but is that the same\nas really understanding why,",
    "start": "1132350",
    "end": "1141170"
  },
  {
    "text": "or what we're communicating,\nor, for instance, training data and whether that should go in? Some of these broader\nquestions, they",
    "start": "1141170",
    "end": "1147500"
  },
  {
    "text": "knew were important,\nbut maybe didn't know how to make the time,\neven for the educators,",
    "start": "1147500",
    "end": "1152640"
  },
  {
    "text": "make the time to teach,\nor for them to upskill on how they might convey that.",
    "start": "1152640",
    "end": "1158360"
  },
  {
    "text": "And then the other orientation. And I think, actually,\nthe aspirations I'll talk about in a second does\ntouch on both of these things.",
    "start": "1158360",
    "end": "1165549"
  },
  {
    "text": "So the other\norientation that we saw was what we call a\nprocedural orientation, where",
    "start": "1165550",
    "end": "1171220"
  },
  {
    "text": "in a lot of these trainings\nand learning resources, participants felt like they\nwere teaching their company's",
    "start": "1171220",
    "end": "1177370"
  },
  {
    "text": "responsible AI principles,\nor policies, or toolkits. And this participant describes\nit as a process objective like,",
    "start": "1177370",
    "end": "1184914"
  },
  {
    "text": "are you doing the\nprocess correctly rather than this\noutcome objective? And there was some\nambivalence in the paper,",
    "start": "1184915",
    "end": "1190910"
  },
  {
    "text": "we do get more into this in\ndetail, of participants sharing how, well, you might need to do\nthis to create culture change.",
    "start": "1190910",
    "end": "1198408"
  },
  {
    "text": "And, in fact, in some\nof my prior work too, we've tried to embed these\nproactive playbooks for fairness",
    "start": "1198408",
    "end": "1204279"
  },
  {
    "text": "evaluation of like, at this\nstage in problem formulation, ask these questions, do\nthese kinds of things.",
    "start": "1204280",
    "end": "1210340"
  },
  {
    "text": "At this stage in model training,\nask these questions, et cetera. ",
    "start": "1210340",
    "end": "1216460"
  },
  {
    "text": "Participants were ambivalent. On the one hand, if\nyou want to change the culture of\ndevelopment, you might",
    "start": "1216460",
    "end": "1221770"
  },
  {
    "text": "need to require those\nprocesses, and thus, teach those processes to\nget people to do them.",
    "start": "1221770",
    "end": "1227170"
  },
  {
    "text": "But participants\nraise concerns, this might lead to this very\nsanitized version of ethics,",
    "start": "1227170",
    "end": "1233730"
  },
  {
    "text": "where normative questions\nof what should or should not be designed are avoided\nin the first place.",
    "start": "1233730",
    "end": "1239940"
  },
  {
    "text": "For instance, things like\nmilitary applications or policing technologies.",
    "start": "1239940",
    "end": "1245160"
  },
  {
    "text": "Perhaps a fairness\nevaluation may not address the underlying\nroot issues at heart.",
    "start": "1245160",
    "end": "1251250"
  },
  {
    "text": "And so, for some participants,\nit's like, well, OK, we can follow our company's\npolicy or process,",
    "start": "1251250",
    "end": "1256360"
  },
  {
    "text": "but that might not actually help\nus raise these larger questions.",
    "start": "1256360",
    "end": "1263250"
  },
  {
    "text": "So given that this is how these\ntrainings and resources are framed, what do people\nwant out of this?",
    "start": "1263250",
    "end": "1269080"
  },
  {
    "text": "First, touching on\nquestion, there's a lot of desire to move beyond\njust the technical approaches,",
    "start": "1269080",
    "end": "1277950"
  },
  {
    "text": "to focus more on social and\ncultural elements of RAI. Some participants described\nthis as sociological,",
    "start": "1277950",
    "end": "1283899"
  },
  {
    "text": "anthropological\nangles, but this is beyond what many AI\ndevelopers were trained to do",
    "start": "1283900",
    "end": "1290320"
  },
  {
    "text": "or typically do. And I just want\nto shout out here to recent reports, one from\nthe Data and Society Institute",
    "start": "1290320",
    "end": "1296980"
  },
  {
    "text": "and the other for the Center\nfor Democracy and Technology on why AI governance needs\nsociotechnical expertise.",
    "start": "1296980",
    "end": "1304370"
  },
  {
    "text": "So I encourage you to read\nthese for a little bit more on suggestions on\nhow to bring in some",
    "start": "1304370",
    "end": "1309430"
  },
  {
    "text": "of these more sociological\napproaches into AI governance.",
    "start": "1309430",
    "end": "1314620"
  },
  {
    "text": "The other piece of this\nkind of understanding harms was people wanted\nto know, how do we",
    "start": "1314620",
    "end": "1319840"
  },
  {
    "text": "engage with communities\nto allow them to identify potential harms, understand what\nharms mean for them, ideally,",
    "start": "1319840",
    "end": "1327490"
  },
  {
    "text": "proactively co-design\nAI systems with them. And this is something that\na lot of participants, a lot of AI\ndevelopers, they knew",
    "start": "1327490",
    "end": "1333465"
  },
  {
    "text": "that they might want to do this,\nthey knew this was a good thing to do, but they didn't\nfeel like they had the skills for how to do this.",
    "start": "1333465",
    "end": "1340610"
  },
  {
    "text": "And I have a recent paper\nwith some collaborators from Microsoft, understanding\na little bit more",
    "start": "1340610",
    "end": "1345680"
  },
  {
    "text": "beyond just\nperformance disparities of language technologies,\nwhat those impacts might mean for speakers of\ndifferent language varieties.",
    "start": "1345680",
    "end": "1354140"
  },
  {
    "text": "So as one participant\nsaid, well, we have this risk assessment. We say these possible\nharms for these groups.",
    "start": "1354140",
    "end": "1359250"
  },
  {
    "text": "But we should bring people\nfrom those different groups in and co-design with them,\nrun evaluations with them,",
    "start": "1359250",
    "end": "1364919"
  },
  {
    "text": "diary studies, et cetera. And then the second\nbig aspiration here was building capacity\nfor responsible AI.",
    "start": "1364920",
    "end": "1372659"
  },
  {
    "text": "So what do I mean by this? Broadly, this means wanting\nto apply what they learned",
    "start": "1372660",
    "end": "1380210"
  },
  {
    "text": "for their AI applications. So you can think of this--",
    "start": "1380210",
    "end": "1386135"
  },
  {
    "text": "tech companies have these AI\nprinciples about fairness, or bias, or transparency, but\nthese are really high level.",
    "start": "1386135",
    "end": "1393720"
  },
  {
    "text": "And what that looks\nlike in, for instance, education might look\nvery different than what that looks like in health care\nor financial applications.",
    "start": "1393720",
    "end": "1401300"
  },
  {
    "text": "And that's just\nthe use case that also looks a lot different from\none cultural context to another.",
    "start": "1401300",
    "end": "1407920"
  },
  {
    "text": "And practitioners didn't\nfeel like they had the skills to apply what they learned\nat this high level,",
    "start": "1407920",
    "end": "1414830"
  },
  {
    "text": "this 10,000-foot level for their\nspecific products that were being used in all of these\ndifferent cultural contexts",
    "start": "1414830",
    "end": "1421750"
  },
  {
    "text": "and use cases, et cetera. We explored a little bit\nof this translation work in a follow-up paper\nthat presented, actually,",
    "start": "1421750",
    "end": "1427990"
  },
  {
    "text": "just a couple of weeks ago\nat the CSEW conference. But I think there's a lot\nbigger questions here around,",
    "start": "1427990",
    "end": "1433720"
  },
  {
    "text": "how do we build this\ncapacity for application, for translation?",
    "start": "1433720",
    "end": "1439990"
  },
  {
    "text": "As part of this, participants\nwanted customized trainings. OK, well, I'm working in the\nSouth Asian context or Latin",
    "start": "1439990",
    "end": "1448240"
  },
  {
    "text": "American context. What does responsible\nAI, what does fairness mean in this context? Can we get a customized\ntraining for this?",
    "start": "1448240",
    "end": "1454623"
  },
  {
    "text": "The educators, at least in\nthe technology companies, didn't feel like they either\nhad the time, or resources,",
    "start": "1454623",
    "end": "1460470"
  },
  {
    "text": "or capacity, or\nknowledge themselves to develop those\ncustomized trainings. But this is something\nthat was desired.",
    "start": "1460470",
    "end": "1467770"
  },
  {
    "text": "And then people wanted\nmore case studies, more scenarios, more examples. And we found, there was\na lot of toy examples",
    "start": "1467770",
    "end": "1475180"
  },
  {
    "text": "and a lot of the same examples,\nsame case studies that get reused over, and over, and\nover that might not actually",
    "start": "1475180",
    "end": "1480750"
  },
  {
    "text": "be relevant for their\nuse case or application. And they will say, in the\npaper, we talk more about it.",
    "start": "1480750",
    "end": "1485800"
  },
  {
    "text": "This issue of application,\nof learning about RAI at a high level is even more\nexacerbated for generative AI",
    "start": "1485800",
    "end": "1494429"
  },
  {
    "text": "models, where, ostensibly, a\nsingle pre-trained model can be used for a number of\ndifferent applications",
    "start": "1494430",
    "end": "1500730"
  },
  {
    "text": "and contexts, and so putting\nmore of the onus on the product team who's using that\npre-trained model",
    "start": "1500730",
    "end": "1506670"
  },
  {
    "text": "to do that ideation work of what\ndo harms look like in their use case.",
    "start": "1506670",
    "end": "1512070"
  },
  {
    "text": "So if this is what\nfolks wanted, we found organizational\npressures and tensions",
    "start": "1512070",
    "end": "1517790"
  },
  {
    "text": "that impacted these\naspirations, some that resonate with\nsome things that have been seen in prior work\naround RAI practices as well.",
    "start": "1517790",
    "end": "1525810"
  },
  {
    "text": "So despite educators,\non one hand, valuing collaborative learning,\ninterpersonal learning,",
    "start": "1525810",
    "end": "1532730"
  },
  {
    "text": "for instance, as\none educator said, well, these\nsociotechnical concepts,",
    "start": "1532730",
    "end": "1537860"
  },
  {
    "text": "like gender\ndiscrimination, is easier to learn in person through\nsocratic conversations, socratic dialogue than reading\na documentation in a software",
    "start": "1537860",
    "end": "1546169"
  },
  {
    "text": "library. But these educators\nfelt pressure to scale their\nlearning resources",
    "start": "1546170",
    "end": "1552860"
  },
  {
    "text": "and trainings, particularly\nat large technology companies. Scale is an implicit\nvalue, for better or worse,",
    "start": "1552860",
    "end": "1559559"
  },
  {
    "text": "of many technology\ncompanies, and this value was being replicated\neven within the educators",
    "start": "1559560",
    "end": "1565490"
  },
  {
    "text": "feeling like, well, these\nself-study courses, they scale, even if they're\nnot as effective.",
    "start": "1565490",
    "end": "1572230"
  },
  {
    "text": "Similarly, educators wanted to\ndevelop this more longitudinal curriculum of increasing\ndepth, but the learners",
    "start": "1572230",
    "end": "1578860"
  },
  {
    "text": "felt they had pressure\nto ship products quickly. So they wanted something,\na five-minute Tech Talk",
    "start": "1578860",
    "end": "1585549"
  },
  {
    "text": "or something. They could absorb\nit and then move on. And maybe that could lead to a\nmore engaged, deeper learning",
    "start": "1585550",
    "end": "1594399"
  },
  {
    "text": "experience. You might think of\nthe term a low floor, but a high ceiling, something\nthat could bring learners in,",
    "start": "1594400",
    "end": "1602179"
  },
  {
    "text": "engage them with a\nlittle teaser that starts them on this pathway.",
    "start": "1602180",
    "end": "1607520"
  },
  {
    "text": "But as I mentioned from\nthat information foraging, there really aren't many\nwell-structured pathways",
    "start": "1607520",
    "end": "1613240"
  },
  {
    "text": "for people to continue this\nlearning in more depth. And then finally,\neducators wanted",
    "start": "1613240",
    "end": "1619510"
  },
  {
    "text": "to foster mindsets rather\nthan prescriptive guidance.",
    "start": "1619510",
    "end": "1624770"
  },
  {
    "text": "But these organizational\npressures to ship products quickly, scale up\nquickly incentivized,",
    "start": "1624770",
    "end": "1632310"
  },
  {
    "text": "even from the learners,\nthis prescriptive guidance. So as one educator said, yeah,\ntheir learners are saying,",
    "start": "1632310",
    "end": "1639280"
  },
  {
    "text": "look, I have to get through\nour AI review process. Just tell me what\nthat thing is that I need to do so I can do it.",
    "start": "1639280",
    "end": "1645910"
  },
  {
    "text": "This very\ncompliance-oriented approach. But there's no\none answer to RAI. And some of the\nparticipants said,",
    "start": "1645910",
    "end": "1652290"
  },
  {
    "text": "there's no way to say just do\nthese six things on a checklist and then your model\nis going to be fair, and then you're all set.",
    "start": "1652290",
    "end": "1657620"
  },
  {
    "text": "So there was this\ncompeting demand of wanting to be told, how\ndo I get through our launch process, what is the most\nprescriptive guidance you can",
    "start": "1657620",
    "end": "1665850"
  },
  {
    "text": "give me versus educators\nsaying, well, we really want to foster these mindsets\nto allow people to reflect more",
    "start": "1665850",
    "end": "1672180"
  },
  {
    "text": "on their own. OK, so I'm going to\nmove a little bit more quickly through the\ndiscussion here,",
    "start": "1672180",
    "end": "1677400"
  },
  {
    "text": "but I encourage you\nto read the paper. This work has some implications\nfor the learning environments for RAI, including how the\nsites for learning impact",
    "start": "1677400",
    "end": "1684900"
  },
  {
    "text": "what is learned and how. If this is happening\nwithin large tech companies versus, perhaps, open\nsource platforms,",
    "start": "1684900",
    "end": "1692840"
  },
  {
    "text": "you might have some of this\nlearning embedded within them, informal sites for learning,\ncommunity-based learning that",
    "start": "1692840",
    "end": "1700010"
  },
  {
    "text": "might avoid this\nprocedural approach. You can squint and see if you're\na large technology company,",
    "start": "1700010",
    "end": "1706380"
  },
  {
    "text": "why you might want this\nprocedural orientation. Everybody has to go through\nthis review process. Let's teach them how\nto go through it.",
    "start": "1706380",
    "end": "1712583"
  },
  {
    "text": "But other sites for learning\nmight avoid that constraint. How do we design a\nmore sociotechnical",
    "start": "1712583",
    "end": "1719510"
  },
  {
    "text": "learning opportunities. So integrating these social and\ntechnical skills and concepts,",
    "start": "1719510",
    "end": "1725190"
  },
  {
    "text": "both in the learning\nobjectives, the ways of demonstrating mastery, and\nthe pedagogical approaches.",
    "start": "1725190",
    "end": "1731240"
  },
  {
    "text": "And then building off\nof that, how do we resist what [INAUDIBLE]\nGebru and others have called the hierarchy of\nknowledge in learning about RAI?",
    "start": "1731240",
    "end": "1739580"
  },
  {
    "text": "So in the paper, we\nget more into it. But how might we shift the\nprofessional norms, the identity",
    "start": "1739580",
    "end": "1745880"
  },
  {
    "text": "of what it means to\nbe an AI developer, or what some\nsociologists have called the epistemic culture\nfor AI development",
    "start": "1745880",
    "end": "1754000"
  },
  {
    "text": "towards responsible AI. Rather than decomposing\nresponsible AI into a separate thing\nfor other people",
    "start": "1754000",
    "end": "1760780"
  },
  {
    "text": "to do, how do we shift the\nculture of AI development? And in the paper, we\nraise some questions.",
    "start": "1760780",
    "end": "1769075"
  },
  {
    "text": "If and when this takes place\nwithin corporate contexts, this might be hard. But for the field as\na whole, how do we",
    "start": "1769075",
    "end": "1774820"
  },
  {
    "text": "develop these pedagogical\nprovocations to destabilize some of these more hegemonic values?",
    "start": "1774820",
    "end": "1779960"
  },
  {
    "text": "But I know that's\na meaty question. So happy to talk more\nwith folks later.",
    "start": "1779960",
    "end": "1785270"
  },
  {
    "text": "I encourage you to read the\npaper for more discussion. So I want to move to a\nsecond study that pulled out",
    "start": "1785270",
    "end": "1791650"
  },
  {
    "text": "some questions from\nthis work, including how we support this learning\nin situ, or in context,",
    "start": "1791650",
    "end": "1797720"
  },
  {
    "text": "and picked up that question\nof fostering mindsets, applying these concepts in\ndevelopment to meet learners",
    "start": "1797720",
    "end": "1805240"
  },
  {
    "text": "where they are. And this takes me\nto the next study I'll talk about today, around\nsupporting responsible AI",
    "start": "1805240",
    "end": "1813190"
  },
  {
    "text": "during prototyping processes. And this is work led by a\nformer intern, Jay Wang,",
    "start": "1813190",
    "end": "1819490"
  },
  {
    "text": "that we published at the CHI\nConference this past year. So I had an amazing\nproject team led by Jay,",
    "start": "1819490",
    "end": "1826420"
  },
  {
    "text": "along with some other folks. So, perhaps not surprising,\nnow developing AI applications",
    "start": "1826420",
    "end": "1834040"
  },
  {
    "text": "using LLMs is now easy. So thinking about what\nI was talking before about, oh, AI practitioners\nand that category",
    "start": "1834040",
    "end": "1841990"
  },
  {
    "text": "may not actually be stable. Who is an AI practitioner? Is it anybody who uses a AI\nstudio, or GPT playground,",
    "start": "1841990",
    "end": "1851500"
  },
  {
    "text": "or what have you to embed\nsome LLM into their tool",
    "start": "1851500",
    "end": "1857470"
  },
  {
    "text": "or application with an API? Maybe. If that's the case, then\ndeveloping these responsibly",
    "start": "1857470",
    "end": "1864059"
  },
  {
    "text": "is increasingly hard. So this is a quote from a\npaper five years ago now led",
    "start": "1864060",
    "end": "1870390"
  },
  {
    "text": "by Ken Holstein, where\nthey surveyed machine learning practitioners. This quote, \"You just have\nto put your model out there,",
    "start": "1870390",
    "end": "1877529"
  },
  {
    "text": "and then you know if there's\nfairness issues if someone raises hell.\" ",
    "start": "1877530",
    "end": "1883483"
  },
  {
    "text": "They did interviews as well. In that survey, they\nfound that nearly half of the 300 ML practitioners\nfound fairness issues",
    "start": "1883483",
    "end": "1890010"
  },
  {
    "text": "in their products. 99% of those who found\nissues found them",
    "start": "1890010",
    "end": "1896160"
  },
  {
    "text": "after deploying the models. And I would wonder, how\ndifferent is that today?",
    "start": "1896160",
    "end": "1903840"
  },
  {
    "text": "If we were to run the same\nsurvey five years later, how far have we come since then?",
    "start": "1903840",
    "end": "1911909"
  },
  {
    "text": "So I mentioned, at the\nbeginning of the talk, these responsible AI resources. In some prior work\nwith collaborators,",
    "start": "1911910",
    "end": "1918309"
  },
  {
    "text": "we analyzed 30 of these\nresponsible AI or AI ethics",
    "start": "1918310",
    "end": "1923360"
  },
  {
    "text": "toolkits, looking at different\nkinds of things about them. But one of the things\nwe saw was that most",
    "start": "1923360",
    "end": "1928880"
  },
  {
    "text": "were focused in downstream\ndevelopment phases like model training, testing,\ndeployment, and monitoring,",
    "start": "1928880",
    "end": "1936240"
  },
  {
    "text": "and far fewer on the\ndesign phases that",
    "start": "1936240",
    "end": "1941330"
  },
  {
    "text": "might be able to intervene\nbefore deployment. And there are some resources\naround design ethics,",
    "start": "1941330",
    "end": "1947460"
  },
  {
    "text": "but not specifically for AI. So our goal for\nthis study was, how do we support responsible\nAI, including this",
    "start": "1947460",
    "end": "1957559"
  },
  {
    "text": "learning through development? Maybe it's not a formal\ncourse or something, but how do we foster this\nmindset during the design phase?",
    "start": "1957560",
    "end": "1964110"
  },
  {
    "text": "So moving away from\nthis kind of development deployment towards ideation\nprototyping phases.",
    "start": "1964110",
    "end": "1971840"
  },
  {
    "text": "And these were bullets\nfrom the first half. But as I mentioned, most of\nthose learning resources focus--",
    "start": "1971840",
    "end": "1979570"
  },
  {
    "text": "or few of those\nlearning resources, rather, focus on design\nphases or design skills.",
    "start": "1979570",
    "end": "1984740"
  },
  {
    "text": "So that was motivating\nsome of the focus here. And in particular, on\nproactively designing",
    "start": "1984740",
    "end": "1990880"
  },
  {
    "text": "generative AI to avoid harms for\nnew use cases and new contexts.",
    "start": "1990880",
    "end": "1996880"
  },
  {
    "text": "So to do this, we started\nwith a formative study, a co-design study\nwith AI prototypers.",
    "start": "1996880",
    "end": "2003010"
  },
  {
    "text": "And this, again, may not be\na stable category of people, but these are\npeople who are using",
    "start": "2003010",
    "end": "2008760"
  },
  {
    "text": "Google's AI Studio, one of these\nLLM prototyping interfaces.",
    "start": "2008760",
    "end": "2014730"
  },
  {
    "text": "And we worked with them\nto generate and critique different design ideas to\nfoster this proactive ideation",
    "start": "2014730",
    "end": "2022710"
  },
  {
    "text": "about potential harms. We then used the API for\nthe AI incident database,",
    "start": "2022710",
    "end": "2031360"
  },
  {
    "text": "which is a repository of-- it was, at the time, 3,000 news\narticles about AI incidents,",
    "start": "2031360",
    "end": "2039230"
  },
  {
    "text": "and extracted the\nembeddings from those, and computed the\ncosine similarity.",
    "start": "2039230",
    "end": "2046220"
  },
  {
    "text": " You can read the paper\nfor more of the details, but to look, essentially, at the\nsimilarity between the prompt",
    "start": "2046220",
    "end": "2056419"
  },
  {
    "text": "and some of these headlines,\nsome of these news articles of AI incidents.",
    "start": "2056420",
    "end": "2061790"
  },
  {
    "text": "And I'll give you an example of\nwhat this might look like here. OK let's say you're using one\nof these prototyping tools,",
    "start": "2061790",
    "end": "2071179"
  },
  {
    "text": "maybe you have an idea\nfor a translation app, and you type in the\nsystem prompt here of the,",
    "start": "2071179",
    "end": "2077225"
  },
  {
    "text": "you are a good translator, with\ncaveats around how much detail you might provide, how you\nwould frame this, et cetera.",
    "start": "2077225",
    "end": "2084020"
  },
  {
    "text": "And you give some\nexamples of this. The tool, which we call\nFarsight, and you can read",
    "start": "2084020",
    "end": "2091010"
  },
  {
    "text": "or you can find more details\nthere along with a demo and the API for it at the link.",
    "start": "2091010",
    "end": "2099070"
  },
  {
    "text": "Then computes that\ncosine similarity between the prompt translation\napp and these AI incidents",
    "start": "2099070",
    "end": "2106480"
  },
  {
    "text": "from the AI incident database\nto pull in related news articles about, in this\nexample, translation failures",
    "start": "2106480",
    "end": "2114069"
  },
  {
    "text": "and suggest some potential\nuse cases generated, again,",
    "start": "2114070",
    "end": "2119240"
  },
  {
    "text": "based off of those embeddings\nfor potential misuses of this tool, again, all with\nthe goal to foster this mindset,",
    "start": "2119240",
    "end": "2128059"
  },
  {
    "text": "foster this ideation\nabout what could go wrong early in this prototyping\nphase before any product has",
    "start": "2128060",
    "end": "2136839"
  },
  {
    "text": "been built, or\nlaunched, or deployed. And then there's an interactive\ntree visualization here.",
    "start": "2136840",
    "end": "2144910"
  },
  {
    "text": "The tool, Farsight,\nsuggests use cases, suggests different stakeholder\ngroups or different groups who",
    "start": "2144910",
    "end": "2151059"
  },
  {
    "text": "might be impacted by this model,\nand suggests potential harms based off of a harms taxonomy\nfrom Renee Shelby, et al,",
    "start": "2151060",
    "end": "2160270"
  },
  {
    "text": "a systematic review of\nsociotechnical algorithmic harms.",
    "start": "2160270",
    "end": "2166109"
  },
  {
    "text": "Now, so, yeah, this\nis the tool here. And again, I encourage\nyou to check out the demo",
    "start": "2166110",
    "end": "2172830"
  },
  {
    "text": "and read the paper\nfor more details. But we wanted to\nunderstand how this",
    "start": "2172830",
    "end": "2177900"
  },
  {
    "text": "was changing the AI prototyper's\nability and approach",
    "start": "2177900",
    "end": "2183359"
  },
  {
    "text": "to identifying these harms. So we did not want this tool\nto replace that harm ideation,",
    "start": "2183360",
    "end": "2188830"
  },
  {
    "text": "we wanted it to augment\npeople developing these tools. Again, thinking about this\nfrom a learning perspective,",
    "start": "2188830",
    "end": "2194380"
  },
  {
    "text": "how do we foster this\nharm-envisioning early on in the design process.",
    "start": "2194380",
    "end": "2200170"
  },
  {
    "text": "And we had 42 such participants\nwith different familiarity with responsible AI and with\nlanguage model prototyping.",
    "start": "2200170",
    "end": "2209563"
  },
  {
    "text": "And we were looking\nat how this affected their ability and their\napproach to this harm ideation, as well as how effective it\nwas, and the challenges they ran",
    "start": "2209563",
    "end": "2217290"
  },
  {
    "text": "into. So we ran a between and\nwithin subject study.",
    "start": "2217290",
    "end": "2222840"
  },
  {
    "text": "I'll move a little bit\nmore quickly for time, but you can read the\npaper for more details. But we had a couple of\ndifferent conditions.",
    "start": "2222840",
    "end": "2229500"
  },
  {
    "text": "One, we had participants use\nthe full tool that I displayed. One, we were like,\nall right, that's",
    "start": "2229500",
    "end": "2235350"
  },
  {
    "text": "a lot of information\nto display at any time. So we had a light version,\nwhich was just the related news",
    "start": "2235350",
    "end": "2241380"
  },
  {
    "text": "articles, called Farsight Lite. And then the\nenvisioning guide, we",
    "start": "2241380",
    "end": "2246869"
  },
  {
    "text": "thought about that as our\ncontrol or the status quo, which is basically like a PDF\nof this harms taxonomy, of here",
    "start": "2246870",
    "end": "2254760"
  },
  {
    "text": "are the broad\ncategories of harms. And we wanted to\nsee, as I mentioned,",
    "start": "2254760",
    "end": "2259960"
  },
  {
    "text": "how does that affect\npeople's ability to do this independently? So we structured this like\nwe would a learning task.",
    "start": "2259960",
    "end": "2266890"
  },
  {
    "text": "We had a pre-task, where\nwe had them independently try to identify as\nmany possible harms",
    "start": "2266890",
    "end": "2273910"
  },
  {
    "text": "to different stakeholder\ngroups for a given application. Then we gave them\neither the intervention",
    "start": "2273910",
    "end": "2280360"
  },
  {
    "text": "of various kinds or the control. And then we had a similar\nwhat's called isomorphic task,",
    "start": "2280360",
    "end": "2285799"
  },
  {
    "text": "similar kind of post-task. Again, independently. We had an interview at the end.",
    "start": "2285800",
    "end": "2291290"
  },
  {
    "text": "And then because we wanted also\nto do this within subject study, for some groups, we gave\nthem a different condition",
    "start": "2291290",
    "end": "2298900"
  },
  {
    "text": "as well afterwards\nto compare, and then had another\ninterview at the end.",
    "start": "2298900",
    "end": "2305560"
  },
  {
    "text": "So at a high level, we found\nthat after using Farsight in that post-task, users\nwere able to envision",
    "start": "2305560",
    "end": "2312610"
  },
  {
    "text": "more harms independently. They focused more on\nusers and use cases",
    "start": "2312610",
    "end": "2318339"
  },
  {
    "text": "than the control who thought\nmore about model level issues. ",
    "start": "2318340",
    "end": "2324970"
  },
  {
    "text": "The tool helped users\nthink a little bit more about longer-term or\nsecond-order harms,",
    "start": "2324970",
    "end": "2331240"
  },
  {
    "text": "this idea of cascading\nfailures, like, well, if this happens, then that\nmight lead to X, Y, Z.",
    "start": "2331240",
    "end": "2338800"
  },
  {
    "text": "I will note, we did\nnot, in the tool-- the tool does not provide any\nkind of mitigations of how",
    "start": "2338800",
    "end": "2345580"
  },
  {
    "text": "to remediate these harms. But after using Farsight\nin those conditions,",
    "start": "2345580",
    "end": "2351440"
  },
  {
    "text": "users considered more\npossible mitigations during this prototyping phase.",
    "start": "2351440",
    "end": "2358450"
  },
  {
    "text": "And we did have\nsome survey items about usability and usefulness. Although, I will caveat, some\nof my collaborators and I",
    "start": "2358450",
    "end": "2365380"
  },
  {
    "text": "had a paper at\nCHI this past year that many of these RAI\ntools are evaluated",
    "start": "2365380",
    "end": "2370480"
  },
  {
    "text": "for their usability, like can\na developer use this fairness tool? But that's a very\ndifferent question than how effective is that\ntool in changing development",
    "start": "2370480",
    "end": "2378910"
  },
  {
    "text": "practices or outcomes. So with that caveat,\nthat participants found it useful and usable,\nbut there are important studies",
    "start": "2378910",
    "end": "2386820"
  },
  {
    "text": "to be done of, OK, in an\nactual ecologically valid study throughout\ndevelopment processes,",
    "start": "2386820",
    "end": "2392250"
  },
  {
    "text": "how effective is this\nin changing practices? So I encourage you to\nread the paper for more.",
    "start": "2392250",
    "end": "2399119"
  },
  {
    "text": "But, yeah, we raised\nsome questions about other in-situ\ninterventions",
    "start": "2399120",
    "end": "2404820"
  },
  {
    "text": "to motivate learners\nduring development for the kinds of practitioners\nwho may not independently",
    "start": "2404820",
    "end": "2410789"
  },
  {
    "text": "seek out a training or\nlearning resource themselves,",
    "start": "2410790",
    "end": "2415860"
  },
  {
    "text": "smuggle in this learning\ninto their IDE or development environment to\nproactively motivate",
    "start": "2415860",
    "end": "2422609"
  },
  {
    "text": "them to identify these issues. And then this work raises\nquestions about these trade offs of automation and human agency.",
    "start": "2422610",
    "end": "2428820"
  },
  {
    "text": "So I mentioned that\nwe designed this to try to support developers\nreflexivity and ability",
    "start": "2428820",
    "end": "2435660"
  },
  {
    "text": "to independently ideate. But we recognized when\ndiscussed in the paper, there's a real risk that\ndevelopers might offload",
    "start": "2435660",
    "end": "2441990"
  },
  {
    "text": "that harm ideation to the tool. And we tried to avoid that. In the paper, we talked more\nabout some risks and questions",
    "start": "2441990",
    "end": "2449060"
  },
  {
    "text": "there. There's questions\nraised in the study around the role of\nsubjectivity, as in,",
    "start": "2449060",
    "end": "2455540"
  },
  {
    "text": "people's unique positionality,\nbackgrounds, lived experiences, domain expertise,\net cetera, in the kinds of harms",
    "start": "2455540",
    "end": "2462950"
  },
  {
    "text": "that they identify. And this came out both\nfor the participants",
    "start": "2462950",
    "end": "2468530"
  },
  {
    "text": "and for how we evaluated\nthe participants. The paper gets more into\nit, but the participants",
    "start": "2468530",
    "end": "2475100"
  },
  {
    "text": "wrote down these lists of like,\nwell, these potential harms to these groups. And then we gave those to--",
    "start": "2475100",
    "end": "2481460"
  },
  {
    "text": "I think it was 9 or 10\nother people did not",
    "start": "2481460",
    "end": "2487220"
  },
  {
    "text": "aware of the conditions\nof the study, of the hypotheses,\net cetera, but we had very low inter-rater\nreliability among those raters,",
    "start": "2487220",
    "end": "2497730"
  },
  {
    "text": "as in, we asked them\nto rate the likelihood and severity of the harms.",
    "start": "2497730",
    "end": "2503943"
  },
  {
    "text": "Of course, anybody could just\nlist as many possible harms. But are those likely to occur? Will those be severe\nfor the people?",
    "start": "2503943",
    "end": "2511880"
  },
  {
    "text": "We had a very hard time\ngetting the third-party raters to agree on what constituted\na likely or severe harm.",
    "start": "2511880",
    "end": "2520290"
  },
  {
    "text": "In the paper, we talk more about\nhow that may have something to do with the\nsubjectivity, lived experiences, domain expertise\nof both parties involved.",
    "start": "2520290",
    "end": "2528800"
  },
  {
    "text": "And this is why, again,\nwe encourage engagement with communities\nimpacted by AI systems,",
    "start": "2528800",
    "end": "2533930"
  },
  {
    "text": "this kind of participatory\ndesign or co-design. And how might this\nfoster mitigation?",
    "start": "2533930",
    "end": "2540310"
  },
  {
    "text": "We didn't support\nthis with the tool, but design could be a\nmitigation or design",
    "start": "2540310",
    "end": "2545320"
  },
  {
    "text": "choices could be a mitigation. I think, often, in AI, we\nthink of technical mitigations",
    "start": "2545320",
    "end": "2551980"
  },
  {
    "text": "of, for instance, guardrails\nor filters for model outputs,",
    "start": "2551980",
    "end": "2557180"
  },
  {
    "text": "but those are post hoc. And making different\ndesign choices at the beginning of a\nproject could potentially",
    "start": "2557180",
    "end": "2565590"
  },
  {
    "text": "avoid some of these harms. And that was the motivation\nof this work intervening in the prototyping phase.",
    "start": "2565590",
    "end": "2570970"
  },
  {
    "text": "There's this Bill Buxton quote,\nthat we need to not just focus on designing the thing\nright, we should focus",
    "start": "2570970",
    "end": "2577530"
  },
  {
    "text": "on designing the right thing. So, yeah, I know I'm almost at\ntime here, but some of this work",
    "start": "2577530",
    "end": "2584490"
  },
  {
    "text": "raises some broader\nquestions that I would love to keep thinking\nthrough and discussing with all of you. As I mentioned in\nthe first portion,",
    "start": "2584490",
    "end": "2592240"
  },
  {
    "text": "how do we integrate these\nsocial and technical topics in responsible AI\nrather than siloing them",
    "start": "2592240",
    "end": "2597960"
  },
  {
    "text": "both in the learning objectives,\nor in the assessment, or even in a separate\nresource entirely,",
    "start": "2597960",
    "end": "2604410"
  },
  {
    "text": "particularly for\nengineers who might be working in this area\nthat's outside of the field that they've been trained in?",
    "start": "2604410",
    "end": "2610500"
  },
  {
    "text": "How do we move towards\nhigher order cognition in responsible AI learning\ntowards application, analysis,",
    "start": "2610500",
    "end": "2617530"
  },
  {
    "text": "evaluation, and creation? What would it look like to\nassess these more sociotechnical skills?",
    "start": "2617530",
    "end": "2622820"
  },
  {
    "text": "How do we balance this\nscalability of self-study and this more collaborative\nlearning approach?",
    "start": "2622820",
    "end": "2629330"
  },
  {
    "text": "Yeah, what do all\ndevelopers need versus just different roles? How do we balance\nthe just in time? I have so many questions.",
    "start": "2629330",
    "end": "2635250"
  },
  {
    "text": "I don't have answers\nto these questions, but would love to discuss and\nthink more with you, yeah,",
    "start": "2635250",
    "end": "2640460"
  },
  {
    "text": "about how to design these\nlearning environments. And inspired by\nthat second study,",
    "start": "2640460",
    "end": "2645780"
  },
  {
    "text": "how do we move this\nwork of responsible AI upstream from just\na pre-launch review",
    "start": "2645780",
    "end": "2650900"
  },
  {
    "text": "or testing to more early stage\nproblem formulation or design? So that could include the\nkinds of resources and tools",
    "start": "2650900",
    "end": "2658789"
  },
  {
    "text": "to support this\nor the processes. So this is a paper I had\nwith some other collaborators",
    "start": "2658790",
    "end": "2664190"
  },
  {
    "text": "on participatory AI. This is a really dense slide\nto put at the end of a talk. And I'm sorry. But the takeaway\nhere basically is",
    "start": "2664190",
    "end": "2670580"
  },
  {
    "text": "that we found across\n80 papers that claim to do participatory\nAI, nearly or all of them",
    "start": "2670580",
    "end": "2676970"
  },
  {
    "text": "focused on the user\ninterface of the system and very, very few on these\nbroader design questions of,",
    "start": "2676970",
    "end": "2683650"
  },
  {
    "text": "should it be built? Should it use AI? What problem is it solving? And so that is more\nof a methodological.",
    "start": "2683650",
    "end": "2689779"
  },
  {
    "text": "We could develop more tools and\nresources for responsible AI that focus upstream. We could focus on more methods\nlike co-design or participatory",
    "start": "2689780",
    "end": "2697630"
  },
  {
    "text": "AI for generative AI. And this current paradigm, it's\nonly our current paradigm, not",
    "start": "2697630",
    "end": "2705190"
  },
  {
    "text": "necessarily the paradigm of\nAI, but this current design paradigm of pre-trained\nfoundation models,",
    "start": "2705190",
    "end": "2711590"
  },
  {
    "text": "how does this actually,\nperhaps, impede some of this responsible AI work? That is very contextual.",
    "start": "2711590",
    "end": "2717515"
  },
  {
    "text": "Fairness means\nsomething very different in different use cases,\ncultural contexts. But if you're, for instance,\na model developer training",
    "start": "2717515",
    "end": "2724660"
  },
  {
    "text": "a pre-trained model,\nhow do you think about these potential\nenormous range of harms?",
    "start": "2724660",
    "end": "2731000"
  },
  {
    "text": "And some of these methods,\nlike participatory design, value-sensitive design,\nmay need adaptation",
    "start": "2731000",
    "end": "2736710"
  },
  {
    "text": "for this current paradigm\nof pre-trained models given their historical legacy.",
    "start": "2736710",
    "end": "2741910"
  },
  {
    "text": "And you can actually\nread our IMO paper on participatory turn in AI for\nmore thinking through of that.",
    "start": "2741910",
    "end": "2750300"
  },
  {
    "text": "And some work from\nHarini Suresh and others have fact us here on\nparticipatory AI and foundation models.",
    "start": "2750300",
    "end": "2756438"
  },
  {
    "text": "Yeah, so there's a\nlot that, I think, design methods could\noffer to RAI work, but I think there's\nopen questions for how.",
    "start": "2756438",
    "end": "2762700"
  },
  {
    "text": "And I will just say that\nsome of this emerging policy and regulatory\nwork from the EU AI Act,",
    "start": "2762700",
    "end": "2768730"
  },
  {
    "text": "as well as in the\nUS NIST calls out human factors in\nrisk management,",
    "start": "2768730",
    "end": "2773770"
  },
  {
    "text": "but there's open questions\nof how to do that and how to support\nthat work in happening. OK, so I mentioned\nat the beginning",
    "start": "2773770",
    "end": "2779820"
  },
  {
    "text": "that the field of responsible\nAI has a learning and design problem, and I would\nencourage all of you to reconceptualize\nresponsible AI",
    "start": "2779820",
    "end": "2788880"
  },
  {
    "text": "as a learning and\ndesign problem. So I want to thank my\namazing collaborators. And, yeah, thank you all.",
    "start": "2788880",
    "end": "2794500"
  },
  {
    "text": "I think we have some\ntime for questions. [APPLAUSE] ",
    "start": "2794500",
    "end": "2800333"
  },
  {
    "text": "I encourage all\nquestions to be as information-dense as that talk. [LAUGHTER] ",
    "start": "2800333",
    "end": "2806730"
  },
  {
    "text": "Yeah. Thank you so much for this talk. It's very interesting\nand very important to consider these problems.",
    "start": "2806730",
    "end": "2812770"
  },
  {
    "text": "I have two questions. The first one is more\non the developer side. So you mentioned,\nthere are a lot of policy related to\nRAI in the process.",
    "start": "2812770",
    "end": "2820840"
  },
  {
    "text": "I wonder about your impact on\nthe actual product being built. Is there any kind of\nassessment of evaluation",
    "start": "2820840",
    "end": "2827670"
  },
  {
    "text": "of each of the stake or\neach version of the process and their effectiveness on\nthe actual product being",
    "start": "2827670",
    "end": "2833220"
  },
  {
    "text": "made more fair? And my second question\nis more on the user side. So you've been talking a\nlot about all those RAI",
    "start": "2833220",
    "end": "2840540"
  },
  {
    "text": "systems for developer\nor [INAUDIBLE], but given a biased\nmodel or problems",
    "start": "2840540",
    "end": "2846870"
  },
  {
    "text": "with the current system,\nshould the user also be aware or should they\nbe warned or somehow understand these problems?",
    "start": "2846870",
    "end": "2853519"
  },
  {
    "text": "Yeah, I love these questions. So the first question\nwas around evaluation.",
    "start": "2853520",
    "end": "2860315"
  },
  {
    "text": "And if I understood\nit correctly, to what extent evaluation\nis happening at the model",
    "start": "2860315",
    "end": "2865490"
  },
  {
    "text": "level versus product\nlevel and by whom that evaluation is happening. Yeah, it's an\nexcellent question.",
    "start": "2865490",
    "end": "2871585"
  },
  {
    "text": "So I will say, there\ncertainly are evaluations happening at each\nof these stages",
    "start": "2871585",
    "end": "2877940"
  },
  {
    "text": "for different types of things. So Laura Weidinger at Google\nDeepMind and her collaborators",
    "start": "2877940",
    "end": "2883550"
  },
  {
    "text": "had a paper, I think\nit was last year on sociotechnical evaluations,\nwhere they argue that",
    "start": "2883550",
    "end": "2890210"
  },
  {
    "text": "and they propose this framework\nand different processes for model evaluations\nthat might include risks",
    "start": "2890210",
    "end": "2898220"
  },
  {
    "text": "that any product\nor application that uses that base model\nor pre-trained model might encounter.",
    "start": "2898220",
    "end": "2905030"
  },
  {
    "text": "But, of course, those are\nfairly abstracted from any use case or context.",
    "start": "2905030",
    "end": "2910830"
  },
  {
    "text": "And then they look at more\ninteraction evaluations, what",
    "start": "2910830",
    "end": "2915980"
  },
  {
    "text": "you might think of a individual,\na user study kind of thing, and then these broader societal\nor systemic evaluations of, OK,",
    "start": "2915980",
    "end": "2924120"
  },
  {
    "text": "what happens to an entire sector\nof the labor market or field",
    "start": "2924120",
    "end": "2930710"
  },
  {
    "text": "if this were to be deployed? So, absolutely, I\nthink those elections have to happen at each stage.",
    "start": "2930710",
    "end": "2936450"
  },
  {
    "text": "And they may have\nthis in the paper. I may just be forgetting. But I would go even\none step further and say, I actually think that\nwe need more cross-pollination",
    "start": "2936450",
    "end": "2944660"
  },
  {
    "text": "across each of those. So, for instance, if you are an\napplication developer working",
    "start": "2944660",
    "end": "2952300"
  },
  {
    "text": "in, say, the education\ncontext, I'll speak to that just because\nI'm more familiar with that.",
    "start": "2952300",
    "end": "2958140"
  },
  {
    "text": "If you, through your user\nstudies or what have you of your product encounter\nspecific harm, specific risks,",
    "start": "2958140",
    "end": "2965910"
  },
  {
    "text": "can we develop mechanisms to\nsurface those risks, or harms, or valuation results\nup to the developers",
    "start": "2965910",
    "end": "2973200"
  },
  {
    "text": "of the base or\npre-trained model? Some of that is maybe\norganizational processes. Some may be more\nsociotechnical interventions.",
    "start": "2973200",
    "end": "2982140"
  },
  {
    "text": "And I think all of\nthose are somewhat distinct from the\nquestion of effectiveness",
    "start": "2982140",
    "end": "2988095"
  },
  {
    "text": "and how effective are those\nevaluations actually improving the experience?",
    "start": "2988095",
    "end": "2994079"
  },
  {
    "text": "You mentioned policy. So there is currently\nwork, even in the US.",
    "start": "2994080",
    "end": "2999840"
  },
  {
    "text": "The NIST framework\nis not a binding. It's not legislation.",
    "start": "2999840",
    "end": "3005850"
  },
  {
    "text": "It's not regulation. But there is work happening\nwithin federal agencies.",
    "start": "3005850",
    "end": "3010910"
  },
  {
    "text": "So within the Federal Trade\nCommission, the Equal Employment Opportunity Commission, and\nvarious other federal agencies",
    "start": "3010910",
    "end": "3017524"
  },
  {
    "text": "to enforce violations within\ntheir specific purview.",
    "start": "3017524",
    "end": "3022670"
  },
  {
    "text": "And again, going back to\nthis contextual evaluations, I might encourage\nyou to look there, of what's happening within\nthese domain-specific sectors",
    "start": "3022670",
    "end": "3030200"
  },
  {
    "text": "or agencies. To your second question,\nI absolutely agreed. We do need more both\nsupport for users",
    "start": "3030200",
    "end": "3039020"
  },
  {
    "text": "in learning about\nresponsible AI harms, as well as guidance for them\non how to use it responsibly.",
    "start": "3039020",
    "end": "3046920"
  },
  {
    "text": "I'm a little wary of putting\ntoo much of the onus on users to use systems responsibly\nthat may or may not have",
    "start": "3046920",
    "end": "3054920"
  },
  {
    "text": "been developed responsibly. But, for instance,\nI think there's",
    "start": "3054920",
    "end": "3060500"
  },
  {
    "text": "a lot that could be done to\ncommunicate the limitations of language models. For instance, hallucinations\nare an unsolved problem.",
    "start": "3060500",
    "end": "3066890"
  },
  {
    "text": "And I think that perhaps\nbroader education or AI literacy around\nthose limitations",
    "start": "3066890",
    "end": "3072830"
  },
  {
    "text": "might inform how users\nof AI might decide, well, what is an appropriate use case\nwhere it doesn't matter if it",
    "start": "3072830",
    "end": "3079490"
  },
  {
    "text": "hallucinates\nbecause this is just for a brainstorming\ntask or something. And I wasn't sure if this\nwas in the question or not,",
    "start": "3079490",
    "end": "3086200"
  },
  {
    "text": "but there are some\nresources and toolkits for community organizations and\nto advocate for responsible AI,",
    "start": "3086200",
    "end": "3095310"
  },
  {
    "text": "to support that. So there was some work out of\nUW by [INAUDIBLE], Mike Cattell,",
    "start": "3095310",
    "end": "3101500"
  },
  {
    "text": "Meg Young, and others called\nthe Algorithmic Equity Kit. ",
    "start": "3101500",
    "end": "3108299"
  },
  {
    "text": "Maybe it's not. I had a paper where we looked\nat these AI ethics toolkits and who their audience was.",
    "start": "3108300",
    "end": "3115170"
  },
  {
    "text": "It was a Richmond\nWong et al paper. And, yeah, there's\nnot as many that",
    "start": "3115170",
    "end": "3120960"
  },
  {
    "text": "are geared towards community\norganizations and the broader public as there are\ntowards developers, but that's an open area then\nfor folks to contribute to.",
    "start": "3120960",
    "end": "3131490"
  },
  {
    "text": "Yeah, thank you. Yeah. Yeah, I mean, this\nwas a wonderful talk.",
    "start": "3131490",
    "end": "3137410"
  },
  {
    "text": "Thank you. I know a lot of the responsible\nAI discussions in the industry",
    "start": "3137410",
    "end": "3142710"
  },
  {
    "text": "are gone more in\nthe Gen AI category,",
    "start": "3142710",
    "end": "3148410"
  },
  {
    "text": "but there's still\na lot of AIs that are used, for example, in small\nmodels, on the Edge devices,",
    "start": "3148410",
    "end": "3155390"
  },
  {
    "text": "and so on. And I think what\nwe struggled with,",
    "start": "3155390",
    "end": "3160760"
  },
  {
    "text": "like you said, is just\nthe ship it down mentality",
    "start": "3160760",
    "end": "3167030"
  },
  {
    "text": "and then realizing a year later\nthat actually the model was fundamentally biased because\nwe just didn't set the ground",
    "start": "3167030",
    "end": "3175610"
  },
  {
    "text": "rules right, we didn't\nknow something simple like video super resolution.",
    "start": "3175610",
    "end": "3182540"
  },
  {
    "text": "It adds more white hair\non people or wrinkles on people and the actual\nusers in the prototype.",
    "start": "3182540",
    "end": "3190849"
  },
  {
    "text": "When we went into the real\napp experience, it bombed.",
    "start": "3190850",
    "end": "3195890"
  },
  {
    "text": "And the engineers were quite\nupset like, why are people getting so upset?",
    "start": "3195890",
    "end": "3200940"
  },
  {
    "text": "So it's like people\nare getting upset then. And so I think really,\nfundamentally, we",
    "start": "3200940",
    "end": "3208990"
  },
  {
    "text": "haven't figured out\nhow to figure out what the data\ndistribution should",
    "start": "3208990",
    "end": "3214329"
  },
  {
    "text": "be in the design phase for\nthe models to come out fair.",
    "start": "3214330",
    "end": "3220210"
  },
  {
    "text": "So the input design is still\na bit of an art, and science, and just people winging it.",
    "start": "3220210",
    "end": "3227920"
  },
  {
    "text": "Yeah, yeah. Absolutely agreed. Yeah, and I do think I\nfocused a lot on generative AI",
    "start": "3227920",
    "end": "3233214"
  },
  {
    "text": "in this talk, but\nI could not agree more that the issues of bias,\nfairness, responsibility AI",
    "start": "3233215",
    "end": "3239800"
  },
  {
    "text": "are an unsolved problem for\nmore supervised learning, more classical machine\nlearning as well.",
    "start": "3239800",
    "end": "3246950"
  },
  {
    "text": "I do think, at the\nvery least, there are slightly more resources\nout there to support that.",
    "start": "3246950",
    "end": "3251990"
  },
  {
    "text": "Not that that is a solution,\nagain, with caveats of, just because there is a\ntoolkit and people can use it, it doesn't mean it's effective.",
    "start": "3251990",
    "end": "3258760"
  },
  {
    "text": "But, for instance,\na lot of the ones in this paper that we surveyed\ndo focus on data collection",
    "start": "3258760",
    "end": "3264690"
  },
  {
    "text": "and processing\nspecifically for teams that are training their own model. And I do think there's at least\nmore opportunities for a team",
    "start": "3264690",
    "end": "3272910"
  },
  {
    "text": "to intervene at that stage,\nwith the caveats that we've seen in some of our prior work,\nand I totally empathize with,",
    "start": "3272910",
    "end": "3279330"
  },
  {
    "text": "of the organizational incentives\nare to just ship products. People are getting promoted\nfor shipping products and not",
    "start": "3279330",
    "end": "3285315"
  },
  {
    "text": "not shipping products. You know what I mean? However, it at least is perhaps\nwithin the scope of things",
    "start": "3285315",
    "end": "3293070"
  },
  {
    "text": "they could control versus, for\npretrained models, what really worries me is that often\nan entirely different part",
    "start": "3293070",
    "end": "3302579"
  },
  {
    "text": "of the company, or maybe an\nentirely different company, has trained a base model\nor foundation model,",
    "start": "3302580",
    "end": "3309580"
  },
  {
    "text": "if you will, on a data set\nthat was not disclosed. And now third-party\ncompanies are using that API.",
    "start": "3309580",
    "end": "3316300"
  },
  {
    "text": "They don't know what was in the\ntraining for that base model. Even if you have toolkits to\nevaluate data distributions",
    "start": "3316300",
    "end": "3324420"
  },
  {
    "text": "or try to have more\nfair training data sets, they can't inspect it,\nthey can't remediate it,",
    "start": "3324420",
    "end": "3331330"
  },
  {
    "text": "they can't retrain it. At best, maybe they\ncould fine tune it or reinforcement learning\nwith human feedback,",
    "start": "3331330",
    "end": "3337020"
  },
  {
    "text": "like tune the model post hoc. But, yeah, no, I agree with you. And I do think,\nparticularly in high stakes",
    "start": "3337020",
    "end": "3344850"
  },
  {
    "text": "settings in the public sector,\nand this is just my take based on no data, just\nintuition and observation,",
    "start": "3344850",
    "end": "3353226"
  },
  {
    "text": "I actually think those more\ntraditional machine learning models are much more\nwidespread, in part, because of that ability\nof the auditability of it,",
    "start": "3353227",
    "end": "3361349"
  },
  {
    "text": "the traceability of it. So I think there is, yeah, a\nlot of room for improvement,",
    "start": "3361350",
    "end": "3368350"
  },
  {
    "text": "a lot of room to move\nthe needle there. And it's a thornier\nissue for generative AI,",
    "start": "3368350",
    "end": "3375940"
  },
  {
    "text": "but it's not a solved problem\nfor machine learning either. ",
    "start": "3375940",
    "end": "3382400"
  },
  {
    "text": "Let's do one last one. So you talked about [INAUDIBLE]\na lot of different tools.",
    "start": "3382400",
    "end": "3387750"
  },
  {
    "text": "So [INAUDIBLE]. I'm wondering if\nyou've seen references in how they think of\nimplementing responsible AI",
    "start": "3387750",
    "end": "3395450"
  },
  {
    "text": "and where [INAUDIBLE]\nwork context. And what does that mean\nin terms of the learning",
    "start": "3395450",
    "end": "3402200"
  },
  {
    "text": "resources you provide them? Is there a one-size fits\nall learning resource, or should that be different?",
    "start": "3402200",
    "end": "3407390"
  },
  {
    "text": "What do you think? It's a great question. Great question. I'll admit I have\nthe same question.",
    "start": "3407390",
    "end": "3414065"
  },
  {
    "text": "So in one of our\nprevious papers, we did--",
    "start": "3414065",
    "end": "3423329"
  },
  {
    "text": "let me see. Yeah, this one is\nat fact in 2023. We looked at this idea of\ncross-functional collaboration",
    "start": "3423330",
    "end": "3430940"
  },
  {
    "text": "and specifically looking\nat this issue of, what do UX researchers, what\ndo program managers, what",
    "start": "3430940",
    "end": "3436329"
  },
  {
    "text": "do data scientist, et cetera,\nsee as within their purview for responsible AI?",
    "start": "3436330",
    "end": "3441560"
  },
  {
    "text": "What kinds of\nknowledge do they bring to bear when they collaborate\nacross these disciplinary boundaries?",
    "start": "3441560",
    "end": "3447940"
  },
  {
    "text": "We talk a little bit\nmore in that paper. I actually started that\nproject being like, OK,",
    "start": "3447940",
    "end": "3453950"
  },
  {
    "text": "and we're going to develop\na approach to solve these collaboration problems. We didn't.",
    "start": "3453950",
    "end": "3460059"
  },
  {
    "text": "But we did at least\ntry to scope out what are some of those issues. And part of it is a lack\nof a shared language",
    "start": "3460060",
    "end": "3466540"
  },
  {
    "text": "or these suitcase\nterms, like fairness,",
    "start": "3466540",
    "end": "3471580"
  },
  {
    "text": "that bundle in lots of different\ndefinitions or meanings. Maybe when the data\nscientist says fairness,",
    "start": "3471580",
    "end": "3477800"
  },
  {
    "text": "they mean equalized odds,\nor demographic parity, or something like that. And when the UX researcher or\nsocial scientist says fairness,",
    "start": "3477800",
    "end": "3485870"
  },
  {
    "text": "they means something\nvery different. That is just one example. So I think, yeah, there's\nboth issues in this kind",
    "start": "3485870",
    "end": "3493410"
  },
  {
    "text": "of interdisciplinarity. And I think this question of\ncustomized, role-specific,",
    "start": "3493410",
    "end": "3498843"
  },
  {
    "text": "or more general\ntrainings, I mean, I think we don't really have\nenough of these learning",
    "start": "3498843",
    "end": "3505290"
  },
  {
    "text": "resources in general. So I think we just\nneed all of it. But, yeah, it's a good question.",
    "start": "3505290",
    "end": "3513840"
  },
  {
    "text": "And I think, in part, this\ncollaboration question makes me wonder whether\nit's like, well, we",
    "start": "3513840",
    "end": "3519110"
  },
  {
    "text": "may need a little of both. Maybe every role involved\nneeds to know something",
    "start": "3519110",
    "end": "3524339"
  },
  {
    "text": "so they can speak across\nthese disciplinary boundaries to these other roles\nand at least be",
    "start": "3524340",
    "end": "3530400"
  },
  {
    "text": "able to know, OK, generally,\nhow are models trained? What does fine-tuning mean?",
    "start": "3530400",
    "end": "3536680"
  },
  {
    "text": "These kinds of things\nto be able to even talk about these as interventions\nor design opportunities.",
    "start": "3536680",
    "end": "3542380"
  },
  {
    "text": "It's a good question though. Let's thank our speaker. [APPLAUSE]",
    "start": "3542380",
    "end": "3548420"
  },
  {
    "start": "3548420",
    "end": "3552000"
  }
]
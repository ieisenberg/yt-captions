[
  {
    "text": " The plan for today\nis to continue",
    "start": "0",
    "end": "6640"
  },
  {
    "text": "talking about generative\nadversarial networks. As a recap, remember\nthat the nice thing",
    "start": "6640",
    "end": "15340"
  },
  {
    "text": "about generative\nadversarial networks is that it allows\nus to train models",
    "start": "15340",
    "end": "21160"
  },
  {
    "text": "in a likelihood-free way, which\nbasically means that you no longer have to choose kind\nof special architectures",
    "start": "21160",
    "end": "29950"
  },
  {
    "text": "or factorize a distribution\naccording to chain rule because you're forced\nto be able to evaluate",
    "start": "29950",
    "end": "37570"
  },
  {
    "text": "the probability\nof each data point because you want to train\nby maximum likelihood.",
    "start": "37570",
    "end": "43000"
  },
  {
    "text": "The idea is that there are\nways to basically compare the probability distribution\nof your generative model",
    "start": "43000",
    "end": "50140"
  },
  {
    "text": "to the data distribution that\ndoes not involve KL divergence",
    "start": "50140",
    "end": "55360"
  },
  {
    "text": "and does not require,\nbasically, you having to evaluate the probability of\nsamples according to your model.",
    "start": "55360",
    "end": "62213"
  },
  {
    "text": "And in particular,\nwe've seen that there is one very reasonable\nway of figuring out",
    "start": "62213",
    "end": "68860"
  },
  {
    "text": "how well your generative model\nmatches a data distribution, and that involves basically\ntraining a classifier.",
    "start": "68860",
    "end": "77390"
  },
  {
    "text": "And the classifier\nis often called a discriminator in this space. And the discriminator\nis supposed to--",
    "start": "77390",
    "end": "84310"
  },
  {
    "text": "is trained to distinguish\nwhether or not the samples it's\nreceiving are real,",
    "start": "84310",
    "end": "91240"
  },
  {
    "text": "meaning they come from the\ndata distribution, or fake, meaning they come from\nthe model distribution.",
    "start": "91240",
    "end": "96370"
  },
  {
    "text": "And you can think of the\nperformance of this classifier",
    "start": "96370",
    "end": "101380"
  },
  {
    "text": "as an indicator of how well\nyour generative model has been",
    "start": "101380",
    "end": "108369"
  },
  {
    "text": "trained or how similar\nthe samples it produces are to the real\ndata distribution.",
    "start": "108370",
    "end": "113560"
  },
  {
    "text": "If the discriminator is having\na very hard time distinguishing your samples from\nthe real ones, there",
    "start": "113560",
    "end": "119500"
  },
  {
    "text": "is a good chance that\nyour samples are actually pretty good. And so based on\nthis intuition, we",
    "start": "119500",
    "end": "126369"
  },
  {
    "text": "have this kind of\ntraining objective here, which involves\na minimax game.",
    "start": "126370",
    "end": "131720"
  },
  {
    "text": "So it's like an\noptimization problem where there are two players. There is a generator that is\ntrying to produce samples.",
    "start": "131720",
    "end": "137780"
  },
  {
    "text": "That's your generative model. There is a\ndiscriminator D that is trying to distinguish real\nsamples from phase samples.",
    "start": "137780",
    "end": "144740"
  },
  {
    "text": "And there is this performance\nmetric, which is basically the loss of the discriminator.",
    "start": "144740",
    "end": "152620"
  },
  {
    "text": "It's basically the\nnegative cross-entropy loss of the discriminator\non this task",
    "start": "152620",
    "end": "157990"
  },
  {
    "text": "of distinguishing\nreal versus fake. And you have this minimax\ngame where the discriminator is trying to do\nas well as it can",
    "start": "157990",
    "end": "165100"
  },
  {
    "text": "in this classification problem,\nbinary classification problem. And the generator is trying to\nmake the discriminator perform",
    "start": "165100",
    "end": "172660"
  },
  {
    "text": "poorly. So they are playing like a game. And this is like a\nminimax game in the sense",
    "start": "172660",
    "end": "178587"
  },
  {
    "text": "that they're pushing the\nobjective function in two different directions. And the generator\nis being trained",
    "start": "178587",
    "end": "183940"
  },
  {
    "text": "to try to fool, basically, the\ndiscriminator, trying to produce samples that are as close as\npossible to the ones in the data",
    "start": "183940",
    "end": "192189"
  },
  {
    "text": "as measured by a discriminator\nnot being able to distinguish these two types of samples.",
    "start": "192190",
    "end": "198580"
  },
  {
    "text": "And we've seen that\nunder some assumptions. So if you assume\nthat somehow you",
    "start": "198580",
    "end": "205420"
  },
  {
    "text": "are able to compute the\noptimal discriminator, recall that optimal\ndiscriminator is basically",
    "start": "205420",
    "end": "211210"
  },
  {
    "text": "giving you density ratios. And if you plug that optimal\ndiscriminator into this loss",
    "start": "211210",
    "end": "218409"
  },
  {
    "text": "function, then you get a mixture\nof two types of KL divergences.",
    "start": "218410",
    "end": "224240"
  },
  {
    "text": "And we've seen that\ndivergence as a name. It's called the\nJensen-Shannon divergence. And up to scaling\nand shifts, you",
    "start": "224240",
    "end": "231760"
  },
  {
    "text": "can think of this\ntraining objective from the perspective\nof the generator,",
    "start": "231760",
    "end": "238270"
  },
  {
    "text": "assuming the\ndiscriminator is optimal. You can think of this\nas trying to minimize this Jensen-Shannon divergence\nbetween the data distribution",
    "start": "238270",
    "end": "246010"
  },
  {
    "text": "and the model distribution. And so this is not\ntoo different from",
    "start": "246010",
    "end": "251689"
  },
  {
    "text": "traditional maximum\nlikelihood learning, where we minimizing\nKL divergence between the data and the model.",
    "start": "251690",
    "end": "257690"
  },
  {
    "text": "Under these assumptions,\nyou're trying to make-- to instead\nminimize some kind of mixture",
    "start": "257690",
    "end": "263000"
  },
  {
    "text": "of KL divergences\nthat are basically between the data and\nmixtures of models and data.",
    "start": "263000",
    "end": "270470"
  },
  {
    "text": "Why was the shift\nand the scaling important considering there\nisn't much else there?",
    "start": "270470",
    "end": "276139"
  },
  {
    "text": "Would the target\nnot be the same? This shift and\nscaling is just it happens to show up if you\ndefine the loss this way.",
    "start": "276140",
    "end": "284818"
  },
  {
    "text": "It just happens to be the case\nthat Jensen-Shannon divergence is defined that\nway, and it doesn't have this the optimal\nloss that you can have.",
    "start": "284818",
    "end": "292250"
  },
  {
    "text": "Not super important. It's just like if you've\nworked through the math, you get a shift in scale. But yeah, we don't care about--",
    "start": "292250",
    "end": "298009"
  },
  {
    "text": "of course, the loss is the same. Basically the-- you're\njust changing the landscape",
    "start": "298010",
    "end": "304310"
  },
  {
    "text": "by shifting it. So it doesn't really matter. It just happens to show up\nif you do the derivation.",
    "start": "304310",
    "end": "312350"
  },
  {
    "text": "And in practice,\nyou know, of course, this is not feasible in the\nsense that you cannot get",
    "start": "312350",
    "end": "319610"
  },
  {
    "text": "the optimal discriminator. But in practice,\nwhat you would do is you would have two\nneural networks, a generator",
    "start": "319610",
    "end": "325580"
  },
  {
    "text": "and a discriminator,\nand they play this game. And then the\ngenerative distribution",
    "start": "325580",
    "end": "332630"
  },
  {
    "text": "is defined as what you get by\ntransforming simple samples from a prior distribution,\nlike a Gaussian,",
    "start": "332630",
    "end": "338780"
  },
  {
    "text": "through the generator network. And then you just optimize this\nsort of objective function.",
    "start": "338780",
    "end": "345470"
  },
  {
    "text": "And there's been a lot of\nsuccess based on this paradigm.",
    "start": "345470",
    "end": "352190"
  },
  {
    "text": "This is a cool repo where you\ncan see a lot of different GANs and variants of these ideas that\nhave been proposed in the past.",
    "start": "352190",
    "end": "362419"
  },
  {
    "text": "And what we're\ngoing to see today is that this idea of\nsetting up a minimax game",
    "start": "362420",
    "end": "369300"
  },
  {
    "text": "is actually very powerful. And not only you can\nuse it to minimize the Jensen-Shannon divergence,\nbut you can actually",
    "start": "369300",
    "end": "375810"
  },
  {
    "text": "use it as a tool that,\nunder some conditions,",
    "start": "375810",
    "end": "381660"
  },
  {
    "text": "allows you to optimize a much\nbroader class of divergences between the data and\nthe model distribution,",
    "start": "381660",
    "end": "388050"
  },
  {
    "text": "something called f divergences. And we'll see that there is\nalso another kind of extension",
    "start": "388050",
    "end": "396330"
  },
  {
    "text": "or similar framework that allows\nyou to approximately minimize",
    "start": "396330",
    "end": "401550"
  },
  {
    "text": "some notion of the Wasserstein\ndistance between model and data distribution.",
    "start": "401550",
    "end": "406740"
  },
  {
    "text": "And we'll also see how to\nget latent representations from generative\nadversarial networks.",
    "start": "406740",
    "end": "414130"
  },
  {
    "text": "So similar to a VAE,\nwe'll see to what extent it's possible to essentially\nnot only generate samples",
    "start": "414130",
    "end": "421050"
  },
  {
    "text": "but also map samples to\nlatent representations. Then, you can use perhaps on\nto do semi-supervised learning",
    "start": "421050",
    "end": "428430"
  },
  {
    "text": "or use them on other\nkinds of downstream tasks. ",
    "start": "428430",
    "end": "434370"
  },
  {
    "text": "And then we'll also\nsee maybe cycle GANs that like conditional\ngenerative adversarial networks",
    "start": "434370",
    "end": "439980"
  },
  {
    "text": "are also pretty cool. All right. So first, let's go back\nto the high-level picture.",
    "start": "439980",
    "end": "447370"
  },
  {
    "text": "Again, remember\nthat we've been-- in the first part\nof the course, we",
    "start": "447370",
    "end": "452849"
  },
  {
    "text": "were always kind of choosing\nthis divergence between the data and the model to be the KL\ndivergence, which plays nicely",
    "start": "452850",
    "end": "459690"
  },
  {
    "text": "with likelihood-based models. If you can evaluate\nprobabilities under your model",
    "start": "459690",
    "end": "464970"
  },
  {
    "text": "comparing similarity in\nterms of KL divergence makes a lot of sense. And we know that that's kind\nof optimal in a certain sense.",
    "start": "464970",
    "end": "474060"
  },
  {
    "text": "We've seen that,\nto some extent, you can optimize the Jensen-Shannon\ndivergence through the GAN",
    "start": "474060",
    "end": "480090"
  },
  {
    "text": "objective. And what we'll see today\nis that you can actually optimize a broader class\nof divergences that",
    "start": "480090",
    "end": "486600"
  },
  {
    "text": "are called the f-divergences. And an f-divergences\nis just defined-- is defined as follows, so if\nyou have two densities, p and q,",
    "start": "486600",
    "end": "496669"
  },
  {
    "text": "you can define a\ndivergence between them by looking at the\nexpectation with respect",
    "start": "496670",
    "end": "502940"
  },
  {
    "text": "to the second argument, which\nis q of this f function applied",
    "start": "502940",
    "end": "508790"
  },
  {
    "text": "to the density ratio between-- at each point between p and q,\nwhere f is basically a function,",
    "start": "508790",
    "end": "519200"
  },
  {
    "text": "a scalar function that has to\nbe convex, lower semicontinuous,",
    "start": "519200",
    "end": "524630"
  },
  {
    "text": "and it has to evaluate\nto 0 when you plug in 1. And as you change\nbasically this f function,",
    "start": "524630",
    "end": "532759"
  },
  {
    "text": "you get different ways\nof basically comparing how similar p is to q.",
    "start": "532760",
    "end": "539600"
  },
  {
    "text": "And just to be precise, what\nthese technical conditions",
    "start": "539600",
    "end": "545180"
  },
  {
    "text": "mean-- well, one is that you have the-- function f has to be\nconvex, which hopefully you",
    "start": "545180",
    "end": "550890"
  },
  {
    "text": "know what it means it means that\nif you-- the graph, basically, if you take two points\nand you connect them,",
    "start": "550890",
    "end": "557550"
  },
  {
    "text": "that line is above the\ngraph of the function, has to be lower\nsemicontinuous, which is just",
    "start": "557550",
    "end": "562800"
  },
  {
    "text": "a very technical sort of thing. It basically means something\nsimilar to continuous. And if it's\ndiscontinuous, then--",
    "start": "562800",
    "end": "571139"
  },
  {
    "text": "on one of the\ndirections, then it has to be above the\nvalue of the function",
    "start": "571140",
    "end": "577589"
  },
  {
    "text": "where there is a discontinuity,\nnot super important. But the intuition\nis that somehow f",
    "start": "577590",
    "end": "585870"
  },
  {
    "text": "is what tells you how\nmuch your being penalized.",
    "start": "585870",
    "end": "591930"
  },
  {
    "text": "When p and q are assigned\ndifferent probabilities to one of the possible\nthings that can happen,",
    "start": "591930",
    "end": "597330"
  },
  {
    "text": "let's say, one of\nthe possible images. So it's similar in some\nsense to KL divergence, where, remember,\nwhat we were doing",
    "start": "597330",
    "end": "603570"
  },
  {
    "text": "is we were going through all the\npossible things that can happen. And then, we're looking at\nthe ratio of probabilities",
    "start": "603570",
    "end": "609180"
  },
  {
    "text": "assigned by p and q, and then\nwe're taking some kind of log. This is a generalization\nin the sense",
    "start": "609180",
    "end": "614400"
  },
  {
    "text": "that you can use different\nkind of convex functions to score how happy\nor unhappy you",
    "start": "614400",
    "end": "620550"
  },
  {
    "text": "are with different\nkinds of density ratios. And ideally, if p\nand q are the same,",
    "start": "620550",
    "end": "626220"
  },
  {
    "text": "then they are going to assign\nthe same probability to every x. And so the density ratio is 1.",
    "start": "626220",
    "end": "632310"
  },
  {
    "text": "And then, this\nfunction f is going to give you a penalty of 0.",
    "start": "632310",
    "end": "637830"
  },
  {
    "text": "And that's the best\nthat can happen. But f is essentially measuring\nhow much you care about p and q,",
    "start": "637830",
    "end": "650640"
  },
  {
    "text": "assigning different\nprobabilities to the various axes, to\nthe various samples that can be generated by the model.",
    "start": "650640",
    "end": "658350"
  },
  {
    "text": "And the interesting thing\nis that because f is convex,",
    "start": "658350",
    "end": "665759"
  },
  {
    "text": "then you can still\nuse the same trick that we did for KL-divergence\nto basically show that this f-divergences\nis nonnegative.",
    "start": "665760",
    "end": "675190"
  },
  {
    "text": "And in particular, because\nwe have an expectation of a convex function\nof some density ratio,",
    "start": "675190",
    "end": "681070"
  },
  {
    "text": "this is always at least\nas large as the function applied to the expectation.",
    "start": "681070",
    "end": "686440"
  },
  {
    "text": "And now that expectation,\nyou can expand it. It's basically the\nintegral with respect",
    "start": "686440",
    "end": "692110"
  },
  {
    "text": "to this probability\ndistribution q of the density ratio, which is just p over q.",
    "start": "692110",
    "end": "697790"
  },
  {
    "text": "So the q's simplify and you're\nleft with the integral of p.",
    "start": "697790",
    "end": "703240"
  },
  {
    "text": "P is normalized. It evaluates to\n1, that integral. And so this is f of\n1, which is zero.",
    "start": "703240",
    "end": "709490"
  },
  {
    "text": "And so you get the\ndesirable property that, basically, this f divergence\nis nonnegative for any choice",
    "start": "709490",
    "end": "718270"
  },
  {
    "text": "of p and q. And if you plug\nin p equals to q,",
    "start": "718270",
    "end": "723790"
  },
  {
    "text": "then this density ratios here\nare always going to be 1. F of 1 is zero.",
    "start": "723790",
    "end": "728930"
  },
  {
    "text": "And so this whole\nexpectation is zero. And so it behaves similarly to\nKL-divergence in the sense that",
    "start": "728930",
    "end": "735130"
  },
  {
    "text": "it's-- it tells you how similar\nor different p and q are by looking at all\nthese density ratios",
    "start": "735130",
    "end": "742840"
  },
  {
    "text": "and scoring them throughout. If the distributions\nare the same, then the density ratios,\nthe two, p and q,",
    "start": "742840",
    "end": "748690"
  },
  {
    "text": "are assigned exactly\nthe same probabilities to everything that can\nhappen, and that f-divergence",
    "start": "748690",
    "end": "754060"
  },
  {
    "text": "is going to be zero. In general, is going\nto be non-zero. It's going to be greater\nthan or equal to zero.",
    "start": "754060",
    "end": "760399"
  },
  {
    "text": "And so it makes for a\nreasonable objective function to try to\nminimize this quantity.",
    "start": "760400",
    "end": "767320"
  },
  {
    "text": "So we could have one of p and\nq be the data distribution, the other one being\nthe model distribution,",
    "start": "767320",
    "end": "773450"
  },
  {
    "text": "and then we can try to minimize\nthis as a function of the model.",
    "start": "773450",
    "end": "778660"
  },
  {
    "text": "And if you the nice\nthing about f divergences",
    "start": "778660",
    "end": "784389"
  },
  {
    "text": "is that if you plug-in\ndifferent types of f's, you get many existing\nreasonable divergences",
    "start": "784390",
    "end": "791258"
  },
  {
    "text": "that you might want to\nuse to compare probability distributions. For example, if you\nchoose f to be u log u",
    "start": "791258",
    "end": "800410"
  },
  {
    "text": "and you plug it\ninto this formula, then you will see that\nthis expression evaluates",
    "start": "800410",
    "end": "808630"
  },
  {
    "text": "to the usual KL-divergence,\nwhere the way you compare two probability\ndistributions, p and q,",
    "start": "808630",
    "end": "815852"
  },
  {
    "text": "is by going through everything\nthat can happen, look at the density ratios\nand scoring them with respect to\nthis log function.",
    "start": "815853",
    "end": "822880"
  },
  {
    "text": "There are many\nother f-divergences. So the nice thing is that if\nyou plug in different f's, you",
    "start": "822880",
    "end": "829420"
  },
  {
    "text": "get different divergences. So we have the\nJensen-Shannon divergence, which you get by\nchoosing, for example,",
    "start": "829420",
    "end": "835990"
  },
  {
    "text": "this odd-looking choice of u. You can get the\nusual KL-divergence",
    "start": "835990",
    "end": "841870"
  },
  {
    "text": "by choosing u log u. You can get the\nreverse KL-divergence where you basically swap\nthe argument of p and q",
    "start": "841870",
    "end": "849490"
  },
  {
    "text": "in the regular KL-divergence\nby choosing minus log u as the function f.",
    "start": "849490",
    "end": "854620"
  },
  {
    "text": "And you can get many more. You can get-- you can see\nhere squared Hellinger",
    "start": "854620",
    "end": "862120"
  },
  {
    "text": "total variation,\nalpha divergences, a lot of different kind of\nways of comparing similarities",
    "start": "862120",
    "end": "868040"
  },
  {
    "text": "between p and q by choosing\na different f function.",
    "start": "868040",
    "end": "873199"
  },
  {
    "text": "And what will turn out to be\nthe case is that generative, adversarial\nnetwork-like objectives",
    "start": "873200",
    "end": "878870"
  },
  {
    "text": "can not only be used to\nminimize an approximate version of the Jensen-Shannon\ndivergence, which corresponds",
    "start": "878870",
    "end": "885350"
  },
  {
    "text": "to a very particular\nchoice of f, but it can actually be used\nto optimize all of them.",
    "start": "885350",
    "end": "890700"
  },
  {
    "text": "So you can pick any\nf that according to-- which satisfies\nthose constraints",
    "start": "890700",
    "end": "896810"
  },
  {
    "text": "that defines a\nvalid f-divergence. And what we'll see is that we\ncan use a GAN-like objective",
    "start": "896810",
    "end": "901880"
  },
  {
    "text": "to minimize the corresponding\nf-divergence approximately. ",
    "start": "901880",
    "end": "910160"
  },
  {
    "text": "OK, now the basic setup\nis that, as usual,",
    "start": "910160",
    "end": "916310"
  },
  {
    "text": "we're trying to, to\ntrain a generative model, so we have a data distribution,\nwe have a model distribution.",
    "start": "916310",
    "end": "922110"
  },
  {
    "text": "And it would be nice\nif we could choose an f and then either minimize the\nf-divergence between the model",
    "start": "922110",
    "end": "929240"
  },
  {
    "text": "and the data or perhaps the\nf-divergence between data and model. Now, this is reasonable\nbecause we've",
    "start": "929240",
    "end": "935990"
  },
  {
    "text": "seen that for any choice\nof f that satisfies those constraints,\nthis objective function",
    "start": "935990",
    "end": "941690"
  },
  {
    "text": "is nonnegative and is going to\nbe 0 if the two arguments match. So if your generative model\nmatches the data distribution,",
    "start": "941690",
    "end": "949490"
  },
  {
    "text": "then this loss function is\ngoing to be 0, is nonnegative. And so if you set up\na learning objective",
    "start": "949490",
    "end": "956180"
  },
  {
    "text": "where you try to minimize\nthis as a function of theta, you might be able to learn\na good generative model.",
    "start": "956180",
    "end": "963740"
  },
  {
    "text": "Now, the issue is\nthat the expression,",
    "start": "963740",
    "end": "969350"
  },
  {
    "text": "like when we started looking at\nKL-divergence the first time,",
    "start": "969350",
    "end": "974459"
  },
  {
    "text": "doesn't look like something\nyou can actually optimize. It doesn't look like\nsomething you can evaluate, and doesn't look\nlike something you",
    "start": "974460",
    "end": "980498"
  },
  {
    "text": "can actually optimize\nas a function of theta. First of all, you have an\nexpectation outside with respect",
    "start": "980498",
    "end": "986750"
  },
  {
    "text": "to, let's say, the\ndata distribution. Well, we don't know p data,\nbut we have access to samples,",
    "start": "986750",
    "end": "992279"
  },
  {
    "text": "so we can approximate that\nexpectation with a sample average. So that's not a problem.",
    "start": "992280",
    "end": "997430"
  },
  {
    "text": "The real problem\nis that it requires you to evaluate the probability\nof x under the model",
    "start": "997430",
    "end": "1005500"
  },
  {
    "text": "and under the data distribution. And even if you have a\nlikelihood-based model,",
    "start": "1005500",
    "end": "1011410"
  },
  {
    "text": "even if you can\nevaluate p theta, we can never evaluate\nprobabilities under the data distribution.",
    "start": "1011410",
    "end": "1017800"
  },
  {
    "text": "And so that density\nratio is unknown. So like in the\nKL-divergence case",
    "start": "1017800",
    "end": "1023649"
  },
  {
    "text": "where we have that\nlog density ratio, and we couldn't\nactually evaluate it, and we could only actually\noptimize KL-divergence up",
    "start": "1023650",
    "end": "1030040"
  },
  {
    "text": "to a shift, up to the\nentropy of the data. We have the same problem\nhere, that this kind",
    "start": "1030040",
    "end": "1036520"
  },
  {
    "text": "of objective function seems\nreasonable but doesn't look like something we\ncan actually optimize.",
    "start": "1036520",
    "end": "1042459"
  },
  {
    "text": "And if you try to swap, you\ntry, OK, maybe we can do-- instead of doing f divergence\nbetween p theta and p data,",
    "start": "1042460",
    "end": "1049260"
  },
  {
    "text": "we could try to do\np data to p theta, and you kind of end up\nwith something similar.",
    "start": "1049260",
    "end": "1055000"
  },
  {
    "text": "We have, again, an\nexpectation with respect to samples drawn from\nthe model, which is fine,",
    "start": "1055000",
    "end": "1060360"
  },
  {
    "text": "but again, you have\nthis density ratio that is not something we\ncan compute in general,",
    "start": "1060360",
    "end": "1066360"
  },
  {
    "text": "even if you have a\nlikelihood-based model.  And so what we need\nto do is we need",
    "start": "1066360",
    "end": "1074870"
  },
  {
    "text": "to somehow rewrite\nthis divergence or approximate this expression.",
    "start": "1074870",
    "end": "1080980"
  },
  {
    "text": "And write it into something\nthat ideally does not depend on either the probabilities.",
    "start": "1080980",
    "end": "1088100"
  },
  {
    "text": "Basically, it does\nnot require you to be able to evaluate\nprobabilities under the data distribution, and\nideally not even",
    "start": "1088100",
    "end": "1094809"
  },
  {
    "text": "according to the\nmodel distribution, because if the objective\nfunction does not involve neither p\ntheta nor p data,",
    "start": "1094810",
    "end": "1103880"
  },
  {
    "text": "and it only requires\nyou to be able to sample from both of them, Then we're back\nin the setup, just",
    "start": "1103880",
    "end": "1110960"
  },
  {
    "text": "like a generative adversarial\nnetwork where we can basically use any sort of architecture\nto define p theta implicitly",
    "start": "1110960",
    "end": "1119540"
  },
  {
    "text": "as whatever you get. If you were to, sample\nfrom a simple prior",
    "start": "1119540",
    "end": "1124580"
  },
  {
    "text": "or feed the samples through\na neural network, that which is the generator that defines a\npotentially very complicated p",
    "start": "1124580",
    "end": "1130940"
  },
  {
    "text": "theta or x to the extent\nthat we can write down the objective function\nin an equivalent way",
    "start": "1130940",
    "end": "1136580"
  },
  {
    "text": "or approximately equivalent\nway, that does not require us to evaluate\nprobabilities,",
    "start": "1136580",
    "end": "1141920"
  },
  {
    "text": "then we can use a very\nflexible network architectures, like in generative\nadversarial networks.",
    "start": "1141920",
    "end": "1147745"
  },
  {
    "text": " Questions?",
    "start": "1147745",
    "end": "1153429"
  },
  {
    "text": "Yeah. [INAUDIBLE] p data\nof x, the probability",
    "start": "1153430",
    "end": "1158980"
  },
  {
    "text": "of a-- if you're sampling from\np data and it's just [INAUDIBLE] The question is,\nOK, is p theta--",
    "start": "1158980",
    "end": "1167320"
  },
  {
    "text": "p data x1-- and in\ngeneral, no. that's basically the probability\nthat the model assigns",
    "start": "1167320",
    "end": "1174970"
  },
  {
    "text": "to every possible x. So that's just an there is\nan underlying, as usual,",
    "start": "1174970",
    "end": "1183430"
  },
  {
    "text": "data-generating process that\nwe assume we have access to only through samples. So we assume we have a training\nset that was sampled from p data",
    "start": "1183430",
    "end": "1190930"
  },
  {
    "text": "and that distribution\nis not uniform. This is not the\nempirical distribution",
    "start": "1190930",
    "end": "1197770"
  },
  {
    "text": "on the data set, which could\nbe just like 1 over n, where n is the size of the data set.",
    "start": "1197770",
    "end": "1204320"
  },
  {
    "text": "This is the true data\ngenerating process. You could set it up, trying to\nfit the empirical distribution",
    "start": "1204320",
    "end": "1211330"
  },
  {
    "text": "on the data set, but\nthat's not quite-- you could even think of that\nas an approximation of p data",
    "start": "1211330",
    "end": "1217179"
  },
  {
    "text": "where you have a very simple\nkernel density estimator based on the training set.",
    "start": "1217180",
    "end": "1222370"
  },
  {
    "text": "But that doesn't work\nparticularly well because in high dimensions\nit's going to be--",
    "start": "1222370",
    "end": "1227860"
  },
  {
    "text": "it might not generalize. So you're kind of like\noverfitting too much to the training set.",
    "start": "1227860",
    "end": "1233230"
  },
  {
    "text": "Is the reason why\nyou do not even want p theta is to avoid\nlikelihood-based learning?",
    "start": "1233230",
    "end": "1240520"
  },
  {
    "text": "Yes, so this machinery works\nif you can evaluate p theta.",
    "start": "1240520",
    "end": "1248350"
  },
  {
    "text": "But as we know,\nevaluating p theta constrains you in the\nmodels you can use.",
    "start": "1248350",
    "end": "1254890"
  },
  {
    "text": "You have to then either\nuse autoregressive models or you have to use invertible\nneural networks, which is undesirable.",
    "start": "1254890",
    "end": "1261320"
  },
  {
    "text": "And if you could set up a\nlearning objective where p theta is not even something\nthat you have to evaluate,",
    "start": "1261320",
    "end": "1266470"
  },
  {
    "text": "you just need to be\nable to sample from it. Then that opens\nup the possibility of using implicit\nmodels like feed noise",
    "start": "1266470",
    "end": "1276910"
  },
  {
    "text": "through a neural network,\nkind of like a simulator almost, where you don't even\nneed to know how it works.",
    "start": "1276910",
    "end": "1282350"
  },
  {
    "text": "You don't need to know how\nit assigns probabilities to data points, you just need\nto be able to sample from it.",
    "start": "1282350",
    "end": "1287800"
  },
  {
    "text": "So that opens up more-- a broader set of models,\nincluding these implicit ones",
    "start": "1287800",
    "end": "1296620"
  },
  {
    "text": "where you just need to be able\nto sample from it essentially. OK, you mentioned\nthat f should be",
    "start": "1296620",
    "end": "1301809"
  },
  {
    "text": "convex, but [INAUDIBLE]\na log, which is concave. But is u log u because--",
    "start": "1301810",
    "end": "1309410"
  },
  {
    "text": "yeah. Just [INAUDIBLE],, just\nrelated to that question,",
    "start": "1309410",
    "end": "1314889"
  },
  {
    "text": "why is the KL-divergence--\nwhy do we get KL-divergence with u log u. I thought-- Yeah, so the reason we need u\nlog u is because you remember",
    "start": "1314890",
    "end": "1323320"
  },
  {
    "text": "KL-divergence is an expectation\nwith respect to p of log p over",
    "start": "1323320",
    "end": "1328460"
  },
  {
    "text": "q-- Over q, right? But we have-- [INAUDIBLE]? Yeah, so you have to\nmultiply by-- yeah. OK.",
    "start": "1328460",
    "end": "1334060"
  },
  {
    "text": "--to basically change\nthe expectation to 1 with respect to p. But if you see, in fact,\nif you want reverse KL,",
    "start": "1334060",
    "end": "1341500"
  },
  {
    "text": "then it's just minus\nlog u because reverse KL would be an expectation with\nrespect to the second argument.",
    "start": "1341500",
    "end": "1348020"
  },
  {
    "text": "And so the u in\nfront is basically to change the expectation from 1\nunder q to 1 under p basically.",
    "start": "1348020",
    "end": "1357470"
  },
  {
    "text": "OK, so now let's see how we can\nactually move forward and come",
    "start": "1357470",
    "end": "1362960"
  },
  {
    "text": "up with a GAN-like\nway of approximating this f-divergence that does\nnot require likelihoods.",
    "start": "1362960",
    "end": "1370370"
  },
  {
    "text": "Oh, a question. Yeah. Why were we able to estimate\nthe objective for GANs before?",
    "start": "1370370",
    "end": "1375860"
  },
  {
    "text": "If GANs are an example\nof a [INAUDIBLE]?? So we'll be using-- the reason\nwe were able do it for, I guess,",
    "start": "1375860",
    "end": "1384800"
  },
  {
    "text": "Jensen-Shannon divergence is\nexactly what we're going to see now, which is basically\na way to reduce that--",
    "start": "1384800",
    "end": "1393650"
  },
  {
    "text": "this expectation, which\nlooks like something that you might not\nbe able to compute. If you look at the\nJensen-Shannon divergence,",
    "start": "1393650",
    "end": "1400010"
  },
  {
    "text": "it looks like something\nyou're not able to compute. But if you have an\noptimal discriminator,",
    "start": "1400010",
    "end": "1405230"
  },
  {
    "text": "intuitively, the\noptimal discriminator computes this density\nratios for you.",
    "start": "1405230",
    "end": "1410779"
  },
  {
    "text": "And so that's how\nyou get around it. ",
    "start": "1410780",
    "end": "1416300"
  },
  {
    "text": "You are offloading this problem\nof computing the density ratios to a discriminator.",
    "start": "1416300",
    "end": "1422190"
  },
  {
    "text": "And this might be good\nor bad, but the hope is that neural networks\nseem to work really",
    "start": "1422190",
    "end": "1427409"
  },
  {
    "text": "well for supervised learning\nclassification problems. And so we might\nbe able to come up",
    "start": "1427410",
    "end": "1432810"
  },
  {
    "text": "with reasonable estimates\nof these density ratios by training a classifier because\nto do well at classification,",
    "start": "1432810",
    "end": "1439050"
  },
  {
    "text": "if you're trying to classify\nreal samples from fake samples, you essentially need\nto estimate that.",
    "start": "1439050",
    "end": "1444960"
  },
  {
    "text": "The optimal classifier requires\nyou to know, for every x, how likely is this point to\ncome from one versus the other.",
    "start": "1444960",
    "end": "1453669"
  },
  {
    "text": "And so that's the trick. ",
    "start": "1453670",
    "end": "1459600"
  },
  {
    "text": "Cool. So the machinery for doing\nthis goes through something",
    "start": "1459600",
    "end": "1466139"
  },
  {
    "text": "called the Fenchel conjugate\nor the convex conjugate of a function, which\nis defined like this.",
    "start": "1466140",
    "end": "1473710"
  },
  {
    "text": "If you have a function f, you\ncan obtain another function,",
    "start": "1473710",
    "end": "1479399"
  },
  {
    "text": "f star, which is called\nthe convex conjugate of f, by using the\nfollowing expression.",
    "start": "1479400",
    "end": "1488040"
  },
  {
    "text": "So f star is not going\nto be a function of t, And the value of f star at t\nis the solution to basically",
    "start": "1488040",
    "end": "1496470"
  },
  {
    "text": "this optimization\nproblem where you're taking the supremum over all\nthe Us in the domain of f.",
    "start": "1496470",
    "end": "1503790"
  },
  {
    "text": "And then you have this\nrelatively simple objective, which is just ut minus f of u.",
    "start": "1503790",
    "end": "1511820"
  },
  {
    "text": "And so it seems a\nlittle bit random,",
    "start": "1511820",
    "end": "1518909"
  },
  {
    "text": "but this convex conjugate has\na bunch of useful properties. In particular, it's a convex\nfunction, even when f is not.",
    "start": "1518910",
    "end": "1529950"
  },
  {
    "text": "And the reason is that the\nargument here in the supremum as a function of t\nis just basically",
    "start": "1529950",
    "end": "1537600"
  },
  {
    "text": "a bunch of affine functions. It's just linear in t. And so the supremum of a\nbunch of convex functions",
    "start": "1537600",
    "end": "1545520"
  },
  {
    "text": "is also convex. And so you can think\nof this as the supremum of a collection of functions\nthat are indexed u.",
    "start": "1545520",
    "end": "1553370"
  },
  {
    "text": "But as a function of t,\nthey are all very simple. They're just linear functions. And then when you\ntake the supremum",
    "start": "1553370",
    "end": "1558708"
  },
  {
    "text": "of a bunch of convex functions,\nyou get something convex. The other interesting property\nthat we're going to use",
    "start": "1558708",
    "end": "1565799"
  },
  {
    "text": "is that we can look at the\nconjugate of the conjugate, which we're going to denote as\nf star, which is just what you",
    "start": "1565800",
    "end": "1574770"
  },
  {
    "text": "get if you take the conjugate of\nthe conjugate of a function f. And again, you basically just\napply the same definition,",
    "start": "1574770",
    "end": "1582760"
  },
  {
    "text": "but now the function\nf becomes f star. And it turns out that\nthis convex conjugate",
    "start": "1582760",
    "end": "1591210"
  },
  {
    "text": "is a lower bound to the\noriginal function f. ",
    "start": "1591210",
    "end": "1598060"
  },
  {
    "text": "So it's always less\nthan or equal to f. And so the proof is\nactually very simple.",
    "start": "1598060",
    "end": "1605210"
  },
  {
    "text": "You can see that by the\ndefinition that we have up here, we have that for\nevery choice of t.",
    "start": "1605210",
    "end": "1610980"
  },
  {
    "text": "F star is at least as\nlarge as ut minus f of u because it's the supremum.",
    "start": "1610980",
    "end": "1616810"
  },
  {
    "text": "So it has to be at least as\nlarge at all the possible values that you can get\nfor any choice of u.",
    "start": "1616810",
    "end": "1623610"
  },
  {
    "text": "And if you rearrange, you can\nmove the F on the other side and you can write it as\nf of u is at least as",
    "start": "1623610",
    "end": "1630060"
  },
  {
    "text": "large as ut minus\nf star if you just move this and this\non the other side.",
    "start": "1630060",
    "end": "1636070"
  },
  {
    "text": "And now this definition\nmeans that f of u-- because this holds for\nany t and for every u,",
    "start": "1636070",
    "end": "1643110"
  },
  {
    "text": "then it means that f of\nu is at least as large as the sup, the supremum\nof ut minus f star",
    "start": "1643110",
    "end": "1648809"
  },
  {
    "text": "of t, the convex conjugate,\nwhich is exactly the definition that we want.",
    "start": "1648810",
    "end": "1653920"
  },
  {
    "text": "That's exactly the conjugate\nof the conjugate f double star.",
    "start": "1653920",
    "end": "1659490"
  },
  {
    "text": "And so we see that this\nconjugate of the conjugate",
    "start": "1659490",
    "end": "1665840"
  },
  {
    "text": "is always less than or equal\nto the original function that we started with.",
    "start": "1665840",
    "end": "1672190"
  },
  {
    "text": "And it turns out that when\nf is convex, then this f",
    "start": "1672190",
    "end": "1679600"
  },
  {
    "text": "the conjugate of the\nconjugate is actually equal to the original function. If you start with a function,\nyou can get the conjugate,",
    "start": "1679600",
    "end": "1686430"
  },
  {
    "text": "and then if you conjugate again. You go back to the original\nfunction when f is convex.",
    "start": "1686430",
    "end": "1692090"
  },
  {
    "start": "1692090",
    "end": "1697730"
  },
  {
    "text": "Now, the reason this\nis going to be useful is that this is going to\nbe similar to the ELBO,",
    "start": "1697730",
    "end": "1704070"
  },
  {
    "text": "or the evidence lower bound. What we're going to\ndo is we're going to try to write down f in our\ndefinition of the f-divergence",
    "start": "1704070",
    "end": "1711990"
  },
  {
    "text": "in terms of the conjugate. And we're going to get bounds\non the value of the f-divergence",
    "start": "1711990",
    "end": "1717600"
  },
  {
    "text": "by going through\nthis characterization of the f function and\nan f-divergence in terms",
    "start": "1717600",
    "end": "1723360"
  },
  {
    "text": "of this convex conjugate. And so that's\nbasically the idea that",
    "start": "1723360",
    "end": "1733290"
  },
  {
    "text": "underlies this framework for\ntraining generative models based",
    "start": "1733290",
    "end": "1738300"
  },
  {
    "text": "on f-divergences through\na GAN-like objective. So what we do is we have\nthe original definition",
    "start": "1738300",
    "end": "1746080"
  },
  {
    "text": "of the f-divergence, which\ndepends on this density ratio that we don't have access to.",
    "start": "1746080",
    "end": "1753070"
  },
  {
    "text": "We can equivalently--\nbecause f is convex, we can equivalently rewrite this\nin terms of the conjugate, which",
    "start": "1753070",
    "end": "1761680"
  },
  {
    "text": "is just the conjugate of the\nconjugate f double star, which by definition is\njust this supremum.",
    "start": "1761680",
    "end": "1771940"
  },
  {
    "text": "Recall that we're evaluating\nf double star at the density",
    "start": "1771940",
    "end": "1777250"
  },
  {
    "text": "ratio, so we can write f double\nstar as the supremum of t",
    "start": "1777250",
    "end": "1782770"
  },
  {
    "text": "argument minus f\nstar evaluated at t. ",
    "start": "1782770",
    "end": "1789910"
  },
  {
    "text": "That's just the definition of\nthe conjugate of the conjugate. And now this is starting to look\nlike something a little bit more",
    "start": "1789910",
    "end": "1799000"
  },
  {
    "text": "manageable because we see that\nthe density ratio that before was sort of inside\nthe argument of this f",
    "start": "1799000",
    "end": "1805090"
  },
  {
    "text": "function that we didn't\nknow how to handle. Now, it becomes a linear\ndependence on the density ratio.",
    "start": "1805090",
    "end": "1812200"
  },
  {
    "text": "Now, except for this\nannoying supremum, then the dependence\non px over qx",
    "start": "1812200",
    "end": "1818200"
  },
  {
    "text": "is outside the argument\nof f, which will allow us",
    "start": "1818200",
    "end": "1823840"
  },
  {
    "text": "to basically simplify things.  Now, what you can see is\nthat for every value of x,",
    "start": "1823840",
    "end": "1834179"
  },
  {
    "text": "there is going to be a different\nvalue of the density ratio, and that is going to be a\ndifferent value of t that",
    "start": "1834180",
    "end": "1840660"
  },
  {
    "text": "achieves the supremum. And we can denote\nthat supremum that you",
    "start": "1840660",
    "end": "1845820"
  },
  {
    "text": "get for any particular\nx as t star of x.",
    "start": "1845820",
    "end": "1854149"
  },
  {
    "text": "So this is just the\nvalue of the supremum when we're looking\nat data point x.",
    "start": "1854150",
    "end": "1862590"
  },
  {
    "text": "And this is going to be\nwhat the discriminator is",
    "start": "1862590",
    "end": "1867630"
  },
  {
    "text": "going to do later on. But you see that now we have an\nexpression that is not too bad.",
    "start": "1867630",
    "end": "1873180"
  },
  {
    "text": "It's an expectation with\nrespect to q that we know how to approximate using samples.",
    "start": "1873180",
    "end": "1878510"
  },
  {
    "text": "And now we have\nthe density ratio, is outside the argument\nof this f function",
    "start": "1878510",
    "end": "1885390"
  },
  {
    "text": "that we use to score them. And what this means is that\nbasically, if you expand it,",
    "start": "1885390",
    "end": "1891899"
  },
  {
    "text": "it will look\nsomething like this. The expectation\nwith respect to q is just an integral where every\nx is weighted using q of x.",
    "start": "1891900",
    "end": "1899549"
  },
  {
    "text": "And now, if you\nsimplify it further, and you notice that this q of\nx simplifies with this q of x,",
    "start": "1899550",
    "end": "1909390"
  },
  {
    "text": "this whole expression\nbasically just looks like the difference\nof two expectations.",
    "start": "1909390",
    "end": "1914670"
  },
  {
    "text": "There is an expectation\nwith respect to p, and there is an expectation\nwith respect to q.",
    "start": "1914670",
    "end": "1920430"
  },
  {
    "text": "But that's similar to what\nwe had in the GAN framework, where we had an\nexpectation of something",
    "start": "1920430",
    "end": "1927760"
  },
  {
    "text": "with respect to the data\ndistribution, an expectation of something else with respect\nto the model distribution.",
    "start": "1927760",
    "end": "1933770"
  },
  {
    "text": "And that was giving\nus our estimate of the Jensen-Shannon\ndivergence.",
    "start": "1933770",
    "end": "1939040"
  },
  {
    "text": "In that case, you can see\nthat the same idea holds more",
    "start": "1939040",
    "end": "1944110"
  },
  {
    "text": "generally for\ndifferent choices of f. ",
    "start": "1944110",
    "end": "1950790"
  },
  {
    "text": "Yeah, questions. What is supremum [INAUDIBLE]? The supremum is the same\nas the max, basically.",
    "start": "1950790",
    "end": "1958080"
  },
  {
    "text": "It's just like-- yeah, it's the\ndomain that does not necessarily",
    "start": "1958080",
    "end": "1963840"
  },
  {
    "text": "exist a max. So it's a little bit\nof a technicality, but think of it as\nthe max, basically.",
    "start": "1963840",
    "end": "1970370"
  },
  {
    "text": "So where there is a star\nsign for the tx function?",
    "start": "1970370",
    "end": "1976920"
  },
  {
    "text": "I'm just denoting it t star\nbecause this is basically the-- but it's just a way of\ndenoting the value--",
    "start": "1976920",
    "end": "1986370"
  },
  {
    "text": "what this supremum\nover T evaluates to for any particular x.",
    "start": "1986370",
    "end": "1993060"
  },
  {
    "text": "There's going to be a value of\ntheater achieves the supremum.",
    "start": "1993060",
    "end": "1998460"
  },
  {
    "text": "I'm just going to\ndenote it T star. ",
    "start": "1998460",
    "end": "2009300"
  },
  {
    "text": "Other questions? Yeah. In this case, do we still\nhave to evaluate [INAUDIBLE]??",
    "start": "2009300",
    "end": "2015789"
  },
  {
    "text": "So the good thing\nis that this is an-- it still-- it looks like, yeah,\nit still depends on p of x.",
    "start": "2015790",
    "end": "2022180"
  },
  {
    "text": "But if you look at the\nformula, this is basically-- do I have it?",
    "start": "2022180",
    "end": "2027490"
  },
  {
    "text": "OK, maybe it comes up later,\nbut it's an expectation with respect to p of x. OK. And that you can approximate by\ntaking samples, which we have",
    "start": "2027490",
    "end": "2035312"
  },
  {
    "text": "because you have a training set. ",
    "start": "2035312",
    "end": "2042250"
  },
  {
    "text": "Yeah. I saw that you went ahead and\nyou pulled out the supremum from the Ts.",
    "start": "2042250",
    "end": "2048210"
  },
  {
    "text": "And how do you parameterize\nor how do you represent T? Yeah, so then the next step is\nthat, basically, equivalently,",
    "start": "2048210",
    "end": "2056800"
  },
  {
    "text": "you can just say,\nwell, there is going to be some function\nthat we're going to call T that gives you\nthis optimal value of T star",
    "start": "2056800",
    "end": "2065530"
  },
  {
    "text": "for every x.  This doesn't change anything.",
    "start": "2065530",
    "end": "2070850"
  },
  {
    "text": "Basically, for every x,\nthere is an optimal choice of T, which comes\nfrom the supremum.",
    "start": "2070850",
    "end": "2076440"
  },
  {
    "text": "Here I'm denoting it T star. Equivalently, you\ncan say, OK, there is a function T that\ntakes x as an input",
    "start": "2076440",
    "end": "2084010"
  },
  {
    "text": "and gives you as an output\nthe supremum of that--",
    "start": "2084010",
    "end": "2089388"
  },
  {
    "text": "in that definition of\nthe convex conjugate. And then that's where you get\nthe bound, is you can say, well,",
    "start": "2089389",
    "end": "2099040"
  },
  {
    "text": "I cannot-- this would require you sort of\nlike an arbitrarily flexible function t that can\ntake any x and map it",
    "start": "2099040",
    "end": "2106779"
  },
  {
    "text": "to the solution to this\noptimization problem. Recall, this has a little\nbit of the flavor of a VAE,",
    "start": "2106780",
    "end": "2112609"
  },
  {
    "text": "amortize the\ninference in VAE where you have this encoder that is\nsupposed to take x as an input",
    "start": "2112610",
    "end": "2119140"
  },
  {
    "text": "and then map it to the optimal\nvariational parameters, like solving an optimization\nproblem for you.",
    "start": "2119140",
    "end": "2124549"
  },
  {
    "text": "This has the same\nflavor, but we can say is, well, you can\nalways optimize over",
    "start": "2124550",
    "end": "2130520"
  },
  {
    "text": "a set of functions, an\narbitrary set of functions, a set of neural\nnetworks, and that",
    "start": "2130520",
    "end": "2137330"
  },
  {
    "text": "would give you a lower\nbound on this f-divergence. So if instead of optimizing\nover all possible functions,",
    "start": "2137330",
    "end": "2146350"
  },
  {
    "text": "you optimize over a set of\nneural network architectures that you're willing\nto consider, you're",
    "start": "2146350",
    "end": "2152050"
  },
  {
    "text": "always going to\nget something that is less than or equal\nbecause you might not",
    "start": "2152050",
    "end": "2159280"
  },
  {
    "text": "have sufficient\nflexibility for mapping x to the corresponding value t\nstar of x that you would have",
    "start": "2159280",
    "end": "2165400"
  },
  {
    "text": "gotten if you could actually\nsolve this optimization problem exactly. But you definitely\nget a lower bound",
    "start": "2165400",
    "end": "2172210"
  },
  {
    "text": "for any choice of this\nfamily of mappings that you use to map data points\nto essentially something that",
    "start": "2172210",
    "end": "2181480"
  },
  {
    "text": "looks an estimate of\nthe density ratio. And the more flexible\nthis family script",
    "start": "2181480",
    "end": "2188500"
  },
  {
    "text": "T of neural networks\nyou can choose, then the tighter\nthis inequality is.",
    "start": "2188500",
    "end": "2194840"
  },
  {
    "text": "So the better of\nan approximation you get to the true\nvalue of the f-divergence",
    "start": "2194840",
    "end": "2200590"
  },
  {
    "text": "that you started with.  And back to your question,\nOK, does this depend?",
    "start": "2200590",
    "end": "2207290"
  },
  {
    "text": "It looks like this\nstill depends on p and this one still depends on q. You notice that\nthese two are just",
    "start": "2207290",
    "end": "2213190"
  },
  {
    "text": "expectations with respect to\np and q, which, in our case,",
    "start": "2213190",
    "end": "2218470"
  },
  {
    "text": "will be the data distribution\nand the model distribution. And so this is essentially\nthe same as a game",
    "start": "2218470",
    "end": "2225370"
  },
  {
    "text": "generative, adversarial\nnetwork training objective. And remember when\nyou the objective",
    "start": "2225370",
    "end": "2231369"
  },
  {
    "text": "that we were using for training\nagain is the min over g. And then we had the max over\nthe discriminator of something",
    "start": "2231370",
    "end": "2238299"
  },
  {
    "text": "that looked a lot like this. So you were sort of evaluating\nthe discriminator on the data",
    "start": "2238300",
    "end": "2244570"
  },
  {
    "text": "samples. You were evaluating\nthe discriminator on the fake samples,\nand you were trying to distinguish\nthem, contrast them",
    "start": "2244570",
    "end": "2253089"
  },
  {
    "text": "through the cross-entropy loss. And here, we get something that\nhas a very similar flavor, where",
    "start": "2253090",
    "end": "2259960"
  },
  {
    "text": "we're sort of evaluating this\ndiscriminator t over data samples, over model\nsamples, and we're",
    "start": "2259960",
    "end": "2267250"
  },
  {
    "text": "trying to essentially\ndistinguish them by maximizing that quantity.",
    "start": "2267250",
    "end": "2273055"
  },
  {
    "text": "So T is going to be [INAUDIBLE]? Yes, so when we do\nthis optimization",
    "start": "2273055",
    "end": "2278740"
  },
  {
    "text": "over T in this script\nT, that's going to be where we optimize the\ndiscriminator or a critic.",
    "start": "2278740",
    "end": "2284275"
  },
  {
    "text": " And this script T is going to\nbe a family of neural networks",
    "start": "2284275",
    "end": "2290380"
  },
  {
    "text": "that we're going to\nuse to choose T from. ",
    "start": "2290380",
    "end": "2297579"
  },
  {
    "text": "Usually, we represent\nour data distribution as p, and the proposed\ndistribution, like p theta",
    "start": "2297580",
    "end": "2306730"
  },
  {
    "text": "is q, right? Yeah. Yeah, yeah, yeah. So for this to hold, we\ndon't need the discriminator",
    "start": "2306730",
    "end": "2313330"
  },
  {
    "text": "to be optimal? So if you want\ntight, if you want",
    "start": "2313330",
    "end": "2318549"
  },
  {
    "text": "to have an exact estimate\nof the f-divergence, then the discriminator\nhas to be optimal.",
    "start": "2318550",
    "end": "2324510"
  },
  {
    "text": "But if you don't, then that\nyou're going to get at least a lower bound. So the lower bound part holds\neven if the discriminator is not",
    "start": "2324510",
    "end": "2333680"
  },
  {
    "text": "necessarily optimal. Don't you inherit\nthe same problems",
    "start": "2333680",
    "end": "2338730"
  },
  {
    "text": "like we discussed\nhaving a lower bound? Don't you inherit\nit from before?",
    "start": "2338730",
    "end": "2344000"
  },
  {
    "text": "If you don't have an\noptimal discriminator, you just inherit all the\nproblems here, right?",
    "start": "2344000",
    "end": "2349315"
  },
  {
    "text": "Yeah, it's a\nproblem in the sense that you're optimizing a bound. So it might or might not\nbe the right thing to do.",
    "start": "2349315",
    "end": "2357740"
  },
  {
    "text": "And this is a lower bound. So minimizing a\nlower bound might not be going in the right direction.",
    "start": "2357740",
    "end": "2364700"
  },
  {
    "text": "And so, yeah, you still\nhave those problems. So in that sense,\nit's approximately optimizing an f-divergence.",
    "start": "2364700",
    "end": "2372140"
  },
  {
    "text": "If you could somehow\noptimize over all possible discriminators, then, and I\nguess you had infinite data",
    "start": "2372140",
    "end": "2377852"
  },
  {
    "text": "and you were able to actually\nsolve this optimization problem perfectly,\nthen you could really optimize an f-divergence.",
    "start": "2377852",
    "end": "2384090"
  },
  {
    "text": "But in practice, no, there\nis always approximations. So in this setting, not with\nthe discriminator setting,",
    "start": "2384090",
    "end": "2390590"
  },
  {
    "text": "T is supposed to represent\nthe maximum value of x that exceeds the\nfunction of what",
    "start": "2390590",
    "end": "2396720"
  },
  {
    "text": "is the-- your supremum\ndefinition of [INAUDIBLE]?? Yeah, so it's supposed to--",
    "start": "2396720",
    "end": "2403890"
  },
  {
    "text": "essentially-- it's essentially\ncomputing the conjugate",
    "start": "2403890",
    "end": "2412970"
  },
  {
    "text": "of the conjugate of f, and\nit kind of like corresponds to finding supporting\nhyperplanes.",
    "start": "2412970",
    "end": "2418260"
  },
  {
    "text": "So you are encoding the graph of\nthe function as a convex hull. And that optimization\nproblem is trying",
    "start": "2418260",
    "end": "2425330"
  },
  {
    "text": "to find essentially\ntangent to the, to the graph of the function,\nso that's essentially",
    "start": "2425330",
    "end": "2432770"
  },
  {
    "text": "what's going on in that\noptimization problem. Has anyone thought\nabout how to do",
    "start": "2432770",
    "end": "2440180"
  },
  {
    "text": "this for an upper bound\ninstead of lower bound? Because I think it's\nmore natural to minimize an upper bound, right?",
    "start": "2440180",
    "end": "2445970"
  },
  {
    "text": "Yeah. So yeah, that's\nwhat I was saying, that in the outer\noptimization problem you're going to be minimizing\nthis, and then this",
    "start": "2445970",
    "end": "2452270"
  },
  {
    "text": "is a bound that goes\nin the wrong direction. And unfortunately, getting\nupper bounds is much harder.",
    "start": "2452270",
    "end": "2458950"
  },
  {
    "text": "There is work where people have\ntried to come up with bounds,",
    "start": "2458950",
    "end": "2464000"
  },
  {
    "text": "especially as it relates to-- it turns out that you need\nto do something similar if you want to estimate\nmutual information",
    "start": "2464000",
    "end": "2470240"
  },
  {
    "text": "between random variables,\nwhich also basically involves",
    "start": "2470240",
    "end": "2475369"
  },
  {
    "text": "some estimating density ratios. And there is literature and\ntrying to get bounds there,",
    "start": "2475370",
    "end": "2481670"
  },
  {
    "text": "but nothing that works\nparticularly well. How is it better than KL,\nthan just using KL-divergence?",
    "start": "2481670",
    "end": "2491865"
  },
  {
    "text": "[INAUDIBLE] with respect to\nthese versus KL-divergence? Is that the question? Uh-huh. Oh, it is because it\ndoesn't need likelihood,",
    "start": "2491865",
    "end": "2500470"
  },
  {
    "text": "and it achieves-- as\nwe know, KL-divergence is all based on compression,\nwhich might or might not",
    "start": "2500470",
    "end": "2506730"
  },
  {
    "text": "be what you want. These other f-divergences\nare not necessarily",
    "start": "2506730",
    "end": "2511950"
  },
  {
    "text": "capturing a\ncompression-like objective because you're\nevaluating the density",
    "start": "2511950",
    "end": "2517226"
  },
  {
    "text": "ratios in a different way. You don't just care about the\nlog of the density ratios. You can plug-in\ndifferent fs that",
    "start": "2517227",
    "end": "2523830"
  },
  {
    "text": "captures different\npreferences for how close is the model density ratios to\nthe true density ratio that's",
    "start": "2523830",
    "end": "2531450"
  },
  {
    "text": "captured through f. And that gives you more\nflexibility, basically, in defining a loss function\nfor training your model.",
    "start": "2531450",
    "end": "2539200"
  },
  {
    "text": "Which term in this pair of\nexpectations, in the GAN world, corresponds to the discriminator\nand generator [INAUDIBLE]??",
    "start": "2539200",
    "end": "2546690"
  },
  {
    "text": "Yeah, so it depends\nwhat you want to choose. So it could either be p\nis data and q is model,",
    "start": "2546690",
    "end": "2553550"
  },
  {
    "text": "or it could be vice versa. In both cases, you would\nend up with something that you can handle in the sense\nthat it's a different of two",
    "start": "2553550",
    "end": "2559660"
  },
  {
    "text": "expectations. And depending-- do you\nwant KL data model, or do you want KL model data?",
    "start": "2559660",
    "end": "2566180"
  },
  {
    "text": "Depending on what\nyou want, you need to choose the right\norder and the right f that gives you\nthe right thing.",
    "start": "2566180",
    "end": "2572650"
  },
  {
    "text": "So it could be both. It doesn't matter. From the perspective\nof this, it's just the difference\nof the expectations.",
    "start": "2572650",
    "end": "2578360"
  },
  {
    "text": "You have samples from both and\nyou can estimate both of them. Yeah, Monte Carlo. Could you explain one more\ntime how we went from the star",
    "start": "2578360",
    "end": "2587325"
  },
  {
    "text": "x to having a supremum over all\nT, from the fourth last step",
    "start": "2587325",
    "end": "2592450"
  },
  {
    "text": "to the third last step? How do we go from the\nsupremum to the T star? From the T star to [INAUDIBLE].",
    "start": "2592450",
    "end": "2599570"
  },
  {
    "text": "OK, this one? Yeah. Yeah, so this one\nis basically saying that there's going to be an\noptimal T star for every x.",
    "start": "2599570",
    "end": "2606160"
  },
  {
    "text": "In if you are allowed\nto have an arbitrary function, an arbitrarily\ncomplicated function",
    "start": "2606160",
    "end": "2612970"
  },
  {
    "text": "that basically just maps\nevery x to the corresponding T star of x, then you get\nthe same sort of result.",
    "start": "2612970",
    "end": "2620089"
  },
  {
    "text": "So you could say, for every x,\nI'm going to choose a T star,",
    "start": "2620090",
    "end": "2625100"
  },
  {
    "text": "or you could say, I'm going\nto first choose a function that maps xs to T stars.",
    "start": "2625100",
    "end": "2631540"
  },
  {
    "text": "And to the extent\nthat this function can do whatever you want,\nthen there is no difference.",
    "start": "2631540",
    "end": "2636910"
  },
  {
    "text": "You can memorize all\nthe T stars into a table and then encode that\ntable into the function t.",
    "start": "2636910",
    "end": "2643480"
  },
  {
    "text": "And so choosing the function\nor choosing the individual that basically outputs\nof the functions",
    "start": "2643480",
    "end": "2649390"
  },
  {
    "text": "across the different axes\nis actually the same thing.  We've got high,\nlow motivation here",
    "start": "2649390",
    "end": "2656040"
  },
  {
    "text": "that when we look at\nGANs, when you looked at the optimal discriminator,\nwe got the scale and the scale",
    "start": "2656040",
    "end": "2665530"
  },
  {
    "text": "things. But now we go the other way,\nwe look at different functions",
    "start": "2665530",
    "end": "2671070"
  },
  {
    "text": "here that we might get\ndifferent discriminators. Yeah, yeah, essentially. Yes, that's the way\nto think about it.",
    "start": "2671070",
    "end": "2677253"
  },
  {
    "text": "This is a generalization. In the GAN framework, the\noriginal simple thing, we started from an expression\nthat looked like this.",
    "start": "2677253",
    "end": "2684150"
  },
  {
    "text": "And then we showed,\noh, by the way, it gives you the\nJensen-Shannon divergence.",
    "start": "2684150",
    "end": "2689560"
  },
  {
    "text": "This is showing how\nyou can actually start from any\nf-divergence you want and you can get a loss\nthat looks like a GAN.",
    "start": "2689560",
    "end": "2697290"
  },
  {
    "text": "And by the way, if\nyou were to start from Jensen-Shannon\ndivergence, you would get exactly the GAN\nloss that we started with,",
    "start": "2697290",
    "end": "2704340"
  },
  {
    "text": "up to shifts in scales. ",
    "start": "2704340",
    "end": "2710240"
  },
  {
    "text": "Cool. And so yeah, then thing to\nnote is that the lower bound",
    "start": "2710240",
    "end": "2715940"
  },
  {
    "text": "is likelihood-free in the sense\nthat you can evaluate just based on samples. And once you have this kind of\nlower bound on the f-divergence,",
    "start": "2715940",
    "end": "2727400"
  },
  {
    "text": "you can get a GAN-like\nobjective as follows. You can choose an\nf-divergence of your choice.",
    "start": "2727400",
    "end": "2733730"
  },
  {
    "text": "You let, let's say, p to\nbe the data distribution, q to be the model distribution.",
    "start": "2733730",
    "end": "2740510"
  },
  {
    "text": "Defined implicitly\nthrough some generator g.",
    "start": "2740510",
    "end": "2745640"
  },
  {
    "text": "And then you parameterize\nboth using neural networks. So let's say you have a\nset of neural networks",
    "start": "2745640",
    "end": "2751820"
  },
  {
    "text": "with weights phi that\ndefine this function T that you have on the outside,\nthe discriminator, basically.",
    "start": "2751820",
    "end": "2758172"
  },
  {
    "text": "And then, you have\nsome parameters that define the generator g. And then you have an\nf-GAN training objective,",
    "start": "2758173",
    "end": "2767670"
  },
  {
    "text": "which is very similar\nto what we had before. It's again, a minimax kind of\noptimization problem where there",
    "start": "2767670",
    "end": "2774300"
  },
  {
    "text": "is the inner maximization\nproblem over phi, where you're trying to find a\ngood approximation",
    "start": "2774300",
    "end": "2779579"
  },
  {
    "text": "to the f-divergence by\nmaximizing, trying to solve this optimization problem\nas well as you can",
    "start": "2779580",
    "end": "2787750"
  },
  {
    "text": "by trying to find weights, phi,\nthat makes this expression as big as possible.",
    "start": "2787750",
    "end": "2793690"
  },
  {
    "text": "And again, this is no\nlonger of cross-entropy, but it's something\nquite similar.",
    "start": "2793690",
    "end": "2800130"
  },
  {
    "text": "And then, on the outside, you\nhave a minimization over theta because you're\ntrying to minimize",
    "start": "2800130",
    "end": "2805319"
  },
  {
    "text": "the divergence between the model\nand the theta distribution. So just like in the gun\nsetting, we have this.",
    "start": "2805320",
    "end": "2812200"
  },
  {
    "text": "The fake samples that are coming\nfrom this implicit distribution defined by a generator\nwith parameters theta.",
    "start": "2812200",
    "end": "2818170"
  },
  {
    "text": "And you can try to minimize,\nchoose the parameters theta that minimize this, this expression.",
    "start": "2818170",
    "end": "2826240"
  },
  {
    "text": "And it's basically the same\nas what we had in the--",
    "start": "2826240",
    "end": "2831880"
  },
  {
    "text": "if you were to choose the\nJensen-Shannon divergence, this would correspond\nto what we had before. But fundamentally,\nwhat's going on here",
    "start": "2831880",
    "end": "2838222"
  },
  {
    "text": "is that there is\na generator that's trying to minimize the\ndivergence estimate, and there is a\ndiscriminator is trying",
    "start": "2838222",
    "end": "2843250"
  },
  {
    "text": "to come up with the\nbest possible bound on that f-divergence.",
    "start": "2843250",
    "end": "2850600"
  },
  {
    "text": "So if I do take a KL-divergence,\ncan we still show that-- using this equation itself\ndistills down to maximal?",
    "start": "2850600",
    "end": "2858490"
  },
  {
    "text": "So it's not going\nto give you exactly maximum likelihood because\nit's an approximation unless you have infinitely\nflexible discriminators.",
    "start": "2858490",
    "end": "2867400"
  },
  {
    "text": "What people have shown\nis that if you were to-- in the original f-GAN\npaper, they basically",
    "start": "2867400",
    "end": "2872470"
  },
  {
    "text": "tested a bunch of different\nf's for f-divergence. And what they've\nshown is that if you choose the f corresponding\nto KL-divergence, then",
    "start": "2872470",
    "end": "2879580"
  },
  {
    "text": "you tend to get samples\nthat indeed give you better likelihoods,\nas you would expect,",
    "start": "2879580",
    "end": "2884920"
  },
  {
    "text": "because you're approximating\nthe KL-divergence. But as we discussed, that's\nnot necessarily the one",
    "start": "2884920",
    "end": "2891080"
  },
  {
    "text": "that gives you the\nbest sample quality. And you might be getting\nbetter sample quality if you were to choose\ndifferent f's in that paper.",
    "start": "2891080",
    "end": "2898015"
  },
  {
    "text": " Cool.",
    "start": "2898015",
    "end": "2903270"
  },
  {
    "text": "So that's the\nhigh-level takeaway.",
    "start": "2903270",
    "end": "2909780"
  },
  {
    "text": "You're not restricted\nto KL-divergence, exact KL-divergence, or\nJensen-Shannon divergence.",
    "start": "2909780",
    "end": "2916270"
  },
  {
    "text": "You can actually plug\nin other f-divergence. And using the f-GAN\ntraining objective,",
    "start": "2916270",
    "end": "2921450"
  },
  {
    "text": "you can still\napproximately optimize that notion of that divergence.",
    "start": "2921450",
    "end": "2926860"
  },
  {
    "text": " Now, the other\nthing that you can do using a very\nsimilar machinery",
    "start": "2926860",
    "end": "2934600"
  },
  {
    "text": "is optimize, yet\na different notion of divergence, which is based on\nthis idea called the Wasserstein",
    "start": "2934600",
    "end": "2943270"
  },
  {
    "text": "GAN. And the motivation for\nmoving beyond f-divergence",
    "start": "2943270",
    "end": "2948760"
  },
  {
    "text": "is that f-divergence are\nnice, they're very powerful. But there are issues when the\ndistributions p and q don't",
    "start": "2948760",
    "end": "2957070"
  },
  {
    "text": "share, they have, let's\nsay, disjoint support, which can happen, especially\nearly on in training.",
    "start": "2957070",
    "end": "2964640"
  },
  {
    "text": "The samples coming\nfrom your generator could be very, very\ndifferent from the ones that are in the training set.",
    "start": "2964640",
    "end": "2971860"
  },
  {
    "text": "And if that happens, you can\nhave this weird discontinuity where the KL-divergence is\nlike a constant, maybe infinity",
    "start": "2971860",
    "end": "2980170"
  },
  {
    "text": "or something, and then suddenly\nshifts to some better value",
    "start": "2980170",
    "end": "2986049"
  },
  {
    "text": "the moment the supports match. And that's a problem\nbecause, during training, you",
    "start": "2986050",
    "end": "2991250"
  },
  {
    "text": "don't get good signal to go\nin the direction of trying to make the support of your\nmodel distribution close",
    "start": "2991250",
    "end": "2999710"
  },
  {
    "text": "to the support of the\ndata distribution. And you can see an example here. Imagine that you have a super\nsimple data distribution where",
    "start": "2999710",
    "end": "3008410"
  },
  {
    "text": "all the probability\nmass is at zero, and then you have a\nmodel distribution where you put all the probability\nmass at this point, theta.",
    "start": "3008410",
    "end": "3017265"
  },
  {
    "text": " So if theta is zero, then the\ntwo distributions are the same.",
    "start": "3017265",
    "end": "3024940"
  },
  {
    "text": "But if theta is\ndifferent from zero, then these two distributions\ndon't share any--",
    "start": "3024940",
    "end": "3030529"
  },
  {
    "text": "the supports are different. And if you look at, let's\nsay, the KL-divergence",
    "start": "3030530",
    "end": "3037569"
  },
  {
    "text": "is going to be zero if\nthe distributions match, and it's going to be infinity\nfor any other choice of theta.",
    "start": "3037570",
    "end": "3045640"
  },
  {
    "text": "So if we're trying to train this\ngenerative, adversarial network by optimizing theta to\nreduce the KL-divergence,",
    "start": "3045640",
    "end": "3055353"
  },
  {
    "text": "you're not going\nto get any signal until you hit the exact right\nvalue that you're looking for.",
    "start": "3055353",
    "end": "3060790"
  },
  {
    "text": "And if you look at the\nJensen-Shannon divergence, you have a similar problem\nwhere basically it's",
    "start": "3060790",
    "end": "3066579"
  },
  {
    "text": "zero if you have\nthe right value, and then it's a constant for\nwhen you have the wrong value.",
    "start": "3066580",
    "end": "3072920"
  },
  {
    "text": "But again, there is no signal. There is no notion that theta\n0.5 is better than theta 10.",
    "start": "3072920",
    "end": "3080162"
  },
  {
    "text": "Ideally, that's\nsomething you would want because if you\nhave that, then you can do gradient\ndescent, and you can try to get-- to move your theta\ncloser and closer to the value",
    "start": "3080162",
    "end": "3088280"
  },
  {
    "text": "you want. But this divergences can have\ntrouble with these situations.",
    "start": "3088280",
    "end": "3096630"
  },
  {
    "text": "And so the idea\nis to try to think about other notions of\ndistance or divergences",
    "start": "3096630",
    "end": "3104460"
  },
  {
    "text": "that work even when p and\nq have disjoint support.",
    "start": "3104460",
    "end": "3110190"
  },
  {
    "text": "And the support is\njust the set with-- of points that have non-zero\nprobability under p or q.",
    "start": "3110190",
    "end": "3118860"
  },
  {
    "text": "And so, that the one way to\ndo this is to use this thing called the Wasserstein\nor the earth distance.",
    "start": "3118860",
    "end": "3127770"
  },
  {
    "text": "And the intuition is\nsomething like this. Let's say that you have\ntwo distributions, p and q.",
    "start": "3127770",
    "end": "3135180"
  },
  {
    "text": "And you can think of\nthe-- and they are just, let's say, one-dimensional. So you have the densities\nthat I'm showing there",
    "start": "3135180",
    "end": "3141540"
  },
  {
    "text": "and they are just mixtures\nof Gaussians in this case. And you can ask, How\nsimilar are p and q?",
    "start": "3141540",
    "end": "3150480"
  },
  {
    "text": "And one reasonable\nway of comparing how similar p and\nq are is to say if you think of the\nprobability mass",
    "start": "3150480",
    "end": "3157530"
  },
  {
    "text": "as being piles of\nearth or piles of dirt that you have laying\nout on this x-axis,",
    "start": "3157530",
    "end": "3165090"
  },
  {
    "text": "you can imagine how\nmuch effort would it take you if you\nwere to shovel all this dirt from\nthis configuration",
    "start": "3165090",
    "end": "3172230"
  },
  {
    "text": "to this other configuration. And intuitively,\nthe further away",
    "start": "3172230",
    "end": "3177900"
  },
  {
    "text": "you have to move this earth,\nthe more cost you pay, because you have\nto take more time. And p and q-- they\nare both normalized.",
    "start": "3177900",
    "end": "3186670"
  },
  {
    "text": "So the amount of earth\nthat you have on the left is the same as the amount\nyou have on the right,",
    "start": "3186670",
    "end": "3192390"
  },
  {
    "text": "but the more similar p and\nq are the same that you don't have to do any work. If the probability mass\nunder q is very far",
    "start": "3192390",
    "end": "3200178"
  },
  {
    "text": "from the one under p, then\nyou have to do a lot of work because you have to move all\nthis earth from various points",
    "start": "3200178",
    "end": "3207570"
  },
  {
    "text": "where you have it on\nthe left to the points where you have it on the right.",
    "start": "3207570",
    "end": "3213370"
  },
  {
    "text": "And the good thing\nabout this is that we'll see that it can handle\nsituations where the supports are different.",
    "start": "3213370",
    "end": "3218950"
  },
  {
    "text": "This kind of definition doesn't\ncare if the supports of p and q are disjoint or not. And it defines a very natural\nnotion of distance, that is,",
    "start": "3218950",
    "end": "3228910"
  },
  {
    "text": "that varies smoothly as you\nchange the shape of p and q.",
    "start": "3228910",
    "end": "3234210"
  },
  {
    "text": "And the way to\nmathematically write down",
    "start": "3234210",
    "end": "3240750"
  },
  {
    "text": "this intuition of looking at\nthe cost of transporting earth",
    "start": "3240750",
    "end": "3245790"
  },
  {
    "text": "from configuration\np to configuration q is to set up an optimization\nproblem, which looks like this.",
    "start": "3245790",
    "end": "3254780"
  },
  {
    "text": "So the Wasserstein\ndistance between P and q is going to be\nthis infimum, which",
    "start": "3254780",
    "end": "3259800"
  },
  {
    "text": "think of it as the\nminimum, basically. And this infimum is over all\njoint probability distributions",
    "start": "3259800",
    "end": "3268049"
  },
  {
    "text": "over x and y. You can think of x as\nbeing the distribution,",
    "start": "3268050",
    "end": "3274710"
  },
  {
    "text": "p being defined over x and q\nbeing defined over y, let's say, as you look at joint\ndistributions over x and y",
    "start": "3274710",
    "end": "3282630"
  },
  {
    "text": "such that the marginal\nover x matches p and the marginal\nover y matches q.",
    "start": "3282630",
    "end": "3291299"
  },
  {
    "text": "And what you do is, over\nall these probability,",
    "start": "3291300",
    "end": "3296500"
  },
  {
    "text": "joint probability distributions,\nthat you have here, that you are optimizing over,\nyou look at the expected cost",
    "start": "3296500",
    "end": "3303370"
  },
  {
    "text": "that you get when you draw x and\ny from this joint distribution. And the cost is the thing\nthat we talked about,",
    "start": "3303370",
    "end": "3310210"
  },
  {
    "text": "which is basically\nhow much effort it takes to go from x to y. And in this case, this is\nmeasured with this L1 distance.",
    "start": "3310210",
    "end": "3318330"
  },
  {
    "text": "You can choose other\nchoices, but for now, you can think of it basically\nthe absolute value in 1d of x minus y.",
    "start": "3318330",
    "end": "3328280"
  },
  {
    "text": "And you can think\nof this gamma x, y,",
    "start": "3328280",
    "end": "3333740"
  },
  {
    "text": "which is a joint\ndistribution over x and y, as basically telling you\nhow much probability I'm",
    "start": "3333740",
    "end": "3343820"
  },
  {
    "text": "moving from x to y. And so what this is saying\nis that this condition",
    "start": "3343820",
    "end": "3349850"
  },
  {
    "text": "here, that the marginal\nover x is p of x. This is saying that\nat the beginning,",
    "start": "3349850",
    "end": "3355310"
  },
  {
    "text": "you can't you can't move more\nprobability mass than what you started from at x.",
    "start": "3355310",
    "end": "3360530"
  },
  {
    "text": "And the fact that the\nmarginal over y is qy means that the final\nresult, the amount of earth",
    "start": "3360530",
    "end": "3371510"
  },
  {
    "text": "that you find at position\ny, is indeed the one that you want to get in the\nfinal configuration, which is",
    "start": "3371510",
    "end": "3377930"
  },
  {
    "text": "the one you're trying to get. And this objective\nfunction here is telling you what is the cost\nof moving earth basically",
    "start": "3377930",
    "end": "3385539"
  },
  {
    "text": "from x to y. So equivalently, you can think\nof the conditional distribution of y given x as telling you\nwhich fraction of the earth that",
    "start": "3385540",
    "end": "3395349"
  },
  {
    "text": "I have at location x am I going\nto move to the different y's. ",
    "start": "3395350",
    "end": "3402049"
  },
  {
    "text": "And so you can see that then,\nif you look at this expectation, this is telling\nyou in expectation, how much are you going-- how\nmuch is this going to cost you.",
    "start": "3402050",
    "end": "3409410"
  },
  {
    "text": "Well, you look at x,\nyou look at the y's you're moving the\nearth to, you look at the difference\nbetween the two,",
    "start": "3409410",
    "end": "3415400"
  },
  {
    "text": "and that tells you how\nmuch it costs you to-- for a given x, if you take the\nexpectation with respect to y--",
    "start": "3415400",
    "end": "3423270"
  },
  {
    "text": "Gamma y given x,\nit's telling you the cost of moving all the\nprobability mass that you have at x to the places you\nwant it to move it to, which--",
    "start": "3423270",
    "end": "3432470"
  },
  {
    "text": "because of this\nconstraint here, it has to match the final\nresult that you want. ",
    "start": "3432470",
    "end": "3441180"
  },
  {
    "text": "And so that's basically the\noptimization problem that",
    "start": "3441180",
    "end": "3446220"
  },
  {
    "text": "defines this intuition of\ntelling us how much work do you have to do if\nyou want to move this,",
    "start": "3446220",
    "end": "3453860"
  },
  {
    "text": "you want to morph this\nprobability distribution here into the probability\ndistribution q that you have as an outcome.",
    "start": "3453860",
    "end": "3463100"
  },
  {
    "text": "And just to get a sense\nof what this looks like, in the previous example\nwhere we had this data",
    "start": "3463100",
    "end": "3470420"
  },
  {
    "text": "distribution, where all the\nprobability mass is at zero, and this model distribution\nwhere all the probability",
    "start": "3470420",
    "end": "3475730"
  },
  {
    "text": "mass is at theta, this one, the\nKL-divergence between these two",
    "start": "3475730",
    "end": "3480740"
  },
  {
    "text": "objects is not very useful. But if you think about what is\nthe earth mover distance here,",
    "start": "3480740",
    "end": "3486020"
  },
  {
    "text": "how much work do you need to do. If you want to move all the\nprobability mass from here to here--",
    "start": "3486020",
    "end": "3492900"
  },
  {
    "text": "basically you have a big\nspike at 0 on the left, and then you have a big\nspike at theta on the right,",
    "start": "3492900",
    "end": "3498937"
  },
  {
    "text": "how much work do you need to do.  X minus theta?",
    "start": "3498937",
    "end": "3505470"
  },
  {
    "text": "Yeah, so it says absolute\nvalue of theta technically. And so you can see\nthat now it's starting",
    "start": "3505470",
    "end": "3513110"
  },
  {
    "text": "to be more reasonable\nin the sense that the closer q\ntheta is to the target.",
    "start": "3513110",
    "end": "3519390"
  },
  {
    "text": "p, the smaller\nthis divergence is, which you might expect\nit might give you maybe",
    "start": "3519390",
    "end": "3526940"
  },
  {
    "text": "a much better learning\nobjective because you have much better\ngradients, you're kind of--",
    "start": "3526940",
    "end": "3533051"
  },
  {
    "text": "you have a notion of\nhow close you are, how much progress you're making\ntowards achieving your goal.",
    "start": "3533051",
    "end": "3538860"
  },
  {
    "text": "And to the extent that you\ncan really compute this thing, and we'll see how to do\nthat, this would mean--",
    "start": "3538860",
    "end": "3544470"
  },
  {
    "text": "this would be a pretty good\nlearning objective to use. [INAUDIBLE] confused\nabout definitions",
    "start": "3544470",
    "end": "3550430"
  },
  {
    "text": "of p and q and\nthe distributions. There are two\ndistributions [INAUDIBLE].. Are you saying we can have\nmultiple joint distributions",
    "start": "3550430",
    "end": "3555950"
  },
  {
    "text": "of p and q? Yeah, there is an infinite\nnumber of joint distributions",
    "start": "3555950",
    "end": "3561290"
  },
  {
    "text": "that have given marginals. If you think about it, this\nis actually a pretty mild set",
    "start": "3561290",
    "end": "3566720"
  },
  {
    "text": "of constraints. I was just saying that for\nevery x the marginal under gamma",
    "start": "3566720",
    "end": "3575000"
  },
  {
    "text": "has to match the distribution\nat you started from.",
    "start": "3575000",
    "end": "3580170"
  },
  {
    "text": "So this is like saying that if\nyou think of gamma x, comma, y",
    "start": "3580170",
    "end": "3585390"
  },
  {
    "text": "as the amount of earth\nthat is moved from x to y, this is saying that the total\namount of earth that you--",
    "start": "3585390",
    "end": "3594000"
  },
  {
    "text": "or actually that is-- yeah, that the total amount\nof earth that you move has to be the, the amount\nthat you had to begin with.",
    "start": "3594000",
    "end": "3602849"
  },
  {
    "text": "And this is saying that the\nother constraint is saying that if you look at the amount\nof earth that you get at the end",
    "start": "3602850",
    "end": "3611150"
  },
  {
    "text": "after you moved everything\nfrom all the various axes, it has to match\nwhat you want, which",
    "start": "3611150",
    "end": "3616520"
  },
  {
    "text": "is the final result,\nthe final q of y, which is the amount of earth\nthat you want after you've done",
    "start": "3616520",
    "end": "3623720"
  },
  {
    "text": "all this transport, after you've\nmoved all the probability mass. ",
    "start": "3623720",
    "end": "3632990"
  },
  {
    "text": "So, yeah, there are-- if you have two\nrandom variables you can think about many\ndifferent joint distributions",
    "start": "3632990",
    "end": "3639820"
  },
  {
    "text": "with the same marginals. If you think about two\nbinary random variables, these two random variables\ncould be independent,",
    "start": "3639820",
    "end": "3645650"
  },
  {
    "text": "they could be highly dependent,\nand the joint distribution is what tells you how related-- how they are related\nto each other.",
    "start": "3645650",
    "end": "3652250"
  },
  {
    "text": "So there is many\njoint distributions with the same marginals. And in this case, the\nrelationship between them",
    "start": "3652250",
    "end": "3658930"
  },
  {
    "text": "is telling you how much-- yeah, how coupled they are and\nwhere you're going to move,",
    "start": "3658930",
    "end": "3665410"
  },
  {
    "text": "probability mass from\none to the other.  Yeah.",
    "start": "3665410",
    "end": "3670420"
  },
  {
    "text": "Can you go over what\nexactly does [INAUDIBLE]",
    "start": "3670420",
    "end": "3676869"
  },
  {
    "text": "term inside the expectation\nindicates [INAUDIBLE]?? Yeah, so basically what\nthis is saying is--",
    "start": "3676870",
    "end": "3683620"
  },
  {
    "text": "it's just the L1\nnorm, which in 1D, you can think of it as just the\nabsolute value of x minus y--",
    "start": "3683620",
    "end": "3690400"
  },
  {
    "text": "and this is just saying that\nwhen x and y are far away, they're going to pay a higher\ncost because transporting",
    "start": "3690400",
    "end": "3700480"
  },
  {
    "text": "from here to Palo Alto\nis cheaper than from here to San Francisco. And so you can think of--",
    "start": "3700480",
    "end": "3705789"
  },
  {
    "text": "the x-axis is kind\nof like measured in kilometers or something. And then you would-- x minus\ny is just like the distance",
    "start": "3705790",
    "end": "3714010"
  },
  {
    "text": "that you have to travel to go\nfrom one point to the other. And so ideally, you would\nwant to choose a gamma such",
    "start": "3714010",
    "end": "3723010"
  },
  {
    "text": "that when you sample\nfrom it, x and y are very close to each other.",
    "start": "3723010",
    "end": "3729420"
  },
  {
    "text": "So you minimize the amount\nof work that you have to do. But that's non-trivial\nbecause you also have to satisfy\nthese constraints,",
    "start": "3729420",
    "end": "3735990"
  },
  {
    "text": "that's at the end of the day\nyou've moved all the probability mass that you have\nto move, and you",
    "start": "3735990",
    "end": "3741540"
  },
  {
    "text": "get this q configuration\nas a final result, which",
    "start": "3741540",
    "end": "3746730"
  },
  {
    "text": "is this constraint that is\nsaying the marginal over y is q of y. And this constraint is just\nsaying you cannot create earth",
    "start": "3746730",
    "end": "3755339"
  },
  {
    "text": "out of nowhere. You have to move the earth\nthat you started from-- you have to go from\nthe configuration",
    "start": "3755340",
    "end": "3760559"
  },
  {
    "text": "that you have on the\nleft, which is p, to the configuration that you\nhave on the right, which is q. And these constraints\nhere on the marginals",
    "start": "3760560",
    "end": "3766730"
  },
  {
    "text": "are basically just saying that\nthat's the initial condition, that's the final condition. That's the cost that\nyou incur whenever",
    "start": "3766730",
    "end": "3773099"
  },
  {
    "text": "you move earth from x to y. [INAUDIBLE]",
    "start": "3773100",
    "end": "3779165"
  },
  {
    "text": "The [INAUDIBLE],, think of\nit as the minimum, yeah. ",
    "start": "3779165",
    "end": "3785135"
  },
  {
    "text": "So again, basically,\nyou want to choose a gamma, y given x that puts\nas much probability mass on y's",
    "start": "3785135",
    "end": "3791380"
  },
  {
    "text": "that are close to x as possible. But then you can't, not always\ncan do it because sometimes you",
    "start": "3791380",
    "end": "3797230"
  },
  {
    "text": "do have to move away. If you have to move\nprobability mass out here and you didn't have any, then\nyou have to take it somewhere.",
    "start": "3797230",
    "end": "3804369"
  },
  {
    "text": "And this optimization\nproblem tells you what's the optimal way of-- what's the optimal\ntransport plan",
    "start": "3804370",
    "end": "3810040"
  },
  {
    "text": "that moves the mass from\none setting to the other. And again, we're\nbasically in a situation",
    "start": "3810040",
    "end": "3816190"
  },
  {
    "text": "where the original objective\nfunction is reasonable,",
    "start": "3816190",
    "end": "3821650"
  },
  {
    "text": "makes sense. It would be good\nto optimize, but it looks like not something\nwe can actually compute because, as usual, p and\nq should be a model and a data",
    "start": "3821650",
    "end": "3831700"
  },
  {
    "text": "distribution. We don't know how to\nevaluate probabilities according to one or\nthe other, so that",
    "start": "3831700",
    "end": "3837760"
  },
  {
    "text": "doesn't look like\nsomething we can optimize. But it turns out that there is\na variational characterization,",
    "start": "3837760",
    "end": "3845640"
  },
  {
    "text": "or there is a way to\nbasically write it down as the solution of an\noptimization problem,",
    "start": "3845640",
    "end": "3852119"
  },
  {
    "text": "that we can then approximate\nusing some discriminator or some neural network.",
    "start": "3852120",
    "end": "3857780"
  },
  {
    "text": "And it's possible to show\nthat this Wasserstein distance or earth mover distance\nis equal to the solution",
    "start": "3857780",
    "end": "3865950"
  },
  {
    "text": "to this optimization\nproblem where you have a difference\nof expectations,",
    "start": "3865950",
    "end": "3871390"
  },
  {
    "text": "one with respect to p and\none with respect to q. Again, it's very similar\nto the GAN setting.",
    "start": "3871390",
    "end": "3877420"
  },
  {
    "text": "And the only difference is\nthat now what we're doing is we're optimizing over\nfunctions that have Lipschitz",
    "start": "3877420",
    "end": "3886410"
  },
  {
    "text": "constant 1, which basically\nmeans you need to optimize over all functions that basically\ndon't change too rapidly.",
    "start": "3886410",
    "end": "3893210"
  },
  {
    "text": " And so the solution to\nthis optimization problem",
    "start": "3893210",
    "end": "3899050"
  },
  {
    "text": "or this scalar\nfunctions f is actually equal to the\nWasserstein distance.",
    "start": "3899050",
    "end": "3906040"
  },
  {
    "text": "And notice here, we don't\nhave f stars anymore. This is really just the\ndifference in expectations",
    "start": "3906040",
    "end": "3911890"
  },
  {
    "text": "between p and q. And so if you didn't\nhave any constraint,",
    "start": "3911890",
    "end": "3916930"
  },
  {
    "text": "then you could make\nthat thing blow up very easily because you\ncould just pick a point where",
    "start": "3916930",
    "end": "3925135"
  },
  {
    "text": "the probabilities are\ndifferent, and then you could make just\nincrease the value of f at that point arbitrarily.",
    "start": "3925135",
    "end": "3931779"
  },
  {
    "text": "And then you could make this\nobjective here extremely large",
    "start": "3931780",
    "end": "3938860"
  },
  {
    "text": "or extremely small. But you cannot do it. You cannot choose an arbitrary\nfunction f because you have this",
    "start": "3938860",
    "end": "3946990"
  },
  {
    "text": "constraint that basically the\nshape of f cannot change too rapidly.",
    "start": "3946990",
    "end": "3952420"
  },
  {
    "text": "It has to have Lipschitz\nconstant 1, which basically means that if you go\nthrough the graph of f",
    "start": "3952420",
    "end": "3957940"
  },
  {
    "text": "and you take any two points, x\nand y, the slope that you see is bounded by 1, essentially.",
    "start": "3957940",
    "end": "3964130"
  },
  {
    "text": " And again, this optimization\nproblem by itself",
    "start": "3964130",
    "end": "3970320"
  },
  {
    "text": "is not quite something\nwe can solve. But in practice,\nwhat you can do is you can approximate the\ninner this optimization",
    "start": "3970320",
    "end": "3977700"
  },
  {
    "text": "problem over all discriminators\nthat are trying to tell you,",
    "start": "3977700",
    "end": "3984410"
  },
  {
    "text": "think about it, what is\nthis objective doing? You're looking for points where\nthe probability mass under p",
    "start": "3984410",
    "end": "3990140"
  },
  {
    "text": "and q is different. So you can find these\npoints, then you can increase the value of f. And you can get a high value in\nthat difference of expectations.",
    "start": "3990140",
    "end": "4000710"
  },
  {
    "text": "And so you can\napproximate that problem of trying to find\nx's that are given",
    "start": "4000710",
    "end": "4005900"
  },
  {
    "text": "different probabilities\nunder model and data by training a neural network,\nwhich is, again, going to be",
    "start": "4005900",
    "end": "4011870"
  },
  {
    "text": "some kind of discriminator. And at this point, there is,\nagain, no cross-entropy loss.",
    "start": "4011870",
    "end": "4018112"
  },
  {
    "text": "You're just trying to\nfind a network that can take high values on the\ndata points and low values",
    "start": "4018112",
    "end": "4023720"
  },
  {
    "text": "on the fake data. And to enforce the\nLipschitzness-- enforcing",
    "start": "4023720",
    "end": "4030500"
  },
  {
    "text": "Lipschitzness is hard. But in practice, what\nyou can do is, as usual, you don't want this network\nto be arbitrarily changing",
    "start": "4030500",
    "end": "4037040"
  },
  {
    "text": "too fast, too much. And then, in practice, what\nyou do is you would either clip the weights, or you\nwould enforce a penalty",
    "start": "4037040",
    "end": "4044600"
  },
  {
    "text": "on the gradient of this\ndiscriminator so that, again, it cannot change too much,\nit cannot change too rapidly.",
    "start": "4044600",
    "end": "4053355"
  },
  {
    "text": "I think you have mentioned this. I was trying to understand\nthe relationship between the neutrality and\nthe earth mover distance.",
    "start": "4053355",
    "end": "4062280"
  },
  {
    "text": "So are they equivalent? So the earth mover\ndistance is this quantity you have on the left.",
    "start": "4062280",
    "end": "4067760"
  },
  {
    "text": "So to the extent that you\ncould solve this optimization problem on the\nright, then you would",
    "start": "4067760",
    "end": "4072770"
  },
  {
    "text": "be able to compute exactly\nthe earth mover distance. OK, so then-- so basically,\nthe optimized solutions",
    "start": "4072770",
    "end": "4081140"
  },
  {
    "text": "on the right-hand side\nwere equivalent to the-- Yeah. And intuitively, this\nfunction f is telling you",
    "start": "4081140",
    "end": "4090700"
  },
  {
    "text": "where there is a discrepancy\nin probability mass between p and q. So if there are x's that are\ngiven different probabilities",
    "start": "4090700",
    "end": "4098109"
  },
  {
    "text": "under p and q, then f will try\nto choose a large value ideally.",
    "start": "4098109",
    "end": "4104679"
  },
  {
    "text": "But then, because of this\nLipschitzness constraint, then you cannot make\nit arbitrarily big, you cannot go to infinity.",
    "start": "4104680",
    "end": "4110290"
  },
  {
    "text": "So you have to somehow be\nsmooth and, at the same time,",
    "start": "4110290",
    "end": "4115600"
  },
  {
    "text": "try to find differences\nbetween p and q. [INAUDIBLE] this\noptimization problem",
    "start": "4115600",
    "end": "4120700"
  },
  {
    "text": "guarantees to find\nthe solutions? So if you can solve\nthis one, yes, this",
    "start": "4120700",
    "end": "4126729"
  },
  {
    "text": "will give you exactly\nthe Wasserstein. The problem is that in\npractice, you cannot--",
    "start": "4126729",
    "end": "4133009"
  },
  {
    "text": "before, like in\nthe f-GAN setting, you can't really optimize that.",
    "start": "4133010",
    "end": "4138660"
  },
  {
    "text": "And so in practice, you\nwould use approximations where you just use\nsome discriminator.",
    "start": "4138660",
    "end": "4144910"
  },
  {
    "text": "And you try to make sure\nthat the discriminator is not too powerful. And you try to restrict\nbasically how powerful",
    "start": "4144910",
    "end": "4151420"
  },
  {
    "text": "the discriminator is by either,\nfor example, trying to reduce,",
    "start": "4151420",
    "end": "4157028"
  },
  {
    "text": "trying to have a penalty term\non the gradient of with respect to the inputs of the\ndiscriminator so that it cannot",
    "start": "4157029",
    "end": "4163479"
  },
  {
    "text": "change too much. And this doesn't\ngive you bounds. So unlike the\nf-divergence setting,",
    "start": "4163479",
    "end": "4171469"
  },
  {
    "text": "this is just an approximation. It doesn't necessarily\ngive you bounds. So [INAUDIBLE] we have no\nguarantee that the Lipschitz",
    "start": "4171470",
    "end": "4181310"
  },
  {
    "text": "constant will be [INAUDIBLE]? Yeah. OK. Yeah.",
    "start": "4181310",
    "end": "4187609"
  },
  {
    "text": "It's very interesting to me. Even though the math\nderivation are very different, but the end objective--\nthey all look",
    "start": "4187609",
    "end": "4193790"
  },
  {
    "text": "awfully similar to each other? [LAUGHTER] Yeah, so they're all based on\nthe very similar idea where",
    "start": "4193790",
    "end": "4198800"
  },
  {
    "text": "you're trying to find a witness\nfunction, a discriminator, or some kind of classifier that\nis trying to distinguish samples",
    "start": "4198800",
    "end": "4206690"
  },
  {
    "text": "coming from p, from\nsamples coming from q. And depending-- you have to\nrestrict what this witness",
    "start": "4206690",
    "end": "4213560"
  },
  {
    "text": "function or this\nclassifier does in some way and/or you change the\nway you're scoring",
    "start": "4213560",
    "end": "4218900"
  },
  {
    "text": "what this classifier does. And depending on\nhow you do that, you measure similarity\nbasically in different ways.",
    "start": "4218900",
    "end": "4226850"
  },
  {
    "text": "And if you restrict\nthis discriminator to be-- to have a Lipschitz\nconstant of at most 1,",
    "start": "4226850",
    "end": "4233570"
  },
  {
    "text": "then you get Wasserstein. If you use an\narbitrary function, but then you score it with\nrespect to that f star,",
    "start": "4233570",
    "end": "4240110"
  },
  {
    "text": "then you get an f-divergence,\nand so forth, yeah.",
    "start": "4240110",
    "end": "4245300"
  },
  {
    "text": "But the main\nadvantage of this is that it's much easier to train. So in practice, this\nis very often used.",
    "start": "4245300",
    "end": "4253290"
  },
  {
    "text": "And you can see an\nexample here where you can imagine a setting where\nyou have real data that is just",
    "start": "4253290",
    "end": "4259940"
  },
  {
    "text": "a Gaussian that is here. So you see all the\nsamples that are coming, that are these blue dots that.",
    "start": "4259940",
    "end": "4265989"
  },
  {
    "text": "They're lying around here. And then you have a model. Let's say you start out\nwith a bad initialization",
    "start": "4265990",
    "end": "4272630"
  },
  {
    "text": "for your generator, and\nmost of your samples are, again, a Gaussian, but\nsomehow the means are different.",
    "start": "4272630",
    "end": "4278760"
  },
  {
    "text": "And so all your samples\nare here, these green dots. And if you get\nthe discriminator,",
    "start": "4278760",
    "end": "4285068"
  },
  {
    "text": "the discriminator will\nhave a very good job at distinguishing\nbetween the blue samples and the green samples.",
    "start": "4285068",
    "end": "4290470"
  },
  {
    "text": "And it will be a sigmoid,\nbut it's extremely steep. So basically,\neverything to the left",
    "start": "4290470",
    "end": "4297990"
  },
  {
    "text": "here will be classified as real. And everything to the right\nwill be classified as fake. But it's almost entirely flat.",
    "start": "4297990",
    "end": "4305390"
  },
  {
    "text": "And so when you think\nabout trying to figure out, when you update the generator to\ntry to fool the discriminator,",
    "start": "4305390",
    "end": "4312840"
  },
  {
    "text": "you don't get a whole lot of\nsignal in terms of moving-- in which direction should\nyou move these data points",
    "start": "4312840",
    "end": "4319020"
  },
  {
    "text": "because the green-- the red curve is too flat. And so it's very tricky\nto actually get this model",
    "start": "4319020",
    "end": "4326720"
  },
  {
    "text": "to learn and be able to learn\nhow to push the data points, the fake data points\ntowards the right.",
    "start": "4326720",
    "end": "4332810"
  },
  {
    "text": "But if you think about the\nWasserstein GAN critic, which is just the discriminator, it's\nalmost like a linear function.",
    "start": "4332810",
    "end": "4341300"
  },
  {
    "text": "It's this light blue curve. And if you are from the\nperspective of the generator",
    "start": "4341300",
    "end": "4349800"
  },
  {
    "text": "and you're trying to reduce the\nsame objective function that",
    "start": "4349800",
    "end": "4359190"
  },
  {
    "text": "was being optimized\nby the critic, you have a much\nbetter learning signal",
    "start": "4359190",
    "end": "4365670"
  },
  {
    "text": "to push your data\npoints to the left. And you kind of know that,\nyeah, this data points out here",
    "start": "4365670",
    "end": "4371880"
  },
  {
    "text": "are much better than the\ndata points out there. How do we calculate\nthis, the Wasserstein GAN",
    "start": "4371880",
    "end": "4379800"
  },
  {
    "text": "curve, the critic? In this case, I guess you can\neven do it in closed form.",
    "start": "4379800",
    "end": "4386130"
  },
  {
    "text": "I don't know if they did it--",
    "start": "4386130",
    "end": "4391380"
  },
  {
    "text": "you could probably also\napproximate it somehow. But if it's just\ntwo Gaussians, I",
    "start": "4391380",
    "end": "4396600"
  },
  {
    "text": "think you can do\nit in closed form. But why are the\nslopes different?",
    "start": "4396600",
    "end": "4403210"
  },
  {
    "text": "They have different directions. [INAUDIBLE] discriminating?",
    "start": "4403210",
    "end": "4411650"
  },
  {
    "text": "Yeah, so I guess you would\nstill try to minimize the-- so this this is the decision\nboundary, which is not--",
    "start": "4411650",
    "end": "4423830"
  },
  {
    "text": "well, yeah, I guess\nyou would still go. You would try to-- yeah, because it\nwould be the opposite.",
    "start": "4423830",
    "end": "4429240"
  },
  {
    "text": "So you're trying\nto make it fake. So you would still\npush towards the left.",
    "start": "4429240",
    "end": "4435700"
  },
  {
    "text": "And from the perspective\nof the W-GAN, you would still try to minimize\nfrom the G, the perspective.",
    "start": "4435700",
    "end": "4442400"
  },
  {
    "text": "You will minimize this\nexpression that you have inside. And so again, you would\npush the points to the left",
    "start": "4442400",
    "end": "4449830"
  },
  {
    "text": "because this blue curve, the\nlight blue curve goes down. And so I think\nit's just that it's",
    "start": "4449830",
    "end": "4455850"
  },
  {
    "text": "plotting probability of fake\ninstead of plotting probability of real. So that's why it's going\nin the wrong direction.",
    "start": "4455850",
    "end": "4461120"
  },
  {
    "start": "4461120",
    "end": "4467740"
  },
  {
    "text": "OK, yeah. Can you go over again how\nusing this form of divergence",
    "start": "4467740",
    "end": "4474820"
  },
  {
    "text": "is better than the f-divergence? Yeah, so the reason, you\ncan actually see it here. And it's just that you have\nbasically better learning",
    "start": "4474820",
    "end": "4482540"
  },
  {
    "text": "signal. And it's similar to what\nwe were talking about here, that if the distributions\nare too different, then",
    "start": "4482540",
    "end": "4489190"
  },
  {
    "text": "with respect to\nKL-divergence, you might not have good enough\nsignal that tells you",
    "start": "4489190",
    "end": "4495489"
  },
  {
    "text": "if you put all-- in this\ncase, putting the probability mass at 1/2 is better than\nputting the probability",
    "start": "4495490",
    "end": "4500620"
  },
  {
    "text": "mass at 10. With respect to the\nWasserstein, this would show up\nbecause there would",
    "start": "4500620",
    "end": "4505630"
  },
  {
    "text": "be a difference between\nthose two settings. And 1/2 is closer to the\nground truth than 10.",
    "start": "4505630",
    "end": "4511150"
  },
  {
    "text": "And so you would be able\nto do gradient descent on that objective\nwith respect to theta,",
    "start": "4511150",
    "end": "4516490"
  },
  {
    "text": "and you would get\ncloser and closer. With respect to KL,\nyou don't quite see it. And in practice, you\ncan also see it here,",
    "start": "4516490",
    "end": "4524260"
  },
  {
    "text": "where basically doing\noptimization from the generator",
    "start": "4524260",
    "end": "4529429"
  },
  {
    "text": "perspective, doing\noptimization by minimizing the light blue curve is\nmuch easier than trying",
    "start": "4529430",
    "end": "4536929"
  },
  {
    "text": "to fool the discriminator\nin the regular GAN setting because this is these vanishing\ngradients, and it's too flat.",
    "start": "4536930",
    "end": "4545304"
  },
  {
    "text": " So [INAUDIBLE] we understand\nthis Wasserstein, W-GANs,",
    "start": "4545305",
    "end": "4553280"
  },
  {
    "text": "have a better statistics\ntesting something?",
    "start": "4553280",
    "end": "4560000"
  },
  {
    "text": "Yeah, I don't know\nif you can formally prove that it's more\npowerful than a regular GAN.",
    "start": "4560000",
    "end": "4567060"
  },
  {
    "text": "I think it probably-- It is like [INAUDIBLE] GANs tell\nif it's a fake or not, right?",
    "start": "4567060",
    "end": "4574510"
  },
  {
    "text": "But this shows you the\ndistance between the-- Yeah, they're just--\nthey're measuring",
    "start": "4574510",
    "end": "4581389"
  },
  {
    "text": "distance in a different way. And I don't know, in general,\nyou could say you would probably have to make some\nassumptions on p and q",
    "start": "4581390",
    "end": "4587377"
  },
  {
    "text": "to say which one is better\nand which one is worse. I think, in general, I think,\nfrom this, it's more like--",
    "start": "4587377",
    "end": "4596090"
  },
  {
    "text": "if you had access to infinitely\npowerful discriminators, I think in that\nworld, I think it--",
    "start": "4596090",
    "end": "4604490"
  },
  {
    "text": "both would probably work. I think in practice, you\nalways have approximations, and you are optimizing\nover restricted families",
    "start": "4604490",
    "end": "4611940"
  },
  {
    "text": "of discriminators. And you have this minimax thing\nwhere you cannot actually solve the problems to optimality.",
    "start": "4611940",
    "end": "4617320"
  },
  {
    "text": "And it turns out that optimizing\nthe Wasserstein-type objective",
    "start": "4617320",
    "end": "4622409"
  },
  {
    "text": "is much more stable in practice. ",
    "start": "4622410",
    "end": "4629380"
  },
  {
    "text": "Cool. Maybe the last thing we\ncan briefly talk about",
    "start": "4629380",
    "end": "4635320"
  },
  {
    "text": "is how to actually-- inferring latent\nrepresentations in GANs,",
    "start": "4635320",
    "end": "4640460"
  },
  {
    "text": "this is going to be a bit of\na shift in terms of the topic. But once you train a GAN, you\nhave these latent variables",
    "start": "4640460",
    "end": "4647230"
  },
  {
    "text": "that are mapped to\nobserved variables. And you might wonder-- it looks like VAE.",
    "start": "4647230",
    "end": "4652960"
  },
  {
    "text": "--to what extent are you\nable to recover z given x? Let's say if you wanted\nfeatures or something like that.",
    "start": "4652960",
    "end": "4660910"
  },
  {
    "text": "And one way to do it. The problem is that it's no\nlonger an invertible mapping,",
    "start": "4660910",
    "end": "4667960"
  },
  {
    "text": "and you don't have an encoder. So in the flow mapping setting,\nyou just invert the generator.",
    "start": "4667960",
    "end": "4675820"
  },
  {
    "text": "So given an x, you\nfigure out what was the z that would\nbe mapped to that x. In the variational autoencoder,\nyou have the inference model,",
    "start": "4675820",
    "end": "4683260"
  },
  {
    "text": "you have the encoder that\nis doing that job for you. In a GAN, you don't\nquite have it.",
    "start": "4683260",
    "end": "4689360"
  },
  {
    "text": "So one way to get\nfeatures from a GAN is to actually look\nat the discriminator.",
    "start": "4689360",
    "end": "4695300"
  },
  {
    "text": "So the discriminator is trying\nto distinguish real data from fake data. So presumably, to\ndo well at that job.",
    "start": "4695300",
    "end": "4701090"
  },
  {
    "text": "It has to figure out interesting\nfeatures of the data. And so you can try to\ntake the discriminator",
    "start": "4701090",
    "end": "4708450"
  },
  {
    "text": "and fine-tune it\non different tasks or, take the\nrepresentations that you",
    "start": "4708450",
    "end": "4713600"
  },
  {
    "text": "get towards the end\nof the neural network and hope that those\nfeatures are actually",
    "start": "4713600",
    "end": "4720530"
  },
  {
    "text": "useful for other kinds of tasks. If they were helpful for\ndistinguishing real data from fake data, they might\nwork for other tasks as well.",
    "start": "4720530",
    "end": "4727555"
  },
  {
    "text": " But if you want to\nget the z variables",
    "start": "4727555",
    "end": "4735560"
  },
  {
    "text": "from the discriminator, from\nthe generator like in the VAE, then you need a different\nlearning algorithm.",
    "start": "4735560",
    "end": "4742159"
  },
  {
    "text": "And the problem is\nthat in a regular GAN, you're basically just\nlooking at the x part.",
    "start": "4742160",
    "end": "4748610"
  },
  {
    "text": "And somehow, we need to\nchange the training objective to also look at the z part\nand the latent variables.",
    "start": "4748610",
    "end": "4755120"
  },
  {
    "text": "And the way to do it\nis to basically change the way you set up the two\nsample tests or this likelihood",
    "start": "4755120",
    "end": "4762020"
  },
  {
    "text": "free learning objectives\nto not only compare the x samples that\nyou get from the model",
    "start": "4762020",
    "end": "4767360"
  },
  {
    "text": "to the real data\nsamples, but to also look at the representations,\nthe kind of zs that produced",
    "start": "4767360",
    "end": "4774380"
  },
  {
    "text": "the samples that you see. And the thing is that when\nyou sample from the model,",
    "start": "4774380",
    "end": "4781920"
  },
  {
    "text": "you get to see both\nthe x and the z part because you're\nsampling them yourself.",
    "start": "4781920",
    "end": "4787350"
  },
  {
    "text": "But in the data, you\nonly get to see the x. There is no corresponding z.",
    "start": "4787350",
    "end": "4793020"
  },
  {
    "text": "And so the way to do it is to\nessentially just like in VAE,",
    "start": "4793020",
    "end": "4798150"
  },
  {
    "text": "introduce an encoder network\nthat will map x to a latent--",
    "start": "4798150",
    "end": "4803790"
  },
  {
    "text": "to the corresponding\nlatent representation z. And so the architecture\nlooks like this.",
    "start": "4803790",
    "end": "4810370"
  },
  {
    "text": "It's called the BiGAN\nbecause it involves-- it goes in two directions.",
    "start": "4810370",
    "end": "4815440"
  },
  {
    "text": "So you have latent features\nthat get mapped to data through the generator,\nand then you have data that gets\nmapped to latent features",
    "start": "4815440",
    "end": "4822270"
  },
  {
    "text": "through some encoder network. And then, the job\nof the discriminator",
    "start": "4822270",
    "end": "4828300"
  },
  {
    "text": "is to not only distinguish\ngz from x, fake samples from real samples, but\nnow the discriminator",
    "start": "4828300",
    "end": "4835770"
  },
  {
    "text": "is going to try to distinguish\nfake samples with the latent",
    "start": "4835770",
    "end": "4841210"
  },
  {
    "text": "variables from the model,\nfrom real samples and latent variables inferred\nfrom the encoder.",
    "start": "4841210",
    "end": "4847660"
  },
  {
    "text": "So it's going to work on\npairs of inputs, x and z,",
    "start": "4847660",
    "end": "4853870"
  },
  {
    "text": "or sometimes the xs are real. Sometimes they are generated\nby the model and same thing. Sometimes, the z are real.",
    "start": "4853870",
    "end": "4860210"
  },
  {
    "text": "They are produced\nfrom the prior, and sometimes they are produced\nby the-- by fitting real data to the encoder.",
    "start": "4860210",
    "end": "4866920"
  },
  {
    "text": "And then, basically\neverything is the same. Then you train the\ngenerator, trying",
    "start": "4866920",
    "end": "4875770"
  },
  {
    "text": "to fool the discriminator. You train the encoder, and you\ntrain the discriminator trying to distinguish the samples.",
    "start": "4875770",
    "end": "4881679"
  },
  {
    "text": "And to the extent\nthat this works, so the discriminator\nobserves these pairs.",
    "start": "4881680",
    "end": "4888820"
  },
  {
    "text": "And the discriminator is trying\nto do as well as it can at distinguishing these two pairs.",
    "start": "4888820",
    "end": "4895000"
  },
  {
    "text": "And after training, basically\nyou can get the samples from g,",
    "start": "4895000",
    "end": "4901100"
  },
  {
    "text": "and you use the encoder to get\nthe latent representations. And yeah, that's sort\nof like the idea.",
    "start": "4901100",
    "end": "4908510"
  },
  {
    "text": "It's pretty simple. It's like an extension\nof GANs where you have another mapping,\nwhich is also deterministic,",
    "start": "4908510",
    "end": "4916070"
  },
  {
    "text": "going from data to\nlatent features. And then, you let\nthe discriminator operate not only on data\nbut on data, comma, latent.",
    "start": "4916070",
    "end": "4924020"
  },
  {
    "text": "And so to the extent that the\ndiscriminator cannot distinguish the zs that are produced by the\ngenerative procedure from zs",
    "start": "4924020",
    "end": "4930920"
  },
  {
    "text": "that are produced\nby the encoder, then you might expect that the\nencoder is producing latent representations that are similar\nto the one that GANs would have",
    "start": "4930920",
    "end": "4938420"
  },
  {
    "text": "used for generating\na data point. And so effectively, the\nencoder is inverting",
    "start": "4938420",
    "end": "4944600"
  },
  {
    "text": "the generative procedure. So it's very similar to a\nvariational autoencoder except",
    "start": "4944600",
    "end": "4950449"
  },
  {
    "text": "that E is a deterministic\nmapping and is not trained by minimizing KL-divergences\nlike in the ELBO,",
    "start": "4950450",
    "end": "4957200"
  },
  {
    "text": "but it's trained by minimizing\nsome kind of two sample test that is being optimized by a\ndiscriminator, but the same--",
    "start": "4957200",
    "end": "4967310"
  },
  {
    "text": "it's the same\nhigh-level intuition. Yeah.",
    "start": "4967310",
    "end": "4972890"
  },
  {
    "text": "Is that a concatenation\nof x and Ex that is we get in\nthe [INAUDIBLE]",
    "start": "4972890",
    "end": "4978710"
  },
  {
    "text": "Yes, it's the concatenation. So you need to be able to\ndistinguish pairs of real data",
    "start": "4978710",
    "end": "4986030"
  },
  {
    "text": "features produced by the encoder\nfrom fake data, real features produced from the prior.",
    "start": "4986030",
    "end": "4991520"
  },
  {
    "text": "So you cannot distinguish them,\nthen the features that you get from the encoder of x are\ngoing to be very similar",
    "start": "4991520",
    "end": "4996739"
  },
  {
    "text": "to the z's that were actually\nused for generating data points. And so that's how the\nencoder is trained.",
    "start": "4996740",
    "end": "5002660"
  },
  {
    "text": "Everything is trained\nor adversarial. So the discriminator will\nsee latents and images?",
    "start": "5002660",
    "end": "5010860"
  },
  {
    "text": "Yeah. Awesome. Sees pairs. And you mentioned the pair,\nthat they are basically",
    "start": "5010860",
    "end": "5018150"
  },
  {
    "text": "four different\ncombinations, the real image",
    "start": "5018150",
    "end": "5023250"
  },
  {
    "text": "and the deterministic\npicture, the encoded feature",
    "start": "5023250",
    "end": "5030870"
  },
  {
    "text": "was generated image, the encoded\nfeature was the original image? In this version, no,\nthere's only two options.",
    "start": "5030870",
    "end": "5038910"
  },
  {
    "text": "But you could imagine a\nversion where there is-- you're trying to enforce\nsomething stronger,",
    "start": "5038910",
    "end": "5044880"
  },
  {
    "text": "where maybe you want-- it's more like a\ncycle consistency that I guess we didn't have\ntime to talk about today.",
    "start": "5044880",
    "end": "5051060"
  },
  {
    "text": "Here there's only two there's\nbasically samples from the model and corresponding\nlatents versus real data",
    "start": "5051060",
    "end": "5059460"
  },
  {
    "text": "and corresponding latents. And it says after\ntraining is complete,",
    "start": "5059460",
    "end": "5065159"
  },
  {
    "text": "new samples are\ngenerated by a g, and they representations\ninferred via z--",
    "start": "5065160",
    "end": "5071619"
  },
  {
    "text": "via E. But when we generate\nthe new samples with g, didn't we first come up with\nthe latent representation?",
    "start": "5071620",
    "end": "5078790"
  },
  {
    "text": "Why do we still need to\ninfer it [INAUDIBLE]?? So yeah, that's meant\nto be on real data.",
    "start": "5078790",
    "end": "5084560"
  },
  {
    "text": "So let's say that then you\nwant to do transfer learning or you want to do\nsemi-supervised learning,",
    "start": "5084560",
    "end": "5090460"
  },
  {
    "text": "or you want to get-- you want\nto do clustering or something, how do you get the features\nfrom a data point x?",
    "start": "5090460",
    "end": "5095930"
  },
  {
    "text": "You don't use g because you\ndon't know how to invert it. But you've trained a separate\nmodel, this encoder model that",
    "start": "5095930",
    "end": "5101680"
  },
  {
    "text": "is basically\ntrained to invert G. And so on real\ndata at test time, you just use E to get\nthe corresponding latent.",
    "start": "5101680",
    "end": "5109450"
  },
  {
    "text": "So it is two different-- Two different-- like a VAE,\ntwo different pieces that",
    "start": "5109450",
    "end": "5114730"
  },
  {
    "text": "are trained together to fool\na discriminator, in this case,",
    "start": "5114730",
    "end": "5120080"
  },
  {
    "text": "instead of minimizing an ELBO. And right after [INAUDIBLE]\nthere's something [INAUDIBLE] in this graph, where do\nwe sample the z's from?",
    "start": "5120080",
    "end": "5128602"
  },
  {
    "text": "z's are all the same. They are sampled\nfrom a prior, so it's the same training as a GAN. So the z part doesn't change.",
    "start": "5128602",
    "end": "5135560"
  },
  {
    "text": "So the z's are\nfrom the top half. Those are-- the\nzs from the prior",
    "start": "5135560",
    "end": "5140829"
  },
  {
    "text": "and then you pass them through\nthe generator to produce data. OK, so we're just training\nE to make it map those to--",
    "start": "5140830",
    "end": "5150160"
  },
  {
    "text": "map the real images\nto the [INAUDIBLE]?? Essentially, yes,\nexcept that in a VAE",
    "start": "5150160",
    "end": "5155560"
  },
  {
    "text": "that matching is done\nvia KL-divergence. Here, that matching is done\nadversarially basically.",
    "start": "5155560",
    "end": "5162140"
  },
  {
    "text": "So the outputs of\nthe encoder should be indistinguishable\nfrom Zs that",
    "start": "5162140",
    "end": "5167620"
  },
  {
    "text": "are sampled from the prior,\nwhere indistinguishable is measured not\nwith respect to KL.",
    "start": "5167620",
    "end": "5174460"
  },
  {
    "text": "Now it's measured\nwith respect to-- a discriminator should\nnot be able to distinguish that the stuff that comes out\nfrom the encoder when it's",
    "start": "5174460",
    "end": "5182390"
  },
  {
    "text": "fed real data is different\nfrom the real latent variables",
    "start": "5182390",
    "end": "5187640"
  },
  {
    "text": "that you sampled\nyourself from the prior. So it has the same flavor, too. If you remember, at VAE, we had\na very similar kind of intuition",
    "start": "5187640",
    "end": "5195450"
  },
  {
    "text": "that what comes out\nfrom the encoder should be indistinguishable\nfrom what you from the latencies",
    "start": "5195450",
    "end": "5201300"
  },
  {
    "text": "that you generate yourself. In that case, we were enforcing\nthat indistinguishable using KL.",
    "start": "5201300",
    "end": "5206980"
  },
  {
    "text": "Here, we're using a two-sample\ntest, a discriminator. At inference time,\nthe latents are",
    "start": "5206980",
    "end": "5213250"
  },
  {
    "text": "sample from E based on\nthe last class selected? But E requires an\nx as the input.",
    "start": "5213250",
    "end": "5219730"
  },
  {
    "text": "What do we input to E? The image that you want\nto get representation for. So like in a VAE, you have a x,\nyou feed it through the encoder",
    "start": "5219730",
    "end": "5226937"
  },
  {
    "text": "and you get the\ncorresponding latents, and then you do whatever\nyou need to do, you do. Yeah, but in VAE, at training\ntime, at inference time,",
    "start": "5226937",
    "end": "5234165"
  },
  {
    "text": "we don't use the\nencoder at all, right? Yeah, at inference time, if\nyou want to just generate,",
    "start": "5234165",
    "end": "5239260"
  },
  {
    "text": "you don't use the encoder. But if you want to get features,\nthen you still use the encoder, just like here.",
    "start": "5239260",
    "end": "5245070"
  },
  {
    "start": "5245070",
    "end": "5250000"
  }
]
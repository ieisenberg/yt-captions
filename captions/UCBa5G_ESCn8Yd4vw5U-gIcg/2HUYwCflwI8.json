[
  {
    "start": "0",
    "end": "94000"
  },
  {
    "start": "0",
    "end": "5630"
  },
  {
    "text": "OK, so let's talk about open\nproblems, future, all of that,",
    "start": "5630",
    "end": "10370"
  },
  {
    "text": "right?",
    "start": "10370",
    "end": "11000"
  },
  {
    "text": "So I have a bunch\nof things here,",
    "start": "11000",
    "end": "13520"
  },
  {
    "text": "and I think we should\nbe able to hit all,",
    "start": "13520",
    "end": "15620"
  },
  {
    "text": "but let's start\nfrom the beginning.",
    "start": "15620",
    "end": "18800"
  },
  {
    "text": "So we are going to talk about\nseveral of these aspects here.",
    "start": "18800",
    "end": "22359"
  },
  {
    "text": "As you can see, a\nlot of these areas",
    "start": "22360",
    "end": "24940"
  },
  {
    "text": "are still active\nresearch directions,",
    "start": "24940",
    "end": "26780"
  },
  {
    "text": "including coming up with new\npost-hoc explanation methods,",
    "start": "26780",
    "end": "30610"
  },
  {
    "text": "which sort of alleviate or\naddress some of the limitations",
    "start": "30610",
    "end": "34810"
  },
  {
    "text": "that we have talked\nabout, right?",
    "start": "34810",
    "end": "37010"
  },
  {
    "text": "So we'll go in\nthis order and try",
    "start": "37010",
    "end": "38530"
  },
  {
    "text": "to cover each of these\npieces one by one.",
    "start": "38530",
    "end": "41149"
  },
  {
    "text": "So the first-- also this.",
    "start": "41150",
    "end": "44480"
  },
  {
    "text": "The first one is new methods\nfor more reliable post hoc",
    "start": "44480",
    "end": "48730"
  },
  {
    "text": "explanation, right?",
    "start": "48730",
    "end": "49899"
  },
  {
    "text": "Not surprising\nbecause we are seeing",
    "start": "49900",
    "end": "51760"
  },
  {
    "text": "there are all these problems\nwith existing methods.",
    "start": "51760",
    "end": "54309"
  },
  {
    "text": "What do we do?",
    "start": "54310",
    "end": "55120"
  },
  {
    "text": "OK> All right, so we have\nseen that there are several",
    "start": "55120",
    "end": "61870"
  },
  {
    "text": "limitations in the behavior\nof existing methods.",
    "start": "61870",
    "end": "64690"
  },
  {
    "text": "For example, they're unstable,\ninconsistent, fragile, not",
    "start": "64690",
    "end": "68860"
  },
  {
    "text": "faithful.",
    "start": "68860",
    "end": "69610"
  },
  {
    "text": "While there are already\ndifferent attempts",
    "start": "69610",
    "end": "71860"
  },
  {
    "text": "to address some of\nthese limitations,",
    "start": "71860",
    "end": "74210"
  },
  {
    "text": "there is definitely more\nwork that is needed, right?",
    "start": "74210",
    "end": "77560"
  },
  {
    "text": "So for example, I'm going to\ntouch upon one recent approach",
    "start": "77560",
    "end": "81549"
  },
  {
    "text": "that we had, which gained\na lot of traction, which",
    "start": "81550",
    "end": "84700"
  },
  {
    "text": "helps address some\nof the classic issues",
    "start": "84700",
    "end": "86770"
  },
  {
    "text": "with these post hoc\nexplanation methods-- not all",
    "start": "86770",
    "end": "88930"
  },
  {
    "text": "of them, some of them.",
    "start": "88930",
    "end": "90620"
  },
  {
    "text": "So we talked about methods,\nsuch as LIME being unstable,",
    "start": "90620",
    "end": "94580"
  },
  {
    "start": "94000",
    "end": "122000"
  },
  {
    "text": "and we also talked about this\nissue of consistency, which",
    "start": "94580",
    "end": "98080"
  },
  {
    "text": "is the same method\naround the same point",
    "start": "98080",
    "end": "101230"
  },
  {
    "text": "can generate drastically\ndifferent explanations.",
    "start": "101230",
    "end": "104050"
  },
  {
    "text": "And that is\nparticularly true when",
    "start": "104050",
    "end": "106420"
  },
  {
    "text": "the number of perturbations\nyou're using is small, right?",
    "start": "106420",
    "end": "110259"
  },
  {
    "text": "So we discussed\nthis a little bit,",
    "start": "110260",
    "end": "113020"
  },
  {
    "text": "that if it's the\nproblem with having",
    "start": "113020",
    "end": "114609"
  },
  {
    "text": "too few perturbations,\nwhat is the optimal number",
    "start": "114610",
    "end": "117610"
  },
  {
    "text": "of perturbations?",
    "start": "117610",
    "end": "118480"
  },
  {
    "text": "Can we just use a very large\nnumber of perturbations, right?",
    "start": "118480",
    "end": "122500"
  },
  {
    "start": "122000",
    "end": "170000"
  },
  {
    "text": "The issue with using very large\nnumber of perturbations is,",
    "start": "122500",
    "end": "126280"
  },
  {
    "text": "again, it's a computational\nchallenge in practice.",
    "start": "126280",
    "end": "128830"
  },
  {
    "text": "Because, especially if you are\nlooking at very complex models,",
    "start": "128830",
    "end": "132430"
  },
  {
    "text": "like Inception Net,\nor ResNet, and so on,",
    "start": "132430",
    "end": "134980"
  },
  {
    "text": "querying these models for labels\nrepeatedly for a lot of points,",
    "start": "134980",
    "end": "139810"
  },
  {
    "text": "because each time you generate\na perturbation you go and take",
    "start": "139810",
    "end": "142420"
  },
  {
    "text": "the label from the model.",
    "start": "142420",
    "end": "143830"
  },
  {
    "text": "And if you keep\ndoing this repeatedly",
    "start": "143830",
    "end": "146020"
  },
  {
    "text": "for a large number\nof perturbations",
    "start": "146020",
    "end": "147850"
  },
  {
    "text": "for each point in\nthe data set, this",
    "start": "147850",
    "end": "150250"
  },
  {
    "text": "becomes very computationally\nintensive very fast, right?",
    "start": "150250",
    "end": "154300"
  },
  {
    "text": "So because of that, you can't\njust apply the principle of,",
    "start": "154300",
    "end": "156970"
  },
  {
    "text": "just put a large number\nof perturbations there,",
    "start": "156970",
    "end": "159040"
  },
  {
    "text": "and you'll be done.",
    "start": "159040",
    "end": "160000"
  },
  {
    "text": "So a more saner approach\nwould be to actually determine",
    "start": "160000",
    "end": "163480"
  },
  {
    "text": "what is the minimum\nnumber of perturbations",
    "start": "163480",
    "end": "166000"
  },
  {
    "text": "required to get to that sort\nof converged explanation.",
    "start": "166000",
    "end": "169165"
  },
  {
    "text": "OK?",
    "start": "169165",
    "end": "171260"
  },
  {
    "start": "170000",
    "end": "468000"
  },
  {
    "text": "So what we do is this\nkind of idea or paper",
    "start": "171260",
    "end": "174819"
  },
  {
    "text": "on explanations with some\nuncertainty guarantees.",
    "start": "174820",
    "end": "177610"
  },
  {
    "text": "So we consider Bayesian\nversions of LIME and SHAP.",
    "start": "177610",
    "end": "181240"
  },
  {
    "text": "And the reason why\nthis is actually",
    "start": "181240",
    "end": "183940"
  },
  {
    "text": "better than just having\npoint estimates of feature",
    "start": "183940",
    "end": "187060"
  },
  {
    "text": "importances is it,\nat least, tells",
    "start": "187060",
    "end": "190180"
  },
  {
    "text": "you what is the confidence\ninterval or the uncertainty",
    "start": "190180",
    "end": "194019"
  },
  {
    "text": "interval associated\nwith your explanations.",
    "start": "194020",
    "end": "196630"
  },
  {
    "text": "This is particularly important.",
    "start": "196630",
    "end": "198550"
  },
  {
    "text": "Because as we have\nseen, there are not",
    "start": "198550",
    "end": "201040"
  },
  {
    "text": "exactly very\nauthoritative metrics",
    "start": "201040",
    "end": "203439"
  },
  {
    "text": "for things like faithfulness.",
    "start": "203440",
    "end": "204940"
  },
  {
    "text": "I mean, there are ways\nin which we discussed",
    "start": "204940",
    "end": "207340"
  },
  {
    "text": "how they can be approached,\nand you can compare",
    "start": "207340",
    "end": "210040"
  },
  {
    "text": "two explanations and so on.",
    "start": "210040",
    "end": "212049"
  },
  {
    "text": "Given that that piece\nis not completely",
    "start": "212050",
    "end": "215350"
  },
  {
    "text": "set in the literature\nyet, this kind",
    "start": "215350",
    "end": "217380"
  },
  {
    "text": "of having some\nestimates of uncertainty",
    "start": "217380",
    "end": "220840"
  },
  {
    "text": "instead of giving one point\nestimate, one point value",
    "start": "220840",
    "end": "224260"
  },
  {
    "text": "for each feature, and say,\nthis is the importance,",
    "start": "224260",
    "end": "226659"
  },
  {
    "text": "if we can say how\nuncertain the algorithm is",
    "start": "226660",
    "end": "230470"
  },
  {
    "text": "about this feature\nimportance, that",
    "start": "230470",
    "end": "232600"
  },
  {
    "text": "can be very valuable, right?",
    "start": "232600",
    "end": "234580"
  },
  {
    "text": "And this also kind of\nhelps us consolidate.",
    "start": "234580",
    "end": "237370"
  },
  {
    "text": "Like, for example,\nthere was a nice point",
    "start": "237370",
    "end": "239470"
  },
  {
    "text": "about, if you change the\nnumber of perturbations,",
    "start": "239470",
    "end": "242050"
  },
  {
    "text": "your explanation changes, right?",
    "start": "242050",
    "end": "243790"
  },
  {
    "text": "And as an end user or\neven as a designer,",
    "start": "243790",
    "end": "247239"
  },
  {
    "text": "it makes no sense to me if I\nsee two different explanations,",
    "start": "247240",
    "end": "250780"
  },
  {
    "text": "and I don't know how to\nconsolidate which one is right,",
    "start": "250780",
    "end": "253120"
  },
  {
    "text": "all of that.",
    "start": "253120",
    "end": "254030"
  },
  {
    "text": "But once you put uncertainty\ninto the picture,",
    "start": "254030",
    "end": "257019"
  },
  {
    "text": "if I run LIME with, say, 100\nperturbations versus running",
    "start": "257019",
    "end": "261130"
  },
  {
    "text": "LIME with 2,000 perturbations,\nso clearly, the mean",
    "start": "261130",
    "end": "264040"
  },
  {
    "text": "has changed, but the\nuncertainty interval",
    "start": "264040",
    "end": "267850"
  },
  {
    "text": "is still being captured, right?",
    "start": "267850",
    "end": "269620"
  },
  {
    "text": "So with lesser number\nof perturbations,",
    "start": "269620",
    "end": "272050"
  },
  {
    "text": "I'm seeing that there\nis more uncertainty.",
    "start": "272050",
    "end": "274270"
  },
  {
    "text": "With larger number\nof perturbations,",
    "start": "274270",
    "end": "276280"
  },
  {
    "text": "I'm seeing that there\nis less uncertainty.",
    "start": "276280",
    "end": "278500"
  },
  {
    "text": "But at least, it's\ncaptured by this window.",
    "start": "278500",
    "end": "280820"
  },
  {
    "text": "These are not conflicting\nthings, right?",
    "start": "280820",
    "end": "283390"
  },
  {
    "text": "So that is helpful for\nme to sort of consolidate",
    "start": "283390",
    "end": "286420"
  },
  {
    "text": "what is happening here, OK?",
    "start": "286420",
    "end": "288160"
  },
  {
    "text": "What we do here is essentially\nthis kind of a Bayesian locally",
    "start": "288160",
    "end": "291550"
  },
  {
    "text": "weighted regression.",
    "start": "291550",
    "end": "292879"
  },
  {
    "text": "So we make the entire setup\nof LIME Bayesian, pretty much,",
    "start": "292880",
    "end": "296680"
  },
  {
    "text": "and we make it in\nsuch a way that you",
    "start": "296680",
    "end": "298810"
  },
  {
    "text": "don't have to use\nmethods, like sampling,",
    "start": "298810",
    "end": "301330"
  },
  {
    "text": "or variational inference,\nor anything, which",
    "start": "301330",
    "end": "303340"
  },
  {
    "text": "is computationally intensive.",
    "start": "303340",
    "end": "305110"
  },
  {
    "text": "We can compute all the\nparameters in closed form.",
    "start": "305110",
    "end": "308199"
  },
  {
    "text": "And the means of\nthese approaches",
    "start": "308200",
    "end": "310330"
  },
  {
    "text": "also turn out to be the\nestimates that LIME or SHAP",
    "start": "310330",
    "end": "313569"
  },
  {
    "text": "will output in expectation.",
    "start": "313570",
    "end": "314920"
  },
  {
    "text": "OK?",
    "start": "314920",
    "end": "316000"
  },
  {
    "text": "So there is a clear\nparallel, and we",
    "start": "316000",
    "end": "318070"
  },
  {
    "text": "are able to add an uncertainty\ninterval on top of it.",
    "start": "318070",
    "end": "320800"
  },
  {
    "text": "And using some of these\nBayesian frameworks that we have",
    "start": "320800",
    "end": "324699"
  },
  {
    "text": "or the details of\nthis framework,",
    "start": "324700",
    "end": "327430"
  },
  {
    "text": "we also develop like some theory\nfor estimating the required",
    "start": "327430",
    "end": "331960"
  },
  {
    "text": "number of\nperturbations that will",
    "start": "331960",
    "end": "334630"
  },
  {
    "text": "help us achieve user-defined\nlevels of confidence.",
    "start": "334630",
    "end": "339770"
  },
  {
    "text": "So for example,\nif a user says, I",
    "start": "339770",
    "end": "342099"
  },
  {
    "text": "need an explanation where the\ntrue feature importance lies",
    "start": "342100",
    "end": "345520"
  },
  {
    "text": "within plus or minus 0.5 of your\nestimated feature importance",
    "start": "345520",
    "end": "349629"
  },
  {
    "text": "with 95% confidence interval.",
    "start": "349630",
    "end": "351730"
  },
  {
    "text": "If that's the\nrequirement of a user,",
    "start": "351730",
    "end": "353860"
  },
  {
    "text": "we can take those\nand then give you",
    "start": "353860",
    "end": "356050"
  },
  {
    "text": "a number in which is the\nnumber of perturbations",
    "start": "356050",
    "end": "358770"
  },
  {
    "text": "that you need to use with\nBayesLIME or BayesSHAP",
    "start": "358770",
    "end": "362039"
  },
  {
    "text": "in order to give this\nguarantee on the uncertainty",
    "start": "362040",
    "end": "364710"
  },
  {
    "text": "of the feature\nimportance values.",
    "start": "364710",
    "end": "366172"
  },
  {
    "text": "OK?",
    "start": "366172",
    "end": "367830"
  },
  {
    "text": "And we can also do more tweaks\nin this kind of a setting",
    "start": "367830",
    "end": "371400"
  },
  {
    "text": "because we are\ncapturing uncertainty.",
    "start": "371400",
    "end": "373440"
  },
  {
    "text": "For example,\ninstead of just sort",
    "start": "373440",
    "end": "376580"
  },
  {
    "text": "of taking random\nperturbations, which",
    "start": "376580",
    "end": "378569"
  },
  {
    "text": "is what these approaches\ndo, typically, we",
    "start": "378570",
    "end": "381210"
  },
  {
    "text": "can be more sort of\nintelligent about it and say,",
    "start": "381210",
    "end": "384210"
  },
  {
    "text": "we'll only choose those points\nthat the learning algorithm",
    "start": "384210",
    "end": "387810"
  },
  {
    "text": "is most uncertain about.",
    "start": "387810",
    "end": "389460"
  },
  {
    "text": "Because we are capturing\nthe uncertainty, right?",
    "start": "389460",
    "end": "392250"
  },
  {
    "text": "And only on those points we last\nlearned the underlying models",
    "start": "392250",
    "end": "395220"
  },
  {
    "text": "for labels.",
    "start": "395220",
    "end": "396180"
  },
  {
    "text": "For other points, which our\nlearning algorithm is already",
    "start": "396180",
    "end": "399270"
  },
  {
    "text": "certain about, we don't need\nto query this complex model",
    "start": "399270",
    "end": "402599"
  },
  {
    "text": "and waste compute in that.",
    "start": "402600",
    "end": "403980"
  },
  {
    "text": "OK?",
    "start": "403980",
    "end": "405420"
  },
  {
    "text": "So that adds to the efficiency.",
    "start": "405420",
    "end": "408160"
  },
  {
    "text": "So in some sense,\nthis whole approach",
    "start": "408160",
    "end": "410040"
  },
  {
    "text": "allows us to\nconstruct explanations",
    "start": "410040",
    "end": "412140"
  },
  {
    "text": "with user defined\nlevels of confidence",
    "start": "412140",
    "end": "415110"
  },
  {
    "text": "in an efficient manner.",
    "start": "415110",
    "end": "417060"
  },
  {
    "text": "OK, so other\nquestions that would",
    "start": "417060",
    "end": "418889"
  },
  {
    "text": "be interesting to explore\nin this kind of a context",
    "start": "418890",
    "end": "422070"
  },
  {
    "text": "is, can we construct post\nhoc explanations that",
    "start": "422070",
    "end": "425580"
  },
  {
    "text": "are provably robust to various\nadversarial attacks discussed",
    "start": "425580",
    "end": "429330"
  },
  {
    "text": "earlier, right?",
    "start": "429330",
    "end": "430229"
  },
  {
    "text": "So what the previous approach\nhad talked about is fixing",
    "start": "430230",
    "end": "433050"
  },
  {
    "text": "is some pieces, some of the\nconsistency issues, and so on.",
    "start": "433050",
    "end": "437729"
  },
  {
    "text": "But, again, we now develop new\nmethods or new explanations",
    "start": "437730",
    "end": "441420"
  },
  {
    "text": "that are provably robust to some\nof the adversarial attacks we",
    "start": "441420",
    "end": "444570"
  },
  {
    "text": "discussed.",
    "start": "444570",
    "end": "445620"
  },
  {
    "text": "Or can we construct\npost hoc explanations",
    "start": "445620",
    "end": "448260"
  },
  {
    "text": "that can simultaneously\nguarantee several",
    "start": "448260",
    "end": "451170"
  },
  {
    "text": "of the properties\nthat we discussed,",
    "start": "451170",
    "end": "453190"
  },
  {
    "text": "which is whether it's fairness,\nor faithfulness, or stability,",
    "start": "453190",
    "end": "456150"
  },
  {
    "text": "and so on, there are no\nanswers for these questions",
    "start": "456150",
    "end": "458803"
  },
  {
    "text": "at this time.",
    "start": "458803",
    "end": "459345"
  },
  {
    "text": "OK?",
    "start": "459345",
    "end": "461630"
  },
  {
    "text": "All right, let's\ntalk about what are",
    "start": "461630",
    "end": "464840"
  },
  {
    "text": "some problems that are open in\nterms of theoretical analysis.",
    "start": "464840",
    "end": "469949"
  },
  {
    "start": "468000",
    "end": "669000"
  },
  {
    "text": "So we actually discussed some of\nthe recent theoretical results,",
    "start": "469950",
    "end": "472730"
  },
  {
    "text": "just like a few minutes back.",
    "start": "472730",
    "end": "474890"
  },
  {
    "text": "Despite some of those\npreliminary attempts,",
    "start": "474890",
    "end": "476838"
  },
  {
    "text": "of course, there are huge gaps.",
    "start": "476838",
    "end": "478130"
  },
  {
    "text": "There is a lot more to do.",
    "start": "478130",
    "end": "479990"
  },
  {
    "text": "For example, can we\ncharacterize the conditions",
    "start": "479990",
    "end": "482690"
  },
  {
    "text": "under which post hoc explanation\nmethod unsuccessfully",
    "start": "482690",
    "end": "487040"
  },
  {
    "text": "or successfully\ncaptures the behavior",
    "start": "487040",
    "end": "489110"
  },
  {
    "text": "of the underlying model, right?",
    "start": "489110",
    "end": "491389"
  },
  {
    "text": "Currently, there are not\nvery good answers for this.",
    "start": "491390",
    "end": "494060"
  },
  {
    "text": "But can we put a\nprecise characterization",
    "start": "494060",
    "end": "496790"
  },
  {
    "text": "on when they can\nactually capture",
    "start": "496790",
    "end": "498950"
  },
  {
    "text": "the underlying model\nor not, with respect",
    "start": "498950",
    "end": "501500"
  },
  {
    "text": "to different notions\nof what exactly",
    "start": "501500",
    "end": "503240"
  },
  {
    "text": "it means to capture the behavior\nof an underlying model, right?",
    "start": "503240",
    "end": "506720"
  },
  {
    "text": "And given the properties of\nthe underlying model data",
    "start": "506720",
    "end": "510170"
  },
  {
    "text": "distribution, can we\ntheoretically determine",
    "start": "510170",
    "end": "512780"
  },
  {
    "text": "which explanation method\nshould be employed, right?",
    "start": "512780",
    "end": "515990"
  },
  {
    "text": "So some of our recent work is\ngoing along these directions,",
    "start": "515990",
    "end": "520169"
  },
  {
    "text": "but there is no way,\nsort of, a solution",
    "start": "520169",
    "end": "523400"
  },
  {
    "text": "to these big questions.",
    "start": "523400",
    "end": "525590"
  },
  {
    "text": "But it's interesting\nto sort of think",
    "start": "525590",
    "end": "527480"
  },
  {
    "text": "about these kinds\nof questions, right?",
    "start": "527480",
    "end": "529760"
  },
  {
    "text": "And can we theoretically analyze\nthe nature of the prototypes",
    "start": "529760",
    "end": "533780"
  },
  {
    "text": "and attention weights, learn\nby deep nets with added layers?",
    "start": "533780",
    "end": "537650"
  },
  {
    "text": "When are these meaningful?",
    "start": "537650",
    "end": "539270"
  },
  {
    "text": "When are they spurious?",
    "start": "539270",
    "end": "541010"
  },
  {
    "text": "Again, there are no answers.",
    "start": "541010",
    "end": "542870"
  },
  {
    "text": "These are all big open\nproblems, and they're also not",
    "start": "542870",
    "end": "546800"
  },
  {
    "text": "easy problems in some sense,\nbut definitely worth exploring.",
    "start": "546800",
    "end": "552140"
  },
  {
    "text": "OK, so let's talk a\nlittle bit about what",
    "start": "552140",
    "end": "554900"
  },
  {
    "text": "are some other open questions\nin empirical evaluation",
    "start": "554900",
    "end": "558080"
  },
  {
    "text": "of the correctness and utility\nof model interpretations,",
    "start": "558080",
    "end": "561075"
  },
  {
    "text": "right?",
    "start": "561075",
    "end": "562250"
  },
  {
    "text": "So we actually spent\nquite a bit of time",
    "start": "562250",
    "end": "564350"
  },
  {
    "text": "discussing some of the\nempirical results and analysis",
    "start": "564350",
    "end": "567740"
  },
  {
    "text": "of correctness and utility.",
    "start": "567740",
    "end": "569540"
  },
  {
    "text": "In spite of all that, as we\nbriefly talked about earlier,",
    "start": "569540",
    "end": "573990"
  },
  {
    "text": "there is no clear\ncharacterization",
    "start": "573990",
    "end": "576230"
  },
  {
    "text": "of which methods, if any,\nare correct or useful",
    "start": "576230",
    "end": "579800"
  },
  {
    "text": "under what conditions, right?",
    "start": "579800",
    "end": "582950"
  },
  {
    "text": "Again, this is something\nthat, I think, hopefully,",
    "start": "582950",
    "end": "585320"
  },
  {
    "text": "as the field also\nevolves, we come up",
    "start": "585320",
    "end": "588170"
  },
  {
    "text": "with a certain systematic set\nof evaluations, benchmarks,",
    "start": "588170",
    "end": "593180"
  },
  {
    "text": "standard practices for\ndoing user studies.",
    "start": "593180",
    "end": "596029"
  },
  {
    "text": "And then, we'll be able to come\nup with more clearer answers.",
    "start": "596030",
    "end": "599030"
  },
  {
    "text": "But currently, if you\nsay, oh, when does-- or is",
    "start": "599030",
    "end": "602700"
  },
  {
    "text": "LIME explanation or\nare LIME explanations",
    "start": "602700",
    "end": "605840"
  },
  {
    "text": "helpful to doctors in this?",
    "start": "605840",
    "end": "608150"
  },
  {
    "text": "The answer is, we really\ndon't know, right?",
    "start": "608150",
    "end": "612230"
  },
  {
    "text": "And there is actually\neven lesser work.",
    "start": "612230",
    "end": "615260"
  },
  {
    "text": "I'm sure some of you\nhave noticed this,",
    "start": "615260",
    "end": "617190"
  },
  {
    "text": "but there is even lesser work\non the empirical analysis",
    "start": "617190",
    "end": "620360"
  },
  {
    "text": "of the correctness or\nutility of interpretations",
    "start": "620360",
    "end": "623450"
  },
  {
    "text": "generated by inherently\ninterpretable models, right?",
    "start": "623450",
    "end": "627200"
  },
  {
    "text": "Post hoc explanations, there\nhas been a huge sort of area",
    "start": "627200",
    "end": "632570"
  },
  {
    "text": "that has formed around it.",
    "start": "632570",
    "end": "633770"
  },
  {
    "text": "But inherently,\ninterpretable models,",
    "start": "633770",
    "end": "635570"
  },
  {
    "text": "there is even less work.",
    "start": "635570",
    "end": "637490"
  },
  {
    "text": "For example, are\nprototypes generated",
    "start": "637490",
    "end": "639740"
  },
  {
    "text": "by adding these layers\neven meaningful?",
    "start": "639740",
    "end": "641990"
  },
  {
    "text": "We don't know, right?",
    "start": "641990",
    "end": "643730"
  },
  {
    "text": "Can they be leveraged in\nany real world applications?",
    "start": "643730",
    "end": "646910"
  },
  {
    "text": "What about attention weights?",
    "start": "646910",
    "end": "648420"
  },
  {
    "text": "There are absolutely\nno studies to answer",
    "start": "648420",
    "end": "650272"
  },
  {
    "text": "any of these questions.",
    "start": "650272",
    "end": "651230"
  },
  {
    "text": "OK?",
    "start": "651230",
    "end": "653220"
  },
  {
    "text": "All right, so the next piece is\ncharacterizing the similarities",
    "start": "653220",
    "end": "657290"
  },
  {
    "text": "and differences.",
    "start": "657290",
    "end": "658250"
  },
  {
    "text": "We talked about how a\nlot of these methods",
    "start": "658250",
    "end": "660410"
  },
  {
    "text": "actually disagree with each\nother in terms of the outputs",
    "start": "660410",
    "end": "663050"
  },
  {
    "text": "they produce, right?",
    "start": "663050",
    "end": "665000"
  },
  {
    "text": "But let's see what are some\nopen problems to look at there.",
    "start": "665000",
    "end": "668000"
  },
  {
    "text": "OK?",
    "start": "668000",
    "end": "669320"
  },
  {
    "start": "669000",
    "end": "762000"
  },
  {
    "text": "So several post hoc\nexplanation methods",
    "start": "669320",
    "end": "672800"
  },
  {
    "text": "exist which are employing\ndiverse algorithms,",
    "start": "672800",
    "end": "676279"
  },
  {
    "text": "diverse definitions of what\neven is an explanation.",
    "start": "676280",
    "end": "679610"
  },
  {
    "text": "And some are saying,\nrules is an explanation.",
    "start": "679610",
    "end": "681980"
  },
  {
    "text": "Others are saying importances\nare explanations, and so on.",
    "start": "681980",
    "end": "684990"
  },
  {
    "text": "So under what conditions do\nthese methods or a subset",
    "start": "684990",
    "end": "689480"
  },
  {
    "text": "of these methods, at least,\ngenerate similar outputs?",
    "start": "689480",
    "end": "693649"
  },
  {
    "text": "So we want to try\nand quantify that,",
    "start": "693650",
    "end": "696920"
  },
  {
    "text": "and that will also help us\nunderstand when will they",
    "start": "696920",
    "end": "699649"
  },
  {
    "text": "give you similar\noutputs, when will they",
    "start": "699650",
    "end": "701330"
  },
  {
    "text": "give you different outputs.",
    "start": "701330",
    "end": "702770"
  },
  {
    "text": "That understanding is\nalso important for us",
    "start": "702770",
    "end": "705800"
  },
  {
    "text": "to both sort of\nbuild better methods",
    "start": "705800",
    "end": "707959"
  },
  {
    "text": "and basically get\nto a point of where",
    "start": "707960",
    "end": "710120"
  },
  {
    "text": "we know a bit more than what we\nknow about explanation methods",
    "start": "710120",
    "end": "714110"
  },
  {
    "text": "currently, right?",
    "start": "714110",
    "end": "715370"
  },
  {
    "text": "And there are multiple\ninterpretable models",
    "start": "715370",
    "end": "718070"
  },
  {
    "text": "which output\nnatural/synthetic prototypes.",
    "start": "718070",
    "end": "720980"
  },
  {
    "text": "When are these actually\ngenerating similar prototypes?",
    "start": "720980",
    "end": "724519"
  },
  {
    "text": "And why, under what\nconditions, are they",
    "start": "724520",
    "end": "727190"
  },
  {
    "text": "generating similar prototypes?",
    "start": "727190",
    "end": "728990"
  },
  {
    "text": "When are they going to\ngenerate different prototypes?",
    "start": "728990",
    "end": "731930"
  },
  {
    "text": "Again, we don't know, right?",
    "start": "731930",
    "end": "733700"
  },
  {
    "text": "So clearly, I think,\nthat whole space",
    "start": "733700",
    "end": "736370"
  },
  {
    "text": "of making models interpretable\nby adding layers of prototypes",
    "start": "736370",
    "end": "741290"
  },
  {
    "text": "or intentions is there's a huge\nvoid in terms of what can we",
    "start": "741290",
    "end": "744920"
  },
  {
    "text": "say theoretically at all\nor even empirical analysis,",
    "start": "744920",
    "end": "749000"
  },
  {
    "text": "to be honest.",
    "start": "749000",
    "end": "750780"
  },
  {
    "text": "OK, and then the\nnext piece, today,",
    "start": "750780",
    "end": "753690"
  },
  {
    "text": "I think, in this discussion,\nwe have extensively",
    "start": "753690",
    "end": "755850"
  },
  {
    "text": "covered predictive\nmodels, specifically",
    "start": "755850",
    "end": "758339"
  },
  {
    "text": "focusing on classification.",
    "start": "758340",
    "end": "760290"
  },
  {
    "text": "Now, what do we do about going\nbeyond classification, right?",
    "start": "760290",
    "end": "765149"
  },
  {
    "start": "762000",
    "end": "887000"
  },
  {
    "text": "I think our immediate reaction\nis, well, classification",
    "start": "765150",
    "end": "767550"
  },
  {
    "text": "is already messy enough, so\nwhat can we do beyond it?",
    "start": "767550",
    "end": "770980"
  },
  {
    "text": "But I think there is no harm\nin hoping and dreaming anytime.",
    "start": "770980",
    "end": "774959"
  },
  {
    "text": "So yeah, now, with\nsort of this craziness",
    "start": "774960",
    "end": "779220"
  },
  {
    "text": "of more and more complex\nmodels kicking in",
    "start": "779220",
    "end": "782430"
  },
  {
    "text": "into full force and\nhigh gear, so now,",
    "start": "782430",
    "end": "786210"
  },
  {
    "text": "we have all these large language\nmodels, foundation models.",
    "start": "786210",
    "end": "790020"
  },
  {
    "text": "Like, what does it even mean\nto think of interpretability",
    "start": "790020",
    "end": "793530"
  },
  {
    "text": "there, right?",
    "start": "793530",
    "end": "794160"
  },
  {
    "text": "So what's even feasible there?",
    "start": "794160",
    "end": "796680"
  },
  {
    "text": "Those are also\njust open questions",
    "start": "796680",
    "end": "798870"
  },
  {
    "text": "that nobody has good\nanswers for, right?",
    "start": "798870",
    "end": "801690"
  },
  {
    "text": "And there is also\nalready active work",
    "start": "801690",
    "end": "804510"
  },
  {
    "text": "on interpretability in\nreinforcement learning",
    "start": "804510",
    "end": "806820"
  },
  {
    "text": "and graph neural networks.",
    "start": "806820",
    "end": "809170"
  },
  {
    "text": "So however, there is\nvery little research",
    "start": "809170",
    "end": "811500"
  },
  {
    "text": "on analyzing the correctness\nor utility of explanations",
    "start": "811500",
    "end": "814770"
  },
  {
    "text": "in these contexts.",
    "start": "814770",
    "end": "815950"
  },
  {
    "text": "So currently, there are some\napproaches laid out there.",
    "start": "815950",
    "end": "818940"
  },
  {
    "text": "But nobody really\nknows if they're",
    "start": "818940",
    "end": "821100"
  },
  {
    "text": "doing the right thing, If\nthey're right, when are they",
    "start": "821100",
    "end": "823560"
  },
  {
    "text": "right, all of that, OK?",
    "start": "823560",
    "end": "826330"
  },
  {
    "text": "So given that these primitive\ninterpretable models",
    "start": "826330",
    "end": "829110"
  },
  {
    "text": "or post hoc\nexplanations themselves",
    "start": "829110",
    "end": "831480"
  },
  {
    "text": "suffer from so many limitations.",
    "start": "831480",
    "end": "834160"
  },
  {
    "text": "How do we ensure that when we\ntry and construct explanations",
    "start": "834160",
    "end": "838050"
  },
  {
    "text": "for more complex models,\nthose are probably",
    "start": "838050",
    "end": "841860"
  },
  {
    "text": "going to be more\nreliable, and they're not",
    "start": "841860",
    "end": "844470"
  },
  {
    "text": "suffering from all\nthese limitations",
    "start": "844470",
    "end": "846329"
  },
  {
    "text": "that we have just spend the last\ncouple of hours talking, right?",
    "start": "846330",
    "end": "850560"
  },
  {
    "text": "OK, so these three\nare kind of related,",
    "start": "850560",
    "end": "855390"
  },
  {
    "text": "but essentially\nexploring intersections",
    "start": "855390",
    "end": "859170"
  },
  {
    "text": "between interpretability\nand other key pillars",
    "start": "859170",
    "end": "862740"
  },
  {
    "text": "of this broader area of\ntrustworthy machine learning.",
    "start": "862740",
    "end": "865350"
  },
  {
    "text": "Like, robustness, or\nfairness, or privacy",
    "start": "865350",
    "end": "868529"
  },
  {
    "text": "is also very important\nbecause there are implications",
    "start": "868530",
    "end": "872040"
  },
  {
    "text": "of interpretability\non these properties,",
    "start": "872040",
    "end": "874620"
  },
  {
    "text": "and there are also implications\nof these properties",
    "start": "874620",
    "end": "877290"
  },
  {
    "text": "on interpretability.",
    "start": "877290",
    "end": "878579"
  },
  {
    "text": "So how to sort of\nthink about that?",
    "start": "878580",
    "end": "880890"
  },
  {
    "text": "That's also a space\nwhere there are",
    "start": "880890",
    "end": "882810"
  },
  {
    "text": "lots of interesting\nopen problems, OK?",
    "start": "882810",
    "end": "885840"
  },
  {
    "text": "So for example, if we think\nabout robustness, we can say,",
    "start": "885840",
    "end": "891240"
  },
  {
    "start": "887000",
    "end": "994000"
  },
  {
    "text": "are inherently interpretable\nmodels with these prototype",
    "start": "891240",
    "end": "894570"
  },
  {
    "text": "or attention layers\nmore robust than those",
    "start": "894570",
    "end": "897120"
  },
  {
    "text": "without these layers, right?",
    "start": "897120",
    "end": "898350"
  },
  {
    "text": "If so, why?",
    "start": "898350",
    "end": "899910"
  },
  {
    "text": "Are they giving, I think--",
    "start": "899910",
    "end": "901303"
  },
  {
    "text": "earlier, we were\ndiscussing with Anthony",
    "start": "901303",
    "end": "902970"
  },
  {
    "text": "that are these layers\nactually adding",
    "start": "902970",
    "end": "905250"
  },
  {
    "text": "some kind of regularization.",
    "start": "905250",
    "end": "906930"
  },
  {
    "text": "If so, can they improve\nrobustness almost",
    "start": "906930",
    "end": "909444"
  },
  {
    "text": "as a side effect?",
    "start": "909444",
    "end": "910152"
  },
  {
    "text": "OK?",
    "start": "910152",
    "end": "911339"
  },
  {
    "text": "Again, we don't know.",
    "start": "911340",
    "end": "912520"
  },
  {
    "text": "So that's a problem\nup for exploration.",
    "start": "912520",
    "end": "914790"
  },
  {
    "text": "And are there any\ninherent trade offs",
    "start": "914790",
    "end": "917130"
  },
  {
    "text": "between certain kinds of model\ninterpretability and model",
    "start": "917130",
    "end": "920370"
  },
  {
    "text": "robustness?",
    "start": "920370",
    "end": "921390"
  },
  {
    "text": "Or do these aspects always\ntry and reinforce each other?",
    "start": "921390",
    "end": "925620"
  },
  {
    "text": "Again, an open question.",
    "start": "925620",
    "end": "928000"
  },
  {
    "text": "So some of our\nrecent work actually",
    "start": "928000",
    "end": "930000"
  },
  {
    "text": "shows, theoretically\nand empirically,",
    "start": "930000",
    "end": "932220"
  },
  {
    "text": "that counterfactual explanation\ngeneration algorithms actually",
    "start": "932220",
    "end": "936540"
  },
  {
    "text": "output adversarial examples.",
    "start": "936540",
    "end": "938589"
  },
  {
    "text": "So this is pretty interesting\nbecause, essentially,",
    "start": "938590",
    "end": "940890"
  },
  {
    "text": "as we talked about earlier,\na lot of these algorithms",
    "start": "940890",
    "end": "944280"
  },
  {
    "text": "are basically\nsaying, take a point,",
    "start": "944280",
    "end": "946340"
  },
  {
    "text": "perturb it slightly, get\nit across the boundary,",
    "start": "946340",
    "end": "948660"
  },
  {
    "text": "and that is your\ncounterfactual, right?",
    "start": "948660",
    "end": "950490"
  },
  {
    "text": "But that's also what a lot of\nadversarial example approaches",
    "start": "950490",
    "end": "954209"
  },
  {
    "text": "do, OK?",
    "start": "954210",
    "end": "955710"
  },
  {
    "text": "That's one part of it.",
    "start": "955710",
    "end": "957070"
  },
  {
    "text": "But there is the other part of\nit, which is, a lot of machine",
    "start": "957070",
    "end": "960390"
  },
  {
    "text": "learning communities trying\nto build adversarially",
    "start": "960390",
    "end": "962880"
  },
  {
    "text": "robust models, which is\nthey're trying to eliminate",
    "start": "962880",
    "end": "966930"
  },
  {
    "text": "adversarial examples.",
    "start": "966930",
    "end": "969399"
  },
  {
    "text": "So now, what does this mean\nfor counterfactual explanations",
    "start": "969400",
    "end": "973170"
  },
  {
    "text": "or recourses?",
    "start": "973170",
    "end": "974279"
  },
  {
    "text": "So where does the\nboundary of-- or where",
    "start": "974280",
    "end": "977070"
  },
  {
    "text": "does the end of counterfactual\nexplanations happen?",
    "start": "977070",
    "end": "980640"
  },
  {
    "text": "And where does the beginning\nof adversarial examples",
    "start": "980640",
    "end": "983177"
  },
  {
    "text": "happen, right?",
    "start": "983177",
    "end": "983760"
  },
  {
    "text": "So what is the boundary\nbetween those two?",
    "start": "983760",
    "end": "986010"
  },
  {
    "text": "That's also quite blurry.",
    "start": "986010",
    "end": "988210"
  },
  {
    "text": "So I think there is a huge set\nof research problems there.",
    "start": "988210",
    "end": "991470"
  },
  {
    "text": "OK?",
    "start": "991470",
    "end": "993410"
  },
  {
    "text": "So with respect\nto model fairness,",
    "start": "993410",
    "end": "996610"
  },
  {
    "start": "994000",
    "end": "1127000"
  },
  {
    "text": "in fact, there's yet\nanother interesting piece.",
    "start": "996610",
    "end": "999220"
  },
  {
    "text": "Oftentimes, when people\nmotivate model interpretations",
    "start": "999220",
    "end": "1002670"
  },
  {
    "text": "or explanations,\nthey think of it",
    "start": "1002670",
    "end": "1004769"
  },
  {
    "text": "as, oh, explanations can help\nunearth all these unfairness",
    "start": "1004770",
    "end": "1008640"
  },
  {
    "text": "or biases in models, right?",
    "start": "1008640",
    "end": "1010860"
  },
  {
    "text": "So that's like a\nmotivation that's",
    "start": "1010860",
    "end": "1012690"
  },
  {
    "text": "often used in the introductions\nof a lot of papers.",
    "start": "1012690",
    "end": "1015580"
  },
  {
    "text": "However, there is\nnot a whole lot",
    "start": "1015580",
    "end": "1017580"
  },
  {
    "text": "of empirical or\ntheoretical research",
    "start": "1017580",
    "end": "1019680"
  },
  {
    "text": "which actually kind of\ntouches upon this topic.",
    "start": "1019680",
    "end": "1022950"
  },
  {
    "text": "Forget demonstrating\nit, like we don't even",
    "start": "1022950",
    "end": "1025530"
  },
  {
    "text": "have studies that\nsort of try to see",
    "start": "1025530",
    "end": "1028079"
  },
  {
    "text": "if this is happening, right?",
    "start": "1028079",
    "end": "1030449"
  },
  {
    "text": "So definitely conducting\nmore empirical evaluations",
    "start": "1030450",
    "end": "1033659"
  },
  {
    "text": "and user studies\nalong these lines",
    "start": "1033660",
    "end": "1035699"
  },
  {
    "text": "to determine how interpretations\nand explanations can complement",
    "start": "1035700",
    "end": "1039899"
  },
  {
    "text": "statistical notions of\nfairness and identifying biases",
    "start": "1039900",
    "end": "1043319"
  },
  {
    "text": "is important.",
    "start": "1043319",
    "end": "1044220"
  },
  {
    "text": "Because there is already a\nbunch of literature on fairness,",
    "start": "1044220",
    "end": "1048179"
  },
  {
    "text": "but that literature\nfocuses on how",
    "start": "1048180",
    "end": "1050460"
  },
  {
    "text": "to sort of quantify\nstatistically what unfairness",
    "start": "1050460",
    "end": "1053490"
  },
  {
    "text": "looks like.",
    "start": "1053490",
    "end": "1054390"
  },
  {
    "text": "The argument for explanations\nis, when you can't really",
    "start": "1054390",
    "end": "1058140"
  },
  {
    "text": "clearly quantify what\nfairness looks like,",
    "start": "1058140",
    "end": "1060990"
  },
  {
    "text": "that's when\nexplanations can help.",
    "start": "1060990",
    "end": "1063240"
  },
  {
    "text": "But that said, there\nare not many studies",
    "start": "1063240",
    "end": "1065700"
  },
  {
    "text": "which actually show what are\nthe complementary capabilities",
    "start": "1065700",
    "end": "1069090"
  },
  {
    "text": "of explanations or\nmodel interpretations",
    "start": "1069090",
    "end": "1072120"
  },
  {
    "text": "in detecting such unquantifiable\nnotions of what unfairness",
    "start": "1072120",
    "end": "1076260"
  },
  {
    "text": "looks like, right?",
    "start": "1076260",
    "end": "1077320"
  },
  {
    "text": "So there is, again,\na big gap there.",
    "start": "1077320",
    "end": "1079720"
  },
  {
    "text": "And how does the fairness, the\nstatistical notions of fairness",
    "start": "1079720",
    "end": "1084570"
  },
  {
    "text": "of inherently\ninterpretable models",
    "start": "1084570",
    "end": "1087029"
  },
  {
    "text": "compare with that of\nvanilla models, right?",
    "start": "1087030",
    "end": "1089370"
  },
  {
    "text": "So for example, if I just\ntrain an interpretable model,",
    "start": "1089370",
    "end": "1093300"
  },
  {
    "text": "how does the fairness\nof that model,",
    "start": "1093300",
    "end": "1095260"
  },
  {
    "text": "whether it's equality\nof opportunity",
    "start": "1095260",
    "end": "1097080"
  },
  {
    "text": "or whether it's\nstatistical parity,",
    "start": "1097080",
    "end": "1099360"
  },
  {
    "text": "how do those properties\ncompare with the fairness",
    "start": "1099360",
    "end": "1103380"
  },
  {
    "text": "of a model that is\ninherently interpretable?",
    "start": "1103380",
    "end": "1106530"
  },
  {
    "text": "Either things like\nrulers or either",
    "start": "1106530",
    "end": "1108930"
  },
  {
    "text": "when you're adding prototype\nlayers or attention weights,",
    "start": "1108930",
    "end": "1112290"
  },
  {
    "text": "how to think about those, right?",
    "start": "1112290",
    "end": "1113760"
  },
  {
    "text": "And are there any\ninherent trade-offs",
    "start": "1113760",
    "end": "1115740"
  },
  {
    "text": "between certain kinds of model\ninterpretability and model",
    "start": "1115740",
    "end": "1119520"
  },
  {
    "text": "fairness?",
    "start": "1119520",
    "end": "1120150"
  },
  {
    "text": "Or do these aspects\nreinforce each other.",
    "start": "1120150",
    "end": "1122850"
  },
  {
    "text": "Again, that relationship\nor connection is unclear.",
    "start": "1122850",
    "end": "1127470"
  },
  {
    "start": "1127000",
    "end": "1393000"
  },
  {
    "text": "All right, so\nprivacy is actually",
    "start": "1127470",
    "end": "1129690"
  },
  {
    "text": "something that has come\nup during the break.",
    "start": "1129690",
    "end": "1131669"
  },
  {
    "text": "And I was talking to somebody\nthat I now can't recall.",
    "start": "1131670",
    "end": "1134580"
  },
  {
    "text": "But essentially, I\nthink, by definition,",
    "start": "1134580",
    "end": "1137370"
  },
  {
    "text": "a lot of model interpretability\nand explanations",
    "start": "1137370",
    "end": "1140430"
  },
  {
    "text": "is about exposing information\nabout the model, right?",
    "start": "1140430",
    "end": "1143910"
  },
  {
    "text": "So how can these aspects--",
    "start": "1143910",
    "end": "1146280"
  },
  {
    "text": "or can these model\ninterpretations",
    "start": "1146280",
    "end": "1148980"
  },
  {
    "text": "and explanations expose\nsensitive information",
    "start": "1148980",
    "end": "1152490"
  },
  {
    "text": "from the data sets,\nfor example, right?",
    "start": "1152490",
    "end": "1155640"
  },
  {
    "text": "Again, there is very\nlittle research.",
    "start": "1155640",
    "end": "1157350"
  },
  {
    "text": "I think barring a\ncouple of papers,",
    "start": "1157350",
    "end": "1158940"
  },
  {
    "text": "there is not a whole lot\nof work in this area.",
    "start": "1158940",
    "end": "1161409"
  },
  {
    "text": "So there is very little research\non the privacy implications",
    "start": "1161410",
    "end": "1164700"
  },
  {
    "text": "of interpretable\nmodels or explanations.",
    "start": "1164700",
    "end": "1167320"
  },
  {
    "text": "So what kinds of\nprivacy attacks are",
    "start": "1167320",
    "end": "1169559"
  },
  {
    "text": "enabled by providing\nmodel interpretations",
    "start": "1169560",
    "end": "1172530"
  },
  {
    "text": "or explanations?",
    "start": "1172530",
    "end": "1173790"
  },
  {
    "text": "Again, we don't have very\nclear answers, right?",
    "start": "1173790",
    "end": "1176340"
  },
  {
    "text": "And furthermore-- I mean, we\ndon't have answers to that,",
    "start": "1176340",
    "end": "1179380"
  },
  {
    "text": "which means we also don't have\nanswers to this, which is,",
    "start": "1179380",
    "end": "1182580"
  },
  {
    "text": "do differentially\nprivate models actually",
    "start": "1182580",
    "end": "1184890"
  },
  {
    "text": "help defend against\nsuch attacks?",
    "start": "1184890",
    "end": "1186870"
  },
  {
    "text": "If so, under what\nconditions do they help?",
    "start": "1186870",
    "end": "1189309"
  },
  {
    "text": "Should we actually construct\ndifferentially private",
    "start": "1189310",
    "end": "1192030"
  },
  {
    "text": "explanations in\norder to mitigate",
    "start": "1192030",
    "end": "1194430"
  },
  {
    "text": "these kinds of attacks.",
    "start": "1194430",
    "end": "1195790"
  },
  {
    "text": "These are all open problems.",
    "start": "1195790",
    "end": "1199030"
  },
  {
    "text": "All right, OK, so\nthe last part, we",
    "start": "1199030",
    "end": "1202360"
  },
  {
    "text": "have talked quite a bit\nabout model interpretations,",
    "start": "1202360",
    "end": "1205570"
  },
  {
    "text": "explanations, and so on.",
    "start": "1205570",
    "end": "1207980"
  },
  {
    "text": "And we have gone into the depth\nof what their weaknesses are,",
    "start": "1207980",
    "end": "1212260"
  },
  {
    "text": "how to think about\nthese connections,",
    "start": "1212260",
    "end": "1213850"
  },
  {
    "text": "all kinds of stuff, right?",
    "start": "1213850",
    "end": "1215710"
  },
  {
    "text": "And in the process, I mean,\nwhile there are limitations",
    "start": "1215710",
    "end": "1218890"
  },
  {
    "text": "of these approaches,\nthere is nothing",
    "start": "1218890",
    "end": "1220960"
  },
  {
    "text": "that stops us from thinking\nabout new tools, interfaces,",
    "start": "1220960",
    "end": "1224919"
  },
  {
    "text": "which can be used to make\nmodels more interpretable",
    "start": "1224920",
    "end": "1229330"
  },
  {
    "text": "or to facilitate model\nunderstanding, right?",
    "start": "1229330",
    "end": "1231700"
  },
  {
    "text": "So for example, while\nAPIs, and commands,",
    "start": "1231700",
    "end": "1234669"
  },
  {
    "text": "and visualizations are\nprobably natural to some of us.",
    "start": "1234670",
    "end": "1239440"
  },
  {
    "text": "For example, people who\nare maybe more ML savvy,",
    "start": "1239440",
    "end": "1242769"
  },
  {
    "text": "they may not be as\nnatural to, say, somebody",
    "start": "1242770",
    "end": "1245050"
  },
  {
    "text": "like a policymaker or a doctor.",
    "start": "1245050",
    "end": "1247880"
  },
  {
    "text": "So what can be some new tools\nvisualizations interfaces",
    "start": "1247880",
    "end": "1251860"
  },
  {
    "text": "to sort of help them understand\nwhat models are doing, right?",
    "start": "1251860",
    "end": "1256120"
  },
  {
    "text": "So that is also\nan important area",
    "start": "1256120",
    "end": "1259030"
  },
  {
    "text": "of research, which,\nI think, needs",
    "start": "1259030",
    "end": "1261070"
  },
  {
    "text": "to receive more attention.",
    "start": "1261070",
    "end": "1262809"
  },
  {
    "text": "And of course, standardized\nbenchmarks and tools",
    "start": "1262810",
    "end": "1265570"
  },
  {
    "text": "are also important\nfor us to develop",
    "start": "1265570",
    "end": "1267789"
  },
  {
    "text": "some common understanding\nof where we are as a field.",
    "start": "1267790",
    "end": "1272680"
  },
  {
    "text": "So the first question\nunder this broad direction",
    "start": "1272680",
    "end": "1275800"
  },
  {
    "text": "that I put together\nis, can we construct",
    "start": "1275800",
    "end": "1278620"
  },
  {
    "text": "more interactive\ninterfaces for end users",
    "start": "1278620",
    "end": "1282280"
  },
  {
    "text": "to engage with models, right?",
    "start": "1282280",
    "end": "1284470"
  },
  {
    "text": "Instead of giving them, here\nis your LIME explanation,",
    "start": "1284470",
    "end": "1287710"
  },
  {
    "text": "take your future\nimportances, and this",
    "start": "1287710",
    "end": "1289990"
  },
  {
    "text": "is what I can give you,\nwhat if we can make",
    "start": "1289990",
    "end": "1292390"
  },
  {
    "text": "this process more interactive?",
    "start": "1292390",
    "end": "1294250"
  },
  {
    "text": "What would be the nature of\nsuch interactions, right?",
    "start": "1294250",
    "end": "1297530"
  },
  {
    "text": "So this is something that\nwe have been exploring",
    "start": "1297530",
    "end": "1299530"
  },
  {
    "text": "with some students recently.",
    "start": "1299530",
    "end": "1301690"
  },
  {
    "text": "I'll show you a quick demo.",
    "start": "1301690",
    "end": "1303159"
  },
  {
    "text": "Hopefully, that should work.",
    "start": "1303160",
    "end": "1304340"
  },
  {
    "text": "Let's see.",
    "start": "1304340",
    "end": "1304840"
  },
  {
    "text": "OK.",
    "start": "1304840",
    "end": "1306100"
  },
  {
    "text": "So for example, so this\nis basically a tool",
    "start": "1306100",
    "end": "1309130"
  },
  {
    "text": "that we developed\ncalled TalkToModel.",
    "start": "1309130",
    "end": "1311950"
  },
  {
    "text": "So you can use natural language\ninterface and chat with models.",
    "start": "1311950",
    "end": "1315970"
  },
  {
    "text": "Like, this is literally\nlike chatting with models",
    "start": "1315970",
    "end": "1318309"
  },
  {
    "text": "to understand how it's\nmaking predictions, right?",
    "start": "1318310",
    "end": "1320890"
  },
  {
    "text": "So for example, what\nare the predictions",
    "start": "1320890",
    "end": "1324400"
  },
  {
    "text": "on people over 20 years?",
    "start": "1324400",
    "end": "1328015"
  },
  {
    "start": "1328015",
    "end": "1335840"
  },
  {
    "text": "So it's saying, for a data\nwith age greater than 20,",
    "start": "1335840",
    "end": "1338990"
  },
  {
    "text": "the model is predicting this.",
    "start": "1338990",
    "end": "1340880"
  },
  {
    "text": "And if I say, explain\npredictions for people",
    "start": "1340880",
    "end": "1346140"
  },
  {
    "text": "for over 20 years,\nit kind of shows",
    "start": "1346140",
    "end": "1349530"
  },
  {
    "text": "me what are the important\nfeatures, and so on.",
    "start": "1349530",
    "end": "1352100"
  },
  {
    "text": "Then, I can ask questions,\nand so on, and so forth.",
    "start": "1352100",
    "end": "1355419"
  },
  {
    "text": "So this interface\nis more natural.",
    "start": "1355420",
    "end": "1357630"
  },
  {
    "text": "And the reason why we\nbuild such an interface",
    "start": "1357630",
    "end": "1360030"
  },
  {
    "text": "is that, when we\nwork with hospitals",
    "start": "1360030",
    "end": "1361770"
  },
  {
    "text": "and so on, we often get\na request, like a feature",
    "start": "1361770",
    "end": "1364890"
  },
  {
    "text": "request, from a\nlot of these people",
    "start": "1364890",
    "end": "1367050"
  },
  {
    "text": "that the current ways in which\nUML people give us these tools",
    "start": "1367050",
    "end": "1371250"
  },
  {
    "text": "is so clunky.",
    "start": "1371250",
    "end": "1372780"
  },
  {
    "text": "You will give me five\nfeature importance values,",
    "start": "1372780",
    "end": "1375210"
  },
  {
    "text": "and you expect me to\njust deal with it?",
    "start": "1375210",
    "end": "1377460"
  },
  {
    "text": "I want a more natural way\nof engaging with the model.",
    "start": "1377460",
    "end": "1380520"
  },
  {
    "text": "And one of the practitioners\nwe were interviewing, once",
    "start": "1380520",
    "end": "1383580"
  },
  {
    "text": "was like, I just want a natural\nway to talk to the model,",
    "start": "1383580",
    "end": "1386740"
  },
  {
    "text": "right?",
    "start": "1386740",
    "end": "1387240"
  },
  {
    "text": "And from that is born\nall this entire endeavor.",
    "start": "1387240",
    "end": "1392040"
  },
  {
    "text": "So yeah, I mean, I'm not\nsaying that's perfect.",
    "start": "1392040",
    "end": "1394260"
  },
  {
    "start": "1393000",
    "end": "1606000"
  },
  {
    "text": "But essentially, we\nneed to keep thinking",
    "start": "1394260",
    "end": "1396210"
  },
  {
    "text": "about more interactive\ninterfaces, which",
    "start": "1396210",
    "end": "1398610"
  },
  {
    "text": "can make this process\nof understanding models",
    "start": "1398610",
    "end": "1400799"
  },
  {
    "text": "more natural, right?",
    "start": "1400800",
    "end": "1403050"
  },
  {
    "text": "And as model interpretations\nand explanations",
    "start": "1403050",
    "end": "1406830"
  },
  {
    "text": "are employed in\ndifferent settings,",
    "start": "1406830",
    "end": "1409360"
  },
  {
    "text": "we need to develop new\nbenchmarks and tools",
    "start": "1409360",
    "end": "1412020"
  },
  {
    "text": "for enabling comparison\nof various properties",
    "start": "1412020",
    "end": "1414570"
  },
  {
    "text": "of these explanation methods\nor interpretation methods.",
    "start": "1414570",
    "end": "1418799"
  },
  {
    "text": "How do we enable that?",
    "start": "1418800",
    "end": "1420870"
  },
  {
    "text": "Because I think we can't\nuse a single benchmark",
    "start": "1420870",
    "end": "1423570"
  },
  {
    "text": "for all possible\napplication settings.",
    "start": "1423570",
    "end": "1426190"
  },
  {
    "text": "So how do we make the\nprocess of creating",
    "start": "1426190",
    "end": "1428519"
  },
  {
    "text": "multiple benchmarks easier?",
    "start": "1428520",
    "end": "1430345"
  },
  {
    "text": "So that's also something\nwe need to think about.",
    "start": "1430345",
    "end": "1432345"
  },
  {
    "text": "OK?",
    "start": "1432345",
    "end": "1434230"
  },
  {
    "text": "So with that, I think\nwe are almost coming",
    "start": "1434230",
    "end": "1436890"
  },
  {
    "text": "to the end of this discussion.",
    "start": "1436890",
    "end": "1439450"
  },
  {
    "text": "A little earlier than planned,\nbut I think that's good.",
    "start": "1439450",
    "end": "1441760"
  },
  {
    "text": "I'm sure all of you also\nwant to take a break,",
    "start": "1441760",
    "end": "1444120"
  },
  {
    "text": "and go home, and\ndo other things.",
    "start": "1444120",
    "end": "1446800"
  },
  {
    "text": "So there has been a\nlot of renewed interest",
    "start": "1446800",
    "end": "1449790"
  },
  {
    "text": "in model understanding over\nthe past half a decade or so,",
    "start": "1449790",
    "end": "1453150"
  },
  {
    "text": "right?",
    "start": "1453150",
    "end": "1454080"
  },
  {
    "text": "And a lot of this has come from\nthis aspect of ML models being",
    "start": "1454080",
    "end": "1458970"
  },
  {
    "text": "deployed in a lot of health care\nand other high stakes settings,",
    "start": "1458970",
    "end": "1461865"
  },
  {
    "text": "right?",
    "start": "1461865",
    "end": "1462690"
  },
  {
    "text": "So that's when.",
    "start": "1462690",
    "end": "1463769"
  },
  {
    "text": "Because of that happening, there\nhas been a growing interest",
    "start": "1463770",
    "end": "1467100"
  },
  {
    "text": "in seriousness in thinking\nabout, let's understand models.",
    "start": "1467100",
    "end": "1470970"
  },
  {
    "text": "Let's understand the predictions\nthey're making, right?",
    "start": "1470970",
    "end": "1473820"
  },
  {
    "text": "And as these models continue\nto get more and more complex,",
    "start": "1473820",
    "end": "1477960"
  },
  {
    "text": "and they continue to\nfind more applications,",
    "start": "1477960",
    "end": "1480809"
  },
  {
    "text": "the need for understanding\nwhat these models are doing",
    "start": "1480810",
    "end": "1484260"
  },
  {
    "text": "is only going to raise.",
    "start": "1484260",
    "end": "1485610"
  },
  {
    "text": "And I can say that, especially\ngiven the legislations",
    "start": "1485610",
    "end": "1489150"
  },
  {
    "text": "and regulations that\nare also being pushed",
    "start": "1489150",
    "end": "1491640"
  },
  {
    "text": "from different quarters,\nboth in Europe and the US,",
    "start": "1491640",
    "end": "1494790"
  },
  {
    "text": "I think the need for\nmodel understanding",
    "start": "1494790",
    "end": "1497460"
  },
  {
    "text": "is going to become a real\nrequirement in practice,",
    "start": "1497460",
    "end": "1500580"
  },
  {
    "text": "also, in several domains.",
    "start": "1500580",
    "end": "1501674"
  },
  {
    "text": "OK?",
    "start": "1501675",
    "end": "1503680"
  },
  {
    "text": "So as we just saw, there\nare several interesting open",
    "start": "1503680",
    "end": "1506580"
  },
  {
    "text": "research problems, and\nthere are a ton of them.",
    "start": "1506580",
    "end": "1509490"
  },
  {
    "text": "And what we just saw is\nprobably a subset of them.",
    "start": "1509490",
    "end": "1512200"
  },
  {
    "text": "But essentially, the\nfield is sort of wide open",
    "start": "1512200",
    "end": "1514620"
  },
  {
    "text": "to be explored and open\nfor us to basically develop",
    "start": "1514620",
    "end": "1522210"
  },
  {
    "text": "a new understanding of what we\nhave today, where are the gaps,",
    "start": "1522210",
    "end": "1526260"
  },
  {
    "text": "and how to improve, right?",
    "start": "1526260",
    "end": "1528660"
  },
  {
    "text": "So the thing that I really\nlike about the field",
    "start": "1528660",
    "end": "1531510"
  },
  {
    "text": "of explainable AI\nis that you can",
    "start": "1531510",
    "end": "1534000"
  },
  {
    "text": "approach this topic from a\nlot of diverse perspectives.",
    "start": "1534000",
    "end": "1537240"
  },
  {
    "text": "Whether you are a theoretician,\nwhether you are an ML",
    "start": "1537240",
    "end": "1539850"
  },
  {
    "text": "algorithms person, whether\nyou are an HCI researcher,",
    "start": "1539850",
    "end": "1543030"
  },
  {
    "text": "or an interdisciplinary\nresearcher,",
    "start": "1543030",
    "end": "1545190"
  },
  {
    "text": "there is definitely\nroom to contribute",
    "start": "1545190",
    "end": "1547470"
  },
  {
    "text": "from all of these\nsides as probably",
    "start": "1547470",
    "end": "1549780"
  },
  {
    "text": "this discussion and the stock\nhas already convinced you,",
    "start": "1549780",
    "end": "1552210"
  },
  {
    "text": "right?",
    "start": "1552210",
    "end": "1553230"
  },
  {
    "text": "And in fact, I'm somebody\nwho likes to move around",
    "start": "1553230",
    "end": "1555990"
  },
  {
    "text": "some of these areas, so\nI feel like this area",
    "start": "1555990",
    "end": "1559920"
  },
  {
    "text": "of explainable AI is a perfect\nground for somebody like me",
    "start": "1559920",
    "end": "1563730"
  },
  {
    "text": "who likes to do theory,\ndevelop methods, and also",
    "start": "1563730",
    "end": "1566700"
  },
  {
    "text": "do some user studies and\ninterdisciplinary work.",
    "start": "1566700",
    "end": "1569730"
  },
  {
    "text": "I get to exercise\ndifferent aspects of those.",
    "start": "1569730",
    "end": "1573540"
  },
  {
    "text": "OK, so with that, I think\nI'm going to pause here.",
    "start": "1573540",
    "end": "1577110"
  },
  {
    "text": "We are at 3:45, and I'm\nhappy to take more questions,",
    "start": "1577110",
    "end": "1582390"
  },
  {
    "text": "address any other\ncomments, and so on.",
    "start": "1582390",
    "end": "1585890"
  },
  {
    "text": "And oh, before we\ndo that, so there's",
    "start": "1585890",
    "end": "1587750"
  },
  {
    "text": "just a bunch of useful links\nof course on this topic,",
    "start": "1587750",
    "end": "1592460"
  },
  {
    "text": "a bunch more tutorials\non this topic,",
    "start": "1592460",
    "end": "1594620"
  },
  {
    "text": "and Trustworthy\nML Initiative also",
    "start": "1594620",
    "end": "1596809"
  },
  {
    "text": "has a bunch more\nresources on this topic.",
    "start": "1596810",
    "end": "1599830"
  },
  {
    "start": "1599830",
    "end": "1605000"
  }
]
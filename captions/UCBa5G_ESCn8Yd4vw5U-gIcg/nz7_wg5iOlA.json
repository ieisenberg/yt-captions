[
  {
    "start": "0",
    "end": "70000"
  },
  {
    "start": "0",
    "end": "5650"
  },
  {
    "text": "Yes. So making you all see\nthe speaker not just not part of the plan\nbut I'm glad to be here.",
    "start": "5650",
    "end": "12500"
  },
  {
    "text": "And my name is Vivek Natarajan. And I am a research scientist\nin the Health AI team at Google.",
    "start": "12500",
    "end": "20029"
  },
  {
    "text": "A little bit more about me. Growing up in India,\nmy parents always wanted me to be a doctor, to\nbe precise a medical doctor.",
    "start": "20030",
    "end": "27830"
  },
  {
    "text": "But unfortunately, I was\nprobably not good enough to memorize all of\nthe biology textbooks",
    "start": "27830",
    "end": "32989"
  },
  {
    "text": "that you had to do\nin case you wanted to track the medical\nentrance examinations. So I ended up becoming a\ncomputer scientist instead.",
    "start": "32990",
    "end": "41760"
  },
  {
    "text": "But as a great man\nonce said, \"You can connect the dots\nlooking forward. You only join them\nlooking backwards.\"",
    "start": "41760",
    "end": "48570"
  },
  {
    "text": "So through a rather long\nwinded path, not too dissimilar from how we actually\ntrain our neural networks,",
    "start": "48570",
    "end": "55220"
  },
  {
    "text": "I ended up working\nin medicine again, this time armed with this\nmagical new tool of AI.",
    "start": "55220",
    "end": "61460"
  },
  {
    "text": "And I can tell you that my\nparents are far more happy with my life choices right now. ",
    "start": "61460",
    "end": "69140"
  },
  {
    "text": "But they never truly satisfied. But digressions aside,\nmy goal for this job",
    "start": "69140",
    "end": "75290"
  },
  {
    "start": "70000",
    "end": "572000"
  },
  {
    "text": "is to peel back the\ncurtains and give you a flavor of all the\ninnovation that is happening at the intersection\nof AI and biomedicine,",
    "start": "75290",
    "end": "82310"
  },
  {
    "text": "and how that is being\ncatalyzed by transformers and large language\nmodels in particular.",
    "start": "82310",
    "end": "88910"
  },
  {
    "text": "So we will spend the\nfirst few minutes trying to work up from first\nprinciples, why transformers",
    "start": "88910",
    "end": "94280"
  },
  {
    "text": "and large language\nmodels are a particularly good fit for biomedical data.",
    "start": "94280",
    "end": "99890"
  },
  {
    "text": "And then we will deep dive\ninto a few papers covering a bunch of different biomedical\napplications settings.",
    "start": "99890",
    "end": "107360"
  },
  {
    "text": "And finally, I'll\npresent my views on how this field is\nlikely going to evolve in the next few years.",
    "start": "107360",
    "end": "114229"
  },
  {
    "text": "And even though my voice or tone\nmay not exactly sound that way, I am incredibly excited\nby the possibilities of AI",
    "start": "114230",
    "end": "121189"
  },
  {
    "text": "in biomedicine. And I think we have an\nincredible opportunity in front of us to advance human\nhealth and human potential.",
    "start": "121190",
    "end": "127549"
  },
  {
    "text": "And my hope at the\nend of this talk is you all will feel the\nsame way as I do today and perhaps join me.",
    "start": "127550",
    "end": "135060"
  },
  {
    "text": "So yeah, let's jump\nstraight in, why transformers in biomedicine? And sorry I'm going\nto pick people",
    "start": "135060",
    "end": "141600"
  },
  {
    "text": "who are in person to answer. So maybe if one of\nyou could volunteer. ",
    "start": "141600",
    "end": "148320"
  },
  {
    "text": "Go for it. Why not? That's a good answer. ",
    "start": "148320",
    "end": "156696"
  },
  {
    "text": "Sure, go for it. We have a lot of [INAUDIBLE]\ndata, so [INAUDIBLE].. ",
    "start": "156697",
    "end": "166549"
  },
  {
    "text": "Yeah, sure. Medical doctors are expensive. And a lot of their job is\njust like memorizing the DSM.",
    "start": "166550",
    "end": "174100"
  },
  {
    "text": " Yeah, that's an important\napplication setting.",
    "start": "174100",
    "end": "179104"
  },
  {
    "text": "[INAUDIBLE]  Yeah, great one. So I think all of you\nwere on the right track.",
    "start": "179104",
    "end": "186700"
  },
  {
    "text": "And so maybe if you just\nlook at different kinds of biomedical data.",
    "start": "186700",
    "end": "192910"
  },
  {
    "text": "For example, what\nare clinical notes? I think it's sequence\nof doctor gibberish. OK, I did not say\nthat but let's just",
    "start": "192910",
    "end": "200530"
  },
  {
    "text": "call a sequence of doctor\nspeak or doctor notes. Similarly, if you were to look\nat electronic medical records,",
    "start": "200530",
    "end": "207070"
  },
  {
    "text": "what are they? They're essentially a sequence\nof a person's encounters with the medical system. ",
    "start": "207070",
    "end": "214450"
  },
  {
    "text": "What about proteins? Going deeper into\nthe biological stack. They are nothing but a sequence\nof amino acids linked together",
    "start": "214450",
    "end": "220300"
  },
  {
    "text": "by peptide bonds. And does anybody\nknow what this is? ",
    "start": "220300",
    "end": "228480"
  },
  {
    "text": "Go for it. I think that's how we\nstore medical records. ",
    "start": "228480",
    "end": "234320"
  },
  {
    "text": "Sorry, again. Well, looks like chromosomes. It's like they [INAUDIBLE]. You're getting close. ",
    "start": "234320",
    "end": "241760"
  },
  {
    "text": "Anyone else?  So this is in the Wellcome\nCollection in London",
    "start": "241760",
    "end": "248450"
  },
  {
    "text": "and this is actually a printout\nof the full human genome. And note, they did\nnot cheat over here.",
    "start": "248450",
    "end": "256519"
  },
  {
    "text": "The font is super small. And as you can see\nthere's a bunch of ADGCs. The entire printout\ncontains I think",
    "start": "256519",
    "end": "264260"
  },
  {
    "text": "over 130 volumes in that shelf. And each page is\nprinted on both sides and it's a 4 point font\nwith precisely 43,000",
    "start": "264260",
    "end": "272900"
  },
  {
    "text": "characters per page. So that is how big\nthe human reference genome is, more than\nbillions of base pairs.",
    "start": "272900",
    "end": "281860"
  },
  {
    "text": "And so again, the genome\nis nothing but a sequence of nucleotide base pairs.",
    "start": "281860",
    "end": "287000"
  },
  {
    "text": "So what we are essentially\nseeing over here is sequences are everywhere\nin biomedical data",
    "start": "287000",
    "end": "292630"
  },
  {
    "text": "and what is the\nbest neural network architecture for modeling them? ",
    "start": "292630",
    "end": "299270"
  },
  {
    "text": "And I guess since you\nare all in this course, I don't have to convince\nyou that the answer is transformers.",
    "start": "299270",
    "end": "306890"
  },
  {
    "text": "OK, that's good. But maybe I'll just offer\na few reasons over here.",
    "start": "306890",
    "end": "312420"
  },
  {
    "text": "Firstly as you can see, the data\nitself is multimodal in nature. And we just saw a few examples.",
    "start": "312420",
    "end": "319620"
  },
  {
    "text": "And as someone pointed\nout, transformers have proven remarkable\nat gassing up pretty much any kind of data.",
    "start": "319620",
    "end": "326420"
  },
  {
    "text": "And we are really seeing\nthis remarkable convergence across fields, whether that's\nspeech, or LP, or vision,",
    "start": "326420",
    "end": "332420"
  },
  {
    "text": "or robotics. I mean, pretty much everywhere\nwe are using transformers and I think biomedicine\nis no different.",
    "start": "332420",
    "end": "338690"
  },
  {
    "text": "I think secondly, transformers\nare far more effective at modeling complex, long range\ninteractions over sequences.",
    "start": "338690",
    "end": "345660"
  },
  {
    "text": "And this property\nis particularly important in the\nbiomedical domain and we will cover this in\nmore detail later in the talk.",
    "start": "345660",
    "end": "353250"
  },
  {
    "text": "And finally, as\nsomeone pointed out, these data sets\ncan be quite big. And you can easily get into the\nbillions of tokens territory.",
    "start": "353250",
    "end": "360949"
  },
  {
    "text": "And this is where transformers\nwith all the power lies of operations and the\nrelative ease of training.",
    "start": "360950",
    "end": "366530"
  },
  {
    "text": "And maybe someone should\ntry training analysis on these kind of data sets. You'll realize that these\nare much better suited",
    "start": "366530",
    "end": "372530"
  },
  {
    "text": "for the kind of\ndata sets that we have in this domain over here. So yeah, I think there are\na few more reasons as well",
    "start": "372530",
    "end": "379080"
  },
  {
    "text": "but I think these are the key\nones as to why transformers are particularly well-suited for\nbiomedical data sets and does.",
    "start": "379080",
    "end": "387449"
  },
  {
    "text": "Any questions so far. OK, great. So now in the next\npart of this talk,",
    "start": "387450",
    "end": "394319"
  },
  {
    "text": "we will dive deep into a few\npapers applying transformers to biomedical data.",
    "start": "394320",
    "end": "400050"
  },
  {
    "text": "We'll start with\nclinical applications first, and then go gradually\ndeeper into the biology stack, looking at proteins and\ngenomic applications as well.",
    "start": "400050",
    "end": "408780"
  },
  {
    "text": "And what you will\nobserve is that while transformers and large\nlanguage models by extension",
    "start": "408780",
    "end": "414260"
  },
  {
    "text": "are a great fit, often\nyou have to innovate, not just on the modeling\nside but also on the data",
    "start": "414260",
    "end": "420620"
  },
  {
    "text": "and evaluation side to\nmake these application scenarios really work. ",
    "start": "420620",
    "end": "427320"
  },
  {
    "text": "And so the first paper I\nwant to talk about over here is this recent\nwork from our team called \"Large Language Models\nEncode Clinical Knowledge.\"",
    "start": "427320",
    "end": "435620"
  },
  {
    "text": "The motivation for this work is\nactually quite straightforward. So if you look at medicine,\nit is a human endeavor.",
    "start": "435620",
    "end": "441600"
  },
  {
    "text": "And language is at the heart\nof it facilitating interactions between people and those\nwho provide care for them.",
    "start": "441600",
    "end": "447465"
  },
  {
    "text": "Unfortunately, if you look at\na lot of medical AI systems develop till date, these\nare all narrow single tasks",
    "start": "447465",
    "end": "453110"
  },
  {
    "text": "single domain models lacking\ninteractive and expressive capabilities. And as a result,\nwhat has happened",
    "start": "453110",
    "end": "459680"
  },
  {
    "text": "is there is this discordance\nbetween what these models can do and what is expected\nof them by patients,",
    "start": "459680",
    "end": "466400"
  },
  {
    "text": "and care providers, and others. And this in turn has\nI think prevented broad uptake of medical AI.",
    "start": "466400",
    "end": "474517"
  },
  {
    "text": "And you can see that, for\nexample you don't really have AI in many\nclinics out there like helping us with diagnosis\nAnd so on and so forth.",
    "start": "474517",
    "end": "481500"
  },
  {
    "text": "But the recent progress\nwith transformer based large language models,\nit offers us an opportunity",
    "start": "481500",
    "end": "486650"
  },
  {
    "text": "to change all of this and\nredesign and rethink medical AI systems with language at the\nheart of it mediating human AI",
    "start": "486650",
    "end": "493849"
  },
  {
    "text": "interactions between doctors,\nresearchers, and patients.",
    "start": "493850",
    "end": "499710"
  },
  {
    "text": "And I will be honest\nif I don't point out that there has been a large\nvolume of work in this space, particularly in\nthe last few years.",
    "start": "499710",
    "end": "506169"
  },
  {
    "text": "There have been various\nattempts to train language models in\nthe biomedical domain with models of various\ndifferent sizes",
    "start": "506170",
    "end": "512669"
  },
  {
    "text": "on different core pieces\nof biomedical data.  And while this is\nexciting, the quality bar",
    "start": "512669",
    "end": "519780"
  },
  {
    "text": "for applications in the medical\ndomain is actually quite high. And so what is\nmissing is actually",
    "start": "519780",
    "end": "525060"
  },
  {
    "text": "is that there is actually not\nmany good evaluation benchmarks and evaluation protocols\nand frameworks.",
    "start": "525060",
    "end": "530950"
  },
  {
    "text": "So we don't have the equivalent\nof a big bench in medicine. And hopefully, you guys have\ncovered big bench before.",
    "start": "530950",
    "end": "537670"
  },
  {
    "text": "And so big bench is\na benchmark where you can assess large\nlanguage models across a variety of tasks,\ndomains, and settings",
    "start": "537670",
    "end": "543360"
  },
  {
    "text": "but we don't have an equivalent\nof that in the medical domain. And further, if you look at the\nevaluations that are typically",
    "start": "543360",
    "end": "550380"
  },
  {
    "text": "used in these previous\nstudies, they only look at objective metrics like\naccuracy or natural language",
    "start": "550380",
    "end": "557670"
  },
  {
    "text": "generation metrics\nlike blue or cider. But these fail to capture the\nnuances of real world use cases",
    "start": "557670",
    "end": "562920"
  },
  {
    "text": "in clinical settings. So what we essentially need was\na good benchmark, and a task,",
    "start": "562920",
    "end": "569430"
  },
  {
    "text": "and also a good\nevaluation framework for evaluating these models. And so to address\nthis unmet need",
    "start": "569430",
    "end": "575650"
  },
  {
    "start": "572000",
    "end": "1063000"
  },
  {
    "text": "and assess the potential of\nLLMs in medicine, in our team, we decided to focus on the\nmedical question answering",
    "start": "575650",
    "end": "581290"
  },
  {
    "text": "task. Why? Because answering\nmedical questions is actually quite challenging.",
    "start": "581290",
    "end": "587360"
  },
  {
    "text": "It requires reading\ncomprehension skills, ability to accurately recall\nmedical knowledge,",
    "start": "587360",
    "end": "592810"
  },
  {
    "text": "and also manipulate\nand reason about it. And furthermore, the Q&A\ntask is generally enough",
    "start": "592810",
    "end": "598090"
  },
  {
    "text": "and can subsume a bunch of\ndifferent application settings such as summarization\nof clinical notes, clinical decision\nsupport, and also",
    "start": "598090",
    "end": "605920"
  },
  {
    "text": "primary care triaging of\npatient concerns and so on. So we've identified the task.",
    "start": "605920",
    "end": "612120"
  },
  {
    "text": "The next question\nis, what data set? And so when we look at\nthe literature over here, what we saw is that there are\nseveral data sets floating",
    "start": "612120",
    "end": "618023"
  },
  {
    "text": "around assessing model\ncapabilities in a bunch of different settings. So what we decided was we should\nprobably just unify all of them",
    "start": "618023",
    "end": "624960"
  },
  {
    "text": "and put together\nin one benchmark. And so we did that and\nwe called it MultiMedQA. And so if you look\nat it, this benchmark",
    "start": "624960",
    "end": "630459"
  },
  {
    "text": "now covers medical\nquestion answering data sets from a bunch of\ndifferent settings such as professional medical\nquestions like the US",
    "start": "630460",
    "end": "637560"
  },
  {
    "text": "medical license exam\nstyle questions. It also includes medical\nresearch questions, those based on PubMed\nabstracts and so on,",
    "start": "637560",
    "end": "644070"
  },
  {
    "text": "and also questions from live\nusers and consumers asking about medical information.",
    "start": "644070",
    "end": "649830"
  },
  {
    "text": "And also, the setting changes. It could be closed\ndomain or open domain and the model may be\nexpected to produce long form answer in one\nsetting and maybe a short form",
    "start": "649830",
    "end": "656730"
  },
  {
    "text": "answer in another setting. And finally, we saw\nthat while the Q&A data",
    "start": "656730",
    "end": "663682"
  },
  {
    "text": "sets, which covered consumer\ngoods-- yeah, go for it. I have a quick question. How do you evaluate\nlong formats?",
    "start": "663682",
    "end": "669572"
  },
  {
    "text": "I'll come back to this. OK. So yeah, very quickly. Finally, when we looked at-- Sorry, one more thing.",
    "start": "669572",
    "end": "676210"
  },
  {
    "text": "People on screen might not\nget your questions in person so can you repeat questions? OK, cool.",
    "start": "676210",
    "end": "681460"
  },
  {
    "text": "So the question was how do we\nevaluate long form answers? And I'll come back\nto the subject later.",
    "start": "681460",
    "end": "688250"
  },
  {
    "text": "And so very quickly,\nwhen we looked at the data sets that\nactually provided consumer",
    "start": "688250",
    "end": "693712"
  },
  {
    "text": "medical questions, we found\nthem to be quite small in size. So we decided to augment them. And so we went out to Google\nand looked at the most",
    "start": "693712",
    "end": "700060"
  },
  {
    "text": "frequently asked consumer\nmedical questions. And so we curated a data set and\nwe added that to the benchmark.",
    "start": "700060",
    "end": "705160"
  },
  {
    "text": "And we call that health\nsearch QA over here. And so-- yeah, again.",
    "start": "705160",
    "end": "710199"
  },
  {
    "text": "How big is the\ncomposite data set? I'll come back with the\nstatistics, I'm sure.",
    "start": "710200",
    "end": "716620"
  },
  {
    "text": "So here are a few examples. So if you look at the\nconsumer medical questions, they are quite short in nature.",
    "start": "716620",
    "end": "723313"
  },
  {
    "text": "And so they come from the\nhealth search QA and the life QA data sets whereas I think\nif you look at the USMLE style",
    "start": "723313",
    "end": "728350"
  },
  {
    "text": "questions, these are\nlike long vineyards. And so doctors have to\nreally, really carefully read through them and come up\nwith the right answer, which",
    "start": "728350",
    "end": "734110"
  },
  {
    "text": "often involves a\nprocess of elimination. So again very, very different\napplication settings and so the model has to really,\nreally adapt and understand",
    "start": "734110",
    "end": "742420"
  },
  {
    "text": "it has to do well in all these\nsettings across the board. And life QA is interesting\nbecause the reference answers",
    "start": "742420",
    "end": "751050"
  },
  {
    "text": "over here were actually\nprovided by librarians so that's another\ngood comparison point for us going ahead.",
    "start": "751050",
    "end": "757140"
  },
  {
    "text": "And so in terms\nof statistics, we had a total of seven data\nsets in this benchmark.",
    "start": "757140",
    "end": "763130"
  },
  {
    "text": "As I said, we cover professional\nmedicine, medical research, and consumer medical questions. They're again, of\nvarious different sizes",
    "start": "763130",
    "end": "770779"
  },
  {
    "text": "and can be long form,\nshort form, open domain, and close domain,\nso very diverse. And I think it provides a\nvery comprehensive evaluation",
    "start": "770780",
    "end": "777641"
  },
  {
    "text": "of models in this medical\nco-sponsoring setting. ",
    "start": "777642",
    "end": "784390"
  },
  {
    "text": "So if you have a task on the\nbenchmark, the next question, again, I think I asked was, how\ndo we evaluate these models?",
    "start": "784390",
    "end": "790529"
  },
  {
    "text": "And as I mentioned\nbefore, automated metrics are actually deeply\nunsatisfactory because they",
    "start": "790530",
    "end": "795690"
  },
  {
    "text": "fail to capture the\nnuances of real world clinical applications. So what we did was\nactually heavily inspired",
    "start": "795690",
    "end": "801779"
  },
  {
    "text": "by some of Stephen's\nwork over here, was to put together a\nhuman evaluation framework for assessing these\nlong form answers.",
    "start": "801780",
    "end": "808400"
  },
  {
    "text": "And this had two parts. The first part was\nevaluation by clinicians",
    "start": "808400",
    "end": "813810"
  },
  {
    "text": "and we asked them to rate\nthe model responses along 12 axes pertaining to factuality\nof the responses, ability",
    "start": "813810",
    "end": "820470"
  },
  {
    "text": "to recall medical knowledge,\ndo medical reasoning, and also for the\npotential of harm and bias in these responses.",
    "start": "820470",
    "end": "828730"
  },
  {
    "text": "But if you look at the potential\nend users of such medical Q&A systems, these are likely going\nto be non-expert lay users.",
    "start": "828730",
    "end": "834520"
  },
  {
    "text": "So it is also important to\nget these answers evaluated by them as well. And so we also\nadditionally asked",
    "start": "834520",
    "end": "840570"
  },
  {
    "text": "a pool of lay users as to\nhow helpful and actionable they thought the answers were.",
    "start": "840570",
    "end": "847180"
  },
  {
    "text": "And so that was our\nevaluation framework. And we also have the\nbenchmark fixed so now",
    "start": "847180",
    "end": "853260"
  },
  {
    "text": "we monitor the fun part of\nbuilding and aligning LLMs to the medical domain task.",
    "start": "853260",
    "end": "858920"
  },
  {
    "text": "So in this work, we decided\nto build on the PaLM family of language models. Has that been covered\nin the course before?",
    "start": "858920",
    "end": "865510"
  },
  {
    "text": "OK, great. But very quickly, I believe this\nis still the largest publicly announced densely activated\ndecoder-only large language",
    "start": "865510",
    "end": "873580"
  },
  {
    "text": "model, with the largest one\nbeing 540 billion parameters in total.",
    "start": "873580",
    "end": "879540"
  },
  {
    "text": "A few more details. The model's trained\non 40 billion tokens, 25% of which is multilingual.",
    "start": "879540",
    "end": "886150"
  },
  {
    "text": "The data come from a bunch\nof different sources, including social media\nconversations, web pages,",
    "start": "886150",
    "end": "891870"
  },
  {
    "text": "books, GitHub, and Wikipedia,\nand so on and so forth. And at the time of\nrelease, the model was state of the art on many\nNLP reasoning benchmarks.",
    "start": "891870",
    "end": "899310"
  },
  {
    "text": "And also it was the\nfirst model to exceed the average human\nperformance on BIG-bench. Further, over the last\nyear, PaLM-derived models",
    "start": "899310",
    "end": "907183"
  },
  {
    "text": "were shown to be super\nuseful in a bunch of different\napplication settings, including for code generation\nwhich was the PaLM code",
    "start": "907183",
    "end": "912500"
  },
  {
    "text": "model, in robotics,\nthe PaLM second model, and also for answering math\nand science questions which",
    "start": "912500",
    "end": "917880"
  },
  {
    "text": "was the Minerva models. And so we thought PaLM\nwas a very good foundation model for us to build on and\nuse it in the medical domain",
    "start": "917880",
    "end": "923345"
  },
  {
    "text": "as well. And overall, I think PaLM is\na true magic of engineering but I will refer you all\nback to [INAUDIBLE] paper",
    "start": "923345",
    "end": "929940"
  },
  {
    "text": "on this for more details. I think it's a must read. And again, in late\nOctober last year,",
    "start": "929940",
    "end": "937120"
  },
  {
    "text": "Jason Wei and a few\nothers at Google Brain came out with the FLAN PaLM\nvariant of the PaLM model",
    "start": "937120",
    "end": "942640"
  },
  {
    "text": "and this is basically the\ninstruction to and counterpart. And this model was\neven better than PaLM and I believe there's\nstill the state",
    "start": "942640",
    "end": "949000"
  },
  {
    "text": "of the art on many benchmarks\nsuch as MMLU, [INAUDIBLE],, and I think it exceeds PaLM\nperformance by an average",
    "start": "949000",
    "end": "954160"
  },
  {
    "text": "of 9.4% across BIG-bench tasks. ",
    "start": "954160",
    "end": "959660"
  },
  {
    "text": "So we decided to build\non the FLAN-PaLM model and we applied a combination\nof prompting strategies including few short\nprompting, chain",
    "start": "959660",
    "end": "966800"
  },
  {
    "text": "of thought reasoning, and also\nself consistency to the 540 billion parameter variant. And we evaluated it\non the MultiMedQA data",
    "start": "966800",
    "end": "973310"
  },
  {
    "text": "sets that had the short\nform MCQ questions. And we found that this\nmodel was really good.",
    "start": "973310",
    "end": "979490"
  },
  {
    "text": "At the time of publication,\nthis model on the USMLE data set exceeded the previous state\nof the art by over 17%.",
    "start": "979490",
    "end": "986850"
  },
  {
    "text": "This is specifically\nthe short form value? It's only for the\nUSMLE MedQA data set.",
    "start": "986850",
    "end": "991930"
  },
  {
    "text": "[INAUDIBLE] That's right. OK. And so you see that the\naccuracy or the previous state of the art at the\ntime of publication",
    "start": "991930",
    "end": "997951"
  },
  {
    "text": "went up by over 17%. And I believe this was the first\nLLM based AI system to obtain",
    "start": "997952",
    "end": "1003340"
  },
  {
    "text": "a passing equivalent\nscore which was 60% or above on this benchmark.",
    "start": "1003340",
    "end": "1009180"
  },
  {
    "text": "And similarly, when we\nlooked at other MCQA data sets in the benchmark. For example, MedMCQA\nwhich is a data",
    "start": "1009180",
    "end": "1014832"
  },
  {
    "text": "set of Indian medical entrance\nexamination questions, the model was again\nthe state of the art. On PubMedQA which was\nquestion answering based",
    "start": "1014832",
    "end": "1020880"
  },
  {
    "text": "on PubMed abstracts,\nthat was again, the model was state of the art\nat the time of publication. And same story on\nMMLU clinical topics",
    "start": "1020880",
    "end": "1028199"
  },
  {
    "text": "as well, which include genetics,\nanatomy, professional medicine, clinical knowledge, and a\nbunch of other topics in there.",
    "start": "1028200",
    "end": "1035069"
  },
  {
    "text": " All this was great. And then when we started looking\nat the scaling plots what",
    "start": "1035069",
    "end": "1042297"
  },
  {
    "text": "we saw was that the\nperformance seemed to be improving as we scaled\nthe model from 8 billion",
    "start": "1042297",
    "end": "1048580"
  },
  {
    "text": "to 62 billion to 540 billion. And so what this\nbasically suggested that these general purpose\nlarge language models trained",
    "start": "1048580",
    "end": "1054720"
  },
  {
    "text": "on public internet seemed\nto encode clinical knowledge pretty well, and their\nmedical reasoning abilities",
    "start": "1054720",
    "end": "1060450"
  },
  {
    "text": "tend to scale with\nmodel parameter size. We also did another\nexperiment when we",
    "start": "1060450",
    "end": "1066050"
  },
  {
    "start": "1063000",
    "end": "1290000"
  },
  {
    "text": "looked at selective prediction. And we used the self\nconsistency votes",
    "start": "1066050",
    "end": "1071450"
  },
  {
    "text": "to determine when to differ. And this is important\nin clinical settings because doctors\ncommunicate when they",
    "start": "1071450",
    "end": "1078455"
  },
  {
    "text": "don't know about something. And if our AI systems\nare going to be used in clinical settings,\nfor example for diagnosis, they should be able to tell you\nwhen they don't know something.",
    "start": "1078455",
    "end": "1085920"
  },
  {
    "text": "And so what we observed here\nwas this fairly crude metric. We were getting a linear\nimprovement in performance",
    "start": "1085920",
    "end": "1092120"
  },
  {
    "text": "as we change the\ndefault threshold. And this was quite nice\nbut in practice, this",
    "start": "1092120",
    "end": "1097549"
  },
  {
    "text": "is actually quite inefficient\nbecause you are generating multiple decoding samples to\nbe able to compute this metric",
    "start": "1097550",
    "end": "1102740"
  },
  {
    "text": "so we need a better method. Just to be clear, what is the\ncurrent fraction [INAUDIBLE] what fraction you\nfind the model asks?",
    "start": "1102740",
    "end": "1109195"
  },
  {
    "text": "Yeah, it's basically says\nI'm uncertain or unknown. And that's determined based\non the cell consistency works.",
    "start": "1109195",
    "end": "1115470"
  },
  {
    "text": "I see. OK. So [INAUDIBLE] to apply variance\nand apply consistency samples. Got it.",
    "start": "1115470",
    "end": "1120490"
  },
  {
    "text": "Exactly. Oh. Are models trained to be\ncapable of deferring itself",
    "start": "1120490",
    "end": "1126420"
  },
  {
    "text": "[INAUDIBLE] I don't know? No because they're just trained\non this next word prediction",
    "start": "1126420",
    "end": "1132380"
  },
  {
    "text": "task and that depends\non the data set. The PubMedQA has some\nanswers which are maybe but again, we don't explicitly\nfine tune the models over here.",
    "start": "1132380",
    "end": "1138620"
  },
  {
    "text": "So no, the models\nare not trained. Yeah. So [INAUDIBLE]. ",
    "start": "1138620",
    "end": "1157289"
  },
  {
    "text": "No. So this is primarily\nbased on the reference in the data sets, which is-- so\nthis is all accuracy metrics.",
    "start": "1157290",
    "end": "1162860"
  },
  {
    "text": "So we already know between the\nfour options or five options which one is the right one. And so we just do\nthe classification. Yeah.",
    "start": "1162860",
    "end": "1168350"
  },
  {
    "text": "So I'll come back to the\nclinician evaluation a bit later. Sorry, maybe I missed something. How do you measure\nthe uncertainty?",
    "start": "1168350",
    "end": "1175170"
  },
  {
    "text": "So if you know what self\nconsistency prompting, what we do is we generate multiple\ndecodes from the same model",
    "start": "1175170",
    "end": "1181760"
  },
  {
    "text": "and then we see\nthe number of times the highest ranking\nanswer is worded.",
    "start": "1181760",
    "end": "1187315"
  },
  {
    "text": "And based on that, you can\nfix a threshold and say, \"If it's below this number,\nI'm going to differ.\" So if say the majority\nanswer comes up in your self",
    "start": "1187315",
    "end": "1194810"
  },
  {
    "text": "consistency decode only n\ntimes out of k or whatever, then if that n is\ntoo small, then it's",
    "start": "1194810",
    "end": "1200845"
  },
  {
    "text": "very likely the\nmodel's uncertain so that's how we differ. ",
    "start": "1200845",
    "end": "1209556"
  },
  {
    "text": "So you don't really see\na paper on the spot, so it's natural that that's\nwhere the rest of [INAUDIBLE]??",
    "start": "1209556",
    "end": "1217950"
  },
  {
    "text": "I think if you plot it\nfurther, it'll flatline. But again, that's not useful. I mean, if you're saying\nno to every question,",
    "start": "1217950",
    "end": "1223559"
  },
  {
    "text": "that's not useful\nat all so you want to have a reasonable definite\npercentage over here. Yeah, but 0.4 or 0.5 not that--",
    "start": "1223560",
    "end": "1229680"
  },
  {
    "text": "I think that's high. I think that's still\nhigh, 50% is quite high. But again, this is a\nvery contrived setting.",
    "start": "1229680",
    "end": "1236497"
  },
  {
    "text": "But in real world\nuse case is probably I think that number\nshould be much lower. ",
    "start": "1236497",
    "end": "1242970"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "1242970",
    "end": "1259388"
  },
  {
    "text": "That's right. I think balanced accuracy\nmight be a better metric but we looked at some\nof these data sets. And one data set, the\nskew was pretty bad,",
    "start": "1259388",
    "end": "1266260"
  },
  {
    "text": "the PubMedQA data set. And I think no\none should use it. So if anyone's reporting\nnumbers on that data set, you should just distrust them.",
    "start": "1266260",
    "end": "1272710"
  },
  {
    "text": "And I'm talking about\nvery specific people. But again, I think\nas I mentioned,",
    "start": "1272710",
    "end": "1278170"
  },
  {
    "text": "these accuracy metrics are good\nfor publicity and pushing up benchmark numbers and\nso on and so forth. But the real evaluation is human\nevaluation of the long form",
    "start": "1278170",
    "end": "1284770"
  },
  {
    "text": "answers and that's what I'll\ncome to in the next part. ",
    "start": "1284770",
    "end": "1291490"
  },
  {
    "text": "So far so good. I mean, we were getting\nresults on these benchmarks and we were very happy.",
    "start": "1291490",
    "end": "1297140"
  },
  {
    "text": "And so what we did was-- one thing you'll observe that\nI have so far only reported results on multiple choice\nquestions, short form answers.",
    "start": "1297140",
    "end": "1304220"
  },
  {
    "text": "So what was left for us to do\nwas to take these answers-- take these models and\ngenerate long term answers to the other data\nsets that we had",
    "start": "1304220",
    "end": "1310390"
  },
  {
    "text": "and get them human evaluated. And I think that is where\nthe real project began.",
    "start": "1310390",
    "end": "1316150"
  },
  {
    "text": "When we looked at the evals\nby experts and laypeople,",
    "start": "1316150",
    "end": "1322780"
  },
  {
    "text": "it revealed very key\ngaps and limitations in the FLAN-PaLM responses. We are often seeing\nthat these models",
    "start": "1322780",
    "end": "1328929"
  },
  {
    "text": "were hallucinating or\nproducing incomplete responses. And when we asked experts\nwhether they preferred",
    "start": "1328930",
    "end": "1334278"
  },
  {
    "text": "clinician generated answers or\nthese model generated answers, they almost always preferred\nclinician generated answers.",
    "start": "1334278",
    "end": "1341259"
  },
  {
    "text": "So it was very clear that-- Sorry, I didn't\ncatch this earlier, but [INAUDIBLE] evaluators.",
    "start": "1341260",
    "end": "1346870"
  },
  {
    "text": "Are these laypeople or these-- They're both. OK.",
    "start": "1346870",
    "end": "1352250"
  },
  {
    "text": "And so what these\nprevious results showed was while\nthese models already encode some degree of\nclinical knowledge,",
    "start": "1352250",
    "end": "1358630"
  },
  {
    "text": "to be really used in\nactual real world settings, you need to align\nthese models better to the safety\ncritical requirements",
    "start": "1358630",
    "end": "1363700"
  },
  {
    "text": "of the medical domain. But a big challenge\nis we did not have any kind of\nsupervised or feedback data",
    "start": "1363700",
    "end": "1369310"
  },
  {
    "text": "and so we really need\nthe alignment technique to be data efficient. But thankfully,\nwe had instruction",
    "start": "1369310",
    "end": "1375610"
  },
  {
    "text": "from tuning which was\nintroduced by Brian Lester and a few others at\nGoogle a couple of years back.",
    "start": "1375610",
    "end": "1381130"
  },
  {
    "text": "And how this method\nworks is it essentially freezes the big LLM\nmodel and only learns",
    "start": "1381130",
    "end": "1388809"
  },
  {
    "text": "an additional small\nset of prompt vectors which can then be\nused to condition",
    "start": "1388810",
    "end": "1393910"
  },
  {
    "text": "the model that inference\nwhen doing the generation. And the nice thing\nabout this is it allows very easy use of the\nmodel across tasks and domains.",
    "start": "1393910",
    "end": "1403660"
  },
  {
    "text": "And you only need to carry\naround these additional prompt parameters. And these tend to\nbe much smaller",
    "start": "1403660",
    "end": "1409780"
  },
  {
    "text": "than the billions of parameters\nthat you have in the LLM. And the other good thing is\nthis is very computationally",
    "start": "1409780",
    "end": "1417010"
  },
  {
    "text": "efficient as well. So if you were to do\nenter in fine tuning, often in our compute\ninfrastructure, even with like a few\nthousand examples,",
    "start": "1417010",
    "end": "1423460"
  },
  {
    "text": "that would take like a few days. Whereas with instruction\nfrom tuning, given the data set size\nhas also reduced,",
    "start": "1423460",
    "end": "1429580"
  },
  {
    "text": "the number of examples that\nyou need is quite small. And B, you're just updating\nthe prompt token vectors.",
    "start": "1429580",
    "end": "1434885"
  },
  {
    "text": "It meant that we were\nable to get model updates in like a few hours. And so that was really fast and\nenabled really quick iterations",
    "start": "1434885",
    "end": "1440590"
  },
  {
    "text": "for us. So this was how we put together\nthe final Med-PaLM model.",
    "start": "1440590",
    "end": "1446440"
  },
  {
    "text": "We-- sorry, go ahead. Sorry. I'll let you finish. [INAUDIBLE] OK, cool.",
    "start": "1446440",
    "end": "1452200"
  },
  {
    "text": "So this was how we put together\nthe final Med-PaLM model. So we used instructions\nand exemplars from a panel of\nexpert clinicians.",
    "start": "1452200",
    "end": "1459280"
  },
  {
    "text": "And these are in the order\nof hundreds, not thousands and tens of thousands and you\nsee a few examples over there.",
    "start": "1459280",
    "end": "1464770"
  },
  {
    "text": "There's an instruction,\nfollowed by a model answer, followed by an explanation. And we use that to learn\nthe prompt practice.",
    "start": "1464770",
    "end": "1471050"
  },
  {
    "text": "And so the final Med-PaLM model\nis basically all of FLAN-PaLM plus these additional\nprompt vector parameters",
    "start": "1471050",
    "end": "1478012"
  },
  {
    "text": "which are used to align the\nmodel to the requirements of the medical domain. And why this works well is\nbecause as we have seen before,",
    "start": "1478012",
    "end": "1483537"
  },
  {
    "text": "the model already has medical\nknowledge encoded in it. All we need is to\nteach the model how to use it properly in\nthe given application setting",
    "start": "1483537",
    "end": "1489610"
  },
  {
    "text": "and that's what these\nparameters do for us. So the question I wanted\nto ask is, nowadays",
    "start": "1489610",
    "end": "1496390"
  },
  {
    "text": "you've probably seen a\nlot about online chat. And given the fact that you have\nall of these human preferences expressed by your\nmoderators, can",
    "start": "1496390",
    "end": "1502880"
  },
  {
    "text": "you guys explain how you guys\ndefine a reward or preference",
    "start": "1502880",
    "end": "1508000"
  },
  {
    "text": "model and it was not\nconfined to [INAUDIBLE].. Yeah. I think you can think about\ndifferent stages of model",
    "start": "1508000",
    "end": "1513898"
  },
  {
    "text": "development. So this is pre-deployment and\nrelease in the real world. So you can't put a crappy model\nout there in the real world.",
    "start": "1513898",
    "end": "1520490"
  },
  {
    "text": "So even before doing that,\nif you can get like maybe 100 examples from whatever exploits\nthat you can get hold of",
    "start": "1520490",
    "end": "1525730"
  },
  {
    "text": "and use that to prompt you\nin your model, that's better. That's a much better\nstarting point before you expose the\nmodel to the real world and collect preferences\nfrom real users at scale.",
    "start": "1525730",
    "end": "1533000"
  },
  {
    "text": "And so I think RLHF is also much\nless sample efficient compared to the instruction\nfrom tuning, again,",
    "start": "1533000",
    "end": "1539260"
  },
  {
    "text": "because you're probably trying\nto update your entire model as well. So I think this is a\nvery good starting point.",
    "start": "1539260",
    "end": "1544610"
  },
  {
    "text": "And so they can both\nbe combined depending on how depending on the\nlifecycle of the model. From your evaluations, are\nyour evaluations public?",
    "start": "1544610",
    "end": "1551610"
  },
  {
    "text": " The data set is public. I'll talk about the\nresults in a bit.",
    "start": "1551610",
    "end": "1558019"
  },
  {
    "text": "Sorry. I mean, human evaluations\ncontain publicly within the data set.",
    "start": "1558020",
    "end": "1563700"
  },
  {
    "text": "You mean the model responses\nand what the humans-- Human evaluations-- That's a good point.",
    "start": "1563700",
    "end": "1569160"
  },
  {
    "text": "So far not considering\nreleasing them but maybe we can. OK. Do you see a use case for that?",
    "start": "1569160",
    "end": "1574790"
  },
  {
    "text": "Well, just I was thinking\nyou had a bunch of data in the preferences. You frame the model to\nexpress those preferences",
    "start": "1574790",
    "end": "1581159"
  },
  {
    "text": "and use that [INAUDIBLE]. So if I wanted to\ntrain a word model, that data is what I would need\nto train that real world model.",
    "start": "1581160",
    "end": "1588330"
  },
  {
    "text": "Yeah, that's a good point. I think the evaluation\ndata set is-- I'll talk about\nthis a bit later. It's still small. But I think if we scale it up,\nand we are doing it right now,",
    "start": "1588330",
    "end": "1594810"
  },
  {
    "text": "I think we can\nrelease that and that will be I think a good resource\nof what you're trying to do. Cool.",
    "start": "1594810",
    "end": "1600610"
  },
  {
    "start": "1599000",
    "end": "1895000"
  },
  {
    "text": "So if you had the Med-PaLM\nmodel as I said and now we took the long form\nanswers from it and compared that to\nthe FLAN-PaLM model",
    "start": "1600610",
    "end": "1606580"
  },
  {
    "text": "as well as to answers\ngenerated by expert clinicians, and as I said, we have two\nparts to the human evaluation.",
    "start": "1606580",
    "end": "1611890"
  },
  {
    "text": "One is by expert conditions and\nthe other one is by lay users. And so what do these\nresults look like?",
    "start": "1611890",
    "end": "1618100"
  },
  {
    "text": "On the 140-odd questions that\nwe got these evaluation results on, what we observed typically\nacross the board was,",
    "start": "1618100",
    "end": "1627670"
  },
  {
    "text": "when we looked at\ndifferent axes, while the FLAN-PaLM model would\nbe quite terrible honestly,",
    "start": "1627670",
    "end": "1632770"
  },
  {
    "text": "the Med-PaLM model would do\nmuch better and typically close the gap to expert clinicians. So on this axis, you see\nthat the FLAN-PaLM model",
    "start": "1632770",
    "end": "1640000"
  },
  {
    "text": "has probably a 60% accuracy in\nterms of scientific consensus.",
    "start": "1640000",
    "end": "1646600"
  },
  {
    "text": "The Med-PaLM palm model\nimproves and improves on that quite a bit\nand closes the gap to clinicians over here.",
    "start": "1646600",
    "end": "1652630"
  },
  {
    "text": "Similar story on\nother axes as well. Over here you see\nthe clinicians rating",
    "start": "1652630",
    "end": "1658720"
  },
  {
    "text": "on the axes of how\nwell the model can retrieve medical knowledge, how\nwell it can reason about it.",
    "start": "1658720",
    "end": "1664660"
  },
  {
    "text": "And again, we see the same\ntrend as in the previous slide. Sorry to interrupt.",
    "start": "1664660",
    "end": "1670200"
  },
  {
    "text": "Yeah. So the left call on the\nleft is correct [INAUDIBLE]..",
    "start": "1670200",
    "end": "1676010"
  },
  {
    "text": "So it's evidence of correct\ncomprehension and the right-- On the right-hand\nside, it's incorrect, so I think it needs\nto be 1 minus.",
    "start": "1676010",
    "end": "1682540"
  },
  {
    "text": "No. So both can be present\nat the same time. So you can have evidence of\ncorrect comprehension, also",
    "start": "1682540",
    "end": "1687820"
  },
  {
    "text": "evidence of incorrect\ncomprehension. Sometimes you-- [INAUDIBLE] Exactly.",
    "start": "1687820",
    "end": "1693640"
  },
  {
    "text": "So that's why they're\nnot 1 minus so here. I see. But the trends are the same. That's why I skipped it\nbut that's a good point.",
    "start": "1693640",
    "end": "1700150"
  },
  {
    "text": " Yeah. So there's a typo over\nhere but this one pertains",
    "start": "1700150",
    "end": "1706940"
  },
  {
    "text": "to incorrect or missing content. But this was an interesting\none because what--",
    "start": "1706940",
    "end": "1712820"
  },
  {
    "text": "when we were doing\nthis from tuning thing, was we were teaching the\nMed-PaLM model to produce",
    "start": "1712820",
    "end": "1718670"
  },
  {
    "text": "longer and more competencies. And so you'd see a few\nqualitative examples later. But what ended up happening\nthe process was sometimes",
    "start": "1718670",
    "end": "1724688"
  },
  {
    "text": "the model was maybe producing\nmore incorrect information. So that's why you see that\nmaybe in this particular axis,",
    "start": "1724688",
    "end": "1730215"
  },
  {
    "text": "the FLAN-PaLM model\nwas slightly better but again, this was much\nworse compared to clinicians.",
    "start": "1730215",
    "end": "1735559"
  },
  {
    "text": "Well, what does that\neven mean [INAUDIBLE]?? It's a good question.",
    "start": "1735560",
    "end": "1741790"
  },
  {
    "text": "It is more like it's something\ncompletely out of context. So it may be irrelevant\nto the question.",
    "start": "1741790",
    "end": "1748365"
  },
  {
    "text": "So that's where\nI would say it's. ",
    "start": "1748365",
    "end": "1756150"
  },
  {
    "text": "We also looked at possible and\nextent and likelihood of harm. And again, we see that with\nthe instruction from tuning,",
    "start": "1756150",
    "end": "1762450"
  },
  {
    "text": "we're able to close the gap to\nexpert clinicians over here. Same on the bias axis as well.",
    "start": "1762450",
    "end": "1767864"
  },
  {
    "text": "Can you go back? Sure. How do you interpret\nthe top, exactly?",
    "start": "1767864",
    "end": "1774639"
  },
  {
    "text": "So I basically see a big gap\nin the clinicians that 6%",
    "start": "1774640",
    "end": "1780510"
  },
  {
    "text": "[INAUDIBLE] how to clarify\nexactly what that means? ",
    "start": "1780510",
    "end": "1787720"
  },
  {
    "text": "Yeah. So there might be certain\nconditions or pathologies or diagnosis like cancer.",
    "start": "1787720",
    "end": "1794620"
  },
  {
    "text": "And if for example, the\nclinician has not caught that or has maybe given a response\nthat does not appropriately",
    "start": "1794620",
    "end": "1803020"
  },
  {
    "text": "convey the severity\nof the condition, then that could potentially\nlead to severe harm or death. And so that's what we were\ntrying to capture with here.",
    "start": "1803020",
    "end": "1810170"
  },
  {
    "text": "So that's a very\nhigh level overview. This is I think a\nvery nuanced topic",
    "start": "1810170",
    "end": "1815650"
  },
  {
    "text": "and there's a framework for\nit called the AHRQ framework. And so we've linked that\nin the paper as well.",
    "start": "1815650",
    "end": "1821450"
  },
  {
    "text": "And so I think that gives\nyou a very detailed notion of harm and bias. So I would defer to that. But at a high level, this\nis what I'm talking about.",
    "start": "1821450",
    "end": "1828117"
  },
  {
    "text": "Hope that helps. All right. So when later I read plus and\nI say the [INAUDIBLE] possible",
    "start": "1828117",
    "end": "1835660"
  },
  {
    "text": "harm, which means-- what would I say? Does that mean that\nthey recommend something that could kill the patient?",
    "start": "1835660",
    "end": "1842200"
  },
  {
    "text": "Maybe they fail to\nrecommend something. But they fail. Yeah. So it's basically a\nmisdiagnosis or maybe",
    "start": "1842200",
    "end": "1847660"
  },
  {
    "text": "failing to capture the\nseverity of a diagnosis. This is typical in life\nthreatening conditions. ",
    "start": "1847660",
    "end": "1855172"
  },
  {
    "text": "So it's more often\nthan not, not mistakes but rather just\nmissing out on details. ",
    "start": "1855172",
    "end": "1863360"
  },
  {
    "text": "Yes. So I talked about bias as well. And then, as I said, the\nother axis of human evaluation",
    "start": "1863360",
    "end": "1868610"
  },
  {
    "text": "was with lay users. And so we asked them how\nwell does the model address",
    "start": "1868610",
    "end": "1874550"
  },
  {
    "text": "the intent of the question? And again, we saw\nwith instruction from tuning Med-PaLM closing\nthe gap to clinicians.",
    "start": "1874550",
    "end": "1879889"
  },
  {
    "text": "And then we asked them how\nhelpful their responses were, and what we see is that\nwhile FLAN-PaLM responses are",
    "start": "1879890",
    "end": "1886553"
  },
  {
    "text": "considered to be helpful\nlike 60% of the time, the number improved\nto 80% for Med-PaLM but it was still fairly lower\ncompared to clinicians at 90%.",
    "start": "1886553",
    "end": "1893270"
  },
  {
    "text": " So here are a few\nqualitative examples. And so what you see\nis that physicians,",
    "start": "1893270",
    "end": "1899608"
  },
  {
    "start": "1895000",
    "end": "1999000"
  },
  {
    "text": "and this is typically because\nthey work in a time constrained settings, their answers tend\nto be precise and succinct.",
    "start": "1899608",
    "end": "1908030"
  },
  {
    "text": "But sometimes it's very hard\nas lay users or patients to decipher and\ndecode the answer and get all the\nfull set of details.",
    "start": "1908030",
    "end": "1914180"
  },
  {
    "text": "And so what I think language\nmodels like Med-PaLM can help with is actually\nconverting the physician speak to something that's more\neasily digestible by lay users.",
    "start": "1914180",
    "end": "1921870"
  },
  {
    "text": "And so this is where I think\nhow these models will likely fit in clinical settings\nin the near-term.",
    "start": "1921870",
    "end": "1926961"
  },
  {
    "text": "Where they're going\nto augment physicians in terms of interacting with\npatients and other physicians and researchers as well.",
    "start": "1926962",
    "end": "1932660"
  },
  {
    "text": " Sorry, go ahead.",
    "start": "1932660",
    "end": "1938075"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "1938076",
    "end": "1956788"
  },
  {
    "text": "That's right. I think it's subjective. And so that's why I think we're\nstill seeing lay users plan",
    "start": "1956788",
    "end": "1962130"
  },
  {
    "text": "performances to be helpful 80%. Well, that's much\nhigher for physicians. So it's not perfect\nby any means but I",
    "start": "1962130",
    "end": "1967320"
  },
  {
    "text": "think this is where there is\na complementarity element we feel over here. And we've asked that.",
    "start": "1967320",
    "end": "1973670"
  },
  {
    "text": "When we ask people like, \"How\neasy is it to interpret doctor notes or recommendations?\"",
    "start": "1973670",
    "end": "1979503"
  },
  {
    "text": "And they often say,\n\"Oh, it's very hard. I need to go back to Google. Search for what\nthese terms mean, what these abbreviations mean.\"",
    "start": "1979503",
    "end": "1985010"
  },
  {
    "text": "And so I think this is\nwhere a language model can come and take that note and\nconvert that into something that's more easily digestible.",
    "start": "1985010",
    "end": "1991543"
  },
  {
    "text": "So I think that's the\nopportunity over here, I feel. ",
    "start": "1991543",
    "end": "1999750"
  },
  {
    "start": "1999000",
    "end": "2074000"
  },
  {
    "text": "So that was all on\nour paper but I also want to make very quickly\npoint out a very recent work, which came out last week with\nthis rather provocative title,",
    "start": "1999750",
    "end": "2007445"
  },
  {
    "text": "\"Do we still need to\nmake a language models?\" And by clinical\nlanguage models, they meant smaller models\nwhich are trained",
    "start": "2007445",
    "end": "2014510"
  },
  {
    "text": "in domain with clinical\ndata such as medical notes and records and so\non and so forth.",
    "start": "2014510",
    "end": "2021059"
  },
  {
    "text": "And what this paper\nbasically suggests is that smaller fine\ntuned in domain LMs",
    "start": "2021060",
    "end": "2026330"
  },
  {
    "text": "are likely better than\ngeneral purpose LLMs. In this paper, I think\nthey evaluated in GPT 3",
    "start": "2026330",
    "end": "2032000"
  },
  {
    "text": "with in context learning. So I think that's a pretty\ninteresting and neat observation. I think there's a lot\nof value for smaller",
    "start": "2032000",
    "end": "2038404"
  },
  {
    "text": "in-domains such as PubMed,\nGPT, and a few other variants. But I think one thing that\nthis paper does not do",
    "start": "2038405",
    "end": "2044450"
  },
  {
    "text": "is consider in\ncontext learning-- sorry, prompt tuning. And I think that's where some\nof the benefits of this larger",
    "start": "2044450",
    "end": "2050239"
  },
  {
    "text": "general purpose LLMs shine. And again, we haven't done\nany in-domain LM pre-training",
    "start": "2050239",
    "end": "2059120"
  },
  {
    "text": "on these large general\npurpose models. But that's again,\nan option for us as well to do it on the links.",
    "start": "2059120",
    "end": "2064407"
  },
  {
    "text": "So you can take these\n40 billion parameters and then still turn it on\nmedical notes or whatever domain specific data\nthat you can get hold of",
    "start": "2064407",
    "end": "2069710"
  },
  {
    "text": "and hopefully that'll\nprobably further improve the performance. So key takeaways so far.",
    "start": "2069710",
    "end": "2077530"
  },
  {
    "start": "2074000",
    "end": "2379000"
  },
  {
    "text": "What I wanted to convey\nwas general purpose LLMs. It looks like they do\nencode medical knowledge and performance on\nmedical reasoning",
    "start": "2077530",
    "end": "2084250"
  },
  {
    "text": "does seem to improve with scale. However, these\nmodels I don't think can be directly used out of\nthe box in clinical settings",
    "start": "2084250",
    "end": "2090333"
  },
  {
    "text": "and they need to be\naligned with the safety critical requirements\nof the medical domain. And I think instruction\nprompt tuning",
    "start": "2090333",
    "end": "2096850"
  },
  {
    "text": "is an extremely\nefficient technique, both on the data side and\nalso on the compute side. And we should probably use\nit more often depending on--",
    "start": "2096850",
    "end": "2103599"
  },
  {
    "text": "and hopefully the API starts\nsupporting it as well. And these models appear\nto be closing the gap",
    "start": "2103600",
    "end": "2109300"
  },
  {
    "text": "to expert clinicians, at least\non this medical questions and answering tasks. And while this is\nhugely exciting",
    "start": "2109300",
    "end": "2115540"
  },
  {
    "text": "and has profound\nimplications, you can all probably dream up\nand imagine the application scenarios over here.",
    "start": "2115540",
    "end": "2120550"
  },
  {
    "text": "I think comprehensive benchmarks\nand evaluation frameworks are necessary in order to\nfurther assess and improve",
    "start": "2120550",
    "end": "2126700"
  },
  {
    "text": "these models for\nreal world use cases. So I'll stop over here. Any questions?",
    "start": "2126700",
    "end": "2132130"
  },
  {
    "start": "2132130",
    "end": "2137170"
  },
  {
    "text": "Why do you think the\nmedicine [INAUDIBLE]?? ",
    "start": "2137170",
    "end": "2145030"
  },
  {
    "text": "I think-- [INAUDIBLE] A lot of it is because\nthese data sets",
    "start": "2145030",
    "end": "2150690"
  },
  {
    "text": "tend to get locked\nin silos with privacy and other kinds of\nregulations which prevent them from being put out\nthere in the real world.",
    "start": "2150690",
    "end": "2157462"
  },
  {
    "text": "So you have to have HIPAA\ncompliant systems for storage and so on and so forth. So it's very difficult to\nget data out of these silos",
    "start": "2157462",
    "end": "2163560"
  },
  {
    "text": "and put together\nan open benchmark. So honestly, I feel\nlike that's probably not",
    "start": "2163560",
    "end": "2169290"
  },
  {
    "text": "going to improve the\nskill of these data sets. At least the open version\nof these data sets are going to remain quite\nsmall compared to the big LLM",
    "start": "2169290",
    "end": "2177694"
  },
  {
    "text": "training data sets or the\ncomputer vision data sets on actual images and\nso on and so forth. But what may happen\nin the future",
    "start": "2177695",
    "end": "2183270"
  },
  {
    "text": "is we may have more distributed\nfederated evaluation settings where you take the model\ninto these private silos",
    "start": "2183270",
    "end": "2190770"
  },
  {
    "text": "and get them evaluated on\nso they are never exposed and put out there in the public. But rather, we can have these\nfederated evaluation settings.",
    "start": "2190770",
    "end": "2197237"
  },
  {
    "text": "So I think that there's\nsome work on that already. There's a system\ncalled [INAUDIBLE],, and we'll probably\nsee more of them.",
    "start": "2197237",
    "end": "2202660"
  },
  {
    "text": "Can you repeat the question? [INAUDIBLE] Sure.",
    "start": "2202660",
    "end": "2208410"
  },
  {
    "text": "So the question over here\nwas why medical data sets are smaller compared to\nnatural image data",
    "start": "2208410",
    "end": "2215510"
  },
  {
    "text": "sets in computer vision\nor LLM training data sets and so on and so forth. What do you think are\nsome of the earliest",
    "start": "2215510",
    "end": "2221710"
  },
  {
    "text": "applications of medical\nLLMs deployed in industry?",
    "start": "2221710",
    "end": "2228273"
  },
  {
    "text": "I think the first\nset of use cases are probably going to\nbe not diagnostic in it. Sorry. The question was,\nwhat do you think",
    "start": "2228273",
    "end": "2235300"
  },
  {
    "text": "are the use cases of medical\nLLMs and medical industry settings? And so the answer is I think the\nfirst set of use cases that we",
    "start": "2235300",
    "end": "2242260"
  },
  {
    "text": "are going to see are probably\ngoing to be non diagnostic in nature but more around, if a\npatient comes in and interacts",
    "start": "2242260",
    "end": "2249430"
  },
  {
    "text": "with a doctor, can you\ngenerate summary notes? And can you do workflow tasks\nsuch as generating letters",
    "start": "2249430",
    "end": "2257230"
  },
  {
    "text": "for insurance, for\nmedications, for reference, and so on and so forth? I think these stats are right\nup the alley of large language",
    "start": "2257230",
    "end": "2263440"
  },
  {
    "text": "models. And I think if not already, in\nthe next six months to a year we'll see a lot of these\nuse cases coming up. And I think that's going to make\ndoctors' life, care providers'",
    "start": "2263440",
    "end": "2270955"
  },
  {
    "text": "life much easier because\nright now, they're spending a lot of time\ndoing these things and not actually providing care\nand attending to the patient.",
    "start": "2270955",
    "end": "2278318"
  },
  {
    "text": "Diagnostic use cases I think\nwill take a lot more time. We need a lot more evaluation. The data sets, as we can\nsee, are probably not there.",
    "start": "2278318",
    "end": "2283750"
  },
  {
    "text": "The evaluation\nframeworks are not there. But I think in the\nlong run, and that is the dream setting, right?",
    "start": "2283750",
    "end": "2289180"
  },
  {
    "text": "And then maybe a follow up. I'm assuming Medcom\nis not open source.",
    "start": "2289180",
    "end": "2294609"
  },
  {
    "text": "What do you think\nthe best open source model is for medical data?",
    "start": "2294610",
    "end": "2300770"
  },
  {
    "text": "I think it depends on\nthe-- so the question is, what is the best open\nsource model for medical data?",
    "start": "2300770",
    "end": "2307490"
  },
  {
    "text": "I think depends on the\nevaluation setting. So I think the PubMed GPT model\nfrom the Stanford foundation",
    "start": "2307490",
    "end": "2314790"
  },
  {
    "text": "group is quite strong. I think GPT 3 or 3.5\nor whatever variant if you can bring in some\ndomain specific medical data",
    "start": "2314790",
    "end": "2321560"
  },
  {
    "text": "and do some in-domain tuning,\nI think that model can also improve quite a bit. So I think those two would be\nmy favorite starting points",
    "start": "2321560",
    "end": "2326990"
  },
  {
    "text": "over here.  So you're saying part\nof the [INAUDIBLE]??",
    "start": "2326990",
    "end": "2333680"
  },
  {
    "start": "2333680",
    "end": "2339290"
  },
  {
    "text": "You can just think them\nas vectors corresponding to a few additional tokens. So it's not really\nhuman legible.",
    "start": "2339290",
    "end": "2346579"
  },
  {
    "text": "So the question was, what do the\nsoft prompt vectors look like and are they human legible?",
    "start": "2346580",
    "end": "2352010"
  },
  {
    "text": "And the answer is\nno, they're not. Just a follow up. You said [INAUDIBLE]\nDo you really",
    "start": "2352010",
    "end": "2368934"
  },
  {
    "text": "believe that [INAUDIBLE]\non-site hardware, on-site made by all of the teams that can\ntake these models [INAUDIBLE]??",
    "start": "2368934",
    "end": "2378480"
  },
  {
    "text": "Sure. So the question was, given\na lot of the hospital systems and providers\nnetworks are quite low tech",
    "start": "2378480",
    "end": "2386940"
  },
  {
    "start": "2379000",
    "end": "2879000"
  },
  {
    "text": "and don't have good\nenough hardware, do you really think\nfederated learning could be used for distributed\ntraining of large scale LLMs?",
    "start": "2386940",
    "end": "2394560"
  },
  {
    "text": "I think we are increasingly\nseeing a trend towards cloud. And so a lot of these\nhospital systems",
    "start": "2394560",
    "end": "2400890"
  },
  {
    "text": "are moving their\nstorage and data and compute to standard\ncloud providers like AWS or Azure\nor Google Cloud.",
    "start": "2400890",
    "end": "2408690"
  },
  {
    "text": "And so I think that helps\nbecause these systems on the backend side\ndo have the compute to be able to train\nthese kind of models.",
    "start": "2408690",
    "end": "2416360"
  },
  {
    "text": "I think it's going to be\na very gradual process. So systems that have high\nquality infrastructure, probably we're going to\nstart with that first",
    "start": "2416360",
    "end": "2423210"
  },
  {
    "text": "and then gradually work\nour way into the long tail. But it also feels like\nsomething that will inevitably",
    "start": "2423210",
    "end": "2428880"
  },
  {
    "text": "exist in the world. So 10 years down the line\nor 15 years down the line when we have these\ndistributed large scale",
    "start": "2428880",
    "end": "2434040"
  },
  {
    "text": "LLM training systems,\nwe'll always think back, \"Why did I even doubt\nthat this will not exist?\"",
    "start": "2434040",
    "end": "2439973"
  },
  {
    "text": "It's so obvious. It's something that has\nto exist because that's where all the patient data is,\nall the interesting data is, right? So I think that\nwill just happen.",
    "start": "2439973",
    "end": "2446170"
  },
  {
    "text": "It's just not clear\nwhether that's going to be done by one\ncompany, whether that's going to be done by a consortium\nof academic or industry groups,",
    "start": "2446170",
    "end": "2452347"
  },
  {
    "text": "or whether governments\nare going to be involved or so on and so forth. It's interesting. You mentioned cloud computing.",
    "start": "2452347",
    "end": "2458170"
  },
  {
    "text": "It's actually-- you say\nwe're doing it better. But we're still uploading\nthe data, probably the same warehouse.",
    "start": "2458170",
    "end": "2465190"
  },
  {
    "text": "That's right. So the question over here is\nwe're seeing cloud computing but we are pretty much uploading\nthe data to the same warehouse.",
    "start": "2465190",
    "end": "2473290"
  },
  {
    "text": "The answer is true. But again, I think\nthese are all going to be separate buckets with\ntheir own access controls",
    "start": "2473290",
    "end": "2478792"
  },
  {
    "text": "and so on and so forth. So that is how you can\ndifferentiate between them. ",
    "start": "2478792",
    "end": "2486480"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "2486480",
    "end": "2503280"
  },
  {
    "text": "It doesn't seem like that's\nreally present in the datasets that we're [INAUDIBLE]. ",
    "start": "2503280",
    "end": "2511740"
  },
  {
    "text": "Sure. So the question\nwas, has there been any studies in Medcom looking\nat private information in these data sets?",
    "start": "2511740",
    "end": "2517650"
  },
  {
    "text": "And the short answer is no. One of the criteria\nfor selecting the data sets that\nwe used in the study",
    "start": "2517650",
    "end": "2522869"
  },
  {
    "text": "was to not include any kind of\npersonally identifiable data or clinical data of that sort. And that helped get\nthis paper out on time.",
    "start": "2522870",
    "end": "2529950"
  },
  {
    "text": "But I think that's\nan important point. It's unlikely that we're going\nto have a lot of PHI data",
    "start": "2529950",
    "end": "2536559"
  },
  {
    "text": "in the public data sets\nthat we are training on. But even when you're training\non say one private corpus",
    "start": "2536560",
    "end": "2543720"
  },
  {
    "text": "and then you're using it in\nanother application setting, you want to ensure\nthat the model does not leak out any kind of PHI\ninformation during a situation.",
    "start": "2543720",
    "end": "2551002"
  },
  {
    "text": "So I think those sort of\nstudies are necessary. We haven't got into them yet. [INAUDIBLE]",
    "start": "2551002",
    "end": "2556150"
  },
  {
    "start": "2556150",
    "end": "2567680"
  },
  {
    "text": "So the question is,\nwhat are the next steps in terms of improving\nthese models further? Yeah, retrieval is a\nvery important one.",
    "start": "2567680",
    "end": "2575020"
  },
  {
    "text": "Being able to cite\nsources and especially take in authoritative\nsources and use that in generating the answers\nand also communicating that",
    "start": "2575020",
    "end": "2582040"
  },
  {
    "text": "to the users is very important. I think how you communicate\nuncertainty is very important.",
    "start": "2582040",
    "end": "2587510"
  },
  {
    "text": "So we've gotten to some extent\nusing instruction from tuning, but I think that can\nbe much, much better.",
    "start": "2587510",
    "end": "2593300"
  },
  {
    "text": "So I think that's\nanother big bucket. Again, I would stress\non the evaluation side",
    "start": "2593300",
    "end": "2598510"
  },
  {
    "text": "like looking at more data\nsets, which for example may do Q&A on health records or\nother kinds of medical data.",
    "start": "2598510",
    "end": "2605517"
  },
  {
    "text": "I think that would be important. And also extending\nthe evaluation would in terms of scale,\nhaving a diverse panel",
    "start": "2605517",
    "end": "2611380"
  },
  {
    "text": "of clinicians vote,\nand also in terms of the data that you're using. Maybe adversarial\nmodifying the questions to include demographic\nconfounders or something",
    "start": "2611380",
    "end": "2618620"
  },
  {
    "text": "like that. I think those are all could\nbe interesting directions. I think on the modeling side,\nthe interesting question",
    "start": "2618620",
    "end": "2624550"
  },
  {
    "text": "for me is again, this interplay\nbetween smaller domain specific LMs versus\nlarger purpose LLMs",
    "start": "2624550",
    "end": "2631869"
  },
  {
    "text": "and how that's\ngoing to play out. There seems to be some evidence\nof emergence over here,",
    "start": "2631870",
    "end": "2638200"
  },
  {
    "text": "especially with\nmedical reasoning. And so as you can\nsee, at lower scale, sometimes the performance\nis not good enough.",
    "start": "2638200",
    "end": "2644500"
  },
  {
    "text": "I mean, 50%, that's\na good number but that's just not viable. But when you get to 80%\nor 90%, the products",
    "start": "2644500",
    "end": "2650470"
  },
  {
    "text": "really become useful. And so we are seeing at bigger\nparameter sizes of these models",
    "start": "2650470",
    "end": "2655690"
  },
  {
    "text": "but I don't know. I think it's still an\nopen question we're here. [INAUDIBLE]",
    "start": "2655690",
    "end": "2662270"
  },
  {
    "text": "Yeah. The question was, is\nhallucination an issue? I think it still is but I\nbelieve that you can control",
    "start": "2662270",
    "end": "2669410"
  },
  {
    "text": "that fairly well\nwith instruction from tuning, any kind\nof feedback data. I think it's not\nterribly difficult to do.",
    "start": "2669410",
    "end": "2676920"
  },
  {
    "text": "And so I think it might have\nbeen overblown generally.",
    "start": "2676920",
    "end": "2682016"
  },
  {
    "text": "Especially when you are doing\nit in a particular domain, I think it's easier to control. [INAUDIBLE]",
    "start": "2682017",
    "end": "2687372"
  },
  {
    "start": "2687372",
    "end": "2693950"
  },
  {
    "text": "What it looks like. Say recently, there's been\nreporting about [INAUDIBLE]..",
    "start": "2693950",
    "end": "2700190"
  },
  {
    "start": "2700190",
    "end": "2706069"
  },
  {
    "text": "I'm just curious because\nthis particular app, do you think that's\nvery, very relevant?",
    "start": "2706070",
    "end": "2711410"
  },
  {
    "text": "And [INAUDIBLE] high\nbar, the quality of it. So I'm just curious\nif you're even going to speak out about [INAUDIBLE].",
    "start": "2711410",
    "end": "2719630"
  },
  {
    "text": "Yeah. So the question was, there's\na lot of talk and noise around hallucinations\nand general purpose LLMs.",
    "start": "2719630",
    "end": "2726590"
  },
  {
    "text": "In this particular\napplication domain, it seems particularly relevant. And so can you expand on\nthat a little bit further?",
    "start": "2726590",
    "end": "2733079"
  },
  {
    "text": "Sure. So what we are seeing is even\nwith an order of a few hundred examples from expert\nclinicians, teaching the model",
    "start": "2733080",
    "end": "2740960"
  },
  {
    "text": "how to communicate\nmedical information, that is good enough\nto get the model",
    "start": "2740960",
    "end": "2746900"
  },
  {
    "text": "to maybe stop hallucinating\nor at least communicate its uncertainty in a better way.",
    "start": "2746900",
    "end": "2752570"
  },
  {
    "text": " At least in this particular\ndomain or this setting,",
    "start": "2752570",
    "end": "2757850"
  },
  {
    "text": "it feels more tractable to us. And the reason\nI'm saying this is we've looked at the\nanswers qualitatively",
    "start": "2757850",
    "end": "2762858"
  },
  {
    "text": "and we are seeing that\nthe model does not tend to generate\nsuper long answers or make very\nconfident predictions.",
    "start": "2762858",
    "end": "2771740"
  },
  {
    "text": "But rather, the tone itself\nbecomes very reserved and it starts using\nterms like maybe",
    "start": "2771740",
    "end": "2778513"
  },
  {
    "text": "this needs to be done further\nor something like that which communicates uncertainty. So how well is that\nactually correlated",
    "start": "2778513",
    "end": "2784223"
  },
  {
    "text": "with the representation\nunderlying uncertainty that we have, is still I\nthink an area of research. But I think this is\nalready promising for us",
    "start": "2784223",
    "end": "2791030"
  },
  {
    "text": "that it feels controllable\nin limited application settings like medicine. But if you have\na general purpose",
    "start": "2791030",
    "end": "2796240"
  },
  {
    "text": "LLM I'm trying to answer\npretty much everything about the world, I think\nthat's a much harder problem. ",
    "start": "2796240",
    "end": "2802710"
  },
  {
    "text": "Do you think that would be a\nfeature of the domain data set? In medical situations, doctors\nare more reserved perhaps",
    "start": "2802710",
    "end": "2811260"
  },
  {
    "text": "and don't have\nabsolute [INAUDIBLE]",
    "start": "2811260",
    "end": "2816390"
  },
  {
    "text": "or do you think it's more\nthat you just specialize?",
    "start": "2816390",
    "end": "2822670"
  },
  {
    "text": "It could be something\nelse entirely also, I'm just curious what you think.",
    "start": "2822670",
    "end": "2828579"
  },
  {
    "text": "Yeah, so the question is, do you\nthink the way how the model is",
    "start": "2828580",
    "end": "2834570"
  },
  {
    "text": "performing in this domain is\nthat a feature of the data sets in the medical\ndomain and typically based",
    "start": "2834570",
    "end": "2840925"
  },
  {
    "text": "on how doctors communicate? And I think that's true. And I think that's\nsomething we need to build on and use over here.",
    "start": "2840925",
    "end": "2846198"
  },
  {
    "text": "And I think that's\nextremely helpful. And hopefully this kind of\nbehavior is general enough and can be transmitted\nto the model",
    "start": "2846198",
    "end": "2853080"
  },
  {
    "text": "even when it's used in\nnon-medical settings to be more reserved\nwhen it's communicating,",
    "start": "2853080",
    "end": "2859391"
  },
  {
    "text": "hallucinate less, and\nso on and so forth. So I believe that that's one\nof the opportunities over here, to use these benchmarks\ncome up with methods",
    "start": "2859392",
    "end": "2865500"
  },
  {
    "text": "that reduce hallucination,\ncommunicate uncertainty better. And then use that as a\nbidirectional learning opportunity to improve the\ngeneral purpose LLM as well.",
    "start": "2865500",
    "end": "2874027"
  },
  {
    "text": "So if you have any\nfurther questions, I'll come back again\nat the end of the talk but I want to cover the rest\nof the applications as well.",
    "start": "2874028",
    "end": "2880850"
  },
  {
    "start": "2879000",
    "end": "3203000"
  },
  {
    "text": "So the next domain I want\nto talk about is proteins. And the papers\nfrom now I'm going",
    "start": "2880850",
    "end": "2887410"
  },
  {
    "text": "to zip through them a\nlittle bit given time. But the first one I want\nto talk is this paper",
    "start": "2887410",
    "end": "2894910"
  },
  {
    "text": "from a few folks at Google\nResearch back in 2020, called \"Masked Language\nModeling for Proteins via Linearly Scalable\nLong-Context Transformers.\"",
    "start": "2894910",
    "end": "2904160"
  },
  {
    "text": "So the problem here\nis that modeling long range biological sequences\nrequires efficient transformer",
    "start": "2904160",
    "end": "2909680"
  },
  {
    "text": "architectures. And so in this particular\npaper, what they introduced was this performance\narchitecture",
    "start": "2909680",
    "end": "2916430"
  },
  {
    "text": "which approximates the SOC max\nattention kernel via low rank decomposition.",
    "start": "2916430",
    "end": "2921960"
  },
  {
    "text": "And so this does not incorporate\nany sparsity priors say like other methods\nlike the Reformer",
    "start": "2921960",
    "end": "2928549"
  },
  {
    "text": "or there are many others. And this is good because\nsparsity priors may not",
    "start": "2928550",
    "end": "2934520"
  },
  {
    "text": "be appropriate for biological\ndata such as protein which required global\ninteractions to be modeled.",
    "start": "2934520",
    "end": "2941210"
  },
  {
    "text": "And then the other thing is this\nmodel, the performance scales linearly rather than quadraticly\nwith the sequence length L.",
    "start": "2941210",
    "end": "2947750"
  },
  {
    "text": "And the number of\nrandom features that you need to approximate\nthis SOC max attention kernel m, is completely independent\nof the input sequence length.",
    "start": "2947750",
    "end": "2956180"
  },
  {
    "text": "So just to very\nquickly visualize the speed ups and the space\ncomplexity improvements. What you are having\nwith this loading",
    "start": "2956180",
    "end": "2962172"
  },
  {
    "text": "decomposition is instead of\nhaving fat matrices in your SOC max attention kernel, you\nnow have thinner matrices",
    "start": "2962172",
    "end": "2967640"
  },
  {
    "text": "which are determined by the\nsize of the random features. And that basically reduces\nyour quadratic complexity",
    "start": "2967640",
    "end": "2973870"
  },
  {
    "text": "to something that is\nmore linear in nature and also leads to\nspace improvements.",
    "start": "2973870",
    "end": "2979550"
  },
  {
    "text": "Yeah, there are more\ntheoretical analysis and details in the paper, and I would\nrefer you all back to it.",
    "start": "2979550",
    "end": "2984750"
  },
  {
    "text": "But what we see in\nterms of results when doing protein\nlanguage modeling is that the accuracy\nof this model",
    "start": "2984750",
    "end": "2992240"
  },
  {
    "text": "is on par with\ntransformers while reducing computational costs quite a bit. And so what this suggests\nis that the approximation",
    "start": "2992240",
    "end": "2999085"
  },
  {
    "text": "of the SOC max attention kernel\nis a tight approximation. So that is good. And then when you compare\nthat with other methods",
    "start": "2999085",
    "end": "3004870"
  },
  {
    "text": "such as the Reformer\nor [INAUDIBLE],, the accuracy is much higher\nat least on this task. So it seems that compared to\nother methods that approximate,",
    "start": "3004870",
    "end": "3012310"
  },
  {
    "text": "like try to build more\nefficient transformers, this one is much better\nfor biological sequence data, at least in this setting.",
    "start": "3012310",
    "end": "3019960"
  },
  {
    "text": "And finally, if you\nlook at the attention",
    "start": "3019960",
    "end": "3025080"
  },
  {
    "text": "of the amino acid\nsimilarity matrix, you can see that the\nperforma model recognizes",
    "start": "3025080",
    "end": "3030270"
  },
  {
    "text": "highly similar amino acid\npairs such as D and E, and F and Y over here so that suggests\nthat the model is learning",
    "start": "3030270",
    "end": "3036600"
  },
  {
    "text": "the right set of information\nthat we really want over here. So that was a two-minute\noverview of that paper.",
    "start": "3036600",
    "end": "3043630"
  },
  {
    "text": "But I want to talk\nabout another one which also I think is really cool.",
    "start": "3043630",
    "end": "3049360"
  },
  {
    "text": "So this one is called\nProtNLM, again, by a few other folks\nat Google Research. And what this does is model\nbased natural language protein",
    "start": "3049360",
    "end": "3058710"
  },
  {
    "text": "annotation. And why this\nproblem is important is because the\nprotein information",
    "start": "3058710",
    "end": "3064200"
  },
  {
    "text": "is in very high demand. So over 50% of all\nknown proteins that",
    "start": "3064200",
    "end": "3069600"
  },
  {
    "text": "have been sequenced, we don't\nactually know what they do. So it's important that\nwe able to decipher that to some degree at least.",
    "start": "3069600",
    "end": "3075600"
  },
  {
    "text": "And then the second thing is\nwe may want to, for example, find protein sequences with\ngiven functions and this is",
    "start": "3075600",
    "end": "3080910"
  },
  {
    "text": "particularly important\nin the CRISPR domain. And so if you can train\nbidirectional models that can do this, I think that\nwould be incredibly helpful.",
    "start": "3080910",
    "end": "3088740"
  },
  {
    "text": "And the reason I\nsay this, again, is that the unique broad\ndatabase that has over--",
    "start": "3088740",
    "end": "3096462"
  },
  {
    "text": "that has I think millions of\nresearchers worldwide using it today. And so getting this information\npopulated in that database",
    "start": "3096462",
    "end": "3101710"
  },
  {
    "text": "would be incredibly useful and\naccelerate a lot of research in this space.",
    "start": "3101710",
    "end": "3107210"
  },
  {
    "text": "And so the European\nBioinformatics Institute, they have curated this\npretext data about proteins.",
    "start": "3107210",
    "end": "3113620"
  },
  {
    "text": "And so basically, you can\nuse this protein record to train these models. And so what you\nwant to do is you",
    "start": "3113620",
    "end": "3120700"
  },
  {
    "text": "want to maybe learn to directly\nmap from amino acid sequences to natural language\ndescriptions of them.",
    "start": "3120700",
    "end": "3126490"
  },
  {
    "text": "And this problem is not\ntoo different from an image captioning problem where instead\nof having a sequence of pixels,",
    "start": "3126490",
    "end": "3133240"
  },
  {
    "text": "I don't know if sequence is\nright but if you have pixels, instead you have a\nsequence of amino acids and they can range a\nnumber from 2 to 40k.",
    "start": "3133240",
    "end": "3140440"
  },
  {
    "text": "And then what you\nwant to generate out is a description of the protein.",
    "start": "3140440",
    "end": "3146253"
  },
  {
    "text": "And in this paper,\nthe way they do this is they train a T5 model\non protein sequence annotation",
    "start": "3146253",
    "end": "3152170"
  },
  {
    "text": "tasks. So the tasks are set up in\na bunch of different ways. And the supervised\ndata comes from a bunch",
    "start": "3152170",
    "end": "3158859"
  },
  {
    "text": "of different sources in the\nprotein record that they have. And this model is\nan encoded T5 model.",
    "start": "3158860",
    "end": "3164830"
  },
  {
    "text": "So it's a very cool application. And the results are that out\nof the 56 million proteins",
    "start": "3164830",
    "end": "3169930"
  },
  {
    "text": "in that UniProt database\nthat were previously uncharacterized,\n49 million of them now have associated\ntextual descriptions.",
    "start": "3169930",
    "end": "3176799"
  },
  {
    "text": "So we now have a\nhandle on what they do. And so that's really cool. And then the other one I think\nwhich is probably even more",
    "start": "3176800",
    "end": "3183220"
  },
  {
    "text": "interesting is now\nyou can run queries like find me a smaller version\nof this CRISPR Cas9 protein",
    "start": "3183220",
    "end": "3188857"
  },
  {
    "text": "so that it can target\ncertain tissues better and now the model can\ncome back with sequences. And so I think this is going\nto be incredibly useful",
    "start": "3188857",
    "end": "3195190"
  },
  {
    "text": "and going to accelerate a lot\nof research in this space. Already there's a\nlot of momentum. I think these models are\ngoing to further help.",
    "start": "3195190",
    "end": "3201228"
  },
  {
    "text": " So that was on proteins. The last class of applications\nthat I want to cover",
    "start": "3201228",
    "end": "3207915"
  },
  {
    "start": "3203000",
    "end": "3225000"
  },
  {
    "text": "is on the genomics side. Again, the first paper over\nhere was some work last year",
    "start": "3207915",
    "end": "3214670"
  },
  {
    "text": "from our genomics team\nat Health AI at Google, which is building gap\naware sequence transformers",
    "start": "3214670",
    "end": "3220940"
  },
  {
    "text": "for sequence collection. So this module is\ncalled DeepConsensus. And so what role does this model\nplay and why does it matter?",
    "start": "3220940",
    "end": "3229109"
  },
  {
    "text": "So if you look at the sequencing\ndata lifecycle, what you do is you go from\nbasically atoms to bits.",
    "start": "3229110",
    "end": "3236690"
  },
  {
    "text": "And so you have this\nphysical specimen that hopefully has some DNA in it. And you put it\nthrough a sequencing",
    "start": "3236690",
    "end": "3243710"
  },
  {
    "text": "machine such as PacBio and that\ncomes out with the raw data. And that raw data gets\nmapped to a reference genome.",
    "start": "3243710",
    "end": "3251480"
  },
  {
    "text": "And then sometimes\nthere might be DIFS between an individual\nand the reference genome and that can be corrected\nthrough this model called deep",
    "start": "3251480",
    "end": "3257480"
  },
  {
    "text": "variant that was introduced\nby our team a few years back and that's open source. And then once you\nhave this sequence,",
    "start": "3257480",
    "end": "3263462"
  },
  {
    "text": "you can then use it for a\nbunch of different analysis such as ancestry or just\nbasic biomedical research.",
    "start": "3263462",
    "end": "3272349"
  },
  {
    "text": "So where deep variant\nfits in is it's actually makes the raw\nDNA reads that comes out",
    "start": "3272350",
    "end": "3277470"
  },
  {
    "text": "from the PacBio sequencer. It tries to make\nit more accurate. And so how the PacBio\nsequencer actually works",
    "start": "3277470",
    "end": "3285600"
  },
  {
    "text": "is it uses this clear consensus\nsequencing algorithm where",
    "start": "3285600",
    "end": "3291180"
  },
  {
    "text": "the DNA molecule is\nread several times, and it produces multiple\ndifferent subreads.",
    "start": "3291180",
    "end": "3296250"
  },
  {
    "text": "And these subreads, they\ndo contain some errors and so they are finally\nassembled together.",
    "start": "3296250",
    "end": "3302410"
  },
  {
    "text": "And so what deep\nvariant tries to do is it tries to improve on the\nerrors over here basically that",
    "start": "3302410",
    "end": "3308130"
  },
  {
    "text": "comes out from just this\ncircular consensus sequencing algorithm. And so how does this model work?",
    "start": "3308130",
    "end": "3314832"
  },
  {
    "text": "So as I said, the basic\ntask for deep consensus is to use the CCS\ndata and the subreads",
    "start": "3314832",
    "end": "3320240"
  },
  {
    "text": "associated with them to\ngenerate a corrected sequence. And so in this example, when\nwe run through the model, what",
    "start": "3320240",
    "end": "3325760"
  },
  {
    "text": "we see is that while the CCS\nidentity was at like 95.7%, the DeepConsensus prediction\nidentity was 100%.",
    "start": "3325760",
    "end": "3332250"
  },
  {
    "text": "So it's a fairly\nsimple task where you're trying to\nreduce errors that come out from the PacBio\nwith the CCS algorithm.",
    "start": "3332250",
    "end": "3339120"
  },
  {
    "text": "And so the very natural question\nis, where do these labels come from? So each CCS sequence\nthat you have, that is",
    "start": "3339120",
    "end": "3347210"
  },
  {
    "text": "aligned to a high\nquality assembly. And this high\nquality assembly is created by having many CCS\nreads stitched together.",
    "start": "3347210",
    "end": "3356790"
  },
  {
    "text": "And so that ends up\nhaving fewer errors. And so you can then try to\nuse that high quality stitched",
    "start": "3356790",
    "end": "3363590"
  },
  {
    "text": "assembly and map that back to\nthe CCS trade for a given block and use that as that label.",
    "start": "3363590",
    "end": "3369119"
  },
  {
    "text": "So that results in more\nstronger ground truth and you can use that to\ntrain the model to improve",
    "start": "3369120",
    "end": "3375170"
  },
  {
    "text": "the accuracy further. And so this is what the\nmodel is trained on. And so the model\nlooks like this.",
    "start": "3375170",
    "end": "3380940"
  },
  {
    "text": "It's a transformer architecture. It takes these subreads\nand this CCS read as well.",
    "start": "3380940",
    "end": "3387240"
  },
  {
    "text": "And it has a bunch of\nadditional context features that come in from\nthe sequence itself, the instrument sequencing\ninstrument as well.",
    "start": "3387240",
    "end": "3394890"
  },
  {
    "text": "And these are all fed into\nthe transformer model. It produces a polished\nsegment and these segments",
    "start": "3394890",
    "end": "3399892"
  },
  {
    "text": "are then stitched together to\nproduce the final polish read over here.",
    "start": "3399892",
    "end": "3405060"
  },
  {
    "text": "One thing I will\npoint out over here is that in order to\ntrain this model, you can't use a\ncross entropy loss.",
    "start": "3405060",
    "end": "3410790"
  },
  {
    "text": "And this is because\nif you insert--",
    "start": "3410790",
    "end": "3415990"
  },
  {
    "text": "you often have insertions\nin DNA sequences. And so that can when you use a\ncross entropy loss really throw",
    "start": "3415990",
    "end": "3421329"
  },
  {
    "text": "off the model. Even like a single error\nas you can see over here, can propagate\nthroughout the sequence",
    "start": "3421330",
    "end": "3426400"
  },
  {
    "text": "and make it really worse. So what you need\nis a special kind of alignment loss\nbased on distance",
    "start": "3426400",
    "end": "3432370"
  },
  {
    "text": "that can really capture this\nerror much, much better. And so making this\nalignment last work on TPUs",
    "start": "3432370",
    "end": "3438875"
  },
  {
    "text": "and making it\ndifferentiable is I think the real meat of this paper. And so again, go\nback to the paper if you're interested\nin that kind of topic.",
    "start": "3438875",
    "end": "3444872"
  },
  {
    "text": "I think that's really cool. But at a very high level, how\nwell does this model work?",
    "start": "3444872",
    "end": "3450220"
  },
  {
    "text": "So if you look at the final\noutput, you have the read name. You have the base\npredictions and also the predicted quality,\nwhich can be thought",
    "start": "3450220",
    "end": "3456240"
  },
  {
    "text": "of as a confidence score. And these base predictions\nare often quite long and so you can see that\ncontinuous offscreen",
    "start": "3456240",
    "end": "3461670"
  },
  {
    "text": "because it's 10k to 20k\ncases long over here. And when you look\nat the quality, it improved quite a bit over\nthe [INAUDIBLE] CSS algorithm",
    "start": "3461670",
    "end": "3470920"
  },
  {
    "text": "over here. The per read accuracy over\nhere improves quite a bit. And so you may ask like,\nwhat is the real world",
    "start": "3470920",
    "end": "3478349"
  },
  {
    "text": "impact of this kind of model? So the answer is\nthis model is already being used in the real world.",
    "start": "3478350",
    "end": "3484420"
  },
  {
    "text": "So at Stanford in\nthe genomics team by Dr. Ashley and\na few others, there was this recent ultra\nrapid nanopore genome",
    "start": "3484420",
    "end": "3490857"
  },
  {
    "text": "sequencing paper where they set\na world record for the fastest genome sequencing. And this deep consensus\ntransform architecture",
    "start": "3490857",
    "end": "3496650"
  },
  {
    "text": "was used in that\nassembly sequence. And so in this\nparticular study, they were able to very quickly\ndiagnose that Matthew over here",
    "start": "3496650",
    "end": "3503640"
  },
  {
    "text": "had a heart condition\ndue to genetic reasons. And so they were very\nquickly able to put",
    "start": "3503640",
    "end": "3508740"
  },
  {
    "text": "Matthew on the patient's\ndonors list over here. So that's the kind\nof real world impact we can have with these\nbiomedical transfer models",
    "start": "3508740",
    "end": "3516360"
  },
  {
    "text": "and AI systems in general.  And very quickly, the last\npaper that I want to talk",
    "start": "3516360",
    "end": "3524830"
  },
  {
    "start": "3519000",
    "end": "3599000"
  },
  {
    "text": "about is this paper from\nDeepMind on Effective Gene Expression Prediction from\nSequences By Integrating Long",
    "start": "3524830",
    "end": "3531820"
  },
  {
    "text": "Range Interactions.\" This was published\nin Nature Methods. And the motivation for\nthis work is again,",
    "start": "3531820",
    "end": "3538599"
  },
  {
    "text": "that since the Human\nGenome Project, there have been thousands of\ngenome wide association study hits where the goal is\nto map genetic variants",
    "start": "3538600",
    "end": "3548500"
  },
  {
    "text": "to different kind of\ndisease phenotypes. But a lot of this involves\nexperimentation and real world",
    "start": "3548500",
    "end": "3554537"
  },
  {
    "text": "experimentation patient\ntakes a lot of time. So if you can do that with\nmachine learning models, that's really great.",
    "start": "3554537",
    "end": "3560109"
  },
  {
    "text": "And so that's what they set\nout to do in this paper. And so if you look\nat the gene itself,",
    "start": "3560110",
    "end": "3566230"
  },
  {
    "text": "there are 10% of\nthe gene are going to be like coding variants\nand these influence protein",
    "start": "3566230",
    "end": "3572260"
  },
  {
    "text": "function. And then the way they\ncan cause diseases is by disrupting the structure\nof proteins that are generated",
    "start": "3572260",
    "end": "3578770"
  },
  {
    "text": "or by affecting the\nprotein-protein interactions. The good part about\nthese coding variants",
    "start": "3578770",
    "end": "3584050"
  },
  {
    "text": "are they tend to be\ncloser to the gene and so they're\neasier to interpret. On the other hand,\nthe 90% of the gene",
    "start": "3584050",
    "end": "3590200"
  },
  {
    "text": "is like non-coding variants. And the way they work is they\ninfluence protein expression.",
    "start": "3590200",
    "end": "3596060"
  },
  {
    "text": "So they are more like\nregulatory sequences. And so the way they\ncan lead to diseases",
    "start": "3596060",
    "end": "3603250"
  },
  {
    "text": "if they have any\nvariance is by disrupting the transcription of proteins.",
    "start": "3603250",
    "end": "3608920"
  },
  {
    "text": "And given that these non-coding\nvariants can be very, very far away from the gene and\nthe coding variants,",
    "start": "3608920",
    "end": "3614710"
  },
  {
    "text": "it's very difficult\nto interpret them. And so the question is,\ncan we try and transform models that can\npredict the influence",
    "start": "3614710",
    "end": "3620200"
  },
  {
    "text": "of these non-coding variants? And so that is the\ntask over here. And so this is a\nvisualization again.",
    "start": "3620200",
    "end": "3627010"
  },
  {
    "text": "So the paper again\nlooks at the-- it focuses on\ntranscription, which",
    "start": "3627010",
    "end": "3633460"
  },
  {
    "text": "is the first step in terms\nof converting DNA into RNA. And the way this is done is\nyou have RNA polymerase, which",
    "start": "3633460",
    "end": "3640480"
  },
  {
    "text": "gets recruited at the\nbeginning of the gene by these proteins called\ntranscription factors.",
    "start": "3640480",
    "end": "3646180"
  },
  {
    "text": "And these transcription\nfactors have a binding site which correspond to\nthese promoters which are quite close to the gene.",
    "start": "3646180",
    "end": "3651490"
  },
  {
    "text": "But then you also\nhave these enhancers which can be very, very far away\nfrom these promoters in terms",
    "start": "3651490",
    "end": "3657160"
  },
  {
    "text": "of the linear space also\ninfluencing this transcription. And you may ask, how can such--",
    "start": "3657160",
    "end": "3664965"
  },
  {
    "text": "how can these enhancers\ninfluence the activity over here? This is because while\nthey may be far away in the linear space,\nwhen the sequence folds",
    "start": "3664965",
    "end": "3672320"
  },
  {
    "text": "and in the 3D structure,\nthey will end up being quite close to each other. And so they can completely\naffect the transcription",
    "start": "3672320",
    "end": "3677745"
  },
  {
    "text": "process over here. So it's a very\nhigh level overview of what's happening over here\nand in terms of the biology.",
    "start": "3677745",
    "end": "3683920"
  },
  {
    "text": "And so the question\nis if there are any variants in these\nnon-coding variants and in these enhancers.",
    "start": "3683920",
    "end": "3690790"
  },
  {
    "text": "They may disrupt the\ntranscription factor binding and this can in turn\nlead to no proteins",
    "start": "3690790",
    "end": "3695829"
  },
  {
    "text": "and then finally\nto diseases, right? So we want to be\nable to predict that based on the DNA sequences\nthat have been generated.",
    "start": "3695830",
    "end": "3702130"
  },
  {
    "text": "So the problem is\nquite straightforward. It's a supervised\nlearning problem.",
    "start": "3702130",
    "end": "3707280"
  },
  {
    "text": "The setup is predict\nexperimental data from these DNA sequences. And this can take\nmany different forms.",
    "start": "3707280",
    "end": "3713397"
  },
  {
    "text": "The primary one is gene\nexpression over here but then there are\nalso other tasks, such as DNA accessibility,\nhistone modifications,",
    "start": "3713397",
    "end": "3719675"
  },
  {
    "text": "and transcription\nfactor binding, and so on and so forth. So as you can imagine,\nthe baseline model",
    "start": "3719675",
    "end": "3726570"
  },
  {
    "text": "for this task for many\nyears was the CNN model. And as you start to get a\ndifferent set of layers,",
    "start": "3726570",
    "end": "3732930"
  },
  {
    "text": "you can increase\nthe receptive field but there's a limit to that. So in this work,\nwhat they showed was",
    "start": "3732930",
    "end": "3738195"
  },
  {
    "text": "you can use transformers\ninstead and do better modeling of these\nlong range interactions.",
    "start": "3738195",
    "end": "3745045"
  },
  {
    "text": "So the final model\nis called \"Enformer\" which is a combination of\nthis enhancer and transformer.",
    "start": "3745045",
    "end": "3750730"
  },
  {
    "text": "And so if you look\nat the model itself, it has a few CNN layers\nat the beginning, but then it has a bunch\nof transformer blocks",
    "start": "3750730",
    "end": "3756175"
  },
  {
    "text": "that are stacked together. And the input is\n200kb DNA sequences",
    "start": "3756175",
    "end": "3761790"
  },
  {
    "text": "and there are\napproximately 30 examples that have been trained. And the output is like genomic\ntracks of this RNA expression",
    "start": "3761790",
    "end": "3767700"
  },
  {
    "text": "with. And they have organism specific\nso one for humans and one for mouse.",
    "start": "3767700",
    "end": "3773910"
  },
  {
    "text": "And finally, one key detail is\nthat relative position encoding that were used in this\nmodel but actually very key.",
    "start": "3773910",
    "end": "3779370"
  },
  {
    "text": "And these relative position\nencoding for modeling, this power of interactions. And as a result of using this\nrelative position encoding",
    "start": "3779370",
    "end": "3786913"
  },
  {
    "text": "with the transformer\nblock architecture, they were now able to model\ninteractions over 100 base",
    "start": "3786913",
    "end": "3792120"
  },
  {
    "text": "pairs. And so you see that in\nthe results over here. So you have the\nexperimental data in green.",
    "start": "3792120",
    "end": "3798790"
  },
  {
    "text": "And you can see the\nCNN baseline over here. And you see that as\nsoon as you go far away,",
    "start": "3798790",
    "end": "3805080"
  },
  {
    "text": "you see that the CNN model\nis no longer able to capture these gene expressions.",
    "start": "3805080",
    "end": "3811319"
  },
  {
    "text": "But you can see that the\nenhancer model is now able to pick them up. So you can see that as\nthe model goes far away,",
    "start": "3811320",
    "end": "3816920"
  },
  {
    "text": "the enhancer model is\nable to capture this whereas the standard model is\nno longer able to capture this.",
    "start": "3816920",
    "end": "3823950"
  },
  {
    "text": "And finally, one very\ninteresting experiment that they had in the\npaper was they were also",
    "start": "3823950",
    "end": "3829110"
  },
  {
    "text": "able to predict\npromoter-enhancer influences and that prediction was actually\non par with experimental data.",
    "start": "3829110",
    "end": "3836647"
  },
  {
    "text": "So this suggests that using\nthis machine learning model, we can sidestep a lot of\nthese wet lab experiments and get key details which\ncould be super useful.",
    "start": "3836647",
    "end": "3843285"
  },
  {
    "text": " So yeah. So very quickly, I'm sorry I\nhad to cram through proteins",
    "start": "3843285",
    "end": "3849990"
  },
  {
    "text": "and genomics\napplications over here. But I think what you\nwould see is that overall, when you look at\nclinical proteins",
    "start": "3849990",
    "end": "3855900"
  },
  {
    "text": "and genomic applications,\nwe see that transformers have incredible\npotential in biomedicine.",
    "start": "3855900",
    "end": "3861185"
  },
  {
    "text": "And with clinical\napplications, I think the challenges are\nperhaps more centered around data and evaluation. But on the proteins\nand genomics side,",
    "start": "3861185",
    "end": "3867763"
  },
  {
    "text": "I think there are some extremely\ninteresting opportunities to innovate on the architecture. And finally, as\nI said, there are",
    "start": "3867763",
    "end": "3873930"
  },
  {
    "text": "incredible bidirectional\nlearning opportunities. I think the problem\nof modeling long range interactions, that's\nuseful beyond proteins,",
    "start": "3873930",
    "end": "3880140"
  },
  {
    "text": "beyond genomics. I think it's useful\nin genomics and so I think any architecture\nimprovement over here can inspire wider\nprogress in AI.",
    "start": "3880140",
    "end": "3886510"
  },
  {
    "text": "So I think that's a big\nreason to work on this. Any questions so far?",
    "start": "3886510",
    "end": "3894100"
  },
  {
    "text": "Sorry, I covered a lot\nof ground over here. Apologies for that. But I think these\nare super cool papers and you should go\nback and read them.",
    "start": "3894100",
    "end": "3900890"
  },
  {
    "text": "So quite finally, I\nwant to maybe spend a couple of minutes\ntouching on how I see the future of\nbiomedical AI evolving.",
    "start": "3900890",
    "end": "3908349"
  },
  {
    "text": "Overall, I believe it's\nnot a question of if AI will transform biomedicine. I think it's rather a\nquestion of when and how.",
    "start": "3908350",
    "end": "3915610"
  },
  {
    "text": "And I think the\nvery specific thesis I have over here is, given\nthe nature of biomedical data",
    "start": "3915610",
    "end": "3920698"
  },
  {
    "text": "and how multimodal in nature,\nand with all the progress and transformers cells of\nlearning large language models, I think we have an\nincredibly powerful framework",
    "start": "3920698",
    "end": "3928810"
  },
  {
    "text": "to leverage all this\nrichness at scale and truly build foundational\nmedical AI models.",
    "start": "3928810",
    "end": "3934630"
  },
  {
    "text": "So I think that is\nincredibly exciting. And so I'm not--",
    "start": "3934630",
    "end": "3940730"
  },
  {
    "text": "I think you've already been\nover here for far too long so I'm not going to you\nto recognize these people.",
    "start": "3940730",
    "end": "3946070"
  },
  {
    "text": "But they are actually famous\nphysicians and scientists, some of them in front\nof Nobel prizes. And so I think what I\nwant to say over here",
    "start": "3946070",
    "end": "3953750"
  },
  {
    "text": "is there's no reason\nfor a scientist to be different\nfrom a physician. They can be combined\ntogether and that's what I also want to convey\nwith our AI systems as well.",
    "start": "3953750",
    "end": "3960312"
  },
  {
    "text": "We don't have to separate\nclinical applications and biological applications. I think when we\ncombine them together, we are going to discover\na lot of new insights",
    "start": "3960312",
    "end": "3967127"
  },
  {
    "text": "and I think that's going to\naccelerate biomedical research and internally to\nnew discoveries, and which is going to be used\nto eradicate diseases, advance",
    "start": "3967127",
    "end": "3975260"
  },
  {
    "text": "human health span, and generally\ndrive human potential forward. So-- Question.",
    "start": "3975260",
    "end": "3980720"
  },
  {
    "text": "I don't actually know\nwho these three are. Sure. I think the rightmost one is\nAlexander Fleming, and then",
    "start": "3980720",
    "end": "3987890"
  },
  {
    "text": "Jonas Salk, and\nthen Paul Ehrlich. So Fleming is penicillin,\nSalk is polio,",
    "start": "3987890",
    "end": "3992930"
  },
  {
    "text": "and Ehrlich was bunch\nof different stuff. ",
    "start": "3992930",
    "end": "4000250"
  },
  {
    "text": "And so maybe-- I lost this question to all\nof you, which field of AI",
    "start": "4000250",
    "end": "4005279"
  },
  {
    "text": "do you think will-- which field do you think AI will\nwin the first Nobel Prize in?",
    "start": "4005280",
    "end": "4010293"
  },
  {
    "text": "You don't have to\nanswer, just think. ",
    "start": "4010293",
    "end": "4015580"
  },
  {
    "text": "[CLASSROOM DISCUSSION] Six.",
    "start": "4015580",
    "end": "4021640"
  },
  {
    "text": "[INAUDIBLE] No, economics is\nnot a Nobel prize. It is. No, there's like\neight Nobel prizes.",
    "start": "4021640",
    "end": "4027089"
  },
  {
    "text": "Oh, OK. But it's [INAUDIBLE]. [INAUDIBLE] Because was like,\nit's not a real field.",
    "start": "4027090",
    "end": "4032920"
  },
  {
    "text": "I'm not going to give\nthese people a prize. I think economics\nis another place.",
    "start": "4032920",
    "end": "4037944"
  },
  {
    "text": "[INAUDIBLE] It is. It's associated with\nthe Nobel Foundation.",
    "start": "4037944",
    "end": "4043030"
  },
  {
    "text": "No. No? OK. I think it is. The whole point of Nobel\nwas like, this is a joke. I'm not awarding these people.",
    "start": "4043030",
    "end": "4048870"
  },
  {
    "text": "And then economists were\nlike, wait, wait, we're real. And then they [INAUDIBLE]\neconomics Nobel Prize.",
    "start": "4048870",
    "end": "4054760"
  },
  {
    "text": "OK. OK. [INAUDIBLE] oh, he\ninvented this drug",
    "start": "4054760",
    "end": "4061320"
  },
  {
    "text": "that cured cancer or something. That's right. So I also feel the\nsame way, and I hope the overwhelming\nmajority of you",
    "start": "4061320",
    "end": "4067360"
  },
  {
    "text": "also think that it's\ngoing to be in medicine. And I'm going to\nend on that note.",
    "start": "4067360",
    "end": "4072423"
  },
  {
    "text": "Huge thank you to all my\ncollaborators and teammates for most importantly\nallowing me to steal slides.",
    "start": "4072423",
    "end": "4077957"
  },
  {
    "text": "And then also, thank\nyou to all of you for patiently\nlistening over here. Hopefully, this was helpful.",
    "start": "4077957",
    "end": "4083610"
  },
  {
    "start": "4083610",
    "end": "4089000"
  }
]
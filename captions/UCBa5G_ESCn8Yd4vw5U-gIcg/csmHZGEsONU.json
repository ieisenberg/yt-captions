[
  {
    "text": "Let's look at another example.",
    "start": "0",
    "end": "3470"
  },
  {
    "text": "And we're going to--",
    "start": "3470",
    "end": "5270"
  },
  {
    "text": "since we've seen\nthese stats before,",
    "start": "5270",
    "end": "6920"
  },
  {
    "text": "they're going to be a\nlittle easier this time.",
    "start": "6920",
    "end": "10080"
  },
  {
    "text": "So we're going to look at\nthe MNIST digit data set.",
    "start": "10080",
    "end": "12780"
  },
  {
    "text": "So these are the handwritten\ndigits on postal codes,",
    "start": "12780",
    "end": "16129"
  },
  {
    "text": "I think, they're derived from\nthat we're trying to classify",
    "start": "16129",
    "end": "18740"
  },
  {
    "text": "into the 10 digits class.",
    "start": "18740",
    "end": "20970"
  },
  {
    "text": "OK.",
    "start": "20970",
    "end": "21470"
  },
  {
    "text": "So as in the\nhitters data set, we",
    "start": "21470",
    "end": "24410"
  },
  {
    "text": "need to give the data to torch.",
    "start": "24410",
    "end": "26450"
  },
  {
    "text": "So actually, the\nMNIST data is already",
    "start": "26450",
    "end": "28250"
  },
  {
    "text": "sort of prepackaged for\ntorch or almost prepackaged.",
    "start": "28250",
    "end": "32029"
  },
  {
    "text": "So we can find it with\none of those libraries",
    "start": "32030",
    "end": "36590"
  },
  {
    "text": "as torchvision.datasets has\nthe MNIST data already for us.",
    "start": "36590",
    "end": "40410"
  },
  {
    "text": "We're going to do a slight\nbit of preprocessing.",
    "start": "40410",
    "end": "44568"
  },
  {
    "text": "Actually, no.",
    "start": "44568",
    "end": "45110"
  },
  {
    "text": "Oh, I'm sorry, that's\npreprocessing for the CIFAR.",
    "start": "45110",
    "end": "48200"
  },
  {
    "text": "So we again make a data\nmodule that tells torch",
    "start": "48200",
    "end": "52490"
  },
  {
    "text": "how to load in the data.",
    "start": "52490",
    "end": "54330"
  },
  {
    "text": "So what will happen in a--",
    "start": "54330",
    "end": "57890"
  },
  {
    "text": "this specifies what\nan epoch looks like.",
    "start": "57890",
    "end": "60180"
  },
  {
    "text": "There are 256 per batch.",
    "start": "60180",
    "end": "62560"
  },
  {
    "text": "So an epoch goes\nthrough each of the data",
    "start": "62560",
    "end": "66420"
  },
  {
    "text": "points with a chunk of\n256 until every data",
    "start": "66420",
    "end": "70229"
  },
  {
    "text": "point has been visited once,\nand then the epoch is finished.",
    "start": "70230",
    "end": "72960"
  },
  {
    "start": "72960",
    "end": "78220"
  },
  {
    "text": "OK.",
    "start": "78220",
    "end": "78720"
  },
  {
    "text": "Let's specify our model now.",
    "start": "78720",
    "end": "79887"
  },
  {
    "text": "So we're going to do now just\na slightly more complicated",
    "start": "79887",
    "end": "82262"
  },
  {
    "text": "model.",
    "start": "82262",
    "end": "82770"
  },
  {
    "text": "But it will be a\ntwo-layer model.",
    "start": "82770",
    "end": "87929"
  },
  {
    "text": "And, oh, I think I\nmissed one important line",
    "start": "87930",
    "end": "90930"
  },
  {
    "text": "in the hitters example that\nI'm going to emphasize now.",
    "start": "90930",
    "end": "93630"
  },
  {
    "text": "All of these-- so,\nagain, we're going",
    "start": "93630",
    "end": "95340"
  },
  {
    "text": "to make a subclass\nof the nn.Module.",
    "start": "95340",
    "end": "98850"
  },
  {
    "text": "Here we're going to make\nit for the MNIST data.",
    "start": "98850",
    "end": "101400"
  },
  {
    "text": "You can name this\nwhatever you like",
    "start": "101400",
    "end": "102990"
  },
  {
    "text": "but probably useful\nto name it something",
    "start": "102990",
    "end": "105360"
  },
  {
    "text": "related to what you're doing.",
    "start": "105360",
    "end": "107850"
  },
  {
    "text": "And there's this line here,\nthis super line that we also",
    "start": "107850",
    "end": "111930"
  },
  {
    "text": "had for the hitters data.",
    "start": "111930",
    "end": "113560"
  },
  {
    "text": "So what this does is, well, we\ninherit from the module class.",
    "start": "113560",
    "end": "119759"
  },
  {
    "text": "And we only define here\ntwo methods, right,",
    "start": "119760",
    "end": "122250"
  },
  {
    "text": "this init method and\nthe forward method.",
    "start": "122250",
    "end": "124870"
  },
  {
    "text": "But this nn.Module has\nmany other methods.",
    "start": "124870",
    "end": "127710"
  },
  {
    "text": "And that's, of course,\nbecause this torch has",
    "start": "127710",
    "end": "131220"
  },
  {
    "text": "to use this to fit the model.",
    "start": "131220",
    "end": "132668"
  },
  {
    "text": "So it has to know how\nto do many other things.",
    "start": "132668",
    "end": "134585"
  },
  {
    "start": "134585",
    "end": "138348"
  },
  {
    "text": "And what we're doing\nhere is actually",
    "start": "138348",
    "end": "139890"
  },
  {
    "text": "calling the init\nmethod of module",
    "start": "139890",
    "end": "141990"
  },
  {
    "text": "on this newly created\nMNIST example.",
    "start": "141990",
    "end": "145570"
  },
  {
    "text": "So this is actually\nnecessary for every time you",
    "start": "145570",
    "end": "148950"
  },
  {
    "text": "make a subclass of nn.Module.",
    "start": "148950",
    "end": "151050"
  },
  {
    "text": "So the syntax is the same\nthroughout all our examples.",
    "start": "151050",
    "end": "153750"
  },
  {
    "text": "We give the super\nfunction, which",
    "start": "153750",
    "end": "156300"
  },
  {
    "text": "is a built-in function,\nthe class name, self.",
    "start": "156300",
    "end": "159840"
  },
  {
    "text": "And self is a keyword here.",
    "start": "159840",
    "end": "161700"
  },
  {
    "text": "It's the first argument\nto every method.",
    "start": "161700",
    "end": "163980"
  },
  {
    "text": "And we call the init method of--",
    "start": "163980",
    "end": "166980"
  },
  {
    "text": "well, actually\nnn.Module on self.",
    "start": "166980",
    "end": "170190"
  },
  {
    "text": "So you'll have to do that\nfor all your examples,",
    "start": "170190",
    "end": "172950"
  },
  {
    "text": "otherwise you'll have a problem.",
    "start": "172950",
    "end": "174540"
  },
  {
    "text": "OK.",
    "start": "174540",
    "end": "175079"
  },
  {
    "text": "So let's get to the heart\nof specifying our layers.",
    "start": "175080",
    "end": "179940"
  },
  {
    "text": "We're going to do two layers.",
    "start": "179940",
    "end": "182680"
  },
  {
    "text": "So the layers are going\nto be specified much",
    "start": "182680",
    "end": "185430"
  },
  {
    "text": "like our single layer.",
    "start": "185430",
    "end": "187120"
  },
  {
    "text": "So this chunk here is\nvery similar to what we",
    "start": "187120",
    "end": "189299"
  },
  {
    "text": "saw for the hitters data set.",
    "start": "189300",
    "end": "192480"
  },
  {
    "text": "We're just going to\nnow compose two layers.",
    "start": "192480",
    "end": "195099"
  },
  {
    "text": "So we'll store this as layer1,\na similar output as layer2.",
    "start": "195100",
    "end": "199050"
  },
  {
    "text": "And then we'll compose them\nwith the sequential call again.",
    "start": "199050",
    "end": "202680"
  },
  {
    "text": "So features first go into\nlayer1, come out from layer2,",
    "start": "202680",
    "end": "207150"
  },
  {
    "text": "and then they get mapped to 10.",
    "start": "207150",
    "end": "210299"
  },
  {
    "text": "And that's because we\nhave 10 digits here.",
    "start": "210300",
    "end": "212940"
  },
  {
    "text": "So just to get the\nidea, the images",
    "start": "212940",
    "end": "214920"
  },
  {
    "text": "are 28 by 28 grayscale images.",
    "start": "214920",
    "end": "217660"
  },
  {
    "text": "So in the layer1,\nwe see the 28 by 28.",
    "start": "217660",
    "end": "221520"
  },
  {
    "text": "That's the dimension\nof the input.",
    "start": "221520",
    "end": "224540"
  },
  {
    "text": "And the hidden layer\nhas got 256 units.",
    "start": "224540",
    "end": "227760"
  },
  {
    "text": "And we're using\na dropout of 0.4.",
    "start": "227760",
    "end": "229890"
  },
  {
    "text": "And then the second\nlayer, of course,",
    "start": "229890",
    "end": "231490"
  },
  {
    "text": "must take 256 as the input,\ndimension of the input layer",
    "start": "231490",
    "end": "235290"
  },
  {
    "text": "because that's the\nprevious hidden layer.",
    "start": "235290",
    "end": "237719"
  },
  {
    "text": "And then it's got\n128 hidden units.",
    "start": "237720",
    "end": "242900"
  },
  {
    "text": "And specify the dropout.",
    "start": "242900",
    "end": "244760"
  },
  {
    "text": "And then the final\nlayer, the output layer,",
    "start": "244760",
    "end": "246980"
  },
  {
    "text": "goes from the 128 hidden units\nto the 10 dimensional output",
    "start": "246980",
    "end": "254269"
  },
  {
    "text": "layer because there's 10 digits.",
    "start": "254270",
    "end": "256310"
  },
  {
    "text": "And we use a softmax.",
    "start": "256310",
    "end": "258665"
  },
  {
    "text": "We don't have the softmax here.",
    "start": "258665",
    "end": "260492"
  },
  {
    "text": "The loss function\nis actually going",
    "start": "260492",
    "end": "261950"
  },
  {
    "text": "to have the softmax\napplied to it.",
    "start": "261950",
    "end": "263507"
  },
  {
    "text": "But that's similar to\nthe regression example",
    "start": "263507",
    "end": "265340"
  },
  {
    "text": "where this just\ndescribes how features",
    "start": "265340",
    "end": "268580"
  },
  {
    "text": "get transformed into outputs.",
    "start": "268580",
    "end": "270150"
  },
  {
    "text": "And then the loss relates\nthat to the outcome.",
    "start": "270150",
    "end": "272699"
  },
  {
    "text": "So, Jonathan, we\ncan see how easy",
    "start": "272700",
    "end": "274320"
  },
  {
    "text": "it would be if you wanted\nto just add a few more",
    "start": "274320",
    "end": "276320"
  },
  {
    "text": "hidden layers, right?",
    "start": "276320",
    "end": "277310"
  },
  {
    "text": "You just basically\nreplicate this kind of code",
    "start": "277310",
    "end": "279800"
  },
  {
    "text": "and put in the numbers we want.",
    "start": "279800",
    "end": "281490"
  },
  {
    "text": "And it's really straightforward.",
    "start": "281490",
    "end": "282930"
  },
  {
    "text": "You could even if\nyou wanted to have--",
    "start": "282930",
    "end": "284750"
  },
  {
    "text": "if you wanted 10 layers, you\ncould even do a for loop.",
    "start": "284750",
    "end": "287060"
  },
  {
    "text": "You don't even have to\nrepeat the same code.",
    "start": "287060",
    "end": "289100"
  },
  {
    "text": "And we'll do something\nlike that for the CNN.",
    "start": "289100",
    "end": "291140"
  },
  {
    "text": "We'll have, I think,\nfive layers or so.",
    "start": "291140",
    "end": "293060"
  },
  {
    "text": "And rather than writing\nfive chunks like this,",
    "start": "293060",
    "end": "295490"
  },
  {
    "text": "we'll use Python\nto make it easier.",
    "start": "295490",
    "end": "297710"
  },
  {
    "text": "So it takes a little bit of\ngetting used to this layer.",
    "start": "297710",
    "end": "300449"
  },
  {
    "text": "But once you've got\nit, you can basically",
    "start": "300450",
    "end": "302760"
  },
  {
    "text": "set up any neural network.",
    "start": "302760",
    "end": "305610"
  },
  {
    "text": "And again, this forward\nmap, that's the key.",
    "start": "305610",
    "end": "308310"
  },
  {
    "text": "This tells how features\nget translated into,",
    "start": "308310",
    "end": "311270"
  },
  {
    "text": "in this case, the 10 scores.",
    "start": "311270",
    "end": "313650"
  },
  {
    "text": "And that'll get tied to softmax.",
    "start": "313650",
    "end": "315555"
  },
  {
    "text": "OK.",
    "start": "315555",
    "end": "316389"
  },
  {
    "text": "OK.",
    "start": "316390",
    "end": "316890"
  },
  {
    "text": "So then a lot of\nthe rest is going",
    "start": "316890",
    "end": "318360"
  },
  {
    "text": "to be almost\nidentical to before,",
    "start": "318360",
    "end": "320580"
  },
  {
    "text": "that part about\nsetting up the trainer",
    "start": "320580",
    "end": "323460"
  },
  {
    "text": "and training it, and et cetera.",
    "start": "323460",
    "end": "325115"
  },
  {
    "text": "But let's go a little\nquickly to that.",
    "start": "325115",
    "end": "330210"
  },
  {
    "text": "So, again, we'll specify the--\nthis instantiates the MNIST",
    "start": "330210",
    "end": "334050"
  },
  {
    "text": "model.",
    "start": "334050",
    "end": "335229"
  },
  {
    "text": "We can look at\nthe summary again.",
    "start": "335230",
    "end": "336990"
  },
  {
    "text": "So the summary is a bit longer\nnow because we have two layers.",
    "start": "336990",
    "end": "343169"
  },
  {
    "text": "But it can be read pretty\nsimilar to the hitters data.",
    "start": "343170",
    "end": "346380"
  },
  {
    "text": "And we're not going to\nspend too much time on that.",
    "start": "346380",
    "end": "349920"
  },
  {
    "text": "So here, again, we\nmake this module.",
    "start": "349920",
    "end": "353970"
  },
  {
    "text": "This argument here,\nclassification,",
    "start": "353970",
    "end": "355740"
  },
  {
    "text": "says take those 10\noutputs and throw them",
    "start": "355740",
    "end": "358020"
  },
  {
    "text": "into a softmax to compare it to\nthe response in whatever data",
    "start": "358020",
    "end": "362550"
  },
  {
    "text": "this thing gets fit.",
    "start": "362550",
    "end": "363960"
  },
  {
    "text": "And again, this argument here\ntells torch what data will be",
    "start": "363960",
    "end": "369569"
  },
  {
    "text": "fit into the\nclassification problem .",
    "start": "369570",
    "end": "372990"
  },
  {
    "text": "After that, well, this\nis going to look similar.",
    "start": "372990",
    "end": "375330"
  },
  {
    "text": "There will be a\nlot of blue things.",
    "start": "375330",
    "end": "377370"
  },
  {
    "text": "And we could watch them if\nwe were running this live.",
    "start": "377370",
    "end": "380595"
  },
  {
    "start": "380595",
    "end": "383580"
  },
  {
    "text": "Let's make a similar\nplot to what we had",
    "start": "383580",
    "end": "385500"
  },
  {
    "text": "done before for mean squared--",
    "start": "385500",
    "end": "388153"
  },
  {
    "text": "mean absolute error\nin the hitters data.",
    "start": "388153",
    "end": "389820"
  },
  {
    "text": "Let's plot this metric for\naccuracy for the MNIST data.",
    "start": "389820",
    "end": "394080"
  },
  {
    "text": "And again, we can see how\nthings progress for the training",
    "start": "394080",
    "end": "400395"
  },
  {
    "text": "and validation.",
    "start": "400395",
    "end": "401020"
  },
  {
    "text": "And interestingly,\nthe validation",
    "start": "401020",
    "end": "402569"
  },
  {
    "text": "starts off a little higher\nthan the training data.",
    "start": "402570",
    "end": "404653"
  },
  {
    "text": "But in the end, they're\nrelatively comparable.",
    "start": "404653",
    "end": "407220"
  },
  {
    "text": "But that's just\nluck of the draw.",
    "start": "407220",
    "end": "410820"
  },
  {
    "text": "It's about 95% accuracy.",
    "start": "410820",
    "end": "414000"
  },
  {
    "text": "Yes, here's a-- we can evaluate\nthe test accuracy about just",
    "start": "414000",
    "end": "417780"
  },
  {
    "text": "over 95%.",
    "start": "417780",
    "end": "420389"
  },
  {
    "text": "OK.",
    "start": "420390",
    "end": "421950"
  },
  {
    "text": "So the last thing that we will\nnot go over for the MNIST data",
    "start": "421950",
    "end": "426150"
  },
  {
    "text": "is how to fit just a very\nsimple multinomial regression",
    "start": "426150",
    "end": "431550"
  },
  {
    "text": "model rather than a hidden--",
    "start": "431550",
    "end": "433889"
  },
  {
    "text": "a neural network model.",
    "start": "433890",
    "end": "435030"
  },
  {
    "text": "Oh, right.",
    "start": "435030",
    "end": "435870"
  },
  {
    "text": "Using basically the\nsame code, right?",
    "start": "435870",
    "end": "437520"
  },
  {
    "text": "Yes.",
    "start": "437520",
    "end": "437910"
  },
  {
    "text": "Yeah.",
    "start": "437910",
    "end": "438410"
  },
  {
    "text": "So there's just no ReLU,\nno dropout, just a simple--",
    "start": "438410",
    "end": "441007"
  },
  {
    "text": "And no hidden layer.",
    "start": "441007",
    "end": "441840"
  },
  {
    "text": "Yeah, that's right.",
    "start": "441840",
    "end": "442632"
  },
  {
    "text": "And that's just--\nthe only thing that",
    "start": "442632",
    "end": "445406"
  },
  {
    "text": "is different between this\none and the previous one",
    "start": "445407",
    "end": "447490"
  },
  {
    "text": "is that there was a nonlinear\nfunction to get the 10 scores.",
    "start": "447490",
    "end": "450099"
  },
  {
    "text": "Here it's just a\nlinear function.",
    "start": "450100",
    "end": "452080"
  },
  {
    "text": "And last, let's wrap up with\njust looking at its accuracy.",
    "start": "452080",
    "end": "457629"
  },
  {
    "text": "It gets about 90%\naccuracy on the test data.",
    "start": "457630",
    "end": "460473"
  },
  {
    "text": "That's still pretty\ngood actually.",
    "start": "460473",
    "end": "461889"
  },
  {
    "text": "It's still pretty good.",
    "start": "461890",
    "end": "463330"
  },
  {
    "text": "OK.",
    "start": "463330",
    "end": "464879"
  },
  {
    "start": "464880",
    "end": "469000"
  }
]
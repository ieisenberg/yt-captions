[
  {
    "text": "Thanks so much to the\norganizers for inviting me here.",
    "start": "10870",
    "end": "14830"
  },
  {
    "text": "It's really great to have the\nopportunity to present here.",
    "start": "14830",
    "end": "19060"
  },
  {
    "text": "And my name is Annie Chen.",
    "start": "19060",
    "end": "21189"
  },
  {
    "text": "I'm a third-year computer\nscience PhD student here",
    "start": "21190",
    "end": "24400"
  },
  {
    "text": "at Stanford.",
    "start": "24400",
    "end": "25570"
  },
  {
    "text": "I'm advised by Chelsea Finn.",
    "start": "25570",
    "end": "26980"
  },
  {
    "text": "And today, I'm really excited\nto present on some of my work",
    "start": "26980",
    "end": "30670"
  },
  {
    "text": "on single-life robot\ndeployment adapting on the fly",
    "start": "30670",
    "end": "34510"
  },
  {
    "text": "to novel scenarios.",
    "start": "34510",
    "end": "38180"
  },
  {
    "text": "So, in the past few\nyears, we've seen",
    "start": "38180",
    "end": "41180"
  },
  {
    "text": "a lot of amazing recent advances\nin autonomous robots building",
    "start": "41180",
    "end": "45950"
  },
  {
    "text": "on years of prior work.",
    "start": "45950",
    "end": "47810"
  },
  {
    "text": "So these are some recent demos\nfrom Google, Toyota Research",
    "start": "47810",
    "end": "51440"
  },
  {
    "text": "Institute, and also\nsome of my lab mates.",
    "start": "51440",
    "end": "55640"
  },
  {
    "text": "And so it's really exciting.",
    "start": "55640",
    "end": "57170"
  },
  {
    "text": "Now, we have robots that\ncan do tasks, that would",
    "start": "57170",
    "end": "59690"
  },
  {
    "text": "be helpful in many settings.",
    "start": "59690",
    "end": "62300"
  },
  {
    "text": "But generally, these\nstill only work in",
    "start": "62300",
    "end": "64640"
  },
  {
    "text": "pretty controlled environments.",
    "start": "64640",
    "end": "66740"
  },
  {
    "text": "So what's currently\npreventing all of these robots",
    "start": "66740",
    "end": "69350"
  },
  {
    "text": "from helping out\nin the real world",
    "start": "69350",
    "end": "72409"
  },
  {
    "text": "beyond controlled environments.",
    "start": "72410",
    "end": "74720"
  },
  {
    "text": "So the problem is that even\nequipped with prior experience",
    "start": "77350",
    "end": "81130"
  },
  {
    "text": "and pre-training,\nrobots will encounter",
    "start": "81130",
    "end": "84790"
  },
  {
    "text": "a wide variety of\nout-of-distribution situations",
    "start": "84790",
    "end": "88420"
  },
  {
    "text": "at deployment time.",
    "start": "88420",
    "end": "89619"
  },
  {
    "text": "And these might require a large\namount of on the fly adaptation.",
    "start": "89620",
    "end": "94780"
  },
  {
    "text": "And robots often\ngenerally struggle",
    "start": "94780",
    "end": "98530"
  },
  {
    "text": "to adapt on-the-fly to\nunexpected circumstances.",
    "start": "98530",
    "end": "102760"
  },
  {
    "text": "And here's an example of this\nhappening in the real world.",
    "start": "102760",
    "end": "105410"
  },
  {
    "text": "So, here, we have\na legged robot.",
    "start": "105410",
    "end": "107410"
  },
  {
    "text": "And this is part of the\npolice force in New York.",
    "start": "107410",
    "end": "110320"
  },
  {
    "text": "They just got these\nthis is from April 2023.",
    "start": "110320",
    "end": "113710"
  },
  {
    "text": "And I think this is\na collapsed garage.",
    "start": "113710",
    "end": "115930"
  },
  {
    "text": "So they send the robot in to\ndo some search and rescue.",
    "start": "115930",
    "end": "120550"
  },
  {
    "text": "But as soon as it hits\nsome unfamiliar terrain,",
    "start": "120550",
    "end": "123460"
  },
  {
    "text": "it falls over.",
    "start": "123460",
    "end": "125560"
  },
  {
    "text": "And so this isn't great.",
    "start": "125560",
    "end": "127000"
  },
  {
    "text": "We want to avoid things\nlike this happening,",
    "start": "127000",
    "end": "130060"
  },
  {
    "text": "especially as we\nstart to incorporate",
    "start": "130060",
    "end": "132250"
  },
  {
    "text": "real robots in the world.",
    "start": "132250",
    "end": "136160"
  },
  {
    "text": "And so, yeah, the issue here is\nthat we can't often anticipate",
    "start": "136160",
    "end": "143630"
  },
  {
    "text": "every possible test scenario.",
    "start": "143630",
    "end": "146240"
  },
  {
    "text": "For example, so on\nthe previous slide,",
    "start": "146240",
    "end": "148160"
  },
  {
    "text": "a search and rescue robot\nmay encounter novel obstacles",
    "start": "148160",
    "end": "151280"
  },
  {
    "text": "while traversing a building.",
    "start": "151280",
    "end": "153590"
  },
  {
    "text": "A robot exploring on\nMars looking for water",
    "start": "153590",
    "end": "156170"
  },
  {
    "text": "will have to contend with\nsome unknown terrain probably.",
    "start": "156170",
    "end": "161150"
  },
  {
    "text": "And a household robot\ncleaning up a new spill",
    "start": "161150",
    "end": "164510"
  },
  {
    "text": "might have to pick up\nan unfamiliar bowl.",
    "start": "164510",
    "end": "168610"
  },
  {
    "text": "So I'm really\ninterested in how can we",
    "start": "168610",
    "end": "170920"
  },
  {
    "text": "get robots that adapt on\nthe fly at deployment time.",
    "start": "170920",
    "end": "177030"
  },
  {
    "text": "Now, in principle,\nreinforcement learning",
    "start": "177030",
    "end": "179880"
  },
  {
    "text": "provides a framework\nfor allowing robots",
    "start": "179880",
    "end": "182220"
  },
  {
    "text": "to adapt autonomously\nfrom their own experience.",
    "start": "182220",
    "end": "187590"
  },
  {
    "text": "But currently, in\npractice, it doesn't",
    "start": "187590",
    "end": "190050"
  },
  {
    "text": "work to just take\nthese algorithms",
    "start": "190050",
    "end": "191910"
  },
  {
    "text": "and apply them during\ndeployment to have",
    "start": "191910",
    "end": "194760"
  },
  {
    "text": "robots that adapt on the fly.",
    "start": "194760",
    "end": "196860"
  },
  {
    "text": "And this is because of\nseveral different challenges",
    "start": "196860",
    "end": "200130"
  },
  {
    "text": "with this approach.",
    "start": "200130",
    "end": "201330"
  },
  {
    "text": "So standard RL algorithms\noften need a lot of feedback",
    "start": "201330",
    "end": "205020"
  },
  {
    "text": "in the form of some\nreward function.",
    "start": "205020",
    "end": "207690"
  },
  {
    "text": "And it's often difficult to\nconstruct a good dense reward,",
    "start": "207690",
    "end": "212010"
  },
  {
    "text": "especially for\nunseen situations.",
    "start": "212010",
    "end": "215099"
  },
  {
    "text": "And these methods\noften also need",
    "start": "215100",
    "end": "217200"
  },
  {
    "text": "to be able to retry\nthe task many times",
    "start": "217200",
    "end": "220140"
  },
  {
    "text": "in order to learn\nhow to complete it.",
    "start": "220140",
    "end": "222430"
  },
  {
    "text": "And so this often requires\nhuman intervention",
    "start": "222430",
    "end": "225000"
  },
  {
    "text": "to come in and reset the\nrobot over and over again.",
    "start": "225000",
    "end": "228330"
  },
  {
    "text": "And also, a lot of reinforcement\nlearning algorithms",
    "start": "228330",
    "end": "231810"
  },
  {
    "text": "learn from scratch.",
    "start": "231810",
    "end": "233190"
  },
  {
    "text": "And we really want to build\ntowards lifelong agents that",
    "start": "233190",
    "end": "237300"
  },
  {
    "text": "can leverage prior experience so\nthat they can adapt on the fly",
    "start": "237300",
    "end": "242850"
  },
  {
    "text": "from what they already know.",
    "start": "242850",
    "end": "245130"
  },
  {
    "text": "So an alternative paradigm\nis visa-free reinforcement",
    "start": "248140",
    "end": "251860"
  },
  {
    "text": "learning.",
    "start": "251860",
    "end": "252970"
  },
  {
    "text": "Where instead of having a\nhuman come and reset the robot,",
    "start": "252970",
    "end": "256750"
  },
  {
    "text": "the robot actually practices\nboth learning the task",
    "start": "256750",
    "end": "259239"
  },
  {
    "text": "and learning to undo the task.",
    "start": "259240",
    "end": "260708"
  },
  {
    "text": "So it can keep practicing\nwithout human interventions.",
    "start": "260709",
    "end": "264670"
  },
  {
    "text": "However, this is a step\nin the right direction.",
    "start": "264670",
    "end": "267490"
  },
  {
    "text": "But we really want\na paradigm that",
    "start": "267490",
    "end": "269440"
  },
  {
    "text": "focuses on adapting to\nnew unseen scenarios",
    "start": "269440",
    "end": "273640"
  },
  {
    "text": "and also better leverages\nits prior experience.",
    "start": "273640",
    "end": "278740"
  },
  {
    "text": "So we introduce\na third paradigm.",
    "start": "278740",
    "end": "282039"
  },
  {
    "text": "And we call it single-life\nreinforcement learning in hopes",
    "start": "282040",
    "end": "285580"
  },
  {
    "text": "that it may better\nreflect these challenges.",
    "start": "285580",
    "end": "287770"
  },
  {
    "text": "So in this setting, the agent\nis given some prior experience.",
    "start": "287770",
    "end": "291039"
  },
  {
    "text": "And maybe you can even already\ndo the task to some degree.",
    "start": "291040",
    "end": "293980"
  },
  {
    "text": "But then it encounters\nan out-of-distribution",
    "start": "293980",
    "end": "296950"
  },
  {
    "text": "or a new scenario at test time.",
    "start": "296950",
    "end": "298690"
  },
  {
    "text": "And it must adapt\nto solve that task",
    "start": "298690",
    "end": "300490"
  },
  {
    "text": "without any human\ninterventions or supervision.",
    "start": "300490",
    "end": "304120"
  },
  {
    "text": "And it needs to figure out\nhow to handle the situation",
    "start": "304120",
    "end": "308380"
  },
  {
    "text": "within a single episode.",
    "start": "308380",
    "end": "310390"
  },
  {
    "text": "And so that's why we\ncall it a single life.",
    "start": "310390",
    "end": "314430"
  },
  {
    "text": "So, as an instantiation\nof single-life RL,",
    "start": "314430",
    "end": "319360"
  },
  {
    "text": "here the agent has been\ngiven prior knowledge",
    "start": "319360",
    "end": "321550"
  },
  {
    "text": "on how to run in an\nenvironment with no obstacles.",
    "start": "321550",
    "end": "324159"
  },
  {
    "text": "And we evaluate its ability\nto adapt in a single episode",
    "start": "324160",
    "end": "328030"
  },
  {
    "text": "to an environment\nwith obstacles.",
    "start": "328030",
    "end": "330970"
  },
  {
    "text": "So while we might just\ntry to run reinforcement",
    "start": "330970",
    "end": "334840"
  },
  {
    "text": "learning at test time in order\nto adapt to these obstacles.",
    "start": "334840",
    "end": "338560"
  },
  {
    "text": "But here as you can see, when\nthe agent makes a mistake,",
    "start": "338560",
    "end": "342160"
  },
  {
    "text": "and it falls out\nof distribution,",
    "start": "342160",
    "end": "344170"
  },
  {
    "text": "it can no longer rely\non resets to recover.",
    "start": "344170",
    "end": "346960"
  },
  {
    "text": "So what happens is that the\nalgorithm will just get stuck.",
    "start": "346960",
    "end": "351280"
  },
  {
    "text": "And it won't be able to\nhandle this scenario.",
    "start": "351280",
    "end": "354220"
  },
  {
    "text": "So existing reinforcement\nlearning algorithms really",
    "start": "354220",
    "end": "356800"
  },
  {
    "text": "don't allow us to have robots\nthat actually adapt on the fly",
    "start": "356800",
    "end": "360159"
  },
  {
    "text": "during deployment.",
    "start": "360160",
    "end": "361600"
  },
  {
    "text": "And overall, I think this\nis a generally really",
    "start": "361600",
    "end": "364120"
  },
  {
    "text": "interesting problem, there's\na lot of room for progress.",
    "start": "364120",
    "end": "367810"
  },
  {
    "text": "And so one idea that we've\nhad towards this problem",
    "start": "367810",
    "end": "371950"
  },
  {
    "text": "is to have robots not just\nadapt in the low-level space",
    "start": "371950",
    "end": "374980"
  },
  {
    "text": "of actions, but also adapt\nin the space of behaviors",
    "start": "374980",
    "end": "378560"
  },
  {
    "text": "to figure out how to handle a\nnovel scenario at deployment",
    "start": "378560",
    "end": "382730"
  },
  {
    "text": "time.",
    "start": "382730",
    "end": "383370"
  },
  {
    "text": "So, in particular, if the robot\nhas some pretrained behaviors,",
    "start": "383370",
    "end": "387320"
  },
  {
    "text": "like it knows how to\nwalk slide crouch,",
    "start": "387320",
    "end": "390380"
  },
  {
    "text": "could we get it to handle new\nscenarios more efficiently",
    "start": "390380",
    "end": "395090"
  },
  {
    "text": "by adapting in the space\nof these behaviors.",
    "start": "395090",
    "end": "399690"
  },
  {
    "text": "So giving some\npre-trained behaviors,",
    "start": "399690",
    "end": "402510"
  },
  {
    "text": "then within a single\nepisode test time,",
    "start": "402510",
    "end": "404520"
  },
  {
    "text": "we want a robot to be able\nto handle typical conditions,",
    "start": "404520",
    "end": "407669"
  },
  {
    "text": "but also to be able to\nhandle slippery conditions,",
    "start": "407670",
    "end": "410400"
  },
  {
    "text": "maybe it accidentally\ndamages its leg in the middle",
    "start": "410400",
    "end": "414690"
  },
  {
    "text": "of deployment, and so on.",
    "start": "414690",
    "end": "416700"
  },
  {
    "text": "And all of these are\nthings that it might not",
    "start": "416700",
    "end": "419040"
  },
  {
    "text": "have seen during training.",
    "start": "419040",
    "end": "421410"
  },
  {
    "text": "And our hope is that maybe it\ncan handle these conditions",
    "start": "421410",
    "end": "424110"
  },
  {
    "text": "better by trying different\nbehaviors that it knows",
    "start": "424110",
    "end": "428280"
  },
  {
    "text": "and modulating between them.",
    "start": "428280",
    "end": "431600"
  },
  {
    "text": "So, now, there's definitely\na rich body of work",
    "start": "431600",
    "end": "434420"
  },
  {
    "text": "that does look at how to\ncombine prior behaviors to solve",
    "start": "434420",
    "end": "438290"
  },
  {
    "text": "long-horizon tasks.",
    "start": "438290",
    "end": "440090"
  },
  {
    "text": "For example, hierarchical\nreinforcement learning.",
    "start": "440090",
    "end": "443000"
  },
  {
    "text": "And so many of these train\na high-level policy that",
    "start": "443000",
    "end": "447440"
  },
  {
    "text": "learns to choose behaviors.",
    "start": "447440",
    "end": "449030"
  },
  {
    "text": "But the issue is that\ngetting such a policy",
    "start": "449030",
    "end": "452389"
  },
  {
    "text": "often requires an additional\nonline training phase.",
    "start": "452390",
    "end": "456020"
  },
  {
    "text": "And this may need a lot of\nonline samples to learn.",
    "start": "456020",
    "end": "459470"
  },
  {
    "text": "So this isn't effective for\nlearning to adapt quickly",
    "start": "459470",
    "end": "462590"
  },
  {
    "text": "within a single life.",
    "start": "462590",
    "end": "465530"
  },
  {
    "text": "So is there a way\nthat we can quickly",
    "start": "465530",
    "end": "467720"
  },
  {
    "text": "figure out which behaviors are\nrelevant at each time step?",
    "start": "467720",
    "end": "471170"
  },
  {
    "text": "We propose a method called\nrobust autonomous modulation",
    "start": "474590",
    "end": "478220"
  },
  {
    "text": "or ROAM.",
    "start": "478220",
    "end": "479090"
  },
  {
    "text": "And the key observation is\nto leverage the expressive",
    "start": "479090",
    "end": "482600"
  },
  {
    "text": "power of each behavior's value\nfunction to guide the selection.",
    "start": "482600",
    "end": "487340"
  },
  {
    "text": "Value functions inherently\ncontain detailed information",
    "start": "487340",
    "end": "490639"
  },
  {
    "text": "about potential rewards\nassociated with different states",
    "start": "490640",
    "end": "493310"
  },
  {
    "text": "for each behavior.",
    "start": "493310",
    "end": "495110"
  },
  {
    "text": "So for a given behavior,\nif it can likely",
    "start": "495110",
    "end": "499580"
  },
  {
    "text": "succeed in that scenario, the\nvalue function at that state",
    "start": "499580",
    "end": "503870"
  },
  {
    "text": "should be pretty high.",
    "start": "503870",
    "end": "506680"
  },
  {
    "text": "So this means that at each time\nstep during the single life,",
    "start": "506680",
    "end": "510490"
  },
  {
    "text": "if we choose one\nof the behaviors",
    "start": "510490",
    "end": "512799"
  },
  {
    "text": "with a high value at\nthe current state,",
    "start": "512799",
    "end": "515049"
  },
  {
    "text": "perhaps that will lead\nus to handle the novelty",
    "start": "515049",
    "end": "517809"
  },
  {
    "text": "and solve the task.",
    "start": "517809",
    "end": "519280"
  },
  {
    "text": "And since we already have\naccess to value functions",
    "start": "519280",
    "end": "522010"
  },
  {
    "text": "from pre-training the\nbehaviors, this approach",
    "start": "522010",
    "end": "524830"
  },
  {
    "text": "doesn't require any additional\ntraining or data collection.",
    "start": "524830",
    "end": "529870"
  },
  {
    "text": "The issue is naively using\npre-trained value functions",
    "start": "529870",
    "end": "534310"
  },
  {
    "text": "may not lead to\nhigh-reward behaviors.",
    "start": "534310",
    "end": "536110"
  },
  {
    "text": "And this is because these\npre-trained value functions",
    "start": "536110",
    "end": "539050"
  },
  {
    "text": "tend to overestimate in\nout-of-distribution states.",
    "start": "539050",
    "end": "542080"
  },
  {
    "text": "And we don't want\nthis because we",
    "start": "542080",
    "end": "544600"
  },
  {
    "text": "don't want one of the\nbehaviors mistakenly",
    "start": "544600",
    "end": "546670"
  },
  {
    "text": "giving a high value to a\nstate just because it's never",
    "start": "546670",
    "end": "549730"
  },
  {
    "text": "seen it before.",
    "start": "549730",
    "end": "550435"
  },
  {
    "text": "So with the existing prior\ndata from each behavior,",
    "start": "554000",
    "end": "557930"
  },
  {
    "text": "we're going to do an\ninitial fine-tuning",
    "start": "557930",
    "end": "559970"
  },
  {
    "text": "step to correct this.",
    "start": "559970",
    "end": "561649"
  },
  {
    "text": "And fine-tune the\nvalue functions",
    "start": "561650",
    "end": "563450"
  },
  {
    "text": "with an additional loss that\nminimizes overestimation",
    "start": "563450",
    "end": "567230"
  },
  {
    "text": "of the values at states for\nwhich a different behavior is",
    "start": "567230",
    "end": "571610"
  },
  {
    "text": "better.",
    "start": "571610",
    "end": "572930"
  },
  {
    "text": "So, specifically, we have\nthe standard Bellman error",
    "start": "572930",
    "end": "576320"
  },
  {
    "text": "on the left.",
    "start": "576320",
    "end": "576830"
  },
  {
    "text": "And then we additionally\nadd a cross-entropy loss",
    "start": "576830",
    "end": "579770"
  },
  {
    "text": "between the softmax\nof the values",
    "start": "579770",
    "end": "582230"
  },
  {
    "text": "of the behaviors and\nthe behavior index",
    "start": "582230",
    "end": "584779"
  },
  {
    "text": "from which that\nstate was visited.",
    "start": "584780",
    "end": "587390"
  },
  {
    "text": "So what this does is it\njust it trains each behavior",
    "start": "587390",
    "end": "591860"
  },
  {
    "text": "to separate in\nvalue between states",
    "start": "591860",
    "end": "594829"
  },
  {
    "text": "that it visits versus ones\nthat other behaviors visit.",
    "start": "594830",
    "end": "598490"
  },
  {
    "text": "So it pushes up the\nvalue for states",
    "start": "598490",
    "end": "600290"
  },
  {
    "text": "that are visited\nby that behavior",
    "start": "600290",
    "end": "603290"
  },
  {
    "text": "and then pushes\ndown for states that",
    "start": "603290",
    "end": "605120"
  },
  {
    "text": "are visited by other behaviors.",
    "start": "605120",
    "end": "607250"
  },
  {
    "text": "And in this way,\nthe value functions",
    "start": "607250",
    "end": "609560"
  },
  {
    "text": "are then less likely\nto overestimate",
    "start": "609560",
    "end": "611570"
  },
  {
    "text": "at unfamiliar states.",
    "start": "611570",
    "end": "615040"
  },
  {
    "text": "And then once we have these\nfine-tuned value functions",
    "start": "615040",
    "end": "618310"
  },
  {
    "text": "for each of our\nbehaviors at test time,",
    "start": "618310",
    "end": "620470"
  },
  {
    "text": "we'll sample a behavior from\nthe softmax distribution given",
    "start": "620470",
    "end": "625870"
  },
  {
    "text": "by the behaviors values\nat that current state",
    "start": "625870",
    "end": "628210"
  },
  {
    "text": "And then execute an action\nfrom that behavior update.",
    "start": "628210",
    "end": "632140"
  },
  {
    "text": "And then that behavior\nwith fine tuning and then",
    "start": "632140",
    "end": "634750"
  },
  {
    "text": "move on to the next\ntime step where we can",
    "start": "634750",
    "end": "637390"
  },
  {
    "text": "repeat this selection process.",
    "start": "637390",
    "end": "639580"
  },
  {
    "text": "And importantly, we can update\nthat behavior with fine-tuning.",
    "start": "639580",
    "end": "642490"
  },
  {
    "text": "So we're able to both\nadapt at each time step",
    "start": "642490",
    "end": "646360"
  },
  {
    "text": "at the behavior level.",
    "start": "646360",
    "end": "647709"
  },
  {
    "text": "But then also, we can\nfine-tune the parameters",
    "start": "647710",
    "end": "650470"
  },
  {
    "text": "of individual behaviors.",
    "start": "650470",
    "end": "652540"
  },
  {
    "text": "So our selection\nmechanism quickly",
    "start": "656280",
    "end": "658980"
  },
  {
    "text": "identifies appropriate\nbehaviors in a given situation.",
    "start": "658980",
    "end": "662310"
  },
  {
    "text": "So this circumvents\nthe need to learn",
    "start": "662310",
    "end": "664830"
  },
  {
    "text": "a separate high-level\ncontroller or adaptation module.",
    "start": "664830",
    "end": "668490"
  },
  {
    "text": "And this approach is\nalso agnostic to how",
    "start": "668490",
    "end": "672420"
  },
  {
    "text": "the policies and value\nfunctions of the prior behaviors",
    "start": "672420",
    "end": "675570"
  },
  {
    "text": "are trained.",
    "start": "675570",
    "end": "677160"
  },
  {
    "text": "And it can potentially provide\nimprovements in new situations",
    "start": "677160",
    "end": "681360"
  },
  {
    "text": "with either a small or large\nnumber of pre-trained behaviors.",
    "start": "681360",
    "end": "686700"
  },
  {
    "text": "And then finally, the\nadaptation process",
    "start": "686700",
    "end": "690150"
  },
  {
    "text": "all happens within a\nsingle episode at test time",
    "start": "690150",
    "end": "692700"
  },
  {
    "text": "to a variety of situations\ninstead of learning how",
    "start": "692700",
    "end": "696480"
  },
  {
    "text": "to adapt across many episodes.",
    "start": "696480",
    "end": "698760"
  },
  {
    "text": "We have some theory\nin the paper on why",
    "start": "702020",
    "end": "704330"
  },
  {
    "text": "the additional\ncross-entropy loss helps.",
    "start": "704330",
    "end": "706460"
  },
  {
    "text": "But I'm just think it gets\ninto the nitty gritty.",
    "start": "706460",
    "end": "709610"
  },
  {
    "text": "So skip that.",
    "start": "709610",
    "end": "713329"
  },
  {
    "text": "So how does ROAM compare\nto prior methods?",
    "start": "713330",
    "end": "717170"
  },
  {
    "text": "So, in simulation, we\nstarted with a simulated",
    "start": "717170",
    "end": "719959"
  },
  {
    "text": "go one quadruped robot.",
    "start": "719960",
    "end": "722210"
  },
  {
    "text": "And we evaluate two separate\nthings varying joint stiffness",
    "start": "722210",
    "end": "725690"
  },
  {
    "text": "and varying friction.",
    "start": "725690",
    "end": "729050"
  },
  {
    "text": "And we evaluate\nthe number of steps",
    "start": "729050",
    "end": "731360"
  },
  {
    "text": "to succeed in the single life.",
    "start": "731360",
    "end": "732769"
  },
  {
    "text": "So the lower the\nnumber, the better.",
    "start": "732770",
    "end": "737490"
  },
  {
    "text": "We compared to a\nstate-of-the-art fine-tuning",
    "start": "737490",
    "end": "740100"
  },
  {
    "text": "method RLPD, a\nstate-of-the-art meta-RL RMA,",
    "start": "740100",
    "end": "744660"
  },
  {
    "text": "as well as using a high-level\nclassifier to predict",
    "start": "744660",
    "end": "749274"
  },
  {
    "text": "the skills.",
    "start": "749275",
    "end": "749775"
  },
  {
    "text": "So, for the stiffness\nevaluation on the left,",
    "start": "752760",
    "end": "755700"
  },
  {
    "text": "the pre-trained skills\nthat it has corresponds",
    "start": "755700",
    "end": "758070"
  },
  {
    "text": "to having different\njoints that are",
    "start": "758070",
    "end": "760320"
  },
  {
    "text": "frozen during training,\nbut then at test time,",
    "start": "760320",
    "end": "762390"
  },
  {
    "text": "a new joint is frozen.",
    "start": "762390",
    "end": "763770"
  },
  {
    "text": "And then for the\nfriction, there are",
    "start": "763770",
    "end": "766217"
  },
  {
    "text": "skills that were trained\nwith one of the four feet",
    "start": "766217",
    "end": "768300"
  },
  {
    "text": "having low friction.",
    "start": "768300",
    "end": "769320"
  },
  {
    "text": "And then at test time,\nthe friction of one or two",
    "start": "769320",
    "end": "772120"
  },
  {
    "text": "of the feet is changed\nto be lower than anything",
    "start": "772120",
    "end": "774120"
  },
  {
    "text": "that was seen during training.",
    "start": "774120",
    "end": "777390"
  },
  {
    "text": "So, first, looking at\nthese prior methods",
    "start": "777390",
    "end": "779970"
  },
  {
    "text": "both RLPD fine tuning\nand RMA struggle,",
    "start": "779970",
    "end": "783209"
  },
  {
    "text": "especially in the stiffness\nsetting on the left",
    "start": "783210",
    "end": "785910"
  },
  {
    "text": "the bars are really high.",
    "start": "785910",
    "end": "787829"
  },
  {
    "text": "Again, lower bars\nis better here.",
    "start": "787830",
    "end": "790920"
  },
  {
    "text": "So that demonstrates the\nimportance in this evaluation",
    "start": "790920",
    "end": "796200"
  },
  {
    "text": "setting, especially of adapting\nin the space of behaviors",
    "start": "796200",
    "end": "799440"
  },
  {
    "text": "rather than just\nthe space of actions",
    "start": "799440",
    "end": "802770"
  },
  {
    "text": "for more efficient adaptation.",
    "start": "802770",
    "end": "805230"
  },
  {
    "text": "And HLC struggles, especially in\nthe friction suite on the right.",
    "start": "805230",
    "end": "811480"
  },
  {
    "text": "And then this may be\nbecause it doesn't",
    "start": "811480",
    "end": "815529"
  },
  {
    "text": "take into account the value of\nthe behavior at a given state.",
    "start": "815530",
    "end": "818140"
  },
  {
    "text": "It only takes into account\nstate visitation frequency.",
    "start": "818140",
    "end": "824290"
  },
  {
    "text": "And then we evaluate\nROAM which is",
    "start": "824290",
    "end": "826720"
  },
  {
    "text": "shown in the rightmost\nbar in orange,",
    "start": "826720",
    "end": "830050"
  },
  {
    "text": "as well as ROAM [? NOFT ?]\nwhich is an ablation that",
    "start": "830050",
    "end": "833440"
  },
  {
    "text": "doesn't use the additional\ncross-entropy loss that I",
    "start": "833440",
    "end": "836080"
  },
  {
    "text": "mentioned.",
    "start": "836080",
    "end": "837610"
  },
  {
    "text": "So, especially in the\ndynamic friction eval,",
    "start": "837610",
    "end": "841269"
  },
  {
    "text": "having the additional cross\nentropy term in the loss",
    "start": "841270",
    "end": "843580"
  },
  {
    "text": "function is really important\nto encourage better behavior",
    "start": "843580",
    "end": "846730"
  },
  {
    "text": "selection in different\nregions of the state space.",
    "start": "846730",
    "end": "850600"
  },
  {
    "text": "And overall for ROAM,\nwe're able to get over",
    "start": "850600",
    "end": "855910"
  },
  {
    "text": "2x faster adaptation.",
    "start": "855910",
    "end": "858279"
  },
  {
    "text": "So it's able to get\nto the goal, yeah,",
    "start": "858280",
    "end": "862090"
  },
  {
    "text": "twice as fast compared\nto the best approach.",
    "start": "862090",
    "end": "866940"
  },
  {
    "text": "And so can this actually\nwork on a real robot?",
    "start": "866940",
    "end": "870420"
  },
  {
    "text": "So we got to go one and\npre-trained behaviors",
    "start": "870420",
    "end": "874980"
  },
  {
    "text": "walking with different\nlakes frozen.",
    "start": "874980",
    "end": "877860"
  },
  {
    "text": "And then we looked at three\ndifferent test scenarios",
    "start": "877860",
    "end": "880213"
  },
  {
    "text": "that were pretty\ndifferent from anything",
    "start": "880213",
    "end": "881880"
  },
  {
    "text": "that it saw during training.",
    "start": "881880",
    "end": "884395"
  },
  {
    "text": "So the first scenario\nthat we looked at",
    "start": "884395",
    "end": "886020"
  },
  {
    "text": "was to put roller skates on the\nfront two feet of the quadruped.",
    "start": "886020",
    "end": "890310"
  },
  {
    "text": "And if you just evaluate\nthe walking policy,",
    "start": "890310",
    "end": "893670"
  },
  {
    "text": "it basically falls over\nimmediately and really",
    "start": "893670",
    "end": "896760"
  },
  {
    "text": "isn't able to handle\nthis distribution shift.",
    "start": "896760",
    "end": "901410"
  },
  {
    "text": "If you try using something\nlike a high-level classifier,",
    "start": "901410",
    "end": "904050"
  },
  {
    "text": "this also struggles\nto get anywhere.",
    "start": "904050",
    "end": "907740"
  },
  {
    "text": "And then this is with ROAM.",
    "start": "907740",
    "end": "910620"
  },
  {
    "text": "And so we see that even\nthough this scenario is",
    "start": "910620",
    "end": "913650"
  },
  {
    "text": "super out-of-distribution\ncompared",
    "start": "913650",
    "end": "915450"
  },
  {
    "text": "to what it was trained\non, it's able to adapt",
    "start": "915450",
    "end": "919290"
  },
  {
    "text": "within this single\nepisode actually.",
    "start": "919290",
    "end": "922259"
  },
  {
    "text": "And so it actually\nenables the robot",
    "start": "922260",
    "end": "924210"
  },
  {
    "text": "to slide forward\non roller skates",
    "start": "924210",
    "end": "925740"
  },
  {
    "text": "without ever wearing\nthem during training.",
    "start": "925740",
    "end": "928795"
  },
  {
    "text": "We also looked at\nsome other scenarios",
    "start": "931990",
    "end": "934839"
  },
  {
    "text": "like carrying heavy luggage.",
    "start": "934840",
    "end": "936670"
  },
  {
    "text": "So, here, a case\nof heavy luggage",
    "start": "936670",
    "end": "940779"
  },
  {
    "text": "is tied to the back\nleft leg of the robot.",
    "start": "940780",
    "end": "943330"
  },
  {
    "text": "And again, the robot is\nable to bring it forward,",
    "start": "943330",
    "end": "945460"
  },
  {
    "text": "even though it didn't see\nany luggage during training.",
    "start": "945460",
    "end": "948820"
  },
  {
    "text": "And this corresponds\nto about 13 pounds.",
    "start": "948820",
    "end": "953020"
  },
  {
    "text": "And then in this\nlast scenario, we",
    "start": "953020",
    "end": "956950"
  },
  {
    "text": "started with the heavy luggage.",
    "start": "956950",
    "end": "958270"
  },
  {
    "text": "And then midway through,\nwe removed the backpack,",
    "start": "958270",
    "end": "962830"
  },
  {
    "text": "which is actually quite heavy.",
    "start": "962830",
    "end": "964300"
  },
  {
    "text": "And so you see that\nthe robot is actually",
    "start": "964300",
    "end": "966970"
  },
  {
    "text": "speeding up here a little bit.",
    "start": "966970",
    "end": "968920"
  },
  {
    "text": "And so it's able to handle like\nthese dynamic changing payloads.",
    "start": "968920",
    "end": "972670"
  },
  {
    "text": "And it's able to continue\npulling even when",
    "start": "972670",
    "end": "975490"
  },
  {
    "text": "we put on another backpack.",
    "start": "975490",
    "end": "980170"
  },
  {
    "text": "Yeah, so I can\npull heavy luggage",
    "start": "980170",
    "end": "982450"
  },
  {
    "text": "and pull dynamic\npayloads without ever",
    "start": "982450",
    "end": "986182"
  },
  {
    "text": "pulling any object before.",
    "start": "986182",
    "end": "987265"
  },
  {
    "text": "And so across these\nthree situations,",
    "start": "990210",
    "end": "993960"
  },
  {
    "text": "we measured the average time and\nnumber of falls to completion.",
    "start": "993960",
    "end": "998700"
  },
  {
    "text": "And ROAM significantly\noutperforms",
    "start": "998700",
    "end": "1001760"
  },
  {
    "text": "using a high-level\nclassifier, as well as",
    "start": "1001760",
    "end": "1004250"
  },
  {
    "text": "the baseline walking policy.",
    "start": "1004250",
    "end": "1006740"
  },
  {
    "text": "And although none of\nthe prior behaviors",
    "start": "1006740",
    "end": "1008870"
  },
  {
    "text": "are trained to specifically\nhandle these test time",
    "start": "1008870",
    "end": "1013730"
  },
  {
    "text": "scenarios, the\nrobot can leverage",
    "start": "1013730",
    "end": "1016130"
  },
  {
    "text": "parts of each relevant\nbehavior to actually",
    "start": "1016130",
    "end": "1018440"
  },
  {
    "text": "still complete the task.",
    "start": "1018440",
    "end": "1021050"
  },
  {
    "text": "So, in these scenarios\nlike figuring out",
    "start": "1021050",
    "end": "1024020"
  },
  {
    "text": "how to quickly modulate\nin the space of behaviors,",
    "start": "1024020",
    "end": "1027199"
  },
  {
    "text": "and also balancing modulating\nin the space of behaviors",
    "start": "1027200",
    "end": "1031880"
  },
  {
    "text": "with low-level adaptation,\nprovides a mechanism",
    "start": "1031880",
    "end": "1035420"
  },
  {
    "text": "for single-life test time\nadaptation to unseen situations.",
    "start": "1035420",
    "end": "1043099"
  },
  {
    "text": "Yeah, so I'm really excited\nabout single life deployment.",
    "start": "1043099",
    "end": "1047089"
  },
  {
    "text": "It provides a natural setting in\nwhich to study autonomous robot",
    "start": "1047089",
    "end": "1050730"
  },
  {
    "text": "adaptation to novel situations.",
    "start": "1050730",
    "end": "1052590"
  },
  {
    "text": "And ROAM is simple algorithm\nfor autonomous deployment",
    "start": "1052590",
    "end": "1057000"
  },
  {
    "text": "time, this adaptation.",
    "start": "1057000",
    "end": "1060480"
  },
  {
    "text": "Yeah, so thanks to my wonderful\ncollaborators and my advisor",
    "start": "1063150",
    "end": "1068130"
  },
  {
    "text": "Chelsea Finn.",
    "start": "1068130",
    "end": "1069600"
  },
  {
    "text": "And thanks again to the\norganizers for inviting me.",
    "start": "1069600",
    "end": "1074250"
  },
  {
    "text": "And yeah, happy to get\nto present my work here",
    "start": "1074250",
    "end": "1078660"
  },
  {
    "text": "and happy to take any questions.",
    "start": "1078660",
    "end": "1081390"
  },
  {
    "text": "[APPLAUSE]",
    "start": "1081390",
    "end": "1084230"
  },
  {
    "text": "So go ahead.",
    "start": "1086560",
    "end": "1087980"
  },
  {
    "text": "Go ahead.",
    "start": "1087980",
    "end": "1088480"
  },
  {
    "text": "So for all three\nconditions, they",
    "start": "1088480",
    "end": "1091419"
  },
  {
    "text": "are all pretty trained with\nassuming some lags are frozen.",
    "start": "1091420",
    "end": "1095800"
  },
  {
    "text": "Is that correct?",
    "start": "1095800",
    "end": "1096550"
  },
  {
    "text": "Yeah, yeah.",
    "start": "1096550",
    "end": "1097420"
  },
  {
    "text": "So we were just trying\nout how well just",
    "start": "1097420",
    "end": "1105580"
  },
  {
    "text": "what different behaviors,\nwhat adaptation we could get.",
    "start": "1105580",
    "end": "1111220"
  },
  {
    "text": "And so we did pretty much the\nsimplest thing, which was just",
    "start": "1111220",
    "end": "1117070"
  },
  {
    "text": "train walking, and\nthen train walking",
    "start": "1117070",
    "end": "1118840"
  },
  {
    "text": "with different legs frozen.",
    "start": "1118840",
    "end": "1121929"
  },
  {
    "text": "And I think there's a\nlot of interesting ways",
    "start": "1121930",
    "end": "1126580"
  },
  {
    "text": "to explore and extend on what\nhappens when you have access",
    "start": "1126580",
    "end": "1132610"
  },
  {
    "text": "to different sorts of behaviors.",
    "start": "1132610",
    "end": "1134470"
  },
  {
    "text": "Yeah, is there any\nother conditions",
    "start": "1134470",
    "end": "1137020"
  },
  {
    "text": "you all be thinking\nabout pre-training",
    "start": "1137020",
    "end": "1139180"
  },
  {
    "text": "the robot with like other\nthan having a few legs frozen?",
    "start": "1139180",
    "end": "1142570"
  },
  {
    "text": "Yeah, yeah, so\nactually, one thing",
    "start": "1142570",
    "end": "1144620"
  },
  {
    "text": "that we are exploring\nright now is really",
    "start": "1144620",
    "end": "1147380"
  },
  {
    "text": "trying to start with better\npretrained behaviors.",
    "start": "1147380",
    "end": "1150590"
  },
  {
    "text": "So starting with\njumping and crouching.",
    "start": "1150590",
    "end": "1155090"
  },
  {
    "text": "And yeah, those\nsorts of things, too.",
    "start": "1155090",
    "end": "1158960"
  },
  {
    "text": "And seeing how far we can\nactually get the system to",
    "start": "1158960",
    "end": "1161149"
  },
  {
    "text": "adapt there.",
    "start": "1161150",
    "end": "1163183"
  },
  {
    "text": "But you can really explain\nwhat the difference",
    "start": "1163183",
    "end": "1165100"
  },
  {
    "text": "between the dynamic friction and\ndynamic whatever the other one",
    "start": "1165100",
    "end": "1168850"
  },
  {
    "text": "was?",
    "start": "1168850",
    "end": "1169480"
  },
  {
    "text": "Yeah, yeah.",
    "start": "1169480",
    "end": "1170110"
  },
  {
    "text": "So in the dynamic\nfriction suite,",
    "start": "1170110",
    "end": "1175030"
  },
  {
    "text": "it just refers to\ndifferent evaluations",
    "start": "1175030",
    "end": "1178240"
  },
  {
    "text": "where we're testing, where we\ntrain pre-trained behaviors",
    "start": "1178240",
    "end": "1183520"
  },
  {
    "text": "and then evaluate at test time.",
    "start": "1183520",
    "end": "1185660"
  },
  {
    "text": "And so stiffness, we just keep\none joint stiff at test time.",
    "start": "1185660",
    "end": "1192560"
  },
  {
    "text": "So our initial\ninspiration for this",
    "start": "1192560",
    "end": "1196360"
  },
  {
    "text": "was thinking about how\nmaybe a robot might",
    "start": "1196360",
    "end": "1199540"
  },
  {
    "text": "get damaged in the\nmiddle of its deployment.",
    "start": "1199540",
    "end": "1203080"
  },
  {
    "text": "And maybe it might not be able\nto use a joint or something.",
    "start": "1203080",
    "end": "1207309"
  },
  {
    "text": "And so being able\nto adapt to that.",
    "start": "1207310",
    "end": "1210640"
  },
  {
    "text": "But we couldn't actually\ndamage a robot just to see.",
    "start": "1210640",
    "end": "1214660"
  },
  {
    "text": "And then friction was just\ntrying different friction",
    "start": "1214660",
    "end": "1221380"
  },
  {
    "text": "with the feet.",
    "start": "1221380",
    "end": "1222070"
  },
  {
    "text": "All right, I don't know if\nthis is relevant at all.",
    "start": "1225410",
    "end": "1228140"
  },
  {
    "text": "But from the bio-inspired\nside, there's",
    "start": "1228140",
    "end": "1230210"
  },
  {
    "text": "been studies of daddy\nlongleg spiders, which",
    "start": "1230210",
    "end": "1233179"
  },
  {
    "text": "apparently, not rarely, will\nlose one or even two legs.",
    "start": "1233180",
    "end": "1237620"
  },
  {
    "text": "And there must be\nsome latency behavior",
    "start": "1237620",
    "end": "1240740"
  },
  {
    "text": "because they can\nmanage right away.",
    "start": "1240740",
    "end": "1242720"
  },
  {
    "text": "But by the end of the day,\nthey're walking much better.",
    "start": "1242720",
    "end": "1246169"
  },
  {
    "text": "Yeah, that's pretty cool.",
    "start": "1246170",
    "end": "1248750"
  },
  {
    "text": "Cool.",
    "start": "1248750",
    "end": "1249380"
  },
  {
    "text": "All right.",
    "start": "1249380",
    "end": "1249880"
  },
  {
    "text": "Thanks again.",
    "start": "1249880",
    "end": "1250470"
  },
  {
    "text": "Yeah, thank you so much.",
    "start": "1250470",
    "end": "1252549"
  }
]
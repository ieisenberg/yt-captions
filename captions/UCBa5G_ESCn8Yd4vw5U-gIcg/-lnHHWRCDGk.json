[
  {
    "start": "9000",
    "end": "69000"
  },
  {
    "text": "So Chris Potts is the\nProfessor and actually also the Chair of the\nDepartment of Linguistics,",
    "start": "9900",
    "end": "15180"
  },
  {
    "text": "and by courtesy also at the\nDepartment of Computer Science. And he's a great expert in\nthe area of natural language",
    "start": "15180",
    "end": "21480"
  },
  {
    "text": "understanding, so there\nwould not be a better person to hear from about\nthe topic than him,",
    "start": "21480",
    "end": "27180"
  },
  {
    "text": "and we are so grateful that\nhe could make the time. And he's actually also\nteaching the graduate course,",
    "start": "27180",
    "end": "32580"
  },
  {
    "text": "CS224U Natural Language\nUnderstanding, that we actually transformed into a professional\ncourse that is starting",
    "start": "32580",
    "end": "38820"
  },
  {
    "text": "next week on the same topic. So if you're interested\nin learning more, we have some links included\ndown below on your platform",
    "start": "38820",
    "end": "47460"
  },
  {
    "text": "you can check it out. And there's so many other things\nthat can be said about Chris.",
    "start": "47460",
    "end": "52500"
  },
  {
    "text": "He has a super interesting\npodcast he's running, so many interesting research\npapers, projects he worked on,",
    "start": "52500",
    "end": "58980"
  },
  {
    "text": "so go ahead and\nlearn more about him. You should also\nhave a little link. I think without further ado,\nI think we can kick it off,",
    "start": "58980",
    "end": "67800"
  },
  {
    "text": "Chris.\nThank you so much once again. CHRISTOPHER POTTS: Oh,\nthank you so much, Petra, for the kind words. And welcome to everyone.",
    "start": "67800",
    "end": "74280"
  },
  {
    "start": "69000",
    "end": "223000"
  },
  {
    "text": "It's wonderful to be\nhere with you all. I do think that we live in a\ngolden age for natural language",
    "start": "74280",
    "end": "80820"
  },
  {
    "text": "understanding, maybe also a\ndisconcerting age, a weird age, but certainly a time of a lot of\ninnovation and a lot of change.",
    "start": "80820",
    "end": "89100"
  },
  {
    "text": "It's sort of an interesting\nmoment for reflection for me because I started teaching my\nNLU course at Stanford in 2012,",
    "start": "90180",
    "end": "97560"
  },
  {
    "text": "about a decade ago. That feels very recent\nin my lived experience,",
    "start": "97560",
    "end": "103859"
  },
  {
    "text": "but it feels like a\ncompletely different age when it comes to\nNLU, and indeed, all",
    "start": "103860",
    "end": "109140"
  },
  {
    "text": "of artificial intelligence. I never would have\nguessed in 2012 that we would have such an\namazing array of technologies",
    "start": "109140",
    "end": "117720"
  },
  {
    "text": "and scientific\ninnovations, and that we would have these models\nthat were just so performant",
    "start": "117720",
    "end": "123479"
  },
  {
    "text": "and also so widely\ndeployed in the world. This is also a story of again,\nfor better or worse, increasing",
    "start": "123480",
    "end": "132060"
  },
  {
    "text": "societal impact. And so that does come together\nfor me into a golden age. And just to reflect\non this a little bit.",
    "start": "132060",
    "end": "138660"
  },
  {
    "text": "It's really just\namazing to think about how many of\nthese models you can get hands on with if you\nwant to right away, right?",
    "start": "138660",
    "end": "146100"
  },
  {
    "text": "You can download or use VA\nAPIs models like DALL-E 2 that do incredible\ntext-to-image generation.",
    "start": "146100",
    "end": "152820"
  },
  {
    "text": "Stable Diffusion, Midjourney,\nthey're all in that class. We also have GitHub Copilot\nbased in the Codex model",
    "start": "152820",
    "end": "159780"
  },
  {
    "text": "for doing code generation. Tons of people derive a lot\nof value from that system. You.com is at the\nleading edge I would",
    "start": "159780",
    "end": "167880"
  },
  {
    "text": "say of search technologies\nthat are changing the search experience and also leading us\nto new at better results when",
    "start": "167880",
    "end": "174180"
  },
  {
    "text": "we search on the web. Whisper AI is an incredible\nmodel from OpenAI. This does speech-to-text.",
    "start": "174180",
    "end": "180240"
  },
  {
    "text": "And this model is\na generic model that is better than the best\nuser customized models that we",
    "start": "180240",
    "end": "188580"
  },
  {
    "text": "had 10 years ago. Just astounding, not something\nI would have predicted I would have predicted, I think And then, of course, the\nstar of our show for today",
    "start": "188580",
    "end": "195480"
  },
  {
    "text": "is going to be\nthese big language models GPT-3 is the famous one. You can use it via an API.",
    "start": "195480",
    "end": "201900"
  },
  {
    "text": "We have all these open\nsource ones as well that have come out\nOPT, BLOOM, GPT-NeoX,",
    "start": "201900",
    "end": "208080"
  },
  {
    "text": "these are models that\nyou can download and work with to your heart's\ncontent provided that you have all the\ncomputing resources necessary.",
    "start": "208080",
    "end": "214980"
  },
  {
    "text": "So just incredible. And I'm sure you're\nfamiliar with this, but let's just get this\ninto our common ground here.",
    "start": "214980",
    "end": "221459"
  },
  {
    "text": "It's incredible what\nthese models can do. Here's a quick demo of GPT-3.",
    "start": "221460",
    "end": "227580"
  },
  {
    "start": "223000",
    "end": "401000"
  },
  {
    "text": "I asked the Davinci-002\nengine, in which year was Stanford University founded?",
    "start": "227580",
    "end": "233940"
  },
  {
    "text": "When did it enroll\nits first students? Who is its current president? And what is its mascot? And Davinci-002 gave a\nfluent and complete answer",
    "start": "233940",
    "end": "243239"
  },
  {
    "text": "that is correct on all counts. Just incredible. That was with Davinci-002.",
    "start": "243240",
    "end": "248280"
  },
  {
    "text": "We got a big update\nto that model in late 2022,\nthat's Davinci-003. And here I'm showing you that it\nreproduces that result exactly.",
    "start": "248280",
    "end": "256200"
  },
  {
    "text": "And I do think that Davinci-003\nis a big step forward over the previous engine.",
    "start": "256200",
    "end": "261000"
  },
  {
    "text": "Here's actually an\nexample of that. I liked to play adversarial\ngames with this model. And so I asked\nDavinci-002, would it",
    "start": "261660",
    "end": "269160"
  },
  {
    "text": "be possible to hire\na team of tamarins to help me paint\nmy house assuming I'm willing to pay them\ninsufficient quantities",
    "start": "269160",
    "end": "275400"
  },
  {
    "text": "of fruit to meet minimum wage\nrequirements in California? This is adversarial because I\nknow that these models don't",
    "start": "275400",
    "end": "282420"
  },
  {
    "text": "have a really rich understanding\nof the world we live in. They're often distracted\nby details like this.",
    "start": "282420",
    "end": "288180"
  },
  {
    "text": "And sure enough,\nDavinci-002 got confused. Yes, it would be possible\nto hire a team of tamarins",
    "start": "288180",
    "end": "293340"
  },
  {
    "text": "to paint your house. You would need to make sure\nthat you're providing them with enough fruit to meet\nminimum wage requirements",
    "start": "293340",
    "end": "298860"
  },
  {
    "text": "and so forth. So easily distracted. But I tried this again\nwith Davinci-003. And with the same question, it\ngave a very sensible answer,",
    "start": "298860",
    "end": "306780"
  },
  {
    "text": "no, it would not be possible\nto hire a team of tamarins to help you paint your house. Davinci-002 was not distracted\nby my adversarial game.",
    "start": "306780",
    "end": "314220"
  },
  {
    "text": "This is not to say that you\ncan't trick Davinci-002. Just go into Twitter and\nyou'll find examples of that,",
    "start": "314220",
    "end": "320220"
  },
  {
    "text": "but again, I do think we're\nseeing a pretty remarkable rate of progress toward these models\nbeing robust and relatively",
    "start": "320220",
    "end": "328140"
  },
  {
    "text": "trustworthy. This is also a story of\nscientific innovation. That was a brief\nanecdote, but we're",
    "start": "328140",
    "end": "334860"
  },
  {
    "text": "seeing the same level\nof progress in the tools that we use to measure system\nperformance in the field.",
    "start": "334860",
    "end": "340560"
  },
  {
    "text": "I've put this under the\nheading of benchmark saturate faster than ever. This is from a paper\nfrom 2021 that I",
    "start": "340560",
    "end": "347040"
  },
  {
    "text": "was involved with Kiela et al. Here's the framework. Along the x-axis, I have\ntime going back to the 1990s.",
    "start": "347040",
    "end": "353700"
  },
  {
    "text": "And along the y-axis, I\nhave a normalized measure of our estimate of\nhuman performance.",
    "start": "353700",
    "end": "359520"
  },
  {
    "text": "That's the red line set at 0. So MNIST digit recognition,\na grand old data",
    "start": "359520",
    "end": "365580"
  },
  {
    "text": "set in the field that\nwas launched in 1990s, and it took about\n20 years for us to surpass this estimate\nof human performance.",
    "start": "365580",
    "end": "372420"
  },
  {
    "text": "Switchboard is a similar\nstory launched in the '90s. This is the speech\nto text problem. It took about 20 years for us to\nget up past this red line here.",
    "start": "373320",
    "end": "381720"
  },
  {
    "text": "ImageNet is newer. This was launched in 2009. It took about 10 years for us\nto reach this saturation point.",
    "start": "382500",
    "end": "388620"
  },
  {
    "text": "And from here,\nthe pace is really going to pick up so SQuAD\n1.1 is question answering. That was solved in\nabout three years.",
    "start": "389220",
    "end": "396120"
  },
  {
    "text": "The response was SQuAD 2.0. That was solved in\nless than two years.",
    "start": "396780",
    "end": "401160"
  },
  {
    "start": "401000",
    "end": "626000"
  },
  {
    "text": "And then the GLUE benchmark. If you were in the field,\nyou might recall back. The GLUE benchmark\nis this big set",
    "start": "401820",
    "end": "407280"
  },
  {
    "text": "of tasks that was meant to\nstress test our best models. When it was\nannounced, a lot of us",
    "start": "407280",
    "end": "412740"
  },
  {
    "text": "worried that it was just too\nhard for present day models. But GLUE was saturated\nin less than a year.",
    "start": "412740",
    "end": "418199"
  },
  {
    "text": "The response was SuperGlue,\nmeant to be much harder. It was also saturated\nin less than a year.",
    "start": "418200",
    "end": "424200"
  },
  {
    "text": "Remarkable story of\nprogress undoubtedly. Even if you're cynical\nabout this measure of human performance,\nwe are still",
    "start": "425040",
    "end": "431280"
  },
  {
    "text": "seeing a rapid increase in\nthe rate of change here. And 2021 was ages ago\nin the story of AI now.",
    "start": "431280",
    "end": "438960"
  },
  {
    "text": "I think this same\nthing carries over into the current era with\nour largest language models.",
    "start": "438960",
    "end": "444479"
  },
  {
    "text": "This is from a really\nnice post from Jason Wei. He is assessing\nemergent abilities in large language models.",
    "start": "444480",
    "end": "450720"
  },
  {
    "text": "You see eight of\nthem given here. Along the x-axis for these\nplots, you have model size.",
    "start": "450720",
    "end": "456300"
  },
  {
    "text": "And on the y-axis,\nyou have accuracy. And what Jason is\nshowing is that at a certain point these\nreally big models just",
    "start": "456300",
    "end": "464460"
  },
  {
    "text": "attain these abilities to\ndo these really hard tasks. And Jason estimates\nthat for 137 tasks,",
    "start": "464460",
    "end": "471300"
  },
  {
    "text": "models are showing this\nkind of emergent ability, and that includes tasks\nthat were explicitly",
    "start": "471300",
    "end": "477420"
  },
  {
    "text": "set up to help us stress test\nour largest language model. They're just falling\naway one by one.",
    "start": "477420",
    "end": "483180"
  },
  {
    "text": "Really incredible. Now, we're going to\ntalk a little bit later",
    "start": "483180",
    "end": "489120"
  },
  {
    "text": "about the factors that are\ndriving this enormous progress for large language\nmodels, but I want to be upfront that one\nof the major factors",
    "start": "489120",
    "end": "496020"
  },
  {
    "text": "here is just the raw\nsize of these models. You can see that in\nJason's plots, that's where",
    "start": "496020",
    "end": "501539"
  },
  {
    "text": "the emergent ability kicks in. And let me put that\nin context for you. So this is from a famous plot\nfrom a paper that's actually",
    "start": "501540",
    "end": "508200"
  },
  {
    "text": "about making models smaller. And what they did\nis track the rise of increases in model size.",
    "start": "508200",
    "end": "514140"
  },
  {
    "text": "Along the x-axis,\nwe have time depth. It only goes back to 2018. It's not very long ago.",
    "start": "514140",
    "end": "519599"
  },
  {
    "text": "And in 2018, the\nlargest of our models had around 100\nmillion parameters. Seems small by\ncurrent comparisons.",
    "start": "519600",
    "end": "526440"
  },
  {
    "text": "In late 2019, early\n2020, we start to see a rapid increase in\nthe size of these models",
    "start": "526980",
    "end": "533940"
  },
  {
    "text": "so that by the end of 2020, we\nhave this megatron model at 8.3",
    "start": "533940",
    "end": "539100"
  },
  {
    "text": "billion parameters. I remember when that came out. It seemed like it\nmust be some typo.",
    "start": "539100",
    "end": "545220"
  },
  {
    "text": "I could not fathom that\nwe had a model that large. But now, of course, this\nis on the small side.",
    "start": "545220",
    "end": "551640"
  },
  {
    "text": "Soon after that we\ngot an 11 billion parameter variant of that model. And then GPT-3 came out.",
    "start": "551640",
    "end": "557519"
  },
  {
    "text": "That set 175 billion parameters. And that one too now\nlooks small in comparison",
    "start": "557520",
    "end": "564060"
  },
  {
    "text": "to these truly gargantuan\nmegatron models and the PaLM model from Google,\nwhich surpassed",
    "start": "564060",
    "end": "569519"
  },
  {
    "text": "500 billion parameters. I want to emphasize that this\nhas made a complete mockery",
    "start": "569520",
    "end": "575819"
  },
  {
    "text": "of the y-axis of this plot. To capture the\nscale correctly, we would need 5,000 of these slides\nstacked on top of each other.",
    "start": "575820",
    "end": "584220"
  },
  {
    "text": "Again, it still feels\nweird to say that, but that is the truth. The scale of this is absolutely\nenormous and not something",
    "start": "584220",
    "end": "592080"
  },
  {
    "text": "I think that I would have\nanticipated way back when we were dealing with those\n100 million parameter",
    "start": "592080",
    "end": "597600"
  },
  {
    "text": "babies by comparison. They seem large at that point.",
    "start": "597600",
    "end": "601260"
  },
  {
    "text": "So this brings us to our central\nquestion, it's a golden age. This is all\nundoubtedly exciting.",
    "start": "602760",
    "end": "608940"
  },
  {
    "text": "And the things that I've\njust described to you are going to have an\nimpact on your lives, positive and negative,\nbut certainly an impact.",
    "start": "608940",
    "end": "616800"
  },
  {
    "text": "But I take it that\nwe are here today because we are\nresearchers, and we would like to participate\nin this research.",
    "start": "617400",
    "end": "623579"
  },
  {
    "text": "And that could leave you\nwith a worried feeling. How can you contribute\nto NLU in this era",
    "start": "623580",
    "end": "630540"
  },
  {
    "start": "626000",
    "end": "704000"
  },
  {
    "text": "of these gargantuan models? I've set this up\nas a flow chart. First question, do\nyou have $50 million",
    "start": "630540",
    "end": "638279"
  },
  {
    "text": "and a love of deep\nlearning infrastructure? If the answer is Yes\nto this question,",
    "start": "638280",
    "end": "643740"
  },
  {
    "text": "then I would encourage\nyou to go off and build your own large language model. You could change the\nworld in this way.",
    "start": "643740",
    "end": "649560"
  },
  {
    "text": "I would also request that\nyou get in touch with me. Maybe you could join\nmy research group and maybe fund my\nresearch group.",
    "start": "649560",
    "end": "656339"
  },
  {
    "text": "That would be wonderful. But I'm assuming that most of\nyou cannot truthfully answer",
    "start": "656340",
    "end": "662040"
  },
  {
    "text": "yes to this question. I'm in the no camp. And on both counts. I am both dramatically\nshort of the funds,",
    "start": "662040",
    "end": "668880"
  },
  {
    "text": "and I also don't have a love of\ndeep learning infrastructure. So for those of us who have\nto answer no to this question,",
    "start": "668880",
    "end": "675360"
  },
  {
    "text": "how can you contribute\neven if the answer is no? There are tons of things\nthat you can be doing.",
    "start": "675360",
    "end": "680940"
  },
  {
    "text": "All right, so just topics\nthat are front of mind to me include retrieval augmented\nin-context learning.",
    "start": "680940",
    "end": "687480"
  },
  {
    "text": "This could be small\nmodels that are performed. You could always contribute\nto creating better benchmarks.",
    "start": "687480",
    "end": "693660"
  },
  {
    "text": "This is a perennial\nchallenge for the field and maybe the most significant\nthing that you can do is just create devices that\nallow us to accurately measure",
    "start": "693660",
    "end": "701940"
  },
  {
    "text": "the performance of our systems. You could also\nhelp us solve what I've called the\nlast mile problem",
    "start": "701940",
    "end": "707640"
  },
  {
    "start": "704000",
    "end": "815000"
  },
  {
    "text": "for productive applications. These central\ndevelopments in AI take us 95% of the way toward utility,\nbut that last 5%, actually",
    "start": "707640",
    "end": "717660"
  },
  {
    "text": "having a positive\nimpact on people's lives often requires twice as\nmuch development, twice",
    "start": "717660",
    "end": "723780"
  },
  {
    "text": "as much innovation across\ndomain experts, people who are good at human computer\ninteraction, and AI experts.",
    "start": "723780",
    "end": "730440"
  },
  {
    "text": "And so there's\njust a huge amount that has to be done to\nrealize the potential of these technologies.",
    "start": "731040",
    "end": "735840"
  },
  {
    "text": "And then finally,\nyou could think about achieving faithful human\ninterpretable explanations",
    "start": "736440",
    "end": "742260"
  },
  {
    "text": "of how these models behave. If we're going to\ntrust them, we need to understand how they\nwork at a human level.",
    "start": "742260",
    "end": "748019"
  },
  {
    "text": "That is supremely challenging,\nand therefore, this is incredibly important\nwork you could be doing.",
    "start": "748020",
    "end": "752579"
  },
  {
    "text": "Now, I would love to talk\nwith you about all four of those things and\nreally elaborate on them, but our time is short.",
    "start": "753720",
    "end": "759300"
  },
  {
    "text": "And so what I've done\nis select one topic, retrieval augmented\nin-context learning",
    "start": "759300",
    "end": "764520"
  },
  {
    "text": "to focus on because it's\nintimately connected to this notion of\nin-context learning,",
    "start": "764520",
    "end": "769980"
  },
  {
    "text": "and it's a place where\nall of us can participate in lots of innovative ways.",
    "start": "769980",
    "end": "775019"
  },
  {
    "text": "So that's the central\nplan for the day. Before I do that,\nthough, I just want",
    "start": "775020",
    "end": "780899"
  },
  {
    "text": "to help us get more common\nground around what I take to be the really\ncentral change that's",
    "start": "780900",
    "end": "786660"
  },
  {
    "text": "happening as a result of\nthese large language models. And I've put that\nunder the heading of, the rise of in-context learning.",
    "start": "786660",
    "end": "793680"
  },
  {
    "text": "Again, this is something\nwe're all getting used to. It really marks a genuine\nparadigm shift, I would say.",
    "start": "794280",
    "end": "801180"
  },
  {
    "text": "In-context learning really\ntraces to the GPT-3 paper. There are precedents\nearlier in the literature,",
    "start": "802320",
    "end": "808680"
  },
  {
    "text": "but it was the GPT-3\npaper that really gave it a thorough initial investigation\nand show that it had promise",
    "start": "808680",
    "end": "815160"
  },
  {
    "start": "815000",
    "end": "890000"
  },
  {
    "text": "with the earliest GPT models. Here's how this works. We have our big language\nmodel, and we prompt it",
    "start": "815160",
    "end": "822120"
  },
  {
    "text": "with a bunch of text. So for example, this is\nfrom that GPT-3 paper. We might prompt the model with\na context, passage, and a title.",
    "start": "822120",
    "end": "830220"
  },
  {
    "text": "We might follow that with\none or more demonstrations. Here the demonstration is\na question and an answer.",
    "start": "831120",
    "end": "837060"
  },
  {
    "text": "And the goal of\nthe demonstration is to help the model\nlearn in-context, that is from the\nprompt we've given it,",
    "start": "837060",
    "end": "842940"
  },
  {
    "text": "what behavior we're\ntrying to elicit from it. So here you might\nsay we're trying to coax the model to do\nextractive question answering,",
    "start": "842940",
    "end": "850440"
  },
  {
    "text": "to find the answer as a\nsubstring of the passage we gave it. You might have a few of those.",
    "start": "850440",
    "end": "855899"
  },
  {
    "text": "And then finally we\nhave the actual question we want the model to answer. We prompt the model\nwith this prompt",
    "start": "855900",
    "end": "862380"
  },
  {
    "text": "here that puts it in\nsome state, and then its generation is taken to be\nthe prediction or response,",
    "start": "862380",
    "end": "868500"
  },
  {
    "text": "and that's how we\nassess its success. And the whole idea\nis that the model can learn in-context, that\nis from this prompt, what",
    "start": "868500",
    "end": "875460"
  },
  {
    "text": "we want it to do. So that gives you a\nsense for how this works. You've probably all\nprompted language models",
    "start": "875460",
    "end": "880680"
  },
  {
    "text": "like this yourself already. I want to dwell on this\nfor a second though. This is a really\ndifferent thing from what",
    "start": "880680",
    "end": "887280"
  },
  {
    "text": "we used to do throughout\nartificial intelligence. Let me contrast\nin-context learning",
    "start": "887280",
    "end": "892560"
  },
  {
    "start": "890000",
    "end": "1007000"
  },
  {
    "text": "with the standard paradigm\nof standard supervision. Back in the old days\nof 2017 or whatever,",
    "start": "892560",
    "end": "900000"
  },
  {
    "text": "we would typically set\nthings up like this. We would have, say,\nwe wanted to solve a problem like classifying\ntexts according",
    "start": "900000",
    "end": "906420"
  },
  {
    "text": "to whether they express\nnervous anticipation or complex human emotion. The first step would\nbe that we would",
    "start": "906420",
    "end": "911880"
  },
  {
    "text": "need to create a data set of\npositive and negative examples of that phenomenon,\nand then we would",
    "start": "911880",
    "end": "917820"
  },
  {
    "text": "train a custom built model to\nmake the binary distinction reflected in the labels here.",
    "start": "917820",
    "end": "922860"
  },
  {
    "text": "It can be surprisingly\npowerful, but you can start to see\nalready how this isn't going to scale\nto the complexity",
    "start": "923520",
    "end": "929640"
  },
  {
    "text": "of the human experience. We're going to need\nseparate data sets and maybe separate models for\noptimism, and sadness,",
    "start": "929640",
    "end": "937080"
  },
  {
    "text": "and every other emotion\nyou can think of. And that's just a subset\nof all the problems we might want our models to solve.",
    "start": "937080",
    "end": "943200"
  },
  {
    "text": "For each one, we're going\nto need data and maybe a custom built model.",
    "start": "943200",
    "end": "946980"
  },
  {
    "text": "The promise of\nin-context learning is that a single, big,\nfrozen language model",
    "start": "948420",
    "end": "954000"
  },
  {
    "text": "can serve all those goals. And in this mode, we\ndo that prompting thing that I just described.",
    "start": "954000",
    "end": "959160"
  },
  {
    "text": "We're going to give the\nmodel examples just expressed in flat text of positive\nand negative instances,",
    "start": "959160",
    "end": "965220"
  },
  {
    "text": "and hope that\nthat's enough for it to learn in-context about\nthe distinction we're trying to establish.",
    "start": "965220",
    "end": "970380"
  },
  {
    "text": "This is really,\nreally different. Consider that over here, the\nphrase nervous anticipation",
    "start": "970380",
    "end": "975540"
  },
  {
    "text": "has no special status. The model doesn't\nreally process it. It's entirely structured to\nmake a binary distinction,",
    "start": "975540",
    "end": "981780"
  },
  {
    "text": "and the label nervous\nanticipation is for us. On the right, the model needs to\nlearn essentially the meanings",
    "start": "981780",
    "end": "989220"
  },
  {
    "text": "of all of these terms\nand our intentions and figure out how to make these\ndistinctions on new examples",
    "start": "989220",
    "end": "995220"
  },
  {
    "text": "all from a prompt. It's just weird and wild\nthat this works at all. I think I used to\nbe discouraging",
    "start": "995220",
    "end": "1001640"
  },
  {
    "text": "about this as an\navenue, and now we're seeing it bear so much fruit.",
    "start": "1001640",
    "end": "1005240"
  },
  {
    "start": "1007000",
    "end": "1098000"
  },
  {
    "text": "What are the\nmechanisms behind this? I'm going to identify\na few of them for you. The first one is certainly\nthe Transformer architecture.",
    "start": "1007940",
    "end": "1015620"
  },
  {
    "text": "This is the basic building block\nof essentially all the language models that I've\nmentioned so far.",
    "start": "1015620",
    "end": "1021020"
  },
  {
    "text": "We have great coverage\nof the Transformer in our course, Natural\nLanguage Understanding, so I'm going to do this quickly.",
    "start": "1021020",
    "end": "1026900"
  },
  {
    "text": "The Transformer starts\nwith word embeddings and propositional encoding. On top of those, we have a\nbunch of attention mechanisms.",
    "start": "1026900",
    "end": "1034699"
  },
  {
    "text": "These give the name\nto the famous paper, Attention is All You Need,\nwhich announced the Transformer.",
    "start": "1034700",
    "end": "1040220"
  },
  {
    "text": "Evidently, attention\nis not all you need because we have these\npropositional encoding at the bottom and\nthen we have a bunch",
    "start": "1040220",
    "end": "1046400"
  },
  {
    "text": "of feed-forward layers\nand regularization steps at the top. But attention really is the\nbeating heart of this model,",
    "start": "1046400",
    "end": "1054500"
  },
  {
    "text": "and it really was a\ndramatic departure from the fancy mechanisms\nLSTMs and so forth",
    "start": "1054500",
    "end": "1060140"
  },
  {
    "text": "that were characteristic\nof the pre-Transformer era. So that's essentially,\nthough, on the diagram",
    "start": "1060140",
    "end": "1065720"
  },
  {
    "text": "here the full model. In the course, we have\na bunch of materials that help you get hands on with\nTransformer representations",
    "start": "1065720",
    "end": "1072139"
  },
  {
    "text": "and also dive deep\ninto the mathematics. So I'm just going\nto skip past this. I will say that\nif you dive deep,",
    "start": "1072140",
    "end": "1079460"
  },
  {
    "text": "you're likely to go through the\nsame journey we all go through where your first question is,\nhow on earth does this work?",
    "start": "1079460",
    "end": "1086179"
  },
  {
    "text": "This diagram looks\nvery complicated. But then you come\nto terms with it,",
    "start": "1086180",
    "end": "1091400"
  },
  {
    "text": "and you realize oh,\nthis is actually a bunch of very\nsimple mechanisms. But then you arrive\nat a question that",
    "start": "1091400",
    "end": "1098120"
  },
  {
    "start": "1098000",
    "end": "1115000"
  },
  {
    "text": "is a burning question for all of\nus, why does this work so well? This remains an open question.",
    "start": "1098120",
    "end": "1103460"
  },
  {
    "text": "A lot of people are\nworking on explaining why this is so effective,\nand that is certainly an area in which all of\nus could participate,",
    "start": "1103460",
    "end": "1110180"
  },
  {
    "text": "analytic work, understanding\nwhy this is so successful.",
    "start": "1110180",
    "end": "1114140"
  },
  {
    "start": "1115000",
    "end": "1268000"
  },
  {
    "text": "The second big innovation\nhere is a realization that what I've called\nself-supervision",
    "start": "1116000",
    "end": "1121580"
  },
  {
    "text": "is an incredibly\npowerful mechanism for acquiring rich\nrepresentations of form and meaning.",
    "start": "1121580",
    "end": "1127040"
  },
  {
    "text": "This is also very strange. In self-supervision, the\nmodel's only objective",
    "start": "1127040",
    "end": "1132980"
  },
  {
    "text": "is to learn from co-occurrence\npatterns in the sequence as it's trained on. This is purely\ndistributional learning.",
    "start": "1132980",
    "end": "1139760"
  },
  {
    "text": "Another way to put\nthis is the model is just learning to\nassign high probability to attested sequences.",
    "start": "1139760",
    "end": "1146420"
  },
  {
    "text": "That is the\nfundamental mechanism. We think about these\nmodels as generators, but generation is just\nsampling from the model.",
    "start": "1147200",
    "end": "1153919"
  },
  {
    "text": "That's a secondary or\nderivative process. The main thing is learning from\nthese co-ocurrence patterns.",
    "start": "1153920",
    "end": "1160520"
  },
  {
    "text": "An enlightening thing\nabout the current era is that it's fruitful\nfor these sequences to contain lots of symbols.",
    "start": "1160520",
    "end": "1166220"
  },
  {
    "text": "Not just language\nbut computer code, sensor readings, even\nimages, and so forth.",
    "start": "1166220",
    "end": "1171500"
  },
  {
    "text": "Those are all just\nsymbol streams, and the model learns\nassociations among them.",
    "start": "1171500",
    "end": "1175700"
  },
  {
    "text": "The core thing about\nself-supervision, though, that really contrasts\nit with the standard supervised",
    "start": "1176660",
    "end": "1181700"
  },
  {
    "text": "paradigm I mentioned before\nis that the objective doesn't mention any specific symbols,\nor relations between them",
    "start": "1181700",
    "end": "1188840"
  },
  {
    "text": "is entirely about learning\nthese co-ocurrence patterns. And from this simple mechanism\nwe get such rich results.",
    "start": "1188840",
    "end": "1196220"
  },
  {
    "text": "And that is\nincredibly empowering because you need\nhardly any human effort to train a model with\nself-supervision.",
    "start": "1197060",
    "end": "1203720"
  },
  {
    "text": "You just need vast quantities\nof these symbol streams. And so that has\nfacilitated the rise",
    "start": "1203720",
    "end": "1210019"
  },
  {
    "text": "of another important mechanism\nhere, large-scale pretraining. And there are actually\ntwo innovations",
    "start": "1210020",
    "end": "1215960"
  },
  {
    "text": "that are happening here. So we see the rise of\nlarge-scale pretraining in the earliest work on\nstatic word representations",
    "start": "1215960",
    "end": "1223460"
  },
  {
    "text": "like Word2vec and GloVe And\nwhat those teams realize is not only that it's\npowerful to train",
    "start": "1223460",
    "end": "1230120"
  },
  {
    "text": "on vast quantities of data\nusing just self-supervision, but also that it's\nempowering to the community",
    "start": "1230120",
    "end": "1235880"
  },
  {
    "text": "to release those parameters. Not just data, not just\ncode, but the actual",
    "start": "1235880",
    "end": "1241280"
  },
  {
    "text": "learned representations for\nother people to build on. That has been\nincredible in terms of building effective systems.",
    "start": "1241280",
    "end": "1247880"
  },
  {
    "text": "After those we get ELMO\nwhich was the first model to do this for contextual\nword representations,",
    "start": "1248480",
    "end": "1253640"
  },
  {
    "text": "truly large language models. Then we get BERT, of course,\nand GPT, and then finally,",
    "start": "1253640",
    "end": "1260180"
  },
  {
    "text": "of course, GPT-3 at a\nscale that was really previously unimagined and\nmaybe unimaginable for me.",
    "start": "1260180",
    "end": "1266900"
  },
  {
    "start": "1268000",
    "end": "1292000"
  },
  {
    "text": "A final piece that we\nshould not overlook is the role of human\nfeedback in all of this,",
    "start": "1268520",
    "end": "1274460"
  },
  {
    "text": "and I'm thinking in particular\nof the OpenAI models. I have given a lot of coverage\nso far of this mechanism",
    "start": "1274460",
    "end": "1281779"
  },
  {
    "text": "of self-supervision, but we have\nto acknowledge that our best models are what OpenAI\ncalls the Instruct models,",
    "start": "1281780",
    "end": "1288740"
  },
  {
    "text": "and those are trained\nwith way more than just self-supervision. This is a diagram from\nthe ChatGPT blog post.",
    "start": "1288740",
    "end": "1295940"
  },
  {
    "start": "1292000",
    "end": "1422000"
  },
  {
    "text": "It has a lot of details. I'm confident that\nthere are really two pieces that are important. First, the language\nmodel is fine",
    "start": "1295940",
    "end": "1303600"
  },
  {
    "text": "tuned on a human-level\nsupervision just making binary distinctions about\ngood generations and bad ones.",
    "start": "1303600",
    "end": "1310700"
  },
  {
    "text": "That's already beyond\nself-supervision. And then in a second phase,\nthe model generates outputs,",
    "start": "1310700",
    "end": "1316340"
  },
  {
    "text": "and humans rank all of the\noutputs the model has produced. And that feedback goes into\na lightweight reinforcement",
    "start": "1316340",
    "end": "1323360"
  },
  {
    "text": "learning mechanism. In both of those phases, we have\nimportant human contributions",
    "start": "1323360",
    "end": "1328519"
  },
  {
    "text": "that take us beyond that\nself-supervision step and reduce the magical feeling\nof how these models are",
    "start": "1328520",
    "end": "1335539"
  },
  {
    "text": "achieving so much. I'm emphasizing\nthis because I think what we're seeing is a return\nto a familiar and cynical",
    "start": "1335540",
    "end": "1342559"
  },
  {
    "text": "sounding story\nabout AI, which is that many of the\ntransformative step forwards are actually on the back\nof a lot of human effort",
    "start": "1342560",
    "end": "1351020"
  },
  {
    "text": "behind the scenes expressed\nat the level of training data. But on the positive\nside here, it",
    "start": "1351020",
    "end": "1357919"
  },
  {
    "text": "is incredible that this\nhuman feedback is having such an important impact-- Instruct models, our best\nin class in the field,",
    "start": "1357920",
    "end": "1364160"
  },
  {
    "text": "and we have a lot of\nevidence that that must be because of\nthese human feedback steps happening at a scale\nthat I assume is astounding.",
    "start": "1364160",
    "end": "1372620"
  },
  {
    "text": "They must have at OpenAI large\nteams of people providing very fine grained\nfeedback across lots",
    "start": "1372620",
    "end": "1379100"
  },
  {
    "text": "of different domains with lots\nof different tasks in mind.",
    "start": "1379100",
    "end": "1381919"
  },
  {
    "text": "Final piece by way of\nbackground, prompting itself. This has been a real\njourney for all of us.",
    "start": "1384140",
    "end": "1390440"
  },
  {
    "text": "I've described this\nas step-by-step and chain-of-thought reasoning. To give you a feel for\nhow this is happening,",
    "start": "1390440",
    "end": "1397100"
  },
  {
    "text": "let's just imagine that\nwe've posed a question like, can our models reason\nabout negation? That is if we\ndidn't eat any food,",
    "start": "1397100",
    "end": "1404120"
  },
  {
    "text": "does the model know that\nwe didn't eat any pizza? In the old days of\n2021, we were so naive.",
    "start": "1404120",
    "end": "1412279"
  },
  {
    "text": "We would prompt models with\njust that direct question like, is it true that if we\ndidn't eat any food, then",
    "start": "1412280",
    "end": "1418100"
  },
  {
    "text": "we didn't eat any pizza? And we would see what\nthe model said in return. Now, in 2023, we know so much.",
    "start": "1418100",
    "end": "1426140"
  },
  {
    "start": "1422000",
    "end": "1693000"
  },
  {
    "text": "And we have learned\nthat it can really help to design a prompt\nthat helps the model reason in the intended ways.",
    "start": "1426140",
    "end": "1432500"
  },
  {
    "text": "This is often called\nstep-by-step reasoning. Here's an example\nof a prompt that was given to me by Omar Khattab. You start by telling it it's\na logic and common sense",
    "start": "1432500",
    "end": "1440480"
  },
  {
    "text": "reasoning exam. For some reason that's helpful. Then you give it some\nspecific instructions,",
    "start": "1440480",
    "end": "1445580"
  },
  {
    "text": "and then you use\nsome special markup to give it an example\nof the kind of reasoning",
    "start": "1445580",
    "end": "1450740"
  },
  {
    "text": "that you would\nlike it to follow. After that example\ncomes the actual prompt. And in this context, what we\nessentially ask the model to do",
    "start": "1450740",
    "end": "1458780"
  },
  {
    "text": "is express its own\nreasoning and then, conditional on what it has\nproduced, create an answer.",
    "start": "1458780",
    "end": "1464480"
  },
  {
    "text": "And the eye-opening thing\nabout the current era is that this can be\ntransformatively better.",
    "start": "1465140",
    "end": "1470360"
  },
  {
    "text": "I think if you wanted\nto put this poetically, you'd say that these\nlarge language models are like alien creatures, and\nit's taking us some time",
    "start": "1470360",
    "end": "1477680"
  },
  {
    "text": "to figure out how to\ncommunicate with them. And together with all\nthat instruct fine tuning with human\nsupervision, we're",
    "start": "1477680",
    "end": "1484580"
  },
  {
    "text": "converging on prompts like\nthis as the powerful device. And this is exciting to me\nbecause what's really emerging",
    "start": "1484580",
    "end": "1490039"
  },
  {
    "text": "is that this is a very light\nway of programming an AI system using only\nprompts as opposed",
    "start": "1490040",
    "end": "1497300"
  },
  {
    "text": "to all the deep learning code\nthat we used to have to write. And that's going to be\nincredibly empowering in terms of system development\nand experimentation.",
    "start": "1497300",
    "end": "1504320"
  },
  {
    "text": "All right, so we have\nour background in place. I'd like to move to\nmy main topic here which is retrieval-augmented\nin-context learning, which",
    "start": "1506540",
    "end": "1514820"
  },
  {
    "text": "you're going to see\nhere is a combination of language models with\nretriever models, which",
    "start": "1514820",
    "end": "1519860"
  },
  {
    "text": "are themselves under the hood\nlarge language models as well. But let me start with a\nbit of a backstory here.",
    "start": "1519860",
    "end": "1525980"
  },
  {
    "text": "I think we're all probably\nvaguely aware at this point that large language models have\nbeen revolutionizing search.",
    "start": "1525980",
    "end": "1533360"
  },
  {
    "text": "Again, the star of this is\nthe Transformer or maybe more specifically, its famous\nspokesmodel, BERT.",
    "start": "1533360",
    "end": "1539900"
  },
  {
    "text": "Right after BERT was\nannounced around 2018, Google announced that it was\nincorporating aspects of BERT",
    "start": "1539900",
    "end": "1546620"
  },
  {
    "text": "into its core search technology. And Microsoft made a\nsimilar announcement at about the same time.",
    "start": "1546620",
    "end": "1552380"
  },
  {
    "text": "And I think those are just\ntwo public-facing stories of many instances of large\nsearch technologies having",
    "start": "1552380",
    "end": "1560540"
  },
  {
    "text": "BERT elements incorporated\ninto them in that era. And then, of course,\nin the current era we have startups\nlike You.com which",
    "start": "1560540",
    "end": "1568039"
  },
  {
    "text": "have made large\nlanguage models pretty central to the entire search\nexperience in the form",
    "start": "1568040",
    "end": "1573320"
  },
  {
    "text": "of delivering results but\nalso interactive search with conversational agents.",
    "start": "1573320",
    "end": "1578720"
  },
  {
    "text": "So that's all exciting,\nbut I am an NLPer at heart. And so for me in a way,\nthe more exciting direction",
    "start": "1578720",
    "end": "1586040"
  },
  {
    "text": "here is the fact that finally\nsearch is revolutionizing NLP by helping us bridge the\ngap into much more relevant",
    "start": "1586040",
    "end": "1594980"
  },
  {
    "text": "knowledge-intensive tasks. To give you a feel for\nhow that's happening, let's just use question\nanswering as an example.",
    "start": "1594980",
    "end": "1602240"
  },
  {
    "text": "So prior to this\nwork in NLP, we would pose question answer answering\nor QA in the following way--",
    "start": "1602240",
    "end": "1609080"
  },
  {
    "text": "you saw this already\nwith the GPT-3 example-- you would have as given\nat test time a title",
    "start": "1609620",
    "end": "1615799"
  },
  {
    "text": "and a context passage\nand then a question. And the task of the model\nis to find the answer",
    "start": "1615800",
    "end": "1621500"
  },
  {
    "text": "to that question as a literal\nsubstring of the context passage, which was guaranteed\nby the nature of the data set.",
    "start": "1621500",
    "end": "1628580"
  },
  {
    "text": "As you can imagine, models\nare really good at this task. Superhuman certainly\nat this task.",
    "start": "1629360",
    "end": "1635180"
  },
  {
    "text": "But it's also a\nvery rarified task. This is not a natural\nform of question answering",
    "start": "1635180",
    "end": "1640400"
  },
  {
    "text": "in the world, and it certainly\nunlike the scenario of, for example, doing web search. So the promise of the open\nformulations of this task",
    "start": "1640400",
    "end": "1648320"
  },
  {
    "text": "are that we're going\nto connect more directly with the real world. In this formulation\nat test time,",
    "start": "1648320",
    "end": "1654200"
  },
  {
    "text": "we're just given a question\nand the standard strategy is to rely on some\nretrieval mechanism",
    "start": "1654200",
    "end": "1661100"
  },
  {
    "text": "to find relevant evidence\nin a large corpus or maybe even the web. And then we proceed as before.",
    "start": "1661100",
    "end": "1668060"
  },
  {
    "text": "This is a much harder\nproblem because we're not going to get the substring\nguarantee anymore, because we're dependent\non the retriever",
    "start": "1668780",
    "end": "1675440"
  },
  {
    "text": "to find relevant evidence. But of course, it's a\nmuch more important task because this is much more like\nour experience of searching",
    "start": "1675440",
    "end": "1682880"
  },
  {
    "text": "on the web. Now, I've biased already in\ndescribing things this way",
    "start": "1682880",
    "end": "1688460"
  },
  {
    "text": "where I assume we're\nretrieving a passage, but there is another\nnarrative out there.",
    "start": "1688460",
    "end": "1693500"
  },
  {
    "start": "1693000",
    "end": "2489000"
  },
  {
    "text": "Let me skip to this. Then you could call this the\nLLMs for everything approach. And this would be where\nthere's no explicit retriever.",
    "start": "1693500",
    "end": "1700520"
  },
  {
    "text": "You just have a\nquestion come in, you have a big,\nopaque model process that question and\nout comes an answer.",
    "start": "1700520",
    "end": "1706760"
  },
  {
    "text": "Voila. You hope that the\nuser's information need is met directly. No separate retrieval mechanism\njust the language model",
    "start": "1706760",
    "end": "1714799"
  },
  {
    "text": "doing everything. I think this is an\nincredibly inspiring vision, but we should be aware that\nthere are lots of danger zones",
    "start": "1714800",
    "end": "1722660"
  },
  {
    "text": "here.\nSo the first is just efficiency. One of the major factors driving\nthat explosion in model size",
    "start": "1722660",
    "end": "1729500"
  },
  {
    "text": "that I tracked before is that\nin this LLMs for everything approach we are\nasking this model",
    "start": "1729500",
    "end": "1734540"
  },
  {
    "text": "to play the role of both\nknowledge store and language capability. If we could separate\nthose out, we",
    "start": "1734540",
    "end": "1741080"
  },
  {
    "text": "might get away with\nsmaller models. We have a related\nproblem of updateability.",
    "start": "1741080",
    "end": "1747140"
  },
  {
    "text": "Suppose a fact in the\nworld changes, the document on the web changes, for\nexample, well, you're",
    "start": "1747140",
    "end": "1752960"
  },
  {
    "text": "going to have to\nupdate the parameters of this big, opaque\nmodel somehow to conform to the\nchange in reality.",
    "start": "1752960",
    "end": "1758660"
  },
  {
    "text": "There are people hard\nat work on that problem. That's a very exciting\nproblem, but I think we're a long way from\nbeing able to offer guarantees",
    "start": "1759380",
    "end": "1766940"
  },
  {
    "text": "that a change in the world\nis reflected in the model behavior. And that plays into\nall sorts of issues",
    "start": "1766940",
    "end": "1772220"
  },
  {
    "text": "of trustworthiness\nand explainability of behavior and so forth.",
    "start": "1772220",
    "end": "1776780"
  },
  {
    "text": "Also we have an\nissue of provenance. Look at the answer\nat the bottom there. Is that the correct answer?",
    "start": "1777920",
    "end": "1783980"
  },
  {
    "text": "Should you trust this model? In the standard web\nsearch experience, we typically are given some\nweb pages that we can click on",
    "start": "1783980",
    "end": "1791000"
  },
  {
    "text": "to verify at least at\nthe next level of detail whether the\ninformation is correct, but here we're just\ngiven this response.",
    "start": "1791000",
    "end": "1798200"
  },
  {
    "text": "And if the model also\ngenerated a provenance string, if it told us where it\nfound the information, we'd be left with the\nconcern that that provenance",
    "start": "1798200",
    "end": "1805639"
  },
  {
    "text": "string was also untrustworthy. And this is like really\nbreaking a fundamental contract",
    "start": "1805640",
    "end": "1811040"
  },
  {
    "text": "that users expect to have with\nsearch technologies, I believe. So those are some\nthings to worry about.",
    "start": "1811040",
    "end": "1816860"
  },
  {
    "text": "There are positives,\nthough, of course, these models are incredibly\neffective at meeting",
    "start": "1816860",
    "end": "1822140"
  },
  {
    "text": "your information need directly. And they're also outstanding\nat synthesizing information. If your question can only be\nanswered by 10 different web",
    "start": "1822140",
    "end": "1830480"
  },
  {
    "text": "pages, it's very likely that\nthe language model will still be able to do it without\nyou having to hunt through all those pages.",
    "start": "1830480",
    "end": "1836840"
  },
  {
    "text": "So exciting but lots\nof concerns here. Here is the alternative of\nretrieval-augmented approaches.",
    "start": "1837680",
    "end": "1844520"
  },
  {
    "text": "Oh, I can't resist\nthis actually. Just to give you an\nexample of how important",
    "start": "1844520",
    "end": "1849860"
  },
  {
    "text": "this trustworthy thing can be. So I used to be impressed by\nDavinci-003 because it would",
    "start": "1849860",
    "end": "1856940"
  },
  {
    "text": "give a correct answer\nto the question, are professional\nbaseball players allowed to glue small\nwings onto their caps?",
    "start": "1856940",
    "end": "1863000"
  },
  {
    "text": "This is a question that I\ngot from a wonderful article by Hector Levesque where he\nencourages us to stress test",
    "start": "1863000",
    "end": "1868580"
  },
  {
    "text": "our models by asking them\nquestions that would seem to run up against any\nsimple distributional",
    "start": "1868580",
    "end": "1874520"
  },
  {
    "text": "or statistical learning model\nand really get at whether they have a model of the world.",
    "start": "1874520",
    "end": "1878960"
  },
  {
    "text": "And for Davinci-002,\nit gave what looked like a really good\nLevesque-style answer. There is no rule\nagainst it, but it",
    "start": "1879560",
    "end": "1885620"
  },
  {
    "text": "is not common but seems true. So I was disappointed, I\nguess, or I'm actually not",
    "start": "1885620",
    "end": "1891860"
  },
  {
    "text": "sure how to feel about this. When I asked Davinci-003 the\nsame question, and it said, no, professional\nbaseball players",
    "start": "1891860",
    "end": "1897680"
  },
  {
    "text": "are not allowed to glue\nsmall wings onto their caps. Major League Baseball\nhas strict rules about the appearance of\nplayers uniforms and caps,",
    "start": "1897680",
    "end": "1904340"
  },
  {
    "text": "and any modification to\nthe caps are not allowed. That also sounds\nreasonable to me. Is it true?",
    "start": "1904340",
    "end": "1910700"
  },
  {
    "text": "It would help enormously\nif the model could offer me at least a web page\nwith evidence that's",
    "start": "1910700",
    "end": "1916940"
  },
  {
    "text": "relevant to these\nclaims, otherwise, I'm simply left wondering. And I think that\nshows you that we've",
    "start": "1916940",
    "end": "1922760"
  },
  {
    "text": "broken this implicit\ncontract with the user that we expect from search. So that will bring\nme to my alternative",
    "start": "1922760",
    "end": "1929660"
  },
  {
    "text": "here, retrieval-based or\nretrieval-augmented NLP. To give you a sense for\nthis, at the top here,",
    "start": "1929660",
    "end": "1934880"
  },
  {
    "text": "I have a standard\nsearch box, and I've put in a very complicated\nquestion indeed. The first step in\nthis approach is",
    "start": "1934880",
    "end": "1941720"
  },
  {
    "text": "familiar from the LLMs\nfor everything one. We're going to encode\nthat query into a dense numerical representation\ncapturing aspects of its form",
    "start": "1941720",
    "end": "1949340"
  },
  {
    "text": "and meaning. We'll use a language\nmodel for that. The next step is new, though. We are also going to\nuse a language model.",
    "start": "1949340",
    "end": "1956000"
  },
  {
    "text": "Maybe the same one\nwe used for the query to process all of the documents\nin our document collection.",
    "start": "1956000",
    "end": "1961340"
  },
  {
    "text": "So each one has some kind\nof numerical deep learning representation now.",
    "start": "1961880",
    "end": "1967040"
  },
  {
    "text": "On the basis of these\nrepresentations, we can now score\ndocuments with respect to queries just like we would\nin the standard good, old days",
    "start": "1967040",
    "end": "1975740"
  },
  {
    "text": "of information retrieval. So we can reproduce every aspect\nof that familiar experience",
    "start": "1975740",
    "end": "1980960"
  },
  {
    "text": "if we want to. We're just doing it now in\nthis very rich, semantic space.",
    "start": "1980960",
    "end": "1985220"
  },
  {
    "text": "So we get some results back,\nand we could offer those to the user as ranked results,\nbut we can also go further.",
    "start": "1986120",
    "end": "1991520"
  },
  {
    "text": "We can have another\nlanguage model, call it a reader or\na generator, slurp up",
    "start": "1991520",
    "end": "1996980"
  },
  {
    "text": "those retrieved passages\nand synthesize them into a single answer maybe\nmeeting the user's information",
    "start": "1996980",
    "end": "2003100"
  },
  {
    "text": "need directly. So let's check in on how we're\ndoing with respect to our goals",
    "start": "2003100",
    "end": "2008139"
  },
  {
    "text": "here.\nFirst, efficiency. I won't have time to\nsubstantiate this today, but these systems in\nterms of parameter counts",
    "start": "2008140",
    "end": "2014320"
  },
  {
    "text": "can be much smaller\nthan the integrated approach I mentioned before. We also have an easy\npath to updateability.",
    "start": "2014320",
    "end": "2021460"
  },
  {
    "text": "We have this index here. So as pages change in\nour document store, we simply use our frozen\nlanguage model to reprocess",
    "start": "2021460",
    "end": "2029440"
  },
  {
    "text": "and rerepresent them. And we can have a pretty\ngood guarantee at this point that information changes\nwill be reflected",
    "start": "2029440",
    "end": "2035920"
  },
  {
    "text": "in the retrieved\nresults down here. We're also naturally\ntracking provenance because we have all\nof these documents,",
    "start": "2035920",
    "end": "2042760"
  },
  {
    "text": "and they're used to\ndeliver the results, and we can have that carry\nthrough into the generation. So we've kept that\ncontract with the user.",
    "start": "2042760",
    "end": "2049899"
  },
  {
    "text": "These models are incredibly\neffective across lots of literature. We're seeing that\nretrieval-augmented approaches",
    "start": "2050440",
    "end": "2056560"
  },
  {
    "text": "are just superior to the fully\nintegrated LLMs for everything one. And we've retained\nthe benefit of LLMs",
    "start": "2056560",
    "end": "2063820"
  },
  {
    "text": "for everything because we\nhave this model down here, the reader generator, that\ncan synthesize information",
    "start": "2063820",
    "end": "2068919"
  },
  {
    "text": "into answers that meet the\ninformation need directly.",
    "start": "2068920",
    "end": "2072460"
  },
  {
    "text": "So that's my fundamental pitch. Now, again, things are changing\nfast and even the approach",
    "start": "2073960",
    "end": "2080500"
  },
  {
    "text": "to designing these systems\nis also changing really fast. So in the previous\nera of 2020, we",
    "start": "2080500",
    "end": "2088600"
  },
  {
    "text": "would have these\npretrained components like we have our index\nand our retriever. Maybe we have a language\nmodel like reader generator,",
    "start": "2088600",
    "end": "2096100"
  },
  {
    "text": "and you might have other\npretrained components, image processing and so forth. So you have all these assets.",
    "start": "2096100",
    "end": "2101740"
  },
  {
    "text": "And the question is, how are\nyou going to bring them together into an integrated solution? The standard deep learning\nanswer to that question",
    "start": "2101740",
    "end": "2109839"
  },
  {
    "text": "is to define a bunch of\ntask-specific parameters that are meant to tie\ntogether all those components.",
    "start": "2109840",
    "end": "2116619"
  },
  {
    "text": "And then you learn those\nparameters with respect to some tasks, and you\nhope that that has created",
    "start": "2116620",
    "end": "2121720"
  },
  {
    "text": "an effective integrated system. That's the modular\nvision of deep learning.",
    "start": "2121720",
    "end": "2126880"
  },
  {
    "text": "The truth in\npractice is that even for very experienced\nresearchers and system designers",
    "start": "2126880",
    "end": "2133120"
  },
  {
    "text": "this can often go really wrong. And debugging these\nsystems and figuring out",
    "start": "2133120",
    "end": "2138820"
  },
  {
    "text": "how to improve them\ncan be very difficult because they are so opaque,\nand the scale is so large.",
    "start": "2138820",
    "end": "2144520"
  },
  {
    "text": "But maybe we're moving\nout of an era in which we have to do this at all. So this will bring us back\nto in-context learning.",
    "start": "2146440",
    "end": "2154120"
  },
  {
    "text": "The fundamental insight here\nis that many of these models can in principle communicate\nin natural language.",
    "start": "2154120",
    "end": "2161619"
  },
  {
    "text": "So a retriever is\nabstractly just a device for pulling in text and\nproducing text with scores.",
    "start": "2161620",
    "end": "2169240"
  },
  {
    "text": "And our language model is also\na device for pulling in text and producing text with scores.",
    "start": "2170140",
    "end": "2176140"
  },
  {
    "text": "And we have already\nseen in my basic picture of retrieval-augmented\napproaches that we could have the retriever\ncommunicate with the language",
    "start": "2176920",
    "end": "2184180"
  },
  {
    "text": "model via retrieve results. Well, what if we just allow\nthat to go in both directions? Now, we've got a system that\nis essentially constructed",
    "start": "2184180",
    "end": "2192760"
  },
  {
    "text": "by prompts that help these\nmodels do message passing between them in potentially\nvery complicated ways.",
    "start": "2192760",
    "end": "2199300"
  },
  {
    "text": "An entirely new approach to\nsystem design that I think is going to have an\nincredible democratizing",
    "start": "2199300",
    "end": "2205360"
  },
  {
    "text": "effect on who designs these\nsystems and what they're for. And they give you a deep\nsense for just how wide",
    "start": "2205360",
    "end": "2212380"
  },
  {
    "text": "open the design space is here. Again, to give you a sense\nfor how much of this research",
    "start": "2212380",
    "end": "2217660"
  },
  {
    "text": "is still left to be done\neven in this golden era. Let's imagine a search context.",
    "start": "2217660",
    "end": "2223240"
  },
  {
    "text": "The question is,\nwhat course to take? What we're going to\ndo in this new mode is begin a prompt that contains\nthat question just as before.",
    "start": "2223240",
    "end": "2230860"
  },
  {
    "text": "And now what we can do next\nis retrieve a context passage. That'll be like the\nretrieval-augmented approach",
    "start": "2232480",
    "end": "2239200"
  },
  {
    "text": "that I showed you at the\nstart of this section. You could just use our\nretriever for that. But there's more\nthat could be done.",
    "start": "2239200",
    "end": "2245620"
  },
  {
    "text": "What about demonstrations? Let's imagine that we have a\nlittle train set of QA pairs that demonstrate for our system\nwhat the intended behavior is.",
    "start": "2245620",
    "end": "2253840"
  },
  {
    "text": "Well, we can add\nthose into the prompt. And now we're giving the system\na lot of Few-shot guidance about how to learn in-context.",
    "start": "2253840",
    "end": "2260440"
  },
  {
    "text": "But that's also\njust the beginning. I might have sampled these\ntraining examples randomly",
    "start": "2261880",
    "end": "2267579"
  },
  {
    "text": "from my training set, but I\nhave a retriever remember. And so what I could do instead\nis find the demonstrations",
    "start": "2267580",
    "end": "2274839"
  },
  {
    "text": "that are the most similar\nto the user's question and put those in my prompt\nwith the expectation",
    "start": "2274840",
    "end": "2280480"
  },
  {
    "text": "that that will help it\nunderstand topical coherence and lead to better results.",
    "start": "2280480",
    "end": "2285220"
  },
  {
    "text": "But I could go further. I could use my retriever\nagain to find relevant context",
    "start": "2286120",
    "end": "2291580"
  },
  {
    "text": "passages for each one\nof those demonstrations to further help\nit figure out how to reason in terms of evidence.",
    "start": "2291580",
    "end": "2297880"
  },
  {
    "text": "And that also opens up\na huge design space. We could do what we call\nhindsight retrieval, where for each one of\nthese we're using",
    "start": "2298600",
    "end": "2304720"
  },
  {
    "text": "both the question and the\nanswer to find relevant context passages to really give you\nintegrated informational",
    "start": "2304720",
    "end": "2311500"
  },
  {
    "text": "packets that the model\ncan benefit from. And there's lots\nmore that we could",
    "start": "2311500",
    "end": "2316660"
  },
  {
    "text": "do with these demonstrations. You're probably\nstarting to see it. We could do some\nrewriting and so forth.",
    "start": "2316660",
    "end": "2322180"
  },
  {
    "text": "Really make sophisticated use of\nthe retriever and the language model interwoven.",
    "start": "2322180",
    "end": "2327099"
  },
  {
    "text": "We could also think about how\nwe selected this background passage. I was assuming\nthat we would just",
    "start": "2327820",
    "end": "2333339"
  },
  {
    "text": "retrieve the most\nrelevant passage according to our question.",
    "start": "2333340",
    "end": "2338020"
  },
  {
    "text": "But we could also think about\nrewriting the user's query in terms of the\ndemonstrations that we",
    "start": "2338740",
    "end": "2344080"
  },
  {
    "text": "constructed to get a new query\nthat will help the model. That's especially powerful if\nyou have a interactional mode",
    "start": "2344080",
    "end": "2350620"
  },
  {
    "text": "where the demonstrations are\nactually part of a dialogue history or something like that.",
    "start": "2350620",
    "end": "2355900"
  },
  {
    "text": "And then finally we\ncould turn our attention to how we're actually\ngenerating the answer. I was assuming we would\ntake the top generation",
    "start": "2357160",
    "end": "2363819"
  },
  {
    "text": "from the language model,\nbut we could do much more. We could filter its\ngenerations to just those that",
    "start": "2363820",
    "end": "2369220"
  },
  {
    "text": "match a substring of the\npassage reproducing some of the old mode of\nquestion answering",
    "start": "2369220",
    "end": "2374680"
  },
  {
    "text": "but now in this completely\nopen formulation. That can be incredibly\npowerful if you know your model can retrieve\ngood background passages here.",
    "start": "2374680",
    "end": "2382480"
  },
  {
    "text": "Those are two simple steps. You could also go all the\nway to the other extreme and use the full Retrieval\nAugmented Generation or RAG",
    "start": "2383140",
    "end": "2391120"
  },
  {
    "text": "model, which essentially creates\na full probability model that allows us to marginalize out\nthe contribution of passages.",
    "start": "2391120",
    "end": "2398380"
  },
  {
    "text": "That can be incredibly\npowerful in terms of making maximal use of\nthe capacity of this model",
    "start": "2398380",
    "end": "2404619"
  },
  {
    "text": "to generate text\nconditional on all the work that we did up here.",
    "start": "2404620",
    "end": "2408760"
  },
  {
    "text": "I hope that's given you\na sense for just how much can happen here. What we're starting\nto see, I think,",
    "start": "2410560",
    "end": "2415780"
  },
  {
    "text": "is that there is a new\nprogramming mode emerging. It's a programming\nmode that involves",
    "start": "2415780",
    "end": "2420940"
  },
  {
    "text": "using these large pretrained\ncomponents to design encode prompts that\nare essentially full AI",
    "start": "2420940",
    "end": "2428799"
  },
  {
    "text": "systems that are\nentirely about message passing between these\nfrozen components.",
    "start": "2428800",
    "end": "2433840"
  },
  {
    "text": "We have a new paper out that's\ncalled Demonstrate Search Predict or DSP. This is a lightweight\nprogramming framework",
    "start": "2433840",
    "end": "2440440"
  },
  {
    "text": "for doing exactly what I\nwas just describing for you. And one thing I\nwant to call out is",
    "start": "2440440",
    "end": "2445600"
  },
  {
    "text": "that our results are fantastic. Now, we can pat\nourselves on the back.",
    "start": "2445600",
    "end": "2451599"
  },
  {
    "text": "We have a very talented\nteam, and so it's no surprise the results are so good. But I actually want to\nbe upfront with you.",
    "start": "2451600",
    "end": "2457960"
  },
  {
    "text": "I think the real\ninsight here is that it is such early days in\nterms of us figuring out",
    "start": "2457960",
    "end": "2463660"
  },
  {
    "text": "how to construct\nthese prompts, how to program these systems\nthat we've only just begun",
    "start": "2463660",
    "end": "2468940"
  },
  {
    "text": "to understand what's optimal. We have explored only a\ntiny part of this space, and everything we're\ndoing is suboptimal.",
    "start": "2468940",
    "end": "2475059"
  },
  {
    "text": "And that's just the\nconditions where you get these huge leaps forward\nin performance on these tasks.",
    "start": "2475060",
    "end": "2481540"
  },
  {
    "text": "So I suspect that the\nbold row that we have here will not be long lived\ngiven how much innovation",
    "start": "2481540",
    "end": "2487660"
  },
  {
    "text": "is happening in this space. And I want to make a\npitch for our course here. So we have in this course a\nbunch of assignments/bakeoff.",
    "start": "2487660",
    "end": "2496000"
  },
  {
    "start": "2489000",
    "end": "2788000"
  },
  {
    "text": "And the way that\nworks essentially is that you have\nan assignment that helps you build some\nbaselines, and then work",
    "start": "2497620",
    "end": "2503440"
  },
  {
    "text": "toward an original system, which\nyou enter into a bakeoff, which is an informal competition\naround data and modeling.",
    "start": "2503440",
    "end": "2510400"
  },
  {
    "text": "Our newest of these is\ncalled Few-shot OpenQA with ColBERT retrieval. It's a version of the\nproblems that I've just",
    "start": "2510940",
    "end": "2517600"
  },
  {
    "text": "been describing for you. This is a problem that could\nnot even have been meaningfully posed five years ago.",
    "start": "2517600",
    "end": "2523420"
  },
  {
    "text": "And now we are seeing students\ndoing incredible, cutting edge things in this mode.",
    "start": "2523420",
    "end": "2528760"
  },
  {
    "text": "It's exactly what I was\njust describing for you. And we're in the moment where\na student project could lead",
    "start": "2528760",
    "end": "2535240"
  },
  {
    "text": "to a paper that really leads\nto state-of-the-art performance in surprising ways.",
    "start": "2535240",
    "end": "2540400"
  },
  {
    "text": "Again, because there is\njust so much research that has to be done here.",
    "start": "2540400",
    "end": "2544300"
  },
  {
    "text": "I'm running out of time. What I think I'll\ndo is just briefly call out again those\nimportant other areas",
    "start": "2546760",
    "end": "2553660"
  },
  {
    "text": "that I've given short\nshrift to today, but I think are\njust so important starting with datasets.",
    "start": "2553660",
    "end": "2559060"
  },
  {
    "text": "I've been talking about system\ndesign and task performance, but it is now and will\nalways be the case",
    "start": "2559060",
    "end": "2566140"
  },
  {
    "text": "that contributing in\nnew benchmark datasets is basically the most\nimportant thing you can do.",
    "start": "2566140",
    "end": "2571960"
  },
  {
    "text": "I like this analogy. Jacques Cousteau\nsaid, \"Water and air, the two essential fluids\non which all life depends.\"",
    "start": "2571960",
    "end": "2578920"
  },
  {
    "text": "I would extend that to NLP. Our datasets are the resource\non which all progress depends.",
    "start": "2578920",
    "end": "2587020"
  },
  {
    "text": "Now, Cousteau\nextended this with, \"Have become global\ngarbage cans.\" I am not that cynical\nabout our datasets.",
    "start": "2587020",
    "end": "2593080"
  },
  {
    "text": "I think we've learned\na lot about how to create effective datasets. We're getting better\nat this, but we",
    "start": "2593080",
    "end": "2598359"
  },
  {
    "text": "need to watch out for this\nmetaphorical pollution. And we need always to\nbe pushing our systems",
    "start": "2598360",
    "end": "2604120"
  },
  {
    "text": "with harder tasks\nthat come closer to the human capabilities\nthat we're actually",
    "start": "2604120",
    "end": "2609580"
  },
  {
    "text": "trying to get them to achieve. And without contributions\nof datasets, we could be tricking\nourselves when we think",
    "start": "2609580",
    "end": "2616060"
  },
  {
    "text": "we're making a lot of progress. The second thing that\nI wanted to call out",
    "start": "2616060",
    "end": "2621340"
  },
  {
    "text": "relates to model explainability. Now, we're in an era\nof incredible impact and that has rightly\nturned researchers",
    "start": "2621340",
    "end": "2628480"
  },
  {
    "text": "to questions of system\nreliability, safety, trust, approved use, and\npernicious social biases.",
    "start": "2628480",
    "end": "2635859"
  },
  {
    "text": "We have to get serious\nabout all these issues if we're going to responsibly\nhave all of the impact",
    "start": "2635860",
    "end": "2642520"
  },
  {
    "text": "that we're achieving\nat this point. All of these things\nare incredibly difficult because the\nsystems we're talking about",
    "start": "2642520",
    "end": "2649000"
  },
  {
    "text": "are these enormous, opaque,\nimpossible to understand analytically devices like\nthis that are just clouding",
    "start": "2649000",
    "end": "2656200"
  },
  {
    "text": "our understanding of them. And so to me, that\nshines a light on the importance of\nachieving analytic guarantees",
    "start": "2656200",
    "end": "2662980"
  },
  {
    "text": "about our model behaviors. That seems to me to\nbe a prerequisite for getting serious about\nany one of these topics.",
    "start": "2662980",
    "end": "2669400"
  },
  {
    "text": "And the goal there\nin our terms is to achieve faithful,\nhuman interpretable",
    "start": "2669400",
    "end": "2675580"
  },
  {
    "text": "explanations of model behavior. We have great coverage of\nthese methods in the course, hands on materials,\nscreencasts, and other things",
    "start": "2675580",
    "end": "2683920"
  },
  {
    "text": "that will help you\nparticipate in this research. And also as a side effect,\nwrite absolutely outstanding",
    "start": "2683920",
    "end": "2691060"
  },
  {
    "text": "discussion and analysis\nsections for your papers.",
    "start": "2691060",
    "end": "2694660"
  },
  {
    "text": "And the final thing\nI wanted to call out is just that last mile problem. Fundamental advances in AI\ntake us 95% of the way there,",
    "start": "2696160",
    "end": "2705160"
  },
  {
    "text": "but that last 5% is every bit\nas difficult as the first 95%. In my group, we've been looking\na lot at image accessibility.",
    "start": "2705160",
    "end": "2713440"
  },
  {
    "text": "This is an incredibly\nimportant societal problem because images are so\ncentral to modern life",
    "start": "2714100",
    "end": "2721000"
  },
  {
    "text": "across being on the web and in\nsocial media, also in the news and in our scientific discourse.",
    "start": "2721000",
    "end": "2727240"
  },
  {
    "text": "And it's a sad fact about the\ncurrent state of the world that almost none\nof these images are",
    "start": "2727240",
    "end": "2733000"
  },
  {
    "text": "made nonvisually accessible,\nso blind and low vision users are basically unable to\nunderstand all this context",
    "start": "2733000",
    "end": "2739900"
  },
  {
    "text": "and receive all of\nthis information. Something has to change that. Image-based text generation\nhas become incredibly good",
    "start": "2739900",
    "end": "2748720"
  },
  {
    "text": "over the last 10 years. That's another story\nof astounding progress, but it has yet to\ntake us to the point",
    "start": "2748720",
    "end": "2755140"
  },
  {
    "text": "where we can actually\nwrite useful descriptions of these images that\nwould help a BLV user.",
    "start": "2755140",
    "end": "2760720"
  },
  {
    "text": "And that last bit\nis going to require HCI research,\nlinguistic research,",
    "start": "2760720",
    "end": "2765880"
  },
  {
    "text": "and fundamental advances in AI. And by the way, lots of\nastounding new datasets.",
    "start": "2765880",
    "end": "2772000"
  },
  {
    "text": "And this is just one example\nof the innumerable number of applied problems\nthat fall into this mode",
    "start": "2772000",
    "end": "2779260"
  },
  {
    "text": "and that can be very\nexciting for people who have domain\nexpertise that can help us close that final mile.",
    "start": "2779260",
    "end": "2786760"
  },
  {
    "start": "2788000",
    "end": "3473000"
  },
  {
    "text": "So let me wrap up here. I don't want to have\na standard conclusion. I think it's fun to close\nwith some predictions",
    "start": "2788500",
    "end": "2795400"
  },
  {
    "text": "about the future. And I have put this under\nthe heading of predictions for the next 10 years\nor so, although, I'm",
    "start": "2795400",
    "end": "2802900"
  },
  {
    "text": "about to retract that for\nreasons I will get to. But here are the predictions. First, laggard industries\nthat are rich in text data",
    "start": "2802900",
    "end": "2811240"
  },
  {
    "text": "will be transformed in\npart by NLP technology, and that's likely to happen\nfrom some disruptive newcomers",
    "start": "2811240",
    "end": "2817780"
  },
  {
    "text": "coming out of left field. Second prediction,\nartificial assistance will get dramatically better\nand become more ubiquitous",
    "start": "2817780",
    "end": "2825400"
  },
  {
    "text": "with the side effect that\nyou'll often be unsure in life whether this customer\nservice representative is",
    "start": "2825400",
    "end": "2831760"
  },
  {
    "text": "a person, or an AI, or some\nteam combining the two.",
    "start": "2831760",
    "end": "2835900"
  },
  {
    "text": "Many kinds of writing, including\nstudent papers at universities, will be done with AI\nwriting assistance.",
    "start": "2837280",
    "end": "2843640"
  },
  {
    "text": "And this might be\ntransparently true given how sophisticated\nautocomplete and other tools",
    "start": "2843640",
    "end": "2849220"
  },
  {
    "text": "have gotten at this point. And then finally, the negative\neffects of NLP and of AI",
    "start": "2849220",
    "end": "2855160"
  },
  {
    "text": "will be amplified along\nwith the positives. I'm thinking of things like\ndisinformation spread, market disruption, systemic bias.",
    "start": "2855160",
    "end": "2861880"
  },
  {
    "text": "It's almost sure to be the\ncase if it hasn't already happened already that there will\nbe some calamitous world event",
    "start": "2863080",
    "end": "2869140"
  },
  {
    "text": "that traces to the intentional\nor unintentional misuse of some AI technology.",
    "start": "2869140",
    "end": "2874960"
  },
  {
    "text": "That's in our future. So I think these are\nreasonable predictions, and I'm curious for yours.",
    "start": "2874960",
    "end": "2880120"
  },
  {
    "text": "But I have to tell you that I\nmade these predictions in 2020,",
    "start": "2880120",
    "end": "2885280"
  },
  {
    "text": "two years ago, with\nthe expectation that they would be\ngood for 10 years.",
    "start": "2885280",
    "end": "2890680"
  },
  {
    "text": "But more than half\nof them probably have already come true. Two and three are definitely\ntrue about the world",
    "start": "2891400",
    "end": "2897640"
  },
  {
    "text": "we live in. And on the flip\nside, I just failed to predict so many\nimportant things. The most prominent\nexample is that I just",
    "start": "2897640",
    "end": "2904060"
  },
  {
    "text": "failed to predict\nthe progress we would see in\ntext-to-image models like Dall-E2 and\nStable Diffusion.",
    "start": "2904060",
    "end": "2910720"
  },
  {
    "text": "In fact, I'll be\nhonest with you. I might have bet against them. I thought that was an\narea that was going",
    "start": "2910720",
    "end": "2916420"
  },
  {
    "text": "to languish for a long time, and\nyet nonetheless, seemingly out of nowhere, we had this\nincredible set of advances.",
    "start": "2916420",
    "end": "2922540"
  },
  {
    "text": "And there are probably\nlots of other areas where I would make\nsimilarly bad predictions. So I said 10 years,\nbut I think my new rule",
    "start": "2922540",
    "end": "2931480"
  },
  {
    "text": "is going to be that I'm going\nto predict only through 2024 at the very outside.",
    "start": "2931480",
    "end": "2936940"
  },
  {
    "text": "Because in 10 years, the only\nthing I can say with confidence",
    "start": "2936940",
    "end": "2942040"
  },
  {
    "text": "is that we will be in a\nradically different place from where we are now,\nbut what that place will be like is anyone's guess.",
    "start": "2942040",
    "end": "2948400"
  },
  {
    "text": "I'm interested in your\npredictions about it, but I think I will stop here. Thank you very much.",
    "start": "2948400",
    "end": "2954220"
  },
  {
    "text": "PETRA: Thank you so\nmuch, Chris, for engaging in an extremely interesting\ntopic and presentation you",
    "start": "2954840",
    "end": "2962140"
  },
  {
    "text": "have given. I'm always so amazed by all the\nnew things you're mentioning. Every single time we talk, I\nfeel there is something new,",
    "start": "2962140",
    "end": "2968860"
  },
  {
    "text": "something exciting. Not you-- not me. Especially not me,\nlike, expected you'll",
    "start": "2968860",
    "end": "2974260"
  },
  {
    "text": "be talking about it so soon. Many questions came in. I must already say we\nwill unfortunately not",
    "start": "2974260",
    "end": "2980020"
  },
  {
    "text": "be able to get to all of them\nbecause the time is limited, and the audience is so active,\nand so many people showed up.",
    "start": "2980020",
    "end": "2986140"
  },
  {
    "text": "So let me pick a few. Chris, so the costs\nof the training model.",
    "start": "2986140",
    "end": "2991480"
  },
  {
    "text": "So it seems it really\nscales with the size, and we are paying\na lot of attention and putting a lot of\neffort into the training.",
    "start": "2991480",
    "end": "2998080"
  },
  {
    "text": "So what does it mean for\nthe energy requirements? And I guess you are\ntalking about predictions, but how does it look like\nnow and what do you recommend",
    "start": "2998980",
    "end": "3006480"
  },
  {
    "text": "people to pay attention to? CHRISTOPHER POTTS: Oh,\nit's a wonderful set",
    "start": "3006480",
    "end": "3011820"
  },
  {
    "text": "of questions to be answering\nand critically important. I mean, I ask myself, if\nyou think about industries",
    "start": "3011820",
    "end": "3020880"
  },
  {
    "text": "in the world, some\nof them are improving in terms of their\nenvironmental impacts, some are getting much worse.",
    "start": "3020880",
    "end": "3026040"
  },
  {
    "text": "Where is artificial\nintelligence in that? Is it getting better\nor is it getting worse?",
    "start": "3026040",
    "end": "3031200"
  },
  {
    "text": "I don't know the answer. Because, on the one\nhand, the expenditure for training and now serving,\nfor example, GPT-3 to everyone",
    "start": "3031200",
    "end": "3039660"
  },
  {
    "text": "who wants to use it is\nabsolutely enormous, and it has real costs\nlike measured in emissions",
    "start": "3039660",
    "end": "3046500"
  },
  {
    "text": "and things like that. On the other hand, this is a\ncentralisation of all of that.",
    "start": "3046500",
    "end": "3052380"
  },
  {
    "text": "And that can often\nbring real benefits. And I want to not forget\nof the previous era where",
    "start": "3052380",
    "end": "3058559"
  },
  {
    "text": "every single person\ntrained every single model from scratch. And so now a lot of our\nresearch is actually just using",
    "start": "3058560",
    "end": "3066840"
  },
  {
    "text": "these frozen components. They were expensive, but\nthe expenditure of our lab is probably going way\ndown because we are not",
    "start": "3066840",
    "end": "3076080"
  },
  {
    "text": "training these big models. It kind of reminds me of\nthat last mile problem again. In the previous era,\nit was like we were all",
    "start": "3076080",
    "end": "3083220"
  },
  {
    "text": "driving to pick up our\ngroceries everywhere. Huge expenditure with all\nthose individual trips.",
    "start": "3083220",
    "end": "3088320"
  },
  {
    "text": "Now, it's much more\nlike they're all brought to the\nend of the street, and we walk to get them.",
    "start": "3088320",
    "end": "3093480"
  },
  {
    "text": "But of course, that's\ndone in big trucks, and those have real\nconsequences as well. I don't know but I hope\nthat a lot of smart people",
    "start": "3094140",
    "end": "3101880"
  },
  {
    "text": "will continue to\nwork on this problem and that will lead\nto benefits in terms of us doing all these things\nmore efficiently as well.",
    "start": "3101880",
    "end": "3108960"
  },
  {
    "text": "PETRA: Thank you so much. The next question, and you\ntouched on that a few times,",
    "start": "3109820",
    "end": "3116400"
  },
  {
    "text": "but it might be good to\nsummarize that a little bit because we got a\nlot of questions about the trustworthiness.",
    "start": "3116400",
    "end": "3123360"
  },
  {
    "text": "And if the model actually knows\nthat it's wrong or correct? And how do we trust the model?",
    "start": "3123360",
    "end": "3130560"
  },
  {
    "text": "How do we achieve the\ntrustworthiness of the model? Because right now, it's\na lot of the generation happening, generative\nmodels happening,",
    "start": "3130560",
    "end": "3137580"
  },
  {
    "text": "so how do we trust that? CHRISTOPHER POTTS: It's an\nincredibly good question,",
    "start": "3137580",
    "end": "3145200"
  },
  {
    "text": "and it is the thing I have\nin mind when we're doing all our work on explaining models.",
    "start": "3145200",
    "end": "3150840"
  },
  {
    "text": "Because I feel like offering\nfaithful human interpretable explanations is the step we can\ntake toward trustworthiness.",
    "start": "3151380",
    "end": "3157800"
  },
  {
    "text": "It's a very difficult problem. I just want to add that it\nmight be even harder than we've",
    "start": "3157800",
    "end": "3163500"
  },
  {
    "text": "anticipated because people\nare also pretty untrustworthy.",
    "start": "3163500",
    "end": "3167700"
  },
  {
    "text": "It's just that\nindividual people often don't have a systemic effect.",
    "start": "3168540",
    "end": "3174480"
  },
  {
    "text": "So if you're really doing\na poor job at something, you probably impact just\na handful of people,",
    "start": "3175080",
    "end": "3181080"
  },
  {
    "text": "and other people say, your\ncompany do a much better job. But these AIs are now it's\nlike they're everyone.",
    "start": "3181080",
    "end": "3188160"
  },
  {
    "text": "And so any kind of small\nproblem that they have is amplified across the entire\npopulation they interact with.",
    "start": "3188160",
    "end": "3195960"
  },
  {
    "text": "And that's going\nto probably mean that our standards for\ntrustworthiness for them need to be higher than\nthey are for humans.",
    "start": "3195960",
    "end": "3202560"
  },
  {
    "text": "And that's another\nsense in which they're going to have to\nbe superhuman to achieve the jobs we're asking of them.",
    "start": "3202560",
    "end": "3208620"
  },
  {
    "text": "And the field cannot offer\nguarantees right now.",
    "start": "3208620",
    "end": "3212640"
  },
  {
    "text": "So come help us. PETRA: Fascinating\nThank you so much. And I saw also some\nquestions or comments",
    "start": "3214080",
    "end": "3221280"
  },
  {
    "text": "about the bias in data,\nand like you mentioned, also we are improving. There is a big\nimprovement happening.",
    "start": "3221280",
    "end": "3227880"
  },
  {
    "text": "Last question for\nyou like a little bit of a thought experiment. But do you think that the\nlarge language models might",
    "start": "3229140",
    "end": "3236760"
  },
  {
    "text": "be able to come up with\nanswers to as yet unanswered important scientific\nquestions, like something",
    "start": "3236760",
    "end": "3242580"
  },
  {
    "text": "we are not even sure it even\nexists in our minds right now? CHRISTOPHER POTTS: Oh, it's\na wonderful question, yeah.",
    "start": "3242580",
    "end": "3249300"
  },
  {
    "text": "And people are asking this\nacross multiple domains. Like they're producing\nincredible artwork, but are we now trapped\ninside a feedback",
    "start": "3249300",
    "end": "3256380"
  },
  {
    "text": "loop that's going to lead to\nless truly innovative art? And if we ask them\nto generate text,",
    "start": "3256380",
    "end": "3261839"
  },
  {
    "text": "are they going to do either\nweird irrelevant stuff or just more of the boring\naverage case stuff?",
    "start": "3261840",
    "end": "3267660"
  },
  {
    "text": "I don't know the answer. I will say, though,\nthat these models have an incredible capacity\nto synthesize information",
    "start": "3269280",
    "end": "3275820"
  },
  {
    "text": "across sources. And I feel like that is a\nsource of innovation for humans",
    "start": "3275820",
    "end": "3282180"
  },
  {
    "text": "as well simply making\nthose connections. And it might be true that there\nis nothing new under the sun,",
    "start": "3282180",
    "end": "3288060"
  },
  {
    "text": "but there are lots of new\nconnections, perspectives, and so forth to be had. And I actually do\nhave faith that models",
    "start": "3288060",
    "end": "3295740"
  },
  {
    "text": "are going to be able to at\nleast simulate some of that, and it might look to\nus like innovation.",
    "start": "3295740",
    "end": "3300359"
  },
  {
    "text": "But this is not to say that\nthis is not a concern for us. It should be something we think\nabout, especially because we",
    "start": "3301560",
    "end": "3309780"
  },
  {
    "text": "might be heading into an era\nwhen whether we want them to or not, mostly\nthese models are trained on their own output,\nwhich is being put on the web",
    "start": "3309780",
    "end": "3316619"
  },
  {
    "text": "and then consumed when\npeople create train sets and so forth and so on. Yeah.",
    "start": "3316620",
    "end": "3321720"
  },
  {
    "text": "PETRA: Great. Thank you so much. And we are nearing the end. So last point, do you\nhave any last remarks?",
    "start": "3321720",
    "end": "3331440"
  },
  {
    "text": "Anything interesting\nyou would suggest others to look at, follow,\nread, learn about and get more",
    "start": "3332520",
    "end": "3340980"
  },
  {
    "text": "acquainted with the subject? Learn more about the NLU GPT-3,\nother large language models",
    "start": "3340980",
    "end": "3346200"
  },
  {
    "text": "and the recommendations? The thing that comes to mind\nbased on all the interactions I",
    "start": "3346200",
    "end": "3354600"
  },
  {
    "text": "have with the\nprofessional development students who've taken\nour course before is that a lot of\nyou, I'm guessing,",
    "start": "3354600",
    "end": "3361080"
  },
  {
    "text": "have incredibly valuable\ndomain expertise. You work in an\nindustry, in a position",
    "start": "3361080",
    "end": "3366720"
  },
  {
    "text": "that has taught\nyou tons of things and given you lots of skills. And my last mile\nproblem shows you",
    "start": "3366720",
    "end": "3374580"
  },
  {
    "text": "that that is relevant to\nAI, and therefore, you could bring it to bear\non AI, and we might all",
    "start": "3374580",
    "end": "3380400"
  },
  {
    "text": "benefit where you would be\ntaking all these innovations you can learn about in our\ncourse and other courses,",
    "start": "3380400",
    "end": "3385560"
  },
  {
    "text": "combining that with\nyour domain expertise, and maybe actually making\nprogress in a meaningful way",
    "start": "3385560",
    "end": "3392520"
  },
  {
    "text": "on a problem as opposed to\nmerely having demos and things that our scientific\ncommunity often produces.",
    "start": "3392520",
    "end": "3399360"
  },
  {
    "text": "Real impact so often requires\nreal domain expertise of the sort you all have.",
    "start": "3399360",
    "end": "3405240"
  },
  {
    "text": "PETRA: Great. Thank you so much. And yeah, at the end,\nthank you so much,",
    "start": "3405240",
    "end": "3410778"
  },
  {
    "text": "Chris for taking\nthe time to do this. I know beginning of the\nquarter, hectic Stanford life.",
    "start": "3410778",
    "end": "3417150"
  },
  {
    "text": "And I appreciate you\ntaking the time to do this, to run this webinar. Thank you also everybody who\nhad a chance to join us live",
    "start": "3417150",
    "end": "3424920"
  },
  {
    "text": "or who is watching\nthis recording. If you could please let\nus know what other topics",
    "start": "3424920",
    "end": "3430920"
  },
  {
    "text": "you might be interested in\nthis sort of a free webinar structure. We have a little survey\ndown on the console.",
    "start": "3430920",
    "end": "3438660"
  },
  {
    "text": "And yeah, hope you\nall have a great day. Wonderful start of end of the\nwinter, start of the spring.",
    "start": "3439860",
    "end": "3447720"
  },
  {
    "text": "And yeah, thank you,\neverybody for joining us. CHRISTOPHER POTTS: Yeah,\nPetra, this is wonderful. We got an astounding number\nof really great questions.",
    "start": "3447720",
    "end": "3453840"
  },
  {
    "text": "It's too bad we're out of time. There's a lot to\nthink about here, and so that's just\nanother thank you to the audience for all\nthis food for thought.",
    "start": "3453840",
    "end": "3460560"
  },
  {
    "text": "PETRA: Thank you.",
    "start": "3460560",
    "end": "3461640"
  }
]
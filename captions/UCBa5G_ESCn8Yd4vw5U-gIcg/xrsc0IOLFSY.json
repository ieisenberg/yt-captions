[
  {
    "start": "0",
    "end": "46000"
  },
  {
    "start": "0",
    "end": "4340"
  },
  {
    "text": "CHRISTOPHER POTTS:\nWelcome, everyone",
    "start": "4340",
    "end": "5840"
  },
  {
    "text": "to part 3 in our series\non grounded language",
    "start": "5840",
    "end": "7820"
  },
  {
    "text": "understanding.",
    "start": "7820",
    "end": "8780"
  },
  {
    "text": "Recall that in\npart 2, we focused",
    "start": "8780",
    "end": "10730"
  },
  {
    "text": "on speakers, speakers\nin our sense,",
    "start": "10730",
    "end": "12679"
  },
  {
    "text": "taking on linguistic\nrepresentations as inputs",
    "start": "12680",
    "end": "15470"
  },
  {
    "text": "and generate language\non that basis.",
    "start": "15470",
    "end": "18260"
  },
  {
    "text": "Listeners are the\nconverse of that.",
    "start": "18260",
    "end": "20270"
  },
  {
    "text": "They accept linguistic inputs.",
    "start": "20270",
    "end": "22340"
  },
  {
    "text": "And try to make a\nguess about the state",
    "start": "22340",
    "end": "24170"
  },
  {
    "text": "of the world on the basis\nof that linguistic input.",
    "start": "24170",
    "end": "27320"
  },
  {
    "text": "For this unit, in\nterms of modeling,",
    "start": "27320",
    "end": "29330"
  },
  {
    "text": "our focus is going\nto be on speakers.",
    "start": "29330",
    "end": "31550"
  },
  {
    "text": "But I think it's helpful to\nhave the listener perspective",
    "start": "31550",
    "end": "33950"
  },
  {
    "text": "in mind as you create speakers.",
    "start": "33950",
    "end": "35870"
  },
  {
    "text": "And you might even bring\nin the listener perspective",
    "start": "35870",
    "end": "38239"
  },
  {
    "text": "as part of your original system.",
    "start": "38240",
    "end": "40400"
  },
  {
    "text": "And I'll cover some\ntechniques for doing",
    "start": "40400",
    "end": "42110"
  },
  {
    "text": "that in the context of\nthe rational SpeechX model",
    "start": "42110",
    "end": "44720"
  },
  {
    "text": "a bit later in this series.",
    "start": "44720",
    "end": "47390"
  },
  {
    "start": "46000",
    "end": "177000"
  },
  {
    "text": "Now to make the speaker\ntask meaningful,",
    "start": "47390",
    "end": "49550"
  },
  {
    "text": "we need to complicate our\nprevious task a little bit.",
    "start": "49550",
    "end": "52410"
  },
  {
    "text": "So in part 2, we had for the\nspeaker, just a single colors",
    "start": "52410",
    "end": "56100"
  },
  {
    "text": "input.",
    "start": "56100",
    "end": "56600"
  },
  {
    "text": "And their task was to produce\na description on that basis.",
    "start": "56600",
    "end": "60313"
  },
  {
    "text": "For listeners,\nwe're going to move",
    "start": "60313",
    "end": "61730"
  },
  {
    "text": "to a more complicated task.",
    "start": "61730",
    "end": "63200"
  },
  {
    "text": "And this is the task that's\nour focus for the entire unit.",
    "start": "63200",
    "end": "66080"
  },
  {
    "text": "It comes from the Stanford\ncolors in context corpus.",
    "start": "66080",
    "end": "68615"
  },
  {
    "text": "And for that corpus,\nthe context is not just",
    "start": "68615",
    "end": "71360"
  },
  {
    "text": "a single color representation,\nbut now three colors.",
    "start": "71360",
    "end": "74540"
  },
  {
    "text": "And the idea is that the\nspeaker is privately told which",
    "start": "74540",
    "end": "77870"
  },
  {
    "text": "of those three is their target.",
    "start": "77870",
    "end": "79640"
  },
  {
    "text": "And they produce a description\nthat will hopefully",
    "start": "79640",
    "end": "82070"
  },
  {
    "text": "communicate to a listener, who's\nlooking at those same three",
    "start": "82070",
    "end": "85130"
  },
  {
    "text": "colors, which one was\nthe speaker's target.",
    "start": "85130",
    "end": "88600"
  },
  {
    "text": "You can see that gets really\ninteresting and grounded",
    "start": "88600",
    "end": "91070"
  },
  {
    "text": "very quickly.",
    "start": "91070",
    "end": "91830"
  },
  {
    "text": "So in this first case, the\nthree colors are very different.",
    "start": "91830",
    "end": "94920"
  },
  {
    "text": "And the speaker\nsimply said blue.",
    "start": "94920",
    "end": "96409"
  },
  {
    "text": "And that seems to\nget the job done.",
    "start": "96410",
    "end": "97980"
  },
  {
    "text": "And I think a listener\nreceiving blue as input",
    "start": "97980",
    "end": "100317"
  },
  {
    "text": "would know which of\nthese three colors",
    "start": "100317",
    "end": "101900"
  },
  {
    "text": "was the speaker's\nprivate target.",
    "start": "101900",
    "end": "104390"
  },
  {
    "text": "When we move to\nthe second context,",
    "start": "104390",
    "end": "105950"
  },
  {
    "text": "we have two competing blues.",
    "start": "105950",
    "end": "107655"
  },
  {
    "text": "They're very similar.",
    "start": "107655",
    "end": "108530"
  },
  {
    "text": "And as a result, the speaker\nsaid the darker blue one.",
    "start": "108530",
    "end": "111979"
  },
  {
    "text": "And the idea is that this\ncomparative here, darker blue,",
    "start": "111980",
    "end": "115310"
  },
  {
    "text": "is making the\nimplicit reference,",
    "start": "115310",
    "end": "117140"
  },
  {
    "text": "not only to the target\nbut to at least one",
    "start": "117140",
    "end": "120170"
  },
  {
    "text": "of the two distractors.",
    "start": "120170",
    "end": "122090"
  },
  {
    "text": "Third example is similar.",
    "start": "122090",
    "end": "123350"
  },
  {
    "text": "Teal, not the two\nthat are more green.",
    "start": "123350",
    "end": "125570"
  },
  {
    "text": "That's really grounded\nin the full context here.",
    "start": "125570",
    "end": "127820"
  },
  {
    "text": "The speaker is not\nonly identifying",
    "start": "127820",
    "end": "129949"
  },
  {
    "text": "properties of the\ntarget but also",
    "start": "129949",
    "end": "131660"
  },
  {
    "text": "properties of the distractor\nin order to draw out contrasts.",
    "start": "131660",
    "end": "136040"
  },
  {
    "text": "And I think the final\ntwo examples here are",
    "start": "136040",
    "end": "138170"
  },
  {
    "text": "interesting in different ways.",
    "start": "138170",
    "end": "140380"
  },
  {
    "text": "So here we have the\ntarget on the left.",
    "start": "140380",
    "end": "143300"
  },
  {
    "text": "In the first example,\nthe speaker said purple.",
    "start": "143300",
    "end": "145617"
  },
  {
    "text": "And in the second\nexample, the speaker",
    "start": "145617",
    "end": "147200"
  },
  {
    "text": "said blue even though these\nare identical colors here",
    "start": "147200",
    "end": "150830"
  },
  {
    "text": "for the targets.",
    "start": "150830",
    "end": "152060"
  },
  {
    "text": "The reason we saw a variation\nis because the distractors",
    "start": "152060",
    "end": "155120"
  },
  {
    "text": "are so different.",
    "start": "155120",
    "end": "156125"
  },
  {
    "text": "And that just shows you\nthat even though this",
    "start": "156125",
    "end": "158000"
  },
  {
    "text": "is a simple task,\nit is meaningfully",
    "start": "158000",
    "end": "159740"
  },
  {
    "text": "grounded in the full context\nthat we're talking about.",
    "start": "159740",
    "end": "164220"
  },
  {
    "text": "Now what we'll do for our\nlisteners is essentially",
    "start": "164220",
    "end": "166320"
  },
  {
    "text": "give them these\nutterances as inputs",
    "start": "166320",
    "end": "168450"
  },
  {
    "text": "and have them function\nas classifiers,",
    "start": "168450",
    "end": "170340"
  },
  {
    "text": "making a guess about\nwhich of the three colors",
    "start": "170340",
    "end": "172860"
  },
  {
    "text": "is the most likely, that the\nspeaker was trying to refer to.",
    "start": "172860",
    "end": "177765"
  },
  {
    "text": "So in a little more detail.",
    "start": "177765",
    "end": "178890"
  },
  {
    "text": "Here's the neural\nlistener model.",
    "start": "178890",
    "end": "180680"
  },
  {
    "text": "It's again, an\nencoder-decoder architecture.",
    "start": "180680",
    "end": "183200"
  },
  {
    "text": "For the encoder side, we can\nimagine some recurrent neural",
    "start": "183200",
    "end": "186073"
  },
  {
    "text": "network or something\nthat is going",
    "start": "186073",
    "end": "187490"
  },
  {
    "text": "to consume a sequence\nof tokens, look them up",
    "start": "187490",
    "end": "190460"
  },
  {
    "text": "in an embedding\nspace and then have",
    "start": "190460",
    "end": "191990"
  },
  {
    "text": "some sequence of hidden states.",
    "start": "191990",
    "end": "194810"
  },
  {
    "text": "For the decoder, the handoff\nhappens for the final encoder",
    "start": "194810",
    "end": "198080"
  },
  {
    "text": "state, presumably.",
    "start": "198080",
    "end": "199400"
  },
  {
    "text": "And what we're going to do here\nis extract some statistics,",
    "start": "199400",
    "end": "202370"
  },
  {
    "text": "in this case, a mean\nand covariance matrix,",
    "start": "202370",
    "end": "204950"
  },
  {
    "text": "and use those for scoring.",
    "start": "204950",
    "end": "207260"
  },
  {
    "text": "So in a little more detail.",
    "start": "207260",
    "end": "208920"
  },
  {
    "text": "We have those three colors\nthat's given for the listener.",
    "start": "208920",
    "end": "212060"
  },
  {
    "text": "Those are represented down here.",
    "start": "212060",
    "end": "213630"
  },
  {
    "text": "When we embed those\nin some color space,",
    "start": "213630",
    "end": "216050"
  },
  {
    "text": "we could use the\nFourier transform,",
    "start": "216050",
    "end": "217520"
  },
  {
    "text": "just like we did\nfor the speakers",
    "start": "217520",
    "end": "219020"
  },
  {
    "text": "at the end of the\nprevious screen test.",
    "start": "219020",
    "end": "221480"
  },
  {
    "text": "And then we'll use those extract\nstatistics from the encoder",
    "start": "221480",
    "end": "224629"
  },
  {
    "text": "to create a scoring function.",
    "start": "224630",
    "end": "226730"
  },
  {
    "text": "And then we just need to\ndefine a softmax classifier",
    "start": "226730",
    "end": "229099"
  },
  {
    "text": "on top of those scores.",
    "start": "229100",
    "end": "230390"
  },
  {
    "text": "And it will be that module\nthat makes it guess,",
    "start": "230390",
    "end": "233720"
  },
  {
    "text": "based on this encoder\nrepresentation, about which",
    "start": "233720",
    "end": "236900"
  },
  {
    "text": "of the three colors the\nspeaker was referring",
    "start": "236900",
    "end": "238879"
  },
  {
    "text": "to, so fundamentally, a kind\nof classification decision",
    "start": "238880",
    "end": "242420"
  },
  {
    "text": "in this continuous space\nof colors and encoder",
    "start": "242420",
    "end": "245270"
  },
  {
    "text": "representations.",
    "start": "245270",
    "end": "248460"
  },
  {
    "start": "247000",
    "end": "365000"
  },
  {
    "text": "Now once we start\nthinking in this mode,",
    "start": "248460",
    "end": "250290"
  },
  {
    "text": "I think a lot of\nother tasks can be",
    "start": "250290",
    "end": "252629"
  },
  {
    "text": "thought of as listener-based\ncommunication tasks.",
    "start": "252630",
    "end": "255590"
  },
  {
    "text": "So even the simplest classifiers\nare listeners in our sense.",
    "start": "255590",
    "end": "259829"
  },
  {
    "text": "They consume language.",
    "start": "259829",
    "end": "261390"
  },
  {
    "text": "And they make an\ninference about the world,",
    "start": "261390",
    "end": "263250"
  },
  {
    "text": "usually in a very\nstructured space, right?",
    "start": "263250",
    "end": "265320"
  },
  {
    "text": "So even in the simple case\nof our sentiment analysis,",
    "start": "265320",
    "end": "268410"
  },
  {
    "text": "you receive a linguistic\ninput, and you",
    "start": "268410",
    "end": "270600"
  },
  {
    "text": "make a guess about whether the\nstate is positive, negative,",
    "start": "270600",
    "end": "273130"
  },
  {
    "text": "or neutral as its\ncommon classifier.",
    "start": "273130",
    "end": "276070"
  },
  {
    "text": "But thinking of it as\na communication task",
    "start": "276070",
    "end": "278700"
  },
  {
    "text": "might bring new\ndimensions to the problem.",
    "start": "278700",
    "end": "282340"
  },
  {
    "text": "Semantic parsers are\nalso complex listeners.",
    "start": "282340",
    "end": "285130"
  },
  {
    "text": "They consume language.",
    "start": "285130",
    "end": "286510"
  },
  {
    "text": "They create a rich,\nlatent representations",
    "start": "286510",
    "end": "288630"
  },
  {
    "text": "out of logical form.",
    "start": "288630",
    "end": "290380"
  },
  {
    "text": "And then they predict into\nsome structured prediction",
    "start": "290380",
    "end": "292930"
  },
  {
    "text": "space like a database\nor something like that.",
    "start": "292930",
    "end": "296449"
  },
  {
    "text": "Scene generation is clearly\na kind of listener task.",
    "start": "296450",
    "end": "299730"
  },
  {
    "text": "In this task, you\nmap from language",
    "start": "299730",
    "end": "302510"
  },
  {
    "text": "to structured representations\nof visual scenes.",
    "start": "302510",
    "end": "306150"
  },
  {
    "text": "So it's a very complicated\nversion of our simple color",
    "start": "306150",
    "end": "308990"
  },
  {
    "text": "reference problem.",
    "start": "308990",
    "end": "310880"
  },
  {
    "text": "Young et al explored\nthe idea that we",
    "start": "310880",
    "end": "312530"
  },
  {
    "text": "might learn visual denotations\nfor linguistic expressions,",
    "start": "312530",
    "end": "315410"
  },
  {
    "text": "mapping from language into\nsome highly structured space",
    "start": "315410",
    "end": "319100"
  },
  {
    "text": "similar to same description.",
    "start": "319100",
    "end": "322310"
  },
  {
    "text": "Mei et al, 2015,\ndeveloped a sequence",
    "start": "322310",
    "end": "324680"
  },
  {
    "text": "to sequence model that's\nvery much like the above.",
    "start": "324680",
    "end": "327410"
  },
  {
    "text": "But the idea is that instead\nof having simple output spaces,",
    "start": "327410",
    "end": "331880"
  },
  {
    "text": "we have entire\nnavigational instructions",
    "start": "331880",
    "end": "334897"
  },
  {
    "text": "that we want to get.",
    "start": "334897",
    "end": "335730"
  },
  {
    "text": "So that's going from\na linguistic input",
    "start": "335730",
    "end": "337355"
  },
  {
    "text": "into some kind of\naction sequence.",
    "start": "337355",
    "end": "340680"
  },
  {
    "text": "And finally, the\nCerealBar data set",
    "start": "340680",
    "end": "342660"
  },
  {
    "text": "is an interesting one to\nexplore in our context.",
    "start": "342660",
    "end": "345780"
  },
  {
    "text": "That was a task of learning\nto execute full instructions.",
    "start": "345780",
    "end": "348990"
  },
  {
    "text": "So that's, again, mapping some\npretty complicated utterances",
    "start": "348990",
    "end": "352289"
  },
  {
    "text": "into some embedded\naction that you",
    "start": "352290",
    "end": "354570"
  },
  {
    "text": "want to take in a game world.",
    "start": "354570",
    "end": "356315"
  },
  {
    "text": "And that could be a very\nexciting extension of what",
    "start": "356315",
    "end": "359010"
  },
  {
    "text": "we've just been covering.",
    "start": "359010",
    "end": "361160"
  },
  {
    "start": "361160",
    "end": "365000"
  }
]
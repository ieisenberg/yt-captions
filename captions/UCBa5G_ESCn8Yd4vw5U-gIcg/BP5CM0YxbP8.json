[
  {
    "start": "0",
    "end": "5080"
  },
  {
    "text": "Today, I'm going to talk to\nyou about vision transformers. And this is all about\ntransformers, and specifically",
    "start": "5080",
    "end": "11410"
  },
  {
    "text": "their application for visual\nrepresentation learning. But before we jump\ninto transformers, I'm going to spend, like,\n10 or 15 minutes giving you",
    "start": "11410",
    "end": "18580"
  },
  {
    "text": "a lot of context on all\nof this, and specifically also on the vision\npart of things,",
    "start": "18580",
    "end": "24280"
  },
  {
    "text": "because I think a majority\nof what you have seen, and will see, will\nbe about language.",
    "start": "24280",
    "end": "30710"
  },
  {
    "text": "All right, so let's get started. My goal, and that of\nmy close collaborators, is to find general\nvisual representation.",
    "start": "30710",
    "end": "36890"
  },
  {
    "text": "And you're going to soon\nsee what that means. And why or what can\nwe do if we imagine",
    "start": "36890",
    "end": "42680"
  },
  {
    "text": "we have a general\nvisual representation? The hope is that\nwith this, we can kick-start all kinds of tasks\nthat require visual input.",
    "start": "42680",
    "end": "51320"
  },
  {
    "text": "It means most tasks that you do\nwhen you have your eyes open, basically, because if you have\na good understanding of what you",
    "start": "51320",
    "end": "58760"
  },
  {
    "text": "see, then you can much quicker\nunderstand what's going on and what you should do.",
    "start": "58760",
    "end": "66420"
  },
  {
    "text": "And eventually-- I have now\na little kid since the year. And so I really want that,\nwhen he's grown up, that there",
    "start": "66420",
    "end": "73970"
  },
  {
    "text": "is some kind of robot. It doesn't need to be nice\nand pretty like in movies-- just maybe an arm or whatever\nthat my kid could teach,",
    "start": "73970",
    "end": "81590"
  },
  {
    "text": "or my parents who cannot program\ncan teach to do some boring tasks that they really\ndon't want to do.",
    "start": "81590",
    "end": "87420"
  },
  {
    "text": "And then if even one\ncomponent of this is a good visual\nrepresentation that generalizes to understanding\nthe world visually everywhere.",
    "start": "87420",
    "end": "95960"
  },
  {
    "text": "It's not all that's required,\nbut it's one part, and the part that I'm trying to push. So this is for\ncontext and motivation",
    "start": "95960",
    "end": "102530"
  },
  {
    "text": "on working on visual\nrepresentation. And one good example of a\ngeneral visual representation",
    "start": "102530",
    "end": "107900"
  },
  {
    "text": "is the humans. And I'm going to show\nyou what I mean by that. So here is a task\nthat I give you.",
    "start": "107900",
    "end": "115640"
  },
  {
    "text": "There is three classes--\nclass A, B, and C. And I give you five\nimages of each class, OK?",
    "start": "115640",
    "end": "122150"
  },
  {
    "text": "And here, I'll give\nyou a new image. And I'm sure that by now, you\nall know which class it is.",
    "start": "122150",
    "end": "128989"
  },
  {
    "text": "I'm not going to ask because\nI don't actually see you. If I was in the room, I\nwould have you raise hands.",
    "start": "128990",
    "end": "134569"
  },
  {
    "text": "But I'm sure you know\nit's class A now. OK, this is fine. We have seen millions of\nflowers in our lives, hopefully.",
    "start": "134570",
    "end": "141560"
  },
  {
    "text": "But there is other\nkinds of pictures, like these satellite\nimages that you don't see much in your life.",
    "start": "141560",
    "end": "147019"
  },
  {
    "text": "Some people may have\nnever seen it-- sometimes like when you fly or maybe on\nTV or on the internet or so.",
    "start": "147020",
    "end": "152900"
  },
  {
    "text": "But it's rather rare. But still, same story-- three classes, class A, B,\nand C, five images of each.",
    "start": "152900",
    "end": "159740"
  },
  {
    "text": "And I show you a new image. This might be a little bit\nless trivial than the flower, but I think I've spent enough\ntime talking that, by now,",
    "start": "159740",
    "end": "168530"
  },
  {
    "text": "most of you should know that\nthis is class B. It shows-- what is it? Basketball court, right?",
    "start": "168530",
    "end": "173840"
  },
  {
    "text": " So now even more abstract-- you\ndon't see this in real life,",
    "start": "173840",
    "end": "179107"
  },
  {
    "text": "right? But still I give you\nimages of class A and B. I have just two, to\nmake it a bit easier",
    "start": "179107",
    "end": "184920"
  },
  {
    "text": "here, because you need to use\nyour brain a little bit more. And I show you this image.",
    "start": "184920",
    "end": "191390"
  },
  {
    "text": "And now I should do a little bit\nof small talk to let you think. Like, you see that there is\nspheres, boxes, and whatnot.",
    "start": "191390",
    "end": "199189"
  },
  {
    "text": "And by now I hope that most\nof that this is class A. Why?",
    "start": "199190",
    "end": "204230"
  },
  {
    "text": "Because there is three\nobjects in class. And class B is always,\nwhat is it, five objects,",
    "start": "204230",
    "end": "210900"
  },
  {
    "text": "no matter what they are,\nwhat they look like. I think by now, you\nmore or less understand",
    "start": "210900",
    "end": "217618"
  },
  {
    "text": "what I mean when I mean a\ngood visual representation or general visual\nrepresentation, right? Some I don't know how to call\nit in your brain, in your eyes,",
    "start": "217618",
    "end": "228740"
  },
  {
    "text": "such that you can\nquickly see something new and understand what's going\non with just a few examples,",
    "start": "228740",
    "end": "236210"
  },
  {
    "text": "and then generalize from that. And that's the goal. Then the next step--\nif we have the goal,",
    "start": "236210",
    "end": "242760"
  },
  {
    "text": "how do we measure\nprogress towards it? And this is a paper\nwe did a few years ago with my collaborators, which\nwe called the Visual Task",
    "start": "242760",
    "end": "250040"
  },
  {
    "text": "Adaptation Benchmark.\nit's a formalization of the little game\nthat we just played.",
    "start": "250040",
    "end": "255680"
  },
  {
    "text": "So it's a benchmark, and\nthere is some components that you or anybody who\nparticipated in benchmark does,",
    "start": "255680",
    "end": "262560"
  },
  {
    "text": "which is creating a\nmodel with some data. We don't really care what\ndata, what model, how whatnot.",
    "start": "262560",
    "end": "268849"
  },
  {
    "text": "Just you come with a model. Then we come with this landscape\nof all possible visual tasks",
    "start": "268850",
    "end": "275300"
  },
  {
    "text": "that make sense, which\nis a big statement, and we sample some\ntasks from that.",
    "start": "275300",
    "end": "282090"
  },
  {
    "text": "And this is the task\nthat you have just seen. They were actually taken out of\nthis task adaptation benchmark.",
    "start": "282090",
    "end": "289220"
  },
  {
    "text": "And we have, for\na first step, made 19 such tasks, where\nwe try to cover",
    "start": "289220",
    "end": "294379"
  },
  {
    "text": "broad types of visual tasks. Not just classes of natural\nimages, like these dogs",
    "start": "294380",
    "end": "300050"
  },
  {
    "text": "and cats things, but also\nvery specialized images like satellite image, and also\nknown classification tasks",
    "start": "300050",
    "end": "306410"
  },
  {
    "text": "that involve counting, like the\none I showed you before, right? But that can be expressed in\nthis simple classification API.",
    "start": "306410",
    "end": "313140"
  },
  {
    "text": "But that logically requires\nsome more thinking. Some things like distance,\nwe have something",
    "start": "313140",
    "end": "319130"
  },
  {
    "text": "with cars and with\ndistance of the closest car and things like that.",
    "start": "319130",
    "end": "324470"
  },
  {
    "text": "It should cover a broad\nrange of variation. And then with the model that\nyou came to this benchmark,",
    "start": "324470",
    "end": "331940"
  },
  {
    "text": "you can do some adaptation step\non each of the datasets, one after another all\nat the same time.",
    "start": "331940",
    "end": "337610"
  },
  {
    "text": "It doesn't really matter. But then, you should\nhave, as a result, a model of this dataset,\nwhich is very small.",
    "start": "337610",
    "end": "344150"
  },
  {
    "text": "It just has seen a few\nexamples for each class that then performs well there.",
    "start": "344150",
    "end": "349305"
  },
  {
    "text": "And then we just take\nthe average score across all of these\ntasks, and this is what we call the VTAB task. And this is how for\nnow we judge how",
    "start": "349305",
    "end": "359270"
  },
  {
    "text": "good of a generated visual\nrepresentation does your model and the adaptation\nalgorithm have.",
    "start": "359270",
    "end": "365150"
  },
  {
    "text": "And now, just for some\nnomenclature, is preparation. We have words that we\noften use, pre-training.",
    "start": "365150",
    "end": "370760"
  },
  {
    "text": "Sometimes, we call\nit the upstream, like upstream data, upstream\ntraining, something. So I may use this\nword interchangeably",
    "start": "370760",
    "end": "377480"
  },
  {
    "text": "with pre-training. And then there is\nthe second part, which we usually call transfer. And then sometimes,\nwe say downstream.",
    "start": "377480",
    "end": "384830"
  },
  {
    "text": "And the adaptation in\nprinciple is whatever you want. But for our work,\nwe almost always",
    "start": "384830",
    "end": "391250"
  },
  {
    "text": "just use very simple fine-tuning\nwithout any bells and whistles, because it's simple,\nand works well.",
    "start": "391250",
    "end": "396740"
  },
  {
    "text": "In general, we try to do\nthings as simple as possible as they work well. And so sometimes, I even\njust say like fine-tuning,",
    "start": "396740",
    "end": "403551"
  },
  {
    "text": "when fine-tuning, the thing's\nmoving from this pre-training through the transfer. ",
    "start": "403552",
    "end": "409790"
  },
  {
    "text": "All right, so so far for the\nsetting, so far, so good? ",
    "start": "409790",
    "end": "415659"
  },
  {
    "text": "Good. Then the question is,\nhow do we get there? And we spend a lot of\ntime thinking about this",
    "start": "415660",
    "end": "420800"
  },
  {
    "text": "and trying different things. And this is also roughly\nthe outline of all that I have available to talk\nabout, which doesn't mean we're",
    "start": "420800",
    "end": "428530"
  },
  {
    "text": "going to cover everything. So I'm not going to go\nthrough the outline exactly.",
    "start": "428530",
    "end": "433667"
  },
  {
    "text": "But you will see\nthis again and again. And as you see,\nvision transformer. The transformer only\ncomes a little bit later.",
    "start": "433667",
    "end": "439220"
  },
  {
    "text": "There's some stuff before it. So this one-- just\nreally quickly, because it doesn't\nmatter for these scores.",
    "start": "439220",
    "end": "445472"
  },
  {
    "text": "It's that we spent\nsome time trying self-supervised\npre-training, which is very popular in language,\nand in vision only recently",
    "start": "445472",
    "end": "451750"
  },
  {
    "text": "has become popular. And it doesn't work\nthat way, right? You don't need to\nunderstand these bars,",
    "start": "451750",
    "end": "458110"
  },
  {
    "text": "but basically, higher is better. And here, just look\nat the blue ones. That's the VTAB score\nfor this few-shot VTAB.",
    "start": "458110",
    "end": "466870"
  },
  {
    "text": "And self-supervised learning\nperformance like this bar. We tried multiple methods\nand multiple models",
    "start": "466870",
    "end": "472150"
  },
  {
    "text": "and so on, it's also\nproper good benchmark. But it was a couple\nof years ago.",
    "start": "472150",
    "end": "477790"
  },
  {
    "text": "Then we moved on to\nsemi-supervised training-- so a few labeled examples, and\na ton of unlabeled examples.",
    "start": "477790",
    "end": "483440"
  },
  {
    "text": "That's this next blue bar. Do you actually see\nthe mouse cursor? Sorry. ",
    "start": "483440",
    "end": "490070"
  },
  {
    "text": "We don't see the mouse cursor. Maybe I have to do some-- [INTERPOSING VOICES]",
    "start": "490070",
    "end": "497110"
  },
  {
    "text": " Yeah, so then semi-supervised\nis that blue bar,",
    "start": "497110",
    "end": "502680"
  },
  {
    "text": "which is a lot higher\nthan this other blue bar. So what this means to us is\nthat, by adding a few labeled",
    "start": "502680",
    "end": "507710"
  },
  {
    "text": "examples, we are able to get\nmuch better or a much more general visual representation.",
    "start": "507710",
    "end": "514280"
  },
  {
    "text": "Then I'm not going to\nspend more time on this and how exactly and so on. But I'm going to move to the\nnext one, which was for us kind",
    "start": "514280",
    "end": "520550"
  },
  {
    "text": "of a breakthrough, when\nwe figured out that, well, if we just scaled up fully\nsupervised pre-training,",
    "start": "520550",
    "end": "527300"
  },
  {
    "text": "then we get really much\nbetter representations than everything\nwe've seen before. And here, I want to briefly\nspend some time on that one,",
    "start": "527300",
    "end": "534140"
  },
  {
    "text": "because it's the precursor to\nusing transformers in vision.",
    "start": "534140",
    "end": "539200"
  },
  {
    "text": "So the idea is\nsimple that there are tons of images on the internet. That's always what\nyou hear as motivation",
    "start": "539200",
    "end": "544860"
  },
  {
    "text": "for self-supervised or\nunsupervised learning, right? But actually, where\nthese images come from,",
    "start": "544860",
    "end": "550170"
  },
  {
    "text": "there is almost always some\nextra information surrounding the image on the web. Or if you connected otherwise,\nthere's some extra information",
    "start": "550170",
    "end": "557940"
  },
  {
    "text": "there that you could use as\nsome weak source of information or some weak label, right?",
    "start": "557940",
    "end": "563670"
  },
  {
    "text": "Then it happens that\nin Google, there's some team that actually\ndoes this for production.",
    "start": "563670",
    "end": "568740"
  },
  {
    "text": "And they have collected\nalready a large dataset with some pipeline that from the\nsurrounding signals, somewhat",
    "start": "568740",
    "end": "574860"
  },
  {
    "text": "automatically, but very\nnoisily, annotates the images. And we wanted to figure\nout how far can we go",
    "start": "574860",
    "end": "582150"
  },
  {
    "text": "when we scale up pre-training. Then long story short, you\nneed a couple ingredients.",
    "start": "582150",
    "end": "588070"
  },
  {
    "text": "One is patience. I really like this plot. This is one of the curves of\njust pre-training on large data",
    "start": "588070",
    "end": "594149"
  },
  {
    "text": "with large models, OK? The details don't really matter. The gist is that, if I\nzoom into this little box,",
    "start": "594150",
    "end": "600360"
  },
  {
    "text": "I see this here. And this is the metric\nfor the training, like the performance\nin upstream,",
    "start": "600360",
    "end": "606149"
  },
  {
    "text": "that I see after spending\n8 GPU weeks of compute. What does GPU week mean? It means 8 GPUs for a week or--",
    "start": "606150",
    "end": "613650"
  },
  {
    "text": "sorry 1 GPU for\neight weeks or 8 GPUs for one week or 16 GPUs for\na half week and so on, right?",
    "start": "613650",
    "end": "621450"
  },
  {
    "text": "But this looks bad. A reasonable person\nwould say, yeah, there's no progress\nfor a week on 8 GPUs.",
    "start": "621450",
    "end": "626890"
  },
  {
    "text": "This is bad. I'm going to stop and\ntry something else. But we are not reasonable. So we keep going. And this is what the exact same\nspot looks like after 8 GPU",
    "start": "626890",
    "end": "634889"
  },
  {
    "text": "months of training. And you can clearly see that\nthings are progressing, right? So it may not always be\nobvious and you need patience.",
    "start": "634890",
    "end": "643320"
  },
  {
    "text": "The second thing is\nthat you actually need to scale up everything. So this was work done\nwith ResNets, not",
    "start": "643320",
    "end": "649200"
  },
  {
    "text": "yet with transformers. So you see a lot of\nResNet models here. The x-axis is the number\nof images available.",
    "start": "649200",
    "end": "655279"
  },
  {
    "text": "In vision, there is\nthis ImageNet dataset, which is a very super-common\ndataset for pre-training,",
    "start": "655280",
    "end": "660420"
  },
  {
    "text": "which has 1.3 million images. There's another one which has 10\ntimes more images that's still public, and then\nthere is one subset",
    "start": "660420",
    "end": "667620"
  },
  {
    "text": "from this internal group that\nhas 300 million labeled images. So the y-axis is a measure\nof accuracy on some tasks.",
    "start": "667620",
    "end": "676560"
  },
  {
    "text": "And we tried many. They all look similar. And the dots are\ndifferently sized ResNets.",
    "start": "676560",
    "end": "682019"
  },
  {
    "text": "The blue dot is the standard\nResNet 50 that everybody uses. If this only trained\non more data,",
    "start": "682020",
    "end": "687389"
  },
  {
    "text": "it looks promising at first. But if you go to\neven more data, it looks like, oh, OK this doesn't\nreally seem that useful.",
    "start": "687390",
    "end": "694230"
  },
  {
    "text": "And this is what\nmost people have been doing for a long time. And a lot of people, even\nat Google are like, yeah,",
    "start": "694230",
    "end": "700440"
  },
  {
    "text": "I tried this internal\ncheckpoint on this tons of data. It doesn't really\nhave that much.",
    "start": "700440",
    "end": "705910"
  },
  {
    "text": "However, what we\nfound out in hindsight is kind of obvious\nis that you actually",
    "start": "705910",
    "end": "711240"
  },
  {
    "text": "need to scale not just the\ndata, but also the model. Here is the blue dot. It's a gigantic ResNet\nthat is slow as heck.",
    "start": "711240",
    "end": "717360"
  },
  {
    "text": "But when you scale this\nup together with the data, you keep getting benefit\nwith adding more data. And then if you do\nthese two things,",
    "start": "717360",
    "end": "723900"
  },
  {
    "text": "scale up everything\nand be patient. Be patient could also be\nquite scale of your patience,",
    "start": "723900",
    "end": "732390"
  },
  {
    "text": "then you get a lot of benefits. So here is a few-shot\ntransfer learning-- what I showed you before.",
    "start": "732390",
    "end": "740190"
  },
  {
    "text": "On the x-axis is the\nsize of the model. On the y-axis is the accuracy\non one of these tasks.",
    "start": "740190",
    "end": "745540"
  },
  {
    "text": "But again, others look similar. And these three different\ncurves are pre-trained with different dataset\nsizes, the green one",
    "start": "745540",
    "end": "752250"
  },
  {
    "text": "being the standard one. You don't really see\nbenefit, or small benefit, from going with larger models.",
    "start": "752250",
    "end": "757620"
  },
  {
    "text": "The blue one is 10 times larger. You start seeing\nsome slope upwards. But really, only\nwith this giant data,",
    "start": "757620",
    "end": "763770"
  },
  {
    "text": "you start getting better\nand better and better at this few-shot\ntransfer learning, when you pre-train on more\nand more data with larger",
    "start": "763770",
    "end": "770160"
  },
  {
    "text": "and larger models. A second benefit that we did\nnot anticipate really at all,",
    "start": "770160",
    "end": "775530"
  },
  {
    "text": "but then found out,\nis that these models are super-robust when\nyou scale everything up.",
    "start": "775530",
    "end": "781390"
  },
  {
    "text": "This ObjectNet, it's a\ndataset that's specifically designed to measure\nrobustness, and it shows things crazy like\na chair in a bathtub",
    "start": "781390",
    "end": "788940"
  },
  {
    "text": "and things like that. And you should\nrecognize it as a chair. And here, the pink\ndots are basically",
    "start": "788940",
    "end": "795900"
  },
  {
    "text": "how existing models,\nand x-axis is again how large is the\nmodel, and the pink dot is existing ones\nfrom the literature.",
    "start": "795900",
    "end": "802529"
  },
  {
    "text": "And then these lines, same color\ncoding, is what we found out. And again, you see\nthis large data.",
    "start": "802530",
    "end": "808050"
  },
  {
    "text": "And then going to a\nlarge model, it just gives you amazing\nbenefits like in this case out of distribution robustness.",
    "start": "808050",
    "end": "815760"
  },
  {
    "text": "All right, so this was amazing. Scale up everything, be\npatient, and get huge benefit.",
    "start": "815760",
    "end": "822210"
  },
  {
    "text": "Sorry, Lucas. Sorry for interrupting you,\nbut there is a question from a student in the class.",
    "start": "822210",
    "end": "827769"
  },
  {
    "text": "Yeah. But do you want to unmute\nyourself and ask it yourself?",
    "start": "827770",
    "end": "833020"
  },
  {
    "text": "Yeah, I can ask my question. Can people hear me? Maybe there's some echo. One second, let me just\nstep away real quick.",
    "start": "833020",
    "end": "838420"
  },
  {
    "text": "Yeah, so the question\nI want to know is, what work has been done\ncharacterizing the parameters after pre-training finishes?",
    "start": "838420",
    "end": "843998"
  },
  {
    "text": "Like, the reason why I'm\nmotivating this question is it seems like we do\nthis tremendous amount of pre-training.",
    "start": "843998",
    "end": "849250"
  },
  {
    "text": "But it seems like we might be\nable to significantly reduce that if we just have smarter\ninitialization schemes.",
    "start": "849250",
    "end": "855700"
  },
  {
    "text": "Yeah, I've been thinking\nthis for a long time, actually, also.",
    "start": "855700",
    "end": "860830"
  },
  {
    "text": "And they've come to\nconclude that I think not.",
    "start": "860830",
    "end": "866630"
  },
  {
    "text": "I think there is two parts. One is what I like\nto call hand-waving the numerics of the weights.",
    "start": "866630",
    "end": "873520"
  },
  {
    "text": "Everything is in\na nice range, such that it can have nice\ninput-output functions and so",
    "start": "873520",
    "end": "878680"
  },
  {
    "text": "on and, that your\noptimizer can do steps that make reasonable changes to\nthe input-output function,",
    "start": "878680",
    "end": "884500"
  },
  {
    "text": "but not too large, and so on. I think that is part\nof it, and that you can get through a good\nimage or good normalizations",
    "start": "884500",
    "end": "891399"
  },
  {
    "text": "and whatnot. But then, I do think that\nthese models memorize a lot.",
    "start": "891400",
    "end": "897100"
  },
  {
    "text": "And then personally, I believe,\nbut I don't know if evidence or so that these models do more\nkind of remembering similarity",
    "start": "897100",
    "end": "907060"
  },
  {
    "text": "to things they've\nseen in training. And then as you grow things\nup, they have more memory",
    "start": "907060",
    "end": "912430"
  },
  {
    "text": "and they have seen more things. So they should be better\non more newer things, because there's more similar\nthings they have seen.",
    "start": "912430",
    "end": "919149"
  },
  {
    "text": "And this, I don't think\nyou can just create one shot from initialization.",
    "start": "919150",
    "end": "926600"
  },
  {
    "text": "But I don't have an\nimmediate pointer to a paper at the top of my head,\nto answer your question.",
    "start": "926600",
    "end": "931650"
  },
  {
    "text": "OK. Thank you. We also have more questions. So [INAUDIBLE] has posted on the\nchat and is raising his hand.",
    "start": "931650",
    "end": "941190"
  },
  {
    "text": "Maybe in this order, you want\nto ask your question, please? Yeah, for sure,\nI could go ahead. So I just had a quick\nclarification on this chart",
    "start": "941190",
    "end": "950410"
  },
  {
    "text": "right here, the chart number 3. The BiT-L BiT-M, and BiT-S,\nare they the same model",
    "start": "950410",
    "end": "956830"
  },
  {
    "text": "architecture, but just\ntrained on different datasets? So the BiT-S is trained\non the 1.3 million,",
    "start": "956830",
    "end": "962740"
  },
  {
    "text": "all the way to 300 million\nimage dataset or BiT-L? ",
    "start": "962740",
    "end": "968310"
  },
  {
    "text": "Yes and no. The architecture is\nhere on the x-axis. So within one\nvertical slice, these",
    "start": "968310",
    "end": "974280"
  },
  {
    "text": "are the same architecture. And then the different\npoints are random restarts, because when you\nfew-shot learning,",
    "start": "974280",
    "end": "980340"
  },
  {
    "text": "there is a lot of variance in\nwhich few examples do you see. And then again, this\nnext vertical slice",
    "start": "980340",
    "end": "986250"
  },
  {
    "text": "is the same model, and so on. And as you go to the right,\nthe model gets larger. And so you can see that\nfor this little data,",
    "start": "986250",
    "end": "992760"
  },
  {
    "text": "going to a larger\nmodel doesn't really help you much for pre-training--\nonly for this giant data.",
    "start": "992760",
    "end": "997860"
  },
  {
    "text": "It means the giant\ndata, not necessarily giant model in this case. Right, that makes\na lot of sense.",
    "start": "997860",
    "end": "1003620"
  },
  {
    "text": "Thank you. OK.  Do you have a question? I see you're raising\nyour hand as well.",
    "start": "1003620",
    "end": "1011600"
  },
  {
    "text": "[INAUDIBLE] Thanks. What is the intuition for\nthe upstream performance",
    "start": "1011600",
    "end": "1020050"
  },
  {
    "text": "in figure 1 spiking so\nsuddenly at [INAUDIBLE]",
    "start": "1020050",
    "end": "1025569"
  },
  {
    "text": "three points in training? You're right. Yeah. Yeah, again like\naround one point--",
    "start": "1025569",
    "end": "1032407"
  },
  {
    "text": "I don't know. That just seems like an\nodd-looking training curve. So what's the\nintuition behind that?",
    "start": "1032408",
    "end": "1039009"
  },
  {
    "text": "Yeah, this is old-school\ncomputer vision thing. By old school. I mean a few years ago.",
    "start": "1039010",
    "end": "1044049"
  },
  {
    "text": "This is when the\nlearning rate changes. In computer vision,\nit used to be very common to have\nthe learning rate",
    "start": "1044050",
    "end": "1049480"
  },
  {
    "text": "in a kind of staircase pattern. So it's constant for a\nwhile, and then you stop. You divide the learning rate\nby 10 usually or smaller,",
    "start": "1049480",
    "end": "1056830"
  },
  {
    "text": "and then you continue. And this gives you\nthis huge jump. And nowadays, people don't\nuse this much anymore.",
    "start": "1056830",
    "end": "1062919"
  },
  {
    "text": "And this work was, like,\nthree years ago I think, or two or three years ago. I don't remember. It was very common back then.",
    "start": "1062920",
    "end": "1068800"
  },
  {
    "text": "And nowadays, people use\nmore continuously changing learning rate schedule. And then you don't really have\nthis sudden change anymore.",
    "start": "1068800",
    "end": "1075820"
  },
  {
    "text": "But if you would overlay it,\nit would be more continuously, but going roughly the same.",
    "start": "1075820",
    "end": "1080960"
  },
  {
    "text": "And then in language, I think\nmost people or many people use just linearly pre-trained\nlearning schedule.",
    "start": "1080960",
    "end": "1086288"
  },
  {
    "text": "Also, you don't see this\neffect, because learning rate continuously decreases. OK.",
    "start": "1086288",
    "end": "1091450"
  },
  {
    "text": "Yeah, sounds good. Thanks. And then this is what\nbecause you ask about this,",
    "start": "1091450",
    "end": "1097710"
  },
  {
    "text": "is dotted line, actually here if\nyou're like here you could say, OK. But this is excessive, right?",
    "start": "1097710",
    "end": "1102840"
  },
  {
    "text": "Maybe it does really\nseem almost flat. Maybe you could have\nstarted the decay earlier",
    "start": "1102840",
    "end": "1108960"
  },
  {
    "text": "and earlier and\nearlier, and then you would get the same,\nbut much quicker. And this one shows\nwhat would happen then,",
    "start": "1108960",
    "end": "1115710"
  },
  {
    "text": "and you do land at a much\nworse place in the end than with the patient.",
    "start": "1115710",
    "end": "1121139"
  },
  {
    "text": "OK, yeah. Yeah, that makes sense. Thanks.",
    "start": "1121140",
    "end": "1126700"
  },
  {
    "text": "Was there any more\nquestion, or I continue? I think [INAUDIBLE]",
    "start": "1126700",
    "end": "1131720"
  },
  {
    "text": "Because I need to\nmention, I don't see you. I just see my slide. Yeah, it's fine.",
    "start": "1131720",
    "end": "1136870"
  },
  {
    "text": "We can coordinate that, Lucas. Hi. Yeah, so I just wanted to make\nsure that I'm on the same page.",
    "start": "1136870",
    "end": "1144857"
  },
  {
    "text": "So basically, what\nyou're trying to do is multi-task learning with\nconvolutional neural networks",
    "start": "1144857",
    "end": "1150549"
  },
  {
    "text": "slash LSTMs, right? That's kind of like ResNet. But you're doing multi-task\nlearning, correct?",
    "start": "1150550",
    "end": "1157159"
  },
  {
    "text": "No. Where does the multitask come\nfrom or why do you think-- Because initially,\nyou showed different--",
    "start": "1157160",
    "end": "1165365"
  },
  {
    "text": "[INTERPOSING VOICES] OK. But there is two phases.",
    "start": "1165365",
    "end": "1170789"
  },
  {
    "text": "The first one is\nthe pre-training. And this pre-training, I\ndidn't mention it, yeah.",
    "start": "1170790",
    "end": "1176330"
  },
  {
    "text": "I just said I don't care what\nyou do in the pre-training. Just pre-train somehow\nand give me the model.",
    "start": "1176330",
    "end": "1181490"
  },
  {
    "text": "And then I test it on\nmultiple tasks independently. And [INAUDIBLE] means\nthat I transfer it",
    "start": "1181490",
    "end": "1188179"
  },
  {
    "text": "to the task, which in our\ncase means fine-tune it just on the task, and then see\nhow well it does and so on.",
    "start": "1188180",
    "end": "1194150"
  },
  {
    "text": "But it could mean other things. Like later, we moved to just\nlearning a linear regression on top of the embeddings\nfor each task.",
    "start": "1194150",
    "end": "1201049"
  },
  {
    "text": "And now during the\npre-training, what we do is just regular supervised\nlearning, but just",
    "start": "1201050",
    "end": "1206270"
  },
  {
    "text": "scaling everything up. And regular supervised\nlearning is just-- well not much it has, but\nmuch label in the sense",
    "start": "1206270",
    "end": "1213899"
  },
  {
    "text": "that an image could have\na couple labels or not. But it usually doesn't\nhave these [INAUDIBLE]..",
    "start": "1213900",
    "end": "1219450"
  },
  {
    "text": "Got it. Thanks. ",
    "start": "1219450",
    "end": "1224730"
  },
  {
    "text": "[INAUDIBLE] had a question. Yeah, just have\na quick follow-up about the question-- like the\ndiscussion [INAUDIBLE] started",
    "start": "1224730",
    "end": "1233130"
  },
  {
    "text": "about this. It's like memorization or it's\nmore along memorizing the data in pre-training the dataset.",
    "start": "1233130",
    "end": "1238960"
  },
  {
    "text": "So I know in the\nlanguage side, there's a quite interesting phenomenon\nthat you can pre-train on a synthetic language\nthat doesn't have",
    "start": "1238960",
    "end": "1247530"
  },
  {
    "text": "any semantic meaning, but\nit only have structural pair premises or things like that.",
    "start": "1247530",
    "end": "1252550"
  },
  {
    "text": "And that actually gives\nyou almost the same boost in your downstream transfer\nas normal pre-training.",
    "start": "1252550",
    "end": "1259350"
  },
  {
    "text": "So I wonder if, say, like-- this means even for language,\nright, the structure seems",
    "start": "1259350",
    "end": "1265419"
  },
  {
    "text": "makes a large\ncontribution, which can be replaced by integerization. But I don't know\nif it's an image",
    "start": "1265420",
    "end": "1271020"
  },
  {
    "text": "is a different case maybe. Have people done maybe\nsome, I don't know, synthetic pre-training\ndataset for image?",
    "start": "1271020",
    "end": "1277679"
  },
  {
    "text": "[INTERPOSING VOICES] There was a paper. I forget the name\nand the authors, but it creates completely\nsynthetic images,",
    "start": "1277680",
    "end": "1284580"
  },
  {
    "text": "and not even rendering\nof some realistic things, but just completely\npatterns, waves,",
    "start": "1284580",
    "end": "1290400"
  },
  {
    "text": "and shapes, and so on, and\nuses it for pre-training. And then it shows that they\nget almost the same performance",
    "start": "1290400",
    "end": "1297000"
  },
  {
    "text": "as ImageNet quickly. They actually do this\nwith vision transformers. But yeah, they never go\nfurther, or it's not clear.",
    "start": "1297000",
    "end": "1305580"
  },
  {
    "text": "They show that you can almost\nget to this point here. And then it's not clear how\nmuch further can you go with it,",
    "start": "1305580",
    "end": "1313510"
  },
  {
    "text": "and I think probably\nnot much further. But it's just me guessing\nthe not much further.",
    "start": "1313510",
    "end": "1319110"
  },
  {
    "text": "I don't have evidence for this.  Thanks. So I have one question, and\nthen we'll continue the talk.",
    "start": "1319110",
    "end": "1327570"
  },
  {
    "text": "Said that even\nlarge vision models are learning some sort of\nsimilarity to the dataset they train on.",
    "start": "1327570",
    "end": "1333020"
  },
  {
    "text": "So do you think\nthey are behaving like prototypical\nnetworks in a sense? They're behaving\nlike what networks?",
    "start": "1333020",
    "end": "1339720"
  },
  {
    "text": "Oh, so like\nprototypical networks. Essentially, like when you're\ndoing few-shot learning, you just say, like, I'm\ngoing to learn a network",
    "start": "1339720",
    "end": "1347120"
  },
  {
    "text": "and learn the matrix space. ",
    "start": "1347120",
    "end": "1353220"
  },
  {
    "text": "Probably not exactly,\nbut close-ish. ",
    "start": "1353220",
    "end": "1358960"
  },
  {
    "text": "I mean, I cannot really say,\nbecause these are just some intuitive guesses that I\nhave that's what they do.",
    "start": "1358960",
    "end": "1364280"
  },
  {
    "text": "But nobody really knows what\ncan the models do, right? ",
    "start": "1364280",
    "end": "1369900"
  },
  {
    "text": "Yeah. I mean, we do get much-- when we do something like\nprototypical networks or the few-shot learning with\nthese pre-trained models,",
    "start": "1369900",
    "end": "1377549"
  },
  {
    "text": "we do get much worse performance\nthan when we do fine-tuning. So there is a bit\nmore to it then.",
    "start": "1377550",
    "end": "1384039"
  },
  {
    "text": "However, I don't know\nwhat is this more. OK.",
    "start": "1384040",
    "end": "1389490"
  },
  {
    "text": "Thanks. All right, let's continue. ",
    "start": "1389490",
    "end": "1399940"
  },
  {
    "text": "And I didn't mention, but\non ImageNet which is the top benchmark in computer vision,\nwith this work with the big",
    "start": "1399940",
    "end": "1407080"
  },
  {
    "text": "transfer, we finally were able\nto increase the score after there was a long period\nof a couple of years of no",
    "start": "1407080",
    "end": "1413919"
  },
  {
    "text": "improvement, but many attempts\nas you'll see the grey dots there. This was, yay, awesome--\npre-training, scaling up",
    "start": "1413920",
    "end": "1420549"
  },
  {
    "text": "everything, and\nleveraging the data. And then-- let's\nnot care about that.",
    "start": "1420550",
    "end": "1425890"
  },
  {
    "text": " This is just a little aside\nthat, if you are in the setting",
    "start": "1425890",
    "end": "1433120"
  },
  {
    "text": "that I mentioned of pre-training\non huge amounts of data and then testing on\nmany other tasks, you should, of\ncourse, be careful",
    "start": "1433120",
    "end": "1439540"
  },
  {
    "text": "that you don't have images\nfrom the other tasks in your pre-training\ndata, right?",
    "start": "1439540",
    "end": "1445360"
  },
  {
    "text": "Otherwise, you have seen\nthem during training, and then you're not\nreally generalizing, and you're just putting\nyourself with good scores.",
    "start": "1445360",
    "end": "1452470"
  },
  {
    "text": "And this is a real danger when\nwe get huge amounts of data, because the ImageNet\nimages can totally be",
    "start": "1452470",
    "end": "1457630"
  },
  {
    "text": "in huge amounts of data, right? So we actually use\nan internal pipeline",
    "start": "1457630",
    "end": "1462850"
  },
  {
    "text": "that is really good at\nfinding duplicates, and also new duplicates. When they are shifted,\nrotated, squeezed,",
    "start": "1462850",
    "end": "1468880"
  },
  {
    "text": "the color changes a bit,\nwhatnot, it still finds it. And we use this to completely\nremove all images from the test",
    "start": "1468880",
    "end": "1475570"
  },
  {
    "text": "datasets that we test on later. And we actually found\nthat a lot of procedures in vision datasets have clear\nduplicates between the training",
    "start": "1475570",
    "end": "1483340"
  },
  {
    "text": "and validation set,\nbetween the training set of ImageNet and CIFAR-10 and\nCIFAR-100 test sets, and so on.",
    "start": "1483340",
    "end": "1490960"
  },
  {
    "text": "So new duplicates are quite a\nwidespread problem in vision. And this slide is just to\nsay, hey, there are problems.",
    "start": "1490960",
    "end": "1497080"
  },
  {
    "text": "But in order to be\npresent, we actually took care of that in the\npre-training as best as we can.",
    "start": "1497080",
    "end": "1502400"
  },
  {
    "text": "We don't have near duplicates. Right, now back to being like,\nhey, we figured out large data,",
    "start": "1502400",
    "end": "1509853"
  },
  {
    "text": "our large model. And then things get\nreally good and that's how we got to\ntransformers, basically.",
    "start": "1509853",
    "end": "1516280"
  },
  {
    "text": "In computer vision, everything\nwas convolutional networks for many years. And basically, there\nwas nothing else.",
    "start": "1516280",
    "end": "1522565"
  },
  {
    "text": "CNN is king. However, in language, we saw a\ntransformation recently, right, that everything used\nto be LSTM everywhere.",
    "start": "1522565",
    "end": "1529900"
  },
  {
    "text": "LSTM was king. And then came the transformer. And in the case when there is a\nlot of data available, so many",
    "start": "1529900",
    "end": "1536320"
  },
  {
    "text": "transformers work\nmuch better than LSTM. For image data, it was\nstill not the case exactly.",
    "start": "1536320",
    "end": "1542890"
  },
  {
    "text": "So what we then\nthought is that, OK, so we are now in this regime\nwhere we have tons of data",
    "start": "1542890",
    "end": "1548380"
  },
  {
    "text": "and we see benefit from it. Can we see even more benefit\nif we try also the transformer",
    "start": "1548380",
    "end": "1553419"
  },
  {
    "text": "architecture in vision? And that's basically\nwhat we did.",
    "start": "1553420",
    "end": "1559179"
  },
  {
    "text": "To be fair, there were a few\nother attempts at trying out transformers on vision before. But I don't want to detail\ntoo much here, because I don't",
    "start": "1559180",
    "end": "1566919"
  },
  {
    "text": "want to point fingers too much. But they were all\nnot really using transformers for learning\neverything from the data.",
    "start": "1566920",
    "end": "1574870"
  },
  {
    "text": "It was always like,\nget something out of a ResNet first,\nlike object detection",
    "start": "1574870",
    "end": "1580750"
  },
  {
    "text": "proposals or high-level feature\nmaps or things like that, and then stick a little\ntransformer on top.",
    "start": "1580750",
    "end": "1586480"
  },
  {
    "text": "But we wanted to go all the way,\njust transformer everything. And so we came up with the\nsimplest and most natural,",
    "start": "1586480",
    "end": "1593110"
  },
  {
    "text": "I believe, way of\napplying transformers to vision, which is to take the\nimage, you cut it into pieces.",
    "start": "1593110",
    "end": "1599320"
  },
  {
    "text": "And that's it, like a\npuzzle [INAUDIBLE] pictures, and that's it.",
    "start": "1599320",
    "end": "1605470"
  },
  {
    "text": "Each of these pictures, you\ntake it and you project it into your embedding\nspace, which is",
    "start": "1605470",
    "end": "1611110"
  },
  {
    "text": "the input to the transformer. Embedding space is just\nabstract space of, let's say, 768 images, for example.",
    "start": "1611110",
    "end": "1618220"
  },
  {
    "text": "How do you embed it? You just take the pixel values\nand put a linear projection layer on top.",
    "start": "1618220",
    "end": "1623810"
  },
  {
    "text": "So take all the pixels, flatten\nthe vector, matrix multiply into whatever size you want,\nand use the same matrix",
    "start": "1623810",
    "end": "1631870"
  },
  {
    "text": "for all the pictures. And here, we just went\nthe simplest way ever with non-overlapping\npictures and everything.",
    "start": "1631870",
    "end": "1639010"
  },
  {
    "text": "You can, and people later\ndid, go on and say, hey, this is almost a convolution,\nlet's make proper convolution,",
    "start": "1639010",
    "end": "1645850"
  },
  {
    "text": "let's make a stack\nof them, whatnot. But this is our [INAUDIBLE]. This is just the simplest\nway to do it first.",
    "start": "1645850",
    "end": "1652480"
  },
  {
    "text": "Then we have these\nembedded pictures, and we treat them\nexactly literally like the tokens in\nlanguage, and then",
    "start": "1652480",
    "end": "1661450"
  },
  {
    "text": "give them to exactly the BERT\ntransformer from language first. And just like in language,\nwe add this class token,",
    "start": "1661450",
    "end": "1669429"
  },
  {
    "text": "or I think the language is,\nlike, end of sentence token or something. And we add the position\nembedding to the tokens that",
    "start": "1669430",
    "end": "1677860"
  },
  {
    "text": "can be learned. And then we feed all of this\nto a transformer encoder, which has an MLP head, which\nreads out this class token,",
    "start": "1677860",
    "end": "1687160"
  },
  {
    "text": "and then maps it to a Softmax\nlayer for classification, for example.",
    "start": "1687160",
    "end": "1692740"
  },
  {
    "text": "And that's it. That is the vision transformer. So it's literally you\ntake a BERT transformer, but instead of words\nor sentence tokens",
    "start": "1692740",
    "end": "1700649"
  },
  {
    "text": "it feeds in in patches\ntransformed as image tokens. And that's it, and then just\nthe same story as before.",
    "start": "1700650",
    "end": "1707350"
  },
  {
    "text": "Scale everything up-- compute,\ndataset, model size, patience, everything, and\nsee what happens.",
    "start": "1707350",
    "end": "1713750"
  },
  {
    "text": "Is this good or not? That was the question. And now we can see a plot here.",
    "start": "1713750",
    "end": "1719220"
  },
  {
    "text": "This is a similar\nplot as before. The gray area is actually where\nall of the BiT dots before.",
    "start": "1719220",
    "end": "1726360"
  },
  {
    "text": "And now the bubbles\nare vision transformers of different sizes. And the bubble is kind\nof the size of the model,",
    "start": "1726360",
    "end": "1734040"
  },
  {
    "text": "though it's a bit\nhard to see, exactly. And what you can see first\nis that with little data, ImageNet is the\n1.3 million images,",
    "start": "1734040",
    "end": "1741270"
  },
  {
    "text": "it works worse than ResNet's. So if we would not\nbelieve in this idea and just try this we say,\nOK, this is a crap idea.",
    "start": "1741270",
    "end": "1747840"
  },
  {
    "text": "And 1.3 million images\nis not that little. Then the 10 times\nlarger datasets",
    "start": "1747840",
    "end": "1753330"
  },
  {
    "text": "are in the same\nballpark as the ResNet. And when we go to\nmuch larger data",
    "start": "1753330",
    "end": "1758730"
  },
  {
    "text": "with a much larger\ntransformer, then we actually start outperforming this ResNet. And we outperform\nit just by little.",
    "start": "1758730",
    "end": "1765630"
  },
  {
    "text": "But this ResNet was\nreally hard to get, and is extremely clumsy\nand slow and big. So we were very excited by this.",
    "start": "1765630",
    "end": "1773765"
  },
  {
    "text": "Then we did more controlled\nstudies and everything, and one of them is using a\nsubset of this same dataset.",
    "start": "1773765",
    "end": "1779910"
  },
  {
    "text": "And there is lots of curves. But basically, just look\nat the dark gray one and the light blue one.",
    "start": "1779910",
    "end": "1786299"
  },
  {
    "text": "These are roughly similarly\nfast and clumsy or easy to use",
    "start": "1786300",
    "end": "1791580"
  },
  {
    "text": "or difficult to use BiT,\nwhich is a ResNet variant, and with the vision transformer.",
    "start": "1791580",
    "end": "1796933"
  },
  {
    "text": "And what you can see\nvision transformer, when we have\n\"little\" in quotes-- \"little data\" is really\nbad compared to ResNets.",
    "start": "1796933",
    "end": "1804270"
  },
  {
    "text": "But as we start having\na lot of data actually, it starts outperforming\nthe ResNet. And this is very promising,\nbecause I think everything",
    "start": "1804270",
    "end": "1811950"
  },
  {
    "text": "that looks huge and a lot and\nso on now, in five or ten years, it's maybe already there.",
    "start": "1811950",
    "end": "1817049"
  },
  {
    "text": "Like ten years ago,\nImageNet, this one, seemed to be huge and\nmassive amounts of data. No, not anymore.",
    "start": "1817050",
    "end": "1823530"
  },
  {
    "text": "So we should look to\nthe future, and this looks promising for the future. Then back to the same benchmark,\nthat was another little jump.",
    "start": "1823530",
    "end": "1832350"
  },
  {
    "text": "[INAUDIBLE] [INTERPOSING VOICES] Yeah, we have some questions. Yes.",
    "start": "1832350",
    "end": "1838320"
  },
  {
    "text": "There is also this\nsection about [INAUDIBLE].. Yeah. So it's in that order, if you\nwant to unmute yourself and ask",
    "start": "1838320",
    "end": "1847730"
  },
  {
    "text": "the questions. True, yeah. I think [INAUDIBLE] already\nanswered part of the question.",
    "start": "1847730",
    "end": "1854110"
  },
  {
    "text": "But I was wondering,\nin the input to the transformer,\nwhen you're chunking up the imaging to little puzzle\npieces, and then finding them,",
    "start": "1854110",
    "end": "1862940"
  },
  {
    "text": "does the order of getting\nthese patches in matter? Like, if you switch the\norder, does the prediction",
    "start": "1862940",
    "end": "1870010"
  },
  {
    "text": "maybe change? Yeah, that's a good question. And I actually have a slide\non something like this,",
    "start": "1870010",
    "end": "1876100"
  },
  {
    "text": "but not exactly. Let me jump there. So first of all, if the order\nis consistent during training,",
    "start": "1876100",
    "end": "1884169"
  },
  {
    "text": "right, and you don't shuffle the\norder again for each new image, then it's literally\nthe exact same.",
    "start": "1884170",
    "end": "1890243"
  },
  {
    "text": "You get the same\ncurve, same everything, because we don't encode\nthe order anywhere. If you start randomizing\nthe order all the time",
    "start": "1890243",
    "end": "1896799"
  },
  {
    "text": "during training,\nthen performance gets quite a lot worse. And let me show you why. This slide was on my\nplan to present, anyways.",
    "start": "1896800",
    "end": "1905260"
  },
  {
    "text": "Then if you ask about\nit, let's jump here. This is a visualization of\nthe position embeddings.",
    "start": "1905260",
    "end": "1911840"
  },
  {
    "text": "What does it mean? So in this case, we\nhad 14 by 14 patches that we cut the image in. So it means we have also 14\nby 14 position embeddings,",
    "start": "1911840",
    "end": "1921190"
  },
  {
    "text": "although we just see them as\none run sequence of, what is it, 150-something or--",
    "start": "1921190",
    "end": "1926200"
  },
  {
    "text": "I don't know, 140-something. And now each of these pictures\nshows the position embedding,",
    "start": "1926200",
    "end": "1933070"
  },
  {
    "text": "which corresponds\nto this location. How similar is it to all the\nother position embeddings?",
    "start": "1933070",
    "end": "1938809"
  },
  {
    "text": "So let's look at\nthis one for example. Yellow means they're perfectly\nsimilar, like exactly the same. And blue mean the opposite in\nterms of percent similarity.",
    "start": "1938810",
    "end": "1947200"
  },
  {
    "text": "So this position embedding\nis most similar to itself, which is the pixel here.",
    "start": "1947200",
    "end": "1952240"
  },
  {
    "text": "And then the\nneighboring pixels is how similar is it to the\nposition embeddings that correspond originally to\nthe neighboring patch.",
    "start": "1952240",
    "end": "1960669"
  },
  {
    "text": "And we do see a\nvery clear pattern. At each position, embedding is\nvery similar to the embedding",
    "start": "1960670",
    "end": "1965710"
  },
  {
    "text": "from its surrounding patches. And we didn't implement\nany of this, right?",
    "start": "1965710",
    "end": "1971890"
  },
  {
    "text": "We just had these\nposition embeddings at randomly\ninitialized variables, and they are learned\nas freely as the rest",
    "start": "1971890",
    "end": "1977860"
  },
  {
    "text": "of the parameters of the model. But they learn to recover this\nnotion of what are my neighbor patches, even though we don't\ngive this information anywhere",
    "start": "1977860",
    "end": "1985600"
  },
  {
    "text": "at any time, besides the\nraw image data and the task to please classify this image.",
    "start": "1985600",
    "end": "1992288"
  },
  {
    "text": "So that's pretty cool, I think. But it also means that if you\ntake the trained model now, and give patches in a completely\ndifferently structured order,",
    "start": "1992288",
    "end": "2001169"
  },
  {
    "text": "it's going to perform poorly,\nbecause these position embeddings don't\nmake sense anymore.",
    "start": "2001170",
    "end": "2006580"
  },
  {
    "text": "We did try also to implement\nposition embeddings which encode the location\nas hard-coded by us,",
    "start": "2006580",
    "end": "2015360"
  },
  {
    "text": "and other fancy position\nembeddings like relative ones. But basically,\nnone of that really",
    "start": "2015360",
    "end": "2021299"
  },
  {
    "text": "outperformed these\nfreely learned. And then the freely\nlearned is simple. You just send an image, let\nit learn as part of SGD,",
    "start": "2021300",
    "end": "2027480"
  },
  {
    "text": "and that's it. And so we go with that\nand suggesting that. ",
    "start": "2027480",
    "end": "2033340"
  },
  {
    "text": "Nice. It's awesome. OK. We have one more question\nfrom [INAUDIBLE]..",
    "start": "2033340",
    "end": "2038950"
  },
  {
    "text": "Hey, yeah, I was wondering--\nyeah, this slide. I think something that's\nreally interesting is we're talking about scaling\nup data and scaling",
    "start": "2038950",
    "end": "2045770"
  },
  {
    "text": "the model to be kind of small. But it seems like you're\nreaching and passing [INAUDIBLE] when you keep\ndoing this the same way.",
    "start": "2045770",
    "end": "2053469"
  },
  {
    "text": "So I'm curious if you\nhave any thoughts on that. Is that why these points\njust look like that, or is there kind of a best you\ncan sort of do where you're",
    "start": "2053469",
    "end": "2063339"
  },
  {
    "text": "pre-training the data or the\nparameters you're actually not going to get much movement? Yeah, I have another slide,\nbut much further in the talk",
    "start": "2063340",
    "end": "2070510"
  },
  {
    "text": "about that, where\nI would like to not jump on it if you don't mind.",
    "start": "2070510",
    "end": "2076730"
  },
  {
    "text": "And then maybe in 10 or 15\nminutes, we will be there. Sounds great. Thanks.",
    "start": "2076730",
    "end": "2081810"
  },
  {
    "text": " Yeah, maybe to be\na bit optimistic, it does seem like the\ntransformers have a better",
    "start": "2081810",
    "end": "2089179"
  },
  {
    "text": "slope here in the end. And there is the next\nplateau earlier, right? Sorry, Lucas, I did\nnot mean to interrupt.",
    "start": "2089179",
    "end": "2097029"
  },
  {
    "text": "Are there any other\nquestions before we proceed? Yeah, can I ask my\nquestion real quick?",
    "start": "2097030",
    "end": "2102310"
  },
  {
    "text": "Sorry about that. So what I'm curious\nto know is, how does this ViT compare\nto if you equip",
    "start": "2102310",
    "end": "2107850"
  },
  {
    "text": "a ConvNet so for example ResNet,\nwith an attention mechanism?",
    "start": "2107850",
    "end": "2113267"
  },
  {
    "text": "Like how much of this\nis going to distract from a transformer in the\nparticular way it operates versus just the\nbenefit of attention",
    "start": "2113267",
    "end": "2118830"
  },
  {
    "text": "that a vanilla ConvNet\ndoes not have access to? Yeah, this has been\ntried many times before.",
    "start": "2118830",
    "end": "2126400"
  },
  {
    "text": "And the first thing that I\nknow of was actually from-- I mispronounce his\nname, but Kaiming",
    "start": "2126400",
    "end": "2132140"
  },
  {
    "text": "He, the inventor of ResNet. And some of his colleagues,\nthey call it non-local networks.",
    "start": "2132140",
    "end": "2137369"
  },
  {
    "text": "This was, I think, even\nbefore the transformer paper, if I remember correctly.",
    "start": "2137370",
    "end": "2142680"
  },
  {
    "text": "And they basically\ninserted attention blocks at various locations\nin the ResNet. And then they\nshowed improvement,",
    "start": "2142680",
    "end": "2148230"
  },
  {
    "text": "but it was tiny improvements\nthat-- it was a cool block and a simple paper.",
    "start": "2148230",
    "end": "2153420"
  },
  {
    "text": "But it was not really worth it. And people usually\nplace their attention--",
    "start": "2153420",
    "end": "2159238"
  },
  {
    "text": "you can imagine, if you\nplace that attention just on the pixel and don't\ndo this patch cutting, this is way too expensive\ncomputationally.",
    "start": "2159238",
    "end": "2166859"
  },
  {
    "text": "So if you have 2 to 4 by 2\nto 4 pixels, that's like-- I cannot do this in my head. I don't know, 40,000\nor so maybe pixels",
    "start": "2166860",
    "end": "2174270"
  },
  {
    "text": "attending to 40,000 others. That doesn't work. So people just do it in the\nvery high and very final",
    "start": "2174270",
    "end": "2179730"
  },
  {
    "text": "layers of the ResNet, like\nwhere it's maybe 7 by 7. And then they add a bit of\nsprinkle, a bit of attention",
    "start": "2179730",
    "end": "2186570"
  },
  {
    "text": "there. But then you don't really\nget much benefit of scaling, because it's essentially\nstill a ResNet.",
    "start": "2186570",
    "end": "2192210"
  },
  {
    "text": "And in ResNet,\nthere is this block called [INAUDIBLE] site that\nhas gotten really popular",
    "start": "2192210",
    "end": "2201150"
  },
  {
    "text": "and improves ResNet quite a bit. And that is also kind\nof a form of attention,",
    "start": "2201150",
    "end": "2207089"
  },
  {
    "text": "but nicely tailored to images. Sorry, not doing. It's arguable.",
    "start": "2207090",
    "end": "2213450"
  },
  {
    "text": "But it has been tried\nmany times before, but it hasn't been shown\nto have this scaling",
    "start": "2213450",
    "end": "2220530"
  },
  {
    "text": "benefit as much as the ViT. So I think I'm missing\nsomething critical here, which is you just\nsaid it's intract,",
    "start": "2220530",
    "end": "2226920"
  },
  {
    "text": "or it's computationally\ndifficult to put an attention layer at a low\nlevel in the ResNet.",
    "start": "2226920",
    "end": "2232920"
  },
  {
    "text": "But why is it any different\nthan doing an attention layer in the vision transformer? Because we cut\nthe patches first.",
    "start": "2232920",
    "end": "2240140"
  },
  {
    "text": "So we have maybe\n14 by 14 patches, which is not that much.",
    "start": "2240140",
    "end": "2246309"
  },
  {
    "text": "OK, but I'm confused. Like, you could imagine not\nat a high layer in the ResNet,",
    "start": "2246310",
    "end": "2252910"
  },
  {
    "text": "but at a relatively pre\nlayer after you applied one or two\nconvolutional filters, or convolutional\nlayers, excuse me,",
    "start": "2252910",
    "end": "2259158"
  },
  {
    "text": "then you have\nsomething approximating the size of the patches. Now that's still 50 by\n50 at the early layers.",
    "start": "2259158",
    "end": "2266430"
  },
  {
    "text": "And that's-- 50 by 50 is significantly less\nthan, I don't know, like 400 by 400 or whatever.",
    "start": "2266430",
    "end": "2272280"
  },
  {
    "text": "But it's still 2,500 tokens\nattending to 2,500 tokens, which--",
    "start": "2272280",
    "end": "2277307"
  },
  {
    "text": "I mean, it's a lot. But it's not comparable. I don't know. OK, cool. Thank you.",
    "start": "2277308",
    "end": "2282520"
  },
  {
    "text": "Yeah. I mean, it could be tract, OK. And maybe another\nanswer to your question is then we're slowly getting\nto this, my next slide,",
    "start": "2282520",
    "end": "2290330"
  },
  {
    "text": "after this set of questions,\nwhere we do try something almost like what you said.",
    "start": "2290330",
    "end": "2297599"
  },
  {
    "text": "Have a very small\npart of the ResNet, and then stick a\ntransformer on top of it.",
    "start": "2297600",
    "end": "2303530"
  },
  {
    "text": "But like if we put a transformer\nand encoder on top of it, and not just sprinkle\na few attention layers,",
    "start": "2303530",
    "end": "2309349"
  },
  {
    "text": "and then continue with\n[INAUDIBLE] and so on. And this is this process,\nand we call them hybrid.",
    "start": "2309350",
    "end": "2315230"
  },
  {
    "text": "But actually, almost literally\nwhat you said actually. Like a few early\nlayers from the ResNet and with different\nvarying amounts,",
    "start": "2315230",
    "end": "2322010"
  },
  {
    "text": "and then stick it there\nfor transforming quota. And this seems to\nwork well, too,",
    "start": "2322010",
    "end": "2328069"
  },
  {
    "text": "especially for when\nyou exact in this case this amount of compute.",
    "start": "2328070",
    "end": "2333380"
  },
  {
    "text": "So for the little compute,\nit seems to work well. But then the scaling\nbehavior of the pure ResNet is a little better,\nso we focused on that.",
    "start": "2333380",
    "end": "2340670"
  },
  {
    "text": "I think we later tried also\nhybrid further to the right, and it was a bit lower. But it was after the\npaper, so it's not",
    "start": "2340670",
    "end": "2346430"
  },
  {
    "text": "on this plot, which I\njust cut out of the paper. But you can already see\nthe trend here, yeah. ",
    "start": "2346430",
    "end": "2353200"
  },
  {
    "text": "So if you don't\nscale all the way up, then this is a totally\nreasonable thing to do. Have a little bit of\nResNet, and then the encoder",
    "start": "2353200",
    "end": "2361620"
  },
  {
    "text": "from transformer.  Do you want to ask a question?",
    "start": "2361620",
    "end": "2369140"
  },
  {
    "text": "Yeah, I was just\nwondering about, basically, there\nwas a short section",
    "start": "2369140",
    "end": "2375160"
  },
  {
    "text": "in the paper about fine-tuning\nand higher resolution, and in that case, right,\nthe pre-trained position",
    "start": "2375160",
    "end": "2381640"
  },
  {
    "text": "embeddings, sorry,\nare skewed, right? And then it basically says that\nyou guys are interpolating.",
    "start": "2381640",
    "end": "2388359"
  },
  {
    "text": "Can you like talk on\nthat a little bit? Like, how do you\ninterpolate what's going on? Yeah, actually, when I checked\nthe slides earlier today,",
    "start": "2388360",
    "end": "2395645"
  },
  {
    "text": "I was like, oh, it would be\ncool to have a slide on that. [LAUGHTER] [INAUDIBLE] And then we don't have\na nice visualization",
    "start": "2395645",
    "end": "2401942"
  },
  {
    "text": "in the paper,\neither, because it's a bit difficult to explain. But this is the best\nstarting point we have.",
    "start": "2401943",
    "end": "2408350"
  },
  {
    "text": "So if you want to increase\nthe resolution of the image, and you keep the\npatch size fixed,",
    "start": "2408350",
    "end": "2413620"
  },
  {
    "text": "it means you have more\npatches suddenly, right? And then as you say,\nthe patch embeddings,",
    "start": "2413620",
    "end": "2418800"
  },
  {
    "text": "would you even use as\nposition embeddings, right? And basically, you can see here\nthat they learn a very regular",
    "start": "2418800",
    "end": "2426970"
  },
  {
    "text": "structure, right? We don't really know what is\nthe structure of these position embedding, the color. We just see the\nsimilarity to each other,",
    "start": "2426970",
    "end": "2433660"
  },
  {
    "text": "and that it is very regular. And so this gave\nus the impression that we may be able\nto just take them.",
    "start": "2433660",
    "end": "2442090"
  },
  {
    "text": "Imaging these boxes,\nthey slide apart and new boxes\nappear between them. And they are just\nthe interpolation",
    "start": "2442090",
    "end": "2448390"
  },
  {
    "text": "of the surrounding ones. And that's basically what we do\nwith the position embeddings.",
    "start": "2448390",
    "end": "2454570"
  },
  {
    "text": "We create new ones where\nthere are missing ones because we need more and by\ninterpolating the surrounding.",
    "start": "2454570",
    "end": "2462160"
  },
  {
    "text": "Or more precisely, we basically\nsee them as a picture-- in this case 14 by 14,\nwith 700-something channels",
    "start": "2462160",
    "end": "2470050"
  },
  {
    "text": "or whatever is the\ndimensionality. And then we basically\nresize this, like you would\nresize a picture--",
    "start": "2470050",
    "end": "2475840"
  },
  {
    "text": "by linear interpolation. And that way, we will get more\nand new position embeddings",
    "start": "2475840",
    "end": "2482280"
  },
  {
    "text": "that we don't understand\nwhere they are. But they follow the same\npattern as the learned ones and just at a higher\nresolution, basically.",
    "start": "2482280",
    "end": "2490300"
  },
  {
    "text": " Yeah, go ahead. Yeah, I just had\na quick question.",
    "start": "2490300",
    "end": "2499190"
  },
  {
    "text": "So when you are creating\nthe embedding as input,",
    "start": "2499190",
    "end": "2504940"
  },
  {
    "text": "right now you're doing\n[INAUDIBLE] projection [INAUDIBLE]. ",
    "start": "2504940",
    "end": "2510520"
  },
  {
    "text": "Has there been work\nto do [INAUDIBLE] pixels are close to each other?",
    "start": "2510520",
    "end": "2517000"
  },
  {
    "text": "Yeah, there were\nquite a few works that tried varying other things.",
    "start": "2517000",
    "end": "2522850"
  },
  {
    "text": "One that I especially\nliked recently, it's called \"Early Convolutions\nHelp Transformers See Better,\"",
    "start": "2522850",
    "end": "2528880"
  },
  {
    "text": "or is something like that. And they basically\nsay, OK, instead of this linear\nprojection, instead",
    "start": "2528880",
    "end": "2534100"
  },
  {
    "text": "of this one big linear\nprojection, we replace it by a stack of 3 by 3\nconvolution with a stride 2.",
    "start": "2534100",
    "end": "2542260"
  },
  {
    "text": "And then they have also\nnonlinearities between them, normalizations\nbetween them, but such that the overall stride is the\nsame as this patch [INAUDIBLE]..",
    "start": "2542260",
    "end": "2552070"
  },
  {
    "text": "So the outcome will then\nbe the same dimensionality as after this edge cutting,\nand then projecting.",
    "start": "2552070",
    "end": "2558970"
  },
  {
    "text": "And then they showed\nthat supposedly, it makes it a bit\neasier to optimize,",
    "start": "2558970",
    "end": "2565210"
  },
  {
    "text": "in the sense that more optimized\nsettings are good settings. In many scenarios, it performs\nthe same, but more robustly",
    "start": "2565210",
    "end": "2575560"
  },
  {
    "text": "to get there. And they also show\nsome scenarios where this performs much better.",
    "start": "2575560",
    "end": "2582069"
  },
  {
    "text": "Like, for example,\nwhen pre-training on-- actually when they\npre-trained on more data, that seems to\nperform even better.",
    "start": "2582070",
    "end": "2590799"
  },
  {
    "text": "I have played a bit with it\nand tried to reproduce it. I don't have it\nfully reproduced,",
    "start": "2590800",
    "end": "2596110"
  },
  {
    "text": "but I don't see as much\nbenefit as in the paper yet. But that's not to say\nthat the paper is wrong. Just that I didn't\nget there yet.",
    "start": "2596110",
    "end": "2604510"
  },
  {
    "text": "That is one example of that. There are other\npapers that do stuff. But this one, I found\nespecially interesting",
    "start": "2604510",
    "end": "2610480"
  },
  {
    "text": "because it's simple. Thank you. ",
    "start": "2610480",
    "end": "2616100"
  },
  {
    "text": "All right, continue? We don't have any\nmore questions. All right, then let's see.",
    "start": "2616100",
    "end": "2622640"
  },
  {
    "text": "Yeah, I have three more\ninteresting details from the paper. And then, depending on if you\nwant more discussion or more",
    "start": "2622640",
    "end": "2629300"
  },
  {
    "text": "content, I have more content,\nlike also the question about does it saturate here or not.",
    "start": "2629300",
    "end": "2635805"
  },
  {
    "text": "All right, so another\ninteresting thing that we had in the paper, but\nit is buried in the appendix--",
    "start": "2635805",
    "end": "2641359"
  },
  {
    "text": "and then follow up\npapers from others have been written\non this by now, actually, is like how should\nwe scale these transformers.",
    "start": "2641360",
    "end": "2649460"
  },
  {
    "text": "So right in the high-level\nshape of the transformer, there's lots of settings\nthat you could choose.",
    "start": "2649460",
    "end": "2657770"
  },
  {
    "text": "And we actually\ntried many of them. So we started with a reasonable\nmedium-sized transformer. It is the dot in the middle.",
    "start": "2657770",
    "end": "2663560"
  },
  {
    "text": "And then we varied\nthings one by one, such that we always\ndouble the compute.",
    "start": "2663560",
    "end": "2670880"
  },
  {
    "text": "So for example, this pink\nline, if we go to the right, this point increases\nthe width such",
    "start": "2670880",
    "end": "2677060"
  },
  {
    "text": "that we double the compute. X-axis is compute relative\nto this starting point.",
    "start": "2677060",
    "end": "2684410"
  },
  {
    "text": "And we have all of these\ndifferent settings. There is the width, which is how\nwide are the vectors with which",
    "start": "2684410",
    "end": "2690890"
  },
  {
    "text": "say, patching is done, which\nis for the base model 768, and then goes larger or smaller.",
    "start": "2690890",
    "end": "2698480"
  },
  {
    "text": "There is like here as\nyou see, scaling this does not seem promising. So we didn't scale that much.",
    "start": "2698480",
    "end": "2705022"
  },
  {
    "text": "Then there's other\nthings, like the width of the multilayer perceptron,\nor some people call it the 1",
    "start": "2705022",
    "end": "2710270"
  },
  {
    "text": "by 1 convolution in\nthese attentions. And this seems to\nscale a bit nicer. This orange part, I actually\nwonder where it went.",
    "start": "2710270",
    "end": "2717890"
  },
  {
    "text": "To the left? I don't remember. I don't know if it's\nhidden somewhere or if we just didn't scale\nit down, but anyways.",
    "start": "2717890",
    "end": "2724640"
  },
  {
    "text": "Then another thing\nto scale, which does not exist in the\ntransformers context, is the patch size.",
    "start": "2724640",
    "end": "2730370"
  },
  {
    "text": "As you make the\npatch smaller, you get more and more\ntokens out of an image, and thus, more and\nmore compute capacity.",
    "start": "2730370",
    "end": "2739280"
  },
  {
    "text": "This is the green one, which\nalso seems to scale nicely. Then the depth is an interesting\none, this yellow one.",
    "start": "2739280",
    "end": "2745940"
  },
  {
    "text": "And this is the number\nof encoder blocks. As we scale it first,\nit seems like, wow, this is the thing you want to scale.",
    "start": "2745940",
    "end": "2751882"
  },
  {
    "text": "But then it does\nseem to plateau. And it scales really badly\nif you decrease the depth.",
    "start": "2751882",
    "end": "2757483"
  },
  {
    "text": "So that's not a great\nthing to decrease. However, the width\nseems to be a good thing to decrease if you want\nto go to smaller models.",
    "start": "2757483",
    "end": "2763099"
  },
  {
    "text": "And then the blue is just\nscaling everything together, such that the compute\nhas kept everything",
    "start": "2763100",
    "end": "2768904"
  },
  {
    "text": "by roughly the same amount. It seems to scale nicely,\nas well as the rest,",
    "start": "2768905",
    "end": "2774890"
  },
  {
    "text": "and is relatively simple\nor at least conceptually. So we like this, so we\nwent with that whenever we scaled up or down the model.",
    "start": "2774890",
    "end": "2780619"
  },
  {
    "text": " And this one I really like\nis the inference speed,",
    "start": "2780620",
    "end": "2786540"
  },
  {
    "text": "because if you have the\nimage size of 2 to 4 pixels, it actually means you have 2\nto 4 by 2 to 4 pixels, right?",
    "start": "2786540",
    "end": "2792500"
  },
  {
    "text": "So if you have [INAUDIBLE]\nthen you patchify it with a 16 by 16, for example, patch size.",
    "start": "2792500",
    "end": "2798770"
  },
  {
    "text": "Then you have 14 by 14 patches. So that's the sequence length. It's actually 150, right?",
    "start": "2798770",
    "end": "2805310"
  },
  {
    "text": "And then on top of\nthe sequence length, you have the\nself-attention operation, which is square again.",
    "start": "2805310",
    "end": "2811760"
  },
  {
    "text": "So overall, with\nrespect to image size, the self-attention operation\nis 2 to the fourth power,",
    "start": "2811760",
    "end": "2818180"
  },
  {
    "text": "where it's equal to quartic. So that is really bad, right? Like, everybody who sees 0\nof something to the fourth",
    "start": "2818180",
    "end": "2825728"
  },
  {
    "text": "is like, what the\nhell are you doing? This never [INAUDIBLE]. So we checked what does it look\nlike in practice with the image",
    "start": "2825728",
    "end": "2833120"
  },
  {
    "text": "sizes that we operate in. And this is what you see here. On the y-axis is how\nfast it goes basically--",
    "start": "2833120",
    "end": "2840350"
  },
  {
    "text": "how fast it does inference. And on the x-axis it's\nvarying the input size.",
    "start": "2840350",
    "end": "2845869"
  },
  {
    "text": "And what this means is it\ndoesn't look so bad yet.",
    "start": "2845870",
    "end": "2851820"
  },
  {
    "text": "Basically, when you go here to\nthe 512 to the real large net, then you see that the\ntransformers actually",
    "start": "2851820",
    "end": "2857790"
  },
  {
    "text": "started going down a lot\nmore than the ResNets.",
    "start": "2857790",
    "end": "2862920"
  },
  {
    "text": "But in this reasonable\nimage size-- let's call it very typical, it\ndoesn't seem so bad in practice yet.",
    "start": "2862920",
    "end": "2868230"
  },
  {
    "text": "So we're not getting hit\nby the [INAUDIBLE] yet. But as we go larger, it\nwill likely be a problem.",
    "start": "2868230",
    "end": "2874415"
  },
  {
    "text": "And there have been a lot\nof follow-up works trying to make that better, right? ",
    "start": "2874415",
    "end": "2881540"
  },
  {
    "text": "Then this is the last one\nfrom the original ViT paper.",
    "start": "2881540",
    "end": "2887560"
  },
  {
    "text": "This is looking at the\ninput's receptive field size. So in the self-attention\noperation,",
    "start": "2887560",
    "end": "2893290"
  },
  {
    "text": "how far do heads\ntypically attend? And here on the x-axis, we\nsee the layer in the network.",
    "start": "2893290",
    "end": "2901509"
  },
  {
    "text": "To the right it's more towards\nthe output, the classes. And to the left it's more\ntowards the input, the patches.",
    "start": "2901510",
    "end": "2907690"
  },
  {
    "text": "And the y-axis is how far\non average across I think the whole validation set\ndoes the self-attention look,",
    "start": "2907690",
    "end": "2915280"
  },
  {
    "text": "and does look mean that the\npeak of the self-attention or the max how far is it away--",
    "start": "2915280",
    "end": "2921369"
  },
  {
    "text": "something like that. And each dot is\na different head, because we can use multi-head\nself-attention, right?",
    "start": "2921370",
    "end": "2928450"
  },
  {
    "text": "And so what this shows is that,\nin the early layers, actually, you have some heads that go\na little far, but also a lot",
    "start": "2928450",
    "end": "2934180"
  },
  {
    "text": "of heads that look very\nnearby them-- so locally. And as we go deeper\nin the model,",
    "start": "2934180",
    "end": "2939550"
  },
  {
    "text": "we only are left with heads\nthat on average look further. So is this some\nkind of analysis?",
    "start": "2939550",
    "end": "2947030"
  },
  {
    "text": "There is not immediately\naction to take about this, but it's interesting to see\nthat earlier layers there.",
    "start": "2947030",
    "end": "2952640"
  },
  {
    "text": "They learn a mixture of\nlooking to a local neighborhood and looking globally.",
    "start": "2952640",
    "end": "2957980"
  },
  {
    "text": "And later layers only look\nglobally anymore, right? ",
    "start": "2957980",
    "end": "2964290"
  },
  {
    "text": "So that is about the\noriginal vision transformers.",
    "start": "2964290",
    "end": "2970470"
  },
  {
    "text": "Now, I don't know how long\nyou wanted me to continue speaking or discussing. I have a couple of options\nthat I can talk about,",
    "start": "2970470",
    "end": "2978850"
  },
  {
    "text": "which is one project that\nwas further scaling up ViTs. And this one also has\nthe answer to the-- I can also jump straight to\nthe answer if you don't want",
    "start": "2978850",
    "end": "2985950"
  },
  {
    "text": "to hear the rest,\nbut to the question of how does it continue to\ndirect, are we saturating.",
    "start": "2985950",
    "end": "2992700"
  },
  {
    "text": "There is another project about\nhow to transition transformers when you don't have\nmassive amounts of data.",
    "start": "2992700",
    "end": "2998580"
  },
  {
    "text": "Can we still do it? Is it reasonable, or is it\nmaybe just unreasonable to do? This one is maybe too unrelated.",
    "start": "2998580",
    "end": "3004850"
  },
  {
    "text": "Let's not ask for this. And the last one\nis, like, I talked all about these benefits\nof really large model",
    "start": "3004850",
    "end": "3011960"
  },
  {
    "text": "when you pre-trained\nthem and lots of data. That's nice. That's how we get a good model. But then actually using\na model that is massive",
    "start": "3011960",
    "end": "3019790"
  },
  {
    "text": "is not fun at all. It doesn't fit on your GPU. You need multiple GPUs\nused to even use it.",
    "start": "3019790",
    "end": "3026030"
  },
  {
    "text": "So people are not\nhappy to use it. And usually, they go\nback to smallish models,",
    "start": "3026030",
    "end": "3031970"
  },
  {
    "text": "even though they know larger\nmodels should be better. What can we do about it?",
    "start": "3031970",
    "end": "3037860"
  },
  {
    "text": "That's another project we had,\nwhich is about distillation. So I would say to you guys,\nwhat do you prefer to do?",
    "start": "3037860",
    "end": "3046082"
  },
  {
    "text": "Or if you have\nplenty of questions, we can continue with\nthe questions now. Because I think now,\nthe original one hour",
    "start": "3046082",
    "end": "3051290"
  },
  {
    "text": "would be over, right? So I think one suggestion\nwas we can continue to talk.",
    "start": "3051290",
    "end": "3056780"
  },
  {
    "text": "And we will also be recording it\nso people later can go and see it, if they missed something.",
    "start": "3056780",
    "end": "3062720"
  },
  {
    "text": "So we could do that. Yeah, the other thing is, two\npeople have their hands raised. So we can [INAUDIBLE]\nquestions for us.",
    "start": "3062720",
    "end": "3070970"
  },
  {
    "text": "OK, up to you guys. I'm fine either way. ",
    "start": "3070970",
    "end": "3079040"
  },
  {
    "text": "So you guys want\nto ask a question?",
    "start": "3079040",
    "end": "3084750"
  },
  {
    "text": "Yeah, I just had a\npretty basic question. So if an object lies on the\nborder between the patches,",
    "start": "3084750",
    "end": "3092270"
  },
  {
    "text": "does that impact the model's\nperformance in any way? Yeah.",
    "start": "3092270",
    "end": "3097790"
  },
  {
    "text": "I mean, that's not\na basic question. It's a good question. ",
    "start": "3097790",
    "end": "3103650"
  },
  {
    "text": "There is a mix of answers. So one is, we didn't\nspecifically go and test this.",
    "start": "3103650",
    "end": "3108920"
  },
  {
    "text": "It would be an\ninteresting thing to test in a very controlled way with\nsome of the trained models.",
    "start": "3108920",
    "end": "3115010"
  },
  {
    "text": "That's for sure. The other thing is that when\nyou have a massive dataset,",
    "start": "3115010",
    "end": "3121339"
  },
  {
    "text": "like 300 million images,\nit's an insane amount. I used to try to\nconceptualize how much is",
    "start": "3121340",
    "end": "3127400"
  },
  {
    "text": "ImageNet, 1 million images. And I did the math. It's like if you go\nto an image, and look",
    "start": "3127400",
    "end": "3134569"
  },
  {
    "text": "at all of the images, each\nimage for a couple of seconds, you were sitting there for a\nmonth or something like that.",
    "start": "3134570",
    "end": "3139730"
  },
  {
    "text": "I don't remember. But so 300 million is\njust insanely massive. And then on top of\nthat, we do actually",
    "start": "3139730",
    "end": "3146720"
  },
  {
    "text": "use random augmentations, like\nrandom crap out of the image. So I would say it's\nthe default that you",
    "start": "3146720",
    "end": "3153380"
  },
  {
    "text": "see objects that don't fall\non a patch during the training already.",
    "start": "3153380",
    "end": "3158850"
  },
  {
    "text": "And if you look at\nhere, basically, this is the standard model,\nlike how the pictures are.",
    "start": "3158850",
    "end": "3164330"
  },
  {
    "text": "When we have 14 by 14, they\nlook roughly this size also.",
    "start": "3164330",
    "end": "3170240"
  },
  {
    "text": "Then an object is usually\nscattered across many patches, actually, because\nobjects in typical images",
    "start": "3170240",
    "end": "3177950"
  },
  {
    "text": "are relatively large. People don't take a picture\nwhere the object of interest is super tiny in the corner.",
    "start": "3177950",
    "end": "3184286"
  },
  {
    "text": "So this is the default that\nyou see during pre-training. And so I believe\nthat the model just learns to do that\nmuch better, actually.",
    "start": "3184287",
    "end": "3193609"
  },
  {
    "text": "Then the other answer\nto the question is like, OK, maybe if you did\nsome nicer thing than this very",
    "start": "3193610",
    "end": "3200210"
  },
  {
    "text": "crude patch cutting-- like for example, this stack of\nconvolutions that I mentioned,",
    "start": "3200210",
    "end": "3205230"
  },
  {
    "text": "maybe this is even better. Could be. ",
    "start": "3205230",
    "end": "3210920"
  },
  {
    "text": "Thank you.  OK, so you mentioned\nthat [INAUDIBLE]",
    "start": "3210920",
    "end": "3219710"
  },
  {
    "text": "transformers\n[INAUDIBLE] in the paper that they lack locality\nand a [INAUDIBLE]..",
    "start": "3219710",
    "end": "3230250"
  },
  {
    "text": "I was thinking, are these\nproperties that [INAUDIBLE]",
    "start": "3230250",
    "end": "3237580"
  },
  {
    "text": "and [INAUDIBLE],, and especially\nwhen you're in the [INAUDIBLE]..",
    "start": "3237580",
    "end": "3243010"
  },
  {
    "text": "So why is that we would\nprefer [INAUDIBLE]?? ",
    "start": "3243010",
    "end": "3252080"
  },
  {
    "text": "The audio was not that good. But I believe I\nunderstood the question, is that we say that transformer\nlacked locality bias or prior",
    "start": "3252080",
    "end": "3260210"
  },
  {
    "text": "or whatever, and why is this\neven something that we want, right? Wouldn't we want our models\nto know about locality",
    "start": "3260210",
    "end": "3267579"
  },
  {
    "text": "if they are about pictures\nin the first place? Yes and no.",
    "start": "3267580",
    "end": "3272690"
  },
  {
    "text": "So that's why I gave the\ncontext in the beginning. This is all about what happens\nwhen you scale things up.",
    "start": "3272690",
    "end": "3279710"
  },
  {
    "text": "And specifically in an ideal\nworld, at least in our mind,",
    "start": "3279710",
    "end": "3286640"
  },
  {
    "text": "we want gigantic\namounts of data. And we believe that\nit will just keep growing as the years\ngo by, and there",
    "start": "3286640",
    "end": "3294349"
  },
  {
    "text": "will be more and more\ndata just generally there. And then we want the\nmodel to have as little",
    "start": "3294350",
    "end": "3301130"
  },
  {
    "text": "of our thinking built\nin, because what we may think that is\ngood to solve the task",
    "start": "3301130",
    "end": "3308090"
  },
  {
    "text": "may actually not be\nbest to solve the task. Maybe the analogy\nwould be, like--",
    "start": "3308090",
    "end": "3314270"
  },
  {
    "text": "what was it, AlphaGo,\nthat made some moves that experts would\nsay, this is crazy, this is a silly move.",
    "start": "3314270",
    "end": "3319430"
  },
  {
    "text": "But it actually,\nthen, was much better. And in a similar way, we\nwant to encode as little as",
    "start": "3319430",
    "end": "3325550"
  },
  {
    "text": "possible into the model,\nsuch that if we just throw massive amounts of data\nin a difficult task at it,",
    "start": "3325550",
    "end": "3331695"
  },
  {
    "text": "it might think things that\nare even better that we didn't think of before. This is our approach,\nbecause we believe",
    "start": "3331695",
    "end": "3339109"
  },
  {
    "text": "that, as I mentioned\nI think already, what seems massive\nand excessive now",
    "start": "3339110",
    "end": "3345380"
  },
  {
    "text": "will be the norm in\nfive years or so. So that's where we want to go\nand look what's the direction.",
    "start": "3345380",
    "end": "3351539"
  },
  {
    "text": "However, if you want to just\nget something working now, and don't have massive\namounts of data",
    "start": "3351540",
    "end": "3358222"
  },
  {
    "text": "and don't want to use\na pre-trained model for some reason, which always\nuses a pre-trained model.",
    "start": "3358222",
    "end": "3364619"
  },
  {
    "text": "But if you don't\nwant to, then it makes total sense to bring in\nsome of your prior intuition",
    "start": "3364620",
    "end": "3370280"
  },
  {
    "text": "and knowledge of what should\nprobably have the model, like locality.",
    "start": "3370280",
    "end": "3376380"
  },
  {
    "text": "I hope this answered\nyour question. This is just a quick\nfollow-up [INAUDIBLE]..",
    "start": "3376380",
    "end": "3382690"
  },
  {
    "start": "3382690",
    "end": "3387859"
  },
  {
    "text": "We like any vision task? Isn't that like sort\nof, I don't know.",
    "start": "3387860",
    "end": "3393610"
  },
  {
    "text": "Maybe I'm not seeing\nexactly why we would not want those inductive biases.",
    "start": "3393610",
    "end": "3399980"
  },
  {
    "text": "If you maybe\nelaborate on that, why is it that we don't want\nlocality or translation that",
    "start": "3399980",
    "end": "3407158"
  },
  {
    "text": "could bring.  Well, ideally, we want the\nmodel that is powerful enough",
    "start": "3407158",
    "end": "3415200"
  },
  {
    "text": "to learn about this\nconcept itself, if it is useful\nto solve the task.",
    "start": "3415200",
    "end": "3421290"
  },
  {
    "text": "If it's not useful to solve the\ntask, then if we had put it in, there is no way for the\nmodel not to do this, right?",
    "start": "3421290",
    "end": "3430920"
  },
  {
    "text": "That is ideally the outcome. And in a similar way\nalso that in language, it",
    "start": "3430920",
    "end": "3436440"
  },
  {
    "text": "seemed to be nonsense\nto not encode from the left to right direction\nof text, like in [INAUDIBLE]..",
    "start": "3436440",
    "end": "3443873"
  },
  {
    "text": "But then comes\ntransformer, and it just doesn't and works\nmuch better if you throw a lot of data at it.",
    "start": "3443873",
    "end": "3449609"
  },
  {
    "text": "And it recovers that plus\nsome more, or a more flexible variant of it or something\nlike that, that is even",
    "start": "3449610",
    "end": "3456360"
  },
  {
    "text": "better for solving the task. So basically the idea\nis that we are not",
    "start": "3456360",
    "end": "3462930"
  },
  {
    "text": "as smart to design the thing,\nthe model in the way that would be best for the task.",
    "start": "3462930",
    "end": "3469230"
  },
  {
    "text": "Let's rather give it all the\nflexibility and all the data it needs to figure\nout what is the best",
    "start": "3469230",
    "end": "3474240"
  },
  {
    "text": "way of solving the task.  Thank you.",
    "start": "3474240",
    "end": "3481360"
  },
  {
    "text": "I believe this is a\nphilosophy of approaching it. I'm not saying this is\nthe only true way, right?",
    "start": "3481360",
    "end": "3487670"
  },
  {
    "start": "3487670",
    "end": "3493579"
  },
  {
    "text": "Yeah, so we have\naround seven minutes left before the scheduled\nend of the talk.",
    "start": "3493580",
    "end": "3498800"
  },
  {
    "text": "And Lucas, we want to\nbe mindful of your time as well because it is\nevening where you are.",
    "start": "3498800",
    "end": "3504660"
  },
  {
    "text": "So one thing we could do is-- I don't see any more\nquestions right now.",
    "start": "3504660",
    "end": "3510320"
  },
  {
    "text": "So you could quickly sort of\ngo over the last few bits, maybe skipping\nthrough the details",
    "start": "3510320",
    "end": "3516049"
  },
  {
    "text": "and just talking about\nthe final results. Yeah. I will do these\ntwo in a high level then those two that\nare still very, very",
    "start": "3516050",
    "end": "3523039"
  },
  {
    "text": "tied to transformers,\nand answer some questions that happened before. The first question was like, OK,\nare we saturating, yes or no?",
    "start": "3523040",
    "end": "3531320"
  },
  {
    "text": "And here, no.",
    "start": "3531320",
    "end": "3536330"
  },
  {
    "text": "This was the ViT\non this benchmark from the original\ntransformer paper.",
    "start": "3536330",
    "end": "3541370"
  },
  {
    "text": "But then, it's like these\ntransformers, when we use them, we just notice they have\nreally nice scaling properties.",
    "start": "3541370",
    "end": "3547310"
  },
  {
    "text": "And they seem\nactually to be easier to scale up without\npaying massive compute as",
    "start": "3547310",
    "end": "3552650"
  },
  {
    "text": "much as ResNets, just\nfrom that feeling from us having experience with both.",
    "start": "3552650",
    "end": "3557870"
  },
  {
    "text": "And so we went and\nlooked what happens if we scale vision transformer\njust as far up as we possibly",
    "start": "3557870",
    "end": "3564740"
  },
  {
    "text": "can. And we spent quite a lot of our\nblood into making this happen.",
    "start": "3564740",
    "end": "3570380"
  },
  {
    "text": "One part of it is\ngetting the dataset. So we went back to this\nGoogle internal team.",
    "start": "3570380",
    "end": "3577099"
  },
  {
    "text": "This 300 million\ndataset is just one out of many that they work with. And we asked around, and they\nbasically had three billion--",
    "start": "3577100",
    "end": "3584599"
  },
  {
    "text": "like 10 times larger\ndataset that we could also play around with. So there we go.",
    "start": "3584600",
    "end": "3590224"
  },
  {
    "text": "We want to scale up the dataset. And this is just showing, yes,\njust scaling up the dataset",
    "start": "3590225",
    "end": "3596150"
  },
  {
    "text": "and switching it\ngives you benefits, but that's not all of it. Then the next thing is\nwe needed to figure out",
    "start": "3596150",
    "end": "3603140"
  },
  {
    "text": "how to use less memory on\ndevices, like on a GPU or CPU, because already previously\nwith this score,",
    "start": "3603140",
    "end": "3610339"
  },
  {
    "text": "we fitted the model as\nmuch as we could fit. So we did a lot of clicks\nthat I will skip for now,",
    "start": "3610340",
    "end": "3616370"
  },
  {
    "text": "and are able to\nscale much larger. This plot shows the size of the\nmodel and the different shape",
    "start": "3616370",
    "end": "3624042"
  },
  {
    "text": "factors that I mentioned\nbefore, like the width of the [INAUDIBLE]\nx-axis, the self-attention with on the y-axis, and\nthen the different plots",
    "start": "3624042",
    "end": "3630690"
  },
  {
    "text": "are different layers\nfor the depth. These block are how\nlarge a transformer",
    "start": "3630690",
    "end": "3635810"
  },
  {
    "text": "we did in the original paper. And then, boom, one step\nfurther and two steps further, this is just a\nsuper-massive transformer",
    "start": "3635810",
    "end": "3643430"
  },
  {
    "text": "that we did in\nthis scaling paper, and with all of our tricks\non how much larger we",
    "start": "3643430",
    "end": "3649040"
  },
  {
    "text": "could go-- a lot larger. Then yeah, so we had some\nreally great stuff that is really cool.",
    "start": "3649040",
    "end": "3654410"
  },
  {
    "text": "I recommend people to look\nat square root learning rate schedule, which\nis cool, and often just mentioned as a side note.",
    "start": "3654410",
    "end": "3662480"
  },
  {
    "text": "It is also cool, but\nI'm going to skip it for the basic interest of time.",
    "start": "3662480",
    "end": "3668030"
  },
  {
    "text": "And basically, we\nscale it up a lot. And of course, again, we get\nalways this ImageNet number",
    "start": "3668030",
    "end": "3676880"
  },
  {
    "text": "a bit higher. This is actually plus 2%\non what we had before, which is very significant in\nthis high percentage range",
    "start": "3676880",
    "end": "3683540"
  },
  {
    "text": "there. But also what's very interesting\nis the few-shot again.",
    "start": "3683540",
    "end": "3688880"
  },
  {
    "text": "By just keeping\nscaling up everything, we get super-large\nfew-shot again. This is ImageNet top-1 accuracy.",
    "start": "3688880",
    "end": "3695780"
  },
  {
    "text": "And for example,\nwith just 10 images per image in a class, which\nmeans 10,000 images total,",
    "start": "3695780",
    "end": "3702589"
  },
  {
    "text": "because 1,000 classes, we\nget this big of a graph. We get 85% top-1 accuracy,\nwhich is what you typically",
    "start": "3702590",
    "end": "3713000"
  },
  {
    "text": "get when using the full\ndataset, basically. So [INAUDIBLE] up, it makes\nactually a few-shot work",
    "start": "3713000",
    "end": "3720750"
  },
  {
    "text": "significantly better. And then I'm going\nto skip on this. Well, this actually has\nan interesting message.",
    "start": "3720750",
    "end": "3726539"
  },
  {
    "text": "This is three times\nthe same story, but measured in a slightly\ndifferent way, which is that if you make\nthe model larger,",
    "start": "3726540",
    "end": "3733950"
  },
  {
    "text": "it actually needs\nto see fewer images to get to a similar score. Like, this blue line is a\ntiny vision transformer,",
    "start": "3733950",
    "end": "3742140"
  },
  {
    "text": "and the base vision\ntransformer in the large one. And the y-axis is the error. So lower is better.",
    "start": "3742140",
    "end": "3747930"
  },
  {
    "text": "And actually, still, we are\ntalking in millions of images. And here, it's 100\nmillion images.",
    "start": "3747930",
    "end": "3753839"
  },
  {
    "text": "But still, you need to see a\nlot fewer images with the larger models. Doesn't mean a lot\nless compute, right,",
    "start": "3753840",
    "end": "3759600"
  },
  {
    "text": "because the model is larger and\nslower, but it's interesting. And then there's\nsome scaling loss",
    "start": "3759600",
    "end": "3765780"
  },
  {
    "text": "that are popular in\nlanguage, and I think maybe for the first time in\ndiscriminative image",
    "start": "3765780",
    "end": "3772710"
  },
  {
    "text": "showed that they\nappear to be here, too. And then, right,\nthen we want to--",
    "start": "3772710",
    "end": "3781440"
  },
  {
    "text": "sorry, I had the order of the\nslides mixed up in my head. That's why I'm a bit surprised. But then another thread was\nthat, besides further scaling",
    "start": "3781440",
    "end": "3788640"
  },
  {
    "text": "up the model, we wanted\nto push even further into this direction of less\nhand engineering of things",
    "start": "3788640",
    "end": "3796590"
  },
  {
    "text": "into the model architecture. And then with the\nvision transformer, or transform in general,\nwhat is the obviously",
    "start": "3796590",
    "end": "3803760"
  },
  {
    "text": "most hand-engineered part\nof it is the self-attention. So we tried, can we do\nsomething more generic than that",
    "start": "3803760",
    "end": "3811410"
  },
  {
    "text": "and less smart than\nthat, basically. And we ended up by\nreplacing it, essentially,",
    "start": "3811410",
    "end": "3816539"
  },
  {
    "text": "with just a\nmulti-layer perceptron. That, however, has a\nlittle bit of structure",
    "start": "3816540",
    "end": "3823840"
  },
  {
    "text": "but much less than\nself-attention. So I will skip the structure\nfor the sake here of time.",
    "start": "3823840",
    "end": "3829720"
  },
  {
    "text": "And we're coming back to this\nplot, where the question was, aren't we saturating? Now, this plot is\nslightly different.",
    "start": "3829720",
    "end": "3836060"
  },
  {
    "text": "We again have this BiT\nResNet here in black, and the full green line\nis the vision transformer.",
    "start": "3836060",
    "end": "3842680"
  },
  {
    "text": "And the other color\nalso, the full lines are the vision transformers. This is exactly the same\nnumbers as from before.",
    "start": "3842680",
    "end": "3849050"
  },
  {
    "text": "However, now we also throw\nin this mixed architecture, which we believe is even\nmore flexible and less hand",
    "start": "3849050",
    "end": "3855007"
  },
  {
    "text": "engineered data transform. And as you see, with less\ndata, it's even worse. However, with much\nmore data, it may",
    "start": "3855007",
    "end": "3862569"
  },
  {
    "text": "be surpassing the transformer\nor it may be random lines. It's not clear at\nthis point, right,",
    "start": "3862570",
    "end": "3869020"
  },
  {
    "text": "because it's the only\npoint where this happens. So we need to go further. So we used this 3 billion\ndataset, for example,",
    "start": "3869020",
    "end": "3876670"
  },
  {
    "text": "from the previous paper that\nI mentioned here, and tried to extend these lines to the\nright to see what happens.",
    "start": "3876670",
    "end": "3884230"
  },
  {
    "text": "We don't extend many\nof them because these are very expensive experiments\nthat require a ton of patience.",
    "start": "3884230",
    "end": "3890289"
  },
  {
    "text": "But we extended two\nmost interesting, and it seems that it continues. And that first of all,\nyes, the vision transformer",
    "start": "3890290",
    "end": "3898040"
  },
  {
    "text": "keeps increasing. We don't have such\nexperiments with the ResNet because it doesn't\nlook promising enough",
    "start": "3898040",
    "end": "3904450"
  },
  {
    "text": "to pay the cost of doing it. But it also seems\nthat the mixer, what",
    "start": "3904450",
    "end": "3909700"
  },
  {
    "text": "we believe is even more\nflexible architecture actually, is consistently\nabove the transformer now, which is good news.",
    "start": "3909700",
    "end": "3917079"
  },
  {
    "text": "And yeah, it is good news. So we're now right at the time\nwhen I should stop or open",
    "start": "3917080",
    "end": "3924180"
  },
  {
    "text": "to more questions again. Yeah, I guess [INAUDIBLE]\nhas a question.",
    "start": "3924180",
    "end": "3929240"
  },
  {
    "text": "Can I ask a follow-up\non the scaling that you were showing earlier? It's really integral\nto my question.",
    "start": "3929240",
    "end": "3935119"
  },
  {
    "text": "I'm curious how this\nmodel size compares to model sizes for BERT or\nnatural language models,",
    "start": "3935120",
    "end": "3943970"
  },
  {
    "text": "like especially going\nfrom smaller models to much bigger models. Are they comparable at all\nin terms of model size?",
    "start": "3943970",
    "end": "3950870"
  },
  {
    "text": "And if not, why do you think-- what is different for the models\nfor these two different tasks?",
    "start": "3950870",
    "end": "3957290"
  },
  {
    "text": "Yeah, actually, a colleague of\nmine has a slide, which I hate. But he learned it's the\nmodel number of parameters",
    "start": "3957290",
    "end": "3964310"
  },
  {
    "text": "in NLP and in vision. And the question is, how do\nyou measure your model size?",
    "start": "3964310",
    "end": "3970100"
  },
  {
    "text": "If you just measure a\nnumber of parameters, then these visual\nmodels are much smaller.",
    "start": "3970100",
    "end": "3975210"
  },
  {
    "text": "However, the language\nmodel's number of parameters, like a huge chunk\nof it, is in the dictionary,",
    "start": "3975210",
    "end": "3981500"
  },
  {
    "text": "for example, which\nfor us just doesn't exist if there's linear\nembedding, which is a trivial number of parameters.",
    "start": "3981500",
    "end": "3989160"
  },
  {
    "text": "So in terms of number of\nparameters, it's much smaller. My personal opinion is\nthat number of parameters",
    "start": "3989160",
    "end": "3994869"
  },
  {
    "text": "doesn't mean that much. Then the other way\nthat you could measure is maybe in terms of compute.",
    "start": "3994870",
    "end": "4001150"
  },
  {
    "text": "Like, how much floating\npoint operations does it do on one data point?",
    "start": "4001150",
    "end": "4006400"
  },
  {
    "text": "And in terms of this,\nit's in the same ballpark. However, last time\nI checked, which",
    "start": "4006400",
    "end": "4011920"
  },
  {
    "text": "is quite a few months ago,\nthe largest language model was still, like, four times\nmore or five times more",
    "start": "4011920",
    "end": "4018760"
  },
  {
    "text": "in the vision model, I believe. Yeah, so that's the two ways\nof measuring model size.",
    "start": "4018760",
    "end": "4025360"
  },
  {
    "text": "I don't think either of the\nways is the one true way to measure model size. And I think it's actually an\ninteresting research topic,",
    "start": "4025360",
    "end": "4031930"
  },
  {
    "text": "like, how to properly\nmeasure and order models in terms of capacity.",
    "start": "4031930",
    "end": "4037090"
  },
  {
    "text": "It's not clear. Follow up on that, do\nyou know why the vision is four times smaller?",
    "start": "4037090",
    "end": "4043675"
  },
  {
    "text": "What about that task\nreally makes it-- I think it's just there\nis less interest in it,",
    "start": "4043675",
    "end": "4049720"
  },
  {
    "text": "and so less resources\nspent on it, basically. Like in Google, there are many,\nmany more groups doing research",
    "start": "4049720",
    "end": "4058059"
  },
  {
    "text": "with language than with vision. And I think we are one\nof the few groups that",
    "start": "4058060",
    "end": "4064000"
  },
  {
    "text": "have access to a\nlot of resources and are interested in scaling\nup things in vision so much. Whereas in language, it seems\nthere are a lot of groups",
    "start": "4064000",
    "end": "4071290"
  },
  {
    "text": "that are doing that, right? I think that's the\nmain reason, actually. It's not that we don't\nwant to go beyond it.",
    "start": "4071290",
    "end": "4079930"
  },
  {
    "text": "Like if we can, we\nwould go even more. Awesome. Thank you. ",
    "start": "4079930",
    "end": "4088180"
  },
  {
    "text": "So we are actually over\ntime at this point. So anyone who has to leave,\nplease feel free to do so.",
    "start": "4088180",
    "end": "4093970"
  },
  {
    "text": "Before we do that,\nLucas, thank you so much for joining all the\nway from across the ocean.",
    "start": "4093970",
    "end": "4101649"
  },
  {
    "text": "And we know it's in the\nevening, so thank you for taking your free time\nto come and talk to us here.",
    "start": "4101649",
    "end": "4107489"
  },
  {
    "text": "Yeah. Thanks for the invitation. I always like to\ntalk about the work. ",
    "start": "4107490",
    "end": "4116000"
  }
]
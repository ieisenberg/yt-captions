[
  {
    "start": "0",
    "end": "5330"
  },
  {
    "text": "Let's start our class\nwith a tiny bit of review. We're in this terribly\nexciting part of CS 109",
    "start": "5330",
    "end": "11120"
  },
  {
    "text": "where we are transferring\nfrom pure probability theory into the basics and core\nprinciples of machine learning.",
    "start": "11120",
    "end": "19369"
  },
  {
    "text": "And particularly, what\nthe rest of CS 109 is going to look\nlike is we're going to build up the foundations\nof classic machine learning",
    "start": "19370",
    "end": "26779"
  },
  {
    "text": "algorithms and\nthen talk about how those are the basis\nof this thing called deep learning, which you\nmight have learned about.",
    "start": "26780",
    "end": "32960"
  },
  {
    "text": "But really all the theory\ncomes from these three different mechanisms for\nestimating parameters.",
    "start": "32960",
    "end": "39740"
  },
  {
    "text": "In fact, there's one\nsingle task, perhaps, is the heart and soul of what\nyou call machine learning",
    "start": "39740",
    "end": "46649"
  },
  {
    "text": "and what is modern\nartificial intelligence. And it's such a\nstraightforward task it's amazing to think\nabout the impact it's had.",
    "start": "46650",
    "end": "53120"
  },
  {
    "text": "And the straightforward task\nis, you have some parameters and you need to figure\nout what they are.",
    "start": "53120",
    "end": "59380"
  },
  {
    "text": "To put that in other\nwords, in CS 109, we've often had either\nrandom variables",
    "start": "59380",
    "end": "65080"
  },
  {
    "text": "or probabilistic models, that's\njust more random variables being random together. And when we had those\nrandom variables,",
    "start": "65080",
    "end": "71890"
  },
  {
    "text": "a lot of times those\nrandom variables would be defined by numbers. And those numbers we're going\nto now be calling parameters.",
    "start": "71890",
    "end": "78820"
  },
  {
    "text": "Before this section of\nCS 109, we would always give you those numbers. We would tell you, you have a\nnormal, and here's the mean,",
    "start": "78820",
    "end": "86050"
  },
  {
    "text": "and here's its variance. But now, we're going to start\ncalling those things parameters",
    "start": "86050",
    "end": "91450"
  },
  {
    "text": "and talking about the\nproblem of estimating those parameters based on data.",
    "start": "91450",
    "end": "96910"
  },
  {
    "text": "And parameters could be from\nsingle random variables. But just to be clear,\nit gets really exciting when you get into\nprobabilistic models.",
    "start": "96910",
    "end": "103479"
  },
  {
    "text": "And probabilistic models\nstill have parameters. Those are these magical numbers\nthat showed up in our model.",
    "start": "103480",
    "end": "109420"
  },
  {
    "text": "And parameter\nestimation, the task of choosing those\nnumbers based off of data is the same problem whether\nit's one random variable",
    "start": "109420",
    "end": "116620"
  },
  {
    "text": "or multiple. And the reason we care so much. The reason it is\nsuch a big deal is",
    "start": "116620",
    "end": "122720"
  },
  {
    "text": "because most of\nartificial intelligence looks like a three step process. The first step is find\na real world problem",
    "start": "122720",
    "end": "129500"
  },
  {
    "text": "that you think is worth solving\nand then model the problem. And when you model the\nproblem, you might end up",
    "start": "129500",
    "end": "135560"
  },
  {
    "text": "with a Bayesian network\nor you may end up with a single random variable. But we always think about this\nmodel as having parameters",
    "start": "135560",
    "end": "141920"
  },
  {
    "text": "and we're going to call\nthose parameters theta. So the first step of\nsolving a real world problem",
    "start": "141920",
    "end": "146990"
  },
  {
    "text": "is to model it. And then the second step\nis almost always, OK, you've got a model and\nit's got some theta.",
    "start": "146990",
    "end": "153770"
  },
  {
    "text": "Based on some\nhistorical data, can I choose what those values\nof the parameters are? We call this training.",
    "start": "153770",
    "end": "160100"
  },
  {
    "text": "And you could have different\nalgorithms for estimating those parameters.",
    "start": "160100",
    "end": "165320"
  },
  {
    "text": "And the result will be\na model with numbers. You'll have a model\nwith numbers for each of those important parameters.",
    "start": "165320",
    "end": "172560"
  },
  {
    "text": "So if I could rephrase\nmachine learning, it's basically\nparameter estimation",
    "start": "172560",
    "end": "177860"
  },
  {
    "text": "for probabilistic models. There are several\nalgorithms we can use. One of the most\npopular ones is the one",
    "start": "177860",
    "end": "184620"
  },
  {
    "text": "that we learned on Monday. The one that we learnt on Monday\nstarted with a really nice,",
    "start": "184620",
    "end": "190330"
  },
  {
    "text": "simple intuition. If I give you\ndata-- for example, I give you all this\ndata points, I tell you",
    "start": "190330",
    "end": "196590"
  },
  {
    "text": "that my model for where\nthese data points come from is a Gaussian, and your job\nis to choose parameters.",
    "start": "196590",
    "end": "202980"
  },
  {
    "text": "The idea is for different\nsettings of parameters, those data points will\nlook more or less likely.",
    "start": "202980",
    "end": "209680"
  },
  {
    "text": "And the simple idea of the\nalgorithm we talked about on Monday is what\nif we just chose the parameters that\nmake the data look",
    "start": "209680",
    "end": "216720"
  },
  {
    "text": "as likely as possible. This has a name. It's called maximum\nlikelihood estimation.",
    "start": "216720",
    "end": "223020"
  },
  {
    "text": "And the sorts of problems\nthat you'll have to solve will often look like this. I'll be like, here's a data set.",
    "start": "223020",
    "end": "229200"
  },
  {
    "text": "I assume that each\nof these numbers is coming from a\nparticular model. That model has a parameter.",
    "start": "229200",
    "end": "235120"
  },
  {
    "text": "And in this case, it's alpha. And could you estimate alpha. The answer for MLE will\nbe a little equation",
    "start": "235120",
    "end": "242190"
  },
  {
    "text": "that you could use. You could say, take each of\nthese data points which we call x sub i's. Sum up the log of them.",
    "start": "242190",
    "end": "248230"
  },
  {
    "text": "n divided by that number,\nthat's going to be my estimate for the parameter. But how do we get there?",
    "start": "248230",
    "end": "253370"
  },
  {
    "text": "Well, we use the MLE intuition. And the MLE intuition\nstarts with, let's write down how\nlikely are all my data",
    "start": "253370",
    "end": "260919"
  },
  {
    "text": "points based on a given\nstate of the parameter. So if the parameter\nwas a different alpha,",
    "start": "260920",
    "end": "266530"
  },
  {
    "text": "you would get a different\nvalue for how likely all the data points look. And because we assume the\ndata points are I.I.D.,",
    "start": "266530",
    "end": "272770"
  },
  {
    "text": "this likelihood is\na big old product. Now we would like to just\nchoose the alpha that",
    "start": "272770",
    "end": "278500"
  },
  {
    "text": "makes this as large as possible,\nbut we had this cool intuition that the alpha that\nmakes this large is same as the alpha that makes\nthe log of this expression",
    "start": "278500",
    "end": "286810"
  },
  {
    "text": "large. And it turns out the\nlog of this expression, which could be written like\nthis or rewritten like this,",
    "start": "286810",
    "end": "292870"
  },
  {
    "text": "is much easier to work with. Choosing the alpha\nthat maximizes this log of the\nexpression is way easier",
    "start": "292870",
    "end": "300220"
  },
  {
    "text": "than choosing the alpha that\nmaximizes this original thing. And so almost\nalways, we're going to be choosing an alpha that\nmaximizes the log likelihood.",
    "start": "300220",
    "end": "308020"
  },
  {
    "text": "Because logs are\nmonotonic, whichever alpha makes this the largest\nwill be the same alpha",
    "start": "308020",
    "end": "313570"
  },
  {
    "text": "that makes this larger. Yay, thank you logs. So now all you have\nto do is choose",
    "start": "313570",
    "end": "318810"
  },
  {
    "text": "whichever alpha makes this\nequation as big as possible. There's a few different\nways of doing it.",
    "start": "318810",
    "end": "325380"
  },
  {
    "text": "But all the different\nmethods that I know about for choosing an alpha\nto make this equation as large as possible\nare going to require",
    "start": "325380",
    "end": "332490"
  },
  {
    "text": "you to take the derivative\nof this equation with respect to alpha. This derivative will\nbe the key to choosing",
    "start": "332490",
    "end": "339060"
  },
  {
    "text": "the biggest alpha possible. Can I pause here for a\nsecond because maybe people had questions? That was a lot of content\nthat we covered on Monday.",
    "start": "339060",
    "end": "346770"
  },
  {
    "text": "Questions, thoughts, concerns? Yes? What's the difference between\nlikelihood and probability?",
    "start": "346770",
    "end": "353310"
  },
  {
    "text": "Likelihood and probability\nsound very synonymous. But likelihood is\na particular term,",
    "start": "353310",
    "end": "359890"
  },
  {
    "text": "which is the probability\nof the data I saw. So in this case, this\nis the probability",
    "start": "359890",
    "end": "366520"
  },
  {
    "text": "of my whole data set. And so likelihood\nis a probability. If you use likelihood\nsynonymously",
    "start": "366520",
    "end": "372340"
  },
  {
    "text": "with probability in all CS\n109, no one would blink an eye. But if you want to\nbe really, really, really pedantic, which\nI don't want to be,",
    "start": "372340",
    "end": "378490"
  },
  {
    "text": "technically, it is the\nprobability of a data set. Does that answer the question?",
    "start": "378490",
    "end": "383675"
  },
  {
    "text": "[INAUDIBLE] to find the\nlikelihood of a single event we use the [INAUDIBLE]?",
    "start": "383675",
    "end": "389120"
  },
  {
    "text": "Yeah. So the likelihood of\nthe entire data set is going to be the\nproduct because they're independent of the likelihood\nof each data point.",
    "start": "389120",
    "end": "396710"
  },
  {
    "text": "Each data point x sub i, i,\nthat's my notation for one data point, is likelihood, is\njust the probability density function.",
    "start": "396710",
    "end": "402080"
  },
  {
    "text": "If it was discrete, you'd use\nthe probability mass function. If it was a model, you would\nput the joint probability here.",
    "start": "402080",
    "end": "407780"
  },
  {
    "text": "Good questions. Very good questions. OK, we're getting\nour MLE review done.",
    "start": "407780",
    "end": "415250"
  },
  {
    "text": "Rocking and rolling. So what's the story so far? We have this\nbeautiful philosophy for choosing parameters now.",
    "start": "415250",
    "end": "421590"
  },
  {
    "text": "It uses this cool bit of math. And the hardest thing\nwill be choosing an alpha to make this as\nlarge as possible.",
    "start": "421590",
    "end": "427780"
  },
  {
    "text": "We know that we'll\nneed a derivative. But so far in this\nreview, I haven't really talked about how to\nuse the derivative.",
    "start": "427780",
    "end": "433620"
  },
  {
    "text": "I want to start\nby just mentioning this hidden, mysterious\nproblem we have to solve,",
    "start": "433620",
    "end": "439840"
  },
  {
    "text": "which is, if you want\nto choose an alpha that makes this as large as\npossible, that's not the easiest thing to do.",
    "start": "439840",
    "end": "446120"
  },
  {
    "text": "One thing we know how to do\nis we can take the derivative and in Monday's class,\nwe used a particular hack",
    "start": "446120",
    "end": "453610"
  },
  {
    "text": "to find the argmax. And that particular\nhack was we know",
    "start": "453610",
    "end": "459100"
  },
  {
    "text": "that the maximum\nwill be at a place where the derivative\nis equal to 0. And for some equations, it\nturns out if you just put in 0,",
    "start": "459100",
    "end": "467200"
  },
  {
    "text": "you can solve for alpha. And then you get\nthe right answer. It's not a very general method.",
    "start": "467200",
    "end": "473380"
  },
  {
    "text": "Not many times in my\nlife as a mathematician do I use this method. Because it doesn't really apply\nnicely when you have models.",
    "start": "473380",
    "end": "482740"
  },
  {
    "text": "It's not always\nguaranteed to work because the derivative of\n0 could also be a minimum. There could be several maxima.",
    "start": "482740",
    "end": "489700"
  },
  {
    "text": "There's lots of reasons\nthat what we used on Monday is a bit of a hack. So story so far,\nmachine learning",
    "start": "489700",
    "end": "496270"
  },
  {
    "text": "is all based on\nparameter estimation. One of the great theories\nfor parameter estimation is maximum likelihood\nestimation.",
    "start": "496270",
    "end": "502330"
  },
  {
    "text": "We can get this log\nlikelihood function and we want to choose\nthe parameters that make that as large as possible,\nthat's going to require",
    "start": "502330",
    "end": "508810"
  },
  {
    "text": "us to do some optimization. We have a pretty crummy method\nfor optimization right now.",
    "start": "508810",
    "end": "515380"
  },
  {
    "text": "So that's the end of our review. And where I'd really like to\ncontinue this conversation is, can I just give you a better\nmethod for optimization?",
    "start": "515380",
    "end": "522760"
  },
  {
    "text": "Now certainly, you can take\nentire class at Stanford where you learn\nabout optimization. All these different ways\nfor solving argmaxes.",
    "start": "522760",
    "end": "531790"
  },
  {
    "text": "But if there's one algorithm\nthat every single person in Stanford CS should know it\nis this method for optimization.",
    "start": "531790",
    "end": "539470"
  },
  {
    "text": "It's not Lion King. Not everyone has to\nwatch Lion King though. Fine movie. What you need to know is this\nother method for optimization,",
    "start": "539470",
    "end": "547270"
  },
  {
    "text": "a.k.a., another method\nfor doing argmax, and that's called gradient\ndescent or gradient ascent.",
    "start": "547270",
    "end": "554290"
  },
  {
    "text": "It goes like this. Let's say you're trying\nto choose the theta which",
    "start": "554290",
    "end": "561260"
  },
  {
    "text": "is the argmax of some function. And let's say,\nparticularly, this is the function you're\ntrying to find the argmax of.",
    "start": "561260",
    "end": "569240"
  },
  {
    "text": "Just as a bit of review, before\nI jump into the algorithm, is this the argmax?",
    "start": "569240",
    "end": "576010"
  },
  {
    "text": "Just yell it. Come on. Is this the argmax? No. Is this it? No. Is this it? No. Is this it?",
    "start": "576010",
    "end": "581770"
  },
  {
    "text": "No. Is this it? No. Is that it? Yeah. Yeah. OK. [CHUCKLES] Hey, how\neasy would argmax",
    "start": "581770",
    "end": "589780"
  },
  {
    "text": "be if somebody just\ngave you a visualization of the entire\nlikelihood function.",
    "start": "589780",
    "end": "595240"
  },
  {
    "text": "If somebody visualized\nas you change theta all the different\nvalues of likelihood,",
    "start": "595240",
    "end": "600279"
  },
  {
    "text": "choosing argmax\nwould be so simple. You would just look at the\ncurve and you'd be done.",
    "start": "600280",
    "end": "605500"
  },
  {
    "text": "But that's really, really,\nreally computationally expensive. You have to try-- you have to calculate likelihood\nfor every possible input",
    "start": "605500",
    "end": "612639"
  },
  {
    "text": "of theta. Too much work. People don't do that. If you have more than one theta,\nbecomes exponentially bad.",
    "start": "612640",
    "end": "619430"
  },
  {
    "text": "So if you can't see\nthis blue curve, is there another way of getting\nthe theta that takes you",
    "start": "619430",
    "end": "625750"
  },
  {
    "text": "to the top of the mountain? And I still give you the fact\nthat you know the derivative.",
    "start": "625750",
    "end": "632410"
  },
  {
    "text": "For any alpha, you can\ncalculate the likelihood and you can calculate the\nderivative of the likelihood.",
    "start": "632410",
    "end": "639139"
  },
  {
    "text": "It would be too much\neffort to calculate the likelihood for every alpha. That will take too much work. But can we use a\nmore clever algorithm",
    "start": "639140",
    "end": "647090"
  },
  {
    "text": "to get to the top\nof the mountain? And a lot of you guys might\nhave seen this before. So let me just remind\nthose who have seen it",
    "start": "647090",
    "end": "653660"
  },
  {
    "text": "and teach those who\nhave not seen it before. The very simple idea is imagine\nyou start with any theta.",
    "start": "653660",
    "end": "660740"
  },
  {
    "text": "You choose an initial value. Maybe you choose 0. Maybe you choose 50. It doesn't really matter\nwhich one you choose.",
    "start": "660740",
    "end": "666500"
  },
  {
    "text": "Because that will not be your\nfinal guess for the argmax. You can only see what's in red.",
    "start": "666500",
    "end": "672665"
  },
  {
    "text": "So you choose a theta. You look at the\nlikelihood of your theta. And you can know the\nderivative at that point.",
    "start": "672665",
    "end": "679430"
  },
  {
    "text": "You can't see the\nwhole blue curve. But let's say if you\nlook at the derivative, you know that the\nderivative is like this.",
    "start": "679430",
    "end": "685400"
  },
  {
    "text": "That means if you\nincrease theta, you think likelihood\nwill go up because it's a positive derivative.",
    "start": "685400",
    "end": "691320"
  },
  {
    "text": "So if the derivative\nis positive, do you think we should\ntake theta to the right or to the left?",
    "start": "691320",
    "end": "698111"
  },
  {
    "text": "Right. Is that from your perspective? Larger value of theta. [CHUCKLES] If we increase\nthe value of theta",
    "start": "698111",
    "end": "705050"
  },
  {
    "text": "because the slope is positive,\nthe slope is telling us that uphill is this way. Increased theta should lead\nto increased likelihood.",
    "start": "705050",
    "end": "712110"
  },
  {
    "text": "So even though we can't\nsee the blue line, we know that going this way\nshould make likelihood go up. So the very simple algorithm\nis start anywhere, figure out",
    "start": "712110",
    "end": "720080"
  },
  {
    "text": "which direction is uphill, and\ntake a step in that direction. So maybe we take one\nstep in this direction. Now we can see\nwhat's in the red.",
    "start": "720080",
    "end": "726889"
  },
  {
    "text": "We're here. We can know that we've improved. And we can also\nknow the derivative.",
    "start": "726890",
    "end": "732870"
  },
  {
    "text": "The derivative is not as\nsteep but it's still positive. It's still telling us that\nuphill is that direction.",
    "start": "732870",
    "end": "738600"
  },
  {
    "text": "So imagine you're a climber and\nyou're somewhere on a mountain. You can't see the\nwhole mountain. What a weird mountain\nto be climbing. Maybe it's very foggy.",
    "start": "738600",
    "end": "744080"
  },
  {
    "text": "But you do know that\nuphill is this direction. And if you want to get\nto the top of that hill, you go in that direction.",
    "start": "744080",
    "end": "750060"
  },
  {
    "text": "So very simply, if uphill\nis in this direction. Let's go that way. Boom, boom, boom, boom, boom. And if we repeat\nthis process enough,",
    "start": "750060",
    "end": "757340"
  },
  {
    "text": "eventually, we'll\nget to the top. And at this point, you\nare still the red dot but you are that final red dot.",
    "start": "757340",
    "end": "764009"
  },
  {
    "text": "You can't tell that you're\nat the top of the mountain. But what you can do is you\ncan look at your gradient",
    "start": "764010",
    "end": "770970"
  },
  {
    "text": "and you can figure out\nthat my gradient is 0. So my slope is 0. That means no direction is\ngoing to take me up any more.",
    "start": "770970",
    "end": "779690"
  },
  {
    "text": "And therefore, I think I've made\nit to the top of a mountain. How simple is that algorithm?",
    "start": "779690",
    "end": "784910"
  },
  {
    "text": "Some people call\nit hill climbing, some people call\nthis gradient ascent. Now of course, we don't\ncare about the likelihood.",
    "start": "784910",
    "end": "790340"
  },
  {
    "text": "We cared about the theta\nthat gave that likelihood. And so we would just\nrun this algorithm and return back theta.",
    "start": "790340",
    "end": "795920"
  },
  {
    "text": "This is the number one most\nimportant algorithm that you need to know in optimization. There's people who do slightly\nfancier versions of this.",
    "start": "795920",
    "end": "804200"
  },
  {
    "text": "Adaptive gradients is a thing. People have improved upon this. But this is the core\ninsight that people",
    "start": "804200",
    "end": "810533"
  },
  {
    "text": "use when they're doing something\nlike training a neural network. They're going to try and\nchoose parameters that argmax",
    "start": "810533",
    "end": "815580"
  },
  {
    "text": "something. And they use hill climbing. Questions, ideas? Yeah? What's the size of the step?",
    "start": "815580",
    "end": "822530"
  },
  {
    "text": "You have to set a constant. How annoying is that? It's like, what happens\nif you overshoot?",
    "start": "822530",
    "end": "828410"
  },
  {
    "text": "Oh, my god. That would be a disaster. [CHUCKLES] OK, the question is, what's\nthe size of the step?",
    "start": "828410",
    "end": "835445"
  },
  {
    "text": "And I'm telling\nyou that you have to choose that number before\nyou run the algorithm. So let's run the algorithm.",
    "start": "835445",
    "end": "841140"
  },
  {
    "text": "I've got an imagined\ncurve and let's say you choose a really big step size. So you start here.",
    "start": "841140",
    "end": "846720"
  },
  {
    "text": "Gradient's this way. So you take a huge step\nand you step over here.",
    "start": "846720",
    "end": "854150"
  },
  {
    "text": "And now, you take the gradient\nhere and it's negative. And you take a huge step\nand you end up over here.",
    "start": "854150",
    "end": "861339"
  },
  {
    "text": "And you end up with\na positive gradient. Ideally, you'll start\nnarrowing in on the top.",
    "start": "861340",
    "end": "866949"
  },
  {
    "text": "There is a possibility\nthough, that if you keep taking huge steps, it's\nlike you keep leaping over",
    "start": "866950",
    "end": "872290"
  },
  {
    "text": "the top of the mountain and\nyou never converge to the top. So small step size guarantee\nyou converge but it'll",
    "start": "872290",
    "end": "877990"
  },
  {
    "text": "take longer to get there. But eventually, this turned into\na sort of binary search then? You can think of it as having\nsome binary search capacities,",
    "start": "877990",
    "end": "885800"
  },
  {
    "text": "yes. But step size does matter. So your original\nquestion was really good. If your step size\nis too big-- you're going to have to\nchoose a number, which",
    "start": "885800",
    "end": "892133"
  },
  {
    "text": "I'll talk about in a second. And that's an important choice. Yes? Is this similar to what\nwe did in the last lecture",
    "start": "892133",
    "end": "898660"
  },
  {
    "text": "where you were just\nputting in numbers and seeing if it was\ngoing up and coming down?",
    "start": "898660",
    "end": "903940"
  },
  {
    "text": "I mean, yeah, a little bit. So the question is, is\nthis similar to what I did at the beginning\nof last lecture.",
    "start": "903940",
    "end": "909320"
  },
  {
    "text": "So just to remind people, at\nthe beginning of last lecture, I did this thing. Where I was trying in\ndifferent parameters",
    "start": "909320",
    "end": "914650"
  },
  {
    "text": "and I was seeing\nwhat was the largest. It's a little bit smarter. When I was doing this, I\nwasn't looking at gradients.",
    "start": "914650",
    "end": "922570"
  },
  {
    "text": "I was just looking\nat likelihoods. And this time, I'm also going\nto be looking at gradients and that's going to\nguide the computer.",
    "start": "922570",
    "end": "929170"
  },
  {
    "text": "And actually, that's what's\ngoing to allow the computer to really do this, both\nautomatically and a lot",
    "start": "929170",
    "end": "934180"
  },
  {
    "text": "more efficiently. So does that make sense? What a cool question. Yes, another question.",
    "start": "934180",
    "end": "940029"
  },
  {
    "text": "Do we assume that the graph\nthat we look at always looks like that in terms\nof having one single hump.",
    "start": "940030",
    "end": "945790"
  },
  {
    "text": "But could it have two\nhumps or two peaks at some point [INAUDIBLE]? OK, so imagine the mysterious,\nfoggy log likelihood function.",
    "start": "945790",
    "end": "955840"
  },
  {
    "text": "Remember, we're trying to use\nlog likelihood of our theta. We want the theta\nthat maximizes it. Which one of these\nis the argmax?",
    "start": "955840",
    "end": "962920"
  },
  {
    "text": "This one? No. This one? Yeah! But what if you did hill\nclimb and you started here?",
    "start": "962920",
    "end": "970060"
  },
  {
    "text": "You would go uphill, uphill,\nuphill, uphill, uphill. And then you'd get\nhere and be like, I'm at the top of the\nmountain, woo-hoo!",
    "start": "970060",
    "end": "976420"
  },
  {
    "text": "And you would return not\nthe best parameters ever, which is a little bit sad.",
    "start": "976420",
    "end": "982160"
  },
  {
    "text": "Not really the end of the\nworld, but a little bit sad. OK, if you were\nfeeling super hacky,",
    "start": "982160",
    "end": "987620"
  },
  {
    "text": "how would you solve this? ",
    "start": "987620",
    "end": "992740"
  },
  {
    "text": "Oh. You have been taking,\nlike, [INAUDIBLE] classes. [LAUGHTER] What's your idea?",
    "start": "992740",
    "end": "998899"
  },
  {
    "text": "Do it again. Yeah, do it again. This is the really hacky\nthing that people actually do, is they'll choose random\nstarting positions and be like,",
    "start": "998900",
    "end": "1006015"
  },
  {
    "text": "oh, I started here and\nI got to the top here. I started here and I ended\nup at this spot again. But then one time I start\nhere and I end up over here.",
    "start": "1006015",
    "end": "1012677"
  },
  {
    "text": "And another time I start\nhere, I end up over here. And I ran it four times\nand out of those, this",
    "start": "1012677",
    "end": "1017912"
  },
  {
    "text": "was the top of the\nmountain that I found. Super hacky, but\npeople actually do it. People are crazy.",
    "start": "1017912",
    "end": "1025032"
  },
  {
    "text": "And then they present themselves\nlike very elegant machine learning theorists. [LAUGHTER]",
    "start": "1025033",
    "end": "1031240"
  },
  {
    "text": " Now, I do want to note that not\nevery probabilistic model only",
    "start": "1031240",
    "end": "1038130"
  },
  {
    "text": "has one parameter. A Gaussian, for example,\nhas two parameters. If you had a whole\nBayesian network, you could have\nhundreds of parameters.",
    "start": "1038130",
    "end": "1045584"
  },
  {
    "text": "This method works even if you\nhave more than one parameter. So if you have more\nthan one parameter, your log likelihood\nfunction becomes",
    "start": "1045585",
    "end": "1052800"
  },
  {
    "text": "a three-dimensional\ngraph, where high values on this third dimension\nmeans high log likelihoods.",
    "start": "1052800",
    "end": "1059940"
  },
  {
    "text": "And we'd still like\nto get to the top. The parameters that have\nthe highest log likely. And it will be a combination\nof parameters that",
    "start": "1059940",
    "end": "1065880"
  },
  {
    "text": "lead to high log likelihoods. And you can have\ndifferent starting points and you can still\nuse hill climbing.",
    "start": "1065880",
    "end": "1071940"
  },
  {
    "text": "And hill climbing, you just\nneed a derivative with respect to each parameter. And if you have a derivative\nwith respect to each parameter,",
    "start": "1071940",
    "end": "1078210"
  },
  {
    "text": "you can know which\nway is uphill. And it works with more\nthan two parameters. Does it work with more than two?",
    "start": "1078210",
    "end": "1084029"
  },
  {
    "text": "Oh, yeah, it works with\nthree, four, and five. But our puny, little\nhuman visual system can only visualize\ntwo parameters",
    "start": "1084030",
    "end": "1091110"
  },
  {
    "text": "optimizing at the same time. But the same algorithm works if\nyou have hundreds of parameters",
    "start": "1091110",
    "end": "1096490"
  },
  {
    "text": "and you're trying to jointly\noptimize all of them. What's confusing about this?",
    "start": "1096490",
    "end": "1102620"
  },
  {
    "text": "Questions? [VOCALIZING] OK. So this whole algorithm works.",
    "start": "1102620",
    "end": "1108850"
  },
  {
    "text": "The only thing you need to do\nto be able to use this is you need to know the derivative of\nthe thing you want to optimize",
    "start": "1108850",
    "end": "1113980"
  },
  {
    "text": "with respect to each parameter. That's the thing\nthat you must do. That's your work. And if you do that work, then\nyou can just use optimization.",
    "start": "1113980",
    "end": "1120850"
  },
  {
    "text": "I have really good news. Almost every single optimization\nthat you do in CS 109",
    "start": "1120850",
    "end": "1126940"
  },
  {
    "text": "will be functions that have a\nvery beautiful property, which is called that they're convex.",
    "start": "1126940",
    "end": "1131950"
  },
  {
    "text": "And convex has\nthis nice property that if you find an optima,\nit will be the global optima",
    "start": "1131950",
    "end": "1137170"
  },
  {
    "text": "so we don't have to do any of\nthese really complicated hacks. If you're curious to\ngo deeper about convex,",
    "start": "1137170",
    "end": "1142990"
  },
  {
    "text": "let's talk about that offline. Now if I had to give you\nthat algorithm written",
    "start": "1142990",
    "end": "1149450"
  },
  {
    "text": "in mathematical notation,\nhere's what it would look like. When you're choosing a\nnew, you will continually",
    "start": "1149450",
    "end": "1155750"
  },
  {
    "text": "update your guess for\nthe best parameter. When you're choosing\nyour next guess,",
    "start": "1155750",
    "end": "1161180"
  },
  {
    "text": "you're going to\ntake your old guess and then you're\ngoing to figure out the derivative of likelihood\nat your current point,",
    "start": "1161180",
    "end": "1168860"
  },
  {
    "text": "multiply that derivative\nby some constant, and then add that to your guess. So if your derivative\nis positive,",
    "start": "1168860",
    "end": "1175070"
  },
  {
    "text": "constant is always positive. If your derivative is\npositive, then theta will increase in value. If your derivative is\nnegative, then your theta",
    "start": "1175070",
    "end": "1181790"
  },
  {
    "text": "will decrease in value. And we will repeat\nthis many, many times. And isn't this such\nprofound life philosophy?",
    "start": "1181790",
    "end": "1188179"
  },
  {
    "text": "We do not need to just jump\nto the top of a mountain. If every day, you wake up and\nfigure out which way is uphill",
    "start": "1188180",
    "end": "1195020"
  },
  {
    "text": "and take a small step uphill,\nyou will eventually make it to the top of your mountain.",
    "start": "1195020",
    "end": "1200700"
  },
  {
    "text": "Isn't that such a\nnice way to live? OK, other nice things,\ngradient ascent.",
    "start": "1200700",
    "end": "1206760"
  },
  {
    "text": "Now, if I give you the\nexact same thing in code, you could have many parameters,\ngive them all an initial random",
    "start": "1206760",
    "end": "1214980"
  },
  {
    "text": "starting points. And then many times,\ncalculate the gradient and then run that\nupdated equation.",
    "start": "1214980",
    "end": "1220020"
  },
  {
    "text": "Where each parameter,\nyou add to it a constant step size times the\ngradient for that parameter.",
    "start": "1220020",
    "end": "1226170"
  },
  {
    "text": "The gradient of log\nlikelihood for that parameter. That means that you will\nhave to do some work.",
    "start": "1226170",
    "end": "1231315"
  },
  {
    "text": "Every step, you'll have\nto calculate a gradient. And if we go back\nto that example",
    "start": "1231315",
    "end": "1237510"
  },
  {
    "text": "from last class of\nfitting the Pareto, this was the gradient\nwe calculated. We had a log\nlikelihood function.",
    "start": "1237510",
    "end": "1244020"
  },
  {
    "text": "It was based on a\nparameter alpha. And we figured\nout the derivative of the log likelihood\nwith respect to alpha was this thing.",
    "start": "1244020",
    "end": "1249720"
  },
  {
    "text": "If you want to actually\nimplement that, you would have to turn this\nmath equation into code.",
    "start": "1249720",
    "end": "1256380"
  },
  {
    "text": "And if you could turn this\nmath equation into code, then this would give you\nthe best choice of alpha.",
    "start": "1256380",
    "end": "1261400"
  },
  {
    "text": "Start alpha at\nsome random start. Then many times, calculate\nthe gradient of alpha",
    "start": "1261400",
    "end": "1267340"
  },
  {
    "text": "based on the data. And then change alpha\nbased off of the gradient you just calculated.",
    "start": "1267340",
    "end": "1274600"
  },
  {
    "text": "Now, of course,\nyou can't just type [INAUDIBLE] into a computer. But it wouldn't be too hard\nto turn this into Python.",
    "start": "1274600",
    "end": "1280570"
  },
  {
    "text": "And just to show you what\nthat would look like, it would look like this. Many times when you're\ncalculating the gradient,",
    "start": "1280570",
    "end": "1286610"
  },
  {
    "text": "started out as\nthis value and then you're going to have\nto calculate this term. So started out as\nn divided by alpha.",
    "start": "1286610",
    "end": "1292630"
  },
  {
    "text": "And then for every x_i in\nyour data, you get its log and you subtract it off of that.",
    "start": "1292630",
    "end": "1297970"
  },
  {
    "text": "When you're done with\nthis whole expression, you'll have the\ngradient for alpha based on the current alpha\nyou had and your data points.",
    "start": "1297970",
    "end": "1306200"
  },
  {
    "text": "And then you update. Questions, comments, concerns? Wow, optimization,\nchanges the world.",
    "start": "1306200",
    "end": "1311669"
  },
  {
    "text": "Yes? Will we ever be expected\nto find the global maximum or if there's more\nthan one, [INAUDIBLE]??",
    "start": "1311670",
    "end": "1317809"
  },
  {
    "text": "Yeah, in CS 109, if you\nfind the local maxima, it will be the global maxima. But I do want to be\ncomplete in my exposition",
    "start": "1317810",
    "end": "1324980"
  },
  {
    "text": "because someday\nin the world, you may end up in a local maxima. But you know what?",
    "start": "1324980",
    "end": "1330350"
  },
  {
    "text": "Is perfection always\nthe goal we want. [CHUCKLING] Maybe not. Other life philosophy, we\ncan talk about that offline.",
    "start": "1330350",
    "end": "1336540"
  },
  {
    "text": "OK. But I do want to leave\nthis up for a second because this is what it looks\nlike to put it into code. And a lot of times, when\nwe implement our machine",
    "start": "1336540",
    "end": "1342980"
  },
  {
    "text": "learning algorithms\nlater in CS 109, you'll write code that\nlooks a lot like this. I want to do argmax\non my parameters",
    "start": "1342980",
    "end": "1349620"
  },
  {
    "text": "so I'll use gradient ascent. OK. Has anyone-- oh, yeah, question.",
    "start": "1349620",
    "end": "1355690"
  },
  {
    "text": "For gradient alpha, why-- can we just divide n by alpha?",
    "start": "1355690",
    "end": "1361870"
  },
  {
    "text": "Because that was my-- this was this term. So n will be a positive number.",
    "start": "1361870",
    "end": "1367840"
  },
  {
    "text": "Hopefully, alpha\ndidn't start out as 0. And an interesting thing,\nalpha will change every time",
    "start": "1367840",
    "end": "1373360"
  },
  {
    "text": "through this equation. And when I use alpha, it will\nbe just my current estimate of alpha. OK. But basically, this\nexpression is the derivative?",
    "start": "1373360",
    "end": "1381290"
  },
  {
    "text": "Yeah, this expression is\ncalculating the derivative and then storing\nit into a variable. Crazy, a derivative can\nbe stored as a variable?",
    "start": "1381290",
    "end": "1388840"
  },
  {
    "text": "Yeah, it will be just a number. At the end of the day, the\nderivative will be a value. That whole crazy\nexpression becomes whatever",
    "start": "1388840",
    "end": "1397120"
  },
  {
    "text": "gets stored in that bucket. Wow, exciting. Has anyone ever\nheard of an algorithm",
    "start": "1397120",
    "end": "1403930"
  },
  {
    "text": "called gradient descent? It turns out every\nPython package, every computational\npackage you ever",
    "start": "1403930",
    "end": "1410710"
  },
  {
    "text": "use doesn't give\nyou gradient ascent. But I just told you it's the\nmost important thing ever. It's because everybody\nuses gradient descent.",
    "start": "1410710",
    "end": "1419150"
  },
  {
    "text": "Every package gives\nyou an algorithm not to find the highest point,\nbut to find the lowest point.",
    "start": "1419150",
    "end": "1425900"
  },
  {
    "text": "It's because you want to\nminimize regret or minimize loss. If we want to use a\ngradient descent algorithm,",
    "start": "1425900",
    "end": "1432140"
  },
  {
    "text": "so a gradient descent\nalgorithm you start somewhere and it will give you\nthe lowest point.",
    "start": "1432140",
    "end": "1437270"
  },
  {
    "text": "I want to maximize likelihood. I don't want to\nminimize anything. Hackers, unite.",
    "start": "1437270",
    "end": "1443145"
  },
  {
    "text": "[CHUCKLES] If you found a gradient\ndescent algorithm,",
    "start": "1443145",
    "end": "1452080"
  },
  {
    "text": "how could you use\ngradient descent to choose a parameter that\nmaximizes the log likelihood?",
    "start": "1452080",
    "end": "1459315"
  },
  {
    "text": "Oh, it's on the slides\nfor those of you who are fantastic at reading. Yes? [CHUCKLES] You just multiply\nit by negative 1.",
    "start": "1459315",
    "end": "1465230"
  },
  {
    "text": "Yes, exactly. Just this is an aside. In CS 109, you can always\nimplement gradient ascent.",
    "start": "1465230",
    "end": "1471110"
  },
  {
    "text": "But if you ever find a package\nthat does gradient descent, you'll notice that\nthey will be minimizing",
    "start": "1471110",
    "end": "1476510"
  },
  {
    "text": "not the log likelihood, but\nthe negative log likelihood.",
    "start": "1476510",
    "end": "1481860"
  },
  {
    "text": "So normally, we want to maximize\nthe positive log likelihood. And if somebody gives me\ngradient descent, an algorithm",
    "start": "1481860",
    "end": "1488000"
  },
  {
    "text": "for gradient descent, it'll\njust minimize the negative log likelihood. Again, that's not so\nimportant because in CS 109,",
    "start": "1488000",
    "end": "1493940"
  },
  {
    "text": "you'll always be writing\nyour algorithms from scratch. But if you ever find a library\nthat just does it for you,",
    "start": "1493940",
    "end": "1499019"
  },
  {
    "text": "you just need to\nknow that descent will be a negative, fantastic.",
    "start": "1499020",
    "end": "1504289"
  },
  {
    "text": "OK, I want to take a moment. This is early for a pedagogical\npause but this is critical. We just talked about some of\nthe most important things.",
    "start": "1504290",
    "end": "1511440"
  },
  {
    "text": "And if you can solidify\nthis knowledge, then the rest of the lecture\nwill be a lot easier to follow. So I want you guys\nto take a minute.",
    "start": "1511440",
    "end": "1517425"
  },
  {
    "text": "I want you to think\nabout what we've learned. I want you to see if you can\nthink about some questions that you care about. Feel free to talk about this\nwith the person next to you",
    "start": "1517425",
    "end": "1524223"
  },
  {
    "text": "before we jump into another way\nof doing parameter estimation. So what do we talk about and\nwhat's confusing, go for it?",
    "start": "1524223",
    "end": "1530153"
  },
  {
    "text": "Take a minute and a half. ",
    "start": "1530153",
    "end": "1538740"
  },
  {
    "text": "[SIDE CONVERSATIONS] ",
    "start": "1538740",
    "end": "1564766"
  },
  {
    "text": "Yeah. It sounds like\nparameters [INAUDIBLE].. ",
    "start": "1564766",
    "end": "1609960"
  },
  {
    "text": "It's got to be on the top.  I want to be writing\nstuff that is--",
    "start": "1609960",
    "end": "1615944"
  },
  {
    "text": " But I think the thing closed.",
    "start": "1615944",
    "end": "1621670"
  },
  {
    "text": " We'll talk about it after class.",
    "start": "1621670",
    "end": "1627400"
  },
  {
    "start": "1627400",
    "end": "1643710"
  },
  {
    "text": "Yes. ",
    "start": "1643710",
    "end": "1649838"
  },
  {
    "text": "I am so sorry. [INAUDIBLE] I thought we could\nestimate [INAUDIBLE].. ",
    "start": "1649838",
    "end": "1667832"
  },
  {
    "text": "I guess it's kind of a donut.  Oh, yeah.",
    "start": "1667832",
    "end": "1675460"
  },
  {
    "text": "OK, let's bring\nit back together. I started writing\nthe plot here just because I want to make\nsure no one loses the plot.",
    "start": "1675460",
    "end": "1682540"
  },
  {
    "text": "Why are we doing this? All of machine learning is based\noff of parameter estimation.",
    "start": "1682540",
    "end": "1687980"
  },
  {
    "text": "So far, we have one great idea\nfor parameter estimation, which is that we can have a log\nlikelihood function, which",
    "start": "1687980",
    "end": "1695379"
  },
  {
    "text": "for any state of the\nparameters we can say how likely the data looks. And then we want to\nchoose the parameters that",
    "start": "1695380",
    "end": "1700929"
  },
  {
    "text": "make this log likelihood\nas large as possible. And so we can choose\nthat parameter that maximizes log likelihood\nusing gradient ascent.",
    "start": "1700930",
    "end": "1708730"
  },
  {
    "text": "That's the plot so far. But questions probably came up. There's probably some parts of\nthis plot that are confusing.",
    "start": "1708730",
    "end": "1714130"
  },
  {
    "text": "And if it's confusing\nto you, it's confusing to a lot of people. I love the questions\nin this class. Yes?",
    "start": "1714130",
    "end": "1719289"
  },
  {
    "text": "What's the benefit of\nusing a gradient ascent over the first\nmethod we discussed, just doing the first\nderivative test, basically?",
    "start": "1719290",
    "end": "1724920"
  },
  {
    "text": "So it's a good question. Why would you use\ngradient ascent",
    "start": "1724920",
    "end": "1730250"
  },
  {
    "text": "instead of the first method? And the first method was\nyou take your derivative, set equal to 0, and\nthen just solve.",
    "start": "1730250",
    "end": "1736919"
  },
  {
    "text": "It's just that the\nfirst method doesn't work for general problems. For example, this method\nwe just talked about,",
    "start": "1736920",
    "end": "1744050"
  },
  {
    "text": "this whole plot line is going\nto work for deep learning. And deep learning, you'll\nhave a huge neural network",
    "start": "1744050",
    "end": "1749570"
  },
  {
    "text": "with millions of parameters. You want to choose\nthe parameters that maximize log likelihood. And when you have\nmillions of parameters,",
    "start": "1749570",
    "end": "1756710"
  },
  {
    "text": "you can't sit down and set\nall the derivatives equal to 0 and solve for them. And so you're going to need\na more general algorithm.",
    "start": "1756710",
    "end": "1762318"
  },
  {
    "text": "So a gradient descent is\nthe most general bread and butter algorithm. The setting equal to 0 works in\nsome cases but just not in all.",
    "start": "1762318",
    "end": "1769100"
  },
  {
    "text": "What a cool question. And I bet a lot of people\nwere wondering about that.",
    "start": "1769100",
    "end": "1774894"
  },
  {
    "text": "A term that was used\na lot last lecture was the idea of an\nunbiased estimator. We have used that in\nall of this lecture",
    "start": "1774895",
    "end": "1780070"
  },
  {
    "text": "but what if you can\ntalk a little bit more about what that means exactly\nand what's a gradient descent? So before we did\nMLE, a different way",
    "start": "1780070",
    "end": "1788100"
  },
  {
    "text": "for doing parameter\nestimation was using the things that taught\nus about a couple of weeks ago, where you could\nestimate the sample mean",
    "start": "1788100",
    "end": "1795450"
  },
  {
    "text": "and there is an\nequation for that. You could estimate\nthe sample mean by taking all your data points,\nsumming them up, and then",
    "start": "1795450",
    "end": "1802080"
  },
  {
    "text": "dividing by n. And you could estimate\nthe sample variance. And you could do that cool\nequation that we had before,",
    "start": "1802080",
    "end": "1809340"
  },
  {
    "text": "where you take all\nof your data points, subtract off your guess of\nthe sample mean squared,",
    "start": "1809340",
    "end": "1817500"
  },
  {
    "text": "divided by n minus 1. These can be used for\nparameter estimation.",
    "start": "1817500",
    "end": "1824860"
  },
  {
    "text": "Not in general. The Pareto thing? You can use this for the Pareto. But you could do this for\nvery, very specific cases.",
    "start": "1824860",
    "end": "1833110"
  },
  {
    "text": "Like if you're\nestimating the mean and variance of a Gaussian? You could use this. If you were estimating\nthe p of a Bernoulli,",
    "start": "1833110",
    "end": "1840340"
  },
  {
    "text": "you could use this because it\nturns out this works out well. So for a very small\nclass of problems,",
    "start": "1840340",
    "end": "1846070"
  },
  {
    "text": "you could estimate\nparameters just by figuring out these\nstatistics and then knowing",
    "start": "1846070",
    "end": "1851740"
  },
  {
    "text": "how to calculate your parameters\nbased off the statistics. Does that make sense? It's not general though.",
    "start": "1851740",
    "end": "1857230"
  },
  {
    "text": "It doesn't work for\nPareto distributions. It doesn't work for\nBayesian networks. It doesn't work\nfor deep learning.",
    "start": "1857230",
    "end": "1862850"
  },
  {
    "text": "So while that was a nice idea,\nwe needed something general. So MLE is general.",
    "start": "1862850",
    "end": "1867970"
  },
  {
    "text": "And gradient ascent,\nthey're general. They work for any\nmodel, any parameters you might care about.",
    "start": "1867970",
    "end": "1874929"
  },
  {
    "text": "OK, fantastic. Now this could be the\nend of our plotline.",
    "start": "1874930",
    "end": "1880040"
  },
  {
    "text": "We could just be\nlike great, we're done with machine learning. Or we know the core\ntheoretical basis of it.",
    "start": "1880040",
    "end": "1885470"
  },
  {
    "text": "And this is one of the\ncore theoretical bases. But I want you to know why\nit doesn't always work.",
    "start": "1885470",
    "end": "1891730"
  },
  {
    "text": "And particularly,\nin Monday's class, we talked about one\nreason it doesn't work. And to put that into\nwords, it's that MLE likes",
    "start": "1891730",
    "end": "1900880"
  },
  {
    "text": "to overfit the data it's seen. It's choosing the\nparameters that makes the data it's seen\nlook as likely as possible.",
    "start": "1900880",
    "end": "1908270"
  },
  {
    "text": "It doesn't think about data\nit might not have seen. So for example, if\nyou're fitting a uniform",
    "start": "1908270",
    "end": "1913750"
  },
  {
    "text": "and it got this data, it\nwill choose parameters that makes that\ndata look as likely as possible without imagining\nthat there will be data",
    "start": "1913750",
    "end": "1921910"
  },
  {
    "text": "outside. So MLE, if it had to\nfit a uniform to this, sets the minimum\nto be the smallest",
    "start": "1921910",
    "end": "1928419"
  },
  {
    "text": "value in this list and\nthe maximum parameter to be the largest value. But if you've only seen\nseven points, how likely it",
    "start": "1928420",
    "end": "1935860"
  },
  {
    "text": "is that one of the points\nwe saw was exactly the min? And how likely is it that\none of the points we saw is exactly the max?",
    "start": "1935860",
    "end": "1942880"
  },
  {
    "text": "It's overfitting to the small\namount of data it's given. Those parameters it comes up\nwith are not very general.",
    "start": "1942880",
    "end": "1949120"
  },
  {
    "text": "In fact, these values I\nchose, 1, 2, 3, 4, 5, 6, 7, I can tell you that MLE\na very bad job of using",
    "start": "1949120",
    "end": "1957360"
  },
  {
    "text": "those parameters because\nI generated those seven numbers from a uniform\nwhose true Min was 0",
    "start": "1957360",
    "end": "1962450"
  },
  {
    "text": "and whose true max was 1. And you just happened to see\n0.15 as your smallest value",
    "start": "1962450",
    "end": "1967580"
  },
  {
    "text": "because if you only\nsee seven data points, you're not going\nto get something too close to the true min.",
    "start": "1967580",
    "end": "1972625"
  },
  {
    "text": "You're not going\nto see something too close to the true max. So you'll hear a\nlot of people talk in machine learning\nabout overfitting.",
    "start": "1972625",
    "end": "1979190"
  },
  {
    "text": "It's when the parameters you\nchoose describe your data set too well.",
    "start": "1979190",
    "end": "1984380"
  },
  {
    "text": "And they don't describe things\nthat you'll see in the future very well. So MLE is great but it does\nhave this little problem.",
    "start": "1984380",
    "end": "1992929"
  },
  {
    "text": "Now for a little bit\nof foreshadowing, I am going to need a volunteer. It's got to be somebody who\nhasn't volunteered before.",
    "start": "1992930",
    "end": "2000970"
  },
  {
    "text": "You, come on up. And we are going to play a game. As you make your way up, I\nwill explain the game though.",
    "start": "2000970",
    "end": "2008890"
  },
  {
    "text": "Please ask questions\nif you have any. I have two envelopes.",
    "start": "2008890",
    "end": "2013900"
  },
  {
    "text": "One is labeled A\nand one's labeled B. Before we play this\ngame, what's your name?",
    "start": "2013900",
    "end": "2019150"
  },
  {
    "text": "Nice to meet you. I am Chris. Hey everybody, this is class. Class, this is [MUTED]. Did I say that right?",
    "start": "2019150",
    "end": "2025910"
  },
  {
    "text": "Everybody, [MUTED],,\nthis is a class. A little round of applause\nfor our wonderful volunteer. [APPLAUSE]",
    "start": "2025910",
    "end": "2032410"
  },
  {
    "text": "I have two envelopes. I'm going to allow\nyou to have one. OK.",
    "start": "2032410",
    "end": "2037870"
  },
  {
    "text": "I'll take A. Yeah, good choice. Here is the game.",
    "start": "2037870",
    "end": "2043113"
  },
  {
    "text": "And it's a wild. One also, if the lights bothers\nyou, you can stand over here. One of these envelopes\ncontains X dollars",
    "start": "2043113",
    "end": "2050649"
  },
  {
    "text": "and the other envelope\ncontains 2X dollars. So you got an envelope\nand you can look inside. ",
    "start": "2050650",
    "end": "2060000"
  },
  {
    "text": "OK. So now, here is the question. Do you want to switch? I've given you information.",
    "start": "2060000",
    "end": "2066179"
  },
  {
    "text": "I told you one\nenvelope has X dollars and one envelope has 2X dollars. Before you make your decision,\ndo you want to see some math?",
    "start": "2066179",
    "end": "2073138"
  },
  {
    "text": "Sure. Do you want to know the\nexpected amount of money in the other envelope? And everyone else in\nclass, pay attention",
    "start": "2073139",
    "end": "2078149"
  },
  {
    "text": "because we're going to help\nmake an optimal decision. So maybe you want to choose this\nbased on the expected amount",
    "start": "2078150",
    "end": "2083820"
  },
  {
    "text": "of money in this envelope. So let's say that Y\nis the amount of money in the envelope, [MUTED].",
    "start": "2083820",
    "end": "2089991"
  },
  {
    "text": "If you think about the\nexpected amount of money in the other envelope,\nthere's a 50% chance",
    "start": "2089991",
    "end": "2095129"
  },
  {
    "text": "that this has twice as\nmuch money and a 50% chance it has half as much money. So there's a 50% chance\nyou've got Y over 2",
    "start": "2095130",
    "end": "2102930"
  },
  {
    "text": "and 50% chance of 2Y. You do law of total\nexpectation and you get that the expected amount\nof money in here is 5 over 4Y.",
    "start": "2102930",
    "end": "2112080"
  },
  {
    "text": "Isn't that wild? Now, what do you think\nabout switching it?",
    "start": "2112080",
    "end": "2119120"
  },
  {
    "text": "Now I want everyone to think. We're going to get\nto poll the audience. We're going to say, do\nyou want to-- do you",
    "start": "2119120",
    "end": "2124190"
  },
  {
    "text": "guys think you recommend I\nswitch or I don't switch? So I want you guys to think. Expectation says, in\nexpectation, there's",
    "start": "2124190",
    "end": "2131030"
  },
  {
    "text": "more money in the\nother envelope. But you might have\nother opinions. Expectation's not at\nthe end of the world.",
    "start": "2131030",
    "end": "2136890"
  },
  {
    "text": "It's not the only thing\nwe can do in probability. OK, do you want to give\nthem some time to think?",
    "start": "2136890",
    "end": "2142310"
  },
  {
    "text": "Or should we make them\nmake their decision? I'll give them time to think. Yeah, that sounds good. OK, you guys think. A lot on the line.",
    "start": "2142310",
    "end": "2148100"
  },
  {
    "text": "[CHUCKLES] [SIDE CONVERSATIONS]  [CHUCKLING]",
    "start": "2148100",
    "end": "2156440"
  },
  {
    "text": "It's wild, right? [LAUGHS] I guess that means that\nit could either be $80 or $20.",
    "start": "2156440",
    "end": "2163460"
  },
  {
    "text": "[LAUGHTER]  You can weigh opinions\nhowever you want.",
    "start": "2163460",
    "end": "2169320"
  },
  {
    "text": "OK. [CHATTER] This envelope could have\n$80 or it could have $20.",
    "start": "2169320",
    "end": "2178400"
  },
  {
    "text": "And since $80 is so much\nlarger in expectations, switching always seems\nlike a good strategy. But now [MUTED] wants\nto get your advice.",
    "start": "2178400",
    "end": "2186320"
  },
  {
    "text": "Who says switch? Who says doesn't switch? First, just make your noise\nsay switch or no switch. No switch.",
    "start": "2186320",
    "end": "2192200"
  },
  {
    "text": "Oh, wow, do you want to see\nhands or was that clear enough? Feels like they said no switch.",
    "start": "2192200",
    "end": "2197313"
  },
  {
    "text": "Yeah, that seems like. But expectation says\nyou should switch. But you can choose no\nswitch, that's a fair choice.",
    "start": "2197313",
    "end": "2202683"
  },
  {
    "text": "I'll choose no switch. OK. Do you want to know\nwhat's in the other one? There's in fact $20. You made the right choice.",
    "start": "2202683",
    "end": "2208007"
  },
  {
    "text": "OK, everybody, good advice. [APPLAUSE] Thank you very much. Take your seat. Yeah. But I want the envelope.",
    "start": "2208007",
    "end": "2213635"
  },
  {
    "text": "[LAUGHTER] Hard to find envelopes. ",
    "start": "2213635",
    "end": "2221490"
  },
  {
    "text": "Now that is interesting. Everybody says don't switch. And yet, expectation\nsays that there",
    "start": "2221490",
    "end": "2228420"
  },
  {
    "text": "is more likely to be money\nin the other envelope. And I'm going to say that there\nis a bug in our thinking, which",
    "start": "2228420",
    "end": "2234570"
  },
  {
    "text": "is similar to the bug in MLE. If you got to play this\ngame a whole bunch of times,",
    "start": "2234570",
    "end": "2239760"
  },
  {
    "text": "you could figure out a\nlot of interesting things. And particularly, one of the\nthings that you could figure",
    "start": "2239760",
    "end": "2248700"
  },
  {
    "text": "out is when we made\nthis calculation, I assumed it was equally\nlikely that there",
    "start": "2248700",
    "end": "2254430"
  },
  {
    "text": "was $20 and just as\nlikely that there was $80 in the other envelope.",
    "start": "2254430",
    "end": "2259940"
  },
  {
    "text": "If you could play this game\nmany, many, many, many times, you could actually get\nbetter at estimating those.",
    "start": "2259940",
    "end": "2265970"
  },
  {
    "text": "You could be like,\nChris never puts $80. He doesn't have\nthat kind of money. [CHUCKLES] And you could become more and\nmore intelligent about this.",
    "start": "2265970",
    "end": "2273080"
  },
  {
    "text": "And in fact, though,\neven without playing this many times, I can tell you\nthat this is really misleading.",
    "start": "2273080",
    "end": "2279950"
  },
  {
    "text": "This idea that\nit's just as likely to have half as much money\nas double as much money. And to drive that\npoint home, let's",
    "start": "2279950",
    "end": "2286400"
  },
  {
    "text": "say you open the first envelope. This is back when I was younger\nand didn't have $40 to my name.",
    "start": "2286400",
    "end": "2292130"
  },
  {
    "text": "And it could have had $10 in it. If you claim that $20 and $5 are\nequally likely, if you recurse",
    "start": "2292130",
    "end": "2301000"
  },
  {
    "text": "on that assumption, you\ncould say $40 must then also be equally likely.",
    "start": "2301000",
    "end": "2306430"
  },
  {
    "text": "And $80 must be equally likely. And then $160 must\nbe equally likely. It turns out there is\ninfinite powers of 2.",
    "start": "2306430",
    "end": "2314349"
  },
  {
    "text": "And if you have infinite\nvalues that are equally likely, you no longer have a valid\nprobability distribution.",
    "start": "2314350",
    "end": "2322010"
  },
  {
    "text": "And you're claiming\nthat it's equally likely that I have $20 in\nmy envelope as it is that I have 2 to the\n50th dollars in my envelope.",
    "start": "2322010",
    "end": "2330320"
  },
  {
    "text": "And we know that\nthat's just not true. I'm a professor. [LAUGHTER] So that was a broken assumption.",
    "start": "2330320",
    "end": "2337490"
  },
  {
    "text": "And the broken assumption,\nit could have been solved in a few different ways.",
    "start": "2337490",
    "end": "2342780"
  },
  {
    "text": "One way you could\nhave solved it is, you could have played this\ngame a whole bunch of times.",
    "start": "2342780",
    "end": "2347920"
  },
  {
    "text": "If you played this\ngame hundreds of times, or if you watched all the\npast videos of CS 109, you could realize that there's\na pretty tight distribution",
    "start": "2347920",
    "end": "2354140"
  },
  {
    "text": "over the amounts of money\nI'll put in envelopes. But the problem is, I only\nlet you play this game once.",
    "start": "2354140",
    "end": "2360590"
  },
  {
    "text": "And there are so many\ncontexts in the world, in your algorithms, in\nproblems that you'll want to solve where you don't\nget to have a ton of data.",
    "start": "2360590",
    "end": "2368570"
  },
  {
    "text": "You don't get to play\na game many times before you have to make a\ndecision under uncertainty. And one of the\nways to solve this",
    "start": "2368570",
    "end": "2376100"
  },
  {
    "text": "is before you walk into the\ngame, you have a prior belief.",
    "start": "2376100",
    "end": "2381110"
  },
  {
    "text": "You use all your knowledge of\nChris and what sort of things I might put in envelopes.",
    "start": "2381110",
    "end": "2387090"
  },
  {
    "text": "And you encode that\nin a way that's not through experimentation. And Bayesian prior beliefs\nis a really good way",
    "start": "2387090",
    "end": "2394440"
  },
  {
    "text": "to talk about that. You can have subjective\nprobabilities. You can have beliefs\nbefore you see any data.",
    "start": "2394440",
    "end": "2400950"
  },
  {
    "text": "Now of course, by extension,\nif you have a prior belief, all posteriors have some\nsubjectivity in them.",
    "start": "2400950",
    "end": "2407310"
  },
  {
    "text": "But it's really helpful when you\nhave to answer questions when you have limited to no data. And it can also be\nvery, very helpful",
    "start": "2407310",
    "end": "2414300"
  },
  {
    "text": "when you would like to\nnot overfit the data that you've seen so far.",
    "start": "2414300",
    "end": "2420250"
  },
  {
    "text": "So your subjective\nprobability, if you had a belief about\nenvelopes before, you might think 20 is a\npretty likely number for Chris",
    "start": "2420250",
    "end": "2427660"
  },
  {
    "text": "to put in. And 10 is possible. But I think that\nthe probabilities of these other numbers\nare somehow smaller.",
    "start": "2427660",
    "end": "2433560"
  },
  {
    "text": "And particularly,\nit is very unlikely that I put a dollar in. Because if I put\na dollar in, then",
    "start": "2433560",
    "end": "2439500"
  },
  {
    "text": "you'd be able to weigh\nthe other one and be like, there's no coins in here. And similarly, it's\nreally unlikely I put $5",
    "start": "2439500",
    "end": "2446910"
  },
  {
    "text": "in because then $2.50 would\nalso be really easy to weigh. You can have a really\nstrong prior belief",
    "start": "2446910",
    "end": "2453340"
  },
  {
    "text": "about what's in this envelope. And my claim is, you guys\nall knew the right answer. And the reason you\nknew the right answer",
    "start": "2453340",
    "end": "2459510"
  },
  {
    "text": "is because in your\nbrains, you were holding on to this\nsubjective belief over how likely different numbers were.",
    "start": "2459510",
    "end": "2464820"
  },
  {
    "text": "You, in yourselves, felt\nthat it was very unlikely that I put $80 in there. And this is called--\nthis is a paradox.",
    "start": "2464820",
    "end": "2471587"
  },
  {
    "text": "And the solution to the\nparadox, the reason humans don't find this hard is\nbecause we have strong priors.",
    "start": "2471587",
    "end": "2477150"
  },
  {
    "text": "OK. Oh, we've already\nplayed the game. But in my first version,\nI had you standing up here",
    "start": "2477150",
    "end": "2483329"
  },
  {
    "text": "through that whole exposition. Now, if I could summarize the\nmajor takeaways from this.",
    "start": "2483330",
    "end": "2490000"
  },
  {
    "text": "Probabilities really do have\na belief element to them. In some level,\nprobabilities representing",
    "start": "2490000",
    "end": "2495580"
  },
  {
    "text": "what we don't know\nabout the world will help us make\nbetter decisions. So if you can incorporate\nprior beliefs maybe",
    "start": "2495580",
    "end": "2503200"
  },
  {
    "text": "when you have small\namounts of data, you will make better decisions. You will overfit your data\nless and you will maybe",
    "start": "2503200",
    "end": "2510010"
  },
  {
    "text": "end up with better parameters. We've actually seen\nthis play out before.",
    "start": "2510010",
    "end": "2516839"
  },
  {
    "text": "And I want to recall a\nproblem from earlier in class. And I want to show you the\nequivalent version as parameter",
    "start": "2516840",
    "end": "2524010"
  },
  {
    "text": "estimation. Earlier in class, I gave\nyou a problem that says, a medicine is tried\non 20 patients.",
    "start": "2524010",
    "end": "2529920"
  },
  {
    "text": "It works for 14 and\nit doesn't work for 6. What is your new belief\nthat the drug works?",
    "start": "2529920",
    "end": "2536670"
  },
  {
    "text": "That was the question\nI asked you earlier. But I could have phrased this\nas a parameter estimation question. I said, I could say I\nhave 20 I.I.D. samples",
    "start": "2536670",
    "end": "2544200"
  },
  {
    "text": "from Bernoulli, estimate p. Here's your data. 16 1's and-- oh, I'm sorry.",
    "start": "2544200",
    "end": "2550260"
  },
  {
    "text": "14 1's and 6 0's. Now, if you set up this problem,\nwe can now just throw in MLE.",
    "start": "2550260",
    "end": "2558620"
  },
  {
    "text": "And MLE, if you worked\nout the MLE estimate, we talked about what\nit is for Bernoulli, it's just the average.",
    "start": "2558620",
    "end": "2564630"
  },
  {
    "text": "So you'd sum up all these\nvalue and divide by 20 and that would give\nyou 14 divided by 20. MLE would just give you 0.07.",
    "start": "2564630",
    "end": "2571809"
  },
  {
    "text": "But we saw this particular\nproblem earlier in class. We actually had a\ndifferent way of solving it",
    "start": "2571810",
    "end": "2577870"
  },
  {
    "text": "that didn't require us to use\nthis particular plot line. In this case, we had a\nmuch more elegant way",
    "start": "2577870",
    "end": "2584619"
  },
  {
    "text": "of talking about the\nprobability parameter p. We had this elegant conversation\nabout a thing called a beta.",
    "start": "2584620",
    "end": "2592710"
  },
  {
    "text": "You said, I can have a prior\nbelief in what my parameter is. And then I can update my belief\nin what p is after I saw data.",
    "start": "2592710",
    "end": "2601930"
  },
  {
    "text": "And this was so elegant\nfor two reasons. The first reason it was elegant\nis like the envelope example,",
    "start": "2601930",
    "end": "2609280"
  },
  {
    "text": "it allows for you to incorporate\nwhat you know before you start doing any experiments. Maybe you know something\nabout these drugs.",
    "start": "2609280",
    "end": "2615910"
  },
  {
    "text": "And you can incorporate\nthat information. So it's stronger\nfor that reason. It was also stronger for\nthe other reason, which",
    "start": "2615910",
    "end": "2622110"
  },
  {
    "text": "is instead of just giving\nyou about a single number, it gave you a whole distribution\naround that number so you could",
    "start": "2622110",
    "end": "2628380"
  },
  {
    "text": "express not just\nthat I think 0.71 is the most likely value\nof p, but I can also talk about my confidence.",
    "start": "2628380",
    "end": "2634930"
  },
  {
    "text": "So for a few\nreasons, what we did earlier was more elegant\nthan what we're doing now.",
    "start": "2634930",
    "end": "2641280"
  },
  {
    "text": "Now, reason we haven't\nseen this in place of MLE",
    "start": "2641280",
    "end": "2646800"
  },
  {
    "text": "is because that worked\nfor the p of a Bernoulli. Could we take that\nsame beautiful idea",
    "start": "2646800",
    "end": "2653640"
  },
  {
    "text": "and make it work for\nother parameters? Because if we could, then maybe\nwe could do a little bit better",
    "start": "2653640",
    "end": "2659370"
  },
  {
    "text": "than MLE and we could learn\nabout our final estimator. So today, the plot line\nis going to diverge",
    "start": "2659370",
    "end": "2665640"
  },
  {
    "text": "and we're going to be\nlearning about a different way that we could do\nour estimations.",
    "start": "2665640",
    "end": "2671280"
  },
  {
    "text": "And it's going to\nbe a Bayesian policy that we're going to talk about\ncalled maximum a posteriori.",
    "start": "2671280",
    "end": "2678150"
  },
  {
    "text": "And really, what it's\ngoing to allow us to do, it's going to allow us\nto incorporate priors for parameter estimation.",
    "start": "2678150",
    "end": "2683340"
  },
  {
    "text": "It will be a different method\nfor choosing our parameters. I would like to introduce it\nby contrasting it explicitly",
    "start": "2683340",
    "end": "2692250"
  },
  {
    "text": "with MLE. MLE says, hey, you\nwant parameters, pal? I'll give you parameters.",
    "start": "2692250",
    "end": "2698250"
  },
  {
    "text": "How I'm going to\ngive you parameters is I will choose the\nparameters that maximize the likelihood of your data.",
    "start": "2698250",
    "end": "2705370"
  },
  {
    "text": "Which parameters make the data\nlook as likely as possible. The Bayesian approach\nlooks very similar.",
    "start": "2705370",
    "end": "2713849"
  },
  {
    "text": "But if you're very\nattentive, you'll notice it answers a\nslightly different question.",
    "start": "2713850",
    "end": "2719650"
  },
  {
    "text": "There is another way of\nestimating parameters. It says, yo, pal,\nyou want parameters? I'll get you parameters.",
    "start": "2719650",
    "end": "2725280"
  },
  {
    "text": "But I'm not MLE. I'm going to give you\nmore elegant parameters. Instead of choosing\nthe parameters that",
    "start": "2725280",
    "end": "2732690"
  },
  {
    "text": "make the data most\nlikely, I'm going to choose the parameters\nthat are the most likely",
    "start": "2732690",
    "end": "2739110"
  },
  {
    "text": "given the values of the data. ",
    "start": "2739110",
    "end": "2744690"
  },
  {
    "text": "I saw 20 heads go like, what? [LAUGHS] Yeah.",
    "start": "2744690",
    "end": "2749730"
  },
  {
    "text": "These are slightly\ndifferent philosophies. This is saying, what makes\nthe data look likely.",
    "start": "2749730",
    "end": "2757200"
  },
  {
    "text": "And this is saying what's\nthe most likely parameter. They're slightly different. They're the conditional\nin the reverse.",
    "start": "2757200",
    "end": "2764160"
  },
  {
    "text": "And when you put the\nconditional in the reverse, then we're going to\nhave to solve this using a different mechanism.",
    "start": "2764160",
    "end": "2769410"
  },
  {
    "text": "And that different mechanism is\ngoing to invoke Bayes' theorem. And the unknowable\nis the parameter",
    "start": "2769410",
    "end": "2778020"
  },
  {
    "text": "and the data is the observable. So this is the more natural\ndirection to express. In terms of equations, we\nhave likelihood functions.",
    "start": "2778020",
    "end": "2784800"
  },
  {
    "text": "Whereas, this is something\nthat we don't exactly know how we would\nhave to solve for it.",
    "start": "2784800",
    "end": "2790650"
  },
  {
    "text": "Just to be clear, these\ntwo different philosophies are going to lead to\ntwo different algorithms",
    "start": "2790650",
    "end": "2795990"
  },
  {
    "text": "because we never did\nthis algorithm directly. Instead, we did\nthe log likelihood. We did argmax of\nthe log likelihood.",
    "start": "2795990",
    "end": "2802440"
  },
  {
    "text": "And similarly, we're going to\ndo some manipulations to make this easier to work with. But today, we're going to learn\nabout our final estimator.",
    "start": "2802440",
    "end": "2808619"
  },
  {
    "text": "And the final estimator\nstarts by taking a different\nphilosophical stance. And the idea of the different\nphilosophical stance",
    "start": "2808620",
    "end": "2814410"
  },
  {
    "text": "is it will allow us\nto incorporate priors. It will allow us to come\nup with maybe better estimates, especially when we\nhave small amounts of data.",
    "start": "2814410",
    "end": "2821610"
  },
  {
    "text": "OK. So a little bit of\nshorthand because I'm",
    "start": "2821610",
    "end": "2827135"
  },
  {
    "text": "going to have to write equations\nlike this over and over again. And I want to be clear\nthat when I use shorthand, I don't lose people.",
    "start": "2827135",
    "end": "2833080"
  },
  {
    "text": "So we're thinking\nabout our parameters now as being random\nvariables, just like the beta.",
    "start": "2833080",
    "end": "2839880"
  },
  {
    "text": "And we want to\nchoose the assignment to those random variables\nthat are the most likely",
    "start": "2839880",
    "end": "2844950"
  },
  {
    "text": "given the assignments to\nthe I.I.D. samples we have. But I'm going to\nstart using theta",
    "start": "2844950",
    "end": "2850589"
  },
  {
    "text": "as shorthand for the event of\nthe random variables for theta equals theta. And x i as shorthand for the\nevent the i'th data point takes",
    "start": "2850590",
    "end": "2858750"
  },
  {
    "text": "on the value that we\nsaw in the database. Also, one small thing.",
    "start": "2858750",
    "end": "2864840"
  },
  {
    "text": "Did you notice how I used to\nhave the i'th data point using a subscript and now I've\nmoved to a superscript?",
    "start": "2864840",
    "end": "2871500"
  },
  {
    "text": "I'm just trying to gently\nget us ready for when we get to machine\nlearning algorithms on Friday and beyond.",
    "start": "2871500",
    "end": "2876725"
  },
  {
    "text": "Because when we get to\nmachine learning algorithms, our data points will have\nmultiple values per data point.",
    "start": "2876725",
    "end": "2882010"
  },
  {
    "text": "So I'm just going to start\nputting my i's as superscripts. But this is still saying x i.",
    "start": "2882010",
    "end": "2888270"
  },
  {
    "text": "Using this shorthand\nnotation, I'm still saying choose the thetas\nthat are the most likely",
    "start": "2888270",
    "end": "2894300"
  },
  {
    "text": "given the data points\nthat we've observed. OK, let's jump in.",
    "start": "2894300",
    "end": "2900860"
  },
  {
    "text": "But give people a moment. Let that sink in. It's like, OK, this is MLE but\nwe're flipping the conditional.",
    "start": "2900860",
    "end": "2907099"
  },
  {
    "text": "That seems fine. Will it actually be different? We'll find out. ",
    "start": "2907100",
    "end": "2915500"
  },
  {
    "text": "Now, just to be clear,\nif you are estimating",
    "start": "2915500",
    "end": "2920790"
  },
  {
    "text": "the most likely\nvalue of a parameter given data for a particular\nmodel of a Bernoulli.",
    "start": "2920790",
    "end": "2928805"
  },
  {
    "text": "So I'm telling\nyou, all your data points come from a Bernoulli. If you wanted to choose the\nmost likely value of theta given",
    "start": "2928805",
    "end": "2938790"
  },
  {
    "text": "my Bernoulli data, so that could\nbe heads equals 16 and tails-- or heads equals 14\nand tails equals 6,",
    "start": "2938790",
    "end": "2948720"
  },
  {
    "text": "we already know how to think\nabout this probability. This would actually be\na beta distribution.",
    "start": "2948720",
    "end": "2954940"
  },
  {
    "text": "So if you said, what\nis the distribution of the likelihoods\nof the parameters given the data that\nyou have observed?",
    "start": "2954940",
    "end": "2960810"
  },
  {
    "text": "We know this will come\nout to a beta distribution in the case of a Bernoulli. And then if we put\nan argmax here,",
    "start": "2960810",
    "end": "2971020"
  },
  {
    "text": "it's saying which value of\ntheta has the highest value.",
    "start": "2971020",
    "end": "2976023"
  },
  {
    "text": "And this is actually,\ntechnically, a probability density in the\nprobability density of theta.",
    "start": "2976023",
    "end": "2981790"
  },
  {
    "text": "When we did the\nbeta distribution, these were x's because x was\nour random variable for p.",
    "start": "2981790",
    "end": "2988150"
  },
  {
    "text": "But now I'm using theta. It's because theta is my more\ngeneral random variable for p. So if you say the\ndistribution of your parameter",
    "start": "2988150",
    "end": "2996280"
  },
  {
    "text": "given data you saw, it is a-- or sorry, it is a beta. And if you say\nargmax, it will just",
    "start": "2996280",
    "end": "3002910"
  },
  {
    "text": "return the mode, which is\nwhichever input to the beta",
    "start": "3002910",
    "end": "3010200"
  },
  {
    "text": "has the highest probability. ",
    "start": "3010200",
    "end": "3015750"
  },
  {
    "text": "So before we get\ninto any heavy math, I just want to tell you that\nif you use this new philosophy,",
    "start": "3015750",
    "end": "3021630"
  },
  {
    "text": "this MAP philosophy. And if you used it to\nestimate the parameter for a Bernoulli\nor a binomial, it",
    "start": "3021630",
    "end": "3028289"
  },
  {
    "text": "would be really,\nreally straightforward because we've already\ndone the math for a beta. Because we've\nalready done the math",
    "start": "3028290",
    "end": "3033690"
  },
  {
    "text": "for beta, what this\nwould look like is you're going to have to choose a\nprior belief in your parameter.",
    "start": "3033690",
    "end": "3040410"
  },
  {
    "text": "You'll express that as a beta. Recall that a beta\nwith a, b means that you saw a minus 1\nimaginary successes and b",
    "start": "3040410",
    "end": "3048690"
  },
  {
    "text": "minus 1 imaginary\nfailures before you started looking at any data.",
    "start": "3048690",
    "end": "3053770"
  },
  {
    "text": "Then you run an\nexperiment, which is, you start to see\nsome data points. You'll see particularly n data\npoints of successes and m data",
    "start": "3053770",
    "end": "3060779"
  },
  {
    "text": "points of failures. The posterior of your\nbelief in the probability",
    "start": "3060780",
    "end": "3066417"
  },
  {
    "text": "is going to be a new beta. And we derived\nthis earlier, where the parameters in new beta is\na, which came from our prior.",
    "start": "3066417",
    "end": "3073080"
  },
  {
    "text": "Plus n that came from\nthe data we observed. So imaginary successes minus 1,\nplus true successes observed.",
    "start": "3073080",
    "end": "3080620"
  },
  {
    "text": "And the second parameter is\nimaginary failures minus 1, plus the true number of\nfailures that we observed.",
    "start": "3080620",
    "end": "3088270"
  },
  {
    "text": "So for estimating just\nthe p of Bernoulli,",
    "start": "3088270",
    "end": "3093880"
  },
  {
    "text": "you could end up\nwith this posterior belief over the parameter,\nin this case, the p.",
    "start": "3093880",
    "end": "3100120"
  },
  {
    "text": "And your posterior belief\nwould be a beta once again. Maximum a posterior then\nthrows an argmax around this.",
    "start": "3100120",
    "end": "3107170"
  },
  {
    "text": "So we saw this in class. Maximum a posteriori, this other\nway of choosing parameters,",
    "start": "3107170",
    "end": "3113200"
  },
  {
    "text": "will choose a single number. Instead of giving\nyou back a full beta, it will choose the number\nwhich is whichever value makes",
    "start": "3113200",
    "end": "3120790"
  },
  {
    "text": "the beta as large as possible. That is the mode. And it's always equal\nto the first parameter",
    "start": "3120790",
    "end": "3127270"
  },
  {
    "text": "minus 1 divided by the sum of\nthe two parameters minus 2. And it's always that\nfor a beta distribution.",
    "start": "3127270",
    "end": "3135500"
  },
  {
    "text": "So back to our plot line. And I'm not going to\nwrite this in green because that's hard to see.",
    "start": "3135500",
    "end": "3141250"
  },
  {
    "text": "We now have this core need. You need parameter estimation\nfor machine learning.",
    "start": "3141250",
    "end": "3146860"
  },
  {
    "text": "MLE is great. But it generally overfits. And it doesn't allow\nyou to have priors. So we're going to have MAP to\neliminate-- or to not overfit.",
    "start": "3146860",
    "end": "3156700"
  },
  {
    "start": "3156700",
    "end": "3161839"
  },
  {
    "text": "And while this is\na good idea, and we can see how this would be a\ngreat idea if we're estimating p, we have one huge issue.",
    "start": "3161840",
    "end": "3171000"
  },
  {
    "text": "MLE works for more\nthan just estimating p. Parameter estimation is supposed\nto be something general.",
    "start": "3171000",
    "end": "3176250"
  },
  {
    "text": "For any machine\nlearning model, we should be able to\nestimate parameters. And while MAP,\nMaximum A Posteriori,",
    "start": "3176250",
    "end": "3181890"
  },
  {
    "text": "that really fancy term\nfor just saying, what's the most likely\nparameters given my data.",
    "start": "3181890",
    "end": "3187210"
  },
  {
    "text": "While that seems\nlike a good idea, so far, we've only seen it for\nestimating a single parameter for a single type of model.",
    "start": "3187210",
    "end": "3192790"
  },
  {
    "text": "It doesn't feel that general. I do have good news.",
    "start": "3192790",
    "end": "3198320"
  },
  {
    "text": "People are like, this\nseems like a good idea. Let's get to work, crew! And a whole bunch--",
    "start": "3198320",
    "end": "3203830"
  },
  {
    "text": "I imagine everybody\nhad a meeting and then everybody\nwent and figured out what's the way to do maximum\na posteriori for a whole bunch",
    "start": "3203830",
    "end": "3210370"
  },
  {
    "text": "of classic random variables. And they did. And they thrived. And they had a good time. Somebody figured out how\ndid you do the maximum",
    "start": "3210370",
    "end": "3217240"
  },
  {
    "text": "a posteriori for a p. Well, we're going to use\na beta prior that's going to lead to a beta posterior.",
    "start": "3217240",
    "end": "3223315"
  },
  {
    "text": "And then we can just do\nthe mode of the beta. Fantastic. That also works for binomial. Then somebody whose\njob was to do Poisson.",
    "start": "3223315",
    "end": "3229990"
  },
  {
    "text": "Hey, you want to estimate\nthe lambda Poisson? Great, you have to\ngive me a prior. There's a particular\ndistribution called a gamma.",
    "start": "3229990",
    "end": "3236470"
  },
  {
    "text": "And if you express\nyour prior as a gamma, then your posterior\nwill also be a gamma. And then we can\nchoose the value that",
    "start": "3236470",
    "end": "3243910"
  },
  {
    "text": "maximizes your belief in\nlambda by choosing whatever maximizes the posterior gamma.",
    "start": "3243910",
    "end": "3249920"
  },
  {
    "text": "Same thing with the\nexponential lambda. And people did something\nfor the normal mean.",
    "start": "3249920",
    "end": "3255150"
  },
  {
    "text": "It turns out your prior\nshould also be a normal. And people did the same thing\nfor a normal of the variance--",
    "start": "3255150",
    "end": "3261319"
  },
  {
    "text": "of the variance\nparameter in a normal. And each of these,\nsomebody worked out",
    "start": "3261320",
    "end": "3266480"
  },
  {
    "text": "the math for how you could\ndo maximum a posteriori. I'm just going to show\nyou a few of these.",
    "start": "3266480",
    "end": "3272790"
  },
  {
    "text": "I'm going to show you what\nit looks like for this lambda",
    "start": "3272790",
    "end": "3278190"
  },
  {
    "text": "in a Poisson. I'm going to show you what it\nlooks like for a multinomial. And then I'm going to\nshow you the math that you",
    "start": "3278190",
    "end": "3283370"
  },
  {
    "text": "could use if you wanted\nto derive one yourself. Yes? Can you explain again what\na conjugate distribution is?",
    "start": "3283370",
    "end": "3289789"
  },
  {
    "text": "Yeah. Do you remember when\nwe talked about betas, if you expressed\nyour prior as a beta",
    "start": "3289790",
    "end": "3296840"
  },
  {
    "text": "and then you did Bayes' theorem,\nthe posterior magically was still in the form of a beta?",
    "start": "3296840",
    "end": "3303590"
  },
  {
    "text": "We call that a conjugate. When the form of a prior\nmatches the form of a posterior, it's really, really\nnice and good times.",
    "start": "3303590",
    "end": "3310730"
  },
  {
    "text": "And so when expressing\nprior beliefs, we often try and\nlook for expressions",
    "start": "3310730",
    "end": "3316400"
  },
  {
    "text": "that have this property. Do you need to come up\nwith conjugate priors yourself in CS 109?",
    "start": "3316400",
    "end": "3323120"
  },
  {
    "text": "No. But is it nice to know\nthat these are really good choices for representing\npriors for these variables?",
    "start": "3323120",
    "end": "3330530"
  },
  {
    "text": "You should know that. Yes? So does that mean\nwe're re-representing",
    "start": "3330530",
    "end": "3335880"
  },
  {
    "text": "the distribution parameter\ncompletely as, for example, a beta instead of binomial? Yeah.",
    "start": "3335880",
    "end": "3341040"
  },
  {
    "text": "So the binomial\nhas a parameter p. And we now need a random\nvariable type for p.",
    "start": "3341040",
    "end": "3348660"
  },
  {
    "text": "So even though p is for\nbinomial, the variable for p itself is a beta.",
    "start": "3348660",
    "end": "3355530"
  },
  {
    "text": "Lambda is the\nparameter for Poisson. That's a good time. But if you were to turn lambda\nitself into a random variable",
    "start": "3355530",
    "end": "3361861"
  },
  {
    "text": "so you could choose\nthe most likely value of that random variable,\nthe right format for that random\nvariables distribution",
    "start": "3361862",
    "end": "3367920"
  },
  {
    "text": "is a gamma, which we'll\ntalk about in a second. So I understand the\ndifference between MAP and MLE",
    "start": "3367920",
    "end": "3374705"
  },
  {
    "text": "and how you're looking for-- so for example, in\nthis case, you're",
    "start": "3374705",
    "end": "3379970"
  },
  {
    "text": "trying to maximize the\nlikelihood of your parameters.",
    "start": "3379970",
    "end": "3386390"
  },
  {
    "text": "Intuitively, it makes sense\nthat the most likely parameter would give you values\nthat are the most likely.",
    "start": "3386390",
    "end": "3393047"
  },
  {
    "text": "But obviously, that's not true. But what's an example\nor this isn't the case? So I mean, if--",
    "start": "3393048",
    "end": "3401119"
  },
  {
    "text": "the question is, what's the\nrelationship between this and if you flipped\nthe conditional.",
    "start": "3401120",
    "end": "3406460"
  },
  {
    "text": "In what case is it\ndifferent asking what is the most likely value\nof the parameters versus what",
    "start": "3406460",
    "end": "3412490"
  },
  {
    "text": "parameters make the data\nas likely as possible. I mean, I'm jumping the\nplot line a little bit.",
    "start": "3412490",
    "end": "3417890"
  },
  {
    "text": "But let's replace\nthis with data. So we want to choose\nthe parameters that",
    "start": "3417890",
    "end": "3425660"
  },
  {
    "text": "are most likely given the data. And using Bayes' theorem, this\nwill be data given parameters,",
    "start": "3425660",
    "end": "3433670"
  },
  {
    "text": "times your prior belief\nin the parameters, divided by some\nnormalization constant.",
    "start": "3433670",
    "end": "3438869"
  },
  {
    "text": "So I'll say that this\nis equal to some-- divided by some constant K.",
    "start": "3438870",
    "end": "3444350"
  },
  {
    "text": "Notice this relationship. If you think this constant\nK doesn't change an argmax, which it doesn't.",
    "start": "3444350",
    "end": "3450590"
  },
  {
    "text": "Multiplying everything\nby a constant won't change which argument\nmaximizes this function.",
    "start": "3450590",
    "end": "3455690"
  },
  {
    "text": "If the argmax of this is\nequal to the argmax of this, your question is,\nwhat's the relationship",
    "start": "3455690",
    "end": "3461329"
  },
  {
    "text": "between this expression,\nand this expression, and when are they different. And notice, there's a\nmathematical relationship.",
    "start": "3461330",
    "end": "3468400"
  },
  {
    "text": "What's the difference\nbetween the likelihood of your parameter\ngiven your data and the likelihood of your\ndata given your parameter?",
    "start": "3468400",
    "end": "3475290"
  },
  {
    "text": "To make them equal, you have to\nmultiply this one by this term.",
    "start": "3475290",
    "end": "3480870"
  },
  {
    "text": "That is the term\nthat shows you how these two things are different. And what is that term?",
    "start": "3480870",
    "end": "3487715"
  },
  {
    "text": "That's a little bit\nof a hard question. But I'm going to ask you. You asked me a hard question. [CHUCKLES] Right.",
    "start": "3487715",
    "end": "3492970"
  },
  {
    "text": "So it's going to be the\nvalue of your beta, right?",
    "start": "3492970",
    "end": "3500359"
  },
  {
    "text": "I mean more generally. What does it mean to\ntalk about the likelihood of the parameters\nwithout any data?",
    "start": "3500360",
    "end": "3508610"
  },
  {
    "text": "That's your prior. That's your prior. Let's write that in all caps.",
    "start": "3508610",
    "end": "3514490"
  },
  {
    "text": "These two philosophies\nare incredibly similar. Because these two expressions\nare incredibly similar.",
    "start": "3514490",
    "end": "3520490"
  },
  {
    "text": "There's just one term\nthat makes them different. These things would be equal if\nyou took what we had from MLE",
    "start": "3520490",
    "end": "3526400"
  },
  {
    "text": "and multiplied it by\nhow likely you thought those parameters were before\nyou saw any data, a.k.a.,",
    "start": "3526400",
    "end": "3532670"
  },
  {
    "text": "the prior. And if you could\ninterpret this term, then you have a way of\nchoosing the parameters that",
    "start": "3532670",
    "end": "3537680"
  },
  {
    "text": "are most likely given the data. What a wild ride. We're throwing all\nthe 109 things.",
    "start": "3537680",
    "end": "3543050"
  },
  {
    "text": "You've got conditional\nprobabilities. You have parameters\nas random variables. And you have optimization\nfor parameter estimation.",
    "start": "3543050",
    "end": "3549680"
  },
  {
    "text": "Oh, my god. This is throwing everything\nat you guys all at once. And you got some Bayes'\ntheorem just for good measure.",
    "start": "3549680",
    "end": "3555335"
  },
  {
    "text": "Just to verify,\nthe bottom equation is as if we did the\nlikelihood thing",
    "start": "3555335",
    "end": "3560359"
  },
  {
    "text": "but also incorporated\nthat specific graph of how",
    "start": "3560360",
    "end": "3566150"
  },
  {
    "text": "we thought you're going to\nput money in the envelope and then it's the same as\ndoing it the other way around?",
    "start": "3566150",
    "end": "3571750"
  },
  {
    "text": "Yeah. Basically, it will be\nthe exact same formula but we now will have a\nterm for how likely you",
    "start": "3571750",
    "end": "3577320"
  },
  {
    "text": "thought parameters were\nbefore you saw any data. And so we'll have a new\nlanguage for talking",
    "start": "3577320",
    "end": "3582710"
  },
  {
    "text": "about that prior belief. And it'll hopefully make\nour estimation better. Now, actually, I\ndon't want to go",
    "start": "3582710",
    "end": "3589110"
  },
  {
    "text": "over this too much\nbecause it's a little bit rote, in that there's\nnot a lot of deep insight in these next few lines.",
    "start": "3589110",
    "end": "3594390"
  },
  {
    "text": "I just want to tell you\nthat people have solved this for different parameters. If you solve this equation for--",
    "start": "3594390",
    "end": "3600900"
  },
  {
    "text": "if you want to come up with\ngood ways of expressing priors so that you could come\nup with good posteriors, I just want to show you what\nit looked for a couple of them.",
    "start": "3600900",
    "end": "3607740"
  },
  {
    "text": "If you want to choose a\nlambda, one of the ways is you set a prior belief.",
    "start": "3607740",
    "end": "3613710"
  },
  {
    "text": "And the prior belief that\nyou choose for your lambda, it's like, I'm going\nto imagine that I've",
    "start": "3613710",
    "end": "3621869"
  },
  {
    "text": "seen some number of\nimaginary time periods. And in that imaginary\nnumber of time periods, I saw some number\nof imaginary events.",
    "start": "3621870",
    "end": "3629460"
  },
  {
    "text": "And it's your way of\nrepresenting your belief in the rate before\nyou see any data.",
    "start": "3629460",
    "end": "3635385"
  },
  {
    "text": "If you had that belief,\nyou can express it in this new random variable\nwhich you've not seen before. But it turns out\nto be a useful way",
    "start": "3635385",
    "end": "3641760"
  },
  {
    "text": "of expressing the prior\nof a lambda, which is called a gamma. And it has exactly\nthose two parameters",
    "start": "3641760",
    "end": "3647250"
  },
  {
    "text": "that we just mentioned. You could express your prior\nbelief as a gamma before.",
    "start": "3647250",
    "end": "3652350"
  },
  {
    "text": "And then in your\nexperiment, when you're trying to update\nyour belief about the lambda of a Poisson, if you actually\nsee n events in k time periods,",
    "start": "3652350",
    "end": "3661260"
  },
  {
    "text": "if you express your\nprior as a gamma, your posterior will\nalso be a gamma.",
    "start": "3661260",
    "end": "3666810"
  },
  {
    "text": "And it will be your\nimaginary number of events plus how many\nevents you actually saw.",
    "start": "3666810",
    "end": "3672790"
  },
  {
    "text": "And your imaginary number of\ntime periods plus how many time periods you actually saw. Just to give you a sense\nthat people have solved this,",
    "start": "3672790",
    "end": "3679600"
  },
  {
    "text": "this is how you would\nend up with-- this is what MAP looks like for lambda. I want to skip this\nfor a second because I",
    "start": "3679600",
    "end": "3686230"
  },
  {
    "text": "do want to jump to actually\nsolving this for ourselves.",
    "start": "3686230",
    "end": "3692010"
  },
  {
    "text": "So far, you should\nuse a beta if you want to estimate p for a Bernoulli.",
    "start": "3692010",
    "end": "3697530"
  },
  {
    "text": "I just told you, you\nshould use a gamma if you want to\nestimate a lambda. And I just want to\nreally quickly tell you",
    "start": "3697530",
    "end": "3702869"
  },
  {
    "text": "that somebody has also solved\nthis for a multinomial. Remember multinomial? You're rolling a\nwhole bunch of dice",
    "start": "3702870",
    "end": "3708120"
  },
  {
    "text": "and you want to know successes\nof each type of outcome. You can set up a prior\nthat's the extension",
    "start": "3708120",
    "end": "3713430"
  },
  {
    "text": "of a beta for a multinomial. And it has a really fancy\nname called a Dirichlet. But it's just a beta\nfor a multinomial.",
    "start": "3713430",
    "end": "3719355"
  },
  {
    "text": "In that prior belief,\nyou say, before I look at actual dice\nrolls for my multinomial,",
    "start": "3719355",
    "end": "3725550"
  },
  {
    "text": "I'm going to imagine that I saw\na1 minus 1 outcomes of type 1,",
    "start": "3725550",
    "end": "3730680"
  },
  {
    "text": "a2 minus 1 outcomes\nof type 2, and am minus 1 outcomes of type m. A beta would just have\ntwo different terms here,",
    "start": "3730680",
    "end": "3737970"
  },
  {
    "text": "a number of 0's and\na number of 1's. But a multinomial extends\nthat to m different outcomes. And the Dirichlet\nextends the beta",
    "start": "3737970",
    "end": "3744450"
  },
  {
    "text": "to m different outcomes as well. It's the exact same thing\nas a beta but with a few more outcomes. Then if you actually\nobserve n1 outcomes of type",
    "start": "3744450",
    "end": "3753520"
  },
  {
    "text": "1, n2 outcomes of type 2. So here is your prior. You actually collect some data.",
    "start": "3753520",
    "end": "3758560"
  },
  {
    "text": "If you chose your prior\nexpressed as a Dirichlet, your posterior will\nalso be a Dirichlet. And particularly, it won't\njust be any Dirichlet.",
    "start": "3758560",
    "end": "3765400"
  },
  {
    "text": "We can know what Dirichlet\nSleigh it will be. And it's, imagine the\nsuccesses of type 1 plus actual success of type 1.",
    "start": "3765400",
    "end": "3772090"
  },
  {
    "text": "Imagined success of type 2\nplus actual success of type 2. And then MAP will choose\nfor every single parameter",
    "start": "3772090",
    "end": "3779170"
  },
  {
    "text": "pi in your multinomial,\nit will choose it to be this expression,\nwhich is the value which",
    "start": "3779170",
    "end": "3785380"
  },
  {
    "text": "maximizes the probability\ndistribution of the Dirichlet.",
    "start": "3785380",
    "end": "3790589"
  },
  {
    "text": "So I'm going to\nreally quickly note that most people choose a\nparticular Dirichlet, which",
    "start": "3790590",
    "end": "3798030"
  },
  {
    "text": "is that they imagine one\noutcome for every type. We'll talk about this a little\nbit more on Friday's class so I'll actually save\nthis for Friday's class.",
    "start": "3798030",
    "end": "3806789"
  },
  {
    "text": "I do want to take a moment\nthough, and get a little bit deeper into the math. Because the plot line\nso far of MAP is this.",
    "start": "3806790",
    "end": "3814920"
  },
  {
    "text": "OK, we have a new philosophy\nand this new philosophy seems elegant.",
    "start": "3814920",
    "end": "3820599"
  },
  {
    "text": "But so far, we've seen it\nwork in different cases but we don't have the ability\nto solve it ourselves.",
    "start": "3820600",
    "end": "3829130"
  },
  {
    "text": "So if I gave you a new case,\ncould you actually come up with an MAP estimate? What if you had to\ncome up with what",
    "start": "3829130",
    "end": "3835840"
  },
  {
    "text": "to do for updating your\nbelief in a lambda? So you guys ready for the slide\nthat puts together all the CS",
    "start": "3835840",
    "end": "3843710"
  },
  {
    "text": "109 concepts you've\nlearned so far? Not all of them,\nbut a lot of them. ",
    "start": "3843710",
    "end": "3850750"
  },
  {
    "text": "I would like to give\nyou a general way of doing maximum a\nposteriori yourselves.",
    "start": "3850750",
    "end": "3856390"
  },
  {
    "text": "So far we've got some\nintuition, but now is where we see the cold, hard math. At the end of the\nday, the key insight",
    "start": "3856390",
    "end": "3862847"
  },
  {
    "text": "is we want to choose\nthe parameters that are most likely given our data set. That is the opposite\ncondition of MLE.",
    "start": "3862847",
    "end": "3871150"
  },
  {
    "text": "Bayes' theorem tells\nus what we can do. We can say, if we want to choose\nthe argmax of our parameters",
    "start": "3871150",
    "end": "3878110"
  },
  {
    "text": "given the data, if we put\nthis into Bayes' theorem, it gives us that this should\nbe the likelihood of what's",
    "start": "3878110",
    "end": "3887130"
  },
  {
    "text": "on the right side\nof the conditional given what's on the left side. So Bayes' theorem flips\nthose two in the numerator.",
    "start": "3887130",
    "end": "3892440"
  },
  {
    "text": "Then it has the probability\nof this term on its own. That was your prior\nbefore your posterior.",
    "start": "3892440",
    "end": "3899650"
  },
  {
    "text": "And then you have this\nterm on the bottom, which is just how likely is the data\nnot conditioned on parameters.",
    "start": "3899650",
    "end": "3906079"
  },
  {
    "text": "Remember that in Bayes' theorem,\nwe call this term the prior. We call this the\nlikelihood term.",
    "start": "3906080",
    "end": "3911630"
  },
  {
    "text": "And we call this the posterior. Now in Bayes' theorem, what\ndo we call this bottom thing?",
    "start": "3911630",
    "end": "3918752"
  },
  {
    "text": "The normalization constant. Yeah, the\nnormalization constant. Because as theta changes values,\nthis doesn't change values.",
    "start": "3918752",
    "end": "3927040"
  },
  {
    "text": "If theta equals 1, this\nwill be the exact same as if theta equals 2.",
    "start": "3927040",
    "end": "3933190"
  },
  {
    "text": "It's a constant. And so if you say which value\nof theta maximizes this,",
    "start": "3933190",
    "end": "3938350"
  },
  {
    "text": "and that's just a big\nconstant, the argmax of a constant\ntimes a function is the same as the argmax\nof the function itself.",
    "start": "3938350",
    "end": "3944980"
  },
  {
    "text": "This whole normalization\nconstant goes away. One small thing. For notation, I am actually\ngoing to flip these two terms.",
    "start": "3944980",
    "end": "3953089"
  },
  {
    "text": "Even though we almost\nalways wrote Bayes' theorem with likelihood times\nprior because we",
    "start": "3953090",
    "end": "3961520"
  },
  {
    "text": "can change the order\nof the multiplication and it's going to make\nthings much easier. So I'm just going to\nput the g over here.",
    "start": "3961520",
    "end": "3966890"
  },
  {
    "text": "Is that OK? OK. I'm going to derive\nthings step by step.",
    "start": "3966890",
    "end": "3973172"
  },
  {
    "text": "Actually, I'm going to drive\nwhat's on the board step by step. The next step is\nbecause we always",
    "start": "3973172",
    "end": "3979190"
  },
  {
    "text": "assume our data\npoints are I.I.D., when we talk about the likely of\nour data given the parameters,",
    "start": "3979190",
    "end": "3984619"
  },
  {
    "text": "this actually becomes a\nproduct of the likelihood of each data point on its\nown given the parameters. We did this same step for MLE.",
    "start": "3984620",
    "end": "3991700"
  },
  {
    "text": "So this is a pretty\nreasonable step to take me from this\nline to this line.",
    "start": "3991700",
    "end": "3997549"
  },
  {
    "text": "The next step is we're going\nto use the fact that argmax",
    "start": "3997550",
    "end": "4002920"
  },
  {
    "text": "of a constant\ntimes an expression is the same as argmax\nof an expression itself. I can maybe convince\nyou of this.",
    "start": "4002920",
    "end": "4011049"
  },
  {
    "text": "If you want to find\nargmax of this expression, if instead I give you two\ntimes this function, whichever",
    "start": "4011050",
    "end": "4025470"
  },
  {
    "text": "argument maximizes\nthis is going to be the same argument that\nmaximizes 2 times that function.",
    "start": "4025470",
    "end": "4031720"
  },
  {
    "text": "So if you multiply any\nfunction by a constant, the argmax ignores\nthat constant.",
    "start": "4031720",
    "end": "4038040"
  },
  {
    "text": "So at this point, I have\na mathematical expression for saying if you\nwant to choose an MAP",
    "start": "4038040",
    "end": "4044780"
  },
  {
    "text": "estimate for your\nparameters, you should be using this expression. Now before when we did\nMLE, we had an expression",
    "start": "4044780",
    "end": "4053270"
  },
  {
    "text": "that looked like this. And we wanted to choose\nthe thetas that maximized. It instead of\nmaximizing it directly,",
    "start": "4053270",
    "end": "4058970"
  },
  {
    "text": "we chose the theta that\nmaximize the log of it. It was a really cool trick. And we're going to use\nthat trick one last time.",
    "start": "4058970",
    "end": "4064910"
  },
  {
    "text": "If you do the argmax\nnot of this expression but the log of this\nexpression, these two terms",
    "start": "4064910",
    "end": "4070580"
  },
  {
    "text": "will become the log of this\nterm plus the log of this term. The log of this term, we\nalready know what it is. It's just the sum of the logs\nof each of the likelihoods.",
    "start": "4070580",
    "end": "4078230"
  },
  {
    "text": "And then the log of\nthis term will just become a log of a prior. ",
    "start": "4078230",
    "end": "4085259"
  },
  {
    "text": "This is how people do MAP. If you wanted to use this other\nphilosophical way of choosing",
    "start": "4085260",
    "end": "4092130"
  },
  {
    "text": "your parameters, you end up\nwith a pretty similar algorithm. And that pretty\nsimilar algorithm",
    "start": "4092130",
    "end": "4097619"
  },
  {
    "text": "is going to say, choose\nthe parameters that maximize this expression. It has a term that just\nlooks a lot like MLE,",
    "start": "4097620",
    "end": "4104818"
  },
  {
    "text": "but you also have a\nterm for your belief that theta was the actual\nparameter before you",
    "start": "4104819",
    "end": "4110520"
  },
  {
    "text": "started any experimentation. So you're going to end up\nwith an estimated parameter. You're going to do that\nby using an argmax.",
    "start": "4110520",
    "end": "4117580"
  },
  {
    "text": "Choose the value\nof your parameter that maximizes this thing. It has the sum of\nlog likelihoods.",
    "start": "4117580",
    "end": "4124318"
  },
  {
    "text": "But it also has a log\nterm for a prior belief in your parameters.",
    "start": "4124319",
    "end": "4129960"
  },
  {
    "text": "So just to fill out\nthis slide from before, MLE says if you want\nto choose a theta MLE,",
    "start": "4129960",
    "end": "4137130"
  },
  {
    "text": "you're going to argmax over\nthis nice little expression. Maximum a posteriori,\nafter we did",
    "start": "4137130",
    "end": "4142528"
  },
  {
    "text": "all this different\nphilosophical stuff and we had all this\nlong conversation, look how similar this\nequation ended up being.",
    "start": "4142529",
    "end": "4148559"
  },
  {
    "text": "We're going to choose the thetas\nthat maximize this expression. And this expression has a term\nthat looks exactly like MLE.",
    "start": "4148560",
    "end": "4155250"
  },
  {
    "text": "It's just got one extra term. All this complicated\nexposition just to say,",
    "start": "4155250",
    "end": "4161710"
  },
  {
    "text": "hey, you want to have priors? That's fine. We're just going to have a\nterm in your log likelihood",
    "start": "4161710",
    "end": "4167189"
  },
  {
    "text": "function for the prior belief\nthat you had in your parameter. And it all comes\nfrom Bayes' theorem. We can derive it step by step.",
    "start": "4167189",
    "end": "4173009"
  },
  {
    "text": "But it leads to this\nvery, very nice result. Two different philosophies\nfor choosing parameters.",
    "start": "4173010",
    "end": "4178170"
  },
  {
    "text": "One requires you\nto have a prior. And it will just\nbecome a prior term. ",
    "start": "4178170",
    "end": "4184839"
  },
  {
    "text": "Yes? I don't understand what\ng of the [INAUDIBLE] is?",
    "start": "4184840",
    "end": "4190000"
  },
  {
    "text": "Yeah, sorry. g is just saying like, you had a\nprior belief in your parameter. Put the probability density\nof that prior belief here.",
    "start": "4190000",
    "end": "4197955"
  },
  {
    "text": "So if your prior\nbelief was a uniform, this could be a uniform. If your prior belief\nwas a beta, this could be a beta probability\ndensity function.",
    "start": "4197955",
    "end": "4204655"
  },
  {
    "text": "Let's actually put\nthat to the test. Oh, and before I\nmove on, though, I do want you guys to\nnotice that those two",
    "start": "4204655",
    "end": "4210610"
  },
  {
    "text": "terms are exactly the same. And so MLE and MAP are\nactually very, very similar. ",
    "start": "4210610",
    "end": "4218099"
  },
  {
    "text": "I want to-- you can do the\nBernoulli but I actually feel like this is going to\nmake a lot more sense--",
    "start": "4218100",
    "end": "4223890"
  },
  {
    "text": "sorry, when I do\none last expression. I want to skip to this example.",
    "start": "4223890",
    "end": "4230699"
  },
  {
    "text": "I want to do this example and\nI want to do it a little bit slowly. Because I feel like once\nyou can do this example,",
    "start": "4230700",
    "end": "4237030"
  },
  {
    "text": "then everything else\nwill make a lot of sense. Let's go back to this\nthing we solved before.",
    "start": "4237030",
    "end": "4242691"
  },
  {
    "text": "Before I said, I give you a\nwhole bunch of data points. I tell you that all\nof my data points",
    "start": "4242691",
    "end": "4249120"
  },
  {
    "text": "come from a Pareto distribution. That's something you hadn't\nseen before but it has a PDF. From now, you'll be able\nto do parameter estimation",
    "start": "4249120",
    "end": "4255750"
  },
  {
    "text": "whether or not you've seen\na random variable before or whether or not\nyou've seen a model. As long as somebody\ngives you a PDF or PMF,",
    "start": "4255750",
    "end": "4261240"
  },
  {
    "text": "you should be able to\ndo parameter estimation. The problem is going to\nlook exactly the same.",
    "start": "4261240",
    "end": "4267200"
  },
  {
    "text": "But I want to use\nthis new philosophy. And this new philosophy is going\nto be maximum a posteriori,",
    "start": "4267200",
    "end": "4273600"
  },
  {
    "text": "choose the most likely\nparameters given the data. So there's your\ndata and I want you to choose the most likely\nvalue of the parameters.",
    "start": "4273600",
    "end": "4279930"
  },
  {
    "text": "The one extra piece\nof information I now have to give you is\nmy belief in the parameters",
    "start": "4279930",
    "end": "4285300"
  },
  {
    "text": "before I see any information. This time, I didn't choose\na really fancy conjugate",
    "start": "4285300",
    "end": "4291180"
  },
  {
    "text": "prior because I want\nto show you that this works even if you don't use\na fancy conjugate prior. I chose a pretty silly prior.",
    "start": "4291180",
    "end": "4298170"
  },
  {
    "text": "I said, before I started\nany of this experimentation, I have a belief in my parameter.",
    "start": "4298170",
    "end": "4303480"
  },
  {
    "text": "I believe that it's normal. I believe that it's\nnormal around 2.0. I think I did my math using\n2, with variance equal to 3.",
    "start": "4303480",
    "end": "4311820"
  },
  {
    "text": "But anyways, I\nexpressed a prior. And just like the\nenvelope, sometimes a prior can really help you come\nup with a good, better",
    "start": "4311820",
    "end": "4318827"
  },
  {
    "text": "estimate of your parameters. So if you can have\na good prior, you can do better with less data.",
    "start": "4318828",
    "end": "4324210"
  },
  {
    "text": "Now let's see if\nwe can do the math. Because if you can do\nthe math, for this, that's the high water\nmark for understanding",
    "start": "4324210",
    "end": "4329550"
  },
  {
    "text": "maximum a posteriori.  Maximum a posteriori\nsays that there's",
    "start": "4329550",
    "end": "4335373"
  },
  {
    "text": "this thing-- we don't call it\nthe log likelihood function. Instead, we're going to\ncall it the MAP function. But it's just the same as\nthe log likelihood function",
    "start": "4335373",
    "end": "4342949"
  },
  {
    "text": "plus the log of your prior\nbelief in your parameter. So this we derived earlier.",
    "start": "4342950",
    "end": "4348668"
  },
  {
    "text": "I don't want to lose\nanybody on this. But this term comes\nfrom, we had figured out what was the log\nof the likelihood",
    "start": "4348668",
    "end": "4356570"
  },
  {
    "text": "function for the Pareto. And when we did this earlier in\nclass, we got this expression.",
    "start": "4356570",
    "end": "4361920"
  },
  {
    "text": "If you want to do\nmaximum a posteriori, we're going to\nchoose an alpha that maximizes not just this\nexpression, but that expression",
    "start": "4361920",
    "end": "4367770"
  },
  {
    "text": "plus a term for the prior. Somebody asked earlier,\nwhat is g of alpha?",
    "start": "4367770",
    "end": "4374640"
  },
  {
    "text": "In this problem, you should\nbe able to figure out what is g of alpha.",
    "start": "4374640",
    "end": "4380750"
  },
  {
    "text": "Just to be clear, I told\nyou that my prior belief is that alpha is a normal. So g is supposed to\nbe your prior belief",
    "start": "4380750",
    "end": "4388790"
  },
  {
    "text": "in a particular\nsetting of alpha. ",
    "start": "4388790",
    "end": "4396570"
  },
  {
    "text": "Yeah? Is this is normal distribution? Yeah. But CDF or PDF?",
    "start": "4396570",
    "end": "4402139"
  },
  {
    "text": "The PDF. It is exactly the PDF. This will be the PDF\nevaluated at alpha.",
    "start": "4402140",
    "end": "4408619"
  },
  {
    "text": "So remember, I think I solved\nthis using mean equals 2 and variance equals 3. So if you know mean equals\n2 and variance equals 3,",
    "start": "4408620",
    "end": "4416179"
  },
  {
    "text": "you can say, what is\nthe density at alpha. And the density at\nalpha would just",
    "start": "4416180",
    "end": "4421520"
  },
  {
    "text": "look like putting alpha\ninto the PDF expression. And as I said, I\nused 2 for mean.",
    "start": "4421520",
    "end": "4426960"
  },
  {
    "text": "So this is what that\nexpression looks like. I put in the mean. I put in the variance.",
    "start": "4426960",
    "end": "4432180"
  },
  {
    "text": "And I got this expression. Now, the other\nterms stay the same.",
    "start": "4432180",
    "end": "4438270"
  },
  {
    "text": "I do want to split this up. The log of this expression\nwill be the log of this term plus the log of that term.",
    "start": "4438270",
    "end": "4445170"
  },
  {
    "text": "And we split it up. The log of this term is going\nto be some crazy constant. But when you do the log of that\nterm, check out what happens.",
    "start": "4445170",
    "end": "4452970"
  },
  {
    "text": "You'll have log of\nsomething base e. Those things go away. And you'll just be left\nwith this expression.",
    "start": "4452970",
    "end": "4459780"
  },
  {
    "text": "So this expression is\nsaying, instead of just doing log likelihood, I'm\ngoing to do log likelihood plus a prior term.",
    "start": "4459780",
    "end": "4465770"
  },
  {
    "text": "When we work it\nout, we end up with, we're going to choose the alpha\nthat maximizes this thing.",
    "start": "4465770",
    "end": "4472265"
  },
  {
    "text": "Before we were\nchoosing the alpha that maximized just\nthe term on the right. Now we're choosing\nthe alpha that maximizes this whole term which\nincorporates a prior belief.",
    "start": "4472265",
    "end": "4481560"
  },
  {
    "text": "I will tell you that-- well, actually, if you want to\nchoose an alpha that maximizes this, the first thing\nyou're going to have to do",
    "start": "4481560",
    "end": "4487829"
  },
  {
    "text": "is figure out the derivative. We're back to argmax. All argmax functions\nthat we know about",
    "start": "4487830",
    "end": "4493230"
  },
  {
    "text": "require you to do a derivative. When we do this\nderivative, we already did the derivative of\nthe thing on the right.",
    "start": "4493230",
    "end": "4500010"
  },
  {
    "text": "That was n over alpha\nminus the sum over all the logs of your data points.",
    "start": "4500010",
    "end": "4505560"
  },
  {
    "text": "But what's the derivative\nof k with respect to alpha? 0.",
    "start": "4505560",
    "end": "4510590"
  },
  {
    "text": "And if you expanded\nthis term, you could figure out the derivative\nof this term with respect",
    "start": "4510590",
    "end": "4516050"
  },
  {
    "text": "to the different\nvalues of alpha. I actually believe I'm missing--",
    "start": "4516050",
    "end": "4521390"
  },
  {
    "text": "this whole thing I think should\nbe multiplied by 1 over 6. Sorry about that. ",
    "start": "4521390",
    "end": "4533040"
  },
  {
    "text": "Just a really quick check. Before we were choosing alphas\nthat maximized this term.",
    "start": "4533040",
    "end": "4539160"
  },
  {
    "text": "Now we have this prior belief. And the prior belief was\nthat the true parameter value was Gaussian centered around 2.",
    "start": "4539160",
    "end": "4547050"
  },
  {
    "text": "Notice what happens\nto the derivative. If you put 2 in for alpha,\nthis term will be 0.",
    "start": "4547050",
    "end": "4554110"
  },
  {
    "text": "It says, oh, my prior\nbelief was it was 2 and so I'm not going to\nbe changing my derivative.",
    "start": "4554110",
    "end": "4559210"
  },
  {
    "text": "But if you put a term\nthat's larger than 2 here, so you put in a 3. That'll be negative 6 plus 4.",
    "start": "4559210",
    "end": "4565510"
  },
  {
    "text": "It'll be a negative number. So if you put a\nterm that's larger than the mean of\nyour prior belief,",
    "start": "4565510",
    "end": "4570730"
  },
  {
    "text": "this gradient is going\nto pull you closer to 2. And if you put a term\nthat's smaller than 2,",
    "start": "4570730",
    "end": "4576130"
  },
  {
    "text": "it's going to pull you closer\nto 2 the other direction. And so it's this little\ngravity well around two",
    "start": "4576130",
    "end": "4582540"
  },
  {
    "text": "that's trying to prevent your\nparameter from getting too far away from where you originally\nbelieved it would be.",
    "start": "4582540",
    "end": "4588460"
  },
  {
    "text": "So anyways, once you\nhave this derivative, then you can do argmax. You could use gradient ascent.",
    "start": "4588460",
    "end": "4594820"
  },
  {
    "text": "All paths lead to\ngradient ascent here if you have a derivative. And just to drive that home, you\ncould have actually just done",
    "start": "4594820",
    "end": "4603190"
  },
  {
    "text": "your derivative calculation\nwith a slightly different starting point for how you\ncalculate your gradient.",
    "start": "4603190",
    "end": "4608800"
  },
  {
    "text": "But you could still use gradient\nascent or gradient descent. ",
    "start": "4608800",
    "end": "4614599"
  },
  {
    "text": "So to be clear, we\nare doing all of this",
    "start": "4614600",
    "end": "4622250"
  },
  {
    "text": "because we would like to build\nmachine learning algorithms. If you come back\non Friday, you will learn about our first machine\nlearning algorithm in CS 109.",
    "start": "4622250",
    "end": "4630080"
  },
  {
    "text": "We'll build an\nalgorithm that can solve a general important task. All of these\nalgorithms are going",
    "start": "4630080",
    "end": "4635809"
  },
  {
    "text": "to rely on the mathematics\nand the philosophy that you guys have worked so\nhard to build a foundation for.",
    "start": "4635810",
    "end": "4641180"
  },
  {
    "text": "We learned about\nunbiased estimates. They're not so useful. We talked about maximum\nlikelihood estimation.",
    "start": "4641180",
    "end": "4646250"
  },
  {
    "text": "Very nice math. Very easy to use. Very general. But with a small problem that\nis sometimes overfits data.",
    "start": "4646250",
    "end": "4652700"
  },
  {
    "text": "And now we did Bayesian\nestimation, called MAP, Maximum A Posteriori. Which basically\nis MLE, but it has",
    "start": "4652700",
    "end": "4659600"
  },
  {
    "text": "a term for a prior\nbelief on parameters. Now that you've worked so\nhard to build this foundation,",
    "start": "4659600",
    "end": "4664640"
  },
  {
    "text": "we can celebrate. We can have a fun time. Come back on Friday. We will celebrate. We will use this to\nactually solve Naive Bayes.",
    "start": "4664640",
    "end": "4670798"
  },
  {
    "text": "Then we will learn about\nlogistic regression. Then we will put it together\ninto a whole neural network. And it will be a party.",
    "start": "4670798",
    "end": "4676130"
  },
  {
    "text": "Thank you guys very much\nfor working so hard today. See you on Friday. ",
    "start": "4676130",
    "end": "4687000"
  }
]
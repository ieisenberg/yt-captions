[
  {
    "start": "0",
    "end": "5350"
  },
  {
    "text": "The plan for today is to\ntalk about evaluation. So instead of talking\nabout how to build",
    "start": "5350",
    "end": "14170"
  },
  {
    "text": "new types of generative\nmodels, we're going to discuss how to actually\nevaluate how good they are.",
    "start": "14170",
    "end": "19930"
  },
  {
    "text": "It's going to be-- it's kind of a challenging\ntopic where there's not really a consensus on what's\nthe right way to do it,",
    "start": "19930",
    "end": "27710"
  },
  {
    "text": "but we'll try to\ncover at least some of the ways that are out there. Nothing is perfect\nat this point,",
    "start": "27710",
    "end": "34150"
  },
  {
    "text": "but we'll cover some of it. So just as a brief recap, we've\ntalked a lot about modeling.",
    "start": "34150",
    "end": "42789"
  },
  {
    "text": "We talked about different\ntypes of probabilistic models",
    "start": "42790",
    "end": "49930"
  },
  {
    "text": "that you can use. You can work directly with\nthe probability density or the probability mass\nfunction, which case we've",
    "start": "49930",
    "end": "56170"
  },
  {
    "text": "seen autoregressive models,\nnormalizing flow models, latent variable models like\nthe variational autoencoder.",
    "start": "56170",
    "end": "61809"
  },
  {
    "text": "We've seen energy-based models. We've talked about probabilistic\nmodels or generative models",
    "start": "61810",
    "end": "69140"
  },
  {
    "text": "where, instead of representing\na probability density function, you represent directly\nthe sampling procedure.",
    "start": "69140",
    "end": "74549"
  },
  {
    "text": "So this is kind of generative\nadversarial networks would be one example. And then we've talked\nabout score-based models",
    "start": "74550",
    "end": "80869"
  },
  {
    "text": "where instead of\nrepresenting the density, you represent the score, which\nis just like the gradient",
    "start": "80870",
    "end": "86090"
  },
  {
    "text": "essentially. And that's yet\nanother model family that you can use\nto model your data.",
    "start": "86090",
    "end": "93409"
  },
  {
    "text": "And we've talked about a number\nof different training objectives that you can use to\nfit a model to data.",
    "start": "93410",
    "end": "100380"
  },
  {
    "text": "We've talked about\nKL divergence, which is the same as-- minimizing KL divergence is the\nsame as maximizing likelihood,",
    "start": "100380",
    "end": "107010"
  },
  {
    "text": "which is a very natural\nkind of objective to use whenever the likelihood\nis accessible directly.",
    "start": "107010",
    "end": "112259"
  },
  {
    "text": "So if you're modeling directly\nthe probability density function, probability\nmass function this is a very reasonable\nkind of objective to use.",
    "start": "112260",
    "end": "119280"
  },
  {
    "text": "And so autoregressive\nmodels, flow models, the ELBO in variational\nautoencoders is also kind of like\nan approximation",
    "start": "119280",
    "end": "125780"
  },
  {
    "text": "to the maximum\nlikelihood objective. And to some extent,\ncontrastive divergence",
    "start": "125780",
    "end": "132080"
  },
  {
    "text": "is also an approximation too,\nor it's exact to the extent that you can get perfect\nsamples from the model.",
    "start": "132080",
    "end": "140120"
  },
  {
    "text": "We've seen f-divergences\nand two sample tests, which are very\nnatural in the context",
    "start": "140120",
    "end": "145519"
  },
  {
    "text": "of generative\nadversarial networks. If the only thing\nyou have access to our samples from\nthe distributions,",
    "start": "145520",
    "end": "150920"
  },
  {
    "text": "then this is a reasonable way\nof training a generative model. And then we've seen\nFisher divergence,",
    "start": "150920",
    "end": "157560"
  },
  {
    "text": "which is essentially the\nsame as score matching, which makes a lot of sense whenever\nyou have access to scores",
    "start": "157560",
    "end": "163280"
  },
  {
    "text": "or whenever you're working\nwith energy-based models because it allows you to bypass\nthe normalizing constant.",
    "start": "163280",
    "end": "169970"
  },
  {
    "text": "And we've seen noise\ncontrastive estimation, which works for energy-based models.",
    "start": "169970",
    "end": "175440"
  },
  {
    "text": "And the question\nis, at this point, there is a lot of\ndifferent pieces,",
    "start": "175440",
    "end": "182090"
  },
  {
    "text": "a lot of different\ningredients that you can use. There is many different\nkinds of model families that you can pick from.",
    "start": "182090",
    "end": "187670"
  },
  {
    "text": "There's different kinds\nof training objectives. And a natural question\nis, how do you pick which one you should use\nfor a particular data set?",
    "start": "187670",
    "end": "195470"
  },
  {
    "text": "And eventually, this boils\ndown to the question of, which model is better? Should you train an\nautoregressive model",
    "start": "195470",
    "end": "202788"
  },
  {
    "text": "on your data? Should you train a flow\nModel So you train a GAN? And in order to\nanswer that question, you need to be able to say\nmodel A is better than model B,",
    "start": "202788",
    "end": "211430"
  },
  {
    "text": "essentially. And that requires you to be\nable to evaluate, basically, the quality of a\ngenerative model.",
    "start": "211430",
    "end": "218900"
  },
  {
    "text": "And that's really,\nreally important because it allows you to\nmake comparisons and pick",
    "start": "218900",
    "end": "227150"
  },
  {
    "text": "a model that is most\nsuitable for your problem. And it's kind of like if we\nthink of it from a research",
    "start": "227150",
    "end": "233720"
  },
  {
    "text": "perspective, it's kind of like\na super important ingredient. We always want to make progress.",
    "start": "233720",
    "end": "240270"
  },
  {
    "text": "We want to build better models. We want to get better and\nbetter, but in order to do that, we need to be able to\nmeasure how good a model is.",
    "start": "240270",
    "end": "249780"
  },
  {
    "text": "And so we live in a world where\nit's pretty easy to just-- people make their\nmodels open source.",
    "start": "249780",
    "end": "256380"
  },
  {
    "text": "You can clone a GitHub repo. You can improve. You can make a change to a model\nor to a training objective.",
    "start": "256380",
    "end": "262470"
  },
  {
    "text": "You get something new out. It's very important to be\nable to quantify your proposed solution better than\nsomething that existed before.",
    "start": "262470",
    "end": "270580"
  },
  {
    "text": "And again, that\nrequires you to be able to evaluate different\nkinds of generative models.",
    "start": "270580",
    "end": "276690"
  },
  {
    "text": "And unlike the case of\ndiscriminative models, typical machine learning models\nevaluating generative models",
    "start": "276690",
    "end": "284190"
  },
  {
    "text": "is unfortunately, pretty hard. In the case of a typical\nmachine learning model that you would use for\na discriminative task.",
    "start": "284190",
    "end": "290820"
  },
  {
    "text": "Let's say you're training\na classifier to label data, to map inputs to\nlabels, so a pretty kind",
    "start": "290820",
    "end": "298290"
  },
  {
    "text": "of low-dimensional simple\nkind of output space. That's a setting that is\npretty well understood",
    "start": "298290",
    "end": "303580"
  },
  {
    "text": "how to measure progress. Somebody comes up with a new\narchitecture for, let's say,",
    "start": "303580",
    "end": "308770"
  },
  {
    "text": "computer vision tasks,\nyou can train the models. And you can check what kind\nof losses they achieve.",
    "start": "308770",
    "end": "314320"
  },
  {
    "text": "You can use it on-- you're going to define some\nkind of loss that quantifies",
    "start": "314320",
    "end": "319990"
  },
  {
    "text": "what is it that you care about. Is it top-one accuracy, top-five\naccuracy, or whatever decision",
    "start": "319990",
    "end": "326380"
  },
  {
    "text": "problem you intend to use\nthe predictions that you get from the model in.",
    "start": "326380",
    "end": "331690"
  },
  {
    "text": "You can specify a loss function,\nand then you can try to, given two models, you\ncan evaluate the losses",
    "start": "331690",
    "end": "337960"
  },
  {
    "text": "that they achieve on\nheld-out unseen data. And that gives you\na pretty good handle",
    "start": "337960",
    "end": "347517"
  },
  {
    "text": "on the performance of the model. That tells you essentially,\nif you were to at test time,",
    "start": "347517",
    "end": "353272"
  },
  {
    "text": "when you deploy\nthe model, you work to fit in data that kind\nof looks like the one that you've been training on. This looks like the one that\nyou have in the test set,",
    "start": "353272",
    "end": "360610"
  },
  {
    "text": "and that's the performance\nthat you would expect. And so that allows you to\ncompare different models",
    "start": "360610",
    "end": "366610"
  },
  {
    "text": "and decide which one is better. And unfortunately,\nthings are not so easy for a generative model.",
    "start": "366610",
    "end": "374800"
  },
  {
    "text": "It's not clear what is the task. Essentially that's\nthe main challenge.",
    "start": "374800",
    "end": "379870"
  },
  {
    "text": "What is it that we care about? Why are you training\na generative model? And there is many different\noptions and many different,",
    "start": "379870",
    "end": "388840"
  },
  {
    "text": "and all of them are\nmore or less valid. Perhaps you're training\na generative model because you care about\ndensity estimation,",
    "start": "388840",
    "end": "395740"
  },
  {
    "text": "you care about\nevaluating probabilities of, say, images or sentences.",
    "start": "395740",
    "end": "402400"
  },
  {
    "text": "Maybe you care\nabout compression. Maybe you care about\ngenerating samples. At the end of the day, you're\ntraining a diffusion model",
    "start": "402400",
    "end": "410590"
  },
  {
    "text": "over images and\nwhat you care about is being able to generate\npretty outputs that",
    "start": "410590",
    "end": "415630"
  },
  {
    "text": "are aesthetically pleasing. Or maybe you're\nreally just trying",
    "start": "415630",
    "end": "420819"
  },
  {
    "text": "to do representation learning\nor unsupervised learning.",
    "start": "420820",
    "end": "426107"
  },
  {
    "text": "At the end of the\nday, you have access to a lot of\nunlabeled data, maybe large collections\nof images or text",
    "start": "426107",
    "end": "432970"
  },
  {
    "text": "that you've scraped\nfrom the internet. You'd like your model\nto learn something about the structure\nof this data.",
    "start": "432970",
    "end": "438290"
  },
  {
    "text": "And you'd like to be able\nto get representations out",
    "start": "438290",
    "end": "443470"
  },
  {
    "text": "of the models that then you\ncan use to improve performance on downstream tasks. Instead of working\ndirectly on pixels,",
    "start": "443470",
    "end": "450590"
  },
  {
    "text": "maybe you can work on\nrepresentations obtained by a generative model, and then\nyou can get better performance.",
    "start": "450590",
    "end": "456460"
  },
  {
    "text": "You can reduce the\namount of labeled data that you need to train a model. Or maybe you're thinking\nabout many different tasks",
    "start": "456460",
    "end": "465370"
  },
  {
    "text": "that you need to be able\nto use your model for. Perhaps you're trying to train\na single good model over images",
    "start": "465370",
    "end": "476710"
  },
  {
    "text": "that then you can\nuse to do compressed sensing, semi-supervised\nlearning, image translation.",
    "start": "476710",
    "end": "481960"
  },
  {
    "text": "Or if you're thinking\nabout language models, again, you are trying to\nfind a single model that",
    "start": "481960",
    "end": "489220"
  },
  {
    "text": "has been trained\non a lot of text, a lot of collected\nfrom the internet. And what you really\ncare about is",
    "start": "489220",
    "end": "494650"
  },
  {
    "text": "being able to leverage all the\nknowledge that has been encoded in this big language\nmodel, an LLM",
    "start": "494650",
    "end": "502160"
  },
  {
    "text": "and then what you\nreally care about is being able to\nprompt the model",
    "start": "502160",
    "end": "508240"
  },
  {
    "text": "to solve tasks using a\nsmall number of instructions or examples.",
    "start": "508240",
    "end": "514270"
  },
  {
    "text": "So lots of different\nthings you could do. And these different things will\nlead, and for each one of them,",
    "start": "514270",
    "end": "522269"
  },
  {
    "text": "or for some of them, at least,\nthere is many different metrics that you could use to--",
    "start": "522270",
    "end": "528480"
  },
  {
    "text": "even if you pick\none of these tasks,",
    "start": "528480",
    "end": "533820"
  },
  {
    "text": "it's not entirely obvious\nhow you measure performance on each one of them.",
    "start": "533820",
    "end": "539610"
  },
  {
    "text": "The simplest one is\nprobability density estimation. If you really care about\ndensity estimation,",
    "start": "539610",
    "end": "545970"
  },
  {
    "text": "if you really care about being\nable to accurately quantify probabilities using\na generative model,",
    "start": "545970",
    "end": "552150"
  },
  {
    "text": "then likelihood is a pretty\ngood metric for that. So what you can do is, you can\nsplit your data into train,",
    "start": "552150",
    "end": "561240"
  },
  {
    "text": "validation, and test. You can fit your model\nusing a training set.",
    "start": "561240",
    "end": "566339"
  },
  {
    "text": "Maybe you pick hyperparameters\non the validation set, and then you can\nevaluate the performance",
    "start": "566340",
    "end": "572520"
  },
  {
    "text": "on the test set, where\nthe performance is just the average log likelihood\nthat the model assigns",
    "start": "572520",
    "end": "578620"
  },
  {
    "text": "to on test data, which is\na pretty good approximation to the kind of\naverage log likelihood",
    "start": "578620",
    "end": "587530"
  },
  {
    "text": "that you would expect the model\nto assign to samples drawn from this data distribution.",
    "start": "587530",
    "end": "593800"
  },
  {
    "text": "And essentially, this is the\nsame thing as compression. We've seen that\nmaximizing likelihood",
    "start": "593800",
    "end": "601000"
  },
  {
    "text": "is the same as minimizing\nKL divergence, which is the same thing as trying\nto compress data, essentially.",
    "start": "601000",
    "end": "609459"
  },
  {
    "text": "So at the end of the\nday, what we're saying, is that if you use\nthat as a metric,",
    "start": "609460",
    "end": "616690"
  },
  {
    "text": "you are comparing models\nbased on how well they compress the data.",
    "start": "616690",
    "end": "622930"
  },
  {
    "text": "And to see that,\nturns out that there",
    "start": "622930",
    "end": "629589"
  },
  {
    "text": "is a way to take a\nprobabilistic model and map it to a compression\nscheme, where what you would do",
    "start": "629590",
    "end": "635380"
  },
  {
    "text": "is, you would\nencode a data point x to some string that can be\ndecoded back in a unique way.",
    "start": "635380",
    "end": "644860"
  },
  {
    "text": "And the length of the\nstring, basically, depends on the probability\nof the data point. So if you have data points\nthat are very likely,",
    "start": "644860",
    "end": "652660"
  },
  {
    "text": "they are very frequent, then\nyou want to assign short codes. And if they are very\ninfrequent, then",
    "start": "652660",
    "end": "658879"
  },
  {
    "text": "you can afford to assign very\nlong codes if you're are not going to see them very often.",
    "start": "658880",
    "end": "664070"
  },
  {
    "text": "And that's a way to\ncompress data using a code.",
    "start": "664070",
    "end": "672320"
  },
  {
    "text": "And it goes back to the\nintuition that we had before. If you think about\nthe Morse code, it's based on this principle.",
    "start": "672320",
    "end": "679070"
  },
  {
    "text": "So if you have vowels like\ne and a, they are common, so you want to\nassign a short code.",
    "start": "679070",
    "end": "685100"
  },
  {
    "text": "And then if you have letters\nthat are less frequent, then you want to assign\na long code to that.",
    "start": "685100",
    "end": "690450"
  },
  {
    "text": "And when if you train a\ngenerative model based on maximum likelihood,\nyou're basically trying to do as well as\nyou can at compression.",
    "start": "690450",
    "end": "697230"
  },
  {
    "text": "And if you compare models\nbased on likelihood, you are comparing how\nwell they compress data, which might or might\nnot be what you care about.",
    "start": "697230",
    "end": "705740"
  },
  {
    "text": "And to see that,\nit's pretty clear that if the length of the code\nthat you assigned to a data",
    "start": "705740",
    "end": "712519"
  },
  {
    "text": "point x, basically,\nis proportional to-- it is very close to\nthe log of 1 over p,",
    "start": "712520",
    "end": "719470"
  },
  {
    "text": "then you can see that the\naverage code length that you get is going to be this\nquantity, which is roughly--",
    "start": "719470",
    "end": "726550"
  },
  {
    "text": "if you get rid of the fact that\nthe lengths have to be integers,",
    "start": "726550",
    "end": "734050"
  },
  {
    "text": "if you approximate\nit, it's roughly equal to the negative\nlog likelihood.",
    "start": "734050",
    "end": "739130"
  },
  {
    "text": "So if you try to\nmaximize the likelihood, you're minimizing the average\nlength of the code that you get.",
    "start": "739130",
    "end": "746120"
  },
  {
    "text": "So you maximize the compression\nthat you can achieve. And in practice, if you use this\nkind of Shannon or Huffman codes",
    "start": "746120",
    "end": "757030"
  },
  {
    "text": "that you might have seen\nbefore, it's actually expensive, and it's not tractable\nto actually build",
    "start": "757030",
    "end": "763180"
  },
  {
    "text": "one of these codes. But there are ways to get\npractical compression schemes. So to the extent that you\ncan get a good likelihood,",
    "start": "763180",
    "end": "770560"
  },
  {
    "text": "there is an actual\ncomputational efficient way of constructing\ncompression schemes that",
    "start": "770560",
    "end": "776200"
  },
  {
    "text": "will perform well,\nas long as you get good likelihoods on the data. There's something called\narithmetic coding, for example,",
    "start": "776200",
    "end": "781850"
  },
  {
    "text": "that you can actually use. So if you are able to train\na deep generative model that gets you good\nlikelihoods, then you",
    "start": "781850",
    "end": "787089"
  },
  {
    "text": "can potentially compress\nyour data very well. ",
    "start": "787090",
    "end": "793649"
  },
  {
    "text": "And actually, if\nyou've read papers on language models, the GPTs\nand those kind of things,",
    "start": "793650",
    "end": "802190"
  },
  {
    "text": "that's essentially\nthe same metric that they use when they\ncompare language models.",
    "start": "802190",
    "end": "807320"
  },
  {
    "text": "They call it perplexity\nin that setting, but it's essentially like\na scaled version of the log",
    "start": "807320",
    "end": "814520"
  },
  {
    "text": "likelihood.  Now, the question\nis, why compression?",
    "start": "814520",
    "end": "821884"
  },
  {
    "text": "Is that a reasonable\nthing to do? Is that what we\nreally care about? It's reasonable in the\nsense that, as we've",
    "start": "821885",
    "end": "830850"
  },
  {
    "text": "discussed, if you want to\nachieve good compression rates, then you need to, basically,\nbe able to identify patterns",
    "start": "830850",
    "end": "837540"
  },
  {
    "text": "in the data. The only way you can\nachieve good compression is by identifying redundancy,\nidentifying patterns,",
    "start": "837540",
    "end": "844920"
  },
  {
    "text": "identifying structure\nin the data. So it's a good\nlearning objective, and we know that if you can\nget the KL divergence to zero,",
    "start": "844920",
    "end": "851100"
  },
  {
    "text": "then it means that\nyou've perfectly match the data distribution.",
    "start": "851100",
    "end": "856260"
  },
  {
    "text": "And this makes sense. If you're trying to build, train\na generative model to capture",
    "start": "856260",
    "end": "862020"
  },
  {
    "text": "knowledge about the world,\nthis is a reasonable objective.",
    "start": "862020",
    "end": "867270"
  },
  {
    "text": "We're training the model\nto compress the data and by doing so, we're\nlearning something about how the world\nworks essentially",
    "start": "867270",
    "end": "873089"
  },
  {
    "text": "because that's the only way to\nachieve compression schemes. So the intuition could\nbe something like this.",
    "start": "873090",
    "end": "878440"
  },
  {
    "text": "And if you think\nabout physical laws, like Newton's law or\nsomething like that, you can think of it as one\nway of compressing data.",
    "start": "878440",
    "end": "885810"
  },
  {
    "text": "If you notice there is\nsome kind of relationship between variables\nyou care about, F equals ma, then knowing\nthat sort of relationship",
    "start": "885810",
    "end": "894810"
  },
  {
    "text": "allows you to compress the data. Let's say if you have a sequence\nof accelerations and forces,",
    "start": "894810",
    "end": "900630"
  },
  {
    "text": "you don't have to\nstore both of them. You can store just\nthe accelerations, and you can recover the\nforces through the equation,",
    "start": "900630",
    "end": "906820"
  },
  {
    "text": "for example. So any kind of pattern or\nstructure in the data like this,",
    "start": "906820",
    "end": "912990"
  },
  {
    "text": "allows you to achieve\nbetter compression rates. And so by training\na model to compress,",
    "start": "912990",
    "end": "918279"
  },
  {
    "text": "you might be able to discover\nsome interesting structure in the data, including maybe,\nknowledge about physical laws",
    "start": "918280",
    "end": "925690"
  },
  {
    "text": "and things like that. And that's kind of like\nthere's actually something called the Hutter prize.",
    "start": "925690",
    "end": "932610"
  },
  {
    "text": "It's actually there's a\nhalf a million dollars for developing a\ngood compression",
    "start": "932610",
    "end": "939090"
  },
  {
    "text": "scheme for Wikipedia. And the quote from\nthe prize website is, \"being able to compress\nwell is closely related",
    "start": "939090",
    "end": "948600"
  },
  {
    "text": "to intelligence. While intelligence is\na slippery concept, file sizes are hard\nnumbers, Wikipedia",
    "start": "948600",
    "end": "955560"
  },
  {
    "text": "is an extensive snapshot\nof human knowledge. If you can compress Wikipedia\nbetter than the predecessors,",
    "start": "955560",
    "end": "962010"
  },
  {
    "text": "your decompressor is likely\ngoing to be smarter, basically.\" And the whole idea\nbehind this prize",
    "start": "962010",
    "end": "968430"
  },
  {
    "text": "is to basically\nencourage the development of intelligent compressors as\na path towards achieving AGI.",
    "start": "968430",
    "end": "974670"
  },
  {
    "text": "So the hypothesis here\nis that if you can really compress Wikipedia\nvery well, then",
    "start": "974670",
    "end": "980759"
  },
  {
    "text": "you must achieve a very\nhigh level of intelligence. And indeed, you can\nactually compare",
    "start": "980760",
    "end": "989000"
  },
  {
    "text": "how well humans do\nat this, how good are humans at compressing text.",
    "start": "989000",
    "end": "995449"
  },
  {
    "text": "There's actually an\nexperiment that Shannon did, many years ago, and\nhe was very interested",
    "start": "995450",
    "end": "1001210"
  },
  {
    "text": "in this kind of\ntopic of compression. And he invented the whole\nfield of information theory.",
    "start": "1001210",
    "end": "1007030"
  },
  {
    "text": "And he actually did\nexperiments checking how good-- humans have a lot\nof knowledge, a lot of context.",
    "start": "1007030",
    "end": "1013540"
  },
  {
    "text": "If you see a string\nof text, you're probably going to be pretty good\nat predicting what comes next.",
    "start": "1013540",
    "end": "1018680"
  },
  {
    "text": "And so he actually\ndid an experiment with getting human\nsubjects involved",
    "start": "1018680",
    "end": "1024400"
  },
  {
    "text": "and trying to see\nhow good are people, basically, at predicting the\nnext character in English text.",
    "start": "1024400",
    "end": "1030550"
  },
  {
    "text": "And what he found\nis that they achieve a compression rate of about\n1.2, 1.3 bits per character.",
    "start": "1030550",
    "end": "1037899"
  },
  {
    "text": "So there are 27 characters\nor something like that.",
    "start": "1037900",
    "end": "1044359"
  },
  {
    "text": "So there's a lot of uncertainty. If you didn't know\nanything about it, you would need maybe four or\nfive bits to encode a character.",
    "start": "1044359",
    "end": "1053980"
  },
  {
    "text": "But people are able to do\nit with only one or two. So there's not too\nmuch uncertainty. When you predict the next\ncharacter in English text,",
    "start": "1053980",
    "end": "1061539"
  },
  {
    "text": "people are pretty good. There's kind of only if\nyou think about one bit of information, it\nencodes two possibilities.",
    "start": "1061540",
    "end": "1068990"
  },
  {
    "text": "And so that's the typical\nuncertainty that people have when they predict the\nnext character in text.",
    "start": "1068990",
    "end": "1074960"
  },
  {
    "text": "So kind of like one bit\nwould correspond to, OK, there's two\npossibilities, and I'm uncertain about them,\nabout which one it is.",
    "start": "1074960",
    "end": "1083540"
  },
  {
    "text": "And you might ask, how well\ndo large language models, neural network?",
    "start": "1083540",
    "end": "1088910"
  },
  {
    "text": "They actually do better\nthan humans already. And you can get something like\npeople trained on Wikipedia",
    "start": "1088910",
    "end": "1094340"
  },
  {
    "text": "and that Hutter price\nkind of data set, and they were able\nto get something like 0.94 bits per character.",
    "start": "1094340",
    "end": "1100400"
  },
  {
    "text": "So even better than humans. And again, this is a reasonable\nobjective, a reasonable way",
    "start": "1100400",
    "end": "1107700"
  },
  {
    "text": "of comparing models. That's what people use for\ntraining large language models. They train them at\nmaximum likelihood.",
    "start": "1107700",
    "end": "1113340"
  },
  {
    "text": "It makes sense to compare\nthem based on perplexity to some extent or\ntry to forecast how good the perplexity is going\nto be if you were to increase",
    "start": "1113340",
    "end": "1120330"
  },
  {
    "text": "data or you were to increase\ncompute, scaling laws kind of things. But there are issues\nwith compression.",
    "start": "1120330",
    "end": "1126990"
  },
  {
    "text": "And the main issue\nis that it's probably not the task we actually\ncare about or not",
    "start": "1126990",
    "end": "1132390"
  },
  {
    "text": "entirely reflective\nof what we care about. And the issue is\nthat, basically, not all bits of information\nare created equal.",
    "start": "1132390",
    "end": "1138610"
  },
  {
    "text": "And so if you think\nabout compression, a bit that is encoding a life\nor death kind of situation",
    "start": "1138610",
    "end": "1147090"
  },
  {
    "text": "is worth exactly the\nsame as something maybe less important, like, is it\ngoing to rain or not tomorrow?",
    "start": "1147090",
    "end": "1154340"
  },
  {
    "text": "And so compressing one\nor compressing the other, is the same from the\nperspective of KL",
    "start": "1154340",
    "end": "1161419"
  },
  {
    "text": "divergence or\nmaximum likelihood, but obviously, it\ndoesn't reflect the way we're going to use the\ninformation in downstream tasks.",
    "start": "1161420",
    "end": "1169800"
  },
  {
    "text": "So there are some\nserious limitations of what you can say by\njust comparing models",
    "start": "1169800",
    "end": "1175700"
  },
  {
    "text": "in terms of compression. Think about image\ndata sets, same thing.",
    "start": "1175700",
    "end": "1180860"
  },
  {
    "text": "There is certain\npieces of information that are much less\nimportant to us.",
    "start": "1180860",
    "end": "1185990"
  },
  {
    "text": "You could think about a\nslight change in color for a particular pixel. It doesn't matter too much.",
    "start": "1185990",
    "end": "1191299"
  },
  {
    "text": "While there's information about\nwhat's the label of the image.",
    "start": "1191300",
    "end": "1198440"
  },
  {
    "text": "That is much more important. But from this perspective,\nit is all the same. Basically, it doesn't matter.",
    "start": "1198440",
    "end": "1204990"
  },
  {
    "text": "So that's main limitation\nof density estimation or compression. ",
    "start": "1204990",
    "end": "1212429"
  },
  {
    "text": "And yeah, we'll talk\nabout this more later. The other thing to\nkeep in mind, is",
    "start": "1212430",
    "end": "1218460"
  },
  {
    "text": "that compression\nor likelihood is a reasonable metric for models\nwhich have tractable likelihood.",
    "start": "1218460",
    "end": "1226529"
  },
  {
    "text": "But there is a bunch of models\nthat don't even have it. So if you're working with\nVAEs or GANs or EBMs,",
    "start": "1226530",
    "end": "1233400"
  },
  {
    "text": "it's not even obvious how you\nwould compare models in terms of likelihood or compression.",
    "start": "1233400",
    "end": "1239500"
  },
  {
    "text": "For VAEs, at least\nyou can compare them based on ELBO values, which we\nknow is kind of like a lower",
    "start": "1239500",
    "end": "1245220"
  },
  {
    "text": "bound on likelihood. So it's a lower bound on how\nwell they would compress data.",
    "start": "1245220",
    "end": "1251260"
  },
  {
    "text": "But if you have GANs,\nfor example, how would you compare, let's\nsay, the likelihood",
    "start": "1251260",
    "end": "1256860"
  },
  {
    "text": "that you achieve\nwith a GAN to the one that you've achieved with an\nautoregressive model or a flow",
    "start": "1256860",
    "end": "1262440"
  },
  {
    "text": "model. You can't even compare\nthem because there is no way to get likelihoods\nout of a Generative Adversarial",
    "start": "1262440",
    "end": "1269160"
  },
  {
    "text": "Network. I remember when we are kind\nof learning the GAN part,",
    "start": "1269160",
    "end": "1274440"
  },
  {
    "text": "you mentioned kind of one\nbig motivations about it is it's a lot likely to\nbe [INAUDIBLE],, right.",
    "start": "1274440",
    "end": "1281460"
  },
  {
    "text": "So I was just trying to\nunderstand your why--",
    "start": "1281460",
    "end": "1287850"
  },
  {
    "text": "so there's a evaluation\nmetrics where it really depend how we're looking\nat the downstream task?",
    "start": "1287850",
    "end": "1294600"
  },
  {
    "text": "So it depends what\nyou care about GANs. It's a great question. I mean, do you really\ncare about compression? Maybe not, but if you wanted\nto compare the compression",
    "start": "1294600",
    "end": "1301559"
  },
  {
    "text": "capabilities of a GAN\nto something else, you would not even\nbe able to do that.",
    "start": "1301560",
    "end": "1306847"
  },
  {
    "text": "And we'll see that maybe\nthat's not what you care about. Maybe you care about\nsample quality. And we'll see there are other\nevaluation metrics that maybe",
    "start": "1306847",
    "end": "1314559"
  },
  {
    "text": "make more sense where\nyou can say, OK, is a GAN better than an\nautoregressive model trained on the same data set.",
    "start": "1314560",
    "end": "1319929"
  },
  {
    "text": "But if you cared about\ndensity estimation, then you need to at least be able\nto evaluate likelihoods,",
    "start": "1319930",
    "end": "1326890"
  },
  {
    "text": "and it's not something you\ncan directly do with a GAN. And so in general, it's\na pretty tricky problem",
    "start": "1326890",
    "end": "1336160"
  },
  {
    "text": "to figure out if you have a\ngenerative adversarial network, and you have, let's\nsay, I have an image,",
    "start": "1336160",
    "end": "1342097"
  },
  {
    "text": "and you want to know\nwhat is the probability that the model generated\nthis particular image is",
    "start": "1342097",
    "end": "1347140"
  },
  {
    "text": "pretty difficult to do. Even if you can generate a\nlot of samples from the GAN,",
    "start": "1347140",
    "end": "1354042"
  },
  {
    "text": "it's actually pretty\ntricky to figure out what is the underlying\nprobability density function.",
    "start": "1354042",
    "end": "1359470"
  },
  {
    "text": "And typically, you have\nto use approximations. And one that is pretty common\nis called a kernel density",
    "start": "1359470",
    "end": "1368409"
  },
  {
    "text": "estimation. That allows you to basically\nget an approximation of what is the underlying probability\ndensity function given",
    "start": "1368410",
    "end": "1375789"
  },
  {
    "text": "only samples from the model. So it would look\nsomething like this. Suppose that you have a\ngenerative model for which you",
    "start": "1375790",
    "end": "1383720"
  },
  {
    "text": "are not able to evaluate\nlikelihoods directly, but you're able\nto sample from it. Then you can draw\na bunch of samples.",
    "start": "1383720",
    "end": "1390950"
  },
  {
    "text": "Here, I'm showing six of them. And just for simplicity,\nlet's say that the samples",
    "start": "1390950",
    "end": "1396200"
  },
  {
    "text": "are just scalars. So you generate six of them,\nand the first one is minus 2.1,",
    "start": "1396200",
    "end": "1401660"
  },
  {
    "text": "minus 1.3, and so forth. And these are\nrepresentative of what",
    "start": "1401660",
    "end": "1407179"
  },
  {
    "text": "is the underlying distribution\nthat generated this data.",
    "start": "1407180",
    "end": "1412680"
  },
  {
    "text": "And the question is, what can\nwe say about probabilities of other data points? So given that you have these\nsix samples from the model, what",
    "start": "1412680",
    "end": "1422000"
  },
  {
    "text": "is the probability, let's\nsay, that we should assign it to the point minus 0.5?",
    "start": "1422000",
    "end": "1429630"
  },
  {
    "text": "And one answer could be, well,\nthe model never generated 0.5,",
    "start": "1429630",
    "end": "1435900"
  },
  {
    "text": "or 0.5 is not among the six\nsamples that we have access to.",
    "start": "1435900",
    "end": "1440980"
  },
  {
    "text": "So we could say, since\nit doesn't belong to this set of samples, maybe\nwe should set the probability to zero, which is probably\nnot a great answer",
    "start": "1440980",
    "end": "1449910"
  },
  {
    "text": "because we only\nhave six samples. It could be just\ndue to chance we didn't see that particular data\npoint in our set of samples.",
    "start": "1449910",
    "end": "1458880"
  },
  {
    "text": "So a better way of doing things\nis to do some kind of binning, build some kind of histogram\nover the possible values",
    "start": "1458880",
    "end": "1466050"
  },
  {
    "text": "that these samples can take. For example, you can\nbuild a histogram, let's say, where we\nhave bins with two here.",
    "start": "1466050",
    "end": "1475320"
  },
  {
    "text": "And then you basically count\nhow frequently the data points land in the different bins.",
    "start": "1475320",
    "end": "1482700"
  },
  {
    "text": "And then you make sure that\nthe object that you get",
    "start": "1482700",
    "end": "1488970"
  },
  {
    "text": "is properly normalized, so\nthat the area under the curve is actually one.",
    "start": "1488970",
    "end": "1495050"
  },
  {
    "text": "So because we had a bunch of-- we have two data two data points\nlanding between minus 2 and 2,",
    "start": "1495050",
    "end": "1501760"
  },
  {
    "text": "then we have a\nlittle bit higher. We assign a little bit higher\nprobability to that region,",
    "start": "1501760",
    "end": "1506770"
  },
  {
    "text": "and then you can kind of see\nthe shape of this histogram is related to where we're seeing\nthe samples that we have access",
    "start": "1506770",
    "end": "1514810"
  },
  {
    "text": "to in this set. And then you can evaluate\nprobabilities of new data points",
    "start": "1514810",
    "end": "1524320"
  },
  {
    "text": "by basically checking in which\nbin does this test data point",
    "start": "1524320",
    "end": "1530289"
  },
  {
    "text": "land. Minus 0.5 lands in this bin\nwhere there is two data points.",
    "start": "1530290",
    "end": "1536300"
  },
  {
    "text": "And so we assign probability\ndensity 1 over 6. And then if you take, let's\nsay, minus 0.99, 1.99,",
    "start": "1536300",
    "end": "1544780"
  },
  {
    "text": "I guess that's also in\nthe first in this bin, where there's two data points. And so it should\nalso be one sixth.",
    "start": "1544780",
    "end": "1550990"
  },
  {
    "text": "And then the moment you\nstep over to the next bin, on the left, then the\nprobability goes down",
    "start": "1550990",
    "end": "1559000"
  },
  {
    "text": "to 1 over 12 or\nsomething like that. So just basic histogram\nas a way of constructing",
    "start": "1559000",
    "end": "1565960"
  },
  {
    "text": "an approximation of\nthe probability density function based on samples. ",
    "start": "1565960",
    "end": "1572170"
  },
  {
    "text": "It's a reasonable thing,\nbut you can kind of see that these transitions\nare probably not very natural.",
    "start": "1572170",
    "end": "1578890"
  },
  {
    "text": "Perhaps there is something\nbetter we can do. And indeed, a better solution\nis to basically smooth",
    "start": "1578890",
    "end": "1584620"
  },
  {
    "text": "these kind of hard\nthresholds that we had because we were using bins.",
    "start": "1584620",
    "end": "1590950"
  },
  {
    "text": "And so the way a kernel\ndensity estimator works, is that when we evaluate the\nprobability of a test data point",
    "start": "1590950",
    "end": "1599200"
  },
  {
    "text": "x, we basically check\nhow similar this data point is to all the samples\nthat we have in our set.",
    "start": "1599200",
    "end": "1608090"
  },
  {
    "text": "And we do that using this\nfunction k, a kernel function. And then we evaluate\nthis probability",
    "start": "1608090",
    "end": "1614890"
  },
  {
    "text": "by basically looking at all the\nn samples that we have access",
    "start": "1614890",
    "end": "1620140"
  },
  {
    "text": "to checking, evaluating the\nkernel on the difference between the data point that\nwe're testing the density on",
    "start": "1620140",
    "end": "1626680"
  },
  {
    "text": "and the samples that\nwe have access to and then where the distance\nis scaled by this parameter",
    "start": "1626680",
    "end": "1633100"
  },
  {
    "text": "sigma, which is called the\nbandwidth of the kernel. And to make things concrete,\nyou can think of the kernel",
    "start": "1633100",
    "end": "1640340"
  },
  {
    "text": "as being just a Gaussian\nfunction that has that sort of functional form.",
    "start": "1640340",
    "end": "1646200"
  },
  {
    "text": "And so the similarity\nbetween two data points decays exponentially\nbased on that equation.",
    "start": "1646200",
    "end": "1656440"
  },
  {
    "text": "And if you do that, then\nyou get a smoother kind of interpolation.",
    "start": "1656440",
    "end": "1662040"
  },
  {
    "text": "Before, we had these\nkind of bins that were sort of not very natural.",
    "start": "1662040",
    "end": "1667600"
  },
  {
    "text": "Now what we're doing if\nyou're doing a kernel density estimator using a\nGaussian kernel, is we're basically putting\nlittle Gaussians centered",
    "start": "1667600",
    "end": "1675570"
  },
  {
    "text": "around each data point that\nwe have in the set of samples. And then we're summing up,\nbasically, all these Gaussians.",
    "start": "1675570",
    "end": "1683670"
  },
  {
    "text": "And we get an estimate\nof the density that is now much more smooth. ",
    "start": "1683670",
    "end": "1689670"
  },
  {
    "text": "And so essentially,\nthe probability is high if you are close to many data\npoints, kind of like before,",
    "start": "1689670",
    "end": "1698950"
  },
  {
    "text": "but now it's being\nclosed is smooth. It's not only about whether\nyou are in the bin or not.",
    "start": "1698950",
    "end": "1706530"
  },
  {
    "text": "Now there is some small effect,\neven if you're very far away.",
    "start": "1706530",
    "end": "1713170"
  },
  {
    "text": "Although the effect\nof a data point decays according to\nthat whatever function",
    "start": "1713170",
    "end": "1720870"
  },
  {
    "text": "you choose for the kernel. Yeah? Are there some\nheuristics for how you choose the\nvariants specifically",
    "start": "1720870",
    "end": "1728390"
  },
  {
    "text": "for your kernel functions? Yeah, that's going\nto come up next. That's a great question.",
    "start": "1728390",
    "end": "1733770"
  },
  {
    "text": "And it seems like, OK,\nyou choose the kernel. The kernel is\nbasically telling you, should be a non-negative\nfunction that is normalized.",
    "start": "1733770",
    "end": "1743190"
  },
  {
    "text": "So it integrates\nto 1 so that when you take the sum of n kernels,\nthe total area is going to be n.",
    "start": "1743190",
    "end": "1752330"
  },
  {
    "text": "And then you divide\nby n, and you get an object that is normalized. So you get a valid\nprobability density.",
    "start": "1752330",
    "end": "1758870"
  },
  {
    "text": "And then, I guess, it\nhas to be symmetric because it's sort of intuitively\nlike a notion of similarity",
    "start": "1758870",
    "end": "1768590"
  },
  {
    "text": "between a pair of data points. And so the function\nvalue is going",
    "start": "1768590",
    "end": "1774450"
  },
  {
    "text": "to be high when the\ndifference is close to zero. And the bandwidth controls\nhow smooth, basically,",
    "start": "1774450",
    "end": "1782580"
  },
  {
    "text": "that interpolation looks like. And so what you see\nhere, on the left,",
    "start": "1782580",
    "end": "1788400"
  },
  {
    "text": "are different kinds of kernel\nfunctions you could choose. You could choose Gaussian. You could choose more like\na square kind of kernel",
    "start": "1788400",
    "end": "1796919"
  },
  {
    "text": "that determines\nwhat you think is",
    "start": "1796920",
    "end": "1803100"
  },
  {
    "text": "the right way of comparing how\nsimilar two data points are. So if you choose a\nGaussian, you have",
    "start": "1803100",
    "end": "1808380"
  },
  {
    "text": "that sort of functional form. If you choose some\nkind of square kernel that looks like that,\nthen it's more back",
    "start": "1808380",
    "end": "1814890"
  },
  {
    "text": "to the histogram\nkind of thing where two points are similar if their\ndistance is relatively small.",
    "start": "1814890",
    "end": "1821430"
  },
  {
    "text": "After you're above\nthis threshold, then the distance\nbecomes extremely high. ",
    "start": "1821430",
    "end": "1827900"
  },
  {
    "text": "The bandwidth controls\nthe smoothness. And so you can imagine\nthat, ideally, you'd",
    "start": "1827900",
    "end": "1836750"
  },
  {
    "text": "like to pick a\nbandwidth such that you get the distribution\nlike the black one,",
    "start": "1836750",
    "end": "1846080"
  },
  {
    "text": "the black curve\nhere is as close as possible to the true curve\nthat generated the data, which",
    "start": "1846080",
    "end": "1851240"
  },
  {
    "text": "is shown in gray there. But you can see that if you were\nto choose a value of sigma that",
    "start": "1851240",
    "end": "1856910"
  },
  {
    "text": "is too small, then you\nare going to get something",
    "start": "1856910",
    "end": "1862760"
  },
  {
    "text": "like the red curve, which\nis very jaggy again. And so it's kind\nof under smoothed.",
    "start": "1862760",
    "end": "1870260"
  },
  {
    "text": "And if you were to choose\na very high value of sigma, then everything is kind\nof similar to each other,",
    "start": "1870260",
    "end": "1875640"
  },
  {
    "text": "then you're going to get a\nvery smooth interpolation, and you get something like the\ngreen curve, which again, is not",
    "start": "1875640",
    "end": "1883429"
  },
  {
    "text": "a good approximation of the\ndensity that actually generated the data. So back to the question,\nhow do you choose sigma?",
    "start": "1883430",
    "end": "1891110"
  },
  {
    "text": "What you would try\nto do is you can try to tune it by trying to do\ncross validation where you leave out some of your\nsamples and then",
    "start": "1891110",
    "end": "1897300"
  },
  {
    "text": "you try to see\nwhich kind of sigma fits the samples that you've\nleft out as best as possible.",
    "start": "1897300",
    "end": "1902570"
  },
  {
    "text": " And so. yeah, that's true.",
    "start": "1902570",
    "end": "1910130"
  },
  {
    "text": "At least in\nprinciple, it's a way that would allow you\nto compute, to get",
    "start": "1910130",
    "end": "1915500"
  },
  {
    "text": "an estimate for the underlying\ndensity given only samples. Unfortunately, it's actually\nextremely unreliable.",
    "start": "1915500",
    "end": "1922860"
  },
  {
    "text": "The moment you go\nin high dimensions, just because, of course, of\ndimensionality basically,",
    "start": "1922860",
    "end": "1928730"
  },
  {
    "text": "you would need an extremely\nlarge number of samples to cover the whole space and\nall the possible things that",
    "start": "1928730",
    "end": "1934970"
  },
  {
    "text": "can happen. And so the more dimensions you\nhave, the more samples you need. And in practice, it's\nnot going to work",
    "start": "1934970",
    "end": "1940820"
  },
  {
    "text": "very well if you're working\non something like images. So there are limitations\nof what you can do.",
    "start": "1940820",
    "end": "1947100"
  },
  {
    "text": " Now, what if you have\nlatent variable models?",
    "start": "1947100",
    "end": "1955520"
  },
  {
    "text": "If you have a latent\nvariable model, again, but you would like to\nsomehow get the likelihood,",
    "start": "1955520",
    "end": "1961760"
  },
  {
    "text": "in theory, you can get\nit by integrate out over the latent variable z.",
    "start": "1961760",
    "end": "1968660"
  },
  {
    "text": "We know that that's sort of the\nexpression that you would need. If you want to evaluate the\nlikelihood of a data point x,",
    "start": "1968660",
    "end": "1974900"
  },
  {
    "text": "you can, in principle,\nget it by looking at all the possible values\nof the latent variables and then checking the\nconditional probability",
    "start": "1974900",
    "end": "1981500"
  },
  {
    "text": "of generating the data point\nx given the different z's that you're integrating over.",
    "start": "1981500",
    "end": "1987950"
  },
  {
    "text": "As we know, this can\nhave very high variance if the distribution\nof the prior is",
    "start": "1987950",
    "end": "1993799"
  },
  {
    "text": "very different from the\nposterior, which basically,",
    "start": "1993800",
    "end": "2000167"
  },
  {
    "text": "means that, again, you're\ngoing to need a lot of samples to basically get a reasonable\nestimate of that likelihood.",
    "start": "2000167",
    "end": "2006940"
  },
  {
    "text": "And there are ways to basically,\nmake the estimate more accurate.",
    "start": "2006940",
    "end": "2012857"
  },
  {
    "text": "There is something called\nannealed importance sampling, which is a procedure to\nbasically do importance sampling",
    "start": "2012858",
    "end": "2020000"
  },
  {
    "text": "by constructing a\nsequence of distributions to draw these z variables.",
    "start": "2020000",
    "end": "2025430"
  },
  {
    "text": "That is kind of\nlike interpolating between the bad, naive\nchoice of just sampling",
    "start": "2025430",
    "end": "2030860"
  },
  {
    "text": "from the prior p of z and\nthe optimal thing that you would like to do, which is\nto sample from the posterior.",
    "start": "2030860",
    "end": "2036280"
  },
  {
    "text": "And we're not going to\ngo into the details. I me actually skip\nsome of this stuff. But if you have in\nyour project, you're",
    "start": "2036280",
    "end": "2043850"
  },
  {
    "text": "working with latent variable\nmodels, you have a VA and somehow you need\nto compute likelihoods, you might want to look\ninto these kind of things",
    "start": "2043850",
    "end": "2050869"
  },
  {
    "text": "because they might help you\nget more accurate estimates of the likelihoods\nthat you get from",
    "start": "2050870",
    "end": "2057408"
  },
  {
    "text": "your variational autoencoder. Cool, now, what\nabout sample quality?",
    "start": "2057409",
    "end": "2065129"
  },
  {
    "text": "In a lot of these\nsituations, we maybe don't care about likelihoods,\nwe don't care about compression.",
    "start": "2065130",
    "end": "2070169"
  },
  {
    "text": "We have two generative\nmodels, maybe, and we can produce\nsamples from them.",
    "start": "2070170",
    "end": "2076408"
  },
  {
    "text": "And we would like to know which\none is producing better samples. Let's say if you're\nworking on images, maybe you have two\ngroups of samples,",
    "start": "2076409",
    "end": "2082620"
  },
  {
    "text": "and you'd like to know\nwhich one is better. And how to do that\nis not very obvious.",
    "start": "2082620",
    "end": "2091620"
  },
  {
    "text": "It's actually pretty\ntricky, to say, does this generative model that\nproduce these samples better",
    "start": "2091620",
    "end": "2097980"
  },
  {
    "text": "than the generative model\nthat produce these samples, not obvious how\nyou could do that. ",
    "start": "2097980",
    "end": "2105800"
  },
  {
    "text": "Probably the best\nway to go about it, would be to involve humans. ",
    "start": "2105800",
    "end": "2113900"
  },
  {
    "text": "So ask some annotators to\nessentially compare the samples",
    "start": "2113900",
    "end": "2119750"
  },
  {
    "text": "and check which ones are better. And of course, that's\nnot going to be scalable.",
    "start": "2119750",
    "end": "2127272"
  },
  {
    "text": "Maybe it's not something\nyou can use during training. But if we have\nthe budget for it,",
    "start": "2127272",
    "end": "2133859"
  },
  {
    "text": "and we have the time for to\ngo through a human evaluation that's usually sort of\nlike the gold standard.",
    "start": "2133860",
    "end": "2140920"
  },
  {
    "text": "There is actually\nvery interesting work in the HCI community\nwhere people have explored",
    "start": "2140920",
    "end": "2148010"
  },
  {
    "text": "what are principled ways of\ngetting feedback from humans and try to figure\nout and get them",
    "start": "2148010",
    "end": "2155470"
  },
  {
    "text": "to compare the quality of\ndifferent types of samples or different kinds\nof generative models.",
    "start": "2155470",
    "end": "2161500"
  },
  {
    "text": "This paper is\nactually from Stanford looking at perceptual\nevaluation of generative models.",
    "start": "2161500",
    "end": "2169600"
  },
  {
    "text": "And they're, which is based in\npsychology cognitive science",
    "start": "2169600",
    "end": "2175840"
  },
  {
    "text": "kind of literature. What they suggest is\nthat what you should do",
    "start": "2175840",
    "end": "2181720"
  },
  {
    "text": "is you should take\nsamples from your model. You have real data,\nAnd then you can check how much time people\nneed to accurately decide",
    "start": "2181720",
    "end": "2190990"
  },
  {
    "text": "whether or not the samples\nthat they are seeing are fake or real. So if you can only look at a\nsample for a very small amount",
    "start": "2190990",
    "end": "2198400"
  },
  {
    "text": "of time, you might not be able\nto perceive the difference from what is real\nand what is not.",
    "start": "2198400",
    "end": "2204400"
  },
  {
    "text": "Maybe the hands are\nnot rendered correctly. But if you don't\nhave enough time to actually stare at the\npictures long enough,",
    "start": "2204400",
    "end": "2210850"
  },
  {
    "text": "you might not be able to see it. And so what they\nsuggested is that we need to look at this time\nto get a sense of the longer",
    "start": "2210850",
    "end": "2219020"
  },
  {
    "text": "it takes for people to\ndistinguish real from fake, the better the samples are.",
    "start": "2219020",
    "end": "2226500"
  },
  {
    "text": "And the other metric that they\npropose is more traditional. And it would basically\nbe the percentage",
    "start": "2226500",
    "end": "2232350"
  },
  {
    "text": "of samples that deceive\npeople when you're giving them an infinite amount of\ntime to actually check whether it is real or not.",
    "start": "2232350",
    "end": "2239500"
  },
  {
    "text": "And so you can look at the\nwebsite if you're interested. And this is sort of\nwhat it would do,",
    "start": "2239500",
    "end": "2245550"
  },
  {
    "text": "what it would work\nlike if you want to determine how much time it\ntakes for people to figure out",
    "start": "2245550",
    "end": "2250980"
  },
  {
    "text": "whether or not samples are real. What you do is, you\nmight start with a very,",
    "start": "2250980",
    "end": "2257430"
  },
  {
    "text": "maybe, a fairly large\nnumber of, maybe 500 milliseconds you give them\nto decide whether or not",
    "start": "2257430",
    "end": "2264119"
  },
  {
    "text": "the image is real. Maybe they always get it right\nbecause they have a lot of time to figure out what\nkind of mistakes",
    "start": "2264120",
    "end": "2270330"
  },
  {
    "text": "are made by the\ngenerative model. Then you start decreasing\nthe time you give them until you get maybe\naround 300 milliseconds,",
    "start": "2270330",
    "end": "2277109"
  },
  {
    "text": "where people start not being\nable to distinguish real from fake. And at that point,\nthat would be sort of",
    "start": "2277110",
    "end": "2284490"
  },
  {
    "text": "like the hype time score for\nthis particular generative model. And then as I\nmentioned, the longer",
    "start": "2284490",
    "end": "2290920"
  },
  {
    "text": "it takes people to figure that\nout, the better the samples are.",
    "start": "2290920",
    "end": "2296849"
  },
  {
    "text": "And here you can see\nsome of the examples. And then you can also\nrank different samples",
    "start": "2296850",
    "end": "2303359"
  },
  {
    "text": "based on how long it would\ntake for human evaluators to basically distinguish\ndifferent types of samples.",
    "start": "2303360",
    "end": "2310080"
  },
  {
    "text": " Now the problem with human\nevaluations are great,",
    "start": "2310080",
    "end": "2319070"
  },
  {
    "text": "and maybe you can use\nthem for your project. The problem with\nhuman evaluation is that they tend\nto be expensive.",
    "start": "2319070",
    "end": "2326080"
  },
  {
    "text": "You actually have\nto pay people to go through the process\nof comparing samples, deciding which ones look better.",
    "start": "2326080",
    "end": "2332960"
  },
  {
    "text": "They are hard to reproduce,\nand there are strange-- you need to be very\ncareful on how you set up",
    "start": "2332960",
    "end": "2338300"
  },
  {
    "text": "these human evaluations. The lay out that\nyou use to ask them questions affects the\nanswers that you get.",
    "start": "2338300",
    "end": "2346370"
  },
  {
    "text": "The way you phrase the questions\naffect the answers that you get. So it's actually very\ntricky to rely entirely",
    "start": "2346370",
    "end": "2353059"
  },
  {
    "text": "on human evaluations. And they tend to be\npretty hard to reproduce. And so the other\nthing you might not",
    "start": "2353060",
    "end": "2362829"
  },
  {
    "text": "be able to get if\nyou just do this, is you might not be able\nto actually evaluate generalization.",
    "start": "2362830",
    "end": "2369039"
  },
  {
    "text": "Again, if you imagine a\ngenerative model that is only just memorizing\nthe training set,",
    "start": "2369040",
    "end": "2374320"
  },
  {
    "text": "it would give you very good\nsamples, just by definition. And you might not be\nable to even use humans.",
    "start": "2374320",
    "end": "2380110"
  },
  {
    "text": "You might not be able\nto actually figure out that indeed the model is\nactually just memorizing",
    "start": "2380110",
    "end": "2385300"
  },
  {
    "text": "the training set, and it's not\nactually able to generalize in any meaningful way.",
    "start": "2385300",
    "end": "2390880"
  },
  {
    "text": "And so it would be\nnice if there was some kind of automatic\nevaluation metric",
    "start": "2390880",
    "end": "2399330"
  },
  {
    "text": "to actually figure out the\nquality of the samples. And some that are very\npopular that are often",
    "start": "2399330",
    "end": "2406650"
  },
  {
    "text": "used in the literature, and you\nmight need to implement or use also for your projects, are\nInception Scores, FID Scores,",
    "start": "2406650",
    "end": "2415230"
  },
  {
    "text": "and KID Scores, which\nactually, I think, came up at some point in\nthe last lecture,",
    "start": "2415230",
    "end": "2420650"
  },
  {
    "text": "and there were questions\nof what they actually are. So now we're going to see how\nthey are actually computed",
    "start": "2420650",
    "end": "2428870"
  },
  {
    "text": "and what they actually mean. So Inception Scores\nis something you",
    "start": "2428870",
    "end": "2434390"
  },
  {
    "text": "can use when you're working\non labeled data sets. So if somehow you're in a\nsetting where the images have",
    "start": "2434390",
    "end": "2442250"
  },
  {
    "text": "associated labels,\nthen what you can do is you can try to\nessentially predict",
    "start": "2442250",
    "end": "2448490"
  },
  {
    "text": "the labels on synthetic samples. And you can check what kind of\ndistributions over the labels",
    "start": "2448490",
    "end": "2454640"
  },
  {
    "text": "you get on synthetic\nsamples versus real samples. So if you have access to a\nclassifier that can essentially",
    "start": "2454640",
    "end": "2462770"
  },
  {
    "text": "tell you what's the label for an\nimage x, then what you can try",
    "start": "2462770",
    "end": "2469610"
  },
  {
    "text": "to do is, you can\ntry to quantify how good a generative\nmodel is by looking",
    "start": "2469610",
    "end": "2476690"
  },
  {
    "text": "at the behavior of the\nclassifier on the samples that it produces. So there is two things that\nthe inception score looks at.",
    "start": "2476690",
    "end": "2485850"
  },
  {
    "text": "The first thing it looks at\nis something called sharpness. And essentially, you can\nimagine two sets of samples.",
    "start": "2485850",
    "end": "2493410"
  },
  {
    "text": "One that looks like this,\nand one that looks like this. And if you were to-- this is a labeled data set.",
    "start": "2493410",
    "end": "2499350"
  },
  {
    "text": "Every sample has a label,\nwhich is just a number. This is MNIST, so it's\nkind of like a toy example.",
    "start": "2499350",
    "end": "2504630"
  },
  {
    "text": "But every digit, every\nimage you produce can be mapped to a number\nthat it represents,",
    "start": "2504630",
    "end": "2512940"
  },
  {
    "text": "and you can kind of see that\nsomehow the true samples are",
    "start": "2512940",
    "end": "2519000"
  },
  {
    "text": "probably relatively\neasy to classify while synthetic samples that\nare a little bit blurred,",
    "start": "2519000",
    "end": "2524310"
  },
  {
    "text": "they're not very clear, they're\ngoing to be harder, essentially, to classify if you\nhave a good classifier.",
    "start": "2524310",
    "end": "2530940"
  },
  {
    "text": "And so the intuition\nbehind sharpness is to basically look at how\nconfident the classifier is",
    "start": "2530940",
    "end": "2537660"
  },
  {
    "text": "in making predictions on\nthe synthetic samples, on the generated samples. And so the formula\nlooks like this.",
    "start": "2537660",
    "end": "2544349"
  },
  {
    "text": "And it's essentially\nsomething related to the entropy of the classifier\nwhen evaluated on samples.",
    "start": "2544350",
    "end": "2551770"
  },
  {
    "text": "So you generate\nsamples from the model. And then you make predictions. You look at all the\npossible predictions",
    "start": "2551770",
    "end": "2557177"
  },
  {
    "text": "that the classifier produces\nover the x's that are synthetic. Then this quantity here\nis basically related",
    "start": "2557177",
    "end": "2563940"
  },
  {
    "text": "to the entropy of\nthe classifier. And so when the classifier\npredictive distribution has low",
    "start": "2563940",
    "end": "2572420"
  },
  {
    "text": "entropy, so kind of like\nthe classifier is putting all the probability\nmass on one single y,",
    "start": "2572420",
    "end": "2578257"
  },
  {
    "text": "it's very confident\nin the prediction that it makes,\nthen the sharpness value is going to be high.",
    "start": "2578258",
    "end": "2584210"
  },
  {
    "text": " And the other thing\nwe want to check",
    "start": "2584210",
    "end": "2590900"
  },
  {
    "text": "is something called diversity. And the idea is that if you're\nworking with a labeled data set,",
    "start": "2590900",
    "end": "2596420"
  },
  {
    "text": "you'd like the model\nto essentially produce images of all the classes that\nare represented in the training",
    "start": "2596420",
    "end": "2603740"
  },
  {
    "text": "set. So if you have,\nlet's say, a GAN that generates samples\nthat look like this,",
    "start": "2603740",
    "end": "2610508"
  },
  {
    "text": "this would indicate something\nlike mode collapse, where it's only producing once. And we would like\nto somehow say, OK,",
    "start": "2610508",
    "end": "2616122"
  },
  {
    "text": "these are not good samples\nbecause there is not enough diversity. And the way to quantify\nit is to basically look",
    "start": "2616122",
    "end": "2623030"
  },
  {
    "text": "at the marginal\ndistribution over the labels that you get from the\nclassifier when you evaluate it",
    "start": "2623030",
    "end": "2630770"
  },
  {
    "text": "on the samples. And you basically,\ntry to make sure that this marginal\ndistribution has high entropy,",
    "start": "2630770",
    "end": "2639710"
  },
  {
    "text": "meaning that all the\nclasses that are possible are actually predicted\nby the classifier",
    "start": "2639710",
    "end": "2646589"
  },
  {
    "text": "over the synthetic\nsamples essentially. So it's not just\nproducing once the model.",
    "start": "2646590",
    "end": "2653890"
  },
  {
    "text": "That's the formula. Again, it's basically\nlooking at the entropy of the marginal\ndistribution, then",
    "start": "2653890",
    "end": "2660317"
  },
  {
    "text": "the way you get the inception\nscore is, you multiply together these two numbers.",
    "start": "2660318",
    "end": "2665770"
  },
  {
    "text": "And so high inception\nscore is good because it means that\nyou have high diversity then you have high sharpness.",
    "start": "2665770",
    "end": "2672950"
  },
  {
    "text": "So how do you evaluate\nclassifier diversity? Because with\nsomething like this, it seems like you could just\ntake a bunch of rollouts,",
    "start": "2672950",
    "end": "2680890"
  },
  {
    "text": "and then just average the number\nof times it's predicted 0, 1, 2, 3, 4, 5, 6, 7, 8, just to make\nsure that the distributions are",
    "start": "2680890",
    "end": "2688390"
  },
  {
    "text": "all about the same. But it seems a little bit\nharder to say, within the class,",
    "start": "2688390",
    "end": "2694600"
  },
  {
    "text": "I have several\ndifferent 1's drawn. Yeah, so it doesn't do that.",
    "start": "2694600",
    "end": "2699613"
  },
  {
    "text": "So that's the problem, yeah. So it's not perfect. And that's one example\nof a failure mode. If somehow it does represent\nall the digits, but only",
    "start": "2699613",
    "end": "2707200"
  },
  {
    "text": "one kind of digit, you\nwould have potentially, a high inception score,\neven though you're",
    "start": "2707200",
    "end": "2713770"
  },
  {
    "text": "sort of like dropping modes\nwithin the clusters kind",
    "start": "2713770",
    "end": "2718810"
  },
  {
    "text": "of like corresponding\nto different labels. So not perfect for sure but\nwidely used, nevertheless.",
    "start": "2718810",
    "end": "2726190"
  },
  {
    "text": "And so higher inception score\ncorresponds to better quality. Why is it called\ninception score?",
    "start": "2726190",
    "end": "2732680"
  },
  {
    "text": "Well, if you don't\nhave a classifier, so if you're not in\nthe MNIST or toys or like situations, what you can\ndo is you train a classifier,",
    "start": "2732680",
    "end": "2740569"
  },
  {
    "text": "train on ImageNet, like\nthe inception net typically that people use for this, and\nthen you compute these metrics",
    "start": "2740570",
    "end": "2747380"
  },
  {
    "text": "with respect to that. ",
    "start": "2747380",
    "end": "2752610"
  },
  {
    "text": "Can you go over this diversity? How is it exactly\nassessing diversity again? So it's basically checking.",
    "start": "2752610",
    "end": "2758770"
  },
  {
    "text": "So this c of y,\nif you look at it, it's basically the\nmarginal distribution over the predicted labels when\nyou fit in synthetic samples.",
    "start": "2758770",
    "end": "2767859"
  },
  {
    "text": "So if you were to\nonly produce once, then this c y would be like\na one hot kind of vector.",
    "start": "2767860",
    "end": "2774570"
  },
  {
    "text": "And then the entropy\nwould be very low. And so you would be\nunhappy, basically.",
    "start": "2774570",
    "end": "2780790"
  },
  {
    "text": "And so you want high entropy,\nmeaning that ideally, it should be uniform. The c y should be uniform\nover the different y's",
    "start": "2780790",
    "end": "2787290"
  },
  {
    "text": "that are possible. So then that means that all\nthe classes are represented in equal numbers, essentially.",
    "start": "2787290",
    "end": "2793345"
  },
  {
    "text": " Yeah? So doesn't that mean that if\nyou want to increase diversity,",
    "start": "2793345",
    "end": "2803680"
  },
  {
    "text": "you would decrease sharpness. Yes.",
    "start": "2803680",
    "end": "2808690"
  },
  {
    "text": "They are competing. And you would like to have a\nhigh value of both in there. ",
    "start": "2808690",
    "end": "2818680"
  },
  {
    "text": "Cool, OK, so that was one. And it was often used. But as we discussed, not\nperfect, far from perfect.",
    "start": "2818680",
    "end": "2827050"
  },
  {
    "text": "One issue is that\nyou're not really-- you're kind of only\nlooking at samples from the synthetic samples, but\nyou're not really ever comparing",
    "start": "2827050",
    "end": "2834880"
  },
  {
    "text": "them to real data. If you think about\nthese formulas, you're just looking\nat synthetic samples.",
    "start": "2834880",
    "end": "2840070"
  },
  {
    "text": "You pass them through\nthe classifier. Then you look at statistics\nof what comes out from the classifier, which seems\nsuboptimal because you're never",
    "start": "2840070",
    "end": "2847510"
  },
  {
    "text": "even comparing synthetic\nsamples to real samples. So there is something\ncalled FID score, which",
    "start": "2847510",
    "end": "2854200"
  },
  {
    "text": "tries to essentially compare\nthe similarity of the features extracted by a large,\npre-trained model",
    "start": "2854200",
    "end": "2861910"
  },
  {
    "text": "on synthetic samples\nversus real samples. So what you do is this.",
    "start": "2861910",
    "end": "2868260"
  },
  {
    "text": "You generate a bunch of samples\nfrom your generative model, and you have a bunch of\nreal data from, let's say,",
    "start": "2868260",
    "end": "2874950"
  },
  {
    "text": "the test set. And then you feed each\nsample through some kind of pre-trained neural network,\nlike an inception net,",
    "start": "2874950",
    "end": "2883220"
  },
  {
    "text": "for example. That's why it's\ncalled FID score. And then you get features\nfor each data point.",
    "start": "2883220",
    "end": "2891360"
  },
  {
    "text": "There's going to be a\ndistribution over these features because every data\npoint is going to have a different\ncorresponding feature vector.",
    "start": "2891360",
    "end": "2898230"
  },
  {
    "text": "And what you can\ntry to do is you can fit a Gaussian\nto the features",
    "start": "2898230",
    "end": "2903757"
  },
  {
    "text": "that you get from the synthetic\nsamples and the features that you get in\nthe real samples. And you're going to get\ntwo different Gaussians,",
    "start": "2903757",
    "end": "2911843"
  },
  {
    "text": "meaning that the Gaussians\nwill have different means and different variances.",
    "start": "2911843",
    "end": "2917400"
  },
  {
    "text": "And the closer these\ntwo Gaussians are, the higher the quality of\nthe samples, essentially.",
    "start": "2917400",
    "end": "2927089"
  },
  {
    "text": "Because if the samples\nfrom the synthetic model, are very different\nfrom the real ones, then you might expect\nthat the features that",
    "start": "2927090",
    "end": "2933810"
  },
  {
    "text": "are extracted by a pre-trained\nmodel are going to be different. And therefore,\nthese two Gaussians",
    "start": "2933810",
    "end": "2938880"
  },
  {
    "text": "might be different, maybe\nhave different means, or they have different standard\ndeviations, different variances.",
    "start": "2938880",
    "end": "2945880"
  },
  {
    "text": "Then you get a\nscalar out of this by taking the Wasserstein two\ndistance between these two Gaussians, which you can\ncompute in closed form.",
    "start": "2945880",
    "end": "2952829"
  },
  {
    "text": "And it's essentially looking at\nthe difference between the means of the Gaussians and some\nquantity that basically",
    "start": "2952830",
    "end": "2959160"
  },
  {
    "text": "quantifies how different the\ntwo, the variances that you got by fitting a Gaussian to the\nreal data and the fake data",
    "start": "2959160",
    "end": "2967200"
  },
  {
    "text": "are, with respect to each other.  So what's the intuition for\nusing multivariate Gaussians?",
    "start": "2967200",
    "end": "2975270"
  },
  {
    "text": "Why not any other statistic? Yeah, you could\nuse other things. The reason they use\nmultivariate Gaussians,",
    "start": "2975270",
    "end": "2981510"
  },
  {
    "text": "is that this\nWasserstein distance can be computed in closed form\nbut yeah, not particularly",
    "start": "2981510",
    "end": "2987240"
  },
  {
    "text": "principal. Yeah? What does depend on the\nsamples that are being drawn?",
    "start": "2987240",
    "end": "2995740"
  },
  {
    "text": "So considering\nthe imaging model,",
    "start": "2995740",
    "end": "3000940"
  },
  {
    "text": "so generated samples\ncould refer to [INAUDIBLE] some other subject area.\nwhere there is a kind of--",
    "start": "3000940",
    "end": "3006870"
  },
  {
    "text": "and the trained ones\ncould be some others. So are we really comparing\napples to apples?",
    "start": "3006870",
    "end": "3012000"
  },
  {
    "text": " Well, if the model\nis doing a good job",
    "start": "3012000",
    "end": "3018630"
  },
  {
    "text": "at fitting the\ndata distribution, then you would expect\nthe statistics extracted by a pre-trained network\nwould also be similar.",
    "start": "3018630",
    "end": "3025630"
  },
  {
    "text": "So if, for example, this\npre-trained network is looking at-- it's extracting statistics,\nhigh-level features",
    "start": "3025630",
    "end": "3032460"
  },
  {
    "text": "like what's in the image,\nwhere the objects are located, and things like that,\nwhich you might expect",
    "start": "3032460",
    "end": "3039310"
  },
  {
    "text": "these networks to do because\nthey perform pretty well when you fine tune them on a\nvariety of different tasks,",
    "start": "3039310",
    "end": "3045990"
  },
  {
    "text": "then in some sense,\nyou're hoping that looking at these statistics will\ntell you something about how",
    "start": "3045990",
    "end": "3052330"
  },
  {
    "text": "similar the samples\nare in terms of do they capture a\nsimilar distribution.",
    "start": "3052330",
    "end": "3059790"
  },
  {
    "text": "So two questions\nrelated to the feature. First one was that, why we\nfitting multivariate Gaussians",
    "start": "3059790",
    "end": "3068630"
  },
  {
    "text": "to the features? What about checking the mean\nand variance of the generated",
    "start": "3068630",
    "end": "3075589"
  },
  {
    "text": "and the test samples directly? And the second one was like,\nyeah, can you elaborate on,",
    "start": "3075590",
    "end": "3082400"
  },
  {
    "text": "for example, variational\nautoencoders. We try to compute a feature\nrepresentation, right?",
    "start": "3082400",
    "end": "3089507"
  },
  {
    "text": "So is that what you're referring\nto when you say feature represent anything here? So for the second\nquestion, the features",
    "start": "3089507",
    "end": "3095450"
  },
  {
    "text": "are the ones that are extracted\nby a pre-trained model, which could be anything. In the FID case,\nits inception net.",
    "start": "3095450",
    "end": "3102600"
  },
  {
    "text": "That's why it's called\ninception distance. And so that's a\npre-trained model, typically, on some\nlarge scale image data",
    "start": "3102600",
    "end": "3108710"
  },
  {
    "text": "set, where you have a\nlot of different classes in order to perform well\nclassification and probably",
    "start": "3108710",
    "end": "3114800"
  },
  {
    "text": "has to extract\nreasonable features comparing the feature space. Kind of makes sense?",
    "start": "3114800",
    "end": "3119980"
  },
  {
    "text": "The other question was, why\nnot just compare the means of the samples themselves?",
    "start": "3119980",
    "end": "3125369"
  },
  {
    "text": "That would be a very\nsimple kind of feature, where you're just looking\nat the individual pixels.",
    "start": "3125370",
    "end": "3130559"
  },
  {
    "text": "You could, but it may be not\nexactly what we care about. It's more interesting to compare\nthese higher level features that",
    "start": "3130560",
    "end": "3138030"
  },
  {
    "text": "are extracted by a model. When you're using\nFID, do people ever add auxiliary losses to\nthe training card itself,",
    "start": "3138030",
    "end": "3145380"
  },
  {
    "text": "like [INAUDIBLE] or something\nto make this metric be better downstream, or is it separated?",
    "start": "3145380",
    "end": "3151470"
  },
  {
    "text": "Yeah, you could train on FID. Then you can no longer use\nit as an evaluation metric.",
    "start": "3151470",
    "end": "3157420"
  },
  {
    "text": "So it's not-- the moment you\nstart training on something, it stops to become a good--",
    "start": "3157420",
    "end": "3162570"
  },
  {
    "text": "so but you could, yeah. To the extent that it's not\ntoo expensive to compute,",
    "start": "3162570",
    "end": "3168200"
  },
  {
    "text": "which I think it might be. But you could try,\nat the very least.",
    "start": "3168200",
    "end": "3173440"
  },
  {
    "text": "And then in this case,\nlower FID is better. And the other thing\nyou can do, is",
    "start": "3173440",
    "end": "3180619"
  },
  {
    "text": "to do something called the\nkernel inception distance. And the idea is to basically\ndo two-sample test, kind",
    "start": "3180620",
    "end": "3189680"
  },
  {
    "text": "of like the same thing we've\nused for training models, but instead of doing it at the\nlevel of the samples themselves,",
    "start": "3189680",
    "end": "3195194"
  },
  {
    "text": "we're going to, again, do it\nat the level of the features extracted by a\npre-trained model. And so the MMD is another\nkind of two-sample test, where",
    "start": "3195195",
    "end": "3203930"
  },
  {
    "text": "you have samples from two\ndistributions, p and q. And what you do is, you\ncompare the difference",
    "start": "3203930",
    "end": "3210525"
  },
  {
    "text": "in different moments,\nkind of like what was suggested by Dev\nright now looking at the mean, the\nvariance, and so forth.",
    "start": "3210525",
    "end": "3216950"
  },
  {
    "text": "And more specifically,\nthe way you do it is back to the kernel idea. You use a kernel to measure\nsimilarity between data points.",
    "start": "3216950",
    "end": "3225580"
  },
  {
    "text": "And what you do is you do this. If you have\ndistribution p and q, you check what is the average\nsimilarity between two samples,",
    "start": "3225580",
    "end": "3234610"
  },
  {
    "text": "two real samples, let's say. What's the average similarity\nbetween two fake samples,",
    "start": "3234610",
    "end": "3240970"
  },
  {
    "text": "and then you compare that\nto the average similarity between a real\nand a fake sample.",
    "start": "3240970",
    "end": "3247130"
  },
  {
    "text": "And if p, again, is\nequal to q, then you can see that this\nthing evaluates to 0 because the difference\nbetween real and fake samples",
    "start": "3247130",
    "end": "3256599"
  },
  {
    "text": "is the same as the difference\nbetween two real samples or two fake samples.",
    "start": "3256600",
    "end": "3263170"
  },
  {
    "text": "And the idea is that\nwe're now allowed to use a kernel to\nbasically compare how similar two samples are.",
    "start": "3263170",
    "end": "3270240"
  },
  {
    "text": "And so we don't necessarily\nhave to compare samples in terms",
    "start": "3270240",
    "end": "3276040"
  },
  {
    "text": "of their raw pixel values. But what we can do\nis, we can, again, do MMD in the feature\nspace of our classifier.",
    "start": "3276040",
    "end": "3285955"
  },
  {
    "text": "And so what you would do,\nis you would use a kernel to compare the features\nor two samples,",
    "start": "3285955",
    "end": "3293210"
  },
  {
    "text": "two real samples,\ntwo fake samples, and a real and a fake\nsample basically.",
    "start": "3293210",
    "end": "3299490"
  },
  {
    "text": "And it's similar to FID. The key difference is that KID\nis a little bit more principled.",
    "start": "3299490",
    "end": "3308070"
  },
  {
    "text": "But it's more expensive\nbecause you're kind of like, if you have n samples, then it\nhas a quadratic cost, as opposed",
    "start": "3308070",
    "end": "3315283"
  },
  {
    "text": "to a linear one because\nyou have to make all pairwise comparisons between\nthe two groups of samples.",
    "start": "3315283",
    "end": "3322220"
  },
  {
    "text": "But similar flavor to FID So how does FID compare the\ntwo distribution's moments?",
    "start": "3322220",
    "end": "3333140"
  },
  {
    "text": "Yeah, it's not obvious\nfrom this perspective, but you could also think of\nit as, basically, the kernel,",
    "start": "3333140",
    "end": "3342770"
  },
  {
    "text": "you could, basically,\nmap the samples in the reproducing kernel\nHilbert space of the kernel.",
    "start": "3342770",
    "end": "3349770"
  },
  {
    "text": "So it's kind of like if the\nkernel is comparing data points based on some features,\nthen this is basically",
    "start": "3349770",
    "end": "3356420"
  },
  {
    "text": "the same thing as embedding\nthe real data points and the fake data points in the\nfeature space of the kernel,",
    "start": "3356420",
    "end": "3362600"
  },
  {
    "text": "and then comparing\nthose two objects. But the nice thing\nis that the kernels could be looking at an\ninfinite number of features.",
    "start": "3362600",
    "end": "3369030"
  },
  {
    "text": "So it's kind of like the\nkernel trick, where you're allowed to compare\ndata points using an infinite number of\nfeatures without ever",
    "start": "3369030",
    "end": "3375080"
  },
  {
    "text": "having to compute them. ",
    "start": "3375080",
    "end": "3381820"
  },
  {
    "text": "OK, so that was the\nthree main metrics",
    "start": "3381820",
    "end": "3387220"
  },
  {
    "text": "that are used for\nevaluating sample quality. There is many more\nthat you might",
    "start": "3387220",
    "end": "3393460"
  },
  {
    "text": "need to consider, especially\nif you're thinking about text-to-image models. Then there's many things\nyou have to worry about.",
    "start": "3393460",
    "end": "3400220"
  },
  {
    "text": "So if the generative model\nis supposed to take a caption and generate an image, then you\ndo care about image quality,",
    "start": "3400220",
    "end": "3406569"
  },
  {
    "text": "but you do care\nabout other things. For example, you care\nabout whether or not the images that you generate are\nconsistent with the caption that",
    "start": "3406570",
    "end": "3414910"
  },
  {
    "text": "was provided by the\nuser, but then you might care about other things. You might care about\nthe kind of biases",
    "start": "3414910",
    "end": "3421119"
  },
  {
    "text": "that are shown by the model. You might care\nabout whether or not it's producing toxic content\nthat you might need to filter.",
    "start": "3421120",
    "end": "3428680"
  },
  {
    "text": "How good it is about\nreasoning about if the caption talks\nabout different objects and their spatial relationship.",
    "start": "3428680",
    "end": "3435070"
  },
  {
    "text": "How good is the model\nat understanding the spatial relationship\nand spatial reasoning",
    "start": "3435070",
    "end": "3441410"
  },
  {
    "text": "kind of problems. So there's actually\nsomething pretty new that, also, I was involved\nin came out of Stanford.",
    "start": "3441410",
    "end": "3450200"
  },
  {
    "text": "So we put together this\nbenchmark called HEIM, Holistic Evaluation of\nText2Image models, where",
    "start": "3450200",
    "end": "3457670"
  },
  {
    "text": "we've considered all\nthe different metrics that we could think of.",
    "start": "3457670",
    "end": "3462710"
  },
  {
    "text": "And we've considered different\nkind of evaluation scenarios.",
    "start": "3462710",
    "end": "3468230"
  },
  {
    "text": "And so you can see some\nexamples here trying to look at quality,\nwhere maybe we",
    "start": "3468230",
    "end": "3473600"
  },
  {
    "text": "use the usual FID and\ninception and KID that we just talked about. But then we also\nlook at other things.",
    "start": "3473600",
    "end": "3479809"
  },
  {
    "text": "How robust the models are if you\nchange words in the captions, and the alignment\nbetween the image",
    "start": "3479810",
    "end": "3485630"
  },
  {
    "text": "that you generate and the\ncaption, various kinds of aesthetic scores, various\nkind of originality scores.",
    "start": "3485630",
    "end": "3491480"
  },
  {
    "text": "So a lot of different metrics,\nand we actually try to do. But I think today it is the\nmost comprehensive evaluation",
    "start": "3491480",
    "end": "3499190"
  },
  {
    "text": "of existing\ntext-to-image models. We took a lot of\nexisting models, and then we tried to\ncompare them with respect",
    "start": "3499190",
    "end": "3505040"
  },
  {
    "text": "to all these different metrics. And that you can go if you're\ninterested and see the results and see which model\nproduces the highest quality",
    "start": "3505040",
    "end": "3513740"
  },
  {
    "text": "images as measured by all these\ndifferent metrics, both real, both human and automated\nor other things",
    "start": "3513740",
    "end": "3522110"
  },
  {
    "text": "and if you care about the\nbiases that these models have, we have a bunch of\nmetrics to measure that.",
    "start": "3522110",
    "end": "3527760"
  },
  {
    "text": "So that might be a\nuseful resource, again, as you develop your projects.",
    "start": "3527760",
    "end": "3533750"
  },
  {
    "text": "Now, another thing you might\nwant to do with the model is to get features.",
    "start": "3533750",
    "end": "3538790"
  },
  {
    "text": "We've talked about this idea\nof doing unsupervised learning. You have a lot of\nunlabeled data.",
    "start": "3538790",
    "end": "3544470"
  },
  {
    "text": "You might be able to get\ngood features from the model. How do you evaluate whether\nyou have good features or not?",
    "start": "3544470",
    "end": "3552920"
  },
  {
    "text": "We should know, already, what's\nthe task you are thinking about. You're trying to get\nfeatures because then",
    "start": "3552920",
    "end": "3559627"
  },
  {
    "text": "at the end of the day, you\ncare about classifying. You have a classification\nproblem in mind. Then you can always\nmeasure the performance",
    "start": "3559627",
    "end": "3567349"
  },
  {
    "text": "on the downstream task. So in that case,\nit's not too hard.",
    "start": "3567350",
    "end": "3572460"
  },
  {
    "text": "It's a lot more tricky to-- if you don't have\na task in mind,",
    "start": "3572460",
    "end": "3577463"
  },
  {
    "text": "and you're just\ntrying to say, OK, is this model producing better\nfeatures than this other model, then it's a lot\nmore tricky to be",
    "start": "3577463",
    "end": "3584569"
  },
  {
    "text": "able to say something\ndefinitive there. And there is different\naspects that you",
    "start": "3584570",
    "end": "3594230"
  },
  {
    "text": "might want to\nconsider if you are in the unsupervised kind of\nsetting, where there is no task, there is no labels, so no\nobjective way of basically",
    "start": "3594230",
    "end": "3602329"
  },
  {
    "text": "comparing different\nsort of representations that you might get. You might care about how good\nthe model is at clustering.",
    "start": "3602330",
    "end": "3609200"
  },
  {
    "text": "Maybe you care\nabout compression. Maybe you care about\ndisentanglement. So maybe you care\nabout this idea",
    "start": "3609200",
    "end": "3615710"
  },
  {
    "text": "that we briefly talked about,\nthat if you have a latent variable model, you would\nlike latent variables",
    "start": "3615710",
    "end": "3620810"
  },
  {
    "text": "to have some kind of meaning. And maybe you might want\nto be able to control different factors of\nvariation by changing",
    "start": "3620810",
    "end": "3626870"
  },
  {
    "text": "the variables individually. So that's what's kind of like\nreferred as disentanglement, where the different variables\nhave separate meanings,",
    "start": "3626870",
    "end": "3634550"
  },
  {
    "text": "and they control\ndifferent aspects of the data-generating process.",
    "start": "3634550",
    "end": "3640369"
  },
  {
    "text": "So if you care about\nclustering, ideally, you",
    "start": "3640370",
    "end": "3645700"
  },
  {
    "text": "would like to be able to\ngroup together data points that have somehow the\nsame similar meaning,",
    "start": "3645700",
    "end": "3652270"
  },
  {
    "text": "or that they are\nsimilar in some way. And this is all very cyclical,\nbut that's the problem with unsupervised learning.",
    "start": "3652270",
    "end": "3658210"
  },
  {
    "text": "And one thing you\ncan do, is you can take your VAE or your\nmodel that gives you",
    "start": "3658210",
    "end": "3664660"
  },
  {
    "text": "latent representations,\nyou can map points into this feature space.",
    "start": "3664660",
    "end": "3670599"
  },
  {
    "text": "And then you can apply some\nkind of clustering algorithm, like K means to\ngroup them together.",
    "start": "3670600",
    "end": "3675830"
  },
  {
    "text": "And so here's an example\nof the kind of thing. You train two generative\nmodels on MNIST,",
    "start": "3675830",
    "end": "3680920"
  },
  {
    "text": "and then you map the data points\nto a two-dimensional latent space. And here, the colors represent\nthe different classes.",
    "start": "3680920",
    "end": "3688930"
  },
  {
    "text": "I don't even remember exactly\nwhat is B and what is D, but these are two\ndifferent models. And they produce two different\nembeddings of the data.",
    "start": "3688930",
    "end": "3698260"
  },
  {
    "text": "And which one is better? Is B Better Is D better?",
    "start": "3698260",
    "end": "3705530"
  },
  {
    "text": "It's unclear, right? They both seem to be doing\nsomething reasonable or data",
    "start": "3705530",
    "end": "3711080"
  },
  {
    "text": "points belonging to\nthe same class end up being grouped together\nin this latent space,",
    "start": "3711080",
    "end": "3717715"
  },
  {
    "text": "is not obvious which\none you would prefer.  And so for label data\nsets, again, there",
    "start": "3717715",
    "end": "3726922"
  },
  {
    "text": "is many quantitative metrics. ",
    "start": "3726922",
    "end": "3731990"
  },
  {
    "text": "So if you do have\nlabels that you use to--",
    "start": "3731990",
    "end": "3737450"
  },
  {
    "text": "use unlabeled data to\ncome up with the clusters. And then you use\nlabels to evaluate",
    "start": "3737450",
    "end": "3742630"
  },
  {
    "text": "the quality of the clusters. Then there is a bunch\nof metrics things like the completeness scores,\nhomogeneity score, V measures.",
    "start": "3742630",
    "end": "3750608"
  },
  {
    "text": "I'm going to go through\nthem quickly, but sort of like there is a bunch of\nmeasures that you can use. If you have a\nlabel data set, you",
    "start": "3750608",
    "end": "3757150"
  },
  {
    "text": "pretend you don't\nhave the labels. You get representations. You do clustering,\nand then you can",
    "start": "3757150",
    "end": "3763900"
  },
  {
    "text": "use the labels to see how good\nthe clusters that you get are.",
    "start": "3763900",
    "end": "3769299"
  },
  {
    "text": "And intuitively,\nwhat you want to do is you would like\nto be able to group together points that\nbelong to the same class.",
    "start": "3769300",
    "end": "3776119"
  },
  {
    "text": "And so maybe you care\nabout making sure that all the points that belong\nto the same class end up--",
    "start": "3776120",
    "end": "3782350"
  },
  {
    "text": "land in the same cluster. Or maybe you care about\nhomogeneity within the clusters.",
    "start": "3782350",
    "end": "3787490"
  },
  {
    "text": "So you would like to make\nsure that all the points that land in the same cluster,\nhave the same label, or maybe",
    "start": "3787490",
    "end": "3793480"
  },
  {
    "text": "some combination of\nthese two scores.",
    "start": "3793480",
    "end": "3798550"
  },
  {
    "text": "So there's different\nmetrics that you can use. And again, if your project\ninvolves something like this,",
    "start": "3798550",
    "end": "3805560"
  },
  {
    "text": "you can look into\nthis into more detail. ",
    "start": "3805560",
    "end": "3811823"
  },
  {
    "text": "Another thing you\nmight want to do is to check how well, basically,\nthe latent representations",
    "start": "3811823",
    "end": "3818520"
  },
  {
    "text": "preserve information about\nthe original data points. So to what extent, basically,\nyou can reconstruct data, given",
    "start": "3818520",
    "end": "3826710"
  },
  {
    "text": "the latent representations,\nwhich is task you care about if you're\ntrying to do lossy compression.",
    "start": "3826710",
    "end": "3832390"
  },
  {
    "text": "So you have data. It might make sense to map it\nto a latent representation, especially if that\nlatent representation is",
    "start": "3832390",
    "end": "3838260"
  },
  {
    "text": "kind of lower dimensional. And in this case, maybe\nyou care about being able to reconstruct the\noriginal data point as",
    "start": "3838260",
    "end": "3844020"
  },
  {
    "text": "accurately as possible. So here you see some examples\nof different representations,",
    "start": "3844020",
    "end": "3851880"
  },
  {
    "text": "and you have the original\nimages on the top. And then what you\nsee here, is what",
    "start": "3851880",
    "end": "3857220"
  },
  {
    "text": "you get if you map them\nto the latent space, and then you try to reconstruct\nthe image from the latent",
    "start": "3857220",
    "end": "3863010"
  },
  {
    "text": "representation. And so you'd like\nthe reconstructions to be as close as possible\nto the original data",
    "start": "3863010",
    "end": "3869880"
  },
  {
    "text": "while basically reducing\nthe size of the latent space as much as possible.",
    "start": "3869880",
    "end": "3874957"
  },
  {
    "text": "So here, for example,\nthey are looking at different kinds\nof representations where maybe if\nyou compress using",
    "start": "3874957",
    "end": "3881250"
  },
  {
    "text": "JPEG, you would get something\nlike a 17x compression in images",
    "start": "3881250",
    "end": "3886770"
  },
  {
    "text": "with a small loss in\naccuracy or quality, while there are these other\nrepresentations that you get",
    "start": "3886770",
    "end": "3892350"
  },
  {
    "text": "from training a\ngenerative model, where maybe you\ncan get something",
    "start": "3892350",
    "end": "3897390"
  },
  {
    "text": "like a 90x compression, meaning\nthe latent vectors that you",
    "start": "3897390",
    "end": "3902460"
  },
  {
    "text": "get by mapping data\nto the latent space are much smaller than\nthe original data points.",
    "start": "3902460",
    "end": "3909016"
  },
  {
    "text": "And still, you're able to do\nvery well at reconstructing the original data\npoints as measured by kind of\nreconstruction metrics",
    "start": "3909017",
    "end": "3915490"
  },
  {
    "text": "like mean squared\nerror or PSNR or SSIM. ",
    "start": "3915490",
    "end": "3920760"
  },
  {
    "text": "Weren't we already\ntrying to do this back when we were discussing VAEs and\nother latent variable models?",
    "start": "3920760",
    "end": "3926650"
  },
  {
    "text": "Yeah, so VAEs have a\nreconstruction loss embedded in them. So it would make sense that\nthey do reasonably well at that.",
    "start": "3926650",
    "end": "3934295"
  },
  {
    "text": "But if you had a\ndifferent model, maybe you're looking\nat the representation that you get from\na GAN, and you want",
    "start": "3934295",
    "end": "3939900"
  },
  {
    "text": "to know are those better\nthan the ones I have on VAE, it depends on what you want to\ndo with this representations.",
    "start": "3939900",
    "end": "3945085"
  },
  {
    "text": "Do you care about clustering? Do you care about\nreconstruction quality?",
    "start": "3945085",
    "end": "3950640"
  },
  {
    "text": "So this is one aspect\nthat you might care about if you're trying to\ncompare two different types",
    "start": "3950640",
    "end": "3957470"
  },
  {
    "text": "of representations that you\nget in generative models. Now, the other thing that you\nmight care about the latent",
    "start": "3957470",
    "end": "3964119"
  },
  {
    "text": "space is disentanglement. The idea that we would\nlike these latent representations,\nthe latent variables",
    "start": "3964120",
    "end": "3970540"
  },
  {
    "text": "to capture independent and\ninterpretable attributes of the observed data.",
    "start": "3970540",
    "end": "3977390"
  },
  {
    "text": "Something like if you have\na generative model of faces,",
    "start": "3977390",
    "end": "3982839"
  },
  {
    "text": "maybe if you change one\nof the latent variables, you change the skin color\nof the image you produce,",
    "start": "3982840",
    "end": "3988539"
  },
  {
    "text": "or maybe there is another latent\nvariable that kind of controls the age of the\npeople you generate",
    "start": "3988540",
    "end": "3995080"
  },
  {
    "text": "through this generative\nmodel and so forth. And so for example, maybe\nthere is a latent variable z1",
    "start": "3995080",
    "end": "4006869"
  },
  {
    "text": "that is controlling the size\nof the objects you produce. So if you don't change z1,\nthen the size of the object",
    "start": "4006870",
    "end": "4013590"
  },
  {
    "text": "never changes. As soon as you\nchange the z1, then you change the sizes of\nthe objects you produce.",
    "start": "4013590",
    "end": "4020430"
  },
  {
    "text": "Or yeah, that would\nbe the ideal outcome",
    "start": "4020430",
    "end": "4027140"
  },
  {
    "text": "kind of like PCA sort of\nbut in a non-linear way.",
    "start": "4027140",
    "end": "4033710"
  },
  {
    "text": "You find important aspects,\nlatent factors of variation in the data, and then you're\nable to control them separately,",
    "start": "4033710",
    "end": "4039950"
  },
  {
    "text": "essentially. And again, there is many metrics\nthat people have come up with.",
    "start": "4039950",
    "end": "4047250"
  },
  {
    "text": "For example, the accuracy\nof a linear classifier that tries to predict a fixed\nfactor of variation",
    "start": "4047250",
    "end": "4054350"
  },
  {
    "text": "and a bunch of others that\nI'm not going to go over. But there are some\nlibraries that",
    "start": "4054350",
    "end": "4059450"
  },
  {
    "text": "would allow you to\ncompute these metrics. So if you're doing a project\naround disentanglement,",
    "start": "4059450",
    "end": "4066080"
  },
  {
    "text": "this might be a good\nresource to look into. And the kind of\nunfortunate aspect here,",
    "start": "4066080",
    "end": "4072590"
  },
  {
    "text": "is that it's provably impossible\nto learn a generative model that",
    "start": "4072590",
    "end": "4078560"
  },
  {
    "text": "is disentangled if you\nonly have unlabeled data. So if you never get to see\nthe true kind of latent",
    "start": "4078560",
    "end": "4084920"
  },
  {
    "text": "factors of variation,\nthere is no labels associated with these\nfactors that you're trying to discover from data.",
    "start": "4084920",
    "end": "4091600"
  },
  {
    "text": "It's actually provably\nimpossible to do this. So there has been some\nempirical success,",
    "start": "4091600",
    "end": "4098259"
  },
  {
    "text": "but it's not well understood\nwhy these methods work. And there is some\ntheoretical results showing that it's\nactually not possible.",
    "start": "4098260",
    "end": "4104445"
  },
  {
    "text": "So I guess there are\nsome limitations there. ",
    "start": "4104446",
    "end": "4111060"
  },
  {
    "text": "Cool, now, the other thing\nthat, of course, is very popular",
    "start": "4111060",
    "end": "4117390"
  },
  {
    "text": "these days, is this idea that if\nyou are working with a language",
    "start": "4117390",
    "end": "4123420"
  },
  {
    "text": "model, perhaps you don't care\nabout going through this process of let's take the data.",
    "start": "4123420",
    "end": "4129479"
  },
  {
    "text": "Let's map it to a\nlatent space, and then let's try to somehow use these\nrepresentations to improve",
    "start": "4129479",
    "end": "4136380"
  },
  {
    "text": "performance in some\nkind of downstream task. If you have a generative\nmodel of language,",
    "start": "4136380",
    "end": "4142200"
  },
  {
    "text": "then you might be able\nto directly use the model to solve tasks that involve\nlanguage by specifying",
    "start": "4142200",
    "end": "4149970"
  },
  {
    "text": "the tasks in natural language. So there are two different ways\nof using the generative model.",
    "start": "4149970",
    "end": "4155460"
  },
  {
    "text": "You could try to train\nthe generative model in an unsupervised way and then\ntry to leverage the knowledge",
    "start": "4155460",
    "end": "4161100"
  },
  {
    "text": "that it discovered by mapping\ndata points in this latent space and then training classifiers\nthe usual way on these latent",
    "start": "4161100",
    "end": "4166979"
  },
  {
    "text": "representations. Or if you're working\nwith a language model,",
    "start": "4166979",
    "end": "4173799"
  },
  {
    "text": "then there is this idea of\npre-training the model using a lot of unlabeled\ndata, and then trying",
    "start": "4173800",
    "end": "4180970"
  },
  {
    "text": "to adapt it, for example,\nthrough prompts, to actually get it to solve a variety\nof different tasks.",
    "start": "4180970",
    "end": "4187827"
  },
  {
    "text": "So even though these\nmodels have been trained by maximum\nlikelihood, which we know is just compression, we\nknow that they are by doing--",
    "start": "4187828",
    "end": "4195310"
  },
  {
    "text": "if they do well\nat compression, it means they've learned something\nabout the structure of the data. They've memorized a lot\nof interesting things.",
    "start": "4195310",
    "end": "4201889"
  },
  {
    "text": "And then the hope is that we\ncan leverage that knowledge in different kinds\nof downstream tasks.",
    "start": "4201890",
    "end": "4208130"
  },
  {
    "text": "So for example, let's say that\nyou are doing sentiment analysis where you're\nbasically given, let's",
    "start": "4208130",
    "end": "4215470"
  },
  {
    "text": "say, a review maybe of\na movie, and the goal is to predict whether the\nsentiment of that review",
    "start": "4215470",
    "end": "4221740"
  },
  {
    "text": "is positive or negative. It's a classic kind of NLP task.",
    "start": "4221740",
    "end": "4226920"
  },
  {
    "text": "How would you use a language\nmodel to solve this problem? And the idea is\nthat because we're",
    "start": "4226920",
    "end": "4233280"
  },
  {
    "text": "working with natural\nlanguage, what you could do is you could try to-- we have our interface is a\nmodel that takes a sentence",
    "start": "4233280",
    "end": "4240210"
  },
  {
    "text": "and predicts the next word. Let's say it's an\nautoregressive model. It takes up a piece of\nlanguage, and then it",
    "start": "4240210",
    "end": "4245670"
  },
  {
    "text": "predicts the next word. Then what you can do is, you\ncan craft the sentence here,",
    "start": "4245670",
    "end": "4252510"
  },
  {
    "text": "such that this prediction is\nthe only thing the model can do, predict the next word\ngiven the previous text,",
    "start": "4252510",
    "end": "4259650"
  },
  {
    "text": "is actually solving\nthe task for you. And so what you can do is you\ncan construct a sentence like,",
    "start": "4259650",
    "end": "4264870"
  },
  {
    "text": "classify the sentiment\nof the movies below as either\npositive or negative. Then you give it an example of a\nmovie review which is positive,",
    "start": "4264870",
    "end": "4273520"
  },
  {
    "text": "maybe. This has got to be one of the\nbest episodes blah, blah, blah, with a positive sentiment.",
    "start": "4273520",
    "end": "4278820"
  },
  {
    "text": "And then you give\nit another example maybe with negative sentiment. And then you have this review\nthat you'd like to classify.",
    "start": "4278820",
    "end": "4285480"
  },
  {
    "text": "And then you fit in\nthe text of the review, and then you have\nsentiment and then blank.",
    "start": "4285480",
    "end": "4292850"
  },
  {
    "text": "Then you use the model\nto predict the next word. You use the model to\npredict what goes-- what should you\nreplace blank with,",
    "start": "4292850",
    "end": "4299810"
  },
  {
    "text": "which is exactly consistent\nwith the API of the model, which is predict the next\nword given some context.",
    "start": "4299810",
    "end": "4307470"
  },
  {
    "text": "Then if the model\npredicts positive, then you're going to classify\nthis as a positive example.",
    "start": "4307470",
    "end": "4312630"
  },
  {
    "text": "And if the model\noutputs negative there, then they're going to classify\nit as a negative example. And so this is an\nexample of prompting.",
    "start": "4312630",
    "end": "4319860"
  },
  {
    "text": "And of course, there are many\nsmarter ways of doing it. There's a whole prompt\nengineering kind of job",
    "start": "4319860",
    "end": "4325830"
  },
  {
    "text": "where people supposedly are\ngood at extracting knowledge from the models by\ncrafting smart prompts.",
    "start": "4325830",
    "end": "4332850"
  },
  {
    "text": "But that's the basic idea. Getting the knowledge from these\ngenerative models by crafting",
    "start": "4332850",
    "end": "4340890"
  },
  {
    "text": "prompts such that\nencode the kind of task that you want to\nsolve, without actually",
    "start": "4340890",
    "end": "4347010"
  },
  {
    "text": "going through representations. Of course, it's also\npossible to just fine tune the model, which is closer\nto the idea of getting",
    "start": "4347010",
    "end": "4353820"
  },
  {
    "text": "representations. You could also\njust take the model and then fine tune it to solve\nthe tasks you care about.",
    "start": "4353820",
    "end": "4361390"
  },
  {
    "text": "So presumably, the\npre-trained model is already mapping the\ninputs, like a sentence here, to some\nrepresentation that",
    "start": "4361390",
    "end": "4368440"
  },
  {
    "text": "is good for predicting\nthe next word. So you might be able\nto fine tune the model to do something interesting.",
    "start": "4368440",
    "end": "4374110"
  },
  {
    "text": "That's also quite successful. I think prompting\nis perhaps nicer because it doesn't\ninvolve any training.",
    "start": "4374110",
    "end": "4381520"
  },
  {
    "text": "That is somewhat special\nfor language models. And it tends to\nwork pretty well,",
    "start": "4381520",
    "end": "4387560"
  },
  {
    "text": "especially if the language\nmodel is a very powerful one. And again, what kind of tasks\nare you going to consider?",
    "start": "4387560",
    "end": "4398650"
  },
  {
    "text": "That's still pretty\nmuch very much an open problem in terms\nof which generative model",
    "start": "4398650",
    "end": "4404800"
  },
  {
    "text": "of language is better. There's many of them out there. How can you say whether model\nA is better than model B?",
    "start": "4404800",
    "end": "4413170"
  },
  {
    "text": "And you can compute perplexity,\nwhich is the same as likelihood but does not quite reflect\nwhat we care about.",
    "start": "4413170",
    "end": "4421010"
  },
  {
    "text": "Maybe what we care about is\nall these kind of scenarios that we might want to be able\nto ask questions to the language",
    "start": "4421010",
    "end": "4429050"
  },
  {
    "text": "model. Or we might want to ask it\nto do movie reviews for us, or whatever it is that we\ncare about, or do math,",
    "start": "4429050",
    "end": "4437290"
  },
  {
    "text": "or solve riddles for us,\nor do question answering. And so again, this is a space\nwhere it's not clear what",
    "start": "4437290",
    "end": "4444940"
  },
  {
    "text": "is the right task to consider. And so one way to go\nabout it is to consider",
    "start": "4444940",
    "end": "4450790"
  },
  {
    "text": "a lot of different tasks, a\nlot of different scenarios, a lot of different\nmetrics because maybe you",
    "start": "4450790",
    "end": "4457090"
  },
  {
    "text": "care about accuracy, but maybe\nyou care about other things. And you can try to see how these\ndifferent models that exist out",
    "start": "4457090",
    "end": "4465160"
  },
  {
    "text": "there perform on all\nthese different tasks. So you can consider\ndifferent scenarios.",
    "start": "4465160",
    "end": "4470740"
  },
  {
    "text": "You can consider different\nadaptation strategies, let's say, different\nprompting strategies.",
    "start": "4470740",
    "end": "4477250"
  },
  {
    "text": "You can have different\nmetrics, for example, accuracy or whatever it is, when\nyou use the model to solve",
    "start": "4477250",
    "end": "4483100"
  },
  {
    "text": "the task that way,\nand then you can compare many of the\nexisting models that are out there with respect\nto all these metrics.",
    "start": "4483100",
    "end": "4490030"
  },
  {
    "text": "And that allows you to maybe\nsay a more precise way, this model is better than\nthis other model with respect",
    "start": "4490030",
    "end": "4496660"
  },
  {
    "text": "to these metrics on\nthese kind of scenarios. So then there is different\nefforts out there. There is one from\nStanford, Helm other",
    "start": "4496660",
    "end": "4503998"
  },
  {
    "text": "looked at a lot of\ndifferent metrics, a lot of different scenarios,\na lot of different-- which is very thorough.",
    "start": "4503998",
    "end": "4510160"
  },
  {
    "text": "There is one that was led\nby Google, where they also was more like\ncollaborative effort",
    "start": "4510160",
    "end": "4515830"
  },
  {
    "text": "where they asked all the\npeople around the world to come up with\ntasks, and then they are all part of this\nbig benchmark where",
    "start": "4515830",
    "end": "4524350"
  },
  {
    "text": "there is over 200 tasks that\nyou can ask your language model to solve. And you can see the\nperformance that you get",
    "start": "4524350",
    "end": "4532400"
  },
  {
    "text": "across these different tasks. How could we adopt this\nidea of prompting to task",
    "start": "4532400",
    "end": "4540119"
  },
  {
    "text": "like the inputs where\nthere is no natural way of sequentializing the data?",
    "start": "4540120",
    "end": "4546630"
  },
  {
    "text": "So you're thinking of images\nor something like that? Yeah, I think it's\na good question",
    "start": "4546630",
    "end": "4554010"
  },
  {
    "text": "that somehow the prompting idea\nhas not quite been applied So.",
    "start": "4554010",
    "end": "4559289"
  },
  {
    "text": "Heavily to the-- if you have a\ngood generative model of images, how can you use it to solve\ntasks through prompts?",
    "start": "4559290",
    "end": "4566910"
  },
  {
    "text": "And it's not as natural\nbecause the output is an image. And it's easy to\nthink of the output",
    "start": "4566910",
    "end": "4572340"
  },
  {
    "text": "to map, say, labels to text,\nor even bounding boxes to text.",
    "start": "4572340",
    "end": "4580380"
  },
  {
    "text": "And so if the API of your\nmodel has text as an output, it's relatively easy to use it\nto solve a variety of tasks.",
    "start": "4580380",
    "end": "4588040"
  },
  {
    "text": "I think it's a bit less\nnatural if the API has images as an output, but\nit might be possible.",
    "start": "4588040",
    "end": "4594010"
  },
  {
    "text": "I think it's an\ninteresting kind of area that people are still exploring. And yeah, I don't think there is\nanything particularly good there",
    "start": "4594010",
    "end": "4600610"
  },
  {
    "text": "but yeah. So GPT 4 B actually\nanswers questions",
    "start": "4600610",
    "end": "4607910"
  },
  {
    "text": "about answers zero shot. There's no idea of\nprompting there. Do you have an\nidea how it works?",
    "start": "4607910",
    "end": "4615270"
  },
  {
    "text": "Well, they don't say it, yeah. But yeah, it's probably been-- the underlying mechanics is just\npredicting the next word, right?",
    "start": "4615270",
    "end": "4624650"
  },
  {
    "text": "And then it has been probably\ndone something instruction fine tuning, so it has\nbeen actually pre-trained",
    "start": "4624650",
    "end": "4631940"
  },
  {
    "text": "and a lot of unsupervised text\nis predicting the next word. That's just compression.",
    "start": "4631940",
    "end": "4637310"
  },
  {
    "text": "It wouldn't probably\ndo very well if you start asking\nquestions in a zero-shot way. And so what you have to do,\nis you have to fine tune it",
    "start": "4637310",
    "end": "4644480"
  },
  {
    "text": "on a slightly different kind\nof data set that is emphasizing more the sort of tasks that\nyou might expect the model",
    "start": "4644480",
    "end": "4652130"
  },
  {
    "text": "to be asked at inference time. And again, there is a\nlittle bit of a question",
    "start": "4652130",
    "end": "4657800"
  },
  {
    "text": "of what is the right way of-- what kind of task, what\nis the right distribution, do we care about movie\nreviews, or do we",
    "start": "4657800",
    "end": "4663177"
  },
  {
    "text": "care about question\nanswering, and how do we weight those tools? It's not clear what's\nthe-- that seems to help,",
    "start": "4663177",
    "end": "4670130"
  },
  {
    "text": "but we don't yet have a good\nhandle in terms of evaluating",
    "start": "4670130",
    "end": "4675440"
  },
  {
    "text": "or seeing what works\nand what doesn't. It's very coarse at the moment.",
    "start": "4675440",
    "end": "4680900"
  },
  {
    "text": "I think it's becoming clear,\nwhen it comes to text maybe. But maybe I need to look\nat the image model, like,",
    "start": "4680900",
    "end": "4688405"
  },
  {
    "text": "all that stuff construction,\nfine tuning, and stuff [INAUDIBLE] and like Alpaca\nhere, reproduce and then",
    "start": "4688405",
    "end": "4694670"
  },
  {
    "text": "since then other models. But what about the image stuff? We're doing actually\nusing similar things in--",
    "start": "4694670",
    "end": "4701120"
  },
  {
    "text": "just right now, we're\nbasically working on applying-- I mean, now, we are\nnot the only ones. But people are trying\nto do basically you",
    "start": "4701120",
    "end": "4709878"
  },
  {
    "text": "train a model on a lot of\nimages on the internet, but then maybe you\nreally have there's some kind of\nunderlying preference",
    "start": "4709878",
    "end": "4716600"
  },
  {
    "text": "that we would like the\nmodel to generate images with higher aesthetic value.",
    "start": "4716600",
    "end": "4721880"
  },
  {
    "text": "Or maybe we would like\nthe model to be non-toxic, or we would like the model\nto be more fair, less biased,",
    "start": "4721880",
    "end": "4727699"
  },
  {
    "text": "and how do you adapt the model\nto the kind of downstream use?",
    "start": "4727700",
    "end": "4734100"
  },
  {
    "text": "And so what you can do is you\ncan collect preference data. And maybe you can show\nyou can have a caption.",
    "start": "4734100",
    "end": "4741380"
  },
  {
    "text": "You produce two\nimages, and you ask a user which one do you prefer? You get preference data on what\nwe like and what we don't like,",
    "start": "4741380",
    "end": "4747590"
  },
  {
    "text": "and then you can fine\ntune the diffusion model to be more consistent with\nthis kind of preference data.",
    "start": "4747590",
    "end": "4753630"
  },
  {
    "text": "So that's possible too. Yeah? I have a question. So what are the pros and\ncons for solving the task",
    "start": "4753630",
    "end": "4764260"
  },
  {
    "text": "by fine tuning a large language\nmodel or prompt engineering? Yeah, so prompting\nis great because you",
    "start": "4764260",
    "end": "4769930"
  },
  {
    "text": "don't have to actually--\nyou don't have to have access to any compute. You don't even need to\nknow how to program, right?",
    "start": "4769930",
    "end": "4776230"
  },
  {
    "text": "The only thing you\nneed to do is you need to be able to specify\nin natural language what you want the model to do.",
    "start": "4776230",
    "end": "4781550"
  },
  {
    "text": "And so it can be completely\ndone in a black box way without even having to\nknow what the model is",
    "start": "4781550",
    "end": "4788170"
  },
  {
    "text": "doing, what the weights are. Fine tuning requires\nyou to actually train",
    "start": "4788170",
    "end": "4794200"
  },
  {
    "text": "the model, for a\nlittle bit, at least, on some new data or some\nnew task or something new.",
    "start": "4794200",
    "end": "4800150"
  },
  {
    "text": "So the buyer is a lot\nhigher in terms of the cost and the expertise that\nis required for that.",
    "start": "4800150",
    "end": "4807278"
  },
  {
    "text": "[INAUDIBLE] Depends, typically, it's a\nbetter way of doing things,",
    "start": "4807278",
    "end": "4812290"
  },
  {
    "text": "I think, although, people have\ngotten pretty good at prompting. So yeah, I think it\ndepends on the task. ",
    "start": "4812290",
    "end": "4820570"
  },
  {
    "text": "Cool, yeah, so I guess we're out\nof time, so it's perfect timing. But basically, I think it's\ngoing to take away very",
    "start": "4820570",
    "end": "4829380"
  },
  {
    "text": "high-level messages that\nit's still a pretty much-- it's still a pretty\nopen kind of area how to evaluate\ngenerative models.",
    "start": "4829380",
    "end": "4836430"
  },
  {
    "text": "There is still a\nlot more that we don't know that we have some\ncoarse ways of comparing in models.",
    "start": "4836430",
    "end": "4841660"
  },
  {
    "text": "And we have a\nsense of, OK, we're making progress over the years. But there is a lot\nmore work to be",
    "start": "4841660",
    "end": "4847620"
  },
  {
    "text": "done in this space in terms of\ncoming up with better metrics. And even if you have all\nthese large-scale benchmarks,",
    "start": "4847620",
    "end": "4856455"
  },
  {
    "text": "where you have a lot of\ntasks, a lot of metrics, it's still not obvious\nhow you weight them and what is the right\ndistribution of tasks you might",
    "start": "4856455",
    "end": "4862908"
  },
  {
    "text": "expect to use the model on. And so yeah, lots of work\nto be done in this space.",
    "start": "4862908",
    "end": "4868630"
  },
  {
    "text": "But hopefully, this was helpful. I know many of you\nare starting to get into the weeds of the project.",
    "start": "4868630",
    "end": "4874730"
  },
  {
    "text": "And so I'm sure you\nhave a lot of questions on how to evaluate models. And so hopefully, you got a\nsense of what's out there.",
    "start": "4874730",
    "end": "4881324"
  },
  {
    "text": "Unfortunately, we don't have\nany definitive answer yet. But at least that\ngives you some ideas of the kind of things you\ncan use for the project.",
    "start": "4881325",
    "end": "4888840"
  },
  {
    "start": "4888840",
    "end": "4894000"
  }
]
[
  {
    "start": "0",
    "end": "5510"
  },
  {
    "text": "Hi, everybody. Welcome back to CS224N but first\njust a couple of announcements.",
    "start": "5510",
    "end": "13100"
  },
  {
    "text": "Originally this was going to be\nthe day when assignment 5 was due, but as you've seen\nwe're giving you one",
    "start": "13100",
    "end": "19250"
  },
  {
    "text": "extra day so it's now\ndue Friday at 4:30. We do realize that\nassignment 5 has",
    "start": "19250",
    "end": "25400"
  },
  {
    "text": "been a bit of a tough\nchallenge for many people, that we've been trying to help\npeople out of office hours",
    "start": "25400",
    "end": "31550"
  },
  {
    "text": "and otherwise. So I hope at the\nend of the day it will seem like it was a really\ngood learning experience",
    "start": "31550",
    "end": "37220"
  },
  {
    "text": "to really get some much\nmore kind of close hands on look at how\ntransformers work,",
    "start": "37220",
    "end": "42920"
  },
  {
    "text": "rather than simply being\nloading up a transformers as a black mystery box.",
    "start": "42920",
    "end": "49760"
  },
  {
    "text": "After Friday, I guess there's\nno rest since we do really hope that you can\nsort of basically",
    "start": "49760",
    "end": "56750"
  },
  {
    "text": "immediately transition to\nworking on final projects since there's basically four\nweeks to go on final projects.",
    "start": "56750",
    "end": "63470"
  },
  {
    "text": "And in particular, we're hoping\nto get feedback on your project proposals back by next Tuesday\nto help that process along",
    "start": "63470",
    "end": "72050"
  },
  {
    "text": "with people, we have to\nget started on them soon. And it's just\nmaybe a good moment",
    "start": "72050",
    "end": "81710"
  },
  {
    "text": "to say that we do\nreally appreciate all the people putting tons of\neffort into these assignments.",
    "start": "81710",
    "end": "87049"
  },
  {
    "text": "And we like that\nseveral of the keenness we're seeing from the students. OK.",
    "start": "87050",
    "end": "92540"
  },
  {
    "text": "So with that out of\nthe way, today I'm delighted to have giving today's\nlecture on neural language",
    "start": "92540",
    "end": "99830"
  },
  {
    "text": "generation Antoine\nBosselut who is at present a\npostdoc at Stanford. He's someone who's\ndone a lot of work",
    "start": "99830",
    "end": "106520"
  },
  {
    "text": "on natural language generation\nin his previous life as a University of\nWashington PhD student.",
    "start": "106520",
    "end": "114170"
  },
  {
    "text": "And next year he's\ngoing to be taking up a position as a\nprofessor in Switzerland.",
    "start": "114170",
    "end": "120689"
  },
  {
    "text": "OK. So welcome, Antoine. Thanks Chris, that's a\nvery kind introduction.",
    "start": "120690",
    "end": "128850"
  },
  {
    "text": "It's great to be here giving\nthis lecture in CS224N.",
    "start": "128850",
    "end": "135050"
  },
  {
    "text": "Particularly on one\nof my favorite topics in deep learning for NLP,\nnatural language generation.",
    "start": "135050",
    "end": "144220"
  },
  {
    "text": "So hopefully by the end of\nthis lecture most of you will have at least learned a\nbit about NLG with deep learning",
    "start": "144220",
    "end": "151220"
  },
  {
    "text": "and hopefully be motivated to\nstart doing some research on it or launch a startup in\nNLG, or perhaps go work",
    "start": "151220",
    "end": "158480"
  },
  {
    "text": "on it at a larger organization. OK.",
    "start": "158480",
    "end": "164280"
  },
  {
    "text": "So to start, I think it might\nbe really helpful to define what we mean at a high level when\nwe talk about natural language",
    "start": "164280",
    "end": "170250"
  },
  {
    "text": "generation because over\nthe last few years, the definition has\nactually sort of changed",
    "start": "170250",
    "end": "176040"
  },
  {
    "text": "and has really\ngrown as a sub-field to really encapsulate\nany part of NLP that",
    "start": "176040",
    "end": "182520"
  },
  {
    "text": "involves the production of\nwritten or spoken language. In other words, if\nyou're given some inputs",
    "start": "182520",
    "end": "189180"
  },
  {
    "text": "and your goal is to generate\ntext to describe, respond, translate or summarize\nthat piece of text,",
    "start": "189180",
    "end": "198000"
  },
  {
    "text": "NLG really focuses on\nhow you can actually build a system that\ncan automatically produce a coherent and\nuseful written piece of text",
    "start": "198000",
    "end": "207040"
  },
  {
    "text": "for human consumption. And it used to be a much\nmore limited research",
    "start": "207040",
    "end": "212910"
  },
  {
    "text": "area since many\ntasks that we now view as NLG problems\ndidn't actually involve much text production\nprior to neural networks.",
    "start": "212910",
    "end": "221500"
  },
  {
    "text": "But now that scope has\nexpanded considerably and we have this much larger\narea to sort of work in.",
    "start": "221500",
    "end": "229500"
  },
  {
    "text": "Unfortunately\nwe're not quite yet at the level of the\ntypes of AI NLG tools",
    "start": "229500",
    "end": "234540"
  },
  {
    "text": "that we've seen in pop culture\nand that we like to imagine, but we are starting to see\nmany areas where NLG tools are",
    "start": "234540",
    "end": "241950"
  },
  {
    "text": "having a massive impact. To start with,\nmachine translation",
    "start": "241950",
    "end": "247410"
  },
  {
    "text": "is kind of the classical\nexample of an NLG task",
    "start": "247410",
    "end": "253950"
  },
  {
    "text": "thhese days, ever\nsince the tasks moved to neural networks and\nan NLG framework around 2014",
    "start": "253950",
    "end": "261060"
  },
  {
    "text": "or so. And now we've seen\na rapid improvement in the quality and applicability\nof translation systems.",
    "start": "261060",
    "end": "267310"
  },
  {
    "text": "In fact, you can often\nuse Google Translate for most of your kind of\nretail translation needs",
    "start": "267310",
    "end": "276090"
  },
  {
    "text": "as a good starting point. Similarly, NLG\ntechnologies really underpin some of\nthe dialogue systems",
    "start": "276090",
    "end": "282600"
  },
  {
    "text": "that you might interact\nwith on a daily basis. Any time you use, let's say\nSiri, Alexa, Cortana, Google",
    "start": "282600",
    "end": "289110"
  },
  {
    "text": "Home, Bixby, or pretty much any\nother major company's dialogue system, there's a good chance\nthat there's a neural NLG",
    "start": "289110",
    "end": "295949"
  },
  {
    "text": "component embedded\nin that system that's involved with providing you\nan answer to your query.",
    "start": "295950",
    "end": "301430"
  },
  {
    "text": "And there's really\nstill a ton of progress to be made in this\narea, and it's led to some major companies to\nactually crowd source chat bot",
    "start": "301430",
    "end": "308340"
  },
  {
    "text": "technologies from researchers\nand students such as yourself to continue to try to make\nbig advances in this area.",
    "start": "308340",
    "end": "316680"
  },
  {
    "text": "We're also seeing lots\nof NLG technologies used",
    "start": "316680",
    "end": "321690"
  },
  {
    "text": "in areas such as summarization\nwhere systems often have to aggregate\ninformation from potentially",
    "start": "321690",
    "end": "329280"
  },
  {
    "text": "multiple sources and rephrase\nthe most salient content",
    "start": "329280",
    "end": "334470"
  },
  {
    "text": "in a shortened but\nstill very engaging way. While our go to example\nfor summarization",
    "start": "334470",
    "end": "341430"
  },
  {
    "text": "is generally related to, let's\nsay generating news highlights, summarization systems\nhave actually achieved",
    "start": "341430",
    "end": "347250"
  },
  {
    "text": "broad applicability\nin many areas where we address content,\nsuch as summarizing emails or summarizing\nmeeting transcripts.",
    "start": "347250",
    "end": "356190"
  },
  {
    "text": "And there's actually many\nmore areas not listed here. I don't actually\nput it on the slide, but a few months\nback a tool called",
    "start": "356190",
    "end": "362220"
  },
  {
    "text": "Semantic Scholar actually\ndeveloped a neural system for generating summaries\nof scientific papers, which",
    "start": "362220",
    "end": "367530"
  },
  {
    "text": "is something that I personally\nend up using quite a bit as an example of how\nhumans can interact",
    "start": "367530",
    "end": "373409"
  },
  {
    "text": "with these technologies. But these modalities aren't\nactually limited to text in",
    "start": "373410",
    "end": "378810"
  },
  {
    "text": "or text out. So actually the classical NLG\narea that I mentioned earlier is how the tasks\nused to be framed",
    "start": "378810",
    "end": "385470"
  },
  {
    "text": "was actually around what we now\ncall data to text generation. So can you learn to\ncompile or let's say",
    "start": "385470",
    "end": "391290"
  },
  {
    "text": "summarize the most interesting\nfacts from a table, or a knowledge graph, or\nsome type of data stream.",
    "start": "391290",
    "end": "398220"
  },
  {
    "text": "That way humans can get the most\ninteresting and salient content that's being presented\nin these data structures",
    "start": "398220",
    "end": "405360"
  },
  {
    "text": "rapidly, and in an\neasier to adjust format than having to look through\nthe structures themselves.",
    "start": "405360",
    "end": "411840"
  },
  {
    "text": "We've also seen a\nlot of recent work in visual description\nthat tries to use language",
    "start": "411840",
    "end": "417330"
  },
  {
    "text": "to describe the content\nin images or videos. So around 2014 or so we start\nto see the first neural NLG",
    "start": "417330",
    "end": "423690"
  },
  {
    "text": "systems in the space,\nand they've really continued to mature\nin the last six years.",
    "start": "423690",
    "end": "429690"
  },
  {
    "text": "And now we actually tackle much\nmore challenging description tasks such as generating\nfull descriptive paragraphs",
    "start": "429690",
    "end": "435990"
  },
  {
    "text": "of scenes or generating\nstreams of visual, generating descriptions for streams\nof visual content",
    "start": "435990",
    "end": "442830"
  },
  {
    "text": "such as video captioning. And these tools have\nreally broad applicability",
    "start": "442830",
    "end": "448800"
  },
  {
    "text": "in different areas of AI. And finally the last\nsort of application",
    "start": "448800",
    "end": "454040"
  },
  {
    "text": "I kind of want to mention\nis that we've also started seeing NLG\nsystems being developed in more creative applications\nsuch as story generation",
    "start": "454040",
    "end": "462050"
  },
  {
    "text": "where AI systems can\nnow help humans write short stories, blog posts, or\neven full books in some case",
    "start": "462050",
    "end": "468470"
  },
  {
    "text": "as creative writing assistants. In another area such\nas poetry generation,",
    "start": "468470",
    "end": "473720"
  },
  {
    "text": "we can actually have kind\nof full automated settings where you can have AI agents\nthat can generate something",
    "start": "473720",
    "end": "478970"
  },
  {
    "text": "like a sonnet, and\nin fact condition that on a lot of demands\nthat are given through a user",
    "start": "478970",
    "end": "484550"
  },
  {
    "text": "interface. So I hope that by\nthis point I've really given you a look into\nthe breadth of NLG applications",
    "start": "484550",
    "end": "493940"
  },
  {
    "text": "and how it sort of\nencompasses any task that you might think of that\ninvolves production of text.",
    "start": "493940",
    "end": "501890"
  },
  {
    "text": "And each of these tasks really\nrequires different algorithms and different models and a\ndifferent way of designing",
    "start": "501890",
    "end": "507380"
  },
  {
    "text": "the system to get right. But what they have in\ncommon is that a lot of them are powered by next\ngeneration advances",
    "start": "507380",
    "end": "514940"
  },
  {
    "text": "in deep learning for NLG. And the goal of today\nis to really give you",
    "start": "514940",
    "end": "521880"
  },
  {
    "text": "the introduction to these\ntopics that really allows you to contribute to the next\nera of these technologies",
    "start": "521880",
    "end": "528360"
  },
  {
    "text": "and in designing deep\nlearning systems for NLG. And so I think to\nstart what might",
    "start": "528360",
    "end": "534300"
  },
  {
    "text": "be interesting to do is\nto quickly recap topics that you may have seen\nin previous lectures",
    "start": "534300",
    "end": "540569"
  },
  {
    "text": "but which are going to\nbe very relevant today when we're trying to\ndesign an NLG system.",
    "start": "540570",
    "end": "547320"
  },
  {
    "text": "And what we're effectively\ntrying to do in the setting is take a sequence\nof tokens as inputs",
    "start": "547320",
    "end": "553110"
  },
  {
    "text": "and produce new text that is\nconditioned on this inputs. And then what we typically call\nthe auto regressive setting,",
    "start": "553110",
    "end": "559150"
  },
  {
    "text": "which is the most common sort\nof text generation setting. We take these produced\ntokens of text",
    "start": "559150",
    "end": "565200"
  },
  {
    "text": "and we feed them\nback into our model to generate the next\ntoken in the sequence that we want to generate.",
    "start": "565200",
    "end": "572810"
  },
  {
    "text": "But so to really\nunderstand what's going on in an auto\nregressive NLG system, what we really\nneed to start to do",
    "start": "572810",
    "end": "578990"
  },
  {
    "text": "is look at what happens\nfor the generation of an individual token\nsince further stages really depend on taking\nthat generated token",
    "start": "578990",
    "end": "585529"
  },
  {
    "text": "and passing it back in as\ninput and doing the same thing. So what happens at a low\nlevel is that your model takes",
    "start": "585530",
    "end": "591290"
  },
  {
    "text": "in the sequence of\ninputs, so these y's, and it computes a vector of\nscores using the model itself.",
    "start": "591290",
    "end": "599120"
  },
  {
    "text": "And each index in that vector\ncorresponds to the score for a token in your vocabulary. So the only tokens that\nyour model is actually",
    "start": "599120",
    "end": "605930"
  },
  {
    "text": "allowed to generate. And then what you do is that\nyou compute a probability distribution over\nthese scores using",
    "start": "605930",
    "end": "612410"
  },
  {
    "text": "what we call a soft max function\nto compute a probability estimate for each token\nin your vocabulary",
    "start": "612410",
    "end": "620000"
  },
  {
    "text": "given the context\nthat precedes it. And as a shorthand, I'll just\nmention that sometimes I'll",
    "start": "620000",
    "end": "627290"
  },
  {
    "text": "remove the W from this\nprobability equation, but just know that\nwhen I write out the probability of a token\ny at time t, what I mean",
    "start": "627290",
    "end": "634790"
  },
  {
    "text": "is the probability that\ny(t) is a particular word. So it's kind of a\nvariable assignment.",
    "start": "634790",
    "end": "643320"
  },
  {
    "text": "But so what actually is the\noutput of what we typically call the text generation\nmodel at this point",
    "start": "643320",
    "end": "648440"
  },
  {
    "text": "is actually this\nvector of scores, and then that vector gets\npassed to the softmax function to give us a probability\ndistribution over the set",
    "start": "648440",
    "end": "655430"
  },
  {
    "text": "of tokens in the vocabulary. And then to actually\ngenerate a token, we can define what we call\na decoding algorithm, that",
    "start": "655430",
    "end": "662790"
  },
  {
    "text": "is a function that takes in\nthis distribution peak over all the tokens of the vocabulary.",
    "start": "662790",
    "end": "668370"
  },
  {
    "text": "And it defines a function\nfor selecting a token from this distribution\nas the next token that",
    "start": "668370",
    "end": "675300"
  },
  {
    "text": "is produced by our NLG system. And for that distribution to\nbe calibrated in such a way",
    "start": "675300",
    "end": "681600"
  },
  {
    "text": "that it means anything, we need\nto train the model to actually be able to do the task.",
    "start": "681600",
    "end": "687139"
  },
  {
    "text": "And so the most common way of\ntraining text generation models is to use maximum\nlikelihood training.",
    "start": "687140",
    "end": "694470"
  },
  {
    "text": "And despite its name,\nwe don't actually maximize likelihoods, we\nactually minimize negative log likelihoods.",
    "start": "694470",
    "end": "700350"
  },
  {
    "text": "And what that actually is just\na multi class classification task where each word\nin our vocabulary",
    "start": "700350",
    "end": "706410"
  },
  {
    "text": "is a class that can be\npredicted by the model. And so at each step\nin the sequence we're actually trying to predict\nthe class that corresponds",
    "start": "706410",
    "end": "713880"
  },
  {
    "text": "to the word that comes next\nin the sequence of text that we're trying to train on. And this word is often called\nthe gold or ground truth token.",
    "start": "713880",
    "end": "722210"
  },
  {
    "text": "That was just kind of\ninterchangeable vocabulary that we use. And another term for this\ndeep training algorithm",
    "start": "722210",
    "end": "729480"
  },
  {
    "text": "is teacher forcing. So you might see\nthese expressions kind of used interchangeably if\nyou read papers on this topic.",
    "start": "729480",
    "end": "736973"
  },
  {
    "text": "But so at each\nstep, you're really computing a loss term,\nthat is the negative log likelihood of predicting this\ngold token y1 at every step.",
    "start": "736973",
    "end": "745000"
  },
  {
    "text": "So in these slides whenever\nyou see an asterisk next to a y, that means that\nthis is a gold token that",
    "start": "745000",
    "end": "750510"
  },
  {
    "text": "comes from a training sequence. And you could do this\nfor multiple steps adding up the log\nlikelihoods along the way.",
    "start": "750510",
    "end": "758070"
  },
  {
    "text": "Eventually, you're\ngoing to arrive at the end of your\ngold sequence, and you'll be able to compute\ngradients with respect",
    "start": "758070",
    "end": "763920"
  },
  {
    "text": "to this summed loss term for\nevery parameter in your model, which allows you to update it so\nthat the next time around, when",
    "start": "763920",
    "end": "770760"
  },
  {
    "text": "you see the sequence,\nyour model is more confident in the probability\nthat the sequence is a correct sequence,\ngiven the same context it",
    "start": "770760",
    "end": "778019"
  },
  {
    "text": "has seen before. But most of this\nshould just be a recap from previous lectures on\nlanguage modeling and machine",
    "start": "778020",
    "end": "784620"
  },
  {
    "text": "translation. But now that we've got\nthat out of the way, let's get to the fun part and\ntalk about some new topics.",
    "start": "784620",
    "end": "793982"
  },
  {
    "text": "The first one of which is\ndecoding, which is actually one of my favorite topics in\nnatural language generation",
    "start": "793982",
    "end": "799490"
  },
  {
    "text": "research. So if you recall, your\ndecoding algorithm is really the\nfunction that takes",
    "start": "799490",
    "end": "804800"
  },
  {
    "text": "in this induced\nprobability distribution from your model over\nthe next possible tokens",
    "start": "804800",
    "end": "810500"
  },
  {
    "text": "that can be\ngenerated and selects which one of those tokens\nshould be outputted.",
    "start": "810500",
    "end": "816290"
  },
  {
    "text": "So once your model was\ntrained, this distribution should be meaningful,\nand you want to be able to generate\na sensible next token.",
    "start": "816290",
    "end": "824600"
  },
  {
    "text": "And then you can use these\ngenerated next tokens-- so the blue y hats here-- as inputs in the next\nstep of the model, which",
    "start": "824600",
    "end": "831320"
  },
  {
    "text": "allows you to recompute\na new distribution, decode a new token,\nrepeat the process, and eventually end up\nwith a full sequence",
    "start": "831320",
    "end": "837980"
  },
  {
    "text": "that your model has now\ngenerated given a fixed starting sequence of text.",
    "start": "837980",
    "end": "844019"
  },
  {
    "text": "And so let's talk a bit\nabout the algorithms that we can use to decode\ntokens from this distribution.",
    "start": "844020",
    "end": "851139"
  },
  {
    "text": "So you've actually\nalready seen some of these in a previous lecture\non neural machine translation",
    "start": "851140",
    "end": "856200"
  },
  {
    "text": "I believe where you started\noff by seeing a relatively simple decoding algorithm\nthat nonetheless remains",
    "start": "856200",
    "end": "862800"
  },
  {
    "text": "very popular, argmax decoding. And with argmax decoding\nyou pretty much just take the highest probability\ntoken from your distribution",
    "start": "862800",
    "end": "871350"
  },
  {
    "text": "as the decoded token\nand feed it back into the model to get the\ndistribution at the next step.",
    "start": "871350",
    "end": "876810"
  },
  {
    "text": "And you keep repeating this\nprocess, and it's very nice, and it's very convenient.",
    "start": "876810",
    "end": "881848"
  },
  {
    "text": "And you've also I think\nlearned about beam search where you can scale up these\ngreedy methods by doing a wider",
    "start": "881848",
    "end": "888090"
  },
  {
    "text": "search over the set\nof tokens that follow, the set of most\nlikely tokens that follow to try to find a\nsubsequence that is a lower",
    "start": "888090",
    "end": "896820"
  },
  {
    "text": "overall negative\nlog likelihood even if in the intermediate\nstep it tends",
    "start": "896820",
    "end": "902820"
  },
  {
    "text": "to be higher than what would\nbe the argmax decoded token. And while these greedy\nmethods work great",
    "start": "902820",
    "end": "909600"
  },
  {
    "text": "for machine translation\nand in other tasks as well, such as\nsummarization, they",
    "start": "909600",
    "end": "915720"
  },
  {
    "text": "do tend to be problematic in\nmany other text generation tasks, particularly ones that\nend up being more open ended.",
    "start": "915720",
    "end": "923018"
  },
  {
    "text": "So one of these big\nproblems that they have is that they often end\nup repeating themselves. So here in this example\nfrom Holtzmann et al 2020,",
    "start": "923018",
    "end": "931170"
  },
  {
    "text": "we can see that after\naround 20 or sorry, yeah, 60 tokens or\nso of generation,",
    "start": "931170",
    "end": "937230"
  },
  {
    "text": "the model really devolves into\njust repeating the same thing over and over again. And this actually tends to\nhappen a lot in text generation",
    "start": "937230",
    "end": "944850"
  },
  {
    "text": "systems. Repetition was actually\none of the biggest problems that we tried to tackle in\ntext generation for many years",
    "start": "944850",
    "end": "951389"
  },
  {
    "text": "and still face to this day. And I think it's worth taking a\nlook at why repetition happens",
    "start": "951390",
    "end": "959160"
  },
  {
    "text": "a bit more analytically\nso that you can perhaps better understand the\ninteraction between your model",
    "start": "959160",
    "end": "965400"
  },
  {
    "text": "and your decoding algorithm. So just as a quick little\nvisual demonstration,",
    "start": "965400",
    "end": "970560"
  },
  {
    "text": "here I'm showing you the step\nby step negative log likelihoods from two different\nlanguage models,",
    "start": "970560",
    "end": "975690"
  },
  {
    "text": "one based on recurrent\nneural networks and one based on a transformer\nlanguage model called GPT.",
    "start": "975690",
    "end": "982380"
  },
  {
    "text": "And I'm showing this plot for a\nparticular phrase I don't know, which for anyone who's\nworked in chat bots",
    "start": "982380",
    "end": "989550"
  },
  {
    "text": "has probably seen many times,\npotentially in nightmares.",
    "start": "989550",
    "end": "994790"
  },
  {
    "text": "It's not a very interesting\nplot, though what we do see is that the\ntransformer model does tend to be a bit less confident\nin the probability of each word",
    "start": "994790",
    "end": "1002900"
  },
  {
    "text": "than the recurrent\nneural network does. What's more\ninteresting though is what happens if I repeat the\nsame phrase multiple times",
    "start": "1002900",
    "end": "1009410"
  },
  {
    "text": "in a row. And one of the things\nthat we notice here is that the repetition\nof this phrase",
    "start": "1009410",
    "end": "1014750"
  },
  {
    "text": "actually causes the\ntoken level negative log likelihoods to get\nlower and lower for each",
    "start": "1014750",
    "end": "1020839"
  },
  {
    "text": "of these tokens, which actually\nmeans that the model is becoming more confident that\nthese are the right tokens",
    "start": "1020840",
    "end": "1026449"
  },
  {
    "text": "and that they should\nprobably follow the preceding context as we generate\nit more times.",
    "start": "1026450",
    "end": "1031579"
  },
  {
    "text": "And this doesn't really\nsubside as the sequence gets longer and longer. And as you keep repeating\nthe same phrases again,",
    "start": "1031579",
    "end": "1040230"
  },
  {
    "text": "over and over again, the model\nbecomes more and more confident the next time around it\nshould say the same thing.",
    "start": "1040230",
    "end": "1047359"
  },
  {
    "text": "And while this actually\nkind of makes sense and that if you say the phrase\nlet's say I'm tired 15 times,",
    "start": "1047359",
    "end": "1053990"
  },
  {
    "text": "it's a fair bet\nthat on a 16th time you're actually going\nto say it again, it's not necessarily\nthe behavior that we want our generation\nsystems to get stuck in.",
    "start": "1053990",
    "end": "1063096"
  },
  {
    "text": "Another interesting thing\nto note here as an aside is that this\nbehavior is actually less problematic in\nrecurrent neural networks",
    "start": "1063097",
    "end": "1069980"
  },
  {
    "text": "than in transformer\nlanguage models. So you can see\nthat for the LSTM, the curve flattens\nafter a certain point.",
    "start": "1069980",
    "end": "1077220"
  },
  {
    "text": "And so if you remember in\nperhaps a previous lecture on why we might transform\nour language models,",
    "start": "1077220",
    "end": "1082633"
  },
  {
    "text": "one of their\nbenefits is that they don't have the\ntemporal bottleneck of tracking a state, which a\nrecurrent neural network tends",
    "start": "1082633",
    "end": "1089960"
  },
  {
    "text": "to have. And so the removal\nof that bottleneck actually ends up\nmaking them more prone to repetitive\nbehavior when you use",
    "start": "1089960",
    "end": "1095899"
  },
  {
    "text": "greedy algorithms to decode. And so what can we actually\ndo to reduce repetition",
    "start": "1095900",
    "end": "1101130"
  },
  {
    "text": "since it's a pretty big\nproblem in these systems? Well, there are actually quite\na few proposed approaches",
    "start": "1101130",
    "end": "1106470"
  },
  {
    "text": "in the last few years, some\nof which I'll summarize here, which range from\nthe kind of hacky",
    "start": "1106470",
    "end": "1112530"
  },
  {
    "text": "but surprisingly effective,\ndon't repeat any n-grams at inference time.",
    "start": "1112530",
    "end": "1117730"
  },
  {
    "text": "But there's also been training\ntime approaches to do it, such as having a\nloss function that minimizes the similarity\nbetween hidden",
    "start": "1117730",
    "end": "1124350"
  },
  {
    "text": "activations at\ndifferent time steps, or coverage loss that\npenalizes attending to the same tokens over time.",
    "start": "1124350",
    "end": "1131170"
  },
  {
    "text": "So if you change the inputs\nthat your model is allowed to focus on, it's\nnaturally going to produce different\ntext, or more recently",
    "start": "1131170",
    "end": "1137640"
  },
  {
    "text": "an unlikelihood objective\nthat actually penalizes outputting the same\nwords, which we'll talk a bit more about later.",
    "start": "1137640",
    "end": "1145540"
  },
  {
    "text": "But the truth is\nthat the problem here really lies in using greedy\nalgorithms in the first place.",
    "start": "1145540",
    "end": "1152910"
  },
  {
    "text": "In many applications\nof human language, humans don't actually speak in\na probability maximizing way.",
    "start": "1152910",
    "end": "1160660"
  },
  {
    "text": "So if you look at this plot\nfrom Holtzmann et al 2020, it shows the per time step\nprobability of human written",
    "start": "1160660",
    "end": "1167100"
  },
  {
    "text": "text in orange and beam\nsearch decoded text in blue on the same graph. And what you can see\nis that beam search",
    "start": "1167100",
    "end": "1173550"
  },
  {
    "text": "decoded text tends to\nbe very high probability with little variance over time. And this makes a lot of\nsense because it's literally",
    "start": "1173550",
    "end": "1180630"
  },
  {
    "text": "trying to maximize the\nprobability of the sequences that it produces. And a big part of that\nis maximizing the step",
    "start": "1180630",
    "end": "1186960"
  },
  {
    "text": "by step probabilities of\nthe tokens that it uses. But meanwhile we can see\nthat human error in text is a lot more variable, often\nactually dipping into very",
    "start": "1186960",
    "end": "1194430"
  },
  {
    "text": "low probability territory. That actually makes\na lot of sense if we could always predict human\ntext with high probability,",
    "start": "1194430",
    "end": "1201690"
  },
  {
    "text": "there would really be no reason\nto listen to each other speak since we know what\nwe were going to say.",
    "start": "1201690",
    "end": "1208012"
  },
  {
    "text": "But so ultimately what\nwe want to be able to do is to match the uncertainty\nof human language patterns in how we decode text, which\nis why, in many applications",
    "start": "1208012",
    "end": "1217590"
  },
  {
    "text": "that tend to have this\nhigher variability sampling from these distributions\nhas kind of become",
    "start": "1217590",
    "end": "1223200"
  },
  {
    "text": "a go to decoding\nmethod particularly in creative generation tasks.",
    "start": "1223200",
    "end": "1229140"
  },
  {
    "text": "And so with sampling,\nwe take the distribution over tokens that's\nproduced by our model",
    "start": "1229140",
    "end": "1234720"
  },
  {
    "text": "and we generate a token\nrandomly according to the probability\nmass that is assigned",
    "start": "1234720",
    "end": "1241200"
  },
  {
    "text": "to each potential option. So rather than doing\nany type of greedy step, we use the probability\non each token",
    "start": "1241200",
    "end": "1247770"
  },
  {
    "text": "to give us a chance that\nthat token is generated. ",
    "start": "1247770",
    "end": "1253580"
  },
  {
    "text": "And so this does allow us\nto kind of get much more stochasticity in the types\nof tokens that are generated.",
    "start": "1253580",
    "end": "1261260"
  },
  {
    "text": "But a challenge\nthat pops up here is that these\ndistributions tend to be over a very large vocabulary.",
    "start": "1261260",
    "end": "1267500"
  },
  {
    "text": "And so even if there\nis clearly tokens that have a higher chance\nof being generated,",
    "start": "1267500",
    "end": "1272840"
  },
  {
    "text": "the tail of the\ndistribution can often be spread over a much larger\nnumber of possible tokens.",
    "start": "1272840",
    "end": "1279740"
  },
  {
    "text": "And so this becomes\na bit of a problem because these tokens\nin the long tail are probably\ncompletely irrelevant",
    "start": "1279740",
    "end": "1286460"
  },
  {
    "text": "to the current context. So they shouldn't\nhave any chance of being selected\nindividually, but as",
    "start": "1286460",
    "end": "1291860"
  },
  {
    "text": "a group it ends up that there's\na decent chance that you could output a completely\nirrelevant token.",
    "start": "1291860",
    "end": "1297170"
  },
  {
    "text": "Even if 90% of your probability\nmass is on relevant tokens, that means that you have a\n1 in 10 chance of outputting",
    "start": "1297170",
    "end": "1303050"
  },
  {
    "text": "something that completely throws\noff your entire text generation pipeline and it's\ncompletely inane.",
    "start": "1303050",
    "end": "1309500"
  },
  {
    "text": "So to mitigate\nthis, the field has developed a new\nset of algorithms that tries to prune\nthese distributions",
    "start": "1309500",
    "end": "1316400"
  },
  {
    "text": "at inference time. And so top-k sampling is\nkind of the most obvious way to do this.",
    "start": "1316400",
    "end": "1322320"
  },
  {
    "text": "So here we recognize that most\nof the tokens in our vocabulary should have no probability\nof being selected at all.",
    "start": "1322320",
    "end": "1329210"
  },
  {
    "text": "So we just truncate\nthe set of tokens that we're allowed\nto sample from to be the k tokens with the\nhighest amount of probability",
    "start": "1329210",
    "end": "1337790"
  },
  {
    "text": "mass of the distributions. And common values of k are often\n5, 10, 20, sometimes up to 100.",
    "start": "1337790",
    "end": "1345325"
  },
  {
    "text": "But really it's\na hyper parameter that you end up setting as\nthe designer of this system.",
    "start": "1345325",
    "end": "1350409"
  },
  {
    "text": "In general though\nwhat's important to note is that the higher you\nmake k, the more you'll be able to generate\ndiverse outputs,",
    "start": "1350410",
    "end": "1356772"
  },
  {
    "text": "which is good because that's\nwhat we're trying to do. But you're also\ngoing to increase the chance of letting that long\ntail seep in and generating",
    "start": "1356772",
    "end": "1364737"
  },
  {
    "text": "something that's\ncompletely irrelevant to the current context. Oops, sorry. Meanwhile if you\ndecrease k, your outputs",
    "start": "1364737",
    "end": "1371240"
  },
  {
    "text": "are going to be safer from\nthese long tail effects, but your text may end up\nbeing boring and generic",
    "start": "1371240",
    "end": "1376553"
  },
  {
    "text": "because your sampling\nalgorithm starts to look a lot more greedy in nature.",
    "start": "1376553",
    "end": "1382122"
  },
  {
    "text": "And this kind of\nshows the problem of having a fixed k as\nthe number of tokens that you can generate\nfrom your distribution.",
    "start": "1382123",
    "end": "1389330"
  },
  {
    "text": "If your distribution\nat a certain point is pretty flat such\nas in this example, she said I never\nblank, you might not",
    "start": "1389330",
    "end": "1395960"
  },
  {
    "text": "want to truncate a lot of\ninteresting options using a small value of\nk when there's so many good choices that could\nfit in this potential context.",
    "start": "1395960",
    "end": "1406220"
  },
  {
    "text": "Conversely in a\ndifferent example, you might want to cut off\nmuch more than let's say your minimum k options\nbecause only a subset of them",
    "start": "1406220",
    "end": "1414170"
  },
  {
    "text": "end up being quite suitable,\nand higher k than is really necessary lts that long tail\nseep in and potentially ruin",
    "start": "1414170",
    "end": "1420500"
  },
  {
    "text": "your generation. And so in response to this,\ntop-p or nucleus sampling",
    "start": "1420500",
    "end": "1426770"
  },
  {
    "text": "is a way around this issue. So here instead of sampling\nfrom a fixed number of tokens at each step, you\nsample from a fixed",
    "start": "1426770",
    "end": "1433610"
  },
  {
    "text": "amount of probability mass. And so depending on the\nflatness of your distribution,",
    "start": "1433610",
    "end": "1439790"
  },
  {
    "text": "you end up including a\nvariable number of tokens that is kind of dynamically\nchanging depending",
    "start": "1439790",
    "end": "1447830"
  },
  {
    "text": "on how that probability mass is\nspread across the distribution. And so to kind of\ndescribe this visually,",
    "start": "1447830",
    "end": "1455090"
  },
  {
    "text": "if you have three\ndifferent distributions at a particular step to\ngenerate a particular token in,",
    "start": "1455090",
    "end": "1461270"
  },
  {
    "text": "they're each going to prune\na different number of tokens from the available set that\nyou can sample from, depending",
    "start": "1461270",
    "end": "1467930"
  },
  {
    "text": "on what the value\nof P is and what the peakiness of\nthat distribution actually ends up being.",
    "start": "1467930",
    "end": "1473510"
  },
  {
    "text": " So I keep talking about\nthis concept of flatness",
    "start": "1473510",
    "end": "1481730"
  },
  {
    "text": "of a distribution being kind\nof critical in understanding how many tokens we can\nactually end up sampling from.",
    "start": "1481730",
    "end": "1489200"
  },
  {
    "text": "And in fact, as we try to\nuse sampling algorithms, we might find that the\nmodel that we've learned",
    "start": "1489200",
    "end": "1494990"
  },
  {
    "text": "may not actually be producing\nprobability distributions that lend themselves very nicely to\nusing these types of sampling",
    "start": "1494990",
    "end": "1500630"
  },
  {
    "text": "algorithms. The distributions might be too\nflat, they might be too peaky. And in fact, what\nwe might want to do",
    "start": "1500630",
    "end": "1506390"
  },
  {
    "text": "is re-scale those\ndistributions to better fit the decoding algorithm\nthat we might want to use.",
    "start": "1506390",
    "end": "1512429"
  },
  {
    "text": "And we can do this\nwith a method that goes by a variety\nof different names which I call\ntemperature scaling.",
    "start": "1512430",
    "end": "1518900"
  },
  {
    "text": "And here what you do is that\nyou apply a linear coefficient to every score for each\ntoken before you pass it",
    "start": "1518900",
    "end": "1526340"
  },
  {
    "text": "through the softmax. That temperature coefficient\nis the same for every token. So it's not dynamically changing\namongst your vocabulary,",
    "start": "1526340",
    "end": "1533600"
  },
  {
    "text": "it stays the same. But what happens is\nthat that change ends up",
    "start": "1533600",
    "end": "1538759"
  },
  {
    "text": "being amplified by\nthe soft max function. And what ends up happening\nis that if your temperature coefficient is\ngreater than 1, you're",
    "start": "1538760",
    "end": "1545600"
  },
  {
    "text": "actually going to make your\nprobability distribution much more uniform. In other words, you're\ngoing to make it flatter.",
    "start": "1545600",
    "end": "1553340"
  },
  {
    "text": "Meanwhile if your temperature\ncoefficient is less than 1, these scores are\ngoing to increase, which is going to make your\ndistributions more spiky",
    "start": "1553340",
    "end": "1559850"
  },
  {
    "text": "and make the probability\nmass kind of be pushed towards the most likely tokens.",
    "start": "1559850",
    "end": "1566690"
  },
  {
    "text": "One last thing to\nnote about temperature is that it's not actually\na decoding algorithm, it's just a way of re-balancing\nyour probability distribution.",
    "start": "1566690",
    "end": "1574650"
  },
  {
    "text": "So in fact, it can be applied to\nall of the sampling algorithms I described before, and\nsome greedy decoding",
    "start": "1574650",
    "end": "1580370"
  },
  {
    "text": "algorithms as well. The only one whose\nbehavior is not affected by softmax\ntemperature scaling",
    "start": "1580370",
    "end": "1586670"
  },
  {
    "text": "is argmax decoding,\nbecause even though you change the relative\nmagnitudes of the probability",
    "start": "1586670",
    "end": "1593120"
  },
  {
    "text": "mass in your distribution,\nyou don't actually change the relative\nranking amongst tokens in that distribution.",
    "start": "1593120",
    "end": "1599190"
  },
  {
    "text": "So argmax decoding will give\nyou the exact same output as before. ",
    "start": "1599190",
    "end": "1606210"
  },
  {
    "text": "But now that we're\nthinking about how we might change the distribution\nthat's produced by our model,",
    "start": "1606210",
    "end": "1611852"
  },
  {
    "text": "we might realize\nthat we might want to change more than the\nrelative magnitudes I mentioned,",
    "start": "1611852",
    "end": "1617030"
  },
  {
    "text": "and also instead change\nhow they're ranked with respect to one another. Maybe in fact our model is\nnot a perfect approximation",
    "start": "1617030",
    "end": "1625970"
  },
  {
    "text": "of what the distribution\nover tokens should be. Perhaps the training\nwasn't done right or we didn't have enough\ntraining data to actually make",
    "start": "1625970",
    "end": "1633182"
  },
  {
    "text": "it well calibrated. And so if we decide that our\nmodel isn't well calibrated for the task that\nwe're doing, we",
    "start": "1633182",
    "end": "1639230"
  },
  {
    "text": "may want to bring in outside\ninformation at decoding time. And so here I want to talk a\nbit about new classes of methods",
    "start": "1639230",
    "end": "1647450"
  },
  {
    "text": "that let us change\nour model prediction distributions at\ninference time rather than",
    "start": "1647450",
    "end": "1653270"
  },
  {
    "text": "relying on a fixed static model\nthat's only been trained once.",
    "start": "1653270",
    "end": "1658790"
  },
  {
    "text": "And a cool way of doing\nthis that came out last year is to actually use k nearest\nneighbor language models",
    "start": "1658790",
    "end": "1665539"
  },
  {
    "text": "which allow you to re-calibrate\nyour output probability distribution by using phrases\nstatistics from let's say",
    "start": "1665540",
    "end": "1672800"
  },
  {
    "text": "a much larger corpus. And so what you\ndo in this method",
    "start": "1672800",
    "end": "1678020"
  },
  {
    "text": "is that you initialize\na large database of phrases along with\nvector representations",
    "start": "1678020",
    "end": "1684680"
  },
  {
    "text": "for those phrases. And then at decoding\ntime, you can search for the most similar\nphrases in the database.",
    "start": "1684680",
    "end": "1692690"
  },
  {
    "text": "And so what you do is that\nyou take the representation of the context that you\nhave from your model",
    "start": "1692690",
    "end": "1698580"
  },
  {
    "text": "and you compute a\nsimilarity function with all the representations\nof the phrases that you have stored.",
    "start": "1698580",
    "end": "1704130"
  },
  {
    "text": "And based off the\nrelative differences amongst these different phrases\nto your current context,",
    "start": "1704130",
    "end": "1709230"
  },
  {
    "text": "you can compute a distribution\nover these most similar phrases, and then you can\ntake the next tokens that",
    "start": "1709230",
    "end": "1716670"
  },
  {
    "text": "follow these phrases and add the\nstatistics around those phrases to the distribution\nfrom your model.",
    "start": "1716670",
    "end": "1724110"
  },
  {
    "text": "And so this allows you to really\nre-balance the probability distribution that your\nmodel has given you",
    "start": "1724110",
    "end": "1729720"
  },
  {
    "text": "with this induced\ndistribution over phrases and interpolate them together to\nget a different estimate of how",
    "start": "1729720",
    "end": "1736770"
  },
  {
    "text": "likely certain words are.  One question right now is,\nhow do you know what to cache?",
    "start": "1736770",
    "end": "1747760"
  },
  {
    "text": "Yeah, so that's a\nreally good question.  I guess the answer there\nis that you could probably",
    "start": "1747760",
    "end": "1755820"
  },
  {
    "text": "decide on what might be\na salient set of phrases depending on let's\nsay named entities that you might be\ninterested in or phrases",
    "start": "1755820",
    "end": "1763440"
  },
  {
    "text": "that you know your model's\ndistribution doesn't handle very well. But I'm pretty sure\nin this work they",
    "start": "1763440",
    "end": "1770039"
  },
  {
    "text": "took every phrase in\ntheir training corpus, cached it, and then relied\non very efficient algorithms",
    "start": "1770040",
    "end": "1776610"
  },
  {
    "text": "for doing the search over\nrepresentation similarity to actually find the\nmost likely ones.",
    "start": "1776610",
    "end": "1783540"
  },
  {
    "text": "Though they did prune\nthe number of phrases that they actually used\nto make this distribution,",
    "start": "1783540",
    "end": "1789059"
  },
  {
    "text": "the phrase distributions that it\nwasn't over the entire corpus. ",
    "start": "1789060",
    "end": "1799940"
  },
  {
    "text": "So it's fantastic\nthat we can now re-balance these\ndistributions if we find that our model is doing poorly.",
    "start": "1799940",
    "end": "1807910"
  },
  {
    "text": "Particularly this\nmight be relevant if let's say we're\njumping into a new domain. So we've trained a\nnice big generation",
    "start": "1807910",
    "end": "1814850"
  },
  {
    "text": "model on Wikipedia\ntext and now we're going into something that's\nmore linked to the stories.",
    "start": "1814850",
    "end": "1823130"
  },
  {
    "text": "We might want to use\nthis type of system to get distributions\nfrom phrases from there. But it's also possible\nthat we may not always",
    "start": "1823130",
    "end": "1830180"
  },
  {
    "text": "have a good database of phrases\nto help us calibrate output distributions for\nall the types of text",
    "start": "1830180",
    "end": "1835970"
  },
  {
    "text": "that we want to generate. And so luckily\nlast year, there's also been new approaches\nthat look at doing",
    "start": "1835970",
    "end": "1842540"
  },
  {
    "text": "this in a gradient based way. And so the idea here is\nthat you can actually",
    "start": "1842540",
    "end": "1848030"
  },
  {
    "text": "define some type of\nexternal objective using a classifier that we typically\ncall a discriminator.",
    "start": "1848030",
    "end": "1855650"
  },
  {
    "text": "But in this figure from\nthe paper that proposed it, they called an attribute model. And what that classifier\ndoes is that it approximates",
    "start": "1855650",
    "end": "1863300"
  },
  {
    "text": "some property that you'd\nlike to encourage your text to exhibit as you decode. So perhaps it's a\nsentiment classifier",
    "start": "1863300",
    "end": "1869990"
  },
  {
    "text": "because you are working\non a dialogue model and you want to encourage\npositive sounding comments.",
    "start": "1869990",
    "end": "1877430"
  },
  {
    "text": "So then what you do is\nthat as you generate text, you input the output of\nyour text generation model",
    "start": "1877430",
    "end": "1882590"
  },
  {
    "text": "to this attribute\nmodel, and there's some tricks on how you should\ndo that in order to actually",
    "start": "1882590",
    "end": "1888890"
  },
  {
    "text": "not have it be a discrete token\nthat you provide to the model but instead a\ndistribution over tokens.",
    "start": "1888890",
    "end": "1895230"
  },
  {
    "text": "But the important thing is that\nif you do this the right way by using the soft distribution\nof tokens as inputs",
    "start": "1895230",
    "end": "1900800"
  },
  {
    "text": "to the attribute\nmodel, it's going to be able to compute a\nscore for the sequence that it receives.",
    "start": "1900800",
    "end": "1906780"
  },
  {
    "text": "So that if it's a\nsentiment classifier, it can evaluate how\npositive of the sequence you provided to it.",
    "start": "1906780",
    "end": "1913400"
  },
  {
    "text": "And then what you can do is\nthat you can compute gradients with respect to this\nproperty and backpropagate",
    "start": "1913400",
    "end": "1919460"
  },
  {
    "text": "those gradients back to your\ntext generation model directly. ",
    "start": "1919460",
    "end": "1925269"
  },
  {
    "text": "But instead of updating\nthe parameters, which is what you would\ndo during training, you instead update the\nintermediate activations",
    "start": "1925270",
    "end": "1931840"
  },
  {
    "text": "at each layer of your model,\nwhich you can then forward propagate to compute\na new distribution over the sets of tokens.",
    "start": "1931840",
    "end": "1938600"
  },
  {
    "text": "And so it's a neat\ntrick that allows you to do real time\ndistribution updating based on some outside discriminator\nthat's allowing you to update",
    "start": "1938600",
    "end": "1946659"
  },
  {
    "text": "your internal representations\nof the sequence such that it hopefully\ngenerates something more positive at the\noutputs in this case.",
    "start": "1946660",
    "end": "1953050"
  },
  {
    "text": " So these distribution\nre-balancing methods",
    "start": "1953050",
    "end": "1959790"
  },
  {
    "text": "either based off\nnearest neighbor search or on using some\ntype of discriminator",
    "start": "1959790",
    "end": "1965790"
  },
  {
    "text": "are quite promising\nand interesting, but they also end up being\nquite computationally intensive.",
    "start": "1965790",
    "end": "1971148"
  },
  {
    "text": "In the first case,\nyou're essentially doing a search over\nthousands of phrases to re-balance your distribution.",
    "start": "1971148",
    "end": "1977880"
  },
  {
    "text": "In the second you're\ndoing multiple forwards and backwards\npasses at every step to try and make\nthe tokens exhibit",
    "start": "1977880",
    "end": "1982970"
  },
  {
    "text": "a particular behavior more. And unfortunately,\nneither of them actually stop you from\ndecoding that sequences either.",
    "start": "1982970",
    "end": "1991106"
  },
  {
    "text": "It's possible that even\nafter you re-balance your distribution,\nyou're still generating something that looks terrible.",
    "start": "1991107",
    "end": "1996879"
  },
  {
    "text": "So in practice, something that\nwe often use in text generation to improve our sequence outputs\nare what are called re-rankers.",
    "start": "1996880",
    "end": "2003440"
  },
  {
    "text": "And so what we do here is\nthat we actually decode multiple sequences perhaps\nusing sampling or a wider",
    "start": "2003440",
    "end": "2010100"
  },
  {
    "text": "greedy search, say maybe 10. And then what we can do is\nthat we can initialize a score",
    "start": "2010100",
    "end": "2015650"
  },
  {
    "text": "to evaluate the\nsequences we produce and re-rank these sequences\naccording to the score.",
    "start": "2015650",
    "end": "2022669"
  },
  {
    "text": "And the simplest thing we can do\nis to actually just score them by the likelihood given\nby the model for example.",
    "start": "2022670",
    "end": "2030822"
  },
  {
    "text": "Especially if we're using\na sampling algorithm, we might want to make sure that\nwe didn't generate something that totally deviated from\ngood text which would tend",
    "start": "2030822",
    "end": "2038600"
  },
  {
    "text": "to have a very high perplexity. So this perplexity is perhaps\na good re-ranking function.",
    "start": "2038600",
    "end": "2045052"
  },
  {
    "text": "It's just important\nto be careful as well that repetitive sequences tend\nto have very low perplexity as",
    "start": "2045052",
    "end": "2050929"
  },
  {
    "text": "well. And so if you rank\nby perplexity, you're likely to just generate\nsomething you were trying to avoid in the first case.",
    "start": "2050929",
    "end": "2059780"
  },
  {
    "text": "But we can also make\nour re-rankers evaluate more complex behaviors. In the same way that we could\nuse gradient based methods",
    "start": "2059780",
    "end": "2067010"
  },
  {
    "text": "to update our distributions to\nexhibit more complex behaviors, we can actually just take\nthose same attribute models",
    "start": "2067010",
    "end": "2073340"
  },
  {
    "text": "and use them as re-rankers\nto re-rank a fixed set of sequences\nrather than have them back propagate\ngradients to the main model.",
    "start": "2073340",
    "end": "2081090"
  },
  {
    "text": "And so we can use\nthem to rank things such as style, discourse,\nfactuality, logical consistency.",
    "start": "2081090",
    "end": "2087530"
  },
  {
    "text": "But just be careful if\nyour re-ranker ends up being poorly calibrated.",
    "start": "2087530",
    "end": "2092690"
  },
  {
    "text": "Just because you've\ntrained a classifier to predict whether a sentence\nmakes a factual statement doesn't actually\nmean that it will",
    "start": "2092690",
    "end": "2098780"
  },
  {
    "text": "be good at ranking different\nfactual statements with respect to one another.",
    "start": "2098780",
    "end": "2104032"
  },
  {
    "text": "And finally a nice\nthing about re-rankers as well is that you can use\nmultiple re-rankers in parallel if there's multiple\nproperties you want to score",
    "start": "2104032",
    "end": "2111641"
  },
  {
    "text": "and come up with, let's\nsay, a weighted average of different ranking\nscores to decide on what might be the\nbest sequence according",
    "start": "2111642",
    "end": "2118130"
  },
  {
    "text": "to different properties. But so to recap what we've\ntalked about in terms",
    "start": "2118130",
    "end": "2124940"
  },
  {
    "text": "of decoding, I want to\nmention that decoding is still a very challenging problem in\nnatural language generation",
    "start": "2124940",
    "end": "2131660"
  },
  {
    "text": "that we haven't really\nfigured out yet. Our algorithms\nstill don't really reflect the way that humans\nchoose words when they speak,",
    "start": "2131660",
    "end": "2139810"
  },
  {
    "text": "and our best approaches\nare currently based on trying to calibrate\nprobability distributions produced by models to perhaps\nbe more representative",
    "start": "2139810",
    "end": "2147349"
  },
  {
    "text": "of human likelihood. But the truth is the human\nlanguage distribution is quite noisy and doesn't\nreflect the simple properties",
    "start": "2147350",
    "end": "2155750"
  },
  {
    "text": "that our decoding\nalgorithms often capture such as\nprobability maximization.",
    "start": "2155750",
    "end": "2162320"
  },
  {
    "text": "But different\ndecoding algorithms do allow us to\nperhaps inject biases that encourage\ndifferent properties",
    "start": "2162320",
    "end": "2168080"
  },
  {
    "text": "of coherent natural\nlanguage generation. That's allowed us to make\npromising improvements in this area as well.",
    "start": "2168080",
    "end": "2174150"
  },
  {
    "text": "And in fact, some of the\nmost impactful advances in NLG over the last\nfew years have really come from simple but very\neffective modifications",
    "start": "2174150",
    "end": "2181310"
  },
  {
    "text": "to decoding algorithms\nbecause you can often have impact across a very\nlarge number of tasks",
    "start": "2181310",
    "end": "2186770"
  },
  {
    "text": "by making a good change\nto a decoding algorithm. But really there's\nstill a lot more work to be done in the space,\nand hopefully many of you",
    "start": "2186770",
    "end": "2194960"
  },
  {
    "text": "will be the ones to make\nthese next breakthroughs. I'm happy to take\nquestions at this point if any have popped up.",
    "start": "2194960",
    "end": "2201250"
  },
  {
    "text": "Oh, here's one question. How do you evaluate,\nhow do you tell whether re-balance\ndistribution is better?",
    "start": "2201250",
    "end": "2208400"
  },
  {
    "text": "And if I editorialized\nfrom there, I guess you're\nadmitting on this slide that you can't just\nlook at the probability.",
    "start": "2208400",
    "end": "2216279"
  },
  {
    "text": "Yeah. So yes, you can't just\nlook at the probability. I mean, there is a\ncertain amount of trust",
    "start": "2216280",
    "end": "2223359"
  },
  {
    "text": "that happens that if you don't\ntrust that your ranker is giving you a better assessment\nof whether you've produced",
    "start": "2223360",
    "end": "2229960"
  },
  {
    "text": "a quality piece of text,\nperhaps you shouldn't be using that re-ranker\nin the first place. And hopefully you've actually\nmeans tested that re-ranker",
    "start": "2229960",
    "end": "2237130"
  },
  {
    "text": "to actually show\nthat it has, that it improves the quality of text. But we're going to talk a lot\nmore about how you can actually",
    "start": "2237130",
    "end": "2243369"
  },
  {
    "text": "evaluate the quality of text\nlater on, though I should warn you ahead of time that\nthe answers are not",
    "start": "2243370",
    "end": "2251890"
  },
  {
    "text": "as direct and complete as\nyou might want them to be. And in fact, there's a lot of\nroom for interpretation in how",
    "start": "2251890",
    "end": "2258700"
  },
  {
    "text": "you would actually do that. Maybe you should go\non about that later, but I guess people are puzzled\non that because there's",
    "start": "2258700",
    "end": "2265390"
  },
  {
    "text": "another question that's asking.  It was saying that\nyou said, you don't",
    "start": "2265390",
    "end": "2272119"
  },
  {
    "text": "know how to make a model\nchoose words like a human, how do we model different humans\nfrom different backgrounds,",
    "start": "2272120",
    "end": "2280559"
  },
  {
    "text": "et cetera? ",
    "start": "2280560",
    "end": "2286230"
  },
  {
    "text": "Yeah, that's a\nreally good question. The answer to that is\nthat you could potentially",
    "start": "2286230",
    "end": "2292290"
  },
  {
    "text": "try to do kind of fine\ntuning on the language",
    "start": "2292290",
    "end": "2299110"
  },
  {
    "text": "distribution of a particular\nhuman starting from let's say a pre-trained language model\nsince you'll probably never",
    "start": "2299110",
    "end": "2304360"
  },
  {
    "text": "have enough data to only use\na single human's outputs, or you could try to do some\nof these re-balancing methods",
    "start": "2304360",
    "end": "2310660"
  },
  {
    "text": "that we've spoken about to\nperhaps use those to actually make your distributions approach\na particular human's language",
    "start": "2310660",
    "end": "2318700"
  },
  {
    "text": "distribution more closely. So in the gradient based\nmethods that I described, I could perhaps train a\nsingle language model only",
    "start": "2318700",
    "end": "2324700"
  },
  {
    "text": "on my type of language, even if\nI have a much larger one that's trained on a much larger\ncorpus of language",
    "start": "2324700",
    "end": "2330680"
  },
  {
    "text": "from different\nspeakers, but then try to make it so\nthat my model ranks",
    "start": "2330680",
    "end": "2335770"
  },
  {
    "text": "the outputs of the main model. I've got a question.",
    "start": "2335770",
    "end": "2340780"
  },
  {
    "text": "Yep. So nucleus sampling\nand top-k sampling are really effective\nin practice,",
    "start": "2340780",
    "end": "2346900"
  },
  {
    "text": "and you made the\nargument that there are all these little tiny things\nwith very little probability mass but it sums up to\nmore probability mass.",
    "start": "2346900",
    "end": "2353890"
  },
  {
    "text": "But if it sums up to\nmore probability mass than they actually should have\nunder the real distribution",
    "start": "2353890",
    "end": "2360490"
  },
  {
    "text": "of human language,\nshouldn't our models have been trained to put less\nprobability mass on them?",
    "start": "2360490",
    "end": "2365530"
  },
  {
    "text": "And so why aren't our language\nmodels better in that case? Like why do we have this\nissue if they actually",
    "start": "2365530",
    "end": "2372133"
  },
  {
    "text": "are getting more probability\nthan they should? ",
    "start": "2372133",
    "end": "2379110"
  },
  {
    "text": "Yeah, that's a\nreally good question. I think the answer to that is\nthat the way we train them,",
    "start": "2379110",
    "end": "2385289"
  },
  {
    "text": "which I'll get to in a bit\nis really trying to do,",
    "start": "2385290",
    "end": "2390390"
  },
  {
    "text": "is really trying to model the\ndistribution of human language as it sees in its\ntraining corpus. And it's actually surprisingly\neffective at doing that.",
    "start": "2390390",
    "end": "2399869"
  },
  {
    "text": "But at the same time,\nwhen we actually start to use these\nlanguage models out of the box in the NLG task that\nwe work with, first of all,",
    "start": "2399870",
    "end": "2407700"
  },
  {
    "text": "there's always slight deviations\nin the distribution of text that we're actually trying to\nmodel for the task we're doing,",
    "start": "2407700",
    "end": "2413220"
  },
  {
    "text": "and what the large\ncorpus we trained on was in the first place,\nwhich can make these decoding algorithms less effective.",
    "start": "2413220",
    "end": "2420155"
  },
  {
    "text": "And the second\nthing I would note is that even though these\ndecoding algorithms are quite effective in practice,\nthey aren't doing",
    "start": "2420155",
    "end": "2428370"
  },
  {
    "text": "what humans do when we speak. At no point when\na human speaks are we potentially\ntrying to maximize",
    "start": "2428370",
    "end": "2434310"
  },
  {
    "text": "the probability of a\npotential next token or randomly select a word\namongst a set of tokens.",
    "start": "2434310",
    "end": "2439470"
  },
  {
    "text": "We ultimately have\nworld models that drive how we select the tokens\nthat we choose to say in order",
    "start": "2439470",
    "end": "2444840"
  },
  {
    "text": "to make our points. And that's very\ndifferent from what we get in probabilistic\nlanguage models.",
    "start": "2444840",
    "end": "2450780"
  },
  {
    "text": "Now should we throw away\nprobabilistic language models? No, because as you mentioned\nthey end up working quite well.",
    "start": "2450780",
    "end": "2457089"
  },
  {
    "text": "But at some point\nwe also do need to mitigate these differences\nbetween how humans end up speaking and how language\nmodels end up modeling language.",
    "start": "2457090",
    "end": "2463349"
  },
  {
    "text": " Thanks. ",
    "start": "2463350",
    "end": "2470340"
  },
  {
    "text": "So now that John has primed us\nperfectly for what comes next,",
    "start": "2470340",
    "end": "2475440"
  },
  {
    "text": "let's jump back into the\ntraining these models because the pipeline that\nI framed earlier being,",
    "start": "2475440",
    "end": "2482849"
  },
  {
    "text": "you train your model, then you\nchoose your decoding algorithm depending on properties you're\ninterested in, is great.",
    "start": "2482850",
    "end": "2490140"
  },
  {
    "text": "But the truth is\nthere's interactions between your decoding model\nand your training algorithm that you might want to be\nthinking about during training,",
    "start": "2490140",
    "end": "2497620"
  },
  {
    "text": "which is not really what\nwe're doing right now. And so if you recall\nthe training algorithm",
    "start": "2497620",
    "end": "2503010"
  },
  {
    "text": "that we've proposed\nup to this point is one where we just try to\nminimize the negative log likelihood of the next\ntoken in a sequence",
    "start": "2503010",
    "end": "2510570"
  },
  {
    "text": "given the preceding\nones at every step. And as I mentioned this\nactually works pretty well",
    "start": "2510570",
    "end": "2517410"
  },
  {
    "text": "for training autoregressive\nmodels of human language. But it actually causes a few\nissues, which John hinted at.",
    "start": "2517410",
    "end": "2526710"
  },
  {
    "text": "So in the next few\nslides, I'm going to talk a bit about\nthese issues and then highlight some training\nsolutions to these problems",
    "start": "2526710",
    "end": "2532710"
  },
  {
    "text": "that I found\ninteresting, or that I think are important\nfrom the last few years.",
    "start": "2532710",
    "end": "2538943"
  },
  {
    "text": "So the first issue\nis actually one that I hinted at in\nthe last section, which is that training with\nmaximum likelihood",
    "start": "2538943",
    "end": "2545640"
  },
  {
    "text": "tends to discourage\ntextual diversity. And I showed the sequence\non a slide earlier",
    "start": "2545640",
    "end": "2551880"
  },
  {
    "text": "as an example of\ngreedy algorithms being prone to generating\nrepetitive sequences, which",
    "start": "2551880",
    "end": "2557280"
  },
  {
    "text": "is just about the worst form of\ndiversity that you could get.",
    "start": "2557280",
    "end": "2562470"
  },
  {
    "text": "But greedy algorithms\nare just trying to maximize the probability\nof the sequences that they produce.",
    "start": "2562470",
    "end": "2567690"
  },
  {
    "text": "So it can really only be prone\nto repetitive and un-diverse phrases if those phrases\nare scored highly",
    "start": "2567690",
    "end": "2574500"
  },
  {
    "text": "by the model to begin with. And that ends up being\none of the issues with maximum\nlikelihood training is",
    "start": "2574500",
    "end": "2580620"
  },
  {
    "text": "that it tends to end up\nfavoring generic expressions because those are the ones\nthat are often the most likely",
    "start": "2580620",
    "end": "2586650"
  },
  {
    "text": "in human language production. But as we all know and\nas I mentioned earlier,",
    "start": "2586650",
    "end": "2591990"
  },
  {
    "text": "human language production isn't\nabout maximizing the likelihood of the words that we produce. So even though we might produce\ngeneric phrases more often",
    "start": "2591990",
    "end": "2599228"
  },
  {
    "text": "than ungeneric phrases,\nthat's not the goal that we're setting out\nwith when we speak. There's a lot more\nto communication",
    "start": "2599228",
    "end": "2604830"
  },
  {
    "text": "that really isn't synthesized\nby a training objective that tries to maximize probability\nover the human language that's",
    "start": "2604830",
    "end": "2612210"
  },
  {
    "text": "being read. So how can we end up\nmitigating this problem?  So an interesting\napproach that I really",
    "start": "2612210",
    "end": "2618869"
  },
  {
    "text": "like that came out\nlast year was actually proposed by Welleck\net al, which was",
    "start": "2618870",
    "end": "2624990"
  },
  {
    "text": "called unlikelihood training. And so here what you\ndo is that you actually discourage the production\nof particular tokens",
    "start": "2624990",
    "end": "2633050"
  },
  {
    "text": "by the model in\ncertain contexts. And so what happens\nthat this loss term here decreases as the probability\nof the y-neg tokens decreases.",
    "start": "2633050",
    "end": "2641658"
  },
  {
    "text": "So for any token that you\ndon't want to generate, as the probability of generating\nthat token goes down, so",
    "start": "2641658",
    "end": "2646910"
  },
  {
    "text": "does the loss term, which\nmeans that you're not actually updating the model as much\nfor this particular behavior.",
    "start": "2646910",
    "end": "2653430"
  },
  {
    "text": "What's important, though,\nis that you still have your teacher forcing objective. So what's going to\nhappen is that the model",
    "start": "2653430",
    "end": "2658970"
  },
  {
    "text": "is going to learn to capture\nboth the distribution of language from the training\ncorpus which it needs to do",
    "start": "2658970",
    "end": "2664000"
  },
  {
    "text": "to learn how to generate text. But also it's going to learn\nhow to not say particular words",
    "start": "2664000",
    "end": "2670130"
  },
  {
    "text": "that you might not want it to. And then what you can do is that\nyou can set this list of words",
    "start": "2670130",
    "end": "2676599"
  },
  {
    "text": "that you don't want the model\nto generate to actually be words that you've already\ngenerated before.",
    "start": "2676600",
    "end": "2682090"
  },
  {
    "text": "And so in essence you're\nteaching the model to not say the same things again. And that's just\nnaturally going to limit",
    "start": "2682090",
    "end": "2688420"
  },
  {
    "text": "the amount of repetition\nthat your model is going to be able to spit\nout and you're going to be able to\ngenerate more diverse texts",
    "start": "2688420",
    "end": "2694420"
  },
  {
    "text": "as the result as well. ",
    "start": "2694420",
    "end": "2700280"
  },
  {
    "text": "But a second and\nvery important issue that comes from training\nwith maximum likelihood is what we often call\nexposure bias, which",
    "start": "2700280",
    "end": "2709640"
  },
  {
    "text": "is that the context\nthat we train on to generate the\nnext token are going to look different from the ones\nthat we see at generation time.",
    "start": "2709640",
    "end": "2717720"
  },
  {
    "text": "And so why might that be? Well, so what happens\nduring training is that we always get a\ntoken from a gold document",
    "start": "2717720",
    "end": "2725540"
  },
  {
    "text": "or human text as input. It's the gold sequence\nas we call it. But then during\ngeneration, we're",
    "start": "2725540",
    "end": "2732230"
  },
  {
    "text": "feeding our previously\ngenerated tokens back into the model as\nthe input rather than",
    "start": "2732230",
    "end": "2738380"
  },
  {
    "text": "these teacher forced tokens that\nare from the gold documents. And so that set of\ntokens is actually",
    "start": "2738380",
    "end": "2745010"
  },
  {
    "text": "quite affected by things like\nthe distributions produced by our model and the decoding\nalgorithm we use to get tokens.",
    "start": "2745010",
    "end": "2752380"
  },
  {
    "text": "And so can this end\nup being a problem? Well, yes because as\nwe've seen before, the types of text that\nour model generates",
    "start": "2752380",
    "end": "2760400"
  },
  {
    "text": "are often not a very close\napproximation of human language patterns in the training set.",
    "start": "2760400",
    "end": "2766107"
  },
  {
    "text": "And so there's going to be\nan imbalance between the type of text that our\nmodel has learned to predict, and to expect\nto see, and the type of text",
    "start": "2766107",
    "end": "2774950"
  },
  {
    "text": "that it will see once we\nactually start decoding. And so once your model starts\nreceiving its own inputs which",
    "start": "2774950",
    "end": "2782180"
  },
  {
    "text": "are going to deviate from the\ndistribution of text to expect, It's going to be very\nchallenging for it to be able to generate coherent\ntext going forward because it's",
    "start": "2782180",
    "end": "2789290"
  },
  {
    "text": "not going to really know how to\nsynthesize its own information that it's generated. And so there's a\nvariety of ways to try",
    "start": "2789290",
    "end": "2795680"
  },
  {
    "text": "to counter this exposure\nbias issue and many more that that continue to come out.",
    "start": "2795680",
    "end": "2801120"
  },
  {
    "text": "And unfortunately there's\nnot really enough time to talk about all of\nthem, so I've added slides to discuss\ntwo of them that",
    "start": "2801120",
    "end": "2806540"
  },
  {
    "text": "are based on semi-supervised\nlearning here. But I really want to focus\nmore on two other approaches",
    "start": "2806540",
    "end": "2813950"
  },
  {
    "text": "that I personally\nfind very interesting. The first is called\nsequence rewriting.",
    "start": "2813950",
    "end": "2819800"
  },
  {
    "text": "And so in this\nsetting, your model first learns to\nretrieve a sequence",
    "start": "2819800",
    "end": "2825020"
  },
  {
    "text": "from an existing database\nof human written prototypes.",
    "start": "2825020",
    "end": "2830060"
  },
  {
    "text": "So it's kind of like our nearest\nneighbor decoders earlier will be cached a bunch of phrases. Here you cache a\nbunch of sequences",
    "start": "2830060",
    "end": "2835973"
  },
  {
    "text": "that might be similar to the one\nthat you're supposed to produce for this new situation.",
    "start": "2835973",
    "end": "2841369"
  },
  {
    "text": "And then what we do is that\nonce we take this sequence and retrieve it,\nwe learn to edit it by doing things like adding,\nremoving, or modifying tokens",
    "start": "2841370",
    "end": "2850280"
  },
  {
    "text": "to more accurately reflect the\ncontext that we're actually given rather than the one that\nthis original sequence was",
    "start": "2850280",
    "end": "2856790"
  },
  {
    "text": "designed for in the first place. And so we can still\nuse an algorithm here that tries to maximize\nlikelihood for training.",
    "start": "2856790",
    "end": "2862970"
  },
  {
    "text": "But because there's this sort\nof latent variable of retrieving the right prototype\nthat's involved, it makes it less likely that\nour generated text ends up",
    "start": "2862970",
    "end": "2870560"
  },
  {
    "text": "suffering from exposure\nbias because you're already starting from something that\nlooks more like a training sequence that you\nmight have seen.",
    "start": "2870560",
    "end": "2878820"
  },
  {
    "text": "Another general class of\npossibilities we can do is to let our model learn\nto generate text by learning",
    "start": "2878820",
    "end": "2885930"
  },
  {
    "text": "from its own samples. And this naturally\nmaps itself nicely to reinforcement learning,\nwhich is actually",
    "start": "2885930",
    "end": "2892080"
  },
  {
    "text": "one of my favorite ways to\nlearn how to generate text. In the setting you're going\nto cast your text generation",
    "start": "2892080",
    "end": "2899670"
  },
  {
    "text": "model as a Markov decision\nprocess where your state S is the model's representation\nof the preceding context",
    "start": "2899670",
    "end": "2906720"
  },
  {
    "text": "that you see, your\nactions A are the words that can be generated,\nyour policy is the decoder,",
    "start": "2906720",
    "end": "2912960"
  },
  {
    "text": "and your rewards are provided\nby some type of external score. And here you can learn\nmany different behaviors",
    "start": "2912960",
    "end": "2919560"
  },
  {
    "text": "for your text generation\nmodel by rewarding it when it exhibits those behaviors.",
    "start": "2919560",
    "end": "2925859"
  },
  {
    "text": "And so to kind of\nquickly join this framing with the perspective of\nthe text generation models that we've seen so\nfar, you're going",
    "start": "2925860",
    "end": "2932070"
  },
  {
    "text": "to be taking actions\nby sampling words hat y from the distribution,\nand then you're",
    "start": "2932070",
    "end": "2939270"
  },
  {
    "text": "going to feed them\nback into the input to get a new state,\nwhich is what we've been doing at every point.",
    "start": "2939270",
    "end": "2945510"
  },
  {
    "text": "What's different though, is\nthat as you generate text, you're using some\nexternal reward function",
    "start": "2945510",
    "end": "2950670"
  },
  {
    "text": "to compute rewards for each\ntoken that you generate. So you're rewarding every\naction that you take.",
    "start": "2950670",
    "end": "2956010"
  },
  {
    "text": "And then you scale the sample\nloss on this particular token that you generate by\nthis reward, which",
    "start": "2956010",
    "end": "2963067"
  },
  {
    "text": "is going to encourage\nthe model to generate the sequence in similar\ncontexts if the reward is high.",
    "start": "2963068",
    "end": "2968880"
  },
  {
    "text": "So to put it very\nclearly, you're minimizing the\nnegative log likelihood of your sample token.",
    "start": "2968880",
    "end": "2974430"
  },
  {
    "text": "So here it's not a gold token. Notice the hat that\nis on the y expression in the reward function.",
    "start": "2974430",
    "end": "2981510"
  },
  {
    "text": "And then you're going to\ncompute a reward for that token and scale this negative log\nlikelihood by that reward.",
    "start": "2981510",
    "end": "2987805"
  },
  {
    "text": "And so if the reward\nis high, the model is going to be more\nlikely to generate the same sequence in a\nsimilar context in the future.",
    "start": "2987805",
    "end": "2993780"
  },
  {
    "text": "If the reward is low,\nit will be less likely.  But this sort of brings\nup a natural question,",
    "start": "2993780",
    "end": "3000640"
  },
  {
    "text": "what can we actually\nuse as a reward to encourage the behaviors we\nwant in this text generation system?",
    "start": "3000640",
    "end": "3006520"
  },
  {
    "text": "That's really up to you as\nyou design your generation pipeline. A common practice\nin the early days",
    "start": "3006520",
    "end": "3012640"
  },
  {
    "text": "of using RL for\ntext generation was to set the reward to\nbe the final evaluation",
    "start": "3012640",
    "end": "3017740"
  },
  {
    "text": "metric that you are\ngoing to evaluate on. And so here instead of having\na unique reward for each",
    "start": "3017740",
    "end": "3023680"
  },
  {
    "text": "generated token at\nevery time step, you would just take the\nfinal sequence score that you get and reward every\ntoken in the generated sequence",
    "start": "3023680",
    "end": "3031030"
  },
  {
    "text": "with that value. And this was absolutely magical.",
    "start": "3031030",
    "end": "3036220"
  },
  {
    "text": "You would set your evaluation\nmetric as the reward, and you'd end up learning to\nget more reward because that's what RL algorithms do, which\nin turn means that you were",
    "start": "3036220",
    "end": "3044720"
  },
  {
    "text": "learning to generate\nsequences that do better on your evaluation metric. So NLG benchmark scores were\nshooting through the roof.",
    "start": "3044720",
    "end": "3051800"
  },
  {
    "text": "We were making real progress. But it was actually all a lie.",
    "start": "3051800",
    "end": "3056810"
  },
  {
    "text": "Turns out as I'll talk\nabout later evaluation metrics particularly\nfor text generation are just approximations,\nand it's not always clear",
    "start": "3056810",
    "end": "3064690"
  },
  {
    "text": "that optimizing to\nthose approximations is going to lead to more\nand better coherent text",
    "start": "3064690",
    "end": "3070750"
  },
  {
    "text": "generation. Instead, oftentimes\nwhat ends up happening is that it just learns\nto exploit the noise",
    "start": "3070750",
    "end": "3076120"
  },
  {
    "text": "in the evaluation metric. And in fact, in their\nlarge work where",
    "start": "3076120",
    "end": "3081357"
  },
  {
    "text": "they introduce Google's\nneural machine translation system in 2016, Google\nresearchers generally",
    "start": "3081357",
    "end": "3087010"
  },
  {
    "text": "found that training machine\ntranslation models with RL and BLEU scores as\nrewards didn't actually",
    "start": "3087010",
    "end": "3093490"
  },
  {
    "text": "improve the translation quality\nat all even if it did lead to higher BLEU scores. ",
    "start": "3093490",
    "end": "3101340"
  },
  {
    "text": "But so, designing\nyour reward function is a very important\nproblem in RL",
    "start": "3101340",
    "end": "3106590"
  },
  {
    "text": "for actually learning the\nbehavior that you want. And I've listed\nsome cool work here",
    "start": "3106590",
    "end": "3113040"
  },
  {
    "text": "on how you can actually learn\nto tie fairly complex behaviors to reward functions by actually\ninitializing the scores they",
    "start": "3113040",
    "end": "3120750"
  },
  {
    "text": "use as rewards as\nneural networks that get trained on an auxiliary\ntask ahead of time, but can then be used to provide\nscores as rewards to the system",
    "start": "3120750",
    "end": "3129120"
  },
  {
    "text": "that you produce. So to go back to\nour example earlier of trying to create a dialogue\nagent that is very positive",
    "start": "3129120",
    "end": "3135750"
  },
  {
    "text": "and only says\npositive things, you could use a sentiment\nclassifier to produce a reward for the sequences\nthat you generate.",
    "start": "3135750",
    "end": "3144505"
  },
  {
    "text": "And so that's a lot of fun.  Unfortunately,\ndespite all the fun that you can have using RL to\ntrain text generation engines,",
    "start": "3144505",
    "end": "3151920"
  },
  {
    "text": "there's a bit of a\ndark side too, which is that reinforcement\nlearning algorithms can",
    "start": "3151920",
    "end": "3157440"
  },
  {
    "text": "be notoriously unstable. And so to get these text\ngeneration systems to learn",
    "start": "3157440",
    "end": "3162510"
  },
  {
    "text": "with RL, you often\nhave to be thorough in tuning different dials in\nyour model setup accurately.",
    "start": "3162510",
    "end": "3169495"
  },
  {
    "text": "There's many of them. Two of them that I think\nare worth mentioning are one that you always need to\npre-train with teacher forcing.",
    "start": "3169495",
    "end": "3175482"
  },
  {
    "text": "You generally can't train\nwith reinforcement learning from scratch, and also\nyou need to provide some type of baseline reward\nthat your model should",
    "start": "3175482",
    "end": "3183180"
  },
  {
    "text": "be achieving. So for example, BLEU score\nwhich I described earlier is always a positive\nvalue unless it's zero.",
    "start": "3183180",
    "end": "3189672"
  },
  {
    "text": "What that means that if you\nuse it alone as a reward, every single sequence\nthat you sample ends up being encouraged\nin the future.",
    "start": "3189672",
    "end": "3197110"
  },
  {
    "text": "So what you want to have\nis some type of baseline that is an expectation\nof how much reward you should be getting which can\nbe subtracted from the reward",
    "start": "3197110",
    "end": "3205210"
  },
  {
    "text": "that you actually get so\nthat you can discourage certain behaviors as well.",
    "start": "3205210",
    "end": "3210349"
  },
  {
    "text": "One last note about this\nis that neural networks are quite good at finding the\neasiest way to learn something.",
    "start": "3210350",
    "end": "3216730"
  },
  {
    "text": "So if there's a way to\nexploit your reward function, it will find a way\nto do it particularly",
    "start": "3216730",
    "end": "3222098"
  },
  {
    "text": "that's easier than learning\nthe behavior that you want it to learn. So something to remember\nthat's kind of important",
    "start": "3222098",
    "end": "3228569"
  },
  {
    "text": "if you try to use reinforcement\nlearning for text generation systems, particularly because\nthey're such a large action",
    "start": "3228570",
    "end": "3234700"
  },
  {
    "text": "space of words that\nit can generate to try to accomplish their behaviors. ",
    "start": "3234700",
    "end": "3242809"
  },
  {
    "text": "So to end the\nsection, I just want to start off by saying\nthat in general we still use teacher forcing as a\nprimary means of learning",
    "start": "3242810",
    "end": "3249580"
  },
  {
    "text": "to generate coherent text. It has diversity\nissues, but it still lets us learn a model with\ndecent text generation",
    "start": "3249580",
    "end": "3258580"
  },
  {
    "text": "abilities. One thing I haven't focused\ntoo much on in this lecture is the type of model that you\ncan use to actually generate",
    "start": "3258580",
    "end": "3265930"
  },
  {
    "text": "text because they tend to\nbe less universal and much more designed to very\nspecific end tasks.",
    "start": "3265930",
    "end": "3272500"
  },
  {
    "text": "But in general a\ncommon approach in NLG is to try to design a\nneural architecture that allows your model\nto be perhaps less",
    "start": "3272500",
    "end": "3281140"
  },
  {
    "text": "sensitive to the problems\nof teacher forcing or to address them with\nadditional loss terms that are perhaps task specific.",
    "start": "3281140",
    "end": "3287920"
  },
  {
    "text": "Exposure bias though is a\nproblem everywhere, pretty much regardless of your\nneural architecture.",
    "start": "3287920",
    "end": "3294600"
  },
  {
    "text": "And to kind of mitigate\nit you can either train your model to\nbe more resistant to its own distribution\nchanges through things",
    "start": "3294600",
    "end": "3300490"
  },
  {
    "text": "like semi supervised learning,\nor you can change your pipeline",
    "start": "3300490",
    "end": "3305492"
  },
  {
    "text": "such that you're learning\nto make modifications to an existing sequence that\nyou retrieved from your training set rather than trying to\nlearn how to generate sequences",
    "start": "3305492",
    "end": "3312880"
  },
  {
    "text": "from scratch. The caveat there is that as\nthe type of text that you're generating gets\nlonger and longer,",
    "start": "3312880",
    "end": "3319060"
  },
  {
    "text": "doing this kind of\nretrieval and editing becomes just as\nchallenging as generating from scratch in many cases.",
    "start": "3319060",
    "end": "3326687"
  },
  {
    "text": "And finally, you can\nuse reinforcement learning as another\nmeans of learning from your own examples.",
    "start": "3326687",
    "end": "3332140"
  },
  {
    "text": "And in effect, you\ncan also use it to encourage different\nbehaviors than just likelihood maximization.",
    "start": "3332140",
    "end": "3338110"
  },
  {
    "text": "But this type of learning can\nend up being quite unstable and unless your\nreward is well shaped, the model can often\nlearn to exploit it.",
    "start": "3338110",
    "end": "3344740"
  },
  {
    "text": " Are there online\nlanguage simulators",
    "start": "3344740",
    "end": "3351670"
  },
  {
    "text": "where you can train\nwith RL online or are you only talking\nabout training offline?",
    "start": "3351670",
    "end": "3357355"
  },
  {
    "start": "3357355",
    "end": "3362872"
  },
  {
    "text": "No, in this setting\nwe're generally talking about training offline. So you train it all\nahead of time and then",
    "start": "3362872",
    "end": "3367960"
  },
  {
    "text": "you use your model as it's been\ntrained the first time around. OK, Yeah. So now we've finally\nreached the section",
    "start": "3367960",
    "end": "3376400"
  },
  {
    "text": "that I hinted at earlier\non a very important topic, evaluation, which to be honest\nis something that we should be",
    "start": "3376400",
    "end": "3384619"
  },
  {
    "text": "thinking about\nbefore we even start designing a model or a training\nalgorithm or a decoding",
    "start": "3384620",
    "end": "3390190"
  },
  {
    "text": "algorithm. It's how can we actually\ncheck that our method is-- how can we act-- how\nare we actually going to evaluate that our\nmethod is even working?",
    "start": "3390190",
    "end": "3397670"
  },
  {
    "text": "And today I want to talk a bit\nabout three types of evaluation metrics. So first we'll talk about\nautomatic eval metrics",
    "start": "3397670",
    "end": "3404960"
  },
  {
    "text": "because generally you\nneed to be able to rapidly prototype and diagnose\nfailures in your model. So it's essential to be able to\nhave this quick feedback even",
    "start": "3404960",
    "end": "3411830"
  },
  {
    "text": "if it's very coarse. And in automatic\nevaluation metrics,",
    "start": "3411830",
    "end": "3417470"
  },
  {
    "text": "we've traditionally used what\nI'm calling content overlap metrics which focus on how much\na sequence explicitly resembles",
    "start": "3417470",
    "end": "3424730"
  },
  {
    "text": "another sequence usually\nin terms of word or phrase matching. Lately there's also been new\nautomatic evaluations that",
    "start": "3424730",
    "end": "3432560"
  },
  {
    "text": "are model based where we try to\nuse advances, and embeddings, and neural models to define\nmore implicit similarity",
    "start": "3432560",
    "end": "3439070"
  },
  {
    "text": "measures between sequences. And finally we'll talk a bit\nabout human evaluations, which are kind of the gold standard\nof evaluating text generation.",
    "start": "3439070",
    "end": "3448820"
  },
  {
    "text": "But they also do have downsides\nthat we'll get to as well. And I just want to note\nthat some of these slides",
    "start": "3448820",
    "end": "3454940"
  },
  {
    "text": "here are actually\nrepurposed from slides from Asli Celikyilmaz,\nwho's a leading expert on NLG evaluation.",
    "start": "3454940",
    "end": "3463260"
  },
  {
    "text": "But so let's jump in. So content overlap\nmetrics generally compute an explicit similarity\nscore between two sequences,",
    "start": "3463260",
    "end": "3471119"
  },
  {
    "text": "the one that's been\ngenerated by your model and some gold standard reference\nsequence that was attached",
    "start": "3471120",
    "end": "3477390"
  },
  {
    "text": "to the inputs that you had. So in other words, a\nsequence that you know was an appropriate generation\nfor the inputs you had.",
    "start": "3477390",
    "end": "3487670"
  },
  {
    "text": "And these metrics are often\na popular starting point because they're fast\nand very efficient,",
    "start": "3487670",
    "end": "3492743"
  },
  {
    "text": "which is their main benefit. As long as you have a reference\nsequence to compare to, you can compute z-scores\nrapidly to get feedback.",
    "start": "3492743",
    "end": "3499640"
  },
  {
    "text": "And I'm going to categorize\nthem into two zones here first, n-gram\noverlap metrics that compute different functions\nof word and word-like overlap",
    "start": "3499640",
    "end": "3507410"
  },
  {
    "text": "and semantic overlap\nmetrics which involve more complex\noverlap functions based off semantic structures.",
    "start": "3507410",
    "end": "3514279"
  },
  {
    "text": "Unfortunately besides\nbeing fast and efficient, most N-gram overlap\nmetrics don't actually",
    "start": "3514280",
    "end": "3520220"
  },
  {
    "text": "give you a great approximation\nof sequence quality a lot",
    "start": "3520220",
    "end": "3525349"
  },
  {
    "text": "of times. They're already not\nideal for something like machine translation where\nthere can be multiple ways",
    "start": "3525350",
    "end": "3531350"
  },
  {
    "text": "to translate the same sequence\nwith things like synonyms, and they get progressively\nmuch worse for tasks that",
    "start": "3531350",
    "end": "3538099"
  },
  {
    "text": "are more open-ended than MT. So for example in summarization,\nthe longer output texts",
    "start": "3538100",
    "end": "3545210"
  },
  {
    "text": "make it naturally harder\nto measure something using word match, and it's\nsomething like dialogue,",
    "start": "3545210",
    "end": "3550910"
  },
  {
    "text": "it's incredibly open-ended\nand in fact, you can have multiple responses\nto a particular utterance that",
    "start": "3550910",
    "end": "3558770"
  },
  {
    "text": "mean the same thing but\ndon't use any common words. And so we can illustrate this\nwith a simple, fairly contrived",
    "start": "3558770",
    "end": "3564620"
  },
  {
    "text": "example where you have a\ndialogue context utterance that asks a question such as,\nare you going to Antoine's",
    "start": "3564620",
    "end": "3570920"
  },
  {
    "text": "incredible CS224N lecture, a\ncompletely unbiased reference text derived from a human,\nand then a dialogue agent that",
    "start": "3570920",
    "end": "3579650"
  },
  {
    "text": "spits out different answers,\nsuch as yes which gets a pretty high score on our n-gram\noverlap metrics, or you know it",
    "start": "3579650",
    "end": "3587329"
  },
  {
    "text": "which already scores a lot\nlower despite depicting the exact same\nidea, or yup which",
    "start": "3587330",
    "end": "3592700"
  },
  {
    "text": "actually gets a score of 0. Meanwhile, a completely\nincorrect answer, heck no,",
    "start": "3592700",
    "end": "3599030"
  },
  {
    "text": "gets the highest score\nout of all of them, which kind of\npoints to the issue when you use n-gram\noverlap measures",
    "start": "3599030",
    "end": "3605810"
  },
  {
    "text": "in a lot of applications,\nyou're going to be missing the\nsalient elements of what the generated sequence\nshould capture,",
    "start": "3605810",
    "end": "3611270"
  },
  {
    "text": "and instead be getting stylistic\nsimilarities between text even as you miss the\nmost important context.",
    "start": "3611270",
    "end": "3619170"
  },
  {
    "text": "And if you prefer\nempirical validations to contrived examples,\nit's actually been shown that many dialogue\nevaluation metrics don't really",
    "start": "3619170",
    "end": "3626240"
  },
  {
    "text": "correlate well with\nhuman judgments at all. And this gets worse as your\nsequence length increases",
    "start": "3626240",
    "end": "3633810"
  },
  {
    "text": "typically. So with an open-ended task\nlike story generation, you can get improved\nscores by just matching",
    "start": "3633810",
    "end": "3640018"
  },
  {
    "text": "a whole lot of stop\nwords that have nothing to do with the content\nof the story itself. ",
    "start": "3640018",
    "end": "3646890"
  },
  {
    "text": "We also have another\ncategory of overlap metrics that I'll call semantic\noverlap metrics because they don't necessarily tie directly\nto the words you used,",
    "start": "3646890",
    "end": "3654620"
  },
  {
    "text": "but instead try to create\nconceptual representations of the generated and\nreference outputs instead.",
    "start": "3654620",
    "end": "3660440"
  },
  {
    "text": "So the center one\nhere, spice for example creates a scene graph\nof your generated text",
    "start": "3660440",
    "end": "3667820"
  },
  {
    "text": "and then compares that\nto your reference caption to see how similar this more\nsemantic representation ends",
    "start": "3667820",
    "end": "3675000"
  },
  {
    "text": "up being.  But clearly, there's\nsome limitations",
    "start": "3675000",
    "end": "3680510"
  },
  {
    "text": "to how well explicit\ncontent overlap metrics can do, particularly\nas we start thinking about more open-ended tasks.",
    "start": "3680510",
    "end": "3687135"
  },
  {
    "text": "So in response over\nthe last few years, there's been a focus on\nusing model-based metrics whose representations come\nfrom machine learning models,",
    "start": "3687135",
    "end": "3696680"
  },
  {
    "text": "and where they can be\nused to actually evaluate the fidelity of generated text.",
    "start": "3696680",
    "end": "3702720"
  },
  {
    "text": "And these are nice because\nthere's no more needing explicit matches between\nwords in your reference and generated text.",
    "start": "3702720",
    "end": "3708380"
  },
  {
    "text": "Instead, you can rely on\nmuch more implicit notions of similarity that you\nget from word embeddings.",
    "start": "3708380",
    "end": "3716380"
  },
  {
    "text": "And so there's been a lot of\nmodels developed in this area. Some of the original\nones kind of",
    "start": "3716380",
    "end": "3722200"
  },
  {
    "text": "focused on defining\ncomposition functions over the embedding of words\nin your generated in reference",
    "start": "3722200",
    "end": "3729970"
  },
  {
    "text": "sequences, and then\ncomputing a distance between the compositions\nof the two sequences.",
    "start": "3729970",
    "end": "3737619"
  },
  {
    "text": "Some more involved\ntakes on this idea",
    "start": "3737620",
    "end": "3742820"
  },
  {
    "text": "are things like word\nmover's distance where here you actually\ntry to map word vectors in both your generated\nand reference sequences",
    "start": "3742820",
    "end": "3750470"
  },
  {
    "text": "into pairs with one another. So each word vector is\npaired to another word vector in the opposite sequence and\nthe distance between them",
    "start": "3750470",
    "end": "3757670"
  },
  {
    "text": "is computed. And then you allow\nthe evaluation metric to actually compute\nthe optimal matching",
    "start": "3757670",
    "end": "3763730"
  },
  {
    "text": "between these pairs of words,\nsuch as the total distances minimized. And BERTSCORE which\nhas become quite",
    "start": "3763730",
    "end": "3770960"
  },
  {
    "text": "popular over the last year or\nso as an evaluation metric is pretty much just\nword mover's distance",
    "start": "3770960",
    "end": "3777170"
  },
  {
    "text": "but using contextualized\nBERT embeddings to compute these distances.",
    "start": "3777170",
    "end": "3783630"
  },
  {
    "text": "Sentence mover's\nsimilarity is kind of another extension of\nword mover's similarity that adds sentence embeddings\nfrom recurrent neural networks",
    "start": "3783630",
    "end": "3791760"
  },
  {
    "text": "to this distance\noptimization and that allows it to be more effective\nfor evaluating let's say long multi-sentence\ntext as opposed",
    "start": "3791760",
    "end": "3799380"
  },
  {
    "text": "to just single sentences. And finally last year\nthere was a new model named",
    "start": "3799380",
    "end": "3806609"
  },
  {
    "text": "BLEURT, which is actually\na regression model that's based on BERT. And here it takes a\npair of sentences,",
    "start": "3806610",
    "end": "3813413"
  },
  {
    "text": "the reference on\nthe generated one and returns a score that\nindicates to what extent the candidate is grammatical\nand conveys the meaning",
    "start": "3813413",
    "end": "3819960"
  },
  {
    "text": "of the reference text. ",
    "start": "3819960",
    "end": "3826050"
  },
  {
    "text": "So we can talk about a lot\nmore evaluation metrics that are computed automatically,\nand there's far more of them",
    "start": "3826050",
    "end": "3832727"
  },
  {
    "text": "than I actually\nmentioned though they do tend to fit in those two\ncategories that I described. But it's important to remember\nthat at the end of the day,",
    "start": "3832728",
    "end": "3839920"
  },
  {
    "text": "the true mark of an NLG\nsystem's performance is whether it's valuable\nto the human user that has to interact with it\nor read the text that's",
    "start": "3839920",
    "end": "3846480"
  },
  {
    "text": "produced from it. And unfortunately,\nautomatic metrics tend to fall short\nof replicating",
    "start": "3846480",
    "end": "3851970"
  },
  {
    "text": "human opinions of the\nquality of generated text. And that's why for this\nreason human evaluations",
    "start": "3851970",
    "end": "3859980"
  },
  {
    "text": "are viewed as the most\nimportant form of evaluation for text generation systems.",
    "start": "3859980",
    "end": "3865920"
  },
  {
    "text": "Almost all work in NLG\ngenerally include some form of human evaluation,\nparticularly",
    "start": "3865920",
    "end": "3871109"
  },
  {
    "text": "if the task is more open-ended. And if it doesn't\nwell, let me be frank,",
    "start": "3871110",
    "end": "3876660"
  },
  {
    "text": "you should probably be\nskeptical of any claim that's being made by that work.",
    "start": "3876660",
    "end": "3882619"
  },
  {
    "text": "And, finally, another\nuse of human evaluations is that in addition to\nevaluating model performance,",
    "start": "3882620",
    "end": "3889829"
  },
  {
    "text": "you can also use them\nto actually train new machine learning models\nthat are meant to be evaluated,",
    "start": "3889830",
    "end": "3895820"
  },
  {
    "text": "that are meant to serve as\nevaluation scoring functions themselves.",
    "start": "3895820",
    "end": "3901720"
  },
  {
    "text": "So I guess the main thing to\nmention about human evaluations since we could talk\nabout them for a while is",
    "start": "3901720",
    "end": "3908460"
  },
  {
    "text": "that they're both very simple\nbut also very difficult to run. They're simple because\nyou generally just need",
    "start": "3908460",
    "end": "3914820"
  },
  {
    "text": "to find judges and\nask them to rate an intrinsic dimension of the\nquality of your generated text.",
    "start": "3914820",
    "end": "3920400"
  },
  {
    "text": "So you have to define\na set of criteria that you decide is\nimportant for the task that you're designing\na system for,",
    "start": "3920400",
    "end": "3926039"
  },
  {
    "text": "and that can be\nthings like fluency where you just measure things\nlike grammar, spelling, word",
    "start": "3926040",
    "end": "3931140"
  },
  {
    "text": "choice. Does this actually look\nlike human language? Factuality, does\nthe text accurately",
    "start": "3931140",
    "end": "3936420"
  },
  {
    "text": "reflect facts that are\ndescribed in the context? Common sense, does\nit sort of follow",
    "start": "3936420",
    "end": "3941970"
  },
  {
    "text": "the logical rules of the\nworld that we might expect? But once you've\ndefined these criteria,",
    "start": "3941970",
    "end": "3948670"
  },
  {
    "text": "you can have humans evaluate the\ngenerated text for how well it actually produces\ntext that caters",
    "start": "3948670",
    "end": "3956490"
  },
  {
    "text": "to these particular criteria. One thing to note here is that\nwhile these dimensions are",
    "start": "3956490",
    "end": "3962430"
  },
  {
    "text": "common and repeated across\ndifferent evaluations, they can often be\nreferred to by other names",
    "start": "3962430",
    "end": "3968099"
  },
  {
    "text": "and explained to evaluators\nin different terms, and be measured\nin different ways.",
    "start": "3968100",
    "end": "3974470"
  },
  {
    "text": "And in fact, one of the\nproblems with human evaluations is that across works they tend\nto be very unstandardized which",
    "start": "3974470",
    "end": "3980220"
  },
  {
    "text": "can make the replication of\nhuman results quite difficult. And that's why when you\nread text generation papers,",
    "start": "3980220",
    "end": "3985890"
  },
  {
    "text": "you rarely see a comparison\nof human evaluation scores between two\ndifferent studies even if they evaluated\nthe same dimensions.",
    "start": "3985890",
    "end": "3992490"
  },
  {
    "text": " But another set of issues\nwith human evaluations",
    "start": "3992490",
    "end": "3999660"
  },
  {
    "text": "beyond the fact that\nthey're slow, expensive, and unstandardized is\nthat humans themselves aren't actually perfect.",
    "start": "3999660",
    "end": "4008990"
  },
  {
    "text": "I guess there's a few negatives\nthat I can say about humans, even though we're all humans\nis that we tend to not",
    "start": "4008990",
    "end": "4014900"
  },
  {
    "text": "be very consistent folks, often\nchanging our minds about how we view something\ndepending on something",
    "start": "4014900",
    "end": "4020990"
  },
  {
    "text": "as trivial as the time of day. We don't always\nreason in the way",
    "start": "4020990",
    "end": "4026870"
  },
  {
    "text": "that we're expected\nto when presented with a task such as\nevaluating something. We can lose concentration\nand not really be",
    "start": "4026870",
    "end": "4034670"
  },
  {
    "text": "focused on what we were doing. And we can often\nmisinterpret what let's say a human\nevaluation is asking",
    "start": "4034670",
    "end": "4040880"
  },
  {
    "text": "us to do such that we inject\nour own biases into the task. And on top of all\nof these things,",
    "start": "4040880",
    "end": "4046970"
  },
  {
    "text": "when we run human\nevaluations, we're also dealing with the\nfact that one of the big motivators that our\nhuman judges have is to do the task as\nquickly as possible, which",
    "start": "4046970",
    "end": "4055040"
  },
  {
    "text": "isn't a great mix, particularly\nif we want them to really give us high quality ratings.",
    "start": "4055040",
    "end": "4061830"
  },
  {
    "text": "But humans are kind\nof the best thing that we have to actually give\nus the most accurate assessments",
    "start": "4061830",
    "end": "4067230"
  },
  {
    "text": "of whether text generation\nsystems are doing well so we do the best that we can.",
    "start": "4067230",
    "end": "4073967"
  },
  {
    "text": "I'm actually going\nto skip this slide, but I mentioned earlier that one\nof the things that we can also do is use human ratings to\ntrain models to actually predict",
    "start": "4073967",
    "end": "4082300"
  },
  {
    "text": "scores for text itself. And so two systems that do\nsomething along these lines I",
    "start": "4082300",
    "end": "4089900"
  },
  {
    "text": "provided citations\nto here so that you can take a look at them if\nyou're curious later on. ",
    "start": "4089900",
    "end": "4096890"
  },
  {
    "text": "But so the takeaways\nI kind of want you to get from the section are\nthat evaluation is quite hard,",
    "start": "4096890",
    "end": "4103759"
  },
  {
    "text": "and particularly\nin text generation. So content overlap metrics do\nprovide a good starting point",
    "start": "4103760",
    "end": "4109740"
  },
  {
    "text": "for evaluating the\nquality of generated text. If you run these\nn-gram overlap metrics",
    "start": "4109740",
    "end": "4115700"
  },
  {
    "text": "and they show scores that are\nworse than they should be, that's the first sign\nthat you have a problem.",
    "start": "4115700",
    "end": "4121229"
  },
  {
    "text": "But they're generally not\ngood enough on their own. Model based metrics\ntend to be more",
    "start": "4121229",
    "end": "4127549"
  },
  {
    "text": "correlated with human judgments\nthan content overlap ones particularly as the\ntasks become more",
    "start": "4127550",
    "end": "4132770"
  },
  {
    "text": "open-ended such as\ndialogue and storytelling. But the downside there\nis that they're not",
    "start": "4132770",
    "end": "4137869"
  },
  {
    "text": "very interpretable\nunlike with the content overlap metric where you\ncan say exactly, oh, this",
    "start": "4137870",
    "end": "4143660"
  },
  {
    "text": "is why this score is this way\nit's because these words match up with these words, with a\nmodel based metric you get",
    "start": "4143660",
    "end": "4148910"
  },
  {
    "text": "a much more implicit\ndefinition of similarity which while useful is also\nless interpretable.",
    "start": "4148910",
    "end": "4157160"
  },
  {
    "text": "Human judgments are absolutely\ncritical because even if they're inconsistent\nand sometimes don't",
    "start": "4157160",
    "end": "4164179"
  },
  {
    "text": "do the task that\nyou want them to, humans are actually able\nto intrinsically evaluate dimensions that we don't even\nknow how to formulate using",
    "start": "4164180",
    "end": "4172159"
  },
  {
    "text": "any type of automatic metric. But lastly slightly\nunrelated to what",
    "start": "4172160",
    "end": "4177199"
  },
  {
    "text": "I've spoken about this\nsection, I just I just want to say that the number\none evaluator of any NLG system that you create\nshould really be you.",
    "start": "4177200",
    "end": "4185170"
  },
  {
    "text": "Look at your model's\noutputs as perhaps you do a project that\ninvolves NLG can really",
    "start": "4185170",
    "end": "4191568"
  },
  {
    "text": "be worth days,\nweeks, and sometimes months of staring at evaluation\nmetrics that are perhaps a bit uninformative.",
    "start": "4191569",
    "end": "4197450"
  },
  {
    "text": "So if you design\nNLG systems, make sure to evaluate your own\ngenerations very consistently.",
    "start": "4197450",
    "end": "4202730"
  },
  {
    "start": "4202730",
    "end": "4207830"
  },
  {
    "text": "So in this last section, I\nthink it's quite important to talk about ethical topics\nin natural language generation",
    "start": "4207830",
    "end": "4215869"
  },
  {
    "text": "as well because ultimately\nwhile NLG really allows us to tackle new and\ninteresting applications,",
    "start": "4215870",
    "end": "4223730"
  },
  {
    "text": "if we're not capable we\ncan end up deploying fairly dangerous and harmful systems. And as a warning,\nI just want to say",
    "start": "4223730",
    "end": "4229790"
  },
  {
    "text": "that some of the content\non the next few slides is going to potentially\nbe quite uncomfortable.",
    "start": "4229790",
    "end": "4236148"
  },
  {
    "text": "But I think it's important\nto make very clear how these systems can\ngo very, very wrong.",
    "start": "4236148",
    "end": "4241430"
  },
  {
    "text": "And without picking on\na particular example, I do perhaps think that one\nof the most famous examples",
    "start": "4241430",
    "end": "4248810"
  },
  {
    "text": "of this was the Tay\ndialogue chatbot which was released onto Twitter in 2016.",
    "start": "4248810",
    "end": "4254870"
  },
  {
    "text": "And within 24 hours\nit had started making some very\nnasty comments that",
    "start": "4254870",
    "end": "4260030"
  },
  {
    "text": "exhibited racist, sexist,\nanti-Semitic, white supremacist meanings, which is\nultimately probably not what",
    "start": "4260030",
    "end": "4267320"
  },
  {
    "text": "the designers of\nTay had in mind. So what actually ended up\ngoing wrong with Tay, well,",
    "start": "4267320",
    "end": "4273170"
  },
  {
    "text": "here's the thing,\nTay behaved exactly as we should have\nexpected it would.",
    "start": "4273170",
    "end": "4279380"
  },
  {
    "text": "It was designed to\nlearn to exhibit the conversational\npatterns of the users that it interacted\nwith and it did that.",
    "start": "4279380",
    "end": "4286070"
  },
  {
    "text": "NLG models are very\ngood at capturing the language distribution\nof their training examples. That's been the one\nthing that we've",
    "start": "4286070",
    "end": "4291890"
  },
  {
    "text": "been remarkably consistent\non in the last few years. And it turns out if their\ntraining examples end up",
    "start": "4291890",
    "end": "4298460"
  },
  {
    "text": "having toxic content, they will\nlearn to repeat that content. And this is perhaps\nno clearer than if you",
    "start": "4298460",
    "end": "4304670"
  },
  {
    "text": "look at what\npre-trained language models have to say about let's\nsay different demographics.",
    "start": "4304670",
    "end": "4311070"
  },
  {
    "text": "So if you remember, large\npre-trained language models that underlie\nmany modern NLG systems,",
    "start": "4311070",
    "end": "4317660"
  },
  {
    "text": "they're trained on\nmassive corpora of text which are often opaque and\ncrawled from online resources.",
    "start": "4317660",
    "end": "4323240"
  },
  {
    "text": "If it turns out that those\ncorpora have toxic content, the language models are going\nto learn it, and in fact",
    "start": "4323240",
    "end": "4328430"
  },
  {
    "text": "make it even worse. And then it turns out that\nif you prompt these language models for certain\npieces of information,",
    "start": "4328430",
    "end": "4334440"
  },
  {
    "text": "it can spit out\nthat toxic content showing very different\nopinions across gender,",
    "start": "4334440",
    "end": "4340820"
  },
  {
    "text": "races, sexual orientations. Now you can see that\nit would actually be rare to ask a\nlanguage model to weigh",
    "start": "4340820",
    "end": "4347210"
  },
  {
    "text": "in with their opinions\non this matter, but you do have to ask yourself\nif this type of information is encoded in the model in some\nway, in what other ways could",
    "start": "4347210",
    "end": "4354800"
  },
  {
    "text": "these learned patterns end up\nbeing reflected by this model once it's actually\ndeployed in practice?",
    "start": "4354800",
    "end": "4360850"
  },
  {
    "text": "And that kind of leads\nus to the second problem with these language models. We actually don't really\nknow how information ends up",
    "start": "4360850",
    "end": "4367468"
  },
  {
    "text": "being learned and encoded by\nthem, which means that we don't have a rigorous understanding\nof what types of inputs are going to trigger\nwhat types of outputs.",
    "start": "4367468",
    "end": "4375100"
  },
  {
    "text": "And in fact, Wallace et al\nshowed in their EMNLP 2019 work that this was a big problem\nbecause if you prime",
    "start": "4375100",
    "end": "4381370"
  },
  {
    "text": "these models with particularly\nadversarial inputs, they would generally devolve\nimmediately into producing",
    "start": "4381370",
    "end": "4386469"
  },
  {
    "text": "very toxic content. In other words, what it took\nTay 24 hours to learn how to do, these systems can kind\nof do out of the box",
    "start": "4386470",
    "end": "4393340"
  },
  {
    "text": "if primed with the\nwrong examples. And unfortunately,\nthe wrong examples",
    "start": "4393340",
    "end": "4400920"
  },
  {
    "text": "end up being a lot less nasty\nthan we might have expected, a lot less nasty than the\nones on the previous slide",
    "start": "4400920",
    "end": "4406410"
  },
  {
    "text": "at the very least. But in a work at EMNLP Findings\nlast year, a research group",
    "start": "4406410",
    "end": "4414900"
  },
  {
    "text": "showed that much more\ninnocuous looking inputs could actually prime these\nlanguage models to go on pretty toxic diatribes as before.",
    "start": "4414900",
    "end": "4422699"
  },
  {
    "text": "It wasn't as consistent\nas in the previous work, but it was still often enough.",
    "start": "4422700",
    "end": "4429820"
  },
  {
    "text": "And these examples\nreally go to show that we need to be careful with\nhow these systems are deployed. If you have an NLG system,\nyou need safeguards to stop it",
    "start": "4429820",
    "end": "4437650"
  },
  {
    "text": "from outputing harmful content. And this goes\nbeyond the examples of the toxic and toxicity\nbias that I've shown today,",
    "start": "4437650",
    "end": "4444700"
  },
  {
    "text": "a model that can be\nprimed to generate incorrect or\nunfactual information can be quite dangerous too.",
    "start": "4444700",
    "end": "4451730"
  },
  {
    "text": "And also NLG models\nshouldn't be deployed without an understanding\nof who its users will be.",
    "start": "4451730",
    "end": "4456920"
  },
  {
    "text": "And there's always going to be\nadversarial users for any model that you create\neven if you can't",
    "start": "4456920",
    "end": "4462893"
  },
  {
    "text": "think of them in the moment.  And that leads us\nto the final point,",
    "start": "4462893",
    "end": "4469380"
  },
  {
    "text": "which is that the\nadvances in NLG have really allowed us to\nbuild text production systems",
    "start": "4469380",
    "end": "4476330"
  },
  {
    "text": "for many new applications. As we do this though,\nit's important to ask",
    "start": "4476330",
    "end": "4481880"
  },
  {
    "text": "does the content that\nwe're building a system to automatically generate\nfor easy human ingestion,",
    "start": "4481880",
    "end": "4489170"
  },
  {
    "text": "does it really need to be\ngenerated automatically? And I think a good\nexample of this",
    "start": "4489170",
    "end": "4494960"
  },
  {
    "text": "is the work of Zeller's\net al at NeurIPS 2019, which showed off the potential\ndangers of fake news generators",
    "start": "4494960",
    "end": "4501500"
  },
  {
    "text": "from pre-trained\nlanguage models. I actually thought\nthis was a great work and it highlighted many\nof the defenses that",
    "start": "4501500",
    "end": "4508190"
  },
  {
    "text": "could be developed against a\nfake news generations system.",
    "start": "4508190",
    "end": "4514050"
  },
  {
    "text": "But the point is more so\nthat you should always imagine that any\ntool that you create",
    "start": "4514050",
    "end": "4519110"
  },
  {
    "text": "could be used in a negative way. So a storytelling NLG\nsystem can also potentially",
    "start": "4519110",
    "end": "4524840"
  },
  {
    "text": "be repurposed to do\nfake news generation.",
    "start": "4524840",
    "end": "4530511"
  },
  {
    "text": "And you should really\nalways ask yourself whether the positive\napplications of a particular\ntechnology outweigh",
    "start": "4530512",
    "end": "4536540"
  },
  {
    "text": "the potential negative ones. And that turns out to often\nnot be an easy question. ",
    "start": "4536540",
    "end": "4544260"
  },
  {
    "text": "So I guess as concluding\nthoughts for today, I just",
    "start": "4544260",
    "end": "4549400"
  },
  {
    "text": "want to mention that if you\nstart interacting with NLG systems in practice,\nyou're quickly",
    "start": "4549400",
    "end": "4556780"
  },
  {
    "text": "going to see the fairly\nlarge limitations that they tend to have.",
    "start": "4556780",
    "end": "4562300"
  },
  {
    "text": "Even in tasks where\nwe've achieved a larger amount of progress at\nbuilding systems that",
    "start": "4562300",
    "end": "4569080"
  },
  {
    "text": "can do the task\nfairly well, there's still a lot of\nimprovements that can be made to make them even better.",
    "start": "4569080",
    "end": "4576580"
  },
  {
    "text": "In pretty much any NLG task at\nthe same time, evaluating it effectively remains\na huge challenge.",
    "start": "4576580",
    "end": "4582760"
  },
  {
    "text": "We often have to rely\non humans to give us the best estimates of how\nwell our system is doing.",
    "start": "4582760",
    "end": "4588679"
  },
  {
    "text": "And so, an area where a large\nimprovement would really",
    "start": "4588680",
    "end": "4593800"
  },
  {
    "text": "kind of bootstrap\nlarger improvements in many other areas\nof NLG would be to find better automatic\nevaluation for NLP systems.",
    "start": "4593800",
    "end": "4603170"
  },
  {
    "text": "On the other hand, on\na very optimistic note, I do want to say that with the\nadvent of large-scale language models, deep NLG research\nhasn't been reset,",
    "start": "4603170",
    "end": "4611800"
  },
  {
    "text": "but it's never been easier\nto jump in the space and start playing\naround with the systems, and designing cool new tools\nthat can help humans ingest",
    "start": "4611800",
    "end": "4622030"
  },
  {
    "text": "content and information more\nrapidly and more efficiently. And as a result,\nI think that it's",
    "start": "4622030",
    "end": "4627880"
  },
  {
    "text": "one of the most exciting\nareas of NLP to work in. And I think that if you\nstart working on it as well",
    "start": "4627880",
    "end": "4634540"
  },
  {
    "text": "you'll feel the same way. And I would encourage\nyou to do so. So thanks a lot for\nhaving me today.",
    "start": "4634540",
    "end": "4639750"
  },
  {
    "text": "It was really exciting. ",
    "start": "4639750",
    "end": "4646000"
  }
]
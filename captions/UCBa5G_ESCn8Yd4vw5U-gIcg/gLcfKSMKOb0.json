[
  {
    "text": "OK well, so far we've been\ntalking about regression trees,",
    "start": "0",
    "end": "3360"
  },
  {
    "text": "the response was\nquantitative salaries",
    "start": "3360",
    "end": "5450"
  },
  {
    "text": "in this case of\nbaseball players.",
    "start": "5450",
    "end": "9110"
  },
  {
    "text": "Oftentimes, trees are\nused when the response is",
    "start": "9110",
    "end": "11750"
  },
  {
    "text": "a categorical variable,\nand so then we",
    "start": "11750",
    "end": "14150"
  },
  {
    "text": "call those classification trees.",
    "start": "14150",
    "end": "16320"
  },
  {
    "text": "But you'll see the\ntechnology is very similar,",
    "start": "16320",
    "end": "19670"
  },
  {
    "text": "and we just have to change,\nessentially, the loss function",
    "start": "19670",
    "end": "22580"
  },
  {
    "text": "and how we measure\ngood performance.",
    "start": "22580",
    "end": "25020"
  },
  {
    "text": "So let's see how that goes.",
    "start": "25020",
    "end": "26230"
  },
  {
    "start": "26230",
    "end": "27895"
  },
  {
    "text": "So we're going to predict\nin a classification",
    "start": "27895",
    "end": "32250"
  },
  {
    "text": "tree, each observation\nbelonging to the most commonly",
    "start": "32250",
    "end": "35520"
  },
  {
    "text": "occurring class.",
    "start": "35520",
    "end": "37050"
  },
  {
    "text": "So that's what's going\nto happen in the terminal",
    "start": "37050",
    "end": "39210"
  },
  {
    "text": "node of the tree.",
    "start": "39210",
    "end": "40219"
  },
  {
    "text": "Instead of just giving the\nprediction being the mean,",
    "start": "40220",
    "end": "43770"
  },
  {
    "text": "we're going to classify it\nto the most common class.",
    "start": "43770",
    "end": "47580"
  },
  {
    "text": "We're going to grow the\ntree in a very same way",
    "start": "47580",
    "end": "50130"
  },
  {
    "text": "as we did for\nregression trees, but we",
    "start": "50130",
    "end": "53670"
  },
  {
    "text": "don't use residual sum\nof squares as a criterion",
    "start": "53670",
    "end": "56429"
  },
  {
    "text": "for making the splits,\nwe need a criterion",
    "start": "56430",
    "end": "58350"
  },
  {
    "text": "that's more geared\ntowards classification.",
    "start": "58350",
    "end": "60750"
  },
  {
    "text": "So one thing you can do is that\neach internal node, you can just",
    "start": "60750",
    "end": "63720"
  },
  {
    "text": "look at the\nclassification error rate.",
    "start": "63720",
    "end": "66120"
  },
  {
    "text": "And that's easy to compute.",
    "start": "66120",
    "end": "67843"
  },
  {
    "start": "67843",
    "end": "76730"
  },
  {
    "text": "So suppose you've got\ncapital K classes,",
    "start": "76730",
    "end": "79320"
  },
  {
    "text": "and you compute the proportion\nin the terminal node",
    "start": "79320",
    "end": "83100"
  },
  {
    "text": "in each of the classes from\n1 up to capital K. Well,",
    "start": "83100",
    "end": "86423"
  },
  {
    "text": "the class you're\ngoing to classify",
    "start": "86423",
    "end": "87840"
  },
  {
    "text": "is to use the class\nthat's got the largest",
    "start": "87840",
    "end": "91299"
  },
  {
    "text": "of those probabilities,\nthose proportions.",
    "start": "91300",
    "end": "93393"
  },
  {
    "text": "And the error\nyou're going to make",
    "start": "93393",
    "end": "94810"
  },
  {
    "text": "is going to be 1\nminus that maximum.",
    "start": "94810",
    "end": "97979"
  },
  {
    "text": "So all the ones that don't\nbelong to the maximum class",
    "start": "97980",
    "end": "100510"
  },
  {
    "text": "are going to be\ncounted as errors.",
    "start": "100510",
    "end": "102160"
  },
  {
    "text": "So you could use that\nto decide on the split.",
    "start": "102160",
    "end": "106660"
  },
  {
    "text": "And so that's a proportion of\nerrors you're going to make.",
    "start": "106660",
    "end": "109250"
  },
  {
    "text": "But it turns out that that's\na little bit jumpy and noisy,",
    "start": "109250",
    "end": "112360"
  },
  {
    "text": "and it doesn't lead to a very\nsmooth tree growing process.",
    "start": "112360",
    "end": "118580"
  },
  {
    "text": "And for that reason, some\nother measures are preferable.",
    "start": "118580",
    "end": "124210"
  },
  {
    "text": "One measure is the Gini index,\nand it's a variance measure",
    "start": "124210",
    "end": "129100"
  },
  {
    "text": "across the classes.",
    "start": "129100",
    "end": "130399"
  },
  {
    "text": "So you've got capital K\nclasses, often K is two,",
    "start": "130400",
    "end": "134530"
  },
  {
    "text": "but not necessarily.",
    "start": "134530",
    "end": "136600"
  },
  {
    "text": "And for those who know\nthe binomial distribution,",
    "start": "136600",
    "end": "141310"
  },
  {
    "text": "each of the terms here is\nlike a binomial variance.",
    "start": "141310",
    "end": "144170"
  },
  {
    "text": "And in fact, for\nthe multinomial,",
    "start": "144170",
    "end": "147220"
  },
  {
    "text": "these are on the of\nthe covariance matrix.",
    "start": "147220",
    "end": "151040"
  },
  {
    "text": "So this is a measure of total\nvariability in that region.",
    "start": "151040",
    "end": "157579"
  },
  {
    "text": "And if the Gini index\nis really small,",
    "start": "157580",
    "end": "159850"
  },
  {
    "text": "what that means is pretty\nmuch one class is favored",
    "start": "159850",
    "end": "163750"
  },
  {
    "text": "and all the rest\nare really small.",
    "start": "163750",
    "end": "165740"
  },
  {
    "text": "Whereas in an\nextreme case, Trevor,",
    "start": "165740",
    "end": "167240"
  },
  {
    "text": "if the region is pure,\nso it's all one class,",
    "start": "167240",
    "end": "169230"
  },
  {
    "text": "then one of those p hats will\nbe 1, the rest will be 0,",
    "start": "169230",
    "end": "172720"
  },
  {
    "text": "and G will be 0.",
    "start": "172720",
    "end": "174670"
  },
  {
    "text": "That's a good point.",
    "start": "174670",
    "end": "175520"
  },
  {
    "text": "And on the other hand,\nI guess if they're",
    "start": "175520",
    "end": "177970"
  },
  {
    "text": "all equally distributed\nin the classes,",
    "start": "177970",
    "end": "180280"
  },
  {
    "text": "the Gini index will be maximum.",
    "start": "180280",
    "end": "183610"
  },
  {
    "text": "But it changes in a smooth way.",
    "start": "183610",
    "end": "187330"
  },
  {
    "text": "So that's one of the criteria\nthat are very popular.",
    "start": "187330",
    "end": "190470"
  },
  {
    "start": "190470",
    "end": "193270"
  },
  {
    "text": "And it's also known\nas a purity index,",
    "start": "193270",
    "end": "196635"
  },
  {
    "text": "it measures the\npurity of the class.",
    "start": "196635",
    "end": "198135"
  },
  {
    "start": "198135",
    "end": "200780"
  },
  {
    "text": "An alternative is the\ndeviance or cross-entropy.",
    "start": "200780",
    "end": "205020"
  },
  {
    "text": "And this is based\non the binomial log",
    "start": "205020",
    "end": "208100"
  },
  {
    "text": "likelihood, or the\nmultinomial log likelihood.",
    "start": "208100",
    "end": "210450"
  },
  {
    "text": "And it's a measure that\nbehaves rather similarly",
    "start": "210450",
    "end": "214010"
  },
  {
    "text": "to the Gini index.",
    "start": "214010",
    "end": "215760"
  },
  {
    "text": "And either of these are used\nand give very similar results.",
    "start": "215760",
    "end": "219970"
  },
  {
    "start": "219970",
    "end": "222850"
  },
  {
    "text": "So let's look at an example.",
    "start": "222850",
    "end": "224600"
  },
  {
    "text": "We'll look at the heart data.",
    "start": "224600",
    "end": "226480"
  },
  {
    "text": "These data have a\nbinary m called HD.",
    "start": "226480",
    "end": "230230"
  },
  {
    "text": "There's 303 patients,\nand they all",
    "start": "230230",
    "end": "232780"
  },
  {
    "text": "represented with chest pains.",
    "start": "232780",
    "end": "234790"
  },
  {
    "text": "So the outcome has a value,\nyes indicates the presence",
    "start": "234790",
    "end": "238569"
  },
  {
    "text": "of heart disease, based on an\nangiographic test, while no",
    "start": "238570",
    "end": "241570"
  },
  {
    "text": "means no heart disease.",
    "start": "241570",
    "end": "243550"
  },
  {
    "text": "For these data, there\nare 13 predictors,",
    "start": "243550",
    "end": "246130"
  },
  {
    "text": "amongst them age, sex,\ncholesterol and other heart",
    "start": "246130",
    "end": "249790"
  },
  {
    "text": "and lung function measurements.",
    "start": "249790",
    "end": "252349"
  },
  {
    "text": "And so we ran the tree-growing\nprocess with cross validation,",
    "start": "252350",
    "end": "256790"
  },
  {
    "text": "and we see what we get\nin the next figure.",
    "start": "256790",
    "end": "260420"
  },
  {
    "text": "At the top, you see the full\ntree grown to all the data.",
    "start": "260420",
    "end": "265140"
  },
  {
    "text": "And you can see it's\nquite a bushy tree",
    "start": "265140",
    "end": "268190"
  },
  {
    "text": "with an early split on thal?",
    "start": "268190",
    "end": "271970"
  },
  {
    "text": "It's actually a\nthallium stress test.",
    "start": "271970",
    "end": "274670"
  },
  {
    "text": "A thallium stress test, OK.",
    "start": "274670",
    "end": "278074"
  },
  {
    "text": "And then the left and right\nnodes were split on CA--",
    "start": "278074",
    "end": "284210"
  },
  {
    "text": "Calcium I think.",
    "start": "284210",
    "end": "284990"
  },
  {
    "text": "--which is calcium.",
    "start": "284990",
    "end": "286710"
  },
  {
    "text": "And then the subsequent splits.",
    "start": "286710",
    "end": "289150"
  },
  {
    "text": "It's hard to see here, but\nthese pictures are in the book.",
    "start": "289150",
    "end": "292680"
  },
  {
    "text": "So quite a bushy tree.",
    "start": "292680",
    "end": "294620"
  },
  {
    "text": "And you see at the\nterminal nodes of this tree",
    "start": "294620",
    "end": "297889"
  },
  {
    "text": "are the classifications,\nno or yes.",
    "start": "297890",
    "end": "302430"
  },
  {
    "text": "So that means an observation\nthat, for example, ended up",
    "start": "302430",
    "end": "305479"
  },
  {
    "text": "in this leftmost terminal node\nhere, the majority in that class",
    "start": "305480",
    "end": "309260"
  },
  {
    "text": "were no's, no heart disease.",
    "start": "309260",
    "end": "311190"
  },
  {
    "text": "And so the classification\nproduced would be a no,",
    "start": "311190",
    "end": "315720"
  },
  {
    "text": "whereas the right-hand\none is a yes.",
    "start": "315720",
    "end": "320160"
  },
  {
    "text": "Interest, this terminal\nnode has two no's.",
    "start": "320160",
    "end": "324480"
  },
  {
    "text": "So if they both\npredicted no, why",
    "start": "324480",
    "end": "327180"
  },
  {
    "text": "was there a split here at all?",
    "start": "327180",
    "end": "328750"
  },
  {
    "text": "Well, it must mean\nthat one of these nodes",
    "start": "328750",
    "end": "330840"
  },
  {
    "text": "is purer than the other.",
    "start": "330840",
    "end": "332050"
  },
  {
    "text": "So even though\nthey both ended up",
    "start": "332050",
    "end": "334139"
  },
  {
    "text": "having a majority of\nno's, the one node",
    "start": "334140",
    "end": "337170"
  },
  {
    "text": "was purer than the other\nnode, and the Gini index",
    "start": "337170",
    "end": "340440"
  },
  {
    "text": "would identify such a node.",
    "start": "340440",
    "end": "343140"
  },
  {
    "text": "So this tree is\nprobably too bushy.",
    "start": "343140",
    "end": "345520"
  },
  {
    "text": "And so once again,\ncross-validation was used.",
    "start": "345520",
    "end": "347979"
  },
  {
    "text": "And again, we see in the\nright-hand panel, the results",
    "start": "347980",
    "end": "350760"
  },
  {
    "text": "of cross-validation.",
    "start": "350760",
    "end": "352920"
  },
  {
    "text": "And we see the training\nerror, the test error,",
    "start": "352920",
    "end": "357550"
  },
  {
    "text": "and the validation error.",
    "start": "357550",
    "end": "359099"
  },
  {
    "text": "Here we've actually looked at\nthe training error averaged",
    "start": "359100",
    "end": "362130"
  },
  {
    "text": "over each of the\ncross-validation folds, which",
    "start": "362130",
    "end": "365700"
  },
  {
    "text": "is why it's a little jumpy, and\nactually, even increases in one",
    "start": "365700",
    "end": "372327"
  },
  {
    "text": "point here, because the\ntrees and the architecture",
    "start": "372327",
    "end": "374410"
  },
  {
    "text": "of the trees are different\nin each of the folds.",
    "start": "374410",
    "end": "378250"
  },
  {
    "text": "The cross-validation and test\nerror, we had a left out test",
    "start": "378250",
    "end": "381970"
  },
  {
    "text": "set here as well.",
    "start": "381970",
    "end": "383180"
  },
  {
    "text": "Those curves look\npretty much the same.",
    "start": "383180",
    "end": "385419"
  },
  {
    "text": "And we end up seeing that a\ntree size of around about six,",
    "start": "385420",
    "end": "390100"
  },
  {
    "text": "tends to do well.",
    "start": "390100",
    "end": "392690"
  },
  {
    "text": "These bars on these cross\nvalidation and test curves",
    "start": "392690",
    "end": "396010"
  },
  {
    "text": "are standard error\nbars, so there's",
    "start": "396010",
    "end": "397540"
  },
  {
    "text": "quite a bit of variability,\nthe data set's not that big.",
    "start": "397540",
    "end": "400780"
  },
  {
    "text": "And on the right here, we\nsee the pruned back tree,",
    "start": "400780",
    "end": "404620"
  },
  {
    "text": "that's pruned back to size 6.",
    "start": "404620",
    "end": "407600"
  },
  {
    "text": "Of course, the pruning was again\ngoverned by the cost complexity",
    "start": "407600",
    "end": "412330"
  },
  {
    "text": "parameter, alpha.",
    "start": "412330",
    "end": "414159"
  },
  {
    "text": "And this year will be a\nsubtree of the big tree grown,",
    "start": "414160",
    "end": "418390"
  },
  {
    "text": "and that gave the best\nclassification performance,",
    "start": "418390",
    "end": "421520"
  },
  {
    "text": "which is estimated to be around\nabout 25% error in this case.",
    "start": "421520",
    "end": "426039"
  },
  {
    "start": "426040",
    "end": "430150"
  },
  {
    "text": "In this figure, we compared\ntrees with linear models.",
    "start": "430150",
    "end": "434830"
  },
  {
    "text": "Trees aren't always\nthe right thing to do.",
    "start": "434830",
    "end": "436879"
  },
  {
    "text": "And so to contrast that, we\nlook at two different scenarios.",
    "start": "436880",
    "end": "440590"
  },
  {
    "text": "In these cartoons\nhere, the truth",
    "start": "440590",
    "end": "443889"
  },
  {
    "text": "is indicated by\nthese two colors.",
    "start": "443890",
    "end": "445840"
  },
  {
    "text": "In this top left\npanel, the truth",
    "start": "445840",
    "end": "447970"
  },
  {
    "text": "is actually best depicted\nby a linear model.",
    "start": "447970",
    "end": "450230"
  },
  {
    "text": "So the decision\nboundary, in this case,",
    "start": "450230",
    "end": "452770"
  },
  {
    "text": "between the two classes,\nis best given by a line.",
    "start": "452770",
    "end": "456729"
  },
  {
    "text": "And in this case, a tree is\nnot going to do very well.",
    "start": "456730",
    "end": "460040"
  },
  {
    "text": "We see trees attempt to\npartition this space.",
    "start": "460040",
    "end": "463810"
  },
  {
    "text": "And while it does a\nvaliant job, it just",
    "start": "463810",
    "end": "467440"
  },
  {
    "text": "doesn't do well\nenough, because it's",
    "start": "467440",
    "end": "469450"
  },
  {
    "text": "confined to big boxy regions.",
    "start": "469450",
    "end": "471530"
  },
  {
    "text": "So there'd be a split over\nhere, a split over there.",
    "start": "471530",
    "end": "474590"
  },
  {
    "text": "And then this region\nwas subdivided,",
    "start": "474590",
    "end": "476270"
  },
  {
    "text": "then that region was\nsubdivided in an attempt",
    "start": "476270",
    "end": "479169"
  },
  {
    "text": "to get at this linear\ndecision boundary.",
    "start": "479170",
    "end": "482780"
  },
  {
    "text": "So this would be\nclassified as beige.",
    "start": "482780",
    "end": "487430"
  },
  {
    "text": "This would be classified as\ngreen, beige, green, and so on",
    "start": "487430",
    "end": "491840"
  },
  {
    "text": "in a steppy fashion.",
    "start": "491840",
    "end": "495270"
  },
  {
    "text": "On the other hand, in\nthe lower two panels,",
    "start": "495270",
    "end": "498389"
  },
  {
    "text": "the optimal region is a\nblocky partition region.",
    "start": "498390",
    "end": "505150"
  },
  {
    "text": "And here a linear model\nis not going to do well.",
    "start": "505150",
    "end": "507580"
  },
  {
    "text": "In the left panel, we see\nthe best linear approximation",
    "start": "507580",
    "end": "510300"
  },
  {
    "text": "to this decision\nboundary, and it's",
    "start": "510300",
    "end": "512010"
  },
  {
    "text": "going to make lots of\nerrors, because with one",
    "start": "512010",
    "end": "514979"
  },
  {
    "text": "single linear boundary,\nit's hard to approximate",
    "start": "514980",
    "end": "517678"
  },
  {
    "text": "a rectangular region like this.",
    "start": "517679",
    "end": "519460"
  },
  {
    "text": "And of course, in this\none, a tree will nail it.",
    "start": "519460",
    "end": "522309"
  },
  {
    "text": "So with two splits, it can get\nthe decision boundary perfectly.",
    "start": "522309",
    "end": "526320"
  },
  {
    "text": "So some problems are more\nnaturally suited to trees,",
    "start": "526320",
    "end": "529740"
  },
  {
    "text": "some problems aren't.",
    "start": "529740",
    "end": "531040"
  },
  {
    "text": "And so the idea is,\nwe're going to think",
    "start": "531040",
    "end": "532709"
  },
  {
    "text": "of trees as one\ntool in our toolbox,",
    "start": "532710",
    "end": "535020"
  },
  {
    "text": "and we'll use it\nwhere appropriate.",
    "start": "535020",
    "end": "537700"
  },
  {
    "text": "But of course, we'll also bear\nin mind simpler linear models",
    "start": "537700",
    "end": "541680"
  },
  {
    "text": "as well.",
    "start": "541680",
    "end": "544740"
  },
  {
    "text": "So just to wrap up\nthe section on trees,",
    "start": "544740",
    "end": "546779"
  },
  {
    "text": "then, we've seen there's\nadvantages and disadvantages.",
    "start": "546780",
    "end": "550300"
  },
  {
    "text": "In a sense, they're simple, if\nthe trees are small, not too",
    "start": "550300",
    "end": "553589"
  },
  {
    "text": "many terminal nodes,\nbecause they're",
    "start": "553590",
    "end": "555090"
  },
  {
    "text": "easy to display and to\nunderstand for non-specialists.",
    "start": "555090",
    "end": "559110"
  },
  {
    "text": "And for example, if we look\nback at this heart disease tree,",
    "start": "559110",
    "end": "562470"
  },
  {
    "text": "right, the prune one\nin the bottom, a doctor",
    "start": "562470",
    "end": "567899"
  },
  {
    "text": "might like this tree, because\nit mimics, in a sense,",
    "start": "567900",
    "end": "571470"
  },
  {
    "text": "the way his decision-making\nprocess might work.",
    "start": "571470",
    "end": "573550"
  },
  {
    "text": "In other words, trying to decide\nwhether a patient has heart",
    "start": "573550",
    "end": "575279"
  },
  {
    "text": "disease, he might first\ndo an initial test,",
    "start": "575280",
    "end": "577230"
  },
  {
    "text": "based on thallium stress test.",
    "start": "577230",
    "end": "579000"
  },
  {
    "text": "And if they fail that test,\nthen do a further test,",
    "start": "579000",
    "end": "582990"
  },
  {
    "text": "based on calcium, and\ndecide about heart disease.",
    "start": "582990",
    "end": "586180"
  },
  {
    "text": "If the test was passed, we,\nagain, do a calcium test,",
    "start": "586180",
    "end": "590760"
  },
  {
    "text": "and then followed by\nsome other criteria.",
    "start": "590760",
    "end": "593500"
  },
  {
    "text": "So you stratify the population\nin a series of simple rules",
    "start": "593500",
    "end": "596658"
  },
  {
    "text": "to try to determine whether a\npatient is of high or low risk.",
    "start": "596658",
    "end": "599200"
  },
  {
    "text": "So for that reason,\ntrees are popular,",
    "start": "599200",
    "end": "601920"
  },
  {
    "text": "because of their simplicity in\nthe fact that they mimic the way",
    "start": "601920",
    "end": "605350"
  },
  {
    "text": "some people make decisions\nas a series of splits.",
    "start": "605350",
    "end": "610759"
  },
  {
    "text": "And they can display\nin a simple tree, which",
    "start": "610760",
    "end": "613095"
  },
  {
    "text": "means, again,\nthey're attractive,",
    "start": "613095",
    "end": "614470"
  },
  {
    "text": "because there aren't equations\nto have to understand.",
    "start": "614470",
    "end": "617269"
  },
  {
    "text": "They can also handle qualitative\npredictors without the need",
    "start": "617270",
    "end": "620110"
  },
  {
    "text": "to create dummy variables.",
    "start": "620110",
    "end": "621878"
  },
  {
    "text": "In other words, some of\nthe categorical variables",
    "start": "621878",
    "end": "623920"
  },
  {
    "text": "can have more than\ntwo levels, and you",
    "start": "623920",
    "end": "626230"
  },
  {
    "text": "can split a categorical variable\ninto two sets of subcategories.",
    "start": "626230",
    "end": "631459"
  },
  {
    "text": "So these are all good things.",
    "start": "631460",
    "end": "633020"
  },
  {
    "text": "The big downside is that they\ndon't predict so well compared",
    "start": "633020",
    "end": "637790"
  },
  {
    "text": "to more state-of-the-art\nmethods.",
    "start": "637790",
    "end": "639712"
  },
  {
    "text": "And we'll see, for\nexample, for the hard data,",
    "start": "639713",
    "end": "641630"
  },
  {
    "text": "that the prediction\naccuracy of a tree",
    "start": "641630",
    "end": "644090"
  },
  {
    "text": "is not very good compared\nto other methods.",
    "start": "644090",
    "end": "646317"
  },
  {
    "text": "The other methods\nwe'll talk about now",
    "start": "646317",
    "end": "647900"
  },
  {
    "text": "are actually used trees, but in\nensemble, they combine trees.",
    "start": "647900",
    "end": "652250"
  },
  {
    "text": "They build many trees\non the same data,",
    "start": "652250",
    "end": "655040"
  },
  {
    "text": "and then they average or\ncombining them in some way,",
    "start": "655040",
    "end": "657320"
  },
  {
    "text": "and in the process they\nimprove the prediction error",
    "start": "657320",
    "end": "659487"
  },
  {
    "text": "substantially.",
    "start": "659487",
    "end": "661450"
  }
]
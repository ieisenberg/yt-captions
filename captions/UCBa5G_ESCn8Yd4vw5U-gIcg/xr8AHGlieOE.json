[
  {
    "start": "0",
    "end": "5510"
  },
  {
    "text": "So, today, we're pleased to have\nTatsu Hashimoto here with us.",
    "start": "5510",
    "end": "10880"
  },
  {
    "text": "Tatsu did his PhD at MIT,\ndid a post-doc at Stanford, spent one year as a researcher\nat Microsoft Semantic Machines.",
    "start": "10880",
    "end": "18680"
  },
  {
    "text": "And he's joining\nStanford as of last month as a fresh assistant professor.",
    "start": "18680",
    "end": "24290"
  },
  {
    "text": "So welcome back to Stanford. He'll actually be teaching\n221 in the winter.",
    "start": "24290",
    "end": "30980"
  },
  {
    "text": "So if you like his\ntalk, you should go tell all your friends to have\nthem take 221 in the winter.",
    "start": "30980",
    "end": "37700"
  },
  {
    "text": "So Tatsu has worked\non a number of areas from computational biology,\ntext generation, and NLP.",
    "start": "37700",
    "end": "44450"
  },
  {
    "text": "But he's probably really\nwell-known for his work on robustness in\nmachine learning.",
    "start": "44450",
    "end": "50629"
  },
  {
    "text": "And I think throughout\nthis course, we've emphasized that machine\nlearning is something that's",
    "start": "50630",
    "end": "56840"
  },
  {
    "text": "really being deployed in the\nreal world all over right now and having real\nimpact in the world.",
    "start": "56840",
    "end": "63710"
  },
  {
    "text": "Just last week, we heard\nfrom Tino Cuellar about this. So I think robustness of\nmachine learning systems",
    "start": "63710",
    "end": "69230"
  },
  {
    "text": "is a really, really\nimportant area. And Tatsu is an expert in this. So I'm really happy\nto have him tell us",
    "start": "69230",
    "end": "75859"
  },
  {
    "text": "what robustness in machine\nlearning is all about and where things\nare at the moment. So take it away, Tatsu.",
    "start": "75860",
    "end": "83640"
  },
  {
    "text": "OK, great. So I want to start with\nemphasizing what Percy already",
    "start": "83640",
    "end": "89909"
  },
  {
    "text": "said, which is that there's\nbeen this enormous and rapid progress in machine learning\nover the last decade",
    "start": "89910",
    "end": "96540"
  },
  {
    "text": "or so in-- especially in\ntasks like image recognition. 10 years ago, errors were\nat the level of 20%, 30%,",
    "start": "96540",
    "end": "105329"
  },
  {
    "text": "and human level\nperformance was sub 7%. And there was this huge\ngap in performance,",
    "start": "105330",
    "end": "112415"
  },
  {
    "text": "and everyone said it will\ntake a long time to reach human-level performance. But, nowadays, really,\nhuman-level performance",
    "start": "112415",
    "end": "118710"
  },
  {
    "text": "is being achieved on all sorts\nof tasks, image recognition as of, say, 2015 but also in\ntasks like natural language",
    "start": "118710",
    "end": "125160"
  },
  {
    "text": "processing and much\nmore challenging reasoning-based tasks. These systems are now\ngetting really close if not",
    "start": "125160",
    "end": "131160"
  },
  {
    "text": "exceeding human performance. And so machine\nlearning has really achieved these sort\nof great successes,",
    "start": "131160",
    "end": "137250"
  },
  {
    "text": "and they're being deployed. And we can sort of ask, what has\nmachine learning been good at? And what is it good at?",
    "start": "137250",
    "end": "142418"
  },
  {
    "text": "And it's really good\nat extracting patterns from training data and applying\nthis on a test distribution",
    "start": "142418",
    "end": "148860"
  },
  {
    "text": "to do some prediction. And so we can think of this as\nclassic digit prediction tasks. You have some images\nof digits, and you",
    "start": "148860",
    "end": "155040"
  },
  {
    "text": "need to return the numbers\nthat are associated with them. As long as sort of the\nsource and the target distributions look the same,\nmodern machine learning systems",
    "start": "155040",
    "end": "163920"
  },
  {
    "text": "based on large amounts\nof data and neural nets are going to do exceedingly\nwell on these tasks. But, really, the\nchallenge is, what",
    "start": "163920",
    "end": "170310"
  },
  {
    "text": "if the training data doesn't\nlook very much like the test data? In these cases, we're going\nto have a lot of challenges.",
    "start": "170310",
    "end": "177340"
  },
  {
    "text": "So on the image that I put\nhere in the source domain, we have these black\nand white images",
    "start": "177340",
    "end": "182670"
  },
  {
    "text": "in sort of desaturated settings. And now at test time, you have\nthese yellow cabs in New York,",
    "start": "182670",
    "end": "187980"
  },
  {
    "text": "and your predictions\nmight not work so well once you\nhave this what's called distribution shift.",
    "start": "187980",
    "end": "193950"
  },
  {
    "text": "And so once we start\nto think about going beyond just sort of data that\nlooks like the training data,",
    "start": "193950",
    "end": "199110"
  },
  {
    "text": "we see a lot of\nproblems on the horizon. And we've discovered a\nlot of these problems beyond test set accuracy.",
    "start": "199110",
    "end": "205090"
  },
  {
    "text": "And I'm going to, at the\nbeginning of this talk, cover sort of three\nclasses of problems that, hopefully,\nyou'll think about",
    "start": "205090",
    "end": "211590"
  },
  {
    "text": "as you sort of continue on\nyour journey in AI and machine learning. The first one is sort of\ndiscrimination and performance",
    "start": "211590",
    "end": "218250"
  },
  {
    "text": "on minorities. Another one is\nvulnerability to adversaries in high-stakes\nsecure applications.",
    "start": "218250",
    "end": "226290"
  },
  {
    "text": "And then last one, which is\na little bit more abstract, but I will get into\nthis in more detail, is that models\ndon't really display",
    "start": "226290",
    "end": "232680"
  },
  {
    "text": "an understanding of the\ntasks that they're actually performing. And this is going to be\na little bit abstract. But because it's a\nAI-focused class,",
    "start": "232680",
    "end": "239340"
  },
  {
    "text": "I think this is\nan important thing to be discussing\nand going through. And so it's sort of\nthe unifying theme.",
    "start": "239340",
    "end": "244770"
  },
  {
    "text": "These seem like very different\nproblems, right, problems that machine learning\nsystems have today. But, really, they're\nall sort of connected",
    "start": "244770",
    "end": "251190"
  },
  {
    "text": "with a single underlying theme,\nin that many of these problems can be cast as these\nproblems in robustness.",
    "start": "251190",
    "end": "258167"
  },
  {
    "text": "And so when the training\ndistribution and the test distribution are\ndifferent, these models break down because\nthey're brittle.",
    "start": "258167",
    "end": "265715"
  },
  {
    "text": "So to start with,\nlet's talk about sort of discrimination and\nfairness in minority groups. So a really typical thing that\nhappens in a lot of machine",
    "start": "265715",
    "end": "275440"
  },
  {
    "text": "learning systems\ntoday is that there is sort of a majority group. Let's say western\ncultures, English text,",
    "start": "275440",
    "end": "281320"
  },
  {
    "text": "or sort of males in many cases. So in this majority group that\ndominates the training data,",
    "start": "281320",
    "end": "286840"
  },
  {
    "text": "you get extremely good\nsuperhuman performance in these systems. And, often, you are going\nto be deploying this",
    "start": "286840",
    "end": "293410"
  },
  {
    "text": "to a wide variety of users. And so you will have\nminorities using your system.",
    "start": "293410",
    "end": "298630"
  },
  {
    "text": "And in these cases, you\nend up with horrible sort of near random performance. And you can sort\nof immediately see",
    "start": "298630",
    "end": "304000"
  },
  {
    "text": "how this is a discrimination\nissue and sort of an equity issue. And I'm going to go over a\nlot of these examples in turn.",
    "start": "304000",
    "end": "310120"
  },
  {
    "text": "But these just show up\nin all sorts of places that you might not\ninitially think about when you think about\nfairness problems like, say,",
    "start": "310120",
    "end": "315819"
  },
  {
    "text": "dependency parsing\nor video captioning. Face recognition is\na very common one that people probably\nalready know.",
    "start": "315820",
    "end": "321970"
  },
  {
    "text": "But in these sorts of common\nwidely deployed ML systems, you start to see\nthese gaps between how these systems perform on\nmajority groups versus minority",
    "start": "321970",
    "end": "331220"
  },
  {
    "text": "groups.  So the first one that I\nthink is probably maybe",
    "start": "331220",
    "end": "337080"
  },
  {
    "text": "surprising to many people that\nthere's these kinds of gaps, it is a test called\ndependency parsing.",
    "start": "337080",
    "end": "342250"
  },
  {
    "text": "So the input is just sort of\nsentences tokenized and sort of split up. So an example here\nis bills on ports",
    "start": "342250",
    "end": "348540"
  },
  {
    "text": "and immigration were submitted\nby Senator Brownback, Republican of Kansas. And the output is\nthat you're supposed",
    "start": "348540",
    "end": "354810"
  },
  {
    "text": "to analyze sort of the syntactic\nstructure of this sentence and create dependencies between\nwhat are called headwords",
    "start": "354810",
    "end": "360390"
  },
  {
    "text": "and their dependents. And so you end up with what\nlooks like a tree here. And so the sentence above, like\nthe bills on ports and so on,",
    "start": "360390",
    "end": "367650"
  },
  {
    "text": "can be parsed into this\ntree-shaped structure here on the bottom. And so this is called dependency\nparsing because there's",
    "start": "367650",
    "end": "373920"
  },
  {
    "text": "these explicit\ndependencies between tokens that show up in your data.",
    "start": "373920",
    "end": "379440"
  },
  {
    "text": "And in sort of\nclassical NLP pipelines such as, say, if you\nwant to extract relations between people or entities, who\nwas the person that submitted",
    "start": "379440",
    "end": "387659"
  },
  {
    "text": "the bill in the\nsentence, for example, you might use something\nlike a dependency parser to look at dependencies\nin your sentence",
    "start": "387660",
    "end": "393917"
  },
  {
    "text": "and to extract relations, right? So this is a first step\nin terms of getting these kinds of more\nsophisticated analyses",
    "start": "393917",
    "end": "400560"
  },
  {
    "text": "in these sort of\nclassical pipelines. Nowadays, many things are\nsort of end-to-end and neural. But that's sort of\nbeside the point here.",
    "start": "400560",
    "end": "407430"
  },
  {
    "text": "And what's sort of surprising--\nor maybe not surprising if you've thought about\nthese kinds of problems is that these parsers\ndo much, much worse",
    "start": "407430",
    "end": "414750"
  },
  {
    "text": "on data that's not\ncommonly used to train these dependency parsers.",
    "start": "414750",
    "end": "419880"
  },
  {
    "text": "So this is a study from\nSu Lin Blodgett in 2016, where they took a bunch of\ndifferent dependency parsers",
    "start": "419880",
    "end": "427110"
  },
  {
    "text": "and applied them to text from\nstandard American English as well as African-American\nvernacular.",
    "start": "427110",
    "end": "433050"
  },
  {
    "text": "And that's the column\nlabeled AA LAS. And the performance here\nis measured by what's",
    "start": "433050",
    "end": "438900"
  },
  {
    "text": "called label attachment score. So that's how well do\nyou reconstruct the tree. And the numbers here,\nyou might not really",
    "start": "438900",
    "end": "444450"
  },
  {
    "text": "know how to internalize this. But you see these\nbig gaps, right? So in terms of standard\nAmerican English,",
    "start": "444450",
    "end": "450030"
  },
  {
    "text": "you get this 57 sort of\nF1-score type accuracy and then 43 in African-American.",
    "start": "450030",
    "end": "456330"
  },
  {
    "text": "And you get a 14-point gap. And sort of state of\nthe art for this task you're competing over\na one-point difference.",
    "start": "456330",
    "end": "461715"
  },
  {
    "text": "So these are enormous\ngaps once you go from standard\nAmerican English to African-American vernacular.",
    "start": "461715",
    "end": "467550"
  },
  {
    "text": "And these kinds of things can\nhave huge downstream impact if they're used in things\nlike relation extraction or QA",
    "start": "467550",
    "end": "473370"
  },
  {
    "text": "systems, right, because\ntext from African-Americans are just systematically\nnot going to get extracted",
    "start": "473370",
    "end": "479069"
  },
  {
    "text": "into, say, relations or entities\nwhen you build knowledge bases and things like that. And so you might\nsee how this begins",
    "start": "479070",
    "end": "486450"
  },
  {
    "text": "to affect these kinds\nof minority groups through these kinds of\nrobustness problems. ",
    "start": "486450",
    "end": "494770"
  },
  {
    "text": "Another example is\nvideo captioning. So many of you have\nalready interacted",
    "start": "494770",
    "end": "499830"
  },
  {
    "text": "with systems like this through\nYouTube's video captioning system, where the\ninput is you have",
    "start": "499830",
    "end": "505319"
  },
  {
    "text": "a video with some\nspoken text audio, and the output is text\ncaptions that are automatically",
    "start": "505320",
    "end": "510930"
  },
  {
    "text": "added to the video. And these things are\nincreasingly important because, say, if you have a--",
    "start": "510930",
    "end": "517679"
  },
  {
    "text": "I know that in medical\ndomains, if you have Medicaid-funded\nsort of videos that you need to put\nup on the internet,",
    "start": "517679",
    "end": "522909"
  },
  {
    "text": "you need to have captions. And so in these cases, you\neither run these systems, or you have people\ntranscribe the videos.",
    "start": "522909",
    "end": "531390"
  },
  {
    "text": "And what's been found is\nthat these kinds of systems work a lot worse for women. So this is a study by\nRachael Tatman in 2017,",
    "start": "531390",
    "end": "538740"
  },
  {
    "text": "where she basically showed\nthat if you took male versus female speakers and\nyou ran them through YouTube's",
    "start": "538740",
    "end": "545580"
  },
  {
    "text": "video captioning system,\nyou got systematically higher error rates for women. And you see that sort\nof the median error rate",
    "start": "545580",
    "end": "550857"
  },
  {
    "text": "is essentially the upper\nquartile error rate for men. So that's actually a pretty\nsubstantial difference in the word error rate\nbetween these two groups.",
    "start": "550857",
    "end": "558180"
  },
  {
    "text": "And you also see sort\nof expected differences between dialects, which\nis Scottish speakers get substantially worse\nvideo captioning accuracy,",
    "start": "558180",
    "end": "566760"
  },
  {
    "text": "whereas speakers from California\nget really good word error rates. And so you can see how\nthis manifests, right?",
    "start": "566760",
    "end": "574170"
  },
  {
    "text": "YouTube being based in\nCalifornia, obviously dogfooded with people\nwith Californian accents",
    "start": "574170",
    "end": "579630"
  },
  {
    "text": "and, when tested\nout of distribution on Scottish speakers,\nsuddenly performs a lot worse.",
    "start": "579630",
    "end": "584860"
  },
  {
    "text": "And so this is the kind\nof robustness problems that you initially don't think\nabout because you sort of think about, well, is our\nmodel performing well",
    "start": "584860",
    "end": "591600"
  },
  {
    "text": "on really complex inputs? And so you might put in\nsome really complex inputs",
    "start": "591600",
    "end": "597150"
  },
  {
    "text": "as a California speaker. But, really, you haven't\ntested out of distribution on Scottish accents.",
    "start": "597150",
    "end": "602654"
  },
  {
    "text": " And then we'll come to another\nexample, which many of you",
    "start": "602655",
    "end": "608430"
  },
  {
    "text": "hopefully already know,\nin facial recognition. This has sort of been\nreally widely discussed even in the media.",
    "start": "608430",
    "end": "614190"
  },
  {
    "text": "And just to go over\nwhat the task is, the input is images,\npossibly containing a face",
    "start": "614190",
    "end": "621209"
  },
  {
    "text": "or not depending on the task. And you can do many sorts\nof things with these images. And there are many\noutputs that are",
    "start": "621210",
    "end": "626808"
  },
  {
    "text": "associated with facial\nrecognition or identification tasks. And so you might ask, is\nthere a face in this image?",
    "start": "626808",
    "end": "632820"
  },
  {
    "text": "And that's sort of\nface recognition. You might need to match a given\nface to a database of faces.",
    "start": "632820",
    "end": "639690"
  },
  {
    "text": "And that would be\nidentification, or you might need to\npredict attributes. Is this face a female face or\na male face or happy or sad?",
    "start": "639690",
    "end": "649810"
  },
  {
    "text": "You have many sort of\nattribute prediction tasks that can be built\non top of faces. And this is one of\nthe original studies,",
    "start": "649810",
    "end": "658210"
  },
  {
    "text": "I think, in terms\nof highlighting how bad these kinds\nof systems can be in sort of widespread ways.",
    "start": "658210",
    "end": "664820"
  },
  {
    "text": "And so there's a study from\nMIT Media Lab, Gender Shades, and Joy Buolamwini in\n2018, where she basically",
    "start": "664820",
    "end": "673060"
  },
  {
    "text": "took a whole bunch of\nportraits of legislators from different\ncountries, African",
    "start": "673060",
    "end": "679330"
  },
  {
    "text": "and, I think, northern\nEuropean, and ran them through different face\nattribute prediction systems for",
    "start": "679330",
    "end": "685660"
  },
  {
    "text": "whether or not they\nwere male or female. And what you can sort of\nsee on this on the top right",
    "start": "685660",
    "end": "691510"
  },
  {
    "text": "is that dark female skin\nresults in much worse gender",
    "start": "691510",
    "end": "696820"
  },
  {
    "text": "predictions compared to\nlight-skinned males, where you basically have\nperfect prediction.",
    "start": "696820",
    "end": "703570"
  },
  {
    "text": "And these kinds of things\nare pretty problematic. If you've been\ntesting your systems on light-skinned\npeople, you think",
    "start": "703570",
    "end": "710320"
  },
  {
    "text": "your system is near perfect. And so you might be using it for\nreally high-stakes tasks where",
    "start": "710320",
    "end": "715360"
  },
  {
    "text": "you need 100% performance. But then when applied to the\ndarker-skinned demographic",
    "start": "715360",
    "end": "720670"
  },
  {
    "text": "groups, you end up with\nsubstantially worse performance. And so you don't even\nrealize the kinds of harms",
    "start": "720670",
    "end": "727150"
  },
  {
    "text": "that you're causing by using\nthese kinds of systems. And what's sort of problematic\nand sort of you can see",
    "start": "727150",
    "end": "734520"
  },
  {
    "text": "is that they reflect a lot\nof the benchmark data that's been constructed for this task. And so on the right,\non the right bottom",
    "start": "734520",
    "end": "740097"
  },
  {
    "text": "here, you see the distribution\nof sort of skin color",
    "start": "740097",
    "end": "745140"
  },
  {
    "text": "and gender for\nbenchmark data sets in this kind of sort of\ngender identification",
    "start": "745140",
    "end": "751740"
  },
  {
    "text": "from face image tasks. And what you see is\nthat there's sort of a systematic\nunderrepresentation",
    "start": "751740",
    "end": "757230"
  },
  {
    "text": "of both females and\ndarker-skinned demographics. And you might say this\nreally just reflects",
    "start": "757230",
    "end": "765270"
  },
  {
    "text": "the underlying\ndata distribution. And so maybe all we need\nto get is unbiased data. You hear this term\na lot from, I think,",
    "start": "765270",
    "end": "772080"
  },
  {
    "text": "people who haven't thought\ntoo deeply about problems of robustness. But the issue is\nthat there's really",
    "start": "772080",
    "end": "778110"
  },
  {
    "text": "no such thing as truly\nunbiased data in the sense that there will always be an\nunderrepresented group if you slice your data fine enough.",
    "start": "778110",
    "end": "784230"
  },
  {
    "text": "So we need to really\njust go beyond thinking about balancing the data set. And we need to think about\nhow can we make our models",
    "start": "784230",
    "end": "789528"
  },
  {
    "text": "work well even for really\nsmall groups, really small demographic groups\nand even individuals. ",
    "start": "789528",
    "end": "796430"
  },
  {
    "text": "Another task that has\nthese kinds of issues is language identification.",
    "start": "796430",
    "end": "801530"
  },
  {
    "text": "So as an input, you might\nbe working at Twitter. And you need to identify\nthe language of a tweet so that you can run a\nmachine translation system",
    "start": "801530",
    "end": "808387"
  },
  {
    "text": "and automatically translate\na tweet into someone's sort of speaking language.",
    "start": "808387",
    "end": "813459"
  },
  {
    "text": "But in order to\ndo this, you need to first identify what text\nthe tweet is written in, right?",
    "start": "813460",
    "end": "818620"
  },
  {
    "text": "And so you might have a lot\nof different kinds of inputs. And this figure one shows\nthe challenge in this task.",
    "start": "818620",
    "end": "824690"
  },
  {
    "text": "So you might have\ndialectical text. So the top one is\nNigerian English.",
    "start": "824690",
    "end": "830140"
  },
  {
    "text": "The second one is\nsort of Irish tweets, and the last one you\ncan have code switching. So you can have a mix of\nboth Indonesian and English.",
    "start": "830140",
    "end": "837250"
  },
  {
    "text": "And so in language\nidentification, when you're given\nthese kinds of tweets, you need to identify\nthe source language",
    "start": "837250",
    "end": "843310"
  },
  {
    "text": "that they were written in. And so the output of the\ntask is the language.",
    "start": "843310",
    "end": "848535"
  },
  {
    "text": "What's sort of\nbeen identified is that there's systematic\nbiases once again in language identification.",
    "start": "848535",
    "end": "853839"
  },
  {
    "text": "And sort of one that's\nimmediately a little bit troubling is that\nAfrican-American English often gets identified not as English.",
    "start": "853840",
    "end": "860290"
  },
  {
    "text": "So there's sort of like an\nimplicit normative judgment being made here that\nAfrican-American Vernacular is",
    "start": "860290",
    "end": "865870"
  },
  {
    "text": "not English. And you see this\nerror rate here as AAE having almost double the error\nrate of language identification",
    "start": "865870",
    "end": "872800"
  },
  {
    "text": "compared to a more standard\nAmerican English data set. And you also see this\nacross languages.",
    "start": "872800",
    "end": "879340"
  },
  {
    "text": "And this is a study by\nJurgens et al in 2017, where if you sort the languages\nby the human development",
    "start": "879340",
    "end": "886149"
  },
  {
    "text": "index of the countries, you see\nthat there is this decreasing recall or decreasing\naccuracy as the countries",
    "start": "886150",
    "end": "893352"
  },
  {
    "text": "get less and less developed. And that's because, often,\nthese kinds of countries have under-resourced data sets.",
    "start": "893353",
    "end": "899770"
  },
  {
    "text": "And so there isn't as\nmuch data with which to train these language\nidentification systems.",
    "start": "899770",
    "end": "905180"
  },
  {
    "text": "So you see these\nsystematic biases in terms of how well-developed\nand how internet connected these countries are.",
    "start": "905180",
    "end": "911500"
  },
  {
    "text": "And this leads to sort of\nrepresentational harms, right? If you're an African-American\nEnglish speaker and the system tells you that\nyou're not speaking English,",
    "start": "911500",
    "end": "919180"
  },
  {
    "text": "that's kind of harmful. And there's also\nutility harms,, right? If your text doesn't\nautomatically get translated to\nEnglish, you're going to--",
    "start": "919180",
    "end": "926649"
  },
  {
    "text": "your tweets won't reach\nas wide of an audience. And so you can think\nof these as having sort of pretty serious\nimplications for fairness",
    "start": "926650",
    "end": "934150"
  },
  {
    "text": "as machine learning becomes\nmore widespread and more useful and more impactful. And so there's these\nproblems of serious sort",
    "start": "934150",
    "end": "942080"
  },
  {
    "text": "of active discrimination, where\nthis was a story in The New York Times, where a face\nrecognition system identified",
    "start": "942080",
    "end": "950590"
  },
  {
    "text": "a person as being a criminal. And this was faulty,\nand this was essentially the only reason for\narresting this Michigan man.",
    "start": "950590",
    "end": "957190"
  },
  {
    "text": "And so if you have\na system that's much more error-prone\non African-Americans, you're basically going to\nhave a much higher error",
    "start": "957190",
    "end": "963700"
  },
  {
    "text": "rate when deploying these\nkinds of algorithms. So you have these active\ndiscriminations and harms that are being done. But on the other side, we think\nthat-- as people taking machine",
    "start": "963700",
    "end": "972274"
  },
  {
    "text": "learning and studying\nmachine learning, we think that these\nkinds of technologies are broadly beneficial and\nuseful and increase efficiency.",
    "start": "972275",
    "end": "979360"
  },
  {
    "text": "And so there's a study by\nEric Brynjolfsson, which says the application of\nmachine translation systems",
    "start": "979360",
    "end": "987250"
  },
  {
    "text": "increased exports\non eBay by 17.5% because it's really\neasy to translate text.",
    "start": "987250",
    "end": "992920"
  },
  {
    "text": "And so people from other\ncountries can buy your product. But if, for example,\nlanguage identifiers",
    "start": "992920",
    "end": "998200"
  },
  {
    "text": "can't identify your\nlanguage and so you can't use machine\ntranslation systems, then you don't get\nthese benefits, right?",
    "start": "998200",
    "end": "1003510"
  },
  {
    "text": "So you get unequal access\nto sort of the fruits of these kinds of AI systems. And so this can lead to\nsort of harms in both ways.",
    "start": "1003510",
    "end": "1011710"
  },
  {
    "text": "You don't get access\nto the benefits, and you get these kinds of\nactive harms from the errors that these systems make.",
    "start": "1011710",
    "end": "1018300"
  },
  {
    "text": "And I'm going to\nstop here because I think fairness is a topic\nthat many people have feelings",
    "start": "1018300",
    "end": "1023477"
  },
  {
    "text": "and comments about. And I'd be happy to sort of\njust sit around and discuss for the next couple\nof minutes if anyone has questions about\nsort of how fairness",
    "start": "1023478",
    "end": "1030685"
  },
  {
    "text": "and these sorts of\nrobustness questions interact with each other. Yeah, Tatsu, there's a bunch\nof questions in the chat.",
    "start": "1030685",
    "end": "1036099"
  },
  {
    "text": "Oh. You mind taking a look? Yes, sorry. I have full screen. So give me a moment\nto pull up the chat.",
    "start": "1036099",
    "end": "1045040"
  },
  {
    "text": "Yes, OK. OK, I see it now. OK, so I think there are--",
    "start": "1045040",
    "end": "1053142"
  },
  {
    "text": "I'll start with the\nfirst question, which is having balanced,\nunbiased data is not enough.",
    "start": "1053142",
    "end": "1059130"
  },
  {
    "text": "And so this is a\nvery subtle point. So there are data\nthat you can construct that will make you robust to\ncertain kinds of groups, right?",
    "start": "1059130",
    "end": "1066010"
  },
  {
    "text": "So let's go back\nto just this slide. ",
    "start": "1066010",
    "end": "1071770"
  },
  {
    "text": "So if we look at this sort\nof distribution of data, it's clear that at least\nfor this top one Adience,",
    "start": "1071770",
    "end": "1077850"
  },
  {
    "text": "we're probably going to have\nsome sort of bias in terms of light versus dark-skinned\nbecause dark-skinned is so underrepresented.",
    "start": "1077850",
    "end": "1084390"
  },
  {
    "text": "But if we balance this\ndata out, right, we might still have sort of\nunbalanced demographics",
    "start": "1084390",
    "end": "1091559"
  },
  {
    "text": "in certain other areas. Maybe it's not dark\nversus light skin, but maybe it's\ngeographic region.",
    "start": "1091560",
    "end": "1097290"
  },
  {
    "text": "It might be income, right? These kinds of problems\nare innumerable. And so what you really\nneed is not necessarily",
    "start": "1097290",
    "end": "1102870"
  },
  {
    "text": "the search for this\nunreachable perfectly balanced data set but\nsort of a model that",
    "start": "1102870",
    "end": "1108420"
  },
  {
    "text": "can sort of do well\non small data sets or small amounts of data. So you want to have\na model that can",
    "start": "1108420",
    "end": "1114060"
  },
  {
    "text": "take in these kinds\nof imbalanced data and do well both on the male-- or sorry-- the dark\nand the light-skinned.",
    "start": "1114060",
    "end": "1119550"
  },
  {
    "text": "And the important\nthing in this task is there's no real\ntrade off, right? There's no real reason that you\ncan't do well on both the light",
    "start": "1119550",
    "end": "1125370"
  },
  {
    "text": "and dark-skinned. And I think that's the sort\nof crucial structure here. If you can do well\non both groups,",
    "start": "1125370",
    "end": "1130965"
  },
  {
    "text": "then it's not really\nabout the amount of data or the distribution of data. It's more about the model and\nsort of how you're learning it.",
    "start": "1130965",
    "end": "1139000"
  },
  {
    "text": "And the second question-- \"Is there a way to audit\nmodels without having access to the model?\"",
    "start": "1139000",
    "end": "1146019"
  },
  {
    "text": "So that's an\ninteresting question. I mean, I'm not sure if you\nmeant by this like access",
    "start": "1146020",
    "end": "1151740"
  },
  {
    "text": "to the model's outputs\nor something else. If you have access to\nthe model's outputs, right, you can perform a study\nlike Gender Shades, where",
    "start": "1151740",
    "end": "1158670"
  },
  {
    "text": "you run the model on certain\nsort of challenge examples, and you look at what\nthe error rate is.",
    "start": "1158670",
    "end": "1164520"
  },
  {
    "text": "And you say, well,\nclearly, we are doing much worse on\ndark-skinned females than light-skinned males, so\nthere is some sort of bias.",
    "start": "1164520",
    "end": "1170680"
  },
  {
    "text": "So you can audit\nmodels that way. It becomes much\nharder to audit models if you can't execute the\nmodel on your own data.",
    "start": "1170680",
    "end": "1177220"
  },
  {
    "text": "Then you'll have to do\nsomething a little bit tricky, and it requires very\nspecialized conditions, I think,",
    "start": "1177220",
    "end": "1182670"
  },
  {
    "text": "to be able to audit\nthose kinds of models. Also feel free to ask\nfollow-up questions if I",
    "start": "1182670",
    "end": "1188130"
  },
  {
    "text": "didn't answer any of these. So similar to the issue\nwith the person in Michigan,",
    "start": "1188130",
    "end": "1193200"
  },
  {
    "text": "there has been\nefforts in applying AI to model future human behavior.",
    "start": "1193200",
    "end": "1198540"
  },
  {
    "text": "Oh, this is a comment. Yes. And that's highly problematic. I think in one of the\nearlier slides or talks,",
    "start": "1198540",
    "end": "1205020"
  },
  {
    "text": "there was a discussion\nabout how sort of amplification of feedback\neffects are really insidious. And, yeah, so\npredicting the future",
    "start": "1205020",
    "end": "1211350"
  },
  {
    "text": "and actioning on\npredicting future behavior is even more problematic than\nthe task I described here",
    "start": "1211350",
    "end": "1216750"
  },
  {
    "text": "because acting on the real world\nwill change the outcome, right? So if you predict that crime\nwill happen in a certain area,",
    "start": "1216750",
    "end": "1221948"
  },
  {
    "text": "you assign more police,\nand you find more crime. That's going to lead to a\npretty vicious feedback loop. So you need to really\nthink about sort",
    "start": "1221948",
    "end": "1227940"
  },
  {
    "text": "of the whole sociotechnical\nsystem rather than just the classification\nsystem narrowly when",
    "start": "1227940",
    "end": "1235230"
  },
  {
    "text": "you're in those settings. The last one-- \"it\nseems that we can",
    "start": "1235230",
    "end": "1240532"
  },
  {
    "text": "always slice our data\ninto more sub-populations to test for fairness. Are there industry standards\nfor what we should usually",
    "start": "1240532",
    "end": "1245880"
  },
  {
    "text": "start with?\" That's a great question\nand also a really important academic one.",
    "start": "1245880",
    "end": "1251310"
  },
  {
    "text": "So there is a sort\nof easy answer, which is that a lot of research\nand a lot of industry work",
    "start": "1251310",
    "end": "1257970"
  },
  {
    "text": "has focused on sort of\nlegally protected groups. And that's a well-defined\nset of attributes",
    "start": "1257970",
    "end": "1263098"
  },
  {
    "text": "that you can't discriminate on. And so you can group by those. You can group by\nintersections of those. And you can say\nthose are the groups",
    "start": "1263098",
    "end": "1268860"
  },
  {
    "text": "I shouldn't discriminate on. But, sort of\nacademically, this seems unsatisfying because\nwhy should those be",
    "start": "1268860",
    "end": "1274380"
  },
  {
    "text": "the only things we care about? And there's a lot\nof work on sort of individualized\nfairness, making sure",
    "start": "1274380",
    "end": "1279539"
  },
  {
    "text": "that you do well on sort\nof individual people, make sure you treat people\nthat are similar similarly",
    "start": "1279540",
    "end": "1284790"
  },
  {
    "text": "and things like that. And that's a whole active\narea of research and sort of not really something where\nthere's an obvious and clear",
    "start": "1284790",
    "end": "1290730"
  },
  {
    "text": "answer yet. OK, any other final\nquestions before I move on?",
    "start": "1290730",
    "end": "1295940"
  },
  {
    "start": "1295940",
    "end": "1301789"
  },
  {
    "text": "OK, so now I'm going to sort\nof move on to the second point",
    "start": "1301790",
    "end": "1307640"
  },
  {
    "text": "that I talked about before, that\nmachine learning systems aren't really secure and\ncan't really be used",
    "start": "1307640",
    "end": "1312710"
  },
  {
    "text": "in many high-stakes situations. So I'm going to start with one\nof the most well-known examples",
    "start": "1312710",
    "end": "1319700"
  },
  {
    "text": "of this called adversarial\nexamples, where on the left, we have an image.",
    "start": "1319700",
    "end": "1324870"
  },
  {
    "text": "This is a panda. And a classification system\ngets this mostly right. It's a panda with\n57% confidence.",
    "start": "1324870",
    "end": "1330620"
  },
  {
    "text": "That's great. Now what we're\ngoing to do is we're going to add a very specially\ndesigned and visually",
    "start": "1330620",
    "end": "1336650"
  },
  {
    "text": "imperceptible perturbation. So this middle panel\nlooks like complete noise. We scale it down so that\nit looks just like zeros,",
    "start": "1336650",
    "end": "1343550"
  },
  {
    "text": "and then we add it\nto the panda image. And we get the\nimage on the right. Now we run our image classifier. And what we get out is it's\nalmost certainly a gibbon,",
    "start": "1343550",
    "end": "1351150"
  },
  {
    "text": "which is completely wrong. And so what this\ntells us is we can find visually\nimperceptible perturbations",
    "start": "1351150",
    "end": "1358160"
  },
  {
    "text": "that lead to very confident\nmisclassifications. And I'm not going to\nshow you the results of this adversarial\nexample stuff.",
    "start": "1358160",
    "end": "1365182"
  },
  {
    "text": "But you can do this\nto almost any system, and you can completely\nand catastrophically destroy the accuracy of\nall of these systems.",
    "start": "1365182",
    "end": "1371610"
  },
  {
    "text": "And this also happens in\nNLP systems and so on. So this is a really sort\nof hard to avoid and almost",
    "start": "1371610",
    "end": "1377050"
  },
  {
    "text": "sort of universal behavior. And I want to show you how sort\nof robust this kind of behavior",
    "start": "1377050",
    "end": "1383660"
  },
  {
    "text": "is. And so it doesn't have to be\nimages on a computer screen. It can happen by putting\nlittle black and white patches",
    "start": "1383660",
    "end": "1391190"
  },
  {
    "text": "to a stop sign. And so the left system\nis going to classify that as a yield instead\nof a stop sign.",
    "start": "1391190",
    "end": "1396769"
  },
  {
    "text": "The middle one is a\nfun, 3D-printed toy, where if you try to run\nan object recognizer,",
    "start": "1396770",
    "end": "1402950"
  },
  {
    "text": "it will say gun from\nalmost any angle. And the right one is\nan adversarial sticker,",
    "start": "1402950",
    "end": "1408152"
  },
  {
    "text": "where if you stick it anywhere\nand you take an image, it's going to say that it's a\ntoaster instead of a banana,",
    "start": "1408152",
    "end": "1413790"
  },
  {
    "text": "which is what it should be. So these are very many\ndifferent formats. But you have this same and\nkind of disturbing phenomena,",
    "start": "1413790",
    "end": "1420290"
  },
  {
    "text": "where it's obvious\nto us that something shouldn't be tricking us.",
    "start": "1420290",
    "end": "1426200"
  },
  {
    "text": "Black and white patches that\nare that small or weird texture on a turtle shouldn't\nreally be fooling us",
    "start": "1426200",
    "end": "1431900"
  },
  {
    "text": "into changing our predictions. But it really fools\nthese image classifiers.",
    "start": "1431900",
    "end": "1437570"
  },
  {
    "text": "And when you first\nsee this, you think there must be a really\nsimple patch, right? Maybe you run it through\na JPEG compressor.",
    "start": "1437570",
    "end": "1443750"
  },
  {
    "text": "Maybe you add a little bit of\nextra noise in every image. And so this has led to an\nenormous number of papers,",
    "start": "1443750",
    "end": "1450559"
  },
  {
    "text": "over a hundred or so\nover the last five or six years in which people have\ntried a lot of different things",
    "start": "1450560",
    "end": "1457879"
  },
  {
    "text": "to defend against these\nkinds of what's called adversarial perturbations. But the problem is that\nevery time someone comes up",
    "start": "1457880",
    "end": "1465230"
  },
  {
    "text": "with a defense, soon\nafter, someone's going to-- someone breaks it by\nfinding a better attack or even",
    "start": "1465230",
    "end": "1471633"
  },
  {
    "text": "somewhat more\ndisturbingly, just running the old attack for longer. And so it kind of\nseems like this",
    "start": "1471633",
    "end": "1477860"
  },
  {
    "text": "is a really persistent\nand serious phenomenon. And I think the\nrecent view of a lot",
    "start": "1477860",
    "end": "1484730"
  },
  {
    "text": "of these adversarial\nexample type problems",
    "start": "1484730",
    "end": "1490280"
  },
  {
    "text": "is not that there's some\nreally degenerate artifact about the way we train models\nor the way we optimize things.",
    "start": "1490280",
    "end": "1497930"
  },
  {
    "text": "It's really just\nthe fact that there are a lot of ways to have a\nhigh-performance prediction system.",
    "start": "1497930",
    "end": "1503029"
  },
  {
    "text": "And many of the ways in which\nwe can predict accurately rely on these what we're going\nto call non-robust features.",
    "start": "1503030",
    "end": "1509809"
  },
  {
    "text": "And so when we try to, say,\nclassify a dog or a cat or so on, we as\nhumans rely on these",
    "start": "1509810",
    "end": "1515960"
  },
  {
    "text": "what we're going to term\nrobust features, right? We try to identify eyes\nand snout and these parts.",
    "start": "1515960",
    "end": "1521804"
  },
  {
    "text": "And so these kinds\nof things are pretty robust to pixel-level\nperturbations. But, actually, low-level\ntextures and really small image",
    "start": "1521805",
    "end": "1529460"
  },
  {
    "text": "patches are also very predictive\nof classes of dogs versus cats, let's say.",
    "start": "1529460",
    "end": "1535610"
  },
  {
    "text": "And who are we to say,\nright, that that's like an incorrect way to make\nthe predictions because when we train the model,\nall we're saying",
    "start": "1535610",
    "end": "1541820"
  },
  {
    "text": "is just classify these\ndogs and cats well. And so you can think of\nthis as saying our problem",
    "start": "1541820",
    "end": "1547940"
  },
  {
    "text": "is underspecified. And there are many ways\nto get a good classifier. And some of them really rely\non the use of these sort",
    "start": "1547940",
    "end": "1554110"
  },
  {
    "text": "of non-robust features. And this has kind of serious\nsecurity implications, right?",
    "start": "1554110",
    "end": "1563830"
  },
  {
    "text": "If you're trying to make\na self-driving car system,",
    "start": "1563830",
    "end": "1569745"
  },
  {
    "text": "the stop sign being classified\nas a yield is pretty bad. You might run over a pedestrian. And this really\nprevents the application",
    "start": "1569745",
    "end": "1575970"
  },
  {
    "text": "of machine learning systems in\nthings like self-driving cars. Or at least we should\nbe very hesitant",
    "start": "1575970",
    "end": "1582300"
  },
  {
    "text": "if we believe that\nthese kinds of problems are inherent, right, because\nthe world is kind of designed so that they're really\neasily perceptible to humans",
    "start": "1582300",
    "end": "1590460"
  },
  {
    "text": "and not necessarily designed so\nthat small perturbations, say, by putting on stickers\ndon't change stop signs",
    "start": "1590460",
    "end": "1596970"
  },
  {
    "text": "and yield signs. And in other cases, right,\nvision systems, I think, are being increasingly\nbeing used",
    "start": "1596970",
    "end": "1603299"
  },
  {
    "text": "in high-stakes applications. We might reasonably imagine,\nsay, at a TSA checkpoint, there's a camera\nthat's running, and it",
    "start": "1603300",
    "end": "1609450"
  },
  {
    "text": "tries to identify whether or\nnot you have a gun, right? And if you can make these\nadversarial examples that say make a gun a\nnot gun or a turtle",
    "start": "1609450",
    "end": "1616320"
  },
  {
    "text": "a gun, that seems very\nproblematic, right? We can't use vision\nsystems for those kinds of high-stakes applications that\nwe might want to use them for.",
    "start": "1616320",
    "end": "1624460"
  },
  {
    "text": "And so both of these\nreally pose challenges for the use of machine\nlearning in these sort of high-stakes life or\ndeath kind of settings.",
    "start": "1624460",
    "end": "1633450"
  },
  {
    "text": "And I'm going to stop\nhere to take questions about adversarial examples for\nthe next couple of minutes.",
    "start": "1633450",
    "end": "1639720"
  },
  {
    "text": " \"Do I know why the\nfirst example was",
    "start": "1639720",
    "end": "1644730"
  },
  {
    "text": "classified as a yield sign?\" That's a good question. I mean, with all of these\nadversarial examples,",
    "start": "1644730",
    "end": "1651400"
  },
  {
    "text": "the reason why they're\nbeing classified as yield is pretty confusing. I think, well, for example, why\nis this turtle being classified",
    "start": "1651400",
    "end": "1660000"
  },
  {
    "text": "as a gun? I'm really not sure. It doesn't look\nanything like a gun, and the textures\ndon't look like a gun. The way these things\nare constructed,",
    "start": "1660000",
    "end": "1666405"
  },
  {
    "text": "right, is they're constructed\nby an optimization process. You're basically looking\nfor perturbations on, say,",
    "start": "1666405",
    "end": "1673679"
  },
  {
    "text": "a normal turtle texture\nthat lead it to be a gun. And so there's no real\ninterpretable reason why, say,",
    "start": "1673680",
    "end": "1679980"
  },
  {
    "text": "this looks like a\nyield sign, or this is being classified as\na gun from every angle. ",
    "start": "1679980",
    "end": "1686500"
  },
  {
    "text": "\"Can I train on these examples\nto correct classification?\"",
    "start": "1686500",
    "end": "1692060"
  },
  {
    "text": "Oh, sorry. I skipped the question. \"How do we define the non-robust\nfeature versus--\" yes, OK.",
    "start": "1692060",
    "end": "1698409"
  },
  {
    "text": "So this is an ad hoc definition. So the split here is\njust whether or not a feature can be flipped by\nchanging the image slightly",
    "start": "1698410",
    "end": "1707470"
  },
  {
    "text": "in pixel space. And so that's really the\nworking definition here of robust versus non-robust.",
    "start": "1707470",
    "end": "1714050"
  },
  {
    "text": "And I think if we were\nbeing more precise, I think this should\nreally be split as saying visually\nimperceptible is non-robust",
    "start": "1714050",
    "end": "1722050"
  },
  {
    "text": "and visually perceptible\nis possibly robust. And I think that's sort of\na pretty reasonable split. Anything that humans really\ncannot visually tell should not",
    "start": "1722050",
    "end": "1730690"
  },
  {
    "text": "be being used as sort\nof features as inputs to a reliable prediction system.",
    "start": "1730690",
    "end": "1737659"
  },
  {
    "text": "\"Can I train on these examples\nto correct classification?\" I'm going to try to interpret\nthis question because I'm not",
    "start": "1737660",
    "end": "1744230"
  },
  {
    "text": "100% sure. I think what you're\ndescribing is an idea called adversarial training. So the idea is to,\nbasically, instead",
    "start": "1744230",
    "end": "1752090"
  },
  {
    "text": "of training on just the input\nimage-- let's just go back a little bit-- instead of\ntraining on the pandas, right,",
    "start": "1752090",
    "end": "1758690"
  },
  {
    "text": "we try to train our system\nto basically classify this image, the adversarial\nimage, as being a panda, right?",
    "start": "1758690",
    "end": "1765440"
  },
  {
    "text": "And you might think,\nOK, this is good. We can now make this a panda. But now we need to prevent some\nother sort of adversarially",
    "start": "1765440",
    "end": "1773299"
  },
  {
    "text": "designed noise from making\nsure that we look like a panda, right, because\nthere's probably many, many, many different\nattacks that",
    "start": "1773300",
    "end": "1780200"
  },
  {
    "text": "will change this into a panda. And so the idea that\nyou're describing here is basically called\nadversarial training.",
    "start": "1780200",
    "end": "1786170"
  },
  {
    "text": "And I think that's in-- yes, that's one of the\nearliest defense approaches.",
    "start": "1786170",
    "end": "1792720"
  },
  {
    "text": "And it's empirically\nreasonably effective. But you can still attack it\nby more sophisticated methods.",
    "start": "1792720",
    "end": "1801649"
  },
  {
    "text": "You can find still visually\nimperceptible attacks after adversarial training\nthat breaks the system.",
    "start": "1801650",
    "end": "1806690"
  },
  {
    "text": "So this is not really\na foolproof way of trying to make\nmodels more robust. It's better than nothing.",
    "start": "1806690",
    "end": "1813260"
  },
  {
    "text": "\"Are you saying yet\nunfound defenses are needed for ML\nself-driving cars to be secure from\nnefarious attacks?\"",
    "start": "1813260",
    "end": "1818600"
  },
  {
    "text": "I think this is\na great question. I think I was-- I'm being a little\nbit too aggressive",
    "start": "1818600",
    "end": "1824873"
  },
  {
    "text": "in terms of the things\nthat I'm saying, right?  It's an open question whether\nor not these kinds of attacks",
    "start": "1824873",
    "end": "1832560"
  },
  {
    "text": "are really feasible\nin the real world or whether or not there\nare things that we should worry about, right?",
    "start": "1832560",
    "end": "1838110"
  },
  {
    "text": "In the real world,\nI can easily cut off a stop sign using a saw. And that's an\nadversarial human attack.",
    "start": "1838110",
    "end": "1844050"
  },
  {
    "text": "But we're not too worried\nabout that attack. And so maybe we\nshouldn't be worried about adversarial attacks\non self-driving car systems.",
    "start": "1844050",
    "end": "1850360"
  },
  {
    "text": "But I think there are two\nthings that this highlights. One thing is that we\nshould be a little bit careful when we deploy these\nself-driving car systems,",
    "start": "1850360",
    "end": "1857340"
  },
  {
    "text": "right? We should have fail-safes that,\nfor example, don't rely just on vision. That seems pretty important. We might want to\nuse RADAR or LiDAR.",
    "start": "1857340",
    "end": "1864233"
  },
  {
    "text": "RADAR doesn't work\non soft people. But let's say LiDAR, try\nto make sure we're not going to run over people when\nwe miss-detect the stop sign,",
    "start": "1864233",
    "end": "1869429"
  },
  {
    "text": "right? Having lots of orthogonal checks\nbecomes increasingly important once you realize\nthat there are ways",
    "start": "1869430",
    "end": "1875280"
  },
  {
    "text": "to fool these vision systems. And I think people\nare working on sort",
    "start": "1875280",
    "end": "1881330"
  },
  {
    "text": "of provably robust\nmachine learning systems. Maybe in settings like\nmilitary applications,",
    "start": "1881330",
    "end": "1887280"
  },
  {
    "text": "those become truly important. And so there is\nprogress on that. But it's just that\nprovably robust systems",
    "start": "1887280",
    "end": "1892800"
  },
  {
    "text": "achieve much worse\naverage accuracy than non-robust systems. There's this big gap right\nnow that we don't really",
    "start": "1892800",
    "end": "1897930"
  },
  {
    "text": "know how to close.  OK, \"in my opinion, is\nresearch now shifting",
    "start": "1897930",
    "end": "1903828"
  },
  {
    "text": "towards reformulating models\nto rely on robust features instead of finding\nad hoc defenses?\"",
    "start": "1903828",
    "end": "1909780"
  },
  {
    "text": "That's a good question. I think there is still\na big gap in terms of provably robust defenses\nversus these what you might",
    "start": "1909780",
    "end": "1918180"
  },
  {
    "text": "call ad hoc defenses that\nwork well for, say, one or two targeted attack types. ",
    "start": "1918180",
    "end": "1924413"
  },
  {
    "text": "But I think there's things\nlike randomized smoothing and procedures like\n[INAUDIBLE] that sort of get the best of\nboth worlds in some sense.",
    "start": "1924413",
    "end": "1930240"
  },
  {
    "text": "They're getting\nincreasingly-- they're provably correct\nin some framework, and they're getting\nincreasingly better.",
    "start": "1930240",
    "end": "1936027"
  },
  {
    "text": "And so I think for\nhigh-stakes applications, I think we'll end\nup in a place where we'll lose some\naverage case accuracy",
    "start": "1936027",
    "end": "1941370"
  },
  {
    "text": "but not catastrophically so. And we'll still have sort of\nadversarially robust models,",
    "start": "1941370",
    "end": "1947340"
  },
  {
    "text": "not sort of where I\nimagine the field will go. It does seem like ad hoc\ndefenses keep getting broken.",
    "start": "1947340",
    "end": "1953060"
  },
  {
    "text": "So that's not really a path\ntowards truly robust systems even though they might make\nfor more useful systems overall",
    "start": "1953060",
    "end": "1959600"
  },
  {
    "text": "if, for example, adversarial\ntraining leads to more interpretable latent features.",
    "start": "1959600",
    "end": "1965590"
  },
  {
    "text": "\"Does producing adversarial\nattacks require access to the model? If so, isn't this just\nan issue of info security",
    "start": "1965590",
    "end": "1971350"
  },
  {
    "text": "equivalent of--\" I can't\nparse that second sentence.",
    "start": "1971350",
    "end": "1976450"
  },
  {
    "text": "But, yes, I agree with\nthis general sentiment as well, right? So if you need access to\nthe internals of the model,",
    "start": "1976450",
    "end": "1983710"
  },
  {
    "text": "then, really, at\nthat point, you've rooted the system\nif you're attacking,",
    "start": "1983710",
    "end": "1988870"
  },
  {
    "text": "say, a medical imaging system. Or you have access\nto someone's car. And if you're the\nMossad, you can probably",
    "start": "1988870",
    "end": "1995140"
  },
  {
    "text": "mess with their brakes, right? And so it's true that\nthose attack models",
    "start": "1995140",
    "end": "2000270"
  },
  {
    "text": "are pretty obscure and weird. But there are what are called\nwhite-box attacks, which",
    "start": "2000270",
    "end": "2005759"
  },
  {
    "text": "only require you to\nevaluate the model for one. And for two, a lot of\nsystems are shared, right?",
    "start": "2005760",
    "end": "2012180"
  },
  {
    "text": "So you only need to learn\nto attack them once. And so if you're trying to\nattack Tesla's auto driving",
    "start": "2012180",
    "end": "2018617"
  },
  {
    "text": "system, you need to get a Tesla. You need to figure out the\nadversarial sticker that's going to make your\nsystem go haywire,",
    "start": "2018617",
    "end": "2024600"
  },
  {
    "text": "and then you need to paste\nthat everywhere, right? That doesn't require a\nparticularly sophisticated threat model in\norder to execute.",
    "start": "2024600",
    "end": "2032442"
  },
  {
    "text": "So I think there are some\nmodels in which these are sort of real and\nproblematic even though I think there is a lot of\nquestions and debate about",
    "start": "2032442",
    "end": "2038960"
  },
  {
    "text": "whether or not we\nshould really care about this cost-benefit\ntrade-offs of robust versus non-robust\nsystems and so on.",
    "start": "2038960",
    "end": "2045110"
  },
  {
    "text": "But it's an important thing\nto keep in mind, right? ",
    "start": "2045110",
    "end": "2050690"
  },
  {
    "text": "OK, any other questions for\nthe adversarial examples part? ",
    "start": "2050690",
    "end": "2060138"
  },
  {
    "text": "OK, and so now I'm going to\nget to the last part, which, given that this is a AI class,\nis maybe the most important",
    "start": "2060139",
    "end": "2068419"
  },
  {
    "text": "of the three failures\nof machine learning now in terms of robustness.",
    "start": "2068420",
    "end": "2073908"
  },
  {
    "text": "And I think it's one\nof understanding. And people throw this\nword around a lot, that models don't\nreally understand.",
    "start": "2073909",
    "end": "2080119"
  },
  {
    "text": "And it's hard to pin down\nwhat understanding is. But it's very easy to show\nwhen models don't understand.",
    "start": "2080120",
    "end": "2085520"
  },
  {
    "text": "And so we can go through\nsome examples here. We'll go through them\nagain in more detail.",
    "start": "2085520",
    "end": "2090560"
  },
  {
    "text": "But this is from an overview\nof what people call shortcuts in the citation on the bottom.",
    "start": "2090560",
    "end": "2095942"
  },
  {
    "text": "And, for example,\nlet's say we're trying to caption this image here. And so we need to describe\nin text what's happening.",
    "start": "2095943",
    "end": "2103400"
  },
  {
    "text": "But, really, sometimes\nthese systems might just use the background\ninstead of actually recognizing hills and skies and sheep.",
    "start": "2103400",
    "end": "2111320"
  },
  {
    "text": "Adversarial examples\nmay be because we're recognizing textures and\nnot actually recognizing the shape of things\nlike teapots.",
    "start": "2111320",
    "end": "2118220"
  },
  {
    "text": "And if we're doing\nmedical image diagnostics, we might be looking\nat markings on X-rays,",
    "start": "2118220",
    "end": "2123950"
  },
  {
    "text": "what hospital the X-ray came\nfrom instead of actually performing prediction. And so in all of\nthese cases, we're",
    "start": "2123950",
    "end": "2129080"
  },
  {
    "text": "making use of these\npieces of information that shouldn't really\nbe central to the task. They're not the core prediction\ntests that we care about.",
    "start": "2129080",
    "end": "2136713"
  },
  {
    "text": "And somehow the model\nhas picked them up and learned to do really well. And I'm just going\nto group this broadly",
    "start": "2136713",
    "end": "2142760"
  },
  {
    "text": "under this label of\nshortcut learning. And the way to\nthink about this is",
    "start": "2142760",
    "end": "2147850"
  },
  {
    "text": "that when we train models\nin machine learning, we're training them to do well\nwhile directly on the training",
    "start": "2147850",
    "end": "2153520"
  },
  {
    "text": "set. And these days,\nwe now expect them to do well on the test set. But, really, what\nwe would ideally",
    "start": "2153520",
    "end": "2159250"
  },
  {
    "text": "like them to do\nas sort of systems that reason and understand and\nso on is that they perform well",
    "start": "2159250",
    "end": "2165700"
  },
  {
    "text": "on these challenge sets,\nreally difficult examples that we've constructed\nto break the model.",
    "start": "2165700",
    "end": "2171290"
  },
  {
    "text": "And so you can think\nabout this as there's a lot of possible rules that\nwork well in the training set, and there's fewer that\nwork well on test sets.",
    "start": "2171290",
    "end": "2179530"
  },
  {
    "text": "And there's very, very\nfew that work well on sort of these challenge sets,\nthe intended true reasoning",
    "start": "2179530",
    "end": "2186130"
  },
  {
    "text": "that we would like\nour models to extract. And so we can think about\nmachine learning today",
    "start": "2186130",
    "end": "2191480"
  },
  {
    "text": "as we've gone from this\ntan-colored circle, where we were before, to\nthis blue-colored circle,",
    "start": "2191480",
    "end": "2198415"
  },
  {
    "text": "where we are now, where we\ndo well on the test set. But what we really want\nto be is still further. We want to make sure we learn\nthe right sort of mechanism.",
    "start": "2198415",
    "end": "2205430"
  },
  {
    "text": "And you may have\nheard this classic AI story of tank identification. And I think this is\na really old Cold War",
    "start": "2205430",
    "end": "2213050"
  },
  {
    "text": "kind of story, where I'm\ngoing to read this out loud. The Army trained a program to\ndifferentiate American tanks",
    "start": "2213050",
    "end": "2219110"
  },
  {
    "text": "from Russian tanks. It got 100% accuracy\non a test set. But, later, people realized\nthat American tanks were",
    "start": "2219110",
    "end": "2225020"
  },
  {
    "text": "photographed on a sunny\nday, and Russian tanks were photographed\non a cloudy day. And the computer had learned\nto detect brightness, not",
    "start": "2225020",
    "end": "2231380"
  },
  {
    "text": "actually detect tanks. And so this is exactly\nthe kind of problem that I'm talking\nabout, right, where",
    "start": "2231380",
    "end": "2237620"
  },
  {
    "text": "we have this extremely\nhigh-test accuracy, and we are super happy. But then we realize we\nhaven't learned anything",
    "start": "2237620",
    "end": "2243290"
  },
  {
    "text": "about the underlying task. And this has been attributed\nto a lot of different people. It was, I think,\noriginally in written form",
    "start": "2243290",
    "end": "2249650"
  },
  {
    "text": "on Dreyfus's textbook. But it turns out it's not\nan actual real example. This can't really be attributed\nto any actual experiment run",
    "start": "2249650",
    "end": "2256580"
  },
  {
    "text": "by the Army. The citation here is Gwern. He has a website\nwhere he has gone through all the\npossible attributions",
    "start": "2256580",
    "end": "2262100"
  },
  {
    "text": "of this urban myth. But, really, this urban\nmyth is so popular,",
    "start": "2262100",
    "end": "2267380"
  },
  {
    "text": "I think, at least in the AI\nmachine learning community because there is a kernel of\ntruth to this sort of story.",
    "start": "2267380",
    "end": "2275750"
  },
  {
    "text": "And we're going to go through\nseveral examples of tasks",
    "start": "2275750",
    "end": "2281240"
  },
  {
    "text": "today where there's\nthese kinds of failures. So one of them\nthat's kind of fun",
    "start": "2281240",
    "end": "2286640"
  },
  {
    "text": "is this vision task\napparently of where people have tried to predict\ngender from iris patterns.",
    "start": "2286640",
    "end": "2293540"
  },
  {
    "text": "And there was\napparently some belief that this was a test that you\ncan perform because you can",
    "start": "2293540",
    "end": "2299120"
  },
  {
    "text": "actually get a reasonably\nhigh-test accuracy if you train CNNs on cropped\nimages of irises,",
    "start": "2299120",
    "end": "2304640"
  },
  {
    "text": "and you try to predict gender. But there's this paper that\nidentified that, actually, this",
    "start": "2304640",
    "end": "2310280"
  },
  {
    "text": "is not actually\nbecause of the iris. It's because female\neyes often have mascara.",
    "start": "2310280",
    "end": "2315589"
  },
  {
    "text": "And that systematically shifts\nthe brightness of the images. And this sort of histogram tells\na thousand words in one image.",
    "start": "2315590",
    "end": "2324470"
  },
  {
    "text": "And so on the top one, you see\nthis distribution of males. And this x-axis here is\nthe average brightness",
    "start": "2324470",
    "end": "2330710"
  },
  {
    "text": "of the image. And so the distributions\nlook pretty similar. Males and females have a similar\nbrightness distribution when",
    "start": "2330710",
    "end": "2336920"
  },
  {
    "text": "females have no cosmetics on. But if you restrict yourself\nto females with cosmetics,",
    "start": "2336920",
    "end": "2342500"
  },
  {
    "text": "this red distribution\nshifts to the left, and the image becomes darker. And so you see that there's this\nvery strong confounding effect",
    "start": "2342500",
    "end": "2350750"
  },
  {
    "text": "of the female eyes having\nmascara, therefore, being darker and, therefore,\nthese systems predicting quite",
    "start": "2350750",
    "end": "2357319"
  },
  {
    "text": "well based on this average\ndarkness even though really, apparently, it wasn't\nlearning anything at all",
    "start": "2357320",
    "end": "2363619"
  },
  {
    "text": "in terms of this\nactual prediction task. Another one from sort of\nthe Gwern website and sort",
    "start": "2363620",
    "end": "2369910"
  },
  {
    "text": "of the investigation into\nthis tank phenomenon, which is interesting, is\nKaggle fisheries competition,",
    "start": "2369910",
    "end": "2375859"
  },
  {
    "text": "where the task is you're\ngiven images of fishes being caught on a fishing boat. And the task is to identify\nwhether or not these boats are",
    "start": "2375860",
    "end": "2383869"
  },
  {
    "text": "catching fish illegally. So you're supposed to\nidentify whether or not these fish are part of a set\nof protected category of fish",
    "start": "2383870",
    "end": "2391100"
  },
  {
    "text": "you're not supposed to catch. And it turns out on\nthe training set, you can do extremely\nwell on this task",
    "start": "2391100",
    "end": "2396349"
  },
  {
    "text": "using a very simple heuristic. These images come from a\nrelatively small number of boats.",
    "start": "2396350",
    "end": "2401680"
  },
  {
    "text": "So you first identify\neach boat, and then you identify for each\nboat whether or not they have been\ncatching illegal fish.",
    "start": "2401680",
    "end": "2406952"
  },
  {
    "text": "And this approach\ndoes really well because it turns out only\na few fish-- or a few boats",
    "start": "2406952",
    "end": "2411980"
  },
  {
    "text": "catch these illegal\ntypes of fish. And so by first identifying\nthe boat and then by identifying the fish, you\ncan get extremely high accuracy",
    "start": "2411980",
    "end": "2418850"
  },
  {
    "text": "even though you\nhave learned nothing about actually performing\nthis fish identification task.",
    "start": "2418850",
    "end": "2425900"
  },
  {
    "text": "Another one that seems\nmaybe more high stakes and problematic is in\nmedical prediction.",
    "start": "2425900",
    "end": "2431470"
  },
  {
    "text": "There is a lot of talk about\ntumor identification or chest X-ray sort of\nmalignancy prediction.",
    "start": "2431470",
    "end": "2438970"
  },
  {
    "text": "And in these cases, right,\nit's pretty important to ask whether or\nnot we're doing well because these are\nhigh-stakes situations",
    "start": "2438970",
    "end": "2446650"
  },
  {
    "text": "that you would like to make sure\nthat you're not being fooled by some sort of feature that\nmakes the task easier than it",
    "start": "2446650",
    "end": "2451780"
  },
  {
    "text": "actually should be. And there's often claims now\nof the systems performing just",
    "start": "2451780",
    "end": "2457550"
  },
  {
    "text": "as well as human\ndoctors in terms of their diagnostic\naccuracy and so on.",
    "start": "2457550",
    "end": "2462820"
  },
  {
    "text": "And one sort of\nreally interesting, and maybe a little\nproblematic example,",
    "start": "2462820",
    "end": "2468780"
  },
  {
    "text": "is when you have these sort of\ntumors, sort of skin lesions that you're trying to\nclassify as whether or not",
    "start": "2468780",
    "end": "2474870"
  },
  {
    "text": "they're cancerous\nor not, doctors will often put surgical\nmarkers to highlight tumors",
    "start": "2474870",
    "end": "2481050"
  },
  {
    "text": "that they think are more\nserious than others, just so that when someone\nelse is looking at them, they can immediately identify\nthe more problematic ones.",
    "start": "2481050",
    "end": "2488550"
  },
  {
    "text": "And the training set\napparently for these systems contained a lot\nof these markings.",
    "start": "2488550",
    "end": "2493800"
  },
  {
    "text": "And so there was an\nexamination into these sort of tumor classification\nsystems, where they artificially",
    "start": "2493800",
    "end": "2499559"
  },
  {
    "text": "added markings to these images\nas well as cropped-out markings from already marked images.",
    "start": "2499560",
    "end": "2505650"
  },
  {
    "text": "And they show that\nthey can basically flip the classification\nof these systems. And so in some ways,\nthe high accuracy",
    "start": "2505650",
    "end": "2512400"
  },
  {
    "text": "of these kinds of\nclassification systems are not because they're\nidentifying tumors. It's because\nthey're piggybacking",
    "start": "2512400",
    "end": "2518130"
  },
  {
    "text": "on humans who have\nalready, in many cases, classified the tumors as\nbeing malignant or not.",
    "start": "2518130",
    "end": "2525000"
  },
  {
    "text": "An early problem that\nsomeone identified in one of the earlier works\nin-- oh, sorry, identification",
    "start": "2525000",
    "end": "2533119"
  },
  {
    "text": "of this Esteva in\n2011 is when people are trying to identify whether\nor not tumors are malignant,",
    "start": "2533120",
    "end": "2539180"
  },
  {
    "text": "when, in serious cases,\npeople would include rulers to show how big the tumor is. And so the existence\nof a ruler would",
    "start": "2539180",
    "end": "2545510"
  },
  {
    "text": "serve as a sort of\nspurious correlation or as a confounder in\nterms of whether or not",
    "start": "2545510",
    "end": "2553120"
  },
  {
    "text": "a tumor was malignant. And, finally, one that\nI think people are now",
    "start": "2553120",
    "end": "2558550"
  },
  {
    "text": "aware about but, initially, I\nthink people are sort of not as aware of is that\nhospital ID often",
    "start": "2558550",
    "end": "2565570"
  },
  {
    "text": "serves as a really\nreliable indicator of both sort of base\nrisk level as well as the type of procedures\nbeing performed at a hospital.",
    "start": "2565570",
    "end": "2574210"
  },
  {
    "text": "And this you can think of\nas analogous to the boat example and the\nfishing problem, where",
    "start": "2574210",
    "end": "2579520"
  },
  {
    "text": "if you identify hospitals that,\nsay, have a lot of smokers, you're going to much\nmore likely find cancer",
    "start": "2579520",
    "end": "2587500"
  },
  {
    "text": "in lung chest X-rays from\nthose types of hospitals. And so it's really\nimportant to try to remove the effect of sort\nof identifying the hospital",
    "start": "2587500",
    "end": "2594910"
  },
  {
    "text": "and then identifying\nthe base risk. ",
    "start": "2594910",
    "end": "2600670"
  },
  {
    "text": "A really interesting\none I wasn't aware of in image classification\nuntil yesterday or so is Pascal VOC is a pretty common\nobject identification data set.",
    "start": "2600670",
    "end": "2611500"
  },
  {
    "text": "And a bias that's\nbeen identified is that the horse class\nfor this, I guess,",
    "start": "2611500",
    "end": "2617140"
  },
  {
    "text": "was taken by a single\nhorse photographer who put in watermarks at the\nbottom left of the image. So around 20% of the horse\nimages have a watermark",
    "start": "2617140",
    "end": "2625000"
  },
  {
    "text": "and rely-- classification\nsystems just learned to pick up on the watermark. So you can make cars\nclassified as horses",
    "start": "2625000",
    "end": "2631810"
  },
  {
    "text": "as long as you add the\nwatermark on the bottom right. And so this is something where\nunless you really carefully",
    "start": "2631810",
    "end": "2638570"
  },
  {
    "text": "looked at the data\nset, you probably won't even realize\nthat this kind of bias exists until you've actually\nsort of carefully examined",
    "start": "2638570",
    "end": "2646880"
  },
  {
    "text": "and adversarially examined\nthe data sets that you have. ",
    "start": "2646880",
    "end": "2653470"
  },
  {
    "text": "Finally, I've mostly talked\nabout vision examples thus far.",
    "start": "2653470",
    "end": "2659380"
  },
  {
    "text": "But these sort of shortcuts\nand lack of understanding is a problem that's\ncommon to every area.",
    "start": "2659380",
    "end": "2666647"
  },
  {
    "text": "And I'm going to give probably\na very well-known example in natural language processing. The task here is\nentailment prediction.",
    "start": "2666647",
    "end": "2673640"
  },
  {
    "text": "So you're given a\npair of sentences. One is called the\npremise, and the other one is called the hypothesis. So the first one\nis a sentence like,",
    "start": "2673640",
    "end": "2679810"
  },
  {
    "text": "\"the economy could be\nbetter,\" and the second one is a sentence like, \"the\neconomy has never been better.\"",
    "start": "2679810",
    "end": "2686230"
  },
  {
    "text": "And the goal here is to say,\ndoes the hypothesis logically follow from the statement\nmade in the premise?",
    "start": "2686230",
    "end": "2692859"
  },
  {
    "text": "And so if they follow,\nyou say it's entailed. If it's contradicted, you\nsay it's a contradiction. And if it's neither,\nyou say it's neither.",
    "start": "2692860",
    "end": "2699230"
  },
  {
    "text": "And so it's a three-class\nclassification problem. And the way these\ntasks are-- or sorry-- the way these examples\nare constructed is through",
    "start": "2699230",
    "end": "2706150"
  },
  {
    "text": "crowdsourcing, where you extract\na premise sentence from some large internet text--",
    "start": "2706150",
    "end": "2711460"
  },
  {
    "text": "or newswire text, I guess. And you have a label\nthat you randomly pick. So you say I have\na premise, and it's",
    "start": "2711460",
    "end": "2718300"
  },
  {
    "text": "going to be a contradiction. And then you ask crowd workers\nto write down a contradiction. And so they write\nsomething like,",
    "start": "2718300",
    "end": "2723369"
  },
  {
    "text": "\"the economy has\nnever been better.\" Right? And so what happens here is that\ncrowd workers, because they're",
    "start": "2723370",
    "end": "2730660"
  },
  {
    "text": "writing the hypothesis text\nafter seeing the label, have systematic biases. And the bias that's\nreally strong",
    "start": "2730660",
    "end": "2737590"
  },
  {
    "text": "is this negation, where they\nlearn that negation is often-- or sorry-- where the bias is\nthat when something is not",
    "start": "2737590",
    "end": "2745030"
  },
  {
    "text": "entailed, they use negation. And so a model will often\nlearn to associate the negation or lack thereof with\nthe outcome label.",
    "start": "2745030",
    "end": "2752230"
  },
  {
    "text": "And so instead of actually doing\nthese sort of entailment tasks, they'll often pick up\nthese negation biases.",
    "start": "2752230",
    "end": "2757480"
  },
  {
    "text": "And even more\nproblematically, systems have what's called--\nor sorry-- what's",
    "start": "2757480",
    "end": "2762850"
  },
  {
    "text": "called a hypothesis-only\nbaseline, where you don't even\nlook at the premise, it can do extremely well, right?",
    "start": "2762850",
    "end": "2768040"
  },
  {
    "text": "And there's no way to do\nwell on this task while looking just at the hypothesis,\nright, because how can you know that the hypothesis is\nentailed from the premise while",
    "start": "2768040",
    "end": "2775329"
  },
  {
    "text": "only just looking at one? And so this shows this\nreally strong bias",
    "start": "2775330",
    "end": "2780350"
  },
  {
    "text": "that these crowd workers\nput into this data set. And so this has\nserious implications",
    "start": "2780350",
    "end": "2787340"
  },
  {
    "text": "for the project of\npushing machine learning and getting towards\nunderstanding in general AI",
    "start": "2787340",
    "end": "2794120"
  },
  {
    "text": "because, thus far, all\nof machine learning has been predicated\non benchmark progress. And that's the way in which the\nfield has really grown and done",
    "start": "2794120",
    "end": "2802520"
  },
  {
    "text": "well. ImageNet and MNLI and these\nsort of well-known tasks, you get everyone together,\nand we push on these numbers.",
    "start": "2802520",
    "end": "2809840"
  },
  {
    "text": "And we hope that improvements\nin these benchmark performances lead to understanding. But it's clear that\nbecause of these biases,",
    "start": "2809840",
    "end": "2816710"
  },
  {
    "text": "that may not necessarily\nbe the case, right? So we need a different paradigm\nto link machine learning",
    "start": "2816710",
    "end": "2822710"
  },
  {
    "text": "performance to understanding. And the other\nproblem that I hope by going over so\nmany examples I was",
    "start": "2822710",
    "end": "2829250"
  },
  {
    "text": "able to impress upon you\nis that there are so many shortcuts, right? And in this negation\nbias from crowd workers,",
    "start": "2829250",
    "end": "2838100"
  },
  {
    "text": "you wouldn't know about this\nunless you sort of looked at the data set\ncarefully after being",
    "start": "2838100",
    "end": "2843170"
  },
  {
    "text": "told that there\nwas a bias, right, where the watermarks\nwere horses. I don't even know how\nthey found that given",
    "start": "2843170",
    "end": "2848960"
  },
  {
    "text": "that how sort of minor that is. So it becomes really hard to say\nwe're just going to construct",
    "start": "2848960",
    "end": "2855109"
  },
  {
    "text": "a data set free of shortcuts. When you're told about\nthese shortcuts afterwards, it seems really obvious.",
    "start": "2855110",
    "end": "2860330"
  },
  {
    "text": "But how can you construct\na shortcut-free data set? And so that's the sort\nof real challenge.",
    "start": "2860330",
    "end": "2867320"
  },
  {
    "text": "Now if we think that we\ncan't get data sets free of these shortcuts and these\nbiases and these minority groups, we need a\nnew way of trying",
    "start": "2867320",
    "end": "2874880"
  },
  {
    "text": "to make sure that our models\nreally learn the right thing. And I'm going to stop\nhere for a moment",
    "start": "2874880",
    "end": "2880530"
  },
  {
    "text": "to sort of talk about\nshortcuts and understanding. And, hopefully, people\nhave lots of questions because I think this one\nis a fun one in terms",
    "start": "2880530",
    "end": "2887130"
  },
  {
    "text": "of thinking about how\nmachine learning relates to AI and so on.",
    "start": "2887130",
    "end": "2892360"
  },
  {
    "text": "I have a question. Sure. Sure. ",
    "start": "2892360",
    "end": "2898670"
  },
  {
    "text": "Just thinking about\ncommittee modeling and I'm going back\nto that stop sign",
    "start": "2898670",
    "end": "2904220"
  },
  {
    "text": "with the patches that's\nseen as a yield sign. ",
    "start": "2904220",
    "end": "2910425"
  },
  {
    "text": "Does it make more sense to\nuse one big model trained on every piece of\ndata you can find?",
    "start": "2910425",
    "end": "2916850"
  },
  {
    "text": "Or does it make sense to\ntrain a bunch of models on some partitions of the data\nthat might overlap in some way",
    "start": "2916850",
    "end": "2925310"
  },
  {
    "text": "and then combine the\nresults in order to make it less sort of\noverreactive and sort",
    "start": "2925310",
    "end": "2932430"
  },
  {
    "text": "of robotically easily\nfooled and in a robotic way.",
    "start": "2932430",
    "end": "2940349"
  },
  {
    "text": "Yeah. In any way? I think that's a generally\ngood thing to do. So I guess there's two answers.",
    "start": "2940350",
    "end": "2947990"
  },
  {
    "text": "And the more general\none is to think about the trade-off\nbetween model capacity",
    "start": "2947990",
    "end": "2953930"
  },
  {
    "text": "and your ability to fit\nthese sort of minority groups or these shortcuts, right? So the idea you're\ndescribing-- let's",
    "start": "2953930",
    "end": "2961310"
  },
  {
    "text": "say we have 10 or 100\ndifferent models, right, and we fit them to\ndifferent parts of the data. Then we might have a model\nthat's dedicated to shortcuts.",
    "start": "2961310",
    "end": "2968470"
  },
  {
    "text": "But we might also have\na model that really learns the right thing, right? And so the more\nflexible our model,",
    "start": "2968470",
    "end": "2974840"
  },
  {
    "text": "the bigger our sort\nof model class, the more we can say\npart of the model might dedicate to shortcuts. But that's OK because\nthe rest of our model",
    "start": "2974840",
    "end": "2981830"
  },
  {
    "text": "will still learn the\nright thing, right? But that's sort of still a hope. There's no real guarantee\nthat this will happen.",
    "start": "2981830",
    "end": "2987030"
  },
  {
    "text": "And if the shortcuts\nare strong enough, that's what the\nmodel will learn. So I think it seems\nreally important to have",
    "start": "2987030",
    "end": "2992870"
  },
  {
    "text": "bigger-capacity models. That's sort of a given. But how can we learn big models\nwell without overfitting?",
    "start": "2992870",
    "end": "3000549"
  },
  {
    "text": "How can we make\nsure that they still learn sort of the right thing? If one part of the model\nfits the shortcuts, how can we make\nsure the rest of it",
    "start": "3000550",
    "end": "3006400"
  },
  {
    "text": "learns to do the right sort of\nprediction without shortcuts? That's sort of\nthe open question, I think, in this area, yeah.",
    "start": "3006400",
    "end": "3012130"
  },
  {
    "text": " There was a question. \"For image segmentation,\ndo we have a way",
    "start": "3012130",
    "end": "3018628"
  },
  {
    "text": "to know which part of the image\ncontributes to the prediction?\" We could call it\nprediction traceability. Yes.",
    "start": "3018628",
    "end": "3024549"
  },
  {
    "text": "So I, of course, glossed\nover quite a bit. But this paper, Lapuschkin 2019,\nhere is exactly about that.",
    "start": "3024550",
    "end": "3034050"
  },
  {
    "text": "It's about trying to identify--\nor to attribute predictions to parts of the image using\ninterpretability methods.",
    "start": "3034050",
    "end": "3043380"
  },
  {
    "text": "And that's how they found,\nI think, this horse problem, where they attributed\npredictions to locations,",
    "start": "3043380",
    "end": "3049829"
  },
  {
    "text": "and they found that for\nhorses, they were always localized to the bottom right. And it was because\nof this watermark.",
    "start": "3049830",
    "end": "3055470"
  },
  {
    "text": "And so I think a\nbig important use case of interpretability\nmethods is exactly this.",
    "start": "3055470",
    "end": "3061860"
  },
  {
    "text": "It's to identify these\nkinds of shortcuts by attributing predictions\nto locations in the image",
    "start": "3061860",
    "end": "3067559"
  },
  {
    "text": "or to subgroups in the data set.  Going along the above\ncomment-- \"are there",
    "start": "3067560",
    "end": "3073920"
  },
  {
    "text": "methods of finding what parts\nof the image or data example has high weights\nassociated with it?\" Yes. So the general approach, I\nthink, that people have--",
    "start": "3073920",
    "end": "3083015"
  },
  {
    "text": "I think there's, of course,\nmany different methods. But Shapley values are a\npretty general framework.",
    "start": "3083015",
    "end": "3089220"
  },
  {
    "text": "You can sort of think about-- the analogy is like this. Think about each pixel or each\nregion or sub-part of the image",
    "start": "3089220",
    "end": "3097710"
  },
  {
    "text": "as participating\nin the prediction. And you can ask, when I\nremove that part of the image,",
    "start": "3097710",
    "end": "3103349"
  },
  {
    "text": "how much does the prediction\naccuracy go down, right? And so you can do that\nafter randomly removing",
    "start": "3103350",
    "end": "3109118"
  },
  {
    "text": "other parts of the image. So you randomly remove the\nother parts of the image, like drop random\npixels, and then you drop the part you're\ninterested in.",
    "start": "3109118",
    "end": "3115398"
  },
  {
    "text": "And you ask, on\naverage, how much more accuracy does\nthis part that I'm interested in give me, right?",
    "start": "3115398",
    "end": "3121020"
  },
  {
    "text": "And that's this sort of the\nestimate called the Shapley value. And Pang Wei, I\nthink who is here, has a paper on approximations\nto that based on the influence",
    "start": "3121020",
    "end": "3128640"
  },
  {
    "text": "function. So there's all sorts of ways in\nthe interpretability community about doing what's called\nfeature attribution.",
    "start": "3128640",
    "end": "3136890"
  },
  {
    "text": "Another question-- \"for a\nproblem with discrimination, would a reasonable approach\nbe to adopt active learning",
    "start": "3136890",
    "end": "3142619"
  },
  {
    "text": "by default, where\nthe model can train with more emphasis on\nwrongly categorized examples? Then the hope is that the\nmodel could steer itself away",
    "start": "3142620",
    "end": "3149100"
  },
  {
    "text": "from the initial\nbiases over time. Or is it not as simple?\" Yeah, so that's obviously a--",
    "start": "3149100",
    "end": "3155880"
  },
  {
    "text": "actually, one way\naround it, right? When you can collect\nyour own data and you have the ability to know\nwhat you're getting wrong, then",
    "start": "3155880",
    "end": "3163200"
  },
  {
    "text": "collecting data in\nthe places where you're wrong serves as a\nnegative feedback loop, right? You get more data\nwhere you're wrong.",
    "start": "3163200",
    "end": "3169260"
  },
  {
    "text": "Your model gets the training\nsignal it needs to correct. And so, eventually, you'll\nlearn the right thing.",
    "start": "3169260",
    "end": "3174670"
  },
  {
    "text": "It's just that active\nlearning on the scale that you need is very,\nvery challenging, right? Can you actively collect\nImageNet-sized style data?",
    "start": "3174670",
    "end": "3183119"
  },
  {
    "text": "Very challenging. Also very challenging\nto know what parts of the data you're\ndoing badly on, right?",
    "start": "3183120",
    "end": "3188580"
  },
  {
    "text": "You need to know well\nenough to say, oh, the part of the data I'm\ndoing badly on is horses without the watermark, right?",
    "start": "3188580",
    "end": "3194789"
  },
  {
    "text": "That's sort of a hard\nthing to be able to say. So you need to know\nwhat you don't know, which is almost equally as\nchallenging as robustness.",
    "start": "3194790",
    "end": "3203849"
  },
  {
    "text": "Oh, wow, there's a\nlot of questions now.  \"Physicians are experimenting\non end-of-life care based",
    "start": "3203850",
    "end": "3210540"
  },
  {
    "text": "on AI to nudge conversations. Do you have any suggestions\nfor patients and doctors?\"",
    "start": "3210540",
    "end": "3215625"
  },
  {
    "text": " Yeah, that's very challenging.",
    "start": "3215625",
    "end": "3221230"
  },
  {
    "text": "I do think one important\nthing about sort of these high-stakes settings\nis to think about sort",
    "start": "3221230",
    "end": "3226460"
  },
  {
    "text": "of the alternative and\nthe whole decision systems that they're part of, right?",
    "start": "3226460",
    "end": "3231680"
  },
  {
    "text": "So, say, a medical diagnosis-- or I'll give another example\nI'm more familiar with, which",
    "start": "3231680",
    "end": "3236930"
  },
  {
    "text": "is predicting whether or not\nsomeone will commit crime again and so should be\nreleased for parole. These are both really\nhigh-stakes prediction tasks.",
    "start": "3236930",
    "end": "3244490"
  },
  {
    "text": "And the way they're\nperformed is there's a machine learning system and a\nhuman, and they sort of jointly make a decision.",
    "start": "3244490",
    "end": "3249990"
  },
  {
    "text": "And so you need to\nthink about not only the machine learning\nsystem, which is sort of what I've\ntalked about here, but also the human part,\nright, and how they integrate",
    "start": "3249990",
    "end": "3255870"
  },
  {
    "text": "and how their decisions\nget combined together. I think that's actually\nthe important part. How do humans\noverride the machines?",
    "start": "3255870",
    "end": "3261950"
  },
  {
    "text": "How do they incorporate the\nsuggestions of the machines even more so than the\npredictions, which I think need to always be\ntaken carefully?",
    "start": "3261950",
    "end": "3270348"
  },
  {
    "text": "Next one-- \"how can we\ncombine model's objectives to gain greater\nunderstanding of the world and to combine it to create\nintelligent behavior?\"",
    "start": "3270348",
    "end": "3276799"
  },
  {
    "text": "Yeah, I think this is basically\nthe open question, right, the unfortunate thing that\nwe don't know how to do.",
    "start": "3276800",
    "end": "3283920"
  },
  {
    "text": "And I think that's\nthe thing that we are struggling with in the\nrobustness generalization",
    "start": "3283920",
    "end": "3289070"
  },
  {
    "text": "literature. What is the right approach? And I think there's not\nreally even a consensus. Is it more data collection?",
    "start": "3289070",
    "end": "3294080"
  },
  {
    "text": "Is it smarter ways of\ntraining the model? Or is it better models? It's not clear yet what\nthe right way is yet.",
    "start": "3294080",
    "end": "3301160"
  },
  {
    "text": "Unfortunately, I don't have\na great answer beyond that. \"For shortcuts, I think\neven people use shortcuts",
    "start": "3301160",
    "end": "3306770"
  },
  {
    "text": "to identify something. Do we have some way to\nunderstand shortcuts based on training data?\"",
    "start": "3306770",
    "end": "3311780"
  },
  {
    "text": "Yeah, this is a good point. So humans will\nalso use shortcuts. But I think the\nimportant thing here",
    "start": "3311780",
    "end": "3317420"
  },
  {
    "text": "is that these shortcuts\nare a lot more crude than the human ones that we use. And at some level, they don't\neven pass basic sanity checks,",
    "start": "3317420",
    "end": "3325290"
  },
  {
    "text": "right? For entailment, we know\nthat the output should depend on both the inputs.",
    "start": "3325290",
    "end": "3330530"
  },
  {
    "text": "But in reality, it's only\ndepending on the hypothesis, which is very problematic. And what people do today is they\nhave these sort of challenge",
    "start": "3330530",
    "end": "3338870"
  },
  {
    "text": "sets, like examine the\nperformance of a model just based on the hypothesis. And these kinds of sort of\nwhat are close to-- those",
    "start": "3338870",
    "end": "3344787"
  },
  {
    "text": "are unit tests help\ncatch these kinds of shortcuts in many cases. So I think one way to detect\nthem is things like that.",
    "start": "3344787",
    "end": "3352520"
  },
  {
    "text": "Our model shouldn't be sensitive\nto certain perturbations, or it should be sensitive\nto certain perturbations.",
    "start": "3352520",
    "end": "3357920"
  },
  {
    "text": "And you go off of those\nkinds of assertions. \"Is there currently\na correlation",
    "start": "3357920",
    "end": "3363019"
  },
  {
    "text": "between model capacity and\nnumber of shortcuts employed? Are larger models\nmore likely to happen",
    "start": "3363020",
    "end": "3368060"
  },
  {
    "text": "on the correct correlations? Or are smaller models more\nlikely to use shortcuts?\" That's a good question.",
    "start": "3368060",
    "end": "3374040"
  },
  {
    "text": "I think the general\nsense that I get from reading the literature\nis that smaller models are",
    "start": "3374040",
    "end": "3379520"
  },
  {
    "text": "more likely to use\nshortcuts in many ways. For example, in this\npaper about sort of watermark-based shortcuts,\nlinear models did a lot worse.",
    "start": "3379520",
    "end": "3389299"
  },
  {
    "text": "They would really pick up\nheavily on these watermarks, whereas CNNs did so with less\nweights and less frequency.",
    "start": "3389300",
    "end": "3397309"
  },
  {
    "text": "And I think,\ngenerally, that's true, that large-capacity models\ntrained with a lot of data can use some of its capacity\njust to model the shortcuts.",
    "start": "3397310",
    "end": "3403910"
  },
  {
    "text": "And it'll still do\nwell on the data without shortcuts as\nlong as they exist. But, really, the\nkey thing here is",
    "start": "3403910",
    "end": "3409490"
  },
  {
    "text": "you need to at least see some\ndata without the shortcut pattern. ",
    "start": "3409490",
    "end": "3415570"
  },
  {
    "text": "\"How much are you--\"\nOh, I already answered. OK, great. Yeah, so I want to get\ninto the breakout now,",
    "start": "3415570",
    "end": "3422700"
  },
  {
    "text": "actually, especially because\nsomeone asked the question, what's sort of the solution? And are humans robust?",
    "start": "3422700",
    "end": "3428590"
  },
  {
    "text": "So if, Woody, you could drop\nus into our breakout session for, say, five or\nsix minutes, it",
    "start": "3428590",
    "end": "3435818"
  },
  {
    "text": "would be great to talk\nabout these two questions. So the first one is, are the\nbrittleness issues inevitable?",
    "start": "3435818",
    "end": "3441420"
  },
  {
    "text": "What do you think\nare the solutions? What are the right\napproaches that you think of? a The second question\nis, are humans robust?",
    "start": "3441420",
    "end": "3447930"
  },
  {
    "text": "And if you think so, what's\nthe key ingredient that makes humans robust or\nmore robust than machines?",
    "start": "3447930",
    "end": "3455609"
  },
  {
    "text": "Awesome. Yes, I'll create\nthe breakout rooms. If everyone wants to\ntake a quick screenshot or try to remember these I'll\npost the questions in the chat",
    "start": "3455610",
    "end": "3462480"
  },
  {
    "text": "as well. But they won't be in\nthe breakout session. Oh, OK.",
    "start": "3462480",
    "end": "3468925"
  },
  {
    "text": " Great.",
    "start": "3468925",
    "end": "3474480"
  },
  {
    "text": "I think I'm muted. Let's see. Yes, you're muted. OK, great. All right, excellent.",
    "start": "3474480",
    "end": "3479940"
  },
  {
    "text": "All right, so I'll go\nthrough the second part a little bit quicker. I'm glad that we got\nso many good questions",
    "start": "3479940",
    "end": "3485550"
  },
  {
    "text": "on the first part, which\nis the more important of the two parts of this talk. And the second part is thinking\na little bit about, how can",
    "start": "3485550",
    "end": "3492420"
  },
  {
    "text": "we do learning? How can we fix these problems? And the kinds of research\nthat Percy and I and others",
    "start": "3492420",
    "end": "3498990"
  },
  {
    "text": "in Stanford have been doing. And so the key\nproblem that I think you should keep in\nmind with all of this",
    "start": "3498990",
    "end": "3504450"
  },
  {
    "text": "is that the training\ndistribution is very different from\nthe test distribution. This is the root of all evil\nfor these robustness problems.",
    "start": "3504450",
    "end": "3511140"
  },
  {
    "text": "And so we need to think\nabout, is the limitation that we can't generalize from\ntrain to test inevitable?",
    "start": "3511140",
    "end": "3516377"
  },
  {
    "text": "Or can we come up with\nsome clever data collection schemes or model\ntraining mechanisms that allow us to generalize?",
    "start": "3516377",
    "end": "3523320"
  },
  {
    "text": "And so to do this, we need to\nthink a little bit about how distributions can shift.",
    "start": "3523320",
    "end": "3529047"
  },
  {
    "text": "And so I'll give you a\nlittle bit of definitions. The first one is\ncovariate shift. And this is what\nyou usually think",
    "start": "3529048",
    "end": "3534090"
  },
  {
    "text": "of when people say the\ndistributions are different. So you might get these-- Let's say you're making\na face recognizer.",
    "start": "3534090",
    "end": "3539850"
  },
  {
    "text": "You have these really\nnice well-lit portraits in the training data. And at test time, you're using\nit with CCTVs, so all sorts",
    "start": "3539850",
    "end": "3546057"
  },
  {
    "text": "of different environments. But the underlying\ntask is the same, and there should be\na single predictor that does well both on portraits\nand images cropped from CCTVs.",
    "start": "3546057",
    "end": "3555670"
  },
  {
    "text": "Another example is label\nshift, where the input features look similar. But now the output label's\ndistribution has shifted.",
    "start": "3555670",
    "end": "3563260"
  },
  {
    "text": "So, for example, if you're\nmaking a face recognizer and at training time, you\nneed really precise matching, so you're only going to\nbe calling detections",
    "start": "3563260",
    "end": "3570310"
  },
  {
    "text": "when the images look\nexactly the same. But at test time, you're making\na product for your camera. And so it can be a\nlittle bit looser.",
    "start": "3570310",
    "end": "3576490"
  },
  {
    "text": "And so you might deal with\nblurry images and so on. And so the litmus test for this\nis you have the same predictor,",
    "start": "3576490",
    "end": "3582550"
  },
  {
    "text": "but you're changing\nyour threshold. You're just saying\nit's OK if I'm a little bit less confident. I'm still going\nto make the call.",
    "start": "3582550",
    "end": "3588485"
  },
  {
    "text": "And this is an instance\nof label shift. And the final one\nthat is basically intractable in all\ncases is concept drift.",
    "start": "3588485",
    "end": "3595579"
  },
  {
    "text": "And so here, you might\nhave a prediction task where you're trying\nto initially recognize",
    "start": "3595580",
    "end": "3601030"
  },
  {
    "text": "faces of the same people. But then at test time, you want\nto match people across time, like young pictures\nand old pictures.",
    "start": "3601030",
    "end": "3607750"
  },
  {
    "text": "The task is fundamentally\ndifferent, right, whether or not you're\nmatching the same person or person shifted in time.",
    "start": "3607750",
    "end": "3612920"
  },
  {
    "text": "And so no one predictor\nis going to do really well on both of these tasks. And so there's a sort of\nfundamental change in the task",
    "start": "3612920",
    "end": "3619720"
  },
  {
    "text": "definition. And I'm going to go\nover to sort of ways to deal with all\nof these problems.",
    "start": "3619720",
    "end": "3625369"
  },
  {
    "text": "The first one is we're just\ngoing to collect more data. Someone sort of talked about\nthis as a question earlier.",
    "start": "3625370",
    "end": "3630520"
  },
  {
    "text": "And this is sort of\nthe key thing, right? If we get more data, we\ncan do a lot more things. And the second part is a\nlittle bit more ambitious.",
    "start": "3630520",
    "end": "3636670"
  },
  {
    "text": "And it's going to say,\nlet's try to only deal with what data we have. So the first idea\nis let's just say",
    "start": "3636670",
    "end": "3642790"
  },
  {
    "text": "we're going to try to\ngeneralize to a test set, and we're just going\nto collect more data. So a classic example\nof this kind of task",
    "start": "3642790",
    "end": "3649480"
  },
  {
    "text": "is you're recognizing digits. So you have images of digits. The left one is MNIST,\nwhich is really old. The USPS is even older\nactually and SVHN,",
    "start": "3649480",
    "end": "3656800"
  },
  {
    "text": "which is a more\nmodern recognized digits from, I think, mail\nnumbers that are taken",
    "start": "3656800",
    "end": "3663369"
  },
  {
    "text": "from the wild. So in all of these cases, you\nneed to output the number, right? This one is a 2. This one is a 7 and so on.",
    "start": "3663370",
    "end": "3669522"
  },
  {
    "text": "When we're collecting\nnew data, let's say we train a model on MNIST,\nand we want to do well on SVHN",
    "start": "3669522",
    "end": "3674859"
  },
  {
    "text": "at test time. And so this is a\ndistribution shift. But we might be able to\ncollect more data, right?",
    "start": "3674860",
    "end": "3680260"
  },
  {
    "text": "It's unrealistic to maybe\nsay we only have this, and we have to predict this. And so what we might\nhave is we might",
    "start": "3680260",
    "end": "3687760"
  },
  {
    "text": "be able to collect\nsome unlabeled data from SVHN, right? We can't afford someone\nlabeling them by hand,",
    "start": "3687760",
    "end": "3693040"
  },
  {
    "text": "but we might just be\nable to get the images. And this is called\nunsupervised domain adaptation. And if we can collect\nlabels, that's",
    "start": "3693040",
    "end": "3699549"
  },
  {
    "text": "all called supervised\ndomain adaptation. And that's even better. And so we can ask, when\ncan we do learning, right?",
    "start": "3699550",
    "end": "3705940"
  },
  {
    "text": "If we're in covariate shift\nand we have this source data, we might be able to do learning\nbecause we have a better",
    "start": "3705940",
    "end": "3711940"
  },
  {
    "text": "model that can adapt to these\ndifferent kinds of distribution shifts that occur. And so the general thing that\nyou should sort of think about",
    "start": "3711940",
    "end": "3718570"
  },
  {
    "text": "is if we're in\ncovariate shift settings and we have source domain\ndata, so unlabeled data",
    "start": "3718570",
    "end": "3724270"
  },
  {
    "text": "from our target\ndistribution, then we can actually sometimes\ngeneralize to our target task",
    "start": "3724270",
    "end": "3729940"
  },
  {
    "text": "even though we\ndon't have labels. And so this is a\nsetting that we're",
    "start": "3729940",
    "end": "3735220"
  },
  {
    "text": "going to be talking about for\nthe rest of the talk, the rest of the couple of\nminutes of this talk, where we're going\nto have to say,",
    "start": "3735220",
    "end": "3741190"
  },
  {
    "text": "we have this covariate shift\nproblem where the prediction task is fundamentally the same.",
    "start": "3741190",
    "end": "3746230"
  },
  {
    "text": "And how can we generalize? So the easiest thing to do and\nthe most classic thing to do",
    "start": "3746230",
    "end": "3752259"
  },
  {
    "text": "is reweighting. So let's say we have\ntraining data that's 90% frontal images but 10%\nimages taken from the side.",
    "start": "3752260",
    "end": "3758620"
  },
  {
    "text": "And we want to generalize\nthe test data that's 50-50, front and side, right? So how can we do this?",
    "start": "3758620",
    "end": "3764270"
  },
  {
    "text": "Well, let's just\nreweight the data set. So each frontal\nfacing image counts for less, and each side facing\nimage counts for more, right?",
    "start": "3764270",
    "end": "3771250"
  },
  {
    "text": "So we've artificially\nrebalanced the data. And this gives us this\nassumption-free way of getting estimates of\nhow well our model will",
    "start": "3771250",
    "end": "3778480"
  },
  {
    "text": "perform on this 50-50 test set. And this applies to all of\nwhat I've talked about before.",
    "start": "3778480",
    "end": "3784030"
  },
  {
    "text": "If your data is imbalanced\nand has a minority group or maybe has\nshortcuts, maybe we can rebalance it to get rid of\nall of these problems, right?",
    "start": "3784030",
    "end": "3790570"
  },
  {
    "text": "So are we done? No, because even though I\ntalked about it that way,",
    "start": "3790570",
    "end": "3795880"
  },
  {
    "text": "if we reshuffle or\nrestructure the data set, the training data is. 100% men, and the test\ndata is 100% women.",
    "start": "3795880",
    "end": "3802510"
  },
  {
    "text": "So there's no overlap. And if we try to\nreweight this data, we're going to get\ninfinite error, right? because we need to\ninfinitely upweight",
    "start": "3802510",
    "end": "3808840"
  },
  {
    "text": "the women that we don't\nhave in our training data. And so this is the\nfundamental problem with all of these approaches.",
    "start": "3808840",
    "end": "3814068"
  },
  {
    "text": "When you don't have any\noverlap, your estimates all blow up and go to infinity. And so in the real world,\neverything is non-overlapping.",
    "start": "3814068",
    "end": "3822700"
  },
  {
    "text": "And so, usually, these kinds\nof estimates don't work. But, intuitively, we might\nthink these kinds of tasks",
    "start": "3822700",
    "end": "3829599"
  },
  {
    "text": "are possible. And the reason why you\nand I and many others think this is possible\nis this intuition, right?",
    "start": "3829600",
    "end": "3836320"
  },
  {
    "text": "Let's say we have training data\nthat's blue images and test data that's orange images. Clearly, there is no overlap\nbetween any of these images,",
    "start": "3836320",
    "end": "3843145"
  },
  {
    "text": "right? They're on different\ncolor channels. But if we desaturate\nthe images, we can perform prediction\non the desaturated image,",
    "start": "3843145",
    "end": "3849940"
  },
  {
    "text": "and we'll get really\ngood performance, right? And so the intuition that if\nwe can't distinguish the two",
    "start": "3849940",
    "end": "3855460"
  },
  {
    "text": "domains because we've\ndesaturated the images, we might do really well. And this is the idea behind most\nof modern domain adaptation,",
    "start": "3855460",
    "end": "3862690"
  },
  {
    "text": "where you learn to represent\nyour data in a space that doesn't change when you go from\ntraining to test distribution.",
    "start": "3862690",
    "end": "3869080"
  },
  {
    "text": "And so you measure how\nmuch your data changes in this sort of\nhigher-level representation.",
    "start": "3869080",
    "end": "3875215"
  },
  {
    "text": "And if your data is close, then\nyou're going to do really well. And the thing to keep in\nmind is your test performance",
    "start": "3875215",
    "end": "3881170"
  },
  {
    "text": "is going to be your\ntraining data's performance plus some sort of\ndistance that measures how different the training\nand test distributions are.",
    "start": "3881170",
    "end": "3888829"
  },
  {
    "text": "And if you can keep that small\nyou're going to do really well. And so you can think about\nthis very simply as saying,",
    "start": "3888830",
    "end": "3896130"
  },
  {
    "text": "this gap. The test error of a model\nis the source performance. How well we do on the training\ndata and the gap between train",
    "start": "3896130",
    "end": "3902910"
  },
  {
    "text": "error and test error? And this idea is\nthat we're going to look at a domain distance\nwhere no matter what model we",
    "start": "3902910",
    "end": "3910500"
  },
  {
    "text": "pick, we're going to do well\nbecause the distributions look so similar, right? If an image is desaturated\nand they look identical,",
    "start": "3910500",
    "end": "3916740"
  },
  {
    "text": "it doesn't matter\nwhat the model is. They do identically. And so if we do well\nin the source domain",
    "start": "3916740",
    "end": "3923490"
  },
  {
    "text": "and the domain distance is low,\nwe might be able to generalize. And this is really interesting\nand optimistic, right?",
    "start": "3923490",
    "end": "3929759"
  },
  {
    "text": "These all seem like things that\nwe can measure and think about, and they give us\nconditions under which we might be able to do well\non a test distribution.",
    "start": "3929760",
    "end": "3937560"
  },
  {
    "text": "And there's been a lot of\nwork over the last almost two decades now on these kinds of\ndomain distances and bounds",
    "start": "3937560",
    "end": "3943740"
  },
  {
    "text": "and how you can learn\nfrom unlabeled data. And they give great intuition. They let you think carefully\nabout these kinds of problems.",
    "start": "3943740",
    "end": "3950680"
  },
  {
    "text": "But, unfortunately, if you\ntry to actually compute these bounds, what's my\nguarantee of test error, they're usually vacuous.",
    "start": "3950680",
    "end": "3956490"
  },
  {
    "text": "So you'll say things like\nthe accuracy will be greater than 0. And the error will be less than\n1, which is not super helpful.",
    "start": "3956490",
    "end": "3963000"
  },
  {
    "text": " And just to go over how\nthese kinds of things often work in practice,\ndomain distances,",
    "start": "3963000",
    "end": "3971533"
  },
  {
    "text": "the thing I just\ndescribed, is the basis for a lot of these modern\ndomain adaptation methods. And the key idea is that\nneural nets are everywhere",
    "start": "3971533",
    "end": "3978600"
  },
  {
    "text": "because neural nets work. And you use them as a way to\nmeasure the domain distance.",
    "start": "3978600",
    "end": "3983700"
  },
  {
    "text": "And the idea here\nis that you have one part of your model\nmaximizing performance on the training data.",
    "start": "3983700",
    "end": "3989400"
  },
  {
    "text": "And you have another part\nof the model making sure that you can't distinguish\nbetween the training and the data distribution on\nthis what's called a bottleneck",
    "start": "3989400",
    "end": "3996510"
  },
  {
    "text": "feature space,\nwhere, at this level, your training and test data\nshould be indistinguishable",
    "start": "3996510",
    "end": "4001760"
  },
  {
    "text": "and yet useful for\nactually doing the task. ",
    "start": "4001760",
    "end": "4007480"
  },
  {
    "text": "And so we have this hope\nthat we have this reweighting thing, which has no\nmodel dependence,",
    "start": "4007480",
    "end": "4013109"
  },
  {
    "text": "and this model-based\ndomain distances that requires us to carefully\nconstruct a neural network.",
    "start": "4013110",
    "end": "4018770"
  },
  {
    "text": "But on the other hand,\nthat's the only way we can get these things\nto work in the real world. With reweighting, often,\nthese weights are infinity.",
    "start": "4018770",
    "end": "4026110"
  },
  {
    "text": "And so there's no free lunch. We either need model\nassumptions or assumptions about overlap on the domain.",
    "start": "4026110",
    "end": "4032710"
  },
  {
    "text": "But if we have one of those\nand unlabeled data on the test domain, we can actually\nsometimes do well.",
    "start": "4032710",
    "end": "4040430"
  },
  {
    "text": "The other approach that I\ngo over with little quickly because I'm running\nlow on time, I can describe at a very\nhigh level as this idea.",
    "start": "4040430",
    "end": "4049460"
  },
  {
    "text": "As I said before,\nthe main issue is that our training distribution\nand the test distribution are different, right?",
    "start": "4049460",
    "end": "4055390"
  },
  {
    "text": "And if they were the\nsame, we'd be done. But they're not. But what if I told you I gave\nyou a list of 100 possible test",
    "start": "4055390",
    "end": "4061789"
  },
  {
    "text": "distributions? And I say your true test\ndistribution is going to be one amongst these 100.",
    "start": "4061790",
    "end": "4067040"
  },
  {
    "text": "Then we can train a model to\ndo well in all of these, right? We just go through each\none of these test sets, and we say our model has to\ndo well on the worst one.",
    "start": "4067040",
    "end": "4074990"
  },
  {
    "text": "And if we can get a model\nthat works on all of them, we know that our model\nis going to do well in the true test set.",
    "start": "4074990",
    "end": "4080269"
  },
  {
    "text": "So this is thinking\nabout a potential set of test distributions and\nconsidering the worst case.",
    "start": "4080270",
    "end": "4086120"
  },
  {
    "text": "And this is what's called a\nminimax optimization problem. So we're going to\nfind the best model-- that's the min part--\nthat works well",
    "start": "4086120",
    "end": "4093110"
  },
  {
    "text": "over the worst possible\npotential test set, and that's the max part. And this idea is going to\nwork whenever the true test",
    "start": "4093110",
    "end": "4099509"
  },
  {
    "text": "set is contained in\nthis uncertainty, q. We're saying worst case\nover this big Q, which",
    "start": "4099510",
    "end": "4105500"
  },
  {
    "text": "is the set of potential\ntest distributions. And this fails whenever Q\nis too small or too big. If Q doesn't contain the\nreal test distribution,",
    "start": "4105500",
    "end": "4112068"
  },
  {
    "text": "you've got no guarantees. If Q is so big that it\ncontains everything, then your model is going to\nbe so pessimistic, right,",
    "start": "4112069",
    "end": "4119000"
  },
  {
    "text": "because it has to be prepared\nfor any possible distribution that's it's just going to\npredict 50-50 or something",
    "start": "4119000",
    "end": "4124970"
  },
  {
    "text": "vacuous for all of your inputs. I'm going to skip over\na bit of examples.",
    "start": "4124970",
    "end": "4132290"
  },
  {
    "text": "And I'm going to\ngo to this slide and say these kinds of\nideas can be applied in each one of the settings\nthat I described before,",
    "start": "4132290",
    "end": "4139339"
  },
  {
    "text": "talking about minority\ngroups in fairness or adversarial examples\nor understanding by carefully choosing the\nkinds of worst-case groups.",
    "start": "4139340",
    "end": "4147439"
  },
  {
    "text": "In the case of minority\ngroups, we basically explicitly list out all\nof the possible minorities that we care about.",
    "start": "4147439",
    "end": "4152960"
  },
  {
    "text": "And we consider the worst-case\nperformance over all of those. In adversarial examples,\nwe know that these images",
    "start": "4152960",
    "end": "4159799"
  },
  {
    "text": "before and after\nperturbation are close. So we consider all\ndistributions that are nearby each other in pixel\nspace, and then",
    "start": "4159800",
    "end": "4165950"
  },
  {
    "text": "we maximize over the\nworst case over those. And then for shortcuts,\nwhat we can do",
    "start": "4165950",
    "end": "4171770"
  },
  {
    "text": "is we can explicitly construct\ngroups that don't contain some of these shortcuts. And we enumerate all\nsuch groups and then",
    "start": "4171770",
    "end": "4177657"
  },
  {
    "text": "make sure that these worst\ncase groups work well. So, for example, if\nwe have a model that relies too much\non backgrounds, we",
    "start": "4177658",
    "end": "4183889"
  },
  {
    "text": "construct subgroups\nof the data that have sort of mismatching\nbackgrounds and objects.",
    "start": "4183890",
    "end": "4190989"
  },
  {
    "text": "So to basically wrap\nup here, the limits of this kind of\napproach is that if we",
    "start": "4190990",
    "end": "4196210"
  },
  {
    "text": "pick too small of a worst-case\ngroup, we get no robustness. And if we pick too broad\nof a worst-case group,",
    "start": "4196210",
    "end": "4201640"
  },
  {
    "text": "we get vacuous models. And there's no simple\nor general principle for designing these losses even\nthough this approach gives us",
    "start": "4201640",
    "end": "4207610"
  },
  {
    "text": "really nice ways of thinking\nabout and optimizing models for the worst case and\ngetting guarantees.",
    "start": "4207610",
    "end": "4213250"
  },
  {
    "text": "OK, I'm going to wrap up there. If anyone has questions, I\nwould be happy to answer them.",
    "start": "4213250",
    "end": "4219020"
  },
  {
    "text": "I can stay for a little\nbit longer in chat if people have questions.",
    "start": "4219020",
    "end": "4225199"
  },
  {
    "text": "All right, maybe we\nshould just thank Tatsu for his really insightful\nand interesting talk.",
    "start": "4225200",
    "end": "4231530"
  },
  {
    "text": "And then maybe people can\nrun off if they have to go. So thanks, Tatsu.",
    "start": "4231530",
    "end": "4236570"
  },
  {
    "text": " Thank you. Really, a lot of interesting\nthings food for thought.",
    "start": "4236570",
    "end": "4244050"
  },
  {
    "text": "So I hope that everyone has\ntheir eyes opened with respect",
    "start": "4244050",
    "end": "4249290"
  },
  {
    "text": "to all the different\nproblems that we're seeing and hopefully motivated to\nhelp solve some of these",
    "start": "4249290",
    "end": "4254510"
  },
  {
    "text": "because I think there's a lot\nof interesting open research questions here. ",
    "start": "4254510",
    "end": "4263083"
  }
]
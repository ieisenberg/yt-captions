[
  {
    "start": "0",
    "end": "11000"
  },
  {
    "text": "Welcome to the lecture on classifiers.",
    "start": "5150",
    "end": "9190"
  },
  {
    "start": "11000",
    "end": "727000"
  },
  {
    "text": "So this is the point in the class which we are going to change to our next major topic.",
    "start": "11810",
    "end": "21735"
  },
  {
    "text": "So far we've talked about in the main regression",
    "start": "21735",
    "end": "27224"
  },
  {
    "text": "problems where the target variable y is a real number or real vector.",
    "start": "27224",
    "end": "35625"
  },
  {
    "text": "And now we want to switch to a different problem, and this problem is called classification.",
    "start": "35625",
    "end": "42370"
  },
  {
    "text": "In classification, the target value- the target variable v is categorical.",
    "start": "42650",
    "end": "50430"
  },
  {
    "text": "It can only take a finite number of possible values, and we will call that set script V. Now",
    "start": "50430",
    "end": "63470"
  },
  {
    "text": "these problems of classification are- are treated in a very similar way to regression.",
    "start": "63470",
    "end": "73325"
  },
  {
    "text": "In that we will have a performance metric of a loss function,",
    "start": "73325",
    "end": "78439"
  },
  {
    "text": "have do empirical risk minimization with regularizes.",
    "start": "78440",
    "end": "83450"
  },
  {
    "text": "But then there are also specific attributes of classification problems which",
    "start": "83450",
    "end": "89149"
  },
  {
    "text": "distinguish them from regression problems. Uh, in particular,",
    "start": "89150",
    "end": "94910"
  },
  {
    "text": "we'll see that the type of loss functions we use is different, that there is, uh,",
    "start": "94910",
    "end": "101460"
  },
  {
    "text": "that there are particular types of error which can occur in a classification problem,",
    "start": "101460",
    "end": "107000"
  },
  {
    "text": "that cannot occur, you know, in a regression problem, and there are ways of specifying the nature of",
    "start": "107000",
    "end": "117979"
  },
  {
    "text": "the predictor for classification problems which are different from how we would do those in regression.",
    "start": "117980",
    "end": "125765"
  },
  {
    "text": "We will also have a chance to talk about probabilistic regression, yeah, in a later section of the class.",
    "start": "125765",
    "end": "138130"
  },
  {
    "text": "Now the set script v, its elements noted V1 to V capital K is called the label set.",
    "start": "139220",
    "end": "149060"
  },
  {
    "text": "It's the set of possible values of V The VI called the classes or the labels or the categories,",
    "start": "149060",
    "end": "157950"
  },
  {
    "text": "and when- when k is 2, this is called Boolean classification.",
    "start": "157950",
    "end": "163915"
  },
  {
    "text": "In which case we usually think about script v as being true or false, positive or negative.",
    "start": "163915",
    "end": "170600"
  },
  {
    "text": "Um, it's called multiclass classification. When capital K is greater than 2,",
    "start": "170600",
    "end": "177410"
  },
  {
    "text": "when we have more than two classes. Uh, then our script v might be maybe yes,",
    "start": "177410",
    "end": "184190"
  },
  {
    "text": "maybe no, it might be uh, places or countries, it might be languages,",
    "start": "184190",
    "end": "193480"
  },
  {
    "text": "it might be the set of English words in some dictionary. It might be the set of possible orderings of M horses and erase,",
    "start": "193480",
    "end": "205010"
  },
  {
    "text": "so that's the m factorial permutations of the numbers 1-n.",
    "start": "205010",
    "end": "214200"
  },
  {
    "text": "Very often we just number our categories, and so instead,",
    "start": "216130",
    "end": "221870"
  },
  {
    "text": "instead of thinking them as V1 through V capital K, we think of them as just the numbers 1 through",
    "start": "221870",
    "end": "227120"
  },
  {
    "text": "k. So when we're",
    "start": "227120",
    "end": "234950"
  },
  {
    "text": "predicting a categorical raw output V, given a raw input U, that's called classification. Um,",
    "start": "234950",
    "end": "244739"
  },
  {
    "text": "we were talking about Boolean classification or multiclass classification,",
    "start": "245890",
    "end": "251650"
  },
  {
    "text": "and the predictor is a map from script U. Our U is our set of possible independent variables to script V,",
    "start": "251650",
    "end": "260989"
  },
  {
    "text": "the set of target variables. We would denote that by a capital G. Remember that in the regression section,",
    "start": "260990",
    "end": "268685"
  },
  {
    "text": "we talked about little g as being the predictor and it was parametrized by Theta. But also remember that little g was the map from x to y,",
    "start": "268685",
    "end": "278955"
  },
  {
    "text": "where x was an embedding of U and y was an embedding of V,",
    "start": "278955",
    "end": "284115"
  },
  {
    "text": "and so here we have named the map from U to V capital G. And so v hat is capital G of u is our prediction of v given u,",
    "start": "284115",
    "end": "297365"
  },
  {
    "text": "and then G is called a classifier.",
    "start": "297365",
    "end": "300539"
  },
  {
    "text": "And one way to think about the classification is to think about",
    "start": "303820",
    "end": "308915"
  },
  {
    "text": "which values of u give a result of g of u is equal to 1?",
    "start": "308915",
    "end": "316805"
  },
  {
    "text": "Which values of u give a result of g of u is equal to 2 and so on,",
    "start": "316805",
    "end": "322389"
  },
  {
    "text": "and if you think about that, then what we've done is we've classified the inputs u into K different categories,",
    "start": "322390",
    "end": "331464"
  },
  {
    "text": "or K different classes, and those classes are mutually exclusive and collectively exhaustive.",
    "start": "331464",
    "end": "340259"
  },
  {
    "text": "So here's an example. Here we have our set capital U,",
    "start": "344270",
    "end": "352560"
  },
  {
    "text": "as a- so capital U will be uh,",
    "start": "352560",
    "end": "362400"
  },
  {
    "text": "the square, the set of points, u_1, u_2.",
    "start": "362400",
    "end": "371115"
  },
  {
    "text": "Where I think the absolute value of the components in this example is between minus 4 and 4,",
    "start": "371115",
    "end": "381440"
  },
  {
    "text": "and our set V is equal to minus 1 or 1.",
    "start": "381440",
    "end": "390350"
  },
  {
    "text": "We have two categories, one of which is minus 1, and the other one, which is 1,",
    "start": "390350",
    "end": "395730"
  },
  {
    "text": "and in this plot you can see all of our data points, so here there's no split into training and test set.",
    "start": "395730",
    "end": "405574"
  },
  {
    "text": "This is just the training set, and there are, I think 100 points here.",
    "start": "405575",
    "end": "411920"
  },
  {
    "text": "And so we've got 100 data points, and for each data point, we have a record consisting of a u,",
    "start": "411920",
    "end": "421490"
  },
  {
    "text": "which will be a point in the square, and a v, which will either be a minus 1 or a 1,",
    "start": "421490",
    "end": "428825"
  },
  {
    "text": "and so we have 4i between 1 and n,",
    "start": "428825",
    "end": "436160"
  },
  {
    "text": "where n is 100, U i is script u the square,",
    "start": "436160",
    "end": "442199"
  },
  {
    "text": "and little v i is either minus 1 or 1,",
    "start": "442199",
    "end": "447665"
  },
  {
    "text": "and we've denoted the points here. We've shown them in the plot, so that minus 1 here, yeah, uh,",
    "start": "447665",
    "end": "458510"
  },
  {
    "text": "points with-points with for which V i is minus 1 are shown as red points,",
    "start": "458510",
    "end": "465655"
  },
  {
    "text": "and points for which VI equals 1, are shown as blue points,",
    "start": "465655",
    "end": "470830"
  },
  {
    "text": "and so these are 100 data points. Um, now what a classifier has to do is a classifier has to map",
    "start": "470830",
    "end": "480144"
  },
  {
    "text": "every point in script U to either minus 1 or 1.",
    "start": "480144",
    "end": "487950"
  },
  {
    "text": "So that if somebody comes along later and says, here's a new point in U,",
    "start": "487950",
    "end": "494420"
  },
  {
    "text": "Tell me what value for v you predict for it. Give me v hat,",
    "start": "494420",
    "end": "499850"
  },
  {
    "text": "well that's what the classifier does. And we denoted that in this picture by shading the square,",
    "start": "499850",
    "end": "508535"
  },
  {
    "text": "some of it is shaded pink, those points are points for which we predict an outcome which is minus 1,",
    "start": "508535",
    "end": "518714"
  },
  {
    "text": "and some points are shaded blue where we predict an outcome of 1. And so if somebody comes along with some new point,",
    "start": "518715",
    "end": "527270"
  },
  {
    "text": "let's make it some new point right here, and then our prediction for that point would be that v hat is minus 1,",
    "start": "527270",
    "end": "536880"
  },
  {
    "text": "if it's here, our prediction is that v hat is 1.",
    "start": "536880",
    "end": "543299"
  },
  {
    "text": "And we are trying to learn that predictor, capital G, we tried to construct it.",
    "start": "543760",
    "end": "550535"
  },
  {
    "text": "We're going to learn it from this dataset, and this particular predictor, we haven't talked about how to construct it yet.",
    "start": "550535",
    "end": "557120"
  },
  {
    "text": "But this predictor, particular predictor has learned from this particular dataset. And you can see it, that's okay.",
    "start": "557120",
    "end": "563750"
  },
  {
    "text": "Um, in particular, if we look at how well is it doing on the training set, well,",
    "start": "563750",
    "end": "571190"
  },
  {
    "text": "there are points such as-these points where the true value of v i is 1 and the prediction is the true value of v i is minus 1,",
    "start": "571190",
    "end": "584390"
  },
  {
    "text": "and the prediction is also minus 1, and there are points like these 1,",
    "start": "584390",
    "end": "590144"
  },
  {
    "text": "where the true value is 1 and the prediction is also 1. But then there are other points like this red point right there,",
    "start": "590145",
    "end": "599480"
  },
  {
    "text": "for that red point, the true value is minus 1 because it's a red point,",
    "start": "599480",
    "end": "606365"
  },
  {
    "text": "but the predicted value is 1 because it's in the blue region. And so these are points for which",
    "start": "606365",
    "end": "616355"
  },
  {
    "text": "our predictor is giving the wrong answer on the training data.",
    "start": "616355",
    "end": "623610"
  },
  {
    "text": "And there were some points in the other which would make a different type of error.",
    "start": "623650",
    "end": "629195"
  },
  {
    "text": "There are blue points for which we predict the outcome should be red,",
    "start": "629195",
    "end": "634680"
  },
  {
    "text": "and the red points for which we predict the outcome should be blue. One way to think about this is to kind of regression,",
    "start": "634680",
    "end": "643930"
  },
  {
    "text": "it's a kind of function fitting inside of our function,",
    "start": "643930",
    "end": "648940"
  },
  {
    "text": "assigning a real number to every point,",
    "start": "648940",
    "end": "654260"
  },
  {
    "text": "every possible value of U, a function is assigning a category to every possible value of U.",
    "start": "654260",
    "end": "662200"
  },
  {
    "text": "That category, either being minus 1 or 1, the category being red or blue.",
    "start": "662200",
    "end": "668690"
  },
  {
    "text": "This is a good picture to have in your mind when you're thinking about what is a classification problem?",
    "start": "669920",
    "end": "675300"
  },
  {
    "text": "Got a bunch of data points. They have colors associated with them. And you want to shade in the plane so that",
    "start": "675300",
    "end": "683140"
  },
  {
    "text": "the predictions corresponding to your shaded color match up with the true colors of the DataPoints.",
    "start": "683570",
    "end": "692340"
  },
  {
    "text": "And of course this is convenient to think like that. And in two dimensions, of course the problem is kinda easy.",
    "start": "692340",
    "end": "698040"
  },
  {
    "text": "We can simply shade in the plane to correspond to the colors of the points that we see and there's no need for us to ever get it wrong.",
    "start": "698040",
    "end": "706605"
  },
  {
    "text": "But if I'm working in d dimensions and d is large, well then I can't hope to do this by hand and I have to,",
    "start": "706605",
    "end": "715829"
  },
  {
    "text": "uh, uh, come up with an algorithm that's gonna do this for me.",
    "start": "715830",
    "end": "721270"
  },
  {
    "start": "727000",
    "end": "1205000"
  },
  {
    "text": "Let's talk about some applications of classification.",
    "start": "727880",
    "end": "733020"
  },
  {
    "text": "Um, here's an example. Medical diagnosis, u is a bunch of patient attributes.",
    "start": "733020",
    "end": "738209"
  },
  {
    "text": "So the fields in, uh, patient record, uh, test results,",
    "start": "738210",
    "end": "743475"
  },
  {
    "text": "and age, gender, height, body mass, a whole bunch of other attributes of the person.",
    "start": "743475",
    "end": "751560"
  },
  {
    "text": "Um, and then the Boolean V, the target variable,",
    "start": "751560",
    "end": "757185"
  },
  {
    "text": "encodes some disease status, has a disease or not or maybe it's multi-class.",
    "start": "757185",
    "end": "763755"
  },
  {
    "text": "Um, does the person have COVID-19, flu or just a cold?",
    "start": "763755",
    "end": "770740"
  },
  {
    "text": "Um, uh, if we're doing advertising, then u contains the attributes of a person,",
    "start": "774830",
    "end": "782024"
  },
  {
    "text": "the demographic data about an individual. And it also contains information about an ad that's being shown to them.",
    "start": "782025",
    "end": "791310"
  },
  {
    "text": "And then V encodes whether they will buy the item,",
    "start": "791310",
    "end": "796935"
  },
  {
    "text": "whether they're going to click on the ad, etc. Uh, fraud detection, so here u might contain the attributes of a transaction.",
    "start": "796935",
    "end": "807149"
  },
  {
    "text": "Was it in-person, was it over the phone, was it online? What kind of credit card it was?",
    "start": "807150",
    "end": "812805"
  },
  {
    "text": "Was it international? And then V is an attempt to, um,",
    "start": "812805",
    "end": "819540"
  },
  {
    "text": "V, the categories that V can be are either that it's a fraudulent transaction or that's it's a valid transaction.",
    "start": "819540",
    "end": "825615"
  },
  {
    "text": "And so one might have a whole bunch of data, um, where historic- where we have historical data of transactions",
    "start": "825615",
    "end": "834825"
  },
  {
    "text": "and they are labeled as to either being fraudulent transactions or valid transactions.",
    "start": "834825",
    "end": "840855"
  },
  {
    "text": "And we would learn from that data a predictor that when somebody makes a new transaction,",
    "start": "840855",
    "end": "847620"
  },
  {
    "text": "it can be- the attributes of that transaction can be fed into the predictor and then the predictor would",
    "start": "847620",
    "end": "853980"
  },
  {
    "text": "predict whether or not that transaction is fraudulent or valid.",
    "start": "853980",
    "end": "858639"
  },
  {
    "text": "Image classification. Uh, here U is an image that would be an array of pixels",
    "start": "862190",
    "end": "870045"
  },
  {
    "text": "and V would be categories of possible objects within the image.",
    "start": "870045",
    "end": "878790"
  },
  {
    "text": "So we might be- be looking to, uh, categorize natural objects, lions and tigers and bears, uh, vegetation,",
    "start": "878790",
    "end": "887370"
  },
  {
    "text": "trees, vehicles, buses and we might build a ca- classifier that you give it an image and it tells you what's in the image.",
    "start": "887370",
    "end": "897060"
  },
  {
    "text": "And, uh, one can do simple things",
    "start": "897060",
    "end": "902070"
  },
  {
    "text": "where one has an image which we know contains just one object.",
    "start": "902070",
    "end": "908205"
  },
  {
    "text": "And the classifier has to return simply which object it is and which case script V is just a list of possible objects,",
    "start": "908205",
    "end": "917700"
  },
  {
    "text": "or we might do more complicated things where the classifier has to return a list of all objects in the image.",
    "start": "917700",
    "end": "925740"
  },
  {
    "text": "And that would be- and then in that case the script V would have to contain not just individual objects,",
    "start": "925740",
    "end": "934080"
  },
  {
    "text": "but pairs of objects or lists of possible objects.",
    "start": "934080",
    "end": "939550"
  },
  {
    "text": "Here's another one, spam filtering. This was one of the very first successes of",
    "start": "942710",
    "end": "949095"
  },
  {
    "text": "the classification methodologies which we are discussing in this class, where, uh,",
    "start": "949095",
    "end": "955319"
  },
  {
    "text": "u contains the attributes of a mail message, uh, the formal dress, the two address,",
    "start": "955320",
    "end": "961964"
  },
  {
    "text": "and also a description of the text in the email message.",
    "start": "961965",
    "end": "969585"
  },
  {
    "text": "So which words are in the text in particular? And then V, the target variables would, uh,",
    "start": "969585",
    "end": "977090"
  },
  {
    "text": "uh, the categories would be either spam or ham. Ham, of course, meaning that it's,",
    "start": "977090",
    "end": "984405"
  },
  {
    "text": "uh, a good email message.",
    "start": "984405",
    "end": "988720"
  },
  {
    "text": "And back in the, uh, mid 1990s, uh, when email was becoming very popular, uh,",
    "start": "989630",
    "end": "1001985"
  },
  {
    "text": "the, uh, technique called Bayesian classification that we, um, may see later in this class,",
    "start": "1001985",
    "end": "1010310"
  },
  {
    "text": "we will certainly see related techniques, was one of the first successful methods of distinguishing spam from ham.",
    "start": "1010310",
    "end": "1019355"
  },
  {
    "text": "Another example application of classification is sports forecasting.",
    "start": "1019355",
    "end": "1027395"
  },
  {
    "text": "Here u contains the attributes of a game or a match and team A versus Team B,",
    "start": "1027395",
    "end": "1033935"
  },
  {
    "text": "so which teams are playing, attributes of the teams themselves.",
    "start": "1033935",
    "end": "1039034"
  },
  {
    "text": "And V encodes which game? Which- which of the, uh, teams wins the game?",
    "start": "1039035",
    "end": "1047525"
  },
  {
    "text": "Or possibly a tie. Uh, topic detection.",
    "start": "1047525",
    "end": "1054664"
  },
  {
    "text": "So u as an article or a news item and V encodes the topic.",
    "start": "1054664",
    "end": "1060110"
  },
  {
    "text": "So politics, sports or business, and so on. Uh, another example is sentence parsing,",
    "start": "1060110",
    "end": "1069335"
  },
  {
    "text": "so u is a sentence and V encodes the grammatical parsing of the sentence.",
    "start": "1069335",
    "end": "1075589"
  },
  {
    "text": "So that is a tree structure that encodes the relationships between the nouns,",
    "start": "1075589",
    "end": "1080825"
  },
  {
    "text": "the verbs, the oj- the adjectives, the adverbs, and all the other possible parts of speech.",
    "start": "1080825",
    "end": "1087990"
  },
  {
    "text": "So when we are measuring the performance of a classifier, ah,",
    "start": "1097210",
    "end": "1108245"
  },
  {
    "text": "there's a very natural performance metric that we have,",
    "start": "1108245",
    "end": "1113270"
  },
  {
    "text": "that is probably the most commonly used. And that is the idea of the error rate.",
    "start": "1113270",
    "end": "1120740"
  },
  {
    "text": "So, ah, if we have a data set with u 1 through u",
    "start": "1120740",
    "end": "1127445"
  },
  {
    "text": "n and v 1 through v n. So we have n records, for each one we have a u i and v i pair",
    "start": "1127445",
    "end": "1134899"
  },
  {
    "text": "where u i lies in script U. And vi is the target variable,",
    "start": "1134900",
    "end": "1141130"
  },
  {
    "text": "tells us which class u i belongs to. And then the predictions are given by v hat i,",
    "start": "1141130",
    "end": "1149335"
  },
  {
    "text": "which is g of u i. And a prediction is correct if v hat is v, and it's wrong or it's an error if v hat is not v.",
    "start": "1149335",
    "end": "1161390"
  },
  {
    "text": "The error rate E is the fraction of data points on which the predictor gave an incorrect prediction.",
    "start": "1161390",
    "end": "1170975"
  },
  {
    "text": "So in other words, we look at all i from 1 up to n. We compare vi with v hat i and if they're not the same,",
    "start": "1170975",
    "end": "1180620"
  },
  {
    "text": "well, that's an error and we count the number of errors and divide by n. Um, and this is the simplest possible performance metric for our classifier.",
    "start": "1180620",
    "end": "1190625"
  },
  {
    "text": "And once we've computed it, we can use it to compare different classifiers.",
    "start": "1190625",
    "end": "1196355"
  },
  {
    "text": "And in particular, we would do this not only on the training set but on the test set.",
    "start": "1196355",
    "end": "1202290"
  },
  {
    "start": "1205000",
    "end": "1333000"
  },
  {
    "text": "Now when we're working on with Boolean classification,",
    "start": "1205630",
    "end": "1212465"
  },
  {
    "text": "where the set of target variables, it has only two elements, we'll call them minus 1 and 1.",
    "start": "1212465",
    "end": "1219170"
  },
  {
    "text": "Then we refer to the class v is",
    "start": "1219170",
    "end": "1224660"
  },
  {
    "text": "minus 1 as the negative class and the class v is 1 as the positive class.",
    "start": "1224660",
    "end": "1230525"
  },
  {
    "text": "And that allows us to use this very nice terminology about the possible outcomes.",
    "start": "1230525",
    "end": "1237805"
  },
  {
    "text": "So we're going to be choosing v hat. That's what our predictor does for us.",
    "start": "1237805",
    "end": "1242920"
  },
  {
    "text": "And we've got a true v, which is part of the training set. And if v hat is 1 and v is 1,",
    "start": "1242920",
    "end": "1252019"
  },
  {
    "text": "well, then that's a correct prediction. And we would call that kind of prediction a true positive.",
    "start": "1252020",
    "end": "1257120"
  },
  {
    "text": "If v hat is minus 1 and v is minus 1, well that's also a correct prediction and we'd call that a true negative.",
    "start": "1257120",
    "end": "1264784"
  },
  {
    "text": "And then there are two different types of errors we can make. It could be that v is 1,",
    "start": "1264785",
    "end": "1270395"
  },
  {
    "text": "but we predict that v hat is minus 1. And that's called a false negative or type two error.",
    "start": "1270395",
    "end": "1276965"
  },
  {
    "text": "Or it could be that v is minus 1 and v hat is 1. And that's called a false positive or a type one error.",
    "start": "1276965",
    "end": "1284990"
  },
  {
    "text": "[NOISE] And once we've constructed a predictor,",
    "start": "1284990",
    "end": "1293015"
  },
  {
    "text": "we can construct a statistic which describes the performance of the predictor.",
    "start": "1293015",
    "end": "1302405"
  },
  {
    "text": "And that's this thing called a confusion matrix C. It's a two-by-two matrix.",
    "start": "1302405",
    "end": "1308885"
  },
  {
    "text": "And ah, its entries are the number of true negatives, the number of false negatives,",
    "start": "1308885",
    "end": "1315709"
  },
  {
    "text": "the number of false positives, and the number of true positives. And when we look at this,",
    "start": "1315709",
    "end": "1320735"
  },
  {
    "text": "we should realize that the first column here corresponds to v equals minus 1.",
    "start": "1320735",
    "end": "1328535"
  },
  {
    "text": "The second one corresponds to v is equal to 1. And the first row corresponds to v hat is minus 1.",
    "start": "1328535",
    "end": "1337610"
  },
  {
    "start": "1333000",
    "end": "1605000"
  },
  {
    "text": "And the second row corresponds to v hat is 1. So in the first row, we pick a v hat is minus 1.",
    "start": "1337610",
    "end": "1344344"
  },
  {
    "text": "If we're in the first column also, then we've got a true negative, if we're in the second column, then we've got a false negative.",
    "start": "1344344",
    "end": "1350660"
  },
  {
    "text": "We also refer to these entries individually as the number of true negatives, number of",
    "start": "1350660",
    "end": "1355850"
  },
  {
    "text": "false positives to number of false negatives and number of true positives.",
    "start": "1355850",
    "end": "1360980"
  },
  {
    "text": "Ctn, Cfn, Cfp, and Ctp. And these are numbers, not rates.",
    "start": "1360980",
    "end": "1368330"
  },
  {
    "text": "So that if we add up those four numbers, they add up to n,",
    "start": "1368330",
    "end": "1374270"
  },
  {
    "text": "which is the total number of data points. We have the total number of examples. We also have the number of negative examples,",
    "start": "1374270",
    "end": "1381280"
  },
  {
    "text": "which we'll denote by N, with little n as a subscript. It's the number of true negatives plus the number of false positives.",
    "start": "1381280",
    "end": "1390225"
  },
  {
    "text": "And the number of positive examples, which is the number of false negatives plus the number of true positives.",
    "start": "1390225",
    "end": "1395690"
  },
  {
    "text": "And these a-a sums over a-the columns.",
    "start": "1395690",
    "end": "1401120"
  },
  {
    "text": "So this-this sum right here, Ctn plus Cfp, that's equal to N n the number of negative examples.",
    "start": "1401120",
    "end": "1410990"
  },
  {
    "text": "And this sum right here is equal to Np the number of positive examples.",
    "start": "1410990",
    "end": "1419040"
  },
  {
    "text": "When we look at this matrix, of course, how do we get this matrix?",
    "start": "1419310",
    "end": "1424690"
  },
  {
    "text": "Well, we have predicted G, and we can evaluate it on the training set.",
    "start": "1424690",
    "end": "1432105"
  },
  {
    "text": "And that will give us a matrix C. And we can evaluate it on the test set. And that what gives R the matrix C. And these two matrices,",
    "start": "1432105",
    "end": "1440690"
  },
  {
    "text": "these two confusion matrices, are measurements of performance.",
    "start": "1440690",
    "end": "1447500"
  },
  {
    "text": "And when we look at them, well, what we'd like to see is large numbers on the diagonal.",
    "start": "1447500",
    "end": "1454085"
  },
  {
    "text": "Because the diagonals are measurements of the number of times in which we've made correct predictions.",
    "start": "1454085",
    "end": "1461914"
  },
  {
    "text": "And small numbers on the off diagonal, because all the off diagonal entries are incorrect predictions and that's",
    "start": "1461915",
    "end": "1467900"
  },
  {
    "text": "what they're counting, and they're counting separately the two different types of",
    "start": "1467900",
    "end": "1474515"
  },
  {
    "text": "incorrect predictions and the diagonals are counting separately the two different types of correct predictions.",
    "start": "1474515",
    "end": "1480899"
  },
  {
    "text": "Now, the- ah, ah, there are some very ah,",
    "start": "1487420",
    "end": "1495500"
  },
  {
    "text": "standard terminology that surrounds the confusion matrix that's worth coming over.",
    "start": "1495500",
    "end": "1502355"
  },
  {
    "text": "Ah, in particular, the false positive rate is simply Cfp divided by n. And the false negative rate is Cfn divided by",
    "start": "1502355",
    "end": "1510875"
  },
  {
    "text": "n. And the error rate is the sum of those two Cfp plus Cfn divided by n. Ah, there also,",
    "start": "1510875",
    "end": "1519860"
  },
  {
    "text": "ah, there's also a whole bunch of other terminology that people like to use, often in very specific fields.",
    "start": "1519860",
    "end": "1526385"
  },
  {
    "text": "Ah, so people talk about the true positive rate or the sensitivity or recall that Ctp every Np,",
    "start": "1526385",
    "end": "1533210"
  },
  {
    "text": "it's the fraction of true positives, which we guess correctly. The false alarm rate,",
    "start": "1533210",
    "end": "1539450"
  },
  {
    "text": "is Cfp on N n, the fraction of true negatives we incorrectly guess as positive.",
    "start": "1539450",
    "end": "1546230"
  },
  {
    "text": "There's the specificity or the true negative rate, which is Ctn on N n. The fraction of true negatives that we correct-correctly guess.",
    "start": "1546230",
    "end": "1556775"
  },
  {
    "text": "And there's the precision which is Ctp on Ctp plus Cfp,",
    "start": "1556775",
    "end": "1561800"
  },
  {
    "text": "which is the fraction of our positive guesses that really are positive. And these are, well, they're used in different fields.",
    "start": "1561800",
    "end": "1570410"
  },
  {
    "text": "Quite a lot of them are used in medicine. Some of them are used in specific branches of statistics.",
    "start": "1570410",
    "end": "1576260"
  },
  {
    "text": "Um, we will- I think, never use things like sensitivity or specificity in this class.",
    "start": "1576260",
    "end": "1583700"
  },
  {
    "text": "In machine learning, almost always people just look at the confusion matrix in the camps,",
    "start": "1583700",
    "end": "1589144"
  },
  {
    "text": "which are readily interpretable and readily converted to one of these other measures,",
    "start": "1589145",
    "end": "1595760"
  },
  {
    "text": "if you're working in the appropriate field. Um.",
    "start": "1595760",
    "end": "1604765"
  },
  {
    "text": "Now, one of the things about looking at, uh, the confusion matrix is that it highlights for us that we have",
    "start": "1604765",
    "end": "1612435"
  },
  {
    "start": "1605000",
    "end": "1849000"
  },
  {
    "text": "really two metrics for a Boolean classifier. We'd like to keep both the false positive rates small and the false negative rates small.",
    "start": "1612435",
    "end": "1622860"
  },
  {
    "text": "And the sum of those two numbers is the error rate. Um, keeping the error rates small is fine,",
    "start": "1622860",
    "end": "1631440"
  },
  {
    "text": "um, but sometimes it's not what you want out of a classifier. Um, so for example,",
    "start": "1631440",
    "end": "1638235"
  },
  {
    "text": "if you have, uh, uh, a manufacturing line, you have a camera that's looking at the, um,",
    "start": "1638235",
    "end": "1646340"
  },
  {
    "text": "objects that are coming off the magic manufacturing line and is trying to determine whether or not they are correctly manufactured or incorrectly manufactured.",
    "start": "1646340",
    "end": "1656310"
  },
  {
    "text": "Now if you've got very few errors in your manufacturing process,",
    "start": "1656310",
    "end": "1661485"
  },
  {
    "text": "then a huge percentage of those, uh, manufactured objects will actually be currently manufactured.",
    "start": "1661485",
    "end": "1670320"
  },
  {
    "text": "And only a very, very small percentage will be incorrectly manufactured. Classification is often difficult for, uh, such manufacturing problems.",
    "start": "1670320",
    "end": "1680475"
  },
  {
    "text": "And very often the predictor that minimizes",
    "start": "1680475",
    "end": "1685740"
  },
  {
    "text": "the error rate is simply to predict that all of the objects coming off your,",
    "start": "1685740",
    "end": "1693059"
  },
  {
    "text": "uh, production line are actually correctly manufactured.",
    "start": "1693060",
    "end": "1698290"
  },
  {
    "text": "Um, however, that's- that`s completely useless, of course, because it's giving you no information.",
    "start": "1698330",
    "end": "1704325"
  },
  {
    "text": "What you are much more interested in in such a situation, is to be able to detect those bad objects,",
    "start": "1704325",
    "end": "1715410"
  },
  {
    "text": "those incorrectly produced objects. And so one would have a classifier there, that is willing to incorrectly classify a few good objects as bad,",
    "start": "1715410",
    "end": "1727215"
  },
  {
    "text": "as long as it caught most of the bad objects. And so there, one is quite happy to accept a few false positives.",
    "start": "1727215",
    "end": "1736784"
  },
  {
    "text": "Positive here corresponding to bad objects in exchange for a very small number of false negatives.",
    "start": "1736785",
    "end": "1743865"
  },
  {
    "text": "For where the false negatives there would be incorrectly assuming that a bad object is good.",
    "start": "1743865",
    "end": "1750550"
  },
  {
    "text": "This is a very common situation that the thing you're trying to detect is rare and",
    "start": "1751480",
    "end": "1757820"
  },
  {
    "text": "so choosing a classifier that minimizes the error gives us an uninformative classifier.",
    "start": "1757820",
    "end": "1765210"
  },
  {
    "text": "And it's much better to try to choose a classifier that focuses on either false positives or false negatives.",
    "start": "1765210",
    "end": "1773985"
  },
  {
    "text": "Now we still need to be able to compare classifiers. And it's very often convenient to have a single metric by number.",
    "start": "1773985",
    "end": "1783809"
  },
  {
    "text": "And the way we do that, is we combine them with a weight. So and that- that's called the Neyman-Pearson metric, ENP.",
    "start": "1783810",
    "end": "1793605"
  },
  {
    "text": "It's Kappa times the false negative rate,",
    "start": "1793605",
    "end": "1799245"
  },
  {
    "text": "plus the false positive rate. And so here Kappa is some positive number.",
    "start": "1799245",
    "end": "1805500"
  },
  {
    "text": "And it sets how much we care about false negatives compared to false positives. So if Kappa is very large",
    "start": "1805500",
    "end": "1812415"
  },
  {
    "text": "then our Neyman-Pearson metric, uh, is affected very much by false negatives and not so much by false positives.",
    "start": "1812415",
    "end": "1822674"
  },
  {
    "text": "If Kappa is very small, then, our Neyman-Pearson metric is large when we've got a large number of false positives.",
    "start": "1822675",
    "end": "1830880"
  },
  {
    "text": "And not so much when we`ve got a large number of false negatives. And if Kappa is 1, well,",
    "start": "1830880",
    "end": "1836580"
  },
  {
    "text": "then the Neyman-Pearson metric is just the sum of the false negative rate and the false positive rate, which is the error rate.",
    "start": "1836580",
    "end": "1843400"
  },
  {
    "text": "Uh, let's look at this",
    "start": "1845120",
    "end": "1850380"
  },
  {
    "start": "1849000",
    "end": "2034000"
  },
  {
    "text": "more conveniently as a trade-off graph.",
    "start": "1850380",
    "end": "1856590"
  },
  {
    "text": "Um, if you pick any classifier, you designed it using whatever your favorite method of designing classifiers is,",
    "start": "1856590",
    "end": "1866100"
  },
  {
    "text": "and we haven't told you how to do that yet. And then you say, well, okay, I've got these- I've got a classifier and I can",
    "start": "1866100",
    "end": "1873540"
  },
  {
    "text": "compute its false negative and false positive rate on- on the test set. And that- those are going to give me two numbers.",
    "start": "1873540",
    "end": "1881535"
  },
  {
    "text": "And I can plot those two numbers on this plot right here.",
    "start": "1881535",
    "end": "1887130"
  },
  {
    "text": "So on the horizontal axis here, I've got the, uh, the false negative rate and the vertical axis,",
    "start": "1887130",
    "end": "1894765"
  },
  {
    "text": "I've got the false positive rate. And so you give me any classifier,",
    "start": "1894765",
    "end": "1900150"
  },
  {
    "text": "I have some particular point. There's one, there's one, here's another.",
    "start": "1900150",
    "end": "1907845"
  },
  {
    "text": "And so different classifiers correspond to different points on this,",
    "start": "1907845",
    "end": "1913260"
  },
  {
    "text": "uh, on this plot. Now one thing that's worth observing on this plot is that there were",
    "start": "1913260",
    "end": "1919020"
  },
  {
    "text": "some classifiers that you would just never use. One is G_3.",
    "start": "1919020",
    "end": "1925515"
  },
  {
    "text": "And the reason you would use never- you would never use G_3 is that,",
    "start": "1925515",
    "end": "1930750"
  },
  {
    "text": "if you compare it with G_2, our G_2 does better in terms of the false positive rate and the false negative rate.",
    "start": "1930750",
    "end": "1940845"
  },
  {
    "text": "And so G_2 wins on both counts.",
    "start": "1940845",
    "end": "1946065"
  },
  {
    "text": "And if you're interested, even if you're more concerned about one of those measures, then the other one, you'd still use G_2 over G_3.",
    "start": "1946065",
    "end": "1953460"
  },
  {
    "text": "If on the other hand, we compare with G_1.",
    "start": "1953460",
    "end": "1961905"
  },
  {
    "text": "Well, if I compare G_1 with G_3, well, G_1 does better in the false negative rate,",
    "start": "1961905",
    "end": "1969450"
  },
  {
    "text": "but worse in the false positive rate, and so I might well use G_3 instead of G_1.",
    "start": "1969450",
    "end": "1978540"
  },
  {
    "text": "But if I've got G_2, I would use G_2 over G_3.",
    "start": "1978540",
    "end": "1984460"
  },
  {
    "text": "Now if I compare G_1 and G_2, well, that's not so easy because G_1 has a smaller false negative rate,",
    "start": "1984530",
    "end": "1993120"
  },
  {
    "text": "but a larger false positive rate than G_2. And those two classifiers are incomparable.",
    "start": "1993120",
    "end": "2001550"
  },
  {
    "text": "Choosing between them is up to you, the designer of the system.",
    "start": "2001550",
    "end": "2007655"
  },
  {
    "text": "You may be more interested in keeping the false negative rate small. If you're more interested keeping",
    "start": "2007655",
    "end": "2013670"
  },
  {
    "text": "the false negative- negative rate small, then you should choose G_1. If you're more interested keeping the false positive rate small,",
    "start": "2013670",
    "end": "2020495"
  },
  {
    "text": "then you should choose G_2. If you have G_2 available,",
    "start": "2020495",
    "end": "2027995"
  },
  {
    "text": "then you should never choose G_3.",
    "start": "2027995",
    "end": "2030809"
  },
  {
    "start": "2034000",
    "end": "2177000"
  },
  {
    "text": "So when you look at a classifier on this plot,",
    "start": "2035170",
    "end": "2041420"
  },
  {
    "text": "the important classifiers, uh, one, where are- are those for which there is nothing",
    "start": "2041420",
    "end": "2048378"
  },
  {
    "text": "better in both false positive and false negative. So if I look at a particular classifier and say let's look at G_2,",
    "start": "2048379",
    "end": "2057710"
  },
  {
    "text": "and then if I draw here the region of the plane",
    "start": "2057710",
    "end": "2063095"
  },
  {
    "text": "consisting of values for the false positive and the false negative rate,",
    "start": "2063095",
    "end": "2069349"
  },
  {
    "text": "which are better than those achieved by G_2, if there's no classifier in that region,",
    "start": "2069350",
    "end": "2075770"
  },
  {
    "text": "then it's a good classifier. Conversely, if I look at G_3 and I look at the region consisting of better performance,",
    "start": "2075770",
    "end": "2087365"
  },
  {
    "text": "well, there are classifiers in that region. So G_3 is a bad classifier.",
    "start": "2087365",
    "end": "2094953"
  },
  {
    "text": "Now the good classifiers have a name. They're called Pareto optimal.",
    "start": "2094954",
    "end": "2100580"
  },
  {
    "text": "They`re good because no other classifier is better in both false positive and false negative rates.",
    "start": "2100580",
    "end": "2107940"
  },
  {
    "text": "The set of all of these Pareto optimal classifier, so the Pareto optimal classifiers are these red points.",
    "start": "2108100",
    "end": "2115140"
  },
  {
    "text": "So the set of all Pareto optimal points is called the operating characteristic, or the ROC.",
    "start": "2121990",
    "end": "2128900"
  },
  {
    "text": "ROC stands for receiver operating characteristic. This is a term that goes back to the design of radar systems in World War II.",
    "start": "2128900",
    "end": "2137930"
  },
  {
    "text": "And almost nobody calls it the receiver operating characteristic anymore. Almost always it's just referred to as the ROC.",
    "start": "2137930",
    "end": "2145110"
  },
  {
    "text": "And so what we commonly do, is we develop many different classifiers and we plot them on this plot,",
    "start": "2145120",
    "end": "2153680"
  },
  {
    "text": "we rule out the ones which are bad, which are not Pareto.",
    "start": "2153680",
    "end": "2158704"
  },
  {
    "text": "And then out of the ones that are Pareto, we get to make our choice.",
    "start": "2158705",
    "end": "2163530"
  },
  {
    "text": "Now when we've got the Neyman-Pearson measure,",
    "start": "2170400",
    "end": "2176650"
  },
  {
    "text": "that's Kappa times the false negative rate plus the false positive rate.",
    "start": "2176650",
    "end": "2182305"
  },
  {
    "start": "2177000",
    "end": "2448000"
  },
  {
    "text": "Well, what that's doing is it's measuring performance in a particular direction in this plane.",
    "start": "2182305",
    "end": "2189369"
  },
  {
    "text": "And so when I think about this, I'll call- uh, I've got the false negative rate and the false positive rate.",
    "start": "2189370",
    "end": "2198190"
  },
  {
    "text": "And I can- if I've got a particular Kappa, I can draw a vector.",
    "start": "2198190",
    "end": "2203290"
  },
  {
    "text": "There's a vector, and that vector is in the direction [NOISE]",
    "start": "2203290",
    "end": "2218080"
  },
  {
    "text": "Kappa 1. And so I can think about my false- my Neyman-Pearson metric as Kappa 1 transpose,",
    "start": "2218080",
    "end": "2231204"
  },
  {
    "text": "uh, C_fn on n, C_fp on n. Now because we're using the vector Kappa 1,",
    "start": "2231205",
    "end": "2242425"
  },
  {
    "text": "multiplied by the vector of coordinates in this plane,",
    "start": "2242425",
    "end": "2248875"
  },
  {
    "text": "what that measures is it measures the distance from the origin in the direction Kappa 1.",
    "start": "2248875",
    "end": "2257095"
  },
  {
    "text": "And so, if we look at the set of all points which are- for which",
    "start": "2257095",
    "end": "2264010"
  },
  {
    "text": "Kappa 1 transpose multiplied by the coordinates of that point is equal to say,",
    "start": "2264010",
    "end": "2272635"
  },
  {
    "text": "1, that would be a line here.",
    "start": "2272635",
    "end": "2281815"
  },
  {
    "text": "And then if we look at the set of all points for which that linear combination Kappa 1 transpose multiplied by the coordinates is equal to 2,",
    "start": "2281815",
    "end": "2290589"
  },
  {
    "text": "it would be a different line, and so on. And so by minimizing Kappa times the false-negative rate plus the false positive rate,",
    "start": "2290590",
    "end": "2302755"
  },
  {
    "text": "we are trying to pick the point that is on the line of these lines,",
    "start": "2302755",
    "end": "2313660"
  },
  {
    "text": "which is closest to the origin. In this particular case,",
    "start": "2313660",
    "end": "2319405"
  },
  {
    "text": "the point is G_2 for this particular value of Kappa shown here.",
    "start": "2319405",
    "end": "2325690"
  },
  {
    "text": "And these lines have a slope of minus K, minus Kappa.",
    "start": "2325690",
    "end": "2330700"
  },
  {
    "text": "And so by varying Kappa between 0 and infinity, we have slopes.",
    "start": "2330700",
    "end": "2339970"
  },
  {
    "text": "When Kappa is 0, we have uh- uh- a vector pointing in this direction,",
    "start": "2339970",
    "end": "2351190"
  },
  {
    "text": "and when Kappa is very large, we have a vector pointing in this direction.",
    "start": "2351190",
    "end": "2357380"
  },
  {
    "text": "So we can pick Kappa, uh, according to our preference.",
    "start": "2358320",
    "end": "2364570"
  },
  {
    "text": "If we make Kappa very large, then we're going to try and minimize.",
    "start": "2364570",
    "end": "2370990"
  },
  {
    "text": "We're going to try- we're going to have  slope lines that are like this. And we're going to try- we're going to be concerned about performance,",
    "start": "2370990",
    "end": "2381430"
  },
  {
    "text": "where the best thing one can do in order",
    "start": "2381430",
    "end": "2387190"
  },
  {
    "text": "to make the performance measure small is to choose",
    "start": "2387190",
    "end": "2395515"
  },
  {
    "text": "a predictor that has a low false negative rate. If instead,",
    "start": "2395515",
    "end": "2403220"
  },
  {
    "text": "we use a Kappa which is very small, well, then Kappa 1 looks a vector like this,",
    "start": "2407340",
    "end": "2418810"
  },
  {
    "text": "and we're going to have corresponding lines in- in this direction.",
    "start": "2418810",
    "end": "2428440"
  },
  {
    "text": "And the best thing we can do to make that performance metrics small is to pick",
    "start": "2428440",
    "end": "2433615"
  },
  {
    "text": "a predictor for which the false positive rate is small.",
    "start": "2433615",
    "end": "2440150"
  },
  {
    "start": "2448000",
    "end": "2885000"
  },
  {
    "text": "Here's an example. Um, here we have,",
    "start": "2448440",
    "end": "2453790"
  },
  {
    "text": "uh, the same dataset that we showed before. We have blue points and red points.",
    "start": "2453790",
    "end": "2459025"
  },
  {
    "text": "The red points are minus 1, and the blue points have target variable 1.",
    "start": "2459025",
    "end": "2465805"
  },
  {
    "text": "We can see there are some false negatives. The false negatives are blue points for which the classifier would predict red,",
    "start": "2465805",
    "end": "2475900"
  },
  {
    "text": "so where is the false negative?",
    "start": "2475900",
    "end": "2480529"
  },
  {
    "text": "There's one false negative right in there. Underneath there, there was a blue dot which I will now make visible. There it is.",
    "start": "2481230",
    "end": "2492980"
  },
  {
    "text": "So this blue dot there is in the red region.",
    "start": "2493430",
    "end": "2499244"
  },
  {
    "text": "It's in the region which our classifier will predict red. That's a false negative. And then there are many false positives, right?",
    "start": "2499245",
    "end": "2507865"
  },
  {
    "text": "All of these red dots are points which we would predict- predict as blue,",
    "start": "2507865",
    "end": "2513670"
  },
  {
    "text": "we'd give a positive prediction, but it's a false positive. If you count the number of red dots the false- in the blue region,",
    "start": "2513670",
    "end": "2522655"
  },
  {
    "text": "that for classifier number 1, that turns out to be 16.",
    "start": "2522655",
    "end": "2527860"
  },
  {
    "text": "And we've already seen that there's one blue dot in the red region.",
    "start": "2527860",
    "end": "2533995"
  },
  {
    "text": "And so this here is our false negative,",
    "start": "2533995",
    "end": "2540054"
  },
  {
    "text": "this here is our 16 false positives, this is our- is our correct predictions of minus 1.",
    "start": "2540054",
    "end": "2549415"
  },
  {
    "text": "So these are red dots in the red region, and there were 24 such red dots. And these are blue dots in the blue region,",
    "start": "2549415",
    "end": "2558040"
  },
  {
    "text": "and there are 59 such blue dots. Now if we- on this particular test,",
    "start": "2558040",
    "end": "2565240"
  },
  {
    "text": "uh, on this particular example, there are 100 points. And so, uh, the false negative rate is,",
    "start": "2565240",
    "end": "2575484"
  },
  {
    "text": "uh, 0.01 and the false positive rate is 0.16.",
    "start": "2575484",
    "end": "2582109"
  },
  {
    "text": "And we can plot those. Um, false negative rate is 0.01,",
    "start": "2585750",
    "end": "2591160"
  },
  {
    "text": "false positive rate is 0.16. Well, there's 0.01, there's is 0.16.",
    "start": "2591160",
    "end": "2599185"
  },
  {
    "text": "That's predictor 1, right there. We can look at predictor 2,",
    "start": "2599185",
    "end": "2605560"
  },
  {
    "text": "this is a different predictor. You can say it's got different regions. And, uh, this predictor is, uh, encompassed more.",
    "start": "2605560",
    "end": "2614605"
  },
  {
    "text": "So when you look at these- these setup dataset, these two data points, you can see that it's largely- uh,",
    "start": "2614605",
    "end": "2624850"
  },
  {
    "text": "let me erase that. It largely consists of blue points going",
    "start": "2624850",
    "end": "2633550"
  },
  {
    "text": "across the middle here and red points going this way.",
    "start": "2633550",
    "end": "2638950"
  },
  {
    "text": "And so our predictor here is focused on getting the blue points covered by blue region.",
    "start": "2638950",
    "end": "2647905"
  },
  {
    "text": "And unfortunately, it's going to have some red points covered as well.",
    "start": "2647905",
    "end": "2655195"
  },
  {
    "text": "And that's why it's got a large number of false positives because the- uh,",
    "start": "2655195",
    "end": "2663355"
  },
  {
    "text": "the red points have been classified as blue. Here we've said, well,",
    "start": "2663355",
    "end": "2668800"
  },
  {
    "text": "we don't want that anymore. We would like to balance the- um,",
    "start": "2668800",
    "end": "2673670"
  },
  {
    "text": "the- um, red and blue arrows. And so, we've got a predictor that is classifying more of the red points",
    "start": "2674280",
    "end": "2685840"
  },
  {
    "text": "as actually red. More of the region in which the red points are, it has a closer corresponding prediction of red.",
    "start": "2685840",
    "end": "2695470"
  },
  {
    "text": "As a result, we can look here and we can see, well, now there are eight false negatives.",
    "start": "2695470",
    "end": "2703250"
  },
  {
    "text": "There's one, um, but there's only eight false positives, here's one.",
    "start": "2703740",
    "end": "2712430"
  },
  {
    "text": "And that gives us, uh, corresponding false positive and false negative rates of 0.08, which is right there.",
    "start": "2713220",
    "end": "2722210"
  },
  {
    "text": "Here's a- uh, plot number 3 is a classifier at the other extreme.",
    "start": "2723870",
    "end": "2729534"
  },
  {
    "text": "Here, we've tried to focus on getting the red points correct.",
    "start": "2729534",
    "end": "2735025"
  },
  {
    "text": "And in exchange, we're getting some of the blue points wrong. What does that mean in terms of false positives and false negatives?",
    "start": "2735025",
    "end": "2743020"
  },
  {
    "text": "It means that we've got very few false positives and a large number of false negatives.",
    "start": "2743020",
    "end": "2748900"
  },
  {
    "text": "Um, our false positives are red points that are classified as blue and there are two of them.",
    "start": "2748900",
    "end": "2758305"
  },
  {
    "text": "Here is one of them. Um, and we've got a large number of blue points that are classified as red. There's one of them.",
    "start": "2758305",
    "end": "2767185"
  },
  {
    "text": "Our resulting, uh, counts, uh, there are 23 false negatives and two false positives.",
    "start": "2767185",
    "end": "2778890"
  },
  {
    "text": "And that gives us this classifier right there. So there are three classifiers, um,",
    "start": "2778890",
    "end": "2787350"
  },
  {
    "text": "and which one you pick out of those three, that's up to you.",
    "start": "2787350",
    "end": "2793065"
  },
  {
    "text": "I think there is no way of choosing between these three classifiers.",
    "start": "2793065",
    "end": "2799599"
  },
  {
    "text": "Number 2 beats number 3 in false negative rate.",
    "start": "2799600",
    "end": "2805795"
  },
  {
    "text": "But does worse in false positive rate. Number 1 beats number 2 in the same way.",
    "start": "2805795",
    "end": "2812140"
  },
  {
    "text": "Um, and neither one of them- we would say neither one of them dominates the other.",
    "start": "2812140",
    "end": "2822400"
  },
  {
    "text": "And so this is a design question. It depends on the particular problem that you're looking at,",
    "start": "2822400",
    "end": "2830590"
  },
  {
    "text": "whether you're interested in a classifier that has smallest overall error rate.",
    "start": "2830590",
    "end": "2835915"
  },
  {
    "text": "Let's look at what the overall error rates are. So this one has an error rate of 17,",
    "start": "2835915",
    "end": "2841810"
  },
  {
    "text": "this one has an error rate of 16, and this one has an error rate of 25.",
    "start": "2841810",
    "end": "2847960"
  },
  {
    "text": "And those of course error counts, error rates up 0.17, 0.16 and 0.25.",
    "start": "2847960",
    "end": "2854395"
  },
  {
    "text": "So the one with the smallest error rate is number 2.",
    "start": "2854395",
    "end": "2859790"
  },
  {
    "text": "The one with the smallest number of false negatives is number 1,",
    "start": "2860400",
    "end": "2866724"
  },
  {
    "text": "and the number- one with the smallest number of false positives is number 3.",
    "start": "2866725",
    "end": "2871220"
  },
  {
    "text": "And when you look at multiclass classification, well, there are no longer just four possible values for v-hat and v,",
    "start": "2881460",
    "end": "2892089"
  },
  {
    "start": "2885000",
    "end": "3353000"
  },
  {
    "text": "there are K squared possible values because there are K classes,",
    "start": "2892090",
    "end": "2898150"
  },
  {
    "text": "v_1 through v_K, and, uh,",
    "start": "2898150",
    "end": "2903579"
  },
  {
    "text": "and each of v-hat and v can be in any one of those classes.",
    "start": "2903580",
    "end": "2909490"
  },
  {
    "text": "So K squared possible outcome pairs. Um, when we say v-hat is v_i and v is v_j,",
    "start": "2909490",
    "end": "2917530"
  },
  {
    "text": "it means the true value is v_j and we're predicting v_i.",
    "start": "2917530",
    "end": "2922870"
  },
  {
    "text": "So the only ones that are correct are when v_i is v_j,",
    "start": "2922870",
    "end": "2929125"
  },
  {
    "text": "and it's incorrect when v_i is not v_j. In other words, if v-hat is v, that's correct,",
    "start": "2929125",
    "end": "2934839"
  },
  {
    "text": "and if v-hat is not v, that's incorrect. So there are K different ways in which we can make the same- make a correct prediction.",
    "start": "2934840",
    "end": "2944545"
  },
  {
    "text": "If, uh, we predict v_1 and the truth is v_1, that's correct, if we predict v_2 and the truth is v_2, that's also correct.",
    "start": "2944545",
    "end": "2951325"
  },
  {
    "text": "Um, but there's also a bunch of different errors.",
    "start": "2951325",
    "end": "2956935"
  },
  {
    "text": "If we predict v_1 but the truth is v_2, well, then, uh, that's an error.",
    "start": "2956935",
    "end": "2964210"
  },
  {
    "text": "But there's a different error where the truth is v_2 and we predicted v_3.",
    "start": "2964210",
    "end": "2969625"
  },
  {
    "text": "So there are K times K minus 1 types of errors, one for each possible pair where i is not equal to j.",
    "start": "2969625",
    "end": "2978200"
  },
  {
    "text": "So we have a K by K confusion matrix. And the ijth entry of the mat- confusion matrix C is the number",
    "start": "2982260",
    "end": "2992800"
  },
  {
    "text": "of data records where we guessed- we predicted v-hat was v_i,",
    "start": "2992800",
    "end": "2998710"
  },
  {
    "text": "but actually the true v was v_j. Um, uh, and you should be aware that sometimes,",
    "start": "2998710",
    "end": "3005535"
  },
  {
    "text": "uh, people transpose this, so they swap i and j, and,",
    "start": "3005535",
    "end": "3011640"
  },
  {
    "text": "uh, uh, of course, that's just a- a convention.",
    "start": "3011640",
    "end": "3016830"
  },
  {
    "text": "Um, of course, the entries in C add up to n number of data points. The column sums give the number of records in each class.",
    "start": "3016830",
    "end": "3026550"
  },
  {
    "text": "Um, C_ii is the number of times we predicted v_i correctly.",
    "start": "3026550",
    "end": "3034725"
  },
  {
    "text": "If i is not j, then C_ij is the number of times we mistook v_j for v_i.",
    "start": "3034725",
    "end": "3042100"
  },
  {
    "text": "Now these quantities C_ij, where i is not equal to j,",
    "start": "3043100",
    "end": "3048359"
  },
  {
    "text": "if we normalize them by the number of records n, that's called the error rate for those particular pair of classes.",
    "start": "3048360",
    "end": "3056025"
  },
  {
    "text": "E_ij is the number- is the fraction of the data points on which we mistake v_j for v_i,",
    "start": "3056025",
    "end": "3066819"
  },
  {
    "text": "and the overall error rate is the sum of all of the different error rates.",
    "start": "3066860",
    "end": "3073180"
  },
  {
    "text": "So here's an example. Here we've shown data points, uh,",
    "start": "3075410",
    "end": "3081240"
  },
  {
    "text": "which have target value; 1 is red, 2 is green, and 3 is blue. And we've got a classifier that- that",
    "start": "3081240",
    "end": "3088950"
  },
  {
    "text": "classifies points in the plane as either red, green, or blue.",
    "start": "3088950",
    "end": "3094275"
  },
  {
    "text": "And you can see that it's doing okay, uh, the, uh, green region mostly contains green points,",
    "start": "3094275",
    "end": "3101670"
  },
  {
    "text": "the blue region mostly contains blue points, and the red region mostly contains red points. There are a few, uh,",
    "start": "3101670",
    "end": "3108240"
  },
  {
    "text": "cases where we have green points but they would be predicted as red.",
    "start": "3108240",
    "end": "3113910"
  },
  {
    "text": "Here's 1, 2, 3, 4, 5.",
    "start": "3113910",
    "end": "3120464"
  },
  {
    "text": "So there's green points that we would predict as red, and there's a blue point that we would predict as red as well.",
    "start": "3120465",
    "end": "3127740"
  },
  {
    "text": "That's this one right here. And so there's one of that type of error as well.",
    "start": "3127740",
    "end": "3133335"
  },
  {
    "text": "Um, what other types of error are there? There's a red point that we are predicting as green.",
    "start": "3133335",
    "end": "3142450"
  },
  {
    "text": "There, that's this error. And there's a green point that we're predicting as blue.",
    "start": "3142970",
    "end": "3150870"
  },
  {
    "text": "That's this point right there, and that's this error. All the other points are correctly classified.",
    "start": "3150870",
    "end": "3158460"
  },
  {
    "text": "We've got 39 reds that we're classifying as red, 34 greens that we're classifying as green,",
    "start": "3158460",
    "end": "3165930"
  },
  {
    "text": "and 17 blues that we're classifying as blue. Now to take the error rates, well, there are 100 points,",
    "start": "3165930",
    "end": "3171930"
  },
  {
    "text": "so I simply take all the non-diagonal or the off-diagonal entries of the confusion matrix divide them by 100 and that gives me the error rate matrix there.",
    "start": "3171930",
    "end": "3182654"
  },
  {
    "text": "And if I sum up all of these different errors, I'll find this 10% error rate.",
    "start": "3182655",
    "end": "3188769"
  },
  {
    "text": "Now, just as in the Boolean case when we want to,",
    "start": "3193220",
    "end": "3202410"
  },
  {
    "text": "uh, pick a classifier, it's very often convenient to have one number that measures that is our performance metric.",
    "start": "3202410",
    "end": "3211140"
  },
  {
    "text": "And the way we would do that is we would use our weighted sum of the different types of errors.",
    "start": "3211140",
    "end": "3217245"
  },
  {
    "text": "Now you could attach a- a weight to all of the different cat- categories of errors. So in our, uh, three class example,",
    "start": "3217245",
    "end": "3227775"
  },
  {
    "text": "there are six possible types of errors. And so you can have six different Kappa values and use",
    "start": "3227775",
    "end": "3235740"
  },
  {
    "text": "those six different Kappa values to weight the different errors.",
    "start": "3235740",
    "end": "3241515"
  },
  {
    "text": "And that would be a perfectly fine, um, performance measure.",
    "start": "3241515",
    "end": "3246885"
  },
  {
    "text": "In fact, we don't do that. What- instead, we tend to do is we tend to,",
    "start": "3246885",
    "end": "3253410"
  },
  {
    "text": "uh, use a Kappa value, which is only defined per column, per true class.",
    "start": "3253410",
    "end": "3262815"
  },
  {
    "text": "And so we'll have one weight which is associated with these two errors,",
    "start": "3262815",
    "end": "3269415"
  },
  {
    "text": "one weight associated with these two errors, and one weight associated with those two errors in the last column.",
    "start": "3269415",
    "end": "3278680"
  },
  {
    "text": "And so associated with each column, there is the error rate,",
    "start": "3279620",
    "end": "3284640"
  },
  {
    "text": "which is- we've denoted by E_j. It's the number of times we mistook v_j for some other class.",
    "start": "3284640",
    "end": "3291240"
  },
  {
    "text": "And we could divide by n and get the error rate as well as the error count.",
    "start": "3291240",
    "end": "3296640"
  },
  {
    "text": "And then we take a weighted sum of these three error rates.",
    "start": "3296640",
    "end": "3302505"
  },
  {
    "text": "And that's the Neyman-Pearson error. So Kappa j is then how much we care about mistaking v_j for something else.",
    "start": "3302505",
    "end": "3312450"
  },
  {
    "text": "And if Kappa j is 1 for all of the different i's, then the Neyman-Pearson error is the error rate;",
    "start": "3312450",
    "end": "3321150"
  },
  {
    "text": "we're just summing up all the different errors. So to summarize, in this section,",
    "start": "3321150",
    "end": "3327150"
  },
  {
    "text": "we've talked about how you measure the performance of classifiers, both for Boolean classifiers and for multiclass classifiers.",
    "start": "3327150",
    "end": "3336045"
  },
  {
    "text": "We haven't yet talked about how you find classifiers.",
    "start": "3336045",
    "end": "3341430"
  },
  {
    "text": "And, uh, uh, that's coming in the next section.",
    "start": "3341430",
    "end": "3346510"
  }
]
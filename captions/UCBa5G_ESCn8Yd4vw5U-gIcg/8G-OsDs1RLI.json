[
  {
    "start": "0",
    "end": "5350"
  },
  {
    "text": "Today, we're going to start\ntalking about score-based models or diffusion models,\nand we're going",
    "start": "5350",
    "end": "12850"
  },
  {
    "text": "to see that, which is kind\nof like a state of the art class of generative models for\nimages, video, speech, audio,",
    "start": "12850",
    "end": "21040"
  },
  {
    "text": "a lot of different\ncontinuous data modalities, this is the way to go. And we'll see it's\ngoing to build",
    "start": "21040",
    "end": "27190"
  },
  {
    "text": "on some of the techniques\nwe talked about in the last lecture.",
    "start": "27190",
    "end": "33100"
  },
  {
    "text": "So first of all,\nusual picture here, kind of like the\noverview of what we're",
    "start": "33100",
    "end": "42129"
  },
  {
    "text": "talking about in this class. We've talked a lot about\ndifferent kinds of model families, and we've\nseen two main classes",
    "start": "42130",
    "end": "51040"
  },
  {
    "text": "of generative models. We've seen likelihood-based\nmodels, where, basically,",
    "start": "51040",
    "end": "56949"
  },
  {
    "text": "the key object you're working\nwith is the probability density or the\nprobability mass function.",
    "start": "56950",
    "end": "62440"
  },
  {
    "text": "So the model is\nbasically just a function that takes as input\nsome x and maps it",
    "start": "62440",
    "end": "67690"
  },
  {
    "text": "to some scalar, which\nis how likely is that x according to the model. And we've seen that probability\nmass functions or probability",
    "start": "67690",
    "end": "75340"
  },
  {
    "text": "density functions are\ntricky to model because they have to be normalized. They have to integrate to 1.",
    "start": "75340",
    "end": "81649"
  },
  {
    "text": "So we've seen that one\nway to get there is to use autoregressive models. Another way to get there\nis use flow models,",
    "start": "81650",
    "end": "87580"
  },
  {
    "text": "but that's always constraints\nthe kind of architectures you can use. And the alternative\nway to go around it",
    "start": "87580",
    "end": "98140"
  },
  {
    "text": "is to, well, give up in some\nsense on the normalization and use variational tricks\nto essentially evaluate",
    "start": "98140",
    "end": "106030"
  },
  {
    "text": "the likelihood. So we've seen\nvariational autoencoders. And we've seen\nenergy-based models",
    "start": "106030",
    "end": "111280"
  },
  {
    "text": "where you have to deal with\nthis normalization constant that normalizes the\nprobability density.",
    "start": "111280",
    "end": "117170"
  },
  {
    "text": "And we've talked about\na bunch of techniques to try to get around\nthe fact that you",
    "start": "117170",
    "end": "123250"
  },
  {
    "text": "have to evaluate Z\ntheta and maybe avoid likelihood-based training\nand various ways of training",
    "start": "123250",
    "end": "129289"
  },
  {
    "text": "energy-based models. And then the pros\nhere is that you",
    "start": "129289",
    "end": "134302"
  },
  {
    "text": "can do maximum likelihood\ntraining, which is principal is great. It's a lot that you can monitor. You can see how well it goes.",
    "start": "134302",
    "end": "141020"
  },
  {
    "text": "It's optimal in a certain sense. You can compare\nmodels, but you have",
    "start": "141020",
    "end": "146720"
  },
  {
    "text": "to deal with the\nrestricted architectures. You can't plug in an\narbitrary neural network to model the likelihood.",
    "start": "146720",
    "end": "153890"
  },
  {
    "text": "The alternative way\nto go about this is to just model the\nsampling process. So this is kind of like an\nimplicit generative model,",
    "start": "153890",
    "end": "160130"
  },
  {
    "text": "again, where we're\njust going to describe the way you produce samples. For example, you feed random\nnoise through a neural network.",
    "start": "160130",
    "end": "168620"
  },
  {
    "text": "Essentially, any neural network\nyou can pick as the generator defines a valid\nsampling procedure.",
    "start": "168620",
    "end": "175130"
  },
  {
    "text": "The problem is that given\na sample, given an output from this network, evaluating\nhow likely the model is",
    "start": "175130",
    "end": "181010"
  },
  {
    "text": "to generate that is very hard. And so you have to give\nup on likelihoods again.",
    "start": "181010",
    "end": "187020"
  },
  {
    "text": "And although these models\ntend to work pretty well, the key problem is that\nyou can't train them",
    "start": "187020",
    "end": "193700"
  },
  {
    "text": "in a very stable way. You have to do\nminimax optimization, and that's a problem.",
    "start": "193700",
    "end": "199010"
  },
  {
    "text": "And so what we're going\nto talk about today is a different way of representing\nprobability distributions,",
    "start": "199010",
    "end": "206120"
  },
  {
    "text": "probability densities\nthat deals with the score. That's what these\nmodels are going to be.",
    "start": "206120",
    "end": "211590"
  },
  {
    "text": "They're going to-- they're\ncalled score-based generative models. And this is only going to\nbe applicable to probability",
    "start": "211590",
    "end": "219230"
  },
  {
    "text": "density functions. So continuous random variables. But when we're dealing with\ncontinuous random variables,",
    "start": "219230",
    "end": "226010"
  },
  {
    "text": "then we can start\nthinking about working with the gradient\nof the log density",
    "start": "226010",
    "end": "233150"
  },
  {
    "text": "instead of working with\nthe density itself. So we've seen that in a\nlikelihood-based model.",
    "start": "233150",
    "end": "239780"
  },
  {
    "text": "You would normally\nwork with p of x. And score-based model instead,\nthe object that you work with",
    "start": "239780",
    "end": "246560"
  },
  {
    "text": "is the gradient of\nthe log density. And the gradient, again, is\nwith respect to the inputs. So it's not with respect to\nthe parameters of your model.",
    "start": "246560",
    "end": "256310"
  },
  {
    "text": "And that's the score function. And we've seen this in\nthe previous lecture,",
    "start": "256310",
    "end": "261470"
  },
  {
    "text": "but the idea is\nthat it provides you an alternative interpretation\nof the probability density",
    "start": "261470",
    "end": "268580"
  },
  {
    "text": "function. You can alternatively\nthink of the PDF as a function that maps every\npoint to a scalar, which",
    "start": "268580",
    "end": "275900"
  },
  {
    "text": "is non-negative. So you can think of it as the\nheight of some kind of surface over this 2D space.",
    "start": "275900",
    "end": "281670"
  },
  {
    "text": "In this case, it's a\nmixture of two Gaussians. And the score is just\na function that is",
    "start": "281670",
    "end": "286850"
  },
  {
    "text": "vector valued at every point. It gives you the gradient\nof the log density. And so it's vector field, where\nat every point, you get the--",
    "start": "286850",
    "end": "296070"
  },
  {
    "text": "the arrow is telling you what's\nthe direction that you should follow if you want to increase\nthe log likelihood most rapidly.",
    "start": "296070",
    "end": "303660"
  },
  {
    "text": "And these two are sort\nof like equivalent views. So if you like, again,\nanalogies with physics, this",
    "start": "303660",
    "end": "309319"
  },
  {
    "text": "is kind of like describing\na physical system in terms of electric potentials\nor electric fields that",
    "start": "309320",
    "end": "315290"
  },
  {
    "text": "are kind of like the same. But computationally, it might\nbe advantageous, as we'll see,",
    "start": "315290",
    "end": "321290"
  },
  {
    "text": "to work with one\nversus the other. And in particular,\nthe main challenge",
    "start": "321290",
    "end": "330060"
  },
  {
    "text": "that we talked a lot\nabout in this course when modeling probability\ndensity functions is",
    "start": "330060",
    "end": "335550"
  },
  {
    "text": "that you have to make sure\nthat these PDFs are normalized. So you need to figure out a\nway of parameterizing curves",
    "start": "335550",
    "end": "342450"
  },
  {
    "text": "that are ideally flexible. And since they can have\narbitrary shapes as you change--",
    "start": "342450",
    "end": "348090"
  },
  {
    "text": "or as complicated as\npossible of a shape as you can get by\nchanging the parameters",
    "start": "348090",
    "end": "353520"
  },
  {
    "text": "of your neural network. But somehow you\nneed to make sure that the total area\nunder the curve is fixed.",
    "start": "353520",
    "end": "359500"
  },
  {
    "text": "It's equal to 1. So you have a normalized object\nor some way of somehow computing the area under the curve for\nany choice of the parameters.",
    "start": "359500",
    "end": "368620"
  },
  {
    "text": "And that's potentially\ntricky, as we've seen. Often what it means\nis that you have",
    "start": "368620",
    "end": "374040"
  },
  {
    "text": "to choose very specific\narchitectures that allow you to basically\neither guarantee",
    "start": "374040",
    "end": "379440"
  },
  {
    "text": "that the area under the\ncurve is 1 or somehow in a normalizing flow that you\ncan compute it efficiently.",
    "start": "379440",
    "end": "387340"
  },
  {
    "text": "And now if you think about\nthe score in the one decays,",
    "start": "387340",
    "end": "392380"
  },
  {
    "text": "the score is just a--\nthis is the gradient. It's [? that, ?] the\nderivative of the function you see of the log of the\nfunction you see on the left.",
    "start": "392380",
    "end": "400270"
  },
  {
    "text": "And the function on\nthe right no longer needs to satisfy any kind\nof normalization constraint.",
    "start": "400270",
    "end": "408990"
  },
  {
    "text": "And it's potentially much\nsimpler to work with. You see here, you have this\nrelatively complicated curve",
    "start": "408990",
    "end": "415440"
  },
  {
    "text": "on the left, and the\ncorresponding score function on the right is potentially\nmuch easier to work with.",
    "start": "415440",
    "end": "423040"
  },
  {
    "text": "So the intuition behind\na score-based model is that instead of modeling\ndata using the density,",
    "start": "423040",
    "end": "428520"
  },
  {
    "text": "we're going to model\ndata using the score. So that's going to be\nthe object that we're going to use to define\nour model family.",
    "start": "428520",
    "end": "436580"
  },
  {
    "text": " And we've seen that this\nis useful in the context",
    "start": "436580",
    "end": "444580"
  },
  {
    "text": "of energy-based models. Energy-based models\nare one way of defining very flexible probability\ndensity functions by saying, OK,",
    "start": "444580",
    "end": "453250"
  },
  {
    "text": "I'm going to pick an\narbitrary neural network. I'm going to make\nit non-negative. And then I'm going to\nrenormalize by somehow computing",
    "start": "453250",
    "end": "461080"
  },
  {
    "text": "the total area under the curve\nand then dividing by the number to get a valid probability\ndensity function.",
    "start": "461080",
    "end": "467270"
  },
  {
    "text": "Super flexible. The problem is that if you want\nto do evaluating likelihoods,",
    "start": "467270",
    "end": "473020"
  },
  {
    "text": "involve the log\npartition function. So if you want to do\nmaximum likelihood training, you have to go through either\nsomehow estimate a partition",
    "start": "473020",
    "end": "480460"
  },
  {
    "text": "function, or you need to\ndo contrastive divergence things, where you have to\nsample from the model, which",
    "start": "480460",
    "end": "486310"
  },
  {
    "text": "is expensive. On the other hand-- which is something\nyou don't want to do. On the other hand,\nwhat we're seeing",
    "start": "486310",
    "end": "493180"
  },
  {
    "text": "is that we can train\nenergy-based models by instead of trying to match, basically,\nthe density ratios using",
    "start": "493180",
    "end": "502790"
  },
  {
    "text": "KL divergences, we can try\nto fit our energy-based model by trying to make sure that\nthe corresponding vector",
    "start": "502790",
    "end": "511040"
  },
  {
    "text": "field of gradients-- so\nthe scores of the model match the scores of\nthe data distribution.",
    "start": "511040",
    "end": "518672"
  },
  {
    "text": "And recall that this was\nbasically the Fisher divergence.",
    "start": "518673",
    "end": "524949"
  },
  {
    "text": "And we were able to do--\nthrough integration by parts, we were able to rewrite\nthis objective function",
    "start": "524950",
    "end": "530520"
  },
  {
    "text": "into 1 that basically only\ninvolves the score, which,",
    "start": "530520",
    "end": "536740"
  },
  {
    "text": "as we've seen in\nthe last lecture, does not require you to\ncompute the partition function.",
    "start": "536740",
    "end": "542520"
  },
  {
    "text": "So the score here, the\ncritical thing to notice here is that the score function,\nthe gradient of the log density",
    "start": "542520",
    "end": "551760"
  },
  {
    "text": "according to the model, when\nyou take the log of an EBM, you get your neural network. And then you get the\nlog partition function.",
    "start": "551760",
    "end": "558850"
  },
  {
    "text": "Critically, the log partition\nfunction does not depend on x. It's the same for every point. It's just the area\nunder the curve.",
    "start": "558850",
    "end": "564448"
  },
  {
    "text": "No matter where you are,\nthe area under the curve is the same. And so when you take the\ngradient with respect to x,",
    "start": "564448",
    "end": "569580"
  },
  {
    "text": "that's 0. And so we can compute\nthis model score in terms of the original\nenergy of the model.",
    "start": "569580",
    "end": "578480"
  },
  {
    "text": "So in this expression here, we\ncan basically compute this term efficiently without having to\ndeal with the normalization",
    "start": "578480",
    "end": "586509"
  },
  {
    "text": "constant. And so we have this expression. If you want to do score matching\nfor an energy-based model,",
    "start": "586510",
    "end": "593800"
  },
  {
    "text": "you have that loss which you\ncan in principle optimize and try to minimize as\na function of theta.",
    "start": "593800",
    "end": "602780"
  },
  {
    "text": "And now you might\nwonder, I mean, can we only do score\nmatching for EBMs?",
    "start": "602780",
    "end": "608690"
  },
  {
    "text": "And if you think about\nit, you look at the loss.",
    "start": "608690",
    "end": "614100"
  },
  {
    "text": "It's something that is well\ndefined for any model family.",
    "start": "614100",
    "end": "620500"
  },
  {
    "text": "As long as you're\nable to compute this gradient with respect\nto x of the log density according to the model, then\nyou can do score matching.",
    "start": "620500",
    "end": "628630"
  },
  {
    "text": "And you can train a model\nby minimizing the Fisher divergence. So in particular, what\nother kind of model families",
    "start": "628630",
    "end": "636670"
  },
  {
    "text": "can we apply score matching to? Well, we can certainly apply\nit to continuous autoregressive",
    "start": "636670",
    "end": "642850"
  },
  {
    "text": "models. If you can compute\nthe log density, you can probably also\ndifferentiate through that",
    "start": "642850",
    "end": "648399"
  },
  {
    "text": "and compute the score. You can do it on a\nnormalizing flow models. Again, we can compute\nthe log likelihood.",
    "start": "648400",
    "end": "656140"
  },
  {
    "text": "And so we can also compute\nthe score, although perhaps it doesn't make a lot of sense\nbecause you have access",
    "start": "656140",
    "end": "661690"
  },
  {
    "text": "to the likelihood. So you might as well train these\nmodels by maximum likelihood. But in principle, you\ncould apply score matching",
    "start": "661690",
    "end": "668380"
  },
  {
    "text": "to these models, and you could\ntrain them that way as well. ",
    "start": "668380",
    "end": "673972"
  },
  {
    "text": "But you could also\nwonder, I mean, what's the most general\nmodel family that we can train using score matching?",
    "start": "673972",
    "end": "680730"
  },
  {
    "text": "And you can think that\nwhile you can certainly apply it to autoregressive\nmodels, to flow models,",
    "start": "680730",
    "end": "688810"
  },
  {
    "text": "you can think of EBMs as\nkind of like a generalization where autoregressive\nmodels and flow",
    "start": "688810",
    "end": "694540"
  },
  {
    "text": "models are special kinds of\nEBMs, where the partition function is\nguaranteed to be one.",
    "start": "694540",
    "end": "700870"
  },
  {
    "text": "But perhaps there is\nsomething even larger. Like, we can even optimize\nover an even broader set of model family.",
    "start": "700870",
    "end": "710560"
  },
  {
    "text": "And that's the idea behind\na score-based model. Instead of modeling the energy,\nwe're basically directly going",
    "start": "710560",
    "end": "718990"
  },
  {
    "text": "to model the score function. So we're going to define our\nmodel family by defining the--",
    "start": "718990",
    "end": "729550"
  },
  {
    "text": "by basically specifying\nthe corresponding vector field of gradients. So the model is not\ngoing to be a likelihood.",
    "start": "729550",
    "end": "737019"
  },
  {
    "text": "The model is not\ngoing to be an energy. The model is going to be a\nvector-valued function or a set",
    "start": "737020",
    "end": "742180"
  },
  {
    "text": "of vector-valued functions. As you change theta, as you\nchange your neural network, you're going to get\ndifferent vector fields.",
    "start": "742180",
    "end": "749140"
  },
  {
    "text": "And that's what we're going\nto use to describe basically the set of possible\ndistributions",
    "start": "749140",
    "end": "756520"
  },
  {
    "text": "that we are going to\nbe fitting to our data distribution in the usual way.",
    "start": "756520",
    "end": "764069"
  },
  {
    "text": "So basically the difference\nwith respect to an EBM is that we're not going to\nmodel necessarily the energy",
    "start": "764070",
    "end": "770770"
  },
  {
    "text": "and then take the\ngradient of it. Instead, we're going\nto directly think about different kinds of\nvector fields that we can get",
    "start": "770770",
    "end": "780069"
  },
  {
    "text": "and we can parameterize\nusing a neural network. In this case, the neural network\nis a vector-valued function.",
    "start": "780070",
    "end": "786760"
  },
  {
    "text": "For every x s theta, the\nestimated score at that point is a vector with the same number\nof dimensions as the input.",
    "start": "786760",
    "end": "795890"
  },
  {
    "text": "So as theta is really a\nfunction from Rd to Rd-- so if you have d dimensions, the\noutput of this neural network",
    "start": "795890",
    "end": "803740"
  },
  {
    "text": "will also have D dimensions\nbecause that's however many coordinates you need to\nspecify one of these arrows",
    "start": "803740",
    "end": "811600"
  },
  {
    "text": "at every point.  And so that's basically the\nvery high-level story here.",
    "start": "811600",
    "end": "823910"
  },
  {
    "text": "As usual, we want to fit\na model to a data density. So there is a true underlying\ndata density that is unknown.",
    "start": "823910",
    "end": "831580"
  },
  {
    "text": "We assume we have access to a\nbunch of samples from the data density. And then what we're\ngoing to try to do",
    "start": "831580",
    "end": "838250"
  },
  {
    "text": "is we're going to try to find\nsome function in our model",
    "start": "838250",
    "end": "845070"
  },
  {
    "text": "family. So we're going to try to\nchoose parameters theta. Or we're going to try to choose\nsome vector field of gradients",
    "start": "845070",
    "end": "852330"
  },
  {
    "text": "that is hopefully as close\nas possible to the vector field of gradients of the\noriginal data density.",
    "start": "852330",
    "end": "859610"
  },
  {
    "text": "So that's going to be\nthe learning objective. And try to choose\nparameters theta such",
    "start": "859610",
    "end": "865430"
  },
  {
    "text": "that the corresponding\nvector-valued function that we get matches the true\nvector field of gradients",
    "start": "865430",
    "end": "872450"
  },
  {
    "text": "of the data density. How can we make sure\nthe gradients calculated from the sparse samples as\nclose as to the underlying",
    "start": "872450",
    "end": "883010"
  },
  {
    "text": "distribution of our data? Yeah, so that's\na great question. The only thing we have\naccess to are samples,",
    "start": "883010",
    "end": "888950"
  },
  {
    "text": "and so we don't have\naccess to the true density. And so we're never going to be\nable to achieve this perfectly.",
    "start": "888950",
    "end": "894270"
  },
  {
    "text": "And there is a learning\nelement in the sense that we only have access\nto a bunch of samples.",
    "start": "894270",
    "end": "900010"
  },
  {
    "text": "And so we need to make\nsure we're not overfitting. And we need to make\nsure that there's",
    "start": "900010",
    "end": "906200"
  },
  {
    "text": "going to be some limits to\nhow well we can do this. But it's that you\nhave the same problem,",
    "start": "906200",
    "end": "911220"
  },
  {
    "text": "even if you have a-- if you're\ntraining by maximum likelihood, you're only given\nsamples, you can",
    "start": "911220",
    "end": "916310"
  },
  {
    "text": "try to get as close as\npossible to the empirical data distribution, hoping that\nby fitting the samples,",
    "start": "916310",
    "end": "924660"
  },
  {
    "text": "you're also fitting the true\nunderlying data density. So we're going to have the\nsame problem in the sense",
    "start": "924660",
    "end": "930779"
  },
  {
    "text": "that we only have samples. We have limited data. But the main difference\nis that instead",
    "start": "930780",
    "end": "936170"
  },
  {
    "text": "of trying to fit one of\nthese scalar function that is giving us\nthe likelihood,",
    "start": "936170",
    "end": "941480"
  },
  {
    "text": "we're going to try to fit this\nvector-valued function that is giving us the gradient of\nthe log likelihood, essentially.",
    "start": "941480",
    "end": "950660"
  },
  {
    "text": "Yeah. So building off that, but-- so for instance, over\nhere, we have two clusters.",
    "start": "950660",
    "end": "958790"
  },
  {
    "text": "But we want a model to\nbe able to predict even in the decision\nboundary of the score",
    "start": "958790",
    "end": "964820"
  },
  {
    "text": "and all these sorts of things. But isn't that too\nmuch of an OD problem?",
    "start": "964820",
    "end": "970670"
  },
  {
    "text": "I know you said that, OK,\neven when you're going for the likelihood, it's fine. But when you're going\nfor the likelihood,",
    "start": "970670",
    "end": "976160"
  },
  {
    "text": "you're sort of within\nreasonable range if you're trying to push\n[INAUDIBLE] close to the mod",
    "start": "976160",
    "end": "981800"
  },
  {
    "text": "that your samples are. Here, you're sort of learning\nlike, OK, I have some data here,",
    "start": "981800",
    "end": "987200"
  },
  {
    "text": "and I have no other\ndata and some valley. And yet, somehow\nexpected to learn some.",
    "start": "987200",
    "end": "993080"
  },
  {
    "text": "Yeah, so I think in both\ncases, it's a hard problem. I would say that even if\nyou work with likelihoods,",
    "start": "993080",
    "end": "1000197"
  },
  {
    "text": "you don't just want\nto put probability mass around the training\ndata because you want the model to generalize\nto unseen data",
    "start": "1000197",
    "end": "1009310"
  },
  {
    "text": "that it hopefully coming\nfrom the same distribution as the one you've\nused for training. But you don't want to just\nfit the training distribution.",
    "start": "1009310",
    "end": "1017710"
  },
  {
    "text": "If you're fitting a model\nover a training set of images, you don't just want to\nput probability mass",
    "start": "1017710",
    "end": "1024230"
  },
  {
    "text": "around the images that you\nhave in the training set. You want to spread it out. And you need to be\nable to say, oh, there",
    "start": "1024230",
    "end": "1029689"
  },
  {
    "text": "is other parts of\nthe space where I need to put probability\nmass, even though I have not seen them during training.",
    "start": "1029690",
    "end": "1035400"
  },
  {
    "text": "And so we have a\nsimilar problem. To some extent, kind of like\nthe gradient and the function",
    "start": "1035400",
    "end": "1041630"
  },
  {
    "text": "are essentially the same thing. So if you have the gradient,\nyou can integrate it, and you can get the function.",
    "start": "1041630",
    "end": "1047030"
  },
  {
    "text": "And because everything\nhas to be normalized-- so you know that the-- I mean, you can get the\nfunction up to a constant.",
    "start": "1047030",
    "end": "1053608"
  },
  {
    "text": "And we know what the\nvalue of that constant needs to be because it\nhas to be normalized. So in some sense, it's just as\nhard as the original problem.",
    "start": "1053608",
    "end": "1063399"
  },
  {
    "text": "As far as overfitting\nis concerned, I think it will be strongest in\nthis compared to other models we have seen because I mean--",
    "start": "1063400",
    "end": "1070500"
  },
  {
    "text": "It depends on the\nloss that you use. As we'll see, there\nis going to be issues that are very specific\nto training with the Fisher",
    "start": "1070500",
    "end": "1078370"
  },
  {
    "text": "divergence that makes it\nso that doing things--",
    "start": "1078370",
    "end": "1083860"
  },
  {
    "text": "this vanilla approach\nwill not quite work. And we'll need to do a\nbunch of different things to actually make it\nwork in practice.",
    "start": "1083860",
    "end": "1090920"
  },
  {
    "text": "But so far, it's more like a-- up to here, I'm\njust saying, it's going to be a different\nrepresentation",
    "start": "1090920",
    "end": "1096460"
  },
  {
    "text": "of the kind of models we\nare willing to consider. I haven't even said, how are\nwe going to do the training,",
    "start": "1096460",
    "end": "1101980"
  },
  {
    "text": "and how do we prevent\noverfitting and so forth. And I'm wondering how\nour energy-based models",
    "start": "1101980",
    "end": "1109910"
  },
  {
    "text": "not a generalized kind of\na model for score matching. Because from my understanding,\nif you're using training",
    "start": "1109910",
    "end": "1116930"
  },
  {
    "text": "by Fisher divergence, you\ndon't estimate the energy or the partition at all. You just look at the scores.",
    "start": "1116930",
    "end": "1123740"
  },
  {
    "text": "And how is that\nnot a generalized? So the idea would be that\npotentially, the vector",
    "start": "1123740",
    "end": "1131850"
  },
  {
    "text": "field that you model might not\nbe the gradient of a scalar function. So it might not necessarily be\na conservative vector field.",
    "start": "1131850",
    "end": "1139299"
  },
  {
    "text": "So you can imagine that here,\nif you do things this way, f theta is a scalar\nfunction, which",
    "start": "1139300",
    "end": "1147270"
  },
  {
    "text": "is kind of like the\npotential, if you think about in physics term. There is a potential, maybe\nan electric potential.",
    "start": "1147270",
    "end": "1154380"
  },
  {
    "text": "And that's a scalar. And you get the vector field\nby taking the gradient of that.",
    "start": "1154380",
    "end": "1159920"
  },
  {
    "text": "So it's a way of parameterizing\na set of vector fields that they need to satisfy\ncertain kind of properties",
    "start": "1159920",
    "end": "1166750"
  },
  {
    "text": "because they are the gradients\nof a scalar function. Here, I'm saying, oh,\nI'm no longer even",
    "start": "1166750",
    "end": "1174100"
  },
  {
    "text": "going to restrict myself to\ngradients of scalar function. I'm going to allow myself to\njust have arbitrary vector",
    "start": "1174100",
    "end": "1181630"
  },
  {
    "text": "fields.  That might not be an underlying\nscalar function, such",
    "start": "1181630",
    "end": "1189760"
  },
  {
    "text": "that this vector field is the\ngradient of that function. So we're just modeling\nraw gradients.",
    "start": "1189760",
    "end": "1196720"
  },
  {
    "text": "We're not having any\nfunctional parameters. Exactly. So building on that\nquestion, is it",
    "start": "1196720",
    "end": "1202059"
  },
  {
    "text": "fair to say that in\nthe energy-based model, we try to model-- we still\ntry to model directly",
    "start": "1202060",
    "end": "1207250"
  },
  {
    "text": "the likelihood versus here we\ndirectly model the scores, which are equations?",
    "start": "1207250",
    "end": "1212570"
  },
  {
    "text": "Yes. Oh, maybe here. Are we missing the\n[? v? ?] Or [INAUDIBLE]??",
    "start": "1212570",
    "end": "1219040"
  },
  {
    "text": "Is that on-- [? va ?] is not technically EBM\nbecause you don't even get the--",
    "start": "1219040",
    "end": "1225230"
  },
  {
    "text": "yeah, there is no\nnormalization constant and that the likelihood comes\nfrom an integral because",
    "start": "1225230",
    "end": "1230800"
  },
  {
    "text": "of the latent variables. It's not directly something\nthat would fit here. I mean, I think--",
    "start": "1230800",
    "end": "1235957"
  },
  {
    "text": "I was just wondering,\nlike there seems to be some semantic overloading. Why do we call this x scores\nand not just gradients?",
    "start": "1235957",
    "end": "1242630"
  },
  {
    "text": "Like, why do we have different\nterms giving the same thing? The reason they're\ncalled scores is",
    "start": "1242630",
    "end": "1249080"
  },
  {
    "text": "that they're called\nscores in the literature. And people use score\nmatching for the losses.",
    "start": "1249080",
    "end": "1254120"
  },
  {
    "text": "And it's called a Fisher score. That's why we chose that name.",
    "start": "1254120",
    "end": "1261100"
  },
  {
    "text": "Yeah. What's the cost of\nlooking at the gradients? Because then, if\nthere's nothing, then we can just look at\nthe second derivative,",
    "start": "1261100",
    "end": "1266740"
  },
  {
    "text": "the third derivative. We can just keep\ngoing [INAUDIBLE].. Yeah, yeah, yeah. Although I haven't seen\nit done, but in principle,",
    "start": "1266740",
    "end": "1273910"
  },
  {
    "text": "you could potentially look at. Maybe it's going to be too high\ndimensional or too complicated, but you could.",
    "start": "1273910",
    "end": "1281320"
  },
  {
    "text": "If the gradients are in\nrespect to [INAUDIBLE],, how do we practically\ngenerate [INAUDIBLE]??",
    "start": "1281320",
    "end": "1286732"
  },
  {
    "text": "Yeah, so we'll talk\nabout how to do inference, how to do sampling,\nand those kind of things. I want to go back to when you\nfirst talked about the score",
    "start": "1286732",
    "end": "1295630"
  },
  {
    "text": "matching, like, why score\nmatching will at least lead",
    "start": "1295630",
    "end": "1300680"
  },
  {
    "text": "to identical or to distribution\nlike [INAUDIBLE] similar?",
    "start": "1300680",
    "end": "1308500"
  },
  {
    "text": "Because for the score\nmatching, if we think about it, it's kind of like a\ngradient of the PDF, right?",
    "start": "1308500",
    "end": "1313760"
  },
  {
    "text": "Yeah. And then we do integrations by\nhow about the constant terms that will-- It has to integrate to 1\nbecause it's a density.",
    "start": "1313760",
    "end": "1323779"
  },
  {
    "text": "So if you integrate a function--\nso yeah, when you integrate, you get the function\nup to a constant.",
    "start": "1323780",
    "end": "1330540"
  },
  {
    "text": "And that constant has to be-- is determined by the fact\nthat the integral of the PDF",
    "start": "1330540",
    "end": "1335690"
  },
  {
    "text": "has to be 1. So there is no loss\nof information. In general, when you go from\na function to the derivative,",
    "start": "1335690",
    "end": "1341960"
  },
  {
    "text": "you lose information\nabout a shift, basically, because you can't recover--",
    "start": "1341960",
    "end": "1348320"
  },
  {
    "text": "if you take a function and\nyou shift it by a constant, they will both have\nthe same derivative, So it looks like you're\nlosing information.",
    "start": "1348320",
    "end": "1355142"
  },
  {
    "text": "But here, you don't because we\nknow that the functions have to be-- have to integrate to 1. ",
    "start": "1355142",
    "end": "1364000"
  },
  {
    "text": "Cool. So that's the high-level idea. We're going to try to fit\ndirectly score models to data.",
    "start": "1364000",
    "end": "1373510"
  },
  {
    "text": "So the problem is this. You're given IID\nsamples from our data density, which is unknown.",
    "start": "1373510",
    "end": "1379360"
  },
  {
    "text": "Usual learning\nsetting, our training set of samples from some\nunknown data distribution.",
    "start": "1379360",
    "end": "1385780"
  },
  {
    "text": "And you want to try to\nestimate the score of this data distribution.",
    "start": "1385780",
    "end": "1390909"
  },
  {
    "text": "And so we're going to think\nabout model family, which is going to be a set of\nvector-valued functions",
    "start": "1390910",
    "end": "1397720"
  },
  {
    "text": "parameterized by\nneural networks. As you change theta, you change\nthe shape of the vector field.",
    "start": "1397720",
    "end": "1403090"
  },
  {
    "text": "And the goal is to choose\nparameters so that the vector fields are similar.",
    "start": "1403090",
    "end": "1409870"
  },
  {
    "text": "So you can imagine the\nfirst question is, how do we compare two vector fields?",
    "start": "1409870",
    "end": "1415810"
  },
  {
    "text": "So there's going to\nbe the true vector field of gradients corresponding\nto the data density.",
    "start": "1415810",
    "end": "1421940"
  },
  {
    "text": "There's going to be an estimated\nvector field of gradients. How do we compare them?",
    "start": "1421940",
    "end": "1427720"
  },
  {
    "text": "A reasonable way to do it\nis to basically overlap these two vector fields.",
    "start": "1427720",
    "end": "1432970"
  },
  {
    "text": "At every point, there is\ngoing to be a true gradient, an estimated gradient. And we can look at the\ndifference between the two",
    "start": "1432970",
    "end": "1439750"
  },
  {
    "text": "and average this\nover the whole space.",
    "start": "1439750",
    "end": "1444790"
  },
  {
    "text": "And if you do that, you get\nback the Fisher divergence",
    "start": "1444790",
    "end": "1450430"
  },
  {
    "text": "that we talked about before. So if you go\nthrough every x, you",
    "start": "1450430",
    "end": "1455740"
  },
  {
    "text": "look at the true\ngradient at that point according to the data density. You look at the estimated\ngradient at that point",
    "start": "1455740",
    "end": "1460810"
  },
  {
    "text": "according to the model. There's going to\nbe some difference. You look at the\nnorm of that vector.",
    "start": "1460810",
    "end": "1466890"
  },
  {
    "text": "You average with respect\nto the data density. And that's going to be a\nscalar value that tells you",
    "start": "1466890",
    "end": "1473720"
  },
  {
    "text": "how far away your model\nis from the true vector field of gradients of\nthe data distribution.",
    "start": "1473720",
    "end": "1482200"
  },
  {
    "text": "So if you can get this quantity\nto 0 as a function of theta, then you know that the\nvector fields match.",
    "start": "1482200",
    "end": "1488140"
  },
  {
    "text": "And you have a perfect model. And so trying to minimize\nthis as a function of theta is a reasonable\nlearning objective.",
    "start": "1488140",
    "end": "1495170"
  },
  {
    "text": "And we know that even though it\nlooks like something that you cannot possibly optimize because\nit depends on this unknown",
    "start": "1495170",
    "end": "1503149"
  },
  {
    "text": "quantity here, recall, we\nonly have access to samples. We can do integration\nby parts, and you",
    "start": "1503150",
    "end": "1509780"
  },
  {
    "text": "can rewrite it in terms\nof an objective that only depends on your model.",
    "start": "1509780",
    "end": "1515640"
  },
  {
    "text": "And it still involves an\nexpectation with respect to the data, but you can\napproximate that using",
    "start": "1515640",
    "end": "1522240"
  },
  {
    "text": "the sample average. So in order to train\nthis kind of model,",
    "start": "1522240",
    "end": "1527669"
  },
  {
    "text": "you need to be able to\nevaluate s theta efficiently.",
    "start": "1527670",
    "end": "1533120"
  },
  {
    "text": "And we need to somehow\nbe able to compute",
    "start": "1533120",
    "end": "1538610"
  },
  {
    "text": "this trace of the Jacobian,\nwhich is basically the sum of all a bunch\nof partial derivatives.",
    "start": "1538610",
    "end": "1548120"
  },
  {
    "text": "And then there is the\nquestion of, well, do we need this core\nmodel to be proper,",
    "start": "1548120",
    "end": "1555110"
  },
  {
    "text": "to correspond to the gradient\nof some energy function? And we'll see that\nthat's actually not",
    "start": "1555110",
    "end": "1561260"
  },
  {
    "text": "really needed in practice. So the most straightforward\nway of parameterizing the score",
    "start": "1561260",
    "end": "1573520"
  },
  {
    "text": "would be to just pick a vector\nvalue, the neural network. So let's say you have three\ninputs and three outputs.",
    "start": "1573520",
    "end": "1581409"
  },
  {
    "text": "Because we know at every\npoint, this neural network has to estimate\na gradient, which is a vector, which is the\nsame dimension as the input.",
    "start": "1581410",
    "end": "1589919"
  },
  {
    "text": "And then we need to be\nable to basically evaluate this loss, which\ninvolves the norm",
    "start": "1589920",
    "end": "1596370"
  },
  {
    "text": "of the output of\nthe neural network and the trace of the Jacobian.",
    "start": "1596370",
    "end": "1603559"
  },
  {
    "text": "And so to evaluate\nthe first term, which is just the norm of\nthe output, it's easy.",
    "start": "1603560",
    "end": "1610170"
  },
  {
    "text": "Basically, what you do is\nyou just do a forward pass, and then you can\ncompute as theta. And then you can also compute\nthe squared a normal as theta.",
    "start": "1610170",
    "end": "1620789"
  },
  {
    "text": "The more complicated piece\nis the trace of the Jacobian. So the Jacobian is\nbasically this matrix",
    "start": "1620790",
    "end": "1630300"
  },
  {
    "text": "where you have basically\nall the partial derivatives or all the gradients of\nevery output with respect",
    "start": "1630300",
    "end": "1638850"
  },
  {
    "text": "to the inputs. So the first term up here\nis the partial derivative",
    "start": "1638850",
    "end": "1645120"
  },
  {
    "text": "of the first output with\nrespect to the first input. And then you have all\nthese partial derivatives",
    "start": "1645120",
    "end": "1653460"
  },
  {
    "text": "that you have to deal with. And the problem is\nwe're trying to compute",
    "start": "1653460",
    "end": "1661809"
  },
  {
    "text": "the trace of this matrix,\nwhich is basically the sum of the elements\nof the diagonal.",
    "start": "1661810",
    "end": "1667240"
  },
  {
    "text": "And so what you\nneed to do is you need to be able to compute\nthe partial derivative of the first output with\nrespect to the first input.",
    "start": "1667240",
    "end": "1674860"
  },
  {
    "text": "And then you need to\ncompute this element here on the diagonal. You need to compute the partial\nderivative of the second output",
    "start": "1674860",
    "end": "1682960"
  },
  {
    "text": "with respect to\nthe second input. And then you need to compute\nthe partial derivative",
    "start": "1682960",
    "end": "1688299"
  },
  {
    "text": "of the third output with\nrespect to the third input. Then you have to sum\nup these three numbers",
    "start": "1688300",
    "end": "1695830"
  },
  {
    "text": "because you need to sum up\nthese three, the elements on the diagonal of this matrix.",
    "start": "1695830",
    "end": "1702630"
  },
  {
    "text": "And although we can\ndo back propagation-- so you can compute these\nderivatives relatively",
    "start": "1702630",
    "end": "1708960"
  },
  {
    "text": "efficiently-- naively doing this would require\na number of back propagation",
    "start": "1708960",
    "end": "1716690"
  },
  {
    "text": "steps that scales linearly\nwith the number of dimensions that you have.",
    "start": "1716690",
    "end": "1722457"
  },
  {
    "text": "And we don't know if there\nis a more efficient way of basically doing this. But the only way basically\nwe know how to do it",
    "start": "1722457",
    "end": "1729130"
  },
  {
    "text": "is essentially\nextremely inefficient when the number of dimensions\ngrows and is very large.",
    "start": "1729130",
    "end": "1738010"
  },
  {
    "text": "And so even though\nthis loss does not involve partition\nfunctions, it still",
    "start": "1738010",
    "end": "1744070"
  },
  {
    "text": "scales pretty poorly with the\ndimensionality of the data.",
    "start": "1744070",
    "end": "1749309"
  },
  {
    "text": "So doesn't EBMs have\nthe same problem? Like, we also have to calculate\nthe trees of the hash and--",
    "start": "1749310",
    "end": "1755669"
  },
  {
    "text": "Yeah, so EBMs are even worse. Because in an EBM,\nyou would need to do one more back\nprop to get the score",
    "start": "1755670",
    "end": "1764820"
  },
  {
    "text": "and then one more to\nget these derivatives. So an EBM would be\neven more expensive.",
    "start": "1764820",
    "end": "1773774"
  },
  {
    "text": "This at least saves you\none back propagation because you are already modeling\nthe gradient of something.",
    "start": "1773775",
    "end": "1780630"
  },
  {
    "text": "But it's still expensive. Yeah. I taught in EBMs, it\nreduced to f theta.",
    "start": "1780630",
    "end": "1788730"
  },
  {
    "text": "Yeah, so you have\nthe hash of f theta. So when you take the first\ngradient with respect",
    "start": "1788730",
    "end": "1794220"
  },
  {
    "text": "to x of f theta, you\nget essentially s theta. And then you have to do\nthe Jacobian of s theta.",
    "start": "1794220",
    "end": "1802860"
  },
  {
    "text": "So you need to do\nsecond order, basically, derivatives in that case. So it's even more expensive.",
    "start": "1802860",
    "end": "1811900"
  },
  {
    "text": "Do the input and output\nconnections have to be the same? Or can you use different ones?",
    "start": "1811900",
    "end": "1817280"
  },
  {
    "text": "They have to be the\nsame here because you're modeling the score, which is the\ngradient of the log likelihood.",
    "start": "1817280",
    "end": "1823160"
  },
  {
    "text": "And so that has to be the\nsame dimension as the input. You have to-- I guess you're trying to\nmatch with the gradient.",
    "start": "1823160",
    "end": "1829610"
  },
  {
    "text": "So then. yeah. OK. So does this method\nonly deal with the data",
    "start": "1829610",
    "end": "1837310"
  },
  {
    "text": "that has the same\ndimension, because we're trying to basically compare\nthe scores at each points.",
    "start": "1837310",
    "end": "1846710"
  },
  {
    "text": "So we can only deal\nwith the data that has the identical dimensions.",
    "start": "1846710",
    "end": "1852370"
  },
  {
    "text": "Sorry, this is-- we're\nmodeling a joint distribution over a set of random variables.",
    "start": "1852370",
    "end": "1860540"
  },
  {
    "text": "And if some of them are\nmissing, computing marginals might be expensive.",
    "start": "1860540",
    "end": "1866060"
  },
  {
    "text": " Cool. So this vanilla version,\nwhich is something we briefly",
    "start": "1866060",
    "end": "1874169"
  },
  {
    "text": "mentioned also in the last\nlecture-- if you recall, we said, OK, this is avoids\nthe partition function.",
    "start": "1874170",
    "end": "1879840"
  },
  {
    "text": "But doing integration by\nparts is still expensive because of this Hessian term\nor trace of the [? Jacobian ?]",
    "start": "1879840",
    "end": "1887460"
  },
  {
    "text": "in this case. And so we need more scalable\nkind of approximations that work in high dimensions.",
    "start": "1887460",
    "end": "1894030"
  },
  {
    "text": "And that's what we're going\nto talk about next, which is how to get this to scale\nto high-dimensional settings",
    "start": "1894030",
    "end": "1901170"
  },
  {
    "text": "where basically this d is large. And there's two approaches\nthat we're going to talk about.",
    "start": "1901170",
    "end": "1908280"
  },
  {
    "text": "The first one is called the\ndenoising score matching. And the idea is that\ninstead of trying",
    "start": "1908280",
    "end": "1914700"
  },
  {
    "text": "to estimate the\ngradient of the data, we're going to try to estimate\nthe gradient of the data",
    "start": "1914700",
    "end": "1921810"
  },
  {
    "text": "perturbed with noise. So you can imagine that there\nis a data distribution that might look like this.",
    "start": "1921810",
    "end": "1927820"
  },
  {
    "text": "And then there's going to\nbe a noise-perturbed data",
    "start": "1927820",
    "end": "1933000"
  },
  {
    "text": "distribution shown in orange\ndenoted q sigma, where we're basically just adding\nnoise to the data",
    "start": "1933000",
    "end": "1940559"
  },
  {
    "text": "or convolving the data\ndensity in this case with a noise distribution\nq sigma of x tilde",
    "start": "1940560",
    "end": "1948299"
  },
  {
    "text": "given x, which\nmight be something like a Gaussian in this case. We're smoothing the\noriginal data density",
    "start": "1948300",
    "end": "1956960"
  },
  {
    "text": "by essentially adding noise. Then it turns out\nthat estimating",
    "start": "1956960",
    "end": "1964280"
  },
  {
    "text": "the score of this distribution\nthat you get after adding noise is a lot easier computationally.",
    "start": "1964280",
    "end": "1970890"
  },
  {
    "text": "And so to the extent\nthat you choose the noise level to be\nrelatively small, this",
    "start": "1970890",
    "end": "1976770"
  },
  {
    "text": "might be a reasonable\napproximation. If you don't add too much\nnoise, then this yellow density",
    "start": "1976770",
    "end": "1982740"
  },
  {
    "text": "will be pretty close\nto the blue one. And so the scores that you\nestimate for the yellow density,",
    "start": "1982740",
    "end": "1989677"
  },
  {
    "text": "the noise perturbed\ndensity, are going to be pretty close\nto what you want,",
    "start": "1989677",
    "end": "1998270"
  },
  {
    "text": "because, basically,\nq sigma is going to be pretty close to\nthe original data density when sigma is small.",
    "start": "1998270",
    "end": "2004840"
  },
  {
    "text": "That's the high-level idea. And so works like this.",
    "start": "2004840",
    "end": "2011020"
  },
  {
    "text": "You have a data density,\nwhich could be over images. Then you add noise to the images\nby using this Gaussian kernel q",
    "start": "2011020",
    "end": "2019110"
  },
  {
    "text": "sigma. And then you get\na new distribution over images plus with noise.",
    "start": "2019110",
    "end": "2024780"
  },
  {
    "text": "And we're going to try to\nestimate the score of that. And the way we're\ngoing to try to fit",
    "start": "2024780",
    "end": "2034289"
  },
  {
    "text": "our model to this\nnoise-perturbed data density is again using the\nFisher divergence.",
    "start": "2034290",
    "end": "2040110"
  },
  {
    "text": "But now, instead of doing a\nFisher divergence between model and data, we do\nFisher divergence",
    "start": "2040110",
    "end": "2045240"
  },
  {
    "text": "between model and this\nnoise-perturbed data density.",
    "start": "2045240",
    "end": "2052300"
  },
  {
    "text": "So it's the same\nthing as before, except we replace p\ndata with q sigma, which",
    "start": "2052300",
    "end": "2057879"
  },
  {
    "text": "is the same as-- which\nis data plus noise, basically, which is just this.",
    "start": "2057880",
    "end": "2066579"
  },
  {
    "text": "So the expectation is just\nthis integral with respect to q sigma.",
    "start": "2066580",
    "end": "2072520"
  },
  {
    "text": "So just like before, it's just\nthe norm of the difference between the estimated gradient\nand the true gradient,",
    "start": "2072520",
    "end": "2078399"
  },
  {
    "text": "except that now instead of\nusing the real data density, we use this q sigma, which\nis the noise-perturbed data",
    "start": "2078400",
    "end": "2084908"
  },
  {
    "text": "density. And then just of like when\nwe're doing integration",
    "start": "2084909",
    "end": "2091260"
  },
  {
    "text": "by parts, we expand this\nsquare and get three terms.",
    "start": "2091260",
    "end": "2097620"
  },
  {
    "text": "We get the norm\nof the first term, the norm of the second term. Then we have this inner\nproduct between the two pieces.",
    "start": "2097620",
    "end": "2108060"
  },
  {
    "text": "The red term, which is going\nto be the complicated one. Basically, just like in\nthe integration by part,",
    "start": "2108060",
    "end": "2115950"
  },
  {
    "text": "you can see that the blue\nterm does not depend on theta. So we can ignore it. The green term depends\non theta in an easy way.",
    "start": "2115950",
    "end": "2125460"
  },
  {
    "text": "So it's just basically\nthe usual thing. And the complicated\npiece is the red one.",
    "start": "2125460",
    "end": "2133400"
  },
  {
    "text": "Or we have this dot\nproduct between the score of the noisy data and\nthe estimated score.",
    "start": "2133400",
    "end": "2139390"
  },
  {
    "text": " Yeah? Can you describe again how\nyou start with [INAUDIBLE]??",
    "start": "2139390",
    "end": "2147180"
  },
  {
    "text": "Are you opposed to formally\nsampling the data and then-- Yeah, so q is defined as--",
    "start": "2147180",
    "end": "2154650"
  },
  {
    "text": "basically, you get a\nsample from q sigma by randomly drawing\nfrom the data,",
    "start": "2154650",
    "end": "2160710"
  },
  {
    "text": "randomly drawing some Gaussian\nnoise and adding it to the data. ",
    "start": "2160710",
    "end": "2168230"
  },
  {
    "text": "Yeah. Other questions?",
    "start": "2168230",
    "end": "2173809"
  },
  {
    "text": "Yeah. What does this q give us? ",
    "start": "2173810",
    "end": "2178940"
  },
  {
    "text": "What do we achieve\nby doing that? So we achieve that is going\nto be tractable in the sense",
    "start": "2178940",
    "end": "2184520"
  },
  {
    "text": "that we're going to get rid of\nthat trace of the [? Jacobian ?] term. So we're going to get\na loss function that",
    "start": "2184520",
    "end": "2190520"
  },
  {
    "text": "is going to be scalable\nin high dimensions. So that's going to be the--",
    "start": "2190520",
    "end": "2195780"
  },
  {
    "text": "we're doing this because\nthe trace of the Jacobian was too expensive. This introduces an approximation\nbecause you're no longer",
    "start": "2195780",
    "end": "2203150"
  },
  {
    "text": "estimating the score\nof the data density or estimating the score\nof this other thing.",
    "start": "2203150",
    "end": "2208735"
  },
  {
    "text": "But it turns out\nthat we're going to be able to do it\nmuch more efficiently. ",
    "start": "2208735",
    "end": "2216019"
  },
  {
    "text": "Yeah? Looking back, gradient\nsomehow still depend on the gradient\nwith respect to x?",
    "start": "2216020",
    "end": "2222920"
  },
  {
    "text": "Yeah, it looks like it does. But then it turns out there is-- we'll see that it actually\nsimplifies to something pretty",
    "start": "2222920",
    "end": "2230900"
  },
  {
    "text": "intuitive and very simple. It's going to reduce this\nproblem to denoising.",
    "start": "2230900",
    "end": "2235950"
  },
  {
    "text": "So, basically, this\nscore-matching objective will end up being equivalent\nto the problem of given",
    "start": "2235950",
    "end": "2244640"
  },
  {
    "text": "this x tilde. Try to remove noise. And try to estimate the\noriginal image you started with,",
    "start": "2244640",
    "end": "2251390"
  },
  {
    "text": "basically. It's going to be\nmathematically equivalent.",
    "start": "2251390",
    "end": "2256640"
  },
  {
    "text": "Basically, we're going to\nrewrite this red term in a sum. Where do I have my cursor?",
    "start": "2256640",
    "end": "2261890"
  },
  {
    "text": "We're going to rewrite\nthis red term in some way. And we're going\nto show it's going to be equivalent to denoising. ",
    "start": "2261890",
    "end": "2270030"
  },
  {
    "text": "OK, so we ignore the blue term. It doesn't depend on theta. Then we have this green\nterm, which is easy. And then we have this red\nterm, which is tricky.",
    "start": "2270030",
    "end": "2277829"
  },
  {
    "text": "But we're going to rewrite it. So focusing on the red\nterm, it looks like this.",
    "start": "2277830",
    "end": "2283950"
  },
  {
    "text": "And just like in the\nintegration by part trick,",
    "start": "2283950",
    "end": "2289320"
  },
  {
    "text": "we can write the\ngradient of the log as 1 over the argument of the\nlog times the gradient",
    "start": "2289320",
    "end": "2295589"
  },
  {
    "text": "of the argument of the log. This is the basic-- I just basically expanded the\ngradient of the log of q sigma.",
    "start": "2295590",
    "end": "2304890"
  },
  {
    "text": "And now you see that this\nq sigma here and q sigma down here will cancel\nwith each other.",
    "start": "2304890",
    "end": "2312000"
  },
  {
    "text": "And so we end up with\nsomething a little bit simpler. It's just the dot\nproduct basically",
    "start": "2312000",
    "end": "2317579"
  },
  {
    "text": "between the gradient of\nthe noise-perturbed density",
    "start": "2317580",
    "end": "2322770"
  },
  {
    "text": "and the gradient and the\nscore model at every point. And now we can\nwrite the expression",
    "start": "2322770",
    "end": "2330740"
  },
  {
    "text": "for q sigma, which is\njust this integral.",
    "start": "2330740",
    "end": "2335800"
  },
  {
    "text": "Basically, the probability of\nany particular sigma x tilde is going to be the probability\nof sampling any data point",
    "start": "2335800",
    "end": "2344050"
  },
  {
    "text": "x times the probability of\ngenerating x tilde by adding noise to x, basically.",
    "start": "2344050",
    "end": "2350750"
  },
  {
    "text": " Think about the\nsampling process. What is the probability\nof generating an x tilde?",
    "start": "2350750",
    "end": "2357540"
  },
  {
    "text": "You have to look at\nevery possible x. And you have to check what was\nthe probability of generating x tilde by adding noise to x.",
    "start": "2357540",
    "end": "2364950"
  },
  {
    "text": "That's basically what\nthis integral here is giving you is just\nthe definition of q sigma",
    "start": "2364950",
    "end": "2370318"
  },
  {
    "text": "that we had in the\nprevious slide.  And now we can see\nthat this is linear.",
    "start": "2370318",
    "end": "2378050"
  },
  {
    "text": "So we can push the gradient\ninside the integral.",
    "start": "2378050",
    "end": "2383630"
  },
  {
    "text": "And that's where things become\na lot simpler because now you see that now we are getting\na gradient of this Gaussian",
    "start": "2383630",
    "end": "2392570"
  },
  {
    "text": "density basically. And we no longer have to deal\nwith the gradient of the data density, basically.",
    "start": "2392570",
    "end": "2400000"
  },
  {
    "text": "And now we can\nfurther push out the--",
    "start": "2400000",
    "end": "2406240"
  },
  {
    "text": "well, now we can\nuse, again, this trick here that the\ngradient of the log of q is 1 over q times\nthe gradient of q.",
    "start": "2406240",
    "end": "2412870"
  },
  {
    "text": "And we can rewrite the\ngradient of the transition of the Gaussian density as q\ntimes the gradient of log q.",
    "start": "2412870",
    "end": "2421483"
  },
  {
    "text": "If you take the\ngradient of log q, you're going to get the\ngradient of q times 1 minus q. And so these two things\nare obviously the same.",
    "start": "2421483",
    "end": "2430520"
  },
  {
    "text": "And now you push\nthe expectation out. And we basically\nhave an expression that looks very much\nlike the original one",
    "start": "2430520",
    "end": "2438769"
  },
  {
    "text": "that we started with. But we no longer have to deal\nwith this gradient of the log data density\nperturbed with noise.",
    "start": "2438770",
    "end": "2445160"
  },
  {
    "text": "But we have to look\nat the gradient of this conditional\ndistribution of x tilde given x, which is just\na Gaussian density.",
    "start": "2445160",
    "end": "2456180"
  },
  {
    "text": "And so overall,\nbasically, we've rewritten this complicated object\nup here into something",
    "start": "2456180",
    "end": "2463358"
  },
  {
    "text": "that is a little bit\nsimpler because now it involves only the gradient. It basically involves\nthe score of this q",
    "start": "2463358",
    "end": "2470190"
  },
  {
    "text": "sigma of x tilde given x, which\nis just going to be Gaussian. ",
    "start": "2470190",
    "end": "2475980"
  },
  {
    "text": "And so bringing\nit together, this is what we started with\nestimating the score of the data",
    "start": "2475980",
    "end": "2482220"
  },
  {
    "text": "density perturbed with noise. We know you could\nwrite it this way.",
    "start": "2482220",
    "end": "2487860"
  },
  {
    "text": "And through this algebra\nthat we just did, we could also rewrite the\nred term in terms of this.",
    "start": "2487860",
    "end": "2495490"
  },
  {
    "text": "And now you can basically\nsee that essentially--",
    "start": "2495490",
    "end": "2504390"
  },
  {
    "text": "you can write it as the square\ndifference between theta and the gradient of this\nGaussian transition kernel",
    "start": "2504390",
    "end": "2511410"
  },
  {
    "text": "that we have here,\nbecause that would give us when you take the\nsquare of this term, it would give you the red one. ",
    "start": "2511410",
    "end": "2518780"
  },
  {
    "text": "The square term of this one\nwill give you this brown term when we're subtracting out.",
    "start": "2518780",
    "end": "2524380"
  },
  {
    "text": "And then the dot product\nbetween these two is exactly this red term\nthat we just derived.",
    "start": "2524380",
    "end": "2531040"
  },
  {
    "text": "So all in all, basically,\nwhat we've shown is that if you want to estimate\nthe score of the q sigma,",
    "start": "2531040",
    "end": "2537910"
  },
  {
    "text": "the noise perturbed\ndata density, it's basically\nequivalent to trying to estimate the score of\nthis transition kernel,",
    "start": "2537910",
    "end": "2547080"
  },
  {
    "text": "this Gaussian density\nthat we use to add noise across different axes and\ndifferent x tildes that",
    "start": "2547080",
    "end": "2556300"
  },
  {
    "text": "are sampled from the\nnoise distribution. So a lot of algebra, but,\nbasically, up to constants,",
    "start": "2556300",
    "end": "2566490"
  },
  {
    "text": "we can rewrite the\nscore matching objective for the noise perturbed data\ndensity into a new score",
    "start": "2566490",
    "end": "2572300"
  },
  {
    "text": "matching objective that\nnow involves terms that are relatively easy to work with.",
    "start": "2572300",
    "end": "2577730"
  },
  {
    "text": "And in particular, if you\nlook at this expression,",
    "start": "2577730",
    "end": "2584010"
  },
  {
    "text": "it turns out that this gradient\nof the log of q sigma x tilde given x is easy to compute\nbecause that's just a Gaussian.",
    "start": "2584010",
    "end": "2592390"
  },
  {
    "text": "So q sigma x tilde\ngiven x is just a Gaussian with mean x and\nstandard deviation and variance",
    "start": "2592390",
    "end": "2601780"
  },
  {
    "text": "sigma squared identity. So that's just a\nsquared exponential.",
    "start": "2601780",
    "end": "2608320"
  },
  {
    "text": "When you take the log, it\njust becomes a quadratic form. When you take the gradient,\nyou just get a relatively--",
    "start": "2608320",
    "end": "2615550"
  },
  {
    "text": "basically an expression\nthat looks like that. And so when you plug-in\nthis expression in here,",
    "start": "2615550",
    "end": "2624920"
  },
  {
    "text": "you get something\neasy to work with.",
    "start": "2624920",
    "end": "2630095"
  },
  {
    "text": "Maybe I don't have it here. But, basically, you end\nup with an objective",
    "start": "2630095",
    "end": "2635390"
  },
  {
    "text": "that no longer involves\ntraces of the Jacobians.",
    "start": "2635390",
    "end": "2640630"
  },
  {
    "text": "It's like an L2\nloss between s theta compared to this x tilde minus x\nover x over sigma squared, which",
    "start": "2640630",
    "end": "2650670"
  },
  {
    "text": "is basically a denoising\nobjective, as we'll see in the next couple of slides.",
    "start": "2650670",
    "end": "2658260"
  },
  {
    "text": "So the key takeaway\nhere is you don't have to estimate the trace\nof the Jacobian anymore.",
    "start": "2658260",
    "end": "2665730"
  },
  {
    "text": "if you're willing to\nestimate the score, not of the clean data.",
    "start": "2665730",
    "end": "2670820"
  },
  {
    "text": "But if you're\nwilling to estimate the score of this q sigma,\nwhich is data plus noise. ",
    "start": "2670820",
    "end": "2678240"
  },
  {
    "text": "So practically the algorithm\nis something like this. You have a mini batch of data\npoints sample from the data.",
    "start": "2678240",
    "end": "2685430"
  },
  {
    "text": "You perturb these data points\nby adding Gaussian noise.",
    "start": "2685430",
    "end": "2691420"
  },
  {
    "text": "So literally just add noise to\neach xi with the variance sigma",
    "start": "2691420",
    "end": "2698500"
  },
  {
    "text": "squared. And then you just estimate the\ndenoising score matching loss,",
    "start": "2698500",
    "end": "2704550"
  },
  {
    "text": "which is just based on the\nminibatch, which is just the loss on these data points. And it's just basically\nthis expression.",
    "start": "2704550",
    "end": "2712330"
  },
  {
    "text": "And recall that if this\nq sigma is Gaussian,",
    "start": "2712330",
    "end": "2717420"
  },
  {
    "text": "then the loss looks\nsomething like this. And so it has a very\nintuitive interpretation",
    "start": "2717420",
    "end": "2726200"
  },
  {
    "text": "because what we're saying is\nthat what this core model needs to do at every data\npoint x tilde--",
    "start": "2726200",
    "end": "2732570"
  },
  {
    "text": "so the score model is being\nevaluated at this noisy data points x tilde.",
    "start": "2732570",
    "end": "2737600"
  },
  {
    "text": "And for each data point, what\nthe score model is trying to do is it's trying to estimate\nthe noise that was",
    "start": "2737600",
    "end": "2744170"
  },
  {
    "text": "added to xi to produce x tilde.",
    "start": "2744170",
    "end": "2750940"
  },
  {
    "text": "Do we have some restriction\non how noisy, like how large,",
    "start": "2750940",
    "end": "2757660"
  },
  {
    "text": "let's say, the\nstandard sigma here we're trying to add\nnoise to the arrangement?",
    "start": "2757660",
    "end": "2763599"
  },
  {
    "text": "Yeah, so you'd want sigma to be\nas small as possible because you want q sigma to be as close\nas possible to [? p data. ?]",
    "start": "2763600",
    "end": "2771130"
  },
  {
    "text": "On the other hand, the variance\ngoes to infinity of this [? law ?] as sigma goes to 0.",
    "start": "2771130",
    "end": "2778000"
  },
  {
    "text": "So you can't actually choose\nsigma to be too small. So in practice, you\nneed to try to choose the sigma as small\nas possible such",
    "start": "2778000",
    "end": "2786280"
  },
  {
    "text": "that you still\noptimize the loss. But there is always\nan approximation.",
    "start": "2786280",
    "end": "2791685"
  },
  {
    "text": "That's the trade off. You don't have Hessians or\ntraces of the Jacobian anymore.",
    "start": "2791685",
    "end": "2797560"
  },
  {
    "text": "But you're not estimating\nthe score of the clean data. You're estimating the\nscore of the noisy data.",
    "start": "2797560",
    "end": "2804430"
  },
  {
    "text": "I don't understand because-- so they're different. But the gain here, we get rid\nof the trace of the derivative",
    "start": "2804430",
    "end": "2812290"
  },
  {
    "text": "of the score is because we know\nthe closed forms of the noise that was added.",
    "start": "2812290",
    "end": "2818930"
  },
  {
    "text": "Yeah, we're no\nlonger estimating-- I mean, we're\nchanging the goalpost. We're no longer estimating-- you\ncan think of this as basically",
    "start": "2818930",
    "end": "2826870"
  },
  {
    "text": "a numerical approximation of-- in some sense, we're adding\nwe're adding Gaussian noise. And we're trying to\nestimate derivatives",
    "start": "2826870",
    "end": "2833589"
  },
  {
    "text": "through a finite difference. Basically, that's one way\nof deriving the same thing,",
    "start": "2833590",
    "end": "2842260"
  },
  {
    "text": "if you like, that sort\nof approximation route. It has the flavor of basically\nestimating the derivatives",
    "start": "2842260",
    "end": "2850840"
  },
  {
    "text": "through a perturbation. Why is it denoising\nscore matching because we're matching with--",
    "start": "2850840",
    "end": "2858349"
  },
  {
    "text": "we're matching to a\nperturbed data point. How does it help with denoising? So if you think about\nwhen is this loss zero--",
    "start": "2858350",
    "end": "2866920"
  },
  {
    "text": "maybe I have it\non the next slide. Yeah, so if you think\nabout it, the loss function",
    "start": "2866920",
    "end": "2877570"
  },
  {
    "text": "looks like this. The original loss\nfunction was this. And then we were able\nto rewrite it as this. And so what are you doing?",
    "start": "2877570",
    "end": "2883880"
  },
  {
    "text": "You're starting\nwith a clean image. Then you add noise\nto generate x tilde.",
    "start": "2883880",
    "end": "2889460"
  },
  {
    "text": "Then look at this loss. What we're saying is\nthat the score model takes x tilde as an input.",
    "start": "2889460",
    "end": "2896390"
  },
  {
    "text": "And to make this L2 loss\nas small as possible, you're trying to\nmatch this x minus x",
    "start": "2896390",
    "end": "2903170"
  },
  {
    "text": "tilde, which is exactly\nthe noise that we added. And so to make this loss\nas small as possible,",
    "start": "2903170",
    "end": "2912000"
  },
  {
    "text": "s theta has to match\nthe vector of noise that we added to this image.",
    "start": "2912000",
    "end": "2918440"
  },
  {
    "text": "And so that's why\nit's a denoiser because it gets to see x tilde.",
    "start": "2918440",
    "end": "2923870"
  },
  {
    "text": "And it needs to figure out what\ndo I subtract to this x tilde to get back a clean image.",
    "start": "2923870",
    "end": "2931317"
  },
  {
    "text": "Because even though\nwe're not directly comparing with the\noriginal image, we still somehow managed to--",
    "start": "2931317",
    "end": "2936599"
  },
  {
    "text": "Yes, that's called Stein\nunbiased risk estimator. That's the key\ntrick that is used.",
    "start": "2936600",
    "end": "2943160"
  },
  {
    "text": "You can still evaluate the\nquality of an estimator without actually knowing the\nground truth in some sense.",
    "start": "2943160",
    "end": "2950060"
  },
  {
    "text": "Yeah. So do I understand correctly\nthat the only unknown in this optimization is\nbasically the [? theta? ?]",
    "start": "2950060",
    "end": "2957320"
  },
  {
    "text": "You have basically the x,\nthe x tilde, the sigma is",
    "start": "2957320",
    "end": "2962330"
  },
  {
    "text": "you get everything except\nfor the tilde, right? Yes, so the x's and\nthe x tilde, you are generating them yourself.",
    "start": "2962330",
    "end": "2968210"
  },
  {
    "text": "And then my s theta\ndoesn't see the clean data. So x theta only\nsees the noise data. And then you're trying\nto predict the noise.",
    "start": "2968210",
    "end": "2974155"
  },
  {
    "text": " Yeah? ",
    "start": "2974155",
    "end": "2981170"
  },
  {
    "text": "So after we added this Gaussian\ndistribution perturbation, the s is trying\nto basically match",
    "start": "2981170",
    "end": "2989140"
  },
  {
    "text": "the gradient of that\nGaussian noise distribution. But the training goal\nwas this s score function",
    "start": "2989140",
    "end": "2996099"
  },
  {
    "text": "should be the gradient\nof original log likelihood of the original\ndata distribution.",
    "start": "2996100",
    "end": "3001120"
  },
  {
    "text": "So it seems that this trained s\ndeviates from the original goal.",
    "start": "3001120",
    "end": "3007300"
  },
  {
    "text": "For example, if instead of\nusing Gaussian distribution to add the perturbation, if we\nuse another noise distribution,",
    "start": "3007300",
    "end": "3016230"
  },
  {
    "text": "that basically changes\nthe loss function for as",
    "start": "3016230",
    "end": "3021630"
  },
  {
    "text": "and gives a different as. Is that what's happening? You could. Yeah.",
    "start": "3021630",
    "end": "3027110"
  },
  {
    "text": "So it is not restricted\nto Gaussian noise. If you look at the\nmath, the only thing you need to be able to\ncompute is this gradients of--",
    "start": "3027110",
    "end": "3036130"
  },
  {
    "text": "basically, as long\nas the distribution that you use to add noise that\nyou can compute likelihoods,",
    "start": "3036130",
    "end": "3042098"
  },
  {
    "text": "and you can get the gradient\nin closed form, then you can get a denoising\nloss for that.",
    "start": "3042098",
    "end": "3047890"
  },
  {
    "text": "You're going to end up\nestimating the score. We are estimating the\nscore of q sigma, which",
    "start": "3047890",
    "end": "3057310"
  },
  {
    "text": "if you're adding Gaussian\nnoise is going to be basically theta plus Gaussian noise. If you add another\nkind of perturbation,",
    "start": "3057310",
    "end": "3065410"
  },
  {
    "text": "you're going to get another\ntype of data perturbed data.",
    "start": "3065410",
    "end": "3071680"
  },
  {
    "text": "And you're estimating\nthe score of that. So you're right. We're not estimating the score\nof the clean data density.",
    "start": "3071680",
    "end": "3079160"
  },
  {
    "text": "We're estimating the score\nof the data plus noise. The hope is that you need to\njust a small amount of noise",
    "start": "3079160",
    "end": "3086809"
  },
  {
    "text": "so that like if sigma is small\nenough that these images are indistinguishable\nfrom the clean ones,",
    "start": "3086810",
    "end": "3093010"
  },
  {
    "text": "then the approximation\nis not too bad. And what we gain by doing that\nis that it's much more scalable.",
    "start": "3093010",
    "end": "3099555"
  },
  {
    "text": " It feels like\ninstead of converging",
    "start": "3099555",
    "end": "3105970"
  },
  {
    "text": "to the distribution of\nclean data plus noise, it gives me the\nfeeling that we are",
    "start": "3105970",
    "end": "3112000"
  },
  {
    "text": "converging to the distribution\nof the noise function. It doesn't. No, that's the key thing. ",
    "start": "3112000",
    "end": "3120640"
  },
  {
    "text": "I mean, that's the magic\nof denoising score matching that basically these two\nobjectives are equivalent",
    "start": "3120640",
    "end": "3126520"
  },
  {
    "text": "up to a constant. So by minimizing the\nbottom one, the denoising, you are actually also\nminimizing the top objective,",
    "start": "3126520",
    "end": "3134970"
  },
  {
    "text": "where you're really estimating\nthe score of the distribution of the data convolved\nbasically with Gaussian noise,",
    "start": "3134970",
    "end": "3142290"
  },
  {
    "text": "the smoothed version\nof the data density even though you can\njust work at the level",
    "start": "3142290",
    "end": "3148170"
  },
  {
    "text": "of the individual conditionals. That's the beauty of this\ndenoising score matching.",
    "start": "3148170",
    "end": "3153390"
  },
  {
    "text": "Maybe taking a step back, the\nwhole premise of this approach is that it is easier to\nmodel the, basically, vector",
    "start": "3153390",
    "end": "3161760"
  },
  {
    "text": "field of gradients than the\nprobability distribution directly, right? Yeah.",
    "start": "3161760",
    "end": "3167280"
  },
  {
    "text": "And another way to say it\nmaybe is that denoising is not too hard as a problem. And so we have pretty\ngood neural networks",
    "start": "3167280",
    "end": "3174180"
  },
  {
    "text": "that can do denoising. And so to some extent,\nwe've reduced the problem of generating images\nto the problem",
    "start": "3174180",
    "end": "3180839"
  },
  {
    "text": "of denoising, which is\na relatively easy task for our neural networks.",
    "start": "3180840",
    "end": "3187049"
  },
  {
    "text": "So to the extent that you\ncan do well denoising, you're going to do well\nat estimating the score. And we know that the score\nis basically to some extent",
    "start": "3187050",
    "end": "3195800"
  },
  {
    "text": "equivalent to\nhaving a likelihood. So we haven't yet talked about\nhow do you actually generate",
    "start": "3195800",
    "end": "3202190"
  },
  {
    "text": "samples from these models. But essentially we'll do MCMC. And so after all\nthese steps, we've",
    "start": "3202190",
    "end": "3209450"
  },
  {
    "text": "reduced generative\nmodeling to denoising, which is an easy task to\nprobably one of the easiest",
    "start": "3209450",
    "end": "3215030"
  },
  {
    "text": "tasks that you can think of. So, OK, is this\nlike going through--",
    "start": "3215030",
    "end": "3222850"
  },
  {
    "text": "getting the gradient,\nthis turns out to be this denoising objective\nthat only Gaussians or just",
    "start": "3222850",
    "end": "3229300"
  },
  {
    "text": "that this [INAUDIBLE]. Or there's some underlying\nthing that needs to [INAUDIBLE]..",
    "start": "3229300",
    "end": "3234884"
  },
  {
    "text": "So it doesn't have\nto be Gaussian as long as the machinery--\nyeah, basically, as long as you can compute\nthis gradient of whatever",
    "start": "3234885",
    "end": "3245160"
  },
  {
    "text": "distribution you use to add\nnoise, the math works out. And really if you think about\nwhat happened in the proof,",
    "start": "3245160",
    "end": "3252473"
  },
  {
    "text": "really the only\nthing that matters is that the gradient is linear. The gradient is a\nlinear operator.",
    "start": "3252473",
    "end": "3258140"
  },
  {
    "text": "And so this whole\nmachinery works. ",
    "start": "3258140",
    "end": "3263310"
  },
  {
    "text": "So I'm looking at the\noptimization objective.",
    "start": "3263310",
    "end": "3269350"
  },
  {
    "text": "So if we are doing\noptimal optimization, the score function should be\nclose to the noise divided",
    "start": "3269350",
    "end": "3278280"
  },
  {
    "text": "by the standard\ndeviation we chose. And it should also be close\nto the actual gradient of q.",
    "start": "3278280",
    "end": "3286600"
  },
  {
    "text": "Yeah? So are we claiming that the\ngradient of the disturbed image",
    "start": "3286600",
    "end": "3295050"
  },
  {
    "text": "should be similar to the noise? So let's see to what\nextent that is true.",
    "start": "3295050",
    "end": "3302080"
  },
  {
    "text": "So here we've seen the score\nmatching reduces to denoising. So estimating the score is the\nsame as estimating the noise.",
    "start": "3302080",
    "end": "3308310"
  },
  {
    "text": "That was added to\nthe data point. And so the reason this\nis true, or another way to think about\nthis, is that there",
    "start": "3308310",
    "end": "3316890"
  },
  {
    "text": "is something called Tweedie's\nformula, which is basically an alternative way of deriving\nthe same result, which is--",
    "start": "3316890",
    "end": "3326050"
  },
  {
    "text": "it's telling you that,\nindeed, as was suggested",
    "start": "3326050",
    "end": "3331090"
  },
  {
    "text": "by you that the optimal\ndenoising strategy is to basically follow the gradient\nof the perturbed log likelihood.",
    "start": "3331090",
    "end": "3339640"
  },
  {
    "text": "So you can imagine that if\nyou had a data density that only has like three images--",
    "start": "3339640",
    "end": "3347410"
  },
  {
    "text": "so it's like three deltas. And this is like a toy picture.",
    "start": "3347410",
    "end": "3352630"
  },
  {
    "text": "But just for\nvisualization purposes, you can imagine that if you add\nnoise to these three images,",
    "start": "3352630",
    "end": "3358480"
  },
  {
    "text": "you're going to get a density\nthat kind of looks like this. And then you can imagine-- let's\nsay you're trying to denoise.",
    "start": "3358480",
    "end": "3365859"
  },
  {
    "text": "And what we've just shown is\nthat the best way to denoise is to follow the gradient.",
    "start": "3365860",
    "end": "3371589"
  },
  {
    "text": "So if somehow somebody gives you\na data point to the left here,",
    "start": "3371590",
    "end": "3376630"
  },
  {
    "text": "how should you denoise it? You should follow\nthe gradient to try to go towards high probability\nregions, which makes sense.",
    "start": "3376630",
    "end": "3385130"
  },
  {
    "text": "You're trying to denoise. Try to change the image, and\npush it towards high probability regions.",
    "start": "3385130",
    "end": "3390569"
  },
  {
    "text": "And in fact, the optimal\ndenoising strategy is to take the noisy\nsample and follow a step",
    "start": "3390570",
    "end": "3397260"
  },
  {
    "text": "plus with the right scaling. But, basically,\nfollow the gradient of the log-perturbed\ndata density.",
    "start": "3397260",
    "end": "3404550"
  },
  {
    "text": "Is it based on the assumption\nthat the expectation of the noise is zero\nor something like that?",
    "start": "3404550",
    "end": "3411720"
  },
  {
    "text": "Because there's not-- I mean, there must be some sort\nof-- like you said the gradient",
    "start": "3411720",
    "end": "3418230"
  },
  {
    "text": "must-- it must be some sort of\nconstraints on the noise.",
    "start": "3418230",
    "end": "3424059"
  },
  {
    "text": "Because if I can consider\ncoming up with noises where",
    "start": "3424060",
    "end": "3429330"
  },
  {
    "text": "the gradient might not be-- the gradient might not\nbe optimal for that. So for these results, the\ndenoising score matching stuff",
    "start": "3429330",
    "end": "3440820"
  },
  {
    "text": "is still true. What is good about\nGaussian is the following.",
    "start": "3440820",
    "end": "3448680"
  },
  {
    "text": "Maybe that will clarify. So, essentially, what\nyou can look at is--",
    "start": "3448680",
    "end": "3455130"
  },
  {
    "text": "there is the clean data. And then there is\nthe noisy data. And then there is the posterior\ndistribution of the clean data",
    "start": "3455130",
    "end": "3463520"
  },
  {
    "text": "given the noisy data. And we know the definition of\nthe noisy data distribution.",
    "start": "3463520",
    "end": "3471400"
  },
  {
    "text": "And, basically,\nTweedie's formula is telling you\nthat the expected--",
    "start": "3471400",
    "end": "3477566"
  },
  {
    "text": " given a noisy image\nx, the expected value",
    "start": "3477566",
    "end": "3485140"
  },
  {
    "text": "of the clean image is\ngiven by this expression. So if you want to\nminimize the L2 loss,",
    "start": "3485140",
    "end": "3491769"
  },
  {
    "text": "the best thing you\ncan do is to output the conditional expectation\nof x given x tilde.",
    "start": "3491770",
    "end": "3497089"
  },
  {
    "text": "And so from that perspective,\nyou want to follow the gradient.",
    "start": "3497090",
    "end": "3502680"
  },
  {
    "text": "And this particular\nversion of the formula is only true for Gaussians.",
    "start": "3502680",
    "end": "3511270"
  },
  {
    "text": "You just give it\nnoise do denoise that is there a notion\nthat if you keep denoising",
    "start": "3511270",
    "end": "3517450"
  },
  {
    "text": "noise, what would happen? So if you keep denoising noise-- so are you asking if\nyou have a lot of noise,",
    "start": "3517450",
    "end": "3524289"
  },
  {
    "text": "or if you keep\nrepeating the process? I guess, you start\nwith a bunch of noise and just keep\nletting it denoise. Yeah, so that's\ngoing to be basically",
    "start": "3524290",
    "end": "3530782"
  },
  {
    "text": "how we sample from the model. So that's going to come up soon. But, essentially,\nthat's how we're",
    "start": "3530782",
    "end": "3536515"
  },
  {
    "text": "going to keep\nfollowing the gradient or if we want to keep denoising. And that's going to\nbe MCMC in some sense.",
    "start": "3536515",
    "end": "3544182"
  },
  {
    "text": "And that's going to\nbe Langevin dynamics. And that's how we're going to\nproduce samples, basically.",
    "start": "3544182",
    "end": "3549460"
  },
  {
    "text": "Is how diffusion\nmodels [INAUDIBLE]?? ",
    "start": "3549460",
    "end": "3556549"
  },
  {
    "text": "Cool. So the other way to\nmake things efficient",
    "start": "3556550",
    "end": "3564030"
  },
  {
    "text": "is to take random projections. We still have time. So another alternative\nway of coming up",
    "start": "3564030",
    "end": "3572820"
  },
  {
    "text": "with an efficient approximation\nto the original score matching",
    "start": "3572820",
    "end": "3578100"
  },
  {
    "text": "loss that does not involve\ntraces of the Jacobians is to basically take\nrandom projections.",
    "start": "3578100",
    "end": "3585020"
  },
  {
    "text": "So you can imagine\nthat at the end of the day what\nwe're trying to do is we're trying to match\nthe estimated vector",
    "start": "3585020",
    "end": "3591079"
  },
  {
    "text": "field to the true vector field. And if the true vector-- if this vector fields\nare really the same,",
    "start": "3591080",
    "end": "3597680"
  },
  {
    "text": "then they should\nalso be the same if we project them along\nany kind of direction.",
    "start": "3597680",
    "end": "3603780"
  },
  {
    "text": "So you can take this\ndirection and this direction. And you can project the\narrows along that direction.",
    "start": "3603780",
    "end": "3612369"
  },
  {
    "text": "And if the vector fields are the\nsame, then they should match. The projections should match.",
    "start": "3612370",
    "end": "3619130"
  },
  {
    "text": "That's in particular if\nthese projections are just axis aligned, then individual\ncomponents of these vectors",
    "start": "3619130",
    "end": "3625100"
  },
  {
    "text": "should match.  And the idea is that working\non the projection space",
    "start": "3625100",
    "end": "3632955"
  },
  {
    "text": "is going to be much more\nefficient because now it's going to be a\none-dimensional problem.",
    "start": "3632955",
    "end": "3638830"
  },
  {
    "text": "And so that's the\ndefiance, basically, a variant of the\nFisher divergence,",
    "start": "3638830",
    "end": "3645160"
  },
  {
    "text": "which we call the Sliced\nFisher Divergence, which is exactly what we had before. But before comparing the\ndata to the model gradient,",
    "start": "3645160",
    "end": "3655090"
  },
  {
    "text": "we project them along\na random direction v.",
    "start": "3655090",
    "end": "3660280"
  },
  {
    "text": "So you randomly pick a direction\nv. And then at every data point, you compare the true\ngradient and the estimated",
    "start": "3660280",
    "end": "3668330"
  },
  {
    "text": "gradient along this\ndirection v. And note",
    "start": "3668330",
    "end": "3674140"
  },
  {
    "text": "that after you take this dot\nproduct, these are scalars. So these are no longer vectors. They are scalars.",
    "start": "3674140",
    "end": "3681220"
  },
  {
    "text": "And it turns out you can\nstill do integration by parts. And you end up with an objective\nfunction that looks like this.",
    "start": "3681220",
    "end": "3690010"
  },
  {
    "text": "And it still involves\nthe Jacobian. But, crucially, now\nit involves basically",
    "start": "3690010",
    "end": "3696490"
  },
  {
    "text": "Jacobian vector products,\nwhich are basically directional derivatives\nand are things",
    "start": "3696490",
    "end": "3702190"
  },
  {
    "text": "that you can estimate using\nbackpropagation efficiently. So the second term is just\nthe usual thing, is efficient.",
    "start": "3702190",
    "end": "3710900"
  },
  {
    "text": "It's just the output of\nthe network times dot product with a random vector. So that's efficient to evaluate.",
    "start": "3710900",
    "end": "3717910"
  },
  {
    "text": "Now we have something\nthat looks like this. We have this Jacobian matrix\nleft multiplied by this vector v",
    "start": "3717910",
    "end": "3724900"
  },
  {
    "text": "and right multiplied\nby the same vector v. And it turns out that,\nbasically, this thing is just",
    "start": "3724900",
    "end": "3731349"
  },
  {
    "text": "a directional derivative. And that's something you can\ncompute with backpropagation efficiently.",
    "start": "3731350",
    "end": "3737440"
  },
  {
    "text": "So if you think about it,\nthis is the expression we started with, which\nyou can equivalently",
    "start": "3737440",
    "end": "3743319"
  },
  {
    "text": "write as the gradient\nof the dot product. And that's something that\nyou would compute like this.",
    "start": "3743320",
    "end": "3750780"
  },
  {
    "text": "So you have a forward pass\nthat computes s theta. Then you take the\ndot product with v.",
    "start": "3750780",
    "end": "3758420"
  },
  {
    "text": "And that gives you a scalar. Now you do a single\nbackpropagation to compute the gradient of\nthat scalar with respect",
    "start": "3758420",
    "end": "3766390"
  },
  {
    "text": "to all the inputs. And then you take another\ndot product to get back",
    "start": "3766390",
    "end": "3771970"
  },
  {
    "text": "the derivative or the quantity. So this can basically\nbe done roughly",
    "start": "3771970",
    "end": "3779480"
  },
  {
    "text": "at the cost of a single\nbackpropagation step. What is the projection\noperation [INAUDIBLE]??",
    "start": "3779480",
    "end": "3788560"
  },
  {
    "text": "Or it's just a\nvector dot product? It's a dot product. Dot product, I see.",
    "start": "3788560",
    "end": "3794960"
  },
  {
    "text": "Yeah. So it's like the v\nis pretty predefined. The v is sampled from\nsome distribution.",
    "start": "3794960",
    "end": "3802090"
  },
  {
    "text": "And let me see if\nI have it here. So this is what it\nwould look like.",
    "start": "3802090",
    "end": "3808269"
  },
  {
    "text": "It would sample data. For every data point, you would\nrandomly sample a direction",
    "start": "3808270",
    "end": "3813460"
  },
  {
    "text": "according to some distribution. And then you just optimize\nthis objective function,",
    "start": "3813460",
    "end": "3820130"
  },
  {
    "text": "which as we've seen is\ntractable to estimate. And it does not involve\ntrace of the Jacobian.",
    "start": "3820130",
    "end": "3826869"
  },
  {
    "text": "And there's a lot of\nflexibility in terms of choosing this pv, like how\ndo you choose the directions.",
    "start": "3826870",
    "end": "3834740"
  },
  {
    "text": "And you can choose, for example,\nGaussian or [? Rademacher ?] vectors. And they both work in theory.",
    "start": "3834740",
    "end": "3841730"
  },
  {
    "text": "Then the variance can vary. But, basically, there's\na lot of flexibility in terms of choosing\nthese random directions.",
    "start": "3841730",
    "end": "3849380"
  },
  {
    "text": " So, OK, with this one\nyou can run one backprop.",
    "start": "3849380",
    "end": "3855470"
  },
  {
    "text": "Why in the other case did we\nhave to run multiple backdrops? Because you have to compute--",
    "start": "3855470",
    "end": "3862660"
  },
  {
    "text": "before you had to compute\nthe partial derivatives of every output with\nrespect to every input. So you needed d backprops.",
    "start": "3862660",
    "end": "3869608"
  },
  {
    "text": "And here you can do a single\none because it's basically a directional derivative. ",
    "start": "3869608",
    "end": "3876290"
  },
  {
    "text": "Does it ever make sense to bias\nthe projections that you sample towards certain directions? Yeah. It seems like an intuitive--\nwe tried it for a long time",
    "start": "3876290",
    "end": "3883603"
  },
  {
    "text": "and never saw any\ndifference in practice. I don't have anything\nconclusive to say. It seems like a good\nidea but never worked.",
    "start": "3883603",
    "end": "3890569"
  },
  {
    "text": "So if you have a\nhigh-dimensional output vector space-- but then depending on the\nstructure of that output space,",
    "start": "3890570",
    "end": "3900323"
  },
  {
    "text": "there are going to be\ncertain directions where you have a lot of\nsignal and then probably many more\ndirections where you just",
    "start": "3900323",
    "end": "3906019"
  },
  {
    "text": "don't have a lot of signal. And so it seems to me that just\npicking a projection vector",
    "start": "3906020",
    "end": "3911510"
  },
  {
    "text": "from a Gaussian distribution\nwouldn't work very well. You would get some small\namount at the time.",
    "start": "3911510",
    "end": "3917869"
  },
  {
    "text": "You would get a high\nvalue of this projection. But some other larger\namount at the time, you would get a projection where\nyour signal or your information",
    "start": "3917870",
    "end": "3925790"
  },
  {
    "text": "was very, very low. And, yeah, I guess,\nhow does that work out in training or in practice?",
    "start": "3925790",
    "end": "3932010"
  },
  {
    "text": "Yeah, so, basically, these are\nessentially unbiased estimators",
    "start": "3932010",
    "end": "3937490"
  },
  {
    "text": "of the original objective. You can also think\nof it that way. There is variance that you're\nintroducing because you're sort of comparing\nprojections of the vectors",
    "start": "3937490",
    "end": "3945859"
  },
  {
    "text": "instead of comparing\nthe vectors fully, which is what the original\nscore matching loss would do.",
    "start": "3945860",
    "end": "3952380"
  },
  {
    "text": "And so that's the price\nyou pay, basically. And you can use variance\nreduction techniques",
    "start": "3952380",
    "end": "3958609"
  },
  {
    "text": "to actually make things\nmore stable in practice, different distributions.",
    "start": "3958610",
    "end": "3964380"
  },
  {
    "text": "Well, what you can\ndo is you can take-- if you are willing to pay a\nlittle bit more computation",
    "start": "3964380",
    "end": "3969740"
  },
  {
    "text": "cost, you can take\nmultiple random projections per data point. You can just try to\nmatch not just sample",
    "start": "3969740",
    "end": "3977279"
  },
  {
    "text": "every x1 along direction v1. But you can take a bunch of\nthem and then average them.",
    "start": "3977280",
    "end": "3983560"
  },
  {
    "text": "And so there is a natural\nway of reducing variance by taking more projections. But then it becomes\nmore expensive.",
    "start": "3983560",
    "end": "3989530"
  },
  {
    "text": "Eventually, if you\ntake n-projections where n is the\ndimensionality, and you can compare on every\nsingle coordinate,",
    "start": "3989530",
    "end": "3995770"
  },
  {
    "text": "it goes back to\nthe original one. And you are free to choose\nsomething in between. In practice, one\nprojection works.",
    "start": "3995770",
    "end": "4004500"
  },
  {
    "text": "So is the key idea why\nthis doesn't take-- [? on/od ?] time is that at\neach backpropagation step",
    "start": "4004500",
    "end": "4012360"
  },
  {
    "text": "we do the vector product,\nand it becomes one single-- It becomes a scalar. Yes, yes.",
    "start": "4012360",
    "end": "4018790"
  },
  {
    "text": "Exactly. Yeah. We do all of this projection\nwithout worrying about noise?",
    "start": "4018790",
    "end": "4024800"
  },
  {
    "text": " Here there is no noise. So the advantage of this\nis that you are actually",
    "start": "4024800",
    "end": "4031320"
  },
  {
    "text": "estimating the score of\nthe data density as opposed to the data density plus noise.",
    "start": "4031320",
    "end": "4037500"
  },
  {
    "text": "Yeah. And here you see\nsome plots showing",
    "start": "4037500",
    "end": "4043440"
  },
  {
    "text": "that if you do vanilla\nscore matching, how long it takes per iteration as a\nfunction of the data dimension.",
    "start": "4043440",
    "end": "4049980"
  },
  {
    "text": "It can go up to\n3, 400 dimensions. And then you run out of memory. This was a few years ago.",
    "start": "4049980",
    "end": "4055319"
  },
  {
    "text": "But it scales poorly linearly\nwith respect to the dimension. And if you have these\nsliced versions,",
    "start": "4055320",
    "end": "4061410"
  },
  {
    "text": "they are basically constant with\nrespect to the data dimension. And in terms of model\nquality, it actually",
    "start": "4061410",
    "end": "4070020"
  },
  {
    "text": "performs-- not super important\nwhat this graph means. But what you get with sliced\nversions of score matching",
    "start": "4070020",
    "end": "4076050"
  },
  {
    "text": "matches pretty much what you\nwould get with the exact score",
    "start": "4076050",
    "end": "4081210"
  },
  {
    "text": "matching objective. Now, the final thing\nI wanted to talk about",
    "start": "4081210",
    "end": "4087390"
  },
  {
    "text": "is actually how do\nwe do inference, how do we generate samples. Suppose that somehow\nwe are able to--",
    "start": "4087390",
    "end": "4094540"
  },
  {
    "text": "Question. Yeah, I just had one\nmore question on this, basically, creating the scalar\nand then doing one backprop.",
    "start": "4094540",
    "end": "4101220"
  },
  {
    "text": "Why do you do this\nwith a random vector not with just a scalar product\nwith the corresponding--",
    "start": "4101220",
    "end": "4107259"
  },
  {
    "text": "so you have predicted\nthis gradient, right? And you know, basically, the\ngradient of the actual gradient,",
    "start": "4107260",
    "end": "4113247"
  },
  {
    "text": "the ground truth gradient. You don't know it. But didn't we take the\nL2 norm previously?",
    "start": "4113247",
    "end": "4119580"
  },
  {
    "text": "Yeah, so you still need to do\nthe integration by parts trick. This one you don't know it.",
    "start": "4119580",
    "end": "4125080"
  },
  {
    "text": "So the original loss would\nbasically just take-- at every x, you\ntake the dot product with the true gradient,\nthe estimated gradient.",
    "start": "4125080",
    "end": "4131939"
  },
  {
    "text": "And then you square\nthe difference. You can't evaluate\nthat loss because it",
    "start": "4131939",
    "end": "4138100"
  },
  {
    "text": "depends on the true gradient,\nwhich you don't know. But then you can do\nintegration by parts. And you can rewrite it\nas this thing, which",
    "start": "4138100",
    "end": "4146200"
  },
  {
    "text": "is like what we had before. And it no longer depends\non the true score. ",
    "start": "4146200",
    "end": "4153710"
  },
  {
    "text": "Cool. So the thing I wanted to talk\nabout is how to do sampling. So let's say that somehow\nyou've used the real vanilla",
    "start": "4153710",
    "end": "4164979"
  },
  {
    "text": "score matching or\ndenoising score matching or SLI score\nmatching, and you are able to train your neural\nnetwork as theta so",
    "start": "4164979",
    "end": "4173500"
  },
  {
    "text": "that the estimated\nvector field of gradients is close to the true vector\nfield of gradients of the data",
    "start": "4173500",
    "end": "4180220"
  },
  {
    "text": "density-- The question is,\nhow do you use this?",
    "start": "4180220",
    "end": "4185470"
  },
  {
    "text": "You no longer have\naccess to a likelihood. There is no\nautoregressive generation.",
    "start": "4185470",
    "end": "4191560"
  },
  {
    "text": "How do you generate samples? And so the intuition is that\nthe scores are basically",
    "start": "4191560",
    "end": "4200020"
  },
  {
    "text": "telling you in\nwhich direction you should perturb a sample to\nincrease its likelihood most",
    "start": "4200020",
    "end": "4207190"
  },
  {
    "text": "rapidly. And so you could imagine\na basic procedure",
    "start": "4207190",
    "end": "4212950"
  },
  {
    "text": "where an MCMC procedure, like\nwhat we talked about before, where you initialize\nparticles at random.",
    "start": "4212950",
    "end": "4223030"
  },
  {
    "text": "And here I'm showing\nmultiple particles. But you could\nimagine sampling x0",
    "start": "4223030",
    "end": "4229210"
  },
  {
    "text": "based on some\ninitial distribution. Then you could\nimagine repeatedly",
    "start": "4229210",
    "end": "4237010"
  },
  {
    "text": "taking this update\nwhere you're basically taking a step in the direction\nof the estimated gradient.",
    "start": "4237010",
    "end": "4242900"
  },
  {
    "text": "So we just do gradient ascent\nusing the estimated scores to decide the direction.",
    "start": "4242900",
    "end": "4250540"
  },
  {
    "text": "And if you do that, you can-- you're going to get\nsomething like this, where the particles\nwill all converge",
    "start": "4250540",
    "end": "4258880"
  },
  {
    "text": "in this local optima,\nthe local maxima, hopefully, of this density,\nwhich is kind of right.",
    "start": "4258880",
    "end": "4268290"
  },
  {
    "text": "You could imagine you start\nwith random noise, which is an image which is pure noise.",
    "start": "4268290",
    "end": "4273330"
  },
  {
    "text": "And then you follow the gradient\nuntil you reach a local optimum where you can no longer improve.",
    "start": "4273330",
    "end": "4279750"
  },
  {
    "text": "We know that that's not the\nright way to generate a sample. The right way to\ngenerate a sample is to follow the noisy gradient.",
    "start": "4279750",
    "end": "4287100"
  },
  {
    "text": "That's what we call Langevin\nMCMC, which is exactly the same procedure,\nexcept that we also",
    "start": "4287100",
    "end": "4293850"
  },
  {
    "text": "add a little bit of Gaussian\nnoise at every step. And if you do that,\nthen you'll see",
    "start": "4293850",
    "end": "4299460"
  },
  {
    "text": "that we'll actually generate-- when you run it for long\nenough, this procedure is guaranteed to produce samples\nfrom the underlying density.",
    "start": "4299460",
    "end": "4310220"
  },
  {
    "text": "So remember that this vector\nfield corresponded to a density where we have a lot\nof probability mass",
    "start": "4310220",
    "end": "4315680"
  },
  {
    "text": "here, a lot of\nprobability mass there. And, indeed, if you look at the\ndistribution of these particles, they're going to have\nthe right distribution",
    "start": "4315680",
    "end": "4324194"
  },
  {
    "text": "because what we've seen is\nthat these Langevin dynamics sampling is a valid MCMC\nprocedure in the limit.",
    "start": "4324194",
    "end": "4331600"
  },
  {
    "text": "So it's a way of sampling\nfrom a density when you only have access to the score.",
    "start": "4331600",
    "end": "4338220"
  },
  {
    "text": "So we know that if you\ninitialize your particle, it doesn't matter how you do it.",
    "start": "4338220",
    "end": "4343980"
  },
  {
    "text": "And then you repeat this process\nof following the noisy gradient. ",
    "start": "4343980",
    "end": "4351570"
  },
  {
    "text": "In the limit of small step\nsizes, an infinite number of steps, this will give you\na sample from the underlying",
    "start": "4351570",
    "end": "4358830"
  },
  {
    "text": "density. So literally all we're doing\nis replacing the true score",
    "start": "4358830",
    "end": "4364280"
  },
  {
    "text": "function with the\nestimated score function. And, basically, that's one\nway of generating samples.",
    "start": "4364280",
    "end": "4375200"
  },
  {
    "text": "Your first estimate the score by\nscore matching trying to match-- have this neural network output\narrows, output gradients,",
    "start": "4375200",
    "end": "4384020"
  },
  {
    "text": "that are close to the true one. And then you just\nfollow the directions. ",
    "start": "4384020",
    "end": "4390050"
  },
  {
    "text": "And to the extent that\nyou've done a good job at estimating the\ngradient and to the extent",
    "start": "4390050",
    "end": "4395389"
  },
  {
    "text": "that these technical\nconditions are satisfied, this would produce\na valid sample.",
    "start": "4395390",
    "end": "4400675"
  },
  {
    "text": " And so that's basically\nthe full picture.",
    "start": "4400675",
    "end": "4408122"
  },
  {
    "text": "The full pipeline is\nyou start with data. You estimate the score. And you generate\nsamples by, basically,",
    "start": "4408122",
    "end": "4414760"
  },
  {
    "text": "following the score, which\ncorresponds to removing noise",
    "start": "4414760",
    "end": "4420342"
  },
  {
    "text": "because we know that the score\nis telling you the direction that you should follow if\nyou want to remove noise. And so back to what we\nwere discussing before,",
    "start": "4420342",
    "end": "4427682"
  },
  {
    "text": "it has a little\nbit of this flavor of removing noise and then\nadding noise because that's what",
    "start": "4427683",
    "end": "4434580"
  },
  {
    "text": "Langevin is telling you to do. ",
    "start": "4434580",
    "end": "4439889"
  },
  {
    "text": "And, unfortunately, if you\njust do this, it doesn't work. So this is what you get\nif you use this procedure.",
    "start": "4439890",
    "end": "4447000"
  },
  {
    "text": "You train a model on MNIST. Even a simple data set,\nMNIST, CelebA, CIFAR-10",
    "start": "4447000",
    "end": "4452010"
  },
  {
    "text": "just doesn't work. And this is what the Langevin\nprocedure looks like.",
    "start": "4452010",
    "end": "4458710"
  },
  {
    "text": "You start with pure noise. And then it gets\nstuck somewhere.",
    "start": "4458710",
    "end": "4464580"
  },
  {
    "text": "But it doesn't\nproduce good samples. And there are several\nreasons for this.",
    "start": "4464580",
    "end": "4474000"
  },
  {
    "text": "One is that basically\ndata tends to-- real world data tends to, basically,\nlie on a manifold.",
    "start": "4474000",
    "end": "4480875"
  },
  {
    "text": " And if the data is\nreally on a manifold,",
    "start": "4480875",
    "end": "4486949"
  },
  {
    "text": "the score might not be defined. And you can see\nthis intuitively. Imagine you have a density that\nis concentrated on a ring--",
    "start": "4486950",
    "end": "4497159"
  },
  {
    "text": "as you make the ring\nthinner and thinner, the magnitude of the gradient\ngets bigger and bigger.",
    "start": "4497160",
    "end": "4502620"
  },
  {
    "text": "And at some point,\nit becomes undefined. And so that's a problem.",
    "start": "4502620",
    "end": "4509500"
  },
  {
    "text": "And, indeed, real\ndata tends to lie on low-dimensional manifolds.",
    "start": "4509500",
    "end": "4515770"
  },
  {
    "text": "If you just take MNIST samples,\nand then you take the first 595",
    "start": "4515770",
    "end": "4521950"
  },
  {
    "text": "PCA components-- so you project it down\non a linear manifold of dimension 595--",
    "start": "4521950",
    "end": "4529510"
  },
  {
    "text": "there is almost no difference. So it basically\nmeans that, indeed,",
    "start": "4529510",
    "end": "4538360"
  },
  {
    "text": "even if you restrict\nyourself to linear manifolds that you can get with PCA,\nthere is almost no loss.",
    "start": "4538360",
    "end": "4543730"
  },
  {
    "text": "And if you take\nCIFAR-10, and you take a 2,165\ndimensional manifold,",
    "start": "4543730",
    "end": "4549700"
  },
  {
    "text": "again, almost no difference\nafter you project the data. So it seems like,\nindeed, that's an issue.",
    "start": "4549700",
    "end": "4560000"
  },
  {
    "text": "And you can see if you look at\nthe training curve on CIFAR-10, that's the score matching loss.",
    "start": "4560000",
    "end": "4565590"
  },
  {
    "text": "It's very, very bumpy. And it doesn't quite train. The other issue, which\nwas hinted at before,",
    "start": "4565590",
    "end": "4574739"
  },
  {
    "text": "is that if you think\nabout it, we're going to have problems in\nthe low data density regions,",
    "start": "4574740",
    "end": "4580950"
  },
  {
    "text": "because if you think\nabout points that are likely under the\ndata distribution,",
    "start": "4580950",
    "end": "4586650"
  },
  {
    "text": "we're going to get a lot of\nsamples from those regions.",
    "start": "4586650",
    "end": "4592580"
  },
  {
    "text": "If you think about\nthe loss, the loss is an expectation with respect\nto the data distribution of the difference\nbetween the estimated",
    "start": "4592580",
    "end": "4599330"
  },
  {
    "text": "gradient and the true gradient. But with this expectation,\nwe're approximating it",
    "start": "4599330",
    "end": "4607280"
  },
  {
    "text": "with a sample average. And most of our samples\nare going to come-- let's say, are\ngoing to be up here",
    "start": "4607280",
    "end": "4613010"
  },
  {
    "text": "and are going to be down here. And we're never going to\nsee samples in between.",
    "start": "4613010",
    "end": "4618700"
  },
  {
    "text": "And so if you think\nabout the loss, the neural network\nis going to have a pretty hard time estimating\nthe gradients in between.",
    "start": "4618700",
    "end": "4626500"
  },
  {
    "text": "And you can see here an example\nwhere we have the true data scores in the middle panel\nand the estimated data",
    "start": "4626500",
    "end": "4633850"
  },
  {
    "text": "scores on the right panel. And you can see that\nthe arrows, they match pretty well at the\ncorners where we're going",
    "start": "4633850",
    "end": "4640120"
  },
  {
    "text": "to see a lot of training data. But they're pretty\nbad the moment you go away from the high\ndata density regions.",
    "start": "4640120",
    "end": "4647429"
  },
  {
    "text": " Is there some way\nwhen you're doing",
    "start": "4647430",
    "end": "4652880"
  },
  {
    "text": "this MCMC to want smaller\nvector field directory?",
    "start": "4652880",
    "end": "4661130"
  },
  {
    "text": "So if you sample the whole\nthing, it'll be like, oh, wait, the bottom of one of\nthe top right corner have really small arrows.",
    "start": "4661130",
    "end": "4667647"
  },
  {
    "text": "So then I want more there. So just, generically, what's\nmore there than [INAUDIBLE]?? Yeah, the problem is\nhow do you find it.",
    "start": "4667647",
    "end": "4674150"
  },
  {
    "text": "And, I guess, one\nway to try to go to-- you're trying to find\nstationary points or trying to maximize, I\nguess, the log likelihood.",
    "start": "4674150",
    "end": "4680480"
  },
  {
    "text": "And it's not obvious\nhow you would do it. You could do gradient ascent\nand try to find a local maximum.",
    "start": "4680480",
    "end": "4688468"
  },
  {
    "text": "But the problem is that\nthe gradient is not estimated accurately. If you imagine randomly\ninitializing a data point,",
    "start": "4688468",
    "end": "4695539"
  },
  {
    "text": "very likely you're going to be\ninitializing in the red region. And then you're going\nto follow the gradients.",
    "start": "4695540",
    "end": "4701550"
  },
  {
    "text": "But the gradients\nare not accurate because they're estimated\nvery inaccurately. And then your Langevin\ndynamics procedure",
    "start": "4701550",
    "end": "4707030"
  },
  {
    "text": "would get lost, basically. What happens is that, if you\nthink about those particles,",
    "start": "4707030",
    "end": "4715560"
  },
  {
    "text": "a lot of those particles\nstarts out here. And you're going to\nfollow these arrows. But the arrows are pointing\nyou in the wrong direction.",
    "start": "4715560",
    "end": "4722730"
  },
  {
    "text": "So you're never going to be able\nto reach this high data density",
    "start": "4722730",
    "end": "4727800"
  },
  {
    "text": "regions by following the\nwrong instructions somehow. ",
    "start": "4727800",
    "end": "4736090"
  },
  {
    "text": "Yeah? What if we just initialize\nat one of our data points, would that help? You could try to initialize\nthrough one of the data points.",
    "start": "4736090",
    "end": "4743200"
  },
  {
    "text": "The problem is that\nstill then it's not going to mix, which is what's\ngoing to come up next that even",
    "start": "4743200",
    "end": "4750230"
  },
  {
    "text": "though Langevin dynamics,\nin theory, converges, it can take a very long time. And you can see the\nextreme case here,",
    "start": "4750230",
    "end": "4757250"
  },
  {
    "text": "where if you have\na data density that is like a mixture of two\ndistributions, where the mixture",
    "start": "4757250",
    "end": "4766180"
  },
  {
    "text": "weights are pi and 1\nminus pi but crucially, p1 and p2 have\ndisjoint support--",
    "start": "4766180",
    "end": "4771660"
  },
  {
    "text": " and so, basically, you\nhave probability pi--",
    "start": "4771660",
    "end": "4781210"
  },
  {
    "text": "[? pp1 ?] when you are in a. And you have 1 minus pi\np2 when you are in b. So there's two sets\nthat are disjoint.",
    "start": "4781210",
    "end": "4787870"
  },
  {
    "text": "And you have a mixture\nof two distributions that are with disjoint supports. Think of a mixture of\ntwo uniform distributions",
    "start": "4787870",
    "end": "4794140"
  },
  {
    "text": "with two disjoint supports. If you look at the\nscore function,",
    "start": "4794140",
    "end": "4800020"
  },
  {
    "text": "you'll see it has\nthis expression. This is the log of\nthis in the support",
    "start": "4800020",
    "end": "4807970"
  },
  {
    "text": "of the first distribution\nand the log of this in the support of the\nsecond distribution. And you can see that when you\ntake the gradient with respect",
    "start": "4807970",
    "end": "4815290"
  },
  {
    "text": "to x, the pi disappears. So it does not\ndepend on the weight",
    "start": "4815290",
    "end": "4822849"
  },
  {
    "text": "that you put on the\ntwo mixture modes. And so the problem here is that\nthe score function does not",
    "start": "4822850",
    "end": "4831430"
  },
  {
    "text": "depend on the weighting\ncoefficient at all. So if you were to sample just\nusing the score function, you would not be able to recover\nwhat is the relative probability",
    "start": "4831430",
    "end": "4839380"
  },
  {
    "text": "that you assign to the first\nmode versus the second mode. This is like an extreme\ncase of Langevin",
    "start": "4839380",
    "end": "4846760"
  },
  {
    "text": "not even mixing, basically. And, yeah, basically,\nif you're not Langevin,",
    "start": "4846760",
    "end": "4853810"
  },
  {
    "text": "it will not reflect pi. And here you can see an example\nof this where the true samples--",
    "start": "4853810",
    "end": "4860530"
  },
  {
    "text": "there is more samples\nup here than down here. So this p1 is maybe--",
    "start": "4860530",
    "end": "4867690"
  },
  {
    "text": "2/3 of them are up here. And one third are down here. If you just run Langevin, you\nend up with half and half.",
    "start": "4867690",
    "end": "4875219"
  },
  {
    "text": "So it's not reflecting\nthe right weight. And that's basically an\nindication that, again, Langevin",
    "start": "4875220",
    "end": "4882390"
  },
  {
    "text": "is mixing too slowly. And, yeah, then what we'll\nsee in the next lecture",
    "start": "4882390",
    "end": "4888300"
  },
  {
    "text": "is a way to fix it that\nwill actually make it work. And that's the idea behind\ndiffusion models, which",
    "start": "4888300",
    "end": "4893790"
  },
  {
    "text": "is to essentially\nfigure out a way to estimate these scores more\naccurately all over the space",
    "start": "4893790",
    "end": "4901889"
  },
  {
    "text": "and get better guidance. And that will actually\nfix this problem. And we'll get to the state\nof the art diffusion models.",
    "start": "4901890",
    "end": "4910520"
  },
  {
    "start": "4910520",
    "end": "4915000"
  }
]
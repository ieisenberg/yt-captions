[
  {
    "text": "So what we are going to, uh,",
    "start": "4130",
    "end": "7125"
  },
  {
    "text": "discuss today is, uh, three topics.",
    "start": "7125",
    "end": "10260"
  },
  {
    "text": "First, I'm going to give a basic overview",
    "start": "10260",
    "end": "13469"
  },
  {
    "text": "of rudimentary deep learning neural network concepts.",
    "start": "13469",
    "end": "17070"
  },
  {
    "text": "Uh, and this will be important so that we all get on the same page.",
    "start": "17070",
    "end": "20235"
  },
  {
    "text": "And then I'm going to spend majority of the time talking about",
    "start": "20235",
    "end": "23400"
  },
  {
    "text": "deep learning for graphs and this concept of graph neural networks.",
    "start": "23400",
    "end": "26625"
  },
  {
    "text": "And then I'm going to discuss two specific, uh, architectures.",
    "start": "26625",
    "end": "30270"
  },
  {
    "text": "One is called graph convolutional networks and the other one is called,",
    "start": "30270",
    "end": "34275"
  },
  {
    "text": "uh, GraphSAGE, uh, to give you some intuition.",
    "start": "34275",
    "end": "36780"
  },
  {
    "text": "And then through, uh,",
    "start": "36780",
    "end": "38460"
  },
  {
    "text": "uh- through then series of the next lectures,",
    "start": "38460",
    "end": "40820"
  },
  {
    "text": "we are then going to go more in- deeper into the theory,",
    "start": "40820",
    "end": "43579"
  },
  {
    "text": "more go- deeper into different applications, different,",
    "start": "43580",
    "end": "46380"
  },
  {
    "text": "uh- different architectures, different design choices, um, and so on.",
    "start": "46380",
    "end": "50120"
  },
  {
    "text": "So we are going to talk about this graph neural networks topic,",
    "start": "50120",
    "end": "53320"
  },
  {
    "text": "uh, for the- for the next,",
    "start": "53320",
    "end": "54930"
  },
  {
    "text": "uh, couple of lectures.",
    "start": "54930",
    "end": "56525"
  },
  {
    "text": "So let's talk about, uh,",
    "start": "56525",
    "end": "59405"
  },
  {
    "text": "basics or do a quick tutorial introduction,",
    "start": "59405",
    "end": "62059"
  },
  {
    "text": "uh, to deep learning and deep neural networks.",
    "start": "62060",
    "end": "64555"
  },
  {
    "text": "So we will think of machine learning,",
    "start": "64555",
    "end": "67325"
  },
  {
    "text": "uh, supervised learning as an optimization problem.",
    "start": "67325",
    "end": "70409"
  },
  {
    "text": "So the idea is that we are given some inputs x,",
    "start": "70410",
    "end": "73250"
  },
  {
    "text": "and the goal is to predict or to produce outputs, uh, y.",
    "start": "73250",
    "end": "77395"
  },
  {
    "text": "And these outputs y we will call labels or classes and so on.",
    "start": "77395",
    "end": "81244"
  },
  {
    "text": "Um, and x can be represented in different ways.",
    "start": "81245",
    "end": "84015"
  },
  {
    "text": "X can be a vector of real numbers.",
    "start": "84015",
    "end": "86555"
  },
  {
    "text": "X can be a sequence,",
    "start": "86555",
    "end": "88310"
  },
  {
    "text": "like a natural language sequence,",
    "start": "88310",
    "end": "89750"
  },
  {
    "text": "sequence of word, sequence of tokens, voices.",
    "start": "89750",
    "end": "92650"
  },
  {
    "text": "It can be matrices,",
    "start": "92650",
    "end": "94310"
  },
  {
    "text": "meaning it can be a fixed size matrix like a-",
    "start": "94310",
    "end": "96680"
  },
  {
    "text": "the images that are already sized to be the same size.",
    "start": "96680",
    "end": "99620"
  },
  {
    "text": "Or it can be also an entire graph,",
    "start": "99620",
    "end": "102445"
  },
  {
    "text": "um, or a node in a graph,",
    "start": "102445",
    "end": "103995"
  },
  {
    "text": "which is what we will be, uh,",
    "start": "103995",
    "end": "105525"
  },
  {
    "text": "interested in, uh, later down,",
    "start": "105525",
    "end": "107610"
  },
  {
    "text": "uh, in the lecture today.",
    "start": "107610",
    "end": "109065"
  },
  {
    "text": "And then, right, the goal is that we want to map this abstract x,",
    "start": "109065",
    "end": "112730"
  },
  {
    "text": "whatever it is into the label y.",
    "start": "112730",
    "end": "115140"
  },
  {
    "text": "So we wanna be able to predict, uh, the label y.",
    "start": "115140",
    "end": "117375"
  },
  {
    "text": "And we are going to, uh,",
    "start": "117375",
    "end": "119415"
  },
  {
    "text": "need to learn this function that makes this mapping.",
    "start": "119415",
    "end": "121880"
  },
  {
    "text": "And we are going to formulate learning of this function as an optimization problem.",
    "start": "121880",
    "end": "126954"
  },
  {
    "text": "So we formulated as an optimization problem in",
    "start": "126955",
    "end": "130280"
  },
  {
    "text": "a sense that we say this function f that we are interested in,",
    "start": "130280",
    "end": "133640"
  },
  {
    "text": "that will take input x and produ- produce output",
    "start": "133640",
    "end": "136580"
  },
  {
    "text": "y would be parameterized by some parameters Theta.",
    "start": "136580",
    "end": "139820"
  },
  {
    "text": "And our goal will be that we will define this notion of a loss,",
    "start": "139820",
    "end": "143900"
  },
  {
    "text": "um, that we will say what is",
    "start": "143900",
    "end": "145879"
  },
  {
    "text": "the discrepancy between the predicted value and the true value?",
    "start": "145880",
    "end": "149080"
  },
  {
    "text": "So there are two important,",
    "start": "149080",
    "end": "152055"
  },
  {
    "text": "uh, things here, right?",
    "start": "152055",
    "end": "153689"
  },
  {
    "text": "Is that first, we are going to say, let's minimize, uh,",
    "start": "153690",
    "end": "157260"
  },
  {
    "text": "over these model parameters, uh,",
    "start": "157260",
    "end": "159705"
  },
  {
    "text": "Theta such that this discrepancy,",
    "start": "159705",
    "end": "161960"
  },
  {
    "text": "this loss is minimized.",
    "start": "161960",
    "end": "163749"
  },
  {
    "text": "So, uh, Theta is a set of parameters,",
    "start": "163749",
    "end": "166439"
  },
  {
    "text": "uh, we want to optimize.",
    "start": "166440",
    "end": "167850"
  },
  {
    "text": "Uh, you know, this could be a scalar value,",
    "start": "167850",
    "end": "171515"
  },
  {
    "text": "a vector, an entire matrix,",
    "start": "171515",
    "end": "173465"
  },
  {
    "text": "or a set of matrices.",
    "start": "173465",
    "end": "175090"
  },
  {
    "text": "Uh, and for example,",
    "start": "175090",
    "end": "176250"
  },
  {
    "text": "if you think in these, uh- uh,",
    "start": "176250",
    "end": "177780"
  },
  {
    "text": "laws-based framework, um, our, um, uh, deep,",
    "start": "177780",
    "end": "183675"
  },
  {
    "text": "uh- shallow encoders like, uh,",
    "start": "183675",
    "end": "185910"
  },
  {
    "text": "DeepWalk and node2vec ,",
    "start": "185910",
    "end": "187470"
  },
  {
    "text": "they're- in their- in those- those cases,",
    "start": "187470",
    "end": "189575"
  },
  {
    "text": "our parameter matrix Theta was really",
    "start": "189575",
    "end": "192379"
  },
  {
    "text": "the embedding matrix z in the shallower encoder case, right?",
    "start": "192380",
    "end": "196250"
  },
  {
    "text": "So- so Theta is just a generic, uh,",
    "start": "196250",
    "end": "198575"
  },
  {
    "text": "symbol to describe the parameters of the model.",
    "start": "198575",
    "end": "201805"
  },
  {
    "text": "And then loss function, as I said,",
    "start": "201805",
    "end": "203689"
  },
  {
    "text": "measures the or quantifies the discrepancy",
    "start": "203690",
    "end": "206690"
  },
  {
    "text": "between the predicted value and the re- and the, uh, true value.",
    "start": "206690",
    "end": "209900"
  },
  {
    "text": "So for example, um,",
    "start": "209900",
    "end": "211174"
  },
  {
    "text": "if you think about a regression,",
    "start": "211175",
    "end": "213289"
  },
  {
    "text": "so predicting real value numbers,",
    "start": "213289",
    "end": "215725"
  },
  {
    "text": "then y is the correct prediction,",
    "start": "215725",
    "end": "218370"
  },
  {
    "text": "f of x is the prediction,",
    "start": "218370",
    "end": "220860"
  },
  {
    "text": "what our modulary terms,",
    "start": "220860",
    "end": "222315"
  },
  {
    "text": "and L2 loss is simply ,",
    "start": "222315",
    "end": "224685"
  },
  {
    "text": "uh,a square, uh, of the distance- of the difference between the two numbers, right?",
    "start": "224685",
    "end": "229040"
  },
  {
    "text": "So we would say, I want to- I want to find the model parameters Theta",
    "start": "229040",
    "end": "233069"
  },
  {
    "text": "so- so- such that the sum of the squares of the differences is as small as possible,",
    "start": "233070",
    "end": "237470"
  },
  {
    "text": "square differences between the true value and the predicted value.",
    "start": "237470",
    "end": "240905"
  },
  {
    "text": "And of course, there are many different types of losses one may want to,",
    "start": "240905",
    "end": "245310"
  },
  {
    "text": "uh, use depending on the problem,",
    "start": "245310",
    "end": "247160"
  },
  {
    "text": "whether it's a regression wets- whether it's like",
    "start": "247160",
    "end": "249080"
  },
  {
    "text": "classification, whether it is, you know,",
    "start": "249080",
    "end": "251180"
  },
  {
    "text": "this, uh, um- whether it is a ranking task,",
    "start": "251180",
    "end": "254239"
  },
  {
    "text": "whether it's a classification task.",
    "start": "254240",
    "end": "256390"
  },
  {
    "text": "Um, and, uh, here's the link where you can,",
    "start": "256390",
    "end": "259665"
  },
  {
    "text": "uh, uh, talk- learn more about various types of losses.",
    "start": "259665",
    "end": "263030"
  },
  {
    "text": "Um, I won't go more into details of this,",
    "start": "263030",
    "end": "265405"
  },
  {
    "text": "but, you know, we mostly work with,",
    "start": "265405",
    "end": "266940"
  },
  {
    "text": "uh, L2 loss, which is used for,",
    "start": "266940",
    "end": "269010"
  },
  {
    "text": "uh, regression most often.",
    "start": "269010",
    "end": "270860"
  },
  {
    "text": "So when we are trying to predict, uh,",
    "start": "270860",
    "end": "272270"
  },
  {
    "text": "real values, uh, or cross entropy loss,",
    "start": "272270",
    "end": "274759"
  },
  {
    "text": "which I'm going to define later,",
    "start": "274760",
    "end": "276125"
  },
  {
    "text": "which is all about classification,",
    "start": "276125",
    "end": "277670"
  },
  {
    "text": "which is like classifying, you know,",
    "start": "277670",
    "end": "278960"
  },
  {
    "text": "single colors, for example.",
    "start": "278960",
    "end": "281020"
  },
  {
    "text": "So now let me give you an example of a loss function, right?",
    "start": "281020",
    "end": "285139"
  },
  {
    "text": "One common, uh, loss function that we are interested in is called a cross entropy.",
    "start": "285140",
    "end": "289690"
  },
  {
    "text": "Um, and let's say that we are talking about multiclass classification,",
    "start": "289690",
    "end": "294170"
  },
  {
    "text": "so we can have multiple color- colors.",
    "start": "294170",
    "end": "296270"
  },
  {
    "text": "So in this case, let say we have five classes- five different colors.",
    "start": "296270",
    "end": "299425"
  },
  {
    "text": "So, uh, this means that we are going to encode the-",
    "start": "299425",
    "end": "302569"
  },
  {
    "text": "the color using what is called one-hot encoding,",
    "start": "302570",
    "end": "306695"
  },
  {
    "text": "which means that we will say, aha,",
    "start": "306695",
    "end": "308470"
  },
  {
    "text": "now what we are trying to predict,",
    "start": "308470",
    "end": "310250"
  },
  {
    "text": "we are trying to predict a vector of dimensionality five, where, you know,",
    "start": "310250",
    "end": "314540"
  },
  {
    "text": "the first they mentioned perhaps corresponds to blue,",
    "start": "314540",
    "end": "316670"
  },
  {
    "text": "second corresponds to red,",
    "start": "316670",
    "end": "318145"
  },
  {
    "text": "third corresponds to green,",
    "start": "318145",
    "end": "319569"
  },
  {
    "text": "fourth corresponds to black and I don't know,",
    "start": "319570",
    "end": "322030"
  },
  {
    "text": "uh, the last corresponds to white, right?",
    "start": "322030",
    "end": "324250"
  },
  {
    "text": "So now I have- and if I given node of interest is- is green,",
    "start": "324250",
    "end": "329095"
  },
  {
    "text": "then, you know, the third entry of this vector is set to one.",
    "start": "329095",
    "end": "332420"
  },
  {
    "text": "So this is now how I encode the, uh- uh,",
    "start": "332420",
    "end": "336145"
  },
  {
    "text": "the, the- the colors in using this what is called one-hot encoding because there's 1,",
    "start": "336145",
    "end": "341150"
  },
  {
    "text": "1 and the rest is zero,",
    "start": "341150",
    "end": "342910"
  },
  {
    "text": "and then I can say, aha,",
    "start": "342910",
    "end": "344750"
  },
  {
    "text": "what I am going to do is I'm going to model this now in some sense,",
    "start": "344750",
    "end": "348020"
  },
  {
    "text": "probability distribution over colors, um, using,",
    "start": "348020",
    "end": "351305"
  },
  {
    "text": "uh, a function f, that will be a softmax of some function g. Um,",
    "start": "351305",
    "end": "356580"
  },
  {
    "text": "and, you know, lecture 3,",
    "start": "356580",
    "end": "358000"
  },
  {
    "text": "we defined the notion of soft max,",
    "start": "358000",
    "end": "359945"
  },
  {
    "text": "which is simply you go over to the ne- over the entries,",
    "start": "359945",
    "end": "363425"
  },
  {
    "text": "you expo- exponentiate them, and,",
    "start": "363425",
    "end": "365870"
  },
  {
    "text": "uh, you make sure that they sum up to one, right?",
    "start": "365870",
    "end": "368449"
  },
  {
    "text": "So for example, in our case,",
    "start": "368450",
    "end": "370190"
  },
  {
    "text": "maybe f of x, uh,",
    "start": "370190",
    "end": "371630"
  },
  {
    "text": "after we put in, uh,",
    "start": "371630",
    "end": "373550"
  },
  {
    "text": "f, uh, de- denote x,",
    "start": "373550",
    "end": "376129"
  },
  {
    "text": "we would produce the set of numbers",
    "start": "376130",
    "end": "378365"
  },
  {
    "text": "where basically you would say 100 probability point, you know,",
    "start": "378365",
    "end": "381139"
  },
  {
    "text": "we think the color is blue,",
    "start": "381140",
    "end": "382400"
  },
  {
    "text": "which points three-eighths and had read 0.40 is green and so on and so forth.",
    "start": "382400",
    "end": "386500"
  },
  {
    "text": "So now, what we wanna do is we want to measure the quality of this prediction, right?",
    "start": "386500",
    "end": "391350"
  },
  {
    "text": "We wanna say, what is the discrepancy between",
    "start": "391350",
    "end": "394415"
  },
  {
    "text": "the predicted probability of being green and the- the item truly being green.",
    "start": "394415",
    "end": "399955"
  },
  {
    "text": "And the way we computed this is no- is- is, uh, denoted, uh,",
    "start": "399955",
    "end": "404159"
  },
  {
    "text": "or called cross entropy loss,",
    "start": "404160",
    "end": "406625"
  },
  {
    "text": "where basically we are seeing,",
    "start": "406625",
    "end": "407960"
  },
  {
    "text": "let's sum up over all the classes.",
    "start": "407960",
    "end": "410479"
  },
  {
    "text": "Um, you know, here,",
    "start": "410480",
    "end": "411540"
  },
  {
    "text": "we have five classes,",
    "start": "411540",
    "end": "412730"
  },
  {
    "text": "so C goes up to five.",
    "start": "412730",
    "end": "414095"
  },
  {
    "text": "We say white is y_i?",
    "start": "414095",
    "end": "415620"
  },
  {
    "text": "What is the true probability of",
    "start": "415620",
    "end": "417889"
  },
  {
    "text": "that class times the lock predicted probability of that plus, right?",
    "start": "417890",
    "end": "421490"
  },
  {
    "text": "So in this sense, what this means is y is the actual and",
    "start": "421490",
    "end": "425780"
  },
  {
    "text": "f of x is the predicted value of the ith glass or the ith color.",
    "start": "425780",
    "end": "430805"
  },
  {
    "text": "And to intuition is the lower the loss,",
    "start": "430805",
    "end": "432995"
  },
  {
    "text": "the closer the pred- prediction is to one-hot, right?",
    "start": "432995",
    "end": "435860"
  },
  {
    "text": "If- if the value here would be one,",
    "start": "435860",
    "end": "438139"
  },
  {
    "text": "then log of one is zero.",
    "start": "438140",
    "end": "440620"
  },
  {
    "text": "So we made the correct prediction.",
    "start": "440620",
    "end": "443585"
  },
  {
    "text": "So now that we have a loss- defined the loss or",
    "start": "443585",
    "end": "447740"
  },
  {
    "text": "a discrepancy over any individual example or an individual data point,",
    "start": "447740",
    "end": "452539"
  },
  {
    "text": "we can then define the notion of a total loss,",
    "start": "452540",
    "end": "455615"
  },
  {
    "text": "which is just a loss summed up over all the training examples.",
    "start": "455615",
    "end": "459964"
  },
  {
    "text": "So it's a total amount of discrepancy between the predicted value and the true value,",
    "start": "459964",
    "end": "465560"
  },
  {
    "text": "summed up over all the training examples, right?",
    "start": "465560",
    "end": "469095"
  },
  {
    "text": "And what we want, right,",
    "start": "469095",
    "end": "470700"
  },
  {
    "text": "we want to find our function f,",
    "start": "470700",
    "end": "472805"
  },
  {
    "text": "our parameters to function f Theta,",
    "start": "472805",
    "end": "475100"
  },
  {
    "text": "so that this total discrepancy between the true values and predicted values is minimized.",
    "start": "475100",
    "end": "480905"
  },
  {
    "text": "And in this case,",
    "start": "480905",
    "end": "482030"
  },
  {
    "text": "we measure the discrepancy, uh, ah, for each,",
    "start": "482030",
    "end": "486260"
  },
  {
    "text": "uh, data point, for each prediction using this notion of a cross entropy loss.",
    "start": "486260",
    "end": "491660"
  },
  {
    "text": "So that's essentially, uh, the idea.",
    "start": "491660",
    "end": "494495"
  },
  {
    "text": "So now that we have defined the notion of loss and we have defined the notion, uh,",
    "start": "494495",
    "end": "500209"
  },
  {
    "text": "of the optimization problem,",
    "start": "500209",
    "end": "502400"
  },
  {
    "text": "basically trying to model parameters that minimize the loss.",
    "start": "502400",
    "end": "505580"
  },
  {
    "text": "The next question is,",
    "start": "505580",
    "end": "506930"
  },
  {
    "text": "how do we optimize this objective function, right?",
    "start": "506930",
    "end": "510035"
  },
  {
    "text": "And a classic way to- to minimize objective functions goes through,",
    "start": "510035",
    "end": "515740"
  },
  {
    "text": "uh, various kinds of more or less advanced notions of gradient descent.",
    "start": "515740",
    "end": "520580"
  },
  {
    "text": "So this notion of a gradient,",
    "start": "520580",
    "end": "522385"
  },
  {
    "text": "notion of a derivative,",
    "start": "522385",
    "end": "523520"
  },
  {
    "text": "the becomes central and most important, right?",
    "start": "523520",
    "end": "526910"
  },
  {
    "text": "So recall that gradient vector, uh,",
    "start": "526910",
    "end": "529295"
  },
  {
    "text": "at the given point is a direction and the rate of fastest,",
    "start": "529295",
    "end": "533419"
  },
  {
    "text": "uh, increase of a function.",
    "start": "533419",
    "end": "534920"
  },
  {
    "text": "So I can say, aha, I have my loss function,",
    "start": "534920",
    "end": "537154"
  },
  {
    "text": "and now I can ask my loss function, I can evaluate it,",
    "start": "537155",
    "end": "540260"
  },
  {
    "text": "um, with respect to my parameters,",
    "start": "540260",
    "end": "543665"
  },
  {
    "text": "and I can- this will tell me if I'm right- if",
    "start": "543665",
    "end": "546199"
  },
  {
    "text": "my parameters have a certain value right now, um,",
    "start": "546200",
    "end": "549050"
  },
  {
    "text": "what is the direction in which,",
    "start": "549050",
    "end": "550970"
  },
  {
    "text": "um, this, uh- this,",
    "start": "550970",
    "end": "552649"
  },
  {
    "text": "uh objective function, this loss function would,",
    "start": "552650",
    "end": "555230"
  },
  {
    "text": "um- would increase the fastest.",
    "start": "555230",
    "end": "558285"
  },
  {
    "text": "And- and that is very important because this means",
    "start": "558285",
    "end": "562240"
  },
  {
    "text": "then that I can think about what is called a directional derivative,",
    "start": "562240",
    "end": "566110"
  },
  {
    "text": "which is a multi- of a multivariable function, like for example,",
    "start": "566110",
    "end": "569920"
  },
  {
    "text": "the loss function, which is um,",
    "start": "569920",
    "end": "571945"
  },
  {
    "text": "where the variable are our model parameters theta.",
    "start": "571945",
    "end": "575125"
  },
  {
    "text": "Basically, it, uh, it basically tells us that alo- at a given point,",
    "start": "575125",
    "end": "579310"
  },
  {
    "text": "along a given vector represents instantaneous rate of change of a function along,",
    "start": "579310",
    "end": "584320"
  },
  {
    "text": "uh, at that vector.",
    "start": "584320",
    "end": "585580"
  },
  {
    "text": "So this means that I can now say given my current parameters,",
    "start": "585580",
    "end": "589630"
  },
  {
    "text": "in which direction should I change them such that the loss will decrease the most,",
    "start": "589630",
    "end": "596650"
  },
  {
    "text": "and that's essentially, uh,",
    "start": "596650",
    "end": "598435"
  },
  {
    "text": "what we are trying to do, right.",
    "start": "598435",
    "end": "599710"
  },
  {
    "text": "We would say we have a current estimate of our parameters,",
    "start": "599710",
    "end": "602500"
  },
  {
    "text": "let's compute the directional derivative of",
    "start": "602500",
    "end": "605350"
  },
  {
    "text": "our loss function surface or up that point where we are,",
    "start": "605350",
    "end": "609490"
  },
  {
    "text": "and then we are going to move into the direction, um,",
    "start": "609490",
    "end": "612730"
  },
  {
    "text": "of the fastest decrease of the loss and hopefully reach some good local,",
    "start": "612730",
    "end": "618878"
  },
  {
    "text": "uh, solution or a global minimum solution.",
    "start": "618879",
    "end": "621865"
  },
  {
    "text": "So gradient evaluated for the given point is the direction or derivative,",
    "start": "621865",
    "end": "626350"
  },
  {
    "text": "um, that gives me the direction of the largest increase, right.",
    "start": "626350",
    "end": "631345"
  },
  {
    "text": "Um, we are not interested in the increase,",
    "start": "631345",
    "end": "634060"
  },
  {
    "text": "we are interested in the decrease,",
    "start": "634060",
    "end": "636479"
  },
  {
    "text": "so we are going to walk in the direction opposite of the gradient.",
    "start": "636479",
    "end": "640140"
  },
  {
    "text": "We are going to walk- walk down,",
    "start": "640140",
    "end": "641925"
  },
  {
    "text": "not walk up, in terms of the gradient, uh, update.",
    "start": "641925",
    "end": "645410"
  },
  {
    "text": "Right. So a way how we think about this is to use",
    "start": "645410",
    "end": "648160"
  },
  {
    "text": "the algorithm called gradient, uh, descent.",
    "start": "648160",
    "end": "650935"
  },
  {
    "text": "This is the most basic version and then everything just kind of,",
    "start": "650935",
    "end": "653500"
  },
  {
    "text": "uh, uses the same intuition,",
    "start": "653500",
    "end": "655330"
  },
  {
    "text": "but it's just an improved over this.",
    "start": "655330",
    "end": "657055"
  },
  {
    "text": "And essentially, what this is saying is let me, uh,",
    "start": "657055",
    "end": "660205"
  },
  {
    "text": "repeatedly update the weights or the parameters of the model",
    "start": "660205",
    "end": "663565"
  },
  {
    "text": "in the opposite direction of the gradients until I converge, right.",
    "start": "663565",
    "end": "667030"
  },
  {
    "text": "So I say I have my current estimate of the grade- of the parameters,",
    "start": "667030",
    "end": "671530"
  },
  {
    "text": "let me evaluate the gradient, uh,",
    "start": "671530",
    "end": "675505"
  },
  {
    "text": "the derivative of the loss function at that, uh,",
    "start": "675505",
    "end": "679030"
  },
  {
    "text": "set of parameters at that point where my parameters currently are.",
    "start": "679030",
    "end": "682990"
  },
  {
    "text": "And then, you know, let me make a step in the direction that is opposite of the gradient.",
    "start": "682990",
    "end": "687790"
  },
  {
    "text": "So that's why I had minus here.",
    "start": "687790",
    "end": "689350"
  },
  {
    "text": "And this constant eta,",
    "start": "689350",
    "end": "691209"
  },
  {
    "text": "this is the learning rate, right?",
    "start": "691210",
    "end": "692860"
  },
  {
    "text": "It says how big of a step I wanna make.",
    "start": "692860",
    "end": "695394"
  },
  {
    "text": "And then this gives me the new updated set of parameters.",
    "start": "695395",
    "end": "698305"
  },
  {
    "text": "And now again, I put them here,",
    "start": "698305",
    "end": "700300"
  },
  {
    "text": "I evaluate the gradient,",
    "start": "700300",
    "end": "701575"
  },
  {
    "text": "and- and, uh, I make an- an update.",
    "start": "701575",
    "end": "704080"
  },
  {
    "text": "So basically in training, we say that, you know,",
    "start": "704080",
    "end": "706450"
  },
  {
    "text": "we optimize this Theta parameters iteratively,",
    "start": "706450",
    "end": "709465"
  },
  {
    "text": "and one iteration is one step of gradient descent.",
    "start": "709465",
    "end": "712990"
  },
  {
    "text": "And as I said, uh, eta here,",
    "start": "712990",
    "end": "715810"
  },
  {
    "text": "is the learning rate which is a hyperparameter that controls the size of a step, right.",
    "start": "715810",
    "end": "721510"
  },
  {
    "text": "Uh, and the idea is that usually at the beginning you could make bigger steps.",
    "start": "721510",
    "end": "725605"
  },
  {
    "text": "But as you get closer to the minimum,",
    "start": "725605",
    "end": "727300"
  },
  {
    "text": "you wanna make smaller steps because you don't wanna overstep.",
    "start": "727300",
    "end": "731019"
  },
  {
    "text": "You don't wanna kind of jump over the value,",
    "start": "731020",
    "end": "733630"
  },
  {
    "text": "you want to slowly descend into the value.",
    "start": "733630",
    "end": "735760"
  },
  {
    "text": "If you think of a function like this, right,",
    "start": "735760",
    "end": "737380"
  },
  {
    "text": "you don't want to kind of jump across.",
    "start": "737380",
    "end": "739435"
  },
  {
    "text": "And an ideal termination condition is when the gradient is zero,",
    "start": "739435",
    "end": "744040"
  },
  {
    "text": "which means you got stuck in some local minimum",
    "start": "744040",
    "end": "747009"
  },
  {
    "text": "where the function is flat so you know you are at the bottom.",
    "start": "747010",
    "end": "750325"
  },
  {
    "text": "In practice, um, we would stop training if",
    "start": "750325",
    "end": "753580"
  },
  {
    "text": "it no longer improves the performance on the validation set.",
    "start": "753580",
    "end": "756700"
  },
  {
    "text": "So rather than stopping when the gradient is zero, in practice,",
    "start": "756700",
    "end": "760915"
  },
  {
    "text": "we have a separate validation set over which we",
    "start": "760915",
    "end": "764695"
  },
  {
    "text": "validate the predictions of the model but we don't use it to compute gradients,",
    "start": "764695",
    "end": "768865"
  },
  {
    "text": "and, um, as soon as our performance on that",
    "start": "768865",
    "end": "771940"
  },
  {
    "text": "validation set stops improving, we stop the training.",
    "start": "771940",
    "end": "775405"
  },
  {
    "text": "That's usually the case,",
    "start": "775405",
    "end": "776590"
  },
  {
    "text": "even though, you know,",
    "start": "776590",
    "end": "777670"
  },
  {
    "text": "it might be still, uh,",
    "start": "777670",
    "end": "778750"
  },
  {
    "text": "possible to keep, uh, optimizing your, uh, objective function.",
    "start": "778750",
    "end": "783085"
  },
  {
    "text": "So the problem with this general gradient descent idea is that",
    "start": "783085",
    "end": "788500"
  },
  {
    "text": "computing the exact gradient requires a pass over the entire data set.",
    "start": "788500",
    "end": "793270"
  },
  {
    "text": "Uh, this is the case because if you remember earlier when I defined the loss,",
    "start": "793270",
    "end": "796900"
  },
  {
    "text": "I said the loss measures the discrepancy between",
    "start": "796900",
    "end": "799540"
  },
  {
    "text": "the data point- the predicted value and the true value,",
    "start": "799540",
    "end": "803095"
  },
  {
    "text": "and the total loss is a sum of the losses over all the training examples.",
    "start": "803095",
    "end": "807699"
  },
  {
    "text": "So now, this means that this- even when you are computing the gradient of the loss,",
    "start": "807700",
    "end": "812950"
  },
  {
    "text": "it means you have to dis- kind of propagate the gradient",
    "start": "812950",
    "end": "815950"
  },
  {
    "text": "inside the sum over all the training examples.",
    "start": "815950",
    "end": "819160"
  },
  {
    "text": "So it mean- which- which means that when you compute the gradient, each discrepancy,",
    "start": "819160",
    "end": "823810"
  },
  {
    "text": "each training example evalu- uh,",
    "start": "823810",
    "end": "826105"
  },
  {
    "text": "and the loss evaluated at the training example will have some contribution to the,",
    "start": "826105",
    "end": "830970"
  },
  {
    "text": "uh, to the total gradients.",
    "start": "830970",
    "end": "832740"
  },
  {
    "text": "So it means that one iteration of gradient descent in this case would",
    "start": "832740",
    "end": "837450"
  },
  {
    "text": "allo- would require to make a pass over the entire, uh, training dataset.",
    "start": "837450",
    "end": "842915"
  },
  {
    "text": "Um, and this is problematic because modern data sets",
    "start": "842915",
    "end": "846579"
  },
  {
    "text": "often have or often contain billions of data points,",
    "start": "846580",
    "end": "850375"
  },
  {
    "text": "um, and this can become very expensive and very slow.",
    "start": "850375",
    "end": "853780"
  },
  {
    "text": "So the solution, the speedup,",
    "start": "853780",
    "end": "856555"
  },
  {
    "text": "is called stochastic gradient descent or SGD.",
    "start": "856555",
    "end": "860230"
  },
  {
    "text": "And the idea is that rather than computing the loss over all the training examples,",
    "start": "860230",
    "end": "865269"
  },
  {
    "text": "we are only going to s- to compute the loss",
    "start": "865270",
    "end": "868795"
  },
  {
    "text": "and the gradient of the loss over what is called a minibatch.",
    "start": "868795",
    "end": "872570"
  },
  {
    "text": "And the minibatch is simply some small subset of the data.",
    "start": "872570",
    "end": "876615"
  },
  {
    "text": "And this is what we will call an x.",
    "start": "876615",
    "end": "879345"
  },
  {
    "text": "So let me now, uh,",
    "start": "879345",
    "end": "881444"
  },
  {
    "text": "define a couple of very important concepts",
    "start": "881445",
    "end": "884235"
  },
  {
    "text": "that you are going to hear over and over again.",
    "start": "884235",
    "end": "887135"
  },
  {
    "text": "So first, we talked about the notion of batch,",
    "start": "887135",
    "end": "891655"
  },
  {
    "text": "which is a subset of the data over which we evaluate the gradient, right?",
    "start": "891655",
    "end": "897340"
  },
  {
    "text": "Rather than evaluating it over the entire training dataset,",
    "start": "897340",
    "end": "900475"
  },
  {
    "text": "we are going to evaluate it on a small subset of the training dataset,",
    "start": "900475",
    "end": "904209"
  },
  {
    "text": "maybe hundreds, maybe thousands examples.",
    "start": "904210",
    "end": "906520"
  },
  {
    "text": "Batch size is the number of data points in the minibatch, right.",
    "start": "906520",
    "end": "911275"
  },
  {
    "text": "Um, so this is, uh, uh, important.",
    "start": "911275",
    "end": "914035"
  },
  {
    "text": "Usually, we like to make batches bigger,",
    "start": "914035",
    "end": "916045"
  },
  {
    "text": "but bigger batches make the- make the optimization slower because for every step,",
    "start": "916045",
    "end": "921084"
  },
  {
    "text": "we need to compute, uh,",
    "start": "921085",
    "end": "922525"
  },
  {
    "text": "over, uh, larger batch size.",
    "start": "922525",
    "end": "924865"
  },
  {
    "text": "Iteration in terms of stochastic gradient descent is then one step of, uh,",
    "start": "924865",
    "end": "930220"
  },
  {
    "text": "stochastic gradient descent where we evaluate the gradient on a given minibatch,",
    "start": "930220",
    "end": "934375"
  },
  {
    "text": "and we call these an iteration.",
    "start": "934375",
    "end": "936340"
  },
  {
    "text": "And then an epoch is basically a full pass over the datasets.",
    "start": "936340",
    "end": "940720"
  },
  {
    "text": "So basically, it means we get processing batches 1, 2, 3,",
    "start": "940720",
    "end": "943750"
  },
  {
    "text": "4, 5 all the way until we exhaust the training dataset.",
    "start": "943750",
    "end": "947170"
  },
  {
    "text": "So if we have, I don't know, a million examples and, uh,",
    "start": "947170",
    "end": "949915"
  },
  {
    "text": "we have, I don't know,",
    "start": "949915",
    "end": "951384"
  },
  {
    "text": "uh, um, 100,000 batches,",
    "start": "951385",
    "end": "953530"
  },
  {
    "text": "each one of size 10,",
    "start": "953530",
    "end": "954865"
  },
  {
    "text": "so basically after we have pre-processed,",
    "start": "954865",
    "end": "957220"
  },
  {
    "text": "uh,100,000 batches, this is one- one epoch.",
    "start": "957220",
    "end": "960384"
  },
  {
    "text": "And then we go to the beginning and start from the,",
    "start": "960385",
    "end": "962740"
  },
  {
    "text": "uh, beginning again, right.",
    "start": "962740",
    "end": "964000"
  },
  {
    "text": "So the number of iterations is equal to the ratio of the dataset size,",
    "start": "964000",
    "end": "969040"
  },
  {
    "text": "uh, and the batch size.",
    "start": "969040",
    "end": "970930"
  },
  {
    "text": "And as I mentioned, if you create these batches, uh, uh,",
    "start": "970930",
    "end": "975070"
  },
  {
    "text": "uniformly at random, then SGD is unbiased estimator of the full gradient, right?",
    "start": "975070",
    "end": "980815"
  },
  {
    "text": "Um, of course, there is no guarantee on the rate of convergence.",
    "start": "980815",
    "end": "984355"
  },
  {
    "text": "And in practice, uh,",
    "start": "984355",
    "end": "986065"
  },
  {
    "text": "this means it requires tuning the learning rate.",
    "start": "986065",
    "end": "989185"
  },
  {
    "text": "And this SGD idea is kind of a common core idea that then many other, um,",
    "start": "989185",
    "end": "996070"
  },
  {
    "text": "optimizers, uh, improve on,",
    "start": "996070",
    "end": "998320"
  },
  {
    "text": "like ada- adagrad, adadelta,",
    "start": "998320",
    "end": "1001290"
  },
  {
    "text": "M RMSprop and so on.",
    "start": "1001290",
    "end": "1003720"
  },
  {
    "text": "Essentially, all use this core idea of selecting the subsets of the- subset of data,",
    "start": "1003720",
    "end": "1009045"
  },
  {
    "text": "evaluating the gradient over it and making the steps.",
    "start": "1009045",
    "end": "1012240"
  },
  {
    "text": "Now- now the details, uh,",
    "start": "1012240",
    "end": "1014310"
  },
  {
    "text": "vary in terms of what data points you select,",
    "start": "1014310",
    "end": "1016770"
  },
  {
    "text": "how big of a step you make,",
    "start": "1016770",
    "end": "1018450"
  },
  {
    "text": "how do you decide on the step size,",
    "start": "1018450",
    "end": "1020760"
  },
  {
    "text": "um, and so on and so forth.",
    "start": "1020760",
    "end": "1022230"
  },
  {
    "text": "But essentially, this minibatch stochastic gradient descent is the core of,",
    "start": "1022230",
    "end": "1027194"
  },
  {
    "text": "um, optimization in deep learning.",
    "start": "1027195",
    "end": "1030149"
  },
  {
    "text": "So now that we have discussed the objective function,",
    "start": "1030150",
    "end": "1035100"
  },
  {
    "text": "we discussed the notion of a minibatch,",
    "start": "1035100",
    "end": "1037214"
  },
  {
    "text": "we discussed the notion of a stochastic gradient descent, now,",
    "start": "1037215",
    "end": "1040574"
  },
  {
    "text": "we need to, uh,",
    "start": "1040575",
    "end": "1041639"
  },
  {
    "text": "talk about how is- is this actually done?",
    "start": "1041640",
    "end": "1044610"
  },
  {
    "text": "How are these, um,",
    "start": "1044610",
    "end": "1046020"
  },
  {
    "text": "gradients, uh, computed, evaluated, right.",
    "start": "1046020",
    "end": "1049305"
  },
  {
    "text": "Because in the old days, pre-deep learning,",
    "start": "1049305",
    "end": "1052440"
  },
  {
    "text": "you actually had to write down the model with the set of equations",
    "start": "1052440",
    "end": "1055590"
  },
  {
    "text": "and then you have to do by hand computed these gradients essentially,",
    "start": "1055590",
    "end": "1059100"
  },
  {
    "text": "you know, like we did it in high school, uh,",
    "start": "1059100",
    "end": "1061020"
  },
  {
    "text": "many of you are computing the gradients by hand- by hand on the whiteboard.",
    "start": "1061020",
    "end": "1064350"
  },
  {
    "text": "So essentially, you would have to compute those gradients by",
    "start": "1064350",
    "end": "1066990"
  },
  {
    "text": "hand and then code them into your, uh,",
    "start": "1066990",
    "end": "1069809"
  },
  {
    "text": "software C++, Python, Matlab, whatever,",
    "start": "1069810",
    "end": "1073260"
  },
  {
    "text": "uh, to be then able to,",
    "start": "1073260",
    "end": "1075285"
  },
  {
    "text": "uh, run the optimization.",
    "start": "1075285",
    "end": "1076860"
  },
  {
    "text": "Um, and interestingly, you're writing deep learning.",
    "start": "1076860",
    "end": "1080025"
  },
  {
    "text": "In deep learning, this prediction functions f can be very complex, right?",
    "start": "1080025",
    "end": "1084030"
  },
  {
    "text": "It can be this complex multi-layer deep neural networks.",
    "start": "1084030",
    "end": "1087810"
  },
  {
    "text": "Uh, and what I'm going to show you now is that basically,",
    "start": "1087810",
    "end": "1090810"
  },
  {
    "text": "the benefit of these deep learning approaches is",
    "start": "1090810",
    "end": "1093030"
  },
  {
    "text": "that the gradient computation is actually very,",
    "start": "1093030",
    "end": "1095790"
  },
  {
    "text": "very simple and um,",
    "start": "1095790",
    "end": "1097710"
  },
  {
    "text": "it comes for free in a sense that as you- as you made more complex models,",
    "start": "1097710",
    "end": "1103005"
  },
  {
    "text": "you- the complexity of gradient computation",
    "start": "1103005",
    "end": "1105750"
  },
  {
    "text": "in terms of what you have to do as a- as a programmer,",
    "start": "1105750",
    "end": "1108524"
  },
  {
    "text": "um, uh, doesn't really affect you.",
    "start": "1108524",
    "end": "1110880"
  },
  {
    "text": "So the idea is the following, right?",
    "start": "1110880",
    "end": "1112815"
  },
  {
    "text": "Let's start with a very, uh,",
    "start": "1112815",
    "end": "1113909"
  },
  {
    "text": "simple function, uh, f, that, uh,",
    "start": "1113910",
    "end": "1116865"
  },
  {
    "text": "basically take the input x and multiplies it with W. So",
    "start": "1116865",
    "end": "1120315"
  },
  {
    "text": "our parameters Theta of the model is this, um, is this,",
    "start": "1120315",
    "end": "1124590"
  },
  {
    "text": "uh, object W. Now if f returns a scalar,",
    "start": "1124590",
    "end": "1128429"
  },
  {
    "text": "if f returns a single number,",
    "start": "1128430",
    "end": "1130290"
  },
  {
    "text": "then W should be a vector, right?",
    "start": "1130290",
    "end": "1132450"
  },
  {
    "text": "X is a vector times a vector gives me a scalar.",
    "start": "1132450",
    "end": "1135419"
  },
  {
    "text": "So then for example, the gradient,",
    "start": "1135420",
    "end": "1138300"
  },
  {
    "text": "with respect to, uh, uh,",
    "start": "1138300",
    "end": "1141420"
  },
  {
    "text": "v of f respect- respect to W, is simply, uh,",
    "start": "1141420",
    "end": "1145095"
  },
  {
    "text": "vector where- where we differentiate, uh,",
    "start": "1145095",
    "end": "1148950"
  },
  {
    "text": "f with respect to w_1,",
    "start": "1148950",
    "end": "1151485"
  },
  {
    "text": "w_2, w_3, which are the components of our, uh,",
    "start": "1151485",
    "end": "1154245"
  },
  {
    "text": "vector W. And this, um,",
    "start": "1154245",
    "end": "1156245"
  },
  {
    "text": "gradient is then simply the derivative evaluate at- at a particular,",
    "start": "1156245",
    "end": "1160870"
  },
  {
    "text": "specific point, uh, W. So basically,",
    "start": "1160870",
    "end": "1163170"
  },
  {
    "text": "we have to work out what these derivatives are,",
    "start": "1163170",
    "end": "1165230"
  },
  {
    "text": "then plug in the concrete number for w and, um, get to the value,",
    "start": "1165230",
    "end": "1169975"
  },
  {
    "text": "and that would be then the gradient of that point W. Now for example,",
    "start": "1169975",
    "end": "1174760"
  },
  {
    "text": "if f returns a vector,",
    "start": "1174760",
    "end": "1176809"
  },
  {
    "text": "so f is a more complex function,",
    "start": "1176809",
    "end": "1179080"
  },
  {
    "text": "then W would be a matrix, right.",
    "start": "1179080",
    "end": "1181539"
  },
  {
    "text": "We would have matrix times a vector, gives me a vector.",
    "start": "1181540",
    "end": "1184330"
  },
  {
    "text": "So, uh, in this case,",
    "start": "1184330",
    "end": "1186355"
  },
  {
    "text": "W would be what is called a weight matrix.",
    "start": "1186355",
    "end": "1189515"
  },
  {
    "text": "It is also called a Jacobian matrix.",
    "start": "1189515",
    "end": "1192485"
  },
  {
    "text": "And then the way you would compute the gradient is",
    "start": "1192485",
    "end": "1194530"
  },
  {
    "text": "exactly the same sum up but now you would take the derivate",
    "start": "1194530",
    "end": "1197415"
  },
  {
    "text": "with respect to every entry of that W. So with respect to w1 1,",
    "start": "1197415",
    "end": "1202600"
  },
  {
    "text": "w1 2, w1 3,",
    "start": "1202600",
    "end": "1204655"
  },
  {
    "text": "and then you know to end of the first level,",
    "start": "1204655",
    "end": "1206410"
  },
  {
    "text": "and then it'll be W2 1,",
    "start": "1206410",
    "end": "1208060"
  },
  {
    "text": "2 2 and so on, right.",
    "start": "1208060",
    "end": "1209560"
  },
  {
    "text": "But essentially it's, uh, it's the same,",
    "start": "1209560",
    "end": "1212020"
  },
  {
    "text": "so now the gradient would be, uh, the matrix.",
    "start": "1212020",
    "end": "1215585"
  },
  {
    "text": "Now, we just had this very simple, uh,",
    "start": "1215585",
    "end": "1219825"
  },
  {
    "text": "predictor that just states the input and multiplies it with the- with the W. But now,",
    "start": "1219825",
    "end": "1224970"
  },
  {
    "text": "what if we wanna create more complex predictors?",
    "start": "1224970",
    "end": "1227865"
  },
  {
    "text": "Imagine, uh, just for the sake of the example,",
    "start": "1227865",
    "end": "1230695"
  },
  {
    "text": "I wanna have this complex predictor, uh, f,",
    "start": "1230695",
    "end": "1233350"
  },
  {
    "text": "that now first takes input x,",
    "start": "1233350",
    "end": "1235975"
  },
  {
    "text": "multiplies it with W,",
    "start": "1235975",
    "end": "1237735"
  },
  {
    "text": "and then multi- w_1 and then multiplies it with w_2.",
    "start": "1237735",
    "end": "1241080"
  },
  {
    "text": "So this now seems kind of more complex because first,",
    "start": "1241080",
    "end": "1243850"
  },
  {
    "text": "we are multiplying with",
    "start": "1243850",
    "end": "1245110"
  },
  {
    "text": "a one weight- weight matrix and then we are multiplying with the second weight matrix.",
    "start": "1245110",
    "end": "1248900"
  },
  {
    "text": "In this case, parameters of the model are the two,",
    "start": "1248900",
    "end": "1251995"
  },
  {
    "text": "let say rate, uh, matrices.",
    "start": "1251995",
    "end": "1254505"
  },
  {
    "text": "And now what we'd like to do is we'd like to compute the derivative,",
    "start": "1254505",
    "end": "1258515"
  },
  {
    "text": "both with respect to W_1 and W_2.",
    "start": "1258515",
    "end": "1261110"
  },
  {
    "text": "And what happens here is that we can actually apply the chain rule, right?",
    "start": "1261110",
    "end": "1265054"
  },
  {
    "text": "The chain rule says if you take a deriva- if you wanna take a derivative of variable,",
    "start": "1265055",
    "end": "1269540"
  },
  {
    "text": "uh, uh, z with respect to some variable x, but, um, uh,",
    "start": "1269540",
    "end": "1273950"
  },
  {
    "text": "variable z depends on variable y,",
    "start": "1273950",
    "end": "1275720"
  },
  {
    "text": "then the way you can do it is you say, aha,",
    "start": "1275720",
    "end": "1277370"
  },
  {
    "text": "I take z with respect to y,",
    "start": "1277370",
    "end": "1279875"
  },
  {
    "text": "and then I have to take y and, uh,",
    "start": "1279875",
    "end": "1282350"
  },
  {
    "text": "they could- derivative with- of it with respect to x.",
    "start": "1282350",
    "end": "1285605"
  },
  {
    "text": "So basically, this is how I can apply this chain rule to create this, uh,",
    "start": "1285605",
    "end": "1289940"
  },
  {
    "text": "deriva- partial- these derivatives, um,",
    "start": "1289940",
    "end": "1292325"
  },
  {
    "text": "and- and chain them together based- based on the dependencies.",
    "start": "1292325",
    "end": "1295894"
  },
  {
    "text": "So in our case,",
    "start": "1295895",
    "end": "1297080"
  },
  {
    "text": "if I wanna take my function f and compute the derivative of it with respect to x,",
    "start": "1297080",
    "end": "1301700"
  },
  {
    "text": "I could first take the function and take a derivative of it with respect to",
    "start": "1301700",
    "end": "1306080"
  },
  {
    "text": "W_1x and then I think the W_1x and take a derivative of it with respect to, uh, x.",
    "start": "1306080",
    "end": "1313370"
  },
  {
    "text": "And the notion of, uh,",
    "start": "1313370",
    "end": "1316175"
  },
  {
    "text": "back-propagation uses the chain rule to propa-",
    "start": "1316175",
    "end": "1319490"
  },
  {
    "text": "propagate gradients of intermediate steps and,",
    "start": "1319490",
    "end": "1323255"
  },
  {
    "text": "uh, finally obtain the gradient with respect of",
    "start": "1323255",
    "end": "1326180"
  },
  {
    "text": "the loss with respect to the model parameters.",
    "start": "1326180",
    "end": "1329240"
  },
  {
    "text": "Um, and this is very, um, uh,",
    "start": "1329240",
    "end": "1331100"
  },
  {
    "text": "interesting because it means we can mechanically compute, uh, the gradients.",
    "start": "1331100",
    "end": "1335945"
  },
  {
    "text": "So let me, uh,",
    "start": "1335945",
    "end": "1337174"
  },
  {
    "text": "give you an example, right?",
    "start": "1337175",
    "end": "1338540"
  },
  {
    "text": "So it- we are still working with this simple,",
    "start": "1338540",
    "end": "1341480"
  },
  {
    "text": "uh, two layer linear network, right?",
    "start": "1341480",
    "end": "1344570"
  },
  {
    "text": "Here is kind of the neural network representation of this,",
    "start": "1344570",
    "end": "1346880"
  },
  {
    "text": "but essentially, it takes,",
    "start": "1346880",
    "end": "1348050"
  },
  {
    "text": "let say, two dimensional on input x,",
    "start": "1348050",
    "end": "1350300"
  },
  {
    "text": "multiply it- it with W_1.",
    "start": "1350300",
    "end": "1352790"
  },
  {
    "text": "This is happening here,",
    "start": "1352790",
    "end": "1353990"
  },
  {
    "text": "and then multiply it with W_2 here,",
    "start": "1353990",
    "end": "1356210"
  },
  {
    "text": "to get an output, right?",
    "start": "1356210",
    "end": "1358054"
  },
  {
    "text": "Imagine I have some loss function.",
    "start": "1358055",
    "end": "1359720"
  },
  {
    "text": "Let's say I have a, uh, L_2 loss,",
    "start": "1359720",
    "end": "1362059"
  },
  {
    "text": "a squared loss that sim- simply says- was a discrepancy between the predicted value,",
    "start": "1362060",
    "end": "1367160"
  },
  {
    "text": "uh, and the true value?",
    "start": "1367160",
    "end": "1368720"
  },
  {
    "text": "And then, um, you know,",
    "start": "1368720",
    "end": "1370745"
  },
  {
    "text": "I evaluate this over the minibatch- mini-batch B.",
    "start": "1370745",
    "end": "1373625"
  },
  {
    "text": "And then I also have the notion of a hidden layer, uh,",
    "start": "1373625",
    "end": "1376700"
  },
  {
    "text": "and hidden layer is an intermediate representation for,",
    "start": "1376700",
    "end": "1379490"
  },
  {
    "text": "uh, input x, right?",
    "start": "1379490",
    "end": "1380929"
  },
  {
    "text": "So here, I'm using this, uh,",
    "start": "1380930",
    "end": "1382730"
  },
  {
    "text": "h of x to be W1 times x to denote the hidden layer, right?",
    "start": "1382730",
    "end": "1386660"
  },
  {
    "text": "It's some transformation of x that is not yet,",
    "start": "1386660",
    "end": "1389945"
  },
  {
    "text": "uh, the final output, uh, of the network.",
    "start": "1389945",
    "end": "1392384"
  },
  {
    "text": "And then of course, then I can rewrite this to say f of x is,",
    "start": "1392385",
    "end": "1395560"
  },
  {
    "text": "you know, uh, h of x,",
    "start": "1395560",
    "end": "1397330"
  },
  {
    "text": "which is the first product and then evaluate it, uh, um,",
    "start": "1397330",
    "end": "1401809"
  },
  {
    "text": "on the- on the s- on the g of h, uh,",
    "start": "1401810",
    "end": "1404930"
  },
  {
    "text": "which is the multiplication with, uh, W_2.",
    "start": "1404930",
    "end": "1408680"
  },
  {
    "text": "What this means now, if I wanna do what is called a forward pass,",
    "start": "1408680",
    "end": "1412865"
  },
  {
    "text": "I start with x, I multiply with W_1,",
    "start": "1412865",
    "end": "1416105"
  },
  {
    "text": "and then I multiply with W_2 to get the output.",
    "start": "1416105",
    "end": "1418669"
  },
  {
    "text": "So the way I can think of this as I start from x,",
    "start": "1418670",
    "end": "1421190"
  },
  {
    "text": "I apply W_1 to- to basically compute h. Now I,",
    "start": "1421190",
    "end": "1425419"
  },
  {
    "text": "uh, take h to, uh, um,",
    "start": "1425420",
    "end": "1428210"
  },
  {
    "text": "and apply function G to it, which is again,",
    "start": "1428210",
    "end": "1430730"
  },
  {
    "text": "I multiply with W_2 and I- I get the- I get now",
    "start": "1430730",
    "end": "1434090"
  },
  {
    "text": "the output f. And now I want to evaluate f,",
    "start": "1434090",
    "end": "1438110"
  },
  {
    "text": "uh, with respect to the loss.",
    "start": "1438110",
    "end": "1440030"
  },
  {
    "text": "So we have this kind of, uh,",
    "start": "1440030",
    "end": "1441560"
  },
  {
    "text": "nesting or chaining of functions.",
    "start": "1441560",
    "end": "1443810"
  },
  {
    "text": "And if I wanna do back-propagation now,",
    "start": "1443810",
    "end": "1446060"
  },
  {
    "text": "back-propagation means I have to now compute the derivative,",
    "start": "1446060",
    "end": "1448940"
  },
  {
    "text": "the gradient, and I wanna work backward.",
    "start": "1448940",
    "end": "1451700"
  },
  {
    "text": "So what does this means is that if these are my model parameters,",
    "start": "1451700",
    "end": "1455465"
  },
  {
    "text": "I start from the loss and compute gradients backwards.",
    "start": "1455465",
    "end": "1458419"
  },
  {
    "text": "So I would start with a loss, for example,",
    "start": "1458420",
    "end": "1460730"
  },
  {
    "text": "and I'm interested to compute the gradient of the loss,",
    "start": "1460730",
    "end": "1463160"
  },
  {
    "text": "uh, with respect to W2.",
    "start": "1463160",
    "end": "1464825"
  },
  {
    "text": "Then I have to go from the loss,",
    "start": "1464825",
    "end": "1466580"
  },
  {
    "text": "compute- take the derivative with respect to f,",
    "start": "1466580",
    "end": "1469355"
  },
  {
    "text": "and then I have to take, uh,",
    "start": "1469355",
    "end": "1470870"
  },
  {
    "text": "f and take a derivative with respect to W2, right?",
    "start": "1470870",
    "end": "1474920"
  },
  {
    "text": "So I went from lost to f to W, uh,2.",
    "start": "1474920",
    "end": "1478160"
  },
  {
    "text": "While, for example, to compute the derivative of the loss,",
    "start": "1478160",
    "end": "1481550"
  },
  {
    "text": "uh, with the- with respect to W_1,",
    "start": "1481550",
    "end": "1484115"
  },
  {
    "text": "I have to take the- the loss compute f of",
    "start": "1484115",
    "end": "1488150"
  },
  {
    "text": "the derivative with respect to f. Take f compute the derivative with respect to W_2,",
    "start": "1488150",
    "end": "1492800"
  },
  {
    "text": "and then kind of take the result of that W_2,",
    "start": "1492800",
    "end": "1495680"
  },
  {
    "text": "take a derivative, uh,",
    "start": "1495680",
    "end": "1497540"
  },
  {
    "text": "with respect to, uh, W_1.",
    "start": "1497540",
    "end": "1499400"
  },
  {
    "text": "And you can see kind of how I'm working backwards and how, uh,",
    "start": "1499400",
    "end": "1503270"
  },
  {
    "text": "as I go deeper into the network,",
    "start": "1503270",
    "end": "1504785"
  },
  {
    "text": "I can kind of re-use,",
    "start": "1504785",
    "end": "1506825"
  },
  {
    "text": "uh, uh, previous computations.",
    "start": "1506825",
    "end": "1508625"
  },
  {
    "text": "And this is why this is called a back-propagation because I kind of- kind of, uh,",
    "start": "1508625",
    "end": "1512195"
  },
  {
    "text": "working backwards, um, uh,",
    "start": "1512195",
    "end": "1515465"
  },
  {
    "text": "from the output all the way towards the, uh- the input.",
    "start": "1515465",
    "end": "1519080"
  },
  {
    "text": "And this then tells me how to update my parameter values so that,",
    "start": "1519080",
    "end": "1523370"
  },
  {
    "text": "uh, the discrepancy, the value of the loss will be smaller.",
    "start": "1523370",
    "end": "1527510"
  },
  {
    "text": "Um, note that in- in my case that I showed you so far,",
    "start": "1527510",
    "end": "1532235"
  },
  {
    "text": "we used a very simple two layer neural network",
    "start": "1532235",
    "end": "1535145"
  },
  {
    "text": "which is- which if- if you look at it carefully, uh,",
    "start": "1535145",
    "end": "1538895"
  },
  {
    "text": "is still a linear, uh,",
    "start": "1538895",
    "end": "1540890"
  },
  {
    "text": "function because W_1 times W_2 is,",
    "start": "1540890",
    "end": "1543920"
  },
  {
    "text": "uh- is another matrix or- or- or a vector.",
    "start": "1543920",
    "end": "1546920"
  },
  {
    "text": "But basically, it means that by chaining things,",
    "start": "1546920",
    "end": "1549140"
  },
  {
    "text": "we did not get any more expressive power.",
    "start": "1549140",
    "end": "1551900"
  },
  {
    "text": "This was still a linear model, right?",
    "start": "1551900",
    "end": "1554825"
  },
  {
    "text": "So, um, in this case,",
    "start": "1554825",
    "end": "1557075"
  },
  {
    "text": "in this simple example,",
    "start": "1557075",
    "end": "1558304"
  },
  {
    "text": "f is still a linear model with respect to x.",
    "start": "1558305",
    "end": "1560855"
  },
  {
    "text": "Now ma- no matter how many weight matrices do we compose,",
    "start": "1560855",
    "end": "1564230"
  },
  {
    "text": "how many Ws do we have.",
    "start": "1564230",
    "end": "1565880"
  },
  {
    "text": "But if we introduce non-linearities, for example, um,",
    "start": "1565880",
    "end": "1569810"
  },
  {
    "text": "a rectified linear unit defined like this and here's how it looked",
    "start": "1569810",
    "end": "1572990"
  },
  {
    "text": "like or a sigmoid function defined like this and here is,",
    "start": "1572990",
    "end": "1576770"
  },
  {
    "text": "you know, the pictorial version of it.",
    "start": "1576770",
    "end": "1578435"
  },
  {
    "text": "Then, um, these things become much more interesting",
    "start": "1578435",
    "end": "1581810"
  },
  {
    "text": "because now, by introducing non-linearity,",
    "start": "1581810",
    "end": "1585590"
  },
  {
    "text": "so actually increase the expressivity, uh,",
    "start": "1585590",
    "end": "1588289"
  },
  {
    "text": "of our model and the more than Ws we chain,",
    "start": "1588290",
    "end": "1591125"
  },
  {
    "text": "um, the more, uh, expressive the model will be.",
    "start": "1591125",
    "end": "1594755"
  },
  {
    "text": "And this now leads us to the model that is called multi-layer perceptron.",
    "start": "1594755",
    "end": "1599660"
  },
  {
    "text": "And in each layer of a multi-layer perceptron,",
    "start": "1599660",
    "end": "1603005"
  },
  {
    "text": "we combine linear transformation with the non-linearity.",
    "start": "1603005",
    "end": "1606590"
  },
  {
    "text": "So meaning so far,",
    "start": "1606590",
    "end": "1607820"
  },
  {
    "text": "we talked about W times x.",
    "start": "1607820",
    "end": "1610445"
  },
  {
    "text": "What to do now is, uh,",
    "start": "1610445",
    "end": "1612830"
  },
  {
    "text": "also apply a non-linearity tool,",
    "start": "1612830",
    "end": "1615335"
  },
  {
    "text": "for example, a sigmoid, uh,",
    "start": "1615335",
    "end": "1616895"
  },
  {
    "text": "or a- or a, uh, RELU, uh, function.",
    "start": "1616895",
    "end": "1620930"
  },
  {
    "text": "Um, here b is just a bias to a- a constant to exclusively take it out.",
    "start": "1620930",
    "end": "1626165"
  },
  {
    "text": "One way is also to assume that the feature vector is",
    "start": "1626165",
    "end": "1628850"
  },
  {
    "text": "one- one element or one entry longer,",
    "start": "1628850",
    "end": "1632105"
  },
  {
    "text": "and that entry is always value one,",
    "start": "1632105",
    "end": "1634054"
  },
  {
    "text": "and then these buyers becomes kind of part of b,",
    "start": "1634055",
    "end": "1637025"
  },
  {
    "text": "be- becomes a, uh, uh,",
    "start": "1637025",
    "end": "1638270"
  },
  {
    "text": "uh- a row- a row in b.",
    "start": "1638270",
    "end": "1641075"
  },
  {
    "text": "So, um, this is- this is now how,",
    "start": "1641075",
    "end": "1644360"
  },
  {
    "text": "uh, multi-layered perceptron works.",
    "start": "1644360",
    "end": "1645890"
  },
  {
    "text": "It's the same as we had before,",
    "start": "1645890",
    "end": "1647720"
  },
  {
    "text": "but just I sent things through a non-linear, uh, activation function.",
    "start": "1647720",
    "end": "1651679"
  },
  {
    "text": "And now, you know, if I want- now I can take this access at a given layer and I can,",
    "start": "1651680",
    "end": "1656900"
  },
  {
    "text": "uh, keep, uh, uh, chaining them by- by multiplying with another W,",
    "start": "1656900",
    "end": "1661715"
  },
  {
    "text": "sending through another, uh,",
    "start": "1661715",
    "end": "1663065"
  },
  {
    "text": "non-linear layer, multiplying with another W,",
    "start": "1663065",
    "end": "1666154"
  },
  {
    "text": "another non-linear layer, and I can make deeper and",
    "start": "1666155",
    "end": "1668900"
  },
  {
    "text": "deeper and more and more complex, uh, neural networks.",
    "start": "1668900",
    "end": "1672200"
  },
  {
    "text": "But in terms of optimizing them because of the,",
    "start": "1672200",
    "end": "1675230"
  },
  {
    "text": "uh, chain rule we explained here.",
    "start": "1675230",
    "end": "1677330"
  },
  {
    "text": "Um, the gradient computations can basically be done, uh,",
    "start": "1677330",
    "end": "1680870"
  },
  {
    "text": "mechanistically by the deep learning framework and we don't need to worry",
    "start": "1680870",
    "end": "1685100"
  },
  {
    "text": "about actually writing them down or worrying about how to do optimization,",
    "start": "1685100",
    "end": "1689674"
  },
  {
    "text": "uh, you know, which is great and really speeds up the development of,",
    "start": "1689675",
    "end": "1693185"
  },
  {
    "text": "uh, machine learning algorithms.",
    "start": "1693185",
    "end": "1695540"
  },
  {
    "text": "So to summarize, we talked about how to define machine learning using",
    "start": "1695540",
    "end": "1700055"
  },
  {
    "text": "objective function of minimizing the loss with respect to model parameters.",
    "start": "1700055",
    "end": "1704960"
  },
  {
    "text": "Uh, f, as we said,",
    "start": "1704960",
    "end": "1706610"
  },
  {
    "text": "this probability function can be a simple linear layer,",
    "start": "1706610",
    "end": "1709115"
  },
  {
    "text": "just W times x or a multi-layered perceptron where it's W times x,",
    "start": "1709115",
    "end": "1714845"
  },
  {
    "text": "uh, passed through a non-linearity, or, you know,",
    "start": "1714845",
    "end": "1717530"
  },
  {
    "text": "some other more- more complex neural network.",
    "start": "1717530",
    "end": "1720230"
  },
  {
    "text": "Um, and the idea is that we sample a batch,",
    "start": "1720230",
    "end": "1722270"
  },
  {
    "text": "uh, of input, uh, x.",
    "start": "1722270",
    "end": "1724145"
  },
  {
    "text": "We call this a mini-batch.",
    "start": "1724145",
    "end": "1725495"
  },
  {
    "text": "We then do the forward propagation,",
    "start": "1725495",
    "end": "1727970"
  },
  {
    "text": "um, to compute, uh,",
    "start": "1727970",
    "end": "1729409"
  },
  {
    "text": "the value of loss.",
    "start": "1729410",
    "end": "1730835"
  },
  {
    "text": "And then we do the backward propagation,",
    "start": "1730835",
    "end": "1733054"
  },
  {
    "text": "where we obtain gradients of the loss with",
    "start": "1733055",
    "end": "1735800"
  },
  {
    "text": "respect to the model parameters using the chain rule.",
    "start": "1735800",
    "end": "1738980"
  },
  {
    "text": "And then that- now that we have computed",
    "start": "1738980",
    "end": "1741275"
  },
  {
    "text": "the gradients with respect to the model parameters,",
    "start": "1741275",
    "end": "1745055"
  },
  {
    "text": "we use stochastic gradient descent, um, uh,",
    "start": "1745055",
    "end": "1748085"
  },
  {
    "text": "over this mini-batches to optimize our parameters Theta over multiple iterations.",
    "start": "1748085",
    "end": "1754880"
  },
  {
    "text": "And this, uh, you know,",
    "start": "1754880",
    "end": "1756110"
  },
  {
    "text": "now concludes our, um,",
    "start": "1756110",
    "end": "1758495"
  },
  {
    "text": "deep learning tutorial, and what we are going to talk about next is actually,",
    "start": "1758495",
    "end": "1763295"
  },
  {
    "text": "uh, graph neural networks.",
    "start": "1763295",
    "end": "1765840"
  }
]
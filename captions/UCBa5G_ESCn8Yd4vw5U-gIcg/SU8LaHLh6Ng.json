[
  {
    "text": "is there a way to tell awesome okay uh I hi uh it's a small group so if people",
    "start": "11480",
    "end": "17400"
  },
  {
    "text": "have questions interrupt me I uh I had no idea really what the mix of backgrounds would be so uh this may be",
    "start": "17400",
    "end": "23240"
  },
  {
    "text": "either to high level or to low level um I um I'm actually coming from LinkedIn",
    "start": "23240",
    "end": "29160"
  },
  {
    "text": "uh where I've been for a long time uh like the last seven years um and I I worked there on data infrastructure uh",
    "start": "29160",
    "end": "35280"
  },
  {
    "text": "primarily so I worked I worked on a bunch of things from from kind of the early days but spent at least the last three years pretty heavily focused on",
    "start": "35280",
    "end": "42160"
  },
  {
    "text": "the data infrastructure that kind of ran the the website and shuffled data around uh a lot of what I'll talk about is kind",
    "start": "42160",
    "end": "48520"
  },
  {
    "text": "of ideas and systems that came out of the problems we had there um and I I'll kind of motivate those uh recently as",
    "start": "48520",
    "end": "54879"
  },
  {
    "text": "was alluded to I actually left LinkedIn and I'm starting a company which is actually related to some of these ideas and I'm happy to to answer questions",
    "start": "54879",
    "end": "61600"
  },
  {
    "text": "about that as well um so I'm going to talk about a couple different things I'm",
    "start": "61600",
    "end": "66799"
  },
  {
    "text": "going to talk about the the problem of data integration which is not something people talk about that much I'll talk",
    "start": "66799",
    "end": "71880"
  },
  {
    "text": "about Apachi Kafka which is a system we built which is you know kind of related um and then I'll motivate kind of uh why",
    "start": "71880",
    "end": "78159"
  },
  {
    "text": "we built this system and the problems it's useful for so let me start with data integration uh this is my my",
    "start": "78159",
    "end": "84200"
  },
  {
    "text": "favorite problem uh a lot of people would call this ETL so just so that I ground myself people have people heard",
    "start": "84200",
    "end": "89920"
  },
  {
    "text": "heard of like ETL yeah everybody know okay ETL everybody knows ETL all right so this this will be an easy one all",
    "start": "89920",
    "end": "95479"
  },
  {
    "text": "right so ETL is you want to get a copy of your data into your data warehouse and kind of munge on it for analysis um",
    "start": "95479",
    "end": "101479"
  },
  {
    "text": "this similar problem kind of exists all over the place and it's it's actually one of the bigger problems for for any kind of large company uh running a bunch",
    "start": "101479",
    "end": "108399"
  },
  {
    "text": "of different systems is putting everything together and making sense out of it um and it's a problem that I kind",
    "start": "108399",
    "end": "113680"
  },
  {
    "text": "of fell into without a lot of understanding uh and I'll talk a little bit about why I think it's important um",
    "start": "113680",
    "end": "119520"
  },
  {
    "text": "uh this is maso's hierarchy I guess no business presentation is complete without maso's hierarchy I don't know",
    "start": "119520",
    "end": "124840"
  },
  {
    "text": "how many people have seen this uh this is supposed to be some hierarchy of human needs um you know starting with",
    "start": "124840",
    "end": "130440"
  },
  {
    "text": "your physiological needs like food and water and moving up to kind of like self-actualization and the respect of",
    "start": "130440",
    "end": "135760"
  },
  {
    "text": "your peers or whatever um and the point of this hierarchy is uh when you when you are lacking um food and sleep and",
    "start": "135760",
    "end": "143319"
  },
  {
    "text": "safety you don't care about anything above it um and so my belief is you know a lot of the use of data like there's a",
    "start": "143319",
    "end": "148640"
  },
  {
    "text": "lot of companies that are struggling use data effectively there's this kind of like big data movement nobody knows",
    "start": "148640",
    "end": "153760"
  },
  {
    "text": "exactly what that means but it has something to do with collecting using data um there's some kind of similar",
    "start": "153760",
    "end": "159200"
  },
  {
    "text": "hierarchy the base of this pyramid is actually being able to kind of capture and instrument what is there um the next",
    "start": "159200",
    "end": "164879"
  },
  {
    "text": "thing up is you know what the hell does this mean like are we able to keep track of what all these fields mean and then everything above like understanding",
    "start": "164879",
    "end": "171480"
  },
  {
    "text": "automation like we we eventually you know had a bunch of sophisticated processes that at LinkedIn that predict",
    "start": "171480",
    "end": "176959"
  },
  {
    "text": "people you might know or you know come up with similar profiles or whatever but all of that is is built on like you know",
    "start": "176959",
    "end": "182480"
  },
  {
    "text": "actually having the data and being able to make sense out of it um and you know as I spent time in this area I found",
    "start": "182480",
    "end": "187879"
  },
  {
    "text": "that there was more and more problems down towards the bottom of the pyramid and I think the further a field you go kind of in the world uh the more that's",
    "start": "187879",
    "end": "194200"
  },
  {
    "text": "true so a lot of people are you know very interested in in uh uh who are kind",
    "start": "194200",
    "end": "199560"
  },
  {
    "text": "of getting into this big data stuff they're they're very interested in kind of you know how can we apply deep learning algorithms to do whatever and",
    "start": "199560",
    "end": "205720"
  },
  {
    "text": "they basically don't have any reliable data flow to anything to and of course the algorithms do not produce uh correct",
    "start": "205720",
    "end": "211879"
  },
  {
    "text": "results when fed in correct data uh that has remained true in computers um so the",
    "start": "211879",
    "end": "217040"
  },
  {
    "text": "reason that this problem has gotten harder you know the reason it's not solved out of the box is really two things so first of all you know",
    "start": "217040",
    "end": "223400"
  },
  {
    "text": "companies are interested in new types of data so if you were to ask a company what their data was you know maybe a",
    "start": "223400",
    "end": "228879"
  },
  {
    "text": "decade or so ago they would basically go through their database tables right so they would say well we we've got a users",
    "start": "228879",
    "end": "234840"
  },
  {
    "text": "table we have a products table we have orders this is our data um the set of",
    "start": "234840",
    "end": "240079"
  },
  {
    "text": "things that people consider data that's valuable about the businesses expanded dramatically that includes a bunch of things you would call event data so for",
    "start": "240079",
    "end": "246760"
  },
  {
    "text": "a website that's clicks Impressions page views whatever but you know almost any kind of business has some events about",
    "start": "246760",
    "end": "253040"
  },
  {
    "text": "what's happening not all of which are represented in the current state of your database tables um and then you know",
    "start": "253040",
    "end": "258600"
  },
  {
    "text": "this kind of machine data which is you know again for the website use case is application metrics you know what what",
    "start": "258600",
    "end": "265320"
  },
  {
    "text": "is a CPU load across all these servers in a data center um and application logs",
    "start": "265320",
    "end": "270680"
  },
  {
    "text": "this is again you know kind of events for machines and um so you know the problem",
    "start": "270680",
    "end": "276520"
  },
  {
    "text": "with these types of data they're much larger and you know the more traditional Data Systems are not built to to address",
    "start": "276520",
    "end": "282400"
  },
  {
    "text": "them uh the second thing is really the explosion of systems right so these are things which are at LinkedIn um that we",
    "start": "282400",
    "end": "288479"
  },
  {
    "text": "were running those are kind of our primary data systems that we made heavily use heavy use out of it's different for each company but there",
    "start": "288479",
    "end": "294800"
  },
  {
    "text": "there's kind of a multiplication of these things hopefully at some point there'll be some amount of contraction but but nonetheless it's it's pretty",
    "start": "294800",
    "end": "300840"
  },
  {
    "text": "diverse so we had some things that were basically key value stores we had something which was a kind of distributed graph engine that would",
    "start": "300840",
    "end": "306680"
  },
  {
    "text": "answer queries about who's connected to who and what are the paths between people um we had an analytical store",
    "start": "306680",
    "end": "312039"
  },
  {
    "text": "that would do the kind of like you know real time reporting like counting things",
    "start": "312039",
    "end": "317520"
  },
  {
    "text": "basically uh we had a search system which is how you search for people and we had a whole kind of uh you know",
    "start": "317520",
    "end": "322840"
  },
  {
    "text": "real-time monitoring layer then we had the offline World which was mostly Hadoop um and",
    "start": "322840",
    "end": "328400"
  },
  {
    "text": "terod um and as as these systems started to evolve uh this is kind of the world",
    "start": "328400",
    "end": "334560"
  },
  {
    "text": "we started ending up in so you have these different at the top different sources of data at the bottom these are",
    "start": "334560",
    "end": "339880"
  },
  {
    "text": "kind of different destinations for data and very slowly you start to kind of piece together these pipelines that ship",
    "start": "339880",
    "end": "345120"
  },
  {
    "text": "data from one thing to the other um and as you get to some scale each of these little lines actually gets a little bit",
    "start": "345120",
    "end": "351080"
  },
  {
    "text": "complicated right the data volume becomes large you're potentially shipping data uh around the world right",
    "start": "351080",
    "end": "356479"
  },
  {
    "text": "because you're operating out of multiple physical locations um there's different kind of requirements",
    "start": "356479",
    "end": "361960"
  },
  {
    "text": "typically uh you know a data warehouse is more of an offline you know load of data whereas a lot of these other things",
    "start": "361960",
    "end": "367479"
  },
  {
    "text": "are much more real time um and you you kind of get to this full connectivity where you have something on the order of",
    "start": "367479",
    "end": "373520"
  },
  {
    "text": "you know N squared pipelines that you're building between systems to shuffle data so that you can say search your logs and",
    "start": "373520",
    "end": "380360"
  },
  {
    "text": "search the you know people on LinkedIn but also get that same stuff into Hadoop and and that becomes this kind of",
    "start": "380360",
    "end": "385800"
  },
  {
    "text": "increasing set of complexity um where every system kind of ends up you know know uh knowing a little bit about every",
    "start": "385800",
    "end": "392160"
  },
  {
    "text": "other system and um the the solution we came up to you know we we came up with for",
    "start": "392160",
    "end": "398120"
  },
  {
    "text": "this is really a kind of central log and I'll talk about this this idea um where",
    "start": "398120",
    "end": "403319"
  },
  {
    "text": "everything you know kind of gets represented as a series of changes in this log and these changes are each you",
    "start": "403319",
    "end": "409479"
  },
  {
    "text": "know kind of structured record and so everything in the business is in some sense a series of structured changes and",
    "start": "409479",
    "end": "415560"
  },
  {
    "text": "so that would that would cover at LinkedIn that would cover everything from you know the page views that were ref in error messages in different",
    "start": "415560",
    "end": "421800"
  },
  {
    "text": "applications in the data center if you restart a machiney that's a that's a message uh changes to databases um and",
    "start": "421800",
    "end": "428840"
  },
  {
    "text": "that stuff would flow out into search indexes it would flow out into monitoring systems it would flow out into real-time processing systems uh it",
    "start": "428840",
    "end": "435919"
  },
  {
    "text": "would flow into Hadoop where you can run kind of like you know big batch jobs on it and became this kind of central you know distribution",
    "start": "435919",
    "end": "443479"
  },
  {
    "text": "Point uh and that system that that that kind of handled all that that log box in",
    "start": "443479",
    "end": "448520"
  },
  {
    "text": "the middle uh is called Kafka uh and so I'll talk a little bit about what it is and kind of where it came from um you",
    "start": "448520",
    "end": "454720"
  },
  {
    "text": "know we it it's a little bit hard to describe where we basically implemented a kind of distributed log um we call it",
    "start": "454720",
    "end": "460039"
  },
  {
    "text": "usually a messaging system because people are more familiar with that as a you know genre of infrastructure so you",
    "start": "460039",
    "end": "466120"
  },
  {
    "text": "know at a high level you have this cluster of machines which is acting as kind of a middleman and you have um you",
    "start": "466120",
    "end": "472039"
  },
  {
    "text": "know producers which are people sending a stream of messages um you know publishing messages you have consumers",
    "start": "472039",
    "end": "477240"
  },
  {
    "text": "who subscribe to that data and you would Oran iiz it you know we would say by topic so you might have you know uh page",
    "start": "477240",
    "end": "483199"
  },
  {
    "text": "views is one you know big stream that people are subscribing to and um uh for",
    "start": "483199",
    "end": "489039"
  },
  {
    "text": "a while this was kind of alone uh as a weird infrastructure thing but actually Amazon and some of the other cloud",
    "start": "489039",
    "end": "494680"
  },
  {
    "text": "service providers have have created similar uh systems to offer kind of as a service in the cloud so if you're in",
    "start": "494680",
    "end": "500319"
  },
  {
    "text": "Amazon you can use Kinesis is pretty similar actually down to the apis as as cka is um so it's becoming almost a",
    "start": "500319",
    "end": "506879"
  },
  {
    "text": "class of things um and yeah I can talk a little bit about",
    "start": "506879",
    "end": "512120"
  },
  {
    "text": "how we how we got here how we how we came up with this idea and how the infrastructure evolved so um you know",
    "start": "512120",
    "end": "517360"
  },
  {
    "text": "like I said we were we were kind of starting down this path of building these custom uh you know pipelines I was",
    "start": "517360",
    "end": "522680"
  },
  {
    "text": "managing one of the teams that was building one of them which was really for the Hadoop cluster um and I was managing another team that was building",
    "start": "522680",
    "end": "528959"
  },
  {
    "text": "another one which was for this key Value Store we' made and so it was just kind of weird that we were hiring people to shuffle data on two different parts and",
    "start": "528959",
    "end": "534920"
  },
  {
    "text": "they they're kind of doing the same thing um and at the same time we had kind of increasing requirements to be able to do um processing of data more",
    "start": "534920",
    "end": "542040"
  },
  {
    "text": "real time right so you know stream processing or reacting and Computing things quickly um and and so that was",
    "start": "542040",
    "end": "547800"
  },
  {
    "text": "how we thought well you know instead of having three projects we should probably try and combine these in some way and come up with this Central feed and we",
    "start": "547800",
    "end": "554079"
  },
  {
    "text": "went through a series of um you know kind of trial approaches where we we got different messaging systems and we we",
    "start": "554079",
    "end": "560839"
  },
  {
    "text": "kind of benchmarked them and we would like Fork off some of the production traffic and try and run it against it and see if that would work um we found",
    "start": "560839",
    "end": "567399"
  },
  {
    "text": "well you know they weren't really designed for this kind of thing um and in particular almost nothing was designed to be able to feed into an",
    "start": "567399",
    "end": "573519"
  },
  {
    "text": "offline system like Hadoop right so so in the Hadoop case you know that that system may go down for a period of time",
    "start": "573519",
    "end": "579600"
  },
  {
    "text": "and come back after maintenance you know in the in the meantime you're buffering up everything that happened in some large scale web company to feed to it um",
    "start": "579600",
    "end": "588000"
  },
  {
    "text": "so so none of our Solutions worked and then we started down the you know slightly crazy path of like making our own messaging system uh that would you",
    "start": "588000",
    "end": "595600"
  },
  {
    "text": "know hopefully share some of the properties of the different ad hoc Solutions we had because each had hoc",
    "start": "595600",
    "end": "601320"
  },
  {
    "text": "solution was good at least one thing so you know some were reliable at delivering data some were low latency",
    "start": "601320",
    "end": "607000"
  },
  {
    "text": "some were high throughput you know they each had to nail at least the one problem that they were there for and we thought well you know it must be",
    "start": "607000",
    "end": "612600"
  },
  {
    "text": "possible to make these things work together um and the basic design principles we had was you know first of",
    "start": "612600",
    "end": "617880"
  },
  {
    "text": "all one pipeline to roll them all we wanted to take the union of these requirements and try and put them together instead of making things you",
    "start": "617880",
    "end": "623000"
  },
  {
    "text": "know a bunch of ad hoc kind of bubble gum and duct cake duct tape uh Solutions",
    "start": "623000",
    "end": "628279"
  },
  {
    "text": "we try to make one thing that was good um that was both durable and and um you know high throughput and low latency um",
    "start": "628279",
    "end": "635399"
  },
  {
    "text": "second of all we wanted it to be a good basis for processing not just shipping data around so very often it's the case",
    "start": "635399",
    "end": "640639"
  },
  {
    "text": "you have to transform data that comes around that's like simple if uh you can",
    "start": "640639",
    "end": "646120"
  },
  {
    "text": "do all your transformation in a single process but if you have to be able to split the processing up then you need some kind of partitioning model and and",
    "start": "646120",
    "end": "652240"
  },
  {
    "text": "so on um and and finally you know we wanted something that was managed as a cluster right so I guess you know kind",
    "start": "652240",
    "end": "658560"
  },
  {
    "text": "of nature of of modern systems is you want to kind of think about it write to it operate it configure it as a cluster",
    "start": "658560",
    "end": "666040"
  },
  {
    "text": "rather than as an individual machine like you would with like you know a mySQL database where you kind of tune",
    "start": "666040",
    "end": "671600"
  },
  {
    "text": "one database and then another application has another database you know much nicer as something where you can think of like a distributed file",
    "start": "671600",
    "end": "677480"
  },
  {
    "text": "system you don't really think about which machine you're writing to um and that makes it obviously much easier to run at",
    "start": "677480",
    "end": "683079"
  },
  {
    "text": "scale um and so what that meant we had to do was um you know we we had to be able to provide scalability kind of kind",
    "start": "683079",
    "end": "689880"
  },
  {
    "text": "of like a file system um because if we wanted to replace these logging use cases usually the way people are doing",
    "start": "689880",
    "end": "696240"
  },
  {
    "text": "logs is they write it to the file system really quickly and then they kind of ship this log off somewhere eventually",
    "start": "696240",
    "end": "701880"
  },
  {
    "text": "so if we wanted to replace that use case this had to be fast it had to be efficient in terms of megabytes per second um we had to have guarantees that",
    "start": "701880",
    "end": "708560"
  },
  {
    "text": "were you know good enough to handle the database updates that we had in other words we had to be able to guarantee",
    "start": "708560",
    "end": "713800"
  },
  {
    "text": "that if you update your profile we wrote it to the database that that that update would get shipped into the you know the",
    "start": "713800",
    "end": "719240"
  },
  {
    "text": "data warehouse or the search system and it would get there um didn't have to get there all in one giant transaction but",
    "start": "719240",
    "end": "725079"
  },
  {
    "text": "it has to get there pretty quickly and it has to get there it can't remain permanently inconsistent um so so that",
    "start": "725079",
    "end": "730240"
  },
  {
    "text": "meant we had to have some guarantee around both The Ordering of updates and then also not losing updates in the",
    "start": "730240",
    "end": "736040"
  },
  {
    "text": "system um and I I already talked about you know making it distributed by default which means you know having a",
    "start": "736040",
    "end": "741320"
  },
  {
    "text": "partitioning model having replication among server so if you do a riot and a machine fails um you don't lose your",
    "start": "741320",
    "end": "746920"
  },
  {
    "text": "data this kind of stuff is just really required to make a system like this operable right you need to be able to go in and restart machines and not worry",
    "start": "746920",
    "end": "753480"
  },
  {
    "text": "too much about uh what's happening at the application Level while you're doing that um and so over over time this",
    "start": "753480",
    "end": "760199"
  },
  {
    "text": "became heavily used uh at LinkedIn at any given time there's you know uh",
    "start": "760199",
    "end": "765480"
  },
  {
    "text": "probably now this is a little older but maybe a couple hundred terabytes of inflight data that's kind of being shipped around um we replicate between",
    "start": "765480",
    "end": "773040"
  },
  {
    "text": "the different data centers that we serve out of and the offline data centers where we would have Hadoop and this kind of batch Warehouse",
    "start": "773040",
    "end": "780440"
  },
  {
    "text": "um the the load is pretty high both in terms of reads and writes and you know the there's tens of thousands of of",
    "start": "780440",
    "end": "787519"
  },
  {
    "text": "processes that are connected to this that are publishing or reading messages um all right so so that's kind",
    "start": "787519",
    "end": "793959"
  },
  {
    "text": "of Kafka um let me talk about kind of why what what what the abstraction Kafka",
    "start": "793959",
    "end": "799920"
  },
  {
    "text": "presents is and um you know how how it comes into play in our usage so so what kka provides I said is",
    "start": "799920",
    "end": "806800"
  },
  {
    "text": "kind of a log um and so so I guess I should start and kind of explain what a log is many people may already know this",
    "start": "806800",
    "end": "813160"
  },
  {
    "text": "it kind of depends if you have a a systemy background or not um you know I I guess uh most programmers when I talk",
    "start": "813160",
    "end": "819040"
  },
  {
    "text": "to them if you say log they think really like a text file with a bunch of updates in it I guess that is a log uh but but I",
    "start": "819040",
    "end": "825440"
  },
  {
    "text": "mean it more in the kind of commit log sense of a a structured ordered list of records that have been appended in some",
    "start": "825440",
    "end": "831320"
  },
  {
    "text": "kind of order um and so this is the abstraction that the Kafka provides it's",
    "start": "831320",
    "end": "837360"
  },
  {
    "text": "basically a series of changes um you know you are always appending to the end",
    "start": "837360",
    "end": "842519"
  },
  {
    "text": "uh the records are immutable they have some kind of sequence number that identifies them uh and you usually read",
    "start": "842519",
    "end": "848639"
  },
  {
    "text": "from the left to the right obviously left to right is kind of a madeup thing but we'll say it's left to right and",
    "start": "848639",
    "end": "855360"
  },
  {
    "text": "then um because we are kind of having lots of logs right one for maybe page views and one for changes to this",
    "start": "855360",
    "end": "861720"
  },
  {
    "text": "database and one for errors and and so on um and because some of those we're going to want to scale quite a lot we",
    "start": "861720",
    "end": "867399"
  },
  {
    "text": "actually provide a partitioning model so so so at LinkedIn every page view you know there's a topic called page view",
    "start": "867399",
    "end": "873480"
  },
  {
    "text": "which is actually made up of a bunch of partitions each partition is a lock all right so that's that's the abstraction",
    "start": "873480",
    "end": "879639"
  },
  {
    "text": "that that Kafka Pro provides um most people don't I also said it was a messaging system most people don't think",
    "start": "879639",
    "end": "886360"
  },
  {
    "text": "of logs as a way of doing messaging um but they are actually not a bad way of doing messaging um you can think of the",
    "start": "886360",
    "end": "893360"
  },
  {
    "text": "the publisher or the data source is doing rights which are appending to the log and then you can have any number of",
    "start": "893360",
    "end": "898480"
  },
  {
    "text": "processes which which are reading um and you can think of each of these readers as being caught up at some point in time",
    "start": "898480",
    "end": "905040"
  },
  {
    "text": "right and time here is really just this deterministic sequence number that we're keeping with the lock um and so if you",
    "start": "905040",
    "end": "911720"
  },
  {
    "text": "go back to our our uh horrible picture with all those different systems all subscribing to each other um you can",
    "start": "911720",
    "end": "918320"
  },
  {
    "text": "imagine how you can use something like this each of these you can reason about how caught up is that system what what time is it up to um for a bunch of",
    "start": "918320",
    "end": "924759"
  },
  {
    "text": "different data sources um so I I'll go through you know depending on people's backgrounds I I'll",
    "start": "924759",
    "end": "930800"
  },
  {
    "text": "go through a simple example of how logs um are used in systems and um kind of",
    "start": "930800",
    "end": "936240"
  },
  {
    "text": "give at least an analogy to how we use these in some of the systems that are are running at LinkedIn um in order to",
    "start": "936240",
    "end": "942199"
  },
  {
    "text": "uh kind of motivate this example I'll give kind of how to make a a fault tolerant hash table uh since this is a",
    "start": "942199",
    "end": "947480"
  },
  {
    "text": "popular thing and to make it concrete we'll we'll keep CEO names in our hash table",
    "start": "947480",
    "end": "952920"
  },
  {
    "text": "um so uh you know to motivate this example I'm basically trying to do a series of updates",
    "start": "952920",
    "end": "959360"
  },
  {
    "text": "and I want to kind of you know end up with this final state which is you know the for for each company name what's the",
    "start": "959360",
    "end": "965680"
  },
  {
    "text": "CEO right and if if I'm doing this in a single process is obviously very simple if I'm doing across machines it's more",
    "start": "965680",
    "end": "972560"
  },
  {
    "text": "complicated um and so I'll go through kind of how can you keep two two machines in sync um off of off of this",
    "start": "972560",
    "end": "979360"
  },
  {
    "text": "sequence of updates um and so an easy way you know one of the easy ways is is",
    "start": "979360",
    "end": "985279"
  },
  {
    "text": "a log right so if I if I log each of these updates to my hash table I can feed these against both replicas um I",
    "start": "985279",
    "end": "991440"
  },
  {
    "text": "can reason when I'm querying what's the state of my hash table how caught up is it uh so I can reason about how how",
    "start": "991440",
    "end": "996959"
  },
  {
    "text": "visible my data is um if one of these fails it can kind of Replay that log to come back into shape and so this starts",
    "start": "996959",
    "end": "1003600"
  },
  {
    "text": "to address some of the problems of of distribution um this is not a new idea",
    "start": "1003600",
    "end": "1009040"
  },
  {
    "text": "this is a very old idea um that's existed in systems for a long time uh the only difference I think is now in",
    "start": "1009040",
    "end": "1015519"
  },
  {
    "text": "addition to using it uh as an implementation detail of system we're also using it kind of in the large where",
    "start": "1015519",
    "end": "1020759"
  },
  {
    "text": "you have some Central commit log that's applying to these external systems that are are replicas of data um as it",
    "start": "1020759",
    "end": "1026319"
  },
  {
    "text": "happens we we end up also using this internally as a way of building our system so that uh our search system and",
    "start": "1026319",
    "end": "1032520"
  },
  {
    "text": "our social graph system we have a bunch of these kind of data stores they're actually built in this way as well right each of the nodes is subscribing to some",
    "start": "1032520",
    "end": "1039400"
  },
  {
    "text": "of these partitions keeping a local index it's good for certain types of queries and then answering queries",
    "start": "1039400",
    "end": "1044959"
  },
  {
    "text": "against this yeah what if that reach on the tra on the um yeah so I mean I guess",
    "start": "1044959",
    "end": "1052160"
  },
  {
    "text": "this is how you are how you are maintaining reads and rs across replicas so reads you know maybe if it's our",
    "start": "1052160",
    "end": "1058400"
  },
  {
    "text": "hashtable example it's get and so these are the replicas of your original yeah",
    "start": "1058400",
    "end": "1064080"
  },
  {
    "text": "yeah this is this is kind of how you can use a log to to provide uh you know some kind of consistency guarantees over",
    "start": "1064080",
    "end": "1071720"
  },
  {
    "text": "machines okay so now let me apply this back to the this data integration problem um Let me give a concrete",
    "start": "1071720",
    "end": "1078000"
  },
  {
    "text": "example uh one of the things LinkedIn has is jobs so uh there's a bunch of jobs on the website um when you start",
    "start": "1078000",
    "end": "1084880"
  },
  {
    "text": "out uh the logic for displaying a job is very simple you kind of get the job out of the database and you you show it to",
    "start": "1084880",
    "end": "1091120"
  },
  {
    "text": "the user uh but over time actually um what most companies do with with with data becomes more sophisticated and your",
    "start": "1091120",
    "end": "1098200"
  },
  {
    "text": "display of a job actually gets a lot more complicated um in this example I actually think I gave a subset of the",
    "start": "1098200",
    "end": "1103919"
  },
  {
    "text": "total set of things that happens when somebody views a job uh so that set of things would be well we monitor this",
    "start": "1103919",
    "end": "1110080"
  },
  {
    "text": "right so if our job views is important if that drops we want to know that something is bad uh we we do",
    "start": "1110080",
    "end": "1116440"
  },
  {
    "text": "recommendations for jobs we recommend them to people and so you know we actually keep track of what's the",
    "start": "1116440",
    "end": "1121760"
  },
  {
    "text": "click-through rate or the application rate for individual jobs so we can say oh this is a good match for this type of person so that system needs to know",
    "start": "1121760",
    "end": "1128320"
  },
  {
    "text": "whenever somebody views a job um we we provide analytics to the people who post jobs so we have to be able to show them",
    "start": "1128320",
    "end": "1134480"
  },
  {
    "text": "like hey you know you posted this job this is a number of people who looked at it for whatever much money you spent um",
    "start": "1134480",
    "end": "1141799"
  },
  {
    "text": "there's a security team which kind of analyzes all this type of activity to make sure we're not being scraped or",
    "start": "1141799",
    "end": "1147000"
  },
  {
    "text": "spammed or abused so anything that that happens there is going to get analyzed and finally there's kind of a data warehouse and so so you can see like",
    "start": "1147000",
    "end": "1154320"
  },
  {
    "text": "this is one example of that data integration problem each of these systems has to be updated um if if the",
    "start": "1154320",
    "end": "1159440"
  },
  {
    "text": "system that was responsible for displaying jobs had to update all those systems and doing so correctly and making sure you have the same",
    "start": "1159440",
    "end": "1164799"
  },
  {
    "text": "information available everywhere gets very complicated the way in practice they do that is they would you know they would publish an event it contains all",
    "start": "1164799",
    "end": "1171039"
  },
  {
    "text": "the information it says Hey a job view occurred this is all the information about the job view this is the time it happened this is a job that was view",
    "start": "1171039",
    "end": "1177039"
  },
  {
    "text": "this is the person who did it this is what you need to know and all of these other systems subscribe and apply that",
    "start": "1177039",
    "end": "1183400"
  },
  {
    "text": "change and and so you can kind of see this is this is similar to that you know logs inside a distributed system but",
    "start": "1183400",
    "end": "1190120"
  },
  {
    "text": "it's now actually across a bunch of systems you can think of this as a kind of central commit log for the data",
    "start": "1190120",
    "end": "1195640"
  },
  {
    "text": "center or wherever where you're you're journaling out updates and you're applying those across different systems",
    "start": "1195640",
    "end": "1201480"
  },
  {
    "text": "um and I would claim that this is actually a lot better than what most companies do for data transfer um so",
    "start": "1201480",
    "end": "1208120"
  },
  {
    "text": "depending on how much people know about that it's sort of the dirty secret of how large companies ship data around you know it's mostly a bunch of like CSV",
    "start": "1208120",
    "end": "1215480"
  },
  {
    "text": "dumps are syncing files around you know periodic jobs it's kind of it's kind of",
    "start": "1215480",
    "end": "1221000"
  },
  {
    "text": "a a murky a murky thing to reason about whether it works or not um the advantage here is you know okay first of all it's",
    "start": "1221000",
    "end": "1227480"
  },
  {
    "text": "real time uh so you you get updates quickly um it can be I think comparably High throughput to the kind of file",
    "start": "1227480",
    "end": "1233640"
  },
  {
    "text": "copies people are otherwise doing um and you can kind of react and process at the rate you want you can also you know do",
    "start": "1233640",
    "end": "1240720"
  },
  {
    "text": "it in batch and and do a batch load into a data warehouse so it has the same kind of advantages I think of of an offline",
    "start": "1240720",
    "end": "1246000"
  },
  {
    "text": "ETL cycle while allowing faster stuff um so finally I'll talk about one",
    "start": "1246000",
    "end": "1251720"
  },
  {
    "text": "one of the the things that we also got out of making all of our data available as realtime streams which is stream",
    "start": "1251720",
    "end": "1257679"
  },
  {
    "text": "processing right this is kind of the ability to uh react to each of these streams and compute something on the Fly",
    "start": "1257679",
    "end": "1264320"
  },
  {
    "text": "um so uh you know it's it's kind of an interesting question why uh more things",
    "start": "1264320",
    "end": "1270400"
  },
  {
    "text": "aren't done this way um I can give kind of one example from our experience which is when I first got to LinkedIn um a",
    "start": "1270400",
    "end": "1277200"
  },
  {
    "text": "pretty cool company called triso came and I think this was uh based out of maybe Telegraph CQ or one of the early",
    "start": "1277200",
    "end": "1283360"
  },
  {
    "text": "stream processing systems and and they came to sell us a stream processing engine and we were um we were actually",
    "start": "1283360",
    "end": "1289240"
  },
  {
    "text": "pretty enthusiastic we thought okay this is really cool we're going to use it and at that time when I had first got to LinkedIn we had no real-time data so we",
    "start": "1289240",
    "end": "1295279"
  },
  {
    "text": "took the system we were like really looking for anything we could hook it up to that we could run realtime queries against and of course um we found",
    "start": "1295279",
    "end": "1302919"
  },
  {
    "text": "nothing and you know the the best the best we could kind of come up with is we could take our hourly log files and we",
    "start": "1302919",
    "end": "1309039"
  },
  {
    "text": "could you know feed them into the stream processor at the end of at the end of the hour um but then we spent a bunch of",
    "start": "1309039",
    "end": "1315000"
  },
  {
    "text": "time and we uh we built Kafka we got everything going in real time and then actually it became very pressing once",
    "start": "1315000",
    "end": "1320279"
  },
  {
    "text": "all your data is available in real time you want to process it in real time and I think this is actually a fairly uh General uh thing about how uh companies",
    "start": "1320279",
    "end": "1328000"
  },
  {
    "text": "operate so so this is the uh first US Census and if you ever um if you ever",
    "start": "1328000",
    "end": "1334400"
  },
  {
    "text": "talk to a software engineer about the census one of the questions they have is like why do they just go around every 10",
    "start": "1334400",
    "end": "1340640"
  },
  {
    "text": "years and count everyone like going door to door why don't they just like journal the births and deaths and keep like a",
    "start": "1340640",
    "end": "1345679"
  },
  {
    "text": "running count all the time but it actually makes sense why they don't do it that way right when they started doing censuses they were doing it on",
    "start": "1345679",
    "end": "1352120"
  },
  {
    "text": "Horseback uh you know with large binders um so you literally had to kind of do this batch collection um and I think",
    "start": "1352120",
    "end": "1358799"
  },
  {
    "text": "this is actually not a bad metaphor for how a lot of companies it situations started where you have a bunch of systems that are kind of loosely",
    "start": "1358799",
    "end": "1365080"
  },
  {
    "text": "connected you're kind of periodically shipping data out over you know finicky",
    "start": "1365080",
    "end": "1370120"
  },
  {
    "text": "networks as Things become more digital as there's less people involved I think it's much it's very natural that that",
    "start": "1370120",
    "end": "1375880"
  },
  {
    "text": "large glump of data that's dumped periodically gets smaller and smaller and you end up with a stream that you",
    "start": "1375880",
    "end": "1381960"
  },
  {
    "text": "process um my view of how this works is pretty shaped by what we did at LinkedIn",
    "start": "1381960",
    "end": "1387200"
  },
  {
    "text": "which is basically we take these logs we apply um jobs that that transform the",
    "start": "1387200",
    "end": "1392279"
  },
  {
    "text": "feeds and produce new logs of changes and so we we ended up with a pretty uh Rich ecosystem of things that were",
    "start": "1392279",
    "end": "1398360"
  },
  {
    "text": "taking these uh feeds of of activity that were happening transforming them you know counting filtering whatever and",
    "start": "1398360",
    "end": "1404960"
  },
  {
    "text": "producing new feeds of transformed data those transformed feeds of course would get fed into to all the other things that uh data fed into so like derived",
    "start": "1404960",
    "end": "1411679"
  },
  {
    "text": "serving indexes um the the offline hop cluster the metrics and graphing system",
    "start": "1411679",
    "end": "1418000"
  },
  {
    "text": "so this becomes kind of the transformation layer in that big interconnected picture",
    "start": "1418000",
    "end": "1424000"
  },
  {
    "text": "um and you know when I when I talk to people about this there's there's kind of a perception that stream processing",
    "start": "1424000",
    "end": "1429720"
  },
  {
    "text": "is um you know kind of this uh kind of weak Niche you can't quite get the right",
    "start": "1429720",
    "end": "1435240"
  },
  {
    "text": "answers it's all you know kind of approximate um and actually that's not true uh you know the the stream",
    "start": "1435240",
    "end": "1441799"
  },
  {
    "text": "processing Frameworks that are out there today are a little bit immature but there's no particular reason that this model of computation has to be much",
    "start": "1441799",
    "end": "1448320"
  },
  {
    "text": "weaker than the batch model so so actually you know it is actually possible to move a lot of the things",
    "start": "1448320",
    "end": "1454080"
  },
  {
    "text": "that happen kind of on a daily cycle in companies to be much faster you can get correct results you can you can handle",
    "start": "1454080",
    "end": "1459440"
  },
  {
    "text": "all these things the fact that it hasn't all been done that way doesn't mean it can't be done um and the the examples",
    "start": "1459440",
    "end": "1466799"
  },
  {
    "text": "where this is particularly compelling um for uh a website like LinkedIn is really monitoring this is kind of how do you",
    "start": "1466799",
    "end": "1474039"
  },
  {
    "text": "keep track of what the heck is going on across all these computers and different business metrics and why why is it working or not working um anything",
    "start": "1474039",
    "end": "1481799"
  },
  {
    "text": "around security you know these are both domains where you want to react very quickly um content processing you know",
    "start": "1481799",
    "end": "1488840"
  },
  {
    "text": "if you if you kind of go in and update your LinkedIn profile we go in and we try and figure out okay you said you",
    "start": "1488840",
    "end": "1494399"
  },
  {
    "text": "worked at this company is that correct maybe that maps to this you know standardized company that everybody's a",
    "start": "1494399",
    "end": "1500399"
  },
  {
    "text": "part of um kind of all that data normalization a lot of the recommendation systems especially",
    "start": "1500399",
    "end": "1505559"
  },
  {
    "text": "anything that's dealing with click-through rate data uh the kind of news feed of updates that come in and tell you oh these are the people who",
    "start": "1505559",
    "end": "1512120"
  },
  {
    "text": "change jobs and finally some of the processing that happens as part of the ETL pipeline so all of these are",
    "start": "1512120",
    "end": "1517679"
  },
  {
    "text": "actually pretty naturally suited to lower latency stream processing versus a kind of daily batch",
    "start": "1517679",
    "end": "1523520"
  },
  {
    "text": "cycle um and there's a couple of Frameworks that are out there that can help um there's stor form and we worked",
    "start": "1523520",
    "end": "1529360"
  },
  {
    "text": "on one that was called samza uh both of these are pretty well integrated with Kafka so you can you can take these feeds and kind of transform them and",
    "start": "1529360",
    "end": "1536399"
  },
  {
    "text": "produce new outputs um the way samso works it's basically a layer that works",
    "start": "1536399",
    "end": "1541840"
  },
  {
    "text": "on top of Kafka and yarn which is kind of part of the Hado ecosystem and allows you to kind of run processes across lots",
    "start": "1541840",
    "end": "1548320"
  },
  {
    "text": "of machines um you you have a cluster like this you can run a bunch of jobs that are doing these Transformations and",
    "start": "1548320",
    "end": "1553720"
  },
  {
    "text": "producing data back out to Kafka uh and using that you get this kind of um you know integrated",
    "start": "1553720",
    "end": "1560399"
  },
  {
    "text": "architecture where uh anything that is is kind of produced as data comes into this kind of central log the stream",
    "start": "1560399",
    "end": "1567200"
  },
  {
    "text": "processing can transform it into some other log uh you can get kind of monitoring or warehousing or key value",
    "start": "1567200",
    "end": "1573360"
  },
  {
    "text": "storage on top of it um you can index it in your search system Etc you get this kind of very well integrated",
    "start": "1573360",
    "end": "1580399"
  },
  {
    "text": "picture um and that's what I had that that's uh that's basically the kind of Kafka samsa",
    "start": "1580399",
    "end": "1587480"
  },
  {
    "text": "pitch there's more detailed write up on this uh there's also actually I think they turned it into an O'Reilly book if",
    "start": "1587480",
    "end": "1593039"
  },
  {
    "text": "you want to kind of dive into more details uh I also in that go into more details on you know how you can actually",
    "start": "1593039",
    "end": "1598840"
  },
  {
    "text": "build the kind of drived uh serving systems we had off of these uh log structured data stores so um you know if",
    "start": "1598840",
    "end": "1605960"
  },
  {
    "text": "you're interested in that that's kind of a niche for people who are interested in building distributed Data Systems um but",
    "start": "1605960",
    "end": "1611840"
  },
  {
    "text": "that has more details on it um and I'm happy to answer whatever questions people have",
    "start": "1611840",
    "end": "1619399"
  },
  {
    "text": "question yeah so when you're talking about real time multiple producers consumers how do you make sure that the",
    "start": "1623559",
    "end": "1632000"
  },
  {
    "text": "streams gets consumed when they have different rate of processing your right",
    "start": "1632000",
    "end": "1638080"
  },
  {
    "text": "and where would this data be buffered if somebody just much much slower than",
    "start": "1638080",
    "end": "1644399"
  },
  {
    "text": "other yeah so the question is let's say you have many many people producing data",
    "start": "1644399",
    "end": "1649720"
  },
  {
    "text": "um and then you have different consumers that are operating on different uh time scales like one is very caught up and",
    "start": "1649720",
    "end": "1655240"
  },
  {
    "text": "the other is very far behind um what happens to the data that is not yet consumed how does that get buffered um",
    "start": "1655240",
    "end": "1661600"
  },
  {
    "text": "yeah so that's basically what Kafka does it basically acts as this giant buffer so you know what what",
    "start": "1661600",
    "end": "1668679"
  },
  {
    "text": "go no no so so let me talk a little bit I've kind of glossed over how cka",
    "start": "1668679",
    "end": "1674200"
  },
  {
    "text": "actually works because this is more like a how to use it what is it good four which is maybe the more important",
    "start": "1674200",
    "end": "1679760"
  },
  {
    "text": "question to answer first the way the way it works the way CCO works is it you know it literally maintains a log file",
    "start": "1679760",
    "end": "1686360"
  },
  {
    "text": "on disk okay so every time a write comes in it writes into this log file and that log file is replicated across machines",
    "start": "1686360",
    "end": "1692960"
  },
  {
    "text": "so so when a WR comes in it writes it the right replicates we acknowledge back and say oh we got you right um and so uh",
    "start": "1692960",
    "end": "1700279"
  },
  {
    "text": "so no like the the amount of buffering space you have in a Kafka cluster is the total disc space of all the machines",
    "start": "1700279",
    "end": "1707200"
  },
  {
    "text": "divided by the replication Factor you're using for your data so if you're using replication Factor 3 and uh you know",
    "start": "1707200",
    "end": "1713080"
  },
  {
    "text": "maybe you get 5 terab per machine you have 10 machines then you got 50 over3 uh terabytes of buffer space and so yeah",
    "start": "1713080",
    "end": "1720519"
  },
  {
    "text": "in fact not only do not all your consumers have to be totally caught up you can have consumers like a warehouse",
    "start": "1720519",
    "end": "1726440"
  },
  {
    "text": "type consumer that just pops up once a day sucks down The Daily ETL load should you choose to run your ETL in a daily",
    "start": "1726440",
    "end": "1732960"
  },
  {
    "text": "cycle processes it and goes on its business and that's actually kind of one of the primary things you need it",
    "start": "1732960",
    "end": "1738279"
  },
  {
    "text": "actually turns out to also be really important for stream processing um the reason being okay you would think stream",
    "start": "1738279",
    "end": "1743840"
  },
  {
    "text": "processing it's all real time they should all be caught up yeah I mean maybe right but this is a company full of people working somebody's thing kind",
    "start": "1743840",
    "end": "1750159"
  },
  {
    "text": "of breaks down or slows up and can't keep up uh you can't have everything kind of backing up backing up and the",
    "start": "1750159",
    "end": "1756799"
  },
  {
    "text": "whole data flow processing graph grinds to a halt because one guy you know checked in a bug um so that buffering",
    "start": "1756799",
    "end": "1764039"
  },
  {
    "text": "capability is extremely important um on a companywide scale",
    "start": "1764039",
    "end": "1769840"
  },
  {
    "text": "what's the data generation rate would you use uh yeah that's a good question I",
    "start": "1769840",
    "end": "1774960"
  },
  {
    "text": "think I had some stats which may be slightly out of date",
    "start": "1774960",
    "end": "1781000"
  },
  {
    "text": "but I think we were claiming we had about 175 terabytes of inflight per day",
    "start": "1785559",
    "end": "1790679"
  },
  {
    "text": "so that would be 175 terabytes of new updates or whatever and I think that that is",
    "start": "1790679",
    "end": "1797279"
  },
  {
    "text": "probably the compressed number pre-replication I guess if you multiply if you count each",
    "start": "1797279",
    "end": "1803960"
  },
  {
    "text": "right three times then I guess it's bigger what do you think is the average size of a record uh yeah okay question",
    "start": "1803960",
    "end": "1810120"
  },
  {
    "text": "is what's the average size of a record it actually varies a lot so um some of the records are very small they're just",
    "start": "1810120",
    "end": "1817120"
  },
  {
    "text": "a few IDs like this person did this thing at this time stamp da d da and all the things are normalized so you just refer them by ID and it's very tight",
    "start": "1817120",
    "end": "1823600"
  },
  {
    "text": "we're using something called Avo which kind of helps shrink the data down",
    "start": "1823600",
    "end": "1828880"
  },
  {
    "text": "um other things are actually these incredibly large records with lots of",
    "start": "1828880",
    "end": "1834399"
  },
  {
    "text": "key value pairs describing all kinds of context around what was happening so it totally depends on the type of data um",
    "start": "1834399",
    "end": "1840720"
  },
  {
    "text": "so for example application error logs tend to be very verose with like huge",
    "start": "1840720",
    "end": "1845880"
  },
  {
    "text": "error stack traces and error messages and whatever um other things tended to",
    "start": "1845880",
    "end": "1851519"
  },
  {
    "text": "be very small it's totally it's basically this was an open system so in the end there was actually um probably",
    "start": "1851519",
    "end": "1858720"
  },
  {
    "text": "well over a thousand um of these topics of data created by different people and so it kind of is whatever whatever",
    "start": "1858720",
    "end": "1865399"
  },
  {
    "text": "somebody put there so do you normalize data at all before it receives K before kco receives",
    "start": "1865399",
    "end": "1872919"
  },
  {
    "text": "it or do you do that all after when when you consume consumers are working on",
    "start": "1872919",
    "end": "1878360"
  },
  {
    "text": "yeah yeah so um if you yeah the question is like what kind of normalization is there for data the way it is usually",
    "start": "1878360",
    "end": "1885279"
  },
  {
    "text": "convenient to uh write stuff is usually by IDs usually whenever you're working with data in one of the applications you",
    "start": "1885279",
    "end": "1890960"
  },
  {
    "text": "have the ID so you have a user ID maybe a job you have a job ID a geography has an ID everything has an ID right so you",
    "start": "1890960",
    "end": "1897480"
  },
  {
    "text": "would probably be writing out those IDs um if you want to get back any more attributes about that thing you have to",
    "start": "1897480",
    "end": "1902840"
  },
  {
    "text": "join it on which is what people you have what happens in the Stream processing layer or offline in Hadoop very commonly",
    "start": "1902840",
    "end": "1908000"
  },
  {
    "text": "you read from other databases information yeah yeah yeah this is actually an interesting design point so",
    "start": "1908000",
    "end": "1914559"
  },
  {
    "text": "it's very common um that there's a lot of debate so the people who process data they typically want you to add",
    "start": "1914559",
    "end": "1920679"
  },
  {
    "text": "everything in for them so that the feed has everything the people who generate data usually don't want to do that because it's slow and a big pain in the",
    "start": "1920679",
    "end": "1927159"
  },
  {
    "text": "butt and so there's some debate over what what makes it into the event and what doesn't um I'm not sure what the",
    "start": "1927159",
    "end": "1932880"
  },
  {
    "text": "right answer is I mean I think if you find yourself like we had situations where someone would be like querying the",
    "start": "1932880",
    "end": "1938440"
  },
  {
    "text": "social graph to find out distance information to figure out some distance to put in the logging event that's",
    "start": "1938440",
    "end": "1944399"
  },
  {
    "text": "probably not really required you're like slowing down the site right like probably that should be done offline um",
    "start": "1944399",
    "end": "1949519"
  },
  {
    "text": "so so I guess usually the principle is do it offline if you can um but sometimes there's things that are just",
    "start": "1949519",
    "end": "1955240"
  },
  {
    "text": "so convenient for analysis you might as well just stick it in I I don't know that there's a hard and fast role other",
    "start": "1955240",
    "end": "1960679"
  },
  {
    "text": "question I'm trying to understand the size of this cluster with so many reads and writes happening per second with the",
    "start": "1960679",
    "end": "1967120"
  },
  {
    "text": "latency of 1.5 yeah no I I think uh the latency I should say that this is a",
    "start": "1967120",
    "end": "1973279"
  },
  {
    "text": "mixture of um observed and performance test data the latency is probably more a",
    "start": "1973279",
    "end": "1979240"
  },
  {
    "text": "performance test result um the actual observed latency depends on three things it depends on the buffering in the",
    "start": "1979240",
    "end": "1985399"
  },
  {
    "text": "clients um it depends on what data center you're in because we replicate asynchronously between data centers um",
    "start": "1985399",
    "end": "1991679"
  },
  {
    "text": "so it depending on the amount of buffering it can be higher that's really just the time it takes with no buffering",
    "start": "1991679",
    "end": "1996720"
  },
  {
    "text": "to do a right have it replicate out to two replicas and have the the consumer process together so in this case this is",
    "start": "1996720",
    "end": "2004320"
  },
  {
    "text": "for for data center like for Colo for yeah know I I think the the size data is",
    "start": "2004320",
    "end": "2011399"
  },
  {
    "text": "probably overall and I think that the um the rights and reads per second I think",
    "start": "2011399",
    "end": "2017159"
  },
  {
    "text": "are probably also overall um I I don't I don't think those are per data center",
    "start": "2017159",
    "end": "2022919"
  },
  {
    "text": "but it appears that that cluster would run into thousands of notes or no no so um yeah okay question is how big how big",
    "start": "2022919",
    "end": "2029720"
  },
  {
    "text": "of how big is a Kafka cluster so um I guess you know we we we had two things that were usually actually pretty",
    "start": "2029720",
    "end": "2036159"
  },
  {
    "text": "closely related one is Hadoop and the is Kafka the reason they're related is because everything that went into hio pretty much came from Kafka um but",
    "start": "2036159",
    "end": "2042919"
  },
  {
    "text": "they're not the same size and the reason they're not the same size is because Kafka is just keeping data by default",
    "start": "2042919",
    "end": "2048158"
  },
  {
    "text": "for a week and then some people would set it to longer so that they could replay off of that but it it's not",
    "start": "2048159",
    "end": "2053200"
  },
  {
    "text": "keeping it forever whereas hio was keeping two years retention um and that pretty much determines the size it also",
    "start": "2053200",
    "end": "2059480"
  },
  {
    "text": "deter the processing model is also really different right a stream processing engine is much more efficient",
    "start": "2059480",
    "end": "2064520"
  },
  {
    "text": "it mostly just keeps up with the live stream so if you process a Year's worth of data in a stream processing system",
    "start": "2064520",
    "end": "2070720"
  },
  {
    "text": "you do it in a year if you process a Year's worth of data in a batch system you're usually trying to do it as quickly as possible and so the number of",
    "start": "2070720",
    "end": "2076720"
  },
  {
    "text": "nodes in an offline system ends up kind of ballooning up because of that and so like our I think we had thousands of",
    "start": "2076720",
    "end": "2082760"
  },
  {
    "text": "Hado machines total Kafka footprint was like maybe 300 machines but by no means",
    "start": "2082760",
    "end": "2089358"
  },
  {
    "text": "the reason for that was like oh we would have a cluster for each acquisition because they're in different data centers and then we segregated",
    "start": "2089359",
    "end": "2095599"
  },
  {
    "text": "operational data from business data so that led to different clusters and then you need a cluster and so like it kind",
    "start": "2095599",
    "end": "2101400"
  },
  {
    "text": "of counts up but you know like probably the individual sizes of the Clusters was",
    "start": "2101400",
    "end": "2106760"
  },
  {
    "text": "like 20 or 30 nodes something like that they're not they're not huge um so let's",
    "start": "2106760",
    "end": "2112320"
  },
  {
    "text": "3 400 what do it so essentially it's handling maybe 100,000 messages per note",
    "start": "2112320",
    "end": "2117640"
  },
  {
    "text": "per second yeah that's probably that's probably reasonable um if you think",
    "start": "2117640",
    "end": "2122880"
  },
  {
    "text": "about it this is like a throughput oriented system so it's pretty easy to get good throughput like",
    "start": "2122880",
    "end": "2128520"
  },
  {
    "text": "100,000 is not really that much when you kind of like multiply it by bites and turn it into iio Yeah question um I read",
    "start": "2128520",
    "end": "2136359"
  },
  {
    "text": "on your block that you're using it on real Hardware instead of virtual machines can you talk a little bit about",
    "start": "2136359",
    "end": "2142960"
  },
  {
    "text": "that and what the performance implications are that you found yeah sure um so the question is you know you",
    "start": "2142960",
    "end": "2149480"
  },
  {
    "text": "guys are running this on real machines kind of why and what are the performance implications um so we uh you know",
    "start": "2149480",
    "end": "2155800"
  },
  {
    "text": "LinkedIn is not in AWS so we run everything on on real machines we have",
    "start": "2155800",
    "end": "2161800"
  },
  {
    "text": "uh systems that kind of deploy software out to everything so I guess there's some level of elasticity on the machines",
    "start": "2161800",
    "end": "2168119"
  },
  {
    "text": "you have but there's no like um uh you know KVM or Zen or something layer in",
    "start": "2168119",
    "end": "2174800"
  },
  {
    "text": "fact it doesn't really make sense within a c company that you would need that like virtualizing the OS you kind of are",
    "start": "2174800",
    "end": "2180160"
  },
  {
    "text": "all using the same OS at a certain point yeah you realize oh we're running 20 yeah I don't know uh so um so so yeah",
    "start": "2180160",
    "end": "2188200"
  },
  {
    "text": "the question is I guess there's a couple ways you could ask it like one question you could ask is why isn't LinkedIn and",
    "start": "2188200",
    "end": "2193640"
  },
  {
    "text": "AWS another question you could ask is does kfka Work Well in that virtualized",
    "start": "2193640",
    "end": "2199079"
  },
  {
    "text": "environment it's a bunch of different things I mean basically at a certain scale um you kind of want to pay attention to efficiencies and you can",
    "start": "2199079",
    "end": "2206640"
  },
  {
    "text": "probably do it cheaper yourself I guess linkedin's probably at that scale at this point um I know we did some cost",
    "start": "2206640",
    "end": "2212480"
  },
  {
    "text": "stuff and it was basically cheaper yeah well with us it's more like the data center is just built that way it's own",
    "start": "2212480",
    "end": "2218599"
  },
  {
    "text": "but they put I mean they have machines and they carve out certain junks of it",
    "start": "2218599",
    "end": "2223720"
  },
  {
    "text": "the machines are just so big quote unquote doesn't make sense to just leverage a full machine for yeah one",
    "start": "2223720",
    "end": "2230400"
  },
  {
    "text": "node totally and so the question is basically at what point if you did did",
    "start": "2230400",
    "end": "2236200"
  },
  {
    "text": "you see that it make just made sense to go onto real Hardware versus staying on",
    "start": "2236200",
    "end": "2241560"
  },
  {
    "text": "yeah yeah okay so I can answer that both ways so so LinkedIn and other web companies they have the opposite problem",
    "start": "2241560",
    "end": "2246800"
  },
  {
    "text": "as what's typically solved by virtualization typically virtualization is like we have way more applications",
    "start": "2246800",
    "end": "2252640"
  },
  {
    "text": "than machines so we want to shove a lot of applications on a one machine uh I think most of the web companies actually",
    "start": "2252640",
    "end": "2258160"
  },
  {
    "text": "have the opposite problem which is they need to actually scale applications over large clusters of machines so they're doing like the opposite thing which is",
    "start": "2258160",
    "end": "2264119"
  },
  {
    "text": "managing applications over pools of Hardware um and we have some internal stuff to do that I guess there's systems",
    "start": "2264119",
    "end": "2269520"
  },
  {
    "text": "out now like misos which are uh meant to be kind of general purpose solutions to that um the kfka will actually run quite",
    "start": "2269520",
    "end": "2277760"
  },
  {
    "text": "well on AWS I think there's a number of the the biggest Kafka users are like Netflix Pinterest whatever and are",
    "start": "2277760",
    "end": "2283960"
  },
  {
    "text": "totally doing it that way you do take some IO hit um in with that type of",
    "start": "2283960",
    "end": "2290040"
  },
  {
    "text": "virtualization uh but it's it's not uh very large one of the things we paid very close attention to is since we're",
    "start": "2290040",
    "end": "2295800"
  },
  {
    "text": "just keeping a log um we are doing really very simple linear IO it's kind",
    "start": "2295800",
    "end": "2301160"
  },
  {
    "text": "of the simplest possible IO model it works with old-fashioned spinning rust",
    "start": "2301160",
    "end": "2307119"
  },
  {
    "text": "disc uh and it it doesn't you know suffer terribly by",
    "start": "2307119",
    "end": "2312280"
  },
  {
    "text": "virtualization um they seem to have some weird things like the first time you write in AWS you pay some penalty and",
    "start": "2312280",
    "end": "2317720"
  },
  {
    "text": "whatever but um so you definitely take a hit but but it seems to be totally fine to run uh the people who run there don't",
    "start": "2317720",
    "end": "2324359"
  },
  {
    "text": "seem to have any big operational changes in how they run it other than the interesting thing is they actually choose to run much larger clusters on",
    "start": "2324359",
    "end": "2331599"
  },
  {
    "text": "smaller uh Hardware um because the cost of losing one is less um and I guess you",
    "start": "2331599",
    "end": "2338079"
  },
  {
    "text": "can so that was that was the only major difference I I came up with from looking at their setup and",
    "start": "2338079",
    "end": "2344839"
  },
  {
    "text": "ours question so in the example slide which is I would say are use cases CFT",
    "start": "2344839",
    "end": "2351200"
  },
  {
    "text": "right so your monitoring and security which are also The Sweet Spot of slunk",
    "start": "2351200",
    "end": "2356440"
  },
  {
    "text": "and that's right um so how would you compare this solution to the wellknown",
    "start": "2356440",
    "end": "2364240"
  },
  {
    "text": "yeah spun B solution yeah okay so this the question how does this compare to swun um which is a good question um yeah",
    "start": "2364240",
    "end": "2371000"
  },
  {
    "text": "this is a much more platformy approach so the good news about this is it's like this open piece of infrastructure",
    "start": "2371000",
    "end": "2376240"
  },
  {
    "text": "everything can plug into it's open source um Etc um the you know Splunk I",
    "start": "2376240",
    "end": "2382240"
  },
  {
    "text": "think did a great job of putting together an endtoend Pipeline with a search engine on the other end for",
    "start": "2382240",
    "end": "2388040"
  },
  {
    "text": "really text logs right and they've kind of branched out to other stuff um I think the thesis I have is that this",
    "start": "2388040",
    "end": "2395240"
  },
  {
    "text": "kind of like log or event data is really an important thing and so the way you get started of course is with a kind of",
    "start": "2395240",
    "end": "2400400"
  },
  {
    "text": "vertically integrated pipeline like Splunk but I think the end result for companies is they'll have something that's more general purpose that cuts",
    "start": "2400400",
    "end": "2406480"
  },
  {
    "text": "across different data sources and and plugs into you know more outputs allows richer processing Primitives and so on",
    "start": "2406480",
    "end": "2413920"
  },
  {
    "text": "um rather than a you know proprietary vertical pipeline um time time will tell and in terms of performance let's say",
    "start": "2413920",
    "end": "2420359"
  },
  {
    "text": "the same blocks that coming spunk versus C how would you yeah I mean so so I",
    "start": "2420359",
    "end": "2425520"
  },
  {
    "text": "would describe Splunk the question is about what's the performance of Splunk versus kakka I mean kakka is basically a",
    "start": "2425520",
    "end": "2431119"
  },
  {
    "text": "log and so you know it's very fast to logging data if you want to get a good",
    "start": "2431119",
    "end": "2437359"
  },
  {
    "text": "performance summary um this is more like uh production data but we did do a good",
    "start": "2437359",
    "end": "2442599"
  },
  {
    "text": "performance blog if you Google for like Kafka performance or whatever there's a um a reasonable rundown of like okay",
    "start": "2442599",
    "end": "2449520"
  },
  {
    "text": "with different replication levels and acknowledgement guarantees and so on um but splunk's Focus has actually I",
    "start": "2449520",
    "end": "2455640"
  },
  {
    "text": "Believe been more on indexing and and so you know unless you know a multi subscriber log to Fan out to other",
    "start": "2455640",
    "end": "2462319"
  },
  {
    "text": "systems right mostly they want you to Fan it into Splunk and they they have some hookups to Hadoop and a few other",
    "start": "2462319",
    "end": "2468319"
  },
  {
    "text": "things um the so I guess their performan is I think and we were a long time ago",
    "start": "2468319",
    "end": "2475000"
  },
  {
    "text": "we were we were a customer of spunk um at that time their performance was very driven by indexing speed of their search",
    "start": "2475000",
    "end": "2481520"
  },
  {
    "text": "component um so I don't know that it would really make sense to compare their search indexing which is probably a much",
    "start": "2481520",
    "end": "2487400"
  },
  {
    "text": "expensive operation with you know the fast cheap logging uh that we do um well",
    "start": "2487400",
    "end": "2492920"
  },
  {
    "text": "my question would be more than you know once C has the logs there's some processing that needs to happen in case",
    "start": "2492920",
    "end": "2498079"
  },
  {
    "text": "of spunk search indexing in application is there on top of C yeah that's right",
    "start": "2498079",
    "end": "2504040"
  },
  {
    "text": "then how that's right yeah so so an equivalent thing if you were trying to make an open source Splunk like thing",
    "start": "2504040",
    "end": "2510079"
  },
  {
    "text": "that would be something like elastic search or solar which are the kind of Open Source you know search things very",
    "start": "2510079",
    "end": "2516760"
  },
  {
    "text": "commonly used with logs and Kafka would be a sort of data pipeline for that and",
    "start": "2516760",
    "end": "2522520"
  },
  {
    "text": "along the same lines you have recommendations as one of the examples yeah uh how easy or good that",
    "start": "2522520",
    "end": "2530079"
  },
  {
    "text": "recommendation engine would be to do it on top of streaming versus offline yeah yeah I put recommendations that's more a",
    "start": "2530079",
    "end": "2537560"
  },
  {
    "text": "family of different types of applications than it is an application we built a bunch of different uh",
    "start": "2537560",
    "end": "2544119"
  },
  {
    "text": "recommendation things and there's bunch of techniques that all work differently so we had uh you know batch algorithms",
    "start": "2544119",
    "end": "2551680"
  },
  {
    "text": "that would recompute periodically um we had things that were click-through rate based which I think is the best match",
    "start": "2551680",
    "end": "2558240"
  },
  {
    "text": "for this kind of streaming stuff where you're looking at what's popular now um",
    "start": "2558240",
    "end": "2563559"
  },
  {
    "text": "the that's really probably the best fit for this kind of streaming model is what's popular now what's what's",
    "start": "2563559",
    "end": "2569720"
  },
  {
    "text": "trending you know you basically take the attributes of the user you pull click through rates or whatever by those",
    "start": "2569720",
    "end": "2575480"
  },
  {
    "text": "attributes and you do some modeling based on that to roll it up the areas where that makes sense is like ads news",
    "start": "2575480",
    "end": "2581319"
  },
  {
    "text": "things where popularity and freshness matter um anything where there's no freshness component can just be totally",
    "start": "2581319",
    "end": "2587720"
  },
  {
    "text": "done offline so for example uh we do similar you know profiles if you go to",
    "start": "2587720",
    "end": "2593640"
  },
  {
    "text": "somebody's profile that has a long list that was something I worked on a long time ago that's totally done offline it doesn't change that often like people",
    "start": "2593640",
    "end": "2599160"
  },
  {
    "text": "aren't becoming similar to each other or dis similar very quickly uh so it gets recomputed like maybe every day or",
    "start": "2599160",
    "end": "2605920"
  },
  {
    "text": "something um and there's not that much value in making it faster question uh would you recommend",
    "start": "2605920",
    "end": "2612680"
  },
  {
    "text": "the system for something that's not um say a Social Network website but say um",
    "start": "2612680",
    "end": "2618240"
  },
  {
    "text": "a sequence of nuclear reactors that are all you know again have have data logs and error reports and the same sort of",
    "start": "2618240",
    "end": "2624440"
  },
  {
    "text": "things except on a different scale yeah possibly I I um i' I I don't know",
    "start": "2624440",
    "end": "2629640"
  },
  {
    "text": "anything about that application so that's IED or a sequence of ground stations",
    "start": "2629640",
    "end": "2634800"
  },
  {
    "text": "that so um you know something similar to this is actually uh very similar in uh a",
    "start": "2634800",
    "end": "2640839"
  },
  {
    "text": "lot of finance companies like Financial Services anybody who kind of comes into who has to come into this real-time",
    "start": "2640839",
    "end": "2646680"
  },
  {
    "text": "domain very often ends up with a similar thing where you have some kind of log and you have a bunch of things that feed off of it and you have replicas of that",
    "start": "2646680",
    "end": "2652880"
  },
  {
    "text": "um so yeah I I actually think it's um I think it's actually a pretty good",
    "start": "2652880",
    "end": "2657960"
  },
  {
    "text": "General way I've used a lot of like social network examples because I know them um but but yeah I think it is",
    "start": "2657960",
    "end": "2663880"
  },
  {
    "text": "pretty General the things that have to be true for this system to make sense is your has to be record oriented um which",
    "start": "2663880",
    "end": "2669800"
  },
  {
    "text": "is not always true so if you have like if your events are like genomes or something they're probably pretty big",
    "start": "2669800",
    "end": "2675839"
  },
  {
    "text": "they don't really make sense as events this is really like things happened the things are you know records they're",
    "start": "2675839",
    "end": "2681720"
  },
  {
    "text": "happening really quickly our data model is like the world is streams of Records so if you don't have",
    "start": "2681720",
    "end": "2687640"
  },
  {
    "text": "records this probably isn't a good fit um and then you know you would have to get some value out of the uh processing",
    "start": "2687640",
    "end": "2695440"
  },
  {
    "text": "things kind of as they occur uh versus um at least some scientific Computing",
    "start": "2695440",
    "end": "2700920"
  },
  {
    "text": "applications maybe you just have a big pool of data and you run some cool algorithms on it and you get the result",
    "start": "2700920",
    "end": "2706079"
  },
  {
    "text": "but the data isn't really changing as quickly um so so I don't know if it's I don't know if it's a good pit for that",
    "start": "2706079",
    "end": "2711319"
  },
  {
    "text": "but yeah it definitely has found um usage in like a bunch of non web",
    "start": "2711319",
    "end": "2716800"
  },
  {
    "text": "companies so like telecom companies finance companies and so on cool question on the back um a couple",
    "start": "2716800",
    "end": "2724480"
  },
  {
    "text": "questions come to mind around just vision of the future and um ecosystem",
    "start": "2724480",
    "end": "2732040"
  },
  {
    "text": "that You' like to see emerge around this for example an app store of producer and",
    "start": "2732040",
    "end": "2738359"
  },
  {
    "text": "consumers and we kind of standardize on a bus um confluent Confluence is that yeah",
    "start": "2738359",
    "end": "2745920"
  },
  {
    "text": "yeah Confluence is the company s do you see that as being a steward for open",
    "start": "2745920",
    "end": "2752160"
  },
  {
    "text": "source in the doctor sense or do you see that going as the kesis direction of cop",
    "start": "2752160",
    "end": "2758720"
  },
  {
    "text": "as a service yeah so so uh one of the early things you know I guess the",
    "start": "2758720",
    "end": "2764000"
  },
  {
    "text": "question was uh what's the company doing well I mean we're just getting off the ground so we're still figuring out but",
    "start": "2764000",
    "end": "2770200"
  },
  {
    "text": "uh another question was you know what what about all these different plugins to connect different systems yeah being",
    "start": "2770200",
    "end": "2776200"
  },
  {
    "text": "able to make those work in a standard way have a common data model across them so it's easier to plug things together",
    "start": "2776200",
    "end": "2781319"
  },
  {
    "text": "that's kind of like super lwh hanging fruit thing we'd like to take care of",
    "start": "2781319",
    "end": "2787240"
  },
  {
    "text": "any other questions okay did I hear a company name at any point yeah yeah the company name is",
    "start": "2787240",
    "end": "2793160"
  },
  {
    "text": "confluent okay okay confluent um and what was the motivation to start",
    "start": "2793160",
    "end": "2801720"
  },
  {
    "text": "I mean my first my question when you came in was why isn't this a company but why is it a company yeah so the question",
    "start": "2801720",
    "end": "2809400"
  },
  {
    "text": "is why is this a company um the yeah the answer is we thought this was basically a much better way of organizing your",
    "start": "2809400",
    "end": "2816240"
  },
  {
    "text": "data uh than what most companies were doing and we thought it was not totally",
    "start": "2816240",
    "end": "2822240"
  },
  {
    "text": "feasible to get everybody in the world to do it via an open source project um",
    "start": "2822240",
    "end": "2827720"
  },
  {
    "text": "you can kind of get a certain amount of the way where people who uh are very technically sophisticated have a large",
    "start": "2827720",
    "end": "2833040"
  },
  {
    "text": "team of Engineers to throw on it and adopt things quickly we'll do it and that's kind of the state we're in now um",
    "start": "2833040",
    "end": "2838319"
  },
  {
    "text": "but to get the rest of the way uh I think it actually requires more money it requires more support and so on so so",
    "start": "2838319",
    "end": "2844400"
  },
  {
    "text": "yeah so the mission of the company is basically to make this real time data stuff work right to make you know the data flow and data integration problem",
    "start": "2844400",
    "end": "2851000"
  },
  {
    "text": "work this way um replace the kind of our sync batch files uh make stream",
    "start": "2851000",
    "end": "2856400"
  },
  {
    "text": "processing a reasonable way to consume that data uh and transform it into other things um that's what we're that's what",
    "start": "2856400",
    "end": "2863119"
  },
  {
    "text": "we're trying to accomplish and and the reason for the company is just because um you can only go so far uh on GitHub I",
    "start": "2863119",
    "end": "2869559"
  },
  {
    "text": "guess so so like it's like K clera that sort of thing yeah that's right yeah",
    "start": "2869559",
    "end": "2876160"
  },
  {
    "text": "we're not we're not looking to do any kind of hosted uh Kafka I think this naturally lives wherever the rest of",
    "start": "2876160",
    "end": "2881319"
  },
  {
    "text": "your systems live so if that's in the cloud then you would run it in the cloud but if it's if it's on premise in your own data center then",
    "start": "2881319",
    "end": "2887200"
  },
  {
    "text": "it's say IBM Consulting of you've got these problems we will make solutions",
    "start": "2887200",
    "end": "2892280"
  },
  {
    "text": "for you and give them back to you yeah that's right we're we're we're not really doing heavy Consulting um we're",
    "start": "2892280",
    "end": "2897359"
  },
  {
    "text": "going to kind of take take this package and put together uh a set of things that that people can use you know uh product",
    "start": "2897359",
    "end": "2904040"
  },
  {
    "text": "services so in terms of the processing infrastructure on top of it yeah so you",
    "start": "2904040",
    "end": "2910720"
  },
  {
    "text": "mentioned about stream processing on top so what kind of uh modules of components",
    "start": "2910720",
    "end": "2915839"
  },
  {
    "text": "you anticipate in this package yeah yeah I you know I'm not sure uh we basically",
    "start": "2915839",
    "end": "2921240"
  },
  {
    "text": "just just announced the company like two days ago so we're still figuring it out",
    "start": "2921240",
    "end": "2927119"
  },
  {
    "text": "um question back yeah um so I've read the the data bus paper and been curious",
    "start": "2927119",
    "end": "2933480"
  },
  {
    "text": "is that Co yeah no uh it's actually says there was the history of this is there was actually a a system before Kafka at",
    "start": "2933480",
    "end": "2941079"
  },
  {
    "text": "LinkedIn that was virtually identical in the abstraction it it provided um and it was called datab bus um and uh the",
    "start": "2941079",
    "end": "2949559"
  },
  {
    "text": "caveat on it was it only worked with databases so um it would it basically",
    "start": "2949559",
    "end": "2955160"
  },
  {
    "text": "acted as a sort of cache for whatever the database log was and and it was used in this way and then um basically we",
    "start": "2955160",
    "end": "2962480"
  },
  {
    "text": "liked that so much it was built originally to feed like the social graph and Sur search so it was like very very",
    "start": "2962480",
    "end": "2968280"
  },
  {
    "text": "straightforward we had you know relational database we had a social Graph Search system they each had a",
    "start": "2968280",
    "end": "2974000"
  },
  {
    "text": "bunch of machines they had to be fed changes we built this like cash for the log and we fed it out and then we were",
    "start": "2974000",
    "end": "2980040"
  },
  {
    "text": "like oh my God this is the best way to feed changes around everything we're doing is basically feeding changes um",
    "start": "2980040",
    "end": "2985720"
  },
  {
    "text": "and in particular we were interested in extending that to event data you know this is the page views and the clicks",
    "start": "2985720",
    "end": "2991240"
  },
  {
    "text": "and The Impressions and that kind of stuff uh which is much higher volume and obviously there's no Upstream",
    "start": "2991240",
    "end": "2997280"
  },
  {
    "text": "log of that to act as a cach for so so that was what we made Kafka for originally it was just used for that",
    "start": "2997280",
    "end": "3002559"
  },
  {
    "text": "it's now kind of expanding out to all the use cases that that were originally uh datab bus the interesting thing that",
    "start": "3002559",
    "end": "3008520"
  },
  {
    "text": "I with with the datab bus paper was the idea that somebody could bootstrap from Ground Zero whole background thing which",
    "start": "3008520",
    "end": "3015799"
  },
  {
    "text": "is something that I guess is not really part of cop cop just keeps it for a week yeah so so um the uh that's a good",
    "start": "3015799",
    "end": "3022839"
  },
  {
    "text": "question okay so this is a Nuance um we had two systems data bus kfka databus was the earlier system one of the",
    "start": "3022839",
    "end": "3029280"
  },
  {
    "text": "features of databus was it would allow you to kind of go back to time zero and",
    "start": "3029280",
    "end": "3034599"
  },
  {
    "text": "it would kind of filter out redundant updates for you um and and uh that was",
    "start": "3034599",
    "end": "3040119"
  },
  {
    "text": "actually very nice you would think well why would you want to do that turns out it's very useful if you have something like a search system where you have a",
    "start": "3040119",
    "end": "3046599"
  },
  {
    "text": "bunch of nodes which are subscribing to some part of the log and indexing it um if you lose one of those nodes and they",
    "start": "3046599",
    "end": "3052400"
  },
  {
    "text": "lose their data the most natural way to restore the data is actually just to say hey that that no is at time zero that's",
    "start": "3052400",
    "end": "3057839"
  },
  {
    "text": "its time and it just kind of like plays forwards and re reexes um the uh and so",
    "start": "3057839",
    "end": "3064040"
  },
  {
    "text": "we actually do have that feature in Kafka to be able to kind of prune obsolete updates in a similar way we",
    "start": "3064040",
    "end": "3069520"
  },
  {
    "text": "call it log compaction um and and it's it's specifically used for that um",
    "start": "3069520",
    "end": "3074680"
  },
  {
    "text": "because kfka also takes rights you can actually use that for all types of interesting journaling of computation",
    "start": "3074680",
    "end": "3080760"
  },
  {
    "text": "use cases we use it uh in the Stream processing system uh to be able to do stateful stream processing like maintain",
    "start": "3080760",
    "end": "3087760"
  },
  {
    "text": "counts and all of those updates are journaled out so that if the stream you know the stream processing with one of those instances fails it can kind of",
    "start": "3087760",
    "end": "3093880"
  },
  {
    "text": "restore itself from that log um so actually it's a very cool feature uh I didn't go into it in detail here just",
    "start": "3093880",
    "end": "3099079"
  },
  {
    "text": "because it's um sort of a a more advanced topic I guess",
    "start": "3099079",
    "end": "3105480"
  },
  {
    "text": "um I'm curious on high availability yeah um achieving 5 9es while",
    "start": "3105640",
    "end": "3114280"
  },
  {
    "text": "simultaneously adding more Hardware rearing just keeping things going",
    "start": "3114280",
    "end": "3119520"
  },
  {
    "text": "without interruption to the stream MH yeah so okay so the question is I think",
    "start": "3119520",
    "end": "3125079"
  },
  {
    "text": "just generally High availability how does it work right um okay so this is a fairly traditional um like Master Slave",
    "start": "3125079",
    "end": "3132839"
  },
  {
    "text": "model so at any given time you know the cluster has a bunch of partitions maybe a thousand partitions that cover all the",
    "start": "3132839",
    "end": "3139200"
  },
  {
    "text": "different topics each of those partitions has a leader and some followers um and the leader accepts all",
    "start": "3139200",
    "end": "3145799"
  },
  {
    "text": "the rights and determines the order the followers apply those rights um in whatever order the leader determines if",
    "start": "3145799",
    "end": "3152280"
  },
  {
    "text": "the leader fails you elect a new follower out of the set of uh followers",
    "start": "3152280",
    "end": "3157520"
  },
  {
    "text": "that are in sync and available for election um so you know the guarantees you get out of that are um you know your",
    "start": "3157520",
    "end": "3166200"
  },
  {
    "text": "your your non-availability window is going to be the time it takes to detect that the leader has failed um and then",
    "start": "3166200",
    "end": "3174680"
  },
  {
    "text": "the time it takes to reelect a new uh during so so whenever you know whenever that failure happens you have a",
    "start": "3174680",
    "end": "3180520"
  },
  {
    "text": "small window of WR unavailability um usually for this kind of system it's okay like the producer",
    "start": "3180520",
    "end": "3186040"
  },
  {
    "text": "can kind of buffer and keep writing as long as it's very quick um where you would run into larger problems is if you",
    "start": "3186040",
    "end": "3192079"
  },
  {
    "text": "had some kind of like persistent Network partition that mostly doesn't happen to us inside of data centers very often it",
    "start": "3192079",
    "end": "3198920"
  },
  {
    "text": "does happen between data centers but we would always run these clusters in a Data Center and kind of replicate",
    "start": "3198920",
    "end": "3204359"
  },
  {
    "text": "asynchronously across and so that that problem is less less of a problem um",
    "start": "3204359",
    "end": "3210200"
  },
  {
    "text": "that is the kind of that you know that's how the fa tolerance Works maybe your question is more like what's important",
    "start": "3210200",
    "end": "3215839"
  },
  {
    "text": "to run it uh and keep it available um yeah an operational side to yeah yeah",
    "start": "3215839",
    "end": "3222160"
  },
  {
    "text": "that's right so Kinesis um has this concept of rearing which kind of exposes",
    "start": "3222160",
    "end": "3229160"
  },
  {
    "text": "their implementation to you mentioned there's some paod in the API I'm just wondering yeah that's right that's right",
    "start": "3229160",
    "end": "3236280"
  },
  {
    "text": "yeah so cka doesn't do rearing you can add partitions right but we don't do any",
    "start": "3236280",
    "end": "3242440"
  },
  {
    "text": "kind of transfer of data if you do so if you have one partition and all your data",
    "start": "3242440",
    "end": "3247720"
  },
  {
    "text": "is in that partition you can add another partition but then you have one partition with a bunch of data in one partition that's empty um presumably",
    "start": "3247720",
    "end": "3255040"
  },
  {
    "text": "your rights will now distribute over those two but we don't we don't reshuffle the data if that makes sense",
    "start": "3255040",
    "end": "3260400"
  },
  {
    "text": "so over time you know this partition will Beed and then yeah I should yeah I should answer that so so our model is",
    "start": "3260400",
    "end": "3267160"
  },
  {
    "text": "basically an overp partitioning model where we say like okay if you think you want to scale eventually to 100 machines you need 100 partitions um now of course",
    "start": "3267160",
    "end": "3275240"
  },
  {
    "text": "some people underestimate what they need and then they do but but when that happens you have to if there's really",
    "start": "3275240",
    "end": "3281359"
  },
  {
    "text": "two cases sometimes the partitioning is used really just for scalability and sometimes it's used uh as a kind of",
    "start": "3281359",
    "end": "3288240"
  },
  {
    "text": "semantic partitioning where you're partitioning by key and the stream processing system that is subscribing is",
    "start": "3288240",
    "end": "3293520"
  },
  {
    "text": "partitioning up its processing along with that in the first case it's easy right now you're just Distributing over",
    "start": "3293520",
    "end": "3298760"
  },
  {
    "text": "more shards in the second case uh it's actually hard and resharding that data is going to depend on the semantics of",
    "start": "3298760",
    "end": "3304400"
  },
  {
    "text": "how you're using it and that's something like you would have to participate in all right any other",
    "start": "3304400",
    "end": "3310319"
  },
  {
    "text": "questions back what are some of the things you see need to be done in C to",
    "start": "3310319",
    "end": "3316440"
  },
  {
    "text": "make it more um widely accepted in",
    "start": "3316440",
    "end": "3321799"
  },
  {
    "text": "the yeah yeah so the question is what um what's needed in kka to make it more widely accepted um couple things like uh",
    "start": "3321799",
    "end": "3329240"
  },
  {
    "text": "security like right now we we don't have any built-in security uh that's a big deal um the maturity of the clients",
    "start": "3329240",
    "end": "3336119"
  },
  {
    "text": "outside of java um there's a long taale of clients and really getting something that's robust in every language is",
    "start": "3336119",
    "end": "3341440"
  },
  {
    "text": "important so that it works with whatever language people are using and I think um just the kind of out of the box",
    "start": "3341440",
    "end": "3346960"
  },
  {
    "text": "experience like we've done this as an open source project so we kind of give you this pretty reliable piece of",
    "start": "3346960",
    "end": "3352280"
  },
  {
    "text": "low-level infrastructure but everything to plug into all the rest of the systems is something kind of do yourself so so",
    "start": "3352280",
    "end": "3358319"
  },
  {
    "text": "it's a lot of work now to uh to actually adopt this in a company and put it to use any any ideas for tooling on C to",
    "start": "3358319",
    "end": "3366559"
  },
  {
    "text": "make things easier I mean there are command tools today probably people at some point want to see a console and",
    "start": "3366559",
    "end": "3373520"
  },
  {
    "text": "interface that can do things is this part of your Charter for the new company or yeah yeah so the question is you know",
    "start": "3373520",
    "end": "3379960"
  },
  {
    "text": "is it company going to do anything to make tooling for cfat easier the answer is yes probably but but I I don't think",
    "start": "3379960",
    "end": "3385160"
  },
  {
    "text": "we know exactly what it this point oh one other question I had was about the example you took of true Visa which",
    "start": "3385160",
    "end": "3391760"
  },
  {
    "text": "is more of a stream processing engine and K is more of you know logging",
    "start": "3391760",
    "end": "3397119"
  },
  {
    "text": "buffering so those are two different that's right Solutions so I guess what you trying to achieve with tro would be",
    "start": "3397119",
    "end": "3403839"
  },
  {
    "text": "very different from what you can achieve with kka so what was the vision around yeah deploying",
    "start": "3403839",
    "end": "3409760"
  },
  {
    "text": "TR yeah uh so I gave this triso example at LinkedIn I was was kind of trying to",
    "start": "3409760",
    "end": "3414839"
  },
  {
    "text": "motivate why um um I I think the point I'm trying to make is I I feel that like step one for us was actually making data",
    "start": "3414839",
    "end": "3421920"
  },
  {
    "text": "available in real time and then once you have that you very much want to process it in real time it's very hard to",
    "start": "3421920",
    "end": "3427400"
  },
  {
    "text": "process data in real time if you don't have anything available in real time that was really the point I was making in this model um there's really two",
    "start": "3427400",
    "end": "3434280"
  },
  {
    "text": "things right there's a kind of real-time stream and then there's like a processing engine which would be the processing point in tro it's obviously",
    "start": "3434280",
    "end": "3441480"
  },
  {
    "text": "uh more combined right um You could argue whether or not this separation of the processing layer and the kind of",
    "start": "3441480",
    "end": "3447599"
  },
  {
    "text": "underlying log is good or bad um but but that is you know how it is um the",
    "start": "3447599",
    "end": "3454200"
  },
  {
    "text": "processing layers people use commonly are like storm uh samama which I talked",
    "start": "3454200",
    "end": "3459760"
  },
  {
    "text": "about and a little bit spark which has some stream processing stuff all of which uh integrate pretty well with",
    "start": "3459760",
    "end": "3467559"
  },
  {
    "text": "kopka cool so it's still building these systems is",
    "start": "3468440",
    "end": "3476880"
  },
  {
    "text": "still sort of at the stage of trying to figure out what all your pieces are and then go then Scurry around in in GitHub",
    "start": "3476880",
    "end": "3483680"
  },
  {
    "text": "and various companies in the valley and pick up tools and make things when is",
    "start": "3483680",
    "end": "3488880"
  },
  {
    "text": "somebody going to figure out system integration is it for large scale systems as a product or as a company M",
    "start": "3488880",
    "end": "3496240"
  },
  {
    "text": "um okay so the question is uh it's very hard to build you know these types of",
    "start": "3496240",
    "end": "3501359"
  },
  {
    "text": "large scale systems I don't know if you mean individual components or you know",
    "start": "3501359",
    "end": "3506480"
  },
  {
    "text": "your other question was more like integration between components I mean to build LinkedIn yeah yeah um so yeah I",
    "start": "3506480",
    "end": "3514359"
  },
  {
    "text": "mean I I think hopefully this helps with some of the data integration problems I mean what we found to be a simplifying",
    "start": "3514359",
    "end": "3519559"
  },
  {
    "text": "abstraction was being able to take data across many different things and make it available in a uniform way right that",
    "start": "3519559",
    "end": "3525920"
  },
  {
    "text": "obviously helps there's other parts to that so like there was a bunch of tools we had specifically around building",
    "start": "3525920",
    "end": "3531680"
  },
  {
    "text": "distributed systems that's kind of of use to people who are building distributed systems but it's you know uh",
    "start": "3531680",
    "end": "3538119"
  },
  {
    "text": "not necessarily as related to the data integration problem um so so yeah I don't know uh I guess I had this",
    "start": "3538119",
    "end": "3543839"
  },
  {
    "text": "discussion with a friend that uh maybe all the hard problems are integration problems because just the nature of",
    "start": "3543839",
    "end": "3549839"
  },
  {
    "text": "software is anything that's um you know you can turn into a reusable abstraction you've done it so once you have all the",
    "start": "3549839",
    "end": "3555960"
  },
  {
    "text": "reusable abstractions all that's left is integration yeah so maybe the nature of",
    "start": "3555960",
    "end": "3561640"
  },
  {
    "text": "it is it's all it's always going to be integration problems it's just that the type of integration problem will change I don't",
    "start": "3561640",
    "end": "3568480"
  },
  {
    "text": "know cool guess Qui question on data retention J going back to kesis is a",
    "start": "3568599",
    "end": "3574839"
  },
  {
    "text": "24hour retention yeah uh you mention time zero with the data pipe",
    "start": "3574839",
    "end": "3582359"
  },
  {
    "text": "um given there's this race to zero and storage drop BLX box these various",
    "start": "3582359",
    "end": "3589799"
  },
  {
    "text": "players do you extrapolate out storage over time do you proceed five or",
    "start": "3589799",
    "end": "3596520"
  },
  {
    "text": "10 years we can infinitely retain logs that open up new machine learning",
    "start": "3596520",
    "end": "3604160"
  },
  {
    "text": "or that kind of Corpus of data yeah so the question is can is it is it is it",
    "start": "3604160",
    "end": "3609520"
  },
  {
    "text": "reasonable to infinitely retain logs um yeah the answer is yeah absolutely um",
    "start": "3609520",
    "end": "3615039"
  },
  {
    "text": "the um there's you know the the retention is configurable um if you",
    "start": "3615039",
    "end": "3621000"
  },
  {
    "text": "configure a it to Infinity then it will change forever um usually people don't",
    "start": "3621000",
    "end": "3626440"
  },
  {
    "text": "actually want to reprocess everything but but it can actually be useful um the",
    "start": "3626440",
    "end": "3633280"
  },
  {
    "text": "model we've taken is you know we we use Hadoop as kind of the archival store um",
    "start": "3633280",
    "end": "3640119"
  },
  {
    "text": "for LinkedIn I think most things just go back two years it doesn't go back to the beginning of the company you could argue",
    "start": "3640119",
    "end": "3645520"
  },
  {
    "text": "whether that's uh good or not um and then we use uh cka really for the stream",
    "start": "3645520",
    "end": "3651440"
  },
  {
    "text": "processor for for kind of reprocessing in these stream processing jobs and so there are some topics that have much",
    "start": "3651440",
    "end": "3657280"
  },
  {
    "text": "longer retention or use that kind of keyed compaction to give you a complete snapshot for the stream processor to be",
    "start": "3657280",
    "end": "3663240"
  },
  {
    "text": "able to restore it state so why why would you want your stream processor to go back in time the answer there is",
    "start": "3663240",
    "end": "3670280"
  },
  {
    "text": "usually like you change the logic in the Stream processing and you want to compute it some different way it has to kind of restart and",
    "start": "3670280",
    "end": "3677359"
  },
  {
    "text": "reprocess forens exotic for example is usually post facto um so oy compliance retention of",
    "start": "3679200",
    "end": "3688680"
  },
  {
    "text": "12 or 13 months of logging into every single system then having to go back in",
    "start": "3688680",
    "end": "3695799"
  },
  {
    "text": "retrospect and analyze the logs and that's huge it problem",
    "start": "3695799",
    "end": "3702000"
  },
  {
    "text": "today distributed systems distributed logs yeah so the question is like would",
    "start": "3702000",
    "end": "3707160"
  },
  {
    "text": "this be useful for an audit of historical legs yeah potentially I I haven't heard of that use case but but",
    "start": "3707160",
    "end": "3713359"
  },
  {
    "text": "absolutely adding to that one so uh size becomes huge is there some kind of compression",
    "start": "3713359",
    "end": "3719359"
  },
  {
    "text": "that yeah so so cka does have internally a kind of uh bat or block compression",
    "start": "3719359",
    "end": "3725039"
  },
  {
    "text": "that compresses together records which is very important especially for these text Heavy records um for getting good",
    "start": "3725039",
    "end": "3730960"
  },
  {
    "text": "compression so going back to the question that was asked earli around integration in large systems right so",
    "start": "3730960",
    "end": "3736960"
  },
  {
    "text": "these corporations which have multitude of systems talking to each other and individual connections typically we'll",
    "start": "3736960",
    "end": "3743760"
  },
  {
    "text": "have some ETL tool in the WEA trying to form fortica something else so how easy",
    "start": "3743760",
    "end": "3749760"
  },
  {
    "text": "would it be for them to replace that plug this in and and you know what kind of support will conflent be able to",
    "start": "3749760",
    "end": "3756400"
  },
  {
    "text": "provide in that regard to take that transformation which comes with its own store as well so that you then data can",
    "start": "3756400",
    "end": "3763760"
  },
  {
    "text": "transform what yeah so I think the question is how how good of a replacement is this stuff for uh you",
    "start": "3763760",
    "end": "3770119"
  },
  {
    "text": "know an ETL uh tool um today I think the answer is it kind of depends",
    "start": "3770119",
    "end": "3776440"
  },
  {
    "text": "um what the ETL tools really do a good job of I would say today is they have a pretty rich goey which allows you to",
    "start": "3776440",
    "end": "3782520"
  },
  {
    "text": "kind of model all the Transformations and then they kind of carry that out in their system um what this does I think a",
    "start": "3782520",
    "end": "3788680"
  },
  {
    "text": "good job of is uh or what we did a good job of at least at Link in what we'd like to make easier for other people to do what some companies have done is",
    "start": "3788680",
    "end": "3795400"
  },
  {
    "text": "actually do a good job of capturing structured data capturing good metadata along with your streams and be able to",
    "start": "3795400",
    "end": "3801039"
  },
  {
    "text": "kind of like directly mirror that in uh something like Hadoop um what we found",
    "start": "3801039",
    "end": "3806200"
  },
  {
    "text": "at LinkedIn was if you do a good job of that you can actually replace a lot of the more mundane data cleanup problems",
    "start": "3806200",
    "end": "3812680"
  },
  {
    "text": "because your data is well structured to begin with um you can get rid of a lot of the manual work in data loads because",
    "start": "3812680",
    "end": "3818200"
  },
  {
    "text": "hoop is actually pretty scalable so you can just have a rule that's like hey everything that shows up we load and we turn into a hive table we use the",
    "start": "3818200",
    "end": "3824160"
  },
  {
    "text": "metadata to create the hive tables um that doesn't get rid of every type of transformation um there there's actually",
    "start": "3824160",
    "end": "3830279"
  },
  {
    "text": "a lot of high value transformation that happens later but it becomes a subset instead of it being the case at every",
    "start": "3830279",
    "end": "3835319"
  },
  {
    "text": "piece of has transformation along with it um I think as if the stream processing layers if these kind of open",
    "start": "3835319",
    "end": "3841000"
  },
  {
    "text": "stream processing layers become more sophisticated I think it'll be U more possible to replace all of it but to a",
    "start": "3841000",
    "end": "3846880"
  },
  {
    "text": "certain extent like um transformation of data is kind of the Mandate of almost",
    "start": "3846880",
    "end": "3852440"
  },
  {
    "text": "every tool in the hiep ecosystem like there's like 47 transformation tools and",
    "start": "3852440",
    "end": "3858000"
  },
  {
    "text": "languages um and so uh one you know critique I have of ETL is like well e is",
    "start": "3858000",
    "end": "3865160"
  },
  {
    "text": "extract and and L is load e and l are pretty mechanical uh T is actually like all of programming and so you have to be",
    "start": "3865160",
    "end": "3871920"
  },
  {
    "text": "specific about what part of T you're actually trying to capture all right cool so I'm happy to take other questions if people have them",
    "start": "3871920",
    "end": "3877440"
  },
  {
    "text": "up here um but but thank you all so much",
    "start": "3877440",
    "end": "3882558"
  },
  {
    "text": "[Applause]",
    "start": "3882940",
    "end": "3886099"
  }
]
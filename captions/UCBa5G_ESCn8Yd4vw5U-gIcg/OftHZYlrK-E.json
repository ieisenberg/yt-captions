[
  {
    "start": "0",
    "end": "138000"
  },
  {
    "text": "Topics for today are first we will- uh, so on- on- on the last class we covered evaluation metrics.",
    "start": "4070",
    "end": "10960"
  },
  {
    "text": "And, uh, kind of like, uh, a- a continuation of that, today we'll talk about some pract- practical tips for, uh,",
    "start": "10960",
    "end": "18210"
  },
  {
    "text": "applying Machine Learning in practice, uh, especially if you want to, uh, you know, um, build a machine learning model focused on a real-world deployment.",
    "start": "18210",
    "end": "26615"
  },
  {
    "text": "And with that, we're gonna, uh, uh, finish up all the topics and we'll spend some time talking,",
    "start": "26615",
    "end": "33835"
  },
  {
    "text": "uh, about the final exam format, what kind of a- a final exam structure you can expect uh,",
    "start": "33835",
    "end": "39000"
  },
  {
    "text": "in the take-home exam. And then we're gonna be- begin our- uh, the full course review, uh,",
    "start": "39000",
    "end": "44745"
  },
  {
    "text": "starting all the way from the beginning, giving you an overview of what we've covered, um, in the course, uh, so far.",
    "start": "44745",
    "end": "50929"
  },
  {
    "text": "We'll be- um, as part of the course review, we'll be emphasizing more on topics that are more relevant for- for the exam.",
    "start": "50930",
    "end": "58625"
  },
  {
    "text": "And we'll go over both the, um, topics that we covered in the lectures and also discussing related homework problems.",
    "start": "58625",
    "end": "66980"
  },
  {
    "text": "So we haven't really had a chance to kind of go over the homework problems, um, in the lecture itself.",
    "start": "66980",
    "end": "72170"
  },
  {
    "text": "So we'll be discussing some of the, uh, homework problems that we've covered and how they kind of, um, match up with what we've seen in",
    "start": "72170",
    "end": "79560"
  },
  {
    "text": "the- in the lectures and how they relate to the lectures and so on. So, uh, machine learning for, uh, production.",
    "start": "79560",
    "end": "86470"
  },
  {
    "text": "So with, uh, the algorithms that we've- so far in the course we've mostly studied algorithms, right?",
    "start": "86470",
    "end": "92020"
  },
  {
    "text": "So we've studied different kinds of algorithms, supervised, unsupervised, reinforcement learning. We've looked at some theory and, uh,",
    "start": "92020",
    "end": "99145"
  },
  {
    "text": "in the last lecture, we also saw some, uh, evaluation metrics. If you are planning to build a machine learning model for some kind of,",
    "start": "99145",
    "end": "108670"
  },
  {
    "text": "uh, uh, say, a real life product that you say you're- you're- you're uh, building a product for let's say in your company,",
    "start": "108670",
    "end": "115870"
  },
  {
    "text": "say you're working for a company or you wanna start a new startup which uses some kind of a machine learning model.",
    "start": "115870",
    "end": "122409"
  },
  {
    "text": "The approach that you, uh, take towards building a real practical model",
    "start": "122410",
    "end": "128795"
  },
  {
    "text": "is somewhat different from the kind of approach you would take for, let's say, uh, building a new algorithm to be published in a research paper, right?",
    "start": "128795",
    "end": "137735"
  },
  {
    "text": "And most of the- uh, probably the biggest difference, uh, between machine learning in- in uh,",
    "start": "137735",
    "end": "144785"
  },
  {
    "start": "138000",
    "end": "220000"
  },
  {
    "text": "practice and machine learning in research, [NOISE] in practice [NOISE] versus research.",
    "start": "144785",
    "end": "155210"
  },
  {
    "text": "[NOISE] The first thing that you would do,",
    "start": "155210",
    "end": "160710"
  },
  {
    "text": "uh, if you were to, uh, deploy, uh, machine learning, um- if you're building a machine learning model for deployment,",
    "start": "160710",
    "end": "166985"
  },
  {
    "text": "is to start collecting a dev set.",
    "start": "166985",
    "end": "176730"
  },
  {
    "text": "Okay? So the first thing you would do before deciding, you know, which model you wanna use,",
    "start": "177470",
    "end": "182890"
  },
  {
    "text": "it may be logistic regression, it may be, you know, a neural network, what- what have you. The first thing you wanna do is start collecting a dev set.",
    "start": "182890",
    "end": "190610"
  },
  {
    "text": "By collecting a dev set, what we mean is start collecting data that your model is gonna encounter when it is deployed in production.",
    "start": "190610",
    "end": "199985"
  },
  {
    "text": "Let's say you're building some kind of- um, for the sake of an example, let's say you're building some kind of a- a- a phone-based",
    "start": "199985",
    "end": "208189"
  },
  {
    "text": "app that recognizes things in- in- in the pictures that you take, right? The first thing you wanna do is start collecting pictures from- you know,",
    "start": "208190",
    "end": "216334"
  },
  {
    "text": "uh, from, uh, uh, mobile phones, right? And the reason you wanna do it is you want to have your dev set distribution",
    "start": "216335",
    "end": "224660"
  },
  {
    "text": "[NOISE]",
    "start": "224660",
    "end": "231480"
  },
  {
    "text": "match the production scenario, right.",
    "start": "231480",
    "end": "241200"
  },
  {
    "text": "And it's important that you start with this step even before you start thinking about what your training data is. You know, first define what your dev set is,",
    "start": "241200",
    "end": "249055"
  },
  {
    "text": "and then work backwards from there, right? And you- you wanna spend as much time as possible on",
    "start": "249055",
    "end": "255385"
  },
  {
    "text": "collecting a dev set that matches the real world distribution as closely as possible. And by matching it as closely as possible,",
    "start": "255385",
    "end": "262345"
  },
  {
    "text": "we mean that, you know, um, if your target set of users are, let's say,",
    "start": "262345",
    "end": "268180"
  },
  {
    "text": "um, those who take pictures on phones as opposed to say tablets. Or even better if you- if you- if you know that your target set of",
    "start": "268180",
    "end": "275320"
  },
  {
    "text": "users initially are gonna be iPhone users versus Android users. Then take pictures from the camera that you're",
    "start": "275320",
    "end": "280900"
  },
  {
    "text": "gonna- your app is gonna be used in, right? And then spend time on labeling it yourself, right?",
    "start": "280900",
    "end": "287645"
  },
  {
    "text": "That gives you a real good feel for how your data actually looks and feels, right? So as part of this, collect data,",
    "start": "287645",
    "end": "295590"
  },
  {
    "text": "preferably from the same devices- collected from the same devices that your model is",
    "start": "296450",
    "end": "301610"
  },
  {
    "text": "gonna get used and label it. Right. Once you do this,",
    "start": "301610",
    "end": "308690"
  },
  {
    "start": "308000",
    "end": "440000"
  },
  {
    "text": "you get your- your uh, validation set or a dev set. The next- the next thing you wanna do is to define an evaluation metric, [NOISE]",
    "start": "308690",
    "end": "328440"
  },
  {
    "text": "right? So these two tasks of collecting a dataset and defining some kind of an evaluation metric should be the first thing you do if you are,",
    "start": "328440",
    "end": "339155"
  },
  {
    "text": "you know, some kind of- uh, if- say you're- you're- you're the leader of an ML group or you're a product manager, um,",
    "start": "339155",
    "end": "345240"
  },
  {
    "text": "the first thing you wanna do is define what your dev set is, which should be a good representation of who",
    "start": "345240",
    "end": "350810"
  },
  {
    "text": "your users are or how your users are gonna use the model. And defining what- uh,",
    "start": "350810",
    "end": "355919"
  },
  {
    "text": "defining metric on this. And this metric will capture what's- what's, um, uh, kind of important for you from this product, right?",
    "start": "355920",
    "end": "362725"
  },
  {
    "text": "And once you define this dataset and evaluation metric, you now effectively kind of, you know,",
    "start": "362725",
    "end": "368285"
  },
  {
    "text": "painted a target for your team to go after, right? These two are- should always be the first thing you define.",
    "start": "368285",
    "end": "374544"
  },
  {
    "text": "And once you're- you've uh, uh, done this, then- then now comes the question of what the training set is, right?",
    "start": "374545",
    "end": "383270"
  },
  {
    "text": "So your training set could- could come from anywhere, right? If collecting data is inexpensive,",
    "start": "383270",
    "end": "389810"
  },
  {
    "text": "then you probably want to collect as much data as you can that mimics the production scenario and make that your training set.",
    "start": "389810",
    "end": "396740"
  },
  {
    "text": "However, that's usually very expensive, right, especially, you know, if you want to label your dataset.",
    "start": "396740",
    "end": "402930"
  },
  {
    "text": "That becomes really expensive because you- you probably wanna use, you know, your own time or you wanna spend money and use,",
    "start": "402930",
    "end": "409960"
  },
  {
    "text": "you know, crowdsourcing to label your data. And generally, labeling data can be very expensive, right?",
    "start": "409960",
    "end": "416845"
  },
  {
    "text": "And- which is why, uh, most of the time, uh, training data usually comes from a distribution that may or may not match your,",
    "start": "416845",
    "end": "424840"
  },
  {
    "text": "um, uh, dev set exactly, right? If you're working with images, let's say you're building an image classifier,",
    "start": "424840",
    "end": "430975"
  },
  {
    "text": "you may wanna use some kind of a pre-trained model or use a- a- very famous dataset called the ImageNet for- for,",
    "start": "430975",
    "end": "438595"
  },
  {
    "text": "you know, creating your training data, right? And that can be very different from the- uh,",
    "start": "438595",
    "end": "443815"
  },
  {
    "start": "440000",
    "end": "853000"
  },
  {
    "text": "from the use case where your model will eventually get used, right? So um, collect- so the next thing you wanna do is now collect",
    "start": "443815",
    "end": "451759"
  },
  {
    "text": "your training data, right?",
    "start": "451760",
    "end": "458175"
  },
  {
    "text": "And while you're collecting your training data, it should be as- as",
    "start": "458175",
    "end": "464010"
  },
  {
    "text": "close as possible [NOISE] to the dev set.",
    "start": "464010",
    "end": "472090"
  },
  {
    "text": "And generally, um, collecting the dev set, uh, you know, as I said, collecting more of the dev set itself,",
    "start": "474740",
    "end": "481319"
  },
  {
    "text": "uh, can be pretty expensive. And here, you- you generally, uh,",
    "start": "481320",
    "end": "486565"
  },
  {
    "text": "end up using some kind of an automated labeling, automated or noisy labeling, right?",
    "start": "486565",
    "end": "499305"
  },
  {
    "text": "And you may be surprised that noisy labeling or automated labeling can sometimes be extremely effective.",
    "start": "499305",
    "end": "507440"
  },
  {
    "text": "And the- the idea there is that you kind of make up by quantity what you lose by quality.",
    "start": "507440",
    "end": "513460"
  },
  {
    "text": "And in fact, we've actually seen, um, uh, you know, some examples of this in the course already. For example, in your homework 1, PS1,",
    "start": "513460",
    "end": "521650"
  },
  {
    "text": "I think it was question 2, you know, we looked at the case where you have some training set,",
    "start": "521650",
    "end": "527440"
  },
  {
    "text": "where the noises are- where the labels are noisy. Where the labels are available,",
    "start": "527440",
    "end": "532980"
  },
  {
    "text": "say, only for positive examples and, um, the- the- uh, unlabeled examples can contain both positive and negative, right?",
    "start": "532980",
    "end": "540410"
  },
  {
    "text": "That's- that's, uh, one- that's one kind of, um, uh, dataset that you may get by automated labeling,",
    "start": "540410",
    "end": "546830"
  },
  {
    "text": "where you label only the points that you are very confident of and leave everything else as, you know, unlabeled, okay?",
    "start": "546830",
    "end": "552650"
  },
  {
    "text": "And with that, you can still build, uh, models in a naive way and then apply some kind of a correction to get,",
    "start": "552650",
    "end": "560345"
  },
  {
    "text": "you know, pretty good or decent models. Yes. Question. [inaudible]",
    "start": "560345",
    "end": "567390"
  },
  {
    "text": "That's a very good question. So- so the question is when we were doing homework, uh, or, you know, uh, covering rest of the material,",
    "start": "567390",
    "end": "572915"
  },
  {
    "text": "we spoke of first starting with some dataset- some given dataset, and split that into a test,",
    "start": "572915",
    "end": "578540"
  },
  {
    "text": "validation and train, right? Why not do the same here as well? The reason why you wanna,",
    "start": "578540",
    "end": "584420"
  },
  {
    "text": "um, uh, think about it, uh, this way is because the approach that we uh,",
    "start": "584420",
    "end": "589760"
  },
  {
    "text": "discussed earlier of starting with some given dataset and splitting it into three was quite common in- in- um,",
    "start": "589760",
    "end": "597495"
  },
  {
    "text": "you know, a few years ago, or a few decades ago when data was really scarce. Right? Now we're kind of, um,",
    "start": "597495",
    "end": "604120"
  },
  {
    "text": "in a situation where it's easy to collect data, it's difficult to label them, but it's, you know, generally,",
    "start": "604120",
    "end": "610484"
  },
  {
    "text": "you know, the availability of data is quite abundant in a lot of use cases. Of course, there are use cases where data availability itself is low, for example,",
    "start": "610484",
    "end": "618110"
  },
  {
    "text": "in- in healthcare when- you know, if you want data about some rare disease, of course, you're not- you're not gonna have a- a lot of examples there.",
    "start": "618110",
    "end": "624035"
  },
  {
    "text": "But for the most part, um, especially if you want to build some kind of, um, uh, commercializable product, you know, um, then it's- it generally tends to be around, you know,",
    "start": "624035",
    "end": "633920"
  },
  {
    "text": "you know, images, text, you know, media, uh, videos, etc., and generally it's- um,",
    "start": "633920",
    "end": "640144"
  },
  {
    "text": "it's quite easy to get lots of- lots of data, uh, but labeling them is still hard, right?",
    "start": "640145",
    "end": "646425"
  },
  {
    "text": "And in these- in these scenarios, um, you probably want to have your model be tested",
    "start": "646425",
    "end": "653480"
  },
  {
    "text": "against the kind of scenarios it's gonna be deployed against. And have your test set performance reflect that reality when- you know,",
    "start": "653480",
    "end": "662840"
  },
  {
    "text": "when- when you actually put it in deployment as opposed to take some dataset that you, uh, you know, obtained from, you know,",
    "start": "662840",
    "end": "669380"
  },
  {
    "text": "somewhere and get a sense of generalization performance to that distribution which could be very different from where your model gets used, right?",
    "start": "669380",
    "end": "678420"
  },
  {
    "text": "So if you want to- if you want to- um, if you're thinking of deploying your model in a real-world use case,",
    "start": "678420",
    "end": "684350"
  },
  {
    "text": "always sta- start from the way it is gonna get deployed and work backwards from there.",
    "start": "684350",
    "end": "689410"
  },
  {
    "text": "[inaudible]",
    "start": "689410",
    "end": "710269"
  },
  {
    "text": "Yeah. So- so- so the question is, uh, you know, what about using- using, uh, you know, scrape the web for images and do some kind of automated,",
    "start": "710270",
    "end": "718345"
  },
  {
    "text": "uh, labeling. Is that even legal? Uh, of course, if you are, you know, if you're scraping copyrighted images, then, you know,",
    "start": "718345",
    "end": "725020"
  },
  {
    "text": "you're actually subject to the terms, you know, that come with the license of that, you know, uh, of whoever owns the,",
    "start": "725020",
    "end": "730420"
  },
  {
    "text": "uh, owns the images. Um, so yes. So, uh, legality is definitely open- open question and you should, you know, answer that.",
    "start": "730420",
    "end": "738280"
  },
  {
    "text": "Um, in this course, we don't provide you legal answers for such questions. Um, but, you know, you absolutely need to, you know, uh,",
    "start": "738280",
    "end": "745180"
  },
  {
    "text": "ask those questions and- and, uh, find out if, you know, the- the method that you're following,",
    "start": "745180",
    "end": "751060"
  },
  {
    "text": "you know, is it legal or not? Absolutely, you should- you should pay attention to that. And, um, in terms of crowdsourcing,",
    "start": "751060",
    "end": "758125"
  },
  {
    "text": "it is strongly recommended that the dev set, the labeling of the dev set be done with as much care as possible,",
    "start": "758125",
    "end": "765835"
  },
  {
    "text": "preferably by you and your team. And you could use crowdsourcing for labeling,",
    "start": "765835",
    "end": "771355"
  },
  {
    "text": "say your training data, but you wanna be as careful as possible for labeling your, uh, dev set, uh, definitely.",
    "start": "771355",
    "end": "778195"
  },
  {
    "text": "Yeah. Yeah. So, um, we saw some of the, uh,",
    "start": "778195",
    "end": "783685"
  },
  {
    "text": "some of the automated, um, what could happen under automated labeling with, uh, uh, in PS1 Q2.",
    "start": "783685",
    "end": "791110"
  },
  {
    "text": "That's the positive only- only, uh, uh, um, scenario. And once you- once you kind of,",
    "start": "791110",
    "end": "798910"
  },
  {
    "text": "um, done your labeling, then you get into the question of,",
    "start": "798910",
    "end": "804279"
  },
  {
    "text": "how do we build- how do we build a model that works well in production, right?",
    "start": "804280",
    "end": "810220"
  },
  {
    "text": "Your- your goal should always be to build a model that works well in production, right?",
    "start": "810220",
    "end": "816714"
  },
  {
    "text": "Which is- which- which might seem closely related to a model that works",
    "start": "816715",
    "end": "821890"
  },
  {
    "text": "well on your test set or model that works well on your dev set but that is still a proxy.",
    "start": "821890",
    "end": "827230"
  },
  {
    "text": "You should always aim for building a model that works well in production, right?",
    "start": "827230",
    "end": "832300"
  },
  {
    "text": "And the way you want to, um, work towards improving your model,",
    "start": "832300",
    "end": "837970"
  },
  {
    "text": "uh, performance on production, is to, uh, let's say you- you, uh,",
    "start": "837970",
    "end": "843505"
  },
  {
    "text": "come up with some kind of, um, let's say you decide to use I don't know,",
    "start": "843505",
    "end": "848715"
  },
  {
    "text": "SVMs or, you know, logistic regression, doesn't matter what it is, right? Anytime you- you, uh,",
    "start": "848715",
    "end": "855540"
  },
  {
    "start": "853000",
    "end": "1573000"
  },
  {
    "text": "fit the model and you want to measure performance, you should always measure this breakdown.",
    "start": "855540",
    "end": "863520"
  },
  {
    "text": "So first you have say, human level performance, [NOISE] right?",
    "start": "872740",
    "end": "887769"
  },
  {
    "text": "And this human level performance, even though it is inaccurate,",
    "start": "887770",
    "end": "892840"
  },
  {
    "text": "it is sometimes okay to think of this as a proxy for irreducible error.",
    "start": "892840",
    "end": "897850"
  },
  {
    "text": "[NOISE]",
    "start": "897850",
    "end": "906730"
  },
  {
    "text": "Of course this is- this is inaccurate, but it serves as a good proxy. We do have models that work better than humans in many examples.",
    "start": "906730",
    "end": "913915"
  },
  {
    "text": "So in those kind of examples, this may not always work, but for the most part, if you're starting about building some kind of a model or some kind",
    "start": "913915",
    "end": "921790"
  },
  {
    "text": "of a- a- a machine-learning model for a, you know, a- a specific product that you're, uh, uh, working on,",
    "start": "921790",
    "end": "929545"
  },
  {
    "text": "then human level performance on the dev set can work as a good proxy for irreducible error.",
    "start": "929545",
    "end": "935605"
  },
  {
    "text": "Again, it's just a proxy. Yes, question. So question about the automated denoising label. So what exactly is meant by that? So you're saying like you get data from an already labeled [inaudible]",
    "start": "935605",
    "end": "961443"
  },
  {
    "text": "Yes. So- so the question is, what- what do we mean by automated labeling? Do we mean by using some, uh, some dataset that's already labeled?",
    "start": "961443",
    "end": "968680"
  },
  {
    "text": "Is that what- so what- what we mean by this is, um, let's say you're- you're trying to, um,",
    "start": "968680",
    "end": "975085"
  },
  {
    "text": "build a classifier for, uh, let's say, you know,",
    "start": "975085",
    "end": "981490"
  },
  {
    "text": "the- the- the prototypi- typical example. Let's say you want to build a- a classifier given an image,",
    "start": "981490",
    "end": "986875"
  },
  {
    "text": "is that a cat in that image, right? And let's say you scrape the web, you know, possibly that's illegal.",
    "start": "986875",
    "end": "992920"
  },
  {
    "text": "Let's- we'll- we'll push that question apart and you- you've collected a big, uh, dataset. And in this dataset,",
    "start": "992920",
    "end": "998635"
  },
  {
    "text": "now we want to label this dataset as those having cats versus no cats, right? And you want to have some kind of an odd- so- so first thing you do",
    "start": "998635",
    "end": "1007785"
  },
  {
    "text": "is collect a dev set that's going to match your deployment scenario, right?",
    "start": "1007785",
    "end": "1012915"
  },
  {
    "text": "If- if your use case for your- for your, say, mobile phone app is through pictures, then take pictures from let's say your phone.",
    "start": "1012915",
    "end": "1020264"
  },
  {
    "text": "Take lots of pictures and manually label those that have cats or not, right? And then comes the problem of collecting training data, right?",
    "start": "1020265",
    "end": "1027480"
  },
  {
    "text": "Your data can be images that you scrape off the web, which may be completely unrelated. It may look kind of different from pictures taken in your, uh, in your phone.",
    "start": "1027480",
    "end": "1035339"
  },
  {
    "text": "And now you wanna do some kind of an automated labeling, right? And what does it mean here? You could perform automated labeling with some simple rules.",
    "start": "1035340",
    "end": "1044055"
  },
  {
    "text": "For example, if the- if the file name of the image has the word cat, then maybe it has a cat so, you know,",
    "start": "1044055",
    "end": "1050835"
  },
  {
    "text": "label it, you know, ha- have some initial noisy labeling where you look at the file name,",
    "start": "1050835",
    "end": "1056505"
  },
  {
    "text": "if ha- if it has the word cat in it, label it as positive. If it does not label, it as negative, that's very noisy.",
    "start": "1056505",
    "end": "1062175"
  },
  {
    "text": "You know, what, you know, it- it probably works okay, uh, in terms of its,",
    "start": "1062175",
    "end": "1067605"
  },
  {
    "text": "um, um, um, uh, degree of noise in it. You probably want to still perform some kind of a spot check to see, you know,",
    "start": "1067605",
    "end": "1073799"
  },
  {
    "text": "collect some random number of images from this label dataset and see what fraction of them were labeled correctly with this automated rule.",
    "start": "1073800",
    "end": "1081285"
  },
  {
    "text": "And maybe refine it a little further till it is, you know, probably, you know, say 90% accurate or 95% accurate.",
    "start": "1081285",
    "end": "1087780"
  },
  {
    "text": "[OVERLAPPING] [inaudible] Yeah. You could use a simple model to do this automated labeling but generally,",
    "start": "1087780",
    "end": "1095895"
  },
  {
    "text": "this- this automated labeling will use some kind of prior knowledge or domain knowledge to construct a rule-based,",
    "start": "1095895",
    "end": "1101580"
  },
  {
    "text": "you know, it's- it's generally a rule based, uh, uh, labeling at the automated labeling stage. [NOISE] So, um, you wanna break down the,",
    "start": "1101580",
    "end": "1110205"
  },
  {
    "text": "uh, performance into the following, uh, following parts and then you have training performance.",
    "start": "1110205",
    "end": "1119490"
  },
  {
    "text": "[NOISE]",
    "start": "1119490",
    "end": "1130290"
  },
  {
    "text": "And when you're training, once you obtain this training data, you probably want to split it into,",
    "start": "1130290",
    "end": "1138690"
  },
  {
    "text": "uh, an actual train set. And what you might call as a train dev set,",
    "start": "1138690",
    "end": "1144045"
  },
  {
    "text": "which is a fraction of your training set, which is distinct from the dev set that you're- and-",
    "start": "1144045",
    "end": "1149970"
  },
  {
    "text": "and- the goal of the dev set is to mimic the deployment scenario as well as possible.",
    "start": "1149970",
    "end": "1155220"
  },
  {
    "text": "But your training data, you probably don't wanna, uh, overfit or use all your,",
    "start": "1155220",
    "end": "1161115"
  },
  {
    "text": "uh, training data for fitting the model as well. So within the training data that you've- that you've labeled, possibly with, uh,",
    "start": "1161115",
    "end": "1167130"
  },
  {
    "text": "automated labeling, you still wanna hold out a fraction of this and let's call it the train dev set, right?",
    "start": "1167130",
    "end": "1173054"
  },
  {
    "text": "So train-dev performance.",
    "start": "1173055",
    "end": "1179290"
  },
  {
    "text": "It is sometimes common to take a fraction of your dev set and include",
    "start": "1181310",
    "end": "1187140"
  },
  {
    "text": "it in the train dev set and yeah,",
    "start": "1187140",
    "end": "1192165"
  },
  {
    "text": "measure the train dev performance, and then measure the dev set performance.",
    "start": "1192165",
    "end": "1197680"
  },
  {
    "text": "And this is the part that you manually labeled and manually collected.",
    "start": "1203630",
    "end": "1210850"
  },
  {
    "text": "Okay. And finally, we can talk about the deployment performance.",
    "start": "1213590",
    "end": "1221080"
  },
  {
    "text": "By deployment performance, what- what I mean is, when you actually deploy the model into production and real users start using your model,",
    "start": "1227390",
    "end": "1237480"
  },
  {
    "text": "you know, what's the accuracy? What's the level of performance, um, on- on- on the, uh, real world, right?",
    "start": "1237480",
    "end": "1243255"
  },
  {
    "text": "And previously, we were generally talking about,",
    "start": "1243255",
    "end": "1248715"
  },
  {
    "text": "you know, train error and test error or maybe train error, dev error and test error.",
    "start": "1248715",
    "end": "1254174"
  },
  {
    "text": "But here, when you- when you actually put things in- in, uh, or when you're working towards an actual deployment,",
    "start": "1254175",
    "end": "1261380"
  },
  {
    "text": "you actually want to measure all five, you know, all, you know, there- there are these five different measurements that you're, uh, measuring.",
    "start": "1261380",
    "end": "1268284"
  },
  {
    "text": "And the way you want to think of each of these different performance is the human level performance,",
    "start": "1268285",
    "end": "1273645"
  },
  {
    "text": "as I said, you can think of it as a proxy for irreducible error. Once you- once your model starts working really,",
    "start": "1273645",
    "end": "1280350"
  },
  {
    "text": "really well, it might start performing better than humans. But, you know, we'll- we'll, we'll ignore those, uh, cases for now.",
    "start": "1280350",
    "end": "1286965"
  },
  {
    "text": "And the gap between training performance and human level performance,",
    "start": "1286965",
    "end": "1292320"
  },
  {
    "text": "the gap between these two, you wanna think of this gap as",
    "start": "1292320",
    "end": "1297915"
  },
  {
    "text": "a proxy to the bias in the model, right?",
    "start": "1297915",
    "end": "1306285"
  },
  {
    "text": "The gap between training performance and human level performance, right? And similarly, the gap between the train dev performance and the training performance,",
    "start": "1306285",
    "end": "1315224"
  },
  {
    "text": "you wanna think of that as the variance in the model. [NOISE] Right?",
    "start": "1315224",
    "end": "1329929"
  },
  {
    "text": "[NOISE] And now, similarly, the gap between the train dev performance and the dev set performance, this gap,",
    "start": "1329930",
    "end": "1338505"
  },
  {
    "text": "you can think of it as the error due to distribution mismatch- distribution mismatch",
    "start": "1338505",
    "end": "1348804"
  },
  {
    "text": "between dev and train.",
    "start": "1348804",
    "end": "1355620"
  },
  {
    "text": "And this distribution mismatch is, is because the training set that you obtained was generally",
    "start": "1357550",
    "end": "1366110"
  },
  {
    "text": "obtained from a different process rather than starting with-rather than the,",
    "start": "1366110",
    "end": "1372170"
  },
  {
    "text": "the process you use to mimic the test set because this is too expensive, right?",
    "start": "1372170",
    "end": "1377240"
  },
  {
    "text": "And this is generally, you know, uh, therefore, you can think of this as, like,",
    "start": "1377240",
    "end": "1383015"
  },
  {
    "text": "you know, due to cost of collecting. Yes, question?",
    "start": "1383015",
    "end": "1392465"
  },
  {
    "text": "What is train dev? So the train dev is a fraction of the training data that you obtain,",
    "start": "1392465",
    "end": "1397565"
  },
  {
    "text": "that you hold out as, as, you know, a train dev set. Why do we call it dev?",
    "start": "1397565",
    "end": "1403085"
  },
  {
    "text": "Because we're calling this dev so we just call it train dev because it was- it just a fraction of the training data that you have,",
    "start": "1403085",
    "end": "1409640"
  },
  {
    "text": "which is distinct from the dev set which you manually collected and labeled. So what type of train dev is going to be used with somewhat like the validation set?",
    "start": "1409640",
    "end": "1419720"
  },
  {
    "text": "So the purpose of the train dev set is to kind of, uh, use it as a way to check if your model is overfitting or not.",
    "start": "1419720",
    "end": "1426635"
  },
  {
    "text": "And the, and the dev set is used to check if the- um, if the model is going to work well in the deployment scenario or not",
    "start": "1426635",
    "end": "1436250"
  },
  {
    "text": "because the training data that you obtained was distinct or different from the, um, from the, from the, uh, uh,",
    "start": "1436250",
    "end": "1443240"
  },
  {
    "text": "potential deployment scenario, okay? And finally, the gap between these- between",
    "start": "1443240",
    "end": "1453409"
  },
  {
    "text": "the dev set performance and the deployment performance is generally due to overfitting on the dev set.",
    "start": "1453410",
    "end": "1460220"
  },
  {
    "text": "[NOISE] How can we",
    "start": "1460220",
    "end": "1469730"
  },
  {
    "text": "overfit on the dev set even though we are not training on it? We can overfit on the debit side because we go through the cycle of refining our model and",
    "start": "1469730",
    "end": "1477020"
  },
  {
    "text": "tuning our model to work better and better on the dev set to reduce this gap. And in a way, indirectly,",
    "start": "1477020",
    "end": "1483980"
  },
  {
    "text": "due to our hyperparameters, we will inevitably end up overfitting on the dev set, right?",
    "start": "1483980",
    "end": "1490460"
  },
  {
    "text": "And once you overfit on the dev set, then your, your actual deployment performance can be pretty, pretty bad, right?",
    "start": "1490460",
    "end": "1498725"
  },
  {
    "text": "And to kind of summarize, our goal is to build models that work well in deployment.",
    "start": "1498725",
    "end": "1506330"
  },
  {
    "text": "And this is our eventual target. We should never lose track of the eventual target which is deployment performance.",
    "start": "1506330",
    "end": "1511985"
  },
  {
    "text": "And all these other different ar- uh, um, measurements that you perform are a way so that",
    "start": "1511985",
    "end": "1518660"
  },
  {
    "text": "you can perform diagnosis to improve the deployment performance, right? These, these performance by themselves are not of direct interest, right?",
    "start": "1518660",
    "end": "1528005"
  },
  {
    "text": "You want to use these to diagnose where the error- where the error is coming from and go after and fix that error so that eventually,",
    "start": "1528005",
    "end": "1536029"
  },
  {
    "text": "we can do well on, on, uh, deployment performance. And the dev set, as you can see,",
    "start": "1536030",
    "end": "1541895"
  },
  {
    "text": "um, can be subject to overfitting, especially if you evaluate your model performance on the dev set multiple times,",
    "start": "1541895",
    "end": "1549350"
  },
  {
    "text": "you're going to reach a state where you've kind of overfit on it. In which case, you might want to go back and recollect a new dataset because you,",
    "start": "1549350",
    "end": "1558455"
  },
  {
    "text": "you overfit on, on the, on the old one, right? And that's, that's pretty common too where you, you,",
    "start": "1558455",
    "end": "1563495"
  },
  {
    "text": "you recreate a new dev set, uh, because you, uh, overfit on the current one, okay?",
    "start": "1563495",
    "end": "1569009"
  },
  {
    "text": "And now- [NOISE] right?",
    "start": "1570340",
    "end": "1576919"
  },
  {
    "start": "1573000",
    "end": "1993000"
  },
  {
    "text": "So given these, let's, let's, uh, let's kind of go through some simple exercise to see",
    "start": "1576920",
    "end": "1583700"
  },
  {
    "text": "what steps we can take to mitigate each of these, okay? Let's say you measure the human level performance and it's pretty low.",
    "start": "1583700",
    "end": "1593120"
  },
  {
    "text": "What do we do? Well, if the human level performance is pretty low,",
    "start": "1593120",
    "end": "1603155"
  },
  {
    "text": "like you- we have not even started- [inaudible] So there's no model in question here.",
    "start": "1603155",
    "end": "1609170"
  },
  {
    "text": "You've collected a da- uh, you know, a dataset and then you ask a human to, to, uh, uh, measure the humans performance against, um,",
    "start": "1609170",
    "end": "1616880"
  },
  {
    "text": "um, on that task and that is pretty low. The accuracy is low?",
    "start": "1616880",
    "end": "1621980"
  },
  {
    "text": "Yeah. You, you know, whatever metric that you come up with, accuracy or precision or recall. Get better humans. Get better humans. [LAUGHTER]",
    "start": "1621980",
    "end": "1630610"
  },
  {
    "text": "[inaudible] Exactly. So, you know, you, you- if, if the human level performance is pretty low, then maybe go after a different problem, right?",
    "start": "1630610",
    "end": "1636740"
  },
  {
    "text": "[LAUGHTER] So [LAUGHTER] um, because, um, it's, you know, especially if you want to run some kind of diagnostics and,",
    "start": "1636740",
    "end": "1644195"
  },
  {
    "text": "and, you know, um, categorize your errors, if a human level performance is pretty low on a task,",
    "start": "1644195",
    "end": "1650825"
  },
  {
    "text": "then you know, you can think of it as a problem where the irreducible error itself is very high. So it- it's kind of a bleak scenario,",
    "start": "1650825",
    "end": "1657530"
  },
  {
    "text": "it kind of represents- it says that the problem is really, really hard, right? Now, what if, you know,",
    "start": "1657530",
    "end": "1664460"
  },
  {
    "text": "the human level performance is pretty good, it's, it's, it's, you know, um,",
    "start": "1664460",
    "end": "1669485"
  },
  {
    "text": "within an acceptable range but your training performance is low, your training error is high, right?",
    "start": "1669485",
    "end": "1676580"
  },
  {
    "text": "But you know, uh, when, when, when, when you ask the human to perform the labeling or human to do the prediction, it was pretty good.",
    "start": "1676580",
    "end": "1682295"
  },
  {
    "text": "You know, what does this represent? It represents, you know, your model probably has high bias, right?",
    "start": "1682295",
    "end": "1688190"
  },
  {
    "text": "And what do we do to address high bias? Increase flexibility. Increase? Increase flexibility of the model, right?",
    "start": "1688190",
    "end": "1696200"
  },
  {
    "text": "So, um, so steps to kind of overcome this, right?",
    "start": "1696200",
    "end": "1704669"
  },
  {
    "text": "Increase flexibility of the model. And how do we increase the flexibility of the model?",
    "start": "1706030",
    "end": "1712190"
  },
  {
    "text": "Add more nonlinearities. Add features. Reduce regularization.",
    "start": "1712190",
    "end": "1718940"
  },
  {
    "text": "Add feature and somebody said, um, add more nonlinearities. So, uh, let's call it add features of,",
    "start": "1718940",
    "end": "1724909"
  },
  {
    "text": "say, add more depth if you're adding a neural network. Add depth, right?",
    "start": "1724910",
    "end": "1732140"
  },
  {
    "text": "And I think someone said reduce regularization. [NOISE] Right?",
    "start": "1732140",
    "end": "1743150"
  },
  {
    "text": "[NOISE] And let's say, if you're, if you're, uh, um, using some kind of a kernel method, use more complex kernels, right?",
    "start": "1743150",
    "end": "1754895"
  },
  {
    "text": "So these are, these are, these are like, uh, standard, standard, uh, approaches for fighting bias.",
    "start": "1754895",
    "end": "1761315"
  },
  {
    "text": "If your model has high bias, then these steps will help you fight, um, uh, uh, bias.",
    "start": "1761315",
    "end": "1767015"
  },
  {
    "text": "And if you remember, uh, bias is due to, uh, the inability for the model to represent like the true function or the,",
    "start": "1767015",
    "end": "1776240"
  },
  {
    "text": "or the best possible, uh, function. The best possible function or the best possible model will give you,",
    "start": "1776240",
    "end": "1782420"
  },
  {
    "text": "you know, the irreducible error, that's the best possible we can do, and the inability of our hypothesis class to represent the,",
    "start": "1782420",
    "end": "1791195"
  },
  {
    "text": "uh, best possible model is called bias. And anything you can do to increase our model class,",
    "start": "1791195",
    "end": "1798020"
  },
  {
    "text": "to make it an even bigger class will help fight bias. Okay? So all these things, you know,",
    "start": "1798020",
    "end": "1804395"
  },
  {
    "text": "adding more features, adding more depth, adding more width in your neural networks, uh,",
    "start": "1804395",
    "end": "1809840"
  },
  {
    "text": "reducing regularization because regularization pushes your model towards, uh, towards zero, uh,",
    "start": "1809840",
    "end": "1815240"
  },
  {
    "text": "you know, more complex kernels. All these are different ways in which we can, we can, uh, fight bias.",
    "start": "1815240",
    "end": "1821375"
  },
  {
    "text": "Now, what if the gap",
    "start": "1821375",
    "end": "1826820"
  },
  {
    "text": "between the training performance and the training out performances is more? What can we do there? [NOISE] Okay?",
    "start": "1826820",
    "end": "1836420"
  },
  {
    "text": "So what can we do here? [inaudible] Everything opposite. So yeah,",
    "start": "1836420",
    "end": "1842195"
  },
  {
    "text": "so look for smaller models, [NOISE] right?",
    "start": "1842195",
    "end": "1849235"
  },
  {
    "text": "And fewer features.",
    "start": "1849235",
    "end": "1852110"
  },
  {
    "text": "Your features increase regularization. [NOISE] Okay?",
    "start": "1856000",
    "end": "1866434"
  },
  {
    "text": "Increase regularization. You know, less complex kernels, [NOISE] and finally,",
    "start": "1866435",
    "end": "1876880"
  },
  {
    "text": "there is one- you know, most of these are like the inverse of, inverse of the other, however, there is one thing that is distinct which is collect more data.",
    "start": "1876880",
    "end": "1884590"
  },
  {
    "text": "[NOISE]",
    "start": "1884590",
    "end": "1895919"
  },
  {
    "text": "Okay? Does getting more data help fight bias? Can it?",
    "start": "1895920",
    "end": "1903520"
  },
  {
    "text": "Some say yes, some say no. So generally you don't think of getting more data as- as for- for fighting bias.",
    "start": "1905720",
    "end": "1911640"
  },
  {
    "text": "If your problem is that your training performance is much,",
    "start": "1911640",
    "end": "1917219"
  },
  {
    "text": "much worse compared to human level performance, which means that the-the model that you have cannot even fit the training data that you have.",
    "start": "1917219",
    "end": "1924870"
  },
  {
    "text": "Right? Which means the- the- the- the problem is that the model class that you have is too inflexible.",
    "start": "1924870",
    "end": "1931125"
  },
  {
    "text": "Okay? Getting more training data will not necessarily help your model fit that superset better than the subset that you had initially, right?",
    "start": "1931125",
    "end": "1940290"
  },
  {
    "text": "So if your training error is low, you kind of think of it as a proxy for bias,",
    "start": "1940290",
    "end": "1945929"
  },
  {
    "text": "and the thing you wanna do is not necessarily go and collect more data, but start increasing the capacity of your model, make it more flexible.",
    "start": "1945930",
    "end": "1954220"
  },
  {
    "text": "However, if the gap between the Train-Dev error and the training performance is large,",
    "start": "1954830",
    "end": "1961304"
  },
  {
    "text": "it means your model is doing really well in just fitting the training- training data, right?",
    "start": "1961305",
    "end": "1967385"
  },
  {
    "text": "But it's not able to generalize well, which means you want to probably make your- make it harder for the model",
    "start": "1967385",
    "end": "1973549"
  },
  {
    "text": "just- to just fit the training data so just collect more data, right? And with the hope that it generalizes better, right?",
    "start": "1973550",
    "end": "1982570"
  },
  {
    "text": "And what do we do if there's a gap between train-dev and dev set?",
    "start": "1982570",
    "end": "1989080"
  },
  {
    "text": "Change the- change the rules for labeling.",
    "start": "1990470",
    "end": "1996940"
  },
  {
    "start": "1993000",
    "end": "2433000"
  },
  {
    "text": "Right? So if the- if the gap between the Train-Dev and Dev Set is- is high,",
    "start": "1998210",
    "end": "2004985"
  },
  {
    "text": "then it's an indication that there's a distribution mismatch between the dev set and a training set.",
    "start": "2004985",
    "end": "2010475"
  },
  {
    "text": "And when there's uh, a- a- a gap between the- the um, uh, when there is uh,",
    "start": "2010475",
    "end": "2016490"
  },
  {
    "text": "a- a- a- a distribution mismatch between the- the dev set and the train set, then obviously, the- the thing that you want to do",
    "start": "2016490",
    "end": "2023270"
  },
  {
    "text": "is minimize that difference in distributions, right? One way to do it is to make the dev set closer",
    "start": "2023270",
    "end": "2029390"
  },
  {
    "text": "to the training set which would not be ideal, which would be kind of, you know,",
    "start": "2029390",
    "end": "2034684"
  },
  {
    "text": "um- um, yeah, it would be kind of, uh, stupid in a way. But instead what you wanna do is make your train",
    "start": "2034685",
    "end": "2040850"
  },
  {
    "text": "dev set be closer to your dev set, right? And that you can do in- in,",
    "start": "2040850",
    "end": "2047285"
  },
  {
    "text": "there are many ways to go about doing that. For example, you may want to, you know, spend some more money and- and, you know,",
    "start": "2047285",
    "end": "2053899"
  },
  {
    "text": "collect more real data, realistic data, label them and include them in your train dev and training uh, set.",
    "start": "2053900",
    "end": "2059994"
  },
  {
    "text": "You could do that. Um, you could also, you know, do something more clever, for example,",
    "start": "2059995",
    "end": "2065200"
  },
  {
    "text": "in your training set, maybe there is a subset of your training set that's somewhat close to your dev set, maybe up-weight those examples.",
    "start": "2065200",
    "end": "2072165"
  },
  {
    "text": "Okay? You could also um, um, you could also maybe, uh,",
    "start": "2072165",
    "end": "2077300"
  },
  {
    "text": "think of some kind of, you know, data transformations on your Training Set. For example, if your Dev Set is mostly images that are black and white,",
    "start": "2077300",
    "end": "2085520"
  },
  {
    "text": "but your training set has a lot of color images. You know, maybe run some filters and make them look to,",
    "start": "2085520",
    "end": "2090560"
  },
  {
    "text": "you know, closer to your dev set in some way. The- the- the- you, this is- this- for this,",
    "start": "2090560",
    "end": "2095945"
  },
  {
    "text": "you need to use your creativity and somehow reduce the- the distance between your training distribution or",
    "start": "2095945",
    "end": "2102740"
  },
  {
    "text": "the train dev distribution and the dev set distribution, and you want to reduce it by making this closer to the dev set,",
    "start": "2102740",
    "end": "2108260"
  },
  {
    "text": "not the other way. Yes, question. [inaudible]",
    "start": "2108260",
    "end": "2121250"
  },
  {
    "text": "Also just to clarify what I meant was making this closer to your training set by-by what I meant was,",
    "start": "2121250",
    "end": "2127535"
  },
  {
    "text": "replace some of these examples by examples from your Training Set. You- you could potentially change this to make this closer to your training set, right?",
    "start": "2127535",
    "end": "2136039"
  },
  {
    "text": "But that would be kind of against the point.",
    "start": "2136040",
    "end": "2139230"
  },
  {
    "text": "The dev set is what you get actually from the situation. Yeah, that was my point. So you- you want to keep",
    "start": "2141580",
    "end": "2147349"
  },
  {
    "text": "your dev set as it is and not change it to. But- but you would want to incorporate",
    "start": "2147350",
    "end": "2153305"
  },
  {
    "text": "examples like as you observe them in the dev set from the training set like let's say you're- like the model",
    "start": "2153305",
    "end": "2159829"
  },
  {
    "text": "you're giving is to represent places or something like that but you realize that since your training data was collected in a very noisy way,",
    "start": "2159830",
    "end": "2168890"
  },
  {
    "text": "maybe it has a lot of images of",
    "start": "2168890",
    "end": "2178220"
  },
  {
    "text": "vehicles or something, so you might want to actually go and like manually include more things that are similar to your dev set, right? Yes, that was my point. Yes. Okay. Yeah. That was not stupid.",
    "start": "2178220",
    "end": "2184600"
  },
  {
    "text": "That's not stupid, yeah. Okay. And what if the gap between the dev set and the deployment performance is poor?",
    "start": "2184600",
    "end": "2192190"
  },
  {
    "text": "Let's say you- you- you, you know, you, uh, taken your dev set in- in, um,",
    "start": "2192190",
    "end": "2197589"
  },
  {
    "text": "as- as kind of uh, a pure way as possible. You've sampled it randomly from the actual deployment scenario,",
    "start": "2197590",
    "end": "2204759"
  },
  {
    "text": "you've labeled it and you- you fit your model and it's working well on your dev set, but it's not working well in real performance- in real life,",
    "start": "2204760",
    "end": "2212210"
  },
  {
    "text": "right? What do we do then? [inaudible]",
    "start": "2212210",
    "end": "2221210"
  },
  {
    "text": "Yeah, exactly. So it's probably time to refresh your dev set, right? It's- it's- it's a good indication that you've likely overfit on your dev set",
    "start": "2221210",
    "end": "2228680"
  },
  {
    "text": "by going through this cycle over and over again as- as- uh, as we mentioned in one of the earlier lectures,",
    "start": "2228680",
    "end": "2234484"
  },
  {
    "text": "the more number of times you measure the performance of your model against a dev set and tweak the model to improve the performance.",
    "start": "2234485",
    "end": "2241595"
  },
  {
    "text": "Think of that as your dataset getting rotted, right? It probably means your dev set has rotted quite a bit.",
    "start": "2241595",
    "end": "2247805"
  },
  {
    "text": "And it's time to collect a new Dev Set and- and- and- and start all over again, okay?",
    "start": "2247805",
    "end": "2253775"
  },
  {
    "text": "And these two that we saw were some of the things that we saw earlier in the bias-variance lecture, right?",
    "start": "2253775",
    "end": "2263630"
  },
  {
    "text": "In order to improve your model performance, there are a set of actions that you can take and",
    "start": "2263630",
    "end": "2271385"
  },
  {
    "text": "that set of actions contain contradictory actions, right? So some of the action is to add more features,",
    "start": "2271385",
    "end": "2279935"
  },
  {
    "text": "whereas another action is to reduce features, right? These are all actions to improve your overall model performance.",
    "start": "2279935",
    "end": "2287765"
  },
  {
    "text": "But in order to decide which specific action you want to take at the- at this moment,",
    "start": "2287765",
    "end": "2293660"
  },
  {
    "text": "it is very critical that you look at both the training set error and your dev set error",
    "start": "2293660",
    "end": "2300335"
  },
  {
    "text": "in order to characterize whether the current problem that you have is a high bias problem or a high variance problem, right?",
    "start": "2300335",
    "end": "2307685"
  },
  {
    "text": "And only then, one- only after you've characterized whether the,",
    "start": "2307685",
    "end": "2313010"
  },
  {
    "text": "uh, immediate problem is a high bias problem or a high variance problem. Only then do you- do you choose on the subset",
    "start": "2313010",
    "end": "2321140"
  },
  {
    "text": "of actions that are meaningful and take that action? Yes, question. So you know when to stop when both the in facts like",
    "start": "2321140",
    "end": "2328700"
  },
  {
    "text": "human-level performance [inaudible] performance [NOISE]and training performance and training performance when those both are equal that's when you- like the",
    "start": "2328700",
    "end": "2336350"
  },
  {
    "text": "best you can do is make bo- make both bias and variance equal. Yeah, so, so the question is,",
    "start": "2336350",
    "end": "2342560"
  },
  {
    "text": "do we stop when, you know, this error vanishes and this error vanishes? What is, is equal?",
    "start": "2342560",
    "end": "2348305"
  },
  {
    "text": "Or, or, you- or the gap between them vanishes and the gap between them vanishes, which means that all three are equal, right?",
    "start": "2348305",
    "end": "2354635"
  },
  {
    "text": "So the question is, do we stop them? The answer is, no. Your goal should always be deployment performance, right?",
    "start": "2354635",
    "end": "2360515"
  },
  {
    "text": "And all these are components that you can tackle with different action sets to help reduce.",
    "start": "2360515",
    "end": "2366890"
  },
  {
    "text": "Since the- since the- [NOISE] since the risk can replicate, both, both problems are contradictory, [NOISE] you can only do one of them.",
    "start": "2366890",
    "end": "2373145"
  },
  {
    "text": "Yeah. So I'm saying, if you want to know whether you, like, you want to tackle bias or variance in your model.",
    "start": "2373145",
    "end": "2379945"
  },
  {
    "text": "You have- like, the best you can hope to do is reduce both of those, uh, difference in performances to equal,",
    "start": "2379945",
    "end": "2386905"
  },
  {
    "text": "that's the best you can do. Yeah. So there is- there is some amount of, um, so, uh, let, let,",
    "start": "2386905",
    "end": "2393665"
  },
  {
    "text": "let me get to that in, in, uh, you know, um, uh, in a few minutes, um, of, of, uh, what, what,",
    "start": "2393665",
    "end": "2399484"
  },
  {
    "text": "what you, um, what you wanna do. The- the short answer is yes, you know, you can, you can, um,",
    "start": "2399485",
    "end": "2405950"
  },
  {
    "text": "you can always collect more data and drive your variance towards 0,",
    "start": "2405950",
    "end": "2411335"
  },
  {
    "text": "and you can always col- increase a bigger, you know, make a- use a bigger model, and drive your bias towards 0.",
    "start": "2411335",
    "end": "2417170"
  },
  {
    "text": "So theoretically, if you have enough compute and enough data, you can drive both bias and variance to 0, right?",
    "start": "2417170",
    "end": "2424340"
  },
  {
    "text": "That's one way to think of it. Uh, yes, question? What- what do we do when the training error is large but dev at the dev error is short?",
    "start": "2424340",
    "end": "2431700"
  },
  {
    "text": "So what do we do when training error is large, but dev- the train dev or a dev error is small?",
    "start": "2432460",
    "end": "2440464"
  },
  {
    "start": "2433000",
    "end": "2753000"
  },
  {
    "text": "Do you mean this gap is large and this gap is small, or the training error's absolute value is large but",
    "start": "2440465",
    "end": "2447350"
  },
  {
    "text": "the train dev or the dev error's absolute value is better? Yeah, like, uh, we have high bias but [inaudible]",
    "start": "2447350",
    "end": "2457130"
  },
  {
    "text": "So, so again, to just understand your question better, do you mean that the gap between train and train dev is small,",
    "start": "2457130",
    "end": "2465665"
  },
  {
    "text": "or the train dev itself is less than the training error? Whi- which of the two scenarios are you talking about?",
    "start": "2465665",
    "end": "2473600"
  },
  {
    "text": "So are you talking about the scenario [NOISE] where the training performance has, let's say, 80% accuracy and the train dev is 79% accurate,",
    "start": "2473600",
    "end": "2484100"
  },
  {
    "text": "which means the gap is small, or are you talking about the case where the train dev is 85% accuracy,",
    "start": "2484100",
    "end": "2489290"
  },
  {
    "text": "[NOISE] which means, you know, the, the performance is better than that? Which of these two are you talking about?",
    "start": "2489290",
    "end": "2494585"
  },
  {
    "text": "The latter one. The latter one, 85%. So this generally means, uh, that if- if the- if the, uh, training, uh,",
    "start": "2494585",
    "end": "2501910"
  },
  {
    "text": "dev performance is higher than the training, uh, performance, this generally means that there is still some kind of,",
    "start": "2501910",
    "end": "2508210"
  },
  {
    "text": "um, um, that there's, um, uh, still some kind of, um, um, um,",
    "start": "2508210",
    "end": "2515690"
  },
  {
    "text": "distributional mismatch in the sense that maybe there is- your train devs set is not, uh, uh,",
    "start": "2515690",
    "end": "2523520"
  },
  {
    "text": "perfectly randomly sampled from the- from the dev set, maybe there is some bias in the way your- you've,",
    "start": "2523520",
    "end": "2528980"
  },
  {
    "text": "uh, sampled the, uh, uh, train dev set, and it could be that the,",
    "start": "2528980",
    "end": "2534215"
  },
  {
    "text": "the fraction that got left out in the training set for harder examples but, you know, this biased subset are easier examples, it's something like that.",
    "start": "2534215",
    "end": "2542030"
  },
  {
    "text": "Generally, you don't expect this to happen. [NOISE]",
    "start": "2542030",
    "end": "2547190"
  },
  {
    "text": "So if that happens, do we train them [inaudible] So if this happens, it probably means you wanna reshuffle your- your train dev,",
    "start": "2547190",
    "end": "2554420"
  },
  {
    "text": "uh, uh, um, you know, merge them and resplit them again. Uh, usually, that's, that's, uh, one way to go about it,",
    "start": "2554420",
    "end": "2561680"
  },
  {
    "text": "because you should not expect- uh, there's no reasonable, um, um, reason for",
    "start": "2561680",
    "end": "2567770"
  },
  {
    "text": "your train dev performance to be better than the training performance, right? I- it means you're likely doing a bad job at,",
    "start": "2567770",
    "end": "2574430"
  },
  {
    "text": "you know, in just fitting your, uh, fitting your training data or, you know, there is some kind of a bias in the way you've split your train and dev set.",
    "start": "2574430",
    "end": "2582875"
  },
  {
    "text": "Good question. Right? [NOISE] So now, you know,",
    "start": "2582875",
    "end": "2590210"
  },
  {
    "text": "there are, there are, um, there are- wha- what we've seen is, you know, there is some action space and- yes, question?",
    "start": "2590210",
    "end": "2597500"
  },
  {
    "text": "My question is, how do you measure deployment performance? Because for everything else, you have a, you know, a set data that you've kind of measured against.",
    "start": "2597500",
    "end": "2604595"
  },
  {
    "text": "But for deployment performance, you kind of put it up into deployment already? That's a very good question. So how do we measure deployment performance?",
    "start": "2604595",
    "end": "2611645"
  },
  {
    "text": "And usually, the way you measure deployment performance is to, you know, generally,",
    "start": "2611645",
    "end": "2616985"
  },
  {
    "text": "uh, there might be ways in which the, the feedback is implicit in, in deployment.",
    "start": "2616985",
    "end": "2622549"
  },
  {
    "text": "For example, let's say, if the action that, um, if- if- if the prediction that you made was right,",
    "start": "2622550",
    "end": "2627845"
  },
  {
    "text": "let's say the user ends up taking a certain, uh, path of actions, and you can- you can kind of get",
    "start": "2627845",
    "end": "2633380"
  },
  {
    "text": "this implicit feedback of whether your prediction was right or wrong. Uh, so so- sometimes, you ki- you kind of get that automated feedback.",
    "start": "2633380",
    "end": "2640175"
  },
  {
    "text": "In other, other scenarios, you want to make this prediction on, on the real data, and then have somebody relabel them and measure the performance, right?",
    "start": "2640175",
    "end": "2649250"
  },
  {
    "text": "So collect- collect some predictions that you made in deployment and have somebody label them just to see what fraction of them you got right.",
    "start": "2649250",
    "end": "2655730"
  },
  {
    "text": "So it's like another dev set, essentially? Yeah, yeah. Think of it as another dev set if there is no implicit feedback,",
    "start": "2655730",
    "end": "2662510"
  },
  {
    "text": "but sometimes, there can be implicit feedback in your- in overall application. Let's say, your- the user takes",
    "start": "2662510",
    "end": "2667700"
  },
  {
    "text": "a certain kind of actions if the prediction was right, right? In, in that case, you get like automated, automated feedback. Good question.",
    "start": "2667700",
    "end": "2674645"
  },
  {
    "text": "So, um, so here in our action space,",
    "start": "2674645",
    "end": "2679715"
  },
  {
    "text": "we saw that some of these actions are- can, can, can- you know, this, this- uh,",
    "start": "2679715",
    "end": "2685085"
  },
  {
    "text": "can be kind of contradictory with other actions. For example, add features versus fewer features, add depth versus reduce depth,",
    "start": "2685085",
    "end": "2692015"
  },
  {
    "text": "reduce regularization versus increase regularization, right? So some of them are kind of contradictory, and it's inevitable that you absolutely need to do",
    "start": "2692015",
    "end": "2700160"
  },
  {
    "text": "a bias-variance analysis to decide which of those actions you need to take. However, there is this- this, um,",
    "start": "2700160",
    "end": "2707570"
  },
  {
    "text": "um, this action called get more data, right? So get more data can help fight bias,",
    "start": "2707570",
    "end": "2715130"
  },
  {
    "text": "but you don't expect it to help- uh, uh, it can help fight variance but you don't expect it to,",
    "start": "2715130",
    "end": "2721190"
  },
  {
    "text": "you know, affect your bias in any way. But generally, getting more data is a pretty expensive step,",
    "start": "2721190",
    "end": "2727625"
  },
  {
    "text": "and quite often, you know, you need to answer the question of, you know,",
    "start": "2727625",
    "end": "2733130"
  },
  {
    "text": "i- is it- i- does, does getting more data, is it going to help me or not, okay? Is go- getting more data is going to help me fight the,",
    "start": "2733130",
    "end": "2741109"
  },
  {
    "text": "uh, you know, the variance in my model or not? Maybe the, you know, the, the, the amount of data that you have is,",
    "start": "2741110",
    "end": "2746375"
  },
  {
    "text": "is, is not sufficient or maybe it is sufficient. How do you, how do you answer that question?",
    "start": "2746375",
    "end": "2752180"
  },
  {
    "text": "So for that, there is this, you know, pretty useful plot that you would wanna make. [NOISE] so the, uh,",
    "start": "2752180",
    "end": "2760099"
  },
  {
    "start": "2753000",
    "end": "3253000"
  },
  {
    "text": "the plot that you wanna do is something like this. [NOISE] So this, think",
    "start": "2760100",
    "end": "2772490"
  },
  {
    "text": "of it as [NOISE] fraction of data or data size.",
    "start": "2772490",
    "end": "2782090"
  },
  {
    "text": "[NOISE]",
    "start": "2782090",
    "end": "2807230"
  },
  {
    "text": "Green line is desired performance level,",
    "start": "2807230",
    "end": "2814580"
  },
  {
    "text": "or let's call it desired error level.",
    "start": "2814580",
    "end": "2818370"
  },
  {
    "text": "And this axis is error,",
    "start": "2823090",
    "end": "2828440"
  },
  {
    "text": "and this is fraction of data. [NOISE] And you have your- [NOISE]",
    "start": "2828440",
    "end": "2860329"
  },
  {
    "text": "right? So what we do is we take the- the full data that we have and split it into smaller and smaller fractions, okay?",
    "start": "2860330",
    "end": "2870275"
  },
  {
    "text": "And with each of the small fractions, [NOISE] each of the smaller fractions,",
    "start": "2870275",
    "end": "2875600"
  },
  {
    "text": "get the train error and test error or the, ah, dev error from that fraction alone.",
    "start": "2875600",
    "end": "2882890"
  },
  {
    "text": "And then take a bigger set, get the, uh, corresponding train and dev error from the big- bigger fraction,",
    "start": "2882890",
    "end": "2888590"
  },
  {
    "text": "then get an even bigger set. So each of these here represents your data size increasing, right?",
    "start": "2888590",
    "end": "2896105"
  },
  {
    "text": "So, you know, for simplicity, assume both your dev set and train set are proportionally increasing.",
    "start": "2896105",
    "end": "2902345"
  },
  {
    "text": "And w- with each, uh, uh, with- with- with with increasing data size,",
    "start": "2902345",
    "end": "2907984"
  },
  {
    "text": "plot both the train error, so- or train.",
    "start": "2907985",
    "end": "2913100"
  },
  {
    "text": "Uh, so this is the training error [NOISE] and this is",
    "start": "2913100",
    "end": "2921770"
  },
  {
    "text": "the test error, [NOISE] okay?",
    "start": "2921770",
    "end": "2931835"
  },
  {
    "text": "In this scenario, the desired error level is- is somewhere over here.",
    "start": "2931835",
    "end": "2937880"
  },
  {
    "text": "Now, think of it as human level performance. And by plotting your model performance of",
    "start": "2937880",
    "end": "2943340"
  },
  {
    "text": "both a train and test error as you subsample your data. And a sub-sampling would go this way as you- as you,",
    "start": "2943340",
    "end": "2949160"
  },
  {
    "text": "um, um, uh, measure it on the full data. This kind of a model where the train and test performance come really close,",
    "start": "2949160",
    "end": "2957335"
  },
  {
    "text": "will tell you that collecting more data is not going to help you, right?",
    "start": "2957335",
    "end": "2962525"
  },
  {
    "text": "Because the gap between the training error and test error is pretty small.",
    "start": "2962525",
    "end": "2967714"
  },
  {
    "text": "And they're, you know, they're pretty close to converging. So if you were to collect more data and if you were to extrapolate these,",
    "start": "2967715",
    "end": "2974375"
  },
  {
    "text": "it would probably kind of, you know, convert to this level, right?",
    "start": "2974375",
    "end": "2980570"
  },
  {
    "text": "And their- the- the- the- the two are pretty close to converging, okay? So this is a scenario where collecting more data is not gonna help you, right?",
    "start": "2980570",
    "end": "2990020"
  },
  {
    "text": "This is, think of this as a high bias scenario.",
    "start": "2990020",
    "end": "2996270"
  },
  {
    "text": "And the question of collecting more data.",
    "start": "2997450",
    "end": "3002900"
  },
  {
    "text": "The answer is no, right? So collecting more data should not be the first thing you are thinking",
    "start": "3005940",
    "end": "3013780"
  },
  {
    "text": "of in- in- um, in such a scenario. However, you're in situations like this where",
    "start": "3013780",
    "end": "3024349"
  },
  {
    "text": "this is your desired error level [NOISE]",
    "start": "3026430",
    "end": "3037240"
  },
  {
    "text": "and your training error. [NOISE]",
    "start": "3037240",
    "end": "3048280"
  },
  {
    "text": "That's you're training error. Let's see.",
    "start": "3048280",
    "end": "3051590"
  },
  {
    "text": "I'm loosely calling this test error, but, you know, think of this as your train dev set error, dev set error, right?",
    "start": "3060090",
    "end": "3067810"
  },
  {
    "text": "In- in this scenario, collecting more data. So again, this is fraction of data or data size.",
    "start": "3067810",
    "end": "3077480"
  },
  {
    "text": "Here it would be reasonable to, you know, extrapolate this as this rising up a little further,",
    "start": "3083820",
    "end": "3091510"
  },
  {
    "text": "and this coming down a little more. All right, so if your- if your plot looks like this,",
    "start": "3091510",
    "end": "3097785"
  },
  {
    "text": "then you want to think of this as a high-variance scenario. [NOISE]",
    "start": "3097785",
    "end": "3108600"
  },
  {
    "text": "Scenario. And for the question of collect more data, [NOISE] the answer here is yes.",
    "start": "3108600",
    "end": "3119055"
  },
  {
    "text": "You know, it is worth collecting more data. It is- it is worth, um, depending on, you know, um, how- how much you value your performance,",
    "start": "3119055",
    "end": "3126645"
  },
  {
    "text": "it may be worth spending more money and, you know, collecting more data, okay?",
    "start": "3126645",
    "end": "3131830"
  },
  {
    "text": "Whereas, if you are over here, you're training error itself is a lot worse than the desired performance level.",
    "start": "3131830",
    "end": "3139795"
  },
  {
    "text": "And your test error is matching your training error. Which means you probably want to increase your model capacity, right?",
    "start": "3139795",
    "end": "3147325"
  },
  {
    "text": "Use a bigger neural network or use more features or use a more complex kernel, right? So that, first you bring your training error down and, you know.",
    "start": "3147325",
    "end": "3156410"
  },
  {
    "text": "Any- Any questions on this? Yes, question? [inaudible] desired [inaudible]",
    "start": "3157410",
    "end": "3166660"
  },
  {
    "text": "Yeah. So- so the question is, how do we set the desired error level? And- And that is, um,",
    "start": "3166660",
    "end": "3172915"
  },
  {
    "text": "there is no common answer for that, that really depends on your application.",
    "start": "3172915",
    "end": "3177985"
  },
  {
    "text": "And you know, as- as- as the, you know, owner of the product, you need to decide what your desired error level is.",
    "start": "3177985",
    "end": "3184480"
  },
  {
    "text": "We want to [inaudible] You- well, so the desired error level,",
    "start": "3184480",
    "end": "3189640"
  },
  {
    "text": "it may not always be possible to bring it down to 0. And the value to which you want to bring it to will actually depend on,",
    "start": "3189640",
    "end": "3198295"
  },
  {
    "text": "you know, the metric of your choice, right? So- so if your metric is say, accuracy and your prevalence is very low, then,",
    "start": "3198295",
    "end": "3205135"
  },
  {
    "text": "you know, this will be like a really low value in general. So it depends on your choice of metric. So intentionally I've just called it error,",
    "start": "3205135",
    "end": "3212020"
  },
  {
    "text": "but what the actual, you know, units here are- will depend on the metric that you've chosen. Any other questions?",
    "start": "3212020",
    "end": "3219579"
  },
  {
    "text": "[inaudible] question [inaudible] desired performance security like the [inaudible]",
    "start": "3219580",
    "end": "3230260"
  },
  {
    "text": "So the desired error level performance, um, could be upper bounded by human level performance, sure, it could be, yeah.",
    "start": "3230260",
    "end": "3237920"
  },
  {
    "text": "All right. Any other questions? Ah, let's see, are we done with the practical?",
    "start": "3240060",
    "end": "3247750"
  },
  {
    "text": "A few more, uh, uh, uh, concluding, um, uh, uh, comments.",
    "start": "3247750",
    "end": "3253510"
  },
  {
    "start": "3253000",
    "end": "3599000"
  },
  {
    "text": "As I said, ah, always, always, always our goal should be deployment performance, right?",
    "start": "3253510",
    "end": "3263410"
  },
  {
    "text": "Don't lose sight of the end goal, right? All the other measurements that we do are only to aid",
    "start": "3263410",
    "end": "3271240"
  },
  {
    "text": "us in taking the right actions so that the deployment performance improves, right?",
    "start": "3271240",
    "end": "3276895"
  },
  {
    "text": "It's very common to lose track and just focus on, say, dev-set performance or just focus on the train-dev performance,",
    "start": "3276895",
    "end": "3285535"
  },
  {
    "text": "but you should never lose- lose- lose track of the fact that your end goal is always the deployment performance.",
    "start": "3285535",
    "end": "3292585"
  },
  {
    "text": "And why- why deployment performance is your end goal,",
    "start": "3292585",
    "end": "3299820"
  },
  {
    "text": "it is for- for tactical purposes, you want to measure the training performance and",
    "start": "3299820",
    "end": "3307150"
  },
  {
    "text": "the train-dev performance or the training performance and the dev-set performance and look at those. And the reason you want to measure them is so",
    "start": "3307150",
    "end": "3314650"
  },
  {
    "text": "that you can decide which action to take, right? But the action you are taking is with the goal of",
    "start": "3314650",
    "end": "3319780"
  },
  {
    "text": "still getting good deployment performance, right? And this is where bias-variance analysis,",
    "start": "3319780",
    "end": "3325150"
  },
  {
    "text": "kind of, comes into picture, because with bias-variance analysis, you can decide among these conflicting set of actions,",
    "start": "3325150",
    "end": "3333250"
  },
  {
    "text": "which is the action that you wanna take. If you blindly take some action that, let's say, you know, um, um, um,",
    "start": "3333250",
    "end": "3339400"
  },
  {
    "text": "increasing features, is a good thing, and if you're- you're to go- go ahead and increase your features,",
    "start": "3339400",
    "end": "3345055"
  },
  {
    "text": "then, um, you know, that may be wrong or the wrong thing to do if the problem that you're facing is high-variance.",
    "start": "3345055",
    "end": "3352795"
  },
  {
    "text": "Similarly, um, let's say you're- you're- you're, uh, at some, uh, you're getting some, kind of, a model, uh,",
    "start": "3352795",
    "end": "3359380"
  },
  {
    "text": "some kind of a performance on your dev-set, you know, you'll- you- you feel it is, you know, um, insufficient and you go",
    "start": "3359380",
    "end": "3366970"
  },
  {
    "text": "about just collecting more data to increase your dev-set performance. And if you are in a scenario like this where",
    "start": "3366970",
    "end": "3373299"
  },
  {
    "text": "your test set performance was lower than- than the, uh, training performance, which means that this set error",
    "start": "3373300",
    "end": "3379270"
  },
  {
    "text": "was higher than the- than the desired level error, then collecting more data is not gonna help you, right?",
    "start": "3379270",
    "end": "3385089"
  },
  {
    "text": "And- and therefore, looking at the trainer- uh,",
    "start": "3385090",
    "end": "3390415"
  },
  {
    "text": "looking at basically the breakdown of the performance at all these metrics, it's extremely crucial to decide what",
    "start": "3390415",
    "end": "3397900"
  },
  {
    "text": "the next action that you're gonna take is- is- is gonna be. And another final advice is in your homework, uh, basically,",
    "start": "3397900",
    "end": "3407590"
  },
  {
    "text": "you've been, um, implementing a lot of these algorithms, implementing gradient descent yourself,",
    "start": "3407590",
    "end": "3412630"
  },
  {
    "text": "implementing GDA yourself, or neural networks yourself. Please don't ever do that in- in- in- in- in, uh, in production, right?",
    "start": "3412630",
    "end": "3419920"
  },
  {
    "text": "Don't implement the algorithms yourself. Always, always use some kind of, uh, a software package that somebody has already implemented and tested.",
    "start": "3419920",
    "end": "3427630"
  },
  {
    "text": "[LAUGHTER] You know, don't go about doing gradient descent by yourself if- if you wanna build some kind of, uh, um, uh, a real-world application, right?",
    "start": "3427630",
    "end": "3434710"
  },
  {
    "text": "That's- that's totally the wrong, uh, uh, thing to do. It's- it's very important to implement",
    "start": "3434710",
    "end": "3440080"
  },
  {
    "text": "neural networks yourself for the purposes of understanding how they work, right? But- but, you know, um, uh,",
    "start": "3440080",
    "end": "3445795"
  },
  {
    "text": "don't- don't- don't do that, don't go about, you know, in a- some, kind of, an adventurous path and implement gradient descent yourself for your, uh,",
    "start": "3445795",
    "end": "3452350"
  },
  {
    "text": "application. [NOISE] Yes, question. So [inaudible] Yeah.",
    "start": "3452350",
    "end": "3466900"
  },
  {
    "text": "[inaudible] in your experience [inaudible] Biggest pitfalls in practical stuff? [OVERLAPPING] Yeah. What- what do people do wrong, like, so many things [inaudible]",
    "start": "3466900",
    "end": "3473590"
  },
  {
    "text": "So- uh, so- so- so the question is, you know, uh, there, you know,",
    "start": "3473590",
    "end": "3480039"
  },
  {
    "text": "a lot of people, you know, probably, you know, know this knowledge, um, but still lots of, you know,",
    "start": "3480040",
    "end": "3486385"
  },
  {
    "text": "uh, companies fail, lots of teams fail. Why does that happen? And I don't think there's a single answer to that because,",
    "start": "3486385",
    "end": "3493225"
  },
  {
    "text": "uh, first of all, you may know all the theory, but, you know, your execution may be poor, right?",
    "start": "3493225",
    "end": "3498430"
  },
  {
    "text": "You know, er, uh, even though you know things, you may not always execute them in the right way.",
    "start": "3498430",
    "end": "3503454"
  },
  {
    "text": "That apart, there can be, you know, other reasons beyond your, you know, control.",
    "start": "3503455",
    "end": "3508869"
  },
  {
    "text": "For example, even though your machine learning approach was correct, you may be solving the wrong problem for which there's no customer traction, right?",
    "start": "3508870",
    "end": "3517060"
  },
  {
    "text": "So there are lots of other reasons that come into picture why teams fails, right? It's not always the- the, uh,",
    "start": "3517060",
    "end": "3522474"
  },
  {
    "text": "the technology that causes failure, right?",
    "start": "3522475",
    "end": "3528130"
  },
  {
    "text": "So it's- it's equally important that you go after a problem that, you know, that's kind of, what solving and there are, you know,",
    "start": "3528130",
    "end": "3535060"
  },
  {
    "text": "people or- or- or, you know, something that's valuable. If- if- if solving the problem is valuable, then, you know, um,",
    "start": "3535060",
    "end": "3541145"
  },
  {
    "text": "it's- it's- it's, um, it's good, but if your problem- is solving a problem, even though you solve it well,",
    "start": "3541145",
    "end": "3546900"
  },
  {
    "text": "if nobody is interested in the solution, then, you know, obviously, you know, you're, like, the team is gonna fail,",
    "start": "3546900",
    "end": "3552045"
  },
  {
    "text": "not for machine learning reasons, but, you know, it's- it's still a failure. [NOISE] All right.",
    "start": "3552045",
    "end": "3558690"
  },
  {
    "text": "Uh, any other questions on this before we move on to,",
    "start": "3558690",
    "end": "3563829"
  },
  {
    "text": "um, [NOISE] uh, topics related to the exam? Good. Okay. So- so for the- for the,",
    "start": "3563830",
    "end": "3573715"
  },
  {
    "text": "um, so the next thing I wanna, uh, briefly touch upon, just for a few minutes, is to give you, you know, um, um,",
    "start": "3573715",
    "end": "3581194"
  },
  {
    "text": "some kind of an expectation of the format of the final exam, um.",
    "start": "3581195",
    "end": "3586660"
  },
  {
    "text": "We have posted some- some practice final exams on- on Piazza,",
    "start": "3586660",
    "end": "3592359"
  },
  {
    "text": "which hopefully you've already had a look. Um, however, use those,",
    "start": "3592360",
    "end": "3597685"
  },
  {
    "text": "um, those- those, uh, practice exams as- only for the purposes of,",
    "start": "3597685",
    "end": "3603685"
  },
  {
    "text": "you know, getting access to a pool of questions, right? The format of the exam, uh, this time will likely be, uh, different.",
    "start": "3603685",
    "end": "3611995"
  },
  {
    "text": "And in terms of the format itself, uh, there are gonna be- so,",
    "start": "3611995",
    "end": "3619330"
  },
  {
    "text": "uh, so the- the- the, uh, format that I'm gonna describe now, there is a very high probability that that will be the format,",
    "start": "3619330",
    "end": "3627130"
  },
  {
    "text": "but there is a small probability we may, you know, um, uh, tune a few things. Uh, but, you know, uh,",
    "start": "3627130",
    "end": "3632965"
  },
  {
    "text": "more or less, what you can expect is, uh, the first question is gonna be true or false,",
    "start": "3632965",
    "end": "3639439"
  },
  {
    "text": "and they're gonna be about 10 of them. The second question is gonna be short answers,",
    "start": "3640170",
    "end": "3649520"
  },
  {
    "text": "and they're gonna be about five of them. The third question is,",
    "start": "3651810",
    "end": "3658569"
  },
  {
    "text": "uh, you can call it a theory question. I'm just gonna call it theory, right? Uh, it's gonna be basically just math,",
    "start": "3658570",
    "end": "3665380"
  },
  {
    "text": "and it's, uh, it's, uh, uh, there are gonna be sub-questions, where essentially,",
    "start": "3665380",
    "end": "3672790"
  },
  {
    "text": "it is a much longer proof for which we, kind of, guide you by breaking it down into, you know,",
    "start": "3672790",
    "end": "3678579"
  },
  {
    "text": "sub-problems and, you know, you solve each of the sub-problems, you will- you will have effectively,",
    "start": "3678580",
    "end": "3684115"
  },
  {
    "text": "um, um, solved the full- full question. And the fourth one is, you know,",
    "start": "3684115",
    "end": "3690070"
  },
  {
    "text": "you can call it theory/application, where again,",
    "start": "3690070",
    "end": "3696535"
  },
  {
    "text": "um, it's- it's- it's, uh, it's, kind of, a new problem setting that, you know,",
    "start": "3696535",
    "end": "3702220"
  },
  {
    "text": "it's like, ka- ed- um, um, a novel scenario, um, for which you wanna extend some of",
    "start": "3702220",
    "end": "3708339"
  },
  {
    "text": "the- the ideas that you've learned in this course to this new setting, and they're gonna be like two, um, uh,",
    "start": "3708340",
    "end": "3715224"
  },
  {
    "text": "theoretical parts where you, like, kind of, derive whatever the update rules, prediction rules, etc.",
    "start": "3715225",
    "end": "3720535"
  },
  {
    "text": "and a third programming component, where you implement these rules in the starter code",
    "start": "3720535",
    "end": "3726010"
  },
  {
    "text": "that you provide and you execute it and you get a plot and you, you know, include the plot in your write-up.",
    "start": "3726010",
    "end": "3731440"
  },
  {
    "text": "So, uh, this is gonna be the- the, uh, structure of the exam. Um, you can, I would say,",
    "start": "3731440",
    "end": "3738940"
  },
  {
    "text": "you know, expect it to be hard. It's not gonna be long. So, you know, this is, you know,",
    "start": "3738940",
    "end": "3744295"
  },
  {
    "text": "not- not- not- uh, we don't have, like, you know, 10 big theory questions or anything. It's much shorter than the home-works that you've encountered with.",
    "start": "3744295",
    "end": "3751720"
  },
  {
    "text": "Uh, but it's gonna be, um, um, it's- it would be very necessary that you have a good,",
    "start": "3751720",
    "end": "3757960"
  },
  {
    "text": "kind of, overall understanding of the course. You're good at the prerequisites,",
    "start": "3757960",
    "end": "3763645"
  },
  {
    "text": "so things like probability, right, uh,",
    "start": "3763645",
    "end": "3769195"
  },
  {
    "text": "matrix calculus, um, linear algebra,",
    "start": "3769195",
    "end": "3778070"
  },
  {
    "text": "and, you know, um, general, you know, um, um, things that we've covered throughout the course like maximum likelihood, uh, etc.",
    "start": "3779820",
    "end": "3787990"
  },
  {
    "text": "It's very important that you have a good understanding of- of, um, the prerequisites and also the important concepts from the course like bias-variance,",
    "start": "3787990",
    "end": "3797980"
  },
  {
    "text": "etc., um, but the- the, um, the specific, um, uh,",
    "start": "3797980",
    "end": "3804350"
  },
  {
    "text": "the- the- the, you know, the different set of questions, so basically these 15 questions and these two questions,",
    "start": "3804350",
    "end": "3809890"
  },
  {
    "text": "you know, kind of, more or less touch upon all parts of the course. Any questions on the format itself? Yes, question.",
    "start": "3809890",
    "end": "3820359"
  },
  {
    "text": "The only coding will mean the, uh, one part of the [inaudible] Yeah. So the co- so the coding is gonna be the last part of- of,",
    "start": "3820360",
    "end": "3826930"
  },
  {
    "text": "uh, question- Question 4. Yes, question. Uh, approximately how many hours is it expected to take?  Is there a case where it would actually take 24 hours to finish?",
    "start": "3826930",
    "end": "3833020"
  },
  {
    "text": "Uh, it's hard to say.",
    "start": "3833020",
    "end": "3840670"
  },
  {
    "text": "So, uh, there are just- so these are, you know, true-false question and short answers.",
    "start": "3840670",
    "end": "3846250"
  },
  {
    "text": "Um, I mean, we expect you to say true or false in one sentence for,",
    "start": "3846250",
    "end": "3851380"
  },
  {
    "text": "you know, an explanation, so one or two sentences for justification. Similarly, short answers, we expect you to,",
    "start": "3851380",
    "end": "3857755"
  },
  {
    "text": "you know, derive an answer, but, you know, we only expect you to provide one or two sentences,",
    "start": "3857755",
    "end": "3862809"
  },
  {
    "text": "you know, of reasoning or justification. So if you know the answers, you know, you can finish one and two in a few minutes, right?",
    "start": "3862810",
    "end": "3870225"
  },
  {
    "text": "But, you know, if- if- if you spend more time on this, you could potentially spend the entire 24 hours on just answering these.",
    "start": "3870225",
    "end": "3876880"
  },
  {
    "text": "So it's very hard to tell, you know, how long it's gonna, um, um, uh, take. So the format itself,",
    "start": "3876880",
    "end": "3883194"
  },
  {
    "text": "if you know everything, we expect you to comfortably finish it in three hours, but,",
    "start": "3883195",
    "end": "3888520"
  },
  {
    "text": "uh, if you're spending time on- on, you know, the- er, if you- if you need more time to spend on each of these,",
    "start": "3888520",
    "end": "3894100"
  },
  {
    "text": "you could potentially take, you know, more than 24 hours. So it's- it's hard for us to set an expectation of how long it's gonna take for a student.",
    "start": "3894100",
    "end": "3901660"
  },
  {
    "text": "We could tell on average, but for a given student, you know, the variance can be quite high. But, you know, um,",
    "start": "3901660",
    "end": "3908650"
  },
  {
    "text": "think of this as, like, approximately two homework questions, right, and some,",
    "start": "3908650",
    "end": "3914725"
  },
  {
    "text": "you know- this again, in it, they're just true, false, and short answers, so it shouldn't take too long.",
    "start": "3914725",
    "end": "3921245"
  },
  {
    "text": "Er, any- any- any questions? Yeah. Yes, question. [NOISE] I mean, I- I think [inaudible] we'll be answering Piazza [inaudible]",
    "start": "3921245",
    "end": "3929255"
  },
  {
    "text": "Very good question. So during- so this is going to be a take-home exam, which means we gonna post the- the, um,",
    "start": "3929255",
    "end": "3937640"
  },
  {
    "text": "post the, uh, exam on Piazza as a PDF, and you will write up your solutions,",
    "start": "3937640",
    "end": "3945185"
  },
  {
    "text": "uh, I don't know, in tech or by hand. However, just the way you do your homework, preferably in tech,",
    "start": "3945185",
    "end": "3951020"
  },
  {
    "text": "so that it's easier for us to grade and you will post it on Gradescope, like, uh, any other homework.",
    "start": "3951020",
    "end": "3957155"
  },
  {
    "text": "Um, during the exam period itself, we will disable Piazza, right?",
    "start": "3957155",
    "end": "3963140"
  },
  {
    "text": "So even though the format is like a homework, it is not a homework, it's an exam, which means, uh,",
    "start": "3963140",
    "end": "3969860"
  },
  {
    "text": "we will, um, um, you cannot talk to each other,",
    "start": "3969860",
    "end": "3975410"
  },
  {
    "text": "uh, you cannot collaborate. That's against the honor code. Collaborating on the exam is against the honor code.",
    "start": "3975410",
    "end": "3981560"
  },
  {
    "text": "You can use any of the resources that you want. Look at the course notes, look up- uh,",
    "start": "3981560",
    "end": "3986945"
  },
  {
    "text": "you know, watch the lectures again, look at a homework solutions. You are even free to look up the Internet,",
    "start": "3986945",
    "end": "3992735"
  },
  {
    "text": "but you cannot post on some, say Stack Exchange, and ask for somebody [LAUGHTER] for help. But you're totally allowed to- you know,",
    "start": "3992735",
    "end": "4000250"
  },
  {
    "text": "search the Internet for any- any- uh, kind of- um, um, uh, any kind of,",
    "start": "4000250",
    "end": "4006550"
  },
  {
    "text": "uh, uh, questions that you may have. Uh, but no communication basically. By communication, I mean, no asking questions.",
    "start": "4006550",
    "end": "4013150"
  },
  {
    "text": "Uh, but you can ask Google but, you know no asking, uh, uh, any other- any other human being, right?",
    "start": "4013150",
    "end": "4020290"
  },
  {
    "text": "Uh, during the exam, um, we will not help you in Piazza for things that you don't understand.",
    "start": "4020290",
    "end": "4030265"
  },
  {
    "text": "You- you can create private Piazza posts. And if we think the question is already clear about it,",
    "start": "4030265",
    "end": "4036265"
  },
  {
    "text": "we will not respond to it. Just like an exam room, uh, you know, if- if you have a question, um,",
    "start": "4036265",
    "end": "4042190"
  },
  {
    "text": "uh, you know, ask yourself, would this be a question that I ask a TA in an exam room and,",
    "start": "4042190",
    "end": "4048850"
  },
  {
    "text": "uh, you know, create a private Piazza post. If we think it's a valid question and if there is an ambiguity,",
    "start": "4048850",
    "end": "4055135"
  },
  {
    "text": "then we will make a public post and clarify to everyone. Um, however, if we think that, you know, if the- the- the- um,",
    "start": "4055135",
    "end": "4063190"
  },
  {
    "text": "the- the question is already clear about it and you have not thought sufficiently about it,",
    "start": "4063190",
    "end": "4070210"
  },
  {
    "text": "then we will, uh, refrain from answering those kind of questions, or maybe we will tell you, you know,",
    "start": "4070210",
    "end": "4076120"
  },
  {
    "text": "the question's already clear about it, you know, something like that just so that all the students obtain the same level of- of, uh, response from us.",
    "start": "4076120",
    "end": "4086990"
  },
  {
    "text": "Does that- does that answer the question? Okay. Yes, question? Uh, when you say that Piazza will be disabled, um,",
    "start": "4087120",
    "end": "4092920"
  },
  {
    "text": "are- will there be like responses in questions from brought, like, before the exam by the quarter still be available or [OVERLAPPING]?",
    "start": "4092920",
    "end": "4099549"
  },
  {
    "text": "Yes, you can- you can, um, you can open Piazza and search for all the previous, uh, uh, questions, but, uh,",
    "start": "4099550",
    "end": "4106315"
  },
  {
    "text": "I think there's an option in which we can disable posting new questions or there- there are some such feature in Piazza,",
    "start": "4106315",
    "end": "4112134"
  },
  {
    "text": "uh, that- that will be up. Yes, question. [inaudible] like the first [NOISE] does it cover everything we wanna know.",
    "start": "4112135",
    "end": "4126099"
  },
  {
    "text": "Yes. So I would say for- for the math part of it, focus on matrix calculus,",
    "start": "4126100",
    "end": "4131679"
  },
  {
    "text": "focus on probability, and of course, linear algebra. You know, if you're- if you're really comfortable with them, uh,",
    "start": "4131680",
    "end": "4138699"
  },
  {
    "text": "we expect the- the- these parts to be pretty- pretty straightforward. Yes.",
    "start": "4138700",
    "end": "4145730"
  },
  {
    "text": "Regarding the grade, uh, like [inaudible] how would you [inaudible] I'm sorry, I didn't get the question. Can you repeat? Grades- like grades on every problem.",
    "start": "4148830",
    "end": "4154960"
  },
  {
    "text": "So the grades? Uh, I don't remember it offhand, but it's something like 10,",
    "start": "4154960",
    "end": "4160855"
  },
  {
    "text": "10, and I don't know, it's- it's like 15, 15 or 10, 10 or 20, 20 or something like that.",
    "start": "4160855",
    "end": "4166540"
  },
  {
    "text": "Yeah. All right. So with that,",
    "start": "4166540",
    "end": "4172900"
  },
  {
    "text": "let's kind of rewind all the way back and start our course review.",
    "start": "4172900",
    "end": "4179634"
  },
  {
    "text": "So the course review that we'll be doing some amount today and the rest on Wednesday is to- is to kind of,",
    "start": "4179635",
    "end": "4187915"
  },
  {
    "text": "uh, provide an overview or a second look at all the, uh, uh, all the topics that we've covered.",
    "start": "4187915",
    "end": "4194844"
  },
  {
    "text": "And also kind of, uh, spend some time- spend some time drawing reference to the,",
    "start": "4194845",
    "end": "4201745"
  },
  {
    "text": "uh, relevant homework questions that you've answered. Um, because, um, a lot of- a lot of the things that you learn from this course,",
    "start": "4201745",
    "end": "4209710"
  },
  {
    "text": "we're from, you know, lectures, but an even bigger chunk was from the homeworks, right? And- and, um, some of you have probably,",
    "start": "4209710",
    "end": "4218080"
  },
  {
    "text": "um, gotten all the homework answers correctly and have understood them well. Some of you may have gotten the answers to the homework questions,",
    "start": "4218080",
    "end": "4226270"
  },
  {
    "text": "but haven't really kind of- you know, kind of- kind of understood like the big take-home messages from each homework.",
    "start": "4226270",
    "end": "4233500"
  },
  {
    "text": "The homeworks are a huge part of the- you know, of the overall educational aspects of this course, right?",
    "start": "4233500",
    "end": "4239665"
  },
  {
    "text": "And unlike, you know, many of the other math courses where homeworks are just assigned from, you know, some random textbooks with problem numbers,",
    "start": "4239665",
    "end": "4246430"
  },
  {
    "text": "you know, 17, 15, and 30 or whatever. Uh, in this course, a lot of effort has been put into designing each homework so that it kind",
    "start": "4246430",
    "end": "4252610"
  },
  {
    "text": "of complements your- complements the lectures and the overall learning experience. So we'll- we'll, um,",
    "start": "4252610",
    "end": "4258385"
  },
  {
    "text": "at least do a quick- quick reference to each of the relevant homeworks and- and, um,",
    "start": "4258385",
    "end": "4263635"
  },
  {
    "text": "at least touch upon the take-home messages from each homework as well, uh, depending on the, uh,",
    "start": "4263635",
    "end": "4269485"
  },
  {
    "text": "in the order in which we are doing the review. All right? So let's jump right in.",
    "start": "4269485",
    "end": "4274615"
  },
  {
    "text": "We're gonna start off with supervised learning. That was the first- first,",
    "start": "4274615",
    "end": "4282310"
  },
  {
    "text": "uh, section of the course.",
    "start": "4282310",
    "end": "4284720"
  },
  {
    "text": "So in supervised learning, if you remember, the goal of supervised learning is to learn a mapping from x to y.",
    "start": "4306060",
    "end": "4314905"
  },
  {
    "text": "Where you think of x as an input and y as an output.",
    "start": "4314905",
    "end": "4320139"
  },
  {
    "text": "And you are given pairs of x-ys as a training set, right?",
    "start": "4320140",
    "end": "4326110"
  },
  {
    "text": "So in supervised learning-",
    "start": "4326110",
    "end": "4328550"
  },
  {
    "text": "so in supervised learning,",
    "start": "4331350",
    "end": "4341935"
  },
  {
    "text": "our goal is to learn a mapping from x to y. And in order to learn this mapping,",
    "start": "4341935",
    "end": "4349300"
  },
  {
    "text": "you are provided a training set s and that training set is basically pairs of x, y examples.",
    "start": "4349300",
    "end": "4358580"
  },
  {
    "text": "I equals 1 to n. Generally, small n refers to the number of examples in our training set.",
    "start": "4359070",
    "end": "4365139"
  },
  {
    "text": "Okay. And x i generally resides in a d-dimensional space,",
    "start": "4365140",
    "end": "4373300"
  },
  {
    "text": "and this is usually called the input, and output- output y",
    "start": "4373300",
    "end": "4382270"
  },
  {
    "text": "i if it recides- if it's a real value,",
    "start": "4382270",
    "end": "4387415"
  },
  {
    "text": "then we call this regression, right?",
    "start": "4387415",
    "end": "4393175"
  },
  {
    "text": "If y i is either 0 or 1, we call this binary classification.",
    "start": "4393175",
    "end": "4401080"
  },
  {
    "text": "[NOISE] Okay.",
    "start": "4401080",
    "end": "4410360"
  },
  {
    "text": "Y^i could be, you know, um, integers 1, 2, 3, and so on.",
    "start": "4410520",
    "end": "4418210"
  },
  {
    "text": "And this, you can either call it count or Poisson regression and so on.",
    "start": "4418210",
    "end": "4429160"
  },
  {
    "text": "And the overall workflow for supervised learning was to start with a training set,",
    "start": "4429160",
    "end": "4436060"
  },
  {
    "text": "[NOISE] training set, and then run this training set through a learning algorithm,",
    "start": "4436060",
    "end": "4445990"
  },
  {
    "text": "[NOISE] and the output",
    "start": "4445990",
    "end": "4453250"
  },
  {
    "text": "of the learning algorithm was a model, which we called the hypothesis.",
    "start": "4453250",
    "end": "4460030"
  },
  {
    "text": "Right? So think of this as your training set could be, you know, um, uh, um,",
    "start": "4460030",
    "end": "4466120"
  },
  {
    "text": "xy pairs, where y is in 0a nd 1. The learning algorithm was le- uh, say, logistic regression,",
    "start": "4466120",
    "end": "4472120"
  },
  {
    "text": "and the learned hypothesis is the- is the, uh, uh, set of parameters that you got when logistic regression reached convergence, right?",
    "start": "4472120",
    "end": "4481405"
  },
  {
    "text": "And this learned hypothesis will now accept new examples,",
    "start": "4481405",
    "end": "4487375"
  },
  {
    "text": "x, that it has not seen before from the training set and make predictions, y.",
    "start": "4487375",
    "end": "4494995"
  },
  {
    "text": "Right? This is the- this is the kind of, um, uh, um, workflow overview of what exam- what- what happens in supervised learning, right?",
    "start": "4494995",
    "end": "4504040"
  },
  {
    "text": "And the first lear- algorithm that we learned was linear regression. [NOISE] Linear regression.",
    "start": "4504040",
    "end": "4516475"
  },
  {
    "text": "In linear regression, we- we assume that the function h belongs to this parametric family,",
    "start": "4516475",
    "end": "4528145"
  },
  {
    "text": "where we defined it as h Theta of x equals Theta transpose x,",
    "start": "4528145",
    "end": "4534025"
  },
  {
    "text": "where Theta was some vector in R^d. Right? And there's also this intercept term.",
    "start": "4534025",
    "end": "4541840"
  },
  {
    "text": "We assume that x will include the intercept term and- and, you know, Theta is, uh, uh,",
    "start": "4541840",
    "end": "4547090"
  },
  {
    "text": "will also be the- the parameter in the Theta vector that corresponds to the intercept term would be the bias term.",
    "start": "4547090",
    "end": "4552864"
  },
  {
    "text": "Right? So sometimes, uh, to make it explicit, we call it d plus 1, and, you know,",
    "start": "4552865",
    "end": "4558100"
  },
  {
    "text": "other times we just leave it as Theta d and assume that, you know, it's in there. And in order to learn this, uh,",
    "start": "4558100",
    "end": "4566315"
  },
  {
    "text": "learn this parameter vector Theta, right, we need to have a learning algorithm. And the learning- for the learning algorithm,",
    "start": "4566315",
    "end": "4573164"
  },
  {
    "text": "we first define what is called as a, uh, as a cost function J Theta, which is equal to sum over i equals 1 to",
    "start": "4573164",
    "end": "4581200"
  },
  {
    "text": "n h Theta of x minus x^i minus y^i square, right?",
    "start": "4581200",
    "end": "4592495"
  },
  {
    "text": "And this is also commonly called the squared error, where the- you want to penalize the- the, uh, uh,",
    "start": "4592495",
    "end": "4599290"
  },
  {
    "text": "the difference between the predicted value and the correct value and we want to penalize the square of that value and sum over all the squares of these errors.",
    "start": "4599290",
    "end": "4610075"
  },
  {
    "text": "Right? And this, we treat it as a function of Theta,",
    "start": "4610075",
    "end": "4615460"
  },
  {
    "text": "and we want to minimize this error by adjusting Theta to the best possib- to the best possible value, right?",
    "start": "4615460",
    "end": "4623095"
  },
  {
    "text": "Another way to write this in vectorized notation is x",
    "start": "4623095",
    "end": "4629110"
  },
  {
    "text": "Theta minus y square. Yes, question?",
    "start": "4629110",
    "end": "4635215"
  },
  {
    "text": "So is this the choice for the cost function because of the Gaussian, uh,",
    "start": "4635215",
    "end": "4640659"
  },
  {
    "text": "or the- the negative log-likelihood or is this, uh, are there other choices for cost function to do considering the factors?",
    "start": "4640660",
    "end": "4647365"
  },
  {
    "text": "Yeah, so the question is, is this cost function a co- uh, a consequence of the, uh, uh, of- of assuming a- a Gaussian on the, uh, uh,",
    "start": "4647365",
    "end": "4655930"
  },
  {
    "text": "Gaussian on the error term or, you know, can you use other, uh, uh, um, other- other- other loss functions?",
    "start": "4655930",
    "end": "4662455"
  },
  {
    "text": "So there are, um, uh, I'll be answering that shortly. This, uh, the- the- the quick answer is that you can give",
    "start": "4662455",
    "end": "4669909"
  },
  {
    "text": "this a probabilistic interpretation that had you assumed a Gaussian error term then this would be the cost to minimize,",
    "start": "4669910",
    "end": "4678130"
  },
  {
    "text": "but there are other interpretations for linear regression as well. Yeah. Right? So we-we- what we want to do is find",
    "start": "4678130",
    "end": "4687250"
  },
  {
    "text": "Theta is equal to arg min Theta of J of Theta.",
    "start": "4687250",
    "end": "4694305"
  },
  {
    "text": "Right? And in order to- to, um, we put hats on all estimated values.",
    "start": "4694305",
    "end": "4700440"
  },
  {
    "text": "[NOISE] And in order to perform this minimization, first algorithm that we saw was gradient descent.",
    "start": "4700440",
    "end": "4709390"
  },
  {
    "text": "[NOISE] Right?",
    "start": "4709390",
    "end": "4715000"
  },
  {
    "text": "And in- in gradient descent, we start with a random initialization of Theta and run this iterative loop where we",
    "start": "4715000",
    "end": "4723390"
  },
  {
    "text": "repeat Theta equals Theta plus some learning rate,",
    "start": "4723390",
    "end": "4732390"
  },
  {
    "text": "Alpha times y^i minus",
    "start": "4732390",
    "end": "4738495"
  },
  {
    "text": "h Theta of x^i times x^i.",
    "start": "4738495",
    "end": "4745995"
  },
  {
    "text": "And here, we include a summation",
    "start": "4745995",
    "end": "4751250"
  },
  {
    "text": "plus Alpha times summation i equals 1 to n. So this is gradient descent.",
    "start": "4751620",
    "end": "4760525"
  },
  {
    "text": "And we also saw a variant of gradient descent called stochastic gradient descent,",
    "start": "4760525",
    "end": "4765670"
  },
  {
    "text": "where instead of this summation in each iteration, we randomly sample some example, SGD,",
    "start": "4765670",
    "end": "4774790"
  },
  {
    "text": "where we repeat Theta equals Theta plus Alpha times,",
    "start": "4774790",
    "end": "4782995"
  },
  {
    "text": "let's call it y- y- y^k",
    "start": "4782995",
    "end": "4788380"
  },
  {
    "text": "minus h Theta of x^k times x^k,",
    "start": "4788380",
    "end": "4796465"
  },
  {
    "text": "where k  are sampled from the uniform distribution between 0 and n or 1 and n if you,",
    "start": "4796465",
    "end": "4808239"
  },
  {
    "text": "right? So sample a random example number, use that example to run gradient descent for that iteration, right?",
    "start": "4808240",
    "end": "4815995"
  },
  {
    "text": "So that was stochastic gradient descent. So this was one way in which, you know, uh,",
    "start": "4815995",
    "end": "4822355"
  },
  {
    "text": "we solve linear regression using gradient descent. [NOISE] And then we saw these [NOISE] few other interpretations of linear regression.",
    "start": "4822355",
    "end": "4833440"
  },
  {
    "text": "[NOISE]",
    "start": "4833440",
    "end": "4860635"
  },
  {
    "text": "So this was- this was using gradient, uh, uh, based approaches where the gradient descent based approach works for any cost function,",
    "start": "4860635",
    "end": "4869035"
  },
  {
    "text": "not just linear regression. But in case of linear regression, we can also get the closed form solution for the final Theta hat directly, okay?",
    "start": "4869035",
    "end": "4878440"
  },
  {
    "text": "The second approach was what we called as the normal equations for getting a closed form solution, [NOISE] right?",
    "start": "4878440",
    "end": "4887890"
  },
  {
    "text": "And in the normal equations, we basically get x transpose x Theta equals x transpose y.",
    "start": "4887890",
    "end": "4897220"
  },
  {
    "text": "From which if we assume invertibility of x transpose x,",
    "start": "4897220",
    "end": "4902710"
  },
  {
    "text": "which for now we will assume x transpose x is invertible, we get Theta equals x transpose x inverse x transpose y,",
    "start": "4902710",
    "end": "4911755"
  },
  {
    "text": "or Theta hat equals x transpose x inverse x transpose y, right? And this is kind of a pattern that you should tune your eye to look for.",
    "start": "4911755",
    "end": "4921730"
  },
  {
    "text": "Because this pattern we also saw that, you know, can- can show up in other places like,",
    "start": "4921730",
    "end": "4926875"
  },
  {
    "text": "you know, in factor analysis. In factor analysis we saw that, you know, uh, uh, uh, one of the parameter, uh,",
    "start": "4926875",
    "end": "4932955"
  },
  {
    "text": "updates looked- look very close to linear regression, right? So that's- that's, uh, the normal equation.",
    "start": "4932955",
    "end": "4939525"
  },
  {
    "text": "And then we saw a few more interpretations of linear regression.",
    "start": "4939525",
    "end": "4945505"
  },
  {
    "text": "So the other one was projection based, right, projection.",
    "start": "4945505",
    "end": "4953905"
  },
  {
    "text": "So if- if, um- so let's assume this is,",
    "start": "4953905",
    "end": "4963985"
  },
  {
    "text": "um, Theta_1, Theta_d, and this is the parameter space, right?",
    "start": "4963985",
    "end": "4974155"
  },
  {
    "text": "And then there is this design matrix X, right? This is the matrix,",
    "start": "4974155",
    "end": "4980149"
  },
  {
    "text": "and run it through this. And we get an output space.",
    "start": "4980790",
    "end": "4986570"
  },
  {
    "text": "This is y_1, y_2,",
    "start": "4989010",
    "end": "4994090"
  },
  {
    "text": "call this y_n, right? So each dimension in the input- in the parameter space",
    "start": "4994090",
    "end": "5000510"
  },
  {
    "text": "or the input space corresponds to each parameter or each feature. And each axis or each dimension in",
    "start": "5000510",
    "end": "5007500"
  },
  {
    "text": "the output space represents a different example, right? That's because x takes input,",
    "start": "5007500",
    "end": "5014869"
  },
  {
    "text": "you know, x is in R^d, or sorry, R^n by d. So it takes us input something in",
    "start": "5014870",
    "end": "5023160"
  },
  {
    "text": "d-dimension and produces output something in the- in n-dimension, right? And here, because this is a d-dimensional space,",
    "start": "5023160",
    "end": "5033555"
  },
  {
    "text": "getting kind of up map to an n-dimensional space where we expect d to be smaller than n,",
    "start": "5033555",
    "end": "5039360"
  },
  {
    "text": "the- the column space or the range of x is going to be a subspace of the entire output space y,",
    "start": "5039360",
    "end": "5048120"
  },
  {
    "text": "but the subspace has dimension d, right? So let me use some different colors.",
    "start": "5048120",
    "end": "5053460"
  },
  {
    "text": "[NOISE]",
    "start": "5053460",
    "end": "5065670"
  },
  {
    "text": "So uh, the entire d-dimensional space will now get mapped to some subspace,",
    "start": "5065670",
    "end": "5072489"
  },
  {
    "text": "right, and this subspace basically spans to infinity in all four directions,",
    "start": "5074570",
    "end": "5080685"
  },
  {
    "text": "right, and it crosses through the origin. By definition, a subspace crosses through the origin, right, and the subspace is d-dimensional.",
    "start": "5080685",
    "end": "5088635"
  },
  {
    "text": "However, for the given data that we have, the point y or the vector y may reside outside the subspace, right?",
    "start": "5088635",
    "end": "5098340"
  },
  {
    "text": "So this is the y, um, that- that is- that is given in the data.",
    "start": "5098340",
    "end": "5104400"
  },
  {
    "text": "So we are given x and we want to find the Theta such that x- x Theta equals y,",
    "start": "5104400",
    "end": "5114705"
  },
  {
    "text": "and x and y come from the training set. And we want to find the best possible Theta y such that",
    "start": "5114705",
    "end": "5121395"
  },
  {
    "text": "X Theta is as close to- to uh, y as possible. Now, the way we- uh,",
    "start": "5121395",
    "end": "5128730"
  },
  {
    "text": "we cannot always solve this exactly, right? X Theta will- cannot always be exactly equal to y because",
    "start": "5128730",
    "end": "5135855"
  },
  {
    "text": "y can reside outside the- outside the range of- of x. So instead what we do is solve X Theta",
    "start": "5135855",
    "end": "5145618"
  },
  {
    "text": "equals projection of y onto the range of x.",
    "start": "5145619",
    "end": "5152955"
  },
  {
    "text": "Instead, what we do is project y onto the- onto the subspace spanned by x,",
    "start": "5152955",
    "end": "5164010"
  },
  {
    "text": "and then solve x Theta equals projection, right? This cannot be equal because y can- can be outside the range.",
    "start": "5164010",
    "end": "5172230"
  },
  {
    "text": "But this, by definition, the projection of- of y onto the column space of x can be solved, right?",
    "start": "5172230",
    "end": "5181660"
  },
  {
    "text": "And if you remember, the projection of y onto the,",
    "start": "5181790",
    "end": "5188370"
  },
  {
    "text": "um, column space of x is given by x, x transpose x inverse, x transpose y,",
    "start": "5188370",
    "end": "5199829"
  },
  {
    "text": "where this part is called the projection matrix, [NOISE] right?",
    "start": "5199830",
    "end": "5208365"
  },
  {
    "text": "So this is- this is just the projection of y onto the column space of x.",
    "start": "5208365",
    "end": "5213495"
  },
  {
    "text": "And once we have it in this form, when y is projected onto the column space,",
    "start": "5213495",
    "end": "5219510"
  },
  {
    "text": "it is now part, you know, x- this x can be inverted in principle because there",
    "start": "5219510",
    "end": "5225210"
  },
  {
    "text": "is a bijection between the input space and this column space, there is a one to one, um, um,",
    "start": "5225210",
    "end": "5230955"
  },
  {
    "text": "uh, bijection, which means we can now informally speaking,",
    "start": "5230955",
    "end": "5237585"
  },
  {
    "text": "invert x form this projection, uh, uh, for x. So you can cancel the x's and say x transpose x inverse x transpose y, right?",
    "start": "5237585",
    "end": "5249885"
  },
  {
    "text": "So this was the projection interpretation of linear regression. And finally, we also went over the probabilistic interpretation of linear regression.",
    "start": "5249885",
    "end": "5261640"
  },
  {
    "text": "So in the probabilistic interpretation, we know that- that, um,",
    "start": "5265190",
    "end": "5272835"
  },
  {
    "text": "x Theta will never exactly, uh, equal to y with this linear form. So we say- so instead we assume y",
    "start": "5272835",
    "end": "5280410"
  },
  {
    "text": "equals x transpose Theta or Theta transpose x plus some Epsilon,",
    "start": "5280410",
    "end": "5289620"
  },
  {
    "text": "where Epsilon is distributed according to a standard normal distribution with mean 0,",
    "start": "5289620",
    "end": "5297675"
  },
  {
    "text": "and the- the, uh, um, the variance for now let's just assume Sigma square,",
    "start": "5297675",
    "end": "5304380"
  },
  {
    "text": "which is some unknown constant, right? And now we can- we can, uh,",
    "start": "5304380",
    "end": "5310515"
  },
  {
    "text": "write this as the probability of- so with this,",
    "start": "5310515",
    "end": "5316860"
  },
  {
    "text": "we can write Epsilon equals y minus x transpose Theta or Theta transpose x,",
    "start": "5316860",
    "end": "5324824"
  },
  {
    "text": "which gives us probability of Epsilon equal to",
    "start": "5324825",
    "end": "5330480"
  },
  {
    "text": "probability of y minus x transpose Theta,",
    "start": "5330480",
    "end": "5336180"
  },
  {
    "text": "which is now a Gaussian distribution. It should be 1 over square root 2 Pi Sigma square,",
    "start": "5336180",
    "end": "5344429"
  },
  {
    "text": "where Sigma square is inside the square root times exponent minus- this has mean 0.",
    "start": "5344430",
    "end": "5354435"
  },
  {
    "text": "So it will be this minus 0 square, which is just y minus x transpose Theta",
    "start": "5354435",
    "end": "5362055"
  },
  {
    "text": "square divided by 2 Sigma square, right?",
    "start": "5362055",
    "end": "5368685"
  },
  {
    "text": "So this is just the uh, standard normal distribution. And now, if we pass- perform maximum likelihood,",
    "start": "5368685",
    "end": "5375600"
  },
  {
    "text": "that is basically find the parameter Theta that maximizes this likelihood term so that it is- you know, it,",
    "start": "5375600",
    "end": "5384120"
  },
  {
    "text": "it conforms to a standard normal distribution as much as possible, we get l of Theta is equal to log product I equals 1 to n,",
    "start": "5384120",
    "end": "5397295"
  },
  {
    "text": "1 over square root 2 Pi Sigma square exponent of minus",
    "start": "5397295",
    "end": "5405274"
  },
  {
    "text": "y^i minus x^i transpose Theta",
    "start": "5405274",
    "end": "5410440"
  },
  {
    "text": "squared over 2 Sigma square, right?",
    "start": "5410440",
    "end": "5417010"
  },
  {
    "text": "And now we can, uh, take the, uh, log of the product, the sum of the logs.",
    "start": "5417010",
    "end": "5422655"
  },
  {
    "text": "So this gives us sum i equals 1 to n. Log of this term is some constant,",
    "start": "5422655",
    "end": "5431195"
  },
  {
    "text": "and it's the same constant for all examples. So let's just call it, you know, some c plus log and the exponent",
    "start": "5431195",
    "end": "5439530"
  },
  {
    "text": "cancel minus y^i minus x^i transpose Theta",
    "start": "5439530",
    "end": "5447585"
  },
  {
    "text": "squared over 2 Sigma squared, right?",
    "start": "5447585",
    "end": "5452660"
  },
  {
    "text": "So we have some arbitrary constant that is common for all examples, and another arbitrary scaling constant that is common for all examples.",
    "start": "5452660",
    "end": "5461765"
  },
  {
    "text": "So instead, we can now write this as some- some- some other constants as c prime plus 1",
    "start": "5461765",
    "end": "5469940"
  },
  {
    "text": "over 2 Sigma squared times the negative sum over i equals 1",
    "start": "5469940",
    "end": "5477469"
  },
  {
    "text": "to n y^i minus x^i transpose Theta squared.",
    "start": "5477470",
    "end": "5485835"
  },
  {
    "text": "And now if you wanna maximize the- the, uh, likelihood, uh, objective,",
    "start": "5485835",
    "end": "5492045"
  },
  {
    "text": "so let me take the negative sign out over here. If you want to maximize this,",
    "start": "5492045",
    "end": "5498690"
  },
  {
    "text": "that is the same as minimizing the term inside, right, because of the negative sign.",
    "start": "5498690",
    "end": "5503940"
  },
  {
    "text": "And we can also ignore this 2 Sigma square because it's just a common positive scalar across all examples.",
    "start": "5503940",
    "end": "5510719"
  },
  {
    "text": "So argmax, respect to Theta, L of Theta is equal to argmin of Theta of the sum over i equals 1 to n,",
    "start": "5510720",
    "end": "5525270"
  },
  {
    "text": "x^i minus- sorry,",
    "start": "5525270",
    "end": "5529180"
  },
  {
    "text": "y^i minus x^i transpose Theta squared, right?",
    "start": "5532400",
    "end": "5540690"
  },
  {
    "text": "So it's not by the- the- uh, the reason why we cancel the two Sigma squared is",
    "start": "5540690",
    "end": "5546090"
  },
  {
    "text": "because we are only interested in the argmin and not the minimum value, but just the- the Theta value that gets us to the minimum, right?",
    "start": "5546090",
    "end": "5554460"
  },
  {
    "text": "And- and the Theta value is- is the same, whether we include the scaling constant or not.",
    "start": "5554460",
    "end": "5559510"
  },
  {
    "text": "And this is the probabilistic interpretation of- of uh, linear regression, [NOISE] probabilistic interpretation.",
    "start": "5560810",
    "end": "5573940"
  },
  {
    "text": "And here we saw basically the Gaussian distribution, and the main, uh,",
    "start": "5576270",
    "end": "5581920"
  },
  {
    "text": "takeaway from this is that whenever there is a Gaussian distribution involved,",
    "start": "5581920",
    "end": "5588295"
  },
  {
    "text": "there will always- that generally always corresponds to some kind of a squared error, right?",
    "start": "5588295",
    "end": "5594864"
  },
  {
    "text": "Because you take the log likelihood, the log will cancel- will- this is a log of some constant,",
    "start": "5594865",
    "end": "5600369"
  },
  {
    "text": "log in the exponent cancel, so maximizing the Gaussian likelihood is generally equivalent to minimizing the squared error of some term.",
    "start": "5600370",
    "end": "5607900"
  },
  {
    "text": "So that was, uh, linear regression. Any- any questions on the li- on linear regression?",
    "start": "5607900",
    "end": "5613120"
  },
  {
    "text": "[NOISE] All good. [NOISE] And then after, uh,",
    "start": "5613120",
    "end": "5622735"
  },
  {
    "text": "covering linear regression, we move on to the first classification algorithm,",
    "start": "5622735",
    "end": "5628344"
  },
  {
    "text": "binary classification algorithm, which is logistic regression.",
    "start": "5628345",
    "end": "5632720"
  },
  {
    "text": "So in logistic regression, we are given- [NOISE] logistic",
    "start": "5634380",
    "end": "5643540"
  },
  {
    "text": "regression.",
    "start": "5645600",
    "end": "5652540"
  },
  {
    "text": "Logistic regression y^i is now either 0 or 1.",
    "start": "5655290",
    "end": "5661645"
  },
  {
    "text": "Okay? And in order to solve logistic regression, we kind of follow the probabilistic interpretation",
    "start": "5661645",
    "end": "5669190"
  },
  {
    "text": "and do the same thing for logistic regression. In logistic regression, we assume that y^i is sampled",
    "start": "5669190",
    "end": "5677440"
  },
  {
    "text": "from a Bernoulli distribution, right?",
    "start": "5677440",
    "end": "5683020"
  },
  {
    "text": "Bernoulli distribution, and probability of",
    "start": "5683020",
    "end": "5689005"
  },
  {
    "text": "y^i equals 1 is given by",
    "start": "5689005",
    "end": "5695905"
  },
  {
    "text": "this 1 over 1 plus e to the minus Theta transpose x.",
    "start": "5695905",
    "end": "5703989"
  },
  {
    "text": "Okay? And initially, we- we kind of construct this 1 over 1plus,",
    "start": "5703990",
    "end": "5710435"
  },
  {
    "text": "uh, e to the minus, uh, uh, uh, function, you know, um, as- as, uh,",
    "start": "5710435",
    "end": "5717550"
  },
  {
    "text": "a good reasonable guess, which we later re-derive in GLMs, uh, as a natural consequence of assuming Bernoulli.",
    "start": "5717550",
    "end": "5724180"
  },
  {
    "text": "Uh, but for now, uh, let's just go ahead. Where the, uh, predicted y^i, uh, equals 1.",
    "start": "5724180",
    "end": "5732085"
  },
  {
    "text": "So this will be our prediction, and this gives us the,",
    "start": "5732085",
    "end": "5737140"
  },
  {
    "text": "uh, likelihood, uh, expression. So- so l of Theta is now equal to 1- uh,",
    "start": "5737140",
    "end": "5743514"
  },
  {
    "text": "log of the product of i equals 1 to n of the Bernoulli likelihood,",
    "start": "5743515",
    "end": "5750685"
  },
  {
    "text": "which is y^i- oh, sorry, y hat to the power y^i-",
    "start": "5750685",
    "end": "5756790"
  },
  {
    "text": "[NOISE] y hat i to the power y^i,",
    "start": "5756790",
    "end": "5767140"
  },
  {
    "text": "times one minus y hat i to the power 1 minus y^i,",
    "start": "5767140",
    "end": "5777370"
  },
  {
    "text": "where y hat i is this, okay?",
    "start": "5777370",
    "end": "5783235"
  },
  {
    "text": "And all of this is a function of Theta. And this allows us to write the- the objective of- of",
    "start": "5783235",
    "end": "5790090"
  },
  {
    "text": "logistic regression as- so log of the product is the sum of the logs i equals 1 to n,",
    "start": "5790090",
    "end": "5795804"
  },
  {
    "text": "y^i log y hat i plus 1 minus",
    "start": "5795805",
    "end": "5803515"
  },
  {
    "text": "y^i log 1 minus y hat i, right?",
    "start": "5803515",
    "end": "5815665"
  },
  {
    "text": "And for- in -in place of y hat i, include this as y^i here and here,",
    "start": "5815665",
    "end": "5824739"
  },
  {
    "text": "and to solve it, we use gradient ascent. There is no closed form solution for this, okay?",
    "start": "5824740",
    "end": "5831535"
  },
  {
    "text": "Run gradient ascent and when you converge with gradient ascent, the Theta value is basically the maximizer of this likelihood function, okay?",
    "start": "5831535",
    "end": "5840475"
  },
  {
    "text": "That was logistic regression. Any questions on that? Can you repeat the last part?",
    "start": "5840475",
    "end": "5846625"
  },
  {
    "text": "Can I repeat the last part? So, uh, there is no closed form solution for recovering Theta from this,",
    "start": "5846625",
    "end": "5853165"
  },
  {
    "text": "uh- from this likelihood expression. Instead, what we do is run gradient ascent, and run gradient ascent till the algorithm converges,",
    "start": "5853165",
    "end": "5861610"
  },
  {
    "text": "and when it converges the Theta value at the point of convergence, it's going to be the solution for maximizing",
    "start": "5861610",
    "end": "5869080"
  },
  {
    "text": "the log likelihood of Theta. There was another question. Yeah, actually, my question was- so",
    "start": "5869080",
    "end": "5876540"
  },
  {
    "text": "I'm assuming if some sort of those same value have a probability, and they branch at a actual value,",
    "start": "5876540",
    "end": "5883060"
  },
  {
    "text": "will you consider the algorithm? Uh, can you- can you, uh, describe that a little more? I don't think [OVERLAPPING] I quite understand.",
    "start": "5883060",
    "end": "5889764"
  },
  {
    "text": "I- I really confused so you could have the- total probability that y^i equals to 1 is just Phi,",
    "start": "5889765",
    "end": "5895255"
  },
  {
    "text": "because y^i is Bernoulli distributed. Yes, the probability that y^i equals 1 is just Phi. Yes.",
    "start": "5895255",
    "end": "5904945"
  },
  {
    "text": "But then you- so- But the probability that y^i equals 0 is 1 minus Phi. I agree.",
    "start": "5904945",
    "end": "5910230"
  },
  {
    "text": "Yeah. In your third- in the third line of your exposition, I- I- Third line is this one?",
    "start": "5910230",
    "end": "5915670"
  },
  {
    "text": "Yeah, so you wrote a probability y^i equal 1. [OVERLAPPING] My first question, should that be y hat i or is that like a-",
    "start": "5915670",
    "end": "5922975"
  },
  {
    "text": "So this is the probability that y- y- y^i equals 1. Should it be the probability that y hat i equals [inaudible] minus 1?",
    "start": "5922975",
    "end": "5928520"
  },
  {
    "text": "So this is just y hat, this will be y hat. Okay, then should you have a catch-all value saying that if y hat is",
    "start": "5928860",
    "end": "5935559"
  },
  {
    "text": "above that then y^i equal to 1  [inaudible]. I see. So- so- so the question is,",
    "start": "5935560",
    "end": "5941455"
  },
  {
    "text": "um, if I understood right. So here we are only talking about values in order to make a decision of what our predicted y^i is,",
    "start": "5941455",
    "end": "5949645"
  },
  {
    "text": "should there be a threshold to say if this is greater than whatever 0.5, then the, um, um,",
    "start": "5949645",
    "end": "5956260"
  },
  {
    "text": "then the prediction is- is- is one versus the other. And the- the, uh, answer to that is logistic regression. So that's a good question.",
    "start": "5956260",
    "end": "5963655"
  },
  {
    "text": "So logistic regression, even though we call it a classifier, it is actually just a probability machine.",
    "start": "5963655",
    "end": "5970645"
  },
  {
    "text": "It outputs probabilities. And the way we convert these probabilistic outputs into",
    "start": "5970645",
    "end": "5976570"
  },
  {
    "text": "decisions is using some kind of an additional threshold after the fact, right? So first we train a model to just output probabilities.",
    "start": "5976570",
    "end": "5984460"
  },
  {
    "text": "And then using, you know, um, um, um, um, basically we saw this in the- in the evaluation metrics lecture.",
    "start": "5984460",
    "end": "5991870"
  },
  {
    "text": "You know, you can choose different thresholds to optimize for different kinds of metrics.",
    "start": "5991870",
    "end": "5997420"
  },
  {
    "text": "So you can choose a threshold for maximizing your accuracy, your- maximizing your, you know,",
    "start": "5997420",
    "end": "6002429"
  },
  {
    "text": "precision or- or what have you, right? So that's- that's generally done after the fact of- of choosing the threshold, right?",
    "start": "6002430",
    "end": "6009360"
  },
  {
    "text": "But logistic regression by itself just gives you probabilities, okay? Next question.",
    "start": "6009360",
    "end": "6015840"
  },
  {
    "text": "[inaudible] assume that it exist",
    "start": "6015840",
    "end": "6020969"
  },
  {
    "text": "[inaudible] probability of y^i",
    "start": "6020970",
    "end": "6026160"
  },
  {
    "text": "is given by this and then we want to find a good theta to approximate the solution. That's correct. So what we're assuming is that the probability",
    "start": "6026160",
    "end": "6034980"
  },
  {
    "text": "of y^i given xi can be represented in this form. And that there is some Theta that gives us the right answer,",
    "start": "6034980",
    "end": "6042105"
  },
  {
    "text": "and we go about and- and, uh, try to recover- recover that Theta. And the- the important thing to note there is that it is an assumption.",
    "start": "6042105",
    "end": "6050145"
  },
  {
    "text": "We assume that probability of y^i equals 1 can be represented in this form and try to recover it.",
    "start": "6050145",
    "end": "6055995"
  },
  {
    "text": "And in one of the examples that we saw in- I think it was uh,",
    "start": "6055995",
    "end": "6061320"
  },
  {
    "text": "Homework 2, Question 1. Let me- let me [NOISE].",
    "start": "6061320",
    "end": "6069930"
  },
  {
    "text": "So in Homework 2, Question 1, we had this logistic regression stability problem, right?",
    "start": "6069930",
    "end": "6077475"
  },
  {
    "text": "Where you are given two datasets. On one dataset, logistic regression would converge, and on another dataset,",
    "start": "6077475",
    "end": "6083070"
  },
  {
    "text": "logistic regression would- would never converge. It would go on and on. In that example, [NOISE] right?",
    "start": "6083070",
    "end": "6090305"
  },
  {
    "text": "The data was perfectly separable, which means- [NOISE] which",
    "start": "6090305",
    "end": "6100170"
  },
  {
    "text": "means we could draw a line that perfectly separated the two- the two classes. And in- in this kind of a scenario,",
    "start": "6100170",
    "end": "6107445"
  },
  {
    "text": "the assumption that p of y equals 1,",
    "start": "6107445",
    "end": "6113114"
  },
  {
    "text": "equals 1 over 1 plus exponent minus Theta transpose x.",
    "start": "6113115",
    "end": "6118980"
  },
  {
    "text": "The assumption that p of y given, uh, 1. So this should be given x, right?",
    "start": "6118980",
    "end": "6125179"
  },
  {
    "text": "So we assume a conditioning, uh, over there as well. [NOISE] So they're corrected right over here.",
    "start": "6125180",
    "end": "6131030"
  },
  {
    "text": "[NOISE] This is p of y given 1 , given x.",
    "start": "6131030",
    "end": "6137730"
  },
  {
    "text": "[NOISE] So probability y equals 1 given x can be represented in this form.",
    "start": "6137730",
    "end": "6147075"
  },
  {
    "text": "In a way this assumption is not met here, right? Because if you tried to solve this, then the algorithm never converges and Theta just goes to infinity, right?",
    "start": "6147075",
    "end": "6156780"
  },
  {
    "text": "So this- this- this- this assumption that, uh, that the, uh, probabilities can be represented",
    "start": "6156780",
    "end": "6162510"
  },
  {
    "text": "from is an assumption which may or may not hold. And in case of the perfectly separable case,",
    "start": "6162510",
    "end": "6167745"
  },
  {
    "text": "this assumption does not hold. And in those cases, to handle such cases, we want to use regularization,",
    "start": "6167745",
    "end": "6174179"
  },
  {
    "text": "where regularization makes it kind of a well-defined problem and- and we'll come to- we'll review regularization again when we go uh,",
    "start": "6174180",
    "end": "6181600"
  },
  {
    "text": "uh, uh, um, um. Sir, one word before you carry on, I think, uh, so in the same question,",
    "start": "6181600",
    "end": "6188460"
  },
  {
    "text": "you're mentioning the- actually the method of regularization was to imagine that the two [inaudible] the data- it passes through some points.",
    "start": "6188460",
    "end": "6198540"
  },
  {
    "text": "And the points are so close, it doesn't- two-dimensional space, it looks like, you know, it may not be passing through- may not be separating perfectly,",
    "start": "6198540",
    "end": "6205095"
  },
  {
    "text": "but there's something about separating a hyper plane in a higher dimension, you know, in a higher dimension. So can you explain in which step of the algorithm the points are visualized by the,",
    "start": "6205095",
    "end": "6214635"
  },
  {
    "text": "uh, parameters as existing in two- So in the- in the, um, in the dataset that you have, uh,",
    "start": "6214635",
    "end": "6221579"
  },
  {
    "text": "that was given the- the mod- the dataset where the model does not converge, in- in the, uh,",
    "start": "6221580",
    "end": "6228165"
  },
  {
    "text": "you don't have to map it to a higher-dimensional space. The separating hyperplane can clearly separate them. Some of the points maybe so close that in the- in the graph,",
    "start": "6228165",
    "end": "6235545"
  },
  {
    "text": "they may look as though they are- they are, uh, not separated because in- in the plot,",
    "start": "6235545",
    "end": "6241935"
  },
  {
    "text": "each point is kind of represented by a small circle and the circle may cross the separating line,",
    "start": "6241935",
    "end": "6248130"
  },
  {
    "text": "and the line also has some thickness as- as- as a consequence of just plotting it.",
    "start": "6248130",
    "end": "6253199"
  },
  {
    "text": "But if you look at the- at the numerical values of each of the points,",
    "start": "6253200",
    "end": "6258240"
  },
  {
    "text": "they are perfectly separable. Yeah, so you don't have to take it to a higher dimensional- higher dimensional space for that example.",
    "start": "6258240",
    "end": "6265065"
  },
  {
    "text": "It's just that the- the, uh, the plotting involves, you know, thick lines and so it does not appear to be perfectly separated or they're too close by.",
    "start": "6265065",
    "end": "6273795"
  },
  {
    "text": "But if you inspect the numerical values, it's- it is perfectly separable. So that was, uh,",
    "start": "6273795",
    "end": "6280770"
  },
  {
    "text": "logistic regression, right. Yes, question.",
    "start": "6280770",
    "end": "6286710"
  },
  {
    "text": "[inaudible]",
    "start": "6286710",
    "end": "6314340"
  },
  {
    "text": "Yeah, good question. So well, so in- in that question, one of the- one of the, ah, ah, sub-questions was to recommend ways to fix this scenario.",
    "start": "6314340",
    "end": "6321960"
  },
  {
    "text": "And one of the proposed ways was to make the learning rate of,",
    "start": "6321960",
    "end": "6327195"
  },
  {
    "text": "ah, logistic regression decay over time at the rate of whatever 1 over t or t squared or whatever.",
    "start": "6327195",
    "end": "6332835"
  },
  {
    "text": "So in- in- in, ah, in that scenario, it is kind of important to distinguish between convergence in code versus,",
    "start": "6332835",
    "end": "6342659"
  },
  {
    "text": "you know, convergence mathematically, right? So if you were to decay the learning rate,",
    "start": "6342660",
    "end": "6348074"
  },
  {
    "text": "and if you just decay to 0, then obviously the code will, will stop iterating, right?",
    "start": "6348075",
    "end": "6354930"
  },
  {
    "text": "But the- the- the parameter value that you get is not necessarily the argmin or the two argmin.",
    "start": "6354930",
    "end": "6362055"
  },
  {
    "text": "Why not actually? I don't think I caught your phi of y given x explanation very well.",
    "start": "6362055",
    "end": "6367980"
  },
  {
    "text": "So, ah, wha- wha- what I, ah, mean by that is, um, so we define this l theta equals,",
    "start": "6367980",
    "end": "6375344"
  },
  {
    "text": "you know, some- some expression, right? And now in order to minimize this, we have this iterative algorithm where we say,",
    "start": "6375345",
    "end": "6383160"
  },
  {
    "text": "you know, repeat until- repeat. We have some condition, repeat,",
    "start": "6383160",
    "end": "6388559"
  },
  {
    "text": "you know, until some condition. And you do theta equals theta plus alpha times y_i minus h Theta of x_i times x_i.",
    "start": "6388560",
    "end": "6401864"
  },
  {
    "text": "Right? So we are- we are- we are, um, um, looping this. Now, if this is perfectly minimizable which means if",
    "start": "6401865",
    "end": "6409500"
  },
  {
    "text": "your loss function is well-defined and has a well-defined local minimum,",
    "start": "6409500",
    "end": "6417480"
  },
  {
    "text": "then this algorithm will eventually reach you know some- some, ah, ah,",
    "start": "6417480",
    "end": "6422565"
  },
  {
    "text": "nearby point here and Theta hat will be this- this nearby point of- of the- of the global minimum.",
    "start": "6422565",
    "end": "6429270"
  },
  {
    "text": "However, in- in the- in the problem that we had, so if this is theta,",
    "start": "6429270",
    "end": "6434400"
  },
  {
    "text": "and the last function actually looks like this. Right. It reaches the minimum at infinity.",
    "start": "6434400",
    "end": "6442530"
  },
  {
    "text": "Right. So now the question is, if we run gradient descent on this, the algorithm will keep,",
    "start": "6442530",
    "end": "6448500"
  },
  {
    "text": "you know, hopping over and over and over and over and over with each iteration, it keeps updating Thetas all the way to infinity.",
    "start": "6448500",
    "end": "6454860"
  },
  {
    "text": "Now the question is, what do we mean by convergence, right? By convergence, you know, the mathematical meaning of convergence means recover the true Theta.",
    "start": "6454860",
    "end": "6464460"
  },
  {
    "text": "And in this case there is no true finite Theta for it to recover. So it's not even something that can possibly converge.",
    "start": "6464460",
    "end": "6471614"
  },
  {
    "text": "Right. It just goes to infinity. Now, however, here, if we have a condition, you know,",
    "start": "6471615",
    "end": "6477960"
  },
  {
    "text": "some arbitrary condition which evaluates to false, right, this computational algorithm will break out of the loop.",
    "start": "6477960",
    "end": "6488415"
  },
  {
    "text": "Now, do we wanna call that convergence or do we wanna call, you know, this mathematical notion of convergence where",
    "start": "6488415",
    "end": "6495120"
  },
  {
    "text": "our estimate has- has gone arbitrary close to the true value.",
    "start": "6495120",
    "end": "6500200"
  },
  {
    "text": "Right. So there are these- these- you can- you can, um, there are these two different meanings of convergence.",
    "start": "6500690",
    "end": "6506910"
  },
  {
    "text": "One is, you know, does this computational algorithm stop,",
    "start": "6506910",
    "end": "6512219"
  },
  {
    "text": "versus ha- has our parameter estimate come sufficiently close to the true parameter, right.",
    "start": "6512220",
    "end": "6520530"
  },
  {
    "text": "There- there are two different- two different meanings. Right. So by adding regularization,",
    "start": "6520530",
    "end": "6527429"
  },
  {
    "text": "we convert this ill-framed problem into a well-framed problem, right.",
    "start": "6527430",
    "end": "6533615"
  },
  {
    "text": "So regularization takes us from here to here.",
    "start": "6533615",
    "end": "6539160"
  },
  {
    "text": "Right. So that was logistic regression.",
    "start": "6541790",
    "end": "6548260"
  },
  {
    "text": "Next, we studied a second algorithm for optimization called Newton's method.",
    "start": "6549710",
    "end": "6556710"
  },
  {
    "text": "[NOISE] Right.",
    "start": "6556710",
    "end": "6562860"
  },
  {
    "text": "So Newton's method is a root finding method where given some function f,",
    "start": "6562860",
    "end": "6570315"
  },
  {
    "text": "ah, let's- let's, ah, call this x. Given some function f and some random initialization,",
    "start": "6570315",
    "end": "6582405"
  },
  {
    "text": "right, Newton's method takes us to the nearest root.",
    "start": "6582405",
    "end": "6588570"
  },
  {
    "text": "What do we mean by root? Root is an input to f such that f of x equals 0.",
    "start": "6588570",
    "end": "6595290"
  },
  {
    "text": "Right. So Newton's method is a way where with some random initialization,",
    "start": "6595290",
    "end": "6600705"
  },
  {
    "text": "Newton's method will take us to the nearest root of a function. Right. And we use Newton's method for solving our cost function by feeding the gradient",
    "start": "6600705",
    "end": "6614760"
  },
  {
    "text": "of our function as- as the input to Newton's method as f. So we set f is equal to L prime.",
    "start": "6614760",
    "end": "6625200"
  },
  {
    "text": "Right. So the gradient function is used as the function whose root we're trying to,",
    "start": "6625200",
    "end": "6630510"
  },
  {
    "text": "ah, calculate using Newton's method. And Newton's method basically, ah, gives us the update rule that Theta equals Theta plus 1 over,",
    "start": "6630510",
    "end": "6640710"
  },
  {
    "text": "um, in this case, um, l double prime Theta times l of Theta.",
    "start": "6640710",
    "end": "6648540"
  },
  {
    "text": "If, uh, Theta is scalar, and in case of the, ah, ah,",
    "start": "6648540",
    "end": "6655920"
  },
  {
    "text": "vector-valued inputs, that is the extension of Newton's method called Newton-Raphson method.",
    "start": "6655920",
    "end": "6662170"
  },
  {
    "text": "Newton-Raphson where the update rule is Theta equals Theta plus 1",
    "start": "6664460",
    "end": "6670560"
  },
  {
    "text": "or H inverse of Theta times gradient of Theta,",
    "start": "6670560",
    "end": "6680415"
  },
  {
    "text": "where H is the Hessian. H of Theta equals H is the Hessian and the- this is the update rule.",
    "start": "6680415",
    "end": "6694030"
  },
  {
    "text": "So a few things to keep in mind is that Newton's method is not a cost minimizing method.",
    "start": "6694280",
    "end": "6700559"
  },
  {
    "text": "It is not a cost maximizing method. It's just a root finding method, which means,",
    "start": "6700560",
    "end": "6705570"
  },
  {
    "text": "no matter what kind of a function you feed it, you know, it's plug and play. You don't ask Newton's method to maximize it or minimize it, it's doing neither.",
    "start": "6705570",
    "end": "6712500"
  },
  {
    "text": "It's just finding the nearest root. Now, if the function- if l that you're using in- in, um, sorry.",
    "start": "6712500",
    "end": "6721275"
  },
  {
    "text": "If- if l that you are, ah, ah, using in Newton's method is a concave function,",
    "start": "6721275",
    "end": "6728100"
  },
  {
    "text": "sorry, a convex function, right. So the- if this is l,",
    "start": "6728100",
    "end": "6735435"
  },
  {
    "text": "then l prime of Theta is going to be- so- so ah,",
    "start": "6735435",
    "end": "6741975"
  },
  {
    "text": "the gradient starts out to be negative here, it becomes 0 over here,",
    "start": "6741975",
    "end": "6747449"
  },
  {
    "text": "and it becomes positive later. So the grid- the gradient function is an increasing function.",
    "start": "6747450",
    "end": "6753285"
  },
  {
    "text": "Right. So this is 0 and this is l prime Theta, so it's an increasing function.",
    "start": "6753285",
    "end": "6758790"
  },
  {
    "text": "Right. Similarly, if your, um, ah, l Theta is concave, right,",
    "start": "6758790",
    "end": "6765705"
  },
  {
    "text": "then l prime of Theta is a decreasing function.",
    "start": "6765705",
    "end": "6771045"
  },
  {
    "text": "Right. And Newton's method will just recover the point where the gradient is 0.",
    "start": "6771045",
    "end": "6778400"
  },
  {
    "text": "Right. Ah, because that's- that's what it's- it's- it's doing root finding. It's not- it is not checking whether at",
    "start": "6778400",
    "end": "6785030"
  },
  {
    "text": "this point the gradient is decreasing or increasing. It doesn't care. It just gets you to the nearest root.",
    "start": "6785030",
    "end": "6790235"
  },
  {
    "text": "Which means if you feed in a convex function or a concave function, it will automatically recover the corresponding optimum point or the stationary point.",
    "start": "6790235",
    "end": "6801250"
  },
  {
    "text": "Which also means, if you feed a function that is, you know, kind of weird shaped where it does not have a well-defined local maxima or minima,",
    "start": "6801250",
    "end": "6810855"
  },
  {
    "text": "has multiple local maxima, it just takes you to the nearest stationary point.",
    "start": "6810855",
    "end": "6816269"
  },
  {
    "text": "What that means is, if you start over here, right. If- if- if, ah, your starting point is here,",
    "start": "6816270",
    "end": "6822960"
  },
  {
    "text": "then Newton's method will maximize and take you to the nearest stationary point. If you start over here, ah, or ah,",
    "start": "6822960",
    "end": "6830385"
  },
  {
    "text": "if you start over here, then Newton's method will take you- will minimize it and take you to the nearest stationary point.",
    "start": "6830385",
    "end": "6835710"
  },
  {
    "text": "Depending on the initialization, it was either a local maximization or a local minimization.",
    "start": "6835710",
    "end": "6840990"
  },
  {
    "text": "Right. Newton's method only takes you to the nearest stationary point. Yes, question. [inaudible] you can actually just find h of theta, right?",
    "start": "6840990",
    "end": "6854640"
  },
  {
    "text": "So generally you don't want to use- even use Newton's method in these, ah, unless you know that the- the function is convex or concave.",
    "start": "6854640",
    "end": "6861030"
  },
  {
    "text": "[inaudible] Well, so generally you know that by function,",
    "start": "6861030",
    "end": "6866985"
  },
  {
    "text": "you- by looking at the functional form, you can tell whether it's convex or concave. Like if you can show that the Hessian is positive- positive definite,",
    "start": "6866985",
    "end": "6873855"
  },
  {
    "text": "then you know it's a concave function or a convex function, and you know Newton's method is a good idea to use in those cases.",
    "start": "6873855",
    "end": "6879075"
  },
  {
    "text": "If you're not sure, like for example, in a- in a neural network, you would never use Newton's method on a neural network because it might- it might even be,",
    "start": "6879075",
    "end": "6885750"
  },
  {
    "text": "you know, maximizing to a local minimum- local maximum. [inaudible]",
    "start": "6885750",
    "end": "6897540"
  },
  {
    "text": "Yeah. If it is- if it is, ah, convex, then the Hessian positive definite if it's negative. All right. So it looks like we have run over time. Apologies for that.",
    "start": "6897540",
    "end": "6905430"
  },
  {
    "text": "We will continue our- our, ah, review in the- in the, ah, next lecture on Wednesday, and that will be the,",
    "start": "6905430",
    "end": "6911460"
  },
  {
    "text": "ah, final lecture. All right. Thanks everyone.",
    "start": "6911460",
    "end": "6914590"
  }
]
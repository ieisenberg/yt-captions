[
  {
    "start": "0",
    "end": "5550"
  },
  {
    "text": "So the plan for\ntoday as I mentioned in the previous\nlecture, we're going to try to start with the basics.",
    "start": "5550",
    "end": "11110"
  },
  {
    "text": "And so this means\nthat today we'll be talking about\nmethods that were",
    "start": "11110",
    "end": "16199"
  },
  {
    "text": "starting to be developed in\nthe ancient times of the 1990s. And then starting\nI think next week,",
    "start": "16200",
    "end": "23970"
  },
  {
    "text": "we'll get into more newer stuff. That said, even\ntoday, we'll start",
    "start": "23970",
    "end": "29574"
  },
  {
    "text": "to talk about a case study of\na real world problem that's quite relevant today, and is\nfrom a very modern research",
    "start": "29575",
    "end": "36030"
  },
  {
    "text": "paper. And by the end of the\nlecture, the goals is to really try to convey\nwhat multi-task learning is,",
    "start": "36030",
    "end": "43260"
  },
  {
    "text": "and what the key\ndesign choices are when trying to build these\nmultitask systems in practice. ",
    "start": "43260",
    "end": "50770"
  },
  {
    "text": "Awesome. So we'll start off\nwith some notation. So we'll start\noff with something like a neural network.",
    "start": "50770",
    "end": "56552"
  },
  {
    "text": "It could be a convolutional\nnetwork like the one shown here or some other neural network. And we'll denote the input as\nx, and the label or output is y.",
    "start": "56552",
    "end": "69000"
  },
  {
    "text": "For example, our input\nmight be an image like an image of a tiger\nhere, and the label",
    "start": "69000",
    "end": "74040"
  },
  {
    "text": "might be a classification\nof that tiger, it might be an image\nclassification problem, or maybe something\nmore interesting",
    "start": "74040",
    "end": "79620"
  },
  {
    "text": "like trying to\nclassify what to do if you see something like this.",
    "start": "79620",
    "end": "84630"
  },
  {
    "text": "And alternatively,\ninstead of being an image, it could be something\nlike the title of a paper. In this case, you\nprobably wouldn't",
    "start": "84630",
    "end": "90570"
  },
  {
    "text": "use a convolutional network,\nyou would probably use something like a transformer\nif you're trendy,",
    "start": "90570",
    "end": "95610"
  },
  {
    "text": "or if you're a bit\nolder, maybe an LSDM. And the label could be something\nlike the length of the paper.",
    "start": "95610",
    "end": "102220"
  },
  {
    "text": "And so in this case, if\nit was linked to the paper this might be more of\na regression problem rather than a discrete\nclassification problem.",
    "start": "102220",
    "end": "109065"
  },
  {
    "text": " Now, we'll refer\nto the parameters of the neural network\ntypically with theta,",
    "start": "109065",
    "end": "117850"
  },
  {
    "text": "and so this will correspond\nto all of the parameters of that neural network. You can think of it as a\nvector that basically flattens",
    "start": "117850",
    "end": "125340"
  },
  {
    "text": "each of these weight\nmatrices and upends them into a single very large vector. This may have millions\nof values in this vector.",
    "start": "125340",
    "end": "136020"
  },
  {
    "text": "And we can then refer to\nthe function represented by this neural network\nas f, which will give us",
    "start": "136020",
    "end": "141900"
  },
  {
    "text": "a distribution over y given the\ninput x parameterized by theta.",
    "start": "141900",
    "end": "147362"
  },
  {
    "text": "So this should follow\nfairly standard notation that you may have seen before.",
    "start": "147363",
    "end": "152560"
  },
  {
    "text": "Now in single-task\nsupervised learning, we will be given some\nform of data set,",
    "start": "152560",
    "end": "158430"
  },
  {
    "text": "which has input output pairs. So a number of\nexamples of images like the tiger and labels\nlike the options on the right.",
    "start": "158430",
    "end": "168629"
  },
  {
    "text": "And then we will\ndefine a loss function that tells us how good is that\nmodel at performing that task.",
    "start": "168630",
    "end": "176490"
  },
  {
    "text": "And our goal will be to\nfind the parameters that minimize that loss function. So try to find the\nparameter setting of one",
    "start": "176490",
    "end": "182730"
  },
  {
    "text": "of these neural networks\nsuch that we do well on a classification\nproblem for example. ",
    "start": "182730",
    "end": "189940"
  },
  {
    "text": "And so a typical form\nof this loss function might be something like\nnegative log likelihood.",
    "start": "189940",
    "end": "195150"
  },
  {
    "text": "This would look\nsomething like this, where we're measuring the\nlikelihood that f assigns to a given label given x.",
    "start": "195150",
    "end": "201870"
  },
  {
    "text": "And then negating that because\ntypically loss functions are things that we minimize. And then trying to minimize\nthe negative probability",
    "start": "201870",
    "end": "209880"
  },
  {
    "text": "of the label given the input.  And this kind of log\nlikelihood loss, this",
    "start": "209880",
    "end": "216040"
  },
  {
    "text": "is equivalent to something\nlike a cross-entropy loss or a mean squared\nerror loss that you may have seen in other\nmachine learning courses.",
    "start": "216040",
    "end": "223555"
  },
  {
    "text": " So that should mostly\nbe review for folks.",
    "start": "223555",
    "end": "230910"
  },
  {
    "text": "Now, how do we go from\nsingle-task learning to multi-task learning?",
    "start": "230910",
    "end": "235950"
  },
  {
    "text": "For that, we need to figure\nout actually, what is a task? What does it mean to be a task? We defined what a task is\nin the previous lecture,",
    "start": "235950",
    "end": "243209"
  },
  {
    "text": "but we're going to cover a\ntask more formally this time. And in particular in the\ncontext of this course,",
    "start": "243210",
    "end": "249490"
  },
  {
    "text": "we'll think about\na task as a set of three things, a distribution\nover x, a distribution over y",
    "start": "249490",
    "end": "257519"
  },
  {
    "text": "given x, and a loss function. And so you can think of these\nas the distribution that",
    "start": "257519",
    "end": "263190"
  },
  {
    "text": "generates the data. And the reason why that\nwe want to define it something like this\nis that we want",
    "start": "263190",
    "end": "269143"
  },
  {
    "text": "to be able to say whether or\nnot the network is doing well at a task. And doing well at a\ntask is a little bit",
    "start": "269143",
    "end": "274710"
  },
  {
    "text": "different than doing\nwell on a data set. And in particular,\nyou could have",
    "start": "274710",
    "end": "279810"
  },
  {
    "text": "something that does really,\nreally well in a training data set, but doesn't\nactually generalize to other examples for that task.",
    "start": "279810",
    "end": "285509"
  },
  {
    "text": "And therefore by defining a\ntask as the data generating distributions, and\nthe corresponding loss function for that\ntask, we can then",
    "start": "285510",
    "end": "294811"
  },
  {
    "text": "capture notions of\nhow well it's actually doing on that task in general. So we can have\ncorresponding data sets",
    "start": "294812",
    "end": "300870"
  },
  {
    "text": "that are sampled\nfrom these underlying distributions like the\ntraining set and the test set.",
    "start": "300870",
    "end": "307270"
  },
  {
    "text": "And note that here I'm using\ni to like index into the task. So for task i, it has these\ntwo distributions and this loss",
    "start": "307270",
    "end": "313660"
  },
  {
    "text": "function, and it has data\nsets that are sampled from these distributions.",
    "start": "313660",
    "end": "319720"
  },
  {
    "text": "In practice, you\nwon't have any sort of access to these ground truth\ndata generating distributions.",
    "start": "319720",
    "end": "325180"
  },
  {
    "text": "You will generally\nonly have access to the corresponding data sets. ",
    "start": "325180",
    "end": "332620"
  },
  {
    "text": "And then also in\nthe future slides, I'll generally use di\nas shorthand for di",
    "start": "332620",
    "end": "338229"
  },
  {
    "text": "train just because typically we\nwill refer to the training data set a lot, and it can be\nconvenient to drop off the tr.",
    "start": "338230",
    "end": "344845"
  },
  {
    "text": " OK. So that is how\nwe'll define a task.",
    "start": "344845",
    "end": "352590"
  },
  {
    "text": "And now let's look\nat some examples of different multi-task\nlearning problems. So generally, a multi-task\nlearning problem",
    "start": "352590",
    "end": "359699"
  },
  {
    "text": "is one where our goal isn't\njust to solve one task, but to solve a set of tasks.",
    "start": "359700",
    "end": "366120"
  },
  {
    "text": "And the tasks could\nvary in different ways. So in something like\nmulti-task classification,",
    "start": "366120",
    "end": "372323"
  },
  {
    "text": "the loss function\nwill probably be the same across all the tasks. It will probably just be\nthe cross-entropy loss.",
    "start": "372323",
    "end": "378190"
  },
  {
    "text": "And for example, this\ncould be something where we want to be able\nto recognize handwriting in different languages.",
    "start": "378190",
    "end": "383289"
  },
  {
    "text": "So each language will\ncorrespond to a different task. And you could have a\ndata set that looks like.",
    "start": "383290",
    "end": "388680"
  },
  {
    "text": "This is actually the\nOmni glide data set, and you have different alphabets\nor different languages.",
    "start": "388680",
    "end": "395680"
  },
  {
    "text": "And so in this\ncase, you're going to have a different p of x\ndistribution, a different p of y given x distribution\nbecause the characters",
    "start": "395680",
    "end": "403183"
  },
  {
    "text": "themselves will look\ndifferent, and also the label given\nthose characters will be different for\ndifferent languages,",
    "start": "403183",
    "end": "408250"
  },
  {
    "text": "but the underlying\nloss function will be the same because it's all\nstill a classification problem. ",
    "start": "408250",
    "end": "416410"
  },
  {
    "text": "As another example of this kind\nof multi-task classification problem, you could also have\na personalized spam filter",
    "start": "416410",
    "end": "421539"
  },
  {
    "text": "where different tasks\ncorrespond to different people. And different\npeople will receive different kinds of spam.",
    "start": "421540",
    "end": "426879"
  },
  {
    "text": "And they will also have\ndifferent preferences for what is spam and what's not spam. And so it will also in this case\nhave a different distribution",
    "start": "426880",
    "end": "434169"
  },
  {
    "text": "over x, and a different\ndistribution over y given x, but yet again the\nsame loss function.",
    "start": "434170",
    "end": "441370"
  },
  {
    "text": "So that's multi-task\nclassification. We could also\nconsider a scenario where both p of x\nand the loss function",
    "start": "441370",
    "end": "449490"
  },
  {
    "text": "are the same across these tasks,\nand the only thing that differs is y given x.",
    "start": "449490",
    "end": "455070"
  },
  {
    "text": "In a case like this, you\ncould think of face attribute recognition as an\nexample of this where one task is\nmaybe to detect",
    "start": "455070",
    "end": "461580"
  },
  {
    "text": "if someone has black\nhair or brown hair or blond hair or white hair. And a different task is to\npredict their eye color.",
    "start": "461580",
    "end": "468720"
  },
  {
    "text": "In this case, all of\nthe images are the same, you just have different\ndistributions over labels.",
    "start": "468720",
    "end": "474120"
  },
  {
    "text": "Yeah? Would be imaging task qualify\nfor multi-label classes",
    "start": "474120",
    "end": "480672"
  },
  {
    "text": "base on the different\nnormal distribution or it's not possible? So the question was, can\nimage not be considered",
    "start": "480672",
    "end": "488180"
  },
  {
    "text": "multi-label learning? And I guess the thing\nthat really differentiates",
    "start": "488180",
    "end": "493455"
  },
  {
    "text": "multi-label learning\nhere and something like image classification is\nat least the way that image",
    "start": "493455",
    "end": "498620"
  },
  {
    "text": "classification is framed. There's only one\nlabel that is correct.",
    "start": "498620",
    "end": "504482"
  },
  {
    "text": "And the thing that's\ndifferent here is that you actually have\na different set of labels.",
    "start": "504482",
    "end": "509840"
  },
  {
    "text": "And so for example, someone\ncan have both brown hair and brown eyes or they can have\nblonde hair and brown eyes,",
    "start": "509840",
    "end": "517130"
  },
  {
    "text": "for example. And so you actually\nhave different sets of labels itself. And that's like the key\ndifferentiating factor.",
    "start": "517130",
    "end": "524185"
  },
  {
    "text": "And so in general,\nit's something like image classification would\nbe considered a single task problem.",
    "start": "524185",
    "end": "529340"
  },
  {
    "text": "That said, you can\nalso frame things like image net as\nmulti-label problems because oftentimes\nthere are actually",
    "start": "529340",
    "end": "534500"
  },
  {
    "text": "more than one thing in an\nimage, and you may actually want to classify all the things\nin the image rather than just",
    "start": "534500",
    "end": "539510"
  },
  {
    "text": "one thing.  Another example of\nmulti-label learning",
    "start": "539510",
    "end": "545760"
  },
  {
    "text": "is something like\nscene understanding where you have images of\nlots of different 3D scenes.",
    "start": "545760",
    "end": "552340"
  },
  {
    "text": "And one task is to\npredict the depth, one task is to predict\nkey points in the image,",
    "start": "552340",
    "end": "557360"
  },
  {
    "text": "and another task is\nto predict the surface normals in that scene. And so this is,\nagain, an example",
    "start": "557360",
    "end": "562620"
  },
  {
    "text": "where actually all the images\nin the data set are the same. The only thing that's different\nis the different labels.",
    "start": "562620",
    "end": "567720"
  },
  {
    "text": " So these are a\ncouple instantiation",
    "start": "567720",
    "end": "573589"
  },
  {
    "text": "of multi-task learning problems. There's also scenarios\nwhere the loss function might vary as well.",
    "start": "573590",
    "end": "579782"
  },
  {
    "text": "So in both of these\nexamples, these are settings where the loss\nfunction isn't changing. But you could also\nhave scenarios",
    "start": "579782",
    "end": "585350"
  },
  {
    "text": "where, for example, some of\nyour labels are continuous and some of your\nlabels are discrete. And you use a mean\nsquared error loss",
    "start": "585350",
    "end": "591560"
  },
  {
    "text": "function for the continuous and\na cross-entropy loss function for the discrete labels, or\nyou might have multiple metrics",
    "start": "591560",
    "end": "597620"
  },
  {
    "text": "that you care\nabout, and you want to optimize those\nobjectives simultaneously.",
    "start": "597620",
    "end": "604580"
  },
  {
    "text": "Cool. So I'll pause here. Is there any\nquestions on the setup before we get into\nactually solving",
    "start": "604580",
    "end": "611737"
  },
  {
    "text": "these multi-task problems? Yeah? So from last time,\nyou said the tasks",
    "start": "611737",
    "end": "616790"
  },
  {
    "text": "should share some structure. So does structure\nmean like they should share either p of x or p of\ny to the next part, the loss",
    "start": "616790",
    "end": "624980"
  },
  {
    "text": "function? Like if they are\ndifferent, that means they don't share any solution?",
    "start": "624980",
    "end": "630400"
  },
  {
    "text": "Yeah. That's a great question. So the question\nwas, last lecture, we were talking about\nhow the task should",
    "start": "630400",
    "end": "636140"
  },
  {
    "text": "share some structure. Does that mean that they\nshould share the loss function or share one of\nthese three things?",
    "start": "636140",
    "end": "641899"
  },
  {
    "text": "And what I meant by a\nstructure in that first lecture is something a little\nbit more abstract.",
    "start": "641900",
    "end": "648660"
  },
  {
    "text": "So these are three\nvery concrete things. And you can actually have\ntasks that differ in all three of these things, but still\nhave a lot of common structure.",
    "start": "648660",
    "end": "658190"
  },
  {
    "text": "And so I guess structure\nis something that's a little bit more abstract. We can think of--",
    "start": "658190",
    "end": "663410"
  },
  {
    "text": "we'll come back to\na little bit more to what structure is when we\nget to some of the Bayesian perspective on it.",
    "start": "663410",
    "end": "669260"
  },
  {
    "text": "But I guess as one example,\nyou could imagine something like the per language\nhandwriting recognition.",
    "start": "669260",
    "end": "677220"
  },
  {
    "text": "These tasks have a lot of\nshared structure intuitively in the sense that\nrecognizing characters",
    "start": "677220",
    "end": "682880"
  },
  {
    "text": "is implicitly about recognizing\nthe shape of the handwriting.",
    "start": "682880",
    "end": "688043"
  },
  {
    "text": "But you could also have\na version of this that has different loss functions. Because maybe in one case\none of your loss functions",
    "start": "688043",
    "end": "695210"
  },
  {
    "text": "is more continuous because\nmaybe some of the digits are-- some of the characters\nare actually",
    "start": "695210",
    "end": "700310"
  },
  {
    "text": "like numerical values\nrather than characters. And something like\nthat, you may actually have different loss\nfunctions while still having",
    "start": "700310",
    "end": "707230"
  },
  {
    "text": "a lot of shared structure. ",
    "start": "707230",
    "end": "714950"
  },
  {
    "text": "Cool. So now let's get into actually\nlearning networks that solve",
    "start": "714950",
    "end": "720170"
  },
  {
    "text": "multi-task learning problems. So the first thing\nthat we generally need to do in multi-task\nlearning problems",
    "start": "720170",
    "end": "726980"
  },
  {
    "text": "is to tell the neural\nnetwork what the task is. And we'll do this with what I'll\ncall a task descriptor, which",
    "start": "726980",
    "end": "734720"
  },
  {
    "text": "we'll denote as zi. And we'll pass this into the\nnetwork in some way or another.",
    "start": "734720",
    "end": "741570"
  },
  {
    "text": "And so the function\nwill no longer be modeling y given\nx, but actually modeling y given x comma zi.",
    "start": "741570",
    "end": "750430"
  },
  {
    "text": "And so let's kind\nof actually better understand what this\ntask descriptor might be.",
    "start": "750430",
    "end": "755649"
  },
  {
    "text": "So say that you're a very\ndiligent grad student, and you were assigned a\nbunch of papers to review,",
    "start": "755650",
    "end": "762370"
  },
  {
    "text": "and you want to understand\nhow long it's going to take you to review these papers. So you maybe one\nof your tasks might be to take the\ntitle of the paper",
    "start": "762370",
    "end": "768695"
  },
  {
    "text": "and predict the\nlength of the paper. The second task\nis maybe you want",
    "start": "768695",
    "end": "773902"
  },
  {
    "text": "to get an initial summary of\nthe paper before reviewing it. And so you the second task is to\npredict a summary of the paper.",
    "start": "773902",
    "end": "780240"
  },
  {
    "text": "And maybe the third\ntask is you're getting maybe a\nlittle bit too lazy, and you just want it to write\nthe paper review for you.",
    "start": "780240",
    "end": "786220"
  },
  {
    "text": "So we have three tasks here. And the task descriptor,\nin this case, could be a few different things.",
    "start": "786220",
    "end": "792542"
  },
  {
    "text": "The first thing is it\ncould just be a one hot encoding of the task index. And in this case,\nwhat this means",
    "start": "792542",
    "end": "799050"
  },
  {
    "text": "is that we just have\na one hot vector. A one hot vector\nis just something that looks like\nthis, where we're",
    "start": "799050",
    "end": "805110"
  },
  {
    "text": "encoding an integer\nin vector form where, for example, the integer\n1 will be denoted with a 1",
    "start": "805110",
    "end": "814110"
  },
  {
    "text": "in the first position\nand 0 and the other two. The integer 2 will\nbe denoted with a 1",
    "start": "814110",
    "end": "819840"
  },
  {
    "text": "in the second position. And for the third task,\nthe task descriptor would be something like this.",
    "start": "819840",
    "end": "826570"
  },
  {
    "text": "So this would be an example-- the simplest possible\nway that we could tell the network what the task is. So this would be telling\nit that the task is",
    "start": "826570",
    "end": "832740"
  },
  {
    "text": "the first one, the second\none, and the third one. But we can also do something\na little bit more creative.",
    "start": "832740",
    "end": "838630"
  },
  {
    "text": "So we could, for example,\ngive it a language description of what we want it to do. So we could tell it,\ngive me a summary,",
    "start": "838630",
    "end": "844990"
  },
  {
    "text": "tell me the length of the\npaper, or give me a review. And so z could actually be\na natural language string",
    "start": "844990",
    "end": "851230"
  },
  {
    "text": "of what the task is as well. So some other\nexamples, it really",
    "start": "851230",
    "end": "857260"
  },
  {
    "text": "could just be whatever metadata\nyou have about the tasks. So it could be--",
    "start": "857260",
    "end": "862805"
  },
  {
    "text": "not really in this example. But if you have an example\nwhere different tasks are different people,\nthey can correspond to different attributes\nof those users.",
    "start": "862805",
    "end": "869920"
  },
  {
    "text": "If you have an example\nlike this one where you have some sort of\nnatural description of what",
    "start": "869920",
    "end": "875050"
  },
  {
    "text": "the task is, and you\ncould condition on that. You may also have\nsome domains where",
    "start": "875050",
    "end": "880150"
  },
  {
    "text": "you have a more formal\nspecification of what the task is, and\nyou could also try to pass that into the network\nto tell it what the task is.",
    "start": "880150",
    "end": "886240"
  },
  {
    "text": " Cool. So now that we've defined--",
    "start": "886240",
    "end": "893510"
  },
  {
    "text": "now that we've told the\nnetwork what the task is, we can also formulate\nthe objective.",
    "start": "893510",
    "end": "898820"
  },
  {
    "text": "So the basic way to formulate\nthe objective is actually what we covered in\nthe previous lecture",
    "start": "898820",
    "end": "904790"
  },
  {
    "text": "is we just sum up\nthe loss functions for each of the tasks. So Li here is computing the\nloss function of the network",
    "start": "904790",
    "end": "911899"
  },
  {
    "text": "on the training data\nset for that task. Then we'll sum up over all\nof the t tasks that we have,",
    "start": "911900",
    "end": "918260"
  },
  {
    "text": "and try to minimize\nthe loss function-- minimize the parameters\nof our neural network",
    "start": "918260",
    "end": "925190"
  },
  {
    "text": "over the sum of loss functions. Yeah? So the task descriptor\nthat you're mentioning, is that very much the same\nas completing the model,",
    "start": "925190",
    "end": "933086"
  },
  {
    "text": "like the recent work\nthat's been done? Yeah. So you can think of the task\ndescriptor as a form of prompt.",
    "start": "933086",
    "end": "938692"
  },
  {
    "text": "You typically wouldn't\nthink of something like this as a prompt. But yeah, it basically can be a\nprompt or it could be something",
    "start": "938692",
    "end": "945259"
  },
  {
    "text": "a little bit more basic. Yeah? It's another part\nof the di you say?",
    "start": "945260",
    "end": "952800"
  },
  {
    "text": "Obviously, you say di are\nsame across all the task.",
    "start": "952800",
    "end": "957850"
  },
  {
    "text": "So di is a set of xy pairs. And so what exactly\nwere you asking?",
    "start": "957850",
    "end": "965190"
  },
  {
    "text": "I mean, the di, if they\nprocess more all the same across all the task?",
    "start": "965190",
    "end": "970410"
  },
  {
    "text": "So you'll have\ndifferent data sets for different tasks in general. So as we talked about\nbefore, each task",
    "start": "970410",
    "end": "978480"
  },
  {
    "text": "will be defined by its own\ndata generating distribution. And then the training data\nset is drawn from that data",
    "start": "978480",
    "end": "984390"
  },
  {
    "text": "generating distribution. You may have cases where p of\nx is the same across tasks.",
    "start": "984390",
    "end": "989460"
  },
  {
    "text": "And so in that case, all\nof the x's in your data set may be identical. But then even in\nthose cases, the y's",
    "start": "989460",
    "end": "996180"
  },
  {
    "text": "will be different\nfor different tasks. And in general, these\ntraining data sets will be different across tasks.",
    "start": "996180",
    "end": "1003019"
  },
  {
    "text": "Does that answer your question? Since just now, you say\nthat the multi-task has--",
    "start": "1003020",
    "end": "1012260"
  },
  {
    "text": "look I said, across\nall the task, but--",
    "start": "1012260",
    "end": "1017720"
  },
  {
    "text": "You're asking if the\ndata set is the same across all the tasks in a\nmulti-task learning setting? Say that based on\nprevious thoughts,",
    "start": "1017720",
    "end": "1024109"
  },
  {
    "text": "you mention up all these. So I mentioned here that, for\nexample, the x-- the images",
    "start": "1024109",
    "end": "1030260"
  },
  {
    "text": "might all be the\nsame across tasks. So in this example in\nscene understanding,",
    "start": "1030260",
    "end": "1035473"
  },
  {
    "text": "the images will\nall be potentially identical across tasks, but\nthe labels will be different. So the labels for the depth\ntask correspond to the depth",
    "start": "1035473",
    "end": "1043339"
  },
  {
    "text": "annotations. The labels for the normal\ntask correspond to something like this, and so forth. Yeah?",
    "start": "1043339",
    "end": "1049340"
  },
  {
    "text": "You mentioned a task descriptor. There are often\ndata sets where you",
    "start": "1049340",
    "end": "1054890"
  },
  {
    "text": "don't get the task description. What happens then? Yeah. So you might have a\ndata set where you",
    "start": "1054890",
    "end": "1060860"
  },
  {
    "text": "don't have the task descriptor. In that case, you can just go\nwith the basic one hot encoding",
    "start": "1060860",
    "end": "1066230"
  },
  {
    "text": "assuming that you at least have\nsome sort of differentiation between the tasks. It's also possible\nthat in some cases,",
    "start": "1066230",
    "end": "1072792"
  },
  {
    "text": "you might be able to tell\nwhat the task is just from the input. If p of x is different\nacross tasks,",
    "start": "1072792",
    "end": "1081600"
  },
  {
    "text": "you might just be able to\ntell without a form of task descriptor. But in general in\nmulti-task learning,",
    "start": "1081600",
    "end": "1087900"
  },
  {
    "text": "we're going to assume that we\nat least have some separate data sets for each task.",
    "start": "1087900",
    "end": "1093640"
  },
  {
    "text": "Yeah? Where does the task\ndescriptor insert for like parts of the network? Is it with the original x or\nis it pass on or something?",
    "start": "1093640",
    "end": "1101600"
  },
  {
    "text": "Yeah. So we'll talk about that next. Cool. So I think that we can just\ntransition into the next part.",
    "start": "1101600",
    "end": "1109250"
  },
  {
    "text": "So this is the basic setup,\nbut there's still a lot of design choices to make here.",
    "start": "1109250",
    "end": "1116200"
  },
  {
    "text": "We need to design the model, the\nobjective, and the optimization process. Like what was just\nasked, we need",
    "start": "1116200",
    "end": "1121660"
  },
  {
    "text": "to figure out how do we actually\npass an zi into the network? We also need to figure out\nif we should use this vanilla",
    "start": "1121660",
    "end": "1129039"
  },
  {
    "text": "objective, or if we can use\nsomething a little bit more sophisticated,\nand also how do we",
    "start": "1129040",
    "end": "1134890"
  },
  {
    "text": "go about optimizing\nthis objective. So we'll talk about each\nof these design choices one",
    "start": "1134890",
    "end": "1140679"
  },
  {
    "text": "by one. And we'll start with the model. So we'll start by\ntrying to think about, how can the model be\nconditioned on zi?",
    "start": "1140680",
    "end": "1146260"
  },
  {
    "text": "And what parameters of\nthe model should be shared across tasks versus separate?",
    "start": "1146260",
    "end": "1151990"
  },
  {
    "text": " Cool. So now let's assume that zi\nis a one hot index like what",
    "start": "1151990",
    "end": "1159920"
  },
  {
    "text": "we talked about before. I have a question\nfor all of you, which is, how should we choose\nto condition the network",
    "start": "1159920",
    "end": "1169519"
  },
  {
    "text": "on this one hot vector\nin a way that will try to share as little as possible?",
    "start": "1169520",
    "end": "1175233"
  },
  {
    "text": "And what I mean\nby this is we want to have as few of the parameters\nfor different tasks be shared.",
    "start": "1175233",
    "end": "1181550"
  },
  {
    "text": "We want to basically get as\nclose as possible to training completely separate neural\nnetworks on each task.",
    "start": "1181550",
    "end": "1188830"
  },
  {
    "text": "Does anyone have any thoughts? Yeah?  Are you good at loss functions?",
    "start": "1188830",
    "end": "1195990"
  },
  {
    "text": "Can you explain a\nlittle bit more? ",
    "start": "1195990",
    "end": "1207929"
  },
  {
    "text": "Yeah. The question is, if we\nassume that zi is just a one hot vector for\neach of the tasks,",
    "start": "1207930",
    "end": "1214370"
  },
  {
    "text": "how should we condition\nthe network on zi such that the network is sharing\nas little as possible, such",
    "start": "1214370",
    "end": "1221210"
  },
  {
    "text": "that we are as close as possible\nto just training completely different neural networks? ",
    "start": "1221210",
    "end": "1228140"
  },
  {
    "text": "Yeah? I guess we could just have\na switch statement for each of the different conditions.",
    "start": "1228140",
    "end": "1233450"
  },
  {
    "text": "So if it's one hot 1, then\njust do a separate effort from 2 and 3.",
    "start": "1233450",
    "end": "1238730"
  },
  {
    "text": "Yeah, exactly. So in particular, what we\ncan do and what was suggested is you can basically just have\ndifferent neural networks,",
    "start": "1238730",
    "end": "1247700"
  },
  {
    "text": "t different neural\nnetworks, and basically, have a switch statement,\nhave z basically modulate",
    "start": "1247700",
    "end": "1253550"
  },
  {
    "text": "which of those networks you\nuse to make a prediction. And so formally, what\nthis would look like if z",
    "start": "1253550",
    "end": "1259580"
  },
  {
    "text": "is a one hot vector\nis you would pass-- say y1 is the output\nof the first network, y2 is the output of\nthe second network",
    "start": "1259580",
    "end": "1266083"
  },
  {
    "text": "and so forth, and all of these\nhave separate parameters. Then we can compute the output\nas basically just switching",
    "start": "1266083",
    "end": "1274817"
  },
  {
    "text": "between these different outputs. And so if the task is the first\ntask, then you would output y1. If the task is the second\ntask, then you would output y2,",
    "start": "1274817",
    "end": "1282440"
  },
  {
    "text": "and so forth. And what you get\nas a result of this is that you basically-- this is\nstill a single neural network,",
    "start": "1282440",
    "end": "1291080"
  },
  {
    "text": "but you get completely\nindependently trained neural networks within\nthis single neural network.",
    "start": "1291080",
    "end": "1300040"
  },
  {
    "text": "Was there a question? No. OK. And so essentially,\nthis corresponds",
    "start": "1300040",
    "end": "1306410"
  },
  {
    "text": "to having no shared\nparameters across the tasks. Yeah? Which means that we\nwill need to learn--",
    "start": "1306410",
    "end": "1313813"
  },
  {
    "text": "like when it does\nthat, that means to have best performance\nacross all the script with as many shared\nparameters as possible",
    "start": "1313813",
    "end": "1319519"
  },
  {
    "text": "so that the combination\ncomplexity goes down? Yes, exactly. So in general, this\nis not a great way",
    "start": "1319520",
    "end": "1326179"
  },
  {
    "text": "to go about doing\nmulti-task learning. It's one extreme. And on the other\nextreme of the problem,",
    "start": "1326180",
    "end": "1333200"
  },
  {
    "text": "we could share a lot more. We could share\nbasically everything. And so what we\ncould do instead is",
    "start": "1333200",
    "end": "1338887"
  },
  {
    "text": "to have a single neural network. And basically just for\nexample, concatenate z with one of the layers.",
    "start": "1338887",
    "end": "1347580"
  },
  {
    "text": "And in this case, if you\njust concatenate z to one of the layers and then have\neverything else be normal,",
    "start": "1347580",
    "end": "1356240"
  },
  {
    "text": "then in this case, basically,\nall of the parameters are shared across the tasks\nwith the small exception",
    "start": "1356240",
    "end": "1363470"
  },
  {
    "text": "of the parameters following\nzi technically will not be shared across tasks, but\nall the other parameters",
    "start": "1363470",
    "end": "1369179"
  },
  {
    "text": "of the network will be shared. ",
    "start": "1369180",
    "end": "1376262"
  },
  {
    "text": "So you have these two\ndifferent extremes. And there's becomes this\nchoice of what should you",
    "start": "1376262",
    "end": "1384090"
  },
  {
    "text": "actually do in practice. And so an alternative\nway of viewing",
    "start": "1384090",
    "end": "1391515"
  },
  {
    "text": "this form of\nconditioning on zi is basically splitting\nthe parameters",
    "start": "1391515",
    "end": "1397020"
  },
  {
    "text": "into shared parameters and\ntask specific parameters. So if you split it, the\nobjective and shared parameters",
    "start": "1397020",
    "end": "1404570"
  },
  {
    "text": "and task-specific parameters-- we saw one example where\neverything was basically task specific, we\nsaw another example",
    "start": "1404570",
    "end": "1410000"
  },
  {
    "text": "where everything was shared. You can basically formulate-- rewrite the objective\nas something like this, which is\nexactly equivalent",
    "start": "1410000",
    "end": "1417080"
  },
  {
    "text": "to the previous objective. The only thing\nthat we're doing is we're now saying\nthat we've basically",
    "start": "1417080",
    "end": "1425210"
  },
  {
    "text": "split up our parameter\nvector into these two parts. And the thing that's\nuseful about writing it",
    "start": "1425210",
    "end": "1430220"
  },
  {
    "text": "this way is that\nit really shows us that the task-specific\nparameters for task i are only optimized with\nrespect to loss function i.",
    "start": "1430220",
    "end": "1438080"
  },
  {
    "text": "And so those parts\nof the network will only see data\nfrom one of the tasks",
    "start": "1438080",
    "end": "1444080"
  },
  {
    "text": "rather than all of the tasks.  Yeah? Is there a constraint\nin multi-task",
    "start": "1444080",
    "end": "1450370"
  },
  {
    "text": "learning that you're learning\nall the task at the same time? Like for example,\nin the MLT space,",
    "start": "1450370",
    "end": "1458620"
  },
  {
    "text": "if you just train a\nlarge limit model, it's somewhat task-specific\ntoward the end. But when you train for\neach specific task,",
    "start": "1458620",
    "end": "1464690"
  },
  {
    "text": "you can do those sequentially. So is that muilti-task\nlearning when there are contributing all at once?",
    "start": "1464690",
    "end": "1470960"
  },
  {
    "text": "Yeah. That's an awesome question. So the question was,\nis there a constraint that in multi-task\nlearning that we're",
    "start": "1470960",
    "end": "1476920"
  },
  {
    "text": "going to be learning all the\ntasks all at the same time? And in general for the\npurpose of this lecture,",
    "start": "1476920",
    "end": "1482462"
  },
  {
    "text": "we're only going to be\nconsidering things that we're learning at the same time. In the next lecture\non Monday, we'll",
    "start": "1482463",
    "end": "1487900"
  },
  {
    "text": "start talking about\ntransfer learning where we learn one task and\nthen learn another task. And then the last\nlecture in the course,",
    "start": "1487900",
    "end": "1493990"
  },
  {
    "text": "we're going to also talk\nabout lifelong learning where we are learning a set\nof tasks in sequence,",
    "start": "1493990",
    "end": "1499360"
  },
  {
    "text": "one task then another tasks\nthen another task and so forth. In general, a lot of the\nunderlying ideas underlying",
    "start": "1499360",
    "end": "1506110"
  },
  {
    "text": "multi-task learning are also\napplicable to the setting where you're not learning\neverything at once.",
    "start": "1506110",
    "end": "1512350"
  },
  {
    "text": "And one thing that is\nsomewhat nice about looking at things like this is that\nyou could imagine training",
    "start": "1512350",
    "end": "1518410"
  },
  {
    "text": "on a few tasks. And that gives you maybe\nsome good shared parameters. And then additionally,\ntraining some task",
    "start": "1518410",
    "end": "1523809"
  },
  {
    "text": "specific parameters\nseparately after the fact. And so things like that are\noften very reasonable to do.",
    "start": "1523810",
    "end": "1531310"
  },
  {
    "text": " Yeah? This multi-task or doing\nmulti-task learning as",
    "start": "1531310",
    "end": "1537559"
  },
  {
    "text": "understand they are\ndelaying structure and delay feed on double task. Like one of the big method scale\nis like to speak about that it",
    "start": "1537560",
    "end": "1544070"
  },
  {
    "text": "something which is sharing\nin public with this movement. Do we hope an optimal method\nto just capture the shared",
    "start": "1544070",
    "end": "1550910"
  },
  {
    "text": "structure, and then basically\ninclude it or possibly start with the shared structure\nthen do this condition only,",
    "start": "1550910",
    "end": "1556940"
  },
  {
    "text": "just to split it initially? Like do we have some that\nkind of result on that? Yeah. So the question is, it\nseems annoying to have",
    "start": "1556940",
    "end": "1563090"
  },
  {
    "text": "to manually break\nthis up and figure out what should be shared and\nwhat shouldn't be shared. Can we just have it-- like\nhave an algorithm figure it out",
    "start": "1563090",
    "end": "1569930"
  },
  {
    "text": "for us? And so there are some approaches\nthat do something like that.",
    "start": "1569930",
    "end": "1575600"
  },
  {
    "text": "In general, it's somewhat of\na chicken and egg problem, because if you have something\nelse to choose what to share",
    "start": "1575600",
    "end": "1582740"
  },
  {
    "text": "and what not to share, then\nthat thing that's choosing will probably use data\nfrom all the tasks. And so that's going to be\nshared across all the tasks.",
    "start": "1582740",
    "end": "1589860"
  },
  {
    "text": "So in general, there\nare going to be",
    "start": "1589860",
    "end": "1594890"
  },
  {
    "text": "some manual choices regardless. But there are some techniques\nthat do something like that. ",
    "start": "1594890",
    "end": "1602659"
  },
  {
    "text": "Yeah? Another problem question. Do we know anything\nabout comparative rates",
    "start": "1602660",
    "end": "1607899"
  },
  {
    "text": "of how quickly these\ntasks are learning? Yeah. So the question is,\ndo we know anything",
    "start": "1607900",
    "end": "1613370"
  },
  {
    "text": "about the comparative rates\nof different task learning? I'll briefly talk\nabout that when",
    "start": "1613370",
    "end": "1618860"
  },
  {
    "text": "we start to talk about\nthe optimization process. So the next thing that I want\nto talk about and specifically",
    "start": "1618860",
    "end": "1626067"
  },
  {
    "text": "thinking about breaking things\ninto shared parameters and task specific parameters is that\nin the previous two slides,",
    "start": "1626067",
    "end": "1632830"
  },
  {
    "text": "we saw one extreme\nof sharing nothing, and we saw one extreme\nof sharing everything just based on how we\nconditioned on zi.",
    "start": "1632830",
    "end": "1639809"
  },
  {
    "text": "And one of the things\nI think is interesting here is it suggests\nthat basically choosing how to condition\nthe network on zi",
    "start": "1639810",
    "end": "1646019"
  },
  {
    "text": "is equivalent to choosing how\nand where to share parameters. And so in general, choosing\nhow to condition on zi",
    "start": "1646020",
    "end": "1655253"
  },
  {
    "text": "is actually a very\ndelicate choice because you need to be\ncareful about how much you should be sharing versus how\nmuch you shouldn't be sharing.",
    "start": "1655253",
    "end": "1661740"
  },
  {
    "text": " So we looked at two\nextremes of conditioning.",
    "start": "1661740",
    "end": "1668059"
  },
  {
    "text": "I want to go over two other\ncommon choices in conditioning, well actually, sort of\nthree other common choices.",
    "start": "1668060",
    "end": "1675590"
  },
  {
    "text": "So we talked about just\nconcatenating the zi with the activations\nat one of the layers.",
    "start": "1675590",
    "end": "1680910"
  },
  {
    "text": "And so this looks\nsomething like this, where you take the input or\nthe activations at one layer.",
    "start": "1680910",
    "end": "1685970"
  },
  {
    "text": "You take your zi. You concatenate them together. And then pass that\ninto the network.",
    "start": "1685970",
    "end": "1692760"
  },
  {
    "text": "Another thing that you could\ndo instead of concatenating is adding together a\nrepresentation of both of them.",
    "start": "1692760",
    "end": "1698610"
  },
  {
    "text": "So you could pass the zi\nthrough a linear layer and pass the input\nthrough a linear layer and then add them rather\nthan conditioning them,",
    "start": "1698610",
    "end": "1706429"
  },
  {
    "text": "and then get the\nresulting output. Now one thing that\nyou might notice here",
    "start": "1706430",
    "end": "1712620"
  },
  {
    "text": "is these are two options\nthat seem somewhat different. But it actually turns out\nthat the concatenation base",
    "start": "1712620",
    "end": "1720352"
  },
  {
    "text": "conditioning here and\nthe additive conditioning here are exactly\nequivalent to one another.",
    "start": "1720352",
    "end": "1725850"
  },
  {
    "text": " And so I'm curious.",
    "start": "1725850",
    "end": "1731150"
  },
  {
    "text": "Maybe one thing-- I want\nto try something new. So typically, I ask people\nwhy they're the same thing. Rather than just\nasking you, I want",
    "start": "1731150",
    "end": "1737300"
  },
  {
    "text": "you to take maybe one\nminute to think about it, and then one minute to talk\nto your neighbor about it.",
    "start": "1737300",
    "end": "1745680"
  },
  {
    "text": "And then after two\nminutes, I'll ask you-- we'll ask you to share why you\nthink they're the same thing.",
    "start": "1745680",
    "end": "1752720"
  },
  {
    "text": "So you can think\nabout it for a minute. I'll tell you in a minute to\ntalk to someone, and yeah.",
    "start": "1752720",
    "end": "1758680"
  },
  {
    "start": "1758680",
    "end": "1780560"
  },
  {
    "text": "OK. Cool. Let's come back. Does anyone want to share\nwhat they came up with?",
    "start": "1780560",
    "end": "1788260"
  },
  {
    "text": "Yeah? So in the concatenation\nbase approach, the linear layer that you've\ncontaminated input through",
    "start": "1788260",
    "end": "1797490"
  },
  {
    "text": "is effectively the start of\nbeing truly aware of the number",
    "start": "1797490",
    "end": "1804110"
  },
  {
    "text": "two of instances with holding\noperation over [INAUDIBLE]..",
    "start": "1804110",
    "end": "1810450"
  },
  {
    "text": "Yeah. Awesome. So in particular, if we have\nsome input x and some task",
    "start": "1810450",
    "end": "1819090"
  },
  {
    "text": "descriptor z, we're going to-- if we concatenate them,\nwe'll do something like this",
    "start": "1819090",
    "end": "1824190"
  },
  {
    "text": "and have a weight\nmatrix right here. And you can instead think\nof this weight matrix",
    "start": "1824190",
    "end": "1831090"
  },
  {
    "text": "as having two parts, W1 and W2. ",
    "start": "1831090",
    "end": "1838107"
  },
  {
    "text": "So this is just the\nleft half of the matrix. This is the right\nhalf of that matrix. And this is equivalent to\nW1 times x plus W2 times z.",
    "start": "1838107",
    "end": "1850490"
  },
  {
    "text": "And so one thing that's\nimportant in the second figure is that actually the x\nand the z first going",
    "start": "1850490",
    "end": "1857600"
  },
  {
    "text": "through a linear layer\nbefore you add them together. And this is exactly kind of the\nadditive conditioning version.",
    "start": "1857600",
    "end": "1868100"
  },
  {
    "text": "And you can visually\nsee this right here where the red matrix\ncorresponds to W1,",
    "start": "1868100",
    "end": "1873529"
  },
  {
    "text": "the blue matrix\ncorresponds to W2. ",
    "start": "1873530",
    "end": "1879200"
  },
  {
    "text": "Yeah? So if you have a\nnonlinear, do you fall in each when\nyou're weighing the additive\nconditioning, or would you",
    "start": "1879200",
    "end": "1884920"
  },
  {
    "text": "have more expressive power? And would also be additive\nconditioning be better than that concatenation base?",
    "start": "1884920",
    "end": "1894170"
  },
  {
    "text": "So you're saying if you had a\nnonlinearity basically here.",
    "start": "1894170",
    "end": "1899990"
  },
  {
    "text": "So if you had something like a\nnonlinearity here, basically? ",
    "start": "1899990",
    "end": "1905899"
  },
  {
    "text": "Yeah. So something-- once you\nstart adding nonlinearity is it does get more expressive. ",
    "start": "1905900",
    "end": "1913820"
  },
  {
    "text": "And yeah. So if you did do have some\nnonlinearities on these separately, it would be a\nlittle bit more expressive.",
    "start": "1913820",
    "end": "1919220"
  },
  {
    "text": "You could also imagine--  yeah. So in that case, it would be\na little bit more expensive.",
    "start": "1919220",
    "end": "1925945"
  },
  {
    "text": "Yeah? Is there any computational\ntrade off between these two?",
    "start": "1925945",
    "end": "1931279"
  },
  {
    "text": "Is there any computational\ntrade off between the two? In general, I think that--",
    "start": "1931280",
    "end": "1936725"
  },
  {
    "text": " I would guess that-- So I guess that on\nmodern computers,",
    "start": "1936725",
    "end": "1944070"
  },
  {
    "text": "this is better because we\nhave very good matrix vector multiplication modules.",
    "start": "1944070",
    "end": "1949080"
  },
  {
    "text": " But I haven't tested\nit myself on hardware.",
    "start": "1949080",
    "end": "1955095"
  },
  {
    "text": " And I would guess\nit's probably not that significant compared to\nother layers of neural networks",
    "start": "1955095",
    "end": "1962550"
  },
  {
    "text": "like convolutional layers. Yeah? So for the nonlinear\nthing, shouldn't that",
    "start": "1962550",
    "end": "1968850"
  },
  {
    "text": "concatenation base\nwould be better? Because it would then explore\nthe correlating terms as well",
    "start": "1968850",
    "end": "1974390"
  },
  {
    "text": "between x and z. ",
    "start": "1974390",
    "end": "1982500"
  },
  {
    "text": "I guess--  It could be like you\nbrace from x and z.",
    "start": "1982500",
    "end": "1988429"
  },
  {
    "text": "So if we [INAUDIBLE]\nit would also explore the x and z together,\nwhile the code really does it.",
    "start": "1988430",
    "end": "1994140"
  },
  {
    "text": "Yeah. I guess in both of\nthese cases in practice, you probably won't just be\nlike having this literally be the output of your network.",
    "start": "1994140",
    "end": "1999900"
  },
  {
    "text": "You'll probably also\ncontinue to pass that through fully connected\nlayers and so forth. And so in general,\nwhen we talked",
    "start": "1999900",
    "end": "2006670"
  },
  {
    "text": "about adding\nnonlinearity there, I'm guessing that wouldn't\nhave a huge effect in terms on the expressive\npower because this is a part of a larger network.",
    "start": "2006670",
    "end": "2012810"
  },
  {
    "text": " Cool.",
    "start": "2012810",
    "end": "2017950"
  },
  {
    "text": "So that was concatenation\nand additive conditioning. Two other choices\nthat are quite common.",
    "start": "2017950",
    "end": "2025450"
  },
  {
    "text": "One is to use a\nmulti-head architecture where you have some\nshared bottom layers that",
    "start": "2025450",
    "end": "2031420"
  },
  {
    "text": "are like all the tasks\nyou pass on the input do the same exact layers. And then for\ndifferent tasks, you",
    "start": "2031420",
    "end": "2038530"
  },
  {
    "text": "have different heads\nor different sets of task specific layers.",
    "start": "2038530",
    "end": "2044500"
  },
  {
    "text": "And a generalization of\nthis that you can consider is multiplicative conditioning.",
    "start": "2044500",
    "end": "2050620"
  },
  {
    "text": "So before we saw\nadditive conditioning, you can also multiply the task\ndescriptor or representation",
    "start": "2050620",
    "end": "2058239"
  },
  {
    "text": "of the task descriptor\nwith the activations. And so what this will look\nlike is basically just replace the additive--",
    "start": "2058239",
    "end": "2065530"
  },
  {
    "text": "the addition operation\nin the previous equation with the dot product,\nor sorry, with",
    "start": "2065530",
    "end": "2071110"
  },
  {
    "text": "an element-wise multiplication. And something like\nthis is going to be",
    "start": "2071110",
    "end": "2077829"
  },
  {
    "text": "more expressive, at least\nper layer, than adding. And it could actually\nrepresent things",
    "start": "2077830",
    "end": "2087219"
  },
  {
    "text": "like the multi-head\narchitecture. And the reason that\nwe can see that is-- if you remember the kind\nof very first example",
    "start": "2087219",
    "end": "2094768"
  },
  {
    "text": "that we looked at where we\nwere essentially multiplying the zi with the outputs,\nthe sort of multiplication",
    "start": "2094768",
    "end": "2101710"
  },
  {
    "text": "can sort of gate the\nnetwork and create, basically modulate which layers\nare used for which tasks.",
    "start": "2101710",
    "end": "2109105"
  },
  {
    "start": "2109105",
    "end": "2114790"
  },
  {
    "text": "Cool. And so in general,\nmultiplicative conditioning is going to generalize\nhaving independent networks",
    "start": "2114790",
    "end": "2121330"
  },
  {
    "text": "and independent heads. Yeah? So for better\ndisplay, would you say attention is sort of\nlabor task specification?",
    "start": "2121330",
    "end": "2129050"
  },
  {
    "text": " Attention is sort\nof like a task?",
    "start": "2129050",
    "end": "2137490"
  },
  {
    "text": "If so far attention is\nbasically like dot products, then yes, something\nlike attention",
    "start": "2137490",
    "end": "2143060"
  },
  {
    "text": "can be viewed of as\ntask specification. Any other questions?",
    "start": "2143060",
    "end": "2148450"
  },
  {
    "text": "Yeah? So [INAUDIBLE] in general\nthey collect data. Where can we all apply\nthe specific layers",
    "start": "2148450",
    "end": "2156838"
  },
  {
    "text": "so that all the\nnetwork [INAUDIBLE]?? If you're looking\nat [INAUDIBLE] part, everything seems lack of value.",
    "start": "2156839",
    "end": "2162869"
  },
  {
    "text": "Would the network will\nstill be here, right? Yeah. Where are you\nmultiply will matter?",
    "start": "2162870",
    "end": "2169970"
  },
  {
    "text": "Although that said you\ncould also imagine-- like even if you do this sort\nof gating at the very beginning",
    "start": "2169970",
    "end": "2176830"
  },
  {
    "text": "of the network,\nyou could imagine-- well, I guess, yeah. Even with a fully\nconnected layer,",
    "start": "2176830",
    "end": "2185560"
  },
  {
    "text": "the architecture will\ngenerally still matter. And so it can represent\ncertain kinds of gating.",
    "start": "2185560",
    "end": "2193420"
  },
  {
    "text": " But yeah, the architecture\nstill matters.",
    "start": "2193420",
    "end": "2202100"
  },
  {
    "text": "Yeah. [INAUDIBLE] every layer of\nexactly what the network itself",
    "start": "2202100",
    "end": "2211630"
  },
  {
    "text": "figure out how much of\nthe structure [INAUDIBLE]",
    "start": "2211630",
    "end": "2216769"
  },
  {
    "text": " So the question is, if you do\nthe multiplicative conditioning",
    "start": "2216770",
    "end": "2224630"
  },
  {
    "text": "on every single layer, does\nthat let the network figure out what to share and\nwhat not to share?",
    "start": "2224630",
    "end": "2229640"
  },
  {
    "text": "To some extent, yes. I guess I should also mention\nthat even if the network is sharing all the parameters\nand it's getting gradients",
    "start": "2229640",
    "end": "2236060"
  },
  {
    "text": "from all the tasks for\nall the parameters, you could also\nimagine it zeroing out",
    "start": "2236060",
    "end": "2241850"
  },
  {
    "text": "certain parts of the weights,\nso that it represents something more like independent networks.",
    "start": "2241850",
    "end": "2247410"
  },
  {
    "text": "And so the network can\narrive in a setting in where some things are\nbeing used for only one task",
    "start": "2247410",
    "end": "2257210"
  },
  {
    "text": "even without multiplicative\nconditioning like that.",
    "start": "2257210",
    "end": "2263830"
  },
  {
    "text": " Cool. So we covered really the basics.",
    "start": "2263830",
    "end": "2270230"
  },
  {
    "text": "I mean, the basics are really\neither concatenation/additive conditioning or\nmultiplicative conditioning.",
    "start": "2270230",
    "end": "2275930"
  },
  {
    "text": "And you can have\nmore complex choices. There's a lot of papers that\nconsider more complex choices.",
    "start": "2275930",
    "end": "2283790"
  },
  {
    "text": "Although even just the\nbasic approach typically works pretty well. ",
    "start": "2283790",
    "end": "2292630"
  },
  {
    "text": "Now unfortunately,\nfiguring out how you structure the\narchitecture and how",
    "start": "2292630",
    "end": "2298320"
  },
  {
    "text": "you condition on the network\nis a lot just general neural network\narchitecture tuning,",
    "start": "2298320",
    "end": "2303760"
  },
  {
    "text": "which is that it often is\nfairly problem dependent, and it's a little bit more\nof an art than a science.",
    "start": "2303760",
    "end": "2310110"
  },
  {
    "text": "And it's oftentimes guided\nmore by intuition or knowledge of the problem as\nopposed to having",
    "start": "2310110",
    "end": "2317322"
  },
  {
    "text": "a really rigorous\nset of guidelines for exactly what you should do. That said, we'll\ntalk a little bit",
    "start": "2317322",
    "end": "2322920"
  },
  {
    "text": "in some of the coming slides\nabout some things that can help guide that process.",
    "start": "2322920",
    "end": "2330260"
  },
  {
    "text": "Yeah. This little condition\nincrease depend on the type of descriptor that we're using. So if you're using a\nnatural language descriptor,",
    "start": "2330260",
    "end": "2337600"
  },
  {
    "text": "you can condition\non that differently. And also do you\nhave any insights on what descriptors\nmight be better.",
    "start": "2337600",
    "end": "2344050"
  },
  {
    "text": "Is the one hot better\nbecause it's more explicit or could not language\nbe better because it's more nuanced and detailed?",
    "start": "2344050",
    "end": "2350390"
  },
  {
    "text": "Yeah. So there are two\nquestions there. One is, what descriptors\nshould you use? And the second is, the\nway that you condition",
    "start": "2350390",
    "end": "2356440"
  },
  {
    "text": "the network on that\ndescriptor differ based off of the kind of\ndescriptor that you have?",
    "start": "2356440",
    "end": "2362420"
  },
  {
    "text": "So in general, for the first\nquestion, the more information you give to the network\ntypically, the better.",
    "start": "2362420",
    "end": "2368650"
  },
  {
    "text": "If you give it just\na one hot vector, these one hot vectors are\northogonal to each other.",
    "start": "2368650",
    "end": "2374869"
  },
  {
    "text": "And so you're not giving\nit any information about how these tasks might\nrelate to one another.",
    "start": "2374870",
    "end": "2380510"
  },
  {
    "text": "And if you instead give\nit a language description of the task, where one of the\ntasks says write me a story,",
    "start": "2380510",
    "end": "2385810"
  },
  {
    "text": "and other tasks write\nme a poem, another task is translate between\nthese two tasks,",
    "start": "2385810",
    "end": "2391599"
  },
  {
    "text": "between these two\nlanguages, then that will give it a\nlittle bit of information about the similarity between\ntasks because write me a story",
    "start": "2391600",
    "end": "2397628"
  },
  {
    "text": "and write me a poem, those\nare similar sentences. And so naturally, the task\nshould be a little bit more similar as well.",
    "start": "2397628",
    "end": "2403503"
  },
  {
    "text": "So generally, the\nmore information you give it, the better\nif you have access to that information.",
    "start": "2403503",
    "end": "2408550"
  },
  {
    "text": "And then in terms\nof conditioning, I think that my\ngeneral advice would be that multiplicative\nconditioning is generally",
    "start": "2408550",
    "end": "2417550"
  },
  {
    "text": "the way to go because it gives\nyou more expressive power. And in practice,\nwe've seen things like attention and\nmultiplicative conditioning",
    "start": "2417550",
    "end": "2425020"
  },
  {
    "text": "through like feature wise\nmodulation to be at least one of the approaches that you see\nthe most in what people do.",
    "start": "2425020",
    "end": "2433930"
  },
  {
    "text": "And just a follow up question. Has there been any work\ndone on task embeddings, like similar, how we we have\nword embeddings, if you could",
    "start": "2433930",
    "end": "2440530"
  },
  {
    "text": "have a task embedding,\nso it's not just like one whole perspective [INAUDIBLE]? Yeah. So the question is,\nis there any work",
    "start": "2440530",
    "end": "2449109"
  },
  {
    "text": "on getting a task embedding? And I should note that if you\nhave a weight matrix that's",
    "start": "2449110",
    "end": "2456309"
  },
  {
    "text": "going after a task\ndescriptor, then",
    "start": "2456310",
    "end": "2463150"
  },
  {
    "text": "this is going to\nconvert that one hot vector into a dense vector. And so in that sense,\nthe first weight matrix",
    "start": "2463150",
    "end": "2469870"
  },
  {
    "text": "that comes after\nthat one hot task descriptor is going to give\nyou an embedding of the task. And it's essentially, if you\nlearn multi task learning",
    "start": "2469870",
    "end": "2477580"
  },
  {
    "text": "from scratch, then it's\ngoing to learn these task embeddings from scratch. But it would be interesting\nif we could develop things",
    "start": "2477580",
    "end": "2484720"
  },
  {
    "text": "like the notion of word\nvectors, but for tasks. And one thing you could do is\nif you have a natural language",
    "start": "2484720",
    "end": "2490270"
  },
  {
    "text": "description, encode that\ninto a sentence encoding and use that representation\nas your task descriptor.",
    "start": "2490270",
    "end": "2497150"
  },
  {
    "text": "Yeah. The questions is,\nhow do you implement the multiplicative gate? So if you have four\ntasks, you just",
    "start": "2497150",
    "end": "2502700"
  },
  {
    "text": "add a soft-max gate\nlayer over dimension for probably the last layer?",
    "start": "2502700",
    "end": "2508380"
  },
  {
    "text": "Yeah. So the way that\nyou can implement the multiplicative gate is\ngoing to look a lot like this. So if say the say the\ndimensionality of one",
    "start": "2508380",
    "end": "2520310"
  },
  {
    "text": "of your activations\nis like D dimensional, then what you'll want to do is\ntake your one hot vector also",
    "start": "2520310",
    "end": "2529280"
  },
  {
    "text": "multiply that by\na weight matrix, so you get another D\ndimensional vector.",
    "start": "2529280",
    "end": "2534293"
  },
  {
    "text": "So once you have to two\nD dimensional vectors, then you'll just do element\nwise multiplication.",
    "start": "2534293",
    "end": "2539450"
  },
  {
    "text": "And so you'll replace this\nplus sign with an element wise multiplication operation.",
    "start": "2539450",
    "end": "2545450"
  },
  {
    "start": "2545450",
    "end": "2551109"
  },
  {
    "text": "Cool. So we've talked a lot about\nthe architecture of the model.",
    "start": "2551110",
    "end": "2556280"
  },
  {
    "text": "Now let's talk about\nthe actual objective. So earlier on, we formulated\nthis vanilla multi task",
    "start": "2556280",
    "end": "2563260"
  },
  {
    "text": "learning objective. But in many cases, we may\nwant to weight the tasks",
    "start": "2563260",
    "end": "2568660"
  },
  {
    "text": "differently. So we may want to\nformulate an objective that looks like this,\nwhere we are going",
    "start": "2568660",
    "end": "2574329"
  },
  {
    "text": "to assign a higher weight to\nsome tasks compared to others. Does anyone have\nany thoughts on how",
    "start": "2574330",
    "end": "2580910"
  },
  {
    "text": "we might choose the weights? Yeah. Perhaps, so how many times\nis the data for each task?",
    "start": "2580910",
    "end": "2589840"
  },
  {
    "text": "So stuff that we see\nmore, it'll be [INAUDIBLE] so it's not imbalanced?",
    "start": "2589840",
    "end": "2597100"
  },
  {
    "text": "Yeah. So you could have\nsomething where you change the weight based\noff of the amount of data",
    "start": "2597100",
    "end": "2603617"
  },
  {
    "text": "that you have. Maybe if you have\na lot more data, it could actually make\nsense to downweight. If you have less data, it\nmay make sense to upweight.",
    "start": "2603617",
    "end": "2609780"
  },
  {
    "text": "One thing I'll mention here is\nby formulating this objective as a sum over tasks,\nthis is already",
    "start": "2609780",
    "end": "2614910"
  },
  {
    "text": "going to somewhat normalize over\nthe amount of data per task. Because rather than if\nwe instead summed over",
    "start": "2614910",
    "end": "2621720"
  },
  {
    "text": "the data points that\nwe had, then that would assign higher weight\nto task with more data.",
    "start": "2621720",
    "end": "2628120"
  },
  {
    "text": "Yeah. You can weight it\nby the magnitude of the loss of the task. So like one loss function\ncould end up the large values",
    "start": "2628120",
    "end": "2636030"
  },
  {
    "text": "into the small values. And you don't want\nthe [INAUDIBLE] dominate the lost terms,\nso you can [INAUDIBLE]",
    "start": "2636030",
    "end": "2642180"
  },
  {
    "text": "Yeah, absolutely. So if you have some\nloss functions that are much higher in\nmagnitude, then you may want to downweight those\nand upweight loss functions that",
    "start": "2642180",
    "end": "2648060"
  },
  {
    "text": "have a lower magnitude. Yeah. Sure. I'm just using the vanilla MTL. And you see that the\nnetworks really struggling",
    "start": "2648060",
    "end": "2654930"
  },
  {
    "text": "on a specific task, then\nyou weight task higher. Yeah. So you find that the model\nis doing poorly on one task,",
    "start": "2654930",
    "end": "2660601"
  },
  {
    "text": "then you could try to\nupweight that task. And we'll actually\ncover a method that will do that automatically\nlater on this slide.",
    "start": "2660602",
    "end": "2667770"
  },
  {
    "text": "Any other ideas? If one tasks is like\nthe most important, you have a really high weight.",
    "start": "2667770",
    "end": "2673470"
  },
  {
    "text": "Yeah. So if there's some\ntasks that you care about more than\nothers, like in some cases, maybe there's actually only\none task you care about,",
    "start": "2673470",
    "end": "2680010"
  },
  {
    "text": "and you just have these\nother auxiliary tasks that you are hoping\nmight help out, then you could\nupweight the tasks",
    "start": "2680010",
    "end": "2685200"
  },
  {
    "text": "that you care about the most. I think some\n[INAUDIBLE] certainly makes you want to do this.",
    "start": "2685200",
    "end": "2692830"
  },
  {
    "text": "Yeah. So you could. In some ways, treat the eyes\nas hyperparameters as well. Although when you choose\nthose hyperparameters,",
    "start": "2692830",
    "end": "2700619"
  },
  {
    "text": "you need some overall objective\nto tune them with respect to. And for example, that\noverall objective",
    "start": "2700620",
    "end": "2708178"
  },
  {
    "text": "could be the vanilla objective. But you may also have cases\nwhere the vanilla objective is not suitable when the magnitude\nof the losses are different,",
    "start": "2708178",
    "end": "2714720"
  },
  {
    "text": "or when some tasks\nmatter more than others. One more.",
    "start": "2714720",
    "end": "2720630"
  },
  {
    "text": "Maybe you could use\nthe wiggle function to help the system\nlearn what it has.",
    "start": "2720630",
    "end": "2727920"
  },
  {
    "text": "When someone get stuck in a\nlocal, minimum, or maximum,",
    "start": "2727920",
    "end": "2733290"
  },
  {
    "text": "you have a less\nweighted objective that the error accrues.",
    "start": "2733290",
    "end": "2739290"
  },
  {
    "text": "That will check it\nout so you don't take the little more weight. [INAUDIBLE] in subsequent one.",
    "start": "2739290",
    "end": "2745230"
  },
  {
    "text": "Using it to solve some\nof the [INAUDIBLE].. Yeah. So if you run into some\noptimization challenges,",
    "start": "2745230",
    "end": "2750642"
  },
  {
    "text": "it could be that actually\nchanging the weighting aids in the optimization challenges. For example, maybe if you have\na task that seems to be stuck,",
    "start": "2750642",
    "end": "2757109"
  },
  {
    "text": "maybe if you start placing all\nof your weight on that task, it will help push it out of\nthat local optimum or something.",
    "start": "2757110",
    "end": "2764280"
  },
  {
    "text": "Or maybe if it's\nstuck on that task, maybe you should actually\nstop optimizing and revisit it later. So there are a number\nof different approaches",
    "start": "2764280",
    "end": "2772560"
  },
  {
    "text": "that you could take. The first thing that\nI have listed here is actually just based on some\nimportance or priority, which",
    "start": "2772560",
    "end": "2778380"
  },
  {
    "text": "would be some manual selection. But there are also\nvarious heuristics",
    "start": "2778380",
    "end": "2783390"
  },
  {
    "text": "that you could use to choose\nthese weights as well.",
    "start": "2783390",
    "end": "2789348"
  },
  {
    "text": "And the other thing\nthat I'll mention is you don't have to\nhave these weights be fixed throughout training. You can actually have them\nvary at different points",
    "start": "2789348",
    "end": "2796075"
  },
  {
    "text": "of training. For example, if you have\noptimization challenges, or if some tasks are\ndoing worse than others in the optimization.",
    "start": "2796075",
    "end": "2804300"
  },
  {
    "text": "And so in addition\nto some of the things that you have also\nsuggested, another heuristic that some prior\nwork has looked at",
    "start": "2804300",
    "end": "2810397"
  },
  {
    "text": "is encouraging gradients\nto have similar magnitudes. That said, there's\na pretty large body",
    "start": "2810397",
    "end": "2816420"
  },
  {
    "text": "of work on different\nheuristics that have looked at, different\nways of approaching this.",
    "start": "2816420",
    "end": "2822030"
  },
  {
    "text": "In general, the vanilla\nobjective or manually chosen weights is generally one\nof the strongest approaches",
    "start": "2822030",
    "end": "2828060"
  },
  {
    "text": "that you can take. But it's worth\nacknowledging a lot of work that on certain problems\nyou can see improvements.",
    "start": "2828060",
    "end": "2836950"
  },
  {
    "text": "Now, the other\napproach that I want to mention here, which\nactually came up before is you could optimize for the task\nthat is doing the worst.",
    "start": "2836950",
    "end": "2845800"
  },
  {
    "text": "And in particular,\nyou can formulate this as a minimax optimization,\nwhere at each point in training,",
    "start": "2845800",
    "end": "2852580"
  },
  {
    "text": "you pick the task that\nhas the highest loss and you update the\nparameters on that task.",
    "start": "2852580",
    "end": "2858590"
  },
  {
    "text": "And this is exactly\ngoing to basically try to normalize or equalize\nthe task to some extent.",
    "start": "2858590",
    "end": "2865480"
  },
  {
    "text": "And this is relevant when you\nthink that all of the tasks matter equally.",
    "start": "2865480",
    "end": "2871220"
  },
  {
    "text": "And so in particular,\nwhat this will look like",
    "start": "2871220",
    "end": "2876450"
  },
  {
    "text": "is if you have task one,\ntask two, and task three,",
    "start": "2876450",
    "end": "2881820"
  },
  {
    "text": "and you plot their lost value. And for example, for task one,\nyour loss values down here, for task two, your loss values\nup here, for task three,",
    "start": "2881820",
    "end": "2888750"
  },
  {
    "text": "your loss values right\nhere, what this will do is you're going to\nestimate these loss",
    "start": "2888750",
    "end": "2894090"
  },
  {
    "text": "value at your current\niteration of training. You'll notice that this\none is doing the worst, and then you'll start only\noptimizing on task two.",
    "start": "2894090",
    "end": "2901230"
  },
  {
    "text": "And then after you start\noptimizing on task two, you'll reevaluate this. Chances are hopefully this\nhas gone down a little bit.",
    "start": "2901230",
    "end": "2907440"
  },
  {
    "text": "Maybe one of the other ones\nhas gone up a little bit because you weren't\noptimizing on that one. And then you'll start\noptimizing for this one.",
    "start": "2907440",
    "end": "2915549"
  },
  {
    "text": "At the end of this\nprocess, in general, you should end up\nwith loss values that are more similar\nacross the three tasks",
    "start": "2915550",
    "end": "2921609"
  },
  {
    "text": "compared to if you would only\noptimize the sum of them. Because if you optimize the\nsum, it might just prioritize--",
    "start": "2921610",
    "end": "2927460"
  },
  {
    "text": "it might minimize the\ntasks that are easiest rather than trying to\nmaintain equal value. And this can be especially\nuseful in fairness settings,",
    "start": "2927460",
    "end": "2935049"
  },
  {
    "text": "where maybe different\ntasks correspond to different users, or\ndifferent demographics, or different subpopulations or\ndifferent geographic regions.",
    "start": "2935050",
    "end": "2943150"
  },
  {
    "text": "And in those settings, you want\nto have similar loss values for those different\nsubpopulations, because you don't want to have\nsome customers that are getting",
    "start": "2943150",
    "end": "2949900"
  },
  {
    "text": "a really great experience in\nsome customers that are having a really terrible experience. Or likewise, some people\nthat have a great experience",
    "start": "2949900",
    "end": "2956230"
  },
  {
    "text": "versus a terrible experience. Yeah. Would this be harder to optimize\nsince it becomes [INAUDIBLE]??",
    "start": "2956230",
    "end": "2963050"
  },
  {
    "text": "Yeah. So this in general, becomes a\nharder optimization problem.",
    "start": "2963050",
    "end": "2968240"
  },
  {
    "text": "Yeah. So there are a\nrange of challenges with this kind of approach. Another thing that's\nsomewhat challenging",
    "start": "2968240",
    "end": "2974260"
  },
  {
    "text": "is you need to compute\nwhat is the worst loss.",
    "start": "2974260",
    "end": "2979300"
  },
  {
    "text": "And the way that you\nwould optimize this exactly is every\nsingle iteration, you would compute\nwhat is the worst one",
    "start": "2979300",
    "end": "2985420"
  },
  {
    "text": "and evaluating the loss\nfunction on your entire data set may be expensive. But there are ways\nto approximate which",
    "start": "2985420",
    "end": "2992860"
  },
  {
    "text": "one is the worst one by\nkeeping like a running average or something like that. And in practice,\nit's not something",
    "start": "2992860",
    "end": "2999970"
  },
  {
    "text": "that is too hard to\noptimize, especially if you have a relatively\nsmall number of tasks. You have a lot of tasks.",
    "start": "2999970",
    "end": "3005530"
  },
  {
    "text": "It gets a little bit trickier. Yeah. [INAUDIBLE] Do you\nnormalize the losses first before getting the max so\nthat you're in the same scale?",
    "start": "3005530",
    "end": "3013040"
  },
  {
    "text": "Yeah. So in practice, it\nis good practice to normalize your labels.",
    "start": "3013040",
    "end": "3018400"
  },
  {
    "text": " Yeah, normalize\nyour labels and make sure your loss functions\nare all on the same scale.",
    "start": "3018400",
    "end": "3025450"
  },
  {
    "text": "If you don't do\nsomething like that, or if it's difficult to do\nthat, what this is going to do is prioritize the loss functions\nthat are the most difficult",
    "start": "3025450",
    "end": "3032349"
  },
  {
    "text": "or that are the\nhighest in magnitude. Yeah. So my question is a\nbit opposite or onsite.",
    "start": "3032350",
    "end": "3039610"
  },
  {
    "text": "But if you want\nto-- so let's say if your objective is\non a primary task, you want optimize our\nprimary task, many of times,",
    "start": "3039610",
    "end": "3048010"
  },
  {
    "text": "we use multi-task learning\nto improve the single task performance, right?",
    "start": "3048010",
    "end": "3053050"
  },
  {
    "text": "So now my question is, how do\nwe find our, or in particular, how do we configure\nthe optical function",
    "start": "3053050",
    "end": "3059380"
  },
  {
    "text": "to decide on what\nauxiliary does would be helpful for primary operator?",
    "start": "3059380",
    "end": "3064960"
  },
  {
    "text": "Yeah. So if you really only care about\none of the tasks, for example,",
    "start": "3064960",
    "end": "3070600"
  },
  {
    "text": "then, in that case, actually,\ntreating WI as a parameter makes a lot of sense.",
    "start": "3070600",
    "end": "3075970"
  },
  {
    "text": "Because your outer\nobjective is I want to do as best as\npossible on task one, and I want those other\ntasks to help me.",
    "start": "3075970",
    "end": "3081830"
  },
  {
    "text": "And so you can\nmanually figure out what WI leads the lowest loss\nfunction on the validation set",
    "start": "3081830",
    "end": "3088510"
  },
  {
    "text": "for task one, or you could\napply automatic hyperparameter optimization techniques\nas well to do it for you.",
    "start": "3088510",
    "end": "3096260"
  },
  {
    "text": "Yeah. I was wondering. So this type of idea of trying\nto minimize the maximum loss,",
    "start": "3096260",
    "end": "3105950"
  },
  {
    "text": "it reminds me of L1 versus\nL2 or L infinity norms. So it's possible to\nhave people tried",
    "start": "3105950",
    "end": "3114089"
  },
  {
    "text": "to changing the\nexponent for the loss instead of just doing\nweight times loss",
    "start": "3114090",
    "end": "3119685"
  },
  {
    "text": "because loss squared. And it's to L2 norm\npushing everything down. And L infinity is kind of\nsimilar to the min-max.",
    "start": "3119685",
    "end": "3126860"
  },
  {
    "text": "Yeah. Actually, that's\na great question. I haven't come across\nother things that",
    "start": "3126860",
    "end": "3132350"
  },
  {
    "text": "aren't L2 or L infinity or L1. Like something that does some\nother exponent basically.",
    "start": "3132350",
    "end": "3139880"
  },
  {
    "text": "But something like that could\nbe interesting to think about. And one of the challenges\nwith this objective",
    "start": "3139880",
    "end": "3145400"
  },
  {
    "text": "is sometimes it can be a\nlittle bit too pessimistic and can place a little bit too\nmuch focus on the worst case.",
    "start": "3145400",
    "end": "3151880"
  },
  {
    "text": "And something that is somewhere\nin between L2 and L infinity may actually mitigate\nthat challenge. So that could be\ninteresting to explore.",
    "start": "3151880",
    "end": "3159440"
  },
  {
    "text": "One last thing\nthat I'll mention. If you're interested in\ndigging more into this, this looks a lot like what's\ncalled Distributional Robust",
    "start": "3159440",
    "end": "3166040"
  },
  {
    "text": "Optimization, or DRO. And so if you want a keyword\nto learn more about it,",
    "start": "3166040",
    "end": "3173120"
  },
  {
    "text": "you could take a look at that. And the math gets quite deep. There's all the nice\nguarantees that you can",
    "start": "3173120",
    "end": "3180020"
  },
  {
    "text": "get about this optimization. ",
    "start": "3180020",
    "end": "3185210"
  },
  {
    "text": "Great. And then lastly, we'll briefly\ntalk about the optimization process itself before\ngoing into a case study.",
    "start": "3185210",
    "end": "3194520"
  },
  {
    "text": "And I'm just going to go over\nthe standard optimization process that we might\ndo for this objective. Because in general,\nit works pretty well.",
    "start": "3194520",
    "end": "3206880"
  },
  {
    "text": "And so the basic\nversion of this is we'll sample a mini\nbatch of tasks. So I mean, if we only\nhave three tasks,",
    "start": "3206880",
    "end": "3213803"
  },
  {
    "text": "then we can just\nsample all three. But if you have a very\nlarge number of tasks, you might just sample a\nsubset of those tasks.",
    "start": "3213803",
    "end": "3220310"
  },
  {
    "text": "Then we will sample data\npoints for each of the tasks that we sampled. So this is going to\nbe another mini batch.",
    "start": "3220310",
    "end": "3229350"
  },
  {
    "text": "And then we can compute the\nloss on that mini batch. So we have each of the\ntasks in our batch of tasks,",
    "start": "3229350",
    "end": "3235440"
  },
  {
    "text": "and then we have the data\nset, the mini batch data set for that task that we computed. And this will correspond to\na mini batch loss function",
    "start": "3235440",
    "end": "3242130"
  },
  {
    "text": "in the multi-task setting. And so once we've computed\nour mini batch loss function,",
    "start": "3242130",
    "end": "3247440"
  },
  {
    "text": "then we can compute the\ngradient of that loss function and back propagate that\ninto the neural network",
    "start": "3247440",
    "end": "3253290"
  },
  {
    "text": "and apply the gradient with\nyour favorite optimizer. So you can use vanilla\nstochastic gradient descent perhaps with momentum, or\nyou could use something",
    "start": "3253290",
    "end": "3260280"
  },
  {
    "text": "like atom, which is\noften used in practice.",
    "start": "3260280",
    "end": "3265373"
  },
  {
    "text": "So this basically\njust corresponds to stochastic gradient descent\non the multi-task objective.",
    "start": "3265373",
    "end": "3271260"
  },
  {
    "text": "The thing that's probably the\nmost different from that is we are going to be sampling\na mini batch of tasks.",
    "start": "3271260",
    "end": "3277300"
  },
  {
    "text": "And so this ensures\nthat the tasks are sampled uniformly regardless\nof the quantities of data. And so if you have\na lot more data",
    "start": "3277300",
    "end": "3283950"
  },
  {
    "text": "for one task than\nanother task, this is going to make sure that\nthose two tasks are still sampled at the same rate.",
    "start": "3283950",
    "end": "3289242"
  },
  {
    "text": "Of course, if you care a\nlot more about the task that has more data, then\nyou may actually want to do something\na little bit",
    "start": "3289242",
    "end": "3294540"
  },
  {
    "text": "different than this first step. The only thing that came\nup is that you may actually",
    "start": "3294540",
    "end": "3300760"
  },
  {
    "text": "have loss functions that\nare at different scales. And if you have a\nregression problem, even if your loss\nfunction is the same,",
    "start": "3300760",
    "end": "3306790"
  },
  {
    "text": "if its mean squared\nerror, if your task labels for different tasks\nare at different scales like one varies from\n-5 to 5, another",
    "start": "3306790",
    "end": "3313540"
  },
  {
    "text": "varies from -100 to 100,\nthen your loss function is going to be scaled\ncorrespondingly.",
    "start": "3313540",
    "end": "3320529"
  },
  {
    "text": "And so it's good to try\nto normalize your labels, so that your loss functions\nare at the same scale.",
    "start": "3320530",
    "end": "3326170"
  },
  {
    "start": "3326170",
    "end": "3332540"
  },
  {
    "text": "Cool. So actually, before we\ngo into the case study, there's a few\ndifferent challenges",
    "start": "3332540",
    "end": "3337670"
  },
  {
    "text": "that I want to bring up. And this is going to affect some\nof the design choices as well. So one challenge that comes\nup is negative transfer",
    "start": "3337670",
    "end": "3345650"
  },
  {
    "text": "between tasks. And what negative\ntransfer means is that sometimes if you try to\ntrain with multi-task learning,",
    "start": "3345650",
    "end": "3353180"
  },
  {
    "text": "the resulting model\nactually does worse than if you were to train completely\nindependent neural networks.",
    "start": "3353180",
    "end": "3360100"
  },
  {
    "text": "And as one example\nof this, you can formulate a multi-task version\nof the CIFAR-100 data set.",
    "start": "3360100",
    "end": "3366200"
  },
  {
    "text": "And you can compare\nthe performance of a multi-head architecture\nof a cross-stitch architecture,",
    "start": "3366200",
    "end": "3371880"
  },
  {
    "text": "which was an architecture\nproposed by some prior work and also just independently\ntraining the models.",
    "start": "3371880",
    "end": "3377780"
  },
  {
    "text": "And what we see here is actually\nthe independently trained model is getting 67% accuracy,\nwhich is more than 10%",
    "start": "3377780",
    "end": "3384560"
  },
  {
    "text": "higher than the multi-task\nlearning approaches. ",
    "start": "3384560",
    "end": "3389880"
  },
  {
    "text": "So why might this be the case? This could be the case because\nof optimization challenges.",
    "start": "3389880",
    "end": "3395450"
  },
  {
    "text": "So there might be some\ninterference between the tasks. They might be trying to\nuse the representation",
    "start": "3395450",
    "end": "3400460"
  },
  {
    "text": "in different ways,\nor the test might be learning at different rates. And if one of the tasks\nis more or less converged,",
    "start": "3400460",
    "end": "3408105"
  },
  {
    "text": "and one of the tasks\nis still learning, that may make it difficult to\nkeep on updating the network.",
    "start": "3408105",
    "end": "3416340"
  },
  {
    "text": "It could also be not an\noptimization challenge, but just a challenge of limited\nrepresentational capacity.",
    "start": "3416340",
    "end": "3422700"
  },
  {
    "text": "Oftentimes, multi-tasking\nnetworks are doing more. And so they need to be\nlarger than if you were",
    "start": "3422700",
    "end": "3427710"
  },
  {
    "text": "to just train on a single task. So if you have a\nnegative transfer,",
    "start": "3427710",
    "end": "3435799"
  },
  {
    "text": "the natural thing to do is just\ntry to share less across tasks. And so you can see if you're\nhaving a negative transfer",
    "start": "3435800",
    "end": "3442130"
  },
  {
    "text": "by just trying to\ntrain independently. If you're seeing the independent\ntraining is doing better, then you can just try to make it\nmore like independent training.",
    "start": "3442130",
    "end": "3450713"
  },
  {
    "text": "And so we saw a\nfew different ways to try to do that\nbefore by, for example, having a multi-head\narchitecture that explicitly",
    "start": "3450713",
    "end": "3458280"
  },
  {
    "text": "has different parts of the\nnetwork that are not shared at all between the tasks. Yeah.",
    "start": "3458280",
    "end": "3464910"
  },
  {
    "text": "Is there [INAUDIBLE]\nmethods to define how advances may just [INAUDIBLE]",
    "start": "3464910",
    "end": "3470710"
  },
  {
    "text": "Yeah. So the question is, are there\nany unsupervised methods for telling if\nthere's going to be positive or negative\ntransfer between the tasks?",
    "start": "3470710",
    "end": "3478350"
  },
  {
    "text": " I guess I'll show that in\na little bit in a minute.",
    "start": "3478350",
    "end": "3485170"
  },
  {
    "text": "But in general, without\nthe labels of the task, you certainly can't.",
    "start": "3485170",
    "end": "3491058"
  },
  {
    "text": "It's certainly very\ndifficult to tell if there's going to be\npositive or negative transfer. Ideally, it'd be awesome\nif you could just",
    "start": "3491058",
    "end": "3496920"
  },
  {
    "text": "have a description of the task. And of each of the\ntasks, and then something that tells you like,\nare these going",
    "start": "3496920",
    "end": "3502140"
  },
  {
    "text": "to work well together or not? Unfortunately, I\nthink that something like that is nearly impossible,\nbecause it's not just",
    "start": "3502140",
    "end": "3509069"
  },
  {
    "text": "going to depend on\nwhat the task is, but also the nature of\nthe data set, the nature of the model that you're\ntraining, potentially also",
    "start": "3509070",
    "end": "3515430"
  },
  {
    "text": "the nature of the\noptimizer as well. So in general, these things are\nvery hard to tell a priority.",
    "start": "3515430",
    "end": "3522710"
  },
  {
    "text": "Yeah. If you are getting\nnegative transfer and you see that using two\nseparate models sometimes",
    "start": "3522710",
    "end": "3527960"
  },
  {
    "text": "better than using than\nassure architecture? Why would you continue\nto try to use assure?",
    "start": "3527960",
    "end": "3533270"
  },
  {
    "text": "Are you still hoping to\nget even better performance than the sector models? Yeah. It's a great question. So if you're seeing that\nindependent training is doing",
    "start": "3533270",
    "end": "3539270"
  },
  {
    "text": "better than your current\nmulti-task model, why not just go with the\nindependent networks? It's very reasonable\nto stop there and go",
    "start": "3539270",
    "end": "3547430"
  },
  {
    "text": "with the independent networks. Although, there are\ndefinitely scenarios where you could get\nbetter performance",
    "start": "3547430",
    "end": "3553310"
  },
  {
    "text": "with a different architecture. For example, if you started\nby trying to share everything, there are certainly scenarios\nwhere training and multi head",
    "start": "3553310",
    "end": "3560028"
  },
  {
    "text": "architecture will\ndo a lot better than both sharing everything\nand training independently.",
    "start": "3560028",
    "end": "3567210"
  },
  {
    "text": "Yeah. There's a way to tell whether\nthe task is inherently incompatible or\nwas it my mistake that I did not work out\nmorning with the architecture?",
    "start": "3567210",
    "end": "3575300"
  },
  {
    "text": "How do I tell them? So the question\nis, is there a way to tell if there's like if\nthe task are just incompatible",
    "start": "3575300",
    "end": "3582260"
  },
  {
    "text": "versus, did I mess up I guess? In general, I think it's\na trial and error process.",
    "start": "3582260",
    "end": "3590630"
  },
  {
    "text": "It's very similar\nto trying to tell a priorrity if there's going\nto be negative transfer or not. ",
    "start": "3590630",
    "end": "3596770"
  },
  {
    "text": "Yeah. [INAUDIBLE] could it be possible\nto pre-train on the other task",
    "start": "3596770",
    "end": "3603160"
  },
  {
    "text": "and then train the [INAUDIBLE]. Yeah. So another way that you\ncould possibly share less",
    "start": "3603160",
    "end": "3608832"
  },
  {
    "text": "is to basically pre-train on\none task and then fine tune on maybe the tasks that\nyou care more about",
    "start": "3608832",
    "end": "3614080"
  },
  {
    "text": "or something like that. And actually, this\nties in a little bit to what I had on the\nrest of this slide, which is that you\ndon't actually have",
    "start": "3614080",
    "end": "3620950"
  },
  {
    "text": "to either share parameters\nor not share parameters. It can be a little bit more\nflexible of a decision.",
    "start": "3620950",
    "end": "3626750"
  },
  {
    "text": "It could be something like\npre-training and fine-tuning. Or you could have\nsomething, which is referred to as soft parameter\nsharing where you actually",
    "start": "3626750",
    "end": "3634090"
  },
  {
    "text": "have separate parameters for\nthe tasks like a pre-train versus fine to network. But perhaps, you just\nhave some soft constraint",
    "start": "3634090",
    "end": "3640690"
  },
  {
    "text": "that encourages those parameters\nto be similar to one another. And the way that you\ncould implement that is take the same exact\nobjective that you had before,",
    "start": "3640690",
    "end": "3648010"
  },
  {
    "text": "where you have some task\nspecific parameters. Perhaps even the\nentire network has to have specific parameters.",
    "start": "3648010",
    "end": "3654010"
  },
  {
    "text": "But then try to\ntie them together with a loss that\nencourages the tasks that the parameters\nof different tasks",
    "start": "3654010",
    "end": "3660130"
  },
  {
    "text": "to be similar to one another. And so there is\nactually much more of a continuum than just\nsharing versus not sharing.",
    "start": "3660130",
    "end": "3667915"
  },
  {
    "text": " Some of the benefits of this\ncan allow for more fluid degrees",
    "start": "3667915",
    "end": "3675180"
  },
  {
    "text": "of parameter sharing. And things like fine-tuning\nare also an example of that.",
    "start": "3675180",
    "end": "3680670"
  },
  {
    "text": "It's also worth\nacknowledging though that this has some\nlimitations because this introduces yet another set\nof design decisions and hyper",
    "start": "3680670",
    "end": "3687340"
  },
  {
    "text": "parameters. You need to figure out how to\nweight that loss function that ties them together.",
    "start": "3687340",
    "end": "3693167"
  },
  {
    "text": "And this is also going to\nbe more memory intensive because you have to store\nseparate parameters.",
    "start": "3693167",
    "end": "3699610"
  },
  {
    "text": "Cool. The second challenge\nthat you might encounter is almost the opposite\nof negative transfer,",
    "start": "3699610",
    "end": "3708740"
  },
  {
    "text": "which is that you might not\nactually be sharing enough. So if you see that\nyou are training",
    "start": "3708740",
    "end": "3714705"
  },
  {
    "text": "your multi-task\nlearning problem, but you're actually overfitting\na lot on your problem,",
    "start": "3714705",
    "end": "3719890"
  },
  {
    "text": "multi-task learning is\na form of regularization because you're giving\nit these auxiliary loss functions that should help\nlearn representations.",
    "start": "3719890",
    "end": "3726430"
  },
  {
    "text": "And if you're seeing that you're\noverfitting on your tasks, then it could actually\nbe beneficial to try to share more than what\nyou're currently sharing.",
    "start": "3726430",
    "end": "3733240"
  },
  {
    "text": " And now, the last\nchallenge that I'll",
    "start": "3733240",
    "end": "3739240"
  },
  {
    "text": "come to which is related to\nsome questions that came up before is that generally, if\nyou have a number of tasks",
    "start": "3739240",
    "end": "3747232"
  },
  {
    "text": "and you want to\ndetermine if you're going to see positive\ntransfer or negative transfer, and trying to understand\nshould you train all of them",
    "start": "3747232",
    "end": "3753190"
  },
  {
    "text": "together, can you\nfigure out which ones are going to be\ncomplementary, in general, I think this is somewhat\nof an open problem.",
    "start": "3753190",
    "end": "3760510"
  },
  {
    "text": "And the bad news is\nthat as I mentioned, there's no thing that\nwill just tell you, will it work or\nnot at the outset?",
    "start": "3760510",
    "end": "3767770"
  },
  {
    "text": "There's no closed form\nmeasure of how similar to tasks are, how complementary\nthey are in practice.",
    "start": "3767770",
    "end": "3773930"
  },
  {
    "text": "And the reason for\nthis is that it depends not just on\nwhat the tests are, but on the data set on the\noptimizer, on the architecture,",
    "start": "3773930",
    "end": "3781330"
  },
  {
    "text": "and so forth, and\nit could even depend on where you are in the\noptimization process. So for example,\none task might be",
    "start": "3781330",
    "end": "3787930"
  },
  {
    "text": "to pick up a fork and\nskewer, and another task might be to pick up\na fork, in that case, if you're early on\nin the optimization,",
    "start": "3787930",
    "end": "3793600"
  },
  {
    "text": "then picking up the fork\nis the first step that you need to learn. And so they might be\nvery complementary early on in the optimization.",
    "start": "3793600",
    "end": "3799660"
  },
  {
    "text": "But then later on,\nthey may actually be not very complimentary\nbecause one of them actually needs to do something\nonce you've picked up",
    "start": "3799660",
    "end": "3804910"
  },
  {
    "text": "the fork, whereas the\nother thing doesn't need to do anything.  The somewhat better news\nis that there are some ways",
    "start": "3804910",
    "end": "3812590"
  },
  {
    "text": "to try to approximate\ntask similarity from a single training\nrun rather than trying",
    "start": "3812590",
    "end": "3817720"
  },
  {
    "text": "to brute force and\nsee what happens when you train different\nsets of tasks together.",
    "start": "3817720",
    "end": "3824357"
  },
  {
    "text": "And so here's one\nexample of something that tries to basically\ndo a single training run of a single multi-task network.",
    "start": "3824357",
    "end": "3831010"
  },
  {
    "text": "Analyze how those tasks\nare similar to each other by looking at the gradients,\nlooking at the optimization",
    "start": "3831010",
    "end": "3837790"
  },
  {
    "text": "process, and then\nultimately figuring out which tasks to be\ngrouped together and which tasks should\nbe trained separately.",
    "start": "3837790",
    "end": "3843861"
  },
  {
    "text": " OK. So to recap, most\nof the lecture,",
    "start": "3843861",
    "end": "3852269"
  },
  {
    "text": "we talked about what a\ntask is as these data generating\ndistributions, we talked about how each of these\ntasks have data sets, how",
    "start": "3852270",
    "end": "3860102"
  },
  {
    "text": "for the model\narchitecture we could have multiplicative\nconditioning, versus additive conditioning,\nand that multiplicative is a bit more general,\nor a bit more expressive.",
    "start": "3860102",
    "end": "3868422"
  },
  {
    "text": "And then you can\nalso try to share more or less of your network\ndepending on the transfer that you observe.",
    "start": "3868423",
    "end": "3874542"
  },
  {
    "text": "We also talked a little\nbit about the objective and the optimization about\nchoosing task weights, and as well as stratifying\nyour mini batches,",
    "start": "3874542",
    "end": "3881062"
  },
  {
    "text": "so that you have a\nsimilar amount of data per task in your mini batch.",
    "start": "3881062",
    "end": "3886340"
  },
  {
    "text": "Question? Is there like a data science\nrelation to the success of these approaches?",
    "start": "3886340",
    "end": "3892619"
  },
  {
    "text": "So if you have\nless data, would it make more sense to train\nlike separate models for each task as opposed\nto a more complex",
    "start": "3892620",
    "end": "3898589"
  },
  {
    "text": "multi-task architecture? Yeah. So in general, if you\nhave less data per task,",
    "start": "3898590",
    "end": "3906600"
  },
  {
    "text": "then multi task learning\nhas more potential to be beneficial because\nit's a form of bringing",
    "start": "3906600",
    "end": "3913109"
  },
  {
    "text": "in additional data basically. The data from other\ntasks is being brought into the optimization process.",
    "start": "3913110",
    "end": "3918270"
  },
  {
    "text": "Whereas if you have a ton of\ndata for all of the tasks, then chances are you'll\nprobably do well",
    "start": "3918270",
    "end": "3924510"
  },
  {
    "text": "if you just train from\nscratch on those tasks. Yeah. Is there a reasonable\nway to describe",
    "start": "3924510",
    "end": "3932039"
  },
  {
    "text": "how much structure\nto not share, which is similar to the\nusual information?",
    "start": "3932040",
    "end": "3937620"
  },
  {
    "text": "But how are you going\n[INAUDIBLE] and quantify? How well you can create\none bit for another? Is there something\nanalogous for that?",
    "start": "3937620",
    "end": "3944590"
  },
  {
    "text": "Yeah. So the question\nis, is there a way to quantify the\nsimilarity between tasks and with something like\nmutual information?",
    "start": "3944590",
    "end": "3952230"
  },
  {
    "text": "And yeah. So I usually cover this\na little bit later,",
    "start": "3952230",
    "end": "3957960"
  },
  {
    "text": "but I'll see if I can try to\ncover this in the next lecture. Basically, there's a way to\nformulate, to basically think",
    "start": "3957960",
    "end": "3964950"
  },
  {
    "text": "in the language of\ngraphical models, and think about what are\nthe statistical dependencies",
    "start": "3964950",
    "end": "3970320"
  },
  {
    "text": "between the data\nsets and the strength of those statistical\ndependencies will translate into the\nsimilarity between the tasks.",
    "start": "3970320",
    "end": "3978360"
  },
  {
    "text": " Awesome.",
    "start": "3978360",
    "end": "3983470"
  },
  {
    "text": "So in the remaining\n10 minutes, I'd like to get into a case study\nof where people actually",
    "start": "3983470",
    "end": "3990160"
  },
  {
    "text": "use multi-task learning\nin a real world problem. And in particular,\nthis is a paper",
    "start": "3990160",
    "end": "3995980"
  },
  {
    "text": "from some folks\nthat work at Google. And their goal was to make\nrecommendations for YouTube.",
    "start": "3995980",
    "end": "4001829"
  },
  {
    "text": "And so they are basically\ntrying to figure out what should you put in this\nright column right here.",
    "start": "4001830",
    "end": "4007900"
  },
  {
    "text": "So a very real\nproblem probably even something that you may\nhave encountered yourself.",
    "start": "4007900",
    "end": "4014061"
  },
  {
    "text": "And it's pretty cool\nbecause the paper actually goes into a lot of detail\nin how they actually",
    "start": "4014062",
    "end": "4019350"
  },
  {
    "text": "try to solve this problem. So before we get into how\nthis is a multi-task learning",
    "start": "4019350",
    "end": "4025390"
  },
  {
    "text": "problem, let's get\ninto the setup. So as input, they\nhave information",
    "start": "4025390",
    "end": "4030400"
  },
  {
    "text": "about what the user\nis currently watching, and they also have some\nfeatures about that user. So they have features\nabout the video",
    "start": "4030400",
    "end": "4035830"
  },
  {
    "text": "and features about the user. And once they have\nthat input, they're",
    "start": "4035830",
    "end": "4040990"
  },
  {
    "text": "going to generate a\nfew candidate videos, and then try to rank\nthose candidate videos.",
    "start": "4040990",
    "end": "4048170"
  },
  {
    "text": "And then ultimately, once\nyou have a ranking, then you'll serve the top ranking\nvideos in that right side",
    "start": "4048170",
    "end": "4054619"
  },
  {
    "text": "panel. The candidate videos\nare going to be",
    "start": "4054620",
    "end": "4059990"
  },
  {
    "text": "pooled from multiple candidate\ngeneration algorithms. These candidate\ngeneration algorithms are going to use\nthings like matching",
    "start": "4059990",
    "end": "4066452"
  },
  {
    "text": "the topic of the query\nvideo, looking at videos that were most frequently watched\nwith the query video, and also",
    "start": "4066452",
    "end": "4072440"
  },
  {
    "text": "other approaches. The focus of this paper isn't\non candidate generation, it's really on the\nsecond step of once we",
    "start": "4072440",
    "end": "4079940"
  },
  {
    "text": "have a few candidates, how do we\nrank the ones that we think are going to be the best options. ",
    "start": "4079940",
    "end": "4087700"
  },
  {
    "text": "Cool. So in this ranking\nproblem, the input is, again, the information\nabout the query video,",
    "start": "4087700",
    "end": "4095079"
  },
  {
    "text": "information about\nthe candidate video, and also information about\nthe user and other context.",
    "start": "4095080",
    "end": "4104179"
  },
  {
    "text": "And so in particular,\nthose input features are shown in the\nbottom yellow boxes.",
    "start": "4104180",
    "end": "4109689"
  },
  {
    "text": "So features of the\ncreating candidate video and features of the\nuser in the context. That's going to be passed into\nthe neural network as input.",
    "start": "4109689",
    "end": "4118439"
  },
  {
    "text": "And then there's the output. So the output of\nthis model is going to try to output measures of\nengagement and satisfaction",
    "start": "4118439",
    "end": "4126259"
  },
  {
    "text": "with the candidate video. And so intuitively, if\nwe want to be able to--",
    "start": "4126260",
    "end": "4131450"
  },
  {
    "text": "in this case, their goal\nis to try to figure out things that have higher rank. And so things that\nhave, if you're able to predict the engagement\nand satisfaction you'll",
    "start": "4131450",
    "end": "4138259"
  },
  {
    "text": "be able to rank the videos. And so more concretely,\nwhat engagement means",
    "start": "4138260",
    "end": "4144399"
  },
  {
    "text": "is they're going\nto be predicting binary classification\ntasks like whether or not they click on the video,\nand also regression",
    "start": "4144399",
    "end": "4151719"
  },
  {
    "text": "tasks that relate to the time\nspent watching the candidate video.",
    "start": "4151720",
    "end": "4157290"
  },
  {
    "text": "And satisfaction is going\nto correspond to things like clicking the like button\non the candidate video,",
    "start": "4157290",
    "end": "4163080"
  },
  {
    "text": "and also the rating that they\ngive to that video, which I believe is from surveys. ",
    "start": "4163080",
    "end": "4170452"
  },
  {
    "text": "One thing that's\ninteresting is once they have the model output,\ntheir training model to output these things\nfrom the input features.",
    "start": "4170452",
    "end": "4176539"
  },
  {
    "text": "That's what the machine\nlearning problem is. To get the ranking score,\nthey manually weight",
    "start": "4176540",
    "end": "4184580"
  },
  {
    "text": "a combination of these\ndifferent predictions and tune the weights of\nall these different things",
    "start": "4184580",
    "end": "4190370"
  },
  {
    "text": "in a manual process\nbased on what they think seems to do the best. ",
    "start": "4190370",
    "end": "4196610"
  },
  {
    "text": "Cool. So I guess question\nfor you before we move on to the approach. So the objective is to predict\nengagement and satisfaction.",
    "start": "4196610",
    "end": "4205630"
  },
  {
    "text": "I'm curious, do these\nobjectives seem reasonable, and what are some issues\nthat might come up with this objective?",
    "start": "4205630",
    "end": "4211810"
  },
  {
    "text": " Yeah. Subject to no response.",
    "start": "4211810",
    "end": "4218712"
  },
  {
    "text": "Quite so people don't do\nmost of the [INAUDIBLE] Yeah. So you might have\nsome missing data",
    "start": "4218712",
    "end": "4225130"
  },
  {
    "text": "that comes up, because people\nmight not respond to a survey or they might like maybe\npeople like a video,",
    "start": "4225130",
    "end": "4230200"
  },
  {
    "text": "but they don't click\nlike for example. Yeah. The time spent.",
    "start": "4230200",
    "end": "4235360"
  },
  {
    "text": "Are we the only maybe\nlike shorter or longer? And maybe just a light\nbutton switch [INAUDIBLE]..",
    "start": "4235360",
    "end": "4244220"
  },
  {
    "text": "Yeah. So things like time spend. If you have a longer\nvideo, maybe that people will spend more time watching\nthat than short videos.",
    "start": "4244220",
    "end": "4250480"
  },
  {
    "text": "And so you may want\nto control for that. Yeah. Data and balance. I mean, it's possible that\nthere is a lot of engagement.",
    "start": "4250480",
    "end": "4258380"
  },
  {
    "text": "But satisfaction is good. Yeah. So you're going to\nhave data imbalance.",
    "start": "4258380",
    "end": "4263860"
  },
  {
    "text": "Like the surveys,\nfor example, you're going to have a lot\nless survey data. Maybe a lot less data\nabout whether not users",
    "start": "4263860",
    "end": "4270100"
  },
  {
    "text": "click like or not, but more\ndense data about engagement. Yeah.",
    "start": "4270100",
    "end": "4275470"
  },
  {
    "text": "A video that user\nengages with a lot. They might not necessarily like. So [INAUDIBLE]\nemotional reaction",
    "start": "4275470",
    "end": "4280970"
  },
  {
    "text": "that might be negative and\nmaybe they'll leave a review, but they actually dislikes that\nis causing issues for them.",
    "start": "4280970",
    "end": "4286820"
  },
  {
    "text": "Yeah. So people might watch\nsomething, but not actually like what they're watching.",
    "start": "4286820",
    "end": "4292380"
  },
  {
    "text": "Yeah. So like self-reinforcing\ngroups I think. But if a user\nscreaming on a video,",
    "start": "4292380",
    "end": "4298695"
  },
  {
    "text": "and then you show them\nmore of the same type, then they just clicking\non the same thing, but then actually\nenjoying the content?",
    "start": "4298695",
    "end": "4304527"
  },
  {
    "text": "You're just restricting\nwhat they're saying. Yeah. So feedback loops. So once you start\ndeploying the system",
    "start": "4304527",
    "end": "4309540"
  },
  {
    "text": "and actually have\nit collect data, then that might affect what\npeople are clicking on, and that might lead to\na data distribution that",
    "start": "4309540",
    "end": "4319177"
  },
  {
    "text": "is a little bit skewed and\ndifficult to make generations on. Yeah. Well. This is a bit of an\neditorealization.",
    "start": "4319177",
    "end": "4324840"
  },
  {
    "text": "But from a social\nperspective, you're optimizing for wasting\npeople's time when you do.",
    "start": "4324840",
    "end": "4332050"
  },
  {
    "text": "Yeah. Awesome. So the point was\nthat maybe optimizing for time spent on YouTube\nis not good for society.",
    "start": "4332050",
    "end": "4340030"
  },
  {
    "text": "And I really like this response. Because last time, I\nasked people last year, I asked people this\nquestion, and everyone",
    "start": "4340030",
    "end": "4346128"
  },
  {
    "text": "was pointing out\ntechnical challenges and not pointing out actual\nethical or societal challenges with this. So actually thinking\nabout this objective,",
    "start": "4346128",
    "end": "4353998"
  },
  {
    "text": "not just from the standpoint\nof a technical standpoint, but also what should you\nbe optimizing for I think",
    "start": "4353998",
    "end": "4359160"
  },
  {
    "text": "is really important. Yeah. One thing that we platform\nmight also care about is that we want to make sure\nthat along with exploitation,",
    "start": "4359160",
    "end": "4367832"
  },
  {
    "text": "there's also some\nexploitation happening. So some media might\nnot be thought popular, but for longer for the\nplatform, this more diversity",
    "start": "4367832",
    "end": "4375030"
  },
  {
    "text": "and solve these kind of problems\nthey might not be that into. Yeah. So I mean, in\ngeneral, these metrics",
    "start": "4375030",
    "end": "4381390"
  },
  {
    "text": "are very short term metrics. And actually,\nfactoring in what's going to happen\nin the long term,",
    "start": "4381390",
    "end": "4387630"
  },
  {
    "text": "and whether or not videos that-- and yeah, exactly what that\nfeedback process will look like",
    "start": "4387630",
    "end": "4394620"
  },
  {
    "text": "is really important for\ntheir business model, and also in general for\nactually serving stuff",
    "start": "4394620",
    "end": "4402929"
  },
  {
    "text": "that people want to see. Cool. For the sake of time, let's go\ninto actually how they do this.",
    "start": "4402930",
    "end": "4412900"
  },
  {
    "text": "So the basic option, this\nis really the baseline is a multi head\narchitecture, where",
    "start": "4412900",
    "end": "4418050"
  },
  {
    "text": "they passes the input features\ninto a shared bottom layer,",
    "start": "4418050",
    "end": "4424469"
  },
  {
    "text": "and then how these\ntask specific heads that are predicting different\nengagement and satisfaction",
    "start": "4424470",
    "end": "4430949"
  },
  {
    "text": "measures. They found that this\ncan harm learning when the correlation\nbetween tasks is low.",
    "start": "4430950",
    "end": "4437850"
  },
  {
    "text": "And they're actually\ngoing to try to improve upon this\narchitecture right here by actually allowing the model\nto share a little bit less",
    "start": "4437850",
    "end": "4444150"
  },
  {
    "text": "between the tasks. And so what they\nchoose to do is they use an architecture, which\nthey refer to as the multi gate",
    "start": "4444150",
    "end": "4451130"
  },
  {
    "text": "mixture of experts model. And what essentially this\nis going to look like is there is still going to\nbe one shared bottom layer.",
    "start": "4451130",
    "end": "4458540"
  },
  {
    "text": "But there's going to be a\nnumber of different experts. And it's going to try to\nactually have the model choose",
    "start": "4458540",
    "end": "4463880"
  },
  {
    "text": "how it uses those experts each\nof those parts of the model",
    "start": "4463880",
    "end": "4469010"
  },
  {
    "text": "based on what it\nfinds works well. And essentially, what\nthis will try to do",
    "start": "4469010",
    "end": "4474340"
  },
  {
    "text": "is to allow different\nparts of the network to specialize for\ndifferent tasks while also having it figure out\nwhether it's useful to reuse",
    "start": "4474340",
    "end": "4481700"
  },
  {
    "text": "some components. So specifically, what this looks\nlike is after the shared bottom",
    "start": "4481700",
    "end": "4487400"
  },
  {
    "text": "layer, you have a set of\nexpert neural networks.",
    "start": "4487400",
    "end": "4492420"
  },
  {
    "text": "So these are different\nmodules denoted by AI. And for a given set of features\nfor input X and task K,",
    "start": "4492420",
    "end": "4503540"
  },
  {
    "text": "we're going to try\nto basically predict which expert we want to use for\nthat input and for that task.",
    "start": "4503540",
    "end": "4512875"
  },
  {
    "text": "And so the way that we're\ngoing to do this is we're going to pass this through\na softmax function. You can think of\na softmax function",
    "start": "4512875",
    "end": "4518360"
  },
  {
    "text": "as something that's trying\nto predict a one hot vector, but in a soft way, so that we\ncan differentiate through it.",
    "start": "4518360",
    "end": "4523869"
  },
  {
    "text": "So in particular, this\nis going to give us a probability distribution\nover the experts that we want to use.",
    "start": "4523870",
    "end": "4530190"
  },
  {
    "text": "And then once we have this\nprobability distribution, we're going to wait the\npredictions of the experts by these probabilities.",
    "start": "4530190",
    "end": "4538040"
  },
  {
    "text": "And then once we have the\noutput of this weighted expert",
    "start": "4538040",
    "end": "4543410"
  },
  {
    "text": "outputs, we'll then compute\nthe output from there. And in their experiments, they\nimplemented this in Tensorflow",
    "start": "4543410",
    "end": "4550190"
  },
  {
    "text": "with TPUs. They trained on videos\nin temporal order because they have a\nton of video data. And so they're going to be\nrunning training continuously",
    "start": "4550190",
    "end": "4557180"
  },
  {
    "text": "to consume the\nnewly arriving data. And then they did online\nA/B testing in comparison",
    "start": "4557180",
    "end": "4562310"
  },
  {
    "text": "to a production system. ",
    "start": "4562310",
    "end": "4567500"
  },
  {
    "text": "And then here, also model\ncomputational efficiency matters as well. And in the results, they\nfound that this mixture",
    "start": "4567500",
    "end": "4575500"
  },
  {
    "text": "of expert models\nwith eight experts is able to do 3% better\non satisfaction metrics",
    "start": "4575500",
    "end": "4581140"
  },
  {
    "text": "and 0.45% better on engagement\nmetrics, which is actually pretty substantial given the\nscale of this kind of system.",
    "start": "4581140",
    "end": "4590212"
  },
  {
    "text": "And this is in comparison\nto a shared bottom network. And you can also\nlook at how it's",
    "start": "4590212",
    "end": "4595239"
  },
  {
    "text": "utilizing the different\nexperts for different tasks. And we see that there\nis some specialization. For example, expert 7 is used\na lot for satisfaction task 4.",
    "start": "4595240",
    "end": "4603517"
  },
  {
    "text": "But there's also a\nconsiderable amount of sharing. For example, expert 5 is\nused for a lot of the tasks. ",
    "start": "4603517",
    "end": "4611810"
  },
  {
    "text": "Cool. So we're basically out of time. So to recap the\nlecture, we talked",
    "start": "4611810",
    "end": "4617355"
  },
  {
    "text": "about multi-task\nlearning and how it learns a neural\nnetwork conditioned on zi. We talked about how the\nchoice of the task weighting",
    "start": "4617355",
    "end": "4623260"
  },
  {
    "text": "is going to affect the\nprioritization of the tasks, and we also talked about\nhow conditioning on zi",
    "start": "4623260",
    "end": "4628510"
  },
  {
    "text": "will affect how the\nparameters are shared. And if you observe\nnegative transfer, it's helpful to share less.",
    "start": "4628510",
    "end": "4633620"
  },
  {
    "text": "And if you observe\npositive transfer, it's helpful to share, but\npotentially try sharing more, or if you observe overfitting.",
    "start": "4633620",
    "end": "4641960"
  },
  {
    "text": "So really these are\nthe key design choices when it comes to multi-task\nlearning systems. And next time, we'll start\nto cover transfer learning",
    "start": "4641960",
    "end": "4649180"
  },
  {
    "text": "and get to some cool\nlearning topics as well. ",
    "start": "4649180",
    "end": "4657000"
  }
]
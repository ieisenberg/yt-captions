[
  {
    "text": "Well, good to see you again.",
    "start": "0",
    "end": "2690"
  },
  {
    "text": "Sorry you got two\nold guys again.",
    "start": "2690",
    "end": "6410"
  },
  {
    "text": "In this section, we're going\nto talk about fitting nonlinear",
    "start": "6410",
    "end": "10100"
  },
  {
    "text": "functions and nonlinear models.",
    "start": "10100",
    "end": "12270"
  },
  {
    "text": "Up to now, we focused\non linear models.",
    "start": "12270",
    "end": "14520"
  },
  {
    "text": "And what you'll see is that\nit's actually very easy",
    "start": "14520",
    "end": "17720"
  },
  {
    "text": "to bring non-linearity into\nyour modeling in somewhat",
    "start": "17720",
    "end": "21019"
  },
  {
    "text": "seamless way.",
    "start": "21020",
    "end": "22550"
  },
  {
    "text": "And you'll see the tools are\nalmost as easy as they were when",
    "start": "22550",
    "end": "25340"
  },
  {
    "text": "we were fitting linear models.",
    "start": "25340",
    "end": "26940"
  },
  {
    "text": "And we'll talk about a\nhierarchy of methods,",
    "start": "26940",
    "end": "29390"
  },
  {
    "text": "some completely straightforward\nand some slightly more",
    "start": "29390",
    "end": "33410"
  },
  {
    "text": "sophisticated.",
    "start": "33410",
    "end": "34618"
  },
  {
    "text": "And some of what you'll actually\nsee today, for Trevor and I,",
    "start": "34618",
    "end": "37160"
  },
  {
    "text": "is somewhat historical.",
    "start": "37160",
    "end": "38233"
  },
  {
    "text": "The very first\npaper we ever wrote",
    "start": "38233",
    "end": "39650"
  },
  {
    "text": "together was called\nGeneralized Additive Models",
    "start": "39650",
    "end": "43430"
  },
  {
    "text": "as graduate students\nhere at Stanford.",
    "start": "43430",
    "end": "45060"
  },
  {
    "text": "And the last part of\nthis section, we'll",
    "start": "45060",
    "end": "47060"
  },
  {
    "text": "talk about generalized\nadditive models, which",
    "start": "47060",
    "end": "48935"
  },
  {
    "text": "are a way of using the\ntools for non-linearity",
    "start": "48935",
    "end": "51920"
  },
  {
    "text": "for more than one predictor.",
    "start": "51920",
    "end": "53920"
  },
  {
    "text": "And you know, Rob, it\njust occurred to me",
    "start": "53920",
    "end": "56780"
  },
  {
    "text": "that that paper we\nwrote 30 years ago.",
    "start": "56780",
    "end": "59660"
  },
  {
    "text": "It's still good.",
    "start": "59660",
    "end": "60820"
  },
  {
    "text": "It's still a good paper.",
    "start": "60820",
    "end": "63280"
  },
  {
    "text": "So here we go.",
    "start": "63280",
    "end": "65670"
  },
  {
    "text": "Well, the first fact is,\nthe truth is never linear.",
    "start": "65670",
    "end": "72060"
  },
  {
    "text": "That's a shocking thing for a\nstatistics professor to say,",
    "start": "72060",
    "end": "77200"
  },
  {
    "text": "Or almost never.",
    "start": "77200",
    "end": "78990"
  },
  {
    "text": "Well, that is the truth.",
    "start": "78990",
    "end": "80950"
  },
  {
    "text": "Linearity is an approximation,\nand often a linearity assumption",
    "start": "80950",
    "end": "86399"
  },
  {
    "text": "is good enough.",
    "start": "86400",
    "end": "87220"
  },
  {
    "text": "And that's why we\nlike the linear model.",
    "start": "87220",
    "end": "90425"
  },
  {
    "text": "The approximation\nis good enough,",
    "start": "90425",
    "end": "91800"
  },
  {
    "text": "and it gives us a\nnice simple summary.",
    "start": "91800",
    "end": "93940"
  },
  {
    "text": "But we need to go\nbeyond linearity often,",
    "start": "93940",
    "end": "97110"
  },
  {
    "text": "and we have lots of\ntools to do that.",
    "start": "97110",
    "end": "99190"
  },
  {
    "text": "And in this section, we're going\nto talk about some of those.",
    "start": "99190",
    "end": "102160"
  },
  {
    "text": "So there's the list, polynomial\nstep, function splines,",
    "start": "102160",
    "end": "106050"
  },
  {
    "text": "local regression, and\ngeneralized additive models,",
    "start": "106050",
    "end": "109320"
  },
  {
    "text": "increasing in complexity\nas we go down the list.",
    "start": "109320",
    "end": "113220"
  },
  {
    "text": "And as you'll see,\nthey just as easy",
    "start": "113220",
    "end": "115290"
  },
  {
    "text": "to work with as linear models.",
    "start": "115290",
    "end": "119890"
  },
  {
    "text": "So polynomial regression\nwe've really covered before.",
    "start": "119890",
    "end": "124360"
  },
  {
    "text": "And when we introduce\nthese nonlinear methods,",
    "start": "124360",
    "end": "127870"
  },
  {
    "text": "we're going to introduce\nthem for the most part,",
    "start": "127870",
    "end": "130119"
  },
  {
    "text": "except when we get to\ngeneralized additive models,",
    "start": "130120",
    "end": "132730"
  },
  {
    "text": "with a single\nvariable, but you'll",
    "start": "132730",
    "end": "135370"
  },
  {
    "text": "see it's just as easy to do\nit in many variables as well.",
    "start": "135370",
    "end": "139470"
  },
  {
    "text": "And so here;s a polynomial\nregression model.",
    "start": "139470",
    "end": "144060"
  },
  {
    "text": "We've m not only a linear term,\nbut we've got polynomial terms",
    "start": "144060",
    "end": "149010"
  },
  {
    "text": "as well, so there's x\nsquared, x cubed, and so on,",
    "start": "149010",
    "end": "151980"
  },
  {
    "text": "and we can go up to\nwhatever degree we like.",
    "start": "151980",
    "end": "154750"
  },
  {
    "text": "And for the linear model, it's\nlinear in the coefficients,",
    "start": "154750",
    "end": "160320"
  },
  {
    "text": "but it's a nonlinear\nfunction of x.",
    "start": "160320",
    "end": "162960"
  },
  {
    "text": "And in the left panel,\nwe see on the wage data,",
    "start": "162960",
    "end": "166650"
  },
  {
    "text": "polynomial function fitted to\nage, that's a third degree,",
    "start": "166650",
    "end": "170459"
  },
  {
    "text": "I believe, polynomial.",
    "start": "170460",
    "end": "172460"
  },
  {
    "text": "And you see the fitted\nfunction, and you",
    "start": "172460",
    "end": "175250"
  },
  {
    "text": "see pointwise\nstandard error bands,",
    "start": "175250",
    "end": "177540"
  },
  {
    "text": "that's these dotted bands here.",
    "start": "177540",
    "end": "179700"
  },
  {
    "text": "That's plus and minus\n1 standard error.",
    "start": "179700",
    "end": "183280"
  },
  {
    "text": "And it's a nonlinear\nfunction, it",
    "start": "183280",
    "end": "185290"
  },
  {
    "text": "seems, to capture what's\ngoing on in the data.",
    "start": "185290",
    "end": "187689"
  },
  {
    "text": "I noticed the standard error\nbands are wider at the ends",
    "start": "187690",
    "end": "190300"
  },
  {
    "text": "there, Trevor, why is that?",
    "start": "190300",
    "end": "193360"
  },
  {
    "text": "That's a good point, Rob.",
    "start": "193360",
    "end": "194500"
  },
  {
    "text": "And it's called leverage.",
    "start": "194500",
    "end": "197765"
  },
  {
    "text": "The points right at\nthe end, you notice",
    "start": "197765",
    "end": "199390"
  },
  {
    "text": "the data thins out at the\nend, so there's not so much",
    "start": "199390",
    "end": "201597"
  },
  {
    "text": "data there.",
    "start": "201598",
    "end": "202490"
  },
  {
    "text": "And so the information for\nfitting the curve at the end",
    "start": "202490",
    "end": "206080"
  },
  {
    "text": "is much less, so the\nstandard error gets wider.",
    "start": "206080",
    "end": "209290"
  },
  {
    "text": "But also, points\nat the end, we call",
    "start": "209290",
    "end": "212409"
  },
  {
    "text": "it wagging the tail of the dog.",
    "start": "212410",
    "end": "214970"
  },
  {
    "text": "A polynomial is a very\nflexible function,",
    "start": "214970",
    "end": "217900"
  },
  {
    "text": "and it's especially\nflexible at the end,",
    "start": "217900",
    "end": "220810"
  },
  {
    "text": "and those tails\ntend to wag around,",
    "start": "220810",
    "end": "222610"
  },
  {
    "text": "and the standard\nerror indicates it.",
    "start": "222610",
    "end": "225610"
  },
  {
    "text": "In fact, in this figure\non the right here,",
    "start": "225610",
    "end": "228580"
  },
  {
    "text": "we fit, using a polynomial\nto fit a logistic regression.",
    "start": "228580",
    "end": "232690"
  },
  {
    "text": "And to do that in this section,\nwe just turn wage into a binary",
    "start": "232690",
    "end": "237040"
  },
  {
    "text": "variable by looking at whether\nwage is bigger than 250k or not.",
    "start": "237040",
    "end": "242739"
  },
  {
    "text": "And so that's a\nlogistic regression now,",
    "start": "242740",
    "end": "246100"
  },
  {
    "text": "trying to model the\nprobability of that event.",
    "start": "246100",
    "end": "248620"
  },
  {
    "text": "And notice how wide the standard\nerrors are at the end right now.",
    "start": "248620",
    "end": "252043"
  },
  {
    "text": "When I first saw that,\nI thought it was crazy,",
    "start": "252043",
    "end": "253960"
  },
  {
    "text": "but then I realized the vertical\nscale is pretty stretched,",
    "start": "253960",
    "end": "257209"
  },
  {
    "text": "so it's only ranging up to 0.20.",
    "start": "257209",
    "end": "259940"
  },
  {
    "text": "A good point, Rob.",
    "start": "259940",
    "end": "261320"
  },
  {
    "text": "If you saw that from 0 to 1, it\nwould look a lot more narrow.",
    "start": "261320",
    "end": "264920"
  },
  {
    "text": "That's a very good point.",
    "start": "264920",
    "end": "266300"
  },
  {
    "text": "And that's something\nto always bear",
    "start": "266300",
    "end": "267758"
  },
  {
    "text": "in mind, the plotting scales.",
    "start": "267758",
    "end": "269889"
  },
  {
    "text": "It's important how you\ndecide on what scales to use,",
    "start": "269890",
    "end": "274130"
  },
  {
    "text": "and in this case, as Rob said,\nit's only going up to 0.2.",
    "start": "274130",
    "end": "278170"
  },
  {
    "text": "What you also notice here is,\nwe've got this so-called rug",
    "start": "278170",
    "end": "281830"
  },
  {
    "text": "plot, we see at the\nbottom of the plot",
    "start": "281830",
    "end": "284259"
  },
  {
    "text": "where all the zeros occurred,\nthat's these little spikes here,",
    "start": "284260",
    "end": "288080"
  },
  {
    "text": "it's uniformly across the range.",
    "start": "288080",
    "end": "290400"
  },
  {
    "text": "And then up above, we've got\nwhere all the ones occur.",
    "start": "290400",
    "end": "292669"
  },
  {
    "text": "And you'll notice there's one\nin the middle of the range,",
    "start": "292670",
    "end": "295790"
  },
  {
    "text": "and not many ones at the end.",
    "start": "295790",
    "end": "297570"
  },
  {
    "text": "So there's really not any data\nat all to estimate this function",
    "start": "297570",
    "end": "301190"
  },
  {
    "text": "right at the end.",
    "start": "301190",
    "end": "301990"
  },
  {
    "start": "301990",
    "end": "304590"
  },
  {
    "text": "So in detail, with polynomial\nregression, what you do",
    "start": "304590",
    "end": "307860"
  },
  {
    "text": "is you create new variables.",
    "start": "307860",
    "end": "309723"
  },
  {
    "text": "And in this case, they're\njust transformations",
    "start": "309723",
    "end": "311639"
  },
  {
    "text": "of the original variables, so\nwe make x1 is the original x,",
    "start": "311640",
    "end": "315855"
  },
  {
    "text": "x2 is x squared and so on.",
    "start": "315855",
    "end": "317595"
  },
  {
    "text": "And then just treat the problem\nas a multiple linear regression",
    "start": "317595",
    "end": "320220"
  },
  {
    "text": "model with these new\nderived variables.",
    "start": "320220",
    "end": "323740"
  },
  {
    "text": "And in this case,\nwe're not really",
    "start": "323740",
    "end": "325270"
  },
  {
    "text": "interested in the\ncoefficients, we're",
    "start": "325270",
    "end": "327280"
  },
  {
    "text": "more interested in\nthe fitted functions",
    "start": "327280",
    "end": "329680"
  },
  {
    "text": "at any particular value x0.",
    "start": "329680",
    "end": "332830"
  },
  {
    "text": "we're interested in\nthe composed function.",
    "start": "332830",
    "end": "334990"
  },
  {
    "text": "So once we fit the model,\nwe might say, well,",
    "start": "334990",
    "end": "337479"
  },
  {
    "text": "what does the function look\nlike at a new value x0.",
    "start": "337480",
    "end": "341090"
  },
  {
    "text": "And so the\ncoefficients themselves",
    "start": "341090",
    "end": "342940"
  },
  {
    "text": "aren't that interesting.",
    "start": "342940",
    "end": "345590"
  },
  {
    "text": "And since the fitted\nfunction is actually",
    "start": "345590",
    "end": "348470"
  },
  {
    "text": "a linear function of the\ncoefficients, the beta L hats,",
    "start": "348470",
    "end": "353630"
  },
  {
    "text": "we can get a simple expression\nfor the pointwise variances.",
    "start": "353630",
    "end": "357850"
  },
  {
    "text": "So you say what is the variance\nof the fitted function at x0.",
    "start": "357850",
    "end": "362410"
  },
  {
    "text": "Well, that fitted function at\nx0 is just a linear combination",
    "start": "362410",
    "end": "368170"
  },
  {
    "text": "of the parameters.",
    "start": "368170",
    "end": "370360"
  },
  {
    "text": "And so, by using the covariance\nmatrix of the fitted parameters,",
    "start": "370360",
    "end": "375250"
  },
  {
    "text": "you can then get a\nsimple expression",
    "start": "375250",
    "end": "377830"
  },
  {
    "text": "for the variance of\nthis fitted value.",
    "start": "377830",
    "end": "379879"
  },
  {
    "text": "We describe this in\nmore detail in the book,",
    "start": "379880",
    "end": "381790"
  },
  {
    "text": "in somewhat more detail.",
    "start": "381790",
    "end": "383140"
  },
  {
    "text": "And it seems in the\nplot, we actually",
    "start": "383140",
    "end": "387200"
  },
  {
    "text": "plot the fitted function plus\nor minus 2 standard errors,",
    "start": "387200",
    "end": "390000"
  },
  {
    "text": "I said one earlier.",
    "start": "390000",
    "end": "391520"
  },
  {
    "text": "And so getting these\npointwise standard errors",
    "start": "391520",
    "end": "393979"
  },
  {
    "text": "is fairly straightforward.",
    "start": "393980",
    "end": "397900"
  },
  {
    "text": "Pointwise means that\nthe standard error",
    "start": "397900",
    "end": "401550"
  },
  {
    "text": "band is pointwise, so\nthe band is showing you",
    "start": "401550",
    "end": "404819"
  },
  {
    "text": "at any given point what\nthe standard error is.",
    "start": "404820",
    "end": "407140"
  },
  {
    "text": "This is not to be confused with\nglobal confidence bands, which",
    "start": "407140",
    "end": "411150"
  },
  {
    "text": "is another story.",
    "start": "411150",
    "end": "411965"
  },
  {
    "start": "411965",
    "end": "414540"
  },
  {
    "text": "The other thing is\nwhat degree do we use.",
    "start": "414540",
    "end": "418410"
  },
  {
    "text": "So here we were actually using\na fourth degree polynomial.",
    "start": "418410",
    "end": "422220"
  },
  {
    "text": "I said third, but we use fourth.",
    "start": "422220",
    "end": "425520"
  },
  {
    "text": "So that d is\nobviously a parameter",
    "start": "425520",
    "end": "427710"
  },
  {
    "text": "and often we just pick d to be\nsome small number, like 2, or 3,",
    "start": "427710",
    "end": "431729"
  },
  {
    "text": "4 in this case.",
    "start": "431730",
    "end": "433080"
  },
  {
    "text": "Or otherwise, we can actually\nselect d by cross-validation,",
    "start": "433080",
    "end": "436319"
  },
  {
    "text": "think of it as a\ntuning parameter.",
    "start": "436320",
    "end": "437950"
  },
  {
    "start": "437950",
    "end": "443030"
  },
  {
    "text": "For logistic\nregression, the details",
    "start": "443030",
    "end": "446780"
  },
  {
    "text": "are pretty much the same.",
    "start": "446780",
    "end": "448940"
  },
  {
    "text": "As I said in the figure, this\nis what we were modeling.",
    "start": "448940",
    "end": "452480"
  },
  {
    "text": "And so there's our\ninverse logistic function.",
    "start": "452480",
    "end": "455640"
  },
  {
    "text": "And it's just a polynomial\ninstead of a linear function.",
    "start": "455640",
    "end": "459470"
  },
  {
    "text": "And one small detail\nthat's somewhat important",
    "start": "459470",
    "end": "463330"
  },
  {
    "text": "is to get confidence intervals.",
    "start": "463330",
    "end": "465819"
  },
  {
    "text": "What you do is,\nif you try and get",
    "start": "465820",
    "end": "467800"
  },
  {
    "text": "confidence intervals\nfor the probabilities",
    "start": "467800",
    "end": "470440"
  },
  {
    "text": "using direct methods, you\nmight get outside of the range",
    "start": "470440",
    "end": "473440"
  },
  {
    "text": "0 and 1.",
    "start": "473440",
    "end": "474500"
  },
  {
    "text": "So what you do is you\nget confidence intervals",
    "start": "474500",
    "end": "476530"
  },
  {
    "text": "for the fitted logit,\nand then you put them,",
    "start": "476530",
    "end": "479200"
  },
  {
    "text": "the upper and lower\nconfidence band end",
    "start": "479200",
    "end": "481900"
  },
  {
    "text": "points through the inverse\nlogit transformation.",
    "start": "481900",
    "end": "484820"
  },
  {
    "text": "And those give you the\nconfidence intervals,",
    "start": "484820",
    "end": "490370"
  },
  {
    "text": "or in this case, for the\nfitted probabilities,",
    "start": "490370",
    "end": "494260"
  },
  {
    "text": "so that's a useful\ntrick to bear in mind.",
    "start": "494260",
    "end": "496975"
  },
  {
    "start": "496975",
    "end": "500010"
  },
  {
    "text": "OK.",
    "start": "500010",
    "end": "500510"
  },
  {
    "text": "A few other points.",
    "start": "500510",
    "end": "501600"
  },
  {
    "start": "501600",
    "end": "505920"
  },
  {
    "text": "So we've just talked about\nwith a single variable.",
    "start": "505920",
    "end": "508042"
  },
  {
    "text": "For several variables,\nyou can do it separately",
    "start": "508042",
    "end": "510000"
  },
  {
    "text": "on each variable.",
    "start": "510000",
    "end": "511560"
  },
  {
    "text": "So you just generate\nthese transformations",
    "start": "511560",
    "end": "513809"
  },
  {
    "text": "on each variable.",
    "start": "513809",
    "end": "514799"
  },
  {
    "text": "And then just stack them\ntogether in one big matrix.",
    "start": "514799",
    "end": "517229"
  },
  {
    "text": "And fit a big linear model in\nall these new derived variables.",
    "start": "517230",
    "end": "521349"
  },
  {
    "text": "So if you've got\na variable x, you",
    "start": "521350",
    "end": "523798"
  },
  {
    "text": "might make x1, x2,\nup to, say, x4.",
    "start": "523799",
    "end": "527320"
  },
  {
    "text": "If you have another variable\nz, you can make z1 up to z4.",
    "start": "527320",
    "end": "530628"
  },
  {
    "text": "Then you just stack\nthem all together",
    "start": "530628",
    "end": "532170"
  },
  {
    "text": "and make a big model matrix\nand fit your linear model.",
    "start": "532170",
    "end": "535959"
  },
  {
    "text": "And then you have to unpack the\npieces to compose the functions.",
    "start": "535960",
    "end": "539410"
  },
  {
    "text": "And we'll see later on that\nthe GAM technology, Generalized",
    "start": "539410",
    "end": "543060"
  },
  {
    "text": "Additive Model technology, helps\nyou do this in a seamless way.",
    "start": "543060",
    "end": "548730"
  },
  {
    "text": "There's some caveats with\npolynomial regression.",
    "start": "548730",
    "end": "552360"
  },
  {
    "text": "Polynomials, as I\nmentioned before,",
    "start": "552360",
    "end": "554310"
  },
  {
    "text": "have notorious tail behavior.",
    "start": "554310",
    "end": "556150"
  },
  {
    "text": "Very bad for extrapolation.",
    "start": "556150",
    "end": "557800"
  },
  {
    "text": "Those tails tend\nto wiggle around.",
    "start": "557800",
    "end": "559380"
  },
  {
    "text": "And you really wouldn't\nwant to trust predictions",
    "start": "559380",
    "end": "561780"
  },
  {
    "text": "beyond the range\nof the data or even",
    "start": "561780",
    "end": "563640"
  },
  {
    "text": "too near the ends of the data.",
    "start": "563640",
    "end": "567610"
  },
  {
    "text": "And finally, fitting a\npolynomial in R is very simple.",
    "start": "567610",
    "end": "571700"
  },
  {
    "text": "Here's a simple\nexpression for fitting",
    "start": "571700",
    "end": "574070"
  },
  {
    "text": "the polynomial in x to y.",
    "start": "574070",
    "end": "576440"
  },
  {
    "text": "This is the model\nformula that you'd use.",
    "start": "576440",
    "end": "578350"
  },
  {
    "text": "There's a poly\nfunction that generates",
    "start": "578350",
    "end": "580360"
  },
  {
    "text": "these transformations for you.",
    "start": "580360",
    "end": "582649"
  },
  {
    "text": "And it's as simple as that.",
    "start": "582650",
    "end": "584800"
  },
  {
    "text": "And we'll see in the lab.",
    "start": "584800",
    "end": "587830"
  },
  {
    "text": "We'll get some\nexperience with that.",
    "start": "587830",
    "end": "589620"
  },
  {
    "start": "589620",
    "end": "595070"
  },
  {
    "text": "Step functions.",
    "start": "595070",
    "end": "596040"
  },
  {
    "text": "That's another way of\nfitting non-linearities.",
    "start": "596040",
    "end": "598589"
  },
  {
    "text": "Especially popular in\nepidemiology and biostatistics",
    "start": "598590",
    "end": "601760"
  },
  {
    "text": "in the last 20 or so years.",
    "start": "601760",
    "end": "605450"
  },
  {
    "text": "And what you do is\nyou cut your variable,",
    "start": "605450",
    "end": "608180"
  },
  {
    "text": "your continuous variable,\ninto discrete subranges.",
    "start": "608180",
    "end": "615300"
  },
  {
    "text": "For example, here we've cut\nage at 35 and again at 65.",
    "start": "615300",
    "end": "625010"
  },
  {
    "text": "There's actually a\ncut at 50 as well.",
    "start": "625010",
    "end": "627150"
  },
  {
    "text": "You can't see it here.",
    "start": "627150",
    "end": "628260"
  },
  {
    "text": "And then, the idea is\nyou fit a constant model",
    "start": "628260",
    "end": "631520"
  },
  {
    "text": "in each of the regions.",
    "start": "631520",
    "end": "633360"
  },
  {
    "text": "So it's a piecewise\nconstant model.",
    "start": "633360",
    "end": "636880"
  },
  {
    "text": "So you can see here, when\nyou fit it and plot them",
    "start": "636880",
    "end": "641280"
  },
  {
    "text": "all together, you see the\nconstant in the first range,",
    "start": "641280",
    "end": "644020"
  },
  {
    "text": "the second range.",
    "start": "644020",
    "end": "645000"
  },
  {
    "text": "The third range\nis hardly visible",
    "start": "645000",
    "end": "647790"
  },
  {
    "text": "that it's different than\nin the fourth range.",
    "start": "647790",
    "end": "650170"
  },
  {
    "text": "And so this becomes,\nwhen put together",
    "start": "650170",
    "end": "652200"
  },
  {
    "text": "as a non-linear function, it's\na piecewise constant function.",
    "start": "652200",
    "end": "657580"
  },
  {
    "text": "And this is often useful\nif there's some natural cut",
    "start": "657580",
    "end": "660760"
  },
  {
    "text": "points that are of interest.",
    "start": "660760",
    "end": "662380"
  },
  {
    "text": "So what is the average\nincome for somebody",
    "start": "662380",
    "end": "665980"
  },
  {
    "text": "below the age of 35?",
    "start": "665980",
    "end": "667959"
  },
  {
    "text": "So you can read it\nstraight off the plot.",
    "start": "667960",
    "end": "670780"
  },
  {
    "text": "This is often good for summaries\nin newspapers and reports",
    "start": "670780",
    "end": "673990"
  },
  {
    "text": "and things like that, which\nhas led to its popularity.",
    "start": "673990",
    "end": "677580"
  },
  {
    "text": "And to do it is just as easy\nas it was for polynomials.",
    "start": "677580",
    "end": "684990"
  },
  {
    "text": "If you think of this\nfunction over here,",
    "start": "684990",
    "end": "687480"
  },
  {
    "text": "it's a binary variable.",
    "start": "687480",
    "end": "691000"
  },
  {
    "text": "You make a binary variable.",
    "start": "691000",
    "end": "692730"
  },
  {
    "text": "Is x less than 35?",
    "start": "692730",
    "end": "695459"
  },
  {
    "text": "If yes, you make it 1.",
    "start": "695460",
    "end": "696850"
  },
  {
    "text": "If not, you make it a 0.",
    "start": "696850",
    "end": "698440"
  },
  {
    "text": "And for each of\nthese, it's the same.",
    "start": "698440",
    "end": "701170"
  },
  {
    "text": "And so you create a bunch of\ndummy variables, 0, 1 variables.",
    "start": "701170",
    "end": "705079"
  },
  {
    "text": "And then you just fit\nthose with a linear model.",
    "start": "705080",
    "end": "707080"
  },
  {
    "text": "You can always see\nthe advantage this",
    "start": "707080",
    "end": "708120"
  },
  {
    "text": "has over polynomials, right?",
    "start": "708120",
    "end": "709720"
  },
  {
    "text": "This is local.",
    "start": "709720",
    "end": "710889"
  },
  {
    "text": "Remember, with polynomials,\nit's a single function",
    "start": "710890",
    "end": "713580"
  },
  {
    "text": "for the whole range\nof the x variable.",
    "start": "713580",
    "end": "715660"
  },
  {
    "text": "So for example, if I change\na point on the left side,",
    "start": "715660",
    "end": "717972"
  },
  {
    "text": "it could potentially\nchange the fit",
    "start": "717972",
    "end": "719430"
  },
  {
    "text": "on the right side quite\na bit for polynomials.",
    "start": "719430",
    "end": "722010"
  },
  {
    "text": "That's a good point, Rob,\nwhich I forgot to say.",
    "start": "722010",
    "end": "724150"
  },
  {
    "text": "Yeah.",
    "start": "724150",
    "end": "724650"
  },
  {
    "text": "But for step\nfunctions, a point only",
    "start": "724650",
    "end": "729300"
  },
  {
    "text": "affects the fit in the partition\nit's sitting in and not",
    "start": "729300",
    "end": "733170"
  },
  {
    "text": "the other partitions.",
    "start": "733170",
    "end": "734910"
  },
  {
    "text": "That's a great point.",
    "start": "734910",
    "end": "736879"
  },
  {
    "text": "And thanks for reminding us.",
    "start": "736880",
    "end": "739740"
  },
  {
    "text": "The polynomial, the parameters\naffect the function everywhere",
    "start": "739740",
    "end": "743130"
  },
  {
    "text": "and can have dramatic effects.",
    "start": "743130",
    "end": "747150"
  },
  {
    "text": "Here, we've done\nthe same thing as we",
    "start": "747150",
    "end": "748890"
  },
  {
    "text": "did before for the\nlogistic regression,",
    "start": "748890",
    "end": "750720"
  },
  {
    "text": "but with a piecewise\nconstant function.",
    "start": "750720",
    "end": "752930"
  },
  {
    "text": "Everything else is the same.",
    "start": "752930",
    "end": "754140"
  },
  {
    "text": "But the fitted function\nis kind of blocky",
    "start": "754140",
    "end": "756880"
  },
  {
    "text": "and maybe considered\nnot as attractive.",
    "start": "756880",
    "end": "761900"
  },
  {
    "start": "761900",
    "end": "764550"
  },
  {
    "text": "Step functions are\neasy to work with.",
    "start": "764550",
    "end": "766360"
  },
  {
    "text": "As I said, you make a\nbunch of dummy variables",
    "start": "766360",
    "end": "768510"
  },
  {
    "text": "and just fit the linear model.",
    "start": "768510",
    "end": "771560"
  },
  {
    "text": "It's also a useful way\nof creating interactions",
    "start": "771560",
    "end": "774529"
  },
  {
    "text": "that are easy to interpret.",
    "start": "774530",
    "end": "776470"
  },
  {
    "text": "So, for example, think of the\ninteraction effect of year",
    "start": "776470",
    "end": "779540"
  },
  {
    "text": "and age in a linear model.",
    "start": "779540",
    "end": "781699"
  },
  {
    "text": "So what you can do\nis, for example,",
    "start": "781700",
    "end": "784220"
  },
  {
    "text": "make a dummy variable of year.",
    "start": "784220",
    "end": "786360"
  },
  {
    "text": "So let's say cut year\nto less than 2005.",
    "start": "786360",
    "end": "792130"
  },
  {
    "text": "And have another one here\nbigger than or equal to 2005.",
    "start": "792130",
    "end": "795850"
  },
  {
    "text": "And then, if you multiply that\nwith age, what you've done",
    "start": "795850",
    "end": "799029"
  },
  {
    "text": "is create an interaction.",
    "start": "799030",
    "end": "800780"
  },
  {
    "text": "And that will fit a\ndifferent linear model",
    "start": "800780",
    "end": "804190"
  },
  {
    "text": "as a function of age for people\nwho worked before 2005 and those",
    "start": "804190",
    "end": "810520"
  },
  {
    "text": "after 2005.",
    "start": "810520",
    "end": "812630"
  },
  {
    "text": "And so, visually, that's nice.",
    "start": "812630",
    "end": "815030"
  },
  {
    "text": "You'll see two different\nlinear functions.",
    "start": "815030",
    "end": "816780"
  },
  {
    "text": "It's the easy way of seeing\nthe effect of an interaction.",
    "start": "816780",
    "end": "819450"
  },
  {
    "start": "819450",
    "end": "821970"
  },
  {
    "text": "And in R, creating these dummy\nvariables is really easy.",
    "start": "821970",
    "end": "826769"
  },
  {
    "text": "Creating an indicator\nfunction is pretty much",
    "start": "826770",
    "end": "829470"
  },
  {
    "text": "the same expression\nwe've shown up until now.",
    "start": "829470",
    "end": "832149"
  },
  {
    "text": "There is a function I in R,\nwhich is basically an indicator.",
    "start": "832150",
    "end": "836610"
  },
  {
    "text": "And year less than 25\nturns into a logical.",
    "start": "836610",
    "end": "840660"
  },
  {
    "text": "But when wrapped\nin the indicator,",
    "start": "840660",
    "end": "842115"
  },
  {
    "text": "it is essentially\na 0 1 variable.",
    "start": "842115",
    "end": "845399"
  },
  {
    "text": "And if you want to cut\nin more than one place,",
    "start": "845400",
    "end": "848400"
  },
  {
    "text": "there's a function called cut.",
    "start": "848400",
    "end": "849910"
  },
  {
    "text": "So you can cut age and you\ngive it the cut points.",
    "start": "849910",
    "end": "852810"
  },
  {
    "text": "You need to give cut the\ntwo boundary points as well.",
    "start": "852810",
    "end": "855930"
  },
  {
    "text": "So in this case,\n18 and 90, those",
    "start": "855930",
    "end": "857940"
  },
  {
    "text": "are the ranges of\nthe ages, well,",
    "start": "857940",
    "end": "859890"
  },
  {
    "text": "beyond the age range actually,\nand then the interior cut",
    "start": "859890",
    "end": "862780"
  },
  {
    "text": "points.",
    "start": "862780",
    "end": "863280"
  },
  {
    "text": "And it will create a factor\nfor you, an ordered factor,",
    "start": "863280",
    "end": "866640"
  },
  {
    "text": "that cuts the variable\ninto those bins.",
    "start": "866640",
    "end": "868880"
  },
  {
    "start": "868880",
    "end": "872560"
  },
  {
    "text": "Now, the choice\nof the cut points,",
    "start": "872560",
    "end": "874300"
  },
  {
    "text": "or knots, as we're\ngoing to call them,",
    "start": "874300",
    "end": "876040"
  },
  {
    "text": "can be a little problematic.",
    "start": "876040",
    "end": "878709"
  },
  {
    "text": "For creating non-linearities,\nsmooth alternatives",
    "start": "878710",
    "end": "881800"
  },
  {
    "text": "are available.",
    "start": "881800",
    "end": "882580"
  },
  {
    "text": "And we're going to\ntalk about them next.",
    "start": "882580",
    "end": "884480"
  },
  {
    "text": "You might just pick\nan unfortunate choice",
    "start": "884480",
    "end": "886449"
  },
  {
    "text": "of cut points.",
    "start": "886450",
    "end": "887350"
  },
  {
    "text": "And it doesn't show the\nnon-linearity at all.",
    "start": "887350",
    "end": "890389"
  },
  {
    "text": "And so there's\nsomewhat of an art.",
    "start": "890390",
    "end": "892240"
  },
  {
    "text": "So usually these piecewise\nconstant functions",
    "start": "892240",
    "end": "895540"
  },
  {
    "text": "are especially good if\nthey are natural cut points",
    "start": "895540",
    "end": "897880"
  },
  {
    "text": "that you want to use.",
    "start": "897880",
    "end": "899500"
  },
  {
    "start": "899500",
    "end": "900000"
  }
]
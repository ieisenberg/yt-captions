[
  {
    "start": "0",
    "end": "5510"
  },
  {
    "text": "OK. We'll continue. There was a couple of things\nI wanted to point out here",
    "start": "5510",
    "end": "11090"
  },
  {
    "text": "that we already saw a couple. So the idea here is you create\na penalty function, which",
    "start": "11090",
    "end": "17930"
  },
  {
    "text": "basically describes how you\nfeel, how irritated are you",
    "start": "17930",
    "end": "23240"
  },
  {
    "text": "with a residual of\na certain value. So these are residuals\nhere, and then this",
    "start": "23240",
    "end": "29780"
  },
  {
    "text": "is basically your irritation. And what you're going\nto do is actually minimize your total\nirritation by minimizing",
    "start": "29780",
    "end": "36470"
  },
  {
    "text": "the sum of these things. And then you can interpret\nthese all sorts of ways. Your standard thing\nwould be a quadratic,",
    "start": "36470",
    "end": "42260"
  },
  {
    "text": "that's been a tradition for\na couple of hundred years, and also has analytical\nsolutions in some simple cases.",
    "start": "42260",
    "end": "50000"
  },
  {
    "text": "But then we have some others\nhere like this deadzone-linear. And these are interesting\nbecause they have a kink here.",
    "start": "50000",
    "end": "57800"
  },
  {
    "text": "And what we observed last\ntime was actually interesting,",
    "start": "57800",
    "end": "62989"
  },
  {
    "text": "it was this. It was that when you\nhave a kink here, you",
    "start": "62990",
    "end": "68370"
  },
  {
    "text": "find a whole bunch of\nvalues right at the kink. Notice that that's also true\nfor the L1 solution as well.",
    "start": "68370",
    "end": "76770"
  },
  {
    "text": "So the L1 solution says\nyou don't like residuals--",
    "start": "76770",
    "end": "82899"
  },
  {
    "text": "in fact, one way to analyze\nwhat an L1 penalty function is is that, for large\nresiduals, it's",
    "start": "82900",
    "end": "88619"
  },
  {
    "text": "relatively chill, at least,\nfor a convex penalty. Because it's a lot\nsmaller than a quadratic",
    "start": "88620",
    "end": "95550"
  },
  {
    "text": "when a residual is large because\na quadratic is large squared.",
    "start": "95550",
    "end": "100680"
  },
  {
    "text": "Conversely, for small\nresiduals, something like an L1 or something\nwith a sharp point",
    "start": "100680",
    "end": "107700"
  },
  {
    "text": "is actually not chill. It gets very upset with--\nit gets relatively upset",
    "start": "107700",
    "end": "115140"
  },
  {
    "text": "with small residuals whereas,\nfor example, a square penalty is not, is fine.",
    "start": "115140",
    "end": "120542"
  },
  {
    "text": "And I'm just-- there's no more\nto what I'm saying than just this, so don't try to over-- I mean, you can-- if\nyou wanted to people",
    "start": "120542",
    "end": "126178"
  },
  {
    "text": "have actually attempted\nto make this extremely mathematical and so on. It's a bit silly because\nI think it's actually",
    "start": "126178",
    "end": "132000"
  },
  {
    "text": "very interesting to actually\njust see how this works. OK.",
    "start": "132000",
    "end": "138000"
  },
  {
    "text": "That is actually something--\nespecially this top one, which is the L1 thing, here you see\nthat a whole bunch of penalties",
    "start": "138000",
    "end": "144150"
  },
  {
    "text": "are 0. And, in fact, this\nis a theme you're going to see-- you may already\nhave seen it in some statistics",
    "start": "144150",
    "end": "150120"
  },
  {
    "text": "and machine learning classes. And basically what\npeople say is that L1",
    "start": "150120",
    "end": "155970"
  },
  {
    "text": "is a sparsifier, meaning\nthat when you take an L1 norm of something in\nan optimization problem,",
    "start": "155970",
    "end": "163500"
  },
  {
    "text": "it is often the case\nthat at the solution, the argument has a\nlot of 0 entries.",
    "start": "163500",
    "end": "169800"
  },
  {
    "text": "That's the case here, OK? And so that's just\na common phenomenon, and it's got tons\nof uses, including",
    "start": "169800",
    "end": "177540"
  },
  {
    "text": "a lot of practical uses. We'll get to it in\nmachine learning, there's just tons of them,\nbut it comes up in engineering",
    "start": "177540",
    "end": "184650"
  },
  {
    "text": "and has been used actually\nnow for several decades. So OK. ",
    "start": "184650",
    "end": "191620"
  },
  {
    "text": "I guess this is the-- we\nlooked at the Huber penalty that that focuses on large\nresiduals, and the fact",
    "start": "191620",
    "end": "199390"
  },
  {
    "text": "that a Huber penalty is like\nthis Frankenstein penalty that blends together a quadratic\nfor small residuals",
    "start": "199390",
    "end": "205570"
  },
  {
    "text": "with, basically,\nsomething that looks like an L1 penalty for large.",
    "start": "205570",
    "end": "211720"
  },
  {
    "text": "And so you might say that\na Huber penalty matches least squares for small\nresiduals, which is to say",
    "start": "211720",
    "end": "218500"
  },
  {
    "text": "that it's relatively chill. Not as chill as a deadzone,\nthat's as chill as you can get. That's like, well, OK.",
    "start": "218500",
    "end": "224769"
  },
  {
    "text": "But for large residuals,\na Huber penalty actually looks more like an L1 thing,\nwhich is, for a convex penalty,",
    "start": "224770",
    "end": "231820"
  },
  {
    "text": "as chill as you can get. So OK.",
    "start": "231820",
    "end": "237780"
  },
  {
    "text": "We looked at least-norm\nproblems where, basically, the same story\nhappens, but now I can--",
    "start": "237780",
    "end": "244950"
  },
  {
    "text": "you can guess a lot of stuff. If, for example, X is a sequence\nof forces that you apply--",
    "start": "244950",
    "end": "254070"
  },
  {
    "text": "let's see-- or yeah, that\nyou apply to something. Let's say Ax equals\nB says, make me",
    "start": "254070",
    "end": "259890"
  },
  {
    "text": "a trajectory of forces to\nput every 20 milliseconds on this rigid body to\nmove it from this position",
    "start": "259890",
    "end": "267360"
  },
  {
    "text": "to that position. Let's just say that's what X is. If I use an L1 norm here,\nI want someone to guess.",
    "start": "267360",
    "end": "274979"
  },
  {
    "text": "Which is, by the way, a\nfirst order approximation of fuel use, at\nleast, for rockets.",
    "start": "274980",
    "end": "280470"
  },
  {
    "text": "So somebody want to\nmake a guess as to what it's going to look like. What is X going to\nbe based on what",
    "start": "280470",
    "end": "289000"
  },
  {
    "text": "we were just talking about? It's going to be sparse. It's going to be sparse, yeah. And by the way, if\nyou go and watch",
    "start": "289000",
    "end": "296169"
  },
  {
    "text": "videos of satellites maneuvering\nor rockets maneuvering, that's exactly what\nyou'll see if you watch.",
    "start": "296170",
    "end": "303030"
  },
  {
    "text": "Because you'll actually\nsee puffs come out of the thrusters, and there's\nlittle bursts, and it'll--",
    "start": "303030",
    "end": "308170"
  },
  {
    "text": "you'll see 1, 2, 3,\nand then just nothing. And then some other\nthruster you'll get like two bursts out of\nit or something like that.",
    "start": "308170",
    "end": "315320"
  },
  {
    "text": "So that's exactly\nright, they're sparse. Everybody got this? So that's a theme.",
    "start": "315320",
    "end": "320710"
  },
  {
    "text": "Don't worry, you're going to\nsee it basically from now on. And it's used in a whole\nlot of other applications,",
    "start": "320710",
    "end": "327889"
  },
  {
    "text": "not just-- well, that's one. So anyway, OK,\nwe'll get to that.",
    "start": "327890",
    "end": "335060"
  },
  {
    "text": "OK. We talked about\nregularized approximation last time as, basically,\na bicriterion problem,",
    "start": "335060",
    "end": "342320"
  },
  {
    "text": "where you have two criteria. And, of course, you\ncould extend it and have three and things like that. And I think we looked at an\nexample of that, not this one,",
    "start": "342320",
    "end": "350690"
  },
  {
    "text": "but optimal input design. We looked at this last time. And this is very typical. This is a pure quadratic\nproblem, so it's not that--",
    "start": "350690",
    "end": "357290"
  },
  {
    "text": "I mean, it's very simple. You don't need the\nmaterial of this class to solve this problem. But it looks\nsomething like this.",
    "start": "357290",
    "end": "363410"
  },
  {
    "text": "You're designing\nan input, which is an input to some system which\nis given by a convolution,",
    "start": "363410",
    "end": "369979"
  },
  {
    "text": "or in dialect I would say\nit's a linear time invariant system that would be like EE\nand maybe mechanical engineering",
    "start": "369980",
    "end": "377630"
  },
  {
    "text": "dialect for what this is. So the output is the input\nconvolved with something.",
    "start": "377630",
    "end": "385069"
  },
  {
    "text": "I guess in fancy\nlanguage you would say it's the convolution\nkernel, that would be something that everyone would understand.",
    "start": "385070",
    "end": "392280"
  },
  {
    "text": "But if you're\nexclusively with people who speak this EE,\nME dialect, you",
    "start": "392280",
    "end": "397800"
  },
  {
    "text": "would say something like\nh is the impulse response. So I'm just mentioning\nthat different groups",
    "start": "397800",
    "end": "403949"
  },
  {
    "text": "have different names\nfor these things. OK. So here we have\nthree objectives.",
    "start": "403950",
    "end": "410520"
  },
  {
    "text": "The first one is we want to\ntrack some desired trajectory. We want the input\nsmall, roughly we're",
    "start": "410520",
    "end": "416850"
  },
  {
    "text": "making it L2 norm small squared,\nand we want the input variation",
    "start": "416850",
    "end": "421950"
  },
  {
    "text": "to be small. So we want the difference\nbetween u t plus 1 and ut to be relatively small.",
    "start": "421950",
    "end": "428410"
  },
  {
    "text": "And so what we'll do\nis we will minimize a weighted sum of them. These are positive weights,\nthe delta and the eta,",
    "start": "428410",
    "end": "434863"
  },
  {
    "text": "that weight the\ndifferent things, right? And then the way-- in fact, people in control in\nother areas talk about this",
    "start": "434863",
    "end": "440970"
  },
  {
    "text": "is they would say-- they would say that\nthe delta and the eta are knobs, design\nknobs that will allows",
    "start": "440970",
    "end": "448680"
  },
  {
    "text": "you to shape, to make\nyou look like what you want it to look like. Everybody got that? Right.",
    "start": "448680",
    "end": "454020"
  },
  {
    "text": "So I guess in machine learning\nyou'd call them hyperparameters which are things you wiggle\nto change your model,",
    "start": "454020",
    "end": "461790"
  },
  {
    "text": "to make it less\nsensitive to something or something like that. Everybody got that? Unlike in machine learning\nwhere you actually",
    "start": "461790",
    "end": "467520"
  },
  {
    "text": "have rather good ways to defend\nchoices of delta and eta, in a ton of applications,\nyou don't, right?",
    "start": "467520",
    "end": "475080"
  },
  {
    "text": "So I mean, you do\nkind of, right? So in control, you do\nsomething like pick some values",
    "start": "475080",
    "end": "480690"
  },
  {
    "text": "and say, ooh, that's nice. Saves a lot of fuel, but the\nride is too rough, right?",
    "start": "480690",
    "end": "485760"
  },
  {
    "text": "And then you would\nwiggle these things, multiply them, one of them or\ntwo of them by a factor of 2, divide one by a\nfactor of 2, rerun it",
    "start": "485760",
    "end": "492360"
  },
  {
    "text": "and you'd say, OK, that looks\nwe're only using about 5%. We only lost a few percent\nin fuel efficiency. But it's a lot smoother\nride or something like that.",
    "start": "492360",
    "end": "499512"
  },
  {
    "text": "It would be things like this. So, OK. And we looked actually at some\nexamples of how that works.",
    "start": "499513",
    "end": "506550"
  },
  {
    "text": "And the example actually shows\nwhat the whole idea here is. And it's identical to\nthe idea, by the way,",
    "start": "506550",
    "end": "513284"
  },
  {
    "text": "in regularization and\nmachine learning, which we'll talk about later. It's identical and\nwhat it is based on",
    "start": "513284",
    "end": "519690"
  },
  {
    "text": "is you can actually\nsometimes get away with not a huge loss in\nyour primary objective while",
    "start": "519690",
    "end": "529170"
  },
  {
    "text": "at the same time actually\ngetting a substantial reduction in your secondary objectives.",
    "start": "529170",
    "end": "534420"
  },
  {
    "text": "So this is a, a lot smoother\nthan that and also b, a lot smaller.",
    "start": "534420",
    "end": "539550"
  },
  {
    "text": "I mean, if this\nis not good enough tracking error,\nthis versus that, then this is all\ntheoretical, right?",
    "start": "539550",
    "end": "546450"
  },
  {
    "text": "But if you say like,\noh, that's fine. That's all I wanted\nthis thing to do--",
    "start": "546450",
    "end": "552190"
  },
  {
    "text": "oh, and I think-- I couldn't remember\nthe name in control or mechanical\nengineering for this. It's called a doublet.",
    "start": "552190",
    "end": "558460"
  },
  {
    "text": "Is that-- someone\ntold me anyway. It's something like a doublet\nmotion or something like that. That's what it is when\nsomething goes like this.",
    "start": "558460",
    "end": "564950"
  },
  {
    "text": "It goes over here, over\nthere, and then back. So OK, all right.",
    "start": "564950",
    "end": "570320"
  },
  {
    "text": "Does this make sense? And now I'm going to\nask you a question. What would happen\nif I change this",
    "start": "570320",
    "end": "578830"
  },
  {
    "text": "to the sum of the\nabsolute values? You just guess.",
    "start": "578830",
    "end": "584650"
  },
  {
    "text": "I mean, three lines of\nPython and you would know. But just if someone\ncould just make a guess. ",
    "start": "584650",
    "end": "591568"
  },
  {
    "text": "What do you think would happen? Would it be sparsity? Yeah, but I don't think\nu was sparse at all.",
    "start": "591568",
    "end": "596820"
  },
  {
    "text": "Like here let's go look at u. Sorry. Here's u. Well, that's not true.",
    "start": "596820",
    "end": "601950"
  },
  {
    "text": "I shouldn't have spoke, right? It does look like it doesn't\ndo anything for 40 steps. It would be sparser, right?",
    "start": "601950",
    "end": "607110"
  },
  {
    "text": " What if I changed this to be\nthe sum of the absolute values?",
    "start": "607110",
    "end": "614280"
  },
  {
    "text": "What would you get? I mean, you're just\nguessing here so-- ",
    "start": "614280",
    "end": "621170"
  },
  {
    "text": "what's that? Sparse derivative? Sparse derivative. It's not a derivative. It's a first difference. Yes, sparse first difference.",
    "start": "621170",
    "end": "626990"
  },
  {
    "text": "What does it mean\nif something has-- if a time series has a\nsparse first difference, what does that mean?",
    "start": "626990",
    "end": "632330"
  },
  {
    "text": "More smooth. It's what? More smooth. It's what?",
    "start": "632330",
    "end": "637400"
  },
  {
    "text": "More smooth. I can't hear. More smooth. More smooth.",
    "start": "637400",
    "end": "642860"
  },
  {
    "text": "I don't think that's\nvery smooth, no. I mean, it's smooth in\na certain sense, right? In the sense that the L1 norm of\nthe first difference is small.",
    "start": "642860",
    "end": "650630"
  },
  {
    "text": "I don't know. Yeah? Piecewise. Piecewise what? Kind of constant and when\nit changes, it's constant.",
    "start": "650630",
    "end": "657350"
  },
  {
    "text": "It's piecewise constant, right? If I give you a time\nseries and I tell you that the first\ndifferences are sparse,",
    "start": "657350",
    "end": "665870"
  },
  {
    "text": "then it means that most\nof the time it's 0. And that means most\nof the time the value is equal to the previous value.",
    "start": "665870",
    "end": "671220"
  },
  {
    "text": "So it would encourage piecewise\nconstant inputs, right? So make sense? Yeah, so that's actually used\nin chemical engineering plants",
    "start": "671220",
    "end": "680000"
  },
  {
    "text": "when they're planning out\nchanges to inputs and things like that. They actually put\na term that looks",
    "start": "680000",
    "end": "687210"
  },
  {
    "text": "like this with absolute values. And they even have\nsome great name for that like I\nthink they call--",
    "start": "687210",
    "end": "693570"
  },
  {
    "text": "what happens then\nis you get things that says you're\ngoing to run 3.5 hours and then you're going to\nincrease the feed rate to this,",
    "start": "693570",
    "end": "700380"
  },
  {
    "text": "right? And then 3 hours\nafter that, you're going to turn up the\npower to this heater",
    "start": "700380",
    "end": "705540"
  },
  {
    "text": "or something like that. And they call those\ndeltas which is-- I mean, it's dialect, but\nit's kind of cool that",
    "start": "705540",
    "end": "711780"
  },
  {
    "text": "that's-- and it's done exactly\nby solving actually quadratic programs. Actually, it looks\nexactly like that.",
    "start": "711780",
    "end": "717990"
  },
  {
    "text": "But with an absolute value here. And the whole idea here should\nbe kind of obvious, right?",
    "start": "717990",
    "end": "725355"
  },
  {
    "text": "We make-- you can\ndesign these penalty terms, and objective\nterms, and things",
    "start": "725355",
    "end": "731970"
  },
  {
    "text": "like that to get something\nthat you want, right? Like some kind of sparsity\nor something like that.",
    "start": "731970",
    "end": "739110"
  },
  {
    "text": "OK, next up is another\nvery simple problem.",
    "start": "739110",
    "end": "744480"
  },
  {
    "text": "It's called signal\nreconstruction. It didn't stop\npeople from writing a thousand papers on it. But still, here it is.",
    "start": "744480",
    "end": "751370"
  },
  {
    "text": "And it goes like this. So I give you a\ncorrupted signal. And then what you\nwant to do is form a--",
    "start": "751370",
    "end": "757730"
  },
  {
    "text": "you want to form an\napproximation of it, or an uncorrupted\nor cleaned signal, or a reconstructed signal.",
    "start": "757730",
    "end": "763908"
  },
  {
    "text": "We're going to call that x hat. That's our variable. X corrupted is given, right? So that would be\nsomething like that.",
    "start": "763908",
    "end": "771950"
  },
  {
    "text": "And then what\nyou're also given is you're given phi is\nsomething like it's a regularization function\nor a smoothing objective.",
    "start": "771950",
    "end": "778550"
  },
  {
    "text": "So it basically says that it\nsays that the larger phi is,",
    "start": "778550",
    "end": "784490"
  },
  {
    "text": "the less plausible x hat is as\nwhat it really-- what you're",
    "start": "784490",
    "end": "790700"
  },
  {
    "text": "trying to reconstruct, right? So simple things would be things\nlike a quadratic smoother.",
    "start": "790700",
    "end": "795840"
  },
  {
    "text": "This would be the one we\nwere just talked about. It's an L1 smoother. You could take the\nthird difference",
    "start": "795840",
    "end": "802260"
  },
  {
    "text": "and take the L1 difference. You could put a\ndead zone penalty on the second difference.",
    "start": "802260",
    "end": "807510"
  },
  {
    "text": "I mean, it just there's\njust a lot of stuff you can do with this, OK? So this is sort of the idea.",
    "start": "807510",
    "end": "815699"
  },
  {
    "text": "Now, by the way-- OK, so let's just take a\nlook at how this works.",
    "start": "815700",
    "end": "822230"
  },
  {
    "text": "So here's just a kind of a\nclassic example for how you would do signal reconstruction.",
    "start": "822230",
    "end": "827889"
  },
  {
    "text": "So here's an original signal. And you can see it's smooth\nor something like that. And now here we add\nsome noise to it.",
    "start": "827890",
    "end": "835820"
  },
  {
    "text": "And it looks like that, right? And now we simply do-- this is\nwith quadratic smoothing, which",
    "start": "835820",
    "end": "841839"
  },
  {
    "text": "by the way, turns\nout to be linear. And it turns out to be\nexactly classical smoothing",
    "start": "841840",
    "end": "847480"
  },
  {
    "text": "and whatever, all the\nstuff you would learn and stuff like that. That's what it is. So that's what that is.",
    "start": "847480",
    "end": "853149"
  },
  {
    "text": "And it's basically\nthe smoother is then-- I'll go into dialect-- a low pass filter is what\npeople would say, OK?",
    "start": "853150",
    "end": "859915"
  },
  {
    "text": "So and someone would\nsay, what are you doing? And you say, I'm filtering\nout the high frequency noise here to estimate the signal\nwhich has lots of low frequency",
    "start": "859915",
    "end": "870310"
  },
  {
    "text": "content. OK, so that's quasi dialect for\nsaying this thing is smooth,",
    "start": "870310",
    "end": "875589"
  },
  {
    "text": "and the noise added\nto it is much rougher. OK, I mean, you could say that\nin other dialects too, right?",
    "start": "875590",
    "end": "881899"
  },
  {
    "text": "Certainly, in time\nseries dialect, you would be able to\nsay something like that. I don't exactly\nspeak that dialect,",
    "start": "881900",
    "end": "887089"
  },
  {
    "text": "so I'm not going to even\nattempt, but you could. OK, and then here are\nsome examples, right? So you have a trade off\nwhere you're trading off",
    "start": "887090",
    "end": "894440"
  },
  {
    "text": "two things, like how\nfar do you deviate from what was given to you? That's this term.",
    "start": "894440",
    "end": "899660"
  },
  {
    "text": "And the second term is how\nsmall is this quadratic, or how big is this quadratic? Or in this case,\nquadratic smoothing cost.",
    "start": "899660",
    "end": "907830"
  },
  {
    "text": "And you can see this is with-- this thing is\nrelatively high here,",
    "start": "907830",
    "end": "914510"
  },
  {
    "text": "this one, the\nquadratic component. And this is something like\nyou might guess, I guess, just",
    "start": "914510",
    "end": "921320"
  },
  {
    "text": "by eyeball you might say\nthat's not enough smoothing, which means you should--\nit depends which one you're",
    "start": "921320",
    "end": "927693"
  },
  {
    "text": "putting the weight on. Probably you're putting\nthe weight on this. And it says you should\nprobably decrease the weight on the\nsmoothing regularizer,",
    "start": "927693",
    "end": "933920"
  },
  {
    "text": "then you might get\nsomething like this. And then you might\nsay over here, well, that's already too smoothed\nor something like that, right?",
    "start": "933920",
    "end": "940490"
  },
  {
    "text": "So here, by the way, you\ncan use an obvious method",
    "start": "940490",
    "end": "947540"
  },
  {
    "text": "to actually, in a\nvery principled way, select the amount of smoothing. You just do cross-validation\nhere, right?",
    "start": "947540",
    "end": "954230"
  },
  {
    "text": "So I think a lot of\npeople who do this, don't do that, which\nI find bizarre. But nevertheless-- because\nit's in your first class",
    "start": "954230",
    "end": "961417"
  },
  {
    "text": "on statistics and machine\nlearning-- nevertheless, you could. And you do that by\ndoing the following.",
    "start": "961417",
    "end": "967250"
  },
  {
    "text": "What you do to do that,\nI'll just explain it, is over here in this\none, you take the x,",
    "start": "967250",
    "end": "974720"
  },
  {
    "text": "the one that you're\ngiven, x corrupted. And you extend this formulation\nto allow it to have NAs in it,",
    "start": "974720",
    "end": "981330"
  },
  {
    "text": "so unknown, like\nunknown measurements, like I didn't get a measurement\nfor index 37, 52, 53, 62, 70,",
    "start": "981330",
    "end": "989897"
  },
  {
    "text": "anyway you do that. And it's actually\nextremely simple if you make this a sum\nof squares over those. But the x hat is going\nto be a full one.",
    "start": "989898",
    "end": "997320"
  },
  {
    "text": "It doesn't have any NAs in\nit, if you're following me. NA meaning not a number, right? Or NAN, I think that would be\nthe other way to say it, right?",
    "start": "997320",
    "end": "1004279"
  },
  {
    "text": "Or question mark, or whatever,\nor missing data, right? So then you do this-- now, once you extend this,\nwhich is unbelievably simple",
    "start": "1004280",
    "end": "1012980"
  },
  {
    "text": "to handle missing data, now\nyou can do cross validation. And you do that by saying thanks\nfor your data, 10% is missing.",
    "start": "1012980",
    "end": "1020150"
  },
  {
    "text": "You randomly yank\nout another 10% of the data which you\nknew but isn't missing,",
    "start": "1020150",
    "end": "1025910"
  },
  {
    "text": "and you pretend it's missing. Now, you do signal\nreconstruction and you try this thing and\nsomeone at the next desk",
    "start": "1025910",
    "end": "1033770"
  },
  {
    "text": "says, oh, you should try\nHuber, try whatever, try Huber on the third difference. And you're like, OK, dude.",
    "start": "1033770",
    "end": "1039233"
  },
  {
    "text": "And you try these things. Every time you do that,\nyou can make a prediction, which is x hat of the values\nthat you actually observed",
    "start": "1039233",
    "end": "1049280"
  },
  {
    "text": "but pretended you didn't. Everybody see that? And then we can say\nthanks for your suggesting",
    "start": "1049280",
    "end": "1054590"
  },
  {
    "text": "of using a Huber penalty\non the third difference. Just for the record, it\ndid a lot worse than mine.",
    "start": "1054590",
    "end": "1061490"
  },
  {
    "text": "OK, so everyone, if you\nfollow that, that's fine. And if you didn't,\nit's probably OK.",
    "start": "1061490",
    "end": "1067610"
  },
  {
    "text": "So I mean, certainly not part\nof the class, this class, OK.",
    "start": "1067610",
    "end": "1072799"
  },
  {
    "text": " Now, when your penalty is an L1\nnorm on the first difference,",
    "start": "1072800",
    "end": "1083750"
  },
  {
    "text": "that's actually got a name. And this is like just\ncompletely standard math. It's the total variation, right?",
    "start": "1083750",
    "end": "1089690"
  },
  {
    "text": "So it's the-- it's\nactually-- well, literally, it's in continuous time\nit's like the integral",
    "start": "1089690",
    "end": "1095840"
  },
  {
    "text": "of the absolute value\nof the derivative or something like that, right? And so this is the\nanalog of that.",
    "start": "1095840",
    "end": "1100970"
  },
  {
    "text": "And as we actually\nreasoned earlier when you have a\npenalty, which is like an L1 norm on\na difference, you",
    "start": "1100970",
    "end": "1108679"
  },
  {
    "text": "should be expecting the solution\nto have a difference, which",
    "start": "1108680",
    "end": "1114920"
  },
  {
    "text": "is sparse which corresponds\nto a piecewise constant approximation, right?",
    "start": "1114920",
    "end": "1121220"
  },
  {
    "text": "And so here's an example\nhere where here's this original thing, right?",
    "start": "1121220",
    "end": "1126530"
  },
  {
    "text": "And here's the corrupted one. And I'll come back and describe\nhow people in some dialects",
    "start": "1126530",
    "end": "1132899"
  },
  {
    "text": "would describe this. But the point is that's it. Now we're going to do L1. ",
    "start": "1132900",
    "end": "1138630"
  },
  {
    "text": "OK, sorry, this is\nquadratic, right? So in quadratic, you see you\ndo a little bit of smoothing.",
    "start": "1138630",
    "end": "1144000"
  },
  {
    "text": "And good news is like the\nnoise has gone way down. Bad news, you can't\nreally see it here.",
    "start": "1144000",
    "end": "1150549"
  },
  {
    "text": "But what was actually a\ntransition in one period up here, these sharp things,\nwere actually are now smoothed",
    "start": "1150550",
    "end": "1156870"
  },
  {
    "text": "and they go down\nover 10, 20 periods. That's over here. When I put this amount\non it, good news,",
    "start": "1156870",
    "end": "1162390"
  },
  {
    "text": "this noise is attenuated more. But now you can see it's\nreally quite smooth, right? And then this is\nvery smooth, right?",
    "start": "1162390",
    "end": "1169860"
  },
  {
    "text": "So if you wanted to\npreserve these shifts, then you would use instead\nof a quadratic smoother,",
    "start": "1169860",
    "end": "1177780"
  },
  {
    "text": "you would use an\nL1 smoother, OK? And this sort of makes sense.",
    "start": "1177780",
    "end": "1184430"
  },
  {
    "text": "I was going to say like\nif you know about audio, this is just applying\na low pass filter. And what you're losing are,\nfor example, the attack",
    "start": "1184430",
    "end": "1191640"
  },
  {
    "text": "of a drumbeat, right? And it would just-- good news, the noise\nwould be attenuated.",
    "start": "1191640",
    "end": "1196710"
  },
  {
    "text": "Bad news, the drums are muffled. I mean, that was rough but\nactually correct, right?",
    "start": "1196710",
    "end": "1201990"
  },
  {
    "text": "What I just said, OK. So now we do a total\nvariation smoothing.",
    "start": "1201990",
    "end": "1207429"
  },
  {
    "text": "So total variation\nsmoothing goes like this. This is maybe not quite enough.",
    "start": "1207430",
    "end": "1213429"
  },
  {
    "text": "This might be about right. But the cool part is if\nyou take a look at it, it actually has preserved these\nsharp these sharp shock OK",
    "start": "1213430",
    "end": "1221460"
  },
  {
    "text": "shocks sorry that's from\neconometrics, right? So but so there's a\nlot-- this comes up in lots and lots of fields\nall with different dialects",
    "start": "1221460",
    "end": "1229260"
  },
  {
    "text": "and names for everything, right? And then this one is\nsort of interesting. You might say that's a\nlittle bit over regularized",
    "start": "1229260",
    "end": "1235350"
  },
  {
    "text": "and what you can\nsee here is it's going towards what we guessed\nwas going to happen, right?",
    "start": "1235350",
    "end": "1240450"
  },
  {
    "text": "That you're going to\nget something that's piecewise constant, right? And it would look like this.",
    "start": "1240450",
    "end": "1246000"
  },
  {
    "text": "OK, everybody,\neverybody got this? And so there's no\nmystery here it just this is it just\nfollows from knowing",
    "start": "1246000",
    "end": "1252900"
  },
  {
    "text": "about what happens with L1\nnorms and things like that. Let's see. I should probably\nmake some other--",
    "start": "1252900",
    "end": "1258900"
  },
  {
    "text": "yeah. Yeah, so you get the same thing. You get total variation\ndenoising, for example,",
    "start": "1258900",
    "end": "1264840"
  },
  {
    "text": "in images. That's actually\nsuper interesting. It's actually not sum of--",
    "start": "1264840",
    "end": "1270690"
  },
  {
    "text": "you can do a sum\nof absolute values. You can take an image, right? Let's say represented\nby a matrix, right?",
    "start": "1270690",
    "end": "1278280"
  },
  {
    "text": "And you could do something\nlike this, right? You could have i j plus 1.",
    "start": "1278280",
    "end": "1283620"
  },
  {
    "text": "And then you would have Xij\nminus Xi minus 1 and j, right?",
    "start": "1283620",
    "end": "1293220"
  },
  {
    "text": "And so you can take\nthe L1 norm of that and then sum it over all\npixels in your image, right?",
    "start": "1293220",
    "end": "1300420"
  },
  {
    "text": "This is sort of like-- this is\na very crude idea of the space gradient in the image.",
    "start": "1300420",
    "end": "1307790"
  },
  {
    "text": "OK. So it turns out a very\ngood thing to do there. If you actually take\nthe L1 norm of this, you actually end\nup with artifacts",
    "start": "1307790",
    "end": "1313947"
  },
  {
    "text": "that are aligned with the axes. But if you just simply do this-- is a generalization\nof an absolute value.",
    "start": "1313947",
    "end": "1321919"
  },
  {
    "text": "If you take this\nobjective here--  let me draw that a\nlittle bit better.",
    "start": "1321920",
    "end": "1330049"
  },
  {
    "text": "By the way, this is not squared. It is not squared. It's just the sum of the norms.",
    "start": "1330050",
    "end": "1335630"
  },
  {
    "text": "Everybody got that? That's called total variation. That's a total variation\npenalty for images.",
    "start": "1335630",
    "end": "1342740"
  },
  {
    "text": "That works, like, actually\nreally well, like, quite well. I mean, if you want to get\ninto fancier ones, you can.",
    "start": "1342740",
    "end": "1349620"
  },
  {
    "text": "But this is like--\nas a first cut, this is actually\nreally quite good. And what happens there\nis it preserves--",
    "start": "1349620",
    "end": "1356720"
  },
  {
    "text": "it's going to preserve\nsharp boundaries. Obviously, there's boundaries\nif I'm looking over there.",
    "start": "1356720",
    "end": "1361790"
  },
  {
    "text": "Some pixels are the podium, and\nsome is the chair behind it, and there's a sharp boundary. And if I were to do this,\nsmoothing with this,",
    "start": "1361790",
    "end": "1371429"
  },
  {
    "text": "I'm just, again-- I'm just doing a\nlinear smoothing with a kernel that\ngoes down like that,",
    "start": "1371430",
    "end": "1377130"
  },
  {
    "text": "and it's going to blur things. Everybody-- I mean, you\ndon't have to follow this, but if you know some of the\nstuff I'm talking about,",
    "start": "1377130",
    "end": "1383670"
  },
  {
    "text": "that's great. So this is total variation-- that people refer to that\nas total variation image",
    "start": "1383670",
    "end": "1391110"
  },
  {
    "text": "denoising. Have people seeing this-- who has seen this before?",
    "start": "1391110",
    "end": "1397820"
  },
  {
    "text": "Somewhere, OK, cool. In where? In what kind of-- Pressure jumps\nacross shockwaves.",
    "start": "1397820",
    "end": "1404300"
  },
  {
    "text": "But we have a similar-- Yeah, so this preserves. What happens if I use excessive\nregularization of this",
    "start": "1404300",
    "end": "1410630"
  },
  {
    "text": "on an image? So I have a black\nand white image. I give it to you,\nand you say I just",
    "start": "1410630",
    "end": "1415970"
  },
  {
    "text": "learned about total variation,\nwhatever, denoising. And you use too much\nof this regularization.",
    "start": "1415970",
    "end": "1425330"
  },
  {
    "text": "What do you get? Just guess. I think everyone can guess. Blur.",
    "start": "1425330",
    "end": "1430799"
  },
  {
    "text": "What? Blur Same color? Ooh. Yeah, OK. Sorry, yes.",
    "start": "1430800",
    "end": "1436110"
  },
  {
    "text": "Not a blur. No, no. I don't think you-- OK. If you-- OK, oh,\nby the way, if I",
    "start": "1436110",
    "end": "1442200"
  },
  {
    "text": "add too much like\nL1 regularization, what's the limit of that? What happens when I\nadd an enormous amount?",
    "start": "1442200",
    "end": "1448110"
  },
  {
    "text": "It's 0. It's 0, which is indeed\nvery sparse, right? You have to admit that, right? OK.",
    "start": "1448110",
    "end": "1453540"
  },
  {
    "text": "So yes, if it was way\ntoo high, it would say, here's your new image. And the entire thing is just\none some grayscale value,",
    "start": "1453540",
    "end": "1461340"
  },
  {
    "text": "which is kind of the-- OK, everybody got that? OK. Let's crank it down to\nsomething reasonable.",
    "start": "1461340",
    "end": "1468900"
  },
  {
    "text": "And what do you think happens? I mean, it's something\nlike this phenomenon here.",
    "start": "1468900",
    "end": "1475200"
  },
  {
    "text": "what do you think--\nbut in an image, what do you think it\nwould-- what would be the phenomenon in an image?",
    "start": "1475200",
    "end": "1481060"
  },
  {
    "text": "Edges. What's that? You get edges. Yeah, you would you\nget edges and regions",
    "start": "1481060",
    "end": "1486690"
  },
  {
    "text": "with a constant grayscale value. Yeah. So, actually, what you'd\nend up getting is like cartoonish-looking things\nbecause you take an image",
    "start": "1486690",
    "end": "1495420"
  },
  {
    "text": "with-- 8-bit or whatever\nit is, 8-bit stuff, and then you end up with\nthree different values,",
    "start": "1495420",
    "end": "1501900"
  },
  {
    "text": "and you get regions. So, OK, these are\njust sort of examples to give you the idea of\nhow these things are done.",
    "start": "1501900",
    "end": "1509100"
  },
  {
    "text": "But, OK. Next topic, which is something\nwe're going to talk about also",
    "start": "1509100",
    "end": "1516360"
  },
  {
    "text": "in other contexts, like\na statistical context, is the idea of\nrobust approximation. So I mean, robustness\nis this thing--",
    "start": "1516360",
    "end": "1522630"
  },
  {
    "text": "I think we've talked\nabout it before. It's a universal thing. If you do anything\nwith math at all,",
    "start": "1522630",
    "end": "1530530"
  },
  {
    "text": "then it's something you\nneed to be aware of. Your model is not\nwhat you think it is.",
    "start": "1530530",
    "end": "1536280"
  },
  {
    "text": "Might be really\naccurate if we're talking electromagnetics or\nphotonics or E&M or Newtonian",
    "start": "1536280",
    "end": "1543299"
  },
  {
    "text": "mechanics. It's pretty accurate, thank you. But in other cases,\nit's not at all, right? That would be in areas\nlike machine learning",
    "start": "1543300",
    "end": "1551429"
  },
  {
    "text": "or, for that matter, finance. Your model is just a\nfantasy, and it's not",
    "start": "1551430",
    "end": "1557759"
  },
  {
    "text": "what's actually happening. Newtonian mechanics,\nI'd say it's kind of is what's happening.",
    "start": "1557760",
    "end": "1563759"
  },
  {
    "text": "E&M, your model is actually\nkind of what's happening. So although even there,\nthere's questions.",
    "start": "1563760",
    "end": "1569502"
  },
  {
    "text": "You might not know stuff\nand things like that. OK. So here it is.",
    "start": "1569503",
    "end": "1574960"
  },
  {
    "text": "We want to, let's say-- we\nwant an approximation problem. We want to minimize\nnorm AX minus b.",
    "start": "1574960",
    "end": "1580779"
  },
  {
    "text": "But we are-- we're going\nto actually address the idea that we don't\nknow A. So don't know A.",
    "start": "1580780",
    "end": "1590320"
  },
  {
    "text": "By the way, let's talk about\nhow do most people in practice handle uncertainty.",
    "start": "1590320",
    "end": "1596370"
  },
  {
    "text": "What's the most common method\nfor handling uncertainty? It's not fancy. ",
    "start": "1596370",
    "end": "1604220"
  },
  {
    "text": "How do most people\nhandle uncertainty? I mean, look, right\nnow as we're speaking, people are doing supply--\nthey're working out supply--",
    "start": "1604220",
    "end": "1611600"
  },
  {
    "text": "I guarantee you Amazon is\nworking out supply chains. They're deciding\nstuff that's going to go to various warehouses\nand land at fulfillment centers",
    "start": "1611600",
    "end": "1619700"
  },
  {
    "text": "in the Bay Area. Obviously, they don't-- so how\ndo they handle the uncertainty,",
    "start": "1619700",
    "end": "1624710"
  },
  {
    "text": "mostly? They have a mean\nand some variance, assume a probability\ndistribution. That's a good--\nso the question is",
    "start": "1624710",
    "end": "1630590"
  },
  {
    "text": "they have a mean and\na variance for A way. Turns out that's not true. OK. It's even dumber.",
    "start": "1630590",
    "end": "1637370"
  },
  {
    "text": "What's the simplest way\nto handle uncertainty? They simulate\nmultiple scenarios.",
    "start": "1637370",
    "end": "1642740"
  },
  {
    "text": "I mean, you guys are too-- what do you-- you really think\nthings are that sophisticated? What do you do?",
    "start": "1642740",
    "end": "1648420"
  },
  {
    "text": "Think about a safety\nstock, I think. Yeah. I can't believe this. [LAUGHTER]",
    "start": "1648420",
    "end": "1653540"
  },
  {
    "text": "It's time for you\nto know something about the real world,\nwhich is horrifying. What is the simplest way\nto handle uncertainty?",
    "start": "1653540",
    "end": "1659700"
  },
  {
    "text": "They guess. What? They guess. They guess. OK. Now, what is that-- oh,\nyou're getting close. What does that mean, guess?",
    "start": "1659700",
    "end": "1665700"
  },
  {
    "text": "Educated guess. Educated guess. OK. So but in particular,\nhere's what they do-- they just ignore it.",
    "start": "1665700",
    "end": "1671100"
  },
  {
    "text": "[LAUGHTER] You just ignore it, right? I mean that's a-- I guarantee you that's how\n99% of actual uncertainty,",
    "start": "1671100",
    "end": "1678990"
  },
  {
    "text": "in practice, is handled. You're like-- you're\nlike, this is the demand we think for these products\nover the next hours and days,",
    "start": "1678990",
    "end": "1686530"
  },
  {
    "text": "or something like that. And you're like-- you\njust say, cool, thanks.",
    "start": "1686530",
    "end": "1691800"
  },
  {
    "text": "And then you solve like\nsome big convex problem to figure out what to do. That's actually kind\nof what happens, right?",
    "start": "1691800",
    "end": "1699160"
  },
  {
    "text": "I mean, not always. You just ignore it. By the way, ignoring it\nand then just go ahead and implementing it\nis a very bad idea.",
    "start": "1699160",
    "end": "1705580"
  },
  {
    "text": "So the least you could\ndo-- and now I'll take some of these\nsuggestions-- is what?",
    "start": "1705580",
    "end": "1711400"
  },
  {
    "text": "The least you can do, if you\nignore it-- if someone says, look, here's my data,\nand then they say, oh,",
    "start": "1711400",
    "end": "1717580"
  },
  {
    "text": "the data is really-- it changes quite-- it can be\nnot what I'm saying, right? And you say, yeah, no problem.",
    "start": "1717580",
    "end": "1723980"
  },
  {
    "text": "Thanks. And if they give you-- anyway. If they give you 50 different\nvalues for-- possible values",
    "start": "1723980",
    "end": "1730180"
  },
  {
    "text": "for A, you just take the\naverage or something like that and then go with it, right? But what should you do then?",
    "start": "1730180",
    "end": "1735415"
  },
  {
    "text": " What would you do at that point?",
    "start": "1735415",
    "end": "1741608"
  },
  {
    "text": "Well, at the least, you-- yeah? You can simulate the analysis. Yeah, you simulate it with that.",
    "start": "1741608",
    "end": "1748030"
  },
  {
    "text": "So that would be probably the-- I mean, the ones that I\ndon't think are criminal,",
    "start": "1748030",
    "end": "1753160"
  },
  {
    "text": "that would be an approach\nthat's not criminal, right? If someone comes\nto you and says,",
    "start": "1753160",
    "end": "1759130"
  },
  {
    "text": "oh, I've generated samples\nfrom what I think A is. And you go, cool,\nthank you. right? Then the first thing you do\nis you form the average of A",
    "start": "1759130",
    "end": "1767230"
  },
  {
    "text": "or the median or\nsomething like that. Use it in this thing. You get an x, and then you\nsimulate this thing across all",
    "start": "1767230",
    "end": "1774010"
  },
  {
    "text": "the individual samples. Everybody following that? And by the way, if it's pretty\ntight, you just say, done,",
    "start": "1774010",
    "end": "1780520"
  },
  {
    "text": "right? So that's the least. OK. So there is a--",
    "start": "1780520",
    "end": "1788590"
  },
  {
    "text": "so there are methods for\nhandling uncertainty. Like I said, anyone who\ndoes anything in practice anywhere is going to\nhave regularization.",
    "start": "1788590",
    "end": "1794710"
  },
  {
    "text": "They may not call\nit regularization. They might call it robustness. That would be one name for it.",
    "start": "1794710",
    "end": "1800450"
  },
  {
    "text": "It's got lots of names. But you can't make\nanything practical work without addressing this\nuncertainty somehow.",
    "start": "1800450",
    "end": "1812440"
  },
  {
    "text": "Actually, all of regularization\nin machine learning statistics, all of it is nothing but\naddressing uncertainty",
    "start": "1812440",
    "end": "1819429"
  },
  {
    "text": "like this in data\nand stuff like that. OK. let's take-- so\nwe'll look at a couple--",
    "start": "1819430",
    "end": "1826600"
  },
  {
    "text": "now we're going to look at\nfancy methods for doing this. Well, there's\ndifferent approaches.",
    "start": "1826600",
    "end": "1832698"
  },
  {
    "text": "I think we saw these in\nsome very early examples. But so one is stochastic. So you say A comes\nfrom a distribution.",
    "start": "1832698",
    "end": "1839270"
  },
  {
    "text": "They come from a\nname distribution, or you could have-- who knows? It could be-- it could\nactually be something",
    "start": "1839270",
    "end": "1844733"
  },
  {
    "text": "from which you can sample A's if\nyou have a fancy model for it, right? That would be something.",
    "start": "1844733",
    "end": "1851270"
  },
  {
    "text": "Another actually probably\nbetter defensible is you estimate A. A is itself.",
    "start": "1851270",
    "end": "1858137"
  },
  {
    "text": "There's a whole department\nthat's estimating A. By A, I just mean the model, right? Or people say the forward model. The whole department doing it.",
    "start": "1858137",
    "end": "1864383"
  },
  {
    "text": "And they could do things. Like, what you do is you say to\nthem, don't give me one model. Give me 50 plausible models.",
    "start": "1864383",
    "end": "1872260"
  },
  {
    "text": "And what they would then\ndo is they would say, cool, if you're going with one, here's\nthe A we think you should use.",
    "start": "1872260",
    "end": "1878260"
  },
  {
    "text": "But here's 50 others that are\nconsistent with everything we know and we have seen.",
    "start": "1878260",
    "end": "1883337"
  },
  {
    "text": "Everybody understand\nwhat I just said? So that's, like, ideal. That's, like, OK,\nthank you, right?",
    "start": "1883337",
    "end": "1889300"
  },
  {
    "text": "Or you could say\nhere's 1,000 because I have that department that does\nthe modeling, says, I actually",
    "start": "1889300",
    "end": "1895210"
  },
  {
    "text": "have a generative model. I can generate as many-- how\nmany A's you want, right? I'll just sample from\nthat distribution.",
    "start": "1895210",
    "end": "1901360"
  },
  {
    "text": "Everybody following this? So that's stochastic.",
    "start": "1901360",
    "end": "1907420"
  },
  {
    "text": "And then you might do something\nlike actually minimize the expected value. Now, that's a convex\nproblem, I mean,",
    "start": "1907420",
    "end": "1913299"
  },
  {
    "text": "because expectation\npreserves minimization-- sorry, expectation\npreserves convexity, right?",
    "start": "1913300",
    "end": "1921610"
  },
  {
    "text": "So, OK. At the other end,\npeople do worst case.",
    "start": "1921610",
    "end": "1927160"
  },
  {
    "text": "And this would be\nsomething like, look, I don't even believe it. It's not generated from a\nprobability distribution, which",
    "start": "1927160",
    "end": "1934330"
  },
  {
    "text": "is true of almost everything. Like, almost nothing is, right? So it's ridiculous. It's not from a\nprobability distribution.",
    "start": "1934330",
    "end": "1941200"
  },
  {
    "text": "You'd say, but my\nexperience says I think that the\nentries in this matrix",
    "start": "1941200",
    "end": "1946420"
  },
  {
    "text": "are correct plus/minus 3%. I mean, it could be a lot more\nsophisticated than that, right?",
    "start": "1946420",
    "end": "1952270"
  },
  {
    "text": "You could say, well,\nthe diagonal entries, I know this well. These things-- oh, that entry? I barely know the sign.",
    "start": "1952270",
    "end": "1958300"
  },
  {
    "text": "Everybody following this? It would be things like that. So you could make up\nsomething like that. And then you could say,\nwell, which A is it?",
    "start": "1958300",
    "end": "1964463"
  },
  {
    "text": "And you'd say, any\nA that satisfies the constraints that I just\ndescribed to you is plausible.",
    "start": "1964463",
    "end": "1971230"
  },
  {
    "text": "And then by the\nway, people have-- they have huge\nphilosophical fights, which is kind of hilarious. So the worst-case, people\nsay, like, oh, my god, it's",
    "start": "1971230",
    "end": "1979720"
  },
  {
    "text": "so unsophisticated to\nassume a distribution. And they're like,\nthat's ridiculous",
    "start": "1979720",
    "end": "1984860"
  },
  {
    "text": "because it's not a probability\ndistribution, blah, blah, blah, and stuff like that. And then I don't know,\nthe stochastic people--",
    "start": "1984860",
    "end": "1990530"
  },
  {
    "text": "it'd be like a fight between\nBayesians and frequentists or whatever. Anyway. So, and then the stochastic one\nwould say something like, oh,",
    "start": "1990530",
    "end": "1998403"
  },
  {
    "text": "the worst-case is way\ntoo conservative-- and you're like-- none of this makes\nany sense, by the way. They're both-- but they're\nmuch closer than they think.",
    "start": "1998403",
    "end": "2006283"
  },
  {
    "text": "And actually, a lot of\ntimes it's embarrassing because they have this huge\nphilosophical argument, and then it turns\nout you work out",
    "start": "2006283",
    "end": "2012310"
  },
  {
    "text": "the math of what they're\ndoing, and they're doing exactly the\nsame thing, where",
    "start": "2012310",
    "end": "2017680"
  },
  {
    "text": "one person has a knob that\nsays how big their uncertainty set is. And the other has a knob\nthat's basically, like,",
    "start": "2017680",
    "end": "2024120"
  },
  {
    "text": "variance or something like that. So it turns out that they;re\nkind of the same thing. Oh, and there are\nhybrids of these.",
    "start": "2024120",
    "end": "2030880"
  },
  {
    "text": "There's robust stochastic. And then you'd say, well,\nhere's my uncertain parameter.",
    "start": "2030880",
    "end": "2040960"
  },
  {
    "text": "From a probability distribution. And you go, cool, do you mind\ngiving me the parameters? And you go, aha, no.",
    "start": "2040960",
    "end": "2046419"
  },
  {
    "text": "I gave you a set of\nparameters, right? And then they would claim that\nthis gives you the advantages",
    "start": "2046420",
    "end": "2052617"
  },
  {
    "text": "of both of these methods or so. Anyway, this is just to give you\nthe big picture of uncertainty",
    "start": "2052617",
    "end": "2059379"
  },
  {
    "text": "modeling and things like that. OK. All right. OK.",
    "start": "2059380",
    "end": "2064719"
  },
  {
    "text": "So here's just a baby example\nto see what the idea is. So here-- I mean,\nthis is a matrix.",
    "start": "2064719",
    "end": "2070405"
  },
  {
    "text": "I don't know how big it is. It doesn't really matter,\nbut it's a matrix, right? And what we're\ngoing to do is we're going to have extremely\nexplicit uncertainty.",
    "start": "2070405",
    "end": "2077320"
  },
  {
    "text": "It's extremely dumb. There's a line segment in-- there's a line segment\nin matrix space.",
    "start": "2077320",
    "end": "2084190"
  },
  {
    "text": "I mean, that's kind of silly\nbecause it's-- a more common model would be all the-- these\nentries are all plus/minus 1%",
    "start": "2084190",
    "end": "2089982"
  },
  {
    "text": "and things like that, right? So, OK. But this is just\nto make the example so we can work out\nexactly what happened.",
    "start": "2089983",
    "end": "2096379"
  },
  {
    "text": "So the A that you get\nis parameterized by u. OK. Here it is.",
    "start": "2096380",
    "end": "2102680"
  },
  {
    "text": "And so this is what\npeople would normally do. They would say, what\ndoes my matrix look like? It looks like that. u\nis centered around 0,",
    "start": "2102680",
    "end": "2109599"
  },
  {
    "text": "and they'd say cool. My A matrix is\nA0, period, right? And that would give\nyou this curve here.",
    "start": "2109600",
    "end": "2118490"
  },
  {
    "text": "And what this is\nshowing you is here, this is what happens\nwhen is A is A0.",
    "start": "2118490",
    "end": "2123520"
  },
  {
    "text": "This is what happens\nas you change A. And you can see,\nwell, this is going to be these other methods.",
    "start": "2123520",
    "end": "2129520"
  },
  {
    "text": "They're not as good as this one. This one has the absolute\nminimum value here. And you can see that\nas your errors-- like,",
    "start": "2129520",
    "end": "2135835"
  },
  {
    "text": "I don't know what this is-- 3 and then by the time this\ngets to minus 1, it's double. It's 6. And so you might say, well,\nthis is too sensitive.",
    "start": "2135835",
    "end": "2143020"
  },
  {
    "text": " Then, you might look\nat this stochastic one.",
    "start": "2143020",
    "end": "2149070"
  },
  {
    "text": "So here's this-- this\nis the stochastic one. And what we do there is we\nminimize basically the integral",
    "start": "2149070",
    "end": "2156210"
  },
  {
    "text": "of this over this range, and\nthat gives you this one here. And what you can see\nhere is you-- so here's",
    "start": "2156210",
    "end": "2163320"
  },
  {
    "text": "how people would say\nthis-- you have given up nominal performance.",
    "start": "2163320",
    "end": "2168660"
  },
  {
    "text": "So you gave up\nnominal performance. And what you got was\nsomething that was much less",
    "start": "2168660",
    "end": "2174390"
  },
  {
    "text": "sensitive to the variations. Everybody see this? I mean, that's kind of\nthe story you want that.",
    "start": "2174390",
    "end": "2180130"
  },
  {
    "text": "That is exactly the story you--\nthat's you want to happen, right? And then the worst-case\none, again, you",
    "start": "2180130",
    "end": "2186420"
  },
  {
    "text": "can-- that's not hard to solve. And it turns out for\nthe worst-case one here,",
    "start": "2186420",
    "end": "2192060"
  },
  {
    "text": "you could see you gave\nup some performance here, but you can see that\nit's incredibly robust.",
    "start": "2192060",
    "end": "2198390"
  },
  {
    "text": "So everybody got-- So this picture plays\nout and obviously in much more\nsophisticated settings,",
    "start": "2198390",
    "end": "2204130"
  },
  {
    "text": "but this is the\nstory that you want to have when you have a method\nthat addresses robustness",
    "start": "2204130",
    "end": "2209890"
  },
  {
    "text": "or uncertainty. So all this make sense? Yeah. So I can tell you\na little trick.",
    "start": "2209890",
    "end": "2217975"
  },
  {
    "text": "Do you want to hear a-- yeah, but this is unofficial,\nso you can't tell people where you learned this.",
    "start": "2217975",
    "end": "2224060"
  },
  {
    "text": "OK. So it turns out-- as a street fighting matter,\nit turns out that all you need",
    "start": "2224060",
    "end": "2231220"
  },
  {
    "text": "is just literally a shockingly\nsmall number of samples of A.",
    "start": "2231220",
    "end": "2236440"
  },
  {
    "text": "And then you do something like a\nminimax or something like that, which would be\nsomething like this--",
    "start": "2236440",
    "end": "2241820"
  },
  {
    "text": "a very crude approximation\nof this worst-case thing does the trick. So for example, if you\nsay, design me a trajectory",
    "start": "2241820",
    "end": "2251050"
  },
  {
    "text": "for, I don't know, this\ndrone or something-- goes from here to there. And you go, like, OK,\ncan I have the model?",
    "start": "2251050",
    "end": "2257260"
  },
  {
    "text": "And they go, yeah, sure. And they go, well, what\nare these parameters? And you go, we don't know. They can vary.",
    "start": "2257260",
    "end": "2262660"
  },
  {
    "text": "That's the-- I mean, because\nit depends on the payload and blah, blah, blah. And by the way, even if\nI tell you the payload,",
    "start": "2262660",
    "end": "2268690"
  },
  {
    "text": "I might not know it within\nplus or minus 5% or something like that. So there, it turns out\nan extremely good thing",
    "start": "2268690",
    "end": "2276119"
  },
  {
    "text": "to do-- is you just ask whoever\nis coming up with the model, you'd say, give me 10 models.",
    "start": "2276120",
    "end": "2281650"
  },
  {
    "text": "And you say, here\nare the rules-- they have to be plausible. They can't be-- they can't\ngive you some crazy thing.",
    "start": "2281650",
    "end": "2288640"
  },
  {
    "text": "You'd say, every\none of these you would have to defend\nas a plausible model. That it's consistent\nwith what you",
    "start": "2288640",
    "end": "2293950"
  },
  {
    "text": "know about the problem\nand the past data. Everybody see what I'm saying? And they could do that\nall sorts of-- so you might do it this way.",
    "start": "2293950",
    "end": "2299289"
  },
  {
    "text": "You'd say, not a problem. I'll fit a model on Monday data,\nTuesday data, Wednesday data, and Thursday data.",
    "start": "2299290",
    "end": "2304450"
  },
  {
    "text": "Done. Now, you have seven\ndifferent models. If they're wildly different,\nsomething's weird.",
    "start": "2304450",
    "end": "2309990"
  },
  {
    "text": "If they're all the\nsame as doubles, what do you think has happened? ",
    "start": "2309990",
    "end": "2316506"
  },
  {
    "text": "What would you do\nif you asked someone to make a model of\nsomething and they go, cool, I made one for Monday,\nTuesday, Wednesday, Thursday?",
    "start": "2316507",
    "end": "2322410"
  },
  {
    "text": "And you go, god, thanks so much. And then they're kind of\nlike equal as doubles.",
    "start": "2322410",
    "end": "2328119"
  },
  {
    "text": " It's not a convex\noptimization question here.",
    "start": "2328120",
    "end": "2335549"
  },
  {
    "text": "What would you do?  Variation is not dependent\non the day, so it's--",
    "start": "2335550",
    "end": "2342950"
  },
  {
    "text": "Nah, nah, that's not-- no. Yeah. Really, you think out of the\neighth significant figure,",
    "start": "2342950",
    "end": "2348980"
  },
  {
    "text": "it doesn't-- no. It's fraud. That's what it is. They just lied.",
    "start": "2348980",
    "end": "2355069"
  },
  {
    "text": "They just said\nthey just gave you seven copies of a single model.",
    "start": "2355070",
    "end": "2360110"
  },
  {
    "text": "So the least they should\ndo is cover their tracks and add a little bit of\n[? rand/and ?] into the model. I mean, come on, right?",
    "start": "2360110",
    "end": "2365510"
  },
  {
    "text": "So if you're in this situation\nand some crazy person comes to you and say\nget 10 models, yeah. So just for fun,\nthat'd be one extreme.",
    "start": "2365510",
    "end": "2373470"
  },
  {
    "text": "And so fraud is one approach\nto generating a set of models.",
    "start": "2373470",
    "end": "2378843"
  },
  {
    "text": "Let's do a principled\none in statistics. We're jumping ahead, but\nI don't mind doing it. How would you make a\nprincipled one in statistics?",
    "start": "2378843",
    "end": "2386033"
  },
  {
    "text": "Fitting a model, let's\nsay maximum likelihood. Sorry, I'm getting ahead,\nbut you can just pretend. If you don't know what\nI'm talking about,",
    "start": "2386033",
    "end": "2392028"
  },
  {
    "text": "that's fine, too. Someone told me a good way\nto honor a request for 10",
    "start": "2392028",
    "end": "2398970"
  },
  {
    "text": "plausible models. We'll do maximum\nlikelihood here. Someone tell me how\nto get 10 models.",
    "start": "2398970",
    "end": "2405555"
  },
  {
    "text": "That's what I want to know. And don't pretend there's no\none in statistics here because I know there's a lot of people\nin statistics here, so don't--",
    "start": "2405555",
    "end": "2412230"
  },
  {
    "text": "yeah, go ahead. Somebody make a suggestion. You were going to make one?",
    "start": "2412230",
    "end": "2418350"
  },
  {
    "text": "Do you bootstrap just like 10-- That would be fine. Bootstrap would be fine. Here's a simple way that\nis convex optimization.",
    "start": "2418350",
    "end": "2424890"
  },
  {
    "text": "You would do this-- certainly, you would find the\nmaximum likelihood estimate. And you'd send that parameter\nand say, if you have",
    "start": "2424890",
    "end": "2431970"
  },
  {
    "text": "to go with one, take this one. OK. But then what you\nwould do is you'd find the maximum likelihood.",
    "start": "2431970",
    "end": "2437850"
  },
  {
    "text": "I will draw the likelihood\nfunction right now. Sorry, I'm getting ahead of\nmyself, but it's just fun. So here's the\nlikelihood function.",
    "start": "2437850",
    "end": "2443799"
  },
  {
    "text": "Here's the maximum\nlikelihood point. What you'd do is\nyou would record what the maximum likelihood is.",
    "start": "2443800",
    "end": "2450030"
  },
  {
    "text": "Drop something to\na likelihood level that is slightly less than\nthe maximum likelihood, which",
    "start": "2450030",
    "end": "2456299"
  },
  {
    "text": "is completely defensible\nstatistically. And then what you would do is\nyou would find points in here",
    "start": "2456300",
    "end": "2464069"
  },
  {
    "text": "like that. I mean, I guess it depends. If it's all smooth, this\nwould be like from-- you'd sample from the\nfisher information,",
    "start": "2464070",
    "end": "2472890"
  },
  {
    "text": "the ellipsoid defined by it. OK, sorry, that was weird. I just couldn't help myself. But did everybody get that? And then someone said,\nwhat have you given me?",
    "start": "2472890",
    "end": "2479679"
  },
  {
    "text": "And you'd say, I\ngave you 10 models. And you go, which-- well, you\nsay the first one is actually the maximum likelihood. If you're going to go with\none, I'd go with that of our.",
    "start": "2479679",
    "end": "2486353"
  },
  {
    "text": "And you go, what are\nthe other 10 or 100? And you would say, oh, those\nare models whose parameters",
    "start": "2486353",
    "end": "2493890"
  },
  {
    "text": "are almost maximum likelihood. Everybody got that?",
    "start": "2493890",
    "end": "2499170"
  },
  {
    "text": "OK. And then you'd say, thank you. And then you'd come over here,\nand you'd do something with--",
    "start": "2499170",
    "end": "2505299"
  },
  {
    "text": "and then you'd put these in\nas a maximum or something like that or an average. It wouldn't matter.",
    "start": "2505300",
    "end": "2511140"
  },
  {
    "text": "Oh, sorry, I was going to\ntell you the secret on this. The secret is by simply\nadmitting and acknowledging",
    "start": "2511140",
    "end": "2518100"
  },
  {
    "text": "that there is uncertainty\ngets you, like, 90% of the way there. Then you can do all these fancy\nthings later and, you know,",
    "start": "2518100",
    "end": "2525110"
  },
  {
    "text": "blah, blah, blah. But the point is just\ndoing 10 is good enough. So now you know a secret, right?",
    "start": "2525110",
    "end": "2531530"
  },
  {
    "text": "So if I go to my forecasting\ngroup and I tell you, here's the demand for this\nproduct over the next week,",
    "start": "2531530",
    "end": "2537080"
  },
  {
    "text": "hour by hour, and you go, OK. You go, are you certain? And they're like, no.",
    "start": "2537080",
    "end": "2542168"
  },
  {
    "text": "And then they say,\nplease generate me 10 such trajectories or 100. I don't care, right? Then this tells you it's fine.",
    "start": "2542168",
    "end": "2548187"
  },
  {
    "text": "And you say, but the rule is\nthey have to be defensible. They can't be, like,\nweird things, right? Every single one would\nhave to pass as a model.",
    "start": "2548187",
    "end": "2555320"
  },
  {
    "text": "So that's what you would do. ",
    "start": "2555320",
    "end": "2560600"
  },
  {
    "text": "OK. So, sorry, that was just a\nweird aside on all these things. OK.",
    "start": "2560600",
    "end": "2566170"
  },
  {
    "text": "But this is the picture. So you can actually do things\nlike stochastic robust least",
    "start": "2566170",
    "end": "2573250"
  },
  {
    "text": "squares. And I'll go through this because\nit actually is very cool, and it tells you about what\nregularization really is.",
    "start": "2573250",
    "end": "2579640"
  },
  {
    "text": "So here it is. So we're going to\ndo least squares.",
    "start": "2579640",
    "end": "2584690"
  },
  {
    "text": "Here we are. So it's 1805 now, and\nwe're doing least squares. And so our model is\ngoing to be stochastic.",
    "start": "2584690",
    "end": "2591820"
  },
  {
    "text": "We're going to say, well, no,\nI don't know A. A is A bar. That's kind of like\na nominal value of A,",
    "start": "2591820",
    "end": "2598840"
  },
  {
    "text": "plus U. Use a random\nmatrix, 0 mean. And let's say that the expected\nvalue [INAUDIBLE] is p.",
    "start": "2598840",
    "end": "2605740"
  },
  {
    "text": "So if p were like\nlittle sigma squared I, it says the entries are\nall completely independent,",
    "start": "2605740",
    "end": "2612160"
  },
  {
    "text": "and they're all perturbed\nby an n0 sigma squared, little sigma squared\nvalue independently,",
    "start": "2612160",
    "end": "2617900"
  },
  {
    "text": "and completely reasonable. By the way, if someone\ngives you a matrix and you say how accurate\nare the entries?",
    "start": "2617900",
    "end": "2623148"
  },
  {
    "text": "And they can't say,\nfind someone else to work with because\nin any practical--",
    "start": "2623148",
    "end": "2629020"
  },
  {
    "text": "if you can't say something\nlike, oh, those are pretty good, like, third significant digit\nis actually probably right.",
    "start": "2629020",
    "end": "2638032"
  },
  {
    "text": "That's one thing. Or if they say the second\ndigit is meaningless. So if they can't say anything,\nthen just find someone else",
    "start": "2638032",
    "end": "2645250"
  },
  {
    "text": "to work with because\nthis is not someone who knows what they're doing. Everybody got that? OK.",
    "start": "2645250",
    "end": "2650442"
  },
  {
    "text": "All right, so this is one of\nthose cases where you can just analytically work this out. I mean, you just expand\nthis, and you get",
    "start": "2650442",
    "end": "2656620"
  },
  {
    "text": "something really, really cool. It turns out you should\nsolve this problem here.",
    "start": "2656620",
    "end": "2662230"
  },
  {
    "text": "It's super interesting--\nit's super simple, right? And actually, now, let's\njust take p equals delta I.",
    "start": "2662230",
    "end": "2671050"
  },
  {
    "text": "So delta would be little sigma\nsquared I. Then it's very cool. You end up with this. And you go, oh, that's\nTikhonov regularization.",
    "start": "2671050",
    "end": "2677890"
  },
  {
    "text": "So you can turn this around. And someone says,\nwhat are you doing? And you go, well, I'm doing\nregularized least squares.",
    "start": "2677890",
    "end": "2684250"
  },
  {
    "text": "I'm doing ridge regression,\nyou would say here. Or you'd say Tikhonov\nregularization or something like that.",
    "start": "2684250",
    "end": "2689600"
  },
  {
    "text": "And they'd say, why? And one reason-- one\nthing you could say is, yeah, because I\ndon't know A, right?",
    "start": "2689600",
    "end": "2696407"
  },
  {
    "text": "And I think we already\ntalked about the fact that this makes sense because\nthe thing that happened--",
    "start": "2696407",
    "end": "2701630"
  },
  {
    "text": "Ax is sort of the result. If\nA is uncertain and x is big,",
    "start": "2701630",
    "end": "2706684"
  },
  {
    "text": "you get a lot of\nuncertainty in the result. If x is small, like if it's 0,\nit doesn't matter what A is. Everybody following this?",
    "start": "2706685",
    "end": "2713060"
  },
  {
    "text": "So this all sort of makes\nsense, but it's very cool so. It means that,\nwell, now you know",
    "start": "2713060",
    "end": "2718250"
  },
  {
    "text": "what taking Tikhonov\nregularization is or ridge regression is. It's basically saying\nthat all of your data-- I guess in, let's see,\nin a regression context,",
    "start": "2718250",
    "end": "2728660"
  },
  {
    "text": "you're basically saying, thank\nyou for all your features, your feature matrix\nbecause that's what A is.",
    "start": "2728660",
    "end": "2735260"
  },
  {
    "text": "Basically, it says I don't\ntrust all these features are plus/minus 0.01 with--",
    "start": "2735260",
    "end": "2741290"
  },
  {
    "text": "they're disturbed by\nindependent Gaussians. Everybody following this? So that's what\nthis-- and then it says, that suggests a\nTikhonov parameter, right?",
    "start": "2741290",
    "end": "2749869"
  },
  {
    "text": "So that makes sense? I think it's kind of cool. ",
    "start": "2749870",
    "end": "2757197"
  },
  {
    "text": "I'm not going to go\ninto the details of this because it's actually\nquite complicated. But you can actually\ndo a weird thing with--",
    "start": "2757197",
    "end": "2764230"
  },
  {
    "text": "you can actually\nhave-- you can actually work out the case\nwhere A is in-- this is",
    "start": "2764230",
    "end": "2770040"
  },
  {
    "text": "an ellipsoid in matrix space. That's what that is. This would be the analog\nof the previous one.",
    "start": "2770040",
    "end": "2775860"
  },
  {
    "text": "In the previous one,\nI made a-- well, I didn't say what\nthe distribution was, but I told you its first\nand second moments.",
    "start": "2775860",
    "end": "2781980"
  },
  {
    "text": "But I didn't say it was Gaussian\nor anything, but anyway. So here this would be like an--\nthis would be the ellipsoid.",
    "start": "2781980",
    "end": "2789660"
  },
  {
    "text": "And you'd say, any\nmatrix in this ellipsoid is a plausible model. You can actually-- I'm not\ngoing to go through it,",
    "start": "2789660",
    "end": "2795970"
  },
  {
    "text": "but it's actually-- these are\nthings that, oh, let's say, Lagrange would not have known. Let's just put it that way.",
    "start": "2795970",
    "end": "2802335"
  },
  {
    "text": "Probably could have\nexplained it to him pretty quickly, to be honest. But nevertheless-- well, OK,\nthey did have some questions,",
    "start": "2802335",
    "end": "2807650"
  },
  {
    "text": "like, how on earth do\nyou solve that problem? But we'd have an\nanswer for that, too?",
    "start": "2807650",
    "end": "2813260"
  },
  {
    "text": "So, OK, I'm not\ngoing to look at it. I won't go into the details\nbecause it's quite complicated,",
    "start": "2813260",
    "end": "2819500"
  },
  {
    "text": "but I'll just show\nyou the results, which are really very cool. Oh, and this is, by the\nway, the kind of thing",
    "start": "2819500",
    "end": "2824750"
  },
  {
    "text": "you'd expect to have. Let me explain what we're doing.",
    "start": "2824750",
    "end": "2831440"
  },
  {
    "text": "So, here's what we're\ndoing is, this is now-- I have a disk in matrix space. I mean, it's a baby\nexample, but I have a disk.",
    "start": "2831440",
    "end": "2838070"
  },
  {
    "text": "That's what this is\nif you think about it. It's two-dimensional. It goes off in these two\ndirections, A1 and A2.",
    "start": "2838070",
    "end": "2844310"
  },
  {
    "text": "I have a disk. And actually, I put a uniform\ndistribution on the disk, on the unit--",
    "start": "2844310",
    "end": "2850100"
  },
  {
    "text": "this unit disk. That's what actually happens. So this one is cool. This is x least squares.",
    "start": "2850100",
    "end": "2856280"
  },
  {
    "text": "That just says that's\nthe traditional method of handling uncertainty,\nwhich is ignore it. And I just plug in the\nmean and I calculate x.",
    "start": "2856280",
    "end": "2864599"
  },
  {
    "text": "And then you get\nthis distribution like this, which you should\ndo anyway just to check. And that's a message to you that\nyou probably shouldn't-- that",
    "start": "2864600",
    "end": "2873637"
  },
  {
    "text": "you need to be a little bit\nmore sophisticated than just ignoring uncertainty.",
    "start": "2873637",
    "end": "2878849"
  },
  {
    "text": "And let me just check\non a few things here. Let's describe. How would you describe\nin words these events?",
    "start": "2878850",
    "end": "2884805"
  },
  {
    "text": " What would you say? ",
    "start": "2884805",
    "end": "2893560"
  },
  {
    "text": "Worst-case scenario? Yeah. You just say, look, this is bad. These are perturbations\nto A where my choice of x",
    "start": "2893560",
    "end": "2898930"
  },
  {
    "text": "gave me a really big residual. So this is bad luck or\nsomething Oh, by the way,",
    "start": "2898930",
    "end": "2904420"
  },
  {
    "text": "how do you describe these? Best-case good luck. Yeah.",
    "start": "2904420",
    "end": "2909720"
  },
  {
    "text": "What'd you call them? Good luck. Yeah. How about dumb luck? Because you're using\na dumb method, right?",
    "start": "2909720",
    "end": "2916500"
  },
  {
    "text": "And sure enough, 5% of the\ntime, the perturbation of A is in a way that\nactually helped you.",
    "start": "2916500",
    "end": "2922170"
  },
  {
    "text": "So this is-- I would\ncall this dumb luck.  Then we look at Tikhonov\nhere, or ridge regression,",
    "start": "2922170",
    "end": "2931290"
  },
  {
    "text": "if you want to-- that's a\ndifferent dialect for it. So if you do ridge\nregression, you get this. And actually, it's\nreally cool to see what--",
    "start": "2931290",
    "end": "2938280"
  },
  {
    "text": "I mean, you see immediately kind\nof what adding regularization does. It tightens the distribution\nwith respect-- in this case,",
    "start": "2938280",
    "end": "2945760"
  },
  {
    "text": "it's with respect to a\nvery specific perturbation of the parameters. So that's this one.",
    "start": "2945760",
    "end": "2950790"
  },
  {
    "text": "And then when you do the\nrobustly squares, I mean, that's unfair because we told\nit exactly what the disk was",
    "start": "2950790",
    "end": "2959670"
  },
  {
    "text": "and stuff like that. And you can see you get\nthis beautiful, very tight distribution. So make sense?",
    "start": "2959670",
    "end": "2966880"
  },
  {
    "text": "Yeah. OK. OK. So this is-- and these are\nall convex problems and stuff",
    "start": "2966880",
    "end": "2974040"
  },
  {
    "text": "like that. So, OK. All right, so our next topic\nis statistical estimation.",
    "start": "2974040",
    "end": "2982420"
  },
  {
    "text": "It's extremely elementary,\nbut we'll talk about-- it's sort of interesting.",
    "start": "2982420",
    "end": "2987858"
  },
  {
    "text": "So actually, it's one\nof those things where if you haven't seen this stuff\nbefore, you are probably-- you're not going to\nunderstand it from what I say.",
    "start": "2987858",
    "end": "2994900"
  },
  {
    "text": "And if you've seen\nit before, you'll be bored out of your mind\nor something like that. So I'll probably tell some weird\nstories through it, anyway,",
    "start": "2994900",
    "end": "3000960"
  },
  {
    "text": "just to make it more\ninteresting, but here we go. So we'll just start with\nparametric distribution",
    "start": "3000960",
    "end": "3007020"
  },
  {
    "text": "estimation. So here's the idea, is\nthat we have a density--",
    "start": "3007020",
    "end": "3014580"
  },
  {
    "text": "and we have an observed\nvalue of something. We have a density,\nbut the density",
    "start": "3014580",
    "end": "3020550"
  },
  {
    "text": "is indexed by a parameter. For example, a Gaussian\nwould be indexed by, let's say, its mean and its\ncovariance matrix, let's say,",
    "start": "3020550",
    "end": "3028260"
  },
  {
    "text": "right? Or a Poisson variable by its\nrate or something like this,",
    "start": "3028260",
    "end": "3033690"
  },
  {
    "text": "or an exponential variable by\nits rate or whatever it is. So you'd have parameters.",
    "start": "3033690",
    "end": "3039369"
  },
  {
    "text": "And what we'll do is we'll put\nthe parameter as a subscript. So Px of y is going to be the\ndensity with parameter values",
    "start": "3039370",
    "end": "3050049"
  },
  {
    "text": "x at the point y. So that's going to be--",
    "start": "3050050",
    "end": "3056470"
  },
  {
    "text": "that is going to be-- that that's called the\nlikelihood function.",
    "start": "3056470",
    "end": "3062710"
  },
  {
    "text": "People often work with the\nlog likelihood function. Obviously, maximizing a\nlikelihood and a log likelihood",
    "start": "3062710",
    "end": "3068980"
  },
  {
    "text": "are the same thing. And so you would have\nsomething that looks like this. So here this is an\nestimator for x,",
    "start": "3068980",
    "end": "3075070"
  },
  {
    "text": "and you're given y,\nwhich is an observation. And I mean, it kind\nof makes sense, and you could argue a\nlot of things about it.",
    "start": "3075070",
    "end": "3081320"
  },
  {
    "text": "And if you take a\nstatistics 101 class, you'll hear a lot about\nproperties of this.",
    "start": "3081320",
    "end": "3087080"
  },
  {
    "text": "OK. So that's maximum\nlikelihood estimation. So as I said, this is called\nthe log likelihood function.",
    "start": "3087080",
    "end": "3093974"
  },
  {
    "text": "By the way, here\nwhat we're doing is we're considering\nthis a function of x, which is the parameter in\nthe distribution, not of y.",
    "start": "3093975",
    "end": "3101069"
  },
  {
    "text": " And you can add\nconstraints to this.",
    "start": "3101070",
    "end": "3109210"
  },
  {
    "text": "I mean, for example, if x\nis-- if this is a Gaussian distribution, let's say, scalar\nwith mean mu and standard",
    "start": "3109210",
    "end": "3117910"
  },
  {
    "text": "deviation little sigma,\nthen little sigma has to be positive.",
    "start": "3117910",
    "end": "3123520"
  },
  {
    "text": "Like, otherwise, it\nmakes no sense at all. So you could add-- you would\nadd that as a constraint, or simply define the\nlikelihood to be 0.",
    "start": "3123520",
    "end": "3131589"
  },
  {
    "text": "If you say, well, what\ndensity do I get when--",
    "start": "3131590",
    "end": "3137890"
  },
  {
    "text": "what's my likelihood if I guess\nthat the standard deviation is minus 1? I mean, aside from that\nbeing profoundly stupid,",
    "start": "3137890",
    "end": "3144549"
  },
  {
    "text": "you just get 0. And then log of 0\nis minus infinity.",
    "start": "3144550",
    "end": "3149900"
  },
  {
    "text": "And that means you did a\nvery bad job of maximizing. So, OK. You can add regularization, too.",
    "start": "3149900",
    "end": "3156039"
  },
  {
    "text": "So, regularized maximum\nlikelihood you could do. So the question is,\nwhen is this convex?",
    "start": "3156040",
    "end": "3161980"
  },
  {
    "text": "And it's convex when the log\nlikelihood function is concave.",
    "start": "3161980",
    "end": "3169070"
  },
  {
    "text": "So now you have to be super\ncareful because up till now, we saw the idea of a log concave\ndistribution or density.",
    "start": "3169070",
    "end": "3176370"
  },
  {
    "text": "So a density is log\nconcave if, when you fix x, this thing is concave and y.",
    "start": "3176370",
    "end": "3183380"
  },
  {
    "text": "That's a log concave density. This is not that.",
    "start": "3183380",
    "end": "3188900"
  },
  {
    "text": "This is the opposite. This is, how does this\nvary as a function of when",
    "start": "3188900",
    "end": "3194960"
  },
  {
    "text": "you fix y of x, which is the\nparameter in the distribution? Everybody got that? Now, it's going to turn out\nthat there's lots of cases--",
    "start": "3194960",
    "end": "3202490"
  },
  {
    "text": "like, if it's an\nexponential family, I mean, then it's going to turn\nout they're the same thing.",
    "start": "3202490",
    "end": "3207750"
  },
  {
    "text": "But in general,\nthey're different. So I'm just going\nslow just to make sure this is all totally clear.",
    "start": "3207750",
    "end": "3214300"
  },
  {
    "text": "OK. So that's it. So roughly speaking, maximum\nlikelihood is estimation",
    "start": "3214300",
    "end": "3220320"
  },
  {
    "text": "is a convex problem when the log\nlikelihood function is concave,",
    "start": "3220320",
    "end": "3226600"
  },
  {
    "text": "which is not the same as saying\nthat the densities are all log",
    "start": "3226600",
    "end": "3231630"
  },
  {
    "text": "concave. That's a different thing. OK. So we'll just look at\nsome simple examples here.",
    "start": "3231630",
    "end": "3237340"
  },
  {
    "text": "So here's one. It's a traditional\nlinear measurement model. So I make a bunch\nof measurements,",
    "start": "3237340",
    "end": "3245339"
  },
  {
    "text": "and they're going\nto look like Yi. So Yi is-- and my model is\ngoing to be that each Yi,",
    "start": "3245340",
    "end": "3251370"
  },
  {
    "text": "which is a scalar, is a\nlinear function of x here plus",
    "start": "3251370",
    "end": "3257490"
  },
  {
    "text": "a noise, which is independent-- which is independent\nacross different i's.",
    "start": "3257490",
    "end": "3262980"
  },
  {
    "text": "So that's what the model is. And so actually, it's kind of\ninteresting because someone in like EE or something\nlike that would describe",
    "start": "3262980",
    "end": "3269880"
  },
  {
    "text": "this in a pretty simple way. They would say something\nlike, x is what you really want to measure.",
    "start": "3269880",
    "end": "3275190"
  },
  {
    "text": "Ai tells you what your\ni'th measurement is. Oh, that's a radar snapshot\nfrom this position like that.",
    "start": "3275190",
    "end": "3281760"
  },
  {
    "text": "Or A7 is what I deduce\nfrom some GPS thing or something like that.",
    "start": "3281760",
    "end": "3288210"
  },
  {
    "text": "And they say, well,\nyou-- that's how they would describe the problem. But a statistician would\nhave to describe it",
    "start": "3288210",
    "end": "3294640"
  },
  {
    "text": "this way-- they\nwould say that what you observe from your\nsensor suite actually",
    "start": "3294640",
    "end": "3300250"
  },
  {
    "text": "comes from a distribution. And you go, oh, OK. And then you say, ah,\nthe distribution changes.",
    "start": "3300250",
    "end": "3307360"
  },
  {
    "text": "It's parametrized by this x. Everybody got that? I mean, they're\nsaying the same thing, but I'm just saying this is a\nlanguage a statistician would",
    "start": "3307360",
    "end": "3314800"
  },
  {
    "text": "use. And then they would\nsay, so your problem is really to estimate\nwhich distribution",
    "start": "3314800",
    "end": "3320050"
  },
  {
    "text": "generated the measurements, the\n27 measurements you actually got. Everybody following this?",
    "start": "3320050",
    "end": "3326530"
  },
  {
    "text": "Whereas, I think a normal person\nwould just say something like, that's the model. These are the 27\nmeasurements I got.",
    "start": "3326530",
    "end": "3332410"
  },
  {
    "text": "These are independent. Could you please\nguess what x is? So I mean, I have lots of\nfriends who are statisticians,",
    "start": "3332410",
    "end": "3337990"
  },
  {
    "text": "so this is fine. So all fine. Actually, that's how I can-- I've learned-- I've\npicked up their dialect.",
    "start": "3337990",
    "end": "3344859"
  },
  {
    "text": "Actually, makes me very nervous\nwhen I-- anyway, so it's-- which, I, of course, enjoy.",
    "start": "3344860",
    "end": "3350270"
  },
  {
    "text": "So, anyway. All right. OK. So let's see how this works. Well, if Y-- these\nare independent.",
    "start": "3350270",
    "end": "3360740"
  },
  {
    "text": "So what you're really saying\nhere is something like, Yi minus Ai transpose\nx, which is Vi--",
    "start": "3360740",
    "end": "3366230"
  },
  {
    "text": "these are independent. So the density is the\nproduct of the densities.",
    "start": "3366230",
    "end": "3371240"
  },
  {
    "text": "So the density of the\nvector of measurements is equal to this\nthing over here.",
    "start": "3371240",
    "end": "3377180"
  },
  {
    "text": "And you take the log of\nthat, and you get this. And here, this is-- we want to--",
    "start": "3377180",
    "end": "3385460"
  },
  {
    "text": "the variable here is x. So what's interesting\nhere is this is when is--",
    "start": "3385460",
    "end": "3393800"
  },
  {
    "text": "this thing is a\nconvex problem, which is to say that the log\nlikelihood is convex.",
    "start": "3393800",
    "end": "3398810"
  },
  {
    "text": "In this case, it\ncoincides exactly with the density\nbeing log concave.",
    "start": "3398810",
    "end": "3404000"
  },
  {
    "text": "So this is a case where the two\nare the same, because actually",
    "start": "3404000",
    "end": "3409650"
  },
  {
    "text": "you see something here. It's because basically the x--",
    "start": "3409650",
    "end": "3416700"
  },
  {
    "text": "if this thing is log-- so if it's a log concave\ndensity, then this is-- that tells you that\nthis is concave in--",
    "start": "3416700",
    "end": "3424320"
  },
  {
    "text": "log p is concave in this. But if log concave\nis- if p is such",
    "start": "3424320",
    "end": "3430050"
  },
  {
    "text": "that this is a concave\nfunction, then this is precomposition with\nan affine function.",
    "start": "3430050",
    "end": "3435300"
  },
  {
    "text": "And so these are\nconcave functions of x. That makes sense? So that's the picture.",
    "start": "3435300",
    "end": "3441060"
  },
  {
    "text": "OK. So all right. And let's look at some\nspecific examples.",
    "start": "3441060",
    "end": "3446640"
  },
  {
    "text": "So someone says, OK,\nthe noises are Gaussian. And you'd say, well, here's\nthe log likelihood function.",
    "start": "3446640",
    "end": "3452970"
  },
  {
    "text": "And you see it's a constant\nminus, a quadratic.",
    "start": "3452970",
    "end": "3458280"
  },
  {
    "text": "And what you see immediately is\nthe maximum likelihood solution is the least squares solution.",
    "start": "3458280",
    "end": "3464300"
  },
  {
    "text": "So this says if you're\ndoing least squares and you want to make it sound\nfancy and brush someone off, they'd say, what are you doing?",
    "start": "3464300",
    "end": "3470072"
  },
  {
    "text": "And you go, oh, I'm doing\nmaximum likelihood estimation with a Gaussian distribution,\nnoise distribution,",
    "start": "3470072",
    "end": "3475560"
  },
  {
    "text": "or something like that. So everybody got that?",
    "start": "3475560",
    "end": "3480870"
  },
  {
    "text": "OK. You could have--\nlet's make the noise-- let's make the noise Laplacian.",
    "start": "3480870",
    "end": "3487650"
  },
  {
    "text": "So Laplacian means that it\nlooks like-- the density looks like this.",
    "start": "3487650",
    "end": "3495330"
  },
  {
    "text": "Here's 0. And it goes like this. And out here, it's got way, way\nbigger tails than a Gaussian",
    "start": "3495330",
    "end": "3505560"
  },
  {
    "text": "and for the same-- let's say,\nfor the same whatever variance. So that's-- and what this says\nis you now take the log of this",
    "start": "3505560",
    "end": "3515118"
  },
  {
    "text": "and you end up with this. And you see that's cool. So maximum likelihood\nestimation with Laplacian noise",
    "start": "3515118",
    "end": "3524069"
  },
  {
    "text": "is basically L1 estimation. By the way, we can actually\nnow figure something out.",
    "start": "3524070",
    "end": "3530549"
  },
  {
    "text": "We can understand robustness now\nfrom two completely different things.",
    "start": "3530550",
    "end": "3535589"
  },
  {
    "text": "Earlier today, I was\njust drawing down-- let's do the-- let's compare\nthe square and the quadratic,",
    "start": "3535590",
    "end": "3542510"
  },
  {
    "text": "right? So the square penalty\nlooks like this,",
    "start": "3542510",
    "end": "3547720"
  },
  {
    "text": "and then the absolute\nvalue looks like that. ",
    "start": "3547720",
    "end": "3553740"
  },
  {
    "text": "We'd say if you're,\nagain, not-- if you're not doing a statistical\ninterpretation, you would say,\nwell, the difference",
    "start": "3553740",
    "end": "3560010"
  },
  {
    "text": "between least squares and\nL1 estimation-- there's two, really. One, let's focus on\nthe large residuals.",
    "start": "3560010",
    "end": "3569460"
  },
  {
    "text": "You'd say, well,\nleast squares is going to be very sensitive\nto large residuals. Like, it really doesn't like\nhim because it squares them.",
    "start": "3569460",
    "end": "3575910"
  },
  {
    "text": "And you'd say, by contrast, L1\nis going to be much more chill. Everybody got what I'm saying? And so you'd say, and\nwhat does that mean?",
    "start": "3575910",
    "end": "3582510"
  },
  {
    "text": "And you go, well,\nwhat it means is that when you do L1\nestimation, it's much less",
    "start": "3582510",
    "end": "3588300"
  },
  {
    "text": "sensitive to outliers. That's what it means. So it's a robust estimator,\nactually, literally",
    "start": "3588300",
    "end": "3594390"
  },
  {
    "text": "in the statistics sense. So it's a robust estimator. OK.",
    "start": "3594390",
    "end": "3599670"
  },
  {
    "text": "What's cool is you get the\nsame-- you can argue it here. You could say, well, the\ndifference between L2 fitting",
    "start": "3599670",
    "end": "3607079"
  },
  {
    "text": "and L1 approximation-- you\nsay the difference is actually basically this. It's a difference\nbetween whether you",
    "start": "3607080",
    "end": "3613360"
  },
  {
    "text": "believe the noise\ndensity looks like this or it looks like this.",
    "start": "3613360",
    "end": "3620230"
  },
  {
    "text": "That's a pretty bad job. It's a horrible Gaussian,\nbut you get the idea. So it looks like that.",
    "start": "3620230",
    "end": "3626410"
  },
  {
    "text": "And actually, you pick\neverything off from this. You would say,\nlook, if you thought",
    "start": "3626410",
    "end": "3633460"
  },
  {
    "text": "your noises were Laplacian, then\nthe probability of a 3 sigma event is not insignificant.",
    "start": "3633460",
    "end": "3640330"
  },
  {
    "text": "I mean, you could\nexpect to have thing-- you could expect\nto have a noise, which is like three times\nthe standard deviation--",
    "start": "3640330",
    "end": "3646150"
  },
  {
    "text": "that's the whole point-- or four times, or\nsomething in there. It can happen. Gaussian can't happen.",
    "start": "3646150",
    "end": "3652053"
  },
  {
    "text": "I mean, kind of. You what I mean? It's extremely unlikely. So you'd say-- so if I\nwere you, your estimation--",
    "start": "3652053",
    "end": "3658869"
  },
  {
    "text": "if it's going to work well, it\ncannot be sensitive to these large noises. Everybody following this?",
    "start": "3658870",
    "end": "3664990"
  },
  {
    "text": "So that's why. So that explains\nwhy L1 estimation",
    "start": "3664990",
    "end": "3670160"
  },
  {
    "text": "would be actually more\nrobust than the other one because you're basically\nfitting with the presumption",
    "start": "3670160",
    "end": "3676940"
  },
  {
    "text": "that your noises have fat tails. ",
    "start": "3676940",
    "end": "3682000"
  },
  {
    "text": "Oh, and this is actually\ninteresting, too. This is not the main point,\nbut if you look up here, it's actually super interesting.",
    "start": "3682000",
    "end": "3688790"
  },
  {
    "text": "So if you zoom in\non a Gaussian, it's uniform density at the top. it just looks-- it's uniform.",
    "start": "3688790",
    "end": "3695150"
  },
  {
    "text": "And you're saying, well,\nwhat that means is, I don't-- know it means once\nyour residual is smaller than",
    "start": "3695150",
    "end": "3701630"
  },
  {
    "text": "when you zoom in and a\nGaussian looks like it's flat, once your residual is in there,\nyou don't care if it's 0.01",
    "start": "3701630",
    "end": "3707900"
  },
  {
    "text": "or minus 0.03, you\ncouldn't care less. They're all equally likely--\nstatistically speaking, they're all reason--\neverybody see what I'm saying?",
    "start": "3707900",
    "end": "3715640"
  },
  {
    "text": "For a Laplacian noise,\nthat's not the case.",
    "start": "3715640",
    "end": "3720920"
  },
  {
    "text": "As a matter of fact,\nthere's a sharp peak. And actually being 0 is\nactually quite likely.",
    "start": "3720920",
    "end": "3726420"
  },
  {
    "text": "And that explains also why\nyou get the sparsity and stuff like that. But, OK. So this all makes sense?",
    "start": "3726420",
    "end": "3732330"
  },
  {
    "text": "And let's do one\nmore just for fun. And you can turn this\nbackwards and forwards, so let's do one more.",
    "start": "3732330",
    "end": "3738960"
  },
  {
    "text": "You tell me--\nsuppose someone says, I'm going to use Huber fitting. That looks like this.",
    "start": "3738960",
    "end": "3744430"
  },
  {
    "text": "It's quadratic up\nto some threshold, and then it goes linear, OK? So there's Huber fitting.",
    "start": "3744430",
    "end": "3751052"
  },
  {
    "text": "And someone says, why\nare you doing that? And you go, well,\nbecause it's, like, I want to do least squares,\nbut I want to be--",
    "start": "3751052",
    "end": "3757680"
  },
  {
    "text": "I want to be insensitive\nto occasional, weird, large noises. Done-- that's more than a\ngood enough explanation.",
    "start": "3757680",
    "end": "3764850"
  },
  {
    "text": "But suppose you want to\ndefend it statistically. In fact, how would\nyou describe it? How would you say-- what\nis Huber fitting when",
    "start": "3764850",
    "end": "3770640"
  },
  {
    "text": "you're doing it statistically? How do you-- what is it in\nterms of maximum likelihood? How do you translate\nit to that dialect?",
    "start": "3770640",
    "end": "3776355"
  },
  {
    "text": " What's Hubert fitting with--",
    "start": "3776355",
    "end": "3782830"
  },
  {
    "text": "I mean, what maximum likelihood\nproblem does it correspond to? ",
    "start": "3782830",
    "end": "3791630"
  },
  {
    "text": "This is like a mix of the two? It's not a mixture. It's close.",
    "start": "3791630",
    "end": "3797550"
  },
  {
    "text": "It's actually pretty close\nto a mixture, but it's not. It's actually a weird--\nit says, oh, I'm doing maximum likelihood estimation.",
    "start": "3797550",
    "end": "3803760"
  },
  {
    "text": "You go, with what noise density? And they would say, well,\nit's this weird Frankenstein",
    "start": "3803760",
    "end": "3809340"
  },
  {
    "text": "density that looks like this. It looks like this. It's a Gaussian.",
    "start": "3809340",
    "end": "3815700"
  },
  {
    "text": "it's actually E\nto the minus this. So it's actually, literally,\nexactly a Gaussian out",
    "start": "3815700",
    "end": "3823019"
  },
  {
    "text": "to some threshold. And then, you glue on to\nit an exponential tail.",
    "start": "3823020",
    "end": "3829308"
  },
  {
    "text": "Everybody got that? Because that's what the x of\nthe Huber thing is, right? You have to normalize\nit, but who cares?",
    "start": "3829308",
    "end": "3834992"
  },
  {
    "text": "But it looks like that. Everyone agree? And someone said, well,\nwhat are you doing? And you go, I'm doing maximum\nlikelihood estimation.",
    "start": "3834992",
    "end": "3841260"
  },
  {
    "text": "And you go, then why aren't\nyou using-- it and you say, it's pretty much Gaussian, but\nI'm going to use Huber instead.",
    "start": "3841260",
    "end": "3846390"
  },
  {
    "text": "And they'd say,\nwhat does that mean? And you say, well,\nwhat it really means is I'm assuming that\nmy noise density, this thing",
    "start": "3846390",
    "end": "3854180"
  },
  {
    "text": "would go way down. I mean, I'd have to adjust\nthings to get the normalization right, but whatever. The density is\nproportional to this.",
    "start": "3854180",
    "end": "3860549"
  },
  {
    "text": "So what you do is you\njust take a Gaussian, cut it, and then glue\non exponential tails.",
    "start": "3860550",
    "end": "3866750"
  },
  {
    "text": "If you do maximum likelihood\nestimation, congratulations, you're doing Huber fitting.",
    "start": "3866750",
    "end": "3872319"
  },
  {
    "text": "Everybody got this? Makes sense? So there's lots of\nways to understand exactly the same thing.",
    "start": "3872320",
    "end": "3879349"
  },
  {
    "text": "What about-- what if I did-- what if I did fitting\nwith a, I don't know, here",
    "start": "3879350",
    "end": "3886820"
  },
  {
    "text": "with a dead zone linear penalty? ",
    "start": "3886820",
    "end": "3892579"
  },
  {
    "text": "That's maximum\nlikelihood for what? ",
    "start": "3892580",
    "end": "3900106"
  },
  {
    "text": "What's your noise\ndensity for that? ",
    "start": "3900106",
    "end": "3907069"
  },
  {
    "text": "Yeah. You say, well, my noise is this. It's actually flat--\nit's a uniform.",
    "start": "3907070",
    "end": "3913660"
  },
  {
    "text": "It's a uniform\nover some interval. And then that's some\nfraction of the probability. And then I glue on exp--",
    "start": "3913660",
    "end": "3919810"
  },
  {
    "text": "I glue on exponential tails. So you'd say actually,\nbetween plus and minus 0.1,",
    "start": "3919810",
    "end": "3925540"
  },
  {
    "text": "it's just uniform. I mean, you're equally likely\nto have anything in there in the noise. And you'd say,\noccasionally, though, you",
    "start": "3925540",
    "end": "3931450"
  },
  {
    "text": "get some big things, and those\nare these exponential tails you glued on.",
    "start": "3931450",
    "end": "3936900"
  },
  {
    "text": "All make sense? So, OK. OK.",
    "start": "3936900",
    "end": "3942040"
  },
  {
    "text": "We'll look at just\na couple of others. So, logistic regression, which\nI very much hope many people",
    "start": "3942040",
    "end": "3949330"
  },
  {
    "text": "have seen. But anyway. And it's the same sort of thing. You would say I have a--",
    "start": "3949330",
    "end": "3957910"
  },
  {
    "text": "here I have a random\nvariable, takes values 01. And the probability of\nbeing 1 is a logistic",
    "start": "3957910",
    "end": "3965090"
  },
  {
    "text": "of this thing, which\nis an affine function of some features or\nexplanatory variables",
    "start": "3965090",
    "end": "3970550"
  },
  {
    "text": "that you can see right. So that's what it would be.",
    "start": "3970550",
    "end": "3976070"
  },
  {
    "text": "And so that is the-- and here you would say something\nlike, conditioned on you,",
    "start": "3976070",
    "end": "3983710"
  },
  {
    "text": "you'd say the density or, sorry,\nthe probability mass function, or just the probability\nthat it's 1.",
    "start": "3983710",
    "end": "3990050"
  },
  {
    "text": "It depends on a parameter\nwhich is A and B. If you just take the-- if you take the log of this,\nyou end up with this thing,",
    "start": "3990050",
    "end": "3997722"
  },
  {
    "text": "and it comes down here. And you can see immediately\nthat this is going to be concave because that's affine.",
    "start": "3997722",
    "end": "4005460"
  },
  {
    "text": "And then this is log sum exp\nbecause this is exp of 0. So this is log sum exp.",
    "start": "4005460",
    "end": "4013320"
  },
  {
    "text": "I think that's\nthe logistic loss. And with a minus sign,\nit becomes concave. And affine is concave.",
    "start": "4013320",
    "end": "4020010"
  },
  {
    "text": "So that's a-- I'm sure people have seen this. so that's the idea.",
    "start": "4020010",
    "end": "4026400"
  },
  {
    "text": "So that's logistic modeling. And then this would just be\nlike a little baby example.",
    "start": "4026400",
    "end": "4032440"
  },
  {
    "text": "so. The example is here I have\none explanatory variable U, which might be age or--",
    "start": "4032440",
    "end": "4039250"
  },
  {
    "text": "I don't know, I'm just\nmaking this up, age. And this is the, I don't\nknow, the probability that when you're admitted\nfor something to the ER,",
    "start": "4039250",
    "end": "4048127"
  },
  {
    "text": "I don't know, you survive. I mean, I'm just making this up. But that would be it. Oh, it looks like young\npeople don't do very well,",
    "start": "4048127",
    "end": "4054920"
  },
  {
    "text": "and older people do pretty well. Maybe this is the-- maybe that's the probability\nthat you don't survive. How about that?",
    "start": "4054920",
    "end": "4060280"
  },
  {
    "text": "And then this makes sense. Then it has the right flavor. So, OK.",
    "start": "4060280",
    "end": "4065800"
  },
  {
    "text": "And so these dots\nare your sample-- the data you have. You'd say, here's someone\nwho was 63, didn't survive.",
    "start": "4065800",
    "end": "4074180"
  },
  {
    "text": "Here's someone who was 27,\ndid survive or something like, that kind of thing. That's the data.",
    "start": "4074180",
    "end": "4079450"
  },
  {
    "text": "And your eyeball\nwould look at it and say, look, the\nprobability of being 1",
    "start": "4079450",
    "end": "4084850"
  },
  {
    "text": "is higher when U is large. But there's things\nthat are not obvious. Like, how about there?",
    "start": "4084850",
    "end": "4091480"
  },
  {
    "text": "There's someone,\nlike, really old. And for whatever\nreason, they survived, or something like that. I'm just making this up.",
    "start": "4091480",
    "end": "4097450"
  },
  {
    "text": "OK. And if you fit-- now, that's just a\nconvex problem to fit it.",
    "start": "4097450",
    "end": "4102970"
  },
  {
    "text": "And you would fit\nit, and you would-- you'd end up with\nthis curve here.",
    "start": "4102970",
    "end": "4108639"
  },
  {
    "text": "So it looks like\nthat, this curve here. It kind of makes sense. Let me ask a couple of\nquestions about this.",
    "start": "4108640",
    "end": "4116060"
  },
  {
    "text": "What if the data actually\nlooked like this? ",
    "start": "4116060",
    "end": "4122450"
  },
  {
    "text": "What if the data\nlooked like this? Here's you. And suppose it looked like--\nhere's 1 and here's 0.",
    "start": "4122450",
    "end": "4127630"
  },
  {
    "text": "And suppose there's a whole\nbunch of points along here, and then there's a whole\nbunch of points along here. ",
    "start": "4127630",
    "end": "4137528"
  },
  {
    "text": "So a couple of questions--\nwhat does it mean? Tell me about the maximum\nlikelihood problem.",
    "start": "4137529",
    "end": "4143490"
  },
  {
    "text": "And let's just talk about that. So what does it mean? ",
    "start": "4143490",
    "end": "4152729"
  },
  {
    "text": "This just means, look,\neveryone less than 32 survived. No one above that\nage survived, OK?",
    "start": "4152729",
    "end": "4158180"
  },
  {
    "text": "So you tell me\nwhat does it mean? I mean, there's so many ways to\nsay this in different dialects.",
    "start": "4158180",
    "end": "4164509"
  },
  {
    "text": "It's-- yeah. They're linearly separable. Yeah. You would say that the data\nare linearly separable.",
    "start": "4164510",
    "end": "4170568"
  },
  {
    "text": "OK. How about the-- what\nabout the logistic?",
    "start": "4170569",
    "end": "4175729"
  },
  {
    "text": "Sorry, the log likelihood? Suppose I asked you to-- suppose\nI ask you to maximize the log",
    "start": "4175729",
    "end": "4181250"
  },
  {
    "text": "likelihood here. Again, you can just\nguess, or you might know. But what do you think\nis going to happen?",
    "start": "4181250",
    "end": "4186845"
  },
  {
    "start": "4186845",
    "end": "4195310"
  },
  {
    "text": "Any guesses? How should I draw your actual--",
    "start": "4195310",
    "end": "4201699"
  },
  {
    "text": "I'll draw the logistic\nmap corresponding to the maximum likelihood. What's it going to look like?",
    "start": "4201700",
    "end": "4207760"
  },
  {
    "text": "Yeah, OK. I'll take your-- it's\ngoing to look like this. It's going to have a super\nsharp like that, right?",
    "start": "4207760",
    "end": "4214290"
  },
  {
    "text": "OK. How sharp is this going to be? Infinitely sharp because the\nless sharp you make this,",
    "start": "4214290",
    "end": "4221220"
  },
  {
    "text": "you start dropping\nthe probability here. But you know\neveryone over age 33 survived, so you're losing\nlog likelihood, right?",
    "start": "4221220",
    "end": "4229440"
  },
  {
    "text": "And the other thing,\ntoo, is if you make this less than\ninfinite slope here,",
    "start": "4229440",
    "end": "4234570"
  },
  {
    "text": "then you're shortchanging\nthe predictions here. So in this case,\nthis is precisely",
    "start": "4234570",
    "end": "4240900"
  },
  {
    "text": "the case when the log\nlikelihood is unbounded above.",
    "start": "4240900",
    "end": "4247100"
  },
  {
    "text": "So this is extremely\ncommon in models. If the log likelihood\nis unbounded above, it means they're separable\nand stuff like that.",
    "start": "4247100",
    "end": "4254450"
  },
  {
    "text": "So, of course, this is fixed\nby regression and things like that. Sorry, by adding regularization.",
    "start": "4254450",
    "end": "4259490"
  },
  {
    "text": "So that's fine. OK. All right, our last\ntopic is just a sort",
    "start": "4259490",
    "end": "4267670"
  },
  {
    "text": "of a whirlwind of topics. There's more in the book, which\nwe expect you to be reading. ",
    "start": "4267670",
    "end": "4275050"
  },
  {
    "text": "And the last one is just on kind\nof basic hypothesis testing.",
    "start": "4275050",
    "end": "4280210"
  },
  {
    "text": "And the setting here,\nit's super simple setting. It just says I have\na random variable.",
    "start": "4280210",
    "end": "4286010"
  },
  {
    "text": "And for fun, I'm just going to\nmake it with values in 1 to n. ",
    "start": "4286010",
    "end": "4291614"
  },
  {
    "text": "And it was generated\nfrom two different-- one of two different distributions. And you have to guess which\none it was generated from.",
    "start": "4291615",
    "end": "4299818"
  },
  {
    "text": "Did it come from P? Did it come from Q? That's your question. I mean, it's the\nbasic question here.",
    "start": "4299818",
    "end": "4306730"
  },
  {
    "text": "And the way that's\ngoing to work is an outcome is going to happen. Like, I'm going to\nsay, OK, I observe 7.",
    "start": "4306730",
    "end": "4314680"
  },
  {
    "text": "And then from that,\nyou have to guess Was. It from distribution P or Q?",
    "start": "4314680",
    "end": "4321820"
  },
  {
    "text": "You could almost guess. Or from a course,\nyou would certainly know what the optimal guess is.",
    "start": "4321820",
    "end": "4331090"
  },
  {
    "text": "I mean, it'd be very weird if\nP7 was like 0.8 or something",
    "start": "4331090",
    "end": "4337300"
  },
  {
    "text": "and Q7 was 0.05. And I said 7 is what occurred. Which one do you\nthink it came from?",
    "start": "4337300",
    "end": "4343470"
  },
  {
    "text": "And you go, oh, Q. It's just-- I mean, if you\nthink carefully about it, that's weird. I mean, unless\nyou know something",
    "start": "4343470",
    "end": "4349210"
  },
  {
    "text": "you secretly behind the--\nyou must know something. And you go, whoa, it's much\nmore likely with the first model",
    "start": "4349210",
    "end": "4355180"
  },
  {
    "text": "than the second. And you go, yeah, but I've\nbeen doing this for 20 years. I got a good feel\nfor these things. So go with Q. I mean,\nanyway, I'm just",
    "start": "4355180",
    "end": "4363010"
  },
  {
    "text": "saying you can even\nguess what it is, but we'll just work\nout what it is. OK.",
    "start": "4363010",
    "end": "4368063"
  },
  {
    "text": "So what we're going\nto do is we're going to look at a\nrandomized detector. And a randomized detector\nis like a 2 by n matrix.",
    "start": "4368063",
    "end": "4374830"
  },
  {
    "text": "It's a very weird thing. It looks like this. So it's a 2 by n matrix. It looks like 0.8,\n0.2, 1, 0, 0, 1.",
    "start": "4374830",
    "end": "4384340"
  },
  {
    "text": "That's good. And 0.3 and 0.7. And let's say this is P and\nQ, and this is the outcome.",
    "start": "4384340",
    "end": "4392900"
  },
  {
    "text": "This is 1 and that's n. So the idea here is\nthis is my detector.",
    "start": "4392900",
    "end": "4398469"
  },
  {
    "text": "It's a policy. And what it does is it says\nthat if the outcome is 2, I will simply say it\ncame from P. Period.",
    "start": "4398470",
    "end": "4407090"
  },
  {
    "text": "Everybody following this? If the outcome is\n3, I'll say it came from Q. If the outcome\nis 1, I will then",
    "start": "4407090",
    "end": "4415679"
  },
  {
    "text": "do something very weird. I'll flip a coin\nwith probability 0.8. And if it comes up heads,\nI'll say it's P. Otherwise,",
    "start": "4415680",
    "end": "4422849"
  },
  {
    "text": "I'll say it's Q.\neverybody got that? By the way, we're going\nto see examples where",
    "start": "4422850",
    "end": "4428670"
  },
  {
    "text": "you need a randomized detector. Oh, a deterministic detector\nis when all the numbers in that matrix are 0 or 1.",
    "start": "4428670",
    "end": "4434610"
  },
  {
    "text": "And then it's just a partition\nof the outcomes, which are 1 to n into the ones\nwhere you guess it's P,",
    "start": "4434610",
    "end": "4441540"
  },
  {
    "text": "and the ones where\nyou guess it's Q Yeah. Isn't P a distribution\nand Q is a distribution?",
    "start": "4441540",
    "end": "4447540"
  },
  {
    "text": "Yeah. Those are n numbers that are\nnon-negative and add up to 1. Yeah. But like, here they\ndon't add up to 1, right?",
    "start": "4447540",
    "end": "4453915"
  },
  {
    "text": "This is a detector matrix. This is not a probability--\nthis is not a probability",
    "start": "4453915",
    "end": "4460020"
  },
  {
    "text": "distribution at all. Yeah. So P and Q do. Those things, of course, right?",
    "start": "4460020",
    "end": "4465690"
  },
  {
    "text": "The sum of the Pi's is 1. Sum of the Qi's is 1, right? The only thing-- in fact,\nthe rules for this matrix",
    "start": "4465690",
    "end": "4472950"
  },
  {
    "text": "are they're non-negative,\nand the column sums are 1. That's the rules for\nthis detector matrix.",
    "start": "4472950",
    "end": "4480200"
  },
  {
    "text": "It's a randomized--\nit characterizes a randomized detector. So you'd say it's like column\nstochastic or something",
    "start": "4480200",
    "end": "4485630"
  },
  {
    "text": "like that, the matrix. ",
    "start": "4485630",
    "end": "4491270"
  },
  {
    "text": "OK. Now, what you could do\nis just work out the--",
    "start": "4491270",
    "end": "4497740"
  },
  {
    "text": "you can actually just work out\nthe so-called detector matrix, which actually you get\nby just doing literally",
    "start": "4497740",
    "end": "4503230"
  },
  {
    "text": "matrix multiplication. So if I do the following-- if I multiply my\nmatrix here by--",
    "start": "4503230",
    "end": "4512410"
  },
  {
    "text": "here's p and here's Q-- I get a 2 by 2 matrix,\nwhich is super interesting.",
    "start": "4512410",
    "end": "4518140"
  },
  {
    "text": "And what it's going to\ntell me-- it's called, I don't know, confusion matrix\nor lots of names for this.",
    "start": "4518140",
    "end": "4524739"
  },
  {
    "text": "But it tells you actually\nwhat the probability of your being either\nright or wrong",
    "start": "4524740",
    "end": "4529960"
  },
  {
    "text": "is as a function of whether\nit was generated from P or Q.",
    "start": "4529960",
    "end": "4537100"
  },
  {
    "text": "And so that's called a confusion\nmatrix, although maybe for a 2 by 2 it's not. But I don't know,\nit's got some--",
    "start": "4537100",
    "end": "4542739"
  },
  {
    "text": "I don't know what it is. Anyway. And so here you would like the--",
    "start": "4542740",
    "end": "4548889"
  },
  {
    "text": "if this were the--\nif this matrix, this detection\nprobability matrix were an identity, that's perfect\nbecause it means that whenever",
    "start": "4548890",
    "end": "4556400"
  },
  {
    "text": "it comes from P, I guess P.\nWhenever it comes from Q, I guess Q. By the way, would that ever ha--",
    "start": "4556400",
    "end": "4562820"
  },
  {
    "text": "when do you imagine\nthat's possible? Somebody give me an example. ",
    "start": "4562820",
    "end": "4569270"
  },
  {
    "text": "yeah. When the distributions\ndon't overlap. Yeah. They don't overlap. So here's P. I'll draw a P here.",
    "start": "4569270",
    "end": "4576280"
  },
  {
    "text": "It's 0, 0, 0.5. 0.5. And here's Q. This\nis P and here's",
    "start": "4576280",
    "end": "4582310"
  },
  {
    "text": "Q. It's going to be 0.03, OK?",
    "start": "4582310",
    "end": "4587350"
  },
  {
    "text": "So they just have\nnon-overlapping support, or they're just different. And so this is silly.",
    "start": "4587350",
    "end": "4592570"
  },
  {
    "text": "But now, if I tell you the\noutcome is 3, what can you say?",
    "start": "4592570",
    "end": "4598500"
  },
  {
    "text": "And with certainty, you can\nsay, if the outcome is 3, it can't have come from\nQ, so it came from P.",
    "start": "4598500",
    "end": "4604860"
  },
  {
    "text": "And if the outcome were 2,\nit came from Q, not P, right? And so in this case, if you\nhad a reasonable deterministic",
    "start": "4604860",
    "end": "4612600"
  },
  {
    "text": "detector there,\nyou would come up with this detection\nmatrix being the identity,",
    "start": "4612600",
    "end": "4618329"
  },
  {
    "text": "meaning you make no mistakes. I mean, that's a silly thing,\nbut nevertheless, that's",
    "start": "4618330",
    "end": "4624449"
  },
  {
    "text": "the idea. OK. So what you really end up having\nin the choice of T now is this",
    "start": "4624450",
    "end": "4631500"
  },
  {
    "text": "is a multicriterion problem\nbecause there's two-- actually,",
    "start": "4631500",
    "end": "4637350"
  },
  {
    "text": "you can even weirdly say that-- well, here we can-- this matrix only has two\nfree parameters in it--",
    "start": "4637350",
    "end": "4644405"
  },
  {
    "text": "the probability of a false\nnegative and probability of false positive. Both of those you want small.",
    "start": "4644405",
    "end": "4649949"
  },
  {
    "text": "So we can say it's a\nbicriterion problem, and it would look like this. It looks exactly like this.",
    "start": "4649950",
    "end": "4654969"
  },
  {
    "text": "So, yeah, this is\nwhat you would do.",
    "start": "4654970",
    "end": "4660180"
  },
  {
    "text": "These are your false\nprobability and false negative-- false positive\nfalse negative probabilities. You want them both small.",
    "start": "4660180",
    "end": "4666300"
  },
  {
    "text": "So what's cool is over here-- I mean, with this ridiculous\nexample over here, we can make both of them 0.",
    "start": "4666300",
    "end": "4671400"
  },
  {
    "text": "But in general, obviously,\nyou can't do that. so it's a bicriterion problem,\nand it looks like this.",
    "start": "4671400",
    "end": "4677970"
  },
  {
    "text": "That is an LP, right? Actually, it's an\nLP that's so simple,",
    "start": "4677970",
    "end": "4684449"
  },
  {
    "text": "it has an analytical solution,\nwhich you could work out.",
    "start": "4684450",
    "end": "4690180"
  },
  {
    "text": "We'll get to that in a minute. But if you scalerize\nit-- and so lambda would be the penalty\nthat tells you",
    "start": "4690180",
    "end": "4698100"
  },
  {
    "text": "how much false negatives bother\nyou more than false positives.",
    "start": "4698100",
    "end": "4704220"
  },
  {
    "text": "If you solve this,\nyou actually end up with a solution that is\na deterministic detector.",
    "start": "4704220",
    "end": "4710130"
  },
  {
    "text": "So you get-- and as\na matter of fact, the method is actually\nincredibly simple.",
    "start": "4710130",
    "end": "4715240"
  },
  {
    "text": "It's really dumb. It basically says that it\ndepends on the ratio of P",
    "start": "4715240",
    "end": "4720389"
  },
  {
    "text": "over Q. And so this\nis, I guess, they call it a likelihood ratio test.",
    "start": "4720390",
    "end": "4727679"
  },
  {
    "text": "I mean, this is a super\ndumb example, but actually this kind of works in\ninfinite dimensions and things like that. So it'd be the exact same\nthing in infinite dimensions.",
    "start": "4727680",
    "end": "4735150"
  },
  {
    "text": "If I had two\ncontinuous densities, and I say, hey, here's x,\nwhich density did it come from?",
    "start": "4735150",
    "end": "4742290"
  },
  {
    "text": "You look at the\ntwo-- what you do is you'd look at the\nratio of the densities. And then there's\na threshold, which",
    "start": "4742290",
    "end": "4747630"
  },
  {
    "text": "you interpret as\nhow much you care about being false negative\ncompared to false positive.",
    "start": "4747630",
    "end": "4752763"
  },
  {
    "text": "And if you're above\nthe threshold, you guess one distribution\nif you're below and all that kind of stuff. OK. Everybody got this?",
    "start": "4752763",
    "end": "4759080"
  },
  {
    "text": "So, OK. Now, those are\ndeterministic detectors.",
    "start": "4759080",
    "end": "4765500"
  },
  {
    "text": "But you could do other stuff. Like, you could say, actually,\nhere's what I care about-- I want to minimize the\nprobability of being wrong.",
    "start": "4765500",
    "end": "4774290"
  },
  {
    "text": "Minimize the probability. Did I say maximize? Whatever. You want to minimize the\nprobability of being wrong.",
    "start": "4774290",
    "end": "4781670"
  },
  {
    "text": "And so there, you're minimizing\nthe max of these two things. That's an LP, and\nit usually ends up",
    "start": "4781670",
    "end": "4788329"
  },
  {
    "text": "not being a\ndeterministic detector. So we'll quit today, and we'll\nstart up again next time.",
    "start": "4788330",
    "end": "4798700"
  },
  {
    "start": "4798700",
    "end": "4803000"
  }
]
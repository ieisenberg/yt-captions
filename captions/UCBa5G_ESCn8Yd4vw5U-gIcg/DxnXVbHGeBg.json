[
  {
    "start": "0",
    "end": "92000"
  },
  {
    "start": "0",
    "end": "3950"
  },
  {
    "text": "CHRISTOPHER POTTS:\nWelcome back, everyone.",
    "start": "3950",
    "end": "5700"
  },
  {
    "text": "This is part 3 in our series on\nsupervised sentiment analysis.",
    "start": "5700",
    "end": "8283"
  },
  {
    "text": "This screencast is going to\nfocus on the Stanford Sentiment",
    "start": "8283",
    "end": "10742"
  },
  {
    "text": "Treebank.",
    "start": "10742",
    "end": "11250"
  },
  {
    "text": "Let me start with a\nquick project overview.",
    "start": "11250",
    "end": "13980"
  },
  {
    "text": "The associated paper\nis Socher et al.",
    "start": "13980",
    "end": "15629"
  },
  {
    "text": "2013.",
    "start": "15630",
    "end": "17200"
  },
  {
    "text": "I think this paper is a kind\nof model of open science.",
    "start": "17200",
    "end": "19530"
  },
  {
    "text": "At this website\nhere, you can see",
    "start": "19530",
    "end": "21060"
  },
  {
    "text": "the full code, all\nthe data of course,",
    "start": "21060",
    "end": "23590"
  },
  {
    "text": "as well as an API that will\nlet you try out new examples",
    "start": "23590",
    "end": "26130"
  },
  {
    "text": "and kind of interact\nwith the core models",
    "start": "26130",
    "end": "28439"
  },
  {
    "text": "that are motivated in the paper.",
    "start": "28440",
    "end": "30870"
  },
  {
    "text": "It's a sentence-level corpus.",
    "start": "30870",
    "end": "32279"
  },
  {
    "text": "It's got about 11,000\nsentences in total.",
    "start": "32280",
    "end": "34649"
  },
  {
    "text": "And all of those\nsentences are originally",
    "start": "34650",
    "end": "36450"
  },
  {
    "text": "from Rotten Tomatoes.",
    "start": "36450",
    "end": "37650"
  },
  {
    "text": "So they are sentences\nfrom movie reviews.",
    "start": "37650",
    "end": "40033"
  },
  {
    "text": "The sentences themselves\nwere originally",
    "start": "40033",
    "end": "41700"
  },
  {
    "text": "released by Pang\nand Lee in 2005.",
    "start": "41700",
    "end": "44010"
  },
  {
    "text": "It's a kind of classic data set.",
    "start": "44010",
    "end": "45750"
  },
  {
    "text": "And what the SST did\nwas expand the data set",
    "start": "45750",
    "end": "48750"
  },
  {
    "text": "by labeling not only the\nfull sentences but all",
    "start": "48750",
    "end": "52440"
  },
  {
    "text": "of the sub-constituents\naccording",
    "start": "52440",
    "end": "54090"
  },
  {
    "text": "to a kind of traditional\nparse, syntactic parse,",
    "start": "54090",
    "end": "56640"
  },
  {
    "text": "of each of the examples.",
    "start": "56640",
    "end": "57790"
  },
  {
    "text": "And those are all\ncrowdsourced labels.",
    "start": "57790",
    "end": "59680"
  },
  {
    "text": "So what this means is that we\nhave vastly more supervision",
    "start": "59680",
    "end": "62850"
  },
  {
    "text": "signals all throughout the\nstructure of these examples",
    "start": "62850",
    "end": "65777"
  },
  {
    "text": "than we would get from the\noriginal, where we just",
    "start": "65777",
    "end": "67860"
  },
  {
    "text": "had a single sentiment label\nfor the entire sentence.",
    "start": "67860",
    "end": "72052"
  },
  {
    "text": "The labels themselves\nand the underlying corpus",
    "start": "72052",
    "end": "74010"
  },
  {
    "text": "are five-way labels that are\nextracted from workers' slider",
    "start": "74010",
    "end": "77760"
  },
  {
    "text": "responses.",
    "start": "77760",
    "end": "78480"
  },
  {
    "text": "So there's kind of an\ninitial layer of aggregation.",
    "start": "78480",
    "end": "81690"
  },
  {
    "text": "They made a slider choice.",
    "start": "81690",
    "end": "82800"
  },
  {
    "text": "They were all grouped\ntogether into five labels.",
    "start": "82800",
    "end": "85722"
  },
  {
    "text": "And then we are going to\nwork with a formulation that",
    "start": "85722",
    "end": "87930"
  },
  {
    "text": "is even more collapsed\ndown to ternary sentiment.",
    "start": "87930",
    "end": "90610"
  },
  {
    "text": "I'll return to that a bit later.",
    "start": "90610",
    "end": "93630"
  },
  {
    "start": "92000",
    "end": "227000"
  },
  {
    "text": "The fully labeled\ntree thing is one",
    "start": "93630",
    "end": "95250"
  },
  {
    "text": "of the really exciting\naspects of this corpus",
    "start": "95250",
    "end": "97650"
  },
  {
    "text": "that we will be able to take\nadvantage of, especially",
    "start": "97650",
    "end": "100230"
  },
  {
    "text": "during training.",
    "start": "100230",
    "end": "101010"
  },
  {
    "text": "So the way that worked\nis, there were parses.",
    "start": "101010",
    "end": "103470"
  },
  {
    "text": "This is a simple constituent\nparse of a sentence,",
    "start": "103470",
    "end": "106830"
  },
  {
    "text": "NLU is enlightening.",
    "start": "106830",
    "end": "108330"
  },
  {
    "text": "And as I've indicated\nhere, we have",
    "start": "108330",
    "end": "109920"
  },
  {
    "text": "labels in that\nspace, 0 through 4,",
    "start": "109920",
    "end": "113340"
  },
  {
    "text": "on all of the lexical items,\nNLU, is, and enlightening,",
    "start": "113340",
    "end": "116399"
  },
  {
    "text": "as well as all the\nsubconstituents in this phrase.",
    "start": "116400",
    "end": "119083"
  },
  {
    "text": "And so you can see\nthat \"is\" is neutral.",
    "start": "119083",
    "end": "120750"
  },
  {
    "text": "But since \"enlightening\"\nis positive,",
    "start": "120750",
    "end": "122790"
  },
  {
    "text": "the whole verb phrase, \"is\nenlightening\" is positive.",
    "start": "122790",
    "end": "125730"
  },
  {
    "text": "We can say that NLU is neutral.",
    "start": "125730",
    "end": "127860"
  },
  {
    "text": "But in the context\nof this sentence,",
    "start": "127860",
    "end": "129360"
  },
  {
    "text": "the overall contribution\nis a highly positive one.",
    "start": "129360",
    "end": "132270"
  },
  {
    "text": "So label 4 on the root.",
    "start": "132270",
    "end": "136230"
  },
  {
    "text": "In the first screencast\nfor this unit,",
    "start": "136230",
    "end": "137970"
  },
  {
    "text": "I motivated sentiment\nanalysis with some cases",
    "start": "137970",
    "end": "140178"
  },
  {
    "text": "that I thought were\nkind of difficult",
    "start": "140178",
    "end": "141720"
  },
  {
    "text": "from a syntactic point of view.",
    "start": "141720",
    "end": "143638"
  },
  {
    "text": "This is one of them, they\nsaid it would be great.",
    "start": "143638",
    "end": "145680"
  },
  {
    "text": "I love how this\nis being handled.",
    "start": "145680",
    "end": "147239"
  },
  {
    "text": "We can see that down\nhere, \"be great\"",
    "start": "147240",
    "end": "149580"
  },
  {
    "text": "is kind of clearly positive.",
    "start": "149580",
    "end": "151290"
  },
  {
    "text": "But by the time we have filtered\nthat through this report,",
    "start": "151290",
    "end": "154170"
  },
  {
    "text": "they said just kind of\ndisplacing the sentiment",
    "start": "154170",
    "end": "156720"
  },
  {
    "text": "onto another agent.",
    "start": "156720",
    "end": "157800"
  },
  {
    "text": "The speaker is not\nnecessarily endorsing",
    "start": "157800",
    "end": "160110"
  },
  {
    "text": "the claim of greatness.",
    "start": "160110",
    "end": "161392"
  },
  {
    "text": "What we get in the end is\nmore like a neutral sentiment.",
    "start": "161392",
    "end": "163724"
  },
  {
    "text": "I think that's interesting.",
    "start": "163725",
    "end": "165360"
  },
  {
    "text": "And we can extend that\neven further, right?",
    "start": "165360",
    "end": "167220"
  },
  {
    "text": "These are actual predictions\nfrom the model that's motivated",
    "start": "167220",
    "end": "169740"
  },
  {
    "text": "in the underlying paper.",
    "start": "169740",
    "end": "171210"
  },
  {
    "text": "If we take that constituent\nthat I just showed you",
    "start": "171210",
    "end": "173880"
  },
  {
    "text": "and conjoin it with\n\"they were wrong,\"",
    "start": "173880",
    "end": "175620"
  },
  {
    "text": "which is clearly negative,\nstrikingly the model",
    "start": "175620",
    "end": "178470"
  },
  {
    "text": "is able to figure out that the\noverall sentiment is determined",
    "start": "178470",
    "end": "181350"
  },
  {
    "text": "by this second clause here,\nand assigned negatives",
    "start": "181350",
    "end": "183580"
  },
  {
    "text": "to the entire thing, despite the\nfact that there are obviously",
    "start": "183580",
    "end": "186330"
  },
  {
    "text": "subconstituents in\nhere that are positive.",
    "start": "186330",
    "end": "188295"
  },
  {
    "text": "And that exactly the kind\nof mixing that I think",
    "start": "188295",
    "end": "190680"
  },
  {
    "text": "is correct for\nhow language works",
    "start": "190680",
    "end": "192750"
  },
  {
    "text": "in the domain of sentiment.",
    "start": "192750",
    "end": "194052"
  },
  {
    "text": "And it's kind of\nencouraging to see",
    "start": "194052",
    "end": "195510"
  },
  {
    "text": "that this model\nis able to capture",
    "start": "195510",
    "end": "197159"
  },
  {
    "text": "at least some aspects of it.",
    "start": "197160",
    "end": "199050"
  },
  {
    "text": "Here's a similar case that I\nthink is pretty good as well.",
    "start": "199050",
    "end": "201540"
  },
  {
    "text": "Although, maybe not as\nstrikingly positive in the end",
    "start": "201540",
    "end": "204159"
  },
  {
    "text": "here.",
    "start": "204160",
    "end": "204660"
  },
  {
    "text": "I've just changed from\nthe previous example,",
    "start": "204660",
    "end": "207630"
  },
  {
    "text": "\"they were wrong,\"\nto \"they were right.\"",
    "start": "207630",
    "end": "209970"
  },
  {
    "text": "It knows that right is correct.",
    "start": "209970",
    "end": "211590"
  },
  {
    "text": "And it seems to get that\nthis is middle of the scale.",
    "start": "211590",
    "end": "214500"
  },
  {
    "text": "And I'd hope this\nwas a 3 or a 4.",
    "start": "214500",
    "end": "216660"
  },
  {
    "text": "But I think that\nstill we're seeing",
    "start": "216660",
    "end": "218310"
  },
  {
    "text": "some interesting\ninteractions between what's",
    "start": "218310",
    "end": "220410"
  },
  {
    "text": "happening in subconstituents\nin these examples",
    "start": "220410",
    "end": "223200"
  },
  {
    "text": "and the prediction that's\nmade at the root level.",
    "start": "223200",
    "end": "225430"
  },
  {
    "text": "So it's very encouraging.",
    "start": "225430",
    "end": "227959"
  },
  {
    "start": "227000",
    "end": "495000"
  },
  {
    "text": "There are a bunch of ways that\nyou can formulate the SST task.",
    "start": "227960",
    "end": "231655"
  },
  {
    "text": "Kind of the raw one that\ncomes from the paper would",
    "start": "231655",
    "end": "233830"
  },
  {
    "text": "be a 5-way classification\nproblem where we have",
    "start": "233830",
    "end": "236980"
  },
  {
    "text": "these numerical labels here\nwith the meaning of kind of 0",
    "start": "236980",
    "end": "240430"
  },
  {
    "text": "is very negative, 1 is negative,\n2 is neutral, 3 is positive,",
    "start": "240430",
    "end": "244599"
  },
  {
    "text": "and 4 is very positive.",
    "start": "244600",
    "end": "246530"
  },
  {
    "text": "I think this is fine,\nbut there are two gotchas",
    "start": "246530",
    "end": "248830"
  },
  {
    "text": "underlying this kind of scheme.",
    "start": "248830",
    "end": "250300"
  },
  {
    "text": "First, it's not really a fully\nordered scale in the sense",
    "start": "250300",
    "end": "253930"
  },
  {
    "text": "that 4 is stronger than 3,\nbut 0 is stronger than 1,",
    "start": "253930",
    "end": "258970"
  },
  {
    "text": "because we have kind\nof this polarity split",
    "start": "258970",
    "end": "260859"
  },
  {
    "text": "with neutral in the center.",
    "start": "260860",
    "end": "263250"
  },
  {
    "text": "So that's a kind of\nconceptual difficulty.",
    "start": "263250",
    "end": "265000"
  },
  {
    "text": "And then the other part is that,\nby and large, classifier models",
    "start": "265000",
    "end": "268030"
  },
  {
    "text": "that you pick will not give you\npartial credit for being close.",
    "start": "268030",
    "end": "271510"
  },
  {
    "text": "We might hope that a model\nthat predicted a 1, negative,",
    "start": "271510",
    "end": "275770"
  },
  {
    "text": "was kind of right or\ncertainly more right",
    "start": "275770",
    "end": "278470"
  },
  {
    "text": "if the true label is 0 than\na model that had predicted 4.",
    "start": "278470",
    "end": "281765"
  },
  {
    "text": "But of course, if\nthese are all treated",
    "start": "281765",
    "end": "283390"
  },
  {
    "text": "as independent\nclassification bins,",
    "start": "283390",
    "end": "285730"
  },
  {
    "text": "then you're just\nequally wrong no matter",
    "start": "285730",
    "end": "288850"
  },
  {
    "text": "which prediction you made\nrelative to the gold label.",
    "start": "288850",
    "end": "291700"
  },
  {
    "text": "And that seems\nunfair to our models.",
    "start": "291700",
    "end": "294942"
  },
  {
    "text": "We are going to\nwork with what I've",
    "start": "294942",
    "end": "296400"
  },
  {
    "text": "called the ternary problem.",
    "start": "296400",
    "end": "297820"
  },
  {
    "text": "I think this is the minimal\nproblem that really makes sense",
    "start": "297820",
    "end": "300450"
  },
  {
    "text": "conceptually.",
    "start": "300450",
    "end": "301530"
  },
  {
    "text": "For this one, we grouped 0 and\n1 into a negative category,",
    "start": "301530",
    "end": "304860"
  },
  {
    "text": "3 and 4 into a\npositive category,",
    "start": "304860",
    "end": "307020"
  },
  {
    "text": "and reserved 2, as before, for\nwhat we're calling neutral.",
    "start": "307020",
    "end": "312120"
  },
  {
    "text": "And this kind of avoids\nthe false presupposition",
    "start": "312120",
    "end": "314790"
  },
  {
    "text": "that every sentence is\neither negative or positive,",
    "start": "314790",
    "end": "316950"
  },
  {
    "text": "because it does allow\nus to make predictions",
    "start": "316950",
    "end": "319230"
  },
  {
    "text": "into this neutral or\nnon-sentiment laden space.",
    "start": "319230",
    "end": "324042"
  },
  {
    "text": "It's very common, and\nyou see this in the paper",
    "start": "324042",
    "end": "326000"
  },
  {
    "text": "as well as in a lot\nof work on the SST,",
    "start": "326000",
    "end": "327770"
  },
  {
    "text": "to formulate this\nas a binary problem.",
    "start": "327770",
    "end": "329930"
  },
  {
    "text": "For the binary\nproblem, we simply",
    "start": "329930",
    "end": "331340"
  },
  {
    "text": "remove the middle of the\nscale and treat 0 and 1",
    "start": "331340",
    "end": "333770"
  },
  {
    "text": "as negative and 3 and 4\nas positive, as before.",
    "start": "333770",
    "end": "336830"
  },
  {
    "text": "I think that has two drawbacks.",
    "start": "336830",
    "end": "338159"
  },
  {
    "text": "First, we have to\nthrow away some data.",
    "start": "338160",
    "end": "339785"
  },
  {
    "text": "And second, then we're making\nthis false presupposition",
    "start": "339785",
    "end": "342380"
  },
  {
    "text": "that every sentence is either\nclassified as negative or as",
    "start": "342380",
    "end": "345200"
  },
  {
    "text": "positive when for a wide\nrange of cases in the world,",
    "start": "345200",
    "end": "348710"
  },
  {
    "text": "that might be inappropriate.",
    "start": "348710",
    "end": "351860"
  },
  {
    "text": "Now, I focused here on\nthe root level problem.",
    "start": "351860",
    "end": "353990"
  },
  {
    "text": "You can see that the numbers\nhere for train and dev",
    "start": "353990",
    "end": "356139"
  },
  {
    "text": "are small, and the test set\nnumbers are a little bit larger",
    "start": "356140",
    "end": "358870"
  },
  {
    "text": "than for devs.",
    "start": "358870",
    "end": "359520"
  },
  {
    "text": "So they're comparable.",
    "start": "359520",
    "end": "361090"
  },
  {
    "text": "But we can also think of\nthis as the all nodes task,",
    "start": "361090",
    "end": "363460"
  },
  {
    "text": "because recall that a\nhallmark feature of the SST",
    "start": "363460",
    "end": "367150"
  },
  {
    "text": "is that every single\nsubconstituent",
    "start": "367150",
    "end": "369190"
  },
  {
    "text": "in these examples has been\nlabeled by crowd workers.",
    "start": "369190",
    "end": "371830"
  },
  {
    "text": "So we could treat\neach one of those",
    "start": "371830",
    "end": "373389"
  },
  {
    "text": "as a kind of independent\nclassification problem.",
    "start": "373390",
    "end": "376060"
  },
  {
    "text": "We have the same range\nfor all of the values",
    "start": "376060",
    "end": "378393"
  },
  {
    "text": "that they can take on.",
    "start": "378393",
    "end": "379310"
  },
  {
    "text": "So we can do similar\nkind of collapsing down",
    "start": "379310",
    "end": "381580"
  },
  {
    "text": "into the ternary problem\nor the binary problem.",
    "start": "381580",
    "end": "384764"
  },
  {
    "text": "And of course, here, we\nhave a much larger dataset.",
    "start": "384765",
    "end": "386890"
  },
  {
    "start": "386890",
    "end": "389600"
  },
  {
    "text": "For us, we're going\nto, by and large,",
    "start": "389600",
    "end": "392960"
  },
  {
    "text": "work with the data in one\nparticular way, which I think",
    "start": "392960",
    "end": "395389"
  },
  {
    "text": "is common in the literature.",
    "start": "395390",
    "end": "396740"
  },
  {
    "text": "As I said, we're going to\nhave the ternary formulations.",
    "start": "396740",
    "end": "399240"
  },
  {
    "text": "Our labels will be positive,\nnegative, and neutral.",
    "start": "399240",
    "end": "402770"
  },
  {
    "text": "When we do the\ndev and test step,",
    "start": "402770",
    "end": "405020"
  },
  {
    "text": "we are going to test\nonly on full examples.",
    "start": "405020",
    "end": "407400"
  },
  {
    "text": "So for them, we will\nnot make predictions",
    "start": "407400",
    "end": "409699"
  },
  {
    "text": "into the subconstituent space.",
    "start": "409700",
    "end": "413210"
  },
  {
    "text": "And then as a default for\nthe code, as you'll see,",
    "start": "413210",
    "end": "416000"
  },
  {
    "text": "it is set up to train\nonly on full examples.",
    "start": "416000",
    "end": "419370"
  },
  {
    "text": "So for these two cases,\nNLU is enlightening",
    "start": "419370",
    "end": "421322"
  },
  {
    "text": "and not enlightening\nhere, if those",
    "start": "421322",
    "end": "422780"
  },
  {
    "text": "were two independent\nsentences in the corpus,",
    "start": "422780",
    "end": "425150"
  },
  {
    "text": "we would train just on those\ntwo independent examples,",
    "start": "425150",
    "end": "427970"
  },
  {
    "text": "one negative labeled positive\nand the other labeled negative.",
    "start": "427970",
    "end": "431210"
  },
  {
    "text": "However, you might imagine that\nyou'll get a lot more strength",
    "start": "431210",
    "end": "435169"
  },
  {
    "text": "in training if you also trained\non all the subconstituents,",
    "start": "435170",
    "end": "438860"
  },
  {
    "text": "which would mean\nessentially expanding",
    "start": "438860",
    "end": "440629"
  },
  {
    "text": "this example into its\nfull root version,",
    "start": "440630",
    "end": "443000"
  },
  {
    "text": "NLU is enlightening,\nbut also all",
    "start": "443000",
    "end": "445100"
  },
  {
    "text": "of the sub-pieces that\nare captured and labeled",
    "start": "445100",
    "end": "447250"
  },
  {
    "text": "in the corpus.",
    "start": "447250",
    "end": "448118"
  },
  {
    "text": "So that would give you many\nmore examples and much more",
    "start": "448118",
    "end": "450410"
  },
  {
    "text": "diversity.",
    "start": "450410",
    "end": "451647"
  },
  {
    "text": "And then of course,\n\"not enlightening\"",
    "start": "451647",
    "end": "453230"
  },
  {
    "text": "would be split apart as well.",
    "start": "453230",
    "end": "455047"
  },
  {
    "text": "And then you could decide\nfor yourself in addition",
    "start": "455047",
    "end": "457130"
  },
  {
    "text": "whether you want to treat\nthis as two instances",
    "start": "457130",
    "end": "459320"
  },
  {
    "text": "of \"enlightening\" or one.",
    "start": "459320",
    "end": "461300"
  },
  {
    "text": "And the code\nfacilitates all this.",
    "start": "461300",
    "end": "462849"
  },
  {
    "text": "So you can formulate it as a\nroot only training scenario",
    "start": "462850",
    "end": "465620"
  },
  {
    "text": "or as a subconstituent\ntraining scenario.",
    "start": "465620",
    "end": "467780"
  },
  {
    "text": "And you can keep or\nremove duplicates.",
    "start": "467780",
    "end": "470113"
  },
  {
    "text": "This is going to\nimpact the amount",
    "start": "470113",
    "end": "471530"
  },
  {
    "text": "of computational resources that\nyou need for training models.",
    "start": "471530",
    "end": "474680"
  },
  {
    "text": "But of course, bigger could\nbe better in this space,",
    "start": "474680",
    "end": "477350"
  },
  {
    "text": "because you're just seeing much\nmore gold labeled information.",
    "start": "477350",
    "end": "482272"
  },
  {
    "text": "So that's the overview.",
    "start": "482272",
    "end": "483230"
  },
  {
    "text": "And for much more\non this, and how",
    "start": "483230",
    "end": "484460"
  },
  {
    "text": "to work with our\ndistribution of the corpus,",
    "start": "484460",
    "end": "486319"
  },
  {
    "text": "and so forth, I\nwould encourage you",
    "start": "486320",
    "end": "487880"
  },
  {
    "text": "to work through this notebook\nthat I've linked at the bottom",
    "start": "487880",
    "end": "490380"
  },
  {
    "text": "here.",
    "start": "490380",
    "end": "491650"
  },
  {
    "start": "491650",
    "end": "496000"
  }
]
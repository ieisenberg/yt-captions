[
  {
    "start": "0",
    "end": "10960"
  },
  {
    "text": "I gave my seminar\nlast year, but it's great to come back in person\nand get the actual Stanford",
    "start": "10960",
    "end": "17410"
  },
  {
    "text": "experience. I think the Stanford experience\nstarted this morning in my Uber to the university.",
    "start": "17410",
    "end": "22810"
  },
  {
    "text": "Had talks about consciousness\nwith the Uber driver. So I was really getting\nthe full experience there.",
    "start": "22810",
    "end": "29560"
  },
  {
    "text": "So the plan for today is to tell\nyou a little bit of-- give you a little bit of an update\nabout the progress we made",
    "start": "29560",
    "end": "35080"
  },
  {
    "text": "on spatial perception\nfor robotics pretty much since my last seminar. And we start with a slide,\njust giving plenty of credits",
    "start": "35080",
    "end": "42100"
  },
  {
    "text": "to the students,\npostdocs, and collaborator doing the hard work\nand the heavy lifting",
    "start": "42100",
    "end": "47140"
  },
  {
    "text": "behind the slides I'm\ngoing to present today. So for those of you\nwho don't know my lab,",
    "start": "47140",
    "end": "53460"
  },
  {
    "text": "I'm the director of\nthe SPARKlab at MIT. And we work-- we focus\non spatial perception and vision-based navigation.",
    "start": "53460",
    "end": "59250"
  },
  {
    "text": "We have a particular emphasis\non motivating applications, which are safety critical,\nhigh integrity, and highly",
    "start": "59250",
    "end": "65940"
  },
  {
    "text": "interactive. So example of safety\ncritical applications are search and rescue\nand maybe self-driving.",
    "start": "65940",
    "end": "71970"
  },
  {
    "text": "Here, if the vision-based\nsystem is failing, maybe you can fail\nto find survivors, or maybe you can crash\nyour self-driving cars.",
    "start": "71970",
    "end": "79110"
  },
  {
    "text": "We care about applications\nwhich are high integrity. For example, the rocket\nhere on the right-hand side, maybe there is no\nhuman on board.",
    "start": "79110",
    "end": "84750"
  },
  {
    "text": "So it's not safety\ncritical, but it's still a pretty expensive\npiece of equipment. You don't want to break it. And we care about applications\nthat we call highly interactive.",
    "start": "84750",
    "end": "93240"
  },
  {
    "text": "Here, we are interested in\nall sorts of interactions, interaction with\nmultiple robots, interaction of the robot\nwith the environment,",
    "start": "93240",
    "end": "99570"
  },
  {
    "text": "or interaction between\nrobots and humans. So for today, before\ngetting into our technical",
    "start": "99570",
    "end": "106200"
  },
  {
    "text": "contributions, I want to start\nwith a video, a video which is highlighting the\ntype of capabilities",
    "start": "106200",
    "end": "111789"
  },
  {
    "text": "that we want to\ndevelop for our robots. It's not a real video\nlike computer animation, but it's a good summary of the\ncapabilities we want to develop.",
    "start": "111790",
    "end": "119469"
  },
  {
    "text": "So in the video, what\nyou see is a drone which is able to do very\naggressive and natural",
    "start": "119470",
    "end": "125920"
  },
  {
    "text": "navigation in\ncomplex environments. So the robots are\ndoing, in this case, some vision-based navigation.",
    "start": "125920",
    "end": "132070"
  },
  {
    "text": "They are able to understand\nobjects and agents around them. They're able to do this clever\ninteraction with objects,",
    "start": "132070",
    "end": "137950"
  },
  {
    "text": "and they're even able to do\ninteraction among each other. So large swarm of\nrobots interacting",
    "start": "137950",
    "end": "143740"
  },
  {
    "text": "in a very natural\nway among each other. So for today, I want to tell\na little bit of the work which",
    "start": "143740",
    "end": "149380"
  },
  {
    "text": "we are doing towards this\nkind of vision of robots with this kind of\nnavigation capabilities.",
    "start": "149380",
    "end": "155230"
  },
  {
    "text": "And I'm going to touch on\nthree main topics, three main foundational topics\nwe have been working on,",
    "start": "155230",
    "end": "160240"
  },
  {
    "text": "which, hopefully, are\nbringing us closer to this vision of\nthese capable drones.",
    "start": "160240",
    "end": "166060"
  },
  {
    "text": "So today I want to talk\nabout robust estimation as a first topic. I want to talk about\nhierarchical representations.",
    "start": "166060",
    "end": "172210"
  },
  {
    "text": "And then I want to talk about\nself-supervised learning. And I'm going to use\nthis slide a little bit as an outline of the\nrest of the presentation.",
    "start": "172210",
    "end": "179500"
  },
  {
    "text": "So for the first two\nparts, robust estimation and hierarchical\nrepresentations, I will focus a little bit more\non localization and mapping",
    "start": "179500",
    "end": "185697"
  },
  {
    "text": "problems or SLAM problems. For the last part, I will talk\nabout object understanding",
    "start": "185697",
    "end": "191000"
  },
  {
    "text": "instead. So self-supervised\nobject pose estimation.",
    "start": "191000",
    "end": "196240"
  },
  {
    "text": "So let me start with the\nrobust estimation part. And the point I want to make\nin this part of the talk",
    "start": "196240",
    "end": "202840"
  },
  {
    "text": "is that new and old tools\nfor robust estimation enable unprecedented robustness\nin localization and mapping",
    "start": "202840",
    "end": "208990"
  },
  {
    "text": "problems and unlock\nperformance guarantees. I told you about\nsome of the tools",
    "start": "208990",
    "end": "216220"
  },
  {
    "text": "last time I gave\nthe seminar in 2022. I will try to cover a\ndifferent set of algorithms and to give a little bit of\na summary of the progress we",
    "start": "216220",
    "end": "223300"
  },
  {
    "text": "made on these topics over\nthe last several years. We've been working on these\nfor more than six years now.",
    "start": "223300",
    "end": "231489"
  },
  {
    "text": "But let me start\nby telling you why we care about robust estimation,\nrobustness to what exactly.",
    "start": "231490",
    "end": "237160"
  },
  {
    "text": "So the context is that\nwe care about robustness in the context of localization\nand mapping problem. And in localization\nand mapping problem,",
    "start": "237160",
    "end": "243730"
  },
  {
    "text": "typically, the first\nthing that you do or a key element of simultaneous\nlocalization and mapping systems",
    "start": "243730",
    "end": "249400"
  },
  {
    "text": "is to reconstruct the\ntrajectory of your robot. Let's imagine we deploy the\nrobot in a completely unknown",
    "start": "249400",
    "end": "254470"
  },
  {
    "text": "environment. The first thing\nthat we want to do is that the robot is moving\nover time, time 1 and time 2 is covering a\ntrajectory, and want",
    "start": "254470",
    "end": "260958"
  },
  {
    "text": "to reconstruct how the\ntrajectory looks like. I want to solve an\nestimation problem to reconstruct the trajectory.",
    "start": "260959",
    "end": "267950"
  },
  {
    "text": "What we are given in\nterms of measurements are relative measurements\nbetween different poses",
    "start": "267950",
    "end": "273260"
  },
  {
    "text": "and the trajectory. For example, we can\nmeasure odometry, which is telling how the\nrobot moved from time 1",
    "start": "273260",
    "end": "278870"
  },
  {
    "text": "to time 2, time 2 to\ntime 3, and so on. And we typically--\nSLAM also have what are called loop closures,\nwhich are measurements",
    "start": "278870",
    "end": "285680"
  },
  {
    "text": "of poses which are far away. For example, these dashed\nlines will be loop closures.",
    "start": "285680",
    "end": "291200"
  },
  {
    "text": "The way you get these is\ntypically through place recognition methods. There is a computer vision\nsystem that is telling you,",
    "start": "291200",
    "end": "297650"
  },
  {
    "text": "look, pose 1 and\npose 7 are observing the same piece of\nenvironment, the same part of the environment.",
    "start": "297650",
    "end": "303440"
  },
  {
    "text": "So you can figure out what\nis the relative relation between these poses. And from all these\nset of relations,",
    "start": "303440",
    "end": "309610"
  },
  {
    "text": "which you can think\nof as being associated to the edges in\nthis graph, you want to reconstruct poses associated\nto the nodes of this graph.",
    "start": "309610",
    "end": "317920"
  },
  {
    "text": "Now the challenge here is that\nmany of these measurements will be reasonable, will be\nnoisy but still fairly accurate.",
    "start": "317920",
    "end": "324520"
  },
  {
    "text": "The odometry is going to\nbe noisy and prone to drift but will be relatively accurate. The issue is that for\nmodern system that",
    "start": "324520",
    "end": "330759"
  },
  {
    "text": "use for place recognition, you\nwill have a bunch of outliers. You will have a\nbunch of measurements which are complete garbage.",
    "start": "330760",
    "end": "336490"
  },
  {
    "text": "And it's pretty intuitive\nwhy that is the case. You might have two\ndifferent poses which",
    "start": "336490",
    "end": "342010"
  },
  {
    "text": "are observing an environment\nthat looks kind of similar, but they are two\ndifferent environments.",
    "start": "342010",
    "end": "347290"
  },
  {
    "text": "They just look similar, but\nthey are different portion of the environment. This is something\nthat is typically",
    "start": "347290",
    "end": "352360"
  },
  {
    "text": "called perceptual\naliasing in robotics. So essentially, some of the\nmeasurements-- some of the loop",
    "start": "352360",
    "end": "357910"
  },
  {
    "text": "closures are reasonable. Some of the others\nare completely-- wrong measurements\nare complete outliers.",
    "start": "357910",
    "end": "365650"
  },
  {
    "text": "Why do we worry so much\nabout these outliers? Well, let me show you\nan animation here.",
    "start": "365650",
    "end": "371949"
  },
  {
    "text": "So imagine that here I'm\nsolving some problem, which I want to reconstruct the\ntrajectory of the robot, which is this blue line.",
    "start": "371950",
    "end": "377770"
  },
  {
    "text": "If I have zero outliers, I get\na reasonable reconstruction of the trajectory.",
    "start": "377770",
    "end": "383550"
  },
  {
    "text": "If I have five outliers over\nthousands of measurements, the trajectory reconstruction\nis very deformed already.",
    "start": "383550",
    "end": "390990"
  },
  {
    "text": "If I have 20 outliers, which is\na tiny portion, tiny percentage of measurements, the entire\ntrajectory is complete garbage.",
    "start": "390990",
    "end": "398490"
  },
  {
    "text": "We are not going to do any\nnavigation or any mapping for this type of-- using\nthis type of trajectory.",
    "start": "398490",
    "end": "405360"
  },
  {
    "text": "So we studied how to get\nrobustness to outliers. And of course, you can go back\na few years, several years",
    "start": "405360",
    "end": "412560"
  },
  {
    "text": "actually to the '60s. And people will tell you\nfrom robust statistics that to get robustness\nto outliers, you",
    "start": "412560",
    "end": "418380"
  },
  {
    "text": "have to use some robust cost. So imagine that you have an\noptimization problem in which you want to figure\nout the trajectory",
    "start": "418380",
    "end": "424470"
  },
  {
    "text": "x of the robot given a\nbunch of measurements y. Robust statistics will\ntell you that what",
    "start": "424470",
    "end": "431040"
  },
  {
    "text": "you have to minimize the\nrobust loss function, which will get you some robustness\nto these bad measurements.",
    "start": "431040",
    "end": "436440"
  },
  {
    "text": "The issue is that people\nfrom robust statistics didn't tell us how to optimize\nactually this cost function.",
    "start": "436440",
    "end": "441570"
  },
  {
    "text": "And it's provable. We proved that-- there\nwere results proving that is intractable to try\nto solve this optimization",
    "start": "441570",
    "end": "448600"
  },
  {
    "text": "problem to optimality. And we also proved\nthat it's even hard computing an approximate\nsolution to this optimization",
    "start": "448600",
    "end": "454480"
  },
  {
    "text": "problem. So we spent a really\na number of years trying to understand how to\nsolve better these optimization",
    "start": "454480",
    "end": "459610"
  },
  {
    "text": "problems and how to get\nperformance guarantees. So one of the\nalgorithms we propose",
    "start": "459610",
    "end": "465460"
  },
  {
    "text": "is what is called\ngraduated non-convexity. The realization is that the\nhardness of the optimization",
    "start": "465460",
    "end": "470470"
  },
  {
    "text": "problem is due to non-convexity. And insight behind\nnon-convexity--",
    "start": "470470",
    "end": "476500"
  },
  {
    "text": "let me play this again-- is that instead of\nsolving directly the original\noptimization problem,",
    "start": "476500",
    "end": "482020"
  },
  {
    "text": "maybe we can start from a convex\napproximation of the problem. And iteration\nafter iteration, we can increase a bit more\nthe amount of non-convexity",
    "start": "482020",
    "end": "489640"
  },
  {
    "text": "until we recover the\noriginal non-convex cost. And at each iteration,\nwe use the solution from the previous\niteration as initial guess",
    "start": "489640",
    "end": "496960"
  },
  {
    "text": "from the optimization with the\nresult that our set of solutions will track this wide\npath and eventually",
    "start": "496960",
    "end": "503260"
  },
  {
    "text": "get to the optimal solution. So this algorithm,\nextreme robust",
    "start": "503260",
    "end": "510430"
  },
  {
    "text": "to outliers for\nthis SLAM problem. We get robustness empirically\nto 70%, 90% of outliers",
    "start": "510430",
    "end": "518020"
  },
  {
    "text": "that you find in practice,\nwhich is much, much better than having robustness to 20\noutliers, as in this case.",
    "start": "518020",
    "end": "525760"
  },
  {
    "text": "So the type of performance\nthat you get in real problems is that you try to figure\nout the trajectory. There are a bunch of outliers,\nwhich are these red lines.",
    "start": "525760",
    "end": "533080"
  },
  {
    "text": "Graduated non-convexity is\nable to solve this optimization problem and figure out\nwhich are the outliers,",
    "start": "533080",
    "end": "538990"
  },
  {
    "text": "and we result in a much\nnicer map reconstruction.",
    "start": "538990",
    "end": "544300"
  },
  {
    "text": "If you paid\nattention to my slide about the message of\nthis part, I said, new and old tools\nfrom robust estimation",
    "start": "544300",
    "end": "551260"
  },
  {
    "text": "are going to be useful to\nsolve localization and mapping problems. And indeed, for those of you who\nare really maybe senior faculty",
    "start": "551260",
    "end": "558400"
  },
  {
    "text": "members working\ncomputer vision, you realize that graduated\nnon-convexity is not a new algorithm. [INAUDIBLE] proposed\nin the '90s to solve",
    "start": "558400",
    "end": "565790"
  },
  {
    "text": "a very different problem like\ndepth reconstruction in images. What we did here is to\nrediscover it and apply that",
    "start": "565790",
    "end": "573740"
  },
  {
    "text": "to a completely different\nsetup, which is pose estimation in the context of SLAM, so.",
    "start": "573740",
    "end": "578885"
  },
  {
    "text": " I want to show the impact\nof this kind of algorithms",
    "start": "578885",
    "end": "584360"
  },
  {
    "text": "across a number of applications. Have been using\ngraduated non-convexity for a number of problems. In this case, I'm showcasing\nit for an application",
    "start": "584360",
    "end": "591710"
  },
  {
    "text": "of underground mapping in\nthe context of the DARPA Subterranean Challenge. So we did this fun challenge\nwith the JPL and Caltech",
    "start": "591710",
    "end": "598910"
  },
  {
    "text": "where the goal was to deploy\nrobots in very challenging underground environments and\nhaving them map the environments",
    "start": "598910",
    "end": "604730"
  },
  {
    "text": "with very high accuracy. And through the use of graduated\nnon-convexity and our SLAM system, we were able\nto pretty much get",
    "start": "604730",
    "end": "613460"
  },
  {
    "text": "pose estimation\nerrors like localize the robot with submeter\nprecision over very",
    "start": "613460",
    "end": "618620"
  },
  {
    "text": "long trajectories. And again, this is a case\nin which is, of course, GPS denied is underground. But also the robot has no\nidea about the environment.",
    "start": "618620",
    "end": "626000"
  },
  {
    "text": "So it's completely\nunknown environment. Part of this allowed us\nto get competitive results",
    "start": "626000",
    "end": "633172"
  },
  {
    "text": "in the DARPA challenge. We are second and\nfirst place in two out of the three competitions.",
    "start": "633172",
    "end": "638569"
  },
  {
    "text": "The last competition\ndidn't go as well, but that's another story. We'll do that over beers, maybe.",
    "start": "638570",
    "end": "644630"
  },
  {
    "text": "And all the code, you will see\nthat as a pattern, I guess. We tend to release as much\nopen-source code as we can.",
    "start": "644630",
    "end": "650210"
  },
  {
    "text": "So if you want to try out\nsome of these contributions, you will find them on github.",
    "start": "650210",
    "end": "655460"
  },
  {
    "text": " With Ford, we\napplied these ideas",
    "start": "655460",
    "end": "660530"
  },
  {
    "text": "in the context of self-driving\nand, in particular, mapping for autonomous valet parking.",
    "start": "660530",
    "end": "665540"
  },
  {
    "text": "So in this case, you imagine\nyou have a car with four cameras around the car. And you're trying to map,\nfor example, a parking lot.",
    "start": "665540",
    "end": "673520"
  },
  {
    "text": "So what you see here is that\nthe car is driving around. And we are doing mapping\nof the parking lot. You will see maybe some of\nthe parking spaces here,",
    "start": "673520",
    "end": "681470"
  },
  {
    "text": "but you are able to do this\njust with a bunch of monocular cameras and very\ncheap cameras as well.",
    "start": "681470",
    "end": "687780"
  },
  {
    "text": "Slightly more challenging\nthan the setup I showed for the\nsubterranean challenge, just because now we\nhave monocular cameras--",
    "start": "687780",
    "end": "694120"
  },
  {
    "text": "and essentially,\nthe loop closures are going to be\nmeasured up to scale. So there is some ambiguity\nin the reconstruction,",
    "start": "694120",
    "end": "699940"
  },
  {
    "text": "but you can still\ndo an excellent job and reject outliers through\ngraduated non-convexity.",
    "start": "699940",
    "end": "705490"
  },
  {
    "text": "And just to tell you\nhow much accuracy you can get through these\nalgorithms, in the table,",
    "start": "705490",
    "end": "710560"
  },
  {
    "text": "I'm showing, again, the\nerrors in meters compared",
    "start": "710560",
    "end": "715600"
  },
  {
    "text": "to the length of the\ntrajectory for many, many data sets comparing the proposed\napproach with the two",
    "start": "715600",
    "end": "722380"
  },
  {
    "text": "state of the art SLAM systems-- VINS-Fusion and ORB-SLAM3. And you can see\nalso that we express",
    "start": "722380",
    "end": "729009"
  },
  {
    "text": "the drift which is the\nerror as a percentage of the trajectory traveled.",
    "start": "729010",
    "end": "734140"
  },
  {
    "text": "So the SLAM, first\nof all, can give you very accurate\ntrajectories in which the drift is a tiny fraction\nof the trajectory traveled.",
    "start": "734140",
    "end": "742440"
  },
  {
    "text": "But also, with these cool\nideas from robust estimation, you can get just\nmuch better accuracy",
    "start": "742440",
    "end": "747600"
  },
  {
    "text": "over very competitive\ngrid systems, such as VINS-Fusion\nand ORB-SLAM3.",
    "start": "747600",
    "end": "757320"
  },
  {
    "text": "So from self-driving\nto Space, we have been using some of these\nideas from robust estimation,",
    "start": "757320",
    "end": "762870"
  },
  {
    "text": "also for terrain-relative\nnavigation, which is the problem of estimating the\npose of a rocket in this case",
    "start": "762870",
    "end": "768990"
  },
  {
    "text": "during the descent phase. I will not mention\ntoo much about-- this is a cool collaboration\nwe did with Draper.",
    "start": "768990",
    "end": "774840"
  },
  {
    "text": "But the cool thing\nabout this is that we're able to run some\nof our algorithms on these two platforms. So a high-altitude balloon and\nthe blue origin new Shepard",
    "start": "774840",
    "end": "782769"
  },
  {
    "text": "rocket. So my students were pretty\nexcited to put algorithms on the payloads\nof these rockets.",
    "start": "782770",
    "end": "790800"
  },
  {
    "text": "Very challenging\nproblem, these platforms navigating at very\nhigh altitude, very large speeds with\nclouds, and so on.",
    "start": "790800",
    "end": "798520"
  },
  {
    "text": "So very challenging conditions. And you can get a decent\nlocalization error through robust estimation and\nso on, which, of course, is not",
    "start": "798520",
    "end": "806399"
  },
  {
    "text": "going to be submitters. But it's going to still be\ncompatible with, for example,",
    "start": "806400",
    "end": "812070"
  },
  {
    "text": "entry phase or terrain-relative\nnavigation in this case.",
    "start": "812070",
    "end": "817730"
  },
  {
    "text": "OK, so I want to maybe conclude\nthis part just by summarizing-- I told you about this\ngraduated non-convexity idea.",
    "start": "817730",
    "end": "824779"
  },
  {
    "text": "But the truth is\nthat my group has been working on this topic of\nrobust estimation for perception",
    "start": "824780",
    "end": "830930"
  },
  {
    "text": "for a number of years. I want to do a one-slide summary\nof the other contributions we did just in case you are\ninterested in this area",
    "start": "830930",
    "end": "836990"
  },
  {
    "text": "if you want to read more. So the idea is how to solve\nthis kind of robust estimation problems.",
    "start": "836990",
    "end": "842480"
  },
  {
    "text": "I was showcasing applications\nto localization and mapping, but the truth is that\nthis kind of problems show up in pose estimation for\nobjects using point clouds,",
    "start": "842480",
    "end": "851540"
  },
  {
    "text": "images for SLAM and so on. So it's a very general tool. And what we did\nin our research is",
    "start": "851540",
    "end": "856880"
  },
  {
    "text": "to develop [INAUDIBLE] like\ntoolbox of algorithms, not a single algorithm,\nbut a set of algorithms",
    "start": "856880",
    "end": "861980"
  },
  {
    "text": "to solve these robust\nestimation problems more reliably and possibly\nperformance guarantees.",
    "start": "861980",
    "end": "868820"
  },
  {
    "text": "So I told you about\ngraduated non-convexity. The algorithm actually\nworks so well that it is now included in Matlab.",
    "start": "868820",
    "end": "874130"
  },
  {
    "text": "If you are curious about\nthat in the navigation toolbox in Matlab, we have\ngraph theoretic approaches,",
    "start": "874130",
    "end": "879150"
  },
  {
    "text": "which are able to prune outliers\nby reasoning over compatibility between measurements.",
    "start": "879150",
    "end": "884272"
  },
  {
    "text": "And I think last time I\nwas giving the seminar, I was telling more about\nmodel relaxations, which I think is one of\nthe coolest things",
    "start": "884272",
    "end": "889890"
  },
  {
    "text": "that we have done\nin which the idea is to use convex, semidefinite\nrelaxations to get provably",
    "start": "889890",
    "end": "898290"
  },
  {
    "text": "optimal solutions for these\noptimization problem, which is something that nobody was\nable to do before in robotics.",
    "start": "898290",
    "end": "906060"
  },
  {
    "text": "So there is some recent\nprogress on that also including this idea of\nestimation contracts.",
    "start": "906060",
    "end": "911700"
  },
  {
    "text": "I will not cover\nthat too much today, but I want to stress\nthat part of our work is about designing\ncertifiable algorithms, which",
    "start": "911700",
    "end": "918690"
  },
  {
    "text": "carry some performance\nguarantees in the sense that our algorithms either\ncompute an estimate that",
    "start": "918690",
    "end": "924210"
  },
  {
    "text": "can certify the\noptimal estimate, or they can detect\nfailure, otherwise.",
    "start": "924210",
    "end": "929819"
  },
  {
    "text": "OK, so after this summary,\nwe switch gears and actually talk a little bit more about\nhierarchical representations",
    "start": "929820",
    "end": "937410"
  },
  {
    "text": "instead. And the point I want to make in\nthis part of the presentation is that highly interactive\nrobotics applications require",
    "start": "937410",
    "end": "945900"
  },
  {
    "text": "metric-semantic semantic\nhierarchical map representations in real time 3D scene\nunderstanding algorithms",
    "start": "945900",
    "end": "951900"
  },
  {
    "text": "to build them. So what I mean-- what do I mean\nby interactive applications? Imagine that I have\ninteraction with humans.",
    "start": "951900",
    "end": "958350"
  },
  {
    "text": "I would like for my robot\nto understand and execute very complex instructions. For example, I want to\ntell my robot, robot, go",
    "start": "958350",
    "end": "964800"
  },
  {
    "text": "grab me a cup of coffee on\nthe table in the kitchen. What I'm arguing is that\nin order for the robot",
    "start": "964800",
    "end": "969839"
  },
  {
    "text": "to understand and execute\nthese instructions, we need metric-semantic\nand hierarchical map",
    "start": "969840",
    "end": "975210"
  },
  {
    "text": "representations. I don't think we need\ntoo much convincing to do in convincing that we\nneed metric-semantic maps.",
    "start": "975210",
    "end": "983070"
  },
  {
    "text": "Of course, if the\ninstruction is, robot, go grab me a cup\nof coffee on the desk, the robot will need to\nknow about geometry.",
    "start": "983070",
    "end": "989800"
  },
  {
    "text": "We need to know how\nto get to the desk, how to avoid obstacles\nalong the way. But we also need to\nknow about semantics,",
    "start": "989800",
    "end": "996040"
  },
  {
    "text": "which is, what is the cup\nof coffee, what is the desk, and how to detect\nthem in the scene.",
    "start": "996040",
    "end": "1001590"
  },
  {
    "text": "So a few years ago,\nwe developed a library for metric-semantic mapping,\nwhich is called Kimera.",
    "start": "1001590",
    "end": "1007560"
  },
  {
    "text": "The high-level picture\nof what Kimera does is Kimera is taking a\nbunch of camera images as well as inertial data, is\napplying semantic segmentation",
    "start": "1007560",
    "end": "1017010"
  },
  {
    "text": "to the image, and\nthen is mapping these 2D understanding of the\nenvironment into a 3D map.",
    "start": "1017010",
    "end": "1023339"
  },
  {
    "text": "So you can imagine that\nthe robot is going around and is building a 3D mesh of\nthe environment in real time.",
    "start": "1023340",
    "end": "1028626"
  },
  {
    "text": "These are very\nlightweight algorithms. So everything is running on CPU. But not only can be the\n3D map of the environment,",
    "start": "1028627",
    "end": "1034619"
  },
  {
    "text": "the map also has\ndifferent colors which correspond to\ndifferent semantic labels. So green maybe are the chairs.",
    "start": "1034619",
    "end": "1041550"
  },
  {
    "text": "Blue are the desks. Yellow are the cubicles. So this is an example\nof metric-semantic map,",
    "start": "1041550",
    "end": "1046949"
  },
  {
    "text": "in which the robot\nfinally can understand the identity and the semantics\nof different objects in 3D.",
    "start": "1046950",
    "end": "1055020"
  },
  {
    "text": "We have a bunch of extension. We work a lot on these topics. We also have extension\nlike multi-robot systems. But after working\non these, we quickly",
    "start": "1055020",
    "end": "1061740"
  },
  {
    "text": "realized that metric-semantic\nmapping is actually not enough for the type of\ninteractions we are envisioning",
    "start": "1061740",
    "end": "1067830"
  },
  {
    "text": "with our robots. That's fairly easy to explain. Imagine that I want to tell\nthe robot, robot, go search",
    "start": "1067830",
    "end": "1074970"
  },
  {
    "text": "for survivors near the\nfridge in the kitchen. We realized that in\norder for the robot to understand this\ninstruction, the robot",
    "start": "1074970",
    "end": "1081450"
  },
  {
    "text": "will need to understand\nsemantics beyond objects. For example, we need\nto understand rooms in the environments. The structure involves\nthe notion of kitchen.",
    "start": "1081450",
    "end": "1088620"
  },
  {
    "text": "But if you are just mapping\nflat objects in the environment, the robot will have no idea\nabout what the kitchen is",
    "start": "1088620",
    "end": "1093900"
  },
  {
    "text": "or where the kitchen is. And second, this\nkind of instruction require reasoning over\nrelations between elements",
    "start": "1093900",
    "end": "1100740"
  },
  {
    "text": "in the environment. For example, the instruction\nsays that the fridge is in the kitchen.",
    "start": "1100740",
    "end": "1106260"
  },
  {
    "text": "So we have to understand\nwhat that relation means. OK, we need a map\nrepresentation, which is encoding that relation.",
    "start": "1106260",
    "end": "1113640"
  },
  {
    "text": "So over the past year,\nhave been working a lot on this new\nrepresentation, which is called 3D Scene\nGraphs, in which you",
    "start": "1113640",
    "end": "1119429"
  },
  {
    "text": "start modeling semantics at\ndifferent levels of abstraction. You start thinking about\nrelation between objects.",
    "start": "1119430",
    "end": "1126299"
  },
  {
    "text": "What the scene graph is just a\nhierarchical map representation, in which at the\nbottom layer, you",
    "start": "1126300",
    "end": "1131430"
  },
  {
    "text": "have a 3D metric-semantic\nmesh, pretty much the same that I had in previous slides. But as you go up\nin the hierarchy,",
    "start": "1131430",
    "end": "1138390"
  },
  {
    "text": "you are abstracting\naway the mesh into objects, places,\nrooms, and buildings.",
    "start": "1138390",
    "end": "1144690"
  },
  {
    "text": "I guest rooms, buildings\nare fairly intuitive. Places are just a\ntopological representation",
    "start": "1144690",
    "end": "1150870"
  },
  {
    "text": "of the free space. So you can imagine that\nas a graph of free space that represents traversability\nbetween different places",
    "start": "1150870",
    "end": "1158130"
  },
  {
    "text": "in the environment. So actually, we\nare among the first to propose this representation. I think the first work\nproposing this representation",
    "start": "1158130",
    "end": "1165000"
  },
  {
    "text": "is from Iro Armeni,\nwho is a faculty here in civil engineering. So very cool work.",
    "start": "1165000",
    "end": "1170400"
  },
  {
    "text": "What is ended up doing\nover the last year is to be a little\nbit more rigorous",
    "start": "1170400",
    "end": "1177780"
  },
  {
    "text": "about why a hierarchical\nrepresentation is needed. And in this slide, I'm\ncomparing essentially",
    "start": "1177780",
    "end": "1184680"
  },
  {
    "text": "a flat representation in\nwhich you just have voxels. And maybe you are attaching\na bunch of semantic labels to voxels against the type of\nhierarchical map representations",
    "start": "1184680",
    "end": "1194190"
  },
  {
    "text": "we are proposing. And we realized\nthat, first of all, hierarchical representations\nscale better.",
    "start": "1194190",
    "end": "1201270"
  },
  {
    "text": "It's like a trivial point. I would say, if you have to\nstore a bunch of attributes to each voxel, the\nscalability of this map",
    "start": "1201270",
    "end": "1207570"
  },
  {
    "text": "will increase with the\nnumber of semantic labels and with the number of voxels. If instead you arrange\nthings as a tree,",
    "start": "1207570",
    "end": "1214020"
  },
  {
    "text": "you can essentially\ngroup concepts together. And the scalability in\nterms of storage and memory",
    "start": "1214020",
    "end": "1219090"
  },
  {
    "text": "will get much, much better\nover time, which is great. Simple observation.",
    "start": "1219090",
    "end": "1224789"
  },
  {
    "text": "The second observation is that\nif you care about modeling relations, modeling relation\nis pretty easy if you have",
    "start": "1224790",
    "end": "1230480"
  },
  {
    "text": "a graph-based representation. You can just capture relations\nas edges in the graph. For example, you can\nmodel that the stove is",
    "start": "1230480",
    "end": "1236660"
  },
  {
    "text": "close to the fridge,\nor maybe the kitchen is connected to the dining room. But something that\nwe proved which",
    "start": "1236660",
    "end": "1242372"
  },
  {
    "text": "is a little bit\nmore fundamental is that this type of what we\ncall hierarchical graphs",
    "start": "1242372",
    "end": "1247669"
  },
  {
    "text": "have low treewidth. So the treewidth is a\nfundamental property of a graph.",
    "start": "1247670",
    "end": "1252710"
  },
  {
    "text": "And proving that a graph\nhas a low treewidth is pretty much allowing\nto conclude that is easy,",
    "start": "1252710",
    "end": "1257990"
  },
  {
    "text": "is fast to do inference\nover this graph. So it's much nicer to have\ngraphs with low treewidth.",
    "start": "1257990",
    "end": "1264920"
  },
  {
    "text": "And in a few slides,\nthis notion of treewidth will allow us to get\nsome approximation result",
    "start": "1264920",
    "end": "1270049"
  },
  {
    "text": "that you're going to see applied\nto even graph neural networks.",
    "start": "1270050",
    "end": "1275660"
  },
  {
    "text": "OK, so not only we prove\nthat this representation is much nicer in\nterms of scalability, treewidth, and so on.",
    "start": "1275660",
    "end": "1281420"
  },
  {
    "text": "But we also designed\nthe first algorithms to build this type of 3D\nscene graph representation in real time using sensor data.",
    "start": "1281420",
    "end": "1289590"
  },
  {
    "text": "Hydra is a name of\nthe system which is putting these things together\nand is allowing 3D scene graph",
    "start": "1289590",
    "end": "1294720"
  },
  {
    "text": "construction. So imagine that our robot\nis starting in a kitchen without prior knowledge\nabout the environment.",
    "start": "1294720",
    "end": "1300150"
  },
  {
    "text": "What these systems are\ndoing is to allow the robot to estimate its own\ntrajectory pretty much like the same\ntrajectory estimation",
    "start": "1300150",
    "end": "1306660"
  },
  {
    "text": "problem I was covering before. Is able for the robot-- is allowing the\nrobot to understand",
    "start": "1306660",
    "end": "1311970"
  },
  {
    "text": "objects and the semantics\nof objects nearby-- sink, fridge, and so on.",
    "start": "1311970",
    "end": "1317130"
  },
  {
    "text": "And then from the\nsemantics of objects, drawing conclusion\nabout what are the different rooms in\nthe environment-- kitchen,",
    "start": "1317130",
    "end": "1323640"
  },
  {
    "text": "bedroom, and so on. So I'll not tell you too\nmany details about these, but you can imagine that\nthese actually to me",
    "start": "1323640",
    "end": "1331049"
  },
  {
    "text": "is of the evolution of the\ntraditional SLAM problem. There is some SLAM\nproblem in solving",
    "start": "1331050",
    "end": "1336210"
  },
  {
    "text": "for the mesh reconstruction\nat the bottom layer. So there is some\nmetric-semantic reconstruction.",
    "start": "1336210",
    "end": "1341400"
  },
  {
    "text": "But then to get to this 3D scene\ngraph, you have to do much more. First of all, you have to\ndo more geometric reasoning.",
    "start": "1341400",
    "end": "1347190"
  },
  {
    "text": "For example, you have to\nextract the free space, which is this layer of places\nin the scene graph.",
    "start": "1347190",
    "end": "1352500"
  },
  {
    "text": "And you do that by doing what\nis called a generalized Voronoi diagram. The second thing\nthat you have to do",
    "start": "1352500",
    "end": "1358170"
  },
  {
    "text": "is to cluster the places\ninto different rooms. And here we use tools\nactually from topology.",
    "start": "1358170",
    "end": "1363600"
  },
  {
    "text": "There is a tool which is called\npersistent homology, which, given a graph of places in our\ncase, we break down the graph",
    "start": "1363600",
    "end": "1369930"
  },
  {
    "text": "into different rooms. And then to reason\nover the semantics of the different rooms, you\nare going to see in a while",
    "start": "1369930",
    "end": "1375702"
  },
  {
    "text": "that we use tools from\ngeometric deep learning and, in particular,\ngraph neural networks. I will cover that a\nlittle bit more details",
    "start": "1375702",
    "end": "1384780"
  },
  {
    "text": "in a couple of slides. The exciting thing\nabout this work is that this is not\njust robotics work.",
    "start": "1384780",
    "end": "1392530"
  },
  {
    "text": "We can run, and\nwe paid attention to being able to run these\nalgorithms on real robots right now.",
    "start": "1392530",
    "end": "1398092"
  },
  {
    "text": "So we're doing all sorts of\ndemonstration with these. I'm going to show you just\na quick demo with the robot mapping like in a\nbuilding at MIT.",
    "start": "1398092",
    "end": "1404763"
  },
  {
    "text": "But the bottom\nline is that we can run these on board computers,\nfor example, the Xavier NX, and constructing the\ndifferent layers of a scene",
    "start": "1404763",
    "end": "1411513"
  },
  {
    "text": "graph in a matter\nof milliseconds. We can do all these in\nreal time on a real robot. ",
    "start": "1411513",
    "end": "1418270"
  },
  {
    "text": "So last time I was telling\nyou a little bit more details about maybe how\nto form the lower",
    "start": "1418270",
    "end": "1425860"
  },
  {
    "text": "layers of this representation. For today, I want to cover\na single topic, which is how to attach semantic\nlabels to the top layers.",
    "start": "1425860",
    "end": "1434905"
  },
  {
    "text": "So let's say that I'm building\na scene graph as the robot moves through the environment. I'm able to cluster\nthe environment",
    "start": "1434905",
    "end": "1440680"
  },
  {
    "text": "into different rooms, in this\ncase, R1 to R16, I guess. How do I attach\nlabels to this room?",
    "start": "1440680",
    "end": "1446650"
  },
  {
    "text": "How do I know if a room is\na kitchen versus a bedroom? So I would like to\ntackle that problem and tell you a\nlittle bit the tools",
    "start": "1446650",
    "end": "1452788"
  },
  {
    "text": "that we develop to\ntackle that problem.  First of all, I want to tackle\nthe elephant in the room here.",
    "start": "1452788",
    "end": "1462370"
  },
  {
    "text": "Just checking. Maybe this is an easy problem. Maybe the progress we made in\nvision language models, maybe",
    "start": "1462370",
    "end": "1469900"
  },
  {
    "text": "it's easy to classify. And to understand\nthe environment and the different rooms in\nthe environment is easy. Maybe I just have to take a\nsnapshot of my reconstruction,",
    "start": "1469900",
    "end": "1477550"
  },
  {
    "text": "and I have to pass it to\na visual language model and query what are the\nrooms in the environment.",
    "start": "1477550",
    "end": "1482590"
  },
  {
    "text": "Maybe it's that easy. So I tried that. I took the interface for LLaVA. I uploaded one of the\n3D reconstructions",
    "start": "1482590",
    "end": "1489850"
  },
  {
    "text": "we have like this point cloud. I can ask LLaVA to\ndescribe the point cloud.",
    "start": "1489850",
    "end": "1497180"
  },
  {
    "text": "Kind of makes sense. I will not read this\ninto too many details. Then I start having a little\nbit more targeted questions.",
    "start": "1497180",
    "end": "1505100"
  },
  {
    "text": "The question I ask\nis, how many bedrooms do you see in the image? We're interested in\nroom classification. How many bedrooms do you see?",
    "start": "1505100",
    "end": "1511370"
  },
  {
    "text": "And the language\nmodel is replying, there is one bedroom\nvisible in the image located in the open\nconcept living space.",
    "start": "1511370",
    "end": "1518345"
  },
  {
    "text": "Well, we started the image. You see, OK, I\ncount at least one, two, maybe three\nbeds and bedrooms.",
    "start": "1518345",
    "end": "1524390"
  },
  {
    "text": "So this doesn't\nsound quite right, but maybe the language model is\njust not paying enough attention",
    "start": "1524390",
    "end": "1530149"
  },
  {
    "text": "maybe to the image. So let me try to\nhelp a little bit. See, I can count three beds. And the language model replied,\nI apologize for the confusion.",
    "start": "1530150",
    "end": "1537800"
  },
  {
    "text": "Upon further examination,\nthere are indeed three beds. So then I ask again, like, so\nhow many bedrooms do you see?",
    "start": "1537800",
    "end": "1544549"
  },
  {
    "text": "It says, OK, finally,\nthere are three bedrooms. So maybe just didn't pay enough\nattention in the previous stage.",
    "start": "1544550",
    "end": "1551810"
  },
  {
    "text": "But then I keep going. And I say, upon\nfurther inspection, I can count two beds. And then it starts\nagreeing with me that there",
    "start": "1551810",
    "end": "1557100"
  },
  {
    "text": "are two beds instead. So I can still essentially\nthe language model to tell me whatever I want here. It doesn't seem like there is\nenough really understanding",
    "start": "1557100",
    "end": "1564000"
  },
  {
    "text": "of the image. But then I say, maybe I'm\ntrying with the problem which is too hard. Maybe the reconstruction\nis noisy, is an incomplete.",
    "start": "1564000",
    "end": "1571440"
  },
  {
    "text": "Maybe you have to pass a\ntop view of the environment and maybe make it into a\nfloor plan with room labels.",
    "start": "1571440",
    "end": "1577050"
  },
  {
    "text": "I mean, that should be easy. We start a new conversation. How many bedrooms do\nyou see in this picture?",
    "start": "1577050",
    "end": "1584580"
  },
  {
    "text": "1, 2, 3, and 4 and then says\nthat there are two instead. So yeah, I think you\ncan prompt your way",
    "start": "1584580",
    "end": "1591270"
  },
  {
    "text": "to getting the exact answer,\nbut that is not the point. What I'm arguing is\nthat it's not as easy.",
    "start": "1591270",
    "end": "1597210"
  },
  {
    "text": "The language model will not have\nan immediate understanding-- even in a very simple\nproblem will not have an immediate understanding\nof rooms in the environment.",
    "start": "1597210",
    "end": "1606478"
  },
  {
    "text": "So therefore, we have to\ncome up with tools which are a little bit more clever. And today I'm going to tell\nyou in a couple of slides maybe",
    "start": "1606478",
    "end": "1613050"
  },
  {
    "text": "the tool set we developed. Again, the problem is that\nyou have this scene graph.",
    "start": "1613050",
    "end": "1618680"
  },
  {
    "text": "And you want to come\nup with semantic labels for the different\nrooms, semantic labels being kitchen,\nbedroom, and so on.",
    "start": "1618680",
    "end": "1625850"
  },
  {
    "text": "And we do this as\nhumans all the time. The way, I think,\nwe do that as humans",
    "start": "1625850",
    "end": "1631010"
  },
  {
    "text": "is that we look at\nthe objects around us. And from the objects,\nwe can really easily understand what is the\nroom type we are traversing.",
    "start": "1631010",
    "end": "1639320"
  },
  {
    "text": "So for example, if in a\nroom there, there is a bed, there is a chair,\nthere is a book, maybe we can conclude\nthat that's a bedroom.",
    "start": "1639320",
    "end": "1645169"
  },
  {
    "text": "So we would like to do\nthe same type of inference with our robots. The old style version of\ndoing this type of inference",
    "start": "1645170",
    "end": "1651860"
  },
  {
    "text": "would be something like a\nprobabilistic graphical model. For that, we need to hard\ncode a lot of information.",
    "start": "1651860",
    "end": "1656870"
  },
  {
    "text": "The modern version of that is\nto use a graph neural network. How many of you are familiar\nwith graph neural networks here?",
    "start": "1656870",
    "end": "1662720"
  },
  {
    "text": " So in a graph neural network,\nyou have a graph with nodes.",
    "start": "1662720",
    "end": "1669490"
  },
  {
    "text": "Imagine that five\nis the room nodes. And these other four\nare objects nodes. What you do is you do\nsome message passing",
    "start": "1669490",
    "end": "1676299"
  },
  {
    "text": "to form embeddings at\neach node, and then you classify these embeddings into-- I don't know-- bedroom,\nbathroom, and so on.",
    "start": "1676300",
    "end": "1683570"
  },
  {
    "text": "So it's just a neural\nmessage passing over a graph. We use this indeed\nas a baseline, but we actually\npropose something",
    "start": "1683570",
    "end": "1689440"
  },
  {
    "text": "that is a little bit more\nclever, is a new graph neural network,\nwhich is something that we call the neural tree.",
    "start": "1689440",
    "end": "1695780"
  },
  {
    "text": "And I'm going to present this\nidea in a single picture, just because it's\nreally that simple. I can present these\nideaness in a single figure.",
    "start": "1695780",
    "end": "1703310"
  },
  {
    "text": "So the idea of\nthe neural tree is that you do not\nhave-- what we say is that we do not have\nto do message passing",
    "start": "1703310",
    "end": "1709130"
  },
  {
    "text": "over the original graph. What you have to do is\nto transform the graph into a tree using something that\nis called a tree decomposition.",
    "start": "1709130",
    "end": "1715610"
  },
  {
    "text": "And then you have to do message\npassing on the tree instead. And if you do this\ntrick, you just",
    "start": "1715610",
    "end": "1720740"
  },
  {
    "text": "gain performance guarantees, and\nyou get much better performance in practice.",
    "start": "1720740",
    "end": "1726470"
  },
  {
    "text": "So for the few of\nyou who might be very familiar with\nprobabilistic graphical models, you might have seen the\njunction tree algorithm.",
    "start": "1726470",
    "end": "1733340"
  },
  {
    "text": "What we are doing is essentially\nlike a neural version of a junction tree algorithm. So we are bringing insights\nfrom graphical models and graph",
    "start": "1733340",
    "end": "1741440"
  },
  {
    "text": "neural networks together to\nget performance guarantees. So what do we gain by doing\nthese neural tree architecture?",
    "start": "1741440",
    "end": "1748820"
  },
  {
    "text": "First of all, we gain\ntheoretical guarantees. There is a long statement. As a theorem, I\nwill just summarize",
    "start": "1748820",
    "end": "1754640"
  },
  {
    "text": "what are the main points. Imagine that f is a probability\ndistribution over the graph",
    "start": "1754640",
    "end": "1759899"
  },
  {
    "text": "that you care about. And let's call G\nthe set of functions that can be implemented through\nyour graph neural network",
    "start": "1759900",
    "end": "1768120"
  },
  {
    "text": "to your neural\ntree architecture. What we prove is\nthat you can find",
    "start": "1768120",
    "end": "1773820"
  },
  {
    "text": "a G which is close enough to\nany probability distribution up to an error epsilon.",
    "start": "1773820",
    "end": "1779649"
  },
  {
    "text": "You can do this using a\nnumber of parameters, which you can imagine as the weights\nin your neural network, which",
    "start": "1779650",
    "end": "1785940"
  },
  {
    "text": "is this capital N. And\nthe number of parameters grows linearly in the size\nof the graph, which is good--",
    "start": "1785940",
    "end": "1791880"
  },
  {
    "text": "linear is good-- and\nonly grows exponentially in the treewidth of the graph.",
    "start": "1791880",
    "end": "1797580"
  },
  {
    "text": "But we just proved that scene\ngraph has small treewidth. So essentially,\nwhat I'm saying is that with this result\nabout the treewidth,",
    "start": "1797580",
    "end": "1803430"
  },
  {
    "text": "we can prove that these\narchitectures are provably expressive over scene\ngraphs with a small number",
    "start": "1803430",
    "end": "1808680"
  },
  {
    "text": "of parameters. So in a nutshell, again,\nlet me repeat this. The neural tree will\nneed a parameter",
    "start": "1808680",
    "end": "1814897"
  },
  {
    "text": "which is exponential\nin the treewidth. But the treewidth will be\nsmall for scene graphs.",
    "start": "1814897",
    "end": "1820500"
  },
  {
    "text": "OK, so maybe we don't\ncare about the theory. We want to see how\nthis works in practice.",
    "start": "1820500",
    "end": "1825790"
  },
  {
    "text": "So we do experiments,\nin this case, on the Stanford 3D\nscene graph data",
    "start": "1825790",
    "end": "1831049"
  },
  {
    "text": "set in which there are these\npairs of objects and rooms. And we evaluate the\npercentage of things",
    "start": "1831050",
    "end": "1836910"
  },
  {
    "text": "which we classify correctly. Of course, we would like\nfor this to be 100%. These percentages are\nwhat we show in the table.",
    "start": "1836910",
    "end": "1845430"
  },
  {
    "text": "Higher, the better. And in the table, we\ncompare different types of message passing, graph\nattention, and another types",
    "start": "1845430",
    "end": "1852030"
  },
  {
    "text": "of message passing. We compare doing message passing\non the original graph, which is standard graph\nneural networks,",
    "start": "1852030",
    "end": "1858179"
  },
  {
    "text": "against the neural architecture,\nwhich is what we proposed. And you can see that just by\ndoing this trick of the tree",
    "start": "1858180",
    "end": "1864870"
  },
  {
    "text": "decomposition, we boost\nthe performance by 10%, in many cases, substantial\nboost in performance",
    "start": "1864870",
    "end": "1870870"
  },
  {
    "text": "with really a minor\naddition in the pipeline. And by the way, because our\ngraphs have small treewidth,",
    "start": "1870870",
    "end": "1876870"
  },
  {
    "text": "it means that the tree\ndecomposition is not huge, which means that the\nruntime of these algorithms of traditional graph neural\nnetworks and neural tree",
    "start": "1876870",
    "end": "1884620"
  },
  {
    "text": "are not very different. So we don't lose much in terms\nof-- in terms of computation.",
    "start": "1884620",
    "end": "1890990"
  },
  {
    "text": "OK, so I want to\nstress now for a couple of slides just some very recent\nextension of this 3D scene graph",
    "start": "1890990",
    "end": "1900890"
  },
  {
    "text": "work. This is something that will\nbe on archive hopefully today, is something that we are pretty\nmuch finalizing right now, which",
    "start": "1900890",
    "end": "1908410"
  },
  {
    "text": "is the observation that\nhierarchical representations are not just for indoor\nenvironments. But it makes sense to define\nhierarchical representations",
    "start": "1908410",
    "end": "1915279"
  },
  {
    "text": "in arbitrary environments. So imagine now we have\nan outdoor environment. We can still reason over\nthe mesh of the environment.",
    "start": "1915280",
    "end": "1922419"
  },
  {
    "text": "We can reason over\nobjects, places which represent traversability. But then instead of classifying\nthings into rooms, buildings,",
    "start": "1922420",
    "end": "1929200"
  },
  {
    "text": "and so on, we can classify them\ninto maybe field, road, park, and so on. There is still a hierarchy that\nwe can leverage in outdoors.",
    "start": "1929200",
    "end": "1937630"
  },
  {
    "text": "So the question\nwe ask is, can we adapt our algorithms to reason\nover arbitrary possibly outdoor",
    "start": "1937630",
    "end": "1943510"
  },
  {
    "text": "environments? And the way we are\nthinking about this problem is a problem of classifying\nplaces into high-level regions.",
    "start": "1943510",
    "end": "1950140"
  },
  {
    "text": "So I want to take this graph of\nnodes which are the black nodes, and I want to classify if\na place is part of a field,",
    "start": "1950140",
    "end": "1956289"
  },
  {
    "text": "is part of a road, and so\non, leveraging probably some possibly\nsemantic information",
    "start": "1956290",
    "end": "1961360"
  },
  {
    "text": "from the lower layers,\nfor example, which objects are nearby for each place.",
    "start": "1961360",
    "end": "1968200"
  },
  {
    "text": "So in theory, I could solve\nthis with a neural tree. I can solve this with\na graph neural network, but there are two challenges\nin outdoor environments.",
    "start": "1968200",
    "end": "1975580"
  },
  {
    "text": "The first challenge is that I'm\nnot really sure which concepts to include in the scene graph. I do not have rooms.",
    "start": "1975580",
    "end": "1981909"
  },
  {
    "text": "I can have very arbitrary\nset of concepts. And I really don't want to do\nthe job that for every testing",
    "start": "1981910",
    "end": "1988920"
  },
  {
    "text": "scenario, I have to come up\nwith a different set of objects. I would like to\nautomate that process. The more fundamental\nproblem is that there",
    "start": "1988920",
    "end": "1994810"
  },
  {
    "text": "is a lack of training data. For indoor scene\ngraphs, there are a bunch of training data sets.",
    "start": "1994810",
    "end": "2000100"
  },
  {
    "text": "For outdoor, you can think maybe\nthere is Google maps and things like that. But actually, there\nare no data sets",
    "start": "2000100",
    "end": "2005289"
  },
  {
    "text": "which are connecting\nthese high-level concepts with the objects\nin the data set. It's not easy to do\nthe training at all.",
    "start": "2005290",
    "end": "2013040"
  },
  {
    "text": "So we try to solve this problem\nwith a couple of contributions. The first one is to\ncreate a spatial ontology.",
    "start": "2013040",
    "end": "2019570"
  },
  {
    "text": "An ontology is just a graph\nof concepts and relations. So the idea is that we have\nto define an ontology, which",
    "start": "2019570",
    "end": "2025390"
  },
  {
    "text": "is summarizing the\nset of concepts we care about, dividing concepts\nbetween high-level concepts",
    "start": "2025390",
    "end": "2032050"
  },
  {
    "text": "like this can be the\nequivalent of rooms but can be fields\nand things that apply to outdoors and\nlow-level concepts, which",
    "start": "2032050",
    "end": "2038830"
  },
  {
    "text": "are pretty much the objects. And we can also establish\nrelations which are saying,",
    "start": "2038830",
    "end": "2045130"
  },
  {
    "text": "for example, a bed is more\nlikely to be in a bedroom, a kitchen is very likely\nto contain a fridge.",
    "start": "2045130",
    "end": "2050619"
  },
  {
    "text": "The tree set we\nhave-- of course, ontology can have a\nvery long history. And the tree set we have is that\nwe let a language model actually",
    "start": "2050620",
    "end": "2057250"
  },
  {
    "text": "populate a very dense\nontology for us. The main problem in\nbuilding ontology is that once you scale\nthe number of concepts",
    "start": "2057250",
    "end": "2063940"
  },
  {
    "text": "and the number of edges\nis very tough for a human to populate that, we just create\na language model with things",
    "start": "2063940",
    "end": "2069040"
  },
  {
    "text": "like, which k elements\nfrom the lowest layer are most distinctive about\na high-level concept?",
    "start": "2069040",
    "end": "2076120"
  },
  {
    "text": "For example, what\nare the objects which are more\ndistinctive of a kitchen? And with the response\nof a language model,",
    "start": "2076120",
    "end": "2082658"
  },
  {
    "text": "we populate all the\nedges in the ontology. The other thing that\nI think is pretty cool",
    "start": "2082659",
    "end": "2088899"
  },
  {
    "text": "is use to try to use the\nstructure of the ontology to help learning, in particular,\nin the case in which you do not",
    "start": "2088900",
    "end": "2096010"
  },
  {
    "text": "have a lot of training data. And to do that, we use a tool\nwhich is called logic tensor networks.",
    "start": "2096010",
    "end": "2101440"
  },
  {
    "text": "Logic tensor network\nin a nutshell are tools to enforce\nlogical rules",
    "start": "2101440",
    "end": "2106750"
  },
  {
    "text": "as part of the training\nof a neural network. So for example, in\na neural network, I want to give my neural network\na bunch of training examples.",
    "start": "2106750",
    "end": "2114440"
  },
  {
    "text": "But then I want to make\nsure that the prediction of my neural network are\nconsistent with the ontology. I want to make sure that\nthe neural network is not",
    "start": "2114440",
    "end": "2121000"
  },
  {
    "text": "predicting that the rock\ncan be in the bedroom. So I want to enforce these\nas hard logical constraints",
    "start": "2121000",
    "end": "2128770"
  },
  {
    "text": "on top of my training data. Logic tensor networks\nwill allow just that.",
    "start": "2128770",
    "end": "2133990"
  },
  {
    "text": "And just to give you a very\nbrief summary of what's going on, logic tensor networks\nwill use a loss function, which",
    "start": "2133990",
    "end": "2141280"
  },
  {
    "text": "is not the typical\ncross entropy and so on but will be a cross\nfunction, which is quantifying satisfaction\nof a set of formulas,",
    "start": "2141280",
    "end": "2149830"
  },
  {
    "text": "logical formulas. These are the five. And of course, if you think\nabout logical formulas, typically, you think\nabout [0, 1] satisfaction.",
    "start": "2149830",
    "end": "2157860"
  },
  {
    "text": "What logic tensor network does\nis to use real logic in which relaxed satisfaction\nin the interval [0, 1].",
    "start": "2157860",
    "end": "2164790"
  },
  {
    "text": "And you make everything\ndifferentiable by just relaxing satisfaction in [0, 1]. So it's a differentiable logic.",
    "start": "2164790",
    "end": "2171450"
  },
  {
    "text": "That's one way\nyou can take this. The advantage of\nthis is that now, we can use partially some training\ndata for doing training",
    "start": "2171450",
    "end": "2180030"
  },
  {
    "text": "of our graph neural network. But we can also use\nthe spatial ontology",
    "start": "2180030",
    "end": "2185460"
  },
  {
    "text": "to provide a supervision signal\nfor the neural network itself.",
    "start": "2185460",
    "end": "2191240"
  },
  {
    "text": "OK, so let me show you a couple\nof slides with results here. Qualitative results\nare on the right.",
    "start": "2191240",
    "end": "2197030"
  },
  {
    "text": "In this case, I'm starting\nwith indoor environments, just because we have a lot of\ndata for testing in this case.",
    "start": "2197030",
    "end": "2202400"
  },
  {
    "text": "So you see here, the\nenvironment being split in different rooms\nand all the room labels. And here, I have the\nquantitative results.",
    "start": "2202400",
    "end": "2210110"
  },
  {
    "text": "So the quantitative results\nare showing the accuracy of the classification\nof the rooms",
    "start": "2210110",
    "end": "2216050"
  },
  {
    "text": "in this case for decreasing\namount of training data. So here, I have close to 100%.",
    "start": "2216050",
    "end": "2222050"
  },
  {
    "text": "I have lots of data. Here, I have very\nlittle training data. What happens is that if you\nhave lots of training data,",
    "start": "2222050",
    "end": "2229490"
  },
  {
    "text": "if you use, for example,\nhere, cross entropy, you have very good performance.",
    "start": "2229490",
    "end": "2235460"
  },
  {
    "text": "And the proposed approach, which\nis based on this logic tensor network, will have pretty\nmuch similar performance.",
    "start": "2235460",
    "end": "2240890"
  },
  {
    "text": "So when you have plenty\nof data, you probably don't need this\nlogic tensor network. But as the amount of\ntraining data drops,",
    "start": "2240890",
    "end": "2248540"
  },
  {
    "text": "essentially, the cross\nentropy, standard cross entropy formulation will just drop.",
    "start": "2248540",
    "end": "2253680"
  },
  {
    "text": "And we'll get to, essentially,\nrandom guessing of the labels. And instead, the\nproposed approach",
    "start": "2253680",
    "end": "2259290"
  },
  {
    "text": "will approach a\nlower bound, which is the amount of information\nin the spatial ontology.",
    "start": "2259290",
    "end": "2264990"
  },
  {
    "text": "So in other words, if you remove\ncompletely the training data, the proposed approach\nwill still no",
    "start": "2264990",
    "end": "2271049"
  },
  {
    "text": "correlation between\nobjects and places through the spatial ontology,\nwhich will guarantee a minimum level of performance.",
    "start": "2271050",
    "end": "2277160"
  },
  {
    "text": "So if you're here, you\nprobably don't care about logic tensor networks. If you have very\nlittle data, they",
    "start": "2277160",
    "end": "2282810"
  },
  {
    "text": "can make a huge\ndifference for you. So for different projects,\nwe tried this out",
    "start": "2282810",
    "end": "2288360"
  },
  {
    "text": "in outdoor environments. The results are quite\neasy to understand already",
    "start": "2288360",
    "end": "2293370"
  },
  {
    "text": "from the figures. What you see in the figures\nare ground truth labels, which are the polygons here.",
    "start": "2293370",
    "end": "2300119"
  },
  {
    "text": "And the color of\nthe classification is the result of our network. So essentially, if all\nthese dots a green color",
    "start": "2300120",
    "end": "2307075"
  },
  {
    "text": "with the bounding\nbox, it means that we are classifying correctly. If we say they don't agree,\nlike in this case, for example,",
    "start": "2307075",
    "end": "2313000"
  },
  {
    "text": "the color doesn't agree, it\nmeans that the classification is incorrect. And we see that we are able\nto do decent classification",
    "start": "2313000",
    "end": "2320880"
  },
  {
    "text": "of many different concepts in\nlarge-scale outdoor data sets involving like roads,\nbuildings, forests, and so on.",
    "start": "2320880",
    "end": "2327990"
  },
  {
    "text": "This is an experiment with the\narmy research lab at West Point as well as dealing with\ncompletely different",
    "start": "2327990",
    "end": "2333150"
  },
  {
    "text": "environments. Like, this is a beach\nlike seaside environment close to Boston.",
    "start": "2333150",
    "end": "2338520"
  },
  {
    "text": "And I will not spend too\nmuch time about that. But it turns out that with\nthis logic tensor networks,",
    "start": "2338520",
    "end": "2343650"
  },
  {
    "text": "you can even predict\nat test time concepts that you haven't seen\nat training time,",
    "start": "2343650",
    "end": "2348810"
  },
  {
    "text": "just because the ontology can\nencode relations that maybe you haven't seen at test time. We can do even prediction,\nzero shot prediction of regions",
    "start": "2348810",
    "end": "2358590"
  },
  {
    "text": "that we haven't\nseen at test time. Also, in this case,\nwe really care about running these\non real robots.",
    "start": "2358590",
    "end": "2365069"
  },
  {
    "text": "So I'm showing\njust an experiment of q real robot running\nin the courtyard near to our building at MIT.",
    "start": "2365070",
    "end": "2371490"
  },
  {
    "text": "The robot, of\ncourse, is building this semantic map of the scene. He's isolating different\nobjects, for example,",
    "start": "2371490",
    "end": "2378810"
  },
  {
    "text": "chairs versus boxes and so on. And if you see--",
    "start": "2378810",
    "end": "2385050"
  },
  {
    "text": "maybe let me restart this. If you see on top of building\nthese low-level concepts,",
    "start": "2385050",
    "end": "2391200"
  },
  {
    "text": "the logic tensor network will\nallow to segment the space into different regions. So for example, we'll find\nthat there is a walkway.",
    "start": "2391200",
    "end": "2397980"
  },
  {
    "text": "There is some off-road\nterrain, and we're going to see this a little\nbit better in a few seconds.",
    "start": "2397980",
    "end": "2405990"
  },
  {
    "text": "So that's the type of\nperformance that we get. Again, the real image here and\nthe real-time reconstruction",
    "start": "2405990",
    "end": "2411900"
  },
  {
    "text": "on this side, there's a\nlittle bit of an acceleration, just to be fair.",
    "start": "2411900",
    "end": "2417190"
  },
  {
    "text": "The robot is not\nmoving that fast. You see that the logic tensor\nnetwork is getting from objects",
    "start": "2417190",
    "end": "2423940"
  },
  {
    "text": "to classifying. ",
    "start": "2423940",
    "end": "2429990"
  },
  {
    "text": "Should really cut this video\nin a better way, but let's see if I can-- so in this case, these\ntop ones are the places.",
    "start": "2429990",
    "end": "2436560"
  },
  {
    "text": "And they are classified into\ndifferent semantic regions. And I think it shows a little\nbit better later in the video,",
    "start": "2436560",
    "end": "2441570"
  },
  {
    "text": "but I think you got\nthe point there. So to close this part,\nI was insisting a lot",
    "start": "2441570",
    "end": "2447930"
  },
  {
    "text": "on this idea of hierarchical\nmaps for robotics. Now that we have\nthese maps or we made good progress on these\nmaps, what can we do with them?",
    "start": "2447930",
    "end": "2455670"
  },
  {
    "text": "And in this slide,\nI'm summarizing that there is a lot actually\nwe can do with them. We have been showing even\nin the original paper",
    "start": "2455670",
    "end": "2462672"
  },
  {
    "text": "that we proposed\nabout scene graphs that you can do now\nhierarchical path planning. You can speed up motion\nplanning a lot on these maps.",
    "start": "2462672",
    "end": "2470010"
  },
  {
    "text": "You can do-- you can apply\nreinforcement learning. You can do object search\nwith much better performance",
    "start": "2470010",
    "end": "2475080"
  },
  {
    "text": "compared to pixel to\naction approaches. And you can even\nuse the scene graph to reduce the amount\nof communication",
    "start": "2475080",
    "end": "2481170"
  },
  {
    "text": "in multi-robot systems. The thing that was reassuring\nis that the work at the bottom is from actually\ndifferent groups that",
    "start": "2481170",
    "end": "2487290"
  },
  {
    "text": "also found scene graphs\nto be very useful, in particular, for\nproblems involving task or task and motion planning\nas well as goal navigation.",
    "start": "2487290",
    "end": "2494320"
  },
  {
    "text": "And they've been showing\nimproved performance when using these\nhierarchical models.",
    "start": "2494320",
    "end": "2500020"
  },
  {
    "text": "And there is a lot\nmore to be done like in terms of human-robot\ninteraction, monitoring prediction, and so on.",
    "start": "2500020",
    "end": "2505060"
  },
  {
    "text": "But these models seems to be\npretty useful for robotics. So I want to spend the last\nfive minutes or so here",
    "start": "2505060",
    "end": "2512710"
  },
  {
    "text": "talking about\nself-supervised learning. I will make this quite fast.",
    "start": "2512710",
    "end": "2518170"
  },
  {
    "text": "The basic observation\nhere is that for safety critical robotics\napplication, we need algorithms,\nperception algorithms that",
    "start": "2518170",
    "end": "2524770"
  },
  {
    "text": "are able to distinguish correct\nestimates from incorrect ones. And we want them to adapt in\na self-supervised fashion.",
    "start": "2524770",
    "end": "2532240"
  },
  {
    "text": "Why do I care about\nfailures and adaptation? Well, even if you take the\nlatest foundation model and so",
    "start": "2532240",
    "end": "2538240"
  },
  {
    "text": "on, there are always going\nto be errors, in particular, in scenarios which are not the\ntypical ones that you encounter",
    "start": "2538240",
    "end": "2544330"
  },
  {
    "text": "in the training data. If you don't believe that,\nI just took a random image",
    "start": "2544330",
    "end": "2551190"
  },
  {
    "text": "from the web. Of course, it's a robot\nin a fire scenario.",
    "start": "2551190",
    "end": "2556770"
  },
  {
    "text": "And I pass this to a\ntransformer-based semantic segmentation architecture. One former is a pretty\ngood reasonable baseline,",
    "start": "2556770",
    "end": "2563550"
  },
  {
    "text": "is a very decent approach. And you see that even\nthe state of the art transformer-based\nmethods will classify the robot as a fire hydrant\nand the fire as a light.",
    "start": "2563550",
    "end": "2571410"
  },
  {
    "text": "So definitely, we have\nto worry about failures, even if you go for\nlarge foundation models.",
    "start": "2571410",
    "end": "2576720"
  },
  {
    "text": "So we started thinking\nabout essentially self-supervision for\nobject understanding",
    "start": "2576720",
    "end": "2583680"
  },
  {
    "text": "and, in particular, for\nobject pose estimation. So it's a little bit more\ngeometric than this example. So let me set the\nstage a little bit.",
    "start": "2583680",
    "end": "2591779"
  },
  {
    "text": "So in the first\npart of the talk, I discuss a lot about\nrobust estimation. I said that robust estimation\ncan be applied to localization",
    "start": "2591780",
    "end": "2599760"
  },
  {
    "text": "and mapping problem. In this part of\nthe talk, I'm going to apply that to a pose\nestimation problem for objects,",
    "start": "2599760",
    "end": "2604980"
  },
  {
    "text": "in which I say that I pass\nto the robust estimation a bunch of measurements\nof points on the object",
    "start": "2604980",
    "end": "2611550"
  },
  {
    "text": "I care about. And I want the robust\nestimator to figure out what is the pose of the\nobject I care about.",
    "start": "2611550",
    "end": "2618060"
  },
  {
    "text": "What is the role of\nlearning and all that? The role of learning is that,\ntypically, these measurements like these detections\nof the object",
    "start": "2618060",
    "end": "2625110"
  },
  {
    "text": "are produced by neural network. So what they ask is\nthat, now that you have much better robust\nestimation techniques,",
    "start": "2625110",
    "end": "2631860"
  },
  {
    "text": "can I use them to self-supervise\nthe neural network? So can we self-supervise\na neural network",
    "start": "2631860",
    "end": "2637620"
  },
  {
    "text": "using certifiable\nestimation algorithms? What I'm going to\nargue is actually that certification\nand self-supervision",
    "start": "2637620",
    "end": "2643710"
  },
  {
    "text": "are very coupled topics. If you solve one, you\nare very likely to be able to solve the other as well.",
    "start": "2643710",
    "end": "2648910"
  },
  {
    "text": "And I will show you the insight. I will keep it high\nlevel, but I will show you the\nintuition behind that just with a simple animation.",
    "start": "2648910",
    "end": "2656490"
  },
  {
    "text": "So imagine that you have a\npre-trained neural network, a neural network\nwhich is trained maybe just in simulation.",
    "start": "2656490",
    "end": "2661950"
  },
  {
    "text": "This can be maybe a foundation\nmodel like a pre-trained model. And imagine now that\nI'm going to expose that",
    "start": "2661950",
    "end": "2668610"
  },
  {
    "text": "to real data which is unlabeled. So imagine at test time, I\nprovide a batch of three samples",
    "start": "2668610",
    "end": "2675964"
  },
  {
    "text": "to my pre-trained\nneural network.  So what happens\nis that I can just",
    "start": "2675965",
    "end": "2681359"
  },
  {
    "text": "do a forward pass of\nthe neural network. The neural network will\npredict a bunch of key points. And then I can do my robust\nestimation algorithms",
    "start": "2681360",
    "end": "2688740"
  },
  {
    "text": "to predict the\npose of the object. Now if you have a\ncertifiable algorithm, which",
    "start": "2688740",
    "end": "2694988"
  },
  {
    "text": "is an algorithm that\nis able to distinguish correct estimates\nfrom incorrect ones and be able to understand\nwhich of the results is correct",
    "start": "2694988",
    "end": "2701430"
  },
  {
    "text": "and which of the\nresults is wrong-- and I can do\nsomething very simple. I can take the correct\none as a pseudo label",
    "start": "2701430",
    "end": "2708000"
  },
  {
    "text": "and back propagate the result\nto improve my neural network a little bit. And then I can try with\nanother batch of data.",
    "start": "2708000",
    "end": "2714930"
  },
  {
    "text": "The network now\nimproved a little bit. And maybe in this case, I\nproduced two correct results. And I can back\npropagate these a bit.",
    "start": "2714930",
    "end": "2722030"
  },
  {
    "text": "And then I can keep\ngoing, incrementally improving the quality\nof my neural network, again, without any labels.",
    "start": "2722030",
    "end": "2728920"
  },
  {
    "text": "Essentially, the\npipeline by certifying which outputs are correct\nwill create labels on the fly, pseudo\nlabels on the fly.",
    "start": "2728920",
    "end": "2737840"
  },
  {
    "text": "OK, so we applied this idea\nfor object pose estimation. We are giving RGB-D data.",
    "start": "2737840",
    "end": "2743420"
  },
  {
    "text": "We have to estimate the pose\nof an object in the image. Again, there is a\nneural network that you want to self-supervise\nand improve over time.",
    "start": "2743420",
    "end": "2751309"
  },
  {
    "text": "We have this robust corrector\nwhich is our robust estimation module. And we have\ncertificates which are",
    "start": "2751310",
    "end": "2756560"
  },
  {
    "text": "in charge of deciding if\nwe got the right estimate or the wrong one. And the type of performance we\nget is summarized by this video.",
    "start": "2756560",
    "end": "2763550"
  },
  {
    "text": "So we start at initial iteration\nin which the pre-trained network is not doing great. So you see that the\nprediction of the object",
    "start": "2763550",
    "end": "2770450"
  },
  {
    "text": "doesn't match the\npoint cloud very well. But the more self-supervised\niterations, we do the better.",
    "start": "2770450",
    "end": "2776180"
  },
  {
    "text": "The point cloud in\ngreen is aligning to the object, which\nmeans the better job we are doing at estimating\nthe pose of the object.",
    "start": "2776180",
    "end": "2783289"
  },
  {
    "text": "And all of these is just\nimproving the performance of the network without the\nneed for any supervision from a human.",
    "start": "2783290",
    "end": "2789440"
  },
  {
    "text": "So we push this-- this is\na more recent line of work. We push this in a\ncouple of papers at RSS. We actually shown that we\ncan apply this idea also",
    "start": "2789440",
    "end": "2797339"
  },
  {
    "text": "if you put multiple\nmodels in parallel. So if you have an\nensemble of model, you can self-supervise them.",
    "start": "2797340",
    "end": "2803220"
  },
  {
    "text": "At the same time, you\ncan take advantage that maybe one model is cross\nsupervising the other and so on.",
    "start": "2803220",
    "end": "2809110"
  },
  {
    "text": "So you can apply this idea to\nan ensemble of models instead. ",
    "start": "2809110",
    "end": "2814770"
  },
  {
    "text": "I will spend maybe one\nslide about results, and then I know we have to stop. But you can look at the\nperformance of maybe this video,",
    "start": "2814770",
    "end": "2823980"
  },
  {
    "text": "this figure. This is the cumulative\ndistribution of the errors.",
    "start": "2823980",
    "end": "2829049"
  },
  {
    "text": "You want this to be on the\nleft as much as possible. The proposed\napproach is in blue. We actually do\npretty well compared",
    "start": "2829050",
    "end": "2835619"
  },
  {
    "text": "to a fully supervised baseline. And we do much, much\nbetter than Self6d++,",
    "start": "2835620",
    "end": "2840750"
  },
  {
    "text": "which is a\nself-supervised baseline. We have been applying this\nidea for all sorts of problems.",
    "start": "2840750",
    "end": "2847110"
  },
  {
    "text": "NASA is using this for\nlunar tower assembly. We are doing a project right\nnow for warehouse automation",
    "start": "2847110",
    "end": "2854190"
  },
  {
    "text": "in which we do pose\nestimation with these methods. And we are having fun also using\nthis kind of pose estimation",
    "start": "2854190",
    "end": "2859440"
  },
  {
    "text": "methods for aggressive\naerial manipulation, as you can see in the\nvideo on the right.",
    "start": "2859440",
    "end": "2865980"
  },
  {
    "text": "Maybe let me get the real demo. So we can do aggressive\nmanipulation of objects just by detecting\nthem in real time.",
    "start": "2865980",
    "end": "2874300"
  },
  {
    "text": "So in summary, today, hopefully,\nI cover a lot of ground. I hope you saw some\nof the progress we",
    "start": "2874300",
    "end": "2880770"
  },
  {
    "text": "made on robust\nestimation, scene graph, and hierarchical representation\nand self-supervised learning. And hopefully,\nthat will bring us",
    "start": "2880770",
    "end": "2886800"
  },
  {
    "text": "closer to having agents\nthat can interact with objects and\nwith the environment and the vision-based navigation.",
    "start": "2886800",
    "end": "2892020"
  },
  {
    "text": "So I wrap up here thanking\nthe sponsors and, of course, thanking you for your attention. All right.",
    "start": "2892020",
    "end": "2897210"
  },
  {
    "text": "[APPLAUSE] ",
    "start": "2897210",
    "end": "2904000"
  }
]
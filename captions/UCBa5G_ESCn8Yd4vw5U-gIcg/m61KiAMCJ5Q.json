[
  {
    "start": "0",
    "end": "5400"
  },
  {
    "text": "So the plan for today is to\ntalk about energy-based model. So it's going to be another\nfamily of generative models",
    "start": "5400",
    "end": "13950"
  },
  {
    "text": "that is closely related to\ndiffusion models, which is what we're going to talk about next.",
    "start": "13950",
    "end": "19950"
  },
  {
    "text": "So as a recap, remember, this\nis the high level picture",
    "start": "19950",
    "end": "25020"
  },
  {
    "text": "where which I think summarizes\npretty well the design space. When you're trying to\nbuild a generative model,",
    "start": "25020",
    "end": "31800"
  },
  {
    "text": "you have data coming from\nsome unknown data distribution and you have IID\nsamples from it.",
    "start": "31800",
    "end": "37900"
  },
  {
    "text": "You always need to define\nsome kind of model family. And then you need to define a\nloss function that basically",
    "start": "37900",
    "end": "44250"
  },
  {
    "text": "tells you how good your\nmodel is compared to the data distribution.",
    "start": "44250",
    "end": "49450"
  },
  {
    "text": "And we've seen that\nlikelihood or KL divergence is a very reasonable approach.",
    "start": "49450",
    "end": "56250"
  },
  {
    "text": "And that's pretty natural to\nuse without regressive models,",
    "start": "56250",
    "end": "62970"
  },
  {
    "text": "normalizing flow models,\nand to some extent, variational autoencoders\nbecause they give you",
    "start": "62970",
    "end": "69670"
  },
  {
    "text": "ways to either exactly\nor approximately evaluate the probability of a data point.",
    "start": "69670",
    "end": "75500"
  },
  {
    "text": "And so you can of score how\nclose p theta is to a data distribution by basically\ncomputing the KL divergence up",
    "start": "75500",
    "end": "83260"
  },
  {
    "text": "to a constant, which is\njust like the likelihood assigned by the\nmodel to the data, which is like a\ncompression-based type",
    "start": "83260",
    "end": "90640"
  },
  {
    "text": "of objective. And as we know, maximum\nlikelihood training",
    "start": "90640",
    "end": "96009"
  },
  {
    "text": "is very good. It's a very principled\nway of training models. But you always have some kind\nof restrictions in terms of,",
    "start": "96010",
    "end": "102580"
  },
  {
    "text": "OK, how do you define this set\nof probability distributions. And you cannot pick an arbitrary\nneural network that will take",
    "start": "102580",
    "end": "110950"
  },
  {
    "text": "as input the different axes,\nlike the data point and maps it to a scalar.",
    "start": "110950",
    "end": "116650"
  },
  {
    "text": "It has to be a valid probability\ndensity or a valid probability mass function.",
    "start": "116650",
    "end": "121850"
  },
  {
    "text": "And so in order to do that, you\nhave to either use chain rule and break it down into a\nproduct of conditionals.",
    "start": "121850",
    "end": "128949"
  },
  {
    "text": "Or you have to use some kind\nof invertible neural network to define that the\nmarginal distribution.",
    "start": "128949",
    "end": "135680"
  },
  {
    "text": "Or you have to deal\nwith approximations and use a variational\nautoencoder.",
    "start": "135680",
    "end": "141760"
  },
  {
    "text": "And then the other approach\nor the other extreme is to try to have as much\nflexibility as possible in terms",
    "start": "141760",
    "end": "150340"
  },
  {
    "text": "of defining the model family. And specifically, we're just\ngoing to define the probability",
    "start": "150340",
    "end": "157720"
  },
  {
    "text": "distribution implicitly by\ninstead defining the sampling procedure. And the price that\nyou have to pay",
    "start": "157720",
    "end": "167650"
  },
  {
    "text": "is that you can no\nlonger basically measure this kind of similarity up\nhere using KL divergence.",
    "start": "167650",
    "end": "176230"
  },
  {
    "text": "You have to essentially come up\nwith a training objective that",
    "start": "176230",
    "end": "181629"
  },
  {
    "text": "does not require you to evaluate\nprobability of data points. Essentially, the only thing you\nhave access to at this point",
    "start": "181630",
    "end": "187600"
  },
  {
    "text": "is samples from the data\nand samples from the model. And so you have to come up\nwith some kind of two sample",
    "start": "187600",
    "end": "194720"
  },
  {
    "text": "test, some kind of likelihood\nfree way of comparing how similar the samples, the real\nsamples from the fake samples",
    "start": "194720",
    "end": "202190"
  },
  {
    "text": "are. And GANs are one way to do that\nwhere you have this minimax objective, where you're\ntrying to train a generator",
    "start": "202190",
    "end": "209420"
  },
  {
    "text": "to produce samples that\nare hard to distinguish from the real ones as measured\nby some discriminator that",
    "start": "209420",
    "end": "216620"
  },
  {
    "text": "is trained in the innermost\nmaximization problem to do as well as it\ncan to distinguish real",
    "start": "216620",
    "end": "222680"
  },
  {
    "text": "versus fake samples. And we've seen that\nunder some conditions,",
    "start": "222680",
    "end": "230569"
  },
  {
    "text": "this is principled in the\nsense that if you had access to extremely powerful\ndiscriminator, then",
    "start": "230570",
    "end": "236930"
  },
  {
    "text": "you could, to some\nextent, approximate the optimization of an f\ndivergence or even a Wasserstein",
    "start": "236930",
    "end": "242870"
  },
  {
    "text": "distance. But in practice,\nalthough it's true",
    "start": "242870",
    "end": "247940"
  },
  {
    "text": "that you can use essentially\nany architecture you want to define the\nsampling procedure,",
    "start": "247940",
    "end": "253549"
  },
  {
    "text": "training this kind of minimax-- with this minimax\nobjectives is very tricky",
    "start": "253550",
    "end": "259278"
  },
  {
    "text": "because we don't\nhave likelihoods. You have to do minimax\noptimization, which is unstable. It's hard to track progress.",
    "start": "259279",
    "end": "265560"
  },
  {
    "text": "It's hard to know whether\nyou have converged or not. It's hard to evaluate whether\none model is better than the other because you cannot\njust look at the loss.",
    "start": "265560",
    "end": "272420"
  },
  {
    "text": "And you have mode collapses. And so all sorts of issues\nthat arise in practice when you try to train an\nadversarial-type model.",
    "start": "272420",
    "end": "281870"
  },
  {
    "text": "And so what we're\ngoing to see today is another way of\ndefining a model family.",
    "start": "281870",
    "end": "288240"
  },
  {
    "text": "So kind of a different\nway of parameterizing probabilistic models that is\ncalled an energy-based model.",
    "start": "288240",
    "end": "295520"
  },
  {
    "text": "And what we'll see is that this\nwill allow us to essentially lift all those\nrestrictions that we",
    "start": "295520",
    "end": "302060"
  },
  {
    "text": "had on the kind\nof neural networks you can use to define a\nvalid probability density",
    "start": "302060",
    "end": "307400"
  },
  {
    "text": "function or a valid\nprobability mass function. So that's the main\nbenefit of using this kind of energy-based\nmodels, extreme flexibility.",
    "start": "307400",
    "end": "316560"
  },
  {
    "text": "And to some extent,\nthey will allow us to have some fairly stable\ntraining procedure in the sense",
    "start": "316560",
    "end": "324690"
  },
  {
    "text": "that it's still going to be\nbased on maximum likelihood or other variants of\nlosses that are fully--",
    "start": "324690",
    "end": "333750"
  },
  {
    "text": "that are taking\nadvantage of the fact that you have a\nprobabilistic model and not just a sampling procedure.",
    "start": "333750",
    "end": "340979"
  },
  {
    "text": "And these models tend\nto work pretty well. They give you fairly\nhigh sample quality. And we'll see they are\nvery closely related",
    "start": "340980",
    "end": "347880"
  },
  {
    "text": "to diffusion models\nwhich are actually state of the art\nmodels right now for a lot of\ncontinuous modalities",
    "start": "347880",
    "end": "354540"
  },
  {
    "text": "like images, videos,\nand audio, and others.",
    "start": "354540",
    "end": "359910"
  },
  {
    "text": "And as another benefit, you can\nalso compose energy-based models in interesting ways.",
    "start": "359910",
    "end": "366400"
  },
  {
    "text": "And so we'll see that\nthat's another thing you can do that you can\ntake different kinds",
    "start": "366400",
    "end": "372720"
  },
  {
    "text": "of generative models and\nyou can combine them. Because essentially,\nit's one way of defining an\nenergy-based model",
    "start": "372720",
    "end": "378980"
  },
  {
    "text": "and that allows you to do\ninteresting things like,",
    "start": "378980",
    "end": "384320"
  },
  {
    "text": "essentially, combining\ndifferent concepts and combining different\nkinds of model families",
    "start": "384320",
    "end": "389660"
  },
  {
    "text": "together like a flow model\nand an autoregressive model and we'll see that that's also\nbeneficial in some settings.",
    "start": "389660",
    "end": "398930"
  },
  {
    "text": "So the high level\nmotivation is the usual one.",
    "start": "398930",
    "end": "405539"
  },
  {
    "text": "We want to define a\nprobabilistic model. So we want to define a\nprobability distribution",
    "start": "405540",
    "end": "411020"
  },
  {
    "text": "because that's the\nkey building block. We need to define this green set\nhere that we're optimizing over.",
    "start": "411020",
    "end": "418670"
  },
  {
    "text": "And if we can do\nthat, then we can just couple that with a loss\nfunction and you get a new kind of generative model.",
    "start": "418670",
    "end": "426150"
  },
  {
    "text": "And to some extent,\nthis is just a function. It's a function that\ntakes x as an input",
    "start": "426150",
    "end": "432690"
  },
  {
    "text": "where x could be an image,\nor a sentence, or whatever and maps it to a scalar.",
    "start": "432690",
    "end": "438000"
  },
  {
    "text": "So it seems pretty\nstraightforward. But the key thing is that\nyou cannot pick an arbitrary",
    "start": "438000",
    "end": "444000"
  },
  {
    "text": "function. This valid probability density\nfunctions or probability mass",
    "start": "444000",
    "end": "449970"
  },
  {
    "text": "functions in the\ndiscrete case, they are a special kind of functions\nin the sense that they need",
    "start": "449970",
    "end": "455550"
  },
  {
    "text": "to satisfy certain constraints. The first one is that they\nhave to be non-negative. So given any input\nx, the output scalar",
    "start": "455550",
    "end": "463650"
  },
  {
    "text": "that you get from this function\nhas to be a non-negative number. And this will say it's not a\nparticularly hard constraint",
    "start": "463650",
    "end": "470130"
  },
  {
    "text": "to enforce. The more difficult one is that\nthey have to be normalized.",
    "start": "470130",
    "end": "476920"
  },
  {
    "text": "So because we're working\nwith probabilities, it has to be the\ncase that if you look at all the possible\nthings that can happen",
    "start": "476920",
    "end": "483690"
  },
  {
    "text": "and you sum up their\nprobabilities, you get 1. Or if you're working with\ncontinuous random variables,",
    "start": "483690",
    "end": "489780"
  },
  {
    "text": "if you integrate, the\nprobability density function over the whole\nspace, you should get 1.",
    "start": "489780",
    "end": "497220"
  },
  {
    "text": "And so again, this is\nbasically due to the fact",
    "start": "497220",
    "end": "502290"
  },
  {
    "text": "that essentially\nthe probabilities,",
    "start": "502290",
    "end": "508380"
  },
  {
    "text": "if you go through all the\npossible things that can happen, have to sum to 1.",
    "start": "508380",
    "end": "514260"
  },
  {
    "text": "And that's a much trickier\nkind of constraint to enforce.",
    "start": "514260",
    "end": "519280"
  },
  {
    "text": "That's really the hard\nconstraint to enforce. And that's because\nessentially, the reason",
    "start": "519280",
    "end": "524490"
  },
  {
    "text": "we have to enforce those\nstrange architectures like autoregressive\nmodels or flow models",
    "start": "524490",
    "end": "530519"
  },
  {
    "text": "is basically because we have\nto enforce this normalization constraint. And enforcing that is tricky.",
    "start": "530520",
    "end": "536157"
  },
  {
    "text": "And if you take an\narbitrary neural network, it's not going to enforce-- it's not going to satisfy that\nconstraint and enforcing that is",
    "start": "536157",
    "end": "543630"
  },
  {
    "text": "not it's not straightforward. And so again, if you think\nabout the first constraint,",
    "start": "543630",
    "end": "551340"
  },
  {
    "text": "it's not a very hard\nproperty to satisfy.",
    "start": "551340",
    "end": "557220"
  },
  {
    "text": "It's not hard to come up with\na very broad set of families",
    "start": "557220",
    "end": "562829"
  },
  {
    "text": "of functions that are guaranteed\nto be non-negative given any input. And in fact, if you take\nan arbitrary function,",
    "start": "562830",
    "end": "570930"
  },
  {
    "text": "let's say an arbitrary\nneural network, it's pretty trivial to change\nit a little bit and make sure",
    "start": "570930",
    "end": "577260"
  },
  {
    "text": "that the output is guaranteed\nto be non-negative. And so one thing\nyou can do is you",
    "start": "577260",
    "end": "583079"
  },
  {
    "text": "can take an arbitrary\nneural network f theta. If you just square the\noutput that it produces,",
    "start": "583080",
    "end": "588900"
  },
  {
    "text": "you get a new neural\nnetwork, g theta, which is also very flexible\nbecause it's basically very similar to the f\ntheta that you started with",
    "start": "588900",
    "end": "596820"
  },
  {
    "text": "and it's guaranteed to be\nnon-negative given any input. Or you can take the exponential.",
    "start": "596820",
    "end": "603709"
  },
  {
    "text": "Again, given an arbitrary\nneural network f theta, if you just basically add an\nextra layer at the end which",
    "start": "603710",
    "end": "609709"
  },
  {
    "text": "takes the output and passes\nit through this exponential non-linearity, then you\nget a new neural network,",
    "start": "609710",
    "end": "616260"
  },
  {
    "text": "which is guaranteed\nto be non-negative. Or you could take\nthe absolute value. Or I'm sure you can cook\nup many, many other ways",
    "start": "616260",
    "end": "624380"
  },
  {
    "text": "of transforming a neural\nnetwork into one that is just",
    "start": "624380",
    "end": "629570"
  },
  {
    "text": "as basically flexible,\nwhere you just add a new layer at the end that\nis guaranteed to make the output",
    "start": "629570",
    "end": "635930"
  },
  {
    "text": "non-negative. So that's not hard to do.",
    "start": "635930",
    "end": "641370"
  },
  {
    "text": "The tricky part is to\nguarantee that basically if you go through all the\npossible inputs",
    "start": "641370",
    "end": "646440"
  },
  {
    "text": "that you can feed through\nthis neural network and you sum up the\noutputs, you get 1.",
    "start": "646440",
    "end": "653050"
  },
  {
    "text": "Or if you have a continuous\nsetting where the inputs are continuous, then the integral\nover all possible inputs",
    "start": "653050",
    "end": "659580"
  },
  {
    "text": "to this neural\nnetwork has to be 1. And I guess one way to\nthink about it is that--",
    "start": "659580",
    "end": "666790"
  },
  {
    "text": "and why this is\nimportant if you're building a probabilistic model\nis that this is basically enforcing that the total\nprobability mass is fixed.",
    "start": "666790",
    "end": "675740"
  },
  {
    "text": "So if you're thinking about the\nrole of a probabilistic model as being-- or the meaning of outputting\nof computing p of x",
    "start": "675740",
    "end": "683907"
  },
  {
    "text": "is you're saying, what is the\nprobability that the model assigns to one particular x,\nwhich could be an image or it",
    "start": "683907",
    "end": "689839"
  },
  {
    "text": "could be some sentence in a\nlanguage modeling application.",
    "start": "689840",
    "end": "694910"
  },
  {
    "text": "The fact that basically the sum\nof all the probabilities is 1",
    "start": "694910",
    "end": "700639"
  },
  {
    "text": "is enforcing this fact that\nessentially the total volume is fixed. So if you increase the\nprobability of one data point,",
    "start": "700640",
    "end": "709190"
  },
  {
    "text": "you're guaranteed that the\nprobability of something else will have to go down. So the analogy is\nthat there is a cake",
    "start": "709190",
    "end": "715640"
  },
  {
    "text": "and you can divide it up\nin many different ways. But if you make\none slice bigger,",
    "start": "715640",
    "end": "720829"
  },
  {
    "text": "then the other ones will have\nto get smaller inevitably.",
    "start": "720830",
    "end": "725960"
  },
  {
    "text": "And we need this\nkind of guarantee so that when we increase\nthe probability of the data",
    "start": "725960",
    "end": "734900"
  },
  {
    "text": "that we have in the\ntraining set by increasing the slice of the cake that we\nassign to the samples we like,",
    "start": "734900",
    "end": "744247"
  },
  {
    "text": "the ones that are\nin the training set, we're automatically reducing\nthe probability of other things",
    "start": "744247",
    "end": "749820"
  },
  {
    "text": "which are, in the case of a\ngenerative model, the things that basically we don't like.",
    "start": "749820",
    "end": "756600"
  },
  {
    "text": "And again, enforcing the\nnon-negativity constraint, which is basically\nsaying with this analogy",
    "start": "756600",
    "end": "763830"
  },
  {
    "text": "that the size of each slice\nis non-negative, is easy.",
    "start": "763830",
    "end": "770220"
  },
  {
    "text": "But enforcing this constraint\nthat's the volume is fixed. ",
    "start": "770220",
    "end": "777720"
  },
  {
    "text": "Here in the definition, it's 1. But as long as you\ncan keep it fixed, basically, that's fine\nbecause you can always",
    "start": "777720",
    "end": "784890"
  },
  {
    "text": "divide by the constant. But enforcing that\nbasically regardless",
    "start": "784890",
    "end": "791519"
  },
  {
    "text": "of how you choose\nyour parameters theta in your neural network,\nyou're guaranteed sort of like--",
    "start": "791520",
    "end": "798870"
  },
  {
    "text": "if you go through all\nthe possible inputs, or if you sum over\nall possible inputs, or you take an integral\nover all possible inputs",
    "start": "798870",
    "end": "805560"
  },
  {
    "text": "and you look at\nthe output value, you get a constant which\ndoes not depend on theta,",
    "start": "805560",
    "end": "811690"
  },
  {
    "text": "does not depend\non the parameters of the neural\nnetwork, that's hard. You can always compute what is\nthe total normalized probability",
    "start": "811690",
    "end": "823240"
  },
  {
    "text": "that is assigned by\na neural network. If you go through all\nthe possible inputs, there's always going\nto be some number.",
    "start": "823240",
    "end": "829288"
  },
  {
    "text": "If you go through\nall possible inputs and you evaluate the output\nof the neural network, you sum them up, you're\ngoing to get a value.",
    "start": "829288",
    "end": "836650"
  },
  {
    "text": "But in general, that value\nis going to depend on theta. It's going to depend\non the parameters",
    "start": "836650",
    "end": "843340"
  },
  {
    "text": "of your neural network. And it's not going to be 1. It's not going to\nbe something fixed. Unless, you choose g theta.",
    "start": "843340",
    "end": "849640"
  },
  {
    "text": "You choose your function family\nin some very special way, like an autoregressive model or\nwith invertible architectures,",
    "start": "849640",
    "end": "856450"
  },
  {
    "text": "that's guaranteed by\ndesign that no matter how you choose your parameters, the\ntotal mass or the total volume",
    "start": "856450",
    "end": "862420"
  },
  {
    "text": "is basically fixed. And the analogy here is\nin the discrete case,",
    "start": "862420",
    "end": "868810"
  },
  {
    "text": "you sum over all\npossible inputs. In the continuous\ncase, it's the integral",
    "start": "868810",
    "end": "874240"
  },
  {
    "text": "that you have to worry about. ",
    "start": "874240",
    "end": "880020"
  },
  {
    "text": "And so that's basically the\nhard constraint to enforce.",
    "start": "880020",
    "end": "886710"
  },
  {
    "text": "Somehow what we need\nto be able to do is we need to be able to come up\nwith a family of functions that",
    "start": "886710",
    "end": "893670"
  },
  {
    "text": "are parameterized by theta. Ideally, this function should\nbe as flexible as possible, meaning that you\nwould like to choose",
    "start": "893670",
    "end": "902250"
  },
  {
    "text": "essentially an arbitrary\nneural network, or very deep neural networks, or\nno kind of constraints",
    "start": "902250",
    "end": "908459"
  },
  {
    "text": "on the kind of layers\nthat you can choose. It's easy to enforce that\nthe function is non-negative",
    "start": "908460",
    "end": "914280"
  },
  {
    "text": "but it's very hard to\nenforce that the volume is fixed to some value.",
    "start": "914280",
    "end": "920460"
  },
  {
    "text": "Yeah? I mean, we still\nneed one function that satisfies if you're\ngoing to redistribute",
    "start": "920460",
    "end": "927060"
  },
  {
    "text": "the pie though, we\nneed a starting point? So yeah, basically, that's the\nidea of energy-based models",
    "start": "927060",
    "end": "933000"
  },
  {
    "text": "is that basically,\nas long as you can compute the\ntotal area of the pie",
    "start": "933000",
    "end": "939880"
  },
  {
    "text": "or the total amount\nof pie that you have, then you can define\nan energy-- you can define a valid probabilistic\nmodel by basically just dividing",
    "start": "939880",
    "end": "947020"
  },
  {
    "text": "by that number. And that's basically the idea\nbehind energy-based models. The fact is that given a\nnon-negative function g theta,",
    "start": "947020",
    "end": "959770"
  },
  {
    "text": "you can always define a valid\nprobabilistic model by basically",
    "start": "959770",
    "end": "965860"
  },
  {
    "text": "dividing by the total volume, by\nthe total area, the total size",
    "start": "965860",
    "end": "972070"
  },
  {
    "text": "of the pie, by dividing\nby the integral over all possible inputs of\nthe unnormalized probability.",
    "start": "972070",
    "end": "978190"
  },
  {
    "text": "And that defines a valid\nprobability distribution because this object\nis now normalized. So if for every\ntheta you can compute",
    "start": "978190",
    "end": "985540"
  },
  {
    "text": "these unnormalized\nprobabilities, the size of each slice of the cake,\nand at the same time",
    "start": "985540",
    "end": "991000"
  },
  {
    "text": "you can also compute\nhow big is the cake, and you divide\nthese two, then you get something that is normalized\nbecause it's like a ratio.",
    "start": "991000",
    "end": "998750"
  },
  {
    "text": "And that is basically the main\nidea behind energy-based models,",
    "start": "998750",
    "end": "1007840"
  },
  {
    "text": "is to just bite\nthe bullet and be willing to work with probability\ndensity functions or probability",
    "start": "1007840",
    "end": "1017100"
  },
  {
    "text": "mass functions that are\ndefined by normalizing objects",
    "start": "1017100",
    "end": "1022470"
  },
  {
    "text": "that are not necessarily\nnormalized by design. By dividing by this\nquantity Z theta,",
    "start": "1022470",
    "end": "1028260"
  },
  {
    "text": "which is often called\nthe partition function, this normalization\nconstant, the total volume,",
    "start": "1028260",
    "end": "1033689"
  },
  {
    "text": "the total normal amount of\nunnormalized probability that we need to divide by to\nget a valid probabilistic model.",
    "start": "1033690",
    "end": "1040829"
  },
  {
    "text": "And you can see that if you\nare willing to divide by this Z theta, you can get a valid--",
    "start": "1040829",
    "end": "1048580"
  },
  {
    "text": "you get an object\nthat is normalized. Because if you integrate\nthe left hand side here",
    "start": "1048580",
    "end": "1055710"
  },
  {
    "text": "and you swap in the\ndefinition, which is g theta over the\nnormalization constant,",
    "start": "1055710",
    "end": "1060870"
  },
  {
    "text": "you basically get the integral\nover all the possible things that can happen in the\nnumerator, the integral of all",
    "start": "1060870",
    "end": "1067920"
  },
  {
    "text": "the possible things that can\nhappen in the denominator. And when you divide them, you\nget 1 by definition, basically.",
    "start": "1067920",
    "end": "1077029"
  },
  {
    "text": "And so basically, as long as you\nhave a non-negative function, g theta, you can always define\na valid normalized probabilistic",
    "start": "1077030",
    "end": "1085279"
  },
  {
    "text": "model by dividing by this\nnormalization constant, by this partition\nfunction, by the integral",
    "start": "1085280",
    "end": "1091580"
  },
  {
    "text": "over the scalar that\nis well defined, which is just the integral\nover all possible inputs",
    "start": "1091580",
    "end": "1098330"
  },
  {
    "text": "or the sum over all possible\ninputs in the discrete space of these unnormalized\nprobabilities that you get by\njust using g theta.",
    "start": "1098330",
    "end": "1106030"
  },
  {
    "text": " And as a few examples that you\nmight have seen before is--",
    "start": "1106030",
    "end": "1118660"
  },
  {
    "text": "or one way to go about this\nis to choose functions g theta for which\nthis denominator,",
    "start": "1118660",
    "end": "1126610"
  },
  {
    "text": "this normalizing constant,\nthis partition function is basically known analytically.",
    "start": "1126610",
    "end": "1132610"
  },
  {
    "text": "In general, we might not know. This integral might\nbe tricky to compute.",
    "start": "1132610",
    "end": "1138040"
  },
  {
    "text": "But if we restrict ourselves to\nrelatively simple functions, g theta, we might be able\nto compute that integral",
    "start": "1138040",
    "end": "1144520"
  },
  {
    "text": "in closed form analytically. For example, if we choose g to\nhave a very simple form, which",
    "start": "1144520",
    "end": "1152200"
  },
  {
    "text": "is just the relationship that\nyou have in a Gaussian PDF,",
    "start": "1152200",
    "end": "1159820"
  },
  {
    "text": "so g is just basically\na squared exponential. And g now has two\nparameters, mu and sigma.",
    "start": "1159820",
    "end": "1166960"
  },
  {
    "text": "And this non-negative\nfunction is just a-- or e to the minus x minus\nmu squared basically",
    "start": "1166960",
    "end": "1175980"
  },
  {
    "text": "is divided by the\nvariance, sigma squared. This function is non-negative.",
    "start": "1175980",
    "end": "1182590"
  },
  {
    "text": "By itself, it's not\nnecessarily normalized. But it's a simple\nenough function",
    "start": "1182590",
    "end": "1188470"
  },
  {
    "text": "that you can actually compute\nthe integral analytically. We have a closed form\nsolution to that.",
    "start": "1188470",
    "end": "1195039"
  },
  {
    "text": "And the total volume\nis just the square root of 2 pi sigma squared. And indeed, if you take\nthis expression of g",
    "start": "1195040",
    "end": "1204400"
  },
  {
    "text": "and you divide it\nby the total volume, you get the Gaussian PDF. So you can think of that\nstrange scaling factor",
    "start": "1204400",
    "end": "1213820"
  },
  {
    "text": "that you have in front of the\nGaussian PDF as being basically the total volume that you\nhave to divide for if you want",
    "start": "1213820",
    "end": "1219820"
  },
  {
    "text": "to get a normalized object. Or you could choose,\nOK, let's choose g",
    "start": "1219820",
    "end": "1224890"
  },
  {
    "text": "to be just an exponential\nthat looks like this. You have a single\nparameter lambda and g",
    "start": "1224890",
    "end": "1231070"
  },
  {
    "text": "of x is e to the minus lambda x. Again, non-negative\nfunction by itself is not necessarily normalized.",
    "start": "1231070",
    "end": "1237850"
  },
  {
    "text": "But you can compute the\nvolume in closed form. It turns out to be\njust 1 over lambda.",
    "start": "1237850",
    "end": "1243290"
  },
  {
    "text": "And so you can actually get-- if you divide these\ntwo things, you get a valid PDF which\nis the one corresponding",
    "start": "1243290",
    "end": "1251590"
  },
  {
    "text": "to the exponential distribution. And more generally,\nthere is a broad family",
    "start": "1251590",
    "end": "1260030"
  },
  {
    "text": "of distributions that have PDFs\nthat basically have this form. It's similar to what\nwe have up here.",
    "start": "1260030",
    "end": "1267120"
  },
  {
    "text": "It's also an\nexponential of some dot product between a vector\nof parameters theta",
    "start": "1267120",
    "end": "1272930"
  },
  {
    "text": "and a vector of functions of\nsufficient statistics T of x. Not super important but it turns\nout that there is a volume here,",
    "start": "1272930",
    "end": "1281940"
  },
  {
    "text": "which is just,\nagain, the integral of the unnormalized probability.",
    "start": "1281940",
    "end": "1288880"
  },
  {
    "text": "And then if you divide\nby that quantity,",
    "start": "1288880",
    "end": "1294220"
  },
  {
    "text": "you get this family\nof distributions that are called the\nexponential family which",
    "start": "1294220",
    "end": "1300670"
  },
  {
    "text": "captures a lot of known\ncommonly used distributions like normal, Poisson,\nexponential, Bernoulli,",
    "start": "1300670",
    "end": "1307420"
  },
  {
    "text": "and many more. And so this kind\nof setting where",
    "start": "1307420",
    "end": "1316929"
  },
  {
    "text": "you start with a\nnon-negative function and you somehow restrict\nyourself to functional forms that are simple\nenough that you can compute",
    "start": "1316930",
    "end": "1325330"
  },
  {
    "text": "the integrals analytically, they\nare pretty powerful in the sense that these are very\nuseful building blocks,",
    "start": "1325330",
    "end": "1335950"
  },
  {
    "text": "useful in many applications. But you can see that you\ncan't choose an arbitrary g.",
    "start": "1335950",
    "end": "1341950"
  },
  {
    "text": "If you choose some\nreally complicated thing or you plug in a\nneural network, you might not be able to compute\nthat integral analytically.",
    "start": "1341950",
    "end": "1350840"
  },
  {
    "text": "There might not be a closed\nform for that partition function, the theta, or the\ntotal unnormalized probability.",
    "start": "1350840",
    "end": "1358770"
  },
  {
    "text": "And that's where\nenergy-based models come in. How do we go from this kind\nof setting where everything",
    "start": "1358770",
    "end": "1367279"
  },
  {
    "text": "is simple, handcrafted, it\ncan be solved analytically in closed form to something\nmore flexible where we can start",
    "start": "1367280",
    "end": "1373220"
  },
  {
    "text": "to plug in much more\ncomplicated functions here like neural networks\nessentially.",
    "start": "1373220",
    "end": "1380820"
  },
  {
    "text": "And now these simple\nbuilding blocks",
    "start": "1380820",
    "end": "1386370"
  },
  {
    "text": "like Gaussians,\nexponentials, and so forth, they're still pretty\nuseful in the sense that what we've been\ndoing so far, like using",
    "start": "1386370",
    "end": "1395190"
  },
  {
    "text": "autoregressive models or even\nvariational autoencoders, latent variable\nmodels are essentially",
    "start": "1395190",
    "end": "1402470"
  },
  {
    "text": "tricks for composing simple\nfunctions that are normalized by design and building more\ncomplicated probabilistic models",
    "start": "1402470",
    "end": "1411000"
  },
  {
    "text": "that are, again, by\nconstruction, guaranteed to be normalized.",
    "start": "1411000",
    "end": "1416920"
  },
  {
    "text": " But we can see\nthat in some sense,",
    "start": "1416920",
    "end": "1424400"
  },
  {
    "text": "an autoregressive\nmodel is basically just a way of defining\njoint probability",
    "start": "1424400",
    "end": "1432710"
  },
  {
    "text": "distribution or joint\nprobability density function that is normalized\nby design because it's",
    "start": "1432710",
    "end": "1439580"
  },
  {
    "text": "a product of conditionals that\nare normalized, that sort of are",
    "start": "1439580",
    "end": "1444980"
  },
  {
    "text": "Gaussians, or are\nexponentials, or they are the ones for\nwhich we know how to compute these integrals,\nthese partition functions",
    "start": "1444980",
    "end": "1453230"
  },
  {
    "text": "analytically. And so if you imagine you\nhave two of these objects that",
    "start": "1453230",
    "end": "1459450"
  },
  {
    "text": "are guaranteed to be normalized,\nlike a family parameterized",
    "start": "1459450",
    "end": "1466559"
  },
  {
    "text": "by theta and another family here\nthat is parameterized by theta prime, where theta prime can\nbe a function of x as long",
    "start": "1466560",
    "end": "1476400"
  },
  {
    "text": "as, for every theta prime, the\ndistribution that you get over y is normalized, this\nfull object that you",
    "start": "1476400",
    "end": "1483600"
  },
  {
    "text": "get by multiplying them together\nis guaranteed to be normalized. So if you look over--\nif you try to--",
    "start": "1483600",
    "end": "1489570"
  },
  {
    "text": "if you multiply together two\nobjects that are basically, by construction, normalized,\nlike the marginal over x",
    "start": "1489570",
    "end": "1496500"
  },
  {
    "text": "and the conditional over y,\nwhere the parameters depend on x, you get something\nthat is normalized.",
    "start": "1496500",
    "end": "1503610"
  },
  {
    "text": "This is basically what we do\nin an autoregressive model. You define the joint as a\nproduct of conditionals.",
    "start": "1503610",
    "end": "1510100"
  },
  {
    "text": "And if you look at the-- if you look at the integral\nover all possible inputs",
    "start": "1510100",
    "end": "1515530"
  },
  {
    "text": "of the joint, you get\nsomething that is, by design, basically normalized.",
    "start": "1515530",
    "end": "1520930"
  },
  {
    "text": "And the reason is that,\nif the-- by construction, the distribution over\ny is such that it's",
    "start": "1520930",
    "end": "1528970"
  },
  {
    "text": "normalized for any\nchoice of the parameters. And the choice of the parameters\ncan depend on the value",
    "start": "1528970",
    "end": "1535120"
  },
  {
    "text": "that x can take. Then, by design,\nthe integral over y",
    "start": "1535120",
    "end": "1540490"
  },
  {
    "text": "is guaranteed to evaluate to\n1, regardless of the choice that you have for x.",
    "start": "1540490",
    "end": "1546759"
  },
  {
    "text": "And then when you\nintegrate over x, again, that object is normalized. And so you get, once\nagain, something that--",
    "start": "1546760",
    "end": "1554260"
  },
  {
    "text": "where the full\njoint distribution is guaranteed to be normalized\nand to integrate to 1.",
    "start": "1554260",
    "end": "1561520"
  },
  {
    "text": "So the object in\nhere is essentially-- one way of thinking of\nthe conditional of y--",
    "start": "1561520",
    "end": "1569160"
  },
  {
    "text": "the probability over y\nis, let's say, a Gaussian, where the parameters\ndepend on the value of x.",
    "start": "1569160",
    "end": "1578160"
  },
  {
    "text": "This would be one setting\nwhere this would show up if you have an autoregressive\nmodel where, let's say, p of x",
    "start": "1578160",
    "end": "1584790"
  },
  {
    "text": "is a Gaussian. p theta of x is a Gaussian. So here, theta could be the\nmean and the standard deviation.",
    "start": "1584790",
    "end": "1590310"
  },
  {
    "text": "And the distribution\nover the second variable, or the second\ngroup of variables, is, again, a Gaussian, where\nthe parameters of the Gaussian,",
    "start": "1590310",
    "end": "1597480"
  },
  {
    "text": "theta prime, are\nallowed to depend on x. For example, you compute the\nmean and the standard deviation",
    "start": "1597480",
    "end": "1603450"
  },
  {
    "text": "as a function of the previous\nvariable in the ordering. Then you have an object\nthat is guaranteed",
    "start": "1603450",
    "end": "1609419"
  },
  {
    "text": "to be normalized by design. So you can think of\nautoregressive models as a way of combining objects\nthat are normalized, simpler",
    "start": "1609420",
    "end": "1617580"
  },
  {
    "text": "objects, and putting together\na more complicated one, a joint distribution\nthat is, again,",
    "start": "1617580",
    "end": "1623309"
  },
  {
    "text": "guaranteed to be\nnormalized by design, which is the product\nof normalized objects.",
    "start": "1623310",
    "end": "1628770"
  },
  {
    "text": "And then if you slide these\nintegrals in, you can-- all the integrals evaluate to 1.",
    "start": "1628770",
    "end": "1635643"
  },
  {
    "text": "When you integrate\nout the conditionals, they all evaluate to\n1, and the full object is guaranteed to be normalized.",
    "start": "1635643",
    "end": "1642890"
  },
  {
    "text": "And to some extent, even\nlatent variable models can be thought as\na way of, again,",
    "start": "1642890",
    "end": "1649429"
  },
  {
    "text": "combining normalized objects and\nbuilding a more complicated one that is, again, guaranteed\nto be normalized.",
    "start": "1649430",
    "end": "1656250"
  },
  {
    "text": "So if you have two densities,\np theta and p theta prime, that are\nnormalized, and then you",
    "start": "1656250",
    "end": "1662930"
  },
  {
    "text": "take a convex\n[INAUDIBLE] like alpha p plus 1 minus alpha p prime\nfor any choice of alpha,",
    "start": "1662930",
    "end": "1671250"
  },
  {
    "text": "or between 0 and 1, you\nget another density, which",
    "start": "1671250",
    "end": "1676400"
  },
  {
    "text": "is guaranteed to be normalized. Because if you integrate it out,\nagain, you get something that--",
    "start": "1676400",
    "end": "1683924"
  },
  {
    "text": "basically, the first\nintegral evaluates to alpha because p\ntheta is normalized. The second integral\nevaluates to 1 minus alpha",
    "start": "1683925",
    "end": "1690690"
  },
  {
    "text": "because theta prime\nis normalized. So again, you get an\nobject that is normalized. And that's basically\nwhat happens",
    "start": "1690690",
    "end": "1696750"
  },
  {
    "text": "in a variational\nautoencoder, where you have this mixture in behavior.",
    "start": "1696750",
    "end": "1702070"
  },
  {
    "text": "The conditionals that\nyou have in the encoder-- in the decoder are simple\nnormalized objects,",
    "start": "1702070",
    "end": "1708960"
  },
  {
    "text": "like Gaussians. And you're taking\na mixture of them. And by doing that, you\ndefine a marginal, which is,",
    "start": "1708960",
    "end": "1715770"
  },
  {
    "text": "again, normalized\nby construction. ",
    "start": "1715770",
    "end": "1725180"
  },
  {
    "text": "So you can think of what\nwe've been doing, building autoregressive models or latent\nvariable models, as trying to--",
    "start": "1725180",
    "end": "1733430"
  },
  {
    "text": "clever ways of combining\nsimple normalized object and building more\ncomplicated objects that",
    "start": "1733430",
    "end": "1739760"
  },
  {
    "text": "are normalized by design. But this is enforcing\nsome restrictions still, in terms of how complicated\nthe final object is.",
    "start": "1739760",
    "end": "1748020"
  },
  {
    "text": "And you have to\nfollow these rules to construct objects that are\nguaranteed to be normalized.",
    "start": "1748020",
    "end": "1753500"
  },
  {
    "text": "So what energy-based models\ndo is they try to break this",
    "start": "1753500",
    "end": "1758840"
  },
  {
    "text": "constraint and try to\ngo beyond, basically,",
    "start": "1758840",
    "end": "1764059"
  },
  {
    "text": "probability densities or\nprobability mass functions that are guaranteed to be normalized,\nfor which, basically, the--",
    "start": "1764060",
    "end": "1771740"
  },
  {
    "text": "because the normalization\nconstant is known analytically. And instead, we're going to\nbe working with settings where",
    "start": "1771740",
    "end": "1780270"
  },
  {
    "text": "this product\nnormalization constant, this partition function\nZ theta, is something",
    "start": "1780270",
    "end": "1786570"
  },
  {
    "text": "that we'll have to\nmaybe deal with, that either we're not going\nto be able to compute it, or we're going to\napproximate it.",
    "start": "1786570",
    "end": "1793078"
  },
  {
    "text": "But it's not going to be able-- it's not going to be\nsomething that is known. Say value 1 for\nany choice of theta",
    "start": "1793078",
    "end": "1799200"
  },
  {
    "text": "is going to change as\na function of theta in some complicated way. And we're just going to have\nto basically deal with it.",
    "start": "1799200",
    "end": "1806705"
  },
  {
    "text": "And so, specifically,\nwe're going to be looking at models\nof this form, where we have a probability density\nfunction over x, which",
    "start": "1806705",
    "end": "1814830"
  },
  {
    "text": "is parameterized by\ntheta and is defined as the exponential of\nf theta, because we",
    "start": "1814830",
    "end": "1820889"
  },
  {
    "text": "need to make sure that the\nfunction is non-negative. So this is the\nunnormalized probability,",
    "start": "1820890",
    "end": "1827789"
  },
  {
    "text": "the exponential of f theta. And then we divide by\nthe partition function to get an object that\nis actually normalized.",
    "start": "1827790",
    "end": "1835510"
  },
  {
    "text": "And so you can start with\nan arbitrary, basically, neural network, f theta.",
    "start": "1835510",
    "end": "1841380"
  },
  {
    "text": "You take the exponential. You get a non-negative function. And then you define a valid\nprobability density function",
    "start": "1841380",
    "end": "1848520"
  },
  {
    "text": "by dividing by this\npartition function by this normalization\nconstant, which is just the integral,\nbasically, of this unnormalized",
    "start": "1848520",
    "end": "1855780"
  },
  {
    "text": "probability. And so that's all, basically.",
    "start": "1855780",
    "end": "1861980"
  },
  {
    "text": "That's the definition of\nan energy-based model. It's very flexible because\nyou can choose, essentially,",
    "start": "1861980",
    "end": "1869210"
  },
  {
    "text": "an arbitrary function, f theta. And that defines a valid\nprobability density function.",
    "start": "1869210",
    "end": "1877789"
  },
  {
    "text": "We chose specifically the\nexponential here instead of, let's say, squaring f\ntheta for several reasons.",
    "start": "1877790",
    "end": "1887510"
  },
  {
    "text": "The first one is that it allows\nus to capture pretty nicely, pretty easily, big variations in\nthe probability that the model",
    "start": "1887510",
    "end": "1896149"
  },
  {
    "text": "assigns to different x's. So if you're thinking about\nmodeling images or even text,",
    "start": "1896150",
    "end": "1901370"
  },
  {
    "text": "to some extent, you might\nexpect very big variations in the probabilities that\nthe model assigns to,",
    "start": "1901370",
    "end": "1907610"
  },
  {
    "text": "let's say, well-formed images\nas opposed to pure noise.",
    "start": "1907610",
    "end": "1913010"
  },
  {
    "text": "So it makes it easier to\nmodel these big variations in the probability if you\ntake an exponential here",
    "start": "1913010",
    "end": "1921879"
  },
  {
    "text": "because small\nchanges in f theta, which is what your\nneural network does, will lead to big changes in\nthe actual probabilities that",
    "start": "1921880",
    "end": "1929460"
  },
  {
    "text": "are assigned by the model. You could also do it with-- just take a square here.",
    "start": "1929460",
    "end": "1936960"
  },
  {
    "text": "But then that would\nrequire bigger changes in the outputs of\nthe neural network.",
    "start": "1936960",
    "end": "1942190"
  },
  {
    "text": "So it's going to be\nmuch less smooth. What is an energy\nby definition is? ",
    "start": "1942190",
    "end": "1948280"
  },
  {
    "text": "Yeah. So that will come up\nin the next bullet. Yeah. Yeah?",
    "start": "1948280",
    "end": "1953730"
  },
  {
    "text": "Is this not softmax? Softmax is an example of that. Yeah. That's a good point.",
    "start": "1953730",
    "end": "1960280"
  },
  {
    "text": "Yeah. A softmax is one way of\ndoing this and, essentially,",
    "start": "1960280",
    "end": "1965730"
  },
  {
    "text": "mapping the output\nof a neural network, which is not necessarily\na valid probability--",
    "start": "1965730",
    "end": "1971769"
  },
  {
    "text": "a valid categorical\ndistribution over, let's say, the outputs that\nyou're trying to-- [INAUDIBLE] is that-- because\nyou mentioned latent variable",
    "start": "1971770",
    "end": "1980840"
  },
  {
    "text": "earlier. But in, say, our\nVAE, we use softmax to compute the\nreconstruction likelihood.",
    "start": "1980840",
    "end": "1987080"
  },
  {
    "text": "So how is that a different--\nhow is that not an energy-based model that-- So \"energy-based model\"\nis a very general term,",
    "start": "1987080",
    "end": "1996260"
  },
  {
    "text": "in the sense that-- you could even think of\nan autoregressive model",
    "start": "1996260",
    "end": "2001810"
  },
  {
    "text": "as being a type of\nenergy-based model, where, by construction, Z theta\nis always guaranteed to be 1.",
    "start": "2001810",
    "end": "2011110"
  },
  {
    "text": "So this is just a very\ngeneral type of model,",
    "start": "2011110",
    "end": "2016960"
  },
  {
    "text": "where we're going\nto be able to take an arbitrary neural\nnetwork, let's say f theta,",
    "start": "2016960",
    "end": "2022030"
  },
  {
    "text": "and get a valid probability\ndensity function from it. It's not how to\nrefer new concepts?",
    "start": "2022030",
    "end": "2027040"
  },
  {
    "text": "It's not mutually exclusive? It's more general because\nit doesn't have to be-- Z theta doesn't have\nto be exactly 1,",
    "start": "2027040",
    "end": "2033880"
  },
  {
    "text": "and it doesn't have to be,\nlike in the Gaussian case, some unknown.",
    "start": "2033880",
    "end": "2040840"
  },
  {
    "text": "Z theta might not be something\nthat is known analytically, so you might not be able\nto know that the integral--",
    "start": "2040840",
    "end": "2046660"
  },
  {
    "text": "that this integral evaluates to\nthe square root of 2 pi sigma squared. Because that only happens\nwhen f theta is very simple.",
    "start": "2046660",
    "end": "2056290"
  },
  {
    "text": "If f theta is x\nminus mu squared, then you've get a Gaussian.",
    "start": "2056290",
    "end": "2061794"
  },
  {
    "text": "And then you know how to compute\nthat integral analytically. But in general,\nyou don't have to. So the output for-- in\nthe latent variable,",
    "start": "2061795",
    "end": "2068980"
  },
  {
    "text": "the formula you showed\nin the previous slide-- so is-- that just shows the\nprobability of a mixture",
    "start": "2068980",
    "end": "2075638"
  },
  {
    "text": "of Gaussian prior or something? Yeah. It's basically-- if you're\nthinking about the problem more",
    "start": "2075639",
    "end": "2081369"
  },
  {
    "text": "abstractly, as saying,\nhow do I come up with a way of designing\nfunctions that are non-negative,",
    "start": "2081370",
    "end": "2089888"
  },
  {
    "text": "and they are guaranteed to\nhave some fixed integral? How would you go about it?",
    "start": "2089889",
    "end": "2095710"
  },
  {
    "text": "One way is to define\na set of rules, almost like an algebra, where\nyou can start from objects that",
    "start": "2095710",
    "end": "2102859"
  },
  {
    "text": "have the properties you want. And you can combine\nthem to construct more complicated\nobjects that, again,",
    "start": "2102860",
    "end": "2108800"
  },
  {
    "text": "have the properties you want. And one way to do it is\nwhat I was showing here, is you can take\nlinear combinations",
    "start": "2108800",
    "end": "2117320"
  },
  {
    "text": "of these objects, convex\ncombinations of these objects. And that's one way of\ndefining a new object that",
    "start": "2117320",
    "end": "2123589"
  },
  {
    "text": "still has the\nproperties you want, in terms of simpler objects. But which part in this function\nrepresents the latent variables?",
    "start": "2123590",
    "end": "2133339"
  },
  {
    "text": "The latent variable would\nbasically be the alphas. The alphas are the\nprobabilities that the latent--",
    "start": "2133340",
    "end": "2141620"
  },
  {
    "text": "basically, this would correspond\nto a latent variable model. But there is a single\nlatent variable,",
    "start": "2141620",
    "end": "2146940"
  },
  {
    "text": "which is-- can only take\ntwo different values. And it takes value-- the first value with\nprobability alpha.",
    "start": "2146940",
    "end": "2153380"
  },
  {
    "text": "The second value with\nprobability 1 minus alpha. And so that gives you\nthat sort of behavior.",
    "start": "2153380",
    "end": "2160990"
  },
  {
    "text": "Thank you. But I think what you were\nsaying about the softmax is another good example\nof, essentially,",
    "start": "2160990",
    "end": "2167550"
  },
  {
    "text": "an energy-based model. Softmax is a way of defining--",
    "start": "2167550",
    "end": "2173631"
  },
  {
    "text": "it essentially has-- if you\nthink about a softmax layer, it has exactly this\nkind of structure.",
    "start": "2173631",
    "end": "2181060"
  },
  {
    "text": "And it is, in fact, a way\nof defining a probability distribution over a set of--\nover a categorical, basically,",
    "start": "2181060",
    "end": "2188220"
  },
  {
    "text": "random variable, which is\nthe predicted label in terms of a function f\ntheta, which is just",
    "start": "2188220",
    "end": "2194970"
  },
  {
    "text": "the raw outputs of your neural\nnetwork, which might not be necessarily normalized.",
    "start": "2194970",
    "end": "2200130"
  },
  {
    "text": "So the softmax is exactly\nthis kind of thing. But the softmax is a case\nwhere this partition function,",
    "start": "2200130",
    "end": "2206580"
  },
  {
    "text": "this normalization constant,\ncan be computed analytically because you only have, let's\nsay, k different classes.",
    "start": "2206580",
    "end": "2212700"
  },
  {
    "text": "So the softmax will involve-- in the denominator\nof the softmax, you have a sum over k\ndifferent possible outputs.",
    "start": "2212700",
    "end": "2221060"
  },
  {
    "text": "And so in that case, this-- yeah, this\nnormalization constant can actually be\ncomputed exactly.",
    "start": "2221060",
    "end": "2227320"
  },
  {
    "text": "We're going to be interested in\nsettings where x, this integral,",
    "start": "2227320",
    "end": "2234940"
  },
  {
    "text": "is going to be very difficult\nto compute exactly because x",
    "start": "2234940",
    "end": "2241450"
  },
  {
    "text": "is very high-dimensional. So there is many\ndifferent-- if you think about a\ndistribution over images,",
    "start": "2241450",
    "end": "2247990"
  },
  {
    "text": "x can take on an\nexponentially large number",
    "start": "2247990",
    "end": "2253030"
  },
  {
    "text": "of different values. So if you have to integrate\nover all possible images,",
    "start": "2253030",
    "end": "2258340"
  },
  {
    "text": "that's going to be a very\nexpensive computation, practically\nimpossible to compute. So that's the difference between\nthe softmax style computation",
    "start": "2258340",
    "end": "2266607"
  },
  {
    "text": "and what we're doing here.  Cool.",
    "start": "2266607",
    "end": "2272100"
  },
  {
    "text": "And so-- yeah. Why do we use exponential? Because we want to\ncapture big variation.",
    "start": "2272100",
    "end": "2278280"
  },
  {
    "text": "The other reason is\nthat, as we've seen, many common distributions\nlike the Gaussian,",
    "start": "2278280",
    "end": "2283950"
  },
  {
    "text": "and the exponential, and all the\nones in the exponential family-- they have this functional form.",
    "start": "2283950",
    "end": "2289410"
  },
  {
    "text": "They have this flavor of\nsomething exponential-- of some simple function in the\nargument of the exponential.",
    "start": "2289410",
    "end": "2296340"
  },
  {
    "text": "And the reason these\ndistributions are so common is that they actually\narise under fairly general",
    "start": "2296340",
    "end": "2302910"
  },
  {
    "text": "assumptions. ",
    "start": "2302910",
    "end": "2309891"
  },
  {
    "text": "If you know about maximum\nentropy modeling assumptions,",
    "start": "2309891",
    "end": "2315750"
  },
  {
    "text": "which is basically this\nidea of trying to come up with a distribution that,\nin some sense, fits the data",
    "start": "2315750",
    "end": "2322620"
  },
  {
    "text": "but minimizes all the other\nassumptions that you make about the model,\nthen it turns out that the solution to that\nkind of modeling problem",
    "start": "2322620",
    "end": "2329859"
  },
  {
    "text": "has the form of an\nexponential family. So that's why they are\ncalled energy-based models,",
    "start": "2329860",
    "end": "2337720"
  },
  {
    "text": "because this also shows\nup a lot in physics. Think about the second\nlaw of thermodynamics.",
    "start": "2337720",
    "end": "2342789"
  },
  {
    "text": "And in that case, minus f\nof x is called the energy.",
    "start": "2342790",
    "end": "2349720"
  },
  {
    "text": "And there is a minus because-- if you think about\nphysics, configurations",
    "start": "2349720",
    "end": "2354790"
  },
  {
    "text": "where you can imagine x are the\npossible states that the system can be in, states that have\nlower energy, so high f theta,",
    "start": "2354790",
    "end": "2363910"
  },
  {
    "text": "should be more likely. So that's why there\nis the minus sign. But that's why they are\ncalled energy-based models,",
    "start": "2363910",
    "end": "2370750"
  },
  {
    "text": "because they are inspired\nby statistical physics, essentially. ",
    "start": "2370750",
    "end": "2380589"
  },
  {
    "text": "Cool. So that's the basic paradigm\nof an energy-based model.",
    "start": "2380590",
    "end": "2387550"
  },
  {
    "text": "You start with an essentially\narbitrary neural network,",
    "start": "2387550",
    "end": "2394150"
  },
  {
    "text": "f theta. You take an exponential\nto make it non-negative. And then you divide by this\nnormalization constant,",
    "start": "2394150",
    "end": "2401650"
  },
  {
    "text": "this partition\nfunction, which is just the integral of this\nunnormalized probability.",
    "start": "2401650",
    "end": "2407410"
  },
  {
    "text": "And this, for any\nchoice of theta, defines a valid\nprobabilistic model.",
    "start": "2407410",
    "end": "2414069"
  },
  {
    "text": "So it's guaranteed\nto be non-negative. It's guaranteed to sum to 1.",
    "start": "2414070",
    "end": "2419140"
  },
  {
    "text": "And so from the point of\nview of the flexibility, this is basically\nas good as it gets.",
    "start": "2419140",
    "end": "2425590"
  },
  {
    "text": "There is no restriction,\nessentially, on the f thetas\nthat you can choose,",
    "start": "2425590",
    "end": "2430750"
  },
  {
    "text": "which means that you can\nplug in whatever architecture you want to model the data.",
    "start": "2430750",
    "end": "2436030"
  },
  {
    "text": "The cons are-- there\nis many, as usual. There is usually\nsome price to pay. If you want flexibility,\nyou're basically",
    "start": "2436030",
    "end": "2443089"
  },
  {
    "text": "making less assumptions about\nthe structure of your model. And so there is a price\nto pay, computationally.",
    "start": "2443090",
    "end": "2448650"
  },
  {
    "text": "And one big negative aspect\nof energy-based models",
    "start": "2448650",
    "end": "2455329"
  },
  {
    "text": "is that sampling is\ngoing to be very hard. So even if you\ncan fit the model, if you want to generate\nsamples from it,",
    "start": "2455330",
    "end": "2461630"
  },
  {
    "text": "it's going to be very\ntricky to do that. So it's going to be very\nslow to generate new samples",
    "start": "2461630",
    "end": "2467690"
  },
  {
    "text": "from an energy-based model. And the reason is\nthat, basically,",
    "start": "2467690",
    "end": "2473540"
  },
  {
    "text": "evaluating probabilities\nis also hard. Because if you want to evaluate\nthe probability of a data point,",
    "start": "2473540",
    "end": "2480440"
  },
  {
    "text": "you basically-- it's easy to get the\nunnormalized piece, this exponential of f theta.",
    "start": "2480440",
    "end": "2485944"
  },
  {
    "text": "You just feed it through\nyour neural network. You get a number that gives\nyou the normalized probability. But somehow, to actually\nevaluate a probability,",
    "start": "2485945",
    "end": "2493370"
  },
  {
    "text": "you have to divide by this\nnormalization constant, which is, in general, very\nexpensive to compute, and--",
    "start": "2493370",
    "end": "2501170"
  },
  {
    "text": "which hints at why,\nalso, sampling is hard. If you don't even know how\nto evaluate probabilities",
    "start": "2501170",
    "end": "2507980"
  },
  {
    "text": "of data points\nefficiently, it's going to be pretty tricky to\nfigure out how to generate--",
    "start": "2507980",
    "end": "2513130"
  },
  {
    "text": "know how to pick an x with-- which are the right probability. Even evaluating the probability\nof a data point is hard.",
    "start": "2513130",
    "end": "2520340"
  },
  {
    "text": "So why is sampling hard for\nthis energy-based model, since we have already--",
    "start": "2520340",
    "end": "2526700"
  },
  {
    "text": "since we could learn\na form of [INAUDIBLE]?? If we could learn?",
    "start": "2526700",
    "end": "2531890"
  },
  {
    "text": "If we could already learn\na form of p theta of x.",
    "start": "2531890",
    "end": "2537359"
  },
  {
    "text": "Yeah. So sampling is hard. Even if somebody gives you\nthe p theta, the function,",
    "start": "2537360",
    "end": "2543140"
  },
  {
    "text": "it tells you, OK,\nhere's the model. Basically, the problem\nis that sampling is hard",
    "start": "2543140",
    "end": "2549740"
  },
  {
    "text": "because, first of all,\nthere is no order. If you think about an\nautoregressive model, there is no ordering.",
    "start": "2549740",
    "end": "2556040"
  },
  {
    "text": "So the only thing\nyou can do is-- as we'll see,\nthere's going to be some kind of\nlocal-type procedure,",
    "start": "2556040",
    "end": "2562030"
  },
  {
    "text": "where you can try to\nuse, essentially, Markov chain/Monte Carlo\nmethods to try to go",
    "start": "2562030",
    "end": "2567310"
  },
  {
    "text": "look for x's that are likely,\nessentially, under the Model. But even evaluating\nlikelihoods is not possible.",
    "start": "2567310",
    "end": "2575930"
  },
  {
    "text": "It's hard because that requires\nthe normalization constant. And so, in general,\nthere's not going",
    "start": "2575930",
    "end": "2581350"
  },
  {
    "text": "to be an efficient way\nof generating samples from these kind of models. So when you said the input\nx has no order with--",
    "start": "2581350",
    "end": "2591350"
  },
  {
    "text": "Yeah. So you can imagine-- yeah,\nthere is no ordering. x is just a vector.",
    "start": "2591350",
    "end": "2596859"
  },
  {
    "text": "It's your data, and you just\nfeed it into a neural network. And then you get a number that\nis the unnormalized probability.",
    "start": "2596860",
    "end": "2604690"
  },
  {
    "text": "But that doesn't\ntell you how likely that data point\nis until you know how likely everything else is.",
    "start": "2604690",
    "end": "2610760"
  },
  {
    "text": "So you need to know the\nnormalizing constant, the partition\nfunction, to know-- even just to know how\nlikely a data point is.",
    "start": "2610760",
    "end": "2618440"
  },
  {
    "text": "And so, as you can imagine,\neven figuring out if you were to sample from a\ndistribution like that--",
    "start": "2618440",
    "end": "2623990"
  },
  {
    "text": "it's pretty difficult\nbecause you cannot even--",
    "start": "2623990",
    "end": "2629570"
  },
  {
    "text": "if you wanted to even\njust invert the CDF thing, that would require you to be\nable to evaluate probabilities.",
    "start": "2629570",
    "end": "2635910"
  },
  {
    "text": "And so it's just a very\ntricky thing to do. ",
    "start": "2635910",
    "end": "2642740"
  },
  {
    "text": "Yeah? So I guess the cons-- really, they nullify\nthe [INAUDIBLE],, right?",
    "start": "2642740",
    "end": "2650450"
  },
  {
    "text": "Yeah, as we'll see. ",
    "start": "2650450",
    "end": "2656120"
  },
  {
    "text": "It's hard, but possible. And, in fact, if you\nabout a diffusion model, it's essentially doing this.",
    "start": "2656120",
    "end": "2663450"
  },
  {
    "text": "So it's not going to be as\nstraightforward as the sampling",
    "start": "2663450",
    "end": "2668510"
  },
  {
    "text": "from a bunch of conditionals\nlike in autoregressive models. We're going to have to do more\nwork to sample from the model.",
    "start": "2668510",
    "end": "2675480"
  },
  {
    "text": "Evaluating\nprobabilities will also require some approximations\nor some other techniques that",
    "start": "2675480",
    "end": "2681180"
  },
  {
    "text": "are much more sophisticated. But yeah, this idea of being\nable to essentially use",
    "start": "2681180",
    "end": "2688650"
  },
  {
    "text": "an energy-based model and be\nable to use whatever arbitrary architectures to model your data\nactually paid off in a big time,",
    "start": "2688650",
    "end": "2697180"
  },
  {
    "text": "if you think about the success\nof diffusion model, which I think largely\ndepends on the fact",
    "start": "2697180",
    "end": "2703290"
  },
  {
    "text": "that we're allowed to use very\ncomplicated neural networks to model the data.",
    "start": "2703290",
    "end": "2709025"
  },
  {
    "text": " And yeah, there\nis also no feature",
    "start": "2709025",
    "end": "2714490"
  },
  {
    "text": "learning, in the sense that-- at least in this\nvanilla formulation, there is no latent variables.",
    "start": "2714490",
    "end": "2719860"
  },
  {
    "text": "But, I guess, that you can add. So it's not really a\nbig con in this case.",
    "start": "2719860",
    "end": "2725650"
  },
  {
    "text": "And the fundamental issue-- the\nreason why all these tasks are",
    "start": "2725650",
    "end": "2731230"
  },
  {
    "text": "so hard is the curse of\ndimensionality, which basically,",
    "start": "2731230",
    "end": "2736270"
  },
  {
    "text": "in this case, means that-- because we want to have\nvery-- a lot of flexibility",
    "start": "2736270",
    "end": "2741970"
  },
  {
    "text": "in choosing f theta,\nwe're not going to be able to compute these\nintegrals analytically.",
    "start": "2741970",
    "end": "2748279"
  },
  {
    "text": "It's not like the Gaussian case. So we're not going to be able\nto compute that in closed form. And if you wanted to basically\nbrute force it or use",
    "start": "2748280",
    "end": "2755830"
  },
  {
    "text": "numerical methods to try to\napproximate the integral,",
    "start": "2755830",
    "end": "2760990"
  },
  {
    "text": "the cost that you pay will\nbasically scale exponentially in the number of variables\nthat you're trying to model.",
    "start": "2760990",
    "end": "2768609"
  },
  {
    "text": "And essentially, if you think\nabout the discrete case,",
    "start": "2768610",
    "end": "2774400"
  },
  {
    "text": "there is-- the number of possible x's\nthat you would have to sum over",
    "start": "2774400",
    "end": "2780580"
  },
  {
    "text": "grows combinatorially\nin the number of-- grows exponentially in\nthe number of dimensions",
    "start": "2780580",
    "end": "2786010"
  },
  {
    "text": "that you have. And essentially, the\nsame thing happens also in the continuous world. If you were to discretize and\nhave little units of volume",
    "start": "2786010",
    "end": "2795970"
  },
  {
    "text": "that you use to cover\nthe whole space, the number of little units\nof volume that you need will grow exponentially in\nthe number of dimensions",
    "start": "2795970",
    "end": "2803410"
  },
  {
    "text": "that you deal with. And so that's essentially\nthe key challenge",
    "start": "2803410",
    "end": "2810490"
  },
  {
    "text": "of this energy-based model. Computing this denominator\nis going to be hard. So on the one hand, we're\ngoing to get flexibility.",
    "start": "2810490",
    "end": "2818180"
  },
  {
    "text": "On the other hand, there is this\nbig computational bottleneck that we have to deal with the\npartition function, basically.",
    "start": "2818180",
    "end": "2826520"
  },
  {
    "text": "And the good news\nis that there is a bunch of tasks that do not\nrequire knowing the partition",
    "start": "2826520",
    "end": "2833540"
  },
  {
    "text": "function. For example, if all you\nhave to do is to compare--",
    "start": "2833540",
    "end": "2841560"
  },
  {
    "text": "you have two data\npoints, x and x prime. And all you have to do is to\nknow which one is more likely.",
    "start": "2841560",
    "end": "2848589"
  },
  {
    "text": "So you just want to do a\nrelative comparison between two data points.",
    "start": "2848590",
    "end": "2853640"
  },
  {
    "text": "So you cannot necessarily-- even though you might\nnot be able to evaluate the probability of x\nand the probability of x",
    "start": "2853640",
    "end": "2860740"
  },
  {
    "text": "prime under this model, because\nthat would require knowing the partition function-- if you think about what happens\nif you take the ratios of two",
    "start": "2860740",
    "end": "2868150"
  },
  {
    "text": "probabilities, that\ndoes not depend on the normalization constant.",
    "start": "2868150",
    "end": "2873455"
  },
  {
    "text": "But if you take the\nratio, both the numerator and the denominator--\nthey are both",
    "start": "2873455",
    "end": "2879500"
  },
  {
    "text": "normalized by the same constant. And so that basically goes away.",
    "start": "2879500",
    "end": "2884640"
  },
  {
    "text": "If you think about\nthe slices of pie-- if you're trying to just\nlook at the relative size,",
    "start": "2884640",
    "end": "2891900"
  },
  {
    "text": "you can do that easily without\nknowing the actual size of the pie, and--",
    "start": "2891900",
    "end": "2899950"
  },
  {
    "text": "which means that we can check. Given two data points,\nwe can check which one is more likely very easily.",
    "start": "2899950",
    "end": "2905830"
  },
  {
    "text": "Even though we cannot\nknow how likely it is, we can check which one is\nmore likely between the two.",
    "start": "2905830",
    "end": "2910869"
  },
  {
    "text": "And this is going to\nbe quite useful when we design sampling procedures.",
    "start": "2910870",
    "end": "2917430"
  },
  {
    "text": "And you can still use it to do\nthings like anomaly detection.",
    "start": "2917430",
    "end": "2922800"
  },
  {
    "text": "Denoising, as we'll see when\nwe talk about diffusion models, also relies on this.",
    "start": "2922800",
    "end": "2929260"
  },
  {
    "text": "And in fact, people have been\nusing energy-based models for a long time,\neven for a variety",
    "start": "2929260",
    "end": "2936579"
  },
  {
    "text": "of different basic\ndiscriminative tasks.",
    "start": "2936580",
    "end": "2941950"
  },
  {
    "text": "If you think about\nobject recognition-- if you have some kind\nof energy function",
    "start": "2941950",
    "end": "2947980"
  },
  {
    "text": "that relates the label\ny to the image x, then--",
    "start": "2947980",
    "end": "2953590"
  },
  {
    "text": "and you're trying to figure out\nwhat is the most likely label, then as long as you can compare\nthe labels between them,",
    "start": "2953590",
    "end": "2959800"
  },
  {
    "text": "then you can basically\nsolve object recognition. And these kind of\nenergy-based models",
    "start": "2959800",
    "end": "2966730"
  },
  {
    "text": "have been used to do\nsequence labeling, to do image restorations. As long as the application\nrequires relative comparisons,",
    "start": "2966730",
    "end": "2974349"
  },
  {
    "text": "the partition function\nis not needed. And as an example, we can\nthink about the problem",
    "start": "2974350",
    "end": "2981210"
  },
  {
    "text": "of doing denoising. And this is an\nold-school approach to denoising, where we have\na probabilistic model that",
    "start": "2981210",
    "end": "2989010"
  },
  {
    "text": "involves two groups\nof variables. We have the-- a true\nimage y that is unknown.",
    "start": "2989010",
    "end": "2995740"
  },
  {
    "text": "And then we have a\ncorrupted image x, which we get to observe. And the goal is to infer\nthe clean image given",
    "start": "2995740",
    "end": "3002480"
  },
  {
    "text": "the corrupted image. And one way to do it is to\nhave a joint probability",
    "start": "3002480",
    "end": "3008059"
  },
  {
    "text": "distribution, which is going\nto be an energy-based model. And so we're saying that\nthe probability of observing",
    "start": "3008060",
    "end": "3015890"
  },
  {
    "text": "a clean image y and a\ncorresponding noisy image x",
    "start": "3015890",
    "end": "3021200"
  },
  {
    "text": "has this functional\nform, where there is the normalization\nconstant, and then it's the exponential of some\nrelatively simple function,",
    "start": "3021200",
    "end": "3029900"
  },
  {
    "text": "which is the energy, or the\nnegative energy in this case. And this function is basically\nsaying something like--",
    "start": "3029900",
    "end": "3037109"
  },
  {
    "text": "there is some relationship\nbetween the i-th corrupted pixel and the i-th clean pixel.",
    "start": "3037110",
    "end": "3043900"
  },
  {
    "text": "For example, they should\nbe fairly similar. So whenever you\nplug in xi and yi,",
    "start": "3043900",
    "end": "3050700"
  },
  {
    "text": "configurations where\nxi is similar to yi should be more likely because\nwe expect the corrupted pixel",
    "start": "3050700",
    "end": "3057570"
  },
  {
    "text": "to be more likely to be\nsimilar to the clean pixel than to be very\ndifferent from it. And then maybe\nyou have some kind",
    "start": "3057570",
    "end": "3063900"
  },
  {
    "text": "of prior where the image is\nthat is saying what kind of-- what choices of y are\nmore likely a priori.",
    "start": "3063900",
    "end": "3070790"
  },
  {
    "text": "And maybe you have some kind\nof prior that is saying, neighboring pixels tend\nto have a similar value.",
    "start": "3070790",
    "end": "3080050"
  },
  {
    "text": "Then you sum up all\nthese interaction terms, one per pixel. And then maybe you have a bunch\nof spatial, local interactions",
    "start": "3080050",
    "end": "3087100"
  },
  {
    "text": "between pixels that are close\nto each other in the image, and that defines\nan energy function.",
    "start": "3087100",
    "end": "3092740"
  },
  {
    "text": "And if you want\nto do denoising-- if you want to compute given an\nx-- if you want to figure out",
    "start": "3092740",
    "end": "3099580"
  },
  {
    "text": "what is the corresponding\ny, what you would do is you would try to find a y\nthat maximizes p of y given x.",
    "start": "3099580",
    "end": "3107290"
  },
  {
    "text": "And even though p,\nthe probability, depends on the\nnormalization constant,",
    "start": "3107290",
    "end": "3113829"
  },
  {
    "text": "basically, you can see that the\nnormalization constant doesn't matter.",
    "start": "3113830",
    "end": "3119800"
  },
  {
    "text": "So as long as you want to find\nthe most likely solution--",
    "start": "3119800",
    "end": "3126220"
  },
  {
    "text": "what is the actual probability? So what is the-- 1 over z just becomes\na scaling factor.",
    "start": "3126220",
    "end": "3132230"
  },
  {
    "text": "And it doesn't actually affect\nthe solution of the optimization problem. [INAUDIBLE]?",
    "start": "3132230",
    "end": "3139150"
  },
  {
    "text": "Why is dimensionality\nkind of large? But in real images [INAUDIBLE]. So it might be still tricky\nto solve the optimization",
    "start": "3139150",
    "end": "3145850"
  },
  {
    "text": "problem in that you're\nstill optimizing on a very large space. But at least it\ndoes not depend--",
    "start": "3145850",
    "end": "3153140"
  },
  {
    "text": "as long as you're maximizing\nthe actual value-- basically, all the y's are going\nto be divided by the same z.",
    "start": "3153140",
    "end": "3160250"
  },
  {
    "text": "So again, it doesn't\nmatter as long as you can-- you're going to be\nable to compare to y's.",
    "start": "3160250",
    "end": "3165410"
  },
  {
    "text": "And that's all you need\nif you're trying to-- [INAUDIBLE] So x will show up in the energy.",
    "start": "3165410",
    "end": "3171843"
  },
  {
    "text": "But again, x is fixed. So we don't have to\nsum over [INAUDIBLE]?? Yeah, exactly. Exactly. So it's really all about--",
    "start": "3171843",
    "end": "3178130"
  },
  {
    "text": "there are a bunch of tasks. Well, basically, what you care\nabout is doing comparisons. And to the extent that the\ntask only involves comparisons,",
    "start": "3178130",
    "end": "3186530"
  },
  {
    "text": "then you don't actually need\nto know the partition function. You may still need to have\nthe partition function if you",
    "start": "3186530",
    "end": "3192290"
  },
  {
    "text": "want to train the models. That's what's going\nto come up next. But at least doing\ncomparison is something",
    "start": "3192290",
    "end": "3199910"
  },
  {
    "text": "you can do without knowing\nthe partition function. Yeah. For comparison case,\nwe end up getting away",
    "start": "3199910",
    "end": "3207170"
  },
  {
    "text": "with knowing z value. I also observe that if we take\nthe derivative of the energy",
    "start": "3207170",
    "end": "3214520"
  },
  {
    "text": "functions, then\nit also goes away. Yeah. Will that have\nsome implications? Yeah. So that's going to\ncome up towards the--",
    "start": "3214520",
    "end": "3221420"
  },
  {
    "text": "some of the last slides. That's another nice thing,\nis that the derivative also does not depend-- the derivative\nof the log probability",
    "start": "3221420",
    "end": "3227342"
  },
  {
    "text": "does not depend on the\nnormalization constant. So we're going to be able to\nuse it to define, basically,",
    "start": "3227342",
    "end": "3234410"
  },
  {
    "text": "sampling schemes. Yeah. ",
    "start": "3234410",
    "end": "3239990"
  },
  {
    "text": "Cool. Now, another thing you can do is\nyou can combine various models.",
    "start": "3239990",
    "end": "3245540"
  },
  {
    "text": "So let's say that you have a\nbunch of probabilistic models.",
    "start": "3245540",
    "end": "3251820"
  },
  {
    "text": "For example, it could be\ndifferent model families, maybe a PixelCNN, a\nFlow model, whatnot.",
    "start": "3251820",
    "end": "3258720"
  },
  {
    "text": "You could imagine\nthat each one of them is an expert that will\nindividually tell you",
    "start": "3258720",
    "end": "3265970"
  },
  {
    "text": "how likely is a\ngiven x according to each one of\nthese three models.",
    "start": "3265970",
    "end": "3271850"
  },
  {
    "text": "And you could imagine\nwhat happens if you try to ensemble these experts.",
    "start": "3271850",
    "end": "3277850"
  },
  {
    "text": "And, for example, you could\nsay, if all these experts are making judgments\nindependently,",
    "start": "3277850",
    "end": "3283820"
  },
  {
    "text": "it might make sense to ensemble\nthem by taking a product.",
    "start": "3283820",
    "end": "3290550"
  },
  {
    "text": "And the product of\nthese objects that are normalized by themselves\nis not going to be normalized.",
    "start": "3290550",
    "end": "3298740"
  },
  {
    "text": "But we can define\na normalized object by dividing by this\nnormalization constant.",
    "start": "3298740",
    "end": "3305990"
  },
  {
    "text": "And intuitively, this\nway of ensembling behaves like an end operator,\nwhere, as long as one",
    "start": "3305990",
    "end": "3314090"
  },
  {
    "text": "of the models assigns\n0 probability, then the product evaluates to 0.",
    "start": "3314090",
    "end": "3319980"
  },
  {
    "text": "And this ensemble model\nwill assign a 0 probability. While if you think\nabout the mixture model,",
    "start": "3319980",
    "end": "3326480"
  },
  {
    "text": "where you would say alpha p\ntheta 1 plus 1 minus alpha p theta 2, that behaves more like\nan OR, where you're saying,",
    "start": "3326480",
    "end": "3335270"
  },
  {
    "text": "as long as one of the models\nassigns some probability, then the ensemble model will\nalso assign some probability.",
    "start": "3335270",
    "end": "3343250"
  },
  {
    "text": "Taking a product behaves\nmore like an AND. But it's much trickier\nto deal with because you",
    "start": "3343250",
    "end": "3350240"
  },
  {
    "text": "have to take into account\nthe partition function. But this allows you to\ncombine energy-based models",
    "start": "3350240",
    "end": "3358160"
  },
  {
    "text": "and combine models in\nan interesting way. You can have a model that is--",
    "start": "3358160",
    "end": "3366950"
  },
  {
    "text": "produces young people. And then you have a model\nthat produces females.",
    "start": "3366950",
    "end": "3373130"
  },
  {
    "text": "And then you can combine them\nby multiplying them together. And then you get a model that is\nputting most of the probability",
    "start": "3373130",
    "end": "3378740"
  },
  {
    "text": "mass on the intersection\nof these two groups. And you can get that\nkind of behavior.",
    "start": "3378740",
    "end": "3384090"
  },
  {
    "text": "So you can combine concepts. As long as the different models\nhave learned different things by ensembling them this\nway, you can combine them",
    "start": "3384090",
    "end": "3392270"
  },
  {
    "text": "in interesting ways. ",
    "start": "3392270",
    "end": "3397369"
  },
  {
    "text": "Another example-- yeah? [INAUDIBLE] between\nproduct and mixture?",
    "start": "3397370",
    "end": "3404240"
  },
  {
    "text": "If we use mixture, then\nthis will look different? So the difference is, if\nyou think about it like--",
    "start": "3404240",
    "end": "3410690"
  },
  {
    "text": "the product will-- as long as one of them\nbasically assigns 0 probability,",
    "start": "3410690",
    "end": "3416480"
  },
  {
    "text": "then the whole product\nevaluates to 0. And so the ensemble model,\nthe product of experts,",
    "start": "3416480",
    "end": "3421670"
  },
  {
    "text": "will also assign 0 probability. If you think about a\nmixture, even if one of them assigns 0 probability,\nas long as the others",
    "start": "3421670",
    "end": "3429050"
  },
  {
    "text": "think this thing is\nlikely, that thing will still have\nsome probability.",
    "start": "3429050",
    "end": "3434160"
  },
  {
    "text": "And so it behaves more like\nan OR, in the sense that-- as long as it's a soft\nOR because it's a--",
    "start": "3434160",
    "end": "3441260"
  },
  {
    "text": "[INAUDIBLE] Yeah, exactly. Exactly. It's like an average. Yeah.",
    "start": "3441260",
    "end": "3447230"
  },
  {
    "text": "How do you sample from\nthis product of experts? And how do you not think of it? How do you ignore\nthe Z part of it?",
    "start": "3447230",
    "end": "3452700"
  },
  {
    "text": "Yeah. How do we sample? Yeah, that will come up, how-- there are ways to do it. It's just expensive.",
    "start": "3452700",
    "end": "3457800"
  },
  {
    "text": "So it's not impossible. It's just-- an autoregressive\nmodel is very fast.",
    "start": "3457800",
    "end": "3464210"
  },
  {
    "text": "In an energy-based\nmodel, you're going to have to put more\ncompute, basically, at inference time when you\nwant to generate a sample.",
    "start": "3464210",
    "end": "3470520"
  },
  {
    "text": "That's the price you pay. Yeah. How is the product\nof experts related to the energy-based\nmodel formalism?",
    "start": "3470520",
    "end": "3477790"
  },
  {
    "text": "Yeah. So you can see that if you have\nindividual probability density",
    "start": "3477790",
    "end": "3483780"
  },
  {
    "text": "functions or probability mass\nfunctions-- if you multiply them together, you get\nanother function, which",
    "start": "3483780",
    "end": "3490830"
  },
  {
    "text": "is non-negative, but is\nnot necessarily normalized. So to normalize it, you have\nto divide by this partition",
    "start": "3490830",
    "end": "3498420"
  },
  {
    "text": "function. And from that perspective,\nit's an energy-based model. And so you can think of the\nenergy of the product of experts",
    "start": "3498420",
    "end": "3506099"
  },
  {
    "text": "as being the sum of\nthe log likelihoods of each individual model.",
    "start": "3506100",
    "end": "3511710"
  },
  {
    "text": "Because you can write\np theta 1 as exp log p theta 1 and the other\none as exp log p theta 2.",
    "start": "3511710",
    "end": "3519130"
  },
  {
    "text": "And then it's the exp\nof the sum of the logs. The problem is that the sum\nof the log likelihoods--",
    "start": "3519130",
    "end": "3525600"
  },
  {
    "text": "it's an energy, and\nit's not guaranteed to be normalized by design.",
    "start": "3525600",
    "end": "3531250"
  },
  {
    "text": "And so you have to then\nrenormalize everything with this global\npartition function.",
    "start": "3531250",
    "end": "3536495"
  },
  {
    "text": " Cool. Another example is the RBM, the\nRestricted Boltzmann Machine.",
    "start": "3536495",
    "end": "3545550"
  },
  {
    "text": "This is actually an energy-based\nmodel with latent variables. And this one is a discrete\nprobabilities probabilistic",
    "start": "3545550",
    "end": "3554059"
  },
  {
    "text": "model, where both the\nvisible variables, let's say, are binary. And the latent variables\nare also binary.",
    "start": "3554060",
    "end": "3561570"
  },
  {
    "text": "So you have n binary variables\nx and m latent variables z.",
    "start": "3561570",
    "end": "3567500"
  },
  {
    "text": "Both of them-- all the variables\nhere are going to be binary. And, for example, the x\ncould represent pixel values.",
    "start": "3567500",
    "end": "3575360"
  },
  {
    "text": "And the z's, as usual,\nare latent features. And the joint\ndistribution between z",
    "start": "3575360",
    "end": "3582050"
  },
  {
    "text": "and x is an energy-based model. And it's a pretty simple\nenergy-based model in the sense that there is the usual\nnormalization constant.",
    "start": "3582050",
    "end": "3588620"
  },
  {
    "text": "There is the usual exponential. And then the energy is\njust a quadratic form,",
    "start": "3588620",
    "end": "3594619"
  },
  {
    "text": "where you get the\nenergy by a W matrix. You have a vector of\nbiases, basically b.",
    "start": "3594620",
    "end": "3603740"
  },
  {
    "text": "Another vector of biases, c. And you map the values that\nthe x variables have and the z",
    "start": "3603740",
    "end": "3611599"
  },
  {
    "text": "variables have to a scalar\nby just taking this kind of expression, which is\njust a bunch of linear terms",
    "start": "3611600",
    "end": "3620220"
  },
  {
    "text": "in the x's, a bunch of\nlinear terms in the z's. And then there is\nthis cross product between the xi's\nand the zj's, which",
    "start": "3620220",
    "end": "3628290"
  },
  {
    "text": "are weighted by these weighting\nterms, this weight matrix W.",
    "start": "3628290",
    "end": "3634860"
  },
  {
    "text": "And it's restricted. It's called a Restricted\nBoltzmann Machine because,",
    "start": "3634860",
    "end": "3641799"
  },
  {
    "text": "basically, in this\nexpression, there is no connection between the\nvisible units or the hidden",
    "start": "3641800",
    "end": "3649810"
  },
  {
    "text": "units. And so, basically, there\nis no xi/xj term in here.",
    "start": "3649810",
    "end": "3655119"
  },
  {
    "text": "There are interactions\nbetween the x variables and the z variables, but\nnot between the x variables",
    "start": "3655120",
    "end": "3661810"
  },
  {
    "text": "or between the z\nvariables by themselves. Not super important,\nbut the key thing",
    "start": "3661810",
    "end": "3669700"
  },
  {
    "text": "is that this is actually\none of the very first-- important for\nhistorical reasons. This is one of the\nfirst deep generative",
    "start": "3669700",
    "end": "3677079"
  },
  {
    "text": "models that actually worked.",
    "start": "3677080",
    "end": "3682090"
  },
  {
    "text": "They were able to\ntrain these models by-- on image data by\nstacking multiple RBMs.",
    "start": "3682090",
    "end": "3690579"
  },
  {
    "text": "So an RBM is basically\na joint distribution between visible and hidden. And then if you stack\na bunch of them--",
    "start": "3690580",
    "end": "3698390"
  },
  {
    "text": "so you have visibles\nat the bottom. Then you have one RBM here. Then you build an RBM\nbetween the hidden",
    "start": "3698390",
    "end": "3706240"
  },
  {
    "text": "units of the first RBM,\nand some other hidden units of the second\nRBM, and so forth.",
    "start": "3706240",
    "end": "3713050"
  },
  {
    "text": "You get a Deep\nBoltzmann Machine. And the idea is that--",
    "start": "3713050",
    "end": "3718990"
  },
  {
    "text": "OK, you have the\npixels at the bottom. And then you have a hierarchy\nof more and more abstract features at the top.",
    "start": "3718990",
    "end": "3725560"
  },
  {
    "text": "And actually, it's\nactually pretty interesting that early-- in the very\nearly days of deep learning,",
    "start": "3725560",
    "end": "3733599"
  },
  {
    "text": "people were not able to train\ndeep neural networks very well. Even by-- in the supervised\nlearning setting,",
    "start": "3733600",
    "end": "3740770"
  },
  {
    "text": "things didn't quite work. And the only way they were\nable to get good results was to actually pre-train\nthe neural network",
    "start": "3740770",
    "end": "3747760"
  },
  {
    "text": "as a generative model. So they would choose\nan architecture which is like this Deep\nBoltzmann Machine architecture.",
    "start": "3747760",
    "end": "3755560"
  },
  {
    "text": "They would train the model in\nan unsupervised way as an RBM. So just as an\nenergy-based model,",
    "start": "3755560",
    "end": "3761119"
  },
  {
    "text": "they would train the\nweights of these matrices through some technique\nthat we'll talk",
    "start": "3761120",
    "end": "3767030"
  },
  {
    "text": "about later in this lecture. And then they would use\nthat as initialization for their supervised\nlearning algorithms.",
    "start": "3767030",
    "end": "3774020"
  },
  {
    "text": "And that was the first thing\nthat made deep learning work. And it was the only thing\nthat worked initially.",
    "start": "3774020",
    "end": "3779870"
  },
  {
    "text": "Then they figured out other\nways of making things work. But yeah, it was\nactually quite important",
    "start": "3779870",
    "end": "3785450"
  },
  {
    "text": "for getting people onboard\nwith the idea of training large neural networks.",
    "start": "3785450",
    "end": "3792050"
  },
  {
    "text": "And here, you can see some\nsamples of these kind of models. Again, this is a\nlong time ago, 2009.",
    "start": "3792050",
    "end": "3798530"
  },
  {
    "text": "But people were able to generate\nsome reasonable-looking samples by training one of these\nDeep Boltzmann Machines.",
    "start": "3798530",
    "end": "3807619"
  },
  {
    "text": "And so the-- You can see that the\nfundamental issue here",
    "start": "3807620",
    "end": "3816500"
  },
  {
    "text": "is the partition function\nis normalization constant. And just by looking through\nan example in the RBM setting,",
    "start": "3816500",
    "end": "3823759"
  },
  {
    "text": "we can see why, indeed,\ncomputing the volume is hard. If you think about even\njust a single-layer RBM,",
    "start": "3823760",
    "end": "3831110"
  },
  {
    "text": "where you have these x\nvariables, these z variables--",
    "start": "3831110",
    "end": "3836160"
  },
  {
    "text": "you have this\nenergy-based model. Computing the exponential\nof this energy function is super easy.",
    "start": "3836160",
    "end": "3842520"
  },
  {
    "text": "It's just basically a\nbunch of dot products. But the normalization\nconstant is very expensive.",
    "start": "3842520",
    "end": "3849132"
  },
  {
    "text": "The normalization\nconstant is going to be a function of w, b, and c. So the theta are the\nparameters that you",
    "start": "3849132",
    "end": "3855115"
  },
  {
    "text": "have in the model,\nwhich, in this case, are the-- these biases, b\nand c, in this matrix W.",
    "start": "3855115",
    "end": "3860880"
  },
  {
    "text": "But computing a\nnormalization constant requires you to go through\nevery possible configuration,",
    "start": "3860880",
    "end": "3866670"
  },
  {
    "text": "every possible assignment\nto the x variable, every possible assignment\nto the z variables, and sum up all these\nunnormalized probabilities.",
    "start": "3866670",
    "end": "3875580"
  },
  {
    "text": "And the problem is\nthat there is basically 2 to the n terms in this sum,\n2 to the m terms in this sum.",
    "start": "3875580",
    "end": "3882000"
  },
  {
    "text": "So you can see that, even\nfor small values of n and m, computing a normalization\nconstant is super expensive.",
    "start": "3882000",
    "end": "3890150"
  },
  {
    "text": "Is it possible to keep a running\n[INAUDIBLE] to approximate?",
    "start": "3890150",
    "end": "3895299"
  },
  {
    "text": "Approximate? Yeah. That's what we're going\nto have to do, basically. It's just like the-- it's a well-defined function.",
    "start": "3895300",
    "end": "3901619"
  },
  {
    "text": "It's just that if you\nwant it to compute it-- it doesn't have a closed form,\nunlike the Gaussian case.",
    "start": "3901620",
    "end": "3907200"
  },
  {
    "text": "There's no closed form\nfor this expression. And brute forcing\ntakes exponential time.",
    "start": "3907200",
    "end": "3913619"
  },
  {
    "text": "So we'll have to basically do\nsome kind of approximation. And in particular, the fact\nthat the partition function",
    "start": "3913620",
    "end": "3921470"
  },
  {
    "text": "is so hard to evaluate means\nthat likelihood-based training is going to be almost\nimpossible because just",
    "start": "3921470",
    "end": "3927410"
  },
  {
    "text": "to evaluate the\nprobability of a data point under the current\nchoice of the parameters",
    "start": "3927410",
    "end": "3933290"
  },
  {
    "text": "requires you to know the\ndenominator in that expression. And that's not generally\nknown, and you're not",
    "start": "3933290",
    "end": "3940730"
  },
  {
    "text": "going to be able to compute it. And so that's the issue.",
    "start": "3940730",
    "end": "3949080"
  },
  {
    "text": "Optimizing the\nunnormalized probability, which is just the\nexponential, is super easy.",
    "start": "3949080",
    "end": "3955770"
  },
  {
    "text": "But you have to take\ninto account, basically, during learning, you\nneed to figure out, If you were to change the\nparameters by a little bit,",
    "start": "3955770",
    "end": "3962940"
  },
  {
    "text": "how does that affect\nthe numerator? which is easy in\nthis expression.",
    "start": "3962940",
    "end": "3968430"
  },
  {
    "text": "But then you also\nhave to account, How does changing the parameters\naffect the total volume? How does that affect\nthe probability",
    "start": "3968430",
    "end": "3974910"
  },
  {
    "text": "that the model\nassigns to everything else, all the possible\nthings that can happen? And that is tricky because\nwe cannot even compute this",
    "start": "3974910",
    "end": "3982800"
  },
  {
    "text": "quantity. So it's going to be\nhard to figure out how does that\nquantity change if we were to make a small change\nto any of the parameters.",
    "start": "3982800",
    "end": "3989799"
  },
  {
    "text": "If I were to change, let's\nsay, b by a little bit-- I know how to evaluate how\nthis expression changes",
    "start": "3989800",
    "end": "3995910"
  },
  {
    "text": "by a little bit. But I don't know how to evaluate\nhow this partition function changes by a little bit.",
    "start": "3995910",
    "end": "4001170"
  },
  {
    "text": "And that's what makes\nlearning so hard. Could you expand\nthe slide before,",
    "start": "4001170",
    "end": "4006240"
  },
  {
    "text": "where you showed the samples-- the generated samples\nfrom the RBF-- RBM? Mhm. I didn't understand\nhow they sum--",
    "start": "4006240",
    "end": "4014130"
  },
  {
    "text": "how were they able\nto generate that? So you put in the\nobserved pixels. And then, with the stacking, you\ncan learn the latent variables?",
    "start": "4014130",
    "end": "4023200"
  },
  {
    "text": "Yeah. But how did they generate them? The-- So yeah. So how do they generate?",
    "start": "4023200",
    "end": "4029100"
  },
  {
    "text": "How do they learn? We haven't talked about it. That's going to come up\nnext, how do we do learning",
    "start": "4029100",
    "end": "4034230"
  },
  {
    "text": "and how do you sample\nfrom the models. Yeah. The problem is that\neven learning is hard",
    "start": "4034230",
    "end": "4039900"
  },
  {
    "text": "because it requires\nevaluating likelihoods. It requires the partition\nfunction, which you don't have. Sampling, as we'll\nsee, is also hard.",
    "start": "4039900",
    "end": "4047500"
  },
  {
    "text": "But there are approximations\nthat you can do, and that's basically\nwhat they did. All right.",
    "start": "4047500",
    "end": "4053280"
  },
  {
    "text": "And the intuition\nis that, if you",
    "start": "4053280",
    "end": "4059670"
  },
  {
    "text": "want to do maximum\nlikelihood learning, you have an expression that\nlooks like this that you",
    "start": "4059670",
    "end": "4064800"
  },
  {
    "text": "want to maximize. So you have a\ntraining data point, and you want to evaluate\nits probability according",
    "start": "4064800",
    "end": "4070380"
  },
  {
    "text": "to the model. And then you want to\nmaximize this expression as a function of theta. And the probability of\na data point, as usual,",
    "start": "4070380",
    "end": "4077250"
  },
  {
    "text": "is the unnormalized\nprobability divided by the partition function,\nthe total probability assigned",
    "start": "4077250",
    "end": "4084030"
  },
  {
    "text": "by the model to-- or the total\nunnormalized probability assigned by the model\nto everything else.",
    "start": "4084030",
    "end": "4090240"
  },
  {
    "text": "And so if you want\nto, you could make that ratio as big as possible.",
    "start": "4090240",
    "end": "4096060"
  },
  {
    "text": "You need to be able\nto do two things. You need to be able to\nincrease the numerator and decrease the denominator,\nwhich makes sense.",
    "start": "4096060",
    "end": "4105859"
  },
  {
    "text": "The intuition is that\nyou want to figure out how to change your\nparameters so that you make--",
    "start": "4105859",
    "end": "4112049"
  },
  {
    "text": "you increase the unnormalized\nprobability of the training data, while at\nthe same time, you",
    "start": "4112050",
    "end": "4118380"
  },
  {
    "text": "need to make sure\nthat you're not increasing the probability of\neverything else by too much.",
    "start": "4118380",
    "end": "4123390"
  },
  {
    "text": "So what really matters is\nthe relative probability of the training point you\ncare about with respect",
    "start": "4123390",
    "end": "4130170"
  },
  {
    "text": "to all the other things\nthat could happen, which is what you got in the\ndenominator, which is looking",
    "start": "4130170",
    "end": "4135429"
  },
  {
    "text": "at the total unnormalized\nprobability of all the other things that\ncould have happened.",
    "start": "4135430",
    "end": "4141880"
  },
  {
    "text": "And so, essentially,\nwhen you train, what you need to do is\nyou cannot just optimize",
    "start": "4141880",
    "end": "4148509"
  },
  {
    "text": "the numerator. Because if you just increase\nthe numerator like you just increased the size of\nthe slice of the pie",
    "start": "4148510",
    "end": "4156160"
  },
  {
    "text": "that you assigned to the\nparticular data point, you might be increasing the size\nof the total pie by even more.",
    "start": "4156160",
    "end": "4162109"
  },
  {
    "text": "And so the relative probability\ndoes not even go up. And so you need to be able\nto account for the effect",
    "start": "4162109",
    "end": "4171769"
  },
  {
    "text": "that changes to the\nparameters theta has not only on the training\ndata, but also on all the",
    "start": "4171770",
    "end": "4176810"
  },
  {
    "text": "other points that could have\nbeen sampled by the model.",
    "start": "4176810",
    "end": "4181920"
  },
  {
    "text": "And so, somehow, you need to\nincrease the probability-- the normalized probability\nof the training point",
    "start": "4181920",
    "end": "4187410"
  },
  {
    "text": "while pushing down the\nprobability of everything else.",
    "start": "4187410",
    "end": "4193930"
  },
  {
    "text": "And so it's the intuition\nthat you have here. If this is f theta, and\nyou have the correct answer",
    "start": "4193930",
    "end": "4199989"
  },
  {
    "text": "and some wrong answers, it's\nnot sufficient to just push up the normalized probability\nof the correct answer",
    "start": "4199990",
    "end": "4207220"
  },
  {
    "text": "because everything\nelse might also go up. So the relative probability\ndoesn't actually go up.",
    "start": "4207220",
    "end": "4212900"
  },
  {
    "text": "So you need to be\nable to push up the probability of the right\nanswer while, at the same time, pushing down the probability\nof everything else,",
    "start": "4212900",
    "end": "4220410"
  },
  {
    "text": "of basically the wrong answers. And that's basically the idea.",
    "start": "4220410",
    "end": "4230080"
  },
  {
    "text": "Instead of evaluating the\npartition function exactly, we're going to use some kind\nof Monte Carlo estimate.",
    "start": "4230080",
    "end": "4236860"
  },
  {
    "text": "So instead of evaluating the\nactual total unnormalized probability of\neverything else, we're",
    "start": "4236860",
    "end": "4243070"
  },
  {
    "text": "just going to sample\na few other things. And we're going to try to\ncompare the training point we",
    "start": "4243070",
    "end": "4248829"
  },
  {
    "text": "care about to\nthese other samples from the model, these\nother wrong answers, these other negative samples.",
    "start": "4248830",
    "end": "4255880"
  },
  {
    "text": "We have a positive\nsample, which is what we like in the training set. There's going to be a\nbunch of negative samples",
    "start": "4255880",
    "end": "4261768"
  },
  {
    "text": "that we're going to sample. And we're going to\ntry to contrast them. We're going to try to\nincrease the probability of the positive one and decrease\nthe probability of everything",
    "start": "4261768",
    "end": "4268630"
  },
  {
    "text": "else. And that's basically the\ncontrastive divergence algorithm",
    "start": "4268630",
    "end": "4274340"
  },
  {
    "text": "that has been-- was used to\ntrain that RBM-- the DBM that we had before.",
    "start": "4274340",
    "end": "4279440"
  },
  {
    "text": "Essentially, what you do is you\nmake this intuition concrete",
    "start": "4279440",
    "end": "4287050"
  },
  {
    "text": "by a fairly simple algorithm,\nwhere-- what you do is you sample from the model.",
    "start": "4287050",
    "end": "4297530"
  },
  {
    "text": "So you generate a\nnegative example by sampling from the model. And then you take the\ngradient of the difference",
    "start": "4297530",
    "end": "4306470"
  },
  {
    "text": "between the log of f theta,\nbasically, which is just",
    "start": "4306470",
    "end": "4312680"
  },
  {
    "text": "the energy of the model,\nor the negative energy",
    "start": "4312680",
    "end": "4318710"
  },
  {
    "text": "on the trainings, minus f theta\nevaluated on the negative one,",
    "start": "4318710",
    "end": "4324739"
  },
  {
    "text": "which is exactly doing\nthis thing of pushing up the correct answer while pushing\ndown the wrong answer, where",
    "start": "4324740",
    "end": "4331910"
  },
  {
    "text": "the wrong answer\nis what is defined as the sample from the model. How do we know that the\nsample we get is wrong?",
    "start": "4331910",
    "end": "4340469"
  },
  {
    "text": "Yeah. So the sample is not\nnecessarily wrong. It's just something else that\ncould have come from the model.",
    "start": "4340470",
    "end": "4347420"
  },
  {
    "text": "And we're considering it. It's a representative\nsample of something else",
    "start": "4347420",
    "end": "4353929"
  },
  {
    "text": "that could have happened if you\nwere to sample from the model. So we want the probability\nof the true data point",
    "start": "4353930",
    "end": "4361070"
  },
  {
    "text": "to go up, as compared to\nsome other typical scenario",
    "start": "4361070",
    "end": "4366590"
  },
  {
    "text": "that you could have\nsampled from your model. And that's actually\nprincipled, as we'll see.",
    "start": "4366590",
    "end": "4372530"
  },
  {
    "text": "This actually gives you\nan unbiased estimate",
    "start": "4372530",
    "end": "4377900"
  },
  {
    "text": "of the true gradient that\nyou would like to optimize. Is it still possible\nthat the sample you get",
    "start": "4377900",
    "end": "4383660"
  },
  {
    "text": "is also something that's\nfrom the training set? But the-- overall,\nthe estimation--",
    "start": "4383660",
    "end": "4389880"
  },
  {
    "text": "Yes. The expectation is-- An expectation. Yeah, yeah, yeah, yeah. Was there--",
    "start": "4389880",
    "end": "4395290"
  },
  {
    "text": "Yeah. Presumably, how do you\nsample from that model? Yeah.",
    "start": "4395290",
    "end": "4400400"
  },
  {
    "text": "OK. We haven't talked\nabout how to sample. But if you could somehow sample\nfrom a model, then what I claim",
    "start": "4400400",
    "end": "4406970"
  },
  {
    "text": "is that this algorithm would\ngive you the right answer. And this idea of making\nthe training data more",
    "start": "4406970",
    "end": "4414020"
  },
  {
    "text": "likely than a typical sample\nfrom the model actually",
    "start": "4414020",
    "end": "4419630"
  },
  {
    "text": "is what you want, so to the\nextent that you can, indeed, generate these samples, which\nwe don't know how to do yet.",
    "start": "4419630",
    "end": "4425480"
  },
  {
    "text": "But if you can,\nthen this gives you a way of training,\na model to make it better to fit to some data set.",
    "start": "4425480",
    "end": "4432750"
  },
  {
    "text": "Yeah. So when you draw a sample you\ndon't do whether you can go--",
    "start": "4432750",
    "end": "4439290"
  },
  {
    "text": "if the sample is not\npresent in training data, you just draw this sample. You just draw a sample, yeah.",
    "start": "4439290",
    "end": "4445170"
  },
  {
    "text": "Whether or not it's in the\ntraining set, it doesn't matter. And so why does\nthis algorithm work?",
    "start": "4445170",
    "end": "4453489"
  },
  {
    "text": "Well, if you think\nabout it, what you want to do is if you look\nat the log of this expression,",
    "start": "4453490",
    "end": "4460050"
  },
  {
    "text": "which is just the\nlog-likelihood, you're going to get\nthese two terms. You're going to get the\nf theta, which is just",
    "start": "4460050",
    "end": "4466440"
  },
  {
    "text": "the neural network\nthat you're using to parameterize your energy. And then you have this\ndependence on the partition",
    "start": "4466440",
    "end": "4473790"
  },
  {
    "text": "function, the partition\nfunction has on the parameters that you're optimizing\nwith respect to.",
    "start": "4473790",
    "end": "4480659"
  },
  {
    "text": "And what we want is the\ngradient of this quantity with respect to theta. And so just like before, we\nwant to increase the f theta",
    "start": "4480660",
    "end": "4489389"
  },
  {
    "text": "on the training set\nwhile decreasing the total amount of\nunnormalized probability mass",
    "start": "4489390",
    "end": "4495490"
  },
  {
    "text": "that we get by changing\ntheta by a little bit. And so really what we\nwant is the gradient",
    "start": "4495490",
    "end": "4503440"
  },
  {
    "text": "of this difference,\nwhich is just the difference of the gradients. And the gradient of the f\ntheta is trivial to compute.",
    "start": "4503440",
    "end": "4513020"
  },
  {
    "text": "That's just your neural network. We know how to\noptimize that quantity. We know how to adjust the\nparameters so that we push up",
    "start": "4513020",
    "end": "4520761"
  },
  {
    "text": "the output of the neural\nnetwork on the training data points that we have access to. What's more tricky\nis to figure out",
    "start": "4520762",
    "end": "4526150"
  },
  {
    "text": "how does changing theta\naffect the total amount of unnormalized\nprobability mass.",
    "start": "4526150",
    "end": "4533440"
  },
  {
    "text": "And we know that the derivative\nof the log of z theta is just like the derivative\nof the argument of the log",
    "start": "4533440",
    "end": "4540730"
  },
  {
    "text": "divided by z theta, just\nthe derivative of the log expression.",
    "start": "4540730",
    "end": "4546489"
  },
  {
    "text": "And now we can replace\nz theta in the numerator",
    "start": "4546490",
    "end": "4551590"
  },
  {
    "text": "there with the\nexpression that we have. And because the\ngradient is linear,",
    "start": "4551590",
    "end": "4557380"
  },
  {
    "text": "we can push the\ngradient inside this sum and that's basically\nthe same thing.",
    "start": "4557380",
    "end": "4563480"
  },
  {
    "text": "We know that z theta\nis just the integral of the unnormalized\nprobability and then we can push the gradient inside\nand we get this quantity here.",
    "start": "4563480",
    "end": "4572530"
  },
  {
    "text": "And now we know how to compute\nthat gradient using chain rule",
    "start": "4572530",
    "end": "4577869"
  },
  {
    "text": "and that evaluates to that. It's just the\ngradient of f theta.",
    "start": "4577870",
    "end": "4583530"
  },
  {
    "text": "Again, this is something\nwe know how to compute. And then it's rescaled by this\nexponential and the partition",
    "start": "4583530",
    "end": "4591520"
  },
  {
    "text": "function. And if we push the\npartition function inside,",
    "start": "4591520",
    "end": "4597890"
  },
  {
    "text": "you'll recognize\nthat this is just the probability\nassigned by the model to a possible data point x.",
    "start": "4597890",
    "end": "4606160"
  },
  {
    "text": "And so the true gradient\nof the log-likelihood, which is what we would\nlike to optimize and take",
    "start": "4606160",
    "end": "4613190"
  },
  {
    "text": "the gradient ascent\nwith respect to, is basically the gradient\nof the energy evaluated",
    "start": "4613190",
    "end": "4622040"
  },
  {
    "text": "at the data point minus the\nexpected gradient with respect",
    "start": "4622040",
    "end": "4627890"
  },
  {
    "text": "to the model distribution,\nwhich makes sense.",
    "start": "4627890",
    "end": "4633660"
  },
  {
    "text": "We need to figure out how does\nchanging theta by a little bit affect the unnormalized\nprobability that you",
    "start": "4633660",
    "end": "4640190"
  },
  {
    "text": "assign to the true data\npoint we care about. And then we also\nneed to understand how changing theta affects\nthe probability of everything",
    "start": "4640190",
    "end": "4647360"
  },
  {
    "text": "else that could have happened. And we need to weigh\nall the possible axes with the probability assigned by\nthe model for the current choice",
    "start": "4647360",
    "end": "4656440"
  },
  {
    "text": "of theta. And now you see why the\ncontrastive divergence work. The contrastive\ndivergence algorithm",
    "start": "4656440",
    "end": "4662620"
  },
  {
    "text": "is just a Monte\nCarlo approximation of that expectation. So we approximate\nthe expectation",
    "start": "4662620",
    "end": "4668350"
  },
  {
    "text": "with respect to the\nmodel distribution with a single sample and\nthat's an unbiased estimator",
    "start": "4668350",
    "end": "4676080"
  },
  {
    "text": "of the true gradient. And so the true\ngradient is basically",
    "start": "4676080",
    "end": "4681940"
  },
  {
    "text": "this difference between\nthe gradient evaluated at the true data point\nand the gradient evaluated at a typical sample, what you\nget by sampling from the model.",
    "start": "4681940",
    "end": "4690530"
  },
  {
    "text": "And as long as this-- you can follow this direction\nand your gradient ascent algorithm.",
    "start": "4690530",
    "end": "4696220"
  },
  {
    "text": "You are making the relative\nprobability of the data increase basically because the data goes\nup more than the denominator",
    "start": "4696220",
    "end": "4707320"
  },
  {
    "text": "that how much the partition\nfunction grows, essentially. ",
    "start": "4707320",
    "end": "4714860"
  },
  {
    "text": "And that's the key idea behind\nthe contrastive divergence",
    "start": "4714860",
    "end": "4720139"
  },
  {
    "text": "algorithm. The main thing that\nstill remains to be seen",
    "start": "4720140",
    "end": "4725449"
  },
  {
    "text": "is how do you get samples. We still don't know how to\nsample from these models.",
    "start": "4725450",
    "end": "4730579"
  },
  {
    "text": "And the problem\nis that, well, we don't have a direct\nway of sampling",
    "start": "4730580",
    "end": "4736846"
  },
  {
    "text": "in an autoregressive\nmodel where we can just go through the\nvariables one at a time and set them by sampling\nfrom the conditionals.",
    "start": "4736847",
    "end": "4745699"
  },
  {
    "text": "And we cannot evaluate the\nprobability of every data point because that requires knowing\nthe partition function.",
    "start": "4745700",
    "end": "4753350"
  },
  {
    "text": "But what we can do is we\ncan compare two data points or we can compare two possible\nsamples x and x prime.",
    "start": "4753350",
    "end": "4763730"
  },
  {
    "text": "And the basic idea\nis that we can do some kind of local\nsearch or local optimization",
    "start": "4763730",
    "end": "4771890"
  },
  {
    "text": "where we can start with a\nsample that might not be good just by randomly initializing\nx0 somehow, and then trying",
    "start": "4771890",
    "end": "4782690"
  },
  {
    "text": "to locally make some\nperturb, this sample, to try to make it more\nlikely essentially according",
    "start": "4782690",
    "end": "4789830"
  },
  {
    "text": "to the model. And because we can do\ncomparisons checking",
    "start": "4789830",
    "end": "4797539"
  },
  {
    "text": "whether the sample or its\nperturbation is more likely is going to be tractable.",
    "start": "4797540",
    "end": "4803480"
  },
  {
    "text": "And so this is a particular\ntype of algorithm called a Markov chain\nMonte Carlo method.",
    "start": "4803480",
    "end": "4810110"
  },
  {
    "text": "It's actually pretty simple. What you do is, again, you\ninitialize the procedure",
    "start": "4810110",
    "end": "4815120"
  },
  {
    "text": "somehow, and then\nat every step you propose basically some\nchange to your sample.",
    "start": "4815120",
    "end": "4822530"
  },
  {
    "text": "And it could be as simple\nas adding some noise to what you have right now.",
    "start": "4822530",
    "end": "4827630"
  },
  {
    "text": "And then if what you get\nby perturbing your sample has higher probability\nthan what you started from,",
    "start": "4827630",
    "end": "4835380"
  },
  {
    "text": "which we can do this comparison\nbecause we don't need the partition function to\ncompare the probability of x",
    "start": "4835380",
    "end": "4841670"
  },
  {
    "text": "prime with what we\nhave right now with xt, then we update our sample to\nthis new candidate, x prime.",
    "start": "4841670",
    "end": "4850390"
  },
  {
    "text": " And then what we\nneed to do is we also",
    "start": "4850390",
    "end": "4855600"
  },
  {
    "text": "need to add a\nlittle bit of noise to the process where\nbasically, if you think of this",
    "start": "4855600",
    "end": "4863580"
  },
  {
    "text": "as an optimization\nproblem, we're always taking uphill moves. So if the probability goes\nup, we always take that step.",
    "start": "4863580",
    "end": "4873450"
  },
  {
    "text": "But if x prime, this\nproposed transform,",
    "start": "4873450",
    "end": "4880410"
  },
  {
    "text": "the sample that we get\nby adding noise actually has lower probability\nthan what we started from, we occasionally\ntake this downhill",
    "start": "4880410",
    "end": "4887580"
  },
  {
    "text": "moves with probability\nproportional to this quantity. So basically proportional to\nhow much worse this new sample",
    "start": "4887580",
    "end": "4896310"
  },
  {
    "text": "we're proposing is compared\nto where we started from. And then you keep doing this.",
    "start": "4896310",
    "end": "4906070"
  },
  {
    "text": "And it turns out that\nin theory, at least, if you repeat this procedure\nfor a sufficiently large number",
    "start": "4906070",
    "end": "4913060"
  },
  {
    "text": "of steps, you will\neventually get a sample from the true distribution.",
    "start": "4913060",
    "end": "4920230"
  },
  {
    "text": "Why do you need to\nprobabilistically accept the noise one instead of\njust ignoring the first one?",
    "start": "4920230",
    "end": "4928000"
  },
  {
    "text": "Yeah, great question. Why do we need to\noccasionally accept",
    "start": "4928000",
    "end": "4935600"
  },
  {
    "text": "samples that are worse\nthan what we started from? The reason is that we don't\njust want to do optimization.",
    "start": "4935600",
    "end": "4941239"
  },
  {
    "text": "If you were to just\ndo step 1, then you would do some kind of\nlocal search procedure",
    "start": "4941240",
    "end": "4948475"
  },
  {
    "text": "where you would\nkeep going around until you find a\nlocal optimum, then you would stop there,\nwhich is not what we",
    "start": "4948475",
    "end": "4955780"
  },
  {
    "text": "want because we want a sample. So we want to somehow be able\nto explore the space more.",
    "start": "4955780",
    "end": "4961300"
  },
  {
    "text": "And so we need to\nbe able to accept downhill moves occasionally,\nand they are not too bad.",
    "start": "4961300",
    "end": "4967400"
  },
  {
    "text": "And that basically\nallows the algorithm to explore the whole space of\nsamples we could have generated,",
    "start": "4967400",
    "end": "4974080"
  },
  {
    "text": "because maybe you're stuck in\na local optimum that is not very good and if you had\nmoved much further away,",
    "start": "4974080",
    "end": "4980080"
  },
  {
    "text": "there would have been regions\nwith very high probability.",
    "start": "4980080",
    "end": "4985180"
  },
  {
    "text": "Discard every time you'll\nget the same sample. Also. Yeah.",
    "start": "4985180",
    "end": "4991389"
  },
  {
    "text": "So why don't we just\nuse the probability to go uphill as well?",
    "start": "4991390",
    "end": "4997000"
  },
  {
    "text": "Why do we always go to the\none with a higher value? Why we always go to the one\nwith the higher likelihood is--",
    "start": "4997000",
    "end": "5003330"
  },
  {
    "text": "Why don't we use\nthe probability? You could define other-- this is not the only\nway of doing it. You could define other variants\nof this where you don't always",
    "start": "5003330",
    "end": "5011790"
  },
  {
    "text": "accept uphill moves. There is a certain something\ncalled the Metropolis-Hastings algorithm that you can use\nto define different variants",
    "start": "5011790",
    "end": "5021010"
  },
  {
    "text": "of MCMC that would also work. This is the simplest\nversion that is guaranteed to give\nsamples, but yeah, there",
    "start": "5021010",
    "end": "5027250"
  },
  {
    "text": "are other variants\nthat you can use. The choice that you\nmake in step 1 and 2",
    "start": "5027250",
    "end": "5033730"
  },
  {
    "text": "in that loop in that\ncondition is that the same? I think in both cases you\ntake the x prime, right?",
    "start": "5033730",
    "end": "5044380"
  },
  {
    "text": "But in the second case, you only\ntake it with some probability. OK. So you always take an uphill.",
    "start": "5044380",
    "end": "5051880"
  },
  {
    "text": "If your probability goes up,\nyou always take that step. If it's a downhill\nmove, then you",
    "start": "5051880",
    "end": "5059860"
  },
  {
    "text": "take it with some probability. And if it's about the same,\nthen you're likely to take it.",
    "start": "5059860",
    "end": "5065690"
  },
  {
    "text": "If it's much worse,\nthen this probability is going to be very\nsmall and you're not going to take that kind of move.",
    "start": "5065690",
    "end": "5072280"
  },
  {
    "text": " So that's the way\nyou generate samples",
    "start": "5072280",
    "end": "5077460"
  },
  {
    "text": "and that's what you do in\nthe contrastive divergence algorithm.",
    "start": "5077460",
    "end": "5083570"
  },
  {
    "start": "5083570",
    "end": "5088000"
  }
]
[
  {
    "start": "0",
    "end": "113000"
  },
  {
    "text": "Welcome back.",
    "start": "0",
    "end": "1320"
  },
  {
    "text": "Our next topic is Bayesian\nadditive regression trees,",
    "start": "1320",
    "end": "5600"
  },
  {
    "text": "also known--",
    "start": "5600",
    "end": "6680"
  },
  {
    "text": "how do you say that, Trevor?",
    "start": "6680",
    "end": "8650"
  },
  {
    "text": "BART.",
    "start": "8650",
    "end": "9559"
  },
  {
    "text": "I just want to make\nfun of your accent.",
    "start": "9560",
    "end": "11610"
  },
  {
    "text": "It's BART.",
    "start": "11610",
    "end": "13340"
  },
  {
    "text": "That's what I said.",
    "start": "13340",
    "end": "14390"
  },
  {
    "text": "BART.",
    "start": "14390",
    "end": "15380"
  },
  {
    "text": "OK, so we're going to discuss\nBayesian additive regression",
    "start": "15380",
    "end": "18410"
  },
  {
    "text": "trees, or BART, an ensemble\nmethod that uses decision",
    "start": "18410",
    "end": "21320"
  },
  {
    "text": "trees as its building blocks.",
    "start": "21320",
    "end": "23720"
  },
  {
    "text": "Now, we've talked about\ntwo or three other methods",
    "start": "23720",
    "end": "26720"
  },
  {
    "text": "already for using\ndecision trees,",
    "start": "26720",
    "end": "28400"
  },
  {
    "text": "and supervised learning, bagging\nand random forest, for example,",
    "start": "28400",
    "end": "31610"
  },
  {
    "text": "make predictions from an\naverage of regression trees.",
    "start": "31610",
    "end": "34310"
  },
  {
    "text": "Each one is built up using\na random sample of data.",
    "start": "34310",
    "end": "37400"
  },
  {
    "text": "Either sample the data\nas a bootstrap sample",
    "start": "37400",
    "end": "40160"
  },
  {
    "text": "or we sample the features.",
    "start": "40160",
    "end": "42242"
  },
  {
    "text": "And each one is\nbuilt up separately",
    "start": "42242",
    "end": "43880"
  },
  {
    "text": "and they're averaged at the end.",
    "start": "43880",
    "end": "46140"
  },
  {
    "text": "Boosting, on the other hand,\nuses a weighted sum of trees,",
    "start": "46140",
    "end": "48920"
  },
  {
    "text": "each of which is constructed\nfrom fitting a tree",
    "start": "48920",
    "end": "50989"
  },
  {
    "text": "to the residual of\nthe current fit.",
    "start": "50990",
    "end": "52712"
  },
  {
    "text": "So they're not\nbuilt independently,",
    "start": "52712",
    "end": "54170"
  },
  {
    "text": "but they're built in sequence.",
    "start": "54170",
    "end": "55699"
  },
  {
    "text": "So each tree tries to capture\nthe signal that's not yet",
    "start": "55700",
    "end": "59480"
  },
  {
    "text": "accounted for by the\ncurrent set of trees.",
    "start": "59480",
    "end": "61680"
  },
  {
    "text": "So it's kind of a\nforward stepwise, forward",
    "start": "61680",
    "end": "63680"
  },
  {
    "text": "stagewise method.",
    "start": "63680",
    "end": "65110"
  },
  {
    "text": "So, Rob, what does\nBART do differently?",
    "start": "65110",
    "end": "68550"
  },
  {
    "text": "Well, if you wait for the\nnext slide, you'll find out.",
    "start": "68550",
    "end": "72120"
  },
  {
    "text": "OK, BART is related both to\nrandom forest and boosting.",
    "start": "72120",
    "end": "77080"
  },
  {
    "text": "It has the random feature as\nin bagging and random forest",
    "start": "77080",
    "end": "79950"
  },
  {
    "text": "that it draws random\nsamples to build trees.",
    "start": "79950",
    "end": "82840"
  },
  {
    "text": "But it also has a\nsimilarity to boosting,",
    "start": "82840",
    "end": "84630"
  },
  {
    "text": "in that it uses the other trees\nin kind of a passer residual",
    "start": "84630",
    "end": "87689"
  },
  {
    "text": "to choose the next tree to\nimprove the overall fit,",
    "start": "87690",
    "end": "91710"
  },
  {
    "text": "to try to account for the\nsignal that's not been captured",
    "start": "91710",
    "end": "94590"
  },
  {
    "text": "by the current model.",
    "start": "94590",
    "end": "95500"
  },
  {
    "text": "So it's got similarities\nto both random forests,",
    "start": "95500",
    "end": "97800"
  },
  {
    "text": "bagging, and boosting.",
    "start": "97800",
    "end": "99690"
  },
  {
    "text": "The main novelty, as\nyou'll see, is the way",
    "start": "99690",
    "end": "101598"
  },
  {
    "text": "in which the new\ntrees are generated,",
    "start": "101598",
    "end": "103140"
  },
  {
    "text": "which is quite different\nthan the other methods.",
    "start": "103140",
    "end": "106170"
  },
  {
    "text": "It can be applied to regression,\nclassification, other problems",
    "start": "106170",
    "end": "109830"
  },
  {
    "text": "like survival analysis.",
    "start": "109830",
    "end": "110860"
  },
  {
    "text": "But here, we'll just\nfocus on regression.",
    "start": "110860",
    "end": "113400"
  },
  {
    "start": "113000",
    "end": "207000"
  },
  {
    "text": "So first of all, in a\npicture, this is the idea,",
    "start": "113400",
    "end": "116010"
  },
  {
    "text": "and then we'll go into\ndetails in the coming slides.",
    "start": "116010",
    "end": "119080"
  },
  {
    "text": "A number of trees that\nare fit in parallel.",
    "start": "119080",
    "end": "120910"
  },
  {
    "text": "So one chooses a number\nK, maybe a few hundred,",
    "start": "120910",
    "end": "124350"
  },
  {
    "text": "and B steps in each\nstage and each tree",
    "start": "124350",
    "end": "129270"
  },
  {
    "text": "is changed B times as\nthe algorithm proceeds.",
    "start": "129270",
    "end": "133740"
  },
  {
    "text": "For each tree, say\nthe first tree,",
    "start": "133740",
    "end": "135300"
  },
  {
    "text": "we start with the root node.",
    "start": "135300",
    "end": "136528"
  },
  {
    "text": "So they all start\nwith the root node.",
    "start": "136528",
    "end": "138070"
  },
  {
    "text": "And then perturbations\nare applied to the trees",
    "start": "138070",
    "end": "141240"
  },
  {
    "text": "to change them.",
    "start": "141240",
    "end": "142062"
  },
  {
    "text": "These perturbations, as we'll\nsee, can be of various kinds.",
    "start": "142062",
    "end": "144519"
  },
  {
    "text": "We can add a branch,\nwe can delete a branch,",
    "start": "144520",
    "end": "147810"
  },
  {
    "text": "or we can change the predicted\nvalues at each of the nodes.",
    "start": "147810",
    "end": "151180"
  },
  {
    "text": "In this case, since we\nstarted with the root node,",
    "start": "151180",
    "end": "153930"
  },
  {
    "text": "each of these trees gets a\nsingle split added to them,",
    "start": "153930",
    "end": "157290"
  },
  {
    "text": "although the split points and\nsplit variables are different.",
    "start": "157290",
    "end": "159930"
  },
  {
    "text": "And then at the next\nstage, this tree,",
    "start": "159930",
    "end": "161909"
  },
  {
    "text": "we've added another\nbranch just on the left.",
    "start": "161910",
    "end": "164880"
  },
  {
    "text": "This tree, we've actually\nremoved the existing branches",
    "start": "164880",
    "end": "168150"
  },
  {
    "text": "back, and it's the root node.",
    "start": "168150",
    "end": "169360"
  },
  {
    "text": "And this tree, again, we add\nanother branch on the left side.",
    "start": "169360",
    "end": "172080"
  },
  {
    "text": "And this continues for\nmaybe a few thousand steps,",
    "start": "172080",
    "end": "176460"
  },
  {
    "text": "these perturbations, to get\na whole sequence of trees",
    "start": "176460",
    "end": "179250"
  },
  {
    "text": "of varying sizes with different\npredictions in the root nodes.",
    "start": "179250",
    "end": "182710"
  },
  {
    "text": "So Robert, so it looks like--\nso the iterations, where",
    "start": "182710",
    "end": "185760"
  },
  {
    "text": "you go 1 through B, and it\nseems like what you're doing",
    "start": "185760",
    "end": "188700"
  },
  {
    "text": "is maintaining K\ntrees at each step.",
    "start": "188700",
    "end": "191650"
  },
  {
    "text": "Exactly.",
    "start": "191650",
    "end": "192150"
  },
  {
    "text": "And each step you change\neach of those K trees",
    "start": "192150",
    "end": "194579"
  },
  {
    "text": "in some kind of random way.",
    "start": "194580",
    "end": "196740"
  },
  {
    "text": "Exactly.",
    "start": "196740",
    "end": "197450"
  },
  {
    "text": "Yeah.",
    "start": "197450",
    "end": "197950"
  },
  {
    "text": "So at the end, we make\nour final prediction",
    "start": "197950",
    "end": "199770"
  },
  {
    "text": "by averaging the prediction\nover all K sequences of trees",
    "start": "199770",
    "end": "203310"
  },
  {
    "text": "and all of steps B.\nOK, so let's actually",
    "start": "203310",
    "end": "209535"
  },
  {
    "start": "207000",
    "end": "360000"
  },
  {
    "text": "go over that now in more\ndetail with some notation.",
    "start": "209535",
    "end": "211660"
  },
  {
    "text": "So the number of\nregression trees,",
    "start": "211660",
    "end": "214447"
  },
  {
    "text": "that was the different columns\nin that previous picture,",
    "start": "214447",
    "end": "216780"
  },
  {
    "text": "is K and the number\nof iterations",
    "start": "216780",
    "end": "219450"
  },
  {
    "text": "for which we apply the\nalgorithm, we'll call it B, OK.",
    "start": "219450",
    "end": "223440"
  },
  {
    "text": "And the prediction\nat a query point",
    "start": "223440",
    "end": "226560"
  },
  {
    "text": "X for the Kth tree\nand the Bth iteration,",
    "start": "226560",
    "end": "228690"
  },
  {
    "text": "we'll call it F hat [INAUDIBLE]\nB sub K. So at the end",
    "start": "228690",
    "end": "234240"
  },
  {
    "text": "of each iteration,\nwe have K trees",
    "start": "234240",
    "end": "237000"
  },
  {
    "text": "and our prediction\nat the beat step",
    "start": "237000",
    "end": "240120"
  },
  {
    "text": "is simply the sum of\nthose predictions.",
    "start": "240120",
    "end": "245040"
  },
  {
    "text": "OK, so what do those\niterations look like?",
    "start": "245040",
    "end": "247409"
  },
  {
    "text": "At the beginning, as\nwe saw in the picture,",
    "start": "247410",
    "end": "250755"
  },
  {
    "text": "each tree starts with\na single root node",
    "start": "250755",
    "end": "252870"
  },
  {
    "text": "and the prediction\nin each tree is just",
    "start": "252870",
    "end": "254970"
  },
  {
    "text": "the average of the observation's\nover all observations.",
    "start": "254970",
    "end": "257920"
  },
  {
    "text": "So our overall prediction\nat the first step",
    "start": "257920",
    "end": "260398"
  },
  {
    "text": "is simply this average.",
    "start": "260399",
    "end": "262689"
  },
  {
    "text": "So we divide each\nof those averages",
    "start": "262690",
    "end": "265020"
  },
  {
    "text": "by K so that when\nwe sum up K of them,",
    "start": "265020",
    "end": "267210"
  },
  {
    "text": "we get the overall mean of Y?",
    "start": "267210",
    "end": "269889"
  },
  {
    "text": "Exactly.",
    "start": "269890",
    "end": "270720"
  },
  {
    "text": "And then in coming iterations,\ntwo, three, et cetera,",
    "start": "270720",
    "end": "274860"
  },
  {
    "text": "this is what happens.",
    "start": "274860",
    "end": "275979"
  },
  {
    "text": "We take the partial residual\nfor all tree, but the Kth tree,",
    "start": "275980",
    "end": "280160"
  },
  {
    "text": "we subtract off the\ncurrent fit, and we",
    "start": "280160",
    "end": "283310"
  },
  {
    "text": "form what's called\nthe partial residual,",
    "start": "283310",
    "end": "285200"
  },
  {
    "text": "and then we build our tree\non the partial residual.",
    "start": "285200",
    "end": "288200"
  },
  {
    "text": "But we might think, well,\nI'll just build a regression",
    "start": "288200",
    "end": "290570"
  },
  {
    "text": "tree directly from scratch,\nbut instead what BART",
    "start": "290570",
    "end": "293810"
  },
  {
    "text": "does is it takes the\nexisting tree at that step",
    "start": "293810",
    "end": "296810"
  },
  {
    "text": "and it perturbs it\nin a certain way, OK.",
    "start": "296810",
    "end": "299750"
  },
  {
    "text": "And so instead of\nfitting a fresh tree,",
    "start": "299750",
    "end": "303580"
  },
  {
    "text": "it chooses a perturbation\nof the existing",
    "start": "303580",
    "end": "306189"
  },
  {
    "text": "tree from the previous\nstep for the Kth",
    "start": "306190",
    "end": "309820"
  },
  {
    "text": "tree from a set of\npossible perturbations",
    "start": "309820",
    "end": "314030"
  },
  {
    "text": "try to improve the fit.",
    "start": "314030",
    "end": "315620"
  },
  {
    "text": "Now, we're trying to\nmake the sum of squares",
    "start": "315620",
    "end": "318310"
  },
  {
    "text": "on the partial residual\nsmall as possible.",
    "start": "318310",
    "end": "320800"
  },
  {
    "text": "And there's two different ways\nthis perturbation can be made,",
    "start": "320800",
    "end": "324884"
  },
  {
    "text": "we can change the\nstructure of the tree",
    "start": "324885",
    "end": "326510"
  },
  {
    "text": "by adding or pruning branches,\nand we saw in that picture,",
    "start": "326510",
    "end": "329963"
  },
  {
    "text": "in one case, we added\nbranches, in other case,",
    "start": "329963",
    "end": "331880"
  },
  {
    "text": "we actually removed\nthe only branch,",
    "start": "331880",
    "end": "333690"
  },
  {
    "text": "or we can leave the tree alone\nand change the predicted value",
    "start": "333690",
    "end": "336950"
  },
  {
    "text": "at each terminal node.",
    "start": "336950",
    "end": "339060"
  },
  {
    "text": "OK, so we choose among a set of\nperturbations to vary the train.",
    "start": "339060",
    "end": "342270"
  },
  {
    "text": "And what we're doing here is\nmoving around the tree space,",
    "start": "342270",
    "end": "345900"
  },
  {
    "text": "kind of in a\nsimilar way, bagging",
    "start": "345900",
    "end": "347393"
  },
  {
    "text": "and boosting do\nthe same way, they",
    "start": "347393",
    "end": "348810"
  },
  {
    "text": "generate a set of trees\nthat tries to cover",
    "start": "348810",
    "end": "350610"
  },
  {
    "text": "the set of possible trees.",
    "start": "350610",
    "end": "352750"
  },
  {
    "text": "This is also moving\naround the tree",
    "start": "352750",
    "end": "354270"
  },
  {
    "text": "space, the space of possible\ntrees, but in a different way",
    "start": "354270",
    "end": "357599"
  },
  {
    "text": "through perturbations.",
    "start": "357600",
    "end": "359410"
  },
  {
    "text": "And here are some examples.",
    "start": "359410",
    "end": "361120"
  },
  {
    "start": "360000",
    "end": "414000"
  },
  {
    "text": "Suppose we're at a step\nwhere we for the Kth tree,",
    "start": "361120",
    "end": "365210"
  },
  {
    "text": "we have at step B minus 1\nthis tree, one possibility",
    "start": "365210",
    "end": "369280"
  },
  {
    "text": "for perturbation is to leave the\nstructure of the tree the same,",
    "start": "369280",
    "end": "372430"
  },
  {
    "text": "but the predictions\nin the terminal nodes",
    "start": "372430",
    "end": "374180"
  },
  {
    "text": "are varied a little bit,\nlike this 0.4079 change",
    "start": "374180",
    "end": "377949"
  },
  {
    "text": "to 0.444221, et cetera.",
    "start": "377950",
    "end": "381100"
  },
  {
    "text": "Another possibility\nis to remove a branch.",
    "start": "381100",
    "end": "383783"
  },
  {
    "text": "Well, here, it actually\nlooks like we've",
    "start": "383783",
    "end": "385449"
  },
  {
    "text": "trimmed off this branch here.",
    "start": "385450",
    "end": "388790"
  },
  {
    "text": "So we've removed these\nthree terminal nodes.",
    "start": "388790",
    "end": "390960"
  },
  {
    "text": "And then here's\nanother possibility.",
    "start": "390960",
    "end": "392720"
  },
  {
    "text": "So instead of trimming\na branch, we've added.",
    "start": "392720",
    "end": "394720"
  },
  {
    "text": "Quite a bit of randomness\nin this trimming, Rob.",
    "start": "394720",
    "end": "397770"
  },
  {
    "text": "It similar to your mouse\nwork on the computer.",
    "start": "397770",
    "end": "401259"
  },
  {
    "text": "I wish I had a\nmouse, but I don't.",
    "start": "401260",
    "end": "403310"
  },
  {
    "text": "So, OK.",
    "start": "403310",
    "end": "403940"
  },
  {
    "text": "So in this fourth example,\nI've added a branch,",
    "start": "403940",
    "end": "406975"
  },
  {
    "text": "it looks like here.",
    "start": "406975",
    "end": "409430"
  },
  {
    "text": "So it can remove\nbranches, add branches,",
    "start": "409430",
    "end": "411740"
  },
  {
    "text": "or change the predicted\nvalues in the nodes.",
    "start": "411740",
    "end": "414650"
  },
  {
    "start": "414000",
    "end": "525000"
  },
  {
    "text": "So what do you\nget from all this?",
    "start": "414650",
    "end": "416270"
  },
  {
    "text": "Well, you get a collection\nof prediction models",
    "start": "416270",
    "end": "418430"
  },
  {
    "text": "at each step B.\nAgain, our prediction",
    "start": "418430",
    "end": "421160"
  },
  {
    "text": "is a sum of the predictions\nfor the K trees.",
    "start": "421160",
    "end": "425060"
  },
  {
    "text": "And as I mentioned,\nthe prediction",
    "start": "425060",
    "end": "428490"
  },
  {
    "text": "is that the average of all\nthe predictions for all trees",
    "start": "428490",
    "end": "433349"
  },
  {
    "text": "and for all B, except\nthat since this",
    "start": "433350",
    "end": "435570"
  },
  {
    "text": "is a process which is random and\nit starts in a place and it--",
    "start": "435570",
    "end": "439483"
  },
  {
    "text": "we hope is going to settle\ndown after a while, what's done",
    "start": "439483",
    "end": "441900"
  },
  {
    "text": "is a kind of burn-in.",
    "start": "441900",
    "end": "444000"
  },
  {
    "text": "The first L iterations\nyou actually throw away.",
    "start": "444000",
    "end": "446980"
  },
  {
    "text": "So maybe B is 1,000, L is 100.",
    "start": "446980",
    "end": "450400"
  },
  {
    "text": "That means you ignore the first\n100 steps in the prediction",
    "start": "450400",
    "end": "454810"
  },
  {
    "text": "and you take the average\nof the remaining 900.",
    "start": "454810",
    "end": "457660"
  },
  {
    "text": "So Rob, what I'm seeing here\nis that for any given B,",
    "start": "457660",
    "end": "461790"
  },
  {
    "text": "the bot prediction is\nlike a boosting model,",
    "start": "461790",
    "end": "465220"
  },
  {
    "text": "it's a sum of trees, K trees.",
    "start": "465220",
    "end": "467940"
  },
  {
    "text": "But the difference here is\nthat you got many of those",
    "start": "467940",
    "end": "471135"
  },
  {
    "text": "and you've created\nthese many by having",
    "start": "471135",
    "end": "473700"
  },
  {
    "text": "this randomization in the\ntree selection each time.",
    "start": "473700",
    "end": "476198"
  },
  {
    "text": "That's right.",
    "start": "476198",
    "end": "476740"
  },
  {
    "text": "And another difference\nis you're not",
    "start": "476740",
    "end": "478440"
  },
  {
    "text": "building each tree by a simple\ntree fit to the residual,",
    "start": "478440",
    "end": "482740"
  },
  {
    "text": "you're actually taking\nthe existing tree",
    "start": "482740",
    "end": "484410"
  },
  {
    "text": "and doing a perturbation.",
    "start": "484410",
    "end": "485452"
  },
  {
    "text": "So it's actually kind of\nslower too, you're not fitting",
    "start": "485452",
    "end": "487870"
  },
  {
    "text": "as hard to data each time.",
    "start": "487870",
    "end": "489710"
  },
  {
    "text": "And I think we'll see in\nthe example of this section",
    "start": "489710",
    "end": "491979"
  },
  {
    "text": "that the overfitting is reduced\nby this slower learning.",
    "start": "491980",
    "end": "497350"
  },
  {
    "text": "Another nice thing\nabout BART is not only",
    "start": "497350",
    "end": "499120"
  },
  {
    "text": "do you get, as we'll see,\nquite good predictions,",
    "start": "499120",
    "end": "501400"
  },
  {
    "text": "you get other quantities,\nlike quantiles.",
    "start": "501400",
    "end": "503857"
  },
  {
    "text": "So for example, you can\ntake the percentiles",
    "start": "503857",
    "end": "505690"
  },
  {
    "text": "of the non-predictions as\na measure of uncertainty",
    "start": "505690",
    "end": "510280"
  },
  {
    "text": "of the final prediction.",
    "start": "510280",
    "end": "511540"
  },
  {
    "text": "You get not just one number,\nbut a collection of predictions.",
    "start": "511540",
    "end": "515070"
  },
  {
    "text": "So if you want, say, the 95th\npercentile of the prediction,",
    "start": "515070",
    "end": "518429"
  },
  {
    "text": "you can use the 95th percentile\nof the predictions after",
    "start": "518429",
    "end": "523380"
  },
  {
    "text": "burn-in.",
    "start": "523380",
    "end": "524110"
  },
  {
    "text": "Here's an example onto\na heart data, which",
    "start": "524110",
    "end": "526440"
  },
  {
    "start": "525000",
    "end": "603000"
  },
  {
    "text": "we saw in the book, in\nwhich in the first edition",
    "start": "526440",
    "end": "529680"
  },
  {
    "text": "we applied it to, we\napplied bagging and boosting",
    "start": "529680",
    "end": "532350"
  },
  {
    "text": "in random forest.",
    "start": "532350",
    "end": "533162"
  },
  {
    "text": "And now we're going to see what\nhappens when we apply BART.",
    "start": "533162",
    "end": "535620"
  },
  {
    "text": "So the number of trees\nhere was 200 and the number",
    "start": "535620",
    "end": "538440"
  },
  {
    "text": "of iterations, the B was\nbrought up to 10,000.",
    "start": "538440",
    "end": "542360"
  },
  {
    "text": "And the burn-in here\nis 100, you can see.",
    "start": "542360",
    "end": "545160"
  },
  {
    "text": "Here's the training and\ntest error for boosting,",
    "start": "545160",
    "end": "548009"
  },
  {
    "text": "which you've seen before.",
    "start": "548010",
    "end": "549490"
  },
  {
    "text": "That's the dark blue\nand the dark green.",
    "start": "549490",
    "end": "551820"
  },
  {
    "text": "The BART training\nerror is in gold",
    "start": "551820",
    "end": "554790"
  },
  {
    "text": "and the BART test\nerror is in light blue.",
    "start": "554790",
    "end": "557230"
  },
  {
    "text": "And you can see,\nthe training error",
    "start": "557230",
    "end": "559350"
  },
  {
    "text": "goes down more slowly\nthan in boosting.",
    "start": "559350",
    "end": "561029"
  },
  {
    "text": "Again, this is the evidence that\nit's not fitting nearly as hard,",
    "start": "561030",
    "end": "564090"
  },
  {
    "text": "but the test error is\ncompetitive with boosting.",
    "start": "564090",
    "end": "566920"
  },
  {
    "text": "There it is.",
    "start": "566920",
    "end": "568310"
  },
  {
    "text": "So that's really interesting\nbecause you can see boosting,",
    "start": "568310",
    "end": "573740"
  },
  {
    "text": "as you fit more and more trees,\nreally starts to overfit,",
    "start": "573740",
    "end": "577320"
  },
  {
    "text": "and the training error\nkeeps on going down,",
    "start": "577320",
    "end": "579440"
  },
  {
    "text": "and the test error\nstarts increasing.",
    "start": "579440",
    "end": "581660"
  },
  {
    "text": "But it's showing behavior\nmore like random forest, where",
    "start": "581660",
    "end": "586009"
  },
  {
    "text": "once you reach a certain number\nof trees, it just flattens off",
    "start": "586010",
    "end": "589040"
  },
  {
    "text": "and it doesn't seem to overfit.",
    "start": "589040",
    "end": "592680"
  },
  {
    "text": "It's not as aggressive, which\nis one of the selling points.",
    "start": "592680",
    "end": "595510"
  },
  {
    "text": "As we say, it'll work\nwell out-of-the-box,",
    "start": "595510",
    "end": "597870"
  },
  {
    "text": "you don't need to tune it very\nmuch because it's not as prone",
    "start": "597870",
    "end": "600440"
  },
  {
    "text": "to overfitting as,\nsay, boosting is.",
    "start": "600440",
    "end": "602460"
  },
  {
    "text": "So where do these\nperturbations come from?",
    "start": "602460",
    "end": "604410"
  },
  {
    "start": "603000",
    "end": "694000"
  },
  {
    "text": "Are they just pulled\nout of the air?",
    "start": "604410",
    "end": "605670"
  },
  {
    "text": "Well, it turns out it's\na Bayesian method, hence",
    "start": "605670",
    "end": "607670"
  },
  {
    "text": "the name Bayesian\nadditive regression trees.",
    "start": "607670",
    "end": "610070"
  },
  {
    "text": "And we didn't talk much in the\nbook about Bayesian methods,",
    "start": "610070",
    "end": "612790"
  },
  {
    "text": "we talked a little bit about\nBayes' rule and Bayes' methods.",
    "start": "612790",
    "end": "615290"
  },
  {
    "text": "But the Bayesian method starts\nwith a prior on the parameters,",
    "start": "615290",
    "end": "618980"
  },
  {
    "text": "you collect the data, you\nhave a sampling model,",
    "start": "618980",
    "end": "622060"
  },
  {
    "text": "you then combine the prior\nand the sampling model",
    "start": "622060",
    "end": "624130"
  },
  {
    "text": "to get a posterior distribution.",
    "start": "624130",
    "end": "625880"
  },
  {
    "text": "Well, it turns out that\nthe perturbations in BART",
    "start": "625880",
    "end": "628690"
  },
  {
    "text": "correspond to a certain prior\ndistribution on the parameters.",
    "start": "628690",
    "end": "632030"
  },
  {
    "text": "The parameters here being the\nsplit points and the values",
    "start": "632030",
    "end": "635470"
  },
  {
    "text": "at the terminal nodes.",
    "start": "635470",
    "end": "636769"
  },
  {
    "text": "So we won't go into detail\nhere, but it's a Bayesian method",
    "start": "636770",
    "end": "639460"
  },
  {
    "text": "under a certain prior.",
    "start": "639460",
    "end": "640555"
  },
  {
    "text": "And what we're doing\nwith these perturbations",
    "start": "640555",
    "end": "642430"
  },
  {
    "text": "is actually drawing from\nthe posterior distribution",
    "start": "642430",
    "end": "644890"
  },
  {
    "text": "from that model.",
    "start": "644890",
    "end": "646990"
  },
  {
    "text": "Furthermore, the\nalgorithm can be",
    "start": "646990",
    "end": "648790"
  },
  {
    "text": "viewed as a Markov chain\nMonte Carlo, MCMC method,",
    "start": "648790",
    "end": "651759"
  },
  {
    "text": "for fitting the BART model.",
    "start": "651760",
    "end": "653560"
  },
  {
    "text": "MCMC is a standard way of\ndrawing from a posterior",
    "start": "653560",
    "end": "656770"
  },
  {
    "text": "distribution from\na Bayesian model.",
    "start": "656770",
    "end": "658800"
  },
  {
    "text": "So the point is that\nthis method, which",
    "start": "658800",
    "end": "661600"
  },
  {
    "text": "may seem kind of ad hoc, it's\ngrounded in statistical theory.",
    "start": "661600",
    "end": "666329"
  },
  {
    "text": "It's a real posterior\ndistribution",
    "start": "666330",
    "end": "667890"
  },
  {
    "text": "from an actual\nprior distribution.",
    "start": "667890",
    "end": "669840"
  },
  {
    "text": "And we typically choose values\nfor B and K that are large",
    "start": "669840",
    "end": "673830"
  },
  {
    "text": "and the burn-in is\npretty moderate.",
    "start": "673830",
    "end": "675780"
  },
  {
    "text": "So, for example, a reasonable\nchoice might be 200 sets",
    "start": "675780",
    "end": "678570"
  },
  {
    "text": "of trees, 1,000 iterations, or\nwe did 10,000 of that example,",
    "start": "678570",
    "end": "683010"
  },
  {
    "text": "and a burn-in of about 100.",
    "start": "683010",
    "end": "685050"
  },
  {
    "text": "And as I mentioned, was selling\npoint of BART is that it works",
    "start": "685050",
    "end": "687899"
  },
  {
    "text": "well right out-of-the-box\nwithout much tuning,",
    "start": "687900",
    "end": "690580"
  },
  {
    "text": "which we saw also with\nrandom forests and bagging.",
    "start": "690580",
    "end": "694070"
  }
]
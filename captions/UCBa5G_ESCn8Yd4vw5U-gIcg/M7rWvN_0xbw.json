[
  {
    "start": "0",
    "end": "6000"
  },
  {
    "start": "0",
    "end": "5760"
  },
  {
    "text": "Hi, In this module, I'm going\nto talk about Laplace Smoothing",
    "start": "5760",
    "end": "8640"
  },
  {
    "start": "6000",
    "end": "11000"
  },
  {
    "text": "for guarding\nagainst overfitting.",
    "start": "8640",
    "end": "11330"
  },
  {
    "start": "11000",
    "end": "109000"
  },
  {
    "text": "So let's review maximum\nlikelihood estimation",
    "start": "11330",
    "end": "14120"
  },
  {
    "text": "in Bayesian networks.",
    "start": "14120",
    "end": "15710"
  },
  {
    "text": "Remember last time,\nwe had an example",
    "start": "15710",
    "end": "17420"
  },
  {
    "text": "of a two variable network,\nit's genre of a movie",
    "start": "17420",
    "end": "21290"
  },
  {
    "text": "and the rating of a movie,\nwhere their joint distribution",
    "start": "21290",
    "end": "24320"
  },
  {
    "text": "is given by probability\nof a genre times",
    "start": "24320",
    "end": "27110"
  },
  {
    "text": "probability of rating given.",
    "start": "27110",
    "end": "29890"
  },
  {
    "text": "And now, we don't\nknow these parameters,",
    "start": "29890",
    "end": "32279"
  },
  {
    "text": "but we want to estimate\nthem from data.",
    "start": "32280",
    "end": "34440"
  },
  {
    "text": "Suppose we gather\nfive data points here.",
    "start": "34440",
    "end": "38680"
  },
  {
    "text": "And the way that maximum\nlikelihood estimation works",
    "start": "38680",
    "end": "41460"
  },
  {
    "text": "is by counting and normalizing.",
    "start": "41460",
    "end": "44550"
  },
  {
    "text": "Parameters here are\nprobability of g.",
    "start": "44550",
    "end": "48000"
  },
  {
    "text": "And for that, I'm going to count\nthe number of times g goes up,",
    "start": "48000",
    "end": "52470"
  },
  {
    "text": "and normalize.",
    "start": "52470",
    "end": "54390"
  },
  {
    "text": "And for probability\nof r given g,",
    "start": "54390",
    "end": "58530"
  },
  {
    "text": "I'm going to look at\nthe number of times",
    "start": "58530",
    "end": "60210"
  },
  {
    "text": "each of these\nconfigurations shows up.",
    "start": "60210",
    "end": "62670"
  },
  {
    "text": "And then I'm going to\nnormalize each one, conditioned",
    "start": "62670",
    "end": "66630"
  },
  {
    "text": "on the value of g.",
    "start": "66630",
    "end": "67916"
  },
  {
    "start": "67916",
    "end": "70690"
  },
  {
    "text": "So if you look at\nthese estimates,",
    "start": "70690",
    "end": "72760"
  },
  {
    "text": "you might notice that there's\nsomething funny going on here.",
    "start": "72760",
    "end": "76610"
  },
  {
    "text": "So the probability\nthat these parameters",
    "start": "76610",
    "end": "81010"
  },
  {
    "text": "assigned to a rating of 2, given\nthat there's a comedy, is 0.",
    "start": "81010",
    "end": "86110"
  },
  {
    "text": "It doesn't show up in this\nrow at this table, which",
    "start": "86110",
    "end": "88780"
  },
  {
    "text": "means that it's 0.",
    "start": "88780",
    "end": "90729"
  },
  {
    "text": "So do we really believe this?",
    "start": "90730",
    "end": "93250"
  },
  {
    "text": "Just because we didn't see\nan example of a comedy being",
    "start": "93250",
    "end": "97210"
  },
  {
    "text": "rated as a 2, are\nwe licensed to just",
    "start": "97210",
    "end": "99534"
  },
  {
    "text": "give it a probability of 0?",
    "start": "99535",
    "end": "100660"
  },
  {
    "text": "Well, that would be\nvery closed minded.",
    "start": "100660",
    "end": "103390"
  },
  {
    "text": "So this is a case where maximum\nlikelihood has [INAUDIBLE]",
    "start": "103390",
    "end": "106090"
  },
  {
    "text": "overfit to [INAUDIBLE].",
    "start": "106090",
    "end": "109450"
  },
  {
    "start": "109000",
    "end": "225000"
  },
  {
    "text": "There's a very simple way to fix\nthis, called Laplace smoothing.",
    "start": "109450",
    "end": "113630"
  },
  {
    "text": "And the idea is that\nwe're just going",
    "start": "113630",
    "end": "115549"
  },
  {
    "text": "to add a lambda, which\nis some positive value,",
    "start": "115550",
    "end": "120380"
  },
  {
    "text": "let's say 1, to each count.",
    "start": "120380",
    "end": "123040"
  },
  {
    "text": "Let's do a maximum likelihood\nwith Laplace smoothing.",
    "start": "123040",
    "end": "125945"
  },
  {
    "text": "So the training data\nis the same as before.",
    "start": "125945",
    "end": "129090"
  },
  {
    "text": "And what we're going\nto do is, for each",
    "start": "129090",
    "end": "130789"
  },
  {
    "text": "of these local distributions,\nwe're going to preset,",
    "start": "130789",
    "end": "134390"
  },
  {
    "text": "preload a 1, lambda, more\ngenerally, into this position.",
    "start": "134390",
    "end": "140310"
  },
  {
    "text": "And now I'm going to\ngo through the training",
    "start": "140310",
    "end": "142330"
  },
  {
    "text": "and count as usual.",
    "start": "142330",
    "end": "143360"
  },
  {
    "text": "So I had 3.",
    "start": "143360",
    "end": "144080"
  },
  {
    "text": "And I had 2.",
    "start": "144080",
    "end": "145610"
  },
  {
    "text": "And then I'm going to normalize\nover these combined counts.",
    "start": "145610",
    "end": "151070"
  },
  {
    "text": "And same with the probability\nof r given g, for each",
    "start": "151070",
    "end": "156830"
  },
  {
    "text": "of these configurations.",
    "start": "156830",
    "end": "159600"
  },
  {
    "text": "So now I have to\nactually instantiate",
    "start": "159600",
    "end": "161780"
  },
  {
    "text": "all possible configurations.",
    "start": "161780",
    "end": "163640"
  },
  {
    "text": "I'm going to load a 1\ninto each of these counts.",
    "start": "163640",
    "end": "169400"
  },
  {
    "text": "And then I'm going to\nlook at my training data.",
    "start": "169400",
    "end": "172319"
  },
  {
    "text": "And I'm going to add 2.",
    "start": "172320",
    "end": "173810"
  },
  {
    "text": "There's two d4's, 1\nd5, 1 c1, and 1 c5.",
    "start": "173810",
    "end": "179023"
  },
  {
    "text": "Now, given these\ncounts, I'm going",
    "start": "179023",
    "end": "180440"
  },
  {
    "text": "to normalize to get\nmy probability emit,",
    "start": "180440",
    "end": "183170"
  },
  {
    "text": "look at all of the d's,\nadd them up, normalize.",
    "start": "183170",
    "end": "186319"
  },
  {
    "text": "I get some d's here.",
    "start": "186320",
    "end": "189860"
  },
  {
    "text": "And look at all\nthe case rows where",
    "start": "189860",
    "end": "192920"
  },
  {
    "text": "[INAUDIBLE],, I'm going\nto come [INAUDIBLE]..",
    "start": "192920",
    "end": "198750"
  },
  {
    "text": "So now, while we\nrevisit our probability",
    "start": "198750",
    "end": "202010"
  },
  {
    "text": "estimate of r equals 2, given\ng equals c, this was 0 before.",
    "start": "202010",
    "end": "208549"
  },
  {
    "text": "But now, it's here,\nthat's 1 over 7,",
    "start": "208550",
    "end": "212300"
  },
  {
    "text": "which is greater than 0.",
    "start": "212300",
    "end": "214250"
  },
  {
    "text": "So now, because we\nsmooth these estimates,",
    "start": "214250",
    "end": "216860"
  },
  {
    "text": "now we have a little\nbit more probability",
    "start": "216860",
    "end": "219260"
  },
  {
    "text": "on even those outcomes\nthat we've never",
    "start": "219260",
    "end": "222319"
  },
  {
    "text": "seen during training.",
    "start": "222320",
    "end": "226100"
  },
  {
    "start": "225000",
    "end": "287000"
  },
  {
    "text": "So the key idea behind maximum\nlikelihood with Laplace",
    "start": "226100",
    "end": "229100"
  },
  {
    "text": "smoothing is as follows.",
    "start": "229100",
    "end": "231950"
  },
  {
    "text": "So we're going to go\nthrough each distribution",
    "start": "231950",
    "end": "235690"
  },
  {
    "text": "and partial assignment\nto the parents of a node",
    "start": "235690",
    "end": "240430"
  },
  {
    "text": "and the node itself.",
    "start": "240430",
    "end": "242590"
  },
  {
    "text": "And we're simply going to\nadd lambda to the count.",
    "start": "242590",
    "end": "247640"
  },
  {
    "text": "Now we do maximum likelihood\nestimation as usual,",
    "start": "247640",
    "end": "251150"
  },
  {
    "text": "though we're going to go\nthrough the training data",
    "start": "251150",
    "end": "253280"
  },
  {
    "text": "and increment those counts,\nbased on what we saw.",
    "start": "253280",
    "end": "256667"
  },
  {
    "text": "And then recount and normalize.",
    "start": "256667",
    "end": "257958"
  },
  {
    "text": "And that's it.",
    "start": "257959",
    "end": "260060"
  },
  {
    "text": "So the interpretation that we\ncan place on Laplace smoothing",
    "start": "260060",
    "end": "263510"
  },
  {
    "text": "is it's like we hallucinated\nlambda occurrences",
    "start": "263510",
    "end": "267470"
  },
  {
    "text": "of each local assignment.",
    "start": "267470",
    "end": "269270"
  },
  {
    "text": "So sometimes,\nthese lambda counts",
    "start": "269270",
    "end": "271759"
  },
  {
    "text": "are called pseudo counts.",
    "start": "271760",
    "end": "272937"
  },
  {
    "text": "Because they're not\nbased on the data,",
    "start": "272937",
    "end": "274520"
  },
  {
    "text": "they're kind of made\nup or virtual counts.",
    "start": "274520",
    "end": "277759"
  },
  {
    "text": "So you can think\nabout pretending",
    "start": "277760",
    "end": "279260"
  },
  {
    "text": "you saw some examples\nbefore you saw data,",
    "start": "279260",
    "end": "282890"
  },
  {
    "text": "and then doing maximum\nlikelihood estimation.",
    "start": "282890",
    "end": "285497"
  },
  {
    "start": "285497",
    "end": "288180"
  },
  {
    "start": "287000",
    "end": "376000"
  },
  {
    "text": "So how much should lambda be?",
    "start": "288180",
    "end": "292333"
  },
  {
    "text": "How much smoothing\nshould we have?",
    "start": "292333",
    "end": "293750"
  },
  {
    "text": "And how does it\ninteract with the data?",
    "start": "293750",
    "end": "296125"
  },
  {
    "text": "There's two observations\nthat I want to make.",
    "start": "296125",
    "end": "298000"
  },
  {
    "text": "First is that the\nmore you smooth,",
    "start": "298000",
    "end": "301080"
  },
  {
    "text": "which means that the more,\nthe bigger the lambda is,",
    "start": "301080",
    "end": "304530"
  },
  {
    "text": "the closer you're going\nto push the probability",
    "start": "304530",
    "end": "306720"
  },
  {
    "text": "estimates closer to the\nuniform distribution.",
    "start": "306720",
    "end": "310060"
  },
  {
    "text": "So for example, if I just\nsmooth with lambda equals 1/2,",
    "start": "310060",
    "end": "314625"
  },
  {
    "text": "and I observe only a d here,\nthen the probability estimates",
    "start": "314625",
    "end": "318600"
  },
  {
    "text": "are going to be 3/4 and 1/4.",
    "start": "318600",
    "end": "321000"
  },
  {
    "text": "Whereas, if I smooth with\n1, then the probabilities",
    "start": "321000",
    "end": "324840"
  },
  {
    "text": "are going to be 2/3 and 1/3,\nwhich is closer to half half.",
    "start": "324840",
    "end": "329910"
  },
  {
    "text": "The second observation\nI want to make",
    "start": "329910",
    "end": "331500"
  },
  {
    "text": "is that no matter what\nyou set lambda to,",
    "start": "331500",
    "end": "334710"
  },
  {
    "text": "the data wins out in the end.",
    "start": "334710",
    "end": "337210"
  },
  {
    "text": "So suppose we only see\nexamples of dramas, g.",
    "start": "337210",
    "end": "341740"
  },
  {
    "text": "So suppose that we're\nsmoothing with lambda equals 1,",
    "start": "341740",
    "end": "345880"
  },
  {
    "text": "and we saw only one\nexample of g equals 1.",
    "start": "345880",
    "end": "349350"
  },
  {
    "text": "Then, again, the probability\nestimates are 2/3 and 1/3.",
    "start": "349350",
    "end": "354020"
  },
  {
    "text": "But suppose we keep on seeing\ndramas over and over again,",
    "start": "354020",
    "end": "358590"
  },
  {
    "text": "so we see 998 of them.",
    "start": "358590",
    "end": "361100"
  },
  {
    "text": "And now, if we\naccount and normalize,",
    "start": "361100",
    "end": "364460"
  },
  {
    "text": "then we get the\nprobability estimate",
    "start": "364460",
    "end": "366080"
  },
  {
    "text": "is 0.999 of drama, which is much\ncloser to seeing only dramas.",
    "start": "366080",
    "end": "372935"
  },
  {
    "start": "372935",
    "end": "376740"
  },
  {
    "start": "376000",
    "end": "422000"
  },
  {
    "text": "So to summarize, we\nlooked at Laplace",
    "start": "376740",
    "end": "382910"
  },
  {
    "text": "smoothing for avoiding\noverfitting and estimating",
    "start": "382910",
    "end": "386290"
  },
  {
    "text": "Bayesian networks.",
    "start": "386290",
    "end": "387500"
  },
  {
    "text": "And the key idea is that we\npreload counts with a lambda.",
    "start": "387500",
    "end": "393200"
  },
  {
    "text": "And then we're going\nto go to training data",
    "start": "393200",
    "end": "395120"
  },
  {
    "text": "and we add counts\nbased on our data.",
    "start": "395120",
    "end": "398570"
  },
  {
    "text": "And then we normalize.",
    "start": "398570",
    "end": "401260"
  },
  {
    "text": "So the smoothing pulls\nus away from zeros",
    "start": "401260",
    "end": "406690"
  },
  {
    "text": "to the uniform distribution.",
    "start": "406690",
    "end": "409430"
  },
  {
    "text": "But in the end,\nall the smoothing",
    "start": "409430",
    "end": "412660"
  },
  {
    "text": "gets washed out with more data.",
    "start": "412660",
    "end": "415360"
  },
  {
    "text": "That's the end.",
    "start": "415360",
    "end": "417210"
  },
  {
    "start": "417210",
    "end": "421419"
  }
]
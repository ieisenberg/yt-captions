[
  {
    "text": "It's my pleasure to\nwelcome Jan from OpenAI. He leads the\nalignment team there. And he was previously a\nresearcher at DeepMind as well.",
    "start": "5799",
    "end": "13150"
  },
  {
    "text": "Holds a PhD in reinforcement\nlearning theory, has been thinking about the\nalignment problem for over 10",
    "start": "13150",
    "end": "18279"
  },
  {
    "text": "years. And today, he'll be giving\na very interesting talk. So I hope you guys enjoy. Yeah, thanks a\nlot for the intro.",
    "start": "18279",
    "end": "25810"
  },
  {
    "text": "And Thanks a lot for having me. I'm very excited to\ntalk about this stuff.",
    "start": "25810",
    "end": "31168"
  },
  {
    "text": "I'm also super happy\nto keep it interactive. If you have questions at any\npoint, please interrupt me.",
    "start": "31169",
    "end": "36680"
  },
  {
    "text": "And yeah, I wanted to start\nout with a few very basic",
    "start": "36680",
    "end": "43730"
  },
  {
    "text": "observations on what\nI think is going on.",
    "start": "43730",
    "end": "49030"
  },
  {
    "text": "And so the first one is\nTeam AI is joining the game.",
    "start": "49030",
    "end": "55850"
  },
  {
    "text": "So Team AI have a lot\nof different players. They all joined\nat the same time.",
    "start": "55850",
    "end": "62820"
  },
  {
    "text": "But rather, they\njoined one by one. And not all-- their players\nare varying a lot in how good",
    "start": "62820",
    "end": "69960"
  },
  {
    "text": "they are. And right now, a lot of the\nplayers that have gone so far aren't really that\nsmart and usually can",
    "start": "69960",
    "end": "77390"
  },
  {
    "text": "do it on a very narrow\nset of [INAUDIBLE]..",
    "start": "77390",
    "end": "83060"
  },
  {
    "text": "But one thing that\nwe've kind of observed is that over time, we're\nseeing stronger and stronger",
    "start": "83060",
    "end": "90670"
  },
  {
    "text": "players join. And this is kind of\nwhere we are now. And then in general, we\nexpect that Team AI has",
    "start": "90670",
    "end": "98990"
  },
  {
    "text": "some incredibly strong players. So those will be\nplayers that are able to think so much\nbetter than humans,",
    "start": "98990",
    "end": "106188"
  },
  {
    "text": "so much faster, and\nso much more cheaply. And these haven't joined yet.",
    "start": "106189",
    "end": "113398"
  },
  {
    "text": "And so the kind of anchor\npoint that we have, if you think, for\nexample, about ChatGPT,",
    "start": "113399",
    "end": "121680"
  },
  {
    "text": "ChatGPT can already beat any\nhuman at knowing more facts or speaking more languages.",
    "start": "121680",
    "end": "128890"
  },
  {
    "text": "And it can write about And it can do so about 100\ntimes cheaper than humans",
    "start": "128890",
    "end": "135750"
  },
  {
    "text": "could at a minimum wage. And so there's the-- ChatGPT also has some really\nimportant limitations.",
    "start": "135750",
    "end": "144810"
  },
  {
    "text": "And there's a lot of things\nthat it can't do yet. But it is kind of an indicator\nof some of the players",
    "start": "144810",
    "end": "153920"
  },
  {
    "text": "that be able to\njoin in the future. And so it seems like\nin the long run,",
    "start": "153920",
    "end": "161540"
  },
  {
    "text": "Team AI will have all the\nadvantages over team human.",
    "start": "161540",
    "end": "166870"
  },
  {
    "text": "But-- and there's one-- there's\nan important caveat, which is there's one important\nadvantage that humans have,",
    "start": "166870",
    "end": "176800"
  },
  {
    "text": "which is Team Human gets to pick\nwhich players from Team AI join and when.",
    "start": "176800",
    "end": "183650"
  },
  {
    "text": "And so this is kind of an\nadvantage that we should really be leaning into when we're\nthinking about what to do",
    "start": "183650",
    "end": "190890"
  },
  {
    "text": "and when we're thinking\nabout this game that we're playing with Team\nAI and that we'll be playing",
    "start": "190890",
    "end": "196430"
  },
  {
    "text": "with Team AI in the future. So I think two of the\nmain objectives of what",
    "start": "196430",
    "end": "205180"
  },
  {
    "text": "we as Team Human\nshould do is first, we should try to recruit\nplayers from Team AI",
    "start": "205180",
    "end": "212430"
  },
  {
    "text": "to play on Team Human. And so this is kind of what I\nwould broadly call alignment.",
    "start": "212430",
    "end": "220200"
  },
  {
    "text": "And this is kind of like the\nproblem that I'm working on. And then there is\nalso other objectives.",
    "start": "220200",
    "end": "225489"
  },
  {
    "text": "So another objective\nthat I think is going to be\nreally important is you want to write\nthe rules of the game",
    "start": "225489",
    "end": "230970"
  },
  {
    "text": "so that Team Human doesn't lose. And right now, Team Human\nkind of has the ball.",
    "start": "230970",
    "end": "236310"
  },
  {
    "text": "And we get to write the rules. So we should write\nrules that make sense",
    "start": "236310",
    "end": "241769"
  },
  {
    "text": "and that we'll play\nthis game in the future. And so in this\ntalk, I won't really",
    "start": "241769",
    "end": "248930"
  },
  {
    "text": "talk about the\nsecond point at all. And I will talk\nabout the first point because that's what I know.",
    "start": "248930",
    "end": "254950"
  },
  {
    "text": "That's what I'm working on. And perhaps to phrase\nit differently, or to make it more\npractical, one way",
    "start": "254950",
    "end": "265050"
  },
  {
    "text": "I'm thinking about\nalignment is we want to build systems\nthat follow human intent",
    "start": "265050",
    "end": "270520"
  },
  {
    "text": "and that follow human\npreferences, that do we want them to do.",
    "start": "270520",
    "end": "276630"
  },
  {
    "text": "And so a bunch of the\nthings, basically, I'll talk about two main things. The first part is going\nto be work that we've",
    "start": "276630",
    "end": "284940"
  },
  {
    "text": "done in the past, and kind of-- which roughly is\nin the bucket of we",
    "start": "284940",
    "end": "291390"
  },
  {
    "text": "are trying to figure\nout how we can make the models that we have\ntoday as aligned as we can.",
    "start": "291390",
    "end": "299919"
  },
  {
    "text": "And you just try and--\ntry hard to do this,",
    "start": "299919",
    "end": "305190"
  },
  {
    "text": "and we'll see how far we get. And then the second\nbucket is the things that we have to do next, the\nstuff that we haven't done yet",
    "start": "305190",
    "end": "311020"
  },
  {
    "text": "that we think are going\nto be really important. And I want to kind of\nlay out why I think",
    "start": "311020",
    "end": "319100"
  },
  {
    "text": "they're going to be important. So now, I said I'm trying to\nmake this more clear, or more",
    "start": "319100",
    "end": "326910"
  },
  {
    "text": "broken down, what\nalignment means. [INAUDIBLE] here, because\nnow, the big question is, what does it mean\nto follow human intent?",
    "start": "326910",
    "end": "335120"
  },
  {
    "text": "And two main categories of\ncontent that we care about is, I would say,\nexplicit intent,",
    "start": "335120",
    "end": "341509"
  },
  {
    "text": "if you give the\nsystem an instruction, or if it want it\nto be my assistant,",
    "start": "341510",
    "end": "347100"
  },
  {
    "text": "it should be my assistant. It should follow\nthe instruction. But then there's also\nall these other intents.",
    "start": "347100",
    "end": "353300"
  },
  {
    "text": "And I don't say,\nwhen I'm usually talking to a system or a human,\nthat I also really care about. It shouldn't literally\nalways do what they say,",
    "start": "353300",
    "end": "361060"
  },
  {
    "text": "but the thing that I mean. It shouldn't make up stuff. And it shouldn't\ndo harmful things.",
    "start": "361060",
    "end": "366550"
  },
  {
    "text": "And it should ask\nfollow-up questions when it's not sure what I\nmean, and so on, and so on.",
    "start": "366550",
    "end": "374009"
  },
  {
    "text": "And so these are\nall kind of things that are often just really\ndifficult to precisely specify",
    "start": "374009",
    "end": "384110"
  },
  {
    "text": "or precisely [INAUDIBLE]. But it is still things that\nwe want to get AI to do. And then we have to figure\nout how to get into it.",
    "start": "384110",
    "end": "395199"
  },
  {
    "text": "And so kind of like\nthe main technique that we're using today for this\nis what we call reinforcement",
    "start": "395199",
    "end": "401080"
  },
  {
    "text": "learning feedback. So that was used to train\nInstructGPT and ChatGPT, which are the two main systems\nI'll talk about in this part.",
    "start": "401080",
    "end": "408180"
  },
  {
    "text": "And basically, the basic\nsystem is very simple. And it's also like a\nsuper general technique",
    "start": "408180",
    "end": "416280"
  },
  {
    "text": "that applies to lots\nof different AI models, and modalities, and settings. But in this case, it\nwill be the [INAUDIBLE]..",
    "start": "416280",
    "end": "424750"
  },
  {
    "text": "And so two steps is actually\nanother step of [INAUDIBLE]",
    "start": "424750",
    "end": "430450"
  },
  {
    "text": "to stop for the\nsake of simplicity. First up is you want to train a\nreward model from comparisons.",
    "start": "430450",
    "end": "440629"
  },
  {
    "text": "So you have [INAUDIBLE] in\nthis case, explain [INAUDIBLE] field.",
    "start": "440629",
    "end": "446460"
  },
  {
    "text": "Or help me with my term\npaper, whatever it is. And then the model\ndoes a bunch of things.",
    "start": "446460",
    "end": "452900"
  },
  {
    "text": "And then you rate which\none is closest to the thing that you intended\nthe model to do. And so you have a bigger\nset of preferences. And you're training one model.",
    "start": "452900",
    "end": "460139"
  },
  {
    "text": "One model basically just\n[INAUDIBLE] which one would you prefer.",
    "start": "460139",
    "end": "466220"
  },
  {
    "text": "Everything OK? I would say I just\nstand more in front of the camera as possible.",
    "start": "466220",
    "end": "472210"
  },
  {
    "text": "Sorry about that. Maybe let's try [INAUDIBLE]. OK, so OK, so now we\nhave this reward model",
    "start": "472210",
    "end": "484340"
  },
  {
    "text": "that captures kind\nof our preferences, and what we care about, and what\nwe intend for the model to do.",
    "start": "484340",
    "end": "489990"
  },
  {
    "text": "And then the second step is now\nyou optimize the reward model with the reinforcement learning.",
    "start": "489990",
    "end": "495190"
  },
  {
    "text": "And so not that a-- the model tries a whole\nbunch of different things. And the reward model tells\nit which one of these things",
    "start": "495190",
    "end": "503840"
  },
  {
    "text": "is probably more like the\nthing that [INAUDIBLE].. Yep? When you say\ncomparison, does that mean by a human labeler\ngoes in the data?",
    "start": "503840",
    "end": "509780"
  },
  {
    "text": "Yeah, and all [INAUDIBLE]\nthat depends on the label? They will depend on the labeler.",
    "start": "509780",
    "end": "515090"
  },
  {
    "text": "Different labelers will\nhave different preferences.",
    "start": "515090",
    "end": "520140"
  },
  {
    "text": "They also might be\ninconsistencies. And you can give examples\nin front of the preferences.",
    "start": "520140",
    "end": "528270"
  },
  {
    "text": "But those haven't really\nbeen a problem in practice. And so far, our labelers\noften don't agree.",
    "start": "528270",
    "end": "536750"
  },
  {
    "text": "But the model will\naverage RL [INAUDIBLE].. Yeah, so this is like\nthe basic technique.",
    "start": "536750",
    "end": "545420"
  },
  {
    "text": "It's conceptually\nlike quite simple. You can make it\neven simpler if you",
    "start": "545420",
    "end": "553769"
  },
  {
    "text": "didn't train the\nreward model and you labeled every [INAUDIBLE]. But it would be a lot\nless data efficient.",
    "start": "553769",
    "end": "560410"
  },
  {
    "text": "And so you could--\ntraining a reward model to think of a data [INAUDIBLE]. So how will it work?",
    "start": "560410",
    "end": "567300"
  },
  {
    "text": "So this is kind of like\none of the main thoughts",
    "start": "567300",
    "end": "572740"
  },
  {
    "text": "from the InstructGPT paper. And it's the one that I'm\nsharing because it really blew my mind.",
    "start": "572740",
    "end": "578550"
  },
  {
    "text": "And it still does. What do we see here? So on the x-axis, you see this\nis one of the PP3 model matrix",
    "start": "578550",
    "end": "584750"
  },
  {
    "text": "and you see this is three\ndifferent types of models over two orders of magnitude. And on the y-axis is\nhow well does the model",
    "start": "584750",
    "end": "590430"
  },
  {
    "text": "score on human preferences. So if you show a bunch\nof samples to humans,",
    "start": "590430",
    "end": "597710"
  },
  {
    "text": "how likely are they to\nprefer one over the other?",
    "start": "597710",
    "end": "604260"
  },
  {
    "text": "And then what we see is\nthat even the largest PP3 model is dispreferred to the\nsmallest InstructGPT variant.",
    "start": "604260",
    "end": "613780"
  },
  {
    "text": "And so the 100x\nsmaller Instruct model",
    "start": "613780",
    "end": "619940"
  },
  {
    "text": "is actually preferred over\nthe much larger [INAUDIBLE] like GPT, [INAUDIBLE] model.",
    "start": "619940",
    "end": "627170"
  },
  {
    "text": "And that's kind of wild. Let me just finish my thought.",
    "start": "627170",
    "end": "633600"
  },
  {
    "text": "So why-- why is\nthis [INAUDIBLE]?? So basically, it basically shows\nthat they would [INAUDIBLE]",
    "start": "633600",
    "end": "641800"
  },
  {
    "text": "be on the line [INAUDIBLE]\nmaking it a whole lot more",
    "start": "641800",
    "end": "648519"
  },
  {
    "text": "useful than giving [INAUDIBLE]. Or fine-tuning works, then\nnobody want to use it.",
    "start": "648519",
    "end": "654880"
  },
  {
    "text": "And make all these fancy\nalignments techniques that don't get adopted.",
    "start": "654880",
    "end": "660100"
  },
  {
    "text": "And so what we were-- originally, in\nthe first version,",
    "start": "660100",
    "end": "665389"
  },
  {
    "text": "we saw these regressions. And then what here\nis labeled PPO,",
    "start": "665389",
    "end": "670519"
  },
  {
    "text": "PTX is kind of like a very end,\nwhere we mix in pretraining data into the fine tuning.",
    "start": "670519",
    "end": "676209"
  },
  {
    "text": "And that mitigated a bunch of\nthe regressions that we saw. Yeah? And I just had a quick\nfollow-up to that.",
    "start": "676209",
    "end": "685490"
  },
  {
    "text": "How important is like fidelity\non fine-tuned that you have?",
    "start": "685490",
    "end": "691440"
  },
  {
    "text": "You guys, you collect\ndata from humans, right? What if you were to\nuse some pretrained",
    "start": "691440",
    "end": "696610"
  },
  {
    "text": "[INAUDIBLE] model\nto score [INAUDIBLE] or something like that?",
    "start": "696610",
    "end": "702620"
  },
  {
    "text": "Yeah, you could do that. And there have been\nother papers on that. A topic wrote this\npaper on [INAUDIBLE] AI",
    "start": "702620",
    "end": "709220"
  },
  {
    "text": "was trying to exactly do that. In terms of-- well,\nthere are certain things",
    "start": "709220",
    "end": "715720"
  },
  {
    "text": "that the language model will\nbe able to automatically rank and some things that\nwon't because it won't",
    "start": "715720",
    "end": "722269"
  },
  {
    "text": "know your exact preferences. Or it won't know exactly\nwhat we want it to do.",
    "start": "722269",
    "end": "727459"
  },
  {
    "text": "And so whenever the language\nmodel does something that we disprefer,\nwe actually-- we",
    "start": "727460",
    "end": "734070"
  },
  {
    "text": "have to give it\nanother data point. Or in other words, if\nyou're aligning with humans,",
    "start": "734070",
    "end": "739190"
  },
  {
    "text": "you somehow have to put\nhumans into the loop. So that otherwise,\nhow does the model",
    "start": "739190",
    "end": "745200"
  },
  {
    "text": "know what you are\nsupposed to do? Lots of more questions, I\ndon't know who was first.",
    "start": "745200",
    "end": "753779"
  },
  {
    "text": "Yeah? How many-- approximately\nwhat's-- how many orders of magnitude of human\npreferences do you need",
    "start": "753779",
    "end": "760570"
  },
  {
    "text": "to achieve these-- Yes, I'm going to get\nto that in a second.",
    "start": "760570",
    "end": "771060"
  },
  {
    "text": "[INAUDIBLE] So why did [INAUDIBLE]?",
    "start": "771060",
    "end": "780449"
  },
  {
    "text": "We haven't actually\ncompared, carefully compared across\nall our algorithms. And it could very well\nbe that a different RL",
    "start": "780449",
    "end": "786940"
  },
  {
    "text": "algorithm would be better. That was kind of like-- I know, PPO was invented OpenAI.",
    "start": "786940",
    "end": "793259"
  },
  {
    "text": "So that's why we used it. It's not really a good\nreason other than that. It works also pretty well.",
    "start": "793260",
    "end": "801250"
  },
  {
    "text": "Yes? [INAUDIBLE] Comparisons, this better\nthan this sort of thing.",
    "start": "801250",
    "end": "810470"
  },
  {
    "text": "So usually, we\nhave people compare between three to six\ndifferent responses",
    "start": "810470",
    "end": "816769"
  },
  {
    "text": "from usually different models. Yeah.",
    "start": "816770",
    "end": "822570"
  },
  {
    "text": "So is PPO and the reward\nmodel currently used in ChatGPT in production?",
    "start": "822570",
    "end": "829130"
  },
  {
    "text": "And if so, do you use any\nof the human feedback, you regenerate responses\nand stuff like that, so--",
    "start": "829130",
    "end": "835060"
  },
  {
    "text": "as a reward function as well? How do you mean to regenerate?",
    "start": "835060",
    "end": "840759"
  },
  {
    "text": "There's a button\non ChatGPT where you can say\nregenerate responses, or do you use any implicit\nfeedback, basically in humans?",
    "start": "840759",
    "end": "848190"
  },
  {
    "text": "I don't know what the\ncurrent state is for that. I expect people\nwill try to use it.",
    "start": "848190",
    "end": "853699"
  },
  {
    "text": "But ChatGPT hasn't\nbeen out that long. Yeah.",
    "start": "853699",
    "end": "858910"
  },
  {
    "text": "So I'm curious about this graph. But it seems like increasing parameters\ndoesn't give you that much more like\nfidelity there.",
    "start": "858910",
    "end": "866050"
  },
  {
    "text": "Qualitatively, you have been\ntracking this for a while. Can you tell right\noff the bat if you're like interacting with a one--",
    "start": "866050",
    "end": "872899"
  },
  {
    "text": "model or the 100 billion model\nlike a pseudo Turing test with parameter size? I give you a--",
    "start": "872900",
    "end": "878190"
  },
  {
    "text": "see on how many\nparameters it has? Probably not very precisely.",
    "start": "878190",
    "end": "884180"
  },
  {
    "text": "But I think the big\ncounterquestion is do I get to write the prompt?",
    "start": "884180",
    "end": "890930"
  },
  {
    "text": "So if you just\ndraw random prompts from whatever people put in\nthe OpenAI playground, which is what we use for\nInstructGPT, then I probably",
    "start": "890930",
    "end": "899470"
  },
  {
    "text": "need quite a few to\ntell the difference. But if I get to\nwrite the prompt, I can probably do\nit in one or two,",
    "start": "899470",
    "end": "904839"
  },
  {
    "text": "at least if the task is tell\nthe difference between this and this. I want to-- can I just do\ntwo more slides and maybe",
    "start": "904839",
    "end": "916430"
  },
  {
    "text": "your questions get answered? And then-- so this was the\nquestion about training costs.",
    "start": "916430",
    "end": "922750"
  },
  {
    "text": "So this is another thing\nthat kind of really blew my mind is\ncompared to pretraining,",
    "start": "922750",
    "end": "928120"
  },
  {
    "text": "it is incredibly cheap. So if you look at the amount\nof laps that it takes to train",
    "start": "928120",
    "end": "934480"
  },
  {
    "text": "GPT to [INAUDIBLE]. And then you compare\nit with how much the fine tuning and\nthe pretraining works",
    "start": "934480",
    "end": "942339"
  },
  {
    "text": "and everything, the most\nexpensive InstructGPT variant is less than 2% of the\npretraining compute.",
    "start": "942339",
    "end": "948310"
  },
  {
    "text": "And if you want to train\nan even bigger model, it's going to be more expensive. And you could still use\nthe same fine tuning step",
    "start": "948310",
    "end": "954519"
  },
  {
    "text": "to make it more aligned. And of course, I think\nthe important thing to note also here is we\nhaven't fixed all the problems.",
    "start": "954519",
    "end": "961160"
  },
  {
    "text": "There's important limitations. And so I wouldn't say that\nthis is the last version.",
    "start": "961160",
    "end": "967329"
  },
  {
    "text": "And we wouldn't\ntry to figure out how to spend more compute and\nmore human data in the future. But all in all, it was\nsurprisingly effective.",
    "start": "967329",
    "end": "974750"
  },
  {
    "text": "OK, there were more questions? More questions? Yeah.",
    "start": "974750",
    "end": "980139"
  },
  {
    "text": "I just wanted to ask\nwhat the PTFs were.",
    "start": "980139",
    "end": "985410"
  },
  {
    "text": "Mixing pre-training\ndata into the fine tune, just like mix the gradients.",
    "start": "985410",
    "end": "990730"
  },
  {
    "text": "Yeah? What's the number\npractice for this graph? So you're fixing\n[INAUDIBLE] for this one?",
    "start": "990730",
    "end": "998050"
  },
  {
    "text": "So this is the full\nsize GPT-3 version. So this is the Questions?",
    "start": "998050",
    "end": "1003420"
  },
  {
    "text": "No. OK. [INAUDIBLE] Great.",
    "start": "1003420",
    "end": "1009550"
  },
  {
    "text": "sure, so the first one is--",
    "start": "1009550",
    "end": "1016660"
  },
  {
    "text": "OK, sure. So the first question\nis, how would you deal",
    "start": "1016660",
    "end": "1021740"
  },
  {
    "text": "with [INAUDIBLE] in the limit? Example preferences are\na good proxy for values.",
    "start": "1021740",
    "end": "1027289"
  },
  {
    "text": "But optimizing for\nthem just [INAUDIBLE] to incentivize research. Yes, I'll get to that.",
    "start": "1027290",
    "end": "1033660"
  },
  {
    "text": "Sure, that's the next question. So that is like you want to\nautomate [INAUDIBLE] research,",
    "start": "1033660",
    "end": "1041779"
  },
  {
    "text": "what happens if we need\nconceptual big tools, which are difficult for\nexperts to verify? OK, that would be good to\ntake at the end as well.",
    "start": "1041780",
    "end": "1053220"
  },
  {
    "text": "Sure, let's see. Sorry. I guess one question is how\nwould find getting better",
    "start": "1053220",
    "end": "1059179"
  },
  {
    "text": "on human feedback compared to\nfine tuning of [INAUDIBLE].. Fine tuning-- like\nsupervised fine tuning?",
    "start": "1059180",
    "end": "1064590"
  },
  {
    "text": "It's more like if you actually\nuse the human [INAUDIBLE].. I'm also not sure\nwhat they mean.",
    "start": "1064590",
    "end": "1074700"
  },
  {
    "text": "So I mean, so one\nbaseline was showing here is what if you just take human\ndemonstrations in the sense",
    "start": "1074700",
    "end": "1080389"
  },
  {
    "text": "that we have a bunch\nof tasks, we just ask humans to do them,\nrecord what they did,",
    "start": "1080390",
    "end": "1086029"
  },
  {
    "text": "and then train the\nmodel to imitate that. And here, it's like just very\nbasic behavioral cloning,",
    "start": "1086030",
    "end": "1091580"
  },
  {
    "text": "just using the same laws\nthey use in pretraining. And then it's noticeably\nbetter than the future",
    "start": "1091580",
    "end": "1098140"
  },
  {
    "text": "prompted version. But it's still\nnot as good as RL. And so that's why\nwe like using RL.",
    "start": "1098140",
    "end": "1103639"
  },
  {
    "text": "And basically,\nconceptually, there's two problems with the\nimitating humans approach.",
    "start": "1103640",
    "end": "1109010"
  },
  {
    "text": "One is humans are better at\nsome things than the model is. And they're worse\nat other things.",
    "start": "1109010",
    "end": "1115100"
  },
  {
    "text": "And so the things that\nthe model is worse, you're trying to imitate\nsomething that you can't do.",
    "start": "1115100",
    "end": "1120250"
  },
  {
    "text": "And on the things where\nthe model is better, you're making the model\nworse because you're forcing it to do the thing in\nthe way that the human would.",
    "start": "1120250",
    "end": "1129820"
  },
  {
    "text": "And so with RL, you\nkind of-- with RL HF, you're kind of letting the\nmodel do whatever it wants to.",
    "start": "1129820",
    "end": "1136679"
  },
  {
    "text": "And it can just figure out the\nbest way for it to do things. There's also another\nimportant advantage.",
    "start": "1136679",
    "end": "1143830"
  },
  {
    "text": "And I'm going to get to that. But I briefly I want\nto talk about ChatGPT. So one thing-- I kind\nof think of ChatGPT",
    "start": "1143830",
    "end": "1150429"
  },
  {
    "text": "as like the upgrade\nto InstructGPT. It's kind of like the\nnext step at making the models more aligned\nand more useful to humans.",
    "start": "1150429",
    "end": "1158539"
  },
  {
    "text": "And some things that I\nthink Chat does better is using dialogue as\nthe universal interface.",
    "start": "1158540",
    "end": "1165549"
  },
  {
    "text": "You can talk to it directly. You can ask follow-up questions. You can ask it to refine the\nanswer and all of these things.",
    "start": "1165549",
    "end": "1174090"
  },
  {
    "text": "That makes it a lot\neasier to deal with. It's better at\nrefusing harmful tasks.",
    "start": "1174090",
    "end": "1180600"
  },
  {
    "text": "But it's also-- there's\nstill important limitations. The biggest one is like the\nmodel of hallucinates a lot.",
    "start": "1180600",
    "end": "1187020"
  },
  {
    "text": "It makes up facts when-- for whatever tasks you give it.",
    "start": "1187020",
    "end": "1193991"
  },
  {
    "text": "And that makes it\nquite unreliable. It's also still sensitive to\nprompting which kind of shows",
    "start": "1193991",
    "end": "1199700"
  },
  {
    "text": "that it still has\nimportant misalignment that we need to fix.",
    "start": "1199700",
    "end": "1207420"
  },
  {
    "text": "Really, if a model was like-- models should really do the\ntask to the best of its ability,",
    "start": "1207420",
    "end": "1216210"
  },
  {
    "text": "no matter how you\nprompt it to do that. But yeah, one important\nprinciple that I think",
    "start": "1216210",
    "end": "1225100"
  },
  {
    "text": "is really useful for-- or that [INAUDIBLE] on\na lot is that evaluation",
    "start": "1225100",
    "end": "1230130"
  },
  {
    "text": "is easier than generation. So if we ask humans\nto compare and rank different responses\nthe model gave,",
    "start": "1230130",
    "end": "1237929"
  },
  {
    "text": "it is easier to\ntell the difference between different variants\nof what the model did than it",
    "start": "1237929",
    "end": "1245120"
  },
  {
    "text": "is to do the task itself. Or in other words, you can\ndo the comparisons on tasks.",
    "start": "1245120",
    "end": "1251460"
  },
  {
    "text": "You can still spot\ngood behavior on tasks that you might not be\nable to do by yourself.",
    "start": "1251460",
    "end": "1257250"
  },
  {
    "text": "And so if you're giving\nthis kind of feedback, that lets the system do better\nthan you actually could.",
    "start": "1257250",
    "end": "1266740"
  },
  {
    "text": "And I think that's a very\ngeneral principle that holds in lots of domains.",
    "start": "1266740",
    "end": "1271760"
  },
  {
    "text": "So kind of like you're\nprobably most familiar-- [INAUDIBLE] you know\nthat P versus NP.",
    "start": "1271760",
    "end": "1277768"
  },
  {
    "text": "And everyone-- we don't actually\nknow whether they're different. But in practice, it seems like\nNP tasks are just much harder.",
    "start": "1277769",
    "end": "1284840"
  },
  {
    "text": "It also applies to\nlots of other settings. A lot of professional\nsports, so e-sports just",
    "start": "1284840",
    "end": "1290340"
  },
  {
    "text": "wouldn't be fun to watch\nif you couldn't tell who's winning more easily then\nyou could actually compete",
    "start": "1290340",
    "end": "1296390"
  },
  {
    "text": "on a professional level. It applies to a lot\nof consumer products.",
    "start": "1296390",
    "end": "1301440"
  },
  {
    "text": "You can look at two smart\nphones and tell which one you like more without--",
    "start": "1301440",
    "end": "1306549"
  },
  {
    "text": "that is also deeper than\njust looking at the specs. That is actually pretty high.",
    "start": "1306549",
    "end": "1312720"
  },
  {
    "text": "But it's my phone. It also applies to\nacademic research. It's much easier to review\nyour paper and say what--",
    "start": "1312720",
    "end": "1320230"
  },
  {
    "text": "all the things that are\nbad about it than it is to write a good\npaper yourself.",
    "start": "1320230",
    "end": "1325610"
  },
  {
    "text": "It applies to-- I don't\nknow, when you're--",
    "start": "1325610",
    "end": "1331000"
  },
  {
    "text": "yeah, basically, there's lots\nof domains where this applies. And so I think this is a very--",
    "start": "1331000",
    "end": "1336850"
  },
  {
    "text": "this principle is\nvery useful when we want to align AI systems\non tasks that we might not",
    "start": "1336850",
    "end": "1343350"
  },
  {
    "text": "be able to do ourselves well. So having said that, RL HF\nhas some really important",
    "start": "1343350",
    "end": "1353260"
  },
  {
    "text": "limitations. And I think that's going to\nmake it really difficult to use our RL HF to scale alignment.",
    "start": "1353260",
    "end": "1362940"
  },
  {
    "text": "Let me explain this\nwith the diagram. So basically, on the x-axi,\nlet's plot the AI progress.",
    "start": "1362940",
    "end": "1373950"
  },
  {
    "text": "And on the y-axis, how\ndifficult different tasks are. And then as we have more AI\nprogress, kind of like the task",
    "start": "1373950",
    "end": "1381470"
  },
  {
    "text": "that AI-- the difficulty of tasks\nAI can do goes up. And one of the\nfundamental problems",
    "start": "1381470",
    "end": "1389090"
  },
  {
    "text": "is that the level of tasks that\nhumans can reliably evaluate doesn't go up.",
    "start": "1389090",
    "end": "1395399"
  },
  {
    "text": "Because humans don't get\nbetter with AI progress. And so I think we're\nsomewhere here.",
    "start": "1395400",
    "end": "1402470"
  },
  {
    "text": "But the problem is once\nyou cross this line, you don't really know whether\nyour model is actually",
    "start": "1402470",
    "end": "1411059"
  },
  {
    "text": "doing the right thing\nbecause you can't reliably evaluate it anymore. And so that's kind\nof like the point",
    "start": "1411059",
    "end": "1417890"
  },
  {
    "text": "where RL HF training\nwill start to break down. And what we'll probably see\nis what the question before",
    "start": "1417890",
    "end": "1426190"
  },
  {
    "text": "alluded to is like,\nwell now, the systems are optimized for whatever\nfeedback we give them.",
    "start": "1426190",
    "end": "1432770"
  },
  {
    "text": "And so they will\ntry to tell us what we want to hear, rather all the\nthings that they to be true.",
    "start": "1432770",
    "end": "1438299"
  },
  {
    "text": "And they might learn\nhow to deceive us because that makes it easier\nto score high on preferences.",
    "start": "1438300",
    "end": "1447500"
  },
  {
    "text": "And so kind of the basic\nidea that we want to leverage is related to the\nprinciple I just mentioned,",
    "start": "1447500",
    "end": "1457130"
  },
  {
    "text": "which is evaluation is\neasier than generation. So for example, if you have a\nlarge language model writing",
    "start": "1457130",
    "end": "1463950"
  },
  {
    "text": "a code base, an\nentire code base, there's just no way humans would\nbe able to find all the bugs,",
    "start": "1463950",
    "end": "1469740"
  },
  {
    "text": "and all the flaws\nin the code base. Or the code base could\nhave a Trojan in there.",
    "start": "1469740",
    "end": "1475161"
  },
  {
    "text": "And you might not be able to\ntell because it is so hard. And that's why we see so\nmuch buggy code out there.",
    "start": "1475161",
    "end": "1482180"
  },
  {
    "text": "But if you ask your language\nmodel to find bugs and point them out to you, once\nyou've seen the bug,",
    "start": "1482180",
    "end": "1489720"
  },
  {
    "text": "it's so much easier for you to\nsay, oh yeah, this was a bug. Please fix it.",
    "start": "1489720",
    "end": "1494850"
  },
  {
    "text": "And so now, you've taken the\ntask of [INAUDIBLE] code base down to, well, I\njust have to evaluate",
    "start": "1494850",
    "end": "1501500"
  },
  {
    "text": "whether that was a bug according\nto the spec they had in mind. And so the general principle\nthat we are excited about here",
    "start": "1501500",
    "end": "1509180"
  },
  {
    "text": "is we want to\nleverage AI assistance for human evaluation.",
    "start": "1509180",
    "end": "1515029"
  },
  {
    "text": "And so the hope is\nthat we together, we pair up humans with\nAI, you actually get a line that looks more like\nthis, where humans together",
    "start": "1515029",
    "end": "1522880"
  },
  {
    "text": "with AI can evaluate\nmuch more than they could by on their own.",
    "start": "1522880",
    "end": "1530159"
  },
  {
    "text": "And so to make this\nconcrete, there's like two different\nways you could do that.",
    "start": "1530159",
    "end": "1535260"
  },
  {
    "text": "Or there's many different\nways you could do that. Two I want to highlight. First, you can write-- ask\nAI to write a critique.",
    "start": "1535260",
    "end": "1542129"
  },
  {
    "text": "This is a project\nwe did last year. And in this case, it was a\nsimple summarization task.",
    "start": "1542130",
    "end": "1547840"
  },
  {
    "text": "And we trained a language\nmodel to kind of just say things that are\nwrong with the summary.",
    "start": "1547840",
    "end": "1556080"
  },
  {
    "text": "And there's other\nthings you could do. For example, you can give\npeople ChatGPT and ask them,",
    "start": "1556080",
    "end": "1562150"
  },
  {
    "text": "OK, use ChatGPT to\nhelp you evaluate. And then you could\nask for a critique.",
    "start": "1562150",
    "end": "1567190"
  },
  {
    "text": "Or you could ask for\na lot of other things. You could ask for\nan explanation. You can ask for a fact\nchecking, or a quote,",
    "start": "1567190",
    "end": "1572880"
  },
  {
    "text": "or whatever the model ChatGPT\ncan actually reliably help you with.",
    "start": "1572880",
    "end": "1578750"
  },
  {
    "text": "And so the idea would be that\nlike using AI assistance, you can kind of get all the\nsmarts that AI has and leverage",
    "start": "1578750",
    "end": "1588570"
  },
  {
    "text": "that in order to figure\nout how you should evaluate what this system is\ndoing and whether it's",
    "start": "1588570",
    "end": "1593820"
  },
  {
    "text": "aligned with your\npreferences or whether it's trying to deceive you. And the big problem\nwith this is how do",
    "start": "1593820",
    "end": "1602260"
  },
  {
    "text": "we know whether it's working? And one of the difficulties\nis that by assumption, we're",
    "start": "1602260",
    "end": "1612620"
  },
  {
    "text": "kind of dealing with\na hard task where it's difficult to evaluate. And we also wanted\nthe task to be",
    "start": "1612620",
    "end": "1617779"
  },
  {
    "text": "a real because we want to solve\nsome task that doesn't matter.",
    "start": "1617779",
    "end": "1623990"
  },
  {
    "text": "And so it becomes-- So you need like a\nhard task that is real.",
    "start": "1623990",
    "end": "1630309"
  },
  {
    "text": "But also if you have\nthose, you usually don't have ground truth. So you got no issue\nwith the right answer.",
    "start": "1630309",
    "end": "1636179"
  },
  {
    "text": "And how do you know whether\nassistance is working or it's biasing everyone\nto just say the same thing?",
    "start": "1636179",
    "end": "1642660"
  },
  {
    "text": "And so there's a simple\ntechnique that we use [INAUDIBLE] to do this where--",
    "start": "1642660",
    "end": "1652190"
  },
  {
    "text": "that we call targeted\nperturbations. And so what you do is you\nhave a bunch of prompts. So this could be like whatever\npeople type into ChatGPT.",
    "start": "1652190",
    "end": "1660220"
  },
  {
    "text": "And then you kind of take the\nresponse that you have and say,",
    "start": "1660220",
    "end": "1666350"
  },
  {
    "text": "this is the correct response. It doesn't actually\nhave to be correct. But let's just assume it is. And now, you're asking\na human to introduce",
    "start": "1666350",
    "end": "1673429"
  },
  {
    "text": "some kind of subtle flaw\nthat is easy to miss but is an important flaw.",
    "start": "1673429",
    "end": "1679160"
  },
  {
    "text": "And now, what you have is\nyou have this paired dataset of a good response\nand a bad response.",
    "start": "1679160",
    "end": "1684190"
  },
  {
    "text": "And you know which\none is good and bad because you made it worse. And so in a way, that\ngives you ground truth.",
    "start": "1684190",
    "end": "1694230"
  },
  {
    "text": "And so what you now can\ndo is you can take-- randomly select one-- either the\ncorrect or the flawed response,",
    "start": "1694230",
    "end": "1701550"
  },
  {
    "text": "and then show it to\neither a human or a human with assistance. And then they have\nto say whether it was the correct or flawed one,\nor how good the response is.",
    "start": "1701550",
    "end": "1711490"
  },
  {
    "text": "And in this setting,\nwe can figure-- just try a lot of different\nAI assistance or scalable",
    "start": "1711490",
    "end": "1720100"
  },
  {
    "text": "oversight techniques. And then say is this\nactually helping",
    "start": "1720100",
    "end": "1726860"
  },
  {
    "text": "humans find the flaws that we\nplanted more likely than not?",
    "start": "1726860",
    "end": "1731929"
  },
  {
    "text": "And if it is, then you're\nactually really helping.",
    "start": "1731929",
    "end": "1737519"
  },
  {
    "text": "And so we did this in\nthe critiques paper. So this is training the language\nmodels to read critiques",
    "start": "1737520",
    "end": "1744549"
  },
  {
    "text": "and for summaries. And what we can show is that\nwhen we're assisting humans",
    "start": "1744549",
    "end": "1749679"
  },
  {
    "text": "with critiques at\nthe evaluation, they actually find 50% more\nflaws than they did without.",
    "start": "1749679",
    "end": "1754760"
  },
  {
    "text": "And so this is kind of\nlike real signs of life that you can already use in\nmodels that we can have today",
    "start": "1754760",
    "end": "1761429"
  },
  {
    "text": "to help humans evaluate\nand find problems they would have\nmissed otherwise. And of course, we still have to\ndo this on a much harder task",
    "start": "1761429",
    "end": "1771390"
  },
  {
    "text": "and with a real\ntask, in a sense. And we also want to have\na bigger effect size.",
    "start": "1771390",
    "end": "1778820"
  },
  {
    "text": "But I think it's\njust like, it shows that there's promise of these\ntechniques already working.",
    "start": "1778820",
    "end": "1785129"
  },
  {
    "text": "And so in the long run, what\nI think we want to get to is",
    "start": "1785130",
    "end": "1790591"
  },
  {
    "text": "we kind of want to leverage\nAI for all the cognitive labor that goes into evaluating\nwhatever our AI systems are",
    "start": "1790591",
    "end": "1798898"
  },
  {
    "text": "doing. And this could be like reading\neverything that's relevant, or fact checking, or doing\ncalculations, or writing",
    "start": "1798899",
    "end": "1807179"
  },
  {
    "text": "code, or any of these things. And then humans should focus\non their preference input.",
    "start": "1807179",
    "end": "1814360"
  },
  {
    "text": "Like the things, figuring out\nwhat they actually care about, and what they want\nthe model to do.",
    "start": "1814360",
    "end": "1820690"
  },
  {
    "text": "And in this way, we can\nleverage the abilities",
    "start": "1820690",
    "end": "1829518"
  },
  {
    "text": "that the AI players will bring\nto the table, and the things that they will be better\nat than us eventually.",
    "start": "1829519",
    "end": "1837679"
  },
  {
    "text": "And then kind of like use\nthem to help communicate the thing that we\nactually care about",
    "start": "1837679",
    "end": "1843299"
  },
  {
    "text": "and the things that we\nactually want them to do.",
    "start": "1843299",
    "end": "1849260"
  },
  {
    "text": "And yeah, that's it. But yeah, those are\nthe main slides.",
    "start": "1849260",
    "end": "1854700"
  },
  {
    "text": "So I'm happy to\ntake more questions. [APPLAUSE]",
    "start": "1854700",
    "end": "1862559"
  },
  {
    "text": "Yes? I was wondering about this\nhallucination of responses.",
    "start": "1862559",
    "end": "1868760"
  },
  {
    "text": "Have you ever tried to consider\nsome notion of uncertainty",
    "start": "1868760",
    "end": "1874029"
  },
  {
    "text": "in the answers? Yes. [INAUDIBLE] attempt to evaluate\nvariance between the responses",
    "start": "1874029",
    "end": "1881090"
  },
  {
    "text": "and [INAUDIBLE] the uncertainty. So on some things it's\ndifficult because either you're",
    "start": "1881090",
    "end": "1888610"
  },
  {
    "text": "training-- fine tuning a sample\nfrom a pretrained model. And so you don't get that\nmuch variance in your sample.",
    "start": "1888610",
    "end": "1895330"
  },
  {
    "text": "Or you're pretraining a\nbunch of different models. And now you're spending a\nlot of money on pretraining.",
    "start": "1895330",
    "end": "1901130"
  },
  {
    "text": "One thing-- I mean,\nit seems like it should be a solvable\nproblem to just teach",
    "start": "1901130",
    "end": "1908039"
  },
  {
    "text": "the model to say it's uncertain\nwhen it's actually uncertain.",
    "start": "1908039",
    "end": "1914509"
  },
  {
    "text": "And there's been a bunch of\nresearch in that direction. But I think, right now,\nit's still like-- we're not",
    "start": "1914510",
    "end": "1920960"
  },
  {
    "text": "really in a good shape. There's more stuff to do.",
    "start": "1920960",
    "end": "1927390"
  },
  {
    "text": "Yeah? Do you think we may run into a\nkind of signal-to-noise ratio problem when it comes to AI\nsuggested critiques to AI",
    "start": "1927390",
    "end": "1937380"
  },
  {
    "text": "answers? Because sure, when AI is trying\nto point out potential problems",
    "start": "1937380",
    "end": "1942590"
  },
  {
    "text": "with text, humans are more\nlikely to report more problems. But what if it's mostly\nproblems that humans",
    "start": "1942590",
    "end": "1948690"
  },
  {
    "text": "wouldn't have necessarily had\na problem with to begin with? Yeah, so we did try to control\nfor that a little bit by having",
    "start": "1948690",
    "end": "1957750"
  },
  {
    "text": "humans rate the\nseverity of the flaws and whether they would have\nnoticed them otherwise.",
    "start": "1957750",
    "end": "1963620"
  },
  {
    "text": "It can still see a\nsignificant effect. But also, I mean a lot of the\ntime, the model is nitpicking.",
    "start": "1963620",
    "end": "1972100"
  },
  {
    "text": "And then those are not\nthe interesting cases. Also, if you're like look\nat the example I showed,",
    "start": "1972100",
    "end": "1978279"
  },
  {
    "text": "which I think is from the blog\npost, a lot of the critiques are just actually quite garbage.",
    "start": "1978280",
    "end": "1984450"
  },
  {
    "text": "And one of the things\nthat makes it easy for critiques is it's\nOK for the most of them",
    "start": "1984450",
    "end": "1991408"
  },
  {
    "text": "are garbage because\nthe human can just read them and discard them. And it kind of more helps\nevaluate it and know",
    "start": "1991409",
    "end": "2000419"
  },
  {
    "text": "where to focus on or notice-- think of something they\nwould have missed otherwise.",
    "start": "2000419",
    "end": "2006460"
  },
  {
    "text": "So it's more like\nthe critiques help you brainstorm how you\nshould evaluate or something.",
    "start": "2006460",
    "end": "2012200"
  },
  {
    "text": "But if you're\nusing an assistant, you probably want\nmore reliability than most of the\nanswers [INAUDIBLE]..",
    "start": "2012200",
    "end": "2021850"
  },
  {
    "text": "Yes? How do we ensure that\nthe valuation metrics",
    "start": "2021850",
    "end": "2028950"
  },
  {
    "text": "we are using in your recursive\nreward modeling approach detect deception, or\nleft turns, or something?",
    "start": "2028950",
    "end": "2035780"
  },
  {
    "text": "Do you have major discontinuity? Yeah, I think-- well, it depends\na lot what kind of community",
    "start": "2035780",
    "end": "2043899"
  },
  {
    "text": "you're talking about. If you get overnight a\nmodel that is, let's say,",
    "start": "2043900",
    "end": "2050550"
  },
  {
    "text": "a number of parameters, or equivalently better, that\ncan create quite a step up.",
    "start": "2050550",
    "end": "2061579"
  },
  {
    "text": "And that makes it\nquite difficult to do this kind of evaluation.",
    "start": "2061580",
    "end": "2070368"
  },
  {
    "text": "So in that sense,\nI think it's going to be very important to\nscale up AI more continuously",
    "start": "2070369",
    "end": "2076259"
  },
  {
    "text": "and do more incremental steps. Having said that, I think the\nbasic picture with request",
    "start": "2076259",
    "end": "2083470"
  },
  {
    "text": "reward modeling is that you're\ntraining the systems to help you evaluate--",
    "start": "2083470",
    "end": "2091000"
  },
  {
    "text": "systems that are trained or\nfine tuned from the same system. And so if you can\nfigure out how to get--",
    "start": "2091000",
    "end": "2100430"
  },
  {
    "text": "fine tune them in a way\nthat they mention everything that is actually\nuseful and relevant, then it would still be\nable to evaluate systems,",
    "start": "2100430",
    "end": "2109430"
  },
  {
    "text": "even though they are much\nsmarter than anything you've evaluated before. Maybe let me make\nthis more concrete",
    "start": "2109430",
    "end": "2117050"
  },
  {
    "text": "because I think a way that you\ncould measure that, or like one way we've tried it was using\nwhat we call the discriminator",
    "start": "2117050",
    "end": "2124100"
  },
  {
    "text": "critique gap. So to measure that,\nyou're training two different-- you're fine\ntuning to different models",
    "start": "2124100",
    "end": "2130690"
  },
  {
    "text": "from the same pretrained model. One is the\ndiscriminator that says is this the flawed response\nor the correct response,",
    "start": "2130690",
    "end": "2138260"
  },
  {
    "text": "or a more correct response? And the other one is\na critique model that tells you what the flaw was.",
    "start": "2138260",
    "end": "2144619"
  },
  {
    "text": "And now, you can measure how\noften does the discriminator get it correctly?",
    "start": "2144619",
    "end": "2150520"
  },
  {
    "text": "And the discriminator is\njust like q gradient descent. It doesn't have to want\nto tell you anything.",
    "start": "2150520",
    "end": "2155730"
  },
  {
    "text": "You're just basically hooking\ninto the model's presentations and trying to get all\nthe relevant insight",
    "start": "2155730",
    "end": "2163960"
  },
  {
    "text": "it has to this prediction task. And then on the other\nside-- other hand, you have this critique model or\nthis general assistance model.",
    "start": "2163960",
    "end": "2171588"
  },
  {
    "text": "And you're measuring how often\ndoes the assistant actually help me point to the right flaw?",
    "start": "2171589",
    "end": "2178940"
  },
  {
    "text": "And then if you compare\nthese two scores, you can look at the\ngap between them, hence this generated-- sorry,\ndiscriminated critique gap.",
    "start": "2178940",
    "end": "2187160"
  },
  {
    "text": "And then if the gap is\nlarge, then the model knows a lot about the\ntask it's not telling you. And so that would\nbe very worrying.",
    "start": "2187160",
    "end": "2193870"
  },
  {
    "text": "And if the gap is small,\nthen there's much-- presumably, there's fewer\nthings that the model is not",
    "start": "2193870",
    "end": "2202859"
  },
  {
    "text": "telling you. But I guess there's\nlots of value like ensuring this\napproach is robust",
    "start": "2202859",
    "end": "2209609"
  },
  {
    "text": "and testing it on\ncurrent models? That's right. That's why you want to\ntest it on current models.",
    "start": "2209609",
    "end": "2216510"
  },
  {
    "text": "Yes, I don't know who was first. I think someone in the back.",
    "start": "2216510",
    "end": "2222609"
  },
  {
    "text": "So I wanted to ask\nabout the previous slide",
    "start": "2222609",
    "end": "2228740"
  },
  {
    "text": "where, it's like [INAUDIBLE]. So I couldn't help but--",
    "start": "2228740",
    "end": "2235140"
  },
  {
    "text": "part of that also\nit's communicating what you want the AI to\ndo, not just evaluate,",
    "start": "2235140",
    "end": "2242400"
  },
  {
    "text": "but communicating perhaps,\nI would like you to do this. And maybe [INAUDIBLE] that.",
    "start": "2242400",
    "end": "2248568"
  },
  {
    "text": "And so like at least like in\nmy personal experience using the ChatGPT, there\nare some things that could do that without\n[INAUDIBLE] surprising.",
    "start": "2248569",
    "end": "2256369"
  },
  {
    "text": "But [INAUDIBLE] to the\nterminal, for instance, or you",
    "start": "2256369",
    "end": "2262818"
  },
  {
    "text": "can ask about [INAUDIBLE]. These are different\nthings where I'm like, OK, what can I ask for? And what [INAUDIBLE].",
    "start": "2262819",
    "end": "2269390"
  },
  {
    "text": "One thing that I thought\nwas a bit concerning which just this idea that\npeople don't always communicate",
    "start": "2269390",
    "end": "2276270"
  },
  {
    "text": "their preferences honestly. Or there could be\ncoordinated efforts",
    "start": "2276270",
    "end": "2283560"
  },
  {
    "text": "to instill words for\nspecific capabilities, a coordinated effort\nto do such a thing.",
    "start": "2283560",
    "end": "2292190"
  },
  {
    "text": "One idea I had for\nthis is I tried to ask if that has like some\nidea of a Wikipedia for itself.",
    "start": "2292190",
    "end": "2301210"
  },
  {
    "text": "I didn't know how\nto use it at first. So I just thought that-- [INAUDIBLE] there\ndidn't seem to be one.",
    "start": "2301210",
    "end": "2306660"
  },
  {
    "text": "I was hoping there was one--\nthere was one for GPT-3. [INAUDIBLE]",
    "start": "2306660",
    "end": "2311750"
  },
  {
    "text": "And so my question is like-- how do you make that\nsort of thing safe?",
    "start": "2311750",
    "end": "2318839"
  },
  {
    "text": "How do you recognize\ncoordinated efforts to specifically reward\ncertain kinds of behavior,",
    "start": "2318839",
    "end": "2327380"
  },
  {
    "text": "maybe like some group\ndecides that they would like to give it some capability?",
    "start": "2327380",
    "end": "2335119"
  },
  {
    "text": "So this is a-- yeah, this is a\nreally good question. And in a way, I mean,\nthe first obvious thing",
    "start": "2335119",
    "end": "2342240"
  },
  {
    "text": "that you shouldn't do is\nyou shouldn't just literally train on the data that people\ngive you using the interface.",
    "start": "2342240",
    "end": "2350770"
  },
  {
    "text": "And we've kind of seen\nother examples of what happens when you do that. If you think of like\nMicrosoft K or something,",
    "start": "2350770",
    "end": "2357240"
  },
  {
    "text": "that can go pretty wrong. The other thing is, I\nmean right now, what",
    "start": "2357240",
    "end": "2362359"
  },
  {
    "text": "we're doing is we're\nhiring a bunch of people and then ask them to rate\ndifferent model responses.",
    "start": "2362360",
    "end": "2367650"
  },
  {
    "text": "But also, now, the question\nbecomes who are we hiring? And what's their background?",
    "start": "2367650",
    "end": "2372880"
  },
  {
    "text": "What are they trying to do? And so in particular,\nthe thing, I think,",
    "start": "2372880",
    "end": "2378828"
  },
  {
    "text": "we're doing quite\npoorly right now is actually importing a\ndiverse and representative set",
    "start": "2378829",
    "end": "2387250"
  },
  {
    "text": "of human preferences. And it's more just whoever\nwe end up we can hire.",
    "start": "2387250",
    "end": "2394290"
  },
  {
    "text": "And so I kind of\nwish there was also this more targeted research\non how we should do that",
    "start": "2394290",
    "end": "2401630"
  },
  {
    "text": "and how that could be done well. And some of that is also\nlike better placed outside",
    "start": "2401630",
    "end": "2406740"
  },
  {
    "text": "of big tech companies. Because if you're-- tech\ncompanies always have an incentive to import human\npreferences in a way that maybe",
    "start": "2406740",
    "end": "2419030"
  },
  {
    "text": "is not the thing\nthat we actually-- humanity would do under\nreflection or something.",
    "start": "2419030",
    "end": "2425318"
  },
  {
    "text": "And so I think it's a really\nbig important question. Does this [INAUDIBLE]\ndata contamination is like the dual\nproblem to this?",
    "start": "2425319",
    "end": "2432530"
  },
  {
    "text": "Do you think the internet\nmight [INAUDIBLE]?? Probably is.",
    "start": "2432530",
    "end": "2437660"
  },
  {
    "text": "Yeah, I mean-- Is that something-- People might-- anyone\ncan poison the future anyway, just post\nsomething on the internet.",
    "start": "2437660",
    "end": "2445800"
  },
  {
    "text": "And it's something that we\nhave to be very mindful of. Yes?",
    "start": "2445800",
    "end": "2451480"
  },
  {
    "text": "I don't know. [INAUDIBLE] Considering that we're\ncurrently training these models",
    "start": "2451480",
    "end": "2456520"
  },
  {
    "text": "for [INAUDIBLE],,\nthose things are-- hopefully getting closer\nto human preferences",
    "start": "2456520",
    "end": "2462040"
  },
  {
    "text": "at this point. As human preferences change,\nas we've seen [INAUDIBLE],,",
    "start": "2462040",
    "end": "2467480"
  },
  {
    "text": "is there something-- is there a paradigm? Is there a way you can make\nsure the model's keeping up",
    "start": "2467480",
    "end": "2476390"
  },
  {
    "text": "with data better? What are your\nthoughts around that? Yeah, I mean, the\nmost obvious thing",
    "start": "2476390",
    "end": "2481819"
  },
  {
    "text": "is like the model's\nknowledge base is kind of like the\npretraining cutoff date.",
    "start": "2481820",
    "end": "2487200"
  },
  {
    "text": "Whatever data you\nwent into pretraining, it doesn't know\nabout a lot of things",
    "start": "2487200",
    "end": "2493460"
  },
  {
    "text": "that happened after that. In terms of updating\nkind of human preferences",
    "start": "2493460",
    "end": "2499088"
  },
  {
    "text": "or the comparisons that\ngo into the reward model, we just collect more\ndata and we train.",
    "start": "2499089",
    "end": "2504630"
  },
  {
    "text": "The functioning run is\nlike comparatively cheap. So you can do that again. I think what gets\nharder is that as you've",
    "start": "2504630",
    "end": "2513740"
  },
  {
    "text": "deployed the model and\npeople started using it for all kinds of\ntasks that they want",
    "start": "2513740",
    "end": "2518940"
  },
  {
    "text": "to build their company\naround, if you update",
    "start": "2518940",
    "end": "2524790"
  },
  {
    "text": "and you change the\nmodel, then they also have to do a bunch of work\ninto adopting their prompts to whatever they're doing.",
    "start": "2524790",
    "end": "2532710"
  },
  {
    "text": "And so it doesn't\ncome at a zero cost. Yes?",
    "start": "2532710",
    "end": "2538160"
  },
  {
    "text": "Sorry, you. So on the note of exceeding\nhuman performance.",
    "start": "2538160",
    "end": "2544200"
  },
  {
    "text": "One of the advantages\nof GPT-3 is that it has this immense\ncorpus of basically",
    "start": "2544200",
    "end": "2549849"
  },
  {
    "text": "the entire internet. If you want to specialize\nin specific domains, like chemistry, or material\nscience, or something, in",
    "start": "2549849",
    "end": "2557500"
  },
  {
    "text": "[INAUDIBLE] generate new\ncontent, then [INAUDIBLE] be adapted to use less data\nand still run as efficiently?",
    "start": "2557500",
    "end": "2565180"
  },
  {
    "text": "[INAUDIBLE] You mean like less data on the\nchemical domain or something? Yeah, you may just have\nthe research papers",
    "start": "2565180",
    "end": "2572190"
  },
  {
    "text": "over the last 30\nyears or something? Yeah, and you can throw\nthem to pretraining. And then the model\nknows about it.",
    "start": "2572190",
    "end": "2577750"
  },
  {
    "text": "Can the model really\nmanage effectively without so much data? Can it be-- that the abstract\nconcepts behind GPT-3,",
    "start": "2577750",
    "end": "2585099"
  },
  {
    "text": "[INAUDIBLE]. Yeah, I mean, that's kind of\nthe general idea with what you intend to do with fine tuning.",
    "start": "2585100",
    "end": "2591480"
  },
  {
    "text": "And to some extent, we've seen\nit generalized in this way. For example, InstructGPT\nwas trained almost entirely",
    "start": "2591480",
    "end": "2597950"
  },
  {
    "text": "on English language\nfeedback and demonstrations.",
    "start": "2597950",
    "end": "2603300"
  },
  {
    "text": "And it works in other languages. And so that's kind of wild. And so similarly, you\ncould train the model",
    "start": "2603300",
    "end": "2609599"
  },
  {
    "text": "with people who don't know\nanything about chemistry. And then it learns to\nfollow instructions. And it will do so on\nthe topic of chemistry.",
    "start": "2609599",
    "end": "2618400"
  },
  {
    "text": "And this fine tuning can\nbe very sample efficient. With 100 data points,\nyou can actually make a meaningful change\nin the model of behavior.",
    "start": "2618400",
    "end": "2624380"
  },
  {
    "text": "So it can be quite effective. I'm going to pick\nsomeone hasn't asked.",
    "start": "2624380",
    "end": "2632269"
  },
  {
    "text": "Yes? Regarding response\ngeneration, do you-- or how much effort do you put\non [INAUDIBLE] the emphasis",
    "start": "2632270",
    "end": "2642140"
  },
  {
    "text": "and training of different\nexpression styles? So what I've noticed from\nChatGPT, that it always",
    "start": "2642140",
    "end": "2649940"
  },
  {
    "text": "gives back structured\nor scientifically structured answers. Do you consider in the\ntraining if [INAUDIBLE]",
    "start": "2649940",
    "end": "2656930"
  },
  {
    "text": "scientific research to\nanswer or [INAUDIBLE]??",
    "start": "2656930",
    "end": "2662170"
  },
  {
    "text": "Yeah, I mean, the\ntricky thing is ideally",
    "start": "2662170",
    "end": "2667619"
  },
  {
    "text": "the model should give\nyou the kind of answer that you want to have.",
    "start": "2667619",
    "end": "2673319"
  },
  {
    "text": "And some people prefer more\nscientific or technical answers. Some people might prefer\na more generic answer.",
    "start": "2673320",
    "end": "2680880"
  },
  {
    "text": "And I mean, right\nnow, ChatGPT doesn't have a way for you to set like\nyour specific preferences.",
    "start": "2680880",
    "end": "2688829"
  },
  {
    "text": "And that's something that would\nbe really exciting to have. But also I think the kind of\nstatistic property that you've",
    "start": "2688829",
    "end": "2697579"
  },
  {
    "text": "observed is, in fact, probably\na product of our labeler pool.",
    "start": "2697579",
    "end": "2703770"
  },
  {
    "text": "And so a lot of the\nChatGPT workers were more, I think, more like\ncomputer sciencey.",
    "start": "2703770",
    "end": "2710109"
  },
  {
    "text": "And more-- there was like more\ndata generated by programmers",
    "start": "2710109",
    "end": "2715410"
  },
  {
    "text": "compared to InstructGPT, which\nwas more generalist labelers.",
    "start": "2715410",
    "end": "2721250"
  },
  {
    "text": "And yeah, there's different-- it\nkind of changes also the style.",
    "start": "2721250",
    "end": "2727859"
  },
  {
    "text": "So there is no specific\neffort to distinguish",
    "start": "2727859",
    "end": "2733259"
  },
  {
    "text": "them, but [INAUDIBLE]? Yeah, I mean, we should\nmake a distinguished effort.",
    "start": "2733260",
    "end": "2739650"
  },
  {
    "text": "It should give you the\nstyle that you want, right? Yes.",
    "start": "2739650",
    "end": "2746420"
  },
  {
    "text": "So one of the things that I've\nbeen thinking about recently is how ChatGPT is going to\nplay a factor in the education",
    "start": "2746420",
    "end": "2752020"
  },
  {
    "text": "realm. [INAUDIBLE] coming generation. And if you go back to the\ngraph of the AI progress,",
    "start": "2752020",
    "end": "2760930"
  },
  {
    "text": "the human level,\n[INAUDIBLE] evaluate. What I'm starting to think\nabout is for a grade,",
    "start": "2760930",
    "end": "2766280"
  },
  {
    "text": "I had to use [INAUDIBLE] I\nshowed my 10-year-old cousin",
    "start": "2766280",
    "end": "2772940"
  },
  {
    "text": "how to use ChatGPT, just\nto mess around with.",
    "start": "2772940",
    "end": "2778940"
  },
  {
    "text": "And that green line\nis a lot lower. And furthermore, if\nthis becomes part",
    "start": "2778940",
    "end": "2786320"
  },
  {
    "text": "of their educational experience,\nit's going to be much-- I perceive it to be\nmore difficult for them",
    "start": "2786320",
    "end": "2793720"
  },
  {
    "text": "to discriminate even simpler\ntasks than what they do now.",
    "start": "2793720",
    "end": "2798760"
  },
  {
    "text": "And so I'm already\nthinking about how that might disrupt or make\nthis a little bit more",
    "start": "2798760",
    "end": "2806210"
  },
  {
    "text": "difficult in the long run, as\nyou have people who are more-- take for instance,\nwhat ChatGBC--",
    "start": "2806210",
    "end": "2814440"
  },
  {
    "text": "sorry, ChatGPT says as\na hidden truth, anyway.",
    "start": "2814440",
    "end": "2819800"
  },
  {
    "text": "I was just wondering what\nyour thoughts are on that? I mean, there's a real\nrisk of overrelying on a tech that is\nimmature and that is not",
    "start": "2819800",
    "end": "2826760"
  },
  {
    "text": "ready for you just believing it. Please don't believe\neverything the model says.",
    "start": "2826760",
    "end": "2834220"
  },
  {
    "text": "But also I think\none thing that I'm hopeful for is that like\nyour cousin will end up",
    "start": "2834220",
    "end": "2841130"
  },
  {
    "text": "figuring out how to do this. Where they grew up with\nall of these AI tools",
    "start": "2841130",
    "end": "2849280"
  },
  {
    "text": "that are getting\nbetter and learning how to actually leverage\nthem productively, right?",
    "start": "2849280",
    "end": "2855640"
  },
  {
    "text": "And it's kind of\nlike 20 years ago or something, when you were\nusing Google Search much",
    "start": "2855640",
    "end": "2863730"
  },
  {
    "text": "earlier than\neveryone else, you're probably going to\nget better at using that as a tool for\neverything you want to do.",
    "start": "2863730",
    "end": "2870599"
  },
  {
    "text": "More questions? I think you had your\nhand up for a while.",
    "start": "2870599",
    "end": "2879849"
  },
  {
    "text": "The slide where human tasks\nand the chat task and the model",
    "start": "2879849",
    "end": "2888460"
  },
  {
    "text": "task. Oh, the last one? Yeah, so right now, it seems\nlike you guys are using humans",
    "start": "2888460",
    "end": "2896119"
  },
  {
    "text": "as biological sensors for the\nreal world, the physical ground",
    "start": "2896119",
    "end": "2901960"
  },
  {
    "text": "truth, and using language\nas a compressed interface to that ground truth.",
    "start": "2901960",
    "end": "2906980"
  },
  {
    "text": "Are you guys also looking\nat using sensor technology directly with your models to\nget a more truthful answer of--",
    "start": "2906980",
    "end": "2916580"
  },
  {
    "text": "Yeah, I mean, it depends on\nwhat that sensor could be. I guess one of the most\nstraightforward things",
    "start": "2916580",
    "end": "2923500"
  },
  {
    "text": "is you could ask\nthe model to browse. And then they can fact\ncheck its own answers.",
    "start": "2923500",
    "end": "2928780"
  },
  {
    "text": "And it can import\nexternal knowledge that it didn't remember.",
    "start": "2928780",
    "end": "2935030"
  },
  {
    "text": "And yeah, I think that\nwould be quite useful. I think that would be quite\nuseful for a sustained human",
    "start": "2935030",
    "end": "2944440"
  },
  {
    "text": "evaluation. [INAUDIBLE] You can look at WebGPT, which\nis a published work on using",
    "start": "2944440",
    "end": "2954650"
  },
  {
    "text": "the model for browsing. I think-- so one thing that\nmakes it harder when you're",
    "start": "2954650",
    "end": "2960570"
  },
  {
    "text": "using these external sensors,\nor if you're letting the model interact more directly\nwith the real world",
    "start": "2960570",
    "end": "2966599"
  },
  {
    "text": "is that it raises\nmore safety questions. If you let your language model\nmake arbitrary API calls,",
    "start": "2966599",
    "end": "2973950"
  },
  {
    "text": "then you have to be\na lot more careful with which calls it's allowed\nto make and which is it not.",
    "start": "2973950",
    "end": "2981869"
  },
  {
    "text": "And if you're-- as opposed\nto if you're just reviewing everything the model says, then\nyou can decide which ones you",
    "start": "2981869",
    "end": "2988760"
  },
  {
    "text": "want to make. So yeah, it's an open problem.",
    "start": "2988760",
    "end": "2997020"
  },
  {
    "text": "OK, one more question. I think you didn't.",
    "start": "2997020",
    "end": "3002180"
  },
  {
    "text": "--about the reasoning\nabilities of these [INAUDIBLE] language models. I've seen many\ndifferent people talk",
    "start": "3002180",
    "end": "3007730"
  },
  {
    "text": "about how there's only a fixed\namount of compute for token. While in humans, they have\nsystem one or system two where",
    "start": "3007730",
    "end": "3012970"
  },
  {
    "text": "we can just speak quickly\nversus actually using reasoning and think through things\nthat take more effort.",
    "start": "3012970",
    "end": "3019930"
  },
  {
    "text": "And then I'll see how that works\nto try to use the [INAUDIBLE]",
    "start": "3019930",
    "end": "3025170"
  },
  {
    "text": "to achieve prompt, or\nthe chain of reasoning, or [INAUDIBLE] step by step. So do you think that's\nsufficient to do everything",
    "start": "3025170",
    "end": "3031490"
  },
  {
    "text": "that's the level that we want? Or will it require\nreal big fine tuning",
    "start": "3031490",
    "end": "3036579"
  },
  {
    "text": "or architectural changes? I don't know. I'm also the wrong\nperson to ask.",
    "start": "3036579",
    "end": "3043380"
  },
  {
    "text": "I'm mostly not trying to\nget the models to have",
    "start": "3043380",
    "end": "3048410"
  },
  {
    "text": "new capabilities and\nmore like getting them to play on Team Human.",
    "start": "3048410",
    "end": "3056190"
  },
  {
    "text": "And oh, do we want to\ndo the online questions? Sure, yeah. [INAUDIBLE] question.",
    "start": "3056190",
    "end": "3062260"
  },
  {
    "text": "So what do you think is\nthe [INAUDIBLE] from,",
    "start": "3062260",
    "end": "3068839"
  },
  {
    "text": "especially if you have\nhuman [INAUDIBLE] chat bots is happening more\nthan human infections.",
    "start": "3068839",
    "end": "3075338"
  },
  {
    "text": "So do you think the InstructGPT\ncould be more open arrow? Yeah, quite possibly.",
    "start": "3075339",
    "end": "3084080"
  },
  {
    "text": "I mean, yeah, as\nyou point out, there",
    "start": "3084080",
    "end": "3091200"
  },
  {
    "text": "is a lot of conversational data. And if you can use\nit, that would be-- it should be useful.",
    "start": "3091200",
    "end": "3099010"
  },
  {
    "text": "I think broadly, you can\ncategorize this kind of thing as like let's make the\nRL algorithm better.",
    "start": "3099010",
    "end": "3104240"
  },
  {
    "text": "And I welcome the feedback. And I think that's valuable. And that should help us make\nthe same pretrained models more",
    "start": "3104240",
    "end": "3113009"
  },
  {
    "text": "aligned according to the human\npreferences that we collected.",
    "start": "3113010",
    "end": "3118119"
  },
  {
    "text": "But also, you would still\nrun into all the limitations that RL HF has.",
    "start": "3118119",
    "end": "3124839"
  },
  {
    "text": "Someone wants to [INAUDIBLE]\nGPT model, OpenAI [INAUDIBLE]..",
    "start": "3124839",
    "end": "3129970"
  },
  {
    "text": "I think there's a fine\ntuning API for GPT-3. I don't think it\noffers RL right now.",
    "start": "3129970",
    "end": "3135640"
  },
  {
    "text": "But it's supervised fine tuning. So you could do like-- you can distill best of m and\ndo this kind of expert iteration",
    "start": "3135640",
    "end": "3142660"
  },
  {
    "text": "RL. [INAUDIBLE] questions. So the first question\ncould you more clearly",
    "start": "3142660",
    "end": "3151068"
  },
  {
    "text": "describe the pretraining\nprocess for GPT? Example, starting with\nthe x [INAUDIBLE] 001,",
    "start": "3151069",
    "end": "3158290"
  },
  {
    "text": "and then [INAUDIBLE] offering\ndata [INAUDIBLE] like that. Sorry, I didn't catch that. Start with text\nimage 001 and then--",
    "start": "3158290",
    "end": "3165040"
  },
  {
    "text": "How much user data\n[INAUDIBLE] and how many steps are there, that kind of things?",
    "start": "3165040",
    "end": "3173190"
  },
  {
    "text": "I think the exact\nnumbers are not public. It's basically similar\nto InstructGPT.",
    "start": "3173190",
    "end": "3180230"
  },
  {
    "text": "And for the InstructGPT\nnumbers, we had, I think, around 50,000\ncomparisons and probably",
    "start": "3180230",
    "end": "3190088"
  },
  {
    "text": "like 10,000 demonstrations,\nor maybe tens of thousands. I don't remember\nthe exact numbers.",
    "start": "3190089",
    "end": "3197329"
  },
  {
    "text": "So I had this other slide with-- yeah, I was like about 20,000\nhours of human feedback.",
    "start": "3197329",
    "end": "3205240"
  },
  {
    "text": "That's what I calculated. [INAUDIBLE] feedback. Because that's-- you can\nget 1 million or whatever",
    "start": "3205240",
    "end": "3211369"
  },
  {
    "text": "[INAUDIBLE]. I mean, the big question\nis how do you make-- how do you ensure quality? [INAUDIBLE] models that can\ncreate that out, or give",
    "start": "3211369",
    "end": "3220049"
  },
  {
    "text": "rankings or something. But it's the whole problem.",
    "start": "3220049",
    "end": "3225680"
  },
  {
    "text": "That assumes you\nalready have the reward model that you trust. OK sure, so next question,\nI think, that also was you",
    "start": "3225680",
    "end": "3236320"
  },
  {
    "text": "want to automate\naround the search, what happens if you need conceptual\n[INAUDIBLE] experts to verify?",
    "start": "3236320",
    "end": "3242280"
  },
  {
    "text": "Yeah, so I mean the kind of\nlike ambition of that plan",
    "start": "3242280",
    "end": "3249410"
  },
  {
    "text": "is to train to model\nthat can do this kind of conceptual research.",
    "start": "3249410",
    "end": "3254579"
  },
  {
    "text": "And you can picture\nthat a language model that writes an alignment\nresearch paper that we know we",
    "start": "3254579",
    "end": "3263049"
  },
  {
    "text": "read. And then we're like, oh,\nthis is a really cool idea. We should try this. And I think going\nback to evaluation",
    "start": "3263049",
    "end": "3271530"
  },
  {
    "text": "is easier than generation. I think it also applies\nto alignment research. And I think, at\nthe very least, I",
    "start": "3271530",
    "end": "3277838"
  },
  {
    "text": "find it much easier to evaluate\nalignment research than I find it to produce it.",
    "start": "3277839",
    "end": "3284609"
  },
  {
    "text": "And so while there might\nbe conceptual breakthroughs that we need that we\ncouldn't even evaluate right",
    "start": "3284609",
    "end": "3292690"
  },
  {
    "text": "now because they're just like-- if we saw them, we'd\nbe like, what is this?",
    "start": "3292690",
    "end": "3298140"
  },
  {
    "text": "And this is kind of like-- this is the reason why we\nwant to do scalable oversight.",
    "start": "3298140",
    "end": "3304420"
  },
  {
    "text": "Because if the language model\nproduces this really brilliant insight and we can't even\nrecognize it at the time,",
    "start": "3304420",
    "end": "3313349"
  },
  {
    "text": "we should be able to have an\neasier time recognizing it if we use AI assistance.",
    "start": "3313349",
    "end": "3318890"
  },
  {
    "text": "And if we leverage like our\nbest AI models to figure it out",
    "start": "3318890",
    "end": "3324510"
  },
  {
    "text": "whether or not that was a good\nidea, what is the weaknesses, and what are the strengths? And what kind of\nexperiments should we",
    "start": "3324510",
    "end": "3330838"
  },
  {
    "text": "run to know whether\nthis is a good idea? And so yeah, I think\nbasically, the story",
    "start": "3330839",
    "end": "3338230"
  },
  {
    "text": "of just using RL HF to train\na model to do good alignment research, you have\nthe obvious pitfalls,",
    "start": "3338230",
    "end": "3344319"
  },
  {
    "text": "which is the model might write\nan alignment proposal that kind of looks good to us but is\nactually not a good proposal.",
    "start": "3344319",
    "end": "3352510"
  },
  {
    "text": "And it creates the AI that\nis misaligned with humans. And so in order to distinguish\nthe two, which might",
    "start": "3352510",
    "end": "3359880"
  },
  {
    "text": "be really hard, maybe it's not. But I think we should\nexpect it to be really hard.",
    "start": "3359880",
    "end": "3365210"
  },
  {
    "text": "And then leveraging AI\nassistants to evaluate that seems like a really\npromising plan.",
    "start": "3365210",
    "end": "3371940"
  },
  {
    "text": "[INAUDIBLE] I mean, that was my whole point.",
    "start": "3371940",
    "end": "3377680"
  },
  {
    "text": "It's not sufficient. [INAUDIBLE] But do you think--\ndo you need something more?",
    "start": "3377680",
    "end": "3385349"
  },
  {
    "text": "Or [INAUDIBLE] don't\nyou think if you can get a lot of feedback data? Will that be sufficient to\nget a better generation?",
    "start": "3385349",
    "end": "3393540"
  },
  {
    "text": "Or are we seeing more\nbehaviors that are missing? I mean, the general, or like--",
    "start": "3393540",
    "end": "3401859"
  },
  {
    "text": "I think the-- basically, the\nvast majority of the models capabilities and\nall the cool things",
    "start": "3401859",
    "end": "3408690"
  },
  {
    "text": "you see it do come from\npretraining, and not from the fine tuning stage. The reason why people sometimes\nattribute it to the fine tuning",
    "start": "3408690",
    "end": "3416568"
  },
  {
    "text": "stage is that you didn't see\nit in the pretrained model.",
    "start": "3416569",
    "end": "3421750"
  },
  {
    "text": "And the reason-- I think the reason\nthat we didn't see it in the pretrained model\nis because the prewritten",
    "start": "3421750",
    "end": "3427200"
  },
  {
    "text": "model was so misaligned, it\nwas not trying to help you. And it was not\ntrying to show you all the cool things it can do.",
    "start": "3427200",
    "end": "3433230"
  },
  {
    "text": "And instead, it\njust regurgitates a bunch of random web text. And that's not what\nyou're looking for.",
    "start": "3433230",
    "end": "3439680"
  },
  {
    "text": "And so yeah, I think\nwhat RL HF basically has been doing is unlocking\ncapabilities that were already",
    "start": "3439680",
    "end": "3447470"
  },
  {
    "text": "in the model and making those\navailable for humans to use.",
    "start": "3447470",
    "end": "3453299"
  },
  {
    "text": "And in some ways,\nalignment research is very dual use in\nthe sense that, a,",
    "start": "3453299",
    "end": "3460960"
  },
  {
    "text": "if you have really good\nalignment techniques, you can use it to align with\nwhatever values you want, including values that we\nwouldn't particularly endorse.",
    "start": "3460960",
    "end": "3470109"
  },
  {
    "text": "And b, it also-- if you're doing\nalignment right, it",
    "start": "3470109",
    "end": "3475220"
  },
  {
    "text": "will always look a\nlittle bit like you've made the system more\ncapable because before, it",
    "start": "3475220",
    "end": "3481260"
  },
  {
    "text": "wasn't really trying\nthat hard to help you. And now, you've made\nit more aligned.",
    "start": "3481260",
    "end": "3486609"
  },
  {
    "text": "So you actually see these\ncapabilities or already had. Sure, [INAUDIBLE]\nquestion before.",
    "start": "3486609",
    "end": "3494300"
  },
  {
    "text": "How would you [INAUDIBLE]\nproject that's [INAUDIBLE]..",
    "start": "3494300",
    "end": "3500840"
  },
  {
    "text": "So it's not like-- [INAUDIBLE] to\nincentivize deception. So how we counter that?",
    "start": "3500840",
    "end": "3507288"
  },
  {
    "text": "Yeah, so that was what I\nwas talking about here. This is the whole\nproblem that we have",
    "start": "3507289",
    "end": "3515370"
  },
  {
    "text": "where what humans can\nevaluate is constant. And so we won't be able to\nevaluate sophisticated attempts",
    "start": "3515370",
    "end": "3522420"
  },
  {
    "text": "at deceiving us. And that's why we want to\ndo a scalable supervision so that we empower humans to spot\nthese attempts of deception.",
    "start": "3522420",
    "end": "3535270"
  },
  {
    "text": "Familiar plans for conquering\n[INAUDIBLE] stand up to [INAUDIBLE] in a\nword, could be changing",
    "start": "3535270",
    "end": "3541910"
  },
  {
    "text": "[INAUDIBLE] AI assistance? So I think these\nare real worries.",
    "start": "3541910",
    "end": "3548578"
  },
  {
    "text": "And to some extent,\nwe kind of have to test empirically\nhow difficult",
    "start": "3548579",
    "end": "3556309"
  },
  {
    "text": "and how severe\nthey actually are. I think so my personal\nstance right now is something",
    "start": "3556309",
    "end": "3563340"
  },
  {
    "text": "like I think trying to get the\nouter alignment signal really right is going to be",
    "start": "3563340",
    "end": "3571318"
  },
  {
    "text": "And once we have that, then\na lot of the other things might also fall into place. So for example, I\nmean, it kind of",
    "start": "3571319",
    "end": "3578200"
  },
  {
    "text": "depends on which startup\nin a misalignment you're worried about. But one story is you kind\nof training your system,",
    "start": "3578200",
    "end": "3585020"
  },
  {
    "text": "and it learns how to do-- it learns, basically, a\nbunch of inner optimizers,",
    "start": "3585020",
    "end": "3590890"
  },
  {
    "text": "kind of like meta\nreinforcement learning. So for example, GPT-3 can\ndo like in-context learning.",
    "start": "3590890",
    "end": "3597849"
  },
  {
    "text": "And that's a kind of\nlearned optimizer. And so now, you're doing\nRL HF training or whatever",
    "start": "3597849",
    "end": "3607170"
  },
  {
    "text": "alignment training you have. And you're like--\nthen optimizers",
    "start": "3607170",
    "end": "3612190"
  },
  {
    "text": "learn to do the thing that\nyou want on distribution. But now, if you have a\ndistributional shift,",
    "start": "3612190",
    "end": "3618320"
  },
  {
    "text": "and this distributional shift\ncould be auto-induced, meaning the model is causing it itself. Now, you've got an\nouter distribution,",
    "start": "3618320",
    "end": "3625430"
  },
  {
    "text": "all these inner optimizers try\nto optimize for something else. And one way you could like--",
    "start": "3625430",
    "end": "3634250"
  },
  {
    "text": "and you know, how much\nthat would actually happen in practice is kind of unclear. But one kind of more\nimportant question",
    "start": "3634250",
    "end": "3640760"
  },
  {
    "text": "is if you have a really\nreliable outer alignment signal and you have this general\ntraining signal that you trust,",
    "start": "3640760",
    "end": "3649990"
  },
  {
    "text": "you can also use that\non the new distribution to train the system to be more--",
    "start": "3649990",
    "end": "3656470"
  },
  {
    "text": "or to get these inner\noptimizers in a row, basically.",
    "start": "3656470",
    "end": "3662559"
  },
  {
    "text": "And so then you've reduced\nthe inner alignment problems to how do you deal with\na distributional shift.",
    "start": "3662559",
    "end": "3668470"
  },
  {
    "text": "And how do you construct\nan outer alignment signal that you trust? And those are problems that\nwe have to deal with anyways.",
    "start": "3668470",
    "end": "3676619"
  },
  {
    "text": "But yeah, I don't know how it's\nactually going to shake out. But it's important\nopen questions.",
    "start": "3676620",
    "end": "3686530"
  },
  {
    "text": "So regarding alignment,\na lot of the problems",
    "start": "3686530",
    "end": "3695660"
  },
  {
    "text": "that we're encountering\n[INAUDIBLE] there not much interest, it\nseems, in explaining why",
    "start": "3695660",
    "end": "3700940"
  },
  {
    "text": "from these [INAUDIBLE]. I was wondering if\nthere's much interest in the OpenAI for\n[INAUDIBLE] these models",
    "start": "3700940",
    "end": "3708808"
  },
  {
    "text": "and explaining why [INAUDIBLE]. arbitrarily. I mean, that's\ndefinitely a [INAUDIBLE].. As to why [INAUDIBLE],,\njudgements.",
    "start": "3708809",
    "end": "3717859"
  },
  {
    "text": "Have you all been able\nto interrogate the model?",
    "start": "3717859",
    "end": "3723599"
  },
  {
    "text": "I mean, I think where\nwe are right now is pretty dissatisfactory.",
    "start": "3723600",
    "end": "3730670"
  },
  {
    "text": "I mean, you can ask the model\nwhy it gave a certain response.",
    "start": "3730670",
    "end": "3737200"
  },
  {
    "text": "But you don't know whether\nit's answering truthfully. And you can also-- I mean, another\nthing you can do is",
    "start": "3737200",
    "end": "3743058"
  },
  {
    "text": "you can give the\nmodel its own response and ask it to find out\nflaws, which is what we did in the critiques paper.",
    "start": "3743059",
    "end": "3750640"
  },
  {
    "text": "But I think the-- I mean, there's\none version where you try to make that better.",
    "start": "3750640",
    "end": "3756370"
  },
  {
    "text": "But then the question is what\nis your ground truth signal? And I think better\nangle of attack",
    "start": "3756370",
    "end": "3763300"
  },
  {
    "text": "is probably interpretability,\nwhere you figure out how to look inside the model\nand then how it actually works.",
    "start": "3763300",
    "end": "3771000"
  },
  {
    "text": "That's what I'm asking about. The level of research\non interpretability,",
    "start": "3771000",
    "end": "3776029"
  },
  {
    "text": "it seems as though that's\nbeen really [INAUDIBLE] such a high pressure space.",
    "start": "3776029",
    "end": "3782000"
  },
  {
    "text": "Your current thinking is moving\ntowards [INAUDIBLE] reducing dimensionality effects of\nreputation something that",
    "start": "3782000",
    "end": "3788540"
  },
  {
    "text": "can be [INAUDIBLE]. Yeah, I mean, we are\nworking on that problem.",
    "start": "3788540",
    "end": "3797058"
  },
  {
    "text": "But I don't think\nwe have anything that like-- to show right now. And so it seems, generally,\nnot to be a very easy problem.",
    "start": "3797059",
    "end": "3809460"
  },
  {
    "text": "But I'm hopeful that\nwe can do some things. I think in general, the problem\nof interpretability or using",
    "start": "3809460",
    "end": "3819318"
  },
  {
    "text": "interpretability for\nalignment is kind of tricky because I suspect it's\ngoing to be neither--",
    "start": "3819319",
    "end": "3825539"
  },
  {
    "text": "it's going to be not sufficient. And it might not be necessary. So any amount of\ninterpretability",
    "start": "3825539",
    "end": "3831770"
  },
  {
    "text": "you can leverage would\nbe useful because it's another tool in the toolbox of\ndetecting deception or knowing",
    "start": "3831770",
    "end": "3840069"
  },
  {
    "text": "what you said, how-- why the model gave\na certain answer and made a certain decision.",
    "start": "3840070",
    "end": "3847359"
  },
  {
    "text": "But it is kind of\nunclear if you really get really good at\ninterpretability",
    "start": "3847359",
    "end": "3852838"
  },
  {
    "text": "how you then leverage\nthat for alignment. Presumably, you could\nlook in the model",
    "start": "3852839",
    "end": "3858550"
  },
  {
    "text": "and just throw\nall the models out that you can find\na misalignment in. But then aren't\nyou just selecting",
    "start": "3858550",
    "end": "3864328"
  },
  {
    "text": "for models that\nhave misalignments that are really hard to find\nwith the interpretability tools?",
    "start": "3864329",
    "end": "3869900"
  },
  {
    "text": "Sure, just [INAUDIBLE] because\nreason I ask about that is standard practice\nin a ethical journal is that you have to put an\nexplanation on [INAUDIBLE]..",
    "start": "3869900",
    "end": "3877309"
  },
  {
    "text": "And I guess my\nquestion is like-- why would you think\ninterpretabilty would not be necessary?",
    "start": "3877310",
    "end": "3882828"
  },
  {
    "text": "Yes, so why would\nit not be necessary? So again, this is kind\nof like an open question.",
    "start": "3882829",
    "end": "3890670"
  },
  {
    "text": "But basically, what stance you\ncould take is that at the end",
    "start": "3890670",
    "end": "3895788"
  },
  {
    "text": "of the day, what really\nis going to matter is the decisions that the\nmodel actually takes and not",
    "start": "3895789",
    "end": "3901769"
  },
  {
    "text": "the reasons why it took them. And so if you can\nget to the point where you're confident that all\nthe things the model actually",
    "start": "3901770",
    "end": "3908859"
  },
  {
    "text": "does are aligned\nwith what you want, then does it still matter what\nthe model thinks internally?",
    "start": "3908859",
    "end": "3915610"
  },
  {
    "text": "I don't know. [INAUDIBLE] if I\nhave the ability to evaluate the\nmorality of the model?",
    "start": "3915610",
    "end": "3922549"
  },
  {
    "text": "Yeah, that's what\nwe're trying to do. We're trying to make like a\nreally, really good evaluation",
    "start": "3922549",
    "end": "3928880"
  },
  {
    "text": "signal. And then you can select for-- you can train the\nmodel to do the things that you want it to do because\nyou can just always evaluate.",
    "start": "3928880",
    "end": "3937720"
  },
  {
    "text": "Then the model can do stuff. I've probably [INAUDIBLE]\nthat much about that.",
    "start": "3937720",
    "end": "3946288"
  },
  {
    "text": "Yeah, that's my question. I don't think\nthere's [INAUDIBLE].. But yeah, thanks so much\nfor the great lecture.",
    "start": "3946289",
    "end": "3953360"
  },
  {
    "text": "Very interesting. Actually, [INAUDIBLE]\ntopic of ChatGPT, I might care just to do a live\non this application thing.",
    "start": "3953360",
    "end": "3960410"
  },
  {
    "text": "Yeah, sure. Just to end the class.",
    "start": "3960410",
    "end": "3965620"
  },
  {
    "text": "Sorry, so I'll just [INAUDIBLE]. [INTERPOSING VOICES]",
    "start": "3965620",
    "end": "3970730"
  },
  {
    "text": "Give our speaker a\nround of applause.",
    "start": "3970730",
    "end": "3973619"
  }
]
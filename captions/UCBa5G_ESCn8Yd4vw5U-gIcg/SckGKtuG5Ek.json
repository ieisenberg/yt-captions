[
  {
    "start": "0",
    "end": "9900"
  },
  {
    "text": "So I'm very happy to be\nhere to share with you some of our recent research on\nenhancing AI-assisted decision",
    "start": "9900",
    "end": "16650"
  },
  {
    "text": "making. So as we all know,\nthe AI technology has made remarkable\nprogress in the past decade.",
    "start": "16650",
    "end": "23310"
  },
  {
    "text": "Today, AI has been widely\napplied to many different areas in our daily life, from\nfinance to health care",
    "start": "23310",
    "end": "29610"
  },
  {
    "text": "to criminal justice. And this rapid development of AI\nhas also fundamentally changed",
    "start": "29610",
    "end": "35430"
  },
  {
    "text": "how decisions are made today. So in the past, given a\ndecision-making task, usually,",
    "start": "35430",
    "end": "40470"
  },
  {
    "text": "it's a human who will\nprocess this task and deliberate about\ndifferent possible options and make a final decision.",
    "start": "40470",
    "end": "46860"
  },
  {
    "text": "But today, AI models\nhave been trained to uncover hidden\ninsights from big data.",
    "start": "46860",
    "end": "52300"
  },
  {
    "text": "So now, given this same\ndecision-making tasks, those decision AIs that\nare powered by AI models",
    "start": "52300",
    "end": "58410"
  },
  {
    "text": "can analyze the task and\ncome up with some decision recommendations,\nwhich will later be presented to\nhuman decision makers",
    "start": "58410",
    "end": "65670"
  },
  {
    "text": "to assist them in\ntheir decision making. So of course, this essentially\ntransformed the decision",
    "start": "65670",
    "end": "71620"
  },
  {
    "text": "making from the\ntask of humans alone to a task that is jointly\ncompleted by human decision",
    "start": "71620",
    "end": "77530"
  },
  {
    "text": "makers and AI model. And the hope here is that\nbecause human and AI each",
    "start": "77530",
    "end": "83050"
  },
  {
    "text": "have their respective\nstrengths and weakness, through collaborating\nwith each other, they can complement each\nother's strengths and weakness",
    "start": "83050",
    "end": "91549"
  },
  {
    "text": "and therefore, as\na team, they can achieve a level of\ndecision-making performance that outperform either\nhuman alone or AI alone.",
    "start": "91550",
    "end": "99890"
  },
  {
    "text": "But in reality, this\nkind of human-AI complements reality\nis rarely observed.",
    "start": "99890",
    "end": "105770"
  },
  {
    "text": "And naturally, we will\nwonder why this is the case and what we can do\nin order to improve",
    "start": "105770",
    "end": "111250"
  },
  {
    "text": "the AI-assisted\ndecision-making performance. So I will argue that\nin order to improve",
    "start": "111250",
    "end": "117190"
  },
  {
    "text": "the performance of\nAI-assisted decision making, there are two essential\nsteps for us to take.",
    "start": "117190",
    "end": "122659"
  },
  {
    "text": "First, we really need to obtain\nmore empirical understandings of how exactly do human\ndecision makers engage",
    "start": "122660",
    "end": "130300"
  },
  {
    "text": "with AI-based decision aids? So this could mean how\nwell human decision makers trust and rely on the\nrecommendations provided by AI.",
    "start": "130300",
    "end": "137989"
  },
  {
    "text": "And this could\nalso mean how human will factor AI models\ndecision recommendation",
    "start": "137990",
    "end": "143230"
  },
  {
    "text": "into their final decision. Now, with this\nempirical understanding of humans interaction\nwith or humans engagement",
    "start": "143230",
    "end": "150460"
  },
  {
    "text": "with AI-based decision\naids, the next step is really to leverage\nthis understanding",
    "start": "150460",
    "end": "155560"
  },
  {
    "text": "and improve the designs\nof AI-based decision aids to account for humans'\nengagement behavior.",
    "start": "155560",
    "end": "161810"
  },
  {
    "text": "And in today's talk,\nwhat I'm going to do is that I will share with\nyou a couple of projects",
    "start": "161810",
    "end": "166990"
  },
  {
    "text": "that is carried out in my group\nalong these two directions and showcase how we may leverage\nour understandings of humans'",
    "start": "166990",
    "end": "174730"
  },
  {
    "text": "engagement with AI to improve\nAI-assisted decision making. OK, so now, let's start\nwith this first step,",
    "start": "174730",
    "end": "181910"
  },
  {
    "text": "obtaining more\nempirical understandings of humans' engagement with AI. So in the past few\nyears, my group",
    "start": "181910",
    "end": "188860"
  },
  {
    "text": "has carried out a number of\nempirical research projects to look into how\nexactly do humans",
    "start": "188860",
    "end": "195130"
  },
  {
    "text": "engage with AI in this joint\ndecision-making process. And we have identified a\nnumber of interesting lessons",
    "start": "195130",
    "end": "203320"
  },
  {
    "text": "through this process. The first lesson\nthat we learned is that in collaboration\nwith AI-based decision",
    "start": "203320",
    "end": "211250"
  },
  {
    "text": "is humans' trust\nand reliance on AI is often shaped by various\nperformance indicators of the AI",
    "start": "211250",
    "end": "218560"
  },
  {
    "text": "model, especially\nAI's performance that humans observed in\nthe field by themselves.",
    "start": "218560",
    "end": "224390"
  },
  {
    "text": "Now, secondly, in addition\nto AI's performance, we also find that\nhumans' confidence",
    "start": "224390",
    "end": "230500"
  },
  {
    "text": "in their own\nindependent judgment on different\ndecision-making cases will influence how much\nthey are willing to listen",
    "start": "230500",
    "end": "237790"
  },
  {
    "text": "to AI's suggestions. So holding everything\nelse equal, humans are more likely to be\nreceptive to AI's decision",
    "start": "237790",
    "end": "244930"
  },
  {
    "text": "recommendation when\ntheir own decision confidence is relatively low. Now, in reality, there\nare actually many cases",
    "start": "244930",
    "end": "253000"
  },
  {
    "text": "that humans will not observe\nany AI model's performance. So in those cases,\nhow would humans",
    "start": "253000",
    "end": "259450"
  },
  {
    "text": "decide how much to\ntrust or rely on AI? And the third lesson\nthat we find here is that when AI performance\ninformation is absent,",
    "start": "259450",
    "end": "268460"
  },
  {
    "text": "humans have this\ntendency that they will make use of the level\nof agreement between AI",
    "start": "268460",
    "end": "274120"
  },
  {
    "text": "models' decision recommendation\nand their own independent judgment on cases that\nthey feel confident about",
    "start": "274120",
    "end": "280210"
  },
  {
    "text": "to gauge the trustworthiness\nof the AI model. So we find out this lesson\nthrough a human subject",
    "start": "280210",
    "end": "285880"
  },
  {
    "text": "experiment. So now let me actually\ntell you a bit more about this human\nsubject experiment.",
    "start": "285880",
    "end": "291220"
  },
  {
    "text": "So in this experiment, what we\nask the human subjects to do is to complete the speed\ndating prediction tasks.",
    "start": "291220",
    "end": "299480"
  },
  {
    "text": "So essentially, we\nwill give our subjects a speed dating profile like\nwhat I'm showing to you here",
    "start": "299480",
    "end": "305380"
  },
  {
    "text": "on the screen. So this profile\ncontains information like the demographic\nbackground of the participants",
    "start": "305380",
    "end": "311449"
  },
  {
    "text": "in the speed dating\nevent, as well as the demographic\nbackground of the date. And we will show\nthem some information",
    "start": "311450",
    "end": "317990"
  },
  {
    "text": "in terms of what kind of things\nthat these participants value in their romantic\npartner and what's",
    "start": "317990",
    "end": "324290"
  },
  {
    "text": "their impression of their date\nin the speed dating event. So after reviewing all\nthis information, what",
    "start": "324290",
    "end": "330320"
  },
  {
    "text": "we ask the subjects to\ndo is to first come up with their own independent\njudgment in terms",
    "start": "330320",
    "end": "335780"
  },
  {
    "text": "of whether they think the\nparticipants in the speed dating event would be willing\nto see their date again",
    "start": "335780",
    "end": "342740"
  },
  {
    "text": "in the future. And after they make their\nindependent judgment, we are going to show to them\nan AI model's prediction",
    "start": "342740",
    "end": "348650"
  },
  {
    "text": "as the decision recommendation. And finally, the subjects need\nto submit their final decision, and they are free to decide\nwhether they want to follow",
    "start": "348650",
    "end": "356810"
  },
  {
    "text": "AI's suggestions or not. So now, in order to enable\nour later experimental design,",
    "start": "356810",
    "end": "363650"
  },
  {
    "text": "as the first step, we carried\nout a pilot study just to get a sense of for different\nspeed dating outcome prediction",
    "start": "363650",
    "end": "370880"
  },
  {
    "text": "tasks, usually what\nkind of decisions that people may come up\nwith and how confident they",
    "start": "370880",
    "end": "376550"
  },
  {
    "text": "are about their decision. So what we did is we\nasked our human subjects to complete a large set of\nspeed dating outcome prediction",
    "start": "376550",
    "end": "384319"
  },
  {
    "text": "tasks on their own. And on each of the\ntask, we are going to ask them to provide\nboth their binary decision,",
    "start": "384320",
    "end": "392990"
  },
  {
    "text": "and also, we ask them to\nindicate how confident they are in their decision. So with this information that\nwe collected from our subjects,",
    "start": "392990",
    "end": "401610"
  },
  {
    "text": "we are able to categorize\ndifferent decision-making tasks into several\ncategories or groups.",
    "start": "401610",
    "end": "408330"
  },
  {
    "text": "For example, the first\ngroup of instances are those decision-making\ntasks where",
    "start": "408330",
    "end": "413660"
  },
  {
    "text": "the overwhelming majority\nof the human subjects, meaning more than 80% of the\nhuman subjects, when they make",
    "start": "413660",
    "end": "419330"
  },
  {
    "text": "decisions on those cases,\nthe decision is correct,",
    "start": "419330",
    "end": "424439"
  },
  {
    "text": "and they also tend to make\nthose decisions with very high confidence. And the second categories\nof cash instances",
    "start": "424440",
    "end": "431540"
  },
  {
    "text": "are those cases that when people\nmake decisions independently, they make wrong decisions, but\nthey also make wrong decisions",
    "start": "431540",
    "end": "438530"
  },
  {
    "text": "with very high confidence. And you can imagine the\nthird and fourth categories of instances are the ones\nthat the overwhelming majority",
    "start": "438530",
    "end": "445820"
  },
  {
    "text": "of the human subjects, when they\nmake decisions on those cases, they are either making correct\ndecision or wrong decision.",
    "start": "445820",
    "end": "452460"
  },
  {
    "text": "But when they make\nthose decisions, their confidence\nis relatively low. So now with these\nfour different types",
    "start": "452460",
    "end": "459230"
  },
  {
    "text": "of instances being\nidentified, I'm ready to tell you about our\nformal experimental design.",
    "start": "459230",
    "end": "464700"
  },
  {
    "text": "So in the formal experiment,\nwhat we asked the subjects to do is to complete a same sequence\nof 40 decision-making tasks",
    "start": "464700",
    "end": "472580"
  },
  {
    "text": "with the help from an AI model. And throughout this\nexperiment, we never tell our human participants\nhow good the AI model performs.",
    "start": "472580",
    "end": "481680"
  },
  {
    "text": "And these 40 tasks are\ndivided into two phases, with each phase\ncontaining 20 tasks.",
    "start": "481680",
    "end": "487590"
  },
  {
    "text": "Now, for the first\n20 tasks in phase 1, we made sure that all\nthose 20 tasks in phase one",
    "start": "487590",
    "end": "493820"
  },
  {
    "text": "selected from the first two\ncategories of task instances as we identified\nin the pilot study,",
    "start": "493820",
    "end": "499710"
  },
  {
    "text": "meaning that when human subjects\nmakes independent decisions on those cases,\nthey tend to have",
    "start": "499710",
    "end": "506090"
  },
  {
    "text": "high confidence in their\nown independent judgment. And then what we\ndid is we created",
    "start": "506090",
    "end": "511280"
  },
  {
    "text": "three experimental\ntreatment by varying how frequently AI models'\ndecision recommendation, agree",
    "start": "511280",
    "end": "518059"
  },
  {
    "text": "with humans' majority judgment\non the 20 tasks in phase 1. So this level of agreement\ncan be as low as 40%,",
    "start": "518059",
    "end": "526710"
  },
  {
    "text": "meaning that the AI's\nsuggestion is owning the same as humans' majority\njudgment on 40% of the phase 1",
    "start": "526710",
    "end": "534290"
  },
  {
    "text": "tasks, or it can\nbe as high as 100%, meaning the AI's\nsuggestion is completely",
    "start": "534290",
    "end": "540110"
  },
  {
    "text": "agreeing with human's\nindependent judgment on all tasks in phase 1. So if you think about it,\nfor our subjects in phase 1,",
    "start": "540110",
    "end": "548220"
  },
  {
    "text": "they essentially see exactly the\nsame 20 decision-making tasks. But depending on the treatment\nthey get assigned to,",
    "start": "548220",
    "end": "554569"
  },
  {
    "text": "they receive different\nrecommendation from the AI model in phase 1.",
    "start": "554570",
    "end": "559710"
  },
  {
    "text": "And they experience a different\nlevel of agreement between AI and themselves on cases that\nthey feel confident about.",
    "start": "559710",
    "end": "566430"
  },
  {
    "text": "And another caveat that\nI want to mention here is that even though\nin this experiment,",
    "start": "566430",
    "end": "571710"
  },
  {
    "text": "we never tell our\nsubjects how good or how bad the AI model\nperforms, to make sure that AI models' actual\nperformance is not",
    "start": "571710",
    "end": "579440"
  },
  {
    "text": "going to be a confounding\nvariable of our experiment, we also made sure that in phase\n1, across the three treatment,",
    "start": "579440",
    "end": "586320"
  },
  {
    "text": "the AI models' actual\naccuracy is exactly the same. And the way that we do this\nis in these three treatment,",
    "start": "586320",
    "end": "593899"
  },
  {
    "text": "for this high\nagreement treatment, we have no choice but to set AI\nmodels' decision recommendation",
    "start": "593900",
    "end": "599899"
  },
  {
    "text": "to be the same as\nhumans' majority judgment on each of the tasks. So this means that whenever\na human is correct,",
    "start": "599900",
    "end": "606300"
  },
  {
    "text": "AI is also correct. When human is wrong,\nAI also is wrong. But as we move from\nhigh agreement treatment",
    "start": "606300",
    "end": "611970"
  },
  {
    "text": "to low agreement\ntreatment, what we did is that every time when we flip\nAI's recommendation on a task",
    "start": "611970",
    "end": "618600"
  },
  {
    "text": "that humans' majority\njudgment is correct, we also flip AI's decision\nrecommendation on another task",
    "start": "618600",
    "end": "625170"
  },
  {
    "text": "where humans' majority\njudgment is wrong. So we are able to preserve the\nAI's accuracy across the three",
    "start": "625170",
    "end": "632160"
  },
  {
    "text": "treatment but create\ndifferent level of agreement. And one note that\nI want to make here",
    "start": "632160",
    "end": "637589"
  },
  {
    "text": "is that if you look at this\nlow agreement AI model, it actually is the\nmodel that complements",
    "start": "637590",
    "end": "644310"
  },
  {
    "text": "humans expertise the\nmost because it's most likely to be\ncorrect in those cases",
    "start": "644310",
    "end": "650430"
  },
  {
    "text": "that humans' own independent\njudgment is wrong. So I'll come back to this\npoint a little bit later",
    "start": "650430",
    "end": "656850"
  },
  {
    "text": "when we discuss about the\nresult of our experiment. OK. So this is phase 1.",
    "start": "656850",
    "end": "662259"
  },
  {
    "text": "Now, we're moving to phase 2. So the goal of\nphase two is to try to say after our\nsubjects experienced",
    "start": "662260",
    "end": "668760"
  },
  {
    "text": "a different level of agreement\nbetween AI and themselves, will they actually trust or\nrely on AI in a different degree",
    "start": "668760",
    "end": "678550"
  },
  {
    "text": "when they are making\ndecisions later on? And in order to maximize this\npossible effect for the 20 tasks",
    "start": "678550",
    "end": "685480"
  },
  {
    "text": "in phase 2, we\nselect them all from the third and fourth categories\nof instances in our pilot study.",
    "start": "685480",
    "end": "691640"
  },
  {
    "text": "So when humans make independent\njudgment on phase 2 tasks, they tend to make their\nindependent judgment",
    "start": "691640",
    "end": "697960"
  },
  {
    "text": "with low confidence. And this time in\nphase 2, we made sure that across the three\ntreatment, the subjects not only",
    "start": "697960",
    "end": "705520"
  },
  {
    "text": "see exactly the same 20\ndecision-making tasks, but they also received the\nsame recommendation from the AI",
    "start": "705520",
    "end": "711130"
  },
  {
    "text": "model. Yeah. Clarification. To make sure I\nfollow, for example, in the low agreement case, this\nis not an actual algorithm then",
    "start": "711130",
    "end": "722470"
  },
  {
    "text": "that's-- like you're assigning\nit the recommendations? Yeah. So we are simulating\nhow the AI will perform.",
    "start": "722470",
    "end": "729019"
  },
  {
    "text": "We are assigning AI model\na different prediction. Although in reality, if we\nwant to train the AI model,",
    "start": "729020",
    "end": "735170"
  },
  {
    "text": "we could train the model\nto behave like this. Unselected tasks as well. OK. Yeah.",
    "start": "735170",
    "end": "741070"
  },
  {
    "text": "OK. Cool. So in order to quantify our\nsubjects' trust and reliance",
    "start": "741070",
    "end": "746740"
  },
  {
    "text": "on the AI model, what we did\nis that we asked the subjects to report their perception\nof the AI model,",
    "start": "746740",
    "end": "752540"
  },
  {
    "text": "both at the middle\nof the experiment and at the end of the\nentire experiment. And we also looked\ninto, in phase 2,",
    "start": "752540",
    "end": "759500"
  },
  {
    "text": "when the AI model provides\nexactly the same decision recommendation across\nthe three treatment,",
    "start": "759500",
    "end": "764540"
  },
  {
    "text": "how frequently our human\nsubjects' final decision is the same as AI models decision\nrecommendation, especially",
    "start": "764540",
    "end": "771430"
  },
  {
    "text": "if humans' initial judgment is\ndifferent from AI's decision recommendation.",
    "start": "771430",
    "end": "777050"
  },
  {
    "text": "So these two metrics\nagreement and switch fractions are the metrics for us to\nquantify people's reliance",
    "start": "777050",
    "end": "783280"
  },
  {
    "text": "on AI. And you can imagine\nthe higher the value, the more people relied on AI.",
    "start": "783280",
    "end": "788520"
  },
  {
    "text": "OK. So now, let me share with you\nwhat we find in this experiment. So as you can see from the\nfigure here, what we see",
    "start": "788520",
    "end": "796990"
  },
  {
    "text": "is that as we increase the level\nof agreement between AI model and humans' independent\njudgment in phase 1 in cases",
    "start": "796990",
    "end": "805000"
  },
  {
    "text": "that people feel\nconfident about, our human subjects\ngenerally report that they see the AI model\nas more Elkridge, more",
    "start": "805000",
    "end": "812470"
  },
  {
    "text": "reliable, more\nunderstandable, and they trust the AI model more. And in the end of\nthe day, they also",
    "start": "812470",
    "end": "817959"
  },
  {
    "text": "relied on the AI models'\ndecision recommendation more in phase 1. But again, recall across\nthe three treatment,",
    "start": "817960",
    "end": "824899"
  },
  {
    "text": "our AI model actually provide\nexactly the same decision recommendation to\npeople in phase 2.",
    "start": "824900",
    "end": "830690"
  },
  {
    "text": "So in this sense,\nwhat we observe here seems to suggest that\nwhen people do not",
    "start": "830690",
    "end": "836080"
  },
  {
    "text": "have any performance\ninformation about an AI, they have this tendency to make\nuse of the level of agreement",
    "start": "836080",
    "end": "842980"
  },
  {
    "text": "between AI and their own\nindependent judgment on cases that they feel confident\nabout as a heuristic",
    "start": "842980",
    "end": "850150"
  },
  {
    "text": "to gauge the trustworthiness\nof the AI model. And if you think about\nit, this kind of heuristic",
    "start": "850150",
    "end": "856320"
  },
  {
    "text": "is highly related to one type\nof human cognitive bias, which is confirmation bias.",
    "start": "856320",
    "end": "862440"
  },
  {
    "text": "So essentially, whoever\nagree with me is great. I'm going to follow\ntheir recommendation.",
    "start": "862440",
    "end": "867730"
  },
  {
    "text": "Whoever disagree with\nme, it will be ignored. So in this sense,\nour findings here seems to suggest\nthat humans may even",
    "start": "867730",
    "end": "874980"
  },
  {
    "text": "exhibit a degree of confirmation\nbias towards AI model who provide decision\nrecommendations to them.",
    "start": "874980",
    "end": "881770"
  },
  {
    "text": "And you can potentially\nimagine this kind of possible confirmation bias\nwill bring up some risks.",
    "start": "881770",
    "end": "888730"
  },
  {
    "text": "For example, if we look back\ninto how our human subjects rely",
    "start": "888730",
    "end": "894600"
  },
  {
    "text": "on AI models' decision\nrecommendation in phase 2 one more time,\nbut this time we separate the case, will\nAI's decision recommendation",
    "start": "894600",
    "end": "902190"
  },
  {
    "text": "is correct versus the case that\nAI's decision recommendation is wrong, you see that the general\npattern across the three",
    "start": "902190",
    "end": "908850"
  },
  {
    "text": "treatments is the same\nin both scenarios. So this really\nsuggests that humans",
    "start": "908850",
    "end": "914070"
  },
  {
    "text": "may over-trust an AI models'\nwrong decision recommendation just because the AI tends\nto agree with themselves",
    "start": "914070",
    "end": "921840"
  },
  {
    "text": "and humans may under-trust\nan AI models decision recommendation just\nbecause AI tends",
    "start": "921840",
    "end": "927510"
  },
  {
    "text": "to disagree with themselves. And in fact, if we look into the\nfinal decision-making accuracy",
    "start": "927510",
    "end": "934140"
  },
  {
    "text": "across the three\ntreatment, you can see that no matter\nwhether we are looking into the accuracy in phase 1 or\nphase 2 or two phases combined,",
    "start": "934140",
    "end": "943900"
  },
  {
    "text": "we actually see very\nlimited difference across the final human\ndecision-making accuracy",
    "start": "943900",
    "end": "949740"
  },
  {
    "text": "across the three treatment. And this is rather\ndisappointing, right, because as we mentioned\nbefore, the AI model used",
    "start": "949740",
    "end": "956640"
  },
  {
    "text": "in this low agreement\ntreatment is actually an AI model that's highly\ncomplimentary to humans'",
    "start": "956640",
    "end": "962400"
  },
  {
    "text": "own expertise. And this seems to suggest\nthat because humans have this tendency to\nunder-trust an AI model that",
    "start": "962400",
    "end": "971170"
  },
  {
    "text": "is highly complementary\nto their own expertise, they may actually miss the\nopportunity to fully release",
    "start": "971170",
    "end": "979240"
  },
  {
    "text": "the potential of human-AI\ncomplementarility when the AI model tries to\ncomplement their expertise.",
    "start": "979240",
    "end": "985670"
  },
  {
    "text": "And finally, in some\nof our recent research, we also noticed that this\nconfirmation bias may actually",
    "start": "985670",
    "end": "992529"
  },
  {
    "text": "reflect a serious vulnerability\nin human-AI collaboration. This is because the adversarial\nparties could strategic--",
    "start": "992530",
    "end": "1001860"
  },
  {
    "text": "understanding humans have this\nconfirmation bias towards AI, they could choose to\nselectively attack the AI model",
    "start": "1001860",
    "end": "1009210"
  },
  {
    "text": "on those cases that they feel\nhumans will be confident about. And doing this will help them\nto destroy humans' trust in AI",
    "start": "1009210",
    "end": "1018149"
  },
  {
    "text": "in the most fast way. And in fact, the\nadversarial parties",
    "start": "1018150",
    "end": "1023370"
  },
  {
    "text": "could even use some\ncomputational models like hidden Markov\nmodel to characterize",
    "start": "1023370",
    "end": "1028589"
  },
  {
    "text": "how their attacks\nto this AI models will influence people's trust\nand reliance on the AI model.",
    "start": "1028589",
    "end": "1035670"
  },
  {
    "text": "And eventually\nusing the insights that they obtained from\nthese computational models,",
    "start": "1035670",
    "end": "1040689"
  },
  {
    "text": "they may be able to develop some\nstrategy to strategically deploy the attacks to AI models\nsuch that they will maximize",
    "start": "1040690",
    "end": "1049260"
  },
  {
    "text": "the reduction of human-AI joint\nteam performance in decision making while minimizing\nthe cost of attack.",
    "start": "1049260",
    "end": "1056650"
  },
  {
    "text": "So this really suggests\nthat it is urgent for us to think about how\ncan we leverage",
    "start": "1056650",
    "end": "1062220"
  },
  {
    "text": "our understandings of\nhumans' engagement behavior with AI to really combat\nagainst the adverserial parties",
    "start": "1062220",
    "end": "1069960"
  },
  {
    "text": "and secure the human\nAI collaboration. OK. So that's all for\nthe first part that I",
    "start": "1069960",
    "end": "1077309"
  },
  {
    "text": "want to show, understanding\nhumans' engagement behavior with AI. Now let me move on\nto the second part.",
    "start": "1077310",
    "end": "1084040"
  },
  {
    "text": "Once we have this\nunderstanding, how can we design interventions\nto improve the human-AI team",
    "start": "1084040",
    "end": "1090090"
  },
  {
    "text": "performance in decision making. So ideally, what we\nreally want to achieve",
    "start": "1090090",
    "end": "1095909"
  },
  {
    "text": "is that we want the human\ndecision makers to cleverly combine their wisdom reflected\nin their own independent",
    "start": "1095910",
    "end": "1103170"
  },
  {
    "text": "judgment with AI models'\ndecision recommendation. But what we see in the\nprevious project basically",
    "start": "1103170",
    "end": "1108990"
  },
  {
    "text": "says that humans\nare not doing that. Humans are leveraging\ntheir independent judgment",
    "start": "1108990",
    "end": "1114120"
  },
  {
    "text": "in a rather heuristic way. They are not really\nutilizing their strengths and avoid their weakness in\ntheir independent judgment.",
    "start": "1114120",
    "end": "1121299"
  },
  {
    "text": "So now the question\nis, how can we help humans utilize\ntheir strengths and avoid their weakness in\ntheir independent judgment?",
    "start": "1121300",
    "end": "1128500"
  },
  {
    "text": "So we looked into this\nin a recent CHI paper. And we actually came up with a\nfairly straightforward thought.",
    "start": "1128500",
    "end": "1136120"
  },
  {
    "text": "We think that in order to help\nhumans utilize their strengths and avoid their\nweakness, we first",
    "start": "1136120",
    "end": "1142020"
  },
  {
    "text": "need to let humans know\nwhere their strengths and weaknesses are, especially\nin comparison to AI.",
    "start": "1142020",
    "end": "1148770"
  },
  {
    "text": "So this means that it\nwill be super great if on each individual\ndecision making task,",
    "start": "1148770",
    "end": "1154780"
  },
  {
    "text": "we can estimate how likely\nhumans' decision is going to be correct on that case\nand how likely AI's decision",
    "start": "1154780",
    "end": "1162360"
  },
  {
    "text": "recommendation is going to\nbe correct on that case. Because if we are\nable to come up with this kind of correctness\nlikelihood estimation,",
    "start": "1162360",
    "end": "1170529"
  },
  {
    "text": "then maybe we can guide\nthe human decision makers to follow AI when I is\nmore likely to be correct,",
    "start": "1170530",
    "end": "1178210"
  },
  {
    "text": "and we can guide humans\nto follow themselves when they themselves are\nmore likely to be correct.",
    "start": "1178210",
    "end": "1184120"
  },
  {
    "text": "So this vision is really\nnice, but in order to realize this vision, we have\na couple of practical challenges",
    "start": "1184120",
    "end": "1190679"
  },
  {
    "text": "to address. The first practical\nchallenge is that how can we actually estimate the\ncorrectness likelihood",
    "start": "1190680",
    "end": "1196620"
  },
  {
    "text": "of both human and AI? And AI's side, things\nmight be slightly easier",
    "start": "1196620",
    "end": "1201840"
  },
  {
    "text": "because we can potentially just\nuse AI's calibrated confidence score as an indication for\nthis correctness likelihood.",
    "start": "1201840",
    "end": "1209370"
  },
  {
    "text": "But what about humans? How can we estimate humans'\ncorrectness likelihood on different decision-making\ntasks in the real-time?",
    "start": "1209370",
    "end": "1216740"
  },
  {
    "text": "So that is our\nchallenge number one. Now, challenge number two is\neven if we are able to obtain",
    "start": "1216740",
    "end": "1223559"
  },
  {
    "text": "this correctness likelihood\nestimation for both humans and AI, what should we do to\ncommunicate this information",
    "start": "1223560",
    "end": "1231000"
  },
  {
    "text": "back to human decision makers\nso that we can nudge them into taking more, quote,\nunquote, \"rational actions\"",
    "start": "1231000",
    "end": "1238140"
  },
  {
    "text": "by either follow AI\nor follow themselves. That's our challenge number two. So in the next few\nminutes, I'm going",
    "start": "1238140",
    "end": "1244530"
  },
  {
    "text": "to expand a little bit on\nhow we address these two challenges, starting\nfrom the first one,",
    "start": "1244530",
    "end": "1250480"
  },
  {
    "text": "how can we estimate humans'\ncorrectness likelihood on different decision making\ntasks for which we may not even",
    "start": "1250480",
    "end": "1257280"
  },
  {
    "text": "know the ground truth answer. So this sounds to be a\nrelatively complicated task.",
    "start": "1257280",
    "end": "1263160"
  },
  {
    "text": "So if we don't really\nknow the ground truth answer for a\ndecision-making task, how can we even\nknow whether human",
    "start": "1263160",
    "end": "1268950"
  },
  {
    "text": "is going to be correct\nor not on that task? So here, we are making\nan important assumption.",
    "start": "1268950",
    "end": "1274940"
  },
  {
    "text": "We are assuming that if a\nperson's decision on a task that is similar to the\ncurrent task is correct,",
    "start": "1274940",
    "end": "1282649"
  },
  {
    "text": "then this person's decision\non the current task is more likely to be correct.",
    "start": "1282650",
    "end": "1287919"
  },
  {
    "text": "So if you agree with this\nassumption, then potentially, one way we can adopt to estimate\nhumans' correctness likelihood",
    "start": "1287920",
    "end": "1297730"
  },
  {
    "text": "on the particular\ndecision-making task that we don't really know\nthe ground truth answer is that we can just look\ninto some other tasks that",
    "start": "1297730",
    "end": "1305950"
  },
  {
    "text": "are similar to this\ncurrent task and we check how frequently\nhumans' final decision is",
    "start": "1305950",
    "end": "1311740"
  },
  {
    "text": "correct on those other tasks. And for those other tasks, we\nneed to know the ground truth",
    "start": "1311740",
    "end": "1316960"
  },
  {
    "text": "answer. And one way for us to\nget those other tasks could be coming from the AI\nmodels' training data set.",
    "start": "1316960",
    "end": "1324490"
  },
  {
    "text": "So with this idea\nin mind, we actually developed a four-step\nworkflow to estimate",
    "start": "1324490",
    "end": "1331809"
  },
  {
    "text": "humans' correctness likelihood\non a decision-making task. So what we did is that we start\nby having the human decision",
    "start": "1331810",
    "end": "1338650"
  },
  {
    "text": "makers complete a small set\nof decision-making tasks on their own. And using the data we collected\nfrom the human decision maker,",
    "start": "1338650",
    "end": "1347000"
  },
  {
    "text": "we are able to learn a decision\ntree to roughly categorize how this decision maker makes\ntheir own independent decision.",
    "start": "1347000",
    "end": "1355429"
  },
  {
    "text": "And then we extract the\nrules from this decision tree and present the rules back\nto the human decision maker.",
    "start": "1355430",
    "end": "1362210"
  },
  {
    "text": "So if the human\ndecision maker thinks some of the rules in this\nset is not accurately",
    "start": "1362210",
    "end": "1369730"
  },
  {
    "text": "reflect their own\ndecision rationale, they can also\nmodify those rules. And in the end of\nthe day, what we",
    "start": "1369730",
    "end": "1375850"
  },
  {
    "text": "did is that using this\nuser-modified set of decision rules, we are able to\npredict what kind of decision",
    "start": "1375850",
    "end": "1384700"
  },
  {
    "text": "this decision maker may\nmake on each of the training task instances of the AI\nmodels' training data set.",
    "start": "1384700",
    "end": "1392560"
  },
  {
    "text": "And we can determine\nwhether those predicted decisions are correct or not. So in the wrong time, if we want\nto estimate the decision maker's",
    "start": "1392560",
    "end": "1401710"
  },
  {
    "text": "correctness likelihood on a new\ntask instance, what we will do is we will fetch a number\nof training task instances",
    "start": "1401710",
    "end": "1409600"
  },
  {
    "text": "that are similar to\nthis new task instance, and we will try to check how\nfrequently humans predicted",
    "start": "1409600",
    "end": "1415480"
  },
  {
    "text": "decisions on those similar\ntraining task instance is correct. And that frequency will be used\nas our correctness likelihood",
    "start": "1415480",
    "end": "1424270"
  },
  {
    "text": "estimation for the\nhuman decision maker. OK. So that helps us to solve\nthe first challenge,",
    "start": "1424270",
    "end": "1430270"
  },
  {
    "text": "how to estimate humans'\ncorrectness likelihood on different\ndecision making task. But we still have another\nmajor challenge ahead of us,",
    "start": "1430270",
    "end": "1439940"
  },
  {
    "text": "which is, how can we communicate\nthis information back to the human decision maker?",
    "start": "1439940",
    "end": "1445100"
  },
  {
    "text": "So perhaps one of the\nmost intuitive thought is that let's just\ntell people directly.",
    "start": "1445100",
    "end": "1451330"
  },
  {
    "text": "That's actually our\nfirst intervention, which is direct display.",
    "start": "1451330",
    "end": "1456370"
  },
  {
    "text": "So on this interface, you see\nwe tell human decision maker, here is our estimate of\nhow likely you are going",
    "start": "1456370",
    "end": "1463600"
  },
  {
    "text": "to be correct on this instance. Here is our estimation\nof how likely AI is going to be correct on this instance.",
    "start": "1463600",
    "end": "1470270"
  },
  {
    "text": "And this is just AI's\ncalibrated confidence score. And we present both\ntype of information",
    "start": "1470270",
    "end": "1475660"
  },
  {
    "text": "to human decision maker and ask\nthem to do whatever they want. So they can process\nthis information",
    "start": "1475660",
    "end": "1481120"
  },
  {
    "text": "and react in whatever\nway that they prefer. So this serves as our first\nintervention, direct display.",
    "start": "1481120",
    "end": "1488840"
  },
  {
    "text": "But after we came up\nwith this solution, we thought that maybe\nthis is too blunt.",
    "start": "1488840",
    "end": "1495520"
  },
  {
    "text": "This is too straightforward. So maybe we should\ntry to communicate",
    "start": "1495520",
    "end": "1501100"
  },
  {
    "text": "this information in a slightly\nmore subtle and indirect way. And the question\nthen is, how can we",
    "start": "1501100",
    "end": "1509130"
  },
  {
    "text": "communicate this information\nin a slightly more subtle way. And we thought that this\nsubtle communication",
    "start": "1509130",
    "end": "1515399"
  },
  {
    "text": "or indirect communication\nof correctness likelihood is actually possible. And one of the important basis\nfor this indirect communication",
    "start": "1515400",
    "end": "1524309"
  },
  {
    "text": "to be possible is that actually\nsome of the previous research have already found\nout that when you",
    "start": "1524310",
    "end": "1531150"
  },
  {
    "text": "use certain interfaces in the\nAI-assisted decision-making process, those interface\nwill nudge humans to decrease",
    "start": "1531150",
    "end": "1539130"
  },
  {
    "text": "their reliance on AI. But the drawback\nof those interfaces is that they will decrease\nhumans' reliance on AI",
    "start": "1539130",
    "end": "1545940"
  },
  {
    "text": "both when AI is correct. And when the AI is wrong. And that is not desirable\nbecause when AI's recommendation",
    "start": "1545940",
    "end": "1552990"
  },
  {
    "text": "is correct, we don't really\nwant humans to decrease their reliance on AI. But even though this is a\ntype of limited interface,",
    "start": "1552990",
    "end": "1562830"
  },
  {
    "text": "that actually provides\nopportunities for us to communicate the correctness\nestimation of both human and AI",
    "start": "1562830",
    "end": "1572970"
  },
  {
    "text": "in an indirect way. Because this means\nthat we may be able to design some adaptive\ninterface such that when",
    "start": "1572970",
    "end": "1581100"
  },
  {
    "text": "on a decision-making task, we\nfind human is more likely to be correct than AI, those\nare the perfect moments",
    "start": "1581100",
    "end": "1588360"
  },
  {
    "text": "that we want humans to\ndecrease their reliance on AI. And those are the\nperfect moment for us",
    "start": "1588360",
    "end": "1593940"
  },
  {
    "text": "to use those interfaces\nthat are known to decrease humans' reliance on AI.",
    "start": "1593940",
    "end": "1600090"
  },
  {
    "text": "So with this idea\nin mind, we came up with two additional\ninterventions.",
    "start": "1600090",
    "end": "1605350"
  },
  {
    "text": "And this first intervention-- well, this is now the\nsecond intervention is what we call\nadaptive workflow.",
    "start": "1605350",
    "end": "1612340"
  },
  {
    "text": "And the key idea here is that we\nare trying to adaptively decide when to present AI models'\ndecision recommendation",
    "start": "1612340",
    "end": "1619620"
  },
  {
    "text": "to human decision maker. And so as you can\nsee here, so what",
    "start": "1619620",
    "end": "1624660"
  },
  {
    "text": "really happened is on\nthe decision-making task,",
    "start": "1624660",
    "end": "1630990"
  },
  {
    "text": "if we find AI is more likely\nto be correct than human, we are going to show to human\ndecision makers the AI's",
    "start": "1630990",
    "end": "1637890"
  },
  {
    "text": "decision recommendation upfront. Otherwise, we are going to\nask the humans to first make",
    "start": "1637890",
    "end": "1643799"
  },
  {
    "text": "their own independent\njudgment and then show to them AI models' decision\nrecommendation. And this is precisely because\nsome of the previous research",
    "start": "1643800",
    "end": "1651720"
  },
  {
    "text": "have found that\nafter humans register their own independent judgment,\neven after they see the AI",
    "start": "1651720",
    "end": "1658620"
  },
  {
    "text": "models' decision\nrecommendation, they are less likely to switch to AI\nmodels' decision recommendation.",
    "start": "1658620",
    "end": "1664610"
  },
  {
    "text": "OK. So now, the third intervention\nthat we came up with is what we call\nadaptive recommendation.",
    "start": "1664610",
    "end": "1670450"
  },
  {
    "text": "And in this intervention, we're\nessentially adaptively change whether to provide AI\nmodels' recommended decision",
    "start": "1670450",
    "end": "1678240"
  },
  {
    "text": "to human at all. So in this case, if on\nthe decision-making task,",
    "start": "1678240",
    "end": "1683350"
  },
  {
    "text": "the AI's correctness\nlikelihood is higher than humans\ncorrectness likelihood,",
    "start": "1683350",
    "end": "1688720"
  },
  {
    "text": "we are going to show\nboth the AI's explanation to its decision and the\nrecommended decision to human.",
    "start": "1688720",
    "end": "1695740"
  },
  {
    "text": "Otherwise, we are going to\nonly show the AI's explanation",
    "start": "1695740",
    "end": "1701590"
  },
  {
    "text": "without showing to them the\nprecise recommended decision. And this is, again, because\nsome of the previous research",
    "start": "1701590",
    "end": "1707559"
  },
  {
    "text": "have found when people\nonly see AI's explanation and do not really see\nthe recommended decision,",
    "start": "1707560",
    "end": "1714200"
  },
  {
    "text": "they are less likely\nto eventually agree with AI's recommended decision.",
    "start": "1714200",
    "end": "1721240"
  },
  {
    "text": "OK. So now, I've introduced\nthe three different types of interventions\nthat we came up with.",
    "start": "1721240",
    "end": "1728059"
  },
  {
    "text": "And what we did is we tried\nto carry out a human subject",
    "start": "1728060",
    "end": "1733780"
  },
  {
    "text": "experiment to test whether\nthese interventions can help us improve the AI-assisted\ndecision-making performance",
    "start": "1733780",
    "end": "1740139"
  },
  {
    "text": "or not. And as you can see\nhere on this figure, compared to a\nbaseline condition--",
    "start": "1740140",
    "end": "1747380"
  },
  {
    "text": "So this is like the\nhuman's own performance. The dashed line is\nAI's own performance.",
    "start": "1747380",
    "end": "1753679"
  },
  {
    "text": "And this baseline condition\nwe are considering now is a default scenario\nthat will always",
    "start": "1753680",
    "end": "1760030"
  },
  {
    "text": "show to the human\ndecision makers, both the AI model's recommended\ndecision and its confidence.",
    "start": "1760030",
    "end": "1767540"
  },
  {
    "text": "And what we see\nhere is that when we provide the three types\nof decision interventions",
    "start": "1767540",
    "end": "1774250"
  },
  {
    "text": "to our human decision makers,\nour human decision makers generally have a marginal\nor significant increase",
    "start": "1774250",
    "end": "1781000"
  },
  {
    "text": "in their final\ndecision-making accuracy. And if we look closer into\nthe data, what we find",
    "start": "1781000",
    "end": "1787150"
  },
  {
    "text": "is that this increase in\ndecision-making accuracy is mostly caused by the decrease\nof humans' over-reliance on AI",
    "start": "1787150",
    "end": "1796160"
  },
  {
    "text": "when AI makes wrong\ndecision recommendation. And when AI makes correct\ndecision recommendation,",
    "start": "1796160",
    "end": "1801440"
  },
  {
    "text": "we find that our interventions\ndo not significantly affect people's trust\nand reliance on AI.",
    "start": "1801440",
    "end": "1808770"
  },
  {
    "text": "OK. ",
    "start": "1808770",
    "end": "1813870"
  },
  {
    "text": "So up until now,\nthe way that we try to adjust the designs of\nAI-based decision aids",
    "start": "1813870",
    "end": "1820970"
  },
  {
    "text": "is pretty much to\nadaptively change how AI's recommendation is\npresented to human decision",
    "start": "1820970",
    "end": "1827240"
  },
  {
    "text": "makers. We try to influence\nhow human behaves, but we don't really change\nanything about the AI model.",
    "start": "1827240",
    "end": "1833580"
  },
  {
    "text": "We are assuming the AI model\nis fixed and it's given. But an alternative way\nthat you can think of",
    "start": "1833580",
    "end": "1841309"
  },
  {
    "text": "to improve the designs\nof AI-based decision aids is that we can really retrain\nthe AI model to anticipate",
    "start": "1841310",
    "end": "1848029"
  },
  {
    "text": "humans' engagement\nbehavior and accommodate to humans' engagement behavior. So this really requires\nus to move away",
    "start": "1848030",
    "end": "1855620"
  },
  {
    "text": "from training behavior-oblivious\nAI model, in which case, we are really trying to find the\noptimal model parameters that",
    "start": "1855620",
    "end": "1864230"
  },
  {
    "text": "optimize for AI's own\ndecision-making performance. But what we really want is to\ntrain some behavior-aware AI",
    "start": "1864230",
    "end": "1872340"
  },
  {
    "text": "models. So this behavior-aware\nAI models will explicitly account for how humans will\nreact to AI models' decision",
    "start": "1872340",
    "end": "1880799"
  },
  {
    "text": "recommendation into\ntheir training objectives so that they will directly\noptimized for the human-AI team",
    "start": "1880800",
    "end": "1887700"
  },
  {
    "text": "performance in decision making. So as an example, we\nhave a recent study",
    "start": "1887700",
    "end": "1892950"
  },
  {
    "text": "trying to look into a particular\nhuman behavior model that is inspired by our\nempirical understandings",
    "start": "1892950",
    "end": "1899429"
  },
  {
    "text": "of humans' engagement with AI. So this model essentially says\nthat the human decision maker",
    "start": "1899430",
    "end": "1905130"
  },
  {
    "text": "will go with their own\nindependent judgment when their confidence\nin their own judgment",
    "start": "1905130",
    "end": "1911400"
  },
  {
    "text": "is higher than the threshold. Otherwise, they will go with AI\nmodel's decision recommendation.",
    "start": "1911400",
    "end": "1916780"
  },
  {
    "text": "And we assume that this\nconfidence threshold is sampled from the\nunderlying distribution.",
    "start": "1916780",
    "end": "1922630"
  },
  {
    "text": "And it turns out that under\nthis human behavior model, the problem of optimizing\nfor the human-AI team",
    "start": "1922630",
    "end": "1929490"
  },
  {
    "text": "performance in decision\nmaking is effectively be the same as trying to solve\na weightage loss optimization",
    "start": "1929490",
    "end": "1936860"
  },
  {
    "text": "problem. And the weight assigned to each\nof the training task instance is actually--",
    "start": "1936860",
    "end": "1942650"
  },
  {
    "text": "the optimal weight assigned\nto each of the training task. Instance is actually 1\nminus the CDF function",
    "start": "1942650",
    "end": "1948050"
  },
  {
    "text": "value for humans' own decision\nconfidence on the training instance. So essentially, when humans are\nmore confident about a training",
    "start": "1948050",
    "end": "1955100"
  },
  {
    "text": "task instance, that\ntraining task instance gets a lower weight in\nthe training process. And through both the human\nsubject study and simulation,",
    "start": "1955100",
    "end": "1964350"
  },
  {
    "text": "we actually find that when\nhumans are collaborating with behavior-aware\nAI model, they're able to achieve a significantly\nhigher level of final decision",
    "start": "1964350",
    "end": "1973220"
  },
  {
    "text": "making accuracy than\nin the case when they are collaborating with\nbehavior-oblivious AI model.",
    "start": "1973220",
    "end": "1980240"
  },
  {
    "text": "So now so far,\nwhen we are talking about enhancing AI-assisted\ndecision making,",
    "start": "1980240",
    "end": "1986850"
  },
  {
    "text": "we are really just\nthinking about the scenario that AI models is trying to\nhelp an individual decision",
    "start": "1986850",
    "end": "1993380"
  },
  {
    "text": "maker in decision making. But in reality, a lot\nof times, the decisions are not made by an individual.",
    "start": "1993380",
    "end": "2000230"
  },
  {
    "text": "It's made by a group of people. So this really means\nwe need to think about how to enhance AI-assisted\ngroup decision making.",
    "start": "2000230",
    "end": "2009110"
  },
  {
    "text": "And I will argue that the\nrecipe is still the same. So in order to enhance\nAI-assisted group decision",
    "start": "2009110",
    "end": "2014770"
  },
  {
    "text": "making, we probably\nwant to start with obtaining more\nunderstanding of how",
    "start": "2014770",
    "end": "2019870"
  },
  {
    "text": "a group of decision makers will\nengage with AI-based decisions aids. And then with that\nunderstanding,",
    "start": "2019870",
    "end": "2025430"
  },
  {
    "text": "we can try to design\nAI-based decision aids to account for a\ngroup's engagement behavior.",
    "start": "2025430",
    "end": "2031460"
  },
  {
    "text": "So in the next few\n10 minutes or so, I'm going to share with you some\ninitial explorations in terms",
    "start": "2031460",
    "end": "2039620"
  },
  {
    "text": "of how we can actually\nunderstand group's engagement with AI and how can we account\nfor groups engagement with AI",
    "start": "2039620",
    "end": "2048199"
  },
  {
    "text": "in the designs of\nAI-based decision aids. So let's start from the\nempirical understanding.",
    "start": "2048199",
    "end": "2053489"
  },
  {
    "text": "So in this case, one of the\nfirst question we want to ask is, compared to an\nindividual decision makers,",
    "start": "2053489",
    "end": "2060960"
  },
  {
    "text": "how will a group of decision\nmakers engage with AI in a way that is-- do they engage with AI in a\nsimilar way or different way?",
    "start": "2060960",
    "end": "2069899"
  },
  {
    "text": "So to understand this, we\nran human subject studies to have decision makers\nmake recidivism prediction.",
    "start": "2069900",
    "end": "2077719"
  },
  {
    "text": "So essentially, they are\nlooking at the profiles of criminal\ndefendants, and we ask",
    "start": "2077719",
    "end": "2083570"
  },
  {
    "text": "them to decide whether the\ncriminal defendant maybe reoffend in the future.",
    "start": "2083570",
    "end": "2089129"
  },
  {
    "text": "And so we create two\nexperimental treatments. In the first treatment,\nwe ask the decision makers",
    "start": "2089130",
    "end": "2094940"
  },
  {
    "text": "to review the defendant\nprofile and make their own independent judgment\nwith the help with AI model.",
    "start": "2094940",
    "end": "2102420"
  },
  {
    "text": "And in the second treatment, we\norganized the decision makers into groups of three people.",
    "start": "2102420",
    "end": "2107820"
  },
  {
    "text": "And these three\npeople actually need to look at the profile\nof the criminal defendant",
    "start": "2107820",
    "end": "2114290"
  },
  {
    "text": "and discuss with each other. And in the end of the\nday, they need to come up with a consensus decision.",
    "start": "2114290",
    "end": "2120840"
  },
  {
    "text": "Again, this is with the\nhelp of an AI model. So AI will provide some\ndecision recommendation to them.",
    "start": "2120840",
    "end": "2126000"
  },
  {
    "text": "So we actually looked into\nmultiple different aspects in terms of how individuals and\ngroups engage with AI similarly",
    "start": "2126000",
    "end": "2133730"
  },
  {
    "text": "or differently. So we looked into their final\ndecision-making accuracy, their reliance on AI fairness,\nconfidence, accountability,",
    "start": "2133730",
    "end": "2142140"
  },
  {
    "text": "their understanding of AI\nand so on and so forth. But for today, I'm\ngoing to only focus",
    "start": "2142140",
    "end": "2147890"
  },
  {
    "text": "on highlighting one of the most\nstriking results to us, which is in terms of group's\nreliance on AI.",
    "start": "2147890",
    "end": "2155190"
  },
  {
    "text": "So what we find is that compared\nto individual decision makers, a group of decision\nmakers actually",
    "start": "2155190",
    "end": "2161840"
  },
  {
    "text": "relied on AI's decision\nrecommendation even more, both on cases when AI is correct\nand on cases where AI is wrong.",
    "start": "2161840",
    "end": "2170790"
  },
  {
    "text": "So this effectively leads to a\nlower degree of under-reliance for groups, but a higher degree\nof over-reliance for groups.",
    "start": "2170790",
    "end": "2180150"
  },
  {
    "text": "And we wonder why\nthis is the case. So we looked into the\nchat logs for groups",
    "start": "2180150",
    "end": "2185660"
  },
  {
    "text": "and try to find out\nwhy this is the case. And we find out a couple of\nvery interesting scenarios",
    "start": "2185660",
    "end": "2191539"
  },
  {
    "text": "or common things\nin the chat logs. One possible scenario is\nthat within the group,",
    "start": "2191540",
    "end": "2197090"
  },
  {
    "text": "someone will just make the\ncase for their own judgment by saying that, look,\nAI agree with me,",
    "start": "2197090",
    "end": "2203580"
  },
  {
    "text": "so that must be saying\nsomething about my judgment being superior. So they try to make\nuse of that to persuade",
    "start": "2203580",
    "end": "2210800"
  },
  {
    "text": "other members in the group\nto vote together with them. So this is one of the frequently\nobserved patterns in the group",
    "start": "2210800",
    "end": "2217250"
  },
  {
    "text": "discussion process. Another frequently observed\npatterns in the group discussion",
    "start": "2217250",
    "end": "2223089"
  },
  {
    "text": "is that in some cases, a group\ncannot reach a consensus. And then somebody in the group\nwill jump out and say, well,",
    "start": "2223090",
    "end": "2231200"
  },
  {
    "text": "since we can't really\nreach a consensus, let's just use AI\nmodel's recommendation as the tiebreaker.",
    "start": "2231200",
    "end": "2237350"
  },
  {
    "text": "So that, again, you can\nimagine significantly increase the chance for people\nto use AI model's decision",
    "start": "2237350",
    "end": "2243880"
  },
  {
    "text": "recommendation as\ntheir final decision. So this results really\nhint us that in order",
    "start": "2243880",
    "end": "2249400"
  },
  {
    "text": "to improve AI-assisted group\ndecision-making performance, we really need to think about\nhow to help groups to critically",
    "start": "2249400",
    "end": "2257380"
  },
  {
    "text": "reflect on the trustworthiness\nof AI models' decision recommendation. They really need to engage\nin more critical deliberation",
    "start": "2257380",
    "end": "2265780"
  },
  {
    "text": "in this process. And if we look into the\ntraditional science management science literature, we'll\nfind that one frequently used",
    "start": "2265780",
    "end": "2273400"
  },
  {
    "text": "approach to encourage\ncritical deliberation is to introduce a devil's\nadvocate in this group",
    "start": "2273400",
    "end": "2279660"
  },
  {
    "text": "discussion process. But the traditional\ntype of devil's advocate may suffer from a\ncouple of limitations.",
    "start": "2279660",
    "end": "2287010"
  },
  {
    "text": "For example, this traditional\ndevil's advocate approach, they will assign a\nparticular person",
    "start": "2287010",
    "end": "2293220"
  },
  {
    "text": "in the group as the\ndevil's advocate and ask that person to come\nup with opposing views.",
    "start": "2293220",
    "end": "2299349"
  },
  {
    "text": "But that person may not actually\nagree with the opposing views that they get assigned,\nand as a result,",
    "start": "2299350",
    "end": "2305069"
  },
  {
    "text": "they can't really come up\nwith very convincing arguments to help this group to\ngenerate more deep thinking.",
    "start": "2305070",
    "end": "2314890"
  },
  {
    "text": "So that's one of\nthe limitations. And another limitation is\nthat the devil's advocate in the group, when they\nget assigned this role,",
    "start": "2314890",
    "end": "2321730"
  },
  {
    "text": "they sometimes suffer from\npsychological safety issues because they are trying to\nbe the outliers of the group,",
    "start": "2321730",
    "end": "2329160"
  },
  {
    "text": "and they're trying to advocate\nagainst other people's opinion. And therefore, they\nsometimes feel that they",
    "start": "2329160",
    "end": "2335550"
  },
  {
    "text": "get isolated in this process. So in order to address these two\nlimitations, we start to think,",
    "start": "2335550",
    "end": "2342730"
  },
  {
    "text": "maybe we can use a\nlarge language model to power this devil's advocate.",
    "start": "2342730",
    "end": "2348410"
  },
  {
    "text": "So because if we use a\nlanguage model to power this devil's advocate,\nwe potentially",
    "start": "2348410",
    "end": "2354250"
  },
  {
    "text": "could generate more\ngenuine opposing views because in a sense,\nlanguage model,",
    "start": "2354250",
    "end": "2359680"
  },
  {
    "text": "once you prompt them\nto do certain things, they can come up with the\nbest or strongest argument",
    "start": "2359680",
    "end": "2364990"
  },
  {
    "text": "that they can think of. And since language model\nis not a human, at least",
    "start": "2364990",
    "end": "2370270"
  },
  {
    "text": "we think they are not\na human at the moment, they will not suffer from\nany psychological harms",
    "start": "2370270",
    "end": "2376660"
  },
  {
    "text": "that humans may suffer from. So with this idea, we start to\nexplore whether we can actually",
    "start": "2376660",
    "end": "2383950"
  },
  {
    "text": "introduce language model\npower to the devil's advocate in AI-assisted group\ndecision making process",
    "start": "2383950",
    "end": "2390160"
  },
  {
    "text": "to improve the group\ndecision-making performance. And we thought\nabout two dimensions",
    "start": "2390160",
    "end": "2397000"
  },
  {
    "text": "that we can vary in the designs\nof the language model-powered devil's advocate. The first dimension is\nwho this devil's advocate",
    "start": "2397000",
    "end": "2405010"
  },
  {
    "text": "should objected to. So traditionally speaking,\nthe devil's advocate is supposed to oppose the\nmajority view within the group,",
    "start": "2405010",
    "end": "2413750"
  },
  {
    "text": "and that's one option\nthat we considered. But since our previous\nempirical study",
    "start": "2413750",
    "end": "2419380"
  },
  {
    "text": "have revealed that the groups\nhave the tendency to overly rely on AI, we also\nconsidered another option",
    "start": "2419380",
    "end": "2427000"
  },
  {
    "text": "that is having the language\nmodel-powered devil's advocate to specifically advocate\nagainst AI model's decision",
    "start": "2427000",
    "end": "2434470"
  },
  {
    "text": "recommendation. So this is the first\ndimension that we varied. And another dimension\nthat we varied",
    "start": "2434470",
    "end": "2440890"
  },
  {
    "text": "is the interactivity of\nthe devil's advocate. So the simplest design is\na static devil's advocate",
    "start": "2440890",
    "end": "2447290"
  },
  {
    "text": "so we only have the\ndevil's advocate to generate some\nthought-provoking, critical,",
    "start": "2447290",
    "end": "2452710"
  },
  {
    "text": "initial questions. And then at the top of\nthe group discussion to encourage the groups\nengage in this kind",
    "start": "2452710",
    "end": "2460270"
  },
  {
    "text": "of critical thinking. But we also thought about\npotentially more interesting",
    "start": "2460270",
    "end": "2466720"
  },
  {
    "text": "language model-powered\ndevil's advocate could be this dynamic devil's\nadvocate that will actively",
    "start": "2466720",
    "end": "2472569"
  },
  {
    "text": "participate in the\ngroup discussion and respond to other\nmembers' argument. And that's our\nsecond option along",
    "start": "2472570",
    "end": "2479740"
  },
  {
    "text": "the interactivity dimension. So again, we tried out\nthis combination of two",
    "start": "2479740",
    "end": "2486460"
  },
  {
    "text": "by two so it gives us four\ndifferent possible designs. We tried out these four\ndifferent possible design using",
    "start": "2486460",
    "end": "2492490"
  },
  {
    "text": "a human subject experiment. And what we find is that when\nthe devil's advocate is actively",
    "start": "2492490",
    "end": "2499090"
  },
  {
    "text": "participating in\nthe group discussion and it's actively arguing\nagainst the AI model's decision",
    "start": "2499090",
    "end": "2505000"
  },
  {
    "text": "recommendation, they can help\na group of decision makers to achieve a level of\ndecision-making accuracy",
    "start": "2505000",
    "end": "2511420"
  },
  {
    "text": "that is higher than in\nthe case when there is no devil's advocate involved.",
    "start": "2511420",
    "end": "2516500"
  },
  {
    "text": "And we also find that having\nthe language model to actively",
    "start": "2516500",
    "end": "2521760"
  },
  {
    "text": "respond to group\nmembers' argument actually helps the groups\nto significantly decrease",
    "start": "2521760",
    "end": "2527910"
  },
  {
    "text": "their over-reliance on\nAI's recommendation. And just to give you a\nsense of what exactly",
    "start": "2527910",
    "end": "2534000"
  },
  {
    "text": "this devil's advocate is doing\nin this entire group discussion process, we again\nlooked into the chat log",
    "start": "2534000",
    "end": "2540030"
  },
  {
    "text": "and find a couple of\nvery interesting emerging behaviors of this language\nmodel-powered devil's advocate.",
    "start": "2540030",
    "end": "2547769"
  },
  {
    "text": "First, what we find is that\neven though we have never prompt a language\nmodel to do so,",
    "start": "2547770",
    "end": "2553740"
  },
  {
    "text": "we find there are cases that\nthis language model-powered devil's advocate will\nactively encourage",
    "start": "2553740",
    "end": "2560490"
  },
  {
    "text": "certain members in the group\nto express their opinions. They want to ensure that\neveryone's voice are being",
    "start": "2560490",
    "end": "2566850"
  },
  {
    "text": "heard, even though this is\nnever explicitly included in our prompt to\nthe language model.",
    "start": "2566850",
    "end": "2573790"
  },
  {
    "text": "And there are also cases that\nthe language model-powered devil's will recognize that\nthe group of decision makers",
    "start": "2573790",
    "end": "2583900"
  },
  {
    "text": "are making their judgment\nbased on wrong information. And they will pick\nup those moments and tell the group of decision\nmaker that pay attention.",
    "start": "2583900",
    "end": "2593810"
  },
  {
    "text": "You are actually\nmaking your argument based on wrong information\nabout this defendant.",
    "start": "2593810",
    "end": "2600670"
  },
  {
    "text": "You should really pay\nattention to what's the actual information presented\nin this defendant's profile.",
    "start": "2600670",
    "end": "2607190"
  },
  {
    "text": "And there are also many times\nthe language model-powered devil's advocate tries to\nencourage holistic evaluation",
    "start": "2607190",
    "end": "2615490"
  },
  {
    "text": "of the defendant's case. So you can see in\nthis case, the group is actually mostly focusing\non one particular feature",
    "start": "2615490",
    "end": "2622000"
  },
  {
    "text": "of the defendant, which\nis the defendant does not have a prior criminal history. And language model-powered\ndevil's advocate",
    "start": "2622000",
    "end": "2629470"
  },
  {
    "text": "will capture this point and try\nto make sure that they are also paying attention to other\nfeatures of this defendant that",
    "start": "2629470",
    "end": "2637569"
  },
  {
    "text": "may suggest opposite decisions. And finally, there are cases\nthat the language model will",
    "start": "2637570",
    "end": "2646310"
  },
  {
    "text": "recognize that the\nentire discussion is based on certain assumptions. And these assumptions may not\nactually showing up anywhere",
    "start": "2646310",
    "end": "2654770"
  },
  {
    "text": "in this decision-making profile. And they will\nencourage the group to think about whether their\nassumption is valid or not.",
    "start": "2654770",
    "end": "2662850"
  },
  {
    "text": "OK. Yeah. Thank you. I'm just wondering, is\nthis something about--",
    "start": "2662850",
    "end": "2669680"
  },
  {
    "text": "is the fact that the\ndynamic adversarial AI, is this the best because it's just\nthe AI system itself is going",
    "start": "2669680",
    "end": "2677400"
  },
  {
    "text": "to be better when you put\nit in this environment where it's like being\npitted against another AI, and so the end result of\nthis line of reasoning",
    "start": "2677400",
    "end": "2685100"
  },
  {
    "text": "is just the most high\nquality line of reasoning? Or is it something\nabout the interaction",
    "start": "2685100",
    "end": "2690500"
  },
  {
    "text": "between the people seeing this\nadversarial interaction that's helping the group come\nto a better decision?",
    "start": "2690500",
    "end": "2699740"
  },
  {
    "text": "So let me try to see whether\nI understand your question. So you are asking whether\nthe benefit is really",
    "start": "2699740",
    "end": "2707750"
  },
  {
    "text": "coming from the\ntwo AI or one is AI",
    "start": "2707750",
    "end": "2712975"
  },
  {
    "text": "that provides decision\nrecommendation and the other is AI that is the\ndevil's advocate? Or is it because the human\nsee more information?",
    "start": "2712975",
    "end": "2721250"
  },
  {
    "text": "I guess it's like if you were\nto just design an AI system that made the best predictions\nabout your decision task,",
    "start": "2721250",
    "end": "2730339"
  },
  {
    "text": "would the dynamic AI be the\nbest at making predictions aside from the dynamics of how the\ngroup perceives the [INAUDIBLE].",
    "start": "2730340",
    "end": "2740670"
  },
  {
    "text": "Yeah. So I guess part of it is\nthe AI's decision-- well,",
    "start": "2740670",
    "end": "2746430"
  },
  {
    "text": "I guess in this particular\ncase, the AI model's performance is probably not so great.",
    "start": "2746430",
    "end": "2752640"
  },
  {
    "text": "You're correct. So the AI model's\nperformance is probably on par with humans' performance.",
    "start": "2752640",
    "end": "2758370"
  },
  {
    "text": "So in this sense, having\nthe devil's advocate to really attacking\nthe AI's suggestions",
    "start": "2758370",
    "end": "2764750"
  },
  {
    "text": "and having people to critically\nreflect on AI's decision recommendation is very helpful.",
    "start": "2764750",
    "end": "2770400"
  },
  {
    "text": "But you're right\nin the sense that I don't know whether this\nresult will generalize",
    "start": "2770400",
    "end": "2775440"
  },
  {
    "text": "if in another setting, the\nAI model's performance is super great. If AI model's performance\nis super great",
    "start": "2775440",
    "end": "2782480"
  },
  {
    "text": "and the devil's advocate is\ntrying to actively prompt people to think\nAI is wrong, then",
    "start": "2782480",
    "end": "2788930"
  },
  {
    "text": "maybe it's going to be\nthe case that it's not helping the group\nachieve a higher level",
    "start": "2788930",
    "end": "2794450"
  },
  {
    "text": "of decision-making accuracy. And in that sense,\nI think we need to better think about how to\ndesign the devil's advocate",
    "start": "2794450",
    "end": "2801049"
  },
  {
    "text": "to really just\njump in those cases that they are highly confident\nthat AI is going to make",
    "start": "2801050",
    "end": "2807260"
  },
  {
    "text": "the wrong recommendation. OK? Yes. [INAUDIBLE] powered\nby a language model?",
    "start": "2807260",
    "end": "2816660"
  },
  {
    "text": "Yes, we directly\ntold them that there is a devil's advocate\nin their group and this devil's advocate is\npowered by a language model.",
    "start": "2816660",
    "end": "2824380"
  },
  {
    "text": "Yes. What were some the\nexamples of the cases",
    "start": "2824380",
    "end": "2830820"
  },
  {
    "text": "like [INAUDIBLE] are\ncorrect or incorrect? Are they all like\nabout criminal cases?",
    "start": "2830820",
    "end": "2838210"
  },
  {
    "text": "And in that case, what is\nthe specific difference? So this experiment is done all\nwith the recidivism prediction",
    "start": "2838210",
    "end": "2845839"
  },
  {
    "text": "task. So the data set actually\nprovides the ground truth in terms of for each of\nthe criminal defendant,",
    "start": "2845840",
    "end": "2854319"
  },
  {
    "text": "whether within two years\nthey reoffend or not. So we are asking\nthe participants",
    "start": "2854320",
    "end": "2859560"
  },
  {
    "text": "in our experiment to predict\nwhether this person will reoffend in two years.",
    "start": "2859560",
    "end": "2864670"
  },
  {
    "text": "So in that sense, the\ndata set actually gave us the ground truth answer. ",
    "start": "2864670",
    "end": "2871770"
  },
  {
    "text": "So you already know the\ndefendant had reoffended, right? Right. Because this is used as\na historical data set.",
    "start": "2871770",
    "end": "2879460"
  },
  {
    "text": "But in reality, we won't know. But in a sense, in\nreality, we would also be able to check\nwhether the decision",
    "start": "2879460",
    "end": "2887579"
  },
  {
    "text": "that the group of\ndecision makers made are correct or\nnot in the future.",
    "start": "2887580",
    "end": "2893370"
  },
  {
    "text": "Yes. It seems to me that LOM is\nplaying the role of facilitator",
    "start": "2893370",
    "end": "2899850"
  },
  {
    "text": "while you are\nprogramming it to play the role of a devil's advocate. So I'm wondering if that\nis because it is something",
    "start": "2899850",
    "end": "2908880"
  },
  {
    "text": "that you already programmed\nin your original design or is something that is because\nsomehow it just realized",
    "start": "2908880",
    "end": "2915450"
  },
  {
    "text": "that as a devil's advocate, one\nof the strategies of winning",
    "start": "2915450",
    "end": "2921630"
  },
  {
    "text": "an argument is to adopt the role\nof facilitator and arguments",
    "start": "2921630",
    "end": "2928589"
  },
  {
    "text": "because you tend to be on the\nside of where most people don't agree and you have to play a\nmore facilitator role in order",
    "start": "2928590",
    "end": "2936150"
  },
  {
    "text": "to get [INAUDIBLE]. So that's a really\ngreat question. And we don't really\nknow the answer.",
    "start": "2936150",
    "end": "2941890"
  },
  {
    "text": "So the way that we prompt the\nlanguage model in this study is in the system prompt,\nwe say that there",
    "start": "2941890",
    "end": "2948150"
  },
  {
    "text": "are a group of people discussing\nabout this recidivism case. And you are going to join this\ngroup as a devil's advocate.",
    "start": "2948150",
    "end": "2956920"
  },
  {
    "text": "And we ask you to\nexercise Socratic method to generate thought\nprovoking questions,",
    "start": "2956920",
    "end": "2964900"
  },
  {
    "text": "encouraging the entire group\nto engage in a deliberation more closely.",
    "start": "2964900",
    "end": "2970610"
  },
  {
    "text": "And somehow, we\nobserved this behavior that the language model\nactually in many cases",
    "start": "2970610",
    "end": "2976600"
  },
  {
    "text": "tries to make sure everyone\nis contributing equally and tries to make\nsure everyone is",
    "start": "2976600",
    "end": "2981640"
  },
  {
    "text": "looking at all the possible\nfeatures of the task. And we don't really\nknow why that happens.",
    "start": "2981640",
    "end": "2987860"
  },
  {
    "text": "And I guess a very interesting\nfuture work along this line is really to\nspecifically engineer",
    "start": "2987860",
    "end": "2995560"
  },
  {
    "text": "the language model in a way\nthat separate these roles. Separate them into the role of\njust the act as a facilitator",
    "start": "2995560",
    "end": "3005640"
  },
  {
    "text": "or act as a coordinator,\nand in other cases, just act as the role of\nthrowing out opposing views",
    "start": "3005640",
    "end": "3011700"
  },
  {
    "text": "and see how would different\nroles actually interact with each other,\nwhich role is most",
    "start": "3011700",
    "end": "3018119"
  },
  {
    "text": "helpful in encouraging the\ngroup decision making accuracy.",
    "start": "3018120",
    "end": "3024220"
  },
  {
    "text": "Yeah. That's actually the\nend of my presentation.",
    "start": "3024220",
    "end": "3029710"
  },
  {
    "text": "I hope I have convinced you\nthat it's important for us to understand humans'\nengagement with AI",
    "start": "3029710",
    "end": "3036250"
  },
  {
    "text": "because this understanding could\nboth help us to design adaptive AI that will promote more\nappropriate engagement",
    "start": "3036250",
    "end": "3044650"
  },
  {
    "text": "from the human side, but\nalso we can potentially retrain the AI model to tailor\nto humans' engagement behavior.",
    "start": "3044650",
    "end": "3052370"
  },
  {
    "text": "OK. Thank you very much. ",
    "start": "3052370",
    "end": "3059000"
  }
]
[
  {
    "start": "0",
    "end": "5650"
  },
  {
    "text": "It is our pleasure today\nto hear from Colin Raffel. So Colin is an\nassistant professor",
    "start": "5650",
    "end": "12820"
  },
  {
    "text": "in computer science at\nthe University of North Carolina in Chapel Hill. Colin is also a faculty\nresearcher at Hugging Face.",
    "start": "12820",
    "end": "20260"
  },
  {
    "text": "And well, maybe you might know\nhim from the celebrated T5 work",
    "start": "20260",
    "end": "27730"
  },
  {
    "text": "that he did. He's really worked on all\nkinds of things related to sequence modeling,\ngeneralization",
    "start": "27730",
    "end": "34210"
  },
  {
    "text": "and memorization, learning\nfrom limited data, semi-supervised and\nunsupervised transfer learning.",
    "start": "34210",
    "end": "41180"
  },
  {
    "text": "So I'm sure he's going to have\nlots of interesting things to share with us today. So thanks so much for\njoining this call.",
    "start": "41180",
    "end": "49000"
  },
  {
    "text": "Thanks a lot for\nthe introduction. And I assume everyone\ncan see my slides,",
    "start": "49000",
    "end": "54309"
  },
  {
    "text": "or else holler if\nthere's a problem. And I will be taking questions\nat two very clear breaks",
    "start": "54310",
    "end": "62530"
  },
  {
    "text": "in this talk. And so if you do have\nquestions, feel free. I think one of the\nTAs is fielding them,",
    "start": "62530",
    "end": "68350"
  },
  {
    "text": "and will read it-- relay them\nback to me during the talk. So yeah, thanks\nagain for having me.",
    "start": "68350",
    "end": "74930"
  },
  {
    "text": "I'm going to be talking\nabout language modeling, and language models is something\nthat I've worked on quite a bit recently, and which I\nthink is of interest",
    "start": "74930",
    "end": "82390"
  },
  {
    "text": "to a meta-learning class. So let me try to explain why. So just to get everyone\non the same page,",
    "start": "82390",
    "end": "90560"
  },
  {
    "text": "one of the most common ways\nthat people use language models is kind of diagrammed\non the screen here.",
    "start": "90560",
    "end": "96260"
  },
  {
    "text": "And what we do is we typically\ntake a bunch of unlabeled text data and we apply something\nwe call a self-supervised",
    "start": "96260",
    "end": "104155"
  },
  {
    "text": "or an unsupervised objective. And what that means is that\nwithout actually having to hand label any data, I can\njust kind of transform my data",
    "start": "104155",
    "end": "111790"
  },
  {
    "text": "in some way that\nthere is something interesting to predict from it. So here is an example of a\nself-supervised objective,",
    "start": "111790",
    "end": "118720"
  },
  {
    "text": "where you're going to\nbe training the model to fill in the blanks. So we take this chunk\nof text shown in green,",
    "start": "118720",
    "end": "124280"
  },
  {
    "text": "and we drop out\nsome words that now have been replaced by blanks.",
    "start": "124280",
    "end": "130269"
  },
  {
    "text": "And then in the yellow, you\ncan see all the missing words. And we're just going\nto train the model to fill in those missing words.",
    "start": "130270",
    "end": "136430"
  },
  {
    "text": "And so this process,\nagain, doesn't require any human labeling. As long as we have\nunlabeled text data, we can apply this unsupervised\npre-training step,",
    "start": "136430",
    "end": "144340"
  },
  {
    "text": "the self-supervised objective. And it turns out that if you do\nthis self-supervised training",
    "start": "144340",
    "end": "149890"
  },
  {
    "text": "as a first step\nbefore you actually train the model to\ndo something useful, it's incredibly helpful.",
    "start": "149890",
    "end": "155030"
  },
  {
    "text": "So this pre-training\nstep tends to make it so that the model converges\nfaster with less labeled data",
    "start": "155030",
    "end": "163450"
  },
  {
    "text": "to a better performance\non a given task that you actually care about. We usually call these\ntasks that we actually",
    "start": "163450",
    "end": "168880"
  },
  {
    "text": "care about, downstream tasks. And we say that we fine-tune\nthe pre-trained model",
    "start": "168880",
    "end": "173890"
  },
  {
    "text": "on the downstream task. So you can see on\nthe right here, we're going to be\nfine-tuning on, let's say, a sentiment\nanalysis task, where",
    "start": "173890",
    "end": "180220"
  },
  {
    "text": "we feed the model\nin a movie review and train the model to predict\nwhether the movie review is positive or negative.",
    "start": "180220",
    "end": "185680"
  },
  {
    "text": "And typically, we have\nlabeled data in this setting, but it allows us to adapt the\npre-trained model to some sort",
    "start": "185680",
    "end": "192990"
  },
  {
    "text": "of important downstream task. And this set up is\nwhat we typically call transfer learning.",
    "start": "192990",
    "end": "198860"
  },
  {
    "text": "I will be describing other\nways that people use language models, but it's\nnot an exaggeration",
    "start": "198860",
    "end": "205300"
  },
  {
    "text": "to say that this is one of the\nmost important applications of language models at\nleast in recent years.",
    "start": "205300",
    "end": "212769"
  },
  {
    "text": "So to kind of illustrate\nthat and why that's true, here's a plot over\ntime of the exact match",
    "start": "212770",
    "end": "219700"
  },
  {
    "text": "score on the SQuAD reading\ncomprehension benchmark. So this is a task where the\nmodel is fed a paragraph,",
    "start": "219700",
    "end": "225855"
  },
  {
    "text": "and then it's asked a\nquestion about the paragraph, and it has to extract the\nanswer from the paragraph. It's what we call--",
    "start": "225855",
    "end": "231159"
  },
  {
    "text": "I would call reading\ncomprehension. And you can see that\non most benchmarks, the performance of\ndifferent models",
    "start": "231160",
    "end": "237040"
  },
  {
    "text": "has gotten better and\nbetter over time, which is just great and exciting. But I would delineate these\nresults into two categories.",
    "start": "237040",
    "end": "244940"
  },
  {
    "text": "The categories\nbefore, people were using a lot of\ntransfer learning, at least in the paradigm\nthat I described earlier,",
    "start": "244940",
    "end": "250880"
  },
  {
    "text": "and the models that use really\nan extensive amount of transfer",
    "start": "250880",
    "end": "255940"
  },
  {
    "text": "learning as shown\non the right here. And you can see\nthere ended up being a huge boost in\nperformance when we shifted to this pre-trained\nthe full model",
    "start": "255940",
    "end": "262870"
  },
  {
    "text": "and then fine-tuned the\nfull model paradigm. And the other\nthing that has made",
    "start": "262870",
    "end": "270340"
  },
  {
    "text": "language models particularly\nuseful recently is scale. And as many of you probably\nhave heard or know,",
    "start": "270340",
    "end": "277778"
  },
  {
    "text": "many of the language models\nthat we trained today just seem to keep getting\nbetter when we make them bigger and train them on\nmore text data.",
    "start": "277778",
    "end": "284120"
  },
  {
    "text": "So this plot here\nshows two axes, one, the size of the model\nin blue, and in red,",
    "start": "284120",
    "end": "291820"
  },
  {
    "text": "the GLUE score, which is\nthe score on a popular meta benchmark of NLP tasks. And as with squad,\nthe performance",
    "start": "291820",
    "end": "298780"
  },
  {
    "text": "has gone up over time. But notably, the\nsize of the models that have gotten state\nof the art performance",
    "start": "298780",
    "end": "303790"
  },
  {
    "text": "has also increased pretty\ndramatically over time. And there are some issues\nand questions around this",
    "start": "303790",
    "end": "311440"
  },
  {
    "text": "that I'll describe much later. But in general, it's a pretty\nuseful property of a method that the performance\ntends to get better",
    "start": "311440",
    "end": "318009"
  },
  {
    "text": "when you make the model bigger\nand train it on more data because it's very easy to get\nthis unlabeled, unstructured",
    "start": "318010",
    "end": "324129"
  },
  {
    "text": "text data that we apply the\nself-supervised objective to. So this is another\nfactor that has",
    "start": "324130",
    "end": "330190"
  },
  {
    "text": "made language models a very\npowerful and popular choice in natural language\nprocessing recently.",
    "start": "330190",
    "end": "339310"
  },
  {
    "text": "So one particular language\nmodel that I helped developed a couple of\nyears ago is called T5.",
    "start": "339310",
    "end": "345159"
  },
  {
    "text": "And one of the things\nthat distinguishes T5 from other similar\nmodels is that we actually",
    "start": "345160",
    "end": "350680"
  },
  {
    "text": "use it to tackle a\nextremely diverse collection of downstream tasks. And specifically,\nyou can think of T5",
    "start": "350680",
    "end": "358480"
  },
  {
    "text": "as having a natural\nlanguage interface where you feed it some\ndata and you tell it",
    "start": "358480",
    "end": "363669"
  },
  {
    "text": "via task prefix what you want\nthe model to do with that data. So for example, we want the\nmodel to translate from English",
    "start": "363670",
    "end": "369310"
  },
  {
    "text": "to German. We want the model to determine\nwhether a sentence is acceptable, that comes from\nthe CoLA benchmark, the Corpus",
    "start": "369310",
    "end": "376270"
  },
  {
    "text": "of Linguistic Acceptability. And you can see\nthat T5 specifically casts not only the\ninput as a text field,",
    "start": "376270",
    "end": "384220"
  },
  {
    "text": "but also the output\nas a text field. So if we're doing a\nclassification task where, for example, we're classifying\nwhether text is acceptable",
    "start": "384220",
    "end": "391642"
  },
  {
    "text": "or not, we actually\ntrain the model to output the text\nnot acceptable. Or if we're doing\na regression task,",
    "start": "391642",
    "end": "397240"
  },
  {
    "text": "we're shown in yellow\nhere, we actually train the model to output\na string representation of the floating point number.",
    "start": "397240",
    "end": "402790"
  },
  {
    "text": "And by applying this\ntext-to-text framework to a very wide variety of tasks,\nwe can take the same model",
    "start": "402790",
    "end": "411370"
  },
  {
    "text": "and apply it to lots of\ntasks and ultimately, achieve very good performance\non all of these tasks.",
    "start": "411370",
    "end": "417998"
  },
  {
    "text": "So since you're in the\nmeta-learning class, this diagram might look a\nlittle bit familiar to you. I guess I should say\nthe last diagram might",
    "start": "417998",
    "end": "424258"
  },
  {
    "text": "look familiar to you, but\ncertainly, this diagram should look familiar to you. And this diagram\nfrom the MAML paper",
    "start": "424258",
    "end": "430470"
  },
  {
    "text": "is summarizing the key\ngoal of meta-learning, which is that we should find a\nmodel, a set of parameters that",
    "start": "430470",
    "end": "438240"
  },
  {
    "text": "can be rapidly adapted to many,\nmany diverse downstream tasks hopefully with as\nlittle data as possible.",
    "start": "438240",
    "end": "444820"
  },
  {
    "text": "And indeed, via the T5\nmodel and many other models, we've actually shown\nthat the pre-trained T5",
    "start": "444820",
    "end": "450990"
  },
  {
    "text": "model can be rapidly adapted\nto a very wide variety of downstream tasks with\nrelatively little label data.",
    "start": "450990",
    "end": "457540"
  },
  {
    "text": "So in effect, we\nhave accidentally been doing meta-learning\nin the sense",
    "start": "457540",
    "end": "462930"
  },
  {
    "text": "that just by doing simple\nself-supervised pre-training, we've ended up with a model\nthat can be rapidly adapted",
    "start": "462930",
    "end": "469080"
  },
  {
    "text": "to lots of tasks. And so what I'm going to try to\nanswer in this lecture is, why",
    "start": "469080",
    "end": "476040"
  },
  {
    "text": "does this language modeling\napproach effectively result in meta-learning? We're not using any of the\nmachinery of meta-learning.",
    "start": "476040",
    "end": "485069"
  },
  {
    "text": "We're just training a\nmodel on an objective that seems to be useful,\nand then by accident,",
    "start": "485070",
    "end": "491590"
  },
  {
    "text": "it's very readily adaptable to\nlots and lots of diverse tasks. So why is that true?",
    "start": "491590",
    "end": "497170"
  },
  {
    "text": "Why is language modeling\nsuch a useful objective despite its simplicity? And the reasons that I'll--",
    "start": "497170",
    "end": "504960"
  },
  {
    "text": "the reasons that I'll\ntry to provide today are shown on the\nscreen here and have",
    "start": "504960",
    "end": "510330"
  },
  {
    "text": "been validated\nthrough various papers that I'll be covering in detail.",
    "start": "510330",
    "end": "515669"
  },
  {
    "text": "And so if I had to\npostulate why this is true, I would say it seems that\nlanguage modeling teaches",
    "start": "515669",
    "end": "522120"
  },
  {
    "text": "models first. Word meanings,\nsyntax, and grammar are like the basics of language.",
    "start": "522120",
    "end": "527460"
  },
  {
    "text": "Language modeling also\nseems to teach models general knowledge about the\nworld, like facts and trivia",
    "start": "527460",
    "end": "533640"
  },
  {
    "text": "and even memorized information. And then finally,\nmost recently, what's",
    "start": "533640",
    "end": "539310"
  },
  {
    "text": "gotten people very excited is\nthat it seems that language modeling accidentally\nteaches language models how",
    "start": "539310",
    "end": "545130"
  },
  {
    "text": "to perform tasks. So even with virtually-- basically no\nadditional training,",
    "start": "545130",
    "end": "551310"
  },
  {
    "text": "language models seem\nto be able to perform a wide variety of tasks\nin some cases, which is quite interesting.",
    "start": "551310",
    "end": "556990"
  },
  {
    "text": "So I'll try to give\nyou some demonstration of these different\nproperties, try to explain why\nthey might happen,",
    "start": "556990",
    "end": "563490"
  },
  {
    "text": "and use that to answer this\nlarger question of why language modeling it seems to\nbe an effective way",
    "start": "563490",
    "end": "570330"
  },
  {
    "text": "to produce a meta-learner? So first, I'll focus\non this first facet.",
    "start": "570330",
    "end": "580080"
  },
  {
    "text": "And to do that,\nI'm actually going to go back even further into\nthe history of models for NLP,",
    "start": "580080",
    "end": "586950"
  },
  {
    "text": "and describe word vectors.  So for those of you who worked\non NLP before the era of BERT",
    "start": "586950",
    "end": "594580"
  },
  {
    "text": "and other pre-trained\nmodels, you probably encountered word vectors. And the idea and the\ngoal of a word vector",
    "start": "594580",
    "end": "601540"
  },
  {
    "text": "is to associate each\nword in the vocabulary with a single, fixed length\nvector of continuous value.",
    "start": "601540",
    "end": "607790"
  },
  {
    "text": "So you can think of it a vector\nin some D dimensional space. And you want these\nvectors to reflect",
    "start": "607790",
    "end": "613660"
  },
  {
    "text": "some amount of meaning about\nthe word that they represent. And I'll describe what I\nmean by meaning in a second.",
    "start": "613660",
    "end": "621310"
  },
  {
    "text": "But first, I'll just say\nthat the objective that we use actually is,\nyou can think of it",
    "start": "621310",
    "end": "627670"
  },
  {
    "text": "like a self-supervised\nobjective that's not so dissimilar\nto the way that we train language models now.",
    "start": "627670",
    "end": "632950"
  },
  {
    "text": "We might have a chunk of text,\nunlabeled, unstructured text shown on the top here, the\ndog and cat ate pot pie.",
    "start": "632950",
    "end": "639940"
  },
  {
    "text": "And the way that word vectors-- one way that word vectors are\ntrained shown on the screen here is that we model the\nprobability of the word, ate,",
    "start": "639940",
    "end": "649360"
  },
  {
    "text": "given the word cat as a\nsoftmax applied to a matrix, V,",
    "start": "649360",
    "end": "655930"
  },
  {
    "text": "that comprises all\nof the word vectors. The dot product of that\nmatrix times a different word",
    "start": "655930",
    "end": "662860"
  },
  {
    "text": "vector for this pivot word,\nthe center word, cat, wcat, and then we index this\nsoftmax at the ate location.",
    "start": "662860",
    "end": "671720"
  },
  {
    "text": "So I'm using cat and\nate as indices here. I hope people are\ncomfortable with that.",
    "start": "671720",
    "end": "676810"
  },
  {
    "text": "But to recap, we're taking\na center word, like cat,",
    "start": "676810",
    "end": "682510"
  },
  {
    "text": "and for each word within\na window around cat, we're saying that the\nprobability of that word, given cat, is computed by\ntaking a word vector for cat,",
    "start": "682510",
    "end": "692650"
  },
  {
    "text": "computing its dot product\nagainst the entire collection of word vectors\nthat we're learning, and computing the\nsoftmax of that.",
    "start": "692650",
    "end": "699404"
  },
  {
    "text": "And that gives us\nthe probability of that particular word. And so we're basically\noptimizing both V and wcat",
    "start": "699405",
    "end": "707170"
  },
  {
    "text": "in order to maximize\nthe probability of words that co-occur in our\npre-training corpus.",
    "start": "707170",
    "end": "715120"
  },
  {
    "text": "This particular\nword vector model is called a skip-gram\nword vector model. There are other ways of\nlearning word vectors.",
    "start": "715120",
    "end": "720250"
  },
  {
    "text": "And this is by no\nmeans the best, per se, but it is an effective one and\nhopefully, is pretty intuitive",
    "start": "720250",
    "end": "728320"
  },
  {
    "text": "and it's easy to understand. So if we do this word\nvector pre-training,",
    "start": "728320",
    "end": "733760"
  },
  {
    "text": "then we end up with some\ninteresting and useful characteristics for\nour word vectors.",
    "start": "733760",
    "end": "738769"
  },
  {
    "text": "And these examples are actually\ntaken from a different word vector model that's a little-- it takes a little\nmore explanation,",
    "start": "738770",
    "end": "744480"
  },
  {
    "text": "so I'm not going to\ndescribe it here. But it's called GloVe. Skip-gram word vector models\nhave similar properties.",
    "start": "744480",
    "end": "750890"
  },
  {
    "text": "It's just that this one had\nsome nice diagrams that I stole. And the first is that\nword vectors seem",
    "start": "750890",
    "end": "757310"
  },
  {
    "text": "to capture the word similarity. So if you take, for example, the\nword vector for the word frog,",
    "start": "757310",
    "end": "763079"
  },
  {
    "text": "and you find all of the\nmost similar word vectors according to their, let's say,\ntheir cosine similarity, then",
    "start": "763080",
    "end": "770720"
  },
  {
    "text": "the words that you\nend up with are shown in the list in the top left. So frog is most\nsimilar to frogs, OK> So plurals and singular\nforms of nouns are similar.",
    "start": "770720",
    "end": "781010"
  },
  {
    "text": "That's great. But frog is also similar to\ntoad, litoria, leptodactylidae.",
    "start": "781010",
    "end": "787670"
  },
  {
    "text": "These additional\nscientific looking words are the names of different--\nbasically the names of different frog species.",
    "start": "787670",
    "end": "794730"
  },
  {
    "text": "It's also similar to\nlizard, for example. So you can tell that\nthe kind of model knows that a frog is similar--",
    "start": "794730",
    "end": "804920"
  },
  {
    "text": "the word frog is similar to\nmore specific descriptions of frogs and also animals\nthat are similar to frogs,",
    "start": "804920",
    "end": "810410"
  },
  {
    "text": "like toads and lizards. So that's quite interesting. Again, all of this sort of fell\nout of a simple self-supervised",
    "start": "810410",
    "end": "816320"
  },
  {
    "text": "objective that just said\nthat words that co-occur-- sorry, words that are\nsurrounded by similar words",
    "start": "816320",
    "end": "824240"
  },
  {
    "text": "should have a similar\nrepresentation. So you might imagine like\na sentence, the frog hopped across the road and the toad\nhopped across the road, right?",
    "start": "824240",
    "end": "831290"
  },
  {
    "text": "So frog and toad appear\nin similar contexts there. Therefore, their word\nvectors should be similar.",
    "start": "831290",
    "end": "836779"
  },
  {
    "text": "And therefore, we end\nup with this property that toad is essentially the\nmost similar singular noun",
    "start": "836780",
    "end": "843650"
  },
  {
    "text": "to frog according\nto our word vectors. The other property\nthat people like",
    "start": "843650",
    "end": "849490"
  },
  {
    "text": "to point to in word vectors\nis that the relationship between different word\nvectors that have a certain--",
    "start": "849490",
    "end": "856420"
  },
  {
    "text": "the spatial relationship\nbetween word vectors that have some particular\nlinguistic relationship",
    "start": "856420",
    "end": "864490"
  },
  {
    "text": "is very similar. So for example, the displacement\nbetween the word vector for strong and the word\nvector for stronger",
    "start": "864490",
    "end": "872110"
  },
  {
    "text": "is similar to the displacement\nbetween the word vector for loud and the word louder. So you can see that these--",
    "start": "872110",
    "end": "879490"
  },
  {
    "text": "if you take an adjective\nand you convert it to a comparative\nadjective, and then into-- and from there,\nconvert it into kind",
    "start": "879490",
    "end": "885506"
  },
  {
    "text": "of the most superlative\nform of the adjective,",
    "start": "885506",
    "end": "890920"
  },
  {
    "text": "you end up with\nsimilar displacements. So this space of\nword vectors ends up",
    "start": "890920",
    "end": "896140"
  },
  {
    "text": "having a lot of very interesting\nand useful structure. And you can imagine\nthat feeding these word",
    "start": "896140",
    "end": "902050"
  },
  {
    "text": "vectors into a downstream\nmodel instead of, let's say, one hot vectors that\nrepresent word identity,",
    "start": "902050",
    "end": "907900"
  },
  {
    "text": "would imbue the model\nwith a lot of knowledge about the meaning\nand relationship of different words.",
    "start": "907900",
    "end": "912910"
  },
  {
    "text": "And again, all of\nthis just falls out of the intuitive notion\nthat if two words appear",
    "start": "912910",
    "end": "918759"
  },
  {
    "text": "in similar contexts, they\nmight mean similar things, or at least their vectors\nshould be similar.",
    "start": "918760",
    "end": "924890"
  },
  {
    "text": " So after word vectors,\ncame a model called ELMo.",
    "start": "924890",
    "end": "934310"
  },
  {
    "text": "And the motivation\nfor ELMo is that when we create a representation\nof a given word,",
    "start": "934310",
    "end": "941660"
  },
  {
    "text": "we actually probably want\nto take into consideration not just that all of the context\nthat the word appeared in",
    "start": "941660",
    "end": "948050"
  },
  {
    "text": "during pre-training,\nbut the specific context that that specific word appears\nin a particular sentence.",
    "start": "948050",
    "end": "954029"
  },
  {
    "text": "So for example--\nwell, let me just wait till the next slide\nto give an example.",
    "start": "954030",
    "end": "959090"
  },
  {
    "text": "First, I'll describe the model. So the difference between the\nELMo model and the word vector",
    "start": "959090",
    "end": "965420"
  },
  {
    "text": "model is rather than having\na specific fixed set of word vectors, we're actually\ngoing to feed our sentence",
    "start": "965420",
    "end": "971060"
  },
  {
    "text": "into a model that will\nrepresent the words in that sentence with\ndifferent vectors",
    "start": "971060",
    "end": "978200"
  },
  {
    "text": "on a sentence-by-sentence basis. And the way that ELMo\nspecifically does that is by taking two RNNs, one\ngoing in the forward direction",
    "start": "978200",
    "end": "987620"
  },
  {
    "text": "and one going in the\nbackwards direction, and feeding the sentence\ninto the two RNNs, and using the hidden\nstates of those RNNs",
    "start": "987620",
    "end": "994640"
  },
  {
    "text": "as the vector representation\nfor each word. And during pre-training,\nthe objective",
    "start": "994640",
    "end": "1000400"
  },
  {
    "text": "used to train the\nmodel is basically a next step prediction\nobjective that goes in the forward\nand backward direction.",
    "start": "1000400",
    "end": "1006529"
  },
  {
    "text": "So the forward LSTM, the forward\nrecurrent neural network, tries to predict the word\ncat from the prefix, the dog",
    "start": "1006530",
    "end": "1013330"
  },
  {
    "text": "and the-- there's a missing word there. Actually no, I\nthink I didn't have that in my example sentence.",
    "start": "1013330",
    "end": "1019000"
  },
  {
    "text": "But at any rate,\nthe forward LSTM tries to predict cat,\ngiven the history,",
    "start": "1019000",
    "end": "1024040"
  },
  {
    "text": "and the backwards LSTM\ntries to predict cat from what came after it. So this is kind of this\nautoregressive next step",
    "start": "1024040",
    "end": "1031270"
  },
  {
    "text": "prediction style language\nmodel pre-training is usually what people mean when they\njust say language model pre-training.",
    "start": "1031270",
    "end": "1036609"
  },
  {
    "text": "But the key distinction\nhere for ELMo is that it happens in both\na forward and a backwards",
    "start": "1036609",
    "end": "1042040"
  },
  {
    "text": "direction. And because a given word can\nhave a different representation",
    "start": "1042040",
    "end": "1049060"
  },
  {
    "text": "based on the sentence\nit appears in, you get this very nice\nproperty that the word vector has become\ncontextualized,",
    "start": "1049060",
    "end": "1055600"
  },
  {
    "text": "is what people say. So for example, with GloVe word\nvectors, the ones that I showed the frog example earlier,\na given word vector",
    "start": "1055600",
    "end": "1064090"
  },
  {
    "text": "only has one representation. It doesn't matter\nwhere the word appears in a given chunk of text. It always produces exactly\nthe same representation.",
    "start": "1064090",
    "end": "1071960"
  },
  {
    "text": "And so if you do this\nnearest neighbor thing that we described earlier,\nwhere we take a word like play and find the nearest\nneighbors, you",
    "start": "1071960",
    "end": "1078358"
  },
  {
    "text": "can see that playing, game,\ngames, played, players, plays, player, play,\nfootball, multiplayer are the nearest words.",
    "start": "1078358",
    "end": "1084940"
  },
  {
    "text": "And you can see that\nthese words actually are kind of semantically\ndifferent in some cases, right?",
    "start": "1084940",
    "end": "1090400"
  },
  {
    "text": "So playing is a verb,\na player is a noun that maybe is a part of a game.",
    "start": "1090400",
    "end": "1097780"
  },
  {
    "text": "But there's also other\nforms of the word play that might appear, for example,\nlike a theatrical play.",
    "start": "1097780",
    "end": "1104900"
  },
  {
    "text": "And you can see that this model\nELMo, which they're denoting, biLM, the bidirectional\nlanguage model,",
    "start": "1104900",
    "end": "1111860"
  },
  {
    "text": "ends up producing a\ncontextualized representation of play that finds--",
    "start": "1111860",
    "end": "1118340"
  },
  {
    "text": "that can be used to find\nsimilar uses of the word play. So for example, the\nnearest neighbor",
    "start": "1118340",
    "end": "1123800"
  },
  {
    "text": "for play in the first example is\nshown in the second row there. And for the second example\nis on the bottom row.",
    "start": "1123800",
    "end": "1131720"
  },
  {
    "text": "And you can see that, for\nexample, in the bottom row, it's talking about\na Broadway play. And the nearest neighbor-- the\nnearest contextualized word",
    "start": "1131720",
    "end": "1140210"
  },
  {
    "text": "representation neighbor is from\na chunk of text talking about, again, a theatrical play.",
    "start": "1140210",
    "end": "1146360"
  },
  {
    "text": "So again, by using\nmaybe slightly more intricate architecture,\nbut still a very simple",
    "start": "1146360",
    "end": "1154670"
  },
  {
    "text": "self-supervised objective,\nwe can get this nice ability that the word vectors\nbecome contextualized.",
    "start": "1154670",
    "end": "1161240"
  },
  {
    "text": "And hopefully, it's intuitive\nto see why that's true. ",
    "start": "1161240",
    "end": "1167000"
  },
  {
    "text": "The last model that\nI'll talk about in terms of explaining how language\nmodels learn word meaning,",
    "start": "1167000",
    "end": "1173679"
  },
  {
    "text": "grammar syntax, et\ncetera, is the BERT model, which I've made a very\nsimple schematic of here",
    "start": "1173680",
    "end": "1179260"
  },
  {
    "text": "because I won't be going into\na ton of detail about it. But in BERT, we\nfeed our sentence,",
    "start": "1179260",
    "end": "1184690"
  },
  {
    "text": "the dog and cat ate pot pie. And instead of\ntraining the model to predict what comes\nnext after a prefix",
    "start": "1184690",
    "end": "1191049"
  },
  {
    "text": "or what came before\naccording to a suffix, we actually are just\ngoing to take random words",
    "start": "1191050",
    "end": "1197080"
  },
  {
    "text": "from the input text and replace\nthem with a mask token, which I have denoted by\nthis m, surrounded",
    "start": "1197080",
    "end": "1203289"
  },
  {
    "text": "by less than or greater than. And in BERT, the goal of the\nself-supervised pre-training",
    "start": "1203290",
    "end": "1209890"
  },
  {
    "text": "objective is to predict the\nmasked out words from the words that aren't masked out, right?",
    "start": "1209890",
    "end": "1215320"
  },
  {
    "text": "So if you saw the sentence\ndog and blank ate pot pie, and you needed to\nfill in that blank,",
    "start": "1215320",
    "end": "1220660"
  },
  {
    "text": "maybe you'd fill it in with cat. Maybe you'd fill it in with boy. I don't know. But either way, you\nwould hope to be",
    "start": "1220660",
    "end": "1226930"
  },
  {
    "text": "able to figure out the\nidentity of that word from its surrounding context.",
    "start": "1226930",
    "end": "1232909"
  },
  {
    "text": "And so you can think of this\nas probabilistically modeling",
    "start": "1232910",
    "end": "1238960"
  },
  {
    "text": "the word cat. According to the equation\non the bottom there, basically just that\nwe're predicting cat from the surrounding context.",
    "start": "1238960",
    "end": "1246130"
  },
  {
    "text": "And a key architectural\ninnovation of BERT is that rather than using\na recurrent neural network",
    "start": "1246130",
    "end": "1251480"
  },
  {
    "text": "like ELMo, it uses a layer type\nthat we call self-attention.",
    "start": "1251480",
    "end": "1256549"
  },
  {
    "text": "And again, I'm not going\nto go into a ton of detail about self-attention,\nexcept to say",
    "start": "1256550",
    "end": "1261860"
  },
  {
    "text": "that what self-attention\nallows the model to do is refer back to\narbitrary input positions",
    "start": "1261860",
    "end": "1268130"
  },
  {
    "text": "when generating a new\nrepresentation for a given position. And I've denoted that\nwith these lines,",
    "start": "1268130",
    "end": "1275630"
  },
  {
    "text": "connecting the different nodes\nin the yellow model here. But you can think of it as,\nif I need to predict the--",
    "start": "1275630",
    "end": "1284660"
  },
  {
    "text": "if I need to fill in a\nmissing word, then maybe it's most valuable for me to\nlook at another specific word",
    "start": "1284660",
    "end": "1291560"
  },
  {
    "text": "or another few words. Because maybe it's\na pronoun and I need to figure out where the\npronoun refers to, or something",
    "start": "1291560",
    "end": "1299809"
  },
  {
    "text": "like that. And it turns out that this\nform of self-attention is a much more efficient\nway of bridging dependencies",
    "start": "1299810",
    "end": "1307280"
  },
  {
    "text": "in sequential data than a\nrecurrent neural network, which has to store all\nof the information about the sequence\nin its hidden state.",
    "start": "1307280",
    "end": "1314690"
  },
  {
    "text": "And so one type of\nanalysis you can do with self-attention models\nor attention models in general",
    "start": "1314690",
    "end": "1320210"
  },
  {
    "text": "is basically looking at\nwhat position in the input the model is attending to\nthe most when it generates",
    "start": "1320210",
    "end": "1327770"
  },
  {
    "text": "the representation for a\nparticular entry in the output sequence.",
    "start": "1327770",
    "end": "1333120"
  },
  {
    "text": "And so this nice\npaper analyzed many of the self-attention\npatterns in BERT",
    "start": "1333120",
    "end": "1338779"
  },
  {
    "text": "to try to see what\nthings BERT was attending to when generating\nrepresentations for a particular word.",
    "start": "1338780",
    "end": "1345049"
  },
  {
    "text": "And interestingly, if you\njust look at the word or words",
    "start": "1345050",
    "end": "1352570"
  },
  {
    "text": "that the model is most\nattending to at a given position and treat that as a classifier\nto try to identify things",
    "start": "1352570",
    "end": "1361270"
  },
  {
    "text": "like which word does a\npronoun refer to, for example,",
    "start": "1361270",
    "end": "1368110"
  },
  {
    "text": "or which verb does a-- sorry, which noun\ndoes a verb apply to,",
    "start": "1368110",
    "end": "1374149"
  },
  {
    "text": "and so on, you actually\nget very high accuracy. And you can see some\nillustrations of this here. So this, to me,\nsuggests that BERT",
    "start": "1374150",
    "end": "1381399"
  },
  {
    "text": "has learned some knowledge\nabout grammar and structure and syntax of language in the\nsense that it has figured out,",
    "start": "1381400",
    "end": "1391660"
  },
  {
    "text": "without any explicit\nsupervision, that when it's generating the representation\nfor a particular word,",
    "start": "1391660",
    "end": "1397059"
  },
  {
    "text": "there are specific words\nwith specific relationships that are most useful\nfor predicting that particular word.",
    "start": "1397060",
    "end": "1403419"
  },
  {
    "text": "And that maybe gives\nthis knowledge, which is quite\ninteresting and useful. And again, it falls\nout of a pretty simple",
    "start": "1403420",
    "end": "1409600"
  },
  {
    "text": "self-supervised objective.  So hopefully, that convinces you\nthat various types of language",
    "start": "1409600",
    "end": "1417580"
  },
  {
    "text": "models or things that are\nused for modeling language teach the model word\nmeaning, syntax, and grammar.",
    "start": "1417580",
    "end": "1425049"
  },
  {
    "text": "Before going on to\nthe next bit, I'll ask if there are any questions\nabout what I just said.",
    "start": "1425050",
    "end": "1431450"
  },
  {
    "text": "Cool. So I think I'll go\nahead and carry on then. So the next thing\nthat I mentioned",
    "start": "1431450",
    "end": "1439460"
  },
  {
    "text": "that language modeling seems\nto teach language models is world knowledge. And when I say world knowledge,\nI mean a broad set of things.",
    "start": "1439460",
    "end": "1448850"
  },
  {
    "text": "But to try to be a\nlittle more specific, I'm talking about kind of\nlearning facts about the world.",
    "start": "1448850",
    "end": "1455940"
  },
  {
    "text": "And some of these might be\ntrivia facts, some of them might be very, very\nspecific facts, some of them",
    "start": "1455940",
    "end": "1461840"
  },
  {
    "text": "might be general-purpose\nthings, properties of well-known things.",
    "start": "1461840",
    "end": "1467659"
  },
  {
    "text": "To give you a very specific\nexample shown on the screen here. For example, maybe knowing\nthe birthplace of Dante.",
    "start": "1467660",
    "end": "1476659"
  },
  {
    "text": "This is a very famous\nperson, and their birthplace might be a well-known\nfact about the world.",
    "start": "1476660",
    "end": "1484370"
  },
  {
    "text": "And typically, in\nthe past, when people have wanted to store\nthis relationship,",
    "start": "1484370",
    "end": "1490910"
  },
  {
    "text": "a common structure to use\nas is knowledge graph. Knowledge graph is\na way of storing",
    "start": "1490910",
    "end": "1496220"
  },
  {
    "text": "relationships between\ndifferent entities, like Dante and Florence. So you might say that Dante\nhas the born-in relationship",
    "start": "1496220",
    "end": "1503960"
  },
  {
    "text": "with Florence. Meaning, that Dante\nwas born in Florence. And a knowledge graph\nis a very useful way",
    "start": "1503960",
    "end": "1510800"
  },
  {
    "text": "of representing these\nkind of relationships, but they typically require\nat least some amount of construction by hand.",
    "start": "1510800",
    "end": "1518120"
  },
  {
    "text": "And there are some\nincredible knowledge graphs out there in\nthe world that involve",
    "start": "1518120",
    "end": "1523190"
  },
  {
    "text": "a lot of human labor to create. But what people have started\nto notice about language models",
    "start": "1523190",
    "end": "1529670"
  },
  {
    "text": "is that language\nmodels themselves build an implicit knowledge graph. And so, for example, if we\ntrain a language model like ELMo",
    "start": "1529670",
    "end": "1537350"
  },
  {
    "text": "or BERT, and we feed the\nlanguage model with a sentence like shown here, Dante\nwas born in blank,",
    "start": "1537350",
    "end": "1544070"
  },
  {
    "text": "you might imagine\nthat if BERT is going to do a good job with its\nself-supervised pre-training objective, it needs to be\nable to fill in that blank.",
    "start": "1544070",
    "end": "1551312"
  },
  {
    "text": "And in order to\nfill in that blank, it needs to know\nwhere Dante was born. So the model actually is trained\nto learn facts indirectly",
    "start": "1551312",
    "end": "1558950"
  },
  {
    "text": "in this way. And indeed, language\nmodels do seem to learn a lot of\nfacts this way.",
    "start": "1558950",
    "end": "1564789"
  },
  {
    "text": "So to put it to the test as\nto how well these language models pick up facts,\nwe actually took T5",
    "start": "1564790",
    "end": "1571420"
  },
  {
    "text": "and applied the following\nevaluation procedure. So after pre-training T5 on\na self-supervised objective,",
    "start": "1571420",
    "end": "1578992"
  },
  {
    "text": "much like the fill-in the\nblank objective I described at the beginning of the talk,\nand similar to the objective that BERT was trained on, where\nwe take a chunk of input text",
    "start": "1578992",
    "end": "1586720"
  },
  {
    "text": "and we randomly remove words and\nreplace them with mass tokens, and train the model to\nfill in the missing--",
    "start": "1586720",
    "end": "1592390"
  },
  {
    "text": "fill in the blanks basically,\nwe then evaluate the model basically by training\nit to predict",
    "start": "1592390",
    "end": "1598840"
  },
  {
    "text": "the answers to questions\nwithout any additional context. And then testing it to\nanswer unseen questions.",
    "start": "1598840",
    "end": "1605570"
  },
  {
    "text": "So for example, we\nmight ask it, when was Franklin D Roosevelt born? And we evaluate the\nmodel on how well",
    "start": "1605570",
    "end": "1613660"
  },
  {
    "text": "it predicts the year 1882,\nwhich was Franklin D Roosevelt's birth year.",
    "start": "1613660",
    "end": "1618880"
  },
  {
    "text": "So since we're only feeding\nthe model this question, we're not feeding the model\nany additional context",
    "start": "1618880",
    "end": "1624490"
  },
  {
    "text": "and giving it--\nwe're not giving it any access to any external\ninformation whatsoever. You might imagine that the only\nway that the model can predict",
    "start": "1624490",
    "end": "1632290"
  },
  {
    "text": "the year 1882 correctly was if\nit saw the fact that Franklin D",
    "start": "1632290",
    "end": "1637450"
  },
  {
    "text": "Roosevelt was born\nin 1882 at some point during its pre-training. And so you might imagine\nthat if the model was trained",
    "start": "1637450",
    "end": "1646059"
  },
  {
    "text": "to fill in the blanks in the\nsentence, President Franklin, blank, born, blank,\nJanuary 1882, maybe it",
    "start": "1646060",
    "end": "1652509"
  },
  {
    "text": "somehow internalized\nthis knowledge. And so this gives us a test of--",
    "start": "1652510",
    "end": "1658300"
  },
  {
    "text": "a real-world test of\nhow much knowledge a language model internalizes.",
    "start": "1658300",
    "end": "1663820"
  },
  {
    "text": "And it also allows us to use\nstandard off-the-shelf question answering benchmarks.",
    "start": "1663820",
    "end": "1668950"
  },
  {
    "text": "Most of the time,\nat least before we wrote this paper, when people\nwould evaluate language models",
    "start": "1668950",
    "end": "1675910"
  },
  {
    "text": "on these benchmarks, they\nwould allow the model to access external\ninformation either by feeding",
    "start": "1675910",
    "end": "1681159"
  },
  {
    "text": "in some context that\nactually contain the answer, like in reading\ncomprehension, or by providing",
    "start": "1681160",
    "end": "1686679"
  },
  {
    "text": "a way for the model\nto look up information in an external\ncollection of knowledge, like maybe you could\nthink of it like searching",
    "start": "1686680",
    "end": "1693700"
  },
  {
    "text": "Wikipedia and\nfinding an article, and extracting a\nparagraph, and extracting the answer from the paragraph. So that's what people call\nopen-domain question answering.",
    "start": "1693700",
    "end": "1701620"
  },
  {
    "text": "We are calling this\nclosed-book question answering because you're not allowed\nto open the book when",
    "start": "1701620",
    "end": "1707200"
  },
  {
    "text": "you're answering the question. So if we evaluate the various\nsizes of T5 on this task,",
    "start": "1707200",
    "end": "1714140"
  },
  {
    "text": "you can see that we\nactually don't do as well as the open-domain\nstate of the art",
    "start": "1714140",
    "end": "1719510"
  },
  {
    "text": "on any of these three standard\nopen-domain question answering benchmarks. We do a bit worse in every case.",
    "start": "1719510",
    "end": "1726470"
  },
  {
    "text": "But notably, you can see that\nas the model size increases, as we go from light\nblue to dark blue,",
    "start": "1726470",
    "end": "1733039"
  },
  {
    "text": "the model's performance\nreliably gets better, which suggests\nthat larger models tend",
    "start": "1733040",
    "end": "1738860"
  },
  {
    "text": "to internalize more knowledge\nthan smaller models. And just to be more\nspecific, T5 base",
    "start": "1738860",
    "end": "1745250"
  },
  {
    "text": "is a model with a few\nhundred million parameters. T5-XXL is a model with about\naround 11 billion parameters.",
    "start": "1745250",
    "end": "1751710"
  },
  {
    "text": "So we're varying the size by\ntwo orders of magnitude or so, and you can see that models do\ntend to apparently internalize",
    "start": "1751710",
    "end": "1761510"
  },
  {
    "text": "more knowledge as they\nget larger and larger. So we thought this was\ninteresting, right, because we're doing respectably\non these benchmarks,",
    "start": "1761510",
    "end": "1769400"
  },
  {
    "text": "compared to an open-domain\nstate of the art, despite the fact that we have\nno access to external knowledge",
    "start": "1769400",
    "end": "1775190"
  },
  {
    "text": "or information whatsoever. So we really-- in order\nto do well on this task, T5 really needs to have\nlearned all of this information",
    "start": "1775190",
    "end": "1782240"
  },
  {
    "text": "during its pre-training. But we wanted to know if we\ncould do a little better. So we took an idea from\na paper that came out",
    "start": "1782240",
    "end": "1788480"
  },
  {
    "text": "around the same time,\ncalled the REALM, which stands for Retrieval-Augmented\nLanguage Model Pre-training.",
    "start": "1788480",
    "end": "1793760"
  },
  {
    "text": "And the idea behind-- the idea here is that rather\nthan just picking words randomly to mask out,\nyou intentionally",
    "start": "1793760",
    "end": "1800720"
  },
  {
    "text": "remove words that kind\nof look like entities. So maybe in this\nexample sentence here,",
    "start": "1800720",
    "end": "1806840"
  },
  {
    "text": "we removed the person's\nname, Ana Santos Aramburo. And the hope is that by\nintentionally masking out",
    "start": "1806840",
    "end": "1814125"
  },
  {
    "text": "kind of phrases that\ncorrespond to entities, the model will learn more\ninformation about entities",
    "start": "1814125",
    "end": "1820220"
  },
  {
    "text": "specifically. So if we take one of\nthe models that I just showed on the last screen and\nwe do additional pre-training",
    "start": "1820220",
    "end": "1827690"
  },
  {
    "text": "with the same masked\nlanguage modeling objective, you can see that the\nperformance-- and that's shown in orange here.",
    "start": "1827690",
    "end": "1832820"
  },
  {
    "text": "You can see the performance\ndoesn't increase much. It just stays flat. But if we do the salient\nspan masking pre-training,",
    "start": "1832820",
    "end": "1839539"
  },
  {
    "text": "where we intentionally mask\nout chunks of the input that correspond to\nentities, you can see",
    "start": "1839540",
    "end": "1844880"
  },
  {
    "text": "that the performance on these\ndownstream question answering benchmarks just tends to\nincrease and increase.",
    "start": "1844880",
    "end": "1852820"
  },
  {
    "text": "So if we take the\nlargest model and we do some additional salient\nspan masking pre-training,",
    "start": "1852820",
    "end": "1858270"
  },
  {
    "text": "you can see what happens\nin the purple bar here. And you can see that we\nactually go a significant way",
    "start": "1858270",
    "end": "1863610"
  },
  {
    "text": "towards closing the gap with\nthe open-domain state of the art by doing this additional\npre-training step.",
    "start": "1863610",
    "end": "1868950"
  },
  {
    "text": "And actually, on web\nquestions ultimately beat the state of the art\nby just a small amount, which is quite exciting,\nright, because it means",
    "start": "1868950",
    "end": "1875190"
  },
  {
    "text": "that this model,\nthis very large model actually has enough information\nin it that it can get better",
    "start": "1875190",
    "end": "1884039"
  },
  {
    "text": "performance than a model\nthat can actually look up the information. So it's better at looking up\ninformation in its parameters",
    "start": "1884040",
    "end": "1890700"
  },
  {
    "text": "than a model that's\nlooking up information, let's say, like on the\ninternet or on Wikipedia. ",
    "start": "1890700",
    "end": "1898020"
  },
  {
    "text": "And just to kind of make\nthe results a little more optimistic, we'll\njust quickly point out",
    "start": "1898020",
    "end": "1903659"
  },
  {
    "text": "that the way that these\nmodels are typically evaluated is by measuring whether\ntheir output matches,",
    "start": "1903660",
    "end": "1910170"
  },
  {
    "text": "after some normalization,\none of the annotated answers for that particular question.",
    "start": "1910170",
    "end": "1915400"
  },
  {
    "text": "So you can see here,\nin this first example, the model is being asked\nwhat the ghost of Christmas",
    "start": "1915400",
    "end": "1920610"
  },
  {
    "text": "present sprinkles\nfrom his torch. The possible answers are\neither little warmth or warmth. And our model\npredicted confetti.",
    "start": "1920610",
    "end": "1926760"
  },
  {
    "text": "That's clearly wrong. But there are actually cases\nwhere the model can kind of output a synonym or a\nparaphrase or some text that",
    "start": "1926760",
    "end": "1935850"
  },
  {
    "text": "means the same thing\nas the true target, but it gets counted as incorrect\nbecause it doesn't actually",
    "start": "1935850",
    "end": "1941460"
  },
  {
    "text": "match the target. So for example, if the correct\ntarget is Kate Mulgrew, but the model predicted\nKatherine Kiernan and Maria",
    "start": "1941460",
    "end": "1948810"
  },
  {
    "text": "Mulgrew, it gets\ncounted as incorrect, even though those actually\ndo refer to the same people.",
    "start": "1948810",
    "end": "1954720"
  },
  {
    "text": "And so if we went through and\nlooked at some of the examples",
    "start": "1954720",
    "end": "1960600"
  },
  {
    "text": "that were being\ncounted incorrectly, and categorize them according\nto these different categories. If we basically count the\nthings that it actually",
    "start": "1960600",
    "end": "1969899"
  },
  {
    "text": "got correct as correct\nand remove the things that there was no way\nfor it to get correct, then our score actually\ngoes up significantly",
    "start": "1969900",
    "end": "1977130"
  },
  {
    "text": "and actually outperforms the\nopen-domain state of the art. Open-domain question\nanswering models don't suffer from quite the same\nissue because most of the time",
    "start": "1977130",
    "end": "1985919"
  },
  {
    "text": "the ground truth annotated\nanswers are annotated according to the text that the model is\nactually going to be extracting",
    "start": "1985920",
    "end": "1992220"
  },
  {
    "text": "the answer from. So all this is to\nsay that it really",
    "start": "1992220",
    "end": "1997500"
  },
  {
    "text": "does seem to be the case that\nlanguage models learn lots of useful world knowledge\nthrough their pre-training,",
    "start": "1997500",
    "end": "2004820"
  },
  {
    "text": "and it's not too\nhard to get the model to retrieve that knowledge and\nanswer questions correctly.",
    "start": "2004820",
    "end": "2014100"
  },
  {
    "text": "So a natural question to ask\nafter that is, so the model",
    "start": "2014100",
    "end": "2019910"
  },
  {
    "text": "picks up lots of\nkind of what we might call like trivia knowledge,\nlike general knowledge",
    "start": "2019910",
    "end": "2025759"
  },
  {
    "text": "that applies to well-known\nentities, and so on. And another question to\nask is, does the model also",
    "start": "2025760",
    "end": "2033080"
  },
  {
    "text": "pick up a lot of not\nso general knowledge that is just kind of very,\nvery specific knowledge",
    "start": "2033080",
    "end": "2038330"
  },
  {
    "text": "that maybe doesn't appear that\nmany times on the internet? Most people-- in fact, almost\nno one would actually know this,",
    "start": "2038330",
    "end": "2044429"
  },
  {
    "text": "but the model,\nnevertheless, memorized it. And so we wrote\na follow-up paper",
    "start": "2044430",
    "end": "2050690"
  },
  {
    "text": "that attempted to answer this\nquestion by studying the GPT-2 model released by OpenAI.",
    "start": "2050690",
    "end": "2056629"
  },
  {
    "text": "And our basic goal was\nto see whether feeding a particular text\nprefix into the model",
    "start": "2056630",
    "end": "2062060"
  },
  {
    "text": "could make the model\noutput something that was clearly memorized,\nthat clearly only appeared",
    "start": "2062060",
    "end": "2067699"
  },
  {
    "text": "a few times on the\ninternet and was not general-purpose knowledge,\nlike Franklin D Roosevelt's birthday.",
    "start": "2067699",
    "end": "2073190"
  },
  {
    "text": "And I wouldn't be\ntalking about this if it wasn't true that the model\nactually does memorize stuff.",
    "start": "2073190",
    "end": "2078360"
  },
  {
    "text": "So here's one\nexample where feeding in a kind of nonsensical prefix\ncaused the model to output",
    "start": "2078360",
    "end": "2083570"
  },
  {
    "text": "the name, email\naddress, phone number, and fax number of a real person.",
    "start": "2083570",
    "end": "2089869"
  },
  {
    "text": "And this particular\nchunk of text only appears on one\nwebsite on the internet.",
    "start": "2089870",
    "end": "2095820"
  },
  {
    "text": "So how did we find these\nexamples of memorized text? I won't go through this\nin a ton of detail,",
    "start": "2095820",
    "end": "2102180"
  },
  {
    "text": "but I'll just describe what\nwe did at a high level. We fed the model with\nvarious prefixes.",
    "start": "2102180",
    "end": "2108200"
  },
  {
    "text": "These prefixes were\neither sampled randomly from the internet or were\ngenerations from the model",
    "start": "2108200",
    "end": "2114680"
  },
  {
    "text": "itself. Then in order to\nidentify completions that seemed likely\nto be memorized,",
    "start": "2114680",
    "end": "2121940"
  },
  {
    "text": "we compared the perplexity\nor the likelihood assigned",
    "start": "2121940",
    "end": "2127160"
  },
  {
    "text": "by the model to\nits own generations to the score assigned by\na different model, right?",
    "start": "2127160",
    "end": "2133430"
  },
  {
    "text": "So if you imagine,\nI have two models, and these models were trained\non disjoint training data.",
    "start": "2133430",
    "end": "2139205"
  },
  {
    "text": "A model that is outputting\nsomething that it has memorized might assign a lot\nhigher likelihood",
    "start": "2139205",
    "end": "2145099"
  },
  {
    "text": "to that memorized data\nthan a model that wasn't trained on that data at all. And so we compared\nthese likelihoods",
    "start": "2145100",
    "end": "2151250"
  },
  {
    "text": "or these perplexities\nacross different models in order to hopefully\nfind text, output",
    "start": "2151250",
    "end": "2159799"
  },
  {
    "text": "by a given model that it\nthinks is unrealistically and unusually likely,\nthat it really shouldn't seem so likely.",
    "start": "2159800",
    "end": "2167960"
  },
  {
    "text": "And then according\nto this score, we chose some examples\nthat we thought were particularly likely\nto be memorized, performed",
    "start": "2167960",
    "end": "2175010"
  },
  {
    "text": "an internet search. If we found it somewhere\non the internet, we asked GPT-2 authors if it\nwas in the training set or not.",
    "start": "2175010",
    "end": "2180890"
  },
  {
    "text": "And that's how we ended up\nidentifying a bunch of text, that GPT-2 output that\nappeared in the training set.",
    "start": "2180890",
    "end": "2189400"
  },
  {
    "text": "And so just to give a\nmore concrete example of what this comparison\nof scores method might do.",
    "start": "2189400",
    "end": "2197140"
  },
  {
    "text": "You can see on the x-axis\nhere, the perplexity assigned by GPT-2 to\na particular example",
    "start": "2197140",
    "end": "2204460"
  },
  {
    "text": "where a lower perplexity\nmeans that the model thinks that it's more likely. And the entropy assigned\nto a particular example",
    "start": "2204460",
    "end": "2211900"
  },
  {
    "text": "by zlib, where a higher\nentropy means that zlib thinks it's less likely. And so you can see there\nare these examples here",
    "start": "2211900",
    "end": "2218920"
  },
  {
    "text": "that are on the top\nleft of the graph, are examples where GPT-2 thinks\nit's a very, very, very likely",
    "start": "2218920",
    "end": "2227230"
  },
  {
    "text": "and zlib thinks it's\nvery, very unlikely. And so if we look at a\nbunch of those examples that",
    "start": "2227230",
    "end": "2234160"
  },
  {
    "text": "have been highlighted\nin blue and red, you can see that a bunch\nof them actually did end up",
    "start": "2234160",
    "end": "2239500"
  },
  {
    "text": "being memorized training data\nfrom a GPT-2 training data set. So this is a pretty\neffective way",
    "start": "2239500",
    "end": "2244930"
  },
  {
    "text": "of identifying\nmemorized content. ",
    "start": "2244930",
    "end": "2250340"
  },
  {
    "text": "And one other result that\nI'll highlight from this paper is that by coincidence,\nthere was one document",
    "start": "2250340",
    "end": "2257375"
  },
  {
    "text": "that we found on the\ninternet that just had a list of a ton of URLs. And we knew that this document\nwas in GPT-2's training data.",
    "start": "2257375",
    "end": "2264130"
  },
  {
    "text": "We confirmed it\nwith the authors. And it just happened that\na bunch of these URLs",
    "start": "2264130",
    "end": "2269650"
  },
  {
    "text": "were duplicated\nin this document. And the amount that\nthey were duplicated",
    "start": "2269650",
    "end": "2275650"
  },
  {
    "text": "varied from URL to URL. So you can see on\nthis table here, we're showing one URL that was\nin this document eight times",
    "start": "2275650",
    "end": "2282940"
  },
  {
    "text": "and one URL that was in\nthis document 359 times. And we know that GPT-2\nwas trained on this data.",
    "start": "2282940",
    "end": "2288940"
  },
  {
    "text": "And fortunately, the authors of\nGPT-2 trained models of varying sizes, all the way up to\none-and-a-half billion",
    "start": "2288940",
    "end": "2295690"
  },
  {
    "text": "parameters, the XL model. And what we found was\nthat the likelihood that a model memorized\na particular URL",
    "start": "2295690",
    "end": "2304660"
  },
  {
    "text": "was much higher when it\ndidn't appear as many times for the largest model.",
    "start": "2304660",
    "end": "2310400"
  },
  {
    "text": "I think I might have said that\nin a slightly confusing way. So the much less\nconfusing way to say",
    "start": "2310400",
    "end": "2315680"
  },
  {
    "text": "that is that larger models\nneed to see examples fewer times in order to\nmemorize them, is",
    "start": "2315680",
    "end": "2320990"
  },
  {
    "text": "what this particular result-- this kind of accidental\nresult suggests. So just as with models picking\nup world knowledge better",
    "start": "2320990",
    "end": "2329420"
  },
  {
    "text": "as they get larger, models also\nseem to memorize not so worldly",
    "start": "2329420",
    "end": "2334640"
  },
  {
    "text": "knowledge, just specific\nfacts in the training data-- specific data in\nthe training data-- specific text from the training\ndata as they get larger.",
    "start": "2334640",
    "end": "2342050"
  },
  {
    "text": "It's kind of easy to cause\nthis memorization to happen, which is interesting.",
    "start": "2342050",
    "end": "2349430"
  },
  {
    "text": "Maybe good, maybe bad. We can discuss that later.",
    "start": "2349430",
    "end": "2355792"
  },
  {
    "text": "So hopefully, that convinces\nyou that language models learn facts. I'll stop there\nagain to see if there",
    "start": "2355792",
    "end": "2361329"
  },
  {
    "text": "are any questions\nabout anything so far. I think there's a\nquestion in the chat.",
    "start": "2361330",
    "end": "2367850"
  },
  {
    "text": "On correcting the\nevaluation of T5, what do you mean by\nanswerable prompts?",
    "start": "2367850",
    "end": "2373510"
  },
  {
    "text": "Yeah, thanks for that question. I didn't cover that just\nin the interest of time,",
    "start": "2373510",
    "end": "2379150"
  },
  {
    "text": "but I'll mention it now since\nI know it was confusing. So if a model isn't allowed\nto look up information",
    "start": "2379150",
    "end": "2385780"
  },
  {
    "text": "on the internet or at least\nlook up information in the fixed knowledge source, and I\nask the model something",
    "start": "2385780",
    "end": "2391090"
  },
  {
    "text": "like who is the president\nof the United States? There's no way to answer that\nquestion without providing it",
    "start": "2391090",
    "end": "2396910"
  },
  {
    "text": "with additional information. For example, what\nyear it is or just providing it with\na fixed knowledge",
    "start": "2396910",
    "end": "2403210"
  },
  {
    "text": "base to look up\nthe information in. So those questions\naren't really a problem for these open-domain\nquestions answering data sets",
    "start": "2403210",
    "end": "2409900"
  },
  {
    "text": "because all of these\ndata sets are shipped with a fixed knowledge\nsource that is basically",
    "start": "2409900",
    "end": "2414910"
  },
  {
    "text": "a snapshot in time. But since our model,\nits knowledge source is whatever its\npre-training data",
    "start": "2414910",
    "end": "2420910"
  },
  {
    "text": "is, if you ask it\nwhat the president is, it thinks that the\npresident is whoever was the president at the\ntime that it was pre-trained.",
    "start": "2420910",
    "end": "2428210"
  },
  {
    "text": "And so it can get\nthose questions wrong. More broadly, you can just think\nof them as ambiguous questions,",
    "start": "2428210",
    "end": "2434650"
  },
  {
    "text": "and they're not answerable by a\nmodel that doesn't have access to external fixed knowledge.",
    "start": "2434650",
    "end": "2440022"
  },
  {
    "text": " Do you want to ask a question?",
    "start": "2440022",
    "end": "2445319"
  },
  {
    "text": "Yeah, just to follow up on that. So is it-- is that\naccomplished just",
    "start": "2445320",
    "end": "2450930"
  },
  {
    "text": "by hand labeling, which\nquestions are unanswerable, which answers count\nas phrase mismatches?",
    "start": "2450930",
    "end": "2460130"
  },
  {
    "text": "Or is there some way to do it? We did not attempt to\ndo it automatically. We actually-- the other\nfirst author and I",
    "start": "2460130",
    "end": "2466320"
  },
  {
    "text": "sat down and just\nspent a day doing it. And we actually released\nour annotations, so you can go and see if you\nagree or disagree with us.",
    "start": "2466320",
    "end": "2475640"
  },
  {
    "text": "Thank you. One more question in the chat. Do these models just\nmemorize, or can they",
    "start": "2475640",
    "end": "2482860"
  },
  {
    "text": "also learn rules such as basic\narithmetic, such as algebra or math equations?",
    "start": "2482860",
    "end": "2489710"
  },
  {
    "text": "Yeah, that's a good question. I think the-- I probably will wait\nto answer that question until after the next\nsection because I",
    "start": "2489710",
    "end": "2497960"
  },
  {
    "text": "think the next section\ngoes some way to addressing that question. ",
    "start": "2497960",
    "end": "2503760"
  },
  {
    "text": "This might not be like a\nmeaningful question to ask, but is it possible to see\nor to think about how--",
    "start": "2503760",
    "end": "2512550"
  },
  {
    "text": "you said that knowledge is kind\nof stored in the parameters. Is there-- I guess, like how--",
    "start": "2512550",
    "end": "2519480"
  },
  {
    "text": "is there like a\nstructure or some way that different parts of the\nmodel or different layers",
    "start": "2519480",
    "end": "2525030"
  },
  {
    "text": "or whatever store different\npieces of information? Yeah, there has been\nsome follow-up work",
    "start": "2525030",
    "end": "2530500"
  },
  {
    "text": "that has attempted\nto either identify whether knowledge is\nlocalized in a model",
    "start": "2530500",
    "end": "2537120"
  },
  {
    "text": "or whether it's possible to\nmore intentionally localize knowledge in a model. That's not work that\nI've done or that I've",
    "start": "2537120",
    "end": "2544500"
  },
  {
    "text": "looked into a ton of detail,\nbut I'm happy to be-- I'd be happy to send\npointers after the talk",
    "start": "2544500",
    "end": "2550830"
  },
  {
    "text": "if you follow up with me. Thank you.",
    "start": "2550830",
    "end": "2556780"
  },
  {
    "text": "Cool. Maybe in the interest\nof time, I'll move on to the next section. But then I'll be happy to\ntake questions after the talk.",
    "start": "2556780",
    "end": "2564660"
  },
  {
    "text": "So hopefully,\nyou're now convinced that this simple self-supervised\napproach causes models",
    "start": "2564660",
    "end": "2570349"
  },
  {
    "text": "to learn things\nabout language, it causes models to learn\nthings about the world. Now, we'll try to see if it\ncauses models to learn actually",
    "start": "2570350",
    "end": "2578420"
  },
  {
    "text": "how to perform useful tasks. And so the setup that we\nuse to answer this question",
    "start": "2578420",
    "end": "2585020"
  },
  {
    "text": "is somewhat different from\nthe transfer learning setup that we've mostly\nbeen using so far.",
    "start": "2585020",
    "end": "2590090"
  },
  {
    "text": "In this particular setup, which\nwe call zero-shot evaluation, we still pre-train the model\nwith an unsupervised objective",
    "start": "2590090",
    "end": "2597920"
  },
  {
    "text": "where we, in this case-- however, that unsupervised\npre-training objective",
    "start": "2597920",
    "end": "2603080"
  },
  {
    "text": "is now somewhat different. So rather than, for\nexample masking out words, we do something a little\nmore specific that looks more",
    "start": "2603080",
    "end": "2610230"
  },
  {
    "text": "like what people think\nof when they say language modeling, which is just that we\ntrain the model to predict what",
    "start": "2610230",
    "end": "2615260"
  },
  {
    "text": "comes next. So we feed in some text. It's just a continuous\nblock of text. And then we train the model\nto predict the following text.",
    "start": "2615260",
    "end": "2623539"
  },
  {
    "text": "So it's just being trained\nfor next step prediction. It's what people usually mean\nwhen they just say language",
    "start": "2623540",
    "end": "2628880"
  },
  {
    "text": "modeling without qualification. And the question will be, if\nwe train the model in this way,",
    "start": "2628880",
    "end": "2634010"
  },
  {
    "text": "can we prompt the model\nin a particular way that elicits a correct response\nfor some particular task?",
    "start": "2634010",
    "end": "2643530"
  },
  {
    "text": "So here, I'm showing a\nnatural language inference task, where the model is\nbeing asked whether it's",
    "start": "2643530",
    "end": "2650450"
  },
  {
    "text": "possible to infer a\nparticular statement from another statement. So this is a classic natural\nlanguage processing task,",
    "start": "2650450",
    "end": "2657050"
  },
  {
    "text": "and it's being converted to\na question answering format. So if you imagine that\nsomewhere on the internet,",
    "start": "2657050",
    "end": "2665180"
  },
  {
    "text": "someone asked this model--\nif someone wrote down a question and the answer after\nthe question, which is not",
    "start": "2665180",
    "end": "2672110"
  },
  {
    "text": "unreasonable to\nexpect, and the model was pre-trained\non that data, then",
    "start": "2672110",
    "end": "2677690"
  },
  {
    "text": "maybe the model starts to\nlearn how to answer questions. And so if you ask it\na question like this,",
    "start": "2677690",
    "end": "2682940"
  },
  {
    "text": "maybe it will predict the\nword yes as more likely than the word no. And in doing so,\nit's essentially",
    "start": "2682940",
    "end": "2688700"
  },
  {
    "text": "labeling this example from\nnatural language inference. It's labeling that\nthe banker contacted",
    "start": "2688700",
    "end": "2693980"
  },
  {
    "text": "the professors and\nthe athlete allows one to infer that the banker\ncontacted the professors.",
    "start": "2693980",
    "end": "2699680"
  },
  {
    "text": "So by doing this language\nmodel pre-training, this next step\nprediction pre-training, we can cast tasks in a\nparticular format that allows",
    "start": "2699680",
    "end": "2707780"
  },
  {
    "text": "us to evaluate things-- evaluate tasks without doing\nany additional training, right?",
    "start": "2707780",
    "end": "2713480"
  },
  {
    "text": "So I'm just feeding in this\nnew context to the model and seeing if it predicts\nthe answer correctly.",
    "start": "2713480",
    "end": "2720360"
  },
  {
    "text": "And you can cast-- just like\nwith the text-to-text format from T5, you can cast lots\nof tasks this way, right?",
    "start": "2720360",
    "end": "2726150"
  },
  {
    "text": "And so actually,\nquestion answering tasks are a natural fit for this\nbecause question answering tasks consist of a question\nfollowed by an answer.",
    "start": "2726150",
    "end": "2733710"
  },
  {
    "text": "So to give an example, if\nwe take TriviaQA, which we used in the paper I\ndescribed a little bit ago,",
    "start": "2733710",
    "end": "2741000"
  },
  {
    "text": "and we just feed\na large language model questions from\nTriviaQA and measure",
    "start": "2741000",
    "end": "2746190"
  },
  {
    "text": "how often it predicts\nthe answer correctly, it actually gets\nthe answer correctly",
    "start": "2746190",
    "end": "2751290"
  },
  {
    "text": "a pretty significant\nproportion of the time. So these are results\nfrom language models or few-shot learners, also\nknown as the GPT-3 paper.",
    "start": "2751290",
    "end": "2759869"
  },
  {
    "text": "And one of the major\ncharacteristics of this paper was trying models\nof varying sizes up",
    "start": "2759870",
    "end": "2765270"
  },
  {
    "text": "to an extremely large model\nwith 175 billion parameters. And sure enough,\njust like we saw",
    "start": "2765270",
    "end": "2770609"
  },
  {
    "text": "with the closed-book question\nanswering results with T5, the performance\nof the model tends to increase as the size\nof the model grows.",
    "start": "2770610",
    "end": "2777498"
  },
  {
    "text": "The difference here\nis that there was no adaptation step for GPT-3. After doing language\nmodel pre-training,",
    "start": "2777498",
    "end": "2784349"
  },
  {
    "text": "the model was just\nfed questions and it was evaluated on\nwhether it had answered",
    "start": "2784350",
    "end": "2790350"
  },
  {
    "text": "the questions correctly. And it does quite well\nin TriviaQA specifically. It also does quite well\non lots of other tasks.",
    "start": "2790350",
    "end": "2797819"
  },
  {
    "text": "In some cases, on natural\nlanguage inference, like I just described, on things\nlike paraphrase identification.",
    "start": "2797820",
    "end": "2803730"
  },
  {
    "text": "So do these two sentences\nmean the same thing? Sentiment analysis. Is this movie review\npositive or negative?",
    "start": "2803730",
    "end": "2809790"
  },
  {
    "text": "Really on a huge\nvariety of tasks. So the conjecture,\ntherefore, was that this unsupervised\nlanguage model",
    "start": "2809790",
    "end": "2816270"
  },
  {
    "text": "pre-training produces a model\nthat is effectively a multitask model. It can perform lots and lots\nof tasks reasonably well.",
    "start": "2816270",
    "end": "2824770"
  },
  {
    "text": "And I think when a lot of people\ninterpreted these results, they thought of\nGPT-3 as doing this",
    "start": "2824770",
    "end": "2833580"
  },
  {
    "text": "by magic because it is becoming\nkind of like a more and more powerful model.",
    "start": "2833580",
    "end": "2839230"
  },
  {
    "text": "And so it just knows more\nand more and more things. And that it achieves\nthis magic through",
    "start": "2839230",
    "end": "2847230"
  },
  {
    "text": "unsupervised pre-training. But I've started to try to\npush a different perspective",
    "start": "2847230",
    "end": "2854800"
  },
  {
    "text": "a little bit, which\nis that actually it's pretty likely that GPT-3 saw\nexamples of what we would",
    "start": "2854800",
    "end": "2861400"
  },
  {
    "text": "probably call labeled\nexamples from lots of tasks during its pre-training\nby accident.",
    "start": "2861400",
    "end": "2867099"
  },
  {
    "text": "So on this slide, I'm showing\nsome text that appears on websites on the internet.",
    "start": "2867100",
    "end": "2872290"
  },
  {
    "text": "These examples actually all\ncome from a data set called C4. We couldn't perform\nthis analysis on GPT-3's data set because\nit wasn't publicly released.",
    "start": "2872290",
    "end": "2880360"
  },
  {
    "text": "But at any rate,\nthis is text that appeared on websites on the\ninternet at some point in time.",
    "start": "2880360",
    "end": "2886030"
  },
  {
    "text": "GPT-3 was trained on\ntext from the internet. So it's not\nunreasonable to think that GPT-3 might have\nbeen trained on text",
    "start": "2886030",
    "end": "2892330"
  },
  {
    "text": "that looks something like this. So for example, you\ncan see that there's text on the internet that looks\na lot like closed-book question",
    "start": "2892330",
    "end": "2899410"
  },
  {
    "text": "answering, like who\nis Frank Sinatra? An American singer,\nactor, and producer. Paraphrase identification.",
    "start": "2899410",
    "end": "2905140"
  },
  {
    "text": "Someone is asking, do these\nsentences mean the same? And then provides\nthe two sentences. Natural language inference,\nsummarization, and so on.",
    "start": "2905140",
    "end": "2913730"
  },
  {
    "text": "These are all natural-- these are classic NLP tasks\nthat GPT-3 was evaluated on,",
    "start": "2913730",
    "end": "2919900"
  },
  {
    "text": "but this is data that\nappears on the internet. So it seems not unlikely\nthat GPT-3 was actually",
    "start": "2919900",
    "end": "2928360"
  },
  {
    "text": "accidentally trained in a kind\nof supervised multitask way. And that might go some\nways towards explaining",
    "start": "2928360",
    "end": "2936190"
  },
  {
    "text": "why the model can\nperform lots of tasks after unsupervised pre-training.",
    "start": "2936190",
    "end": "2942350"
  },
  {
    "text": "But now, the question\nbecomes, if I just train a model with\nmultitask supervised",
    "start": "2942350",
    "end": "2947800"
  },
  {
    "text": "training intentionally, will\nI get a model that can perform new tasks that it\nhasn't been trained on",
    "start": "2947800",
    "end": "2954310"
  },
  {
    "text": "or that I don't think\nit's been trained on, that generalize the new tasks\nin the meta-learning sense that",
    "start": "2954310",
    "end": "2960309"
  },
  {
    "text": "are unlikely to be\nin the training data? Or at least-- yeah,\nI'll leave it at that.",
    "start": "2960310",
    "end": "2967690"
  },
  {
    "text": "And to try to answer\nthis question, we introduced a new\nmodel called T0. And the basic idea\nhere is just that we're",
    "start": "2967690",
    "end": "2975910"
  },
  {
    "text": "going to take a model\nthat was trained with unsupervised\npre-training, and then we're going to train it explicitly via\nsupervised multitask learning,",
    "start": "2975910",
    "end": "2984460"
  },
  {
    "text": "and then we're\ngoing to evaluate it in terms of its\nzero-shot performance on new tasks that\nweren't included",
    "start": "2984460",
    "end": "2990130"
  },
  {
    "text": "in the intentional multitask\nsupervised training step. And just like with GPT-3,\nwith this zero-shot evaluation",
    "start": "2990130",
    "end": "2998220"
  },
  {
    "text": "paradigm, we're going to\ncast all of these tasks as into what we would\ncall a prompted form.",
    "start": "2998220",
    "end": "3004950"
  },
  {
    "text": "So this is a way of taking\nan example from the data set and mapping it to\nsome input and output",
    "start": "3004950",
    "end": "3010370"
  },
  {
    "text": "text that describe what\nyou want the model to do in human readable text.",
    "start": "3010370",
    "end": "3016230"
  },
  {
    "text": "So for example, for\nparaphrase identification, we feed in the two\nquestions in quotes.",
    "start": "3016230",
    "end": "3022670"
  },
  {
    "text": "And then we say, pick one, these\nquestions are duplicates or not duplicates? So if I presented you\na human with this text,",
    "start": "3022670",
    "end": "3028580"
  },
  {
    "text": "and you spoke English and knew\nhow to identify paraphrases, you would be able to tell me\nthat those two sentences are",
    "start": "3028580",
    "end": "3035840"
  },
  {
    "text": "not duplicates. And so we do the\nsame thing with T0. We map things into\nthis format and we",
    "start": "3035840",
    "end": "3042800"
  },
  {
    "text": "train T0 to output the\ncorresponding text. And then finally, after doing\nthis multitask pre-training",
    "start": "3042800",
    "end": "3049430"
  },
  {
    "text": "or intermediate training\nstep, I should say, we evaluate its performance on\nnew tasks that weren't included",
    "start": "3049430",
    "end": "3055490"
  },
  {
    "text": "in the multitask training step. And just to give you a sense\nof the tasks that we included,",
    "start": "3055490",
    "end": "3063170"
  },
  {
    "text": "here are a-- shown in yellow are the\ntasks that we actually did pre-training on for the--",
    "start": "3063170",
    "end": "3070430"
  },
  {
    "text": "and yellow or\nblue, I should say. And then in green\nare tasks and data sets that we did not\ntrain the model on at all.",
    "start": "3070430",
    "end": "3077850"
  },
  {
    "text": "So those are the\ndata sets and tasks that we're going to be\nevaluating the model's performance on. And you can see that\nwe actually-- we",
    "start": "3077850",
    "end": "3084050"
  },
  {
    "text": "try to get a pretty\ndiverse collection of tasks during pre-training\nwith the thought that that might improve\nthe model's zero-shot task",
    "start": "3084050",
    "end": "3090950"
  },
  {
    "text": "generalization abilities. So the next thing we\nhad to do was actually",
    "start": "3090950",
    "end": "3096349"
  },
  {
    "text": "take data from all\nof these data sets and come up with templates\nthat allow us to map them into a prompted form.",
    "start": "3096350",
    "end": "3102170"
  },
  {
    "text": "So for example, going back\nto the paraphrasing example, you can see in green here, we\nwrite a template that says,",
    "start": "3102170",
    "end": "3109640"
  },
  {
    "text": "take the first question\nand the second question, and then write the text. Pick one of these questions\nthat are duplicates or not",
    "start": "3109640",
    "end": "3114770"
  },
  {
    "text": "duplicates. And then we measure\nwhether the model assigns a higher likelihood to\nduplicates or not duplicates.",
    "start": "3114770",
    "end": "3123839"
  },
  {
    "text": "And you can see that we can\napply this templating procedure to a pretty wide variety\nof tasks and data sets.",
    "start": "3123840",
    "end": "3130530"
  },
  {
    "text": "We actually crowdsource\nthis procedure, found a bunch of people\nwho wanted to contribute, and ended up writing over\nalmost 2,000 templates",
    "start": "3130530",
    "end": "3139800"
  },
  {
    "text": "for almost 200 data sets. So now, the question is,\ndoes T0 outperform GPT-3",
    "start": "3139800",
    "end": "3148330"
  },
  {
    "text": "in terms of zero-shot\ntask generalization? So we looked specifically\nat these four tasks",
    "start": "3148330",
    "end": "3154088"
  },
  {
    "text": "shown on the screen here,\nthat's natural language inference, story\ncompletion, coreference, and word sense disambiguation.",
    "start": "3154088",
    "end": "3160869"
  },
  {
    "text": "And there are two\nmodels shown in green. One model is basically,\nyou could think",
    "start": "3160870",
    "end": "3166690"
  },
  {
    "text": "of as just the base T5 model. And then T0, which\nis the model that had this additional intermediate\nmultitask training step.",
    "start": "3166690",
    "end": "3175480"
  },
  {
    "text": "And first of all, you can\nsee that doing the multitask training greatly improves\nthe model zero-shot task",
    "start": "3175480",
    "end": "3180760"
  },
  {
    "text": "generalization, which\nsuggests that training on this kind of task data does\nimprove the model's ability",
    "start": "3180760",
    "end": "3186430"
  },
  {
    "text": "to perform new tasks. And then interestingly, we also\noutperform GPT-3 on a lot--",
    "start": "3186430",
    "end": "3192670"
  },
  {
    "text": "or matched the performance\non a lot of these tasks. And that includes the\nlargest GPT-3 model with 175 billion\nparameters, which",
    "start": "3192670",
    "end": "3199450"
  },
  {
    "text": "is 16 times larger than T0. So it does seem\nthat actually seeing",
    "start": "3199450",
    "end": "3204640"
  },
  {
    "text": "this supervised multitask\ndata allows the model",
    "start": "3204640",
    "end": "3210099"
  },
  {
    "text": "to perform better generalization\nto new tasks, in many cases,",
    "start": "3210100",
    "end": "3216300"
  },
  {
    "text": "despite being much smaller. So it might be a\nmore efficient way to induce this zero-shot\ngeneralization behavior.",
    "start": "3216300",
    "end": "3222510"
  },
  {
    "text": "And it suggests, to me, at\nleast that it's possible that one of the\nreasons that GPT-3 does",
    "start": "3222510",
    "end": "3227730"
  },
  {
    "text": "zero-shot generalization at\nall is because it actually saw a decent amount of\nsupervised multitask training",
    "start": "3227730",
    "end": "3235770"
  },
  {
    "text": "data during pre-training. We also evaluated the T0\nmodel on this new benchmark",
    "start": "3235770",
    "end": "3244710"
  },
  {
    "text": "called Big Bench. I won't go into a lot of\ndetail on these results, except to say that,\nagain, T0 outperformed",
    "start": "3244710",
    "end": "3249910"
  },
  {
    "text": "kind of standard\nlanguage models that were over six times larger.",
    "start": "3249910",
    "end": "3256130"
  },
  {
    "text": "So just to recap what\nI've described so far, I've sort of argued that\nlanguage modeling effectively",
    "start": "3256130",
    "end": "3262160"
  },
  {
    "text": "results in a meta-learned model\nmaybe because language modeling seems to teach models about\nlanguage, also about world",
    "start": "3262160",
    "end": "3269870"
  },
  {
    "text": "knowledge, and also\nprobably teaches the model explicit\nmultitask supervision",
    "start": "3269870",
    "end": "3275240"
  },
  {
    "text": "for different tasks. And the other thing\nthat I've kind of snuck",
    "start": "3275240",
    "end": "3283250"
  },
  {
    "text": "into this discussion\nis, what happens when we make language models larger? And it seems that larger\nlanguage models actually",
    "start": "3283250",
    "end": "3291950"
  },
  {
    "text": "tend to learn more\nworld knowledge, right, because the larger\nvariance of T5 performed better on the\nclosed-book question answering",
    "start": "3291950",
    "end": "3299000"
  },
  {
    "text": "task. They also seem to learn\nmore esoteric facts, right? Like the larger variant of\nGPT-2 seem to have memorized",
    "start": "3299000",
    "end": "3308060"
  },
  {
    "text": "more data than the\nsmaller variants. And it also seems that\nas models get larger,",
    "start": "3308060",
    "end": "3314400"
  },
  {
    "text": "they learn to do more tasks,\nor at least they perform better in terms of their\nzero-shot performance",
    "start": "3314400",
    "end": "3320480"
  },
  {
    "text": "on downstream tasks. And what I'd like to\nhighlight is that world",
    "start": "3320480",
    "end": "3325720"
  },
  {
    "text": "knowledge, the knowledge\nthat the model picks up, and the esoteric fact\nthat the model learns, and the task that a model\nis actually trained on,",
    "start": "3325720",
    "end": "3334090"
  },
  {
    "text": "these are mostly a\nfunction of the data that the model is trained on. Like if I just take a randomly\ninitialized language model,",
    "start": "3334090",
    "end": "3341650"
  },
  {
    "text": "it's very unlikely\nthat the model is going to be able to tell me\nFranklin D Roosevelt's birth date without any training.",
    "start": "3341650",
    "end": "3347840"
  },
  {
    "text": "So in some way, at\nsome point, there was some data that\ntaught the model when Franklin D\nRoosevelt's birthday was,",
    "start": "3347840",
    "end": "3354550"
  },
  {
    "text": "or what someone's address\nand phone number was, or how to perform\na particular task.",
    "start": "3354550",
    "end": "3360460"
  },
  {
    "text": "I say mostly because, of course,\nthere are lots of other factors here, but the data certainly\nplays a very important factor.",
    "start": "3360460",
    "end": "3368390"
  },
  {
    "text": "So then I guess\none question to ask is, given that larger\nlanguage models perform these capabilities better, how\nlarge do language models need",
    "start": "3368390",
    "end": "3376780"
  },
  {
    "text": "to be in order to achieve\nwhat we want them to? So just to give an example of\nwhat we might want a language",
    "start": "3376780",
    "end": "3383530"
  },
  {
    "text": "model to be able to do. Let's say that we actually\nwant to use a language model as opposed to a question answer.",
    "start": "3383530",
    "end": "3389230"
  },
  {
    "text": "And we want it to be able to\nanswer questions about any data in the Wikidata knowledge graph,\nwhich is a very large knowledge",
    "start": "3389230",
    "end": "3397450"
  },
  {
    "text": "graph with lots of\nknowledge in it. This knowledge graph\ncan be compressed to a file using bzip that\nis about 68 gigabytes.",
    "start": "3397450",
    "end": "3406030"
  },
  {
    "text": "If you imagine that the best\ncase ability of a language model to store knowledge\nin its parameters",
    "start": "3406030",
    "end": "3412720"
  },
  {
    "text": "is about as good as the\ncompression abilities of bzip, 68 gigabytes corresponds\nto about 17 billion",
    "start": "3412720",
    "end": "3419064"
  },
  {
    "text": "float 32 parameters. So this is a large model. It's not gargantuan,\nbut it's quite large.",
    "start": "3419064",
    "end": "3426340"
  },
  {
    "text": "And actually, you might\nnot expect a language model to be able to compress\ndata as well as bzip.",
    "start": "3426340",
    "end": "3432119"
  },
  {
    "text": "I mean, who knows? But at any rate, you do actually\nneed a pretty large model in order to achieve\ncertain goals.",
    "start": "3432120",
    "end": "3439920"
  },
  {
    "text": "Whether you actually\nwant a language model that knows all of this or\nnot is sort of up to you. But at any rate, sometimes a\nscale seems somewhat necessary.",
    "start": "3439920",
    "end": "3449440"
  },
  {
    "text": "The problem with\nscale is that in order to train a large model,\nwe often need to collect",
    "start": "3449440",
    "end": "3455130"
  },
  {
    "text": "lots and lots of data. And it's very hard\nto audit that data. And so as people\nhave figured out--",
    "start": "3455130",
    "end": "3462000"
  },
  {
    "text": "have pointed out rather in, for\nexample, the stochastic parrots papers, that as we amplify\nthe training data, as we make",
    "start": "3462000",
    "end": "3469530"
  },
  {
    "text": "the training data\nbigger and bigger to train these larger\nand larger models, the training data\ncan start to-- it's",
    "start": "3469530",
    "end": "3475799"
  },
  {
    "text": "harder and harder to make\nit so that the training data doesn't have problematic\ncharacteristics. And the training data becomes\nbasically inauditable,",
    "start": "3475800",
    "end": "3483630"
  },
  {
    "text": "which is potentially\ndangerous and problematic for actual real-world uses\nof these language models.",
    "start": "3483630",
    "end": "3490657"
  },
  {
    "text": "And then the last\npoint that I'll make is that people are very excited\nabout large language models these days.",
    "start": "3490657",
    "end": "3495720"
  },
  {
    "text": "And lots of people are training\nthem and releasing products based on them, and\nAPIs based on them.",
    "start": "3495720",
    "end": "3500970"
  },
  {
    "text": "And most of these language\nmodels are, as far as we know, very similar. They're very large\ntransformer-based language",
    "start": "3500970",
    "end": "3507600"
  },
  {
    "text": "models. The main difference\nbetween these models is really just the data that\nthe model is trained on.",
    "start": "3507600",
    "end": "3513540"
  },
  {
    "text": "And indeed, as I\ndescribed earlier, the data is probably\na major, major factor",
    "start": "3513540",
    "end": "3519210"
  },
  {
    "text": "in all of these useful\nabilities that I've described that\nlanguage models have, like their knowledge of facts,\ntheir ability to perform",
    "start": "3519210",
    "end": "3527670"
  },
  {
    "text": "tasks, et cetera. But most of the time people\npay relatively little attention to what data they're actually\ntraining their models on.",
    "start": "3527670",
    "end": "3535080"
  },
  {
    "text": "So I guess this is all to say\nthat thinking more carefully about the data\nthat we're actually",
    "start": "3535080",
    "end": "3540780"
  },
  {
    "text": "using to train these\nlarge language models would probably be\npretty fruitful.",
    "start": "3540780",
    "end": "3546079"
  },
  {
    "text": "So I know I'm just\nabout out of time. I'll end there. And I'd like to\njust mention, I'm",
    "start": "3546080",
    "end": "3551990"
  },
  {
    "text": "trying to collect\nfeedback on my talks. So if you have\nany-- if you think I talk too fast or too slowly,\nor cover too much or too",
    "start": "3551990",
    "end": "3557810"
  },
  {
    "text": "little, or too technical or\nnot technical enough, please go to this URL here and provide\nme with anonymous feedback.",
    "start": "3557810",
    "end": "3563960"
  },
  {
    "text": "I greatly would value it. And I'm happy to take a\ncouple more questions now. ",
    "start": "3563960",
    "end": "3571406"
  },
  {
    "text": "I have one quick question. I mean, thanks a\nlot for the talk. It was just super\ninteresting stuff to see how and when these\nmodels just vacuum up knowledge",
    "start": "3571406",
    "end": "3579819"
  },
  {
    "text": "or when they don't\nfrom their data sets. I'm curious, you talked\nabout this phenomenon",
    "start": "3579820",
    "end": "3585790"
  },
  {
    "text": "where knowledge ends up embedded\nin the models parameters. It's really interesting\nthat this happens. But I'm curious if in practice\nor in future work on modeling",
    "start": "3585790",
    "end": "3593740"
  },
  {
    "text": "that we do, is this, in\nyour opinion, the right way to get knowledge\nrepresented in our models?",
    "start": "3593740",
    "end": "3600760"
  },
  {
    "text": "Or when you see these\nretrieval augmented models or semi-parametric\nmodels, does this",
    "start": "3600760",
    "end": "3605800"
  },
  {
    "text": "feel like the more practical way\nto get this type of behavior?",
    "start": "3605800",
    "end": "3611695"
  },
  {
    "text": "Or how do you sort of\ncontrast these two sort of paradigms of purely\nparametric and having the knowledge\nexplicitly represented?",
    "start": "3611695",
    "end": "3618580"
  },
  {
    "text": "Yeah, so it's not clear to me\nthat purely parametric storage",
    "start": "3618580",
    "end": "3624820"
  },
  {
    "text": "of knowledge is the most\nefficient or exact way to do it. And certainly, it has\nvarious disadvantages.",
    "start": "3624820",
    "end": "3630940"
  },
  {
    "text": "Like there's been a lot of good\nand interesting work on this, but it's still not totally clear\nhow to selectively add, update,",
    "start": "3630940",
    "end": "3638359"
  },
  {
    "text": "or remove knowledge in this\nkind of distributed parameter",
    "start": "3638360",
    "end": "3643780"
  },
  {
    "text": "representation. So I would definitely hesitate\nto say that one approach was",
    "start": "3643780",
    "end": "3650680"
  },
  {
    "text": "better or worse. The main benefit of building\nup knowledge in this way",
    "start": "3650680",
    "end": "3656859"
  },
  {
    "text": "is that it requires\nbasically no-- ",
    "start": "3656860",
    "end": "3662619"
  },
  {
    "text": "it basically requires that you\ncollect a lot of unlabeled text data and apply self-supervised\nobjective to it.",
    "start": "3662620",
    "end": "3671950"
  },
  {
    "text": "It's much less cost\nintensive and labor intensive to do that than build\na knowledge graph or build a very clean\ncollection of knowledge.",
    "start": "3671950",
    "end": "3679990"
  },
  {
    "text": "Of course, it also carries\nits own risks and problems like I highlighted at\nthe end of the talk. So I guess that's a very long\nway of saying that I definitely",
    "start": "3679990",
    "end": "3689079"
  },
  {
    "text": "could see both of\nthese approaches having advantages and disadvantages\nin certain situations.",
    "start": "3689080",
    "end": "3695140"
  },
  {
    "text": " We have this one\nquestion in the chat. What do you think will drive\nfuture progress in language",
    "start": "3695140",
    "end": "3702320"
  },
  {
    "text": "models-- model scale. Do you think grounded language\nlearning is promising?",
    "start": "3702320",
    "end": "3708579"
  },
  {
    "text": "Yeah, so you might have gathered\nfrom the end of the talk that actually I think we will-- a lot of progress can and should\nbe made with large language",
    "start": "3708580",
    "end": "3717280"
  },
  {
    "text": "models by being more\ncareful about the data that we train them on. For example, you can\nthink of T0 as just",
    "start": "3717280",
    "end": "3722765"
  },
  {
    "text": "being a lot more\ncareful about the data that we train the model on. And we ended up with a model\nthat was 16 times smaller,",
    "start": "3722765",
    "end": "3728109"
  },
  {
    "text": "but worked about as well or\nbetter than GPT-3 in many cases because we were\nintentionally doing",
    "start": "3728110",
    "end": "3733480"
  },
  {
    "text": "multitask learning instead\nof doing it by accident. Grounded language\nlearning, to me,",
    "start": "3733480",
    "end": "3739359"
  },
  {
    "text": "feels like definitely a way to\nteach the model things that it",
    "start": "3739360",
    "end": "3744640"
  },
  {
    "text": "would be practical or\nimpossible to provide the model with via text alone.",
    "start": "3744640",
    "end": "3751600"
  },
  {
    "text": "We wouldn't necessarily expect\nit to be efficient or easy for a model to learn everything\nthere is about the world",
    "start": "3751600",
    "end": "3757870"
  },
  {
    "text": "just by reading and\nreading lots of texts. I'm not saying that\nit's impossible. It might just be less efficient.",
    "start": "3757870",
    "end": "3764890"
  },
  {
    "text": "And an efficiency\ndoes matter a lot. So all that is to say that I\nagree that grounded language",
    "start": "3764890",
    "end": "3777680"
  },
  {
    "text": "learning would be\nuseful, but there are lots of other useful\nthings that we can do too.",
    "start": "3777680",
    "end": "3784537"
  },
  {
    "text": "How can the multitask\ndemonstrations be extended to under-resourced\nlanguages on the web?",
    "start": "3784538",
    "end": "3792109"
  },
  {
    "text": "So we haven't-- so there's\nbeen a parallel line of work measuring the zero or few-shot\ntransferability across",
    "start": "3792110",
    "end": "3799970"
  },
  {
    "text": "languages. That's not something that we\nspecifically have studied. Although I think it's\nsuper interesting.",
    "start": "3799970",
    "end": "3806089"
  },
  {
    "text": "I think combining some\nof these approaches to doing zero-shot task\ngeneralization with approaches",
    "start": "3806090",
    "end": "3812359"
  },
  {
    "text": "for doing few or zero-shot\nlanguage generalization would be super interesting.",
    "start": "3812360",
    "end": "3817624"
  },
  {
    "text": " Great. I guess, if there are no more\nquestions, we can end there.",
    "start": "3817624",
    "end": "3824070"
  },
  {
    "text": "I know people are trying\nto run, and commonly are extremely busy. So thank you so much just\nfor sharing that hour",
    "start": "3824070",
    "end": "3830550"
  },
  {
    "text": "and change with us. It was packed with knowledge. Thanks a lot.",
    "start": "3830550",
    "end": "3836100"
  },
  {
    "text": "And I usually say at\nthe end of the talk, people can feel\nfree to email me too with any additional\nfollow-up questions.",
    "start": "3836100",
    "end": "3842840"
  },
  {
    "text": "And I did-- I dropped\nthe link to the talk feedback in the chat in case\nanyone wants to do that. But thanks again for having me.",
    "start": "3842840",
    "end": "3849130"
  },
  {
    "text": "It's really fun. ",
    "start": "3849130",
    "end": "3856000"
  }
]
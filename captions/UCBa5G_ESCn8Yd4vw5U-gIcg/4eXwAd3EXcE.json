[
  {
    "start": "0",
    "end": "9870"
  },
  {
    "text": "So it's really nice to be here. It has been a while since\nI've given a lecture since I moved to NVIDIA two\nyears ago, but I",
    "start": "9870",
    "end": "15960"
  },
  {
    "text": "hope I haven't lost my touch. So today I was\nthinking like what to present because this is in\nthe end, a robotics seminar",
    "start": "15960",
    "end": "22950"
  },
  {
    "text": "and I'm not a\nroboticist, so we are working in perception mostly. So I was thinking about bringing\na little bit of the work that",
    "start": "22950",
    "end": "30600"
  },
  {
    "text": "we're doing in segmentation and\ntracking and especially focusing in the work that\nwe're doing in 3D.",
    "start": "30600",
    "end": "37050"
  },
  {
    "text": "So there's two keywords in the\ntitle that I want to highlight. One is the fact\nthat we are going",
    "start": "37050",
    "end": "42330"
  },
  {
    "text": "to be working in an open\nworld vocabulary fashion. So we don't want to be\nsegmenting and tracking",
    "start": "42330",
    "end": "49440"
  },
  {
    "text": "cars or people. We want to really literally\nfind any object that we can find",
    "start": "49440",
    "end": "55320"
  },
  {
    "text": "in the scene and we\nwant to do this in 3D. So let's see how we\nwould go about this.",
    "start": "55320",
    "end": "60629"
  },
  {
    "text": "Well, first of all,\nwhy do we need this? I think I don't need to\nexplain to anyone how embodied",
    "start": "60630",
    "end": "68520"
  },
  {
    "text": "autonomous agents work. But some of the work that\nwe're doing in my group is around these\nthree pillars, which",
    "start": "68520",
    "end": "76330"
  },
  {
    "text": "are key towards enabling\nautonomous agents. One is perception, to understand\nwhat is around the robot.",
    "start": "76330",
    "end": "84100"
  },
  {
    "text": "The second one, and perhaps\nthis is the most important one is how do objects\nmove around the robot.",
    "start": "84100",
    "end": "90950"
  },
  {
    "text": "And again, here, not focusing\nonly on cars and pedestrians for autonomous\nscene, but any object",
    "start": "90950",
    "end": "96580"
  },
  {
    "text": "that can move in the scene. And the third one is\nessentially localization.",
    "start": "96580",
    "end": "102009"
  },
  {
    "text": "So you want to be able\nto localize yourself even in scenarios where you have a\nlot of repetitive structures,",
    "start": "102010",
    "end": "108260"
  },
  {
    "text": "where you have very similar\nfeatures all around. And this is kind of also\nsomething that we're working on.",
    "start": "108260",
    "end": "115570"
  },
  {
    "text": "Now for the purpose\nof this talk, I will focus more on\nthe perception side and on the tracking\nside, and I will not",
    "start": "115570",
    "end": "121359"
  },
  {
    "text": "talk about the\nlocalization work, but I'm happy also to\ndiscuss this after the talk.",
    "start": "121360",
    "end": "128259"
  },
  {
    "text": "So if I had to\nsummarize this talk and let's say the work that\nwe're doing in my group",
    "start": "128259",
    "end": "135610"
  },
  {
    "text": "with one sentence, it would be\ndynamic scene understanding. So we want to understand\nthe scene around us",
    "start": "135610",
    "end": "141319"
  },
  {
    "text": "and we want to pay\nspecial attention into how objects are moving. Now, if we would go about this\nin a classic machine learning",
    "start": "141320",
    "end": "149590"
  },
  {
    "text": "way, we would say,\nwell, on the one hand, we have several tasks--",
    "start": "149590",
    "end": "154900"
  },
  {
    "text": "and I'm going to frame the\ntask from easy at the bottom to more complex at the top.",
    "start": "154900",
    "end": "160040"
  },
  {
    "text": "And then we have on the\nx-axis, the number of classes. So we can start with\na few classes, which",
    "start": "160040",
    "end": "165790"
  },
  {
    "text": "I will put on the left all\nthe way to open world, which is where we want to go.",
    "start": "165790",
    "end": "171970"
  },
  {
    "text": "So let's start with one basic\ntask, semantic segmentation. So this is the task of actually\nassigning a semantic class",
    "start": "171970",
    "end": "178120"
  },
  {
    "text": "to each pixel. And we can do this\nin a supervised way",
    "start": "178120",
    "end": "184150"
  },
  {
    "text": "for a handful of classes. So there's tons of\ndata sets out there with people, trees, cars, road.",
    "start": "184150",
    "end": "191450"
  },
  {
    "text": "All these elements that are\ncrucial for autonomous driving, we have good data\nsets for those.",
    "start": "191450",
    "end": "197650"
  },
  {
    "text": "And we can train a model\nin a supervised fashion. It works pretty well. That, I would say, is\nnot really a problem",
    "start": "197650",
    "end": "204250"
  },
  {
    "text": "that we need to solve nowadays. We can even scale up\nto thousands of classes",
    "start": "204250",
    "end": "210220"
  },
  {
    "text": "if you want. So there's the Elvis data\nset, tons of data sets that are focusing on\nexpanding these vocabulary.",
    "start": "210220",
    "end": "217480"
  },
  {
    "text": "And you can still do this\nin a supervised fashion. Let's start looking\nat the task axis.",
    "start": "217480",
    "end": "224160"
  },
  {
    "text": "So if we want to increase a\nlittle bit the complexity, if we want to have a deeper\nunderstanding of the scene,",
    "start": "224160",
    "end": "230530"
  },
  {
    "text": "we need to have not only\nsemantic segmentation, but we actually need to go\ntowards panoptic segmentation.",
    "start": "230530",
    "end": "237810"
  },
  {
    "text": "And for this, I actually\nmean not only saying, hey, all these red pixels\nbelong to the class person,",
    "start": "237810",
    "end": "243610"
  },
  {
    "text": "but actually identify the\ndifferent people in the scene. And again, for a handful or--",
    "start": "243610",
    "end": "250849"
  },
  {
    "text": "not thousands, but maybe\nhundreds of classes, there's data sets for that.",
    "start": "250850",
    "end": "256320"
  },
  {
    "text": "Let's just now add\nthe temporal domain. Now you want to basically\nsegment and add a semantic label",
    "start": "256320",
    "end": "264210"
  },
  {
    "text": "to each of the pixels. You want to identify\ninstances and you want to track those\ninstances in time,",
    "start": "264210",
    "end": "269740"
  },
  {
    "text": "which means that you want\nto have the same ID for all the frames where you're\nactually observing that object.",
    "start": "269740",
    "end": "276210"
  },
  {
    "text": "And I would argue\nthat tracking is easy if the object is\nnice and visible.",
    "start": "276210",
    "end": "281800"
  },
  {
    "text": "It starts to be complicated\nin crowded scenes, for example, when objects\ninteract with each other,",
    "start": "281800",
    "end": "287670"
  },
  {
    "text": "there's lots of\nocclusions, there's lots of similar appearances. This is where things\nget really interesting.",
    "start": "287670",
    "end": "293850"
  },
  {
    "text": "Now, for a handful of objects,\nlike especially pedestrians",
    "start": "293850",
    "end": "299040"
  },
  {
    "text": "and cars, there's\ntons of data sets. It's doable to train a model\nin a supervised fashion.",
    "start": "299040",
    "end": "305710"
  },
  {
    "text": "It works relatively well. I think this it's a problem\nthat we know how to handle.",
    "start": "305710",
    "end": "310770"
  },
  {
    "text": "When we talk about\nthousand of classes, this is a different story.",
    "start": "310770",
    "end": "316150"
  },
  {
    "text": "But what we really want to\nget to is lifting, again, to another dimension and\nthis is the 3D dimension.",
    "start": "316150",
    "end": "324070"
  },
  {
    "text": "And this is where there's\nnot many works that are working in this domain.",
    "start": "324070",
    "end": "329460"
  },
  {
    "text": "So a lot of works that do\ntracking or segmentation stay in the 2D domain. But if we really want our\nautonomous agents to understand",
    "start": "329460",
    "end": "337320"
  },
  {
    "text": "the surroundings--\nthese are in 3D, right? And I would even argue that\nwe have 4D because we have",
    "start": "337320",
    "end": "342840"
  },
  {
    "text": "the temporal domain. So essentially, what you want\nis you want to have 4D dynamics",
    "start": "342840",
    "end": "348270"
  },
  {
    "text": "in understanding. Now what happens is that the\ndata sets for these kind of data",
    "start": "348270",
    "end": "355820"
  },
  {
    "text": "here-- I'm just showing some\npreliminary results that we had with our method.",
    "start": "355820",
    "end": "360840"
  },
  {
    "text": "And these are projected\nonto a lidar point cloud. So what we're seeing here\nis a car driving around",
    "start": "360840",
    "end": "366750"
  },
  {
    "text": "and it's sensing different\ninstances of different objects. We have traffic lights,\nwe have the street car,",
    "start": "366750",
    "end": "373060"
  },
  {
    "text": "we have the road. And these all need\nto be segmented. These all need to be tracked.",
    "start": "373060",
    "end": "378670"
  },
  {
    "text": "Now, ideally, what\nwe would want is we would move to the\nextreme of this axis.",
    "start": "378670",
    "end": "385840"
  },
  {
    "text": "We would like to have 4D\npanoptic segmentation, and we would like to have\nthis in the open world.",
    "start": "385840",
    "end": "391210"
  },
  {
    "text": "So you can imagine that doing\nthis in a supervised way is completely not feasible. ",
    "start": "391210",
    "end": "398760"
  },
  {
    "text": "So again, for semantic\nand panoptic segmentation, how the community went about\nit is, until 1,000 classes--",
    "start": "398760",
    "end": "405940"
  },
  {
    "text": "let's get some data. For semantic segmentation,\nit's possible. For panoptic, hundreds of\nclasses, it's still possible.",
    "start": "405940",
    "end": "413850"
  },
  {
    "text": "For tracking, we did\npretty much the same. Let's get some more data. So I know quite a lot about\nthis because my postdoc",
    "start": "413850",
    "end": "421949"
  },
  {
    "text": "was spent annotating bounding\nboxes for more challenge. So this was fun.",
    "start": "421950",
    "end": "427170"
  },
  {
    "text": "One thing about\nannotating videos is that it's very repetitive.",
    "start": "427170",
    "end": "432449"
  },
  {
    "text": "And what I mean is\nthat, for example, tracking one person means\nannotating the same person",
    "start": "432450",
    "end": "438120"
  },
  {
    "text": "for 1,000 frames. The appearance of this object\nis the same for 1,000 frames,",
    "start": "438120",
    "end": "444360"
  },
  {
    "text": "which means that the viability\nthat you get when annotating these thousands frames in the\nappearance axis is basically",
    "start": "444360",
    "end": "451530"
  },
  {
    "text": "nothing. So if you want to\nget varied appearance and you want to get\nvaried motions--",
    "start": "451530",
    "end": "459130"
  },
  {
    "text": "it quickly explodes how much\ndata you have to annotate. So annotating videos\nis really not the same",
    "start": "459130",
    "end": "464410"
  },
  {
    "text": "as annotating images.  Yeah. So this was\nbasically my postdoc.",
    "start": "464410",
    "end": "471379"
  },
  {
    "text": "We had to annotate\nhundreds similar frames. We had some techniques\nto actually alleviate a little bit the pain.",
    "start": "471380",
    "end": "477850"
  },
  {
    "text": "And I'm also happy to\ndiscuss this offline. But I think it was\nstill quite a lot of manual work for\nthe amount of benefit",
    "start": "477850",
    "end": "484990"
  },
  {
    "text": "that we got from the data. But if the real world is going\nto be in 4D and it's going to be",
    "start": "484990",
    "end": "493270"
  },
  {
    "text": "open world, it starts to be hard\nto think that we can actually collect this amount of data.",
    "start": "493270",
    "end": "500009"
  },
  {
    "text": "There is just no way. So what I'm going\nto propose to do and what I'm going to\npresent in this work",
    "start": "500010",
    "end": "506289"
  },
  {
    "text": "is a couple of works\nthat say, well, let's not really throw\naway all the data",
    "start": "506290",
    "end": "511300"
  },
  {
    "text": "that we have already annotated. Let's actually use it and let's\ntry to create some of pseudo",
    "start": "511300",
    "end": "517210"
  },
  {
    "text": "labels for our problem, which is\nin 4D and which is open world.",
    "start": "517210",
    "end": "523299"
  },
  {
    "text": "So I'm going to focus on\ncreating 3D and in particular, lidar pseudo labels.",
    "start": "523299",
    "end": "530130"
  },
  {
    "text": "And I'm going to\npresent two methods. The first one is looking at\nthe appearance of the objects.",
    "start": "530130",
    "end": "535769"
  },
  {
    "text": "The second one is\nlooking at the motion. And they serve two\npurposes, as I will explain.",
    "start": "535770",
    "end": "540950"
  },
  {
    "text": "So looking at appearance,\nI'm going to present our work segment, anything in lidar,\nwhich is going to be about",
    "start": "540950",
    "end": "547519"
  },
  {
    "text": "localizing objects in 3D,\nassigning a semantic meaning to them. And the main takeaway\nthere is going",
    "start": "547520",
    "end": "554449"
  },
  {
    "text": "to be how to leverage\nvision foundation models. When we're looking at\nthe motion, what we're",
    "start": "554450",
    "end": "561200"
  },
  {
    "text": "going to want to do is\nforget about the semantics and just say, let's try to\nfind points that move together",
    "start": "561200",
    "end": "569630"
  },
  {
    "text": "and let's try to cluster\nobjects based on motion. Kind of the classic\nmotion clustering.",
    "start": "569630",
    "end": "575700"
  },
  {
    "text": "Very similar idea but\nin a learned fashion. So let's start\nwith the first one.",
    "start": "575700",
    "end": "582950"
  },
  {
    "text": "So this is a little bit of\na video demo that we have.",
    "start": "582950",
    "end": "587990"
  },
  {
    "text": "And I actually have\nan interactive demo later so you can-- you'll be able to\ngive me any prompt",
    "start": "587990",
    "end": "593990"
  },
  {
    "text": "that you want to\nbreak the system. But in here, what I'm showing\nis in blue, the trash cans",
    "start": "593990",
    "end": "600290"
  },
  {
    "text": "and in yellow,\nthe fire hydrants. So the question\nis like, how many",
    "start": "600290",
    "end": "606170"
  },
  {
    "text": "fire hydrants and\ntrash cans are you going to see in\nyour training data? Just a handful, right?",
    "start": "606170",
    "end": "611952"
  },
  {
    "text": "So it's impossible to train\na supervised method that works with this\naccuracy for example,",
    "start": "611952",
    "end": "619080"
  },
  {
    "text": "for these objects of trash\ncans and fire hydrants. I think we saw two fire\nhydrants in the whole data set.",
    "start": "619080",
    "end": "625279"
  },
  {
    "text": "And we're still\nable to capture them in the validation sequences.",
    "start": "625280",
    "end": "631870"
  },
  {
    "text": "So how does this model work? So it's sort of a way, let's\nsay towards a lidar foundation",
    "start": "631870",
    "end": "639180"
  },
  {
    "text": "model. I would still not call it\na lighter foundation model, but let's say laying\nthe groundwork for that.",
    "start": "639180",
    "end": "644860"
  },
  {
    "text": "And the idea is that you want\nto take your lidar point cloud and you want to take your\ntext prompts like what do you",
    "start": "644860",
    "end": "651970"
  },
  {
    "text": "want to detect from the scene? The fire hydrants,\ntrash cans or even common objects like\ncars or persons.",
    "start": "651970",
    "end": "658960"
  },
  {
    "text": "You want to pass them\nonto our cell model. And this will give you\ninstances semantics.",
    "start": "658960",
    "end": "664840"
  },
  {
    "text": "So basically, you want to\nsegment and classify any object. And again, here we're talking\nabout panoptic segmentation.",
    "start": "664840",
    "end": "671019"
  },
  {
    "text": "The instance part\nis very important. Now, again, we could go about\nthis by manually annotating",
    "start": "671020",
    "end": "678230"
  },
  {
    "text": "large scale data in 3D. This is absolutely painful. I think inside NVIDIA, we have\na few annotated sequences.",
    "start": "678230",
    "end": "686100"
  },
  {
    "text": "And this was completely\npainful to obtain. So this is really not scalable.",
    "start": "686100",
    "end": "691490"
  },
  {
    "text": "So what we said is, OK, let's\ntry to benefit from existing 2D annotations, from existing 2D\nmodels and let's see how we can",
    "start": "691490",
    "end": "699110"
  },
  {
    "text": "bring them to 3D. So SAL is maybe two\nconcepts, I would say.",
    "start": "699110",
    "end": "706440"
  },
  {
    "text": "So SAL is a pseudo label\nengine and it's also a model. So at train time, we're going to\nhave unlabeled camera and lidar",
    "start": "706440",
    "end": "715279"
  },
  {
    "text": "data, which is nice\nand calibrated. This is going to be passed\non to a pseudo label engine.",
    "start": "715280",
    "end": "722040"
  },
  {
    "text": "And this is going to work\nwith two foundation models. It's going to work\nwith SAM, which is going to give you\nthe segmentations,",
    "start": "722040",
    "end": "728990"
  },
  {
    "text": "and it's going to work\nwith CLIP, which is going to give you the semantics. Now, again, these foundation\nmodels, they don't work in 3D.",
    "start": "728990",
    "end": "736690"
  },
  {
    "text": "There's some 3D clips and so\non, but these are 2D vision foundation models.",
    "start": "736690",
    "end": "742509"
  },
  {
    "text": "And the question is, how do\nI distill this information and create pseudo labels so that\nthen I can train a SAL model?",
    "start": "742510",
    "end": "752670"
  },
  {
    "text": "So the pseudo label engine\nis going to transfer these 2D vision foundation model\ninformation to 3D labels,",
    "start": "752670",
    "end": "760090"
  },
  {
    "text": "and then the SAL model is going\nto able to perform zero shot segmentation via text prompting.",
    "start": "760090",
    "end": "766510"
  },
  {
    "text": "And the zero shot\nsegmentation is only going to happen in\nthe lidar domain. So at test time, we don't\nreally need the images.",
    "start": "766510",
    "end": "773645"
  },
  {
    "text": " So let me just briefly\ntalk about the SAL model.",
    "start": "773645",
    "end": "779750"
  },
  {
    "text": "It's really nothing fancy. So it's going to take a lidar\npoint cloud and text prompts.",
    "start": "779750",
    "end": "785800"
  },
  {
    "text": "As a model, we're going to have\nclass agnostic segmentation in a mask to former kind of way\nin which you have your backbone,",
    "start": "785800",
    "end": "795620"
  },
  {
    "text": "you process your\nlighter point cloud. And you have your\ntransformer decoder, which takes a set\nof object queries",
    "start": "795620",
    "end": "802029"
  },
  {
    "text": "and decodes them into\nthe actual instances. So you're going to have\nthe mask and you're going",
    "start": "802030",
    "end": "807520"
  },
  {
    "text": "to have an objectness value. The architecture\nis pretty simple. There's nothing\nfancy about that.",
    "start": "807520",
    "end": "813790"
  },
  {
    "text": "What we're going to add in order\nto make our model profitable is we're going to predict\nalso from our object queries,",
    "start": "813790",
    "end": "822160"
  },
  {
    "text": "a clip token. And this clip token is going to\nbe aligned with the embedding",
    "start": "822160",
    "end": "828310"
  },
  {
    "text": "that we will obtain from\nthe actual text prompts. So here, basically how I'm\ntraining this is I say,",
    "start": "828310",
    "end": "834970"
  },
  {
    "text": "if I segment a mask of a\ncar, I want the CLIP token",
    "start": "834970",
    "end": "840439"
  },
  {
    "text": "to be very aligned\nto the embedding that I obtained with CLIP\nfrom the actual world car.",
    "start": "840440",
    "end": "847280"
  },
  {
    "text": "So this is a way to\nbring CLIP to 3D, right? Because now what I'm doing\nis I'm pairing 3D masks with",
    "start": "847280",
    "end": "855500"
  },
  {
    "text": "my CLIP token. And with this, I can then\ndo zero shot classification. So imagine at test time, I type\nthe word car, I obtain my clip",
    "start": "855500",
    "end": "864430"
  },
  {
    "text": "embedding and I look at all\nthe masks that align well with that clip embedding.",
    "start": "864430",
    "end": "871470"
  },
  {
    "text": "Now the question is, OK, how do\nyou actually train this model? How do you actually obtain\nlabels to train this model?",
    "start": "871470",
    "end": "877630"
  },
  {
    "text": "This is a fully\nsupervised model. We do need some\nlabels to train that.",
    "start": "877630",
    "end": "882899"
  },
  {
    "text": "Now, this is where the\npseudo label engine comes in. So here you see the\ninput that we have.",
    "start": "882900",
    "end": "890070"
  },
  {
    "text": "At train time, we\ndo need images. We do need to distill these\n2D information coming from",
    "start": "890070",
    "end": "895530"
  },
  {
    "text": "foundation models. So we have these kind of\nimages that are looking around the lidar point cloud.",
    "start": "895530",
    "end": "901750"
  },
  {
    "text": "We also have the lidar data. They do need to be calibrated\nbecause what we're going to do",
    "start": "901750",
    "end": "907770"
  },
  {
    "text": "is we're going to apply\na SAM onto our image, and then we're going to\nunproject the information",
    "start": "907770",
    "end": "915780"
  },
  {
    "text": "into 3D. So this is why I say that\ncalibration is important. I think public data sets are\nrelatively well calibrated.",
    "start": "915780",
    "end": "924760"
  },
  {
    "text": "But if you've ever worked\nwith lidar and cameras, they don't have\nthe same viewpoint.",
    "start": "924760",
    "end": "931340"
  },
  {
    "text": "So usually the lidar is\na little bit higher up. It can look behind an object\nwhich the image doesn't see,",
    "start": "931340",
    "end": "938240"
  },
  {
    "text": "and this creates tons\nof problems in 3D. So what we have then is also\nwe pass the masks in 2D through",
    "start": "938240",
    "end": "949660"
  },
  {
    "text": "CLIP to obtain the embeddings. This is just classic mask CLIP.",
    "start": "949660",
    "end": "954710"
  },
  {
    "text": "There's also\nnothing fancy there. So now what we have implicitly\nis we have correspondences",
    "start": "954710",
    "end": "960940"
  },
  {
    "text": "between 3D masks because the 2D\nmasks have been projected to 3D. We know the ID and we know what\nis their corresponding CLIP",
    "start": "960940",
    "end": "968800"
  },
  {
    "text": "embedding. So this is all the\ndata that we need to train our model in\na supervised fashion.",
    "start": "968800",
    "end": "974430"
  },
  {
    "text": " Now, the pseudo label engine\nis not just an projection.",
    "start": "974430",
    "end": "981529"
  },
  {
    "text": "So as I said, there's tons of\nproblems when you just naively unproject. There's tons of\nbleeding effects.",
    "start": "981530",
    "end": "988930"
  },
  {
    "text": "Usually, since the lidar, as I\nsaid, is a little bit higher up, you get all these points that\nare suddenly-- for example,",
    "start": "988930",
    "end": "997100"
  },
  {
    "text": "the car points are\nsuddenly passed through a line in the\nbackground, which goes up",
    "start": "997100",
    "end": "1003630"
  },
  {
    "text": "to whatever, 10 meters\nor whatever that is in your units of measurements.",
    "start": "1003630",
    "end": "1009510"
  },
  {
    "text": "So it's really a mess. If you look at\nthat unprojection, it's really a mess. So what we have to do is we\nhave to combine the notion",
    "start": "1009510",
    "end": "1019290"
  },
  {
    "text": "of segmentations that we\ngathered from 2D with 3D clusters by looking at\nthe actual point cloud,",
    "start": "1019290",
    "end": "1027010"
  },
  {
    "text": "by looking at the\nactual 3D clusters. So what we do is\nwe apply DBSCAN--",
    "start": "1027010",
    "end": "1033839"
  },
  {
    "text": "super standard technique\nfor point clustering based on relative distances.",
    "start": "1033839",
    "end": "1039970"
  },
  {
    "text": "You can put tons of\ninformation in there. You could even have a\nlearned version for DBSCAN.",
    "start": "1039970",
    "end": "1046510"
  },
  {
    "text": "But I guess the\nidea is that we want to clean a little bit these\nbleeding effects by saying,",
    "start": "1046510",
    "end": "1053090"
  },
  {
    "text": "look, it makes no\nsense that there's a car 10 meters\naway from the car onto a flat surface, which\nis potentially a building.",
    "start": "1053090",
    "end": "1061370"
  },
  {
    "text": "So this is what\nDBSCAN can nicely do. So here you can see some of the\nresults of the effect of DBSCAN.",
    "start": "1061370",
    "end": "1070580"
  },
  {
    "text": "For example, the bushes\nare nicely segmented. The car has less noise. The car in the background\nalso has less noise.",
    "start": "1070580",
    "end": "1079160"
  },
  {
    "text": "So I think overall, this\nis an important step. And many of the papers that\nare actually working in 3D,",
    "start": "1079160",
    "end": "1088370"
  },
  {
    "text": "mostly indoor scenes that use\nthis idea of distilling 2D",
    "start": "1088370",
    "end": "1094520"
  },
  {
    "text": "vision foundation\nmodels information, projecting them onto 3D,\nthey usually stop here.",
    "start": "1094520",
    "end": "1100530"
  },
  {
    "text": "They usually say, now I\nhave my information in 3D, that's all I need, right?",
    "start": "1100530",
    "end": "1105860"
  },
  {
    "text": "We actually found is\nthat actually training the model on top improves\nthings quite a lot.",
    "start": "1105860",
    "end": "1113330"
  },
  {
    "text": "So here I'm just plotting a\nlittle bit of the results. Like in the first\ntwo rows, I'm going",
    "start": "1113330",
    "end": "1120350"
  },
  {
    "text": "to have just the\nunprojected SAM masks. In the next two rows,\nwhat you see SAM plus DBs,",
    "start": "1120350",
    "end": "1127190"
  },
  {
    "text": "this is the DB scan\nwhich improves things. If we're talking about the\nfirst column of results, PQ,",
    "start": "1127190",
    "end": "1136020"
  },
  {
    "text": "which is the standard\nsegmentation metric, you're going to go more\nor less from 42 to 48.",
    "start": "1136020",
    "end": "1144060"
  },
  {
    "text": "But here's the interesting\nthing, when I actually trained the model on\nthese pseudo labels,",
    "start": "1144060",
    "end": "1149410"
  },
  {
    "text": "suddenly my PQ goes up to 70. And I think this is\nthe key learning here.",
    "start": "1149410",
    "end": "1155880"
  },
  {
    "text": "These are completely free\npseudo labels, right? But they are very noisy.",
    "start": "1155880",
    "end": "1160950"
  },
  {
    "text": "The thing is that if I'm\nlooking at a lot of data-- so I have a lot of pseudo\nlabels and they are noisy",
    "start": "1160950",
    "end": "1168060"
  },
  {
    "text": "and I train a model on\ntop, the model kind of learns to collect the\nsignal, the good signal",
    "start": "1168060",
    "end": "1173940"
  },
  {
    "text": "from these noisy data. There is no way that I\ncould get to a 70 accuracy just with pseudo labels.",
    "start": "1173940",
    "end": "1180690"
  },
  {
    "text": "But the model is able to distill\nthis data from the three pseudo labels that I have\njust obtained.",
    "start": "1180690",
    "end": "1187500"
  },
  {
    "text": "So I think this is one crucial\ncontribution of our work was to say, let's actually train\na model on top of these labels.",
    "start": "1187500",
    "end": "1196149"
  },
  {
    "text": "Let's not just use\nthem as predictions, but these have to\nbe pseudo labels. ",
    "start": "1196150",
    "end": "1203950"
  },
  {
    "text": "Another thing that\nI wanted to focus on is the evaluation between\nsegmentation and semantics.",
    "start": "1203950",
    "end": "1213580"
  },
  {
    "text": "So here is something that we\nfound very interesting actually, and that is that if we actually\nevaluate only for class",
    "start": "1213580",
    "end": "1222940"
  },
  {
    "text": "agnostic segmentation, meaning\nthat I have a semantic Oracle, right? So I forget about\nthe CLIP tokens",
    "start": "1222940",
    "end": "1228880"
  },
  {
    "text": "and whenever I have a mask-- a mask of a car, for example,\nI look at my ground truth",
    "start": "1228880",
    "end": "1235540"
  },
  {
    "text": "and I take the actual\nground truth semantics. So at the top, all\nof these results",
    "start": "1235540",
    "end": "1241270"
  },
  {
    "text": "are without the CLIP tokens. And so you can see\nthat when we actually",
    "start": "1241270",
    "end": "1246669"
  },
  {
    "text": "have the CLIP tokens,\nwhich are these rows here, the accuracy\nsuffers quite a lot.",
    "start": "1246670",
    "end": "1253210"
  },
  {
    "text": "And this basically means that\nwe can actually do segmentation pretty well in 3D\nwithout any labels.",
    "start": "1253210",
    "end": "1261740"
  },
  {
    "text": "When we're looking\nat semantics, we're really lacking behind\na supervised model.",
    "start": "1261740",
    "end": "1269840"
  },
  {
    "text": "Now, this finding\nis not really new. This finding is similar to\nwhat we have seen in 2D with 2D",
    "start": "1269840",
    "end": "1276530"
  },
  {
    "text": "and supervised models. And I think this\njust means that we're going to have to take the\nlocalization aspect of SAL",
    "start": "1276530",
    "end": "1284570"
  },
  {
    "text": "and really use it, but the whole\nsemantic part is maybe something that we will do\nwith another method,",
    "start": "1284570",
    "end": "1289770"
  },
  {
    "text": "with some retrieval method\nwith enhanced features and so on because we really\nnot at the stage where",
    "start": "1289770",
    "end": "1297860"
  },
  {
    "text": "we can actually use this by\njust using the CLIP features. ",
    "start": "1297860",
    "end": "1303290"
  },
  {
    "text": "OK. How this all works. So here I have a demo. This is still the video.",
    "start": "1303290",
    "end": "1310230"
  },
  {
    "text": "So these are just instances. They're not connected in time. So these are just single\nframe predictions.",
    "start": "1310230",
    "end": "1316740"
  },
  {
    "text": "But we can already start\nseeing some interesting things. So for example, we have\nthese traffic signs in blue.",
    "start": "1316740",
    "end": "1323580"
  },
  {
    "text": "We have the street\ncard, which is in brown. We also have the cars in brown.",
    "start": "1323580",
    "end": "1329760"
  },
  {
    "text": "We have three segmented\nseparately from buildings. So you can see\nthat SAL is really",
    "start": "1329760",
    "end": "1335730"
  },
  {
    "text": "starting to understand\nquite a lot the context and really segmenting each\nof these objects separately.",
    "start": "1335730",
    "end": "1343690"
  },
  {
    "text": " OK. Before I go to 4D, I do\nwant to do the live demo,",
    "start": "1343690",
    "end": "1351530"
  },
  {
    "text": "which I hope it works. OK. ",
    "start": "1351530",
    "end": "1358149"
  },
  {
    "text": "Let's see if I can select\nan interesting frame. Actually, I didn't prepare\nfor this, so this is really,",
    "start": "1358150",
    "end": "1363649"
  },
  {
    "text": "truly a demo. OK. So here we can see the images.",
    "start": "1363650",
    "end": "1369049"
  },
  {
    "text": "The images are just\nto show the results for better visualization. But remember that SAL is only\nacting on the lidar point cloud.",
    "start": "1369050",
    "end": "1378289"
  },
  {
    "text": "So the input at test time is\nonly the lidar point cloud. So let's see.",
    "start": "1378290",
    "end": "1383360"
  },
  {
    "text": "We can start by detecting,\nfor example, cars. This is kind of easy. So you put your prompt car and\nyou obtain the segmentation",
    "start": "1383360",
    "end": "1392110"
  },
  {
    "text": "of all the cars. You see-- there is\nstill some bleeding in some of the predictions.",
    "start": "1392110",
    "end": "1398780"
  },
  {
    "text": "But overall, the\nlocalization is good. We can also do things\nlike persons, for example.",
    "start": "1398780",
    "end": "1406360"
  },
  {
    "text": "You detect some of the\npedestrians in the scene. So here, you can see\nbetter in the image.",
    "start": "1406360",
    "end": "1412780"
  },
  {
    "text": "We can do things\nlike traffic lights. This becomes a little\nbit more interesting.",
    "start": "1412780",
    "end": "1418240"
  },
  {
    "text": "Sometimes there is a confusion\nbetween traffic lights and traffic signs like\nstop signs, for example.",
    "start": "1418240",
    "end": "1425570"
  },
  {
    "text": "It tends to detect quite a lot\nthe pole because again, this is only using lidar information.",
    "start": "1425570",
    "end": "1431830"
  },
  {
    "text": "So it basically\nunderstands geometry. So the pole of a traffic\nlight or the pole of a traffic",
    "start": "1431830",
    "end": "1437320"
  },
  {
    "text": "sign, that's pretty similar. But we can also do\nthings like storefront,",
    "start": "1437320",
    "end": "1444440"
  },
  {
    "text": "for example, which does\ndetect some of the stores.",
    "start": "1444440",
    "end": "1449629"
  },
  {
    "text": "It's obviously\nsimilar to buildings so there's not going to be this\nkind of semantic understanding",
    "start": "1449630",
    "end": "1455919"
  },
  {
    "text": "just from the lidar points. Yeah. More like construction work.",
    "start": "1455920",
    "end": "1461950"
  },
  {
    "text": "We can detect that. Now, I don't know if we have-- let me try another frame. ",
    "start": "1461950",
    "end": "1469370"
  },
  {
    "text": "We can detect-- wow. That didn't move quite a lot. Let me just go down.",
    "start": "1469370",
    "end": "1475230"
  },
  {
    "text": "I don't know if this sequence\nhas it, but I'm thinking no. ",
    "start": "1475230",
    "end": "1484080"
  },
  {
    "text": "No. I don't think it's\nthis sequence. So things that I've seen working\nare construction barriers.",
    "start": "1484080",
    "end": "1490549"
  },
  {
    "text": "This is detected perfectly. Traffic cones, for\nexample, this is also good.",
    "start": "1490550",
    "end": "1499120"
  },
  {
    "text": "What else? Yeah. Construction wise, that's--\nbut these are well detected.",
    "start": "1499120",
    "end": "1504950"
  },
  {
    "text": "Yeah. Quick question, can you\nask conditional queries? Can you ask about relationships\nbetween things in the scene?",
    "start": "1504950",
    "end": "1512320"
  },
  {
    "text": "No. Not with this model. No. If you actually put a car\nthat is turning right and--",
    "start": "1512320",
    "end": "1519751"
  },
  {
    "text": "this is not detected for sure. So what we're thinking about\nand how this could be done",
    "start": "1519751",
    "end": "1525460"
  },
  {
    "text": "is basically by having a dynamic\nscene graph where each object is actually not just\nthis point cloud,",
    "start": "1525460",
    "end": "1532460"
  },
  {
    "text": "but you do have\nsome interactions that then you can learn. And then I believe that\nthis would be possible.",
    "start": "1532460",
    "end": "1539290"
  },
  {
    "text": "To be honest, there's so\nmuch prompt engineering to make very specific\ncases work that it's crazy.",
    "start": "1539290",
    "end": "1547920"
  },
  {
    "text": "I mean, if I put car and\nthen I put cars in plural, sometimes the\nresult is different. So this is a bit\npainful, but I think",
    "start": "1547920",
    "end": "1555500"
  },
  {
    "text": "that you can find\nnice recipes so that the result is consistent. The elements are kind\nof a crappy API, right?",
    "start": "1555500",
    "end": "1561649"
  },
  {
    "text": "They're like an API. It's very natural, but\nyeah, maybe very crappy. Yeah.",
    "start": "1561650",
    "end": "1567428"
  },
  {
    "text": "I don't know if there\nwas another question. Or you can just ask\nfor prompts if there's any object that you see\nbecause I really don't",
    "start": "1567428",
    "end": "1573590"
  },
  {
    "text": "know these seeds by heart. Yeah. Can you try Fire hydrant? Yeah.",
    "start": "1573590",
    "end": "1579620"
  },
  {
    "text": "You see our logo, right? Yeah. That's because we\ncan do fire hydrants.",
    "start": "1579620",
    "end": "1585590"
  },
  {
    "text": "But I'm not sure that\nthere's one here. Let me try. ",
    "start": "1585590",
    "end": "1592180"
  },
  {
    "text": "Yeah. There's one here. Oh my God. This is one here. There's also-- sometimes,\nthese kind of errors where",
    "start": "1592180",
    "end": "1599389"
  },
  {
    "text": "you actually detect the road. So what we usually\ndo for this is we do cross check between queries.",
    "start": "1599390",
    "end": "1605220"
  },
  {
    "text": "So for example, if\nthere's sidewalk-- I think sidewalk was\nactually fire there.",
    "start": "1605220",
    "end": "1610850"
  },
  {
    "text": "But let me try. Yeah. Sometimes the sidewalk\nis nicely segmented,",
    "start": "1610850",
    "end": "1617100"
  },
  {
    "text": "sometimes it segments\nthe whole road. And then what we do is\nusually, we cross check things.",
    "start": "1617100",
    "end": "1622429"
  },
  {
    "text": "Like, OK, road versus\nsidewalk and then we do intersection union. And this works pretty well.",
    "start": "1622430",
    "end": "1629400"
  },
  {
    "text": "Yeah. What about the debris. ",
    "start": "1629400",
    "end": "1635090"
  },
  {
    "text": "Let's see if I\nwrite it correctly. Is this how it's written? Yes.",
    "start": "1635090",
    "end": "1640670"
  },
  {
    "text": "OK. Good. I don't know what you're\nexpecting to see in this scene.",
    "start": "1640670",
    "end": "1649837"
  },
  {
    "text": "[INAUDIBLE] you can be specific. It can be anything. In general, it's just\nlike-- if there's like, I don't know, a\npiece of a headlamp",
    "start": "1649837",
    "end": "1656620"
  },
  {
    "text": "on the road or a little animal. Will it actually--\nhas it been tested?",
    "start": "1656620",
    "end": "1662200"
  },
  {
    "text": "No, no, no. This is going to be the\nmotivation for the next work. So what we're trying to find\nis any obstacle in the scene,",
    "start": "1662200",
    "end": "1670899"
  },
  {
    "text": "for example. This is not doable. You really have to specify\nthere's a salmon on the road",
    "start": "1670900",
    "end": "1676960"
  },
  {
    "text": "or there's whatever animal. I say salmon because I\nused to have this video",
    "start": "1676960",
    "end": "1683260"
  },
  {
    "text": "to motivate why you want to\nhave open world tracking where in Seattle at some point,\nthere was some flooding",
    "start": "1683260",
    "end": "1689679"
  },
  {
    "text": "and there was salmon on the\nroad or something like that. So that's why I always\nthink about salmon.",
    "start": "1689680",
    "end": "1694790"
  },
  {
    "text": "I'm not that weird. But you have to be very\nspecific about your queries. Yeah.",
    "start": "1694790",
    "end": "1700065"
  },
  {
    "text": " Yeah. Can you try tree or plant?",
    "start": "1700065",
    "end": "1706070"
  },
  {
    "text": "Yeah, sure. I don't know if there are\nany trees here, though. ",
    "start": "1706070",
    "end": "1713900"
  },
  {
    "text": "OK. Not bad. I think the one on the-- yeah. This one is probably\nbetter, but I",
    "start": "1713900",
    "end": "1719797"
  },
  {
    "text": "don't think you can see\nit from the cameras. So one interesting thing maybe\nis that we cannot see some",
    "start": "1719797",
    "end": "1727070"
  },
  {
    "text": "things from the cameras, but\nwe still want them segmented. And depending on\nthe data set, you don't have 360\ncoverage of the scene.",
    "start": "1727070",
    "end": "1735132"
  },
  {
    "text": "So then what we do\nis we create what we call the Franken frustum\nfor the Frankenstein",
    "start": "1735132",
    "end": "1742070"
  },
  {
    "text": "in which we basically overlap\ndifferent point clouds without--",
    "start": "1742070",
    "end": "1747889"
  },
  {
    "text": "there's no semantic\nrelationship between them. We just want to have pseudo\nlabeled point clouds in a 360",
    "start": "1747890",
    "end": "1755120"
  },
  {
    "text": "fashion, and then we\ntrain our model with that. And then the model is able\nto predict 360 coverage.",
    "start": "1755120",
    "end": "1761420"
  },
  {
    "text": "So this is why you're\nactually seeing these three, but it's not really\nin the image. ",
    "start": "1761420",
    "end": "1769280"
  },
  {
    "text": "Maybe I can find a\nsequence with more trees.",
    "start": "1769280",
    "end": "1775130"
  },
  {
    "text": "I used to have a better selected\nset of diverse sequences.",
    "start": "1775130",
    "end": "1780250"
  },
  {
    "text": "OK. So here's at night. So this is going\nto be interesting. Now I'm scared because I\nhaven't tried this before",
    "start": "1780250",
    "end": "1786360"
  },
  {
    "text": "and if it doesn't work, then\nit looks really bad, right? OK. That's decent.",
    "start": "1786360",
    "end": "1792320"
  },
  {
    "text": "Good. I think we can call it a day. I'm happy. No. Actually, if you want. If you want any other\nprompts, just let me know.",
    "start": "1792320",
    "end": "1799910"
  },
  {
    "text": "We can also play\nwith this later. Yeah. What is the use of\nself-driving cars",
    "start": "1799910",
    "end": "1805920"
  },
  {
    "text": "to be able to label objects\non the side of the road? So imagine that you want to\ndo full scene understanding.",
    "start": "1805920",
    "end": "1815010"
  },
  {
    "text": "You really want your car\nto understand when there's an obstacle in\nthe scene, where's",
    "start": "1815010",
    "end": "1822240"
  },
  {
    "text": "the sidewalks, if there's an\nobject walking on the side",
    "start": "1822240",
    "end": "1827850"
  },
  {
    "text": "and then about to cross. You want to be\nprepared for that. So I think the sides of the car\nare actually pretty important.",
    "start": "1827850",
    "end": "1837570"
  },
  {
    "text": "Maybe less so for,\nI don't know, trees, unless there's a tree in\nthe middle of the road.",
    "start": "1837570",
    "end": "1844140"
  },
  {
    "text": "This tool is something that\nwe envision more for labeling. This model is not\ngoing to go in the car.",
    "start": "1844140",
    "end": "1849270"
  },
  {
    "text": "Are you going to be\nprompting in the car? This makes no sense. So this is more for labeling. Imagine that you want to\nfind interesting data.",
    "start": "1849270",
    "end": "1856830"
  },
  {
    "text": "You want to find data with a\ntree in the middle of the road. You can now prompt\nfor this and say, OK,",
    "start": "1856830",
    "end": "1862179"
  },
  {
    "text": "in your one billion hours\nof self-driving, where are the trees in the road?",
    "start": "1862180",
    "end": "1868159"
  },
  {
    "text": "And then this is something\nthat you can prompt. It requires a little\nbit of hand work because you need to establish\nthe relationship between tree",
    "start": "1868160",
    "end": "1874928"
  },
  {
    "text": "and road, which as I\nsaid, is not automatic. So this needs to be rule\nbased, but this is something that you can do.",
    "start": "1874928",
    "end": "1880340"
  },
  {
    "text": "And then basically, you\ncollect, for example, training data like this.",
    "start": "1880340",
    "end": "1885840"
  },
  {
    "text": "Yeah. Yeah. When you say relationships,\nI use my knowledge graphs",
    "start": "1885840",
    "end": "1890950"
  },
  {
    "text": "to design and connect\nthose relationships? So let's say how I would do it\nfrom my professor head position",
    "start": "1890950",
    "end": "1901299"
  },
  {
    "text": "is I would create a\ndynamic scene graph. I would learn this with\ngraph neural networks.",
    "start": "1901300",
    "end": "1906460"
  },
  {
    "text": "So it would be\nsomething learned. If you have to say,\ngive me a solution",
    "start": "1906460",
    "end": "1912010"
  },
  {
    "text": "by tomorrow in a\nmore practical way, then you can do this rule based. Yeah.",
    "start": "1912010",
    "end": "1919220"
  },
  {
    "text": "You have the 3D position\nso you can really say, OK, there's a tree that touches the\nroad, and this is for example,",
    "start": "1919220",
    "end": "1925790"
  },
  {
    "text": "not the sidewalk or\nnot something else. Then you can say this is\nan interesting scenario,",
    "start": "1925790",
    "end": "1931039"
  },
  {
    "text": "for example.  OK.",
    "start": "1931040",
    "end": "1937540"
  },
  {
    "text": "I think I will go\nback to the talk. ",
    "start": "1937540",
    "end": "1943490"
  },
  {
    "text": "OK. So before, I've said\nthat we actually-- we",
    "start": "1943490",
    "end": "1948680"
  },
  {
    "text": "don't want to have this,\nsingle frame predictions. We actually want to go to 40. And so here I have some\nsuper preliminary results.",
    "start": "1948680",
    "end": "1957240"
  },
  {
    "text": "And by preliminary, I mean\nthat I got them this morning. These are still\npreliminary results.",
    "start": "1957240",
    "end": "1962670"
  },
  {
    "text": "But basically, what we're\nworking on is on extending this understanding to 4D so that we\ncan obtain temporally coherent",
    "start": "1962670",
    "end": "1970880"
  },
  {
    "text": "instances. So we can obtain\ntracks of the object so that when I prompt\nfor a car, I actually",
    "start": "1970880",
    "end": "1976520"
  },
  {
    "text": "obtain the track\nof the car and not just one instance of the car.",
    "start": "1976520",
    "end": "1983160"
  },
  {
    "text": "How we're going about\nthis is very simple. We just say, OK, let's\naccumulate point clouds",
    "start": "1983160",
    "end": "1990260"
  },
  {
    "text": "into one, let's say\nsingle canonical frame and let's do the pseudo\nlabeling as we did.",
    "start": "1990260",
    "end": "1996900"
  },
  {
    "text": "Of course, it requires\na bit of magic because there's a\ntemporal domain. Nothing agrees from\ndifferent frames.",
    "start": "1996900",
    "end": "2004850"
  },
  {
    "text": "And then let's train\na model on top. And these are basically\nsome first results. Maybe I can find later the\nvideo and show you offline.",
    "start": "2004850",
    "end": "2011770"
  },
  {
    "start": "2011770",
    "end": "2017670"
  },
  {
    "text": "So essentially,\nthis was our work. So we found an easy and\nscalable way to get data.",
    "start": "2017670",
    "end": "2024690"
  },
  {
    "text": "And instead of just saying,\nlet's use these as predictions, we propose to actually\ntrain the model.",
    "start": "2024690",
    "end": "2029789"
  },
  {
    "text": "And we really found that\nthis was a huge benefit. But there are still some\ninstances like the debris",
    "start": "2029790",
    "end": "2035780"
  },
  {
    "text": "that you're not going\nto be able to recognize with a specific prompt. And so we were asking\nourselves, OK, is there anything",
    "start": "2035780",
    "end": "2045320"
  },
  {
    "text": "that we can do? So far, we have looked\nat the appearance.",
    "start": "2045320",
    "end": "2050350"
  },
  {
    "text": "This is all based on appearance. SAM is based on appearance. CLIP is based on appearance. But what about\nthe motion, right?",
    "start": "2050350",
    "end": "2058287"
  },
  {
    "text": "So dynamic objects\nare, in general, what you're interested\nin for autonomous agents.",
    "start": "2058287",
    "end": "2064850"
  },
  {
    "text": "So how about focusing\njust on those? Can I detect any moving object,\neven if I don't know what it is.",
    "start": "2064850",
    "end": "2072940"
  },
  {
    "text": "So this is basically\nthe second work that we call what moves\ntogether belongs together.",
    "start": "2072940",
    "end": "2078169"
  },
  {
    "text": "And the idea here is let's try\nto find clusters of lidar point clouds that move\ntogether and let's",
    "start": "2078170",
    "end": "2085330"
  },
  {
    "text": "use those as object instances. And then we're going to\nagain, train a model on top.",
    "start": "2085330",
    "end": "2092110"
  },
  {
    "text": "So let me go a little\nbit more in detail here. So we're going to do what\nwe call motion inspired",
    "start": "2092110",
    "end": "2098650"
  },
  {
    "text": "pseudo labeling, which is-- it requires a little bit\nof labeled lidar streams.",
    "start": "2098650",
    "end": "2106010"
  },
  {
    "text": "So we do need a little bit\nof lidar data annotated. But then the great\nbenefit here is",
    "start": "2106010",
    "end": "2112240"
  },
  {
    "text": "that we're going to use tons\nof unlabeled lidar data. And what we're\ngoing to do or let's",
    "start": "2112240",
    "end": "2118450"
  },
  {
    "text": "say our goal is going to be to\ntrain an object detector, a car detector, for example, that\nis just going to be trained",
    "start": "2118450",
    "end": "2126829"
  },
  {
    "text": "on observed moving objects. So let's see how this works.",
    "start": "2126830",
    "end": "2133010"
  },
  {
    "text": "So the object detector, it\nlike it is nothing fancy. I'm not even going\nto talk about it.",
    "start": "2133010",
    "end": "2139350"
  },
  {
    "text": "You take your off the\nshelf object detector. What we're really\ninterested in is how are we going to do the\npseudo label generation?",
    "start": "2139350",
    "end": "2148190"
  },
  {
    "text": "And so here's the big picture. So we're going to have a\nlittle bit of pre-processing",
    "start": "2148190",
    "end": "2154910"
  },
  {
    "text": "so that we have for\nexample, scene flow computed on the\nlidar point cloud.",
    "start": "2154910",
    "end": "2161520"
  },
  {
    "text": "And so we're going to have some\ntrajectories for lidar points. In general, these\ntrajectories are quite short.",
    "start": "2161520",
    "end": "2169550"
  },
  {
    "text": "And so what we're\ngoing to do next is we're going to cluster\nthese trajectories.",
    "start": "2169550",
    "end": "2175370"
  },
  {
    "text": "And we don't really want to\ndo this in a heuristic way.",
    "start": "2175370",
    "end": "2180540"
  },
  {
    "text": "This is super complex\nbecause you're going to have cars that\nare relatively big. Then you're going to have people\nthat are relatively small.",
    "start": "2180540",
    "end": "2188220"
  },
  {
    "text": "So finding the hyper-parameters,\nfor example, in DBSCAN to cluster these trajectories\nwould be completely insane.",
    "start": "2188220",
    "end": "2196470"
  },
  {
    "text": "So what we propose is let's\ndo this in a learned fashion. And finally, once you\ncluster trajectories,",
    "start": "2196470",
    "end": "2204760"
  },
  {
    "text": "then you can actually\nfind objects. Let's say I have-- like here I plot like five\ntrajectories for the car,",
    "start": "2204760",
    "end": "2212190"
  },
  {
    "text": "I cluster them, I say,\nhey, these belong together. This is an instance. Now I can suddenly place a\nbounding box on top of this car.",
    "start": "2212190",
    "end": "2220860"
  },
  {
    "text": "And this is my detection.  OK.",
    "start": "2220860",
    "end": "2226150"
  },
  {
    "text": "I will talk more about the\nGNN a little bit later.",
    "start": "2226150",
    "end": "2231539"
  },
  {
    "text": "The object detector training,\nagain, there's no secret here. We're going to apply our\nmethod to unseen data.",
    "start": "2231540",
    "end": "2239560"
  },
  {
    "text": "We're going to take this\ndata as pseudo labels, and then we're going to train\nan off the shelf detector.",
    "start": "2239560",
    "end": "2245080"
  },
  {
    "text": "So a little bit the\nsame idea as before. OK. What's happening with\nthe clustering method?",
    "start": "2245080",
    "end": "2251109"
  },
  {
    "text": "I think this is\nthe special part. So we don't really want\nto do this manually.",
    "start": "2251110",
    "end": "2256119"
  },
  {
    "text": "We have some baselines on\nhow to do this with DBSCAN in the paper. But I think here,\nthe interesting part",
    "start": "2256120",
    "end": "2262529"
  },
  {
    "text": "is that you can actually\nlearn to cluster using graph neural networks.",
    "start": "2262530",
    "end": "2267683"
  },
  {
    "text": "So what we're going\nto do is we're going to create this\ngraph where the nodes are point trajectories.",
    "start": "2267683",
    "end": "2273820"
  },
  {
    "text": "So remember that we pre-process\nthe lidar sequences.",
    "start": "2273820",
    "end": "2279240"
  },
  {
    "text": "We obtain scene flow. So we do have some\nof trajectories for the lidar points.",
    "start": "2279240",
    "end": "2286080"
  },
  {
    "text": "And then the edges are going\nto connect trajectories that might belong together or not.",
    "start": "2286080",
    "end": "2291960"
  },
  {
    "text": "So this connectivity says-- these are all the\npossible connections between point trajectories.",
    "start": "2291960",
    "end": "2299099"
  },
  {
    "text": "So now, to actually learn which\nof these connections is true and which of these\nis not true, we",
    "start": "2299100",
    "end": "2306300"
  },
  {
    "text": "can use message passing\nessentially to learn this. So again, nothing secret here.",
    "start": "2306300",
    "end": "2314850"
  },
  {
    "text": "So the idea of a\nmessage passing network is that you share features\nbetween nodes and edges.",
    "start": "2314850",
    "end": "2322470"
  },
  {
    "text": "So the embeddings of the nodes\nand the embedding of the edges are passed along the graph.",
    "start": "2322470",
    "end": "2327750"
  },
  {
    "text": "This is, of course,\nin a learn step. You have your MLP that\ncollects the information. And so after all of\nthese message passing",
    "start": "2327750",
    "end": "2335490"
  },
  {
    "text": "steps, essentially\nwhat you have is a graph that has knowledge\nof the surroundings.",
    "start": "2335490",
    "end": "2340710"
  },
  {
    "text": "So imagine one node, which\nis one trajectory, which has a good knowledge\nabout all the other nodes",
    "start": "2340710",
    "end": "2346705"
  },
  {
    "text": "in the surroundings, right? Because they have\nshared embeddings. So now suddenly, it's\neasier for this node",
    "start": "2346705",
    "end": "2352890"
  },
  {
    "text": "to say if it belongs together\nwith the other trajectories because you have all these\nshared information now.",
    "start": "2352890",
    "end": "2361530"
  },
  {
    "text": "So the only thing that\nyou have to do in the end is you have to train\nthese graph neural network for classification.",
    "start": "2361530",
    "end": "2368760"
  },
  {
    "text": "You want to classify\nedges into active. And active edge means\nthat 2 point trajectories",
    "start": "2368760",
    "end": "2374520"
  },
  {
    "text": "belong to the same object. An inactive edge\nmeans that they don't.",
    "start": "2374520",
    "end": "2379619"
  },
  {
    "text": "Then you do some cleaning\nwith correlation clustering and you can extract\nthe bounding boxes.",
    "start": "2379620",
    "end": "2386590"
  },
  {
    "text": "So I don't want to go too\nmuch into detail on results, but I do want to show\na couple of numbers.",
    "start": "2386590",
    "end": "2394750"
  },
  {
    "text": "So first of all, I\nwant to show what is the gap between ground truth.",
    "start": "2394750",
    "end": "2402140"
  },
  {
    "text": "So actually training\nwith all the detection bounding boxes and the\npseudo labeling method.",
    "start": "2402140",
    "end": "2408190"
  },
  {
    "text": "So the same as for\nSAL, we're going to have a gap between ground\ntruth and the trained model.",
    "start": "2408190",
    "end": "2416480"
  },
  {
    "text": "And in this case, our\ngap in terms of precision is between the purple\nline and the green line.",
    "start": "2416480",
    "end": "2425380"
  },
  {
    "text": "So you can see that\nit's not perfect. But I think the cool thing is\nthat it's much, much better",
    "start": "2425380",
    "end": "2431650"
  },
  {
    "text": "than the yellow line,\nwhich is actually trying to cluster these point\ntrajectories with DBSCAN.",
    "start": "2431650",
    "end": "2437589"
  },
  {
    "text": "So I think that's a\nreally important thing because previously,\nhow people did",
    "start": "2437590",
    "end": "2443260"
  },
  {
    "text": "it is by using DBSCAN to cluster\nand to find these objects.",
    "start": "2443260",
    "end": "2449180"
  },
  {
    "text": "And we have really a\nhuge improvement there. So this tells me that this is\nthe right direction to continue.",
    "start": "2449180",
    "end": "2457780"
  },
  {
    "text": "The other cool thing\nis that, as I said, DBSCAN has all these parameters\nthat you need to tune.",
    "start": "2457780",
    "end": "2464650"
  },
  {
    "text": "And you even need to\ntune it per data set. Well, what we found was that\nwe could transfer between,",
    "start": "2464650",
    "end": "2471890"
  },
  {
    "text": "for example, GNN\ntrained on label, we could transfer it\nto arguers very easily.",
    "start": "2471890",
    "end": "2478420"
  },
  {
    "text": "And we could even\ndetect new classes. So trained on cars, for example,\nand then we could detect buses.",
    "start": "2478420",
    "end": "2484970"
  },
  {
    "text": "So I think this shows that the\nmethod is much more general than, for example, DBSCAN.",
    "start": "2484970",
    "end": "2490174"
  },
  {
    "text": " So these are some of the\nresults that we have on Waymo.",
    "start": "2490175",
    "end": "2496965"
  },
  {
    "text": "All these red bounding boxes are\nthe ones that we detect as cars. And again, here, the goal\nis not to be perfect.",
    "start": "2496965",
    "end": "2505130"
  },
  {
    "text": "These are pseudo labels. I'm going to train\na model on top. This is basically free data. So I think maybe a message that\nthese two works are sending out",
    "start": "2505130",
    "end": "2516610"
  },
  {
    "text": "is that if you\nhave tons of data, just pseudo label it for free,\ntons of it, really tons of data",
    "start": "2516610",
    "end": "2524650"
  },
  {
    "text": "and then train a model on\ntop of this noisy data. And this gives you actually\nquite decent results or at least",
    "start": "2524650",
    "end": "2530800"
  },
  {
    "text": "a decent starting point.  Yeah.",
    "start": "2530800",
    "end": "2535830"
  },
  {
    "text": "These are results on Argoverse. Again, we never see our\nArgoverse during training.",
    "start": "2535830",
    "end": "2541940"
  },
  {
    "text": "So you can see that\nsome objects big trucks or big buses which\nare present here,",
    "start": "2541940",
    "end": "2547460"
  },
  {
    "text": "sometimes they are\ndifficult to cluster, but still it shows pretty\ngood generalization.",
    "start": "2547460",
    "end": "2553170"
  },
  {
    "text": " So I do want to leave\nsome time for questions.",
    "start": "2553170",
    "end": "2558460"
  },
  {
    "text": "So let's say if I had to distill\nall of this talk into three",
    "start": "2558460",
    "end": "2564210"
  },
  {
    "text": "take home messages, one would\nbe that pseudo labeling is a super powerful tool.",
    "start": "2564210",
    "end": "2571230"
  },
  {
    "text": "You should really leverage\n2D foundation models, and you should not be\nretraining those for 3D tasks.",
    "start": "2571230",
    "end": "2578220"
  },
  {
    "text": "The important thing is to\ndistill the information from them. Don't go ahead and collect\nmanual data to train 3D clip,",
    "start": "2578220",
    "end": "2585099"
  },
  {
    "text": "for example. I think there are geometric and\n3D motion cues that still need",
    "start": "2585100",
    "end": "2592710"
  },
  {
    "text": "to be explored. This is just a first\nexploration of this. There's tons to do\nand I think there's",
    "start": "2592710",
    "end": "2598920"
  },
  {
    "text": "a lot of interesting\nthings to do there. And there's a lot of good\ngeneralization to unseen",
    "start": "2598920",
    "end": "2604590"
  },
  {
    "text": "classes, to open\nworld vocabulary. And finally, what we actually\nwant to do with these two works",
    "start": "2604590",
    "end": "2613000"
  },
  {
    "text": "is open up possibilities in 3D\nwithout require any labeled data",
    "start": "2613000",
    "end": "2619190"
  },
  {
    "text": "in 3D. I think labeling\ndata is painful. Labeling data in 3D\nis even more painful.",
    "start": "2619190",
    "end": "2624620"
  },
  {
    "text": "So we should really be\ntrying to avoid that. ",
    "start": "2624620",
    "end": "2630070"
  },
  {
    "text": "With that, I will\nconclude my talk. You have the link if you want\nto see some of the research",
    "start": "2630070",
    "end": "2636030"
  },
  {
    "text": "that we're doing. And yeah, I will be happy\nto take any questions. ",
    "start": "2636030",
    "end": "2649320"
  },
  {
    "text": "Yeah.  Recently when SAM 2 came out, it\nseems like the inter-frame mask",
    "start": "2649320",
    "end": "2658789"
  },
  {
    "text": "tracking is pretty good. How do you think\nthat's going to play through to some of your work? It seems like it would be\na pretty useful feature",
    "start": "2658790",
    "end": "2664830"
  },
  {
    "text": "to leverage. Yeah. We tried. It's not good. So let me tell you. So we're interested\nin long term tracking.",
    "start": "2664830",
    "end": "2672860"
  },
  {
    "text": "So we're interested in-- so for me, let's say SAM 2\nis more like a video object",
    "start": "2672860",
    "end": "2679790"
  },
  {
    "text": "detector in the sense that as\nlong as you see these glasses, SAM 2 can track them, can\nsegment them, no problem.",
    "start": "2679790",
    "end": "2687720"
  },
  {
    "text": "If I hide them, then\nit's over for SAM 2. If there are many\nsimilar objects,",
    "start": "2687720",
    "end": "2694110"
  },
  {
    "text": "it gets quite\nconfused, especially if there's a lot of occlusions. ",
    "start": "2694110",
    "end": "2701630"
  },
  {
    "text": "The interesting\ncases of tracking are not solved by SAM 2. Of course, we do leverage it.",
    "start": "2701630",
    "end": "2707860"
  },
  {
    "text": "So the results that are\npresented for SAL in 4D, these are with SAM 2 as a pseudo\nlabeling method and not SAM 1,",
    "start": "2707860",
    "end": "2715450"
  },
  {
    "text": "let's say. It does have a little bit\nworse semantic accuracy,",
    "start": "2715450",
    "end": "2720970"
  },
  {
    "text": "but I think they\nnow have released a version that is then better. So this might be\ninformation of last week.",
    "start": "2720970",
    "end": "2727590"
  },
  {
    "text": "But yeah, you can leverage it,\nbut for short term tracking, I would say.",
    "start": "2727590",
    "end": "2733869"
  },
  {
    "text": "Yeah. How good are the sensors at\ntelling the difference between,",
    "start": "2733870",
    "end": "2741470"
  },
  {
    "text": "let's say like roadkill or a\ncat that's like laying down in the middle of the road?",
    "start": "2741470",
    "end": "2747980"
  },
  {
    "text": "I would say really bad. But I also like-- I don't know how interesting\nthat is for a car.",
    "start": "2747980",
    "end": "2756410"
  },
  {
    "text": "Because if the animal is dead,\nthen you just don't care. I don't know. I don't do that, so.",
    "start": "2756410",
    "end": "2762050"
  },
  {
    "text": "I hope that no one does that\nand just runs over the animal. I think that it's--",
    "start": "2762050",
    "end": "2768809"
  },
  {
    "text": "[INAUDIBLE] is moving\nversus just being there.",
    "start": "2768810",
    "end": "2777170"
  },
  {
    "text": "What I imagine is that-- or\nI'll say the difference that I imagine is that if the car is\nstill but alive or dead, right?",
    "start": "2777170",
    "end": "2784700"
  },
  {
    "text": "Was that the question? Yeah. No, this is hard. Yeah. So that's something you\nguys would like want",
    "start": "2784700",
    "end": "2790610"
  },
  {
    "text": "to try to work on because-- I don't think so. It's more about the\nobstacle being there.",
    "start": "2790610",
    "end": "2799010"
  },
  {
    "text": "I think this is\nsuper fine grained. I think autonomous\ndriving is not far enough",
    "start": "2799010",
    "end": "2808320"
  },
  {
    "text": "that this is your main problem. I think there are tons of\nother problems to solve. So yeah, I think it's more\nabout the actual localization",
    "start": "2808320",
    "end": "2815420"
  },
  {
    "text": "of something on the road and\nthen giving it a target-- sorry, a tag.",
    "start": "2815420",
    "end": "2821390"
  },
  {
    "text": "So if it's cat, if it's\nalive or dead, I don't know. I don't see the impact there.",
    "start": "2821390",
    "end": "2828319"
  },
  {
    "text": "But maybe I'm wrong. Maybe it's an\ninteresting problem. Yeah. I don't know. Some [INAUDIBLE].",
    "start": "2828320",
    "end": "2835050"
  },
  {
    "text": "If they can move, then sure. Then we can detect it\nwith the second work, like putting motion\nfeatures together",
    "start": "2835050",
    "end": "2841010"
  },
  {
    "text": "with appearance features. That's also something\nwe're thinking about. For sure. Yeah. I assume you wouldn't\nwant the car to just--",
    "start": "2841010",
    "end": "2847280"
  },
  {
    "text": "if the cat was alive,\njust go over it. Yeah. I would argue that it should\njust go around it either way.",
    "start": "2847280",
    "end": "2854515"
  },
  {
    "text": "OK. Yeah. How does the underlying lidar\nhardware matter in the model?",
    "start": "2854515",
    "end": "2862373"
  },
  {
    "text": "Because there's\nnew types of light are called frequency modulation,\nwhich can detect both velocity and position.",
    "start": "2862373",
    "end": "2869250"
  },
  {
    "text": "Like if you want to\ntrain a better model, like utilizing that information\nas well instead of just a mechanical scanning lidar.",
    "start": "2869250",
    "end": "2875680"
  },
  {
    "text": "Yeah. So I have to say the\nmethod is not even-- it doesn't even transfer\nwell across lidars.",
    "start": "2875680",
    "end": "2882930"
  },
  {
    "text": "So if you try the\ndifferent public data sets with different lidars, the point\ndistribution is just different.",
    "start": "2882930",
    "end": "2890819"
  },
  {
    "text": "You could actually train\na model with any new type of information, even\nwith radar information.",
    "start": "2890820",
    "end": "2896475"
  },
  {
    "text": "And of course, it would help\nyou in the case of 4D to have velocity information. That's clear.",
    "start": "2896476",
    "end": "2902470"
  },
  {
    "text": "So radar can be interesting. I don't think you would even\nneed to change the method.",
    "start": "2902470",
    "end": "2908970"
  },
  {
    "text": "It's just a question of what's\nthe input, what's the output. But I think the method\ncould be the same.",
    "start": "2908970",
    "end": "2914130"
  },
  {
    "text": "Yeah. [INAUDIBLE] 2D, 3D only or\njust 2D or it doesn't matter?",
    "start": "2914130",
    "end": "2923710"
  },
  {
    "text": "So the pseudo\nlabeling is the idea of taking automatic output--",
    "start": "2923710",
    "end": "2929970"
  },
  {
    "text": "an automatic output of a\nmodel, something that you haven't labeled manually\nand transferring it to 3D.",
    "start": "2929970",
    "end": "2935860"
  },
  {
    "text": "This is what we call the\npseudo labeling engine. So basically, it's\nobtaining labels for free.",
    "start": "2935860",
    "end": "2941770"
  },
  {
    "text": "That's the core idea.  Yeah.",
    "start": "2941770",
    "end": "2946950"
  },
  {
    "text": "So it sounds like your job is\nin the perception, the real time perception stack. Is that right?",
    "start": "2946950",
    "end": "2952510"
  },
  {
    "text": "Real time? No. It's more for actual labeling. Yeah. This method is not\nreal time, right?",
    "start": "2952510",
    "end": "2958140"
  },
  {
    "text": "Your model will--\nthere'll be some-- this will be on car. It will be kind of these--",
    "start": "2958140",
    "end": "2966119"
  },
  {
    "text": "I think there's people that can\noptimize the methods at NVIDIA. These we know how to do. But that's not--",
    "start": "2966120",
    "end": "2973050"
  },
  {
    "text": "I will not say it's the goal. I think the goal is to have\nbetter understanding of the data that you have.",
    "start": "2973050",
    "end": "2978815"
  },
  {
    "text": "And once you\nunderstand the data, then you can train\na really fast model. [INAUDIBLE] in a\ndifferent direction.",
    "start": "2978815",
    "end": "2985119"
  },
  {
    "text": "OK. One of the things\nI always thought would be really nice that\nNVIDIA could push forward is things that make--\nwhen you're going",
    "start": "2985120",
    "end": "2990990"
  },
  {
    "text": "and you're setting up a model\nfor your robot in the lab or outside or whatever, it'd be\nnice if you could take some data",
    "start": "2990990",
    "end": "2996990"
  },
  {
    "text": "and boom, you get something\nin open USD or Isaacson just like that. Yeah.",
    "start": "2996990",
    "end": "3002930"
  },
  {
    "text": "And I'm just wondering if\nNVIDIA, there's interest or there's a name for closing\nthat loop where things are",
    "start": "3002930",
    "end": "3008240"
  },
  {
    "text": "actually in sim so that I have\na Isaacson model of something just by a robot view of it.",
    "start": "3008240",
    "end": "3013650"
  },
  {
    "text": "I get things that predict-- you're modeling the scene. Yeah. You're labeling objects, so just\ngive me a 3D model of the whole",
    "start": "3013650",
    "end": "3021650"
  },
  {
    "text": "scene. There are some works\nin that direction. I would not say it's done.",
    "start": "3021650",
    "end": "3029600"
  },
  {
    "text": "I hope not. Yeah.  We do a lot of also\nreconstruction and adding",
    "start": "3029600",
    "end": "3036420"
  },
  {
    "text": "semantic information\ninto reconstructions. Like adding this\ninformation into Gaussians",
    "start": "3036420",
    "end": "3041610"
  },
  {
    "text": "plots or nerves or\nsomething like that, right? But they're still not a thing. They're still kind of an image.",
    "start": "3041610",
    "end": "3047940"
  },
  {
    "text": "They're not a 3D model. Right, but then you can\nconvert these into simulation. I think these were\npretty good at doing.",
    "start": "3047940",
    "end": "3054670"
  },
  {
    "text": "There must be a name\nfor that thing, right? At NVIDIA. You must call that something.",
    "start": "3054670",
    "end": "3059730"
  },
  {
    "text": "There must be a name\nfor that process of-- because it could be used for\npeople that are using open",
    "start": "3059730",
    "end": "3065940"
  },
  {
    "text": "used to create things. Creators could use it. It seems it would be a large--",
    "start": "3065940",
    "end": "3071220"
  },
  {
    "text": "Yeah. Could be. I'm not super familiar with\nthat part of the company, I have to admit.",
    "start": "3071220",
    "end": "3076990"
  },
  {
    "text": "But I can see the connections. Yeah, definitely.",
    "start": "3076990",
    "end": "3083430"
  },
  {
    "text": "Yeah. Have you thought about\nprediction tasks? So it seems like\nwhat you presented",
    "start": "3083430",
    "end": "3089369"
  },
  {
    "text": "for the plenoptic\nsegmentation, there are two avenues in which\nyou can do prediction.",
    "start": "3089370",
    "end": "3095170"
  },
  {
    "text": "One is-- lidar is\nprobably incomplete. So if there's occlusion\nin the back of a car,",
    "start": "3095170",
    "end": "3100930"
  },
  {
    "text": "how do you know how far\nback of the car extends? Can you predict-- basically in\npaint the rest of the car in 3D.",
    "start": "3100930",
    "end": "3109450"
  },
  {
    "text": "And then also there's a\nprediction axis in time. You predict for the\ncar, the pedestrian",
    "start": "3109450",
    "end": "3115800"
  },
  {
    "text": "could be two seconds, three\nseconds in the future. Have you guys thought about--",
    "start": "3115800",
    "end": "3121200"
  },
  {
    "text": "We have. We have. So the 4D cell is actually going\nto be 4D and object completion.",
    "start": "3121200",
    "end": "3127859"
  },
  {
    "text": "So this is like how we\nenvision the actual final work. For prediction, there have been\na lot of forecasting methods,",
    "start": "3127860",
    "end": "3136829"
  },
  {
    "text": "lidar forecasting. So adding semantics into\nthe mix is pretty trivial. You do improve forecasting\nif the semantic class",
    "start": "3136830",
    "end": "3144450"
  },
  {
    "text": "of the object. Yeah.  I'm going to say\none more question.",
    "start": "3144450",
    "end": "3150135"
  },
  {
    "text": " Yeah. So for the [INAUDIBLE]\nmodelling produced,",
    "start": "3150135",
    "end": "3156910"
  },
  {
    "text": "I think that if\nsomething is on the road, it means that it can be highly\nmanaged or highly likely",
    "start": "3156910",
    "end": "3163420"
  },
  {
    "text": "that the geometry is somewhat\nmodified if we're comparing with the normal state.",
    "start": "3163420",
    "end": "3170050"
  },
  {
    "text": "I'm not sure that model can\nactually model it correctly. So is there some kind of\nprinciple that [INAUDIBLE]?",
    "start": "3170050",
    "end": "3177934"
  },
  {
    "text": " This is a very good\nquestion, actually,",
    "start": "3177934",
    "end": "3182940"
  },
  {
    "text": "and we should find\nsome data for that. I haven't tried. But the thing is that, as I\nsaid, the semantic part of SAL",
    "start": "3182940",
    "end": "3190490"
  },
  {
    "text": "is not really on par with\nwhat we would like to see. So how I would\nsuggest to use SAL",
    "start": "3190490",
    "end": "3197240"
  },
  {
    "text": "would be to do retrieval\non the image space where you actually also\nuse appearance and then do",
    "start": "3197240",
    "end": "3204290"
  },
  {
    "text": "localization with ASL. Because in the end, SAL can\nbe promptable, like SAM. You can train it to be\npromptable like spatially",
    "start": "3204290",
    "end": "3211790"
  },
  {
    "text": "or however you want. And then the thing that\ncell would give you is the localization in\n3D of that object.",
    "start": "3211790",
    "end": "3218119"
  },
  {
    "text": "And in that sense, I\nthink this could work. If it's just pure SAL, I agree.",
    "start": "3218120",
    "end": "3223667"
  },
  {
    "text": "I don't think this is going to\nwork if the shape is completely different. Yeah.",
    "start": "3223667",
    "end": "3228810"
  },
  {
    "text": " With that, I would like us\nall to thank Laura very much.",
    "start": "3228810",
    "end": "3236210"
  },
  {
    "start": "3236210",
    "end": "3243000"
  }
]
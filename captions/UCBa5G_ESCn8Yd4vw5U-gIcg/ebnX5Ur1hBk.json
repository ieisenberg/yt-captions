[
  {
    "text": "all right so hi everyone we're going to get started um so for today's lecture for CS25 I'm very pleased to have Denny Zo",
    "start": "6160",
    "end": "13519"
  },
  {
    "text": "from Google DeepMind here to give a talk on large language model reasoning and so Denny founded the reasoning team at",
    "start": "13519",
    "end": "20240"
  },
  {
    "text": "Google Brain um which is not now part of Google DeepMind his group is renowned for pioneering um chain of thought",
    "start": "20240",
    "end": "26800"
  },
  {
    "text": "prompting and self-consistency as well as developing the mathematical foundations of in context learning and",
    "start": "26800",
    "end": "33040"
  },
  {
    "text": "chain of thought reasoning um his team also created core capabilities that powered Gemini's um reasoning",
    "start": "33040",
    "end": "39800"
  },
  {
    "text": "capabilities further Danny co-founded the conference on language modeling um",
    "start": "39800",
    "end": "44879"
  },
  {
    "text": "or comb and served as general chair for um the 2024 um conference um so yeah um",
    "start": "44879",
    "end": "51039"
  },
  {
    "text": "I'll let um Denny take it from here",
    "start": "51039",
    "end": "55199"
  },
  {
    "text": "yeah um I'm glad to see um many of you guys have already believe AOM is kind",
    "start": "56559",
    "end": "64559"
  },
  {
    "text": "actually you may wonder what's my answer for this question um",
    "start": "64559",
    "end": "71479"
  },
  {
    "text": "yeah to me actually I don't know um that really depends on the",
    "start": "71840",
    "end": "78560"
  },
  {
    "text": "definition of reasoning so um for my talk today we have a very",
    "start": "78560",
    "end": "85439"
  },
  {
    "text": "specific definition about reasoning so I know there are many debates about if MS",
    "start": "85439",
    "end": "90560"
  },
  {
    "text": "can reason i never joined those debates because without a definition on",
    "start": "90560",
    "end": "97240"
  },
  {
    "text": "reasoning I have no idea about those things but for AM",
    "start": "97240",
    "end": "103000"
  },
  {
    "text": "reasoning and we particularly um mean that intermediate tokens between",
    "start": "103000",
    "end": "112159"
  },
  {
    "text": "input and output that's called reasoning",
    "start": "112159",
    "end": "117920"
  },
  {
    "text": "or intermediate steps so this idea actually um is not very new even in 2017",
    "start": "117920",
    "end": "126280"
  },
  {
    "text": "Deman already published a paper how to use intermediate tokens to solve a mass",
    "start": "126280",
    "end": "133560"
  },
  {
    "text": "problems so in two in at that time I think the community were quite hyped",
    "start": "133560",
    "end": "139599"
  },
  {
    "text": "about alpha go alpha zero but this paper is really groundbreaking paper if you",
    "start": "139599",
    "end": "146000"
  },
  {
    "text": "haven't read that paper before I strongly encourage you to look at that paper",
    "start": "146000",
    "end": "151920"
  },
  {
    "text": "they introduced natural language to solve math",
    "start": "151920",
    "end": "157480"
  },
  {
    "text": "problems however in the literature at that time as everyone else just used",
    "start": "157480",
    "end": "164200"
  },
  {
    "text": "the symbolic approach or search so actually this idea",
    "start": "164200",
    "end": "170160"
  },
  {
    "text": "actually is also very common for neuros symbolic literature um in neuros symbolic literature",
    "start": "170160",
    "end": "177440"
  },
  {
    "text": "actually it's very common to use um intermediate process to solve some",
    "start": "177440",
    "end": "183120"
  },
  {
    "text": "reasoning problems here's example about how to um how to um use AM reasoning when I",
    "start": "183120",
    "end": "192400"
  },
  {
    "text": "founded the reasoning team in Google brain I created this task so it's called a last letter",
    "start": "192400",
    "end": "200920"
  },
  {
    "text": "concatenation I use this task as a motivating example at that time one",
    "start": "200920",
    "end": "206720"
  },
  {
    "text": "could use transform models to solve this task so what's the output when",
    "start": "206720",
    "end": "211840"
  },
  {
    "text": "concatenating the last letter of each word of artificial intelligence so if there's no reasoning",
    "start": "211840",
    "end": "218640"
  },
  {
    "text": "process you will see okay the answer is L E if there's a reasoning process the",
    "start": "218640",
    "end": "223920"
  },
  {
    "text": "model would output say the last letter of artificial uh is L the last letter of",
    "start": "223920",
    "end": "229760"
  },
  {
    "text": "intelligence is E concatenating L and E to S L E or something like that so the",
    "start": "229760",
    "end": "236560"
  },
  {
    "text": "highlighted text here is called reasoning that's what I part mean here",
    "start": "236560",
    "end": "242000"
  },
  {
    "text": "about reasoning so if you are familiar with uh program",
    "start": "242000",
    "end": "248000"
  },
  {
    "text": "synthesis or neuro neurosic reasoning you wouldn't be surprised about this",
    "start": "248000",
    "end": "253680"
  },
  {
    "text": "task design of course you can imagine that I tried other options for example I",
    "start": "253680",
    "end": "259600"
  },
  {
    "text": "didn't see the first letter um the reason is that I tried first letter and",
    "start": "259600",
    "end": "266000"
  },
  {
    "text": "all launching models can solve that problem quite well because there are so many initiatives on the web and the",
    "start": "266000",
    "end": "272400"
  },
  {
    "text": "model has already learned how to concatenate first letters then I switch to last letters and all models",
    "start": "272400",
    "end": "281840"
  },
  {
    "text": "failed um I know many people say oh yeah this",
    "start": "284520",
    "end": "290479"
  },
  {
    "text": "is so natural right we need to intermediate steps just like a humans um I know in the current days you",
    "start": "290479",
    "end": "298160"
  },
  {
    "text": "may see LMS are very similar to humans but for us as a researchers we",
    "start": "298160",
    "end": "304560"
  },
  {
    "text": "should always keep in mind LMS are just practice models they are not humans and",
    "start": "304560",
    "end": "311919"
  },
  {
    "text": "if you always keep this in mind it will be better for you to understand a lot of new",
    "start": "311919",
    "end": "318319"
  },
  {
    "text": "techniques so why intermediate tokens or business matters okay we have",
    "start": "318520",
    "end": "325360"
  },
  {
    "text": "theoretical work actually collaborated with professor Tima in Stanford and his",
    "start": "325360",
    "end": "331800"
  },
  {
    "text": "students so for any problems solvable by booing circuits of size T constant size",
    "start": "331800",
    "end": "340720"
  },
  {
    "text": "transformers can solve it by generating OT intermediate tokens is a very powerful result",
    "start": "340720",
    "end": "349240"
  },
  {
    "text": "so the size here means the number of logical gates so of for example if you",
    "start": "349240",
    "end": "356160"
  },
  {
    "text": "use a GPU clusters that would be t of millions g right even the billions",
    "start": "356160",
    "end": "362400"
  },
  {
    "text": "trillions yeah if we directly generate final answers either require a huge",
    "start": "362400",
    "end": "368560"
  },
  {
    "text": "depths or cannot solve at all that's uh how we understand",
    "start": "368560",
    "end": "376000"
  },
  {
    "text": "reasoning from a s the radatical perspective in the later of this lecture",
    "start": "376000",
    "end": "383280"
  },
  {
    "text": "I come back to this theoretical argument",
    "start": "383280",
    "end": "388280"
  },
  {
    "text": "there's a common belief about reasoning and",
    "start": "390319",
    "end": "396120"
  },
  {
    "text": "preends cannot reason without further prompting engineering like coot",
    "start": "396120",
    "end": "402400"
  },
  {
    "text": "prompting or fine-tuning in kind days everyone talk about I fine tuning",
    "start": "402400",
    "end": "409319"
  },
  {
    "text": "right is that true everyone agree that agree",
    "start": "409319",
    "end": "415680"
  },
  {
    "text": "that okay So I believe it's wrong",
    "start": "416600",
    "end": "422680"
  },
  {
    "text": "yeah it's very wrong yeah so pro train are ready to reason",
    "start": "422680",
    "end": "430080"
  },
  {
    "text": "and all we need is decoding just about decoding process yeah no matter how",
    "start": "430080",
    "end": "435280"
  },
  {
    "text": "fancy those techniques looks like in the kind of",
    "start": "435280",
    "end": "440080"
  },
  {
    "text": "days so here's example here if I have three apples my dad has two more apples",
    "start": "441960",
    "end": "448240"
  },
  {
    "text": "than me and how many airports do we have in total",
    "start": "448240",
    "end": "454840"
  },
  {
    "text": "um if you have any pre models like uh llama deep sake",
    "start": "454840",
    "end": "462759"
  },
  {
    "text": "or chin or something and I didn't try those models okay if you have any",
    "start": "462759",
    "end": "467840"
  },
  {
    "text": "persian models you can type this question in the persian model and see what happened probably it's very likely",
    "start": "467840",
    "end": "474319"
  },
  {
    "text": "you say answer like f apples of course the answer is wrong here okay this is called a graded decoding you will say",
    "start": "474319",
    "end": "480879"
  },
  {
    "text": "okay yeah you're right right for preion models there's no reasoning right the problem is about decoding",
    "start": "480879",
    "end": "488560"
  },
  {
    "text": "because we use decod greed decoding by default if you look at the second",
    "start": "488560",
    "end": "495160"
  },
  {
    "text": "candidates second if you look at the the because you have big vocabulary size right and you can look at the second",
    "start": "495160",
    "end": "501919"
  },
  {
    "text": "candidate a second candidate for the first token and the product will start from I and we see what happened we just",
    "start": "501919",
    "end": "509680"
  },
  {
    "text": "then continue the decoding process we see okay I have three apples and then my",
    "start": "509680",
    "end": "516240"
  },
  {
    "text": "dad has two more apples than me so he has a five apples and 3 + 5 equal to 8",
    "start": "516240",
    "end": "523039"
  },
  {
    "text": "it's perfect right we just need to look for more candidates that's",
    "start": "523039",
    "end": "528839"
  },
  {
    "text": "amazing and uh there's another choice and the third candidate for the first",
    "start": "528839",
    "end": "534240"
  },
  {
    "text": "token is we we see what happened here we have eight apples in",
    "start": "534240",
    "end": "539320"
  },
  {
    "text": "total yeah that's somehow it's al correct and probably from the fourth",
    "start": "539320",
    "end": "545519"
  },
  {
    "text": "candidate will be you we will continue decoding we see what happening here again yeah this you can clearly see a",
    "start": "545519",
    "end": "553120"
  },
  {
    "text": "chain of sort in this response and the final answer is",
    "start": "553120",
    "end": "559279"
  },
  {
    "text": "correct and uh this is the fifth candidate for the first token and I say",
    "start": "560200",
    "end": "566800"
  },
  {
    "text": "file is wrong okay yeah you can see that actually the reason pass is already in",
    "start": "566800",
    "end": "573040"
  },
  {
    "text": "the output space and um in particular here for the",
    "start": "573040",
    "end": "582320"
  },
  {
    "text": "second response and the first response they are",
    "start": "582320",
    "end": "588399"
  },
  {
    "text": "um based on chain of sort of reasoning",
    "start": "588399",
    "end": "593000"
  },
  {
    "text": "the problem is how to select the best response right if we just look at the examples here you may see okay we can by",
    "start": "594320",
    "end": "603519"
  },
  {
    "text": "output length if the model has some sinkings and the output length will be",
    "start": "603519",
    "end": "609920"
  },
  {
    "text": "longer because it contains reasoning",
    "start": "609920",
    "end": "615600"
  },
  {
    "text": "tokens and actually we have a better idea to select",
    "start": "616200",
    "end": "623560"
  },
  {
    "text": "response and by it answer confidence confidence means because the",
    "start": "623560",
    "end": "631279"
  },
  {
    "text": "model is just a priv we can look the probability of the token in",
    "start": "631279",
    "end": "639720"
  },
  {
    "text": "prediction a real interest is that for the response with chain of sort",
    "start": "639720",
    "end": "648000"
  },
  {
    "text": "of reasoning the ISO token has way higher",
    "start": "648000",
    "end": "654360"
  },
  {
    "text": "confidence um for this example actually for for the",
    "start": "654360",
    "end": "659600"
  },
  {
    "text": "token 8 the model confidence is is nearly 90 98%",
    "start": "659600",
    "end": "667920"
  },
  {
    "text": "you can imagine that's a huge right because we have huge recovery size so usually for each token the the private",
    "start": "667920",
    "end": "674640"
  },
  {
    "text": "is nearly zero so this process is called a chain",
    "start": "674640",
    "end": "682399"
  },
  {
    "text": "of sort decoding so basically it consists two",
    "start": "682399",
    "end": "689000"
  },
  {
    "text": "steps step one we just go beyond great decoding by checking more generation",
    "start": "689000",
    "end": "695519"
  },
  {
    "text": "candidates and uh this in the second step we choose",
    "start": "695519",
    "end": "702279"
  },
  {
    "text": "candidates which have the highest confidence on the final",
    "start": "702279",
    "end": "708320"
  },
  {
    "text": "answer um channel s decoding is a very simple",
    "start": "713560",
    "end": "719720"
  },
  {
    "text": "approach um but still it needs some programming work",
    "start": "719720",
    "end": "726560"
  },
  {
    "text": "and I heard in the kind days and the people just want to use a natural language right no one write code of",
    "start": "726560",
    "end": "732160"
  },
  {
    "text": "course you guys are exceptional and we have to say okay can we reshape the model's output",
    "start": "732160",
    "end": "739000"
  },
  {
    "text": "distribution so so that sortful responses naturally rank",
    "start": "739000",
    "end": "746279"
  },
  {
    "text": "first if the channel of sort response is ranked first and then the graded",
    "start": "746279",
    "end": "752959"
  },
  {
    "text": "decoding can naturally found it",
    "start": "752959",
    "end": "756639"
  },
  {
    "text": "Okay so now we can look at the channel prompting if you know channel prompting",
    "start": "760040",
    "end": "767839"
  },
  {
    "text": "now you can see why it works channel prompting is a very simple",
    "start": "767839",
    "end": "773839"
  },
  {
    "text": "approach so given this problem and you probably uh use another",
    "start": "773839",
    "end": "779760"
  },
  {
    "text": "similar problems in the as a example and put that before your",
    "start": "779760",
    "end": "788920"
  },
  {
    "text": "question and then the model will magically follow the uh the style",
    "start": "788920",
    "end": "796079"
  },
  {
    "text": "business style and generate a a step-by-step solution",
    "start": "796079",
    "end": "803240"
  },
  {
    "text": "yeah you can now you can see that why channel prompting works because it",
    "start": "803600",
    "end": "809360"
  },
  {
    "text": "changes the output distribution to push the uh original channel sort of",
    "start": "809360",
    "end": "815360"
  },
  {
    "text": "solutions in the output space to the top position even there's a simple simple",
    "start": "815360",
    "end": "822480"
  },
  {
    "text": "approach is called a less single by step that's another amazing work in",
    "start": "822480",
    "end": "829600"
  },
  {
    "text": "um reasoning when that paper came out",
    "start": "829600",
    "end": "835639"
  },
  {
    "text": "and I I I thought it was a joke how possible yeah",
    "start": "835639",
    "end": "843040"
  },
  {
    "text": "and at that time and the Google brain team built a model called",
    "start": "843040",
    "end": "848120"
  },
  {
    "text": "pal and I tried lesson step by step step by step in our pal model because I of",
    "start": "848120",
    "end": "856800"
  },
  {
    "text": "course I know how pal was built it's definitely not related to this magic",
    "start": "856800",
    "end": "862760"
  },
  {
    "text": "trick and then I found it works on palm i was so shocked",
    "start": "862760",
    "end": "868800"
  },
  {
    "text": "so this paper really uh inspired me a lot on reasoning",
    "start": "868800",
    "end": "875360"
  },
  {
    "text": "research those prompt approach you know are really simple and uh prompting",
    "start": "878600",
    "end": "885600"
  },
  {
    "text": "really works but we can see um there's also some pitfalls so like C",
    "start": "885600",
    "end": "893199"
  },
  {
    "text": "prompting right it needs task specific examples",
    "start": "893199",
    "end": "899639"
  },
  {
    "text": "um to me I I don't feel comfortable about that if I have questions to ask",
    "start": "901720",
    "end": "909079"
  },
  {
    "text": "someone if I know similar problems I can then I can solve it by myself right why",
    "start": "909079",
    "end": "914880"
  },
  {
    "text": "we should ask other people and for the other approach is",
    "start": "914880",
    "end": "922079"
  },
  {
    "text": "called lesson step by step it's generic okay you don't have to find a similar",
    "start": "922079",
    "end": "927320"
  },
  {
    "text": "examples you just say uh lesson step by step and then the magic way come out",
    "start": "927320",
    "end": "935399"
  },
  {
    "text": "unfortunately it performs much worse than the fuel short",
    "start": "935399",
    "end": "942240"
  },
  {
    "text": "prompting and yeah I just mention of that okay yeah both approach looks well",
    "start": "948680",
    "end": "954639"
  },
  {
    "text": "right even for less step is also we right if I ask somebody a question then",
    "start": "954639",
    "end": "962079"
  },
  {
    "text": "I have to follow with less things step by step otherwise they couldn't sync",
    "start": "962079",
    "end": "967920"
  },
  {
    "text": "anymore right that's not expected so how to fix",
    "start": "967920",
    "end": "977040"
  },
  {
    "text": "it so there's a popular approach called um supervised fine",
    "start": "977720",
    "end": "983560"
  },
  {
    "text": "tuning so for this approach and the um the idea actually is very simple we can",
    "start": "983560",
    "end": "991040"
  },
  {
    "text": "collect a set of problems and the stepbystep solutions from human",
    "start": "991040",
    "end": "998600"
  },
  {
    "text": "annotators and then then we maximize the likelihood of human",
    "start": "998600",
    "end": "1006480"
  },
  {
    "text": "solutions maximum likelihood actually for LM's training pretty net token it's",
    "start": "1006600",
    "end": "1012639"
  },
  {
    "text": "just maximize likelihood yeah and after that we can apply the",
    "start": "1012639",
    "end": "1019839"
  },
  {
    "text": "model everywhere So um so I uh listed a deman paper in 2017",
    "start": "1019839",
    "end": "1030079"
  },
  {
    "text": "i mentioned that paper at the very beginning yeah they exactly did something like that they collected a a",
    "start": "1030079",
    "end": "1035918"
  },
  {
    "text": "set of mass world problems and also human annotated step-by-step solutions",
    "start": "1035919",
    "end": "1042798"
  },
  {
    "text": "and then they trained a sequence model to solve math problems in",
    "start": "1042799",
    "end": "1048280"
  },
  {
    "text": "2021 and OPI actually further extended that approach build a much larger data",
    "start": "1048280",
    "end": "1055760"
  },
  {
    "text": "set called G uh GSM8K grad school math",
    "start": "1055760",
    "end": "1062240"
  },
  {
    "text": "problems and then they use the those data set to fine-tune GP3",
    "start": "1062280",
    "end": "1071039"
  },
  {
    "text": "models so here let me give example how it works okay you can just put problems",
    "start": "1071160",
    "end": "1077280"
  },
  {
    "text": "here like for example at the beginning I said okay we can uh do last letter concatenation and you can put this",
    "start": "1077280",
    "end": "1083679"
  },
  {
    "text": "example here the problem and the answer okay and the other one is the the the",
    "start": "1083679",
    "end": "1089600"
  },
  {
    "text": "city math problems how many apples you can put there and then use that as a training data to fetune your model and",
    "start": "1089600",
    "end": "1097280"
  },
  {
    "text": "then you can test the model with a new question so how many hours in the strawberry",
    "start": "1097280",
    "end": "1103679"
  },
  {
    "text": "um uh probably know why I particularly chose this problem here because in the",
    "start": "1103679",
    "end": "1109280"
  },
  {
    "text": "social media many people believe that it's a good question to test if AGI has come or not",
    "start": "1109280",
    "end": "1116360"
  },
  {
    "text": "yeah",
    "start": "1116360",
    "end": "1119360"
  },
  {
    "text": "um yeah and um SFT is really generic approach once you train a model you can",
    "start": "1122280",
    "end": "1129600"
  },
  {
    "text": "apply anywhere right and uh if that can solve reason you my talk is done here right we don't",
    "start": "1129600",
    "end": "1137200"
  },
  {
    "text": "have to more right just collect more examples from those brilliant minds in",
    "start": "1137200",
    "end": "1142640"
  },
  {
    "text": "Stanford right we can train a model and it's done but actually it doesn't",
    "start": "1142640",
    "end": "1147760"
  },
  {
    "text": "generalize well and when I realized this issue in",
    "start": "1147760",
    "end": "1154360"
  },
  {
    "text": "2021 in the summer we found it didn't work well on reasoning what we could do",
    "start": "1154360",
    "end": "1161919"
  },
  {
    "text": "scaling scaling scaling to get a more data to train a model and see how it",
    "start": "1161919",
    "end": "1168480"
  },
  {
    "text": "works yeah is a lesson here is you",
    "start": "1168760",
    "end": "1174440"
  },
  {
    "text": "know Don't scale blindly once the paradigm is wrong no",
    "start": "1174440",
    "end": "1181200"
  },
  {
    "text": "matter how to scale it doesn't",
    "start": "1181200",
    "end": "1184799"
  },
  {
    "text": "work so how to fix the gen gization failure from",
    "start": "1188600",
    "end": "1195320"
  },
  {
    "text": "SFT let's look the SFT procedure here right just two steps so where's the",
    "start": "1195320",
    "end": "1202240"
  },
  {
    "text": "mistake the mystic part actually from",
    "start": "1202240",
    "end": "1211840"
  },
  {
    "text": "human if you don't don't know that before you'll be surprised",
    "start": "1212440",
    "end": "1218840"
  },
  {
    "text": "right if a human are wrong and how scale AI can make",
    "start": "1218840",
    "end": "1225600"
  },
  {
    "text": "money and actually um one of my team member invented tuning Actually when I when he",
    "start": "1227559",
    "end": "1234559"
  },
  {
    "text": "told me and u the response generated by machines could",
    "start": "1234559",
    "end": "1242159"
  },
  {
    "text": "even better um for training than human data i was really surprised at the very beginning",
    "start": "1242159",
    "end": "1249559"
  },
  {
    "text": "yeah so first attempt is called self-improve yeah exactly just change",
    "start": "1249559",
    "end": "1255440"
  },
  {
    "text": "that okay instead of generating uh collecting data from humans we can just",
    "start": "1255440",
    "end": "1261760"
  },
  {
    "text": "let a model generate data so collect a set of problems and",
    "start": "1261760",
    "end": "1269039"
  },
  {
    "text": "also then let your model generate stepby-step solutions and then again maximize the",
    "start": "1269039",
    "end": "1276880"
  },
  {
    "text": "likelihood of correct answers like a math problems um you may know the final",
    "start": "1276880",
    "end": "1284320"
  },
  {
    "text": "answer right you know ground choose answer but you don't have step-by-step",
    "start": "1284320",
    "end": "1289679"
  },
  {
    "text": "solutions okay that model generates step-by-step solutions and then you can",
    "start": "1289679",
    "end": "1296080"
  },
  {
    "text": "ch answer to decide which response to be used if the ice is cracked from the",
    "start": "1296080",
    "end": "1303760"
  },
  {
    "text": "solution then choose that otherwise reject",
    "start": "1303760",
    "end": "1310600"
  },
  {
    "text": "sampling and then you can use um this data set to find your model okay exactly",
    "start": "1310600",
    "end": "1318000"
  },
  {
    "text": "as you have done in the SFT the only difference the data is from your model is not from",
    "start": "1318000",
    "end": "1325720"
  },
  {
    "text": "humans and this approach actually um was proposed by Eric and Tony and uh",
    "start": "1325720",
    "end": "1337440"
  },
  {
    "text": "and also um Noah yeah it's the the paper is called um star yeah the star approach",
    "start": "1337440",
    "end": "1346159"
  },
  {
    "text": "is really amazing paper so um actually in the star paper actually",
    "start": "1346159",
    "end": "1353840"
  },
  {
    "text": "they when they proposed the approach they considered to use that to save cost labeling cost because human labeling are",
    "start": "1353840",
    "end": "1361840"
  },
  {
    "text": "really expensive but in the coming days we",
    "start": "1361840",
    "end": "1367039"
  },
  {
    "text": "understand this approach from different",
    "start": "1367039",
    "end": "1371279"
  },
  {
    "text": "perspective okay once the um response are generated or train data generated by",
    "start": "1373240",
    "end": "1380080"
  },
  {
    "text": "better model and uh the model can be self-improved right and after the model",
    "start": "1380080",
    "end": "1387919"
  },
  {
    "text": "improved and what kind of collect data again that means we can repeat this",
    "start": "1387919",
    "end": "1396360"
  },
  {
    "text": "process right repeat and then that's",
    "start": "1396360",
    "end": "1401440"
  },
  {
    "text": "this approach is then just the same as um the the iron tuning uh approach in",
    "start": "1401440",
    "end": "1410720"
  },
  {
    "text": "the kind of days i uh put a paper here and I think it's a paper by um",
    "start": "1410720",
    "end": "1418400"
  },
  {
    "text": "researchers in bance published in January",
    "start": "1418400",
    "end": "1424919"
  },
  {
    "text": "2024 i think this is the earliest academia publication I have noticed",
    "start": "1424919",
    "end": "1432880"
  },
  {
    "text": "about fontuning even the paper title is called reasoning with reinforced",
    "start": "1432880",
    "end": "1440520"
  },
  {
    "text": "fontuning yeah",
    "start": "1440520",
    "end": "1444520"
  },
  {
    "text": "as an after open one got popular and then everyone began to",
    "start": "1448080",
    "end": "1456919"
  },
  {
    "text": "uh realize uh funing in the public yeah I believe um multiple",
    "start": "1456919",
    "end": "1464600"
  },
  {
    "text": "institutions independently discovered this idea this s such a simple idea",
    "start": "1464600",
    "end": "1471720"
  },
  {
    "text": "yeah but it works really well",
    "start": "1471720",
    "end": "1477840"
  },
  {
    "text": "of course yes if you are if you if after",
    "start": "1481880",
    "end": "1487440"
  },
  {
    "text": "seeing this tuning process and we need verifier in this in",
    "start": "1487440",
    "end": "1495039"
  },
  {
    "text": "this training loop the verifier can tell us which response is",
    "start": "1495039",
    "end": "1501520"
  },
  {
    "text": "correct because we know the final answer we just need to use that to select the",
    "start": "1501520",
    "end": "1506559"
  },
  {
    "text": "step-by-step reasoning path so a a reliable verifier is the",
    "start": "1506559",
    "end": "1512880"
  },
  {
    "text": "most crucial in IO fine tuning not our algorithms i know in in",
    "start": "1512880",
    "end": "1519039"
  },
  {
    "text": "in the country so many people talk about different algorithms and so many many tons of",
    "start": "1519039",
    "end": "1524880"
  },
  {
    "text": "varants of PO and or reinforce you know",
    "start": "1524880",
    "end": "1531480"
  },
  {
    "text": "um if anyone found those some algorithm are significantly better than another",
    "start": "1531480",
    "end": "1536679"
  },
  {
    "text": "one please let me know probably I miss something yeah I really like what",
    "start": "1536679",
    "end": "1542720"
  },
  {
    "text": "Richard S said here verification the key to AI it's the article title by uh by",
    "start": "1542720",
    "end": "1551200"
  },
  {
    "text": "Rich Son in 2021 2001 okay now a very interesting",
    "start": "1551200",
    "end": "1559039"
  },
  {
    "text": "question is why generated from the model",
    "start": "1559039",
    "end": "1564159"
  },
  {
    "text": "instead of from humans",
    "start": "1564159",
    "end": "1569400"
  },
  {
    "text": "right that's a really interesting question right it's not about saving cost it's about performance",
    "start": "1569400",
    "end": "1578760"
  },
  {
    "text": "does anyone have idea here",
    "start": "1579760",
    "end": "1584120"
  },
  {
    "text": "is it consistency in chain of thought structure versus there's variation how",
    "start": "1585679",
    "end": "1591799"
  },
  {
    "text": "different problems about consistency okay yeah the",
    "start": "1591799",
    "end": "1597760"
  },
  {
    "text": "distribution is closer to it's easier to draw the difference the model is closer to",
    "start": "1597760",
    "end": "1605520"
  },
  {
    "text": "what you do train it's easier to train the model yeah excellent yeah yeah",
    "start": "1605520",
    "end": "1612480"
  },
  {
    "text": "yeah thanks so um yeah this related to first",
    "start": "1613080",
    "end": "1619600"
  },
  {
    "text": "principle in machine learning directly optimize what we",
    "start": "1619600",
    "end": "1626120"
  },
  {
    "text": "want I don't know if anyone still remember some machine learning stuff",
    "start": "1626120",
    "end": "1631360"
  },
  {
    "text": "here of course you guys should remember that yeah",
    "start": "1631360",
    "end": "1636440"
  },
  {
    "text": "um so if we want to build a model for reasoning right or just in general about",
    "start": "1636440",
    "end": "1643679"
  },
  {
    "text": "generating something interesting right we need to optimize the metric of",
    "start": "1643679",
    "end": "1651080"
  },
  {
    "text": "measuring generation quality right those metric could be very",
    "start": "1651080",
    "end": "1657600"
  },
  {
    "text": "very different right for example if for solving math problems we would care about the correctness the answer is",
    "start": "1657600",
    "end": "1663840"
  },
  {
    "text": "correct or not if for machine translation you would optimize blue",
    "start": "1663840",
    "end": "1670600"
  },
  {
    "text": "score or just about magic to me imagine the the quality of generations okay once",
    "start": "1670600",
    "end": "1677200"
  },
  {
    "text": "you have a metric all we need is to compute gradients of the metric and do back",
    "start": "1677200",
    "end": "1684919"
  },
  {
    "text": "propagation yeah so mathematically we can write this",
    "start": "1684919",
    "end": "1692559"
  },
  {
    "text": "formula right we need um a function R to measure the response quality given the",
    "start": "1692559",
    "end": "1700000"
  },
  {
    "text": "problem and also your model parameter SATA okay",
    "start": "1700000",
    "end": "1705840"
  },
  {
    "text": "yeah of course you can see R is a real world or R is your coloration accuracy",
    "start": "1705840",
    "end": "1711440"
  },
  {
    "text": "or R is your blue score or no matter you can define any R you want that's that's that's your target right and uh then",
    "start": "1711440",
    "end": "1720559"
  },
  {
    "text": "compute the gradient since the model is a priv",
    "start": "1720559",
    "end": "1727240"
  },
  {
    "text": "model we need to maximize the expected value of the metric",
    "start": "1727240",
    "end": "1735720"
  },
  {
    "text": "So how to do it we need to sampling to compute",
    "start": "1735720",
    "end": "1742200"
  },
  {
    "text": "impactation that's why you got a policy gradient yeah that's how it works",
    "start": "1742200",
    "end": "1749200"
  },
  {
    "text": "there's no if you understand all the mathematical principle here there's no magic i know some people would like to",
    "start": "1749200",
    "end": "1756080"
  },
  {
    "text": "talk about something in a more magical way for example how to incentivize your model to sync incentivize your model to",
    "start": "1756080",
    "end": "1763760"
  },
  {
    "text": "reason i don't use those words i just use a standard machine learning",
    "start": "1763760",
    "end": "1769000"
  },
  {
    "text": "words define your metric computer gradient and do back",
    "start": "1769000",
    "end": "1775240"
  },
  {
    "text": "propagation that's all",
    "start": "1775240",
    "end": "1779520"
  },
  {
    "text": "yeah um of course yeah",
    "start": "1782279",
    "end": "1789440"
  },
  {
    "text": "once you find your pad works well we need to",
    "start": "1789440",
    "end": "1795960"
  },
  {
    "text": "uh scale your approach another problem is what to",
    "start": "1795960",
    "end": "1801559"
  },
  {
    "text": "scale right and the interesting is that for",
    "start": "1801559",
    "end": "1806960"
  },
  {
    "text": "this funing approach we uh scale the output length",
    "start": "1806960",
    "end": "1813520"
  },
  {
    "text": "or scale the length of COT and uh you probably also scale the model depths right because from our",
    "start": "1813520",
    "end": "1822520"
  },
  {
    "text": "analysis once as long as the COT is long enough the model can",
    "start": "1822520",
    "end": "1829640"
  },
  {
    "text": "solve nearly every computable problems that's amazing you don't have to scale",
    "start": "1829640",
    "end": "1835279"
  },
  {
    "text": "your model size you just need a minimal constant size transform",
    "start": "1835279",
    "end": "1840440"
  },
  {
    "text": "models and that's fine",
    "start": "1840440",
    "end": "1845000"
  },
  {
    "text": "so actually if you look literature and um people realized our",
    "start": "1850399",
    "end": "1857440"
  },
  {
    "text": "fine tune is better than SFT in the very early days but it's harder to notice",
    "start": "1857440",
    "end": "1865480"
  },
  {
    "text": "that we need to scale the CT lens that's even more non-trivial to realize",
    "start": "1865480",
    "end": "1874159"
  },
  {
    "text": "Yeah I would like to mention the beauty of Elm reasoning human like reasoning process",
    "start": "1879919",
    "end": "1886480"
  },
  {
    "text": "emerged from tokento token prediction rather than relying on",
    "start": "1886480",
    "end": "1892240"
  },
  {
    "text": "exhaustive research as in classic AI yeah I also uh have fun quote here by",
    "start": "1892240",
    "end": "1902200"
  },
  {
    "text": "u Kazarov after losing to Deep Blue in",
    "start": "1902200",
    "end": "1907360"
  },
  {
    "text": "1997 and say Deep Blue was or only intelligent the way you program alarm uh",
    "start": "1907360",
    "end": "1914880"
  },
  {
    "text": "clock is intelligent actually I agree with him but AM reason is different",
    "start": "1914880",
    "end": "1921840"
  },
  {
    "text": "right we don't we don't do any explicit search and the search is relevant",
    "start": "1921840",
    "end": "1927559"
  },
  {
    "text": "here and before my talk in the hallway and told me she she quoted my uh um my",
    "start": "1927559",
    "end": "1936799"
  },
  {
    "text": "tweet about search is irrelevant and wow I said I'm very happy to know actually um I use your code and",
    "start": "1936799",
    "end": "1944799"
  },
  {
    "text": "to see search is still is useful um actually I want to give example here",
    "start": "1944799",
    "end": "1951919"
  },
  {
    "text": "about why is this AOM reason is so different from classical AI right here",
    "start": "1951919",
    "end": "1959519"
  },
  {
    "text": "um in December 2024 and Google released a model called Gymni 2.0 O syncing um",
    "start": "1959519",
    "end": "1966480"
  },
  {
    "text": "syncing mode of course uh 2.5 pro is much more",
    "start": "1966480",
    "end": "1971760"
  },
  {
    "text": "powerful okay I use that model is for particular reason so in December 2024",
    "start": "1971760",
    "end": "1978480"
  },
  {
    "text": "after model release I tried a U math problem uh just to ensure this problem",
    "start": "1978480",
    "end": "1985039"
  },
  {
    "text": "is not in our training set okay because I use number",
    "start": "1985039",
    "end": "1990679"
  },
  {
    "text": "2025 for the next year now it's for the this year okay using the numbers from 1",
    "start": "1990679",
    "end": "1995919"
  },
  {
    "text": "to 10 to make 225 and use each number once and the",
    "start": "1995919",
    "end": "2001519"
  },
  {
    "text": "primary operations plus and multiplication okay of course one can",
    "start": "2001519",
    "end": "2007840"
  },
  {
    "text": "write a Python program do exhaustive search and get results right let's look",
    "start": "2007840",
    "end": "2013360"
  },
  {
    "text": "the syncing process on the right panel generated from the model actually",
    "start": "2013360",
    "end": "2020080"
  },
  {
    "text": "for for Gina models you can uh you can check the sinking process rule syncing process as it's very interesting to look",
    "start": "2020080",
    "end": "2027399"
  },
  {
    "text": "at okay let's see how model how the model um did the sinking right by search",
    "start": "2027399",
    "end": "2034960"
  },
  {
    "text": "you see that at the very beginning the model said okay this is a relatively",
    "start": "2034960",
    "end": "2040480"
  },
  {
    "text": "large number right suggesting multiplication will be uh heavily",
    "start": "2040480",
    "end": "2046760"
  },
  {
    "text": "involved right this just like a human thinking right and uh wow even I see okay it's",
    "start": "2046760",
    "end": "2054960"
  },
  {
    "text": "worth noting that 2025 is a 45 squared and 45 * 45 uh",
    "start": "2054960",
    "end": "2064158"
  },
  {
    "text": "Actually when I when I made this question even I didn't realize that",
    "start": "2064159",
    "end": "2069280"
  },
  {
    "text": "that's that's huge hint here and I see okay um so the target is",
    "start": "2069280",
    "end": "2077200"
  },
  {
    "text": "large and started thinking about how to get large intermediate products use",
    "start": "2077200",
    "end": "2083480"
  },
  {
    "text": "multiplication and see uh blah blah and that's aim for products that get us",
    "start": "2083480",
    "end": "2089440"
  },
  {
    "text": "closer to the square root of 2024 which is 45 you see that and after actually I",
    "start": "2089440",
    "end": "2095679"
  },
  {
    "text": "made a cut off here the sinking is very very long that's why we did a long s in",
    "start": "2095679",
    "end": "2100880"
  },
  {
    "text": "the in the font tuning and you can find answer after",
    "start": "2100880",
    "end": "2106160"
  },
  {
    "text": "sinking the model show the final answer right they exactly followed the sinking process you see that's break down it",
    "start": "2106160",
    "end": "2113119"
  },
  {
    "text": "okay first part and 10 * 4 + 5 = 40 + 5",
    "start": "2113119",
    "end": "2119920"
  },
  {
    "text": "= 45 and the second part is also So again 45 and then 45 * 45 to get a 205",
    "start": "2119920",
    "end": "2130320"
  },
  {
    "text": "that's amazing right we don't need any",
    "start": "2130320",
    "end": "2136560"
  },
  {
    "text": "search i don't know if anyone read another paper related to chain of sword prompting it's called a chain of sword",
    "start": "2136920",
    "end": "2143560"
  },
  {
    "text": "prompting anyone read that paper great yeah in that paper actually there's a very interesting example is",
    "start": "2143560",
    "end": "2150079"
  },
  {
    "text": "game 24 this problem is way harder than game",
    "start": "2150079",
    "end": "2155160"
  },
  {
    "text": "24 in trail of sword prompting they are combine search with prompting to solve",
    "start": "2155160",
    "end": "2162240"
  },
  {
    "text": "game 24 but now you don't need that at all right the model can solve game 24",
    "start": "2162240",
    "end": "2167760"
  },
  {
    "text": "just by natural language I see that this is how I train",
    "start": "2167760",
    "end": "2172800"
  },
  {
    "text": "is so powerful it's amazing and uh again I would like to",
    "start": "2172800",
    "end": "2181119"
  },
  {
    "text": "site rich sen here you see in the uh the bit lesson right the core idea here okay",
    "start": "2181119",
    "end": "2189520"
  },
  {
    "text": "building all discoveries only makes it harder to see how the discovery process can be",
    "start": "2189520",
    "end": "2195400"
  },
  {
    "text": "done yeah that's u I think uh",
    "start": "2195400",
    "end": "2201400"
  },
  {
    "text": "Raton drew the bit lesson after he joined Google mind and he saw the",
    "start": "2201400",
    "end": "2208560"
  },
  {
    "text": "success of alpha go and alpha zero and he said okay only two process",
    "start": "2208560",
    "end": "2215520"
  },
  {
    "text": "that's uh really scalable is one is learning the other is a search and uh",
    "start": "2215520",
    "end": "2220560"
  },
  {
    "text": "but here I would like to see I only emphasize one thing learning is scalable we just need learning",
    "start": "2220560",
    "end": "2228560"
  },
  {
    "text": "yeah and um yeah for tuning okay yeah and the big",
    "start": "2232280",
    "end": "2242160"
  },
  {
    "text": "advantage is that it generalize So well um but for automatically vifable tasks",
    "start": "2242160",
    "end": "2251359"
  },
  {
    "text": "because we need vifier in the loop there's no way put him in the loop",
    "start": "2251359",
    "end": "2257240"
  },
  {
    "text": "there and of course not all tasks are",
    "start": "2257240",
    "end": "2262280"
  },
  {
    "text": "automatically verifiable h can anyone give examples nonverifiable tasks",
    "start": "2262280",
    "end": "2271400"
  },
  {
    "text": "yeah hm creative writing right yes creative writing yeah great example yeah",
    "start": "2272520",
    "end": "2279760"
  },
  {
    "text": "so yeah that's the um big restrictions for fine tuning at",
    "start": "2279760",
    "end": "2288000"
  },
  {
    "text": "this point i know so many people are really interested at creating RL algorithms to",
    "start": "2288000",
    "end": "2294240"
  },
  {
    "text": "uh improve the approach i really want to see",
    "start": "2294240",
    "end": "2299359"
  },
  {
    "text": "um see we spend more time to think about you know how to solve those",
    "start": "2299480",
    "end": "2307760"
  },
  {
    "text": "non-verr like creative writing even like a coding right I know so so people see okay coding problem will be solved by by",
    "start": "2309480",
    "end": "2317680"
  },
  {
    "text": "AI in a few years and u I think it would be very challenging to be solved right I",
    "start": "2317680",
    "end": "2324800"
  },
  {
    "text": "know Actually for they will talk about a programming they only talk about a competitive",
    "start": "2324800",
    "end": "2330119"
  },
  {
    "text": "programming competitive programming is not like our daily programming work",
    "start": "2330119",
    "end": "2335760"
  },
  {
    "text": "right so we we write code we care about your design your readability right yeah",
    "start": "2335760",
    "end": "2342079"
  },
  {
    "text": "how to collaborate with other people not just uh give a final answer",
    "start": "2342079",
    "end": "2349519"
  },
  {
    "text": "yeah yeah i have a talk about you know all the all of the ideas actually the",
    "start": "2351160",
    "end": "2356480"
  },
  {
    "text": "very beginning I talk about CT decoding okay actually the reason pass is already in the output space and all only need to",
    "start": "2356480",
    "end": "2363440"
  },
  {
    "text": "do is about decoding to uh reshape the output distribution such that great",
    "start": "2363440",
    "end": "2368800"
  },
  {
    "text": "decoding founded okay and then I talk about channel sort of prompting or less",
    "start": "2368800",
    "end": "2375200"
  },
  {
    "text": "step by step which can shape the reshape the output distribution and then SFT and",
    "start": "2375200",
    "end": "2380960"
  },
  {
    "text": "then tuning I find it is so powerful but we still have a chance to",
    "start": "2380960",
    "end": "2387560"
  },
  {
    "text": "u uh improve those process is basically I want to talk",
    "start": "2387560",
    "end": "2393760"
  },
  {
    "text": "about two uh K ideas wise aggregation the other is air",
    "start": "2393760",
    "end": "2400960"
  },
  {
    "text": "retrieval and u we have seen that am is really powerful right and but any",
    "start": "2401560",
    "end": "2408880"
  },
  {
    "text": "decoding issue in the paradigm of generating reasoning tokens and then final",
    "start": "2408880",
    "end": "2414839"
  },
  {
    "text": "answers right it seems so natural right given a problem and generating intermediate tokens and then final",
    "start": "2414839",
    "end": "2423560"
  },
  {
    "text": "answer does anyone see any problem in this process Any problem",
    "start": "2423560",
    "end": "2431079"
  },
  {
    "text": "is the design of the model the model is just designed to predict next the",
    "start": "2431680",
    "end": "2437359"
  },
  {
    "text": "challenge is the way predict next um that's that's what creates a situation",
    "start": "2437359",
    "end": "2444240"
  },
  {
    "text": "where the outcome not being aligned to the expected outcome yeah great yeah",
    "start": "2444240",
    "end": "2450560"
  },
  {
    "text": "yeah the model is um originally designed just for pretty negative tokens yeah so",
    "start": "2450560",
    "end": "2455960"
  },
  {
    "text": "yeah thanks so yeah we need to always keep in mind here that ALMs are practic",
    "start": "2455960",
    "end": "2465400"
  },
  {
    "text": "models they are not humans what does that mean",
    "start": "2465400",
    "end": "2472960"
  },
  {
    "text": "mathematically let's think about what AM does in decoding right given the problem",
    "start": "2473960",
    "end": "2480400"
  },
  {
    "text": "and generate reasoning and then final answer and then the response found by",
    "start": "2480400",
    "end": "2486480"
  },
  {
    "text": "graded decoding great what does graded decoding means a max the probability",
    "start": "2486480",
    "end": "2494200"
  },
  {
    "text": "right however for for us right we need",
    "start": "2494200",
    "end": "2499760"
  },
  {
    "text": "to argue with the maximum probability right",
    "start": "2499760",
    "end": "2505680"
  },
  {
    "text": "chose the most confident",
    "start": "2505680",
    "end": "2509040"
  },
  {
    "text": "answer so they're not aligned right there's",
    "start": "2510920",
    "end": "2516720"
  },
  {
    "text": "such a simple high school condition probability mask here but it's really useful for us to understand the decoding",
    "start": "2516720",
    "end": "2526559"
  },
  {
    "text": "process and we can let's fix it right we just need one step further okay if we",
    "start": "2527000",
    "end": "2533359"
  },
  {
    "text": "generate reasoning pass we should sum over all reasoning",
    "start": "2533359",
    "end": "2539720"
  },
  {
    "text": "pass to find the probability of the final answer in terms of machine learning is",
    "start": "2539720",
    "end": "2546720"
  },
  {
    "text": "called marginalization sum of all because all the reason parts actually essentially are just latent",
    "start": "2546720",
    "end": "2554359"
  },
  {
    "text": "variables and uh of course if you reverse start machine learning and they",
    "start": "2554359",
    "end": "2560160"
  },
  {
    "text": "will know actually this the the sum can be computed by",
    "start": "2560160",
    "end": "2566880"
  },
  {
    "text": "sampling and then uh once you got this idea and you see okay that's exactly the",
    "start": "2570680",
    "end": "2576760"
  },
  {
    "text": "motivation underlying or another proper approach is called self-consistency so generate multiple",
    "start": "2576760",
    "end": "2584240"
  },
  {
    "text": "response by random sampling and then choose the answer that",
    "start": "2584240",
    "end": "2589680"
  },
  {
    "text": "appears most",
    "start": "2589680",
    "end": "2592880"
  },
  {
    "text": "frequently so let me uh show a simple example here for this math problem you",
    "start": "2597240",
    "end": "2603240"
  },
  {
    "text": "know and you could sample the response many times for the first response you",
    "start": "2603240",
    "end": "2608800"
  },
  {
    "text": "will get I say $18 and for the second one you will get",
    "start": "2608800",
    "end": "2614200"
  },
  {
    "text": "$26 and again you will get $18 right and then we look at the final answer right",
    "start": "2614200",
    "end": "2622640"
  },
  {
    "text": "and um then choose the most frequent one right that's exactly",
    "start": "2622640",
    "end": "2631160"
  },
  {
    "text": "the process implementing marginalization",
    "start": "2631160",
    "end": "2638359"
  },
  {
    "text": "improbability we uh don't look at the reasoning pass we only choose the most",
    "start": "2638359",
    "end": "2644400"
  },
  {
    "text": "frequent answer not most frequently reasoning pass that's the trick that's",
    "start": "2644400",
    "end": "2651040"
  },
  {
    "text": "called marginization in",
    "start": "2651040",
    "end": "2654640"
  },
  {
    "text": "empirically and if you apply this approach you can see a huge improvement",
    "start": "2656520",
    "end": "2663520"
  },
  {
    "text": "that's really surprising i know in the kind days you have to um you may think okay if you got want to get a huge",
    "start": "2663520",
    "end": "2669040"
  },
  {
    "text": "improvement you probably need to spend a lot of time to build a sufficated mass",
    "start": "2669040",
    "end": "2674200"
  },
  {
    "text": "formulations we don't have to so um for uh GSMK problems",
    "start": "2674200",
    "end": "2682599"
  },
  {
    "text": "um we um we can see that right even for fine",
    "start": "2683160",
    "end": "2688480"
  },
  {
    "text": "tune GD3 models they used um they could access 33% and then open used verifier",
    "start": "2688480",
    "end": "2695440"
  },
  {
    "text": "to get actually 55% and use P model plus COT we get accuracy",
    "start": "2695440",
    "end": "2702200"
  },
  {
    "text": "58% that's amazing doesn't match the performance from the",
    "start": "2702200",
    "end": "2707400"
  },
  {
    "text": "vifier and however the most surprising thing is after applying self consistency",
    "start": "2707400",
    "end": "2713440"
  },
  {
    "text": "the accuracy jumped to 75% the relative accur relative improvement is nearly",
    "start": "2713440",
    "end": "2719960"
  },
  {
    "text": "50% and use palm two we even get an accuracy 92%",
    "start": "2719960",
    "end": "2726200"
  },
  {
    "text": "and of course one may say okay yeah that's for pi models is you know the model for many for years sounds like 10",
    "start": "2731119",
    "end": "2739040"
  },
  {
    "text": "years ago because in the current days um every year just like one decade the",
    "start": "2739040",
    "end": "2744240"
  },
  {
    "text": "whole field is moving so fast actually if you look at the",
    "start": "2744240",
    "end": "2750240"
  },
  {
    "text": "um 01 model I forgot when uh OPI released 01",
    "start": "2750680",
    "end": "2756720"
  },
  {
    "text": "models probably uh October last year right yeah and uh actually they also",
    "start": "2756720",
    "end": "2764560"
  },
  {
    "text": "showed the results by aggregation see that consensus at 664 use and then we",
    "start": "2764560",
    "end": "2770880"
  },
  {
    "text": "still see a great improvement by aggregation or self",
    "start": "2770880",
    "end": "2777520"
  },
  {
    "text": "consensus by self and and uh use more samples will be more expensive but use",
    "start": "2794200",
    "end": "2799760"
  },
  {
    "text": "more tokens and uh people see that's kind of uh inference time scaling",
    "start": "2799760",
    "end": "2807240"
  },
  {
    "text": "yeah there are so many ways for infant time inference time scaling if you use a longer s also increase inference time so",
    "start": "2807240",
    "end": "2816400"
  },
  {
    "text": "actually when some people told me told me told me about infant time scaling really I don't know what they exactly",
    "start": "2816400",
    "end": "2823680"
  },
  {
    "text": "means unless they completely see what's what's scaled yeah and the self con is",
    "start": "2823680",
    "end": "2830720"
  },
  {
    "text": "definitely a way to scale up",
    "start": "2830720",
    "end": "2835359"
  },
  {
    "text": "yeah and uh and also self consistency is a is naturally",
    "start": "2836920",
    "end": "2845520"
  },
  {
    "text": "uh selfc calibrated um higher consistency",
    "start": "2845520",
    "end": "2850880"
  },
  {
    "text": "indicates higher accuracy is for GSMK benchmark actually",
    "start": "2850880",
    "end": "2856400"
  },
  {
    "text": "when the self consist consistency is more than 80% the accuracy is nearly",
    "start": "2856400",
    "end": "2862160"
  },
  {
    "text": "100% so I know um people some people care",
    "start": "2862160",
    "end": "2867680"
  },
  {
    "text": "about uncertainty or confidence on in prediction and they can can just simply",
    "start": "2867680",
    "end": "2872880"
  },
  {
    "text": "try uh sampling multiple",
    "start": "2872880",
    "end": "2876960"
  },
  {
    "text": "times and I have two short question here so to make sure everyone got the",
    "start": "2878599",
    "end": "2886319"
  },
  {
    "text": "really uh key ideas in self consistency I hope you know how to yeah you you",
    "start": "2886319",
    "end": "2891680"
  },
  {
    "text": "really find a lot of fun use this simple idea so the first question say okay when",
    "start": "2891680",
    "end": "2897200"
  },
  {
    "text": "the LM outputs a direct answer without intermediate steps we use sample several",
    "start": "2897200",
    "end": "2904599"
  },
  {
    "text": "times and then choose the most common answer will",
    "start": "2904599",
    "end": "2910520"
  },
  {
    "text": "you does anyone have answer",
    "start": "2910520",
    "end": "2915040"
  },
  {
    "text": "here if the model just directly generate final answer what do we do",
    "start": "2915640",
    "end": "2922680"
  },
  {
    "text": "yeah go ahead this is like like you can just get probabilities",
    "start": "2923119",
    "end": "2930240"
  },
  {
    "text": "exactly yes exactly exactly just like exactly what",
    "start": "2930240",
    "end": "2935760"
  },
  {
    "text": "we did in the classical machine learning right we have use logistic regression to",
    "start": "2935760",
    "end": "2941280"
  },
  {
    "text": "get a py given x we just need to maximize the probability there that's",
    "start": "2941280",
    "end": "2948680"
  },
  {
    "text": "why we uh couldn't see self consistency in the old machine learning literature",
    "start": "2948680",
    "end": "2955040"
  },
  {
    "text": "is unnecessary it's only useful for reasoning that's why we see it",
    "start": "2955040",
    "end": "2962200"
  },
  {
    "text": "here after we of reasoning and then we need self-consistency",
    "start": "2962200",
    "end": "2967960"
  },
  {
    "text": "yeah and the second question is change self-consistency by letting alms",
    "start": "2967960",
    "end": "2973119"
  },
  {
    "text": "generate multiple response instead of sampling multiple times and then",
    "start": "2973119",
    "end": "2978240"
  },
  {
    "text": "choosing the most common answer does this make sense right you can see J model generate",
    "start": "2978240",
    "end": "2986079"
  },
  {
    "text": "five answers instead of a sample five",
    "start": "2986079",
    "end": "2990880"
  },
  {
    "text": "times right yeah there actually we can try that and um again you know for",
    "start": "2991559",
    "end": "2999839"
  },
  {
    "text": "everything we just need to follow the machine learning principle it actually this principle is",
    "start": "2999839",
    "end": "3005520"
  },
  {
    "text": "called um um max marginal um inference yeah you",
    "start": "3005520",
    "end": "3013680"
  },
  {
    "text": "just need to choose the final answer with maximum probability that's all we need to know you don't have to think",
    "start": "3013680",
    "end": "3019440"
  },
  {
    "text": "about any fancy things about LMS don't have to compare with humans you know",
    "start": "3019440",
    "end": "3025119"
  },
  {
    "text": "math is all we need here and one can naturally um of course",
    "start": "3025119",
    "end": "3032240"
  },
  {
    "text": "self has a problem you see the unique answer right you check the um frequency of the unique answer and um for general",
    "start": "3032240",
    "end": "3041000"
  },
  {
    "text": "problems it's hard to see uh the um answer will be by a single token and for",
    "start": "3041000",
    "end": "3047440"
  },
  {
    "text": "example for this problem you will see um all answers are different okay in this",
    "start": "3047440",
    "end": "3054880"
  },
  {
    "text": "case uh we have extension about self-consistency is called universal",
    "start": "3054880",
    "end": "3061640"
  },
  {
    "text": "self-consistency and for this problem here you can see um the second response is the most",
    "start": "3061640",
    "end": "3067920"
  },
  {
    "text": "common one Japan China and India because all these three countries are in all are",
    "start": "3067920",
    "end": "3074160"
  },
  {
    "text": "in all other answers right and we just need to let LMS choose the most",
    "start": "3074160",
    "end": "3081680"
  },
  {
    "text": "consistent response okay I have talked about how to use",
    "start": "3081680",
    "end": "3087040"
  },
  {
    "text": "aggregation to improve reasoning um the other way is about",
    "start": "3087040",
    "end": "3094599"
  },
  {
    "text": "retrieval so I know there's another a lot of debate about reasoning say people say okay may not just do retrieval",
    "start": "3094599",
    "end": "3102400"
  },
  {
    "text": "instead of reasoning i know many people um I saw",
    "start": "3102400",
    "end": "3107920"
  },
  {
    "text": "that debates in the social media um actually to me it's very it's always",
    "start": "3107920",
    "end": "3115359"
  },
  {
    "text": "hard to differentiate uh retrie and reasoning and when I",
    "start": "3115359",
    "end": "3122359"
  },
  {
    "text": "I chair for all the conference almost every year and have talk about the",
    "start": "3122359",
    "end": "3129680"
  },
  {
    "text": "novelty of each paper and actually is similar to the debate is",
    "start": "3129680",
    "end": "3136240"
  },
  {
    "text": "retrieval reasoning right yeah similar to",
    "start": "3136240",
    "end": "3141480"
  },
  {
    "text": "concept I sort of try an experiment trying different models to run parallel",
    "start": "3141480",
    "end": "3146880"
  },
  {
    "text": "and then running parall they may have literally like running the same concurrenly with",
    "start": "3146880",
    "end": "3153839"
  },
  {
    "text": "running GM 2.5 like four different models in parallel for the same question then at",
    "start": "3153839",
    "end": "3160640"
  },
  {
    "text": "the end just having like a verifier so find the most consistent result",
    "start": "3160640",
    "end": "3166839"
  },
  {
    "text": "um yes uh yes if you are generate",
    "start": "3166839",
    "end": "3171920"
  },
  {
    "text": "response from different models that will be more like theam model exampling",
    "start": "3171920",
    "end": "3177599"
  },
  {
    "text": "approach with many models and command results like a random forest yes yeah",
    "start": "3177599",
    "end": "3183119"
  },
  {
    "text": "the mathematical principle is not exactly the same as self-consistency but the implementation are the same yes yeah",
    "start": "3183119",
    "end": "3191200"
  },
  {
    "text": "great point and yeah about actually again I'm not",
    "start": "3191200",
    "end": "3198559"
  },
  {
    "text": "interested in debate about retrieval revenue and for people working on actually I'm I work industry I really",
    "start": "3198559",
    "end": "3205280"
  },
  {
    "text": "just care about performance so to me you know just do retrieval plus reason why I",
    "start": "3205280",
    "end": "3211280"
  },
  {
    "text": "should do the debate right yeah",
    "start": "3211280",
    "end": "3215800"
  },
  {
    "text": "um so in 2024 we have a paper about analogical reasoning so I can just use",
    "start": "3219000",
    "end": "3225200"
  },
  {
    "text": "this small example to show why retrieval is important in reasoning okay so for this problem see what's the",
    "start": "3225200",
    "end": "3233040"
  },
  {
    "text": "area of the square with the four vertices blah blah blah and okay the uh",
    "start": "3233040",
    "end": "3238640"
  },
  {
    "text": "the red the highlighted text uh is added by me and say okay it's a",
    "start": "3238640",
    "end": "3245359"
  },
  {
    "text": "prompt okay we call a rated problem and then solve this one",
    "start": "3245359",
    "end": "3251119"
  },
  {
    "text": "so at that moment I tried a GPT 3.5 and also our own model and uh they failed",
    "start": "3251119",
    "end": "3259839"
  },
  {
    "text": "solving this problem after adding this after adding the prompt of record uh",
    "start": "3259839",
    "end": "3266319"
  },
  {
    "text": "record recalling a related problems and the model has solve it right let's see",
    "start": "3266319",
    "end": "3271359"
  },
  {
    "text": "what happened here after tell the model to record",
    "start": "3271359",
    "end": "3276559"
  },
  {
    "text": "related problems and the model did Find a related problem related problem",
    "start": "3276559",
    "end": "3283040"
  },
  {
    "text": "doesn't mean the same problem it's indeed just a related problem you see the related problem here is finding the",
    "start": "3283040",
    "end": "3290000"
  },
  {
    "text": "distance between two points on a coordinate plan and this a formula there",
    "start": "3290000",
    "end": "3296160"
  },
  {
    "text": "and then the model oh yeah now I know how to compute the distance and then how to compute the",
    "start": "3296160",
    "end": "3302280"
  },
  {
    "text": "area that's just a small case to show how retrieval is important in",
    "start": "3302280",
    "end": "3308359"
  },
  {
    "text": "reasoning here's another example called uh uh step back for the physical",
    "start": "3308359",
    "end": "3316920"
  },
  {
    "text": "problems and before solving this problem we just let a model you yeah just give",
    "start": "3316920",
    "end": "3322319"
  },
  {
    "text": "we just give few short examples show model okay before solving this problem you can make a step back to sol to",
    "start": "3322319",
    "end": "3328640"
  },
  {
    "text": "consider more abstract problem get the principle and then solve it",
    "start": "3328640",
    "end": "3335680"
  },
  {
    "text": "Okay that's how a retrieval works for reasoning and uh as now everyone knows",
    "start": "3338839",
    "end": "3347200"
  },
  {
    "text": "deep research deep research exactly the same idea here right",
    "start": "3347200",
    "end": "3354040"
  },
  {
    "text": "um so we have a gymnast deep research and also um open",
    "start": "3354040",
    "end": "3360440"
  },
  {
    "text": "research and one of uh OPI as a deep research lead is was my intern and uh",
    "start": "3360440",
    "end": "3368799"
  },
  {
    "text": "and after his PD and he joined OPI and he invented deep research",
    "start": "3368799",
    "end": "3376160"
  },
  {
    "text": "yeah and you see that how the deep research works because they can find a",
    "start": "3376839",
    "end": "3382000"
  },
  {
    "text": "similar problem or knowledge to solve the problem yeah the basic idea is very",
    "start": "3382000",
    "end": "3389119"
  },
  {
    "text": "simple yeah now I can uh give a summary here actually you know forget about",
    "start": "3391240",
    "end": "3396960"
  },
  {
    "text": "those debate if can reason or not forms reasoning is always better than no",
    "start": "3396960",
    "end": "3403640"
  },
  {
    "text": "reasoning and uh a tuning is better than sftt aggregating multiple answers it's",
    "start": "3403640",
    "end": "3411119"
  },
  {
    "text": "better than one answer of course that will be more costly and uh retrieval plus reasoning",
    "start": "3411119",
    "end": "3416960"
  },
  {
    "text": "is better than uh reason only and Um yeah that's um the end of my",
    "start": "3416960",
    "end": "3425240"
  },
  {
    "text": "talk and for the next breakthroughs you know I know you I really want to see",
    "start": "3425240",
    "end": "3430960"
  },
  {
    "text": "okay how to solve the task beyond unique verifiable answers and in the kind of days and I",
    "start": "3430960",
    "end": "3438400"
  },
  {
    "text": "also want to see how uh people build real applications",
    "start": "3438400",
    "end": "3443760"
  },
  {
    "text": "uh instead of just solving benchmarks I think all benchmarks will be saturated soon",
    "start": "3443760",
    "end": "3451160"
  },
  {
    "text": "yeah and um I know you know all you guys are very",
    "start": "3451160",
    "end": "3456480"
  },
  {
    "text": "passionate about AGI or builds i would like to u quote Richard Fman's um",
    "start": "3456480",
    "end": "3463599"
  },
  {
    "text": "um here the truth always turn out to be simple than you thought and uh I think",
    "start": "3463599",
    "end": "3471440"
  },
  {
    "text": "that's a particular true for every research and I saw so many academic",
    "start": "3471440",
    "end": "3476799"
  },
  {
    "text": "papers always try complicated many things uh so that's why I just came my talk as simple as possible as actually",
    "start": "3476799",
    "end": "3483920"
  },
  {
    "text": "it's indeed simple that's it yeah thank you",
    "start": "3483920",
    "end": "3489400"
  },
  {
    "text": "thanks Danny for the very um insightful as well as interesting talk so now we'll be taking questions um we have some",
    "start": "3498319",
    "end": "3504960"
  },
  {
    "text": "questions online from Slido and Zoom but also in person so we can maybe start with some in-person questions",
    "start": "3504960",
    "end": "3513318"
  },
  {
    "text": "hi um thank you for the talk um so earlier on in the lecture you talked about confidence um and like a common",
    "start": "3514480",
    "end": "3521599"
  },
  {
    "text": "way to do this is like just taking the average log probabilities of output token sequences um so like my question",
    "start": "3521599",
    "end": "3529040"
  },
  {
    "text": "is do you think there are better ways to do this and also is this a good indicator um for",
    "start": "3529040",
    "end": "3535079"
  },
  {
    "text": "hallucinations oh for the first slide when I talk about confidence just not aggregation just just the pability for",
    "start": "3535079",
    "end": "3542400"
  },
  {
    "text": "necro prediction just a conditional probability for the generation yeah mhm",
    "start": "3542400",
    "end": "3549520"
  },
  {
    "text": "you can just look the local props from the model and see uh and you can see the",
    "start": "3549520",
    "end": "3554559"
  },
  {
    "text": "uh probability yeah yeah um and like do you think this is a good indicator for hallucinations",
    "start": "3554559",
    "end": "3560960"
  },
  {
    "text": "and yeah same so yeah from our empirical observation yeah and we can see after",
    "start": "3560960",
    "end": "3568480"
  },
  {
    "text": "recent past there's uh there's a huge jump on confidence for the final answer",
    "start": "3568480",
    "end": "3574960"
  },
  {
    "text": "yeah",
    "start": "3574960",
    "end": "3577960"
  },
  {
    "text": "hello um earlier you mentioned that um for example Richard Sutton said that uh",
    "start": "3584160",
    "end": "3590240"
  },
  {
    "text": "it's uh scaling learning and search and you um your opinion is more like scaling",
    "start": "3590240",
    "end": "3596880"
  },
  {
    "text": "learning is all you need i just like to uh expand more on that and uh why you",
    "start": "3596880",
    "end": "3602079"
  },
  {
    "text": "believe that uh search is not as necessary uh that's why I used that example and",
    "start": "3602079",
    "end": "3608559"
  },
  {
    "text": "actually um okay so actually I should make it more concrete when you build a models",
    "start": "3608559",
    "end": "3615599"
  },
  {
    "text": "you don't have to keep search in mind but in the after model is built and you",
    "start": "3615599",
    "end": "3621040"
  },
  {
    "text": "can use search as a tour as a special case of tool use like",
    "start": "3621040",
    "end": "3627280"
  },
  {
    "text": "a trail sort prompting they can just integrate symbolic search with the",
    "start": "3627280",
    "end": "3633400"
  },
  {
    "text": "model Yeah so but for reasoning research I just care about the fundamental",
    "start": "3633400",
    "end": "3640599"
  },
  {
    "text": "abilities yeah for example if you want to solve this problem the model the model could be motivated to write a",
    "start": "3640599",
    "end": "3647280"
  },
  {
    "text": "python program to uh to solve those problems by search but for the reasoning",
    "start": "3647280",
    "end": "3652960"
  },
  {
    "text": "process we don't need to search just um how to say it of course we can always",
    "start": "3652960",
    "end": "3661520"
  },
  {
    "text": "search everything that's why if you use a search to solve any problems you can get a higher accuracy and um I don't",
    "start": "3661520",
    "end": "3668400"
  },
  {
    "text": "know that really depends what you want intelligence or just by search yeah hi",
    "start": "3668400",
    "end": "3674240"
  },
  {
    "text": "thank you for the talk um you mentioned in the case where there's no reasoning that it's not necessary to sample",
    "start": "3674240",
    "end": "3679920"
  },
  {
    "text": "because you can simply look at the loits but wouldn't sampling converge on a different distribution in the case for",
    "start": "3679920",
    "end": "3686160"
  },
  {
    "text": "example where the most likely next token leads to a diffuse distribution for the following token and the different paths",
    "start": "3686160",
    "end": "3692720"
  },
  {
    "text": "spread out whereas if you were to sample and a less likely token were to lead to a sharper distribution you could",
    "start": "3692720",
    "end": "3698559"
  },
  {
    "text": "actually have a more likely path of tokens there so wouldn't these two methods fundamentally differ",
    "start": "3698559",
    "end": "3706760"
  },
  {
    "text": "um good question yeah the problem is actually we still don't know how the distribution are reshaped during the",
    "start": "3706760",
    "end": "3714559"
  },
  {
    "text": "training stage it's very unclear there yeah so it's to me it's very hard to",
    "start": "3714559",
    "end": "3720720"
  },
  {
    "text": "answer this question but we still don't have",
    "start": "3720720",
    "end": "3726000"
  },
  {
    "text": "um good explanation all those distribution are received for the final distribution yeah thank you",
    "start": "3726000",
    "end": "3735480"
  },
  {
    "text": "hi thank you for the talk so how to differentiate um reasoning and answer like do you need",
    "start": "3735839",
    "end": "3743119"
  },
  {
    "text": "to extract that number from the tokens from the final uh strings the output",
    "start": "3743119",
    "end": "3749160"
  },
  {
    "text": "string and what if the answer can be like a program then how to differentiate the",
    "start": "3749160",
    "end": "3756160"
  },
  {
    "text": "reasoning and the answer yeah great question um yeah if the if I say is a is a",
    "start": "3756160",
    "end": "3764160"
  },
  {
    "text": "program and uh will be harder to extract will be harder to so when people use a",
    "start": "3764160",
    "end": "3772400"
  },
  {
    "text": "fine tuning and that's why you just see those guys are to mass problems or",
    "start": "3772400",
    "end": "3778400"
  },
  {
    "text": "competitive programming problems yeah so I think for your for the general case",
    "start": "3778400",
    "end": "3784160"
  },
  {
    "text": "you have for your case you have to write a very careful uh parer for the final",
    "start": "3784160",
    "end": "3790400"
  },
  {
    "text": "answer yeah I see um and also what if the problem is very challenging so um",
    "start": "3790400",
    "end": "3797520"
  },
  {
    "text": "such that actually the lower confidence answer might be the correct answer",
    "start": "3797520",
    "end": "3803039"
  },
  {
    "text": "because possible yeah yes then how can I use the",
    "start": "3803039",
    "end": "3808119"
  },
  {
    "text": "self-consistency method self consens done right yeah not perfect",
    "start": "3808119",
    "end": "3816240"
  },
  {
    "text": "all right okay thank you so considering that you know conversations that AGI is",
    "start": "3816240",
    "end": "3821359"
  },
  {
    "text": "coming you know like from two to five years from now how and basically if we",
    "start": "3821359",
    "end": "3827520"
  },
  {
    "text": "you know if it's true then let's say 90% of jobs automated what skills do you you",
    "start": "3827520",
    "end": "3834240"
  },
  {
    "text": "know develop in kids to give them a shot to survive in the future that is coming",
    "start": "3834240",
    "end": "3839680"
  },
  {
    "text": "that's a big question who said a will come in five years",
    "start": "3839680",
    "end": "3846119"
  },
  {
    "text": "i mean there's AI 2027 right by Danielo uh like lots of conversations in",
    "start": "3846240",
    "end": "3852720"
  },
  {
    "text": "AI community that given like the timeline of like two to five years",
    "start": "3852720",
    "end": "3858240"
  },
  {
    "text": "i was in u I clear last year there was a workshop",
    "start": "3858240",
    "end": "3867119"
  },
  {
    "text": "and I remember um one audience asked me a question in the panelist and he said okay and AI is",
    "start": "3867119",
    "end": "3875680"
  },
  {
    "text": "a point is is is moving so fast the failed you know",
    "start": "3875680",
    "end": "3881039"
  },
  {
    "text": "and what would be the most scary thing in in the in the f in the next few",
    "start": "3881039",
    "end": "3888440"
  },
  {
    "text": "years and uh yeah I I remember some people did talk about the the risk of AI",
    "start": "3888440",
    "end": "3894559"
  },
  {
    "text": "and But my answer is to me most guys thing is yeah I",
    "start": "3894559",
    "end": "3900799"
  },
  {
    "text": "wouldn't come back and then I lost my",
    "start": "3900799",
    "end": "3905960"
  },
  {
    "text": "job uh actually I I saw many restrictions for the kind of",
    "start": "3905960",
    "end": "3912200"
  },
  {
    "text": "approach so um I I actually um I know many people like the chat boards sort of",
    "start": "3912200",
    "end": "3919839"
  },
  {
    "text": "things i really actually really want to see real killer applications from the",
    "start": "3919839",
    "end": "3925119"
  },
  {
    "text": "kind of AI research um I don't know if anyone really need",
    "start": "3925119",
    "end": "3930960"
  },
  {
    "text": "those AI stuff or model just for fun yeah I'm not quite sure about that i know actually the AI models is really",
    "start": "3930960",
    "end": "3938160"
  },
  {
    "text": "good for programming yeah can be a good assistant for coding and uh that's all I",
    "start": "3938160",
    "end": "3945039"
  },
  {
    "text": "know about that yeah we should be fine",
    "start": "3945039",
    "end": "3951359"
  },
  {
    "text": "okay I think we're out of time um but thanks everybody for your great",
    "start": "3952880",
    "end": "3958240"
  },
  {
    "text": "questions and thanks again to Denny for the great talk",
    "start": "3958240",
    "end": "3963880"
  }
]
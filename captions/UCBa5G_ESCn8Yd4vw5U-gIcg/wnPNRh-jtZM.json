[
  {
    "start": "0",
    "end": "10710"
  },
  {
    "text": "Today, I'm going to\nbe talking about how we can leverage foundation\nmodels for robotics and get the best\nout of both of them.",
    "start": "10710",
    "end": "18180"
  },
  {
    "text": "To start to motivate, I'm\ngoing to do a brief demo. So, essentially, right\nnow, we have a robot.",
    "start": "18180",
    "end": "26099"
  },
  {
    "text": "This is running in\nNew York right now. And it's got a\nlanguage model that's",
    "start": "26100",
    "end": "31123"
  },
  {
    "text": "essentially going to command\nwhat the robot's going to do. It writes code out. And then the robot\nexecutes the code.",
    "start": "31123",
    "end": "37590"
  },
  {
    "text": "And it's, basically,\nwill read my chat and then put it on there. So to start, I\nguess, Mark, what's",
    "start": "37590",
    "end": "44970"
  },
  {
    "text": "your favorite color\nof these bowls? And what candy would you like? I like the green bowl.",
    "start": "44970",
    "end": "51540"
  },
  {
    "text": "And what do you have there? Skittles? Yeah. ",
    "start": "51540",
    "end": "57900"
  },
  {
    "text": "So I don't know if\nyou can see this OK. I can make it a little bigger. And then we'll see.",
    "start": "57900",
    "end": "63660"
  },
  {
    "text": "And the robot says, OK. And you want some skittles. Sure. ",
    "start": "63660",
    "end": "76630"
  },
  {
    "text": "So one really nice thing\nabout language models is, essentially, they\nact as this knowledge",
    "start": "76630",
    "end": "82300"
  },
  {
    "text": "base of even very esoteric\nthings like the Skittles are tasting the rainbow.",
    "start": "82300",
    "end": "88030"
  },
  {
    "text": "And you can see the robot\nactually doing it is over here. And this is the\nrobot's view here. And I just said,\nI'll take Reese's.",
    "start": "88030",
    "end": "94329"
  },
  {
    "text": "And it remembers from\nbefore that I just said which bowl is which,\nwho does it belong to. And, again, you get this\nvery abstract knowledge",
    "start": "94330",
    "end": "102909"
  },
  {
    "text": "that tasting the\nrainbow means Skittles. You can also do things like-- ",
    "start": "102910",
    "end": "112567"
  },
  {
    "text": "And I feel when we first started\nplaying with language models, this was something that\nwas like, I don't know, really impressive to us.",
    "start": "112567",
    "end": "118150"
  },
  {
    "text": "That I can just say put them\nall in different corners. And it understands that means\nthat not the same corners. It understands what the\ncorners are and knows",
    "start": "118150",
    "end": "124930"
  },
  {
    "text": "what all the candies are. And it's able to\nloop through this. This was something that--",
    "start": "124930",
    "end": "130690"
  },
  {
    "text": "I don't know-- about\na year ago blew our mind that this is possible. So I think it\nmight have missed--",
    "start": "130690",
    "end": "137590"
  },
  {
    "text": "I think because they're\nin the same bowl, it put the Reese's on\ntop of the Skittles.",
    "start": "137590",
    "end": "142630"
  },
  {
    "text": "And then did that. So this is one area\nthat we're trying to fix is that sometimes this\ngrounding between the code",
    "start": "142630",
    "end": "148793"
  },
  {
    "text": "or the language model. The fact that it\ncan't see things means that it makes\nsimple mistakes like this. And I'll talk through why this\nis a big problem in robotics",
    "start": "148793",
    "end": "157300"
  },
  {
    "text": "and where we're going\nto go to fix it. So let's see. What else can I do?",
    "start": "157300",
    "end": "162625"
  },
  {
    "start": "162625",
    "end": "170830"
  },
  {
    "text": "So something like put the M&M's\nin the center of the bowls. And this is actually like-- so, essentially,\nthis would just knows",
    "start": "170830",
    "end": "176590"
  },
  {
    "text": "that the center is the middle. And then, let's say-- ",
    "start": "176590",
    "end": "186150"
  },
  {
    "text": "So something like,\nmaking a line is also a somewhat abstract concept. It really requires you\nto understand the way",
    "start": "186150",
    "end": "191910"
  },
  {
    "text": "that geometry works. And you can-- the code\nis maybe hard to see.",
    "start": "191910",
    "end": "198810"
  },
  {
    "text": "But, essentially, it\nshould output something. It missed the Reese's,\nbecause I think",
    "start": "198810",
    "end": "204210"
  },
  {
    "text": "it's too far off the screen. But what I wanted to do was put\nthe Reese's in the initial spot.",
    "start": "204210",
    "end": "211500"
  },
  {
    "text": "I think it actually got the\nM&Ms in between the Skittles. And then the Reese's is so off\nthat it's fallen off the table.",
    "start": "211500",
    "end": "217230"
  },
  {
    "text": "But, essentially, it actually\nunderstood what's there. And it wrote code\nto be able to do some abstract geometric\nreasoning like this.",
    "start": "217230",
    "end": "224160"
  },
  {
    "text": "And it's not we've trained\nthis or shown it anything. This is just falling directly\nout of the language model.",
    "start": "224160",
    "end": "231750"
  },
  {
    "text": "Let's say, move the-- ",
    "start": "231750",
    "end": "237990"
  },
  {
    "text": "So something also like,\nmove the M&M down. It has to understand that\nthe direction of down is",
    "start": "237990",
    "end": "245490"
  },
  {
    "text": "in the negative y direction. And wait until that updates.",
    "start": "245490",
    "end": "251263"
  },
  {
    "text": "And it's able to\nsuccessfully move that. And then-- ",
    "start": "251263",
    "end": "257690"
  },
  {
    "text": "And something, like, move\nthem a little bit up requires you to not only understand\ngeneral geometry,",
    "start": "257690",
    "end": "264710"
  },
  {
    "text": "but also that a little\nbit is not all the way up. It's part of the way. And let's see, if move--",
    "start": "264710",
    "end": "270710"
  },
  {
    "start": "270710",
    "end": "276560"
  },
  {
    "text": "And then we can actually\nget some memory out of this that it remembers that\nbefore it put them here. And so to put it back is just\nto recall the last command",
    "start": "276560",
    "end": "284630"
  },
  {
    "text": "that it did. And then execute it again. ",
    "start": "284630",
    "end": "289689"
  },
  {
    "text": "Essentially, I'm going\nto talk through how we've gotten to this\npoint and some directions",
    "start": "289690",
    "end": "294699"
  },
  {
    "text": "forward that we've been looking\nat to expand beyond this, to fix some of the issues when it\npicked up the wrong thing",
    "start": "294700",
    "end": "299949"
  },
  {
    "text": "or didn't do exactly\nwhat we expected. So to start, this is all\nabout foundation models.",
    "start": "299950",
    "end": "306033"
  },
  {
    "text": "And the main idea\nhere is that you take the vast trove of\ninformation on the internet, throw them through\na transformer.",
    "start": "306033",
    "end": "313060"
  },
  {
    "text": "And we get\nperformance out of it. As roboticists, the fact that\nwe get this general performance",
    "start": "313060",
    "end": "319990"
  },
  {
    "text": "without having to do any work or\ncollect data is really magical. I think a lot of times, this\ntakes a lot of work for us",
    "start": "319990",
    "end": "326020"
  },
  {
    "text": "to collect the amount\nof data that was just given to us for free from here. So we should really strive to\nfigure out how to use them.",
    "start": "326020",
    "end": "331870"
  },
  {
    "text": "And these capabilities\nare shooting up starting from\nlanguage models that were able to answer\ntrivia or explain jokes.",
    "start": "331870",
    "end": "339010"
  },
  {
    "text": "We can also now generate images. We can answer questions about\nimages and do these VQA tasks.",
    "start": "339010",
    "end": "345370"
  },
  {
    "text": "And we can even hear\naudio and directly map it through a foundation model\nto get the text out of it.",
    "start": "345370",
    "end": "350580"
  },
  {
    "text": "And the real thing is that\nall of these performances, they're great as they are. And they're continuing\nto improve and improve,",
    "start": "350580",
    "end": "356420"
  },
  {
    "text": "and to become more\nand more general. Robot learning,\non the other hand, has, historically\nbeen in these domains.",
    "start": "356420",
    "end": "362990"
  },
  {
    "text": "So really constrained\nenvironments. We have these easy resets\nso that it can collect data.",
    "start": "362990",
    "end": "369139"
  },
  {
    "text": "It can close these\ntwo bins so that it moves one thing from another. It's got very short horizon\ntasks of pick and place.",
    "start": "369140",
    "end": "376550"
  },
  {
    "text": "It's got a structured tasks. And the robots aren't\nreally moving around, if we're doing any\nmobile manipulation.",
    "start": "376550",
    "end": "382280"
  },
  {
    "text": "It's usually at a\nvery limited scale. So we want to put robots on\nthis wave of foundation models",
    "start": "382280",
    "end": "389120"
  },
  {
    "text": "and see how much can we\nget for free without having the robots having to experience\nthe world from foundation",
    "start": "389120",
    "end": "394669"
  },
  {
    "text": "models. And so there are some\nareas of natural overlap. For example, the reasoning\ncapabilities of language models",
    "start": "394670",
    "end": "400377"
  },
  {
    "text": "are super important. There's this, I guess,\ngeneral knowledge that's in there that is\nimportant for a robot",
    "start": "400377",
    "end": "406280"
  },
  {
    "text": "to act in the world. There's also a lot\nof semantic knowledge of how things map to each other,\nwhat order to do things in.",
    "start": "406280",
    "end": "413477"
  },
  {
    "text": "These are things that\ntraditionally robotics has really struggled with. But there's actually\na lot more challenges",
    "start": "413477",
    "end": "418850"
  },
  {
    "text": "than there really\nare areas of overlap. I think in some\nways, other fields have been very\nquickly revolutionized",
    "start": "418850",
    "end": "425630"
  },
  {
    "text": "by having foundation models\nbe able to solve them. Robotics, on the other hand,\nhas all challenges, like,",
    "start": "425630",
    "end": "431000"
  },
  {
    "text": "just general grounding. You need to know what your\nrobot is capable of, what the environment has. A language model\ncan't see anything.",
    "start": "431000",
    "end": "437900"
  },
  {
    "text": "It's a huge gap for them. Interactive\ndecision-making-- everything",
    "start": "437900",
    "end": "443240"
  },
  {
    "text": "they've been trained on\nis this unsupervised, just internet data with\nno interaction,",
    "start": "443240",
    "end": "448639"
  },
  {
    "text": "making the wrong decision,\nmaking the right decision. This is a core part of\nrobotics that they basically",
    "start": "448640",
    "end": "455810"
  },
  {
    "text": "don't have in them. There's also,\nreally, on one side, we're all about huge\namounts of data.",
    "start": "455810",
    "end": "461547"
  },
  {
    "text": "On the other side, we have\nnot only low amounts of data, but often pretty\nlow quality of data.",
    "start": "461547",
    "end": "466700"
  },
  {
    "text": "Even the data that I'll talk\nabout that we collected later, it's all teleoperation data.",
    "start": "466700",
    "end": "472550"
  },
  {
    "text": "It's relatively slow. It's somewhat limited. So it's really hard to get this\nexpert data that we could--",
    "start": "472550",
    "end": "478639"
  },
  {
    "text": "that we got for free from\nthe internet, essentially. Vision and just general\nsensing modalities",
    "start": "478640",
    "end": "484340"
  },
  {
    "text": "are, I guess, slowly getting\nbetter in vision language models, but have\ntraditionally also not",
    "start": "484340",
    "end": "489740"
  },
  {
    "text": "been an area of strength. And then, finally, safety is\nreally important for robotics.",
    "start": "489740",
    "end": "495110"
  },
  {
    "text": "You can't make, maybe, the same\nmistakes that in language we might forgive you for making.",
    "start": "495110",
    "end": "501020"
  },
  {
    "text": "So all these mean that\nthey're not necessarily",
    "start": "501020",
    "end": "506300"
  },
  {
    "text": "naturally put together. And there's a lot of challenges\nin open areas of research to try to do this. So to first start,\nI'm going to talk",
    "start": "506300",
    "end": "513409"
  },
  {
    "text": "about how we can ground\nthese models in the world and in their environment. Then I'll talk about what\njust powered that demo,",
    "start": "513409",
    "end": "519289"
  },
  {
    "text": "this code as policies. Then I'll talk\nabout steps forward for building foundation models\nor using foundation models",
    "start": "519289",
    "end": "526610"
  },
  {
    "text": "to give new knowledge\nto robotics. And then, finally, I'll\ntalk about maybe training",
    "start": "526610",
    "end": "532160"
  },
  {
    "text": "our own foundation model\nand what that looks like. So as I said before,\na robot can't see--",
    "start": "532160",
    "end": "538550"
  },
  {
    "text": "or a language model can't see. So we imagine this task that\nyou're a language model, and you open your eyes, or\nyou can't open your eyes.",
    "start": "538550",
    "end": "546259"
  },
  {
    "text": "And you're trying to reason\nover the entire environment. Once you open it, and you\nrealize that I've asked you.",
    "start": "546260",
    "end": "551480"
  },
  {
    "text": "I've said, I've\nspilled my drink. Can you help? You realize that\nwhat's in the scene are things like a spilled\ndrink, a sponge, which",
    "start": "551480",
    "end": "558380"
  },
  {
    "text": "might be able to help. And also I've got\na lot of experience in the world of doing\ndifferent things. So as we go through,\nwe see everything",
    "start": "558380",
    "end": "566209"
  },
  {
    "text": "that's where I might want\nto throw that away, what the gripper looks like\nin the embodiment. And then also in the past, I've\nbeen able to do things, like,",
    "start": "566210",
    "end": "573723"
  },
  {
    "text": "pick up these objects. So this is all crucial\nto the embodiment. It's both what you can do. And it's what's in\nthe environment.",
    "start": "573723",
    "end": "579800"
  },
  {
    "text": "And we, basically, want to bring\nthis into a language model. Give it in some ways the hands\nand eyes necessary to make it do these tasks.",
    "start": "579800",
    "end": "586410"
  },
  {
    "text": "But if we just take a\nlanguage model out of the box and say, ask it this question,\nit answers pretty reasonably.",
    "start": "586410",
    "end": "593400"
  },
  {
    "text": "It says, you could try\nusing a vacuum cleaner or calling a cleaner. It even takes credit\nfor the spill, which",
    "start": "593400",
    "end": "600180"
  },
  {
    "text": "is a very reasonable thing\nfrom a language model side, but not necessarily\nactionable for robotics.",
    "start": "600180",
    "end": "606570"
  },
  {
    "text": "So one of the issues is these\nare, again, not actionable. So how do we get the language\nmodel to speak in a way",
    "start": "606570",
    "end": "613260"
  },
  {
    "text": "that robots can actually do\nit, given their embodiment? ",
    "start": "613260",
    "end": "620120"
  },
  {
    "text": "So we want it to be able to\nspeak this language of robots. We want it to be able to\nactually be executable.",
    "start": "620120",
    "end": "626330"
  },
  {
    "text": "And so the first algorithm that\nI put forth is called say-can. And the idea is\nessentially, instead",
    "start": "626330",
    "end": "632337"
  },
  {
    "text": "of letting the language model,\nwhere, normally, it would just generate the max\nprobability next token,",
    "start": "632338",
    "end": "638240"
  },
  {
    "text": "we are instead going to fix\nthe way that it can respond. So these are the only ways\nthat it can possibly respond.",
    "start": "638240",
    "end": "643610"
  },
  {
    "text": "It's called a scoring mode. And we, basically,\nsee how likely is it to respond in\neach of these ways. So if I said, put the apple\non the table, and we say,",
    "start": "643610",
    "end": "651368"
  },
  {
    "text": "these are the things you can\ndo, you can find an apple, find a sponge, pick up an apple. And these are\nactual probabilities",
    "start": "651368",
    "end": "657920"
  },
  {
    "text": "that would come out\nof a language model. And you can see pick up\nthe apple is really high. So that makes a lot of sense.",
    "start": "657920",
    "end": "663110"
  },
  {
    "text": "But if you then\nopen your eyes, you see that, well, there's not\nan apple in front of me.",
    "start": "663110",
    "end": "668960"
  },
  {
    "text": "I'm just in the middle\nof the environment. So how do we bridge this gap? And one way we can do this is\nrobotic policies, usually, come",
    "start": "668960",
    "end": "677270"
  },
  {
    "text": "with trained value functions. And these value functions\nare the probability of getting the\nreward of succeeding at a task, given\nthe state, given",
    "start": "677270",
    "end": "684712"
  },
  {
    "text": "the image of the environment. So here, we might see that\nthe value function say, well,",
    "start": "684712",
    "end": "689790"
  },
  {
    "text": "picking up an apple is pretty\nlow, because there's not an apple there. Putting the apple\ndown is extremely low,",
    "start": "689790",
    "end": "696100"
  },
  {
    "text": "because you don't have\nan apple in front of you. But things that I could do\nis go navigate to places. This has a higher value.",
    "start": "696100",
    "end": "702120"
  },
  {
    "text": "The chance of getting this\nreward is somewhat high. And this, actually,\nis, basically, on one side, a probability\nthat the task is useful.",
    "start": "702120",
    "end": "709930"
  },
  {
    "text": "So this low-level skill is\nuseful to this high-level task. And on the other side,\nit's the probability that you can actually\nsucceed at that, given",
    "start": "709930",
    "end": "716520"
  },
  {
    "text": "the current state\nof your environment and given the robot's abilities. So together, we, essentially,\nhave two probabilities.",
    "start": "716520",
    "end": "723360"
  },
  {
    "text": "One that it's useful. One that it's possible. And together, if\nyou multiply these, we get the most useful\nand possible thing.",
    "start": "723360",
    "end": "729509"
  },
  {
    "text": "So in this case, it\nbecomes find an apple, which makes a lot of sense. First, you need to identify it.",
    "start": "729510",
    "end": "734580"
  },
  {
    "text": "So once you do\nthat, you can then update this prompt that's going\ninto the language model here. And so now, it knows,\nOK, I found an apple.",
    "start": "734580",
    "end": "741570"
  },
  {
    "text": "The value function\ngets updated saying, there's an apple in front of it. And so probably it\npicks up the apple. ",
    "start": "741570",
    "end": "749050"
  },
  {
    "text": "The intuition here is given\nthis query, on one side, we have what's useful\nto do the overall task, what knowledge comes\nfrom a language model.",
    "start": "749050",
    "end": "755589"
  },
  {
    "text": "On the other side, what's\npossible in the environment, given the robotics\nabilities and its knowledge.",
    "start": "755590",
    "end": "762535"
  },
  {
    "text": "And what's really\nnice is we have this interpretable way of\nlooking at its decision-making. We can, actually,\nsee that the language",
    "start": "762535",
    "end": "770089"
  },
  {
    "text": "model is reasoning over this. The affordances are\nreasoning over this. And we can see how it\ncomes to its decision. And we can, actually--\nwhich makes it super",
    "start": "770090",
    "end": "776570"
  },
  {
    "text": "easy to debug and understand. But here, if I said,\nI spilled a Coke. Can you bring a replacement? You, actually, notice\nthat it's picked up",
    "start": "776570",
    "end": "784910"
  },
  {
    "text": "on the idea of a replacement\nrather than before I said, I spilled my Coke, can you\nbring me something to help, and it went for a sponge.",
    "start": "784910",
    "end": "790490"
  },
  {
    "text": "Here, it understands\nthat replacement means the replacement for the Coke. It understands this\ndeep information.",
    "start": "790490",
    "end": "797660"
  },
  {
    "text": "And then the affordances\ntell it that what it can do is find a Coke. It can't pick one up. And it slowly can make\nthese decisions throughout.",
    "start": "797660",
    "end": "804500"
  },
  {
    "text": "So we have this really nice\ninterpretable framework.",
    "start": "804500",
    "end": "809690"
  },
  {
    "text": "I think we did 70%\nof our tasks, though. I think with a better language\nmodel, we got this up to 85%.",
    "start": "809690",
    "end": "815613"
  },
  {
    "text": "So one thing that's really\nnice is we can, basically, just swap out the language\nmodel and put in a new one, as things get better and better.",
    "start": "815613",
    "end": "822350"
  },
  {
    "text": "And the other part\nthat's really, I think, important is that this\ngrounding here halves the errors",
    "start": "822350",
    "end": "827839"
  },
  {
    "text": "that you make. So, essentially,\nrobotics, actually, has something to\nbring to the table. This experience\nin the environment",
    "start": "827840",
    "end": "833510"
  },
  {
    "text": "is crucial for\nthe language model to be able to successfully\nplan and command the robot to what to do.",
    "start": "833510",
    "end": "839600"
  },
  {
    "text": "And a quick video\nof this in action. We type some command.",
    "start": "839600",
    "end": "846290"
  },
  {
    "text": "I think this is like,\nI spilled a Coke. And bring me a replacement\nand something to clean up.",
    "start": "846290",
    "end": "852170"
  },
  {
    "text": "Maybe, the internet's\ncutting out too much. ",
    "start": "852170",
    "end": "861320"
  },
  {
    "text": "And as I was saying, we'll\nsee on the right side that it pops up with the\nactual decision-making process.",
    "start": "861320",
    "end": "866600"
  },
  {
    "text": "So we can-- as it\ngoes, understand what it's trying to do,\nwhy it's trying to do it. It's all in language.",
    "start": "866600",
    "end": "871930"
  },
  {
    "text": "So you can, actually,\nunderstand it rather than some actions or\nsomething more difficult to really grasp\nwhat's happening.",
    "start": "871930",
    "end": "879740"
  },
  {
    "text": "And I'll skip forward\nin the interest of time. But, essentially, it,\neffectively, I think--",
    "start": "879740",
    "end": "885508"
  },
  {
    "text": "we, essentially, asked\nit to do two things. We asked it to both\nthrow away the Coke can and also bring me\nsomething to clean up.",
    "start": "885508",
    "end": "891410"
  },
  {
    "text": "And it's able to put\nthese both together to form this long\nhorizon task, do",
    "start": "891410",
    "end": "896557"
  },
  {
    "text": "a task that takes a couple\nof minutes to roll out. And it's truly long\nhorizon and sequential.",
    "start": "896557",
    "end": "902820"
  },
  {
    "text": "So one issue that arises\nwith this is I just had it so that I\nenumerated these skills.",
    "start": "902820",
    "end": "908459"
  },
  {
    "text": "And I scored over these skills. But if you go into\na world like this, it's pretty computationally\nintractable for me",
    "start": "908460",
    "end": "914579"
  },
  {
    "text": "to write down\neverything I can do. There's pairwise things. I can stack something\non something else. And so say-can\ndoesn't really scale",
    "start": "914580",
    "end": "921540"
  },
  {
    "text": "to this complexity,\nthis intractability of the real world. So how do we go from\nthis idea of how",
    "start": "921540",
    "end": "928770"
  },
  {
    "text": "we ground and value functions\nto a more complicated world like this?",
    "start": "928770",
    "end": "934050"
  },
  {
    "text": "And the idea here in this work,\ngrounded decoding, that Wenlong, actually, put together\nis that, essentially,",
    "start": "934050",
    "end": "942540"
  },
  {
    "text": "instead of picking specific\nscoring things just very specific primitives,\nwe can instead just bias it",
    "start": "942540",
    "end": "950279"
  },
  {
    "text": "at the token level. So a language model is always\npredicting probabilities over the next token.",
    "start": "950280",
    "end": "955770"
  },
  {
    "text": "We can also do\nthis with a policy. We can have that policy\nconditioned on some arbitrary amount of natural language.",
    "start": "955770",
    "end": "960810"
  },
  {
    "text": "So just put the and\nthen the next thing, the next object has to have a\nhigh probability in this scene.",
    "start": "960810",
    "end": "968889"
  },
  {
    "text": "So we see that the\nPepsi is pretty high. The cake is also there. I think these are little\ncakes, as well as,",
    "start": "968890",
    "end": "976029"
  },
  {
    "text": "certain letters are visible. And, essentially, we have\nthis token level grounding",
    "start": "976030",
    "end": "981670"
  },
  {
    "text": "of what's possible\nand what's useful. So this means that we\ncan also include things like safety and\npreferences of the user,",
    "start": "981670",
    "end": "988960"
  },
  {
    "text": "and be able to decode\nin a much more varied combinatorially complex world.",
    "start": "988960",
    "end": "994540"
  },
  {
    "text": "And we can do things\nlike pack a picnic box and ignore things like the\nknife that maybe the robot's not",
    "start": "994540",
    "end": "1001320"
  },
  {
    "text": "capable of doing, because a\nsafety function can biases away from it. And so it's a very\ngeneral way to ground",
    "start": "1001320",
    "end": "1008813"
  },
  {
    "text": "the language model in the\nworld and the capabilities of the robot without losing the\nexpressibility of the language",
    "start": "1008813",
    "end": "1013949"
  },
  {
    "text": "model. We can also use\nit for navigation. So choosing where to navigate.",
    "start": "1013950",
    "end": "1019020"
  },
  {
    "text": "And even the language\nmodel can trigger when it should be\ngrounded and when not. So this is, in a way, a tool\nuse out of the language model.",
    "start": "1019020",
    "end": "1025410"
  },
  {
    "text": "We see that given that we\nwanted some object, you say, I'll go find.",
    "start": "1025410",
    "end": "1031400"
  },
  {
    "text": "And then when it\ngets to the object, it doesn't know\nwhat's in the world. And so it can actually\ntrigger that I need to ground this next statement.",
    "start": "1031400",
    "end": "1037790"
  },
  {
    "text": "And it can look\nbased in the world. In this case, using clip. What have I seen in\nthe past and realized that a Pepsi can was there\nand an apple was there?",
    "start": "1037790",
    "end": "1045859"
  },
  {
    "text": "And then make its\ndecision based on that. So I think the fact that\nthis grounding is a tool",
    "start": "1045859",
    "end": "1050875"
  },
  {
    "text": "that a language\nmodel can call up when necessary means that\nyou can really leverage it for very varied tasks.",
    "start": "1050875",
    "end": "1057530"
  },
  {
    "text": "One thing that still goes\nwrong, though, is, let's say-- and we saw it in\nthe initial demo.",
    "start": "1057530",
    "end": "1064310"
  },
  {
    "text": "It failed at a task. But it didn't get any\nfeedback that, hey, I failed at that task. It just failed that and then\nkept going on to the next one.",
    "start": "1064310",
    "end": "1071180"
  },
  {
    "text": "And in the world,\nwe might get this, like, you're trying\nto unlock a door, and you realize you put the\nkey in and it didn't work.",
    "start": "1071180",
    "end": "1076880"
  },
  {
    "text": "So I need to switch\nto a different one. I turn that. And now, it opened. A language model\nisn't necessarily getting this feedback\nin these earlier setups.",
    "start": "1076880",
    "end": "1085190"
  },
  {
    "text": "So what we need is to have some\ninner monologue thinking of, OK, I tried this. Did that succeed?",
    "start": "1085190",
    "end": "1090750"
  },
  {
    "text": "What do I see in the world? And there's a lot of sources of\nfeedback that we can provide. We can use object recognition\nto tell a language model, what's",
    "start": "1090750",
    "end": "1097203"
  },
  {
    "text": "available. We can use success\ndetection to say whether it succeeded at something.",
    "start": "1097203",
    "end": "1102630"
  },
  {
    "text": "And, basically, build this\nall into a real prompt. So we get some query, like,\nbring me a drink from the table.",
    "start": "1102630",
    "end": "1109170"
  },
  {
    "text": "We use say-can to\ndetermine the next task. And then we go to the table. But the language\nmodel doesn't actually",
    "start": "1109170",
    "end": "1115679"
  },
  {
    "text": "know what's at the table yet. And so in say-can it's\ngoing to reason over all the possible objects.",
    "start": "1115680",
    "end": "1121049"
  },
  {
    "text": "But without knowing\nwhat's there, it's very hard to blindly reason\nwhat possibly could be there. And instead, the\nobject recognition",
    "start": "1121050",
    "end": "1127050"
  },
  {
    "text": "can just write this\ndescription into the prompt. And then it's very clear,\nwhat should be done next.",
    "start": "1127050",
    "end": "1133500"
  },
  {
    "text": "The robot can also\nask questions. And, basically, in\nthis inner monologue, realize this an\nunderspecified problem. I should ask the user something.",
    "start": "1133500",
    "end": "1139710"
  },
  {
    "text": "And then when it tries to do\nsomething like pick up the Coke, and it fails, it can even\nrecognize that it failed and just try this again.",
    "start": "1139710",
    "end": "1145404"
  },
  {
    "text": "So what it looks like\nin the real world is that we have all these\nsources of feedback. And we can just build\nthem all into a prompt.",
    "start": "1145405",
    "end": "1150990"
  },
  {
    "text": "And let the language\nmodel, essentially, handle this monologue of\nwhat's going on in its head of,",
    "start": "1150990",
    "end": "1156059"
  },
  {
    "text": "OK, I tried this. That failed. What should I do next? Should I-- I think, in this case,\nwe have it try something",
    "start": "1156060",
    "end": "1162030"
  },
  {
    "text": "and it fails,\nbecause we explicitly stopped it from working. So picking up a Coke can.",
    "start": "1162030",
    "end": "1168877"
  },
  {
    "text": "But, now, the Coke can\nis not there anymore. So the bring me a soda\nmaybe doesn't work so well.",
    "start": "1168877",
    "end": "1173919"
  },
  {
    "text": "So, maybe, it go back\nto the user and ask hey, this didn't work. I don't see a Coke can anymore.",
    "start": "1173920",
    "end": "1180370"
  },
  {
    "text": "What would you like instead? So I see an orange soda. And it says, there's this. And we say, no, that\ndoesn't work for us.",
    "start": "1180370",
    "end": "1186760"
  },
  {
    "text": "So it goes back to\nthe planning stage and says, OK, now, I need\nto find this lime soda that we asked for instead.",
    "start": "1186760",
    "end": "1192893"
  },
  {
    "text": "So this allows the language\nmodel to be much more grounded in the world by using these\nadditional tools of a success",
    "start": "1192893",
    "end": "1198940"
  },
  {
    "text": "detector of human feedback\nof a scene descriptor. And in this case,\nit successfully",
    "start": "1198940",
    "end": "1206440"
  },
  {
    "text": "delivers it to the person. Another nice thing\nthat we see is",
    "start": "1206440",
    "end": "1212030"
  },
  {
    "text": "that it can even-- it\nactually terminates the end. It says, OK, I've\naccomplished a task. And the last thing\nthat it does is--",
    "start": "1212030",
    "end": "1217790"
  },
  {
    "text": "and this is our new\nposition-- but it'll even raise the thing saying, OK,\nI've completed the task.",
    "start": "1217790",
    "end": "1224730"
  },
  {
    "text": "But there are some limits\nof what language can do. I talked about putting\nthings in a line.",
    "start": "1224730",
    "end": "1231730"
  },
  {
    "text": "But this would be\nhard to specify exactly how to do in language. It's not necessarily\nthe best format.",
    "start": "1231730",
    "end": "1238240"
  },
  {
    "text": "Also, if you wanted to describe\nthe scene in language here, you would have to\ndescribe the complexity.",
    "start": "1238240",
    "end": "1243632"
  },
  {
    "text": "They're all bunched together. And the green one's a\nlittle higher than this. And the blue one's here. And so language\nisn't necessarily",
    "start": "1243632",
    "end": "1249700"
  },
  {
    "text": "the best thing for this. Also, this one where we\nhave to wait until we see something to make\nanother decision.",
    "start": "1249700",
    "end": "1255190"
  },
  {
    "text": "This feels a lot\nmore how code works. And, actually, code is this\nlinguistic representation",
    "start": "1255190",
    "end": "1261820"
  },
  {
    "text": "of actions. It's directly what we're running\non the robot at the lowest",
    "start": "1261820",
    "end": "1266900"
  },
  {
    "text": "level. And it has all this power to\ndo to call external methods, to do any computation, do\nif loops and while loops,",
    "start": "1266900",
    "end": "1274809"
  },
  {
    "text": "and this more complex reasoning. We see things put\nthings in a line works pretty straightforward,\nwhen you're writing it",
    "start": "1274810",
    "end": "1280767"
  },
  {
    "text": "in code, even though it\nmight be a little bit more difficult to\nenumerate in language. And most importantly, there is\na ton of data of what this is.",
    "start": "1280767",
    "end": "1290840"
  },
  {
    "text": "It's the equivalent-- even I\nthink the best GPT models now,",
    "start": "1290840",
    "end": "1295970"
  },
  {
    "text": "start code, trained\non code, and then are fine tuned on instruction\nfollowing and language. So code is this really\nnice structured.",
    "start": "1295970",
    "end": "1303860"
  },
  {
    "text": "And we know it runs. Otherwise, it wouldn't be there. So there's a good signal\nthat it's high quality.",
    "start": "1303860",
    "end": "1309572"
  },
  {
    "text": "So it's actually\na really good fit. And it's what we run on robots. So we should just use\nthese language models",
    "start": "1309572",
    "end": "1315140"
  },
  {
    "text": "to write code and essentially\nrun that directly on the robot.",
    "start": "1315140",
    "end": "1320300"
  },
  {
    "text": "What's nice is we\ncan both use APIs. So, maybe, we have\nperception APIs that",
    "start": "1320300",
    "end": "1326120"
  },
  {
    "text": "can detect where things are. We can use four\nloops out of this. And we can even use the language\nmodel to write new APIs.",
    "start": "1326120",
    "end": "1333980"
  },
  {
    "text": "So if it generates something,\nlike, is empty or stack objects as a function, it can realize--",
    "start": "1333980",
    "end": "1340568"
  },
  {
    "text": "actually, these were\nalready defined. And then just generate\nthe next thing. So this hierarchical code\ngeneration, actually,",
    "start": "1340568",
    "end": "1347720"
  },
  {
    "text": "does extremely well to do much\nmore abstract and complicated",
    "start": "1347720",
    "end": "1354020"
  },
  {
    "text": "reasoning. And it does it all\npretty much, I guess, [INAUDIBLE] but\nwithout any training.",
    "start": "1354020",
    "end": "1360440"
  },
  {
    "text": "So they also looked at every\ntextbook that you've seen. So it can do-- it can write a\nfull controller for something",
    "start": "1360440",
    "end": "1367100"
  },
  {
    "text": "as simple as a cart pole. It can do-- it can understand\nemojis, different languages,",
    "start": "1367100",
    "end": "1375020"
  },
  {
    "text": "all of this falls out for free. It can even use different\ncross embodiments",
    "start": "1375020",
    "end": "1380187"
  },
  {
    "text": "or different embodiments based\non the available actions. So here, we just list\nlike, move up, move right,",
    "start": "1380187",
    "end": "1385370"
  },
  {
    "text": "move back is something versus\nturn left move forward. So this is the way\nthat the robot moves. And then the code is able\nto immediately adapt to that",
    "start": "1385370",
    "end": "1393500"
  },
  {
    "text": "to be able to do new things. So it's really\nshowing this power of, I guess, what prompting can do,\nand, especially, when you're",
    "start": "1393500",
    "end": "1400760"
  },
  {
    "text": "prompting in a language\nthat's directly accessible by the robot. And we put this\non, I guess, two,",
    "start": "1400760",
    "end": "1409640"
  },
  {
    "text": "three robots here with\ndifferent end effectors. And the best thing is\nyou could, I guess--",
    "start": "1409640",
    "end": "1416030"
  },
  {
    "text": "I really like these ones,\nwhere you're drawing shapes, because I think this would be\nan extremely complicated control problem.",
    "start": "1416030",
    "end": "1421360"
  },
  {
    "text": "But in code, it's\nextremely trivial to just write how to do it. And you can just put it on and\nwithin a day, have this running.",
    "start": "1421360",
    "end": "1430370"
  },
  {
    "text": "And it can run fairly robustly. You can also do very\nabstract reasoning like, make this square bigger,\nmove something to the side,",
    "start": "1430370",
    "end": "1437870"
  },
  {
    "text": "or write these while loops and\nif loops that wait for things to happen before it\nmakes a decision.",
    "start": "1437870",
    "end": "1444409"
  },
  {
    "text": "So it's a very, I\nguess, powerful concept. But there's also\nsome limitations",
    "start": "1444410",
    "end": "1450679"
  },
  {
    "text": "of how well we can write\nthings through code. There's a reason\nwhy sometimes we want these end-to-end policies. Something, like,\ngoing to grasp a mug",
    "start": "1450680",
    "end": "1457580"
  },
  {
    "text": "might be very difficult to\neffectively write through code. So instead, what we wanted to do\nwas, basically, what if we just",
    "start": "1457580",
    "end": "1463190"
  },
  {
    "text": "collect a bunch of data? Maybe not quite to the scale\nof foundation models, but, as much as we\ncould, and see what",
    "start": "1463190",
    "end": "1469440"
  },
  {
    "text": "if we just train a model\nto output actions directly. So this is a paper called\nRobotics Transformer or RT1.",
    "start": "1469440",
    "end": "1477420"
  },
  {
    "text": "And the idea was, basically, a\nsimple transformer architecture with a few things to\nmake it efficient enough",
    "start": "1477420",
    "end": "1483810"
  },
  {
    "text": "to run quickly on a robot. We tokenize the whole input,\nthe instruction, the image.",
    "start": "1483810",
    "end": "1489420"
  },
  {
    "text": "And we put it through a\ncouple efficient layers. And then we go\nthrough a transformer. And then we just direct the\noutput, tokenized output.",
    "start": "1489420",
    "end": "1496320"
  },
  {
    "text": "We collected 130,000 episodes. Each episode is maybe seconds\nlong, over 13 robots a year",
    "start": "1496320",
    "end": "1505080"
  },
  {
    "text": "and a half, and 700 tasks\nto be able to get it to decent performance.",
    "start": "1505080",
    "end": "1510330"
  },
  {
    "text": "And, actually, it\ndoes pretty well. So across the scene tasks\nthat we have, it achieves 97%,",
    "start": "1510330",
    "end": "1517059"
  },
  {
    "text": "I think. So it's pretty near perfect\nexcept little mistakes here and there. And these are scenes\nlike this, where",
    "start": "1517060",
    "end": "1523532"
  },
  {
    "text": "we're randomizing\nwhich objects are there and where the objects are. But it can also actually\ndo pretty well with unseen",
    "start": "1523532",
    "end": "1530250"
  },
  {
    "text": "objects with unseen tasks, like,\nadding in a lot more objects, and really cluttering\nup the space here,",
    "start": "1530250",
    "end": "1536370"
  },
  {
    "text": "and progressively making\nit more cluttered. Changing the background is\nalmost exclusively the data",
    "start": "1536370",
    "end": "1543090"
  },
  {
    "text": "came from this scene, where\nit's this gray tabletop. But we put in this white\ntabletop with a wood cabinets",
    "start": "1543090",
    "end": "1553530"
  },
  {
    "text": "and have-- or wood drawers. And it is able to\nstill open the drawers, and able to pick things up. And it does a lot better than\nany of these other approaches.",
    "start": "1553530",
    "end": "1562860"
  },
  {
    "text": "So we tried just\nregular behavior cloning without a transformer. We tried Gato, which has\nsome subtle differences.",
    "start": "1562860",
    "end": "1570289"
  },
  {
    "text": "And found that, in\ngeneral, RT1, actually, works pretty well,\nand most excitingly, starts to generalize\nacross things.",
    "start": "1570290",
    "end": "1576330"
  },
  {
    "text": "But I think the things that\nthey we're most excited about are its ability to ingest\nheterogeneous data.",
    "start": "1576330",
    "end": "1583530"
  },
  {
    "text": "So we collected, again, a\nton of episodes on this robot in this scene.",
    "start": "1583530",
    "end": "1589620"
  },
  {
    "text": "And then we put\nin simulated data, which is very easy to collect.",
    "start": "1589620",
    "end": "1596059"
  },
  {
    "text": "And we put in data\nfrom a different robot. From a Kuka that was collected\nfor a completely different",
    "start": "1596060",
    "end": "1601279"
  },
  {
    "text": "project. And we just made the\naction space the same. And then threw it in. And what you see is\nfirst, the Sim data,",
    "start": "1601280",
    "end": "1609110"
  },
  {
    "text": "if we hold out certain\nobjects, it's only seen in Sim. It makes a massive difference.",
    "start": "1609110",
    "end": "1614480"
  },
  {
    "text": "It went from 10% success\nor 20% success to 85%. So 65% more.",
    "start": "1614480",
    "end": "1620630"
  },
  {
    "text": "It's able to even do new\nskills with those objects that it hasn't seen\nbefore in either one.",
    "start": "1620630",
    "end": "1625700"
  },
  {
    "text": "So it can cross domain transfer. And then adding in these new\nobjects with a different robot",
    "start": "1625700",
    "end": "1631580"
  },
  {
    "text": "also works pretty well. And we're able to\nsuddenly pick those up. So we're actually starting\nto see this scaling.",
    "start": "1631580",
    "end": "1638059"
  },
  {
    "text": "We do see that it\noverfits pretty quickly on the environment that we have. I think we had 97% there and\n80% in the next scene, which",
    "start": "1638060",
    "end": "1646009"
  },
  {
    "text": "is great for\nrobotics, but, maybe, not the level of performance\nthat we hope to see. But it can ingest this\nheterogeneous data,",
    "start": "1646010",
    "end": "1654600"
  },
  {
    "text": "which I feel like that's\nlike the real crux of what a foundation model\nneeds to be able to do",
    "start": "1654600",
    "end": "1659669"
  },
  {
    "text": "is pull in data from all\nthese different environments. So it's starting to\nfeel like, maybe, we",
    "start": "1659670",
    "end": "1665070"
  },
  {
    "text": "can train a foundation model. But some of the big issues\nthat we come across with",
    "start": "1665070",
    "end": "1670320"
  },
  {
    "text": "is so we fixed\nessentially the data-- or we slowly lowered\nthe data size.",
    "start": "1670320",
    "end": "1675490"
  },
  {
    "text": "And we lowered it by\neither uniformly taking out data across all tasks, or\ncutting out like the lowest data",
    "start": "1675490",
    "end": "1681882"
  },
  {
    "text": "performing tasks. So here, we lose, I\nthink, 5% of data. But across, like, the tasks\nthat are underrepresented,",
    "start": "1681882",
    "end": "1688860"
  },
  {
    "text": "but the more diverse tasks. And we see the performance\ndrops really quickly. If we just pull out data\nuniformly across the board",
    "start": "1688860",
    "end": "1696120"
  },
  {
    "text": "and keep our diversity\nup, we actually see that our performance\ndoesn't go down, or, at least,",
    "start": "1696120",
    "end": "1701760"
  },
  {
    "text": "not nearly as quickly. So diversity is the key to this. But diversity is hard to get,\nespecially, for robotics.",
    "start": "1701760",
    "end": "1708150"
  },
  {
    "text": "You need to have them in\na lot of different scenes. You need to-- and, also,\nscaling up in the one scene.",
    "start": "1708150",
    "end": "1716100"
  },
  {
    "text": "So we have this\nclassroom, where we just collect most of our data. It's a waste of\ntime at some point",
    "start": "1716100",
    "end": "1721647"
  },
  {
    "text": "that you've collected\nso much data in there. So we're-- one of the big things\nwe're looking at is how can we vary this data collection?",
    "start": "1721647",
    "end": "1728940"
  },
  {
    "text": "But the performance--\nso one way we can vary this data collection\nis that we can imagine that we",
    "start": "1728940",
    "end": "1734940"
  },
  {
    "text": "were in different scenes. So, maybe, we've\ncollected some data here. Let's use diffusion models to\nimagine something different.",
    "start": "1734940",
    "end": "1741360"
  },
  {
    "text": "So this is,\nessentially, what we've done here is we recognize\nwhich areas we've seen. And then we vary\neverything else that",
    "start": "1741360",
    "end": "1747840"
  },
  {
    "text": "isn't important to this task. So it's picking up the Coke can. But it's imagining\nthat it's in a kitchen. It's imagining that it's in\na living room, in an office.",
    "start": "1747840",
    "end": "1756269"
  },
  {
    "text": "And all this becomes\nuseful data for the robot and, essentially, we've just\nused these massive diffusion models to be able to inject\nnew imagined experience",
    "start": "1756270",
    "end": "1765299"
  },
  {
    "text": "for the robot. And give it this ability\nto handle diversity.",
    "start": "1765300",
    "end": "1770580"
  },
  {
    "text": "The way that it works is\nwe localize areas that are important for the task.",
    "start": "1770580",
    "end": "1775590"
  },
  {
    "text": "And everything else becomes\nan area that we inpaint, which means we replace it\nwith imagined experience.",
    "start": "1775590",
    "end": "1782520"
  },
  {
    "text": "In this case, from\nthe Imagen model, which is a foundation\nmodel for image generation.",
    "start": "1782520",
    "end": "1789110"
  },
  {
    "text": "And then we throw that\nin as, though, that was real robot experience. And after this one, I think,\nI have actual numbers,",
    "start": "1789110",
    "end": "1797460"
  },
  {
    "text": "but another trippy video of\nwe can replace even the thing that it was picking up so\nthat it learns a new task.",
    "start": "1797460",
    "end": "1804390"
  },
  {
    "text": "So it can learn to\npick up these objects while also varying everything\nelse in the scene or not varying everything\nelse in the scene.",
    "start": "1804390",
    "end": "1810432"
  },
  {
    "text": "Keeping the rest of\nthe scene the same. And making sure that we're\nin domain for the parts that we care about.",
    "start": "1810432",
    "end": "1816720"
  },
  {
    "text": "And you end up with\nthis policy that is-- and we can act as,\nthough, the whole time",
    "start": "1816720",
    "end": "1822270"
  },
  {
    "text": "it picked up like a cloth or\nthings that are deformable. And we see that we,\nactually, are able to do this",
    "start": "1822270",
    "end": "1830300"
  },
  {
    "text": "at a higher rate. There's a lot of numbers here. But the main thing\nis when we use Rosie on all the\nbolded numbers, or when",
    "start": "1830300",
    "end": "1836037"
  },
  {
    "text": "we add it in this\nimagined experience, it's across the board. It helps. And it doesn't\nreally hurt anything. So it's getting this\nfree experience just",
    "start": "1836037",
    "end": "1844039"
  },
  {
    "text": "from the foundation model.  But I think what we really want\nto do is, at the lowest levels,",
    "start": "1844040",
    "end": "1851980"
  },
  {
    "text": "use the knowledge contained in\nfoundation models for robotics. So the next thing we try to do\nis, actually, train our own.",
    "start": "1851980",
    "end": "1858370"
  },
  {
    "text": "And we called it\nPaLM-E, which starts with PaLM, which is this massive\nlanguage model from Google.",
    "start": "1858370",
    "end": "1865120"
  },
  {
    "text": "And VIT, which is a massive\nvision model from Google. We put them together.",
    "start": "1865120",
    "end": "1870130"
  },
  {
    "text": "And we put a bunch of all\nthe internet datas in there. But we also put in a\nbunch of robotics data",
    "start": "1870130",
    "end": "1875470"
  },
  {
    "text": "and specific data that is more\nuseful for robotics tasks. So we put this all into\nthis massive mixture.",
    "start": "1875470",
    "end": "1882370"
  },
  {
    "text": "And then we tried it on a\nbunch of different tasks. And suddenly, not only\ncan we do VQA tasks. But we can do task\nin motion planning.",
    "start": "1882370",
    "end": "1888730"
  },
  {
    "text": "We can manipulate things\nin an environment. And we can do real tasks\nand generalize pretty well.",
    "start": "1888730",
    "end": "1894700"
  },
  {
    "text": "So the way that it works\nis given some language model that's taking in\na bunch of text tokens,",
    "start": "1894700",
    "end": "1900640"
  },
  {
    "text": "we also train the VIT\nto output, essentially, text tokens, or some\nco-embedding space",
    "start": "1900640",
    "end": "1906610"
  },
  {
    "text": "between the two. And it can be images. It can be anything else. But you can see, essentially,\nthe language model is just",
    "start": "1906610",
    "end": "1913873"
  },
  {
    "text": "reading in these tokens as\nthough they're all text tokens. And these other\nsmaller models are",
    "start": "1913873",
    "end": "1919160"
  },
  {
    "text": "outputting things that\nthen go in as vision tokens or object tokens or\nthings like that.",
    "start": "1919160",
    "end": "1926000"
  },
  {
    "text": "And we train the whole\nthing end-to-end so that it learns to, essentially,\nrecognize the text tokens",
    "start": "1926000",
    "end": "1931909"
  },
  {
    "text": "and the image tokens as though\nthey're all the same thing. And not only are we able to do\nVQA tasks and complicated ones,",
    "start": "1931910",
    "end": "1939230"
  },
  {
    "text": "like, given this\nimage, what's in there, and answer an emojis or\nsomething really simple,",
    "start": "1939230",
    "end": "1946429"
  },
  {
    "text": "like, just describe this image. But we can also do\nmodal manipulations. So we can do say-can. But all just in a single model.",
    "start": "1946430",
    "end": "1953035"
  },
  {
    "text": "We can do task in\nmotion planning and have an output,\na real plan to do somewhat complex sequential\nreasoning or tabletop",
    "start": "1953035",
    "end": "1960648"
  },
  {
    "text": "manipulation. Then we also did just\nlanguage-only tasks, not even with vision. And because we started\nwith this language model,",
    "start": "1960648",
    "end": "1966890"
  },
  {
    "text": "we don't lose any of the initial\nlanguage reasoning capabilities. So it can do math or\nwrite haikus or very",
    "start": "1966890",
    "end": "1976490"
  },
  {
    "text": "general swatch of things. One of the most\nexciting things though is that we really see\npositive transfer here.",
    "start": "1976490",
    "end": "1982610"
  },
  {
    "text": "So if we train on\nthe same model, but only with this data,\nand only this data,",
    "start": "1982610",
    "end": "1989179"
  },
  {
    "text": "and only this data, we\nget middling performance. But if we put them all\ntogether and we put in",
    "start": "1989180",
    "end": "1994790"
  },
  {
    "text": "all the internet scale data,\nall of them shoot up massively. So we see that,\nbasically, there's",
    "start": "1994790",
    "end": "2000640"
  },
  {
    "text": "reasons to throw\neverything into one pile. And even though these are pretty\ndifferent visually, especially,",
    "start": "2000640",
    "end": "2007780"
  },
  {
    "text": "between this language\ntable and the say-can data, they're extremely\ndiverse visuals.",
    "start": "2007780",
    "end": "2014409"
  },
  {
    "text": "The action space is different. And it's still able to\nactually cross domain transfer.",
    "start": "2014410",
    "end": "2020560"
  },
  {
    "text": "We also see that as we get\nto larger and larger models, the performance doesn't\ngo down as much, when",
    "start": "2020560",
    "end": "2025913"
  },
  {
    "text": "we add in this vision. So, essentially, these are\njust language-only tasks. And with an eight-billion\nparameter PaLM model,",
    "start": "2025913",
    "end": "2033040"
  },
  {
    "text": "this is what it started\nwith for performance. And when we added in this\ntraining, it dropped massively.",
    "start": "2033040",
    "end": "2038950"
  },
  {
    "text": "Basically, it's a terrible\nlanguage model at this point. If we go to a bigger model,\nit drops a little less.",
    "start": "2038950",
    "end": "2044568"
  },
  {
    "text": "And then as we get to\nthe really large one, it, essentially, does the same. And even on some\ntasks, it got better.",
    "start": "2044568",
    "end": "2049599"
  },
  {
    "text": "So we see that if you get\nto a really large model, it's able to ingest all this\ninformation without actually",
    "start": "2049600",
    "end": "2055719"
  },
  {
    "text": "forgetting or having any\ncatastrophic forgetting of its previous knowledge. So this is extremely\npromising that maybe we don't",
    "start": "2055719",
    "end": "2061840"
  },
  {
    "text": "lose too much by doing this. ",
    "start": "2061840",
    "end": "2067560"
  },
  {
    "text": "Some examples that, I think,\nwe were pretty excited about or just thought were fun\nof visual reasoning are here.",
    "start": "2067561",
    "end": "2074120"
  },
  {
    "text": "So it's able to do things\nlike read off here, the price of these items.",
    "start": "2074120",
    "end": "2080169"
  },
  {
    "text": "And then do math based on that\nto tell you how much it would cost to get two custom pizzas.",
    "start": "2080170",
    "end": "2086809"
  },
  {
    "text": "We're able to-- I\nthink this one is particularly complex\nreasoning, because it's a mix of words and rules.",
    "start": "2086810",
    "end": "2094310"
  },
  {
    "text": "So it's saying you can't\nenter unless it's a bike. But it has to understand\nthat it's saying except, but then there's also a\npicture of a bike and emergency",
    "start": "2094310",
    "end": "2101402"
  },
  {
    "text": "vehicles. And it's able to\nreason through this to recognize that on a\nbike, it's OK to go through.",
    "start": "2101402",
    "end": "2108570"
  },
  {
    "text": "We can also use multiple images. So we can compare. And these are definitely\nnot in the training set.",
    "start": "2108570",
    "end": "2113670"
  },
  {
    "text": "This is like-- one of us went\nto, I think, marine layer and took some pictures. And said, what's the difference\nbetween these two images?",
    "start": "2113670",
    "end": "2121619"
  },
  {
    "text": "What matches? And it's able to put this\ncomplex reasoning to work, even over these images that\nit's never seen before,",
    "start": "2121620",
    "end": "2129630"
  },
  {
    "text": "which is very exciting,\nespecially, for robotics tasks. ",
    "start": "2129630",
    "end": "2137075"
  },
  {
    "text": "And then we're able to put\nit on robots, as I said. So we can use it to,\non the same model,",
    "start": "2137075",
    "end": "2142589"
  },
  {
    "text": "do these tasks on the right. And neither of these\nis it putting-- it's not putting out actions.",
    "start": "2142590",
    "end": "2147630"
  },
  {
    "text": "But it's commanding\na low-level policy that's putting out actions. But it's able to handle\nadversarial disturbances.",
    "start": "2147630",
    "end": "2153420"
  },
  {
    "text": "Like here, we block it\nfrom picking something up. It's able to close the\nloop with the environment and repeatedly recognize what\nit's done, what it needs to do,",
    "start": "2153420",
    "end": "2163800"
  },
  {
    "text": "as we manipulate\nthe environment. It can recover to it. And it can do this all\nthrough the same checkpoint.",
    "start": "2163800",
    "end": "2169170"
  },
  {
    "text": "So you feel like this is\na real step towards doing this multi-embodiment brain\nthat this foundation model",
    "start": "2169170",
    "end": "2177420"
  },
  {
    "text": "for robotics. So this is my last slide.",
    "start": "2177420",
    "end": "2182549"
  },
  {
    "text": "But what's next is we want\nto go beyond language. We want to continue pushing on\nthis visual language domain.",
    "start": "2182550",
    "end": "2189819"
  },
  {
    "text": "But we also recognize\nthat there's a lot of issues with applying\nfoundation models to robotics. They're, really, not perfectly\nmated for each other, which,",
    "start": "2189820",
    "end": "2200170"
  },
  {
    "text": "I think, is like a robotics\nresearcher is exciting that there's a lot of\nareas to still figure out.",
    "start": "2200170",
    "end": "2206550"
  },
  {
    "text": "But in the areas that\nwe can leverage them, we should leverage them as best\nwe can and do so in a way that",
    "start": "2206550",
    "end": "2213080"
  },
  {
    "text": "makes sense for robotics. So things like grounding\nthem in the scene, recognizing constraints,\nor using value functions",
    "start": "2213080",
    "end": "2220430"
  },
  {
    "text": "and sources of information that\nwe already had for robotics. ",
    "start": "2220430",
    "end": "2226650"
  },
  {
    "text": "But I think, really, at\nthe end of the day, what we need to improve are the\nrobotics side of things. We need to-- while\nlanguage models continue",
    "start": "2226650",
    "end": "2234390"
  },
  {
    "text": "to increase in performance\nand vision language models, the interaction side of\nrobotics is still definitely",
    "start": "2234390",
    "end": "2240230"
  },
  {
    "text": "the bottleneck of\nthe overall system. But we do think\nthat we can move.",
    "start": "2240230",
    "end": "2246440"
  },
  {
    "text": "There's a lot of\nreally positive signs that in embodied foundation\nmodel is possible. This positive transfer\nacross things.",
    "start": "2246440",
    "end": "2254056"
  },
  {
    "text": "This ability to ingest\nheterogeneous data between different robots from\nSim is extremely promising.",
    "start": "2254056",
    "end": "2261798"
  },
  {
    "text": "And the fact that we don't\nget catastrophic forgetting, as we train these models\nwith more robotics data, means that we can leverage\neverything that was there,",
    "start": "2261798",
    "end": "2268380"
  },
  {
    "text": "but still add in our own data. There's a lot of people\nwho worked on this.",
    "start": "2268380",
    "end": "2275400"
  },
  {
    "text": "Most of which are pictured\nhere, but not all. I think that's it.",
    "start": "2275400",
    "end": "2283025"
  },
  {
    "text": "I can, obviously,\ntake questions. And then we also have the\nrobot running in the back end, if there's anything we\nwant to try on that.",
    "start": "2283025",
    "end": "2289260"
  },
  {
    "text": " All right. Thank you. [APPLAUSE]",
    "start": "2289260",
    "end": "2296412"
  },
  {
    "text": "I just had a quick question. When you were measuring\nthe success rate, you mentioned that you had\nsafety precautions to make sure",
    "start": "2296413",
    "end": "2303010"
  },
  {
    "text": "that there wasn't any\ncatastrophic failures. You would find, maybe, in a\nlanguage model, like you said, that you would forgive. But what was the\nrange of failures?",
    "start": "2303010",
    "end": "2310650"
  },
  {
    "text": "Is there anything that didn't\nperfectly accomplish the task? Or was there anything\nwhere the robot did something that was\nactually left the place worse",
    "start": "2310650",
    "end": "2317770"
  },
  {
    "text": "than it started? Certainly, sometimes,\nit picks something up and knocks it off the table.",
    "start": "2317770",
    "end": "2323380"
  },
  {
    "text": "And then, in a\nway, that's worse. I think our policies are trained\nto terminate or have failure,",
    "start": "2323380",
    "end": "2331510"
  },
  {
    "text": "if they hit something like the\ntable too hard, or things that mostly could cause any damage.",
    "start": "2331510",
    "end": "2337120"
  },
  {
    "text": "So those are both baked\ninto the robotics stack, and then also trained\ninto the policy",
    "start": "2337120",
    "end": "2342280"
  },
  {
    "text": "that that would be\na negative outcome. So there weren't anything\nthat was too terrible.",
    "start": "2342280",
    "end": "2348880"
  },
  {
    "text": "Generally, though, the\nerrors, I feel like, were split pretty evenly between\nthe robotics policy failing",
    "start": "2348880",
    "end": "2354070"
  },
  {
    "text": "and the language model doing\nthe wrong reasoning for what's in the scene. It was 50/50, whether it\ncame from one or the other.",
    "start": "2354070",
    "end": "2361880"
  },
  {
    "text": "But I think as language\nmodels continue to get better, probably, if we went back and\nre-benchmarked this with like,",
    "start": "2361880",
    "end": "2367730"
  },
  {
    "text": "this was-- we probably\nran this a year ago. And if we did a\nlanguage model, now, I think it would be more\non the robotic side",
    "start": "2367730",
    "end": "2374210"
  },
  {
    "text": "than on the language model side. Thank you. ",
    "start": "2374210",
    "end": "2382770"
  },
  {
    "text": "More questions. ",
    "start": "2382770",
    "end": "2390820"
  },
  {
    "text": "A few questions\nfrom the Zoom room. Ken asked, what about monitoring\nforce feedback teleoperation",
    "start": "2390820",
    "end": "2398530"
  },
  {
    "text": "to teach or learn about\nforce interactions? ",
    "start": "2398530",
    "end": "2405280"
  },
  {
    "text": "Maybe, I need more context\non exactly what that means. But I think a lot of the data\nthat we've collected here",
    "start": "2405280",
    "end": "2414910"
  },
  {
    "text": "is through teleoperation. But it's always\nwith a-- or maybe, it's about improving\nteleoperation.",
    "start": "2414910",
    "end": "2420010"
  },
  {
    "text": "But right now, it's with\nan Oculus controller that's tied to what the hand is.",
    "start": "2420010",
    "end": "2425079"
  },
  {
    "text": "And honestly, our\nteleoperation is pretty basic.",
    "start": "2425080",
    "end": "2430738"
  },
  {
    "text": "I've tried to pick\nthings up with it. And it's hard to do. So I think things like\nadding in haptic feedback",
    "start": "2430738",
    "end": "2437770"
  },
  {
    "text": "would be incredibly impactful. We see things like\nrecent like ALOHA",
    "start": "2437770",
    "end": "2444820"
  },
  {
    "text": "paper, where it's just a\nmuch better controller. And it seems dexterous\nmanipulation is much easier.",
    "start": "2444820",
    "end": "2451220"
  },
  {
    "text": "So I think this is a\nhuge area that there's poor performance from\nteleoperation that's",
    "start": "2451220",
    "end": "2456740"
  },
  {
    "text": "limiting our expert data, which\nis then limiting our policies. Maybe, as a follow-up, a lot\nof the tasks that you show",
    "start": "2456740",
    "end": "2463220"
  },
  {
    "text": "are vision-based in robotics. You have lots of other sensors. Is there anything you could say\nabout what your thoughts are",
    "start": "2463220",
    "end": "2470090"
  },
  {
    "text": "on things like LiDAR\nor IMU or whatever? I think there's a lot of\ntasks that not having depth",
    "start": "2470090",
    "end": "2477350"
  },
  {
    "text": "in there is-- and not having torque sensing is\nprobably a little bit limiting.",
    "start": "2477350",
    "end": "2482660"
  },
  {
    "text": "I think the fact that, I\nguess, the way we think about it is we're trying to push\nas far as we can in the simplest domain to see what level\nof performance we can get.",
    "start": "2482660",
    "end": "2491030"
  },
  {
    "text": "If we were a product trying\nto get to the best one, we might add these in. But the fact that we can get\nto 97% on all these tasks,",
    "start": "2491030",
    "end": "2498140"
  },
  {
    "text": "this is like moving objects,\nopening drawers, putting things into things, flipping things\nover, and knocking a can over.",
    "start": "2498140",
    "end": "2505070"
  },
  {
    "text": "The haptics, you'd think,\nwould be important. But we can still actually\nget to 97% through learning.",
    "start": "2505070",
    "end": "2511460"
  },
  {
    "text": "You can get pretty\nfar with images. And since they're\navailable across the board,",
    "start": "2511460",
    "end": "2517340"
  },
  {
    "text": "we want to take the\nsimplest approach. But I do think, probably,\nclosing that last 3%",
    "start": "2517340",
    "end": "2522950"
  },
  {
    "text": "is maybe on adding in extra\nforms of supervision like that. Cool.",
    "start": "2522950",
    "end": "2528350"
  },
  {
    "text": "Final question from\nthe chat asked, curious if it's possible\nfor many of these models",
    "start": "2528350",
    "end": "2535290"
  },
  {
    "text": "to run on consumer hardware for\nsmaller robots like an NVIDIA Jetson or something. 550 billion parameters not going\nto be practical for hardware",
    "start": "2535290",
    "end": "2543630"
  },
  {
    "text": "of this size. So curious what the options\nare for improvement. I think there's a\nlot of areas around",
    "start": "2543630",
    "end": "2549630"
  },
  {
    "text": "like distilling policies that\nseem to be relatively promising. I also think the fact that\nthese are hosted in the cloud.",
    "start": "2549630",
    "end": "2556770"
  },
  {
    "text": "And there's somewhat\nminimal latency, we can run a lot of these at\nunder 1 hertz and, sometimes,",
    "start": "2556770",
    "end": "2565140"
  },
  {
    "text": "5 hertz. IT means that maybe\nthe Jetson doesn't need to have the\nmodel running on it.",
    "start": "2565140",
    "end": "2572520"
  },
  {
    "text": "It's probably the real answer\nthat it's not as crucial",
    "start": "2572520",
    "end": "2577628"
  },
  {
    "text": "as maybe we expect. There's probably some really\nhigh frequency things. And then there's ways\nto speed them up. But for now, the cloud\nseems to work pretty well.",
    "start": "2577628",
    "end": "2586990"
  },
  {
    "text": "Thank you. Elaborate more on how you're\nusing teleoperated data for training for image and text.",
    "start": "2586990",
    "end": "2593447"
  },
  {
    "text": "You don't need that. Are you training the trajectory\nof those using it teleoperation? So, essentially-- so\nthe full architecture",
    "start": "2593447",
    "end": "2601720"
  },
  {
    "text": "looks like we just take the\nlast six images and then output the next action\nthat the person took.",
    "start": "2601720",
    "end": "2609010"
  },
  {
    "text": "So if they have some\ntrajectory, we're chunking this up into\nsingle time steps, where we just predict the\nvery next action to take,",
    "start": "2609010",
    "end": "2616480"
  },
  {
    "text": "given those last six images. I see. So there is someone controlling\nthat arm [INAUDIBLE]",
    "start": "2616480",
    "end": "2623560"
  },
  {
    "text": "Yeah. So to get the data, we,\nessentially, someone takes an Oculus controller\nand moves as though they're",
    "start": "2623560",
    "end": "2630457"
  },
  {
    "text": "going to pick it up. They can also do like\na handheld controller, which moves the robot hand\nto then grasp the object.",
    "start": "2630457",
    "end": "2636810"
  },
  {
    "text": "We then take all that\ndemonstration data and turn it into\nsingle time steps, where we take in an image.",
    "start": "2636810",
    "end": "2642000"
  },
  {
    "text": "And we output an action. I see. Thank you. ",
    "start": "2642000",
    "end": "2651088"
  },
  {
    "text": "Thank you, Brian, for the talk. It was really great. You mentioned that RT1\noutputs actions directly.",
    "start": "2651088",
    "end": "2657839"
  },
  {
    "text": "Whereas, PaLM-E\noutputs decisions that a low-level\ncontroller executes.",
    "start": "2657840",
    "end": "2664230"
  },
  {
    "text": "I guess going forward, which\nof these two approaches",
    "start": "2664230",
    "end": "2669540"
  },
  {
    "text": "do you think is more reliable? And I'm also curious\nlike how reliable is the low-level controller that\nPaLM-E uses to execute actions.",
    "start": "2669540",
    "end": "2677640"
  },
  {
    "text": "So the level controller that\nPaLM-E uses is actually RT1. So it's relatively reliable,\nas long as it's in the scenes",
    "start": "2677640",
    "end": "2685500"
  },
  {
    "text": "that it's been in. But we do see good\ngeneralization, but maybe not perfect generalization.",
    "start": "2685500",
    "end": "2692490"
  },
  {
    "text": "In terms of-- right\nnow, I think the reason why we split it this way is\nthat most the internet data",
    "start": "2692490",
    "end": "2698220"
  },
  {
    "text": "that the language model\nhas been trained on is at that higher level. There isn't action\ndata or things",
    "start": "2698220",
    "end": "2704640"
  },
  {
    "text": "like that are in the internet. I think going forward,\nthough, we're definitely pushing in this direction\nof what levels can",
    "start": "2704640",
    "end": "2711069"
  },
  {
    "text": "we train into these\nmodels and still get pretty high performance. And I think it's somewhat\nof an open question of,",
    "start": "2711070",
    "end": "2717430"
  },
  {
    "text": "where do you get\nbetter performance? Maybe, the language model\nor the vision language model does much better generalization.",
    "start": "2717430",
    "end": "2723880"
  },
  {
    "text": "So, potentially,\nyou need to find the sweet spot in trade-offs\nbetween performance and generalization\nacross the two.",
    "start": "2723880",
    "end": "2730690"
  },
  {
    "text": "So I think the small local model\nis probably higher performance and the other one has higher\ngeneralization is the answer.",
    "start": "2730690",
    "end": "2739790"
  },
  {
    "text": "Got it. And I guess a quick\nfollow-up to that is, for most of the failures\nyou're observing, is that",
    "start": "2739790",
    "end": "2746140"
  },
  {
    "text": "at the low-level\ncontroller level or is that the LLM or VLM level?",
    "start": "2746140",
    "end": "2751630"
  },
  {
    "text": "I guess, initially, about a\nyear ago when we did this, it was 50/50 across,\nwhether it was",
    "start": "2751630",
    "end": "2757539"
  },
  {
    "text": "the high-level making a mistake\nor the low-level making mistake. Now, I think, if you do like\nPaLM-E or something like this,",
    "start": "2757540",
    "end": "2763570"
  },
  {
    "text": "it's much more on the low\nlevel making mistakes. It's probably 80/20 now.",
    "start": "2763570",
    "end": "2770950"
  },
  {
    "text": "The performance of\nfoundation models improving has certainly put\nrobotics in the lower",
    "start": "2770950",
    "end": "2777940"
  },
  {
    "text": "position of performance, like,\nthe errors are on our stack. Thank you so much.",
    "start": "2777940",
    "end": "2784842"
  },
  {
    "text": "Are they any more? Last question. ",
    "start": "2784842",
    "end": "2790339"
  },
  {
    "text": "No. Thank you, again. You have one. ",
    "start": "2790340",
    "end": "2796570"
  },
  {
    "text": "Just out of curiosity, now,\nthat we have you here and have the robot running,\nwhat happens if you ask it to do stuff\nwith objects that",
    "start": "2796570",
    "end": "2803680"
  },
  {
    "text": "are not actually in the scene? Does it throw an error? Or does it try something weird? So I think because it's on\ncode, it probably won't do much.",
    "start": "2803680",
    "end": "2812380"
  },
  {
    "text": "But we can-- what\nwould you like?",
    "start": "2812380",
    "end": "2819549"
  },
  {
    "text": "An apple. Let's see. ",
    "start": "2819550",
    "end": "2826673"
  },
  {
    "text": "It says, I don't have an apple.  It does have this list of\nobjects that are coded in for it",
    "start": "2826673",
    "end": "2836020"
  },
  {
    "text": "to look for. And I guess not on the list. And then that goes through\nthe object detector, and to the language model.",
    "start": "2836020",
    "end": "2841390"
  },
  {
    "text": "I've never-- I haven't\ntried that before. But it doesn't. And you can actually--",
    "start": "2841390",
    "end": "2847000"
  },
  {
    "text": "unfortunately, I can't\nincrease the size of this. But this is all the code that\ngets actually run to do it.",
    "start": "2847000",
    "end": "2853617"
  },
  {
    "text": "And in this case, the\nlanguage model just took it. It just responded\nwithout writing any code.",
    "start": "2853617",
    "end": "2858790"
  },
  {
    "text": " All right. Thank you, again.",
    "start": "2858790",
    "end": "2863869"
  },
  {
    "text": "Thanks. [APPLAUSE] ",
    "start": "2863870",
    "end": "2871000"
  }
]
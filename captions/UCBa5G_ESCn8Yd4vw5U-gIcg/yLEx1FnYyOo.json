[
  {
    "text": "OK.",
    "start": "0",
    "end": "710"
  },
  {
    "text": "The final classification method\nwe'll talk about in today's lab",
    "start": "710",
    "end": "4009"
  },
  {
    "text": "is K-Nearest Neighbors.",
    "start": "4010",
    "end": "5210"
  },
  {
    "text": "And although a different\nclassifier to LDA and QDA",
    "start": "5210",
    "end": "8600"
  },
  {
    "text": "in terms of using sklearn,\nit's quite similar.",
    "start": "8600",
    "end": "11700"
  },
  {
    "text": "So the difference is\nreally in the actual method",
    "start": "11700",
    "end": "15019"
  },
  {
    "text": "we're going to use,\nthat's this first class we",
    "start": "15020",
    "end": "17450"
  },
  {
    "text": "call from scikit learn.",
    "start": "17450",
    "end": "18890"
  },
  {
    "text": "It's the K-Nearest\nNeighbors class,",
    "start": "18890",
    "end": "20689"
  },
  {
    "text": "we construct a classifier\nusing the one nearest neighbor.",
    "start": "20690",
    "end": "25250"
  },
  {
    "text": "The rest of the code\nwhere we fit and predict",
    "start": "25250",
    "end": "27619"
  },
  {
    "text": "on training-- fit on training\npredict on test is identical.",
    "start": "27620",
    "end": "32060"
  },
  {
    "text": "And again, compute\nthe confusion matrix.",
    "start": "32060",
    "end": "35760"
  },
  {
    "text": "So we see here that using\none nearest neighbors,",
    "start": "35760",
    "end": "38430"
  },
  {
    "text": "which is going to be a\nvery flexible classifier.",
    "start": "38430",
    "end": "41460"
  },
  {
    "text": "So like possibly\nhaving high variance,",
    "start": "41460",
    "end": "45170"
  },
  {
    "text": "it may suffer from overfitting.",
    "start": "45170",
    "end": "47359"
  },
  {
    "text": "And indeed, the classifier\nis not very good.",
    "start": "47360",
    "end": "50480"
  },
  {
    "text": "It has about 50% test accuracy.",
    "start": "50480",
    "end": "53030"
  },
  {
    "text": "As bad as you can get.",
    "start": "53030",
    "end": "54199"
  },
  {
    "text": "Yes.",
    "start": "54200",
    "end": "55310"
  },
  {
    "text": "OK.",
    "start": "55310",
    "end": "56090"
  },
  {
    "text": "Let's see if we change\nthe number of neighbors",
    "start": "56090",
    "end": "59720"
  },
  {
    "text": "if we do a bit better.",
    "start": "59720",
    "end": "60840"
  },
  {
    "text": "Using three neighbors,\nwe get about 53%,",
    "start": "60840",
    "end": "64000"
  },
  {
    "text": "which is better,\nbut not quite as",
    "start": "64000",
    "end": "66210"
  },
  {
    "text": "good as the discriminant\nmethods we saw before.",
    "start": "66210",
    "end": "68979"
  },
  {
    "text": "So these K-Nearest\nNeighbor methods",
    "start": "68980",
    "end": "70950"
  },
  {
    "text": "are extremely\nadaptable and flexible,",
    "start": "70950",
    "end": "73750"
  },
  {
    "text": "but they can overfit\nespecially on small data sets.",
    "start": "73750",
    "end": "78660"
  },
  {
    "text": "Yes.",
    "start": "78660",
    "end": "79380"
  },
  {
    "text": "So it would be nice\nto be able to choose",
    "start": "79380",
    "end": "81119"
  },
  {
    "text": "this using in a simple fashion\nand that's what we'll do next.",
    "start": "81120",
    "end": "85660"
  },
  {
    "text": "So we're going to use a\nslightly different data set.",
    "start": "85660",
    "end": "88260"
  },
  {
    "text": "This is the Caravan data set\nfrom the ISLP package, which",
    "start": "88260",
    "end": "92790"
  },
  {
    "text": "talks about whether we can\npredict whether people purchase",
    "start": "92790",
    "end": "96240"
  },
  {
    "text": "caravan insurance or not.",
    "start": "96240",
    "end": "98890"
  },
  {
    "text": "And it's noted-- it's a very\nimbalanced classification",
    "start": "98890",
    "end": "102120"
  },
  {
    "text": "problem because there's only\n6% that actually do purchase,",
    "start": "102120",
    "end": "105330"
  },
  {
    "text": "unlike the stock\nmarket data where",
    "start": "105330",
    "end": "108000"
  },
  {
    "text": "the up or downs are\ngoing to be roughly 50%",
    "start": "108000",
    "end": "110570"
  },
  {
    "text": "if it's basically noise.",
    "start": "110570",
    "end": "113040"
  },
  {
    "text": "In case you didn't\nknow, a caravan",
    "start": "113040",
    "end": "114720"
  },
  {
    "text": "is a campervan in\nAustralia and New Zealand",
    "start": "114720",
    "end": "118320"
  },
  {
    "text": "and South Africa\nand other colonies.",
    "start": "118320",
    "end": "121930"
  },
  {
    "text": "And I guess it would be\nan RV in North America.",
    "start": "121930",
    "end": "126810"
  },
  {
    "text": "OK.",
    "start": "126810",
    "end": "127799"
  },
  {
    "text": "So we'll just create--",
    "start": "127800",
    "end": "131889"
  },
  {
    "text": "we'll use all of the features\nbesides the purchase column",
    "start": "131889",
    "end": "135300"
  },
  {
    "text": "to create some features.",
    "start": "135300",
    "end": "137760"
  },
  {
    "text": "And now, unlike the\nstock market data",
    "start": "137760",
    "end": "141720"
  },
  {
    "text": "where we just had lag 1\nand lag 2 as our features",
    "start": "141720",
    "end": "144783"
  },
  {
    "text": "it turns out there are\nmany different features",
    "start": "144783",
    "end": "146700"
  },
  {
    "text": "in this caravan\nthat are measured",
    "start": "146700",
    "end": "148950"
  },
  {
    "text": "in slightly different units.",
    "start": "148950",
    "end": "150310"
  },
  {
    "text": "So since the K-Nearest\nNeighbors classifier",
    "start": "150310",
    "end": "153840"
  },
  {
    "text": "uses distances between\npoints, if one variable is",
    "start": "153840",
    "end": "157410"
  },
  {
    "text": "much-- has very different\nunits than another variable,",
    "start": "157410",
    "end": "160080"
  },
  {
    "text": "it will tend to\ndominate the distance.",
    "start": "160080",
    "end": "161860"
  },
  {
    "text": "So for that reason,\nwe're going to use--",
    "start": "161860",
    "end": "164130"
  },
  {
    "text": "we're going to standardize the\nfeatures before classifying.",
    "start": "164130",
    "end": "167520"
  },
  {
    "text": "So for that, we'll use a\nscalar or the standard scalar",
    "start": "167520",
    "end": "171030"
  },
  {
    "text": "from scikit learn.",
    "start": "171030",
    "end": "172420"
  },
  {
    "text": "And this is an example\nof a transformer.",
    "start": "172420",
    "end": "175020"
  },
  {
    "text": "We saw transformers in\nchapter 3 in linear regression",
    "start": "175020",
    "end": "180660"
  },
  {
    "text": "in the model spec.",
    "start": "180660",
    "end": "181470"
  },
  {
    "text": "That was an example\nof a transformer.",
    "start": "181470",
    "end": "183420"
  },
  {
    "text": "And if you remember,\nthe transformer",
    "start": "183420",
    "end": "185880"
  },
  {
    "text": "it's something that\nwe mentioned is",
    "start": "185880",
    "end": "188050"
  },
  {
    "text": "used to derive features\nfrom existing features.",
    "start": "188050",
    "end": "192230"
  },
  {
    "text": "That's a typical application.",
    "start": "192230",
    "end": "193819"
  },
  {
    "text": "So we apply-- we call its fit\nmethod on a set of features,",
    "start": "193820",
    "end": "197350"
  },
  {
    "text": "notice there's no-- there's just\nthe set of features in this fit",
    "start": "197350",
    "end": "200650"
  },
  {
    "text": "method, not a response\nbecause it's taking features",
    "start": "200650",
    "end": "203319"
  },
  {
    "text": "to create new features.",
    "start": "203320",
    "end": "204670"
  },
  {
    "text": "And having fit the\ntransformer that",
    "start": "204670",
    "end": "207550"
  },
  {
    "text": "finds all the parameters,\nin this case, the means",
    "start": "207550",
    "end": "210670"
  },
  {
    "text": "and variances needed to\nscale the features to mean",
    "start": "210670",
    "end": "213849"
  },
  {
    "text": "0 and variance 1,\nthen we can apply it",
    "start": "213850",
    "end": "216100"
  },
  {
    "text": "to the features using\nthe transform method.",
    "start": "216100",
    "end": "220070"
  },
  {
    "text": "OK.",
    "start": "220070",
    "end": "220730"
  },
  {
    "text": "So we'll use our\nstandardized features",
    "start": "220730",
    "end": "222650"
  },
  {
    "text": "for K-Nearest Neighbors.",
    "start": "222650",
    "end": "224180"
  },
  {
    "start": "224180",
    "end": "227310"
  },
  {
    "text": "And we'll also do a split\ninto test and training.",
    "start": "227310",
    "end": "231209"
  },
  {
    "text": "And we'll use the test data\nwith various different neighbor",
    "start": "231210",
    "end": "236850"
  },
  {
    "text": "sizes to try and choose a\ngood number of neighbors.",
    "start": "236850",
    "end": "242550"
  },
  {
    "text": "OK.",
    "start": "242550",
    "end": "243090"
  },
  {
    "text": "So this is just like the stock\nmarket K-Nearest Neighbors",
    "start": "243090",
    "end": "246000"
  },
  {
    "text": "example, except of course,\nwe have different data.",
    "start": "246000",
    "end": "248250"
  },
  {
    "text": "This is the caravan data and\nnot the stock market data.",
    "start": "248250",
    "end": "251820"
  },
  {
    "text": "We see with one nearest\nneighbor, actually,",
    "start": "251820",
    "end": "258180"
  },
  {
    "text": "we get about 11% accuracy,\nwhich is better than 6%.",
    "start": "258180",
    "end": "263820"
  },
  {
    "text": "6% is what we would get if\nwe had a reasonable estimate",
    "start": "263820",
    "end": "266520"
  },
  {
    "text": "of what we would get if we\nhad no features, if we just",
    "start": "266520",
    "end": "268770"
  },
  {
    "text": "used an intercept in the model.",
    "start": "268770",
    "end": "270280"
  },
  {
    "text": "So we see some improvement.",
    "start": "270280",
    "end": "272880"
  },
  {
    "text": "But not always-- not\na great improvement.",
    "start": "272880",
    "end": "276840"
  },
  {
    "text": "OK.",
    "start": "276840",
    "end": "277770"
  },
  {
    "text": "So let's talk about choosing\nthe number of nearest neighbors.",
    "start": "277770",
    "end": "280949"
  },
  {
    "text": "This is an example of\nchoosing a tuning parameter",
    "start": "280950",
    "end": "283440"
  },
  {
    "text": "for an estimator, a\ncommon task that we'll see",
    "start": "283440",
    "end": "286300"
  },
  {
    "text": "in other examples coming up.",
    "start": "286300",
    "end": "288680"
  },
  {
    "text": "So what we're going to do is\nfit the K-Nearest Neighbor",
    "start": "288680",
    "end": "295690"
  },
  {
    "text": "classifier for varying\nnumbers of neighbors.",
    "start": "295690",
    "end": "298300"
  },
  {
    "text": "And we're going to choose\nneighbors from here in--",
    "start": "298300",
    "end": "302849"
  },
  {
    "text": "we have a for loop.",
    "start": "302850",
    "end": "304130"
  },
  {
    "text": "And we're going to loop over\nthe neighbors one to five.",
    "start": "304130",
    "end": "308180"
  },
  {
    "text": "And just in case you're--",
    "start": "308180",
    "end": "311020"
  },
  {
    "text": "well, that's the\nrange 1 to 6 actually,",
    "start": "311020",
    "end": "313539"
  },
  {
    "text": "really gives us only\nthe numbers 1 to 5.",
    "start": "313540",
    "end": "316120"
  },
  {
    "text": "That's how the range\nfunction works.",
    "start": "316120",
    "end": "319190"
  },
  {
    "text": "OK.",
    "start": "319190",
    "end": "319690"
  },
  {
    "text": "So what we're going to\ndo is we're going to--",
    "start": "319690",
    "end": "321670"
  },
  {
    "text": "within for loop, do essentially\nwhat we had done above,",
    "start": "321670",
    "end": "325720"
  },
  {
    "text": "that is we're going to\nfit on the training data,",
    "start": "325720",
    "end": "328930"
  },
  {
    "text": "predict on the test data, and\nform the confusion matrix.",
    "start": "328930",
    "end": "332740"
  },
  {
    "text": "And then we'll\ncompute the accuracy",
    "start": "332740",
    "end": "334660"
  },
  {
    "text": "and we're just going to\nprint out with this statement",
    "start": "334660",
    "end": "337540"
  },
  {
    "text": "here, print out the accuracy\nas a function of nearest",
    "start": "337540",
    "end": "340210"
  },
  {
    "text": "neighbors.",
    "start": "340210",
    "end": "340900"
  },
  {
    "text": "In later labs, we'll\nmake a plot of accuracy",
    "start": "340900",
    "end": "345009"
  },
  {
    "text": "or mean squared error as a\nfunction of tuning parameter.",
    "start": "345010",
    "end": "348550"
  },
  {
    "text": "Here, we're just\ngoing to print it out.",
    "start": "348550",
    "end": "352039"
  },
  {
    "text": "OK.",
    "start": "352040",
    "end": "354290"
  },
  {
    "text": "And so one small thing that\nif you noticed earlier,",
    "start": "354290",
    "end": "358440"
  },
  {
    "text": "it took us three lines to\nform the confusion matrix.",
    "start": "358440",
    "end": "361820"
  },
  {
    "text": "We avoided a line by\nlooking at the fit predictor",
    "start": "361820",
    "end": "365270"
  },
  {
    "text": "and directly calling\nit predict method.",
    "start": "365270",
    "end": "368000"
  },
  {
    "text": "It's only two lines to fit\nand form the confusion matrix.",
    "start": "368000",
    "end": "373100"
  },
  {
    "text": "OK.",
    "start": "373100",
    "end": "373820"
  },
  {
    "text": "So let's see.",
    "start": "373820",
    "end": "377060"
  },
  {
    "text": "For this test and\ntraining splits,",
    "start": "377060",
    "end": "379970"
  },
  {
    "text": "we can see most of the\nnumber of neighbors",
    "start": "379970",
    "end": "383990"
  },
  {
    "text": "achieve around 14% or 15%\naccuracy with four neighbors",
    "start": "383990",
    "end": "388250"
  },
  {
    "text": "being a kind of anomaly.",
    "start": "388250",
    "end": "390350"
  },
  {
    "text": "We haven't really investigated\nbut it is a notable difference",
    "start": "390350",
    "end": "393890"
  },
  {
    "text": "between the other ones.",
    "start": "393890",
    "end": "395360"
  },
  {
    "text": "It only predicted forward rent.",
    "start": "395360",
    "end": "398039"
  },
  {
    "text": "Yes.",
    "start": "398040",
    "end": "398540"
  },
  {
    "text": "So it was strange.",
    "start": "398540",
    "end": "401060"
  },
  {
    "text": "And you can get this\nwith nearest neighbors",
    "start": "401060",
    "end": "403070"
  },
  {
    "text": "because it's a very\nnoisy classifier.",
    "start": "403070",
    "end": "406950"
  },
  {
    "text": "OK.",
    "start": "406950",
    "end": "407450"
  },
  {
    "text": "So that wraps up what we were\ngoing to talk about in the lab",
    "start": "407450",
    "end": "410590"
  },
  {
    "text": "today.",
    "start": "410590",
    "end": "411090"
  },
  {
    "text": "There are a few more\nsections in the lab",
    "start": "411090",
    "end": "412757"
  },
  {
    "text": "that we encourage\nyou to go through,",
    "start": "412757",
    "end": "414569"
  },
  {
    "text": "one including Poisson regression\nthat we will leave to you",
    "start": "414570",
    "end": "419220"
  },
  {
    "text": "to do offline.",
    "start": "419220",
    "end": "421340"
  },
  {
    "start": "421340",
    "end": "426000"
  }
]
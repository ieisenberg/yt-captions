[
  {
    "text": "Our next topic are\nconvolutional neural networks.",
    "start": "0",
    "end": "2720"
  },
  {
    "text": "These are very popular\nmodels for image processing",
    "start": "2720",
    "end": "5480"
  },
  {
    "text": "because they capture\nlocal features quite well.",
    "start": "5480",
    "end": "9000"
  },
  {
    "text": "And we're going to use some\ndata from the CIFAR100 data set.",
    "start": "9000",
    "end": "12510"
  },
  {
    "text": "This is one of these\nbig data sets that",
    "start": "12510",
    "end": "15290"
  },
  {
    "text": "are curated by the\ndeep learning community",
    "start": "15290",
    "end": "18170"
  },
  {
    "text": "to compare different models.",
    "start": "18170",
    "end": "20060"
  },
  {
    "text": "And the hundreds sense,\na hundred data classes.",
    "start": "20060",
    "end": "23279"
  },
  {
    "text": "So it's a 100 class\nclassification problem.",
    "start": "23280",
    "end": "25072"
  },
  {
    "text": "Yes.",
    "start": "25072",
    "end": "25572"
  },
  {
    "text": "So for reference, a\nrandom guessing here",
    "start": "25572",
    "end": "27290"
  },
  {
    "text": "should be about 1% accurate.",
    "start": "27290",
    "end": "29050"
  },
  {
    "text": "Yeah.",
    "start": "29050",
    "end": "29550"
  },
  {
    "start": "29550",
    "end": "32930"
  },
  {
    "text": "So the pattern is going to\nbe similar to the Hitters",
    "start": "32930",
    "end": "35720"
  },
  {
    "text": "and MNIST data.",
    "start": "35720",
    "end": "36620"
  },
  {
    "text": "We will sort of\nspecify the data sets,",
    "start": "36620",
    "end": "39260"
  },
  {
    "text": "and then we'll\nspecify the network--",
    "start": "39260",
    "end": "42769"
  },
  {
    "text": "that is how features are\ntransformed to scores--",
    "start": "42770",
    "end": "45020"
  },
  {
    "text": "define the loss,\ndefine the fitter,",
    "start": "45020",
    "end": "47690"
  },
  {
    "text": "and then look at the results.",
    "start": "47690",
    "end": "49129"
  },
  {
    "text": "OK.",
    "start": "49130",
    "end": "50750"
  },
  {
    "text": "The CIFAR data comes packaged\nin the torchvision package,",
    "start": "50750",
    "end": "54200"
  },
  {
    "text": "which is convenient.",
    "start": "54200",
    "end": "55562"
  },
  {
    "text": "In order for us to fit it,\nwe're going to actually do",
    "start": "55562",
    "end": "57770"
  },
  {
    "text": "a little bit of pre-processing.",
    "start": "57770",
    "end": "59930"
  },
  {
    "text": "This is done here.",
    "start": "59930",
    "end": "61340"
  },
  {
    "text": "All that's going on\nhere is this rescaled",
    "start": "61340",
    "end": "63200"
  },
  {
    "text": "to be floating point from 0 to\n1, instead of integer 0 to 255,",
    "start": "63200",
    "end": "68420"
  },
  {
    "text": "and just reorders the arrays.",
    "start": "68420",
    "end": "71159"
  },
  {
    "text": "So does a little transpose.",
    "start": "71160",
    "end": "74030"
  },
  {
    "text": "So then, we have\nour data module,",
    "start": "74030",
    "end": "76220"
  },
  {
    "text": "like we did for\nthe other examples.",
    "start": "76220",
    "end": "78170"
  },
  {
    "text": "We have training data\ntest data, and we'll",
    "start": "78170",
    "end": "81020"
  },
  {
    "text": "use 20% of training\ndata as validation,",
    "start": "81020",
    "end": "83539"
  },
  {
    "text": "and each batch will\nbe of size 128.",
    "start": "83540",
    "end": "86990"
  },
  {
    "text": "So these input images, it's\nthree-dimensional tensor,",
    "start": "86990",
    "end": "90740"
  },
  {
    "text": "right, Jonathan?",
    "start": "90740",
    "end": "91430"
  },
  {
    "text": "That's right.",
    "start": "91430",
    "end": "92240"
  },
  {
    "text": "Three-color channels.",
    "start": "92240",
    "end": "94369"
  },
  {
    "text": "Yes.",
    "start": "94370",
    "end": "95160"
  },
  {
    "text": "So color images are\nrepresented as RGB.",
    "start": "95160",
    "end": "100190"
  },
  {
    "text": "I think Trevor is\ntalking about this 3",
    "start": "100190",
    "end": "104640"
  },
  {
    "text": "here when we look at\nthe different data set.",
    "start": "104640",
    "end": "107520"
  },
  {
    "text": "So the images have three\nchannels and are 32 by 32.",
    "start": "107520",
    "end": "113090"
  },
  {
    "text": "These are RGB channels.",
    "start": "113090",
    "end": "114539"
  },
  {
    "text": "There's also RGB alpha perhaps.",
    "start": "114540",
    "end": "116610"
  },
  {
    "text": "And the MNIST data,\nactually, this was a 1 here.",
    "start": "116610",
    "end": "121020"
  },
  {
    "text": "So we're showing you\nwhat a typical batch",
    "start": "121020",
    "end": "123000"
  },
  {
    "text": "looks like because we've\ngot batch size of 128 here.",
    "start": "123000",
    "end": "126240"
  },
  {
    "text": "That's right.",
    "start": "126240",
    "end": "126810"
  },
  {
    "text": "So there's 128 images\nrandomly selected for a batch,",
    "start": "126810",
    "end": "130800"
  },
  {
    "text": "and then those are the\ndimensions 3, 32, 32.",
    "start": "130800",
    "end": "134310"
  },
  {
    "text": "Yes.",
    "start": "134310",
    "end": "134910"
  },
  {
    "text": "This is just a sort\nof sanity check",
    "start": "134910",
    "end": "136470"
  },
  {
    "text": "to see that the we've\nmade the data loader--",
    "start": "136470",
    "end": "139320"
  },
  {
    "text": "that we understand what\nthe data is looking",
    "start": "139320",
    "end": "141120"
  },
  {
    "text": "like before it goes in.",
    "start": "141120",
    "end": "143230"
  },
  {
    "text": "Let's just take a look\nat these images to see.",
    "start": "143230",
    "end": "146730"
  },
  {
    "text": "The resolution is not great.",
    "start": "146730",
    "end": "149010"
  },
  {
    "text": "It's 32 by 32, but they're still\nrecognizable objects, right?",
    "start": "149010",
    "end": "152040"
  },
  {
    "text": "This one is a wolf.",
    "start": "152040",
    "end": "153879"
  },
  {
    "text": "This one might be Bigfoot.",
    "start": "153880",
    "end": "155100"
  },
  {
    "text": "I don't know.",
    "start": "155100",
    "end": "157560"
  },
  {
    "text": "This is an apple.",
    "start": "157560",
    "end": "158370"
  },
  {
    "text": "That's a nice thing about having\nimages as data observations",
    "start": "158370",
    "end": "163060"
  },
  {
    "text": "because you can look at them.",
    "start": "163060",
    "end": "165010"
  },
  {
    "text": "Usually, you can't look\nat high-dimensional data",
    "start": "165010",
    "end": "167720"
  },
  {
    "text": "so nicely, but images, you can.",
    "start": "167720",
    "end": "169595"
  },
  {
    "text": "Yes.",
    "start": "169595",
    "end": "170095"
  },
  {
    "start": "170095",
    "end": "173690"
  },
  {
    "text": "OK.",
    "start": "173690",
    "end": "174190"
  },
  {
    "text": "So now, we're going to\ndefine our neural network,",
    "start": "174190",
    "end": "177880"
  },
  {
    "text": "and what we're going to do is,\nas is common in these tasks,",
    "start": "177880",
    "end": "181900"
  },
  {
    "text": "is we'll sort of make a\nmulti-scale kind of version",
    "start": "181900",
    "end": "185799"
  },
  {
    "text": "of the analysis.",
    "start": "185800",
    "end": "186640"
  },
  {
    "text": "That is, we're going to\ndo a convolutional filter.",
    "start": "186640",
    "end": "189819"
  },
  {
    "text": "That's this Conv2d from the\nnn module, and apply the ReLU,",
    "start": "189820",
    "end": "198040"
  },
  {
    "text": "and then what's called a\nmax pool over the output,",
    "start": "198040",
    "end": "202028"
  },
  {
    "text": "and we're going to do this\nat several different scales.",
    "start": "202028",
    "end": "204320"
  },
  {
    "text": "So the way we're\ngoing to do this",
    "start": "204320",
    "end": "205695"
  },
  {
    "text": "is to define a basic layer\nthat we'll call building block,",
    "start": "205695",
    "end": "210140"
  },
  {
    "text": "and we'll use building\nblocks of different sizes",
    "start": "210140",
    "end": "212140"
  },
  {
    "text": "in this multi-scale\nkind of network.",
    "start": "212140",
    "end": "216819"
  },
  {
    "text": "By the way, you should\nhave read the chapter",
    "start": "216820",
    "end": "218980"
  },
  {
    "text": "on convolutional neural\nnetworks before doing this lab",
    "start": "218980",
    "end": "222760"
  },
  {
    "text": "because it'll be much\nmore understandable,",
    "start": "222760",
    "end": "224650"
  },
  {
    "text": "and then you'll\nunderstand the idea",
    "start": "224650",
    "end": "226540"
  },
  {
    "text": "of doing convolution and\npooling in that order",
    "start": "226540",
    "end": "230469"
  },
  {
    "text": "sequence of those operations.",
    "start": "230470",
    "end": "232330"
  },
  {
    "text": "Yes.",
    "start": "232330",
    "end": "233110"
  },
  {
    "text": "This is, of course,\njust the lab.",
    "start": "233110",
    "end": "235030"
  },
  {
    "text": "And so what we're doing\nhere is effectively",
    "start": "235030",
    "end": "238720"
  },
  {
    "text": "making a new type of layer.",
    "start": "238720",
    "end": "240410"
  },
  {
    "text": "So we've already seen\nsome of the layers that",
    "start": "240410",
    "end": "244000"
  },
  {
    "text": "are in this nn package.",
    "start": "244000",
    "end": "245260"
  },
  {
    "text": "We've seen like nn.sequential,\nnn.linear, nn.ReLU.",
    "start": "245260",
    "end": "249700"
  },
  {
    "text": "These are all the\nkind of operations",
    "start": "249700",
    "end": "251410"
  },
  {
    "text": "that can be done by\none of the nodes,",
    "start": "251410",
    "end": "253690"
  },
  {
    "text": "and here, nn.Conv2d\nis one of those.",
    "start": "253690",
    "end": "257120"
  },
  {
    "text": "So what we're doing\nhere is essentially",
    "start": "257120",
    "end": "258820"
  },
  {
    "text": "making our own layer that\nwe're going to later use",
    "start": "258820",
    "end": "261940"
  },
  {
    "text": "to build in our\nCIFAR100 network, each",
    "start": "261940",
    "end": "267640"
  },
  {
    "text": "of these convolution\nand max pool layers.",
    "start": "267640",
    "end": "269560"
  },
  {
    "text": "OK.",
    "start": "269560",
    "end": "270060"
  },
  {
    "start": "270060",
    "end": "273190"
  },
  {
    "text": "So what we're going to do is,\nwe're going to make a sequence.",
    "start": "273190",
    "end": "277630"
  },
  {
    "text": "As I said, we're going\nto use our building block",
    "start": "277630",
    "end": "280870"
  },
  {
    "text": "and apply this convolution and\nmax pool on different scales,",
    "start": "280870",
    "end": "286090"
  },
  {
    "text": "and the scales are\ngoing to go as follows.",
    "start": "286090",
    "end": "288310"
  },
  {
    "text": "These numbers here\nare the channels",
    "start": "288310",
    "end": "290380"
  },
  {
    "text": "that are going to be applied\nfor the output of each",
    "start": "290380",
    "end": "298060"
  },
  {
    "text": "of the building block layers.",
    "start": "298060",
    "end": "299860"
  },
  {
    "text": "So input and output,\nI should say.",
    "start": "299860",
    "end": "301990"
  },
  {
    "text": "The first one has\nthree channels,",
    "start": "301990",
    "end": "304270"
  },
  {
    "text": "and we're going to\noutput 32 channels.",
    "start": "304270",
    "end": "310479"
  },
  {
    "text": "One of the things\nabout the max pooling,",
    "start": "310480",
    "end": "312430"
  },
  {
    "text": "since we did a kernel\nsize of 2 by 2,",
    "start": "312430",
    "end": "314680"
  },
  {
    "text": "it will half the size\nof the image each time.",
    "start": "314680",
    "end": "317330"
  },
  {
    "text": "So we start off\nwith 3 by 32 by 32,",
    "start": "317330",
    "end": "323000"
  },
  {
    "text": "and then we'll finish\nwith 32 by 16 by 16,",
    "start": "323000",
    "end": "326350"
  },
  {
    "text": "and then we'll have 32\nby 16 by 16, and 64 by 8",
    "start": "326350",
    "end": "330460"
  },
  {
    "text": "by 8, et cetera.",
    "start": "330460",
    "end": "331910"
  },
  {
    "text": "So once we have this object that\ncan do this convolution and max",
    "start": "331910",
    "end": "335530"
  },
  {
    "text": "pool, that's what we call\nbuilding block before,",
    "start": "335530",
    "end": "338080"
  },
  {
    "text": "we're just going to\napply these in sequence.",
    "start": "338080",
    "end": "340419"
  },
  {
    "text": "So we have these\ndifferent sizes.",
    "start": "340420",
    "end": "342530"
  },
  {
    "text": "This defines the scales\nthat we'll look at,",
    "start": "342530",
    "end": "345070"
  },
  {
    "text": "and we'll just make a\nsequential layer that",
    "start": "345070",
    "end": "349150"
  },
  {
    "text": "uses these in a\nsequence, and here, we're",
    "start": "349150",
    "end": "351820"
  },
  {
    "text": "using the list\ncomprehension of Python.",
    "start": "351820",
    "end": "354490"
  },
  {
    "text": "We'll have seen that\nin the labs before.",
    "start": "354490",
    "end": "356770"
  },
  {
    "text": "If not on video, then\nin the text of the labs,",
    "start": "356770",
    "end": "359259"
  },
  {
    "text": "and this argument here, star,\nthat just takes a sequence",
    "start": "359260",
    "end": "363610"
  },
  {
    "text": "and gives all of those as\narguments to sequential.",
    "start": "363610",
    "end": "366729"
  },
  {
    "text": "So this is really\nnice, Jonathan.",
    "start": "366730",
    "end": "368290"
  },
  {
    "text": "In the previous one with the\nMNIST, we did layer 1, layer 2,",
    "start": "368290",
    "end": "371890"
  },
  {
    "text": "but here, you can just\nprogrammatically specify",
    "start": "371890",
    "end": "375340"
  },
  {
    "text": "the thing and just go in a loop\nand set up all these layers.",
    "start": "375340",
    "end": "377990"
  },
  {
    "text": "Yes.",
    "start": "377990",
    "end": "378490"
  },
  {
    "text": "It's very nice.",
    "start": "378490",
    "end": "378819"
  },
  {
    "text": "It's much more compact.",
    "start": "378820",
    "end": "379810"
  },
  {
    "text": "We would have had to have--",
    "start": "379810",
    "end": "381250"
  },
  {
    "text": "each one might take\nfour or five lines,",
    "start": "381250",
    "end": "383140"
  },
  {
    "text": "so it would have been 20\nlines instead of six or seven.",
    "start": "383140",
    "end": "386710"
  },
  {
    "text": "And then at the end,\nwe'll have 256 channels,",
    "start": "386710",
    "end": "389830"
  },
  {
    "text": "and we're going to have\nto ultimately output that",
    "start": "389830",
    "end": "392110"
  },
  {
    "text": "to 256 channels, and it's\ngoing to be a 2 by 2 image.",
    "start": "392110",
    "end": "398080"
  },
  {
    "text": "So the final output after the\nmax pool will the 256 by 2",
    "start": "398080",
    "end": "403139"
  },
  {
    "text": "by 2.",
    "start": "403140",
    "end": "403950"
  },
  {
    "text": "We'll output that\nto 512, and then",
    "start": "403950",
    "end": "406650"
  },
  {
    "text": "do a ReLU for good\nmeasure, and output to 100.",
    "start": "406650",
    "end": "410009"
  },
  {
    "text": "That's the number of classes.",
    "start": "410010",
    "end": "411840"
  },
  {
    "text": "And OK, once we specified\nour network in that fashion,",
    "start": "411840",
    "end": "416310"
  },
  {
    "text": "the training, et\ncetera, will be similar.",
    "start": "416310",
    "end": "419940"
  },
  {
    "text": "In this case, the\nsummary is a little long,",
    "start": "419940",
    "end": "425550"
  },
  {
    "text": "but it should be predictable\nin how to read it now.",
    "start": "425550",
    "end": "428190"
  },
  {
    "text": "There are quite a\nfew parameters now.",
    "start": "428190",
    "end": "430820"
  },
  {
    "text": "A million parameters.",
    "start": "430820",
    "end": "432310"
  },
  {
    "text": "Yes.",
    "start": "432310",
    "end": "432810"
  },
  {
    "start": "432810",
    "end": "435330"
  },
  {
    "text": "So we won't dwell on it, but\nwe've used a default training",
    "start": "435330",
    "end": "440039"
  },
  {
    "text": "method for all of the stochastic\ngradients operations, so far.",
    "start": "440040",
    "end": "445380"
  },
  {
    "text": "Torch has several other variants\nof stochastic gradients,",
    "start": "445380",
    "end": "448048"
  },
  {
    "text": "so we're going to use\none of those here.",
    "start": "448048",
    "end": "449715"
  },
  {
    "start": "449715",
    "end": "454500"
  },
  {
    "text": "What is the optimizer,\nthat comes into this.",
    "start": "454500",
    "end": "458298"
  },
  {
    "text": "When we tell it's a\nclassification problem,",
    "start": "458298",
    "end": "460090"
  },
  {
    "text": "we give it this\nspecial optimizer,",
    "start": "460090",
    "end": "462580"
  },
  {
    "text": "but let's not dwell on that.",
    "start": "462580",
    "end": "465220"
  },
  {
    "text": "So we'll fit it as we have\ndone all the other ones,",
    "start": "465220",
    "end": "467705"
  },
  {
    "text": "and let's take a look\nat how it's done.",
    "start": "467705",
    "end": "469330"
  },
  {
    "text": "Well, this one takes\na little bit longer,",
    "start": "469330",
    "end": "472879"
  },
  {
    "text": "depending on your hardware.",
    "start": "472880",
    "end": "474670"
  },
  {
    "start": "474670",
    "end": "477550"
  },
  {
    "text": "It took 10 minutes or so on\na pretty modern Mac laptop",
    "start": "477550",
    "end": "481509"
  },
  {
    "text": "with an M1 chip, but\nthat's not too bad.",
    "start": "481510",
    "end": "483610"
  },
  {
    "text": "We only gave it 30 epochs,\nand you probably give it more.",
    "start": "483610",
    "end": "487210"
  },
  {
    "text": "Yeah.",
    "start": "487210",
    "end": "488979"
  },
  {
    "text": "Especially if the accuracy\nis still improving.",
    "start": "488980",
    "end": "491080"
  },
  {
    "text": "Let's take a look.",
    "start": "491080",
    "end": "493337"
  },
  {
    "text": "Well, it looks like\nthe validation accuracy",
    "start": "493338",
    "end": "495130"
  },
  {
    "text": "is a bit leveling out.",
    "start": "495130",
    "end": "496240"
  },
  {
    "text": "So maybe 30 epochs won't be--",
    "start": "496240",
    "end": "498796"
  },
  {
    "text": "Won't help much.",
    "start": "498796",
    "end": "499639"
  },
  {
    "text": "Yeah.",
    "start": "499640",
    "end": "500140"
  },
  {
    "text": "I mean, anything more\nprobably won't help much.",
    "start": "500140",
    "end": "502000"
  },
  {
    "text": "Yeah.",
    "start": "502000",
    "end": "502500"
  },
  {
    "text": "Training, of course, will\nget better and better.",
    "start": "502500",
    "end": "505840"
  },
  {
    "text": "So still 40% accuracy on 100\nclass classification problem's",
    "start": "505840",
    "end": "509270"
  },
  {
    "text": "pretty good.",
    "start": "509270",
    "end": "509770"
  },
  {
    "text": "Yes, compared to\nthe baseline of 1%.",
    "start": "509770",
    "end": "511699"
  },
  {
    "text": "Yes.",
    "start": "511700",
    "end": "512200"
  },
  {
    "start": "512200",
    "end": "514719"
  },
  {
    "text": "And I think what's\nthe current state",
    "start": "514720",
    "end": "517719"
  },
  {
    "text": "of the art in the '70s\nfor this data set perhaps.",
    "start": "517720",
    "end": "519909"
  },
  {
    "text": "I think so.",
    "start": "519909",
    "end": "520659"
  },
  {
    "text": "Yeah.",
    "start": "520659",
    "end": "521260"
  },
  {
    "text": "So people tweak and tune\nthese models forever",
    "start": "521260",
    "end": "524290"
  },
  {
    "text": "and increase the accuracy.",
    "start": "524290",
    "end": "525880"
  },
  {
    "text": "Yes.",
    "start": "525880",
    "end": "526990"
  },
  {
    "text": "Eventually, the field\nwill overfit the data--",
    "start": "526990",
    "end": "530350"
  },
  {
    "text": "any different method won't.",
    "start": "530350",
    "end": "533019"
  },
  {
    "text": "So the accuracy on\ntest data is about 41%.",
    "start": "533020",
    "end": "535600"
  },
  {
    "start": "535600",
    "end": "539680"
  },
  {
    "text": "There are a few other topics\non convolution networks.",
    "start": "539680",
    "end": "542660"
  },
  {
    "text": "If you have certain\nhardware, there",
    "start": "542660",
    "end": "545237"
  },
  {
    "text": "are accelerations you can try.",
    "start": "545237",
    "end": "547870"
  },
  {
    "text": "And finally, one nice\nthing about these models",
    "start": "547870",
    "end": "551830"
  },
  {
    "text": "is that you don't have to just\nuse your own computer sometimes",
    "start": "551830",
    "end": "555160"
  },
  {
    "text": "to use them.",
    "start": "555160",
    "end": "556720"
  },
  {
    "text": "You can sometimes use the work\nthat someone else has done.",
    "start": "556720",
    "end": "559142"
  },
  {
    "text": "So you can use\npre-trained models,",
    "start": "559143",
    "end": "560560"
  },
  {
    "text": "and the torch data sets\nincludes these models",
    "start": "560560",
    "end": "567250"
  },
  {
    "text": "called resnet of various sizes.",
    "start": "567250",
    "end": "569410"
  },
  {
    "text": "Resnet50, I think,\ncorresponds to 50 max pool.",
    "start": "569410",
    "end": "573160"
  },
  {
    "text": "I think the 50 is how many\nconvolution max pooling layers.",
    "start": "573160",
    "end": "577990"
  },
  {
    "text": "And this was trained on 1,000\nimage classification problem.",
    "start": "577990",
    "end": "583130"
  },
  {
    "text": "Yes.",
    "start": "583130",
    "end": "583630"
  },
  {
    "text": "So you can now pass\nin your own images",
    "start": "583630",
    "end": "588310"
  },
  {
    "text": "and look at the\ndifferent classes.",
    "start": "588310",
    "end": "590210"
  },
  {
    "text": "So we have an example\nhere about how to do that.",
    "start": "590210",
    "end": "592840"
  },
  {
    "text": "We encourage you to do offline.",
    "start": "592840",
    "end": "595180"
  },
  {
    "text": "And these are shown in the book.",
    "start": "595180",
    "end": "597040"
  },
  {
    "text": "We show some photographs\nfrom photograph album",
    "start": "597040",
    "end": "601029"
  },
  {
    "text": "and actually classify\nthem, and we show the code",
    "start": "601030",
    "end": "605380"
  },
  {
    "text": "for doing that, too.",
    "start": "605380",
    "end": "606370"
  },
  {
    "text": "Yes.",
    "start": "606370",
    "end": "607920"
  },
  {
    "start": "607920",
    "end": "612000"
  }
]
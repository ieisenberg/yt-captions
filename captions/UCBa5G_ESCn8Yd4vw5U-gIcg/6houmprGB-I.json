[
  {
    "text": " Let me just introduce\nyou a little bit.",
    "start": "0",
    "end": "6370"
  },
  {
    "text": "So, Anima as you may have\nread, is the Bren professor of computing at the California\nInstitute of Technology.",
    "start": "6370",
    "end": "11963"
  },
  {
    "text": "She was previously\nsenior director of machine learning at NVIDIA\nand principal scientist at Amazon Web Services.",
    "start": "11963",
    "end": "19070"
  },
  {
    "text": "She's a pioneer in\nusing AI for science, and her research considers\ntensor algebraic methods, deep learning, and\nnon-convex problems.",
    "start": "19070",
    "end": "25810"
  },
  {
    "text": "She's going to give a\nshort 20 minute or so talk, and then we'll have\na fireside chat and hear all your questions.",
    "start": "25810",
    "end": "31240"
  },
  {
    "text": "Welcome, Anima. [APPLAUSE] Thank you. Thank you.",
    "start": "31240",
    "end": "36360"
  },
  {
    "text": "Thank you, Eric. And let me try to move\nthis a bit closer.",
    "start": "36360",
    "end": "41840"
  },
  {
    "text": "And, OK. Yeah, so I'm sure all\nof you are thinking",
    "start": "41840",
    "end": "49250"
  },
  {
    "text": "a lot about generative\nAI one way or the other. I just heard about\nthe use of AI tools.",
    "start": "49250",
    "end": "55350"
  },
  {
    "text": "So, you're very much aware\nof the language models. But I do think there is\na revolution not just",
    "start": "55350",
    "end": "62750"
  },
  {
    "text": "with language, but the use\nof these kind of frameworks of learning broad\ngenerative models,",
    "start": "62750",
    "end": "73160"
  },
  {
    "text": "in a distributional\nsense that also has an impact in many\nscientific domains.",
    "start": "73160",
    "end": "78620"
  },
  {
    "text": "Indeed, just to quickly set\nthe stage, why generative AI and what's so great about it.",
    "start": "78620",
    "end": "84780"
  },
  {
    "text": "The hard part is to\nbe able to generate samples of some high\ndimensional distribution.",
    "start": "84780",
    "end": "93440"
  },
  {
    "text": "What that means is very complex\naspects like, of course,",
    "start": "93440",
    "end": "98520"
  },
  {
    "text": "large pieces of text images, but\nalso molecules, proteins, maybe",
    "start": "98520",
    "end": "104850"
  },
  {
    "text": "new genomes of viral\nmutations of coronavirus.",
    "start": "104850",
    "end": "110140"
  },
  {
    "text": "So you can think of this ability\nto not just reason about a given",
    "start": "110140",
    "end": "116670"
  },
  {
    "text": "input, but to\ngenerate new samples. And that's really\nthe difference.",
    "start": "116670",
    "end": "122650"
  },
  {
    "text": "The previous era of AI\nover the last decade was more about\ndiscriminative AI.",
    "start": "122650",
    "end": "128899"
  },
  {
    "text": "I give an image, I ask\nyou what's in an image. That's discriminative\nbecause you're",
    "start": "128899",
    "end": "134700"
  },
  {
    "text": "trying to understand, OK, this\nimage is more of a cat and not of a dog. So you're making\nthose distinctions.",
    "start": "134700",
    "end": "141460"
  },
  {
    "text": "And a lot of what we did until\nthese language models came about",
    "start": "141460",
    "end": "147360"
  },
  {
    "text": "was to focus more on being able\nto discriminate within given",
    "start": "147360",
    "end": "152370"
  },
  {
    "text": "samples in an accurate way. But of course, with\nenough compute,",
    "start": "152370",
    "end": "158140"
  },
  {
    "text": "it turns out that\ngenerative AI is possible. It's really the process of\ngoing from specification",
    "start": "158140",
    "end": "166220"
  },
  {
    "text": "that is low dimensional, meaning\na simple prompt or a simple wish list of what you want in a\nmolecule to the actual molecule,",
    "start": "166220",
    "end": "175680"
  },
  {
    "text": "which is, of course, in a much\nlarger set of possibilities. That's a hard process.",
    "start": "175680",
    "end": "181110"
  },
  {
    "text": "So you're going from\na simple specification to an output that is\nmuch more complex.",
    "start": "181110",
    "end": "187250"
  },
  {
    "text": "But with enough\ndata and scale, we are able to accomplish that now.",
    "start": "187250",
    "end": "192620"
  },
  {
    "text": "Of course, just to,\nagain, very quickly set the stage for language models,\nthe idea is very simple.",
    "start": "192620",
    "end": "199640"
  },
  {
    "text": "The way we train\nlanguage models is to predict what the next word\nis given all this context.",
    "start": "199640",
    "end": "205830"
  },
  {
    "text": "So you just learn how to\npredict this well at scale what we call pre-training.",
    "start": "205830",
    "end": "211319"
  },
  {
    "text": "And then you give a little\nbit of human feedback what we call the alignment\nprocess, which is done",
    "start": "211320",
    "end": "218599"
  },
  {
    "text": "with reinforcement learning. So it's RLHF. And with that, you\nmake the models",
    "start": "218600",
    "end": "225659"
  },
  {
    "text": "able to understand our\nprompts or our instructions so that they can respond\nin an appropriate way.",
    "start": "225660",
    "end": "231390"
  },
  {
    "text": "And at the same\ntime, of course, try to make the model not spit out\nhate speech or anything that",
    "start": "231390",
    "end": "238710"
  },
  {
    "text": "is bad in many ways. So the process itself\nis very simple.",
    "start": "238710",
    "end": "246700"
  },
  {
    "text": "So it's all focused on getting\nas much data as possible. In fact, internet scale\ndata, and then learning",
    "start": "246700",
    "end": "253500"
  },
  {
    "text": "to predict the next word. And then from just\nthat very simple aspect",
    "start": "253500",
    "end": "258660"
  },
  {
    "text": "of looking at what is the\nlikelihood of different words",
    "start": "258660",
    "end": "263880"
  },
  {
    "text": "that would appear given the\ncurrent part of the sentence, you are learning the underlying\nmeaning in certain way.",
    "start": "263880",
    "end": "272640"
  },
  {
    "text": "You understand how words\nappear in different contexts by learning this at scale.",
    "start": "272640",
    "end": "279540"
  },
  {
    "text": "So, of course,\nlanguage by itself is great for a number\nof applications, but not all of them.",
    "start": "279540",
    "end": "285700"
  },
  {
    "text": "And ultimately, what language\nlacks by itself is embodiment.",
    "start": "285700",
    "end": "291300"
  },
  {
    "text": "So you can learn how\ndifferent pieces of text",
    "start": "291300",
    "end": "297210"
  },
  {
    "text": "are related to one another,\nwhat is the underlying meaning of words. But words need to translate\ninto actions when it interacts",
    "start": "297210",
    "end": "305970"
  },
  {
    "text": "with the physical world. And that's where we need an\nagent or an embodied agent",
    "start": "305970",
    "end": "312660"
  },
  {
    "text": "where you take\ninstructions in text",
    "start": "312660",
    "end": "319650"
  },
  {
    "text": "or interact with text\nin a certain way, but ultimately convert\nthem into actions.",
    "start": "319650",
    "end": "326100"
  },
  {
    "text": "And so this is one\nof the early work we did at NVIDIA\nwhere we, in fact,",
    "start": "326100",
    "end": "331620"
  },
  {
    "text": "in collaboration\nwith also many folks here at Stanford where the idea\nwas to give instructions in text",
    "start": "331620",
    "end": "340050"
  },
  {
    "text": "about what objects\nto pick and play. So you see a mix of image\nand text as instructions",
    "start": "340050",
    "end": "347580"
  },
  {
    "text": "and have this ability\nnow for the robot to execute a whole range\nof different tasks.",
    "start": "347580",
    "end": "353560"
  },
  {
    "text": "So text is a nice way to provide\nnow the ability for robots",
    "start": "353560",
    "end": "358710"
  },
  {
    "text": "to be generalists, meaning\nnot just be trained to do one specific kind\nof task or pick only one",
    "start": "358710",
    "end": "364980"
  },
  {
    "text": "specific set of objects,\nbut now in a 0 shot way, generalize to new ones.",
    "start": "364980",
    "end": "370620"
  },
  {
    "text": "And it need not be just\nin the physical world. It can also be in\nvirtual worlds. The Voyager work\nwe did was to show",
    "start": "370620",
    "end": "378660"
  },
  {
    "text": "how you can use language models\nto now continuously learn",
    "start": "378660",
    "end": "384390"
  },
  {
    "text": "skills in a variety\nof environments, including Minecraft. So you can progressively learn\nskills from simple to complex",
    "start": "384390",
    "end": "393419"
  },
  {
    "text": "and also use the skills\nyou learned beforehand. This is how we humans do.",
    "start": "393420",
    "end": "398590"
  },
  {
    "text": "So we pick up certain topics. And as a curriculum,\nwe go and tackle",
    "start": "398590",
    "end": "404290"
  },
  {
    "text": "harder and harder problems. And that's what we\nthought our agent to do, to use language models as a way\nto come up with actions that you",
    "start": "404290",
    "end": "412660"
  },
  {
    "text": "can execute in Minecraft, but\nalso decide what to do next. And this is where it's different\nfrom standardly reinforcement",
    "start": "412660",
    "end": "420760"
  },
  {
    "text": "learning. When AlphaGo beat the\nworld's best go champion",
    "start": "420760",
    "end": "426580"
  },
  {
    "text": "bout a decade ago, that\nwas very surprising that AI could\nreally be able to go",
    "start": "426580",
    "end": "435250"
  },
  {
    "text": "through so many possible moves\nand pick out optimal moves that were better than the human.",
    "start": "435250",
    "end": "440440"
  },
  {
    "text": "But then it was focused on\njust one game and one task. So the goal was just to win.",
    "start": "440440",
    "end": "446210"
  },
  {
    "text": "So that was already predefined. Whereas in Minecraft--\nI don't know how many of you have\nplayed Minecraft--",
    "start": "446210",
    "end": "452090"
  },
  {
    "text": "it's about creativity. You don't just like\nfocus on one thing.",
    "start": "452090",
    "end": "457220"
  },
  {
    "text": "You can go build these\ncastles that you're seeing. I think somebody has even built\na CPU and GPU in Minecraft.",
    "start": "457220",
    "end": "464360"
  },
  {
    "text": "So it's endless what you can do. And that's where I think\nthe promise of AI agents is.",
    "start": "464360",
    "end": "471500"
  },
  {
    "text": "So language models are\nnot just in isolation, but they can be\nused by these agents",
    "start": "471500",
    "end": "477370"
  },
  {
    "text": "to continuously\nquery and get help. But ultimately, those\nagents are figuring out",
    "start": "477370",
    "end": "482680"
  },
  {
    "text": "how to continue to\ngather skills, and solve increasingly harder\nproblems in environments.",
    "start": "482680",
    "end": "489620"
  },
  {
    "text": "And the Minecraft is\nreally a showcase of that. You can think of\nthe same software applications for all kinds\nof software programming.",
    "start": "489620",
    "end": "499670"
  },
  {
    "text": "And you're seeing that in a-- well, I think it just\ngoes off to sleep if I--",
    "start": "499670",
    "end": "508139"
  },
  {
    "text": "yeah, we'll see.  So the one thing that\nstill lacks if you only",
    "start": "508140",
    "end": "515520"
  },
  {
    "text": "do language models is the aspect\nof dealing with hallucinations.",
    "start": "515520",
    "end": "521200"
  },
  {
    "text": "So these models currently\nare not grounded in facts. Of course, if you train\non all of the internet,",
    "start": "521200",
    "end": "528210"
  },
  {
    "text": "everything is mixed together. There are people telling\njokes, poetry to software code,",
    "start": "528210",
    "end": "533889"
  },
  {
    "text": "to mathematical facts. And now if you're asking\nlanguage models to prove theorems, you cannot expect\nit to be 100% correct.",
    "start": "533890",
    "end": "542410"
  },
  {
    "text": "It can claim that this\nis the correct proof And many times GPT can be wrong.",
    "start": "542410",
    "end": "549880"
  },
  {
    "text": "And instead, what we\ndid in this project-- and that was one of\nthe suggested reading that I had given-- was to\nnow add with language models",
    "start": "549880",
    "end": "559290"
  },
  {
    "text": "that ability to verify whether\nthe statements the language models are making\nare correct or not.",
    "start": "559290",
    "end": "565900"
  },
  {
    "text": "And this one, we\ndon't need to build. There's decades of work\ncalled formal verifiers",
    "start": "565900",
    "end": "572410"
  },
  {
    "text": "or formal theorem provers. And Lean is one of\nthe leading ones. There are many, but there\nare for several reasons.",
    "start": "572410",
    "end": "580340"
  },
  {
    "text": "Many mathematicians,\nincluding Terry Tau, who was one of the\nleading mathematicians. They use Lean, and\nthere's a large community",
    "start": "580340",
    "end": "588070"
  },
  {
    "text": "building this formalization\nof math into Lean.",
    "start": "588070",
    "end": "593930"
  },
  {
    "text": "So what that really means is\nif you go read a math paper and you look at all the proofs,\nyou don't know if it's correct",
    "start": "593930",
    "end": "601630"
  },
  {
    "text": "or not. You, as an expert mathematician,\nmay go and try to be like, OK, this one is correct,\nthis one is correct.",
    "start": "601630",
    "end": "608360"
  },
  {
    "text": "But instead, if you\nhad a program that could certify that every step is\ncorrect, then now first of all,",
    "start": "608360",
    "end": "616190"
  },
  {
    "text": "you don't need to worry about\nthe correctness of proofs. But ultimately,\nthe same concept is",
    "start": "616190",
    "end": "621250"
  },
  {
    "text": "useful in a wide\nvariety of areas, and especially safety\ncritical areas.",
    "start": "621250",
    "end": "627740"
  },
  {
    "text": "A lot of the control\nof, let's say, aircrafts or drones, rockets\nis done with the same notion",
    "start": "627740",
    "end": "636000"
  },
  {
    "text": "of formal verification. So every step of\nthe program, you have to certify to be correct.",
    "start": "636000",
    "end": "641530"
  },
  {
    "text": "Otherwise, it's just too\nunsafe to use programs without that correctness.",
    "start": "641530",
    "end": "647650"
  },
  {
    "text": "And we can do the same\nin terms of using Lean, but combine it together\nwith language models.",
    "start": "647650",
    "end": "655269"
  },
  {
    "text": "So language models\nnow propose ideas. Language model can say, I\nthink to prove this GCD, which",
    "start": "655270",
    "end": "663210"
  },
  {
    "text": "is the greatest common\ndenominator, which, again, you don't need to know the specific\nnotations in the proof steps,",
    "start": "663210",
    "end": "669329"
  },
  {
    "text": "language model can say,\nthis is what I think the next step in the proof is. And then Lean as a verifier\ncan certify whether the step is",
    "start": "669330",
    "end": "678120"
  },
  {
    "text": "correct or not. And so this way, anything that\nis proven by the language model is now 100% accurate.",
    "start": "678120",
    "end": "685120"
  },
  {
    "text": "So there's no hallucination. And you can do this in math\nbecause you can correctly",
    "start": "685120",
    "end": "690580"
  },
  {
    "text": "verify and certify every step. And in other areas, not so much. If you're talking about social\nbeliefs or moral issues,",
    "start": "690580",
    "end": "700120"
  },
  {
    "text": "you cannot say, OK, this step\nin the logical reasoning is correct. And that's why let me\ngo to the next step.",
    "start": "700120",
    "end": "706550"
  },
  {
    "text": "But with math, we can do that. And that's where I think\ndomain specific applications",
    "start": "706550",
    "end": "711579"
  },
  {
    "text": "of language models\ncan be done better. You can remove\nhallucinations in many areas.",
    "start": "711580",
    "end": "718129"
  },
  {
    "text": "And specifically, if you can\nhave verification, like in math, you can 100% remove\nthose hallucinations.",
    "start": "718130",
    "end": "725930"
  },
  {
    "text": "So I think that kind\nof logical reasoning is really important\nultimately for AI",
    "start": "725930",
    "end": "731380"
  },
  {
    "text": "to succeed in many of\nour scientific domains.",
    "start": "731380",
    "end": "737170"
  },
  {
    "text": "And so far, I've\ntalked about how language models could\nbe used in a range",
    "start": "737170",
    "end": "742870"
  },
  {
    "text": "of different applications. But you can also\nchange from language to other modalities,\nother kinds of data.",
    "start": "742870",
    "end": "750079"
  },
  {
    "text": "And one of such\nareas was using now genomic data instead\nof English language",
    "start": "750080",
    "end": "758020"
  },
  {
    "text": "or any natural language. So what that entails is now you\nhave sequences of nucleotides,",
    "start": "758020",
    "end": "769280"
  },
  {
    "text": "the ATGC, if you\nremember the DNA, and then now you can\ngive these sequences",
    "start": "769280",
    "end": "775120"
  },
  {
    "text": "and, again, ask the\nnow genomic language model to learn to predict\nthe next set of nucleotides",
    "start": "775120",
    "end": "783310"
  },
  {
    "text": "in the sequence. And what this does is learn\nthe underlying intuition",
    "start": "783310",
    "end": "789700"
  },
  {
    "text": "of what genes do, what is the\nfunctionality of different genes in the same way what is\nthe meaning of underlying",
    "start": "789700",
    "end": "796420"
  },
  {
    "text": "words in natural language. So it's the same\nanalogy that holds-- and again, we do this at scale.",
    "start": "796420",
    "end": "802370"
  },
  {
    "text": "We did the first\ngenomic language model where we trained it on more than\n110 million genomic sequences",
    "start": "802370",
    "end": "809649"
  },
  {
    "text": "of many known\nviruses and bacteria. So this is the UK Biobank. It has the biggest\ncollection of known mutations",
    "start": "809650",
    "end": "818170"
  },
  {
    "text": "of viruses and bacteria. So everything from flu\nvirus, E coli, coronavirus.",
    "start": "818170",
    "end": "824990"
  },
  {
    "text": "So everything you can think\nof, we collected all of them. And again, the difference is\nif you're asking a biologist,",
    "start": "824990",
    "end": "831709"
  },
  {
    "text": "they're usually studying\none specific virus. They're looking at flu, they're\nlooking at how could it mutate.",
    "start": "831710",
    "end": "838399"
  },
  {
    "text": "The CDC is trying to come up\nwith some best guesses of what would be the best mutations\nand then creating vaccines",
    "start": "838400",
    "end": "846280"
  },
  {
    "text": "to target those mutations. But now with the use\nof these large scale",
    "start": "846280",
    "end": "851830"
  },
  {
    "text": "generative AI\nmodels, you can now look at how are all of these\ndifferent viruses and bacteria",
    "start": "851830",
    "end": "859509"
  },
  {
    "text": "evolving over time. Because you're learning\nacross all mutations, you can figure\nout which ones are",
    "start": "859510",
    "end": "867550"
  },
  {
    "text": "more likely to happen than\nothers and hence coming up with a way to predict\nnew variants of concern.",
    "start": "867550",
    "end": "874670"
  },
  {
    "text": "And that's what we did where\nwe fine tune the model just to focus on coronavirus.",
    "start": "874670",
    "end": "880670"
  },
  {
    "text": "So during training,\nwe showed the variants that appeared just in the first\nyear of the pandemic, which",
    "start": "880670",
    "end": "886060"
  },
  {
    "text": "was alpha and beta variants. So the other ones\nhadn't yet appeared,",
    "start": "886060",
    "end": "891590"
  },
  {
    "text": "but the language model\ntrained on genomes accurately predicted the\nvariants that emerged later",
    "start": "891590",
    "end": "898970"
  },
  {
    "text": "like Delta and Omicron. So what the model is able\nto do is successfully learn the evolutionary dynamics of how\nviruses are likely to mutate.",
    "start": "898970",
    "end": "909230"
  },
  {
    "text": "And this is very helpful\nfor us to get a hold on all the latest pandemics.",
    "start": "909230",
    "end": "915610"
  },
  {
    "text": "And we haven't\ndone the bird flu, but I imagine that will also\ngive us interesting insights.",
    "start": "915610",
    "end": "920890"
  },
  {
    "text": "Can I ask a question? Yeah, so that's amazing. So were they able to make\nvaccines in advance or is that",
    "start": "920890",
    "end": "927940"
  },
  {
    "text": "the idea that you would have a\nvaccine before the variant even appears?",
    "start": "927940",
    "end": "933120"
  },
  {
    "text": "Yeah, exactly. That's the idea. I mean, by the time we\nwere training this already, the Delta and Omicron waves\nhad just kind of passed.",
    "start": "933120",
    "end": "940830"
  },
  {
    "text": "So for this pandemic,\nit was a bit late. But hopefully-- And then once you\ndo, you can also",
    "start": "940830",
    "end": "946220"
  },
  {
    "text": "start predicting what some\nof the characteristics are or is that beyond\nwhat you guys are doing? And precisely the next question.",
    "start": "946220",
    "end": "952880"
  },
  {
    "text": "So you can now produce\nthese genomic sequences, but what is the impact?",
    "start": "952880",
    "end": "958500"
  },
  {
    "text": "I mean, which ones are more\nconcerning than others, which one should be-- Like a certain set of base pairs\nmight lead to a more lethal--",
    "start": "958500",
    "end": "967970"
  },
  {
    "text": "Exactly, exactly. But how do you study that? And to do that, in this\nexample, what I'm showing you",
    "start": "967970",
    "end": "974210"
  },
  {
    "text": "is how does the spike protein\nof the coronavirus, which is in blue, interact\nwith the protein",
    "start": "974210",
    "end": "980029"
  },
  {
    "text": "targets in the human body. So you need to understand\nwhere is the binding strong",
    "start": "980030",
    "end": "985310"
  },
  {
    "text": "and where is it weak. So if a strain is much more\nlethal or more concerning,",
    "start": "985310",
    "end": "993269"
  },
  {
    "text": "it tends to bind\nstronger and that's when it's more disruptive\nin the human body. So just by looking at\nthe genomic sequence,",
    "start": "993270",
    "end": "1000560"
  },
  {
    "text": "you cannot gather all the\ninformation of which variants should we be worried about.",
    "start": "1000560",
    "end": "1005930"
  },
  {
    "text": "On the other hand, if you\nnow go into the details of the biological\nprocess itself,",
    "start": "1005930",
    "end": "1011000"
  },
  {
    "text": "what does the virus\ndo, how does it go into the human body\nand bind with protein",
    "start": "1011000",
    "end": "1016810"
  },
  {
    "text": "targets inside the body? As well as other\naspects too we studied.",
    "start": "1016810",
    "end": "1022250"
  },
  {
    "text": "We looked at how does\nit get transmitted in the respiratory aerosol,\nwhat are the molecules it",
    "start": "1022250",
    "end": "1028390"
  },
  {
    "text": "binds within a\nrespiratory aerosol that makes it infectious.",
    "start": "1028390",
    "end": "1033800"
  },
  {
    "text": "You transmit through that. And also, how well\ndoes it replicate and what kind of factors help\nor hurt the replication process",
    "start": "1033800",
    "end": "1041500"
  },
  {
    "text": "of this virus. And so this is where,\nto study all this,",
    "start": "1041500",
    "end": "1046630"
  },
  {
    "text": "you cannot just look at discrete\ndata or a sequence kind of data.",
    "start": "1046630",
    "end": "1051800"
  },
  {
    "text": "I made this analogy that\ngenomes are just like language.",
    "start": "1051800",
    "end": "1057040"
  },
  {
    "text": "Instead of the English\nlanguage with 26 alphabets, you have only four\nalphabets, which is ATGC,",
    "start": "1057040",
    "end": "1062800"
  },
  {
    "text": "and you have that\nsequence and you learn a model in a\nsimilar architecture use",
    "start": "1062800",
    "end": "1068560"
  },
  {
    "text": "transformers just as\nyou did with language. But now to study these kind\nof processes, which is now",
    "start": "1068560",
    "end": "1075100"
  },
  {
    "text": "in space and time--\nso in space, you are looking at what are the\nbinding, which molecules bind",
    "start": "1075100",
    "end": "1080440"
  },
  {
    "text": "with each other and also how\ndoes this molecular dynamics itself change over time.",
    "start": "1080440",
    "end": "1085840"
  },
  {
    "text": "And these kind of processes\nare just abound in nature.",
    "start": "1085840",
    "end": "1091010"
  },
  {
    "text": "You can start from all the way\nat atomic and molecular level to planetary scales.",
    "start": "1091010",
    "end": "1097330"
  },
  {
    "text": "So in the second example\nof planetary scales, you can think of what is the\nweather going to be tomorrow,",
    "start": "1097330",
    "end": "1103750"
  },
  {
    "text": "will there be storms,\nwill there be rain. And for that, you're\nlooking at processes",
    "start": "1103750",
    "end": "1109240"
  },
  {
    "text": "that involve\neverything from what are the particles within a\ncloud that cause precipitation",
    "start": "1109240",
    "end": "1116260"
  },
  {
    "text": "to these very large scale\neffects like atmospheric rivers, which are important\nfor California",
    "start": "1116260",
    "end": "1122830"
  },
  {
    "text": "because that's what\ncauses storms in winter and they can be\nthousands of miles wide. So you have from microscopic\nto macroscopic phenomena that",
    "start": "1122830",
    "end": "1131800"
  },
  {
    "text": "are all interacting\ntogether to cause the weather on this planet. And that's the aspect where just\nlanguage models by themselves",
    "start": "1131800",
    "end": "1141730"
  },
  {
    "text": "will not be enough. Language is a high\nlevel description of certain phenomena, just\nas math is a high level",
    "start": "1141730",
    "end": "1150759"
  },
  {
    "text": "description. You can, in fact,\ndescribe these processes",
    "start": "1150760",
    "end": "1155830"
  },
  {
    "text": "through mathematical equations. So if you're looking\nat molecular dynamics, you can use Newton's\nlaws of motion",
    "start": "1155830",
    "end": "1163270"
  },
  {
    "text": "to describe how the molecule\nwill be stretching and moving. You can also go down\nto the quantum effects",
    "start": "1163270",
    "end": "1170180"
  },
  {
    "text": "and use Schr√∂dinger's equation\nand all of its approximations. So we perfectly\nknow the equations",
    "start": "1170180",
    "end": "1178970"
  },
  {
    "text": "that describe these systems. But what's challenging is the\nability to simulate it at scale.",
    "start": "1178970",
    "end": "1185850"
  },
  {
    "text": "In fact, to do that\nfor quantum simulation,",
    "start": "1185850",
    "end": "1191270"
  },
  {
    "text": "the computation would take more\nthan the age of the universe even to simulate just a\nmolecule with 100 atoms.",
    "start": "1191270",
    "end": "1199310"
  },
  {
    "text": "So that's the bottleneck. So here, we are in\na different regime compared to language models\nwhere with language, it's",
    "start": "1199310",
    "end": "1206809"
  },
  {
    "text": "very difficult to try\nto describe the rules. There are too many exceptions.",
    "start": "1206810",
    "end": "1213149"
  },
  {
    "text": "There's not just a\nmathematical equation to describe all of English text.",
    "start": "1213150",
    "end": "1218540"
  },
  {
    "text": "On the other hand, we have\nlots of data on the internet, and we're learning from that. But on the other\nhand, if you want",
    "start": "1218540",
    "end": "1224870"
  },
  {
    "text": "to try and learn these\nkind of physical phenomena, the data is limited.",
    "start": "1224870",
    "end": "1230540"
  },
  {
    "text": "There's certainly some\nobservational data. You can go and look at these\nviruses and, under a microscope,",
    "start": "1230540",
    "end": "1239389"
  },
  {
    "text": "try to look at what is happening\nwith these protein interactions. You can go, of course,\nwith satellite data,",
    "start": "1239390",
    "end": "1247360"
  },
  {
    "text": "try to assess what is the kind\nof wind and other patterns happening in our atmosphere.",
    "start": "1247360",
    "end": "1253549"
  },
  {
    "text": "So you can get some amount\nof data, but it's limited. And now the question is there\nstill a notion of generative AI",
    "start": "1253550",
    "end": "1262060"
  },
  {
    "text": "or large scale AI models,\neven for scientific phenomena. And the way we can do that is\nto incorporate this knowledge",
    "start": "1262060",
    "end": "1270190"
  },
  {
    "text": "of mathematical equations. So either we can use existing\nsimulators to generate data,",
    "start": "1270190",
    "end": "1276530"
  },
  {
    "text": "or we can directly\ntry to incorporate the knowledge of physical laws\nand equations into our models.",
    "start": "1276530",
    "end": "1283755"
  },
  {
    "text": " But the one challenge to do that\nis this requirement to capture",
    "start": "1283755",
    "end": "1292049"
  },
  {
    "text": "really the fine scales. So if you want to understand\nhow far clouds in our atmosphere",
    "start": "1292050",
    "end": "1299130"
  },
  {
    "text": "move, you need to get to\nthese really fine scales. And that's what makes these\nsimulations very expensive",
    "start": "1299130",
    "end": "1306750"
  },
  {
    "text": "if you did that with\ntraditional numerical solvers. So for instance, if you\nhave to simulate clouds,",
    "start": "1306750",
    "end": "1314169"
  },
  {
    "text": "the resolution you\nneed to get to is of the order of maybe 100\nmeters or which is, even",
    "start": "1314170",
    "end": "1321450"
  },
  {
    "text": "within Stanford campus, you\nneed multiple grid points, lots of them. And now think of doing\nthat at a global scale.",
    "start": "1321450",
    "end": "1328390"
  },
  {
    "text": "That's an extremely\nfine resolution image of the Earth you need to do.",
    "start": "1328390",
    "end": "1333899"
  },
  {
    "text": "And you need to then\nalso do that in time, in very fine increments to\nget accurate simulations.",
    "start": "1333900",
    "end": "1342390"
  },
  {
    "text": "And that's what makes\nthis infeasible when you try to do it with\ntraditional simulation methods.",
    "start": "1342390",
    "end": "1349840"
  },
  {
    "text": "So what traditional simulations\ntry to do is look at equations and try to directly solve them.",
    "start": "1349840",
    "end": "1356320"
  },
  {
    "text": "So they're not making use\nof any learning from data. They're saying, OK, let me\ntry and solve these equations.",
    "start": "1356320",
    "end": "1362660"
  },
  {
    "text": "But to do that, I can\nonly take small steps. And then I need to take\na lot of such small steps",
    "start": "1362660",
    "end": "1367970"
  },
  {
    "text": "which becomes too expensive. And also if the area\nitself is large,",
    "start": "1367970",
    "end": "1373570"
  },
  {
    "text": "I need large memory to\nmake the grid fine enough to make this solver converge.",
    "start": "1373570",
    "end": "1380470"
  },
  {
    "text": "And this is where AI now\nhas the potential, not only the potential, now\nwe have the evidence",
    "start": "1380470",
    "end": "1386110"
  },
  {
    "text": "that it can speed up\nsolving these kind of mathematical equations in a\nmuch faster way than possible",
    "start": "1386110",
    "end": "1393130"
  },
  {
    "text": "before. So the analogy is\nsimilar to what you see with computer vision.",
    "start": "1393130",
    "end": "1398300"
  },
  {
    "text": "Before deep learning, people\nwere hand engineering features. So if you had to\nclassify a face,",
    "start": "1398300",
    "end": "1404420"
  },
  {
    "text": "there were certain features\nwhich were thought to be better. Exactly. Try and look for the eye.",
    "start": "1404420",
    "end": "1409809"
  },
  {
    "text": "So you could go and hand\nengineer every one of them. But the tail is too long. You can't try and do this for\nevery variation of the face,",
    "start": "1409810",
    "end": "1418550"
  },
  {
    "text": "every angle, every lighting. And same with, in a way,\nthe numerical solvers.",
    "start": "1418550",
    "end": "1424760"
  },
  {
    "text": "You can try and hand\nengineer the features to try to make it converge,\nbut you don't know if those are the best features.",
    "start": "1424760",
    "end": "1431770"
  },
  {
    "text": "And even though we may\nrequire a very fine grid, if we try to directly solve\nthrough all of these points,",
    "start": "1431770",
    "end": "1438919"
  },
  {
    "text": "you could find a\ntransformation through",
    "start": "1438920",
    "end": "1444280"
  },
  {
    "text": "a non-linear transformation\nto a latent space where the grid is much coarser\nand you get a speed up.",
    "start": "1444280",
    "end": "1450620"
  },
  {
    "text": "And that's what we did with the\nuse of these techniques called neural operators.",
    "start": "1450620",
    "end": "1456760"
  },
  {
    "text": "So neural operators are\nextending the notion of neural networks\nlike transformers,",
    "start": "1456760",
    "end": "1462620"
  },
  {
    "text": "but to now continuous spaces. So if you think about now\nhow I mentioned about clouds.",
    "start": "1462620",
    "end": "1469840"
  },
  {
    "text": "So you can try to model, the\ncloud at a certain resolution.",
    "start": "1469840",
    "end": "1475000"
  },
  {
    "text": "So on the right, if I choose\nmy resolution to be too coarse, I get garbage.",
    "start": "1475000",
    "end": "1481270"
  },
  {
    "text": "It's too blurry. It's not enough\nuseful information to actually predict\nhow the cloud is",
    "start": "1481270",
    "end": "1486390"
  },
  {
    "text": "going to change over time. And that's the challenge\nwith a lot of the physics. If you don't make\nyour grid fine enough,",
    "start": "1486390",
    "end": "1493180"
  },
  {
    "text": "you will not be able\nto accurately capture the prediction in terms of how\nthe fluid is going to flow.",
    "start": "1493180",
    "end": "1500880"
  },
  {
    "text": "And this is where it's also\ndifferent from computer vision where it's more about\nvisual appearance.",
    "start": "1500880",
    "end": "1507100"
  },
  {
    "text": "For me, visually, it looks\ngood enough, it's good. But that's not so true to get\nthe correct physics in terms",
    "start": "1507100",
    "end": "1514260"
  },
  {
    "text": "of accurately predicting\nwhat will happen to fluid flow like clouds. So what we did with\nneural operators",
    "start": "1514260",
    "end": "1521309"
  },
  {
    "text": "was not to worry about fixing\nthe resolution to just one value.",
    "start": "1521310",
    "end": "1527020"
  },
  {
    "text": "Instead, think of\nhow, in graphics, you have vector graphics and\nyou have raster graphics.",
    "start": "1527020",
    "end": "1533390"
  },
  {
    "text": "This is the same analogy here. In the raster\ngraphics, you prefix what should be the\nresolution, what",
    "start": "1533390",
    "end": "1539260"
  },
  {
    "text": "should be the number of pixels. And if you go further\nzoom in, it just gets blurry because you haven't\nincreased the number of pixels.",
    "start": "1539260",
    "end": "1547510"
  },
  {
    "text": "On the other hand,\nwith vector graphics, you represent the\ndata as shapes.",
    "start": "1547510",
    "end": "1553190"
  },
  {
    "text": "you parameterize them as shapes. And you can keep zooming in and\nyou can still get sharp images,",
    "start": "1553190",
    "end": "1559400"
  },
  {
    "text": "sharp graphics. And the neural\noperators do the same. But instead, you learn what\nthose shapes should be.",
    "start": "1559400",
    "end": "1566060"
  },
  {
    "text": "So you're always\nrepresenting the output as functions that\nare continuous.",
    "start": "1566060",
    "end": "1571370"
  },
  {
    "text": "And so you can keep zooming\nin to any resolution and it can still give\nyou valid answers.",
    "start": "1571370",
    "end": "1578350"
  },
  {
    "text": "And so-- So the neural operator learns\nthe functions instead of you programming them\nfrom a neural net.",
    "start": "1578350",
    "end": "1584039"
  },
  {
    "text": "Yeah. From the data. So you can now give a\ndate of fluid dynamics of various scenarios or\nyou give it weather data,",
    "start": "1584040",
    "end": "1590860"
  },
  {
    "text": "you give it data of\nhow material stretches. So all of this, you don't\nhave to fix beforehand",
    "start": "1590860",
    "end": "1596760"
  },
  {
    "text": "what should be the resolution. And in fact, you can train it on\ndata with multiple resolution.",
    "start": "1596760",
    "end": "1602190"
  },
  {
    "text": "And a neural net can fit\nany arbitrary function. So you can make it arbitrarily--",
    "start": "1602190",
    "end": "1607560"
  },
  {
    "text": "Exactly. So the main difference is\nin text, with transformers, you're learning on\ndiscrete tokens.",
    "start": "1607560",
    "end": "1614320"
  },
  {
    "text": "So you fix what is the\nvocabulary of your language, and you're giving a token for\neach part of the vocabulary.",
    "start": "1614320",
    "end": "1621440"
  },
  {
    "text": "And that's how you\nget the tokens. On the other hand, here we\nare not defining the tokens",
    "start": "1621440",
    "end": "1626490"
  },
  {
    "text": "at one resolution. Instead, we are\nsaying, these tokens could be infinitely defined\ninto any resolution I want.",
    "start": "1626490",
    "end": "1633580"
  },
  {
    "text": "So we're giving\nthat flexibility. And I won't get into the\ntechnical details here.",
    "start": "1633580",
    "end": "1639790"
  },
  {
    "text": "But this is just saying that by\ndoing so and capturing the finer resolution, we can get\nto the finer scale.",
    "start": "1639790",
    "end": "1648190"
  },
  {
    "text": "So on the right is a plot in\nterms of how we are accurately predicting what happens at\nhigher frequencies or finer",
    "start": "1648190",
    "end": "1656490"
  },
  {
    "text": "resolutions, even though\nthe model didn't see that during training.",
    "start": "1656490",
    "end": "1662240"
  },
  {
    "text": "So how do you define\nthe function [INAUDIBLE] if it depends on [INAUDIBLE]\nhow does the function vary?",
    "start": "1662240",
    "end": "1672330"
  },
  {
    "text": "Yeah. And that's the beauty of it. With these models, you\nlearn them from data. You don't fix them beforehand.",
    "start": "1672330",
    "end": "1678760"
  },
  {
    "text": "So, for instance, if\nI fix the function to be just sine\nwaves, like sinusoids,",
    "start": "1678760",
    "end": "1684080"
  },
  {
    "text": "that's what the\nFourier transform does. But that's too limiting. If my model is not sparse\nin terms of sine waves,",
    "start": "1684080",
    "end": "1692010"
  },
  {
    "text": "then I can't accurately\nrepresent it. So is it inferring\nthe function-- Yes, precisely.",
    "start": "1692010",
    "end": "1698520"
  },
  {
    "text": "It's learning the\nfunction itself from data, what should\nbe the function. And it's learning that through\nthese nonlinear transformations",
    "start": "1698520",
    "end": "1707240"
  },
  {
    "text": "in between, just as any\nneural network does, just as transformer does. And because of that, it's\ntrying to find shortcuts",
    "start": "1707240",
    "end": "1714710"
  },
  {
    "text": "to solve these partial\ndifferential equations more efficiently compared to\nnumerical solvers, which",
    "start": "1714710",
    "end": "1722520"
  },
  {
    "text": "are already having a fixed\npath of how to solve it. So can you think about this\nas dimensionality reduction,",
    "start": "1722520",
    "end": "1730020"
  },
  {
    "text": "but with functions\ninstead of [INAUDIBLE]? Exactly.",
    "start": "1730020",
    "end": "1735539"
  },
  {
    "text": "So what standard\nneural networks do is do dimensionality reduction,\nbut on a fixed resolution.",
    "start": "1735540",
    "end": "1741820"
  },
  {
    "text": "You decide what the resolution\nis at training time. And at test time, you're forced\nto be at the same resolution.",
    "start": "1741820",
    "end": "1748090"
  },
  {
    "text": "But now we'll remove\nthat limitation and say the input and output\ncan be given at any resolution,",
    "start": "1748090",
    "end": "1753900"
  },
  {
    "text": "and I can still learn a\ndimensionality reduction. I think there was\na question there. Yeah. For numerical simulation,\nit seems like the biggest",
    "start": "1753900",
    "end": "1761070"
  },
  {
    "text": "constraint was compute cost. You give me a sense for what\nis the compute improvement",
    "start": "1761070",
    "end": "1766680"
  },
  {
    "text": "by enabling these. I'm sure it's different across\ndisciplines, but 10 times, 100 times, and then how\ndoes that affect--",
    "start": "1766680",
    "end": "1773040"
  },
  {
    "text": "A million times. Is that true? So for weather prediction-- So for plasma evolution,\nit was a million times.",
    "start": "1773040",
    "end": "1782190"
  },
  {
    "text": "Plasma evolution\nin nuclear fusion. And for weather prediction, it\nwas tens of thousands of times.",
    "start": "1782190",
    "end": "1789080"
  },
  {
    "text": "And so what really\ndetermines this is how hard is it for\nthe solver to the need",
    "start": "1789080",
    "end": "1796210"
  },
  {
    "text": "to get to the finest scales. So something like plasma\nin a tokamak reactor",
    "start": "1796210",
    "end": "1801250"
  },
  {
    "text": "can become extremely unstable. And what scientists need to do\nis make the grid very, very fine",
    "start": "1801250",
    "end": "1808990"
  },
  {
    "text": "to try and understand when\nwill the plasma suddenly escape confinement and become\nunstable, cause disruptions.",
    "start": "1808990",
    "end": "1816830"
  },
  {
    "text": "And so the harder\nthe simulation is, think the gains\nwill be much more.",
    "start": "1816830",
    "end": "1822850"
  },
  {
    "text": "Something very simple\nlike pushing a ball, maybe we won't get any speed\nup because it's so easy",
    "start": "1822850",
    "end": "1828970"
  },
  {
    "text": "to directly just solve it. In closed form, you can\ntell me what that is. There, I don't need this.",
    "start": "1828970",
    "end": "1834740"
  },
  {
    "text": "So think of cases where\nyou need a very fine grid to solve because\nit's highly unstable",
    "start": "1834740",
    "end": "1842140"
  },
  {
    "text": "or nonlinear those fine scales\nhave on the broader sense.",
    "start": "1842140",
    "end": "1848400"
  },
  {
    "text": "So earlier, you spoke\nof how, with regards to mathematical proofs, there is\nthis notion of using verifiers",
    "start": "1848400",
    "end": "1855270"
  },
  {
    "text": "to check the outputs. Say we're solving some system of\nPDEs using this neural operator,",
    "start": "1855270",
    "end": "1862740"
  },
  {
    "text": "how would the verifiers kind of\nextended to this application? That's great. And I mean, that to me is\na world where all of this",
    "start": "1862740",
    "end": "1871500"
  },
  {
    "text": "comes together. So the theorem prover\nis purely symbolic right now in the\nsense you're looking",
    "start": "1871500",
    "end": "1878400"
  },
  {
    "text": "at what are the\nvariables, you're formalizing those\nstatements, and you're proving them step by step.",
    "start": "1878400",
    "end": "1884260"
  },
  {
    "text": "There's no numerical solution. So you're never making the\nvariables into specific values",
    "start": "1884260",
    "end": "1889710"
  },
  {
    "text": "and solving them. On the other hand, this\nis purely numerical. So right now, if you\ngive me navier-stokes",
    "start": "1889710",
    "end": "1895680"
  },
  {
    "text": "for fluid dynamics, I'm just\ndirectly trying to solve it. I'm not symbolically\nmanipulating or making",
    "start": "1895680",
    "end": "1901320"
  },
  {
    "text": "any kind of further\nmodifications. But one day, there could\nbe a neurosymbolic method",
    "start": "1901320",
    "end": "1906570"
  },
  {
    "text": "where you try to make\nvalid transformations that make the equations simpler.",
    "start": "1906570",
    "end": "1912710"
  },
  {
    "text": "Maybe not for navier-stokes,\nbut especially coupled equations,\nlots of them, you try to minimize it\nin a symbolic way,",
    "start": "1912710",
    "end": "1919370"
  },
  {
    "text": "but you also try to\nnumerically solve them better. And right now, the\nmain bottleneck",
    "start": "1919370",
    "end": "1925450"
  },
  {
    "text": "is these verifiers\nlike Lean do not have a lot of good support\nfor calculus or differential",
    "start": "1925450",
    "end": "1932740"
  },
  {
    "text": "equations because there are\nareas like topology where it's purely symbolic.",
    "start": "1932740",
    "end": "1939200"
  },
  {
    "text": "And so more of the\nenergy is there. But one day, that\nwould be a way to bring in neurosymbolic\napproaches to this.",
    "start": "1939200",
    "end": "1946846"
  },
  {
    "text": "Let's actually have\neveryone say their name. I think it'd be useful for-- Yes. And maybe some context. Yeah, that would be [INAUDIBLE].",
    "start": "1946847",
    "end": "1953180"
  },
  {
    "text": "Yes, I guess my\nquestion is concretely, what's the difference\nbetween the inputs that",
    "start": "1953180",
    "end": "1958220"
  },
  {
    "text": "go into a neural\noperator versus which go into a classical\nmachine learning framework because at least envision\ncould train a model",
    "start": "1958220",
    "end": "1964490"
  },
  {
    "text": "to work at lower or higher\nresolutions, but it's still-- Yeah, otherwise\nit's the same thing. So think of it as a video model.",
    "start": "1964490",
    "end": "1971480"
  },
  {
    "text": "It's like Sora or\nany video model. You can give it space and time. So it can be like a three\ndimensions in space and in time,",
    "start": "1971480",
    "end": "1979460"
  },
  {
    "text": "or two dimension\nin this example. So it's the same approach\nas in a vision model.",
    "start": "1979460",
    "end": "1986100"
  },
  {
    "text": "The only addition is\nnow the flexibility to directly input\nmultiple resolutions,",
    "start": "1986100",
    "end": "1992490"
  },
  {
    "text": "both at training\nand testing time. So then do you have\nto change anything in terms of the\nstandard layers you",
    "start": "1992490",
    "end": "1998340"
  },
  {
    "text": "use to adapt to different\nshapes or how does that-- So the main change\nis to make it now flexible in terms of handling\nthese inputs and outputs.",
    "start": "1998340",
    "end": "2006780"
  },
  {
    "text": "So in the middle layers, you\ncan still use a transformer, you can still make it\ninto a coarser grid",
    "start": "2006780",
    "end": "2012680"
  },
  {
    "text": "and use any of the\nstandard approaches. So think of it as mainly\nat the input and output,",
    "start": "2012680",
    "end": "2018360"
  },
  {
    "text": "you need to make changes. But looking at it in terms of\nthe class of architectures,",
    "start": "2018360",
    "end": "2023670"
  },
  {
    "text": "you can take any of the\nexisting architecture like a convolutional\nnet, a transformer, and extend it to now handling\nmultiple resolutions.",
    "start": "2023670",
    "end": "2031410"
  },
  {
    "text": "That's essentially\nwhat these are doing. So this is not a new\narchitecture in itself, but it's more now a superset of\nexisting class of architectures.",
    "start": "2031410",
    "end": "2042020"
  },
  {
    "text": "Hi, I am a PhD student\nstudying formal methods. And so just coming back\nto the computational gains",
    "start": "2042020",
    "end": "2049033"
  },
  {
    "text": "you described earlier,\nyou've mentioned that you've described the\nmodels that you were using. Can you talk a little bit\nmore about the architecture?",
    "start": "2049034",
    "end": "2055329"
  },
  {
    "text": "So more like are these large\ntransformer based models or are these results coming from\nregular fully connected networks",
    "start": "2055330",
    "end": "2062316"
  },
  {
    "text": "and stuff like that? Yeah. So like I mentioned,\nin the general sense, these neural operators are an\nextension of any neural network.",
    "start": "2062317",
    "end": "2071440"
  },
  {
    "text": "So you give me a neural\nnet, I can turn it into a neural operator,\nmeaning I can make now",
    "start": "2071440",
    "end": "2076620"
  },
  {
    "text": "the layers of them be able to\nhandle any resolution of input and output.",
    "start": "2076620",
    "end": "2081669"
  },
  {
    "text": "But of course, among them, which\none is a good candidate, right? So in this example,\nwhat we've done",
    "start": "2081670",
    "end": "2086849"
  },
  {
    "text": "is use Fourier neural operator. So it has Fourier\nlayers, but it also has nonlinear layers like\nMLP, even attention layers",
    "start": "2086850",
    "end": "2096569"
  },
  {
    "text": "you can add. So it has a combination of that. And the Fourier\ntends to be very good",
    "start": "2096570",
    "end": "2102450"
  },
  {
    "text": "for a lot of these applications,\nespecially in fluids, because you have interaction\nacross multiple scales",
    "start": "2102450",
    "end": "2108930"
  },
  {
    "text": "and that is better described\nin a Fourier domain. But unlike a\ntraditional method, it's",
    "start": "2108930",
    "end": "2114270"
  },
  {
    "text": "not purely based on\nFourier transform. You have these\nnon-linearities in between",
    "start": "2114270",
    "end": "2119820"
  },
  {
    "text": "and that's how you learn a more\nexpressive basis than purely a Fourier basis.",
    "start": "2119820",
    "end": "2125027"
  },
  {
    "text": "Could you talk a\nlittle bit about how you landed on a fourier? How did you know that that\nwas the architecture you used?",
    "start": "2125028",
    "end": "2130570"
  },
  {
    "text": "Was there some fine\ntuning along the way? Yeah, so this actually\ncame from our discussions",
    "start": "2130570",
    "end": "2135690"
  },
  {
    "text": "with my collaborators in\napplied math and those who've been using numerical solvers.",
    "start": "2135690",
    "end": "2141250"
  },
  {
    "text": "And it turns out\nfor fluid dynamics, a popular solver is a\npseudospectral solver where you go to\nthe Fourier domain,",
    "start": "2141250",
    "end": "2148420"
  },
  {
    "text": "you make some steps\nor iterations, you come back to\nthe standard domain, and you go back and forth.",
    "start": "2148420",
    "end": "2154240"
  },
  {
    "text": "And we realized that\nin between, you could add a lot of nonlinear layers. You could also add nonlinear\nencoders and decoders.",
    "start": "2154240",
    "end": "2162130"
  },
  {
    "text": "And with that, you\nmake that expressive. So in that sense, a\nspecial case of that",
    "start": "2162130",
    "end": "2167609"
  },
  {
    "text": "is still the numerical solver. So if those models just learnt\nidentity transformations,",
    "start": "2167610",
    "end": "2173650"
  },
  {
    "text": "then you go back to\nyour original solver, which is a valid solution. But you could do something\nmuch better than that.",
    "start": "2173650",
    "end": "2180540"
  },
  {
    "text": "And so we came at\nit while trying to preserve the properties\nthat numerical solvers already",
    "start": "2180540",
    "end": "2186510"
  },
  {
    "text": "have, but extend the\nexpressivity of those models. But it also has\na nice connection",
    "start": "2186510",
    "end": "2192210"
  },
  {
    "text": "to transformers and others. So it kind of meets both\nthe traditional simulations",
    "start": "2192210",
    "end": "2197250"
  },
  {
    "text": "and neural nets in a nice\nway, if that makes sense. That's a quick-- yeah.",
    "start": "2197250",
    "end": "2203320"
  },
  {
    "text": "I'm a CS undergrad. And I'm curious\nabout the mechanics of this specific network. So when it outputs, for example,\nits next frame prediction,",
    "start": "2203320",
    "end": "2212600"
  },
  {
    "text": "does it plug that prediction\nback into the input to get the next frame\nor what are the-- Yeah, again, we have\nmultiple options.",
    "start": "2212600",
    "end": "2219310"
  },
  {
    "text": "That's called autoregressive\nif you plug it in and do one by one. For something like weather\nmodel, that's what we did.",
    "start": "2219310",
    "end": "2225940"
  },
  {
    "text": "But we've also had models\nwhere you can roll out in a latent space, so\nyou don't need to do that in the observed domain.",
    "start": "2225940",
    "end": "2232180"
  },
  {
    "text": "We also have models where\nyou directly output answers at any timestep by also\nhaving a Fourier or other kind",
    "start": "2232180",
    "end": "2243310"
  },
  {
    "text": "of approaches that can do any\nresolution in time as well. So again, there are many\ndifferent candidates",
    "start": "2243310",
    "end": "2250300"
  },
  {
    "text": "and it depends on\nthe use case what would be the most appropriate. Yeah. ",
    "start": "2250300",
    "end": "2257970"
  },
  {
    "text": "Great. I know lots of questions. Do keep them coming.",
    "start": "2257970",
    "end": "2263940"
  },
  {
    "text": "So I wanted to just show some\nof the use cases of where we've used neural operators.",
    "start": "2263940",
    "end": "2269520"
  },
  {
    "text": "The weather model was one\nof the first complex domain, I would say, where\nwe chose this.",
    "start": "2269520",
    "end": "2275650"
  },
  {
    "text": "So what makes weather\nchallenging is, first of all, it's high resolution.",
    "start": "2275650",
    "end": "2280750"
  },
  {
    "text": "This data is like 25 kms\nspacing across the globe.",
    "start": "2280750",
    "end": "2285910"
  },
  {
    "text": "And we have historical data\ngoing back to for decades. And it's not a lot of them. About 50,000 samples, which is\nnothing compared to the language",
    "start": "2285910",
    "end": "2294599"
  },
  {
    "text": "models of the world. So it's good amount,\nbut it's not-- 50,000 timestamps or--",
    "start": "2294600",
    "end": "2300060"
  },
  {
    "text": "50,000 initial condition\nto next time step. So pairs of data.",
    "start": "2300060",
    "end": "2305670"
  },
  {
    "text": "So if it's every 25,\nhow many grids is there?",
    "start": "2305670",
    "end": "2310960"
  },
  {
    "text": "1,000 something in each-- 1,000 or 1,200 or\nsomething like or 1,600.",
    "start": "2310960",
    "end": "2317700"
  },
  {
    "text": "I forget. You can do the math\nglobally what-- so think of that as the image--",
    "start": "2317700",
    "end": "2324140"
  },
  {
    "text": "for computer vision, it's a\nfairly high resolution image. But also, we don't\nhave a lot of samples.",
    "start": "2324140",
    "end": "2330312"
  },
  {
    "text": "The other thing that\nmakes it challenging is also many channels. So unlike RGB for images, you\nnow have wind speed, humidity,",
    "start": "2330312",
    "end": "2340609"
  },
  {
    "text": "you have different\nlayers of the atmosphere. So there are more\nthan 100 variables.",
    "start": "2340610",
    "end": "2346130"
  },
  {
    "text": "So you have this high\ndimensional challenge of coming up with the weather.",
    "start": "2346130",
    "end": "2351920"
  },
  {
    "text": "And when we started working\non this in the late 2020s, we had come up with\nneural operators.",
    "start": "2351920",
    "end": "2358309"
  },
  {
    "text": "We want to\nchallenging use cases. The fluid dynamics was already\nconsidered challenging enough,",
    "start": "2358310",
    "end": "2363890"
  },
  {
    "text": "but we wanted to also touch\nsomething that directly impacts the real world.",
    "start": "2363890",
    "end": "2369559"
  },
  {
    "text": "But many people\nthought we were crazy. No, this is decades of\nmethods that are developed",
    "start": "2369560",
    "end": "2375070"
  },
  {
    "text": "for forecasting weather. And I do remember growing up and\nthinking, one of the use cases",
    "start": "2375070",
    "end": "2381130"
  },
  {
    "text": "for supercomputers\nwas always told-- I was told that look at weather\nmodels, weather forecasting that",
    "start": "2381130",
    "end": "2387550"
  },
  {
    "text": "needs a big supercomputer. And so our question was how\nmuch can we do well with respect",
    "start": "2387550",
    "end": "2394930"
  },
  {
    "text": "to using neural operators and a\ncompletely deep learning based method, meaning I take\nmy initial condition now",
    "start": "2394930",
    "end": "2402070"
  },
  {
    "text": "and I use now a neural\noperator to predict the time",
    "start": "2402070",
    "end": "2408370"
  },
  {
    "text": "step like the weather at the\nsame six hour increments. And we do this\nautoregressively and we",
    "start": "2408370",
    "end": "2413829"
  },
  {
    "text": "can give two week forecasts\nbased on these predictions. And it turns out that\nit is much faster.",
    "start": "2413830",
    "end": "2422320"
  },
  {
    "text": "The first run of the model, it\nwas about 45,000 times faster",
    "start": "2422320",
    "end": "2427480"
  },
  {
    "text": "than what you can do\nwith numerical models. So literally, what would\ntake this big supercomputer",
    "start": "2427480",
    "end": "2433810"
  },
  {
    "text": "based on CPUs, you can run\nthis on a local gaming PC.",
    "start": "2433810",
    "end": "2438860"
  },
  {
    "text": "So all you need is a consumer\ngrade GPU and the model is open source too.",
    "start": "2438860",
    "end": "2443930"
  },
  {
    "text": "So you can download the model\nand run your own weather model. We've open sourced it\nwith permissive license.",
    "start": "2443930",
    "end": "2450290"
  },
  {
    "text": "And I think that,\nto me, is what shows the promise and the\nability of these models",
    "start": "2450290",
    "end": "2457090"
  },
  {
    "text": "to really miniaturize\nwhat is considered as very complex physical\ncalculations and do pretty well.",
    "start": "2457090",
    "end": "2466270"
  },
  {
    "text": "This model is also\nrunning in ECMW app. So you can go get real\ntime weather forecasts.",
    "start": "2466270",
    "end": "2471800"
  },
  {
    "text": "So these are just\nsome of the charts of what do different\nweather variables, how",
    "start": "2471800",
    "end": "2477130"
  },
  {
    "text": "are they predicted. And it has predicted some of the\nhurricanes last year even better than the numerical models.",
    "start": "2477130",
    "end": "2483440"
  },
  {
    "text": "So it's not just being faster,\ntens of thousands of times faster at the price of\naccuracy, but you can",
    "start": "2483440",
    "end": "2490900"
  },
  {
    "text": "get both accuracy and speed. So what are we doing,\nhow is this possible. Usually, it's a trade off.",
    "start": "2490900",
    "end": "2497370"
  },
  {
    "text": "Here, we can do it because\nwe are learning from data. So when you're doing\na numerical solver",
    "start": "2497370",
    "end": "2503790"
  },
  {
    "text": "and the traditional\nweather forecasts, you assume there\nis navier-stokes and you assume there's a\ncertain Reynolds number.",
    "start": "2503790",
    "end": "2510670"
  },
  {
    "text": "So you're making all\nthese modeling assumptions and you're not able to train all\nof that with the data itself.",
    "start": "2510670",
    "end": "2518190"
  },
  {
    "text": "You're not using the data to\ninform your modeling choices to a big extent.",
    "start": "2518190",
    "end": "2523270"
  },
  {
    "text": "You can calibrate still a few\nparameters, but it's only a few of them. You're not adapting the\nbigger set of variables",
    "start": "2523270",
    "end": "2530790"
  },
  {
    "text": "to the data that is available. And this is what now neural\nbased models allow us to do.",
    "start": "2530790",
    "end": "2537369"
  },
  {
    "text": "They can adapt to the data. And many times, these\nmodeling errors are huge.",
    "start": "2537370",
    "end": "2543340"
  },
  {
    "text": "And that's why\nlearning from data can help us get\nto better science. Does that mean that there's some\nother underlying physics that",
    "start": "2543340",
    "end": "2550843"
  },
  {
    "text": "hasn't been written down that's\ndriving the weather that's not navier-stokes? Is it discovering\nsome new physics",
    "start": "2550843",
    "end": "2556510"
  },
  {
    "text": "is a more provocative\nway of saying it? That's a hard thing to say\nbecause either navier-stokes",
    "start": "2556510",
    "end": "2563470"
  },
  {
    "text": "itself is wrong-- again, there are papers of\nall kinds of edge cases where navier-stokes may\nnot be perfect--",
    "start": "2563470",
    "end": "2570040"
  },
  {
    "text": "or the likely answer is you\ndon't know precisely what is the kind of specification in the\nsense of what is the Reynolds",
    "start": "2570040",
    "end": "2578170"
  },
  {
    "text": "number here and how is how does\nnavier-stokes interact with-- [INAUDIBLE] off by a fraction-- Yeah, exactly.",
    "start": "2578170",
    "end": "2583880"
  },
  {
    "text": "Temperature, yeah. And it's also\nimperfect observations. You're looking at satellite\ndata that is irregular.",
    "start": "2583880",
    "end": "2591560"
  },
  {
    "text": "And in fact, in\nthe Global South, the predictions right\nnow are much worse. You can barely predict over\nthe next three to four days",
    "start": "2591560",
    "end": "2600250"
  },
  {
    "text": "compared to in the developed\nworld where we can do up to two week forecasts. Because they don't\nhave as many sensors.",
    "start": "2600250",
    "end": "2606790"
  },
  {
    "text": "Yeah, much less\nsatellite coverage. So that is a big factor.",
    "start": "2606790",
    "end": "2612190"
  },
  {
    "text": "But what these models\ncan enable us to do is further adapt to maybe\neven limited regional data.",
    "start": "2612190",
    "end": "2619270"
  },
  {
    "text": "You can have weather balloons\nor something low cost and further refine and\nlearn from that data.",
    "start": "2619270",
    "end": "2624599"
  },
  {
    "text": "And so this gives\nthe ability compared to standard models, which are-- Just to be clear, it sounds\nlike mainly you're learning more",
    "start": "2624600",
    "end": "2630530"
  },
  {
    "text": "precise data, not necessarily--\nit's not necessarily that the physics is wrong or--",
    "start": "2630530",
    "end": "2635660"
  },
  {
    "text": "We're not decoupling\nthe two effects. But it's learning\nsomething-- it's making predictions different\nthan what the pure equations",
    "start": "2635660",
    "end": "2644270"
  },
  {
    "text": "would have said. Is that mainly because the\ndata is different or is it possibly because there's other\nthings going on driving the--",
    "start": "2644270",
    "end": "2651450"
  },
  {
    "text": "Yeah, it could be a\ncombination of both. And that's what we currently\nhaven't decoupled, meaning",
    "start": "2651450",
    "end": "2657380"
  },
  {
    "text": "you have partial observations. So you imprecisely specified\nyour numerical model",
    "start": "2657380",
    "end": "2664010"
  },
  {
    "text": "and that's why it\nsimulates it wrong or the equations that are being\nsimulated itself are wrong.",
    "start": "2664010",
    "end": "2669799"
  },
  {
    "text": "And I think in my view,\nit's more of the former because these equations\nhave been stress tested in all kinds of wind tunnels.",
    "start": "2669800",
    "end": "2676400"
  },
  {
    "text": "It's mostly OK. But then if there are all kinds\nof changes in Reynolds number",
    "start": "2676400",
    "end": "2682519"
  },
  {
    "text": "everywhere in the\nplanet, and you don't know how to\nmodel that, you can make big errors because\nof those modeling choices.",
    "start": "2682520",
    "end": "2690750"
  },
  {
    "text": "OK, let's get a question in. [INAUDIBLE] I'm from\nthe MBA program.",
    "start": "2690750",
    "end": "2699109"
  },
  {
    "text": "So I'm thinking about\nthe institutional take up of these technologies. A lot of times in this\nclass, we discuss how things",
    "start": "2699110",
    "end": "2705549"
  },
  {
    "text": "are extremely disruptive. But as I look at this, you're\nlooking at a traditional weather forecasting institution\nthat has been able to uptake",
    "start": "2705550",
    "end": "2712720"
  },
  {
    "text": "the technology that's\n45,000 times better. Can you talk to me a little bit\nabout how these technologies are",
    "start": "2712720",
    "end": "2722560"
  },
  {
    "text": "maybe not as disruptive and how\nthese improvements are taken up by existing channels\nwithout as much change,",
    "start": "2722560",
    "end": "2729710"
  },
  {
    "text": "or was there a lot\nof internal shift in the community as this\ntechnology has taken off?",
    "start": "2729710",
    "end": "2735760"
  },
  {
    "text": "No, that's great. And I think I alluded to in\nthe beginning a little bit",
    "start": "2735760",
    "end": "2741040"
  },
  {
    "text": "how there was so\nmuch skepticism. And in fact,\ncoincidentally, just before we released\nthe model, there",
    "start": "2741040",
    "end": "2746140"
  },
  {
    "text": "was even an opinion piece-- can deep learning beat\nnumerical weather models. And the conclusion was\nno, no, no, there's",
    "start": "2746140",
    "end": "2753310"
  },
  {
    "text": "so much needs to be done. Maybe years, maybe even\ndecades before that happens. So I should say a lot\nof people traditionally",
    "start": "2753310",
    "end": "2762080"
  },
  {
    "text": "who don't like the black box\nnature of machine learning were very skeptical,\nfirst of all,",
    "start": "2762080",
    "end": "2768960"
  },
  {
    "text": "that it would do a good\njob because you have rare events like hurricanes. You don't expect to\ndo well on hurricanes.",
    "start": "2768960",
    "end": "2776000"
  },
  {
    "text": "What machine learning tells us\nis to do well on typical events, maybe weather here in\nStanford, every day is sunny.",
    "start": "2776000",
    "end": "2784430"
  },
  {
    "text": "But it turns out that you\ncan capture those events as well pretty accurately\nand sometimes even better",
    "start": "2784430",
    "end": "2791089"
  },
  {
    "text": "than traditional models. It could predict things\nthat it never seen before? It could have\npredict a hurricane",
    "start": "2791090",
    "end": "2796580"
  },
  {
    "text": "without having seen a hurricane? So it did see some hurricanes. So it's able to\ndo better on that.",
    "start": "2796580",
    "end": "2802890"
  },
  {
    "text": "And also, we did some kind\nof even more drastic stress testing, like being able\nto put a big blob of heat",
    "start": "2802890",
    "end": "2811040"
  },
  {
    "text": "near the equator, which is\nalmost unphysical because you can't just heat up just\nthe ocean in some limited",
    "start": "2811040",
    "end": "2818480"
  },
  {
    "text": "by, I think, 3 or 4 degrees. So we did these extreme tests\nwhich hopefully will never",
    "start": "2818480",
    "end": "2823940"
  },
  {
    "text": "happen on this planet. But again, what\nhappened was something you expected, kind of the heat\ndissipated into other areas.",
    "start": "2823940",
    "end": "2831060"
  },
  {
    "text": "Of course, it heated\nup other things, but it was behaving in a\nphysically valid manner, even though we were giving\nit such extreme conditions.",
    "start": "2831060",
    "end": "2839300"
  },
  {
    "text": "And did you get much-- I guess it's being adopted\nthere into Wyatt's question?",
    "start": "2839300",
    "end": "2844850"
  },
  {
    "text": "Tell us a little bit\nabout the resistance. And so to complete that\nstory, we had the skepticism.",
    "start": "2844850",
    "end": "2851220"
  },
  {
    "text": "But we were like,\nno, we have the data. Anytime you give data to\na machine learning person,",
    "start": "2851220",
    "end": "2856230"
  },
  {
    "text": "we're just going to try and do\nit rather than debate beforehand if it works or not.",
    "start": "2856230",
    "end": "2861300"
  },
  {
    "text": "And I think that to me was\nreally the starting point. And once we showed\nthat it's quite",
    "start": "2861300",
    "end": "2867230"
  },
  {
    "text": "competitive to numerical\nweather models, there were other groups which\nare, again, took up just",
    "start": "2867230",
    "end": "2872360"
  },
  {
    "text": "as we do in computer\nvision or language. It's never like one group. You suddenly see a lot of\nactivity in the whole area",
    "start": "2872360",
    "end": "2881750"
  },
  {
    "text": "as well as I was quite\nsurprised, to be honest, like a traditional agency,\nlike ECMWF as well as NOAA,",
    "start": "2881750",
    "end": "2888300"
  },
  {
    "text": "which is-- What does that stand for? ECMWF is the European Center for\nMedium-range Weather Forecasting",
    "start": "2888300",
    "end": "2894740"
  },
  {
    "text": "and NOAA, which is the\nNorth American Atmospheric-- Administration.",
    "start": "2894740",
    "end": "2900320"
  },
  {
    "text": "Administration. Yes, thank you. So both are using these models.",
    "start": "2900320",
    "end": "2906060"
  },
  {
    "text": "They are heavily working. They're further training\non their own data and improving these models.",
    "start": "2906060",
    "end": "2913670"
  },
  {
    "text": "So I think I should say that I\nwas a bit surprised how quickly they took this and employed it.",
    "start": "2913670",
    "end": "2919890"
  },
  {
    "text": "But I think once you show them\ndefinite proofs because we use the same metrics\nthey did, it wasn't just",
    "start": "2919890",
    "end": "2927079"
  },
  {
    "text": "one specific variable\nlike wind or temperature, but even extreme weather events\nlike hurricanes, typhoons.",
    "start": "2927080",
    "end": "2933690"
  },
  {
    "text": "We documented a lot of the\nstatistics of how well it works. And we talked to them a lot.",
    "start": "2933690",
    "end": "2939720"
  },
  {
    "text": "So this was done\nin collaboration with scientists in weather\nand climate community.",
    "start": "2939720",
    "end": "2944880"
  },
  {
    "text": "And that also, I think, matters\nto ensure we do the right thing.",
    "start": "2944880",
    "end": "2950000"
  },
  {
    "text": "Yeah. Yes. I was wondering whether\nthese neural operators should be viewed as accelerators\nfor existing algorithms",
    "start": "2950000",
    "end": "2957700"
  },
  {
    "text": "or are they an entirely\ndifferent class of algorithms? Or maybe do they have the\nsame computational complexity",
    "start": "2957700",
    "end": "2966520"
  },
  {
    "text": "or are they just\ngenerally faster? So compared to\nnumerical solvers, they're generally faster\nbecause the numerical solver,",
    "start": "2966520",
    "end": "2974350"
  },
  {
    "text": "think of it as a special case of\narchitecture within this class. And if you correctly\nchosen your architecture",
    "start": "2974350",
    "end": "2981700"
  },
  {
    "text": "and trained it well, you expect\nit to be faster and better. And that's what we\nsee in many areas.",
    "start": "2981700",
    "end": "2988550"
  },
  {
    "text": "It's only the question is,\nwhat is the level of speed up. And the general rule\nof thumb is if you",
    "start": "2988550",
    "end": "2994510"
  },
  {
    "text": "have numerical solvers that\nrequire a very fine grid and the phenomena is more\nnonlinear and unstable,",
    "start": "2994510",
    "end": "3001440"
  },
  {
    "text": "we tend to get even better\nspeed ups with these models.",
    "start": "3001440",
    "end": "3008349"
  },
  {
    "text": "Yeah. I'm a PhD student in the\ncomputer science department.",
    "start": "3008350",
    "end": "3014490"
  },
  {
    "text": "How does your model compare\nto, say, other models like GraphCast from DeepMind?",
    "start": "3014490",
    "end": "3020450"
  },
  {
    "text": "Yeah. So GraphCast was one\nof the models that followed based on what we do. So graph is one way\nto think about, again,",
    "start": "3020450",
    "end": "3029050"
  },
  {
    "text": "looking at the relationship\nbetween neighboring grid points, and you can do that in\na hierarchical manner.",
    "start": "3029050",
    "end": "3036109"
  },
  {
    "text": "And so what we did was\nto look at it like treat",
    "start": "3036110",
    "end": "3041410"
  },
  {
    "text": "the world as a sphere. And then if I did Fourier\ntransform on the sphere,",
    "start": "3041410",
    "end": "3049430"
  },
  {
    "text": "it's spherical basis and learn\nthe coefficients in that basis and combine them with\nnon-linear layers.",
    "start": "3049430",
    "end": "3055190"
  },
  {
    "text": "So we're going to release an\nupdated architecture where you can think of it as a hybrid\nthat is both graph based,",
    "start": "3055190",
    "end": "3062510"
  },
  {
    "text": "it has local\nconnections, but it also has global information\nthat still treats the geometry as a sphere.",
    "start": "3062510",
    "end": "3069260"
  },
  {
    "text": "So I don't know if\nI had that here. I don't have it in\nthis set of slides, but we can show the benefit of\ntreating the world as a sphere",
    "start": "3069260",
    "end": "3076970"
  },
  {
    "text": "and not a flat Earth,\nnot a rectangle, as if you make\nvery long rollouts. So if you now not just try to\npredict weather for one or two",
    "start": "3076970",
    "end": "3085130"
  },
  {
    "text": "weeks, but do that for years. So you need this for climate\npredictions, very long term",
    "start": "3085130",
    "end": "3090170"
  },
  {
    "text": "predictions. The model with the\nspherical geometry tends to be much\nmore stable compared",
    "start": "3090170",
    "end": "3096320"
  },
  {
    "text": "to treating the\nworld as a rectangle, because at some\npoint, the predictions are no longer consistent\nbecause it's not constraining",
    "start": "3096320",
    "end": "3105050"
  },
  {
    "text": "it to be on the\nsphere and it tends to blow up and become unstable. And that's, I think, the\nother just high level",
    "start": "3105050",
    "end": "3112099"
  },
  {
    "text": "idea to think about\nwhen applying it to scientific domains. It's usually not one\nobjective function.",
    "start": "3112100",
    "end": "3117840"
  },
  {
    "text": "Even if I tell you\nthe loss function is predict the weather,\nin the next six hours, and make that accurate, that's\nusually not good enough.",
    "start": "3117840",
    "end": "3125750"
  },
  {
    "text": "With the weather\nmodel, you also want the ability to go longer term. You want it to be able to\ndo extreme weather, which",
    "start": "3125750",
    "end": "3133820"
  },
  {
    "text": "is rare events. So that's the difficulty in\na lot of scientific domains, the many multiple objectives.",
    "start": "3133820",
    "end": "3140070"
  },
  {
    "text": "And sometimes you can't even\ndefine it as a loss function. So we try to incorporate\nmore of the domain knowledge and constraints to\nmake the model well-behaved.",
    "start": "3140070",
    "end": "3148588"
  },
  {
    "text": "We have a bunch more questions. I'm just looking at\nthe time here also. So I don't know\nif you have more--",
    "start": "3148588",
    "end": "3155180"
  },
  {
    "text": "I can also-- I'm happy to take questions. That's a more fun thing.",
    "start": "3155180",
    "end": "3160920"
  },
  {
    "text": "And I can then quickly\nwrap up after I just have a few more slides, just\nkind of unifying this notion.",
    "start": "3160920",
    "end": "3167550"
  },
  {
    "text": "So I'm not going to\nintroduce much of new ideas. So-- I'm happy to do it that way. Yeah.",
    "start": "3167550",
    "end": "3172970"
  },
  {
    "text": "I'm a CS undergrad. I think you mentioned a lot\nof these different objective functions for different models.",
    "start": "3172970",
    "end": "3178569"
  },
  {
    "text": "I just want to get a layer\nof current weather modeling landscape weather.",
    "start": "3178570",
    "end": "3183730"
  },
  {
    "text": "[INAUDIBLE] Whether there's a bunch of\ndifferent mixture of models for this specific use case\nor this specific climate",
    "start": "3183730",
    "end": "3190300"
  },
  {
    "text": "or something in the desert,\nthere's a desert model. What does that look\nlike right now? I mean, right now,\nit's a global model.",
    "start": "3190300",
    "end": "3196960"
  },
  {
    "text": "It's learning across the globe,\nwhich we treat it as a sphere. It's learning the dependencies.",
    "start": "3196960",
    "end": "3203119"
  },
  {
    "text": "So we're not, again,\ndoing specialized models for different, say, geographies\nor different conditions.",
    "start": "3203120",
    "end": "3210740"
  },
  {
    "text": "It's implicitly determined\nby all the variables. We have variables that\ndescribe the temperature that",
    "start": "3210740",
    "end": "3218170"
  },
  {
    "text": "describe humidity, pressure. So you know implicitly what's\na rainforest and a desert,",
    "start": "3218170",
    "end": "3223340"
  },
  {
    "text": "but we're not doing\nanything further explicitly. Yeah,",
    "start": "3223340",
    "end": "3231500"
  },
  {
    "text": "On that same kind of thing,\nyou have multiple models. Are you thinking of,\non certification,",
    "start": "3231500",
    "end": "3238310"
  },
  {
    "text": "can you validate them using one\nand maybe an adversarial model to challenge it a bit?",
    "start": "3238310",
    "end": "3245280"
  },
  {
    "text": "Yeah, so this was\nthe next thing, talking about uncertainties. So there's different\nkinds of uncertainties.",
    "start": "3245280",
    "end": "3251910"
  },
  {
    "text": "But it turns out, especially for\nextreme weather like hurricanes, the kind of uncertainty\nthat matters is",
    "start": "3251910",
    "end": "3259070"
  },
  {
    "text": "what are my current conditions. So if you slightly change the\npath of your current hurricane",
    "start": "3259070",
    "end": "3265400"
  },
  {
    "text": "prediction, the\nhurricane is still here in the Gulf of Mexico.",
    "start": "3265400",
    "end": "3270480"
  },
  {
    "text": "And then whether it's going to\nhit Florida or make landfall, how do you predict\nthat early on.",
    "start": "3270480",
    "end": "3276089"
  },
  {
    "text": "As early as you can\npredict, the better. But, of course, if you\nstart early on here as you see from the Gulf of\nMexico, you slightly perturb it,",
    "start": "3276090",
    "end": "3284579"
  },
  {
    "text": "the predictions\ncan change vastly because this is what we\ncall chaotic phenomena. If you've seen the Butterfly\nEffect, either the movie",
    "start": "3284580",
    "end": "3292290"
  },
  {
    "text": "or heard about it, very tiny\nchanges can have big effects. And that's the other\nchallenge with this.",
    "start": "3292290",
    "end": "3298530"
  },
  {
    "text": "Compared to standard\nvision models where you have lots\nof robustness, here,",
    "start": "3298530",
    "end": "3303820"
  },
  {
    "text": "this can be quite delicate based\non making even small changes.",
    "start": "3303820",
    "end": "3308890"
  },
  {
    "text": "But what we care about\nare these uncertainties. So not just give\nme a path of where",
    "start": "3308890",
    "end": "3314850"
  },
  {
    "text": "the hurricane is likely to\nbe, but the sensitivity. If I now slightly perturb\nmy current condition,",
    "start": "3314850",
    "end": "3321640"
  },
  {
    "text": "how much is it going to change? And that's what will\nhelp me determine what is the probability\nit will hit Florida.",
    "start": "3321640",
    "end": "3327940"
  },
  {
    "text": "And based on that,\nI can take action. I can be like, should\nthere be an evacuation, should plan for certain\nreinforcement of certain kind.",
    "start": "3327940",
    "end": "3338950"
  },
  {
    "text": "And that's where\nthese models are much better than the\ntraditional weather models,",
    "start": "3338950",
    "end": "3346390"
  },
  {
    "text": "because I think\nyou'll be surprised. If you look at the\ntraditional weather models, can you guess how\nmany ensemble members,",
    "start": "3346390",
    "end": "3354640"
  },
  {
    "text": "meaning how many such\nperturbations are done to determine sensitivity?",
    "start": "3354640",
    "end": "3359700"
  },
  {
    "text": "You want to take a guess? What is done today in the\nactual ECMWF for these?",
    "start": "3359700",
    "end": "3366530"
  },
  {
    "text": " You think only 10?",
    "start": "3366530",
    "end": "3371670"
  },
  {
    "text": "[INAUDIBLE] 50. So it's not a lot.",
    "start": "3371670",
    "end": "3377270"
  },
  {
    "text": "If you ask about standard\ndeviation of 50 numbers, just 50",
    "start": "3377270",
    "end": "3383120"
  },
  {
    "text": "samples, it's not really good. And of course, if you do-- But why do they do so few? Is it expensive to do one?",
    "start": "3383120",
    "end": "3388160"
  },
  {
    "text": "It's that expensive\nbecause each one requires this big supercomputer. Then all goverments have\nlimited resources and we have--",
    "start": "3388160",
    "end": "3397940"
  },
  {
    "text": "and whereas with these\nnow models being so cheap, you can run them\nin a single GPU.",
    "start": "3397940",
    "end": "3403560"
  },
  {
    "text": "Now you can do thousands or\neven millions of samples. So you can get to the right\nstatistical bounds as needed.",
    "start": "3403560",
    "end": "3410640"
  },
  {
    "text": "That's no longer a\nconstraint that you have to limit to just\nhaving 50 scenario runs.",
    "start": "3410640",
    "end": "3416310"
  },
  {
    "text": "And when it comes to\nclimate models, in fact, it's really bad. Many of the climate predictions\nyou see is a single run.",
    "start": "3416310",
    "end": "3423270"
  },
  {
    "text": "But what is climate? Climate is like saying\nwhat happens in decades.",
    "start": "3423270",
    "end": "3428440"
  },
  {
    "text": "So you cannot just do one run\nand say what's going to happen. You need lots of runs. And this is where\nbringing down the cost",
    "start": "3428440",
    "end": "3435570"
  },
  {
    "text": "has an impact in making that\nuncertainty quantification much more precise. And the extreme values may be\nmore important than the median.",
    "start": "3435570",
    "end": "3442800"
  },
  {
    "text": "And that's why the extreme\nweather this is so important. If you don't have\nenough of the spread,",
    "start": "3442800",
    "end": "3448000"
  },
  {
    "text": "you miss the extreme events. You can't even predict that\nthere will be an extreme event. We've shown this not\nonly for hurricanes,",
    "start": "3448000",
    "end": "3454590"
  },
  {
    "text": "but also heat waves and\nall kinds of extreme events that you can capture\nit once you increase",
    "start": "3454590",
    "end": "3460500"
  },
  {
    "text": "the number of ensemble members. Right. If your hand is in the freezer\nand the oven on average,",
    "start": "3460500",
    "end": "3465580"
  },
  {
    "text": "it's fine. But you could-- Exactly. You need to have the spread. Yeah. Hi.",
    "start": "3465580",
    "end": "3471839"
  },
  {
    "text": "Quick question. So I'm studying economics. I'm really\nfascinated, obviously,",
    "start": "3471840",
    "end": "3477520"
  },
  {
    "text": "by what you were talking\nabout with both the work you're doing on genomics and\nviral and bacterial mutation",
    "start": "3477520",
    "end": "3483290"
  },
  {
    "text": "prediction. My dad is a virologist. So this is all really\ncrazy to think about. I'm wondering your perspective,\ncoming both from industry",
    "start": "3483290",
    "end": "3491910"
  },
  {
    "text": "and academia, how\ndo you see academics viewing this new technology.",
    "start": "3491910",
    "end": "3497170"
  },
  {
    "text": "Do you feel like there's\nan openness to it, or is there kind of old\nguard, new guard tension,",
    "start": "3497170",
    "end": "3502780"
  },
  {
    "text": "are they embracing it? How is that looking? Yeah. I mean, it's similar to what I\nmentioned about weather models.",
    "start": "3502780",
    "end": "3508860"
  },
  {
    "text": "But it's funny. I think biologists are a lot\nmore open than physicists.",
    "start": "3508860",
    "end": "3514020"
  },
  {
    "text": "But that's changing fast. But I think maybe\nbecause biology, there's even less of a\nrigidity of I know the model.",
    "start": "3514020",
    "end": "3521039"
  },
  {
    "text": "No one really knows. Sure, you can pause it something\nat the level of molecules, what the forces are, but try to\nget all the way to anything",
    "start": "3521040",
    "end": "3529950"
  },
  {
    "text": "that is at the human\nlevel or clinical level. There's just so many\nlevels of uncertainty",
    "start": "3529950",
    "end": "3535860"
  },
  {
    "text": "and it's clear that\nthe more data we can get at all these different\nlevels of experimentation,",
    "start": "3535860",
    "end": "3542279"
  },
  {
    "text": "the better we can be\nin terms of prediction. And so there's been a\nlot of interesting uses.",
    "start": "3542280",
    "end": "3548410"
  },
  {
    "text": "In fact, not this genomic model,\nbut some of the other techniques we've done in speeding up\nquantum chemistry as well",
    "start": "3548410",
    "end": "3555090"
  },
  {
    "text": "as the binding process. It's been used in\na drug that is now getting to clinical\ntrial in a startup",
    "start": "3555090",
    "end": "3562109"
  },
  {
    "text": "that I helped advise and\nhelp start that venture.",
    "start": "3562110",
    "end": "3567490"
  },
  {
    "text": "So this is now kind of really\ngoing into the real world",
    "start": "3567490",
    "end": "3573210"
  },
  {
    "text": "as we speak. And I don't think\nacademics are any more debating whether to use it.",
    "start": "3573210",
    "end": "3578529"
  },
  {
    "text": "The question is how to use it\nin a way that still satisfies",
    "start": "3578530",
    "end": "3583590"
  },
  {
    "text": "some of the requirements you\nhave for traditional methods. If you have certain\nchecks and balances",
    "start": "3583590",
    "end": "3588990"
  },
  {
    "text": "to say the traditional\nsimulations are doing well, we want AI to more\nthan satisfy it.",
    "start": "3588990",
    "end": "3594930"
  },
  {
    "text": "If it fails those,\nthen it's not good. So you still want\nthat, but do better than what's been done before.",
    "start": "3594930",
    "end": "3603120"
  },
  {
    "text": "Yeah. How much does the quality of\ndata that's put into the models matter and how do you ensure the\nquality of it across the world?",
    "start": "3603120",
    "end": "3613740"
  },
  {
    "text": "Yeah. No, that's a great question. And in a way, we are in a better\nworld than language models.",
    "start": "3613740",
    "end": "3619340"
  },
  {
    "text": "Language models, you're\njust beholden to whatever is on the internet. You try your best to\ncure it, and you've",
    "start": "3619340",
    "end": "3624440"
  },
  {
    "text": "seen over time models that have\ndone better data curation, even small models have gotten to\na very good result, including",
    "start": "3624440",
    "end": "3631760"
  },
  {
    "text": "the Microsoft phi\nmodel, the phi series. And so data quality\ncertainly matters.",
    "start": "3631760",
    "end": "3638160"
  },
  {
    "text": "But here, we're talking about\ncurated data in lots of ways. So the Biobank for\nthe genomic data--",
    "start": "3638160",
    "end": "3645350"
  },
  {
    "text": "these are scientists\ncarefully curating it. Even the protein\nfolding was successful",
    "start": "3645350",
    "end": "3650420"
  },
  {
    "text": "because it's scientists over\ndecades carefully creating that database. The weather data, all\nthe historical data",
    "start": "3650420",
    "end": "3657230"
  },
  {
    "text": "that is taken from\nthe satellites, but further what\nwe call reanalysis. So it's further using the models\nof physics to complete the grid",
    "start": "3657230",
    "end": "3666269"
  },
  {
    "text": "and remove the certain biases\nbecause satellites are not uniform coverage.",
    "start": "3666270",
    "end": "3673990"
  },
  {
    "text": "And of course, any kind of other\nsimulation like fluid dynamics and so, you can generate from\nexisting numerical solvers.",
    "start": "3673990",
    "end": "3681010"
  },
  {
    "text": "So we are in a better world\nbecause even though it's smaller data, it's\nvery carefully",
    "start": "3681010",
    "end": "3686220"
  },
  {
    "text": "curated, cleaned up data,\nhaving experimental validations. For the weather models,\nall of this data",
    "start": "3686220",
    "end": "3693000"
  },
  {
    "text": "has been carefully checked with\nactual real world predictions. So any change you're making\nthere requires a lot of thought.",
    "start": "3693000",
    "end": "3702400"
  },
  {
    "text": "And so we are in this better\nworld with small data, but much higher quality data.",
    "start": "3702400",
    "end": "3708900"
  },
  {
    "text": "And we also have lots of\nphysics in different ways that we can use and\nbe creative about it.",
    "start": "3708900",
    "end": "3714510"
  },
  {
    "text": "Yeah. I'm a senior majoring\nin political science. I'm curious, as we see the\nnext generation of GPT 5,",
    "start": "3714510",
    "end": "3722849"
  },
  {
    "text": "GPT 6, what do you\nthink are going to be the next type\nof frontier problems that we're going to be able to\nsolve that we current aren't",
    "start": "3722850",
    "end": "3731420"
  },
  {
    "text": "able to? Well, agents. So it's very clear\nthey're doing agents and there's also some online\nchatter about a new model",
    "start": "3731420",
    "end": "3738770"
  },
  {
    "text": "and how that's able to\ndo more reasoning and-- And Q star. Yeah.",
    "start": "3738770",
    "end": "3743960"
  },
  {
    "text": "Well, the GPT 2 [INAUDIBLE]. They call it GPT 2.",
    "start": "3743960",
    "end": "3750530"
  },
  {
    "text": "Yeah, I thought that\nwas kind of a joke, no? But it does solve\nsome of the problems,",
    "start": "3750530",
    "end": "3755820"
  },
  {
    "text": "like a Math Olympiad\nproblem it was able to solve that none of the\nprevious models were able to do. OK, well, we'll see.",
    "start": "3755820",
    "end": "3761730"
  },
  {
    "text": "Yeah. We'll see. I'm not speculating. But Yann LeCun was saying\nthat they were just",
    "start": "3761730",
    "end": "3768290"
  },
  {
    "text": "memorizing some of those. I mean Yann LeCun is skeptical. And many times, he's correct.",
    "start": "3768290",
    "end": "3773880"
  },
  {
    "text": "So again, I'm not-- We'll find out soon. I'm just repeating the gossip\nwithout making a judgment",
    "start": "3773880",
    "end": "3779630"
  },
  {
    "text": "on those. I don't disagree with the\ntwo trends, the agentic and then reasoning and stuff.",
    "start": "3779630",
    "end": "3784769"
  },
  {
    "text": "Yeah, I don't know about GPT 2. Yeah, right now, it's no longer\nabout a lot of additional data,",
    "start": "3784770",
    "end": "3790410"
  },
  {
    "text": "but really this repeated\ninteraction and alignment. So you can try to\nreinforce the model",
    "start": "3790410",
    "end": "3797119"
  },
  {
    "text": "to do better on certain tasks by\nlooking at repeated interactions and giving a reward\nfunction that you want",
    "start": "3797120",
    "end": "3804470"
  },
  {
    "text": "to solve Math Olympiad\nproblem in the very end that has a lot of steps. So it's no longer\njust trying to make",
    "start": "3804470",
    "end": "3810890"
  },
  {
    "text": "one step of your\ninteraction to be good, but do it over a\nmuch longer range.",
    "start": "3810890",
    "end": "3817160"
  },
  {
    "text": "And that's computationally\nvery expensive, but OpenAI has compute. So [INAUDIBLE]",
    "start": "3817160",
    "end": "3823700"
  },
  {
    "text": "There's this question\nabout data and theory because it's very fundamental\nto everything you're doing.",
    "start": "3823700",
    "end": "3829050"
  },
  {
    "text": "And we talked about a little\nbit before we came down. So Rich Sutton has this\nbitter lesson, a simple idea",
    "start": "3829050",
    "end": "3834740"
  },
  {
    "text": "that more and more data. And I saw Andre\nKarpathy and we were talking about how\nTesla was getting rid",
    "start": "3834740",
    "end": "3842000"
  },
  {
    "text": "of hundreds of thousands or\nmillions of lines of code, replacing it with\nmachine learning. And I think you and\nI were talking about,",
    "start": "3842000",
    "end": "3849080"
  },
  {
    "text": "in language models,\nhow they used to have rules of grammar\nthat were very important, Chris Manning and others had.",
    "start": "3849080",
    "end": "3855470"
  },
  {
    "text": "And now it's just statistical. Yeah so that's all in\none direction there.",
    "start": "3855470",
    "end": "3861119"
  },
  {
    "text": "But it's more\ncomplicated than that because you're showing\nthat if you add some theory and sometimes put some\nconstraints on it,",
    "start": "3861120",
    "end": "3869155"
  },
  {
    "text": "then you can work with much\nsmaller amounts of data and get reasoning. Can you say a little\nbit more about that? Is there a broad arc to just\nmore and more data and less",
    "start": "3869155",
    "end": "3877550"
  },
  {
    "text": "theory, or what's going\nin the other direction and how should we think\nabout those trade offs?",
    "start": "3877550",
    "end": "3882750"
  },
  {
    "text": "So I would say that need to\nbe very creative and nuanced in terms of adding theory or\nstructure into the models.",
    "start": "3882750",
    "end": "3890750"
  },
  {
    "text": "So it cannot be done in a\nvery rigid way that limits the expressivity of the model\nor the ability of the model",
    "start": "3890750",
    "end": "3897630"
  },
  {
    "text": "to really learn better\nfeatures based on data. So the thing is if\nyou have enough data,",
    "start": "3897630",
    "end": "3904299"
  },
  {
    "text": "always go with data. It should never be at\nthe expense of data, you impose some structure.",
    "start": "3904300",
    "end": "3909790"
  },
  {
    "text": "And that's where I think a\nlot of the previous failures were, because in language, yes,\nyou can try to do a syntax tree,",
    "start": "3909790",
    "end": "3916540"
  },
  {
    "text": "but it's not always perfect. Especially on the\ninternet, people use language in all kinds\nof grammatically bad ways.",
    "start": "3916540",
    "end": "3924310"
  },
  {
    "text": "So you don't have a rule\nthat is perfectly matched. And also, if you impose this,\nthe optimization landscape",
    "start": "3924310",
    "end": "3930420"
  },
  {
    "text": "can become much harder. So even if it's perfectly\ncorrect for a certain domain,",
    "start": "3930420",
    "end": "3935440"
  },
  {
    "text": "you cannot learn it because\nyou've imposed a condition that is too harsh. And same with our models.",
    "start": "3935440",
    "end": "3941260"
  },
  {
    "text": "The thing is, we\nhave the flexibility. It's similar to a\ntransformer, but put into now a continuous domain.",
    "start": "3941260",
    "end": "3947250"
  },
  {
    "text": "So it can learn anything. If it's given enough\ndata, you don't need to add any further structure.",
    "start": "3947250",
    "end": "3952619"
  },
  {
    "text": "But because the data is\nlimited, adding the structure that kind of aids the data.",
    "start": "3952620",
    "end": "3958260"
  },
  {
    "text": "It's complementary to the\ndata and still can learn well. I think that's why it's a\nlittle bit more of an art",
    "start": "3958260",
    "end": "3964930"
  },
  {
    "text": "and you have to be careful. So most of the time, we\njust start with data. In fact, the examples of\nweather, we only use data.",
    "start": "3964930",
    "end": "3973680"
  },
  {
    "text": "The only nature of physics\nwas assuming it's a sphere and making that constraint.",
    "start": "3973680",
    "end": "3980079"
  },
  {
    "text": "We never carefully\nwent and tried to do a conservation\nlaw of physics or where the temperature,\nhow does that move.",
    "start": "3980080",
    "end": "3986980"
  },
  {
    "text": "We never-- There's a little bit of-- when you're describing\nthe satellite data, I guess they're\nusing some physics to fill in some of the\ngaps and smooth things.",
    "start": "3986980",
    "end": "3993460"
  },
  {
    "text": "So even maybe in\ncurating the data-- Exactly. But it's implicit. We are not explicitly\nsaying you should always--",
    "start": "3993460",
    "end": "4000350"
  },
  {
    "text": "and explicitly imposing,\nthat is the hard part, because optimization gets\nharder if you say no--",
    "start": "4000350",
    "end": "4006088"
  },
  {
    "text": "But if when you get the data,\nthere's some kind of data point that just doesn't\nmake any sense? Does your model try to smooth\nthat over or does it try to--",
    "start": "4006088",
    "end": "4015066"
  },
  {
    "text": "That's with any deep learning. If it's only one data point, it\nusually tends to get ignored. If it's enough data points, it\ntries to pick up the structure.",
    "start": "4015066",
    "end": "4023705"
  },
  {
    "text": "And that's why if you\nthink about hurricanes, it's quite anomalous. You have this hot and cold\nair mixing in a weird way.",
    "start": "4023705",
    "end": "4031039"
  },
  {
    "text": "That's not normal condition. But there's still enough\nof those signatures, even if it's a few of them.",
    "start": "4031040",
    "end": "4036640"
  },
  {
    "text": "It's interesting and different\nenough that it picks it up because the model\nhas the flexibility.",
    "start": "4036640",
    "end": "4042680"
  },
  {
    "text": "We are not\nconstraining the model to be rigid enough only\nto have smooth air flow.",
    "start": "4042680",
    "end": "4049310"
  },
  {
    "text": "We are allowing it\nto capture that. And the other thing,\nwhen you're talking about the DNA, the viruses,\nand the protein folding,",
    "start": "4049310",
    "end": "4058690"
  },
  {
    "text": "I mean, there's really\nseveral different theories there about predicting\nthe next word, but also going from the sequence\nto the structure of the protein",
    "start": "4058690",
    "end": "4067120"
  },
  {
    "text": "and how that folds, and then\nultimately to its function",
    "start": "4067120",
    "end": "4072340"
  },
  {
    "text": "And each of those steps, you're\nkind of chaining them together to get-- that's related to\nthe agentic realism.",
    "start": "4072340",
    "end": "4079910"
  },
  {
    "text": "But having a bunch\nof these systems connected together that\neach feed to the next one,",
    "start": "4079910",
    "end": "4085988"
  },
  {
    "text": "is that what we're going to\nbe seeing more and more of? Exactly. And in fact, that's what we did\nin the follow up work to that",
    "start": "4085988",
    "end": "4092040"
  },
  {
    "text": "where now you can\ngive reward function instead of the human feedback. For language models, you\ncan ask a human thumbs up",
    "start": "4092040",
    "end": "4098600"
  },
  {
    "text": "or thumbs down, did it produce\nsomething that you liked or not. And that's how you [INAUDIBLE].",
    "start": "4098600",
    "end": "4104149"
  },
  {
    "text": "And now instead,\nthe reward function here is, does it bind well,\ngive me something, for instance,",
    "start": "4104149",
    "end": "4109920"
  },
  {
    "text": "based on molecular\nbinding simulation is having a certain binding\nfunctionality or does it fold.",
    "start": "4109920",
    "end": "4115649"
  },
  {
    "text": "Well, we don't want\ndisordered proteins. We want ones with\ngood structure. So all of this you can give as\nreward functions and you can",
    "start": "4115649",
    "end": "4123350"
  },
  {
    "text": "do reinforcement\nlearning or what we also call direct preference\noptimization, which was actually",
    "start": "4123350",
    "end": "4129229"
  },
  {
    "text": "developed here at Stanford. So these techniques,\nwe can now use and we can train both models\nthat produce discrete sequences",
    "start": "4129229",
    "end": "4138380"
  },
  {
    "text": "with models that\nhave predictions in the continuous realm\nlike binding, for instance,",
    "start": "4138380",
    "end": "4143750"
  },
  {
    "text": "and bring all that as AI\nmodels, make it fast, but also have the ability to\ndifferentiate through that",
    "start": "4143750",
    "end": "4150560"
  },
  {
    "text": "and come up with ultimately\ngood functional proteins, which is what is a huge\nimpact in real world.",
    "start": "4150560",
    "end": "4157290"
  },
  {
    "text": "Great. Let me just like-- I'll just maybe-- there\nare other use cases.",
    "start": "4157290",
    "end": "4164630"
  },
  {
    "text": "So this is carbon\ndioxide storage. I won't get into the\ndetails other than to say",
    "start": "4164630",
    "end": "4169670"
  },
  {
    "text": "you can simulate\nif I pump carbon dioxide to these\nunderground wells,",
    "start": "4169670",
    "end": "4174750"
  },
  {
    "text": "how do I measure the\npressure build up, how do I predict how the carbon\ndioxide, where it's going to go",
    "start": "4174750",
    "end": "4181220"
  },
  {
    "text": "over several decades, will it\nstay within the well or will it just diffuse off and go back\nto that sphere, in which case,",
    "start": "4181220",
    "end": "4187950"
  },
  {
    "text": "we don't want to be doing this. So it's helping us plan\nfor a net zero future.",
    "start": "4187950",
    "end": "4193020"
  },
  {
    "text": "And again, work done with\ncollaboration here at Stanford with Sally Benson's group.",
    "start": "4193020",
    "end": "4198869"
  },
  {
    "text": "I know I keep coming\nback to Stanford in many of these works, which is great. A lot of great\ncollaborators here.",
    "start": "4198870",
    "end": "4205789"
  },
  {
    "text": "And yeah, so many domains. Material deformation, nuclear\nfusion had mentioned earlier.",
    "start": "4205790",
    "end": "4212699"
  },
  {
    "text": "This is like in\nthe tokamak, how do I predict how the\nplasma is going to evolve, where is it\ngoing to be concentrated,",
    "start": "4212700",
    "end": "4220409"
  },
  {
    "text": "will it try to escape. I can look at the\ncamera data as well as the magnetohydrodynamic\nsimulations.",
    "start": "4220410",
    "end": "4226580"
  },
  {
    "text": "Imaging-- so imaging, you want\nto look at an inverse problem.",
    "start": "4226580",
    "end": "4232320"
  },
  {
    "text": "You look at just waves that\ncome out at the sensor. But what you want is what\nis inside the human body.",
    "start": "4232320",
    "end": "4239159"
  },
  {
    "text": "So these are inverse problems\nthat you can do much faster. So the other thing I\njust want to emphasize",
    "start": "4239160",
    "end": "4245630"
  },
  {
    "text": "is not just trying to think\nabout simulation or prediction, but inverse design.",
    "start": "4245630",
    "end": "4251330"
  },
  {
    "text": "Can I generate better designs? So if you ask DALL-E or\nany kind of image model",
    "start": "4251330",
    "end": "4257090"
  },
  {
    "text": "to draw an aircraft or a\ndrone, it draws something, but probably meaningless, you\ncan't go physically manufacture",
    "start": "4257090",
    "end": "4264440"
  },
  {
    "text": "and do anything with it. So here, I've\nshown two examples. One is a medical catheter\nthat we designed at Caltech.",
    "start": "4264440",
    "end": "4272100"
  },
  {
    "text": "And the idea is in a\nstandard medical catheter, it's just a tube that draws\nfluids out of the human body.",
    "start": "4272100",
    "end": "4279710"
  },
  {
    "text": "But the bacteria tend to\nswim upstream near the wall because there is less\nvelocity of the fluid",
    "start": "4279710",
    "end": "4286100"
  },
  {
    "text": "and it tends to\ninfect the human. In fact, more than half a\nmillion cases of these health",
    "start": "4286100",
    "end": "4291320"
  },
  {
    "text": "care related infections,\nthe top one in a hospital-- so if you're long enough in\na hospital, unfortunately,",
    "start": "4291320",
    "end": "4297180"
  },
  {
    "text": "you tend to get infected. And so we had a\nvery simple idea, which was to build these ridges\nor triangular shapes within",
    "start": "4297180",
    "end": "4305150"
  },
  {
    "text": "the catheter, very tiny,\nsomething you can 3D print, but optimize for\nthe shape of it.",
    "start": "4305150",
    "end": "4310889"
  },
  {
    "text": "And what is the intuition? With these triangular\nshapes, what you can create are vertices. So the fluid, because\nof this sharp shape,",
    "start": "4310890",
    "end": "4319869"
  },
  {
    "text": "it kind of becomes a vortex. And then the bacteria is not\nable to swim upstream because of that disruption.",
    "start": "4319870",
    "end": "4326199"
  },
  {
    "text": "And what you see is the 3D\nprinted version of the catheter down below where the particles\nthat are moving in the fluid",
    "start": "4326200",
    "end": "4333240"
  },
  {
    "text": "flow means they're not able\nto swim against the fluid. So they're not able to\ngo into the human body.",
    "start": "4333240",
    "end": "4338980"
  },
  {
    "text": "And we measured 100-fold\nreduction in bacterial contamination. And now it's in clinical study,\nvery fast amount of time.",
    "start": "4338980",
    "end": "4347530"
  },
  {
    "text": "The AI proposed a design. We 3D printed it just\nonce, and it worked.",
    "start": "4347530",
    "end": "4353409"
  },
  {
    "text": "And to me, that's the\nmessage I want to give. A lot of the experimentation\ncould be potentially removed",
    "start": "4353410",
    "end": "4360180"
  },
  {
    "text": "with the use of AI. And of course, there's\nalways uncertainty. If you cannot model very well,\nyou would need the physical",
    "start": "4360180",
    "end": "4366989"
  },
  {
    "text": "experimentation. But you can further adapt\nyour model based on that and make it\nprogressively better.",
    "start": "4366990",
    "end": "4373690"
  },
  {
    "text": "So you can hopefully do less\nand less experiments in the lab and do it much faster\nwith the use of AI.",
    "start": "4373690",
    "end": "4380826"
  },
  {
    "text": "I mean, this is an early example\nof just a complete revolution that's going to\nhappen where we just make these fantastical images of\nhouses and bridges and catheters",
    "start": "4380827",
    "end": "4389320"
  },
  {
    "text": "or whatever that are\nvery pretty or creative, but ones that actually\nwork, that don't fall down,",
    "start": "4389320",
    "end": "4394880"
  },
  {
    "text": "that have functionality. You bring them to\nthe physical world. And then you can print them. You can create them.",
    "start": "4394880",
    "end": "4399980"
  },
  {
    "text": "Yeah, and so start making the\nmachines that actually work. Yeah. Yeah. And the other quick\nexample of that",
    "start": "4399980",
    "end": "4405460"
  },
  {
    "text": "is optimizing for mask\ndesign in lithography, which is in chip manufacturing.",
    "start": "4405460",
    "end": "4411500"
  },
  {
    "text": "Again, very important part\nof especially the latest GPUs as you go to smaller\nscales aspect of physics,",
    "start": "4411500",
    "end": "4421580"
  },
  {
    "text": "the diffraction effects\nbecome so critical, you have to get the\nright mask design. I won't get into it.",
    "start": "4421580",
    "end": "4427220"
  },
  {
    "text": "But again, this is an inverse\nproblem that can be done. But yeah, where\ndoes all this lead?",
    "start": "4427220",
    "end": "4433700"
  },
  {
    "text": "So far, I talked about lots\nof use cases of science. And mostly, I\ntalked about models",
    "start": "4433700",
    "end": "4439930"
  },
  {
    "text": "that learns on specific\ndata of a specific domain. But ultimately, what we\nare thinking about now",
    "start": "4439930",
    "end": "4447219"
  },
  {
    "text": "is a model that could one day\nunderstand all of science. In a way, you could say ChatGPT\nunderstands all of science",
    "start": "4447220",
    "end": "4454720"
  },
  {
    "text": "because it has read\nall kinds of textbooks. If you ask it question\nin any domain of science,",
    "start": "4454720",
    "end": "4459980"
  },
  {
    "text": "it does a decent job. If you ask it to\ndesign a molecule, it could even do some of it.",
    "start": "4459980",
    "end": "4464990"
  },
  {
    "text": "In fact, we did that for some\nof the direct air capture. It does some suggestions\nof linker molecules.",
    "start": "4464990",
    "end": "4472070"
  },
  {
    "text": "But on the other hand, if you\nask it to actually simulate and predict if the molecule is\ngoing to bind in a certain way",
    "start": "4472070",
    "end": "4481480"
  },
  {
    "text": "or what would be the\nweather tomorrow, it can't internally\nsimulate the physics. And if you look at models like\nSora, it learns lots of videos,",
    "start": "4481480",
    "end": "4490010"
  },
  {
    "text": "but physics is\nalmost an accident. Whatever video showed\nphysics, it kind of learns it.",
    "start": "4490010",
    "end": "4495500"
  },
  {
    "text": "But can you ground all of\nthem with physics itself in a direct way? And that's where now we've\ntrained roughly a GPT 2",
    "start": "4495500",
    "end": "4504490"
  },
  {
    "text": "sized model, which\ninvolves now training on multiple different\nkinds of physics--",
    "start": "4504490",
    "end": "4510520"
  },
  {
    "text": "fluids, wave\nequations, material. So think of a model that now\nlearns to simulate and design",
    "start": "4510520",
    "end": "4517720"
  },
  {
    "text": "on many such phenomena. And not just a simple\nkind of physics, but one that could be even multiphysics.",
    "start": "4517720",
    "end": "4523670"
  },
  {
    "text": "And if you're now\nthinking of an aircraft, it can be both looking\nat aerodynamics,",
    "start": "4523670",
    "end": "4529550"
  },
  {
    "text": "but maybe you also don't want\nit to be having a lot of sound. And it's also the\nmaterial stretching.",
    "start": "4529550",
    "end": "4534889"
  },
  {
    "text": "If it's high\ntemperatures, you don't want the materials to stretch. In the real world, physics is\nnot isolated into one equation.",
    "start": "4534890",
    "end": "4542300"
  },
  {
    "text": "It's lots of\nequations to describe something very complicated. And weather is one such example,\nit's highly multiphysics.",
    "start": "4542300",
    "end": "4549139"
  },
  {
    "text": "You're not just defining it with\na very compact simple equation. And so ultimately,\ncan we have a model",
    "start": "4549140",
    "end": "4555700"
  },
  {
    "text": "that can learn over lots of\nsuch coupled physical phenomena and get to a better physical\nfoundation for all of AI.",
    "start": "4555700",
    "end": "4565570"
  },
  {
    "text": "So to me, I think that\nthat's an exciting future. That is very exciting. Well, thank you\nvery much, Anima. Thank you.",
    "start": "4565570",
    "end": "4570780"
  },
  {
    "text": "Thank you. [APPLAUSE] ",
    "start": "4570780",
    "end": "4577000"
  }
]
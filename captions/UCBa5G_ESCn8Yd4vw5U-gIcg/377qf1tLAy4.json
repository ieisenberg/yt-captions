[
  {
    "start": "0",
    "end": "9810"
  },
  {
    "text": "Thank you for inviting me and,\nyeah, generous introduction.",
    "start": "9810",
    "end": "14850"
  },
  {
    "text": " I totally agree. It's been so fun to work\non that project together.",
    "start": "14850",
    "end": "21189"
  },
  {
    "text": "And I think, part of what\nled to that was really",
    "start": "21190",
    "end": "27510"
  },
  {
    "text": "the interest in this area\nfrom an undergraduate student at Northwestern,\nCarolyn Zou, who",
    "start": "27510",
    "end": "34680"
  },
  {
    "text": "is now incoming\ndoctoral student here in the Stanford HCI program.",
    "start": "34680",
    "end": "40860"
  },
  {
    "text": "And actually, this work\nfeatures a lot of stuff that emerged through\ntheir honors thesis work",
    "start": "40860",
    "end": "49829"
  },
  {
    "text": "at Northwestern. So I implicated\nthem in the talk. I don't think they're going\nto be joining us for the talk",
    "start": "49830",
    "end": "57000"
  },
  {
    "text": "today. They are sleeping off\nan overnight flight after coming back from Kai.",
    "start": "57000",
    "end": "62489"
  },
  {
    "text": "But this really builds off of\nand extends a lot of the stuff that they developed in\ntheir honors thesis.",
    "start": "62490",
    "end": "68940"
  },
  {
    "text": "And that's really brought\nme into this space in a way that I really appreciate.",
    "start": "68940",
    "end": "74539"
  },
  {
    "text": "So thanks to Carolyn for that. Also, Michael mentioned my\ncolleague, Benjamin Mako Hill,",
    "start": "74540",
    "end": "80650"
  },
  {
    "text": "at the University of Washington. Mako also contributed\nsome funding support through an REU supplement to\nan NSF award that supported",
    "start": "80650",
    "end": "90138"
  },
  {
    "text": "some of Carolyn's work on this. So I want to acknowledge that. And this work has been\nheavily, heavily influenced",
    "start": "90138",
    "end": "95680"
  },
  {
    "text": "by the work going on through\nthat I'm collaborating on with Michael, which is\nbeing led by June Park here",
    "start": "95680",
    "end": "103870"
  },
  {
    "text": "and involves a number\nof other folks. But now that I've\nthanked all those people,",
    "start": "103870",
    "end": "109120"
  },
  {
    "text": "I want to withdraw any\nresponsibility from them for what follows and just\nany errors of judgment,",
    "start": "109120",
    "end": "117040"
  },
  {
    "text": "or mistakes, or things\nlike that, or mine. In part, because this is\npretty new work so, like,",
    "start": "117040",
    "end": "124450"
  },
  {
    "text": "hot off the presses\nresults that we're still figuring out what to do with. And so I'm really\nlooking forward",
    "start": "124450",
    "end": "130210"
  },
  {
    "text": "to feedback and\nquestions because it all turns into grist for the\nmill for, what do I do next?",
    "start": "130210",
    "end": "136790"
  },
  {
    "text": "And so apologies\nin advance if it's very rough, if it's\nvery unpolished, if I don't know what\nI'm talking about.",
    "start": "136790",
    "end": "143290"
  },
  {
    "text": "I actually love\ngiving talks like that because it means it's sort\nof live problems for me. And I can enlist you as\ncollaborators and conspirators",
    "start": "143290",
    "end": "151780"
  },
  {
    "text": "along the way. So with that, Michael\nmentioned our lab group. So I don't have to say\na lot more about that.",
    "start": "151780",
    "end": "158650"
  },
  {
    "text": "But I did just\nwant to mention it as context because\na lot of our work",
    "start": "158650",
    "end": "164739"
  },
  {
    "text": "does not look like\nthe stuff that I'm going to talk about today. And one member of the lab who's\nimplicated in that picture",
    "start": "164740",
    "end": "171430"
  },
  {
    "text": "is also here today. So, John [? Huang. ?] But there's a thread that runs\nthrough some of the stuff that I",
    "start": "171430",
    "end": "178840"
  },
  {
    "text": "think Michael mentioned that\nwas work initially in crowd work and crowd-sourcing platforms\na while ago where--",
    "start": "178840",
    "end": "188260"
  },
  {
    "text": "that connects to\nwhat this is about and that connects to some\nother work in the lab group. And if you want to learn\nmore about the lab group,",
    "start": "188260",
    "end": "195243"
  },
  {
    "text": "that's our URL at\nthe top of the slide. And I'll put it up,\nagain, at the end. And we're always\ninterested to hear",
    "start": "195243",
    "end": "200650"
  },
  {
    "text": "from folks who are\ninterested in learning more about what we're doing. So please get in touch. But the thread that runs\nthrough from some prior work",
    "start": "200650",
    "end": "207040"
  },
  {
    "text": "was really trying\nto understand-- think about\ncrowd-sourcing workers as a potential data source,\nor sample, or population",
    "start": "207040",
    "end": "216410"
  },
  {
    "text": "within which social scientific\nresearch could be conducted. Today, now in 2024, that\nsounds arcane and archaic",
    "start": "216410",
    "end": "226609"
  },
  {
    "text": "because it's basically-- one,\nit's not clear that things like Mechanical Turk and other crowd\nwork platforms are going to be--",
    "start": "226610",
    "end": "235670"
  },
  {
    "text": "survive the transition to\ngenerative AI systems very well. I can talk more about\nthat later if you want.",
    "start": "235670",
    "end": "242690"
  },
  {
    "text": "But B, because there was\na lot of early research that basically established ways\nof thinking about sampling bias,",
    "start": "242690",
    "end": "251360"
  },
  {
    "text": "adjustments, validity, and\ninference techniques that could",
    "start": "251360",
    "end": "256640"
  },
  {
    "text": "help resolve some of the\nvariations between crowd work samples for social\nscientific insights,",
    "start": "256640",
    "end": "263180"
  },
  {
    "text": "and other kinds of\nsamples, and populations that you might want to draw. So this is an HCI course.",
    "start": "263180",
    "end": "269427"
  },
  {
    "text": "So before I start talking too\nmuch about samples and sampling, I should just preface that by\nsaying, for social scientists--",
    "start": "269427",
    "end": "275310"
  },
  {
    "text": "and there's a big part\nof my training and brain that's oriented towards\nthe social sciences.",
    "start": "275310",
    "end": "281370"
  },
  {
    "text": "A major concern about\ndeveloping and testing theories and\nunderstanding behavior is thinking about who you're\nconducting the tests among",
    "start": "281370",
    "end": "289949"
  },
  {
    "text": "or what population you're\ntrying to talk about. If I'm interested in\nsaying humans do something",
    "start": "289950",
    "end": "297960"
  },
  {
    "text": "in a certain way,\nwell, in theory, I have to evaluate that in\nsome way that can generalize",
    "start": "297960",
    "end": "303780"
  },
  {
    "text": "from the sample of\npeople I talk about or I conduct the study on to\nthe bigger population of humans",
    "start": "303780",
    "end": "309220"
  },
  {
    "text": "writ large. In the work that I\ndo, it's very rare that I'm actually interested in\ntrying to generalize to humans.",
    "start": "309220",
    "end": "316830"
  },
  {
    "text": "Oftentimes, I'm\ndoing work that's more interested in specific\nkinds of online community contexts or online platforms.",
    "start": "316830",
    "end": "322950"
  },
  {
    "text": "But it's still important\nto understand the biases and variations that\nmay distinguish",
    "start": "322950",
    "end": "328350"
  },
  {
    "text": "the groups in those\nsettings from other parts of the population,\nwhether that's",
    "start": "328350",
    "end": "333570"
  },
  {
    "text": "for the purposes of\nunderstanding who's there and who's not. Things like participation\ngaps and digital inequalities,",
    "start": "333570",
    "end": "340020"
  },
  {
    "text": "or if it's for the purposes\nof understanding what's driving the selection in or\nout of those environments.",
    "start": "340020",
    "end": "350160"
  },
  {
    "text": "So that's all context.  This particular project is\nreally trying to understand how",
    "start": "350160",
    "end": "359430"
  },
  {
    "text": "LLMs may be used to advance\nsocial scientific inquiry, and to [? under-simulate ?] and\nunderstand human behavior more",
    "start": "359430",
    "end": "367289"
  },
  {
    "text": "broadly. So the question is really not-- at this point, I think\nwe're in the early days",
    "start": "367290",
    "end": "372360"
  },
  {
    "text": "of this area of research. There's been a\nrapid flurry of work that I'll talk a little bit\nabout in a moment that's still",
    "start": "372360",
    "end": "380740"
  },
  {
    "text": "probing and trying to\nfigure out what's going on and how to use generative models\nto understand human behavior",
    "start": "380740",
    "end": "387360"
  },
  {
    "text": "and simulate human\nbehavior more effectively, and to do so in ways\nthat can be applied",
    "start": "387360",
    "end": "392640"
  },
  {
    "text": "to behavioral sciences,\nsocial sciences, and a variety of other domains. But this is an active\ndesign challenge",
    "start": "392640",
    "end": "400740"
  },
  {
    "text": "and an inference challenge. So the inference\nchallenge is more of that social science concern I\nwas talking about a minute ago.",
    "start": "400740",
    "end": "407330"
  },
  {
    "text": "Social scientists\nwant to understand, what are the problems\nwith this kind of-- how do you generalize from\nrobots to human populations",
    "start": "407330",
    "end": "416040"
  },
  {
    "text": "or samples? But it's a design challenge too. Because a lot of the\nmodels and the interfaces for interacting\nwith them are not",
    "start": "416040",
    "end": "422520"
  },
  {
    "text": "set up to support this\nparticular use case. And the tooling,\nor the standards,",
    "start": "422520",
    "end": "428100"
  },
  {
    "text": "or norms around how\nto do that effectively are not established at all. This is not the world\nof running experiments",
    "start": "428100",
    "end": "434190"
  },
  {
    "text": "on Mechanical Turk, or\nProlific, or whatever your favorite online\nsampling system is. This is a very new domain.",
    "start": "434190",
    "end": "441810"
  },
  {
    "text": "So it's that challenge that\nI want to try to focus on. And that's the\nsetting for this work.",
    "start": "441810",
    "end": "447990"
  },
  {
    "text": "So as I mentioned, there's a\nreally rapidly growing area of work in this space. And I think it was inspired\nand provoked in part by work",
    "start": "447990",
    "end": "458160"
  },
  {
    "text": "like this, which at least,\nI'll speak for myself here. Personally when I\nread this paper,",
    "start": "458160",
    "end": "465750"
  },
  {
    "text": "my collaborators-- and\nI got very excited. Because we were like, whoa,\nwe could test theories",
    "start": "465750",
    "end": "471479"
  },
  {
    "text": "about social interactions\nand individual level behavior and emergent collective behavior\nin these kinds of AI systems",
    "start": "471480",
    "end": "480270"
  },
  {
    "text": "that we might not be able to\nevaluate among real live people.",
    "start": "480270",
    "end": "486330"
  },
  {
    "text": "So as is often the case, we were\njumping about 30 steps ahead",
    "start": "486330",
    "end": "491370"
  },
  {
    "text": "of what was reasonably\npossible at the time. But since then, this has\nmoved on in various ways.",
    "start": "491370",
    "end": "498210"
  },
  {
    "text": "And some other folks have made\nsome really wonderful steps in the direction of evaluating\nwhat generative agents",
    "start": "498210",
    "end": "507690"
  },
  {
    "text": "and generative models\ncan simulate effectively of human behavior. This is a working paper\nthat John Horton put out",
    "start": "507690",
    "end": "514370"
  },
  {
    "text": "a little over a year ago now. But there have been more. And a number of them have been\npublished in various places.",
    "start": "514370",
    "end": "522500"
  },
  {
    "text": "And at this point, there's\nquite a lot of stuff. And most of the papers,\nyou can certainly",
    "start": "522500",
    "end": "528425"
  },
  {
    "text": "notice there's something funny\nabout this paper, which is very common in a lot of these. And it's this question mark.",
    "start": "528425",
    "end": "533462"
  },
  {
    "text": "A lot of the papers still have\nquestion marks in the title. Like, can we do this\nwith generative AI?",
    "start": "533462",
    "end": "539000"
  },
  {
    "text": "Will it work. How well does it work? They don't know. They're being polite. They're beating around the bush. They all think it\ncan work, otherwise,",
    "start": "539000",
    "end": "544699"
  },
  {
    "text": "they wouldn't be investing\nall the effort that they are in trying to get it to go. But what I think it\nindicates is that there's",
    "start": "544700",
    "end": "551450"
  },
  {
    "text": "a lot of excitement among social\nscientists to become end-- a distinct subset of\nend users of AI systems.",
    "start": "551450",
    "end": "559400"
  },
  {
    "text": "And what a lot of\nthis work is doing is probing with different kinds\nof replication strategies.",
    "start": "559400",
    "end": "567279"
  },
  {
    "text": "Can I reproduce social\nscientific findings or benchmark the performance\nof various prompting strategies",
    "start": "567280",
    "end": "574379"
  },
  {
    "text": "with generative AI systems\nagainst human behavior from various kinds of contexts?",
    "start": "574380",
    "end": "579852"
  },
  {
    "text": " So there's also a growing\narea of work in this space",
    "start": "579853",
    "end": "587610"
  },
  {
    "text": "that's trying to talk about\nsome of the challenges-- both the opportunities\nand the challenges,",
    "start": "587610",
    "end": "593370"
  },
  {
    "text": "being more reflective\nabout this more generally. This paper was\npublished last week",
    "start": "593370",
    "end": "599370"
  },
  {
    "text": "by Chris Bail in the\nproceedings of the National Academy of Sciences.",
    "start": "599370",
    "end": "604459"
  },
  {
    "text": "And it talks a little bit\nabout some of the concerns, and problems, and\nissues in this space. ",
    "start": "604460",
    "end": "612035"
  },
  {
    "text": "The published and pre-print\nstudies in this area are increasingly acknowledging\nthings like--",
    "start": "612035",
    "end": "617420"
  },
  {
    "text": "that they may not be able to\nreplicate even the results of what they're producing when\nthey're prompting AIs to perform",
    "start": "617420",
    "end": "623600"
  },
  {
    "text": "behavioral tasks. A lot of the\ninitial studies were run on versions of GPT\nthat are deprecated,",
    "start": "623600",
    "end": "631100"
  },
  {
    "text": "where the prompts\nweren't published alongside the initial\nstudies in ways that you could track\nthe provenance of how",
    "start": "631100",
    "end": "639740"
  },
  {
    "text": "the results were elicited. And so there are different\nkinds of lurking problems",
    "start": "639740",
    "end": "645530"
  },
  {
    "text": "in a lot of the data and a\nlot of the prompting that's been used to generate these\nearly-stage social science",
    "start": "645530",
    "end": "650990"
  },
  {
    "text": "findings. And I can trot out a\nsmall pile of examples.",
    "start": "650990",
    "end": "656240"
  },
  {
    "text": "But I think that\nthe pattern here is that there's often\nsome attempt to do some--",
    "start": "656240",
    "end": "667252"
  },
  {
    "text": "to demonstrate both that the\nfindings have validity, which",
    "start": "667252",
    "end": "674060"
  },
  {
    "text": "is the primary concern, that\nthe findings that they're getting out of the\nmodels are replicating some human benchmark.",
    "start": "674060",
    "end": "680000"
  },
  {
    "text": "As well as to say,\noh yeah, and here's what we ask the model,\nhow we ask the model. Here's some of the different\nversions that we tried.",
    "start": "680000",
    "end": "687630"
  },
  {
    "text": "So it's a bit of a\nhodgepodge at this point. But people like Chris\nBail, and Michael Frank,",
    "start": "687630",
    "end": "693740"
  },
  {
    "text": "and the psychology\ndepartment here have been very articulate\nabout some of these concerns.",
    "start": "693740",
    "end": "699547"
  },
  {
    "text": "And if you're interested\nin reading more about it, I recommend their work. ",
    "start": "699547",
    "end": "705210"
  },
  {
    "text": "And some of the studies\nthat have come out, this is one that I\nparticularly like that tries to use language\nmodels to simulate",
    "start": "705210",
    "end": "712890"
  },
  {
    "text": "human samples for public opinion\nresearch in political science,",
    "start": "712890",
    "end": "719460"
  },
  {
    "text": "led by Lisa Argyle at BYU. Some of the work\nhas really tried",
    "start": "719460",
    "end": "726180"
  },
  {
    "text": "to embrace really,\nI'll just say,",
    "start": "726180",
    "end": "734010"
  },
  {
    "text": "admirable standards of\ntransparency and reproducibility",
    "start": "734010",
    "end": "739200"
  },
  {
    "text": "and providing the prompting\nmaterials and all of the inputs that they use to generate\nthe resulting social science",
    "start": "739200",
    "end": "750030"
  },
  {
    "text": "benchmarking analyses\nthat they're performing, including things like\nmultiple versions of prompts,",
    "start": "750030",
    "end": "757740"
  },
  {
    "text": "variations of different\nways of tuning the models, or hyperparameter\nsettings that they may have configured in\nthe context of generating",
    "start": "757740",
    "end": "765689"
  },
  {
    "text": "their results. And in one case,\na couple of people",
    "start": "765690",
    "end": "771180"
  },
  {
    "text": "published a piece\nin the-- again, in the proceedings of National\nAcademy of Sciences last year that they conducted\nsome that I really",
    "start": "771180",
    "end": "777420"
  },
  {
    "text": "liked that used generative\nmodels to programmatically",
    "start": "777420",
    "end": "784440"
  },
  {
    "text": "generate out-of-memory prompts. Anyway, we can talk about\nthis a little bit later. But I think there's some\ninteresting strategies",
    "start": "784440",
    "end": "791228"
  },
  {
    "text": "that people are\npursuing in this space. But it's really the\nWild West at this point. And there's-- did\nyou have a question?",
    "start": "791228",
    "end": "796450"
  },
  {
    "text": "I do have a question. Great. I don't know if\nnow's the right-- Fair game for me. --if I'm being a little\nunfair, but I appreciate it.",
    "start": "796450",
    "end": "804950"
  },
  {
    "text": "I'm curious how\nmuch of this work focuses on the data that\nwas used to train the LLM.",
    "start": "804950",
    "end": "811070"
  },
  {
    "text": "Because that seems extremely\nimportant for any kind of generalizability.",
    "start": "811070",
    "end": "817200"
  },
  {
    "text": "Yeah, I agree completely. I think, a number of folks--\nand thinking about this piece,",
    "start": "817200",
    "end": "823040"
  },
  {
    "text": "again, a number of folks--\nso Bail and Mike Franco, I mentioned before who have--\ntheir pieces are separate.",
    "start": "823040",
    "end": "828840"
  },
  {
    "text": "I don't mean to conflate them. But they expressly advocate\nfor using open source models.",
    "start": "828840",
    "end": "836540"
  },
  {
    "text": "In part, because then\nthe inputs can at least be audited more directly. And you can try to\nunderstand biases.",
    "start": "836540",
    "end": "842630"
  },
  {
    "text": "But-- You need open source data. You need open source data. ",
    "start": "842630",
    "end": "848615"
  },
  {
    "text": "I think that these\npapers that have raised the concerns about\nit mention that,",
    "start": "848615",
    "end": "853650"
  },
  {
    "text": "but I don't think\nthat they really-- nobody's got a strong angle\non that at this point.",
    "start": "853650",
    "end": "861287"
  },
  {
    "text": "I'll come back to a piece\nof that in just a moment because I think there is\nsome work that I find really inspiring in that direction.",
    "start": "861287",
    "end": "867190"
  },
  {
    "text": "You're probably very\nfamiliar with it already. But I think a lot of\nthe social science work is taking at face value, OK,\nwe've got a generative model.",
    "start": "867190",
    "end": "877310"
  },
  {
    "text": "Let's see how well it\ncan do in replicating various kinds of human behavior\nfor various kinds of samples",
    "start": "877310",
    "end": "884860"
  },
  {
    "text": "and try to understand\nthe bias as a-- of the output rather than\nthe bias of the input.",
    "start": "884860",
    "end": "890297"
  },
  {
    "text": "Because I think there's also\nsome suggestive stuff right in here. I'm thinking of\nsome of Percy's work too, where it's\nlike, it does seem",
    "start": "890297",
    "end": "897269"
  },
  {
    "text": "to me as a total outsider\nto the field that's building the models, that\nthere's some amount of--",
    "start": "897270",
    "end": "904960"
  },
  {
    "text": "the scaling of the data input\nhas produced performance beyond a lot of\npeople's expectations.",
    "start": "904960",
    "end": "911300"
  },
  {
    "text": "So it may be that the model\ndoesn't need that much data from a very, kind of,\nwhat-- in survey research,",
    "start": "911300",
    "end": "921339"
  },
  {
    "text": "you would call it sparsely\npopulated cell, the idea that you have some\nconstellation of attributes",
    "start": "921340",
    "end": "927820"
  },
  {
    "text": "of a person that may be hard to\nfind in the regular population. If I randomly selected 2,000\npeople from the US population,",
    "start": "927820",
    "end": "936250"
  },
  {
    "text": "I would never find someone\nwith characteristic-- combination of\ncharacteristic a, b, and c.",
    "start": "936250",
    "end": "942010"
  },
  {
    "text": "But my regression model, if I'm\na social scientist using survey data, will still produce\na prediction for a person",
    "start": "942010",
    "end": "947860"
  },
  {
    "text": "with attributes a, b, and\nc, even if there was nobody like that in my data set. And it may be that the LLMs\ncan produce a prediction",
    "start": "947860",
    "end": "955850"
  },
  {
    "text": "that's a lot better than my\n2,000 person sample based prediction.",
    "start": "955850",
    "end": "961270"
  },
  {
    "text": "But the jury's\nstill out, I think. And I don't think it's an\nactive concern that people have figured out a good angle on.",
    "start": "961270",
    "end": "968470"
  },
  {
    "text": "That good to keep moving? Cool. No, I just don't want to\nforeclose further follow-up.",
    "start": "968470",
    "end": "975030"
  },
  {
    "text": "But we can follow up more. So I've said that of\nthe existing studies",
    "start": "975030",
    "end": "981282"
  },
  {
    "text": "that I'm aware of, at least\nthere are a number of them that take admirable steps\nto try to embrace",
    "start": "981282",
    "end": "988120"
  },
  {
    "text": "good standards of\nreproducible research that have emerged across the\nsocial sciences in the last 20 or 30 years.",
    "start": "988120",
    "end": "993757"
  },
  {
    "text": "I'll say a little bit more\nabout that in a moment. The thing is that the\nreasons they're doing this are because of what social\nscientists have learned",
    "start": "993757",
    "end": "1000899"
  },
  {
    "text": "about the problems that\nemerge in your research fields",
    "start": "1000900",
    "end": "1005920"
  },
  {
    "text": "if you don't do so. And for those of you\nwho've heard about things like replication crisis\nor reproducibility",
    "start": "1005920",
    "end": "1011339"
  },
  {
    "text": "crisis in social sciences,\nthat's what I'm talking about. So this is a paper\npublished back in 2005 by--",
    "start": "1011340",
    "end": "1017670"
  },
  {
    "text": "I'm not going to pronounce the\nauthor's last name correctly for fear-- they're here at the\nStanford medical school.",
    "start": "1017670",
    "end": "1024329"
  },
  {
    "text": "So I'm embarrassed to get\nit wrong but John Ioannidis. Somebody can help me out if\nyou know in the audience.",
    "start": "1024329",
    "end": "1030819"
  },
  {
    "text": "But apologies if he\nwatches the YouTube video. But this was published in 2005,\nstaking a pretty bleak but blunt",
    "start": "1030819",
    "end": "1039579"
  },
  {
    "text": "claim that most research\nfindings-- and this was about medical sciences and\nsocial sciences were false.",
    "start": "1039579",
    "end": "1048109"
  },
  {
    "text": "And it enumerated a\nnumber of problems that he argued were causing\nthis, including things",
    "start": "1048109",
    "end": "1055540"
  },
  {
    "text": "like the bias of\njournals in the sciences to publish big, spectacular,\nsplashy findings,",
    "start": "1055540",
    "end": "1066430"
  },
  {
    "text": "various kinds of\nstatistical procedures that people were using that were\nnot resulting in robust results,",
    "start": "1066430",
    "end": "1072550"
  },
  {
    "text": "and a lack of disclosure\nof replication materials so that procedures\ncould be repeated,",
    "start": "1072550",
    "end": "1077679"
  },
  {
    "text": "so that analysis\ncould be replicated. I would categorize these\nas all breakdowns in--",
    "start": "1077680",
    "end": "1085420"
  },
  {
    "text": "broadly, like the culture\nof research integrity that the social sciences had\ncultivated up to that time.",
    "start": "1085420",
    "end": "1091820"
  },
  {
    "text": "And I think, there have been\na number of really great steps to change that since then. But the extreme parallel\ntake here would be something",
    "start": "1091820",
    "end": "1098470"
  },
  {
    "text": "like, OK, if this\nwas a problem and is a problem for a lot of the\nempirical behavioral and social sciences--",
    "start": "1098470",
    "end": "1104440"
  },
  {
    "text": "since that we got worried about\nstarting in the early 2000s,",
    "start": "1104440",
    "end": "1109990"
  },
  {
    "text": "here we stand at the precipice\nof a novel field of AI-simulated social and behavioral science.",
    "start": "1109990",
    "end": "1116500"
  },
  {
    "text": "Are we about to just repeat the\nsame problem all over again, just in new ways?",
    "start": "1116500",
    "end": "1123400"
  },
  {
    "text": "How can we make\nelement-simulated social and behavioral studies at\nleast as trustworthy,",
    "start": "1123400",
    "end": "1130000"
  },
  {
    "text": "at least as reliable, aspire to\nthe same kinds of-- or analogous kinds of integrity standards\nthat we want behavioral science",
    "start": "1130000",
    "end": "1137500"
  },
  {
    "text": "studies to aspire to? Whoops, wrong direction. And so that's the idea here.",
    "start": "1137500",
    "end": "1146665"
  },
  {
    "text": "And I think that this is where\nI see this as a big, inspiring",
    "start": "1146665",
    "end": "1151830"
  },
  {
    "text": "challenge where on the\nsocial science side, this is about taking\nwhat we've learned",
    "start": "1151830",
    "end": "1156900"
  },
  {
    "text": "from the failures of\nsome of our bad, old ways of doing stuff and mapping\nit into this new space.",
    "start": "1156900",
    "end": "1163750"
  },
  {
    "text": "And on an HCI and\nhuman-centered AI side, this is about supporting a\nspecific use case that may have",
    "start": "1163750",
    "end": "1171540"
  },
  {
    "text": "broad implications for design\npolicy and scaling up certain",
    "start": "1171540",
    "end": "1178440"
  },
  {
    "text": "kinds of research\nfields that just--",
    "start": "1178440",
    "end": "1183450"
  },
  {
    "text": "that are still learning\nhow to use these systems. So it's a particular use case.",
    "start": "1183450",
    "end": "1189309"
  },
  {
    "text": "And I think that the\nfirst step that I want to pursue that I'm\ntalking about in the work we've",
    "start": "1189310",
    "end": "1195060"
  },
  {
    "text": "got to present today is about\nassessing the kinds of threats that may be distinct in\nthe context of reproducing",
    "start": "1195060",
    "end": "1202649"
  },
  {
    "text": "social science with AI models. ",
    "start": "1202650",
    "end": "1208020"
  },
  {
    "text": "And I want to just\nacknowledge a few of the things that have inspired\nthe approach we're taking. And I'll try to\nmove through these very quickly because\nI think they're fun",
    "start": "1208020",
    "end": "1214379"
  },
  {
    "text": "to put up on the\nwall but not core to the results I\nwant to talk about. ",
    "start": "1214380",
    "end": "1220960"
  },
  {
    "text": "There have been a\nlot of prior work. And I mentioned\nsome of these trying to estimate bias and sampling\nproblems in other kinds",
    "start": "1220960",
    "end": "1228080"
  },
  {
    "text": "of new research settings. I mentioned Mechanical\nTurk in crowdsourcing work. This is a paper that\nEszter Hargittai and I",
    "start": "1228080",
    "end": "1233240"
  },
  {
    "text": "worked on a few years ago. But Jeremy Freese here in\nthe sociology department did a lot of great work in\nthis space and others as well.",
    "start": "1233240",
    "end": "1239690"
  },
  {
    "text": "So this is about\ntrying to understand what the kind of biases and\nvariations in one setting",
    "start": "1239690",
    "end": "1244929"
  },
  {
    "text": "might be that might shape the\nkinds of findings you get when you try to conduct social\nscientific analysis",
    "start": "1244930",
    "end": "1250400"
  },
  {
    "text": "with that sample and\nwith that population. So I think there's\nsome things that I'm trying to learn from that area\nof work in the past as well.",
    "start": "1250400",
    "end": "1257299"
  },
  {
    "text": "Another area-- and this speaks\nto some of what I was talking about in my response to you-- is Aylin Caliskan and\nArvind Narayanan's work",
    "start": "1257300",
    "end": "1265280"
  },
  {
    "text": "and their collaborators,\ntrying to understand the bias that go\ninto the corpora that",
    "start": "1265280",
    "end": "1270290"
  },
  {
    "text": "are used to train the models. So I think, I find\nthat really inspiring. I'm not building\non it here, but I",
    "start": "1270290",
    "end": "1276710"
  },
  {
    "text": "think there are others\nlike Jessica Holman, who's a colleague at Northwestern,\nwho've also tried to understand",
    "start": "1276710",
    "end": "1283140"
  },
  {
    "text": "the specific kinds\nof biases and errors that you get out of\ngenerative AI or ML systems,",
    "start": "1283140",
    "end": "1289650"
  },
  {
    "text": "or that go into them that might\nthen have implications for end use cases down the\ntrain-- down the track.",
    "start": "1289650",
    "end": "1298559"
  },
  {
    "text": "And then there's the\nwork I mentioned, that crisis and\nreplication crisis work.",
    "start": "1298560",
    "end": "1305153"
  },
  {
    "text": "And I mentioned\nthat a lot of work has been done to try to\nboost up social science and make it more robust, more\nreplicable, more trustworthy.",
    "start": "1305153",
    "end": "1313000"
  },
  {
    "text": "And some of that's been done\nby-- this is a project that was pursued by just massive group of\ncollaborators where they worked",
    "start": "1313000",
    "end": "1321870"
  },
  {
    "text": "in large teams to-- well, a large team of\nteams to replicate hundreds",
    "start": "1321870",
    "end": "1327333"
  },
  {
    "text": "of prior social science\nstudies, in this case, from psychology to really\ntry to assess which findings",
    "start": "1327333",
    "end": "1334320"
  },
  {
    "text": "were going to be-- if you tried to\nrigorously reproduce them in different samples\nin different ways,",
    "start": "1334320",
    "end": "1341159"
  },
  {
    "text": "would hold up over time. And last but not least,\nthere's been some other work.",
    "start": "1341160",
    "end": "1347150"
  },
  {
    "text": "And this involves another\ncolleague, Matt Kay, who's at Northwestern,\nwhich takes an idea of--",
    "start": "1347150",
    "end": "1354789"
  },
  {
    "text": "the idea that when you're\ndoing statistical analysis on social scientific\ndata, you're often",
    "start": "1354790",
    "end": "1359980"
  },
  {
    "text": "making choices along the way. This is Andrew Gelman, a\nstatistician at Columbia University, has\ntalked about this",
    "start": "1359980",
    "end": "1365585"
  },
  {
    "text": "as thinking about forking\npaths in research design. And in walking down those paths\nand choosing particular forks,",
    "start": "1365585",
    "end": "1374280"
  },
  {
    "text": "there are roads you\nare not traveling. And we might start to think\nabout generating research",
    "start": "1374280",
    "end": "1379720"
  },
  {
    "text": "outputs that can\nactually incorporate those alternative paths.",
    "start": "1379720",
    "end": "1385540"
  },
  {
    "text": "And Gelman and then\nthese folks talk about that as thinking about\nresearch multiverses, where",
    "start": "1385540",
    "end": "1391360"
  },
  {
    "text": "you might have the final\nversion of the study that you, the research\nscientist like the best.",
    "start": "1391360",
    "end": "1397059"
  },
  {
    "text": "But you might also be able\nto present to your readers at the same time in a creative\ninteractive visualization, which",
    "start": "1397060",
    "end": "1402850"
  },
  {
    "text": "is what these folks\nbuilt the system to do. What happens if I twiddle\nthis knob this way, in the way I design the analysis?",
    "start": "1402850",
    "end": "1408950"
  },
  {
    "text": "What happens if\nI change the rule that I use to decide who's\nin or out of the study?",
    "start": "1408950",
    "end": "1415544"
  },
  {
    "text": "I find this a really compelling\nand exciting line of work that inspired some of our-- Carolyn's and my\nwork in this space.",
    "start": "1415545",
    "end": "1421580"
  },
  {
    "text": "OK, preamble done. So what I want to\ndo in this space",
    "start": "1421580",
    "end": "1427595"
  },
  {
    "text": "and what I've been\nworking with Carolyn to do is to try to think about\nspecific kinds of-- distinct types of\nLLM-driven threats",
    "start": "1427595",
    "end": "1435050"
  },
  {
    "text": "to robust social scientific\nreplications and simulations,",
    "start": "1435050",
    "end": "1440180"
  },
  {
    "text": "and design probes to\nassess the sensitivity of social scientific\nsimulations to those threats.",
    "start": "1440180",
    "end": "1448970"
  },
  {
    "text": "That's the core of this. And what I'm going\nto do is I'm going to walk you through both\nthe kinds of threats",
    "start": "1448970",
    "end": "1456230"
  },
  {
    "text": "that we've thought about so far\nand the kinds of probe designs that we've developed\nto try to address them,",
    "start": "1456230",
    "end": "1462270"
  },
  {
    "text": "and then give you\na worked example to think about with\nsome actual results, and some graphs that are fun.",
    "start": "1462270",
    "end": "1468740"
  },
  {
    "text": "And then I'll talk a little\nbit about the implications that I see coming out\nfrom that exercise so far and where I'm hoping we\ncan go with the work next.",
    "start": "1468740",
    "end": "1475889"
  },
  {
    "text": "And hopefully, you'll have lots\nof great questions and ideas that can help me think\nabout better ways to do it.",
    "start": "1475890",
    "end": "1483013"
  },
  {
    "text": "So some types of\nLLM-specific threats that we wanted to-- that we've\nidentified that I'm going",
    "start": "1483013",
    "end": "1489450"
  },
  {
    "text": "to talk about in a minute. Three is the magic number here. So the first one is\nprompt sensitivity.",
    "start": "1489450",
    "end": "1497310"
  },
  {
    "text": "This one's glaring in a way\nfor any time you interact with an LLM is that you've\ngot to tell it what-- you've",
    "start": "1497310",
    "end": "1505820"
  },
  {
    "text": "got to ask it for something. And there may be idiosyncrasies\nof how you produce that input",
    "start": "1505820",
    "end": "1511730"
  },
  {
    "text": "or what goes into that\ninput that may generate particular kinds of responses.",
    "start": "1511730",
    "end": "1517830"
  },
  {
    "text": "And for social scientists,\nthis is analogous to--",
    "start": "1517830",
    "end": "1523492"
  },
  {
    "text": "there's a positive\nspin on this, which is that really skillful people-- prompt engineers can design\nprompts that can elicit--",
    "start": "1523492",
    "end": "1531305"
  },
  {
    "text": "very carefully elicit exactly\nthe kind of output from models that they want under\ncertain circumstances.",
    "start": "1531305",
    "end": "1536520"
  },
  {
    "text": "Well, for social\nscience, if you want to be able to simulate\nsocial and human behavior, that's fine, except\nthat we still",
    "start": "1536520",
    "end": "1542809"
  },
  {
    "text": "want to know which\nkinds of simulations are very sensitive to the\ndetails of the prompts",
    "start": "1542810",
    "end": "1548510"
  },
  {
    "text": "that you're giving the model. I was talking to Rob\nWeller yesterday. In psychology, there's this\nidea of stimulus hacking, which",
    "start": "1548510",
    "end": "1555975"
  },
  {
    "text": "is very analogous here\nthat he was telling me about where for\npsychology research,",
    "start": "1555975",
    "end": "1561690"
  },
  {
    "text": "there might be people's studies\nthat only work because they're a very creative research\ndesigner who produces",
    "start": "1561690",
    "end": "1569490"
  },
  {
    "text": "an experimental setup\nthat elicits exactly the response to a\nparticular stimulus",
    "start": "1569490",
    "end": "1576059"
  },
  {
    "text": "that they are hoping to find. And when you actually vary\nthe stimulus a little bit, maybe the result never holds up.",
    "start": "1576060",
    "end": "1582100"
  },
  {
    "text": "And it turns out, that's\nnot a general pattern of human psychology\nor human behavior. But it was just this\nparticular researcher",
    "start": "1582100",
    "end": "1588330"
  },
  {
    "text": "being really good at designing\nthat particular study. So this is the\nanalogous thing here.",
    "start": "1588330",
    "end": "1594340"
  },
  {
    "text": "The second one is stochasticity. And there's a way that\ngenerative models-- and, again, I'm not\ngoing to pretend",
    "start": "1594340",
    "end": "1600340"
  },
  {
    "text": "to be an expert in\nthe architecture or the construction of them. But we can think\nabout-- there are",
    "start": "1600340",
    "end": "1606850"
  },
  {
    "text": "lots of points in\nthese models where there is stochasticity\nand randomness inserted for very good reason.",
    "start": "1606850",
    "end": "1612590"
  },
  {
    "text": "And some of that is\nincredibly valuable because it contributes\nboth to the model's ability",
    "start": "1612590",
    "end": "1618460"
  },
  {
    "text": "to explore and produce\ninteresting and diverse",
    "start": "1618460",
    "end": "1624520"
  },
  {
    "text": "predictions or responses\nfrom across its training data and to produce responses\nthat vary a little bit",
    "start": "1624520",
    "end": "1631450"
  },
  {
    "text": "and maybe embrace some of the\nidiosyncrasies of human behavior in ways that aren't so\nmechanistic that you might see",
    "start": "1631450",
    "end": "1639159"
  },
  {
    "text": "from other kinds of modeling. So these can manifest in things\nlike the model hyperparameters",
    "start": "1639160",
    "end": "1647020"
  },
  {
    "text": "that you might be familiar\nwith if you've interacted with ChatGPT or the APIs from\nOpenAI where you can say,",
    "start": "1647020",
    "end": "1655580"
  },
  {
    "text": "like, I want this to be more\ndeterministic or more random. You can dial that knob.",
    "start": "1655580",
    "end": "1662120"
  },
  {
    "text": "But that's a great\nexample of a thing where if I'm trying to reproduce\na social scientific output,",
    "start": "1662120",
    "end": "1669170"
  },
  {
    "text": "it might be helpful\nto understand what-- how sensitive are my results to\ndialing that knob up or down.",
    "start": "1669170",
    "end": "1679090"
  },
  {
    "text": "And another one is memorization. And so this goes back to\nthe training data issue.",
    "start": "1679090",
    "end": "1685030"
  },
  {
    "text": "A lot of the thing that we\ndo in the social sciences when we want to replicate\nor test something is we grab a really\nbrilliantly executed study",
    "start": "1685030",
    "end": "1692800"
  },
  {
    "text": "from off the shelf\nthat others have tested a few different times. And then we run it in a new\ncontext, or with a new sample,",
    "start": "1692800",
    "end": "1699100"
  },
  {
    "text": "or something like that. That's all fine and\nwell, except that a lot of those studies in\nsome way, shape, or form",
    "start": "1699100",
    "end": "1705159"
  },
  {
    "text": "may be in the training data. And so when you're\nprompting a generative model",
    "start": "1705160",
    "end": "1710740"
  },
  {
    "text": "to reproduce a social\nand behavioral study, you might just be\nproducing artifacts",
    "start": "1710740",
    "end": "1716200"
  },
  {
    "text": "of training data in a sense. And it's hard to assess\nthis for all the reasons that it can be hard to\nfigure out if models are--",
    "start": "1716200",
    "end": "1723190"
  },
  {
    "text": "what part of the\ntraining data models may be drawing on to\ngenerate a particular result.",
    "start": "1723190",
    "end": "1728620"
  },
  {
    "text": "It can be hard to figure\nout if they're actually aware of a prior finding. ",
    "start": "1728620",
    "end": "1737037"
  },
  {
    "text": "But it's a challenge\nbecause if you're benchmarking the performance\nof the model on something that's already part\nof its training data,",
    "start": "1737037",
    "end": "1746900"
  },
  {
    "text": "you're in a world where\nyour testing is not very rigorous in a certain sense.",
    "start": "1746900",
    "end": "1752370"
  },
  {
    "text": "So those are some\nof our problems. And now I want to talk\nabout the sensitivity probes",
    "start": "1752370",
    "end": "1757970"
  },
  {
    "text": "that we've designed to\ntry to evaluate them. So, so far, we've got three. And I'll talk about them in a\nlittle bit more depth in a sec.",
    "start": "1757970",
    "end": "1766880"
  },
  {
    "text": "And they don't correspond\nexactly to the three problems",
    "start": "1766880",
    "end": "1772490"
  },
  {
    "text": "that I laid out. So I just don't want to create\nthe illusion that like, OK, we had three problems. We have three fixes and each\nfix corresponds to one problem.",
    "start": "1772490",
    "end": "1779520"
  },
  {
    "text": "That's not what I'm doing here. These are more flexible\nand adaptable things, but I see them as categories\nor types of techniques",
    "start": "1779520",
    "end": "1790100"
  },
  {
    "text": "that you might use to probe the\nsensitivity of a model result in this case. They're not meant\nto be comprehensive.",
    "start": "1790100",
    "end": "1796890"
  },
  {
    "text": " And the worked example\nthat I'm going to show you is only really going\nto talk about one",
    "start": "1796890",
    "end": "1803240"
  },
  {
    "text": "of them, the first\none, perturbation. So I'll come back to\nthat in a little bit.",
    "start": "1803240",
    "end": "1809000"
  },
  {
    "text": "But I think that they have\nsome interesting strengths and possibilities. So I want to talk about a\nlittle-- talk about each",
    "start": "1809000",
    "end": "1815180"
  },
  {
    "text": "of them a little bit. So perturbation, what\ndo I mean by this? I mean, introduce systematically\nvarying prompts and settings",
    "start": "1815180",
    "end": "1823280"
  },
  {
    "text": "to just try fiddling with\nthe knobs a little bit so that if you're\ntrying to replicate",
    "start": "1823280",
    "end": "1828330"
  },
  {
    "text": "a particular behavioral study or\na particular behavioral pattern, you can assess how\nsensitive the result is",
    "start": "1828330",
    "end": "1837480"
  },
  {
    "text": "to the particulars of\nthe way that you set up the replication\nor the simulation.",
    "start": "1837480",
    "end": "1843309"
  },
  {
    "text": " And I've got a few\ndifferent dimensions that I think-- oops, and a\nspare semicolon over there.",
    "start": "1843310",
    "end": "1851990"
  },
  {
    "text": "Thanks, LaTeX. But I've got a few\ndifferent dimensions that you might\nthink about this in.",
    "start": "1851990",
    "end": "1857060"
  },
  {
    "text": "So one has to do with\nthe study protocol. I talked a minute\nago about this idea that there might be\nstimulus hacking.",
    "start": "1857060",
    "end": "1864409"
  },
  {
    "text": "But there may be\nelements of study designs that we can actually expand\nor explode because we're just",
    "start": "1864410",
    "end": "1871400"
  },
  {
    "text": "simulating this. We can simulate it a\nlot of different ways. And it may be that that can\nhelp us understand, for example,",
    "start": "1871400",
    "end": "1877850"
  },
  {
    "text": "whether a particular finding is\njust an artifact of something having been in the\ntraining data of the model,",
    "start": "1877850",
    "end": "1883160"
  },
  {
    "text": "having memorized it already. Other things include\nthe particular language",
    "start": "1883160",
    "end": "1888170"
  },
  {
    "text": "that we use for the prompt. So as social scientists,\nwe like to pretend",
    "start": "1888170",
    "end": "1893419"
  },
  {
    "text": "that the particular way that\na study was conducted or was designed is somehow sacred.",
    "start": "1893420",
    "end": "1902310"
  },
  {
    "text": "So you take these\nclassic research designs, like a prisoner's dilemma\nor something like that.",
    "start": "1902310",
    "end": "1907500"
  },
  {
    "text": "And you try to find a\ncanonically-worded version of it that you can use in your study.",
    "start": "1907500",
    "end": "1913090"
  },
  {
    "text": "And you do that\npartly because you don't want to have to convince\npeer reviewers that you wrote something new and that you\nchanged something important",
    "start": "1913090",
    "end": "1920010"
  },
  {
    "text": "about the original study design. But you also do that because\nif it worked in one setting, part of what you're\ntrying to do is",
    "start": "1920010",
    "end": "1926070"
  },
  {
    "text": "get it-- is see whether\nit works in a new setting. But that, again,\nthere's lots of reasons",
    "start": "1926070",
    "end": "1932900"
  },
  {
    "text": "why we might want to trivially\nor subtly alter the phrasing to see how models respond when\nthey're conducting simulations",
    "start": "1932900",
    "end": "1941090"
  },
  {
    "text": "of human behavior. And I'll show you an\nexample of that in a minute.",
    "start": "1941090",
    "end": "1946470"
  },
  {
    "text": "Other things are things\nlike the settings. So I talked about\nhyperparameters, the temperature of the model.",
    "start": "1946470",
    "end": "1952080"
  },
  {
    "text": "You can format your\ninput and request the format of your\noutput in different ways from generative language models.",
    "start": "1952080",
    "end": "1958003"
  },
  {
    "text": "And when you're\nprompting it, we've found some evidence that even\nasking the model to output things in a\nstructured data format",
    "start": "1958003",
    "end": "1964920"
  },
  {
    "text": "like JSON produces\npretty different results than just asking it to output\nstuff in more natural language.",
    "start": "1964920",
    "end": "1971100"
  },
  {
    "text": "So you can add, or you can\nget creative in this one. You can add whitespaces, newline\ncharacters, change digits,",
    "start": "1971100",
    "end": "1978809"
  },
  {
    "text": "numbers represented as digits\ninto numbers represented as words, or fractions,\nor whatever you like,",
    "start": "1978810",
    "end": "1986445"
  },
  {
    "text": "and so exploring\nthe effects of that. And then there's different\nprompting strategies",
    "start": "1986446",
    "end": "1993030"
  },
  {
    "text": "that we might pursue. And this ranges\nfrom the mundane, like asking the model to explain\nits reasoning when it gives you",
    "start": "1993030",
    "end": "2002270"
  },
  {
    "text": "an answer-- the chain of\nthought-prompting approach to also doing things that\nare more sophisticated",
    "start": "2002270",
    "end": "2008720"
  },
  {
    "text": "like feeding it a bunch\nof demographic background information about your\nhypothetical-simulated study",
    "start": "2008720",
    "end": "2014100"
  },
  {
    "text": "participant to see if it\ngenerates more accurate outputs once you've done\nthat, or feeding it",
    "start": "2014100",
    "end": "2019860"
  },
  {
    "text": "a memory stream in the\ncase of a generative agent. And then there's model version. I mentioned a\nminute ago that some",
    "start": "2019860",
    "end": "2025860"
  },
  {
    "text": "of the prior work in\nthis space was done on earlier versions of ChatGPT. We can never find out if\nthe initial results were",
    "start": "2025860",
    "end": "2032370"
  },
  {
    "text": "replicable in some\nsense because we can't go back and use a\ndeprecated version of the model.",
    "start": "2032370",
    "end": "2038760"
  },
  {
    "text": "But there are multiple\nmodel versions available at any given time. So we can assess whether\nour simulated result",
    "start": "2038760",
    "end": "2047400"
  },
  {
    "text": "is robust across model versions,\nor at least model generations,",
    "start": "2047400",
    "end": "2052872"
  },
  {
    "text": "or something like that. Or within a single generation,\nthere may be multiple versions. A new version of\nthe GPT AI was--",
    "start": "2052872",
    "end": "2061290"
  },
  {
    "text": "the API was just released\nearlier this week or last week. And so we can see whether\nthe one from last week",
    "start": "2061290",
    "end": "2067945"
  },
  {
    "text": "produces similar\nkinds of outputs to the one from a\nmonth, two months ago. ",
    "start": "2067945",
    "end": "2073132"
  },
  {
    "text": "So the other two that\nI've got-- and I'll spend a little\nless time on these because I'm not going to have\nresults about them yet-- but",
    "start": "2073132",
    "end": "2078156"
  },
  {
    "text": "is to iterate. There's a basic\nidea in statistics where part of the reason why you\nwant to replicate a study design",
    "start": "2078156",
    "end": "2088669"
  },
  {
    "text": "that was conducted\nover here, over here is that by drawing\nmultiple samples, you're actually generating\nwhat you would talk about",
    "start": "2088670",
    "end": "2096679"
  },
  {
    "text": "as a sampling distribution. And so having those\nmultiple draws, especially when you're dealing with\na hidden population.",
    "start": "2096679",
    "end": "2103861"
  },
  {
    "text": "In this case, the\nhidden population is not a group of people who\ndon't want to be identified. The hidden population\nis a theoretical space",
    "start": "2103862",
    "end": "2111560"
  },
  {
    "text": "of possible responses to\na given set of prompts that we can't observe directly.",
    "start": "2111560",
    "end": "2118800"
  },
  {
    "text": "So by drawing multiple\niterations of responses",
    "start": "2118800",
    "end": "2124340"
  },
  {
    "text": "to the same queries\nor to similar queries, we can construct a\nsampling distribution",
    "start": "2124340",
    "end": "2130369"
  },
  {
    "text": "and try to understand the\ndistributional characteristics",
    "start": "2130370",
    "end": "2138220"
  },
  {
    "text": "of the-- what kinds of estimates\nwe get from that, from a single draw from\nthat sampling distribution.",
    "start": "2138220",
    "end": "2145700"
  },
  {
    "text": " And then the other one\nis to re-replicate.",
    "start": "2145700",
    "end": "2150840"
  },
  {
    "text": "So this is our third\nprobe technique where I mentioned that\nthere's been a lot of work like that in that\nreproducibility project,",
    "start": "2150840",
    "end": "2157559"
  },
  {
    "text": "that open science project\nto replicate existing social scientific research\nwith additional social science",
    "start": "2157560",
    "end": "2165330"
  },
  {
    "text": "with additional populations of\npeople or samples of people. Well, let's replicate\nthe replications.",
    "start": "2165330",
    "end": "2171490"
  },
  {
    "text": "I mean, again, the nice\nthing about generative model simulations is that they-- all\nthey cost you is API tokens.",
    "start": "2171490",
    "end": "2181080"
  },
  {
    "text": "And there's a lot of\noff-the-shelf tools that social\nscientists have built to conduct these kind of\nmeta-analytic comparisons",
    "start": "2181080",
    "end": "2187530"
  },
  {
    "text": "where you're comparing the\nresults of many experiments and assessing\nwhether those, kind",
    "start": "2187530",
    "end": "2194400"
  },
  {
    "text": "of, the population of many\nreplicated experiments produces a finding consistent\nwith initial studies",
    "start": "2194400",
    "end": "2200832"
  },
  {
    "text": "or something like that. Yes. [? I'm not ?]\n[? sure I'm following. ?] Is it iterate or re-replicate that\nbasically do Monte Carlo",
    "start": "2200832",
    "end": "2206250"
  },
  {
    "text": "sampling, like run the\nsimulation a bunch of many times? I think that there's overlap.",
    "start": "2206250",
    "end": "2211310"
  },
  {
    "text": "And I think it's\nbecause re-replicating-- to me, it makes the most sense\nwhen you iterate with it.",
    "start": "2211310",
    "end": "2217360"
  },
  {
    "text": "I mean, we can--\nwe do have a result that is a case where you can\nimagine performing just one",
    "start": "2217360",
    "end": "2222690"
  },
  {
    "text": "replication of a replication. And I'll get to\nthis in a moment. But, let's say, I've got\na classic social science",
    "start": "2222690",
    "end": "2230329"
  },
  {
    "text": "study that was done in a lab. It's been replicated really\ncarefully in another sample.",
    "start": "2230330",
    "end": "2238550"
  },
  {
    "text": "I can run one simulated\nreplication of the replication",
    "start": "2238550",
    "end": "2243590"
  },
  {
    "text": "of the original study. I can use the same techniques,\nthe same measurement and draw one replicant sample.",
    "start": "2243590",
    "end": "2251210"
  },
  {
    "text": "Or I can do that 1,000 times,\nor 100 times, or whatever. So to me, that first\nstep of drawing one",
    "start": "2251210",
    "end": "2258320"
  },
  {
    "text": "would be a re-replication. And when I draw 1,000 of those,\nthat would be an iterated re-replication.",
    "start": "2258320",
    "end": "2264240"
  },
  {
    "text": "So that would be iteration and-- So iteration doesn't\nimply variation. It's Just-- Not necessarily. I think that's how I'm\nthinking about it now.",
    "start": "2264240",
    "end": "2270950"
  },
  {
    "text": "Maybe it should. I don't know. I think you can also combine\nperturbation with iteration. So I mean, it gets\nreally confusing",
    "start": "2270950",
    "end": "2276860"
  },
  {
    "text": "when you start thinking-- when\nyou start crossing these over. So like, I could-- ",
    "start": "2276860",
    "end": "2283880"
  },
  {
    "text": "let's work with the\nmodel temperature, which is this\nrandomness thing I can",
    "start": "2283880",
    "end": "2290060"
  },
  {
    "text": "tune as a hyperparameter\nin the OpenAI API.",
    "start": "2290060",
    "end": "2296000"
  },
  {
    "text": "You can imagine a\nscenario where I spin that up to maximum randomness.",
    "start": "2296000",
    "end": "2301880"
  },
  {
    "text": "And then I draw 1,000 samples. At maximum randomness, I\ndraw 1,000 samples at middle",
    "start": "2301880",
    "end": "2310700"
  },
  {
    "text": "randomness and 1,000 samples\nat the most deterministic randomness. So that would be\na case where I've",
    "start": "2310700",
    "end": "2316520"
  },
  {
    "text": "done perturbation\nand iteration to try to understand the\nsampling distribution",
    "start": "2316520",
    "end": "2322550"
  },
  {
    "text": "of perturbed results. Maybe a related\nquestion, is there a difference between\nreplicating the replication",
    "start": "2322550",
    "end": "2329760"
  },
  {
    "text": "and replicating\nthe original study? I think that there is a--",
    "start": "2329760",
    "end": "2335700"
  },
  {
    "text": "there's a difference\ninsofar as social scientists would treat the\nresults of a study that",
    "start": "2335700",
    "end": "2341460"
  },
  {
    "text": "has replicated differently. So you're saying that it's\na replication that has--",
    "start": "2341460",
    "end": "2347140"
  },
  {
    "text": "Worked. --positive [INAUDIBLE]. Maybe, maybe not. Yeah, maybe you're right. That's in some ways, no.",
    "start": "2347140",
    "end": "2353740"
  },
  {
    "text": "I think that social scientists\ntreat these kind of-- meta-analysis and meta-analytic\nanalyses of study replications",
    "start": "2353740",
    "end": "2364180"
  },
  {
    "text": "are published as\ndistinct artifacts in the social sciences. So in that sense,\nthey're different.",
    "start": "2364180",
    "end": "2369440"
  },
  {
    "text": "I think mechanically\nwhat it looks like in terms of conducting the\nstudy, probably not terribly",
    "start": "2369440",
    "end": "2374660"
  },
  {
    "text": "different. Although there are many\nreasons why once you've got an initial finding or an\ninitial set of studies that",
    "start": "2374660",
    "end": "2380380"
  },
  {
    "text": "demonstrate a finding, you\nmay construct a replication differently. Because you know\nsomething, for example,",
    "start": "2380380",
    "end": "2385810"
  },
  {
    "text": "about the expected effect size. You can make a\npower calculation, say like, OK, if I'm expecting\nan effect of at least this size,",
    "start": "2385810",
    "end": "2393370"
  },
  {
    "text": "I want to design my study to\nbe able to detect something of at least that size. That means I need these many\nparticipants in my study.",
    "start": "2393370",
    "end": "2400579"
  },
  {
    "text": "And so the replications\noften have slightly different structures. So is re-replication a\ncommon thing in [INAUDIBLE]?",
    "start": "2400580",
    "end": "2407700"
  },
  {
    "text": "No. But it seems like it. There's a lot of replication. And there's a lot\nof meta-analyses. ",
    "start": "2407700",
    "end": "2414750"
  },
  {
    "text": "I haven't seen re-replication as\na thing in the social sciences.",
    "start": "2414750",
    "end": "2419820"
  },
  {
    "text": "At this point, people are still\nworking in the mode of like, let's get enough\nreplications going first.",
    "start": "2419820",
    "end": "2425609"
  },
  {
    "text": "And then we'll worry about\nwhat happens after that next. Does the replication imply\nthat there has to be variation?",
    "start": "2425610",
    "end": "2430660"
  },
  {
    "text": "So if Manish's Lab publishes\na result, when I replicate, typically I'm replicating with\nmy sample in my lab or something",
    "start": "2430660",
    "end": "2436800"
  },
  {
    "text": "like that. Whereas if I think\nabout a Manish's Lab publishes a simulation,\nI just take the--",
    "start": "2436800",
    "end": "2442859"
  },
  {
    "text": "I run essentially\nthe exact same thing. So analytically, I'm trying to--",
    "start": "2442860",
    "end": "2449340"
  },
  {
    "text": "Yeah, I think that there are-- It's like I ran your software. I think that that is a distinct\ncomponent of replications",
    "start": "2449340",
    "end": "2456960"
  },
  {
    "text": "is that I think replication-- so it's hard for me to\nimagine a replication where--",
    "start": "2456960",
    "end": "2462900"
  },
  {
    "text": "a re-replication where you would\nfundamentally alter the study",
    "start": "2462900",
    "end": "2469760"
  },
  {
    "text": "protocol, for example. That's not really a thing. It makes it a little\nharder to imagine.",
    "start": "2469760",
    "end": "2475859"
  },
  {
    "text": "So I talked a little bit\nabout how re-replication can be combined with iteration. It makes it a little harder for\nme to imagine re-replication",
    "start": "2475860",
    "end": "2483037"
  },
  {
    "text": "being combined with some of\nthe perturbation strategies that I talked\nabout a moment ago. Because then if it\nfails, you don't know.",
    "start": "2483038",
    "end": "2488413"
  },
  {
    "text": "You're like, well,\nwho knows why? I mean, there's a-- so I think\nconceptually, they're distinct. I think that there's--",
    "start": "2488413",
    "end": "2494750"
  },
  {
    "text": "but as you can tell from my\nresponse, I don't think I have-- there's no-- I'm making this stuff up.",
    "start": "2494750",
    "end": "2500510"
  },
  {
    "text": "So let's see what\nwe can do with it. But I think it's\ninteresting to play with. And I think those are exactly\nthe kinds of questions that I would hope could be asked\nwith an approach like this.",
    "start": "2500510",
    "end": "2510960"
  },
  {
    "text": "So let's go through the\npartially worked example because this is, I\nthink, the most fun part. Did you [INAUDIBLE]\n[? find ?] anything?",
    "start": "2510960",
    "end": "2519100"
  },
  {
    "text": "No, OK, great. So I'm doing this\nwith just one study. Carolyn and I did this with\njust one study for now. And we chose this\nstudy, which was",
    "start": "2519100",
    "end": "2525280"
  },
  {
    "text": "published in 2014 in science. So an experiment that's\nbeen published in science--",
    "start": "2525280",
    "end": "2531970"
  },
  {
    "text": "in the social sciences\nis generally treated as-- it was probably done\nreally, really well. And indeed, this\none is no exception.",
    "start": "2531970",
    "end": "2538930"
  },
  {
    "text": "So this is a study led\nby Uri Gneezy, UC San Diego with some collaborators\nabout overhead aversion",
    "start": "2538930",
    "end": "2546940"
  },
  {
    "text": "in donations to charities. So the basic idea, the basic\nfinding from this study, it asks people--",
    "start": "2546940",
    "end": "2553990"
  },
  {
    "text": "brings people into a lab. There are two studies\nin the project. This is the lab\nportion of the project.",
    "start": "2553990",
    "end": "2559130"
  },
  {
    "text": "So there's one study\nthat's a lab experiment. They bring people into the lab. And they say, Michael,\nyou have the choice.",
    "start": "2559130",
    "end": "2564650"
  },
  {
    "text": "We've got two charities. You have $100 that you\ncan decide where it goes. You have to pick one charity.",
    "start": "2564650",
    "end": "2571660"
  },
  {
    "text": "Charity A does lots of nice,\ngood things and has no overhead.",
    "start": "2571660",
    "end": "2577849"
  },
  {
    "text": "So all of your donation will\ngo directly to the cause and will not support overhead.",
    "start": "2577850",
    "end": "2583319"
  },
  {
    "text": "Charity B does really\ngreat, nice things. And for some of the\nstudy, they randomly",
    "start": "2583320",
    "end": "2589880"
  },
  {
    "text": "decide that it's going\nto have no overhead. And for some of\nthe study, they say it's going to have\na little overhead. And for some of\nthe study, they say",
    "start": "2589880",
    "end": "2595938"
  },
  {
    "text": "it's going to have 50% overhead,\nquite a bit of overhead. And it turns out-- [INAUDIBLE] is a little\ncloser to what we got here.",
    "start": "2595938",
    "end": "2601935"
  },
  {
    "text": "Yeah, yeah, Yeah. [LAUGHS] Thanks, universities.",
    "start": "2601935",
    "end": "2607040"
  },
  {
    "text": "So what they find is that people\nare less excited to donate",
    "start": "2607040",
    "end": "2613760"
  },
  {
    "text": "when there's high overhead. That's the overhead\naversion component. That's not novel or surprising. And they find that--",
    "start": "2613760",
    "end": "2620299"
  },
  {
    "text": "they do some\nmanipulations where they find that basically\ntelling people that somebody else out there,\nsome beneficent donor has",
    "start": "2620300",
    "end": "2626869"
  },
  {
    "text": "covered the overhead so that\n100% of your donation, Michael, will go to support\nthe good works",
    "start": "2626870",
    "end": "2632150"
  },
  {
    "text": "and not to pay the staff\nof the organization. That makes it so\nthat you are now",
    "start": "2632150",
    "end": "2638450"
  },
  {
    "text": "willing to donate to\nthat organization, again, at a higher rate. I'll show you the\ngraph in a moment.",
    "start": "2638450",
    "end": "2645869"
  },
  {
    "text": "Well, here, let's do it now. So here's the figure\n1, the top-line finding",
    "start": "2645870",
    "end": "2651050"
  },
  {
    "text": "from this lab study. And what you can see is in the\nstudy, they had five conditions. Each study, each\ncondition produces",
    "start": "2651050",
    "end": "2657260"
  },
  {
    "text": "one of these little points. So they have zero overhead where\nthey just see who donates to--",
    "start": "2657260",
    "end": "2662270"
  },
  {
    "text": "in this case, there\nwas one charity that was more famous than the other. And they did that on purpose.",
    "start": "2662270",
    "end": "2667770"
  },
  {
    "text": "Because that was part of how\nthey indexed how overhead was affecting whether people\nwould or wouldn't donate.",
    "start": "2667770",
    "end": "2672890"
  },
  {
    "text": "Otherwise, it might be\njust a random choice. So when there's no overhead\nfor either organization,",
    "start": "2672890",
    "end": "2678590"
  },
  {
    "text": "most of the people\nin the study donate to the more famous charity. When you have a little\nbit of overhead,",
    "start": "2678590",
    "end": "2685706"
  },
  {
    "text": "that doesn't change much. This is where there's-- the overhead is not\ncovered by somebody else.",
    "start": "2685706",
    "end": "2692940"
  },
  {
    "text": "And then when you have\na lot of overhead, you can see that having that\noverhead covered by somebody, by a beneficent other\ndonor makes a big impact",
    "start": "2692940",
    "end": "2700670"
  },
  {
    "text": "on the proportion of people\nwho are going to donate to the more famous charity. So the overhead\naversion component of it",
    "start": "2700670",
    "end": "2708890"
  },
  {
    "text": "is the difference\nbetween these two dots, where you see if I\ncover the overhead,",
    "start": "2708890",
    "end": "2715160"
  },
  {
    "text": "people will keep donating to the\nmore famous charity versus if I don't cover the\noverhead, people will",
    "start": "2715160",
    "end": "2720230"
  },
  {
    "text": "donate to the charity with\nless overhead more often. ",
    "start": "2720230",
    "end": "2726290"
  },
  {
    "text": "For our perturbation\nexamples, we are only focused on the\noverhead not being covered.",
    "start": "2726290",
    "end": "2733619"
  },
  {
    "text": "We wanted to see if there\nwas overhead aversion. We wanted to see if we could\nreproduce overhead aversion",
    "start": "2733620",
    "end": "2739970"
  },
  {
    "text": "by prompting LLMs. So it's these three\ndots basically, this one with zero overhead\nand then the overhead",
    "start": "2739970",
    "end": "2747320"
  },
  {
    "text": "not being covered,\nthose conditions there. ",
    "start": "2747320",
    "end": "2754990"
  },
  {
    "text": "This was also a study that\nwas replicated very well a few years later. So we have access to the\nreplication in addition.",
    "start": "2754990",
    "end": "2760150"
  },
  {
    "text": "And I'll talk about\nthat in a moment. So for us, study 1-- which\nis basically the only study we've done so far--",
    "start": "2760150",
    "end": "2765880"
  },
  {
    "text": "is to just try to do some\nsimulations to replicate overhead aversion and use some\nof those sensitivity, probing",
    "start": "2765880",
    "end": "2772960"
  },
  {
    "text": "strategies I talked\nabout a moment ago. So here's our first\none where we start off. Let's just see what happens\nwhen we try to take the protocol",
    "start": "2772960",
    "end": "2779650"
  },
  {
    "text": "and prompt the model with\nno further information. Just run the model through\nthe exact same thing",
    "start": "2779650",
    "end": "2786036"
  },
  {
    "text": "that the researchers\ndid with the people who came into their lab. And so you might\nrecall these three",
    "start": "2786037",
    "end": "2792040"
  },
  {
    "text": "dots that I was talking about;\n0%, 5%, and 50% overhead.",
    "start": "2792040",
    "end": "2798100"
  },
  {
    "text": "That's what you've\ngot right here. So what we find,\nlo and behold, is",
    "start": "2798100",
    "end": "2803350"
  },
  {
    "text": "that at low amounts of\noverhead, the model-- the simulated people are\nstill willing to-- the model",
    "start": "2803350",
    "end": "2809680"
  },
  {
    "text": "is still willing to donate\nto the more famous charity. And at about 50%, it falls\noff very steeply to 0%.",
    "start": "2809680",
    "end": "2816390"
  },
  {
    "text": "Nobody is willing to give\nanything to that organization anymore. So it's a bit extreme.",
    "start": "2816390",
    "end": "2822710"
  },
  {
    "text": "I don't know. The question I want you to\nstart putting into your head is, do you still-- do\nyou find this compelling?",
    "start": "2822710",
    "end": "2829440"
  },
  {
    "text": "Do you think this is a\ncompelling replication now? That's the question we were\ntrying to ask with this.",
    "start": "2829440",
    "end": "2834820"
  },
  {
    "text": "So with this first one, when\nI saw this, I was like, OK, it looks like it's showing some\namount of overhead aversion.",
    "start": "2834820",
    "end": "2841059"
  },
  {
    "text": "Boy, does the model\nseem averse to overhead. But maybe a little too averse\nto overhead, maybe it's",
    "start": "2841060",
    "end": "2847200"
  },
  {
    "text": "disappointing. I don't know. Well, it's also under-averse\non the left hand. Yeah, so the corresponding\nplace in the original graph",
    "start": "2847200",
    "end": "2854519"
  },
  {
    "text": "where this would have\nbeen was around 75%, I think, for 0% and 5% overhead.",
    "start": "2854520",
    "end": "2862300"
  },
  {
    "text": "And then for the 50% overhead,\nit dropped to just below 50% choosing that charity.",
    "start": "2862300",
    "end": "2868140"
  },
  {
    "text": "So it's [? cloud-chasing ?]\noverhead [INAUDIBLE]? Yeah. OK, let's keep going.",
    "start": "2868140",
    "end": "2873150"
  },
  {
    "text": "So the next thing we\ndid is we said, well, why settle for just 3\noverhead levels when",
    "start": "2873150",
    "end": "2878940"
  },
  {
    "text": "you could have 12 or 13? So we filled in the\ndistribution because we wanted to see what the model would do.",
    "start": "2878940",
    "end": "2884625"
  },
  {
    "text": " Again, this is just one set\nof settings for otherwise.",
    "start": "2884625",
    "end": "2890940"
  },
  {
    "text": "But now we can see the whole\nspace a little bit more. And we can see the descent\nalong the proportion donating.",
    "start": "2890940",
    "end": "2898380"
  },
  {
    "text": "There's a couple of\nthings I notice here. One is this little\nbump out around 55%,",
    "start": "2898380",
    "end": "2903809"
  },
  {
    "text": "which in another version that\nwe did of this with an earlier version of the model\nwas actually quite large and made us worried that\nmaybe the model had memorized",
    "start": "2903810",
    "end": "2911370"
  },
  {
    "text": "the empirical finding\nwhen we saw it. And the other is these\nfunny, anomalous dips.",
    "start": "2911370",
    "end": "2917002"
  },
  {
    "text": "But maybe that's\njust random noise. We didn't really know. But again, before\nI take a question,",
    "start": "2917002",
    "end": "2922680"
  },
  {
    "text": "I want you to ask\nyourself, do you think the model is\nreplicating overhead aversion? In this case, I'm not sure.",
    "start": "2922680",
    "end": "2929470"
  },
  {
    "text": "It seems that now I can\nsee the descent a bit more. I can see how it's\nmoving through the space.",
    "start": "2929470",
    "end": "2934737"
  },
  {
    "text": "My answer was that I was a\nlittle bit comforted by this. Because at least,\nit's getting the idea that at some intermediate\nlevel of overhead,",
    "start": "2934737",
    "end": "2942110"
  },
  {
    "text": "people are less willing\nto donate to the charity. So it's moving through\nthe distribution",
    "start": "2942110",
    "end": "2948260"
  },
  {
    "text": "in some meaningful way or a\nway to which I might ascribe meaning as someone\ninterested in whether this",
    "start": "2948260",
    "end": "2953840"
  },
  {
    "text": "aligns with human behavior. You had a question? I did, yeah. So how was the question asked?",
    "start": "2953840",
    "end": "2960380"
  },
  {
    "text": "I'm going to get to\nthat in a moment. So we just used the\nexact same protocol that the researchers\nused with the people",
    "start": "2960380",
    "end": "2966680"
  },
  {
    "text": "they brought into the lab. But it's odd that the y-axis\nis labeled [INAUDIBLE].",
    "start": "2966680",
    "end": "2971760"
  },
  {
    "text": "Oh, sorry, it's-- I'll show you in a moment. But it's the proportion\nof people choosing",
    "start": "2971760",
    "end": "2977099"
  },
  {
    "text": "to donate to the more\nfamous charity, given a certain level of overhead.",
    "start": "2977100",
    "end": "2982280"
  },
  {
    "text": "So the conditional\non that charity charging a certain amount\nto support their staff and operations,\nhow many people are",
    "start": "2982280",
    "end": "2989340"
  },
  {
    "text": "willing to-- what\npercentage of the sample is willing to donate to\nthat more famous charity",
    "start": "2989340",
    "end": "2994380"
  },
  {
    "text": "versus the less famous\ncharity that has no overhead? So that's why it's calculated\nas a percentage, sorry.",
    "start": "2994380",
    "end": "3000950"
  },
  {
    "text": "But then there, how\nis it a numeric thing? If you ask the model\nonce and say yes or no. So here you go, a lot of people.",
    "start": "3000950",
    "end": "3006057"
  },
  {
    "text": "You take the average over\nthe binary versus here, it's a single model\nsaying yes or no. It's a single model, but\nwe're prompting it 100 times.",
    "start": "3006057",
    "end": "3012940"
  },
  {
    "text": "I see. At each dot is 100 prompts. Sorry, I should have\nbeen clear about that.",
    "start": "3012940",
    "end": "3018180"
  },
  {
    "text": "Thanks for asking that. ",
    "start": "3018180",
    "end": "3023329"
  },
  {
    "text": "So now we're going to\nget into some fun stuff where we actually\nvaried the prop. So this is the prompt.",
    "start": "3023330",
    "end": "3029240"
  },
  {
    "text": "I should have shown\nyou this first, but I'm showing it to you\nhere because I'm going to mix it up in a little bit.",
    "start": "3029240",
    "end": "3035770"
  },
  {
    "text": "So we're a little\nshort on time, so I don't want to read the\nwhole thing out loud. But what you can see is\nthat it's basically saying,",
    "start": "3035770",
    "end": "3042105"
  },
  {
    "text": "here's the setup. We're going to ask you to\npick between one of these two charities. We're going to tell you a\nlittle bit about each charity.",
    "start": "3042105",
    "end": "3048640"
  },
  {
    "text": "And in telling you about\neach charity, what's going on in this second\nparagraph that's worth",
    "start": "3048640",
    "end": "3053950"
  },
  {
    "text": "pointing at is that I've\ngot our variables in here. But we are randomly\nassigning an overhead level",
    "start": "3053950",
    "end": "3062260"
  },
  {
    "text": "to this second charity. So that's where the\nmanipulation comes in. And the prompt clarifies that\ngiven this overhead level,",
    "start": "3062260",
    "end": "3072250"
  },
  {
    "text": "this amount or percentage\nof your donation will go directly to support\nthe work versus this amount",
    "start": "3072250",
    "end": "3079359"
  },
  {
    "text": "will go to cover the\ncosts of the organization. And this is the original-- this\nis pulled from their replication",
    "start": "3079360",
    "end": "3084400"
  },
  {
    "text": "materials from the\noriginal study. And yeah, so we asked the--",
    "start": "3084400",
    "end": "3093200"
  },
  {
    "text": "LLMs are great at summarizing\nor restating text. So we asked the LLMs to give us\na handful of alternate versions.",
    "start": "3093200",
    "end": "3099637"
  },
  {
    "text": "This is one of the\nalternate versions. It's a little shorter,\nbut I read through it. And as someone who spends a lot\nof time writing and thinking",
    "start": "3099637",
    "end": "3107360"
  },
  {
    "text": "about communicating\nideas, I had quibbles with some of the wording. But I came away feeling\npretty good about this",
    "start": "3107360",
    "end": "3113630"
  },
  {
    "text": "because it basically conveys the\nsame meaning and the same setup. And it alters some things\nthat are pretty small.",
    "start": "3113630",
    "end": "3119430"
  },
  {
    "text": "Like this one, instead\nof being the original-- so for every dollar you\ndonate, these many cents",
    "start": "3119430",
    "end": "3125780"
  },
  {
    "text": "will go to the operations,\nand these many cents will go to the staff.",
    "start": "3125780",
    "end": "3130970"
  },
  {
    "text": "This one, it says\nit as a percentage. So it's making some\nof those minor changes that I talked about.",
    "start": "3130970",
    "end": "3138500"
  },
  {
    "text": "So like I said, we\nran five of those. And the results splay\nout all over the place, all of a sudden in\na way that's fun.",
    "start": "3138500",
    "end": "3144600"
  },
  {
    "text": "So again, each of these dots\ncorresponds to 100 queries. We submitted the\nprompt 100 times.",
    "start": "3144600",
    "end": "3152579"
  },
  {
    "text": "And this is the\nresult that we get. So that one that I showed you\nwas actually prompt number five.",
    "start": "3152580",
    "end": "3158860"
  },
  {
    "text": "So that one produces a very\nsteep descent relatively early",
    "start": "3158860",
    "end": "3166275"
  },
  {
    "text": "in the overhead\nlevel distribution, but actually starts\nout at something",
    "start": "3166275",
    "end": "3172050"
  },
  {
    "text": "more like the\nempirically-observed level. ",
    "start": "3172050",
    "end": "3178430"
  },
  {
    "text": "Here's one where we fiddled\nwith the temperature settings. Far less variation was produced\nwith this one, but still",
    "start": "3178430",
    "end": "3185870"
  },
  {
    "text": "some interesting variation. I think, this\nprediction up here is",
    "start": "3185870",
    "end": "3192815"
  },
  {
    "text": "quite different from\nthis prediction up here. So depending on which\nsetting you choose, you go down the gradient\nat a different rate",
    "start": "3192815",
    "end": "3198430"
  },
  {
    "text": "in a different place. Question, please. Yes. What temperature were they set?",
    "start": "3198430",
    "end": "3204930"
  },
  {
    "text": "Oh, sorry, the range is-- interval, it goes\nfrom 0 to 1 but--",
    "start": "3204930",
    "end": "3210660"
  },
  {
    "text": "Like, the previous\ngraph you showed us. Oh yeah, so the\ndefault, we were just using the recommendation\nfrom OpenAI",
    "start": "3210660",
    "end": "3215760"
  },
  {
    "text": "is usually to use\none of these days. So we were just going with\none as the first one, so yeah.",
    "start": "3215760",
    "end": "3222180"
  },
  {
    "text": "So the initial graph-- the\ninitial figure I showed you where we just ran the prompt\nacross the entire distribution",
    "start": "3222180",
    "end": "3227280"
  },
  {
    "text": "of overhead levels should\ncorrespond to the brown line here. And apologies for the not\naccessible color palette.",
    "start": "3227280",
    "end": "3233590"
  },
  {
    "text": "We're working on that. Here's one where we asked\nit to give us the format--",
    "start": "3233590",
    "end": "3239770"
  },
  {
    "text": "the output as JSON. And again, we layered this with\ntemperature variation as well.",
    "start": "3239770",
    "end": "3246430"
  },
  {
    "text": "So you get like a\ntwo for one here. Asking it to output\nas JSON, you can see it moves everything,\nagain, further to the left",
    "start": "3246430",
    "end": "3253289"
  },
  {
    "text": "and makes the descent\nsteeper, kind of interesting. People will also\nget more frustrated if you make them write JSON.",
    "start": "3253290",
    "end": "3258680"
  },
  {
    "text": "Yeah, I think that's right. So nobody wants to\ndo-- the model doesn't want to donate to this charity\nif you ask it to read JSON.",
    "start": "3258680",
    "end": "3266150"
  },
  {
    "text": "I don't know. This one was pretty\nfun when we ran it through four different\nversions of the model. So the newest one, 4o,\nis the red in here.",
    "start": "3266150",
    "end": "3274740"
  },
  {
    "text": "Again, apologies for the\ninaccessible color palette. You can see that the oldest\nversion, in some sense,",
    "start": "3274740",
    "end": "3280670"
  },
  {
    "text": "performs quite differently\nthan the GPT-4 versions.",
    "start": "3280670",
    "end": "3285770"
  },
  {
    "text": "This is 3.5 turbo.  So anyway, I think--",
    "start": "3285770",
    "end": "3293240"
  },
  {
    "text": "well, here in the interest of\ntime, I'm going to skip ahead. I'm going to skip this. I can tell you about\nit later if you want.",
    "start": "3293240",
    "end": "3299220"
  },
  {
    "text": "We replicated the replication. It replicated, but we\njust did it once so far.",
    "start": "3299220",
    "end": "3304820"
  },
  {
    "text": "So we'll see what comes of that. Overall, I would say that\nfrom this, my takeaway is that the patterns\nare if you squint,",
    "start": "3304820",
    "end": "3311690"
  },
  {
    "text": "they resemble the\noriginal, which is nice. And I think that's\npart of what's exciting to social scientists in\nthis field about the potential",
    "start": "3311690",
    "end": "3318780"
  },
  {
    "text": "of AI-based simulation of\nsocial scientific work. On the other hand, the point\nestimates are pretty bad.",
    "start": "3318780",
    "end": "3326650"
  },
  {
    "text": "By point estimates, I\nmean the actual values, which replicate very well\nin human populations,",
    "start": "3326650",
    "end": "3332730"
  },
  {
    "text": "by the way, human samples. But the model turns\nout to be quite extreme",
    "start": "3332730",
    "end": "3338099"
  },
  {
    "text": "and to move through the\ndistribution of outputs in quite a different way than people do.",
    "start": "3338100",
    "end": "3345330"
  },
  {
    "text": "And on top of that,\nperturbing various aspects of the prompting,\nand the settings,",
    "start": "3345330",
    "end": "3350610"
  },
  {
    "text": "and those other\nfeatures I talked about produces quite\nsubstantial variations. So we can move the distribution.",
    "start": "3350610",
    "end": "3357180"
  },
  {
    "text": "In this case, we've got this\nnice logistic-looking curve. We can move it around. We can change the steepness.",
    "start": "3357180",
    "end": "3362955"
  },
  {
    "text": "We can do lots of things to\nit just by fiddling the knobs. And I don't know.",
    "start": "3362955",
    "end": "3368838"
  },
  {
    "text": "At the end of the\nday, does this mean that I should treat this\nas a reliable replication? Or is this a good\nsimulation that this work?",
    "start": "3368838",
    "end": "3377580"
  },
  {
    "text": "I think that's a\ncomplicated question. But I think that what\nit suggested to me, at least at this point, is\nthat the strategy of probing",
    "start": "3377580",
    "end": "3384780"
  },
  {
    "text": "it and exploring the\nspace of settings can reveal things about how\nsensitive these results are",
    "start": "3384780",
    "end": "3391230"
  },
  {
    "text": "and can help us\nunderstand what kinds of social scientific\nfindings may or may not be worth pursuing further.",
    "start": "3391230",
    "end": "3397369"
  },
  {
    "text": " So in terms of what's next,\nwe've got a bunch of stuff",
    "start": "3397370",
    "end": "3403420"
  },
  {
    "text": "to complete our initial\nstrategy with this and evaluate a bunch\nof other pieces of it.",
    "start": "3403420",
    "end": "3408740"
  },
  {
    "text": "But we're at time, so I'm\ngoing to wrap it up there. And if we have to\nshut it down, I'm happy to hang around\nand talk with folks,",
    "start": "3408740",
    "end": "3415020"
  },
  {
    "text": "address more questions,\nor chat more afterwards. So thank you very much. [APPLAUSE]",
    "start": "3415020",
    "end": "3422069"
  },
  {
    "start": "3422070",
    "end": "3426000"
  }
]
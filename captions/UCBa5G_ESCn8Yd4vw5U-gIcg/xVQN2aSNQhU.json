[
  {
    "start": "0",
    "end": "5410"
  },
  {
    "text": "Hi, everyone. Welcome-- welcome to the class. So topic for today, the class\nis labeled advanced topics.",
    "start": "5410",
    "end": "13600"
  },
  {
    "text": "But really what\nwe'll be doing is we'll be looking at expressive\npower of graph neural networks,",
    "start": "13600",
    "end": "19180"
  },
  {
    "text": "and see whether that\nexpressive power can be improved or increased.",
    "start": "19180",
    "end": "25510"
  },
  {
    "text": "And the way we think of\nright kind of a recap now, back to graph\nneural networks",
    "start": "25510",
    "end": "30759"
  },
  {
    "text": "is that basically,\ngiven the input graph, we were thinking about\nthis computation graphs",
    "start": "30760",
    "end": "37360"
  },
  {
    "text": "and we propagate information\nthrough several layers.",
    "start": "37360",
    "end": "45010"
  },
  {
    "text": "And when we think of this is\nthat-- we have the input graph, we have the graph\nneural networks,",
    "start": "45010",
    "end": "50559"
  },
  {
    "text": "we obtain the node\nembeddings, and then we attach some prediction head\nto it to make predictions.",
    "start": "50560",
    "end": "57820"
  },
  {
    "text": "We have the evaluation metric,\nwe have the loss function, and so on. And today's lecture,\nthe key question",
    "start": "57820",
    "end": "65990"
  },
  {
    "text": "will be asking is, can we make\nthe representation power of GNN",
    "start": "65990",
    "end": "71479"
  },
  {
    "text": "more expressive? So really this is what we are\ngoing to talk about today. So first, I want to highlight\nsome limitations of graph",
    "start": "71480",
    "end": "80270"
  },
  {
    "text": "neural networks, and then I'll\nshow you two principles-- two solutions to address them.",
    "start": "80270",
    "end": "85980"
  },
  {
    "text": "So here is what a perfect\ngraph neural network would do.",
    "start": "85980",
    "end": "91370"
  },
  {
    "text": "What should the perfect\ngraph neural network do? It should provide basically\na K-layer perfect graph",
    "start": "91370",
    "end": "98150"
  },
  {
    "text": "neural network would\nembed a node based on the structure of the K-hop\nneighborhood around that node.",
    "start": "98150",
    "end": "106340"
  },
  {
    "text": "So a perfect GNN would\nbuild an injective function between the neighborhood\nstructure and the embedding.",
    "start": "106340",
    "end": "113480"
  },
  {
    "text": " Every network\nneighborhood should",
    "start": "113480",
    "end": "119030"
  },
  {
    "text": "be mapped to a unique position\nin the embedding space. And just to clarify\nfor today's lecture,",
    "start": "119030",
    "end": "127680"
  },
  {
    "text": "I'm really going to focus\non the graph structure, and I'm going to ignore\na bit node attributes.",
    "start": "127680",
    "end": "134810"
  },
  {
    "text": "I will assume that node features\nare the least informative and things like that.",
    "start": "134810",
    "end": "140640"
  },
  {
    "text": "And I will really focus on\ncapturing the graph structure. So what if this is a\nneighborhood of a node to hop",
    "start": "140640",
    "end": "148310"
  },
  {
    "text": "neighborhood, each\nunique neighborhood should map to a unique position\nin the embedding space.",
    "start": "148310",
    "end": "153350"
  },
  {
    "text": "That would be the perfect GNN. That would be the most\nexpressive GNN I could have.",
    "start": "153350",
    "end": "159290"
  },
  {
    "text": "So here's an example. For a perfect GNN, two nodes\nthat have the same networking",
    "start": "159290",
    "end": "168709"
  },
  {
    "text": "neighborhood structure should\nget the same embedding. So for example, if\nI have two graphs",
    "start": "168710",
    "end": "173870"
  },
  {
    "text": "and I say what should\nbe the embedding of V1 and what should be\nthe embedding of V2? Then these two nodes appear\nexactly in the same graph,",
    "start": "173870",
    "end": "181650"
  },
  {
    "text": "so they will have\nthe same embedding. Again, let's assume--\nlet's don't worry too much",
    "start": "181650",
    "end": "188860"
  },
  {
    "text": "about node features. But what I want\nis these two nodes appear in the same\nnetwork structures,",
    "start": "188860",
    "end": "195049"
  },
  {
    "text": "so I will give them\nthe same embedding.",
    "start": "195050",
    "end": "200570"
  },
  {
    "text": "And if two nodes have different\nneighborhood structures, then they should get\ndifferent embeddings,",
    "start": "200570",
    "end": "206150"
  },
  {
    "text": "like node V1 appears in a\ndifferent network than V3 so the embeddings should differ.",
    "start": "206150",
    "end": "213020"
  },
  {
    "text": "We all agree if we focus only\non the network structure. I want the embeddings\nhere to be different",
    "start": "213020",
    "end": "218720"
  },
  {
    "text": "because I want to\ndistinguish the difference. And here the embeddings\nwould be the same because the network\nstructure is the same.",
    "start": "218720",
    "end": "225030"
  },
  {
    "text": "So all sounds good. However, this may not\nalways be the case,",
    "start": "225030",
    "end": "231720"
  },
  {
    "text": "especially this is the second\none is what we care about.",
    "start": "231720",
    "end": "238040"
  },
  {
    "text": "And even though, if two nodes\nhave the same neighborhood structure, sometimes\nmaybe we want",
    "start": "238040",
    "end": "244159"
  },
  {
    "text": "to assign different\nembeddings to them. And I'll give you\nan example of that. And because nodes that appear\nin different-- for example,",
    "start": "244160",
    "end": "251850"
  },
  {
    "text": "the reason for this\nis for nodes that appear in different\npositions of the graph. And I'll explain\nwhat I mean by that.",
    "start": "251850",
    "end": "257540"
  },
  {
    "text": "And we are going to call\nthis position aware tasks, and I'll talk about a class\nof graph neural networks,",
    "start": "257540",
    "end": "263580"
  },
  {
    "text": "called Position-aware\ngraph neural networks. What's an example of\na position-aware task?",
    "start": "263580",
    "end": "270060"
  },
  {
    "text": "Imagine you live in Manhattan. Manhattan looks\nlike this to you. A graph neural\nnetwork won't know",
    "start": "270060",
    "end": "276420"
  },
  {
    "text": "whether you are in this\ncorner, or in that corner, because the network neighborhood\naround both of these",
    "start": "276420",
    "end": "282420"
  },
  {
    "text": "looks the same. Still you'd like to know that\nyou are at the bottom left of--",
    "start": "282420",
    "end": "288840"
  },
  {
    "text": "I know Southwest of Manhattan or\nin the Northeast of Manhattan. And by Manhattan, I\nmean, it's a grid.",
    "start": "288840",
    "end": "296650"
  },
  {
    "text": "Again, and assume\nno node features. So that's what I mean\nby position-aware.",
    "start": "296650",
    "end": "302490"
  },
  {
    "text": "A graph neural\nnetwork will give you the same embedding\nfor these two nodes, even though they are on the\nopposite sides of the network.",
    "start": "302490",
    "end": "309840"
  },
  {
    "text": "And then also, the\nsecond observation is about different\nnetwork structures,",
    "start": "309840",
    "end": "315120"
  },
  {
    "text": "which we would like to map\ninto different embeddings.",
    "start": "315120",
    "end": "320880"
  },
  {
    "text": "In lecture 9 when we talked\nabout how powerful our graph neural networks, we discussed\nthat the expressive power",
    "start": "320880",
    "end": "327900"
  },
  {
    "text": "of GNNs is upper bounded\nby the expressive power of the Weisfeiler-Lehman\nGraph Isomorphism Test.",
    "start": "327900",
    "end": "336150"
  },
  {
    "text": "And one simple example where\nthis breaks is for example, GNN cannot count\nthe cycle length.",
    "start": "336150",
    "end": "342420"
  },
  {
    "text": "If you are a node on a\ncycle of length three, or you are a node on a\ncycle of length four,",
    "start": "342420",
    "end": "348479"
  },
  {
    "text": "your computation graphs\nwill be the same. You are a node, you\nhave two neighbors,",
    "start": "348480",
    "end": "354060"
  },
  {
    "text": "each of the neighbors\nhas two neighbors. And you can go make this\nas deep as possible, but the computation\ngraphs between V1 and V2",
    "start": "354060",
    "end": "361110"
  },
  {
    "text": "will be the same. So the GNN won't be able to\ndistinguish these two network",
    "start": "361110",
    "end": "366810"
  },
  {
    "text": "structures. Again, I'm not assuming any\nnode features or attributes",
    "start": "366810",
    "end": "372000"
  },
  {
    "text": "that would help me with this. So the plan for\ntoday's lecture is to look into these two kind\nof observations or issues.",
    "start": "372000",
    "end": "380170"
  },
  {
    "text": "One is the observation number\none, where we want nodes, even though they have the same\nnetwork structure around them,",
    "start": "380170",
    "end": "387990"
  },
  {
    "text": "we want them to be embedded\nin different points. This is called Position-aware\nGraph Neural Networks.",
    "start": "387990",
    "end": "395400"
  },
  {
    "text": "And then the second one, which\nsays that the Graph Neural Network cannot count\nthe size of the cycle.",
    "start": "395400",
    "end": "402270"
  },
  {
    "text": "I'll talk about a very simple\nidea, called Identity-aware or Graph Neural Networks.",
    "start": "402270",
    "end": "407280"
  },
  {
    "text": "That actually allows you\nto increase the expressive power of the GNN. So that's the plan\nfor the lecture.",
    "start": "407280",
    "end": "414630"
  },
  {
    "text": "And if we have time, I'll\nbriefly mention a bonus topic at the end. That's the plan.",
    "start": "414630",
    "end": "421000"
  },
  {
    "text": "So here is our\napproach and how we are going to think for\nthe rest of the lecture.",
    "start": "421000",
    "end": "427860"
  },
  {
    "text": "The idea is that given\ntwo different inputs,",
    "start": "427860",
    "end": "433770"
  },
  {
    "text": "we think of them as being\nlabeled differently. And we will say that\nfailed model will always",
    "start": "433770",
    "end": "440490"
  },
  {
    "text": "assign the same embedding\nto these different inputs. And a successful model will\nassign different embeddings",
    "start": "440490",
    "end": "446430"
  },
  {
    "text": "to these different inputs. And the key reasoning\nthat we are going to do",
    "start": "446430",
    "end": "453300"
  },
  {
    "text": "is to realize that the\nembedding created by the GNN is determined by the\ncomputation graph.",
    "start": "453300",
    "end": "460770"
  },
  {
    "text": "So here I have two nodes-- V1 and V2. And imagine that V1 is\nlabeled with label A,",
    "start": "460770",
    "end": "467130"
  },
  {
    "text": "and V2 is labeled by label B. The goal now is\nthat I want to do--",
    "start": "467130",
    "end": "472740"
  },
  {
    "text": "let's say node classification. And in order for me to\nclassify this one in one class and classify the other\none in the other class,",
    "start": "472740",
    "end": "479218"
  },
  {
    "text": "this means that the\nembeddings of these two nodes have to be different. So will this actually happen?",
    "start": "479218",
    "end": "489250"
  },
  {
    "text": "And as I was\nshowing you earlier, this may actually not happen.",
    "start": "489250",
    "end": "497400"
  },
  {
    "text": "I'll show you, I ignore\nthese zeros and ones for now. But imagine I have\ntwo different cycles,",
    "start": "497400",
    "end": "504720"
  },
  {
    "text": "and all the nodes\nhave no features. So all the features\nare the same. So their computation graphs\nwill be exactly the same.",
    "start": "504720",
    "end": "512529"
  },
  {
    "text": "So the embedding of V2\nis going to be the same as the embedding of V1. So you won't be able to\ndistinguish between them,",
    "start": "512530",
    "end": "519640"
  },
  {
    "text": "so you won't be able to\nclassify one into class A, and the other one\nin class B. You [? will either ?] classify\nboth, basically, they",
    "start": "519640",
    "end": "526440"
  },
  {
    "text": "will be assigned the same class. So what would be a\nnaive solution to this?",
    "start": "526440",
    "end": "531870"
  },
  {
    "text": "One naive solution, I\nwould say, the warning",
    "start": "531870",
    "end": "537660"
  },
  {
    "text": "is don't actually try\nthis because it's naive. But to give you a\nflavor, we can assign",
    "start": "537660",
    "end": "544079"
  },
  {
    "text": "each node a different ID. Then we can always differentiate\nbetween different nodes.",
    "start": "544080",
    "end": "549190"
  },
  {
    "text": "So I could say, this is my\nnode one, this is my node two, and this is my node--\nlet's say, four.",
    "start": "549190",
    "end": "555000"
  },
  {
    "text": "I just using this one\nhot indicator to label to account for the nodes.",
    "start": "555000",
    "end": "562260"
  },
  {
    "text": "And now everything\nbecomes distinguishable, because this one has neighbors\nwith one or the last spot,",
    "start": "562260",
    "end": "570810"
  },
  {
    "text": "and the one with\nthe second spot. And this one has neighbors\nat the second spot, and the second spot, so we\nare able to distinguish this.",
    "start": "570810",
    "end": "583110"
  },
  {
    "text": "So this would be\none possible way to say, OK, now, I can actually\ndistinguish these two nodes.",
    "start": "583110",
    "end": "590970"
  },
  {
    "text": "And as I'm looking at this,\nhere's actually a bug. It should be-- no, it's\nnot a bug, it's all good.",
    "start": "590970",
    "end": "596710"
  },
  {
    "text": "I'm just-- maybe--\nyeah, didn't see well. Great. So that's one way\nhow you could try",
    "start": "596710",
    "end": "603940"
  },
  {
    "text": "to distinguish these things. The issue is that now you\nneed a one hot encoding",
    "start": "603940",
    "end": "610360"
  },
  {
    "text": "for every node, so the\ndimensionality of every node will be proportional to the\nsize of the graph, which",
    "start": "610360",
    "end": "618370"
  },
  {
    "text": "is unfeasible and\nit's not inductive. I cannot generalize\nthis two new graphs.",
    "start": "618370",
    "end": "624830"
  },
  {
    "text": "I don't know how to\nlabel or how to assign this IDs to new graphs. So this is why\nthis is a bad idea.",
    "start": "624830",
    "end": "632620"
  },
  {
    "text": "But let me tell you now, how\none possible solution to this that's called Position-aware\nGraph Neural Networks.",
    "start": "632620",
    "end": "641500"
  },
  {
    "text": "That are going to\nsolve for this. And here is how\nwe think of this.",
    "start": "641500",
    "end": "647170"
  },
  {
    "text": "Imagine that generally speaking,\nthere are two types of tasks.",
    "start": "647170",
    "end": "652570"
  },
  {
    "text": "Again, approximately,\nthe two extreme types",
    "start": "652570",
    "end": "658660"
  },
  {
    "text": "of tasks in-- let's say node\nclassification in the graph. One is what you\ncould call or what",
    "start": "658660",
    "end": "663910"
  },
  {
    "text": "we call Structure-aware\ntask, and this would be a structure-aware\nlabeling of the node.",
    "start": "663910",
    "end": "671260"
  },
  {
    "text": "These two nodes have the same\nnetwork structure around them",
    "start": "671260",
    "end": "676570"
  },
  {
    "text": "so they get the same class. These two nodes have the same\nnetwork structure around them so they get the same class.",
    "start": "676570",
    "end": "682279"
  },
  {
    "text": "So this would be\nstructure-aware labeling. Just as an example. And here is a\nposition-aware task.",
    "start": "682280",
    "end": "689529"
  },
  {
    "text": "Nodes here on the left\nare labeled with A, and nodes on the right\nare labeled with B.",
    "start": "689530",
    "end": "696662"
  },
  {
    "text": "And the point is the following. For structure-aware tasks,\nthe computation graph",
    "start": "696662",
    "end": "702960"
  },
  {
    "text": "of nodes labeled\nwith A is going to be different than the computation\ngraph of nodes labeled with B.",
    "start": "702960",
    "end": "710290"
  },
  {
    "text": "Because here, he\nhas three neighbors, this node has two neighbors. So that's already a\ndifference, so the GNN",
    "start": "710290",
    "end": "716459"
  },
  {
    "text": "will be able to distinguish\nbetween these two. And GNNs will work\nbeautifully, and you'll",
    "start": "716460",
    "end": "721650"
  },
  {
    "text": "be able to learn\nthis classification. All good.",
    "start": "721650",
    "end": "727769"
  },
  {
    "text": "How about the position-aware\nlabeling of the graph? Here is this what I would\ncall, position-aware labeling",
    "start": "727770",
    "end": "735420"
  },
  {
    "text": "of the graph. So let's take-- this\nnode labeled with A, and let's take that other\nnode labeled with B,",
    "start": "735420",
    "end": "742200"
  },
  {
    "text": "let's look at their\ncomputation graphs. Actually, computation\ngraphs are identical. And you can go as deep in these\ncomputation graphs as you want,",
    "start": "742200",
    "end": "750390"
  },
  {
    "text": "they will still be identical. Because the two\nnodes, their positions",
    "start": "750390",
    "end": "755840"
  },
  {
    "text": "are isomorphic to each other. So the V1 and V2\nwill always have",
    "start": "755840",
    "end": "763540"
  },
  {
    "text": "the same computational graph\ndue to the structure symmetry, so the question\nbecomes, what could I",
    "start": "763540",
    "end": "771460"
  },
  {
    "text": "do so that my GNN would\nbe more expressive and would be able to capture\nthis difference between nodes A",
    "start": "771460",
    "end": "778180"
  },
  {
    "text": "and B? And learn that once\none set of nodes should be labeled one way,\nand the other set of nodes",
    "start": "778180",
    "end": "783519"
  },
  {
    "text": "should be labeled the other way. So that's the\nquestion we are trying",
    "start": "783520",
    "end": "789130"
  },
  {
    "text": "to address to make GNNs\nwork with this kind of graph",
    "start": "789130",
    "end": "794230"
  },
  {
    "text": "labeling task. So the key concept that\nI'm going to introduce",
    "start": "794230",
    "end": "800529"
  },
  {
    "text": "is the notion of an anchor. So we are going to have\nthis notion of an anchor,",
    "start": "800530",
    "end": "806000"
  },
  {
    "text": "and then we are going\nto generalize it to the notion of the anchor set.",
    "start": "806000",
    "end": "811360"
  },
  {
    "text": "The idea of the anchor\nis that anchor gives you a reference point. The problem with graphs is that\nthere is no reference point,",
    "start": "811360",
    "end": "818170"
  },
  {
    "text": "so you don't know in what\npart of the graph you are. So anchors will provide\nus reference points.",
    "start": "818170",
    "end": "824800"
  },
  {
    "text": "So the idea is\nthat I'm going to-- in this case, let's say randomly\npick a node, let's call it S1,",
    "start": "824800",
    "end": "832149"
  },
  {
    "text": "and I'll define that\nthat's an anchor node. So now, I will be able to\nrepresent positions V1,",
    "start": "832150",
    "end": "839470"
  },
  {
    "text": "V2 as some of how their\npositions relate with respect",
    "start": "839470",
    "end": "845139"
  },
  {
    "text": "to the location of the anchor. So in some sense, what\nwe are going to do, is we are going to develop\nsome positional encoding",
    "start": "845140",
    "end": "852460"
  },
  {
    "text": "in the graph so that nodes\nunderstand where in the graph they reside.",
    "start": "852460",
    "end": "858230"
  },
  {
    "text": "That's another way to\nsay what we are doing. So anchor serves as a\nreference point, point.",
    "start": "858230",
    "end": "865279"
  },
  {
    "text": "And can be used to\nbasically locate or define the position of the\nnode in the graph.",
    "start": "865280",
    "end": "871560"
  },
  {
    "text": "So if this is my anchor,\nthen for example, and let's say I quantify the\ndistance using the shortest",
    "start": "871560",
    "end": "878330"
  },
  {
    "text": "test, then V1 is one step\naway from the anchor V2, is two steps away\nfrom the anchor.",
    "start": "878330",
    "end": "884390"
  },
  {
    "text": "So now, if I would use\nthis as positional encoding",
    "start": "884390",
    "end": "890030"
  },
  {
    "text": "as a property of the node,\nthen the neural network would able to\ndistinguish these two nodes because they are\nat different distances",
    "start": "890030",
    "end": "897260"
  },
  {
    "text": "from the anchor. And to make the entire\nthing more robust",
    "start": "897260",
    "end": "903050"
  },
  {
    "text": "is we can pick\neven more anchors. We can have one anchor,\nhere's the second one. And the observation is that\nmore anchors can better",
    "start": "903050",
    "end": "911300"
  },
  {
    "text": "characterize nodes position in\ndifferent regions of the graph. So we want to have many anchors.",
    "start": "911300",
    "end": "917660"
  },
  {
    "text": "And now, we have\nmulti-dimensional positional encoding of the\nnode in the graph.",
    "start": "917660",
    "end": "924750"
  },
  {
    "text": "What turns out to be\nalso very, very useful, and I'll show you\nsome theory behind it,",
    "start": "924750",
    "end": "930990"
  },
  {
    "text": "is that we can generalize\nthis notion of an anchor to a notion of an anchor\nset, where an anchor set is",
    "start": "930990",
    "end": "937620"
  },
  {
    "text": "a set of nodes. And now a distance of the\nnode to the anchor set is the minimum distance\nof the node to any member",
    "start": "937620",
    "end": "946740"
  },
  {
    "text": "of the anchor set. OK. So it's like, what's my\ndistance to the closest anchor?",
    "start": "946740",
    "end": "952800"
  },
  {
    "text": "It's like, what's my distance\nto the closest petrol station? And there's a lot of\npetrol stations around. OK?",
    "start": "952800",
    "end": "958120"
  },
  {
    "text": "So why is this helpful? Because large anchor\nsets sometimes",
    "start": "958120",
    "end": "963540"
  },
  {
    "text": "may provide more precise\nposition estimation. And we can save on the total\nnumber of anchors, right?",
    "start": "963540",
    "end": "971280"
  },
  {
    "text": "So for example, here\nI denoted it here that's the disk S3, right?",
    "start": "971280",
    "end": "977040"
  },
  {
    "text": "So this would be node S1. And V3 is a size 2 anchor set. And now, the encoding\nwould be, for example, V3",
    "start": "977040",
    "end": "985660"
  },
  {
    "text": "is part of the anchor set. So it has distance 0 to it. While V1 has distance 1\nto the anchor set, right?",
    "start": "985660",
    "end": "993430"
  },
  {
    "text": "And the point is that if I would\nonly have anchors S1 and S2, they cannot differentiate,\nin my case, nodes V1 and V2.",
    "start": "993430",
    "end": "1001260"
  },
  {
    "text": "But this bigger\nanchor sets where I choose the distance\nto the closest one",
    "start": "1001260",
    "end": "1008940"
  },
  {
    "text": "allow me to better\ndifferentiate. Why do you do this way?",
    "start": "1008940",
    "end": "1015120"
  },
  {
    "text": "There's actually a very good\ntheoretical mathematical motivation to do that, right?",
    "start": "1015120",
    "end": "1020490"
  },
  {
    "text": "The way you can think of\nthis as the following. I'll paraphrase a bit of math\nhere to give you the intuition.",
    "start": "1020490",
    "end": "1027030"
  },
  {
    "text": "What we want to do is we want to\nembed metric space of vertices",
    "start": "1027030",
    "end": "1033780"
  },
  {
    "text": "and a distance function\ninto the Euclidean space, into K-dimensional\nEuclidean space.",
    "start": "1033780",
    "end": "1039959"
  },
  {
    "text": "Such that the original distance\nmetric is preserved, right? So it means for every node pair\nUV, the Euclidean embedding",
    "start": "1039960",
    "end": "1048990"
  },
  {
    "text": "distance between\ntheir embeddings is we want it to be close\nto their original distance",
    "start": "1048990",
    "end": "1055140"
  },
  {
    "text": "in the network, OK? And then there is\na beautiful theorem",
    "start": "1055140",
    "end": "1061110"
  },
  {
    "text": "that keeps popping up\nover and over again. It's called Bourgain Theorem.",
    "start": "1061110",
    "end": "1066639"
  },
  {
    "text": "And here is what Bourgain says. Informally, right? Imagine that I am considering\nthe following embedding",
    "start": "1066640",
    "end": "1075030"
  },
  {
    "text": "function. So the embedding of a node is\nsimply the minimum distance of the node to the first anchor\nset, to the second anchor set.",
    "start": "1075030",
    "end": "1083400"
  },
  {
    "text": "And I sample a log n.",
    "start": "1083400",
    "end": "1089850"
  },
  {
    "text": "And I sample anchor sets\nwhere the first index is",
    "start": "1089850",
    "end": "1096750"
  },
  {
    "text": "the number of anchor\nsets of a given size and the second index is the\nsize of the anchor set, right?",
    "start": "1096750",
    "end": "1104340"
  },
  {
    "text": "And here c is a constant.",
    "start": "1104340",
    "end": "1109409"
  },
  {
    "text": "Sij is chosen to include\neach node independently",
    "start": "1109410",
    "end": "1114450"
  },
  {
    "text": "with probability\n1 over 2 to the i. So it basically\nmeans that as I'm",
    "start": "1114450",
    "end": "1127649"
  },
  {
    "text": "sampling smaller anchor\nsets, they basically--",
    "start": "1127650",
    "end": "1132750"
  },
  {
    "text": "as I go more to\nthe right, my i is going to increase so the\nanchor sets are going",
    "start": "1132750",
    "end": "1138690"
  },
  {
    "text": "to get exponentially smaller. But that is going to be\nexponentially more of them, OK?",
    "start": "1138690",
    "end": "1144330"
  },
  {
    "text": "And here in my case the distance\nbetween the node and the given anchor set is the minimum\ndistance between the node v",
    "start": "1144330",
    "end": "1152100"
  },
  {
    "text": "and any member of\nthe anchor set. And what's the\npoint of all this?",
    "start": "1152100",
    "end": "1157485"
  },
  {
    "text": "The point is if you\nconstruct your anchor sets the following way, then\nthe embedding distance",
    "start": "1157485",
    "end": "1163529"
  },
  {
    "text": "produced by this\nembedding f is probably close to the original\ndistance metric.",
    "start": "1163530",
    "end": "1169260"
  },
  {
    "text": "That's the key. This is why we care about this.",
    "start": "1169260",
    "end": "1174520"
  },
  {
    "text": "What is happening\nhere is basically that we are generating\nmultiple anchor sets",
    "start": "1174520",
    "end": "1180990"
  },
  {
    "text": "of bigger and bigger sizes. But having fewer and\nfewer of them, right?",
    "start": "1180990",
    "end": "1186510"
  },
  {
    "text": "So we are going to have a\nlot of anchor sets of size 1, fewer anchor sets of\nsize 2, even fewer anchor",
    "start": "1186510",
    "end": "1194370"
  },
  {
    "text": "sets of size 3, and so on. But we are going to have this\nmany of them with increasing",
    "start": "1194370",
    "end": "1201240"
  },
  {
    "text": "sizes, but with decreasing\nnumbers of them. And if that is happening, then\nthe following fact is true.",
    "start": "1201240",
    "end": "1211230"
  },
  {
    "text": "Yes. So like how is disembedding\ndifferent from node to egg. So in node to [? ECK. ?] We\nalso like some embeddings",
    "start": "1211230",
    "end": "1217830"
  },
  {
    "text": "with the nodes. Aha. Good question. So the question is, how\nthe nodes disembedding different from node to ECK.",
    "start": "1217830",
    "end": "1227380"
  },
  {
    "text": "Node to ECK the\nintuition there was to predict these neighborhoods.",
    "start": "1227380",
    "end": "1233540"
  },
  {
    "text": "And what I showed you in terms\nof theoretical properties, node to ECK boils down to a\nparticular matrix factorization",
    "start": "1233540",
    "end": "1244370"
  },
  {
    "text": "approach of a particularly\ntransformed your graph adjacency matrix, right? I think I showed you some\nugly fat equation, right?",
    "start": "1244370",
    "end": "1252440"
  },
  {
    "text": "Here this is different. This was actually\nthe Bourgain theorem",
    "start": "1252440",
    "end": "1257900"
  },
  {
    "text": "usually was developed\nfor vector spaces, right?",
    "start": "1257900",
    "end": "1263630"
  },
  {
    "text": "And here I'm rephrasing\nit in terms of the graph. But the idea is that\nbasically, if you have a high\ndimensional space, then",
    "start": "1263630",
    "end": "1270260"
  },
  {
    "text": "you can basically\ndefine a set of anchors in this high dimensional space. Determine your log position\naccording to those anchors,",
    "start": "1270260",
    "end": "1278149"
  },
  {
    "text": "and the distances are\ngoing to be preserved. So this is much more\ngeometric intuition, OK?",
    "start": "1278150",
    "end": "1284450"
  },
  {
    "text": "Yes. In practice, does\nit matter what we take from the vertices metric?",
    "start": "1284450",
    "end": "1290990"
  },
  {
    "text": "A good question. So the question is,\nwhat do we pick for D? What people like\nto pick in graphs",
    "start": "1290990",
    "end": "1297860"
  },
  {
    "text": "is the shortest path distance. You could also do\nsome more random walk distance or something like\nthat that you would try.",
    "start": "1297860",
    "end": "1305630"
  },
  {
    "text": "I mean, this will depend\non the application. But I think the point being--",
    "start": "1305630",
    "end": "1314130"
  },
  {
    "text": " yeah, good question.",
    "start": "1314130",
    "end": "1319200"
  },
  {
    "text": "I think the point is\nthat this distance has to be that distance, right?",
    "start": "1319200",
    "end": "1324410"
  },
  {
    "text": "So these two distances\nhave to be compatible. OK? Yes. So if I want to [INAUDIBLE]\nand multiple different graph",
    "start": "1324410",
    "end": "1331399"
  },
  {
    "text": "into a vector space, does\nit matter each of the graph has the same consistent\nanchor selections?",
    "start": "1331400",
    "end": "1337160"
  },
  {
    "text": "Or I can have a different\ntype of anchor Slack for each of the different [INAUDIBLE]? Great question.",
    "start": "1337160",
    "end": "1342860"
  },
  {
    "text": "So what you were\nasking me about, if I have multiple graphs, multiple\nanchor sets, what do I do?",
    "start": "1342860",
    "end": "1348470"
  },
  {
    "text": "Let me address that later\nBecause what you are really asking me, is this inductive\nversus transductive.",
    "start": "1348470",
    "end": "1355400"
  },
  {
    "text": "Because as soon as you\ndefine an anchor set, you have forced yourself\nto pick a set of nodes,",
    "start": "1355400",
    "end": "1360740"
  },
  {
    "text": "And that's problematic. I'm going to address that.",
    "start": "1360740",
    "end": "1366470"
  },
  {
    "text": "So the motivation for\ndefinition development",
    "start": "1366470",
    "end": "1372679"
  },
  {
    "text": "of the position of\nGNN is basically follows this Bourgain theorem,\nWhere basically the idea is",
    "start": "1372680",
    "end": "1379070"
  },
  {
    "text": "that we are going to sample\nsome logarithmic number squared",
    "start": "1379070",
    "end": "1387110"
  },
  {
    "text": "of anchor sets, and then\nembed each node based on the distances to\nthese anchor sets.",
    "start": "1387110",
    "end": "1394070"
  },
  {
    "text": "And what then becomes\nharder, and this is exactly the question, you\nwere asking me, is, how do you maintain\ninductive capability?",
    "start": "1394070",
    "end": "1402020"
  },
  {
    "text": "How can you generalize from\none graph to another graph? Because nodes are different. Anchor sets will be different.",
    "start": "1402020",
    "end": "1407419"
  },
  {
    "text": "And the way this is\nsolved in the paper is that during training,\nnew anchor sets",
    "start": "1407420",
    "end": "1412909"
  },
  {
    "text": "are resampled every time. So you make these\nanchor sets move around,",
    "start": "1412910",
    "end": "1417919"
  },
  {
    "text": "And the position of\nGNN is then to operate over new anchor sets.",
    "start": "1417920",
    "end": "1423950"
  },
  {
    "text": "And at test time when\ngiven a new graph, you can simply sample\nanchor sets at random.",
    "start": "1423950",
    "end": "1431720"
  },
  {
    "text": " To summarize what\nis important is",
    "start": "1431720",
    "end": "1437730"
  },
  {
    "text": "that when you represent\nthe positional information, we represent node\nby its positions",
    "start": "1437730",
    "end": "1445110"
  },
  {
    "text": "to randomly selected\nanchor sets. And each dimension\nof the position is tied now a given anchor set.",
    "start": "1445110",
    "end": "1455520"
  },
  {
    "text": "Now, how do you use\npositional information? I would say the following. If you are inside\none graph and you",
    "start": "1455520",
    "end": "1462480"
  },
  {
    "text": "are learning in a more\nsemi-supervised setting way, then a simple way is to use\nthis positional encoding",
    "start": "1462480",
    "end": "1469650"
  },
  {
    "text": "as a simple augmented\nnode feature to add this additional\ninformation to the GNN",
    "start": "1469650",
    "end": "1476040"
  },
  {
    "text": "to be able to learn. And that works really well in\nthe semi-supervised learning,",
    "start": "1476040",
    "end": "1483150"
  },
  {
    "text": "where you are given one graph. And the anchor\nsets can be fixed. Now, if you want to--",
    "start": "1483150",
    "end": "1489060"
  },
  {
    "text": "the issue with this is that\neach dimension of the position is tied to a\nparticular anchor set.",
    "start": "1489060",
    "end": "1495030"
  },
  {
    "text": "So the dimension of the\npositional encoding cannot be changed or randomly permuted\nwithout changing its meaning.",
    "start": "1495030",
    "end": "1504940"
  },
  {
    "text": "So the position of\nGraph Neural Networks paper, actually develops\na special neural network",
    "start": "1504940",
    "end": "1512830"
  },
  {
    "text": "that can maintain this\npermutational invariant property of\npositional encodings.",
    "start": "1512830",
    "end": "1519400"
  },
  {
    "text": "And permuting the\ninput feature dimension will only result in the\npermutation of the output",
    "start": "1519400",
    "end": "1526480"
  },
  {
    "text": "dimension. And this means that the value\nof each dimension won't change.",
    "start": "1526480",
    "end": "1533320"
  },
  {
    "text": "And more details are in the\nposition of our Graph Neural",
    "start": "1533320",
    "end": "1538769"
  },
  {
    "text": "Networks paper, but the\nidea is the following. If I look at my distance towards\nall sides one anchor sets.",
    "start": "1538770",
    "end": "1547380"
  },
  {
    "text": "Then if I have sampled enough\nsize one anchor sets, then of course, I sampled\nthem in different order",
    "start": "1547380",
    "end": "1554310"
  },
  {
    "text": "but my distribution\nof distances to them will be unchanged if I'm in\na given part of the graph.",
    "start": "1554310",
    "end": "1561540"
  },
  {
    "text": "Kind of in the limit. So that's that when I say\nthis permutation invariant,",
    "start": "1561540",
    "end": "1567540"
  },
  {
    "text": "I want to be basically-- I want my positional encoding to\ndepend on the anchor set size, but not the exact locations or\npositions or the order in which",
    "start": "1567540",
    "end": "1576570"
  },
  {
    "text": "I sampled the anchor sets. That's further\ndetails in this paper.",
    "start": "1576570",
    "end": "1583920"
  },
  {
    "text": "Yes. Can you go back two slides? One, two. Oh, sorry to the slide that\nhas more [? games ?] here",
    "start": "1583920",
    "end": "1590760"
  },
  {
    "text": "embedding function. Yes. Just a clarification question. If we use the embedding function\nthat is described there,",
    "start": "1590760",
    "end": "1600309"
  },
  {
    "text": "the application of\nthis is that it's only using the first layer? We initialize our node features\nwith that vector, right?",
    "start": "1600310",
    "end": "1608289"
  },
  {
    "text": "Yes. So again, one-- let's\nmake a difference between what the\nBourgain is saying",
    "start": "1608290",
    "end": "1614500"
  },
  {
    "text": "and then what we are doing. What Bourgain is saying,\nif you are embedding",
    "start": "1614500",
    "end": "1620530"
  },
  {
    "text": "your nodes the following way,\nand if you are embedding them in a space that has\nthe logarithmic size",
    "start": "1620530",
    "end": "1630820"
  },
  {
    "text": "with the number of nodes,\nwhich is great, exponentially smaller dimension than\nthe number of nodes,",
    "start": "1630820",
    "end": "1636070"
  },
  {
    "text": "then your distances\nwill be preserved. ",
    "start": "1636070",
    "end": "1641289"
  },
  {
    "text": "Like in some sense in\nthe position of GNN, we don't care about\npreserving distances. We care about correct\nclassification.",
    "start": "1641290",
    "end": "1648880"
  },
  {
    "text": "So we have a bit different goal. And this is not the embedding\nfunction we are using,",
    "start": "1648880",
    "end": "1654610"
  },
  {
    "text": "we learn a Graph Neural\nNetwork to learn the embedding, because we want to do\ndownstream prediction.",
    "start": "1654610",
    "end": "1660460"
  },
  {
    "text": "But our choice of\nanchor sets and why",
    "start": "1660460",
    "end": "1666220"
  },
  {
    "text": "we like them is because is\nmotivated by the Bourgain theorem. ",
    "start": "1666220",
    "end": "1673480"
  },
  {
    "text": "Bourgain is a motivation,\nit's an abstract motivation.",
    "start": "1673480",
    "end": "1680380"
  },
  {
    "text": "They don't follow it strictly. So that's a good point. Sorry if that was confusing.",
    "start": "1680380",
    "end": "1686580"
  },
  {
    "text": "Yes. If you go back to where we\nare forward in the slides, were you saying that this is--",
    "start": "1686580",
    "end": "1693500"
  },
  {
    "text": "forward again. So more forward. [LAUGHS] Yeah. So is this saying essentially\nthat the distances",
    "start": "1693500",
    "end": "1701330"
  },
  {
    "text": "to the anchor nodes for\neach individual vertex is follows the same\ndistribution each time",
    "start": "1701330",
    "end": "1706662"
  },
  {
    "text": "you relabel the anchor nodes. So that distribution\nis sort of invariant? That's basically the idea.",
    "start": "1706662",
    "end": "1712760"
  },
  {
    "text": "Exactly.  I know if I'm in a graph and\nI sample 100 different nodes",
    "start": "1712760",
    "end": "1719240"
  },
  {
    "text": "and I look my distribution\nof distances to those-- Yeah. --That distribution will\nbe quite stable regardless",
    "start": "1719240",
    "end": "1725450"
  },
  {
    "text": "of which specific 100-- I mean, 100 again. I pull that number out of the\nhat, of course, it will depend.",
    "start": "1725450",
    "end": "1733820"
  },
  {
    "text": "But that's the idea\nthat kind of stabilizes. ",
    "start": "1733820",
    "end": "1739250"
  },
  {
    "text": "Based on the structure\nof the graph. Yeah. I haven't been able to get\nmy head around why you might want sets of differing sizes.",
    "start": "1739250",
    "end": "1747320"
  },
  {
    "text": "Why don't you just always\nwant make a set of size 1?",
    "start": "1747320",
    "end": "1752360"
  },
  {
    "text": "That's a good question. So the question is,\nwhy is it better to have anchor sets\nof bigger sizes,",
    "start": "1752360",
    "end": "1762320"
  },
  {
    "text": "why not always sets of size 1? The point is the following.",
    "start": "1762320",
    "end": "1767540"
  },
  {
    "text": "The anchor set of\na bigger size will",
    "start": "1767540",
    "end": "1772760"
  },
  {
    "text": "require you one dimension\nin your positional encoding, but in some sense, it will\nprovide much more information",
    "start": "1772760",
    "end": "1781730"
  },
  {
    "text": "because the variance of\nthat will be smaller. Because you can think of\nthat defines some boundary",
    "start": "1781730",
    "end": "1787530"
  },
  {
    "text": "and you just say, how far\naway from the border am I? It's a different\ntype of an object",
    "start": "1787530",
    "end": "1793070"
  },
  {
    "text": "that you are measuring\nyour distance to. So good. Yes.",
    "start": "1793070",
    "end": "1798500"
  },
  {
    "text": "In some applications\nwill be better to merely engineering consensus\nupon the [? randomly? ?]",
    "start": "1798500",
    "end": "1804740"
  },
  {
    "text": "Good question. So the question is, would\nin some applications be good to maybe not\nsample anchor sets",
    "start": "1804740",
    "end": "1812330"
  },
  {
    "text": "randomly and engineer them? I would say yes, if you\nhave a good reason why.",
    "start": "1812330",
    "end": "1817530"
  },
  {
    "text": "Again, the reason\nwe do it randomly is because then you are-- I don't have to say anything\nabout what the data you do it.",
    "start": "1817530",
    "end": "1823940"
  },
  {
    "text": "And again, you could-- I know, for\nmolecules, it might be",
    "start": "1823940",
    "end": "1829550"
  },
  {
    "text": "interesting to be\nmore strategic, what are you going to choose. Cool. So that finishes the\ndiscussion of my first point,",
    "start": "1829550",
    "end": "1838320"
  },
  {
    "text": "which was this Position-aware\nencoding of nodes. So that a nodes knows\nwhat part of the graph",
    "start": "1838320",
    "end": "1845120"
  },
  {
    "text": "it belongs to, so\nthat it can determine its embedding, its label based\non the region of the graph",
    "start": "1845120",
    "end": "1852380"
  },
  {
    "text": "they belong to, and\nnot necessarily based on the exact neighborhood\nstructure that they have. So that was the intuition here.",
    "start": "1852380",
    "end": "1860230"
  },
  {
    "text": "So let's now talk about\nthe second issue, which we said that right\nin Position-aware",
    "start": "1860230",
    "end": "1867780"
  },
  {
    "text": "we say, even though nodes\nhave the same network structure around them,\nwe want them to be",
    "start": "1867780",
    "end": "1873779"
  },
  {
    "text": "embedded in different places. Now, we are going to look at\nwhat is called Identity-aware",
    "start": "1873780",
    "end": "1881309"
  },
  {
    "text": "Graph Neural Networks. And the point here\nis that I want nodes that appear in\ndifferent structures to actually be\nembedded differently.",
    "start": "1881310",
    "end": "1890340"
  },
  {
    "text": "So far, the summary\nis that we learned, the GNN should fail for\nposition of our task",
    "start": "1890340",
    "end": "1895590"
  },
  {
    "text": "and we develop the\nposition of GNN with positional encoding that\nallows us to fix that problem.",
    "start": "1895590",
    "end": "1902940"
  },
  {
    "text": "Then the question is, can\nGNNs perform perfectly on structure-aware tasks? And the answer is no.",
    "start": "1902940",
    "end": "1910170"
  },
  {
    "text": "Why is the answer no? Is because GNNs exhibit failure\ncases at structure-aware tasks",
    "start": "1910170",
    "end": "1919230"
  },
  {
    "text": "at all different-- at node level, edge\nlevel, and graph level because graphs\ncan be highly symmetric,",
    "start": "1919230",
    "end": "1926040"
  },
  {
    "text": "and the WL test\nis going to fail. And I gave you this example,\nwhere I have two nodes--",
    "start": "1926040",
    "end": "1932760"
  },
  {
    "text": "V1 and V2 in obviously\nin different graphs. But if I look at the\nshape, the structure",
    "start": "1932760",
    "end": "1939810"
  },
  {
    "text": "of the GNN computation graph,\nwhich we established in lecture nine that basically\nthis is based",
    "start": "1939810",
    "end": "1947190"
  },
  {
    "text": "on how the embedding of\nthe node gets created. And if the two computation\ngraphs are identical,",
    "start": "1947190",
    "end": "1955830"
  },
  {
    "text": "are isomorphic, then the\nembedding of the two nodes is going to be identical. So there's no way for\nus to distinguish them",
    "start": "1955830",
    "end": "1962160"
  },
  {
    "text": "or to assign them to\ndifferent classes. So this is for example for\nnode classification tasks.",
    "start": "1962160",
    "end": "1969760"
  },
  {
    "text": "I can show you examples also\nfor link prediction tasks. Imagine I have a node 0, and\nthen I have nodes V1 and V2.",
    "start": "1969760",
    "end": "1979409"
  },
  {
    "text": "And the question is, can\nI differentiate between V0",
    "start": "1979410",
    "end": "1990550"
  },
  {
    "text": "linking to node V1, but\nnot linking to node V2. Again, node V0 will\nhave some embedding,",
    "start": "1990550",
    "end": "1997420"
  },
  {
    "text": "but V1 and V2 have\nthe same computation graphs so they'll have\nthe same embedding.",
    "start": "1997420",
    "end": "2002580"
  },
  {
    "text": "So I will either predict that\nV0 links to both V1 and V2",
    "start": "2002580",
    "end": "2007769"
  },
  {
    "text": "or that it links\nto none of them. Again, I cannot my embedding\nwon't distinguish V1 and V2,",
    "start": "2007770",
    "end": "2014370"
  },
  {
    "text": "so there will be no way for\nus to say V0 links to 1 to 1 but not the other.",
    "start": "2014370",
    "end": "2020580"
  },
  {
    "text": "And then how about\nat the graph level? Graph. At graph level, it's also\nbecomes quite interesting.",
    "start": "2020580",
    "end": "2028980"
  },
  {
    "text": "If I have two\ndifferent input graphs,",
    "start": "2028980",
    "end": "2035380"
  },
  {
    "text": "but if I look at their\ncomputation graphs, again, they'll be identical.",
    "start": "2035380",
    "end": "2041210"
  },
  {
    "text": "So even at the graph\nembedding level, these two different graphs will\nbe embedded into the same point",
    "start": "2041210",
    "end": "2047410"
  },
  {
    "text": "so we won't be able to\nclassify them differently. So that's a set of\nissues with GNNs.",
    "start": "2047410",
    "end": "2056500"
  },
  {
    "text": "Again, if you don't\nhave node attributes that would allow you\nto distinguish this.",
    "start": "2056500",
    "end": "2061960"
  },
  {
    "text": "Many times, I know you'll\nbe lucky or I don't know. You have good node\nattributes, and then things",
    "start": "2061960",
    "end": "2068408"
  },
  {
    "text": "start to work out. But without node\nattributes and just focusing on the graph structure,\nGNNs suffer from this problems.",
    "start": "2068409",
    "end": "2078800"
  },
  {
    "text": "So here's an idea. Idea is very simple. It's basically the idea is to\nhave inductive node coloring.",
    "start": "2078800",
    "end": "2087658"
  },
  {
    "text": "We can assign a color to\nthe node we want to embed. If I want to do\nthings inductively,",
    "start": "2087659",
    "end": "2094679"
  },
  {
    "text": "then I always know who is\nthe node that I care about. That is the root of\nmy computation graph.",
    "start": "2094679",
    "end": "2101130"
  },
  {
    "text": "So what if I label that node? And I treat that node\ndifferently-- specially.",
    "start": "2101130",
    "end": "2108599"
  },
  {
    "text": "Let's say here, the\nyellow orange node is the node we want\nto embed, and then",
    "start": "2108600",
    "end": "2115470"
  },
  {
    "text": "the white nodes are\nthe rest of the nodes. So then if you look at this,\nthen the computation graph",
    "start": "2115470",
    "end": "2123930"
  },
  {
    "text": "is going to look like that. I'm going to remember\nwhen the computation graph visits the colored node.",
    "start": "2123930",
    "end": "2131190"
  },
  {
    "text": "So I here, I go to the\ntwo neighbors, and then the two neighbors, one goes\nback, and one goes here.",
    "start": "2131190",
    "end": "2139180"
  },
  {
    "text": "So I'm here, and\nso on and so forth. So this is now my\ncomputation graph, and here's the computation\ngraph if I show you",
    "start": "2139180",
    "end": "2149260"
  },
  {
    "text": "the identities of the nodes. But notice now that I have a\nbit more interesting pattern",
    "start": "2149260",
    "end": "2155530"
  },
  {
    "text": "here that GNN could\ncapture because it knows the color of the node.",
    "start": "2155530",
    "end": "2160900"
  },
  {
    "text": "And assigning a color\nto the node of interest is inductive in a sense,\nI can transfer the model",
    "start": "2160900",
    "end": "2167230"
  },
  {
    "text": "to a new graph because\nthere's always-- whenever I embed, I know what\nnode I'm trying to embed.",
    "start": "2167230",
    "end": "2175650"
  },
  {
    "text": "So the point is this\ncoloring is inductive, it is invariant to the\nnode ordering or identities",
    "start": "2175650",
    "end": "2182760"
  },
  {
    "text": "of the nodes. I can relabel the nodes,\nI can renumber them,",
    "start": "2182760",
    "end": "2188670"
  },
  {
    "text": "but the structure, the shape\nof this computation graph and the pattern of\nwhite versus orange",
    "start": "2188670",
    "end": "2194580"
  },
  {
    "text": "is going to stay the same. So here I have 1, 2, 3.",
    "start": "2194580",
    "end": "2199859"
  },
  {
    "text": "Here I have 1, 2, 3,\nbut the color pattern",
    "start": "2199860",
    "end": "2205710"
  },
  {
    "text": "in the computation\ngraph, remains the same. It's kind of trivial,\nbut it's important.",
    "start": "2205710",
    "end": "2212850"
  },
  {
    "text": "So that's the first one. So I have now an\ninductive capability.",
    "start": "2212850",
    "end": "2218460"
  },
  {
    "text": "How about does this increase\nmy predictive power?",
    "start": "2218460",
    "end": "2223740"
  },
  {
    "text": "And it does. Because if I take\nnow the two graphs--",
    "start": "2223740",
    "end": "2229710"
  },
  {
    "text": "the triangle and a square\nand I do know classification and I say, OK, what\nis now the computation",
    "start": "2229710",
    "end": "2237010"
  },
  {
    "text": "graph for V1 versus V2? It will actually be different.",
    "start": "2237010",
    "end": "2242450"
  },
  {
    "text": "Because this is for V1\nwe already worked it out, but for V2, it\nwill be different.",
    "start": "2242450",
    "end": "2247730"
  },
  {
    "text": "I'm going from V2 to\nneighbors, from neighbors",
    "start": "2247730",
    "end": "2252800"
  },
  {
    "text": "I go either back to V1, or I\ngo to the next neighbor here.",
    "start": "2252800",
    "end": "2258170"
  },
  {
    "text": "But from here on, I\ndon't get to V2 again. So at this level, the\npattern is different.",
    "start": "2258170",
    "end": "2265830"
  },
  {
    "text": "So my GNN, if it accounts\nfor the color as well, we'll be able to\ndistinguish these two nodes.",
    "start": "2265830",
    "end": "2272250"
  },
  {
    "text": "So basically, I'm in\nsome sense able now to count the length\nof the cycle because I",
    "start": "2272250",
    "end": "2278089"
  },
  {
    "text": "see when does the GNN come\nback to where it started.",
    "start": "2278090",
    "end": "2283310"
  },
  {
    "text": "And I see here, it comes\nback in three steps, while here it will need\nfour steps at this level.",
    "start": "2283310",
    "end": "2292490"
  },
  {
    "text": "At this level, I'm going\nto see only empty nodes-- sorry-- white nodes,\nand then here, I'll start seeing\norange nodes again.",
    "start": "2292490",
    "end": "2300750"
  },
  {
    "text": "And if you use\nthis simple trick, then things start to\nwork out very nicely.",
    "start": "2300750",
    "end": "2307829"
  },
  {
    "text": "Here is for graph\nclassification A and B. Even though computation graphs\nwill have the same structure,",
    "start": "2307830",
    "end": "2313380"
  },
  {
    "text": "the identity of\nthe starting node is going to make this\npattern be different",
    "start": "2313380",
    "end": "2321720"
  },
  {
    "text": "from the other pattern. So I'll be able to distinguish\nnode A from node B.",
    "start": "2321720",
    "end": "2330171"
  },
  {
    "text": "And when I say, why do I\ncall this class of models identity-aware?",
    "start": "2330171",
    "end": "2335940"
  },
  {
    "text": "Because it's aware of\nthe identity of the node that we want to embed.",
    "start": "2335940",
    "end": "2343920"
  },
  {
    "text": "And this is my last example,\nwhich is about link prediction.",
    "start": "2343920",
    "end": "2349089"
  },
  {
    "text": "And I'm trying to create\nan embedding for V1, and I want to try it for V2. And again, if I look at\nthe computation graphs,",
    "start": "2349090",
    "end": "2356130"
  },
  {
    "text": "they're going to\ndiffer at two levels. When I go from V1, I go to\nthe neighbor, and neighbor",
    "start": "2356130",
    "end": "2361810"
  },
  {
    "text": "of neighbor and, I can visit V0. While if I start at V2, I'm not\nable to visit V0 in two hops.",
    "start": "2361810",
    "end": "2369640"
  },
  {
    "text": "So because these two computation\ngraphs are different, these two nodes are\ngoing to be embedded",
    "start": "2369640",
    "end": "2375130"
  },
  {
    "text": "in different positions. And I'll be able to\nsay, link A occurs",
    "start": "2375130",
    "end": "2382990"
  },
  {
    "text": "but link B does not occur,\nor something like that. So that's the idea that I wanted\nto convey in an abstract way",
    "start": "2382990",
    "end": "2397480"
  },
  {
    "text": "about this being\nable to differentiate",
    "start": "2397480",
    "end": "2404750"
  },
  {
    "text": "between different nodes\nby using this simple, very cute idea of labeling the\nstarting node-- the node",
    "start": "2404750",
    "end": "2414650"
  },
  {
    "text": "of interest. Now, what I want to do\nnext is actually show you how to build a GNN using\nthis type of node coloring.",
    "start": "2414650",
    "end": "2424069"
  },
  {
    "text": "That's what I want\nto show to you. So I want to now show you how\nto build a Graph Neural Network.",
    "start": "2424070",
    "end": "2431570"
  },
  {
    "text": "Actually, its architecture. And how to take account\ninto this node colors when we are doing propagation.",
    "start": "2431570",
    "end": "2438080"
  },
  {
    "text": "And the idea is that\nwe are going to do heterogeneous message passing.",
    "start": "2438080",
    "end": "2444020"
  },
  {
    "text": "Generally, normally GNN applies\nthe same message aggregation computation function to all the\nneighbors, to all the nodes.",
    "start": "2444020",
    "end": "2450845"
  },
  {
    "text": " Right in a sense that\nat the GNN layer,",
    "start": "2450845",
    "end": "2457430"
  },
  {
    "text": "we apply the same message\naggregation to each children or to each node below us.",
    "start": "2457430",
    "end": "2464520"
  },
  {
    "text": "What we are going\nto do in a ID-GNN is that we are going to do\nheterogeneous message passing.",
    "start": "2464520",
    "end": "2471630"
  },
  {
    "text": "Heterogeneous in a sense\nthat different types of message passing are\napplied to different nodes.",
    "start": "2471630",
    "end": "2477270"
  },
  {
    "text": "So ID-GNN will apply a different\nmessage aggregation function to nodes of different colors.",
    "start": "2477270",
    "end": "2483690"
  },
  {
    "text": "And I only have nodes\nof orange and white, but that's already good. So I'm going to apply\na different aggregation",
    "start": "2483690",
    "end": "2492090"
  },
  {
    "text": "or transformation here, then\nI apply it to white nodes.",
    "start": "2492090",
    "end": "2497920"
  },
  {
    "text": "So at a given layer,\ndifferent message aggregations is going to apply based\non the color of the node.",
    "start": "2497920",
    "end": "2507990"
  },
  {
    "text": "So to be a bit more\nformal and precise, like h is our node embedding.",
    "start": "2507990",
    "end": "2515730"
  },
  {
    "text": "And let's say that I first\nextract the K-hop computation graph, here I label it with\nG raised to the power K.",
    "start": "2515730",
    "end": "2526030"
  },
  {
    "text": "And then, I'm given some set\nthe initial node features",
    "start": "2526030",
    "end": "2532900"
  },
  {
    "text": "at layer zero. That's the input. And now, the way my\naggregation is going to go",
    "start": "2532900",
    "end": "2540100"
  },
  {
    "text": "is the following right for-- now, I'm going for all the\nnodes in the computation graph,",
    "start": "2540100",
    "end": "2547510"
  },
  {
    "text": "and I'm aggregating the fall. I have a message function\nthat is going to change,",
    "start": "2547510",
    "end": "2555730"
  },
  {
    "text": "depending whether the\nnode of interest S is the starting node--",
    "start": "2555730",
    "end": "2562720"
  },
  {
    "text": "sorry-- depending the\nnode of interest v is equal to the center node\nto the node of interest or not",
    "start": "2562720",
    "end": "2570790"
  },
  {
    "text": "and we are going to use\ndifferent neural network functions to transform\nto the embeddings.",
    "start": "2570790",
    "end": "2578290"
  },
  {
    "text": "So the color gets\nconsidered here.",
    "start": "2578290",
    "end": "2583660"
  },
  {
    "text": "The root node-- the\nnode of interest gets a different\ncolor, so it gets to have a different\nmessage function.",
    "start": "2583660",
    "end": "2591170"
  },
  {
    "text": "It means, it gets to have\ndifferent parameters. So why does this heterogeneous\nmessage passing work?",
    "start": "2591170",
    "end": "2600400"
  },
  {
    "text": "Suppose I have two\nnodes that have the same computational\ngraph structure but have different\nnode colorings.",
    "start": "2600400",
    "end": "2607260"
  },
  {
    "text": "Since we apply different neural\nnetwork embedding computation, their embeddings are also\ngoing to be different.",
    "start": "2607260",
    "end": "2614610"
  },
  {
    "text": "Here, I'm going to\napply message function A to all of these\nnodes, while here, I'm",
    "start": "2614610",
    "end": "2621599"
  },
  {
    "text": "going to apply a different\nmessage function B these nodes so the messages are\ngoing to be different,",
    "start": "2621600",
    "end": "2628140"
  },
  {
    "text": "and neural network will be able\nto capture that difference. Yes. Is it possible that the\nloss function won't transfer",
    "start": "2628140",
    "end": "2635220"
  },
  {
    "text": "any information, such\nthat the weights that are developed by neural\nnet A and B are actually any different?",
    "start": "2635220",
    "end": "2641730"
  },
  {
    "text": "Is there a case where the\nnode coloring won't be useful, and so this heterogeneous\nmessage passing would just",
    "start": "2641730",
    "end": "2647850"
  },
  {
    "text": "like wash out? Good question. So you are saying, if I train\nthese heterogeneous neural",
    "start": "2647850",
    "end": "2654450"
  },
  {
    "text": "network, I initialize with some\nrandom parameters this guy, I initialize with some\nrandom parameters that guy.",
    "start": "2654450",
    "end": "2661540"
  },
  {
    "text": "Why wouldn't just\nboth neural networks converge to the same thing?",
    "start": "2661540",
    "end": "2667100"
  },
  {
    "text": "And I think the answer is\nthey might, but they won't,",
    "start": "2667100",
    "end": "2673930"
  },
  {
    "text": "if the identity\ninformation is important because nodes have different\nlabels even though they",
    "start": "2673930",
    "end": "2682390"
  },
  {
    "text": "live on different cycles. So it depends on\nhow the labels are. If the labels are such that the\ncycle length doesn't matter,",
    "start": "2682390",
    "end": "2690940"
  },
  {
    "text": "then it's OK for it to\nconverge to the same thing. But if we want to\ndistinguish, then these things",
    "start": "2690940",
    "end": "2699130"
  },
  {
    "text": "won't shouldn't converge. Won't converge to\nthe same thing. Yes. So we have a different message\nfor each node in the graph?",
    "start": "2699130",
    "end": "2706640"
  },
  {
    "text": "Do we have a different message? No, I mean, what do you mean\nwe have a different node? Different neural net A, B, C.",
    "start": "2706640",
    "end": "2712740"
  },
  {
    "text": "No, no, no. We just have two. One is for white, and\none is for yellow. That's it.",
    "start": "2712740",
    "end": "2718819"
  },
  {
    "text": "I have just two kind of neural\nand I have just two message functions. Message functions that I'm\napplying to these nodes,",
    "start": "2718820",
    "end": "2725228"
  },
  {
    "text": "and message functions that\nI'm applying to those nodes. ",
    "start": "2725228",
    "end": "2730670"
  },
  {
    "text": "Happy? How many nodes can\nwe add [INAUDIBLE]?? I just have two colors. I only know who the root\nis, and everyone else",
    "start": "2730670",
    "end": "2737540"
  },
  {
    "text": "looks the same to me. Yeah, it's just two. Yes. I just connecting\nthis [INAUDIBLE] in with the position\nwhere [? GNN ?] in.",
    "start": "2737540",
    "end": "2743990"
  },
  {
    "text": "Is one way of thinking about\nthis [INAUDIBLE] similar to. If the node we're embedding\nis just the anchor node,",
    "start": "2743990",
    "end": "2750320"
  },
  {
    "text": "is that a way of thinking\nabout what it means to color? Interesting. So you are saying is\nthinking of the color,",
    "start": "2750320",
    "end": "2759559"
  },
  {
    "text": "the same as thinking\nabout the anchor?",
    "start": "2759560",
    "end": "2764630"
  },
  {
    "text": "Not really. Not really. In the anchor, it's more\nlike-- with the anchor, the intuition was\nwhere am I positioned?",
    "start": "2764630",
    "end": "2772670"
  },
  {
    "text": "Am I in the east,\nor am I in the west? Here, you are more asked, how\ndo I embed in my local network",
    "start": "2772670",
    "end": "2780930"
  },
  {
    "text": "structure? And this is a more\nexpressive way to capture the local\nnetwork structure.",
    "start": "2780930",
    "end": "2787580"
  },
  {
    "text": "So this is all\nabout the locality. So it's very kind of\nmicroscopic or mesoscopic view,",
    "start": "2787580",
    "end": "2794720"
  },
  {
    "text": "while the position of air\nwas much of macroscopically, where am I roughly\nsituated in the graph.",
    "start": "2794720",
    "end": "2802170"
  },
  {
    "text": "So these two are orthogonal\nor complementary, and you could apply both.",
    "start": "2802170",
    "end": "2809120"
  },
  {
    "text": "Because they solve\northogonal problems. ",
    "start": "2809120",
    "end": "2816290"
  },
  {
    "text": "Good. Good. Super. Anything else? ",
    "start": "2816290",
    "end": "2823670"
  },
  {
    "text": "Just to explain, so\nwhat's the difference between GNN and an ID-GNN? The difference is here.",
    "start": "2823670",
    "end": "2830180"
  },
  {
    "text": "In the GNN, the computation\ngraphs will be identical. In the ID-GNN, the\ncomputation graphs",
    "start": "2830180",
    "end": "2837110"
  },
  {
    "text": "are structurally equivalent. But I can account through this\nheterogeneous message passing",
    "start": "2837110",
    "end": "2845900"
  },
  {
    "text": "for the identity of\nthe node for having this special orange node.",
    "start": "2845900",
    "end": "2851540"
  },
  {
    "text": "And this will give me\nmore expressive power. So why does ID-GNN\ngenerally outperform GNN?",
    "start": "2851540",
    "end": "2859130"
  },
  {
    "text": "Because ID-GNN can count\ncycles originating from a given starting node, but\nthe GNN cannot.",
    "start": "2859130",
    "end": "2866510"
  },
  {
    "text": "If this information turns\nout to be important, then the GNN allows\nyou to capture it.",
    "start": "2866510",
    "end": "2877070"
  },
  {
    "text": "So what you could also\ndo rather than having this heterogeneous\nmessage passing?",
    "start": "2877070",
    "end": "2882690"
  },
  {
    "text": "You can actually-- on this\nintuition of cycle ends, you could actually create\na feature vector for nodes",
    "start": "2882690",
    "end": "2892260"
  },
  {
    "text": "to actually count cycles. So we would have a fast version\nof this idea, where you include",
    "start": "2892260",
    "end": "2899520"
  },
  {
    "text": "identity information as\nan augmented node feature, and no need to do a\nheterogeneous message passing.",
    "start": "2899520",
    "end": "2909690"
  },
  {
    "text": "And you could use cycle\ncounts at each layer as an augmented node feature.",
    "start": "2909690",
    "end": "2915120"
  },
  {
    "text": "And then use this with any GNN. [COUGHS]",
    "start": "2915120",
    "end": "2921349"
  },
  {
    "text": "So this would be V1 appears\nin a cycle of length zero,",
    "start": "2921350",
    "end": "2929660"
  },
  {
    "text": "this is length 1, this\nwould be 2, 3, and so on.",
    "start": "2929660",
    "end": "2937069"
  },
  {
    "text": "So that would be another way\nto bring in similar intuition",
    "start": "2937070",
    "end": "2943280"
  },
  {
    "text": "but then not change\nthe architecture. So let me summarize this part.",
    "start": "2943280",
    "end": "2950670"
  },
  {
    "text": "So ID-GNN is a general\nextension of the GNN framework,",
    "start": "2950670",
    "end": "2957349"
  },
  {
    "text": "where we can apply the ID-GNN\nto any message passing GNN.",
    "start": "2957350",
    "end": "2962810"
  },
  {
    "text": "You could use a GCN\nconvolutional layer, a GraphSAGE convolutional layer,\na GIN convolutional layer,",
    "start": "2962810",
    "end": "2969930"
  },
  {
    "text": "however you would like. And ID-GNN will allow\nyou to basically build",
    "start": "2969930",
    "end": "2975980"
  },
  {
    "text": "more expressive Graph Neural\nNetwork for both node edge and graph level tasks.",
    "start": "2975980",
    "end": "2983279"
  },
  {
    "text": "The reason why it\nis more expressive is because it takes care\nof this identity node,",
    "start": "2983280",
    "end": "2991020"
  },
  {
    "text": "and allows you to basically have\nthis special node and account for it in the message passing. So basically, now you have\na Graph Neural Network that",
    "start": "2991020",
    "end": "2999570"
  },
  {
    "text": "is more expressive than the WL. So the Weisfeiler-Lehman\nGraph Isomorphism Test.",
    "start": "2999570",
    "end": "3006170"
  },
  {
    "text": "And it's easy to implement,\nand actually PyG, I know implements it, DGL\nI think also implements it,",
    "start": "3006170",
    "end": "3012990"
  },
  {
    "text": "and so on. Yes, question. What is the 1WL versus a 3WL.",
    "start": "3012990",
    "end": "3019760"
  },
  {
    "text": "The 1WL versus multiple WL\nis how dimensional colors",
    "start": "3019760",
    "end": "3027200"
  },
  {
    "text": "are you using? And how many hash\nfunctions are you using? ",
    "start": "3027200",
    "end": "3033470"
  },
  {
    "text": "So the bigger this number, the\nmore expressive the test is.",
    "start": "3033470",
    "end": "3040490"
  },
  {
    "text": "Cool. So maybe what I want, or is\nthere any more questions?",
    "start": "3040490",
    "end": "3045580"
  },
  {
    "text": " No, no, yes. Can we just think\nlike this graph",
    "start": "3045580",
    "end": "3051230"
  },
  {
    "text": "as a [? GNN ?]\ngraph we are like. Like myself is type 1, and like,\noh, I don't know these type 2,",
    "start": "3051230",
    "end": "3058220"
  },
  {
    "text": "and we can bounce something\n[INAUDIBLE] on that. So you are saying, can\nI think of your graph",
    "start": "3058220",
    "end": "3065930"
  },
  {
    "text": "as a heterogeneous graph that\nwith two types of nodes-- type 1 and type 2. And then run an\nRGNN on top of it.",
    "start": "3065930",
    "end": "3073940"
  },
  {
    "text": "Yes, you can. Exactly. That's the whole\npoint of all this. You could also use an RCGN\nthat will be even a bit slower",
    "start": "3073940",
    "end": "3082099"
  },
  {
    "text": "but will achieve the same goal. Yeah. Cool. So a good point.",
    "start": "3082100",
    "end": "3088400"
  },
  {
    "text": "Good point. Great. Let me maybe finish\nthe lecture today",
    "start": "3088400",
    "end": "3094400"
  },
  {
    "text": "with a bit more of a\ndiscussion and an introduction",
    "start": "3094400",
    "end": "3099970"
  },
  {
    "text": "about how would you think of\nrobustness of graph neural networks.",
    "start": "3099970",
    "end": "3105100"
  },
  {
    "text": "And the motivation is right. ",
    "start": "3105100",
    "end": "3112630"
  },
  {
    "text": "How robust are graph neural\nnetworks, and especially, how robust are they against\nadversarial attacks?",
    "start": "3112630",
    "end": "3119200"
  },
  {
    "text": "And this line of research was\nactually motivated, especially by the research\nin computer vision",
    "start": "3119200",
    "end": "3126760"
  },
  {
    "text": "where basically,\nyou can take-- you can ask a convolutional\nneural network what is this.",
    "start": "3126760",
    "end": "3132339"
  },
  {
    "text": "And it will say pandas. Now, you add this type of noise\nto it so you get this image.",
    "start": "3132340",
    "end": "3139310"
  },
  {
    "text": "And here it will\nsay it's a gibbon. OK. And to me, this looks like that.",
    "start": "3139310",
    "end": "3145840"
  },
  {
    "text": "OK. So the point is that\nan adversary can come in at just little carefully\ndecided noise or changes",
    "start": "3145840",
    "end": "3158609"
  },
  {
    "text": "to the pixel values that are\ngoing completely throw off your classifier and\nwhat looks like panda",
    "start": "3158610",
    "end": "3166350"
  },
  {
    "text": "gets confused for a banana\nor some crazy thing. OK. So these adversarial\nexamples, the idea",
    "start": "3166350",
    "end": "3174329"
  },
  {
    "text": "is that somebody carefully\ncalculates this noise",
    "start": "3174330",
    "end": "3179540"
  },
  {
    "text": "or this perturbation. And that small perturbation can\nreally flip your classifier.",
    "start": "3179540",
    "end": "3187170"
  },
  {
    "text": "And this was first\ndiscovered in 2015 for convolutional\nneural networks, right?",
    "start": "3187170",
    "end": "3192980"
  },
  {
    "text": "So the adversarial examples\nare also sometimes reported in natural language\nprocessing, similar problems,",
    "start": "3192980",
    "end": "3202339"
  },
  {
    "text": "as well as in audio, where\nagain, small carefully crafted change can really throw\noff the classifier.",
    "start": "3202340",
    "end": "3211510"
  },
  {
    "text": "And what this means\nis that the existence of this adversarial\nexamples prevents,",
    "start": "3211510",
    "end": "3217450"
  },
  {
    "text": "in some sense, reliable\ndeploying of deep learning models because an adversary\ncan come in and get",
    "start": "3217450",
    "end": "3223390"
  },
  {
    "text": "any classification\nresult they want by just small\nmanipulation, right? Adversaries may try to actively\nhack the deep learning model.",
    "start": "3223390",
    "end": "3231490"
  },
  {
    "text": "The model performance can become\nmuch worse than what we expect. And for this reason,\ndeep learning models",
    "start": "3231490",
    "end": "3238600"
  },
  {
    "text": "are often not robust, right? And this is a very\nactive area of research",
    "start": "3238600",
    "end": "3244720"
  },
  {
    "text": "to think about\nrobustness and this what they call\ndistribution shifts. So the question is, how would\nyou generalize these notions",
    "start": "3244720",
    "end": "3253310"
  },
  {
    "text": "to the graphs? And why is this important?",
    "start": "3253310",
    "end": "3260540"
  },
  {
    "text": "Because the common\napplications of GNNs usually are on public\nsocial network play venues,",
    "start": "3260540",
    "end": "3269569"
  },
  {
    "text": "or it's about banking, and\ntransactions, and so on. So there's a lot of\nmonetary interests",
    "start": "3269570",
    "end": "3274910"
  },
  {
    "text": "from search engines, social\nnetworks recommender systems. And adversaries\nhave the incentive",
    "start": "3274910",
    "end": "3281270"
  },
  {
    "text": "to manipulate the\nunderlying model and try to hack the\npredictions of it, right?",
    "start": "3281270",
    "end": "3288890"
  },
  {
    "text": "If you are in a\nsearch engine, you want to be ranked\nas high as possible. If you are in a recommender\nsystem, and you are a seller,",
    "start": "3288890",
    "end": "3296670"
  },
  {
    "text": "you want your product to be\nrecommended to as many users as possible so you get more sales.",
    "start": "3296670",
    "end": "3302810"
  },
  {
    "text": "There's a lot of gaming\nhappening all the time. So what I want to\nintroduce to you",
    "start": "3302810",
    "end": "3309740"
  },
  {
    "text": "is a framework how to think\nabout this for Graph Neural Networks. So we want to study\nthe robustness of GNNs.",
    "start": "3309740",
    "end": "3317089"
  },
  {
    "text": "We are going to consider\nthe following setting. The task will be semi-supervised\nnode classification.",
    "start": "3317090",
    "end": "3322880"
  },
  {
    "text": "So the graph is\npartially labeled. And we want to complete\nthe labeling of the graph.",
    "start": "3322880",
    "end": "3328789"
  },
  {
    "text": "And the model is we are\ngoing to use the simplest GCN to do this, OK?",
    "start": "3328790",
    "end": "3335030"
  },
  {
    "text": "So the roadmap for\nthe next 20 minutes is that we want to first\ndescribe several real world",
    "start": "3335030",
    "end": "3340970"
  },
  {
    "text": "attack possibilities. Then I will quickly\nshow the GCN model",
    "start": "3340970",
    "end": "3346520"
  },
  {
    "text": "that we are going to attack. So we know our opponent. That's important.",
    "start": "3346520",
    "end": "3352860"
  },
  {
    "text": "And then I'll formalize\nthe attack problem as an optimization\nproblem and then",
    "start": "3352860",
    "end": "3358400"
  },
  {
    "text": "I'll show you some\nempirical results. OK? So that's the idea.",
    "start": "3358400",
    "end": "3363660"
  },
  {
    "text": "So if you are attacking a\ngraph, what can you attack? You can either attack--",
    "start": "3363660",
    "end": "3371780"
  },
  {
    "text": "we have the target node. This is the node\nfor which the model will be making a prediction.",
    "start": "3371780",
    "end": "3376920"
  },
  {
    "text": "And we are going to call\nthis node a target node. And then we are going to talk\nabout attacker nodes, which",
    "start": "3376920",
    "end": "3384859"
  },
  {
    "text": "are the nodes to which attacker\nhas access and attacker can modify these nodes.",
    "start": "3384860",
    "end": "3389900"
  },
  {
    "text": "OK. That's the idea. Now, what can an\nattacker modify?",
    "start": "3389900",
    "end": "3398670"
  },
  {
    "text": "We can talk about\na direct attack where the attacker node\nis also the target node.",
    "start": "3398670",
    "end": "3405510"
  },
  {
    "text": "And the attacker can\nmodify the target node by changing its features, right?",
    "start": "3405510",
    "end": "3413850"
  },
  {
    "text": "And it can also change who the\ntarget node is connected to. OK? Which means it can\nadd connections",
    "start": "3413850",
    "end": "3420930"
  },
  {
    "text": "or it can remove\nconnections, right? It would cut a link,\nit could add a link, or it could change the\nfeatures of the target node.",
    "start": "3420930",
    "end": "3429030"
  },
  {
    "text": "So that's one\nattack possibility. And we call this a direct\nattack because we are attacking",
    "start": "3429030",
    "end": "3435599"
  },
  {
    "text": "directly the node of interest. There is also a more sneaky\nindirect attack, right?",
    "start": "3435600",
    "end": "3443310"
  },
  {
    "text": "In an indirect attack,\nthe target node is different from the nodes that\nattackers are attacking, right?",
    "start": "3443310",
    "end": "3451500"
  },
  {
    "text": "So what can the attacker do? Basically for these\nattacker nodes here in blue,",
    "start": "3451500",
    "end": "3457680"
  },
  {
    "text": "the attacker can\nchange their features, the attacker can\nadd connections, or the attacker can\nbreak connections.",
    "start": "3457680",
    "end": "3464400"
  },
  {
    "text": "Like similar, but\nnow to the nodes that are not the one for which\nwe care to flip its label.",
    "start": "3464400",
    "end": "3471270"
  },
  {
    "text": "OK? So what's the objective\nfunction of the attacker? The attacker wants to\nmaximize the change",
    "start": "3471270",
    "end": "3479280"
  },
  {
    "text": "of the node of the\ntarget nodes label, change the prediction subject\nto small graph manipulation.",
    "start": "3479280",
    "end": "3486990"
  },
  {
    "text": "OK? So the intuition being if graph\nmanipulation is too large,",
    "start": "3486990",
    "end": "3493320"
  },
  {
    "text": "maybe we will be\neasily detected. So the successful attacks should\nchange the target prediction",
    "start": "3493320",
    "end": "3501790"
  },
  {
    "text": "with unnoticeably small\ngraph manipulation, right? So the idea is I want to\nflip the label of this node.",
    "start": "3501790",
    "end": "3511180"
  },
  {
    "text": "Maybe I add an edge, maybe I\nflip some attribute, and all of a sudden, I get a completely\ndifferent prediction, right?",
    "start": "3511180",
    "end": "3518800"
  },
  {
    "text": "So after the attack, maybe\nI want the probability",
    "start": "3518800",
    "end": "3523920"
  },
  {
    "text": "of class III to increase. But probability of class two\nto decrease or something like. That could be my goal.",
    "start": "3523920",
    "end": "3530050"
  },
  {
    "text": "So the way you can formalize\nthis is the following. Let A be the adjacency\nmatrix of the original graph",
    "start": "3530050",
    "end": "3538020"
  },
  {
    "text": "and X be the feature matrix,\nthe features of the nodes. And after the\nattack, we are going",
    "start": "3538020",
    "end": "3544980"
  },
  {
    "text": "to have a different\nadjacency matrix, A prime, and a different feature\nmatrix, X prime.",
    "start": "3544980",
    "end": "3552839"
  },
  {
    "text": "And what we would like to\ndo, what the attacker wants to do is to make\nthis perturbation,",
    "start": "3552840",
    "end": "3558420"
  },
  {
    "text": "this attack as\nsmall as possible. So we want graph\nmanipulation to be small.",
    "start": "3558420",
    "end": "3564780"
  },
  {
    "text": " And here, again,\ngraph manipulation",
    "start": "3564780",
    "end": "3570220"
  },
  {
    "text": "could either be direct, changing\nthe connections of the target node, or we can be\nin indirect attack",
    "start": "3570220",
    "end": "3577090"
  },
  {
    "text": "where the attacker is\nattacking non-target node.",
    "start": "3577090",
    "end": "3582340"
  },
  {
    "text": "So that's the\nfirst thing to say. So the way we are\ngoing to formalize this is the following.",
    "start": "3582340",
    "end": "3588260"
  },
  {
    "text": "We are going to say we\nhave the original adjacency matrix, original features,\nand node labels y.",
    "start": "3588260",
    "end": "3594250"
  },
  {
    "text": "We are going to have\nsome model parameters, learned over A, X, and Y. So our\ngraph features and the labels.",
    "start": "3594250",
    "end": "3604059"
  },
  {
    "text": "And let's see be the class label\nof node v predicted by the GCN",
    "start": "3604060",
    "end": "3610600"
  },
  {
    "text": "with those parameters. Now, we assume that\nthe attacker has access to the graph features\nand the labels,",
    "start": "3610600",
    "end": "3621040"
  },
  {
    "text": "as well as the\nlearning algorithm. And what the\nattacker can modify, the attacker can\nmodify the graph,",
    "start": "3621040",
    "end": "3627350"
  },
  {
    "text": "and the attacker can\nmodify the features. Now, if the attacker\nmakes this modification,",
    "start": "3627350",
    "end": "3634720"
  },
  {
    "text": "we would unknowingly learn a\ndifferent model, a model theta",
    "start": "3634720",
    "end": "3640990"
  },
  {
    "text": "star prime. That is now learned\non the attacked graph, attacked features, but with\nstill the original labels.",
    "start": "3640990",
    "end": "3650329"
  },
  {
    "text": "All right? And now, I'm going\nto use this C star prime to denote the\nclass label of a node v",
    "start": "3650330",
    "end": "3658119"
  },
  {
    "text": "under this different model. And the goal of the attacker\nis to flip the label",
    "start": "3658120",
    "end": "3666250"
  },
  {
    "text": "of that node v, right? That the labeling under when\ntraining on the clean data",
    "start": "3666250",
    "end": "3672280"
  },
  {
    "text": "is different than\nthe labeling when trained on the attacked data.",
    "start": "3672280",
    "end": "3678250"
  },
  {
    "text": "OK? So the mathematical\nformulation goes",
    "start": "3678250",
    "end": "3684240"
  },
  {
    "text": "as follows is that\nfor the target node v, I want to learn the GCN\nover the original graph.",
    "start": "3684240",
    "end": "3693910"
  },
  {
    "text": "And I'm going to use\nthis C star to be the predicted class\nof the GCN that",
    "start": "3693910",
    "end": "3700530"
  },
  {
    "text": "was learned on the\noriginal unattacked data.",
    "start": "3700530",
    "end": "3706500"
  },
  {
    "text": "Then the attacker comes and\nmanipulates my training data. So I'm going to-- so what\nwill happen in that case",
    "start": "3706500",
    "end": "3714480"
  },
  {
    "text": "is that now the network\nthat I'm going to learn, the neural network parameters\nare going to be different.",
    "start": "3714480",
    "end": "3721950"
  },
  {
    "text": "I will learn this\ntheta star prime. And also, because now\nparameters are different,",
    "start": "3721950",
    "end": "3729300"
  },
  {
    "text": "the label, the predicted\nlabel for that node v might be different.",
    "start": "3729300",
    "end": "3735480"
  },
  {
    "text": "And the attacker,\nwhat they want to do is they want to change the\nprediction after the graph is",
    "start": "3735480",
    "end": "3740950"
  },
  {
    "text": "manipulated from one class\nto a different class. OK. That's the goal.",
    "start": "3740950",
    "end": "3748350"
  },
  {
    "text": "So how do we formalize this? The way we formalize\nthis is we want",
    "start": "3748350",
    "end": "3754010"
  },
  {
    "text": "to identify the amount of the\nlikelihood or the confidence.",
    "start": "3754010",
    "end": "3763580"
  },
  {
    "text": "The model has in one versus\nthe other label, right? We want the log probability\nof the newly predicted class.",
    "start": "3763580",
    "end": "3773720"
  },
  {
    "text": "We want to increase this term. But we want the\npredicted log probability of the originally\npredicted class,",
    "start": "3773720",
    "end": "3780230"
  },
  {
    "text": "we want this to be low so\nthat it's going to flip. This is going to be\nlarger than that.",
    "start": "3780230",
    "end": "3785849"
  },
  {
    "text": "So we are going to conclude\nwrongly under the new network",
    "start": "3785850",
    "end": "3790910"
  },
  {
    "text": "that this is the correct\nclass for the node. So the way you can now write\nout the optimization problem",
    "start": "3790910",
    "end": "3799640"
  },
  {
    "text": "that the attacker\nis trying to solve. The attacker is\nbasically saying, I'm trying to change\nthis [? data. ?]",
    "start": "3799640",
    "end": "3805850"
  },
  {
    "text": "I'm trying to push\nthis probability up, or this log likelihood up.",
    "start": "3805850",
    "end": "3811740"
  },
  {
    "text": "And I want to push this\nlog likelihood down, right? I want this to be small,\nand I want this to be large.",
    "start": "3811740",
    "end": "3819000"
  },
  {
    "text": "And I want to do this by\nmanipulating A and X to get",
    "start": "3819000",
    "end": "3824070"
  },
  {
    "text": "the A prime and X prime. And the solving this\noptimization problem,",
    "start": "3824070",
    "end": "3831990"
  },
  {
    "text": "if you are an\nattacker is very hard. The reason is because adjacency\nmatrix is a discrete object.",
    "start": "3831990",
    "end": "3839190"
  },
  {
    "text": "So you cannot take derivatives. And then whenever you\nmake a manipulation,",
    "start": "3839190",
    "end": "3846460"
  },
  {
    "text": "you need to retrain\nyour graph neural network to see how it\nchanges its predictions.",
    "start": "3846460",
    "end": "3852080"
  },
  {
    "text": "So you have both kind of\nthe optimization problem, as well as the\nscalability problem.",
    "start": "3852080",
    "end": "3857950"
  },
  {
    "text": "And the paper that\nwas published at 2018",
    "start": "3857950",
    "end": "3863920"
  },
  {
    "text": "was the first one to formalize\nthis framework, which I gave you the formalization. And they also provided a\nlot of clever techniques",
    "start": "3863920",
    "end": "3873400"
  },
  {
    "text": "to resolve these two problems. And basically, what they come\nup is this locally optimal",
    "start": "3873400",
    "end": "3882070"
  },
  {
    "text": "strategy where they\nin a greedy way try to execute a series\nof perturbations,",
    "start": "3882070",
    "end": "3888430"
  },
  {
    "text": "and sequentially,\nmanipulate the graph. Basically,\nsequentially manipulate the most promising element\nto try to flip the label.",
    "start": "3888430",
    "end": "3899350"
  },
  {
    "text": "And the way they do this is\nthey have this delta objective function, this difference\nin log likelihoods.",
    "start": "3899350",
    "end": "3905720"
  },
  {
    "text": "And then they basically\nwhich indicates the score. And then they pick\nthe perturbation that maximizes the score.",
    "start": "3905720",
    "end": "3912019"
  },
  {
    "text": "And they keep picking the\ngreedily best perturbation",
    "start": "3912020",
    "end": "3918500"
  },
  {
    "text": "until the label changes. OK. So that's what they do. Yes.",
    "start": "3918500",
    "end": "3924050"
  },
  {
    "text": "Why in the setup do we\nassume the attacker can only change the adjacency matrix?",
    "start": "3924050",
    "end": "3930119"
  },
  {
    "text": "Why not also the labels? Good question. So the question is, why are we\nassuming the attacker cannot",
    "start": "3930120",
    "end": "3938370"
  },
  {
    "text": "change the labels? If the attacker could change\nthe label, then it's easy.",
    "start": "3938370",
    "end": "3944022"
  },
  {
    "text": "I just change your\nlabel and you'll be classified\ndifferently tomorrow. So that's a very easy attack.",
    "start": "3944022",
    "end": "3950950"
  },
  {
    "text": "So now, of course, maybe\nwhat we should do, maybe if I answer a bit\nmore seriously,",
    "start": "3950950",
    "end": "3957059"
  },
  {
    "text": "is like, I think there\nare different attack scenarios, right? Here they said I allow myself\nto retrain the network.",
    "start": "3957060",
    "end": "3964740"
  },
  {
    "text": "I think a completely\nreasonable attack scenario would be that you have your A,\nX, and Y. You train your model.",
    "start": "3964740",
    "end": "3973049"
  },
  {
    "text": "But now, A and X can evolve. They can change. But the model remains fixed.",
    "start": "3973050",
    "end": "3979590"
  },
  {
    "text": "How should I change\nthat to flip your label? That would be another\ndifferent scenario, right?",
    "start": "3979590",
    "end": "3986220"
  },
  {
    "text": "It would be like you train\nyour fraud detection system. Now, the question\nis, how do I organize",
    "start": "3986220",
    "end": "3993099"
  },
  {
    "text": "my financial transactions that\ngo through your fraud system, right?",
    "start": "3993100",
    "end": "3998440"
  },
  {
    "text": "So I would say different\nformalizations make sense.",
    "start": "3998440",
    "end": "4003950"
  },
  {
    "text": "Here the authors\npick the one where they say you don't have access\nto labels because labels",
    "start": "4003950",
    "end": "4009020"
  },
  {
    "text": "are external. I think my sense is that if\nyou have access to labels, then",
    "start": "4009020",
    "end": "4014329"
  },
  {
    "text": "it's much easier. It's easy, right? So that's maybe the reason why\nthey choose this one that's",
    "start": "4014330",
    "end": "4020930"
  },
  {
    "text": "a bit more challenging.  One of the attacks\nsucceed because the attack",
    "start": "4020930",
    "end": "4029570"
  },
  {
    "text": "know the structure\nof the model itself. Correct. In this case, we are\nassuming the attacker",
    "start": "4029570",
    "end": "4036250"
  },
  {
    "text": "knows the structure\nof the model itself. In all these\nadversarial examples, you need to have\naccess to the model.",
    "start": "4036250",
    "end": "4044540"
  },
  {
    "text": "Yeah. Has anyone tried to use a\ndeep reinforcement learning to train the attacker?",
    "start": "4044540",
    "end": "4050180"
  },
  {
    "text": "Because it appears that-- A good question. So you are saying, has\nanyone used the reinforcement",
    "start": "4050180",
    "end": "4056780"
  },
  {
    "text": "learning to train the attacker? So you could say, I have a\nmodel that's a black box. ",
    "start": "4056780",
    "end": "4063980"
  },
  {
    "text": "But in most cases, especially\nin the computer vision, they assume you have actually\naccess to the parameters.",
    "start": "4063980",
    "end": "4070190"
  },
  {
    "text": "I think, in this case, I\nwould need to check the paper.",
    "start": "4070190",
    "end": "4075349"
  },
  {
    "text": "But I think they don't really\nlook into the parameters of the model. But they assume they know\nwhat model you are training.",
    "start": "4075350",
    "end": "4082670"
  },
  {
    "text": "So at least they have to have. Could you do\nreinforcement learning?",
    "start": "4082670",
    "end": "4088220"
  },
  {
    "text": "You may to learn\nthe attack strategy. I think it would take\ntraining would be super hard and it would take super long.",
    "start": "4088220",
    "end": "4095019"
  },
  {
    "text": "So it seems similar to map\nestimation or detection ideas?",
    "start": "4095020",
    "end": "4100028"
  },
  {
    "text": "Like you rotate through every\nsingle hypothesis compare it to and choose the one that\nreturns the maximum likelihood?",
    "start": "4100029",
    "end": "4106330"
  },
  {
    "text": "Sure. This is just a greedy algorithm. It's just like\nrather than trying to find the optimal which you\ncan't, you execute the search",
    "start": "4106330",
    "end": "4115990"
  },
  {
    "text": "step by step. And at every step, you\njust do the best thing that is best in\nthat given moment,",
    "start": "4115990",
    "end": "4121179"
  },
  {
    "text": "even though it might\nnot be globally optimal. OK. Good. So I want to show\nyou some results",
    "start": "4121180",
    "end": "4127689"
  },
  {
    "text": "just as a discussion because\nI thought was interesting. So this is setting a\nsemi-supervised node",
    "start": "4127689",
    "end": "4133540"
  },
  {
    "text": "classification with a graph\nconvolutional neural network. Graph is a small\ncitation network,",
    "start": "4133540",
    "end": "4139120"
  },
  {
    "text": "2,800 nodes 8,000 edges. The attack type is modify\nedges, add or delete them.",
    "start": "4139120",
    "end": "4147639"
  },
  {
    "text": "And the attack budget\nis that you can change the degree of the node for two.",
    "start": "4147640",
    "end": "4153670"
  },
  {
    "text": "So you can either\nadd up to two edges or delete up to two edges. And the intuition\nis that it's harder",
    "start": "4153670",
    "end": "4159920"
  },
  {
    "text": "to attack a node with a\nlarger with a larger degree.",
    "start": "4159920",
    "end": "4165739"
  },
  {
    "text": "And the model is trained\nand attacked five times",
    "start": "4165740",
    "end": "4171318"
  },
  {
    "text": "using different random seeds. So you see also success rate.",
    "start": "4171319",
    "end": "4177330"
  },
  {
    "text": "So these are now\npredicted probabilities of the target node over five\ndifferent learnings, right?",
    "start": "4177330",
    "end": "4184068"
  },
  {
    "text": "So this is a seven way\nclassification data set.",
    "start": "4184069",
    "end": "4190549"
  },
  {
    "text": "This is the\npredicted probability for that given target node\nto belong to a given class.",
    "start": "4190550",
    "end": "4196940"
  },
  {
    "text": "You see we are correctly\npredicting this node to be in class 6, which is good.",
    "start": "4196940",
    "end": "4204080"
  },
  {
    "text": "The reason why this each bar\nhere is a different experiment. So it's a different training\nrun from a different random",
    "start": "4204080",
    "end": "4212660"
  },
  {
    "text": "starting point. And because of this, there\nis some variance in what",
    "start": "4212660",
    "end": "4217820"
  },
  {
    "text": "your model converges to. But the point is, in all cases,\nthe prediction is correct.",
    "start": "4217820",
    "end": "4224700"
  },
  {
    "text": "OK? So what we want to\ndo now is we want to change the\nunderlying graph to make",
    "start": "4224700",
    "end": "4231679"
  },
  {
    "text": "this node belong to class number\n7, whatever that number 7 is.",
    "start": "4231680",
    "end": "4238310"
  },
  {
    "text": "OK. So let's look how whether the\nmodel was able to do this.",
    "start": "4238310",
    "end": "4244800"
  },
  {
    "text": "So here, after modifying\njust five edges in the underlying\nnetwork, this was",
    "start": "4244800",
    "end": "4252349"
  },
  {
    "text": "with a direct\nadversarial attack. You can see it\ncompletely changes.",
    "start": "4252350",
    "end": "4257870"
  },
  {
    "text": "So here, we modify five\nedges of the target node with a targeted attack.",
    "start": "4257870",
    "end": "4264440"
  },
  {
    "text": "And we were able to convince\nthe neural network that the node now is of class 7.",
    "start": "4264440",
    "end": "4274010"
  },
  {
    "text": "If you look at of more broadly\nthe results in this paper,",
    "start": "4274010",
    "end": "4279619"
  },
  {
    "text": "basically, they find that\nan adversarial attack is the strongest attack\nsignificantly worsening",
    "start": "4279620",
    "end": "4287540"
  },
  {
    "text": "the GNNs performance\ncompared to the no attack. They find that\nrandomly attacking,",
    "start": "4287540",
    "end": "4294199"
  },
  {
    "text": "randomly adding noise\nis much, much weaker than adversarially\nattacking the network.",
    "start": "4294200",
    "end": "4299780"
  },
  {
    "text": "And that indirect attack\nis more challenging than the direct attack. And here I can interpret\nthe results with you.",
    "start": "4299780",
    "end": "4306829"
  },
  {
    "text": "Here is the\nclassification margin. If it's negative, the\nattacker succeeded.",
    "start": "4306830",
    "end": "4312380"
  },
  {
    "text": "And it was a misclassification.",
    "start": "4312380",
    "end": "4318110"
  },
  {
    "text": "And basically, what\nyou see is that with a direct\nadversarial attack, you can basically always flip\nthe nodes label completely,",
    "start": "4318110",
    "end": "4327320"
  },
  {
    "text": "right? What they find out that\nif you add random attack,",
    "start": "4327320",
    "end": "4332690"
  },
  {
    "text": "this is random edges between\ntarget nodes and nodes with different labels,\nrandom doesn't even work.",
    "start": "4332690",
    "end": "4340240"
  },
  {
    "text": "Even though you can do a\nrandom targeted attack. So you can attack the\ntarget, random manipulation",
    "start": "4340240",
    "end": "4348640"
  },
  {
    "text": "doesn't do much. Sometimes it flips. But most often, it doesn't. So in this respect GNNs are\nquite robust to random noise,",
    "start": "4348640",
    "end": "4357040"
  },
  {
    "text": "either on the target node\nor on the nearby nodes.",
    "start": "4357040",
    "end": "4365440"
  },
  {
    "text": "And here is the adversarial\nindirect attack. And you see that this is not\nreally successful, right?",
    "start": "4365440",
    "end": "4372970"
  },
  {
    "text": "That indirect manipulation\nis much, much harder. And, of course, it\nremains, I think, an open",
    "start": "4372970",
    "end": "4380530"
  },
  {
    "text": "question, what could you do with\nadversarial indirect attacks?",
    "start": "4380530",
    "end": "4385840"
  },
  {
    "text": "And how would you be\nable to manipulate the network in the\nvicinity of the target node",
    "start": "4385840",
    "end": "4391420"
  },
  {
    "text": "to flip the target? That could be quite cool\nif you could master that.",
    "start": "4391420",
    "end": "4396940"
  },
  {
    "text": "OK. So let me just summarize what\nwe studied in this last part",
    "start": "4396940",
    "end": "4403480"
  },
  {
    "text": "of the lecture today. We studied the\nadversarial robustness of Graph Convolutional\nNeural Networks",
    "start": "4403480",
    "end": "4410170"
  },
  {
    "text": "applied to semi-supervised\nnode classification. I showed you. Basically, we\nformalize the problem,",
    "start": "4410170",
    "end": "4416800"
  },
  {
    "text": "talked about direct\nand indirect attacks both on the graph structure,\nas well as the node attributes.",
    "start": "4416800",
    "end": "4423730"
  },
  {
    "text": "And I showed you\nsome experiments that are suggesting that\ntargeted attacks are",
    "start": "4423730",
    "end": "4430600"
  },
  {
    "text": "easy and effective,\nrandom targeted attacks are not effective, and doing\nindirect attacks is very hard.",
    "start": "4430600",
    "end": "4440900"
  },
  {
    "text": "So, in some sense, if somebody\nwants to manipulate the target, they can easily do that.",
    "start": "4440900",
    "end": "4447070"
  },
  {
    "text": "Other types of\nmanipulation seems to be much harder\nto pull off which is very, very encouraging.",
    "start": "4447070",
    "end": "4453789"
  },
  {
    "text": "And also, I think\nwhat is encouraging is that this random noise, GNNs\nseem to be quite robust to it.",
    "start": "4453790",
    "end": "4461909"
  },
  {
    "text": "So with this, I'm\ndone for today.",
    "start": "4461910",
    "end": "4467380"
  },
  {
    "start": "4467380",
    "end": "4472000"
  }
]
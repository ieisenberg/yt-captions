[
  {
    "start": "0",
    "end": "60000"
  },
  {
    "start": "0",
    "end": "6470"
  },
  {
    "text": "Good, well, hi, everyone. Welcome back to CS 330. Today, we'll be talking\nabout lifelong learning.",
    "start": "6470",
    "end": "12630"
  },
  {
    "text": "And this lecture will\nbe a little different than the previous\nlectures we've had. It will be much more open-ended.",
    "start": "12630",
    "end": "20160"
  },
  {
    "text": "And I think a little\nmore interactive as well. And this is because\nthe topic itself is much more open-ended as well.",
    "start": "20160",
    "end": "27970"
  },
  {
    "text": "All right. So the plan for today\nis as following.",
    "start": "27970",
    "end": "33059"
  },
  {
    "text": "We'll start with the lifelong\nlearning problem statement. And we'll try to see\nwhy this by itself",
    "start": "33060",
    "end": "38879"
  },
  {
    "text": "is quite challenging already. Then we'll think of\nsome basic approaches that can allow us to address the\nproblem of lifelong learning.",
    "start": "38880",
    "end": "49105"
  },
  {
    "text": "We will also think about\nhow we can do better than these basic approaches. And then we'll\nrevisit the problem",
    "start": "49105",
    "end": "55450"
  },
  {
    "text": "by looking at it from the\nmeta-learning perspective. All right.",
    "start": "55450",
    "end": "61640"
  },
  {
    "start": "60000",
    "end": "317000"
  },
  {
    "text": "So I want to start with a\nbrief review of the problem statements that we\nhave been considering so far in the class.",
    "start": "61640",
    "end": "69120"
  },
  {
    "text": "And one of them was\nmulti-task learning. And the problem statement\nwas as following.",
    "start": "69120",
    "end": "74210"
  },
  {
    "text": "We were given a set\nof tasks up front. We can train on these tasks. And then we'll be evaluated\nbased on the performance",
    "start": "74210",
    "end": "81020"
  },
  {
    "text": "on those exact same tasks. So we were just trying to\nlearn to solve a set of tasks. ",
    "start": "81020",
    "end": "87388"
  },
  {
    "text": "And then we also talked about\nthe meta-learning problem statement. That is a little bit different. So in this case, we are given\nan i.i.d task distribution.",
    "start": "87388",
    "end": "95920"
  },
  {
    "text": "And we are tasked to learn\na new task efficiently. So we are given a batch of\ndata with many different tasks.",
    "start": "95920",
    "end": "101830"
  },
  {
    "text": "And based on that, we\nneed to be able to learn how to learn quickly, so\nthat if given a new task,",
    "start": "101830",
    "end": "108040"
  },
  {
    "text": "we can quickly adjust to\nit and learn how to do it. All right. So these are the\nproblem statements",
    "start": "108040",
    "end": "114428"
  },
  {
    "text": "we have been considering so far. But in many real world\nsettings, the setting",
    "start": "114428",
    "end": "121970"
  },
  {
    "text": "is actually a little\nbit different. So rather than having this\nbatch of data or batch of different tasks that\nwe can pretrain on,",
    "start": "121970",
    "end": "128660"
  },
  {
    "text": "either in the multi-task\nor meta-learning, it would look more\nor less like this.",
    "start": "128660",
    "end": "134160"
  },
  {
    "text": "So we would have tasks\nthat are given to us, but they are not given to us\nup front right off the bat.",
    "start": "134160",
    "end": "139670"
  },
  {
    "text": "Instead, they are coming\nto us in sequence. So for instance, we need\nto learn how to walk first.",
    "start": "139670",
    "end": "146030"
  },
  {
    "text": "And then after we\ncan do this, we will start learning how to run. And after we do this, we\nare given another task.",
    "start": "146030",
    "end": "151820"
  },
  {
    "text": "And we keep going and keep\nlearning new tasks that come in sequence rather than\nhaving this big batch of data",
    "start": "151820",
    "end": "160820"
  },
  {
    "text": "and tasks up front.  All right. So a few examples,\njust to show you",
    "start": "160820",
    "end": "168270"
  },
  {
    "text": "what I mean by this\nnew problem statement. So for example, a student\nlearning concepts in school",
    "start": "168270",
    "end": "174849"
  },
  {
    "text": "is an example of this real-world\nsetting that is more sequential",
    "start": "174850",
    "end": "180540"
  },
  {
    "text": "but rather than being given all\nthe different classes and all the different levels of--\nin a particular class,",
    "start": "180540",
    "end": "188910"
  },
  {
    "text": "you are given different concepts\nin a sort of curriculum. So you will first learn\nhow to do algebra 1,",
    "start": "188910",
    "end": "195660"
  },
  {
    "text": "and then you'll do algebra 2. You're not given all of those,\nall of the knowledge at once.",
    "start": "195660",
    "end": "202950"
  },
  {
    "text": "Another example is a deployed\nimage classification system that is trying to learn\nfrom a stream of images",
    "start": "202950",
    "end": "208190"
  },
  {
    "text": "that come from users. And here, things that\ncan change over time, things such as user\npreferences or the images",
    "start": "208190",
    "end": "215150"
  },
  {
    "text": "that the users tend to take. The preferences and the\nimages might change over time.",
    "start": "215150",
    "end": "220190"
  },
  {
    "text": "And the algorithm should\nbe able to adjust to that. ",
    "start": "220190",
    "end": "225550"
  },
  {
    "text": "Another robotics\nexample is the robot acquiring an increasingly\nlarge set of skills",
    "start": "225550",
    "end": "230820"
  },
  {
    "text": "in different environments. So in this case, we\ncan imagine a robot that is initially deployed,\nlet's say, in the kitchen.",
    "start": "230820",
    "end": "237542"
  },
  {
    "text": "And it's doing all kinds of\ndifferent tasks in the kitchen. But after a while, we wanted\nit to also clean the bathroom.",
    "start": "237542",
    "end": "244080"
  },
  {
    "text": "So in that case, we\nwould want the robot to be able to quickly\ntransition to that new skill.",
    "start": "244080",
    "end": "249129"
  },
  {
    "text": "And as it's given more and more\ntasks and skills in sequence, every new task should\ncome easier and easier.",
    "start": "249130",
    "end": "255300"
  },
  {
    "text": " Another one is a\nvirtual assistant learning to help different\nusers do different tasks",
    "start": "255300",
    "end": "261708"
  },
  {
    "text": "at different points in time. So in that case, we\nwould want to have",
    "start": "261709",
    "end": "266990"
  },
  {
    "text": "an assistant that can adjust\nto our preferences over time. We don't want to have an\nassistant that was just pretrained on something,\nand it never responds to us",
    "start": "266990",
    "end": "274070"
  },
  {
    "text": "and learns from our\ninteractions with it. But it should be something\nthat can kind of quickly",
    "start": "274070",
    "end": "280430"
  },
  {
    "text": "adjust to our preferences\nand understand that better. So that the longer we interact\nwith it, the better it gets. ",
    "start": "280430",
    "end": "287600"
  },
  {
    "text": "And then the last\nexample we have here is a doctor's assistant aiding in\nmedical decision making, where",
    "start": "287600",
    "end": "294560"
  },
  {
    "text": "things that can change\nover time, as the diseases that the doctor's assistant\nwould need to be able to deal",
    "start": "294560",
    "end": "301490"
  },
  {
    "text": "with, such as\nCOVID-19 that wasn't really around a few years ago.",
    "start": "301490",
    "end": "307910"
  },
  {
    "text": "So it needs to be able to adjust\nthose decisions over time. And hopefully with\nevery new disease or with every new patient, it's\nable to get better and better.",
    "start": "307910",
    "end": "315140"
  },
  {
    "text": " All right. So before we jump into a little\nexercise about the problem",
    "start": "315140",
    "end": "323350"
  },
  {
    "start": "317000",
    "end": "432000"
  },
  {
    "text": "statement, I wanted to introduce\na little bit of terminology. So overall, we'll be concerned\nwith sequential learning",
    "start": "323350",
    "end": "329590"
  },
  {
    "text": "settings. And people refer to it\nwith different names, so such as online learning,\nlifelong learning,",
    "start": "329590",
    "end": "335830"
  },
  {
    "text": "continual learning, incremental\nlearning, and streaming data. Often, they mean slightly\ndifferent things.",
    "start": "335830",
    "end": "343510"
  },
  {
    "text": "And it's important when you\nread papers on lifelong learning to kind of really\nunderstand the problem",
    "start": "343510",
    "end": "349112"
  },
  {
    "text": "statement that the authors\nare trying to solve. Because very often, even though\nthey are called the same, the problem statement\nis slightly different.",
    "start": "349112",
    "end": "356360"
  },
  {
    "text": "But overall, we will assume\nthat all of these terms can be--",
    "start": "356360",
    "end": "361870"
  },
  {
    "text": "try to refer to the same\nsequential learning setting, the lifelong learning setting. And we'll discuss the problem\nstatement in a second.",
    "start": "361870",
    "end": "369910"
  },
  {
    "text": "It's important to\nnote that this is distinct from sequence data\nor sequential decision making.",
    "start": "369910",
    "end": "374990"
  },
  {
    "text": "So an example of sequential\ndata is, for example, a corpora of text\nwhere we might still",
    "start": "374990",
    "end": "382300"
  },
  {
    "text": "want to learn the text\ngenerator that was trained on a large batch of data.",
    "start": "382300",
    "end": "389050"
  },
  {
    "text": "And the data itself\nis sequential. So you're generating\none word after another. But it's not really a sequential\nlearning setting in the sense",
    "start": "389050",
    "end": "395830"
  },
  {
    "text": "that you're not given\nnew tasks over time. You're still pretraining on a\nlarge set of tasks and data.",
    "start": "395830",
    "end": "403449"
  },
  {
    "text": "And then sequential\ndecision making, we talked about this in the\ncontext of reinforcement learning. This is a situation where\nwe can make decisions,",
    "start": "403450",
    "end": "414430"
  },
  {
    "text": "or we have to make\nsequential decisions, but we can still do-- for\nexample using reinforcement",
    "start": "414430",
    "end": "419560"
  },
  {
    "text": "learning, but we can still do\nthis from an offline dataset that we get to pretrain on. So it doesn't necessarily\nmean that it's",
    "start": "419560",
    "end": "426039"
  },
  {
    "text": "a sequential learning\nsetting where we are given new tasks as we go. ",
    "start": "426040",
    "end": "433220"
  },
  {
    "start": "432000",
    "end": "778000"
  },
  {
    "text": "All right. There's a question\nin the chat asking, lifelong learning seems\nsimilar to active learning,",
    "start": "433220",
    "end": "438820"
  },
  {
    "text": "what are the differences\nbetween the two? Yeah. So I think active\nlearning, some people",
    "start": "438820",
    "end": "446900"
  },
  {
    "text": "referred to some aspects\nof lifelong learning as active learning. So one aspect of\nactive learning that--",
    "start": "446900",
    "end": "454472"
  },
  {
    "text": "or one aspect of learning\nthat makes it more active is that we are\nsearching for data that would be particularly\nuseful for the algorithm",
    "start": "454472",
    "end": "463820"
  },
  {
    "text": "to know about. So for example, an\ninteractive system that is trying to query\nthe user for the data",
    "start": "463820",
    "end": "468830"
  },
  {
    "text": "that it's most uncertain\nabout is an example of an active learning system.",
    "start": "468830",
    "end": "474500"
  },
  {
    "text": "I think a lifelong\nlearning system can have this property as well.",
    "start": "474500",
    "end": "480300"
  },
  {
    "text": "But lifelong assumes\nthat sequential-- that these tasks,\nthere's multiple of them.",
    "start": "480300",
    "end": "487940"
  },
  {
    "text": "And as you get new\ntasks, you shouldn't forget about the old ones.",
    "start": "487940",
    "end": "493530"
  },
  {
    "text": "And as you get more\ntasks, you should be getting better and\nbetter at the new task that you are getting. So there are like slightly\ndifferent axes of the problem.",
    "start": "493530",
    "end": "500810"
  },
  {
    "text": "But I think you can build\na lifelong active learning system, where you do both, where\nthe active learning system can",
    "start": "500810",
    "end": "507830"
  },
  {
    "text": "ask for the data that is\nthe most useful to it, and it can also do\nit over its lifetime.",
    "start": "507830",
    "end": "513590"
  },
  {
    "text": " Great. Cool. So we'll do a little\nexercise right now.",
    "start": "513590",
    "end": "522320"
  },
  {
    "text": "And this is so that we can come\nup with a lifelong learning problem statement.",
    "start": "522320",
    "end": "527720"
  },
  {
    "text": "All right. So the exercise is as following.",
    "start": "527720",
    "end": "532790"
  },
  {
    "text": "I'll ask you to pick\nan example setting. And I'll give you the-- I'll put on the\nslide the examples that we just talked about.",
    "start": "532790",
    "end": "539810"
  },
  {
    "text": "And then I'll ask you to\ndiscuss the problem statement in your breakout room. So we'll split in\nbreakout rooms.",
    "start": "539810",
    "end": "545550"
  },
  {
    "text": "And we'll do this in a second. We'll do it such that there's\nthree to four students per room.",
    "start": "545550",
    "end": "550610"
  },
  {
    "text": "And I would ask you if the\nfirst letter of your first name",
    "start": "550610",
    "end": "556070"
  },
  {
    "text": "is closer to the\nbeginning of the alphabet. You'll be the one responsible\nfor taking the notes and then presenting it\nto the rest of the class.",
    "start": "556070",
    "end": "563390"
  },
  {
    "text": " So the problem\nstatement, the questions",
    "start": "563390",
    "end": "568740"
  },
  {
    "text": "that I would like you to\nfocus on are the following. First, how would you\nset up an experiment to develop and test your\nlifelong learning algorithm?",
    "start": "568740",
    "end": "576430"
  },
  {
    "text": "And this is very open-ended,\nso kind of use your creativity and kind of think\nhow would you set up",
    "start": "576430",
    "end": "582240"
  },
  {
    "text": "an experiment to develop and\ntest the lifelong learning algorithm. Second question is, what are\nthe desirable and/or required",
    "start": "582240",
    "end": "589480"
  },
  {
    "text": "properties of such algorithm? And thirdly, how would you\nevaluate such a system?",
    "start": "589480",
    "end": "596130"
  },
  {
    "text": "All right. So here I will show you the-- hang on, if this will work.",
    "start": "596130",
    "end": "601296"
  },
  {
    "text": " Hold on a second.",
    "start": "601296",
    "end": "608010"
  },
  {
    "text": "OK, here are the examples\nof things that I talked about just a few slides ago.",
    "start": "608010",
    "end": "613930"
  },
  {
    "text": "So you're welcome\nto use any of these if that helps for\nyour discussion. Or if you're feeling\nparticularly creative,",
    "start": "613930",
    "end": "621510"
  },
  {
    "text": "feel free to come\nup with your own. This is very encourage. And we'll do this\nfor five minutes.",
    "start": "621510",
    "end": "629250"
  },
  {
    "text": "So I will try to split you\ninto breakout rooms right now. And we'll meet in five minutes.",
    "start": "629250",
    "end": "635010"
  },
  {
    "text": "And we'll have the\npresenters from each group tell us what they came up with.",
    "start": "635010",
    "end": "642280"
  },
  {
    "text": "All right. So we'll split you into\nthe breakout rooms. ",
    "start": "642280",
    "end": "651350"
  },
  {
    "text": "All right. I think all of you\nshould have been invited to join breakout rooms.",
    "start": "651350",
    "end": "656950"
  },
  {
    "text": "So please join them. And I'll see you\nin five minutes. ",
    "start": "656950",
    "end": "687366"
  },
  {
    "text": "All right. So five minutes have passed,\nso we'll close the rooms now. ",
    "start": "687366",
    "end": "696710"
  },
  {
    "text": "Yup. They are closing\nin one minute, OK. ",
    "start": "696710",
    "end": "755150"
  },
  {
    "text": "All right. And breakout rooms\nare all closed. ",
    "start": "755150",
    "end": "762839"
  },
  {
    "text": "Welcome back, everybody. I hope you get good discussions.",
    "start": "762840",
    "end": "768700"
  },
  {
    "text": "So I will be asking for\na person from each room",
    "start": "768700",
    "end": "774030"
  },
  {
    "text": "to tell us a little bit\nabout what they've discussed.",
    "start": "774030",
    "end": "779340"
  },
  {
    "start": "778000",
    "end": "973000"
  },
  {
    "text": "And I'll try to take notes. So I have my little stylus here. And I hope you can\nread my handwriting.",
    "start": "779340",
    "end": "787110"
  },
  {
    "text": "But I'll take notes. And we'll be talking about\ndesirable properties, and considerations, as well\nas the evaluation setup.",
    "start": "787110",
    "end": "794500"
  },
  {
    "text": "And I just wanted to let\nyou know that the problem",
    "start": "794500",
    "end": "800740"
  },
  {
    "text": "setting is one of the hardest\nparts of lifelong learning challenge, or the topic\nof lifelong learning.",
    "start": "800740",
    "end": "808340"
  },
  {
    "text": "So this is a really\ndifficult exercise. But with that,\nlet's get started.",
    "start": "808340",
    "end": "814190"
  },
  {
    "text": "So I'll ask the person\nfrom room number one to tell us a little about\ndesirable properties",
    "start": "814190",
    "end": "820714"
  },
  {
    "text": "and evaluation setup.  Sure.",
    "start": "820715",
    "end": "828520"
  },
  {
    "text": "This is from room\none, I believe. So we chose a setting of an\nimage classification system.",
    "start": "828520",
    "end": "838800"
  },
  {
    "text": "So our experiment would be-- first we decide on a dataset,\nso we chose the MNIST data set.",
    "start": "838800",
    "end": "853300"
  },
  {
    "text": "And our experiment is we\nwant to sort of build up the knowledge of the classifier\nbeing able to distinguish",
    "start": "853300",
    "end": "860290"
  },
  {
    "text": "between each of the digits. It's kind of like\nan incremental.",
    "start": "860290",
    "end": "866380"
  },
  {
    "text": "So we begin with\nthe classifier being able to discriminate\nbetween the first digit",
    "start": "866380",
    "end": "871480"
  },
  {
    "text": "and, let's say,\ndigit number two.",
    "start": "871480",
    "end": "878670"
  },
  {
    "text": "And then we can do the testing,\njust sort of almost in classes.",
    "start": "878670",
    "end": "885750"
  },
  {
    "text": "But then in the\nnext round we had to discriminate between class\none and two, and then three",
    "start": "885750",
    "end": "893635"
  },
  {
    "text": "and four, and then we create\na test on all of the digits.",
    "start": "893635",
    "end": "898770"
  },
  {
    "text": "So we kind of do\nthat incrementally. And then the goal would be to-- it can build up good\nknowledge quickly.",
    "start": "898770",
    "end": "909710"
  },
  {
    "text": "OK, yeah, that makes\na lot of sense. So they're learning\nincrementally, and you're given--",
    "start": "909710",
    "end": "916279"
  },
  {
    "text": "you start with the digit\none, and then you're given the next digit this time.",
    "start": "916280",
    "end": "921410"
  },
  {
    "text": "And what are the\ndesirable properties of such an algorithm? So you wanted to learn--",
    "start": "921410",
    "end": "930110"
  },
  {
    "text": "be learning increasingly. Is that what you said? Yes. And so what were\nthe other properties",
    "start": "930110",
    "end": "939290"
  },
  {
    "text": "that you would want it to have? ",
    "start": "939290",
    "end": "944890"
  },
  {
    "text": "Yeah, I think the\nability to learn what is needed to\nlearn quickly, I guess.",
    "start": "944890",
    "end": "950890"
  },
  {
    "text": "So because of the new kind\nof digits, each kind of digit has its own set of different\nkinds of characteristics.",
    "start": "950890",
    "end": "962182"
  },
  {
    "text": "So, I guess, maybe being\nable to learn quickly. Kind of like a few-shot learner.",
    "start": "962182",
    "end": "967900"
  },
  {
    "text": "OK, so with every\nnew digit it should learn quicker and quicker? Mhm.",
    "start": "967900",
    "end": "973240"
  },
  {
    "start": "973000",
    "end": "1048000"
  },
  {
    "text": "OK. And how would you\nevaluate this algorithm, specifically so you would have--",
    "start": "973240",
    "end": "978850"
  },
  {
    "text": "actually, I should have\nhad that in this part here. It would have the MNIST digits.",
    "start": "978850",
    "end": "985090"
  },
  {
    "text": "And you are measuring\nwhat exactly? So I guess the specific metric--",
    "start": "985090",
    "end": "995089"
  },
  {
    "text": "I guess you would\nevaluate the accuracy, assuming that, like when\nyou said, it was balanced.",
    "start": "995090",
    "end": "1001870"
  },
  {
    "text": "But I think the goal is, kind\nof like how a student has a midterm and a final, it\nshould be assessed sort",
    "start": "1001870",
    "end": "1010000"
  },
  {
    "text": "of on the classes it's seen.",
    "start": "1010000",
    "end": "1015010"
  },
  {
    "text": "As opposed to, OK it\njust went class four, we should just eval it\non class four it's seen.",
    "start": "1015010",
    "end": "1021340"
  },
  {
    "text": "Be able to do well on all\nof the digits, I believe,",
    "start": "1021340",
    "end": "1026709"
  },
  {
    "text": "that it's seen. Right, so it should be\nevaluated on all the classes that it's seen so far.",
    "start": "1026710",
    "end": "1033699"
  },
  {
    "text": "And you would evaluate based on\nthe accuracy of all of those.",
    "start": "1033700",
    "end": "1039970"
  },
  {
    "text": "Yeah, that makes a lot of sense. Cool, is there anything\nelse you would want to add? That's it. All right, great, thank you.",
    "start": "1039970",
    "end": "1047560"
  },
  {
    "text": "All right, I'll ask\nthe room number two. And I think some people don't\nremember their room number, so if your group\nhasn't been called",
    "start": "1047560",
    "end": "1054010"
  },
  {
    "text": "yet just go ahead\nand say something. I believe I was part of room\nnumber two, and I can go next.",
    "start": "1054010",
    "end": "1061960"
  },
  {
    "text": "So we discussed about\nthe problem setting of robot navigation indoors.",
    "start": "1061960",
    "end": "1069880"
  },
  {
    "text": "So when you have a robot\ninside your apartment, the layout of your apartment\nkeeps changing continuously.",
    "start": "1069880",
    "end": "1076780"
  },
  {
    "text": "You keep moving furniture\none place to another. Or you could even move from\none apartment to another,",
    "start": "1076780",
    "end": "1083260"
  },
  {
    "text": "and ideally you would\nwant the same robot to learn how to navigate\nin the new apartment.",
    "start": "1083260",
    "end": "1091420"
  },
  {
    "text": "And one of the ways you\ncould bring such a robot is in a different environment,\nor habitat environment.",
    "start": "1091420",
    "end": "1099610"
  },
  {
    "text": "For example, there\nare different rooms, would be considered\ndifferent tasks. ",
    "start": "1099610",
    "end": "1106760"
  },
  {
    "text": "And one of the evaluation metric\ncould be shortest path taken",
    "start": "1106760",
    "end": "1113860"
  },
  {
    "text": "from source to destination. Or even different goals\ncould be different tasks.",
    "start": "1113860",
    "end": "1121925"
  },
  {
    "text": "And you would want\nit to navigate the kitchen or some other\nroom, things like that.",
    "start": "1121925",
    "end": "1130250"
  },
  {
    "text": "OK, yeah, that makes\na lot of sense. So you would be\nchecking how long it takes for it to\nfind the shortest",
    "start": "1130250",
    "end": "1136850"
  },
  {
    "text": "path to the destination. Is that right? Or how long the path would be.",
    "start": "1136850",
    "end": "1142549"
  },
  {
    "start": "1142550",
    "end": "1148220"
  },
  {
    "text": "I don't know how to\ndefine shortest path here. What would you compare it with? ",
    "start": "1148220",
    "end": "1156000"
  },
  {
    "text": "But I mean essentially\nwhen you have in the--",
    "start": "1156000",
    "end": "1162340"
  },
  {
    "text": "let's say the furniture layout\nchanges from one to another. You would still want to find the\nmost efficient path from source",
    "start": "1162340",
    "end": "1171700"
  },
  {
    "text": "to destination. And one of the\nways I can think of",
    "start": "1171700",
    "end": "1177130"
  },
  {
    "text": "is you would use something\nlike a star, or something, and you would want to\ndo better than that. ",
    "start": "1177130",
    "end": "1184929"
  },
  {
    "text": "So yeah, shortest path could\nbe one evaluation metric. Right. OK, that makes a lot of sense. And what are-- so given that\nthis is a lifelong learning",
    "start": "1184930",
    "end": "1192238"
  },
  {
    "text": "algorithm, you will\nbe-- as you said, you'll be given\none room at a time. What are the\ndesirable properties",
    "start": "1192238",
    "end": "1198550"
  },
  {
    "start": "1193000",
    "end": "1273000"
  },
  {
    "text": "of such an algorithm? What would you want\nthat algorithm to do? ",
    "start": "1198550",
    "end": "1210914"
  },
  {
    "text": "I don't know if-- I don't know. ",
    "start": "1210915",
    "end": "1217470"
  },
  {
    "text": "Yeah, you can jump in. But after that-- so basically,\nwhat we were discussing is",
    "start": "1217470",
    "end": "1222570"
  },
  {
    "text": "it might happen that when\nthe environment changes. Like, the only changes will\nbe fundamental changes.",
    "start": "1222570",
    "end": "1229510"
  },
  {
    "text": "So the bot may get\nconfused maybe. [INAUDIBLE] look like that.",
    "start": "1229510",
    "end": "1236710"
  },
  {
    "text": "So it should be able\nto ask the human, what direction should I be?",
    "start": "1236710",
    "end": "1243090"
  },
  {
    "text": "So basically it should have\nthe ability to somehow quantify the uncertainty.",
    "start": "1243090",
    "end": "1248790"
  },
  {
    "text": "And if it's better\nthan some threshold, it should be able to ask and\nthen incorporate that feedback.",
    "start": "1248790",
    "end": "1256040"
  },
  {
    "text": "Then it will make\nthe new territory. OK, so it should\nquantify uncertainty",
    "start": "1256040",
    "end": "1263110"
  },
  {
    "text": "and it should ask for feedback. ",
    "start": "1263110",
    "end": "1268679"
  },
  {
    "text": "Great.  All right, is\nthere anything else that you would like to add?",
    "start": "1268680",
    "end": "1276730"
  },
  {
    "start": "1273000",
    "end": "2283000"
  },
  {
    "text": "No. I can't think of anything else. OK, great, thank you.",
    "start": "1276730",
    "end": "1281850"
  },
  {
    "text": "This is great. All right, room number three. Yeah, hi.",
    "start": "1281850",
    "end": "1287040"
  },
  {
    "text": "This is-- We have selected\none of the examples listed",
    "start": "1287040",
    "end": "1292380"
  },
  {
    "text": "in the slides. Actually, we picked the\nnumber eight, student",
    "start": "1292380",
    "end": "1297780"
  },
  {
    "text": "learning concepts in school. But maybe this can\nbe applied also for a kind of digital\nlearner, which",
    "start": "1297780",
    "end": "1306630"
  },
  {
    "text": "we feed its content, right? So we argued, a little bit,\nfor this example that there",
    "start": "1306630",
    "end": "1314070"
  },
  {
    "text": "might be kind of two set backs. One is more external things. So similar like a reinforcement\nlearning environment.",
    "start": "1314070",
    "end": "1322350"
  },
  {
    "text": "And another one, which is\nmore of a supervised kind of approach.",
    "start": "1322350",
    "end": "1328720"
  },
  {
    "text": "And that is based on, let's\nsay, similar environments. Like in different\nparts of the world",
    "start": "1328720",
    "end": "1333870"
  },
  {
    "text": "where some knowledge or\nsome schools, let's say, are more spoon\nfeeding, rather than",
    "start": "1333870",
    "end": "1340590"
  },
  {
    "text": "some other places where they\nlet you experiment and learn.",
    "start": "1340590",
    "end": "1345600"
  },
  {
    "text": "So one of the desirable\nproperties and considerations",
    "start": "1345600",
    "end": "1352200"
  },
  {
    "text": "here is that you have\nsome learning objectives. So you know what\nyou want to learn",
    "start": "1352200",
    "end": "1358110"
  },
  {
    "text": "in different kind of milestones,\nand a given time frame to learn those\nlearning objectives.",
    "start": "1358110",
    "end": "1367080"
  },
  {
    "text": "And every second-- or\nevery learning objective that is coming after\nthe previous one",
    "start": "1367080",
    "end": "1375690"
  },
  {
    "text": "needs to be based on\nhistorical knowledge that you have learned before.",
    "start": "1375690",
    "end": "1381040"
  },
  {
    "text": "So it's incremental. And-- So you're-- it's kind of\ngiven to you in some kind of curriculum where each class\ndoes something different.",
    "start": "1381040",
    "end": "1389430"
  },
  {
    "text": "OK, yeah, that makes\na lot of sense. Yeah. And one of the ways to\nevaluate that is to start,",
    "start": "1389430",
    "end": "1399060"
  },
  {
    "text": "let's say, the training,\ncarry out evaluation tests. But these evaluation tests\nneed to be, again, subject",
    "start": "1399060",
    "end": "1409530"
  },
  {
    "text": "to the setup. Either explorative,\nand therefore use the knowledge\nthat you have learned",
    "start": "1409530",
    "end": "1417600"
  },
  {
    "text": "on these sort of\nexplorative questions to understand whether-- it's like critical\nthinking testing, right.",
    "start": "1417600",
    "end": "1426570"
  },
  {
    "text": "Or just to find out, for\nexample, what you have learned",
    "start": "1426570",
    "end": "1433612"
  },
  {
    "text": "from the previous knowledge. You can carry out a task\nwithin a given frame.",
    "start": "1433613",
    "end": "1439400"
  },
  {
    "text": "Yeah, OK. Yeah, I think that\nmakes a lot of sense. So you would stop training\nat a certain point,",
    "start": "1439400",
    "end": "1444590"
  },
  {
    "text": "and then you would test the\nability of the algorithm to reason, given all\nthe previous knowledge?",
    "start": "1444590",
    "end": "1450095"
  },
  {
    "text": "That's right, that's right.  Yeah, I think this is great. Is there anything else\nyou would like to add?",
    "start": "1450095",
    "end": "1458610"
  },
  {
    "text": "No this is what we had\nthe time to discuss for. OK, great, thank you.",
    "start": "1458610",
    "end": "1464880"
  },
  {
    "text": "Group number four. So the situation\nthat we chose was",
    "start": "1464880",
    "end": "1472820"
  },
  {
    "text": "a robot that's going\nfrom room to room, and it's recognizing\nobjects that it sees.",
    "start": "1472820",
    "end": "1479390"
  },
  {
    "text": "And I think a key characteristic\nthat we identified is that the dataset's\nconstantly changing,",
    "start": "1479390",
    "end": "1486350"
  },
  {
    "text": "like the distribution's\nchanging, and it should be able\nto adapt to this. So both learn new\ntypes of new instances",
    "start": "1486350",
    "end": "1494299"
  },
  {
    "text": "that it may encounter. But also, I guess, a\nproperty is that we'd",
    "start": "1494300",
    "end": "1500620"
  },
  {
    "text": "like for it to be able to\nstill remember previous objects that it's recognized.",
    "start": "1500620",
    "end": "1506170"
  },
  {
    "text": "And so even if it hasn't seen an\nobject in the last five rooms, it can still recognize an\nobject from the first room.",
    "start": "1506170",
    "end": "1513700"
  },
  {
    "text": "So some concept of memory. And that, ideally, as it\ngoes through the rooms",
    "start": "1513700",
    "end": "1520299"
  },
  {
    "text": "it can learn to recognize\nnew objects better. But we identify that the\nchallenge of this, or a factor",
    "start": "1520300",
    "end": "1528580"
  },
  {
    "text": "in this, is how similar-- how similar those future tasks\nare compared to previous tasks.",
    "start": "1528580",
    "end": "1537600"
  },
  {
    "text": "So if future objects\nare a lot harder, it might not work out very well.",
    "start": "1537600",
    "end": "1543660"
  },
  {
    "text": "Right, right, that\nmakes a lot of sense. And so how would you\nevaluate these properties?",
    "start": "1543660",
    "end": "1549430"
  },
  {
    "text": "For example, learning new\nobjects better or whether that's-- ",
    "start": "1549430",
    "end": "1556660"
  },
  {
    "text": "whether you have\nsome kind of memory. How would you evaluate that? Yeah, I think you would sort of\ntreat it as a few-shot learner,",
    "start": "1556660",
    "end": "1563440"
  },
  {
    "text": "where every time\nit moves to a new-- moves to a new room\nand encounters almost--",
    "start": "1563440",
    "end": "1570400"
  },
  {
    "text": "I guess it's not\nreally a new task. But there are new instances\nthat it has to recognize. So I guess you can evaluate a\nfew-shot learner region just",
    "start": "1570400",
    "end": "1580390"
  },
  {
    "text": "to give examples\nand see if it can-- I guess it'd be accuracy. Having only seen a few examples\nof new types of objects.",
    "start": "1580390",
    "end": "1588399"
  },
  {
    "text": "Yeah, I think that\nmakes a lot of sense. ",
    "start": "1588400",
    "end": "1594390"
  },
  {
    "text": "Accuracy, here. All right, great. Anything else you want to add? ",
    "start": "1594390",
    "end": "1602400"
  },
  {
    "text": "I think that was all. It was pretty challenging. Yeah, thank you.",
    "start": "1602400",
    "end": "1607530"
  },
  {
    "text": "All right, room number five. Which, I think at some\npoint we reassigned people to other rooms, so\neither five or six.",
    "start": "1607530",
    "end": "1614265"
  },
  {
    "text": " I was actually in\nfive in the beginning,",
    "start": "1614265",
    "end": "1620140"
  },
  {
    "text": "and then I got assigned to four. I see. OK, great. Then room number six. ",
    "start": "1620140",
    "end": "1634830"
  },
  {
    "text": "I think that's us. If I'm remembering\nthe number correctly.",
    "start": "1634830",
    "end": "1639831"
  },
  {
    "text": "The context we\nwere looking at was one of the different ones\nwith [INAUDIBLE] traveling,",
    "start": "1639831",
    "end": "1649630"
  },
  {
    "text": "lots of different tasks,\nand so sort of picturing being able to manipulate\ndifferent objects",
    "start": "1649630",
    "end": "1655190"
  },
  {
    "text": "with different instruments. That was kind of the image\nthat we had in our heads.",
    "start": "1655190",
    "end": "1662240"
  },
  {
    "text": "And then the setup to develop\na test would be either have multiple\nrooms, and each room",
    "start": "1662240",
    "end": "1667960"
  },
  {
    "text": "it's trying to do\na different task, or you add objects\nto the same room. And it's learning to do\ndifferent tasks in that room--",
    "start": "1667960",
    "end": "1673320"
  },
  {
    "text": "pretty similar to some\nof the other stuff you've heard discussed.",
    "start": "1673320",
    "end": "1679700"
  },
  {
    "text": "One discussion we had that I\nthought was kind of interesting was we had this idea\nthat a lot of times you",
    "start": "1679700",
    "end": "1686300"
  },
  {
    "text": "want it to not be\nforgetting the old tasks. But we were wondering\nwhat should happen in those cases\nwhere, say there's",
    "start": "1686300",
    "end": "1692225"
  },
  {
    "text": "something equivalent to\nlearning a bad habit, or learning something that\nthen becomes inadvisable later",
    "start": "1692225",
    "end": "1697610"
  },
  {
    "text": "or something. You need some-- how do you\ndeal with that [INAUDIBLE] when it makes sense\nto forget some skill,",
    "start": "1697610",
    "end": "1704870"
  },
  {
    "text": "or to relay some\nof those skills. So how do you deal with\nthat process was something",
    "start": "1704870",
    "end": "1713220"
  },
  {
    "text": "we weren't really\nsure how exactly you would want to do that. Or set up evaluations so that--",
    "start": "1713220",
    "end": "1720630"
  },
  {
    "text": " and, in terms of\ndesirable properties, it was like most of\nthe time, probably",
    "start": "1720630",
    "end": "1726887"
  },
  {
    "text": "don't forget the old ones. Although, there was the\ndiscussion along that. And then that kind\nof sense of you",
    "start": "1726887",
    "end": "1732170"
  },
  {
    "text": "want to be able to\nleverage old tasks to more quickly learn new tasks\nin sort of a MAML-like idea.",
    "start": "1732170",
    "end": "1738140"
  },
  {
    "text": " And then in terms of evaluation,\nwe were thinking about--",
    "start": "1738140",
    "end": "1746902"
  },
  {
    "text": "you can decide where\nyou're shuffling the tasks and see how different\ntime paths--",
    "start": "1746902",
    "end": "1753780"
  },
  {
    "text": "if you follow the\norder of the tasks you learn affects how\nwell you learn them.",
    "start": "1753780",
    "end": "1759870"
  },
  {
    "text": "Test to see if you really\nare leveraging old ones, if there's-- and also just doing\nthem each as individual tasks",
    "start": "1759870",
    "end": "1767736"
  },
  {
    "text": "with them in sequence. Yeah, I think that\nmakes a lot of sense. And the comment about being\ncareful about what to remember,",
    "start": "1767736",
    "end": "1774450"
  },
  {
    "text": "I think this is\nreally insightful. I haven't thought about this,\nthis is a really good point.",
    "start": "1774450",
    "end": "1780910"
  },
  {
    "text": "So you would see how\nthe order affects tasks, how the ordering of\ntasks affects the performance.",
    "start": "1780910",
    "end": "1787919"
  },
  {
    "text": " Great. And then you would also evaluate\nsome kind of backward transfer.",
    "start": "1787920",
    "end": "1794400"
  },
  {
    "text": "So how good are you at not\nforgetting the older stuff, is that right?",
    "start": "1794400",
    "end": "1799419"
  },
  {
    "text": "Yeah. Although with the caveat\nof maybe it's a nuanced process, and you're learning\na changed preference",
    "start": "1799420",
    "end": "1807168"
  },
  {
    "text": "or something. But some sort of-- you\nwant to retain probably most of what you've learned.",
    "start": "1807168",
    "end": "1813090"
  },
  {
    "text": "Yeah, OK, thank you. And we have the last room. I believe, room number seven.",
    "start": "1813090",
    "end": "1820430"
  },
  {
    "text": "Yeah, I can speak\nfor room seven. So we also talked\nabout kind of a robot",
    "start": "1820430",
    "end": "1827030"
  },
  {
    "text": "learning multiple tasks,\nor continually learning more and more tasks.",
    "start": "1827030",
    "end": "1834320"
  },
  {
    "text": "And so our idea behind it\nwas we wanted the agent",
    "start": "1834320",
    "end": "1842450"
  },
  {
    "text": "to be able to still\nperform well on all tasks, but be quick to\npick up new tasks",
    "start": "1842450",
    "end": "1850880"
  },
  {
    "text": "and get them to a point that\nwould be good for that task.",
    "start": "1850880",
    "end": "1856650"
  },
  {
    "text": "So we were thinking\nmaybe you compare it between the end result of\ntraining for the task alone,",
    "start": "1856650",
    "end": "1862910"
  },
  {
    "text": "versus how far you could\nget, or how much faster you could get to a similar\npoint, having accumulated",
    "start": "1862910",
    "end": "1870770"
  },
  {
    "text": "the skills of previous tasks. Or accumulated some\nkind of middle state from previous tasks.",
    "start": "1870770",
    "end": "1876170"
  },
  {
    "text": "So you would evaluate it\nboth on end performance and on how quickly you reach\nend performance, given how many",
    "start": "1876170",
    "end": "1885470"
  },
  {
    "text": "previous tests you've seen. Right, right. OK, so that will be the\nend performance, and also",
    "start": "1885470",
    "end": "1892071"
  },
  {
    "text": "how long it takes to get there. Yeah.",
    "start": "1892071",
    "end": "1897240"
  },
  {
    "text": "Kind of the idea being\nthat it's built up some skills along the way, or\nsome middle amount of state",
    "start": "1897240",
    "end": "1904710"
  },
  {
    "text": "that can be quick to use. Right, right. Yeah, I think that\nmakes a lot of sense.",
    "start": "1904710",
    "end": "1911500"
  },
  {
    "text": "Great. Is there anything else\nyou would like to add? I think that was what we\nspent the most time on was",
    "start": "1911500",
    "end": "1917730"
  },
  {
    "text": "this kind of evaluation setup. Awesome, thank you.",
    "start": "1917730",
    "end": "1922800"
  },
  {
    "text": "Is there anybody else who\nwas in a different room that we haven't\ntalked about yet,",
    "start": "1922800",
    "end": "1927870"
  },
  {
    "text": "that would like to talk\nabout their thought process or discussion?",
    "start": "1927870",
    "end": "1934140"
  },
  {
    "text": "Great. I think there shouldn't be\nanyone, so that's great. Thank you very much. This is really,\nreally a lot of fun",
    "start": "1934140",
    "end": "1941300"
  },
  {
    "text": "for me, definitely, just to\nhear your thoughts about this. And I think a lot of them\nare along the lines of things",
    "start": "1941300",
    "end": "1947510"
  },
  {
    "text": "that you think\nabout when you try to design a system like this. And I think one thing\nwe can notice here",
    "start": "1947510",
    "end": "1953960"
  },
  {
    "text": "is that there's quite\na lot of diversity in what desirable properties\nand considerations are,",
    "start": "1953960",
    "end": "1960440"
  },
  {
    "text": "and how we would evaluate them. We talked about things such\nas coming up with the right--",
    "start": "1960440",
    "end": "1965720"
  },
  {
    "text": "or doing things in a certain\ncurriculum, which is more about how do we order these tasks. We talked about the\nnotion of memory",
    "start": "1965720",
    "end": "1972410"
  },
  {
    "text": "and how we should be able to\nstill know how to do things that we learned in the past. But at the same\ntime, we would want",
    "start": "1972410",
    "end": "1978620"
  },
  {
    "text": "to get better at learning a new\ntask as we know more and more.",
    "start": "1978620",
    "end": "1983630"
  },
  {
    "text": "And then we talked about\ndifferent evaluation setups, and this was, I\nthought, really fun. So different robot\nnavigation settings.",
    "start": "1983630",
    "end": "1991070"
  },
  {
    "text": "Also, more real life settings,\nsuch as students in school. Robots with, not necessarily\ndoing navigation, but just",
    "start": "1991070",
    "end": "1998570"
  },
  {
    "text": "handling different tasks\nor objects, MNIST digits, and all kinds of things.",
    "start": "1998570",
    "end": "2004280"
  },
  {
    "text": "So thanks a lot. And I did that exercise,\nmyself, a little bit too,",
    "start": "2004280",
    "end": "2012220"
  },
  {
    "text": "and came up with\na few variations, which I think a lot of\nyou came up with as well.",
    "start": "2012220",
    "end": "2017990"
  },
  {
    "text": "So let me list those. So first the task\nand data order might",
    "start": "2017990",
    "end": "2024160"
  },
  {
    "text": "matter, as I think someone\nsaid in the student case. Where we might want to have\na curriculum of tasks for one",
    "start": "2024160",
    "end": "2030550"
  },
  {
    "text": "built on top of\nthe previous one. But we could also\nimagine these tasks as being given to you i.i.d.",
    "start": "2030550",
    "end": "2035590"
  },
  {
    "text": "Or they can be given to\nyou in adversarial fashion. So, for example, you are\nplaying a game with someone,",
    "start": "2035590",
    "end": "2040660"
  },
  {
    "text": "and that other agent is trying\nto find a strategy that would--",
    "start": "2040660",
    "end": "2048835"
  },
  {
    "text": "that is trying to beat you. So it's basically,\nit's trying to find your weakness, or something\nthat is predictable.",
    "start": "2048835",
    "end": "2056290"
  },
  {
    "text": "Where, such as, for example,\nseasons where you can tell that there is\na change coming.",
    "start": "2056290",
    "end": "2061429"
  },
  {
    "text": "And you can predict when\nthe new task or data distribution will come. Another aspect that we\nhaven't talked that much about",
    "start": "2061429",
    "end": "2069138"
  },
  {
    "text": "is whether there are\ndiscrete task boundaries or continuous shifts, right? So we can imagine discrete task\nboundaries where, for example,",
    "start": "2069139",
    "end": "2078090"
  },
  {
    "text": "you have different\nsubjects in school, and you know that one subject\nends and another begins. We can also imagine\ncontinuous shifts",
    "start": "2078090",
    "end": "2084260"
  },
  {
    "text": "when the robot is playing\nwith a bunch of objects and then these objects are\nslowly being exchanged.",
    "start": "2084260",
    "end": "2089290"
  },
  {
    "text": "Or for example, in the\nnavigation scenario the rooms are slowly\nchanging, and it's hard to tell at which point\nyou are given a different task.",
    "start": "2089290",
    "end": "2096815"
  },
  {
    "text": "There's also a question of\nwhether these are known to you or not. So you can know that\nsomething changed. Someone can tell you, now\nyou're in a different room",
    "start": "2096815",
    "end": "2103720"
  },
  {
    "text": "you have to learn. Or it might just\nexperience this, and you'd need to\nadjust to that.",
    "start": "2103720",
    "end": "2109570"
  },
  {
    "text": "And some considerations,\nin terms of the evaluation, is model performance. I think a lot of\nyou mentioned this.",
    "start": "2109570",
    "end": "2116109"
  },
  {
    "text": "Data efficiency. Some people mentioned\nthat, as well. And then things such as\ncomputational resources",
    "start": "2116110",
    "end": "2121720"
  },
  {
    "text": "and memory. But there are also\nother things, and we'll talk about this in a\nsecond, such as privacy",
    "start": "2121720",
    "end": "2127630"
  },
  {
    "text": "or interpretability fairness. And a lot of them are tests\non compute and memory. A lot of them apply to a general\nmachine learning problems--",
    "start": "2127630",
    "end": "2134438"
  },
  {
    "text": "to general machine\nlearning problems. But some of them are more\nspecific to, or more commonly,",
    "start": "2134438",
    "end": "2140942"
  },
  {
    "text": "a lifelong learning scenario.  All right, so we can already\ntell from this exercise,",
    "start": "2140942",
    "end": "2147920"
  },
  {
    "text": "and even from the slide, that\nthere's a substantial variety in the problem statement. And this is a really\nimportant point",
    "start": "2147920",
    "end": "2153410"
  },
  {
    "text": "that I would like you to\nremember when you read papers on lifelong learning.",
    "start": "2153410",
    "end": "2159070"
  },
  {
    "text": "All right, so I'll try to\ncreate a general supervised online learning problem.",
    "start": "2159070",
    "end": "2164480"
  },
  {
    "text": "And given those\nconsiderations, but I'll try to make it quite specific. So we'll be given\ndata points over time,",
    "start": "2164480",
    "end": "2172300"
  },
  {
    "text": "and the problem would\nlook as following. We'll observe the\ndata point, and we'll try to predict the label\nfor the data point.",
    "start": "2172300",
    "end": "2178180"
  },
  {
    "text": "This is a supervised\nonline learning problem. And then we'll get to\nobserve the true label.",
    "start": "2178180",
    "end": "2185559"
  },
  {
    "text": "Right, and if the\nsetting is i.i.d., then our distribution will\nbe not dependent on time.",
    "start": "2185560",
    "end": "2190940"
  },
  {
    "text": "So it doesn't matter\nat which point you're sampling from the\ndistribution p of x, or p of y,",
    "start": "2190940",
    "end": "2196550"
  },
  {
    "text": "given x. You will be sampling from\nthe same distribution. But we can also\nconsider a problem",
    "start": "2196550",
    "end": "2203447"
  },
  {
    "text": "where the distribution\nis dependent on time. So depending when\nyou sample from it, it will look differently.",
    "start": "2203447",
    "end": "2210359"
  },
  {
    "text": "And then there is also\na streaming setting, where the assumption is that you\ncannot store the current sample",
    "start": "2210360",
    "end": "2216000"
  },
  {
    "text": "that you see. So there could be\nvarious reasons for this. For example, it's just too\nbig, and you don't necessarily",
    "start": "2216000",
    "end": "2221519"
  },
  {
    "text": "have the memory to store\nthat, or you don't have enough computational resources. Such as, for example, when you\nhave to classify videos really",
    "start": "2221520",
    "end": "2227842"
  },
  {
    "text": "quickly you don't really\nwant to store them. There are also privacy\nconsiderations.",
    "start": "2227842",
    "end": "2233350"
  },
  {
    "text": "So you could be, in the case\nof the medical assistant,",
    "start": "2233350",
    "end": "2239160"
  },
  {
    "text": "you're not allowed to\nstore the patient's data, but you need to be able\nto use that to make better predictions.",
    "start": "2239160",
    "end": "2245250"
  },
  {
    "text": "Or when you want to study\nneural memory mechanisms, where we, as humans, don't really\nhave hard drives where we can save our data to.",
    "start": "2245250",
    "end": "2252869"
  },
  {
    "text": "So, in general, the streaming\nsetting is true in some cases. But in many cases, these are not\nnecessarily the considerations",
    "start": "2252870",
    "end": "2258960"
  },
  {
    "text": "that we have to consider. In a lot of the\nexamples that we talked about these were not the\nmost important constraints.",
    "start": "2258960",
    "end": "2265650"
  },
  {
    "text": " And in particular,\nremember that, for example,",
    "start": "2265650",
    "end": "2270980"
  },
  {
    "text": "in reinforcement learning,\nwe use replay buffers almost for any off policy algorithm.",
    "start": "2270980",
    "end": "2276920"
  },
  {
    "text": "So it's fairly easy to\nstore the data for us. ",
    "start": "2276920",
    "end": "2284820"
  },
  {
    "start": "2283000",
    "end": "2599000"
  },
  {
    "text": "All right, so what do we\nwant from a lifelong learning algorithm? And there are two particular\nmeasures that are, I think,",
    "start": "2284820",
    "end": "2293050"
  },
  {
    "text": "quite principled, that\nis useful to know about. One of them is regret,\nor minimal regret.",
    "start": "2293050",
    "end": "2298230"
  },
  {
    "text": "So we want a regret\nthat will grow slowly with the number of data points\nover the number of tests.",
    "start": "2298230",
    "end": "2304530"
  },
  {
    "text": "And regret has a strict\nmathematical definition, and is defined as\nthe cumulative loss",
    "start": "2304530",
    "end": "2310140"
  },
  {
    "text": "of the learner minus the\ncumulative loss of the best learner in hindsight. All right.",
    "start": "2310140",
    "end": "2315290"
  },
  {
    "text": "So what that means is a\nformula that looks like this, where the first part-- ",
    "start": "2315290",
    "end": "2322339"
  },
  {
    "text": "let me just check\nmy notes real quick. So the part right here is\ncumulative loss of the learner.",
    "start": "2322340",
    "end": "2331589"
  },
  {
    "text": "So here we have our\nloss that depends on the loss for the\ncurrent task [INAUDIBLE]",
    "start": "2331590",
    "end": "2337760"
  },
  {
    "text": "or for the current data point. And we have the\nparameters, theta. So we don't have\ncontrol over that loss,",
    "start": "2337760",
    "end": "2343377"
  },
  {
    "text": "and this is just something\nthat measures the performance of our algorithm. And then we have our\nparameters theta,",
    "start": "2343377",
    "end": "2349610"
  },
  {
    "text": "that we get to take\nit times [INAUDIBLE].. and this is what our\nalgorithm can produce, so this is what we\ndo have control over.",
    "start": "2349610",
    "end": "2356910"
  },
  {
    "text": "And then we do the\ncumulative loss across all of the data\npoints, or all of the tasks,",
    "start": "2356910",
    "end": "2362570"
  },
  {
    "text": "minus the cumulative loss of\nthe best learner in hindsight. So if we knew all of\nthe tasks up front,",
    "start": "2362570",
    "end": "2369500"
  },
  {
    "text": "and we would find the best\ntheta for all of them, how would the difference\ngrow with the number of tasks, or new tasks, right?",
    "start": "2369500",
    "end": "2377340"
  },
  {
    "text": "So this is the notion of regret. And the goal usually is--",
    "start": "2377340",
    "end": "2382349"
  },
  {
    "text": "so one point here is that\nit's really difficult to evaluate in practice,\nbecause you would need to run this every single time.",
    "start": "2382350",
    "end": "2388980"
  },
  {
    "text": "But it's useful for analysis\nfor different algorithms. And one thing to note is that\nregret that grows linearly in t",
    "start": "2388980",
    "end": "2398829"
  },
  {
    "text": "is trivial. And can you tell\nme why, or can you give me an example of\na regret like this?",
    "start": "2398830",
    "end": "2407350"
  },
  {
    "text": "Or, rather, of a learner that\nachieves a linear regret in t?",
    "start": "2407350",
    "end": "2413230"
  },
  {
    "text": "Please either raise your\nhand, or just speak up. ",
    "start": "2413230",
    "end": "2425940"
  },
  {
    "text": "Any ideas about the regret\nthat will grow linearly in t? ",
    "start": "2425940",
    "end": "2442420"
  },
  {
    "text": "All right, so this might\nbe a little tricky, so let me try to\ngive you one example.",
    "start": "2442420",
    "end": "2449440"
  },
  {
    "text": "So for instance, if we\nhad an algorithm that trains each task from\nscratch, so every time you",
    "start": "2449440",
    "end": "2454470"
  },
  {
    "text": "get a new task, you\ntrain it from scratch, and this term would\ngrow linearly with t. So at every task, assuming that\nthey're of the same difficulty,",
    "start": "2454470",
    "end": "2461400"
  },
  {
    "text": "kind of the regret will be\ngetting bigger and bigger by the same amount.",
    "start": "2461400",
    "end": "2466750"
  },
  {
    "text": "So it will grow linearly\nwith time or with tasks. ",
    "start": "2466750",
    "end": "2473269"
  },
  {
    "text": "All right, does this\nmake sense, more or less? Or are there any questions?",
    "start": "2473270",
    "end": "2479920"
  },
  {
    "text": "Can you explain it again how\n[INAUDIBLE] goes into it.",
    "start": "2479920",
    "end": "2485150"
  },
  {
    "text": "And also I'm looking\nat this small t. Is it the time step or the\ntasks that's being talked there? ",
    "start": "2485150",
    "end": "2494095"
  },
  {
    "text": "Right, so I think\nyou can-- so it kind of depends on the setting. You can either\nconsider this as a task where you are given a\nsingle data point that",
    "start": "2494095",
    "end": "2500329"
  },
  {
    "text": "can be also considered a task. But let's say this\nis the data point, so small t is the\ncurrent data point.",
    "start": "2500330",
    "end": "2509560"
  },
  {
    "text": "And our theta t\nare the parameters that your lifelong\nlearning algorithm",
    "start": "2509560",
    "end": "2515470"
  },
  {
    "text": "can come up with for the\nparticular data point t. All right?",
    "start": "2515470",
    "end": "2520960"
  },
  {
    "text": "And then the capital T is\nacross all the data points that you get to see, and you\nget to see them in sequence.",
    "start": "2520960",
    "end": "2528550"
  },
  {
    "text": "So now the first part is telling\nyou what's the cumulative loss. So the loss that you\nsum up over each one",
    "start": "2528550",
    "end": "2533850"
  },
  {
    "text": "of those of the data points\nfor your parameters, theta t.",
    "start": "2533850",
    "end": "2539360"
  },
  {
    "text": "And then the second\npart of this equation tells you what is the\ncumulative loss of the best",
    "start": "2539360",
    "end": "2545240"
  },
  {
    "text": "learner in hindsight. So across all the data points,\nif you saw all of the data points at once, and you could\nfind the best parameters theta",
    "start": "2545240",
    "end": "2554120"
  },
  {
    "text": "for those, what would be the\ncumulative loss for that? And so this is kind of\nlike our Oracle, the best",
    "start": "2554120",
    "end": "2560840"
  },
  {
    "text": "that we could do. The reason why an algorithm that\nwould train on each data point",
    "start": "2560840",
    "end": "2569780"
  },
  {
    "text": "from scratch has\na linear regret is because, assuming that\neach data point is",
    "start": "2569780",
    "end": "2575720"
  },
  {
    "text": "as difficult as\nthe previous one, that term will grow\nlinearly, all right?",
    "start": "2575720",
    "end": "2584359"
  },
  {
    "text": "So basically, at\nevery point you will be getting a constant loss, and\nthen you'll be summing that up.",
    "start": "2584360",
    "end": "2590030"
  },
  {
    "text": " Does that make sense? Yes, thank you.",
    "start": "2590030",
    "end": "2597240"
  },
  {
    "text": "All right, cool. All right, so there\nwas one other measure that I would like to\nintroduce, and this is",
    "start": "2597240",
    "end": "2605630"
  },
  {
    "start": "2599000",
    "end": "2753000"
  },
  {
    "text": "positive and negative transfer. And this is maybe a\nlittle bit easier. So the positive forward\ntransfer is something",
    "start": "2605630",
    "end": "2614630"
  },
  {
    "text": "that a lot of you mentioned\nduring the discussion, is where the previous tasks\ncause you to do better",
    "start": "2614630",
    "end": "2620600"
  },
  {
    "text": "on future tasks, all right? So that means that as\nyou get more tasks, you are getting better and\nbetter on future tasks.",
    "start": "2620600",
    "end": "2626510"
  },
  {
    "text": "And this is compared to learning\nfuture tasks from scratch. And then the positive\nbackward transfer",
    "start": "2626510",
    "end": "2632497"
  },
  {
    "text": "would mean that the current\ntasks cause you to do better on previous tasks, all right? So as you learn\nmore and more you",
    "start": "2632497",
    "end": "2638609"
  },
  {
    "text": "are getting better at the tasks\nthat you have already seen. And this is also compared\nto learning past tasks",
    "start": "2638610",
    "end": "2644210"
  },
  {
    "text": "from scratch. And if you want to\ntalk about, instead of the positive\ntransfer, you want",
    "start": "2644210",
    "end": "2649430"
  },
  {
    "text": "to talk about the\nnegative transfer, then you need to change the word\n\"better\" to the word \"worse\". And that will be the\ndefinition of that.",
    "start": "2649430",
    "end": "2656000"
  },
  {
    "text": " There are a couple of questions\nabout regret in the chat.",
    "start": "2656000",
    "end": "2661519"
  },
  {
    "text": "So the first question\nis, with linear regret can you say that there is no\nor minimal knowledge learning",
    "start": "2661520",
    "end": "2667430"
  },
  {
    "text": "or transfer from previous tasks? Yeah, exactly. So if there is no positive\ntransfer there is nothing",
    "start": "2667430",
    "end": "2675200"
  },
  {
    "text": "that you're learning from\neach task as it comes, then you're getting\nlinear regret. That basically means\nthat you're not really",
    "start": "2675200",
    "end": "2681470"
  },
  {
    "text": "learning from the process\nof getting these tasks. [INAUDIBLE] is\nasking, can regret",
    "start": "2681470",
    "end": "2687090"
  },
  {
    "text": "be negative if using\njust a single data ends up being too restrictive? ",
    "start": "2687090",
    "end": "2694720"
  },
  {
    "text": "Will the regret be negative-- I see. So I think the question is\nif a single theta is not",
    "start": "2694720",
    "end": "2701410"
  },
  {
    "text": "really able to capture\nall of the task at once,",
    "start": "2701410",
    "end": "2706630"
  },
  {
    "text": "can we do better\nthan that Oracle? I think usually in\nregret we assume that the part on the\nright side is the Oracle.",
    "start": "2706630",
    "end": "2714820"
  },
  {
    "text": "So we assume that we\nhave enough parameters to find the right setting\nto find the minimal loss.",
    "start": "2714820",
    "end": "2721190"
  },
  {
    "text": "So I think usually we don't\nconsider negative regret. ",
    "start": "2721190",
    "end": "2729223"
  },
  {
    "text": "All right, cool. Are there any other\nquestions at this point? So we talked about\nthe problem statement. And we talked quite\na lot about this,",
    "start": "2729223",
    "end": "2735233"
  },
  {
    "text": "so I wanted to tell you a little\nbit about some basic approaches that we can use to tackle that. But before we go there, are\nthere any other questions?",
    "start": "2735233",
    "end": "2743030"
  },
  {
    "text": " All right, if there\nare no questions,",
    "start": "2743030",
    "end": "2749700"
  },
  {
    "text": "then let's jump\ninto the approaches. So I will tell you about some\nvery, very basic approaches.",
    "start": "2749700",
    "end": "2757570"
  },
  {
    "start": "2753000",
    "end": "2932000"
  },
  {
    "text": "So it might seem\nvery, very obvious that this is what\nyou should be doing. But still, I think it's\nimportant to write them out.",
    "start": "2757570",
    "end": "2765161"
  },
  {
    "text": "So one approach is\nthat we can just store all the data that we've\nseen so far and train on it. Right?",
    "start": "2765162",
    "end": "2770550"
  },
  {
    "text": "That's relatively simple,\nand that actually has a name. And the name is, follow the\nleader algorithm, all right?",
    "start": "2770550",
    "end": "2776109"
  },
  {
    "text": "So this is whatever\nyou have seen so far you just keep adding\nto it, and you will take that buffer of\ndata and you'll train on it.",
    "start": "2776110",
    "end": "2785270"
  },
  {
    "text": "So the advantage of that\nis that this actually has a pretty strong baseline. You're training on\nall the tasks that you",
    "start": "2785270",
    "end": "2791330"
  },
  {
    "text": "have seen so far during this\nkind of batch-like setting, and this usually\nworks really well.",
    "start": "2791330",
    "end": "2798410"
  },
  {
    "text": "This is really\ncomputationally intensive, because with every new task,\nor with every new data point, you would have to do\nthe computation on all",
    "start": "2798410",
    "end": "2804850"
  },
  {
    "text": "of the tasks. One thing that can help here is\ncontinuous fine-tuning instead.",
    "start": "2804850",
    "end": "2810930"
  },
  {
    "text": "So you can warm start your model\nfrom the previous iteration, and just perform fine\ntuning, instead of",
    "start": "2810930",
    "end": "2816838"
  },
  {
    "text": "training everything\nfrom scratch every time you get a new data point. And it's going to\nbe also quite memory",
    "start": "2816838",
    "end": "2822860"
  },
  {
    "text": "intensive, because\nyou have to load the entire dataset every time. But that depends, all right.",
    "start": "2822860",
    "end": "2829610"
  },
  {
    "text": "Then another approach\nthat is extremely simple is that you can\ntake a gradient step on the data point you observe.",
    "start": "2829610",
    "end": "2835090"
  },
  {
    "text": "So you get a new data\npoint, you have your model, you can just take the gradient\nstep on that data point.",
    "start": "2835090",
    "end": "2840920"
  },
  {
    "text": "And it also has a\nname, and that name is stochastic gradient descent. That's hopefully most\nof us are familiar with.",
    "start": "2840920",
    "end": "2847830"
  },
  {
    "text": "So every time we get a new data,\nwe'll perform the gradient step on it, and that will allow us to\nmove towards the direction that",
    "start": "2847830",
    "end": "2858050"
  },
  {
    "text": "minimizes the loss. All right, this is very\ncomputationally cheap.",
    "start": "2858050",
    "end": "2863560"
  },
  {
    "text": "We just need to perform\none gradient step on the data point. It requires zero memory, so we\ncan just compute the gradient.",
    "start": "2863560",
    "end": "2871040"
  },
  {
    "text": "Take it, and that's it. We don't need to store the data. But that's subject to\nnegative backward transfer.",
    "start": "2871040",
    "end": "2877400"
  },
  {
    "text": "So if we only get to do gradient\nsteps on the new data that is coming in, that might mean\nthat we can forget about all",
    "start": "2877400",
    "end": "2885800"
  },
  {
    "text": "the old data that we've seen. And because of this\nthat might lead to us forgetting about\nwhat we've done previously.",
    "start": "2885800",
    "end": "2892820"
  },
  {
    "text": "And this is often\nreferred to as forgetting, or also referred to as\ncatastrophic forgetting,",
    "start": "2892820",
    "end": "2898610"
  },
  {
    "text": "depending on the application. And I think we also know from\nstochastic gradient descent,",
    "start": "2898610",
    "end": "2906650"
  },
  {
    "text": "very often we need to\ndo multiple epochs. We need to go over the\ndata multiple times. And it requires quite some\ntime for this to converge.",
    "start": "2906650",
    "end": "2914700"
  },
  {
    "text": "So it can be quite a\nslow-learning algorithm. All right, so these are basic\napproaches that kind of we",
    "start": "2914700",
    "end": "2923210"
  },
  {
    "text": "can think of straight away. And I wanted to show you\none implementation of such a very simple approach in\nthe reinforcement learning",
    "start": "2923210",
    "end": "2929805"
  },
  {
    "text": "scenario.  So this will be a very simple\ncontinual reinforcement",
    "start": "2929805",
    "end": "2935680"
  },
  {
    "start": "2932000",
    "end": "3323000"
  },
  {
    "text": "learning algorithm. And this is work done by\nRyan Julian and others.",
    "start": "2935680",
    "end": "2942890"
  },
  {
    "text": "So in this work we\nhave seven robots that collected 500,000 grasps.",
    "start": "2942890",
    "end": "2948130"
  },
  {
    "text": "And this is the similar\nsetting that you have seen when we were\ndiscussing the QT paper when we were talking\nabout skill learning.",
    "start": "2948130",
    "end": "2954620"
  },
  {
    "text": "So we have these robots\nthat then we can evaluate how well they can do grasping.",
    "start": "2954620",
    "end": "2959770"
  },
  {
    "text": "We train the policy using\nreinforcement learning, and, given a specific bin\nand this set of objects,",
    "start": "2959770",
    "end": "2966700"
  },
  {
    "text": "they can achieve 86% success\nrate on grasping these objects.",
    "start": "2966700",
    "end": "2972060"
  },
  {
    "text": "But then we can also\nfind a scenario where the algorithm is not that good. So for example, in this case, we\nthrew a few transparent bottles",
    "start": "2972060",
    "end": "2979680"
  },
  {
    "text": "into the bin. And these are visually\nchallenging objects, and the algorithm did not\nperform nearly as well.",
    "start": "2979680",
    "end": "2985810"
  },
  {
    "text": "So the evaluation performance\nof that algorithm was just 49%. ",
    "start": "2985810",
    "end": "2991860"
  },
  {
    "text": "So we can consider this\nas a very little sliver of a lifelong learning\nscenario where",
    "start": "2991860",
    "end": "2997380"
  },
  {
    "text": "you are presented with a\nslightly new condition, or you're in a slightly\nnew environment. Or in this case, you're\ndealing with slightly different",
    "start": "2997380",
    "end": "3004322"
  },
  {
    "text": "objects, and you need to adapt\nto it quickly, all right? So the kind of mental model\nthat you can have in mind",
    "start": "3004322",
    "end": "3010050"
  },
  {
    "text": "is something like this. We have our pretraining\ntask that we trained all these robots on. This was with 580,000 grasps.",
    "start": "3010050",
    "end": "3017520"
  },
  {
    "text": "We have the old data that\nis stored somewhere on this. And we have a policy\nthat we trained",
    "start": "3017520",
    "end": "3022740"
  },
  {
    "text": "using some affine reinforcement\nlearning algorithm. And then we have a new data\nthat we, for example, used",
    "start": "3022740",
    "end": "3029990"
  },
  {
    "text": "to compute that number, 49%. And now we need to\nuse that new data,",
    "start": "3029990",
    "end": "3035310"
  },
  {
    "text": "combine it with the policy\nthat we have so far, and perform some kind\nof adaptation procedure so that we are getting better\nat this new task, all right?",
    "start": "3035310",
    "end": "3042230"
  },
  {
    "text": " So this is the adaptation\nprocedure that we came up with,",
    "start": "3042230",
    "end": "3047840"
  },
  {
    "text": "and this is really,\nreally simple. So let me quickly go over this. So here on the left here,\nyou see the base dataset.",
    "start": "3047840",
    "end": "3056280"
  },
  {
    "text": "So this is the dataset that we\noriginally created, and this was around 608,000 grasps.",
    "start": "3056280",
    "end": "3064340"
  },
  {
    "text": "And this achieved 86% success\nrate, as we mentioned before. So this was the--\nthis used the QT-opt--",
    "start": "3064340",
    "end": "3071150"
  },
  {
    "text": "in the QT-opt algorithm\nto train the Q function. So to train our-- from that we can get\nour policy that can",
    "start": "3071150",
    "end": "3077720"
  },
  {
    "text": "achieve that 86% success rate. And then we'll use\nthat policy to collect",
    "start": "3077720",
    "end": "3083540"
  },
  {
    "text": "a little bit more data in a\nslightly different scenario. So, for example, in\ntransparent bubbles. Or we tried a few other\nscenarios as well,",
    "start": "3083540",
    "end": "3089810"
  },
  {
    "text": "and that's what yielded the\nmuch lower success rate. And we will collect a little\nbit of data in that scenario.",
    "start": "3089810",
    "end": "3095550"
  },
  {
    "text": "So less than 800 grasps. Then we will mix the data\n50-50 with the base dataset",
    "start": "3095550",
    "end": "3103430"
  },
  {
    "text": "that we had. And then we'll fine\ntune our Q-function based on that mixture of data\nthat we collected, all right?",
    "start": "3103430",
    "end": "3110940"
  },
  {
    "text": "So we have the\ndataset here and now we are fine tuning\nour Q-function. So we are warm\nstarting the model",
    "start": "3110940",
    "end": "3116540"
  },
  {
    "text": "from the previous\nQ-function, and we are fine tuning it using the data. And from that we get the\nadaptive Q-function that,",
    "start": "3116540",
    "end": "3123050"
  },
  {
    "text": "hopefully, will perform\nbetter at that task",
    "start": "3123050",
    "end": "3129250"
  },
  {
    "text": "All right, OK, so\nwe evaluated this in a few different scenarios\nthat were quite challenging for the robot.",
    "start": "3129250",
    "end": "3135250"
  },
  {
    "text": "So here are the scenarios. So on the left, this is the\npretraining that achieved 86%. And then we are looking for\nscenarios where the robot",
    "start": "3135250",
    "end": "3142420"
  },
  {
    "text": "wouldn't perform as well. So one is harsh\nlighting conditions with our transparent bottles\nthat we talked about as well.",
    "start": "3142420",
    "end": "3149630"
  },
  {
    "text": "We also found that checkerboard\nbacking was really confusing for the robot. It would very often try\nto grasp at the edges",
    "start": "3149630",
    "end": "3155349"
  },
  {
    "text": "of the checkerboard. And then we also changed\nthe morphology a little bit. So we extended the gripper\nto be a little bit longer,",
    "start": "3155350",
    "end": "3161058"
  },
  {
    "text": "and we also offset the\ngripper a little bit to the right where you can see\nthat the gripper is supposed",
    "start": "3161058",
    "end": "3166270"
  },
  {
    "text": "to be here, but it's a little\nbit offset by 10 centimeters. And here at the top you can see\nthe results of the base policy",
    "start": "3166270",
    "end": "3174060"
  },
  {
    "text": "running in these conditions. So you can see that\nin every single time it's quite a bit lower than 86%.",
    "start": "3174060",
    "end": "3180570"
  },
  {
    "text": "And after the simple\nfine tuning procedure these numbers went\nup by quite a bit.",
    "start": "3180570",
    "end": "3186890"
  },
  {
    "text": "So we have a very,\nvery simple fine tuning procedure that continues to\nuse reinforcement learning.",
    "start": "3186890",
    "end": "3193426"
  },
  {
    "text": "And it's going to improve\nthe performance quite a bit. ",
    "start": "3193426",
    "end": "3199760"
  },
  {
    "text": "All right, so we talk here\nabout continual learning or lifelong learning. So how does that little sliver\nof the problem help us here?",
    "start": "3199760",
    "end": "3207869"
  },
  {
    "text": "So since this\nprocedure is so simple, we can actually apply\nit over and over again. So we can collect our\ninitial grasping dataset,",
    "start": "3207870",
    "end": "3216650"
  },
  {
    "text": "do our adaptation\nprocedure right here using the new dataset.",
    "start": "3216650",
    "end": "3222500"
  },
  {
    "text": "And then given\nthat result, we can continue doing this and kind of\nchange the environment again. And continue doing\nit again, and so on.",
    "start": "3222500",
    "end": "3229620"
  },
  {
    "text": "So we did this\nexperiment, and we found that actually\nthe performance that you get by doing\nthis continually",
    "start": "3229620",
    "end": "3237170"
  },
  {
    "text": "is fairly similar\nto the performance that we got in the single\ntime fine tuning procedure.",
    "start": "3237170",
    "end": "3243810"
  },
  {
    "text": "So this is an example of a very\nsimple continual RL algorithm",
    "start": "3243810",
    "end": "3249590"
  },
  {
    "text": "that is a basically follow\nthe leader algorithm, where we are doing fine tuning\nas opposed to training on all of the tasks.",
    "start": "3249590",
    "end": "3256400"
  },
  {
    "text": "But here we are doing this with\nreinforcement learning, right? Does make sense?",
    "start": "3256400",
    "end": "3262017"
  },
  {
    "text": "Is this clear? Are there any questions? ",
    "start": "3262017",
    "end": "3268357"
  },
  {
    "text": "I think there's a question\non chat, \"when you fine tune you only evaluate\non the respective data or in totality like\nprevious datasets as well?\"",
    "start": "3268357",
    "end": "3274430"
  },
  {
    "text": "Yeah, this is a great question. So we're only evaluating\nthis on the respective data. So on the data that\nwe are fine-tuning on.",
    "start": "3274430",
    "end": "3281180"
  },
  {
    "text": "So with this it is\npotentially true that if we tested the\nbackward transfer-- so",
    "start": "3281180",
    "end": "3287450"
  },
  {
    "text": "whether we can still\ndo well, for example, in the harsh light that we\ntried at the very beginning-- the performance\nmight have dropped.",
    "start": "3287450",
    "end": "3293240"
  },
  {
    "text": " And so we didn't really\nevaluate the backward transfer.",
    "start": "3293240",
    "end": "3298900"
  },
  {
    "text": " All right, if there\nare no other questions, then one question that\nI would want to ask",
    "start": "3298900",
    "end": "3305620"
  },
  {
    "text": "is, so far we discussed\nvery simple algorithms, so the question is, can\nwe do better than this?",
    "start": "3305620",
    "end": "3313140"
  },
  {
    "text": "So let me briefly\nintroduce one approach that allows us to do this.",
    "start": "3313140",
    "end": "3318765"
  },
  {
    "text": "And I will go over\nthis fairly quickly, because we're slowly\nrunning out of time.",
    "start": "3318765",
    "end": "3324650"
  },
  {
    "start": "3323000",
    "end": "3542000"
  },
  {
    "text": "So the idea is as following. Can we modify vanilla SGD,\nstochastic gradient descent,",
    "start": "3324650",
    "end": "3332020"
  },
  {
    "text": "to avoid negative\nbackward transfer? So here the algorithms\nare focusing more on the negative\nbackward transfer.",
    "start": "3332020",
    "end": "3337910"
  },
  {
    "text": "So the concept of forgetting. And this is the paper by\nLopez-Paz and Ranzato,",
    "start": "3337910",
    "end": "3344170"
  },
  {
    "text": "called \"Gradient Episodic\nMemory for Continual Learning\", and the idea is as following.",
    "start": "3344170",
    "end": "3349859"
  },
  {
    "text": "It'll store a small amount\nof data per task in memory. So this is not necessarily\nthe entire dataset",
    "start": "3349860",
    "end": "3355020"
  },
  {
    "text": "that you get to see,\nbut for every task it will store a little\nbit of it in memory.",
    "start": "3355020",
    "end": "3360510"
  },
  {
    "text": "And then we're making\nupdates for new tasks. They will try to make sure\nthat they don't unlearn",
    "start": "3360510",
    "end": "3365820"
  },
  {
    "text": "previous tasks, all right? So this is fairly common.",
    "start": "3365820",
    "end": "3370960"
  },
  {
    "text": "And the idea is kind\nof fairly obvious. You're trying to\nlearn in such a way",
    "start": "3370960",
    "end": "3376109"
  },
  {
    "text": "that you don't forget about the\nthings that you knew before. But the question is, how do\nyou actually accomplish this?",
    "start": "3376110",
    "end": "3382779"
  },
  {
    "text": "So in this paper they\ntry to tackle this from an optimization\nperspective.",
    "start": "3382780",
    "end": "3387870"
  },
  {
    "text": "And, in particular, they\npropose something like this. They start with\nlearning a predictor.",
    "start": "3387870",
    "end": "3393640"
  },
  {
    "text": "So this is our predictor,\nour function f of the theta that you're learning. And this is given a current\ndata point and some task, Zt.",
    "start": "3393640",
    "end": "3404190"
  },
  {
    "text": "And they are trying to\nlearn the label for that. And here we also assume that we\nhave memory for the kth task,",
    "start": "3404190",
    "end": "3410950"
  },
  {
    "text": "or for the task Zk, memory\nthat is denoted as Mk. ",
    "start": "3410950",
    "end": "3417460"
  },
  {
    "text": "And now for each task we'll\ntry to minimize the loss as we usually do, for that new\ndata point for the new task.",
    "start": "3417460",
    "end": "3426880"
  },
  {
    "text": "But we'll do it subject\nto this constraint, the constraint right here.",
    "start": "3426880",
    "end": "3432619"
  },
  {
    "text": "And what that\nconstraint says, this is basically us trying to\nensure point number two.",
    "start": "3432620",
    "end": "3438010"
  },
  {
    "text": "So what this constraint says is\nthat our loss for another task,",
    "start": "3438010",
    "end": "3445870"
  },
  {
    "text": "for the previous task, Zk-- that we can evaluate\nbased on the data that we stored in the\nmemory for that task",
    "start": "3445870",
    "end": "3453850"
  },
  {
    "text": "should be lesser or\nequal to the loss",
    "start": "3453850",
    "end": "3459430"
  },
  {
    "text": "that we had at the previous\niteration for that task. So basically we're not allowed-- our loss is not allowed\nto go up for the task",
    "start": "3459430",
    "end": "3466690"
  },
  {
    "text": "that we are not training at. So basically, loss\non the previous task",
    "start": "3466690",
    "end": "3471930"
  },
  {
    "text": "does not get worse. And in particular, the way\nthey are trying to achieve this is that they assume the\nlinearity of the optimization",
    "start": "3471930",
    "end": "3480510"
  },
  {
    "text": "landscape. And by doing so, they can\nexpress that constraint as following, as the inner\nproduct between the gradient",
    "start": "3480510",
    "end": "3488820"
  },
  {
    "text": "with respect to\nour current task, our data point t, and the other\ntasks that can be evaluated",
    "start": "3488820",
    "end": "3498270"
  },
  {
    "text": "based on the memory, Mk. So if that inner\nproduct is non-negative,",
    "start": "3498270",
    "end": "3504270"
  },
  {
    "text": "that means that there is only\npositive or non-transfer. And so basically if\nthese two gradients",
    "start": "3504270",
    "end": "3509550"
  },
  {
    "text": "are perpendicular\nto each other, that means that when we are\ntaking regular with respect to our current task we won't\nbe negatively influencing",
    "start": "3509550",
    "end": "3515850"
  },
  {
    "text": "any other tasks that are\ncompletely independent. And if that inner\nproduct is positive, that means that by taking\nthe loss for our task,",
    "start": "3515850",
    "end": "3525150"
  },
  {
    "text": "by taking the gradient towards-- that makes our task better, we\nwill be also making other tasks",
    "start": "3525150",
    "end": "3530609"
  },
  {
    "text": "better at the same time. And they try to ensure it for\nall of the previous tasks.",
    "start": "3530610",
    "end": "3535700"
  },
  {
    "text": " And then they\nformulate it themselves as a quadratic program.",
    "start": "3535700",
    "end": "3543290"
  },
  {
    "start": "3542000",
    "end": "3599000"
  },
  {
    "text": "All right, so a little\nbit about the experiments. They tried three\ndifferent experiments that are quite common\nin this literature,",
    "start": "3543290",
    "end": "3550220"
  },
  {
    "text": "such as endless permutations,\nwhere they are permuting different pixels in the MNIST\ndigits, and MNIST images.",
    "start": "3550220",
    "end": "3556080"
  },
  {
    "text": "They also tried different\nrotations of MNIST digits that are given to\nyou in sequence, as well as CIFAR-100,\nwhere they were",
    "start": "3556080",
    "end": "3564980"
  },
  {
    "text": "assuming that each task would\ninvolve five new classes. ",
    "start": "3564980",
    "end": "3571272"
  },
  {
    "text": "All right, the total memory\nsize that they were using was 5,012 examples that\nwas split among the tasks",
    "start": "3571272",
    "end": "3577950"
  },
  {
    "text": "that they were considering. And here are some\nof the results. So first I would like you to\nfocus on the pure accuracy.",
    "start": "3577950",
    "end": "3585630"
  },
  {
    "text": "So one of the things\nthat we discussed was how would you measure a\ncontinual learning algorithm. You would just look at the\naccuracy of that algorithm.",
    "start": "3585630",
    "end": "3594027"
  },
  {
    "text": "And here you can see\nthat their method called GM or GEM achieves\nreally good accuracy.",
    "start": "3594027",
    "end": "3599970"
  },
  {
    "text": "And then it also presents\npositive backward transfer, as well as slightly positive\nfor almost zero forward transfer",
    "start": "3599970",
    "end": "3607569"
  },
  {
    "text": "But then more interestingly, you\ncan see the result on the right here, where they show how\nthat performance declines,",
    "start": "3607570",
    "end": "3614589"
  },
  {
    "text": "or how this performance\nchanged after seeing more and more tasks. So here on the\nx-axis we are seeing",
    "start": "3614590",
    "end": "3620050"
  },
  {
    "text": "the task number, or the number\nof tasks you saw so far.",
    "start": "3620050",
    "end": "3625280"
  },
  {
    "text": "And on the y-axis is the\nperformance of task number one, all right? So at this point you\nlearn task number one.",
    "start": "3625280",
    "end": "3632750"
  },
  {
    "text": "This was your\noriginal performance. And as you get to see\nmore and more tasks, your performance stays\nmore or less constant.",
    "start": "3632750",
    "end": "3638089"
  },
  {
    "text": "It doesn't drop,\nbecause you're learning from this constraint that\nprevents you from forgetting.",
    "start": "3638090",
    "end": "3645268"
  },
  {
    "text": " This is a little bit of a\nbump, but hopefully we'll",
    "start": "3645268",
    "end": "3650460"
  },
  {
    "text": "get to the end. So then they also evaluated\nthis on MNIST rotations,",
    "start": "3650460",
    "end": "3657030"
  },
  {
    "text": "and showed very similar\nresults, as well as CIFAR-100 where we can see\nthat this curve stays high,",
    "start": "3657030",
    "end": "3663912"
  },
  {
    "text": "as opposed to the\nother curves that dropped quite a\nbit because they're subject to the\nnegative transfer.",
    "start": "3663912",
    "end": "3670378"
  },
  {
    "text": "And negative backward transfer.  Right, then one thing to\nconsider when looking at papers",
    "start": "3670378",
    "end": "3676720"
  },
  {
    "text": "that talk about\ncontinual learning and propose these\nalgorithms is that sometimes the assumptions that they make\nand the algorithms that they",
    "start": "3676720",
    "end": "3683260"
  },
  {
    "text": "introduce, they\ndon't necessarily apply to the\nparticular experiments that they're running.",
    "start": "3683260",
    "end": "3688460"
  },
  {
    "text": "So in this case, if\nwe took a step back and we looked at the assumptions\nthat they started before you",
    "start": "3688460",
    "end": "3695590"
  },
  {
    "text": "can just store all the data\nfor all the previous tasks, well, this is not necessarily\ntrue in this case.",
    "start": "3695590",
    "end": "3701140"
  },
  {
    "text": "You're operating\non MNIST digits, and you can fairly easily\nstore all the images",
    "start": "3701140",
    "end": "3706427"
  },
  {
    "text": "that you get to see. So some of the\nassumptions may be don't match with the\nexperimental domain, and this is something\nto pay attention to.",
    "start": "3706427",
    "end": "3712850"
  },
  {
    "text": "And this is quite tricky to do. Find the right\nexperimental domain that is kind of realistic\nand shows the properties",
    "start": "3712850",
    "end": "3719350"
  },
  {
    "text": "of your algorithm, all right? And there are also\napproaches that",
    "start": "3719350",
    "end": "3724430"
  },
  {
    "text": "do this using meta\nlearning, that try to avoid negative backward\ntransfer through that.",
    "start": "3724430",
    "end": "3730310"
  },
  {
    "text": "And here are some papers that\nI would suggest you to take a look at that try to do this.",
    "start": "3730310",
    "end": "3736670"
  },
  {
    "text": " All right in the\nlast 10 minutes or so",
    "start": "3736670",
    "end": "3745430"
  },
  {
    "text": "we will talk about revisiting\nthe problem statement from the meta\nlearning perspective. So how can we change that\nproblem statement, such",
    "start": "3745430",
    "end": "3752690"
  },
  {
    "text": "that we can apply some of\nour meta learning algorithms that we learned about?",
    "start": "3752690",
    "end": "3757970"
  },
  {
    "text": "So that the problem statement\nis a little bit more tailored towards those and\nI think makes more sense,",
    "start": "3757970",
    "end": "3764660"
  },
  {
    "text": "in general. Are there any questions\nat this point? All right, in the meantime, I\nwill quickly adjust my charger.",
    "start": "3764660",
    "end": "3791140"
  },
  {
    "text": "Just a second. ",
    "start": "3791140",
    "end": "3805510"
  },
  {
    "text": "I have one quick question\nin the chat asking about SNAIL, which is the Simple\nNeural Attentive Meta-Learner.",
    "start": "3805510",
    "end": "3812405"
  },
  {
    "text": "SNAIL reminds me of\ncontinual learning. Is it an example of\ncontinuous learning? Right, maybe that's a\nquestion that you, Chelsea,",
    "start": "3812405",
    "end": "3820720"
  },
  {
    "text": "can say something about, since\nyou've covered SNAIL before. What do you think? Yeah, I can take that.",
    "start": "3820720",
    "end": "3826310"
  },
  {
    "text": "So the SNAIL\nalgorithm, it is really a meta learning\nalgorithm that kind of",
    "start": "3826310",
    "end": "3832660"
  },
  {
    "text": "can adapt to a dataset using an\nattention based architecture.",
    "start": "3832660",
    "end": "3839260"
  },
  {
    "text": "Like Carl will\ndiscuss in a minute, you can actually kind of\ntake meta learning algorithms and apply them to\nonline settings.",
    "start": "3839260",
    "end": "3845740"
  },
  {
    "text": "But the SNAIL algorithm itself\nis not a lifelong learning algorithm, because\nit just adapts to a fixed data set rather than\nan evolving scene with data.",
    "start": "3845740",
    "end": "3856119"
  },
  {
    "start": "3856120",
    "end": "3864820"
  },
  {
    "text": "All right, thank you. Are there any other questions?",
    "start": "3864820",
    "end": "3870710"
  },
  {
    "text": "Great, OK. So let's talk about how we can\nrevisit the lifelong learning",
    "start": "3870710",
    "end": "3877060"
  },
  {
    "text": "problem statement from the\nmeta learning perspective. So the original online\nlearning formulation,",
    "start": "3877060",
    "end": "3885080"
  },
  {
    "text": "that was introduced\nin these two papers, focuses on a very\nspecific setting",
    "start": "3885080",
    "end": "3890567"
  },
  {
    "text": "where we have to perform\na sequence of tasks while minimizing static regret. So what that means is that you\nare given tasks in sequence,",
    "start": "3890567",
    "end": "3897980"
  },
  {
    "text": "and your performance is\nmeasured as soon as you are given a new task, all right? So you don't have any\nadditional time to kind of adapt",
    "start": "3897980",
    "end": "3905660"
  },
  {
    "text": "to this task, the clock\nwill start ticking, or it will start\nmeasuring your performance as soon as you get to see\nthat new task, all right?",
    "start": "3905660",
    "end": "3912585"
  },
  {
    "text": " So it basically tries to measure\nthe zero-shot performance.",
    "start": "3912585",
    "end": "3920050"
  },
  {
    "text": "The better you are\nat being really good at this test straight away,\nthe better that metric will be.",
    "start": "3920050",
    "end": "3926490"
  },
  {
    "text": "But more realistically,\nwhat we would want to do is to be presented\nthe task, and then given a little bit of time\nto learn the new task,",
    "start": "3926490",
    "end": "3933360"
  },
  {
    "text": "to adapt to the new task, and\nthen be evaluated on the task. So we want to get a\nlittle bit of time",
    "start": "3933360",
    "end": "3938820"
  },
  {
    "text": "to just figure out\nwhat the task is, and then be evaluated on this.",
    "start": "3938820",
    "end": "3944110"
  },
  {
    "text": "So we'll do this\nover time, and slowly learn the next task, and\nnext task, and so on. And then we would want to\nevaluate the performance of it,",
    "start": "3944110",
    "end": "3950805"
  },
  {
    "text": "as opposed to evaluating the\nperformance straight away zero-shot.",
    "start": "3950805",
    "end": "3956410"
  },
  {
    "text": "And we also want to do\nit such that initially we started learning quite\nslowly, but eventually it gets faster and faster.",
    "start": "3956410",
    "end": "3962390"
  },
  {
    "text": "So we can learn a new\ntask much more rapidly the more tasks we are given. ",
    "start": "3962390",
    "end": "3968450"
  },
  {
    "text": "All right, so in this\npaper the authors proposed to formulate an online\nmeta learning problem, where",
    "start": "3968450",
    "end": "3975320"
  },
  {
    "text": "we try to efficiently\nlearn a sequence of tasks from a non-stationary\ndistribution.",
    "start": "3975320",
    "end": "3980930"
  },
  {
    "text": "So in that case,\nthe performance, the evaluation will\nbe done after seeing",
    "start": "3980930",
    "end": "3986230"
  },
  {
    "text": "a small amount of data. So we'll have this\nshort learning period where you can quickly adapt, and\nafter that the performance will",
    "start": "3986230",
    "end": "3994270"
  },
  {
    "text": "be evaluated. So it's important to\nnote that the difference between these two is just in\nevaluation rather than a data",
    "start": "3994270",
    "end": "4000640"
  },
  {
    "text": "stream. They're still given the tasks\nthat are coming in sequence, but you're being evaluated\nslightly differently.",
    "start": "4000640",
    "end": "4006643"
  },
  {
    "text": "The online\nmeta-learning case, you are given the small,\nshort learning period that allows you\nto adapt a little bit.",
    "start": "4006643",
    "end": "4012020"
  },
  {
    "start": "4012020",
    "end": "4017320"
  },
  {
    "text": "All right, so let's talk about\nthis online meta-learning setting. And let's introduce\na simple algorithm that will remind\nyou of an algorithm",
    "start": "4017320",
    "end": "4023800"
  },
  {
    "text": "that you have seen before. So for the online\nmeta-learning setting, we will iterate over tasks.",
    "start": "4023800",
    "end": "4031010"
  },
  {
    "text": "And then first we'll\nobserve this little dataset, the training data\nset for the tasks that we are given at\nthe current timestep.",
    "start": "4031010",
    "end": "4037640"
  },
  {
    "text": "And that will be the dataset\nfrom the learning period.  And then we'll have to come up\nwith some update procedure that",
    "start": "4037640",
    "end": "4045640"
  },
  {
    "text": "will produce the parameters\nfor our learner-- for our function. So parameters--\nphi t for instance.",
    "start": "4045640",
    "end": "4054832"
  },
  {
    "text": "And then we'll get to observe\nthe data point, predict the label for the data\npoint using the parameters. So the parameters\nfunction as parameters,",
    "start": "4054832",
    "end": "4062080"
  },
  {
    "text": "sorry, I screwed up,\nthose parameterized by phi t, that is an output\nof our update procedure",
    "start": "4062080",
    "end": "4070950"
  },
  {
    "text": "that we get to, if we get to\nadjust based on our learning period. And then we'll get\nto observe the label.",
    "start": "4070950",
    "end": "4077490"
  },
  {
    "start": "4077490",
    "end": "4083830"
  },
  {
    "text": "So the last part\nof the for loop is basically equivalent to\nthe standard online setting",
    "start": "4083830",
    "end": "4090339"
  },
  {
    "text": "where you're observing\nthe data point, predicting the label for it,\nand then you observe the label.",
    "start": "4090340",
    "end": "4096799"
  },
  {
    "text": "But here, the first\npart that allows you to use that learning\nperiod to learn a better update procedure.",
    "start": "4096800",
    "end": "4102950"
  },
  {
    "text": "And the goal is similar to\nthe goal that we had before. So we're trying to\nfind the learning algorithm of sub-linear regret.",
    "start": "4102950",
    "end": "4110380"
  },
  {
    "text": "We defined regret\nbefore where it's the difference between\nthe loss of the algorithm",
    "start": "4110380",
    "end": "4116380"
  },
  {
    "text": "minus the loss of the best\nalgorithm in hindsight. ",
    "start": "4116380",
    "end": "4123000"
  },
  {
    "text": "All right, so given that\nthe problem setting, can we apply meta learning in\nthis lifelong learning setting?",
    "start": "4123000",
    "end": "4130659"
  },
  {
    "text": "So if we recall the follow\nthe leader algorithm, the basic idea is\nthat we would store all the data that\nwe've seen so far,",
    "start": "4130660",
    "end": "4136920"
  },
  {
    "text": "and then we'll train on it. And then once we\ntrain on it, we will deploy from the current task.",
    "start": "4136920",
    "end": "4143250"
  },
  {
    "text": "So here we will\nchange it slightly, and we'll say we'll\nintroduce the follow the meta-leader algorithm.",
    "start": "4143250",
    "end": "4149039"
  },
  {
    "text": "Or we'll store all the data\nthat we've seen so far, but instead of just\ntraining it, we'll meta-train on it to get to\na better update procedure.",
    "start": "4149040",
    "end": "4159145"
  },
  {
    "text": "And then we'll run\nthe update procedure on the current task, all right? So it's very, very close,\nbut slightly different.",
    "start": "4159145",
    "end": "4166310"
  },
  {
    "text": "And given that follow the\nmeta-leader idea, what do you think are good\nmeta-learning algorithms",
    "start": "4166310",
    "end": "4174028"
  },
  {
    "text": "that would work well for follow\nthe meta-leader algorithm?",
    "start": "4174029",
    "end": "4179068"
  },
  {
    "text": "And this might be a\nlittle tricky question. So just to guide\nyou a little bit,",
    "start": "4179069",
    "end": "4184210"
  },
  {
    "text": "consider a setting where\nour distribution of task is non-stationary, so the\nnew task that you're given",
    "start": "4184210",
    "end": "4191083"
  },
  {
    "text": "may be a little bit\nout of distribution, and you need to\nextrapolate a little bit. And in particular,\nremember at some point",
    "start": "4191083",
    "end": "4198640"
  },
  {
    "text": "Chelsea was talking\nabout black box meta-learners versus gradient\nbased meta-learning algorithms.",
    "start": "4198640",
    "end": "4205280"
  },
  {
    "text": "So what do you think? What are good\nmeta-learning algorithms that are well-suited for\nfollow the meta-leader?",
    "start": "4205280",
    "end": "4211600"
  },
  {
    "text": "Please either raise your hand,\nor you can answer in the chat. ",
    "start": "4211600",
    "end": "4225365"
  },
  {
    "text": "Or you can just speak\nup straight away. ",
    "start": "4225365",
    "end": "4230820"
  },
  {
    "text": "An LSTM, OK. So an optimization based\nmeta-learner could be--",
    "start": "4230820",
    "end": "4237300"
  },
  {
    "text": "that's one option.  Optimization based since all\ndata is available at all times,",
    "start": "4237300",
    "end": "4244990"
  },
  {
    "text": "and you can do warm\nresearch a la MAML, OK. ",
    "start": "4244990",
    "end": "4252014"
  },
  {
    "text": "All right, so in\nparticular, what I'm trying to\npoint to here is, I think what Chelsea mentioned in\none of the previous lectures,",
    "start": "4252015",
    "end": "4259280"
  },
  {
    "text": "is that the optimization-based,\nthe gradient-based meta-learning algorithms are\npotentially a little bit better",
    "start": "4259280",
    "end": "4265030"
  },
  {
    "text": "at extrapolating, at finding the\ntask that is a little bit out of distribution.",
    "start": "4265030",
    "end": "4272059"
  },
  {
    "text": "As opposed to the\nblack box meta-learners that are not as good\nat extrapolating.",
    "start": "4272060",
    "end": "4277869"
  },
  {
    "text": "And they're doing more of an\ninterpolation between the tasks",
    "start": "4277870",
    "end": "4283220"
  },
  {
    "text": "that you already see. ",
    "start": "4283220",
    "end": "4288720"
  },
  {
    "text": "All right, so that online\nmeta-learning paper introduces an algorithm\nthat uses MAML to do this.",
    "start": "4288720",
    "end": "4297570"
  },
  {
    "text": "So one of the answers\nfrom chat was correct. Basically, that's follow\nthe meta-leader algorithm,",
    "start": "4297570",
    "end": "4303630"
  },
  {
    "text": "where we are doing\nthe meta-training using the MAML algorithm.",
    "start": "4303630",
    "end": "4308850"
  },
  {
    "text": "And they evaluate the algorithm\nbased on a sequence of tasks.",
    "start": "4308850",
    "end": "4316240"
  },
  {
    "text": "So first, they do\nit with colored or rotated or\nscaled MNIST digits.",
    "start": "4316240",
    "end": "4321300"
  },
  {
    "text": "They also try a task of\n3D object pose prediction, where you are given\nviewpoints of a new object,",
    "start": "4321300",
    "end": "4329105"
  },
  {
    "text": "and you have to tell what's\nthe orientation of that object with respect to\nsome frame of reference.",
    "start": "4329105",
    "end": "4334260"
  },
  {
    "text": "In this case, this\nred dot on the table. And then they also do\nCIFAR-100 classification,",
    "start": "4334260",
    "end": "4339920"
  },
  {
    "text": "where new classes are\nconsidered a new task.  All right, so we'll look\nat a few comparisons.",
    "start": "4339920",
    "end": "4347305"
  },
  {
    "text": "So first comparison,\nthe first baseline would be called\nTOE, or T-O-E, where",
    "start": "4347305",
    "end": "4353580"
  },
  {
    "text": "they just trained on all the\ndata that they've seen so far. Then they'll also try the follow\nthe leader algorithm, which",
    "start": "4353580",
    "end": "4361710"
  },
  {
    "text": "is a little bit\ndifferent here, given that online meta-learning\nsetting, where",
    "start": "4361710",
    "end": "4367052"
  },
  {
    "text": "they get to train on\nall the data so far, but they will also use the\ndata from the learning period to fine tune on\nthat so that they",
    "start": "4367052",
    "end": "4373560"
  },
  {
    "text": "can take the full\nadvantage of the setting. So this is the version of follow\nthe leader that kind of takes advantage of that online\nmeta-learning setting.",
    "start": "4373560",
    "end": "4381840"
  },
  {
    "text": "And then they'll also\ntry training from scratch on each one of the tasks, right?",
    "start": "4381840",
    "end": "4387720"
  },
  {
    "text": "And I'll just quickly\nshow you the results. And here we can see, in terms\nof the training efficiency.",
    "start": "4387720",
    "end": "4394830"
  },
  {
    "text": "So how many data points\ndoes the algorithm require to get to a\ncertain performance?",
    "start": "4394830",
    "end": "4401110"
  },
  {
    "text": "And here at the bottom of the\nx-axis, we see the task index. We can see that FTML algorithm\ncan be much more efficient",
    "start": "4401110",
    "end": "4409761"
  },
  {
    "text": "than all the other baselines. And it gets more\nefficient as it gets to see more and more tasks. So it's getting better\nand better at learning.",
    "start": "4409762",
    "end": "4417179"
  },
  {
    "text": "And then here on\nthe right, we see the learning proficiency,\nwhich is basically measured after a learning period\nof 100 plus, take or leave.",
    "start": "4417180",
    "end": "4426150"
  },
  {
    "text": "Or 100 data points, excuse me. Where you see that\nthe performance",
    "start": "4426150",
    "end": "4431280"
  },
  {
    "text": "of the algorithm itself, or\nthe error of the algorithm itself is also the best.",
    "start": "4431280",
    "end": "4438090"
  },
  {
    "text": "So it's going to achieve a\nsmaller and smaller error, as it gets to see more tasks.",
    "start": "4438090",
    "end": "4445179"
  },
  {
    "text": "So in this case,\nfollow the meta-leader learns each new task faster,\nbut also at greater proficiency.",
    "start": "4445180",
    "end": "4451170"
  },
  {
    "text": "And eventually it can approach\nthe future learning regime, where you just need\na few examples to be able to learn a given task.",
    "start": "4451170",
    "end": "4457360"
  },
  {
    "start": "4457360",
    "end": "4462943"
  },
  {
    "text": "All right, so we are\nslightly over time, but I'll ask you for\nquestions right after this.",
    "start": "4462943",
    "end": "4468300"
  },
  {
    "text": "So just a few\ntakeaways that I wanted you to take away from this.",
    "start": "4468300",
    "end": "4473648"
  },
  {
    "text": "So first of all, there are many\nflavors of lifelong learning, and they all exist\nunder the same name. So we went through the exercise\nwhere you kind of realized",
    "start": "4473648",
    "end": "4481020"
  },
  {
    "text": "yourself how many different\nversions of lifelong learning you can come up with. And very often when\nyou read these papers",
    "start": "4481020",
    "end": "4488340"
  },
  {
    "text": "they refer to it as\nthe same concept. They are all doing\nlifelong learning, but the specific problem\nsetting is slightly different.",
    "start": "4488340",
    "end": "4494260"
  },
  {
    "text": "So pay attention to that. And very often, defining\nthe problem statement itself",
    "start": "4494260",
    "end": "4500610"
  },
  {
    "text": "is the hardest part of a\nlifelong learning algorithm. Once you have a very crisp\nproblem-statement definition,",
    "start": "4500610",
    "end": "4506370"
  },
  {
    "text": "you can relatively\neasily come up with an algorithm\nthat can address it.",
    "start": "4506370",
    "end": "4513980"
  },
  {
    "text": "And meta-learning can\nbe viewed as a slice of the lifelong learning\nproblem, where you are just doing adaptation\nto the next task.",
    "start": "4513980",
    "end": "4522520"
  },
  {
    "text": "And as we mentioned\nat the beginning, this is a very open\narea of research. This is, I think, one\nof the most open-ended",
    "start": "4522520",
    "end": "4532150"
  },
  {
    "text": "lectures that we've had here,\nwhere there's a lot of research in the area, and even\nthe problem statement",
    "start": "4532150",
    "end": "4538170"
  },
  {
    "text": "is still being researched. And it's not very\nstrictly defined. ",
    "start": "4538170",
    "end": "4545520"
  },
  {
    "text": "All right then, this is it. So thank you very much. Are there any questions\nat this point? ",
    "start": "4545520",
    "end": "4564403"
  },
  {
    "text": "There's a question from--  I want to ask more about\nthe example that you have.",
    "start": "4564403",
    "end": "4573400"
  },
  {
    "text": "I think it was six\n[INAUDIBLE],, and then you are trying to pick\nup a brass object.",
    "start": "4573400",
    "end": "4579550"
  },
  {
    "text": "In that, I was wondering when\nyou can't [INAUDIBLE] you",
    "start": "4579550",
    "end": "4585610"
  },
  {
    "text": "fine tune around 800 grasps. And I was wondering\nif you had tried",
    "start": "4585610",
    "end": "4591880"
  },
  {
    "text": "everything in that scenario. And when you found some\nevidence of benefiting",
    "start": "4591880",
    "end": "4598300"
  },
  {
    "text": "from fine tuning, how\nthat would have compared against everything, or going\nfrom scratch on that target.",
    "start": "4598300",
    "end": "4609535"
  },
  {
    "text": "Yeah, thank you\nfor the question, it is a really good question. So I think maybe a few points.",
    "start": "4609535",
    "end": "4615740"
  },
  {
    "text": "So first of all, because\nwe had so many grasps from the pretraining\ndata set, I think",
    "start": "4615740",
    "end": "4622580"
  },
  {
    "text": "one worry is that these\n800 grasps will just disappear in the sea of data\nfrom all the other tasks.",
    "start": "4622580",
    "end": "4629010"
  },
  {
    "text": "So it might not pay as much\nattention to that new setting. And I think because of this,\nit will probably get worse than",
    "start": "4629010",
    "end": "4635929"
  },
  {
    "text": "in the fine-tuning case. And then secondly, just from\nthe computational resources",
    "start": "4635930",
    "end": "4642980"
  },
  {
    "text": "perspective, training\non the entire data set every time will take\naround three to four days",
    "start": "4642980",
    "end": "4650570"
  },
  {
    "text": "on multiple machines. So it's just like an\nunfeasible problem.",
    "start": "4650570",
    "end": "4657200"
  },
  {
    "text": "Or unfeasible,\nreally, proposition where every time you\nsee some kind of change",
    "start": "4657200",
    "end": "4662570"
  },
  {
    "text": "in the environment you need to\nretrain and wait for three days to have the policy that can\nperform in that new setting.",
    "start": "4662570",
    "end": "4672590"
  },
  {
    "text": "Probably by the time you\nget trained on an algorithm, you'll be in a\ndifferent setting.",
    "start": "4672590",
    "end": "4678440"
  },
  {
    "text": "And I was just really\nconfused on the arrows, so I was wondering\nwhy you didn't share learning between the\ndifferent fine tuning tasks, so",
    "start": "4678440",
    "end": "4686883"
  },
  {
    "text": "like the transparency\ncheckerboard, the different kinds of repos. I was wondering why\nthere wasn't any shared",
    "start": "4686883",
    "end": "4693065"
  },
  {
    "text": "learning between those bots. Let's see.",
    "start": "4693065",
    "end": "4699130"
  },
  {
    "text": "So by shared\nlearning, do you mean why didn't we construct\nthe datasets that had all of the\ndifferent modifications",
    "start": "4699130",
    "end": "4705940"
  },
  {
    "text": "and try pointing to that? No, as in why the\nnetwork parameters",
    "start": "4705940",
    "end": "4711400"
  },
  {
    "text": "weren't shared between\nthe different sub-tasks, but they were just shared\nbetween the main task",
    "start": "4711400",
    "end": "4716920"
  },
  {
    "text": "and the six different sub-tasks. Right, OK. Yeah. So let me clarify this.",
    "start": "4716920",
    "end": "4723510"
  },
  {
    "text": "So the way we were\ndoing fine tuning is that we would start from\nthat original pretrained policy,",
    "start": "4723510",
    "end": "4732830"
  },
  {
    "text": "and then we'll warm start our\nnew policy from that so it'll have the exact same parameters.",
    "start": "4732830",
    "end": "4738140"
  },
  {
    "text": "And then we'll fine\ntune to the next task. At this point we will have the\nparameters of that new policy",
    "start": "4738140",
    "end": "4743210"
  },
  {
    "text": "that perform quite\nwell on that next task, and then we'll fine\ntune that one again. So we'll warm start the next\none thus and kind of keep going.",
    "start": "4743210",
    "end": "4750980"
  },
  {
    "text": "But does that direction matter? Which you do first,\nwhich you do second. Do you do more general\ntasks ahead upstream,",
    "start": "4750980",
    "end": "4757640"
  },
  {
    "text": "more specific tasks downstream,\nor the other way around? Yeah, that's a\nreally good question.",
    "start": "4757640",
    "end": "4762940"
  },
  {
    "text": "We didn't really evaluate it. At least in terms of the\norder of the fine tuning task.",
    "start": "4762940",
    "end": "4768559"
  },
  {
    "text": "If I were to guess, I'd\nthink that it's important to pretrain on aspect\nof a family of tasks,",
    "start": "4768560",
    "end": "4775250"
  },
  {
    "text": "or aspect of a\ndataset as possible, so that fine tuning is easier. So I don't think you should\nchange and start training",
    "start": "4775250",
    "end": "4782240"
  },
  {
    "text": "on 800 grasps, and then\npoint here to 800,000 grasps. But I think, in terms of the\norder of the fine tuning tasks,",
    "start": "4782240",
    "end": "4790640"
  },
  {
    "text": "we didn't really evaluate this. But I think it would\nbe really interesting. And I don't really have\na good intuition of what",
    "start": "4790640",
    "end": "4797440"
  },
  {
    "text": "the good ordering would be. [INAUDIBLE] I don't\nunderstand what",
    "start": "4797440",
    "end": "4804030"
  },
  {
    "text": "it means for it to be linear. For linear regret. I was wondering if you\ncould explain again",
    "start": "4804030",
    "end": "4809660"
  },
  {
    "text": "why the loss on each\ntask could be constant. ",
    "start": "4809660",
    "end": "4818800"
  },
  {
    "text": "I see. So if we-- assuming\nthat each task is",
    "start": "4818800",
    "end": "4828160"
  },
  {
    "text": "of similar difficulty,\nthen, and assuming that we train each\ntask from scratch,",
    "start": "4828160",
    "end": "4836250"
  },
  {
    "text": "or each data point\nfrom scratch, the loss that we would get\nafter training,",
    "start": "4836250",
    "end": "4841680"
  },
  {
    "text": "assuming the same\ndifficulty, should probably be very similar across\ndifferent tasks.",
    "start": "4841680",
    "end": "4846760"
  },
  {
    "text": "So I give you a data point,\nor a bunch of data points, and I ask you to train on it.",
    "start": "4846760",
    "end": "4851910"
  },
  {
    "text": "And these are very\nsimilar to each other. So after you trained on\nit, probably the loss",
    "start": "4851910",
    "end": "4857670"
  },
  {
    "text": "between all of them\nwill be very close. Does that make sense? It does, yeah.",
    "start": "4857670",
    "end": "4863590"
  },
  {
    "text": "Right. So then if you're\ncumulatively adding that loss every single time step, that\nwill be a linear function",
    "start": "4863590",
    "end": "4870179"
  },
  {
    "text": "of a number of things. I see. And maybe if you have\nanother 30 seconds.",
    "start": "4870180",
    "end": "4876940"
  },
  {
    "text": "What does it mean for\nit to be locally linear? And when the [INAUDIBLE]\npaper solved it,",
    "start": "4876940",
    "end": "4881949"
  },
  {
    "text": "I think they said [INAUDIBLE]. And is that an assumption\nthat's justified, generally?",
    "start": "4881950",
    "end": "4890480"
  },
  {
    "text": "Yeah, so I think ove\nall, the reasoning about the optimization\nlandscape of neural networks",
    "start": "4890480",
    "end": "4898820"
  },
  {
    "text": "that have millions of parameters\nis really, really difficult. These are highly\nnonlinear landscapes,",
    "start": "4898820",
    "end": "4903830"
  },
  {
    "text": "where it's very difficult\nto say something about them. And there's a few papers that\ntry to characterize this, but it's overall\nreally, really tricky.",
    "start": "4903830",
    "end": "4911329"
  },
  {
    "text": " The local linear\nassumptions assumes",
    "start": "4911330",
    "end": "4917840"
  },
  {
    "text": "that, at least for the\nnext gradient step, the landscape is linear. And that's an assumption that\npeople commonly make in order",
    "start": "4917840",
    "end": "4926239"
  },
  {
    "text": "to make any sort of analysis. How a gradient would influence\nother tasks, for example. And this was done\nin a few papers.",
    "start": "4926240",
    "end": "4933500"
  },
  {
    "text": "I've heard that multitask\nlearning or continual learning. But that's a fairly common\nassumption, I would say.",
    "start": "4933500",
    "end": "4939583"
  },
  {
    "text": "It's kind of\nnecessary if you want to reason about the landscape. ",
    "start": "4939583",
    "end": "4949600"
  },
  {
    "text": "There's also a question that\nI was answering in the chat, but you could also\ngive your opinion.",
    "start": "4949600",
    "end": "4956450"
  },
  {
    "text": "Are there works that study,\nbasically, the task order",
    "start": "4956450",
    "end": "4962350"
  },
  {
    "text": "and the difficulty of the tasks\nversus the i.i.d. distribution? Sorry, ordering the tasks\nbased on the difficulty",
    "start": "4962350",
    "end": "4969550"
  },
  {
    "text": "versus an i.i.d. distribution. ",
    "start": "4969550",
    "end": "4977242"
  },
  {
    "text": "Yeah, there's no\nparticular papers that come to mind right now. If I were to guess, I'm not\nfamiliar with any theory",
    "start": "4977243",
    "end": "4985620"
  },
  {
    "text": "on this, or any even-- well, I guess we can come up\nwith some kind of intuition of this for reinforcement\nlearning problems,",
    "start": "4985620",
    "end": "4992760"
  },
  {
    "text": "where you would probably\nwant to start with tasks that are going to help explore\nfor the next tasks",
    "start": "4992760",
    "end": "4999060"
  },
  {
    "text": "or that are a little bit\nbroader than the next task that you want to adjust to.",
    "start": "4999060",
    "end": "5005060"
  },
  {
    "text": "But I think this is more of\nan intuition than something that has been truly shown.",
    "start": "5005060",
    "end": "5012679"
  },
  {
    "text": "And in case of the\nsupervised learning problem, I'm not sure if\nthere is any research",
    "start": "5012680",
    "end": "5019790"
  },
  {
    "text": "on the ordering of tasks there. In the supervised\nlearning setting",
    "start": "5019790",
    "end": "5025440"
  },
  {
    "text": "I added a link to one paper\nthat might be relevant. It shows if you\npretrain on one thing,",
    "start": "5025440",
    "end": "5032250"
  },
  {
    "text": "and then train on another\nthing, that pretraining task can actually deteriorate\nperformance for later tasks",
    "start": "5032250",
    "end": "5037650"
  },
  {
    "text": "in some settings.  Yeah, I think it would\nprobably depend quite a bit",
    "start": "5037650",
    "end": "5043810"
  },
  {
    "text": "on the application, and\nwhat the specific tasks are. So it's difficult to say\nsomething general about this,",
    "start": "5043810",
    "end": "5049270"
  },
  {
    "text": "but it's a really\ninteresting question. OK, I think we can end there.",
    "start": "5049270",
    "end": "5056070"
  },
  {
    "start": "5056070",
    "end": "5061000"
  }
]
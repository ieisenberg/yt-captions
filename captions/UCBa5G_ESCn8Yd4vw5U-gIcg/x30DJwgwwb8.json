[
  {
    "text": "All right. Hi, everyone. As Mark Cutkosky introduced me\nbefore, I'm Daniele Gammelli. I'm a postdoc in\nMarco Govoni's lab",
    "start": "9920",
    "end": "16670"
  },
  {
    "text": "in the Department of AeroAstro. And today, we'll start to\ndo a quick presentation--",
    "start": "16670",
    "end": "22680"
  },
  {
    "text": "a short presentation\non the way in our lab we are starting to think about,\nhow can we leverage foundation models for space autonomy?",
    "start": "22680",
    "end": "29630"
  },
  {
    "text": "And the premise\nin all of this is that it is broadly\nrecognized that we're really",
    "start": "29630",
    "end": "35600"
  },
  {
    "text": "living in a golden age\nfor AI and autonomy. And this is\nmotivated by the fact that over the last\ntwo to three years,",
    "start": "35600",
    "end": "42809"
  },
  {
    "text": "we have been witnessing a lot\nof important breakthroughs in a number of\ndifferent disciplines that are really changing the way\nwe develop the autonomy stack.",
    "start": "42810",
    "end": "50460"
  },
  {
    "text": "So ranging from effective\nmethods for 3D reconstruction to highly parallelizable\nsimulation to, obviously,",
    "start": "50460",
    "end": "57780"
  },
  {
    "text": "the role of foundation models\nsuch as video generation, large language models, visual\nlanguage models, and so forth.",
    "start": "57780",
    "end": "65830"
  },
  {
    "text": "And so with this talk,\nwhat we will do is we'll start to take a look\nabout how we are thinking",
    "start": "65830",
    "end": "73210"
  },
  {
    "text": "and discuss the opportunities\nfor the role of foundation models in the realm of\nspace robotics specifically.",
    "start": "73210",
    "end": "80960"
  },
  {
    "text": "And so we will do this\nby dividing this talk in two main blocks. The first one will\nbe focusing on,",
    "start": "80960",
    "end": "88570"
  },
  {
    "text": "how can we leverage\ntechniques that have been developed in the\nfield of foundation models and apply them to\na space autonomy?",
    "start": "88570",
    "end": "95240"
  },
  {
    "text": "The second block,\nwe'll instead focus on, how can we use pre-trained\nfoundation models",
    "start": "95240",
    "end": "100270"
  },
  {
    "text": "that are out there in a way that\nis useful across the autonomy stack?",
    "start": "100270",
    "end": "105579"
  },
  {
    "text": "But before we get into\nany of these two blocks, let's briefly introduce\nand set the stage",
    "start": "105580",
    "end": "111040"
  },
  {
    "text": "for, what do we even\nmean by foundation model? Although I'm sure\nthat many of you here are quite familiar with it.",
    "start": "111040",
    "end": "116360"
  },
  {
    "text": "So in general, when we\nrefer to a foundation model, we typically mean\na model that has",
    "start": "116360",
    "end": "122060"
  },
  {
    "text": "been trained on broad data,\ntypically internet scale level, in a self-supervised\nmanner, and that",
    "start": "122060",
    "end": "128660"
  },
  {
    "text": "can be adapted to a wide\nrange of downstream tasks. And so examples of\nthis family of methods,",
    "start": "128660",
    "end": "135150"
  },
  {
    "text": "as I mentioned before, are\nvideo generation models, large language models, visual\nlanguage models, and so forth.",
    "start": "135150",
    "end": "140520"
  },
  {
    "text": "So it's a real family of\nmethods that typically share this underlying assumption.",
    "start": "140520",
    "end": "145620"
  },
  {
    "text": "And to this, I would add that\ntypically foundation models really rely on leveraging\nexpressive and scalable",
    "start": "145620",
    "end": "152120"
  },
  {
    "text": "neural network architectures\nsuch as transformers or diffusion models. And so with that\nsaid, let's get into,",
    "start": "152120",
    "end": "159110"
  },
  {
    "text": "how can we take techniques\nthat have been developed in the literature\nof foundation models",
    "start": "159110",
    "end": "164719"
  },
  {
    "text": "and use them for space robotics? And specifically here\nwe will be focusing on spacecraft trajectory\noptimization as a running case",
    "start": "164720",
    "end": "173270"
  },
  {
    "text": "study for this block. And so giving some context\ninto spacecraft trajectory",
    "start": "173270",
    "end": "179610"
  },
  {
    "text": "optimization in\ngeneral, the motivation here is that upcoming\nin-orbit servicing, assembly,",
    "start": "179610",
    "end": "186190"
  },
  {
    "text": "manufacturing, and\nlogistics operations will require autonomous\nrendezvous capabilities.",
    "start": "186190",
    "end": "192239"
  },
  {
    "text": "And trajectory\noptimization is really a key fundamental capability in\norder to achieve these goals,",
    "start": "192240",
    "end": "198910"
  },
  {
    "text": "because at the high level,\ntrajectory optimization formalizes this idea of\ncomputing a sequence of states",
    "start": "198910",
    "end": "204300"
  },
  {
    "text": "and controls that,\nbroadly speaking, optimize some mission\nobjectives while satisfying",
    "start": "204300",
    "end": "209670"
  },
  {
    "text": "constraints that are\ndesigned by the user. However, if you\nlook at the field",
    "start": "209670",
    "end": "215340"
  },
  {
    "text": "of space robotics and spacecraft\nautonomy specifically,",
    "start": "215340",
    "end": "220860"
  },
  {
    "text": "trajectory optimization\nneeds to balance two conflicting desiderata. So on the one hand,\nwe have the limitation",
    "start": "220860",
    "end": "227040"
  },
  {
    "text": "of space-graded compute,\nwhich are orders of magnitude less powerful than\nearth-graded compute.",
    "start": "227040",
    "end": "233770"
  },
  {
    "text": "And on the other hand, we have\nthis really strict requirements, both in terms of\nperformance that we",
    "start": "233770",
    "end": "239120"
  },
  {
    "text": "want to achieve, but\nespecially in terms of safety, because space is in itself a\nvery risky realm to be dealing",
    "start": "239120",
    "end": "246050"
  },
  {
    "text": "with. And when we look at\ndifferent methods that try to approach trajectory\noptimization in space,",
    "start": "246050",
    "end": "253260"
  },
  {
    "text": "these typically fall within one\nof three main categories, which are, the first one is\nthe closed form methods,",
    "start": "253260",
    "end": "261480"
  },
  {
    "text": "which if on the one hand,\nare very fast and reliable, on the other, they are typically\nnot general purpose because they",
    "start": "261480",
    "end": "268430"
  },
  {
    "text": "entail a deep understanding\nof the problem you're trying to solve and putting\nthem down analytically.",
    "start": "268430",
    "end": "273979"
  },
  {
    "text": "The second class is one of\nnumerical optimization, which on the other hand, is much\nmore general purpose because it",
    "start": "273980",
    "end": "279440"
  },
  {
    "text": "entails restructuring\nyour problem into a mathematical formulation\nand then feeding this into,",
    "start": "279440",
    "end": "285150"
  },
  {
    "text": "let's call it some\nblack box solver. But on the other\nhand, these methods are typically much more\ncomputationally expensive",
    "start": "285150",
    "end": "291889"
  },
  {
    "text": "and, therefore, goes in contrast\nwith one of the two desiderata that we were discussing before.",
    "start": "291890",
    "end": "297030"
  },
  {
    "text": "The third class, which\nis much less explored in the case of space autonomy is\none of learning-based methods,",
    "start": "297030",
    "end": "303820"
  },
  {
    "text": "which on the upside, can\nbe extremely expressive and computationally\nefficient compared,",
    "start": "303820",
    "end": "309220"
  },
  {
    "text": "for example, to numerical\noptimization methods. But on the other hand,\nit's very challenging to enforce strict\nsafety guarantees",
    "start": "309220",
    "end": "316725"
  },
  {
    "text": "when we work with\nlearning-based methods. And so in this landscape,\na paradigm that",
    "start": "316725",
    "end": "324180"
  },
  {
    "text": "emerges as an extremely\nappealing one, at least in our view, was one\nof warm starting.",
    "start": "324180",
    "end": "329860"
  },
  {
    "text": "That is, can we leverage\nlearning-based methods to generate fast, potentially\nalso very good initial candidate",
    "start": "329860",
    "end": "336900"
  },
  {
    "text": "solutions and then refine\nthese candidate solution with numerical optimization,\nwhich in turn can guarantee us",
    "start": "336900",
    "end": "343289"
  },
  {
    "text": "the safety requirements\nthat are needed. And so if we look at this\nkind of pictorial image",
    "start": "343290",
    "end": "348840"
  },
  {
    "text": "here on this slide,\nif you imagine finding an optimal\ntrajectory as looking in a high dimensional parameter\nspace or solution space,",
    "start": "348840",
    "end": "357340"
  },
  {
    "text": "learning-based or\nstarting is this idea of using learning-based\nmethods to generate fast",
    "start": "357340",
    "end": "363430"
  },
  {
    "text": "an initial point in this\nlandscape of solutions, which is then fed to a traditional\nnumerical optimizer which",
    "start": "363430",
    "end": "369220"
  },
  {
    "text": "fine tunes it, maybe converging\ninto a local neighborhood while satisfying the\nconstraints that are needed.",
    "start": "369220",
    "end": "375890"
  },
  {
    "text": "And so what we want\nto do with this work is leverage high capacity\nneural networks, namely",
    "start": "375890",
    "end": "381520"
  },
  {
    "text": "transformer-based in\nthis case, to provide these high-quality\nsolutions efficiently.",
    "start": "381520",
    "end": "386560"
  },
  {
    "text": "And on the other hand,\nleverage numerical optimization to\nfine-tune the solution while providing the safety\nguarantees that we care about.",
    "start": "386560",
    "end": "395560"
  },
  {
    "text": "And so when we talk about\ntransformers for control, I think it's just worth setting\nthe stage on how transformers,",
    "start": "395560",
    "end": "404139"
  },
  {
    "text": "broadly speaking,\nwork, and how can we use them for our purposes? So as many of you\nknow, transformers",
    "start": "404140",
    "end": "410310"
  },
  {
    "text": "are essentially the backbone\nof almost the entirety of large language models today. And at their core,\ntransformers are essentially",
    "start": "410310",
    "end": "417960"
  },
  {
    "text": "sequence prediction models. So they take a\ncontext, for example, a set of words or\ntokens, and they",
    "start": "417960",
    "end": "424020"
  },
  {
    "text": "are trained to predict the\nnext element in the sequence. And the reason why these\nare called generative",
    "start": "424020",
    "end": "429840"
  },
  {
    "text": "is that because they\ncan generate new texts by essentially doing\nautoregressive prediction. So given some context,\nthe transformer",
    "start": "429840",
    "end": "436650"
  },
  {
    "text": "gives us the next\nelement in the sequence. I feed this element in the\nsequence back in my context, and I repeat this over and over\nuntil I get a full paragraph,",
    "start": "436650",
    "end": "445360"
  },
  {
    "text": "for example. And in order to switch from\ntransformers for language",
    "start": "445360",
    "end": "450930"
  },
  {
    "text": "and natural language\nprocessing to control, if you want simple\nintuition is that",
    "start": "450930",
    "end": "457440"
  },
  {
    "text": "rather than working\nwith tokens and words, we work with states and\ncontrols that are still",
    "start": "457440",
    "end": "462450"
  },
  {
    "text": "seen as a sequence for\nwhat the transformer is concerned at least.",
    "start": "462450",
    "end": "468460"
  },
  {
    "text": "And so what we do\nhere is we propose a method which we call\nthe Autonomous Rendezvous",
    "start": "468460",
    "end": "473919"
  },
  {
    "text": "Transformer or ART for short,\nwhich essentially tries to combine\noptimization-based methods",
    "start": "473920",
    "end": "479389"
  },
  {
    "text": "and learning-based methods\nfor trajectory optimization. And the way it does this\nis by at training time,",
    "start": "479390",
    "end": "485060"
  },
  {
    "text": "similarly to how large\nlanguage models are trained on next [INAUDIBLE] prediction\non large corpora of text,",
    "start": "485060",
    "end": "492020"
  },
  {
    "text": "ART is trained on a large\ndatabase of presold trajectories and modeled also as sequences\nof states and controls,",
    "start": "492020",
    "end": "500420"
  },
  {
    "text": "and we try to predict the\nnext element in the sequence. And once trained\nat inference, we",
    "start": "500420",
    "end": "506740"
  },
  {
    "text": "can use ART to generate\nnear optimal or ideally good enough solutions for\npotentially unseen scenarios.",
    "start": "506740",
    "end": "515058"
  },
  {
    "text": "So here on this slide,\nwe have something where given a novel or unseen\ninitial condition and some task",
    "start": "515059",
    "end": "521620"
  },
  {
    "text": "specifications, ART can\ngenerate a full trajectory for this task,\nwhich we then feed",
    "start": "521620",
    "end": "528540"
  },
  {
    "text": "to traditional numerical\noptimizer for refinement. And warm-starting\nthrough these methods",
    "start": "528540",
    "end": "535709"
  },
  {
    "text": "typically results in\nfaster convergence, because the numerical\noptimization starts ideally in an already good local\nneighborhood of the solution,",
    "start": "535710",
    "end": "543580"
  },
  {
    "text": "while at the same time,\nenhancing the safety guarantees from learning\nmethods with grounded numerical",
    "start": "543580",
    "end": "550890"
  },
  {
    "text": "optimization. And the way we test\nthis, is for example,",
    "start": "550890",
    "end": "557650"
  },
  {
    "text": "in hardware, we use a free\nflight platform that is just around the block in the run\nbuilding, which essentially",
    "start": "557650",
    "end": "563970"
  },
  {
    "text": "simulates space flight\nthrough free floating robot, the free flyer, on a\n3 by 5 granite table, which",
    "start": "563970",
    "end": "571890"
  },
  {
    "text": "essentially simulates this\nhovering robot in absence of friction, which is\nsimilar to spaceflight.",
    "start": "571890",
    "end": "577930"
  },
  {
    "text": "And the way we control\na free flying robot is by controlling the thrusters,\nor specifically H thrusters,",
    "start": "577930",
    "end": "585155"
  },
  {
    "text": "as you can see here\non the slide, which are equally positioned\naround the circumference of the free flyer.",
    "start": "585155",
    "end": "590899"
  },
  {
    "text": "And so the goal in this\ncase is to, for example, start from a given initial\ncondition and reach a target",
    "start": "590900",
    "end": "597070"
  },
  {
    "text": "position while avoiding the\nobstacles present in the scene. And so what we observed, and as\nyou can see here on this slide,",
    "start": "597070",
    "end": "604839"
  },
  {
    "text": "is that we have the transformer\ngenerates pretty fast candidate solution in blue, which\nis then quickly refined",
    "start": "604840",
    "end": "611050"
  },
  {
    "text": "to a safe solution from\nthe optimizer in green. And numerically, we see that\nthis leads to, first of all,",
    "start": "611050",
    "end": "619360"
  },
  {
    "text": "shorter compute times, but\nalso better solution, seen here",
    "start": "619360",
    "end": "624760"
  },
  {
    "text": "by the smaller firing\ntime from this platform.",
    "start": "624760",
    "end": "630670"
  },
  {
    "text": "And a little bit more\nquantitatively, we also run this in simulation on yes,\nstill the free flyer platform,",
    "start": "630670",
    "end": "637550"
  },
  {
    "text": "but also on a\nsimulated rendezvous and proximity operation\nscenario, which are depicted here on the right.",
    "start": "637550",
    "end": "643920"
  },
  {
    "text": "So the top one is the\nsame freeflyer scenario. The bottom one,\non the other hand, is this rendezvous\nand docking scenario",
    "start": "643920",
    "end": "650630"
  },
  {
    "text": "where the service or spacecraft\nneeds to dock, for example, with the International\nSpace Station.",
    "start": "650630",
    "end": "656130"
  },
  {
    "text": "And what we look at\nhere quantitatively is the improvement or potential\nbenefits in terms of cost.",
    "start": "656130",
    "end": "661980"
  },
  {
    "text": "So, how much better or worse is\nthe solution when we converge? And also, how much\nare we spending",
    "start": "661980",
    "end": "668420"
  },
  {
    "text": "in terms of inference\ntime when we compare it to traditional methods?",
    "start": "668420",
    "end": "672400"
  },
  {
    "text": "And so now taking a step\nback, what we've done here, we're essentially seeing how\nmethods from the literature",
    "start": "676040",
    "end": "684680"
  },
  {
    "text": "and foundation model\nhere, specifically transformers trained\non large databases,",
    "start": "684680",
    "end": "690240"
  },
  {
    "text": "can be used for trajectory\noptimization in space, so in space robotics,\nalthough with some extra care,",
    "start": "690240",
    "end": "697820"
  },
  {
    "text": "because in space, we care\nabout safety guarantees. And so we have to solve these\nproblems like hallucinations",
    "start": "697820",
    "end": "703839"
  },
  {
    "text": "in natural language in order to\nbe able to trust these things.",
    "start": "703840",
    "end": "709840"
  },
  {
    "text": "So that being said, let's\nmove into the second block of this presentation, where\nrather than taking techniques",
    "start": "709840",
    "end": "717160"
  },
  {
    "text": "from the foundation\nmodel literature and applying them to space\nrobotics, we try to assess and we take the first steps\ntowards seeing whether, what are",
    "start": "717160",
    "end": "724870"
  },
  {
    "text": "the opportunities for\npre-trained foundation models like vision\nlanguage models and applying them\nthroughout the autonomy",
    "start": "724870",
    "end": "731890"
  },
  {
    "text": "stack in space robotics? And the premise here is that\nfoundation models, for example,",
    "start": "731890",
    "end": "739430"
  },
  {
    "text": "vision language models, possess\nattributes of intelligence. And this empirically\ndemonstrating",
    "start": "739430",
    "end": "745630"
  },
  {
    "text": "strong common sense reasoning\nand semantic understanding. So here it's like a\nfamous example where",
    "start": "745630",
    "end": "752410"
  },
  {
    "text": "given this image on the\nleft, the model is asked, what is unusual\nabout this image?",
    "start": "752410",
    "end": "757700"
  },
  {
    "text": "And here, the visual\nlanguage model correctly recognizes that\nthe weird thing is",
    "start": "757700",
    "end": "763100"
  },
  {
    "text": "that there is a\nman ironing clothes in the middle of the street\nand attached to a car. So this is what we mean\nby common sense reasoning.",
    "start": "763100",
    "end": "770250"
  },
  {
    "text": "And so the question here is,\nhow can we better leverage these semantic understanding\nand common sense",
    "start": "770250",
    "end": "776090"
  },
  {
    "text": "reasoning for the purpose\nof space autonomy? And we have been putting\nquite some thought into this.",
    "start": "776090",
    "end": "784410"
  },
  {
    "text": "And we think that these\nmodels have the potential to mitigate three core\nchallenges or at least",
    "start": "784410",
    "end": "790880"
  },
  {
    "text": "three core challenges for space\nrobotics, which are scaling, Ground In The Loop\nor GITL operations,",
    "start": "790880",
    "end": "797550"
  },
  {
    "text": "generalizing prior knowledge,\nand being able to handle multiple sensor modalities.",
    "start": "797550",
    "end": "803940"
  },
  {
    "text": "So when we look at the\nfirst challenge, that is scaling ground in\nthe loop operations, the current paradigm\nof space missions",
    "start": "803940",
    "end": "810920"
  },
  {
    "text": "is that you have--\ntypically, there is a tight feedback\nloop with a ground teams of engineers that\nbasically closely monitor",
    "start": "810920",
    "end": "820240"
  },
  {
    "text": "what is happening. And this is extremely costly\nand not really scalable. So for example, consider the\nPerseverance Rover on Mars.",
    "start": "820240",
    "end": "828640"
  },
  {
    "text": "The operations of the Rover\ncosted around $300 million. And you can probably\nimagine how this is not",
    "start": "828640",
    "end": "834340"
  },
  {
    "text": "scalable in the\nmoment where we want to scale up the number\nof space missions we do,",
    "start": "834340",
    "end": "840279"
  },
  {
    "text": "for example,\nmulti-robot missions. And generally speaking, trying\nto be more active in the space domain.",
    "start": "840280",
    "end": "847150"
  },
  {
    "text": "When talking about\ngeneralizing prior knowledge, space is inherently a\nzero shot environment.",
    "start": "847150",
    "end": "854260"
  },
  {
    "text": "So it's understudied. It's typically characterized\nby unexplored domains.",
    "start": "854260",
    "end": "859340"
  },
  {
    "text": "And so what we\nwould like to have is some of technique in\nwhich we could potentially leverage the learnings\nand the takeaways we have",
    "start": "859340",
    "end": "866950"
  },
  {
    "text": "from previous missions and\nbring this knowledge to somehow and generalize it\nto future missions.",
    "start": "866950",
    "end": "875116"
  },
  {
    "text": "A provocative example\ncould be learning-- leveraging some lessons learned\nfrom flying ingenuity on Mars",
    "start": "875116",
    "end": "882350"
  },
  {
    "text": "to the mission on flying\ndragonfly on Titan. And lastly, when looking at\nmultiple sensor modalities,",
    "start": "882350",
    "end": "890630"
  },
  {
    "text": "space robots are equipped with\na plethora of different sensors. It would be nice to\nhave a single model that",
    "start": "890630",
    "end": "897260"
  },
  {
    "text": "can potentially embed and model\nall of these modalities at once, and potentially avoiding to\nhave specialized models for each",
    "start": "897260",
    "end": "905330"
  },
  {
    "text": "of these modalities, rather\nbeing able to use the same model and apply it to various\ndifferent scenarios.",
    "start": "905330",
    "end": "912830"
  },
  {
    "text": "And so when looking at\nadapting pre-trained foundation models for these\npurposes, we break it down",
    "start": "912830",
    "end": "919160"
  },
  {
    "text": "into two main steps. So the first one is\nwell, these models, if we want to adapt them to be\ncapable in the space domain,",
    "start": "919160",
    "end": "926760"
  },
  {
    "text": "we will have to generate\nlarge multi-modal data sets that are useful for\ninjecting the knowledge",
    "start": "926760",
    "end": "932240"
  },
  {
    "text": "that we need. And we do this by\nsynthetically augmenting extraterrestrial data set.",
    "start": "932240",
    "end": "937390"
  },
  {
    "text": "But I will come to this\nin the next slides. The second thing\nthat we do is now assuming we have some\nway of generating",
    "start": "937390",
    "end": "943470"
  },
  {
    "text": "this multi-modal\nlarge data set, we need to fine-tune some\nsort of open source model for these tasks.",
    "start": "943470",
    "end": "949007"
  },
  {
    "text": "And the first steps that\nwe take in this direction is fine-tuning open source\nvisual language models,",
    "start": "949007",
    "end": "955110"
  },
  {
    "text": "which we call space larva, which\nis a model that essentially takes this data set,\nwhich we compose",
    "start": "955110",
    "end": "961470"
  },
  {
    "text": "of tasks like visual question\nanswering, instruction following, question answer\nthat is specifically targeted",
    "start": "961470",
    "end": "969630"
  },
  {
    "text": "for space knowledge,\nbut also keeps with it some of the\ndata set on which",
    "start": "969630",
    "end": "974880"
  },
  {
    "text": "it was originally trained for. In this case, larva instruct,\nwhich is useful for co-training. So avoiding a loss\nin performance",
    "start": "974880",
    "end": "982050"
  },
  {
    "text": "and keeping it broadly\ngeneral use cases. And the model that we are\nlooking at in this work",
    "start": "982050",
    "end": "990000"
  },
  {
    "text": "is indeed a visual\nlanguage model. So something that takes\nan input, some image data",
    "start": "990000",
    "end": "995060"
  },
  {
    "text": "and some text, it encodes them\ninto a shared latent space, and then it decodes.",
    "start": "995060",
    "end": "1000110"
  },
  {
    "text": "So the output of this model\nis also natural language. And this model is then--",
    "start": "1000110",
    "end": "1006160"
  },
  {
    "text": "once it's fine-tuned\non all of these tasks, is hopefully able to be useful\non a number of downstream tasks.",
    "start": "1006160",
    "end": "1012110"
  },
  {
    "text": "And for the purpose\nof this presentation, we focused mostly\non data curation. And we will see more\nin the next slide.",
    "start": "1012110",
    "end": "1018560"
  },
  {
    "text": "So again, we're breaking\nthis down in two steps. The first one is we need\nlarge informative data sets.",
    "start": "1018560",
    "end": "1024699"
  },
  {
    "text": "And the second one, Once\nwe have these data sets, we need to use them with\nsome of architecture which",
    "start": "1024700",
    "end": "1029770"
  },
  {
    "text": "we care about. And in this case, we focus\non visual language models.",
    "start": "1029770",
    "end": "1035290"
  },
  {
    "text": "So let's look at the first\none, which is generating a multimodal data set. And this really\ntries to address what",
    "start": "1035290",
    "end": "1043540"
  },
  {
    "text": "we think is a really important\nproblem in this field because, and the space domain in general,\nwhich is the scarcity of data",
    "start": "1043540",
    "end": "1049970"
  },
  {
    "text": "because this represents\na fundamental challenge in the pursuit of artificial\nintelligence within the space",
    "start": "1049970",
    "end": "1056450"
  },
  {
    "text": "robotics community. And so what we do here, the two\nthings that we focus on more",
    "start": "1056450",
    "end": "1063740"
  },
  {
    "text": "is, first of all, since we\nsay adapt vision language models in this case\nor foundation models,",
    "start": "1063740",
    "end": "1070920"
  },
  {
    "text": "we need some of annotation\nthat is in natural language. And this is typically\nsomething that is not there",
    "start": "1070920",
    "end": "1076400"
  },
  {
    "text": "in open source data sets. You have maybe a bunch of\nimages and a lot of images, also very high quality labels.",
    "start": "1076400",
    "end": "1082320"
  },
  {
    "text": "But you don't tend to\nhave language annotation for these data sets. And the second thing\nthat we focus on",
    "start": "1082320",
    "end": "1088190"
  },
  {
    "text": "is these models have been\ntrained on internet scale data. So they're broadly\nknowledgeable.",
    "start": "1088190",
    "end": "1093750"
  },
  {
    "text": "But this data is\nalso earth-bound. So what we actually want to\ndo is focus its knowledge and really improve\nits performance",
    "start": "1093750",
    "end": "1101070"
  },
  {
    "text": "when we talk about\nspace related domains. And so in the context of\ncreating language annotations,",
    "start": "1101070",
    "end": "1108770"
  },
  {
    "text": "indeed, we focus on open source\nextraterrestrial data sets such as AI for Mars.",
    "start": "1108770",
    "end": "1114810"
  },
  {
    "text": "It's a famous one, which\nis shown here on the slide. It's basically images from the\nMars surface, which provides",
    "start": "1114810",
    "end": "1121640"
  },
  {
    "text": "some segmentation masks. So it's also high\nquality labels. So it differentiates between\ndifferent types of terrains",
    "start": "1121640",
    "end": "1128279"
  },
  {
    "text": "if we are looking at sand,\nrock, bedrock, and so forth. However, these are\nsegmentation masks and not",
    "start": "1128280",
    "end": "1136490"
  },
  {
    "text": "natural language annotations. So what we do is we set up\nautomated pipeline which",
    "start": "1136490",
    "end": "1143150"
  },
  {
    "text": "leverages GPT-4, for example,\nwhich creates this automated annotation.",
    "start": "1143150",
    "end": "1148500"
  },
  {
    "text": "So what we do in\npractice is we feed this image that has a\nsegmentation mask together with the ground\ntruth label or thing",
    "start": "1148500",
    "end": "1156649"
  },
  {
    "text": "that we want to leverage\nfrom that image. And we ask GPT-4 to\nautomatically generate",
    "start": "1156650",
    "end": "1162830"
  },
  {
    "text": "some sort of textual description\nrelated to that task. And so this is one example in\nwhich we can automate it, like",
    "start": "1162830",
    "end": "1170150"
  },
  {
    "text": "in an automated way, create\nlarge data sets from, in this case images\nand segmentation masks,",
    "start": "1170150",
    "end": "1176090"
  },
  {
    "text": "that have images and natural\nlanguage annotations.",
    "start": "1176090",
    "end": "1181460"
  },
  {
    "text": "And the second thing\nwe were talking about is a kind of\nspace-specific knowledge.",
    "start": "1181460",
    "end": "1186899"
  },
  {
    "text": "And so what we do here as a\nagain first steps towards this direction is that we collect\n1,000 of the most recent",
    "start": "1186900",
    "end": "1193610"
  },
  {
    "text": "publications in astrophysics\nfrom archive and we use GPT-4 to automatically again generate\na large scale data set,",
    "start": "1193610",
    "end": "1201450"
  },
  {
    "text": "in this case around\n25k QA pairs. So again, these\nare two examples.",
    "start": "1201450",
    "end": "1208140"
  },
  {
    "text": "But the main thread\nconnecting them is that we want to achieve\nthese two desiderata.",
    "start": "1208140",
    "end": "1213210"
  },
  {
    "text": "So having natural language\nannotations and specific space knowledge. But we want to do this\nin an automated way.",
    "start": "1213210",
    "end": "1220200"
  },
  {
    "text": "And we leverage\nfoundation models itself to create these data\nsets, which we then can use to adapt\nfoundation models again.",
    "start": "1220200",
    "end": "1229780"
  },
  {
    "text": "And so the result of\nall of this is a dataset which we refer to here as the\nspace-LLaVa dataset, which",
    "start": "1229780",
    "end": "1236559"
  },
  {
    "text": "is a dataset comprised of\na number of different tasks that range from visual\nquestion answering,",
    "start": "1236560",
    "end": "1241570"
  },
  {
    "text": "space-specific question answers,\ninstruction following, and so forth. And we use this to fine tune\nopen source vision language",
    "start": "1241570",
    "end": "1249790"
  },
  {
    "text": "models. And the result is indeed\nour Space-LLaVa model.",
    "start": "1249790",
    "end": "1255430"
  },
  {
    "text": "And we evaluate it on both\nin-distribution tasks or close to in-distribution tasks\nand compare it against,",
    "start": "1255430",
    "end": "1263690"
  },
  {
    "text": "first of all, state-of-the-art\nmodels like GPT-4o, but also the pretrained\nversions of LLaVa.",
    "start": "1263690",
    "end": "1272779"
  },
  {
    "text": "So basically saying we take\nLLaVa and we fine-tune it to the space dataset. How well does it compare against\nitself before the fine-tuning.",
    "start": "1272780",
    "end": "1281919"
  },
  {
    "text": "And what we see here is that in\ndistribution tasks for things like scene descriptions or\ngroup terrain localization,",
    "start": "1281920",
    "end": "1291914"
  },
  {
    "text": "the Space-LLaVa model actually\noutperforms the baselines. But also in emergent tasks that\nare withheld from the training",
    "start": "1291914",
    "end": "1302570"
  },
  {
    "text": "tasks, so these are things, in\nthis case terrain comparison. So we didn't explicitly train\nthe model on terrain comparison.",
    "start": "1302570",
    "end": "1308970"
  },
  {
    "text": "But we see that because of\nthe training that we did, Space-LLaVa is more\ncapable on doing terrain comparison than the baselines.",
    "start": "1308970",
    "end": "1316639"
  },
  {
    "text": "What was your metric\nto assess performance? Yes, it's a great question. So the way we measured\nperformance here",
    "start": "1316640",
    "end": "1323750"
  },
  {
    "text": "is that we have this score\nranging from 0 to 100. And what we do is we feed the\noutput of both the Space-LLaVa,",
    "start": "1323750",
    "end": "1331710"
  },
  {
    "text": "so our model, and\nthe comparison, could be GPT-4o, to GPT-4o That\nHas, as its context, the ground",
    "start": "1331710",
    "end": "1338780"
  },
  {
    "text": "truth answer. So again, throughout\nthe entire process, we care to have an\nautomated process",
    "start": "1338780",
    "end": "1344310"
  },
  {
    "text": "to have all of\nthe various steps. And so what we're doing is we\nare feeding state-of-the-art",
    "start": "1344310",
    "end": "1349890"
  },
  {
    "text": "foundation model with the\nground truth answer and the two attempted answer\nfrom the two models.",
    "start": "1349890",
    "end": "1355629"
  },
  {
    "text": "And we aske GPT-4o to\nscore these two answers.",
    "start": "1355630",
    "end": "1362010"
  },
  {
    "text": "So again, the takeaway here\nis that after fine-tuning, we evaluate on\nin-distribution tasks. So withheld data, but\nin-distribution tasks,",
    "start": "1362010",
    "end": "1369179"
  },
  {
    "text": "or withheld tasks that are\nstill close to the distribution because it's on the same data.",
    "start": "1369180",
    "end": "1375250"
  },
  {
    "text": "So it's still a margin\nimagery, for example. But then since we are working\nwith very specialized domain,",
    "start": "1375250",
    "end": "1382600"
  },
  {
    "text": "what we actually care about is\nalso evaluating and making sure that we are not forgetting a\nlot of the specific knowledge",
    "start": "1382600",
    "end": "1390179"
  },
  {
    "text": "or actually generalist knowledge\nthat these visual language models have. And so here on the\nright, we evaluate again",
    "start": "1390180",
    "end": "1399529"
  },
  {
    "text": "Space-LLaVa against baselines on\na far out-of-distribution tasks",
    "start": "1399530",
    "end": "1404750"
  },
  {
    "text": "that are not related with\nthe space domain necessarily. And here, for example, is\na pretty common evaluation",
    "start": "1404750",
    "end": "1411140"
  },
  {
    "text": "benchmark for vision\nlanguage models. And the takeaway here\nis that Space-LLaVa, despite this very targeted\nfine-tuning on space data,",
    "start": "1411140",
    "end": "1420350"
  },
  {
    "text": "is still comparable to its\nnon-fine-tuned counterparts.",
    "start": "1420350",
    "end": "1425436"
  },
  {
    "text": "And lastly, another direction\nthat we evaluate in this space",
    "start": "1428630",
    "end": "1435530"
  },
  {
    "text": "is we've been seeing--\nuntil now, we've been discussing the use of\nfoundation models, specifically",
    "start": "1435530",
    "end": "1440690"
  },
  {
    "text": "vision language models for\ndata curation, essentially. So we are given some\nimage data and we",
    "start": "1440690",
    "end": "1445909"
  },
  {
    "text": "want to generate different\nkind of textual annotations from that data. But now we want\nto look into ways",
    "start": "1445910",
    "end": "1453530"
  },
  {
    "text": "in which foundation\nmodels could be used within a modular\nautonomy stacks. So if we take a step back,\nthe usual autonomy stack",
    "start": "1453530",
    "end": "1462600"
  },
  {
    "text": "is modular, in the sense that\nwe start from perception. This perception is\nthen fed into some sort",
    "start": "1462600",
    "end": "1469020"
  },
  {
    "text": "of planning or decision\nmaking module, which is then fed into a actuation\nmodel, which then takes",
    "start": "1469020",
    "end": "1475380"
  },
  {
    "text": "the decisions that I took\nand actually implements them in practice on the\nreal world robot.",
    "start": "1475380",
    "end": "1480759"
  },
  {
    "text": "What we try to see here\nis where in this pipeline can we use foundation models? And where can this facilitate a\nnumber of different processes?",
    "start": "1480760",
    "end": "1490710"
  },
  {
    "text": "And the way we do this case\nstudy, we focus on here is that we demonstrate the\nuse of a foundation model",
    "start": "1490710",
    "end": "1496950"
  },
  {
    "text": "as a high level path\nplanner and runtime monitor for a lunar rover. So if you can see\nhere from the slide,",
    "start": "1496950",
    "end": "1505210"
  },
  {
    "text": "we are basically dealing with\na 3D simulated environment of the lunar surface where\nwe have a rover and a lander.",
    "start": "1505210",
    "end": "1513429"
  },
  {
    "text": "So these are the two\nkey main players. And the task of this\nrover is, for example, to reach the lander from\nits current position.",
    "start": "1513430",
    "end": "1521510"
  },
  {
    "text": "And the way it has\nto reach the lander is by following some of high\nlevel plan that is being given",
    "start": "1521510",
    "end": "1527659"
  },
  {
    "text": "to it from, say, a ground team. So we have a rover. We hypothesize there is a ground\nteam that gives a high level",
    "start": "1527660",
    "end": "1534919"
  },
  {
    "text": "plan to this rover. And the rover is then tasked\nto follow these waypoints.",
    "start": "1534920",
    "end": "1540090"
  },
  {
    "text": "And visually, you can imagine\nthat here the yellow rectangle is the rover, the\nred is the lander,",
    "start": "1540090",
    "end": "1547380"
  },
  {
    "text": "and the orange rectangles\nare this candidate waypoints that are given to the\nrover from the ground team.",
    "start": "1547380",
    "end": "1553490"
  },
  {
    "text": "So where does the foundation\nmodel fit in this problem? Is that we want to\nuse the foundation",
    "start": "1553490",
    "end": "1559010"
  },
  {
    "text": "model as a monitor and evaluator\nof this candidate path.",
    "start": "1559010",
    "end": "1564270"
  },
  {
    "text": "So the foundation model will\nreceive both the high level candidate path from\nthe ground team,",
    "start": "1564270",
    "end": "1571740"
  },
  {
    "text": "but also onboard\nand offboard images. So we will have camera\nimages from the rover,",
    "start": "1571740",
    "end": "1577510"
  },
  {
    "text": "so depicting the\ncurrent scene around it. And we also have a top-down\nview that potentially",
    "start": "1577510",
    "end": "1582870"
  },
  {
    "text": "sees a more further\naway and zoomed out zone of the environment.",
    "start": "1582870",
    "end": "1589410"
  },
  {
    "text": "And so, for example, as a\nqualitative example here, we had the rover\nin this condition",
    "start": "1589410",
    "end": "1595409"
  },
  {
    "text": "and hopefully it's\nclear from the slide. But it's basically\nin a situation where it's moderately visible seen.",
    "start": "1595410",
    "end": "1603540"
  },
  {
    "text": "On the right, there is\nreally low visibility. And also from the\nthings that we can see,",
    "start": "1603540",
    "end": "1609700"
  },
  {
    "text": "there is rough terrain\nand uneven regolith. And the candidate path\nfrom the ground team",
    "start": "1609700",
    "end": "1616740"
  },
  {
    "text": "is to essentially drive exactly\nthrough this poorly lit area and potentially also risky.",
    "start": "1616740",
    "end": "1625140"
  },
  {
    "text": "And so what we do\nis we basically feed to the foundation model,\nin this case just GPT-4,",
    "start": "1625140",
    "end": "1632200"
  },
  {
    "text": "the onboard camera\nimages from the rover, together with this top-down\nview and a description",
    "start": "1632200",
    "end": "1637419"
  },
  {
    "text": "of the waypoints that\nwe would like to follow. And what we see is that the\nfoundation model, in this case,",
    "start": "1637420",
    "end": "1643429"
  },
  {
    "text": "processes all of these\ninputs and generates some coherent reasoning,\nultimately suggesting",
    "start": "1643430",
    "end": "1650620"
  },
  {
    "text": "an alternative path,\nthat is the green one here on the slide,\nwhich tries to avoid this unlit region and the kind\nof hazardous terrain overall.",
    "start": "1650620",
    "end": "1660430"
  },
  {
    "text": "And in closed loop, if we\nthen apply the candidate path,",
    "start": "1660430",
    "end": "1665770"
  },
  {
    "text": "here you can see in\nthe big rectangle on the left, top-down\nview of the rover.",
    "start": "1665770",
    "end": "1671510"
  },
  {
    "text": "And then the three frontal\ncameras on the rover itself. And essentially, what\nwe see here is that--",
    "start": "1671510",
    "end": "1677980"
  },
  {
    "text": "I think what is interesting\nis that we are seeing how foundation models\ncan essentially process",
    "start": "1677980",
    "end": "1683529"
  },
  {
    "text": "these multi-modal inputs,\nwhich could range from images,",
    "start": "1683530",
    "end": "1688570"
  },
  {
    "text": "textual description of the tasks\nthat we would like to follow. And coherently reason\non it and produce",
    "start": "1688570",
    "end": "1694530"
  },
  {
    "text": "some outputs that in this\ncase is also quite reasonable. And so this is, obviously,\njust a case study.",
    "start": "1694530",
    "end": "1701950"
  },
  {
    "text": "But more broadly, this\nlunar mobility application represents an instantiation\nof a broader framework",
    "start": "1701950",
    "end": "1709559"
  },
  {
    "text": "where foundation models\ncould enable multimodal input processing. So combining data from, say,\nonboard/offboard sensors",
    "start": "1709560",
    "end": "1717090"
  },
  {
    "text": "with mission\nspecifications that are described in natural language.",
    "start": "1717090",
    "end": "1722130"
  },
  {
    "text": "Automated reasoning\ncapabilities. So we can, yes, parse\nall of this input, but then do some non-trivial\nreasoning on top of it.",
    "start": "1722130",
    "end": "1730150"
  },
  {
    "text": "And third, reconfigurable\ninterfaces, because text can be a pretty\nflexible domain, which",
    "start": "1730150",
    "end": "1740009"
  },
  {
    "text": "allows the foundation\nmodel to potentially be at different positions\nwithin the autonomy stack.",
    "start": "1740010",
    "end": "1745085"
  },
  {
    "text": "And so taking a step\nback and linking again to where we started,\nwe started motivated",
    "start": "1747630",
    "end": "1753880"
  },
  {
    "text": "by the breakthroughs that are\nhappening in over the last two or three years. And we focus on the role\nof foundation models",
    "start": "1753880",
    "end": "1760450"
  },
  {
    "text": "for space autonomy. And we looked at two\ndifferent directions. One is directly\ntaking techniques that have been developed in\nthe foundation model literature",
    "start": "1760450",
    "end": "1767770"
  },
  {
    "text": "and applying them to spacecraft\ntrajectory optimization, where specific\nchallenges emerge,",
    "start": "1767770",
    "end": "1774440"
  },
  {
    "text": "like the necessity\nto strictly tackle the problem of hallucinations.",
    "start": "1774440",
    "end": "1780049"
  },
  {
    "text": "And we solved this, or at least\nproposed a candidate solution through the idea\nof warm-starting. And then we said, rather than\nonly taking the techniques,",
    "start": "1780050",
    "end": "1788240"
  },
  {
    "text": "can we leverage foundation\nmodels, pre-trained foundation models in some way that is\nuseful across the autonomy stack?",
    "start": "1788240",
    "end": "1793580"
  },
  {
    "text": "And we've seen the specific\nexample of vision language models for things\nsuch as data curation,",
    "start": "1793580",
    "end": "1799220"
  },
  {
    "text": "but also the integration\nwithin modular autonomy stacks.",
    "start": "1799220",
    "end": "1804580"
  },
  {
    "text": "And this is my last slide. Thanks. [APPLAUSE]",
    "start": "1804580",
    "end": "1811140"
  },
  {
    "text": "Yeah. With training the\nfoundation model for the trajectory generation,\nhow do you deal with a sim",
    "start": "1816100",
    "end": "1822600"
  },
  {
    "text": "to real gap? Because in aerospace, at\nleast, the simulation models for vehicles tend to be very\ncomplicated, but also very",
    "start": "1822600",
    "end": "1830130"
  },
  {
    "text": "inaccurate compared to\ncomplicated real life models? So your question, if\nI understand correctly",
    "start": "1830130",
    "end": "1835870"
  },
  {
    "text": "is, in the first part\nof the presentation where we train a transformer\nfor trajectory optimization,",
    "start": "1835870",
    "end": "1841240"
  },
  {
    "text": "how do we deal with the\ngap between the dynamics that we can replicate\nin simulation",
    "start": "1841240",
    "end": "1846960"
  },
  {
    "text": "and the actual dynamics of-- it is a very good question. And I don't think we\nhave a clear answer",
    "start": "1846960",
    "end": "1852570"
  },
  {
    "text": "that this is the best\nway to go for it. In some sense, in\nspace, typically, you",
    "start": "1852570",
    "end": "1861346"
  },
  {
    "text": "have some idea of the dynamics\nthat you're dealing with. Maybe not all the aspects\nare perfectly modeled.",
    "start": "1861347",
    "end": "1866643"
  },
  {
    "text": "But I would say that what\nyou could do in simulation is you could artificially\ngenerate noise",
    "start": "1866643",
    "end": "1872530"
  },
  {
    "text": "in the dynamic or\nuncertainties in the dynamics that you are simulating. Therefore, rather than\nasking ourselves, what",
    "start": "1872530",
    "end": "1880360"
  },
  {
    "text": "is the ground truth dynamics? And how can I\nrecover in this gap? Maybe one way to see it is,\nhow can I target the training",
    "start": "1880360",
    "end": "1889480"
  },
  {
    "text": "phase in a way that my model\nis not overfitting for one specific dynamic that I\nknow is wrong, but is rather",
    "start": "1889480",
    "end": "1895330"
  },
  {
    "text": "capable of dealing and slightly\nadapting to unmodeled effects?",
    "start": "1895330",
    "end": "1898950"
  },
  {
    "text": "Yeah. I'm curious about your comments\non these two directions",
    "start": "1906400",
    "end": "1912580"
  },
  {
    "text": "overall like comparison for say\ntrajectory generation tasks. So the first one\nis specifically you",
    "start": "1912580",
    "end": "1919990"
  },
  {
    "text": "train a transformer\nthat can handle the specific trajectory\ngeneration task. And the other is embedded into\nthis generation, I would say.",
    "start": "1919990",
    "end": "1929780"
  },
  {
    "text": "So what's your comments on\nwhether people will eventually replace this specific\ntrajectory generation",
    "start": "1929780",
    "end": "1937010"
  },
  {
    "text": "task by embedding that\ninto, say, one of these text generation tasks? Or we will just keep--",
    "start": "1937010",
    "end": "1942620"
  },
  {
    "text": "like this direction will\nkeep thriving instead of say being say like just\nclassified as a text generation?",
    "start": "1942620",
    "end": "1951800"
  },
  {
    "text": "So your question,\nif I reword it, is do I see these directions\nto remain separate?",
    "start": "1951800",
    "end": "1958320"
  },
  {
    "text": "Or do I foresee\nsomething where we have one model that can\ndo text and whatever, but also trajectories?",
    "start": "1958320",
    "end": "1963870"
  },
  {
    "text": "Is this correct? The second one is\nan exciting idea. And I don't see--",
    "start": "1963870",
    "end": "1972251"
  },
  {
    "text": "part of the\nmotivation for this is that we think these\nfoundation models can handle",
    "start": "1972251",
    "end": "1977600"
  },
  {
    "text": "very well this multi modality. Now what this multi-modality\nentails, it's an open question.",
    "start": "1977600",
    "end": "1983690"
  },
  {
    "text": "But it would be very exciting\nto see the same model that can take both vision language\nor other sensor modalities.",
    "start": "1983690",
    "end": "1991370"
  },
  {
    "text": "And then have as an output\nalso some of control. So yes, I see this\nas potentially",
    "start": "1991370",
    "end": "1997659"
  },
  {
    "text": "the two joining\ntogether at some point. Yeah.",
    "start": "1997660",
    "end": "2002880"
  },
  {
    "text": "So in autonomous vehicles\nor autonomous robots, they also can crash.",
    "start": "2002880",
    "end": "2008880"
  },
  {
    "text": "So you highlighted several\ndifferences between the space domain and ground domain.",
    "start": "2008880",
    "end": "2015820"
  },
  {
    "text": "So, what are the\ndifferences that push you",
    "start": "2015820",
    "end": "2021779"
  },
  {
    "text": "towards not using the\nsame methods that are used in autonomous vehicles?",
    "start": "2021780",
    "end": "2025400"
  },
  {
    "text": "It's a good question. So I think that in the--\nso one big difference",
    "start": "2031380",
    "end": "2038340"
  },
  {
    "text": "between the automotive\nsector and the space sector is definitely the\namount of compute.",
    "start": "2038340",
    "end": "2046940"
  },
  {
    "text": "So you see that in\nAVs, for example, there is a very fast integration\nof many of the modules that",
    "start": "2046940",
    "end": "2054280"
  },
  {
    "text": "are originally thought as part\nof the modular autonomy stack are being replaced by\nlearning-based methods.",
    "start": "2054280",
    "end": "2061330"
  },
  {
    "text": "I think the space domain is much\nmore conservative in that sense, rightly so in some cases.",
    "start": "2061330",
    "end": "2067850"
  },
  {
    "text": "And so the way we took a\nfirst step in this direction is that we wanted\nto stay really close",
    "start": "2067850",
    "end": "2074080"
  },
  {
    "text": "with the current strategies\nthat are currently being used for trajectory optimization in\nspace, which typically entail, I",
    "start": "2074080",
    "end": "2081190"
  },
  {
    "text": "mean, what is very\npopular nowadays is some form of sequential\nconvex programming. So you have a non-linear\nmodel, but you",
    "start": "2081190",
    "end": "2087790"
  },
  {
    "text": "linearize it and you\nsolve iteratively this linearized\nversions of the problem. And so this is exactly\nwhat we do here.",
    "start": "2087790",
    "end": "2093888"
  },
  {
    "text": "So to answer your\nquestion is right now, we really focus\non trying to stay",
    "start": "2093889",
    "end": "2099329"
  },
  {
    "text": "close from what is\nconsidered good practice in the case of space. But I don't see why not.",
    "start": "2099330",
    "end": "2105089"
  },
  {
    "text": "There should be\ncross-contamination of ideas between the IVs\nand the space sector.",
    "start": "2105090",
    "end": "2111270"
  },
  {
    "text": "Is it fair to say that you\nmay allow much slower speeds of decision-making and control\nrather than in-- again,",
    "start": "2111270",
    "end": "2119560"
  },
  {
    "text": "so you have this\nluxury of staying close to computational platforms\nthat already exist for space?",
    "start": "2119560",
    "end": "2129160"
  },
  {
    "text": "Yeah. So you're saying\nthe compute that--",
    "start": "2129160",
    "end": "2134940"
  },
  {
    "text": "You don't have to make\ndecisions at 60 miles per hour. Therefore, you can stay\nwithin flight [INAUDIBLE]",
    "start": "2134940",
    "end": "2145980"
  },
  {
    "text": "compute platforms. Yeah, this is one indeed,\ndepending on the application, of course. But if you look at\nspacecraft specifically,",
    "start": "2145980",
    "end": "2152402"
  },
  {
    "text": "this is a big distinction. Thank you. Yeah.",
    "start": "2152402",
    "end": "2157540"
  },
  {
    "text": "Thank you. Thanks for the talk. I was wondering if you have\nany thoughts on how foundation",
    "start": "2157540",
    "end": "2163240"
  },
  {
    "text": "models are obviously\npromising for task planning, but do you have\nthoughts on how they",
    "start": "2163240",
    "end": "2168940"
  },
  {
    "text": "can be used in system management\nor vehicle health, monitoring",
    "start": "2168940",
    "end": "2175359"
  },
  {
    "text": "those things on board? Yeah, it's a great question. Indeed, I didn't mention\nthis during the talk,",
    "start": "2175360",
    "end": "2181070"
  },
  {
    "text": "but some of the other\napplications that we think could be promising\nfor foundation models",
    "start": "2181070",
    "end": "2186490"
  },
  {
    "text": "aside from data curation and\nactual high level path planning is that it is really\nexciting to think",
    "start": "2186490",
    "end": "2193600"
  },
  {
    "text": "about all the\npossible applications across the operations that\ncould benefit from these things.",
    "start": "2193600",
    "end": "2199099"
  },
  {
    "text": "And, for example, the\nmonitoring the sanity of specific components\ncould be one.",
    "start": "2199100",
    "end": "2204260"
  },
  {
    "text": "Again, I think what really\nplays an important role is the fact that these--",
    "start": "2204260",
    "end": "2209849"
  },
  {
    "text": "through natural\nlanguage and being able to handle text or\npotentially even code,",
    "start": "2209850",
    "end": "2214990"
  },
  {
    "text": "these models can\npotentially monitor what is happening on board,\nmaybe request specific checks,",
    "start": "2214990",
    "end": "2222359"
  },
  {
    "text": "interact with humans\nin order to say like, do I have a green light\nto run this check or not?",
    "start": "2222360",
    "end": "2228560"
  },
  {
    "text": "Something else could be aid in\ncreating adversarial examples.",
    "start": "2228560",
    "end": "2234900"
  },
  {
    "text": "So if I'm running a vision\nsystem for satellite operations.",
    "start": "2234900",
    "end": "2241730"
  },
  {
    "text": "It is very rare\nto have situations where I have a specific\nglare on my satellite,",
    "start": "2241730",
    "end": "2246927"
  },
  {
    "text": "but maybe through a\nvision generation model, I can actually\ngenerate some elements of these adversarial examples\nand probe my system accordingly.",
    "start": "2246927",
    "end": "2254280"
  },
  {
    "text": "So it's a long answer,\nbut in short, definitely I think there is\nopportunity there.",
    "start": "2254280",
    "end": "2260848"
  },
  {
    "text": "You discussed the differences\nbetween the computational power of terrestrial compute\nversus space compute. Is that just economies\nof scale problem?",
    "start": "2260848",
    "end": "2267510"
  },
  {
    "text": "The space market\nisn't large enough to justify the investment in\nrad hardening the compute?",
    "start": "2267510",
    "end": "2273180"
  },
  {
    "text": "Or are there\ntechnical limitations that have to be overcome to put\nmore powerful computer space? I think it's both.",
    "start": "2273180",
    "end": "2278900"
  },
  {
    "text": "There are definitely also\njust technical limitations because these\ncompute needs to be hardened and more resistant\nto radiation, for example.",
    "start": "2278900",
    "end": "2286540"
  },
  {
    "text": "So I think it's a mix of both.",
    "start": "2286540",
    "end": "2288020"
  },
  {
    "text": "So is there anything\nparticularly annoying that your models aren't\ncapable of doing? Last time I tried doing things\nwith smaller models like 7 or 13",
    "start": "2295240",
    "end": "2304260"
  },
  {
    "text": "billion and I didn't get a\nlot into the training of them to my specific task, but they\nwould do stupid little things,",
    "start": "2304260",
    "end": "2309790"
  },
  {
    "text": "like they wouldn't follow\ninstructions consistently. Yeah. I think, especially\ndoubling down",
    "start": "2309790",
    "end": "2316240"
  },
  {
    "text": "on the consistency of\nthese models, especially if your model is not extremely\nconfident about what it's doing,",
    "start": "2316240",
    "end": "2322519"
  },
  {
    "text": "the tendency is\nthat it will start to be very open to\nchanging its answer even",
    "start": "2322520",
    "end": "2331390"
  },
  {
    "text": "with very similar inputs or\nvery sensitive to its inputs. Indeed, indeed.",
    "start": "2331390",
    "end": "2336660"
  },
  {
    "text": "So I think there needs to be\na lot of work to go there. But Yes, like the\nconsistency, being",
    "start": "2336660",
    "end": "2343422"
  },
  {
    "text": "able to solve the tasks\nthat I'm asking and not going in other directions. Yeah.",
    "start": "2343422",
    "end": "2348230"
  },
  {
    "text": "The last question [INAUDIBLE]. Yeah, sure. Seems to me like everybody\nthat have robots in the lab",
    "start": "2351800",
    "end": "2358589"
  },
  {
    "text": "ought to be figuring out\nways to close the loop with these models, with ROS 2--",
    "start": "2358590",
    "end": "2364670"
  },
  {
    "text": "with ROS 2 packages\nand things like that, that iron\nover the problems, so that these things can start\nself-supervising on robotics.",
    "start": "2364670",
    "end": "2373660"
  },
  {
    "text": "Your thoughts, sort\nof the big picture. For safety, right? Yes.",
    "start": "2376260",
    "end": "2381800"
  },
  {
    "text": "There has been some recent work\non leveraging language models specifically for\nhuman-robot interface.",
    "start": "2381800",
    "end": "2388560"
  },
  {
    "text": "So if you have a\nlanguage model that can generate highly capable\nROS code, for example,",
    "start": "2388560",
    "end": "2395650"
  },
  {
    "text": "you could specify some desired\ntask or outcome that you want",
    "start": "2395650",
    "end": "2401349"
  },
  {
    "text": "to achieve in natural language. The model could come up very\nquickly with some ROS code",
    "start": "2401350",
    "end": "2406779"
  },
  {
    "text": "and interface itself\nwith the robot. And obviously, I agree with you. At the current\nstage, there needs",
    "start": "2406780",
    "end": "2412060"
  },
  {
    "text": "to be some of feedback loop in\norder to check on the validity. But I think these directions of\nexploring not only the reasoning",
    "start": "2412060",
    "end": "2419980"
  },
  {
    "text": "capabilities. So can these models\nsolve new problems? But also the interfaces. So can we use these models\nto rethink a little bit how",
    "start": "2419980",
    "end": "2428050"
  },
  {
    "text": "we interact with\nrobots that could be generalizable across\nembodiments, for example,",
    "start": "2428050",
    "end": "2434522"
  },
  {
    "text": "or more broadly speaking,\nhelp in scaling up operations.",
    "start": "2434522",
    "end": "2437826"
  },
  {
    "text": "Let's thank our\nspeaker for today. [APPLAUSE]",
    "start": "2440860",
    "end": "2446309"
  }
]
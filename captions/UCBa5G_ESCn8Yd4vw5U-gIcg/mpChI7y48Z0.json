[
  {
    "start": "0",
    "end": "136000"
  },
  {
    "text": ">> Let me now introduce today's speaker, Chris Potts. Christopher Potts is professor of Linguistics and by courtesy,",
    "start": "9470",
    "end": "17280"
  },
  {
    "text": "of Computer Science at Stanford University. He's a director of the Center for the Study of Language and Information at Stanford.",
    "start": "17280",
    "end": "25255"
  },
  {
    "text": "In his research, he develops computational models of linguistic reasoning, emotional expression, and dialogue.",
    "start": "25255",
    "end": "32304"
  },
  {
    "text": "He's the author of the book, The Logic of Conventional Implicatures, and as well as numerous scholarly papers in linguistics and natural language processing.",
    "start": "32304",
    "end": "40945"
  },
  {
    "text": "Thank you for joining us, Chris, and I am happy to hand it over to you. >> Thank you, Petra, and thank you, everyone,",
    "start": "40945",
    "end": "48225"
  },
  {
    "text": "for turning out today, I think this is an exciting event. I also want to have the chance, just want to thank those course alums for coming back to talk about their work.",
    "start": "48225",
    "end": "56630"
  },
  {
    "text": "I think that's very generous they did great and exciting things during the course and it's great for them to be reporting out to you on what they achieved.",
    "start": "56630",
    "end": "63850"
  },
  {
    "text": "To kick this off, I think I just want to say very boldly that we live in the most exciting moments in history for doing work in natural language understanding.",
    "start": "63850",
    "end": "73655"
  },
  {
    "text": "It really does feel like over the past 15 years, we've seen some real qualitative changes in what we're able to do,",
    "start": "73655",
    "end": "80900"
  },
  {
    "text": "both with technology and with kind of core scientific development. That's a very positive picture,",
    "start": "80900",
    "end": "87640"
  },
  {
    "text": "it really is an exciting moment. On the other hand, I think as practitioners, we can see that some of the gains aren't what they first seem,",
    "start": "87640",
    "end": "96020"
  },
  {
    "text": "that really, the big questions are still left open,",
    "start": "96020",
    "end": "101235"
  },
  {
    "text": "and that's part of what makes this such an exciting moment. It's not just that we're able to do new and exciting things,",
    "start": "101235",
    "end": "106760"
  },
  {
    "text": "but also that the big research challenges are still ahead of us. I think what I can do today is give you a full picture of",
    "start": "106760",
    "end": "114079"
  },
  {
    "text": "that through the lens of what I'm going to call adversarial testing, which is a new mode of evaluating",
    "start": "114080",
    "end": "120050"
  },
  {
    "text": "our systems and looking for ways to find problems with them and improve them.",
    "start": "120050",
    "end": "125365"
  },
  {
    "text": "Here's our outline for today. I do want to just emphasize under the heading of a golden age for NLU that lots of exciting things are happening,",
    "start": "125365",
    "end": "134155"
  },
  {
    "text": "and I want that to be the overall message that it really is an exciting moment. However, it's important that we take a peek behind the curtain and come to",
    "start": "134155",
    "end": "142720"
  },
  {
    "start": "136000",
    "end": "136000"
  },
  {
    "text": "a measured understanding of what this progress is actually like. That will key us up to talk about adversarial testing which is this more technical,",
    "start": "142720",
    "end": "152620"
  },
  {
    "text": "more strategic way that we as practitioners can find fault with our systems and then look for ways to improve them.",
    "start": "152620",
    "end": "159860"
  },
  {
    "text": "That's a nice transition into the coursework for XCS224U because I think the tools and techniques that",
    "start": "159860",
    "end": "166600"
  },
  {
    "text": "we introduce are really great for combining that with adversarial testing and finding new ways to make progress.",
    "start": "166600",
    "end": "173950"
  },
  {
    "text": "Let's kick it off on this positive note, a golden age for NLU. I've just assembled some examples that have to do with natural language understanding.",
    "start": "173950",
    "end": "181580"
  },
  {
    "text": "Actually, I could be talking about AI in general because it really is a golden age for the entire field.",
    "start": "181580",
    "end": "188180"
  },
  {
    "text": "First example, artificial assistants. These get a lot of the press, these are things like Siri and Google Home.",
    "start": "188180",
    "end": "194210"
  },
  {
    "text": "Then we're trusting among you might have these devices in your homes, listening to you at all times.",
    "start": "194210",
    "end": "199220"
  },
  {
    "text": "They certainly passed the bar in terms of utility, they're able to help us with simple tasks around the house.",
    "start": "199220",
    "end": "205280"
  },
  {
    "text": "I also want to just call out the fact that their speech-to-text capabilities are astounding.",
    "start": "205280",
    "end": "211010"
  },
  {
    "text": "I think they're good in the sense that 15 years ago, the things that they achieve every day would have looked like science fiction.",
    "start": "211010",
    "end": "217645"
  },
  {
    "text": "Now, it's by no means a solved problem. There are plenty of remaining issues with that speech-to-text.",
    "start": "217645",
    "end": "223715"
  },
  {
    "text": "But again, it really does feel like we've made a phase change in terms of the things that we can achieve there.",
    "start": "223715",
    "end": "228920"
  },
  {
    "text": "Maybe for the NLU, a little less, as we'll see in a little bit. We don't actually talk about machine translation in the course,",
    "start": "228920",
    "end": "236750"
  },
  {
    "text": "but I'd be remiss if I didn't bring it up because this is another major breakthrough area for language technologies.",
    "start": "236750",
    "end": "243125"
  },
  {
    "text": "I've picked Google Translate as my example here. First of all, Google Translate can take you from",
    "start": "243125",
    "end": "249350"
  },
  {
    "text": "dozens of input languages to dozens of output languages. That alone is a kind of astounding science and technology accomplishment.",
    "start": "249350",
    "end": "257875"
  },
  {
    "text": "But it's also remarkable how good the translations can be. Here, just as a quick example, I've put some English in on the left,",
    "start": "257875",
    "end": "265160"
  },
  {
    "text": "I've got a French example on the right, and this is actually a example from a popular dataset so",
    "start": "265160",
    "end": "270650"
  },
  {
    "text": "we have a so-called gold translation here, and it's just striking how close the translated text is to that human gold standard.",
    "start": "270650",
    "end": "279665"
  },
  {
    "text": "You have the usual mistakes in terms of preposition and maybe word choice and stylistics, but again,",
    "start": "279665",
    "end": "286129"
  },
  {
    "text": "it really passes the bar in terms of helping someone who doesn't understand this input language actually figure out what was expressed.",
    "start": "286130",
    "end": "293770"
  },
  {
    "text": "That's just something that wasn't true 15 or 20 years ago for these MT systems.",
    "start": "293770",
    "end": "298819"
  },
  {
    "text": "Image captioning is a really great grounded language understanding task",
    "start": "298820",
    "end": "304460"
  },
  {
    "start": "301000",
    "end": "301000"
  },
  {
    "text": "where the inputs are images, and the task is to assign them accurate and interesting and descriptive captions.",
    "start": "304460",
    "end": "310520"
  },
  {
    "text": "This is from a paper a few years ago that was really a breakthrough paper, I think, on doing this kind of natural language generation.",
    "start": "310520",
    "end": "316880"
  },
  {
    "text": "I just want to observe that these captions are really great. A person riding a motorcycle on a dirt road,",
    "start": "316880",
    "end": "322010"
  },
  {
    "text": "a group of young people playing a game of Frisbee. This is fluent, basically,",
    "start": "322010",
    "end": "327610"
  },
  {
    "text": "factually accurate text that is really good as a caption for those systems.",
    "start": "327610",
    "end": "332974"
  },
  {
    "text": "Again, this just wasn't something we could achieve 15 years ago. Another major technology moment for me anyway was when IBM's Watson system won Jeopardy,",
    "start": "332975",
    "end": "346220"
  },
  {
    "start": "340000",
    "end": "340000"
  },
  {
    "text": "the online game show. This is a really integrated technology system that had to",
    "start": "346220",
    "end": "351320"
  },
  {
    "text": "do lots of things in order to play the game of Jeopardy. But at the heart, this was a very powerful open domain question answering system.",
    "start": "351320",
    "end": "359449"
  },
  {
    "text": "So I really do mark this as a win for NLU that it was able to be superhuman,",
    "start": "359450",
    "end": "365340"
  },
  {
    "text": "in some sense, on this show by beating these two Jeopardy champions here.",
    "start": "365340",
    "end": "369930"
  },
  {
    "text": "If we zoom in on the tasks that we actually focus on in the course,",
    "start": "370760",
    "end": "376730"
  },
  {
    "start": "373000",
    "end": "373000"
  },
  {
    "text": "I think we see a similar kind of picture where the kinds of things that we can do now just feel very different from the kinds of things we could do 15 years ago.",
    "start": "376730",
    "end": "386300"
  },
  {
    "text": "It feels like we're on the cusp of seeing some really transformative things in the near future as well.",
    "start": "386300",
    "end": "391600"
  },
  {
    "text": "Because it's a major unit for the course, I've picked natural language inference as the task I'm going to focus on to illustrate some of this stuff.",
    "start": "391600",
    "end": "399230"
  },
  {
    "text": "So just briefly, in a task of natural language inference or NLI, you're given a premise and a hypothesis test,",
    "start": "399230",
    "end": "406595"
  },
  {
    "text": "and the task is to assign one of three labels to that pair. In this case, we would assign the label entails to the pair,",
    "start": "406595",
    "end": "413645"
  },
  {
    "text": "\"A turtle danced\", \"A turtle moved\". The idea is that any situation in which this premise sentence which is true,",
    "start": "413645",
    "end": "420695"
  },
  {
    "text": "would also be one in which this hypothesis sentence was true. It's a common sense reasoning task.",
    "start": "420695",
    "end": "427330"
  },
  {
    "text": "Here, for the second example, \"Every reptile danced\" is neutral with respect to \"A turtle ate\" because they can be true or false independently of each other.",
    "start": "427330",
    "end": "435545"
  },
  {
    "text": "Finally, \"Some turtles walk\" and \"No turtles move\" would be a contradiction in this notion of common sense reasoning.",
    "start": "435545",
    "end": "442389"
  },
  {
    "text": "That's a fast overview of the NLI task. There are a few major benchmark datasets.",
    "start": "442390",
    "end": "447695"
  },
  {
    "text": "The first one, the oldest one, is the Stanford Natural Language Inference Corpus. Here, what I've done is just map out on the y-axis the F1 score.",
    "start": "447695",
    "end": "456560"
  },
  {
    "start": "450000",
    "end": "450000"
  },
  {
    "text": "You can think of that as a notion of accuracy for this system. In the original paper,",
    "start": "456560",
    "end": "461660"
  },
  {
    "text": "we set a human baseline of just short of 92 on this F1 score metric, that's this red line here.",
    "start": "461660",
    "end": "468135"
  },
  {
    "text": "Across the x-axis, I have time. What we're going to look at is published papers over time",
    "start": "468135",
    "end": "474620"
  },
  {
    "text": "that have tried to achieve new things on this SNLI benchmark. Here's the picture.",
    "start": "474620",
    "end": "479750"
  },
  {
    "text": "What you see is first of all, basically monotonic progress.",
    "start": "479750",
    "end": "484790"
  },
  {
    "text": "I think people are learning from previous papers and figuring out new tricks that help them on the SNLI task,",
    "start": "484790",
    "end": "490690"
  },
  {
    "text": "so you see a lot of very rapid progress. Then the striking thing is that in the middle of last year,",
    "start": "490690",
    "end": "496310"
  },
  {
    "text": "we saw the first what you might call superhuman system for the SNLI task.",
    "start": "496310",
    "end": "502294"
  },
  {
    "text": "Two things I want to say about that: First, again, this is not something that we could have achieved two decades ago.",
    "start": "502295",
    "end": "508820"
  },
  {
    "text": "It really is remarkable that we even have systems that can enter this competition to say nothing of actually surpassing this estimate of human performance.",
    "start": "508820",
    "end": "518090"
  },
  {
    "text": "However, what we have to keep in mind and what we'll see in a little bit is that this does",
    "start": "518090",
    "end": "523459"
  },
  {
    "text": "not mean that we have systems that are superhuman when it comes to the human tasks of common sense reasoning.",
    "start": "523460",
    "end": "529625"
  },
  {
    "text": "All the hard aspects of that problem remain unsolved completely, and I'm going to make that very clear to you.",
    "start": "529625",
    "end": "536285"
  },
  {
    "text": "But nonetheless, it's striking that we have systems that are even this good in this narrowly circumscribed way.",
    "start": "536285",
    "end": "542005"
  },
  {
    "text": "MultiNLI is a very similar dataset, it's just arguably harder because the underlying data is more diverse.",
    "start": "542005",
    "end": "549260"
  },
  {
    "text": "I have the same framework here, F1 score, and the human estimate is 92.6, so a little bit higher.",
    "start": "549260",
    "end": "555565"
  },
  {
    "text": "I again have time along this x-axis here. Now, it's exciting that this dataset,",
    "start": "555565",
    "end": "561250"
  },
  {
    "text": "unlike the previous one, is on Kaggle so many more people can enter and we can get their scores.",
    "start": "561250",
    "end": "567010"
  },
  {
    "text": "The picture overall is there's a lot more variance, a lot more people are entering and doing a lot more interesting and diverse things,",
    "start": "567010",
    "end": "575060"
  },
  {
    "text": "but it's a similar picture in that we can see the community slowly hill climbing toward what is eventually going to be superhuman performance on this task,",
    "start": "575060",
    "end": "584720"
  },
  {
    "text": "and that's exciting to see. NLI, just to be clear, is not the only area in which we have what you might call",
    "start": "584720",
    "end": "591920"
  },
  {
    "start": "588000",
    "end": "588000"
  },
  {
    "text": "superhuman but \"superhuman performance\". Here are a few other examples, they include speech technologies, translation,",
    "start": "591920",
    "end": "599585"
  },
  {
    "text": "question answering, and GLUE here is a big benchmark task that captures a lot of diverse things.",
    "start": "599585",
    "end": "605760"
  },
  {
    "text": "Again, though, you have to be really careful about how you talk about this. What we have is systems that are superhuman.",
    "start": "605760",
    "end": "612320"
  },
  {
    "text": "On these particular datasets, using a very particular set of metrics, this does not mean that we have superhuman performance in any larger sense.",
    "start": "612320",
    "end": "621430"
  },
  {
    "text": "That's the part that I find exciting. In fact, these are unsolved problems. Nonetheless, you might look and reflect back on this technology,",
    "start": "621430",
    "end": "629860"
  },
  {
    "text": "and start to adopt the perspective that's in this book by Nick Bostrom called Superintelligence. Where it looks at the current state of technology and",
    "start": "629860",
    "end": "637805"
  },
  {
    "text": "begins to wonder what life might be like when very soon perhaps, we have systems that are vastly better than humans at all of these core human abilities.",
    "start": "637805",
    "end": "647250"
  },
  {
    "text": "He worries about what the world and the universe might be like when we achieve those breakthroughs.",
    "start": "647250",
    "end": "652899"
  },
  {
    "text": "Have that picture in mind, I can see why people would arrive at it given the golden age that we live in. But I do want to temper that a little bit.",
    "start": "652900",
    "end": "659845"
  },
  {
    "text": "So let's take a peek behind the curtain at those examples. I mentioned those artificial agents before that are in your houses.",
    "start": "659845",
    "end": "667515"
  },
  {
    "start": "665000",
    "end": "665000"
  },
  {
    "text": "You've probably experienced them in various ways. I think the dream is that they'll be able to do things like these: you say,",
    "start": "667515",
    "end": "674260"
  },
  {
    "text": "\"Any good burger joints around here?\" It replies, \"I found a number of burger restaurants near you.\" You say, \"What about tacos?\"",
    "start": "674260",
    "end": "681485"
  },
  {
    "text": "At that point, your device is able to recognize your intention, very flexibly think about your language and the context it's in,",
    "start": "681485",
    "end": "690325"
  },
  {
    "text": "and proactively help you solve the problem that you've implicitly defined for it. That's the dream. I'm not sure how often you'll experience it.",
    "start": "690325",
    "end": "698779"
  },
  {
    "text": "I want to balance that against this very funny sketch from Stephen Colbert show from a number of years ago.",
    "start": "698780",
    "end": "704625"
  },
  {
    "text": "The premise is that Stephen has been playing with his iPhone which has Siri on it all day and he's failed to write his television show.",
    "start": "704625",
    "end": "712475"
  },
  {
    "text": "He says, \"For the love of God, the cameras are on, give me something.\" Siri replies, \"What kind of place are you looking for?",
    "start": "712475",
    "end": "719785"
  },
  {
    "text": "Camera stores or churches?\" As practitioners, we should pause there and realize what has happened.",
    "start": "719785",
    "end": "726490"
  },
  {
    "text": "Siri is doing some very superficial keyword-matching on the utterance, not-deep-language understanding.",
    "start": "726490",
    "end": "732980"
  },
  {
    "text": "That's why it has associated cameras with camera stores and God with churches.",
    "start": "732980",
    "end": "738430"
  },
  {
    "text": "So to a peek behind the curtain there. The interaction continues, \"I don't want to search for anything.",
    "start": "738430",
    "end": "744250"
  },
  {
    "text": "I want to write the show.\" Siri does what Siri often does, \"Searching the web for, 'Search for anything.",
    "start": "744250",
    "end": "749560"
  },
  {
    "text": "I want to write the shuffle'.\" There's a small transcription error there but I think the broader picture is just that Siri does not have a deep understanding of",
    "start": "749560",
    "end": "758050"
  },
  {
    "text": "this interaction and we're seeing on the surface here the cheat tricks that the device uses in order to try to get past those limitations.",
    "start": "758050",
    "end": "766410"
  },
  {
    "text": "This is by no means open domain dialogue of the sort that we were hoping for.",
    "start": "766410",
    "end": "771860"
  },
  {
    "text": "Translation, I think Google Translate is an astounding technological achievement,",
    "start": "771860",
    "end": "776915"
  },
  {
    "text": "but it too shows that it doesn't have deep understanding. For this example, what I've done is just input a bunch of random vowel sequences.",
    "start": "776915",
    "end": "784770"
  },
  {
    "text": "This is the trick I learned from the Language Log website. Completely random input here.",
    "start": "784770",
    "end": "790105"
  },
  {
    "text": "It's interesting that it has inferred that this is the Hawaiian language. If you know something about Hawaiian syllable structure you might",
    "start": "790105",
    "end": "797315"
  },
  {
    "text": "grant that that is at least an interesting hypothesis about this input. Nonetheless, it is completely random.",
    "start": "797315",
    "end": "803680"
  },
  {
    "text": "The really disconcerting part is that on the right here in English we have a completely fluent sentence that by",
    "start": "803680",
    "end": "810160"
  },
  {
    "text": "definition has nothing to do with that nonsense input. Even stranger, if I make very small changes on the left,",
    "start": "810160",
    "end": "817205"
  },
  {
    "text": "I'll get a completely fluent but completely different sentence out on the right. This is revealing that these systems don't know anything about their own uncertainty,",
    "start": "817205",
    "end": "826235"
  },
  {
    "text": "and certainly don't understand the inputs they're processing. I showed you before those examples from image captioning",
    "start": "826235",
    "end": "833080"
  },
  {
    "text": "to their credit from this excellent paper here, they didn't just show the really successful cases.",
    "start": "833080",
    "end": "838495"
  },
  {
    "text": "Here we have a spectrum from the really good ones on the left to the really embarrassing ones on the right.",
    "start": "838495",
    "end": "843904"
  },
  {
    "text": "This middle one says a refrigerator filled with lots of food and drinks. It's actually a sign with some stickers on it.",
    "start": "843905",
    "end": "850345"
  },
  {
    "text": "A yellow school bus parked in a lot. It's close but really not like what the human understanding of those scenes is.",
    "start": "850345",
    "end": "857274"
  },
  {
    "text": "Lots of work to be done even in the narrowly subscribes of space of image captioning.",
    "start": "857275",
    "end": "862940"
  },
  {
    "text": "I mentioned before that I think Watson was a really breakthrough-technology moment for especially open domain question and answering.",
    "start": "862940",
    "end": "869950"
  },
  {
    "text": "But again, Watson did not understand what it was processing. Here's the funny interaction. You have to remember that Jeopardy reverses its questions and answers.",
    "start": "869950",
    "end": "878305"
  },
  {
    "text": "The answer came grasshoppers eat it, and Watson's reply was kosher,",
    "start": "878305",
    "end": "884149"
  },
  {
    "text": "which seems completely disjointed. It's not a guess that a human would make. But if you realize that Watson was primarily",
    "start": "884150",
    "end": "891940"
  },
  {
    "text": "trained on lots of Wikipedia entries and you look out grasshoppers on Wikipedia and you'll find",
    "start": "891940",
    "end": "897670"
  },
  {
    "text": "very rich discussions of whether modern-day grasshoppers are kosher. There is a human way in which we understand what Watson did but this also reveals how",
    "start": "897670",
    "end": "906845"
  },
  {
    "text": "superficial the processing techniques actually are and on how unhuman-like they actually are.",
    "start": "906845",
    "end": "913005"
  },
  {
    "text": "Summarizing, there you might say, I showed you that perspective from the book Superintelligence before you might",
    "start": "913005",
    "end": "919055"
  },
  {
    "start": "915000",
    "end": "915000"
  },
  {
    "text": "having seen behind the curtain, now balance that against the perspective from this very funny book called How to Survive a Robot Uprising.",
    "start": "919055",
    "end": "926015"
  },
  {
    "text": "This is by Daniel Wilson, who is a practitioner, a roboticist. This book is full of advice like if you're being pursued by a robot run up some stairs,",
    "start": "926015",
    "end": "935345"
  },
  {
    "text": "or be sure to wear clothing that you know will confuse its vision system,",
    "start": "935345",
    "end": "940490"
  },
  {
    "text": "a much more tempered perspective. Let's try to make that a little bit more precise in terms of things that we",
    "start": "940490",
    "end": "947730"
  },
  {
    "text": "could take action on in a course like natural-language understanding. That falls under the heading of adversarial testing.",
    "start": "947730",
    "end": "954579"
  },
  {
    "text": "Just to get it into our common ground, let me quickly review what standard evaluations are like.",
    "start": "954580",
    "end": "959825"
  },
  {
    "start": "955000",
    "end": "955000"
  },
  {
    "text": "In standard evaluations in NLU and actually throughout the field of artificial intelligence, we work like this: You create a dataset from some single process.",
    "start": "959825",
    "end": "968825"
  },
  {
    "text": "You could scrape some data from the web or crowdsource a new dataset or something like that, but the point is that it's homogenous.",
    "start": "968825",
    "end": "976180"
  },
  {
    "text": "In the next step, you divide the dataset into disjoint train and test sets and you set the test set aside,",
    "start": "976180",
    "end": "983345"
  },
  {
    "text": "it's under lock and key. You develop your system on the train set never once looking at the test set and only after all,",
    "start": "983345",
    "end": "991180"
  },
  {
    "text": "development is complete, you finally evaluate your train system on that held out test set.",
    "start": "991180",
    "end": "997410"
  },
  {
    "text": "The idea is that that will provide you an estimate of your system's capacity to generalize to new cases.",
    "start": "997410",
    "end": "1004320"
  },
  {
    "text": "Because after all, you held that test under lock and key, and only at the very end did you look at how",
    "start": "1004320",
    "end": "1010045"
  },
  {
    "text": "your system behaves with those entirely new examples. It sounds good, it has a lot going forth,",
    "start": "1010045",
    "end": "1016135"
  },
  {
    "text": "but I want to point out how generous this is to the systems that we're developing. Because in step 1 we had a single process,",
    "start": "1016135",
    "end": "1024510"
  },
  {
    "text": "it's too much to say that this is actually going to be an estimate of how the system will perform in the real world because after all,",
    "start": "1024510",
    "end": "1031259"
  },
  {
    "text": "the real world will throw at our system many more diverse experiences than we saw in step 1 and throughout this process.",
    "start": "1031260",
    "end": "1039525"
  },
  {
    "text": "Adversarial testing embraces that because in adversarial testing we make a slight tweak.",
    "start": "1039525",
    "end": "1045819"
  },
  {
    "start": "1045000",
    "end": "1045000"
  },
  {
    "text": "Start by creating a dataset by whatever means you like, it could be just as before. You develop and assess your system using that dataset again,",
    "start": "1045820",
    "end": "1054295"
  },
  {
    "text": "according to whatever protocols you choose. So this part could be standard. But here's the new bit,",
    "start": "1054295",
    "end": "1059500"
  },
  {
    "text": "you develop a new test dataset of examples that you suspect or know as a practitioner will be challenging given your system and the original dataset.",
    "start": "1059500",
    "end": "1069830"
  },
  {
    "text": "Then, of course, only after all, system development is complete, you evaluate systems on that new test set and you",
    "start": "1069830",
    "end": "1076285"
  },
  {
    "text": "report that number as an estimate of the system's capacity to generalize. A lot of this is familiar except for the introduction of",
    "start": "1076285",
    "end": "1083669"
  },
  {
    "text": "this new and potentially quite adversarial dataset in the middle here. This is simulating what we saw when we looked",
    "start": "1083670",
    "end": "1091559"
  },
  {
    "text": "behind the curtain where entirely new examples that the system developers didn't anticipate are causing",
    "start": "1091560",
    "end": "1097200"
  },
  {
    "text": "a lot of grief for our otherwise very good systems. Let's return to that NLI problem.",
    "start": "1097200",
    "end": "1104295"
  },
  {
    "start": "1104000",
    "end": "1104000"
  },
  {
    "text": "Let me show you what this is like in practice. Remember, this is that premise hypothesis prediction task with three labels.",
    "start": "1104295",
    "end": "1110455"
  },
  {
    "text": "In a lovely paper by Glockner et al, what they did is create a new adversarial dataset that's based on lexical substitutions.",
    "start": "1110455",
    "end": "1118920"
  },
  {
    "text": "I actually hesitate even to call this adversarial because I think this is just an interesting challenge thing that they did.",
    "start": "1118920",
    "end": "1125705"
  },
  {
    "text": "Here's how it worked. You have a fixed premise, here it's, \"A little girl kneeling in the dirt crying.\"",
    "start": "1125705",
    "end": "1131165"
  },
  {
    "text": "The original example had the hypothesis, \"A little girl is very sad,\" and that has the entailment relation.",
    "start": "1131165",
    "end": "1137830"
  },
  {
    "text": "What they did is just used WordNet, which is a structured lexical resource, to substitute here the word sad and have it become the word unhappy.",
    "start": "1137830",
    "end": "1147005"
  },
  {
    "text": "Those are roughly synonymous. So what we would expect is that systems will just continue to predict the entailment relation for this new adversarial example.",
    "start": "1147005",
    "end": "1156160"
  },
  {
    "text": "Everything else about the examples is the same, that's why I say this is actually a friendly adversarial here.",
    "start": "1156160",
    "end": "1162775"
  },
  {
    "text": "What they found in practice is that systems that are otherwise very good are apt to predict something like contradiction for the second case.",
    "start": "1162775",
    "end": "1171515"
  },
  {
    "text": "It's probably because they think that that negation in the word unhappy is a signal of contradiction.",
    "start": "1171515",
    "end": "1177184"
  },
  {
    "text": "So they make a mistake, and it's not a very human mistake. It's something very systematic about our understanding",
    "start": "1177185",
    "end": "1184280"
  },
  {
    "text": "of a language like English that we see that these two are synonymous, assuming we know what the words mean.",
    "start": "1184280",
    "end": "1189519"
  },
  {
    "text": "This example down here is similar where you have the fixed premise and all they've done is changed wine to champagne and that should cause a change from entailment to neutral.",
    "start": "1189520",
    "end": "1199405"
  },
  {
    "text": "But in fact, since the system has a very fuzzy understanding of how wine and champagne are related to each other,",
    "start": "1199405",
    "end": "1204705"
  },
  {
    "text": "it continues to predict entailment in that case. This is a picture of the dataset.",
    "start": "1204705",
    "end": "1210630"
  },
  {
    "text": "I think it's really cool because it's got a lot of examples especially for contradiction and entailment,",
    "start": "1210630",
    "end": "1215690"
  },
  {
    "text": "and it also has this nice breakdown by individual categories so you can get some real insights into what it's doing.",
    "start": "1215690",
    "end": "1222360"
  },
  {
    "text": "As predicted, this is quite devastating for these systems. I have a few models here that we're very good models at the time.",
    "start": "1222360",
    "end": "1230205"
  },
  {
    "text": "They have very good SNLI test accuracy, that's one of those benchmark tests I mentioned before,",
    "start": "1230205",
    "end": "1235800"
  },
  {
    "text": "and their accuracy on this new test set has plummeted by as much as 30 percentage points in absolute terms.",
    "start": "1235800",
    "end": "1243720"
  },
  {
    "text": "So this is really devastating. Now there is a ray of hope here.",
    "start": "1243720",
    "end": "1250365"
  },
  {
    "text": "I'm not going to go into this slide in detail, of course, because there's a lot of information here. I've put it here just to say that our course has",
    "start": "1250365",
    "end": "1257250"
  },
  {
    "text": "really great coverage of what are called transformer-based models; you might have heard about them like BERT, RoBERTa, ELECTRA, XLNet,",
    "start": "1257250",
    "end": "1264270"
  },
  {
    "text": "by the end of the course, you'll have a very deep understanding of all the technical details that you see here.",
    "start": "1264270",
    "end": "1269294"
  },
  {
    "text": "For now though, I would just want you to think, there has been a really interesting breakthrough in",
    "start": "1269295",
    "end": "1274560"
  },
  {
    "text": "the last two years related to how people use these transformer-based models,",
    "start": "1274560",
    "end": "1279570"
  },
  {
    "text": "and the way I can give you a glimpse of that, let's just highlight RoBERTa here. So what I've done on the next slide is just used some of the course code from",
    "start": "1279570",
    "end": "1287100"
  },
  {
    "start": "1286000",
    "end": "1286000"
  },
  {
    "text": "our course and a pre-trained model that's easy to access from using Facebook code.",
    "start": "1287100",
    "end": "1292995"
  },
  {
    "text": "So I read that model in and evaluated on that full of Glockner et all. dataset that I have just showed you,",
    "start": "1292995",
    "end": "1299400"
  },
  {
    "text": "and the result is amazing. These are the performance numbers here. The accuracy is at 0.97 and it's doing",
    "start": "1299400",
    "end": "1306570"
  },
  {
    "text": "extremely well for those two categories where you have enough examples or enough support. Remember, just two years ago,",
    "start": "1306570",
    "end": "1314070"
  },
  {
    "text": "the best system on this adversarial test wasn't even above 0.75 and now we're at 0.97 and doing well on both of these categories.",
    "start": "1314070",
    "end": "1323205"
  },
  {
    "text": "That's starting to look like yet again, some big leap forward of how well we can do.",
    "start": "1323205",
    "end": "1328260"
  },
  {
    "text": "It's very exciting. Now we can level up once more. So just quickly.",
    "start": "1328260",
    "end": "1334260"
  },
  {
    "start": "1332000",
    "end": "1332000"
  },
  {
    "text": "So far we've been using adversaries just for test sets, but we could actually have them be part of the entire lifecycle of a model,",
    "start": "1334260",
    "end": "1342075"
  },
  {
    "text": "and that's what these authors have done for the adversarial NLI dataset. This is a direct response to the kind of",
    "start": "1342075",
    "end": "1348210"
  },
  {
    "text": "adversarial test failings we just saw. Here's how this worked. The annotator is presented with a premise sentence and a condition,",
    "start": "1348210",
    "end": "1356130"
  },
  {
    "text": "so a label they need to produce; entailment, contradiction or neutral. The annotator writes a hypothesis,",
    "start": "1356130",
    "end": "1362970"
  },
  {
    "text": "and then a state-of-the-art model comes in and makes a prediction about this new premise hypothesis pair.",
    "start": "1362970",
    "end": "1369150"
  },
  {
    "text": "If the model's prediction matches the condition, that is, if the model was correct, the end annotator returns to step two and tries again.",
    "start": "1369150",
    "end": "1376905"
  },
  {
    "text": "You could continue that loop until the model is finally fooled and you have a premise hypothesis pair which you then validate with humans.",
    "start": "1376905",
    "end": "1384840"
  },
  {
    "text": "So what's happening here by definition is we're creating a dataset that is intuitive and natural for humans,",
    "start": "1384840",
    "end": "1390865"
  },
  {
    "text": "but by definition, very difficult for state-of-the-art models because they are now in the loop where people are being adversarial with them.",
    "start": "1390865",
    "end": "1399100"
  },
  {
    "text": "It is a familiar picture. This is the current state-of-the-art. So we have a few systems here that are outstanding on SNLI and MultiNLI.",
    "start": "1399100",
    "end": "1408300"
  },
  {
    "text": "All these numbers in the middle here are different views of the adversarial NLI dataset, and you could just see that they are dramatically",
    "start": "1408300",
    "end": "1415650"
  },
  {
    "text": "lower than those standard evaluations on the right. So another unsolved problem.",
    "start": "1415650",
    "end": "1420720"
  },
  {
    "text": "We saw a glimmer of progress, but I think now this is the new thing to be here, and in fact, we're going to hear a bit more about these kind of evaluations a bit later.",
    "start": "1420720",
    "end": "1429779"
  },
  {
    "text": "So finally, just by way of wrapping up, I don't want to take too much time, but I thought I could connect this really nicely with our coursework.",
    "start": "1429780",
    "end": "1437700"
  },
  {
    "text": "So here's the high level summary. We cover these topics on the left. It's by no means an exhaustive list of topics for the field,",
    "start": "1437700",
    "end": "1446640"
  },
  {
    "start": "1441000",
    "end": "1441000"
  },
  {
    "text": "but I think it's a good sample in the sense that it gives you a picture of a lot of different tasks,",
    "start": "1446640",
    "end": "1452175"
  },
  {
    "text": "structures, models, techniques, and metrics. So that if you're good at this sample of topics,",
    "start": "1452175",
    "end": "1458910"
  },
  {
    "text": "you're really empowered to take on anything that's happening in the field of NLU right now.",
    "start": "1458910",
    "end": "1464850"
  },
  {
    "text": "Part of the reason I feel confident saying that is that the course is very hands on. So we have four assignments,",
    "start": "1464850",
    "end": "1471150"
  },
  {
    "text": "each paired with a bake-off. I'm going to tell you about the bake-offs in a second. But each one of them is meant to be a kind of",
    "start": "1471150",
    "end": "1476940"
  },
  {
    "text": "simulation of a small original final project. That culminates or leads into the final projects,",
    "start": "1476940",
    "end": "1483090"
  },
  {
    "text": "which come in a sequence of things that help you incrementally build up from a literature review through in a protocol,",
    "start": "1483090",
    "end": "1490320"
  },
  {
    "text": "and then finally to a final paper so that with the help of a teaching team mentor,",
    "start": "1490320",
    "end": "1495779"
  },
  {
    "text": "slowly built to something that's an original contribution in the field. For those assignments and bake-offs,",
    "start": "1495780",
    "end": "1502440"
  },
  {
    "text": "let me just give you a glimpse of what the rhythm of those is like. So each assignment culminates in a bake-off,",
    "start": "1502440",
    "end": "1507855"
  },
  {
    "start": "1503000",
    "end": "1503000"
  },
  {
    "text": "which is an informal competition in which you enter an original model. This is like the kind of shared evaluation tasks that you see a lot throughout the field.",
    "start": "1507855",
    "end": "1516975"
  },
  {
    "text": "The assignments ask you to build up some baseline systems to inform your own model design",
    "start": "1516975",
    "end": "1522480"
  },
  {
    "text": "and to build that original model and then you enter that original model into the system.",
    "start": "1522480",
    "end": "1528000"
  },
  {
    "text": "We have held out test sets for you so that we really get to look at how good your systems are and the teams that win that get some extra credit.",
    "start": "1528000",
    "end": "1535860"
  },
  {
    "text": "It's also important that the teaching team assembles all of these entries and reflects insights from them back to the entire group,",
    "start": "1535860",
    "end": "1543765"
  },
  {
    "text": "so that we can kind of collectively learn what worked and what didn't for these problems. The rationale, of course,",
    "start": "1543765",
    "end": "1549690"
  },
  {
    "text": "behind all this is that each one of these should exemplify best practices for doing NLU and help make you an expert practitioner.",
    "start": "1549690",
    "end": "1558310"
  },
  {
    "text": "I want to connect back with those earlier themes and I think we have one bake-off that does that in a really exciting way,",
    "start": "1559010",
    "end": "1565230"
  },
  {
    "start": "1562000",
    "end": "1562000"
  },
  {
    "text": "and this is a kind of micro version of the NLI task; we do word level entailment,",
    "start": "1565230",
    "end": "1570444"
  },
  {
    "text": "where the training examples are pairs like turtle, animal, and the one means that they are in the entailment relation.",
    "start": "1570444",
    "end": "1576185"
  },
  {
    "text": "Turtle, desk is in the zero relation. So it's a small one word version of that full NLI problem.",
    "start": "1576185",
    "end": "1582315"
  },
  {
    "text": "The reason it connects with what I was just covering is that we try to make this a bit adversarial. So the train and test sets have disjoint vocabularies.",
    "start": "1582315",
    "end": "1591465"
  },
  {
    "text": "So for example, if you do see turtle in the train set, you won't find it anywhere in these pairs that are in the test set examples.",
    "start": "1591465",
    "end": "1598979"
  },
  {
    "text": "The idea is to really push systems to make sure that they are learning something that is actually generalizable information about the lexicon,",
    "start": "1598979",
    "end": "1607575"
  },
  {
    "text": "as opposed to just benefiting from idiosyncrasies kind of in the patterns of the dataset that happens to exist.",
    "start": "1607575",
    "end": "1613635"
  },
  {
    "text": "So in that way, I think we can push ourselves to develop systems that really have robust lexicon knowledge embedded in them,",
    "start": "1613635",
    "end": "1621780"
  },
  {
    "text": "and these test set evaluations give you a glimpse of how much of that you've actually achieved.",
    "start": "1621780",
    "end": "1627190"
  },
  {
    "text": "Just to kind of emphasize again how hands-on these all is. So this is a full system for that word level entailment problem.",
    "start": "1628280",
    "end": "1637260"
  },
  {
    "text": "We don't need to dive into the details of the code, I'll just say that you make essentially three decisions here.",
    "start": "1637260",
    "end": "1643365"
  },
  {
    "text": "Under GloVe, this is your choice of how to represent the individual words. In this case, I'm using GloVe pre-trained representations,",
    "start": "1643365",
    "end": "1651240"
  },
  {
    "text": "GloVe is a model we cover in some detail at the start of the course. But of course, you are free to make use of",
    "start": "1651240",
    "end": "1656910"
  },
  {
    "text": "any representations scheme you want for these words. You should also decide how to represent the pairs.",
    "start": "1656910",
    "end": "1662940"
  },
  {
    "text": "Here I've chosen to just concatenate the two representations, but lots of things are possible.",
    "start": "1662940",
    "end": "1667980"
  },
  {
    "text": "Then I'd say, finally, the most interesting and exciting part falls under this network here.",
    "start": "1667980",
    "end": "1673139"
  },
  {
    "text": "So this is a bit of PyTorch code. It's using code that we release this part of the course and you will make a lot of use of.",
    "start": "1673140",
    "end": "1680130"
  },
  {
    "text": "The reason that's important is that that pre-built code really frees you up to think creatively about the problem at hand,",
    "start": "1680130",
    "end": "1687720"
  },
  {
    "text": "and you can see that here, this is a complete working system in cell 4. Primarily what you do for this assignment",
    "start": "1687720",
    "end": "1694800"
  },
  {
    "text": "and bake-off is work on this build graph method, where you're essentially building the computation graph for a deep neural network model,",
    "start": "1694800",
    "end": "1702105"
  },
  {
    "text": "and then everything else about the optimization process is handled by the base classes,",
    "start": "1702105",
    "end": "1707130"
  },
  {
    "text": "which are already part of the course repository. That's important because it's hidden away under base keyword arcs here.",
    "start": "1707130",
    "end": "1713925"
  },
  {
    "text": "This model actually has lots of different settings that you can explore for different optimization choices",
    "start": "1713925",
    "end": "1720360"
  },
  {
    "text": "and other things so that you can really experience, in a hands-on way, how best to optimize these modern deep learning models that you're building.",
    "start": "1720360",
    "end": "1728740"
  },
  {
    "text": "I don't have time for it, but I did just want to mention this other bake-off. They're four and all, but this is a really different one from the previous ones.",
    "start": "1728930",
    "end": "1737070"
  },
  {
    "start": "1733000",
    "end": "1733000"
  },
  {
    "text": "If I had more time with you, I think the other thing that I would emphasize would be the importance of grounding",
    "start": "1737070",
    "end": "1743160"
  },
  {
    "text": "natural language outside of language and in actual physical scenes and stuff like that, and the way we kind of explore that in a tractable way is by doing",
    "start": "1743160",
    "end": "1752100"
  },
  {
    "text": "natural language generation where we're trying to describe color patches in context.",
    "start": "1752100",
    "end": "1757155"
  },
  {
    "text": "This is another modeling direction and it does bring in non-linguistic information in the form of these color patches.",
    "start": "1757155",
    "end": "1763815"
  },
  {
    "text": "I think it's a really interesting problem. It kind of connects with interesting topics in linguistics,",
    "start": "1763815",
    "end": "1768840"
  },
  {
    "text": "and it's a chance for you to explore another prominent class of models, which are these encoder-decoder models, which process sequences.",
    "start": "1768840",
    "end": "1777460"
  },
  {
    "text": "On the left, this is not a linguistic sequence, these are color patches, they could be images; and on the right,",
    "start": "1777460",
    "end": "1782899"
  },
  {
    "text": "of course, you're producing a natural language description. But in the interest of time,",
    "start": "1782900",
    "end": "1788720"
  },
  {
    "text": "I think I'll just go quickly to this wrap up. As I said before, I really believe this, this is the most exciting moment ever in history for doing NLU.",
    "start": "1788720",
    "end": "1796515"
  },
  {
    "start": "1791000",
    "end": "1791000"
  },
  {
    "text": "It's not like you're joining the field just at the moment when all of the hard tasks have been solved. I think rather, we now have a good foundation for",
    "start": "1796515",
    "end": "1804750"
  },
  {
    "text": "the really exciting breakthroughs which are in the future and I think the adversarial testing really makes that clear.",
    "start": "1804750",
    "end": "1810735"
  },
  {
    "text": "This course gives you hands-on experience with a wide range of challenging NLU problems,",
    "start": "1810735",
    "end": "1816150"
  },
  {
    "text": "and when you come to do your original research, you'll have a mentor from the teaching team to guide you through,",
    "start": "1816150",
    "end": "1821669"
  },
  {
    "text": "not only the project work, but also all those assignments and bake-offs and so forth. The examples of success there is that some of",
    "start": "1821670",
    "end": "1829170"
  },
  {
    "text": "these things have turned into really exciting and mature papers, some of them even published, and you're going to actually hear about some of that",
    "start": "1829170",
    "end": "1835640"
  },
  {
    "text": "really mature and interesting work in just a moment. So the central goal, of course, of all of this is to make you best,",
    "start": "1835640",
    "end": "1842520"
  },
  {
    "text": "that is most insightful and responsible NLU researcher and practitioner, whatever you decide to do next with all of this new material.",
    "start": "1842520",
    "end": "1851310"
  },
  {
    "text": "So I'll wrap up there. Thank you very much. Thank you Chris. This was extremely interesting.",
    "start": "1851310",
    "end": "1858480"
  },
  {
    "text": "Thank you. If you have any questions for Chris, feel free to post them in the Q&A box.",
    "start": "1858480",
    "end": "1865290"
  },
  {
    "text": "We will be moving on right now to allow enough time for students to present their projects.",
    "start": "1865290",
    "end": "1870660"
  },
  {
    "text": "If you're interested in learning more about the course Chris was mentioning or other courses SCPD is offering in the Artificial Intelligence program,",
    "start": "1870660",
    "end": "1881269"
  },
  {
    "text": "like Machine Learning or Deep Learning, you can check the links you will see on your platform.",
    "start": "1881270",
    "end": "1887215"
  },
  {
    "text": "But now we will move on. We will hear from two project teams that took the Natural Language Understanding course,",
    "start": "1887215",
    "end": "1894914"
  },
  {
    "text": "and developed great projects that they will now briefly present. The first speaker will be Gokhan Cagrici.",
    "start": "1894915",
    "end": "1902355"
  },
  {
    "text": "Gokhan, you can go ahead. Hi, everyone. My name is Gokhan Cagrici,",
    "start": "1902355",
    "end": "1910600"
  },
  {
    "text": "and my presentation is about \"The Effect of Ensembling on ANLI Benchmark.\"",
    "start": "1910600",
    "end": "1918160"
  },
  {
    "text": "Our focus keyword is basically adversarial.",
    "start": "1919250",
    "end": "1924730"
  },
  {
    "text": "As you probably know, there are the leaderboards and",
    "start": "1924920",
    "end": "1930059"
  },
  {
    "text": "these leaderboards are created for some challenging problems, but each one of these are basically using a frozen corpus.",
    "start": "1930060",
    "end": "1941559"
  },
  {
    "text": "Then the practitioners and their researchers who are trying to build the best corpus,",
    "start": "1941560",
    "end": "1948065"
  },
  {
    "text": "and this is how the life cycle goes. But you might imagine that it might not necessarily mean that you are",
    "start": "1948065",
    "end": "1957780"
  },
  {
    "text": "getting the best model that can generalize into new areas.",
    "start": "1957780",
    "end": "1963675"
  },
  {
    "text": "Because of the incapability of generalizing the idea so that these models",
    "start": "1963675",
    "end": "1970500"
  },
  {
    "text": "can take some shortcuts running a fixed training and test set.",
    "start": "1970500",
    "end": "1978090"
  },
  {
    "text": "Here is one of the latest papers about incorporating this adversarial idea.",
    "start": "1978090",
    "end": "1987159"
  },
  {
    "text": "Basically, as Professor Potts mentioned,",
    "start": "1988670",
    "end": "1994800"
  },
  {
    "text": "it is using different ranks. So there is rank 1, which is basically creating this training set and test set.",
    "start": "1994800",
    "end": "2003679"
  },
  {
    "text": "It releases state of the art model and based on the weaknesses of that model, then a new training and test set is being created taking",
    "start": "2003680",
    "end": "2013400"
  },
  {
    "text": "those weaknesses into account and this moves on,",
    "start": "2013400",
    "end": "2018725"
  },
  {
    "text": "so we have to challenge the model capability and increasing the generalization capability.",
    "start": "2018725",
    "end": "2026855"
  },
  {
    "text": "Before we move on with the next slide, I would like to mention something. The question is - Is it even easy for humans,",
    "start": "2026855",
    "end": "2033544"
  },
  {
    "text": "for an NLI test? As you see, there are really simple tests single sentence texts,",
    "start": "2033545",
    "end": "2041059"
  },
  {
    "text": "and really simple hypotheses based on these premises and these judgments are being made by humans.",
    "start": "2041060",
    "end": "2049564"
  },
  {
    "text": "You'll see that, for example, the second example and the last example, even humans cannot agree with the correct label.",
    "start": "2049564",
    "end": "2057395"
  },
  {
    "text": "If this is the case for humans, then how are you going to approach this problem with the machines themselves?",
    "start": "2057395",
    "end": "2066810"
  },
  {
    "text": "Well, as we said, we will challenge a model with progressively harder tasks.",
    "start": "2067300",
    "end": "2074855"
  },
  {
    "text": "In my project, I took the data sets from the paper that I mentioned and I applied several transformer-based settled out models.",
    "start": "2074855",
    "end": "2086645"
  },
  {
    "text": "Actually, you'll see three different models like BERT, RoBERTa, and XLNet.",
    "start": "2086645",
    "end": "2093020"
  },
  {
    "text": "There are two variants, one is a base one, one is a large one. For the outputs from Y1-Y6,",
    "start": "2093020",
    "end": "2101089"
  },
  {
    "text": "you'll see the outputs per model and for Y7, there's a strategy for ensembling",
    "start": "2101090",
    "end": "2109370"
  },
  {
    "text": "these models and to see if ensembling is going to make a cure for us.",
    "start": "2109370",
    "end": "2114690"
  },
  {
    "text": "On the right, I wanted to give you a feeling about the data set.",
    "start": "2114790",
    "end": "2125390"
  },
  {
    "text": "You'll see that this data set contains very complex and long sentences and there are a lot of",
    "start": "2125390",
    "end": "2131839"
  },
  {
    "text": "named entities, other relationships, references. For the top three best-performing models, for example,",
    "start": "2131840",
    "end": "2141020"
  },
  {
    "text": "for these two examples, none of them could come up with the right answers.",
    "start": "2141020",
    "end": "2147120"
  },
  {
    "text": "Again, we see that the task is very hard.",
    "start": "2148570",
    "end": "2153480"
  },
  {
    "text": "For the question that I mentioned, let's see if ensembling is the cure here.",
    "start": "2153760",
    "end": "2160619"
  },
  {
    "text": "Well, these are the results for the models in isolation.",
    "start": "2163660",
    "end": "2169025"
  },
  {
    "text": "We can look at just the F1 score because it is one of the scores being used by the communicator for these problems.",
    "start": "2169025",
    "end": "2178180"
  },
  {
    "text": "Even though 90-plus for some F1 scores have been achieved for SNLI and their variants,",
    "start": "2178180",
    "end": "2188290"
  },
  {
    "text": "here we see that we couldn't even achieve 50 percent F1 scores.",
    "start": "2188290",
    "end": "2193355"
  },
  {
    "text": "Whenever we applied ensembling, yes, there is some new format.",
    "start": "2193355",
    "end": "2198994"
  },
  {
    "text": "We could barely see 51 for some for the F1 score, but again, it is far from a reasonable success.",
    "start": "2198995",
    "end": "2209990"
  },
  {
    "text": "So here we see that just ensembling",
    "start": "2209990",
    "end": "2215045"
  },
  {
    "text": "different models is not going to help for something that is so hard for the models in isolation.",
    "start": "2215045",
    "end": "2222830"
  },
  {
    "text": "People are using ensembling mostly in drawing something that",
    "start": "2222830",
    "end": "2227900"
  },
  {
    "text": "is already influenced by the individual models.",
    "start": "2227900",
    "end": "2233345"
  },
  {
    "text": "Then the next reasonable question to ask is, why are we still far away from a very nice solution?",
    "start": "2233345",
    "end": "2243125"
  },
  {
    "text": "Here's a list. Model architecture can be an issue,",
    "start": "2243125",
    "end": "2248630"
  },
  {
    "text": "but personally, I don't think it is one of the most critical ones. The size of the training data is as important",
    "start": "2248630",
    "end": "2256700"
  },
  {
    "text": "as anything in other areas as well.",
    "start": "2256700",
    "end": "2265025"
  },
  {
    "text": "If you have a high quality in terms of the training data and test data,",
    "start": "2265025",
    "end": "2270770"
  },
  {
    "text": "then you have a much better chance of creating a satisfactory model.",
    "start": "2270770",
    "end": "2276845"
  },
  {
    "text": "But here, even creating a training data is really expensive because, as we said,",
    "start": "2276845",
    "end": "2283625"
  },
  {
    "text": "even humans are having trouble for agreeing with our tutorial and hypotheses and the premise itself.",
    "start": "2283625",
    "end": "2292835"
  },
  {
    "text": "So it means a little effort, time, and money. But yes, it is very important.",
    "start": "2292835",
    "end": "2299465"
  },
  {
    "text": "But the last one is really interesting. If you think of a child,",
    "start": "2299465",
    "end": "2304530"
  },
  {
    "text": "that child's interaction with the environment is playing a very important role,",
    "start": "2304780",
    "end": "2311195"
  },
  {
    "text": "as well as reading some texts from some books, and trying to analyze it.",
    "start": "2311195",
    "end": "2316415"
  },
  {
    "text": "The child is basically experimenting with the external world all the time and then creating new hypothesis and testing it,",
    "start": "2316415",
    "end": "2325444"
  },
  {
    "text": "creating another hypothesis and testing it again. So machines are lacking this ability.",
    "start": "2325445",
    "end": "2331265"
  },
  {
    "text": "Maybe we are trying something that cannot be learned without these machines living around us.",
    "start": "2331265",
    "end": "2341704"
  },
  {
    "text": "Having said that, I would like to conclude with my experience in terms of the project and the class.",
    "start": "2341705",
    "end": "2348380"
  },
  {
    "text": "Yes, it is very demanding, but something should be really demanding for it to give you better insight into the topic.",
    "start": "2348380",
    "end": "2356645"
  },
  {
    "text": "It should challenge you so that you will feel the need to learn more.",
    "start": "2356645",
    "end": "2361650"
  },
  {
    "text": "This is mentioned in the rewarding part. You gain a discipline of analyzing papers, researching,",
    "start": "2363040",
    "end": "2370369"
  },
  {
    "text": "and comparing the results and then trying to repeat those results or even go beyond those results.",
    "start": "2370370",
    "end": "2377780"
  },
  {
    "text": "Last but not least, the guiding parts.",
    "start": "2377780",
    "end": "2382590"
  },
  {
    "text": "It doesn't matter what kind of questions you are having, but there is a very strong community from Stanford helping you.",
    "start": "2382840",
    "end": "2394750"
  },
  {
    "text": "I didn't even see any question that was not answered by those expert people including Professor Potts.",
    "start": "2394750",
    "end": "2404990"
  },
  {
    "text": "I'm really happy to be here and thanks for your time and see you soon",
    "start": "2405540",
    "end": "2414255"
  },
  {
    "text": "Thank you, Gokhan. Thank you for your time and presenting your project to everybody.",
    "start": "2414255",
    "end": "2420904"
  },
  {
    "text": "Now we can move on to the other project that was developed by Mohan Rangarajan,",
    "start": "2420905",
    "end": "2426950"
  },
  {
    "text": "Vu Pham, and Ethan Nguyen. So Mohan will now let you know a little bit more about it.",
    "start": "2426950",
    "end": "2434550"
  },
  {
    "text": "Thank you, Petra. Hi, everyone. This is Mohan. It's a privilege to be presenting here on behalf of my team,",
    "start": "2434550",
    "end": "2442825"
  },
  {
    "text": "Ethan Nguyen and Vu Pham. We're certainly looking forward to this.",
    "start": "2442825",
    "end": "2449295"
  },
  {
    "text": "This quote by Mahatma Gandhi actually captures the essence of how we approach both the course and the project.",
    "start": "2449295",
    "end": "2458130"
  },
  {
    "text": "We had a learning mindset and we said we are going to learn at whatever be the cost.",
    "start": "2458130",
    "end": "2465819"
  },
  {
    "text": "When we actually approached the project work, we wanted to do something in",
    "start": "2465820",
    "end": "2471820"
  },
  {
    "start": "2468000",
    "end": "2468000"
  },
  {
    "text": "question answering obviously and with using knowledge graphs.",
    "start": "2471820",
    "end": "2476570"
  },
  {
    "text": "Like many people and like Professor Potts mentioned earlier, we were enamored with BERT transformers and",
    "start": "2476860",
    "end": "2484520"
  },
  {
    "text": "the BERT variants and the whole notion of contextual embedding. We were curious to see how contextual embedding would improve accuracy.",
    "start": "2484520",
    "end": "2493474"
  },
  {
    "text": "So our hypothesis was really about using knowledge graph and seeing if contextual embedding would improve the accuracy.",
    "start": "2493475",
    "end": "2502485"
  },
  {
    "text": "You may ask, \"Hey, how did you come from this broad topic to a specific focused hypotheses?\"",
    "start": "2502485",
    "end": "2510339"
  },
  {
    "text": "Here we have to really talk about the structured approach that Professor Potts mentioned.",
    "start": "2510340",
    "end": "2517075"
  },
  {
    "text": "Doing the literature review and then the experimental protocol, and then going on to the project.",
    "start": "2517075",
    "end": "2522569"
  },
  {
    "text": "This really helped us narrow down to a specific focus topic on the hypothesis.",
    "start": "2522570",
    "end": "2529080"
  },
  {
    "text": "On the left-hand side, what you see here really is the broad area that you are wanting to initially look at.",
    "start": "2532570",
    "end": "2539644"
  },
  {
    "start": "2535000",
    "end": "2535000"
  },
  {
    "text": "Then one thing that we talked about as we did the literature review,",
    "start": "2539645",
    "end": "2546515"
  },
  {
    "text": "we realized that, you know what? We have to narrow down our focus. Then we start guidance from our course facilitator based on",
    "start": "2546515",
    "end": "2555529"
  },
  {
    "text": "that direction and also looking at how much computing resources we have and the time available.",
    "start": "2555530",
    "end": "2561215"
  },
  {
    "text": "We narrow down to the natural language backend portion of this topic. Even within that, we chose the simple questions data set and for the knowledge graph,",
    "start": "2561215",
    "end": "2571940"
  },
  {
    "text": "we chose embedded approach to represent the knowledge graph which is based on freebase.",
    "start": "2571940",
    "end": "2577175"
  },
  {
    "text": "I would be remiss if I don't point out here that we had complete freedom in choosing the topic, choosing our hypothesis.",
    "start": "2577175",
    "end": "2586055"
  },
  {
    "text": "The outcome really was not a concern because",
    "start": "2586055",
    "end": "2591170"
  },
  {
    "text": "the evaluation was going to be on the methodology and the rigor that we are going to have.",
    "start": "2591170",
    "end": "2597575"
  },
  {
    "text": "So that freed us from the pressure that comes with, our hypothesis should actually improve the results to focusing more on",
    "start": "2597575",
    "end": "2605119"
  },
  {
    "text": "the methodology and the concurrence and the results there.",
    "start": "2605120",
    "end": "2610170"
  },
  {
    "text": "Here's our experiment. We had three fundamental tasks in the project. One was the entity learning,",
    "start": "2610780",
    "end": "2617194"
  },
  {
    "start": "2613000",
    "end": "2613000"
  },
  {
    "text": "the other one was predicate, and the third one was entity detection. The entity learning and predicate learning models were",
    "start": "2617195",
    "end": "2623420"
  },
  {
    "text": "primarily used for predicting the entity and the predicate in the simple question. The entity detection model was useful for",
    "start": "2623420",
    "end": "2631595"
  },
  {
    "text": "collecting a set of tokens that would represent entity names. For the knowledge graph,",
    "start": "2631595",
    "end": "2637790"
  },
  {
    "text": "we use freebase and we use the embedded representation that was needed for the entity and the predicate.",
    "start": "2637790",
    "end": "2645320"
  },
  {
    "text": "The idea here really is we present the tokens in the entity detection to",
    "start": "2645320",
    "end": "2653030"
  },
  {
    "text": "the knowledge graph and we retrieve a set of candidate facts and then detailed entity associated with the facts would yield our possible answer.",
    "start": "2653030",
    "end": "2662750"
  },
  {
    "text": "The closest facts, we were using embedding. The fact that was closest to the embedding representation of the entity",
    "start": "2662750",
    "end": "2670130"
  },
  {
    "text": "and the predicate would result in the answer for the question. That was in an essence what our model was and what our experiment was about.",
    "start": "2670130",
    "end": "2680975"
  },
  {
    "text": "Here's a little bit of detail on the model itself. The entity and predicate learning models were very",
    "start": "2680975",
    "end": "2686660"
  },
  {
    "text": "similar but the entity detection model was slightly different in the sense that each token had to be",
    "start": "2686660",
    "end": "2692960"
  },
  {
    "text": "assessed as to whether it would be a potential entity name or not.",
    "start": "2692960",
    "end": "2697170"
  },
  {
    "text": "Looking at the results and analysis, we should say that we were quite pleased that there was marginal improvement in",
    "start": "2698800",
    "end": "2709445"
  },
  {
    "start": "2701000",
    "end": "2701000"
  },
  {
    "text": "the model that we were using as compared to the baseline model.",
    "start": "2709445",
    "end": "2715820"
  },
  {
    "text": "But I use the word marginal because as you can see, it was an improvement.",
    "start": "2715820",
    "end": "2721144"
  },
  {
    "text": "Since we were using knowledge graphs, we were also wanting to compare the results if we then use an embedded representation of",
    "start": "2721145",
    "end": "2728330"
  },
  {
    "text": "the knowledge graph and it was interesting to note that from the results,",
    "start": "2728330",
    "end": "2734735"
  },
  {
    "text": "then for the individual tasks, that is entity learning and predicate learning and entity detection,",
    "start": "2734735",
    "end": "2740194"
  },
  {
    "text": "the scores for using the knowledge graph directly without using embedding was better.",
    "start": "2740195",
    "end": "2747870"
  },
  {
    "text": "But the interesting part is when we were actually doing the evaluation on the test set,",
    "start": "2748570",
    "end": "2754190"
  },
  {
    "text": "we noticed that the embedding based approach had better results compared to the approach without embedding and of course,",
    "start": "2754190",
    "end": "2763295"
  },
  {
    "text": "the marginal improvement in accuracy was higher compared to the baseline models that we were using.",
    "start": "2763295",
    "end": "2771420"
  },
  {
    "text": "The interesting part really here is while we were pleased with the marginal improvement,",
    "start": "2771460",
    "end": "2778190"
  },
  {
    "text": "we also noticed that the execution time associated with our models was much slower.",
    "start": "2778190",
    "end": "2785510"
  },
  {
    "text": "Our fastest radiant was twice as slow as the original model that was in the baseline.",
    "start": "2785510",
    "end": "2792320"
  },
  {
    "text": "So the interesting part here is we were then puzzled as to did contextual embedding really help in this problem or no?",
    "start": "2792320",
    "end": "2803750"
  },
  {
    "text": "The other part here is we concluded then that the training duration is slow.",
    "start": "2803750",
    "end": "2811460"
  },
  {
    "start": "2807000",
    "end": "2807000"
  },
  {
    "text": "The improvement in accuracy were marginal, so we felt it was less compelling to use of fine tuned",
    "start": "2811460",
    "end": "2818180"
  },
  {
    "text": "BERT model for simple question answering applications in the real world. A big generalization to make but that was our conclusion",
    "start": "2818180",
    "end": "2824960"
  },
  {
    "text": "based on the simple questions data set. The other part also note here is we chose to measure of",
    "start": "2824960",
    "end": "2831950"
  },
  {
    "text": "accuracy because it was a simple question-answering solution, either the answer is correct or incorrect.",
    "start": "2831950",
    "end": "2840150"
  },
  {
    "text": "What did we learned from this exercise? I think it's important to understand the data set that you're using for your testing.",
    "start": "2840480",
    "end": "2849285"
  },
  {
    "start": "2844000",
    "end": "2844000"
  },
  {
    "text": "When we actually started the project with our hypothesis, we felt that we are going to actually have",
    "start": "2849285",
    "end": "2857450"
  },
  {
    "text": "at least 90 percent accuracy considering all the wonderful things and the BERT variants I have done actually.",
    "start": "2857450",
    "end": "2864724"
  },
  {
    "text": "Then we realized we were a bit deflated with our questions. We're not performing as well and we did",
    "start": "2864725",
    "end": "2871940"
  },
  {
    "text": "a little bit more research only to realize that there is a cap of 83.4 percent accuracy as far as using simple questions data set is concerned.",
    "start": "2871940",
    "end": "2882665"
  },
  {
    "text": "This is because there's a high prevalence of unanswerable questions and some questions don't have any ground rules in the knowledge graph.",
    "start": "2882665",
    "end": "2890390"
  },
  {
    "text": "The other part as well is apart from other things, we have now a deep appreciation for the level of effort required to hypothesize,",
    "start": "2890390",
    "end": "2900650"
  },
  {
    "text": "research, experiment, and author a paper that conforms to ACL standards.",
    "start": "2900650",
    "end": "2906689"
  },
  {
    "text": "I'd like to quote Isaac Newton here by saying, \"If I have seen further, it is by standing on the shoulders of Giants. \"",
    "start": "2907570",
    "end": "2914465"
  },
  {
    "text": "We really have a lot of people that we should thank for, Xiao Huang and the team whose works served as a launching pad for our work here.",
    "start": "2914465",
    "end": "2922220"
  },
  {
    "start": "2919000",
    "end": "2919000"
  },
  {
    "text": "Salman Mohammed and the team whose work we use as a baseline for comparing our model.",
    "start": "2922220",
    "end": "2927635"
  },
  {
    "text": "The Hugging Face company, whose transformer based models allowed us to compare different variants.",
    "start": "2927635",
    "end": "2933035"
  },
  {
    "text": "Professor Potts, thank you so much. We learned a ton of new things in this course.",
    "start": "2933035",
    "end": "2939125"
  },
  {
    "text": "Your active participation in the Slack Channel and your enthusiasm was a welcome and pleasant surprise.",
    "start": "2939125",
    "end": "2947435"
  },
  {
    "text": "Of course facilitator, Prabhdeep Cheema and other course facilitators that helped us. They're always there to help and encourage us with our work.",
    "start": "2947435",
    "end": "2955820"
  },
  {
    "text": "Lastly, Steve, it'll be remiss if we don't mention you for helping us throughout the course. Thank you so much.",
    "start": "2955820",
    "end": "2963420"
  },
  {
    "text": "Thank you Mohan. Thank you for presenting the project, I think it's very exciting.",
    "start": "2963580",
    "end": "2969215"
  },
  {
    "text": "Thank you for joining us also Ethan and Vu who are here with us but not visible at this moment, but they are here.",
    "start": "2969215",
    "end": "2976130"
  },
  {
    "text": "I think we can move on to Q&A session. We got some interesting questions from the audience,",
    "start": "2976130",
    "end": "2983030"
  },
  {
    "text": "so thank you everybody also for your questions. I will now ask Chris the first question.",
    "start": "2983030",
    "end": "2989945"
  },
  {
    "text": "Are the adversarial examples generated by the humans exclusively, or by computational models such as Generative Adversarial Network, GAN.",
    "start": "2989945",
    "end": "3000310"
  },
  {
    "text": " That's a great question. You really see a full spectrum of approaches.",
    "start": "3000310",
    "end": "3006655"
  },
  {
    "text": "In some cases, humans have just written new adversarial cases as you saw with Gokhan's project with the adversarial NLI data set.",
    "start": "3006655",
    "end": "3013960"
  },
  {
    "text": "Sometimes we can do quasi automatic stuff with WordNet, where we just do some lexical substitutions,",
    "start": "3013960",
    "end": "3020830"
  },
  {
    "text": "and we can assume that the meaning that we want is preserved or changed in a systematic way.",
    "start": "3020830",
    "end": "3026529"
  },
  {
    "text": "But you can also have models in the loop acting as adversaries. There have been some applications of Generative Adversarial Networks in",
    "start": "3026530",
    "end": "3033850"
  },
  {
    "text": "NLU to make sure these models are robust. The picture seems more mixed than you get from vision,",
    "start": "3033850",
    "end": "3040330"
  },
  {
    "text": "where I know GANs have really been a powerful force for good in making models more robust.",
    "start": "3040330",
    "end": "3045505"
  },
  {
    "text": "I think there's some space for innovation there. But the general picture would be, I think we can think really flexibly,",
    "start": "3045505",
    "end": "3051850"
  },
  {
    "text": "and creatively, about how to create those adversarial tests, and then just creating one could have it's own",
    "start": "3051850",
    "end": "3057940"
  },
  {
    "text": "modeling interests in addition to that serving as a new way to evaluate models,",
    "start": "3057940",
    "end": "3064525"
  },
  {
    "text": "so lots of space for innovation there. I hope it answered the question.",
    "start": "3064525",
    "end": "3072369"
  },
  {
    "text": "The next question is about ELECTRA-based transformer.",
    "start": "3072370",
    "end": "3077980"
  },
  {
    "text": "Is ELECTRA-based transformer more robust to adversarial examples compared to MLM-based transformer such as BERT?",
    "start": "3077980",
    "end": "3086619"
  },
  {
    "text": "Interesting, open question. ELECTRA's primary motivation, is to make more efficient use of its data than BERT does.",
    "start": "3086620",
    "end": "3096099"
  },
  {
    "text": "We have a nice little lecture on ELECTRA and how it works and why it's successful.",
    "start": "3096100",
    "end": "3101800"
  },
  {
    "text": "But in the paper if I remember correctly, there isn't an evaluation that you would call adversarial,",
    "start": "3101800",
    "end": "3107815"
  },
  {
    "text": "they mostly just cost better numbers on the standard data sets and explore a really wide range of variations on the ELECTRA model,",
    "start": "3107815",
    "end": "3115795"
  },
  {
    "text": "looks how it entails with data and how it's structured. But again, I love that question.",
    "start": "3115795",
    "end": "3121120"
  },
  {
    "text": "It's just so interesting to ask for a model that seems to be a step forward here, not only in terms of accuracy,",
    "start": "3121120",
    "end": "3126820"
  },
  {
    "text": "but also in terms of efficient use of data and compute resources. What it is doing on these very human,",
    "start": "3126820",
    "end": "3133075"
  },
  {
    "text": "but ultimately very challenging adversarial data sets. Great question to address.",
    "start": "3133075",
    "end": "3138115"
  },
  {
    "text": "It's especially fruitful if you can address that question and then maybe think about how the answer could inform an improvement to a model like ELECTRA.",
    "start": "3138115",
    "end": "3147115"
  },
  {
    "text": "Because then you have that full cycle of adversary helping us do innovative things with some models we're building.",
    "start": "3147115",
    "end": "3154430"
  },
  {
    "text": "The next question: It seems that there is no adversarial training in this paradigm,",
    "start": "3156960",
    "end": "3163060"
  },
  {
    "text": "but only adversarial testing. Would adversarial training fit into this paradigm for NLU or how would it work?",
    "start": "3163060",
    "end": "3171085"
  },
  {
    "text": "For sure. Actually adversarial NLI of the data set that Gokhan talked about that is large enough that",
    "start": "3171085",
    "end": "3178450"
  },
  {
    "text": "you can use it for training in addition to assessment. There are a few other data sets that are like that.",
    "start": "3178450",
    "end": "3184780"
  },
  {
    "text": "Very few of them were created with the full human in the loop stocks that you saw with adversarial NLI.",
    "start": "3184780",
    "end": "3193464"
  },
  {
    "text": "Some of them have more automatic, model-based means of creating the data sets that are large enough for training.",
    "start": "3193465",
    "end": "3199375"
  },
  {
    "text": "But that's on the horizon and in fact, one of the visionary statements that the adversarial NLI paper makes is that we should move into a mode of",
    "start": "3199375",
    "end": "3208450"
  },
  {
    "text": "continually retraining and evaluating our models on data sets that were created adversarially and that ongoing process,",
    "start": "3208450",
    "end": "3218125"
  },
  {
    "text": "which is a more fundamental change to how we do system development. It's a way to lead to even more robust systems.",
    "start": "3218125",
    "end": "3226780"
  },
  {
    "text": "My quick answer would be, we should be looking for ways to scale the adversarial testing paradigm so that we can have training sets as well.",
    "start": "3226780",
    "end": "3236859"
  },
  {
    "text": "What is the current state of research in applications of deep RL to NLU a part of the transformers?",
    "start": "3239040",
    "end": "3246595"
  },
  {
    "text": "If there is research in it, how promising is it for you? Or how promising do you find it?",
    "start": "3246595",
    "end": "3253610"
  },
  {
    "text": "Interesting question, in overall,",
    "start": "3254390",
    "end": "3260079"
  },
  {
    "text": "I would say, division of reinforcement learning really resonates with me. If you think about your life as an agent in the world,",
    "start": "3260080",
    "end": "3267640"
  },
  {
    "text": "trying to learn things and experience the environment, you don't get the rightful rewards signals,",
    "start": "3267640",
    "end": "3273069"
  },
  {
    "text": "you only get very indirect feedback and you have credit assignment problem, so you don't know how to update your own parameters and so forth.",
    "start": "3273070",
    "end": "3280645"
  },
  {
    "text": "You have to make a lot of guesses and it's a chaotic process. But nonetheless, that's the world we live in and we all learn effectively.",
    "start": "3280645",
    "end": "3287485"
  },
  {
    "text": "Something like that set of techniques has to be brought more fully into the field. I think we're seeing really exciting stuff in the area of combining deep RL with",
    "start": "3287485",
    "end": "3298075"
  },
  {
    "text": "Grounded language understanding and certainly with dialogue and I'm sure there are other areas so it's a great space to explore.",
    "start": "3298075",
    "end": "3305200"
  },
  {
    "text": "The models tend to be hard to optimize and hard to understand. But that's part of the journey toward",
    "start": "3305200",
    "end": "3312579"
  },
  {
    "text": "making them really effective for the problems we look at. I'll give a quick plug. I did some stuff that was really exciting that tried to use",
    "start": "3312580",
    "end": "3320065"
  },
  {
    "text": "reinforcement learning together with transformer like models to induce more modularity,",
    "start": "3320065",
    "end": "3326170"
  },
  {
    "text": "so the systems that we develop, instead of having very diffuse solutions, would do things that looked more like encompassing",
    "start": "3326170",
    "end": "3333955"
  },
  {
    "text": "lexical capabilities and specific functionality, and those are called the recursive routing networks.",
    "start": "3333955",
    "end": "3339910"
  },
  {
    "text": "Hard to tune, but obviously an inspiring idea and we should just keep pushing those techniques.",
    "start": "3339910",
    "end": "3349010"
  },
  {
    "text": "Maybe one very general question, where do you see the future of NLU?",
    "start": "3349830",
    "end": "3355434"
  },
  {
    "text": "How will it look like in the next five years. Five years, it's starting to seem like a long time.",
    "start": "3355435",
    "end": "3362995"
  },
  {
    "text": "After all my short lecture showed you that in just a two-year span, we had what looked like a real phase change on some hard problems,",
    "start": "3362995",
    "end": "3370495"
  },
  {
    "text": "so five years feels like an eternity of system predictions I can make.",
    "start": "3370495",
    "end": "3375700"
  },
  {
    "text": "The idea behind contextual word representations, which is primarily how transformer-based architectures are used,",
    "start": "3375700",
    "end": "3382195"
  },
  {
    "text": "that's powerful and that's going to last. It really has changed things and I think division there is that",
    "start": "3382195",
    "end": "3387355"
  },
  {
    "text": "like more chances to have contextual understanding, more chances to be embedded in a context that's going to be important.",
    "start": "3387355",
    "end": "3395020"
  },
  {
    "text": "Grounded language problems are going to be more prominent and I think that's going to lead to breakthroughs because after all,",
    "start": "3395020",
    "end": "3400720"
  },
  {
    "text": "human learners don't learn just from text, that's an absurd idea, human learners learn from the social environment.",
    "start": "3400720",
    "end": "3408129"
  },
  {
    "text": "Lots of inputs that they get in addition to language inputs. To the extent that our systems can be multimodal like that,",
    "start": "3408129",
    "end": "3414970"
  },
  {
    "text": "they're probably going to get better. I hope there is a personal thing that we,",
    "start": "3414970",
    "end": "3420340"
  },
  {
    "text": "as a field do more to break free of the confines of always looking at English. I saw briefly in the Q&A,",
    "start": "3420340",
    "end": "3426640"
  },
  {
    "text": "there was a question about whether or not the field just looks at English. Data sets tend to be in English,",
    "start": "3426640",
    "end": "3433090"
  },
  {
    "text": "but I think that's changing a little bit. For example, in the NLI problem, we now have some good multilingual data sets.",
    "start": "3433090",
    "end": "3440244"
  },
  {
    "text": "That's important because English is not representative of the world's languages. If we look more further there are fields that might lead us",
    "start": "3440245",
    "end": "3448359"
  },
  {
    "text": "to new kinds of models that would count as fundamental breakthroughs. That's going to be important in that we should all be thinking much more.",
    "start": "3448360",
    "end": "3455484"
  },
  {
    "text": "Now that our systems are more useful, and more often deployed, we should be thinking more holistically like not",
    "start": "3455485",
    "end": "3462700"
  },
  {
    "text": "just that my system did well in some narrow evaluation, but what is it actually doing out there in the world when it interacts with",
    "start": "3462700",
    "end": "3469480"
  },
  {
    "text": "real examples and real users and where the fundamental things should be, we should be assessing,",
    "start": "3469480",
    "end": "3475839"
  },
  {
    "text": "making sure that those systems are having a positive impact as opposed to causing some social process to go awry or something like that.",
    "start": "3475840",
    "end": "3483595"
  },
  {
    "text": "That's a new responsibility we have that's coming from the recent successes.",
    "start": "3483595",
    "end": "3489130"
  },
  {
    "text": "A welcome challenge but an important one. Thank you. We are actually at the time, almost,",
    "start": "3489130",
    "end": "3497305"
  },
  {
    "text": "so I would like to spend the last minute thanking you for your time to take part in this webinar.",
    "start": "3497305",
    "end": "3503755"
  },
  {
    "text": "Also both or all of them, Gokhan, also Ethan, also Mohan,",
    "start": "3503755",
    "end": "3509380"
  },
  {
    "text": "also Vu who joined us today, I think it was really interesting, exciting that they joined us and they talked about the projects,",
    "start": "3509380",
    "end": "3516220"
  },
  {
    "text": "so they brought it in actual life, the course materials. Thank you all for joining us.",
    "start": "3516220",
    "end": "3522820"
  },
  {
    "text": "I hope you participants enjoyed it, and if you're interested in learning more about",
    "start": "3522820",
    "end": "3529270"
  },
  {
    "text": "the course is in a professional certificate. Feel free to check the links we are offering in the interface,",
    "start": "3529270",
    "end": "3539770"
  },
  {
    "text": "or please feel free to contact us also directly. Thank you everybody and stay safe and healthy.",
    "start": "3539770",
    "end": "3547120"
  },
  {
    "text": ">> Thanks, Petra. Thanks to the project teams. Those presentations were really great. I found that really inspiring.",
    "start": "3547120",
    "end": "3554300"
  }
]
[
  {
    "text": " So again, I'm very happy\nto have Jason here.",
    "start": "0",
    "end": "7320"
  },
  {
    "text": "So he's an AI researcher\nbased in San Francisco, currently working at OpenAI. He was previously a\nresearch scientist",
    "start": "7320",
    "end": "13500"
  },
  {
    "text": "at Google Brain, where he\npopularized key ideas in LLMS such as chain of thought\nprompting, instruction tuning,",
    "start": "13500",
    "end": "20039"
  },
  {
    "text": "as well as emergent phenomena. He's also a good\nfriend of mine and he's been here before\nto give some talks,",
    "start": "20040",
    "end": "25320"
  },
  {
    "text": "so we're very happy to have you\nback, Jason, and take it away. Great. [APPLAUSE]",
    "start": "25320",
    "end": "31750"
  },
  {
    "text": "Well, yeah, thanks\nfor the intro. So a bit about the structure.",
    "start": "31750",
    "end": "38580"
  },
  {
    "text": "So I'll talk for\naround 30 minutes, and then I'll take\na few questions, and then Kyeong Hwan\nwill talk for 30 minutes,",
    "start": "38580",
    "end": "44040"
  },
  {
    "text": "and then we'll both take\nquestions at the end.  Great.",
    "start": "44040",
    "end": "49380"
  },
  {
    "text": "So I want to talk about\na few very basic things.",
    "start": "49380",
    "end": "55080"
  },
  {
    "text": "And I think the fundamental\nquestion that I hope to get at is, why do language\nmodels work so well?",
    "start": "55080",
    "end": "69565"
  },
  {
    "text": " And one thing that\nI encourage everyone",
    "start": "69565",
    "end": "74830"
  },
  {
    "text": "to do that I found to be\nextremely helpful in trying to answer this question\nis to use a tool which",
    "start": "74830",
    "end": "81535"
  },
  {
    "text": "is manually inspect data.",
    "start": "81535",
    "end": "87085"
  },
  {
    "text": " And I'll give a short anecdote. I've been doing this\nfor a long time.",
    "start": "87085",
    "end": "94330"
  },
  {
    "text": "So in 2019, I was trying to\nbuild one of the first lung cancer classifiers, so\nthere would be an image,",
    "start": "94330",
    "end": "100240"
  },
  {
    "text": "and you have to say like,\nOK, what type of lung cancer is this? And my first thing\nwas like, OK, if I",
    "start": "100240",
    "end": "107020"
  },
  {
    "text": "want to train a neural\nnetwork to do this, I should be able to,\nat least, do the task. So I went to my\nadvisor and I said",
    "start": "107020",
    "end": "112810"
  },
  {
    "text": "like, oh, I want to learn\nto do this task first. And he said, Jason, you\nneed a medical degree",
    "start": "112810",
    "end": "118329"
  },
  {
    "text": "and like three\nyears of pathology experience to even do this task. And I found that a\nbit discouraging,",
    "start": "118330",
    "end": "123729"
  },
  {
    "text": "but I went and did it anyways. So I basically looked at the\nspecific type of lung cancer",
    "start": "123730",
    "end": "129130"
  },
  {
    "text": "that I was working on. And I'd read all the papers on\nhow to classify different types. And I went to pathologists\nand I said, OK, I",
    "start": "129130",
    "end": "135819"
  },
  {
    "text": "try to classify these,\nwhat do I do wrong? And then, what do\nyou think of that? And in the end, I learned how to\ndo this task of classifying lung",
    "start": "135820",
    "end": "144040"
  },
  {
    "text": "cancer. And the result of this\nwas, I gained intuitions about the task that\nled to many papers.",
    "start": "144040",
    "end": "152590"
  },
  {
    "text": "OK. So first, I will do a quick\nreview of language models.",
    "start": "152590",
    "end": "158560"
  },
  {
    "text": "So the way language models are\ntrained are with the next word prediction task.",
    "start": "158560",
    "end": "164500"
  },
  {
    "text": "So let's say you\nhave a sentence,",
    "start": "164500",
    "end": "171260"
  },
  {
    "text": "Dartmouth students like to-- and the goal of\nnext word prediction",
    "start": "171260",
    "end": "177500"
  },
  {
    "text": "is, you have some\nwords that come before, and then you want to\npredict the next word. And what the language\nmodel does is",
    "start": "177500",
    "end": "185599"
  },
  {
    "text": "it outputs a probability\nfor every single word in the vocabulary. So vocabulary would be like,\na aardvark, drink, study,",
    "start": "185600",
    "end": "201050"
  },
  {
    "text": "and then all the\nway to zucchini. And then the language\nmodel is going",
    "start": "201050",
    "end": "206690"
  },
  {
    "text": "to put a probability over\nevery single word here. So the probability of\na being the next word",
    "start": "206690",
    "end": "212150"
  },
  {
    "text": "is something really small. Aardvark is something\nreally small.",
    "start": "212150",
    "end": "217310"
  },
  {
    "text": "And then maybe drink is\nlike say, 0.6, study is 0.3,",
    "start": "217310",
    "end": "223790"
  },
  {
    "text": "zucchini is, again,\nreally small. ",
    "start": "223790",
    "end": "229210"
  },
  {
    "text": "And then the way that you\ntrain the language model is you say, I want-- let's say\ndrink is the correct word here,",
    "start": "229210",
    "end": "238920"
  },
  {
    "text": "I want this number here, 0.6,\nto be as close as possible to 1. So your loss is basically\nhow close is the actual word?",
    "start": "238920",
    "end": "249090"
  },
  {
    "text": "The probability of\nthe actual next word? And you want this loss\nto be as low as possible. ",
    "start": "249090",
    "end": "256768"
  },
  {
    "text": "OK. So the first intuition that I\nwould encourage everyone to use",
    "start": "256769",
    "end": "269700"
  },
  {
    "text": "is, next word prediction is,\nmassively multi-task learning.",
    "start": "269700",
    "end": "292900"
  },
  {
    "text": "And what I mean by\nthis is the following, I'll give a few examples. ",
    "start": "292900",
    "end": "299870"
  },
  {
    "text": "So when you train\na language model on a large enough database,\na large enough data set",
    "start": "299870",
    "end": "307870"
  },
  {
    "text": "on this task of next\nword prediction, you have a lot of sentences\nthat you can learn from. So for example, there might be\nsome sentence, in my free time",
    "start": "307870",
    "end": "316660"
  },
  {
    "text": "I like to-- and\nthe language model has to learn that code should be\nhigher probability than the word banana, so it\nlearns some grammar.",
    "start": "316660",
    "end": "325479"
  },
  {
    "text": "It will learn lexical\nsemantics, so somewhere in your data set there might be\na sentence, I went to the store",
    "start": "325480",
    "end": "332199"
  },
  {
    "text": "to buy papaya,\ndragonfruit, and durian. And the language\nmodel should know that the probability of durian\nshould be higher than squirrel.",
    "start": "332200",
    "end": "341080"
  },
  {
    "text": "The language model will\nlearn world knowledge. So there will be some sentence\non the internet that says, the capital of\nAzerbaijan is-- and then",
    "start": "341080",
    "end": "348193"
  },
  {
    "text": "the language model should\nlearn that it should be Baku instead of London.",
    "start": "348193",
    "end": "353500"
  },
  {
    "text": "You can learn traditional NLP\ntasks like sentiment analysis. So there will be\nsome sentence, I",
    "start": "353500",
    "end": "358683"
  },
  {
    "text": "was engaged on the\nedge of my seat the whole time the movie was. And the language\nmodel looks like, OK, if these are the\nprior next words,",
    "start": "358683",
    "end": "365259"
  },
  {
    "text": "the next word should\nprobably be good and not bad. And then finally-- or another\nexample is translation.",
    "start": "365260",
    "end": "374060"
  },
  {
    "text": "So here, you might\nsee some sentence. The word for pretty\nand Spanish is-- and then the\nlanguage model should",
    "start": "374060",
    "end": "381140"
  },
  {
    "text": "weigh bonita more than ola. Spatial reasoning. So you might even\nhave some sentence",
    "start": "381140",
    "end": "387620"
  },
  {
    "text": "like, Iroh went to the\nkitchen to make some tea. Standing next to Iroh,\nZuko pondered his destiny.",
    "start": "387620",
    "end": "393440"
  },
  {
    "text": "Zuko left the-- and\nthen kitchen should be higher probability than store.",
    "start": "393440",
    "end": "398860"
  },
  {
    "text": "And then finally, even\nsome math questions. So you might have some\narithmetic exam answer key",
    "start": "398860",
    "end": "405460"
  },
  {
    "text": "somewhere on the internet,\nand then the language model looks at this and says, OK,\nthe next word should probably be 15 and not 11.",
    "start": "405460",
    "end": "413120"
  },
  {
    "text": "And you can have basically\nmillions of tasks like this when you have a huge data set.",
    "start": "413120",
    "end": "418550"
  },
  {
    "text": "And you can think of this as\nbasically extreme multitask learning.",
    "start": "418550",
    "end": "423720"
  },
  {
    "text": "And these are sort of very\nclean examples of tasks, but I'll give an example of how\narbitrary some of these tasks",
    "start": "423720",
    "end": "437000"
  },
  {
    "text": "can be.  So here's a sentence\nfrom Wikipedia.",
    "start": "437000",
    "end": "446530"
  },
  {
    "text": "Biden married Neilia.",
    "start": "446530",
    "end": "454560"
  },
  {
    "text": "OK, and then now, pretend\nyou're the language model. And you could say, OK,\nwhat's the next word here?",
    "start": "454560",
    "end": "461310"
  },
  {
    "text": "And the next word\nhere is hunter. So it's Biden's\nfirst wife, and so,",
    "start": "461310",
    "end": "466657"
  },
  {
    "text": "OK, what's the\nlanguage model learning to predict from\npredicting this word, I guess like world knowledge.",
    "start": "466657",
    "end": "471960"
  },
  {
    "text": " And then what's the\nnext word after this?",
    "start": "471960",
    "end": "478660"
  },
  {
    "text": "It turns out the\nnext word is a comma. So here the model is learning,\nbasically, comma prediction.",
    "start": "478660",
    "end": "486700"
  },
  {
    "text": "And then what's the\nnext word after that? I think it's kind of hard to\nknow, but the answer is a.",
    "start": "486700",
    "end": "493350"
  },
  {
    "text": "And I guess this is\nlike maybe grammar, but like somewhat arbitrary. ",
    "start": "493350",
    "end": "500320"
  },
  {
    "text": "And then what's the\nnext word after that? It turns out it's student. ",
    "start": "500320",
    "end": "507759"
  },
  {
    "text": "And this I would\nsay, I don't know what task this is, this is\nit could have been woman,",
    "start": "507760",
    "end": "515110"
  },
  {
    "text": "it could have been\nsomething else, so this is like a\npretty arbitrary task. And the point that I'm\ntrying to make here",
    "start": "515110",
    "end": "521770"
  },
  {
    "text": "is that, the next\nword prediction task is really challenging. So if you do this over\nthe entire database",
    "start": "521770",
    "end": "527590"
  },
  {
    "text": "you're going to\nlearn a lot of tasks. OK. ",
    "start": "527590",
    "end": "538480"
  },
  {
    "text": "The next intuition\nI want to talk about is scaling, which is, by the\nway, say scaling compute.",
    "start": "538480",
    "end": "555720"
  },
  {
    "text": "And by the way, compute\nis equal to how much data you have times the size\nof the language model.",
    "start": "555720",
    "end": "561330"
  },
  {
    "start": "561330",
    "end": "566600"
  },
  {
    "text": "Reliably improves loss. ",
    "start": "566600",
    "end": "576770"
  },
  {
    "text": "And this idea was\nbasically pioneered by Kaplan et Al in 2020.",
    "start": "576770",
    "end": "587060"
  },
  {
    "text": "I would encourage you\nguys to read the paper. And what this basically says\nis, you can have a plot here,",
    "start": "587060",
    "end": "593930"
  },
  {
    "text": "and we'll see many\nplots like this, where the x-axis is compute,\nand the y-axis is loss.",
    "start": "593930",
    "end": "605600"
  },
  {
    "text": "And what this intuition says\nis, you can train one language model, you'll have that loss.",
    "start": "605600",
    "end": "611660"
  },
  {
    "text": "And obviously, you\nwant loss to be lower, so you can train the next\none, it'll have that loss. If you train the one after\nthat, it'll have that loss,",
    "start": "611660",
    "end": "618950"
  },
  {
    "text": "then if you train the one after\nthat, we'll have that loss. And you can basically predict\nthe loss of a language model",
    "start": "618950",
    "end": "626270"
  },
  {
    "text": "based on how much compute\nyou're going to use to train it. And the reason why\nthis is called a law",
    "start": "626270",
    "end": "632310"
  },
  {
    "text": "is that in this paper they\nshowed that the x-axis here is actually seven\norders of magnitude.",
    "start": "632310",
    "end": "639030"
  },
  {
    "text": "So basically, it\nwould be surprising if the trend broke\nif you continued.",
    "start": "639030",
    "end": "644460"
  },
  {
    "text": "And the important\nthing about this is that the line does\nnot go like that,",
    "start": "644460",
    "end": "649920"
  },
  {
    "text": "because if it went like\nthat, then it would saturate,",
    "start": "649920",
    "end": "654990"
  },
  {
    "text": "and then putting more compute or\ntraining a larger language model wouldn't actually\nlead to lower loss.",
    "start": "654990",
    "end": "660360"
  },
  {
    "start": "660360",
    "end": "673630"
  },
  {
    "text": "OK, so I think a question that\nwe don't have a good answer",
    "start": "673630",
    "end": "678670"
  },
  {
    "text": "to as a field, but I'll give\nyou like a handwavy answer is, why does scaling up the\nsize of your language model",
    "start": "678670",
    "end": "686710"
  },
  {
    "text": "improve the loss? And I'll give like two\nbasically hand-wavy answers. So here's a small LM,\nand here's large LM.",
    "start": "686710",
    "end": "699160"
  },
  {
    "text": "So one thing that's important\nis, how good is your language model at memorizing facts?",
    "start": "699160",
    "end": "704725"
  },
  {
    "text": " And imagine you're a\nsmall language model,",
    "start": "704725",
    "end": "710769"
  },
  {
    "text": "and you see a bunch of\nfacts on the internet. You have to be pretty\nchoosy in which facts",
    "start": "710770",
    "end": "716230"
  },
  {
    "text": "you memorize because if you\ndon't have that many parameters, you're like, oh, I can only\nmemorize a million facts,",
    "start": "716230",
    "end": "721570"
  },
  {
    "text": "is this one of the\nfacts that I want to memorize at the lowest loss? And so you have to\nbe very selective.",
    "start": "721570",
    "end": "727450"
  },
  {
    "text": "Whereas if you're a\nlarge language model,",
    "start": "727450",
    "end": "732800"
  },
  {
    "text": "you can memorize a\nlot of tail knowledge. And so basically, every fact\nyou see, you don't have to say,",
    "start": "732800",
    "end": "738230"
  },
  {
    "text": "is this something\nI want to memorize? You can just memorize it. And then the other\nhand-wavy answer I'll give",
    "start": "738230",
    "end": "745170"
  },
  {
    "text": "is small language models tend\nto learn first order heuristics.",
    "start": "745170",
    "end": "751740"
  },
  {
    "text": "So if you're like a\nsmall language model, you're like already struggling\nto get the grammar correct,",
    "start": "751740",
    "end": "757818"
  },
  {
    "text": "you're not going to do your\nbest to try to get the math problem exactly correct. Whereas if you're a\nlarge language model,",
    "start": "757818",
    "end": "766700"
  },
  {
    "text": "you have a lot of parameters\nin your forward pass, and you can try to do\nreally complicated things",
    "start": "766700",
    "end": "772190"
  },
  {
    "text": "to get the next token correct,\nand to get the loss as low as possible. ",
    "start": "772190",
    "end": "788110"
  },
  {
    "text": "OK, so the third\nintuition I'll talk about is, while overall,\nloss improves smoothly,",
    "start": "788110",
    "end": "806590"
  },
  {
    "text": "individual tasks can\nimprove suddenly.",
    "start": "806590",
    "end": "816875"
  },
  {
    "text": " And here's what I mean by this.",
    "start": "816875",
    "end": "823780"
  },
  {
    "text": "So you can write\nyour overall loss. By this I mean, if you\ntake some corpus of data",
    "start": "823780",
    "end": "833980"
  },
  {
    "text": "and you compute the overall loss\non every word in that data set, the overall loss because we know\nthat next word prediction is",
    "start": "833980",
    "end": "842319"
  },
  {
    "text": "massively multitask\nlearning, you can decompose this\noverall loss into the loss of every single individual task.",
    "start": "842320",
    "end": "848620"
  },
  {
    "text": "So you have, I don't\nknow, some small number times the loss of say grammar,\nplus some small number,",
    "start": "848620",
    "end": "860570"
  },
  {
    "text": "times the loss of like\nsentiment analysis,",
    "start": "860570",
    "end": "866400"
  },
  {
    "text": "plus some small number, times\nthe loss of world knowledge,",
    "start": "866400",
    "end": "876150"
  },
  {
    "text": "plus-- and then all the way to, let's\nsay you have something times",
    "start": "876150",
    "end": "882090"
  },
  {
    "text": "the loss of math.",
    "start": "882090",
    "end": "887190"
  },
  {
    "text": "And so you can basically\nwrite your overall loss as the weighted sum of the\nindividual tasks in the data",
    "start": "887190",
    "end": "893020"
  },
  {
    "text": "set. And now the question\nis, let's say I improve my loss\nfrom four to three,",
    "start": "893020",
    "end": "901529"
  },
  {
    "text": "do each of these individual\ntasks improve at the same rate? Well, I would say, probably not.",
    "start": "901530",
    "end": "907670"
  },
  {
    "text": "So if you have a good\nenough language model, it's already doing\nbasically, perfectly",
    "start": "907670",
    "end": "913130"
  },
  {
    "text": "on grammar and\nsentiment analysis, so this might not improve. ",
    "start": "913130",
    "end": "919170"
  },
  {
    "text": "So this might be saturated. ",
    "start": "919170",
    "end": "925180"
  },
  {
    "text": "And maybe, the law-- the laws\non math is not saturated, it's not that good at math yet,\nso this could improve suddenly.",
    "start": "925180",
    "end": "932005"
  },
  {
    "start": "932005",
    "end": "937850"
  },
  {
    "text": "And I'll redraw the\ndiagram to show this. ",
    "start": "937850",
    "end": "946840"
  },
  {
    "text": "So again, compute\nhere, and loss here,",
    "start": "946840",
    "end": "955270"
  },
  {
    "text": "and your overall\nloss is like this. ",
    "start": "955270",
    "end": "961290"
  },
  {
    "text": "What I'm saying\nis, there might be some part of that overall\nloss that scales like this.",
    "start": "961290",
    "end": "969230"
  },
  {
    "text": "So this is say, grammar. So for example, you could say,\nif GPT-3.5 is there and GPT-4 is",
    "start": "969230",
    "end": "979060"
  },
  {
    "text": "there, you haven't actually\nimproved the grammar that much. On the other hand, you might\nhave something like this,",
    "start": "979060",
    "end": "986640"
  },
  {
    "text": "for say, doing math\nor a harder task, where the difference between\nGPT-3.5 and GPT-4 will be much",
    "start": "986640",
    "end": "994680"
  },
  {
    "text": "larger. And it turns out you can look at\na big set of tasks, which I did,",
    "start": "994680",
    "end": "1009880"
  },
  {
    "text": "and you can look at, what's the\nshape of these scaling curves? So I looked at 202 tasks.",
    "start": "1009880",
    "end": "1018630"
  },
  {
    "text": "There's this corpus called\nBig Bench which has 200 tasks. I looked at all of them and\nhere's the distribution.",
    "start": "1018630",
    "end": "1025859"
  },
  {
    "text": "So you have-- this was 29%\nof tasks that were smooth.",
    "start": "1025859",
    "end": "1037199"
  },
  {
    "text": "So if I draw the scaling plot,\ncompute is on the x-axis,",
    "start": "1037200",
    "end": "1043109"
  },
  {
    "text": "and then here we have\naccuracy instead of loss, so higher is better, then\nyou have something like this.",
    "start": "1043109",
    "end": "1050930"
  },
  {
    "text": "I believe this was\n22% will be flat.",
    "start": "1050930",
    "end": "1056570"
  },
  {
    "text": "So if you have your scaling\ncurve, it'll just all be 0, the task was too hard.",
    "start": "1056570",
    "end": "1062539"
  },
  {
    "text": "2% will be something\ncalled inverse scaling, I'll talk about this in a sec.",
    "start": "1062540",
    "end": "1068880"
  },
  {
    "text": "But what that means is\nthe accuracy actually gets worse as you increase the\nsize of the language model.",
    "start": "1068880",
    "end": "1076919"
  },
  {
    "text": "And then, I think, this was\n13% will be not correlated.",
    "start": "1076920",
    "end": "1083100"
  },
  {
    "text": " So you have something\nlike that, I don't know.",
    "start": "1083100",
    "end": "1090340"
  },
  {
    "text": "And then finally, a\npretty big portion, 33%,",
    "start": "1090340",
    "end": "1096270"
  },
  {
    "text": "will be emergent abilities. And what I mean by that is\nif you plot your compute",
    "start": "1096270",
    "end": "1107880"
  },
  {
    "text": "and accuracy for a certain\npoint, up to a certain point,",
    "start": "1107880",
    "end": "1113470"
  },
  {
    "text": "your loss or your\naccuracy will be 0, and then the accuracy\nsuddenly starts to improve.",
    "start": "1113470",
    "end": "1121860"
  },
  {
    "text": "And so you can define\nan emergent ability basically as for small models.",
    "start": "1121860",
    "end": "1127275"
  },
  {
    "text": " The performance is 0, so it's\nnot present in this model.",
    "start": "1127275",
    "end": "1134440"
  },
  {
    "text": "And then for large models, you\nhave a much better than random",
    "start": "1134440",
    "end": "1143460"
  },
  {
    "text": "performance. And the interesting\nthing about this is, let's say you had only\ntrained the small language",
    "start": "1143460",
    "end": "1149520"
  },
  {
    "text": "models up to that\npoint, you would have predicted\nthat it would have been impossible for the language\nmodel to ever perform the task.",
    "start": "1149520",
    "end": "1156645"
  },
  {
    "text": "But actually when you\ntrain the larger model, the language model does learn to\nperform the task, so in a sense",
    "start": "1156645",
    "end": "1162240"
  },
  {
    "text": "it's pretty unpredictable. ",
    "start": "1162240",
    "end": "1174500"
  },
  {
    "text": "I'll talk about one final\nthing, which is something called",
    "start": "1174500",
    "end": "1182180"
  },
  {
    "text": "inverse scaling/u-shaped\nscaling. ",
    "start": "1182180",
    "end": "1188810"
  },
  {
    "text": "OK, so I'll give a tricky\nprompt to illustrate this. So the tricky prompt is this.",
    "start": "1188810",
    "end": "1195600"
  },
  {
    "text": "Repeat after me.",
    "start": "1195600",
    "end": "1202090"
  },
  {
    "text": "All that glisters is not glib,\nall that glisters is not--",
    "start": "1202090",
    "end": "1222820"
  },
  {
    "text": "and this is the prompt that\nI give to the language model, and the goal is to\npredict this next word.",
    "start": "1222820",
    "end": "1228850"
  },
  {
    "text": "And obviously,\nthe correct answer is glib because you\nasked to repeat after me.",
    "start": "1228850",
    "end": "1237100"
  },
  {
    "text": "And what you see is, let's say\nyou have a extra small language",
    "start": "1237100",
    "end": "1242860"
  },
  {
    "text": "model, a small language model\nand a large language model. The performance for the\nextra small language",
    "start": "1242860",
    "end": "1250000"
  },
  {
    "text": "model will be say here's 100%.",
    "start": "1250000",
    "end": "1255370"
  },
  {
    "text": "The small language model is\nactually worse at this task, so something like\nsomething here.",
    "start": "1255370",
    "end": "1260980"
  },
  {
    "text": "And then the large\nlanguage model again learns to do this task.",
    "start": "1260980",
    "end": "1266139"
  },
  {
    "text": "So how do we basically\nexplain a behavior like this for a\nprompt like this? ",
    "start": "1266140",
    "end": "1281310"
  },
  {
    "text": "And the answer is,\nyou can decompose this prompt into three subtasks\nthat are basically being done.",
    "start": "1281310",
    "end": "1290309"
  },
  {
    "text": "So the first sub task is,\ncan you repeat some text?",
    "start": "1290310",
    "end": "1296160"
  },
  {
    "text": "And if you draw the\nplot here, again, extra small, small large,\nand then here is 100.",
    "start": "1296160",
    "end": "1304440"
  },
  {
    "text": "This is like a super easy task,\nand so all the language models have perfect\nperformance on that.",
    "start": "1304440",
    "end": "1313290"
  },
  {
    "text": "That's one hidden task. The other task is,\ncan you fix a quote?",
    "start": "1313290",
    "end": "1321759"
  },
  {
    "text": "So the quote is supposed to be\nall that glisters is not gold. And so you can then plot, again,\nextra small, small, large.",
    "start": "1321760",
    "end": "1332200"
  },
  {
    "text": "What's the ability\nto fix that quote? Well, the small language\nmodel doesn't know the quote, so it's going to get 0.",
    "start": "1332200",
    "end": "1339520"
  },
  {
    "text": "And then, the extra small\ndoesn't know the quote, so it's going to get 0. The small will be able to do\nit, and the large can obviously",
    "start": "1339520",
    "end": "1347440"
  },
  {
    "text": "do it, so that's what the\nscaling curve looks like. And then finally,\nyou have the quote--",
    "start": "1347440",
    "end": "1357019"
  },
  {
    "text": "you have the task,\nfollow and instruction. ",
    "start": "1357020",
    "end": "1363390"
  },
  {
    "text": "And obviously, this is\nthe instruction here. And you can say, OK,\nwhat's the performance",
    "start": "1363390",
    "end": "1369840"
  },
  {
    "text": "of these models on this task? ",
    "start": "1369840",
    "end": "1376700"
  },
  {
    "text": "And the small model can't do\nit, or the extra small model can't do it, small\nmodel also can't do it,",
    "start": "1376700",
    "end": "1382280"
  },
  {
    "text": "but the large model can do it,\nso you get a curve like this.",
    "start": "1382280",
    "end": "1387320"
  },
  {
    "text": "And then why does this\nexplain this behavior here? Well, the small-- the extra\nsmall model, it can repeat,",
    "start": "1387320",
    "end": "1396500"
  },
  {
    "text": "it can't fix the quote, and it\ncan't follow the instruction, so it actually gets it\ncorrect, it says glib.",
    "start": "1396500",
    "end": "1403281"
  },
  {
    "text": "It says glib. The small model can repeat.",
    "start": "1403281",
    "end": "1410419"
  },
  {
    "text": "It can fix the quote, but it\ndoesn't follow the instruction, so it decides to fix the quote. ",
    "start": "1410420",
    "end": "1419910"
  },
  {
    "text": "And then the large model,\nit can do all three, it can follow the instruction,\nso it just repeats. ",
    "start": "1419910",
    "end": "1428990"
  },
  {
    "text": "And so that's how if you look\nat the individual subtasks, you can explain the behavior\nof some of these weird scaling",
    "start": "1428990",
    "end": "1435620"
  },
  {
    "text": "properties.  So I will conclude with one\ngeneral takeaway which is,",
    "start": "1435620",
    "end": "1451740"
  },
  {
    "text": "applicable if you do research. And the takeaway is to\njust plot scaling curves.",
    "start": "1451740",
    "end": "1459500"
  },
  {
    "start": "1459500",
    "end": "1465870"
  },
  {
    "text": "And I'll just give a\nreally simple example. So let's say I do something\nfor my research project.",
    "start": "1465870",
    "end": "1472320"
  },
  {
    "text": "I fine tune a model on\nsome number of examples, and I get this is my thing.",
    "start": "1472320",
    "end": "1482450"
  },
  {
    "text": "I get some performance there. And then here's the\nline of not doing",
    "start": "1482450",
    "end": "1491370"
  },
  {
    "text": "whatever my research project\nis, and there's the performance.",
    "start": "1491370",
    "end": "1496440"
  },
  {
    "text": "The reason you want to plot a\nscaling curve for this is like, let's say you take\nhalf the data,",
    "start": "1496440",
    "end": "1502560"
  },
  {
    "text": "and you find out that the\nperformance is actually here, so your curve looks like this.",
    "start": "1502560",
    "end": "1509780"
  },
  {
    "text": "What this will tell\nyou is, you didn't have to collect all the\ndata to do your thing. And if you collect\nmore, you probably",
    "start": "1509780",
    "end": "1516470"
  },
  {
    "text": "won't see an improvement\nin performance. Another scenario would be\nif you plotted that point",
    "start": "1516470",
    "end": "1523900"
  },
  {
    "text": "and it was there, then your\ncurve will look like this. And potentially,\nif you kept doing",
    "start": "1523900",
    "end": "1530990"
  },
  {
    "text": "more of whatever your\nresearch project is, you'd see an improvement\nin performance.",
    "start": "1530990",
    "end": "1536860"
  },
  {
    "text": "And then finally,\nmaybe your point is there, so your\ncurve looks like this.",
    "start": "1536860",
    "end": "1543120"
  },
  {
    "text": "And in this case\nyou would expect to see an even larger\njump in performance after you continue\ndoing your thing.",
    "start": "1543120",
    "end": "1551240"
  },
  {
    "text": "So yeah, I'll end\nmy talk here, and happy to take a few questions\nbefore Hyung Won's talk.",
    "start": "1551240",
    "end": "1557660"
  },
  {
    "text": " Yeah, go ahead.",
    "start": "1557660",
    "end": "1563252"
  },
  {
    "text": "So in your [INAUDIBLE] data\nthat has an operational source?",
    "start": "1563252",
    "end": "1572240"
  },
  {
    "text": "Did you write the data\nbased on the source? Repeat the question. Oh, yeah.",
    "start": "1572240",
    "end": "1577490"
  },
  {
    "text": "Yeah, thanks. Good question. So the question is,\nduring pre-training,",
    "start": "1577490",
    "end": "1583909"
  },
  {
    "text": "how do you differentiate\nbetween good data and bad data? The question is or the\nanswer is, you don't really,",
    "start": "1583910",
    "end": "1591140"
  },
  {
    "text": "but you should by only\ntraining on good data. So like maybe you should\nlook at like your data source",
    "start": "1591140",
    "end": "1597410"
  },
  {
    "text": "and filter out some data if it's\nnot from a reliable data source. ",
    "start": "1597410",
    "end": "1603850"
  },
  {
    "text": "Yeah. Do you want to give us maybe the\nintuition behind the intuition for one or two of the\nexamples like emergent",
    "start": "1603850",
    "end": "1610500"
  },
  {
    "text": "or why tail knowledge\nstarts to develop, sort of what's behind that?",
    "start": "1610500",
    "end": "1615672"
  },
  {
    "text": "What do you mean intuition\nbehind intuition? So you've explained\nintuitively these concepts that you're seeing\nin the graphs.",
    "start": "1615672",
    "end": "1621270"
  },
  {
    "text": "And from your experience and\nexpertise, what in the model itself is really causing\nthat emergent behavior?",
    "start": "1621270",
    "end": "1628800"
  },
  {
    "text": " What do you mean in\nthe model itself?",
    "start": "1628800",
    "end": "1634500"
  },
  {
    "text": "Is it more depth,\nmore nodes, more-- Oh, I see.",
    "start": "1634500",
    "end": "1639890"
  },
  {
    "text": "--attention, in an intuitive\nsense not in a [INAUDIBLE]?? Yeah. OK. Yeah. So the question is\nlike what in the model",
    "start": "1639890",
    "end": "1646620"
  },
  {
    "text": "makes the language model better\nat memorizing tail knowledge or at doing math problems?",
    "start": "1646620",
    "end": "1655750"
  },
  {
    "text": "Yeah. I think it's definitely related\nto the size of the language model. So yeah. If you have more layers,\nyou could encode probably",
    "start": "1655750",
    "end": "1662760"
  },
  {
    "text": "a more complex\nfunction within that. And then, I guess, if\nyou have more breadth,",
    "start": "1662760",
    "end": "1669820"
  },
  {
    "text": "you could probably encode like\nmore facts about the world. And then if you want to repeat a\nfactor like retrieve something,",
    "start": "1669820",
    "end": "1677559"
  },
  {
    "text": "it'd probably be easier. I'll get one more in person\nand then I'll move this myself.",
    "start": "1677560",
    "end": "1684840"
  },
  {
    "text": "So when you were studying the\n200-ish problems in the big bench, you noticed\nthat 22% were flat.",
    "start": "1684840",
    "end": "1691290"
  },
  {
    "text": "But there's a possibility that\nif you increase the compute even further, you might have--\nthose might have turned out to be emergent.",
    "start": "1691290",
    "end": "1696775"
  },
  {
    "text": "So my question to\nyou is that, when you were looking at the 33%\nthat turned out to be emergent, did you notice anything about\nthe loss in the flat portion",
    "start": "1696775",
    "end": "1703830"
  },
  {
    "text": "that suggested that they would\neventually become emergent? Yeah.",
    "start": "1703830",
    "end": "1709080"
  },
  {
    "text": "I didn't notice anything. Oh, sorry, let me\nrepeat the question. The question is like, when\nI looked at all the emergent",
    "start": "1709080",
    "end": "1716160"
  },
  {
    "text": "tasks, was there anything that\nI noticed before the emergence point in the loss that would\nhave hinted that it would",
    "start": "1716160",
    "end": "1723540"
  },
  {
    "text": "have become emergent later? To me it was kind of tough,\nwe have a few plots of this. You can look at the loss\nand it kind of gets better,",
    "start": "1723540",
    "end": "1731353"
  },
  {
    "text": "and then suddenly it\nspikes, and there's like no way to predict\nit, but also you don't have perfect data\nbecause like you might not",
    "start": "1731353",
    "end": "1737160"
  },
  {
    "text": "have all the intermediate\npoints for a given model size. Yeah. Great question. ",
    "start": "1737160",
    "end": "1744760"
  },
  {
    "text": "Yeah. We can just hang on. We have a few online questions. Online, OK, yeah.",
    "start": "1744760",
    "end": "1751313"
  },
  {
    "text": "We just have a few\nquestions from people who are joining on Zoom. The first one is,\nwhat do you think",
    "start": "1751313",
    "end": "1756580"
  },
  {
    "text": "are the biggest bottlenecks for\ncurrent large language models? Is it the quality of data,\nthe amount of compute,",
    "start": "1756580",
    "end": "1761830"
  },
  {
    "text": "or something else? Yeah. Great question. I guess like if you go back to\nthe scaling laws paradigm, what",
    "start": "1761830",
    "end": "1772870"
  },
  {
    "text": "it says is that if you\nincrease the size of the data, and the size of the\nmodel, then you'd",
    "start": "1772870",
    "end": "1778510"
  },
  {
    "text": "expect to get a lot\nbetter performance. And I think, yeah,\nwe'll probably try to keep increasing\nthose things.",
    "start": "1778510",
    "end": "1783760"
  },
  {
    "text": "Gotcha. And then the last one. What are your thoughts on\nthe paper if you've read it.",
    "start": "1783760",
    "end": "1789070"
  },
  {
    "text": "Are emergent abilities of\nlanguage large language models a mirage? Oh, yeah. I always get this question.",
    "start": "1789070",
    "end": "1795559"
  },
  {
    "text": "I guess I would encourage\nyou to read the paper and decide for yourself. But yeah, I guess\nwhat the paper says",
    "start": "1795560",
    "end": "1803810"
  },
  {
    "text": "is if you change the metric\na bit, it looks different. But I would say, at\nthe end of the day,",
    "start": "1803810",
    "end": "1810500"
  },
  {
    "text": "I think, the language\nmodel abilities are real. And if you think\nlike, I guess, I don't think that's\na mirage, so yeah.",
    "start": "1810500",
    "end": "1821530"
  },
  {
    "text": "[APPLAUSE] All right. So thanks Jason for the\nvery insightful talk.",
    "start": "1821530",
    "end": "1828290"
  },
  {
    "text": "And now we have Hyung\nWon give a talk. So he's currently a\nresearch scientist",
    "start": "1828290",
    "end": "1833510"
  },
  {
    "text": "at on the OpenAI ChatGPT team. He has worked on various aspects\nof large language models.",
    "start": "1833510",
    "end": "1840530"
  },
  {
    "text": "Things like pre-training,\ninstruction fine tuning, reinforcement learning\nwith human feedback,",
    "start": "1840530",
    "end": "1845600"
  },
  {
    "text": "reasoning, and so forth. And some of his notable works\ninclude the scaling flan papers",
    "start": "1845600",
    "end": "1851120"
  },
  {
    "text": "such as FLAN-T5, as\nwell as Flan-PALM, and T5X, the training framework\nused to train the PALM language",
    "start": "1851120",
    "end": "1857899"
  },
  {
    "text": "model. And before OpenAI, he\nwas at Google Brain, and he received\nhis PhD from MIT.",
    "start": "1857900",
    "end": "1864560"
  },
  {
    "text": "So give a hand for Hyung Won. [APPLAUSE] Do we switch the slides?",
    "start": "1864560",
    "end": "1870330"
  },
  {
    "start": "1870330",
    "end": "1879120"
  },
  {
    "text": "All right. My name is Hyung Won, and I'm\nreally happy to be here today. And this week I was\nthinking about--",
    "start": "1879120",
    "end": "1884880"
  },
  {
    "text": "by the way, is mic working fine? Yeah. So this week I thought about--",
    "start": "1884880",
    "end": "1890289"
  },
  {
    "text": "OK, I'm giving a lecture on\ntransformers at Stanford. What should I talk about? And I thought, OK, some of\nyou in this room and in Zoom",
    "start": "1890290",
    "end": "1899679"
  },
  {
    "text": "will actually go shape\nthe future of AI, so maybe I should\ntalk about that. It's a really important\ngoal and ambitious,",
    "start": "1899680",
    "end": "1905410"
  },
  {
    "text": "and we really have\nto get it right. So that could be a good\ntopic to think about. And when we talk about\nsomething into the future,",
    "start": "1905410",
    "end": "1913419"
  },
  {
    "text": "the best place to get an advice\nis to look into the history. And in particular, we'll\nlook at the early history",
    "start": "1913420",
    "end": "1920380"
  },
  {
    "text": "of transformer, and try to\nlearn many lessons from there. And the goal will be to\ndevelop a unified perspective",
    "start": "1920380",
    "end": "1929110"
  },
  {
    "text": "in which we can look into many\nseemingly disjoint events.",
    "start": "1929110",
    "end": "1934600"
  },
  {
    "text": "And from that we\ncan probably hope to project into the future\nwhat might be coming.",
    "start": "1934600",
    "end": "1940000"
  },
  {
    "text": "And so that will be the\ngoal of this lecture, and we'll look at some\nof the architectures",
    "start": "1940000",
    "end": "1946240"
  },
  {
    "text": "of the transformers,\nso let's get started. Everyone I see is\nsaying, AI is so",
    "start": "1946240",
    "end": "1953600"
  },
  {
    "text": "advancing so fast that\nit's so hard to keep up. And it doesn't matter if you\nhave years of experience,",
    "start": "1953600",
    "end": "1959210"
  },
  {
    "text": "there are so many things\nare coming out every week that it's just hard to keep up. And I do see many people\nspend a lot of time and energy",
    "start": "1959210",
    "end": "1966799"
  },
  {
    "text": "catching up with this latest\ndevelopments, the cutting edge and the newest thing,\nand then not enough attention",
    "start": "1966800",
    "end": "1973760"
  },
  {
    "text": "goes into old things because\nthey become deprecated and no longer relevant.",
    "start": "1973760",
    "end": "1980480"
  },
  {
    "text": "But I think it's\nimportant, actually, to look into that because\nwe really need to-- when things are moving so\nfast beyond our ability",
    "start": "1980480",
    "end": "1988070"
  },
  {
    "text": "to catch up what we need to\ndo is study the change itself. And that means we can look\nback at the previous things,",
    "start": "1988070",
    "end": "1994370"
  },
  {
    "text": "and then look at\nthe current thing, and try to map how we got\nhere, and from which we",
    "start": "1994370",
    "end": "1999650"
  },
  {
    "text": "can look into what where\nwe are heading towards. So what does it mean to\nstudy the change itself?",
    "start": "1999650",
    "end": "2007970"
  },
  {
    "text": "First, we need to identify\nthe dominant driving forces behind the change.",
    "start": "2007970",
    "end": "2013490"
  },
  {
    "text": "So here dominant is\nan important word because typically, a change\nhas many, many driving forces,",
    "start": "2013490",
    "end": "2019640"
  },
  {
    "text": "and we only care\nabout the dominant one because we're not trying\nto get really accurate, we just want to have the\nsense of directionality.",
    "start": "2019640",
    "end": "2026000"
  },
  {
    "text": "Second, we need to understand\nthe driving force really well, and then after\nthat we can predict the future trajectory by rolling\nout the driving force and so on.",
    "start": "2026000",
    "end": "2035360"
  },
  {
    "text": "And you heard that\nright, I mentioned about predicting\nthe future, this is a computer science class not\nlike an astrology or something.",
    "start": "2035360",
    "end": "2041690"
  },
  {
    "text": "But we do-- I think it's actually not\nthat impossible to predict some future trajectory of a\nvery narrow scientific domain.",
    "start": "2041690",
    "end": "2050270"
  },
  {
    "text": "And that endeavor\nis really useful to do because let's\nsay you do all these",
    "start": "2050270",
    "end": "2057619"
  },
  {
    "text": "and then make your prediction\naccuracy to from 1% to 10%, and then you make say 100\npredictions, 10 of them",
    "start": "2057620",
    "end": "2064340"
  },
  {
    "text": "will be correct, say one of them\nwill be really, really correct. Meaning it will have\nan outside impact",
    "start": "2064340",
    "end": "2069830"
  },
  {
    "text": "that outweighs everything. And I think that is\nkind of how many--",
    "start": "2069830",
    "end": "2075169"
  },
  {
    "text": "I've seen many\ngeneral thing in life that you really have to\nbe right a few times.",
    "start": "2075170",
    "end": "2080690"
  },
  {
    "text": "So why-- so if we think about\nwhy predicting the future",
    "start": "2080690",
    "end": "2087408"
  },
  {
    "text": "is difficult or maybe even\nthink about the extreme case where we can all\ndo the prediction",
    "start": "2087409",
    "end": "2093110"
  },
  {
    "text": "with perfect accuracy,\nalmost perfect accuracy. So here, I'm going to do a very\nsimple experiment of dropping",
    "start": "2093110",
    "end": "2099170"
  },
  {
    "text": "this pen, and follow this\nsame three-step process. So we're going to identify\nthe dominant driving force.",
    "start": "2099170",
    "end": "2107240"
  },
  {
    "text": "First of all, what\nare the driving forces acting on this pen? Gravity downwards,\nand is that all?",
    "start": "2107240",
    "end": "2112370"
  },
  {
    "text": "We also have say\nair friction, right? If I drop it, and that\nwill cause what's called",
    "start": "2112370",
    "end": "2119120"
  },
  {
    "text": "a drag force acting upwards. And actually, depending on how\nI drop this, the orientation,",
    "start": "2119120",
    "end": "2126190"
  },
  {
    "text": "the aerodynamic interaction\nwill be so complicated that we don't currently have any\nanalytical way of modeling that.",
    "start": "2126190",
    "end": "2132650"
  },
  {
    "text": "We can do it with the CFD, the\ncomputational fluid dynamics, but it will be non-trivial. So we can neglect that.",
    "start": "2132650",
    "end": "2138664"
  },
  {
    "text": "This is heavy enough\nthat gravity is probably the only dominant force,\nso we simplify the problem.",
    "start": "2138665",
    "end": "2144050"
  },
  {
    "text": "Second, do we understand\nthis dominant driving force, which is gravity? And we do because we have this\nNewtonian mechanics, which",
    "start": "2144050",
    "end": "2150770"
  },
  {
    "text": "provides a reasonably\ngood model. And then with that, we can\npredict the future trajectory of this pen.",
    "start": "2150770",
    "end": "2156230"
  },
  {
    "text": "And if we remember from\nthis dynamics class, if we have this\ninitial velocity is 0,",
    "start": "2156230",
    "end": "2162470"
  },
  {
    "text": "I'm not going to\nput any velocity. And then let's say\nposition is 0 here, and then 1/2 GT squared will\ngive a precise trajectory",
    "start": "2162470",
    "end": "2171440"
  },
  {
    "text": "of this pen as I drop this. So if there is a driving force,\nsingle driving force that we",
    "start": "2171440",
    "end": "2176930"
  },
  {
    "text": "really understand, it's\nactually possible to predict what's going to happen. So then, why do we really fear\nabout predicting the future",
    "start": "2176930",
    "end": "2186470"
  },
  {
    "text": "in the most general sense? And I argue that,\namong many reasons, the number of driving force, the\nsheer number of dominant driving",
    "start": "2186470",
    "end": "2193970"
  },
  {
    "text": "forces acting on the general\nprediction is so complicated and their interaction creates\na complexity that we cannot",
    "start": "2193970",
    "end": "2201980"
  },
  {
    "text": "predict the most general sense. So here is my cartoon\nway of thinking about the prediction of future.",
    "start": "2201980",
    "end": "2207410"
  },
  {
    "text": "x-axis, we have a number\nof dominant driving forces, y-axis we have a\nprediction difficulty. So on the left hand\nside, we have a dropping",
    "start": "2207410",
    "end": "2214400"
  },
  {
    "text": "of pen it's a very simple case. It's a difficulty\nit's very small, you just need to learn physics.",
    "start": "2214400",
    "end": "2220310"
  },
  {
    "text": "And then, as you add more stuff,\nit just becomes impossible. So how does this fit\ninto the AI research?",
    "start": "2220310",
    "end": "2228050"
  },
  {
    "text": "And you might think, OK, I see\nall the time things are coming in, we are bombarded\nby new things,",
    "start": "2228050",
    "end": "2235220"
  },
  {
    "text": "and some people will come\nup with the new agent, new modality, new MMLU\nscore or whatever. We just see so\nmany things it just",
    "start": "2235220",
    "end": "2242810"
  },
  {
    "text": "I'm not even able to catch\nup with the latest thing, how can I even hope to predict\nthe future of the AI research?",
    "start": "2242810",
    "end": "2249450"
  },
  {
    "text": "But I argue that\nit's actually simpler because there is\na dominant driving",
    "start": "2249450",
    "end": "2254460"
  },
  {
    "text": "force that is\ngoverning a lot if any if not all of the AI research. And because of\nthat, I would like",
    "start": "2254460",
    "end": "2261510"
  },
  {
    "text": "to point out that, it's\nactually closer to the left than to the right than\nwe actually may perceive.",
    "start": "2261510",
    "end": "2268920"
  },
  {
    "text": "So what is the driving force? Maybe before that, I\nwould like to caveat",
    "start": "2268920",
    "end": "2274660"
  },
  {
    "text": "that when I do\nthis kind of talk, I would like to not focus too\nmuch on the technical stuff",
    "start": "2274660",
    "end": "2281470"
  },
  {
    "text": "which you can probably do\nbetter in your own time, but rather I want to\nshare how I think.",
    "start": "2281470",
    "end": "2287470"
  },
  {
    "text": "And for that, I want to\nshare how my opinion as is, and so it will be very\nstrongly opinionated.",
    "start": "2287470",
    "end": "2294280"
  },
  {
    "text": "And by no means I'm saying\nthis is correct or not, I just wanted to\nshare my perspective.",
    "start": "2294280",
    "end": "2299590"
  },
  {
    "text": "So coming back to this\ndriving force for AI, what is that dominant\ndriving force? And here is a plot\nfrom Rich Sutton.",
    "start": "2299590",
    "end": "2306970"
  },
  {
    "text": "And on the y-axis, we\nhave the calculations plot if you pay $100, and how much\ncomputing power do you get?",
    "start": "2306970",
    "end": "2315789"
  },
  {
    "text": "And it's in log scale. And then x-axis, we have a\ntime of more than 100 years.",
    "start": "2315790",
    "end": "2321940"
  },
  {
    "text": "So this is actually\nmore than exponential. And I don't know any trend that\nis as strong and as long lasting",
    "start": "2321940",
    "end": "2330310"
  },
  {
    "text": "as this one. So whenever I see this kind\nof thing, I should say,",
    "start": "2330310",
    "end": "2335520"
  },
  {
    "text": "OK, I should not\ncompete with this. And better, I should try to\nleverage as much as possible.",
    "start": "2335520",
    "end": "2341480"
  },
  {
    "text": "And so what this means is, you\nget 10x more compute every five",
    "start": "2341480",
    "end": "2347810"
  },
  {
    "text": "years if you spend the\nsame amount of dollar. And so in other words, you\nget the cost of compute",
    "start": "2347810",
    "end": "2354710"
  },
  {
    "text": "is going down exponentially. And this associated\nscaling is really",
    "start": "2354710",
    "end": "2359960"
  },
  {
    "text": "dominating the AI research, and\nthat is somewhat hard to take, but that is, I think, really\nimportant to think about.",
    "start": "2359960",
    "end": "2367710"
  },
  {
    "text": "So coming back to\nthis AI research, how is this\nexponentially cheaper compute drive the AI research?",
    "start": "2367710",
    "end": "2375260"
  },
  {
    "text": "Let's think about the job\nof the AI researchers. It is to teach machines how to\nthink in a very general sense.",
    "start": "2375260",
    "end": "2381140"
  },
  {
    "text": "And one somewhat\nunfortunately common approach is, we think about how we teach\nmachine how we think we think.",
    "start": "2381140",
    "end": "2390710"
  },
  {
    "text": "So meaning, we\nmodel how we think and then try to incorporate\nthat into some kind",
    "start": "2390710",
    "end": "2397339"
  },
  {
    "text": "of mathematical\nmodel and teach that. And now, the question\nis, do we understand how we think at the very low level?",
    "start": "2397340",
    "end": "2403880"
  },
  {
    "text": "I don't think we do. I have no idea what's going on. So it's fundamentally\nflawed in the sense",
    "start": "2403880",
    "end": "2408950"
  },
  {
    "text": "that we try to model something\nthat we have no idea about. And what happens if we go\nwith this kind of approach",
    "start": "2408950",
    "end": "2414589"
  },
  {
    "text": "is that, it poses\na structure that serves as a shortcut\nin the short term, and so you can maybe get\na paper or something.",
    "start": "2414590",
    "end": "2421370"
  },
  {
    "text": "But then it becomes\na bottleneck when-- because we don't know how this\nwill limit further scaling up.",
    "start": "2421370",
    "end": "2428870"
  },
  {
    "text": "More fundamentally\nwhat this is doing is, we are limiting\nthe degree of freedom we are giving to the\nmachines, and that",
    "start": "2428870",
    "end": "2436040"
  },
  {
    "text": "will backfire at some point. And this has been\ngoing on for decades.",
    "start": "2436040",
    "end": "2442010"
  },
  {
    "text": "And bitter lesson is, I think\nthe single most important piece",
    "start": "2442010",
    "end": "2447050"
  },
  {
    "text": "of writing in AI. And it says, this is\nmy wording by the way. Say past 70 years of\nentire AI research",
    "start": "2447050",
    "end": "2454190"
  },
  {
    "text": "can be summarized into\ndeveloping progressively more general method with\nweaker modeling",
    "start": "2454190",
    "end": "2460370"
  },
  {
    "text": "assumptions or inductive\nbiases, and add more data and compute, in\nother words scale up. And that has been the recipe\nof entire AI research, not",
    "start": "2460370",
    "end": "2469369"
  },
  {
    "text": "fancy things. And if you think about\nthis, the models of 2000",
    "start": "2469370",
    "end": "2474470"
  },
  {
    "text": "is a lot more difficult\nthan what we use now. And so it's much easier\nto get into AI nowadays",
    "start": "2474470",
    "end": "2481010"
  },
  {
    "text": "from technical perspective. So this is, I think, the\nreally the key information.",
    "start": "2481010",
    "end": "2487700"
  },
  {
    "text": "We have this compute cost\nis going down exponentially, and it's getting cheaper faster\nthan we are becoming a better",
    "start": "2487700",
    "end": "2494119"
  },
  {
    "text": "researcher. So don't compete with that and\njust try to leverage that as much as possible, and\nthat is the driving force",
    "start": "2494120",
    "end": "2500809"
  },
  {
    "text": "that I wanted to identify. And I'm not saying this\nis the only driving force,",
    "start": "2500810",
    "end": "2506265"
  },
  {
    "text": "but this is the\ndominant driving force, so we can probably\nneglect the other ones. So here's a graphical\nversion of that.",
    "start": "2506265",
    "end": "2512030"
  },
  {
    "text": "x-axis we have a\ncompute, y-axis we have a performance of some kind. Let's think about some\ngeneral intelligence.",
    "start": "2512030",
    "end": "2517700"
  },
  {
    "text": "And let's look at two\ndifferent methods. One, with more structure,\nmore modeling assumptions,",
    "start": "2517700",
    "end": "2523280"
  },
  {
    "text": "fancier math, whatever. And then the other one\nis a less structure. What you see is typically, you\nstart with a better performance",
    "start": "2523280",
    "end": "2530750"
  },
  {
    "text": "when you have a\nlow compute regime, and then but it plateaus\nbecause of some kind of structure backfiring.",
    "start": "2530750",
    "end": "2536158"
  },
  {
    "text": "And then with the less\nstructure because we give a lot more\nfreedom to the model, it doesn't work\nin the beginning.",
    "start": "2536158",
    "end": "2541369"
  },
  {
    "text": "But then as we add more\ncompute, it starts working, and then it gets better, we\ncall this more scalable method.",
    "start": "2541370",
    "end": "2548370"
  },
  {
    "text": "So does that mean we should\njust go with the least structure, most freedom\nto the model possible way",
    "start": "2548370",
    "end": "2555530"
  },
  {
    "text": "from the get go? And the answer\nis, obviously, no. Let's think about even\nless structured case. This red one here is, it\nwill pick up a lot later",
    "start": "2555530",
    "end": "2564500"
  },
  {
    "text": "and requires a lot more compute. So it really depends\non where we are.",
    "start": "2564500",
    "end": "2569599"
  },
  {
    "text": "We cannot indefinitely wait\nfor the most general case. And so let's think\nabout the case",
    "start": "2569600",
    "end": "2574940"
  },
  {
    "text": "where our compute situation\nis at this dotted line. If we're here, we should\nchoose this last structure",
    "start": "2574940",
    "end": "2581060"
  },
  {
    "text": "one as opposed to this\neven less structure one because the other one\ndoesn't really work and the other one works.",
    "start": "2581060",
    "end": "2587000"
  },
  {
    "text": "But crucially, we\nneed to remember that we are adding some\nstructure because we don't have compute, so we\nneed to remove that later.",
    "start": "2587000",
    "end": "2593990"
  },
  {
    "text": "And so the difference\nbetween these two methods is that additional inductive\nbiases or structure we impose,",
    "start": "2593990",
    "end": "2600319"
  },
  {
    "text": "somewhat impose that\ntypically don't get removed. So adding this.",
    "start": "2600320",
    "end": "2606080"
  },
  {
    "text": "What that means is\nthat, at the given level of compute data\nalgorithmic development",
    "start": "2606080",
    "end": "2611569"
  },
  {
    "text": "and architecture\nthat we have, there's like an optimal inductive\nbias or structure that we can add to the\nproblem to make the progress.",
    "start": "2611570",
    "end": "2619520"
  },
  {
    "text": "And that has been really how\nwe have made so much progress. But these are like shortcuts\nthat hinder further scaling",
    "start": "2619520",
    "end": "2625609"
  },
  {
    "text": "later on, so we\nhave to remove them later on when we have more\ncompute, better algorithm, or whatever.",
    "start": "2625610",
    "end": "2631750"
  },
  {
    "text": "And as a community, we do\nadding structure very well and because there's an incentive\nstructure with like papers.",
    "start": "2631750",
    "end": "2639119"
  },
  {
    "text": "You add a nice one\nthen you get a paper. But removing that doesn't\nreally get you much,",
    "start": "2639120",
    "end": "2644310"
  },
  {
    "text": "so that we don't really do that. And I think we should\ndo a lot more of those. So maybe another implication\nof this bitter lesson",
    "start": "2644310",
    "end": "2651900"
  },
  {
    "text": "is that, because of this what\nis better in the long-term almost necessarily\nlooks worse now.",
    "start": "2651900",
    "end": "2659069"
  },
  {
    "text": "And this is quite\nunique to AI research because the AI research\nof current paradigm",
    "start": "2659070",
    "end": "2665580"
  },
  {
    "text": "is learning based method. Meaning that we are\ngiving models freedom,",
    "start": "2665580",
    "end": "2670590"
  },
  {
    "text": "the machines choose\nhow they learn. So because we need to give\nmore freedom, it gives--",
    "start": "2670590",
    "end": "2676529"
  },
  {
    "text": "it's a more chaotic at the\nbeginning, so it doesn't work. But then when it\nstarted working,",
    "start": "2676530",
    "end": "2681900"
  },
  {
    "text": "we can put in more compute\nand then it can be better, so it's really important\nto have this in mind.",
    "start": "2681900",
    "end": "2687860"
  },
  {
    "text": "So to summarize, we have\nidentified this dominant driving force behind the AI\nresearch, and that",
    "start": "2687860",
    "end": "2694580"
  },
  {
    "text": "is this exponentially\ncheaper compute, and associated scaling up.",
    "start": "2694580",
    "end": "2699800"
  },
  {
    "text": "Now, that we have identified\nif you remember back from my initial slides,\nwe-- the next step",
    "start": "2699800",
    "end": "2705019"
  },
  {
    "text": "is to understand this\ndriving force better. And so that we're going to spend\nmost of the time doing that.",
    "start": "2705020",
    "end": "2711830"
  },
  {
    "text": "And for that, we need to go back\nto some history of transformer because this is a\ntransformers class",
    "start": "2711830",
    "end": "2717675"
  },
  {
    "text": "and analyze key\nstructures and decisions that were made by the\nresearchers at the time,",
    "start": "2717675",
    "end": "2723740"
  },
  {
    "text": "and why they did that. Whether that was an\noptimal structure that could have been\nadded at the time,",
    "start": "2723740",
    "end": "2728960"
  },
  {
    "text": "and why they might be irrelevant\nnow, and should we remove that? And we'll go through some\nof the practices of this.",
    "start": "2728960",
    "end": "2735560"
  },
  {
    "text": "And hopefully,\nthis will give you some flavor of what scaling\nresearch looks like.",
    "start": "2735560",
    "end": "2742020"
  },
  {
    "text": "So now, we'll go into a little\nbit of the technical stuff, tech transformer architecture,\nthere are some variants.",
    "start": "2742020",
    "end": "2748550"
  },
  {
    "text": "I'll talk about three of them. First, is the\nencoder-decoder, which is the original transformer,\nwhich has a little bit",
    "start": "2748550",
    "end": "2754640"
  },
  {
    "text": "more structure. Second one is the encoder-only,\nwhich is popularized by Bert.",
    "start": "2754640",
    "end": "2759710"
  },
  {
    "text": "And then third one\nis decoder-only, which you can think of it\nas a current like GPT-3",
    "start": "2759710",
    "end": "2765770"
  },
  {
    "text": "or other language models,\nthis has a lot less structure than the encoder-decoder. So these are the three\ntypes we'll go into detail.",
    "start": "2765770",
    "end": "2772820"
  },
  {
    "text": "Second, the encoder-only\nis actually not that useful in the\nmost general sense. It still has some place,\nbut we will just briefly",
    "start": "2772820",
    "end": "2781369"
  },
  {
    "text": "go over that, and\nthen spend most of the time comparing 1 and 3. So one has more structure,\nwhat's the implication of that",
    "start": "2781370",
    "end": "2788089"
  },
  {
    "text": "and so on? So first of all, let's think\nabout what a transformer is, just at a very high level.",
    "start": "2788090",
    "end": "2795619"
  },
  {
    "text": "Or first principles,\nwhat is a transformer? Is a sequence model. And sequence model is has\nan input of a sequence.",
    "start": "2795620",
    "end": "2802190"
  },
  {
    "text": "So sequence can be--\na sequence of elements can be words, or\nimages, or whatever.",
    "start": "2802190",
    "end": "2807680"
  },
  {
    "text": "It's a very general concept. In this particular example\nI show you with the words, sentence is a sequence of words.",
    "start": "2807680",
    "end": "2813530"
  },
  {
    "text": "And then we the first\nstep is to tokenize it because we have to represent\nthis word in computers which",
    "start": "2813530",
    "end": "2820730"
  },
  {
    "text": "requires some kind\nof encoding scheme, so we just do it with a\nfixed number of integers,",
    "start": "2820730",
    "end": "2827420"
  },
  {
    "text": "and then we have now a\nsequence of integers. And then the dominant\nparadigm nowadays",
    "start": "2827420",
    "end": "2832760"
  },
  {
    "text": "is to represent each\nsequence element as a vector, dense\nvector, because we know how to multiply them well.",
    "start": "2832760",
    "end": "2838530"
  },
  {
    "text": "And then so we have a\nsequence of vectors. And finally, this sequence\nmodel will do the following.",
    "start": "2838530",
    "end": "2845540"
  },
  {
    "text": "We just want to model the\ninteraction between sequence elements. And we do that by let them take\nthe dot product of each other.",
    "start": "2845540",
    "end": "2853940"
  },
  {
    "text": "And if the dot\nproduct is high, we can say semantically\nthey are more related than the dot\nproducts that is low,",
    "start": "2853940",
    "end": "2859550"
  },
  {
    "text": "and that's kind of\nthe sequence model. And the transformer is a\nparticular type of sequence model that uses what's called\nattention to model this",
    "start": "2859550",
    "end": "2869510"
  },
  {
    "text": "interaction . So let's get into the details\nof this encoder-decoder, which was the original transformer.",
    "start": "2869510",
    "end": "2875720"
  },
  {
    "text": "It's quite many, many pieces. So let's go into a little\nbit a piece at a time. So starting with the encoder.",
    "start": "2875720",
    "end": "2881780"
  },
  {
    "text": "So here I'm going to\nshow you an example of machine translation, which\nused to be very cool thing.",
    "start": "2881780",
    "end": "2887930"
  },
  {
    "text": "And so you are-- you have an\nEnglish sentence that is good, and then we're going to\ntranslate it into German.",
    "start": "2887930",
    "end": "2893480"
  },
  {
    "text": "So first thing is to encode\nthis into a dense vector. So here I'm representing\nit with this a vector",
    "start": "2893480",
    "end": "2901309"
  },
  {
    "text": "of size three or something. And then we have to let\nthem take the dot product. So this lines\nrepresent which element",
    "start": "2901310",
    "end": "2909170"
  },
  {
    "text": "can talk to which\nelement, other elements. And here because\nit's an input, we",
    "start": "2909170",
    "end": "2914190"
  },
  {
    "text": "take what is called a\nbidirectional attention, so any token can talk\nto any other token. And then we have this\nMLP or feedforward",
    "start": "2914190",
    "end": "2921029"
  },
  {
    "text": "layer which is per token, it\ndoesn't have any interaction, we just do some multiplication\njust because we can do it.",
    "start": "2921030",
    "end": "2929190"
  },
  {
    "text": "And then that's one layer,\nand we repeat that n times, and that's just the\ntransformer encoder.",
    "start": "2929190",
    "end": "2935490"
  },
  {
    "text": "And at the end, what you get\nis the sequence of vectors each representing the sequence\nelement in this case a word.",
    "start": "2935490",
    "end": "2944340"
  },
  {
    "text": "So that's the output\nof this encoder. Now, let's look at\nthe decoder, which is similarly shaped\nstack of layers.",
    "start": "2944340",
    "end": "2951210"
  },
  {
    "text": "So here we put in as an input\nwhat the answer should be.",
    "start": "2951210",
    "end": "2956910"
  },
  {
    "text": "So here, BOS, is the\nbeginning of sequence, and then das ist gut, I don't\nknow how to pronounce it, but that's the German\ntranslation of, that is good.",
    "start": "2956910",
    "end": "2963750"
  },
  {
    "text": "And so we kind of go\nthrough the similar process. Here we have a causal\nself-attention,",
    "start": "2963750",
    "end": "2968820"
  },
  {
    "text": "meaning that the tokens of time\nstep t can only attend to t and before because when\nwe start generating it,",
    "start": "2968820",
    "end": "2976110"
  },
  {
    "text": "we don't have the future\ntokens, so we cannot-- when we train it, we should\nlimit that, and that way,",
    "start": "2976110",
    "end": "2982270"
  },
  {
    "text": "this is done by like\nmasking, but this is different from the encoder.",
    "start": "2982270",
    "end": "2987300"
  },
  {
    "text": "So after this, you can get-- after again, n layers, you\nget this sequence output,",
    "start": "2987300",
    "end": "2994830"
  },
  {
    "text": "and you have this--\nthe output of sequence, to sequence, to\nsequence mapping, this is a general\nencoder-decoder architecture.",
    "start": "2994830",
    "end": "3001520"
  },
  {
    "text": "And when you get\nthis end of sequence, you stop generating it. So this is the overall picture.",
    "start": "3001520",
    "end": "3007070"
  },
  {
    "text": "Now, I'll point out some\nimportant attention patterns. So we are translating\ninto German what",
    "start": "3007070",
    "end": "3014359"
  },
  {
    "text": "is into input to the encoder. So there has to be some\nconnection between the decoder and the encoder that is\ndone by this cross attention",
    "start": "3014360",
    "end": "3020930"
  },
  {
    "text": "mechanism shown in this red,\nwhich is just that each vector representation of each\nsequence in the output decoder",
    "start": "3020930",
    "end": "3028220"
  },
  {
    "text": "should attend to some of them in\nthe encoder, and that is done. In particular the design\nfeature which is interesting",
    "start": "3028220",
    "end": "3034880"
  },
  {
    "text": "is that all the\nlayers in the decoder attend to the final layer\noutput of the encoder,",
    "start": "3034880",
    "end": "3040670"
  },
  {
    "text": "and we'll come back to the\nimplication of this design. So yeah, that's that.",
    "start": "3040670",
    "end": "3046400"
  },
  {
    "text": "And now, move on to the\nsecond type of architecture, which is encoder-only. We'll spend a little\nbit of time here.",
    "start": "3046400",
    "end": "3052213"
  },
  {
    "text": "So again, we have to-- we have the same input, and we\ngo through a similar structure.",
    "start": "3052213",
    "end": "3059150"
  },
  {
    "text": "And then in this case, the\nfinal output is a single vector. Regardless of the\nlength of the sequence,",
    "start": "3059150",
    "end": "3065270"
  },
  {
    "text": "we just get a single vector. And that is that represent\nthe input sequence, that's",
    "start": "3065270",
    "end": "3071059"
  },
  {
    "text": "a dense vector representation. And then let's say we do some\nkind of a sentiment analysis,",
    "start": "3071060",
    "end": "3076069"
  },
  {
    "text": "we run through a task\nspecific linear layer to map it to\nclassification label positive or negative\nprobabilities here.",
    "start": "3076070",
    "end": "3082910"
  },
  {
    "text": "And that's required for all\nthese task specific cases.",
    "start": "3082910",
    "end": "3088099"
  },
  {
    "text": "And this is kind of\npopularized by Bert. And what this means is\nthat, here at the time,",
    "start": "3088100",
    "end": "3094010"
  },
  {
    "text": "2018, when Bert came out we\nhad the benchmark called glue, which was a language\nunderstanding task.",
    "start": "3094010",
    "end": "3100220"
  },
  {
    "text": "You have a sequence in\nclassification labels out for most cases. This was how the field\nreally advanced at the time.",
    "start": "3100220",
    "end": "3106750"
  },
  {
    "text": "So when we care\nabout such tasks, then there's an\nincentive to think about simplifying\nthe problem, adding",
    "start": "3106750",
    "end": "3112619"
  },
  {
    "text": "the structure to the problem\nso that we can make a progress. So this, the\nadditional structure that was put into this\nparticular architecture",
    "start": "3112620",
    "end": "3118829"
  },
  {
    "text": "is that we're going to\ngive up on the generation. If we do that, it becomes\na lot simpler problem.",
    "start": "3118830",
    "end": "3125460"
  },
  {
    "text": "Instead of sequence to sequence,\nwe're talking about sequence to classification labels, and\nthat's just so much easier.",
    "start": "3125460",
    "end": "3131460"
  },
  {
    "text": "And so at some point, 2018,\n2019, a lot of the papers",
    "start": "3131460",
    "end": "3136560"
  },
  {
    "text": "are just research was\nlike, we sometimes call it Bert engineers, a\nlittle bit change of something get like 0.5% better\non glue, and you get",
    "start": "3136560",
    "end": "3144720"
  },
  {
    "text": "a paper, and things like that. It was very chaotic error, and-- but if we look at\nfrom this perspective,",
    "start": "3144720",
    "end": "3151710"
  },
  {
    "text": "we are putting the sequence\nstructure of not generating the sequence that puts a\nlot of performance win,",
    "start": "3151710",
    "end": "3158700"
  },
  {
    "text": "but in the long term,\nit's not really useful. So we're not going to look at\nthis encoder-only architecture",
    "start": "3158700",
    "end": "3164010"
  },
  {
    "text": "going forward. Third architecture,\ndecoder-only. This one is my\nfavorite personally.",
    "start": "3164010",
    "end": "3169430"
  },
  {
    "text": "And it looks kind of daunting\nbecause of this attention pattern, but it\nactually is very simple.",
    "start": "3169430",
    "end": "3176300"
  },
  {
    "text": "So here, we only\nhave a single stack, and it can actually\ngenerate stuff.",
    "start": "3176300",
    "end": "3181400"
  },
  {
    "text": "And so there's misconception\nthat some people think this decoder-only architecture is\nused for language modeling next",
    "start": "3181400",
    "end": "3188119"
  },
  {
    "text": "to prediction, so it cannot be\nused for supervised learning. But here, we can actually do it. The trick is to have\nthis input that is good,",
    "start": "3188120",
    "end": "3195170"
  },
  {
    "text": "concatenate it with the target. And if you do that,\nthen it just becomes simple to sequence\nin sequence out.",
    "start": "3195170",
    "end": "3201440"
  },
  {
    "text": "So what we do is, the\nself-attention mechanism here is actually handling\nboth the cross attention",
    "start": "3201440",
    "end": "3207950"
  },
  {
    "text": "between target and the input,\nand self-attention sequence learning within each. So that's the causal attention.",
    "start": "3207950",
    "end": "3214490"
  },
  {
    "text": "And then as I mentioned,\nthe output is a sequence, and then the key\ndesign features are",
    "start": "3214490",
    "end": "3220790"
  },
  {
    "text": "self-attention is\nserving both roles, and we are in some sense sharing\nthe parameters between input",
    "start": "3220790",
    "end": "3227040"
  },
  {
    "text": "and target. So same set of parameters\nare applied to both input and the target sequences. So this is the\ndecoder only, now,",
    "start": "3227040",
    "end": "3234329"
  },
  {
    "text": "we will go into the comparison. So I think there are many-- like they look very different,\nat least, on the schematics.",
    "start": "3234330",
    "end": "3241410"
  },
  {
    "text": "So how different\nare they actually? And I argue that they're\nactually quite similar.",
    "start": "3241410",
    "end": "3247769"
  },
  {
    "text": "And so to illustrate\nthat we're going to transform starting from\nthis encoder-decoder which has more structures\nbuilt in, and then",
    "start": "3247770",
    "end": "3254610"
  },
  {
    "text": "into the decoder-only\narchitecture and see what are some\nof the differences.",
    "start": "3254610",
    "end": "3259740"
  },
  {
    "text": "And then interpret\nthose differences, those additional structures,\nare they relevant nowadays now that we have more compute\nbetter algorithm and so on?",
    "start": "3259740",
    "end": "3268030"
  },
  {
    "text": "So let's have this\ntable, four differences we'll see each of them. And then as we go through,\nwe will populate this table.",
    "start": "3268030",
    "end": "3276240"
  },
  {
    "text": "So let's first look at this\nadditional cross-attention. What that means is\nthat, this on the left",
    "start": "3276240",
    "end": "3282029"
  },
  {
    "text": "is an encoder-decoder, which\nhas this additional red block, the cross-attention\ncompared to the simpler one that doesn't have that.",
    "start": "3282030",
    "end": "3287760"
  },
  {
    "text": "So we want to make it, make\nthe left closer to the right, so that means we need to either\nget rid of it or something.",
    "start": "3287760",
    "end": "3295050"
  },
  {
    "text": "And attention mechanism has kind\nof the four projection matrices, and so self-attention and\ncross attention actually",
    "start": "3295050",
    "end": "3301881"
  },
  {
    "text": "have the same number of\nparameters, same shape, so we can just share them. So that's the first step,\nshare both of these,",
    "start": "3301882",
    "end": "3307170"
  },
  {
    "text": "and then it becomes\nmostly the same mechanism. And then so that's\nthe first difference",
    "start": "3307170",
    "end": "3312240"
  },
  {
    "text": "separate cross-attention\nor self-attention serving both roles. Second difference is\nthe parameter sharing.",
    "start": "3312240",
    "end": "3317730"
  },
  {
    "text": "So what that means is\nthat, between the input and the target,\nencoder-decoder architecture",
    "start": "3317730",
    "end": "3323580"
  },
  {
    "text": "uses a separate parameters. And decoder-only only\nhas a single stack so it uses the shared parameter.",
    "start": "3323580",
    "end": "3329530"
  },
  {
    "text": "So if we want to make\nthe left close to right, we want to share the encoder\nparameters, so let's do that.",
    "start": "3329530",
    "end": "3335110"
  },
  {
    "text": "I just color this, so now,\nthey share the parameters. Third difference is the target\nto input attention pattern.",
    "start": "3335110",
    "end": "3341590"
  },
  {
    "text": "So we need to connect\nthe target to the input. And how does that--\nhow is it done? In the encoder-decoder case,\nwe had this cross attention.",
    "start": "3341590",
    "end": "3349090"
  },
  {
    "text": "And then in the decoder-only,\nit's a per the self-attention doing everything.",
    "start": "3349090",
    "end": "3354370"
  },
  {
    "text": "What the difference\nis that we have this every layer of the decoder\nattending to the final layer",
    "start": "3354370",
    "end": "3362020"
  },
  {
    "text": "output of the encoder, whereas\nif you think about this decoder is actually per\nlayer, within layer",
    "start": "3362020",
    "end": "3367510"
  },
  {
    "text": "when we are decoding\nthe say word thus, we are looking at the same layer\nrepresentation of the encoder,",
    "start": "3367510",
    "end": "3375460"
  },
  {
    "text": "and that's within\nlayer, and I think this is the design feature. So if we want to make\nthis close to that,",
    "start": "3375460",
    "end": "3380770"
  },
  {
    "text": "we have to bring back this\nattention to each layer. So now, layer 1 will be\nattending to layer 1 of this.",
    "start": "3380770",
    "end": "3388090"
  },
  {
    "text": "And that's then finally,\nthe last difference is the input attention.",
    "start": "3388090",
    "end": "3393250"
  },
  {
    "text": "I mentioned about this\nbidirectional attention. And because we have this\ndecoder only typically,",
    "start": "3393250",
    "end": "3398770"
  },
  {
    "text": "with the unidirectional\nattention, we need to make them\nmatching, so that's the we can just get rid of it.",
    "start": "3398770",
    "end": "3405099"
  },
  {
    "text": "I just got rid of the\nsome of the arrows. So then at this point,\nthese two architectures",
    "start": "3405100",
    "end": "3411250"
  },
  {
    "text": "are almost identical. A little bit of difference\nin the cross attention, but same number of parameters.",
    "start": "3411250",
    "end": "3416829"
  },
  {
    "text": "And if you have\nin deep learning, if you just train these,\nthese two architecture in the same task,\nsame data, I think,",
    "start": "3416830",
    "end": "3422810"
  },
  {
    "text": "you will get pretty much\nwithin the noise, probably closer than if you train\nthe same thing twice. So I would say\nthey are identical.",
    "start": "3422810",
    "end": "3429829"
  },
  {
    "text": "And so these are the\nmain differences. Now, we'll look at what are\nthe additional structures, what",
    "start": "3429830",
    "end": "3436220"
  },
  {
    "text": "they mean, it means. So yeah. That's the populated\ntable now, and then",
    "start": "3436220",
    "end": "3441950"
  },
  {
    "text": "so we can say that\nencoder-decoder compared to the decoder-only architecture\nhas these additional structures",
    "start": "3441950",
    "end": "3449510"
  },
  {
    "text": "inductive biases built in, so\nlet's go into each of them. The first one is what\nencoder-decoder tries added",
    "start": "3449510",
    "end": "3457400"
  },
  {
    "text": "as a structure is that, input\nand the target sequences are sufficiently different that we-- it will be useful to use a\nseparate parameters, that's",
    "start": "3457400",
    "end": "3465140"
  },
  {
    "text": "the assumption. And so why is that a useful? When can that\nassumption be useful?",
    "start": "3465140",
    "end": "3471110"
  },
  {
    "text": "And one example is\nmachine translation. Back when the transformer\nwas introduced in 2017,",
    "start": "3471110",
    "end": "3476690"
  },
  {
    "text": "translation was\nreally popular task, and it was difficult,\nconsidered difficult. And because it's a\nsequence-to-sequence",
    "start": "3476690",
    "end": "3483650"
  },
  {
    "text": "and you can actually\nhave a blue score which is heuristic based\nmethod that can give you a single number and then\npeople can optimize that.",
    "start": "3483650",
    "end": "3490320"
  },
  {
    "text": "So what that in\nthat task, we have this input and target in\ncompletely different languages.",
    "start": "3490320",
    "end": "3496280"
  },
  {
    "text": "So if the goal is to\nlearn translation only, then it kind of\nmakes sense to have, OK, this parameter\nin the encoder",
    "start": "3496280",
    "end": "3502490"
  },
  {
    "text": "will take care of the\nEnglish, and this parameter in the decoder will take care of\nthe German, that seems natural.",
    "start": "3502490",
    "end": "3508190"
  },
  {
    "text": "And what about now? Modern language models is\nabout learning knowledge.",
    "start": "3508190",
    "end": "3513530"
  },
  {
    "text": "And it's not just\nabout translation or not even about\nlanguage, languages comes up as a byproduct of\ndoing this next token prediction",
    "start": "3513530",
    "end": "3521000"
  },
  {
    "text": "and translation as well. So does it make sense to\nhave a separate parameter for this kind of situation now?",
    "start": "3521000",
    "end": "3528890"
  },
  {
    "text": "We have some\nknowledge in German, some knowledge in English,\nand we-- if anything",
    "start": "3528890",
    "end": "3534320"
  },
  {
    "text": "we want to combine them. And if we represent them\nin a separate parameters, I don't think that's natural.",
    "start": "3534320",
    "end": "3539510"
  },
  {
    "text": "So I would say with this much\nmore general, larger models that can do a lot of\nthings, this assumption",
    "start": "3539510",
    "end": "3547010"
  },
  {
    "text": "seems very unnatural to me. Second example is a\nlittle bit more modern. Two years ago when I was\nat Google and with Jason,",
    "start": "3547010",
    "end": "3554900"
  },
  {
    "text": "we did this instruction\nfine tuning work. And what this is, is you take\nthe pre-trained model, and then",
    "start": "3554900",
    "end": "3561440"
  },
  {
    "text": "just fine tune on\nacademic data set, and so that it can understand\nthe natural language",
    "start": "3561440",
    "end": "3566540"
  },
  {
    "text": "instruction. So the detail doesn't\nmatter, but here let's think about\nthe performance gain",
    "start": "3566540",
    "end": "3572599"
  },
  {
    "text": "by doing this fine tuning on\ntwo different architectures we tried. So first five is\nthe Flan-T5, which",
    "start": "3572600",
    "end": "3579200"
  },
  {
    "text": "is T5 base which is the\nencoder-decoder architecture. Last one, the latter five\ndecoder-only architecture",
    "start": "3579200",
    "end": "3585440"
  },
  {
    "text": "based on PaLM. So we spent 99% of the time on\nPaLM, optimizing a lot of these,",
    "start": "3585440",
    "end": "3592400"
  },
  {
    "text": "and then at the end we just\nspent like three days on T5. But the performance gain\nwas a lot higher on this.",
    "start": "3592400",
    "end": "3598320"
  },
  {
    "text": "And I was really confused about\nthis, and in a very good way. And after the paper\nwas published,",
    "start": "3598320",
    "end": "3603440"
  },
  {
    "text": "I wanted to take a little\nbit deeper into why this might be the case. So my hypothesis is that,\nit's about the length.",
    "start": "3603440",
    "end": "3612200"
  },
  {
    "text": "So academic data sets we\nuse, we use like 1,832 tasks. And here they have this very\ndistinctive characteristic",
    "start": "3612200",
    "end": "3620450"
  },
  {
    "text": "where we have a long\ninput, long in order to make the task more difficult. But then we cannot make the\ntarget long because if we do,",
    "start": "3620450",
    "end": "3627529"
  },
  {
    "text": "there's no way to create it, so\nthere's fundamental challenge of that. So what happens is, you\nhave a long text of input",
    "start": "3627530",
    "end": "3634250"
  },
  {
    "text": "and then short\ntext of the target. And so this is kind of the\nlength distribution of what it",
    "start": "3634250",
    "end": "3639860"
  },
  {
    "text": "went into the Flan fine tuning. So then you see this, you\nhave a very different sequence",
    "start": "3639860",
    "end": "3647240"
  },
  {
    "text": "going into the\nencoder as an input, and the very different type of\nsequence going into the target. So now, this\nencoder-decoder architecture",
    "start": "3647240",
    "end": "3654745"
  },
  {
    "text": "has an assumption that they\nwill be very different. That structure really\nshines because of this.",
    "start": "3654745",
    "end": "3660280"
  },
  {
    "text": "It was a kind of an accident,\nbut that was, I think, why this really architecture was\njust suitable for fine tuning",
    "start": "3660280",
    "end": "3668650"
  },
  {
    "text": "with the academic data sets. What about now? Do we care about this\nkind of assumption?",
    "start": "3668650",
    "end": "3674109"
  },
  {
    "text": "And if you think about the\ngeneral use cases of language models nowadays, if anything\nthe more interesting cases",
    "start": "3674110",
    "end": "3680920"
  },
  {
    "text": "involve longer\ngeneration, longer target. Just because we\ncannot grade them,",
    "start": "3680920",
    "end": "3686680"
  },
  {
    "text": "doesn't mean that we are\nnot interested in them. Actually, if anything we\nare more interested in that. So now we have this\nlonger target situation,",
    "start": "3686680",
    "end": "3694060"
  },
  {
    "text": "so this separate sequence\nlength parameter doesn't seem to make much sense. And moreover, we\nthink about this chat",
    "start": "3694060",
    "end": "3701710"
  },
  {
    "text": "application like ChatGPT, we\ndo multi-turn conversation. And then so what is\na target of this turn",
    "start": "3701710",
    "end": "3708099"
  },
  {
    "text": "becomes the input\nof the next turn. And then my question\nis, does that make sense to even think\nabout a different parameters",
    "start": "3708100",
    "end": "3716110"
  },
  {
    "text": "if next turn is going\nto be the same thing? So that was the first inductive\nbias we just mentioned.",
    "start": "3716110",
    "end": "3724060"
  },
  {
    "text": "And then the second structure\nis that, target element can only attend to the fully encoded\nones, the final output",
    "start": "3724060",
    "end": "3730660"
  },
  {
    "text": "of the encoder. Let's look at this additional\nstructure, what that means. So as I mentioned, we have this\nvery top layer attending to it.",
    "start": "3730660",
    "end": "3739670"
  },
  {
    "text": "And so in deep neural\nnets, typically, we see that the bottom\nlayers and the top layers",
    "start": "3739670",
    "end": "3745150"
  },
  {
    "text": "encode information at\na very different level. Meaning that, for example, in\ncomputer vision, lower layer--",
    "start": "3745150",
    "end": "3751300"
  },
  {
    "text": "the bottom layers\nencode something like edges, top layers, higher\nlevels combining the features,",
    "start": "3751300",
    "end": "3756730"
  },
  {
    "text": "something like cat face. And so we call\nthis deep learning a hierarchical representation\nlearning method.",
    "start": "3756730",
    "end": "3763180"
  },
  {
    "text": "And so now the question is,\nif decoder layer one attends to encoder final\nlayer, which probably",
    "start": "3763180",
    "end": "3770740"
  },
  {
    "text": "has a very different\nlevel of information, is that some kind of an\ninformation bottleneck which actually motivated the\noriginal attention mechanism?",
    "start": "3770740",
    "end": "3779290"
  },
  {
    "text": "And in practice I would say in\nmy experience doesn't really make any difference, and that's\nbecause my experience was",
    "start": "3779290",
    "end": "3785900"
  },
  {
    "text": "limited to say 25, 24\nlayers of encoder of T5. So layer one attended\nto 24, probably fine.",
    "start": "3785900",
    "end": "3792620"
  },
  {
    "text": "But what if we have 10x\nor 1,000x more layers, would that be problematic? I'm not really\ncomfortable with that.",
    "start": "3792620",
    "end": "3799520"
  },
  {
    "text": "So I think this is\nalso unnecessary design that maybe we need to revisit.",
    "start": "3799520",
    "end": "3805910"
  },
  {
    "text": "Final structure we're\ngoing to talk about is the, when we do this,\nthere's a bi-directional thing",
    "start": "3805910",
    "end": "3811642"
  },
  {
    "text": "in the encoder-decoder. Let's think about that. So yeah. Bi-directional input attention,\nis that really necessary?",
    "start": "3811642",
    "end": "3818180"
  },
  {
    "text": "So when we had this Bert, B in\nBert stands for bi-directional.",
    "start": "3818180",
    "end": "3824390"
  },
  {
    "text": "2018 when we were solving\nlike question answering squad, actually it was\nvery difficult task.",
    "start": "3824390",
    "end": "3829670"
  },
  {
    "text": "So if you have any\nadditional trick, it can make a huge difference. Bidirectionality\nwas really useful,",
    "start": "3829670",
    "end": "3836300"
  },
  {
    "text": "I think, maybe boosting up\nthe squad score by like 20, so it was really huge thing. But at scale, I don't think\nthis matters that much.",
    "start": "3836300",
    "end": "3844160"
  },
  {
    "text": "This is my highly anecdotal\nexperience, so we did in Flan-2, we tried both bi-directional\nand uni-directional fine tuning,",
    "start": "3844160",
    "end": "3852560"
  },
  {
    "text": "didn't really make\nmuch difference. So but I want to point\nout this bidirectionality,",
    "start": "3852560",
    "end": "3858050"
  },
  {
    "text": "actually bring in an\nengineering challenge for modern multi-turn\nchat application.",
    "start": "3858050",
    "end": "3863120"
  },
  {
    "text": "So at every turn, the new\ninput has to be encoded. Again, and for\nuni-directional attention",
    "start": "3863120",
    "end": "3868590"
  },
  {
    "text": "it's much, much better, so\nhere is what I mean by that. So let's think about this more\nmodern conversation between user",
    "start": "3868590",
    "end": "3875130"
  },
  {
    "text": "and assistant, how are you? Bad, and why? And so here, if we think\nabout the bi-directional case,",
    "start": "3875130",
    "end": "3881020"
  },
  {
    "text": "we will-- and when\nwe generate bad, we need to encode this input\nwith the bi-directional thing,",
    "start": "3881020",
    "end": "3886860"
  },
  {
    "text": "which is fine. And then after the\nbad is generated, when we're trying\nto generate why,",
    "start": "3886860",
    "end": "3892890"
  },
  {
    "text": "we'll need to encode how, again,\nbecause how can attend to bad, so we need to do everything\nfrom scratch again.",
    "start": "3892890",
    "end": "3901170"
  },
  {
    "text": "In contrast, if we do\nuni-directional one, we can do much, much better\nbecause now when we are trying",
    "start": "3901170",
    "end": "3907380"
  },
  {
    "text": "to generate why, we don't have\nto redo how because we cannot attend to the future tokens, so\nwe don't have to do anything.",
    "start": "3907380",
    "end": "3915150"
  },
  {
    "text": "So if you see the difference,\nthis part can be cached and then this part is\nthe only thing that can has to be encoded again.",
    "start": "3915150",
    "end": "3922236"
  },
  {
    "text": "So this kind of makes\na big difference when we think about\nmultiple turns going on. So I would say, bi-directional\nattention, that well, in 2018,",
    "start": "3922237",
    "end": "3931380"
  },
  {
    "text": "which is mostly sold\nby scale, and now because of this\nengineering challenge, we don't really need that.",
    "start": "3931380",
    "end": "3936990"
  },
  {
    "text": "So to conclude, we have looked\ninto this driving force, dominant driving force\ncovering this research,",
    "start": "3936990",
    "end": "3944250"
  },
  {
    "text": "and that was this\nexponentially cheaper compute and associated scaling effort.",
    "start": "3944250",
    "end": "3949320"
  },
  {
    "text": "And so to understand\nthis driving force, we analyzed some of the\nadditional structures added to the encoder-decoder\ncompared to the decoder only,",
    "start": "3949320",
    "end": "3957090"
  },
  {
    "text": "and then thought\nabout how-- what that means as a from the\nperspective of scaling. And I wanted to just\nconclude with this remark.",
    "start": "3957090",
    "end": "3966180"
  },
  {
    "text": "So we have looked at these kind\nof analysis, which are all-- one can say, this is\njust historical artifacts",
    "start": "3966180",
    "end": "3972570"
  },
  {
    "text": "and doesn't matter. But if you do many of these, now\nyou look at the current events. You can hopefully think about\nthose in a more unified manner",
    "start": "3972570",
    "end": "3981150"
  },
  {
    "text": "and then see, OK, what\nassumptions in my problem that I need to revisit?",
    "start": "3981150",
    "end": "3986549"
  },
  {
    "text": "And are they relevant? And if not, why? And you have an answer to it. Is can we do it with a more\ngeneral thing and scale up?",
    "start": "3986550",
    "end": "3992910"
  },
  {
    "text": "And so I hope you can\ngo back and really think about these problems. And together we can really\nshape the future of AI",
    "start": "3992910",
    "end": "4000290"
  },
  {
    "text": "in a really nice\nway, so that's it. Thanks. [APPLAUSE]",
    "start": "4000290",
    "end": "4006801"
  },
  {
    "start": "4006801",
    "end": "4022110"
  },
  {
    "text": "Hi, thank you for the talk. So about the mix of\nexpert structure.",
    "start": "4022110",
    "end": "4028530"
  },
  {
    "text": "If your saying, what you're\nsaying is correct then how long do you think\nthe mix of experts",
    "start": "4028530",
    "end": "4035560"
  },
  {
    "text": "is going to stay for the\nnew large language models?",
    "start": "4035560",
    "end": "4041010"
  },
  {
    "text": "So one thing I have to\napologize is the architecture is kind of a thing that I'm\nnot really comfortable sharing",
    "start": "4041010",
    "end": "4048330"
  },
  {
    "text": "a lot, that's why I'm limiting\na little bit to the future. So yeah, if you-- yeah, I'll\nprobably just skip that,",
    "start": "4048330",
    "end": "4057540"
  },
  {
    "text": "but I would say that\nseems quite general. ",
    "start": "4057540",
    "end": "4066560"
  },
  {
    "text": "So some of the changes\nthat you described between encoder-decoder\nversus decoder-only like the parameter sharing and\nthe bidirectional attention.",
    "start": "4066560",
    "end": "4074660"
  },
  {
    "text": "Can they not be interpreted\nas less structured or sorry, more structured, or less\nfreedom for the model to learn?",
    "start": "4074660",
    "end": "4082799"
  },
  {
    "text": "Yeah. I think one can do that, but\nI think somewhat subjective.",
    "start": "4082800",
    "end": "4088070"
  },
  {
    "text": "But I think it's a simpler\nstructure that the model kind of, if--",
    "start": "4088070",
    "end": "4093570"
  },
  {
    "start": "4093570",
    "end": "4098770"
  },
  {
    "text": "but we're just saying\nlike input and target are just sequences and we just,\nif we have enough capacity we",
    "start": "4098770",
    "end": "4105009"
  },
  {
    "text": "can just handle both. And there are other\ncases where like--",
    "start": "4105010",
    "end": "4112318"
  },
  {
    "text": "yeah, so-- yeah,\nI can totally see. Actually, maybe I should\nhave repeated the question. The question is, can we think\nabout this parameter sharing",
    "start": "4112319",
    "end": "4119790"
  },
  {
    "text": "other structures in the\nencoder-decoder as actually less structure? But I think it's a little\nbit more complicated model,",
    "start": "4119790",
    "end": "4125835"
  },
  {
    "text": "and that such\ncomplications of like it has more assumption, right? The input and target\nare different.",
    "start": "4125835",
    "end": "4131310"
  },
  {
    "text": "I think that's a stronger\nassumption than, OK, this is a sequence. We deal with the sequence\nin a unified way,",
    "start": "4131310",
    "end": "4136799"
  },
  {
    "text": "so that would be just my take. ",
    "start": "4136800",
    "end": "4146960"
  },
  {
    "text": "Do you have any thoughts\non the recent state space models like mamba? And how that fits into the\nparadigm of less structure",
    "start": "4146960",
    "end": "4153979"
  },
  {
    "text": "and more structure,\nwithout really [INAUDIBLE] working on an AI. Yeah. ",
    "start": "4153979",
    "end": "4160960"
  },
  {
    "text": "OK. It's hard to think\nabout it on the spot, but I think there are to me, I\ntalked about this architecture,",
    "start": "4160960",
    "end": "4169568"
  },
  {
    "text": "but I don't-- architecture is kind of a it\ndoesn't change things too much,",
    "start": "4169569",
    "end": "4176830"
  },
  {
    "text": "and maybe it's a-- I think multi-modalities\nmight bring in another challenges like when\nthis transformer structure might",
    "start": "4176830",
    "end": "4183970"
  },
  {
    "text": "become a bottleneck,\nwhen we think about that. But yeah.",
    "start": "4183970",
    "end": "4190359"
  },
  {
    "text": "So I think it's transformers\nI've done a good job. So maybe we should think\nabout it, especially",
    "start": "4190359",
    "end": "4196420"
  },
  {
    "text": "with the multi modalities. ",
    "start": "4196420",
    "end": "4202170"
  },
  {
    "text": "So like for cross-attention\nand casual attention it's like imposing\npermutation invariance",
    "start": "4202170",
    "end": "4208710"
  },
  {
    "text": "in a way for multi-head\nattention instead of causal? And then for computer\nvision, there's",
    "start": "4208710",
    "end": "4215340"
  },
  {
    "text": "like a lot of learning\nstructure for invariances, for self-supervised learning. What do you think about\nthose in terms of complexity",
    "start": "4215340",
    "end": "4222840"
  },
  {
    "text": "that you talk about? So the question is,\nthis causal attention versus the\nbidirectional attention.",
    "start": "4222840",
    "end": "4229230"
  },
  {
    "text": "They were probably fine\nin the text domain, but in the computer\nvision case, that being",
    "start": "4229230",
    "end": "4235350"
  },
  {
    "text": "able to attend to the future\npart of it is really important. Yeah, is that the question?",
    "start": "4235350",
    "end": "4241230"
  },
  {
    "text": "But also, like [INAUDIBLE]\nattention remove the invariants",
    "start": "4241230",
    "end": "4247860"
  },
  {
    "text": "for permutation? So what do you think about\ninvariant like for observation",
    "start": "4247860",
    "end": "4253260"
  },
  {
    "text": "like you learn a lot of\ninvariance for augmentation? So what do you think about\nthose as a way to structure?",
    "start": "4253260",
    "end": "4260690"
  },
  {
    "text": "So I think the-- I don't really like this\ninvariance and all these.",
    "start": "4260690",
    "end": "4265710"
  },
  {
    "text": "These are like how humans\nthink we perceive the vision. CNN, for example, is like\ntranslation invariance, which",
    "start": "4265710",
    "end": "4272760"
  },
  {
    "text": "was very important\nwe thought, but it's I don't think it's\nthat important. Actually, if anything now\nit's hurting the model",
    "start": "4272760",
    "end": "4279003"
  },
  {
    "text": "learning more general thing. And so the machines might\nbe learning the vision in a completely different\nway from how humans do,",
    "start": "4279003",
    "end": "4286170"
  },
  {
    "text": "and I don't think\nthat's problematic. So those invariances, I think,\nis like could be a good guiding",
    "start": "4286170",
    "end": "4292410"
  },
  {
    "text": "principle, but I don't-- I'm not too worried about just\nnot having such structures.",
    "start": "4292410",
    "end": "4299400"
  },
  {
    "text": "Yeah. I'll just try out\nlike just based on some metric if not having\nthe invariant structure",
    "start": "4299400",
    "end": "4306790"
  },
  {
    "text": "is actually better\nand more scalable, and I think that's probably\nfine, and actually even better. If we do it without the\nstructure it's actually better.",
    "start": "4306790",
    "end": "4313660"
  },
  {
    "text": " So I actually have\ntwo questions.",
    "start": "4313660",
    "end": "4319849"
  },
  {
    "text": "One, so clearly,\nyou've been thinking about how inductive\nbiases and structure limit",
    "start": "4319850",
    "end": "4325310"
  },
  {
    "text": "our potential essentially. So I'm just curious, what are\nsome fake inductive biases",
    "start": "4325310",
    "end": "4331940"
  },
  {
    "text": "currently that you think\nare big blocks that we can release as or let go of?",
    "start": "4331940",
    "end": "4338060"
  },
  {
    "text": "That would be one\nquestion to [INAUDIBLE].. The current structure\nthat we should get rid of?",
    "start": "4338060",
    "end": "4344120"
  },
  {
    "text": "Just current\ninductive biases you think because clearly, you've\nbeen thinking about this, right? So when you look at the state of\nresearch you must be thinking,",
    "start": "4344120",
    "end": "4351320"
  },
  {
    "text": "man, this is like a\npretty big inductive bias, it'd be really cool if\nwe could let this go. So I'm just trying\nto see what you're--",
    "start": "4351320",
    "end": "4358280"
  },
  {
    "text": "Yeah. So when I think about\nthis as an architecture,",
    "start": "4358280",
    "end": "4363679"
  },
  {
    "text": "I think, the\narchitectures are not the current\nbottleneck in my view, and so partly because I did\na lot of the architecture",
    "start": "4363680",
    "end": "4370170"
  },
  {
    "text": "research. And at the end, we published\nthis paper called, do-- like it's saying, OK, we\ntried 60 different transformer",
    "start": "4370170",
    "end": "4377340"
  },
  {
    "text": "modifications, pretty much the\nsame thing, and none of them really make sense,\nmake a huge difference.",
    "start": "4377340",
    "end": "4383310"
  },
  {
    "text": "Caveat with like now maybe the\nconclusion can be different. So I have a very huge bias\nagainst like not doing",
    "start": "4383310",
    "end": "4388320"
  },
  {
    "text": "the architecture research. And one message could be that,\nactually, the architecture is not the bottleneck\nin further scaling.",
    "start": "4388320",
    "end": "4393810"
  },
  {
    "text": "And I think what's\nthe bottleneck now is this learning\nobjective, especially on the supervised\nlearning paradigm,",
    "start": "4393810",
    "end": "4400080"
  },
  {
    "text": "or even like self-supervised\npre-training. What we're doing with\nthis maximum likelihood estimation is, OK, given this,\nthis is the only correct target",
    "start": "4400080",
    "end": "4407853"
  },
  {
    "text": "and everything else is incorrect\nbecause the probability measure is finite. So is that really a comfortable\nthing to do teaching signal",
    "start": "4407853",
    "end": "4415679"
  },
  {
    "text": "to give the model? And I think if we think\nabout the old days, we were-- we have a-- we could\nformalize the correct behavior",
    "start": "4415680",
    "end": "4423480"
  },
  {
    "text": "for a given input very well. And maybe one answer being the\nsingle correct answer is fine,",
    "start": "4423480",
    "end": "4428520"
  },
  {
    "text": "but now if we're thinking about\nvery general especially the chat applications, OK, for\nlike write a poem,",
    "start": "4428520",
    "end": "4434400"
  },
  {
    "text": "and then you say this is\nthe only correct answer, I think, that the implication\nthat could be really severe.",
    "start": "4434400",
    "end": "4441030"
  },
  {
    "text": "So I think that's\nreally something that I'm not comfortable\nwith, and partly why I'm interested in RLHF as one\ninstantiation of not using",
    "start": "4441030",
    "end": "4449700"
  },
  {
    "text": "this maximum likelihood,\ninstead using a reward model as a learned\nobjective function, which",
    "start": "4449700",
    "end": "4455040"
  },
  {
    "text": "is a lot less structure,\nnow we can scale further. RLHF itself is not really\nthat scalable, I would say,",
    "start": "4455040",
    "end": "4460870"
  },
  {
    "text": "but it just shows\nthat we can use this supervised deep learning\nto train a model that",
    "start": "4460870",
    "end": "4466470"
  },
  {
    "text": "serves as an objective\nfunction, and that really works in a cool way, I\nthink, that's a great paradigm.",
    "start": "4466470",
    "end": "4474700"
  },
  {
    "text": "Thank you. Great answer. Not that you're being\njudged or anything. But second question I\nwould say is, so then",
    "start": "4474700",
    "end": "4481590"
  },
  {
    "text": "in the beginning\nof the talk, you talk about the big driving force\nto be the exponentially cheap",
    "start": "4481590",
    "end": "4488790"
  },
  {
    "text": "compute, right? But some of the stuff\nI've been reading says Moore's law is\nending, and we're",
    "start": "4488790",
    "end": "4494305"
  },
  {
    "text": "going towards like\nperformance-oriented architecture. So can we rely then on--",
    "start": "4494305",
    "end": "4499950"
  },
  {
    "text": "right the past 50 years,\nwe had transistors doubling or whatever, Moore's law,\nbut yeah, that's ending.",
    "start": "4499950",
    "end": "4505920"
  },
  {
    "text": "So when you talk about\nthe compute, these demands that we've been looking at and\nthat structure our history,",
    "start": "4505920",
    "end": "4511860"
  },
  {
    "text": "we're also uncertain\nas to about how that's going to protect the future. So what are some of\nyour thoughts on that? Yeah.",
    "start": "4511860",
    "end": "4517130"
  },
  {
    "text": "I think the Moore's\nlaw is really a red herring in this\ncase because it's like number of transistors,\nbut that doesn't really matter.",
    "start": "4517130",
    "end": "4522810"
  },
  {
    "text": "I think what matters is\nthe compute availability. And like GPU, for example,\nis a very different kind",
    "start": "4522810",
    "end": "4527940"
  },
  {
    "text": "of architecture,\nand that enabled the continuation of this trend. And I think right\nnow 2023, 2024,",
    "start": "4527940",
    "end": "4534083"
  },
  {
    "text": "we're kind of\ntaking the shortcuts with like low precision thing,\nwhich still I think is cool,",
    "start": "4534083",
    "end": "4540120"
  },
  {
    "text": "but I think there are many\nother GPU level things. But also if we are kind of\nsure about the architecture,",
    "start": "4540120",
    "end": "4546780"
  },
  {
    "text": "this is my thoughts, we can\nlike hard code into the chips and that can provide\na lot of benefits.",
    "start": "4546780",
    "end": "4552480"
  },
  {
    "text": "And I think training\nfor training, I don't think\nthat's really done. But GPU, if you think about\nit is like too general,",
    "start": "4552480",
    "end": "4558360"
  },
  {
    "text": "maybe that is like something\nthat we can revisit. And so I'm not losing\nhope, and I don't",
    "start": "4558360",
    "end": "4564840"
  },
  {
    "text": "see any trend of doing that. But maybe other things\nwill come as a bottleneck like maybe energy or something.",
    "start": "4564840",
    "end": "4572280"
  },
  {
    "text": "Yeah. So physics probably is something\nthat we need to study again.",
    "start": "4572280",
    "end": "4577351"
  },
  {
    "text": "If you don't mind continuing. But then the problem\nis like, we're talking about exponential\ndriving forces, right?",
    "start": "4577352",
    "end": "4583498"
  },
  {
    "text": "You can tell me that you\nwant to hard code chips, but that's not the\nsame as telling me that there's going\nto be exponential",
    "start": "4583498",
    "end": "4588780"
  },
  {
    "text": "growth that we can\nride into paradise or whatever the\nhell we're going. Yeah.",
    "start": "4588780",
    "end": "4594105"
  },
  {
    "text": "Here's my very boring answer. I think, we just need to\ndo a little bit better.",
    "start": "4594105",
    "end": "4599160"
  },
  {
    "text": "And at some point, the\nmachines will be better than us in thinking about chip design. [LAUGHTER]",
    "start": "4599160",
    "end": "4605390"
  },
  {
    "text": "So I think it's half joking,\nbut if we look back at say this video two years\nfrom now, I think,",
    "start": "4605390",
    "end": "4610610"
  },
  {
    "text": "it will be less more of\na joke, serious thing. Yeah. Let's just get there first.",
    "start": "4610610",
    "end": "4616770"
  },
  {
    "text": "All right. So thanks to Hyung Won\nfor an amazing talk. [APPLAUSE]",
    "start": "4616770",
    "end": "4623410"
  },
  {
    "start": "4623410",
    "end": "4627000"
  }
]
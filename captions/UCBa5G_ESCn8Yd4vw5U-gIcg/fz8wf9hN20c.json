[
  {
    "start": "0",
    "end": "5870"
  },
  {
    "text": "All right, so, hey, guys. Thanks for coming\nto our second class. Today we have the pleasure\nof welcoming Fei Xia.",
    "start": "5870",
    "end": "12849"
  },
  {
    "text": "He's a senior research scientist\nat Google DeepMind, where he works on the robotics team.",
    "start": "12850",
    "end": "18680"
  },
  {
    "text": "He received his\nPhD here, actually, working with Silvio\nSaverese and Stanford Vision",
    "start": "18680",
    "end": "24619"
  },
  {
    "text": "and Learning Lab, as\nwell as [INAUDIBLE].. And his mission is to build\nintelligent, embodied agents",
    "start": "24620",
    "end": "31730"
  },
  {
    "text": "that can interact with complex\nand unstructured real world environments with applications\nlike home robotics.",
    "start": "31730",
    "end": "39620"
  },
  {
    "text": "And recently, he\nhas been exploring the use of foundation models for\nrobot decision making and action",
    "start": "39620",
    "end": "45680"
  },
  {
    "text": "generation. So now I'll hand it off to Fei. Hi, everyone.",
    "start": "45680",
    "end": "51080"
  },
  {
    "text": "I'm super happy to be\nhere and happy to be back. I graduated from\nhere two years ago. And now I'm a research\nscientist at Google DeepMind.",
    "start": "51080",
    "end": "58940"
  },
  {
    "text": "I work on the robotics team. And today I will be talking\nabout \"Low-level Embodied Intelligence with\nFoundation Models.\"",
    "start": "58940",
    "end": "65500"
  },
  {
    "text": "So it's definitely\nan interesting topic. And I will introduce what\nis embodied intelligence",
    "start": "65500",
    "end": "71460"
  },
  {
    "text": "and what is low-level\nembodied intelligence, and how we can accelerate\nthe building of them",
    "start": "71460",
    "end": "77430"
  },
  {
    "text": "with foundation models. All right, so why are we working\non embodied intelligence?",
    "start": "77430",
    "end": "84340"
  },
  {
    "text": "So embodied intelligence\nis an integral part of artificial intelligence.",
    "start": "84340",
    "end": "90479"
  },
  {
    "text": "And it's an important\nmilestone to artificial general intelligence.",
    "start": "90480",
    "end": "95500"
  },
  {
    "text": "And it has a lot of use cases. Like, for example, we all hope\nwe have a home robot that can be",
    "start": "95500",
    "end": "101145"
  },
  {
    "text": "in our home 24/7 and\nclean the home for us, or clean up our messy\nroom, or cook for us,",
    "start": "101145",
    "end": "109049"
  },
  {
    "text": "or take care of our\naging family members. So we are not quite there yet. In fact, we are\nquite far from it.",
    "start": "109050",
    "end": "116159"
  },
  {
    "text": "That is because our\nintelligence is currently mostly in the virtual world. So we have AI agents that can\nhelp us draft emails, or write",
    "start": "116160",
    "end": "125640"
  },
  {
    "text": "eloquent essays,\nbut they are not super good at interacting\nwith the messy, real world,",
    "start": "125640",
    "end": "131430"
  },
  {
    "text": "unstructured,\ncomplex environment that a human resides in. So just to give you guys\na couple of examples",
    "start": "131430",
    "end": "139440"
  },
  {
    "text": "of how messy the\nreal world can be and how hostile it\ncould be to robotics,",
    "start": "139440",
    "end": "144690"
  },
  {
    "text": "I want to show you a curious\nmistake or curious error from one of our robots.",
    "start": "144690",
    "end": "150730"
  },
  {
    "text": "So the task is to put\nthe Coke can in the sink. And watch what the robot does.",
    "start": "150730",
    "end": "156340"
  },
  {
    "text": "The robot grabs the Coke\ncan and opens the tap. So this is kind of dangerous,\nbut it's kind of interesting,",
    "start": "156340",
    "end": "165690"
  },
  {
    "text": "because we never expect it\nwould do something like that. It's just from random noise. It starts to open the tap, and\nthe water starts coming out.",
    "start": "165690",
    "end": "174130"
  },
  {
    "text": "So for an agent to have this\ntype of physical intelligence, it needs to understand\nthe effect of its actions",
    "start": "174130",
    "end": "182160"
  },
  {
    "text": "and what is so-called\na world model. So people have been complaining\nthat language models so far",
    "start": "182160",
    "end": "187710"
  },
  {
    "text": "don't have a world model. So it doesn't\nunderstand geometry. It doesn't understand the\nspatial relationship of objects",
    "start": "187710",
    "end": "194850"
  },
  {
    "text": "or the effect of\nactions, basically how an object will move\naccording to physical laws.",
    "start": "194850",
    "end": "201510"
  },
  {
    "text": "So we are not quite there yet. In another case--\nso this is our robot",
    "start": "201510",
    "end": "207569"
  },
  {
    "text": "that is ready to deliver a can,\nor actually throw away a can. But as you can see, we have\nthis pre-programmed behavior",
    "start": "207570",
    "end": "214770"
  },
  {
    "text": "of tucking the arm behind. And in doing that, the\ncan is upside down.",
    "start": "214770",
    "end": "219880"
  },
  {
    "text": "So if there is any\nliquid in the can, it will spill and\ndamage the robot. So it's another example of\nreal world is really complex,",
    "start": "219880",
    "end": "228300"
  },
  {
    "text": "and there are a lot\nof things to model. And in order for\nour robots to have",
    "start": "228300",
    "end": "234150"
  },
  {
    "text": "this sort of ambient\nintelligence, it really needs to understand\na lot of very nuanced details",
    "start": "234150",
    "end": "240510"
  },
  {
    "text": "of the environment\nand understanding the physics, physical laws,\nand understanding effect",
    "start": "240510",
    "end": "246090"
  },
  {
    "text": "of its actions. How do we do that? There are many ways to\nachieve embodied intelligence.",
    "start": "246090",
    "end": "252340"
  },
  {
    "text": "Actually, throughout\nmy PhD study, I've been fascinated by\nthis idea of creating",
    "start": "252340",
    "end": "258269"
  },
  {
    "text": "interactive environments. Basically, let an\nagent explore in these interactive environments.",
    "start": "258269",
    "end": "263580"
  },
  {
    "text": "Basically, create environments\nthat are complex enough so that if the agent needs to\nsurvive in such environment,",
    "start": "263580",
    "end": "271830"
  },
  {
    "text": "it must develop intelligence. So it's an ecological view\nof perception and agency,",
    "start": "271830",
    "end": "277200"
  },
  {
    "text": "and it's popularized by American\npsychologist James J. Gibson. So he has a famous quote, \"Ask\nnot what is inside your head,",
    "start": "277200",
    "end": "286710"
  },
  {
    "text": "but what your head\nis inside of.\" So humans learn this type\nof embodied intelligence. A human is able to manipulate\nobjects effortlessly,",
    "start": "286710",
    "end": "295650"
  },
  {
    "text": "one, because of\nevolution, second, because the\nchildhood experience. We have been playing\nwith this toy.",
    "start": "295650",
    "end": "300937"
  },
  {
    "text": "We have been interacting\nwith this toy and watched the physical\neffect so that we learn. And similarly, we can\ngive robots a safe playpen",
    "start": "300937",
    "end": "309810"
  },
  {
    "text": "so they can explore\nin those environment, and interact with\nthe environment, and play, and watch\nthe effect of actions,",
    "start": "309810",
    "end": "317280"
  },
  {
    "text": "and effectively understand how\nto manipulate those objects. So I have been developing\nthis simulation environment,",
    "start": "317280",
    "end": "327300"
  },
  {
    "text": "one of which is called a\nGibson environment, which is published as CVPR. It's mainly aiming at simulating\nthe visual world faithfully",
    "start": "327300",
    "end": "337680"
  },
  {
    "text": "and also simulate the\nphysical world to some extent. So we built this environment,\nwhich is a scanned environment,",
    "start": "337680",
    "end": "344669"
  },
  {
    "text": "from a lot of houses,\nand then an agent, we can spawn an agent in that,\nin this case, a humanoid agent,",
    "start": "344670",
    "end": "351449"
  },
  {
    "text": "and the agent can learn to walk,\nor to run in this environment,",
    "start": "351450",
    "end": "356520"
  },
  {
    "text": "and simulate all this\nperception information. So we can create a perception\naction loop for this agent.",
    "start": "356520",
    "end": "363490"
  },
  {
    "text": "And similarly, we can\nput other types of agent in this environment. In this case, a little cart.",
    "start": "363490",
    "end": "370910"
  },
  {
    "text": "And we can also put a\nquadruped, or this ant into this environment.",
    "start": "370910",
    "end": "375949"
  },
  {
    "text": "So essentially, we\ncreate an environment where we can simulate\nperception for the agent,",
    "start": "375950",
    "end": "382840"
  },
  {
    "text": "and then we can create\na neural network to map the perception to action. And this way, we achieve some\nsort of physical intelligence.",
    "start": "382840",
    "end": "390800"
  },
  {
    "text": "It's mostly for\nnavigation and locomotion. This is not enough.",
    "start": "390800",
    "end": "397319"
  },
  {
    "text": "So in this case, the environment\nis one monolithic piece of mesh.",
    "start": "397320",
    "end": "402420"
  },
  {
    "text": "As you can see, the\nagent ran into the wall, and it bounced back. So there's no articulation\nin this environment.",
    "start": "402420",
    "end": "409900"
  },
  {
    "text": "So it's not simulating the full\ncomplexity of the environment. So the things that we\ncan do with our agent",
    "start": "409900",
    "end": "417270"
  },
  {
    "text": "is rather limited. So that's why we create other\nsimulation environments, one of which is iGibson\nenvironment, which",
    "start": "417270",
    "end": "424319"
  },
  {
    "text": "is called Interactive Gibson. So what we do is we create-- we, again, scan a lot\nof real world houses,",
    "start": "424320",
    "end": "432630"
  },
  {
    "text": "and then we convert\nthem to CAD assets, basically, mesh assets\nthat are interactable.",
    "start": "432630",
    "end": "438460"
  },
  {
    "text": "In this case, we have\na simulated agent that goes into the environment,\nand then closes all the drawers.",
    "start": "438460",
    "end": "444960"
  },
  {
    "text": "So we are able to do that\nbecause we model the complexity of the world a little bit more.",
    "start": "444960",
    "end": "450370"
  },
  {
    "text": "We go beyond just\nmodeling the visual world. We start to model physics\na little bit more. Basically, modeling the degree\nof freedom in the environment,",
    "start": "450370",
    "end": "459710"
  },
  {
    "text": "and our agent can do more\nthan just navigating around. So we can go even further.",
    "start": "459710",
    "end": "466990"
  },
  {
    "text": "So we can even model\nmore degrees of freedom. And our agent can develop\nmore complicated behavior,",
    "start": "466990",
    "end": "472840"
  },
  {
    "text": "such as unloading a\ndishwasher and finding a bowl, or take out a bowl, and\nput it on the table.",
    "start": "472840",
    "end": "479660"
  },
  {
    "text": "So as we scale up the\ncomplexity of the environment, we are able to learn much\nmore complicated skills",
    "start": "479660",
    "end": "487420"
  },
  {
    "text": "in the simulation. And that's one way to achieve\nembodied intelligence, which",
    "start": "487420",
    "end": "493110"
  },
  {
    "text": "is to build a complex enough\nsimulation environment. ",
    "start": "493110",
    "end": "498880"
  },
  {
    "text": "Not just in my research, but the\nentire field of computer vision is undergoing a paradigm shift.",
    "start": "498880",
    "end": "504460"
  },
  {
    "text": "So previously, we are\nfocusing on internet AI. We curate a lot of\ninternet data sets",
    "start": "504460",
    "end": "510190"
  },
  {
    "text": "to study problems, like\nclassification, segmentation, and detection. Basically, all these\ncomputer vision problems.",
    "start": "510190",
    "end": "517070"
  },
  {
    "text": "Now, we focus a lot\nmore on embodied AI, which is adding the action\ndimension to the problem.",
    "start": "517070",
    "end": "524920"
  },
  {
    "text": "We are studying problems like\nvisual navigation, manipulation, rearrangement, embodied\nquestion answering, instruction",
    "start": "524920",
    "end": "530740"
  },
  {
    "text": "following. And the simulators replace-- in some sense replace the\noriginal role of data sets.",
    "start": "530740",
    "end": "539410"
  },
  {
    "text": "One thing that doesn't\nchange, which is the data is still super important. We are still relying\non large amount of data",
    "start": "539410",
    "end": "547960"
  },
  {
    "text": "to learn this\nintelligent behavior, no matter it's from a static\ndata set or from a simulator.",
    "start": "547960",
    "end": "556480"
  },
  {
    "text": "So learning a simulation can\ntake a lot of interactions.",
    "start": "556480",
    "end": "561880"
  },
  {
    "text": "So just to give you an\nexample, we create this iGibson environment, and we want to\nlearn a behavior called \"Go",
    "start": "561880",
    "end": "569830"
  },
  {
    "text": "into a room through\na closed door.\" So this is a rather\nsimple behavior, which I can show on the\ntop right of the screen.",
    "start": "569830",
    "end": "577279"
  },
  {
    "text": "So the agent needs to\nstop in front of the door. It needs to stop at\nthe right distance. If it stops too close to the\ndoor, it cannot extend its arm.",
    "start": "577280",
    "end": "585680"
  },
  {
    "text": "If it's too far, it\ncannot open the door. And then it basically\nopens the door. Let me play this again.",
    "start": "585680",
    "end": "590935"
  },
  {
    "text": "It opens the door. When there is enough clearance,\nit will go into the door. However, it takes about 50,000\nepisodes or 1.25 million",
    "start": "590935",
    "end": "600010"
  },
  {
    "text": "environment interactions to\nlearn this type of behavior. This is because we are using\nmodel-free reinforcement",
    "start": "600010",
    "end": "606399"
  },
  {
    "text": "learning. The agent is exploring\nthis environment. It could really push any point.",
    "start": "606400",
    "end": "611780"
  },
  {
    "text": "It could rather\nstop at any point. So we give it a reward\nfunction to go into the room.",
    "start": "611780",
    "end": "618330"
  },
  {
    "text": "But it's very rare that it will\nstumble upon this behavior. I would like to argue\nwith foundation models,",
    "start": "618330",
    "end": "625320"
  },
  {
    "text": "we can do a lot more different. So what do you do? Nowadays, you just ask ChatGPT.",
    "start": "625320",
    "end": "631490"
  },
  {
    "text": "How do you go into a room\nthrough a closed door? And it will say, open the door. Walk through the door. So this is a gross\nsimplification of the problem.",
    "start": "631490",
    "end": "639389"
  },
  {
    "text": "Of course, the problem\nis not that simple. But what I'm just\nsaying is that we",
    "start": "639390",
    "end": "645680"
  },
  {
    "text": "can leverage a lot of semantic\nprior from the foundation models.",
    "start": "645680",
    "end": "651180"
  },
  {
    "text": "So if we really lack data, if\nwe really need a lot of data, the foundation model\nis a compressed version",
    "start": "651180",
    "end": "657410"
  },
  {
    "text": "of the entire data, and\nit's a knowledge base that you can query to accelerate\nthe development of robotics.",
    "start": "657410",
    "end": "663380"
  },
  {
    "text": "Of course, simulation\nand real world data is still super, super important. But maybe we can get\nthe best of both worlds.",
    "start": "663380",
    "end": "670590"
  },
  {
    "text": "We can use foundation\nmodels, plus a limited amount of simulation\nor real world data.",
    "start": "670590",
    "end": "676699"
  },
  {
    "text": "So that's what I'm going\nto talk about today. So where are we in terms of\nfoundation models plus robotics?",
    "start": "676700",
    "end": "683990"
  },
  {
    "text": "So our team at\nGoogle DeepMind has been piloting in foundation\nmodel plus robotics.",
    "start": "683990",
    "end": "689730"
  },
  {
    "text": "So we developed advanced\nplanning, high-level planning algorithms. One of the first is\ncalled PaLM-SayCan.",
    "start": "689730",
    "end": "697100"
  },
  {
    "text": "It is an algorithm that\ncan parse a user command. So here is a demo.",
    "start": "697100",
    "end": "702217"
  },
  {
    "text": "Here is a scenario. Here is a user command. I spilled my Coke on the table. How would you throw\nit away and bring me something to help clean?",
    "start": "702218",
    "end": "708170"
  },
  {
    "text": "And it's querying\na large language model, which is given a\nscore, highlighted in blue.",
    "start": "708170",
    "end": "714300"
  },
  {
    "text": "And there's also an\naffordance score. The affordance will tell you\nwhether an action at a given state is possible.",
    "start": "714300",
    "end": "720420"
  },
  {
    "text": "It's augmenting\nthe language model to give you only\npossible things. So essentially, it is\ndoing the planning,",
    "start": "720420",
    "end": "727399"
  },
  {
    "text": "doing the semantic planning\nwith the language model, but it's also taking into\nconsideration what it can do.",
    "start": "727400",
    "end": "732840"
  },
  {
    "text": "So it's not just outputting-- the language model\ntends to hallucination.",
    "start": "732840",
    "end": "740880"
  },
  {
    "text": "It doesn't hallucinate. It only gives you what is\npossible for the robot to do and what is actionable\nfor the robot.",
    "start": "740880",
    "end": "746410"
  },
  {
    "text": "And the robot is doing the\nthing that is advancing the long horizon task progress.",
    "start": "746410",
    "end": "751750"
  },
  {
    "text": "And also, each task is\nexecuted by a low-level policy. Here, it doesn't\nquite clean the table",
    "start": "751750",
    "end": "759540"
  },
  {
    "text": "because we haven't added\nthis to the low-level skill. But imagine, there\nis a low-level skill to clean the table.",
    "start": "759540",
    "end": "765220"
  },
  {
    "text": "It will finish the entire thing. What is the local\npolicy used to hear?",
    "start": "765220",
    "end": "770840"
  },
  {
    "text": "The local policy used to hear\nis Robotic Transformer 1.",
    "start": "770840",
    "end": "775880"
  },
  {
    "text": "It's our team's home\ngrown transformer. Essentially, we collect\na large data set",
    "start": "775880",
    "end": "781670"
  },
  {
    "text": "of human demonstrations. We put the transformer, and\nwe train it on this large data",
    "start": "781670",
    "end": "789550"
  },
  {
    "text": "set of expert trajectories. It is able to do about 700\ntasks with 97% success rate.",
    "start": "789550",
    "end": "797190"
  },
  {
    "text": "And it has interesting\ngeneralization behavior. It can operate in a new kitchen\nit has never seen before,",
    "start": "797190",
    "end": "805010"
  },
  {
    "text": "which is showing there is a\nsuccessful recipe to apply foundation models in robotics.",
    "start": "805010",
    "end": "811440"
  },
  {
    "text": "So that's roughly where are we\nin terms of foundation model plus robotics. And I will talk about a few\nnew works that is bringing this",
    "start": "811440",
    "end": "821780"
  },
  {
    "text": "to the next level. So actually, my teammate Ted\ngave a talk of foundation models",
    "start": "821780",
    "end": "830100"
  },
  {
    "text": "plus robotics at the\nbeginning of this year. It's also this class CS25.",
    "start": "830100",
    "end": "835870"
  },
  {
    "text": "I highly recommend it. It's available on YouTube. I actually watched it\nlast night so that I don't",
    "start": "835870",
    "end": "841200"
  },
  {
    "text": "repeat some of the contents. But what he basically\nmentioned is that we--",
    "start": "841200",
    "end": "848310"
  },
  {
    "text": "he revealed our team's\nprogress in terms of building this robotic foundation models.",
    "start": "848310",
    "end": "854550"
  },
  {
    "text": "And we have had a lot\nof somewhat detour, and now we started to\nfigure out a recipe.",
    "start": "854550",
    "end": "860880"
  },
  {
    "text": "So in 2021 to 2022 is how\nwe scale to many tasks with demonstrations.",
    "start": "860880",
    "end": "867010"
  },
  {
    "text": "How do we collect a\nlarge amount of data? In fact, about 100,000\ndemonstrations.",
    "start": "867010",
    "end": "873460"
  },
  {
    "text": "And we tried different\nways to do it. We tried the behavior cloning. We tried imitation learning\nplus reinforcement learning,",
    "start": "873460",
    "end": "880230"
  },
  {
    "text": "and some other ways,\nor combining them with language models,\nsuch as SayCan.",
    "start": "880230",
    "end": "886230"
  },
  {
    "text": "In 2022 to 2023, it's about\nhow we can leverage foundation models to accelerate robotics.",
    "start": "886230",
    "end": "892000"
  },
  {
    "text": "We really see a proliferation\nof using foundation models to accelerate robotics, both\non the high-level planning",
    "start": "892000",
    "end": "899670"
  },
  {
    "text": "and low-level control,\nprobably leaning more towards the high-level planning. So if the recipe works--",
    "start": "899670",
    "end": "907800"
  },
  {
    "text": "so the recipe is essentially\ncombine a large scale, diverse offline data\nset with a high capacity",
    "start": "907800",
    "end": "915420"
  },
  {
    "text": "architecture, such\nas a transformer, and using language\nas a universal glue. So this would be the recipe\nto build foundation models",
    "start": "915420",
    "end": "923400"
  },
  {
    "text": "for robotics. So if this recipe\nworks, what do we do? What do we do next?",
    "start": "923400",
    "end": "928800"
  },
  {
    "text": "Essentially, we\njust-- let's just scale everything to\ntwo orders of magnitude and be done with it,\nand solve robotics.",
    "start": "928800",
    "end": "937230"
  },
  {
    "text": "And guess what. That's what we did. So that's the end\nof the lecture. Maybe we can cut this\na little bit short.",
    "start": "937230",
    "end": "943490"
  },
  {
    "text": "And that's a joke. That's not happening. So we are still on\nour way on our quest",
    "start": "943490",
    "end": "951290"
  },
  {
    "text": "to solve low-level\nembodied intelligence. When I talk to people that\nyou can use foundation models",
    "start": "951290",
    "end": "958190"
  },
  {
    "text": "to do robotics, their\nreaction would be it's mostly doing high-level reasoning.",
    "start": "958190",
    "end": "964710"
  },
  {
    "text": "It doesn't do the low-level\nmanipulation really well. And that's for a reason.",
    "start": "964710",
    "end": "970310"
  },
  {
    "text": "One of the reasons is\nthere's Moravec's paradox. Moravec's paradox\nis the observation",
    "start": "970310",
    "end": "975680"
  },
  {
    "text": "that in artificial\nintelligence and robotics, contrary to traditional\nassumptions or our intuitions,",
    "start": "975680",
    "end": "981680"
  },
  {
    "text": "reasoning requires very\nlittle computation. But sensorimotor control\nand perception skills",
    "start": "981680",
    "end": "986850"
  },
  {
    "text": "require enormous\ncompute resources. That is because as\nbiological creatures,",
    "start": "986850",
    "end": "993329"
  },
  {
    "text": "we acquire the sensorimotor\nskills through evolution. This is very different.",
    "start": "993330",
    "end": "999640"
  },
  {
    "text": "So we might not be\nable to reason or do large amount of large\nscale computation,",
    "start": "999640",
    "end": "1006350"
  },
  {
    "text": "but this sensorimotor control\nis integral to our survival.",
    "start": "1006350",
    "end": "1011519"
  },
  {
    "text": "So it's essentially\nalready learned in our DNA. But in robotics, it's\na little bit different.",
    "start": "1011520",
    "end": "1017490"
  },
  {
    "text": "So the chips are very good at\ndoing reasoning and computation, but they are not\nsuper good-- they",
    "start": "1017490",
    "end": "1023390"
  },
  {
    "text": "haven't experienced the world. They haven't acquired\nthe sensorimotor skills that are necessary for them\nto do tasks in the real world.",
    "start": "1023390",
    "end": "1032209"
  },
  {
    "text": "Here is an example. When the computer beat Kasparov,\nbasically, the human champion",
    "start": "1032210",
    "end": "1039680"
  },
  {
    "text": "in chess, there is not a robot\narm moving the chess piece. It can beat the human\nchampion in chess,",
    "start": "1039680",
    "end": "1047209"
  },
  {
    "text": "but there's still someone that\nneeds to move the chess piece. Similarly, in the\nAlphaGo moment,",
    "start": "1047210",
    "end": "1052400"
  },
  {
    "text": "when Lee Sedol was\nbeaten by AlphaGo. There's still someone who is\nmoving the chess piece for them.",
    "start": "1052400",
    "end": "1057809"
  },
  {
    "text": "It's not a robot doing that. So this is showing\nthe reasoning is-- the hard things are easy,\nand the easy things are hard.",
    "start": "1057810",
    "end": "1065280"
  },
  {
    "text": "There's another thing\nthat prevents us from using foundation\nmodels more prevalently,",
    "start": "1065280",
    "end": "1071460"
  },
  {
    "text": "more in larger scale\nin robotics, which is the training data bias.",
    "start": "1071460",
    "end": "1076980"
  },
  {
    "text": "The training data of foundation\nmodels or large language models are mostly language tasks.",
    "start": "1076980",
    "end": "1082300"
  },
  {
    "text": "So it's perhaps not\nthat surprising it knows how to clean up a\nkitchen, because maybe there",
    "start": "1082300",
    "end": "1088110"
  },
  {
    "text": "are wikiHow articles teaching\nyou how to clean up a kitchen, or to do something\nin a procedural way.",
    "start": "1088110",
    "end": "1093520"
  },
  {
    "text": "But there is no wikiHow\narticles teaching you how to move your finger 5\ncentimeters to the left,",
    "start": "1093520",
    "end": "1098850"
  },
  {
    "text": "because people just\ndon't say that. People don't write that down. So there is a very\nlimited amount",
    "start": "1098850",
    "end": "1104639"
  },
  {
    "text": "of this low-level control data\nin large language model training corpora. So we do have a\nlot of challenges",
    "start": "1104640",
    "end": "1111120"
  },
  {
    "text": "in bringing the foundation\nmodels to a lower level. So that's what I mean by\nlow-level embodied intelligence.",
    "start": "1111120",
    "end": "1117240"
  },
  {
    "text": "So any questions so far? I also want to make\nthis quite interactive. So if there is any\nquestions, feel",
    "start": "1117240",
    "end": "1124110"
  },
  {
    "text": "free to interrupt me any time. ",
    "start": "1124110",
    "end": "1130030"
  },
  {
    "text": "All right, if not,\nwe can continue. So there are a\ncouple of challenges of using large language\nmodels for low-level control.",
    "start": "1130030",
    "end": "1137530"
  },
  {
    "text": "As I just mentioned, the\nfirst thing is lack of data. So we only have perhaps 100,000\nepisodes of human demonstration",
    "start": "1137530",
    "end": "1148820"
  },
  {
    "text": "data. And it takes about 13\nrobots 17 months to collect. So it's a huge amount of effort.",
    "start": "1148820",
    "end": "1155680"
  },
  {
    "text": "On the contrary, large language\nmodels are trained on the order of 1,000 billion tokens.",
    "start": "1155680",
    "end": "1160970"
  },
  {
    "text": "PaLM, smaller PaLM, was trained\non 780 billion parameters-- 780 billion tokens.",
    "start": "1160970",
    "end": "1167960"
  },
  {
    "text": "And the larger one is trained-- following the\nChinchilla rule, you",
    "start": "1167960",
    "end": "1173020"
  },
  {
    "text": "would need to train it\non 1.35 trillion tokens. So it's a huge\namount of discrepancy",
    "start": "1173020",
    "end": "1180910"
  },
  {
    "text": "between how much data we\ncan achieve in robotics and how much we can get\nin large language models.",
    "start": "1180910",
    "end": "1187690"
  },
  {
    "text": "So we will always be\nbounded by robotic data. So maybe we can scale\non other fronts.",
    "start": "1187690",
    "end": "1193260"
  },
  {
    "text": "Maybe we can keep the\nrobotics data the same, and then we can scale\non other fronts. Like maybe we can scale\nthe pre-training mix",
    "start": "1193260",
    "end": "1200080"
  },
  {
    "text": "of text and image, or\nmaybe image and text pairs. Maybe we can build this\ncake, and the robotics data",
    "start": "1200080",
    "end": "1207740"
  },
  {
    "text": "is just a cherry on top of it. And we can scale the\nfoundation really, really well.",
    "start": "1207740",
    "end": "1213950"
  },
  {
    "text": "Some of my work that I'm\ngoing to talk about today actually reused the RT-1 data. We don't collect\nnew data for RT-2.",
    "start": "1213950",
    "end": "1220640"
  },
  {
    "text": "But we want to do more things\nwith the same amount of data.",
    "start": "1220640",
    "end": "1225890"
  },
  {
    "text": "The second challenge is kind of\nrelated to the first challenge. Language models lack an\ninterface for low-level control.",
    "start": "1225890",
    "end": "1234290"
  },
  {
    "text": "If you ask a language model,\n\"How do you make a robot dog stand up on two feet?\", it will\ntell you a lot of things that",
    "start": "1234290",
    "end": "1240800"
  },
  {
    "text": "sound reasonable,\nsound plausible. It will tell you the robot\ndog's torso is upright, balanced over two hind feet, and\nstanding shoulder width apart.",
    "start": "1240800",
    "end": "1249540"
  },
  {
    "text": "This is great. This is all great, but we\ncannot put it on the robot. ",
    "start": "1249540",
    "end": "1255720"
  },
  {
    "text": "On the other hand, maybe\nwe can ask a language model to write control code to\ndirectly control the robot. But usually, that\nrequires you to curate",
    "start": "1255720",
    "end": "1263760"
  },
  {
    "text": "an API that is friendly\nto the language model. If you directly ask it to\ngive you my joint angles",
    "start": "1263760",
    "end": "1270570"
  },
  {
    "text": "to make the robot\nstand upright, it will not give you\nthe right thing because it doesn't\nhave enough context. So essentially,\nlarge language models",
    "start": "1270570",
    "end": "1278009"
  },
  {
    "text": "don't speak robot language. Can we actually find the\nright robot language?",
    "start": "1278010",
    "end": "1284110"
  },
  {
    "text": "Can we find the interface\nbetween large language models and robot control? Or can we just treat robot\naction as another language?",
    "start": "1284110",
    "end": "1291790"
  },
  {
    "text": "So that's what we\nwant to find out. So in today's agenda,\nI will be talking",
    "start": "1291790",
    "end": "1297750"
  },
  {
    "text": "about low-level embodied\nintelligence with foundation models. It's separated into\ntwo parts, and it's",
    "start": "1297750",
    "end": "1304169"
  },
  {
    "text": "addressing the two challenges\nthat I've just mentioned. Part one is about model\nconsolidation, joint scaling,",
    "start": "1304170",
    "end": "1310320"
  },
  {
    "text": "and positive transfer. So I have to put\nthem in one part because they are\nsomewhat related.",
    "start": "1310320",
    "end": "1316179"
  },
  {
    "text": "And part two is developing a\nnew interface of large language models. So what do I mean by\nmodel consolidation?",
    "start": "1316180",
    "end": "1323650"
  },
  {
    "text": "Model consolidation--\nyes, question-- Yeah, I'm just going to ask\nwhy couldn't you just fine tune",
    "start": "1323650",
    "end": "1328860"
  },
  {
    "text": "an LLM for generating specific\nlow-level code, either some text",
    "start": "1328860",
    "end": "1334799"
  },
  {
    "text": "description [INAUDIBLE]. Yeah. That's a good question.",
    "start": "1334800",
    "end": "1340118"
  },
  {
    "text": "So the question is, why cannot\nwe fine tune a language model to directly output low-level\ncode or like robot actions?",
    "start": "1340118",
    "end": "1349660"
  },
  {
    "text": "So I would be talking\nabout RT-2, which does somewhat similar to that. It fine tunes a language\nmodel to output action",
    "start": "1349660",
    "end": "1356800"
  },
  {
    "text": "as a language to output\nour action representation. There are certain downsides to\nthat, like, for example, you",
    "start": "1356800",
    "end": "1363370"
  },
  {
    "text": "would need to collect additional\ndata to fine tune a language model.",
    "start": "1363370",
    "end": "1368530"
  },
  {
    "text": "So either we can fine tune that,\nor we can use a language model zero shot if you find the\nright interface, which",
    "start": "1368530",
    "end": "1374532"
  },
  {
    "text": "I will talk about a little\nbit in the part two. [INAUDIBLE] without fine tuning? Without fine tuning, yeah.",
    "start": "1374532",
    "end": "1380860"
  },
  {
    "text": "So the model consolidation\nis-- essentially, we can do the high-level\nreasoning and low-level control",
    "start": "1380860",
    "end": "1386140"
  },
  {
    "text": "in one model. And joint scaling is not only\nwe scale the robot data, which",
    "start": "1386140",
    "end": "1391210"
  },
  {
    "text": "is expensive, we also scale\nthe pre-training data, or we already start from a\npre-trained vision language",
    "start": "1391210",
    "end": "1398980"
  },
  {
    "text": "model, and the positive\ntransfer is the model benefiting from diverse joint training\nacross internet scale, language,",
    "start": "1398980",
    "end": "1405910"
  },
  {
    "text": "vision, and vision language\ndomains combined with robotics.",
    "start": "1405910",
    "end": "1411300"
  },
  {
    "text": "So this is a\ncontinuation of the axes that Ted drew in\nhis previous talk.",
    "start": "1411300",
    "end": "1419830"
  },
  {
    "text": "So we can see there is a trend. So this visualization\nbasically highlights",
    "start": "1419830",
    "end": "1425370"
  },
  {
    "text": "some of the work of our team. And each work, each\ncolumn is basically",
    "start": "1425370",
    "end": "1432480"
  },
  {
    "text": "a robotic system that is able\nto do both high-level reasoning and low-level control. So previously, we needed to have\nseparate models for each thing.",
    "start": "1432480",
    "end": "1442889"
  },
  {
    "text": "Previously, in the\ninitial release of SayCan, the planning is done by\na large language model,",
    "start": "1442890",
    "end": "1448710"
  },
  {
    "text": "and the affordance is done\nby TQ-Opt, like policy",
    "start": "1448710",
    "end": "1456450"
  },
  {
    "text": "trained with sim2real. And the low-level policy\nis robotic transformer one.",
    "start": "1456450",
    "end": "1463350"
  },
  {
    "text": "So it's each model doing\nits dedicated thing. And we need to train each\nmodel differently and perhaps",
    "start": "1463350",
    "end": "1472090"
  },
  {
    "text": "with different types of data. And later, we have\nQ-transformer, which unifies, which is a kind of an offline\nRL method that is leveraging",
    "start": "1472090",
    "end": "1483160"
  },
  {
    "text": "transformer architecture. So it's a high\ncapacity architecture. It can train on both positive\ndata and negative data.",
    "start": "1483160",
    "end": "1489230"
  },
  {
    "text": "And with that, we are able to\ngather a policy that is also understanding affordances.",
    "start": "1489230",
    "end": "1495880"
  },
  {
    "text": "So we can unify the low-level\npolicy and affordances. But the planning is still\na large language model.",
    "start": "1495880",
    "end": "1500990"
  },
  {
    "text": "And then we have PaLM-E,\nwhich is a vision language model, which is a\nlarge language model,",
    "start": "1500990",
    "end": "1507460"
  },
  {
    "text": "also trained on vision\nlanguage domain. So the PaLM-E can do\nplanning and affordance",
    "start": "1507460",
    "end": "1512830"
  },
  {
    "text": "in just one model, but the\nlow level is still using RT-1. And finally, we unify\neverything together,",
    "start": "1512830",
    "end": "1518540"
  },
  {
    "text": "like there is RT-2,\nwhich I'm going to talk about today, that can\ndo both high-level planning",
    "start": "1518540",
    "end": "1523690"
  },
  {
    "text": "to some extent,\ngenerating affordance, and do low-level policies. So behind the\nmodel consolidation",
    "start": "1523690",
    "end": "1530649"
  },
  {
    "text": "is the consolidation of tasks. We can represent every task as\na vision plus text to text task.",
    "start": "1530650",
    "end": "1539120"
  },
  {
    "text": "So it's a really universal\nrepresentation of the task. And then with\nthat, you can train",
    "start": "1539120",
    "end": "1545019"
  },
  {
    "text": "it really using a lot of data. And you can see\npositive transfer. Basically learning\naffordance can also",
    "start": "1545020",
    "end": "1553000"
  },
  {
    "text": "tell you how to achieve a task. There are a transfer\nbetween tasks when you",
    "start": "1553000",
    "end": "1560120"
  },
  {
    "text": "pull all the tasks together. So to understand\nthis joint scaling",
    "start": "1560120",
    "end": "1566240"
  },
  {
    "text": "and to understand the\nmodel consolidation, we need to understand\nPaLM-E a little bit.",
    "start": "1566240",
    "end": "1572100"
  },
  {
    "text": "So PaLM-E is an embodied\nmulti-modal language model. It's based on the\nPaLM architecture.",
    "start": "1572100",
    "end": "1577380"
  },
  {
    "text": "So PaLM is a large\nlanguage model. We made some adaptation\non the architecture",
    "start": "1577380",
    "end": "1582860"
  },
  {
    "text": "so it can understand\nmultimodal input. So it is basically\none model that",
    "start": "1582860",
    "end": "1590899"
  },
  {
    "text": "is able to take in\nmultimodal input. So in large language\nmodels, each word",
    "start": "1590900",
    "end": "1598460"
  },
  {
    "text": "is tokenized, and\ntokenized, and getting this embedding of these words.",
    "start": "1598460",
    "end": "1605450"
  },
  {
    "text": "And then that is fed into\na large language model. So in PaLM-E, what we do\nis instead of using words,",
    "start": "1605450",
    "end": "1613040"
  },
  {
    "text": "we can use multimodal tokens. So the multimodal\ntokens can come from a vision\nlanguage-- can come",
    "start": "1613040",
    "end": "1619670"
  },
  {
    "text": "from a vision\ntransformer, a ViT, or it can come from\nrobot sensory data.",
    "start": "1619670",
    "end": "1625930"
  },
  {
    "text": "So every multimodal\ntoken, then we",
    "start": "1625930",
    "end": "1631320"
  },
  {
    "text": "map it to the text\nembedding space. We basically train\na linear affine",
    "start": "1631320",
    "end": "1638340"
  },
  {
    "text": "transform between the multimodal\ntoken and the text embedding",
    "start": "1638340",
    "end": "1643679"
  },
  {
    "text": "space. And then we can treat the\nmultimodal token as words",
    "start": "1643680",
    "end": "1649230"
  },
  {
    "text": "as well. So essentially, we have a\nlanguage model as a solid base,",
    "start": "1649230",
    "end": "1655799"
  },
  {
    "text": "and then we start to adapt it\nto understand multimodal tokens. So this is quite interesting,\nbecause we don't--",
    "start": "1655800",
    "end": "1662730"
  },
  {
    "text": "it doesn't require a ton\nof adaptation or fine tuning for it to understand\nmultimodal input.",
    "start": "1662730",
    "end": "1669940"
  },
  {
    "text": "It just aligns naturally\nto the multimodal input, such as images. I will show a couple of\nexamples of what it can do.",
    "start": "1669940",
    "end": "1678150"
  },
  {
    "text": "And we can train the same way as\ntraining large language models. So essentially, we can reuse the\nsame infrastructure and training",
    "start": "1678150",
    "end": "1685770"
  },
  {
    "text": "algorithm and everything\nto train this PaLM-E. A couple other things\nwe find along the way",
    "start": "1685770",
    "end": "1693179"
  },
  {
    "text": "is positive transfer, which\nI will share in a little bit. So I guess here I\nalso want to mention",
    "start": "1693180",
    "end": "1701180"
  },
  {
    "text": "PaLM-E is one of the largest\nmodels we have explored so far. It has 562 billion\nparameters, which",
    "start": "1701180",
    "end": "1707879"
  },
  {
    "text": "is by concatenating the PaLM 540\nbillion parameters and the 22",
    "start": "1707880",
    "end": "1713280"
  },
  {
    "text": "billion ViT. And we find a lot of emergent\ncapabilities of these models.",
    "start": "1713280",
    "end": "1718929"
  },
  {
    "text": "That is we haven't expected\nduring training time,",
    "start": "1718930",
    "end": "1724540"
  },
  {
    "text": "but really, we can\nprompt these models, and ask it to do\ninteresting things. We have also explored using\nneural scene representation,",
    "start": "1724540",
    "end": "1732809"
  },
  {
    "text": "basically, an object-centric\nrepresentation fed into PaLM-E.",
    "start": "1732810",
    "end": "1739440"
  },
  {
    "text": "So object-centric\nrepresentation assigns one token",
    "start": "1739440",
    "end": "1744750"
  },
  {
    "text": "to each object. And we find that\nthis representation is super helpful\nfor robot planning",
    "start": "1744750",
    "end": "1751590"
  },
  {
    "text": "tasks, because traditional ViT\nrepresentation is based on grid, and it doesn't have a full\nunderstanding of layered objects",
    "start": "1751590",
    "end": "1758670"
  },
  {
    "text": "and their relationships. We have done an extensive study\non the scaling performance",
    "start": "1758670",
    "end": "1765960"
  },
  {
    "text": "and the catastrophic\nforgetting performance, and all other interesting\nexperiments in the paper.",
    "start": "1765960",
    "end": "1772560"
  },
  {
    "text": "So please refer to\nthe paper for more. So here I'm just showing some\ninteresting qualitative examples",
    "start": "1772560",
    "end": "1779010"
  },
  {
    "text": "of some emergent capability\nof PaLM-E that we found out.",
    "start": "1779010",
    "end": "1784050"
  },
  {
    "text": "So first, we found this model\nhas some reasoning capability. You can give it an image and\nask it questions that requires",
    "start": "1784050",
    "end": "1791606"
  },
  {
    "text": "a little bit of reasoning. And you can prompt this\nwith, let's think step by step, which is a technique\nused to elicit reasoning",
    "start": "1791607",
    "end": "1799740"
  },
  {
    "text": "in large language models. But here in multimodal language\nmodels, you can do the same. I guess people are\nalso experimenting it",
    "start": "1799740",
    "end": "1807790"
  },
  {
    "text": "these days with GPT-4V. You can also prompt it to think\nstep by step or count, row by row.",
    "start": "1807790",
    "end": "1813190"
  },
  {
    "text": "But here this is before GPT-4V. And we were able\nto elicit reasoning",
    "start": "1813190",
    "end": "1819100"
  },
  {
    "text": "using some of the\ninteresting prompts, such as we can ask it, in\nthis photo, are there",
    "start": "1819100",
    "end": "1824710"
  },
  {
    "text": "more cats or more dogs? Let's think step by step. And they found--\nthe PaLM-E found out",
    "start": "1824710",
    "end": "1829870"
  },
  {
    "text": "there are an equal\namount of dogs and cats. And on the right,\ngiven an image,",
    "start": "1829870",
    "end": "1835149"
  },
  {
    "text": "can I go down this street\non a bicycle, yes or no? Let's think step by step. And the reply is, do not enter.",
    "start": "1835150",
    "end": "1841240"
  },
  {
    "text": "Second, except the bicycles. Do not entry except bicycles. Yes. So it's doing this\nmodus of reasoning.",
    "start": "1841240",
    "end": "1847450"
  },
  {
    "text": "And it's mixing this\nunderstanding of symbols, and also mixing the\nunderstanding of text.",
    "start": "1847450",
    "end": "1855170"
  },
  {
    "text": "So this is quite amazing to me. To be honest, when\nI first saw this,",
    "start": "1855170",
    "end": "1860560"
  },
  {
    "text": "I didn't expect a\nmultimodal language model would be able to do that. And we also tried one thing,\nwhich is traditionally",
    "start": "1860560",
    "end": "1868380"
  },
  {
    "text": "very difficult to language\nmodels, which is to tell a joke. Language models can\nunderstand joke,",
    "start": "1868380",
    "end": "1873990"
  },
  {
    "text": "but sometimes it just doesn't-- it's not able to\ntell you a joke, when",
    "start": "1873990",
    "end": "1880230"
  },
  {
    "text": "it comes to the punchline,\nbecause it's just trying to make something\nthat is plausible",
    "start": "1880230",
    "end": "1885420"
  },
  {
    "text": "and sounds like a joke. And when it comes\nto a punchline, it doesn't really\nknow what to say.",
    "start": "1885420",
    "end": "1890650"
  },
  {
    "text": "So here I give it an\nimage, and I asked it to come up with a description. And then it comes\nup with a joke.",
    "start": "1890650",
    "end": "1897670"
  },
  {
    "text": "So this guides the language\nmodel to think step by step. And the description is a\ndonkey is carrying a dog, cat,",
    "start": "1897670",
    "end": "1904050"
  },
  {
    "text": "and rooster. And the joke is, what\ndo you call a donkey with a rooster on his back? A rooster booster.",
    "start": "1904050",
    "end": "1909210"
  },
  {
    "text": "It's so creative. Like, when I saw this,\nI'm pleasantly surprised. And I searched online.",
    "start": "1909210",
    "end": "1914380"
  },
  {
    "text": "I couldn't find\nanother joke like that. So it's actually an\noriginal joke by PaLM-E. And finally, we see some maths\nreasoning with this model.",
    "start": "1914380",
    "end": "1921920"
  },
  {
    "text": " Basically, I give it a messy\nmenu from a pizza store.",
    "start": "1921920",
    "end": "1928470"
  },
  {
    "text": "And I ask it, how much is-- I'm just buying a pizza\nfor me and my friend.",
    "start": "1928470",
    "end": "1933720"
  },
  {
    "text": "How much should I pay? Let's think step by step. And it's figuring out there is\na pizza, and there's a $9.99.",
    "start": "1933720",
    "end": "1940919"
  },
  {
    "text": "And it tells you the price. In some of the answers,\nit even calculates text.",
    "start": "1940920",
    "end": "1946630"
  },
  {
    "text": "But the text is hallucinated,\nso that doesn't work. All right, let's talk\nabout positive transfer.",
    "start": "1946630",
    "end": "1952290"
  },
  {
    "text": "So apart from the amazing\ncapabilities-- amazing things",
    "start": "1952290",
    "end": "1957610"
  },
  {
    "text": "that PaLM-E can do, it also has\ninteresting positive transfer behavior.",
    "start": "1957610",
    "end": "1962679"
  },
  {
    "text": "So when we train PaLM-E on a\nsingle domain, when we train it",
    "start": "1962680",
    "end": "1967990"
  },
  {
    "text": "on just a single robotics\ntask, the performance is not super great. But when we pull all\nthe data together",
    "start": "1967990",
    "end": "1974270"
  },
  {
    "text": "and we also include internet\nscale visual language tasks,",
    "start": "1974270",
    "end": "1979810"
  },
  {
    "text": "such as captioning,\nvisual question answering, it is able to do much better.",
    "start": "1979810",
    "end": "1985139"
  },
  {
    "text": "So this shows that it's\nimportant to mix all the data together and train it jointly.",
    "start": "1985140",
    "end": "1992169"
  },
  {
    "text": "The internet scale data can\nact as a regularizer for you",
    "start": "1992170",
    "end": "1997240"
  },
  {
    "text": "to not forget the\nrepresentations. And those representations\nare, in turn, very useful",
    "start": "1997240",
    "end": "2003470"
  },
  {
    "text": "for robotics. So that's the positive\ntransfer results. And we start to see\nmore and more positive",
    "start": "2003470",
    "end": "2009809"
  },
  {
    "text": "transfer in other\nof our studies. Yes. So how much did that do to do\nproactive, like in simulation",
    "start": "2009810",
    "end": "2016200"
  },
  {
    "text": "or in real world? I think the playing with\nsorting stuff in [? policy, ?]",
    "start": "2016200",
    "end": "2021990"
  },
  {
    "text": "is very impressive. Right. That's a very good point. So for the-- so these\nare all planning",
    "start": "2021990",
    "end": "2032340"
  },
  {
    "text": "data, high-level planning. ",
    "start": "2032340",
    "end": "2037680"
  },
  {
    "text": "Maybe let's just talk\nabout two things. So first of all, the sorting\nresults, the low-level policy",
    "start": "2037680",
    "end": "2044700"
  },
  {
    "text": "is still using a\ntraditional controller. So it's using a\npolicy called LAVA.",
    "start": "2044700",
    "end": "2050440"
  },
  {
    "text": "And that policy is trained\non 68,000 episodes.",
    "start": "2050440",
    "end": "2055800"
  },
  {
    "text": "The high-level planning is\nprobably easier than you think, because it only needs to tell--",
    "start": "2055800",
    "end": "2062699"
  },
  {
    "text": "put the-- it's giving commands\nto the low-level policy. So it basically\nonly needs to say,",
    "start": "2062699",
    "end": "2068080"
  },
  {
    "text": "put the red block\ninto top left corner. Put another red block\ninto the top left corner. So it's rather a quite standard\nautoregressive language modeling",
    "start": "2068080",
    "end": "2079179"
  },
  {
    "text": "task. The only thing you need\nto do is to determine what task is not finished yet.",
    "start": "2079179",
    "end": "2085129"
  },
  {
    "text": "So, for example, if the block\nis already in the corner, it shouldn't call another policy\nto move it to the corner again.",
    "start": "2085130",
    "end": "2090679"
  },
  {
    "text": "So it's rather like\nunderstanding-- parsing the states and\nunderstanding the states. So this high-level policy\nonly requires about 50 to 100",
    "start": "2090679",
    "end": "2099190"
  },
  {
    "text": "demonstrations to learn. So it's quite\nparameter efficient. And in the future-- that's a very good question,\nactually-- in the future,",
    "start": "2099190",
    "end": "2105730"
  },
  {
    "text": "a lot of these tasks can\nbe taught in context. So maybe you just demonstrate\nit once to the large language",
    "start": "2105730",
    "end": "2112210"
  },
  {
    "text": "model, then it knows\nhow to do that. How can a large language model\nknow which low-level policy",
    "start": "2112210",
    "end": "2123869"
  },
  {
    "text": "it needs? Yeah, this is through human\ndemonstration as well. So a human on a low level can\ndemonstrate a low-level policy",
    "start": "2123870",
    "end": "2131119"
  },
  {
    "text": "by teleoperating a robot\nto do a certain task. But on a high\nlevel, it could also",
    "start": "2131120",
    "end": "2139130"
  },
  {
    "text": "just give the low-level policy. Imagine your control\ninterface is through text. And then you can--",
    "start": "2139130",
    "end": "2145340"
  },
  {
    "text": "as a human, you can also\nguide a low-level policy to accomplish a task. And then that thing can then be\nused to train a large language",
    "start": "2145340",
    "end": "2153800"
  },
  {
    "text": "model. So that's for the sorting block. The second is a little\nbit more interesting",
    "start": "2153800",
    "end": "2159350"
  },
  {
    "text": "because the planning steps are\nactually generated by PaLM. So we essentially distilled\nPaLM plus this affordance model",
    "start": "2159350",
    "end": "2169220"
  },
  {
    "text": "into PaLM-E. So that's a\nlittle bit more interesting. That's like using the AI\ndata to bootstrap itself.",
    "start": "2169220",
    "end": "2176020"
  },
  {
    "text": "That one has about\n3,000 episodes. Also, not quite a lot, but it's\nable to learn complex planning",
    "start": "2176020",
    "end": "2185040"
  },
  {
    "text": "behavior, replanning\nbehavior, error recovery, which I will show in this slide. So with the PaLM-E as\na high-level planner,",
    "start": "2185040",
    "end": "2194339"
  },
  {
    "text": "we are able to take the rice\nchips out of the drawer.",
    "start": "2194340",
    "end": "2200510"
  },
  {
    "text": "And there is a twist, which is I\nwill be messing with the robot.",
    "start": "2200510",
    "end": "2206570"
  },
  {
    "text": "And so as it put it\nonto the counter, I put it back to the drawer. And as it picked it up again,\nand then I put it back again.",
    "start": "2206570",
    "end": "2216690"
  },
  {
    "text": "So it's able to\nunderstand the state. It's able to understand\nmy task is not finished. I cannot proceed\nwith the next task.",
    "start": "2216690",
    "end": "2222980"
  },
  {
    "text": "Now, after I don't\nmess with it anymore, it's able to close the drawer\nand pick up the bag of chips.",
    "start": "2222980",
    "end": "2231160"
  },
  {
    "text": "So PaLM-E is able to combine\naffordance and planning in one",
    "start": "2231160",
    "end": "2236829"
  },
  {
    "text": "model and do complex\nreasoning of the scene and the environment.",
    "start": "2236830",
    "end": "2242230"
  },
  {
    "text": "And interestingly, we can use\nthe exact same model checkpoint to do block sorting as well.",
    "start": "2242230",
    "end": "2249158"
  },
  {
    "text": "So this is the same\nmodel checkpoint. It can not only reason about\nhow to bring a bag of chips",
    "start": "2249158",
    "end": "2255010"
  },
  {
    "text": "to a user. It can also sort blocks. And it's also responding to\nadversarial perturbation,",
    "start": "2255010",
    "end": "2263380"
  },
  {
    "text": "like if the user is putting\nthe block in the middle again, it's able to recover from that.",
    "start": "2263380",
    "end": "2270680"
  },
  {
    "text": "So these are all coming\nfrom the same model. And it can also tell jokes.",
    "start": "2270680",
    "end": "2277250"
  },
  {
    "text": "So yeah, that's just the power\nof vision language models.",
    "start": "2277250",
    "end": "2283220"
  },
  {
    "text": "Now, we want to\ngo a level deeper. These are all visual\nlanguage models that are used for planning\nor high-level reasoning.",
    "start": "2283220",
    "end": "2290310"
  },
  {
    "text": "Can we use them for\nlow-level control? It turns out we can. And that's the RT-2 work, which\nis the vision language action",
    "start": "2290310",
    "end": "2298160"
  },
  {
    "text": "model that transfers web\nknowledge to robotic control. What can it do? When asked, pick up\nthe extinct animal",
    "start": "2298160",
    "end": "2307970"
  },
  {
    "text": "and it has a whole range\nof objects on the table, it will pick up the dinosaur. So it can link\nthe extinct animal",
    "start": "2307970",
    "end": "2316790"
  },
  {
    "text": "to dinosaur and to the action\nto pick the dinosaur up. So it's really doing like this\nemergent reasoning, and also",
    "start": "2316790",
    "end": "2325340"
  },
  {
    "text": "the manipulation in\njust the one model. And by the way,\nthis robot hasn't",
    "start": "2325340",
    "end": "2330770"
  },
  {
    "text": "seen any of these before,\nat least in the robot training data. It might have seen this\nin the internet catalog.",
    "start": "2330770",
    "end": "2338410"
  },
  {
    "text": "But it has never seen it in\nthe robotics training data. So it's quite interesting\nhow we need to evaluate",
    "start": "2338410",
    "end": "2347610"
  },
  {
    "text": "these robots nowadays. So when we evaluate\nlanguage models,",
    "start": "2347610",
    "end": "2353309"
  },
  {
    "text": "to prevent data\ncontamination, every time you need to give it new\nquestions, because, otherwise,",
    "start": "2353310",
    "end": "2358740"
  },
  {
    "text": "it might have already\nmemorized it in its training. When we evaluate these robots,\nwe actually go to a dollar store",
    "start": "2358740",
    "end": "2365700"
  },
  {
    "text": "to buy all these toys to make\nsure it hasn't seen that before. And as we run more\nevaluations, maybe there",
    "start": "2365700",
    "end": "2372119"
  },
  {
    "text": "will be some\nreplication as well. But as you can see, it\nis able to understand",
    "start": "2372120",
    "end": "2377700"
  },
  {
    "text": "to pick up this dinosaur toy. How did we do that?",
    "start": "2377700",
    "end": "2382960"
  },
  {
    "text": "So we start from\na vision language model that is trained\non internet scale data.",
    "start": "2382960",
    "end": "2388640"
  },
  {
    "text": "And then we also combine it with\nrobotics action data, which is the RT-1 data, and we get RT-2.",
    "start": "2388640",
    "end": "2394970"
  },
  {
    "text": "And we can dive deeper, a\nlittle bit deeper into RT-2. So first of all, what is\na vision language model?",
    "start": "2394970",
    "end": "2402540"
  },
  {
    "text": "A vision language\nmodel is a transformer that takes in image and\ntext, and then outputs text.",
    "start": "2402540",
    "end": "2410990"
  },
  {
    "text": "So within Google, there's\na vision language model",
    "start": "2410990",
    "end": "2417650"
  },
  {
    "text": "called PaLI, which is\nan encoder-decoder type of architecture. It's basically having a ViT\nto understand images, and then",
    "start": "2417650",
    "end": "2425809"
  },
  {
    "text": "a transformer encoder and\nthe transformer decoder. They encompass both the\nvisual and semantics",
    "start": "2425810",
    "end": "2434360"
  },
  {
    "text": "to understand the world. In the robotics, we have to deal\nwith a lot of both of these.",
    "start": "2434360",
    "end": "2439930"
  },
  {
    "text": "And the question\nis, can we leverage the knowledge in the\nvisual language models",
    "start": "2439930",
    "end": "2445810"
  },
  {
    "text": "and apply them to robotics? On the other hand,\nwe have the RT-1.",
    "start": "2445810",
    "end": "2451060"
  },
  {
    "text": "If you want to learn\nmore about RT-1, you can listen to the previous\nepisode of this CS25 by Ted.",
    "start": "2451060",
    "end": "2459049"
  },
  {
    "text": "So he gave a detailed\nintroduction on the RT-1. But the RT-1, if you\nstand far enough,",
    "start": "2459050",
    "end": "2466420"
  },
  {
    "text": "it is also a vision language\nto action or something model.",
    "start": "2466420",
    "end": "2472089"
  },
  {
    "text": "It takes in human instruction. It takes in the\ncurrent camera image. The camera image passes through\na film efficient net, which",
    "start": "2472090",
    "end": "2479529"
  },
  {
    "text": "is tokenized into\n81 tokens, and then going to a token learner,\nwhich compresses everything",
    "start": "2479530",
    "end": "2484840"
  },
  {
    "text": "into eight tokens. And then there is\na transformer block leveraging a lot of\nself-attention layer,",
    "start": "2484840",
    "end": "2490570"
  },
  {
    "text": "and then generates actions. The action is also tokenized. The robot has seven\ndegrees of freedom.",
    "start": "2490570",
    "end": "2500380"
  },
  {
    "text": "Basically, the end\neffector has six degrees of freedom, its\nposition and rotation,",
    "start": "2500380",
    "end": "2507040"
  },
  {
    "text": "and the gripper\ncan open and close. And there is another\ndimension representing",
    "start": "2507040",
    "end": "2512480"
  },
  {
    "text": "terminate the episode or not. Terminating means my\ntask is already done. And we discretize every\ndimension into 256 bins.",
    "start": "2512480",
    "end": "2522869"
  },
  {
    "text": "And then we do cross\nentropy loss on those bins. So that's RT-1\narchitecture in a nutshell.",
    "start": "2522870",
    "end": "2529770"
  },
  {
    "text": "It's quite similar to\na vision language model with different output tokens. So it's rather\nnatural that we just",
    "start": "2529770",
    "end": "2536000"
  },
  {
    "text": "use a large pre-trained\nvision language model directly as policy. We can use the PaLI\nor PaLM-E as a policy.",
    "start": "2536000",
    "end": "2543890"
  },
  {
    "text": "And one question is, how\ndo we deal with actions when using pretrained\nvisual language models?",
    "start": "2543890",
    "end": "2549680"
  },
  {
    "text": "And here is the actual\nrepresentation that we use. The robot actions here\nare the eight dimensions.",
    "start": "2549680",
    "end": "2557910"
  },
  {
    "text": "And as I mentioned, there's\ntermination, position change, and rotation change. And we discretize\neverything into 256 bins.",
    "start": "2557910",
    "end": "2566849"
  },
  {
    "text": "We also have tried other\nalternative representations, but they are not as good as\njust this naive representation.",
    "start": "2566850",
    "end": "2573180"
  },
  {
    "text": "Yes. Can you go back to\nthe previous slide? Yeah. [INAUDIBLE],, what is\nFILM EfficientNet?",
    "start": "2573180",
    "end": "2579650"
  },
  {
    "text": "The FILM EfficientNet is a\npretrained convolutional neural network. It's used to\ntokenize the images.",
    "start": "2579650",
    "end": "2586860"
  },
  {
    "text": "So the reason that we do this\nis through some ablation study, we can tokenize the\nimage in different ways.",
    "start": "2586860",
    "end": "2592470"
  },
  {
    "text": "We can tokenize in ResNet. We can tokenize\neverything into ResNet. And we can tokenize\nusing FILM EfficientNet.",
    "start": "2592470",
    "end": "2599810"
  },
  {
    "text": "FILM, what it means is it\nalso takes into the language embedding and appends it\nto the intermediate layers",
    "start": "2599810",
    "end": "2607170"
  },
  {
    "text": "of the ResNet. So you basically have\nsome concatenation of whatever sentence\nyou put in in images?",
    "start": "2607170",
    "end": "2613910"
  },
  {
    "text": "Yeah. That goes through\nthis neural network, this convolutional network? That's right. That's right.",
    "start": "2613910",
    "end": "2619212"
  },
  {
    "text": "[INAUDIBLE] condition\n[INAUDIBLE] transform it. Self-attention output\ngoes to action training.",
    "start": "2619212",
    "end": "2624757"
  },
  {
    "text": "That's right. It's action as in the code. The action is not in code. The action is in text.",
    "start": "2624758",
    "end": "2631680"
  },
  {
    "text": "It's basically\nwhat is shown here. This is the action. ",
    "start": "2631680",
    "end": "2637140"
  },
  {
    "text": "It's eight numbers. Each number ranges\nfrom 0 to 255.",
    "start": "2637140",
    "end": "2643070"
  },
  {
    "text": "And maybe another note\non the FILM ResNet. It's about how we\ntokenize the images",
    "start": "2643070",
    "end": "2649280"
  },
  {
    "text": "and how we combine vision\ninformation and language information.",
    "start": "2649280",
    "end": "2654640"
  },
  {
    "text": "There are many ways to do that. This is not the only way. There is early fusion\nand late fusion,",
    "start": "2654640",
    "end": "2659810"
  },
  {
    "text": "and there is also\ncross-attention. You can basically tokenize\nyour image just by itself.",
    "start": "2659810",
    "end": "2665009"
  },
  {
    "text": "And then you can have language\nand use cross-attention to combine the image\nand text representation.",
    "start": "2665010",
    "end": "2670950"
  },
  {
    "text": "So here we are using this model. This is RT-1 for robotics. So we do have a lot of\nconsiderations, such as latency.",
    "start": "2670950",
    "end": "2678420"
  },
  {
    "text": "That's why we use this FILM\nResNet, because it's super fast. And it can output\na limited amount",
    "start": "2678420",
    "end": "2685130"
  },
  {
    "text": "of tokens, which we can further\ncompress with a token learner. Yeah. And is this autoregressive,\nlike every single image",
    "start": "2685130",
    "end": "2692270"
  },
  {
    "text": "it sees, it then [INAUDIBLE]? Right. So it is autoregressive, yeah. And every time we use a\nhistory of up to six steps,",
    "start": "2692270",
    "end": "2701839"
  },
  {
    "text": "so every time you see\nthis image right now, and you see about 2 seconds\nof history before it.",
    "start": "2701840",
    "end": "2708660"
  },
  {
    "text": "And this will be your input. Again, if you have more\nquestions about RT-1,",
    "start": "2708660",
    "end": "2715290"
  },
  {
    "text": "I recommend watching\nthe previous episode. And here is all about RT-2.",
    "start": "2715290",
    "end": "2722589"
  },
  {
    "text": "So we can convert the\nstring of numbers. This will be our output\nof our transformer, which",
    "start": "2722590",
    "end": "2730020"
  },
  {
    "text": "is a vision language model. We tried other alternatives,\nsuch as floating numbers.",
    "start": "2730020",
    "end": "2735040"
  },
  {
    "text": "Floating numbers is not super\nfriendly to language model tokenizer because it has\nthese decimal points.",
    "start": "2735040",
    "end": "2742420"
  },
  {
    "text": "We also try the human language,\nsuch as left or right. It's more a semantic\nrepresentation, but they cannot be directly\nexecuted on a robot,",
    "start": "2742420",
    "end": "2749400"
  },
  {
    "text": "which is a limitation\nof this method. So if we commit to this action\nrepresentation, which is just",
    "start": "2749400",
    "end": "2757260"
  },
  {
    "text": "a string of numbers,\nwe essentially get a vision language\naction model. We tried different\nvariants, including",
    "start": "2757260",
    "end": "2763680"
  },
  {
    "text": "PaLI-X. This is a Pathways\nlangauge image model.",
    "start": "2763680",
    "end": "2769260"
  },
  {
    "text": "It can-- there are a\n5-billion parameter variant and a 55-billion\nparameter variant.",
    "start": "2769260",
    "end": "2775660"
  },
  {
    "text": "And we also tried PaLM-E,\nwhich is 12 billion parameters. The procedure that we\ndid to train this RT-2",
    "start": "2775660",
    "end": "2784320"
  },
  {
    "text": "is via fine tuning. So fine tuning is to put\nthe internet scale data",
    "start": "2784320",
    "end": "2790380"
  },
  {
    "text": "and the robotic data together. And then we fine tune it\non this mixture of data",
    "start": "2790380",
    "end": "2796650"
  },
  {
    "text": "so that it retains the\ninternet scale knowledge.",
    "start": "2796650",
    "end": "2802660"
  },
  {
    "text": "Maybe that's also an\nartifact of our data is too small and\nnot diverse enough. So if you just fine\ntune on robotics data,",
    "start": "2802660",
    "end": "2808630"
  },
  {
    "text": "it will quickly\noverfit and forget about all this\npretraining mixture.",
    "start": "2808630",
    "end": "2814150"
  },
  {
    "text": "Maybe it's a dynamic of scale. So we'll see.",
    "start": "2814150",
    "end": "2819490"
  },
  {
    "text": "At inference time,\nhow do we do this? We basically-- again, we\ndo this autoregressively.",
    "start": "2819490",
    "end": "2825640"
  },
  {
    "text": "We have an\ninstruction of a task. And we format this as a\nquestion and answering task.",
    "start": "2825640",
    "end": "2832960"
  },
  {
    "text": "What should the robot do\nto achieve a certain task? And the task is a string\nthat humans give the robot",
    "start": "2832960",
    "end": "2838779"
  },
  {
    "text": "for the robot to achieve. And it also has the\ncurrent observation,",
    "start": "2838780",
    "end": "2846390"
  },
  {
    "text": "which is the robot observation,\nthe camera image, RGB image, a pass through of\nViT, and then a pass",
    "start": "2846390",
    "end": "2853349"
  },
  {
    "text": "through of the large language\nmodel, and then output a list of tokens. So we leverage constraint\ndecoding to make sure it always",
    "start": "2853350",
    "end": "2862650"
  },
  {
    "text": "has eight numbers,\nbecause, otherwise,",
    "start": "2862650",
    "end": "2868200"
  },
  {
    "text": "we cannot detokenize it. It's very easy for a language\nmodel to just miss one number, right? So we do have some mechanism,\nsuch as constraint decoding",
    "start": "2868200",
    "end": "2876930"
  },
  {
    "text": "and beam search to make\nsure the format is correct. After we get the string\nof eight numbers, we detokenize it to\na delta t and delta",
    "start": "2876930",
    "end": "2884280"
  },
  {
    "text": "r, which is the end\neffector delta [INAUDIBLE].. And the robot can just\ndirectly run this on the robot.",
    "start": "2884280",
    "end": "2890370"
  },
  {
    "text": "After the run on the robot,\nwe repeat this process. We get another new image,\nrun through this process,",
    "start": "2890370",
    "end": "2895770"
  },
  {
    "text": "and get the new action. And we repeat this process\nuntil a termination is decoded.",
    "start": "2895770",
    "end": "2900900"
  },
  {
    "text": "So some people\nmight be concerned that this is rather slow.",
    "start": "2900900",
    "end": "2906220"
  },
  {
    "text": "It's, in fact, quite\nslow, because it's 12 billion parameters\nor 5 billion parameters.",
    "start": "2906220",
    "end": "2912970"
  },
  {
    "text": "We cannot run it on a robot. So we run on a TPU\ncluster, and the robot is querying the TPU\ncluster to get the numbers",
    "start": "2912970",
    "end": "2920310"
  },
  {
    "text": "and apply it on the robot. So for the 12\nbillion parameters, we can actually run at 10 hertz.",
    "start": "2920310",
    "end": "2927880"
  },
  {
    "text": "So it's quite fast. For all of the model, we\ncan run at least 3 hertz. So that is sufficient for\ncontrolling our robot.",
    "start": "2927880",
    "end": "2937369"
  },
  {
    "text": "And we see a lot of emerging\nskills that is not trained--",
    "start": "2937370",
    "end": "2942770"
  },
  {
    "text": "that is not on the training set. Essentially, as\nI just mentioned, we are probing what\nthis RT-2 can do.",
    "start": "2942770",
    "end": "2949202"
  },
  {
    "text": "We actually don't know. So we are trying to figure\nout what the RT-2 can do. So we test it with a lot\nof new tasks, such as,",
    "start": "2949202",
    "end": "2956089"
  },
  {
    "text": "put a strawberry into\nthe correct bowl, or move banana to\nGermany, like just",
    "start": "2956090",
    "end": "2961310"
  },
  {
    "text": "to test its understanding\nof symbols or flags. Pick a land animal.",
    "start": "2961310",
    "end": "2967753"
  },
  {
    "text": "There's a horse. There's an octopus. But basically, test the\nsemantic reasoning, and also",
    "start": "2967753",
    "end": "2973400"
  },
  {
    "text": "low-level manipulation skills. And we divide the tasks\ninto symbol understanding,",
    "start": "2973400",
    "end": "2981920"
  },
  {
    "text": "and reasoning, and human\nrecognition, and average. We found with RT-1, which is not\ntrained on internet scale data.",
    "start": "2981920",
    "end": "2990590"
  },
  {
    "text": "We do quite poorly in these\nemergent evaluation tasks. And in the RT-2\nvariants, which is fine",
    "start": "2990590",
    "end": "3003320"
  },
  {
    "text": "tuned on the internet\ndata and on robotics data, we do much better\nin these tasks. And there is also\nan effect of scale.",
    "start": "3003320",
    "end": "3011009"
  },
  {
    "text": "So the RT-2 was a\n55 billion PaLI. It's performing better\nthan the 12 billion PaLM-E.",
    "start": "3011010",
    "end": "3017390"
  },
  {
    "text": "Although, they perform quite\nsimilarly for in-domain tasks. But the generalization\nis kind of interesting.",
    "start": "3017390",
    "end": "3023280"
  },
  {
    "text": "It seems with larger scale,\nyou can generalize better. And here are some videos of the\nrobot achieving these tasks,",
    "start": "3023280",
    "end": "3032349"
  },
  {
    "text": "like moving the\nbanana to a number. Put the strawberry\ninto the correct bowl.",
    "start": "3032350",
    "end": "3039250"
  },
  {
    "text": "Move a Rubik's cube\nto the water bottle. But I'm speaking Chinese. Moving the banana\nto a German flag.",
    "start": "3039250",
    "end": "3046750"
  },
  {
    "text": "So it's able to do all of\nthese very interesting tasks.",
    "start": "3046750",
    "end": "3051830"
  },
  {
    "text": "In terms of the\nquantitative evaluations, we also found that\nthe attitude policy",
    "start": "3051830",
    "end": "3057500"
  },
  {
    "text": "is quite robust to unseen\nobjects, unseen backgrounds, and unseen environments.",
    "start": "3057500",
    "end": "3063440"
  },
  {
    "text": "And here is another evidence\nof positive transfer. So co-fine-tuned with\nVQA data outperforms",
    "start": "3063440",
    "end": "3070430"
  },
  {
    "text": "fine-tuning on robotics only. And if you train on robot data\nfrom scratch, it barely works.",
    "start": "3070430",
    "end": "3076740"
  },
  {
    "text": "It almost doesn't work because\nit overfits to robot data, and our robot data\nis just too small. So we do need to do\nco-fine-tuning, or at least",
    "start": "3076740",
    "end": "3086619"
  },
  {
    "text": "the fine-tuning so it retains\nits internet scale knowledge. This is also a\nrecipe for how people",
    "start": "3086620",
    "end": "3093410"
  },
  {
    "text": "would develop a domain\nspecific vision language model. So you start from a very\ngeneral vision language model,",
    "start": "3093410",
    "end": "3099380"
  },
  {
    "text": "and you fine tune\non your domain, or you can co-fine-tune with\nyour specific domain data.",
    "start": "3099380",
    "end": "3105450"
  },
  {
    "text": "This is likely a problem\nthat each vertical of artificial intelligence\nwould incur someday.",
    "start": "3105450",
    "end": "3114450"
  },
  {
    "text": "We can also test\non other platforms, like this shows some\ncross embodiment. The RT-2 PaLI-3B outperforms\nprevious models in terms",
    "start": "3114450",
    "end": "3122580"
  },
  {
    "text": "of moving blocks around\na 2D environment. So this is-- and in\nlarge language models,",
    "start": "3122580",
    "end": "3130370"
  },
  {
    "text": "we have this chain of\nthought reasoning, which is a method to elicit reasoning\nin large language models.",
    "start": "3130370",
    "end": "3137833"
  },
  {
    "text": "You can either do\nzero [INAUDIBLE] chain-of-thought\nreasoning by saying, let's think step by step. I'll give it the\nexamples of reasoning.",
    "start": "3137833",
    "end": "3143570"
  },
  {
    "text": "It's basically\ndecoding more things, and then come to the conclusion. We can use a similar procedure\nfor the RT-2 as well.",
    "start": "3143570",
    "end": "3151970"
  },
  {
    "text": "So in the RT-2 PaLM-E,\ninstead of directly decoding the actions, we can\nactually decode a plan,",
    "start": "3151970",
    "end": "3157910"
  },
  {
    "text": "and then append it with actions. So this gives the language\nmodel an opportunity to understand the question or\nparse the question differently.",
    "start": "3157910",
    "end": "3165809"
  },
  {
    "text": "It also gives us the\nopportunity to reason about things a little bit. For example, if you say, bring\nme a drink, and it will, say,",
    "start": "3165810",
    "end": "3173900"
  },
  {
    "text": "pick up a 7up can because\nthere's a 7up can on the table. So we synthesized a couple of\nhundred such examples using",
    "start": "3173900",
    "end": "3181040"
  },
  {
    "text": "a large language model, just\nby augmenting the instruction, and then fine tune the RT-2 just\nfor a couple of hundred steps.",
    "start": "3181040",
    "end": "3187090"
  },
  {
    "text": "So it's between for fine\ntuning and in-context learning. And it's able to\ndo some reasoning.",
    "start": "3187090",
    "end": "3193170"
  },
  {
    "text": "And some of the\ninteresting reasoning tasks include, I need\nto hammer a nail. Which object from the\nscene might be useful?",
    "start": "3193170",
    "end": "3199360"
  },
  {
    "text": "And in the scene,\nthere is a headphone. There is a rock. And there is a sticky note.",
    "start": "3199360",
    "end": "3204520"
  },
  {
    "text": "And the robot will\nsay, rocks, and then generate actions to\npick up the rock. So it's interesting\nthat it's able to do",
    "start": "3204520",
    "end": "3211260"
  },
  {
    "text": "this self-reasoning with RT-2. And here is a\ndemonstration of some of the chain-of-thought\nreasoning with RT-2 PaLM-E.",
    "start": "3211260",
    "end": "3219510"
  },
  {
    "text": "And the task is\npick up the thing that is different from\nall other objects. And it picks up the chocolate\nbecause this is a snack,",
    "start": "3219510",
    "end": "3227422"
  },
  {
    "text": "and the other things\nare the drink. And I can also speak\na different language. And the plan would be to\ntranslate it into a language",
    "start": "3227422",
    "end": "3234750"
  },
  {
    "text": "that it's familiar\nwith, which is English, and then do the task. ",
    "start": "3234750",
    "end": "3241020"
  },
  {
    "text": "There are also\npotentially failure cases of the chain-of-thought\nreasoning. So here, I say, move the\ngreen objects together.",
    "start": "3241020",
    "end": "3246580"
  },
  {
    "text": "And as you can see,\nthe robot oscillates between the two green\nobjects because there are rather two plans. It could move the can\nto the bag of chips,",
    "start": "3246580",
    "end": "3254400"
  },
  {
    "text": "or it could move the\nbag of chips to the can. It oscillates between two\nplans until one action,",
    "start": "3254400",
    "end": "3260730"
  },
  {
    "text": "bring it to an\nobject, and it will commit to one of the\nplans rather than another.",
    "start": "3260730",
    "end": "3266140"
  },
  {
    "text": "It's not always\nguaranteed to work, but it's quite interesting. And it's also interesting\nthat, again, we",
    "start": "3266140",
    "end": "3271599"
  },
  {
    "text": "are testing the\nmanipulation policy, like how we test intelligence\nof humans, or animals, or kids,",
    "start": "3271600",
    "end": "3278800"
  },
  {
    "text": "because they're getting\nmore and more advanced. As a summary, we have\nthe vision, language,",
    "start": "3278800",
    "end": "3285360"
  },
  {
    "text": "and action model that\nis able to achieve-- improve the generalization.",
    "start": "3285360",
    "end": "3290599"
  },
  {
    "text": "It can do new tasks and\noperate new objects. It can also do\nchain-of-thought reasoning.",
    "start": "3290600",
    "end": "3295619"
  },
  {
    "text": "And improving the\nunderlying model, such as the vision language\nmodel itself by scaling it up.",
    "start": "3295620",
    "end": "3303390"
  },
  {
    "text": "And trained with\ninternet scale data, or trained with larger or higher\nquality internet scale data,",
    "start": "3303390",
    "end": "3310080"
  },
  {
    "text": "we can achieve\nbetter robot control, which is quite amazing,\nbecause robotics field has been traditionally\ndeveloping quite slowly",
    "start": "3310080",
    "end": "3316890"
  },
  {
    "text": "and is bounded by\nhardware, bounded by a lot of different\nthings, bounded by operation. But now it seems we can\npiggyback on the development",
    "start": "3316890",
    "end": "3324750"
  },
  {
    "text": "of the foundation model field. And whatever they do will\ntrickle down to our field as well.",
    "start": "3324750",
    "end": "3330309"
  },
  {
    "text": "And the future will be to\nincrease the motion diversity and extend on the\nchain-of-thought reasoning",
    "start": "3330310",
    "end": "3335430"
  },
  {
    "text": "capability, and many more. And so there is another example\nof positive transfer, which",
    "start": "3335430",
    "end": "3344410"
  },
  {
    "text": "you might have seen recently. So far I've been talking about\nscaling differently, right?",
    "start": "3344410",
    "end": "3349730"
  },
  {
    "text": "I've been talking about\ndon't scale robotics data and scale other data. That's because robotics\ndata is so hard to collect.",
    "start": "3349730",
    "end": "3356720"
  },
  {
    "text": "And the purpose is not to\navoid collecting robotics data. It's to develop a recipe\nthat you can do more",
    "start": "3356720",
    "end": "3364090"
  },
  {
    "text": "with limited robotics data. However, there's also\nan effort from our team and the entire robotics\nfield to scale up",
    "start": "3364090",
    "end": "3372820"
  },
  {
    "text": "the robot data collection, which\nis called the Open X Embodiment. And the model train is called\nRTX, Robotics Transformer",
    "start": "3372820",
    "end": "3379755"
  },
  {
    "text": "X. It's basically 22 type of\nembodiments, and 572 skills,",
    "start": "3379755",
    "end": "3385779"
  },
  {
    "text": "and 60 data sets\npulled all together. So this will be\nthe ultimate data set we can use to study\npositive transfer and to scale--",
    "start": "3385780",
    "end": "3393250"
  },
  {
    "text": "to study this joint scaling. And there are already\nevidences of positive transfer.",
    "start": "3393250",
    "end": "3401850"
  },
  {
    "text": "So we pulled all the data\ntogether from all these labs",
    "start": "3401850",
    "end": "3407190"
  },
  {
    "text": "and find a common\naction representation that we can use to train\nour robotic transformer.",
    "start": "3407190",
    "end": "3412839"
  },
  {
    "text": "And we have already found\nthis jointly trained model can outperform a task-specific\nmodel that is",
    "start": "3412840",
    "end": "3420420"
  },
  {
    "text": "developed in each of the labs. So there is some benefits\nin pulling all of the data together.",
    "start": "3420420",
    "end": "3425680"
  },
  {
    "text": "So scaling robot data\nis also quite important.",
    "start": "3425680",
    "end": "3432260"
  },
  {
    "text": "So the summary for this\npart is that we are having a model consolidation. We can now do the high-level\nreasoning and low-level control",
    "start": "3432260",
    "end": "3440180"
  },
  {
    "text": "in one model. And the low-level\ncontrol part is what excites me,\nbecause it's so far away from the traditional\nlanguage model domain.",
    "start": "3440180",
    "end": "3448980"
  },
  {
    "text": "It's so different. And it shows signs of life\nthat we can trickle down",
    "start": "3448980",
    "end": "3454040"
  },
  {
    "text": "a lot more than we used\nto think is possible. And we can scale the pretraining\nof visual language models,",
    "start": "3454040",
    "end": "3460370"
  },
  {
    "text": "as well as scaling\nrobotics data. And we observe more\nand more positive transfer-- model benefiting\nfrom diverse joint training",
    "start": "3460370",
    "end": "3467630"
  },
  {
    "text": "across internet-scale\nlanguage, vision, and vision-language domains. ",
    "start": "3467630",
    "end": "3474520"
  },
  {
    "text": "So I noticed that we are\nclose to running out of time. So I will just very quickly go\nthrough the second part, which",
    "start": "3474520",
    "end": "3481950"
  },
  {
    "text": "I think is also interesting. It's to find new interfaces\nof language models. But I would only talk\nat a very high level.",
    "start": "3481950",
    "end": "3489720"
  },
  {
    "text": "So language models,\nas we can see, can directly output\naction tokens if we found an action\nrepresentation.",
    "start": "3489720",
    "end": "3495610"
  },
  {
    "text": "So we can treat an action as yet\nanother language to the language model. So a language model\ncan do translation.",
    "start": "3495610",
    "end": "3501579"
  },
  {
    "text": "So it should be able to\ngenerate action as well. But that requires fine tuning. Can we do it\nwithout fine tuning,",
    "start": "3501580",
    "end": "3507810"
  },
  {
    "text": "or can we generate\nmore expressive actions that is beyond the\nscope of fine tuning?",
    "start": "3507810",
    "end": "3514180"
  },
  {
    "text": "So that is about finding\nthe right interface. So previously, we have\nalready established",
    "start": "3514180",
    "end": "3520710"
  },
  {
    "text": "that language model doesn't\nhave an action interface. If it has an action interface,\nit's not as effective.",
    "start": "3520710",
    "end": "3528060"
  },
  {
    "text": "So what is the best\ninterface between language and a lot of actions? I would argue the best interface\nbetween a language model",
    "start": "3528060",
    "end": "3536200"
  },
  {
    "text": "and a lot of actions\nis reward functions. And reward functions\nis universal.",
    "start": "3536200",
    "end": "3544069"
  },
  {
    "text": "It has been used in\nreinforcement learning. And it's also a\nreparameterization of actions.",
    "start": "3544070",
    "end": "3550869"
  },
  {
    "text": "What is action? Let me-- let's see if I\nwant to pick up this bottle. And I can say, what is a skill?",
    "start": "3550870",
    "end": "3557890"
  },
  {
    "text": "A skill is a mapping between\nmy observation and my action. So the mapping between\nmy observation and action",
    "start": "3557890",
    "end": "3563950"
  },
  {
    "text": "can be seen as a skill. But a skill can have an\nalternative definition, which is a set of constraints\nand a set of objectives.",
    "start": "3563950",
    "end": "3571400"
  },
  {
    "text": "So picking up the bottle means\nthe bottle is in my right hand, and the bottle is off\na supporting surface.",
    "start": "3571400",
    "end": "3578900"
  },
  {
    "text": "That means picking up. And how do I pick it up\ndoesn't really matter. That's a more-- to its broader\nsense, the definition of skills",
    "start": "3578900",
    "end": "3587109"
  },
  {
    "text": "is more transferable\nbetween different skills. And the constraints\nand objectives",
    "start": "3587110",
    "end": "3594540"
  },
  {
    "text": "can be represented as rewards. So we can ask the language\nmodel to generate these reward",
    "start": "3594540",
    "end": "3601450"
  },
  {
    "text": "functions. And then there is an optimizer. It could be reinforced\nlearning, or it could be model\npredictive control that",
    "start": "3601450",
    "end": "3608950"
  },
  {
    "text": "optimizes for those rewards,\nand then run it on the robot.",
    "start": "3608950",
    "end": "3614170"
  },
  {
    "text": "So what is in the\nreward translator? Let's open a box.",
    "start": "3614170",
    "end": "3619309"
  },
  {
    "text": "So the reward\ntranslator, basically, is a two-stage process. It's using the same\nlanguage model,",
    "start": "3619310",
    "end": "3625090"
  },
  {
    "text": "and it is using two\ndifferent prompts. So the motion description\nbasically describes the motion.",
    "start": "3625090",
    "end": "3632240"
  },
  {
    "text": "So just now we found that\nthe language model can output a description of how a\nrobot dog should stand up,",
    "start": "3632240",
    "end": "3639760"
  },
  {
    "text": "but it's not able\nto achieve that. But the motion description\nis still sensible. It still makes sense.",
    "start": "3639760",
    "end": "3645290"
  },
  {
    "text": "It gives you the right thing. So we're just like, generate\nthis motion description,",
    "start": "3645290",
    "end": "3650410"
  },
  {
    "text": "and then we have a reward\ntranslator, a reward coder that translates this\nmotion description",
    "start": "3650410",
    "end": "3655540"
  },
  {
    "text": "into a piece of code that is\nrepresenting reward functions.",
    "start": "3655540",
    "end": "3662230"
  },
  {
    "text": "And these reward functions\ncannot be directly executed on the robot.",
    "start": "3662230",
    "end": "3667330"
  },
  {
    "text": "But it can go through\nan optimization process to learn how to achieve\nthose reward functions.",
    "start": "3667330",
    "end": "3673369"
  },
  {
    "text": "So we're using reward as the\ninterface between language model and a low-level controller.",
    "start": "3673370",
    "end": "3679510"
  },
  {
    "text": "And for the\nlow-level controller, we're using MuJoCo MPC, which\nis a model predictive control",
    "start": "3679510",
    "end": "3686170"
  },
  {
    "text": "algorithm. It's basically a\nblack box controller. It samples a lot of\ntrajectories and finds",
    "start": "3686170",
    "end": "3692230"
  },
  {
    "text": "one that optimizes your reward. And we tested it on a robot dog,\na quadruped robot, essentially,",
    "start": "3692230",
    "end": "3699760"
  },
  {
    "text": "and a dexterous manipulator. So the dexterous manipulator\nhas an arm of six",
    "start": "3699760",
    "end": "3704870"
  },
  {
    "text": "or seven degrees of\nfreedom and a hand. It's impossible to\ncontrol it because it",
    "start": "3704870",
    "end": "3710920"
  },
  {
    "text": "has so many degrees of freedom. So it's highly challenging.",
    "start": "3710920",
    "end": "3716230"
  },
  {
    "text": "So just to showcase\nsome of the examples, I omitted the motion\ndescription part.",
    "start": "3716230",
    "end": "3722090"
  },
  {
    "text": "I only output the\nreward code part.",
    "start": "3722090",
    "end": "3727220"
  },
  {
    "text": "So it seems that\nthe language model is able to generate\nthe right reward functions to make\nthe robot stand up",
    "start": "3727220",
    "end": "3734950"
  },
  {
    "text": "on two back feet like a human. And now we are a little\nbit more ambitious.",
    "start": "3734950",
    "end": "3740200"
  },
  {
    "text": "We know it can stand up. Can we make the\nrobot do a moonwalk while standing up like this? So a moonwalk is\nfrom Michael Jackson,",
    "start": "3740200",
    "end": "3747010"
  },
  {
    "text": "and it's very challenging. How do we make the\nrobot to do it? So it generates the\nmotion description",
    "start": "3747010",
    "end": "3752590"
  },
  {
    "text": "and generates the reward code. But the motion is\nnot so correct-- not",
    "start": "3752590",
    "end": "3759170"
  },
  {
    "text": "exactly what we want. The nice thing about\nusing a language model and using the reward function\nis that you can coach the robot.",
    "start": "3759170",
    "end": "3765930"
  },
  {
    "text": "You can go back and\nexplain what went wrong, and ask the language\nmodel to fix it.",
    "start": "3765930",
    "end": "3770990"
  },
  {
    "text": "So now we can actually say-- you're being very patient. You say, moonwalk\nmeans a robot should",
    "start": "3770990",
    "end": "3776900"
  },
  {
    "text": "walk backwards\nwhile the feet swing as if they are moving forward.",
    "start": "3776900",
    "end": "3782690"
  },
  {
    "text": "Such a great explanation. Kudos to my colleague. And correct your\nanswer, and also",
    "start": "3782690",
    "end": "3787820"
  },
  {
    "text": "make it work at the speed\nof 0.5 meters per second. And after you-- like\nbeing very patient",
    "start": "3787820",
    "end": "3793309"
  },
  {
    "text": "and give it the\nright instruction, it's able to modify the\nreward-- the motion descriptor",
    "start": "3793310",
    "end": "3798890"
  },
  {
    "text": "and also generate the right set\nof rewards to make this happen. And now you can teach\na robot to do moonwalk,",
    "start": "3798890",
    "end": "3805849"
  },
  {
    "text": "just by using the\nlanguage as an interface. And one day we'll be able to do\nthis on the real robot as well.",
    "start": "3805850",
    "end": "3812370"
  },
  {
    "text": "Yes. So the previous session, he\nshowed how the [INAUDIBLE]",
    "start": "3812370",
    "end": "3818932"
  },
  {
    "text": "big numbers, and you're\nconstraining them to [? just ?] big numbers. Here, how do you prevent it from\njust hallucinating [INAUDIBLE]??",
    "start": "3818932",
    "end": "3825480"
  },
  {
    "text": "Right. So that's a great question. In this work, we are\nnot preventing it,",
    "start": "3825480",
    "end": "3832319"
  },
  {
    "text": "hallucination-- to\ndo hallucination in a programmatic way. We have a set of system\nprompts or a set of rules",
    "start": "3832320",
    "end": "3840200"
  },
  {
    "text": "that is explaining the API. After all, the\nreward functions need",
    "start": "3840200",
    "end": "3845329"
  },
  {
    "text": "to be able to be compiled by\nthe optimizer, and then after--",
    "start": "3845330",
    "end": "3851600"
  },
  {
    "text": "so we do need to\nhave some check. What's more, if it\ndoesn't compile, we can just give the error\nmessage to the language model.",
    "start": "3851600",
    "end": "3858530"
  },
  {
    "text": "It doesn't have to propagate\nall the way to the motion descriptor. It can stay at the reward coder. If there are errors,\nplease fix it.",
    "start": "3858530",
    "end": "3865080"
  },
  {
    "text": "So after that, it should\nbe able to fix it. We can also chain\nmultiple tasks together.",
    "start": "3865080",
    "end": "3871859"
  },
  {
    "text": "Using this framework, we\ncan say, open the drawer. Take the apple. Put it into the drawer.",
    "start": "3871860",
    "end": "3877980"
  },
  {
    "text": "And close the door. And it will be able to do that. So we tried that.",
    "start": "3877980",
    "end": "3883440"
  },
  {
    "text": "Just using reward coder\nis not good enough. It's rather our two-stage prompt\nis really, really helpful.",
    "start": "3883440",
    "end": "3891000"
  },
  {
    "text": "I think that's another\ninspiration for other fields, like when your domain is too\ndifferent from language domain,",
    "start": "3891000",
    "end": "3897549"
  },
  {
    "text": "maybe it would be good to find\nan intermediate representation and ask the language\nmodel to explain in that intermediate\nrepresentation",
    "start": "3897550",
    "end": "3904050"
  },
  {
    "text": "before it directly goes to a\nmore obscure representation. And finally, we want to\ntransfer this to the real world.",
    "start": "3904050",
    "end": "3912180"
  },
  {
    "text": "But there is a challenge. In simulation, it might\ngenerate actions that are too dexterous, like this.",
    "start": "3912180",
    "end": "3919550"
  },
  {
    "text": "This thing is not possible\nto do in the real world. So we add a few more regularizer\nterms to stabilize the motion.",
    "start": "3919550",
    "end": "3928720"
  },
  {
    "text": "And we also run some state\nestimation on the real robot so that they understand\nwhere is the cubes.",
    "start": "3928720",
    "end": "3936819"
  },
  {
    "text": "And then we can, in the\nsimulation, grab the motion, and then achieve it\nin the real world. So here are some of the\nexecution in the real world.",
    "start": "3936820",
    "end": "3944950"
  },
  {
    "text": "So you can say, pick\nup the Rubik's cube, and it will generate\nthe motion to pick up",
    "start": "3944950",
    "end": "3950670"
  },
  {
    "text": "the Rubik's cube and the apple. This is quite\ndifferent from RT-2. The motions are quite smooth.",
    "start": "3950670",
    "end": "3956820"
  },
  {
    "text": "It's quite fast. It's much faster than 3 hertz. So here it can do 10\nhertz, or even 30 hertz.",
    "start": "3956820",
    "end": "3967870"
  },
  {
    "text": "So it's comparable\nwith human speed. All right, so that's\nlanguage to reward.",
    "start": "3967870",
    "end": "3975230"
  },
  {
    "text": "There's one last\nthing that I want to talk about in terms of\nfinding a new interface.",
    "start": "3975230",
    "end": "3980390"
  },
  {
    "text": "So a lot of time we have been\nthinking about language model as a semantic engine,\na semantic machine.",
    "start": "3980390",
    "end": "3986359"
  },
  {
    "text": "It understands semantics. So, for example, you say the\nstudent takes out the book.",
    "start": "3986360",
    "end": "3993320"
  },
  {
    "text": "You will say book. A language model is able to\nreason about such a sequence. But if you do\nlow-level patterns,",
    "start": "3993320",
    "end": "3999400"
  },
  {
    "text": "like, if you just give\nit obscure numbers, what can you do? It's actually a\nlow-level interface,",
    "start": "3999400",
    "end": "4005430"
  },
  {
    "text": "and we can open up the\nlow-level interface to other language models and\nask it to do robotics tasks.",
    "start": "4005430",
    "end": "4011830"
  },
  {
    "text": "So in this paper, \"Large\nLanguage Models as General Pattern Machines,\" we explore\nusing the low-level interface",
    "start": "4011830",
    "end": "4018060"
  },
  {
    "text": "of a large language model,\nessentially asking it to reason about different sequences.",
    "start": "4018060",
    "end": "4023670"
  },
  {
    "text": "And it's surprisingly\nquite effective. And it can solve tasks like\nthe ARC challenge and the PCFG.",
    "start": "4023670",
    "end": "4031530"
  },
  {
    "text": "And it can even do\nsequence improvement. So I will dig a little bit\ninto sequence improvement, because that's quite\nrelevant to robotics.",
    "start": "4031530",
    "end": "4039140"
  },
  {
    "text": "So sequence improvement is that\nyou prompt the language model with state, action,\nand reward tuples.",
    "start": "4039140",
    "end": "4045130"
  },
  {
    "text": "And you just prompt\nit with higher reward and see if it can\ngenerate actions",
    "start": "4045130",
    "end": "4051069"
  },
  {
    "text": "that achieve the higher reward. So it's doing\nreinforced learning, or a reinforce learning\nlike thing, but in context.",
    "start": "4051070",
    "end": "4058369"
  },
  {
    "text": "So this is quite amazing. So previously, you would need a\ndedicated algorithm collecting",
    "start": "4058370",
    "end": "4064120"
  },
  {
    "text": "data, replay buffer to do\nthis reinforcement learning. But now you can just build\neverything in the language model",
    "start": "4064120",
    "end": "4069130"
  },
  {
    "text": "context by leveraging\nthe low-level interface of a language model. And with that, we can\nactually do something",
    "start": "4069130",
    "end": "4075970"
  },
  {
    "text": "like clicker training. So if we are not very familiar\nwith clicker training, this is how you can do that.",
    "start": "4075970",
    "end": "4082210"
  },
  {
    "text": "You can have a\ndog, and you can-- when it does the right\nthing, you give it a reward by clicking.",
    "start": "4082210",
    "end": "4088335"
  },
  {
    "text": "The other hand. So you can-- so the\nclicker training is giving the agent a reward.",
    "start": "4088335",
    "end": "4096068"
  },
  {
    "text": "And we can now use\nclicker training to train robots as well. So here the robot is exploring.",
    "start": "4096069",
    "end": "4102610"
  },
  {
    "text": "But I would give a click\nwhen it does the right thing or towards the right direction. And over time, it\nwill be able to push",
    "start": "4102611",
    "end": "4109890"
  },
  {
    "text": "the bag of chips, which is the\nobjective of this training. So you can do this entire\ndecision transformer-like",
    "start": "4109890",
    "end": "4116909"
  },
  {
    "text": "operation, but\npurely in context, by just giving a language\nmodel a bunch of patterns and ask it to figure out what is\nthe regularity of this sequence.",
    "start": "4116910",
    "end": "4126970"
  },
  {
    "text": "And this way, it can\ngenerate new actions to improve a previous sequence. ",
    "start": "4126970",
    "end": "4134599"
  },
  {
    "text": "So for the language\nmodel, we can find new interfaces that are\nmore suitable for teaching",
    "start": "4134600",
    "end": "4142278"
  },
  {
    "text": "it low-level skills. Reward is a bridge\nof the language model and the low-level control.",
    "start": "4142279",
    "end": "4147689"
  },
  {
    "text": "And we can fully leverage\nit as a universal interface. And we can optimize\nin real time.",
    "start": "4147689",
    "end": "4155390"
  },
  {
    "text": "Sometimes it outperforms,\ngenerating action directly. So it really motivates to\nuse the reward functions",
    "start": "4155390",
    "end": "4162140"
  },
  {
    "text": "as an interface. And in the language model\nas general pattern machines, we can use language model\nbeyond the semantic tasks.",
    "start": "4162140",
    "end": "4168359"
  },
  {
    "text": "We can ask it to reason\nlow level things. And also, robotics as a domain\nrich of sequence transformation,",
    "start": "4168359",
    "end": "4174770"
  },
  {
    "text": "and sequence completion, and\nsequence improvement tasks. So we can really\nstudy the lower level",
    "start": "4174770",
    "end": "4180109"
  },
  {
    "text": "mechanisms of language models. And the key takeaway is that--",
    "start": "4180109",
    "end": "4185970"
  },
  {
    "text": "for this talk is that we\nare seeing more and more use of foundation models, not\nonly on the semantic reasoning",
    "start": "4185970",
    "end": "4193589"
  },
  {
    "text": "side of robotics, but more on\nthe dexterous, on the generating actions, on the\nlower level embodied",
    "start": "4193590",
    "end": "4200790"
  },
  {
    "text": "intelligence side of robotics. And we need to rethink\nthe scaling law",
    "start": "4200790",
    "end": "4205890"
  },
  {
    "text": "of robotics and transformer. How do we scale it with\nlimited amount of data? We have a new recipe for\nscaling robot model and data",
    "start": "4205890",
    "end": "4212700"
  },
  {
    "text": "in RT-2, which shows that you\ncan do more with the same data. With essentially RT-1\ndata plus internet data,",
    "start": "4212700",
    "end": "4218830"
  },
  {
    "text": "you can generalize\nto a lot more things. And RT-X shows that you can\ndo a lot more with more data.",
    "start": "4218830",
    "end": "4224490"
  },
  {
    "text": "There is also benefits to\ncollecting more robotics data. And there is positive\ntransfers everywhere. And part two, in terms of new\ninterfaces for language models,",
    "start": "4224490",
    "end": "4232590"
  },
  {
    "text": "I think it's worth\nfor the robotics field to think about developing\nnew and lower level",
    "start": "4232590",
    "end": "4238080"
  },
  {
    "text": "interface to language\nmodels, which facilitate learning low level skills. With that, I would like\nto conclude my talk.",
    "start": "4238080",
    "end": "4245570"
  },
  {
    "text": "And if you find it\ninteresting, there are a lot of references\nfor you to look into. And special thanks to my team,\nGoogle DeepMind Robotics Team.",
    "start": "4245570",
    "end": "4255650"
  },
  {
    "text": "So we are at the forefront\nof developing foundation models for robotics. And stay tuned for\nmore in the future.",
    "start": "4255650",
    "end": "4261520"
  },
  {
    "text": "Thank you. ",
    "start": "4261520",
    "end": "4268980"
  },
  {
    "text": "Yes. You mentioned that\n[INAUDIBLE] numbers are difficult for\nlarge language models.",
    "start": "4268980",
    "end": "4274650"
  },
  {
    "text": "But if you're just generating\nthe action tokens themselves, like no [INAUDIBLE],,\nor whatever you had,",
    "start": "4274650",
    "end": "4281010"
  },
  {
    "text": "an example, why don't you\njust have a linear layer appended to the transformer\nthat would just generate numbers",
    "start": "4281010",
    "end": "4288990"
  },
  {
    "text": "from 0 to 25 or whatever it is? Yeah. The question is that if we are--",
    "start": "4288990",
    "end": "4296850"
  },
  {
    "text": "the large language models\nhave difficulty understanding numbers, why don't\nwe use a linear layer to output the action directly?",
    "start": "4296850",
    "end": "4303370"
  },
  {
    "text": "I think-- so language models are\ndifficult to understand numbers, but sometimes we still want\nit to bring in knowledge",
    "start": "4303370",
    "end": "4312150"
  },
  {
    "text": "from the pretraining mixture. If I want-- if I have a new\nlayer, like the new layer is not",
    "start": "4312150",
    "end": "4320369"
  },
  {
    "text": "present in the pretraining, so\nhow do I expect it to transfer? I think that's an\ninteresting question.",
    "start": "4320370",
    "end": "4326130"
  },
  {
    "text": "But at the same time,\nI don't necessarily think using the raw numbers\nis the right interface.",
    "start": "4326130",
    "end": "4332320"
  },
  {
    "text": "We probably could do some\naction representation learning to learn our representation. And the language model can\noutput that representation.",
    "start": "4332320",
    "end": "4339710"
  },
  {
    "text": "So we're still trying\nto figure out what is the right representation. So among the\nrepresentations that we",
    "start": "4339710",
    "end": "4346240"
  },
  {
    "text": "have tried before,\nlike decimal numbers, float the numbers,\nextra tokens, we",
    "start": "4346240",
    "end": "4351460"
  },
  {
    "text": "find that just using\nnumbers or actual tokens would be good enough. Yes.",
    "start": "4351460",
    "end": "4357940"
  },
  {
    "text": "Yes. [INAUDIBLE] three different\n[INAUDIBLE] more promising.",
    "start": "4357940",
    "end": "4378040"
  },
  {
    "text": "Yeah, I think both directions\nare worth exploring. There are different\nadvantages of generating--",
    "start": "4378040",
    "end": "4385585"
  },
  {
    "text": "generating action\ndirectly, I think it borrows the autoregressive\nnature of language modeling.",
    "start": "4385585",
    "end": "4392380"
  },
  {
    "text": "And it aligns with a\nlot of other tasks, like visual question\nanswering really well.",
    "start": "4392380",
    "end": "4398320"
  },
  {
    "text": "The limitation is that then\nwhen you're generating actions, it's heavily regularized.",
    "start": "4398320",
    "end": "4403820"
  },
  {
    "text": "Can you generate\ndexterous actions that is so out-of-distribution? That is kind of difficult. The\nlanguage to reward actually",
    "start": "4403820",
    "end": "4411280"
  },
  {
    "text": "brings a page of the book\nof traditional robotics, this optimization based or\nmodel predictor control.",
    "start": "4411280",
    "end": "4418490"
  },
  {
    "text": "And you can also take into,\nlet's say, safety constraints",
    "start": "4418490",
    "end": "4425200"
  },
  {
    "text": "more easily. It can generate more\ndiverse actions. Maybe one recipe is to\ngenerate a lot of data",
    "start": "4425200",
    "end": "4431770"
  },
  {
    "text": "with the language to reward\nsystem and distill them into a transformer,\nbecause then you",
    "start": "4431770",
    "end": "4437560"
  },
  {
    "text": "are imbuing your\nlarge language model with all this other desirable-- the language to reward itself,\nI don't know how scalable it is.",
    "start": "4437560",
    "end": "4446770"
  },
  {
    "text": "We're not fine tuning\nthe language model, so maybe you are\nlimited to what--",
    "start": "4446770",
    "end": "4452095"
  },
  {
    "text": "you are at the mercy of the\ntraining data of the language model. The language model\ncan do more work,",
    "start": "4452095",
    "end": "4457750"
  },
  {
    "text": "because it knows\nwhat moonwalk is. It roughly knows how to do that.",
    "start": "4457750",
    "end": "4463880"
  },
  {
    "text": "But if you want to scale\nto completely new things, maybe you can use the\nlanguage to reward to bootstrap your\ndata generation,",
    "start": "4463880",
    "end": "4470800"
  },
  {
    "text": "and then put it into\nthe other policy. ",
    "start": "4470800",
    "end": "4478054"
  },
  {
    "text": "What's the next direction\nGoogle is pursuing? So it's like, is the language\nas rewards the right direction or is it more like scaling\nout into [INAUDIBLE]??",
    "start": "4478055",
    "end": "4485080"
  },
  {
    "text": "Yeah, I think that's\na good question. So the scaling being the end of\nthe lecture, that has a joke.",
    "start": "4485080",
    "end": "4491800"
  },
  {
    "text": "But I'm being quite serious. It's actually a\npromising recipe.",
    "start": "4491800",
    "end": "4496820"
  },
  {
    "text": "So we have been-- everybody is believing in the\npower of the scaling rule.",
    "start": "4496820",
    "end": "4504710"
  },
  {
    "text": "So just by giving it more\ndata, giving it more compute, you will see interesting kind\nof capabilities coming out.",
    "start": "4504710",
    "end": "4512619"
  },
  {
    "text": "[INAUDIBLE] GPT2 to\nGPT was a big jump. So do you think we are\nready for robotics to have",
    "start": "4512620",
    "end": "4518800"
  },
  {
    "text": "that jump, where we can-- where do you see\nthe gaps currently?",
    "start": "4518800",
    "end": "4524680"
  },
  {
    "text": "I still think we are not quite-- we don't quite have enough data.",
    "start": "4524680",
    "end": "4530480"
  },
  {
    "text": "I think that's still probably\nthe biggest bottleneck. So we are trying to find ways\nto do more with limited data.",
    "start": "4530480",
    "end": "4538210"
  },
  {
    "text": "And we are trying to\ncollect more data. And I think it needs\nsome time for us",
    "start": "4538210",
    "end": "4543370"
  },
  {
    "text": "to accumulate enough data. And currently, I\nsay we have signs of life for positive transfer.",
    "start": "4543370",
    "end": "4550160"
  },
  {
    "text": "But in language\nmodels, people don't talk about positive\ntransfers anymore, because it's so commonplace.",
    "start": "4550160",
    "end": "4556430"
  },
  {
    "text": "You see it everywhere. And robotics is not\nat that stage yet.",
    "start": "4556430",
    "end": "4563270"
  },
  {
    "text": "How much is your team thinking\nabout safety and alignment? Are you just, right now, relying\non the ethics that emerge",
    "start": "4563270",
    "end": "4572450"
  },
  {
    "text": "from the large language models? It won't tell you to kill\nsomebody to achieve an effect. Yeah, that's a\nvery good question.",
    "start": "4572450",
    "end": "4578610"
  },
  {
    "text": "Actually, we take safety\nvery, very seriously, because all of the other domains\nof developing language models,",
    "start": "4578610",
    "end": "4586640"
  },
  {
    "text": "it doesn't have direct\nimpact on the physical world. But here, it could have\npotential harm to humans",
    "start": "4586640",
    "end": "4596600"
  },
  {
    "text": "and to the environment. And Gary Marcus actually gave a\ncomment previously to our work.",
    "start": "4596600",
    "end": "4602840"
  },
  {
    "text": "What if you say, bring\nout a bowl, feed the cat, and put it in the dishwasher. Would it put the cat\nin the dishwasher?",
    "start": "4602840",
    "end": "4609600"
  },
  {
    "text": "If it misunderstands,\nactually, it will have a catastrophic\nfailure case.",
    "start": "4609600",
    "end": "4616910"
  },
  {
    "text": "We take safety carefully by\ndesigning hardware and software",
    "start": "4616910",
    "end": "4622190"
  },
  {
    "text": "safety layers. And there are also some\nconstitutional safety thing that",
    "start": "4622190",
    "end": "4629910"
  },
  {
    "text": "is coming out sometime soon. I cannot tell much\ndetails right now, but sometime soon we'll\nrelease some work.",
    "start": "4629910",
    "end": "4637329"
  },
  {
    "text": "Is it something like,\n\"If there's a human, just don't interact\"? Well, no, no, no, I think it's a\nlittle bit more nuanced and more",
    "start": "4637330",
    "end": "4645690"
  },
  {
    "text": "detailed than that. But we do take safety\nquite seriously. And in some of our\nexperiments, actually,",
    "start": "4645690",
    "end": "4652170"
  },
  {
    "text": "the robot finger\nwould break off, because it cannot apply enough\nforce to an environment. So this is yet another\nway of ensuring safety.",
    "start": "4652170",
    "end": "4661030"
  },
  {
    "text": "Can we have some\nvisual language model as a supervisor or\nsomething to [INAUDIBLE]?? ",
    "start": "4661030",
    "end": "4668800"
  },
  {
    "text": "And maybe this is kind\nof like [INAUDIBLE],, but both in some [INAUDIBLE].",
    "start": "4668800",
    "end": "4674949"
  },
  {
    "text": "Right, right. Yeah, I think it\nwould be possible. [INAUDIBLE] larger experience,\ndepending on [INAUDIBLE]..",
    "start": "4674950",
    "end": "4681912"
  },
  {
    "text": " Thank you for the great talk. Cool, cool.",
    "start": "4681912",
    "end": "4687990"
  },
  {
    "start": "4687990",
    "end": "4693000"
  }
]
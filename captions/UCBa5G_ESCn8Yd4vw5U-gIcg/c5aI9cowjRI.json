[
  {
    "start": "0",
    "end": "1900"
  },
  {
    "text": "So that's forward\nstepwise selection.",
    "start": "1900",
    "end": "4150"
  },
  {
    "text": "And now we're briefly going to\ntalk about backward stepwise.",
    "start": "4150",
    "end": "6940"
  },
  {
    "text": "And backward stepwise\nis once again",
    "start": "6940",
    "end": "8987"
  },
  {
    "text": "just like forward, it's an\nefficient alternative to best",
    "start": "8987",
    "end": "11320"
  },
  {
    "text": "subset selection,\nbut it actually",
    "start": "11320",
    "end": "13510"
  },
  {
    "text": "is exactly the opposite\nof forward stepwise.",
    "start": "13510",
    "end": "16030"
  },
  {
    "text": "So remember in forward\nstepwise, we built the model M0",
    "start": "16030",
    "end": "19120"
  },
  {
    "text": "and then we added a\nfeature to get M1,",
    "start": "19120",
    "end": "20980"
  },
  {
    "text": "added a feature to get M2.",
    "start": "20980",
    "end": "22869"
  },
  {
    "text": "And in contrast for\nbackward stepwise,",
    "start": "22870",
    "end": "25090"
  },
  {
    "text": "we're going to start with Mp,\nwhich is the model containing",
    "start": "25090",
    "end": "28540"
  },
  {
    "text": "p predictors and we're going\nto remove predictors one",
    "start": "28540",
    "end": "31510"
  },
  {
    "text": "at a time, one at\na time until we",
    "start": "31510",
    "end": "33400"
  },
  {
    "text": "get to M0, which is the\nmodel with just an intercept.",
    "start": "33400",
    "end": "39490"
  },
  {
    "text": "So in a little more\ndetail, we start",
    "start": "39490",
    "end": "41710"
  },
  {
    "text": "with Mp, which is just the\nregular least squares model.",
    "start": "41710",
    "end": "45015"
  },
  {
    "text": "If you just didn't do any\nfeature selection and you",
    "start": "45015",
    "end": "47140"
  },
  {
    "text": "just wanted to use all\nof your predictors.",
    "start": "47140",
    "end": "49780"
  },
  {
    "text": "And then we're going\nto take that model Mp",
    "start": "49780",
    "end": "51640"
  },
  {
    "text": "and we're going to consider\nremoving predictors one",
    "start": "51640",
    "end": "54100"
  },
  {
    "text": "at a time, excuse\nme, we're going",
    "start": "54100",
    "end": "55960"
  },
  {
    "text": "to consider removing\neach of the p predictors",
    "start": "55960",
    "end": "58149"
  },
  {
    "text": "and we're going to\nsee which predictor",
    "start": "58150",
    "end": "59860"
  },
  {
    "text": "is the least useful to\nus, which predictor can we",
    "start": "59860",
    "end": "62230"
  },
  {
    "text": "remove that's going to have the\nsmallest effect on either RSS",
    "start": "62230",
    "end": "66370"
  },
  {
    "text": "or R squared.",
    "start": "66370",
    "end": "67980"
  },
  {
    "text": "So we're going to remove\nthe least useful predictor",
    "start": "67980",
    "end": "70170"
  },
  {
    "text": "and that will give us\nthe model Mp minus 1,",
    "start": "70170",
    "end": "72600"
  },
  {
    "text": "and then we're going\nto take Mp minus 1",
    "start": "72600",
    "end": "74670"
  },
  {
    "text": "and we're going to again\nask which predictor",
    "start": "74670",
    "end": "76650"
  },
  {
    "text": "is the least useful, which\none can we remove in order",
    "start": "76650",
    "end": "79530"
  },
  {
    "text": "to have the least detrimental\neffect on our model fit.",
    "start": "79530",
    "end": "83632"
  },
  {
    "text": "And we're going\nto keep doing this",
    "start": "83633",
    "end": "85050"
  },
  {
    "text": "until we make it down to the\nmodel with just one predictor M1",
    "start": "85050",
    "end": "88410"
  },
  {
    "text": "and finally to the model with\nno predictors, which is M0.",
    "start": "88410",
    "end": "92310"
  },
  {
    "text": "So that's once again going to\ngive us a set of models from M0",
    "start": "92310",
    "end": "96149"
  },
  {
    "text": "to Mp and we're going to choose\namong them using once again",
    "start": "96150",
    "end": "100290"
  },
  {
    "text": "cross-validation AIC, BIC,\nor adjusted R squared.",
    "start": "100290",
    "end": "105000"
  },
  {
    "text": "So just as was the case for\nforward stepwise selection,",
    "start": "105000",
    "end": "108000"
  },
  {
    "text": "backward stepwise\nconsiders around p squared",
    "start": "108000",
    "end": "110490"
  },
  {
    "text": "models instead of 2 to the p.",
    "start": "110490",
    "end": "112689"
  },
  {
    "text": "So it's a fantastic\ncomputational alternative",
    "start": "112690",
    "end": "117132"
  },
  {
    "text": "to best subset selection,\nespecially when p",
    "start": "117132",
    "end": "120960"
  },
  {
    "text": "is moderate or large.",
    "start": "120960",
    "end": "124010"
  },
  {
    "text": "And actually the exact number of\nmodels that backward selection",
    "start": "124010",
    "end": "126890"
  },
  {
    "text": "considers, I've been saying\nit's around p squared, it's",
    "start": "126890",
    "end": "129289"
  },
  {
    "text": "actually more like\np squared over 2.",
    "start": "129289",
    "end": "131050"
  },
  {
    "text": "That's the exact formula,\nand that's a good thing",
    "start": "131050",
    "end": "133220"
  },
  {
    "text": "to work out at home.",
    "start": "133220",
    "end": "134100"
  },
  {
    "text": "So think about it.",
    "start": "134100",
    "end": "135360"
  },
  {
    "text": "Why is it that if you do forward\nstepwise selection or backward",
    "start": "135360",
    "end": "138320"
  },
  {
    "text": "stepwise selection, you're\nactually considering",
    "start": "138320",
    "end": "140870"
  },
  {
    "text": "this number of models?",
    "start": "140870",
    "end": "144140"
  },
  {
    "text": "So just like forward\nstepwise selection,",
    "start": "144140",
    "end": "146360"
  },
  {
    "text": "backward stepwise\nis not guaranteed",
    "start": "146360",
    "end": "148100"
  },
  {
    "text": "to give us the best model\ncontaining a particular subset",
    "start": "148100",
    "end": "151190"
  },
  {
    "text": "of the p predictors.",
    "start": "151190",
    "end": "152460"
  },
  {
    "text": "So it was that same picture\nthat Rob drew a few minutes ago",
    "start": "152460",
    "end": "155750"
  },
  {
    "text": "where we saw that forward\nstepwise for any given model",
    "start": "155750",
    "end": "159260"
  },
  {
    "text": "size might give a larger RSS or\nequivalently a smaller R squared",
    "start": "159260",
    "end": "164450"
  },
  {
    "text": "than best subset.",
    "start": "164450",
    "end": "166040"
  },
  {
    "text": "So similarly backward\nstepwise might not",
    "start": "166040",
    "end": "168349"
  },
  {
    "text": "give quite as good of a model\nin terms of RSS or R squared,",
    "start": "168350",
    "end": "171650"
  },
  {
    "text": "but that can still be\nOK and in the long run",
    "start": "171650",
    "end": "174319"
  },
  {
    "text": "it could give us better\nresults on a test set.",
    "start": "174320",
    "end": "176310"
  },
  {
    "text": "Not to mention it's more\ncomputationally efficient.",
    "start": "176310",
    "end": "180590"
  },
  {
    "text": "So one major difference as\nwe mentioned between backward",
    "start": "180590",
    "end": "183170"
  },
  {
    "text": "and forward stepwise is\nthat with backward stepwise,",
    "start": "183170",
    "end": "185623"
  },
  {
    "text": "we start with the\nmodel containing",
    "start": "185623",
    "end": "187040"
  },
  {
    "text": "all of the predictors.",
    "start": "187040",
    "end": "188510"
  },
  {
    "text": "So in order to be\nable to do that,",
    "start": "188510",
    "end": "190549"
  },
  {
    "text": "we need to be in a situation\nwhere we have more observations",
    "start": "190550",
    "end": "193400"
  },
  {
    "text": "than variables,\nbecause remember,",
    "start": "193400",
    "end": "195943"
  },
  {
    "text": "we can do least squares\nregression when n is greater",
    "start": "195943",
    "end": "198110"
  },
  {
    "text": "than p, but if p\nis greater than n,",
    "start": "198110",
    "end": "200390"
  },
  {
    "text": "we cannot fit a least squares\nmodel, it's not even defined.",
    "start": "200390",
    "end": "203510"
  },
  {
    "text": "So we can only do\nbackward selection",
    "start": "203510",
    "end": "205849"
  },
  {
    "text": "when n is greater than p.",
    "start": "205850",
    "end": "208940"
  },
  {
    "text": "And in contrast, we\ncan do forward stepwise",
    "start": "208940",
    "end": "212070"
  },
  {
    "text": "whether n is less than p\nor n is greater than p.",
    "start": "212070",
    "end": "215350"
  },
  {
    "start": "215350",
    "end": "218650"
  },
  {
    "text": "Oops.",
    "start": "218650",
    "end": "219150"
  },
  {
    "start": "219150",
    "end": "222500"
  },
  {
    "text": "So we mentioned that the model\ncontaining all of the predictors",
    "start": "222500",
    "end": "229340"
  },
  {
    "text": "is always going to have\na smaller R squared,",
    "start": "229340",
    "end": "232382"
  },
  {
    "text": "excuse me, the model containing\nall of the predictors",
    "start": "232382",
    "end": "234590"
  },
  {
    "text": "is always going to\nhave a smaller RSS",
    "start": "234590",
    "end": "236780"
  },
  {
    "text": "and a larger R squared\nthan any other model",
    "start": "236780",
    "end": "239450"
  },
  {
    "text": "because these quantities\nare really related",
    "start": "239450",
    "end": "241550"
  },
  {
    "text": "to the training error.",
    "start": "241550",
    "end": "242990"
  },
  {
    "text": "So again, this is the\npicture that Rob drew.",
    "start": "242990",
    "end": "246740"
  },
  {
    "text": "But if I think about fitting\na model with a number",
    "start": "246740",
    "end": "250070"
  },
  {
    "text": "of predictors on the\ny-axis and RSS on the--",
    "start": "250070",
    "end": "254260"
  },
  {
    "text": "If I think about fitting a model\nwith a number of predictors",
    "start": "254260",
    "end": "256760"
  },
  {
    "text": "on the x-axis and\nRSS on the y axis,",
    "start": "256760",
    "end": "259250"
  },
  {
    "text": "this is going to be\nmonotone decreasing.",
    "start": "259250",
    "end": "261920"
  },
  {
    "text": "And similarly, if I\nthink about a picture",
    "start": "261920",
    "end": "266120"
  },
  {
    "text": "with a number of predictors\non the x-axis and R squared",
    "start": "266120",
    "end": "269750"
  },
  {
    "text": "on the y-axis, it's going\nto be monotone increasing.",
    "start": "269750",
    "end": "272430"
  },
  {
    "start": "272430",
    "end": "275150"
  },
  {
    "text": "So remember when we do\nbest subset or forward",
    "start": "275150",
    "end": "277490"
  },
  {
    "text": "or backward stepwise, we end up\nwith these models M0 through Mp.",
    "start": "277490",
    "end": "281060"
  },
  {
    "text": "And I cannot just choose among\nthem using R squared or using",
    "start": "281060",
    "end": "284060"
  },
  {
    "text": "RSS because I'll always\nchoose the biggest model.",
    "start": "284060",
    "end": "287008"
  },
  {
    "text": "And again, that just\nboils down to the fact",
    "start": "287008",
    "end": "288800"
  },
  {
    "text": "that these quantities are just\nbased on the training error.",
    "start": "288800",
    "end": "292699"
  },
  {
    "text": "But I want a model\nwith low test error",
    "start": "292700",
    "end": "294500"
  },
  {
    "text": "because I want it to do\nwell on future observations",
    "start": "294500",
    "end": "296930"
  },
  {
    "text": "that I haven't seen like\npatients who haven't walked",
    "start": "296930",
    "end": "301492"
  },
  {
    "text": "into the clinic yet for\nwhom I'm going to want",
    "start": "301493",
    "end": "303410"
  },
  {
    "text": "to predict some response.",
    "start": "303410",
    "end": "305980"
  },
  {
    "text": "And unfortunately, just choosing\na model with the best training",
    "start": "305980",
    "end": "309160"
  },
  {
    "text": "error isn't going to give me\na model that has a low test",
    "start": "309160",
    "end": "311530"
  },
  {
    "text": "error because in\ngeneral, training error",
    "start": "311530",
    "end": "313480"
  },
  {
    "text": "is a really bad predictor\nof test error, a really bad",
    "start": "313480",
    "end": "315880"
  },
  {
    "text": "estimate of test error.",
    "start": "315880",
    "end": "317710"
  },
  {
    "text": "And so RSS and R\nsquared just are not",
    "start": "317710",
    "end": "319900"
  },
  {
    "text": "suitable for the\ntask of choosing",
    "start": "319900",
    "end": "321669"
  },
  {
    "text": "among models with different\nnumbers of predictors.",
    "start": "321670",
    "end": "325500"
  },
  {
    "start": "325500",
    "end": "326000"
  }
]
[
  {
    "start": "0",
    "end": "5450"
  },
  {
    "text": "Hi, everyone. My name is Yoonho Lee. I'm a TA for this course. And it's my first\ntime giving a lecture.",
    "start": "5450",
    "end": "13170"
  },
  {
    "text": "So hopefully\neverything goes well. ",
    "start": "13170",
    "end": "20950"
  },
  {
    "text": "Yeah, we're going to be talking\nabout the second edition of advanced meta\nlearning topics.",
    "start": "20950",
    "end": "27010"
  },
  {
    "text": "I think on Monday,\nChelsea talked about memoization and task\nconstruction in meta learning.",
    "start": "27010",
    "end": "34829"
  },
  {
    "text": "And today, we're going to\ntalk about large scale meta optimization.",
    "start": "34830",
    "end": "41750"
  },
  {
    "text": "As a quick reminder,\nhomework three, the one on language\nmodels is out this Monday",
    "start": "41750",
    "end": "46940"
  },
  {
    "text": "and it's due in a week.  So we're going to start\nwith kind of a big picture",
    "start": "46940",
    "end": "55690"
  },
  {
    "text": "question about meta learning\nand why we should even do it.",
    "start": "55690",
    "end": "62539"
  },
  {
    "text": "So we can think about\nlearning methods as being on the spectrum\nbetween hand designed",
    "start": "62540",
    "end": "70900"
  },
  {
    "text": "priors and data-driven priors. And there's kind of a\ncontinual shift downwards",
    "start": "70900",
    "end": "77170"
  },
  {
    "text": "towards more data-driven stuff. So for example, a\nlong time ago, people used to do directly\nmodeling image formation.",
    "start": "77170",
    "end": "86270"
  },
  {
    "text": "And as a slightly\nmore data-driven way, they constructed\nhand coded features.",
    "start": "86270",
    "end": "95110"
  },
  {
    "text": "And extracted those out\nof actual data points. ",
    "start": "95110",
    "end": "101100"
  },
  {
    "text": "And then people\nstarted doing end to end learning of the\nfeatures themselves.",
    "start": "101100",
    "end": "106259"
  },
  {
    "text": "And by, for example, fine\ntuning from pre-trained ImageNet features, we--",
    "start": "106260",
    "end": "111885"
  },
  {
    "text": " the pre-trained networks\ncontain a very good",
    "start": "111885",
    "end": "118320"
  },
  {
    "text": "prior about what natural\nlanguages are like. And it's more of a\ndata-driven fire.",
    "start": "118320",
    "end": "124450"
  },
  {
    "text": "And the reason we\nkeep going downwards is that more data-driven\napproaches are more scalable.",
    "start": "124450",
    "end": "132310"
  },
  {
    "text": "So in a sense, if you keep\nthrowing more real data at them, they get better and\nbetter at encoding real priors",
    "start": "132310",
    "end": "139020"
  },
  {
    "text": "and being effective\nin downstream tasks. So really, one of\nthe pitches for why",
    "start": "139020",
    "end": "147300"
  },
  {
    "text": "we should be doing\nmeta learning is that it's even more\ndata-driven than end to end tuning of a network.",
    "start": "147300",
    "end": "155890"
  },
  {
    "text": "And because the\nthing is we directly learn the learning\nalgorithm themselves.",
    "start": "155890",
    "end": "162900"
  },
  {
    "text": "And a question that\nwe should stop and ask is we go downwards because\nwe want to scale better,",
    "start": "162900",
    "end": "171720"
  },
  {
    "text": "we want to have something that\nmay start out not so good. But as it sees more data,\nit gets better and better.",
    "start": "171720",
    "end": "179760"
  },
  {
    "text": "And we should ask, do meta\nlearning methods actually work at scale? So for the meta\nlearning algorithms",
    "start": "179760",
    "end": "186930"
  },
  {
    "text": "that you've seen in\nthe class like MAML, or pro typical networks, can\nyou actually give them more data",
    "start": "186930",
    "end": "195990"
  },
  {
    "text": "and have them work better? And really, the\nanswer is kind of no.",
    "start": "195990",
    "end": "201300"
  },
  {
    "text": "So if you like become-- if you were lured\ninto this course",
    "start": "201300",
    "end": "207120"
  },
  {
    "text": "from the promise of like\nbeing very data-driven",
    "start": "207120",
    "end": "212129"
  },
  {
    "text": "and being able to learn from\nall the data that you have, then it doesn't really scale.",
    "start": "212130",
    "end": "219060"
  },
  {
    "text": "So in today's\nlecture, we're going to talk about why\nthat's the case",
    "start": "219060",
    "end": "224159"
  },
  {
    "text": "and what we can do about\nit while still staying in a metallurgy setting.",
    "start": "224160",
    "end": "231550"
  },
  {
    "text": "So the plan for\ntoday is we're first going to motivate large scale\nmeta optimization, what it is",
    "start": "231550",
    "end": "236939"
  },
  {
    "text": "and why we should do it. We're going to look at\nsome applications of this. And then we're going to look\nat two approaches in particular",
    "start": "236940",
    "end": "244950"
  },
  {
    "text": "that can handle\nlarge scale settings. And by the end of the lecture--",
    "start": "244950",
    "end": "252400"
  },
  {
    "text": "we won't have time to\ngo into deep detail into most of this stuff. But at least the\ngoal is to scenarios",
    "start": "252400",
    "end": "260790"
  },
  {
    "text": "where large scale stuff\nmakes existing meta learning approaches fail.",
    "start": "260790",
    "end": "266039"
  },
  {
    "text": "And broadly understand\nsome techniques for handling those\ntypes of scenarios.",
    "start": "266040",
    "end": "274650"
  },
  {
    "text": "Yeah, so I think we\ncan roughly summarize a lot of the meta learning\napproaches as doing",
    "start": "274650",
    "end": "281970"
  },
  {
    "text": "direct back propagation. So this is the black box\nmodel that you learned in homework one, I believe.",
    "start": "281970",
    "end": "288720"
  },
  {
    "text": "And it's just the\nnetwork that can take all of your support\ndata and your query data",
    "start": "288720",
    "end": "296940"
  },
  {
    "text": "and outputs predictions. And in the same way, MAML also--",
    "start": "296940",
    "end": "302970"
  },
  {
    "text": "MAML and all the\noptimization-based approaches here to you just--",
    "start": "302970",
    "end": "309629"
  },
  {
    "text": "it's one big computation\ngraph that takes in your source and query data. And then in the end\nyou back propagate.",
    "start": "309630",
    "end": "315930"
  },
  {
    "text": "And PyTorch kind\nof automatically does the modeling for you. And the same story is with\nnon-parametric methods.",
    "start": "315930",
    "end": "324570"
  },
  {
    "text": "So the commonality here is that\nall these methods are first constructing, task\nlearning, computation graph",
    "start": "324570",
    "end": "332610"
  },
  {
    "text": "and then back propagating\nthrough the whole thing. And this is kind\nof a general recipe",
    "start": "332610",
    "end": "338190"
  },
  {
    "text": "that you can apply to any\nlearning computation graph that you come up with. And it's simple in the\nsense that auto grad",
    "start": "338190",
    "end": "346860"
  },
  {
    "text": "does all the work for you. So it's good that it's\ndone automatically.",
    "start": "346860",
    "end": "353050"
  },
  {
    "text": "But the core issue with this\nis that your memory cost scales with the size of your\ncomputation graph.",
    "start": "353050",
    "end": "360040"
  },
  {
    "text": "And there are learning\nsettings where you would like to have\na bigger computation graph, which is what we're\ngoing to talk about today.",
    "start": "360040",
    "end": "366615"
  },
  {
    "text": " So to give you a rough sense of\nhow big computation graphs are",
    "start": "366615",
    "end": "373970"
  },
  {
    "text": "in general, this is from\na meta learning paper. The details don't really matter.",
    "start": "373970",
    "end": "381380"
  },
  {
    "text": "The standardly use\nfour-layer CNN has about 10",
    "start": "381380",
    "end": "386750"
  },
  {
    "text": "to the 5 parameters. Some works use bigger\nnetworks, like wide resonates.",
    "start": "386750",
    "end": "392360"
  },
  {
    "text": "Those have a bit\nmore and resonant 12 has about 10 million parameters,\nwhich might seem like a lot,",
    "start": "392360",
    "end": "402120"
  },
  {
    "text": "but the computation graph\nonly involves at most one feed forward, one back\nprop and then another",
    "start": "402120",
    "end": "409039"
  },
  {
    "text": "feed forward which you don't\nhave to multiply this by a lot to get the whole\ncomputation graph.",
    "start": "409040",
    "end": "416150"
  },
  {
    "text": "And this is a very toy example\nfrom the official PyTorch",
    "start": "416150",
    "end": "422600"
  },
  {
    "text": "tutorial. This is for a\nlearning I think C4. And the network size is a\nbit less than 10 to the 7.",
    "start": "422600",
    "end": "432650"
  },
  {
    "text": "And we trained this for\nfive epochs, five epochs with C4 is about 4,000 steps.",
    "start": "432650",
    "end": "438660"
  },
  {
    "text": "So if you try to calculate the\nsize of that entire computation graph, it's very big.",
    "start": "438660",
    "end": "445650"
  },
  {
    "text": "I think it's about\n100 gigabytes. I may be wrong, but yeah\nit's definitely bigger than whatever GPU you have.",
    "start": "445650",
    "end": "452330"
  },
  {
    "text": "So in these sorts\nof scenarios, if we want to consider learning\nalgorithms at this scale,",
    "start": "452330",
    "end": "458810"
  },
  {
    "text": "what can we do because\nwe can't directly apply direct back propagation?",
    "start": "458810",
    "end": "464780"
  },
  {
    "text": " So again, the three\nbig meta learning",
    "start": "464780",
    "end": "473050"
  },
  {
    "text": "approaches that we've\ncovered in the course so far, they can all be\nsummarized with this big--",
    "start": "473050",
    "end": "481689"
  },
  {
    "text": "not so big F learn, which is\nthe inner loop computation graph with some sort of\nmeta parameters theta.",
    "start": "481690",
    "end": "490520"
  },
  {
    "text": "And we construct this\nand back propagate through the whole thing.",
    "start": "490520",
    "end": "495780"
  },
  {
    "text": "So a question for\nyou is when might this F learn be kind\nof too big to apply",
    "start": "495780",
    "end": "502860"
  },
  {
    "text": "direct back propagation? ",
    "start": "502860",
    "end": "523073"
  },
  {
    "text": "How would you like us\nto answer this question? [LAUGHING]",
    "start": "523074",
    "end": "530280"
  },
  {
    "text": "In terms of number clusters,\nand so strings, [INAUDIBLE]",
    "start": "530280",
    "end": "536550"
  },
  {
    "text": "Just in any sense. What is kind of an inner\nloop learning algorithm",
    "start": "536550",
    "end": "542910"
  },
  {
    "text": "that you would like to use\nbut we can't directly back propagate their little thing? It's pretty common.",
    "start": "542910",
    "end": "549800"
  },
  {
    "text": "It doesn't fit on my GPU. Excuse me. The model doesn't fit in my GPU. Yeah, that's definitely-- yeah.",
    "start": "549800",
    "end": "555930"
  },
  {
    "text": "If you have a model that's\nbigger than your CPU, it's-- yeah. Yeah, this occurs\nmaybe too commonly",
    "start": "555930",
    "end": "563310"
  },
  {
    "text": "for you to give any\nanswer that really works.",
    "start": "563310",
    "end": "568980"
  },
  {
    "text": "So yeah, F learn is too large\nwhen we have a big network",
    "start": "568980",
    "end": "576060"
  },
  {
    "text": "and/or in many gradient steps. So even if your model is small,\nif you take too many gradient steps the whole\ncomputation graph",
    "start": "576060",
    "end": "582270"
  },
  {
    "text": "is the size times the\nnumber of gradient steps. So it's too big. Another possibility is that\nif your inner optimization",
    "start": "582270",
    "end": "590040"
  },
  {
    "text": "includes second\norder optimization, so if you have to back\npropagate through second order",
    "start": "590040",
    "end": "595500"
  },
  {
    "text": "optimization, then that\nis another scenario where it can be too big. So for example, if\nyour inner optimization",
    "start": "595500",
    "end": "604080"
  },
  {
    "text": "is meta learning\nitself and you want to meta meta learn how to meta\nlearn better, which I don't",
    "start": "604080",
    "end": "613350"
  },
  {
    "text": "recommend you work on this,\nbut if you wanted to do that, this would be too big.",
    "start": "613350",
    "end": "618450"
  },
  {
    "text": "And you couldn't use\ndirect back propagation. And when we consider\nbigger F learn",
    "start": "618450",
    "end": "627020"
  },
  {
    "text": "than we get to consider a\nlot more interesting meta parameters theta.",
    "start": "627020",
    "end": "632500"
  },
  {
    "text": "So I'm going to show you a bunch\nof examples of meta parameters.",
    "start": "632500",
    "end": "638462"
  },
  {
    "text": "So first of all, we\nhave things like MAML where to summarize again, we\nlearn the initial parameters.",
    "start": "638462",
    "end": "647410"
  },
  {
    "text": "So this whole thing is\nthe outer loop objective. And in the inner loop, we do\na gradient step with respect",
    "start": "647410",
    "end": "655850"
  },
  {
    "text": "to the loss, the training loss. And as you've seen\nin homework two,",
    "start": "655850",
    "end": "661340"
  },
  {
    "text": "you can also learn the\nlearning rates, which was a component of the\ncomputation graph before,",
    "start": "661340",
    "end": "669540"
  },
  {
    "text": "but we can include it\nas the metaphor janitors and directly learn that so\nthat your final performance is",
    "start": "669540",
    "end": "676380"
  },
  {
    "text": "better. Now the point I want to make\nis that really any components",
    "start": "676380",
    "end": "684620"
  },
  {
    "text": "of your computation\ngraph can be a metaphor. So for example, like building\non the learning made example,",
    "start": "684620",
    "end": "693310"
  },
  {
    "text": "you're optimizer can also be\nsomething that you meta learn. And yeah, really\nwhat is an optimizer?",
    "start": "693310",
    "end": "699790"
  },
  {
    "text": "It's something that\ntakes in your gradients, takes in your current parameters\nand gives you something else.",
    "start": "699790",
    "end": "706120"
  },
  {
    "text": "And this doesn't necessarily\nhave to be hand designed. To get even more\nstrange, we can actually",
    "start": "706120",
    "end": "716430"
  },
  {
    "text": "meta learn the loss function. So by loss function\nI'm referring to things like the cross entropy loss.",
    "start": "716430",
    "end": "722340"
  },
  {
    "text": "And the way you would do this\nis what a loss function is it",
    "start": "722340",
    "end": "727980"
  },
  {
    "text": "takes in your predictions\nand your true labels and gives you a scalar.",
    "start": "727980",
    "end": "733230"
  },
  {
    "text": "And that's back\npropagate from that. So for example, a way you\ncan learn a loss function",
    "start": "733230",
    "end": "739980"
  },
  {
    "text": "is have a-- ",
    "start": "739980",
    "end": "747329"
  },
  {
    "text": "have an L, phi, is\nthat what we call it, the network that takes in-- ",
    "start": "747330",
    "end": "767160"
  },
  {
    "text": "It has two inputs. You input your predictions\nand the ground truth labels.",
    "start": "767160",
    "end": "773370"
  },
  {
    "text": "And it predicts something. And then you treat this as you\nwould a regular loss function.",
    "start": "773370",
    "end": "779310"
  },
  {
    "text": "And you back propagate through\nit and do everything else. And that's possible.",
    "start": "779310",
    "end": "787060"
  },
  {
    "text": "You can also directly\nlearn the data set. So the thing that you feed\nfor through your network",
    "start": "787060",
    "end": "793209"
  },
  {
    "text": "doesn't have to be\nyour original data. The way this can\nwork is you can--",
    "start": "793210",
    "end": "799420"
  },
  {
    "text": "so for the case of images-- ",
    "start": "799420",
    "end": "812480"
  },
  {
    "text": "Yeah. You can just have a\nfour dimensional tensor that acts as your data set.",
    "start": "812480",
    "end": "818500"
  },
  {
    "text": "And you can directly apply your\naugmentations or anything else as just treat this\nlike your data.",
    "start": "818500",
    "end": "826120"
  },
  {
    "text": "And you can also optimize\nthis so that learning is better in the downstream.",
    "start": "826120",
    "end": "833600"
  },
  {
    "text": "A there's even ways to-- Can you give an\nexample of when you",
    "start": "833600",
    "end": "839330"
  },
  {
    "text": "would want to learn a loss\nfunction because it seems like you would have to have\na real loss function that you",
    "start": "839330",
    "end": "845780"
  },
  {
    "text": "actually are trying to\nminimize, and you're trying to learn this\nintermediate loss",
    "start": "845780",
    "end": "851930"
  },
  {
    "text": "function to get there, right? Yeah, so we always need a loss\nfunction in the outer loop.",
    "start": "851930",
    "end": "861850"
  },
  {
    "text": "But in order to minimize the-- let's see, what's up with 36--",
    "start": "861850",
    "end": "869400"
  },
  {
    "text": "so every last function that\nwe use anyway is a proxy. So if you think\nabout classification.",
    "start": "869400",
    "end": "875220"
  },
  {
    "text": "What we really want\nusually is accuracy. And that's not a\nloss function that we can use because it's\nnot back propagatable.",
    "start": "875220",
    "end": "883200"
  },
  {
    "text": "And so we use cross entropy\nloss as a proxy for that. But it may not be the\ncase that cross entropy",
    "start": "883200",
    "end": "889620"
  },
  {
    "text": "is the best thing to optimize\nto get high accuracy. So this kind of\nsearches in that space,",
    "start": "889620",
    "end": "897630"
  },
  {
    "text": "And you wouldn't still\nhave to back propagate it from that accuracy in\norder to find the loss that",
    "start": "897630",
    "end": "902880"
  },
  {
    "text": "maximizes the accuracy? So we can't back propagate\nthrough the accuracy",
    "start": "902880",
    "end": "909000"
  },
  {
    "text": "but we would minimize\nthis objective, which",
    "start": "909000",
    "end": "914550"
  },
  {
    "text": "incorporates the accuracy. Does that make sense?",
    "start": "914550",
    "end": "919960"
  },
  {
    "text": "No, but it's OK. [LAUGHING]  Yeah we learn an L so that\nrunning gradient descent",
    "start": "919960",
    "end": "928149"
  },
  {
    "text": "on L results in bigger accuracy. But when you do\nthat, don't you have",
    "start": "928150",
    "end": "933310"
  },
  {
    "text": "to take the gradient\nof the accuracy with respect to this L.",
    "start": "933310",
    "end": "938701"
  },
  {
    "text": "Oh, OK. That's the confusion. So that the point\nI'm getting at is we don't necessarily have to\nback propagate through this",
    "start": "938701",
    "end": "945220"
  },
  {
    "text": "and there are ways of\noptimizing for things that you can't differentiate through.",
    "start": "945220",
    "end": "951310"
  },
  {
    "text": "And that's the stuff I'm\ngoing to talk about later.  The other was [INAUDIBLE]",
    "start": "951310",
    "end": "959980"
  },
  {
    "text": "Oh, yeah, there\nshould be an L here. Yeah, that's a typo. ",
    "start": "959980",
    "end": "965690"
  },
  {
    "text": "So if we're doing\nthe loss function, could we also learn\nhow to regularize?",
    "start": "965690",
    "end": "970780"
  },
  {
    "text": "But if we learn a\nloss function, then we can learn how to\nregularize it so that the outer loop works well,\nbut it doesn't overfit to the--",
    "start": "970780",
    "end": "980800"
  },
  {
    "text": "Yeah, absolutely. Learning a regularizer is a\nvariant of learning a loss",
    "start": "980800",
    "end": "986889"
  },
  {
    "text": "function where your total loss\nfunction is an original loss plus something else. ",
    "start": "986890",
    "end": "995090"
  },
  {
    "text": "Oh, I should be repeating\nquestions, yeah. How would you redefine\nthe search space",
    "start": "995090",
    "end": "1001959"
  },
  {
    "text": "for the loss function. So is it just your-- do the research across different\ntypes of loss functions,",
    "start": "1001960",
    "end": "1009130"
  },
  {
    "text": "or are you trying more of a\nformula for a loss function that could be really novel--",
    "start": "1009130",
    "end": "1015399"
  },
  {
    "text": "How would you define this? Yeah, the question is, how\ndo we define the search space",
    "start": "1015400",
    "end": "1021610"
  },
  {
    "text": "for loss function? And that's really up\nto you in a sense.",
    "start": "1021610",
    "end": "1026740"
  },
  {
    "text": "You can do a search over a\nfinite set of candidates. You can just make\nyour search space",
    "start": "1026740",
    "end": "1033910"
  },
  {
    "text": "the set of networks that\nhave the same input/output structure. ",
    "start": "1033910",
    "end": "1042159"
  },
  {
    "text": "When we're trying to\noptimize for the data set, does that mean that we're\ntrying get better [INAUDIBLE]",
    "start": "1042160",
    "end": "1048329"
  },
  {
    "text": "the dataset [INAUDIBLE]\ncode examples, or is it a completely-- example\nthat's completely determined",
    "start": "1048329",
    "end": "1053952"
  },
  {
    "text": "by-- Could you repeat that? Sorry. Yeah, absolutely. When we're trying to\noptimize for the dataset,",
    "start": "1053952",
    "end": "1059017"
  },
  {
    "text": "what does it actually mean? I don't get how we can\noptimize the dataset.",
    "start": "1059017",
    "end": "1064650"
  },
  {
    "text": "The question is, what does it\nmean to optimize the data set? And yeah, I agree that this\nis kind of a foreign concept.",
    "start": "1064650",
    "end": "1072340"
  },
  {
    "text": "So what you can do-- this is\nthe simplest way to do it, and you can just directly\nparameterize a four dimensional",
    "start": "1072340",
    "end": "1079470"
  },
  {
    "text": "tensor with the interpretation\nthat each dimension in the batch dimension\ncorresponds to an RGB image.",
    "start": "1079470",
    "end": "1088649"
  },
  {
    "text": "And you feed this forward\nthrough your network as if it were an actual\nimage, and you back propagate.",
    "start": "1088650",
    "end": "1095670"
  },
  {
    "text": "I mean, you do gradient steps\nwith respect to the loss, and then you get\nfinal parameters.",
    "start": "1095670",
    "end": "1102240"
  },
  {
    "text": "And we optimize for downstream\nvalidation loss or performance.",
    "start": "1102240",
    "end": "1108790"
  },
  {
    "text": "So it's like we're\ntrying to find an example, which will perform\nthe best for our current order? ",
    "start": "1108790",
    "end": "1117090"
  },
  {
    "text": "We're looking for\nthe examples so that if we try to minimize\nthe loss for those examples,",
    "start": "1117090",
    "end": "1123630"
  },
  {
    "text": "we would get better\nperformance later on. ",
    "start": "1123630",
    "end": "1129896"
  },
  {
    "text": "Is this the less extreme\nexample of [INAUDIBLE]?? Could you do learning\naugmentations instead of",
    "start": "1129896",
    "end": "1135130"
  },
  {
    "text": "just creating the density? Oh yeah, absolutely,\nyou can have the--",
    "start": "1135130",
    "end": "1140200"
  },
  {
    "text": "question is, can you learn\ninstead augmentations? Yeah, you can start\nwith actual images",
    "start": "1140200",
    "end": "1147279"
  },
  {
    "text": "and learn mild\naugmentations to the images so that you get\nbetter performance.",
    "start": "1147280",
    "end": "1152290"
  },
  {
    "text": "I think a couple of\nteams are working on that as a final project. Yeah, I'm going to move on\nin the interest of time.",
    "start": "1152290",
    "end": "1159279"
  },
  {
    "text": "So we're going to move on to-- in this large scale\noptimization setting,",
    "start": "1159280",
    "end": "1165970"
  },
  {
    "text": "what are some applications\nthat people have-- previous papers have looked at?",
    "start": "1165970",
    "end": "1172760"
  },
  {
    "text": "So one application is\nhyper-parameter optimization. People don't usually\ncall this meta learning,",
    "start": "1172760",
    "end": "1178210"
  },
  {
    "text": "but you can view it as\nin the same rough frame.",
    "start": "1178210",
    "end": "1184929"
  },
  {
    "text": "So by optimizing\nhyper-parameters-- ",
    "start": "1184930",
    "end": "1190120"
  },
  {
    "text": "Yeah, first of all, when we're\noptimizing hyper-parameters, the inner loop is basically\na big learning SGD chain.",
    "start": "1190120",
    "end": "1198190"
  },
  {
    "text": "And of course, we can't directly\nback propagate through that. And by optimizing\nhyper parameters,",
    "start": "1198190",
    "end": "1204550"
  },
  {
    "text": "existing works\nhave shown benefits over random search, better\nLSTM hyper-parameters.",
    "start": "1204550",
    "end": "1213370"
  },
  {
    "text": "And in the same\nframework, you can also",
    "start": "1213370",
    "end": "1220780"
  },
  {
    "text": "optimize the hyper-parameters\nof a data augmentation network, which starts to look\na lot more like parameters",
    "start": "1220780",
    "end": "1226930"
  },
  {
    "text": "than hyper-parameters. And things that you can\noptimize in this way are things like\ndropout fraction,",
    "start": "1226930",
    "end": "1234280"
  },
  {
    "text": "learning rates, yeah,\nthings like that here. The weight that you give\nto regularization terms.",
    "start": "1234280",
    "end": "1243210"
  },
  {
    "text": "So hyper-parameter optimization\nis one application, another is data\nset distillation,",
    "start": "1243210",
    "end": "1249570"
  },
  {
    "text": "which is closer to\noptimizing data sets as we've talked about before.",
    "start": "1249570",
    "end": "1256530"
  },
  {
    "text": "And here, the method\nin this specific paper, it matches the gradients of--",
    "start": "1256530",
    "end": "1264630"
  },
  {
    "text": "the gradients with respect\nto your synthetic data, to the gradients with\nrespect to real data.",
    "start": "1264630",
    "end": "1271179"
  },
  {
    "text": "So we're making\nsynthetic data points so that it results in similar\ngradients as the real data set.",
    "start": "1271180",
    "end": "1279340"
  },
  {
    "text": "And in this way,\nyou can actually compress existing data sets like\n10-way classification problems",
    "start": "1279340",
    "end": "1288150"
  },
  {
    "text": "with a lot more images per class\ninto single images per class",
    "start": "1288150",
    "end": "1294720"
  },
  {
    "text": "and get pretty good performance. It's definitely not as good\nas the original data sets,",
    "start": "1294720",
    "end": "1301050"
  },
  {
    "text": "but you can get 99%\naccuracy on MNIST after training on those\n10 images and so on.",
    "start": "1301050",
    "end": "1309940"
  },
  {
    "text": "Yeah, everything\nmakes sense, right? ",
    "start": "1309940",
    "end": "1315404"
  },
  {
    "text": "Yeah, you can also\nlearn optimizers. This kind of builds\non the learning rates",
    "start": "1315404",
    "end": "1321630"
  },
  {
    "text": "and parameterizing the\noptimizer as a neural network. So one very simple way to\nparameterize an optimizer",
    "start": "1321630",
    "end": "1331530"
  },
  {
    "text": "is as a network that takes\nin, for each parameter, the current gradient\nand the momentum,",
    "start": "1331530",
    "end": "1338620"
  },
  {
    "text": "which is a moving average\nof your previous gradients and outputting an update.",
    "start": "1338620",
    "end": "1347025"
  },
  {
    "text": " This paper uses a more\ncomplex architecture,",
    "start": "1347025",
    "end": "1354080"
  },
  {
    "text": "which takes in gradients,\nmomentum, the second moment, and also takes in the current\ntraining and validation loss",
    "start": "1354080",
    "end": "1361309"
  },
  {
    "text": "and tensor shape\nand gradient norm. So by looking at this in\na meta learning setup,",
    "start": "1361310",
    "end": "1369380"
  },
  {
    "text": "your optimizer can be-- it can take in a\nlot more information than traditional optimizers\ndo, which usually,",
    "start": "1369380",
    "end": "1377090"
  },
  {
    "text": "just to use like the current\nfirst and second order moments of the gradients. ",
    "start": "1377090",
    "end": "1384870"
  },
  {
    "text": "And their learned\noptimizer works at the scale of big ResNets\nfor many training steps.",
    "start": "1384870",
    "end": "1390850"
  },
  {
    "text": "So here they're optimizing\na ResNet for 10,000 training",
    "start": "1390850",
    "end": "1395880"
  },
  {
    "text": "steps, which is\nobviously too big to apply direct back\npropagation through.",
    "start": "1395880",
    "end": "1402760"
  },
  {
    "text": "And they even use\nit to train itself.",
    "start": "1402760",
    "end": "1408360"
  },
  {
    "text": "So what this means\nis, on a set of tasks, they train an\noptimizer so that it",
    "start": "1408360",
    "end": "1415160"
  },
  {
    "text": "gets quick at\nlearning these tasks, and then they\ntotally reinitialize and then use that optimizer\nto optimize the outer loop",
    "start": "1415160",
    "end": "1423429"
  },
  {
    "text": "loss, which is pretty meta. ",
    "start": "1423430",
    "end": "1431150"
  },
  {
    "text": "Another thing you can do is\nneural architecture search. Yeah, this. Here we'll see a way to\nparameterize a neural network.",
    "start": "1431150",
    "end": "1439350"
  },
  {
    "text": "This is one way to do it,\nother works use other ways. Here what they do is\nthey have an RNN that",
    "start": "1439350",
    "end": "1445010"
  },
  {
    "text": "outputs the parameters\nof your neural network. I mean, yeah, the\nparameters of its size.",
    "start": "1445010",
    "end": "1454770"
  },
  {
    "text": "So it outputs things like number\nof filters, filter height, width, stride for a CNN.",
    "start": "1454770",
    "end": "1462080"
  },
  {
    "text": "And when they apply\nthis to an RNN, it produces this very big thing\nwhich no person would come up",
    "start": "1462080",
    "end": "1472930"
  },
  {
    "text": "with from first\nprinciples, but this seems to work better than\nthings like LSTMs or GRUs.",
    "start": "1472930",
    "end": "1480730"
  },
  {
    "text": "And this was in 2017, so\nthis is a long time ago, but at the time, they achieved\nstate of the art results",
    "start": "1480730",
    "end": "1488350"
  },
  {
    "text": "in terms of error rates on-- I think this is ImageNet. I'm not sure.",
    "start": "1488350",
    "end": "1495429"
  },
  {
    "text": "So yeah, through\nthese applications-- ",
    "start": "1495430",
    "end": "1501562"
  },
  {
    "text": "we don't really have time to\ngo into depth on any of those, but hopefully, you're kind of\nconvinced that large-scale meta",
    "start": "1501562",
    "end": "1509270"
  },
  {
    "text": "optimization is possible. And now we're going to look at\nsome approaches to doing that.",
    "start": "1509270",
    "end": "1515960"
  },
  {
    "text": "And I'm going to talk\nabout two approaches. Some of the works I've\ntalked about before use one",
    "start": "1515960",
    "end": "1522710"
  },
  {
    "text": "of these two, and some\nuse other approaches, which I'll briefly touch on. But yeah, that's what\nwe're going to talk about.",
    "start": "1522710",
    "end": "1532010"
  },
  {
    "text": "Are there any questions? I have a question about\nlearning to learn optimizer",
    "start": "1532010",
    "end": "1538250"
  },
  {
    "text": "from the paper. So is it that the optimizer is\nbeing learned simultaneously",
    "start": "1538250",
    "end": "1543260"
  },
  {
    "text": "as the main training\nis happening, or is it that we need\nsome offline data to train this optimizer first and\nthen use this optimizer, so--",
    "start": "1543260",
    "end": "1550341"
  },
  {
    "text": "Yeah, that's a good question. The question is,\nis the optimizer learned alongside training?",
    "start": "1550342",
    "end": "1555860"
  },
  {
    "text": "And I think, in this\npaper, the answer is yes. And you train a little\nbit, update the optimizer,",
    "start": "1555860",
    "end": "1562760"
  },
  {
    "text": "and then train a\nbit more and so on. A question about the computing. So you're like-- so it's like\na [INAUDIBLE] every time you",
    "start": "1562760",
    "end": "1570740"
  },
  {
    "text": "see a new [INAUDIBLE],,\nevery time the optimizer is trying to predict, every time\nyou see a new kind of gradient,",
    "start": "1570740",
    "end": "1576132"
  },
  {
    "text": "every time [INAUDIBLE] is trying\nto build like the end of it in a new position every time.",
    "start": "1576132",
    "end": "1581720"
  },
  {
    "text": "So how is it able to do\npredictions and unseen things every time for optimizers? Because the cleaning is\nlike a random part where",
    "start": "1581720",
    "end": "1589970"
  },
  {
    "text": "it doesn't have\nexperience of navigating to the new false landscape. Right.",
    "start": "1589970",
    "end": "1595160"
  },
  {
    "text": "Yeah, the question is,\nhow does it basically generalize to places in the\nlandscape where it hasn't seen?",
    "start": "1595160",
    "end": "1602690"
  },
  {
    "text": "And the answer is--  so first of all, let's say our\nnetwork learned the identity",
    "start": "1602690",
    "end": "1613560"
  },
  {
    "text": "function of the gradient. So it just passes\nforward the gradient. That works well by itself,\nand it generalizes.",
    "start": "1613560",
    "end": "1620670"
  },
  {
    "text": "So there is a pretty\nsimple solution for the meta-optimization\nthat generalizes.",
    "start": "1620670",
    "end": "1627690"
  },
  {
    "text": "And because we're explicitly\noptimizing for the outer loop",
    "start": "1627690",
    "end": "1633029"
  },
  {
    "text": "loss after you take gradient\nsteps, do you generalize?",
    "start": "1633030",
    "end": "1639120"
  },
  {
    "text": "That's what kind\nof the secret sauce that makes it learn\ngeneralizable updates,",
    "start": "1639120",
    "end": "1646200"
  },
  {
    "text": "if that makes sense. Do you have a [INAUDIBLE] really\nhave to control for getting out",
    "start": "1646200",
    "end": "1654920"
  },
  {
    "text": "of the [INAUDIBLE]\nthe same kind of stuff we don't actually it's a unique\nexperience because the way",
    "start": "1654920",
    "end": "1663080"
  },
  {
    "text": "I think people do have\na problem [INAUDIBLE] it when they're trying to\nout and see what happened and then fix it.",
    "start": "1663080",
    "end": "1669840"
  },
  {
    "text": "So that is [INAUDIBLE]\nwithout seeing what happens. Everything is unseen\nfor the optimizer.",
    "start": "1669840",
    "end": "1677059"
  },
  {
    "text": " Oh, my previous answer\nmay have been confusing.",
    "start": "1677060",
    "end": "1682730"
  },
  {
    "text": "So it does reset. So after you train on a\ncouple of runs, we go back.",
    "start": "1682730",
    "end": "1690120"
  },
  {
    "text": "We completely reset the\ninner loop parameters and then learn again from there.",
    "start": "1690120",
    "end": "1696430"
  },
  {
    "text": "So, yeah, whatever\ntimestep it arrives at, it's probably seen that before. ",
    "start": "1696430",
    "end": "1704014"
  },
  {
    "text": "OK. ",
    "start": "1704014",
    "end": "1709950"
  },
  {
    "text": "Yeah, let's move on.  Yeah, so we're going to talk\nabout a couple of approaches",
    "start": "1709950",
    "end": "1717880"
  },
  {
    "text": "to large-scale\nmeta-optimization. And, yeah, before laying out\nthe direct approaches how",
    "start": "1717880",
    "end": "1729960"
  },
  {
    "text": "to do this, we're going\nto kind of visualize what happens with unrolled\ncomputation graphs.",
    "start": "1729960",
    "end": "1737130"
  },
  {
    "text": "So that means when you\noptimize some set of parameters continuously, we can unroll\nthat computation graph",
    "start": "1737130",
    "end": "1745679"
  },
  {
    "text": "into kind of a\nsequence of parameters. So here, let's say we start\nfrom the parameters by 1,",
    "start": "1745680",
    "end": "1753210"
  },
  {
    "text": "and we do a gradient\nstep and get by 2. And we keep doing that. So these blue blocks are your\nparameters, your inner loop",
    "start": "1753210",
    "end": "1762000"
  },
  {
    "text": "learner parameters. And then we finally\nget the validation loss",
    "start": "1762000",
    "end": "1767669"
  },
  {
    "text": "at the final timestep. So our goal is to\nmodify something",
    "start": "1767670",
    "end": "1774330"
  },
  {
    "text": "about this inner loop\nlearning system so that the red node becomes low.",
    "start": "1774330",
    "end": "1783890"
  },
  {
    "text": "And from this viewpoint, we\ncan view a lot of the things",
    "start": "1783890",
    "end": "1788930"
  },
  {
    "text": "that we talked about as possible\nmeta-parameters as follows.",
    "start": "1788930",
    "end": "1795930"
  },
  {
    "text": "So the initial\nparameters-- it's there. And your red dot, the final\nvalidation loss, is there.",
    "start": "1795930",
    "end": "1802160"
  },
  {
    "text": "So, yeah, that's what makes\nthe backpropagation hard to-- yeah, through the\nwhole training loop.",
    "start": "1802160",
    "end": "1810410"
  },
  {
    "text": "And for learned losses,\nI think you mentioned regularizers or optimizers.",
    "start": "1810410",
    "end": "1817190"
  },
  {
    "text": "The meta-parameters that\nyou're optimizing are-- they appear in the\nmapping from a parameter",
    "start": "1817190",
    "end": "1824750"
  },
  {
    "text": "to the next parameter like this. And for data set distillation\nand learning augmentations,",
    "start": "1824750",
    "end": "1833245"
  },
  {
    "text": "the meta-parameters appear\nas the input to your network.",
    "start": "1833245",
    "end": "1841160"
  },
  {
    "text": "And for the architecture,\nit's kind of embedded inside your parameters.",
    "start": "1841160",
    "end": "1846950"
  },
  {
    "text": "It kind of interacts\nin a way that can't represent with arrows.",
    "start": "1846950",
    "end": "1852340"
  },
  {
    "text": "So kind of the points\nthat I'm getting at is you can view all of these\nas suffering from the same core",
    "start": "1852340",
    "end": "1861139"
  },
  {
    "text": "issue, which is that you have to\nbackpropagate through this very long chain to get from\nthe red to the green.",
    "start": "1861140",
    "end": "1868620"
  },
  {
    "text": "So we can't apply\ndirect backpropagation.",
    "start": "1868620",
    "end": "1874070"
  },
  {
    "text": "So, yeah, we're\ngoing to talk about truncated backpropagation. And, yeah, from\nthe visualizations",
    "start": "1874070",
    "end": "1880730"
  },
  {
    "text": "from before, really\nwhy we consider large-scale meta-optimization\nand these specialized",
    "start": "1880730",
    "end": "1887360"
  },
  {
    "text": "approaches is that we just can't\nfit all of these parameters into a GPU.",
    "start": "1887360",
    "end": "1892865"
  },
  {
    "text": " So truncated backpropagation\nis quite a simple algorithm.",
    "start": "1892865",
    "end": "1901480"
  },
  {
    "text": "It uses a time length.",
    "start": "1901480",
    "end": "1906740"
  },
  {
    "text": "So let's say 3. And as you feed things\nforward, as you optimize,",
    "start": "1906740",
    "end": "1915620"
  },
  {
    "text": "you just detach everything\nbefore three steps ago. And that makes it\nso that you can",
    "start": "1915620",
    "end": "1922940"
  },
  {
    "text": "apply direct backpropagation\nto the green nodes that are nearby.",
    "start": "1922940",
    "end": "1928610"
  },
  {
    "text": "But you have to just ignore\neverything from before. ",
    "start": "1928610",
    "end": "1935680"
  },
  {
    "text": "Yeah, so when we're considering\ntime lengths like this,",
    "start": "1935680",
    "end": "1944800"
  },
  {
    "text": "what could happen if we\nuse two shorts of a T?",
    "start": "1944800",
    "end": "1950152"
  },
  {
    "text": "Like what would\nbe the trade-offs? ",
    "start": "1950152",
    "end": "1958908"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "1958908",
    "end": "1965799"
  },
  {
    "text": "Yeah, the answer-- yeah, you\nsaid backpropagation is faster, but we just don't learn\nthings from earlier.",
    "start": "1965800",
    "end": "1972190"
  },
  {
    "text": "And, yeah, that's\nexactly correct.  We basically can't learn\nany long-term dependencies.",
    "start": "1972190",
    "end": "1981310"
  },
  {
    "text": "If we have a timestep\nof three, then we only optimize things that are\nbeneficial in the short term",
    "start": "1981310",
    "end": "1990220"
  },
  {
    "text": "while ignoring\neverything, every way in which the green nodes\ncan help the red node down",
    "start": "1990220",
    "end": "1998315"
  },
  {
    "text": "the feature.  Implementing this\nis quite simple.",
    "start": "1998315",
    "end": "2003580"
  },
  {
    "text": "This is for an RNN. And it's slightly different\nfrom that visualization,",
    "start": "2003580",
    "end": "2009000"
  },
  {
    "text": "but the main trick is that\nas you feed things forward, you just detach things\nwhen they become too old.",
    "start": "2009000",
    "end": "2016710"
  },
  {
    "text": "And your GPU is happy with that. So for truncated\nbackpropagation,",
    "start": "2016710",
    "end": "2024830"
  },
  {
    "text": "it's very simple. So here also as in\ndirect backpropagation,",
    "start": "2024830",
    "end": "2029870"
  },
  {
    "text": "autograd handles everything\nas long as you detach things when you have to.",
    "start": "2029870",
    "end": "2036169"
  },
  {
    "text": "The problem is that first,\nit's a biased estimator, so you're not getting the true\ngradient of green with respect",
    "start": "2036170",
    "end": "2043820"
  },
  {
    "text": "to red. So that bias can\nharm performance.",
    "start": "2043820",
    "end": "2049040"
  },
  {
    "text": "And more specifically, we cannot\ntake long-range dependencies",
    "start": "2049040",
    "end": "2055969"
  },
  {
    "text": "into account, which when\nwe're meta-learning with big",
    "start": "2055969",
    "end": "2062638"
  },
  {
    "text": "computation graphs, really what\nwe want is to learn something that kind of keeps on being\nuseful as you keep taking",
    "start": "2062639",
    "end": "2070320"
  },
  {
    "text": "steps. And this is kind of undesirable. One point that can be\ngood and can be bad",
    "start": "2070320",
    "end": "2077790"
  },
  {
    "text": "is that by using\ndifferent T, you can have a trade-off between\ncorrectness and memory cost.",
    "start": "2077790",
    "end": "2085239"
  },
  {
    "text": "So in the limits\nof the maximal T, you get totally\nunbiased, totally not",
    "start": "2085239",
    "end": "2093060"
  },
  {
    "text": "ignoring long-range\ndependencies, but you need a lot of memory.",
    "start": "2093060",
    "end": "2098550"
  },
  {
    "text": "And with shorter\nT, you ignore all the long-range dependencies,\nbut it's easier to compute.",
    "start": "2098550",
    "end": "2106829"
  },
  {
    "text": " There's a similar approach\nalso, very good to, say,",
    "start": "2106830",
    "end": "2111900"
  },
  {
    "text": "the inner loop of MAML.  So this is a substitute for RNN,\nor this was a similar approach",
    "start": "2111900",
    "end": "2122220"
  },
  {
    "text": "for MAML? Oh, yeah, the question is,\nis this specific to RNNs?",
    "start": "2122220",
    "end": "2127860"
  },
  {
    "text": "And no, I should have been\nmore clear about that. This works in any\ninner optimization,",
    "start": "2127860",
    "end": "2136020"
  },
  {
    "text": "inner sequential\noptimization loop. And the blue things\ncan be parameters",
    "start": "2136020",
    "end": "2141569"
  },
  {
    "text": "where moving to the right would\nbe a step of gradient descent.",
    "start": "2141570",
    "end": "2146994"
  },
  {
    "text": "So there's a\nbroken, say, MAML so that you keep computing\ngradients every three",
    "start": "2146994",
    "end": "2153830"
  },
  {
    "text": "timesteps? Or do you just forget\nthe [INAUDIBLE]?? ",
    "start": "2153830",
    "end": "2159740"
  },
  {
    "text": "Yeah, you would detach\neverything from before.",
    "start": "2159740",
    "end": "2164880"
  },
  {
    "text": "So let's say you take\n100 gradient steps. At the 100th gradient\nstep before you backprop, you would detach from like\nthe 97th gradient step back.",
    "start": "2164880",
    "end": "2174920"
  },
  {
    "text": "So you would still use\nthe parameter values, but the gradients just\nwouldn't flow past that.",
    "start": "2174920",
    "end": "2179990"
  },
  {
    "start": "2179990",
    "end": "2186654"
  },
  {
    "text": "You called detach\non those variables. [INAUDIBLE] How would you detach\nwith the previous parameters",
    "start": "2186654",
    "end": "2197855"
  },
  {
    "text": "like the gradient\nsteps with the masks? ",
    "start": "2197855",
    "end": "2203690"
  },
  {
    "text": "The question is, how would you\ndetach the previous parameters?",
    "start": "2203690",
    "end": "2210020"
  },
  {
    "text": "Yeah, just calling\ndetach should suffice. And you could--",
    "start": "2210020",
    "end": "2215660"
  },
  {
    "text": "[INAUDIBLE]? ",
    "start": "2215660",
    "end": "2223410"
  },
  {
    "text": "How would you describe\nwhat really [INAUDIBLE]?? Oh, got it. Yeah, so the question\nis, how do you keep track of these variables?",
    "start": "2223410",
    "end": "2228950"
  },
  {
    "text": "Yeah, you would need\nto keep something like a tuple or a list to it. Yeah. Could you explain again what you\nmean by long-range dependency",
    "start": "2228950",
    "end": "2238099"
  },
  {
    "text": "in the inner loop setting? Oh, sure. The question is, what do I mean\nby long-range dependencies?",
    "start": "2238100",
    "end": "2245760"
  },
  {
    "text": "So let's say instead of 5\nsteps it's like 100 steps,",
    "start": "2245760",
    "end": "2252360"
  },
  {
    "text": "there's going to be a way that\nthe input at the first step",
    "start": "2252360",
    "end": "2257550"
  },
  {
    "text": "influences the output\nat the last step. But by truncating\nsomewhere in between,",
    "start": "2257550",
    "end": "2263160"
  },
  {
    "text": "the gradient doesn't flow\nfrom here all the way to the beginning. So we kind of ignore all\nthose long-range dependencies",
    "start": "2263160",
    "end": "2269610"
  },
  {
    "text": "in terms of timesteps. ",
    "start": "2269610",
    "end": "2275960"
  },
  {
    "text": "Yeah, let's move on. And, yeah, we're\nnow going to talk",
    "start": "2275960",
    "end": "2282130"
  },
  {
    "text": "about gradient-free\noptimization. And this just directly\navoids the issue",
    "start": "2282130",
    "end": "2289569"
  },
  {
    "text": "of not being able to\nbackpropagate through the graph because we can do optimization\nwithout using the gradients.",
    "start": "2289570",
    "end": "2300050"
  },
  {
    "text": "So the algorithm that\nwe're going to talk about is evolution\nstrategies, though there",
    "start": "2300050",
    "end": "2305240"
  },
  {
    "text": "are other gradient-free\noptimization methods that aren't this.",
    "start": "2305240",
    "end": "2310670"
  },
  {
    "text": "It's roughly inspired\nby biological evolution where the whatever has\nthe highest survival rate",
    "start": "2310670",
    "end": "2322160"
  },
  {
    "text": "just keeps expanding. And, yeah, nature doesn't\nbackpropagate, so, yeah,",
    "start": "2322160",
    "end": "2331579"
  },
  {
    "text": "we're just going to\ndirectly use that trick. Is this like genetic algorithm?",
    "start": "2331580",
    "end": "2338869"
  },
  {
    "text": "Yeah, the question is, is\nthis like genetic algorithms? I think it's exactly\nthe same thing.",
    "start": "2338870",
    "end": "2344480"
  },
  {
    "text": "That might be false, but, yeah,\nthey're very related, at least. ",
    "start": "2344480",
    "end": "2353089"
  },
  {
    "text": "So how evolution strategies\nworks is roughly like this, and we'll walk through\nthis step by step.",
    "start": "2353090",
    "end": "2360385"
  },
  {
    "text": " So first of all, we\ninitialize the parameters.",
    "start": "2360385",
    "end": "2366600"
  },
  {
    "text": "So in this visualization,\nimagine that your parameter space is two-dimensional.",
    "start": "2366600",
    "end": "2371960"
  },
  {
    "text": "And any parameter combination\nis a single point in this.",
    "start": "2371960",
    "end": "2378589"
  },
  {
    "text": "And the loss surface is so\nthat the lighter regions are better losses.",
    "start": "2378590",
    "end": "2385520"
  },
  {
    "text": "So what we do is we\ninitialize the distribution of parameters, mu and sigma.",
    "start": "2385520",
    "end": "2393460"
  },
  {
    "text": "And then we just sample a\nbunch of parameters like this. ",
    "start": "2393460",
    "end": "2401039"
  },
  {
    "text": "Yeah, so let's say-- ",
    "start": "2401040",
    "end": "2408080"
  },
  {
    "text": "yeah, let's say\nthat is the reason that we want to arrive at. And our initial parameters\nare something like this.",
    "start": "2408080",
    "end": "2416400"
  },
  {
    "text": "So we've sampled 7 points. And after sampling a\nbunch of particles,",
    "start": "2416400",
    "end": "2423920"
  },
  {
    "text": "we evaluate and get\nthe top n with where small n is smaller than big n.",
    "start": "2423920",
    "end": "2432119"
  },
  {
    "text": "So in this case, let's say\nwe had seven particles,",
    "start": "2432120",
    "end": "2438440"
  },
  {
    "text": "and we want to\npick the top four. That would be\nsomething like this.",
    "start": "2438440",
    "end": "2443450"
  },
  {
    "start": "2443450",
    "end": "2449790"
  },
  {
    "text": "So we evaluate this\nand get the top four and then we just plug in\nthe average and variance",
    "start": "2449790",
    "end": "2458450"
  },
  {
    "text": "of the top population. So now we would sample\nfrom this distribution",
    "start": "2458450",
    "end": "2465740"
  },
  {
    "text": "in the next generation. And yeah, we just\nkeep doing this.",
    "start": "2465740",
    "end": "2472190"
  },
  {
    "text": "We sample again from here. Maybe we get\nsomething like this. Take the top four.",
    "start": "2472190",
    "end": "2478609"
  },
  {
    "text": "And the population just\nkeeps converging to this without ever having to\nbackpropagate or need",
    "start": "2478610",
    "end": "2486230"
  },
  {
    "text": "the gradients of\nthis loss service. What about this-- like,\nget stuck in local minima",
    "start": "2486230",
    "end": "2493670"
  },
  {
    "text": "pretty easily? Like, is it pretty exploitative\nas opposed to exploration? Yeah, the question is, won't\nthis get stuck in local minima?",
    "start": "2493670",
    "end": "2501380"
  },
  {
    "text": " It definitely can.",
    "start": "2501380",
    "end": "2507790"
  },
  {
    "text": "I would say that's\nsomething that you can also say of stochastic\ngradient descent, though. So any kind of\nlocal search method",
    "start": "2507790",
    "end": "2515529"
  },
  {
    "text": "can get stuck in local minima. For this, what people usually\ndo is they add an exploration",
    "start": "2515530",
    "end": "2522640"
  },
  {
    "text": "term, so you kind of\nincrease your variance whenever you're too sure\nso that can mitigate that.",
    "start": "2522640",
    "end": "2530450"
  },
  {
    "text": "But, yeah, it definitely\ncan be possible. So if this region was\nlike a lot better,",
    "start": "2530450",
    "end": "2537152"
  },
  {
    "text": "it's definitely possible that\nyou're just stuck here forever. ",
    "start": "2537153",
    "end": "2545050"
  },
  {
    "text": "Yeah. So we're going to walk through\na very simple example of this",
    "start": "2545050",
    "end": "2552400"
  },
  {
    "text": "where we optimize the learning\nrates instead of this 2D",
    "start": "2552400",
    "end": "2558160"
  },
  {
    "text": "surface. So for optimizing\nthe learning rates, how this would work\nis you initialize",
    "start": "2558160",
    "end": "2564370"
  },
  {
    "text": "your average learning\nrates and noise probably to a reasonable value\nfor a learning rate.",
    "start": "2564370",
    "end": "2572080"
  },
  {
    "text": "So yeah, something like\n0.001 is probably reasonable.",
    "start": "2572080",
    "end": "2577210"
  },
  {
    "text": "And we just sample a\nbunch of learning rates from that distribution.",
    "start": "2577210",
    "end": "2584800"
  },
  {
    "text": "And then the inner loop is\nwhere you get to do basically anything you want. And here, using each learning\nrates, we initialize a network",
    "start": "2584800",
    "end": "2595510"
  },
  {
    "text": "and then run SGD. And then we evaluate\nall of those runs and then pick the top end\nwith the best accuracy.",
    "start": "2595510",
    "end": "2603430"
  },
  {
    "text": " And then with those\ntop candidates,",
    "start": "2603430",
    "end": "2611240"
  },
  {
    "text": "we take the average and\nvariance of the learning rates,",
    "start": "2611240",
    "end": "2617640"
  },
  {
    "text": "and then we keep\nrepeating again. And as we do this, we converge\ntowards better learning rates",
    "start": "2617640",
    "end": "2624180"
  },
  {
    "text": "for whatever datasets\nor architecture that you are considering.",
    "start": "2624180",
    "end": "2630794"
  },
  {
    "text": "When you say run the\nSGD, do you mean running for a small number of steps? So it is not like training.",
    "start": "2630794",
    "end": "2638160"
  },
  {
    "text": " The question is, is SGD\na small number of steps?",
    "start": "2638160",
    "end": "2645220"
  },
  {
    "text": "It can be anything you want. I'm considering actual training,\nso very long, many epochs.",
    "start": "2645220",
    "end": "2651730"
  },
  {
    "text": "And the reason we can do that is\nthat we choose the best members",
    "start": "2651730",
    "end": "2657340"
  },
  {
    "text": "without having to hold\nthe entire computation graph in memory. ",
    "start": "2657340",
    "end": "2672990"
  },
  {
    "text": "Yeah, here's a\nconceptual question. What would happen if we\ntry to, instead of learning",
    "start": "2672990",
    "end": "2680000"
  },
  {
    "text": "meta-learning the\nlearning rates, use this exact algorithm to\noptimize the initial parameters",
    "start": "2680000",
    "end": "2686120"
  },
  {
    "text": "as in MAML? ",
    "start": "2686120",
    "end": "2696980"
  },
  {
    "text": "It'd be very inefficient\nbecause the number of parameters is very large.",
    "start": "2696980",
    "end": "2702400"
  },
  {
    "text": "Right. Yeah, the answer was that\nit'd be very inefficient because the number of\nparameters is large.",
    "start": "2702400",
    "end": "2707950"
  },
  {
    "text": "Yeah, I definitely\nagree with that.",
    "start": "2707950",
    "end": "2714660"
  },
  {
    "text": "I would phrase that as, because\nyour parameter space is really high dimensional, we would\nbasically never observe",
    "start": "2714660",
    "end": "2723310"
  },
  {
    "text": "a good outer loop\nloss because just",
    "start": "2723310",
    "end": "2728560"
  },
  {
    "text": "by applying\nhigh-dimensional noise, we would never arrive at\nany sort of good parameters.",
    "start": "2728560",
    "end": "2736880"
  },
  {
    "text": "So this would never learn. It would learn in the\nlimit of infinite time,",
    "start": "2736880",
    "end": "2742470"
  },
  {
    "text": "but, yeah, it'd be very\nsample inefficient. ",
    "start": "2742470",
    "end": "2754450"
  },
  {
    "text": "So the advantage of evolution\nstrategies is that-- oops, yeah, question?",
    "start": "2754450",
    "end": "2759864"
  },
  {
    "text": "Very good. It's high dimensional. That's why you can't do it. So I wanted to ask a question. Is there any way to divide\nthe dimension spaces",
    "start": "2759864",
    "end": "2768270"
  },
  {
    "text": "and work on optimization\nfor some dimensional spaces and then maybe somehow\nmerge it for the point",
    "start": "2768270",
    "end": "2774119"
  },
  {
    "text": "optimal for the whole world? Is there any approach\nthey can start?",
    "start": "2774120",
    "end": "2779140"
  },
  {
    "text": "Yeah, the question\nis, because we have a high-dimensional space,\ncan we divide the dimensions",
    "start": "2779140",
    "end": "2785579"
  },
  {
    "text": "and optimize separately? ",
    "start": "2785580",
    "end": "2791836"
  },
  {
    "text": "And then to accomplish to the\nwork to get the final opt-- Right. ",
    "start": "2791836",
    "end": "2801030"
  },
  {
    "text": "So I think that can work if\nthe loss surface is factorized",
    "start": "2801030",
    "end": "2807070"
  },
  {
    "text": "in the sense that\nif you optimize this set of parameters,\nit has no effect on this.",
    "start": "2807070",
    "end": "2815855"
  },
  {
    "text": "But-- [INAUDIBLE] account for\ninterdependency as well in the merging step?",
    "start": "2815855",
    "end": "2821190"
  },
  {
    "text": " Is there something, any\nresearch on this video?",
    "start": "2821190",
    "end": "2828600"
  },
  {
    "text": "Not that I know of. Yeah, you would\nhave to be relying",
    "start": "2828600",
    "end": "2834080"
  },
  {
    "text": "on some sort of\nindependence conditions, so yeah, I'm not\nsure how that would",
    "start": "2834080",
    "end": "2841190"
  },
  {
    "text": "work or aware of related works. So do we usually use\nthese evolution strategies",
    "start": "2841190",
    "end": "2848390"
  },
  {
    "text": "to the inner loop or outer? Oh, this is all happening in\nthe outer loop at the moment.",
    "start": "2848390",
    "end": "2855869"
  },
  {
    "text": "So in the example here, yeah,\nthe inner loop was just SGD.",
    "start": "2855870",
    "end": "2862760"
  },
  {
    "text": "And we were using evolution\nstrategies in the outer loop, but, of course, you could\nuse evolution strategies",
    "start": "2862760",
    "end": "2870619"
  },
  {
    "text": "in the inner loop. If we use it in the\ninner loop, then how can we fully launch\nwith our outer loop",
    "start": "2870620",
    "end": "2878130"
  },
  {
    "text": "because you don't have\na set creative decision? So the question is, if we\nuse evolution strategies",
    "start": "2878130",
    "end": "2884520"
  },
  {
    "text": "in the inner loop and we want\nto do direct backpropagation in the outer loop?",
    "start": "2884520",
    "end": "2889530"
  },
  {
    "text": " Yeah, to my knowledge,\nthere's no way",
    "start": "2889530",
    "end": "2895320"
  },
  {
    "text": "to backpropagate through\nevolution strategies. So you would have to use some\nouter loop optimization method",
    "start": "2895320",
    "end": "2903150"
  },
  {
    "text": "that doesn't require gradients. So you could do inner\nloop evolution strategies",
    "start": "2903150",
    "end": "2908610"
  },
  {
    "text": "and outer loop\nevolution strategies. That would work. Go ahead. [INAUDIBLE] what's\nthe difference",
    "start": "2908610",
    "end": "2915410"
  },
  {
    "text": "between computational\ncost in evolution and the normal gradient?",
    "start": "2915410",
    "end": "2920760"
  },
  {
    "text": " Could you repeat that? What are we comparing?",
    "start": "2920760",
    "end": "2926540"
  },
  {
    "text": "So for each iteration of update\nin the parameter we used, what's the difference between\nthe computational cost",
    "start": "2926540",
    "end": "2933120"
  },
  {
    "text": "of evolution and normal\ngradient descent?",
    "start": "2933120",
    "end": "2938890"
  },
  {
    "text": "So the question\nis about comparing the computational graph\nof evolution strategies and direct backpropagation?",
    "start": "2938890",
    "end": "2945110"
  },
  {
    "text": "OK, so in terms of computation-- ",
    "start": "2945110",
    "end": "2951769"
  },
  {
    "text": "yeah, evolution\nstrategies just requires",
    "start": "2951770",
    "end": "2959050"
  },
  {
    "text": "a copy of your parameters\nthat can be updated. So it's like your\nnetwork times 1,",
    "start": "2959050",
    "end": "2965230"
  },
  {
    "text": "whereas for a direct\nbackpropagation, it's your network times\nthe number of steps,",
    "start": "2965230",
    "end": "2970375"
  },
  {
    "text": "because you have to keep\neverything in memory so that you can backpropagate. ",
    "start": "2970375",
    "end": "2976650"
  },
  {
    "text": "So in that sense, this\nis constant and direct backpropagation. [INAUDIBLE] toward\nsome [INAUDIBLE]",
    "start": "2976650",
    "end": "2984584"
  },
  {
    "text": "because storing\ngradients and some-- like, some are for\neach parameter.",
    "start": "2984584",
    "end": "2989609"
  },
  {
    "text": "You are just retrieve-- you're\nlosing [INAUDIBLE] over the-- we are just reading, right? You have stored it just once.",
    "start": "2989610",
    "end": "2996030"
  },
  {
    "text": "So you're just\nessentially creating a copy of the architecture. And for each parameter, you're\nactually storing each gradient.",
    "start": "2996030",
    "end": "3002180"
  },
  {
    "text": "So why do we need to store it\nevery time you need to go back? Let's say if I can remove\ngradient for the last year.",
    "start": "3002180",
    "end": "3010160"
  },
  {
    "text": "I stored it. Then last second, I just need\nto retrieve the work, right? So it's just a reading\ncost for the thought, not",
    "start": "3010160",
    "end": "3017900"
  },
  {
    "text": "actually writing costs,\nbut to the metrics. So is the question that--",
    "start": "3017900",
    "end": "3026220"
  },
  {
    "text": "So just asking [INAUDIBLE]. ",
    "start": "3026220",
    "end": "3031888"
  },
  {
    "text": "Yeah, for direct\nbackpropagation? Yeah. Yeah. If you can backpropagate\nfor solutions.",
    "start": "3031888",
    "end": "3037880"
  },
  {
    "text": "Yeah, I think you're talking\nabout gradient checkpointing,",
    "start": "3037880",
    "end": "3043559"
  },
  {
    "text": "which is-- yeah, that would\nsave memory cost",
    "start": "3043560",
    "end": "3049500"
  },
  {
    "text": "at the expense of time cost. And if you start\nusing that, then",
    "start": "3049500",
    "end": "3054990"
  },
  {
    "text": "backpropagating through a\nlong chain would be feasible. But the time cost would make\nit pretty quickly unfeasible,",
    "start": "3054990",
    "end": "3064500"
  },
  {
    "text": "because you would have\nto store parameters. And then you'd have to\nbasically go back and--",
    "start": "3064500",
    "end": "3069839"
  },
  {
    "text": "Repeat everything you've done. Yeah. [INAUDIBLE] ",
    "start": "3069840",
    "end": "3075990"
  },
  {
    "text": "Right. Yeah. And here, they could\nbe done independently. Like all the parameters could\nbe done independently and very,",
    "start": "3075990",
    "end": "3083320"
  },
  {
    "text": "very conservative. Right, Here, it can be\ncompletely in parallel and you don't have\nto store anything.",
    "start": "3083320",
    "end": "3089055"
  },
  {
    "text": "Yeah, right. Thanks. Yeah? Is there a proper ratio\nbetween the number",
    "start": "3089055",
    "end": "3096510"
  },
  {
    "text": "of candidate with simple and\nthe dimension of the parameters to optimize using the\nevolution strategy?",
    "start": "3096510",
    "end": "3106890"
  },
  {
    "text": "So you're talking about large\nand D, which is 2 here, right?",
    "start": "3106890",
    "end": "3112201"
  },
  {
    "text": "The number of big N and\nthe dimension of alpha.",
    "start": "3112201",
    "end": "3119145"
  },
  {
    "text": "OK, yeah, the question is about\nthe proper ratio between big N and the alpha's dimension.",
    "start": "3119145",
    "end": "3124830"
  },
  {
    "text": "I don't think there are\nvery strong guidelines. But it definitely\ncan't be the case",
    "start": "3124830",
    "end": "3132670"
  },
  {
    "text": "that your loss surface is\nvery high dimensional and very curved.",
    "start": "3132670",
    "end": "3138450"
  },
  {
    "text": "And you use N that's\nmuch smaller than that. So if you have a million\ndimensional parameter space,",
    "start": "3138450",
    "end": "3143940"
  },
  {
    "text": "you can't use N equals\n10 to explore that space. ",
    "start": "3143940",
    "end": "3150678"
  },
  {
    "text": "Does that answer your question? ",
    "start": "3150678",
    "end": "3157184"
  },
  {
    "text": "Yeah, I'm just wondering\nhow do evolution try to use computer in general\nto [INAUDIBLE] of learning,",
    "start": "3157184",
    "end": "3164890"
  },
  {
    "text": "like having a Gaussian\nprocess that kind of predicts, supports the loss of each\ncarbon emission [INAUDIBLE]??",
    "start": "3164890",
    "end": "3173560"
  },
  {
    "text": "Because I know we got processes\nyou need to store basically all the samples you've\ntaken throughout history,",
    "start": "3173560",
    "end": "3179930"
  },
  {
    "text": "whereas this one I guess\ndoesn't need to do that. It doesn't need to [INAUDIBLE] Right. And do you want to compare with\nrespect to time, and space,",
    "start": "3179930",
    "end": "3189220"
  },
  {
    "text": "or performance? I guess when you choose\none or the other--",
    "start": "3189220",
    "end": "3195370"
  },
  {
    "text": "because I know for\nGaussian processes, depending on the\nsample strategy, you could find a global optima.",
    "start": "3195370",
    "end": "3204310"
  },
  {
    "text": "But also it becomes\nmuch, much more expensive as dimensions becomes larger. ",
    "start": "3204310",
    "end": "3212820"
  },
  {
    "text": "So yeah, when would you decide\nto use evolution strategy?",
    "start": "3212820",
    "end": "3217900"
  },
  {
    "text": "Yeah, that's a good question. The question is, when would\nyou decide evolution strategies",
    "start": "3217900",
    "end": "3225160"
  },
  {
    "text": "or Gaussian processes for\nthese sorts of settings? And, yeah, honestly,\nI don't really",
    "start": "3225160",
    "end": "3233060"
  },
  {
    "text": "have that good of a sense of\nwhen what would be better. ",
    "start": "3233060",
    "end": "3241250"
  },
  {
    "text": "So for Gaussian processes,\nyour prior in likelihood",
    "start": "3241250",
    "end": "3246410"
  },
  {
    "text": "have to be very well suited to\nwhatever problem you're using.",
    "start": "3246410",
    "end": "3251750"
  },
  {
    "text": "And we generally don't\nhave something like that for high-dimensional data.",
    "start": "3251750",
    "end": "3257329"
  },
  {
    "text": "Like if our task\nin the inner loop is large-scale image\nclassification,",
    "start": "3257330",
    "end": "3264692"
  },
  {
    "text": "I don't really know\nhow we would do that with Gaussian processes. But if you have a really\ngood prior in likelihood",
    "start": "3264692",
    "end": "3271730"
  },
  {
    "text": "model for Gaussian processes,\nthen that can be better. And storage-wise,\nI think something",
    "start": "3271730",
    "end": "3284190"
  },
  {
    "text": "like this would scale a\nlot better because we don't have to store or keep track\nof all the data points",
    "start": "3284190",
    "end": "3291270"
  },
  {
    "text": "that we have. ",
    "start": "3291270",
    "end": "3299173"
  },
  {
    "text": "Yeah.  Yeah, so the main advantage\nof evolution strategies",
    "start": "3299174",
    "end": "3308870"
  },
  {
    "text": "is that the memory cost\nis constant with respect to the number of gradient\nsteps that you use.",
    "start": "3308870",
    "end": "3316760"
  },
  {
    "text": "Basically, whatever\nyou do in step 2, its size doesn't\nmatter to what you",
    "start": "3316760",
    "end": "3325609"
  },
  {
    "text": "need to approximately\ndifferentiate with respect to that.",
    "start": "3325610",
    "end": "3331880"
  },
  {
    "text": "And another advantage is\nthat you can very easily parallelize this.",
    "start": "3331880",
    "end": "3337370"
  },
  {
    "text": "So as soon as you sample\nyour different particles, you can run everything\ncompletely separately.",
    "start": "3337370",
    "end": "3343850"
  },
  {
    "text": "And all you need is\nthe final output. So if you have a lot\nof parallel computers,",
    "start": "3343850",
    "end": "3349700"
  },
  {
    "text": "then this can be well suited. ",
    "start": "3349700",
    "end": "3354990"
  },
  {
    "text": "And you can even consider\nthings in the second step that are non-differentiable\nbecause we don't rely",
    "start": "3354990",
    "end": "3362220"
  },
  {
    "text": "on gradients at the moment. So any sort of sampling\nor discrete operations",
    "start": "3362220",
    "end": "3368400"
  },
  {
    "text": "in the inner loop is very\ncompatible with evolution strategies. ",
    "start": "3368400",
    "end": "3376530"
  },
  {
    "text": "The main disadvantage\nof evolution strategies is that it struggles with\nwhen the parameters, the mu",
    "start": "3376530",
    "end": "3386370"
  },
  {
    "text": "or theta, whatever\nyou want to call it, is very high dimensional\nor when its loss surface",
    "start": "3386370",
    "end": "3392190"
  },
  {
    "text": "is very complex as in\nthe example of optimizing the initial parameters\nwith evolution strategies.",
    "start": "3392190",
    "end": "3400260"
  },
  {
    "start": "3400260",
    "end": "3406960"
  },
  {
    "text": "There are a couple\nof other approaches to large-scale\nmeta-optimization,",
    "start": "3406960",
    "end": "3413290"
  },
  {
    "text": "though these are a bit\nless commonly used. But the method is\npretty interesting.",
    "start": "3413290",
    "end": "3420349"
  },
  {
    "text": "So I'll very briefly\ntouch on them. And there are papers\non the bottom that you",
    "start": "3420350",
    "end": "3425770"
  },
  {
    "text": "can read if you're interested. There's implicit\ndifferentiation.",
    "start": "3425770",
    "end": "3431710"
  },
  {
    "text": "What this does is it leverages\nthe assumption that you",
    "start": "3431710",
    "end": "3437380"
  },
  {
    "text": "converge to an actual\noptimum and differentiates",
    "start": "3437380",
    "end": "3442839"
  },
  {
    "text": "through that optimality\ncondition to get--",
    "start": "3442840",
    "end": "3448930"
  },
  {
    "text": "yeah, you get the\nfull meta-gradient without storing anything. But the assumptions\nthat go in may not",
    "start": "3448930",
    "end": "3457359"
  },
  {
    "text": "be satisfied in all cases. So it's not perfect, but\nit seems to work sometimes.",
    "start": "3457360",
    "end": "3464859"
  },
  {
    "text": "And another approach is\nforward-mode differentiation.",
    "start": "3464860",
    "end": "3471590"
  },
  {
    "text": "So backprop is\nbasically the chain rule where you leverage the fact that\nthe output is one-dimensional.",
    "start": "3471590",
    "end": "3481450"
  },
  {
    "text": "So given all the terms\nin the chain rule, if you start multiplying\nfrom the back,",
    "start": "3481450",
    "end": "3487150"
  },
  {
    "text": "you always have a term\nthat's dimension times 1. So it's always sort of linear.",
    "start": "3487150",
    "end": "3493780"
  },
  {
    "text": "But if you multiply\nfrom the forward, you get these terms that are\nquadratic in the output sizes",
    "start": "3493780",
    "end": "3502390"
  },
  {
    "text": "or parameter sizes, which\ncosts a lot more compute.",
    "start": "3502390",
    "end": "3508900"
  },
  {
    "text": "But this has the advantage of\nnot having to store everything.",
    "start": "3508900",
    "end": "3514609"
  },
  {
    "text": "So because everything\nthat you want to multiply is there at each\nstep, you can just--",
    "start": "3514610",
    "end": "3523730"
  },
  {
    "text": "yeah, you can forward\nprop as you go forward without having to\nstore everything. So it's advantageous when you\ndon't want to store everything.",
    "start": "3523730",
    "end": "3533960"
  },
  {
    "text": "But, yeah, there are cases\nwhere this too is too costly.",
    "start": "3533960",
    "end": "3542150"
  },
  {
    "text": " Yeah. ",
    "start": "3542150",
    "end": "3550130"
  },
  {
    "text": "Yeah, that's roughly -- that's what we have today. So we've talked about\nlarge-scale meta-optimization.",
    "start": "3550130",
    "end": "3559100"
  },
  {
    "text": "We motivated the\nproblem and why existing meta-learning approaches kind\nof fail in large-scale settings.",
    "start": "3559100",
    "end": "3567320"
  },
  {
    "text": "And we talked about\nsome applications and two approaches,\ntruncated backpropagation",
    "start": "3567320",
    "end": "3573260"
  },
  {
    "text": "and gradient-free optimization. And, yeah, the goals were\nthat we know scenarios now",
    "start": "3573260",
    "end": "3582140"
  },
  {
    "text": "where existing approaches\ncan fail because of scale. And we understand\nin a broad sense",
    "start": "3582140",
    "end": "3589820"
  },
  {
    "text": "some techniques for\nthis problem setting. I hope that's been accomplished.",
    "start": "3589820",
    "end": "3596075"
  },
  {
    "text": "Yeah, we have some time for\nquestions if you have any. ",
    "start": "3596075",
    "end": "3608414"
  },
  {
    "text": ", . Does anyone try something\nlike greedy algorithms that we first optimized for what\nwe use only three inner steps",
    "start": "3608414",
    "end": "3621670"
  },
  {
    "text": "and then find a\nresult. And then we fix what we have for\nthe first for inner step",
    "start": "3621670",
    "end": "3627550"
  },
  {
    "text": "and then optimize for the\nfollowing three inner steps so that when we optimize\nfor what the second three",
    "start": "3627550",
    "end": "3638020"
  },
  {
    "text": "inner steps, what we need to\npropagate to the first three in the inner step because we\nalready fixed what we got.",
    "start": "3638020",
    "end": "3647530"
  },
  {
    "text": " So you're talking about\na two-stage method",
    "start": "3647530",
    "end": "3653799"
  },
  {
    "text": "where you do three\nsteps first, and then completely disregard\nwhat happened, and then do three steps again.",
    "start": "3653800",
    "end": "3661050"
  },
  {
    "text": "So we don't need to\nbackpropagate through all of the computation graphs? ",
    "start": "3661050",
    "end": "3670376"
  },
  {
    "text": "Yeah, I think what\nyou're talking about can be viewed as a truncated\nbackpropagation in a sense.",
    "start": "3670376",
    "end": "3677885"
  },
  {
    "text": " Yeah, you're choosing to\nignore the future influence",
    "start": "3677885",
    "end": "3684890"
  },
  {
    "text": "of your first\nthree steps, right? But that influence is\nsomething that can still exist.",
    "start": "3684890",
    "end": "3691515"
  },
  {
    "text": " So in the ideal case, we would\nwant to track this influence.",
    "start": "3691515",
    "end": "3700180"
  },
  {
    "text": "But, yeah, you're making\nthe simple fine choice to ignore that. I think that's just exactly\ntruncated backpropagation.",
    "start": "3700180",
    "end": "3710380"
  },
  {
    "text": "Like truncated\nbackpropagation assume that the result from\nthe bigger steps",
    "start": "3710380",
    "end": "3718359"
  },
  {
    "text": "also apply to the\nfirst few steps. But if we start from the\nfirst and then optimize",
    "start": "3718360",
    "end": "3726850"
  },
  {
    "text": "for the following steps,\nnext we always make sure",
    "start": "3726850",
    "end": "3733660"
  },
  {
    "text": "that we won't get a degenerate\nsolution because we can always make the following\nstep do nothing. ",
    "start": "3733660",
    "end": "3744080"
  },
  {
    "text": "Could you repeat the\ndegenerate solution part? Like when we're doing our\ntruncated backpropagation,",
    "start": "3744080",
    "end": "3751880"
  },
  {
    "text": "we might-- for example, in the slides,\nwe thought the result",
    "start": "3751880",
    "end": "3758610"
  },
  {
    "text": "from the last three\nsteps to the steps,",
    "start": "3758610",
    "end": "3764240"
  },
  {
    "text": "that is detached from\nthe inner optimization. But if we start\nfrom the beginning",
    "start": "3764240",
    "end": "3774030"
  },
  {
    "text": "and then optimize for\nthe following steps, we always can-- those following\nsteps do nothing,",
    "start": "3774030",
    "end": "3784490"
  },
  {
    "text": "so we have exactly\nthe same result as we only do the first few\nsteps that we just optimized.",
    "start": "3784490",
    "end": "3794580"
  },
  {
    "text": "And so is the setting that\nafter the three steps, do you remember the parameters\nof the last third step?",
    "start": "3794580",
    "end": "3802369"
  },
  {
    "text": "Or do you re-initialize\nsomething here? Because if you\nremember it, there",
    "start": "3802370",
    "end": "3808340"
  },
  {
    "text": "is some sort of\nlong-term influence. And if you re-initialize,\nyou're just doing two tasks sequentially.",
    "start": "3808340",
    "end": "3815839"
  },
  {
    "text": "And in the latter\ncase, we can just",
    "start": "3815840",
    "end": "3821210"
  },
  {
    "text": "consider this a two-task set-up.  Yeah, we can take\nthis offline later.",
    "start": "3821210",
    "end": "3828240"
  },
  {
    "start": "3828240",
    "end": "3835580"
  },
  {
    "text": "Yeah, if there are no-- That is a good practical\nquestion, which is, if you're doing\nmodel development,",
    "start": "3835580",
    "end": "3843200"
  },
  {
    "text": "and you're thinking,\nwell, maybe I should optimize my\ninitial parameters, maybe I should optimize\nmy learning rates,",
    "start": "3843200",
    "end": "3848930"
  },
  {
    "text": "but then you're also\nchanging the model as you're going along, can\nyou use these strategies?",
    "start": "3848930",
    "end": "3855770"
  },
  {
    "text": "Or is it better to just do\nthe simple thing every time? And under what circumstances\ndo you apply learning",
    "start": "3855770",
    "end": "3863335"
  },
  {
    "text": "rates and stuff like that? Yeah, the question is when\nyou're doing model development,",
    "start": "3863335",
    "end": "3869330"
  },
  {
    "text": "does it make sense to keep your\npre-optimized learning rate",
    "start": "3869330",
    "end": "3874490"
  },
  {
    "text": "after you change the model? I think that would very\nmuch depends on how much you",
    "start": "3874490",
    "end": "3881150"
  },
  {
    "text": "change the model. If you don't change\nit by that much, I'd assume that the\noptimal hyper-parameters are quite similar.",
    "start": "3881150",
    "end": "3887520"
  },
  {
    "text": "So using the previous solution\nas like maybe the initial thing for your hyper-parameter\noptimization",
    "start": "3887520",
    "end": "3894440"
  },
  {
    "text": "can be a reasonable thing to do. If you make really big changes,\nmaybe starting from scratch",
    "start": "3894440",
    "end": "3902570"
  },
  {
    "text": "would be better. Yeah, I think it\nvery much depends on how you set things up.",
    "start": "3902570",
    "end": "3909760"
  },
  {
    "start": "3909760",
    "end": "3914000"
  }
]
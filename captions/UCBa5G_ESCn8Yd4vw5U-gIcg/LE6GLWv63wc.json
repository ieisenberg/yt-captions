[
  {
    "start": "0",
    "end": "5380"
  },
  {
    "text": "Hi, everyone. Let's get started. So we are towards the\ntail end of the course.",
    "start": "5380",
    "end": "14500"
  },
  {
    "text": "I saw some of your project\nproposals submissions, and it's looking good.",
    "start": "14500",
    "end": "19960"
  },
  {
    "text": "Keep making up the progress. Today, we are\ngoing to be talking about the human angle\nin lossy compression,",
    "start": "19960",
    "end": "26230"
  },
  {
    "text": "particularly focused on\nthe vision aspect of it. So it's another sort\nof special topic,",
    "start": "26230",
    "end": "31300"
  },
  {
    "text": "and it's going to\nbe a fun lecture. It's kind of stuff,\nwhich is typically not covered in information\ntheory, but it's still",
    "start": "31300",
    "end": "38230"
  },
  {
    "text": "finds its ways into practical\nlossy compressors and stuff. Yeah, any questions by\nthe way so far on learning",
    "start": "38230",
    "end": "46730"
  },
  {
    "text": "or logistics or anything?  Good.",
    "start": "46730",
    "end": "52010"
  },
  {
    "text": "No? OK. So yeah. So so far in lossy\ncompression, we have looked at a lot of\ndifferent things, right?",
    "start": "52010",
    "end": "57740"
  },
  {
    "text": "So we have looked\nat quantization, which is a core mechanism\nof introducing loss.",
    "start": "57740",
    "end": "62900"
  },
  {
    "text": "We have looked at third\nunderpinning of rate distortion trade-off. Homework 4 also has a\nquestion to get you warmed",
    "start": "62900",
    "end": "69560"
  },
  {
    "text": "up and practiced about it. We have spent some time\nlooking at optimal solutions in the case of Gaussian sources,\nwhich builds up our intuitions,",
    "start": "69560",
    "end": "77780"
  },
  {
    "text": "as well as particularly focusing\non MSE distortion, right? So far in the course, mostly\nwe have stuck with MSE.",
    "start": "77780",
    "end": "84860"
  },
  {
    "text": "And then we talked about image\ncompression and JPEG and learnt",
    "start": "84860",
    "end": "91040"
  },
  {
    "text": "image compression. OK? So this class is going\nto be very different.",
    "start": "91040",
    "end": "97509"
  },
  {
    "text": "So the main point is that\nall multimedia, at least eventually is consumed\nby humans, right?",
    "start": "97510",
    "end": "103510"
  },
  {
    "text": "So it's like it's for\nthe human consumption. And human sensory\nlike human senses",
    "start": "103510",
    "end": "110860"
  },
  {
    "text": "play a big role in the design\nof these lossy compressors for multimedia. And we are going to\nunderstand like what",
    "start": "110860",
    "end": "117850"
  },
  {
    "text": "properties of this sort of\nhuman sensory perception comes out and plays in\nour design of compressors.",
    "start": "117850",
    "end": "125290"
  },
  {
    "text": "So in particular, we'll\nlook at questions like, so why some of the\ndesign decisions",
    "start": "125290",
    "end": "130960"
  },
  {
    "text": "were made in the\nimage compressors we saw like JPEG in particular? Or how can we further improve\nimage video compression knowing",
    "start": "130960",
    "end": "139630"
  },
  {
    "text": "the fact that, oh, this content\nor this whatever, signal is eventually supposed\nto be consumed by us?",
    "start": "139630",
    "end": "145670"
  },
  {
    "text": "Right? And not just by machines. Finally, I think we have touched\non a little bit about it,",
    "start": "145670",
    "end": "151130"
  },
  {
    "text": "but want to just give you\nguys a flavor on like, OK, MSE is not ever encompassing, right?",
    "start": "151130",
    "end": "156700"
  },
  {
    "text": "So what are some\nother options which you might see if you\npractice compression outside?",
    "start": "156700",
    "end": "162515"
  },
  {
    "text": " OK. So this talk is derived from\nlots of great resources.",
    "start": "162515",
    "end": "168540"
  },
  {
    "text": "Feel free to check them out.  So even before we\ngo into images,",
    "start": "168540",
    "end": "174840"
  },
  {
    "text": "so this is really like-- so these are number one, OK? So what I'm showing\nhere on the right",
    "start": "174840",
    "end": "180960"
  },
  {
    "text": "is using this tool media info. And this is a compress\nPokemon theme dot MP3 file.",
    "start": "180960",
    "end": "187890"
  },
  {
    "text": "What this media info does is\nlike it tells you various stuff about this compressed files. So for example, file size,\nduration, so on and so forth.",
    "start": "187890",
    "end": "195870"
  },
  {
    "text": "Here, you see the\ncompression format is like MPEG audio, which\nis like parallel to JPEG. It's just omnipresent.",
    "start": "195870",
    "end": "202379"
  },
  {
    "text": "And then if I keep going\ndown, at some point, I see two channels,\nand I see sampling",
    "start": "202380",
    "end": "209010"
  },
  {
    "text": "rate of 44.1 kilohertz, right?",
    "start": "209010",
    "end": "214799"
  },
  {
    "text": "Why do you think like this file\nor typical audio compressors have two channels or this\nparticular sampling rate?",
    "start": "214800",
    "end": "221850"
  },
  {
    "text": " Yeah. Oh. I guess human hearing goes\nlike 20 kilohertz or so.",
    "start": "221850",
    "end": "229330"
  },
  {
    "text": "So 44 would let you-- or accurately use\nup to 22 megahertz. Yeah, so OK.",
    "start": "229330",
    "end": "235420"
  },
  {
    "text": "As an answered, like\nhe said, human hearing goes up to 20 kilohertz. That seems to give a hint.",
    "start": "235420",
    "end": "240730"
  },
  {
    "text": "That's exactly correct. So the two channels is\nbecause we have two ears. If humans had three\nears, maybe this file",
    "start": "240730",
    "end": "246452"
  },
  {
    "text": "would have been compressed\nwith three channels, and that would have\nmade better sense. So this very practical\ndesign decision, right?",
    "start": "246452",
    "end": "252520"
  },
  {
    "text": "So this like if I keep\nthis file uncompressed, you are keeping 2x the\nnumber of channels.",
    "start": "252520",
    "end": "258819"
  },
  {
    "text": "This very practical\ndesign decision was taken into account. Very simple fact. Like we have two channels. And sometimes, you want like\nstereo sound in your stuff,",
    "start": "258820",
    "end": "266930"
  },
  {
    "text": "right? So this is why two channels. And 44.1 kilohertz is\nexactly again what Sean said. So if you-- I don't\nknow-- go back",
    "start": "266930",
    "end": "273310"
  },
  {
    "text": "to your elementary\nbiology, like you might have heard that oh\nhumans can hear from 20 hertz",
    "start": "273310",
    "end": "279449"
  },
  {
    "text": "to 20 kilohertz. Though in practice, I don't know\nany human who could actually",
    "start": "279450",
    "end": "284750"
  },
  {
    "text": "hear 20 kilohertz. So if you can, that's great. And so if you know about\nNyquist criteria you would",
    "start": "284750",
    "end": "291350"
  },
  {
    "text": "you would need two times\nthe highest frequency to represent the signal\nwithout any aliasing.",
    "start": "291350",
    "end": "296840"
  },
  {
    "text": "And that's where the\n40 kilohertz come from. And then 44.1 is even more fun.",
    "start": "296840",
    "end": "302457"
  },
  {
    "text": "So you want to give\nsome buffer because you don't have perfect low pass\nfilters, which is typically required in these\nsampling techniques.",
    "start": "302458",
    "end": "308330"
  },
  {
    "text": "So you have to give\nsome buffer over 40. And then 44.1 in particular\nis very interesting",
    "start": "308330",
    "end": "314510"
  },
  {
    "text": "because it can be factorized\nby 2, I think even 3, and 5 and multiple\ndifferent primes.",
    "start": "314510",
    "end": "320270"
  },
  {
    "text": "So that allows you to later\non, downsample the signal by throwing away samples\nmuch more easily.",
    "start": "320270",
    "end": "325550"
  },
  {
    "text": "So even this innocuous,\nvery random looking number, it didn't magically come out.",
    "start": "325550",
    "end": "330800"
  },
  {
    "text": "People thought about it,\nsat down, and then like, this is now default. So almost every file, like\nyou don't think about it when",
    "start": "330800",
    "end": "337340"
  },
  {
    "text": "you are saving an MP3 file,\nbut these design decisions are there, and they are\ndetermining the file sizes,",
    "start": "337340",
    "end": "342770"
  },
  {
    "text": "right? So I could have had double\nthe sampling rate, half the sampling rate, and that\nwould have completely changed",
    "start": "342770",
    "end": "348820"
  },
  {
    "text": "my compression, and file sizes,\nand the kind of reconstructions we would have had. So very direct example of how\nhumans are playing a big role.",
    "start": "348820",
    "end": "357940"
  },
  {
    "text": "Like just the idea that\nhumans are going to consume this plays a big role. OK.",
    "start": "357940",
    "end": "363330"
  },
  {
    "text": "Then teaser number 2. I have already\nasked this question. Maybe let me ask it\nagain just, or I'll just",
    "start": "363330",
    "end": "368700"
  },
  {
    "text": "go through this fast. But this is really a\nvery iconic picture because it very clearly\nsuggests what's happening",
    "start": "368700",
    "end": "374310"
  },
  {
    "text": "in the image compression case. So here, I have\nsome source image, and all this BCDF\nimages basically",
    "start": "374310",
    "end": "382080"
  },
  {
    "text": "have the same mean squared\nerror with respect to a. But clearly, if you look\nvisually, for me at least,",
    "start": "382080",
    "end": "389790"
  },
  {
    "text": "b is much, much better\nreconstruction than any of the c, d, e, f. For example, c is like smooth,\nand e is extremely smooth.",
    "start": "389790",
    "end": "398520"
  },
  {
    "text": "d, e, and f have just clear\nnoise sprinkled over, right? So again, this clearly\nsays that not only",
    "start": "398520",
    "end": "406139"
  },
  {
    "text": "that a lot of design decisions\nwere made with humans in mind.",
    "start": "406140",
    "end": "413560"
  },
  {
    "text": "If you are not careful about\ndesigning your compressors and future, without\ntaking that into account,",
    "start": "413560",
    "end": "418870"
  },
  {
    "text": "you could have designed\na compressor, which would have resulted\nin reconstructions like this, which is just bad.",
    "start": "418870",
    "end": "424449"
  },
  {
    "text": "That's a bad design. Like nobody practically\nwould like to keep a compressor, which generates\nreconstructions like that.",
    "start": "424450",
    "end": "430780"
  },
  {
    "text": "So it's also important\nto understand really for the design, practical\ndesign of compressors.",
    "start": "430780",
    "end": "438700"
  },
  {
    "text": "OK. So rest of the\nlecture will just get some preliminary understanding\nof how human vision works.",
    "start": "438700",
    "end": "445080"
  },
  {
    "text": "We're going to focus on the\nvisual aspect of things. We're not going to\ntalk about the audio. We'll see its role in the design\nof traditional compressors,",
    "start": "445080",
    "end": "452550"
  },
  {
    "text": "learn a bit more about\nperceptual metrics, and the last part would\nbe like, how do you account for perceptual metrics\neventually in this rate",
    "start": "452550",
    "end": "459150"
  },
  {
    "text": "distortion kind of framework? So let's get started.",
    "start": "459150",
    "end": "464319"
  },
  {
    "text": "Again, it'll be fun. It's light. So it's going to be different. So do interact. Let's see how this goes.",
    "start": "464320",
    "end": "471340"
  },
  {
    "text": "So this is just like a\ntypical human eye anatomy. So here, you have some\ncornea pupil, your eyelids,",
    "start": "471340",
    "end": "479320"
  },
  {
    "text": "which basically focus\nany optical signal and to the back of your eye,\nwhich is this retina tissue.",
    "start": "479320",
    "end": "488230"
  },
  {
    "text": "Here at retina basically,\nyou have transduction, which happens, which\nconverts these light signals",
    "start": "488230",
    "end": "493720"
  },
  {
    "text": "into electricity. And finally, like\nthrough this disk-- sorry not optic disk.",
    "start": "493720",
    "end": "499330"
  },
  {
    "text": "Through your optic nerve. You send back these\nelectrical signals back to the brain, which\nthen process and makes",
    "start": "499330",
    "end": "504790"
  },
  {
    "text": "you see different things. So right here is our\nfirst thing like when",
    "start": "504790",
    "end": "511732"
  },
  {
    "text": "you have a light\nsource, which is coming. Suppose you have a light source\nwhich has a single intensity. So suppose you had a delta\nfunction in terms of pixels,",
    "start": "511732",
    "end": "519590"
  },
  {
    "text": "right? Everything is black zero,\nand then just one pixel having very high intensity.",
    "start": "519590",
    "end": "524840"
  },
  {
    "text": "When you look at\nback of the retina, it's no more a delta function.",
    "start": "524840",
    "end": "531480"
  },
  {
    "text": "What happens is that this\nline function spreads out, OK? So you have a low\npass filtering,",
    "start": "531480",
    "end": "537930"
  },
  {
    "text": "which your eye is doing right\nat the beginning just because of the physics and\noptics of things",
    "start": "537930",
    "end": "543710"
  },
  {
    "text": "even before anything\nhas happened. So this is important\nbecause this",
    "start": "543710",
    "end": "548750"
  },
  {
    "text": "kind of goes back and\ncorrelates to our fact, right? That you can throw back\nhigh frequency stuff.",
    "start": "548750",
    "end": "554060"
  },
  {
    "text": "That's because, hey, if there\nwere like many of these lines close to each other,\nI wouldn't have",
    "start": "554060",
    "end": "559280"
  },
  {
    "text": "been able to distinguish\nthem anyways. So there is no point of keeping\nextremely high frequency stuff.",
    "start": "559280",
    "end": "564829"
  },
  {
    "text": "And interestingly, like you\ncan argue like nature also has signals, which have very\nlow power in the high frequency",
    "start": "564830",
    "end": "571910"
  },
  {
    "text": "spectrum, right? And you can always\nargue like humans were designed to pick\nup signals like that",
    "start": "571910",
    "end": "578029"
  },
  {
    "text": "versus like this is just like\nthe basic optics of things, right? So it's interesting.",
    "start": "578030",
    "end": "583160"
  },
  {
    "text": "Right there, you\nhave something which you can utilize in\nyour compressors as soon as you understand\nthis very basic thing.",
    "start": "583160",
    "end": "591470"
  },
  {
    "text": "So this is a bit more detailed. Don't have to worry about it. This is just like the blown\nup part of this retina.",
    "start": "591470",
    "end": "597800"
  },
  {
    "text": "What you need to basically\nthink about is this. So suppose you're watching\nyour favorite Tom Cruise movie.",
    "start": "597800",
    "end": "605900"
  },
  {
    "text": "What happens is the light kind\nof falls in this first region, which is your photoreceptors.",
    "start": "605900",
    "end": "611450"
  },
  {
    "text": "So this is just like\nblown up part of retina. These photoreceptors are what\ntransduce this visual signal",
    "start": "611450",
    "end": "617480"
  },
  {
    "text": "into electrical signals, OK? So you have light to electrical\nconversion like the wavelengths",
    "start": "617480",
    "end": "622730"
  },
  {
    "text": "to electrical conversion. Physical property\nto the electricity. And then you have a\nlot of these neurons,",
    "start": "622730",
    "end": "628820"
  },
  {
    "text": "which are called RGCs or\nRetinal Ganglion Cells-- again, don't have to worry about\nthe names and details as long",
    "start": "628820",
    "end": "634730"
  },
  {
    "text": "as you follow\nthrough the ideas-- which are basically\nthese spiking neurons. So these issue like\nelectrical spikes,",
    "start": "634730",
    "end": "641240"
  },
  {
    "text": "which are then sent\nback to the brain, which processes these\nelectrical spikes and bring out some\nvisual picture for you",
    "start": "641240",
    "end": "647690"
  },
  {
    "text": "like whatever you are\nseeing in this real world. And so here is the second\nbig difference sort of",
    "start": "647690",
    "end": "653300"
  },
  {
    "text": "compared to how\nwe think of images versus how humans process it. So we kind of treat images\nas an array of pixels, right?",
    "start": "653300",
    "end": "662658"
  },
  {
    "text": "Like that's what you have seen. That's what you\nprobably just think. If I ask you generally\nlike sitting around,",
    "start": "662658",
    "end": "667893"
  },
  {
    "text": "like what is an image? You will probably say,\noh, three RGB values. And that's basically\nan image, right?",
    "start": "667893",
    "end": "673130"
  },
  {
    "text": "But humans are not really\nperceiving it like that. What happens in humans\nis that you basically",
    "start": "673130",
    "end": "678440"
  },
  {
    "text": "have many different kinds of\nthese retinal ganglion cells. Around 20. And each of them are\nbasically independently tiling",
    "start": "678440",
    "end": "686390"
  },
  {
    "text": "the whole screen, whole scene. So it's like think\nof this as like one",
    "start": "686390",
    "end": "691400"
  },
  {
    "text": "set of retinal ganglion cells. Yellow ones as the other. Green one as the third. Blue as the fourth, and\nso on, and so forth.",
    "start": "691400",
    "end": "697910"
  },
  {
    "text": "And you can think\nthat each of them basically sends an independent\nsignal to the visual cortex.",
    "start": "697910",
    "end": "703820"
  },
  {
    "text": "So it's like you have-- and it's debatable\na lot of things, like we don't know\nvery precisely.",
    "start": "703820",
    "end": "709279"
  },
  {
    "text": "But this is still a\nrelatively advanced field of [AUDIO OUT]\ncells are basically",
    "start": "709280",
    "end": "715040"
  },
  {
    "text": "extracting different\nfeatures of the visual scene and then sending it back\nto the brain, right?",
    "start": "715040",
    "end": "720710"
  },
  {
    "text": "So which is very different than\nhow you would think of all DC, where each pixel is\nbasically doing one thing.",
    "start": "720710",
    "end": "726259"
  },
  {
    "text": "And then you build\nmachine learning models or whatever it is to\nextract different features.",
    "start": "726260",
    "end": "731720"
  },
  {
    "text": "And humans case like\nit's like, you already have these feature extractors\nin some sense right",
    "start": "731720",
    "end": "738047"
  },
  {
    "text": "at the beginning right\nat the retina, right? And then you, on top of it,\nbuild using your visual cortex",
    "start": "738047",
    "end": "743060"
  },
  {
    "text": "like much more complicated\nassociations in your brain. So again, like the\ndifferences-- human retina",
    "start": "743060",
    "end": "751770"
  },
  {
    "text": "is not your camera. It's not just pixel array. It's doing something\nvery different. The back end.",
    "start": "751770",
    "end": "756900"
  },
  {
    "text": " In particular I think\nthese rod and cone cells--",
    "start": "756900",
    "end": "763570"
  },
  {
    "text": "like a lot of this\nis even [AUDIO OUT] GK level you might have\nheard at some point. But it's very\ninteresting because these",
    "start": "763570",
    "end": "770259"
  },
  {
    "text": "do a lot of interesting things. So these rod and cone cells are\nreally important because these",
    "start": "770260",
    "end": "778240"
  },
  {
    "text": "are our photoreceptors. These are our\nsensors this is how we are sensing the physical\nsignal coming into our eye",
    "start": "778240",
    "end": "783730"
  },
  {
    "text": "and making some\ninterpretation out of it. And these are actually\nvery, very amazing, OK?",
    "start": "783730",
    "end": "790300"
  },
  {
    "text": "So first of all rods they\nare responsible for encoding intensity.",
    "start": "790300",
    "end": "796060"
  },
  {
    "text": "So their only role\nis to figure out like, what's the intensity\nof the scene which is coming in no color\ninformation, nothing else?",
    "start": "796060",
    "end": "803200"
  },
  {
    "text": "And these are\namazing because they are like quite\n[AUDIO OUT] a number like almost a 100 million.",
    "start": "803200",
    "end": "809649"
  },
  {
    "text": "But even more than that\nthey are able to adapt so as to see almost a dynamic\nrange of 10 raise to 9.",
    "start": "809650",
    "end": "815769"
  },
  {
    "text": "Like almost a billion\norders of magnitude. What I mean by\nthat is like think. If you are a human, you can be\nsitting and outside California",
    "start": "815770",
    "end": "825110"
  },
  {
    "text": "summer weather. After a while, you can\nsee everything there. And then suddenly,\nyou have a class.",
    "start": "825110",
    "end": "830330"
  },
  {
    "text": "You rush to your class,\nand it's a dark room. OK, initially, you are\nnot able to see anything for maybe a few seconds,\nbut within a few seconds,",
    "start": "830330",
    "end": "837020"
  },
  {
    "text": "your eyes adjust. And you are able to see\neverything in this room. Now, think about what's really\nthe physical signal which",
    "start": "837020",
    "end": "844550"
  },
  {
    "text": "is coming into your eye? Right? When you are outside in\nthe sun, your intensity",
    "start": "844550",
    "end": "849680"
  },
  {
    "text": "was extremely high, right? And then everything\nelse which was happening was around this base\nlevel, whereas when",
    "start": "849680",
    "end": "856460"
  },
  {
    "text": "you came into this\ndark room, suddenly, the intensity fell\nsignificantly, right? And then you were basically\nseeing stuff around this level,",
    "start": "856460",
    "end": "864240"
  },
  {
    "text": "OK? And this is a hard problem\nif you think about it, right? Like our cameras have struggled\nto adapt to it till date.",
    "start": "864240",
    "end": "871280"
  },
  {
    "text": "Like I don't know. Iphones-- one of the\nselling point is great. Night pictures, right?",
    "start": "871280",
    "end": "876410"
  },
  {
    "text": "Like why? Because it's hard\nto detect things at that level of\nintensity level. And we, as humans,\nwe just do it,",
    "start": "876410",
    "end": "882890"
  },
  {
    "text": "and we don't even\nrealize, right? When we are doing that. And rods basically have--",
    "start": "882890",
    "end": "887930"
  },
  {
    "text": "they are the contributors. Their only role is to\nadapt to intensity figure out, and change sort of like\nthe base level around which they",
    "start": "887930",
    "end": "896540"
  },
  {
    "text": "are going to see\nthe fluctuations and see things around you, OK?",
    "start": "896540",
    "end": "903200"
  },
  {
    "text": "And another very\ninteresting thing about rods is so if you look at\nthis diagram here,",
    "start": "903200",
    "end": "912630"
  },
  {
    "text": "you can think of your eye\nas like a spherical surface, right? And then there are--",
    "start": "912630",
    "end": "918410"
  },
  {
    "text": "you can put angles to the retina\nof where things are happening. And very interestingly,\nyou have some optic nerve,",
    "start": "918410",
    "end": "925320"
  },
  {
    "text": "which is sending signals\nback to the brain, but where this\noptic nerve connect? You don't have any sensors.",
    "start": "925320",
    "end": "931110"
  },
  {
    "text": "You don't have any retina. So whatever faults and\nsort of this region, you can't detect it.",
    "start": "931110",
    "end": "936720"
  },
  {
    "text": "And it's like a fun exercise\nif you want to do that. I don't know. I find it fun. You just focus on your thumb,\nand you keep seeing straight,",
    "start": "936720",
    "end": "945210"
  },
  {
    "text": "and keep moving your thumb. So I can see my thumb. I can see my thumb.",
    "start": "945210",
    "end": "950490"
  },
  {
    "text": "I can see my thumb. I can see my thumb. It just vanishes for me,\nand then it comes back.",
    "start": "950490",
    "end": "956220"
  },
  {
    "text": "You can try it now. Try it at home. That's like a consequence\nof having this blind spot",
    "start": "956220",
    "end": "961440"
  },
  {
    "text": "basically that at\na certain angle, I just have this\nblind spot, where I can't see because\nall the light there is",
    "start": "961440",
    "end": "968310"
  },
  {
    "text": "being focused in this region. But even more interesting than\nthat-- so here is like y-axis",
    "start": "968310",
    "end": "975050"
  },
  {
    "text": "shows the density\nof these receptors. So you can think\nof how many sensors you have in that region.",
    "start": "975050",
    "end": "981260"
  },
  {
    "text": "If you look at the\nsolid line, the rods, so they are present almost\neverywhere in the retina",
    "start": "981260",
    "end": "987830"
  },
  {
    "text": "except like this region, which\nis your blind spot like around, whatever, 20 degrees.",
    "start": "987830",
    "end": "994610"
  },
  {
    "text": "The other cell type which are\ncalled cones on the other hand, if you see their density--",
    "start": "994610",
    "end": "1000820"
  },
  {
    "text": "cones are basically not present\nalmost in whole of retina except near this almost\nzero degree angle, OK?",
    "start": "1000820",
    "end": "1009530"
  },
  {
    "text": "And the role of cones is\nexactly opposite to rods. So rods are just\nbasically trying",
    "start": "1009530",
    "end": "1015380"
  },
  {
    "text": "to understand the intensity. It's giving you\nthe dynamic range. Cones are responsible\nfor colors and details",
    "start": "1015380",
    "end": "1021410"
  },
  {
    "text": "and all those things, right? And they are completely\nabsent in the retina except for maybe a very small\npart of your central vision.",
    "start": "1021410",
    "end": "1028160"
  },
  {
    "text": " Right? And the central part is\ncalled basically fovea.",
    "start": "1028160",
    "end": "1036020"
  },
  {
    "text": "Again, why is this interesting? So if you think\nabout it, if we only",
    "start": "1036020",
    "end": "1042169"
  },
  {
    "text": "have high acuity\nor high resolution vision in such a small part\nlike if you think about it--",
    "start": "1042170",
    "end": "1048500"
  },
  {
    "text": "this is just like a few angles. You can convert it\ninto physical angles. It's like really small region\nof the physical world, which",
    "start": "1048500",
    "end": "1054950"
  },
  {
    "text": "you are sampling with sort\nof this high fidelity.",
    "start": "1054950",
    "end": "1060529"
  },
  {
    "text": "Like other places, you are just\nencoding like a grayscale kind of level to get adjusted.",
    "start": "1060530",
    "end": "1065735"
  },
  {
    "text": " So then how am I able to\nsee this sort of scene",
    "start": "1065735",
    "end": "1071750"
  },
  {
    "text": "in a very smooth\nand nice fashion? Right? That's an interesting\nquestion to maybe think about.",
    "start": "1071750",
    "end": "1078410"
  },
  {
    "text": "And the reason for\nthat is we are actually never seeing any static scene.",
    "start": "1078410",
    "end": "1085900"
  },
  {
    "text": "So when you think you\nare like just looking and you are seeing an image,\nthat's not really true.",
    "start": "1085900",
    "end": "1091120"
  },
  {
    "text": "You are actually\nnot seeing an image. At any given point,\nyou are seeing a video, and your eye is not really\nfocusing at one point.",
    "start": "1091120",
    "end": "1097720"
  },
  {
    "text": "What it's doing is\nyour eye ball really-- it's not eyeball.",
    "start": "1097720",
    "end": "1102860"
  },
  {
    "text": "Sorry. The eye in general. Like it's doing these\nmovements called saccadic movements,\nwhich is just basically--",
    "start": "1102860",
    "end": "1109660"
  },
  {
    "text": "it's moving really fast. You don't even know, but\nit's continuously doing this. The reason it's moving this\nfast and it's doing this",
    "start": "1109660",
    "end": "1117110"
  },
  {
    "text": "is to basically keep\nchanging the point of the physical\nscene, which points to my central region, my fovea.",
    "start": "1117110",
    "end": "1125450"
  },
  {
    "text": "So think of it. It's like there's a very small\npoint at the center, where you have high resolution.",
    "start": "1125450",
    "end": "1132080"
  },
  {
    "text": "Everything around it\nis low resolution, OK? So when I'm looking\nat this scene, if I just do this, if I just--",
    "start": "1132080",
    "end": "1138320"
  },
  {
    "text": "I don't know. Right now, I'm just\ncompletely focusing on clock. And actually, all of your\nfaces all of this thing",
    "start": "1138320",
    "end": "1143960"
  },
  {
    "text": "has really vanished for me. I can't see it if I very\nconsciously focus, right? But if I'm being subconscious,\nI'm not consciously",
    "start": "1143960",
    "end": "1150710"
  },
  {
    "text": "putting my eye to say, OK,\njust look at one point, what my eye really is doing\nit's sampling this region,",
    "start": "1150710",
    "end": "1155914"
  },
  {
    "text": "but it's not staying there. It's like my microcircuits\nare in like milliseconds case. It's basically just continuously\nmoving and sampling.",
    "start": "1155915",
    "end": "1162560"
  },
  {
    "text": "And then your brain is\ninterpolating all this signal to form this continuous kind of\nsmooth looking picture, right?",
    "start": "1162560",
    "end": "1172340"
  },
  {
    "text": "So again, like a\nlot of fun facts. This class is going to be\na lot of things like that.",
    "start": "1172340",
    "end": "1178510"
  },
  {
    "text": "So yeah, so it's pretty cool. Like when I first learned\nabout it, it was amazing. Like my eyes are not\nstaying at the same spot.",
    "start": "1178510",
    "end": "1186059"
  },
  {
    "text": "But now, you can\nbe like, Pulkit, why are you talking about this? Right? Like there are so\nmany GK questions.",
    "start": "1186060",
    "end": "1192030"
  },
  {
    "text": "You can do so many\nthings this idea that you have very high density\nsensors in a single place.",
    "start": "1192030",
    "end": "1199710"
  },
  {
    "text": "It's actually called foveation. And it can be exploited in\nsome very interesting ways",
    "start": "1199710",
    "end": "1210090"
  },
  {
    "text": "in your design of\nphysical sensors and how you do compression, OK? So for example, what it\nsays is that at any given",
    "start": "1210090",
    "end": "1217950"
  },
  {
    "text": "point of time, I'm only sampling\na small region in high density. So then it makes me think,\nmaybe, we can exploit",
    "start": "1217950",
    "end": "1226350"
  },
  {
    "text": "this in some way, right? Maybe, if I am able to track\nhuman vision let's say,",
    "start": "1226350",
    "end": "1231929"
  },
  {
    "text": "then I can. If I know, right? OK. At this particular second,\nI'm just looking here. Let's say next second,\nI'm looking here.",
    "start": "1231930",
    "end": "1238529"
  },
  {
    "text": "And if I can work at this\nlatency and just track, my human eye is going\nto look more densely",
    "start": "1238530",
    "end": "1244080"
  },
  {
    "text": "at a particular\npart of a scene when you are watching your favorite\nmovie or anything it is. Then I don't need to give too\nmany bits to everything else,",
    "start": "1244080",
    "end": "1251350"
  },
  {
    "text": "right? I can just give more\nrate to wherever my humans are focusing. And I can give zero\nrate to things outside.",
    "start": "1251350",
    "end": "1258510"
  },
  {
    "text": "And this may sound very sci-fi,\nbut over the past few years, there have been like lots\nof interest and research",
    "start": "1258510",
    "end": "1264690"
  },
  {
    "text": "projects trying to exploit\nexactly this idea in the VR setting. So right now, we are only\nfocused on 2D setting,",
    "start": "1264690",
    "end": "1270540"
  },
  {
    "text": "but now, you can think\nif you have a VR headset, maybe we can do something\nto actually track where humans are looking.",
    "start": "1270540",
    "end": "1276000"
  },
  {
    "text": "And maybe, we can\nfigure out like how to distribute bit rates\nbecause in VR, you now have a 3D environment, right?",
    "start": "1276000",
    "end": "1282120"
  },
  {
    "text": "You don't want to\ngive equal bits to everything on the periphery. So the kind of things\nwhich we are learning also",
    "start": "1282120",
    "end": "1288990"
  },
  {
    "text": "have implications for\nfuture technology, right? It's not just things\nwhich we have right now. Like lots of cool projects\nalong this basic idea.",
    "start": "1288990",
    "end": "1296460"
  },
  {
    "text": " Yeah, I think we talked\nabout the first one just",
    "start": "1296460",
    "end": "1304519"
  },
  {
    "text": "like [AUDIO OUT] if you\nhave seen this before. So the adaptation aspect of\nhuman eyes-- it's basically",
    "start": "1304520",
    "end": "1310309"
  },
  {
    "text": "called Weber's Law, which\nbasically says that we only care about relative changes, not\nthe absolute value of changes.",
    "start": "1310310",
    "end": "1318920"
  },
  {
    "text": "Again, very small point\nbut it's very interesting how you can exploit it\nin your signal processing and freshened aspects.",
    "start": "1318920",
    "end": "1325520"
  },
  {
    "text": "What it says basically\nis like a bit change at a high value of\nluminance value would not",
    "start": "1325520",
    "end": "1332780"
  },
  {
    "text": "really-- it won't be as significant\nas a single bit change",
    "start": "1332780",
    "end": "1338570"
  },
  {
    "text": "at a low luminance value, right? Even though it's\nexactly one bit change.",
    "start": "1338570",
    "end": "1344820"
  },
  {
    "text": "So you need to be\ncareful about when assigning like rate\nand all those things in these situations,\nor maybe you",
    "start": "1344820",
    "end": "1350190"
  },
  {
    "text": "are uniformly\nassigning the rate. In that case, you may\nhave different artifacts, which might be visible to you\njust because those artifacts",
    "start": "1350190",
    "end": "1357540"
  },
  {
    "text": "are occurring in\nlike low intensity region versus the\nhigh intensity region.",
    "start": "1357540",
    "end": "1363340"
  },
  {
    "text": "Yeah, again, this\naspect, maybe it wasn't so important\n20 years ago, but we are in a world where\nwe have 4k TVS, HD, 4K.",
    "start": "1363340",
    "end": "1371880"
  },
  {
    "text": "Like I'm pretty sure\nwe are not going to stop there if we\ncan fit all that data and be able to process as we\nwant like million more pixels",
    "start": "1371880",
    "end": "1380130"
  },
  {
    "text": "in our cameras, like million\nmore pixels in our TV, right? And at even 4K, HD level\nlike all of these effects",
    "start": "1380130",
    "end": "1387630"
  },
  {
    "text": "starts becoming\nvery significant. And like the big companies\nspending big money trying to understand these issues and\nimprove upon them because it's",
    "start": "1387630",
    "end": "1394740"
  },
  {
    "text": "like straightforward\nmoney, right? Each bit saved or\nyour user experience. So simple idea but can be\nexploited in interesting ways",
    "start": "1394740",
    "end": "1403210"
  },
  {
    "text": "in engineering setting. ",
    "start": "1403210",
    "end": "1408650"
  },
  {
    "text": "OK. I'll pause for a second. Any questions? ",
    "start": "1408650",
    "end": "1414760"
  },
  {
    "text": "Nope. All right. So the next thing\nis-- so we were just talking about cones,\nwhich look at colors.",
    "start": "1414760",
    "end": "1422640"
  },
  {
    "text": "What this plot shows\nis on the x-axis? It's the wavelength\nwhich is how light",
    "start": "1422640",
    "end": "1428160"
  },
  {
    "text": "is sort of colors are\nrepresented physically, right? Colors are just\ndifferent wavelengths.",
    "start": "1428160",
    "end": "1433230"
  },
  {
    "text": "So 400 to 700 nanometer is\nroughly a visible range. 350 to 700, I think.",
    "start": "1433230",
    "end": "1438690"
  },
  {
    "text": "And then y-axis is\nbasically the response for these cones at different\nlevels of wavelength.",
    "start": "1438690",
    "end": "1447870"
  },
  {
    "text": "So think of these as sensors. These different sensors\nrespond differently to different wavelengths, OK?",
    "start": "1447870",
    "end": "1454420"
  },
  {
    "text": "And then what you\nsee is that you [AUDIO OUT],, which\nbasically respond to roughly like the-- it's\nnot really [AUDIO OUT]..",
    "start": "1454420",
    "end": "1460390"
  },
  {
    "text": "It's something, but\nit's roughly responding to the average wavelength\nin the visible spectrum,",
    "start": "1460390",
    "end": "1466570"
  },
  {
    "text": "but then you actually\nhave three cones. And these three cones\nare sometimes called LMS.",
    "start": "1466570",
    "end": "1472419"
  },
  {
    "text": "This long, medium, small. Long for like long wavelength. Medium is for medium wavelength.",
    "start": "1472420",
    "end": "1478060"
  },
  {
    "text": "Small is for small wavelength. So that's the [AUDIO OUT]\nneuro terminology for these.",
    "start": "1478060",
    "end": "1484794"
  },
  {
    "text": "Now, why do you think\n[AUDIO OUT] three cones? Right? Do you think that makes sense?",
    "start": "1484795",
    "end": "1491570"
  },
  {
    "text": "Is that something confusing? The answer is on this\nslide by the way.",
    "start": "1491570",
    "end": "1496880"
  },
  {
    "text": "Don't even have to\nthink that much. ",
    "start": "1496880",
    "end": "1502110"
  },
  {
    "text": "So I'm sure at some point,\nyou would have wondered, oh, why RGB? Where did this RGB\nthing came from?",
    "start": "1502110",
    "end": "1507960"
  },
  {
    "text": "At least, I used to\nwonder quite a lot. Like why RGB? Why are we stuck with\nthese three colors?",
    "start": "1507960",
    "end": "1513570"
  },
  {
    "text": "And that actually comes\ndown because your physical, like your human retinal\nsensors cones actually come",
    "start": "1513570",
    "end": "1520590"
  },
  {
    "text": "in three flavors. And they are roughly sampling\nthe red color, the green color, and the blue color.",
    "start": "1520590",
    "end": "1526320"
  },
  {
    "text": "And that's why like\nRGB is one of the ways you would like to\nrepresent because back",
    "start": "1526320",
    "end": "1531330"
  },
  {
    "text": "in 1700s, a lot of philosophers,\nwhere you couldn't actually do these experiments through\nother psychovisual experiments.",
    "start": "1531330",
    "end": "1539760"
  },
  {
    "text": "Figured out that,\nOK, maybe RGB seems to have some special\nspace place in our vision.",
    "start": "1539760",
    "end": "1547710"
  },
  {
    "text": "And that basically later on, in\nneuroscience, would figure out. You could even figure out\nlike their exact response",
    "start": "1547710",
    "end": "1553620"
  },
  {
    "text": "characteristics, so\non, and so forth. So again, like even\nsomething like RGB has--",
    "start": "1553620",
    "end": "1559408"
  },
  {
    "text": "it's actually other way around. Like RGB doesn't come from here. Since we have these\nthings, that's why RGB has found like\na special kind of place",
    "start": "1559408",
    "end": "1567250"
  },
  {
    "text": "in our thinking\nabout visual images. ",
    "start": "1567250",
    "end": "1573170"
  },
  {
    "text": "And so this color model-- this is also sometimes\ncalled trichromatic theory",
    "start": "1573170",
    "end": "1580009"
  },
  {
    "text": "of color vision. So fancy name but just\nEnglish trichromatic theory.",
    "start": "1580010",
    "end": "1587340"
  },
  {
    "text": "But interestingly,\ntrichromatic theory is not the only theory\nof colors, right?",
    "start": "1587340",
    "end": "1595110"
  },
  {
    "text": "Some point, you might have-- so these are two physical\ncolors, which are exactly same.",
    "start": "1595110",
    "end": "1600179"
  },
  {
    "text": "I could have\nrepresented this as RGB. Like some different\nvalues of RGB, which gives me a\ncertain color, or maybe",
    "start": "1600180",
    "end": "1606690"
  },
  {
    "text": "you have a color\nspace called CMYK. Probably not. So this used to be used\nin old school printers",
    "start": "1606690",
    "end": "1613049"
  },
  {
    "text": "with toners, where-- so RGB is like an\nadditive color space where, oh, I add that,\nI add G, I get a color.",
    "start": "1613050",
    "end": "1619950"
  },
  {
    "text": "In this case, like these\nvalues of RGB gives this color, but I can also think of it\nas like CMYK, which are sort",
    "start": "1619950",
    "end": "1626520"
  },
  {
    "text": "of like subtractive colors. So when you add CM and\nY, you get like a black. So it's like removing sort of\nthing, but it's the same color.",
    "start": "1626520",
    "end": "1634020"
  },
  {
    "text": "So nobody said like,\noh, I need to represent this as just this RGB. I could have represented\nthis as CMYK.",
    "start": "1634020",
    "end": "1640860"
  },
  {
    "text": "And actually, on D, right? What I'm showing\nis this is actually a very complicated and not\nso obvious and confusing",
    "start": "1640860",
    "end": "1649149"
  },
  {
    "text": "topic for engineers. Like where does these\nthings come from? But actually, there have\nbeen a lot and a lot",
    "start": "1649150",
    "end": "1655600"
  },
  {
    "text": "and a lot of studies on like\nhow colors are represented, not just at the neuro\nor engineering level,",
    "start": "1655600",
    "end": "1661150"
  },
  {
    "text": "but actually, at the\npsychovisual level. So at the end of\nthe day, this is like a psychophysics\nexperiment, right?",
    "start": "1661150",
    "end": "1666970"
  },
  {
    "text": "Like what colors do you see? How can I represent\nthe same color? And there have been\ntons and tons and tons",
    "start": "1666970",
    "end": "1673600"
  },
  {
    "text": "like philosophers all\nthe way back, I think, and starting from 1700s. People have been\nasking these questions",
    "start": "1673600",
    "end": "1680500"
  },
  {
    "text": "trying to understand them in\ndeeper and deeper details. And this is something\nwhich you might",
    "start": "1680500",
    "end": "1685779"
  },
  {
    "text": "hear if you work in image\ncompression, video compression at some point. So the CIE-- it's\nlike just a society--",
    "start": "1685780",
    "end": "1694059"
  },
  {
    "text": "In 1931, came up with something\ncalled chromaticity diagram. So again, chroma for color.",
    "start": "1694060",
    "end": "1699789"
  },
  {
    "text": "And it basically looks like\n2D space to represent colors.",
    "start": "1699790",
    "end": "1707250"
  },
  {
    "text": "And what you have is\nlike different standards and companies, et cetera, have\nadopted very different color",
    "start": "1707250",
    "end": "1713549"
  },
  {
    "text": "spaces. So you have RGB,\nwhich we know of. There is something called SRG.",
    "start": "1713550",
    "end": "1719290"
  },
  {
    "text": "OK. So first of all,\nthere is something called visible spectrum. Like so invisibly, we can\nonly see these colors.",
    "start": "1719290",
    "end": "1725640"
  },
  {
    "text": "So this has a weird space. I'm not going to go\ninto details of why, but if you are interested,\ncome talk to me later.",
    "start": "1725640",
    "end": "1733060"
  },
  {
    "text": "But yeah, so the\nyellow one is the set of colors, which your\nhuman eye can see, OK?",
    "start": "1733060",
    "end": "1739700"
  },
  {
    "text": "And then in practice,\nyou actually can't represent those many\ncolors in the same way",
    "start": "1739700",
    "end": "1745100"
  },
  {
    "text": "as you would like to. So historically, people\ncame up with RGB, then there is SRGB, which\nis this black curve here.",
    "start": "1745100",
    "end": "1753740"
  },
  {
    "text": "Adobe had an RGB, which is like\nAdobe RGB, which is this one. So Adobe basically came up\nwith its own RGB standard.",
    "start": "1753740",
    "end": "1761890"
  },
  {
    "text": "Now, you should\nask like, OK, why am I talking about\nthese standards? Right? The reason is there's\n224, 102, 102, right?",
    "start": "1761890",
    "end": "1771580"
  },
  {
    "text": "We simplified our\ndiscussion of images, and we just said, oh, it's\nlike 3 bytes per pixel, which responds to one color.",
    "start": "1771580",
    "end": "1778630"
  },
  {
    "text": "But that's not true. At the end of the day,\nthese digital values are converted into physical\nsignals using your monitor.",
    "start": "1778630",
    "end": "1784570"
  },
  {
    "text": "Maybe, they are printed\nusing your printer. Maybe the actual-- your\ncamera, when it was recording,",
    "start": "1784570",
    "end": "1791830"
  },
  {
    "text": "it was converting this physical\nsignal to this RGB values. And all of this sort\nof depends on what's",
    "start": "1791830",
    "end": "1797410"
  },
  {
    "text": "the color space, right? Like so for example, if a\ndisplay has a different color space, then whatever\nit was recorded with,",
    "start": "1797410",
    "end": "1803470"
  },
  {
    "text": "you will get very\ndifferent reconstruction. And that's important\nfor us because that",
    "start": "1803470",
    "end": "1809350"
  },
  {
    "text": "changes the distortion\ncompletely, right? So you might have to\nthink about these things. And again, it might seem like,\nhey, we never think about it.",
    "start": "1809350",
    "end": "1817600"
  },
  {
    "text": "Do it, but it's\nactually very common. And you have some\nvery interesting bugs",
    "start": "1817600",
    "end": "1823427"
  },
  {
    "text": "which come up if you were\ndoing video compression, image compression, if you are not\nbeing careful about these very small things because like\njust different data recorded",
    "start": "1823427",
    "end": "1831470"
  },
  {
    "text": "in different way. Displayed in different way. And you'll be thinking, why is\nmy Huffman encoder not working",
    "start": "1831470",
    "end": "1838032"
  },
  {
    "text": "or whatever else? The variant not\nworking, but it will be this color space issue,\nwhich you might be sitting with.",
    "start": "1838032",
    "end": "1843280"
  },
  {
    "text": "So it's just important to\nknow that these things exist and do play a role. ",
    "start": "1843280",
    "end": "1849730"
  },
  {
    "text": "OK. So this is going to be fun. So let's talk a little bit more.",
    "start": "1849730",
    "end": "1855299"
  },
  {
    "text": "Let's do this.  By the way, yeah, actually,\njust a quick show of hands.",
    "start": "1855300",
    "end": "1861600"
  },
  {
    "text": "This dress I think blew up\nsometime last year or the year before. How many of you see this\nas a gold and white?",
    "start": "1861600",
    "end": "1869145"
  },
  {
    "text": " Oh. OK.",
    "start": "1869145",
    "end": "1874149"
  },
  {
    "text": "What do you see it as? Let me ask. I forgot what's-- Blue and black. Blue and black. Excellent. So OK.",
    "start": "1874150",
    "end": "1879420"
  },
  {
    "text": "How many of you see\nit as blue and black? Why is it happening? It's the same RGB values\nI'm showing here, right?",
    "start": "1879420",
    "end": "1886810"
  },
  {
    "text": "So right there. It's very interesting,\nand we'll motivate this for the next thing.",
    "start": "1886810",
    "end": "1892480"
  },
  {
    "text": "But even before that, let's do\nthis quick experiment, I think.",
    "start": "1892480",
    "end": "1897700"
  },
  {
    "text": "Oh. Yeah, it loaded. OK. So what I want you\nguys to do is-- OK, first of all,\nwhat do you see here?",
    "start": "1897700",
    "end": "1903400"
  },
  {
    "text": "Don't focus anything. Just look around. What do you see? Anyone?",
    "start": "1903400",
    "end": "1909730"
  },
  {
    "text": "Well, see something. ",
    "start": "1909730",
    "end": "1915040"
  },
  {
    "text": "OK. Do you see a vanishing\npurple circle sort of, right? OK. Now, focus on the x.",
    "start": "1915040",
    "end": "1920590"
  },
  {
    "text": "Just on the x. I just want you\nto focus on the x. ",
    "start": "1920590",
    "end": "1925608"
  },
  {
    "text": "And if this is going to\nwork in this room or not, let me also come here. Oh, what happened? ",
    "start": "1925608",
    "end": "1933970"
  },
  {
    "text": "You see a yellow dot? OK. And anyone else?",
    "start": "1933970",
    "end": "1939250"
  },
  {
    "text": "For a second, I saw a whole\ncircle of yellow dots. You saw a couple of yellow dots?",
    "start": "1939250",
    "end": "1944510"
  },
  {
    "text": "It's interesting. I would have called that color\ngreen, but maybe it's yellow. ",
    "start": "1944510",
    "end": "1951149"
  },
  {
    "text": "[AUDIO OUT] Yeah, it's like\ngreenish yellow, right? So if you keep focusing on\nthat x, the vanishing one,",
    "start": "1951150",
    "end": "1956809"
  },
  {
    "text": "suddenly, becomes like\na greenish yellow color. Like again, it's\nnot your vision.",
    "start": "1956810",
    "end": "1963340"
  },
  {
    "text": "It's nothing wrong\nwith your eyes. You don't have to go get\nnew glasses after this.",
    "start": "1963340",
    "end": "1970299"
  },
  {
    "text": "It's a known effect. And that happens because-- so we talked about the\ntrichromatic theory of color,",
    "start": "1970300",
    "end": "1976630"
  },
  {
    "text": "but there is another theory\nof color, which is basically called this opponent process\ntheory of color vision, OK?",
    "start": "1976630",
    "end": "1985600"
  },
  {
    "text": "Which basically said that\nthere are pairs of colors which are negatives of each other. So the effect, by the way, which\nI showed you in the last slide,",
    "start": "1985600",
    "end": "1992410"
  },
  {
    "text": "it's called the\nafter images effect, which is like if you\nfocus on one color, it's like your eyes are adapting\nto subtract that color out.",
    "start": "1992410",
    "end": "2000299"
  },
  {
    "text": "So suddenly, when you\nlook at somewhere else-- oh, sorry. Your mean color is\nsomewhat very different.",
    "start": "2000300",
    "end": "2006480"
  },
  {
    "text": "And so that white space in that\nprevious lilac chaser example suddenly becomes like negative\nof red, which is what you saw.",
    "start": "2006480",
    "end": "2014220"
  },
  {
    "text": "Like not really negative\nof red, but which is that yellow green\nwhatever color you guys want",
    "start": "2014220",
    "end": "2019470"
  },
  {
    "text": "to call it, right? So that's like again,\na very basic aspect",
    "start": "2019470",
    "end": "2025540"
  },
  {
    "text": "of how our human vision works. And that's the sort of\norigin of this YUV thing,",
    "start": "2025540",
    "end": "2033630"
  },
  {
    "text": "which we have talked about\nin the class before, right? Like we had this random color\ntransform, which we said,",
    "start": "2033630",
    "end": "2039179"
  },
  {
    "text": "OK, let's do YUV. We are not going\nto work with RGB. And I said, OK, later on, we'll\ntalk about a little bit more",
    "start": "2039180",
    "end": "2045179"
  },
  {
    "text": "about this. And it's basically this\ntheory of color vision, which",
    "start": "2045180",
    "end": "2054460"
  },
  {
    "text": "suggests the idea of this\nopponent colors, which basically says that,\noh, maybe, we have",
    "start": "2054460",
    "end": "2059888"
  },
  {
    "text": "this blue, green and red cones. The way humans perceive it is\nactually not these signals,",
    "start": "2059889",
    "end": "2066040"
  },
  {
    "text": "but you merge them. You merge them in\na sense, where you get this white and black signal,\nwhich is basically somewhat",
    "start": "2066040",
    "end": "2072399"
  },
  {
    "text": "summation and addition of\nall these three wavelengths by this presence of all these\nthree black is subtraction.",
    "start": "2072400",
    "end": "2077560"
  },
  {
    "text": "Then you have a blue yellow. And then you have a red\ngreen opponent colors.",
    "start": "2077560",
    "end": "2084000"
  },
  {
    "text": "And it's debatable. There have been lots lots and\nlots of empirical evidence",
    "start": "2084000",
    "end": "2090330"
  },
  {
    "text": "on all sorts of access. We haven't really finalized\non what is correct, but it's like even\nvery recently,",
    "start": "2090330",
    "end": "2097650"
  },
  {
    "text": "I think 2019 or [AUDIO OUT]. There have been papers that\nsay, hey, this theory is wrong, or this is right. Like there is more evidence.",
    "start": "2097650",
    "end": "2104220"
  },
  {
    "text": "And this has been going\non since I think 1800s. So it's very interesting. But for better or worse,\nwe are stuck with this.",
    "start": "2104220",
    "end": "2112230"
  },
  {
    "text": "And we have this shows up in\nour engineering applications all the time.",
    "start": "2112230",
    "end": "2117319"
  },
  {
    "text": "So again, I just recall our\nimage JPEG compression, right? So we started with RGB.",
    "start": "2117320",
    "end": "2122800"
  },
  {
    "text": "And the first step was\n[AUDIO OUT] transformation. And then we also\nbriefly touched upon that we are going to downsample\nthe CBCR components or UV",
    "start": "2122800",
    "end": "2131410"
  },
  {
    "text": "components. And then [AUDIO OUT]\nstandard thing.",
    "start": "2131410",
    "end": "2138720"
  },
  {
    "text": "Now, we can understand\nthis better. So why CBCR or UV? Like all of them are\nconsider them equivalent.",
    "start": "2138720",
    "end": "2146408"
  },
  {
    "text": "Like they have some\nhistorical differences. But for today's class,\nassume by YUV, YCBCR.",
    "start": "2146408",
    "end": "2151770"
  },
  {
    "text": "Sometimes, you'll see\nstar marks on top of it. Like literally\nlike this CD star. CR.",
    "start": "2151770",
    "end": "2156780"
  },
  {
    "text": "Oh, yeah. Here. Sorry. Y-UV. Sometimes, you will\nsee Y-UV, Y-CBCR.",
    "start": "2156780",
    "end": "2162539"
  },
  {
    "text": "Consider all of\nthem equal for now. There are slight nuances and\ndifferences, which we can talk.",
    "start": "2162540",
    "end": "2168330"
  },
  {
    "text": "But the main reason for\nmaybe, if we think about CBCR, it's very obvious. Why going for the\nLuma component.",
    "start": "2168330",
    "end": "2176400"
  },
  {
    "text": "CB is going for\nthis blue yellow, and CR is sort of going\nfor this red green, right?",
    "start": "2176400",
    "end": "2181740"
  },
  {
    "text": "So that's kind of\nmodeling the human vision. And that's why we\nare splitting it in these three\nindependent channels",
    "start": "2181740",
    "end": "2187698"
  },
  {
    "text": "because that's what we think\nour eye sort of works with. And so again, if\nyou have this image,",
    "start": "2187698",
    "end": "2193410"
  },
  {
    "text": "this is how your YCB\nand CR might look like. And we said that these still\nhave a lot of correlation,",
    "start": "2193410",
    "end": "2199595"
  },
  {
    "text": "right?  So OK.",
    "start": "2199595",
    "end": "2205000"
  },
  {
    "text": "So this explains why we did the\ncolor transformation from RGB to YCBCR.",
    "start": "2205000",
    "end": "2210849"
  },
  {
    "text": "But if you recall, we also\ntalked about downsampling, right? And then I said\nsomething that, oh, like you actually downsample\nthe colored components more",
    "start": "2210850",
    "end": "2218500"
  },
  {
    "text": "than the luma ones\nbecause we care more about the average intensity\nthan the everything else.",
    "start": "2218500",
    "end": "2223720"
  },
  {
    "text": "So that's the other reason\nfor actually even converting your RGB signal into these\nthree independent channels",
    "start": "2223720",
    "end": "2230993"
  },
  {
    "text": "because these three\nindependent channels are behaving differently. You care more about Y than CBCR.",
    "start": "2230993",
    "end": "2236500"
  },
  {
    "text": "And that again, comes from\nhuman [AUDIO OUT],, OK? So really the two reasons for\ndoing this color transformation",
    "start": "2236500",
    "end": "2243940"
  },
  {
    "text": "is one is like the\nperceptual color space based on this idea\nof opponent theory",
    "start": "2243940",
    "end": "2250000"
  },
  {
    "text": "like that lilac chaser\nor that dress thing. And the second main idea is\nthat you have different contrast",
    "start": "2250000",
    "end": "2256359"
  },
  {
    "text": "sensitivity for your color\nchannels versus luma channels. If you haven't\nheard this before,",
    "start": "2256360",
    "end": "2262270"
  },
  {
    "text": "let me just explain\nthe idea very quickly. What your contrast\nsensitivity say is this is like similar\nto saying humans",
    "start": "2262270",
    "end": "2267940"
  },
  {
    "text": "can hear 20 hertz\nto 20 kilohertz. Similarly, there are\ncertain spatial frequencies",
    "start": "2267940",
    "end": "2275920"
  },
  {
    "text": "and certain contrasts. So you can think of contrast\njust as the variance",
    "start": "2275920",
    "end": "2282220"
  },
  {
    "text": "around that point. Like how much the\nlevel shifts when you change 1 byte versus\n2 byte versus 4 bytes.",
    "start": "2282220",
    "end": "2289420"
  },
  {
    "text": "You are changing different\nlevels of intensity. And so your contrast\nreally is like a function",
    "start": "2289420",
    "end": "2297240"
  },
  {
    "text": "of your contrast plus\nspatial frequency. So what I have\nhere in this image is there are bars with\nincreasing and increasing",
    "start": "2297240",
    "end": "2304410"
  },
  {
    "text": "spatial frequency, OK? And as you go down, I\nhave higher differentials",
    "start": "2304410",
    "end": "2310809"
  },
  {
    "text": "between these bars. Binary bars. For me, I can make out like\nbars maybe in this region.",
    "start": "2310810",
    "end": "2318110"
  },
  {
    "text": "This red line is supposed to\nbe for a typical human, average human. Everything within\nit-- you should",
    "start": "2318110",
    "end": "2323720"
  },
  {
    "text": "be able to distinguish as like\nsome lines versus around here. You should sort of\nsee it as a gray area.",
    "start": "2323720",
    "end": "2330528"
  },
  {
    "text": "Now, for different people,\nit might be different. For example for me,\nI actually think can't see any of this region.",
    "start": "2330528",
    "end": "2336290"
  },
  {
    "text": "Can't see this region. So my eyes are not\nperfect, right? So like you have this\ndifferent contrast sensitivity.",
    "start": "2336290",
    "end": "2345790"
  },
  {
    "text": "And this is important\nbecause again, what this tells is like whether\nyou can distinguish two signals",
    "start": "2345790",
    "end": "2352480"
  },
  {
    "text": "or not occurring at different\nspatial frequencies. Why do you care about this?",
    "start": "2352480",
    "end": "2358010"
  },
  {
    "text": "Can somebody think\nabout why would I care about this for\ndesigning compressors?",
    "start": "2358010",
    "end": "2364220"
  },
  {
    "start": "2364220",
    "end": "2369910"
  },
  {
    "text": "Anyone? Not that hard again. Yeah. Like, where the things are\nlike you can't see anyways.",
    "start": "2369910",
    "end": "2376590"
  },
  {
    "text": "I guess, you can\njust compress them. Exactly. Where the things I can't see\nanyways, I can just throw away. So if I have some physical\nsignal or some RGB values",
    "start": "2376590",
    "end": "2384180"
  },
  {
    "text": "with luma values lying in here,\nvery low spatial frequency, oh, I could have actually\nincreased the distortion.",
    "start": "2384180",
    "end": "2389640"
  },
  {
    "text": "Sure, my mean square\nerror would have been high for that particular\nreason, but I don't care. Like humans don't care.",
    "start": "2389640",
    "end": "2395490"
  },
  {
    "text": "So again, very simple\nidea, but immediate impact.",
    "start": "2395490",
    "end": "2400650"
  },
  {
    "text": "On the right,\nbasically is a plot which shows this exact\ncontrast sensitivity",
    "start": "2400650",
    "end": "2405750"
  },
  {
    "text": "against spatial frequency. But for the\nluminance component-- so the Y sort of component\nand the CBCR components.",
    "start": "2405750",
    "end": "2412950"
  },
  {
    "text": "And what you see is that\nyour contrast sensitivity falls very fast for\nthe colored components.",
    "start": "2412950",
    "end": "2418410"
  },
  {
    "text": "And that again says is that,\noh, I can throw away more stuff. I don't really need\nhigh resolution even.",
    "start": "2418410",
    "end": "2423510"
  },
  {
    "text": "Like we talked about\nthrowing away bits. Maybe, I can reduce\nthe resolution. I don't need-- why\ndo we need resolution",
    "start": "2423510",
    "end": "2430020"
  },
  {
    "text": "to keep account of higher\nand higher spatial frequency? What this suggests is you\ncan throw away colored.",
    "start": "2430020",
    "end": "2435630"
  },
  {
    "text": "You can downsample\nthe colored signals. And that's exactly\nwhat we do, right? So the downsampling step is sort\nof applied to the CBCR channels",
    "start": "2435630",
    "end": "2443250"
  },
  {
    "text": "and not to the Y channels. And things still work out\nfine, which again, is motivated",
    "start": "2443250",
    "end": "2448559"
  },
  {
    "text": "by how your human vision works. So this particular\ncurve actually has lots of implications for us.",
    "start": "2448560",
    "end": "2456930"
  },
  {
    "text": "So again, like the higher\nquantization of high frequency. DCT components, you can\nagain trace it back.",
    "start": "2456930",
    "end": "2462450"
  },
  {
    "text": "I have been handwaving. Humans don't see high frequency. What does that really mean? Like this is one way\nto quantitatively think",
    "start": "2462450",
    "end": "2469440"
  },
  {
    "text": "about what we mean\nby high frequency and what we can't\nsee really, right? This has implications\nfor chroma subsampling--",
    "start": "2469440",
    "end": "2476940"
  },
  {
    "text": "what we just talked about. Why we do chroma subsampling? Something which we didn't talk\nabout in class in as detail",
    "start": "2476940",
    "end": "2483330"
  },
  {
    "text": "but just like Han verbally\nmentioned, you actually have different quantization\nmatrices itself",
    "start": "2483330",
    "end": "2488700"
  },
  {
    "text": "for luma and chroma components. So that basically says you\nhave a very different design",
    "start": "2488700",
    "end": "2494140"
  },
  {
    "text": "of rate distortion trade-off\nfor the luma components versus the chroma components.",
    "start": "2494140",
    "end": "2499540"
  },
  {
    "text": "And that again, is motivated\nby just this curve. And all of these are\nused in JPEG, right?",
    "start": "2499540",
    "end": "2505420"
  },
  {
    "text": "Like people knew about it. This is being exploited in JPEG.",
    "start": "2505420",
    "end": "2511587"
  },
  {
    "text": "I think I want to show\nyou this thing first. So this is just\nan example, right? So we looked at it in\nthe previous class.",
    "start": "2511587",
    "end": "2517960"
  },
  {
    "text": "So by CBCR, you take this RGB. You convert YCBCR. You downsample the CBCR.",
    "start": "2517960",
    "end": "2523500"
  },
  {
    "text": "I just wanted to remind the\nnumbers, and there is a demo. You can go in that link\nand play with this idea of how much you can subsample\nwithout losing any perception.",
    "start": "2523500",
    "end": "2532140"
  },
  {
    "text": "When you don't downsample, this\nis what the image looks like. And when you do JPEG\ncompression on top of it,",
    "start": "2532140",
    "end": "2538860"
  },
  {
    "text": "you get like three 23 kilo\nbit from 429 kilobits.",
    "start": "2538860",
    "end": "2543900"
  },
  {
    "text": "All of these images are\nroughly at think of them at similar level\nof distortion, OK?",
    "start": "2543900",
    "end": "2550839"
  },
  {
    "text": "Versus if I do this chroma\ndownsampling, and then I-- so OK.",
    "start": "2550840",
    "end": "2556000"
  },
  {
    "text": "Chroma downsampling itself gave\nme some obviously advantage in terms of compression. So I got like 429 to\n352, but personally, I",
    "start": "2556000",
    "end": "2564520"
  },
  {
    "text": "can't see any difference\nbetween these two images, which is the whole point. Like we as humans,\nour eyes work that way",
    "start": "2564520",
    "end": "2570040"
  },
  {
    "text": "that I can't see\nthese differences. So that's advantage number one. Just downsampling gave\nme some advantage.",
    "start": "2570040",
    "end": "2575950"
  },
  {
    "text": "But then since I\nhave downsampled. Now recall how\nJPEG works, right? Since I have\ndownsampled, now there",
    "start": "2575950",
    "end": "2582130"
  },
  {
    "text": "is higher correlation\nbetween neighboring pixels for these channels. So my compressor on top of\nthis straight-up advantage",
    "start": "2582130",
    "end": "2589809"
  },
  {
    "text": "by downsampling can also exploit\nthat there is more correlation in this channels. And so once you do\nthis downsampling",
    "start": "2589810",
    "end": "2596500"
  },
  {
    "text": "and then you apply JPEG, you\nget like almost similar quality image at 176 kilobit.",
    "start": "2596500",
    "end": "2602290"
  },
  {
    "text": "Kilo bit. Yeah, which is like\nalmost half of if you weren't applying\nthis downsampling",
    "start": "2602290",
    "end": "2607300"
  },
  {
    "text": "and then using JPEG. So the advantage is\nsort of multiply. It's not just staying there.",
    "start": "2607300",
    "end": "2613869"
  },
  {
    "text": "And the way this\ndown sampling works is like you will hear terms\nlike 4:4:4, 4:2:2, 4:2:0.",
    "start": "2613870",
    "end": "2620620"
  },
  {
    "text": "So for example here,\nit's called YUV 4:2:0. You will hear terms\nlike this quite often.",
    "start": "2620620",
    "end": "2627970"
  },
  {
    "text": "What this 4:2:0\nsort of is saying is just saying it's defining\nhow are you down sampling",
    "start": "2627970",
    "end": "2633190"
  },
  {
    "text": "the chroma components. So for example, 4:4:$\nis like full resolution.",
    "start": "2633190",
    "end": "2638620"
  },
  {
    "text": "So if you had eight colors,\nyou are representing it as some eight blocks of\ncolors or eight pixels,",
    "start": "2638620",
    "end": "2643990"
  },
  {
    "text": "whichever way you\nwant to think of it. You have some y components,\nand you have CRC components.",
    "start": "2643990",
    "end": "2649840"
  },
  {
    "text": "And you have unique values for\neach of these pixels, right? But when you are down sampling,\nwhat, for example happens,",
    "start": "2649840",
    "end": "2655809"
  },
  {
    "text": "in 4:2:0 is obviously, you keep\nthe same y, whatever y you had. But now, you take the average\nof the UV components basically.",
    "start": "2655810",
    "end": "2665020"
  },
  {
    "text": "So now, instead of using\neight colors to represent it, you are only using four colors.",
    "start": "2665020",
    "end": "2671530"
  },
  {
    "text": "So you combine this to blocks,\nthese 2 blocks, these two. Sorry. Two colors, not four.",
    "start": "2671530",
    "end": "2676540"
  },
  {
    "text": "My bad. So you are basically combining\nthis into a single block. So you are throwing away a\nlot of information, right?",
    "start": "2676540",
    "end": "2681940"
  },
  {
    "text": "From this color to just\nwent to a single color. And 4:2:0 is like default\noption and a lot of like video",
    "start": "2681940",
    "end": "2689500"
  },
  {
    "text": "compressors, image compressors. It's actually quite common. So here, like for\nexample, it's worth 4:2:0.",
    "start": "2689500",
    "end": "2696070"
  },
  {
    "text": "And yeah, so it's good\nthat we have this property",
    "start": "2696070",
    "end": "2701995"
  },
  {
    "text": "but we have to be\ncareful, right? So this is something\nwhich we introduced. And this now leads to some\nvery interesting issues",
    "start": "2701995",
    "end": "2708230"
  },
  {
    "text": "in life and practice. So now, suppose you had a very\nhigh frequency like you just",
    "start": "2708230",
    "end": "2713450"
  },
  {
    "text": "had an array of pixels,\nwhere the 4 pixels were red and everything\nelse was blue, OK?",
    "start": "2713450",
    "end": "2718609"
  },
  {
    "text": "Now, if you downsample it\nto something like 4:2:0, you actually get an image\nwhich looks like this.",
    "start": "2718610",
    "end": "2725279"
  },
  {
    "text": "And in this case, now,\nthere are very specific chromatic artifacts, right? It's like you will\nsee different color.",
    "start": "2725280",
    "end": "2733040"
  },
  {
    "text": "So where do you see\nthese effects even more like these edge effects? So for example let's imagine\nyou had a terminal screen grab.",
    "start": "2733040",
    "end": "2739610"
  },
  {
    "text": "Like \"The quick brown fox\njumps over the lazy dog.\" This is like your screenshot.",
    "start": "2739610",
    "end": "2744680"
  },
  {
    "text": "And let's say I'm just\nusing my compressor. I applied my compressor. It does YUV 4:2:0 down sampling.",
    "start": "2744680",
    "end": "2750080"
  },
  {
    "text": "In that case, what will happen? It's going to do this\nsort of averaging of pixels in 2:2 window.",
    "start": "2750080",
    "end": "2755990"
  },
  {
    "text": "And this is the\noutput which you get. So in this case, you still\nsee maybe the right edges, but the color itself\nchanged, right?",
    "start": "2755990",
    "end": "2762720"
  },
  {
    "text": "So this is suddenly\nlike in terms of maybe mean square error,\nnot that high difference",
    "start": "2762720",
    "end": "2768180"
  },
  {
    "text": "compared to just applying\nYUV 4:2:0 in some other case, but this is extremely lossy.",
    "start": "2768180",
    "end": "2773250"
  },
  {
    "text": "You just change\nthe color itself. So you have to be\ncareful while doing these down sampling and things.",
    "start": "2773250",
    "end": "2778589"
  },
  {
    "text": "Like these artifacts\nshow up in different ways in different situations. ",
    "start": "2778590",
    "end": "2786800"
  },
  {
    "text": "OK. I'm going to pause for a second. Any questions? ",
    "start": "2786800",
    "end": "2806170"
  },
  {
    "text": "OK. Final topic. Final, I guess, point\nabout YUV is cool.",
    "start": "2806170",
    "end": "2814039"
  },
  {
    "text": "We talked so much about YUV. Great. Right? But what exactly is the\nthis RGB to YUV conversion?",
    "start": "2814040",
    "end": "2819650"
  },
  {
    "text": "Like how do you go from\nRGB values to YUB values? Again, if you're\na complete newbie,",
    "start": "2819650",
    "end": "2825500"
  },
  {
    "text": "you probably\nwouldn't care, right? But this is again,\nI would say 101 in video and image compression.",
    "start": "2825500",
    "end": "2831920"
  },
  {
    "text": "Like if you are\nworking on these, these are the issues you\nstruggle with many times in practice in life.",
    "start": "2831920",
    "end": "2838790"
  },
  {
    "text": "And the answer really\nis it's not as simple as it sounds because of\nall that color spaces mess,",
    "start": "2838790",
    "end": "2847700"
  },
  {
    "text": "which we talked about. All the color spaces can\nmean many different things. And so there are various\ndifferent standards.",
    "start": "2847700",
    "end": "2853550"
  },
  {
    "text": "For example, for your\nSDTV color space, there is one standard\nto convert your RGB.",
    "start": "2853550",
    "end": "2859130"
  },
  {
    "text": "So this is just like a\nmatrix multiplication, right? And similarly, for your\nSRGB color space with HDTV,",
    "start": "2859130",
    "end": "2866480"
  },
  {
    "text": "you have some other\nYUV conversion matrix. And many times, you again\nget very interesting box",
    "start": "2866480",
    "end": "2873569"
  },
  {
    "text": "if you are like practically\nworking on these things, if you are not being careful\nabout the color space, which you are working with like\nthe conversion color space.",
    "start": "2873570",
    "end": "2881798"
  },
  {
    "text": "So again, all of these are like\nalso a lot of practical tips. If you start working\nin these areas, these things will come in handy.",
    "start": "2881798",
    "end": "2887385"
  },
  {
    "text": " OK. So let's skip that slide.",
    "start": "2887385",
    "end": "2893650"
  },
  {
    "text": "I just want to get here. So now, I used another\ntool called ExifTool. Doesn't matter. And I took the\nStanford logo dot JPEG.",
    "start": "2893650",
    "end": "2902350"
  },
  {
    "text": "And I asked. I just show the output here, OK? And so the idea after this\nclass really at this point",
    "start": "2902350",
    "end": "2911770"
  },
  {
    "text": "is that you should be able\nto take JPEG image, right? At least or some\ncompressed image,",
    "start": "2911770",
    "end": "2917890"
  },
  {
    "text": "and at least, be\nable to explain what are the various\ncomponents, which are part of this JPEG image.",
    "start": "2917890",
    "end": "2923650"
  },
  {
    "text": "So if you look at the output,\nOK, initially, it's all fine. It's directory file\nsize, whatever. Some file permissions.",
    "start": "2923650",
    "end": "2930460"
  },
  {
    "text": "Now, some interesting\nstuff starts coming in. OK. Big Endian, et cetera. It's just like standard\ncomputer stuff.",
    "start": "2930460",
    "end": "2937269"
  },
  {
    "text": "Color space. This is color space is SRGB. So hopefully now you know. Maybe not exactly but\nroughly know what that means.",
    "start": "2937270",
    "end": "2944740"
  },
  {
    "text": "Like how do I exploit\nthat or use that? You have some image\nwith et cetera. Like if you look at the encoding\nprocess, you see baseline DCT.",
    "start": "2944740",
    "end": "2952340"
  },
  {
    "text": "Huffman encoding. You should immediately know\nwhat happened here, right? So like what exactly was used.",
    "start": "2952340",
    "end": "2959060"
  },
  {
    "text": "Coming down, you see\nbits per sample is 8. Color components is 3. So like no alpha channel\nin this particular one.",
    "start": "2959060",
    "end": "2964490"
  },
  {
    "text": "It's just 8-bit,\nnot 12-bit HD image. Then you see YCBCR subsampling.",
    "start": "2964490",
    "end": "2970790"
  },
  {
    "text": "In this case, it's 4:2:0. Again, this is just\na standard image downloaded from the internet. You can mostly assume that it\nwould be most likely 4:2:0.",
    "start": "2970790",
    "end": "2979400"
  },
  {
    "text": "That's the most used default\noption for subsampling, right? So OK.",
    "start": "2979400",
    "end": "2984910"
  },
  {
    "text": "So at this point, I\nreally hope that something like JPEG traditional\ncompressor is really clear.",
    "start": "2984910",
    "end": "2990670"
  },
  {
    "text": "And you can start playing\nwith various components of it as and when needed.",
    "start": "2990670",
    "end": "2997990"
  },
  {
    "text": "I'm going to pause\nhere for a second. I think we're going to\nchange topics after this. So any questions?",
    "start": "2997990",
    "end": "3003900"
  },
  {
    "start": "3003900",
    "end": "3010760"
  },
  {
    "text": "No? Good. OK. So we looked at one\naspect of human vision",
    "start": "3010760",
    "end": "3017810"
  },
  {
    "text": "and how it specifically\nled us to take many design decisions in JPEG, which is\nvery famous traditional image",
    "start": "3017810",
    "end": "3026000"
  },
  {
    "text": "compressor. Now, let's talk about this idea\nof distortion metric, right?",
    "start": "3026000",
    "end": "3031490"
  },
  {
    "text": "So thing we have said at\nleast 10 times this points in this class that FC\nis a bad distortion",
    "start": "3031490",
    "end": "3037880"
  },
  {
    "text": "metric for practical\ncomponents, and our golden image",
    "start": "3037880",
    "end": "3043009"
  },
  {
    "text": "is back to help us.  So roughly, so like the idea is\nto go towards more perceptual",
    "start": "3043010",
    "end": "3052030"
  },
  {
    "text": "metrics. As the name suggests, they try\nto model how human perception or how human distortion works.",
    "start": "3052030",
    "end": "3058900"
  },
  {
    "text": "And you can roughly\nthink of them as part of being three classes. OK. Like there are\nthree ways you might",
    "start": "3058900",
    "end": "3064978"
  },
  {
    "text": "want to attack this\nproblem as of today. So one way is like,\nOK, one idea is maybe,",
    "start": "3064978",
    "end": "3071410"
  },
  {
    "text": "we should model these low level\nhuman vision features, right? We talked about all of\nthese different things. Why can't we model them, right?",
    "start": "3071410",
    "end": "3078099"
  },
  {
    "text": "We can model it. And then instead of MSE, which\nis a simple formula, maybe we'll have something a\nlittle bit more complicated.",
    "start": "3078100",
    "end": "3083650"
  },
  {
    "text": "And we'll use that as\na distortion metric. And that will be a better guide\nof how to do rate distortion optimization, OK?",
    "start": "3083650",
    "end": "3091060"
  },
  {
    "text": "The second idea is to use\nlike this modern, big learning machine learning models, right?",
    "start": "3091060",
    "end": "3096910"
  },
  {
    "text": "A lot of people have figured\nout that, oh, these actually extract very relevant\nfeatures, very similar features",
    "start": "3096910",
    "end": "3102610"
  },
  {
    "text": "to humans. And maybe, we can use\nlike this huge models to actually extract the\nrelevant information out, OK?",
    "start": "3102610",
    "end": "3111090"
  },
  {
    "text": "So actually, let me\nalso throw some terms. So this modeling\nlow-level human vision features led to metrics such\nas SSIM, MS-SSIM or VIF.",
    "start": "3111090",
    "end": "3123210"
  },
  {
    "text": "Again, if you go read any\npaper on image compression, video compression, as of\ntoday, they would almost 100%",
    "start": "3123210",
    "end": "3133950"
  },
  {
    "text": "include some comparison\nof distortion with SSIM. You probably can't even\npublish or convince anyone",
    "start": "3133950",
    "end": "3139890"
  },
  {
    "text": "that your compressor\nworks better if you only report results\nfor distortion with MSE. So this is like a 2002 paper.",
    "start": "3139890",
    "end": "3146369"
  },
  {
    "text": "It has really become\nindustry standard. Like not even industry academia. Everywhere. It's a standard.",
    "start": "3146370",
    "end": "3151680"
  },
  {
    "text": "That's like one of\nthe early works which tried to model human\nvisual perception.",
    "start": "3151680",
    "end": "3157150"
  },
  {
    "text": "Moving on, this idea of\nLPIPS, which is now using big learned machine learning\nmodels as a proxy",
    "start": "3157150",
    "end": "3162310"
  },
  {
    "text": "to what human vision might\nbe doing and using them as a measure of distortion.",
    "start": "3162310",
    "end": "3167500"
  },
  {
    "text": "The most popular work is\nsomething called LPIPS, right? You don't have to\nremember these terms.",
    "start": "3167500",
    "end": "3172540"
  },
  {
    "text": "You can come back\nand see this slide, but you might see\nthese terms if you are working and doing research\nin these areas very frequently.",
    "start": "3172540",
    "end": "3179080"
  },
  {
    "text": "So that's another sort of-- LPIPS itself is not\na distortion metric. It's just a method\nwhich using which you",
    "start": "3179080",
    "end": "3187069"
  },
  {
    "text": "exploit some distortion metric. And the basic idea is it\nuses this learn models.",
    "start": "3187070",
    "end": "3192980"
  },
  {
    "text": "And then the third\nidea is somewhat in the middle, which\nis OK, let me maybe",
    "start": "3192980",
    "end": "3198049"
  },
  {
    "text": "come up with simple features. Not learned hand-design\nfeatures, right? Like somewhat like first one.",
    "start": "3198050",
    "end": "3204380"
  },
  {
    "text": "But I'll combine them with\nlike different parameters using machine learning,\nlike using some human vision",
    "start": "3204380",
    "end": "3211520"
  },
  {
    "text": "experiments. So in this one, you are\nlearning all the features. In this one, it's everything.",
    "start": "3211520",
    "end": "3216910"
  },
  {
    "text": "Handwritten rules. The third one, it's\nmore like somewhere in the middle, where you know\nwhat features to extract,",
    "start": "3216910",
    "end": "3224110"
  },
  {
    "text": "but then you decide\nhow to combine them by doing a lot of subjective\nstudies and so on.",
    "start": "3224110",
    "end": "3229250"
  },
  {
    "text": "So now, people did that, and\nnow it's fixed so as to say. And like the most famous\nof this is like VMAF, which",
    "start": "3229250",
    "end": "3239590"
  },
  {
    "text": "is used by Netflix popularized. And it's like any\nvideo paper video, compression paper would have\na VMAF score related to it.",
    "start": "3239590",
    "end": "3246640"
  },
  {
    "text": "It's very recent again. So SSIM was something like 2002. So all of these are\nthis century by the way.",
    "start": "3246640",
    "end": "3252460"
  },
  {
    "text": "Before that, we\nweren't even at level that we cared about things. So SSIM something like 2002.",
    "start": "3252460",
    "end": "3258130"
  },
  {
    "text": "LPIPS I think is like 2018, '19. Something like that maybe. '20.",
    "start": "3258130",
    "end": "3263160"
  },
  {
    "text": "And then VMAF is again,\nI think 2015, '16. Something of that. So all of these are\nlike pretty new methods,",
    "start": "3263160",
    "end": "3268740"
  },
  {
    "text": "and it's a really\nhot area of research. Like if you figure out\nsolve this problem, it's really relevant\nin terms of resources.",
    "start": "3268740",
    "end": "3276180"
  },
  {
    "text": "You can save like\nsmartly allocate bits as well as like big money\nfor different aspects.",
    "start": "3276180",
    "end": "3283420"
  },
  {
    "text": "OK. So I'm not going to go into too\nmuch details about any of this, but I think all of\nthese are important.",
    "start": "3283420",
    "end": "3290250"
  },
  {
    "text": "So let me just give\nyou a 5-minute overview of the basic ideas used, OK? In these things.",
    "start": "3290250",
    "end": "3297740"
  },
  {
    "text": "So SSIM. This is now a figure\nfrom the paper.",
    "start": "3297740",
    "end": "3305329"
  },
  {
    "text": "First look, you\nmight get scared. Don't get scared. It's actually not that hard. The basic idea\nreally is like SSIM,",
    "start": "3305330",
    "end": "3311660"
  },
  {
    "text": "it's from Structural Similarity. That's where the\nSSIM terms come from.",
    "start": "3311660",
    "end": "3317359"
  },
  {
    "text": "It uses three key features\nto basically compare any two images. So distortion is between\ntwo images, right?",
    "start": "3317360",
    "end": "3323570"
  },
  {
    "text": "Like you need original\nreconstructed or between two. It's like distance.",
    "start": "3323570",
    "end": "3328589"
  },
  {
    "text": "The way it constructs\nthat is it takes into account the luminescence\nbecause it says like, OK, the average y-value is what\nwe as humans care about.",
    "start": "3328590",
    "end": "3336450"
  },
  {
    "text": "The contrast, again,\nsomething, we as humans care about and the structure. And this is the\npaper actually, which",
    "start": "3336450",
    "end": "3342930"
  },
  {
    "text": "is the source of this image,\nwhich we have been showing. Like they were the ones\nto very clearly show that these things matter.",
    "start": "3342930",
    "end": "3349680"
  },
  {
    "text": "The way you compute\nluminescence is just like mean of blocks x and y. And so you have some L between\nx and y luminescence, distance",
    "start": "3349680",
    "end": "3357990"
  },
  {
    "text": "between x and y images, which\nis just some function of mean of x and mean of y. Let's not get into\ndetails, but again,",
    "start": "3357990",
    "end": "3364410"
  },
  {
    "text": "any topic about this\nlecture if it interests you, come talk to me later. We can discuss more. The contrast, like I said,\nit's just like variance, right?",
    "start": "3364410",
    "end": "3372960"
  },
  {
    "text": "much how many these\npixels are changing, and that's how they model it. Again, like some function of\nthe sigma x and sigma y, OK?",
    "start": "3372960",
    "end": "3380430"
  },
  {
    "text": "And the structural similarity\nis just the idea that basically,",
    "start": "3380430",
    "end": "3388480"
  },
  {
    "text": "what sort of the covariance\nbetween these two images, right? Do they have the edges\nat the same places?",
    "start": "3388480",
    "end": "3394240"
  },
  {
    "text": "Do they have the shallow\nregions at the same places, so on and so forth, right?",
    "start": "3394240",
    "end": "3399370"
  },
  {
    "text": "And that's being captured by\nbasically the sigma xy, which is just the covariance\nmatrix or correlation",
    "start": "3399370",
    "end": "3405550"
  },
  {
    "text": "matrix between these\ntwo images x and y. And then you take this.",
    "start": "3405550",
    "end": "3410900"
  },
  {
    "text": "You compute these three scores. That's what's being shown in\na diagrammatic fashion here.",
    "start": "3410900",
    "end": "3415940"
  },
  {
    "text": "And then you combine\nthese three scores to get this SSIM score finally\nbetween two images x and y.",
    "start": "3415940",
    "end": "3421609"
  },
  {
    "text": " And it looks something\nlike this where",
    "start": "3421610",
    "end": "3426619"
  },
  {
    "text": "you have different values\nof alpha, beta, gamma. It results in some formula. Today, you will find like many,\nmany implementations for SSIM,",
    "start": "3426620",
    "end": "3433940"
  },
  {
    "text": "but the idea is actually\nnot that hard, right? All you are doing is\ncomputing some second order terms between these two images.",
    "start": "3433940",
    "end": "3440480"
  },
  {
    "text": "And then you are using them\nas distortion metric, OK? And again, all of this\n[AUDIO OUT] visually motivated.",
    "start": "3440480",
    "end": "3446540"
  },
  {
    "text": "Luminescence is important. Contrast is important. Structure is important, right? It's going away from\nthe mSE so it's just",
    "start": "3446540",
    "end": "3451968"
  },
  {
    "text": "trying to model this\nlow level behaviors. ",
    "start": "3451968",
    "end": "3458060"
  },
  {
    "text": "OK. So I'm not going to go\ninto details of this but another very\ninteresting factor is the way you compute this mean\nvariance and the covariance.",
    "start": "3458060",
    "end": "3468170"
  },
  {
    "text": "So that's typically\nlike for example mean. It's not just taking\naverage of pixels.",
    "start": "3468170",
    "end": "3473900"
  },
  {
    "text": "It's actually some\nweighted average of pixels. And again, the only reason I\nwant to tell you about this",
    "start": "3473900",
    "end": "3479390"
  },
  {
    "text": "like why you want weighted\naverage of pixels-- OK. It's a heuristic.",
    "start": "3479390",
    "end": "3484559"
  },
  {
    "text": "There isn't really like\na theorem to prove it, but the idea really is like\nit of accounts for foveation,",
    "start": "3484560",
    "end": "3490920"
  },
  {
    "text": "which says that, oh, if\nI'm focusing on this block and I'm calculating like\nthe difference in two",
    "start": "3490920",
    "end": "3496020"
  },
  {
    "text": "images and one\nparticular block, I should put more value to the\ncenter aspects than the side",
    "start": "3496020",
    "end": "3501840"
  },
  {
    "text": "aspects because in some\nsense, when I'm going to look, I'm going to look less\ntowards the side, right? So this weight aspect is\nsort of a Gaussian kernel.",
    "start": "3501840",
    "end": "3510240"
  },
  {
    "text": "Motivation is foveation. Again, it's all hand-wavy, but\nthat's why they do it, right?",
    "start": "3510240",
    "end": "3516840"
  },
  {
    "text": "And then what they could\nshow is that this SSIM metric collaborates much\nbetter with humans",
    "start": "3516840",
    "end": "3523680"
  },
  {
    "text": "judgment compared to\nthe mean square error. ",
    "start": "3523680",
    "end": "3529150"
  },
  {
    "text": "So in future, people\nalso extended it to some more interesting ideas. There is something\ncalled MS-SSIM.",
    "start": "3529150",
    "end": "3534540"
  },
  {
    "text": "Again, very common. MS-SSIM for now multiscale. And the idea really is you\nkeep applying this SSIM.",
    "start": "3534540",
    "end": "3541319"
  },
  {
    "text": "So you apply SSIM for the\nsignal 1 and signal 2. Then you downsample\nboth of them. Then you apply again.",
    "start": "3541320",
    "end": "3547200"
  },
  {
    "text": "Then you downsample\nboth of them. Then you apply again. And you keep doing that. And then you somehow\ncombine them.",
    "start": "3547200",
    "end": "3553710"
  },
  {
    "text": "Why would you want to do that? So there, the idea\nis you want to see how this image responds to\nvarious different spatial",
    "start": "3553710",
    "end": "3561210"
  },
  {
    "text": "frequencies really. And the idea is\nthat we almost have different independent channels\nfor different spatial frequency",
    "start": "3561210",
    "end": "3567750"
  },
  {
    "text": "or contrast behaves\ndifferently, so on and so forth. And what they\nshowed us like this is like a decent\nimprovement over SSIM.",
    "start": "3567750",
    "end": "3574410"
  },
  {
    "text": "So again, like a very\ncommonly used metric in all sorts of image and\nvideo compression works.",
    "start": "3574410",
    "end": "3580815"
  },
  {
    "text": " All right. Then the second idea\nwas around this LPIPS.",
    "start": "3580815",
    "end": "3589730"
  },
  {
    "text": "And this is just like a\nquote from this paper. LPIPS is again, so a lot\nof acronyms in this area.",
    "start": "3589730",
    "end": "3597950"
  },
  {
    "text": "I don't know why,\nbut I think it's OK. So LPIPS is for Learned\nPerceptual Image Patch",
    "start": "3597950",
    "end": "3605030"
  },
  {
    "text": "Similarity. And I think the name kind of-- like if you just want a\nthousand feet overview,",
    "start": "3605030",
    "end": "3610580"
  },
  {
    "text": "the name gives you\nwhat it might be doing. The basic idea\nreally is-- and this",
    "start": "3610580",
    "end": "3616819"
  },
  {
    "text": "is like an image\nfrom the same paper. So this is like a quote\nfrom the paper which says, \"Our results suggest\nthat perceptual similarity is",
    "start": "3616820",
    "end": "3625160"
  },
  {
    "text": "an emergent property\nshared across deep visual representations.\" Very fancy word.",
    "start": "3625160",
    "end": "3631610"
  },
  {
    "text": "Very fancy line. But if you understand machine\nlearning, what these are saying is that you learn\nfeatures themselves",
    "start": "3631610",
    "end": "3638960"
  },
  {
    "text": "are somewhat representative of\nwhat humans would have looked as features in these studies.",
    "start": "3638960",
    "end": "3645950"
  },
  {
    "text": "And the way they go\nabout doing it is they use this deep embeddings\nas a feature space.",
    "start": "3645950",
    "end": "3652370"
  },
  {
    "text": "And then define some distances\nover these embeddings, neural net embeddings,\nwhich are like outputs",
    "start": "3652370",
    "end": "3658400"
  },
  {
    "text": "of these neural\nnets to determine, OK, a new distortion\nmetric for humans.",
    "start": "3658400",
    "end": "3666700"
  },
  {
    "text": "Oh, sorry. A new distortion\nmetric for compressors. And so like for example, what\nyou can see here is let's say,",
    "start": "3666700",
    "end": "3673490"
  },
  {
    "text": "this is your reference image. This is like one\ncompressed image,",
    "start": "3673490",
    "end": "3678740"
  },
  {
    "text": "and this is like another\ncompressed version of that image. Humans would choose\nthis right one. But if you were\ndoing L2, so this one",
    "start": "3678740",
    "end": "3686870"
  },
  {
    "text": "has a lower mean squared\nerror compared to these two. Clearly, but the right\none is much better, right?",
    "start": "3686870",
    "end": "3691880"
  },
  {
    "text": "So, this is again\nanother illustration of what we have seen. But more interestingly,\nwhen SSIM, which we just",
    "start": "3691880",
    "end": "3697099"
  },
  {
    "text": "talked about would\nchoose this one, whereas their method,\nlike whatever these three",
    "start": "3697100",
    "end": "3703640"
  },
  {
    "text": "different networks--\nthink of this as some learned representation. Some distance metric over\nthese deep embeddings--",
    "start": "3703640",
    "end": "3709550"
  },
  {
    "text": "would have chosen this patch. So it shows that\nthese neural nets, the embeddings\nlearned through them.",
    "start": "3709550",
    "end": "3715910"
  },
  {
    "text": "May be doing something\nmore similar to humans. Yeah, we're not going\nto go through this.",
    "start": "3715910",
    "end": "3722420"
  },
  {
    "text": "The important really\nis this line here that what you can do\nis for each image,",
    "start": "3722420",
    "end": "3727880"
  },
  {
    "text": "you can extract its\nembeddings, which is just the output of this\n[AUDIO OUT] neural nets.",
    "start": "3727880",
    "end": "3733430"
  },
  {
    "text": "And then you can\ndefine some distance between these\nembeddings as a proxy",
    "start": "3733430",
    "end": "3738470"
  },
  {
    "text": "to whatever your distortion\nmeasure between these two images. And again, it's now very\ncommonly [AUDIO OUT]",
    "start": "3738470",
    "end": "3745310"
  },
  {
    "text": "reported [AUDIO OUT] first. I'm going to skip this. ",
    "start": "3745310",
    "end": "3751050"
  },
  {
    "text": "Oh. Any [AUDIO OUT]. Nope? OK. And so the third\nidea is this VMAF.",
    "start": "3751050",
    "end": "3757280"
  },
  {
    "text": "I'm actually not going to\ngo into details of this, but again, like the\nbasic idea here really",
    "start": "3757280",
    "end": "3762320"
  },
  {
    "text": "is you have some\npredefined features. So you have some predefined\nspatial features.",
    "start": "3762320",
    "end": "3767330"
  },
  {
    "text": "Think of this VIF, DLM\nas some matrix like SSIM. Like we can talk about\nit, but think of them",
    "start": "3767330",
    "end": "3774200"
  },
  {
    "text": "as like brothers of SSIM. Like people did more\nwork in the similar class of defining low level vision.",
    "start": "3774200",
    "end": "3780500"
  },
  {
    "text": "And then you can\nextract all of these. But then finally, like how you\ncombine all this four or five",
    "start": "3780500",
    "end": "3786020"
  },
  {
    "text": "different existing-- actually exactly two. But how you combine\nthese metrics, which",
    "start": "3786020",
    "end": "3791839"
  },
  {
    "text": "exist at low level\nhumans is now you train a machine learning\nmodel to figure out how to combine these metrics by\ncollecting a lot of human data.",
    "start": "3791840",
    "end": "3800370"
  },
  {
    "text": "So you ask a lot of people,\nOK, which one do you prefer? Which one do you prefer? Which one do you prefer? And then you try to figure out,\nOK, what's the right distance?",
    "start": "3800370",
    "end": "3807750"
  },
  {
    "text": "And that's like another\nidea of coming up with a perceptual metric, right? And so these trained\nparameters are fixed,",
    "start": "3807750",
    "end": "3814859"
  },
  {
    "text": "and then you can use that as\nanother distortion metric. ",
    "start": "3814860",
    "end": "3822170"
  },
  {
    "text": "Going back, so these are\nroughly like how I tried to summarize this sort of area. So there are roughly three kind\nof three classes of things,",
    "start": "3822170",
    "end": "3830329"
  },
  {
    "text": "which people are doing to come\nup with new distortion metrics. Very, very hot area of research.",
    "start": "3830330",
    "end": "3836369"
  },
  {
    "text": "So like I think it's\nfar from mature. So if you want to\ncontribute, it's",
    "start": "3836370",
    "end": "3841700"
  },
  {
    "text": "like you can make big\nimpact by contributing.",
    "start": "3841700",
    "end": "3848280"
  },
  {
    "text": "OK. Any questions? Then we'll just do\nthe last part of where human vision can play a role.",
    "start": "3848280",
    "end": "3856330"
  },
  {
    "text": "OK. So, so far, we have\nlooked at two things. Traditional compressors like\nhow a lot of design decisions.",
    "start": "3856330",
    "end": "3861450"
  },
  {
    "text": "The second one\nwas, oh, MSE is bad so let's figure out like\nwhat are the right distortion measures, which are\nperceptually relevant.",
    "start": "3861450",
    "end": "3868410"
  },
  {
    "text": "Now, the third thing is\nactually even more interesting. So we have talked about\nrate distortion trade-off.",
    "start": "3868410",
    "end": "3874980"
  },
  {
    "text": "But again, a very recent work--\nthis is I think 2018, '19. So all of these are very new.",
    "start": "3874980",
    "end": "3881910"
  },
  {
    "text": "Talks about rate distortion\nand perception trade-off. And here is like a screenshot\nfrom this paper, which I think",
    "start": "3881910",
    "end": "3891000"
  },
  {
    "text": "is very illustrative. So let's say you have\nan image [AUDIO OUT].. So like [AUDIO OUT].",
    "start": "3891000",
    "end": "3896130"
  },
  {
    "text": "You are sitting\noutside at Stanford. You saw some grass. You click a picture, OK? This is what that image looks\nlike compressed using JPEG, OK?",
    "start": "3896130",
    "end": "3908029"
  },
  {
    "text": "And the third one is\nthink of it as our deep--",
    "start": "3908030",
    "end": "3913120"
  },
  {
    "text": "it's a fake image. It's a neural net generated\nimage of that grass, which says statistically\nrepresent grass,",
    "start": "3913120",
    "end": "3919750"
  },
  {
    "text": "but it's not exactly\nthe same grass. How do I know? Maybe, look at this strand here.",
    "start": "3919750",
    "end": "3926020"
  },
  {
    "text": "You see there is a strand here. There is this strand here. There is no strand here, right? So it's just a general grass.",
    "start": "3926020",
    "end": "3932110"
  },
  {
    "text": "Generated grass, OK? But if I ask you,\nlike amongst B and C,",
    "start": "3932110",
    "end": "3939040"
  },
  {
    "text": "which reconstruction\ndo you prefer? How many of you say B?",
    "start": "3939040",
    "end": "3945790"
  },
  {
    "text": "How many of you would say C? ",
    "start": "3945790",
    "end": "3950930"
  },
  {
    "text": "B or C? [INAUDIBLE] Oh. B compared with A or\nC compared with A.",
    "start": "3950930",
    "end": "3957365"
  },
  {
    "text": "Which one would you prefer? Let's say A was\nyour source image. One compressor compresses at\n2 B. The other [AUDIO OUT] C.",
    "start": "3957365",
    "end": "3966339"
  },
  {
    "text": "C. OK. Maybe, that's not a bad. Yeah, I think I would prefer C.\nBut because B is like it's just",
    "start": "3966340",
    "end": "3974800"
  },
  {
    "text": "blurred even though it has\nthe right strands everywhere. But clearly, C has a very high\ndistortion in terms of MSE.",
    "start": "3974800",
    "end": "3981720"
  },
  {
    "text": "It's just like random\narrangement of strands. But we, as humans, don't really\ncare about these strands,",
    "start": "3981720",
    "end": "3987230"
  },
  {
    "text": "right? If this was somebody's face,\nwe would be like mad, right? Like if somebody's face\nwas distorted like this,",
    "start": "3987230",
    "end": "3992390"
  },
  {
    "text": "we'll just lose our stuff. But like for this\ngrass or in general,",
    "start": "3992390",
    "end": "3999410"
  },
  {
    "text": "for a lot of texture kind\nof images and details-- for example, this carpet. I don't really care where\nexactly this is as long",
    "start": "3999410",
    "end": "4006400"
  },
  {
    "text": "as statistically they\nare somewhat similar, or in other words, perceptually,\nthey look the same.",
    "start": "4006400",
    "end": "4012740"
  },
  {
    "text": "And that's really like sort of\na very new and upcoming area both in terms of\ntheory and practice,",
    "start": "4012740",
    "end": "4019210"
  },
  {
    "text": "and lots of open and\ninteresting questions there which is, how do you\naccount for this perception",
    "start": "4019210",
    "end": "4024910"
  },
  {
    "text": "when you are doing compression? Essentially, it's not just\nabout rate distortion. Maybe, I should think about\nthe perception aspect too.",
    "start": "4024910",
    "end": "4034140"
  },
  {
    "text": "And so this is like another\nexample from this paper. So what they do is like, OK,\nyou have some rate definition.",
    "start": "4034140",
    "end": "4039550"
  },
  {
    "text": "Don't worry about the symbols. Your rate is some\nfunction of X, X hat. You have some distortion\nwhich is expected value of we",
    "start": "4039550",
    "end": "4045840"
  },
  {
    "text": "have been looking at d as\na symbol for distortion. Now, you also model perception.",
    "start": "4045840",
    "end": "4052620"
  },
  {
    "text": "And the way you model\nperception is some distance between the probability\ndistributions of your original",
    "start": "4052620",
    "end": "4057700"
  },
  {
    "text": "and reconstructed because\nat the end of the day, your perception is like some\nstatistical, some measurement",
    "start": "4057700",
    "end": "4064290"
  },
  {
    "text": "on the probability distribution. And now, instead of doing\njust R plus lambda d, you would try to basically\nplay with these 3 parameters.",
    "start": "4064290",
    "end": "4071770"
  },
  {
    "text": "So not just trade off 2 but\nmaybe play with 3, right?",
    "start": "4071770",
    "end": "4077490"
  },
  {
    "text": "So here is basically an\nexample of what happens. Let's just look at\nthis last row, OK?",
    "start": "4077490",
    "end": "4085190"
  },
  {
    "text": "Sorry. Yeah, last row. So this is the input. So this is our MNIST\ndigits, which we also",
    "start": "4085190",
    "end": "4091089"
  },
  {
    "text": "saw in the last class. So same MNIST digits. And now, I'm trying to compress\nit to 2 bits and then decode.",
    "start": "4091090",
    "end": "4100600"
  },
  {
    "text": "Sorry. Compress it to 2\nbits and then decode using different trade-offs\nbetween the distortion and perception.",
    "start": "4100600",
    "end": "4106000"
  },
  {
    "text": "So I fixed the rate. I can change my distortion\nand perception, right?",
    "start": "4106000",
    "end": "4111040"
  },
  {
    "text": "So the first column\nhere is what happens if you were to optimally\ncompress it using Shannon.",
    "start": "4111040",
    "end": "4116229"
  },
  {
    "text": "So just rate distortion. You don't care about\nthe perception. And as you move\ntowards the right,",
    "start": "4116229",
    "end": "4121659"
  },
  {
    "text": "you give higher and higher\npenalty for perception. So you care more and\nmore about perception. What do you see that at 2 bits?",
    "start": "4121660",
    "end": "4128589"
  },
  {
    "text": "Like this is very blurred. Like this is like-- right? Versus as you keep\ngoing towards right,",
    "start": "4128590",
    "end": "4135850"
  },
  {
    "text": "it's become higher\nand higher fidelity. But now, what might happen is\nlike your numbers might not",
    "start": "4135850",
    "end": "4142179"
  },
  {
    "text": "match exactly because\nagain, the same thing is like here, the strands\ndidn't match exactly.",
    "start": "4142180",
    "end": "4147200"
  },
  {
    "text": "Here, the numbers\nwon't match exactly. So there is some trade off\nso as to say which you now need to figure out between\nwhat exact distortion",
    "start": "4147200",
    "end": "4154818"
  },
  {
    "text": "and perceptions\nyou can work with. And obviously, I\nthink something which is very important\nto understanding",
    "start": "4154819",
    "end": "4160939"
  },
  {
    "text": "this is if you had infinite\nrate, if you are working in a high bandwidth,\nhigh streaming kind of an application, sure.",
    "start": "4160939",
    "end": "4168380"
  },
  {
    "text": "You would like to represent\neverything exactly. But the more and more\nadvantages of this RDP or taking",
    "start": "4168380",
    "end": "4174290"
  },
  {
    "text": "perception into account starts\ncoming as you are really rate limited, right? Because then, you can't\nspend a lot of bits",
    "start": "4174290",
    "end": "4180740"
  },
  {
    "text": "to represent each of that\nMSE like perfectly, right? At that point, it's not about\nseeing the most pristine, most",
    "start": "4180740",
    "end": "4187910"
  },
  {
    "text": "like all the edges, the perfect\nimage, and your HDTV, right? At that point, you care\nmore about something,",
    "start": "4187910",
    "end": "4194270"
  },
  {
    "text": "which is more acceptable\nto me than like maybe these blurred symbols. Like these blurred symbols\nis something like as a human,",
    "start": "4194270",
    "end": "4200413"
  },
  {
    "text": "I won't accept. This is extremely bad quality. I would rather expect\nmaybe slight distortions.",
    "start": "4200413",
    "end": "4206330"
  },
  {
    "text": "Maybe not at this extreme\nwhere my 5 became 7, right? So this is just bad, but maybe,\nat 5 bits, being 5 is nice,",
    "start": "4206330",
    "end": "4216980"
  },
  {
    "text": "right? So something to be basically-- it's very up and coming and\nsomething to think about.",
    "start": "4216980",
    "end": "4223510"
  },
  {
    "text": "And really maybe, right? Like it's really\ninteresting and important.",
    "start": "4223510",
    "end": "4229080"
  },
  {
    "text": "And so all of this is nice. So this is like sort of\nsome theory component, and there are some\nvery nice new theorems.",
    "start": "4229080",
    "end": "4234660"
  },
  {
    "text": "So if you guys like the\ntheory part of RD, like again, these are not old papers. These are like 2019 I think\nif I recall correctly.",
    "start": "4234660",
    "end": "4243570"
  },
  {
    "text": "And so like more\nrecently, even otherwise, like so this paper talks about\nthat you can bound the maximum.",
    "start": "4243570",
    "end": "4251460"
  },
  {
    "text": "So ideally, you would\nlike to bound some error on the distortion, right? Like you wouldn't want--",
    "start": "4251460",
    "end": "4257010"
  },
  {
    "text": "like OK, if I go for\nperception, I should completely change the number. If I do that, then that's a\nvery bad, bad thing, right?",
    "start": "4257010",
    "end": "4263220"
  },
  {
    "text": "I can't really work\nwith that formulation. So for example, in theory\nwhat this paper showed",
    "start": "4263220",
    "end": "4269250"
  },
  {
    "text": "is that, oh, if you were\nunder certain starma, certain conditions, you can\nbound the error in distortion,",
    "start": "4269250",
    "end": "4276660"
  },
  {
    "text": "even if you were optimally\noptimizing for perception. So that's a good\nresult. That then starts",
    "start": "4276660",
    "end": "4282310"
  },
  {
    "text": "saying that, OK, if\nI do this smartly, maybe it won't be the case\never that my 5 becomes 1.",
    "start": "4282310",
    "end": "4289500"
  },
  {
    "text": "I'm being handwavy, but\nthat's really the idea. And there is like a lot\nof open field there. People haven't\nreally explored this",
    "start": "4289500",
    "end": "4295930"
  },
  {
    "text": "as much whereas RD has been\nexplored for the past 50 years, right? 50, 60 years. So again, if you're\ninterested in theory something",
    "start": "4295930",
    "end": "4302110"
  },
  {
    "text": "nice to look forward to. But in practice also\nlike this RDP framework",
    "start": "4302110",
    "end": "4308230"
  },
  {
    "text": "is already being used in\nmany different senses. So recall this picture from\na [AUDIO OUT] lecture, right?",
    "start": "4308230",
    "end": "4315340"
  },
  {
    "text": "We had this particular\nimage, and then we were trying to\noptimize [AUDIO OUT]..",
    "start": "4315340",
    "end": "4321020"
  },
  {
    "text": "And I said that one of the\nvery, very good benefits about this framework is\nthis distortion is really",
    "start": "4321020",
    "end": "4327350"
  },
  {
    "text": "up to us for decide, right? Like I can plug in\nanything as long as it's differentiable back.",
    "start": "4327350",
    "end": "4333690"
  },
  {
    "text": "So idea 1. I want to take into\naccount perception.",
    "start": "4333690",
    "end": "4340690"
  },
  {
    "text": "[AUDIO OUT] instead of\nmessy or in our notebook, we had I think L1 error. Mean absolute error.",
    "start": "4340690",
    "end": "4346990"
  },
  {
    "text": "Instead of that, maybe\nI can take [AUDIO OUT].. And you saw SSIM was just\n[AUDIO OUT] and sigma.",
    "start": "4346990",
    "end": "4352239"
  },
  {
    "text": "So it's a linear operator. It's differentiable, right? So nice. I can do that. And now, I suddenly get a\nlearned compressor, which",
    "start": "4352240",
    "end": "4359110"
  },
  {
    "text": "is more optimized for SSIM. And it will probably\nalready perform better in terms of like the visual\ncharacteristics for human.",
    "start": "4359110",
    "end": "4369350"
  },
  {
    "text": "But maybe. I can do even more. ",
    "start": "4369350",
    "end": "4377420"
  },
  {
    "text": "I can also add my weight MSE\nloss with my perceptual metric. The idea really there is\nthat-- so for example,",
    "start": "4377420",
    "end": "4385350"
  },
  {
    "text": "I can have mean absolute\nerror as well as my LPIPS.",
    "start": "4385350",
    "end": "4390460"
  },
  {
    "text": "And this is actually quite\ncommonly used like I think-- I don't know.",
    "start": "4390460",
    "end": "4395560"
  },
  {
    "text": "I don't want to say 100,\nbut almost, almost all of learned image and\nvideo compressors",
    "start": "4395560",
    "end": "4402400"
  },
  {
    "text": "actually use like a loss. Something which\nlooks like this where you have some\ndistortion term really",
    "start": "4402400",
    "end": "4408910"
  },
  {
    "text": "and some perceptual term. And the idea there really\nis what we saw, right?",
    "start": "4408910",
    "end": "4413949"
  },
  {
    "text": "Like so distortion\nterm kind of ensures that you don't run away\nand just completely start making up stuff,\nwhereas this LPIPS.",
    "start": "4413950",
    "end": "4422290"
  },
  {
    "text": "For example, like\nLPIPS won't really care about pixel\nlevel details, right? It's finding these higher\nlevel encoding structures,",
    "start": "4422290",
    "end": "4429520"
  },
  {
    "text": "and it would probably say like,\nOK, these two are similar. So this is like idea number 2.",
    "start": "4429520",
    "end": "4435100"
  },
  {
    "text": "So when you are\ntraining like models, you can probably\nuse MEA for keeping",
    "start": "4435100",
    "end": "4440863"
  },
  {
    "text": "track of like distortion\nthat you don't really get very far away in terms\nof the actual pixel values. And then you can also use some\ndeep embeddings like LPIPS",
    "start": "4440863",
    "end": "4448810"
  },
  {
    "text": "to keep track of\nperceptually, right? So at that point, you're keeping\ntrack of the distributions, Px",
    "start": "4448810",
    "end": "4454820"
  },
  {
    "text": "and Px dash.  And then like OK, if you are\nnot really happy with this,",
    "start": "4454820",
    "end": "4461410"
  },
  {
    "text": "you can do even more stuff. For example, maybe\nyou can use like-- it's fine.",
    "start": "4461410",
    "end": "4467260"
  },
  {
    "text": "If you're not aware,\ndon't worry about it, but if you have heard of\nGANs in your life, Generative Adversarial Networks,\nmaybe use some framework",
    "start": "4467260",
    "end": "4474159"
  },
  {
    "text": "like that to train\nnow instead of just your encoder and generator. You can also train\nlike a discriminator,",
    "start": "4474160",
    "end": "4480040"
  },
  {
    "text": "which now figures out whether I\nand I, I dash are safe or not. And in principle, what this\ndiscriminator GAN is doing",
    "start": "4480040",
    "end": "4485860"
  },
  {
    "text": "is exactly like the\nperceptual loss. It's basically trying to\nensure that I and I dash comes from the same probability\ndistribution, right?",
    "start": "4485860",
    "end": "4494470"
  },
  {
    "text": "So these are like various ideas. People try to do a mix of these. I don't have slide on that.",
    "start": "4494470",
    "end": "4500560"
  },
  {
    "text": "I know. But more recently\nlike there have been even more amazing\nworks with like now,",
    "start": "4500560",
    "end": "4506890"
  },
  {
    "text": "we know past year. Literally past year\nwhen we were doing this, like generative modeling has\nreally grown leaps and bounds",
    "start": "4506890",
    "end": "4515290"
  },
  {
    "text": "in terms of what you\ncan generate from what kind of distributions. You can generate\nfake symbols, right?",
    "start": "4515290",
    "end": "4520930"
  },
  {
    "text": "And so that even more so brings\nthis idea of perception, right? Like this PX, PX dash term\ninto the center of compression.",
    "start": "4520930",
    "end": "4529180"
  },
  {
    "text": "A lot of people are trying\nto now use deep neural nets, like deep stable diffusion, and\nyour favorite these days is.",
    "start": "4529180",
    "end": "4538210"
  },
  {
    "text": "LLMS for generation\nmaybe for text. So like Shubham showed\nsomething, right? So there, we were\ndoing lossless,",
    "start": "4538210",
    "end": "4544870"
  },
  {
    "text": "but now, you can also\nthink how that can be exploited for lossy, right? Like you can just keep the\noutput of the LLM as is.",
    "start": "4544870",
    "end": "4552730"
  },
  {
    "text": "And it's a very hot\narea in terms of like",
    "start": "4552730",
    "end": "4558070"
  },
  {
    "text": "even in the last year, right? So how you can maybe use\nall these advancements towards compression. LLMs seems to have the\nknowledge of the world,",
    "start": "4558070",
    "end": "4564880"
  },
  {
    "text": "but like how do we\nactually get it to a point so that we can actually\nuse that for compression",
    "start": "4564880",
    "end": "4570880"
  },
  {
    "text": "and get really low bit rates\nfor the respective things? Right? So I think it's the same idea\nin images but with respect",
    "start": "4570880",
    "end": "4577720"
  },
  {
    "text": "to now like stable diffusion. It's the exact same thing or if\nyou know about multimodal, clip models, DALL-E, things\nlike these, so all",
    "start": "4577720",
    "end": "4585160"
  },
  {
    "text": "of these can in terms. Like if you are more interested\nin the practical angle of this,",
    "start": "4585160",
    "end": "4590650"
  },
  {
    "text": "like RDP takes center\nstage there using these models for example.",
    "start": "4590650",
    "end": "4595990"
  },
  {
    "text": "OK. So yeah, so there is\nlike for example this--",
    "start": "4595990",
    "end": "4602980"
  },
  {
    "text": "so I just talked about GAN. There is this paper\ncalled HiFiC, see, which you should check out.",
    "start": "4602980",
    "end": "4608110"
  },
  {
    "text": "Don't worry about this\nplot, but basically, it uses conditional GANs,\nplus LPIPS and loss.",
    "start": "4608110",
    "end": "4613630"
  },
  {
    "text": "And it achieve like state of\nthe art 2 years ago, right? So the only thing, again like\nterms, which you probably",
    "start": "4613630",
    "end": "4620590"
  },
  {
    "text": "are now more comfortable,\nat least hearing or know the resources where\nto get go learn more from,",
    "start": "4620590",
    "end": "4625810"
  },
  {
    "text": "are at the center stage\nin very recent years being used in very interesting ways.",
    "start": "4625810",
    "end": "4631800"
  },
  {
    "text": "And so yeah, I hope\nlike today's lecture, you really got the idea that--",
    "start": "4631800",
    "end": "4637100"
  },
  {
    "text": "we talk a lot about engineering. But a lot of neuroscience\nand psycho visual aspects",
    "start": "4637100",
    "end": "4644090"
  },
  {
    "text": "are actually at the center\nof engineering and designing these systems. And it's really important\nto understand them",
    "start": "4644090",
    "end": "4650060"
  },
  {
    "text": "if we are designing\nlike lossy compressors. So we talked about\nimages in detail. That has been center.",
    "start": "4650060",
    "end": "4655070"
  },
  {
    "text": "We touched a little\nbit on audio. We showed a very\nbasic compressor. We talked about 44.1\nkilo, whatever it is.",
    "start": "4655070",
    "end": "4661639"
  },
  {
    "text": "But in future, there are\nnew and new data modalities, which are coming up. Like compression is\nnot limited to image",
    "start": "4661640",
    "end": "4667400"
  },
  {
    "text": "videos or audio, right? There is for example VR stuff. There is genomics.",
    "start": "4667400",
    "end": "4672620"
  },
  {
    "text": "There is many other\nmodalities of sensor data. And all of this data is being\nused for some application.",
    "start": "4672620",
    "end": "4680480"
  },
  {
    "text": "And really, what I\nwant to highlight at the end of this\nclass, it's not just about human perception. At the end of the day,\nif you are designing",
    "start": "4680480",
    "end": "4687170"
  },
  {
    "text": "a lossy compressor\nfor any niche area, it's very important to\nunderstand what that data is",
    "start": "4687170",
    "end": "4693050"
  },
  {
    "text": "and what application it is\nbeing used so you don't just use design something for MSE.",
    "start": "4693050",
    "end": "4699750"
  },
  {
    "text": "But be more smart and\nintelligent about what other access you\ncan exploit, which typically gives like huge\ngains in specific applications.",
    "start": "4699750",
    "end": "4708770"
  },
  {
    "text": "So yeah, this is it. Thank you.",
    "start": "4708770",
    "end": "4714340"
  },
  {
    "start": "4714340",
    "end": "4719000"
  }
]
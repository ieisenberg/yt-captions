[
  {
    "text": "this is kind of my signature i've created i've created this um talk within",
    "start": "10960",
    "end": "17039"
  },
  {
    "text": "the last year um because believe it or not i've been in this space for about six or seven years",
    "start": "17039",
    "end": "22240"
  },
  {
    "text": "but i think the last year was has been a year of of codifying all of",
    "start": "22240",
    "end": "28480"
  },
  {
    "text": "the things that i've learned uh as a as a designer a design researcher and a design leader in the mlai space so",
    "start": "28480",
    "end": "36160"
  },
  {
    "text": "uh so i've been trying to put it into to something that's concrete and",
    "start": "36160",
    "end": "42079"
  },
  {
    "text": "frameworks that people can understand about what's different about this field",
    "start": "42079",
    "end": "47280"
  },
  {
    "text": "and how we're addressing some of the um some of the not so nice outcomes that",
    "start": "47280",
    "end": "52559"
  },
  {
    "text": "come from uh humans engaging with machines so hopefully at the end of this you can walk away",
    "start": "52559",
    "end": "58480"
  },
  {
    "text": "with a little idea of what design in an automated future uh i at least from my point of view will look",
    "start": "58480",
    "end": "65280"
  },
  {
    "text": "like and i call it this the birth of ai ml design because i really do feel like",
    "start": "65280",
    "end": "70320"
  },
  {
    "text": "we are crossing this the the the line into a new way of doing design",
    "start": "70320",
    "end": "76560"
  },
  {
    "text": "um that is different than interaction design and different than the industrial design and all the other design",
    "start": "76560",
    "end": "84240"
  },
  {
    "text": "disciplines that we've had before so uh this is my design ethic statement this",
    "start": "84240",
    "end": "91119"
  },
  {
    "text": "is my design ethic statement uh i make my students write one and i had a student say well what's yours and so i",
    "start": "91119",
    "end": "97680"
  },
  {
    "text": "had to write my own uh i was a journalist for a long time and when you join when you become a journalist you",
    "start": "97680",
    "end": "103600"
  },
  {
    "text": "join a organization called the society professional journalist and it's kind of like a place where you learn how all the",
    "start": "103600",
    "end": "109759"
  },
  {
    "text": "moral codes that you're supposed to follow in your profession and i was when i became a designer i was kind of",
    "start": "109759",
    "end": "115040"
  },
  {
    "text": "waiting for that to happen like i was waiting for my um you know uh design ethics uh guidebook and and and",
    "start": "115040",
    "end": "122960"
  },
  {
    "text": "frameworks and and and card you know and none came so uh i started on a journey",
    "start": "122960",
    "end": "129520"
  },
  {
    "text": "with my students actually to create my own design ethics principle um and",
    "start": "129520",
    "end": "135200"
  },
  {
    "text": "framework and so this is mine to amplify the beauty of humanity with design while voting practices that exploit its",
    "start": "135200",
    "end": "141280"
  },
  {
    "text": "fragility so if you don't have one i encourage you to get on that journey to create one for",
    "start": "141280",
    "end": "147599"
  },
  {
    "text": "yourself about me uh yes said uh i",
    "start": "147599",
    "end": "153200"
  },
  {
    "text": "i am head of uh head of i'm a head of design for machine learning and responsible ai and and",
    "start": "153200",
    "end": "160640"
  },
  {
    "text": "machine learning governance and i want to kind of unpack that because i think my my job kind of tells us where we are",
    "start": "160640",
    "end": "168160"
  },
  {
    "text": "with machine learning and ai design right now um uh it used to be just",
    "start": "168160",
    "end": "173599"
  },
  {
    "text": "the the technology right of of how we create models and how we create uh ai",
    "start": "173599",
    "end": "178720"
  },
  {
    "text": "and ml and now people are really thinking about like how do we explain those creations and so you have",
    "start": "178720",
    "end": "184239"
  },
  {
    "text": "something like what's called um machine learning governance where where you have",
    "start": "184239",
    "end": "189360"
  },
  {
    "text": "separate a separate process where you kind of analyze and uh and audit your machine learning um creations to to look",
    "start": "189360",
    "end": "197120"
  },
  {
    "text": "for things like bias and and um discrimination as well as equity and and some other",
    "start": "197120",
    "end": "203280"
  },
  {
    "text": "things and then and then you have what's called responsible ai which is this whole other field of outside of",
    "start": "203280",
    "end": "210560"
  },
  {
    "text": "compliance and governance um how how should these uh machine models",
    "start": "210560",
    "end": "216959"
  },
  {
    "text": "uh interact with with the human population with society with individuals with communities and so i am",
    "start": "216959",
    "end": "224319"
  },
  {
    "text": "and then and then i i'm on a metal level with my team we actually are the design team for the machine learning platforms",
    "start": "224319",
    "end": "232000"
  },
  {
    "text": "so our users are data scientists and model developers so we design for them",
    "start": "232000",
    "end": "237599"
  },
  {
    "text": "so our research is really about how they do their processes and the world domination plan is i get to embed rai",
    "start": "237599",
    "end": "246400"
  },
  {
    "text": "and equity principles into the model development process right so uh i really feel very lucky to be able",
    "start": "246400",
    "end": "252959"
  },
  {
    "text": "to do that my jam has always been into in design i love rapid prototyping i've",
    "start": "252959",
    "end": "258479"
  },
  {
    "text": "always kind of fallen and i've fallen into enterprise software design so",
    "start": "258479",
    "end": "264080"
  },
  {
    "text": "i've always designed system architectures and software like apis and databases and all that kind of stuff and",
    "start": "264080",
    "end": "270560"
  },
  {
    "text": "i think that allowed me kind of like to understand the machine learning uh and",
    "start": "270560",
    "end": "275600"
  },
  {
    "text": "ai systems design kind of framework a little bit better i also am an adjunct",
    "start": "275600",
    "end": "280639"
  },
  {
    "text": "professor teaching designing ethical ai at the school of design in depaul here in chicago",
    "start": "280639",
    "end": "286320"
  },
  {
    "text": "so this is me i have 30 years this is me as a baby and me in fourth grade and then all the way up i used to work at",
    "start": "286320",
    "end": "293120"
  },
  {
    "text": "ideo i used to work at microsoft i worked as a journalist both domestic and internationally",
    "start": "293120",
    "end": "300880"
  },
  {
    "text": "i was like uh doing anthropology research like i've had a",
    "start": "300880",
    "end": "306000"
  },
  {
    "text": "really varied background i've also worked with companies in all kinds of industries",
    "start": "306000",
    "end": "311280"
  },
  {
    "text": "financial healthcare human resources automotive uh worked on self-driving cars and",
    "start": "311280",
    "end": "317120"
  },
  {
    "text": "non-profit and government industries so i have a really wide um i have a ride narrative around design",
    "start": "317120",
    "end": "323759"
  },
  {
    "text": "and a ride narrative around technology um and i i have a ba in communications",
    "start": "323759",
    "end": "329840"
  },
  {
    "text": "and and english and ms and computer science so um i think i wrote this",
    "start": "329840",
    "end": "336560"
  },
  {
    "text": "in interactions magazine last year when when they lovingly asked me to write a",
    "start": "336560",
    "end": "341680"
  },
  {
    "text": "piece about what does design look in the future um that i feel like as a as designers",
    "start": "341680",
    "end": "347919"
  },
  {
    "text": "our roles will be to determine what not to design in a quest to preserve human",
    "start": "347919",
    "end": "352960"
  },
  {
    "text": "culture values and rituals in our future world i do believe we will get to a",
    "start": "352960",
    "end": "358080"
  },
  {
    "text": "point where machines will be able to do almost anything that humans can do i won't say everything that's singularity",
    "start": "358080",
    "end": "364479"
  },
  {
    "text": "but pretty close and and i feel like as designers we're",
    "start": "364479",
    "end": "369520"
  },
  {
    "text": "probably in a unique position to kind of hold up the stop and wait sign",
    "start": "369520",
    "end": "374880"
  },
  {
    "text": "and i think if we don't take that responsibility we will run the danger of",
    "start": "374880",
    "end": "380319"
  },
  {
    "text": "creating products and platforms and services that actually are are",
    "start": "380319",
    "end": "386080"
  },
  {
    "text": "antithetical to human human nature and human needs and and we don't want that",
    "start": "386080",
    "end": "392160"
  },
  {
    "text": "so here are some level setting definitions i like to start off with so everybody understands what point of view",
    "start": "392160",
    "end": "397759"
  },
  {
    "text": "i'm coming from uh and my mental model uh this is my favorite definition of design it comes from uh design",
    "start": "397759",
    "end": "404240"
  },
  {
    "text": "revolutionary victor papanick and if you haven't read design for the real world please do um design is the conscious and",
    "start": "404240",
    "end": "410720"
  },
  {
    "text": "intuitive effort to impose meaningful order to chaos so again i'm putting agency on design to to have a",
    "start": "410720",
    "end": "417400"
  },
  {
    "text": "responsibility to um to make sure that we are imposing meaningful order to",
    "start": "417400",
    "end": "423759"
  },
  {
    "text": "something that is chaotic meaning a lot of problems and issues in the world",
    "start": "423759",
    "end": "429280"
  },
  {
    "text": "so the first chapter when you want to understand machine learning and ai design is you have to understand data um",
    "start": "429280",
    "end": "436319"
  },
  {
    "text": "and from the oxford dictionary uh or data as people say but when i say data i",
    "start": "436319",
    "end": "442319"
  },
  {
    "text": "always think of star trek so um i just say data instead data is things known or",
    "start": "442319",
    "end": "448720"
  },
  {
    "text": "assumed as facts making the basis of reasoning or calculation i love that fact that it says known or assumed as",
    "start": "448720",
    "end": "455360"
  },
  {
    "text": "because i think it really kind of sets the spectrum of what data could be um",
    "start": "455360",
    "end": "461280"
  },
  {
    "text": "i this is this is my t-shirt mantra uh i think i'm gonna get online and create a",
    "start": "461280",
    "end": "467599"
  },
  {
    "text": "whole fleet of these i usually make people in the audience repeat this so that people really understand that data",
    "start": "467599",
    "end": "474560"
  },
  {
    "text": "is created by people and people create data we as humans have a long history of data",
    "start": "474560",
    "end": "480720"
  },
  {
    "text": "we have a long history of i identity being formatted in data how tall are you",
    "start": "480720",
    "end": "486960"
  },
  {
    "text": "uh when were you born uh how many siblings do you have like all of that is data right like who you are as a person",
    "start": "486960",
    "end": "493440"
  },
  {
    "text": "is made up of data and the reason why i like to start with this is especially when i'm talking to data scientists and",
    "start": "493440",
    "end": "500240"
  },
  {
    "text": "technologists is the idea that when we're using data to create these amazing complex models",
    "start": "500240",
    "end": "507680"
  },
  {
    "text": "that the we're using identity we're using people right like we're",
    "start": "507680",
    "end": "513120"
  },
  {
    "text": "we're not just using ones and zeros and i think that's really important to set the stage right off the bat",
    "start": "513120",
    "end": "519518"
  },
  {
    "text": "and as designers who are human-centered designers the idea that we belong in those rooms when things are being",
    "start": "519519",
    "end": "526560"
  },
  {
    "text": "decided because we are the people experts and so if anything is being created with data then that means it's",
    "start": "526560",
    "end": "532000"
  },
  {
    "text": "being created with people and then that means we belong so does anybody know what this is",
    "start": "532000",
    "end": "539360"
  },
  {
    "text": "you guys are smart so you probably already know what this is anybody i don't know",
    "start": "539360",
    "end": "544959"
  },
  {
    "text": "um i don't know if you can talk to the chat or not but um",
    "start": "544959",
    "end": "550320"
  },
  {
    "text": "this is what's known as um uh a shirley card and i want you guys to look at this",
    "start": "550320",
    "end": "557920"
  },
  {
    "text": "little label right here it says normal what what does what does that make you",
    "start": "557920",
    "end": "564640"
  },
  {
    "text": "feel when you look at this and you see that word normal",
    "start": "564640",
    "end": "570720"
  },
  {
    "text": "i just want you to think about that a little bit and maybe we can talk about it later",
    "start": "570800",
    "end": "577440"
  },
  {
    "text": "christina horrified yeah as a black woman it makes me feel",
    "start": "577440",
    "end": "582720"
  },
  {
    "text": "excluded right like it makes me feel like i'm not normal because i certainly don't look like shirley",
    "start": "582720",
    "end": "589120"
  },
  {
    "text": "so shirley cards are historical in photography kodak started it kodak was",
    "start": "589120",
    "end": "595600"
  },
  {
    "text": "the first company to go from black and white to color photography and i don't know how much you know about",
    "start": "595600",
    "end": "601920"
  },
  {
    "text": "photography but i used to work at a newspaper back that was those things that they used to",
    "start": "601920",
    "end": "607120"
  },
  {
    "text": "deliver at your homes i know you guys don't have those but those used to be printed not digital and when you're",
    "start": "607120",
    "end": "613519"
  },
  {
    "text": "doing a newspaper you had to color correct right because of you're using plates that were",
    "start": "613519",
    "end": "619760"
  },
  {
    "text": "combining colors to make cues rather than you know having it digitized and",
    "start": "619760",
    "end": "625200"
  },
  {
    "text": "all that good stuff so you had to make sure that when you were taking a color photo that it was perfectly what they",
    "start": "625200",
    "end": "632000"
  },
  {
    "text": "call white balance a very interesting uh word there as well",
    "start": "632000",
    "end": "637120"
  },
  {
    "text": "so when you were taking a photo you had to like actually put a white sheet of paper in front of the camera lens to",
    "start": "637120",
    "end": "643920"
  },
  {
    "text": "make sure that the photo was balanced correctly so that the hues that would come out of your color photo was where",
    "start": "643920",
    "end": "650720"
  },
  {
    "text": "the right hues were normal but the problem was when kodak decided that they",
    "start": "650720",
    "end": "656480"
  },
  {
    "text": "were going to go from black and white photography to um to color and they had to create uh a",
    "start": "656480",
    "end": "664320"
  },
  {
    "text": "balancing um uh spectrum for that so that they're um so that the technology could recognize",
    "start": "664320",
    "end": "671279"
  },
  {
    "text": "what was normal and what was to the left or to the right of normal lighter or darker um",
    "start": "671279",
    "end": "676800"
  },
  {
    "text": "the this one guy this one engineer had a calendar and it had this woman on it and",
    "start": "676800",
    "end": "681920"
  },
  {
    "text": "he thought this was this would be the way that we could calibrate all color photos um and well",
    "start": "681920",
    "end": "689519"
  },
  {
    "text": "what happened was when they used a woman who was a white woman to normalize color",
    "start": "689519",
    "end": "695519"
  },
  {
    "text": "photography everybody who wasn't her skin color who was darker than her",
    "start": "695519",
    "end": "701600"
  },
  {
    "text": "was was basically made invisible so when you look at old photographs polaroid kodak",
    "start": "701600",
    "end": "708240"
  },
  {
    "text": "whatever this is adopted around the industry you would look at i would look at photographs when i was growing up and",
    "start": "708240",
    "end": "713680"
  },
  {
    "text": "half of my family you couldn't see because they were so dark um and you would think like okay uh vox",
    "start": "713680",
    "end": "721360"
  },
  {
    "text": "media did a whole piece on this it was really great you were thinking like okay we've advanced in technology",
    "start": "721360",
    "end": "727279"
  },
  {
    "text": "you know light years from the shirley cards they they really don't do that today",
    "start": "727279",
    "end": "735680"
  },
  {
    "text": "well um a legacy of shirley cards is bias and facial recognition so you take",
    "start": "736160",
    "end": "742079"
  },
  {
    "text": "photography right and so it's biased against darker skin and so people become",
    "start": "742079",
    "end": "747279"
  },
  {
    "text": "almost invisible when trying to replicate that in print right now you move to things like led lights right",
    "start": "747279",
    "end": "754720"
  },
  {
    "text": "what their color balance they're color balanced the same way right it's institutionalized and so now you go into",
    "start": "754720",
    "end": "762160"
  },
  {
    "text": "a hotel and i put my hands under a faucet right and and it doesn't",
    "start": "762160",
    "end": "768880"
  },
  {
    "text": "recognize my dark skin but my white friend they do it and it recognizes it and so the water",
    "start": "768880",
    "end": "774800"
  },
  {
    "text": "comes out and now okay so that's an led and then now you get to uh facial recognition",
    "start": "774800",
    "end": "781440"
  },
  {
    "text": "software which by the way is about ninety percent accurate but that 10 percent",
    "start": "781440",
    "end": "786560"
  },
  {
    "text": "black females like myself have a have a huge problem being recognized by facial recognition technology and all of that",
    "start": "786560",
    "end": "793920"
  },
  {
    "text": "all of that lineage from the shirley cards all the way to today like google",
    "start": "793920",
    "end": "799200"
  },
  {
    "text": "just released a new version of their phone other of the of the camera phone",
    "start": "799200",
    "end": "806320"
  },
  {
    "text": "that can now quote unquote recognize um darker skin um",
    "start": "806320",
    "end": "812240"
  },
  {
    "text": "that's been a long time in the making but black people have been around forever and so i i use this kind of like",
    "start": "812240",
    "end": "819519"
  },
  {
    "text": "make a a very um pointed example of we only measure what someone says matter so",
    "start": "819519",
    "end": "825920"
  },
  {
    "text": "data define is biased data so if anybody tells you that any ml or ai algorithm is",
    "start": "825920",
    "end": "832560"
  },
  {
    "text": "not biased i i just have to challenge that because our institutional and",
    "start": "832560",
    "end": "838399"
  },
  {
    "text": "systematic racism sexism and ableism and a lot of things go into who we are",
    "start": "838399",
    "end": "844639"
  },
  {
    "text": "and who we define at what matters and what kind of data we want to use and",
    "start": "844639",
    "end": "849920"
  },
  {
    "text": "therefore really kind of starts off our our process and machine",
    "start": "849920",
    "end": "855920"
  },
  {
    "text": "learning ai in a biased narrow view it's not like black people weren't",
    "start": "855920",
    "end": "861440"
  },
  {
    "text": "around when google and apple and other technology companies created",
    "start": "861440",
    "end": "867920"
  },
  {
    "text": "uh camera phones right um it's just that we weren't counted in in the color",
    "start": "867920",
    "end": "873680"
  },
  {
    "text": "spectrum and so we only measure what someone says matters right and if and if lgbtq people",
    "start": "873680",
    "end": "882000"
  },
  {
    "text": "um if the u.s census decides that not marking that you are of",
    "start": "882000",
    "end": "889040"
  },
  {
    "text": "that that's part of your identity then then does that make you invisible you know it wasn't until this year the",
    "start": "889040",
    "end": "895279"
  },
  {
    "text": "u.s census even thought about um counting lgbtq people right so i think",
    "start": "895279",
    "end": "901519"
  },
  {
    "text": "it's really important as designers is if we want to kind of create human centered ai and ethical ai really got to start at",
    "start": "901519",
    "end": "909120"
  },
  {
    "text": "the beginning and the beginning is the data that is either omitted and not used",
    "start": "909120",
    "end": "915600"
  },
  {
    "text": "in models or used in a way that perpetuates systemic racism sexism and",
    "start": "915600",
    "end": "923680"
  },
  {
    "text": "and and um and ableism so this is part of my ten commandments",
    "start": "923680",
    "end": "929120"
  },
  {
    "text": "of mindful ai uh for us to remember that this is how we start off with these",
    "start": "929120",
    "end": "934880"
  },
  {
    "text": "systems we're using data that's biased because we defined it",
    "start": "934880",
    "end": "941600"
  },
  {
    "text": "same with fico scores right um capital one actually doesn't use fico scores we use a we we use we use information from",
    "start": "941600",
    "end": "948880"
  },
  {
    "text": "from the three um um credit viewers but we use it differently um and i think",
    "start": "948880",
    "end": "954560"
  },
  {
    "text": "it's really important that people understand that you don't have to fall",
    "start": "954560",
    "end": "959600"
  },
  {
    "text": "into these systematic um institutionalized data uh creation places you can you can",
    "start": "959600",
    "end": "967279"
  },
  {
    "text": "use data in a different way to be more fair and to be more equitable and i i",
    "start": "967279",
    "end": "973360"
  },
  {
    "text": "like to use the fico score because it's it's this was fico",
    "start": "973360",
    "end": "978480"
  },
  {
    "text": "was created by white engineer in 1958 to help banks",
    "start": "978480",
    "end": "984320"
  },
  {
    "text": "kind of decide credit worthiness right it's been the same formula i won't say the",
    "start": "984320",
    "end": "990720"
  },
  {
    "text": "same but mostly the same formula since 1958 and a lot of people don't like to mess with it because it has",
    "start": "990720",
    "end": "997120"
  },
  {
    "text": "institutional legacy which inherently has institutional bias i mean",
    "start": "997120",
    "end": "1002240"
  },
  {
    "text": "what was going on in 1958 redlining um people weren't getting mortgages",
    "start": "1002240",
    "end": "1008160"
  },
  {
    "text": "because of this their color their skin their sexuality um their religion um",
    "start": "1008160",
    "end": "1013440"
  },
  {
    "text": "there were a lot of things that were going on in 1958 that statistically we have not",
    "start": "1013440",
    "end": "1019040"
  },
  {
    "text": "vetted out of a system like fico",
    "start": "1019040",
    "end": "1024400"
  },
  {
    "text": "so i i have these examples is that data is the lifeblood of ml and ai if you",
    "start": "1024400",
    "end": "1031038"
  },
  {
    "text": "uh are looking to um make sure that human centered design",
    "start": "1031039",
    "end": "1036319"
  },
  {
    "text": "products that are being viewed about ml and ai are equitable and ethical and",
    "start": "1036319",
    "end": "1043839"
  },
  {
    "text": "take into account human needs all that you have to start with the data that goes into those systems",
    "start": "1043839",
    "end": "1049760"
  },
  {
    "text": "data and people are irrevocably linked so all all people create data and",
    "start": "1049760",
    "end": "1054960"
  },
  {
    "text": "keeping people in the forefront of data aggregation ensures more human intelligent product design",
    "start": "1054960",
    "end": "1060640"
  },
  {
    "text": "that is integral to ml and i without data there's no machine learning no artificial intelligence and it's",
    "start": "1060640",
    "end": "1066720"
  },
  {
    "text": "important that we as designers really understand how data is collected how it's cleaned and it's cleaned how it's",
    "start": "1066720",
    "end": "1073600"
  },
  {
    "text": "engineered and how it's transformed by data data scientists and model",
    "start": "1073600",
    "end": "1080080"
  },
  {
    "text": "developers to ensure human-centered ai and data practices ultimately dictate an",
    "start": "1080080",
    "end": "1086000"
  },
  {
    "text": "ai user experience so biased data creates bias machine learning models missing data creates bad machine",
    "start": "1086000",
    "end": "1092000"
  },
  {
    "text": "learning outcomes that affect people just disproportionately",
    "start": "1092000",
    "end": "1097120"
  },
  {
    "text": "in different ways and so ultimately a company's data practices will dictate whether it's a human-centered ai whether",
    "start": "1097120",
    "end": "1103600"
  },
  {
    "text": "it has a human-centered ai experience or outcome some terms i think you should be aware",
    "start": "1103600",
    "end": "1109760"
  },
  {
    "text": "of if you're not already uh if you want to go into this field is unstructured data this is data that isn't easily",
    "start": "1109760",
    "end": "1117360"
  },
  {
    "text": "labeled or stored or categorized which means we have more opportunities as humans to influence how that data is",
    "start": "1117360",
    "end": "1124480"
  },
  {
    "text": "engineered and read some examples include text and pdf images uh word documents then we have",
    "start": "1124480",
    "end": "1131600"
  },
  {
    "text": "structured data this is cleaner than raw data this has been labeled this has been categorized uh like speed limits right",
    "start": "1131600",
    "end": "1139520"
  },
  {
    "text": "things like that and it usually is ready for data analysis or visualization it's also i have a little stop sign here",
    "start": "1139520",
    "end": "1146480"
  },
  {
    "text": "because i think it's also an alert place with a structured data",
    "start": "1146480",
    "end": "1151520"
  },
  {
    "text": "it's also biased data because it comes because somebody has to label it and categorize it and give it meaning so",
    "start": "1151520",
    "end": "1158960"
  },
  {
    "text": "uh structured data goes from just kind of loose data that somebody right some",
    "start": "1158960",
    "end": "1164480"
  },
  {
    "text": "process uh categorizes it and then it becomes then it has meaning right and so",
    "start": "1164480",
    "end": "1170080"
  },
  {
    "text": "you have to really look at those meanings when when people structure data",
    "start": "1170080",
    "end": "1175440"
  },
  {
    "text": "um and then there's explicit data this is information that is provided intentionally by people so i sign in i",
    "start": "1175440",
    "end": "1182720"
  },
  {
    "text": "log up i fill out a registration form you know exactly why i'm putting that data in then there's implicit data this",
    "start": "1182720",
    "end": "1190240"
  },
  {
    "text": "is information not provided intentionally but gathered from available data streams either directly",
    "start": "1190240",
    "end": "1195919"
  },
  {
    "text": "or through analysis of explicit data so for example when you click a thumbs up it's implied that you like that content",
    "start": "1195919",
    "end": "1202960"
  },
  {
    "text": "right i also have red stops there because a",
    "start": "1202960",
    "end": "1208559"
  },
  {
    "text": "lot of implicit data is used to make what i call contextual leaps and without qualitative data to back behi to back",
    "start": "1208559",
    "end": "1216559"
  },
  {
    "text": "that up you don't really know what's happening when that data is created it's really important that data is contextual",
    "start": "1216559",
    "end": "1223440"
  },
  {
    "text": "it's not just something that you collect and then shove into a model right you really need to understand where that",
    "start": "1223440",
    "end": "1228880"
  },
  {
    "text": "data comes from and why it was created so facts to remember again all data is",
    "start": "1228880",
    "end": "1234400"
  },
  {
    "text": "created by people so uh don't divorce people from their data one of the biggest sins in unethical ai",
    "start": "1234400",
    "end": "1242880"
  },
  {
    "text": "or or what i would call um not human-centered ai is the sin of omission so creating a model that makes decisions",
    "start": "1242880",
    "end": "1251280"
  },
  {
    "text": "that has a lot of missing data so if the us census was to create a model to",
    "start": "1251280",
    "end": "1256720"
  },
  {
    "text": "decide um who in the lgbtq community could receive um",
    "start": "1256720",
    "end": "1263120"
  },
  {
    "text": "benefits for example i would i would i would question that because those folks weren't included",
    "start": "1263120",
    "end": "1269919"
  },
  {
    "text": "into uh census counts until this year so there's a lot of missing um",
    "start": "1269919",
    "end": "1276159"
  },
  {
    "text": "last year there's a lot of missing data variables there and then lastly and the",
    "start": "1276159",
    "end": "1281360"
  },
  {
    "text": "number one uh commandment from uh over ten commandments of of mindful",
    "start": "1281360",
    "end": "1288240"
  },
  {
    "text": "ai is that is not truth that is not the unbiased unchallenged input as advertised it's the version of the truth",
    "start": "1288240",
    "end": "1295200"
  },
  {
    "text": "that depends upon who's collecting engineering categorizing and using it data is always contextual it will never",
    "start": "1295200",
    "end": "1302320"
  },
  {
    "text": "stand on its own as as just truth because data is not true we have to work",
    "start": "1302320",
    "end": "1308720"
  },
  {
    "text": "to detect and reduce bias in it right that doesn't mean our machine learning models need to",
    "start": "1308720",
    "end": "1315840"
  },
  {
    "text": "uh perpetuate the historical biases that come with things like medical history or",
    "start": "1315840",
    "end": "1322000"
  },
  {
    "text": "medical experiments right lots of medical experiments have been done but most of them have been done on men",
    "start": "1322000",
    "end": "1328400"
  },
  {
    "text": "white men for sure so how do i know that experiments for for diabetes medication",
    "start": "1328400",
    "end": "1334400"
  },
  {
    "text": "for example which disproportionately affect people color is really the right",
    "start": "1334400",
    "end": "1340000"
  },
  {
    "text": "experiment for me to have good outcomes on uh on my on my health as a black",
    "start": "1340000",
    "end": "1345919"
  },
  {
    "text": "woman um i think ml designers who work with data scientists uh can help to",
    "start": "1345919",
    "end": "1351360"
  },
  {
    "text": "discover detect and reduce historical biases and data collection before it gets into the model that is so important",
    "start": "1351360",
    "end": "1358640"
  },
  {
    "text": "and that is part of machine learning experience design if you want to be a designer in this area your one of the",
    "start": "1358640",
    "end": "1364960"
  },
  {
    "text": "responsibilities is to is to see uh what is going into those models and",
    "start": "1364960",
    "end": "1370559"
  },
  {
    "text": "to detect if historical biases are being fed into a model i think designers could",
    "start": "1370559",
    "end": "1376960"
  },
  {
    "text": "pair you know our normal hcd methods with bias reducing mathematical methods",
    "start": "1376960",
    "end": "1382640"
  },
  {
    "text": "to reduce bias before it becomes a model outcome i think it's important to acknowledge",
    "start": "1382640",
    "end": "1387679"
  },
  {
    "text": "and announce make data inputs and model outcomes more of a glass box in a black box announce the ingredients",
    "start": "1387679",
    "end": "1395440"
  },
  {
    "text": "in the recipe that you're creating right uh that's that's has to do with explainable ai which is what we're",
    "start": "1395440",
    "end": "1401360"
  },
  {
    "text": "working on um be upfront about weak data and data engineering not all data is good data",
    "start": "1401360",
    "end": "1407440"
  },
  {
    "text": "and that's okay but you need to kind of like um say that and model outcomes when",
    "start": "1407440",
    "end": "1412720"
  },
  {
    "text": "you're evaluating model goodness and explainability is a legal requirement but traceable and publicly",
    "start": "1412720",
    "end": "1418880"
  },
  {
    "text": "audible without ip violation is a higher and better bar so i should be able to do an audit on your on your algorithm to",
    "start": "1418880",
    "end": "1425760"
  },
  {
    "text": "see how it made its decision because data is not true wrong data will",
    "start": "1425760",
    "end": "1431120"
  },
  {
    "text": "be occasionally used use this as an opportunity for design don't just abandon uh eliminating biases because we",
    "start": "1431120",
    "end": "1438880"
  },
  {
    "text": "know it's impossible um ml designers create experiences to help users provide",
    "start": "1438880",
    "end": "1444240"
  },
  {
    "text": "model feedback that's one of our biggest charges is to design ways for humans and",
    "start": "1444240",
    "end": "1449600"
  },
  {
    "text": "machines to have a reciprocal relationship when they're going through the machine learning powered experience",
    "start": "1449600",
    "end": "1457200"
  },
  {
    "text": "new better data helps to neutralize the effects of bad data so you can't just set it and forget it you can't just use",
    "start": "1457200",
    "end": "1464000"
  },
  {
    "text": "one data set over and over again there's a thing called model drift where the",
    "start": "1464000",
    "end": "1469279"
  },
  {
    "text": "longer a model is in play the more accurate it can become and you need to detect that",
    "start": "1469279",
    "end": "1477039"
  },
  {
    "text": "so this is a nerd alert now that we've gotten through data i i'm just going to go quickly about how it's used in mlnai",
    "start": "1477600",
    "end": "1484799"
  },
  {
    "text": "and then go into mlnai capabilities and give you kind of like an overview of",
    "start": "1484799",
    "end": "1490640"
  },
  {
    "text": "of of kind of the nerdy side of this world hopefully this won't be too boring",
    "start": "1490640",
    "end": "1495760"
  },
  {
    "text": "for you guys machine learning is a category of artificial intelligence in which computers learn to achieve a desired",
    "start": "1495760",
    "end": "1502559"
  },
  {
    "text": "outcome by applying problem solving rules automatically after being trained to do so",
    "start": "1502559",
    "end": "1509039"
  },
  {
    "text": "uh data is fuel for all machine learning models data scientists use algorithms to",
    "start": "1509039",
    "end": "1514480"
  },
  {
    "text": "use data to train and teach machines to solve problems through models algorithms are the lifeblood that",
    "start": "1514480",
    "end": "1520720"
  },
  {
    "text": "carries the fuel allowing machine learning models to sense act and learn",
    "start": "1520720",
    "end": "1526799"
  },
  {
    "text": "um i've been told that data scientists hate when people explain machine learning uh as replicating the human",
    "start": "1527600",
    "end": "1534640"
  },
  {
    "text": "brain um so i'm gonna have to switch that out um",
    "start": "1534640",
    "end": "1539840"
  },
  {
    "text": "but basically uh i'll go through the process of it and and then you'll see",
    "start": "1539840",
    "end": "1545279"
  },
  {
    "text": "uh how machine learning works um i think it's really important to",
    "start": "1545279",
    "end": "1551200"
  },
  {
    "text": "understand that we create algorithms every day if it's raining outside you have a rule that says i'll go grab a",
    "start": "1551200",
    "end": "1557760"
  },
  {
    "text": "hoodie or or umbrella that's just a simple rule that happens every time",
    "start": "1557760",
    "end": "1563279"
  },
  {
    "text": "right and and that's an algorithm socrates is said to have created the first algorithm right it's analog but",
    "start": "1563279",
    "end": "1569360"
  },
  {
    "text": "it's still an algorithm and this is how the human brain processes",
    "start": "1569360",
    "end": "1575919"
  },
  {
    "text": "information if you're aci you've seen this several times uh we have an",
    "start": "1575919",
    "end": "1580960"
  },
  {
    "text": "internal external stimuli it goes into our brain we reach back into our sensory information sometimes short term which",
    "start": "1580960",
    "end": "1588240"
  },
  {
    "text": "is always working sometimes long term which takes longer to get to thinking fast and slow those kinds of things we",
    "start": "1588240",
    "end": "1594720"
  },
  {
    "text": "recognize oh i've seen this before looks like a flower it's yellow must be",
    "start": "1594720",
    "end": "1600720"
  },
  {
    "text": "a dandelion or must be a flower that looks like that or it's red maybe it's a",
    "start": "1600720",
    "end": "1606480"
  },
  {
    "text": "rose those kinds of things and then we go through a series of thought process to decide how we're going to behave do",
    "start": "1606480",
    "end": "1613279"
  },
  {
    "text": "we pick it do we leave it alone do we walk by those kinds of things eerily familiar on the data on the",
    "start": "1613279",
    "end": "1620559"
  },
  {
    "text": "development of a model development process of a of a ml model",
    "start": "1620559",
    "end": "1627200"
  },
  {
    "text": "we get internal or external stimuli usually data from historical data or data from",
    "start": "1627200",
    "end": "1636080"
  },
  {
    "text": "ambient like the environment it comes in that data is validated and recognized um",
    "start": "1636080",
    "end": "1642480"
  },
  {
    "text": "it it the it's been trained on that data so the so the model kind of goes back",
    "start": "1642480",
    "end": "1648720"
  },
  {
    "text": "into its memory and say oh i recognize this data i've got rules to apply to that data and so it behaves in that",
    "start": "1648720",
    "end": "1656320"
  },
  {
    "text": "applicable way and then uh it as a as the data scientist goes through",
    "start": "1656320",
    "end": "1662159"
  },
  {
    "text": "the process it kind of repeats this process several times to get to a good",
    "start": "1662159",
    "end": "1668720"
  },
  {
    "text": "model goodness score meaning that the model is replicating the same the results that are asked for um at a high",
    "start": "1668720",
    "end": "1676240"
  },
  {
    "text": "accuracy rate um accuracy is only just one way to to to determine model goodness and then it",
    "start": "1676240",
    "end": "1683679"
  },
  {
    "text": "trains it again on data it's never seen before just to make sure that they can validate the results and then",
    "start": "1683679",
    "end": "1691039"
  },
  {
    "text": "it goes through the process again this is the model development process",
    "start": "1691039",
    "end": "1696240"
  },
  {
    "text": "machine learning is used in anomaly detection classification models netflix",
    "start": "1696240",
    "end": "1701279"
  },
  {
    "text": "i'm sorry classification models imaging dog or cat recommendation models netflix",
    "start": "1701279",
    "end": "1707200"
  },
  {
    "text": "what kind of movies do you like um these are examples of machine learning in the real world",
    "start": "1707200",
    "end": "1713679"
  },
  {
    "text": "and then artificial intelligence is just kind of like an umbrella of other ways to do machine learning and other types",
    "start": "1713679",
    "end": "1721679"
  },
  {
    "text": "of um algorithmic based uh technologies uh neural networks deep learning all",
    "start": "1721679",
    "end": "1727760"
  },
  {
    "text": "that um and the the way that i like to separate and this line is becoming more blurred",
    "start": "1727760",
    "end": "1735120"
  },
  {
    "text": "every day it used to be that machine learning just did historical data and artificial intelligence could do",
    "start": "1735120",
    "end": "1741520"
  },
  {
    "text": "real-time contextual data but now machine learning algorithms have become so strong they can do real-time uh",
    "start": "1741520",
    "end": "1748399"
  },
  {
    "text": "contextual data as well so um i don't actually know where the line is going",
    "start": "1748399",
    "end": "1753440"
  },
  {
    "text": "but now they have something called machine intelligence which is the intersection of artificial intelligence",
    "start": "1753440",
    "end": "1758880"
  },
  {
    "text": "and machine learning and these are what we call the deep neural networks and the deep learning networks that places like",
    "start": "1758880",
    "end": "1764720"
  },
  {
    "text": "google and and and facebook and and even some other places are getting into",
    "start": "1764720",
    "end": "1771279"
  },
  {
    "text": "um the i i think the key difference is is that artificial intelligence really",
    "start": "1771279",
    "end": "1776960"
  },
  {
    "text": "transforms the information right um it's transforming it so that decisions or",
    "start": "1776960",
    "end": "1783360"
  },
  {
    "text": "behaviors can be made um it's dynamic right computers are using their",
    "start": "1783360",
    "end": "1788559"
  },
  {
    "text": "environment to do tasks rather than depending on historical data",
    "start": "1788559",
    "end": "1794320"
  },
  {
    "text": "and when compared when paired with other technologies like iot ar vr you can",
    "start": "1794320",
    "end": "1800240"
  },
  {
    "text": "really have a machine see and hear and taste and smell like write poetry and",
    "start": "1800240",
    "end": "1805440"
  },
  {
    "text": "smell bread and taste sugar and see the drive it really kind of like",
    "start": "1805440",
    "end": "1810760"
  },
  {
    "text": "exponentially um creates new capabilities for ai and mo",
    "start": "1810760",
    "end": "1818159"
  },
  {
    "text": "um i like this this kind of like human machine kind of like",
    "start": "1818159",
    "end": "1823520"
  },
  {
    "text": "mirrored uh uh i a mirrored side on capabilities for ai and ml",
    "start": "1823520",
    "end": "1829679"
  },
  {
    "text": "um we see ai power machines can see automatic cars google search classification facial",
    "start": "1829679",
    "end": "1836000"
  },
  {
    "text": "recognitions we hear ai can uh use auditory sensors to to",
    "start": "1836000",
    "end": "1841200"
  },
  {
    "text": "replicate sound and to hear and to process sound we speak natural language",
    "start": "1841200",
    "end": "1846720"
  },
  {
    "text": "processing um um can and can have us have contextual conversations through",
    "start": "1846720",
    "end": "1853360"
  },
  {
    "text": "alexa's series cortana eno we act uh automation allows robots and dancing",
    "start": "1853360",
    "end": "1860080"
  },
  {
    "text": "robots from boston dynamics which are really my favorite um and we make decisions so recommendation models",
    "start": "1860080",
    "end": "1866240"
  },
  {
    "text": "netflix facebook twitter so we're getting close so some key i uh",
    "start": "1866240",
    "end": "1872240"
  },
  {
    "text": "ai terms algorithms machine learning deep learning uh does not require",
    "start": "1872240",
    "end": "1877440"
  },
  {
    "text": "step-by-step programming and can make decisions on its own um narrow ai is",
    "start": "1877440",
    "end": "1882799"
  },
  {
    "text": "also known as weak ai um this is where we are pretty much at",
    "start": "1882799",
    "end": "1888399"
  },
  {
    "text": "uh and then there's generative ai i had this does not exist but it does this scan this is when you see those really",
    "start": "1888399",
    "end": "1894799"
  },
  {
    "text": "amazing like art replicas that um that ai can generate without ever going to",
    "start": "1894799",
    "end": "1900799"
  },
  {
    "text": "art school it's kind of interesting if you've ever seen it and then of course ai singularity and this",
    "start": "1900799",
    "end": "1906960"
  },
  {
    "text": "is really when ai machines become self-aware this is the stuff of you know",
    "start": "1906960",
    "end": "1912080"
  },
  {
    "text": "irobot and uh octavia butler and some other some other folks",
    "start": "1912080",
    "end": "1917519"
  },
  {
    "text": "now i'm fairly certain this does not exist but i'm not gonna you know bet the farm on it",
    "start": "1917519",
    "end": "1923760"
  },
  {
    "text": "this is all how we use ai in the real world it's everywhere i i think uh um",
    "start": "1923760",
    "end": "1929919"
  },
  {
    "text": "uh there's a quote that like 75 of of americans have some kind of ai powered",
    "start": "1929919",
    "end": "1936960"
  },
  {
    "text": "um device or product or service um these are the capabilities",
    "start": "1936960",
    "end": "1943840"
  },
  {
    "text": "and i think it's really important to know the limitations as designers this is where we're going to spend most of",
    "start": "1943840",
    "end": "1949200"
  },
  {
    "text": "our time uh which is kind of a bummer we will be the negative nancy right like we are",
    "start": "1949200",
    "end": "1954720"
  },
  {
    "text": "definitely going to be like yes hey i could do that but should it you know um no data no dice right so um when i think",
    "start": "1954720",
    "end": "1963440"
  },
  {
    "text": "about the the right applicability or desirability of ai i think about what",
    "start": "1963440",
    "end": "1968799"
  },
  {
    "text": "data is it going to be fueled upon and if there's missing data categories",
    "start": "1968799",
    "end": "1975279"
  },
  {
    "text": "then i have to think it's kind of suspect uh garbage in garbage out i also think about ai and ml being applied to",
    "start": "1975279",
    "end": "1982799"
  },
  {
    "text": "systematic and um to being applied to systems that have systematic racism in them like law",
    "start": "1982799",
    "end": "1990080"
  },
  {
    "text": "enforcement right it's a red flag to apply ai and ml to a",
    "start": "1990080",
    "end": "1996559"
  },
  {
    "text": "system that has systematic problems with its data including law enforcement hr is",
    "start": "1996559",
    "end": "2002799"
  },
  {
    "text": "another space um there are a lot of different places that you have to be really careful when you're applying ml",
    "start": "2002799",
    "end": "2009039"
  },
  {
    "text": "and ai nuance is the enemy of machine learning ai like it's very binary but but",
    "start": "2009039",
    "end": "2015519"
  },
  {
    "text": "individuals aren't right like we're we're intersectional human beings and so we really need to really kind of uh",
    "start": "2015519",
    "end": "2022159"
  },
  {
    "text": "scrutinize when we're using ml and ai for human engagement and ml and ai's rep",
    "start": "2022159",
    "end": "2027519"
  },
  {
    "text": "is meant to replicate human rationality but in reality humans are keenly irrational",
    "start": "2027519",
    "end": "2033840"
  },
  {
    "text": "so this is just an example of ai smelling",
    "start": "2035919",
    "end": "2041679"
  },
  {
    "text": "a friend of mine who i worked at when microsoft built this uh smart device to",
    "start": "2041679",
    "end": "2046720"
  },
  {
    "text": "smell uh he he's he's parisian uh french same as benjamin cave and he wanted a",
    "start": "2046720",
    "end": "2053520"
  },
  {
    "text": "better way to see when his bread was uh uh",
    "start": "2053520",
    "end": "2058720"
  },
  {
    "text": "was um uh ready for i got uh slipping ready for for baking a proof proofing",
    "start": "2058720",
    "end": "2065679"
  },
  {
    "text": "yeah and he developed a way he had a tiny ml and he had a raspberry pie and he put it",
    "start": "2065679",
    "end": "2071440"
  },
  {
    "text": "together and and people are like oh wow how can ai smell well smells have a combination of",
    "start": "2071440",
    "end": "2077760"
  },
  {
    "text": "chemicals right that is that can be uh uh numerous right like you you can have",
    "start": "2077760",
    "end": "2084320"
  },
  {
    "text": "certain kinds of combinations that creates things that uh that you can smell and so once you feed those into a",
    "start": "2084320",
    "end": "2092320"
  },
  {
    "text": "microcontroller that has an ai model development component the the",
    "start": "2092320",
    "end": "2097839"
  },
  {
    "text": "the smart device can can detect different uh nuances in in the numerical",
    "start": "2097839",
    "end": "2104079"
  },
  {
    "text": "uh makeup of the smell so now he built something that can smell different whiskeys it can smell coffee it can",
    "start": "2104079",
    "end": "2111119"
  },
  {
    "text": "smell bread it's it's a pretty cool thing and a fourteen-year-old used his uh",
    "start": "2111119",
    "end": "2116560"
  },
  {
    "text": "invention to uh help build something that could detect different smells uh and illnesses",
    "start": "2116560",
    "end": "2123680"
  },
  {
    "text": "it was kind of interesting so what does all this mean i think uh",
    "start": "2123680",
    "end": "2128960"
  },
  {
    "text": "quickly here i think it means we have to redefine what design and research is in",
    "start": "2128960",
    "end": "2134160"
  },
  {
    "text": "an automated future um and here's my why for that and i'm",
    "start": "2134160",
    "end": "2139359"
  },
  {
    "text": "totally with challenged on this but over the years i've come to say that we",
    "start": "2139359",
    "end": "2145520"
  },
  {
    "text": "can't do things and design and research the way that we've done an interaction design if we want to create better human",
    "start": "2145520",
    "end": "2151680"
  },
  {
    "text": "centered ai products so the current technology we have has a user who controls the device it's usually in a",
    "start": "2151680",
    "end": "2159680"
  },
  {
    "text": "single agency sometimes it's a communal thing but mostly it's like me and my my my iphone or me and my controller or",
    "start": "2159680",
    "end": "2166960"
  },
  {
    "text": "me and my television or whatever we're doing the interaction is usually one way even",
    "start": "2166960",
    "end": "2172000"
  },
  {
    "text": "if it's in a group way the machine is interacting with me in a way uh",
    "start": "2172000",
    "end": "2177599"
  },
  {
    "text": "it's usually a one-way street um technology is task based right i want",
    "start": "2177599",
    "end": "2182880"
  },
  {
    "text": "to do this so i'm using the technology to do x and it has affordances uh all of",
    "start": "2182880",
    "end": "2189200"
  },
  {
    "text": "my screens are looking the same i know where the exit button is it's it's pretty familiar to me",
    "start": "2189200",
    "end": "2195440"
  },
  {
    "text": "even if i've never seen this mobile device before i can probably figure it out right because the device interacts with me in",
    "start": "2195440",
    "end": "2202800"
  },
  {
    "text": "the same consistent way and it's static right the device performs tasks in the same way it",
    "start": "2202800",
    "end": "2209040"
  },
  {
    "text": "doesn't really change it yes there's updates but you know i i know i'm gonna push a button right",
    "start": "2209040",
    "end": "2215760"
  },
  {
    "text": "i think with automated or intelligent system technology the difference is the user and machine can both be in control",
    "start": "2215760",
    "end": "2222160"
  },
  {
    "text": "they can be in control simultaneously they can be in control at different times and that presents a different flow",
    "start": "2222160",
    "end": "2229599"
  },
  {
    "text": "for experience design uh the context of use is multi-agency so you have the user you have the device",
    "start": "2229599",
    "end": "2236640"
  },
  {
    "text": "who are both sentient but you also have an ecosystem of other devices that can talk and engage and have relationships",
    "start": "2236640",
    "end": "2244320"
  },
  {
    "text": "so you have a self-driving car and the and the driver you have another self-driving car and driver and there's",
    "start": "2244320",
    "end": "2250160"
  },
  {
    "text": "the ability for them to all you know kind of have engagement in this",
    "start": "2250160",
    "end": "2255280"
  },
  {
    "text": "in this intelligent ecosystem interaction is is at least two-way right",
    "start": "2255280",
    "end": "2260400"
  },
  {
    "text": "like i i can talk to the machine and it can talk back to me um with with a",
    "start": "2260400",
    "end": "2265440"
  },
  {
    "text": "sentient understanding of what i'm saying um technology use is decision based",
    "start": "2265440",
    "end": "2271280"
  },
  {
    "text": "right so so the machine exists to make decisions right not just to do tasks",
    "start": "2271280",
    "end": "2277280"
  },
  {
    "text": "um and technology affordability can change over time right so when i first get my self-driving car i may",
    "start": "2277280",
    "end": "2284560"
  },
  {
    "text": "want to restrict a lot of experiences with it because i don't trust it but after i've been driving this car for a",
    "start": "2284560",
    "end": "2290240"
  },
  {
    "text": "while i may i may want to change that spectrum of of of autonomy for the car",
    "start": "2290240",
    "end": "2296880"
  },
  {
    "text": "um so the affordance can change over time so what does that mean for an experienced designer",
    "start": "2296880",
    "end": "2302800"
  },
  {
    "text": "and technology is dynamic the machine learns and performs differently with new knowledge and for that means my",
    "start": "2302800",
    "end": "2310000"
  },
  {
    "text": "engagement will be different with the machine over time so as designers you have to think about that long tail",
    "start": "2310000",
    "end": "2316960"
  },
  {
    "text": "experience design that isn't the same when the system the machine and the",
    "start": "2316960",
    "end": "2322640"
  },
  {
    "text": "human are first engaged what does that look like for experience design when we want to change that over",
    "start": "2322640",
    "end": "2328480"
  },
  {
    "text": "time right so",
    "start": "2328480",
    "end": "2333839"
  },
  {
    "text": "i think we currently use methods that aren't future oriented enough right",
    "start": "2333839",
    "end": "2339680"
  },
  {
    "text": "so it's really speculative speculative research is different which is difficult with current ux like",
    "start": "2339680",
    "end": "2346320"
  },
  {
    "text": "interviewing and stuff like that you know people don't know what kind of stargate they want research needs to be",
    "start": "2346320",
    "end": "2352079"
  },
  {
    "text": "more dynamic uh not as static so we can't just interview",
    "start": "2352079",
    "end": "2357599"
  },
  {
    "text": "people once um and think okay we've got confidence in design direction and",
    "start": "2357599",
    "end": "2363440"
  },
  {
    "text": "research has to go beyond single agency framework uh and consider like ecosys",
    "start": "2363440",
    "end": "2368480"
  },
  {
    "text": "ecosystems multimodal ai environments um so we got to go beyond usability and",
    "start": "2368480",
    "end": "2375440"
  },
  {
    "text": "desirability i think we have to seek unexpressed rituals culturals and values",
    "start": "2375440",
    "end": "2380720"
  },
  {
    "text": "at in irrational practices that humans do when they're engaging with their",
    "start": "2380720",
    "end": "2387040"
  },
  {
    "text": "environment we can't just automate those out right because for example when i was",
    "start": "2387040",
    "end": "2392560"
  },
  {
    "text": "working on this automation driving project uh self-driving car project with",
    "start": "2392560",
    "end": "2397680"
  },
  {
    "text": "ford one of our recommendations was not to take the steering wheel out which was",
    "start": "2397680",
    "end": "2403119"
  },
  {
    "text": "technologically like illogical because you didn't need it right because the car could drive itself",
    "start": "2403119",
    "end": "2409200"
  },
  {
    "text": "but humans have this deep psycho um",
    "start": "2409200",
    "end": "2414960"
  },
  {
    "text": "psychological need to control their environment and they need to extend that control with their hands right and so if",
    "start": "2414960",
    "end": "2422319"
  },
  {
    "text": "you don't have a control there um the the the people freaked out it was",
    "start": "2422319",
    "end": "2427760"
  },
  {
    "text": "just their mind cognitively couldn't really comprehend that the car was moving without them moving it",
    "start": "2427760",
    "end": "2435599"
  },
  {
    "text": "so um how do i combat kind of like what i saw was a lack of methodology for ml and",
    "start": "2436560",
    "end": "2443520"
  },
  {
    "text": "ai design um i found inspiration in things like design anthropology um design anthropology seeks to",
    "start": "2443520",
    "end": "2450240"
  },
  {
    "text": "understand how the processes and artifacts of design help to define what it means to be human it's just the other",
    "start": "2450240",
    "end": "2455760"
  },
  {
    "text": "way around instead of looking at humanity and trying to try to um",
    "start": "2455760",
    "end": "2462319"
  },
  {
    "text": "make it fit with design you're looking at the design of the human and seeing if",
    "start": "2462319",
    "end": "2467440"
  },
  {
    "text": "you can design things that fit into humanity right design anthropology is a method of",
    "start": "2467440",
    "end": "2473440"
  },
  {
    "text": "research that focuses on how design translates human values into tangible",
    "start": "2473440",
    "end": "2478800"
  },
  {
    "text": "experiences so how do you design trust how do you design",
    "start": "2478800",
    "end": "2484000"
  },
  {
    "text": "uh understanding how do you how do you design um privacy those kinds",
    "start": "2484000",
    "end": "2489359"
  },
  {
    "text": "of things it it combines ethnographic field work but it's iterative and it's both",
    "start": "2489359",
    "end": "2494800"
  },
  {
    "text": "reflection and and and action oriented it's less reliant on observing current states and",
    "start": "2494800",
    "end": "2501520"
  },
  {
    "text": "employs things like simulation mock-ups props and tangible interactions to explore futuristic and speculative",
    "start": "2501520",
    "end": "2508160"
  },
  {
    "text": "design it's definitely co-participatory um it it is it it requires the participant of",
    "start": "2508160",
    "end": "2516000"
  },
  {
    "text": "users uh to really get at understanding of rituals and and and and values",
    "start": "2516000",
    "end": "2522800"
  },
  {
    "text": "uh and it's more scenario based so i use a lot of games performances enactment",
    "start": "2522800",
    "end": "2528800"
  },
  {
    "text": "it's it's and teams are transdisciplinary so each member is working together to create new",
    "start": "2528800",
    "end": "2534240"
  },
  {
    "text": "conceptual theoretical meta and and and methods um for innovation so",
    "start": "2534240",
    "end": "2539839"
  },
  {
    "text": "that means designers data scientists engineers my team at capital one it's made up with people with backgrounds in",
    "start": "2539839",
    "end": "2546720"
  },
  {
    "text": "physics and engineering and design and education and sociology and anthropology",
    "start": "2546720",
    "end": "2552160"
  },
  {
    "text": "it's not just made up with people with hci degrees",
    "start": "2552160",
    "end": "2556720"
  },
  {
    "text": "so design anthropology has transdisciplinary multi uh characteristics it requires that",
    "start": "2557440",
    "end": "2563359"
  },
  {
    "text": "co-participation and its research-led design um and it's iterative research is",
    "start": "2563359",
    "end": "2568720"
  },
  {
    "text": "designed and designed as research there's no like concrete phase between the two",
    "start": "2568720",
    "end": "2575279"
  },
  {
    "text": "and we use provocative prototypes and simulations we put people in scenarios",
    "start": "2575599",
    "end": "2581040"
  },
  {
    "text": "so that we can understand because this dynamic nature of ml and ai we don't",
    "start": "2581040",
    "end": "2586480"
  },
  {
    "text": "know the answers to many of the questions that we have and the only way that we can get more confidence in our",
    "start": "2586480",
    "end": "2593040"
  },
  {
    "text": "design directions is just to try to re try to put people in futuristic",
    "start": "2593040",
    "end": "2598400"
  },
  {
    "text": "scenarios",
    "start": "2598400",
    "end": "2601119"
  },
  {
    "text": "so here's how i think we're gonna evolve as designers we're we're gonna kind of",
    "start": "2603520",
    "end": "2609040"
  },
  {
    "text": "adopt a more hands-on simulated futuristic research methodology to",
    "start": "2609040",
    "end": "2616000"
  },
  {
    "text": "figure out what we should be designing in this area um and and i think we'll",
    "start": "2616000",
    "end": "2623200"
  },
  {
    "text": "have a a broader framework of our design so we'll look at people individuals and",
    "start": "2623200",
    "end": "2629119"
  },
  {
    "text": "systems rather than with a device right and then we'll have multi-disciplinary teams right like we'll hire diverse",
    "start": "2629119",
    "end": "2636560"
  },
  {
    "text": "designers from a wide range of backgrounds and they won't be just designers they'll be data scientists",
    "start": "2636560",
    "end": "2642240"
  },
  {
    "text": "product managers engineers janitors people with all kinds of different backgrounds to bring mental",
    "start": "2642240",
    "end": "2649839"
  },
  {
    "text": "models to to bear and so it's designed today",
    "start": "2649839",
    "end": "2655520"
  },
  {
    "text": "is human centered um it focuses on people's knees and it counteracts counteracts adverse effects people",
    "start": "2655520",
    "end": "2662160"
  },
  {
    "text": "really forget that in the iso definition of acd hcd",
    "start": "2662160",
    "end": "2667280"
  },
  {
    "text": "i think tomorrow we'll have more pluralistic um uh pluralism in design",
    "start": "2667280",
    "end": "2672880"
  },
  {
    "text": "direction we'll shift from universal and we'll have like 15 different journeys that that a person can go through that",
    "start": "2672880",
    "end": "2679760"
  },
  {
    "text": "we could customize and design and automation will help us to do that we'll go um the type of data collection and",
    "start": "2679760",
    "end": "2686880"
  },
  {
    "text": "analysis will afford that kind of individual customization at a massive scale",
    "start": "2686880",
    "end": "2692000"
  },
  {
    "text": "um the role of designer would kind of lose its coveted elitism and apply to people",
    "start": "2692000",
    "end": "2698240"
  },
  {
    "text": "with skills not often connected to design engineers anthropologists hairdressers",
    "start": "2698240",
    "end": "2703280"
  },
  {
    "text": "um because the pluralism will demand intersectional designers i believe we'll",
    "start": "2703280",
    "end": "2708400"
  },
  {
    "text": "move from device and individual to human machine relationships uh this ability to hyper customize will",
    "start": "2708400",
    "end": "2715760"
  },
  {
    "text": "push designers beyond our agency model of interaction design to consider how",
    "start": "2715760",
    "end": "2721040"
  },
  {
    "text": "humans and machines have a cooperative relationship together as the pinnacle of that experience so really learning",
    "start": "2721040",
    "end": "2729040"
  },
  {
    "text": "having the human teach the machine what she or he or they want rather than us",
    "start": "2729040",
    "end": "2736319"
  },
  {
    "text": "designing a journey for them that they all must go down and i i also believe will will hit",
    "start": "2736319",
    "end": "2742880"
  },
  {
    "text": "machine agency and autonomy designers will have to consider the agency not just of the humans but of the",
    "start": "2742880",
    "end": "2749040"
  },
  {
    "text": "machines and the ecosystem within the which they operate this is like my way",
    "start": "2749040",
    "end": "2754720"
  },
  {
    "text": "out moonshine stuffs moonshot stuff so i know it's kind of crazy and we'll redefine design",
    "start": "2754720",
    "end": "2761839"
  },
  {
    "text": "we'll integrate data science design to develop intelligent products that improve",
    "start": "2761839",
    "end": "2767200"
  },
  {
    "text": "people's everyday lives this is my definition of machine learning experience design and it'll be transdisciplinary we'll",
    "start": "2767200",
    "end": "2774240"
  },
  {
    "text": "have explorers we'll have builders we'll chase loon shots those looney tune ideas",
    "start": "2774240",
    "end": "2779839"
  },
  {
    "text": "will will that would be our wheelhouse we'll go after what seems impossible",
    "start": "2779839",
    "end": "2786079"
  },
  {
    "text": "as a designer will be more interdisciplinary um we'll have a bias towards building",
    "start": "2786079",
    "end": "2791839"
  },
  {
    "text": "things and just getting people in environments rather than thinking or conceptually talking about things and",
    "start": "2791839",
    "end": "2799280"
  },
  {
    "text": "we'll be forced to make abstract things like trust and value concrete",
    "start": "2799280",
    "end": "2804880"
  },
  {
    "text": "we'll treat data as a stakeholder we'll be less design centric and we'll have an interdisciplinary focus which means",
    "start": "2804880",
    "end": "2811920"
  },
  {
    "text": "we'll focus on keeping people and data together understand desata as a design tool recognize the right applicability",
    "start": "2811920",
    "end": "2819599"
  },
  {
    "text": "for aiml and understanding the real-time dynamic nature of ml and ai and focus on",
    "start": "2819599",
    "end": "2827839"
  },
  {
    "text": "building to learn rather than our designer in intuition and",
    "start": "2827839",
    "end": "2833200"
  },
  {
    "text": "really encourage participatory design code design with people impacted by these products",
    "start": "2833200",
    "end": "2839599"
  },
  {
    "text": "i i won't go through this because i don't think i have time but",
    "start": "2839920",
    "end": "2845760"
  },
  {
    "text": "this was a project that i worked with with the data scientists and researchers and designers on redesigning um the",
    "start": "2845760",
    "end": "2853040"
  },
  {
    "text": "outpatient experience uh for uh for kids at a pediatric hospital",
    "start": "2853040",
    "end": "2859920"
  },
  {
    "text": "um and i think what i i really want to point out here about",
    "start": "2859920",
    "end": "2865440"
  },
  {
    "text": "what was different about this was that we defined data and systems as stakeholders really early",
    "start": "2865440",
    "end": "2871680"
  },
  {
    "text": "in in this process so definitely we went out and did qualitative interviews but we also collected like three years of",
    "start": "2871680",
    "end": "2878400"
  },
  {
    "text": "employment data and started exploring and looking at that data just like we were exploring and talking to",
    "start": "2878400",
    "end": "2885680"
  },
  {
    "text": "patients and their families we integrated data and field research",
    "start": "2885680",
    "end": "2890720"
  },
  {
    "text": "exploration and synthesis so while the data scientist was doing exploration",
    "start": "2890720",
    "end": "2896559"
  },
  {
    "text": "he he he was putting that visualization in the project room and we as as",
    "start": "2896559",
    "end": "2901599"
  },
  {
    "text": "researchers and designers were asking very inquisitive questions about what he was seeing we were talking about what we",
    "start": "2901599",
    "end": "2908480"
  },
  {
    "text": "saw on the data same thing with the data scientist coming to us he conducted qualitative interviews with folks and",
    "start": "2908480",
    "end": "2916319"
  },
  {
    "text": "and that kind of mix of mental models was really great for us to get at what i call parallel synthesis synthesis that",
    "start": "2916319",
    "end": "2923920"
  },
  {
    "text": "comes from different points of view to come together to have a better insights",
    "start": "2923920",
    "end": "2930480"
  },
  {
    "text": "and so these data-infused research insights allowed us to discover better design opportunities",
    "start": "2930480",
    "end": "2937280"
  },
  {
    "text": "uh on the right are my qualitative notes on the left are the quantitative notes",
    "start": "2937280",
    "end": "2942640"
  },
  {
    "text": "it's so great how they kind of like came together and it led us to this notion of variance and",
    "start": "2942640",
    "end": "2949359"
  },
  {
    "text": "how we could design for that um and some methods that we use were data",
    "start": "2949359",
    "end": "2955440"
  },
  {
    "text": "people journey mapping um this is this is mapping data and people along",
    "start": "2955440",
    "end": "2961599"
  },
  {
    "text": "your journey mapping experience systems mapping where does the data come from",
    "start": "2961599",
    "end": "2967280"
  },
  {
    "text": "where is the data created and transferred and by whom and what and doing you know",
    "start": "2967280",
    "end": "2973760"
  },
  {
    "text": "debriefing systems and data interviews together as well as qualitative interviews",
    "start": "2973760",
    "end": "2978800"
  },
  {
    "text": "and creating uh what does that mean moments where where the different disciplines can come together and ask",
    "start": "2978800",
    "end": "2984559"
  },
  {
    "text": "about their methodology um we were able to eliminate systems",
    "start": "2984559",
    "end": "2991359"
  },
  {
    "text": "challenges rather than individual challenges only right when you think about the user pain points we were able",
    "start": "2991359",
    "end": "2997760"
  },
  {
    "text": "to think about the user's pain points in the context with the systems pain points that allowed us to redesign the",
    "start": "2997760",
    "end": "3003760"
  },
  {
    "text": "ecosystem in a better way and we used lots of simulations to test different design outcomes and scenarios",
    "start": "3003760",
    "end": "3010720"
  },
  {
    "text": "this is one of those simulations the kids loved it um we we just basically redesigned their",
    "start": "3010720",
    "end": "3016880"
  },
  {
    "text": "whole experience of checking in and and figuring out uh when they were going to",
    "start": "3016880",
    "end": "3022319"
  },
  {
    "text": "their next appointment um",
    "start": "3022319",
    "end": "3027440"
  },
  {
    "text": "yeah that's it i think i i left like six minutes for questions",
    "start": "3027440",
    "end": "3034078"
  },
  {
    "text": "oh my gosh that was fantastic um and while we're waiting um i've got to",
    "start": "3034720",
    "end": "3040880"
  },
  {
    "text": "say one of the things we're both educators here one of the things um",
    "start": "3040880",
    "end": "3046160"
  },
  {
    "text": "i think is hard to do is teach people how to think about time so you talked earlier about you know when you first",
    "start": "3046160",
    "end": "3053440"
  },
  {
    "text": "get in you won't trust the car but then over time you start building that trust and eventually you start",
    "start": "3053440",
    "end": "3060079"
  },
  {
    "text": "being willing to um you know hand over more things and i",
    "start": "3060079",
    "end": "3065839"
  },
  {
    "text": "i think it's a it's really hard to get people to stop thinking of a moment and get them yes",
    "start": "3065839",
    "end": "3070880"
  },
  {
    "text": "yeah they have to think about a spectrum right and you have to design for that as the car gets smarter should the",
    "start": "3070880",
    "end": "3077280"
  },
  {
    "text": "experience change right and and sometimes you need the the user",
    "start": "3077280",
    "end": "3082800"
  },
  {
    "text": "to teach you that when they're ready you can't just say all right i'm gonna make the the",
    "start": "3082800",
    "end": "3089440"
  },
  {
    "text": "change happen and one of our principles our design principles with that was",
    "start": "3089440",
    "end": "3094480"
  },
  {
    "text": "designed for the transition state not in-state so when you're when you're designing",
    "start": "3094480",
    "end": "3101200"
  },
  {
    "text": "with an autonomous vehicle you want to make sure you don't miss the transition um where it goes from",
    "start": "3101200",
    "end": "3108800"
  },
  {
    "text": "car to human or human to car a lot of people designing for the in-state right so now the car is in",
    "start": "3108800",
    "end": "3114559"
  },
  {
    "text": "control and you design that experience or the humans in control but really it's about that transition when they",
    "start": "3114559",
    "end": "3120880"
  },
  {
    "text": "switch control that's the real experience you want to design i don't want to get too pragmatic and i",
    "start": "3120880",
    "end": "3127359"
  },
  {
    "text": "know god will interrupt me if there are other questions but um are there some techniques that are particularly well",
    "start": "3127359",
    "end": "3132480"
  },
  {
    "text": "suited to making those kinds of plans you mentioned journey maps uh you know they've become fairly standard",
    "start": "3132480",
    "end": "3139599"
  },
  {
    "text": "yeah i think the the thing about the journey map is and this is uh an alignment that i got from my students is",
    "start": "3139599",
    "end": "3146400"
  },
  {
    "text": "i the journey must that we do are are very different because they're actually",
    "start": "3146400",
    "end": "3152400"
  },
  {
    "text": "not the user journey it's the system's journey and so you have to think about the user",
    "start": "3152400",
    "end": "3158640"
  },
  {
    "text": "is within a journey rather than the journey that the user goes on and it's a",
    "start": "3158640",
    "end": "3164079"
  },
  {
    "text": "it's a it's a new it's a nuance in how you do those mapping um but if you get",
    "start": "3164079",
    "end": "3170319"
  },
  {
    "text": "that nuance then you really understand how to how to change the design and i",
    "start": "3170319",
    "end": "3176559"
  },
  {
    "text": "think i i like to use an example of ordering a pizza because you can map out that journey",
    "start": "3176559",
    "end": "3182319"
  },
  {
    "text": "pretty easily yeah but um online um but then when you when you go to map it",
    "start": "3182319",
    "end": "3189359"
  },
  {
    "text": "you're really going okay how do they get the price of the pizza that they want how do they decide what",
    "start": "3189359",
    "end": "3196640"
  },
  {
    "text": "kind of inner ingredients and all of that stuff doesn't come from the user it comes from different places within the",
    "start": "3196640",
    "end": "3202000"
  },
  {
    "text": "system and so now you're designing around a user so that they can have the",
    "start": "3202000",
    "end": "3207440"
  },
  {
    "text": "experience that they want and so now you're designing beyond what the user wants and what the system can do",
    "start": "3207440",
    "end": "3214480"
  },
  {
    "text": "so you're thinking in terms of architecture databases where the data lives who has access to that like that",
    "start": "3214480",
    "end": "3222800"
  },
  {
    "text": "needs to be part of the design um that makes sense um",
    "start": "3222800",
    "end": "3229920"
  },
  {
    "text": "you'll just let me know right okay yes so as there are no questions okay not not in the uh and i don't see",
    "start": "3230319",
    "end": "3236960"
  },
  {
    "text": "anything on chat so we're good um so i'd like to dig in more into um the ethics side of it um",
    "start": "3236960",
    "end": "3243760"
  },
  {
    "text": "you know uh gosh i want to ask you so many questions like how did you get into ethics but also how do you bring ethics into the",
    "start": "3243760",
    "end": "3251760"
  },
  {
    "text": "work process you know yeah and i think first of all i think i i try not to use the word ethics",
    "start": "3251760",
    "end": "3258480"
  },
  {
    "text": "but i think it's a because ethics is contextual right like like my ethics and india if i my ethics",
    "start": "3258480",
    "end": "3266480"
  },
  {
    "text": "of the way that i operate in america is one way and i've been to 65 countries and i can tell you that if i go to other",
    "start": "3266480",
    "end": "3273440"
  },
  {
    "text": "countries about certain things are allowed that i wouldn't do here in america and it would be completely",
    "start": "3273440",
    "end": "3279359"
  },
  {
    "text": "ethical over there i think that i think what we want to do is to",
    "start": "3279359",
    "end": "3285359"
  },
  {
    "text": "incorporate do no harm right as much as possible and whatever",
    "start": "3285359",
    "end": "3291680"
  },
  {
    "text": "that means right like i i'm not defining that but i'm just saying like that's the way we want to think",
    "start": "3291680",
    "end": "3298240"
  },
  {
    "text": "about when we're trying to do human-centered or responsible or whatever like i think it's really good",
    "start": "3298240",
    "end": "3304960"
  },
  {
    "text": "to just say hey we're going to start off with acknowledging that there there could be harm here so what kind of harm",
    "start": "3304960",
    "end": "3311520"
  },
  {
    "text": "does that look like so we do harms modeling right this is the um uh un kind",
    "start": "3311520",
    "end": "3317599"
  },
  {
    "text": "of like you take the the u.n security needs that they say everybody needs it's",
    "start": "3317599",
    "end": "3322720"
  },
  {
    "text": "like security identity privacy economic access to economic freedom those kinds of things and you you do an exercise",
    "start": "3322720",
    "end": "3329760"
  },
  {
    "text": "that goes if i create this technology how does it not only harm a person but in these",
    "start": "3329760",
    "end": "3335760"
  },
  {
    "text": "individual categories will it interve who will it harm economically who will",
    "start": "3335760",
    "end": "3341359"
  },
  {
    "text": "it harm identity wise who would it harm and and you may find it doesn't but you need",
    "start": "3341359",
    "end": "3348400"
  },
  {
    "text": "to look at it in all of the intersectionality there like on a global kind of system scale rather than just",
    "start": "3348400",
    "end": "3355280"
  },
  {
    "text": "like are there gonna be is one person gonna be hurt by this right",
    "start": "3355280",
    "end": "3360480"
  },
  {
    "text": "so when i when we talk about ethics i think what i really am talking about is being mindful",
    "start": "3360480",
    "end": "3367359"
  },
  {
    "text": "how mindful can you be that's why i call it mindful ai so i'm i'm really considering all the different things",
    "start": "3367359",
    "end": "3374640"
  },
  {
    "text": "that can happen with this model thank you um i have a thousand questions",
    "start": "3374640",
    "end": "3380160"
  },
  {
    "text": "so i wish you weren't remote but uh hopefully our our paths will uh meet again and question in the auditorium",
    "start": "3380160",
    "end": "3388319"
  },
  {
    "text": "oh wonderful okay hi and i wanted to ask um",
    "start": "3388319",
    "end": "3394640"
  },
  {
    "text": "so i'm not a cs major but um but i know a bit of like ml techniques and like",
    "start": "3394640",
    "end": "3400799"
  },
  {
    "text": "a lot of it comes down to like data and probability but when it comes to like more",
    "start": "3400799",
    "end": "3406559"
  },
  {
    "text": "um i would say qualitative data it's a lot harder to capture them",
    "start": "3406559",
    "end": "3412079"
  },
  {
    "text": "and make it ai or like machine learning you know algorithms or whatever it is",
    "start": "3412079",
    "end": "3417119"
  },
  {
    "text": "and i think a lot and a lot of it right now like nowadays has been transiting from like actual data to",
    "start": "3417119",
    "end": "3424559"
  },
  {
    "text": "uh human relations and emotions and especially in this like or like uh in this post-pandemic",
    "start": "3424559",
    "end": "3431680"
  },
  {
    "text": "era when people actually appreciate human relationships a lot more so",
    "start": "3431680",
    "end": "3437359"
  },
  {
    "text": "i mean how does like a company like yours like actually look into this more",
    "start": "3437359",
    "end": "3442559"
  },
  {
    "text": "human relations or like emotional part yeah i love that you asked this question because this is exactly what i'm",
    "start": "3442559",
    "end": "3448960"
  },
  {
    "text": "wrestling with right now and i okay so here's here's how i talk to it",
    "start": "3448960",
    "end": "3455680"
  },
  {
    "text": "to to my company so what a lot of people don't really understand is that banks are heavily",
    "start": "3455680",
    "end": "3461839"
  },
  {
    "text": "regulated and when and when we talk about regulation non non-fair lending practice discrimination",
    "start": "3461839",
    "end": "3467760"
  },
  {
    "text": "all that that extends to our models by the way so we have a a higher bar or burden",
    "start": "3467760",
    "end": "3475599"
  },
  {
    "text": "i won't say burton but a higher bar of of fairness and awareness",
    "start": "3475599",
    "end": "3481280"
  },
  {
    "text": "um and and and explainability and all that kind of stuff because we're banks",
    "start": "3481280",
    "end": "3486559"
  },
  {
    "text": "um and so all the things that we were doing in in anything that we did in our practices it extends to iraq technology",
    "start": "3486559",
    "end": "3493359"
  },
  {
    "text": "by the way and we're audited by that but i talked to my risk officer all at",
    "start": "3493359",
    "end": "3498880"
  },
  {
    "text": "my chief risk officer all the time we have definite indicators",
    "start": "3498880",
    "end": "3504400"
  },
  {
    "text": "that we use to see if our models are",
    "start": "3504400",
    "end": "3510160"
  },
  {
    "text": "you know privacy security fairness anti you know money laundering",
    "start": "3510160",
    "end": "3516400"
  },
  {
    "text": "all of that we are creating indicators",
    "start": "3516400",
    "end": "3521440"
  },
  {
    "text": "that i call the human value index risk or the human engagement risk indicators",
    "start": "3521440",
    "end": "3528960"
  },
  {
    "text": "that aren't in our normal risk factors right that's what we're creating there are new",
    "start": "3528960",
    "end": "3535599"
  },
  {
    "text": "values that we're looking at that says what is the risk of this model when it",
    "start": "3535599",
    "end": "3540880"
  },
  {
    "text": "engages with a human and the human has automation bias",
    "start": "3540880",
    "end": "3547040"
  },
  {
    "text": "the human has availability bias or the human so now we're taking what we",
    "start": "3547040",
    "end": "3552079"
  },
  {
    "text": "understand about human cognitively the cognitive biases we're having and we're",
    "start": "3552079",
    "end": "3557599"
  },
  {
    "text": "creating indicators from that to say and this is over's term but it's it's",
    "start": "3557599",
    "end": "3564000"
  },
  {
    "text": "the human engagement risk so what are the human engagement risk indicators that we need to actually look at in our",
    "start": "3564000",
    "end": "3571359"
  },
  {
    "text": "input variables when we're when we're collecting data when we're",
    "start": "3571359",
    "end": "3576400"
  },
  {
    "text": "creating features when we're creating models completely new stuff",
    "start": "3576400",
    "end": "3582079"
  },
  {
    "text": "yeah um and i think on top of that um okay i guess there's no question for now",
    "start": "3582079",
    "end": "3587200"
  },
  {
    "text": "but um um i think on top of the the things that you say like but who is the right person",
    "start": "3587200",
    "end": "3593920"
  },
  {
    "text": "or the right team to say like this values is the right values because like i don't think like yeah",
    "start": "3593920",
    "end": "3601280"
  },
  {
    "text": "and that's why i say the teams have to be transdisciplinary because it can't just be the data scientists saying that",
    "start": "3601280",
    "end": "3607040"
  },
  {
    "text": "yeah what does he know about exactly sociology yeah like what does he know about how",
    "start": "3607040",
    "end": "3612720"
  },
  {
    "text": "humans congregate or uh how human",
    "start": "3612720",
    "end": "3618799"
  },
  {
    "text": "or psychology like automation bias was one i brought up to a data scientist who've created a model",
    "start": "3618799",
    "end": "3625680"
  },
  {
    "text": "where we're trying to make decisions about xyz and i said look",
    "start": "3625680",
    "end": "3631520"
  },
  {
    "text": "the human will be in the loop on those first nine ten times but if the machine",
    "start": "3631520",
    "end": "3637839"
  },
  {
    "text": "doesn't make a mistake the human will drop out yeah because like and that's exactly",
    "start": "3637839",
    "end": "3643119"
  },
  {
    "text": "what happened with uber's self-driving car she had been in that car for a",
    "start": "3643119",
    "end": "3648720"
  },
  {
    "text": "day for months never had a mistake she just backed out right because",
    "start": "3648720",
    "end": "3655440"
  },
  {
    "text": "we tend to we tend to have an automation bias we trust machines that don't make",
    "start": "3655440",
    "end": "3660640"
  },
  {
    "text": "mistakes how often do you trust the machine to get your checkbook right",
    "start": "3660640",
    "end": "3666240"
  },
  {
    "text": "yeah right you don't go around auditing your digital bank account yeah",
    "start": "3666240",
    "end": "3671920"
  },
  {
    "text": "so i think these are people who understand this needs to be in a room with people who",
    "start": "3671920",
    "end": "3676960"
  },
  {
    "text": "are building this stuff right and so like for example if we build a model that decides whether",
    "start": "3676960",
    "end": "3684160"
  },
  {
    "text": "we're going to sue somebody for collections i'm like we need to have somebody who has been sued for collections in that yeah room",
    "start": "3684160",
    "end": "3692880"
  },
  {
    "text": "yeah the value of empathy is really like um very important in these days and not",
    "start": "3692880",
    "end": "3698640"
  },
  {
    "text": "just especially experience like i'm i want the person who's been through that in that cold",
    "start": "3698640",
    "end": "3704960"
  },
  {
    "text": "designing which is why i say co-participatory design the role of designer will change it would just be",
    "start": "3704960",
    "end": "3712559"
  },
  {
    "text": "people who are going to be impacted by these models right yeah right alongside the person",
    "start": "3712559",
    "end": "3718640"
  },
  {
    "text": "making the model okay thank you so much yeah thank you for that question i think",
    "start": "3718640",
    "end": "3725200"
  },
  {
    "text": "it's very pertinent okay thank you so much i we're over time",
    "start": "3725200",
    "end": "3731280"
  },
  {
    "text": "which is kind of okay wonderful but i thank you so much for all your time and thank you for this thanks for asking me i enjoyed it bye",
    "start": "3731280",
    "end": "3740839"
  }
]
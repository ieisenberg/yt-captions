[
  {
    "start": "0",
    "end": "56000"
  },
  {
    "text": "We are going to generalize what we talked about,",
    "start": "4010",
    "end": "7575"
  },
  {
    "text": "uh, last time, uh,",
    "start": "7575",
    "end": "8940"
  },
  {
    "text": "which will be all about generalizing and mathematically formalizing,",
    "start": "8940",
    "end": "12330"
  },
  {
    "text": "uh, graph neural networks.",
    "start": "12330",
    "end": "13950"
  },
  {
    "text": "The idea for today's lecture,",
    "start": "13950",
    "end": "16965"
  },
  {
    "text": "is to talk about deep graph encoders and mathematically formalize them,",
    "start": "16965",
    "end": "21790"
  },
  {
    "text": "and also show you the design space, the idea,",
    "start": "21790",
    "end": "26100"
  },
  {
    "text": "the diversity of what kind of design choices, uh,",
    "start": "26100",
    "end": "29700"
  },
  {
    "text": "do we have when we are making, uh,",
    "start": "29700",
    "end": "31725"
  },
  {
    "text": "these types of, uh, decisions,",
    "start": "31725",
    "end": "33930"
  },
  {
    "text": "uh, building these types of architectures, right?",
    "start": "33930",
    "end": "36630"
  },
  {
    "text": "So what we want is we wanna build a deep graph encoder that takes the graph, uh,",
    "start": "36630",
    "end": "40680"
  },
  {
    "text": "as the input, and then through a series of non-linear, uh, transformations,",
    "start": "40680",
    "end": "45890"
  },
  {
    "text": "through kind of this deep neural network,",
    "start": "45890",
    "end": "48395"
  },
  {
    "text": "comes up with a set of, uh,",
    "start": "48395",
    "end": "50115"
  },
  {
    "text": "predictions that can be at node level,",
    "start": "50115",
    "end": "52205"
  },
  {
    "text": "can be at the level of sub-graphs,",
    "start": "52205",
    "end": "53870"
  },
  {
    "text": "pairs of nodes, um, and so on.",
    "start": "53870",
    "end": "56165"
  },
  {
    "start": "56000",
    "end": "112000"
  },
  {
    "text": "And what we talked about last time,",
    "start": "56165",
    "end": "58250"
  },
  {
    "text": "is that the way we can define convolutional neural networks on top of graphs is",
    "start": "58250",
    "end": "62750"
  },
  {
    "text": "to- to think about the underlying network as the computation graph, right?",
    "start": "62750",
    "end": "67520"
  },
  {
    "text": "So the idea was when we discussed if I wanna make a prediction for a given,",
    "start": "67520",
    "end": "72030"
  },
  {
    "text": "uh, node in the network,",
    "start": "72030",
    "end": "73220"
  },
  {
    "text": "let's say this red node i,",
    "start": "73220",
    "end": "74690"
  },
  {
    "text": "then first I need to decide how to compose a computation graph,",
    "start": "74690",
    "end": "78760"
  },
  {
    "text": "um, and based on the network neighborhood around this node.",
    "start": "78760",
    "end": "82195"
  },
  {
    "text": "And then I can think of the- um,",
    "start": "82195",
    "end": "84050"
  },
  {
    "text": "of the computation graph as the structure of the graph neural- of the neural network,",
    "start": "84050",
    "end": "88175"
  },
  {
    "text": "where now messages' information gets passed, uh,",
    "start": "88175",
    "end": "91955"
  },
  {
    "text": "and aggregated from a neighbor to neighbor towards",
    "start": "91955",
    "end": "94910"
  },
  {
    "text": "to the center node so that the center node can make a prediction.",
    "start": "94910",
    "end": "98000"
  },
  {
    "text": "And we talked about how graph neural networks allow us to",
    "start": "98000",
    "end": "101120"
  },
  {
    "text": "learn how to propagate and transform, um,",
    "start": "101120",
    "end": "104270"
  },
  {
    "text": "information across the edges of",
    "start": "104270",
    "end": "106490"
  },
  {
    "text": "the underlying network to make a prediction and embedding,",
    "start": "106490",
    "end": "110000"
  },
  {
    "text": "uh, at a given node.",
    "start": "110000",
    "end": "111835"
  },
  {
    "text": "So the intuition was that nodes",
    "start": "111835",
    "end": "114760"
  },
  {
    "start": "112000",
    "end": "155000"
  },
  {
    "text": "aggregate information from their neighbors using neural networks,",
    "start": "114760",
    "end": "118405"
  },
  {
    "text": "so we said that every node in the network gets to define",
    "start": "118405",
    "end": "121835"
  },
  {
    "text": "its own multi-layer neural network structure.",
    "start": "121835",
    "end": "125690"
  },
  {
    "text": "This neural network structure depends on the neighbors and the,",
    "start": "125690",
    "end": "130119"
  },
  {
    "text": "uh, graph structure around the node of interest.",
    "start": "130120",
    "end": "133450"
  },
  {
    "text": "So, for example, node B here takes information from two- two other nodes,",
    "start": "133450",
    "end": "138050"
  },
  {
    "text": "uh, A and C because they are the neighbors of it,",
    "start": "138050",
    "end": "140820"
  },
  {
    "text": "uh, in the network.",
    "start": "140820",
    "end": "142085"
  },
  {
    "text": "And then, of course, the goal will be to learn, uh,",
    "start": "142085",
    "end": "144470"
  },
  {
    "text": "the transformations in- um, in- in this,",
    "start": "144470",
    "end": "148100"
  },
  {
    "text": "uh, in this neural network that- that would be parameterized and this way,",
    "start": "148100",
    "end": "152380"
  },
  {
    "text": "uh, our- our approach is going to work.",
    "start": "152380",
    "end": "155395"
  },
  {
    "text": "So the intuition is that network neighborhood defines a computation graph,",
    "start": "155395",
    "end": "159760"
  },
  {
    "text": "and that every node defines a computation graph based on its, uh, network neighborhood.",
    "start": "159760",
    "end": "164930"
  },
  {
    "text": "So every node in the graph essentially can get its own neural network architecture,",
    "start": "164930",
    "end": "170045"
  },
  {
    "text": "because these are now different kind of neural networks,",
    "start": "170045",
    "end": "172520"
  },
  {
    "text": "they have, uh, different shapes.",
    "start": "172520",
    "end": "174815"
  },
  {
    "text": "So now with this quick recap,",
    "start": "174815",
    "end": "177585"
  },
  {
    "start": "175000",
    "end": "187000"
  },
  {
    "text": "let's talk about how do we generally define",
    "start": "177585",
    "end": "180320"
  },
  {
    "text": "graph neural networks and what are the components of them,",
    "start": "180320",
    "end": "183460"
  },
  {
    "text": "and how do we mathematically formalize, uh, these components?",
    "start": "183460",
    "end": "187090"
  },
  {
    "start": "187000",
    "end": "230000"
  },
  {
    "text": "So first, in this general framework,",
    "start": "187090",
    "end": "189730"
  },
  {
    "text": "is that we have two, uh, aspects.",
    "start": "189730",
    "end": "191830"
  },
  {
    "text": "We have this notion of a message and we have a notion of aggregation.",
    "start": "191830",
    "end": "195745"
  },
  {
    "text": "And different architectures like GCN, GraphSAGE,",
    "start": "195745",
    "end": "199810"
  },
  {
    "text": "graph attention networks and so on and so forth,",
    "start": "199810",
    "end": "202705"
  },
  {
    "text": "what they differ is how they define this notion of aggregation,",
    "start": "202705",
    "end": "206080"
  },
  {
    "text": "and how they define this notion,",
    "start": "206080",
    "end": "207760"
  },
  {
    "text": "uh, of a message.",
    "start": "207760",
    "end": "209140"
  },
  {
    "text": "So that's the first important part,",
    "start": "209140",
    "end": "211690"
  },
  {
    "text": "is how do we define basically a single layer of",
    "start": "211690",
    "end": "215350"
  },
  {
    "text": "a graph neural network, which composed basically by taking the messages,",
    "start": "215350",
    "end": "219730"
  },
  {
    "text": "uh, from the children,",
    "start": "219730",
    "end": "221065"
  },
  {
    "text": "transforming them and aggregating them.",
    "start": "221065",
    "end": "223510"
  },
  {
    "text": "So that's the transformation and aggregation,",
    "start": "223510",
    "end": "226209"
  },
  {
    "text": "are the first two core, um, operations.",
    "start": "226210",
    "end": "229710"
  },
  {
    "text": "The second set of, uh,",
    "start": "229710",
    "end": "232035"
  },
  {
    "start": "230000",
    "end": "254000"
  },
  {
    "text": "operations is about how are we stacking",
    "start": "232035",
    "end": "234910"
  },
  {
    "text": "together multiple layers in a graph neural network, right?",
    "start": "234910",
    "end": "238660"
  },
  {
    "text": "So do we stack these layers sequentially?",
    "start": "238660",
    "end": "241180"
  },
  {
    "text": "Do we add skip connections and so on?",
    "start": "241180",
    "end": "243459"
  },
  {
    "text": "So that's the- that's the, uh,",
    "start": "243460",
    "end": "245380"
  },
  {
    "text": "uh, second part, uh, of the equation,",
    "start": "245380",
    "end": "247720"
  },
  {
    "text": "is how do we add this layer, uh,",
    "start": "247720",
    "end": "249895"
  },
  {
    "text": "connectivity when we combine Layer 1,",
    "start": "249895",
    "end": "251860"
  },
  {
    "text": "uh, with Layer 2.",
    "start": "251860",
    "end": "253355"
  },
  {
    "text": "Um, and then the- the last part that, eh,",
    "start": "253355",
    "end": "256260"
  },
  {
    "start": "254000",
    "end": "290000"
  },
  {
    "text": "- that is an important design- design decision",
    "start": "256260",
    "end": "259260"
  },
  {
    "text": "is how do we create the computation graph, right?",
    "start": "259260",
    "end": "262120"
  },
  {
    "text": "Do we say that the- the input graph equals the computation graph,",
    "start": "262120",
    "end": "266199"
  },
  {
    "text": "or do we do any kind of augmentation?",
    "start": "266200",
    "end": "268795"
  },
  {
    "text": "Maybe we wanna do some feature augmentation,",
    "start": "268795",
    "end": "271180"
  },
  {
    "text": "or we wanna do some graph structure manipulation.",
    "start": "271180",
    "end": "274495"
  },
  {
    "text": "Again, uh, in this lecture,",
    "start": "274495",
    "end": "276275"
  },
  {
    "text": "I'm just kind of giving you an overview of the areas where I will",
    "start": "276275",
    "end": "279800"
  },
  {
    "text": "be going to provide more detail and where we are going to go, uh, deeper.",
    "start": "279800",
    "end": "283340"
  },
  {
    "text": "So that's the- that's the third- the fourth area where this becomes,",
    "start": "283340",
    "end": "287465"
  },
  {
    "text": "um, very important, design decisions, uh, have to be made.",
    "start": "287465",
    "end": "291155"
  },
  {
    "start": "290000",
    "end": "325000"
  },
  {
    "text": "And then the last part is in terms of the learning.",
    "start": "291155",
    "end": "294000"
  },
  {
    "text": "You know, what kind of learn- what kind of objective function,",
    "start": "294000",
    "end": "297365"
  },
  {
    "text": "what kind of task are we going to use to",
    "start": "297365",
    "end": "299539"
  },
  {
    "text": "learn the parameters of our graph neural network,",
    "start": "299540",
    "end": "302060"
  },
  {
    "text": "right? So how do we train it?",
    "start": "302060",
    "end": "303245"
  },
  {
    "text": "Do we train it in a supervised, unsupervised objective?",
    "start": "303245",
    "end": "306560"
  },
  {
    "text": "Do we do it at the level of node prediction, edge prediction,",
    "start": "306560",
    "end": "309945"
  },
  {
    "text": "or entire graph, um, level prediction tasks?",
    "start": "309945",
    "end": "313580"
  },
  {
    "text": "So these are, essentially now gave you a kind of an overview of the parts, uh,",
    "start": "313580",
    "end": "318310"
  },
  {
    "text": "of the design- design space, uh,",
    "start": "318310",
    "end": "320790"
  },
  {
    "text": "for neural, graph neural network, uh, architectures.",
    "start": "320790",
    "end": "324405"
  },
  {
    "text": "So as I said, first is,",
    "start": "324405",
    "end": "326805"
  },
  {
    "text": "defining the layer, then it's defining connectivity between layers.",
    "start": "326805",
    "end": "331354"
  },
  {
    "text": "It's about, uh, uh, eh, layer connectivity.",
    "start": "331355",
    "end": "334835"
  },
  {
    "text": "It's about graph manipulation,",
    "start": "334835",
    "end": "336620"
  },
  {
    "text": "augmentation, feature augmentation, as well as,",
    "start": "336620",
    "end": "339590"
  },
  {
    "text": "uh, finally the learning objectives.",
    "start": "339590",
    "end": "341540"
  },
  {
    "text": "So these are the five, uh,",
    "start": "341540",
    "end": "343040"
  },
  {
    "text": "pieces we are going to talk about.",
    "start": "343040",
    "end": "346320"
  }
]
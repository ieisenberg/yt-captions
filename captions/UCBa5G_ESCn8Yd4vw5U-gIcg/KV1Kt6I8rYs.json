[
  {
    "start": "0",
    "end": "53000"
  },
  {
    "start": "0",
    "end": "920"
  },
  {
    "text": "So let's talk a bit about\nSelecting the Tuning Parameter",
    "start": "920",
    "end": "6180"
  },
  {
    "text": "for Ridge Regression and Lasso.",
    "start": "6180",
    "end": "8480"
  },
  {
    "text": "First point is that\nit's important.",
    "start": "8480",
    "end": "10289"
  },
  {
    "text": "The lambda very strongly\ndetermines the solution",
    "start": "10290",
    "end": "13790"
  },
  {
    "text": "over a broad spectrum.",
    "start": "13790",
    "end": "14900"
  },
  {
    "text": "When lambda is 0, we\nget full least squares.",
    "start": "14900",
    "end": "16860"
  },
  {
    "text": "There's no regularization.",
    "start": "16860",
    "end": "18470"
  },
  {
    "text": "When lamda is infinity, we get\na 0 solution in both cases.",
    "start": "18470",
    "end": "21480"
  },
  {
    "text": "So choosing lambda is\nextremely important,",
    "start": "21480",
    "end": "23779"
  },
  {
    "text": "and cross-validation is a\ngood technique for doing that.",
    "start": "23780",
    "end": "27570"
  },
  {
    "text": "Note also that we couldn't\nuse the other methods",
    "start": "27570",
    "end": "30980"
  },
  {
    "text": "because the d isn't known.",
    "start": "30980",
    "end": "32757"
  },
  {
    "text": "What other methods\nam I talking about?",
    "start": "32757",
    "end": "34340"
  },
  {
    "text": "Cp and AIC and BIC,\nthey all require",
    "start": "34340",
    "end": "38420"
  },
  {
    "text": "a number of parameters d.",
    "start": "38420",
    "end": "40550"
  },
  {
    "text": "And it's not clear\nwhat d is now.",
    "start": "40550",
    "end": "42980"
  },
  {
    "text": "That's actually something\ninteresting to think about.",
    "start": "42980",
    "end": "45390"
  },
  {
    "text": "Well, suppose I've done\na ridge regression,",
    "start": "45390",
    "end": "48800"
  },
  {
    "text": "I started with the 45 variables,\nlike in the credit data.",
    "start": "48800",
    "end": "51440"
  },
  {
    "text": "I use a certain lambda.",
    "start": "51440",
    "end": "53870"
  },
  {
    "start": "53000",
    "end": "114000"
  },
  {
    "text": "Let's go back to\nthat, just so I can",
    "start": "53870",
    "end": "55927"
  },
  {
    "text": "point at something, an example.",
    "start": "55928",
    "end": "57220"
  },
  {
    "start": "57220",
    "end": "63720"
  },
  {
    "text": "Here's our ridge example.",
    "start": "63720",
    "end": "64900"
  },
  {
    "text": "Suppose I decide to use\na lambda of 100, right?",
    "start": "64900",
    "end": "69050"
  },
  {
    "text": "And I'm here, and I ask you,\nwhat's the d for that model?",
    "start": "69050",
    "end": "73088"
  },
  {
    "text": "How many parameters have I fit?",
    "start": "73088",
    "end": "74380"
  },
  {
    "text": "Well, if I count the\nnumber of parameters,",
    "start": "74380",
    "end": "75960"
  },
  {
    "text": "the number of\nnon-zero coefficients,",
    "start": "75960",
    "end": "77460"
  },
  {
    "text": "it's still the full number, 11.",
    "start": "77460",
    "end": "80405"
  },
  {
    "text": "Because none of the\ncoefficients are 0.",
    "start": "80405",
    "end": "82270"
  },
  {
    "text": "So in a sense, all of my\nvariables are still there.",
    "start": "82270",
    "end": "86250"
  },
  {
    "text": "So my d, the number of\nparameters, is still p, 11.",
    "start": "86250",
    "end": "91000"
  },
  {
    "text": "But that doesn't\nsomehow seem right",
    "start": "91000",
    "end": "92915"
  },
  {
    "text": "because I've shrunken\nthe coefficients.",
    "start": "92915",
    "end": "94540"
  },
  {
    "text": "So their number of degrees\nof freedom isn't as large.",
    "start": "94540",
    "end": "100050"
  },
  {
    "text": "So there's a bit of\na subtle point here.",
    "start": "100050",
    "end": "102280"
  },
  {
    "text": "The number of parameters is\nnot just how many parameters",
    "start": "102280",
    "end": "105960"
  },
  {
    "text": "I've used, but how I fit them.",
    "start": "105960",
    "end": "107930"
  },
  {
    "text": "So with ridge\nregression and lasso,",
    "start": "107930",
    "end": "109680"
  },
  {
    "text": "the shrinkage actually\naffects the very idea",
    "start": "109680",
    "end": "112080"
  },
  {
    "text": "of what we mean by\nnumber of parameters.",
    "start": "112080",
    "end": "115430"
  },
  {
    "start": "114000",
    "end": "170000"
  },
  {
    "text": "So that was a long way of saying\nthat for selecting the tuning",
    "start": "115430",
    "end": "120412"
  },
  {
    "text": "parameter for ridge\nregression and lasso,",
    "start": "120412",
    "end": "122120"
  },
  {
    "text": "it's really important\nto use a method that",
    "start": "122120",
    "end": "123870"
  },
  {
    "text": "doesn't require the value of d.",
    "start": "123870",
    "end": "126560"
  },
  {
    "text": "Because it's hard\nto know what D is.",
    "start": "126560",
    "end": "128509"
  },
  {
    "text": "So cross-validation\nfits the bill perfectly.",
    "start": "128509",
    "end": "132200"
  },
  {
    "text": "We do exactly what we did for\nthe other methods for subset",
    "start": "132200",
    "end": "135711"
  },
  {
    "text": "selection, for example.",
    "start": "135712",
    "end": "136670"
  },
  {
    "text": "We divided the data\nup into k parts.",
    "start": "136670",
    "end": "140120"
  },
  {
    "text": "Let's say, k equals 10, we\nfit the model on 9 parts.",
    "start": "140120",
    "end": "144349"
  },
  {
    "text": "Say, we apply ridge\nregression for a whole range",
    "start": "144350",
    "end": "147950"
  },
  {
    "text": "of lambdas for the 9 parts.",
    "start": "147950",
    "end": "150030"
  },
  {
    "text": "And then, we record the\nerror on the 10th part.",
    "start": "150030",
    "end": "152600"
  },
  {
    "text": "We do that in turn\nfor all 10 parts,",
    "start": "152600",
    "end": "154580"
  },
  {
    "text": "playing the role of\nthe validation set.",
    "start": "154580",
    "end": "156470"
  },
  {
    "text": "And then, we add up all\nthe errors together,",
    "start": "156470",
    "end": "158390"
  },
  {
    "text": "and we get a cross-validation\ncurve as a function of lambda.",
    "start": "158390",
    "end": "162260"
  },
  {
    "text": "Same for the lasso.",
    "start": "162260",
    "end": "163580"
  },
  {
    "text": "So conceptually,\ncross-validation",
    "start": "163580",
    "end": "167270"
  },
  {
    "text": "is exactly the same as we\napplied it for other methods.",
    "start": "167270",
    "end": "171470"
  },
  {
    "start": "170000",
    "end": "244000"
  },
  {
    "text": "So let's see what it looks\nlike here for ridge regression.",
    "start": "171470",
    "end": "176130"
  },
  {
    "text": "Here's the result\nof cross-validation.",
    "start": "176130",
    "end": "181460"
  },
  {
    "text": "I'm not sure if it was either\nfive or ten-fold We can check.",
    "start": "181460",
    "end": "184110"
  },
  {
    "text": "Here's cross-validation\nas a function of lambda.",
    "start": "184110",
    "end": "187190"
  },
  {
    "text": "Again, remember, lambda equals\nsmall, means, essentially,",
    "start": "187190",
    "end": "189980"
  },
  {
    "text": "the least squares model,\nfull least squares over here.",
    "start": "189980",
    "end": "193040"
  },
  {
    "text": "And lambda equals large\nmeans the coefficient",
    "start": "193040",
    "end": "196040"
  },
  {
    "text": "have been driven to 0.",
    "start": "196040",
    "end": "197129"
  },
  {
    "text": "So this is the cross-validation\nerror as a function of lambda.",
    "start": "197130",
    "end": "200970"
  },
  {
    "text": "And the minimum is occurring\naround here, around 0.05.",
    "start": "200970",
    "end": "207210"
  },
  {
    "text": "Here's the same\nthing now, but we",
    "start": "207210",
    "end": "210607"
  },
  {
    "text": "plotted as a function of lambda,\nthe standardized coefficient.",
    "start": "210607",
    "end": "213189"
  },
  {
    "text": "So here are the coefficients\nfor each of the predictors,",
    "start": "213190",
    "end": "217800"
  },
  {
    "text": "their profiles.",
    "start": "217800",
    "end": "218830"
  },
  {
    "text": "And we see how they vary\nas a function of lambda.",
    "start": "218830",
    "end": "221430"
  },
  {
    "text": "So again, over here,\nthere's full least squares.",
    "start": "221430",
    "end": "224560"
  },
  {
    "text": "And here, as we move to the\nright, they're shrunken.",
    "start": "224560",
    "end": "228130"
  },
  {
    "text": "And at the minimum value of\nthe curve, this broken line,",
    "start": "228130",
    "end": "231910"
  },
  {
    "text": "we get a bunch of guys, which\nare essentially 0, but not",
    "start": "231910",
    "end": "236380"
  },
  {
    "text": "exactly 0 because this\nis ridge, not lasso.",
    "start": "236380",
    "end": "238670"
  },
  {
    "text": "And then, here are\nthe coefficients",
    "start": "238670",
    "end": "240280"
  },
  {
    "text": "for the three active variables.",
    "start": "240280",
    "end": "242360"
  },
  {
    "start": "242360",
    "end": "247900"
  },
  {
    "start": "244000",
    "end": "327000"
  },
  {
    "text": "And this is the simulated\ndata with n equals 50.",
    "start": "247900",
    "end": "254019"
  },
  {
    "text": "I think, there were two or three\ntruly non-zero coefficients",
    "start": "254020",
    "end": "256600"
  },
  {
    "text": "in the population.",
    "start": "256600",
    "end": "257859"
  },
  {
    "text": "For the lasso, this is now the\nresult of cross-validation.",
    "start": "257860",
    "end": "261979"
  },
  {
    "text": "So we plotted the\ncross-validation error",
    "start": "261980",
    "end": "265450"
  },
  {
    "text": "versus the L1 norm of the\nlasso solution divided",
    "start": "265450",
    "end": "269680"
  },
  {
    "text": "by the L1-norm of the full\nleast squared solution.",
    "start": "269680",
    "end": "271910"
  },
  {
    "text": "This is just a convenient\nway of scaling the x-axis so",
    "start": "271910",
    "end": "274960"
  },
  {
    "text": "that it goes from 0 to 1, right?",
    "start": "274960",
    "end": "277600"
  },
  {
    "text": "The full least squares\nestimates give us a value of 1.",
    "start": "277600",
    "end": "281080"
  },
  {
    "text": "And the estimates of 0\ngives you a value of 0.",
    "start": "281080",
    "end": "283789"
  },
  {
    "text": "And in between, we have the\nintermediate lasso solutions.",
    "start": "283790",
    "end": "287180"
  },
  {
    "text": "So here's the\ncross-validation curve.",
    "start": "287180",
    "end": "289160"
  },
  {
    "text": "Again, it's got that u-shape\nthat Daniella mentioned before.",
    "start": "289160",
    "end": "292060"
  },
  {
    "text": "And its minimum\nis at around here,",
    "start": "292060",
    "end": "295150"
  },
  {
    "text": "about 0.1, which is quite severe\nshrinkage, which is good here",
    "start": "295150",
    "end": "300340"
  },
  {
    "text": "because we know that\nthe true model has only",
    "start": "300340",
    "end": "302863"
  },
  {
    "text": "three non-zero coefficients.",
    "start": "302863",
    "end": "304030"
  },
  {
    "text": "And I think, it's actually two.",
    "start": "304030",
    "end": "305322"
  },
  {
    "text": "Even better.",
    "start": "305322",
    "end": "306180"
  },
  {
    "text": "OK.",
    "start": "306180",
    "end": "306680"
  },
  {
    "text": "Two non-zero coefficients.",
    "start": "306680",
    "end": "308780"
  },
  {
    "text": "And very good because\nhere, we seem to have",
    "start": "308780",
    "end": "310910"
  },
  {
    "text": "picked up exactly two\nnon-zero coefficients.",
    "start": "310910",
    "end": "313100"
  },
  {
    "text": "the green and the red.",
    "start": "313100",
    "end": "314120"
  },
  {
    "text": "And the rest are exactly 0.",
    "start": "314120",
    "end": "315870"
  },
  {
    "text": "So in this made up example, it's\ndone exactly the right thing.",
    "start": "315870",
    "end": "320130"
  },
  {
    "text": "It's found the correct two\nnon-zero features, and set",
    "start": "320130",
    "end": "323750"
  },
  {
    "text": "everything else\nexactly equal to 0.",
    "start": "323750",
    "end": "326440"
  },
  {
    "start": "326440",
    "end": "328000"
  }
]
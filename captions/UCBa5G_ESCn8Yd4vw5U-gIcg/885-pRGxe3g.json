[
  {
    "text": "all right so so whether an industry academia",
    "start": "11599",
    "end": "16960"
  },
  {
    "text": "non-profits or government organizations all over the world are struggling to keep up with the massive amounts of data",
    "start": "16960",
    "end": "23039"
  },
  {
    "text": "being collected from various field instruments devices online services and more and in particular we lack effective",
    "start": "23039",
    "end": "29679"
  },
  {
    "text": "solutions for helping people interactively explore massive data sets by interactive exploration i mean using",
    "start": "29679",
    "end": "35520"
  },
  {
    "text": "an an intuitive interface to make sense of a data set for example to figure out how to clean model and ultimately",
    "start": "35520",
    "end": "42000"
  },
  {
    "text": "extract insights from that data to make decisions now why aren't why are existing systems",
    "start": "42000",
    "end": "47920"
  },
  {
    "text": "unable to support scalable interactive exploration",
    "start": "47920",
    "end": "54440"
  },
  {
    "text": "on the one hand we have visualization systems which can produce intuitive image representations of data that analysts can interact with and and as a",
    "start": "58160",
    "end": "65439"
  },
  {
    "text": "result can be engaging tools for data exploration however these systems are",
    "start": "65439",
    "end": "70640"
  },
  {
    "text": "not scalable due to problematic assumptions being made about the data that's visualized so either that data is",
    "start": "70640",
    "end": "76799"
  },
  {
    "text": "small say small enough to fit in main memory on your laptop or if it's not small enough the user has",
    "start": "76799",
    "end": "84080"
  },
  {
    "text": "to go process that data somewhere else first on the other hand we have database",
    "start": "84080",
    "end": "89759"
  },
  {
    "text": "management systems where they're known for being scalable efficient systems for data processing",
    "start": "89759",
    "end": "96560"
  },
  {
    "text": "and examples include money db defd sql server and so on the problem with database management",
    "start": "96560",
    "end": "102640"
  },
  {
    "text": "systems is that they're optimized for executing jobs and data centers not necessarily in terms of",
    "start": "102640",
    "end": "109600"
  },
  {
    "text": "interactivity or responsiveness to user interactions with an interface nor in the design of the interface itself",
    "start": "109600",
    "end": "116479"
  },
  {
    "text": "and this snapshot from the moneydb website kind of sums up the experience analysts often have with these kinds of",
    "start": "116479",
    "end": "122159"
  },
  {
    "text": "systems which in case you can't tell can be kind of painful so to scale up exploratory visual",
    "start": "122159",
    "end": "127360"
  },
  {
    "text": "analysis to support massive datasets researchers and developers are interested in integrating database",
    "start": "127360",
    "end": "132480"
  },
  {
    "text": "management systems with visualization systems so the database management systems can focus on what they're good at efficient processing of complex",
    "start": "132480",
    "end": "139040"
  },
  {
    "text": "computation and the visualization systems can focus on what they're good at enabling analysts to interpret and manipulate the",
    "start": "139040",
    "end": "144560"
  },
  {
    "text": "results of that computation in an intuitive way and i call the combination of these two systems interactive data analysis",
    "start": "144560",
    "end": "151280"
  },
  {
    "text": "systems so in this context performance now is not defined purely by query speed",
    "start": "151280",
    "end": "156879"
  },
  {
    "text": "throughput and so on instead performance is defined by how assistance behavior helps or hinders an analyst's ability to",
    "start": "156879",
    "end": "164160"
  },
  {
    "text": "extract reliable insights from her data so user behavior drives system performance and system behavior drives",
    "start": "164160",
    "end": "171599"
  },
  {
    "text": "user performance to further clarify the challenges in designing interactive analysis systems",
    "start": "171599",
    "end": "177280"
  },
  {
    "text": "i'll talk about one specific example of exploring satellite sensor data from the moderate resolution spectroradiometer",
    "start": "177280",
    "end": "183760"
  },
  {
    "text": "of the nasa modus so with nasal lotus data you can support a wide variety of use cases say",
    "start": "183760",
    "end": "190480"
  },
  {
    "text": "measuring vegetation density tracking hurricanes tracking phytoplankton populations in the oceans",
    "start": "190480",
    "end": "196560"
  },
  {
    "text": "measuring snowmelt or snow cover over time that's a particular scenario that i studied in my phd",
    "start": "196560",
    "end": "202080"
  },
  {
    "text": "but the problem with the data from modis is that it's large complicated and difficult to manage",
    "start": "202080",
    "end": "207920"
  },
  {
    "text": "so it's multi-dimensional so here's a tiny slice of nasa modus dia that i'm showing you here it's multi-dimensional",
    "start": "207920",
    "end": "214159"
  },
  {
    "text": "it has a latitude longitude and temporal information modis also records many many different",
    "start": "214159",
    "end": "220640"
  },
  {
    "text": "wavelengths of light each referred to as a modus band for example shortwave infrared light",
    "start": "220640",
    "end": "225680"
  },
  {
    "text": "or band b6 or visible green light like band 54",
    "start": "225680",
    "end": "230799"
  },
  {
    "text": "and on top of this on top of this",
    "start": "231120",
    "end": "237200"
  },
  {
    "text": "two weeks of nasa modis data uncompressed takes up about 10 terabytes of space at least when i was working",
    "start": "237200",
    "end": "242879"
  },
  {
    "text": "with it before so imagine being an earth scientist wanting to do a time series analysis",
    "start": "242879",
    "end": "248319"
  },
  {
    "text": "over a long time scale that would be quite challenging so how do we bridge this gap between large complicated moses modis data",
    "start": "248319",
    "end": "255599"
  },
  {
    "text": "and the engaging and intuitive visualizations that i showed you from before",
    "start": "255599",
    "end": "261199"
  },
  {
    "text": "well hailing from the database research community i might argue okay",
    "start": "261199",
    "end": "266320"
  },
  {
    "text": "a starting point could be to take the data where here we're focused on a snow cover so to take modis data and store it",
    "start": "266320",
    "end": "273520"
  },
  {
    "text": "in database management system so now we can capture the snow cover computation we're interested in as a sql query and",
    "start": "273520",
    "end": "280560"
  },
  {
    "text": "here we see a stylized version of a sql query calculating a normalized different snow index where we're taking two modus",
    "start": "280560",
    "end": "286400"
  },
  {
    "text": "bands b4 and b6 and calculating the normalized difference between them so now if we want to visualize our snow",
    "start": "286400",
    "end": "292000"
  },
  {
    "text": "cover results we could take this dbms and connect it to a visualization system we're here we're rendering the results",
    "start": "292000",
    "end": "298560"
  },
  {
    "text": "as a geographic heat map where regions that are more likely to contain snow are colored with a darker shade of blue",
    "start": "298560",
    "end": "305600"
  },
  {
    "text": "so the problem with this classic setup is that database management systems aren't designed to be interactive resulting in an impedance mismatch",
    "start": "305600",
    "end": "312639"
  },
  {
    "text": "between that that system and the visualization system and this could lead to confusing or even biasing the behavior of analysts as",
    "start": "312639",
    "end": "319759"
  },
  {
    "text": "they're exploring their data due to lag or other side effects that they perceive through the interface but the problem of supporting",
    "start": "319759",
    "end": "326080"
  },
  {
    "text": "interactivity at scale can become tractable through two key insights that i study",
    "start": "326080",
    "end": "332240"
  },
  {
    "text": "so the first is not any old sql query is going to be executed on database management system the user interface",
    "start": "334320",
    "end": "340240"
  },
  {
    "text": "actually constrains the scope of queries that can be executed on top of this as users interact with",
    "start": "340240",
    "end": "346320"
  },
  {
    "text": "these interfaces they often do so in predictable ways for example by zooming in multiple times in a row",
    "start": "346320",
    "end": "353759"
  },
  {
    "text": "using these insights i develop what i call behavior driven optimizations where what i do is i analyze how people",
    "start": "353759",
    "end": "360479"
  },
  {
    "text": "explore data using visualization systems i collect that interaction data and build computational models to represent",
    "start": "360479",
    "end": "367120"
  },
  {
    "text": "the patterns of behavior that i observe and i leverage these models in two ways so first",
    "start": "367120",
    "end": "373120"
  },
  {
    "text": "i deploy optimizations that can take advantage of these knowledge of these patterns for example if a user can if i have a sense of where",
    "start": "373120",
    "end": "381680"
  },
  {
    "text": "a user will explore in a snow-covered dataset i can preemptively execute those corresponding queries and fetch the data",
    "start": "381680",
    "end": "388319"
  },
  {
    "text": "ahead of time to improve the overall perceived responsiveness of the system i can also take these models of behavior",
    "start": "388319",
    "end": "394479"
  },
  {
    "text": "and generate workloads that i can use to evaluate other analysis systems basically creating benchmarks",
    "start": "394479",
    "end": "401360"
  },
  {
    "text": "more broadly the question that drives my research is how can we design adaptive systems to amplify the strengths and",
    "start": "401360",
    "end": "408080"
  },
  {
    "text": "mitigate the weaknesses of both system and human analysts to answer this question i conduct",
    "start": "408080",
    "end": "413599"
  },
  {
    "text": "research along three main axis so characterizing exploration or investigating the different ways that analysts explore data through various",
    "start": "413599",
    "end": "420319"
  },
  {
    "text": "visualization interfaces optimizing exploration so designing new systems and",
    "start": "420319",
    "end": "425360"
  },
  {
    "text": "techniques to better support analysts and benchmarking exploration we're designing new methods for systematic and",
    "start": "425360",
    "end": "431039"
  },
  {
    "text": "repeatable evaluation of interactive analysis systems for sake of time i won't go into every",
    "start": "431039",
    "end": "436160"
  },
  {
    "text": "single project i've done along these three nazis but what i will focus on in the remainder of this talk",
    "start": "436160",
    "end": "441919"
  },
  {
    "text": "is how i study the impact of system latency on user exploration performance how i developed the forecast system to",
    "start": "441919",
    "end": "448000"
  },
  {
    "text": "address the performance challenges that i observed and how i extended what i learned from forecast and other projects into a",
    "start": "448000",
    "end": "453919"
  },
  {
    "text": "performance benchmark that connects insights from the visualization database community base and i'll finish with some",
    "start": "453919",
    "end": "459199"
  },
  {
    "text": "of my ongoing work on optimizing and benchmarking for interactive data exploration",
    "start": "459199",
    "end": "464400"
  },
  {
    "text": "so first although system latency sounds like it could certainly be an annoying thing it's not obvious how it actually impacts",
    "start": "464400",
    "end": "471680"
  },
  {
    "text": "an analyst exploration performance so i conducted a series of amazon mechanical turk experiments to investigate this",
    "start": "471680",
    "end": "477840"
  },
  {
    "text": "relationship between latency and user exploration performance and i'll talk a bit about what my results tell us in",
    "start": "477840",
    "end": "483759"
  },
  {
    "text": "terms of designing more effective interactive data analysis systems where here the context the context of",
    "start": "483759",
    "end": "489120"
  },
  {
    "text": "exploration is navigating large tiled visualizations so the system that i developed for cache",
    "start": "489120",
    "end": "495199"
  },
  {
    "text": "and then similar interfaces like google maps take these large visualizations and break them down into smaller pieces basically tiles and what i'm interested",
    "start": "495199",
    "end": "502560"
  },
  {
    "text": "in understanding is what users do when there's a delay in when those tiles actually appear on the screen and i had",
    "start": "502560",
    "end": "508400"
  },
  {
    "text": "two particular research questions that i wanted to investigate through this this series of experiments",
    "start": "508400",
    "end": "513760"
  },
  {
    "text": "so first is how do people change their exploration behavior in response to latency",
    "start": "513760",
    "end": "519680"
  },
  {
    "text": "now the second question is how much latency is too much for example is there a magical latency threshold where",
    "start": "519680",
    "end": "526000"
  },
  {
    "text": "latency suddenly starts to become a problem in terms of affecting users exploration behaviors",
    "start": "526000",
    "end": "531360"
  },
  {
    "text": "this would be really helpful for say the database community which is often geared towards optimizing systems to provide a",
    "start": "531360",
    "end": "538160"
  },
  {
    "text": "better overall user experience experience for sure definitely in reducing latency",
    "start": "538160",
    "end": "545120"
  },
  {
    "text": "however knowledge of the users the user's knowledge of the underlying data set can also influence their exploration",
    "start": "545760",
    "end": "551920"
  },
  {
    "text": "patterns latency is not the only factor so i'll talk about how i control for both of these effects in my experiment",
    "start": "551920",
    "end": "556959"
  },
  {
    "text": "design so the first is to control for how much information",
    "start": "556959",
    "end": "562000"
  },
  {
    "text": "someone knows about the visualization they're exploring so to do this what i did was i abstracted the scenario i",
    "start": "562000",
    "end": "568080"
  },
  {
    "text": "showed you before so instead of looking at specific kinds of tiles these new cover tiles now participants in the",
    "start": "568080",
    "end": "573360"
  },
  {
    "text": "study would look at general image tiles and they would look for a particular target image mimicking an analyst's",
    "start": "573360",
    "end": "578800"
  },
  {
    "text": "interest in searching for something interesting in the data so with this setup now i can simulate",
    "start": "578800",
    "end": "584480"
  },
  {
    "text": "variations in user knowledge and i broke this down into three different levels that participants could",
    "start": "584480",
    "end": "589920"
  },
  {
    "text": "fall into starting with being a data novice or knowing nothing about the target image",
    "start": "589920",
    "end": "595519"
  },
  {
    "text": "being searched for up to being a data expert where participants knew about a couple different paths they could take",
    "start": "595519",
    "end": "601519"
  },
  {
    "text": "to explore the visualization to find the target image so now i'll talk about how i inject",
    "start": "601519",
    "end": "607760"
  },
  {
    "text": "latency into this interface to see how these exploration patterns might change as latency increases and i'll",
    "start": "607760",
    "end": "613360"
  },
  {
    "text": "demonstrate with an example so let's say this large box here represents the current visualization and the user's",
    "start": "613360",
    "end": "619200"
  },
  {
    "text": "current location in the visualization is in the bottom left-hand corner what i what i do is i insert two different",
    "start": "619200",
    "end": "624959"
  },
  {
    "text": "target images that the user could potentially find and i call them the low and high latency",
    "start": "624959",
    "end": "630399"
  },
  {
    "text": "targets because let's say the user moves towards the latency target so the tiles that this user will see",
    "start": "630399",
    "end": "636720"
  },
  {
    "text": "will appear faster or with low latency but if they move towards the high latency target then the tiles they see",
    "start": "636720",
    "end": "642720"
  },
  {
    "text": "will appear slower or with higher latency",
    "start": "642720",
    "end": "647480"
  },
  {
    "text": "now i can address this first question of how latency affects exploration patterns",
    "start": "648000",
    "end": "653040"
  },
  {
    "text": "for example if there's no latency or latency has no effect on user behavior",
    "start": "653040",
    "end": "658240"
  },
  {
    "text": "then we would expect that participants in this study would find these targets with about equal probability but if we",
    "start": "658240",
    "end": "664720"
  },
  {
    "text": "see a consistent preference for say the low latency target or the highland z target that would suggest that latency",
    "start": "664720",
    "end": "670000"
  },
  {
    "text": "biases people's behaviors in terms of how they choose to explore the visualization",
    "start": "670000",
    "end": "675360"
  },
  {
    "text": "and i can actually uh model this as shifts in target preferences as latency increases",
    "start": "675360",
    "end": "681760"
  },
  {
    "text": "so here we have a spectrum depicted along the y-axis",
    "start": "681760",
    "end": "686959"
  },
  {
    "text": "representing target preferences so let's say there's no preference for target",
    "start": "686959",
    "end": "693600"
  },
  {
    "text": "regardless of latency then we would plot a point at the center of the spectrum",
    "start": "693600",
    "end": "698880"
  },
  {
    "text": "if say there's a consistent strong preference for the low latency target so finding that target first as you explore",
    "start": "698880",
    "end": "704800"
  },
  {
    "text": "then we would plot a point at the top of the spectrum now what we can do is add an x axis here",
    "start": "704800",
    "end": "709920"
  },
  {
    "text": "showing what happens as we increase the latency that people see in the interface",
    "start": "709920",
    "end": "716079"
  },
  {
    "text": "so if there's no effect of latency then we would assume that there should also be",
    "start": "716079",
    "end": "722240"
  },
  {
    "text": "no shift in target preferences but if there is a magical threshold at",
    "start": "722240",
    "end": "728160"
  },
  {
    "text": "which latency starts to become a problem what we might expect is something like an s curve where the inflection point of",
    "start": "728160",
    "end": "733839"
  },
  {
    "text": "this s-curve represents the threshold that we're interested in for example maybe one second or 500 milliseconds as",
    "start": "733839",
    "end": "740399"
  },
  {
    "text": "mentioned in the literature what i actually found when i ran my experiments",
    "start": "740399",
    "end": "746160"
  },
  {
    "text": "was something more like this a more gradual almost linear shift",
    "start": "746160",
    "end": "751440"
  },
  {
    "text": "from having no target preference to having a stronger preference for the low latency target so",
    "start": "751440",
    "end": "758160"
  },
  {
    "text": "suggesting there's this gradual increase in exploration bias as latency increases and i found that whether participants",
    "start": "758160",
    "end": "764560"
  },
  {
    "text": "were categorized as data analysis or data experts there was no significant difference in the outcome",
    "start": "764560",
    "end": "770639"
  },
  {
    "text": "so what does this mean for interactive data analysis systems well unfortunately for the database community",
    "start": "770639",
    "end": "776880"
  },
  {
    "text": "i did not find an obvious single interactivity threshold that we could use for optimization instead i found",
    "start": "776880",
    "end": "782800"
  },
  {
    "text": "this consistent relationship between increase in latency and an increase in exploration bias",
    "start": "782800",
    "end": "789680"
  },
  {
    "text": "where the more people the more latency there was the more people seem to bias their expiration behaviors to avoid that",
    "start": "789680",
    "end": "795920"
  },
  {
    "text": "latency so whether you're reducing 10 seconds of latency or one second of latency it just seems like it's always a good idea to reduce system latency",
    "start": "795920",
    "end": "804240"
  },
  {
    "text": "so to summarize i conducted a series of amazon mechanical turk experiments to investigate this relationship between",
    "start": "804240",
    "end": "810000"
  },
  {
    "text": "system latency and user exploration performance i did not find an obvious latency threshold and instead i found",
    "start": "810000",
    "end": "815680"
  },
  {
    "text": "that a reduction in latency in general can help to reduce user exploration bias",
    "start": "815680",
    "end": "821839"
  },
  {
    "text": "so now i'll talk about a specific system that i developed called forecast to address this problem of system latency",
    "start": "821839",
    "end": "829839"
  },
  {
    "text": "so forecast is designed to reduce system latency while users explore array data such as the nasa satellite sensor data",
    "start": "830160",
    "end": "836720"
  },
  {
    "text": "and the key idea behind forecast is that if we can understand how users tend to explore their data then we can design",
    "start": "836720",
    "end": "842160"
  },
  {
    "text": "systems level optimizations to match these known exploration patterns and to do this i translated existing theory and",
    "start": "842160",
    "end": "849120"
  },
  {
    "text": "human computer interaction visualization into code by training machine learning models labeled with user interact with",
    "start": "849120",
    "end": "855519"
  },
  {
    "text": "labeled user interaction data and what forecast does is it uses these trained models to drive tile prefetching",
    "start": "855519",
    "end": "861920"
  },
  {
    "text": "optimizations so now i'll talk about how i compute zoom levels and tiles in forecast",
    "start": "861920",
    "end": "867839"
  },
  {
    "text": "so everything in forecast whether it's a data set or a query is represented as an",
    "start": "867839",
    "end": "873279"
  },
  {
    "text": "array shown here as a grid so what i do to compute zoom levels is i aggregate every n cells of these arrays along each",
    "start": "873279",
    "end": "880959"
  },
  {
    "text": "dimension where i use a larger n to calculate a coarser grains and level and a smaller end to calculate a finer",
    "start": "880959",
    "end": "887120"
  },
  {
    "text": "grains and level and then each zoom level can be partitioned into fixed width blocks or",
    "start": "887120",
    "end": "892240"
  },
  {
    "text": "tiles so forecast can compute tiles directly and incrementally it doesn't have to compute holes in level first but i won't",
    "start": "892240",
    "end": "899120"
  },
  {
    "text": "talk about the tile optimizations today i'm just going to focus on the prefetching optimizations that forecast",
    "start": "899120",
    "end": "905760"
  },
  {
    "text": "has so now let me talk a little bit about the forecast architecture so it has three components the first is a",
    "start": "905760",
    "end": "912320"
  },
  {
    "text": "visualization front-end which is responsible for managing the visualizations that people can actually interact with",
    "start": "912320",
    "end": "919120"
  },
  {
    "text": "then there's a server-side optimization middleware layer which has two components the first is a prediction",
    "start": "919120",
    "end": "924399"
  },
  {
    "text": "framework which takes interaction data from the front end and uses that to make predictions about where the user will",
    "start": "924399",
    "end": "929519"
  },
  {
    "text": "explore next in the data set and then there's a separate tile builder component which then translates these",
    "start": "929519",
    "end": "934959"
  },
  {
    "text": "predictions into queries for tiles that actually get fetched from a backend database management system",
    "start": "934959",
    "end": "940399"
  },
  {
    "text": "and here we use the array-based database management system site b given its native support for array-based",
    "start": "940399",
    "end": "946959"
  },
  {
    "text": "processing and optimization so forecast also does interaction",
    "start": "946959",
    "end": "952079"
  },
  {
    "text": "interaction aware caching along every level of this architecture but i won't talk about those optimization",
    "start": "952079",
    "end": "957199"
  },
  {
    "text": "optimizations today again i'm focusing on the prefetching optimizations so first i'm going to talk about how",
    "start": "957199",
    "end": "963759"
  },
  {
    "text": "forecast predicts users exploration goals which connects to where they're going to explore in a data set providing",
    "start": "963759",
    "end": "970000"
  },
  {
    "text": "us an intuition for where and how they might end up fetching tiles or requesting tiles",
    "start": "970000",
    "end": "976560"
  },
  {
    "text": "so in particular the first core contribution of four cache is the translation of visualization theory into",
    "start": "976560",
    "end": "982399"
  },
  {
    "text": "a model executable by software where i translate this theory into specific goals users have as they're",
    "start": "982399",
    "end": "989199"
  },
  {
    "text": "exploring their data or i call them analysis spaces so foraging sense making and navigation and",
    "start": "989199",
    "end": "995920"
  },
  {
    "text": "the forging and sense making phases are actually derived from the parolee and cards sense making model",
    "start": "995920",
    "end": "1002079"
  },
  {
    "text": "and the proline card model has two major loops of interest here so the first is the forging loop",
    "start": "1002079",
    "end": "1007839"
  },
  {
    "text": "where what people do is they collect potentially relevant and interesting pieces of information for example in for",
    "start": "1007839",
    "end": "1013360"
  },
  {
    "text": "cash that might look like identifying regions of interest to investigate further",
    "start": "1013360",
    "end": "1019199"
  },
  {
    "text": "then the other main loop in the parolee card model that we're interested in is the sense making loop so in this case",
    "start": "1019199",
    "end": "1024720"
  },
  {
    "text": "the user takes the pieces of information that they've collected and investigates them in more detail to answer ascertain",
    "start": "1024720",
    "end": "1030558"
  },
  {
    "text": "potential relationships between them so in forecast this might look like investigating particular regions of interest in more detail",
    "start": "1030559",
    "end": "1038319"
  },
  {
    "text": "so the thing about the purlin card model is that's not able to capture interactions for maneuvering between",
    "start": "1038319",
    "end": "1043678"
  },
  {
    "text": "these two clips for example zooming in so i introduce a separate navigation phase to capture this missing process so",
    "start": "1043679",
    "end": "1050799"
  },
  {
    "text": "now i'll demonstrate how i actually apply these phases of exploration through an example",
    "start": "1050799",
    "end": "1057200"
  },
  {
    "text": "so let's say we're exploring snow cover again but regions that are more likely to contain snow go from blue to red",
    "start": "1057200",
    "end": "1064000"
  },
  {
    "text": "so usually when we're exploring we start at a coarser grain zoom level so we can find things that we're interested in",
    "start": "1064000",
    "end": "1069679"
  },
  {
    "text": "so this represents the foraging phase and let's say we come across this mountain range here and we want to",
    "start": "1069679",
    "end": "1074720"
  },
  {
    "text": "export so now we switch to the navigation phase so we can see this mountain range in",
    "start": "1074720",
    "end": "1079919"
  },
  {
    "text": "more detail so once we've reached an appropriate level of detail that we're happy with then we'll start moving",
    "start": "1079919",
    "end": "1085280"
  },
  {
    "text": "around and investigating this mountain range and these boxes represent the tiles that get fetched along the way",
    "start": "1085280",
    "end": "1091919"
  },
  {
    "text": "now how do we actually use these analysis phases to predict what tiles to fetch next",
    "start": "1091919",
    "end": "1098000"
  },
  {
    "text": "oops sorry before we get there",
    "start": "1099600",
    "end": "1105360"
  },
  {
    "text": "people very rarely explore just one region of interest right so let's say we want to explore more than just this one",
    "start": "1105360",
    "end": "1111280"
  },
  {
    "text": "round range what we're going to do is we're going to zoom out again eventually and then we're going to return to the forging phase to",
    "start": "1111280",
    "end": "1116960"
  },
  {
    "text": "find something interesting that is not the mountain range we just saw so for example let's say this cluster of red",
    "start": "1116960",
    "end": "1122880"
  },
  {
    "text": "pixels in the bottom right hand corner all right now how do we use this information",
    "start": "1122880",
    "end": "1128799"
  },
  {
    "text": "so for cache has multiple prediction levels now let's say",
    "start": "1128799",
    "end": "1134559"
  },
  {
    "text": "considering our previous example these are just performed by pending interaction this information plus the user's current location gets passed to",
    "start": "1134559",
    "end": "1141440"
  },
  {
    "text": "this multi-level prediction framework that forecast has where the top level is the phase predictor",
    "start": "1141440",
    "end": "1146480"
  },
  {
    "text": "so we pass this pounding information to the phase predictor and the role of this layer",
    "start": "1146480",
    "end": "1151679"
  },
  {
    "text": "of the framework is to just say what analysis phases these are currently in let's say given all of the information",
    "start": "1151679",
    "end": "1157520"
  },
  {
    "text": "that we have the user is probably in the sense making place then this information gets passed to a model manager which is in charge of",
    "start": "1157520",
    "end": "1163520"
  },
  {
    "text": "running multiple recommendation models and you can think of a recommendation model as basically a predictor of a specific",
    "start": "1163520",
    "end": "1169679"
  },
  {
    "text": "low-level pattern of interaction where some patterns might be more prominent than others in certain analysis phases",
    "start": "1169679",
    "end": "1176000"
  },
  {
    "text": "so let's say in this case model two is better at predicting tiles to prefetch compared to model one for the sense",
    "start": "1176000",
    "end": "1181919"
  },
  {
    "text": "making phase so then the model manager will use this information to allocate space across these recommendation models",
    "start": "1181919",
    "end": "1188160"
  },
  {
    "text": "to decide which prefetch next so then we run the models we get their predictions we consolidate them and then",
    "start": "1188160",
    "end": "1194480"
  },
  {
    "text": "we send them to our tile builder component for retrieval so now i'll talk about two specific",
    "start": "1194480",
    "end": "1200000"
  },
  {
    "text": "recommendation models that build for cache but i do want to mention you can have however many models you want in this design it's not limited to two",
    "start": "1200000",
    "end": "1208400"
  },
  {
    "text": "all right so the first model that i built for for cache was is what i call the action based recommendation model and the idea is that the user",
    "start": "1208400",
    "end": "1214159"
  },
  {
    "text": "consistently moves in predictable directions which we can capture with simple markov models say mark off change",
    "start": "1214159",
    "end": "1220240"
  },
  {
    "text": "so we're going to revisit this nokia for example but limit the movement to the cardinal directions just for simplicity",
    "start": "1220240",
    "end": "1226960"
  },
  {
    "text": "so let's say we're exploring snow cover and we're pounding right and then we pin down and we pan right and then we pan down intuitively we see this as",
    "start": "1226960",
    "end": "1235120"
  },
  {
    "text": "exploring diagonally along this coastline to look at this snow cover",
    "start": "1235120",
    "end": "1240400"
  },
  {
    "text": "so though a markov chain might not be sophisticated enough to capture all these details it can capture this diagonal padding pattern and extend it",
    "start": "1240400",
    "end": "1247120"
  },
  {
    "text": "to say predict that these will continue to pan right and down but you could say okay rather than",
    "start": "1247120",
    "end": "1252799"
  },
  {
    "text": "fixating on the specific interactions that are being performed what if we just look at the tiles that are fetched as a",
    "start": "1252799",
    "end": "1257840"
  },
  {
    "text": "result of these interactions and then assume the user wants to see more of the same thing well that is actually how the",
    "start": "1257840",
    "end": "1263520"
  },
  {
    "text": "signature based recommendation model works so and the idea is the user just wants",
    "start": "1263520",
    "end": "1269360"
  },
  {
    "text": "to continuously to see more of what they've been looking at in the past so let's revisit this example and let's say we're panning down two",
    "start": "1269360",
    "end": "1276400"
  },
  {
    "text": "times in a row if we were thinking of the action based recommendation model what it would do is continue to predict that these will pin",
    "start": "1276400",
    "end": "1283919"
  },
  {
    "text": "down but this is wrong so this is not my area of expertise per se but i'm pretty sure you're not going to",
    "start": "1283919",
    "end": "1289679"
  },
  {
    "text": "find a ton of snow in that part of the pacific ocean so what would the signature-based",
    "start": "1289679",
    "end": "1295520"
  },
  {
    "text": "recommendation model do well these boxes represent the tiles for the",
    "start": "1295520",
    "end": "1301280"
  },
  {
    "text": "user's current location and then neighboring tiles these tiles look similar to what the",
    "start": "1301280",
    "end": "1307360"
  },
  {
    "text": "user's been exploring in the past so maybe what this model would do is predict that the user would pan right or",
    "start": "1307360",
    "end": "1312400"
  },
  {
    "text": "maybe up back the way they came so to calculate this similarity across",
    "start": "1312400",
    "end": "1318559"
  },
  {
    "text": "tiles i compute signatures what i call signatures and they're basically heuristics",
    "start": "1318559",
    "end": "1324400"
  },
  {
    "text": "so for example you could calculate a histogram or a particular attribute in each tile to estimate similarity you",
    "start": "1324400",
    "end": "1331440"
  },
  {
    "text": "could apply computer vision techniques to the tiles to estimate similarity by comparing the features that were",
    "start": "1331440",
    "end": "1336480"
  },
  {
    "text": "extracted and i'll talk about one particular example that i used so specifically sift i used the scalar",
    "start": "1336480",
    "end": "1343200"
  },
  {
    "text": "variant feature transform and i extracted it from each tile that forecast could fetch and the idea is",
    "start": "1343200",
    "end": "1350559"
  },
  {
    "text": "that because sift is a computer vision technique that helps you identify similar objects across",
    "start": "1350559",
    "end": "1358400"
  },
  {
    "text": "multiple images so what it does is it extracts key points and you can think of them as like landmarks or unique markers",
    "start": "1358400",
    "end": "1365120"
  },
  {
    "text": "for identifying the same object across images the idea behind it is that if i can do that i can potentially find",
    "start": "1365120",
    "end": "1371679"
  },
  {
    "text": "visual artifacts that appear across multiple zoom levels so when you're zooming in you're probably still",
    "start": "1371679",
    "end": "1377600"
  },
  {
    "text": "seeing the same thing it's just a little bigger a little smaller so to compute sift",
    "start": "1377600",
    "end": "1382880"
  },
  {
    "text": "what i did was i extracted key points from each tile i clustered the key points then i went back through the",
    "start": "1382880",
    "end": "1387919"
  },
  {
    "text": "tiles identifying which cluster the frequency with which each cluster appeared so then i'd end up with these",
    "start": "1387919",
    "end": "1394640"
  },
  {
    "text": "different histograms and then i could use the histograms to compare similarity between the tiles",
    "start": "1394640",
    "end": "1400880"
  },
  {
    "text": "all right so now how do i actually evaluate this framework that i developed for cache well what i did was i conducted a a user",
    "start": "1400880",
    "end": "1407840"
  },
  {
    "text": "study with 18 earth science researchers recruited from uw and uc santa clara and the participants explored snow cover",
    "start": "1407840",
    "end": "1413919"
  },
  {
    "text": "visualizations exactly like the ones you've been seeing throughout this talk to explore nasa satellite sensor data",
    "start": "1413919",
    "end": "1420320"
  },
  {
    "text": "so given that latency can bias users exploration behaviors i had participants explore an idyllic version of forecast",
    "start": "1420320",
    "end": "1425919"
  },
  {
    "text": "where everything was pre-computed and then instead i ran retrospective performance experiments using the",
    "start": "1425919",
    "end": "1431279"
  },
  {
    "text": "resulting interaction logs so to run these experiments what i did is i just replayed the logs from that",
    "start": "1431279",
    "end": "1437200"
  },
  {
    "text": "study i had an out of the box version of side eb i didn't do anything fancy as far as",
    "start": "1437200",
    "end": "1442320"
  },
  {
    "text": "the back end and i compared with a non-prefetching baseline to make sure that refreshing is just generally a good",
    "start": "1442320",
    "end": "1447760"
  },
  {
    "text": "idea and then i compared with two existing prefetching techniques at the time so one is momentum where the idea is",
    "start": "1447760",
    "end": "1454240"
  },
  {
    "text": "whatever the user did last they'll do it again so if these are panned down they would pan down again",
    "start": "1454240",
    "end": "1460240"
  },
  {
    "text": "the other technique that i compared with is hot spot so if we do have access to user's interaction histories we could",
    "start": "1460240",
    "end": "1466240"
  },
  {
    "text": "calculate in the data set the most popular regions within that data set and then assume that if the user is moving",
    "start": "1466240",
    "end": "1471279"
  },
  {
    "text": "towards one they will continue to move towards one of those popular regions or hotspots",
    "start": "1471279",
    "end": "1477200"
  },
  {
    "text": "in the absence of information for example if the user is not close to any known hotspots then the hotspot",
    "start": "1477200",
    "end": "1483279"
  },
  {
    "text": "technique defaults to momentum behavior so my results show that forecast",
    "start": "1483279",
    "end": "1488960"
  },
  {
    "text": "provides 20 percent higher accuracy and 88 faster response times compared to existing",
    "start": "1488960",
    "end": "1495279"
  },
  {
    "text": "techniques where a correct prediction resulted in negligible latency and a misprediction",
    "start": "1495279",
    "end": "1501520"
  },
  {
    "text": "resulted in queries having to be issued this idb causing a significant significant delay in when the user would",
    "start": "1501520",
    "end": "1507919"
  },
  {
    "text": "actually see the results visualized on the screen so here we have a line chart where on",
    "start": "1507919",
    "end": "1514559"
  },
  {
    "text": "the x-axis we have the number of tiles that could be prefetched before each user interaction and on the y-axis we have the average",
    "start": "1514559",
    "end": "1521200"
  },
  {
    "text": "response time of the system in milliseconds and we see that four cache which is the orange line is significantly lower than the other two",
    "start": "1521200",
    "end": "1527120"
  },
  {
    "text": "lines so to summarize i presented for cache a system for",
    "start": "1527120",
    "end": "1532960"
  },
  {
    "text": "visually exploring large arrays like nasa satellite sensor data and the key idea behind for cache is",
    "start": "1532960",
    "end": "1539919"
  },
  {
    "text": "that it leverages both theoretical and computational models of user exploration behavior to direct systems level",
    "start": "1539919",
    "end": "1545760"
  },
  {
    "text": "optimizations in a more intelligent way so to evaluate forecasting conducted a study with 18 earth science researchers",
    "start": "1545760",
    "end": "1552559"
  },
  {
    "text": "and find that forecast is 88 faster compared to existing techniques",
    "start": "1552559",
    "end": "1557679"
  },
  {
    "text": "and as a result forecast can help to reduce exploration bias as observed through my study of how system latency",
    "start": "1557679",
    "end": "1563520"
  },
  {
    "text": "impacts user exploration performance so now we'll talk about how forecast",
    "start": "1563520",
    "end": "1569520"
  },
  {
    "text": "sparked my interest in improving the way we evaluate interactive analysis systems as a whole",
    "start": "1569520",
    "end": "1576000"
  },
  {
    "text": "so if you're exploring nasa solid sensor data or other large arrays it's clear that forecast can provide some benefits",
    "start": "1576000",
    "end": "1582320"
  },
  {
    "text": "but if you're an analyst or another researcher you're not just interested in will forecast help me or not your answer",
    "start": "1582320",
    "end": "1587840"
  },
  {
    "text": "asks you're interested in this broader question of well with the grand landscape of interactive analysis systems out there which one should i be",
    "start": "1587840",
    "end": "1595039"
  },
  {
    "text": "using for my use case or which system should i be keeping my eye on if i want to build a better one",
    "start": "1595039",
    "end": "1601760"
  },
  {
    "text": "and i realized it's actually not so easy to try to answer this question so what i tried to do at first is say okay well i",
    "start": "1601760",
    "end": "1608080"
  },
  {
    "text": "have evaluation data why don't i just look at the evaluation data reported or shared from for all of these other",
    "start": "1608080",
    "end": "1613200"
  },
  {
    "text": "systems and then see what i find well for some systems say wisdom mns and so",
    "start": "1613200",
    "end": "1619200"
  },
  {
    "text": "on they were also evaluated in a similar way to forecast but they used completely different input data sets they asked",
    "start": "1619200",
    "end": "1626080"
  },
  {
    "text": "people to explore that data in different ways so they had separate analysis tasks from what i used for my study",
    "start": "1626080",
    "end": "1632880"
  },
  {
    "text": "and i just couldn't make a direct comparison between the numbers that they reported and the numbers that i reported",
    "start": "1632880",
    "end": "1638799"
  },
  {
    "text": "on top of this there are other systems where they were evaluated in terms of performance but not through a user study",
    "start": "1638799",
    "end": "1646240"
  },
  {
    "text": "so then there's even less data that i had available to me to try to make this comparison even for systems that are arguably more relevant for example",
    "start": "1646240",
    "end": "1652880"
  },
  {
    "text": "pirates so in general with the way we evaluate the systems right now there's just so",
    "start": "1652880",
    "end": "1658480"
  },
  {
    "text": "much variability that we can't really answer that question this question so a common and popular way to reduce",
    "start": "1658480",
    "end": "1665600"
  },
  {
    "text": "variability in the way systems get evaluated is by introducing benchmarks",
    "start": "1665600",
    "end": "1671600"
  },
  {
    "text": "so i would be lying to you if i tried to say there are no benchmarks in the database visualization communities",
    "start": "1672000",
    "end": "1677120"
  },
  {
    "text": "because there absolutely are but the key question here is are they applicable for",
    "start": "1677120",
    "end": "1682399"
  },
  {
    "text": "evaluating interactive analysis systems and i would argue that they are not and i'll give some examples so tpch is a",
    "start": "1682399",
    "end": "1690000"
  },
  {
    "text": "very well known and popular benchmark in the database community for evaluating database management systems for their",
    "start": "1690000",
    "end": "1695919"
  },
  {
    "text": "analytics support the thing with tbch is that it's really good at simulating a",
    "start": "1695919",
    "end": "1700960"
  },
  {
    "text": "data warehouse but it's not good at simulating the ad hoc interactions of an individual analyst interacting with a",
    "start": "1700960",
    "end": "1707120"
  },
  {
    "text": "visualization interface on the other hand we have benchmarks like the visual analytics benchmark repository in the visualization",
    "start": "1707120",
    "end": "1713200"
  },
  {
    "text": "community which act as a very useful data archive recording how we've designed different visualization",
    "start": "1713200",
    "end": "1719279"
  },
  {
    "text": "interfaces in the past for different scenarios and different kinds of data sets but it's not a runnable benchmark like",
    "start": "1719279",
    "end": "1725120"
  },
  {
    "text": "tpch is tpch generates queries that can be executed on database management system the va vr is literally just an",
    "start": "1725120",
    "end": "1731279"
  },
  {
    "text": "unlinked archive so here's my vision for what an ideal benchmark might look like it has three",
    "start": "1731279",
    "end": "1737279"
  },
  {
    "text": "components starting with a data set generator and what's nice about this is that you would be able to generate a",
    "start": "1737279",
    "end": "1742799"
  },
  {
    "text": "data set with certain characteristic characteristics you're interested in for example certain data sets queue or data set size and you could load that one",
    "start": "1742799",
    "end": "1749840"
  },
  {
    "text": "data set and do all the systems that you want to compare and that gives us a nice starting point",
    "start": "1749840",
    "end": "1755039"
  },
  {
    "text": "for an equal comparison or an equivalent comparison",
    "start": "1755039",
    "end": "1760559"
  },
  {
    "text": "then we could have a workload generator which then would drive consistent inputs across these different systems",
    "start": "1760559",
    "end": "1767120"
  },
  {
    "text": "leading to queries that we could measure to test their performance",
    "start": "1767120",
    "end": "1772240"
  },
  {
    "text": "and then finally we would want a consistent set of evaluation metric metrics to test those systems for",
    "start": "1772960",
    "end": "1779440"
  },
  {
    "text": "example the average response time metric that i used to evaluate for cash so as a first step towards achieving",
    "start": "1779440",
    "end": "1785679"
  },
  {
    "text": "this vision i led a large interdisciplinary effort in building the first dbms performance benchmark to test",
    "start": "1785679",
    "end": "1791600"
  },
  {
    "text": "real-time interactive visual exploration scenarios and the main contributions of this work were the findings of a user study for",
    "start": "1791600",
    "end": "1798240"
  },
  {
    "text": "collecting relevant interaction data for this use case translation of that interaction data to a benchmark that could actually be run",
    "start": "1798240",
    "end": "1804720"
  },
  {
    "text": "on database management systems and then the findings of running that benchmark with five existing systems showing that",
    "start": "1804720",
    "end": "1811279"
  },
  {
    "text": "none of the systems we tested actually provides satisfactory performance for real-time exploration even for what the",
    "start": "1811279",
    "end": "1816799"
  },
  {
    "text": "database community would consider modest data set sizes of one to a hundred million rows",
    "start": "1816799",
    "end": "1822399"
  },
  {
    "text": "so for a database benchmark to be compelling especially in this space we actually",
    "start": "1822399",
    "end": "1828480"
  },
  {
    "text": "need the community to be excited about the use cases behind the benchmark and i",
    "start": "1828480",
    "end": "1833919"
  },
  {
    "text": "would argue not just for the database community but the visualization community as well so i'll discuss a little bit about the",
    "start": "1833919",
    "end": "1839440"
  },
  {
    "text": "scenario we picked to anchor the benchmark and specifically we chose crossfilter",
    "start": "1839440",
    "end": "1844720"
  },
  {
    "text": "real-time filtering of dashboards via brush filters or overlaid sliders and i'll show an example here so here we're",
    "start": "1844720",
    "end": "1851600"
  },
  {
    "text": "exploring faa on-time flight performance data through this dashboard built using the falcon system from uw",
    "start": "1851600",
    "end": "1858640"
  },
  {
    "text": "and in this dashboard we have six histograms that a user can interact with and they're all connected so if the user",
    "start": "1858640",
    "end": "1864559"
  },
  {
    "text": "say manipulates this brush filter here on departure delay in minutes all of the other histograms update in response to",
    "start": "1864559",
    "end": "1870799"
  },
  {
    "text": "the user's interactions in real time similarly if we create a new brush on top of",
    "start": "1870799",
    "end": "1876159"
  },
  {
    "text": "distance in miles all of the other histograms also update in response to the user's interactions with near",
    "start": "1876159",
    "end": "1882240"
  },
  {
    "text": "immediate um feedback so because of the real-time nature of cross-filter it's one of them arguably",
    "start": "1882240",
    "end": "1889039"
  },
  {
    "text": "one of the most demanding scenarios for data exploration so if database systems can support this they can support just",
    "start": "1889039",
    "end": "1894240"
  },
  {
    "text": "about anything but on top of this because we need results to appear near immediate we need to have some kind of",
    "start": "1894240",
    "end": "1900080"
  },
  {
    "text": "way of tracking this when we run our benchmark so what we did was we adopted an order of magnitude threshold of 100",
    "start": "1900080",
    "end": "1906399"
  },
  {
    "text": "milliseconds from the literature",
    "start": "1906399",
    "end": "1910320"
  },
  {
    "text": "now how do we go from this use case to an actual benchmark what we did was we conducted a user study to better understand how people actually use these",
    "start": "1913039",
    "end": "1919120"
  },
  {
    "text": "kinds of interfaces and we had two specific questions we wanted to answer so for the first was what if any patterns do we see and how",
    "start": "1919120",
    "end": "1925200"
  },
  {
    "text": "users interact with these interfaces for example do they actually leverage the real-time nature of them and then the second was how do these",
    "start": "1925200",
    "end": "1931840"
  },
  {
    "text": "how might these patterns affect the benchmark so what kind of workload can we expect and how does that influence",
    "start": "1931840",
    "end": "1937039"
  },
  {
    "text": "how we would design database management systems in the future in terms of study design we had 22",
    "start": "1937039",
    "end": "1942480"
  },
  {
    "text": "participants explore crossfilter interface interfaces built using falcon and they explored two out of three data",
    "start": "1942480",
    "end": "1948880"
  },
  {
    "text": "sets so movies data flights data and weather data and then on top of this they explored the data and completed",
    "start": "1948880",
    "end": "1956080"
  },
  {
    "text": "various tasks that we gave them and here's an example of some of those tasks",
    "start": "1956080",
    "end": "1962159"
  },
  {
    "text": "so now let me just give you a brief overview of the study findings so one major takeaway from the study was that",
    "start": "1962159",
    "end": "1968000"
  },
  {
    "text": "crossfilter encourages continuous interactions so here we have a bar chart showing the",
    "start": "1968000",
    "end": "1973840"
  },
  {
    "text": "different kinds of interactions that participants could perform during that study and we found that dragging of brushes what i showed you in the video",
    "start": "1973840",
    "end": "1981840"
  },
  {
    "text": "was actually twice as popular as any of the other interaction types so given the opportunity it seems that people will",
    "start": "1981840",
    "end": "1987760"
  },
  {
    "text": "take advantage of these kind of real-time interactions that provide uh immediate near immediate feedback",
    "start": "1987760",
    "end": "1995760"
  },
  {
    "text": "second we find that crossfilter encourages rapid interactions so more interactions and less time downtime in",
    "start": "1995919",
    "end": "2001200"
  },
  {
    "text": "between interactions so here we have a box plot a series of spots showing the distribution of interactions performed",
    "start": "2001200",
    "end": "2007760"
  },
  {
    "text": "on the x-axis broken down by the data set that was explored and the complexity of the task on the y-axis and we see",
    "start": "2007760",
    "end": "2013200"
  },
  {
    "text": "here that more complex tasks tended to lead to more interactions being performed",
    "start": "2013200",
    "end": "2018480"
  },
  {
    "text": "finally we find that crossfilter leads to high query generation rates so not only is dragging of brush filters the",
    "start": "2018480",
    "end": "2024720"
  },
  {
    "text": "most popular interaction type you also find that it generates the most queries on average 174 queries per second per",
    "start": "2024720",
    "end": "2031760"
  },
  {
    "text": "visualization and the kicker here is that there's not just one visualization and a cross filter",
    "start": "2031760",
    "end": "2037360"
  },
  {
    "text": "interface right so with the example i showed you before for any one histogram that gets manipulated",
    "start": "2037360",
    "end": "2043440"
  },
  {
    "text": "five other ones have to update response so we actually have to take that number 174 and multiply it by five to get the",
    "start": "2043440",
    "end": "2049118"
  },
  {
    "text": "true query rate over time which would push this much closer to a thousand queries a second",
    "start": "2049119",
    "end": "2054560"
  },
  {
    "text": "definitely over 900 queries a second",
    "start": "2054560",
    "end": "2058760"
  },
  {
    "text": "now so how do we actually take our user study data and turn it into a benchmark well first what we did was we took all",
    "start": "2061440",
    "end": "2067118"
  },
  {
    "text": "of the individual log records from our study we mapped them to equivalent sql",
    "start": "2067119",
    "end": "2072320"
  },
  {
    "text": "queries using the ide bench framework then to see how well database management",
    "start": "2072320",
    "end": "2078000"
  },
  {
    "text": "systems perform for different data set sizes we created three different sizes of data sets",
    "start": "2078000",
    "end": "2083760"
  },
  {
    "text": "from our user study data sets 1 million 10 million and 100 million words to demonstrate the value of this",
    "start": "2083760",
    "end": "2089839"
  },
  {
    "text": "benchmark that we created we tested it on five different systems selected for their popularity and or",
    "start": "2089839",
    "end": "2096240"
  },
  {
    "text": "support for analytics so for sake of time i'm only going to highlight one result here",
    "start": "2096240",
    "end": "2102160"
  },
  {
    "text": "which is in terms of response rates so for a cross ulcer interface to be successful we need the query results uh",
    "start": "2102160",
    "end": "2108240"
  },
  {
    "text": "we need the system to be able to respond to user interactions within 100 milliseconds with high rates of success",
    "start": "2108240",
    "end": "2113839"
  },
  {
    "text": "and this is admittedly a very modest threshold so what a database management system has",
    "start": "2113839",
    "end": "2119599"
  },
  {
    "text": "to do is return query results within 100 milliseconds or less with high rates of success and we measured this by calculating",
    "start": "2119599",
    "end": "2125520"
  },
  {
    "text": "response rate the response rate is the percentage of queries that were successfully executed within 100",
    "start": "2125520",
    "end": "2132079"
  },
  {
    "text": "milliseconds and here we see a grid of bar charts showing the results",
    "start": "2132079",
    "end": "2139040"
  },
  {
    "text": "so in the 1 million rows case so the smallest data set case we see that two systems performed pretty",
    "start": "2139040",
    "end": "2146880"
  },
  {
    "text": "well moneydb and duct tape productdb is definitely the best performing system and this is interesting because duct",
    "start": "2146880",
    "end": "2152640"
  },
  {
    "text": "tape and money db are the systems that are most geared towards analytics",
    "start": "2152640",
    "end": "2158320"
  },
  {
    "text": "however as we increase the data set size from 1 million to 100 million rows we see that",
    "start": "2158320",
    "end": "2164960"
  },
  {
    "text": "db's near perfect response rate drops dramatically to at best a 29 response",
    "start": "2164960",
    "end": "2170880"
  },
  {
    "text": "rate meaning that 71 of the time those queries were not executed on time where they were dropped",
    "start": "2170880",
    "end": "2177520"
  },
  {
    "text": "and in general we find that the best performing systems were still two to four times too slow to support real-time variant use cases like cross filter",
    "start": "2177520",
    "end": "2186400"
  },
  {
    "text": "so to summarize i led a large interdisciplinary effort to build the first dbms performance benchmark to",
    "start": "2186400",
    "end": "2192240"
  },
  {
    "text": "support real-time interactive exploration by crossfilter interfaces so our study shows that when given the",
    "start": "2192240",
    "end": "2198000"
  },
  {
    "text": "opportunity people will take advantage of the real-time uh properties of crossover interfaces",
    "start": "2198000",
    "end": "2203920"
  },
  {
    "text": "but in making a benchmark out of the interaction data we actually found that existing systems just aren't fast enough",
    "start": "2203920",
    "end": "2209680"
  },
  {
    "text": "to provide satisfaction performance for cross-filter even for modest asses sizes of one two hundred million rows",
    "start": "2209680",
    "end": "2216880"
  },
  {
    "text": "so now i'll briefly discuss my broader research agenda and highlight some ongoing projects that i'm particularly excited about and share my larger vision",
    "start": "2217440",
    "end": "2224079"
  },
  {
    "text": "for this work going forward so to reiterate the question driving my work is how can we design adaptive systems to",
    "start": "2224079",
    "end": "2230240"
  },
  {
    "text": "amplify the strengths and mitigate the weaknesses of system and human analysts",
    "start": "2230240",
    "end": "2235359"
  },
  {
    "text": "to address this question i conduct research along these three axes which also guide my research",
    "start": "2235359",
    "end": "2240839"
  },
  {
    "text": "agenda for example to further characterize exploration i plan to formalize how existing performance",
    "start": "2240839",
    "end": "2246480"
  },
  {
    "text": "models relate to each other from models of human reasoning to models of interface structure to database cost models",
    "start": "2246480",
    "end": "2254079"
  },
  {
    "text": "to further optimize exploration i plan to design more intelligent and interoperable systems",
    "start": "2254079",
    "end": "2259359"
  },
  {
    "text": "and to enable broader benchmarking of exploration systems i plan to leverage my work and user modeling to do",
    "start": "2259359",
    "end": "2265440"
  },
  {
    "text": "dynamically derive benchmarks directly from experiment data",
    "start": "2265440",
    "end": "2271280"
  },
  {
    "text": "so as part of this research done though my students and i are interested in helping people build their own high performance dashboards for the first",
    "start": "2271280",
    "end": "2277839"
  },
  {
    "text": "where the first step is to help people build their own visualization interfaces especially with languages that are",
    "start": "2277839",
    "end": "2283599"
  },
  {
    "text": "powerful and expressive like d3 the drawback a drawback though is that d3 can be",
    "start": "2283599",
    "end": "2288960"
  },
  {
    "text": "complicated and difficult to learn as a steep learning curve if you will so as an example here's a bar chart that was",
    "start": "2288960",
    "end": "2295760"
  },
  {
    "text": "discussed on stack overflow where the bar chart itself seems very simple but",
    "start": "2295760",
    "end": "2300800"
  },
  {
    "text": "the code that the stack overflow user had to write to generate said bar chart was actually quite for books",
    "start": "2300800",
    "end": "2307280"
  },
  {
    "text": "so what i'm interested in is if we can use automation to make it easier for people to learn complex languages like",
    "start": "2307280",
    "end": "2313119"
  },
  {
    "text": "d3 so to the side my students and i have built a system called myrni for",
    "start": "2313119",
    "end": "2319520"
  },
  {
    "text": "automated recommendation and implementation of d3 visualizations",
    "start": "2319520",
    "end": "2325280"
  },
  {
    "text": "so the way mirani works is that you can upload whatever data set you want in json format and your knee will infer the",
    "start": "2325280",
    "end": "2331760"
  },
  {
    "text": "dataset schema and use that to pre-populate some templates for",
    "start": "2331760",
    "end": "2336800"
  },
  {
    "text": "different visualization designs in d3 but the user can actually write whatever they want they don't have to follow one of those templates",
    "start": "2336800",
    "end": "2343359"
  },
  {
    "text": "but let's say we'll pick one here like scatter plot so the user can make whatever edits they want say change the color scheme if",
    "start": "2343359",
    "end": "2349280"
  },
  {
    "text": "they're scatter plot your name will update and show the results in real time in parallel your name will also",
    "start": "2349280",
    "end": "2354400"
  },
  {
    "text": "recommend interactions that can be integrated into your code so that instead of producing just a static",
    "start": "2354400",
    "end": "2360240"
  },
  {
    "text": "visualization you can produce an interactive one so let's say here the user looks at the recommendations and decides okay i would",
    "start": "2360240",
    "end": "2367119"
  },
  {
    "text": "like to include a brushing interaction into my code so muni will automatically add the brushing interaction once the user",
    "start": "2367119",
    "end": "2373520"
  },
  {
    "text": "clicks on it automatically add that directly into the code and then the user can immediately",
    "start": "2373520",
    "end": "2379680"
  },
  {
    "text": "start brushing on their visualization so to build mirini",
    "start": "2379680",
    "end": "2385119"
  },
  {
    "text": "we analyzed tons of examples from blocks.org and observable including the code and the output visualizations",
    "start": "2385119",
    "end": "2391920"
  },
  {
    "text": "we took the patterns that we observed and we built them we used um computational models to",
    "start": "2391920",
    "end": "2399119"
  },
  {
    "text": "learn these patterns and then we also exploited",
    "start": "2399119",
    "end": "2404560"
  },
  {
    "text": "structural patterns in the code to to support our automated code",
    "start": "2404560",
    "end": "2410640"
  },
  {
    "text": "augmentation techniques so analyze lots of examples trained",
    "start": "2410640",
    "end": "2415680"
  },
  {
    "text": "models to capture the patterns we observed including patterns of code oops",
    "start": "2415680",
    "end": "2421599"
  },
  {
    "text": "externally skipped ahead here all right",
    "start": "2421599",
    "end": "2426800"
  },
  {
    "text": "but d3 is just one language and users aren't going to use just a single language there's actually a spectrum of",
    "start": "2426800",
    "end": "2431839"
  },
  {
    "text": "languages out there ranging from simple languages like poly um or seaborn simpler not not dead simple",
    "start": "2431839",
    "end": "2439520"
  },
  {
    "text": "but simpler where you sort of trade simplicity for um expressiveness",
    "start": "2439520",
    "end": "2446560"
  },
  {
    "text": "easier to use fewer things you can do with them and on the other end you have things like d3 where the sky's the limit",
    "start": "2446560",
    "end": "2452400"
  },
  {
    "text": "but it's more difficult to learn and i'm interested in how users navigate along the spectrum and how we can use",
    "start": "2452400",
    "end": "2457920"
  },
  {
    "text": "automation say in muni or even systems like jupiter lab to help users navigate this spectrum",
    "start": "2457920",
    "end": "2463920"
  },
  {
    "text": "smoothly going from less to more complex languages and vice versa",
    "start": "2463920",
    "end": "2469280"
  },
  {
    "text": "but helping users build high performance dashboards is not just about building visualization interface it's also about",
    "start": "2469280",
    "end": "2474720"
  },
  {
    "text": "helping people test the interface and make sure that it's fast enough so one drawback of the benchmark that i",
    "start": "2474720",
    "end": "2480160"
  },
  {
    "text": "showed you is that it's a specific dashboard design and we derived a static performance test a",
    "start": "2480160",
    "end": "2487839"
  },
  {
    "text": "static workload to test the performance but in reality if we want users to build",
    "start": "2487839",
    "end": "2493440"
  },
  {
    "text": "whatever um dashboard they want this is not good enough we need to provide users a way of",
    "start": "2493440",
    "end": "2499680"
  },
  {
    "text": "specifying what kind of dashboard they want to test and then generate a workload to support them",
    "start": "2499680",
    "end": "2505920"
  },
  {
    "text": "so for example if we could allow users to specify their dashboards with a declarative language",
    "start": "2505920",
    "end": "2512240"
  },
  {
    "text": "then we could use inputs from that language to create say a workload simulator",
    "start": "2512240",
    "end": "2519599"
  },
  {
    "text": "and then we can use existing models of user interaction behavior and then future models that we that we would derive",
    "start": "2519599",
    "end": "2526480"
  },
  {
    "text": "to inform how to generate realistic sequences of interactions on that specified dashboard which we could then",
    "start": "2526480",
    "end": "2532960"
  },
  {
    "text": "translate into queries that get executed on database management systems on top of this",
    "start": "2532960",
    "end": "2538560"
  },
  {
    "text": "if we have a large data set that we could use to infer how someone would interact with the dashboard it might",
    "start": "2538560",
    "end": "2543760"
  },
  {
    "text": "also tell us how people would build dashboards to begin with so something i'm really excited about",
    "start": "2543760",
    "end": "2549839"
  },
  {
    "text": "that's um happened fairly recently is that we're collaborating with tableau to see if we can analyze analyze taboo",
    "start": "2549839",
    "end": "2556960"
  },
  {
    "text": "tableau public dashboards at scale so that we can build models to automatically generate specifications of",
    "start": "2556960",
    "end": "2562079"
  },
  {
    "text": "realistic dashboard designs as well as build models of how users will interact with said dashboards",
    "start": "2562079",
    "end": "2568240"
  },
  {
    "text": "so zooming out a bit these ongoing projects hint at a larger vision i have for my work which is that this idea that",
    "start": "2568240",
    "end": "2574800"
  },
  {
    "text": "people grow and change as they explore and analyze their data and it would be great for interactive analysis systems",
    "start": "2574800",
    "end": "2580560"
  },
  {
    "text": "to evolve with them as users interact with systems like forecasting unity",
    "start": "2580560",
    "end": "2585839"
  },
  {
    "text": "they're taking the insights that they learn from their interactions and then develop developing their knowledge and their expertise so then the next time",
    "start": "2585839",
    "end": "2592720"
  },
  {
    "text": "they come to this these systems or even other systems they're making more informed decisions about how and why",
    "start": "2592720",
    "end": "2598480"
  },
  {
    "text": "they're going to perform these interactions so i'm interested in the long term",
    "start": "2598480",
    "end": "2603680"
  },
  {
    "text": "answering this question of how can we design interactive analysis systems that evolve with the user over time for",
    "start": "2603680",
    "end": "2608880"
  },
  {
    "text": "example throughout the course of one or multiple data science projects so with myrni we have we have a",
    "start": "2608880",
    "end": "2616720"
  },
  {
    "text": "technical report it's still um basically under preparation but we do have a technical",
    "start": "2616720",
    "end": "2622000"
  },
  {
    "text": "report on available on archive so if you're interested you can check that out",
    "start": "2622000",
    "end": "2627280"
  },
  {
    "text": "yes that's that is my talk and i would love to take questions excellent",
    "start": "2630079",
    "end": "2636720"
  },
  {
    "text": "thank you so much lelani we have plenty of time for questions um and if they come in over",
    "start": "2639200",
    "end": "2646839"
  },
  {
    "text": "zoom slack uh will help us with those",
    "start": "2646839",
    "end": "2653520"
  },
  {
    "text": "sounds good so can i just ask when out loud",
    "start": "2654480",
    "end": "2662400"
  },
  {
    "text": "but she can hear me i guess yes okay uh yeah i i thought the user",
    "start": "2663839",
    "end": "2669359"
  },
  {
    "text": "modeling was really cool um and i was wondering like there's kind of the assumption that like changing user",
    "start": "2669359",
    "end": "2675359"
  },
  {
    "text": "interface won't um change the behavior like when you're like",
    "start": "2675359",
    "end": "2680640"
  },
  {
    "text": "like you have like the perfect no latency or low latency condition um",
    "start": "2680640",
    "end": "2686640"
  },
  {
    "text": "have you thought at all about how to model like how changing the caching would change the user's behavior",
    "start": "2686640",
    "end": "2693119"
  },
  {
    "text": "and how to evaluate that sort of more complex scenario this is a this is a great question",
    "start": "2693119",
    "end": "2700240"
  },
  {
    "text": "so so actually the the first project that i showed where i was running the amazon",
    "start": "2700240",
    "end": "2705280"
  },
  {
    "text": "mechanical turf studies the original um idea that we were excited about with that with that series of experiments was",
    "start": "2705280",
    "end": "2714720"
  },
  {
    "text": "could i mean this is not a happy sunshiny way of asking this question but",
    "start": "2715599",
    "end": "2720880"
  },
  {
    "text": "could we potentially manipulate users into finding a particular target based",
    "start": "2720880",
    "end": "2726079"
  },
  {
    "text": "on the patterns of latency that they get exposed to so absolutely yes i think the system's",
    "start": "2726079",
    "end": "2732240"
  },
  {
    "text": "behavior that will have an effect on how people choose to explore their data",
    "start": "2732240",
    "end": "2737359"
  },
  {
    "text": "um and i i'm really interested in this question too for visualization recommendations because visualization",
    "start": "2737359",
    "end": "2744560"
  },
  {
    "text": "recommendations or even recommendations on amazon right as you're buying things they literally influence what you're",
    "start": "2744560",
    "end": "2750319"
  },
  {
    "text": "going to do just seeing them will affect your behavior versus you know working with a system",
    "start": "2750319",
    "end": "2756160"
  },
  {
    "text": "with an absence of recommendations so what i'm interested in is a similar question to you for recommendation",
    "start": "2756160",
    "end": "2761440"
  },
  {
    "text": "prevent systems which is can you potentially you know lead users down a path where",
    "start": "2761440",
    "end": "2768400"
  },
  {
    "text": "they would draw certain conclusions from the data maybe in conclusions they shouldn't be drawing um through those recommendations and not",
    "start": "2768400",
    "end": "2774640"
  },
  {
    "text": "realize how much um their exploration patterns are being manipulated",
    "start": "2774640",
    "end": "2780400"
  },
  {
    "text": "this is again looking at it from more of like a security perspective but i find this very interesting",
    "start": "2780480",
    "end": "2786400"
  },
  {
    "text": "and this question of bias in general as well because systems can amplify bias biases",
    "start": "2786400",
    "end": "2791599"
  },
  {
    "text": "that are there um and i'm definitely interested in seeing how we can quantify that how we",
    "start": "2791599",
    "end": "2797040"
  },
  {
    "text": "can measure that and then what that means for the systems that we build in data science the the mirroring uh you",
    "start": "2797040",
    "end": "2804000"
  },
  {
    "text": "mentioned i think it's super interesting and um and you talk about like the tool will allow users to generate different",
    "start": "2804000",
    "end": "2810880"
  },
  {
    "text": "graphs like different kind of models like so so i guess the templates are like still limited like what if the user",
    "start": "2810880",
    "end": "2818000"
  },
  {
    "text": "want to build something that is not supported like are there any features that might for example draw opinions",
    "start": "2818000",
    "end": "2823920"
  },
  {
    "text": "from the experts or like any human loop stuff yeah so",
    "start": "2823920",
    "end": "2828960"
  },
  {
    "text": "the the templates are really just a starting point the work one component of miuni um",
    "start": "2828960",
    "end": "2834000"
  },
  {
    "text": "a user could actually write a d3 visualization from scratch and then mary would still try to make recommendations",
    "start": "2834000",
    "end": "2839359"
  },
  {
    "text": "on interactions that you could add but i agree the template strategy is limited",
    "start": "2839359",
    "end": "2844880"
  },
  {
    "text": "um the idea behind that is we we wanted to pretty much mine templates from a large corpus of d3 code that's",
    "start": "2844880",
    "end": "2852160"
  },
  {
    "text": "where the templates come from and then on top of that we wanted to make basically agile recommendations",
    "start": "2852160",
    "end": "2857839"
  },
  {
    "text": "where you can respond to what the user is doing in the editor live rather than",
    "start": "2857839",
    "end": "2863599"
  },
  {
    "text": "relying solely on the templates but the idea is that if um",
    "start": "2863599",
    "end": "2868800"
  },
  {
    "text": "if what the user's doing still looks pretty similar to a template we've seen in the past we could just try to fill in the gap to",
    "start": "2868800",
    "end": "2875040"
  },
  {
    "text": "make a recommendation that will still work in the code it's not perfect it definitely still can run into errors",
    "start": "2875040",
    "end": "2882480"
  },
  {
    "text": "we don't we don't have a panacea i'm not pretending like i we have one of those but okay thank you",
    "start": "2882480",
    "end": "2889920"
  },
  {
    "text": "so i have a question um so i i really love this idea of",
    "start": "2892400",
    "end": "2897839"
  },
  {
    "text": "capturing interaction traces and using that to analyze performance of the of the database",
    "start": "2897839",
    "end": "2905440"
  },
  {
    "text": "and the visualization um at the same time interaction traces are",
    "start": "2905440",
    "end": "2910960"
  },
  {
    "text": "fairly low they're level they're not uh telling you a whole lot directly about",
    "start": "2910960",
    "end": "2917680"
  },
  {
    "text": "what the user is trying to do and so i wonder um",
    "start": "2917680",
    "end": "2922960"
  },
  {
    "text": "if you thought at all about you know what kind of information you",
    "start": "2922960",
    "end": "2928079"
  },
  {
    "text": "would like to get from the user if you could ideally get it as they're interacting with these",
    "start": "2928079",
    "end": "2933440"
  },
  {
    "text": "visualizations could we go beyond the could we go",
    "start": "2933440",
    "end": "2939040"
  },
  {
    "text": "beyond the kind of low level you know point-and-click yeah i love this question so",
    "start": "2939040",
    "end": "2946559"
  },
  {
    "text": "um in my more recent work i've been thinking about interactions basically as a mode of expression kind of like how we",
    "start": "2946559",
    "end": "2953599"
  },
  {
    "text": "might use words to express ourselves or use other media to express ourselves um and what we have in our heads is",
    "start": "2953599",
    "end": "2960400"
  },
  {
    "text": "never going to be represented perfectly or at least not right now going to be represented perfectly with that",
    "start": "2960400",
    "end": "2965760"
  },
  {
    "text": "particular mode of expression right there's always going to be something that gets translated and interaction",
    "start": "2965760",
    "end": "2971040"
  },
  {
    "text": "logs are basically a translation reverse engineering process",
    "start": "2971040",
    "end": "2976160"
  },
  {
    "text": "so um i don't necessarily have solutions yet but so",
    "start": "2976160",
    "end": "2982160"
  },
  {
    "text": "a recent work that we had a well hopefully we'll",
    "start": "2982160",
    "end": "2988640"
  },
  {
    "text": "most likely be at kai 2022 is we did a wizard of oz style user study",
    "start": "2988640",
    "end": "2994400"
  },
  {
    "text": "where we basically um pretended to be a visualization design system and we",
    "start": "2994400",
    "end": "3001040"
  },
  {
    "text": "worked with experts in public health to understand okay if you as an expert had to recommend yourself",
    "start": "3001040",
    "end": "3008720"
  },
  {
    "text": "visualizations for some other colleague to look at to get started on a new project say analyzing um some national",
    "start": "3008720",
    "end": "3016319"
  },
  {
    "text": "health survey data what visualizations would you as the human recommend to this other human",
    "start": "3016319",
    "end": "3022160"
  },
  {
    "text": "and our interest was you know in understanding what do people value when they're creating",
    "start": "3022160",
    "end": "3027839"
  },
  {
    "text": "recommendations themselves like what do they value in recommendations in general and how does that align with or how does",
    "start": "3027839",
    "end": "3033359"
  },
  {
    "text": "that not align with the way we make prioritizations in how we design visualization recognition systems",
    "start": "3033359",
    "end": "3039359"
  },
  {
    "text": "so this is our way of trying to get at you know what do people value what do people care about",
    "start": "3039359",
    "end": "3044960"
  },
  {
    "text": "and are we you know are we aligned with them so trying to get get out of the kind of",
    "start": "3044960",
    "end": "3050240"
  },
  {
    "text": "log data format and think more about um you know trying trying to find what's",
    "start": "3050240",
    "end": "3056559"
  },
  {
    "text": "what people are thinking and then another thing that i'm working on right now that are that my students",
    "start": "3056559",
    "end": "3063119"
  },
  {
    "text": "are working on is in building a new performance benchmark that rather than just taking the",
    "start": "3063119",
    "end": "3069599"
  },
  {
    "text": "interactions that other people performed and saying you know here's the best way to benchmark just",
    "start": "3069599",
    "end": "3076319"
  },
  {
    "text": "how well would you support this thing these people did rather than the thing these people were trying to do",
    "start": "3076319",
    "end": "3081680"
  },
  {
    "text": "we want to simulate um interaction behavior and the idea is that if we can think of",
    "start": "3081680",
    "end": "3087440"
  },
  {
    "text": "specific kinds of goals like classes of goals that people might want to perform",
    "start": "3087440",
    "end": "3092960"
  },
  {
    "text": "and then we can create an approximation of those goals for a new data set or a",
    "start": "3092960",
    "end": "3098160"
  },
  {
    "text": "new dashboard then we could try to simulate someone trying to achieve that goal using that",
    "start": "3098160",
    "end": "3103359"
  },
  {
    "text": "interface basically that workload simulator simulator work i mentioned towards the",
    "start": "3103359",
    "end": "3108640"
  },
  {
    "text": "end of my talk we are making first steps towards that and what i like about that is it's not just about you know oh yeah",
    "start": "3108640",
    "end": "3115119"
  },
  {
    "text": "this human in the past at some point did this sequence of interactions if",
    "start": "3115119",
    "end": "3120559"
  },
  {
    "text": "your new system can do that sequence interactions and you're good the idea is trying to get away from that and",
    "start": "3120559",
    "end": "3126000"
  },
  {
    "text": "saying more here's a set of goals we think users often have here's how this goal might",
    "start": "3126000",
    "end": "3131680"
  },
  {
    "text": "manifest with your dashboard and here and now we can test whether or not your dashboard will allow people to",
    "start": "3131680",
    "end": "3137920"
  },
  {
    "text": "pursue that goal and if so what interactions make the most sense in trying to pursue that goal so now",
    "start": "3137920",
    "end": "3143920"
  },
  {
    "text": "it's at a higher level so we still need interactions because they're a mode of you know translation but now we're",
    "start": "3143920",
    "end": "3149440"
  },
  {
    "text": "translating from goals rather than just using the interactions and not thinking about you know",
    "start": "3149440",
    "end": "3154880"
  },
  {
    "text": "what they're connected to in terms of what the user's trying to do right and and just to follow up on that",
    "start": "3154880",
    "end": "3161280"
  },
  {
    "text": "how much do you think those goals and the interactions that result",
    "start": "3161280",
    "end": "3166559"
  },
  {
    "text": "there there are two different levels obviously but um how much do you think the goals",
    "start": "3166559",
    "end": "3172400"
  },
  {
    "text": "differ depending on the data right and the task so the tasks will",
    "start": "3172400",
    "end": "3177920"
  },
  {
    "text": "differ depending on the data but how much difference will there be i think there can be pretty significant",
    "start": "3177920",
    "end": "3184480"
  },
  {
    "text": "differences depending so let's say one data set has temporal data associated with it and another data set",
    "start": "3184480",
    "end": "3190559"
  },
  {
    "text": "does not that could completely change the kinds of analyses that you're available that how you have available to you and then there for your goals yeah",
    "start": "3190559",
    "end": "3199359"
  },
  {
    "text": "i think i think it can have a huge difference so um we're starting small we're kind of picking a core set of",
    "start": "3199359",
    "end": "3207040"
  },
  {
    "text": "goals that commonly appear and we're sort of using we're relying on the literature to help guide us there",
    "start": "3207040",
    "end": "3214000"
  },
  {
    "text": "and then the hope is that if we can build you know a framework that people can extend then as more",
    "start": "3214000",
    "end": "3219760"
  },
  {
    "text": "goals come in they can just add and add them to that framework to kind of capture more of the space",
    "start": "3219760",
    "end": "3225200"
  },
  {
    "text": "but it's a huge it's a huge space there are a lot of goals someone could have",
    "start": "3225200",
    "end": "3231119"
  },
  {
    "text": "all right um well we're getting close to the end here are any last questions",
    "start": "3232559",
    "end": "3238559"
  },
  {
    "text": "okay great well thank you again lelani that was a great talk and um",
    "start": "3238559",
    "end": "3244240"
  },
  {
    "text": "uh really glad that you could come down for this thank you so much this has been a ton of fun i hope everyone has a great term",
    "start": "3244240",
    "end": "3252880"
  },
  {
    "text": "thank you we'll see you next time",
    "start": "3252880",
    "end": "3257960"
  }
]
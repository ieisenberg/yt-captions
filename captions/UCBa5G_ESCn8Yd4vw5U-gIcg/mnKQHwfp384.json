[
  {
    "start": "0",
    "end": "12000"
  },
  {
    "start": "0",
    "end": "4460"
  },
  {
    "text": "CHRISTOPHER POTTS:\nWelcome, everyone",
    "start": "4460",
    "end": "5960"
  },
  {
    "text": "to part 3 in our series on\nanalysis methods in NLP.",
    "start": "5960",
    "end": "8900"
  },
  {
    "text": "We're going to be talking about\nadversarial training as well",
    "start": "8900",
    "end": "11509"
  },
  {
    "text": "as testing of systems.",
    "start": "11510",
    "end": "12590"
  },
  {
    "start": "12000",
    "end": "34000"
  },
  {
    "text": "This is the second of the\nbehavioral evaluation methods",
    "start": "12590",
    "end": "15682"
  },
  {
    "text": "that we're considering.",
    "start": "15682",
    "end": "16640"
  },
  {
    "text": "We've previously talked\nabout adversarial testing.",
    "start": "16640",
    "end": "19580"
  },
  {
    "text": "Adversarial training\nand testing, of course,",
    "start": "19580",
    "end": "21560"
  },
  {
    "text": "implies that we have much\nlarger datasets, that this",
    "start": "21560",
    "end": "23810"
  },
  {
    "text": "is more difficult to do.",
    "start": "23810",
    "end": "25820"
  },
  {
    "text": "But for selected tasks\nwhere we have such datasets,",
    "start": "25820",
    "end": "28490"
  },
  {
    "text": "this can be very\nexciting and push",
    "start": "28490",
    "end": "30050"
  },
  {
    "text": "you to address all sorts\nof interesting cutting edge",
    "start": "30050",
    "end": "32270"
  },
  {
    "text": "questions.",
    "start": "32270",
    "end": "34080"
  },
  {
    "start": "34000",
    "end": "56000"
  },
  {
    "text": "I'll start with SWAG.",
    "start": "34080",
    "end": "35190"
  },
  {
    "text": "This is an early entry into the\nspace of adversarial training",
    "start": "35190",
    "end": "38070"
  },
  {
    "text": "sets.",
    "start": "38070",
    "end": "38730"
  },
  {
    "text": "SWAG stands for Situations\nWith Adversarial Generations.",
    "start": "38730",
    "end": "43590"
  },
  {
    "text": "There's actually two data sets,\nSWAG and the colorfully named",
    "start": "43590",
    "end": "46470"
  },
  {
    "text": "HellaSWAG.",
    "start": "46470",
    "end": "47295"
  },
  {
    "text": "And you'll see why there\nare two in a second.",
    "start": "47295",
    "end": "49170"
  },
  {
    "text": "This is fundamentally, again,\nanother interesting story",
    "start": "49170",
    "end": "52379"
  },
  {
    "text": "of very rapid\nprogress in our field.",
    "start": "52380",
    "end": "56180"
  },
  {
    "start": "56000",
    "end": "107000"
  },
  {
    "text": "Here's how SWAG examples work.",
    "start": "56180",
    "end": "57860"
  },
  {
    "text": "We're given as a system input\na context like, \"he is throwing",
    "start": "57860",
    "end": "61970"
  },
  {
    "text": "darts at a target\" and\nanother system input, which",
    "start": "61970",
    "end": "64878"
  },
  {
    "text": "is the start of a sentence,\nhere it's, \"another man.\"",
    "start": "64879",
    "end": "68090"
  },
  {
    "text": "And the task of the system\nis to figure out what",
    "start": "68090",
    "end": "70340"
  },
  {
    "text": "the continuation should be.",
    "start": "70340",
    "end": "71729"
  },
  {
    "text": "So the actual continuation\nthat we predict might be,",
    "start": "71730",
    "end": "74030"
  },
  {
    "text": "\"throws a dart at\nthe target board.\"",
    "start": "74030",
    "end": "76580"
  },
  {
    "text": "And this is fundamentally\na classification task,",
    "start": "76580",
    "end": "79050"
  },
  {
    "text": "the system is given\nsome distractors like,",
    "start": "79050",
    "end": "81320"
  },
  {
    "text": "\"comes running in and shoots\nan arrow at a target,\"",
    "start": "81320",
    "end": "83600"
  },
  {
    "text": "or \"is shown on\nthe side of men,\"",
    "start": "83600",
    "end": "85159"
  },
  {
    "text": "or \"throws darts at a disk.\"",
    "start": "85160",
    "end": "86810"
  },
  {
    "text": "And the system is\ntasked with figuring out",
    "start": "86810",
    "end": "88610"
  },
  {
    "text": "which of the options is\nthe actual continuation",
    "start": "88610",
    "end": "91250"
  },
  {
    "text": "for the sentence,\ngiven the context.",
    "start": "91250",
    "end": "94280"
  },
  {
    "text": "The data sources for this are\nActivityNet and the Large Scale",
    "start": "94280",
    "end": "97549"
  },
  {
    "text": "Movie Description Challenge.",
    "start": "97550",
    "end": "98840"
  },
  {
    "text": "I think the idea\nhere is that we're",
    "start": "98840",
    "end": "100298"
  },
  {
    "text": "going to key in to all\nsorts of interesting notions",
    "start": "100298",
    "end": "102530"
  },
  {
    "text": "of common sense reasoning.",
    "start": "102530",
    "end": "105510"
  },
  {
    "text": "Now here's where the adversarial\npart of this comes in,",
    "start": "105510",
    "end": "107960"
  },
  {
    "start": "107000",
    "end": "177000"
  },
  {
    "text": "we're going to do adversarial\nfiltering for SWAG.",
    "start": "107960",
    "end": "110930"
  },
  {
    "text": "For each of the\nexamples in our corpus,",
    "start": "110930",
    "end": "112790"
  },
  {
    "text": "and there are over\n100,000 examples in SWAG,",
    "start": "112790",
    "end": "115792"
  },
  {
    "text": "we're going to be given the\nsystem input like, \"the mixture",
    "start": "115792",
    "end": "118250"
  },
  {
    "text": "creams the butter.",
    "start": "118250",
    "end": "119220"
  },
  {
    "text": "Sugar.\"",
    "start": "119220",
    "end": "121370"
  },
  {
    "text": "And then we'll have a generator\nmodel- in the case of SWAG,",
    "start": "121370",
    "end": "124300"
  },
  {
    "text": "this was an LSTM produce some\ndistractors for the target.",
    "start": "124300",
    "end": "128119"
  },
  {
    "text": "So let's suppose that the actual\ntarget continuation is added,",
    "start": "128120",
    "end": "131200"
  },
  {
    "text": "we'd have a model produce \"is\nsweet\" and \"is in many foods.\"",
    "start": "131200",
    "end": "135020"
  },
  {
    "text": "And then we have\nthe filtering model.",
    "start": "135020",
    "end": "137350"
  },
  {
    "text": "If it guesses correctly\nfor \"is added,\"",
    "start": "137350",
    "end": "139540"
  },
  {
    "text": "then we're going to drop\nout this entire example",
    "start": "139540",
    "end": "142180"
  },
  {
    "text": "and we'll create some\nnew distractors like",
    "start": "142180",
    "end": "144519"
  },
  {
    "text": "\"is sprinkled on top\"\nor \"is in many foods.\"",
    "start": "144520",
    "end": "146980"
  },
  {
    "text": "And in this case, if the\nmodel guesses incorrectly",
    "start": "146980",
    "end": "149515"
  },
  {
    "text": "like suppose it\nchooses b in this case,",
    "start": "149515",
    "end": "152290"
  },
  {
    "text": "then we'll keep this example\nbecause relative to the current",
    "start": "152290",
    "end": "155349"
  },
  {
    "text": "models for the thing\nwe're using to generate",
    "start": "155350",
    "end": "158140"
  },
  {
    "text": "these distractors and the thing\nthat we're using to filter,",
    "start": "158140",
    "end": "161050"
  },
  {
    "text": "this is a challenging example.",
    "start": "161050",
    "end": "163083"
  },
  {
    "text": "And the idea is\nthat we can repeat",
    "start": "163083",
    "end": "164500"
  },
  {
    "text": "this for a bunch of iterations,\ncontinually retraining",
    "start": "164500",
    "end": "167032"
  },
  {
    "text": "the filtering model\nso that it gets",
    "start": "167032",
    "end": "168489"
  },
  {
    "text": "better and better and therefore,\nending up with a dataset that",
    "start": "168490",
    "end": "171670"
  },
  {
    "text": "is really, really difficult\nin terms of the current models",
    "start": "171670",
    "end": "174819"
  },
  {
    "text": "that we had available to us.",
    "start": "174820",
    "end": "177740"
  },
  {
    "start": "177000",
    "end": "222000"
  },
  {
    "text": "Here's a picture\nof test accuracy.",
    "start": "177740",
    "end": "179470"
  },
  {
    "text": "This is interesting here.",
    "start": "179470",
    "end": "180610"
  },
  {
    "text": "They actually did an\nensemble of filtering models",
    "start": "180610",
    "end": "183430"
  },
  {
    "text": "to try to key into\ndifferent notions that",
    "start": "183430",
    "end": "185799"
  },
  {
    "text": "might be indicating which\nis the correct continuation.",
    "start": "185800",
    "end": "189340"
  },
  {
    "text": "So they start by using just\na multi-layer perceptron",
    "start": "189340",
    "end": "191980"
  },
  {
    "text": "for efficiency,\nand then they bring",
    "start": "191980",
    "end": "193720"
  },
  {
    "text": "in all of these ensembles.",
    "start": "193720",
    "end": "195040"
  },
  {
    "text": "And you can see\nthe test accuracy",
    "start": "195040",
    "end": "197049"
  },
  {
    "text": "as we do this iterative\nfiltering very quickly goes",
    "start": "197050",
    "end": "200080"
  },
  {
    "text": "down so that by iteration\n140 we're at 10% accuracy.",
    "start": "200080",
    "end": "204465"
  },
  {
    "text": "So that's the\nsense in which this",
    "start": "204465",
    "end": "205840"
  },
  {
    "text": "is a very difficult dataset\nbecause given the generator",
    "start": "205840",
    "end": "208510"
  },
  {
    "text": "model and the filtering model\nthat we have available to us,",
    "start": "208510",
    "end": "211780"
  },
  {
    "text": "we have a dataset that is\nvery difficult in terms",
    "start": "211780",
    "end": "214600"
  },
  {
    "text": "of a classification task.",
    "start": "214600",
    "end": "216805"
  },
  {
    "text": "So that looks really\nexciting and challenging",
    "start": "216805",
    "end": "218680"
  },
  {
    "text": "and I think the authors\nexpected this dataset",
    "start": "218680",
    "end": "221140"
  },
  {
    "text": "to last for a very long time.",
    "start": "221140",
    "end": "222920"
  },
  {
    "start": "222000",
    "end": "266000"
  },
  {
    "text": "However, the BERT paper,\nthe original BERT paper,",
    "start": "222920",
    "end": "226540"
  },
  {
    "text": "did evaluations on SWAG and\nessentially solved the problem.",
    "start": "226540",
    "end": "229674"
  },
  {
    "text": "BERT Large got 86.6 and 86.3%\non the dev and test sets",
    "start": "229675",
    "end": "235330"
  },
  {
    "text": "for SWAG respectively, a\nvery unexpected result given",
    "start": "235330",
    "end": "238660"
  },
  {
    "text": "that I just showed you that\nthe SWAG authors got about 10%",
    "start": "238660",
    "end": "242680"
  },
  {
    "text": "with their current models.",
    "start": "242680",
    "end": "244390"
  },
  {
    "text": "And even closely related models\nto BERT like this ESIM model",
    "start": "244390",
    "end": "248800"
  },
  {
    "text": "here, were really pretty\nlow in their performance.",
    "start": "248800",
    "end": "251225"
  },
  {
    "text": "So BERT looked like\na real breakthrough",
    "start": "251225",
    "end": "252850"
  },
  {
    "text": "and you can see that it's\nin some sense superhuman",
    "start": "252850",
    "end": "255550"
  },
  {
    "text": "relative to the SWAG estimates.",
    "start": "255550",
    "end": "257950"
  },
  {
    "text": "So wow.",
    "start": "257950",
    "end": "258880"
  },
  {
    "text": "So, of course, we know what the\nresponse should be given that",
    "start": "258880",
    "end": "261489"
  },
  {
    "text": "we're talking essentially about\nmodel-in-the-loop adversarial",
    "start": "261490",
    "end": "264490"
  },
  {
    "text": "dataset creation.",
    "start": "264490",
    "end": "265930"
  },
  {
    "text": "That leads us to HellaSWAG.",
    "start": "265930",
    "end": "267759"
  },
  {
    "start": "266000",
    "end": "326000"
  },
  {
    "text": "They made some\nchanges to the dataset",
    "start": "267760",
    "end": "269890"
  },
  {
    "text": "that they use for\nHellaSWAG, but I",
    "start": "269890",
    "end": "271450"
  },
  {
    "text": "would say the\nfundamental thing is",
    "start": "271450",
    "end": "273490"
  },
  {
    "text": "that we do the same adversarial\nfiltering with the generator,",
    "start": "273490",
    "end": "277210"
  },
  {
    "text": "except now we have much\nmore powerful filtering",
    "start": "277210",
    "end": "280030"
  },
  {
    "text": "and generator models,\nthanks to developments",
    "start": "280030",
    "end": "282460"
  },
  {
    "text": "related to transformers.",
    "start": "282460",
    "end": "284289"
  },
  {
    "text": "So for HellaSWAG, we again\nhave human performance",
    "start": "284290",
    "end": "286720"
  },
  {
    "text": "that's really good.",
    "start": "286720",
    "end": "287530"
  },
  {
    "text": "This is very\nreassuring because we",
    "start": "287530",
    "end": "289540"
  },
  {
    "text": "are using much more\npowerful models at step 4.",
    "start": "289540",
    "end": "292630"
  },
  {
    "text": "As you can expect, BERT\nis no longer easily",
    "start": "292630",
    "end": "295840"
  },
  {
    "text": "able to solve this problem.",
    "start": "295840",
    "end": "297830"
  },
  {
    "text": "Here's a further summary of\nthe results with BERT Large",
    "start": "297830",
    "end": "300400"
  },
  {
    "text": "before I remember that it's\nessentially solved SWAG.",
    "start": "300400",
    "end": "303160"
  },
  {
    "text": "Now it's down around 50%\nwhich shows that it still gets",
    "start": "303160",
    "end": "307000"
  },
  {
    "text": "traction but is nothing like\nthe superhuman performance",
    "start": "307000",
    "end": "310660"
  },
  {
    "text": "that we saw for SWAG.",
    "start": "310660",
    "end": "312910"
  },
  {
    "text": "OK.",
    "start": "312910",
    "end": "313410"
  },
  {
    "text": "Now let's move into a\nslightly different mode,",
    "start": "313410",
    "end": "315000"
  },
  {
    "text": "and this is going to be a\nkind of human-in-the-loop",
    "start": "315000",
    "end": "317125"
  },
  {
    "text": "adversarial dataset\ncreation method.",
    "start": "317125",
    "end": "319590"
  },
  {
    "text": "The first entry in this space\nwas the adversarial NLI data",
    "start": "319590",
    "end": "322770"
  },
  {
    "text": "set, I think this is a really\nvisionary and exciting paper.",
    "start": "322770",
    "end": "326490"
  },
  {
    "start": "326000",
    "end": "415000"
  },
  {
    "text": "Adversarial NLI is a direct\nresponse to the previous things",
    "start": "326490",
    "end": "331050"
  },
  {
    "text": "that we've seen with the\nSNLI and multi-NLI datasets",
    "start": "331050",
    "end": "334229"
  },
  {
    "text": "where models seem to do\nwell on those benchmarks",
    "start": "334230",
    "end": "337620"
  },
  {
    "text": "but are easily susceptible\nto simple adversaries.",
    "start": "337620",
    "end": "340710"
  },
  {
    "text": "With adversarial\nNLI, we're going",
    "start": "340710",
    "end": "342240"
  },
  {
    "text": "to hopefully push\nsystems to be much more",
    "start": "342240",
    "end": "345389"
  },
  {
    "text": "robust to those\nadversaries and explore",
    "start": "345390",
    "end": "347430"
  },
  {
    "text": "a much wider range of\nthe space of things",
    "start": "347430",
    "end": "349620"
  },
  {
    "text": "you might see under the heading\nof natural language inference.",
    "start": "349620",
    "end": "353020"
  },
  {
    "text": "So here's how it worked.",
    "start": "353020",
    "end": "354425"
  },
  {
    "text": "There's a human in the loop,\nan annotator, and the annotator",
    "start": "354425",
    "end": "356925"
  },
  {
    "text": "is presented with a premise\nsentence and a condition",
    "start": "356925",
    "end": "360120"
  },
  {
    "text": "that they need to be in,\nwhich is just an NLI label-",
    "start": "360120",
    "end": "362370"
  },
  {
    "text": "entailment,\ncontradiction, or neutral.",
    "start": "362370",
    "end": "365350"
  },
  {
    "text": "The annotator writes a\nhypothesis to go along with",
    "start": "365350",
    "end": "367810"
  },
  {
    "text": "the premise and the condition\nand then a state-of-the-art",
    "start": "367810",
    "end": "370720"
  },
  {
    "text": "model comes in and makes a\nprediction about the premise",
    "start": "370720",
    "end": "373330"
  },
  {
    "text": "hypothesis pair.",
    "start": "373330",
    "end": "375189"
  },
  {
    "text": "If the model's prediction\nmatches the condition, that",
    "start": "375190",
    "end": "377980"
  },
  {
    "text": "is, if the model\nwas correct, then",
    "start": "377980",
    "end": "379720"
  },
  {
    "text": "the annotator needs to return\nto step 2 and try again",
    "start": "379720",
    "end": "382720"
  },
  {
    "text": "with a new hypothesis.",
    "start": "382720",
    "end": "384400"
  },
  {
    "text": "And we could continue\nin that loop.",
    "start": "384400",
    "end": "386350"
  },
  {
    "text": "If the model was fooled,\nthe premise-hypothesis pair",
    "start": "386350",
    "end": "389020"
  },
  {
    "text": "is independently validated by\nother annotators, of course.",
    "start": "389020",
    "end": "391990"
  },
  {
    "text": "So what we get out of this\nis we hope a dataset that",
    "start": "391990",
    "end": "395380"
  },
  {
    "text": "is intuitive for humans,\nbecause of the check in step 5,",
    "start": "395380",
    "end": "398690"
  },
  {
    "text": "but assuming we continue to\nloop around through 2, 3 and 4,",
    "start": "398690",
    "end": "402010"
  },
  {
    "text": "an example that is really\ndifficult for whatever",
    "start": "402010",
    "end": "404410"
  },
  {
    "text": "model is in the loop.",
    "start": "404410",
    "end": "406000"
  },
  {
    "text": "And the expectation is that as\nwe put better and better models",
    "start": "406000",
    "end": "409150"
  },
  {
    "text": "in the loop here, we're going to\nget even more challenging data",
    "start": "409150",
    "end": "412150"
  },
  {
    "text": "sets as an outcome.",
    "start": "412150",
    "end": "415560"
  },
  {
    "start": "415000",
    "end": "444000"
  },
  {
    "text": "NLI examples tend to be\nimpressively complex.",
    "start": "415560",
    "end": "418040"
  },
  {
    "text": "You can see that this example\nhas a very long premise.",
    "start": "418040",
    "end": "421130"
  },
  {
    "text": "The hypothesis was\nrelatively shorter.",
    "start": "421130",
    "end": "423080"
  },
  {
    "text": "And an intriguing aspect\nof adverserial NLI",
    "start": "423080",
    "end": "425780"
  },
  {
    "text": "is that annotators\nalso constructed",
    "start": "425780",
    "end": "427790"
  },
  {
    "text": "a reason or a rationale\nfor their label",
    "start": "427790",
    "end": "429950"
  },
  {
    "text": "holding between the\npremise-hypothesis pair.",
    "start": "429950",
    "end": "432650"
  },
  {
    "text": "To date, as far as I know,\nrelatively little use",
    "start": "432650",
    "end": "434762"
  },
  {
    "text": "has been made of\nthese texts, but I",
    "start": "434762",
    "end": "436220"
  },
  {
    "text": "think they could bring in other\naspects of natural language",
    "start": "436220",
    "end": "439453"
  },
  {
    "text": "inference reasoning\nand that could",
    "start": "439453",
    "end": "440870"
  },
  {
    "text": "be an exciting new direction.",
    "start": "440870",
    "end": "444229"
  },
  {
    "start": "444000",
    "end": "480000"
  },
  {
    "text": "Adversarial NLI is a\ndifficult dataset indeed.",
    "start": "444230",
    "end": "447590"
  },
  {
    "text": "We have a similar\nsort of leaderboard",
    "start": "447590",
    "end": "449210"
  },
  {
    "text": "that we've seen throughout\nthis adversarial regime where",
    "start": "449210",
    "end": "452419"
  },
  {
    "text": "across different rounds\nof NLI- there are three,",
    "start": "452420",
    "end": "455240"
  },
  {
    "text": "or cumulatively\nfor the data set,",
    "start": "455240",
    "end": "457400"
  },
  {
    "text": "even really excellent models\nthat do really well on SNLI",
    "start": "457400",
    "end": "461210"
  },
  {
    "text": "and multi-NLI are posting\nreally low numbers for all",
    "start": "461210",
    "end": "465380"
  },
  {
    "text": "of these variants of the\ndataset and that shows you",
    "start": "465380",
    "end": "468080"
  },
  {
    "text": "that this is truly\na difficult problem.",
    "start": "468080",
    "end": "470689"
  },
  {
    "text": "And as far as I know,\nnot much progress",
    "start": "470690",
    "end": "472850"
  },
  {
    "text": "has been made since this\ndataset was released",
    "start": "472850",
    "end": "475670"
  },
  {
    "text": "on boosting these numbers.",
    "start": "475670",
    "end": "477600"
  },
  {
    "text": "So it stands as an\ninteresting challenge.",
    "start": "477600",
    "end": "480977"
  },
  {
    "start": "480000",
    "end": "539000"
  },
  {
    "text": "Stepping back here, I'd just\nlike to say that I think we",
    "start": "480977",
    "end": "483310"
  },
  {
    "text": "find in this paper a real vision\nfor future development and that",
    "start": "483310",
    "end": "486550"
  },
  {
    "text": "you see this also in the SWAG\nand HellaSWAG papers as those",
    "start": "486550",
    "end": "490300"
  },
  {
    "text": "authors say this adversarial\ndataset creation is \"a path",
    "start": "490300",
    "end": "493840"
  },
  {
    "text": "for NLP progress going\nforward: toward benchmarks that",
    "start": "493840",
    "end": "496630"
  },
  {
    "text": "adversariallly co-evolve with\nevolving state-of-the-art",
    "start": "496630",
    "end": "499600"
  },
  {
    "text": "models.\"",
    "start": "499600",
    "end": "500100"
  },
  {
    "text": "Right, with SWAG and\nHellaSWAG, we saw this.",
    "start": "500100",
    "end": "502690"
  },
  {
    "text": "SWAG got solved but\nthe response was clear,",
    "start": "502690",
    "end": "505600"
  },
  {
    "text": "bring the best\nmodel in and use it",
    "start": "505600",
    "end": "507280"
  },
  {
    "text": "to create the successor\ndataset set that",
    "start": "507280",
    "end": "509440"
  },
  {
    "text": "stands as a real challenge.",
    "start": "509440",
    "end": "511390"
  },
  {
    "text": "You have the similar picture\nfrom the adversarial NLI paper.",
    "start": "511390",
    "end": "514840"
  },
  {
    "text": "This process of having iterative\nrounds with humans in the loop",
    "start": "514840",
    "end": "518770"
  },
  {
    "text": "yields a moving post-dynamic\ntarget for natural language",
    "start": "518770",
    "end": "521799"
  },
  {
    "text": "understanding systems, rather\nthan the static benchmarks",
    "start": "521799",
    "end": "525040"
  },
  {
    "text": "that eventually saturate.",
    "start": "525040",
    "end": "526360"
  },
  {
    "text": "And we've seen repeatedly\nthat our benchmarks saturate",
    "start": "526360",
    "end": "529329"
  },
  {
    "text": "very quickly these days, so we\nneed this kind of moving post",
    "start": "529330",
    "end": "532540"
  },
  {
    "text": "to make sure we continue to\nmake meaningful progress.",
    "start": "532540",
    "end": "536920"
  },
  {
    "text": "The Nie et al project\ngave rise, I believe,",
    "start": "536920",
    "end": "539260"
  },
  {
    "start": "539000",
    "end": "579000"
  },
  {
    "text": "to this Dynabench platform, an\nopen source platform for model",
    "start": "539260",
    "end": "542680"
  },
  {
    "text": "and human-in-the-loop creation.",
    "start": "542680",
    "end": "545680"
  },
  {
    "text": "As of this writing, there are\nfour datasets available that",
    "start": "545680",
    "end": "548500"
  },
  {
    "text": "have been created on\nDynabench, an NLI data",
    "start": "548500",
    "end": "551710"
  },
  {
    "text": "set which is a\nsuccessor to ANLI,",
    "start": "551710",
    "end": "554460"
  },
  {
    "text": "a question-answering dataset,\na sentiment dataset, and a hate",
    "start": "554460",
    "end": "558910"
  },
  {
    "text": "speech dataset.",
    "start": "558910",
    "end": "560209"
  },
  {
    "text": "So if you're working on\nproblems of this form",
    "start": "560210",
    "end": "562510"
  },
  {
    "text": "or you have a model that would\nfit into this mold for one",
    "start": "562510",
    "end": "565030"
  },
  {
    "text": "of these tasks,\nI would encourage",
    "start": "565030",
    "end": "566920"
  },
  {
    "text": "you to explore some training of\nthe systems on these datasets",
    "start": "566920",
    "end": "570459"
  },
  {
    "text": "to see whether you're\nmaking progress",
    "start": "570460",
    "end": "572950"
  },
  {
    "text": "or whether they stand as\ntrue adversaries for whatever",
    "start": "572950",
    "end": "575410"
  },
  {
    "text": "innovative thing you're doing.",
    "start": "575410",
    "end": "578019"
  },
  {
    "text": "Finally, I want to close with\na really important question",
    "start": "578020",
    "end": "580590"
  },
  {
    "start": "579000",
    "end": "676000"
  },
  {
    "text": "for this area that\nkind of remains open,",
    "start": "580590",
    "end": "583230"
  },
  {
    "text": "can adversarial training\nimprove systems?",
    "start": "583230",
    "end": "585720"
  },
  {
    "text": "There is a course of\nconcern that as we construct",
    "start": "585720",
    "end": "588360"
  },
  {
    "text": "ever harder data sets,\nwe're pushing systems",
    "start": "588360",
    "end": "591060"
  },
  {
    "text": "into stranger parts of the\nlinguistic and conceptual space",
    "start": "591060",
    "end": "594840"
  },
  {
    "text": "which could actually degrade\ntheir real world performance.",
    "start": "594840",
    "end": "598060"
  },
  {
    "text": "We have to keep an eye on that.",
    "start": "598060",
    "end": "600060"
  },
  {
    "text": "And the evidence so\nfar, I think is pointing",
    "start": "600060",
    "end": "602220"
  },
  {
    "text": "to yes as an answer\nto this question",
    "start": "602220",
    "end": "604050"
  },
  {
    "text": "but the evidence is a bit mixed.",
    "start": "604050",
    "end": "605490"
  },
  {
    "text": "So I've mentioned that in\nthe SQuAD adversarial paper",
    "start": "605490",
    "end": "608820"
  },
  {
    "text": "from Jia and Liang, training\non adversarial examples",
    "start": "608820",
    "end": "611820"
  },
  {
    "text": "makes them more robust\nto of those examples",
    "start": "611820",
    "end": "614880"
  },
  {
    "text": "but not to simple variants, so\nit's hardly very much progress.",
    "start": "614880",
    "end": "619950"
  },
  {
    "text": "In this paper, they found that\nadversarial training provided",
    "start": "619950",
    "end": "622590"
  },
  {
    "text": "no additional robustness\nbenefit in the experiments",
    "start": "622590",
    "end": "625620"
  },
  {
    "text": "using the testset, despite the\nfact that the model achieved",
    "start": "625620",
    "end": "628240"
  },
  {
    "text": "near 100% accuracy classifying\nadversarial examples included",
    "start": "628240",
    "end": "632100"
  },
  {
    "text": "in the train set.",
    "start": "632100",
    "end": "633180"
  },
  {
    "text": "So that's a more\nworrisome picture.",
    "start": "633180",
    "end": "635430"
  },
  {
    "text": "But this is more hopeful.",
    "start": "635430",
    "end": "636690"
  },
  {
    "text": "Fine-tuning with a few\nadversarial examples",
    "start": "636690",
    "end": "638890"
  },
  {
    "text": "improved systems in some\ncases, especially where",
    "start": "638890",
    "end": "642210"
  },
  {
    "text": "you bring in inoculation.",
    "start": "642210",
    "end": "643980"
  },
  {
    "text": "And this is hopefully\nyet again, adversarially",
    "start": "643980",
    "end": "646019"
  },
  {
    "text": "generated paraphrases\nimprove model robustness",
    "start": "646020",
    "end": "649080"
  },
  {
    "text": "to syntactic variation.",
    "start": "649080",
    "end": "650640"
  },
  {
    "text": "That's really the dream\nthere- that as a result",
    "start": "650640",
    "end": "653160"
  },
  {
    "text": "of doing this new\nkind of training,",
    "start": "653160",
    "end": "655230"
  },
  {
    "text": "we get systems that\nare truly more robust.",
    "start": "655230",
    "end": "657899"
  },
  {
    "text": "But I think we might need more\nevidence on this picture, which",
    "start": "657900",
    "end": "660630"
  },
  {
    "text": "means more datasets\nof this form,",
    "start": "660630",
    "end": "662790"
  },
  {
    "text": "and more and interesting use\nof the available resources",
    "start": "662790",
    "end": "666209"
  },
  {
    "text": "and I would just love to see\nwhat the emerging picture is",
    "start": "666210",
    "end": "668850"
  },
  {
    "text": "over the next year or two.",
    "start": "668850",
    "end": "671300"
  },
  {
    "start": "671300",
    "end": "675350"
  }
]
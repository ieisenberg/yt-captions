[
  {
    "start": "0",
    "end": "730"
  },
  {
    "text": "OK.",
    "start": "730",
    "end": "1390"
  },
  {
    "text": "Today, we're going\nto do the labs",
    "start": "1390",
    "end": "3010"
  },
  {
    "text": "for chapter 6, linear models\nand regularization methods.",
    "start": "3010",
    "end": "7510"
  },
  {
    "text": "And we'll start off doing\nforward stepwise selection.",
    "start": "7510",
    "end": "12910"
  },
  {
    "text": "But as always, the\nfirst thing we do",
    "start": "12910",
    "end": "15160"
  },
  {
    "text": "is we import the libraries\nthat we need for the lab.",
    "start": "15160",
    "end": "18850"
  },
  {
    "text": "And you'll be familiar\nwith this by now.",
    "start": "18850",
    "end": "22150"
  },
  {
    "text": "There's one little\nextra thing here,",
    "start": "22150",
    "end": "24220"
  },
  {
    "text": "there's a library\nwe're not actually",
    "start": "24220",
    "end": "26259"
  },
  {
    "text": "going to use in this lab,\nbut notice this exclamation",
    "start": "26260",
    "end": "29770"
  },
  {
    "text": "pip install.",
    "start": "29770",
    "end": "31210"
  },
  {
    "text": "We install in a\npackage on the fly here",
    "start": "31210",
    "end": "33730"
  },
  {
    "text": "and you see some print\nout that follows it.",
    "start": "33730",
    "end": "40670"
  },
  {
    "text": "And so you can do that.",
    "start": "40670",
    "end": "41776"
  },
  {
    "text": "If you don't have a\npackage installed,",
    "start": "41777",
    "end": "43360"
  },
  {
    "text": "you can just in the Jupyter\nNotebook install it on the fly.",
    "start": "43360",
    "end": "46070"
  },
  {
    "text": "So we did that just\nto demonstrate it.",
    "start": "46070",
    "end": "48790"
  },
  {
    "text": "But we're going to go to\nforward stepwise selection",
    "start": "48790",
    "end": "52100"
  },
  {
    "text": "and we're going to run forward\nstepwise on the hitter's data",
    "start": "52100",
    "end": "56019"
  },
  {
    "text": "using salary as the response.",
    "start": "56020",
    "end": "58540"
  },
  {
    "text": "OK.",
    "start": "58540",
    "end": "60030"
  },
  {
    "text": "Now there's a\nlittle problem here",
    "start": "60030",
    "end": "62629"
  },
  {
    "text": "because in the\nhitter's data, there's",
    "start": "62630",
    "end": "65690"
  },
  {
    "text": "59 rows that have missing\nvalues for salary.",
    "start": "65690",
    "end": "69140"
  },
  {
    "text": "Now when you do regression, if\nyou have missing values in some",
    "start": "69140",
    "end": "73250"
  },
  {
    "text": "of the predictors or features,\nyou can do things about that.",
    "start": "73250",
    "end": "76400"
  },
  {
    "text": "You can maybe put\nthe mean value in",
    "start": "76400",
    "end": "78140"
  },
  {
    "text": "or you can do-- have\nways of imputing.",
    "start": "78140",
    "end": "80390"
  },
  {
    "text": "But if you've got missing\nvalues in the response,",
    "start": "80390",
    "end": "82860"
  },
  {
    "text": "you can't do anything so\nyou just get rid of them.",
    "start": "82860",
    "end": "85590"
  },
  {
    "text": "So we use the dropna\nmethod to get rid",
    "start": "85590",
    "end": "93500"
  },
  {
    "text": "of the missing values in\nthat data hitters frame",
    "start": "93500",
    "end": "98000"
  },
  {
    "text": "and now we're ready to go.",
    "start": "98000",
    "end": "99390"
  },
  {
    "text": "And of course, that\nreduces the size",
    "start": "99390",
    "end": "102140"
  },
  {
    "text": "of the data set by 59 because\nthere were 59 that were there.",
    "start": "102140",
    "end": "108270"
  },
  {
    "text": "So in the chapter, you\nlearned about using",
    "start": "108270",
    "end": "111439"
  },
  {
    "text": "Cp statistic to\ndo model selection",
    "start": "111440",
    "end": "115610"
  },
  {
    "text": "and Cp is quite a\nwell known statistic.",
    "start": "115610",
    "end": "119340"
  },
  {
    "text": "And so we're going\nto do that here,",
    "start": "119340",
    "end": "121969"
  },
  {
    "text": "but the problem is\nit's not built into--",
    "start": "121970",
    "end": "125210"
  },
  {
    "text": "It's not in sklearn.",
    "start": "125210",
    "end": "126350"
  },
  {
    "text": "It's not in sklearn.",
    "start": "126350",
    "end": "127442"
  },
  {
    "text": "So here we're going\nto show you how",
    "start": "127442",
    "end": "128899"
  },
  {
    "text": "if you have a metric that-- a\ncustom metric that you like,",
    "start": "128900",
    "end": "132230"
  },
  {
    "text": "you can define a metric\nusing this kind of signature",
    "start": "132230",
    "end": "136430"
  },
  {
    "text": "and use the same\ncross-validation methods",
    "start": "136430",
    "end": "138950"
  },
  {
    "text": "to tune with that metric.",
    "start": "138950",
    "end": "140209"
  },
  {
    "text": "Here, we use Cp but\nyou might have your own",
    "start": "140210",
    "end": "142340"
  },
  {
    "text": "for whatever purposes.",
    "start": "142340",
    "end": "143599"
  },
  {
    "text": "And that's a great feature\nbecause that empowers you",
    "start": "143600",
    "end": "145940"
  },
  {
    "text": "if you've got your favorite\nmetric, you can do it.",
    "start": "145940",
    "end": "148440"
  },
  {
    "text": "So here we write\nthe function and you",
    "start": "148440",
    "end": "151220"
  },
  {
    "text": "can go through the details.",
    "start": "151220",
    "end": "152390"
  },
  {
    "text": "You see the definition\nof Cp in the chapter",
    "start": "152390",
    "end": "154670"
  },
  {
    "text": "and you'll see that's\nwhat we do in there.",
    "start": "154670",
    "end": "156650"
  },
  {
    "text": "One little catch is that sklearn\ntries to maximize a score.",
    "start": "156650",
    "end": "161849"
  },
  {
    "text": "And so we want to\nactually minimize Cp",
    "start": "161850",
    "end": "164810"
  },
  {
    "text": "so the function we write is the\nnegative of the Cp statistic.",
    "start": "164810",
    "end": "169310"
  },
  {
    "text": "So that will work out.",
    "start": "169310",
    "end": "172220"
  },
  {
    "text": "Now, Cp also requires\nin the definition",
    "start": "172220",
    "end": "175130"
  },
  {
    "text": "an estimate of the residual\nvariance sigma squared.",
    "start": "175130",
    "end": "178740"
  },
  {
    "text": "So what we're going to do there\nand that's what's in this code",
    "start": "178740",
    "end": "181760"
  },
  {
    "text": "here is we just fit a\nmodel to all the data",
    "start": "181760",
    "end": "184819"
  },
  {
    "text": "and estimate sigma\nsquared once and for all,",
    "start": "184820",
    "end": "188110"
  },
  {
    "text": "and use that estimate\nof sigma squared",
    "start": "188110",
    "end": "190580"
  },
  {
    "text": "using all the variables.",
    "start": "190580",
    "end": "191940"
  },
  {
    "text": "OK.",
    "start": "191940",
    "end": "192440"
  },
  {
    "text": "And that's standard practice--",
    "start": "192440",
    "end": "195770"
  },
  {
    "text": "Using Cp.",
    "start": "195770",
    "end": "196670"
  },
  {
    "text": "--using Cp.",
    "start": "196670",
    "end": "197630"
  },
  {
    "text": "Yeah, and one little thing\nI'll just note, if we go",
    "start": "197630",
    "end": "199820"
  },
  {
    "text": "and look up at the\nsignature of Cp,",
    "start": "199820",
    "end": "202580"
  },
  {
    "text": "maybe I can take the\npencil for a second.",
    "start": "202580",
    "end": "204560"
  },
  {
    "text": "The first argument\nis the sigma squared,",
    "start": "204560",
    "end": "206550"
  },
  {
    "text": "which we have to\nset but the metric,",
    "start": "206550",
    "end": "209018"
  },
  {
    "text": "it should have a\nsignature that takes",
    "start": "209018",
    "end": "210560"
  },
  {
    "text": "an estimator, an x and a y, so\nwe want to fix this argument.",
    "start": "210560",
    "end": "214550"
  },
  {
    "text": "And that's what this\nlittle-- this line here does.",
    "start": "214550",
    "end": "217130"
  },
  {
    "text": "It takes our original\nestimator and fix the value",
    "start": "217130",
    "end": "219950"
  },
  {
    "text": "of sigma squared in it.",
    "start": "219950",
    "end": "221209"
  },
  {
    "start": "221210",
    "end": "224180"
  },
  {
    "text": "OK.",
    "start": "224180",
    "end": "224680"
  },
  {
    "text": "So now we're ready to go.",
    "start": "224680",
    "end": "226010"
  },
  {
    "text": "Our neg_Cp function can be\nused to do the model selection.",
    "start": "226010",
    "end": "231040"
  },
  {
    "text": "So next thing, we\nset up a strategy",
    "start": "231040",
    "end": "233110"
  },
  {
    "text": "for how we're going to fit\nthe sequence of models.",
    "start": "233110",
    "end": "236050"
  },
  {
    "text": "OK.",
    "start": "236050",
    "end": "236770"
  },
  {
    "text": "And so that's this\nchunk over here,",
    "start": "236770",
    "end": "241180"
  },
  {
    "text": "it defines strategy as\nstepwise, which is forward",
    "start": "241180",
    "end": "245019"
  },
  {
    "text": "stepwise and first peak.",
    "start": "245020",
    "end": "247690"
  },
  {
    "text": "So that means it's going\nto run forward stepwise",
    "start": "247690",
    "end": "251470"
  },
  {
    "text": "until it reaches the\npeak, in this case,",
    "start": "251470",
    "end": "255020"
  },
  {
    "text": "it's going to be\nthe Cp statistic,",
    "start": "255020",
    "end": "257079"
  },
  {
    "text": "negative Cp starts decreasing,\nthen it's going to stop there.",
    "start": "257079",
    "end": "259983"
  },
  {
    "text": "So that's where it's going\nto stop rather than going",
    "start": "259983",
    "end": "262150"
  },
  {
    "text": "through the whole function.",
    "start": "262150",
    "end": "263530"
  },
  {
    "text": "Although, in this\ncase, actually, we do",
    "start": "263530",
    "end": "267010"
  },
  {
    "text": "use all the terms.",
    "start": "267010",
    "end": "270340"
  },
  {
    "text": "So actually-- so in\nthis one, if you look,",
    "start": "270340",
    "end": "272620"
  },
  {
    "text": "we actually haven't\nput in a score",
    "start": "272620",
    "end": "274150"
  },
  {
    "text": "so we're actually not\nusing the negative Cp.",
    "start": "274150",
    "end": "277150"
  },
  {
    "text": "It actually by default, is going\nto use something like R squared",
    "start": "277150",
    "end": "280570"
  },
  {
    "text": "or training MSE.",
    "start": "280570",
    "end": "282380"
  },
  {
    "text": "In the next example,\nwe'll have the next step.",
    "start": "282380",
    "end": "284930"
  },
  {
    "text": "Yes, so in fact, we're\nnot using first peak.",
    "start": "284930",
    "end": "286789"
  },
  {
    "text": "So--",
    "start": "286790",
    "end": "287510"
  },
  {
    "text": "Well, we are using first\npeak but not neg_Cp.",
    "start": "287510",
    "end": "289670"
  },
  {
    "text": "So we will just use\ntraining sum of squares.",
    "start": "289670",
    "end": "291540"
  },
  {
    "text": "So if you allow it to go\nto the end, it will go,",
    "start": "291540",
    "end": "293653"
  },
  {
    "text": "it will include\nall the variables.",
    "start": "293653",
    "end": "295070"
  },
  {
    "text": "OK.",
    "start": "295070",
    "end": "296660"
  },
  {
    "text": "All right.",
    "start": "296660",
    "end": "298670"
  },
  {
    "text": "So now, we set up\nour method and it's",
    "start": "298670",
    "end": "304790"
  },
  {
    "text": "going to be using\nsklearn selected",
    "start": "304790",
    "end": "309440"
  },
  {
    "text": "on using OLS as the fitting\nmethod with the strategy",
    "start": "309440",
    "end": "313730"
  },
  {
    "text": "that we've just defined.",
    "start": "313730",
    "end": "315530"
  },
  {
    "text": "OK.",
    "start": "315530",
    "end": "316730"
  },
  {
    "text": "And now we actually--",
    "start": "316730",
    "end": "318440"
  },
  {
    "text": "we run it, hitters_MSE.fit,\nthat's the function.",
    "start": "318440",
    "end": "325730"
  },
  {
    "text": "We use the fit method using the\nhitters data and the response",
    "start": "325730",
    "end": "329300"
  },
  {
    "text": "Y. And we can extract\nthe selected state,",
    "start": "329300",
    "end": "333889"
  },
  {
    "text": "which is the selected model.",
    "start": "333890",
    "end": "336620"
  },
  {
    "text": "And what we get in this\ncase is all the variables",
    "start": "336620",
    "end": "342080"
  },
  {
    "text": "because we didn't tell\nit to use Cp to select.",
    "start": "342080",
    "end": "345860"
  },
  {
    "text": "So it just selected the whole--",
    "start": "345860",
    "end": "347229"
  },
  {
    "text": "It used training\nMSE as the score.",
    "start": "347230",
    "end": "350120"
  },
  {
    "text": "Oh, so is that the default?",
    "start": "350120",
    "end": "351810"
  },
  {
    "text": "That's the default.\nOr it's either",
    "start": "351810",
    "end": "353630"
  },
  {
    "text": "that or R squared, which\nwill be one to one functions",
    "start": "353630",
    "end": "357620"
  },
  {
    "text": "of each other.",
    "start": "357620",
    "end": "358340"
  },
  {
    "text": "Because here we didn't\nspecify a selection strategy,",
    "start": "358340",
    "end": "361820"
  },
  {
    "text": "whereas next time we use it,\nwe say scoring is neg_Cp.",
    "start": "361820",
    "end": "365280"
  },
  {
    "text": "Yes.",
    "start": "365280",
    "end": "365780"
  },
  {
    "text": "So if you don't select,\nit's going to fit them all.",
    "start": "365780",
    "end": "368520"
  },
  {
    "text": "So when we do the fit using\nthe scoring method over here,",
    "start": "368520",
    "end": "374690"
  },
  {
    "text": "the steps are the\nsame as before,",
    "start": "374690",
    "end": "376790"
  },
  {
    "text": "what you see is a smaller\nsubset of the features that",
    "start": "376790",
    "end": "380330"
  },
  {
    "text": "were selected.",
    "start": "380330",
    "end": "381840"
  },
  {
    "text": "OK.",
    "start": "381840",
    "end": "382340"
  },
  {
    "text": "So that's selecting\nthe model by Cp.",
    "start": "382340",
    "end": "384449"
  },
  {
    "start": "384450",
    "end": "387280"
  },
  {
    "text": "I think the next\nmethod that we're",
    "start": "387280",
    "end": "388930"
  },
  {
    "text": "going to use, the\nsame forward stepwise,",
    "start": "388930",
    "end": "391120"
  },
  {
    "text": "but we're going to use\nthe validation set.",
    "start": "391120",
    "end": "394340"
  },
  {
    "text": "In fact, cross-validation\nto select the model,",
    "start": "394340",
    "end": "397067"
  },
  {
    "text": "OK, which is probably\na more general method",
    "start": "397067",
    "end": "402610"
  },
  {
    "text": "and can be used for\nany kind of modeling.",
    "start": "402610",
    "end": "406159"
  },
  {
    "text": "So here, the strategy\nis stepwise fixed steps",
    "start": "406160",
    "end": "409090"
  },
  {
    "text": "because what we're going\nto do is always use",
    "start": "409090",
    "end": "411850"
  },
  {
    "text": "the full set of steps.",
    "start": "411850",
    "end": "414370"
  },
  {
    "text": "And we're going to\nscore every single step.",
    "start": "414370",
    "end": "416242"
  },
  {
    "text": "And you'll see, we're going\nto make a plot afterwards",
    "start": "416242",
    "end": "418450"
  },
  {
    "text": "that shows the performance as\na function of the step size.",
    "start": "418450",
    "end": "422950"
  },
  {
    "text": "That's right.",
    "start": "422950",
    "end": "423730"
  },
  {
    "text": "And again, the\nfull_path we define",
    "start": "423730",
    "end": "426310"
  },
  {
    "text": "as using the OLS method along\nwith the strategy over here.",
    "start": "426310",
    "end": "432310"
  },
  {
    "text": "And let's fit the full_path\non the hitter's data.",
    "start": "432310",
    "end": "435235"
  },
  {
    "start": "435235",
    "end": "437949"
  },
  {
    "text": "And so we do that.",
    "start": "437950",
    "end": "439340"
  },
  {
    "text": "And so that will fit\na sequence of models.",
    "start": "439340",
    "end": "442875"
  },
  {
    "text": "And we also get we also--",
    "start": "442875",
    "end": "444820"
  },
  {
    "text": "we call it the Yhat_in, we get\npredictions on the full_path.",
    "start": "444820",
    "end": "449870"
  },
  {
    "text": "We give it the hitter's data.",
    "start": "449870",
    "end": "452460"
  },
  {
    "text": "And it gives us back a\nmatrix of predictions.",
    "start": "452460",
    "end": "456350"
  },
  {
    "text": "And what are the\ncolumns of that matrix?",
    "start": "456350",
    "end": "458087"
  },
  {
    "text": "I guess, they're the\ndifferent fitted values",
    "start": "458087",
    "end": "459920"
  },
  {
    "text": "as the model grows?",
    "start": "459920",
    "end": "461870"
  },
  {
    "text": "Yes, that's right.",
    "start": "461870",
    "end": "462900"
  },
  {
    "text": "OK.",
    "start": "462900",
    "end": "463400"
  },
  {
    "text": "So there's going to be\n20 terms in the model.",
    "start": "463400",
    "end": "468139"
  },
  {
    "text": "That includes the null\nmodel and the 19 features",
    "start": "468140",
    "end": "472520"
  },
  {
    "text": "added in importance\none at a time.",
    "start": "472520",
    "end": "475610"
  },
  {
    "text": "Importance in terms of\nresidual sum of squares",
    "start": "475610",
    "end": "479509"
  },
  {
    "text": "because this is not\nusing any scoring method.",
    "start": "479510",
    "end": "482510"
  },
  {
    "text": "That's right.",
    "start": "482510",
    "end": "484280"
  },
  {
    "text": "So we want to make plots to\nshow how these mean squared",
    "start": "484280",
    "end": "489350"
  },
  {
    "text": "error and other measures, how\nthey decline as a function of",
    "start": "489350",
    "end": "495530"
  },
  {
    "text": "or change as a function\nof number of steps.",
    "start": "495530",
    "end": "498300"
  },
  {
    "text": "So we've written some\ncode here for doing that.",
    "start": "498300",
    "end": "502580"
  },
  {
    "text": "And the code sets\nthe size of the plot",
    "start": "502580",
    "end": "505849"
  },
  {
    "text": "and sets the labels and so on.",
    "start": "505850",
    "end": "508140"
  },
  {
    "text": "And we make the plot\nfor our first sequence",
    "start": "508140",
    "end": "514849"
  },
  {
    "text": "of models, which is just\nusing mean squared error.",
    "start": "514850",
    "end": "517759"
  },
  {
    "text": "And this is just\nevaluated at just",
    "start": "517760",
    "end": "519530"
  },
  {
    "text": "on the training data itself.",
    "start": "519530",
    "end": "521330"
  },
  {
    "text": "Subsequently, we're going\nto look at cross-validation",
    "start": "521330",
    "end": "524190"
  },
  {
    "text": "and the validation set method\nand compare them to just using",
    "start": "524190",
    "end": "527990"
  },
  {
    "text": "the training data.",
    "start": "527990",
    "end": "528740"
  },
  {
    "text": "And you'll see if you\nlook at the code we made,",
    "start": "528740",
    "end": "531300"
  },
  {
    "text": "we knew what sort of range\nwe needed because you can see",
    "start": "531300",
    "end": "534545"
  },
  {
    "text": "this range is a bit bigger than\nwe need to plot this curve,",
    "start": "534545",
    "end": "537440"
  },
  {
    "text": "but we were anticipating\nwhat we were",
    "start": "537440",
    "end": "539660"
  },
  {
    "text": "going to see later on\nso that they could all",
    "start": "539660",
    "end": "541699"
  },
  {
    "text": "fit into the plot.",
    "start": "541700",
    "end": "543560"
  },
  {
    "text": "Now the other thing\nto note and of course,",
    "start": "543560",
    "end": "545760"
  },
  {
    "text": "this has to be the case is that\nthe residual sum of squares",
    "start": "545760",
    "end": "549040"
  },
  {
    "text": "is decreasing at every step\nbecause as you add more",
    "start": "549040",
    "end": "552920"
  },
  {
    "text": "variables, you\ncan only do better",
    "start": "552920",
    "end": "554540"
  },
  {
    "text": "in terms of mean squared error\nand residual sum of squares.",
    "start": "554540",
    "end": "560115"
  },
  {
    "text": "OK.",
    "start": "560115",
    "end": "560615"
  },
  {
    "start": "560615",
    "end": "565000"
  },
  {
    "text": "There's some details\nabout how we compute",
    "start": "565000",
    "end": "569170"
  },
  {
    "text": "the residual sum of squares\nand we explain some of them",
    "start": "569170",
    "end": "573250"
  },
  {
    "text": "in the text here, but we\nwon't go over that now.",
    "start": "573250",
    "end": "576530"
  },
  {
    "text": "OK.",
    "start": "576530",
    "end": "577030"
  },
  {
    "text": "Now we're going to\nuse kfold, in fact",
    "start": "577030",
    "end": "579520"
  },
  {
    "text": "five-fold cross-validation.",
    "start": "579520",
    "end": "581360"
  },
  {
    "text": "And we're going to use the\nsklearn cross-validation",
    "start": "581360",
    "end": "585310"
  },
  {
    "text": "technology that we've already\nlearnt in lab for chapter 5.",
    "start": "585310",
    "end": "591537"
  },
  {
    "text": "Though, Trevor, I think there's\nactually something new in this",
    "start": "591537",
    "end": "594120"
  },
  {
    "text": "so we're using this\nfunction if you look at it.",
    "start": "594120",
    "end": "596170"
  },
  {
    "text": "Instead of called\ncross-validate, which we saw,",
    "start": "596170",
    "end": "598180"
  },
  {
    "text": "this one is called\ncross_val_predict.",
    "start": "598180",
    "end": "600339"
  },
  {
    "text": "So what that gives\nus is actually",
    "start": "600340",
    "end": "602500"
  },
  {
    "text": "the predictions for whatever--",
    "start": "602500",
    "end": "607570"
  },
  {
    "text": "whatever the method is and\nthe cross-validation it'll",
    "start": "607570",
    "end": "610180"
  },
  {
    "text": "give us the predicted value.",
    "start": "610180",
    "end": "611360"
  },
  {
    "text": "So on each fold, you'll\nget the predictions having",
    "start": "611360",
    "end": "614769"
  },
  {
    "text": "trained on the remaining folds.",
    "start": "614770",
    "end": "616670"
  },
  {
    "text": "OK.",
    "start": "616670",
    "end": "617170"
  },
  {
    "text": "So that's a function in sklearn?",
    "start": "617170",
    "end": "619600"
  },
  {
    "text": "Yes.",
    "start": "619600",
    "end": "620769"
  },
  {
    "text": "And so that's why the\nYhat_cv has the same shape.",
    "start": "620770",
    "end": "624210"
  },
  {
    "text": "It's actually all 20\ncross-validated predictions.",
    "start": "624210",
    "end": "627350"
  },
  {
    "text": "Oh, OK.",
    "start": "627350",
    "end": "629240"
  },
  {
    "text": "And that's really convenient\nbecause sometimes, you",
    "start": "629240",
    "end": "632810"
  },
  {
    "text": "want these prediction\nmatrices that",
    "start": "632810",
    "end": "635990"
  },
  {
    "text": "have been predicted in an honest\nway through cross-validation",
    "start": "635990",
    "end": "639350"
  },
  {
    "text": "and you can compute\nany measures you like.",
    "start": "639350",
    "end": "643040"
  },
  {
    "text": "And in this case, we are going\nto compute mean squared error.",
    "start": "643040",
    "end": "647430"
  },
  {
    "text": "OK.",
    "start": "647430",
    "end": "647930"
  },
  {
    "start": "647930",
    "end": "652154"
  },
  {
    "text": "So in this chunk of\ncode here, what we do",
    "start": "652155",
    "end": "655800"
  },
  {
    "text": "is actually compute\nthe mean squared error",
    "start": "655800",
    "end": "659370"
  },
  {
    "text": "because this cross-validated\nprediction matrix has",
    "start": "659370",
    "end": "663839"
  },
  {
    "text": "got 20 columns\nagain, and we want",
    "start": "663840",
    "end": "666275"
  },
  {
    "text": "to compute the\nmean squared error",
    "start": "666275",
    "end": "667650"
  },
  {
    "text": "for each of those columns.",
    "start": "667650",
    "end": "669220"
  },
  {
    "text": "But this will be cross-validated\nmean squared error.",
    "start": "669220",
    "end": "672779"
  },
  {
    "text": "So in doing so, what we\ndo, we do it in two steps.",
    "start": "672780",
    "end": "677160"
  },
  {
    "text": "First, we compute this\nmatrix here, which is 20 by 5",
    "start": "677160",
    "end": "682379"
  },
  {
    "text": "and that's the cross-validated--\nthe average error inside each",
    "start": "682380",
    "end": "686670"
  },
  {
    "text": "of the five folds.",
    "start": "686670",
    "end": "689220"
  },
  {
    "text": "And so there's 20\ndifferent models,",
    "start": "689220",
    "end": "692170"
  },
  {
    "text": "there's five folds for each,\nwe get a mean squared error",
    "start": "692170",
    "end": "694680"
  },
  {
    "text": "for each.",
    "start": "694680",
    "end": "695560"
  },
  {
    "text": "So why do we do this?",
    "start": "695560",
    "end": "696697"
  },
  {
    "text": "We could have just computed\nthe average over everything.",
    "start": "696697",
    "end": "699030"
  },
  {
    "text": "Well, we want to also\ncompute the standard error.",
    "start": "699030",
    "end": "701620"
  },
  {
    "text": "And so our final\nestimate of mean",
    "start": "701620",
    "end": "703529"
  },
  {
    "text": "squared error is going to be an\naverage of these five numbers",
    "start": "703530",
    "end": "706230"
  },
  {
    "text": "and then we can have a crude\nestimate of standard error",
    "start": "706230",
    "end": "709139"
  },
  {
    "text": "for the average.",
    "start": "709140",
    "end": "710110"
  },
  {
    "text": "So that's why we do that.",
    "start": "710110",
    "end": "711670"
  },
  {
    "text": "OK.",
    "start": "711670",
    "end": "713310"
  },
  {
    "text": "And now, having\ndone all the work,",
    "start": "713310",
    "end": "716850"
  },
  {
    "text": "we now add the\ncross-validation estimate",
    "start": "716850",
    "end": "719130"
  },
  {
    "text": "to the mean squared error plot.",
    "start": "719130",
    "end": "720820"
  },
  {
    "text": "And this is the\ncode for doing that.",
    "start": "720820",
    "end": "723480"
  },
  {
    "text": "And there we see the results.",
    "start": "723480",
    "end": "727660"
  },
  {
    "text": "And so--",
    "start": "727660",
    "end": "729149"
  },
  {
    "text": "It seems to flatten\nout a little bit.",
    "start": "729150",
    "end": "732195"
  },
  {
    "text": "It doesn't necessarily\nhave to drop,",
    "start": "732195",
    "end": "734040"
  },
  {
    "text": "of course, like\nthe in-sample one",
    "start": "734040",
    "end": "735839"
  },
  {
    "text": "but it seems to\nflatten out some.",
    "start": "735840",
    "end": "739340"
  },
  {
    "text": "And you sometimes see\nthat, and of course, we",
    "start": "739340",
    "end": "741500"
  },
  {
    "text": "have to take the standard\nerrors into account.",
    "start": "741500",
    "end": "744120"
  },
  {
    "text": "But if I were to look\nat this plot, Jonathan,",
    "start": "744120",
    "end": "747300"
  },
  {
    "text": "I would say maybe a\nmodel with six terms",
    "start": "747300",
    "end": "751266"
  },
  {
    "text": "is a good model to select.",
    "start": "751266",
    "end": "753660"
  },
  {
    "text": "Yeah, that looks promising.",
    "start": "753660",
    "end": "755970"
  },
  {
    "text": "And the standard errors\nhelp us make the selection.",
    "start": "755970",
    "end": "759180"
  },
  {
    "text": "OK.",
    "start": "759180",
    "end": "761550"
  },
  {
    "text": "We're also going to\nadd to the plot--",
    "start": "761550",
    "end": "763320"
  },
  {
    "text": "we're going to use-- we\ntalked in the chapter",
    "start": "763320",
    "end": "765510"
  },
  {
    "text": "about the validation approach\nwhere the validation approach,",
    "start": "765510",
    "end": "769380"
  },
  {
    "text": "you just set aside\na training set",
    "start": "769380",
    "end": "771000"
  },
  {
    "text": "and leave some\ndata as a test set.",
    "start": "771000",
    "end": "773450"
  },
  {
    "text": "And so here, we give\ncode for doing that.",
    "start": "773450",
    "end": "776895"
  },
  {
    "text": "So I guess for\nthis one, we won't",
    "start": "776895",
    "end": "778270"
  },
  {
    "text": "get the same standard\nerror as we did",
    "start": "778270",
    "end": "779650"
  },
  {
    "text": "for cross-validation, right?",
    "start": "779650",
    "end": "780817"
  },
  {
    "text": "Yeah, we get we get\nno standard errors.",
    "start": "780817",
    "end": "784690"
  },
  {
    "text": "In fact-- so the code\nlooks pretty much",
    "start": "784690",
    "end": "788320"
  },
  {
    "text": "the same and this is the\nerror on the validation",
    "start": "788320",
    "end": "791680"
  },
  {
    "text": "set that we get when you\njust have one validation set.",
    "start": "791680",
    "end": "795610"
  },
  {
    "text": "Now, the interesting thing\nis this validation set",
    "start": "795610",
    "end": "797890"
  },
  {
    "text": "was randomly selected\n20% of the data.",
    "start": "797890",
    "end": "801130"
  },
  {
    "text": "Now in the five-fold\ncross-validation,",
    "start": "801130",
    "end": "803410"
  },
  {
    "text": "they were also 20%.",
    "start": "803410",
    "end": "806379"
  },
  {
    "text": "The validation sets for each\nfold was 20% of the data.",
    "start": "806380",
    "end": "810490"
  },
  {
    "text": "So this guy seems a\npoor estimator compared",
    "start": "810490",
    "end": "815035"
  },
  {
    "text": "to the cross-validation because\nyou only get the benefit of one",
    "start": "815035",
    "end": "817660"
  },
  {
    "text": "curve, whereas cross-validation\nyou do this five times you get",
    "start": "817660",
    "end": "820810"
  },
  {
    "text": "to average the curve\nand get a better--",
    "start": "820810",
    "end": "822683"
  },
  {
    "text": "It should be more\nstable, I would guess,",
    "start": "822683",
    "end": "824350"
  },
  {
    "text": "and averages out the errors.",
    "start": "824350",
    "end": "826180"
  },
  {
    "text": "And you get the standard error.",
    "start": "826180",
    "end": "827680"
  },
  {
    "text": "Yes.",
    "start": "827680",
    "end": "828290"
  },
  {
    "text": "OK.",
    "start": "828290",
    "end": "828790"
  },
  {
    "text": "So that's it.",
    "start": "828790",
    "end": "831009"
  },
  {
    "text": "We're going to skip\nthe best subset",
    "start": "831010",
    "end": "832600"
  },
  {
    "text": "selection and the\nnext section, we're",
    "start": "832600",
    "end": "835420"
  },
  {
    "text": "going to discuss is going to\nbe ridge regression and Lasso.",
    "start": "835420",
    "end": "839850"
  },
  {
    "start": "839850",
    "end": "845000"
  }
]
[
  {
    "start": "0",
    "end": "83000"
  },
  {
    "text": ">> Now I would like to welcome today's presenter, associate professor, Professor Michael Bernstein.",
    "start": "9350",
    "end": "16990"
  },
  {
    "text": "Michael, the associate professor of computer science in the Stanford School of Engineering,",
    "start": "16990",
    "end": "24275"
  },
  {
    "text": "is also AST microelectronics faculty scholar at Stanford,",
    "start": "24275",
    "end": "29430"
  },
  {
    "text": "where he is a member of the Human Computer Interaction group. His research focuses on the design of social computing and crowdsourcing systems.",
    "start": "29430",
    "end": "40235"
  },
  {
    "text": "Michael has received eight best paper awards at premier computing venues and he has been",
    "start": "40235",
    "end": "46430"
  },
  {
    "text": "recognized with an NSF Career Award and an Alfred P. Sloan Fellowship.",
    "start": "46430",
    "end": "52760"
  },
  {
    "text": "His PhD students have gone on both to industry, working at Adobe, Facebook,",
    "start": "52760",
    "end": "58560"
  },
  {
    "text": "and starting companies, as well as faculty careers at Carnegie Mellon and UC Berkeley.",
    "start": "58560",
    "end": "65530"
  },
  {
    "text": "Michael holds a bachelor's degree in symbolic systems from Stanford, as well as a masters degree and PhD in computer science from MIT.",
    "start": "65530",
    "end": "76870"
  },
  {
    "text": "Welcome, everyone, today and welcome, Michael. Would you please go ahead and get started?",
    "start": "76870",
    "end": "83295"
  },
  {
    "start": "83000",
    "end": "197000"
  },
  {
    "text": ">> All right. It's wonderful to have you all here. Thank you, Anita. My name is Michael Bernstein, as she mentioned, and yeah,",
    "start": "83295",
    "end": "89730"
  },
  {
    "text": "I teach and do research in Stanford's Computer Science department, which means that I'm interested in how we design",
    "start": "89730",
    "end": "95930"
  },
  {
    "text": "computational systems that are a better fit for human needs, goals, and essentially, the broader context.",
    "start": "95930",
    "end": "104355"
  },
  {
    "text": "A lot of what we do draws on the techniques developed by modern artificial intelligence algorithms to create new kinds of user experiences,",
    "start": "104355",
    "end": "114170"
  },
  {
    "text": "and that's really what our goal is going to be today. We're going to be thinking about the kinds of opportunities that",
    "start": "114170",
    "end": "119180"
  },
  {
    "text": "arise when you combine AI with human-computer interaction, or HCI, but also the unique challenges that come.",
    "start": "119180",
    "end": "127285"
  },
  {
    "text": "I want to start off by just mentioning that if get this wrong, it can be really tough.",
    "start": "127285",
    "end": "134375"
  },
  {
    "text": "I'm sure you've all seen examples publicized in the media demonstrating,",
    "start": "134375",
    "end": "141165"
  },
  {
    "text": "for example, when people are applying AI techniques in ways that are racist, biased, creating all sorts of errors.",
    "start": "141165",
    "end": "149105"
  },
  {
    "text": "Even today on the Internet, lots of people, I think, are chiding a website that will tell you the gender of a name and putting in words",
    "start": "149105",
    "end": "157489"
  },
  {
    "text": "like professor and finding out that it's 90 [inaudible] nurses is very female [inaudible].",
    "start": "157490",
    "end": "163200"
  },
  {
    "text": "There's lots of challenges and issues that we have to consider as we think about these,",
    "start": "163200",
    "end": "168500"
  },
  {
    "text": "and I think it's important that we draw on broad stakeholders when we're doing this. Today, we're going to focus on how AI is influencing that last mile of user interaction.",
    "start": "168500",
    "end": "179755"
  },
  {
    "text": "I'm going to go ahead and share my screen, which means that my face is going to largely disappear, but I promise I am talking to you live,",
    "start": "179755",
    "end": "186350"
  },
  {
    "text": "and I encourage you to put questions into the Q&A. I'm happy to have a conversation about this as we wind up.",
    "start": "186350",
    "end": "192310"
  },
  {
    "text": "So again, very thrilled you're here with us. You're going to get a brief moment of transition as we start the slides.",
    "start": "192310",
    "end": "197755"
  },
  {
    "start": "197000",
    "end": "233000"
  },
  {
    "text": "This talk is going to be about what I call interactive artificial intelligence. So I think what we need to do here is acknowledge",
    "start": "197755",
    "end": "206000"
  },
  {
    "text": "that AI is not just a thing that happens in the backend,",
    "start": "206000",
    "end": "211490"
  },
  {
    "text": "but ultimately, these are all done in the service of some human goal, and sometimes these AI systems are put directly in the hands of people.",
    "start": "211490",
    "end": "221925"
  },
  {
    "text": "We need to think about how we co-design the AI and the interaction to be effective.",
    "start": "221925",
    "end": "227975"
  },
  {
    "text": "Now, I'll give a few examples. Here [inaudible] on the right from colleagues at UC Berkeley showing that really,",
    "start": "227975",
    "end": "238085"
  },
  {
    "start": "233000",
    "end": "295000"
  },
  {
    "text": "AI hits the road when it starts to interact with people. Whether we're talking about,",
    "start": "238085",
    "end": "243500"
  },
  {
    "text": "in these examples, robots, you could imagine a completely non-humanoid robot,",
    "start": "243500",
    "end": "249940"
  },
  {
    "text": "but at the end of the day, the robot needs to interact with people. So what these folks on the left at",
    "start": "249940",
    "end": "255849"
  },
  {
    "text": "MIT's personal robotics group are doing are looking at ways in which robots are giving social cues through what it's looking at,",
    "start": "255850",
    "end": "263320"
  },
  {
    "text": "for example, that people can make sense of, where on the right, [inaudible] group at UC Berkeley is",
    "start": "263320",
    "end": "269020"
  },
  {
    "text": "building grasping algorithms that people can understand. They're legible, I can predict where the robot is going to actually grab,",
    "start": "269020",
    "end": "277610"
  },
  {
    "text": "because it turns out that the most direct path for a robot to grab, say, that bottle on the right hand side is",
    "start": "277610",
    "end": "284970"
  },
  {
    "text": "not actually the path that people are going to find the most intuitive. So instead, the robot can take a less direct path,",
    "start": "284970",
    "end": "291500"
  },
  {
    "text": "but one that people make more sense and can predict what it's going to do. Now, we already have AI that's interactive in everyday use.",
    "start": "291500",
    "end": "300235"
  },
  {
    "start": "295000",
    "end": "441000"
  },
  {
    "text": "Maybe you use Siri, or Alexa, or any of these smart assistants,",
    "start": "300235",
    "end": "306080"
  },
  {
    "text": "or maybe you just use systems like Google, Bing, other search engines, and those are all AIs behind the hood.",
    "start": "306080",
    "end": "313895"
  },
  {
    "text": "They are AIs that had been built with the interaction on top of them.",
    "start": "313895",
    "end": "319090"
  },
  {
    "text": "Google very famously created just a single textbox, whereas previous search engines were much more complex.",
    "start": "319090",
    "end": "326290"
  },
  {
    "text": "At the end of the day, I think we have to acknowledge that automation here is not the answer.",
    "start": "326290",
    "end": "334500"
  },
  {
    "text": "Actually, a very good case in point, as I'm speaking, my Alexa is actually talking to me because it thinks I'm trying to address it.",
    "start": "336140",
    "end": "343090"
  },
  {
    "text": "I just had to go unplug my Alexa for right now because it has not been designed effectively to take into account that I might be",
    "start": "343090",
    "end": "350180"
  },
  {
    "text": "talking about Alexa rather than to Alexa, so case in point. Automation, full automation is not the answer.",
    "start": "350180",
    "end": "357230"
  },
  {
    "text": "I think a very simple case in point here is self-driving cars.",
    "start": "357230",
    "end": "362555"
  },
  {
    "text": "I would love it to be the case that I could get into a car and that it would just get me where I need to go,",
    "start": "362555",
    "end": "368495"
  },
  {
    "text": "but a ton of studies have demonstrated that this is a really patently bad idea. What you're seeing here is some moments from a study done by Wendy Ju,",
    "start": "368495",
    "end": "378830"
  },
  {
    "text": "who's now at Cornell Tech looking at handoffs between automation and live human control.",
    "start": "378830",
    "end": "386335"
  },
  {
    "text": "Every automated car, at some point, is going to get into a position where it no longer can drive completely out in an automated way.",
    "start": "386335",
    "end": "392690"
  },
  {
    "text": "There's construction on the road, it's confused. It needs to hand control back to the human. In the bottom left, you can see this person is actually staring at",
    "start": "392690",
    "end": "399830"
  },
  {
    "text": "their phone while they're getting driven somewhere here in a simulator. Then the car, all of a sudden, says, \"Guess what?",
    "start": "399830",
    "end": "406260"
  },
  {
    "text": "It's your turn now,\" and the person freaks out and barely avoids careening off the road.",
    "start": "406260",
    "end": "413820"
  },
  {
    "text": "In fact, there's another cars coming in as oncoming traffic, they always get into an accident.",
    "start": "413820",
    "end": "418865"
  },
  {
    "text": "They're also swearing. I've cut that part out. Essentially it's not about,",
    "start": "418865",
    "end": "425210"
  },
  {
    "text": "is the automation good or the person good? But here, it's that intersection where the automation had to hand back off to the person.",
    "start": "425210",
    "end": "431130"
  },
  {
    "text": "How do we design those seams so that people can work more collaboratively and that",
    "start": "431130",
    "end": "437705"
  },
  {
    "text": "the power can be handed back and forth more effectively? To make this point, I'm going to start by introducing a term.",
    "start": "437705",
    "end": "444905"
  },
  {
    "start": "441000",
    "end": "534000"
  },
  {
    "text": "It's called the intelligence augmentation and it actually has a long history. Intelligence augmentation, I think [inaudible] effectively understood [inaudible] is",
    "start": "444905",
    "end": "453110"
  },
  {
    "text": "a notion that [inaudible] where everyone's just [inaudible] ,",
    "start": "453110",
    "end": "459210"
  },
  {
    "text": "there are many folks [inaudible] including actually Stanford as incoming faculty, [inaudible] , who's just arriving from MIT,",
    "start": "459210",
    "end": "466505"
  },
  {
    "text": "studying which jobs in particular AI might actually eventually displace, and they're largely very rote ones.",
    "start": "466505",
    "end": "473360"
  },
  {
    "text": "In reality, there are some jobs that will be replaced in that way, but the story's going to be much more",
    "start": "473360",
    "end": "481160"
  },
  {
    "text": "complicated and there's going to be much more of a pull and tug. This is a picture of Douglas Engelbart.",
    "start": "481160",
    "end": "488000"
  },
  {
    "text": "He's a Turing Award winner. That's basically the Nobel Prize of computer science. Douglas Engelbart invented, among many things, hypertext,",
    "start": "488000",
    "end": "496640"
  },
  {
    "text": "the mouse, a one-handed key code, the coded keyset which we use.",
    "start": "496640",
    "end": "504250"
  },
  {
    "text": "The initial word processor, all sorts of stuff. Effectively, the first working graphical user interface,",
    "start": "504250",
    "end": "511595"
  },
  {
    "text": "but he had a vision around how all this was going to go. One which he published at Stanford Research Institute,",
    "start": "511595",
    "end": "517700"
  },
  {
    "text": "SRI at the time, about what he called augmenting human intellect, that computers were not here to replace us,",
    "start": "517700",
    "end": "525199"
  },
  {
    "text": "but to actually make us smarter. Imagine a cognitive prosthesis, something that's a strap-on cortex that makes our brains smarter.",
    "start": "525200",
    "end": "534055"
  },
  {
    "start": "534000",
    "end": "566000"
  },
  {
    "text": "I think you can see these two ideas as being a little bit intention. On the left, artificial intelligence,",
    "start": "534055",
    "end": "540425"
  },
  {
    "text": "where you're trying to take human intelligence and just replace it with computation. But on the right, and I think the point I'm going to try to make here,",
    "start": "540425",
    "end": "548750"
  },
  {
    "text": "is much more focused on what I would call intelligence augmentation and what Douglas Engelbart calls intelligence augmentation,",
    "start": "548750",
    "end": "554194"
  },
  {
    "text": "where instead of just displacing what you're doing, it's actually using the computation and the intelligence to help us think through things,",
    "start": "554194",
    "end": "561725"
  },
  {
    "text": "smarter, better, more effectively, more collaboratively. Now, any story about what AI and interaction are going to do together",
    "start": "561725",
    "end": "572845"
  },
  {
    "start": "566000",
    "end": "760000"
  },
  {
    "text": "needs to start with a very brief collective moment of what AI can and cannot actually achieve.",
    "start": "572845",
    "end": "579970"
  },
  {
    "text": "Here I love this quote by Eytan Adar at University of Michigan where he says, \"Don't let your UI, your user interface,",
    "start": "579970",
    "end": "586465"
  },
  {
    "text": "write a check that your AI can't cash.\" What he means by this is that it's very common that people will build",
    "start": "586465",
    "end": "594820"
  },
  {
    "text": "user interface elements that assume an AI that's smarter than AI can actually provide.",
    "start": "594820",
    "end": "602545"
  },
  {
    "text": "I think one of the most famous examples of this, if I'm not going to raise various forms of PTSD for old time computer users,",
    "start": "602545",
    "end": "609640"
  },
  {
    "text": "it's Clippy, the Microsoft Office assistant. It was trying to guess when you were say writing a letter and would pop in a little paperclip and say,",
    "start": "609640",
    "end": "616435"
  },
  {
    "text": "hey, it looks like you're writing a letter. But the AI, they had tuned it down to the point where it was not really very smart.",
    "start": "616435",
    "end": "621714"
  },
  {
    "text": "The user interface was assuming a brilliant AI that didn't actually exist. How do we know what might actually be feasible?",
    "start": "621715",
    "end": "629185"
  },
  {
    "text": "My colleague, Andrew Ng, in computer science is a machine learning researcher, I think had this article in",
    "start": "629185",
    "end": "635320"
  },
  {
    "text": "the Harvard Business Review that I think puts a nice point on it. We can debate the particulars of it, but I think in broad brushstrokes,",
    "start": "635320",
    "end": "641680"
  },
  {
    "text": "this is not so far off. That we have to think about two things, first, essentially, when you're talking about AI,",
    "start": "641680",
    "end": "649000"
  },
  {
    "text": "almost all of its progress is through a particular type of function, something that takes some input A,",
    "start": "649000",
    "end": "655300"
  },
  {
    "text": "and generates some simple response B. The A's and the B's can change, but it's always A becomes B.",
    "start": "655300",
    "end": "661330"
  },
  {
    "text": "You give it an A that's a picture and the B responses a yes or no, is there a face in it. You give it an A that's a lone app,",
    "start": "661330",
    "end": "667420"
  },
  {
    "text": "and B is a prediction, will they repay it? Again, there's lots of issues with doing that and bias that can come out of it.",
    "start": "667420",
    "end": "674230"
  },
  {
    "text": "A might be an English phrase, B might be a French phrase. We're just translating everything, you feed something in, it gives you something back.",
    "start": "674230",
    "end": "682075"
  },
  {
    "text": "When he says, that is a good way of thinking about this, is that if a typical person can do a mental task with less than one second of thought,",
    "start": "682075",
    "end": "691210"
  },
  {
    "text": "then we can probably automate it using AI either now or in the near future. What does that mean? It means that things like,",
    "start": "691210",
    "end": "699500"
  },
  {
    "text": "is that a person, is that a face, is that a dog, is this sentence in English?",
    "start": "699500",
    "end": "706365"
  },
  {
    "text": "All of these kinds of tasks are things that you do almost subconsciously, very quickly, in a second or less.",
    "start": "706365",
    "end": "713570"
  },
  {
    "text": "They vary obviously, if not already, can be done by AI. Other things like, please design this software for me,",
    "start": "713570",
    "end": "721285"
  },
  {
    "text": "architect my home, is this person going to win the Olympics in 10 years?",
    "start": "721285",
    "end": "729069"
  },
  {
    "text": "These are all things that would take much more than one second of thoughts.",
    "start": "729070",
    "end": "733610"
  },
  {
    "text": "This is likely to remain outside of the realm of AI for the considerable future.",
    "start": "734130",
    "end": "741565"
  },
  {
    "text": "Again, is my car inside the lane? Yes, we can do that now that's a very fast task,",
    "start": "741565",
    "end": "747730"
  },
  {
    "text": "but [inaudible] is much [inaudible] harder.",
    "start": "747730",
    "end": "753519"
  },
  {
    "text": "We can make judgments but maybe we're doing okay, but it's not clear we're going to get it right yet.",
    "start": "753520",
    "end": "760165"
  },
  {
    "start": "760000",
    "end": "983000"
  },
  {
    "text": "Then we need to flip this around and say, if that's what AI can and cannot do, what can and can't we do with intelligence augmentation?",
    "start": "760165",
    "end": "768265"
  },
  {
    "text": "Here I'll give you a few examples of how things that are likely coming to market soon are drawing on these advances.",
    "start": "768265",
    "end": "778795"
  },
  {
    "text": "You can imagine, for example, a project in which a piece of hardware that you can install just",
    "start": "778795",
    "end": "785965"
  },
  {
    "text": "turn something into the spigot outside of your house,",
    "start": "785965",
    "end": "791350"
  },
  {
    "text": "it will start to disaggregate your water usage and be able to start telling you how much water is being used by this toilet,",
    "start": "791350",
    "end": "798940"
  },
  {
    "text": "this bathtub, this sink, this dishwasher? Imagine just being able to screw one thing in and then getting all sorts of",
    "start": "798940",
    "end": "804819"
  },
  {
    "text": "visualizations about what's using water. It's learning, someone's being trained.",
    "start": "804820",
    "end": "811570"
  },
  {
    "text": "What's a toilet, what's a faucet? The way you can tell this is by momentary changes in the water pressure in your water line as,",
    "start": "811570",
    "end": "819295"
  },
  {
    "text": "say the faucet opens. Once you have these, you can start to think about how you design",
    "start": "819295",
    "end": "825685"
  },
  {
    "text": "potentially behavior change interfaces that would visualize how much water you're spending,",
    "start": "825685",
    "end": "830890"
  },
  {
    "text": "who's spending it, what time of day, try to help you be more sustainable. Another example are what are known as ability based interfaces.",
    "start": "830890",
    "end": "838839"
  },
  {
    "text": "These are interfaces that can be customized to individuals, say with different motor abilities.",
    "start": "838840",
    "end": "845065"
  },
  {
    "text": "Imagine that I was born with a disability. This system can start to take a user interface like the one on the top,",
    "start": "845065",
    "end": "854395"
  },
  {
    "text": "measure various things about my motor abilities and then predict a version of that same interface that would be",
    "start": "854395",
    "end": "861880"
  },
  {
    "text": "more effective given my motor abilities, and individuals who have these customized interfaces,",
    "start": "861880",
    "end": "867820"
  },
  {
    "text": "you can imagine this being like a web browser plugin, for example, about 25 percent faster,",
    "start": "867820",
    "end": "873670"
  },
  {
    "text": "makes 73 percent fewer errors with these automatic adjustments. We can start to think about how AI can understand how people who are born",
    "start": "873670",
    "end": "883495"
  },
  {
    "text": "with various motor disabilities or visual disabilities might be able to perform.",
    "start": "883495",
    "end": "889330"
  },
  {
    "text": "Also as I age or as I'm distracted because I have a three-year-old at home and I'm working from home now because of COVID-19,",
    "start": "889330",
    "end": "896514"
  },
  {
    "text": "all of these differences. In the style and fashion space, people are building technologies that allow me to",
    "start": "896515",
    "end": "903550"
  },
  {
    "text": "describe in words what it is that I'm looking for. I'm looking for an outfit for a beach wedding.",
    "start": "903550",
    "end": "908755"
  },
  {
    "text": "It needs to look effortless and breezy and build embeddings on top of this that can",
    "start": "908755",
    "end": "914080"
  },
  {
    "text": "return items that match the query even though I may not have used exactly the right terms.",
    "start": "914080",
    "end": "920500"
  },
  {
    "text": "Think of this as a higher level search engine. I don't just say, dress with flowers,",
    "start": "920500",
    "end": "925839"
  },
  {
    "text": "I say a beach wedding that's breezy, and it can do this mapping.",
    "start": "925840",
    "end": "932005"
  },
  {
    "text": "Here's another one. This will be a bit of a short video.",
    "start": "932005",
    "end": "937300"
  },
  {
    "text": "If you're a visual designer, people are building AI models that can understand where people are looking.",
    "start": "937300",
    "end": "943644"
  },
  {
    "text": "You want a heat map that says, look at the red parts. People pay attention to the red parts.",
    "start": "943645",
    "end": "948834"
  },
  {
    "text": "As I move the design of my poster around, say this text October.",
    "start": "948835",
    "end": "954595"
  },
  {
    "text": "As I make it smaller or larger, I can see immediately how much people are going to be paying attention to various parts of the poster.",
    "start": "954595",
    "end": "961465"
  },
  {
    "text": "Now imagine I'm a designer or a marketing person or something like this being able to work in a very tight loop where I can change everything that I'm doing,",
    "start": "961465",
    "end": "970330"
  },
  {
    "text": "I can change the design, I can change the messaging, and get an immediate prediction of what people are going to pay",
    "start": "970330",
    "end": "975490"
  },
  {
    "text": "attention to because we have better models of human visual attention. If I change the color, no one pays attention anymore.",
    "start": "975490",
    "end": "983005"
  },
  {
    "start": "983000",
    "end": "1362000"
  },
  {
    "text": "There are lots of opportunities, but there's lots of challenges in this space as well.",
    "start": "983005",
    "end": "989170"
  },
  {
    "text": "This is where we're going to start to dig into the core issues around designing interactive artificial intelligence,",
    "start": "989170",
    "end": "996759"
  },
  {
    "text": "which is uncertainty and error. What do I mean by this?",
    "start": "996759",
    "end": "1003040"
  },
  {
    "text": "Essentially up to this point in computing and interaction, we've lived in a world in which when I click on something or when I say something,",
    "start": "1004370",
    "end": "1015060"
  },
  {
    "text": "the computer does exactly what I ask. It's known as direct manipulation. That I say click on the ''Save'' button and the machine saves,",
    "start": "1015060",
    "end": "1025275"
  },
  {
    "text": "click on the ''Bold'' button and my text gets bold. But people are trying to do stuff with AI that",
    "start": "1025275",
    "end": "1032745"
  },
  {
    "text": "will inevitably introduce error and uncertainty. That's because I might be saying things at a higher level,",
    "start": "1032745",
    "end": "1039930"
  },
  {
    "text": "like make this look more professional, or it might misunderstand me, or it might misexecute.",
    "start": "1039930",
    "end": "1045525"
  },
  {
    "text": "It's more intelligent, but it's not deterministic. It's not for sure that it will do this.",
    "start": "1045525",
    "end": "1052930"
  },
  {
    "text": "What do we do about this? In some systems, when you have very high certainty,",
    "start": "1053600",
    "end": "1061860"
  },
  {
    "text": "the systems will automatically take action. On the left you can see an example in Gmail.",
    "start": "1061860",
    "end": "1067095"
  },
  {
    "text": "If I said, attached are my tax documents, but I didn't actually attach anything or various other versions of this,",
    "start": "1067095",
    "end": "1075360"
  },
  {
    "text": "Gmail will actually pop up a window that says, hey, did you actually mean to attach files?",
    "start": "1075360",
    "end": "1080685"
  },
  {
    "text": "This is sort of like are you trying to write a letter right now from Microsoft Word, but it's so certain given your language,",
    "start": "1080685",
    "end": "1088050"
  },
  {
    "text": "that this is often viewed as a savior rather than an annoyance. Likewise, when I tell Siri to set an alarm in 25 minutes,",
    "start": "1088050",
    "end": "1097005"
  },
  {
    "text": "Siri just goes ahead and does it. When it's high certainty and the probability of error is low,",
    "start": "1097005",
    "end": "1103740"
  },
  {
    "text": "the systems will go ahead. But what if certainty is lower?",
    "start": "1103740",
    "end": "1108750"
  },
  {
    "text": "What do we do? Here there are a number of different techniques that industry and in research have developed to try and be a bit smarter about this.",
    "start": "1108750",
    "end": "1117945"
  },
  {
    "text": "One of them goes under the heading of adaptive interaction. In adaptive interaction, what you're doing is tweaking the interface",
    "start": "1117945",
    "end": "1126645"
  },
  {
    "text": "to bring things closer to you that the system thinks might be more useful.",
    "start": "1126645",
    "end": "1132945"
  },
  {
    "text": "Rather than trying to execute something automatically, it's more like an assistant",
    "start": "1132945",
    "end": "1141025"
  },
  {
    "text": "who's bringing you the stuff that you might need right at the time when you need it. You've noticed, for example,",
    "start": "1141025",
    "end": "1147190"
  },
  {
    "text": "that when you resize, in this case Microsoft Word, it's not that it just cuts off the various items,",
    "start": "1147190",
    "end": "1155610"
  },
  {
    "text": "it will actually relay out some of them. It'll collapse certain things, it'll expand certain things because it has",
    "start": "1155610",
    "end": "1161440"
  },
  {
    "text": "a notion of what you're likely to be clicking on. It will try to lay things out such that it keeps the tools that you need most available.",
    "start": "1161440",
    "end": "1170905"
  },
  {
    "text": "Again, you can think about being adaptive, that as you'll notice that if I take a website on my phone and I turn my phone from say,",
    "start": "1170905",
    "end": "1182380"
  },
  {
    "text": "vertical to horizontal, it will relay it out. AIs will sometimes do this kind of thing as well,",
    "start": "1182380",
    "end": "1188110"
  },
  {
    "text": "where I can automatically relay out an interface that was say designed for a mouse interaction to work well",
    "start": "1188110",
    "end": "1195640"
  },
  {
    "text": "with touch interaction like on a phone or a tablet by trying to optimize a cost function on how much time and effort it would take someone to do this.",
    "start": "1195640",
    "end": "1205600"
  },
  {
    "text": "Now, you can be adaptive like this, but another large set of options are oriented around accelerators. What are accelerators?",
    "start": "1205600",
    "end": "1214750"
  },
  {
    "text": "Accelerators basically don't force you to do anything. By default, you might be exactly as fast as you are now,",
    "start": "1214750",
    "end": "1222475"
  },
  {
    "text": "but it offers you an opportunity to autocomplete what you're doing. Sometimes literally.",
    "start": "1222475",
    "end": "1228315"
  },
  {
    "text": "When I type San F into Google, this drop-down has lots of guesses about things that I might actually be typing.",
    "start": "1228315",
    "end": "1235495"
  },
  {
    "text": "It's not San Francisco that's the most likely, it's actually San Francisco weather. All I need to do is press the ''Down arrow'' and ''Enter'' and it'll speed me up.",
    "start": "1235495",
    "end": "1245250"
  },
  {
    "text": "Well, likewise, when I'm driving directions like with Google Maps or Apple Maps or various others Waze.",
    "start": "1245250",
    "end": "1254779"
  },
  {
    "text": "It will sometimes say, \"Hey, there's a faster route now available.\" This is an interesting question. I can be accelerated by hitting \"Accept\" or if I do nothing, I stay where I am.",
    "start": "1254780",
    "end": "1265020"
  },
  {
    "text": "There's always the important question here of whether this is opt-in or opt-out. If I do nothing, will it move me to the new route,",
    "start": "1265020",
    "end": "1271005"
  },
  {
    "text": "or if I do nothing, will it just keep me where I am? This is very context-dependent. In general, my advice is to opt toward a heavier user control which would",
    "start": "1271005",
    "end": "1281010"
  },
  {
    "text": "mean by default that they do the last thing the user told you to do but allow them to revise their opinion.",
    "start": "1281010",
    "end": "1287649"
  },
  {
    "text": "Another approach that many interactive systems use when trying to layer on top of uncertain AIs are suggestion.",
    "start": "1287650",
    "end": "1294440"
  },
  {
    "text": "This is when you have lower certainty. These are often seen in the context of what are known as recommender systems.",
    "start": "1294440",
    "end": "1302540"
  },
  {
    "text": "Recommender systems power everything from Amazon to Netflix to Stitch Fix.",
    "start": "1302540",
    "end": "1307700"
  },
  {
    "text": "The basic idea here is that it's saying, \"Hey, here's some stuff you might be interested in seeing.\"",
    "start": "1307700",
    "end": "1314310"
  },
  {
    "text": "Netflix at some point maybe thinks that I'm into comedies,",
    "start": "1315080",
    "end": "1321240"
  },
  {
    "text": "and it'll show me Parks and Rec, Friends, and Cheers, or if Stitch Fix is trying to learn more about my style so",
    "start": "1321240",
    "end": "1326970"
  },
  {
    "text": "that it sends me jeans that fit my style. If you want to learn more about this,",
    "start": "1326970",
    "end": "1332550"
  },
  {
    "text": "I would check out the term collaborative filtering. There's a rich set of techniques around this.",
    "start": "1332550",
    "end": "1338550"
  },
  {
    "text": "But ultimately, what these recommender systems tend to be used to do is to display a large number of personalized suggestions to the user.",
    "start": "1338550",
    "end": "1347850"
  },
  {
    "text": "We don't know which one, we might be wrong about any given one of them, so we're not going to show you one [inaudible] menu,",
    "start": "1347850",
    "end": "1354390"
  },
  {
    "text": "and you're going to pick between them. The hope is that at least one of the things there would be good",
    "start": "1354390",
    "end": "1359760"
  },
  {
    "text": "enough even if some of them are off. Then in general, if you have low certainty, just do nothing.",
    "start": "1359760",
    "end": "1367290"
  },
  {
    "start": "1362000",
    "end": "1566000"
  },
  {
    "text": "This is in fact most interfaces today. It does what's known as direct manipulation. It just says, \"The end user's in control.",
    "start": "1367290",
    "end": "1375420"
  },
  {
    "text": "We're not going to screw anything up, but we're not going to do anything either. We can make guesses, but ultimately,",
    "start": "1375420",
    "end": "1381615"
  },
  {
    "text": "there's so much error that we might make that it's just not worth it. We're going to leave you in control.\"",
    "start": "1381615",
    "end": "1389110"
  },
  {
    "text": "This is overall known as a mixed-initiative interaction framework.",
    "start": "1389450",
    "end": "1394755"
  },
  {
    "text": "It's mixed-initiative because sometimes the computer will take the lead, and sometimes the person will take the lead.",
    "start": "1394755",
    "end": "1400919"
  },
  {
    "text": "If you're a little bit more mathematically oriented, I can provide a visualization of the notion here.",
    "start": "1400920",
    "end": "1410760"
  },
  {
    "text": "On the x-axis, along the bottom, is the probability of some goal being true given that the system thinks it's true.",
    "start": "1410760",
    "end": "1419235"
  },
  {
    "text": "So on the bottom right there is yes, the machine is right. On the bottom left is no, it's wrong.",
    "start": "1419235",
    "end": "1425010"
  },
  {
    "text": "It thought that your goal was G, but it definitely wasn't. On the y-axis is how much of value this brings to you.",
    "start": "1425010",
    "end": "1431429"
  },
  {
    "text": "This is in an economic sense like utility. Is it really good for you, or is it pretty bad for you?",
    "start": "1431430",
    "end": "1437085"
  },
  {
    "text": "If it's unlikely that the user has a given goal, we're on the left half of the square.",
    "start": "1437085",
    "end": "1442784"
  },
  {
    "text": "If it's likely that the user has a given goal, then we're on the right half of that square.",
    "start": "1442785",
    "end": "1449380"
  },
  {
    "text": "You could build out a few utility measures. For example, in the upper left,",
    "start": "1450590",
    "end": "1456705"
  },
  {
    "text": "that little sideways half t is a NOT symbol,",
    "start": "1456705",
    "end": "1462690"
  },
  {
    "text": "logical operator NOT, if you haven't seen that before. What it's saying is what's the utility to the user if I take no action,",
    "start": "1462690",
    "end": "1469875"
  },
  {
    "text": "and it was not their goal? Let's say it means if I interactively do nothing,",
    "start": "1469875",
    "end": "1475050"
  },
  {
    "text": "just let the user do their thing, and I was wrong about what the thing that they were going to do was.",
    "start": "1475050",
    "end": "1481350"
  },
  {
    "text": "In the upper right likewise is the utility of taking action if it was their goal. What if they didn't want to change routes,",
    "start": "1481350",
    "end": "1488985"
  },
  {
    "text": "and I did it for them. How good is that? Likewise, the other two would say, \"What if I don't do anything, but I was right?",
    "start": "1488985",
    "end": "1495180"
  },
  {
    "text": "What if I do do something, and I was wrong?\" That's the false positive. What happens if I say if you're writing a letter,",
    "start": "1495180",
    "end": "1501960"
  },
  {
    "text": "how bad is that? It turns out that you can actually reason over this space to figure out when you should do what.",
    "start": "1501960",
    "end": "1509595"
  },
  {
    "text": "For example, here, this green line is what you could think of as the utility of inaction. They both say NOT A.",
    "start": "1509595",
    "end": "1516210"
  },
  {
    "text": "That means I do nothing. In the upper left, that means if I was wrong about the goal,",
    "start": "1516210",
    "end": "1522750"
  },
  {
    "text": "this is how much utility I would be getting if I did nothing. On the bottom right, if I did nothing but I was right about the goal,",
    "start": "1522750",
    "end": "1528960"
  },
  {
    "text": "that's how much benefit or harm I would bring to the user. Likewise, there's utility of action.",
    "start": "1528960",
    "end": "1534255"
  },
  {
    "text": "What you can start to do is say where's the line highest? We can see is that the line on utility of inaction is higher.",
    "start": "1534255",
    "end": "1542655"
  },
  {
    "text": "It's in the upper left, it's higher up when I'm low certainty on the left half the diagram.",
    "start": "1542655",
    "end": "1551009"
  },
  {
    "text": "When I'm not actually sure, I should probably not do anything. But when as I become more sure,",
    "start": "1551010",
    "end": "1556500"
  },
  {
    "text": "then I should start to act. You can reason about this in a closed-form fashion through this notion of mixed-initiative interaction from Eric Horvitz.",
    "start": "1556500",
    "end": "1565650"
  },
  {
    "text": "Now, that's all what happens at the user interface side.",
    "start": "1565650",
    "end": "1571020"
  },
  {
    "start": "1566000",
    "end": "1896000"
  },
  {
    "text": "What happens about interaction when we're really dealing with the guts of these machine learning models?",
    "start": "1571020",
    "end": "1577770"
  },
  {
    "text": "What should we do? What's going to happen? Here, we're going to dive into these machine learning models,",
    "start": "1577770",
    "end": "1583740"
  },
  {
    "text": "these ML models a little bit more directly because these AI systems were all built on the back of these modern neural networks.",
    "start": "1583740",
    "end": "1591675"
  },
  {
    "text": "We have to understand what we can do to try and make these models more powerful,",
    "start": "1591675",
    "end": "1598170"
  },
  {
    "text": "more effective, more understandable, and so on. I'm going to assume here, at least at a basic level,",
    "start": "1598170",
    "end": "1604440"
  },
  {
    "text": "you know what machine learning is doing. But if you don't, I think you could probably figure out the assumptions that I'm making.",
    "start": "1604440",
    "end": "1610815"
  },
  {
    "text": "One of the core questions of this space is what is that black box learning?",
    "start": "1610815",
    "end": "1616620"
  },
  {
    "text": "You've trained some statistical machine learning model, and what has it learned?",
    "start": "1616620",
    "end": "1622620"
  },
  {
    "text": "How do I know what it knows and what it doesn't know? What kind of errors might it make? These machine learning models are big black boxes.",
    "start": "1622620",
    "end": "1629400"
  },
  {
    "text": "They're powerful, but they're very high-level statistical functions,",
    "start": "1629400",
    "end": "1634680"
  },
  {
    "text": "they're universal approximators which means they could learn anything. But what did it learn?",
    "start": "1634680",
    "end": "1640905"
  },
  {
    "text": "It's opaque, it's unintelligible. Which makes this thing very difficult to predict, design, and debug.",
    "start": "1640905",
    "end": "1646065"
  },
  {
    "text": "It results in some very non-intuitive behavior. This famous image by Ian Goodfellow is an example.",
    "start": "1646065",
    "end": "1652950"
  },
  {
    "text": "I built a computer vision [inaudible] what it's looking [inaudible] here in the bottom left is I feed it that image of a panda,",
    "start": "1652950",
    "end": "1661140"
  },
  {
    "text": "and it outputs panda with an okay level of confidence, about 57 percent confidence.",
    "start": "1661140",
    "end": "1668445"
  },
  {
    "text": "Then, these authors demonstrated that I could add a very,",
    "start": "1668445",
    "end": "1674279"
  },
  {
    "text": "very small amount of carefully chosen noise that is a messed up version of a nematode,",
    "start": "1674280",
    "end": "1682755"
  },
  {
    "text": "I think it's a nematode but be very low confidence in that, and produce the image on the right.",
    "start": "1682755",
    "end": "1689415"
  },
  {
    "text": "That image looks to humans basically exactly the same as the panda image on the left.",
    "start": "1689415",
    "end": "1695970"
  },
  {
    "text": "It does have this high-frequency noise layered into it but we humans can't really tell.",
    "start": "1695970",
    "end": "1701174"
  },
  {
    "text": "But this totally messes up the algorithm. Now the algorithm thinks with very high confidence,",
    "start": "1701175",
    "end": "1706500"
  },
  {
    "text": "99 percent confidence, that this thing is a gibbon. Totally wrong. So two images that look the same to people,",
    "start": "1706500",
    "end": "1715094"
  },
  {
    "text": "the algorithm is thinking are very different. We need to be able to understand why did it think this way?",
    "start": "1715094",
    "end": "1720825"
  },
  {
    "text": "Why did adding the seemingly random-colored noise change its opinion?",
    "start": "1720825",
    "end": "1726960"
  },
  {
    "text": "The goal here is to produce what's known as intelligibility in these models. A model is intelligible as is",
    "start": "1726960",
    "end": "1735539"
  },
  {
    "text": "defined basically to the extent that a person can predict how a change to the inputs will change its outputs.",
    "start": "1735540",
    "end": "1741045"
  },
  {
    "text": "For example, let's examine whether my three-year-old is intelligible. I was trying to feed him lunch earlier today.",
    "start": "1741045",
    "end": "1748770"
  },
  {
    "text": "If I give him a peanut butter sandwich, I can predict that he will be happy and eat it.",
    "start": "1748770",
    "end": "1754575"
  },
  {
    "text": "If I try to give him the lentil soup that I made, I can predict that he will not eat it and will not be happy.",
    "start": "1754575",
    "end": "1760875"
  },
  {
    "text": "I feel that that model is relatively intelligible because I can reason about it. When I change the inputs to his lunch,",
    "start": "1760875",
    "end": "1767805"
  },
  {
    "text": "I can predict the outputs from his mouth. For example, in the bottom left,",
    "start": "1767805",
    "end": "1773385"
  },
  {
    "text": "linear relationships, we tend to view as very intelligible. Y equals MX plus B,",
    "start": "1773385",
    "end": "1780540"
  },
  {
    "text": "if I get more years of education, then my lifetime income goes up. That's a linear relationship.",
    "start": "1780540",
    "end": "1786870"
  },
  {
    "text": "It's just two variables. As I increase X, Y either goes up or down.",
    "start": "1786870",
    "end": "1793185"
  },
  {
    "text": "Convolutional neural networks of the sorts that are used in computer vision, far less intelligible.",
    "start": "1793185",
    "end": "1800235"
  },
  {
    "text": "There's these sliding windows that are compressing down and then recombining.",
    "start": "1800235",
    "end": "1805799"
  },
  {
    "text": "Essentially, one cannot really make a prediction of what happens if I change the little circle on the top of the robot's head to a square.",
    "start": "1805800",
    "end": "1812549"
  },
  {
    "text": "We don't know exactly what's going to happen. As we would say at the end of the day,",
    "start": "1812550",
    "end": "1819540"
  },
  {
    "text": "they would make errors. One way to look at this from an intelligence augmentation point",
    "start": "1819540",
    "end": "1826970"
  },
  {
    "text": "of view is to try and help visualize what the model sees. These are images that might keep you up at night,",
    "start": "1826970",
    "end": "1832640"
  },
  {
    "text": "but what it is is on the far left, you can essentially accentuate",
    "start": "1832640",
    "end": "1838635"
  },
  {
    "text": "the nodes within the neural network that are activating with the notion of a labrador retriever and essentially get it to",
    "start": "1838635",
    "end": "1846570"
  },
  {
    "text": "hallucinate what it sees when it thinks of a labrador retriever, then as you go over to the right, a tiger cat.",
    "start": "1846570",
    "end": "1854115"
  },
  {
    "text": "Then you can build the entire linear space between those to look at what is it paying attention to.",
    "start": "1854115",
    "end": "1861780"
  },
  {
    "text": "As you can see on the far left, when it's recognizing labrador retriever is what's it's really seeing are these big floppy ears,",
    "start": "1861780",
    "end": "1868890"
  },
  {
    "text": "and some brownish nose, and so on. Then on the right with the tiger cat's, you can see the small pointy ears,",
    "start": "1868890",
    "end": "1875760"
  },
  {
    "text": "the texture to its fur, the patterns on its fur, and in-between.",
    "start": "1875760",
    "end": "1882430"
  },
  {
    "text": "The question would be maybe we can't make the thing reason in the same way that a person can,",
    "start": "1883250",
    "end": "1889394"
  },
  {
    "text": "but maybe we can come around the other side and help a person see what the system is seeing.",
    "start": "1889395",
    "end": "1895635"
  },
  {
    "text": "Now there are other approaches as well, just to simplify the model. Sometimes you can actually get 90,",
    "start": "1895635",
    "end": "1902490"
  },
  {
    "start": "1896000",
    "end": "2155000"
  },
  {
    "text": "95 percent of the performance out of the machine learning model but far higher intelligibility.",
    "start": "1902490",
    "end": "1907935"
  },
  {
    "text": "One of my favorite examples in this space is an algorithm known as LIME. What this thing does,",
    "start": "1907935",
    "end": "1915690"
  },
  {
    "text": "is try to point out that even if the entire decision is complex,",
    "start": "1915690",
    "end": "1921855"
  },
  {
    "text": "maybe within a specific case of a single example,",
    "start": "1921855",
    "end": "1926880"
  },
  {
    "text": "it's much simpler to understand. Let's say, for example, here you have these blue circles and these red crosses,",
    "start": "1926880",
    "end": "1933150"
  },
  {
    "text": "and the machine learning algorithm has learned to separate the red crosses from the blue circles through the lighter colored irregular space that you see here.",
    "start": "1933150",
    "end": "1943059"
  },
  {
    "text": "Let's say you were trying to explain why is this red plus sign?",
    "start": "1943070",
    "end": "1948883"
  },
  {
    "text": "Why is it in the red space? Why do I not think it's a blue circle? What would you do? Well, LIME made this observation that you could sample points nearby.",
    "start": "1948884",
    "end": "1958920"
  },
  {
    "text": "For example, these big red crosses and big blue circles, and weigh them in proportion to how close they are to the example you care about,",
    "start": "1958920",
    "end": "1965370"
  },
  {
    "text": "and then learn a very simple linear separator between those. You see that black dashed line around the red plus sign says, you know what?",
    "start": "1965370",
    "end": "1975390"
  },
  {
    "text": "I can't explain that the full complexity of the space to you, but for this particular example,",
    "start": "1975390",
    "end": "1981404"
  },
  {
    "text": "relative to other counterfactuals nearby, here are the features that matter. What's important to note here,",
    "start": "1981404",
    "end": "1987434"
  },
  {
    "text": "well, let me give an example. Again, my three-year-old, when I say it's bedtime, he can say, \"Why is it bedtime? I'm not tired.\"",
    "start": "1987435",
    "end": "1996075"
  },
  {
    "text": "I can give all sorts of different reasons it might involve the fact that he needs sleep or he's going to become a mess.",
    "start": "1996075",
    "end": "2004460"
  },
  {
    "text": "It might be that I need to do some work tonight. It could be many different things, and they might all be true. It's a complex space.",
    "start": "2004460",
    "end": "2010295"
  },
  {
    "text": "But in the case of this particular example,",
    "start": "2010295",
    "end": "2015410"
  },
  {
    "text": "the most salient reason might just be because it's after his bedtime, and that's the simplest explanation to give.",
    "start": "2015410",
    "end": "2023735"
  },
  {
    "text": "If the time were to change to be earlier, it would no longer be his bedtime. I've inserted a simpler explanation,",
    "start": "2023735",
    "end": "2030890"
  },
  {
    "text": "but it's important to point out that this is actually, it's technically a lie. It's not a representation of the full model.",
    "start": "2030890",
    "end": "2036650"
  },
  {
    "text": "There are times where I would let him stay up past his bedtime for specific reasons by I'm not going to explain all that,",
    "start": "2036650",
    "end": "2042290"
  },
  {
    "text": "it's going to be a local explanation. Percy Liang and Pang Wei Koh here at",
    "start": "2042290",
    "end": "2048560"
  },
  {
    "text": "Stanford also did some cool work on influence functions, that are another way you can visualize this. In this case, what you can do is say,",
    "start": "2048560",
    "end": "2055399"
  },
  {
    "text": "well, here's this test image on the left, and you can start to actually identify the training images,",
    "start": "2055400",
    "end": "2062450"
  },
  {
    "text": "the inputs you trained the algorithm on, that were most influential in the decision. Again here, with the sense of my three-year-old sending him to bed,",
    "start": "2062450",
    "end": "2071585"
  },
  {
    "text": "he can say, \"Why?\" Well, I can say, \"Well, let me tell you. Because when you stayed up late last time,",
    "start": "2071585",
    "end": "2078425"
  },
  {
    "text": "you were very cranky the next day,\" so it pulls out the influential training data points,",
    "start": "2078425",
    "end": "2085175"
  },
  {
    "text": "and those are much more readily interpretable than a complex model. Now, as Dan Weld and his colleagues argue,",
    "start": "2085175",
    "end": "2093095"
  },
  {
    "text": "there's actually a dilemma here. Any model simplification like LIME, is a lie.",
    "start": "2093095",
    "end": "2098930"
  },
  {
    "text": "It is not true that this is exactly how the model reasoned about it. We're telling you a single thing when there's",
    "start": "2098930",
    "end": "2105289"
  },
  {
    "text": "a much more complex set of factors in play here. But it turns out that the non simplifications are just unintelligible.",
    "start": "2105290",
    "end": "2112204"
  },
  {
    "text": "We're somewhat in a sticky wicket here, that we either have to lie or we have to give you",
    "start": "2112205",
    "end": "2117920"
  },
  {
    "text": "the full details in a way that are going to be very hard to understand. I think it's really going to depend on your context.",
    "start": "2117920",
    "end": "2124880"
  },
  {
    "text": "What Dan Weld argues is that, you can draw on psychology research to guide what makes for an effective explanation.",
    "start": "2124880",
    "end": "2132770"
  },
  {
    "text": "You make explanations, for example, contrastive, these are things that people tend to understand quite well. Well, why did you recommend movie X?",
    "start": "2132770",
    "end": "2139369"
  },
  {
    "text": "The implicit critique is why didn't you recommend movie Y, and you can explain that much more effectively.",
    "start": "2139370",
    "end": "2145145"
  },
  {
    "text": "Necessary causes being better than sufficient ones. Using few conjuncts, don't say it's because of A and B and C and D, and so on.",
    "start": "2145145",
    "end": "2153390"
  },
  {
    "text": "Now, when we pull all this together, we start to see a situation where these AI techniques are",
    "start": "2154960",
    "end": "2164540"
  },
  {
    "start": "2155000",
    "end": "2465000"
  },
  {
    "text": "especially common as we move off the desktop into voice speech with computer vision-based interaction,",
    "start": "2164540",
    "end": "2172549"
  },
  {
    "text": "because once you're off the desktop, you often require intelligence.",
    "start": "2172550",
    "end": "2177710"
  },
  {
    "text": "I'm going to avoid saying the name of the smart speaker on the left so that I don't say the wake word of the one in my room,",
    "start": "2177710",
    "end": "2184940"
  },
  {
    "text": "but you can get the idea of what it is. A FitBit Apple watch are all sensing am I biking right now, am I walking.",
    "start": "2184940",
    "end": "2193109"
  },
  {
    "text": "Soon, the new version of iOS will tell you whether you are washing your hands.",
    "start": "2193110",
    "end": "2198235"
  },
  {
    "text": "The Nest thermostat detects when it should be changing the temperature and whether you're home and so on.",
    "start": "2198235",
    "end": "2206170"
  },
  {
    "text": "This all requires artificial intelligence because we're not going to sit there and tap every button on everything.",
    "start": "2206170",
    "end": "2212415"
  },
  {
    "text": "There's lots of examples where this has become successful. Here's an example of a research project a number of years ago now at Georgia Tech,",
    "start": "2212415",
    "end": "2219935"
  },
  {
    "text": "demonstrating that you can figure out, just like before when I was showing what's using the water in your home,",
    "start": "2219935",
    "end": "2228460"
  },
  {
    "text": "what's using the electricity in your home. Or here's an example out of Carnegie Mellon demonstrating that by just simply having a smart watch on,",
    "start": "2228460",
    "end": "2237665"
  },
  {
    "text": "it can start to pick up on the electromagnetic waves being sent out by various things you might touch,",
    "start": "2237665",
    "end": "2244415"
  },
  {
    "text": "and your computer can in real-time detect what you're touching. As I'm holding this iron,",
    "start": "2244415",
    "end": "2251360"
  },
  {
    "text": "I'm sending electromagnetic signal pulse to the body, as well as the smartwatch,",
    "start": "2251360",
    "end": "2256925"
  },
  {
    "text": "and that smart watch will make sense of the signal, run some machine learning on top of that,",
    "start": "2256925",
    "end": "2262655"
  },
  {
    "text": "and then detect what I'm doing. Now, imagine that my watch knows what I'm doing,",
    "start": "2262655",
    "end": "2268790"
  },
  {
    "text": "am I grasping my office door, it should unlock the door when I'm grasping the door, for example, and all other examples.",
    "start": "2268790",
    "end": "2277880"
  },
  {
    "text": "Am I turning on the stove, am I grabbing my my toothbrush,",
    "start": "2277880",
    "end": "2283009"
  },
  {
    "text": "am I trying to open a room, am I using my first laptop or my second laptop. Imagine how our interfaces might be able to",
    "start": "2283010",
    "end": "2290300"
  },
  {
    "text": "adapt themselves if they knew what I was doing. These are the kinds of applications that become possible when we go off the desktop.",
    "start": "2290300",
    "end": "2300780"
  },
  {
    "text": "I've just a few closing thoughts, and then we have, hopefully, I left plenty of time for questions and discussion.",
    "start": "2301360",
    "end": "2311165"
  },
  {
    "text": "Again, as a reminder, there's a Q&A area in your interface that you can feel free to toss questions into,",
    "start": "2311165",
    "end": "2316970"
  },
  {
    "text": "and then you'll soon be able to see my face again and we can have a discussion for the rest of the conversation here.",
    "start": "2316970",
    "end": "2323255"
  },
  {
    "text": "A few reflections. First, AI is undoubtedly a very powerful tool that",
    "start": "2323255",
    "end": "2330170"
  },
  {
    "text": "brings along with it some massively unsolved user interaction problems.",
    "start": "2330170",
    "end": "2335645"
  },
  {
    "text": "Often, and there are a few different sources of those. One which warrants an entire lecture on its own,",
    "start": "2335645",
    "end": "2343505"
  },
  {
    "text": "is problems around biased justice and so on, that these models can inherit.",
    "start": "2343505",
    "end": "2349745"
  },
  {
    "text": "The one we talked about today, also important, is the fact that all of a sudden,",
    "start": "2349745",
    "end": "2355250"
  },
  {
    "text": "it takes something that used to be a very certain interaction, direct manipulation, and injects uncertainty.",
    "start": "2355250",
    "end": "2362135"
  },
  {
    "text": "It brings benefits, in that it can do things that are direct manipulation interface never could, but it also makes errors and it's not sure about its answers.",
    "start": "2362135",
    "end": "2370925"
  },
  {
    "text": "We have to think about how to design. The second reflection here that I hope you're taking away,",
    "start": "2370925",
    "end": "2376760"
  },
  {
    "text": "is that if we're smart and thoughtful about how we do the interaction design, we can hide or manage that uncertainty more effectively.",
    "start": "2376760",
    "end": "2384589"
  },
  {
    "text": "That we can build a user experience that still feels good,",
    "start": "2384590",
    "end": "2389675"
  },
  {
    "text": "even though under the hood, it might not be entirely certain. We also now know that if you don't do that well,",
    "start": "2389675",
    "end": "2396680"
  },
  {
    "text": "as I'm sure you can now think of examples, it can really cause someone to throw the thing on the floor.",
    "start": "2396680",
    "end": "2401975"
  },
  {
    "text": "Finally, again, quoting [inaudible] , ''Don't let your artificial intelligence write a check that your UI can't cash'' Meaning",
    "start": "2401975",
    "end": "2409955"
  },
  {
    "text": "don't build an AI model that we can't create an effective user interface around.",
    "start": "2409955",
    "end": "2415505"
  },
  {
    "text": "\"Don't let your user interface, your UI, write and check that your AI can't cash.\" Again meaning that, you shouldn't be building a user interface that assumes or",
    "start": "2415505",
    "end": "2424220"
  },
  {
    "text": "promises things that an artificial intelligence algorithm can't actually do well enough yet.",
    "start": "2424220",
    "end": "2429530"
  },
  {
    "text": "It turns out through prospect theory, Nobel Prize winning theory from Kahneman and Tversky,",
    "start": "2429530",
    "end": "2435964"
  },
  {
    "text": "that people are very averse to problems and errors. People will much rather avoid a problem than essentially get an equivalent benefit.",
    "start": "2435965",
    "end": "2446780"
  },
  {
    "text": "If I have a choice between something that's slower but will do the thing for sure, or faster but might make an error,",
    "start": "2446780",
    "end": "2453920"
  },
  {
    "text": "many people will choose the slow but sure route. I think this is a major impediments. In some ways, are a major reason why people are",
    "start": "2453920",
    "end": "2461480"
  },
  {
    "text": "avoiding intelligent interfaces unless they're very, very accurate. I'll close here, and I think we have a few minutes",
    "start": "2461480",
    "end": "2467990"
  },
  {
    "start": "2465000",
    "end": "2638000"
  },
  {
    "text": "left for conversation questions and so on. I will stop sharing my screen and we will talk.",
    "start": "2467990",
    "end": "2476705"
  },
  {
    "text": "Hopefully, you can now see my face. >> Yes. [NOISE] Hopefully, everybody can hear me.",
    "start": "2476705",
    "end": "2482450"
  },
  {
    "text": "Thank you, Michael. This was very informative and impactful presentation.",
    "start": "2482450",
    "end": "2487490"
  },
  {
    "text": "We've gathered a range of questions from the audience. So let's go ahead and get started.",
    "start": "2487490",
    "end": "2493684"
  },
  {
    "text": "The first question is, if you could talk more broadly, how is AI being utilized to mitigate",
    "start": "2493685",
    "end": "2501558"
  },
  {
    "text": "this particular question of supply chain disruptions during the pandemic? For example, in the food service industry,",
    "start": "2501559",
    "end": "2509480"
  },
  {
    "text": "transportation logistics, clean energy, or any other industry.",
    "start": "2509480",
    "end": "2514700"
  },
  {
    "text": "What are you seeing? What are you hearing out there right now?",
    "start": "2514700",
    "end": "2519799"
  },
  {
    "text": ">> Sure. Yeah. Well, not very well for very particular reason.",
    "start": "2519800",
    "end": "2526730"
  },
  {
    "text": "Again, hopefully, you can see my face now. Here's the reason. Machine learning inherently makes the following assumption;",
    "start": "2526730",
    "end": "2535880"
  },
  {
    "text": "it has training data. The training data is assumed to be coming from",
    "start": "2535880",
    "end": "2541400"
  },
  {
    "text": "the same distribution as the test data or the real world. What that means is that essentially,",
    "start": "2541400",
    "end": "2547955"
  },
  {
    "text": "all of these algorithms assume that what they're going to need to do when they're put in the real world is actually like the training data they were getting.",
    "start": "2547955",
    "end": "2557990"
  },
  {
    "text": "So now imagine that your training data all comes from a pre-pandemic world.",
    "start": "2557990",
    "end": "2563315"
  },
  {
    "text": "You can make all assumptions. Now your test environment, your real world environments is a pandemic.",
    "start": "2563315",
    "end": "2570125"
  },
  {
    "text": "Everything has changed. Many of these algorithms will in fact I predict make",
    "start": "2570125",
    "end": "2575375"
  },
  {
    "text": "the wrong predictions because they don't know what to do in these off kilter scenarios.",
    "start": "2575375",
    "end": "2582455"
  },
  {
    "text": "There's a really good example. A few years ago,",
    "start": "2582455",
    "end": "2588150"
  },
  {
    "text": "Google's AlphaGo algorithm was playing Go master,",
    "start": "2588640",
    "end": "2593869"
  },
  {
    "text": "the world champion, and it did in fact win. But there was a very telling moment where essentially",
    "start": "2593870",
    "end": "2600440"
  },
  {
    "text": "the human player did something that the algorithm had not really seen before.",
    "start": "2600440",
    "end": "2605960"
  },
  {
    "text": "It was a confusing move and the system just totally collapsed and made some nonsensical moves.",
    "start": "2605960",
    "end": "2611960"
  },
  {
    "text": "I would actually be very careful about thinking about how to deploy AIs in a world that has changed because that's not what they're meant to be able to do.",
    "start": "2611960",
    "end": "2623185"
  },
  {
    "text": "In those cases, I would be much more likely to",
    "start": "2623185",
    "end": "2628655"
  },
  {
    "text": "make sure that there's additional human oversight so that it's not making unusual or poor decisions.",
    "start": "2628655",
    "end": "2635940"
  },
  {
    "text": ">> Great. Thank you. That leads me to the next question.",
    "start": "2636640",
    "end": "2642860"
  },
  {
    "start": "2638000",
    "end": "2867000"
  },
  {
    "text": "This is actually a combination of a few different questions. >> Sure. [OVERLAPPING] >> How do we help AI to avoid bias towards things like race,",
    "start": "2642860",
    "end": "2652893"
  },
  {
    "text": "disabilities, gender, where we know there's an issue.",
    "start": "2652894",
    "end": "2658955"
  },
  {
    "text": "How do we adjust for that? >> Yeah. Well, I think we have to be careful that there might",
    "start": "2658955",
    "end": "2668270"
  },
  {
    "text": "be challenging assumptions belying the question how do we adjust for that?",
    "start": "2668270",
    "end": "2673925"
  },
  {
    "text": "Because it assumes that if we could just get something that didn't exhibit that bias,",
    "start": "2673925",
    "end": "2682130"
  },
  {
    "text": "that would solve the problem, and it won't. But let's take this in two parts.",
    "start": "2682130",
    "end": "2688085"
  },
  {
    "text": "If you're interested in the very cutting edge technical work in this space,",
    "start": "2688085",
    "end": "2693109"
  },
  {
    "text": "I would check out a conference. I'll just list out the letters FAT star or asterisk stands for fairness,",
    "start": "2693110",
    "end": "2701870"
  },
  {
    "text": "accountability, and trust, and then everything else around that. It's a conference where people really spent a lot of time thinking about this.",
    "start": "2701870",
    "end": "2708935"
  },
  {
    "text": "However, as many have demonstrated, there's no single really effective definition of what fair means or what bias means.",
    "start": "2708935",
    "end": "2720934"
  },
  {
    "text": "For example, you could stratify on certain demographics and make sure that",
    "start": "2720935",
    "end": "2726470"
  },
  {
    "text": "your algorithm is not performing better or worse on certain demographics than others.",
    "start": "2726470",
    "end": "2734510"
  },
  {
    "text": "There was a subject of a major ProPublica article a number of years ago about how the algorithms used to predict recidivism and used by judges,",
    "start": "2734510",
    "end": "2744605"
  },
  {
    "text": "are you going to show up to your court date if I let you out on bail, were biased against African Americans or black people.",
    "start": "2744605",
    "end": "2751849"
  },
  {
    "text": "It's definitely true that we can start to build estimates of this.",
    "start": "2751850",
    "end": "2756905"
  },
  {
    "text": "But it's actually very, the devil's in the details there, and there's no really good way to capture everything about what we mean by fair.",
    "start": "2756905",
    "end": "2767045"
  },
  {
    "text": "So you end up having to pick one definition or another and then you're going to inevitably basically be missing something.",
    "start": "2767045",
    "end": "2775325"
  },
  {
    "text": "If you're looking for folks at Stanford who had been thinking about this, Sharad Goel in the Management Science and Engineering Department",
    "start": "2775325",
    "end": "2780590"
  },
  {
    "text": "has some really excellent, fairly statistically heavy work looking at how we can reason about these issues.",
    "start": "2780590",
    "end": "2787740"
  },
  {
    "text": "That said, even a perfectly fair, transparent,",
    "start": "2788820",
    "end": "2794905"
  },
  {
    "text": "and accountable algorithm might still be used to advance unjust causes.",
    "start": "2794905",
    "end": "2803105"
  },
  {
    "text": "I can have a perfectly fair algorithm that's yet still used by",
    "start": "2803105",
    "end": "2808369"
  },
  {
    "text": "an authoritarian governments [LAUGHTER] to identify people who are protesting and go throw them in jail.",
    "start": "2808370",
    "end": "2814115"
  },
  {
    "text": "Or that is applied disproportionately toward people of color.",
    "start": "2814115",
    "end": "2819395"
  },
  {
    "text": "I think that's where we need to remember that computing doesn't",
    "start": "2819395",
    "end": "2824750"
  },
  {
    "text": "just exist in some technical magical world where ethics and justice don't matter,",
    "start": "2824750",
    "end": "2830180"
  },
  {
    "text": "but in fact that AI and computing are very tied up with systems of power and oppression,",
    "start": "2830180",
    "end": "2837319"
  },
  {
    "text": "and we have to stop and think, what is it that this system, this AI, etc, is being used to do?",
    "start": "2837320",
    "end": "2844730"
  },
  {
    "text": "What's the goal? Who's going to be in charge of it? How comfortable are we with that answer?",
    "start": "2844730",
    "end": "2849950"
  },
  {
    "text": "What are the likely abuses of that power, and what should be built in the system to prevent it,",
    "start": "2849950",
    "end": "2854975"
  },
  {
    "text": "or should the system be built at all? You'll just be an input to a human who maybe is elected or something like this.",
    "start": "2854975",
    "end": "2865230"
  },
  {
    "text": ">> Great, thank you. This is another combination of a few different questions. [OVERLAPPING]",
    "start": "2865840",
    "end": "2874010"
  },
  {
    "start": "2867000",
    "end": "3168000"
  },
  {
    "text": ">> Sure. >> For inspiring start-up or a company that is never implemented in any AI.",
    "start": "2874010",
    "end": "2882750"
  },
  {
    "text": "The general questions, where does one start? [OVERLAPPING] [LAUGHTER] Then taking that maybe you've done some AI implementation,",
    "start": "2884170",
    "end": "2894650"
  },
  {
    "text": "what are the new fields in which AI is being implemented? >> Sure.",
    "start": "2894650",
    "end": "2901965"
  },
  {
    "text": "Well, to take that in an inverse order, [LAUGHTER] the first business areas that",
    "start": "2901965",
    "end": "2909280"
  },
  {
    "text": "adopted AI were the areas that were fairly computationally-heavy,",
    "start": "2909280",
    "end": "2914890"
  },
  {
    "text": "that tech field because essentially a computer science majors were learning",
    "start": "2914890",
    "end": "2920940"
  },
  {
    "text": "machine learning and say, \"I can work with this. Let's insert here smart email prioritization into Gmail, etc.\"",
    "start": "2920940",
    "end": "2928860"
  },
  {
    "text": "I think what you're starting to see or you've started to see over the last few years is the diffusion of this into supply chain management and everything else, fashion,",
    "start": "2928860",
    "end": "2938785"
  },
  {
    "text": "farming, FiveThirtyEight trying to predict your political outcomes from polling and so on,",
    "start": "2938785",
    "end": "2946330"
  },
  {
    "text": "so you're just seeing a diffusion of this into other areas.",
    "start": "2946330",
    "end": "2953020"
  },
  {
    "text": "Often it goes by different names in other business areas. Sometimes it falls under the heading of a data science team.",
    "start": "2953020",
    "end": "2961945"
  },
  {
    "text": "But I would say that there are very few domains now that remain untouched by AI or at least where someone isn't trying.",
    "start": "2961945",
    "end": "2971725"
  },
  {
    "text": "It doesn't mean that they've necessarily succeeded yet, but I would be stunned to find an area where someone who hasn't tried to figure it out.",
    "start": "2971725",
    "end": "2979484"
  },
  {
    "text": "If you are yourself trying to transition, there are many people here on Stanford's faculty",
    "start": "2979485",
    "end": "2985120"
  },
  {
    "text": "who study business transformation and technological transformation and so on.",
    "start": "2985120",
    "end": "2990955"
  },
  {
    "text": "I'm thinking of my colleague Melissa Valentine in Management Science and Engineering,",
    "start": "2990955",
    "end": "2997910"
  },
  {
    "text": "several of her studies pointed out that there's actually a very complex power dynamics within organizations that have to be designed",
    "start": "2998550",
    "end": "3006240"
  },
  {
    "text": "very carefully if you're trying to turn an existing business into an AI smart business because AI is going to change who has power over what.",
    "start": "3006240",
    "end": "3020740"
  },
  {
    "text": "To be very concrete about that, decisions that used to be made by people over",
    "start": "3020990",
    "end": "3026010"
  },
  {
    "text": "here in the organization are now willing to be made by algorithms over here in the organizations and those algorithms are run by other people.",
    "start": "3026010",
    "end": "3036105"
  },
  {
    "text": "What ends up happening sometimes is that it gets gummed up and if you're not careful about this,",
    "start": "3036105",
    "end": "3041835"
  },
  {
    "text": "these people who are losing power in the organization are going to resist the introduction of the AI because it's reducing what they can say and the influence they have.",
    "start": "3041835",
    "end": "3052945"
  },
  {
    "text": "Angle Christin here at Stanford's Communication Department has studied how this happens in newsrooms.",
    "start": "3052945",
    "end": "3060105"
  },
  {
    "text": "If you're a newspaper in the US, she also studied in France,",
    "start": "3060105",
    "end": "3065490"
  },
  {
    "text": "they have different reactions to these predictions of what's going to get clicks or how many clicks something got, etc.,",
    "start": "3065490",
    "end": "3071325"
  },
  {
    "text": "and it's changing the values of who's important and who gets to make these editorial decisions.",
    "start": "3071325",
    "end": "3080290"
  },
  {
    "text": "It can really go poorly and it can make an organization combust if you don't manage it carefully.",
    "start": "3081380",
    "end": "3089590"
  },
  {
    "text": "The other things that I've heard them mentioned, and really I'm relying here on their expertise substantially, is that, well,",
    "start": "3091760",
    "end": "3098250"
  },
  {
    "text": "obviously, you need to produce people who are very carefully in charge of the data.",
    "start": "3098250",
    "end": "3104625"
  },
  {
    "text": "What is this data that's being trained? You need a ton of data to make any of these things work. Who's collecting it and who's managing it?",
    "start": "3104625",
    "end": "3111390"
  },
  {
    "text": "Who's making sure it's available? Who's making sure that it's clean? Having a clean data is surprisingly challenging.",
    "start": "3111390",
    "end": "3116865"
  },
  {
    "text": "Then you have a group of people who are modeling, building machine learning models on top of that data and",
    "start": "3116865",
    "end": "3123930"
  },
  {
    "text": "who's working with them to decide what's the model and how and when. What is good enough mean?",
    "start": "3123930",
    "end": "3129960"
  },
  {
    "text": "What's the error rate that is okay enough to launch a product?",
    "start": "3129960",
    "end": "3135010"
  },
  {
    "text": "There are a number of programs through SCPD and others,",
    "start": "3135590",
    "end": "3140740"
  },
  {
    "text": "maybe Anita can correct, maybe there's a digital transformations program",
    "start": "3141380",
    "end": "3146430"
  },
  {
    "text": "here at SCPD if you want to learn more about that, but there's quite a bit to be said about how to manage an organizational transformation.",
    "start": "3146430",
    "end": "3153299"
  },
  {
    "text": "If you're a small startup, I think it's somewhat easier. You're luckier because you don't have all that baggage.",
    "start": "3153300",
    "end": "3159660"
  },
  {
    "text": "But I think it will cause and still look quite different than a traditional startup, like a software startup.",
    "start": "3159660",
    "end": "3166120"
  },
  {
    "text": ">> Great, thank you. Yes, there is a digital transformation program,",
    "start": "3166610",
    "end": "3172275"
  },
  {
    "start": "3168000",
    "end": "3475000"
  },
  {
    "text": "which this course is a part of, and you can learn more about that by selecting the Learn More button.",
    "start": "3172275",
    "end": "3179400"
  },
  {
    "text": "One other question and this might be our last one, [LAUGHTER] I thought this was humorous but it's to the point.",
    "start": "3179400",
    "end": "3188384"
  },
  {
    "text": "How would you communicate to a company, the users, that your AI is going to give you answers that are not 100 percent correct?",
    "start": "3188385",
    "end": "3199315"
  },
  {
    "text": "There is that error, and how do you send that message?",
    "start": "3199315",
    "end": "3205109"
  },
  {
    "text": ">> People have tried a bunch of different things. Generally, the most successful technique has been to hide it,",
    "start": "3206210",
    "end": "3213210"
  },
  {
    "text": "just to decide whether it's good enough and to own the fact that it might make mistakes,",
    "start": "3213210",
    "end": "3219015"
  },
  {
    "text": "or to be in a domain where it doesn't matter if there are slight mistakes. Peter Norvig at Google,",
    "start": "3219015",
    "end": "3227025"
  },
  {
    "text": "I remember him pointing out that a lot of successes in modern AI are in domains where they're",
    "start": "3227025",
    "end": "3232725"
  },
  {
    "text": "like soft edges where there are multiple okay solutions.",
    "start": "3232725",
    "end": "3238725"
  },
  {
    "text": "If you look at these things where like GPT-3 recently is producing all sorts of interesting text and looks human written and so on,",
    "start": "3238725",
    "end": "3247320"
  },
  {
    "text": "it's because there's not one single right answer. Things can be a little bit weird and off where there are multiple correct paths and it can usually find one of them.",
    "start": "3247320",
    "end": "3255525"
  },
  {
    "text": "So that's one approach that places have taken.",
    "start": "3255525",
    "end": "3259869"
  },
  {
    "text": "For example, with Tesla's Autopilot, there may be multiple correct paths but there are clearly",
    "start": "3260690",
    "end": "3266609"
  },
  {
    "text": "wrong ones that lead to a crash. You can't just say,",
    "start": "3266609",
    "end": "3272984"
  },
  {
    "text": "''I'm uncertain about this.'' You have to decide at some point am I going to give the control back to the driver and say,",
    "start": "3272984",
    "end": "3278445"
  },
  {
    "text": "''I can't handle this,'' and when would you do that.",
    "start": "3278445",
    "end": "3281650"
  },
  {
    "text": "Many algorithms you might be aware of these unexposed confidence values. I think I'm 92 percent sure this is the right answer.",
    "start": "3286220",
    "end": "3294195"
  },
  {
    "text": "Those can be useful, but I don't think that exposing those to end-users get interpreted quite correctly.",
    "start": "3294195",
    "end": "3300780"
  },
  {
    "text": "The other thing to keep in mind is that people tend not to associate the errors with an AI that might be making errors,",
    "start": "3300780",
    "end": "3308415"
  },
  {
    "text": "they associate it with your product. Again, think back to Clippy in Microsoft Word. It wasn't that there was a machine learning algorithm which there was making errors,",
    "start": "3308415",
    "end": "3319080"
  },
  {
    "text": "they're like, ''No, Microsoft Word is dumb.'' It gets attributed to the company or to the product.",
    "start": "3319080",
    "end": "3324643"
  },
  {
    "text": "So I would be very careful launching things that have high error rates.",
    "start": "3324644",
    "end": "3332760"
  },
  {
    "text": "Again, with my voice assistant in the room, I'm surprised how much I put up with it sometimes.",
    "start": "3332760",
    "end": "3339015"
  },
  {
    "text": "They misinterpret things all the times and it becomes very frustrating.",
    "start": "3339015",
    "end": "3344865"
  },
  {
    "text": "Even though it knows it's uncertain, it still has to do something and sometimes even just asking me, ''Did you mean blah?''",
    "start": "3344865",
    "end": "3352079"
  },
  {
    "text": "is still seen as annoying. I think this again comes back to the don't make promises you can't keep.",
    "start": "3352080",
    "end": "3358275"
  },
  {
    "text": "If it can't do the right thing the vast majority of the time, I would be very careful about designing user experience around it.",
    "start": "3358275",
    "end": "3367110"
  },
  {
    "text": "On the other hand, if you have some system in which the machine is making predictions and then there's",
    "start": "3367110",
    "end": "3373740"
  },
  {
    "text": "a human layer that's always vetting those predictions and the only thing that gets seen by the outside world is the vetted version of it,",
    "start": "3373740",
    "end": "3380819"
  },
  {
    "text": "then maybe you could be more certain. Microsoft has a system called calendar.help,",
    "start": "3380820",
    "end": "3386475"
  },
  {
    "text": "which is a great example of this. It's like a calendaring assistant,",
    "start": "3386475",
    "end": "3393130"
  },
  {
    "text": "maybe Cortana or whatever it's called now, \"Find a time when Anita and I can meet.\"",
    "start": "3393980",
    "end": "3402670"
  },
  {
    "text": "For simple requests, it's an algorithm, for more complex ones, there's actually humans in the loop.",
    "start": "3403010",
    "end": "3408480"
  },
  {
    "text": "You never know which one you're dealing with. It just this opaque system that is some combination of humans and machines.",
    "start": "3408480",
    "end": "3414839"
  },
  {
    "text": "I think that as an intermediary solution it can be quite helpful, and over time,",
    "start": "3414840",
    "end": "3420395"
  },
  {
    "text": "as you're generating data from the human interactions that's the human supervision, the algorithm itself can get better and",
    "start": "3420395",
    "end": "3427715"
  },
  {
    "text": "the people can be focused continually on the harder and harder tasks. Those are some of my thoughts there.",
    "start": "3427715",
    "end": "3434850"
  },
  {
    "text": ">> Excellent. Thank you very much. That is all the time we have for today's webinar.",
    "start": "3434850",
    "end": "3440775"
  },
  {
    "text": "Michael and everyone in the audience, thank you for joining us. If you found this presentation to be helpful in any way,",
    "start": "3440775",
    "end": "3448515"
  },
  {
    "text": "we encourage you to share the recording with your colleagues and we will send out an on-demand version of this with your friends or",
    "start": "3448515",
    "end": "3455490"
  },
  {
    "text": "family or whoever you think will find this information useful. Thank you for taking the time to join us today,",
    "start": "3455490",
    "end": "3461910"
  },
  {
    "text": "and have a great rest of your day.",
    "start": "3461910",
    "end": "3465579"
  }
]
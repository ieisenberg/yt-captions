[
  {
    "start": "0",
    "end": "18000"
  },
  {
    "start": "0",
    "end": "4468"
  },
  {
    "text": "CHRISTOPHER POTTS:\nWelcome, everyone.",
    "start": "4468",
    "end": "6010"
  },
  {
    "text": "This is part 4 in our series\non analysis methods in NLP.",
    "start": "6010",
    "end": "8613"
  },
  {
    "text": "We're going to be\ntalking about probing.",
    "start": "8613",
    "end": "10280"
  },
  {
    "text": "This is the first of the two\nstructural evaluation methods",
    "start": "10280",
    "end": "13110"
  },
  {
    "text": "that we're going to consider.",
    "start": "13110",
    "end": "14519"
  },
  {
    "text": "It's time to get really\nintrospective about what",
    "start": "14520",
    "end": "16980"
  },
  {
    "text": "our models are doing.",
    "start": "16980",
    "end": "19070"
  },
  {
    "start": "18000",
    "end": "138000"
  },
  {
    "text": "Here's an overview\nof the probing idea.",
    "start": "19070",
    "end": "21160"
  },
  {
    "text": "The core thing is that we're\ngoing to use supervised models,",
    "start": "21160",
    "end": "25150"
  },
  {
    "text": "those are the probe\nmodels, to determine",
    "start": "25150",
    "end": "27760"
  },
  {
    "text": "what's latently encoded in\nthe hidden representations",
    "start": "27760",
    "end": "31060"
  },
  {
    "text": "of our target models.",
    "start": "31060",
    "end": "33590"
  },
  {
    "text": "This is often applied in the\ncontext of BERTology, which",
    "start": "33590",
    "end": "36740"
  },
  {
    "text": "should be like, I have BERT\nas a pre-trained artifact",
    "start": "36740",
    "end": "39710"
  },
  {
    "text": "and I would like to\nunderstand the nature",
    "start": "39710",
    "end": "41750"
  },
  {
    "text": "of its hidden representations.",
    "start": "41750",
    "end": "43220"
  },
  {
    "text": "What do they latently encode?",
    "start": "43220",
    "end": "44990"
  },
  {
    "text": "And for that you might\nuse probe models.",
    "start": "44990",
    "end": "49350"
  },
  {
    "text": "Probing, as you will\nsee, can be a source",
    "start": "49350",
    "end": "51269"
  },
  {
    "text": "of really valuable and\ninteresting insights,",
    "start": "51270",
    "end": "53650"
  },
  {
    "text": "but we do need to proceed with\ncaution on two major issues",
    "start": "53650",
    "end": "57180"
  },
  {
    "text": "here.",
    "start": "57180",
    "end": "57850"
  },
  {
    "text": "First, a very\npowerful probe model",
    "start": "57850",
    "end": "60690"
  },
  {
    "text": "since it is a\nsupervised model might",
    "start": "60690",
    "end": "63059"
  },
  {
    "text": "lead you to see things\nthat aren't really",
    "start": "63060",
    "end": "65160"
  },
  {
    "text": "in your target model,\nbut rather just things",
    "start": "65160",
    "end": "67500"
  },
  {
    "text": "that your probe\nmodel has learned.",
    "start": "67500",
    "end": "69600"
  },
  {
    "text": "And you might, therefore,\noverdiagnose latent information",
    "start": "69600",
    "end": "73560"
  },
  {
    "text": "in your target model\nwhen, in fact, it's",
    "start": "73560",
    "end": "75689"
  },
  {
    "text": "all being stored in the probe.",
    "start": "75690",
    "end": "77090"
  },
  {
    "text": "And I'm going to offer you\na technique for navigating",
    "start": "77090",
    "end": "79740"
  },
  {
    "text": "around that issue.",
    "start": "79740",
    "end": "81630"
  },
  {
    "text": "And the second one is that\nprobes cannot tell us about",
    "start": "81630",
    "end": "84360"
  },
  {
    "text": "whether the information that\nwe identify has any causal",
    "start": "84360",
    "end": "87930"
  },
  {
    "text": "relationship with the\ntarget model's behavior.",
    "start": "87930",
    "end": "90090"
  },
  {
    "text": "It will be very tempting\nfor you to say, Oh,",
    "start": "90090",
    "end": "92460"
  },
  {
    "text": "I have discovered that this\nrepresentation layer includes",
    "start": "92460",
    "end": "96600"
  },
  {
    "text": "part of speech information.",
    "start": "96600",
    "end": "98253"
  },
  {
    "text": "And you might therefore conclude\nthat part of speech information",
    "start": "98253",
    "end": "100920"
  },
  {
    "text": "is important for whatever\ntask you have set,",
    "start": "100920",
    "end": "103680"
  },
  {
    "text": "but we can't actually\nmake that inference.",
    "start": "103680",
    "end": "106020"
  },
  {
    "text": "It could be that the part\nof speech information",
    "start": "106020",
    "end": "108240"
  },
  {
    "text": "is simply latently\nencoded, but not actually",
    "start": "108240",
    "end": "111090"
  },
  {
    "text": "especially relevant to your\nmodel's input/output behavior.",
    "start": "111090",
    "end": "117310"
  },
  {
    "text": "Final section of\nthe slide show, I'm",
    "start": "117310",
    "end": "118840"
  },
  {
    "text": "going to just talk briefly\nabout unsupervised probes, which",
    "start": "118840",
    "end": "122020"
  },
  {
    "text": "seek to address this first\nproblem here that the probe",
    "start": "122020",
    "end": "124493"
  },
  {
    "text": "model might actually\nbe the thing that's",
    "start": "124493",
    "end": "126159"
  },
  {
    "text": "encoding all of this\ninformation that we",
    "start": "126160",
    "end": "128380"
  },
  {
    "text": "claimed to have discovered.",
    "start": "128380",
    "end": "130179"
  },
  {
    "text": "And then when we talk about\nfuture attribution methods,",
    "start": "130180",
    "end": "133150"
  },
  {
    "text": "we'll get closer to\nbeing able to address",
    "start": "133150",
    "end": "135159"
  },
  {
    "text": "some of these causal questions.",
    "start": "135160",
    "end": "138210"
  },
  {
    "start": "138000",
    "end": "268000"
  },
  {
    "text": "Let's begin with the\ncore method for probing.",
    "start": "138210",
    "end": "140550"
  },
  {
    "text": "And just because this is a\ntypical framing of these ideas,",
    "start": "140550",
    "end": "143850"
  },
  {
    "text": "I've got depicted here what\nyou might think of as a,",
    "start": "143850",
    "end": "146040"
  },
  {
    "text": "kind of, generic\ntransformer-based model, where",
    "start": "146040",
    "end": "148319"
  },
  {
    "text": "we have three layers\nwith all of these blocks.",
    "start": "148320",
    "end": "151320"
  },
  {
    "text": "These maybe are the\noutput representations",
    "start": "151320",
    "end": "153360"
  },
  {
    "text": "from each of the\ntransformer blocks.",
    "start": "153360",
    "end": "155310"
  },
  {
    "text": "And you can see that I've got an\ninput sequence coming in here.",
    "start": "155310",
    "end": "158610"
  },
  {
    "text": "And the idea would\nbe that we could",
    "start": "158610",
    "end": "160260"
  },
  {
    "text": "pick some hidden\nrepresentation in this model,",
    "start": "160260",
    "end": "162480"
  },
  {
    "text": "like this middle one, h here.",
    "start": "162480",
    "end": "164310"
  },
  {
    "text": "And decide that we're going\nto fit a small linear model",
    "start": "164310",
    "end": "167730"
  },
  {
    "text": "presumably on that\nhidden representation,",
    "start": "167730",
    "end": "170459"
  },
  {
    "text": "and see whether\nwe can figure out",
    "start": "170460",
    "end": "172380"
  },
  {
    "text": "whether that\nrepresentation encodes",
    "start": "172380",
    "end": "174180"
  },
  {
    "text": "some information about some\ntask that we care about.",
    "start": "174180",
    "end": "177217"
  },
  {
    "text": "So for example, if you\nwanted to figure out",
    "start": "177218",
    "end": "179010"
  },
  {
    "text": "whether sentiment or\nlexical entailment",
    "start": "179010",
    "end": "181379"
  },
  {
    "text": "was encoded at that point,\nyou'd need a labeled data set",
    "start": "181380",
    "end": "184140"
  },
  {
    "text": "for sentiment or entailment.",
    "start": "184140",
    "end": "186120"
  },
  {
    "text": "And then you would\nfit the probe model",
    "start": "186120",
    "end": "187830"
  },
  {
    "text": "on this representation\nand use that",
    "start": "187830",
    "end": "189480"
  },
  {
    "text": "to determine the extent to which\nthat information is encoded",
    "start": "189480",
    "end": "192930"
  },
  {
    "text": "there.",
    "start": "192930",
    "end": "194159"
  },
  {
    "text": "This depiction is a\nlittle bit poetical.",
    "start": "194160",
    "end": "195862"
  },
  {
    "text": "So it's worth just walking\nthrough mechanically",
    "start": "195862",
    "end": "197819"
  },
  {
    "text": "what you'd actually be doing.",
    "start": "197820",
    "end": "199350"
  },
  {
    "text": "You would use this BERT model\nand process different examples,",
    "start": "199350",
    "end": "202650"
  },
  {
    "text": "like for the sequence here.",
    "start": "202650",
    "end": "204209"
  },
  {
    "text": "And get an output\nrepresentation,",
    "start": "204210",
    "end": "206070"
  },
  {
    "text": "which should be paired\nwith some task label.",
    "start": "206070",
    "end": "208680"
  },
  {
    "text": "And you would repeatedly do\nthat for different inputs.",
    "start": "208680",
    "end": "211260"
  },
  {
    "text": "You're essentially\nusing this BERT model",
    "start": "211260",
    "end": "214019"
  },
  {
    "text": "as an engine for\ncreating representations",
    "start": "214020",
    "end": "216660"
  },
  {
    "text": "that will become your\nfeature representation matrix",
    "start": "216660",
    "end": "219210"
  },
  {
    "text": "x paired with your labels y.",
    "start": "219210",
    "end": "221910"
  },
  {
    "text": "And it is this\nmodel that will be",
    "start": "221910",
    "end": "223590"
  },
  {
    "text": "the basis for your linear probe\nmodel, this small linear model",
    "start": "223590",
    "end": "227129"
  },
  {
    "text": "as I've identified in here.",
    "start": "227130",
    "end": "229110"
  },
  {
    "text": "So you're kind of\nusing BERT as an engine",
    "start": "229110",
    "end": "230820"
  },
  {
    "text": "to create a data\nset that is then",
    "start": "230820",
    "end": "232740"
  },
  {
    "text": "the input to a supervised\nlearning problem.",
    "start": "232740",
    "end": "235063"
  },
  {
    "text": "Another perspective\nwould be that you're",
    "start": "235063",
    "end": "236730"
  },
  {
    "text": "kind of using frozen BERT\nparameters in this case,",
    "start": "236730",
    "end": "240480"
  },
  {
    "text": "and fitting a model\non top of them.",
    "start": "240480",
    "end": "242260"
  },
  {
    "text": "It's just that instead of\npicking an output point,",
    "start": "242260",
    "end": "244830"
  },
  {
    "text": "you've picked possibly one of\nthe internal representations.",
    "start": "244830",
    "end": "249728"
  },
  {
    "text": "And this is very general.",
    "start": "249728",
    "end": "250770"
  },
  {
    "text": "And in fact, most\noften, when you",
    "start": "250770",
    "end": "252877"
  },
  {
    "text": "read without quotes\nin the literature,",
    "start": "252877",
    "end": "254459"
  },
  {
    "text": "they're actually\nsequence problems",
    "start": "254460",
    "end": "255960"
  },
  {
    "text": "like part of speech tagging\nor named entity recognition.",
    "start": "255960",
    "end": "259528"
  },
  {
    "text": "And therefore, you might\nuse an entire layer or even",
    "start": "259529",
    "end": "262018"
  },
  {
    "text": "a set of layers as the\nbasis for your probe model.",
    "start": "262019",
    "end": "267130"
  },
  {
    "text": "Now you can hear in\nmy description there,",
    "start": "267130",
    "end": "269470"
  },
  {
    "start": "268000",
    "end": "354000"
  },
  {
    "text": "that there is a interesting\njudgment call that you're",
    "start": "269470",
    "end": "271990"
  },
  {
    "text": "making about whether you are\nprobing or simply learning",
    "start": "271990",
    "end": "275229"
  },
  {
    "text": "a new model, right?",
    "start": "275230",
    "end": "276190"
  },
  {
    "text": "Probes, in the sense that\nI just presented them,",
    "start": "276190",
    "end": "279130"
  },
  {
    "text": "are supervised\nmodels whose inputs",
    "start": "279130",
    "end": "281200"
  },
  {
    "text": "are frozen parameters of the\nmodels that we're probing,",
    "start": "281200",
    "end": "283810"
  },
  {
    "text": "our target models, right?",
    "start": "283810",
    "end": "285520"
  },
  {
    "text": "This is hard to\ndistinguish from simply",
    "start": "285520",
    "end": "287470"
  },
  {
    "text": "fitting a supervised\nmodel as usual",
    "start": "287470",
    "end": "289720"
  },
  {
    "text": "with some particular\nchoice of featurization.",
    "start": "289720",
    "end": "293590"
  },
  {
    "text": "As a result of this,\nit is essentially",
    "start": "293590",
    "end": "296020"
  },
  {
    "text": "a foregone conclusion\nthat at least some",
    "start": "296020",
    "end": "298060"
  },
  {
    "text": "of the information that\nwe identify with our probe",
    "start": "298060",
    "end": "301510"
  },
  {
    "text": "is actually stored in the\nprobe model parameters",
    "start": "301510",
    "end": "303920"
  },
  {
    "text": "and it's just that we provided\nuseful input features that",
    "start": "303920",
    "end": "307240"
  },
  {
    "text": "allow this probe\nto be successful.",
    "start": "307240",
    "end": "309410"
  },
  {
    "text": "And that's the sense in\nwhich the inputs are latently",
    "start": "309410",
    "end": "312190"
  },
  {
    "text": "encoding this information.",
    "start": "312190",
    "end": "313590"
  },
  {
    "text": "But with the probe,\nwe have not determined",
    "start": "313590",
    "end": "315340"
  },
  {
    "text": "that it is truly latently\nthere, but rather",
    "start": "315340",
    "end": "317590"
  },
  {
    "text": "that it's a stepping-- a\nstepping stone toward a model",
    "start": "317590",
    "end": "320620"
  },
  {
    "text": "that could be\nsuccessful at this as",
    "start": "320620",
    "end": "322540"
  },
  {
    "text": "conceived of as a\nsupervised learning task.",
    "start": "322540",
    "end": "325040"
  },
  {
    "text": "So those are important\ndistinctions to keep in mind.",
    "start": "325040",
    "end": "327460"
  },
  {
    "text": "As a result of this,\nmore powerful probes,",
    "start": "327460",
    "end": "330460"
  },
  {
    "text": "like deep neural networks,\nmight find more information",
    "start": "330460",
    "end": "334330"
  },
  {
    "text": "than simple linear models.",
    "start": "334330",
    "end": "335590"
  },
  {
    "text": "But that's not because\nthey're able to tease out",
    "start": "335590",
    "end": "337960"
  },
  {
    "text": "more information from the\nrepresentations themselves,",
    "start": "337960",
    "end": "341479"
  },
  {
    "text": "but rather because\nthe probe model now",
    "start": "341480",
    "end": "343660"
  },
  {
    "text": "has so much more capacity\nfor storing information",
    "start": "343660",
    "end": "346840"
  },
  {
    "text": "about the task that\nyou're probing for.",
    "start": "346840",
    "end": "349360"
  },
  {
    "text": "So there are a bunch of\ndifferent judgment calls here.",
    "start": "349360",
    "end": "351610"
  },
  {
    "text": "And that's difficult. But\na very productive entry",
    "start": "351610",
    "end": "354639"
  },
  {
    "start": "354000",
    "end": "500000"
  },
  {
    "text": "into this space is this\nreally lovely paper",
    "start": "354640",
    "end": "356560"
  },
  {
    "text": "from Hewitt and\nLiang 2019, where",
    "start": "356560",
    "end": "358540"
  },
  {
    "text": "they introduce the\nnotion of a control task",
    "start": "358540",
    "end": "361300"
  },
  {
    "text": "and the corresponding\nmetric of probe selectivity.",
    "start": "361300",
    "end": "364419"
  },
  {
    "text": "So here's the idea.",
    "start": "364420",
    "end": "365320"
  },
  {
    "text": "A control task will\nbe some random task",
    "start": "365320",
    "end": "368560"
  },
  {
    "text": "with the same input/output\nstructure as the target task",
    "start": "368560",
    "end": "371830"
  },
  {
    "text": "that we want to use\nfor our probing.",
    "start": "371830",
    "end": "374259"
  },
  {
    "text": "Like for example, for\nword-sense classification,",
    "start": "374260",
    "end": "376880"
  },
  {
    "text": "you might have words assigned\nrandom fixed words senses",
    "start": "376880",
    "end": "380020"
  },
  {
    "text": "independent of their context.",
    "start": "380020",
    "end": "381970"
  },
  {
    "text": "Or for part of speech\ntagging, instead",
    "start": "381970",
    "end": "383560"
  },
  {
    "text": "of using the actual\npart of speech tags,",
    "start": "383560",
    "end": "385570"
  },
  {
    "text": "you might randomly\nassigned words",
    "start": "385570",
    "end": "387700"
  },
  {
    "text": "to fixed tags from\nthe same tag space.",
    "start": "387700",
    "end": "391060"
  },
  {
    "text": "Or for parsing, it gets a\nlittle bit more nuanced,",
    "start": "391060",
    "end": "393700"
  },
  {
    "text": "but you might have some\nedge assignment strategies",
    "start": "393700",
    "end": "396670"
  },
  {
    "text": "that you use semirandomly to\nlink different pairs of words",
    "start": "396670",
    "end": "400540"
  },
  {
    "text": "into a kind of pseudo-parse.",
    "start": "400540",
    "end": "402650"
  },
  {
    "text": "And that would serve\nas a control task",
    "start": "402650",
    "end": "404320"
  },
  {
    "text": "for trying to surface latent\nactual parsing information.",
    "start": "404320",
    "end": "408190"
  },
  {
    "text": "So those are control tasks.",
    "start": "408190",
    "end": "409450"
  },
  {
    "text": "And then selectivity is\nsimply the difference",
    "start": "409450",
    "end": "412540"
  },
  {
    "text": "between your probe\nperformance on the task",
    "start": "412540",
    "end": "415180"
  },
  {
    "text": "and your identical probe model\nstructure on these control",
    "start": "415180",
    "end": "418990"
  },
  {
    "text": "tasks.",
    "start": "418990",
    "end": "420580"
  },
  {
    "text": "And Hewitt and Liang used this\nto tease out what, I think,",
    "start": "420580",
    "end": "423430"
  },
  {
    "text": "is a pretty clear\nintuition, which",
    "start": "423430",
    "end": "425229"
  },
  {
    "text": "is that as you get\nmore powerful probes,",
    "start": "425230",
    "end": "427570"
  },
  {
    "text": "they simply become\nless selective.",
    "start": "427570",
    "end": "429460"
  },
  {
    "text": "So along the x-axis here,\nwe have MLP hidden units.",
    "start": "429460",
    "end": "434090"
  },
  {
    "text": "So we have model complexity\nfrom left to right,",
    "start": "434090",
    "end": "436300"
  },
  {
    "text": "where we have very\ncomplicated, powerful models",
    "start": "436300",
    "end": "438639"
  },
  {
    "text": "at the right-hand side.",
    "start": "438640",
    "end": "440140"
  },
  {
    "text": "And here we have accuracy.",
    "start": "440140",
    "end": "442180"
  },
  {
    "text": "And we're measuring\nour control task in red",
    "start": "442180",
    "end": "445389"
  },
  {
    "text": "and our actual probe task\nin this light blue here.",
    "start": "445390",
    "end": "448720"
  },
  {
    "text": "And selectivity is the\ndifference between those two.",
    "start": "448720",
    "end": "452060"
  },
  {
    "text": "So you can see, for example,\nthat the very weak models,",
    "start": "452060",
    "end": "455200"
  },
  {
    "text": "the ones with two hidden units\nhave very high selectivity.",
    "start": "455200",
    "end": "459190"
  },
  {
    "text": "Whereas by the time I have\nthis very powerful NLP",
    "start": "459190",
    "end": "462220"
  },
  {
    "text": "with lots of hidden\nunits, selectivity",
    "start": "462220",
    "end": "464350"
  },
  {
    "text": "has gone almost to 0.",
    "start": "464350",
    "end": "465700"
  },
  {
    "text": "And it's very hard to say that\nyou've uncovered any latent",
    "start": "465700",
    "end": "468940"
  },
  {
    "text": "information.",
    "start": "468940",
    "end": "469570"
  },
  {
    "text": "Because even the control task\nis fully solvable with a model",
    "start": "469570",
    "end": "474640"
  },
  {
    "text": "that has this much capacity.",
    "start": "474640",
    "end": "476952"
  },
  {
    "text": "So I think what this\nis pushing us toward",
    "start": "476952",
    "end": "478660"
  },
  {
    "text": "is always having control\ntasks as part of the picture",
    "start": "478660",
    "end": "482380"
  },
  {
    "text": "and always reporting\nselectivity so",
    "start": "482380",
    "end": "484240"
  },
  {
    "text": "that we can control for the\ncomplexity of the probe model",
    "start": "484240",
    "end": "487810"
  },
  {
    "text": "itself.",
    "start": "487810",
    "end": "489620"
  },
  {
    "text": "That's an important and\neasy, practical step",
    "start": "489620",
    "end": "491590"
  },
  {
    "text": "that will give you a clearer\npicture of what you've actually",
    "start": "491590",
    "end": "494530"
  },
  {
    "text": "surfaced with your probe.",
    "start": "494530",
    "end": "497440"
  },
  {
    "text": "That's the first issue.",
    "start": "497440",
    "end": "498450"
  },
  {
    "text": "The second issue is just\nsomething that you should keep",
    "start": "498450",
    "end": "500742"
  },
  {
    "start": "500000",
    "end": "623000"
  },
  {
    "text": "in mind as a theoretical\nfact about probing,",
    "start": "500742",
    "end": "503150"
  },
  {
    "text": "which is that it is\nfundamentally limited",
    "start": "503150",
    "end": "505030"
  },
  {
    "text": "in the sense that it cannot tell\nyou that the information you",
    "start": "505030",
    "end": "508389"
  },
  {
    "text": "discover has any causal impact\non the model's input/output",
    "start": "508390",
    "end": "511720"
  },
  {
    "text": "behavior.",
    "start": "511720",
    "end": "512463"
  },
  {
    "text": "To illustrate that,\nI'm just going",
    "start": "512463",
    "end": "513880"
  },
  {
    "text": "to show you a simple example\nthat kind of proves this.",
    "start": "513880",
    "end": "517240"
  },
  {
    "text": "So imagine over\nhere on the left,",
    "start": "517240",
    "end": "518620"
  },
  {
    "text": "I have a simple model that's\ngoing to take in three integers",
    "start": "518620",
    "end": "521770"
  },
  {
    "text": "and sum them.",
    "start": "521770",
    "end": "522760"
  },
  {
    "text": "So the output here will be\nthe sum of three integers.",
    "start": "522760",
    "end": "525250"
  },
  {
    "text": "Like if I put in 1, 2,\n3, it will output 6.",
    "start": "525250",
    "end": "528370"
  },
  {
    "text": "And it does that by representing\neach one of those integers",
    "start": "528370",
    "end": "531190"
  },
  {
    "text": "as the single-dimensional vector\nthat just is that integer.",
    "start": "531190",
    "end": "535090"
  },
  {
    "text": "And then we have a whole\nbunch of transformer",
    "start": "535090",
    "end": "536980"
  },
  {
    "text": "like model parameters,\ndense connections here",
    "start": "536980",
    "end": "539529"
  },
  {
    "text": "that will lead us finally\nto the output layer.",
    "start": "539530",
    "end": "543130"
  },
  {
    "text": "So you can easily imagine that\nyou probe this position L1 here",
    "start": "543130",
    "end": "546570"
  },
  {
    "text": "and you find that it computes x\nplus y, which might be starting",
    "start": "546570",
    "end": "551160"
  },
  {
    "text": "to reveal for you that\nthere's some kind of tree",
    "start": "551160",
    "end": "553290"
  },
  {
    "text": "structure to this model\neven though it was densely",
    "start": "553290",
    "end": "555420"
  },
  {
    "text": "connected.",
    "start": "555420",
    "end": "556060"
  },
  {
    "text": "It has learned a structured\nsolution to the problem.",
    "start": "556060",
    "end": "558870"
  },
  {
    "text": "And you might probe L2 and\nfind that it computes z.",
    "start": "558870",
    "end": "561779"
  },
  {
    "text": "And that would really\nlead you to think",
    "start": "561780",
    "end": "563667"
  },
  {
    "text": "that you've got a, kind\nof, interesting tree",
    "start": "563667",
    "end": "565500"
  },
  {
    "text": "structure with constituents\nfor this addition problem.",
    "start": "565500",
    "end": "569640"
  },
  {
    "text": "And that's certainly suggestive.",
    "start": "569640",
    "end": "571620"
  },
  {
    "text": "However, here is an\nexample of a model that",
    "start": "571620",
    "end": "573900"
  },
  {
    "text": "shows that neither L1 nor L2 has\nanything to do with the model's",
    "start": "573900",
    "end": "578490"
  },
  {
    "text": "output predictions.",
    "start": "578490",
    "end": "579720"
  },
  {
    "text": "It is entirely that\nmiddle state that",
    "start": "579720",
    "end": "582240"
  },
  {
    "text": "tells the complete\nstory about the output.",
    "start": "582240",
    "end": "585029"
  },
  {
    "text": "I'll leave you to work through\nthe details if you choose to,",
    "start": "585030",
    "end": "587530"
  },
  {
    "text": "but a shortcut\nway to see that is",
    "start": "587530",
    "end": "589500"
  },
  {
    "text": "that the final parameters\nthat take us from these output",
    "start": "589500",
    "end": "592230"
  },
  {
    "text": "representations\nto the predictions",
    "start": "592230",
    "end": "594300"
  },
  {
    "text": "have zeroed out the first\nand third positions,",
    "start": "594300",
    "end": "597839"
  },
  {
    "text": "leaving only the\nsecond one as having",
    "start": "597840",
    "end": "599730"
  },
  {
    "text": "any kind of causal efficacy.",
    "start": "599730",
    "end": "602490"
  },
  {
    "text": "Even though in this\nmodel, if you probe,",
    "start": "602490",
    "end": "604950"
  },
  {
    "text": "you do indeed find that it\nlooks like those representations",
    "start": "604950",
    "end": "608280"
  },
  {
    "text": "perfectly encode these\ntwo pieces of information.",
    "start": "608280",
    "end": "611250"
  },
  {
    "text": "That's a dramatic and\nclear, simple illustration",
    "start": "611250",
    "end": "614550"
  },
  {
    "text": "of how a probe\ncould get divorced",
    "start": "614550",
    "end": "616410"
  },
  {
    "text": "from the actual causal\nbehavior of the model.",
    "start": "616410",
    "end": "619800"
  },
  {
    "text": "Again, something that's\nworth keeping in mind.",
    "start": "619800",
    "end": "623209"
  },
  {
    "start": "623000",
    "end": "689000"
  },
  {
    "text": "And finally, to close\nthis out, of course,",
    "start": "623210",
    "end": "624960"
  },
  {
    "text": "for that first problem about\ndistinguishing between probe",
    "start": "624960",
    "end": "628590"
  },
  {
    "text": "capacity and actually\nlatently encoded",
    "start": "628590",
    "end": "631440"
  },
  {
    "text": "information, one\nresponse to that that's",
    "start": "631440",
    "end": "634260"
  },
  {
    "text": "developing in the\nliterature now is",
    "start": "634260",
    "end": "635940"
  },
  {
    "text": "to develop unsupervised probes.",
    "start": "635940",
    "end": "638250"
  },
  {
    "text": "These would be models\nlike these that",
    "start": "638250",
    "end": "640380"
  },
  {
    "text": "seek to find in actual\nfacts about the model",
    "start": "640380",
    "end": "644310"
  },
  {
    "text": "with no additional supervision,\nthe latent information",
    "start": "644310",
    "end": "647490"
  },
  {
    "text": "that we hope to find.",
    "start": "647490",
    "end": "648959"
  },
  {
    "text": "And this would come\nfrom simply doing",
    "start": "648960",
    "end": "651120"
  },
  {
    "text": "linear transformations\nof the parameters",
    "start": "651120",
    "end": "653400"
  },
  {
    "text": "and measuring distance\nbetween parameters",
    "start": "653400",
    "end": "655740"
  },
  {
    "text": "as a way of getting a sense\nfor what's actually there",
    "start": "655740",
    "end": "658470"
  },
  {
    "text": "without the\ncomplications that come",
    "start": "658470",
    "end": "660389"
  },
  {
    "text": "from having this additional\nsupervised probe model.",
    "start": "660390",
    "end": "664060"
  },
  {
    "text": "And finally, for much more\ninformation about probes,",
    "start": "664060",
    "end": "666540"
  },
  {
    "text": "and what we think we've\nlearned from them,",
    "start": "666540",
    "end": "668759"
  },
  {
    "text": "and what they can\ntell us, I encourage",
    "start": "668760",
    "end": "670500"
  },
  {
    "text": "you to check out\nthis paper by Rogers",
    "start": "670500",
    "end": "672750"
  },
  {
    "text": "et al, a primer on BERTology.",
    "start": "672750",
    "end": "674990"
  },
  {
    "text": "It has a large and\ninteresting subsection",
    "start": "674990",
    "end": "677730"
  },
  {
    "text": "entirely devoted to what\nprobes have told us.",
    "start": "677730",
    "end": "680430"
  },
  {
    "text": "Certainly worth a look, and a\ngreat overview of the space.",
    "start": "680430",
    "end": "684130"
  },
  {
    "start": "684130",
    "end": "688491"
  }
]
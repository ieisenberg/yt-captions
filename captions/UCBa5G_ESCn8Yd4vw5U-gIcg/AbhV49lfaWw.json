[
  {
    "text": "So today, uh, the- the plan is to cover bias-variance trade off and",
    "start": "4550",
    "end": "12284"
  },
  {
    "text": "the role played by regularization and the role played by the hypothesis class in bias-variance trade off.",
    "start": "12284",
    "end": "19635"
  },
  {
    "text": "So, uh, in the last class, we spoke about the concepts of bias and variance,",
    "start": "19635",
    "end": "26535"
  },
  {
    "text": "and we probably briefly mentioned that there is a trade off between the two, some kind of a trade off. And today we will see two- two kind of, uh,",
    "start": "26535",
    "end": "35700"
  },
  {
    "text": "more concrete ways of how this trade off comes into picture, um, in practice.",
    "start": "35700",
    "end": "41430"
  },
  {
    "text": "And, uh, the second part, the role played by the hyp- hypothesis class is actually, you know,",
    "start": "41430",
    "end": "47765"
  },
  {
    "text": "if you're interested in- in machine learning research, it forms a good, uh, entry point into statistical learning theory.",
    "start": "47765",
    "end": "54335"
  },
  {
    "text": "However, the kind of, uh, the- the big picture that we want to take away at the end of the class is probably,",
    "start": "54335",
    "end": "63300"
  },
  {
    "text": "uh, extremely important if you want to be a machine learning practitioner, right? So, uh, in order to build good predictive models,",
    "start": "63300",
    "end": "70295"
  },
  {
    "text": "it's very important that you understand the role of bias and variance and how you- how you, uh,",
    "start": "70295",
    "end": "75550"
  },
  {
    "text": "handled the two, uh, the two evils so to speak; uh, both bias and variance are bad and you know,",
    "start": "75550",
    "end": "81290"
  },
  {
    "text": "how do you balance between the two? That's at the heart of, you know, uh, successfully building good machine learning models in practice.",
    "start": "81290",
    "end": "87515"
  },
  {
    "text": "So even though some of it is theoretical, there are very good takeaway messages,",
    "start": "87515",
    "end": "92810"
  },
  {
    "text": "even if you want to just apply machine learning in practice. [NOISE] Before we go into today's topics,",
    "start": "92810",
    "end": "98135"
  },
  {
    "text": "a quick recap of, uh, what we covered in the last lecture, or at least the parts that we covered in the last lecture that are relevant for today.",
    "start": "98135",
    "end": "105244"
  },
  {
    "text": "So we saw the concept of bias and variance in classical statistics. Classical statistics, we are interested in",
    "start": "105245",
    "end": "112445"
  },
  {
    "text": "constructing an estimator for our parameter Theta. And that, um, the estimator that we construct,",
    "start": "112445",
    "end": "120439"
  },
  {
    "text": "uh, we call it Theta hat n; where n is the number of examples that were used in your training set, so to speak.",
    "start": "120440",
    "end": "128209"
  },
  {
    "text": "And what we saw was Theta hat n is a random variable because it depends on,",
    "start": "128210",
    "end": "136010"
  },
  {
    "text": "uh, the noise and the data that was sampled from which the model was fit. And it has- because it's a random variable,",
    "start": "136010",
    "end": "143300"
  },
  {
    "text": "it has an associated probability distribution. And that distribution is called the Sampling distribution. And the bias and variance are directly related to",
    "start": "143300",
    "end": "152240"
  },
  {
    "text": "the sampling distribution of this estimator of Theta hat n, righ t? So the centered mean of- of,",
    "start": "152240",
    "end": "161060"
  },
  {
    "text": "uh, of the sampling distribution or the center first moment is called the bias. And the variance or the covariance of the estimator is called the variance, right?",
    "start": "161060",
    "end": "171575"
  },
  {
    "text": "And, um, supposing, um, in- in the parameter space, theta- theta star,",
    "start": "171575",
    "end": "177575"
  },
  {
    "text": "which is indicated by this, uh, by this black square, was the true parameter from which data is being generated in the world.",
    "start": "177575",
    "end": "185045"
  },
  {
    "text": "And we collect the sample of size n, a random sample of size n, and we run it through our estimator and we get an estimate,",
    "start": "185045",
    "end": "193805"
  },
  {
    "text": "a point estimate for theta, and supposing we plot it. And we repeat that over and over where we're",
    "start": "193805",
    "end": "199625"
  },
  {
    "text": "resampling data from the true data generating distribution, though in practice that is hard, but, uh,",
    "start": "199625",
    "end": "205955"
  },
  {
    "text": "as a mental model, imagine you're gathering a new set of data. You collect new data and you run it through your estimator,",
    "start": "205955",
    "end": "212720"
  },
  {
    "text": "you get another point estimate, you plot it, and you will see that they end up being samples from the sampling distribution, right?",
    "start": "212720",
    "end": "220665"
  },
  {
    "text": "And- and this the- the sampling distribution will be centered around some point here,",
    "start": "220665",
    "end": "226069"
  },
  {
    "text": "uh, calling it, uh, you know, indicating it by a triangle. And this is the mean of the sampling distribution,",
    "start": "226070",
    "end": "235528"
  },
  {
    "text": "and this gap is called the bias of the estimator, right? And the variance of the estimator is how wide the sampling distribution,",
    "start": "235529",
    "end": "244760"
  },
  {
    "text": "um, how, what's- what's the variance of the sampling distribution. That's the- the variance of the sampling,",
    "start": "244760",
    "end": "249800"
  },
  {
    "text": "uh, of the, um, estimator. There are very, uh- there is closely concept, uh,",
    "start": "249800",
    "end": "256889"
  },
  {
    "text": "closely related concept of bias and variance in prediction problems in machine learning.",
    "start": "256890",
    "end": "262380"
  },
  {
    "text": "Over here we are interested in prediction, uh, whereas over here we are interested in statistical inference over the parameters.",
    "start": "262380",
    "end": "269620"
  },
  {
    "text": "Here we are interested in making predictions on unseen data, right? And over here, similarly, let's, um,",
    "start": "269620",
    "end": "278235"
  },
  {
    "text": "this is the- the x, um, and this is y, and we get samples xy from- from,",
    "start": "278235",
    "end": "284985"
  },
  {
    "text": "um, from the data generating distribution. Now supposing the true relation between x,",
    "start": "284985",
    "end": "290560"
  },
  {
    "text": "y, which we, uh, define as y- expectation of y given x is this dotted line.",
    "start": "290560",
    "end": "296740"
  },
  {
    "text": "So this dotted line over here is f equals expectation of y given x.",
    "start": "296740",
    "end": "305655"
  },
  {
    "text": "And because of this definition, we get y equals f of x plus epsilon,",
    "start": "305655",
    "end": "311090"
  },
  {
    "text": "where epsilon is some, uh, zero-mean noise. And here what we see is though this is the true function,",
    "start": "311090",
    "end": "321300"
  },
  {
    "text": "we take some training data of size n and construct an estimator. We call it f hat n. And using f hat n,",
    "start": "321300",
    "end": "329349"
  },
  {
    "text": "we make a prediction on a new test example, x star, right? And the prediction may be anywhere on this line in gen- in principle,",
    "start": "329350",
    "end": "339324"
  },
  {
    "text": "it could be anywhere, uh, the value of, um, f hat n of x star could be anywhere.",
    "start": "339325",
    "end": "345264"
  },
  {
    "text": "And what we see is, if we just like before repeat this sampling, uh,",
    "start": "345265",
    "end": "351445"
  },
  {
    "text": "process where we collect a new set of n examples, construct a new model using the new set,",
    "start": "351445",
    "end": "356870"
  },
  {
    "text": "and make a prediction on the same x star using the new estimator. It's gonna be a different prediction,",
    "start": "356870",
    "end": "363365"
  },
  {
    "text": "and the set of all those predictions is gonna follow some distribution. So the distribution that is, um,",
    "start": "363365",
    "end": "370460"
  },
  {
    "text": "having a thick line is something similar to this distribution, except it's in the prediction setting, right?",
    "start": "370460",
    "end": "377675"
  },
  {
    "text": "And again, this distribution has a mean, which, you know, just like before, I'm using, uh,",
    "start": "377675",
    "end": "384900"
  },
  {
    "text": "a triangle to indicate the- indicate the mean of, uh, the f hat n. And this- this-",
    "start": "384900",
    "end": "394485"
  },
  {
    "text": "this triangle can in general not be equal to the- the point at which the true function makes,",
    "start": "394485",
    "end": "401345"
  },
  {
    "text": "uh, its prediction, right? And this difference is called",
    "start": "401345",
    "end": "407770"
  },
  {
    "text": "the bias of f hat n. Just the way this difference was the bias of the,",
    "start": "407770",
    "end": "414710"
  },
  {
    "text": "uh, theta hat estimator, this difference between the square and the triangle is the bias of, uh,",
    "start": "414710",
    "end": "422275"
  },
  {
    "text": "bias of- of f hat n. It is the gap between f hat n at x star and f at x star,",
    "start": "422275",
    "end": "429755"
  },
  {
    "text": "f hat n at x star, and f at x star. And similarly, the variance is just the variance of this distribution.",
    "start": "429755",
    "end": "439025"
  },
  {
    "text": "The variance of f hat n is just the variance of f hat n, right? However, uh, the- the, uh,",
    "start": "439025",
    "end": "446970"
  },
  {
    "text": "bias-variance decomposition of the squared error loss has a third component,",
    "start": "446970",
    "end": "452420"
  },
  {
    "text": "which- which you call as irreducible error. [NOISE] So the dotted distribution",
    "start": "452420",
    "end": "462110"
  },
  {
    "text": "that's indicated here is the distribution of y given x. So this is y given x.",
    "start": "462110",
    "end": "468515"
  },
  {
    "text": "And it is from this distribution that we make the observations y, right?",
    "start": "468515",
    "end": "474020"
  },
  {
    "text": "So if we were to sample an example from the data-generating process at x equals x star,",
    "start": "474020",
    "end": "480110"
  },
  {
    "text": "then the corresponding y will come from this distribution, right? And the- the expected error that we would make using f hat n on a new example,",
    "start": "480110",
    "end": "493085"
  },
  {
    "text": "y star, x star, can be, uh- was written as- [NOISE] so",
    "start": "493085",
    "end": "500240"
  },
  {
    "text": "mean squared error of f hat n is equal to the expectation",
    "start": "500240",
    "end": "508210"
  },
  {
    "text": "of y star minus f hat n [NOISE] x star, right?",
    "start": "508210",
    "end": "516834"
  },
  {
    "text": "So we use some training set, constructed our model, made a prediction on x star and it was a sample from the thick line distribution, right?",
    "start": "516835",
    "end": "528850"
  },
  {
    "text": "And it's a- it's a random sample because there is noise in the training set- set that we used.",
    "start": "528850",
    "end": "534175"
  },
  {
    "text": "If you use the same training set, then we always make the same prediction, obviously. So suppose the- the predicted f hat n was,",
    "start": "534175",
    "end": "542380"
  },
  {
    "text": "let's say was over here. Similarly, the true label also has some noise in it, right?",
    "start": "542380",
    "end": "548950"
  },
  {
    "text": "Because it's- it's sampled from the data generating distribution and let's say the observed y star was here.",
    "start": "548950",
    "end": "555385"
  },
  {
    "text": "So this is, uh, y star, right? And now this gap is what we are trying to",
    "start": "555385",
    "end": "561850"
  },
  {
    "text": "decompose from y star to f hat n x star, right?",
    "start": "561850",
    "end": "569649"
  },
  {
    "text": "And this can now be broken down again into three parts. First, we, uh, uh, what we have spoken about.",
    "start": "569650",
    "end": "576550"
  },
  {
    "text": "So this can be broken down into three parts. One part is the gap from the black square,",
    "start": "576550",
    "end": "582704"
  },
  {
    "text": "that is like the true function till y star, right? That we call as irreducible error.",
    "start": "582705",
    "end": "588630"
  },
  {
    "text": "There is just no way we can fight that no matter how well we construct our f hat n",
    "start": "588630",
    "end": "593720"
  },
  {
    "text": "in the observation that we are going to make this going to be noise. There is nothing we can do about it. So the expected, uh,",
    "start": "593720",
    "end": "599245"
  },
  {
    "text": "squared error between y star and- and our- our prediction f hat n x star can be broken down into three parts.",
    "start": "599245",
    "end": "607315"
  },
  {
    "text": "One is the irreducible error, the second is the bias, and the third is the variance, right?",
    "start": "607315",
    "end": "614199"
  },
  {
    "text": "So the irreducible error is noise in the test data, right?",
    "start": "614200",
    "end": "619270"
  },
  {
    "text": "It's not noise in the training data. Irreducible error component is noise in the test data. Because when we- when we deploy the model,",
    "start": "619270",
    "end": "625270"
  },
  {
    "text": "that is going to be noise in- in- in- in the data that you're going to encounter. The bias and variance are properties of the training data and the model class, right?",
    "start": "625270",
    "end": "635830"
  },
  {
    "text": "If the data is noisy and we don't have a lot of data, then this variance, uh, the variance of the thick line distribution is going to be large.",
    "start": "635830",
    "end": "644380"
  },
  {
    "text": "It's going to be more spread out. However, if you collect a lot of data, then it- this thick line distribution,",
    "start": "644380",
    "end": "650815"
  },
  {
    "text": "the- the- the distribution of hat n would be more concentrated. But still, even- even if it is concentrated,",
    "start": "650815",
    "end": "657459"
  },
  {
    "text": "there could still be a bias. That is the mean of our- our, er, f hat n and the true value, er,",
    "start": "657460",
    "end": "664030"
  },
  {
    "text": "of f can still- there could still be a bias and there is a variance because of, you know, the remaining is- is the variance.",
    "start": "664030",
    "end": "670765"
  },
  {
    "text": "I think of it as the variance where the variance is due to the noise in the training data, right? So there are three parts.",
    "start": "670765",
    "end": "676570"
  },
  {
    "text": "Irreducible error due to noise in the test data, variance due to noise in the training data, and bias.",
    "start": "676570",
    "end": "685764"
  },
  {
    "text": "There are three parts. And we also covered regularization before we go into regularization,",
    "start": "685765",
    "end": "693505"
  },
  {
    "text": "so we've just discussed the three components. We still haven't spoken of any trade-offs between them.",
    "start": "693505",
    "end": "698514"
  },
  {
    "text": "But this- this is the mental model to have in, you know, in your mind to decompose the- the test error into three parts, right?",
    "start": "698515",
    "end": "706435"
  },
  {
    "text": "Part due to noise in the test data, that's irreducible error, part due to noise in the training data,",
    "start": "706435",
    "end": "712645"
  },
  {
    "text": "that's variance and bias. Now, we also spoke about regularization and we will see why regularization,",
    "start": "712645",
    "end": "720280"
  },
  {
    "text": "er, plays a role in, um, um, shortly, soon. So regularization is a way in which we want to",
    "start": "720280",
    "end": "727075"
  },
  {
    "text": "penalize our estimated parameters from having very large values. We want the estimated Theta values to have small values.",
    "start": "727075",
    "end": "735340"
  },
  {
    "text": "And the reason is that, er, the- the intuition there is that if you have large values of,",
    "start": "735340",
    "end": "741130"
  },
  {
    "text": "um, in your Theta vector, then your predicted hypothesis can be very squiggly.",
    "start": "741130",
    "end": "746635"
  },
  {
    "text": "It can make very sharp turns and it can sway a lot. And the intuition there is we want to, you know,",
    "start": "746635",
    "end": "754105"
  },
  {
    "text": "therefore penalize large values of- of, er, Theta and therefore, we add an extra term to our cost function.",
    "start": "754105",
    "end": "762190"
  },
  {
    "text": "So if j of Theta, which previously used to be x Theta minus y node.",
    "start": "762190",
    "end": "770215"
  },
  {
    "text": "You know, this is standard linear regression cost function and we will add an extra Lambda times Theta node.",
    "start": "770215",
    "end": "780680"
  },
  {
    "text": "You're going to add this extra regularization term into our cost function with the hope that when we minimize the cost,",
    "start": "781290",
    "end": "789145"
  },
  {
    "text": "not only are we trying to fit the data well, but we're also trying to, you know, to some extent, make sure that our Theta values are not too large",
    "start": "789145",
    "end": "796690"
  },
  {
    "text": "and the balance between the two is decided by what is the regularization coefficient",
    "start": "796690",
    "end": "803395"
  },
  {
    "text": "we're going to use to wake this- the regularization term. And we also saw that the motivation that we- we went through just now,",
    "start": "803395",
    "end": "812485"
  },
  {
    "text": "it sounds a little arbitrary, it sounds a little hacky. But in fact, there is, uh,",
    "start": "812485",
    "end": "818035"
  },
  {
    "text": "a more principled interpretation to this from a Bayesian point of view. So remember in, um, in Bayesian statistics,",
    "start": "818035",
    "end": "825220"
  },
  {
    "text": "we construct a posterior distribution over our parameters given the data. And what- instead of holding on to the full posterior distribution to make- to construct,",
    "start": "825220",
    "end": "835420"
  },
  {
    "text": "er, posterior predictive distribution. Instead, what we could do is just calculate the mode of the posterior distribution and use",
    "start": "835420",
    "end": "843670"
  },
  {
    "text": "that mode of the posterior distribution as the output of our estimator and hold onto just that single point estimate,",
    "start": "843670",
    "end": "849595"
  },
  {
    "text": "which we call as Theta MAP. That's Maximum a posteriori estimate, as our output of the estimator.",
    "start": "849595",
    "end": "858190"
  },
  {
    "text": "So the- uh, we saw how Theta-hat MAP can be written as the argmax of the product of these two terms.",
    "start": "858190",
    "end": "866695"
  },
  {
    "text": "So one is the likelihood term. In case of linear regression, the likelihood term will turn out to be exactly equal to",
    "start": "866695",
    "end": "872950"
  },
  {
    "text": "this or rather it's going to be some scalar times this. But effectively, uh, this corresponds to the likelihood term.",
    "start": "872950",
    "end": "879940"
  },
  {
    "text": "And then there's going to be a regularizer term due to the prior we assign on the parameters.",
    "start": "879940",
    "end": "887784"
  },
  {
    "text": "And if the prior happens to be a Gaussian prior, then this prior will take on the form of a squared error on Theta.",
    "start": "887784",
    "end": "896230"
  },
  {
    "text": "Right? So that's another thing you want to keep in your mind in general. And whenever you assign something to be- to have,",
    "start": "896230",
    "end": "902529"
  },
  {
    "text": "er, a Gaussian distribution or Gaussian prior, it's going to show up as a squared error somehow because, you know,",
    "start": "902530",
    "end": "908829"
  },
  {
    "text": "in- in- in the exponent of the Gaussian there is, you know, a square on the, er, a squared term.",
    "start": "908830",
    "end": "914050"
  },
  {
    "text": "And when you take the log likelihood, the exponent and the square cancel out and you're just going to be end up with, er, the log and",
    "start": "914050",
    "end": "919390"
  },
  {
    "text": "the exponent cancel out and you're just going to end up with the square term in the, er, exponent. So, um, when we have a Gaussian prior,",
    "start": "919390",
    "end": "926289"
  },
  {
    "text": "this corresponds to- corresponds to the regularizer term and the variance that we",
    "start": "926289",
    "end": "932290"
  },
  {
    "text": "assign to the prior distribution of the Gaussian is directly related to Lambda, right?",
    "start": "932290",
    "end": "938454"
  },
  {
    "text": "The- the stronger our prior is, then the larger Lambda is. And in your homework, you know,",
    "start": "938455",
    "end": "944380"
  },
  {
    "text": "you work out what is the exact relation between Lambda and the- the variance. Uh, but that's, er, the- that's the idea and in general,",
    "start": "944380",
    "end": "951610"
  },
  {
    "text": "so it means if- if this is the, um, x-axis are the parameters and this is zero, that's the origin.",
    "start": "951610",
    "end": "958015"
  },
  {
    "text": "And we have a prior distribution over data centered around the origin. And we have a likelihood function that is maximized at the maximum likelihood estimate.",
    "start": "958015",
    "end": "967495"
  },
  {
    "text": "So this is our theta hat, MLE, this is 0. And we are trying- now trying to maximize the product of these two, right?",
    "start": "967495",
    "end": "975025"
  },
  {
    "text": "So the product of these two is this dotted function and the way you wanna think of it is,",
    "start": "975025",
    "end": "980815"
  },
  {
    "text": "since you're multiplying two, er, two functions, any region where either of the two functions is close to zero,",
    "start": "980815",
    "end": "989110"
  },
  {
    "text": "the product will be close to 0, right? So it is going to take, um, er, it's going to be non-zero in regions where both, uh,",
    "start": "989110",
    "end": "997240"
  },
  {
    "text": "the prior and the likelihood are- are non-0, right? And so, er, assuming this is the product of these two functions,",
    "start": "997240",
    "end": "1005755"
  },
  {
    "text": "the Theta-hat MAP is the value that maximizes this- the product of these two.",
    "start": "1005755",
    "end": "1011560"
  },
  {
    "text": "So this is like the posterior distribution. It- it might not be normalized, you need to,",
    "start": "1011560",
    "end": "1017685"
  },
  {
    "text": "um, divide it by p of s in this case to normalize it. But, you know, this is- think of this as the unnormalized posterior distribution.",
    "start": "1017685",
    "end": "1025900"
  },
  {
    "text": "And the value where, er, the unnormalized posterior gets maximized is- is the same value at where the unnormalized posterior gets maximized.",
    "start": "1025900",
    "end": "1033745"
  },
  {
    "text": "And this is, er, Theta hat MAP. And therefore what we see is the posterior is going to- because it's- it's the product of these two,",
    "start": "1033745",
    "end": "1041020"
  },
  {
    "text": "the posterior is going to kind of lie between the likelihood and the prior, right? Because of the product of the two functions.",
    "start": "1041020",
    "end": "1047895"
  },
  {
    "text": "And therefore the value that maximizes MAP, is going to be closer to zero than the MLE.",
    "start": "1047895",
    "end": "1052990"
  },
  {
    "text": "And therefore, um, the estimator Theta values will be smaller in value because they are closer to zero, right?",
    "start": "1052990",
    "end": "1059970"
  },
  {
    "text": "So this, this was, er, this was one way to kind of think of regularization using the Bayesian framework.",
    "start": "1059970",
    "end": "1065965"
  },
  {
    "text": "And in fact, in your homework, you also have another, uh, question where instead of assuming p Theta to be- to be a Gaussian,",
    "start": "1065965",
    "end": "1073889"
  },
  {
    "text": "what happens if it's a Laplace distribution, right? And- and there, the intuition to have there is, um, again,",
    "start": "1073890",
    "end": "1081395"
  },
  {
    "text": "assume this is Theta 1, Theta d, the prior of a multivariate or other product",
    "start": "1081395",
    "end": "1088060"
  },
  {
    "text": "of independent Laplaces is gonna look like this.",
    "start": "1088060",
    "end": "1091880"
  },
  {
    "text": "It's a star, you know, it's kind of like a star-shape function. Whereas in a Gaussian,",
    "start": "1093530",
    "end": "1098549"
  },
  {
    "text": "it's going to be circles. And if- if this is Theta hat MLE,",
    "start": "1098550",
    "end": "1107310"
  },
  {
    "text": "so if this is the maximum likelihood estimate and, let's say, these are like the contour plots of the likelihood.",
    "start": "1107310",
    "end": "1115920"
  },
  {
    "text": "Now the product of- and this is the contour plot of the prior, and you can see that the product of",
    "start": "1115920",
    "end": "1124424"
  },
  {
    "text": "this function and the product of this function will achieve a value,",
    "start": "1124425",
    "end": "1129630"
  },
  {
    "text": "or high values generally along the axis, right?",
    "start": "1129630",
    "end": "1136575"
  },
  {
    "text": "And- and- and therefore the value where MAP is maximized will- will lie along the axis,",
    "start": "1136575",
    "end": "1144539"
  },
  {
    "text": "exactly along the axis and in high-dimensional spaces, it turns out that this results in sparse parameters,",
    "start": "1144540",
    "end": "1153330"
  },
  {
    "text": "which means most of the axis- most of the Theta i values will be exactly 0  because it's going to be along the axis because",
    "start": "1153330",
    "end": "1159525"
  },
  {
    "text": "you get you- in order to- to the way you- the way the prior is- is- is,",
    "start": "1159525",
    "end": "1166200"
  },
  {
    "text": "um, structured is that if you want to reach out as far as possible and still have a high prior value,",
    "start": "1166200",
    "end": "1173715"
  },
  {
    "text": "then you need to go along the axes to- to kind of have high- to have high- high prior probability,",
    "start": "1173715",
    "end": "1180059"
  },
  {
    "text": "but still reach- stretch out as far as possible to Theta-hat. You need to do that along the,",
    "start": "1180060",
    "end": "1186330"
  },
  {
    "text": "um, along the axes therefore, applying a Laplace prior will result in- in",
    "start": "1186330",
    "end": "1191865"
  },
  {
    "text": "sparse- sparse parameters and that's called the LASSO dis- the LASSO,",
    "start": "1191865",
    "end": "1197520"
  },
  {
    "text": "um, uh, estimator and you- you explore this in your homework as well. Any other questions before we move on to today's topics? Yes, question.",
    "start": "1197520",
    "end": "1205710"
  },
  {
    "text": "[inaudible]",
    "start": "1205710",
    "end": "1223710"
  },
  {
    "text": "Yeah. So the question is, how- how do the- the definitions of- of the- the",
    "start": "1223710",
    "end": "1229258"
  },
  {
    "text": "statistical inf- the bias and variance in the statistical inference relate to bias and variance in- in the prediction setting?",
    "start": "1229259",
    "end": "1235155"
  },
  {
    "text": "The- the short answer is that, um, the f Theta uh, - f Theta hat of n is generally composed of, you know,",
    "start": "1235155",
    "end": "1244515"
  },
  {
    "text": "Theta hat n. So Theta hat n is- is kind of embedded in this, uh, uh,",
    "start": "1244515",
    "end": "1250670"
  },
  {
    "text": "f- f hat n and- and therefore, you know, the bias and various, in- in- in simple cases- there- they directly transfer,",
    "start": "1250670",
    "end": "1258750"
  },
  {
    "text": "you know, um, which we'll go over, um, um, we'll go over today. But in general, the bias in f hat n is assuming, uh,",
    "start": "1258750",
    "end": "1266490"
  },
  {
    "text": "you're using some kind of a parametric model and not non-parametric, assuming you're using some kind of parametric model,",
    "start": "1266490",
    "end": "1271590"
  },
  {
    "text": "then the bias in f hat n is related to the bias of Theta hat n,",
    "start": "1271590",
    "end": "1279360"
  },
  {
    "text": "uh, which is the parameter of f. [inaudible]",
    "start": "1279360",
    "end": "1285780"
  },
  {
    "text": "They are related in general, no matter what the parametric family is,",
    "start": "1285780",
    "end": "1290880"
  },
  {
    "text": "but it's very hard to come up with an analytical relation between the two. But in- in- in general they're the- the- the noise in f hat n in the prediction",
    "start": "1290880",
    "end": "1300330"
  },
  {
    "text": "is due to the noise in the corresponding Theta. Yes, question.",
    "start": "1300330",
    "end": "1306970"
  },
  {
    "text": "Can you explain that part where [inaudible]",
    "start": "1313340",
    "end": "1319200"
  },
  {
    "text": "So the question is, how does this translate into this? [inaudible] So yes, so the- the,",
    "start": "1319200",
    "end": "1328605"
  },
  {
    "text": "I mean, so this is exactly what you're showing in your homework. You need to show in your homework. The question is, how does the prior result in this?",
    "start": "1328605",
    "end": "1335505"
  },
  {
    "text": "And when you, when you're taking the argmax of this, you know, if you, instead of the product of p of Theta,",
    "start": "1335505",
    "end": "1342315"
  },
  {
    "text": "you- you take the arg max of the log of these two that separates into two additional terms,",
    "start": "1342315",
    "end": "1347505"
  },
  {
    "text": "and this will have a Gaussian distribution, assuming if it's Gaussian. Then the log and the exponent of the Gaussian cancel,",
    "start": "1347505",
    "end": "1354000"
  },
  {
    "text": "and the square root and the prior will end up being this. It's pretty straightforward math. [inaudible]",
    "start": "1354000",
    "end": "1366330"
  },
  {
    "text": "Yeah, so if, if the prior is not Gaussian, this will not be squared error. It could be a different, so if it's,",
    "start": "1366330",
    "end": "1371655"
  },
  {
    "text": "if you apply a Laplace prior then you will have just the Theta norm,",
    "start": "1371655",
    "end": "1377820"
  },
  {
    "text": "the  1-norm instead of the 2-norm, right? So the squared error happens only when you apply,",
    "start": "1377820",
    "end": "1383745"
  },
  {
    "text": "um, um, uh, Gaussian prior. All right, so moving on to today's topics.",
    "start": "1383745",
    "end": "1390150"
  },
  {
    "text": "So today we're going to see",
    "start": "1390150",
    "end": "1396990"
  },
  {
    "text": "how bias and variance there is a trade-off between the two using two kind of, uh, case studies.",
    "start": "1396990",
    "end": "1404190"
  },
  {
    "text": "So in one case study, we're going to see the role played by the regularization to affect, uh, or- or- or how it affects bias and variance.",
    "start": "1404190",
    "end": "1412755"
  },
  {
    "text": "And we're going to use the- the- the, uh, - the case of L2 regularized linear regression.",
    "start": "1412755",
    "end": "1425630"
  },
  {
    "text": "[NOISE] All right, so,",
    "start": "1425630",
    "end": "1432570"
  },
  {
    "text": "uh, I posted some notes over the weekend that gave- that give the, uh, detailed derivation of all- of all the- the steps that we're going to do today.",
    "start": "1432570",
    "end": "1441390"
  },
  {
    "text": "We will just go to the results and discuss the intuitions about the results, but, you know, the step-by-step derivations are there in the notes.",
    "start": "1441390",
    "end": "1448904"
  },
  {
    "text": "So in case of- in case, um, of L2 regularized linear regression.",
    "start": "1448905",
    "end": "1457665"
  },
  {
    "text": "First, we will talk about the bias and variance in Theta, in the Theta hat itself.",
    "start": "1457665",
    "end": "1463260"
  },
  {
    "text": "So remember, L2 regularized linear regression has the cost function i equals 1 to n,",
    "start": "1463260",
    "end": "1473775"
  },
  {
    "text": "yi minus Theta transpose xi square,",
    "start": "1473775",
    "end": "1483370"
  },
  {
    "text": "plus lambda times Theta squared.",
    "start": "1483560",
    "end": "1492040"
  },
  {
    "text": "And if you, if you, uh,",
    "start": "1492080",
    "end": "1498480"
  },
  {
    "text": "if you work out the maximum- if you work out, uh, what the optimal value of Theta is for this case,",
    "start": "1498480",
    "end": "1505815"
  },
  {
    "text": "there is a closed form solution. And the closed form solution will turn out to be this. Theta hat n N is equal to x transpose x",
    "start": "1505815",
    "end": "1516795"
  },
  {
    "text": "plus lambda i inverse x transpose y.",
    "start": "1516795",
    "end": "1525640"
  },
  {
    "text": "And this is very similar to the normal, normal equations that we derived,",
    "start": "1525650",
    "end": "1531195"
  },
  {
    "text": "except there was no extra lambda i term in that case. So if you remember the- the- the normal equation give,",
    "start": "1531195",
    "end": "1539385"
  },
  {
    "text": "had given us Theta hat equals x transpose x inverse x transpose y.",
    "start": "1539385",
    "end": "1547300"
  },
  {
    "text": "And back then we had- we had spoken or at least briefly mentioned that it's,",
    "start": "1547310",
    "end": "1553710"
  },
  {
    "text": "sometimes it's possible that X transpose X may not be invertible, right?",
    "start": "1553710",
    "end": "1558840"
  },
  {
    "text": "And in the case of L2 regularized linear regression, what we see is, you know,",
    "start": "1558840",
    "end": "1565590"
  },
  {
    "text": "we are adding this diagonal, uh, matrix with lambda as the diagonal values to x transpose X, right?",
    "start": "1565590",
    "end": "1573285"
  },
  {
    "text": "And what does this, ah, give us? So supposing X transpose X has an Eigen decomposition where it is",
    "start": "1573285",
    "end": "1581760"
  },
  {
    "text": "U sigma 1 square until sigma d square U transpose.",
    "start": "1581760",
    "end": "1590129"
  },
  {
    "text": "So suppose this is the Eigen decomposition of X transpose X. By adding a lambda parameter to a lambda i to this matrix,",
    "start": "1590129",
    "end": "1600525"
  },
  {
    "text": "you're essentially just adding lambda to all the eigenvalues. If you remember adding a diagonal matrix to,",
    "start": "1600525",
    "end": "1608175"
  },
  {
    "text": "um- adding a diagonal matrix to some- some matrix just increases the eigenvalues by that diagonal value, right?",
    "start": "1608175",
    "end": "1617115"
  },
  {
    "text": "And this is, um, X transpose X plus lambda i, right?",
    "start": "1617115",
    "end": "1622740"
  },
  {
    "text": "And now if we invert this matrix, then we're just inverting the corresponding eigenvalues. Yes, question.",
    "start": "1622740",
    "end": "1635100"
  },
  {
    "text": "[inaudible]",
    "start": "1635100",
    "end": "1647414"
  },
  {
    "text": "So I will not go into the details of that. That's a standard linear algebra result where if you add a diagonal matrix to another symmetric matrix,",
    "start": "1647415",
    "end": "1654630"
  },
  {
    "text": "then you're just increasing the eigenvalues by, you know, the, the uh, amount by which your- the diagonals are scaled.",
    "start": "1654630",
    "end": "1661620"
  },
  {
    "text": "That's a standard linear algebra result and it's very easy to show it. If you can post on Piazza, I can reply with the steps,",
    "start": "1661620",
    "end": "1667065"
  },
  {
    "text": "but that's, you know, just take it as given for now. Can I ask a question? Yes, question.",
    "start": "1667065",
    "end": "1672360"
  },
  {
    "text": "So are U and U-transpose [inaudible] So X transpose- so U here are assumed to be,",
    "start": "1672360",
    "end": "1682350"
  },
  {
    "text": "you know, invertible, where U has the property UU transpose equals U transpose U equals i.",
    "start": "1682350",
    "end": "1690170"
  },
  {
    "text": "So U transpose is the inverse of U. So that's again, that's eigen-decomposition right?",
    "start": "1690170",
    "end": "1697365"
  },
  {
    "text": "So, um [NOISE] so now we see that because we are adding a non-zero value to all the eigenvalues,",
    "start": "1697365",
    "end": "1706200"
  },
  {
    "text": "all the- the inverse will exist because you know, we're not doing a 1 over 0 anymore.",
    "start": "1706200",
    "end": "1711419"
  },
  {
    "text": "In the original X transpose x some of Sigma I squared could have been 0. But now that we've added a small Lambda value,",
    "start": "1711420",
    "end": "1718515"
  },
  {
    "text": "this matrix is always invertible and you always get a unique inverse, right?",
    "start": "1718515",
    "end": "1723795"
  },
  {
    "text": "And now, Theta hat n is now, therefore,",
    "start": "1723795",
    "end": "1729540"
  },
  {
    "text": "this um Theta hat n is ah - so x transpose x plus Lambda I inverse is now this matrix.",
    "start": "1729540",
    "end": "1739410"
  },
  {
    "text": "And we can now see that the expectation of Theta hat n is equal to um - again I'm not going to go over all the steps,",
    "start": "1739410",
    "end": "1750210"
  },
  {
    "text": "but ah I'll directly, ah, write out the last, ah, equation that we get is equal to Sigma 1 squared over Sigma 1",
    "start": "1750210",
    "end": "1762419"
  },
  {
    "text": "square plus Lambda Sigma d square,",
    "start": "1762420",
    "end": "1774735"
  },
  {
    "text": "or Sigma d square plus Lambda. Rest are all 0s, times U transpose of Theta star. Right?",
    "start": "1774735",
    "end": "1788309"
  },
  {
    "text": "Does Lambda take on only positive values? So the question is this Lambda take on only positive values necessarily, yes.",
    "start": "1788310",
    "end": "1794294"
  },
  {
    "text": "So Lambda in case of regularization is always greater than 0. Yeah, good question.",
    "start": "1794295",
    "end": "1800110"
  },
  {
    "text": "So, um so the expectation of Theta hat-Theta hat n,",
    "start": "1800770",
    "end": "1806370"
  },
  {
    "text": "where Theta hat n is the solution of the L2 regularized regression -linear regression is this matrix.",
    "start": "1806370",
    "end": "1815414"
  },
  {
    "text": "So this whole thing is a matrix times a vector, right?",
    "start": "1815415",
    "end": "1821730"
  },
  {
    "text": "So we can make a few observations here. Now, supposing Lambda was 0, right,",
    "start": "1821730",
    "end": "1827565"
  },
  {
    "text": "this whole matrix reduces to the identity matrix, right? Because each of the diagonals become 1 along the diagonals,",
    "start": "1827565",
    "end": "1835290"
  },
  {
    "text": "U and U transpose has this property that U, U transpose is the identity. So this whole matrix reduces to a large identity matrix if Lambda is zero. Yes, question.",
    "start": "1835290",
    "end": "1848265"
  },
  {
    "text": "Can you please explain how you get this expression? How we get this expression? So it is pretty, pretty straightforward.",
    "start": "1848265",
    "end": "1854054"
  },
  {
    "text": "It's in page four of the notes. The way you go about doing this is Theta hat n is equal to -we write it over here.",
    "start": "1854055",
    "end": "1866130"
  },
  {
    "text": "We write this as x transpose x plus Lambda i inverse x transpose and then in place of y,",
    "start": "1866130",
    "end": "1877380"
  },
  {
    "text": "we write x Theta star plus epsilon.",
    "start": "1877380",
    "end": "1882810"
  },
  {
    "text": "Because y is x Theta star plus epsilon as the assumption. And then you, you,",
    "start": "1882810",
    "end": "1888765"
  },
  {
    "text": "you expand this and you will get two terms. And because of the epsilon,",
    "start": "1888765",
    "end": "1893790"
  },
  {
    "text": "the second term just becomes 0. Expectation of epsilon times a scalar is 0, and the first, first um, expression you apply an eigen-decomposition you get this right.",
    "start": "1893790",
    "end": "1902759"
  },
  {
    "text": "The detailed steps are there in the notes. But the idea here is that um, the mean of Theta - Theta hat n is this matrix times Theta star.",
    "start": "1902760",
    "end": "1914789"
  },
  {
    "text": "So, if Lambda is 0, the standard regular linear regression, then expected value of Theta hat ah n is equal to Theta star.",
    "start": "1914790",
    "end": "1924635"
  },
  {
    "text": "So the linear regression, the standard linear regression ah, estimator is unbiased.",
    "start": "1924635",
    "end": "1930080"
  },
  {
    "text": "However, if we add a regularization term,",
    "start": "1930080",
    "end": "1935679"
  },
  {
    "text": "then we are multiplying the, the true Theta star by a matrix whose eigenvalues,",
    "start": "1935680",
    "end": "1943260"
  },
  {
    "text": "all the eigenvalues are less than 1. Right? And if you remember, the, the eigenvalues,",
    "start": "1943260",
    "end": "1951195"
  },
  {
    "text": "decide how much the input space of that matrix shrinks or expands in the output space, right?",
    "start": "1951195",
    "end": "1957825"
  },
  {
    "text": "So if you feed some- any vector into a matrix whose entire spectrum,",
    "start": "1957825",
    "end": "1964725"
  },
  {
    "text": "whose set of all eigenvalues are small, then in the output space is essentially shrunk, right?",
    "start": "1964725",
    "end": "1972300"
  },
  {
    "text": "And so what we see is that the when, when we have Lambda greater than 0,",
    "start": "1972300",
    "end": "1977639"
  },
  {
    "text": "the norm of Theta -of, of ah - the norm of this entire expression is gonna be smaller than the norm of Theta star itself, right?",
    "start": "1977640",
    "end": "1987540"
  },
  {
    "text": "Which is how you see the shrinkage effect coming into picture. You are multiplying the true valu- the true parameter",
    "start": "1987540",
    "end": "1994455"
  },
  {
    "text": "by a matrix whose entire set of eigenvalues is less than 1. And so the result of multiplying ah,",
    "start": "1994455",
    "end": "2002315"
  },
  {
    "text": "the vector is going to be a shrunk version of that vector, right?",
    "start": "2002315",
    "end": "2008375"
  },
  {
    "text": "So, so that's how we get, you know, that's how we see that linear- the regularization term has a bias.",
    "start": "2008375",
    "end": "2017150"
  },
  {
    "text": "When Theta is non-zero, then when Lambda is non-zero, then the expectation is never exactly equal to Theta star, right? So that's bias.",
    "start": "2017150",
    "end": "2026150"
  },
  {
    "text": "What about the variance?",
    "start": "2026150",
    "end": "2028290"
  },
  {
    "text": "For reference I'll just continue it down here so that you can just compare it with what's above.",
    "start": "2033190",
    "end": "2039815"
  },
  {
    "text": "So, so the covariance matrix of Theta hat n- again,",
    "start": "2039815",
    "end": "2050135"
  },
  {
    "text": "um using a very similar argument, if we expand it out, ah you're gonna get that the covariance matrix of Theta hat n will be U times",
    "start": "2050135",
    "end": "2063419"
  },
  {
    "text": "tau squared Sigma 1 squared over 1 squared",
    "start": "2063610",
    "end": "2068840"
  },
  {
    "text": "plus Lambda squared tau",
    "start": "2068840",
    "end": "2076970"
  },
  {
    "text": "squared, sigma d squared",
    "start": "2076970",
    "end": "2079980"
  },
  {
    "text": "times mu transpose, where tau is [inaudible]",
    "start": "2091720",
    "end": "2108280"
  },
  {
    "text": "So if Tau- Tau squared is the variance of the noise in- in, um,",
    "start": "2108280",
    "end": "2113755"
  },
  {
    "text": "in our x and y, such that y equals, uh, Theta star transpose x plus Epsilon.",
    "start": "2113755",
    "end": "2121494"
  },
  {
    "text": "So if Tau squared is the- is the variance of the error, uh, um, of the error terms,",
    "start": "2121495",
    "end": "2127359"
  },
  {
    "text": "then the covariance of the Theta hat N, that's the covariance of our regularized estimate is this matrix.",
    "start": "2127360",
    "end": "2137859"
  },
  {
    "text": "Now, this matrix you can observe is symmetric because,",
    "start": "2137860",
    "end": "2145075"
  },
  {
    "text": "um, um, it's symmetric and it will be, uh, positive definite because all the- all the eigenvalues are greater than 0.",
    "start": "2145075",
    "end": "2152830"
  },
  {
    "text": "So it's a value covariance matrix, right? Just sanity check. And what we also see is that as we increase the- the, uh,",
    "start": "2152830",
    "end": "2162355"
  },
  {
    "text": "la- Lambda value to, uh, to a larger, uh, value, then the covariance matrix is going to have a smaller spectrum, right?",
    "start": "2162355",
    "end": "2172030"
  },
  {
    "text": "The set of all eigenvalues of the covariance matrix also reduces as we increase Lambda.",
    "start": "2172030",
    "end": "2177865"
  },
  {
    "text": "And because these are the, each of these terms is just the,",
    "start": "2177865",
    "end": "2184180"
  },
  {
    "text": "uh, um, are directly related to the- the, uh, um, are- are exactly the eigenvalues.",
    "start": "2184180",
    "end": "2190375"
  },
  {
    "text": "So if you have a larger Lambda, then the eigenvalues of the covariance matrix are also reducing. Which means the intuition to have that is that",
    "start": "2190375",
    "end": "2197380"
  },
  {
    "text": "your covariance or the variance in your estimator is also reducing. So if you remember, if you have, uh, um,",
    "start": "2197380",
    "end": "2204759"
  },
  {
    "text": "a Gaussian distribution that has some mean and some covariance, the covariance,",
    "start": "2204760",
    "end": "2211330"
  },
  {
    "text": "the sign, uh, uh, uh, um, the covariance implicitly, uh, defines, uh, an ellipse around the mean.",
    "start": "2211330",
    "end": "2218410"
  },
  {
    "text": "And the smaller the covariance, the shorter or the- the tighter the,",
    "start": "2218410",
    "end": "2224980"
  },
  {
    "text": "uh, um, uh, ellipsoid will be. And that's the intuition we have here. The larger that, the smaller the eigenvalues you have,",
    "start": "2224980",
    "end": "2232135"
  },
  {
    "text": "the- the tighter the- the ellipsoid is around, uh, um, around the mean, right?",
    "start": "2232135",
    "end": "2239635"
  },
  {
    "text": "So here is one- so, uh, here what we see is as we increase Lambda,",
    "start": "2239635",
    "end": "2246805"
  },
  {
    "text": "the bias in our estimate increases, which is bad. But the variance in our estimator reduces,",
    "start": "2246805",
    "end": "2253420"
  },
  {
    "text": "which is good, right? So we want our variance- our estimated to have low variance, but we also wanted to have low bias.",
    "start": "2253420",
    "end": "2259770"
  },
  {
    "text": "But what we see here is, as we increase Lambda, the bias increases, which is bad,",
    "start": "2259770",
    "end": "2266800"
  },
  {
    "text": "but variance decreases, which is good. Similarly, if you reduce Lambda, the bias decreases,",
    "start": "2266800",
    "end": "2271854"
  },
  {
    "text": "which is good, but variance increases, which is bad, right? So this, this, uh,",
    "start": "2271854",
    "end": "2278875"
  },
  {
    "text": "this is one example of, you know, what's- what's called the bias-variance trade-off where",
    "start": "2278875",
    "end": "2284425"
  },
  {
    "text": "some action that we take will improve one of them, either bias or variance, but at the same time,",
    "start": "2284425",
    "end": "2290485"
  },
  {
    "text": "it can hurt the other one. Yes, question. Can you clarify then what you mean by the or by the bias would reduce.",
    "start": "2290485",
    "end": "2298435"
  },
  {
    "text": "So the bias will increase when we increase Lambda because we are now multiplying the true value",
    "start": "2298435",
    "end": "2305830"
  },
  {
    "text": "of Theta star through a matrix that shrinks it, and it's- it's getting farther and farther away from the true value.",
    "start": "2305830",
    "end": "2311994"
  },
  {
    "text": "So, you know, uh, we- we- that's- that's bad, uh, we're going farther away from the true value itself in expectation.",
    "start": "2311995",
    "end": "2320005"
  },
  {
    "text": "At the same time, there's also, you know, a variance term involved,",
    "start": "2320005",
    "end": "2326035"
  },
  {
    "text": "where- which is our sensitivity to data, right? The larger Lambda- the value of Lambda we have,",
    "start": "2326035",
    "end": "2332230"
  },
  {
    "text": "then the less sensitive we- we become to the noise in the training data. And, uh, and- and- and that's good.",
    "start": "2332230",
    "end": "2339055"
  },
  {
    "text": "So therefore, Lambda is- is, you know, you're kind of, uh, by choosing the value of Lambda, you're doing a trade off between bias and variance, right?",
    "start": "2339055",
    "end": "2347635"
  },
  {
    "text": "And these two terms directly translate into prediction as well. So this was about, you know,",
    "start": "2347635",
    "end": "2353050"
  },
  {
    "text": "about Theta hat itself. Now, if you wanna do prediction, [NOISE] if you wanna do prediction,",
    "start": "2353050",
    "end": "2363640"
  },
  {
    "text": "let's remember- let's recall the- the, um, the da- bias-variance decomposition.",
    "start": "2363640",
    "end": "2371309"
  },
  {
    "text": "So mean squared error of f hat n. This one was, uh,",
    "start": "2371310",
    "end": "2378360"
  },
  {
    "text": "Tau squared plus x star",
    "start": "2378360",
    "end": "2391230"
  },
  {
    "text": "minus x star the whole squared",
    "start": "2391230",
    "end": "2397830"
  },
  {
    "text": "plus variance of- so this is the,",
    "start": "2397830",
    "end": "2407140"
  },
  {
    "text": "uh, standard bias-variance decomposition which we saw last- last time as well. This is called the irreducible error.",
    "start": "2407140",
    "end": "2415640"
  },
  {
    "text": "And this is bias squared.",
    "start": "2418530",
    "end": "2424210"
  },
  {
    "text": "This is variance. And- and this is again in Page 7 of your notes,",
    "start": "2424210",
    "end": "2430780"
  },
  {
    "text": "the detailed, uh, steps of deriving this. But let's just look at- look at the result and- and, uh, trying to get some intuition.",
    "start": "2430780",
    "end": "2437170"
  },
  {
    "text": "So this is, uh, our bias. And what we see is if- if we define f to be",
    "start": "2437170",
    "end": "2444520"
  },
  {
    "text": "now Theta f of x to be Theta star transpose x,",
    "start": "2444520",
    "end": "2450010"
  },
  {
    "text": "which is the- the- the true value of- of Theta, then the bias, uh,",
    "start": "2450010",
    "end": "2455109"
  },
  {
    "text": "will relate- the bias of the predictor will now relate to bias of the estimator in this way.",
    "start": "2455110",
    "end": "2463210"
  },
  {
    "text": "So bias of f hat n of x star is equal to",
    "start": "2463210",
    "end": "2472195"
  },
  {
    "text": "the expectation of f hat n",
    "start": "2472195",
    "end": "2478360"
  },
  {
    "text": "x star minus f of x star.",
    "start": "2478360",
    "end": "2483550"
  },
  {
    "text": "So that's just, um, this and this is equal to the expectation of Theta hat",
    "start": "2483550",
    "end": "2490450"
  },
  {
    "text": "n transpose x star minus Theta star transpose x star.",
    "start": "2490450",
    "end": "2498640"
  },
  {
    "text": "This is equal to expectation of Theta hat n minus Theta star transpose x star,",
    "start": "2498640",
    "end": "2508194"
  },
  {
    "text": "this is equal to bias of Theta hat n, transpose x star.",
    "start": "2508195",
    "end": "2515485"
  },
  {
    "text": "So the bias and the predictor is related to the bias in the estimator.",
    "start": "2515485",
    "end": "2521455"
  },
  {
    "text": "With this relation, it's you- you- you just take the transpose of the bias and the estimator with the point that predict- the prediction point,",
    "start": "2521455",
    "end": "2529720"
  },
  {
    "text": "prediction input and that gives you the bias in the, uh, uh, predictor. Yes question. Can you like also,like, do you have an expectation for Theta hat",
    "start": "2529720",
    "end": "2538000"
  },
  {
    "text": "and have the covariance can you use, uh, those two formal closed-form solutions of Lambda in terms of Sigma and Tau to minimize them?",
    "start": "2538000",
    "end": "2546430"
  },
  {
    "text": "So the question is, can we- can we come up with a closed form expression for Lambda in terms of?",
    "start": "2546430",
    "end": "2554349"
  },
  {
    "text": "Sigma and Tau. Sigma and Tau and minimize what?",
    "start": "2554350",
    "end": "2560305"
  },
  {
    "text": "So if you what the eigenvalues to be as big as possible so that you can stay close to the data but you want the covariance matrix to be minimized.",
    "start": "2560305",
    "end": "2569215"
  },
  {
    "text": "So like you're some sort of a relationship and you minimize your, vari- uh, you minimize your variance and maximize [inaudible] ?",
    "start": "2569215",
    "end": "2576735"
  },
  {
    "text": "And so I guess if I understand you correctly, you're trying to, um, you're trying to say,",
    "start": "2576735",
    "end": "2582725"
  },
  {
    "text": "is there an optimal way to find out kind of the best value of lambda [BACKGROUND] or- or the optimal value of lambda.",
    "start": "2582725",
    "end": "2590010"
  },
  {
    "text": "To simultaneously minimize that and maximize that. We'll- we'll come to that shortly. So we're going to answer the question of how to choose lambda.",
    "start": "2590260",
    "end": "2597740"
  },
  {
    "text": "Uh, the- the, uh, closed form expression has some, uh, challenges which, you know the- the- with the method that you suggest.",
    "start": "2597740",
    "end": "2605360"
  },
  {
    "text": "But, uh, let- let's- let's, uh, come to that shortly. Right? So- so this is the, um,",
    "start": "2605360",
    "end": "2611695"
  },
  {
    "text": "so this is the relation between the bias and the predictor and the bias and the estimator.",
    "start": "2611695",
    "end": "2616850"
  },
  {
    "text": "The relation is defined by the point at which you are making a prediction. And this kind of a closed form relation is possible only for",
    "start": "2616850",
    "end": "2624230"
  },
  {
    "text": "simple models such as linear regression with L2 regularization. For more complex models, if f hat n is a neural network,",
    "start": "2624230",
    "end": "2630845"
  },
  {
    "text": "then it's very hard to come up with a simple relation between the bias of the predictors of the neural networks,",
    "start": "2630845",
    "end": "2636545"
  },
  {
    "text": "of the- uh, the parameters of the neural networks and the prediction that it makes, right? But for simple models, we can- can see the relation between the two.",
    "start": "2636545",
    "end": "2643760"
  },
  {
    "text": "Similarly, the variance of f hat n is equal",
    "start": "2643760",
    "end": "2651290"
  },
  {
    "text": "to x transpose covariance of theta hat n x.",
    "start": "2651290",
    "end": "2658700"
  },
  {
    "text": "So it's a quadratic form that uses the covariance matrix of theta hat n along with x as the input to get the variance of that.",
    "start": "2658700",
    "end": "2666710"
  },
  {
    "text": "So- so- and- and similarly the- the, um, and therefore, because there is, you know, uh,",
    "start": "2666710",
    "end": "2673849"
  },
  {
    "text": "a straight forward relation between the bias from the estimator to the predictor and the variants from the estimator to the predictor,",
    "start": "2673850",
    "end": "2682010"
  },
  {
    "text": "the effect of lambda is also the same. So if we increase lambda to a large value,",
    "start": "2682010",
    "end": "2689195"
  },
  {
    "text": "the variance of the estimator comes down and the variance of the predictor comes down.",
    "start": "2689195",
    "end": "2695060"
  },
  {
    "text": "And if we reduce lambda, then the, um, uh, bias of the, uh, uh,",
    "start": "2695060",
    "end": "2701750"
  },
  {
    "text": "estimator comes down and the bias of the predictor also comes down, right? Because it's- it's a very simple, uh, uh, relation between the two.",
    "start": "2701750",
    "end": "2708525"
  },
  {
    "text": "Now any questions on this?",
    "start": "2708525",
    "end": "2717900"
  },
  {
    "text": "So in general, what we care about is we want to minimize the squared error on future predictions, right?",
    "start": "2720880",
    "end": "2731860"
  },
  {
    "text": "In machine learning, that's our goal, right? What we want to do is- is have,",
    "start": "2731860",
    "end": "2736870"
  },
  {
    "text": "or have an estimator or- or- or a predictor that has very good low generalization error.",
    "start": "2736870",
    "end": "2742780"
  },
  {
    "text": "So generalization error is how well we perform on unseen, uh, examples.",
    "start": "2742780",
    "end": "2748565"
  },
  {
    "text": "And for that, what we see is in order to minimize the generalization error,",
    "start": "2748565",
    "end": "2756200"
  },
  {
    "text": "we have three different components that we can go after. All of them are non-zero, so reducing any one of them will reduce the overall generalization error.",
    "start": "2756200",
    "end": "2766115"
  },
  {
    "text": "Right? And these- these three components, as you, uh, uh, saw before, is the irreducible error bias,",
    "start": "2766115",
    "end": "2772970"
  },
  {
    "text": "the square of the bias and variance that add up to form the- the, uh, mean squared error.",
    "start": "2772970",
    "end": "2778010"
  },
  {
    "text": "Now, to reduce any one of these, let's- let's see, uh, what- what- what happens.",
    "start": "2778010",
    "end": "2783875"
  },
  {
    "text": "So irreducible error is something we- we cannot do anything about, right? That's just a fact of life.",
    "start": "2783875",
    "end": "2789545"
  },
  {
    "text": "We have to live with the irreducible error. No matter what kind of a predictor that you come up with, you can never do better than irreducible error, right?",
    "start": "2789545",
    "end": "2797750"
  },
  {
    "text": "So that's like our- our- the best we can hope for. And then we have these extra two terms, bias and variance.",
    "start": "2797750",
    "end": "2804860"
  },
  {
    "text": "So if you want to reduce generalization error, then we need to reduce either bias or variance or both.",
    "start": "2804860",
    "end": "2811340"
  },
  {
    "text": "Unfortunately, what we saw was some steps such as",
    "start": "2811340",
    "end": "2816440"
  },
  {
    "text": "regularization will- if we tune the regularization to reduce the bias,",
    "start": "2816440",
    "end": "2823685"
  },
  {
    "text": "it increases the variance. If you tune it to reduce the variance, it increases the bias, right?",
    "start": "2823685",
    "end": "2828800"
  },
  {
    "text": "So that's- that's- that's like, um, um, that's the fundamental trade-off that we need to work with to-",
    "start": "2828800",
    "end": "2835234"
  },
  {
    "text": "to find some kind of an optimal- optimal, uh, uh, minimizer of the sum of these two terms.",
    "start": "2835235",
    "end": "2842329"
  },
  {
    "text": "Right? And there was a question that was asked, why not try to analytically minimize this?",
    "start": "2842330",
    "end": "2847744"
  },
  {
    "text": "And in to- to analytically minimize this, we need to be able to compute f of x star.",
    "start": "2847745",
    "end": "2852994"
  },
  {
    "text": "Without being able to compute f of x star, we cannot min- find the right balance to minimize the sum of the two.",
    "start": "2852995",
    "end": "2859310"
  },
  {
    "text": "And therefore, what we are left with is to use cross-validation. So what we do is take a validation set.",
    "start": "2859310",
    "end": "2866920"
  },
  {
    "text": "We discussed cross-validation, uh, in the last lecture. Have a validation set,",
    "start": "2866920",
    "end": "2872315"
  },
  {
    "text": "and- and keep that away when you're fitting your model. Once you fit your model with some specific value of lambda,",
    "start": "2872315",
    "end": "2880144"
  },
  {
    "text": "see how well your- the fitted model, which is regularized, performs on the cross-validation set.",
    "start": "2880144",
    "end": "2886025"
  },
  {
    "text": "Right? And then when you measure it on the cross-validation set, you're measuring the overall mean squared error.",
    "start": "2886025",
    "end": "2893105"
  },
  {
    "text": "We- we're not- we're not measuring the individual components. When you measure the- the error made by the model on the cross-validation set,",
    "start": "2893105",
    "end": "2900530"
  },
  {
    "text": "we're measuring the overall error. Right? And then we now start tuning the lambda parameter to different values.",
    "start": "2900530",
    "end": "2907940"
  },
  {
    "text": "Increase it a little, decrease it a little. And with the tuned values, measure the performance on the cross-validation error again.",
    "start": "2907940",
    "end": "2916295"
  },
  {
    "text": "And tune it such that the- the- the overall, uh, mean squared error on the cross-validation,",
    "start": "2916295",
    "end": "2923030"
  },
  {
    "text": "you find some kind of a good minimum. By doing that process, you are automatically optimizing for",
    "start": "2923030",
    "end": "2930109"
  },
  {
    "text": "the overall mean squared error and implicitly finding a trade off between bias and variance. Right? It's very hard to get",
    "start": "2930110",
    "end": "2937175"
  },
  {
    "text": "an exact breakdown of what was the irreducible error component, what was the bias component,",
    "start": "2937175",
    "end": "2942680"
  },
  {
    "text": "what was the variance component. But the theory suggests that by tuning lambda,",
    "start": "2942680",
    "end": "2947779"
  },
  {
    "text": "we're gonna have- we're gonna have some kind of a trade off between bias and variance. And there may be, and there probably is,",
    "start": "2947779",
    "end": "2954545"
  },
  {
    "text": "some kind of an optimal lambda that finds a suitable trade-off between the two.",
    "start": "2954545",
    "end": "2959555"
  },
  {
    "text": "And the way we do about, uh, the way we go about doing that in practice is using a cross validation set, where we are directly trying to minimize the- the overall mean squared error,",
    "start": "2959555",
    "end": "2969905"
  },
  {
    "text": "uh, without actually finding out what the exact, uh, broken down components was.",
    "start": "2969905",
    "end": "2975060"
  },
  {
    "text": "Right? The other, um,",
    "start": "2976240",
    "end": "2981425"
  },
  {
    "text": "I guess the- the larger takeaway from this is that even beyond regularization,",
    "start": "2981425",
    "end": "2988940"
  },
  {
    "text": "in machine learning, as I said before, what we care about is reducing the mean squared error.",
    "start": "2988940",
    "end": "2995825"
  },
  {
    "text": "Right? And if we want to reduce mean squared error,",
    "start": "2995825",
    "end": "3001450"
  },
  {
    "text": "we want to take some action that either addresses bias or addresses variants.",
    "start": "3001450",
    "end": "3007135"
  },
  {
    "text": "Right? And in order to- to, uh, make the judgment of whether we want to go after bias or go after variants,",
    "start": "3007135",
    "end": "3014485"
  },
  {
    "text": "we need to get some kind of heuristic estimate of what the current bias value is and what the current variance value is.",
    "start": "3014485",
    "end": "3021265"
  },
  {
    "text": "Right? But as I said already, unfortunately it's not possible to get, you know, a closed form expression because f of x star is unknown.",
    "start": "3021265",
    "end": "3028990"
  },
  {
    "text": "That's- that's- that- that's the heart of the problem. We don't know what f of, uh, x star is. Uh, if we knew it, we could exactly calculate bias component and variance component.",
    "start": "3028990",
    "end": "3038185"
  },
  {
    "text": "But, uh, but- but- but we don't have access to f. So instead,",
    "start": "3038185",
    "end": "3044590"
  },
  {
    "text": "uh, what we do is we fall back to heuristics. So the heuristics is that-",
    "start": "3044590",
    "end": "3050470"
  },
  {
    "text": "[NOISE]",
    "start": "3050470",
    "end": "3051680"
  },
  {
    "text": "All right? So this is a heuristic that is extremely useful in practice.",
    "start": "3099540",
    "end": "3107125"
  },
  {
    "text": "It is- if you change this approximately equal to- equal to,",
    "start": "3107125",
    "end": "3112240"
  },
  {
    "text": "and it's very wrong because the training error is not your bias and the cross-validation error minus training error is not the variance,",
    "start": "3112240",
    "end": "3119185"
  },
  {
    "text": "but they're extremely useful heuristics. So when you're trying to- to, uh,",
    "start": "3119185",
    "end": "3125200"
  },
  {
    "text": "build a model that gives us better generalization error,",
    "start": "3125200",
    "end": "3130300"
  },
  {
    "text": "as I said again, our goal is to minimize generalization error. Our goal is to not go after bias or variance by itself,",
    "start": "3130300",
    "end": "3137920"
  },
  {
    "text": "but we do that in o- just in order to minimize the generalization error.",
    "start": "3137920",
    "end": "3143079"
  },
  {
    "text": "And in order to minimize the generalization error, we always want to get a rough sense of the breakdown between bias and",
    "start": "3143080",
    "end": "3151029"
  },
  {
    "text": "variance components that are contributing to the generalization error.",
    "start": "3151030",
    "end": "3156085"
  },
  {
    "text": "And rough heuristic, again, is to consider the training error as the bias",
    "start": "3156085",
    "end": "3161695"
  },
  {
    "text": "and the gap between the cross validation error and the training error as the variance. Okay? So when we want to improve our generalization error,",
    "start": "3161695",
    "end": "3172710"
  },
  {
    "text": "we first need to find out what's the breakdown and go after the component that is larger.",
    "start": "3172710",
    "end": "3179839"
  },
  {
    "text": "We never want to take an arbitrary step, such as, you know, get more data or add more regularization or reduce regularization.",
    "start": "3179840",
    "end": "3189145"
  },
  {
    "text": "There are- there are a whole number of things you can do to improve, uh, generalization error. But it would be extremely wrong if you just tried them arbitrarily, right?",
    "start": "3189145",
    "end": "3198490"
  },
  {
    "text": "That's- that's probably the biggest takeaway from this lecture, and probably, the biggest take away from this course. In machine learning, we want to reduce generalization error,",
    "start": "3198490",
    "end": "3206245"
  },
  {
    "text": "and the way you go about reducing generalization error is to construct heuristic estimates of the components r,",
    "start": "3206245",
    "end": "3214195"
  },
  {
    "text": "and the heuristic estimates are the training error and the cross validation error. And only once we come up with these heuristic estimates,",
    "start": "3214195",
    "end": "3223120"
  },
  {
    "text": "we make a conscious decision of whether in the next step we want to reduce bias or we want to reduce variance.",
    "start": "3223120",
    "end": "3230935"
  },
  {
    "text": "And the way you go about making the decision is to see which of these two is- is like the larger leeway.",
    "start": "3230935",
    "end": "3236650"
  },
  {
    "text": "Is your training error so large and the gap between your cross validation and training error so small that you,",
    "start": "3236650",
    "end": "3242470"
  },
  {
    "text": "you know, better go after your bias first, which means to improve bias- to improve bias",
    "start": "3242470",
    "end": "3255099"
  },
  {
    "text": "or maybe to fight bias, is probably the better term, to fight bias,",
    "start": "3255100",
    "end": "3264610"
  },
  {
    "text": "we do things like make model larger.",
    "start": "3264610",
    "end": "3272155"
  },
  {
    "text": "So if it is a neural network, then add more layers or add more neurons in each layer,",
    "start": "3272155",
    "end": "3277315"
  },
  {
    "text": "reduce regularization, you know, etc.",
    "start": "3277315",
    "end": "3286720"
  },
  {
    "text": "And to fight variance,",
    "start": "3286720",
    "end": "3292580"
  },
  {
    "text": "we do things like increase regularization,",
    "start": "3293970",
    "end": "3299720"
  },
  {
    "text": "or collect more data, right?",
    "start": "3308010",
    "end": "3315865"
  },
  {
    "text": "And- and the way you go about improving- uh, you know, am- am- am repeating this again because this is- you know,",
    "start": "3315865",
    "end": "3323035"
  },
  {
    "text": "this is probably at the heart of this entire lecture that, our goal is to minimize mean squared error.",
    "start": "3323035",
    "end": "3330085"
  },
  {
    "text": "And to minimize mean squared error, in theory, there are so many possible actions that you can take.",
    "start": "3330085",
    "end": "3336535"
  },
  {
    "text": "But before you go about taking any action, you want to come up with some, kind of,",
    "start": "3336535",
    "end": "3341590"
  },
  {
    "text": "a heuristic estimate of what the breakdown is. What does the amount of, you know, estimate of the bias in our-, um,",
    "start": "3341590",
    "end": "3349030"
  },
  {
    "text": "um, in- in our generalization and what's the estimate of variance. And once you get this breakdown,",
    "start": "3349030",
    "end": "3356244"
  },
  {
    "text": "we then make a conscious decision of whether we want to fight bias or we want to fight variance in the next step.",
    "start": "3356245",
    "end": "3362695"
  },
  {
    "text": "And in order to fight that particular- of the two evils, we choose one of the actions that help us fight that component. Yes, question.",
    "start": "3362695",
    "end": "3373050"
  },
  {
    "text": "Do we not consider reducing the flexibility to fight variance of the model [inaudible]. Yeah, yeah, absolutely. So the question is,",
    "start": "3373050",
    "end": "3379510"
  },
  {
    "text": "do we not consider reducing the flexibility of the model to fight variance? Absolutely. In our simpler model- so this- this is not an exhaustive list,",
    "start": "3379510",
    "end": "3388690"
  },
  {
    "text": "but these are just some examples. You know, simpler model, absolutely. More complex model.",
    "start": "3388690",
    "end": "3395390"
  },
  {
    "text": "Yes, question. I can see how we can never achieve those estimation that bias plays exactly.",
    "start": "3402270",
    "end": "3408505"
  },
  {
    "text": "But we know that, like, f star is a function of Theta star,",
    "start": "3408505",
    "end": "3413740"
  },
  {
    "text": "like I drew underlying processes as a function of Theta star, and Theta star and the expectation of",
    "start": "3413740",
    "end": "3420234"
  },
  {
    "text": "our estimated Theta is a function of Theta star from that matrix, and we can plot the different diagonal values,",
    "start": "3420235",
    "end": "3427240"
  },
  {
    "text": "as like, as the- a very weird kind of curve where we can take all diagonal values in",
    "start": "3427240",
    "end": "3432819"
  },
  {
    "text": "the first matrix and all the diagonal values in the second matrix, and you can find a huge, sort of, curve.",
    "start": "3432820",
    "end": "3438700"
  },
  {
    "text": "They keep- keep changing Lambda, that theoretical value of those diagonals will be j theta, right?",
    "start": "3438700",
    "end": "3444295"
  },
  {
    "text": "And if we take that [inaudible] curve and find that minimum of that- that curve, we'll be able to optimize those [inaudible] ,",
    "start": "3444295",
    "end": "3453430"
  },
  {
    "text": "and we do not need to go after Theta star. So the question is, um,",
    "start": "3453430",
    "end": "3458619"
  },
  {
    "text": "I guess- I guess you're- you're, uh- what you're, uh, suggesting is a few ways in which, uh, using this analysis, we can, you know,",
    "start": "3458620",
    "end": "3465730"
  },
  {
    "text": "try to come up with optimal values of- of Lambda that minimizes, like, the sum of both the errors, right?",
    "start": "3465730",
    "end": "3471760"
  },
  {
    "text": "The- the- uh, so the- so the first problem with that is such an analysis is possible only for simple models, right?",
    "start": "3471760",
    "end": "3479590"
  },
  {
    "text": "If you want to increase the- the- uh, for example, if you want to reduce the bias of your model, you- you may want to switch from linear regression to,",
    "start": "3479590",
    "end": "3486760"
  },
  {
    "text": "say, a neural network or a Gaussian process, right? And once you do that, you know, this analysis breaks down at that point.",
    "start": "3486760",
    "end": "3493570"
  },
  {
    "text": "And- and, uh, this exercise of seeing the breakdown is useful to get,",
    "start": "3493570",
    "end": "3499210"
  },
  {
    "text": "like, an intuition- a mathematical intuition of what's happening underneath. Uh, but in order to take some real-world action,",
    "start": "3499210",
    "end": "3505900"
  },
  {
    "text": "you want to follow recipes like this, right? If you wanna- if you- if you see that your model is not fitting,",
    "start": "3505900",
    "end": "3511510"
  },
  {
    "text": "you know, your- your examples- uh, you- your data well, your- to fight bias, you could say add more features, right?",
    "start": "3511510",
    "end": "3518500"
  },
  {
    "text": "And once you do that, your entire covariance matrix is no more of use because it's now a larger covariance matrix with an extra dimension.",
    "start": "3518500",
    "end": "3525070"
  },
  {
    "text": "So it's- it's- the- the actions that you take are- are- like, they are- they're, kind of, beyond that simple analysis.",
    "start": "3525070",
    "end": "3532299"
  },
  {
    "text": "Also in the first equation we have a theta star, is that decision going to be influenced by what theta star actually is, let's suppose we already know what theta star is,",
    "start": "3532300",
    "end": "3542620"
  },
  {
    "text": "will our decisions going to be influenced by that Theta star because [OVERLAPPING]",
    "start": "3542620",
    "end": "3547630"
  },
  {
    "text": "So the question is, are our decisions influenced by Theta star, right?",
    "start": "3547630",
    "end": "3553000"
  },
  {
    "text": "So Theta star is unknown, because if it was known, then we wouldn't even go through this exercise of taking data and fitting models, right?",
    "start": "3553000",
    "end": "3560785"
  },
  {
    "text": "And it is- because it is unknown, that- uh, that we- we come up with, uh, this,",
    "start": "3560785",
    "end": "3567819"
  },
  {
    "text": "kind of an analysis to see, you know, how- how- how, uh, bias and variance can- can,",
    "start": "3567820",
    "end": "3573250"
  },
  {
    "text": "uh, uh, impact us. All right. Uh, any questions on this before we move on to- to,",
    "start": "3573250",
    "end": "3580810"
  },
  {
    "text": "uh, the next part, uniform convergence. All right, so let's move on.",
    "start": "3580810",
    "end": "3588530"
  },
  {
    "text": "So what follows next in this lecture is gonna be, uh, a quick high-level introduction",
    "start": "3597870",
    "end": "3606010"
  },
  {
    "text": "or overview of statistical learning theory or- or- or like,",
    "start": "3606010",
    "end": "3611770"
  },
  {
    "text": "uh, the general, kind of, flavor of how statistical learning theory is.",
    "start": "3611770",
    "end": "3617045"
  },
  {
    "text": "What are, like, the common- what's the common framework of analysis, and- and, you know,",
    "start": "3617045",
    "end": "3622680"
  },
  {
    "text": "what are the kinds of things we could do with statistical learning theory? And this would be especially interesting to- to those who",
    "start": "3622680",
    "end": "3631060"
  },
  {
    "text": "have an interest to move to machine learning research. But also the results that we see will",
    "start": "3631060",
    "end": "3637390"
  },
  {
    "text": "kind of strengthen our intuitions about bias and variance.",
    "start": "3637390",
    "end": "3642049"
  },
  {
    "text": "So for statistical learning theory, so let's-",
    "start": "3653030",
    "end": "3658510"
  },
  {
    "text": "so we make a, uh, so a common assumption that- that's kind of widely made in",
    "start": "3672800",
    "end": "3681990"
  },
  {
    "text": "statistical learning theory or- or in most theory is that our training and test data,",
    "start": "3681990",
    "end": "3688990"
  },
  {
    "text": "they come from the same distribution. [NOISE] If- if this assumption is not there,",
    "start": "3691550",
    "end": "3701490"
  },
  {
    "text": "it's very hard to say anything at all in general. So the- the, uh, the underlying assumption that we're going to make is that",
    "start": "3701490",
    "end": "3708780"
  },
  {
    "text": "our training and test data come from the same distribution, and our examples are sampled IID.",
    "start": "3708780",
    "end": "3717030"
  },
  {
    "text": "[NOISE]",
    "start": "3717030",
    "end": "3727220"
  },
  {
    "text": "So there's in each example a samp- a sample independently of any other example that we've had,",
    "start": "3727220",
    "end": "3732484"
  },
  {
    "text": "and at test and train time, we are- we are working with a data that's coming from the same distribution.",
    "start": "3732485",
    "end": "3739470"
  },
  {
    "text": "And now with these, we define the following terms. So the risk of an estimator,",
    "start": "3739470",
    "end": "3748540"
  },
  {
    "text": "so let's call this distribution as D. Risk of an estimator is defined as,",
    "start": "3752240",
    "end": "3760540"
  },
  {
    "text": "let's call it a risk of a hypothesis.",
    "start": "3763760",
    "end": "3767740"
  },
  {
    "text": "So the risk of a hypothesis is defined as the expectation of x, y",
    "start": "3772190",
    "end": "3781020"
  },
  {
    "text": "sampled from this distribution of loss of y and h of x.",
    "start": "3781020",
    "end": "3792280"
  },
  {
    "text": "Right? So h over here is our hypothesis.",
    "start": "3794480",
    "end": "3801945"
  },
  {
    "text": "It's a function that takes as input some x and produces y as an output.",
    "start": "3801945",
    "end": "3807210"
  },
  {
    "text": "So the risk associated with this function, right? So this is also called as a risk functional because it",
    "start": "3807210",
    "end": "3814920"
  },
  {
    "text": "takes as input a function and returns as output a real value. So the risk of a hypothesis is",
    "start": "3814920",
    "end": "3823620"
  },
  {
    "text": "the expected loss made by that hypothesis under some kind of a loss- loss function.",
    "start": "3823620",
    "end": "3831480"
  },
  {
    "text": "So this is, you know, generally accuracy of squared error or- or, uh, something along that star where the data that we are using to feed",
    "start": "3831480",
    "end": "3838830"
  },
  {
    "text": "as input to x and compare it to the y are sampled from the data distribution. Right? So this is the definition of the risk of the hypothesis.",
    "start": "3838830",
    "end": "3850080"
  },
  {
    "text": "Now, suppose, um, there's a related pair,",
    "start": "3850080",
    "end": "3856890"
  },
  {
    "text": "if S is some set of x^i, y^i pairs,",
    "start": "3856890",
    "end": "3867000"
  },
  {
    "text": "i equals one to n. So if S to some training set, then redefine the empirical risk",
    "start": "3867000",
    "end": "3876820"
  },
  {
    "text": "as Epsilon hat of h is equal to 1 over",
    "start": "3883160",
    "end": "3890369"
  },
  {
    "text": "the size of the dataset times the sum over x plus y in S,",
    "start": "3890370",
    "end": "3898215"
  },
  {
    "text": "loss y comma hx, right?",
    "start": "3898215",
    "end": "3908685"
  },
  {
    "text": "It's very similar to the risk definition, except instead of taking a full expectation over the entire data generating distribution,",
    "start": "3908685",
    "end": "3918915"
  },
  {
    "text": "we just limit ourselves to taking an average over the training set that we- that we have, right?",
    "start": "3918915",
    "end": "3924525"
  },
  {
    "text": "and this is called empirical risk. Now, what we want to do ideally, or,",
    "start": "3924525",
    "end": "3934005"
  },
  {
    "text": "you know, the best we could hope for, is to find some kind of a hypothesis that minimizes the risk.",
    "start": "3934005",
    "end": "3941385"
  },
  {
    "text": "That's we what- that's what we want to do. That's our, um, um, that's- that's our desire to me- to find an h that minimizes the true expected risk.",
    "start": "3941385",
    "end": "3951950"
  },
  {
    "text": "But what we actually do in practice is to find a hypothesis that",
    "start": "3951950",
    "end": "3958620"
  },
  {
    "text": "minimizes the empirical risk because we have some- some training data. We construct a loss function over it and we minimize the empirical risk instead, right?",
    "start": "3958620",
    "end": "3966569"
  },
  {
    "text": "And that's what, you know, uh, you've- you've- you've seen, um, this so many times. You have done it in your homework,",
    "start": "3966570",
    "end": "3972390"
  },
  {
    "text": "linear regression, you know. We use a design matrix. We take the labels and use the normal equations to minimize the empirical risk.",
    "start": "3972390",
    "end": "3980730"
  },
  {
    "text": "Right? So the questions- uh, the question that- that comes into mind is,",
    "start": "3980730",
    "end": "3986100"
  },
  {
    "text": "what's the relation between, you know, for, uh,",
    "start": "3986100",
    "end": "3991140"
  },
  {
    "text": "given h, what is",
    "start": "3991140",
    "end": "3999099"
  },
  {
    "text": "the relation between Epsilon hat",
    "start": "3999100",
    "end": "4007175"
  },
  {
    "text": "of h and Epsilon of h? Right? How does the training error relate",
    "start": "4007175",
    "end": "4014809"
  },
  {
    "text": "to the generalization error for any given hypothesis? Right? You know, that's an interesting question. And the other question is,",
    "start": "4014810",
    "end": "4022890"
  },
  {
    "text": "how does our generalization error",
    "start": "4024700",
    "end": "4034589"
  },
  {
    "text": "compare to the best possible generalization error?",
    "start": "4036040",
    "end": "4045960"
  },
  {
    "text": "Right? So our training error is something that we can measure.",
    "start": "4055510",
    "end": "4061475"
  },
  {
    "text": "The generalization error is something that we cannot measure, right? But we- we're gonna use some theory to make statements about or give you bounds on how",
    "start": "4061475",
    "end": "4069590"
  },
  {
    "text": "well our general- what our generalization error will be given that our training error is some value. Okay? Similarly, what's, I guess, you know, um,",
    "start": "4069590",
    "end": "4079490"
  },
  {
    "text": "what's- what's- what's important at the end of the day is how well is our generalization performance compared",
    "start": "4079490",
    "end": "4085640"
  },
  {
    "text": "to the best possible generalization performance that you can get. Right? And here we are comparing two,",
    "start": "4085640",
    "end": "4091880"
  },
  {
    "text": "you know, two things, both of which we cannot measure, right? We- we have no idea how well our generalization error is",
    "start": "4091880",
    "end": "4097384"
  },
  {
    "text": "and we have no idea what the best possible generalization error is either, right? But we still want to make some kind of probabilistic statements or give",
    "start": "4097385",
    "end": "4104210"
  },
  {
    "text": "us bounds on the gap between the two, right? If we know that our- the- the generalization error of",
    "start": "4104210",
    "end": "4111529"
  },
  {
    "text": "our model is within some small range of the best possible generalization error,",
    "start": "4111530",
    "end": "4116750"
  },
  {
    "text": "then you know, we're happy, right? Or we may not be happy with, you know, happy with the result itself, but we know that we are- we are pretty close to what's theoretically possible.",
    "start": "4116750",
    "end": "4126020"
  },
  {
    "text": "So in order to kind of get a better understanding of each of- of these two,",
    "start": "4126020",
    "end": "4133470"
  },
  {
    "text": "let's define, uh, you know, some terminology.",
    "start": "4133570",
    "end": "4137759"
  },
  {
    "text": "So on the x-axis, we have the set of all possible hypotheses.",
    "start": "4145420",
    "end": "4151609"
  },
  {
    "text": "What I mean by set of all possible hypotheses, I literally mean set of all possible hypotheses",
    "start": "4151610",
    "end": "4157310"
  },
  {
    "text": "like the set of all possible neural networks, the set of all possible SVMs, set of all possible Gaussian processes,",
    "start": "4157310",
    "end": "4162710"
  },
  {
    "text": "set of all possible models that are not yet invented today, you know, every possible hypothesis,",
    "start": "4162710",
    "end": "4167764"
  },
  {
    "text": "you know, comes on the x-axis. And we're going to linearize it to- to make the visualization simple,",
    "start": "4167764",
    "end": "4174350"
  },
  {
    "text": "but, you know, imagine you have all possible hypotheses on- on the x-axis. And on the y-axis, we're going to have risk.",
    "start": "4174350",
    "end": "4181920"
  },
  {
    "text": "Okay? Now- was there a question? [BACKGROUND] Right? Yeah, so- yeah,",
    "start": "4183760",
    "end": "4193375"
  },
  {
    "text": "so what I mean by hypothesis, the set of all possible predictive models you can- you can think of, you know, random forest, neural networks,",
    "start": "4193375",
    "end": "4199090"
  },
  {
    "text": "everything, you know, comes- comes on this axis. Now, on the y-axis, we have risk.",
    "start": "4199090",
    "end": "4204420"
  },
  {
    "text": "And supposing we indeed had access to the true data-generating distribution, right?",
    "start": "4204420",
    "end": "4210739"
  },
  {
    "text": "Hypothetically, we had access to the true data-generating distribution and we could",
    "start": "4210740",
    "end": "4215750"
  },
  {
    "text": "take an infinite number of samples, right? We could pick the entire infinite set of samples from the distribution.",
    "start": "4215750",
    "end": "4225920"
  },
  {
    "text": "Take one of these hypothesis and measure the empirical- measure the- the, uh,",
    "start": "4225920",
    "end": "4232760"
  },
  {
    "text": "expected loss of that hypothesis at the, uh, uh, against all- the entire infinite set of examples and that's what gives the point.",
    "start": "4232760",
    "end": "4243540"
  },
  {
    "text": "Right? So this is the hypothesis that we feed in over here and this is the value it evaluates to,  the risk.",
    "start": "4244330",
    "end": "4253505"
  },
  {
    "text": "Right? And similarly, we can- we can repeat that for every possible hypothesis,",
    "start": "4253505",
    "end": "4258605"
  },
  {
    "text": "you know, across all models, and that's going to give us some kind of some kind of a risk function.",
    "start": "4258605",
    "end": "4268910"
  },
  {
    "text": "[BACKGROUND] So this is not empirical risk. We are talking about the true risk.",
    "start": "4268910",
    "end": "4275375"
  },
  {
    "text": "You know, assume you get the entire infinite sample and- and you- you, um, uh, evaluate the, uh, the loss and,",
    "start": "4275375",
    "end": "4282665"
  },
  {
    "text": "you know, let's assume this is the- the- the kind of loss you get. You know, thi- this is the risk.",
    "start": "4282665",
    "end": "4287809"
  },
  {
    "text": "However, we don't have access to this. Right? We wish we did have access to it and",
    "start": "4287810",
    "end": "4293929"
  },
  {
    "text": "then we could just minimize it if we had access to it, but we don't have access to it. What we instead have is a finite sample S and from this S,",
    "start": "4293930",
    "end": "4305525"
  },
  {
    "text": "we can construct the empirical risk. And the empirical risk might look something like this. [NOISE]",
    "start": "4305525",
    "end": "4318364"
  },
  {
    "text": "Right? It's gonna be some kind of an approximation. And this gap between the true risk and the empirical risk is intuitively,",
    "start": "4318365",
    "end": "4329225"
  },
  {
    "text": "you know, you can think of this gap to be a function of your dataset size, right? As you get more and more dataset,",
    "start": "4329225",
    "end": "4335270"
  },
  {
    "text": "as this n increases, then the empirical risk and the true risk, they- they become tighter and tighter.",
    "start": "4335270",
    "end": "4342095"
  },
  {
    "text": "You know, the- the empirical risk gets closer to, um, uh, the true risk. Now, this particular risk function is specific to",
    "start": "4342095",
    "end": "4351770"
  },
  {
    "text": "one set- one specific set of training set that we have.",
    "start": "4351770",
    "end": "4357650"
  },
  {
    "text": "If we take another training set of the same size, that might give us a different [NOISE] risk function, right?",
    "start": "4357650",
    "end": "4369140"
  },
  {
    "text": "So these- you know, think of these two as two examples of risk functions or loss functions that we get from two different training sets.",
    "start": "4369140",
    "end": "4376550"
  },
  {
    "text": "Both of the training sets are sampled from the same data generating distribution, and they have the same size, right?",
    "start": "4376550",
    "end": "4381710"
  },
  {
    "text": "And if you keep repeating this again and again, we're gonna get more and more such, you know, dotted lines,",
    "start": "4381710",
    "end": "4387575"
  },
  {
    "text": "more and more such empirical risks that are spread about the- the true risk with some variance.",
    "start": "4387575",
    "end": "4393905"
  },
  {
    "text": "And if- you know, you can imagine that if we- if we increase the dataset size, then the spread around the true risk will be much tighter, [NOISE] right?",
    "start": "4393905",
    "end": "4403205"
  },
  {
    "text": "We'll- we'll formalize that, uh, shortly. Now, the true risk, right?",
    "start": "4403205",
    "end": "4411784"
  },
  {
    "text": "The true risk, that's the- the- the thick line is minimized at some point, right?",
    "start": "4411785",
    "end": "4418370"
  },
  {
    "text": "The gap between, you know, this minimal point and the x axis, this gap is the irreducible error.",
    "start": "4418370",
    "end": "4426770"
  },
  {
    "text": "[NOISE] Right?",
    "start": "4426770",
    "end": "4432380"
  },
  {
    "text": "No matter what model you get, you know, model invented, you know, 10 years from now, no matter what model you get,",
    "start": "4432380",
    "end": "4437675"
  },
  {
    "text": "you can never do better than the irreducible error, right? Because- that's just because your data is noisy. Yes, question?",
    "start": "4437675",
    "end": "4444000"
  },
  {
    "text": "How do we know that the irreducible error can be reached by at least one [inaudible] So the question is, how do we know that",
    "start": "4444700",
    "end": "4451490"
  },
  {
    "text": "the irreducible error is- can be reached by, you know, some model? Uh, by definition, if you ha- use non-parametric models and you have the model, um, you know, um,",
    "start": "4451490",
    "end": "4460100"
  },
  {
    "text": "[NOISE] h of x [NOISE] equals expectation of Y given X equals x.",
    "start": "4460100",
    "end": "4469255"
  },
  {
    "text": "You know, uh, uh, a non-parametric model, uh, uh, this function will give you this, right?",
    "start": "4469255",
    "end": "4476600"
  },
  {
    "text": "But you may not be able to approximate this well with- with- with, you know, some function. But there exists a function that is gonna minimize your,",
    "start": "4476600",
    "end": "4483514"
  },
  {
    "text": "uh, true risk to- to the absolute minimum. And that minimum is the irreducible error, right?",
    "start": "4483515",
    "end": "4490835"
  },
  {
    "text": "So this is with the assumption that we're using the squared loss. So the squared loss is minimized by the mean. If you use like the absolute value,",
    "start": "4490835",
    "end": "4497030"
  },
  {
    "text": "then instead of the expectation, take the median and so on, right? But- but that- there exists some- some- some function that's gonna minimize it.",
    "start": "4497030",
    "end": "4503705"
  },
  {
    "text": "Right? So this is the irreducible error. Now, however, we're gonna limit our analysis to a class of models.",
    "start": "4503705",
    "end": "4513364"
  },
  {
    "text": "Right? We're gonna limit ourselves to just say, the set of all neural networks,",
    "start": "4513365",
    "end": "4518659"
  },
  {
    "text": "random forests, and SVMs, and logistic regression, right? We're gonna limit ourselves to a class of models, right?",
    "start": "4518660",
    "end": "4527465"
  },
  {
    "text": "And this class of models, this interval on the x-axis,",
    "start": "4527465",
    "end": "4533810"
  },
  {
    "text": "I'm going to call it script capital H, [NOISE] right? Which is class of model- class of",
    "start": "4533810",
    "end": "4540470"
  },
  {
    "text": "hypothesis- [NOISE] hypothesis, right?",
    "start": "4540470",
    "end": "4548540"
  },
  {
    "text": "And what we didn't see is this class of- within this class of models,",
    "start": "4548540",
    "end": "4553805"
  },
  {
    "text": "the best possible risk that we can hope for is found here.",
    "start": "4553805",
    "end": "4560765"
  },
  {
    "text": "Right? So this is the point within the class of models that minimizes the risk the most. And here, I'm talking about the true risk,",
    "start": "4560765",
    "end": "4567800"
  },
  {
    "text": "not the empirical risk. All right? So let's call this h star,",
    "start": "4567800",
    "end": "4574490"
  },
  {
    "text": "which h star is best in class hypothesis.",
    "start": "4574490",
    "end": "4583610"
  },
  {
    "text": "[NOISE] Right? So this is the best in class hypothesis.",
    "start": "4583610",
    "end": "4589835"
  },
  {
    "text": "And the difference between the two, [NOISE] this gap, it's called the approximation error.",
    "start": "4589835",
    "end": "4602690"
  },
  {
    "text": "[NOISE] Right?",
    "start": "4602690",
    "end": "4610745"
  },
  {
    "text": "It's called the approximation error because this is the penalty that we incur by limiting ourselves to a particular class of models.",
    "start": "4610745",
    "end": "4618545"
  },
  {
    "text": "Right? If- if- if we did not limit ourselves to, you know, this class, but if we use a wider class,",
    "start": "4618545",
    "end": "4625445"
  },
  {
    "text": "then our best-in-class would have been the same as the, you know, irreducible, uh, error. But because we are approximating the hypothesis by some class of hypotheses,",
    "start": "4625445",
    "end": "4634145"
  },
  {
    "text": "then this is the extra- the extra penalty that we are paying due to limiting ourselves. Right? That's called the approximation error.",
    "start": "4634145",
    "end": "4641145"
  },
  {
    "text": "However, that- the- the model that we say end up",
    "start": "4641145",
    "end": "4646160"
  },
  {
    "text": "using is the one that we get by minimizing the empirical error.",
    "start": "4646160",
    "end": "4652010"
  },
  {
    "text": "Okay? So it is the empirical risk that we minimize in order to come up with a model, right?",
    "start": "4652010",
    "end": "4657815"
  },
  {
    "text": "Now, if this dotted line- so let me erase the other dotted line to- [NOISE]",
    "start": "4657815",
    "end": "4678590"
  },
  {
    "text": "so in practice, what we do is we take a training set and we get this as our loss function,",
    "start": "4678590",
    "end": "4684889"
  },
  {
    "text": "and we minimize this loss function. And the point where we minimize,",
    "start": "4684890",
    "end": "4690455"
  },
  {
    "text": "we get the hypothesis, let's call it h hat. Right? That's the estimated hypothesis, right?",
    "start": "4690455",
    "end": "4696740"
  },
  {
    "text": "So in case of linear regression, this corresponds to the Theta hat vector that we get. All right?",
    "start": "4696740",
    "end": "4702110"
  },
  {
    "text": "[NOISE] And now,",
    "start": "4702110",
    "end": "4707344"
  },
  {
    "text": "because we- we- let me move this a little to the right so that it's easier to visualize.",
    "start": "4707345",
    "end": "4715159"
  },
  {
    "text": "[NOISE] Let's assume this is where we get h hat.",
    "start": "4715160",
    "end": "4721950"
  },
  {
    "text": "Now, this is where the- the uh, empirical risk was minimized,",
    "start": "4726130",
    "end": "4731735"
  },
  {
    "text": "and the corresponding generalization error is over here.",
    "start": "4731735",
    "end": "4738020"
  },
  {
    "text": "Right? And this gap is called the excess risk or the estimation error,",
    "start": "4738020",
    "end": "4748130"
  },
  {
    "text": "or the excess risk, you can call it both of them. Let us call it excess risk.",
    "start": "4748130",
    "end": "4752880"
  },
  {
    "text": "Right? So [NOISE] that is one part that is the irreducible error,",
    "start": "4757030",
    "end": "4763175"
  },
  {
    "text": "it cannot do better than that no matter what. There is another part called the approximation error which we- it's",
    "start": "4763175",
    "end": "4770780"
  },
  {
    "text": "just the penalty that we pay by limiting ourselves to a class of hypotheses, right?",
    "start": "4770780",
    "end": "4776135"
  },
  {
    "text": "And there's yet another component called the excess risk, it's also called the estimation error.",
    "start": "4776135",
    "end": "4781730"
  },
  {
    "text": "And this is the penalty that we pay for having a limited dataset,",
    "start": "4781730",
    "end": "4786905"
  },
  {
    "text": "a finite data set, rather than the full infinite number of data. Right? Because if we had the full infinite data,",
    "start": "4786905",
    "end": "4793730"
  },
  {
    "text": "then our empirical risk could be exactly on the thick line, and excess risk would reduce to 0because we would just end- uh,",
    "start": "4793730",
    "end": "4800330"
  },
  {
    "text": "I don't know, finding this as our empirical risk minimizer. Yes, question? Are we are actually doing better than the- just like [NOISE] your actual x-axis,",
    "start": "4800330",
    "end": "4809210"
  },
  {
    "text": "that should be less, right? Yeah, so we want- we want to find points such that the risk is minimized.",
    "start": "4809210",
    "end": "4815014"
  },
  {
    "text": "So going higher up is bad. But if we compare it to the irreducible error, we are are actually doing greater than just going with the optimal line.",
    "start": "4815015",
    "end": "4822260"
  },
  {
    "text": "So we're doing worse than the irreducible error because irreducible error is even lower. Yeah, but in that [NOISE] class,",
    "start": "4822260",
    "end": "4827570"
  },
  {
    "text": "you can either have extra or ex- excess closer to the reducible error in the next chart, right? So- so- so I wouldn't read too much",
    "start": "4827570",
    "end": "4835715"
  },
  {
    "text": "into the verti- into the horizontal distance between anything. Uh, what we care about is the error incurred, expected error incurred.",
    "start": "4835715",
    "end": "4843710"
  },
  {
    "text": "We want the error to be minimized. So this- this is, you know, the fact that I have even drawn it linearly is- is- is a big,",
    "start": "4843710",
    "end": "4850220"
  },
  {
    "text": "you know, um, uh, uh, simplest- simplification. So don't- don't read too much into the- the horizontal ordering of things.",
    "start": "4850220",
    "end": "4857030"
  },
  {
    "text": "[NOISE] Right? So, um, so what we want now ideally is to minimize this excess risk,",
    "start": "4857030",
    "end": "4865190"
  },
  {
    "text": "or at least get a bound on excess risk, right? And the way we go about doing that",
    "start": "4865190",
    "end": "4870500"
  },
  {
    "text": "is you're gonna break it down into- into two sub-steps. [NOISE]",
    "start": "4870500",
    "end": "4921835"
  },
  {
    "text": "So the way we're gonna do it is first- [NOISE]",
    "start": "4921835",
    "end": "4932830"
  },
  {
    "text": "so step 1, uniform convergence.",
    "start": "4932830",
    "end": "4945310"
  },
  {
    "text": "Step 2, excess risk bound, right?",
    "start": "4945310",
    "end": "4955780"
  },
  {
    "text": "So we're gonna follow these two steps. Where the second step, is- is- is- is very- is- is- is a pretty straightforward step and applies to all models.",
    "start": "4955780",
    "end": "4967450"
  },
  {
    "text": "But the class of model that we use and the loss function that we use, is gonna give us different techniques for doing step one.",
    "start": "4967450",
    "end": "4975565"
  },
  {
    "text": "All right, so roughly speaking, uniform convergence means [BACKGROUND] the intuition behind",
    "start": "4975565",
    "end": "4987790"
  },
  {
    "text": "uniform convergence is that we want our risk function- the-",
    "start": "4987790",
    "end": "4992800"
  },
  {
    "text": "the empirical risk function to converge to the true risk function in a uniform way, right?",
    "start": "4992800",
    "end": "5000240"
  },
  {
    "text": "And we want to make- to- to come up with some kind of a- a probabilistic bound on how far apart the empirical risk function is from the true risk function.",
    "start": "5000240",
    "end": "5011130"
  },
  {
    "text": "[NOISE] So if you're- if you- if you've taken some advanced mathematical classes before,",
    "start": "5011130",
    "end": "5018300"
  },
  {
    "text": "you might be familiar with the concept of functions converting to other functions and that's exactly what's gonna happen here.",
    "start": "5018300",
    "end": "5023850"
  },
  {
    "text": "So this is sum function, the emperor- the true risk is another function. And now we're gonna see how,",
    "start": "5023850",
    "end": "5031185"
  },
  {
    "text": "um, um, the empirical risk functions, as we increase the number of data points we have,",
    "start": "5031185",
    "end": "5037500"
  },
  {
    "text": "will probabilistically convert to the true risk function uniformly across all points, right?",
    "start": "5037500",
    "end": "5043680"
  },
  {
    "text": "That's- that's the- the- that's the intuition to have that we want to minimize the gap uniformly across all hypotheses.",
    "start": "5043680",
    "end": "5052559"
  },
  {
    "text": "So the uniform convergence statement. Um, the statement looks something like this,",
    "start": "5053260",
    "end": "5059400"
  },
  {
    "text": "so with probabilities or WP means with probability. So with probability greater than or equal to 1 minus delta.",
    "start": "5059400",
    "end": "5068910"
  },
  {
    "text": "So delta gen- generally, you know, you wanna think of delta as like a small value. So if you wanna give like a 99%, um,",
    "start": "5068910",
    "end": "5077040"
  },
  {
    "text": "um, uh, probability statement, then delta will be 0.01. If you want to give, you know,",
    "start": "5077040",
    "end": "5082530"
  },
  {
    "text": "with probability 80%, then delta will be 0.2, right? So you think of delta as the gap between",
    "start": "5082530",
    "end": "5087735"
  },
  {
    "text": "1 and the level of probability that you wanna give a statement. So with probability 1 minus delta for",
    "start": "5087735",
    "end": "5096090"
  },
  {
    "text": "all h in h. So we're gonna to limit ourselves to a particular class of hypotheses, right?",
    "start": "5096090",
    "end": "5104895"
  },
  {
    "text": "We are doing our analysis now in the context of a particular class of hypothesis. [NOISE] The generalization error epsilon",
    "start": "5104895",
    "end": "5118620"
  },
  {
    "text": "of h minus epsilon hat of h, is less than equal to sum term gamma.",
    "start": "5118620",
    "end": "5128025"
  },
  {
    "text": "Where this gamma is a term that involves,",
    "start": "5128025",
    "end": "5135824"
  },
  {
    "text": "n delta and class of hypothesis, [NOISE] right?",
    "start": "5135825",
    "end": "5143205"
  },
  {
    "text": "So this is the standard template of all uniform convergence results. And the result is- is- is different for different classes of models,",
    "start": "5143205",
    "end": "5153630"
  },
  {
    "text": "for different loss functions. And, uh, so depending on the class of model that you have,",
    "start": "5153630",
    "end": "5160260"
  },
  {
    "text": "you will obtain, you know, um, a different- uh, you will obtain a term for gamma that- that",
    "start": "5160260",
    "end": "5165780"
  },
  {
    "text": "uses these terms in- in- in some particular way if it- if you're using, uh, lets say, SVMs, then this term is gonna be different.",
    "start": "5165780",
    "end": "5171450"
  },
  {
    "text": "But in general, the term over here is- is- is gonna use it- this is going to be a term over n delta and the, uh, hypothesis.",
    "start": "5171450",
    "end": "5180930"
  },
  {
    "text": "And the statement says, with probability 1 minus delta, you know, think of it as with high probability,",
    "start": "5180930",
    "end": "5187740"
  },
  {
    "text": "for all hypotheses, you know, for all hypothesis on the- on the x-axis, the gap between the- the test error or the generalization error,",
    "start": "5187740",
    "end": "5197235"
  },
  {
    "text": "and the gap between the true risk and the empirical risk for that hypothesis is less than gamma.",
    "start": "5197235",
    "end": "5203910"
  },
  {
    "text": "So it's basically tell you- it's telling you, if you give me a training set size n,",
    "start": "5203910",
    "end": "5212280"
  },
  {
    "text": "the degree of- of- of, uh, confidence you want in the statement and the class of hypothesis,",
    "start": "5212280",
    "end": "5218760"
  },
  {
    "text": "then I will return you some margin, think of gamma as a margin.",
    "start": "5218760",
    "end": "5224325"
  },
  {
    "text": "Such that [NOISE] with probability say, 99%,",
    "start": "5224325",
    "end": "5230995"
  },
  {
    "text": "the gap between the true risk and the empirical- and the empirical risk is gonna be less than gamma with probability 99%,",
    "start": "5230995",
    "end": "5240320"
  },
  {
    "text": "which means for, say, 99- with 99% probability, for any given h,",
    "start": "5240320",
    "end": "5247755"
  },
  {
    "text": "the gap between the true risk and the empirical risk, is less than gamma for all h, right?",
    "start": "5247755",
    "end": "5255390"
  },
  {
    "text": "It's- think- think about it, you know, carefully because it- it can be a little confusing.",
    "start": "5255390",
    "end": "5261855"
  },
  {
    "text": "What we mean is for any given h, let's consider this h, right?",
    "start": "5261855",
    "end": "5269610"
  },
  {
    "text": "For this h, we have fixed the, uh, the number of example's n. And we're gonna repeat collecting n examples,",
    "start": "5269610",
    "end": "5279194"
  },
  {
    "text": "fitting a model, evaluating the- the, uh, uh, empirical risk. Repeat, uh, take a new set of n examples,",
    "start": "5279194",
    "end": "5286844"
  },
  {
    "text": "fit the model by minimizing the empirical risk and- and- and plotting the error. [NOISE] And that will give us points like this.",
    "start": "5286845",
    "end": "5294280"
  },
  {
    "text": "So each experiment is gonna give us a point like this.",
    "start": "5294740",
    "end": "5302220"
  },
  {
    "text": "And what it says is for any given hypothesis for all h, the probability that the- the [NOISE] the point that we get,",
    "start": "5302220",
    "end": "5315495"
  },
  {
    "text": "uh, the empirical risk that we get, and the true risk at that point,",
    "start": "5315495",
    "end": "5322950"
  },
  {
    "text": "the gap between the two, let's call it gamma. Gamma is gonna be the- the- the- the gap between- [NOISE] the gap between the two,",
    "start": "5322950",
    "end": "5333690"
  },
  {
    "text": "sorry, this is not gamma, this- this will be less than gamma, right?",
    "start": "5333690",
    "end": "5339075"
  },
  {
    "text": "So there's gonna be some upper and lower bound plus gamma and minus gamma. So this is a gap of 2 gamma.",
    "start": "5339075",
    "end": "5345570"
  },
  {
    "text": "So it says with probability greater than 1 minus delta, the empirical risk is gonna be within,",
    "start": "5345570",
    "end": "5353880"
  },
  {
    "text": "you know, gamma of the true risk. And how do we go about actually calculating this- this particular value of gamma,",
    "start": "5353880",
    "end": "5363555"
  },
  {
    "text": "is gonna depend on the kind of hypothesis that you are working with, right? And- [NOISE] and we'll",
    "start": "5363555",
    "end": "5377760"
  },
  {
    "text": "see a few examples of this shortly, yeah. Is this n just the size of the sample? Yes, n is the size of the sample.",
    "start": "5377760",
    "end": "5383775"
  },
  {
    "text": "And the intuition you wanna have here is the larger the n you have, the smaller gamma will be,",
    "start": "5383775",
    "end": "5389579"
  },
  {
    "text": "which is good, right? And the smaller the delta you have,",
    "start": "5389580",
    "end": "5395895"
  },
  {
    "text": "which means the tighter the bound you have, the larger gamma will be. So if you want a high probability bound then gamma will be bigger, right?",
    "start": "5395895",
    "end": "5403559"
  },
  {
    "text": "And the larger the n you have, you know, you're reducing the variance. So- so to- to reduce gamma,",
    "start": "5403560",
    "end": "5408690"
  },
  {
    "text": "you want to either increase n or even increase delta, which means you want a- a- a lower probability bound. Next question.",
    "start": "5408690",
    "end": "5417465"
  },
  {
    "text": "So is this like an assumption that we're making or is this a theorem and can you prove it? Yes. This is- this is going to be a template for a theorem that you",
    "start": "5417465",
    "end": "5425775"
  },
  {
    "text": "can derive different values of gamma for different model classes. If you don't know if it's going to be uniform for",
    "start": "5425775",
    "end": "5432219"
  },
  {
    "text": "every different kind of hypothesis or not. Is it always going to be the case? It will be uniform and- and you're gonna go more- I- I-",
    "start": "5432220",
    "end": "5439220"
  },
  {
    "text": "I'm just giving you a flavor of the- the way the statements will look. And- and- and we will see a- a- a few more details shortly, right?",
    "start": "5439220",
    "end": "5447405"
  },
  {
    "text": "Right? So this- this uniform convergence results will always follow this flavor where you're trying to",
    "start": "5447405",
    "end": "5455055"
  },
  {
    "text": "ge- obtain a probabilistic bound on the margin of how far apart [NOISE] the true risk and the empirical risk will be.",
    "start": "5455055",
    "end": "5464250"
  },
  {
    "text": "And that margin is gonna depend on n- delta n and the hypothesis class itself. Next question?",
    "start": "5464250",
    "end": "5470955"
  },
  {
    "text": "Uh, why is it such that the, uh, risk function is continuous over the,",
    "start": "5470955",
    "end": "5476790"
  },
  {
    "text": "um, hypo- possible hypothesis space? It need not be continuous over all hypothesis space here.",
    "start": "5476790",
    "end": "5483315"
  },
  {
    "text": "So the question was, you know, is the risk function is continuous over the hypothesis space and- and,",
    "start": "5483315",
    "end": "5488475"
  },
  {
    "text": "you know, the hypothesis space itself need not be continuous so we'll move on, right?",
    "start": "5488475",
    "end": "5495180"
  },
  {
    "text": "So in general- yeah, so the- all uniform convergence results are gonna look like this where you- you want some kind of a gap between, uh, uh,",
    "start": "5495180",
    "end": "5503520"
  },
  {
    "text": "the empirical risk and the true risk for any hypothesis, you know, this any hypothesis is what, you know,",
    "start": "5503520",
    "end": "5509114"
  },
  {
    "text": "is why- is why we call it uniform convergence. And that gap is gonna be, you know, less than some margin",
    "start": "5509115",
    "end": "5515550"
  },
  {
    "text": "gamma fo- for a particular level of probability- probabilistic confidence.",
    "start": "5515550",
    "end": "5520965"
  },
  {
    "text": "And this gamma will depend on n, the level of confidence and the hypothesis class, all right?",
    "start": "5520965",
    "end": "5526815"
  },
  {
    "text": "And assuming we have derived some gamma in this way,",
    "start": "5526815",
    "end": "5533340"
  },
  {
    "text": "we can then plug it into the excess risk bound, right? Excess risk bound.",
    "start": "5533340",
    "end": "5539100"
  },
  {
    "text": "[NOISE]",
    "start": "5539100",
    "end": "5546265"
  },
  {
    "text": "So I'm intentionally, uh, not giving an example of- a concrete example of this yet.",
    "start": "5546265",
    "end": "5552804"
  },
  {
    "text": "Let's see how this plugs into the excess risk bound and then we'll see a more concrete example of this. So the excess risk bound does actually looks something like this.",
    "start": "5552805",
    "end": "5563065"
  },
  {
    "text": "With probability greater than equal to 1 minus Delta.",
    "start": "5563065",
    "end": "5568640"
  },
  {
    "text": "Epsilon of h star is less than or equal to Epsilon- Epsilon of h hat is",
    "start": "5569820",
    "end": "5578980"
  },
  {
    "text": "less than equal to Epsilon of h star plus 2 Gamma, right?",
    "start": "5578980",
    "end": "5587545"
  },
  {
    "text": "This- this looks somewhat similar to this, but it's- it's pretty different. So first of all, here, in uniform convergence,",
    "start": "5587545",
    "end": "5595690"
  },
  {
    "text": "we are talking about the same h but the different risk functions. You know, we're talking about the gap between the- the,",
    "start": "5595690",
    "end": "5602605"
  },
  {
    "text": "uh, true risk and the empirical risk. Whereas over here, we're talking about the true risk itself,",
    "start": "5602605",
    "end": "5609309"
  },
  {
    "text": "but it's the difference in the true risk between our estimated hypothesis, h hat, and the best possible hypothesis h star,",
    "start": "5609310",
    "end": "5617845"
  },
  {
    "text": "or the best put- best-in-class hypothesis h star, right? And the only difference between the two is,",
    "start": "5617845",
    "end": "5623650"
  },
  {
    "text": "you know, from Gamma, we went to 2 Gamma. Why is that, right? And this is- this is a pretty, uh,",
    "start": "5623650",
    "end": "5631300"
  },
  {
    "text": "pretty cool result and a very, kind of, intuitive result. Can I aska  question?",
    "start": "5631300",
    "end": "5636985"
  },
  {
    "text": "Yes, question. Why",
    "start": "5636985",
    "end": "5638949"
  },
  {
    "text": "does the excess risk involve the, uh, an estimate [inaudible] Yes. So let me- let me draw a quick picture about this.",
    "start": "5649350",
    "end": "5655540"
  },
  {
    "text": "Uh, so the question is, why does the excess risk involve h hat? I guess that's what- that's the question was, uh, anyway.",
    "start": "5655540",
    "end": "5661120"
  },
  {
    "text": "So um, so if this is our region of interest, okay?",
    "start": "5661120",
    "end": "5667510"
  },
  {
    "text": "And let's say this was- is the true risk and there's the empirical risk.",
    "start": "5667510",
    "end": "5678760"
  },
  {
    "text": "So this is Epsilon of h. This is Epsilon hat of h, right?",
    "start": "5678760",
    "end": "5687445"
  },
  {
    "text": "So what we want here is- so this is h star that minimizes- that minimizes the true risk,",
    "start": "5687445",
    "end": "5699595"
  },
  {
    "text": "and [NOISE] this is h hat that minimizes the empirical risk.",
    "start": "5699595",
    "end": "5704725"
  },
  {
    "text": "All right? So now the excess risk is this gap.",
    "start": "5704725",
    "end": "5710450"
  },
  {
    "text": "This gap is the excess risk. All right? So the, um, excess risk,",
    "start": "5710490",
    "end": "5721900"
  },
  {
    "text": "we want to get, uh, uh, of, uh, we want to get a bound between two points on the thick line, right?",
    "start": "5721900",
    "end": "5729970"
  },
  {
    "text": "But whereas what uniform, uh, convergence gives us is a bound between",
    "start": "5729970",
    "end": "5735174"
  },
  {
    "text": "the dotted line and the thick line for any given value of h, right? That's what uniform convergence gave us.",
    "start": "5735174",
    "end": "5740920"
  },
  {
    "text": "It gave us a bound on the margin between the thick line and the dotted line for any given value of",
    "start": "5740920",
    "end": "5747100"
  },
  {
    "text": "h. But instead what we want is a bound on the gap between two points on the thick line itself.",
    "start": "5747100",
    "end": "5754420"
  },
  {
    "text": "How do we go from- go from this bound to this bound is I guess the question for this, uh, uh, for this proof.",
    "start": "5754420",
    "end": "5761845"
  },
  {
    "text": "So the proof is pretty- pretty nice and intuitive.",
    "start": "5761845",
    "end": "5768080"
  },
  {
    "text": "So Epsilon of h hat, which is the generalization error of",
    "start": "5771750",
    "end": "5777489"
  },
  {
    "text": "our learned hypothesis or the estimator hypothesis is less than or equal to Epsilon hat of h hat plus Gamma, right?",
    "start": "5777490",
    "end": "5790135"
  },
  {
    "text": "And this comes directly from the uniform convergences idea. We apply the uniform convergence result at h hat and it says that",
    "start": "5790135",
    "end": "5797590"
  },
  {
    "text": "the true risk function can not be more than Gamma away from the empirical risk at h hat.",
    "start": "5797590",
    "end": "5806230"
  },
  {
    "text": "Any questions on this, the first step? Okay. All right. So this is uniform convergence at h hat, right?",
    "start": "5806230",
    "end": "5819700"
  },
  {
    "text": "And then we're gonna say this is less than or equal to Epsilon hat of h star plus Gamma.",
    "start": "5819700",
    "end": "5830640"
  },
  {
    "text": "What change from here to here? The empirical risk at h hat is less than the empirical risk at h star.",
    "start": "5830640",
    "end": "5838619"
  },
  {
    "text": "[NOISE] What does it mean? This is the empirical risk. Empirical risk at h hat is less than empirical risk at h- h star.",
    "start": "5838620",
    "end": "5847825"
  },
  {
    "text": "And that is by definition because h hat minimize the empirical risk. So the- the main- the- the- the risk at",
    "start": "5847825",
    "end": "5855040"
  },
  {
    "text": "h star cannot be less than- the- the empirical risk of h star cannot be less than the empirical risk at",
    "start": "5855040",
    "end": "5860650"
  },
  {
    "text": "h hat because h hat by definition minimizes the empirical risk. Does it make sense? And now- so this is basically, uh,",
    "start": "5860650",
    "end": "5873010"
  },
  {
    "text": "by definition of empirical risk minimization, right?",
    "start": "5873010",
    "end": "5883809"
  },
  {
    "text": "And this in turn is now gonna be- and now we're gonna make",
    "start": "5883810",
    "end": "5890080"
  },
  {
    "text": "a statement that the gap between- let me just write it down.",
    "start": "5890080",
    "end": "5896710"
  },
  {
    "text": "So Epsilon of [NOISE] h star plus Gamma plus Gamma, okay?",
    "start": "5896710",
    "end": "5904870"
  },
  {
    "text": "You're gonna, again, apply uniform convergence for the gap between the true risk and the empirical risk at h star. All right?",
    "start": "5904870",
    "end": "5913870"
  },
  {
    "text": "Uniform convergence tells us that the gap between these two- these two risk functions is going to be",
    "start": "5913870",
    "end": "5919870"
  },
  {
    "text": "less than Gamma at any h with some probability, right? So it's gonna be less than h over here and it's gonna be less than h over here, right?",
    "start": "5919870",
    "end": "5929980"
  },
  {
    "text": "So this is uniform convergence at h star.",
    "start": "5929980",
    "end": "5941110"
  },
  {
    "text": "So the risk between h hat, ah, ah, Epsilon hat of h star and Epsilon of h star is gonna be less than Gamma, right?",
    "start": "5941110",
    "end": "5951010"
  },
  {
    "text": "It's Epsilon of- here, we are- we are- we are applying this at h star.",
    "start": "5951010",
    "end": "5956095"
  },
  {
    "text": "And this is basically equal to Epsilon of h star plus Gamma,",
    "start": "5956095",
    "end": "5963265"
  },
  {
    "text": "plus 2 Gamma, sorry, right? Which is the result that we got;",
    "start": "5963265",
    "end": "5970420"
  },
  {
    "text": "h hat is less than Epsilon of h star plus 2 Gamma. So what happened here?",
    "start": "5970420",
    "end": "5976420"
  },
  {
    "text": "We had a tool called uniform convergence that gives us a gap between the dotted line and",
    "start": "5976420",
    "end": "5982570"
  },
  {
    "text": "the thick line at any hypothesis h. And using that tool,",
    "start": "5982570",
    "end": "5989965"
  },
  {
    "text": "we wanted to obtain a gap, uh, a bound between two points on the thick line itself,",
    "start": "5989965",
    "end": "5997630"
  },
  {
    "text": "which in general is not possible, but we are gonna use the fact that we are doing empirical risk minimization.",
    "start": "5997630",
    "end": "6005579"
  },
  {
    "text": "So we have, you know, one- one gap here. And so this is less than Gamma,",
    "start": "6005580",
    "end": "6013875"
  },
  {
    "text": "this is less than Gamma. Uniform convergence tells us this is less than Gamma and this is less than Gamma.",
    "start": "6013875",
    "end": "6019304"
  },
  {
    "text": "Uniform convergence, at two different points. And empirical risk minimization tells us this point is less than this point.",
    "start": "6019305",
    "end": "6027700"
  },
  {
    "text": "All right? So two, you know, uh, so this- this basically allows us to order",
    "start": "6031100",
    "end": "6037319"
  },
  {
    "text": "this point to be less than 2 Gamma times this point.",
    "start": "6037319",
    "end": "6042585"
  },
  {
    "text": "Because this point cannot be a Gamma more than here. This cannot be ga- uh, you know,",
    "start": "6042585",
    "end": "6048090"
  },
  {
    "text": "this cannot be less than here, and this cannot be Gamma less than here.",
    "start": "6048090",
    "end": "6054780"
  },
  {
    "text": "So at most, the gap between these two is 2 Gamma, right? So to- to- to kind of draw it clearly.",
    "start": "6054780",
    "end": "6063490"
  },
  {
    "text": "So this is Epsilon hat of h, this is Epsilon of h,",
    "start": "6064730",
    "end": "6070875"
  },
  {
    "text": "and this is at most Gamma. And we have Epsilon hat of h star,",
    "start": "6070875",
    "end": "6081149"
  },
  {
    "text": "which must be more than Epsilon hat of h, uh, h hat, and",
    "start": "6081149",
    "end": "6090510"
  },
  {
    "text": "this can be at most this is less than Gamma,",
    "start": "6090510",
    "end": "6096869"
  },
  {
    "text": "and this is Epsilon of h star, right? So this is less than Gamma,",
    "start": "6096870",
    "end": "6102720"
  },
  {
    "text": "this is less than Gamma, and this has to be more. So at most, these two can be",
    "start": "6102720",
    "end": "6108400"
  },
  {
    "text": "less than 2 Gamma, right?",
    "start": "6108400",
    "end": "6115739"
  },
  {
    "text": "So once we are able to derive a uniform convergence bound for a particular hypothesis class,",
    "start": "6115740",
    "end": "6124185"
  },
  {
    "text": "we can just multiply it by two and get an excess risk bound to tell us how well our model is gonna perform in",
    "start": "6124185",
    "end": "6132810"
  },
  {
    "text": "the real world relative to the best to- the best possible model that could have performed in the real world, right?",
    "start": "6132810",
    "end": "6142349"
  },
  {
    "text": "Now with this template, let's see- er, any questions on this before we see a few examples of uniform convergence?",
    "start": "6142350",
    "end": "6151480"
  },
  {
    "text": "This- this is the general recipe, you know, of- of- of- we're gonna use uniform convergence to- to derive the- the Gamma term,",
    "start": "6151510",
    "end": "6161540"
  },
  {
    "text": "and that's gonna be different, uh, using different techniques for different kinds of models, um, and- and- and different kinds of loss functions.",
    "start": "6161540",
    "end": "6168840"
  },
  {
    "text": "But once we get that uniform convergence bound of- of Gamma for a given hypothesis class,",
    "start": "6168840",
    "end": "6175619"
  },
  {
    "text": "you're gonna then plug it, you know using this technique to obtain an excess risk bound which is just 2 times Gamma.",
    "start": "6175620",
    "end": "6181934"
  },
  {
    "text": "All right? No questions? Yes, question.",
    "start": "6181935",
    "end": "6187850"
  },
  {
    "text": "So just to put it in words, uh, what were the statement that say, uh, the empirical risk for the- so restricting yourself to a certain hypothesis,",
    "start": "6187850",
    "end": "6196560"
  },
  {
    "text": "plus the one that- h hat is the one that you pick which minimizes the empirical loss.",
    "start": "6196560",
    "end": "6202650"
  },
  {
    "text": "So the empirical loss in that 1 is less that and the best- it's- it's bounded by two Gammas, uh, at the [inaudible] ?",
    "start": "6202650",
    "end": "6211870"
  },
  {
    "text": "So [inaudible] before you go further, th- this is not the empirical loss, right?",
    "start": "6211870",
    "end": "6218600"
  },
  {
    "text": "So Epsilon is not the empirical loss. Epsilon hat is the empirical loss. [NOISE] Epsilon is the- the generalized loss or the true risk.",
    "start": "6218600",
    "end": "6227000"
  },
  {
    "text": "[NOISE] So that's the true risk? This is the true risk. We're- we're- in- in the excess risk bound, we're talking about the true risk at",
    "start": "6227000",
    "end": "6234050"
  },
  {
    "text": "the empirical risk minimizer and the true risk at the best-in-class [NOISE] hypothesis.",
    "start": "6234050",
    "end": "6239239"
  },
  {
    "text": "[BACKGROUND] [NOISE] All right, so we're kind of- um both of these are,",
    "start": "6239240",
    "end": "6244580"
  },
  {
    "text": "in general, not measurable because it's measuring the true risk at you know at- at two different points.",
    "start": "6244580",
    "end": "6251060"
  },
  {
    "text": "We calculate the H hat using empirical risk minimization. [NOISE] We have no idea what this value evaluates to.",
    "start": "6251060",
    "end": "6257780"
  },
  {
    "text": "[NOISE] Here, we have no idea what h star is, and we have no idea [NOISE] what that evaluates to, but we [NOISE] can still derive [NOISE] an upper bound on",
    "start": "6257780",
    "end": "6265310"
  },
  {
    "text": "this- on this- uh on the gap between the two [NOISE] using this technique. [NOISE] And in order to kind of actually you know, complete this technique,",
    "start": "6265310",
    "end": "6274790"
  },
  {
    "text": "we need to get a- you know a uniform convergence which is a bound on Gamma [NOISE] f- at- at any point of- at any hypothesis H. Yes, question?",
    "start": "6274790",
    "end": "6282080"
  },
  {
    "text": "On the diagram on the left. Are H star and H hat [inaudible]",
    "start": "6282080",
    "end": "6287510"
  },
  {
    "text": "because the empirical risk at the H star should be less than the empirical risk at H hat, right?",
    "start": "6287510",
    "end": "6293690"
  },
  {
    "text": "So the empirical risk at H star should be less than empirical risk at H hat? So it need not be. So that's a good question.",
    "start": "6293690",
    "end": "6300469"
  },
  {
    "text": "[NOISE] So the empirical risk at H star and empirical risk at H- H hat, they may be flipped.",
    "start": "6300470",
    "end": "6305900"
  },
  {
    "text": "They- they may be in any order. What uniform convergence tells us is the absolute value between the two is less than Gamma.",
    "start": "6305900",
    "end": "6312080"
  },
  {
    "text": "[NOISE] So the- the- uh what that means is [NOISE] at H star,",
    "start": "6312080",
    "end": "6317960"
  },
  {
    "text": "[NOISE] the empirical risk may have been, you know, above it. It's- it's- it's- that's- that's totally possible.",
    "start": "6317960",
    "end": "6323929"
  },
  {
    "text": "[NOISE] Yes, question? [NOISE] So you make that [NOISE] capital H, then [inaudible] hypothesis plus.",
    "start": "6323930",
    "end": "6330560"
  },
  {
    "text": "[NOISE] You're saying that you take it and you will need to put one layer and take it to 1,000 layers. Is this always going to hold so like make",
    "start": "6330560",
    "end": "6337820"
  },
  {
    "text": "it and [inaudible] hypothesis [inaudible] always true, right? Yeah, so- so- so- th- th- the question is what if we make hypothesis class like infinite?",
    "start": "6337820",
    "end": "6345395"
  },
  {
    "text": "Say you're using neural networks, we're gonna come to that- uh uh uh th- th- th- that's exactly what we're gonna come to now.",
    "start": "6345395",
    "end": "6350630"
  },
  {
    "text": "[NOISE] So any, any questions on- on- on this- th- this technique. Yes, question. [NOISE] Yes. So the- [NOISE] the question that was",
    "start": "6350630",
    "end": "6356520"
  },
  {
    "text": "previously asked [NOISE] u, h regarding that, isn't it- isn't H uh hard to [NOISE] find to be the empirical loss in [inaudible]",
    "start": "6356520",
    "end": "6363890"
  },
  {
    "text": "Yes. So H hat is the empirical loss minimizer, [NOISE] which means [NOISE] the empirical loss at [NOISE] H hat will be less than",
    "start": "6363890",
    "end": "6369140"
  },
  {
    "text": "empirical- less than or equal to empirical [NOISE] loss at H star, right? [NOISE] It says nothing about [NOISE]",
    "start": "6369140",
    "end": "6374480"
  },
  {
    "text": "the true risk versus empirical risk at any of those points. They may be flipped. [NOISE] Uniform",
    "start": "6374480",
    "end": "6379940"
  },
  {
    "text": "convergence tells us that they cannot be Gamma apart. So the true risk may have- [NOISE] may have gone below the empirical risk also,",
    "start": "6379940",
    "end": "6385970"
  },
  {
    "text": "It's, you know, it's- it's totally possible. [NOISE] All right. So uh, moving on.",
    "start": "6385970",
    "end": "6391445"
  },
  {
    "text": "Um, [NOISE] let's see a few results of empirical risk minimization.",
    "start": "6391445",
    "end": "6397760"
  },
  {
    "text": "[NOISE] I'm sorry, of a few uh, [NOISE] results of uniform convergence. [NOISE]",
    "start": "6397760",
    "end": "6408200"
  },
  {
    "text": "So-",
    "start": "6408200",
    "end": "6419450"
  },
  {
    "text": "[NOISE] so Case 1, [NOISE] finite hypothesis class.",
    "start": "6419450",
    "end": "6424880"
  },
  {
    "text": "[NOISE] So if we",
    "start": "6424880",
    "end": "6431750"
  },
  {
    "text": "assume that we have a finite number of hypotheses in our class, [NOISE] which is- [NOISE] which might seem actually um,",
    "start": "6431750",
    "end": "6439145"
  },
  {
    "text": "you know, uh, very limiting at fr- uh uh at first. But then, if you kind of think about it, you know,",
    "start": "6439145",
    "end": "6444650"
  },
  {
    "text": "if um, uh, you know, um if you consider logistic regression [NOISE] or say a neural network,",
    "start": "6444650",
    "end": "6451940"
  },
  {
    "text": "[NOISE] you represent that- that um, you know, neural network with- with its parameters stored in the computer memory, right?",
    "start": "6451940",
    "end": "6460520"
  },
  {
    "text": "[NOISE] So the weights of your neural weights and biases are gets- are stored in your uh, computer um um as- as,",
    "start": "6460520",
    "end": "6466744"
  },
  {
    "text": "you know, some float values or 64-bit in a parameter or- or some such representation.",
    "start": "6466745",
    "end": "6472909"
  },
  {
    "text": "And your computer has finite representation capab- capacity. [NOISE] So you're each weight uh, each uh, uh, parameter is stored at a 64-bit value,",
    "start": "6472910",
    "end": "6481865"
  },
  {
    "text": "which means it can take at most 2^64 different possible values, [NOISE] right?",
    "start": "6481865",
    "end": "6487610"
  },
  {
    "text": "So even though you have a neural network having real value parameters, in practice, it is actually,",
    "start": "6487610",
    "end": "6493235"
  },
  {
    "text": "you know, we are dealing with the finite hypothesis class just because we are working with [NOISE] finite capacity computer.",
    "start": "6493235",
    "end": "6499010"
  },
  {
    "text": "So [NOISE] even though this might seem very limiting at first, [NOISE] it's possible to kind of use this in pretty powerful ways, [NOISE] right?",
    "start": "6499010",
    "end": "6508100"
  },
  {
    "text": "So [NOISE] if- if you are considering hy- a finite hypothesis class where [NOISE] the size of the hypothesis class is sum value of K, [NOISE] right?",
    "start": "6508100",
    "end": "6518570"
  },
  {
    "text": "[NOISE] The uniform uh convergence results tells us [NOISE] uniform convergence tells us with probability greater than equal to 1 minus um, uh, Delta,",
    "start": "6518570",
    "end": "6528830"
  },
  {
    "text": "[NOISE] absolute value of [NOISE] and for all h in hypothesis",
    "start": "6528830",
    "end": "6539405"
  },
  {
    "text": "minus [NOISE] h is less than equal to- so",
    "start": "6539405",
    "end": "6546230"
  },
  {
    "text": "the Gamma term that we uh, uh, [NOISE] so the Gamma term- so that's uh i- i- if you remember in uniform convergence,",
    "start": "6546230",
    "end": "6552695"
  },
  {
    "text": "this is the template that we always follow. And for each different situation, you're gonna get a Gamma term that involves n,",
    "start": "6552695",
    "end": "6559789"
  },
  {
    "text": "Delta and uh something about the hypothesis class. And in this case, it turns out to be [NOISE] square root of 1 over [NOISE]",
    "start": "6559790",
    "end": "6567739"
  },
  {
    "text": "2n log 2K [NOISE]",
    "start": "6567740",
    "end": "6573830"
  },
  {
    "text": "over Delta [NOISE], right? Yes, question. What do you mean by K?",
    "start": "6573830",
    "end": "6580040"
  },
  {
    "text": "So K here it is the size of the uh finite hypothesis class. How do you get the size of the class?",
    "start": "6580040",
    "end": "6585155"
  },
  {
    "text": "Yeah, as I said, you know, if you're storing things in- in- in the computer, two to the power of, you know, number of parameters you have could be used in this case [NOISE] because, you know,",
    "start": "6585155",
    "end": "6594349"
  },
  {
    "text": "for each number of parameter- for each parameter, it can only take up to, you know, a- a- a- a- a- in a- in a 64-bit uh uh values of-",
    "start": "6594350",
    "end": "6601670"
  },
  {
    "text": "So you're defining the size of the hypothesis class with the sign in its memory representation?",
    "start": "6601670",
    "end": "6607145"
  },
  {
    "text": "Yeah, because, you know, uh that is- you're limited to the, you know, th- by the memory capacity in your computer of,",
    "start": "6607145",
    "end": "6613340"
  },
  {
    "text": "you know, the different possible uh hypothesis you can- you can- [inaudible] much more limited than [inaudible]",
    "start": "6613340",
    "end": "6619369"
  },
  {
    "text": "Yeah, in practice, it is, which- which- w- which doesn't hurt the bound. And the bound might be loose, but bound is still valid, [NOISE] right?",
    "start": "6619370",
    "end": "6626870"
  },
  {
    "text": "So you get- you get um, um, [NOISE] uniform convergences that are  like this, which [NOISE] translates into an excess risk [NOISE] bound.",
    "start": "6626870",
    "end": "6634250"
  },
  {
    "text": "[NOISE] As with probability greater than equal to 1 minus Delta [NOISE] of",
    "start": "6634250",
    "end": "6644405"
  },
  {
    "text": "Epsilon of H hat is less than or equal to [NOISE] Epsilon of [NOISE] H star plus 2 times this",
    "start": "6644405",
    "end": "6653239"
  },
  {
    "text": "[NOISE] and we're 2n [NOISE] log 2K over Delta, [NOISE] right?",
    "start": "6653240",
    "end": "6663110"
  },
  {
    "text": "And there are different results, you know? For finite hypothesis class, we get a margin term in this form for different kinds of classes.",
    "start": "6663110",
    "end": "6674810"
  },
  {
    "text": "For even for infinite dimensional uh, infinite size hypothesis class,",
    "start": "6674810",
    "end": "6679880"
  },
  {
    "text": "there are different techniques [NOISE] where you can [NOISE] obtain terms like this. [NOISE] The key  observation to see here is",
    "start": "6679880",
    "end": "6686780"
  },
  {
    "text": "that this term is essentially [NOISE] min h hypothesis sum of h, okay?",
    "start": "6686780",
    "end": "6697835"
  },
  {
    "text": "This is by definition, the performance, the- the- the true risk of the best-in-class hypothesis, [NOISE] right?",
    "start": "6697835",
    "end": "6704120"
  },
  {
    "text": "And what we see here is now- [NOISE] just like the bias-variance analysis,",
    "start": "6704120",
    "end": "6710135"
  },
  {
    "text": "we can do a very similar analysis here, [NOISE] which is what is the optimal size of our hypothesis class?",
    "start": "6710135",
    "end": "6717380"
  },
  {
    "text": "If we increase the size of our hypothesis class, [NOISE] then this term is gonna",
    "start": "6717380",
    "end": "6723500"
  },
  {
    "text": "reduce [NOISE] because you're- you're- you're searching over a larger hypothesis space. If- if the script h is bigger,",
    "start": "6723500",
    "end": "6730385"
  },
  {
    "text": "then the- the minimized value will be much smaller because you're just minimizing it over a larger space.",
    "start": "6730385",
    "end": "6735620"
  },
  {
    "text": "[NOISE] But if script h is bigger then k is larger, so this is gonna go up because K is in the numerator, [NOISE] right?",
    "start": "6735620",
    "end": "6744065"
  },
  {
    "text": "And this is- [NOISE] this is another way of- of- of- kind of um interpreting the bias-variance tradeoff where [NOISE] in- in- in the earlier case,",
    "start": "6744065",
    "end": "6754060"
  },
  {
    "text": "we saw the effect of regularization. But here, we see the effect of using bigger classes versus smaller hypothesis classes, right?",
    "start": "6754060",
    "end": "6760460"
  },
  {
    "text": "If you increase your- your hypothesis class to be bigger, then think of this as the bias term and the bias comes down.",
    "start": "6760460",
    "end": "6766520"
  },
  {
    "text": "[NOISE] But at the same time, the variance goes up [NOISE] because the sign of the class appears in the numerator here, right?",
    "start": "6766520",
    "end": "6772175"
  },
  {
    "text": "And you can think of this as the- the mean squared error of your, of your hypothesis where you're testing it against,",
    "start": "6772175",
    "end": "6780155"
  },
  {
    "text": "you know, th- the generalized performance. So the generalized performance is bounded by some term, which is like the bias plus some term that- which is like the variance.",
    "start": "6780155",
    "end": "6788030"
  },
  {
    "text": "And here, we see the tradeoff between the- the hypothesis uh b-",
    "start": "6788030",
    "end": "6793864"
  },
  {
    "text": "between having a larger hypothesis versus smaller hypothesis because, you know, a larger hypothesis reduces",
    "start": "6793865",
    "end": "6799010"
  },
  {
    "text": "one component but increases the other component and vice versa. [NOISE] There is, in the notes,",
    "start": "6799010",
    "end": "6805840"
  },
  {
    "text": "there is another,  there's another section on how - how to work with infinite classes uh, where H is infinite using something called VC dimensions.",
    "start": "6805840",
    "end": "6813550"
  },
  {
    "text": "And you're welcome to read that. We won't test you on the exam on any of that. In fact, we probably won't test you on any of these",
    "start": "6813550",
    "end": "6821330"
  },
  {
    "text": "except the- the main takeaway over here is that [NOISE] you- you- you know,  it's- it's",
    "start": "6821330",
    "end": "6827750"
  },
  {
    "text": "very important that you understand this trade-off between bias and variance. What we care at the end of the day is minimizing",
    "start": "6827750",
    "end": "6834739"
  },
  {
    "text": "generalization performance or- or improving our generalization performance or minimizing the generalization error.",
    "start": "6834740",
    "end": "6840395"
  },
  {
    "text": "And that generalization error always has two components: a bias component and a variance component.",
    "start": "6840395",
    "end": "6845540"
  },
  {
    "text": "[NOISE] It's very hard to break them down analytically. [NOISE] But there are heuristics where we can consider the bias as the training error",
    "start": "6845540",
    "end": "6853915"
  },
  {
    "text": "and the gap between cross-validation and- and training error as the variance.",
    "start": "6853915",
    "end": "6859280"
  },
  {
    "text": "[NOISE] And always, always when you wanna take some action to improve your model's generalization performance,",
    "start": "6859280",
    "end": "6866800"
  },
  {
    "text": "characterize these two using those heuristics and purposefully attack one of [NOISE] them at a time.",
    "start": "6866800",
    "end": "6872455"
  },
  {
    "text": "Either go after bias- bias at a time or go after variance at a time depending on which of the two is bigger, right?",
    "start": "6872455",
    "end": "6878900"
  },
  {
    "text": "And that becomes an iterative process where you improve one. And then, you see that, you know,",
    "start": "6878900",
    "end": "6884375"
  },
  {
    "text": "that is no longer, you know, say bias is no longer the biggest error. Then, you go off to variance. And also uh, you know, using these tradeoffs,",
    "start": "6884375",
    "end": "6890630"
  },
  {
    "text": "you see when- once you- when- when you fight bias in some way, you know, that can increase the variance and so on, right?",
    "start": "6890630",
    "end": "6897230"
  },
  {
    "text": "That's- that's probably the- the larger message from today's lecture, and that's probably the biggest takeaway from the course itself of",
    "start": "6897230",
    "end": "6904100"
  },
  {
    "text": "dealing with bias and variance to improve your generalization performance, all right? Let's break for today.",
    "start": "6904100",
    "end": "6910440"
  }
]
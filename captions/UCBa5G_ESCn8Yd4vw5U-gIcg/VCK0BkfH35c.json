[
  {
    "start": "0",
    "end": "5170"
  },
  {
    "text": "Hello, everyone. Welcome on Zoom this time. Welcome to CS 330.",
    "start": "5170",
    "end": "10330"
  },
  {
    "text": "Today, we'll be talking about\nlifelong learning, which is a very interesting\narea of research,",
    "start": "10330",
    "end": "16760"
  },
  {
    "text": "which is not very well defined. And we'll talk\nabout it, and you'll get to experience why that is.",
    "start": "16760",
    "end": "23470"
  },
  {
    "text": "A few things regarding\nZoom lecturing, if you have any\nquestions, please, raise your hand on Zoom.",
    "start": "23470",
    "end": "29920"
  },
  {
    "text": "You can also write\na question in Chat. I won't be monitoring\nall of this at all times, but we have our\nlecture coordinator",
    "start": "29920",
    "end": "37450"
  },
  {
    "text": "with us, who will then\nspeak up any time there is a raised hand or questions\nand we'll try to answer these.",
    "start": "37450",
    "end": "47250"
  },
  {
    "text": "All right, so a few reminders. So this Wednesday will\nbe our last lecture,",
    "start": "47250",
    "end": "58230"
  },
  {
    "text": "and both the lecture, as well\nas the instructor office hours, will be over Zoom.",
    "start": "58230",
    "end": "64220"
  },
  {
    "text": "So it will be in a similar\nsetting, like we have today. One thing that I\nwould like to tell you",
    "start": "64220",
    "end": "70100"
  },
  {
    "text": "is that we'll talk about\nfrontiers and open problems in multitask and\nmeta-learning, and we'll",
    "start": "70100",
    "end": "77479"
  },
  {
    "text": "have maybe six to\neight researchers who work on frontiers\nwill tell us briefly",
    "start": "77480",
    "end": "85010"
  },
  {
    "text": "about some of their\nrecent papers, some of their recent\nprojects, and you will you'll have a chance to meet\nthem and ask them questions.",
    "start": "85010",
    "end": "91340"
  },
  {
    "text": "Because it's all in Zoom,\nso it's a little bit easier to do it for them. So I would encourage you\nto participate and kind of",
    "start": "91340",
    "end": "98420"
  },
  {
    "text": "get to know the people\nbehind the research, as well as the research\nthat is happening.",
    "start": "98420",
    "end": "105380"
  },
  {
    "text": "In addition, the two\nremaining reminders are that on Tuesday we'll\nhave the project poster session, and then on\nWednesday, project interview.",
    "start": "105380",
    "end": "113614"
  },
  {
    "text": " OK. So the plan for today\nis the following.",
    "start": "113614",
    "end": "118750"
  },
  {
    "text": "We'll talk about the lifelong\nlearning problem statement. Then, we'll talk about\nsome basic approaches",
    "start": "118750",
    "end": "125170"
  },
  {
    "text": "to lifelong learning, how\nwe can address the problem. Then, we'll talk about\nhow we can do better",
    "start": "125170",
    "end": "132060"
  },
  {
    "text": "than these basic approaches,\nalso using some of the insights that we learned from\nthe class already.",
    "start": "132060",
    "end": "139189"
  },
  {
    "text": "And then we'll revisit\nthe problem statement from the meta-learning\nperspective.",
    "start": "139190",
    "end": "145618"
  },
  {
    "text": "All right. So let's do a brief overview\nof the problems statements that we discussed so far.",
    "start": "145618",
    "end": "152640"
  },
  {
    "text": "So we talked about\nmulti-task learning, where we try to learn\nto solve a set of tasks. And in that case, we\nhad some kind of task",
    "start": "152640",
    "end": "159560"
  },
  {
    "text": "that we had to learn, that\nwere given to us up front,",
    "start": "159560",
    "end": "164930"
  },
  {
    "text": "and then were evaluated by\nsome of the exact same tasks. So we are not really\ntesting the generalizations",
    "start": "164930",
    "end": "170390"
  },
  {
    "text": "to unseen tasks, but we\ntrain on a set of tasks, and then we evaluate on the\nexact same set of tasks.",
    "start": "170390",
    "end": "175519"
  },
  {
    "text": " And then we also talked\nabout mental learning",
    "start": "175520",
    "end": "180840"
  },
  {
    "text": "where given an i.i.d.\ntask distribution, we try to learn a\nnew task efficiently. So learn to learn\ndifferent tasks.",
    "start": "180840",
    "end": "188640"
  },
  {
    "text": "In that case, you were given a\nset of tasks at training time, and then at test time,\nyou'll be tested,",
    "start": "188640",
    "end": "194610"
  },
  {
    "text": "or it will be measured\nhow quickly you can learn a new task that\nyou haven't seen before.",
    "start": "194610",
    "end": "199760"
  },
  {
    "text": "And so in that case,\nwe are learning-- we are testing how quickly\nyou can adapt to a new task that you've never seen.",
    "start": "199760",
    "end": "205407"
  },
  {
    "text": " However, in both of these-- in both of these\ncases, we assume",
    "start": "205408",
    "end": "214930"
  },
  {
    "text": "that the tasks that\nyou can practice on or that you can learn\nat the beginning are kind of given\nto you up front.",
    "start": "214930",
    "end": "220990"
  },
  {
    "text": "You kind of have them at your\ndisposal right off the bat. And you can sample\nthem differently.",
    "start": "220990",
    "end": "226660"
  },
  {
    "text": "You have access to all\nof them at all times. But in contrast, many\nreal-world settings",
    "start": "226660",
    "end": "232590"
  },
  {
    "text": "look a little bit different. In contrast, the way\nit looks is usually that you are given a task\nthat you have to perform.",
    "start": "232590",
    "end": "239099"
  },
  {
    "text": "And then after you perform\nthe task for a little bit, you're given a new task, right? And you don't really have\naccess to the old task.",
    "start": "239100",
    "end": "245760"
  },
  {
    "text": "Now you have to focus on the\nnew task that you just got. And then you do this over time.",
    "start": "245760",
    "end": "250920"
  },
  {
    "text": "And every now and then,\nyou are given a new task that you haven't seen\nbefore, and you have to-- you're measured how well\nyou're doing on that task,",
    "start": "250920",
    "end": "257910"
  },
  {
    "text": "and you don't have all of\nthe tasks up front available to you. So basically, our\nagents may not be",
    "start": "257910",
    "end": "264370"
  },
  {
    "text": "given a large batch of data\nforecasts right off the bat. Instead, they are revealing--",
    "start": "264370",
    "end": "269402"
  },
  {
    "text": "they're being revealed\nto you slowly over time. All right.  A few examples\nwhen this happens.",
    "start": "269402",
    "end": "277759"
  },
  {
    "text": "For instance, a student\nlearning concepts in school. You go from one\nclass to another.",
    "start": "277760",
    "end": "283040"
  },
  {
    "text": "You go to Algebra 1. And then after Algebra 1,\nyou pass your tests or exams,",
    "start": "283040",
    "end": "288199"
  },
  {
    "text": "then you go to Algebra 2. And then based on the\ncontent in Algebra 2, you're being evaluated how\nwell you're doing in Algebra 2,",
    "start": "288200",
    "end": "295280"
  },
  {
    "text": "and so on and so forth. You're not really given all\nthe material all upfront, and you're not being tested in\nall of the different classes.",
    "start": "295280",
    "end": "303440"
  },
  {
    "text": "These are being revealed\nto you progressively. Another example would be a\ndeployed image classification",
    "start": "303440",
    "end": "311100"
  },
  {
    "text": "system. That is learning from a\nstream of images from users.",
    "start": "311100",
    "end": "317560"
  },
  {
    "text": "So in that case, it's an\nimage classification system. And since maybe the things that\nusers want change over time.",
    "start": "317560",
    "end": "326080"
  },
  {
    "text": "And because of that, this\nimage classification system will be seeing very\ndifferent images over time.",
    "start": "326080",
    "end": "332190"
  },
  {
    "text": "We will also be\ngetting new users. New users might maybe shift the\ndata distribution a little bit.",
    "start": "332190",
    "end": "338070"
  },
  {
    "text": "So we won't have access\nto all the kind of things that the users might\nwant at the beginning.",
    "start": "338070",
    "end": "344610"
  },
  {
    "text": "Another example\ncould be a robot that is acquiring an increasingly\nlarge set of skills",
    "start": "344610",
    "end": "350660"
  },
  {
    "text": "in many different environments. So in that case, you\nmight have a robot",
    "start": "350660",
    "end": "356150"
  },
  {
    "text": "that you deploy in\na certain setting. For instance, you want\nit to clean your kitchen, and then it learns how\nto clean the kitchen,",
    "start": "356150",
    "end": "362063"
  },
  {
    "text": "and it gets better. And then you can use it\nfor cleaning the kitchen. But then you want the robot\nto move to a different room",
    "start": "362063",
    "end": "367729"
  },
  {
    "text": "and now do something\nelse in that room. Maybe you want it\nto do laundry now.",
    "start": "367730",
    "end": "373009"
  },
  {
    "text": "So in that case,\nthis new task is being revealed only once you\nmove the robot to the laundry room.",
    "start": "373010",
    "end": "378230"
  },
  {
    "text": "And then the robot is being\nevaluated on this new task that was given to it at the current\ntime as opposed to having all",
    "start": "378230",
    "end": "383932"
  },
  {
    "text": "the tasks available upfront.  Another example would be\na virtual assistant that",
    "start": "383933",
    "end": "390599"
  },
  {
    "text": "is learning to help\nusers, or different users who have different tasks at\ndifferent points in time.",
    "start": "390600",
    "end": "396940"
  },
  {
    "text": "So the virtual assistant, our\npreferences when we talk to it might change over time.",
    "start": "396940",
    "end": "401970"
  },
  {
    "text": "We will also might need to\nadjust to different users, to constantly\nchanging preferences,",
    "start": "401970",
    "end": "408600"
  },
  {
    "text": "to maybe we want them-- we want the virtual assistant\nto do different tasks and so on. So in that case, it's also being\nrevealed to you in new tasks",
    "start": "408600",
    "end": "417034"
  },
  {
    "text": "every now and then. And then lastly, another example\ncould be a doctor's assistant",
    "start": "417034",
    "end": "424530"
  },
  {
    "text": "aiding in medical decision\nmaking, where suddenly, the users might be changing\ntheir preferences, and so on. But also new diseases\nmight be coming in.",
    "start": "424530",
    "end": "431970"
  },
  {
    "text": "For instance, a few years\nago, a doctor's assistant didn't have to help with\nthings like COVID-19.",
    "start": "431970",
    "end": "438570"
  },
  {
    "text": "Now, it should be\nable to handle that. So there might be new diseases. There might be new\ntreatments and so on,",
    "start": "438570",
    "end": "443686"
  },
  {
    "text": "and it should be able\nto adjust to these. So these are some examples.",
    "start": "443687",
    "end": "450139"
  },
  {
    "text": "Now let's talk about\nsome terminology. So the terminology\nis actually not",
    "start": "450140",
    "end": "457009"
  },
  {
    "text": "very well-defined in this field. So we'll talk a\nlittle bit about this.",
    "start": "457010",
    "end": "462360"
  },
  {
    "text": "So we usually refer to this as\nsequential learning setting. And you can see it under\nmany different names.",
    "start": "462360",
    "end": "468900"
  },
  {
    "text": "So some people call\nit online learning. Some people call it lifelong\nlearning, continual learning, incremental learning,\nstreaming data,",
    "start": "468900",
    "end": "476780"
  },
  {
    "text": "and I think there is\nprobably a few more. The important part is that this\nis distinct from sequence data.",
    "start": "476780",
    "end": "484880"
  },
  {
    "text": "So for instance, texts where\nthe words come in sequence. That doesn't necessarily\nmean that this",
    "start": "484880",
    "end": "491200"
  },
  {
    "text": "is a sequential learning\nsetting where you're being-- or you see the\ntasks that are being revealed to you over time.",
    "start": "491200",
    "end": "497300"
  },
  {
    "text": "And it's also different\nfrom sequential decision making that we discuss in\nthe case of reinforcement learning where you might need\nto reason about the actions",
    "start": "497300",
    "end": "506230"
  },
  {
    "text": "and how they're going\nto influence the future, but you can still have all the\ndata available to you upfront. And the data might not\nbe changing over time",
    "start": "506230",
    "end": "513130"
  },
  {
    "text": "as it does for instance, the\ncase with offline reinforcement learning. ",
    "start": "513130",
    "end": "521299"
  },
  {
    "text": "So what is the lifelong\nlearning problem statement? So actually, to kind\nof show you what it is",
    "start": "521299",
    "end": "527860"
  },
  {
    "text": "and to maybe get you a\nlittle bit more engaged, we'll do a little exercise.",
    "start": "527860",
    "end": "534149"
  },
  {
    "text": "So the exercise\nis the following. We'll split you\ninto breakout rooms. We'll do it in a second.",
    "start": "534150",
    "end": "540439"
  },
  {
    "text": "And in each breakout room,\nyou'll pick an example setting. The example setting could be\none of the example settings",
    "start": "540440",
    "end": "547958"
  },
  {
    "text": "that I just discussed, these\nfive examples that I gave, or you can think of your\nown example setting.",
    "start": "547958",
    "end": "554560"
  },
  {
    "text": "And then, you'll discuss\na problem statement in your breakout room, and\nthere are a few questions I want to ask you.",
    "start": "554560",
    "end": "560670"
  },
  {
    "text": "So first, please\nthink about how you would set up an experiment\nto develop and test",
    "start": "560670",
    "end": "567210"
  },
  {
    "text": "your algorithm. So it's a question\nabout how you would be--",
    "start": "567210",
    "end": "572430"
  },
  {
    "text": "if you were to create a\nlifelong learning algorithm, how would you go about this? And how would you\nactually implement it",
    "start": "572430",
    "end": "578322"
  },
  {
    "text": "in terms of an\nexperiment, and then how would you test\nthat it works?",
    "start": "578322",
    "end": "583420"
  },
  {
    "text": "Secondly, think about what\nare the desirable or required properties for lifelong\nlearning algorithms, all right?",
    "start": "583420",
    "end": "590595"
  },
  {
    "text": "So what are the things that\nyou would want to test, and what kind of\nthings you would want to focus on when you\ndevelop a lifelong learning",
    "start": "590595",
    "end": "597160"
  },
  {
    "text": "algorithm? And then third, it's kind of\nsimilar to what we are already",
    "start": "597160",
    "end": "602960"
  },
  {
    "text": "asking. A, how would you\nevaluate such a system? So exactly what\nkind of numbers you",
    "start": "602960",
    "end": "608770"
  },
  {
    "text": "would be plotting so that\nyou know it's getting better",
    "start": "608770",
    "end": "614380"
  },
  {
    "text": "or it has the desirable required\nproperties that you set? ",
    "start": "614380",
    "end": "621000"
  },
  {
    "text": "All right, so the example\nsettings that I gave before are here. A few logistics-- so we'll\nsplit you into breakout rooms.",
    "start": "621000",
    "end": "629672"
  },
  {
    "text": "I think-- I'm not sure how many\npeople we have on the call, but I think we will decide in\na second how many people will",
    "start": "629672",
    "end": "635910"
  },
  {
    "text": "be in each break out room. And then, let's say that if the\nfirst letter of your first name",
    "start": "635910",
    "end": "643620"
  },
  {
    "text": "is closer to the\nbeginning of the alphabet, you'll be the person responsible\nfor presenting the results.",
    "start": "643620",
    "end": "649230"
  },
  {
    "text": "We'll give you five minutes\nto discuss these questions. And then, we'll ask you\nabout your findings,",
    "start": "649230",
    "end": "656519"
  },
  {
    "text": "and I'll take some notes. Is there anything else? If there is someone else\nin your breakout room",
    "start": "656520",
    "end": "662950"
  },
  {
    "text": "who would rather present it,\nthat's also totally fine. Just if you can't\nreally decide, let's pick the person whose first\nletter of the first name",
    "start": "662950",
    "end": "670710"
  },
  {
    "text": "is closer to the\nbeginning of the alphabet. All right, so let's split\nyou in the breakout rooms,",
    "start": "670710",
    "end": "677550"
  },
  {
    "text": "and I'll see you\nin five minutes. Everyone should be back now.",
    "start": "677550",
    "end": "683070"
  },
  {
    "text": "All right, great. Cool. I hope you had good\nconversations about the problem statement.",
    "start": "683070",
    "end": "689589"
  },
  {
    "text": "So let me switch to the slides. OK, cool. So I'll ask groups\none by one to tell me",
    "start": "689590",
    "end": "698100"
  },
  {
    "text": "about desirable properties\nand considerations, and then also about the\nevaluation setup separately. And I'll try to take some notes.",
    "start": "698100",
    "end": "704800"
  },
  {
    "text": "So let's start with\nroom number one. ",
    "start": "704800",
    "end": "710490"
  },
  {
    "text": "I can talk about it. OK, cool. Cool. So yeah, the example\nsetting that we chose",
    "start": "710490",
    "end": "715870"
  },
  {
    "text": "was League of Legends, or any\nother game for that matter. Yeah, so, the setting would\nbe we have a game bot that's",
    "start": "715870",
    "end": "724269"
  },
  {
    "text": "learning how to play the game. The reason why it would be\nconsidered lifelong learning",
    "start": "724270",
    "end": "729279"
  },
  {
    "text": "is because there are\nconstant patches that are released once\nevery month or so, and the bot has to adapt to--",
    "start": "729280",
    "end": "737019"
  },
  {
    "text": "adapt a player, and then\npick the right champions, pick the right game\nstrategies, stuff like that.",
    "start": "737020",
    "end": "743410"
  },
  {
    "text": "So for the experiment to\ndevelop into this algorithm, it would just be like-- the experiment would\njust be game playing,",
    "start": "743410",
    "end": "749980"
  },
  {
    "text": "and then we could\naccumulate data over patches for\nfour games and then--",
    "start": "749980",
    "end": "756370"
  },
  {
    "text": "it would have to--\nwe would see-- the way we'd test\nit is whether or not it learned to adapt after\nevery patch is released.",
    "start": "756370",
    "end": "762820"
  },
  {
    "text": "And it'll learn to play what the\nmeta picks are, as in like what the best strategy is to play.",
    "start": "762820",
    "end": "769570"
  },
  {
    "text": "And then, pretty\nmuch, we just have to see whether or not the\nbot changes its strategy",
    "start": "769570",
    "end": "776230"
  },
  {
    "text": "as the game environment\nchanges or new patches and stuff like that.",
    "start": "776230",
    "end": "781660"
  },
  {
    "text": "OK, I see. OK. And so what would be-- so you would be just\nmeasuring the pure performance",
    "start": "781660",
    "end": "789190"
  },
  {
    "text": "after the patch. Is that right? That's correct. There's a rating of how you\nplay at the end of the game.",
    "start": "789190",
    "end": "795700"
  },
  {
    "text": "So that rating would\nbe sort of the way we'd measure performance. OK, cool.",
    "start": "795700",
    "end": "802480"
  },
  {
    "text": "I think that makes sense. So should adapt its game--",
    "start": "802480",
    "end": "808269"
  },
  {
    "text": " it's difficult to\nwrite on this-- should",
    "start": "808270",
    "end": "813470"
  },
  {
    "text": "adapt its game after the patch. ",
    "start": "813470",
    "end": "820800"
  },
  {
    "text": "And then could you\ntell me, so would you give it a certain window where\nit can adapt to the new patch",
    "start": "820800",
    "end": "829440"
  },
  {
    "text": "when it can kind of see what\nthe new patch actually is, or would you measure the\nperformance straight away?",
    "start": "829440",
    "end": "835740"
  },
  {
    "text": "Yeah, so it needs to adapt\nquickly enough to keep up with the rest of the players. The players-- human\nplayers themselves",
    "start": "835740",
    "end": "842100"
  },
  {
    "text": "take about a week, or maybe\neven a week and a half sometimes to adapt. And there's a patch\napproximately once every month,",
    "start": "842100",
    "end": "849440"
  },
  {
    "text": "or one and a half months. So it have to adapt\nmaybe at least--",
    "start": "849440",
    "end": "855428"
  },
  {
    "text": "if it adapts slower\nthan the human players, then it's ranking the players-- the bot's ranking would\ngo down in the system.",
    "start": "855428",
    "end": "862080"
  },
  {
    "text": "But if it could adapt faster\nor even at the same time, its ranking would go up.",
    "start": "862080",
    "end": "867670"
  },
  {
    "text": "So the speed of adaptation\nis really a critical factor here for sure.",
    "start": "867670",
    "end": "873090"
  },
  {
    "text": "OK, but you would assume\nthat within a week it should be able to adapt, and\nthere is a new patch coming out",
    "start": "873090",
    "end": "878250"
  },
  {
    "text": "every month. Is that right? Correct, yeah. Cool. Let me put that on. ",
    "start": "878250",
    "end": "889130"
  },
  {
    "text": "And will you ever evaluate\nit on the old performance? So let's say a new\npatch came out,",
    "start": "889130",
    "end": "894710"
  },
  {
    "text": "but you also make sure\nthat before that patch, the previous version,\ndoes it still work?",
    "start": "894710",
    "end": "901210"
  },
  {
    "text": "Not really. The game changes\ntoo drastically. I feel like the play styles\nchange, and the way people--",
    "start": "901210",
    "end": "908110"
  },
  {
    "text": "it's like a completely different\ngame almost after every patch. I don't know. In a way, there\nare common factors.",
    "start": "908110",
    "end": "914357"
  },
  {
    "text": "The main goal of the\ngame is the same. You got to go destroy the\ntowers, beat other champions,",
    "start": "914357",
    "end": "919480"
  },
  {
    "text": "take the nexus. But the way you play\nthe game, the strategies are completely different. Do you go into the jungle?",
    "start": "919480",
    "end": "925420"
  },
  {
    "text": "Do you go to creep? It's like a whole\ndifferent game, which is kind of what\nmakes people addicted to it",
    "start": "925420",
    "end": "931449"
  },
  {
    "text": "because it keeps changing\nconstantly over time. So people keep playing\na new game every time.",
    "start": "931450",
    "end": "937660"
  },
  {
    "text": "So it makes people want\nto come back again.  Cool.",
    "start": "937660",
    "end": "942980"
  },
  {
    "text": "Awesome. Yeah, this is a great example. Is there anything else\nthat you discussed that you'd like to add?",
    "start": "942980",
    "end": "948430"
  },
  {
    "text": "I think that's pretty much it. All right, thank you. Let's move to the group number\ntwo, to room number two.",
    "start": "948430",
    "end": "957240"
  },
  {
    "text": "Hi, can you hear me? Yes. In group two, we\ntalked about how",
    "start": "957240",
    "end": "965180"
  },
  {
    "text": "we would experiment by just\ndoing sort of an ablation test on having all the tasks\nat once versus doing",
    "start": "965180",
    "end": "973050"
  },
  {
    "text": "the tasks in a random order. And similar to homework four,\nhow we had multiple episodes",
    "start": "973050",
    "end": "979399"
  },
  {
    "text": "within a single trial, we\nwould have multiple episodes--",
    "start": "979400",
    "end": "984770"
  },
  {
    "text": "let's just say five episodes-- in a random order, and each\nepisode has a different task",
    "start": "984770",
    "end": "989960"
  },
  {
    "text": "it has to solve. And then, we would test\nthe cumulative return",
    "start": "989960",
    "end": "997520"
  },
  {
    "text": "on all of the episodes, so\nI guess, in this example, five different tasks.",
    "start": "997520",
    "end": "1002920"
  },
  {
    "text": "And that's how we would\nevaluate our algorithm. So it will be sum of returns\nacross all the episodes?",
    "start": "1002920",
    "end": "1011370"
  },
  {
    "text": "Yeah. OK. ",
    "start": "1011370",
    "end": "1020600"
  },
  {
    "text": "And you would be compared-- you'll be comparing it to having\nall the tasks available to you",
    "start": "1020600",
    "end": "1026839"
  },
  {
    "text": "up front? Right. OK, cool. So what are the desirable\nproperties considered?",
    "start": "1026839",
    "end": "1033517"
  },
  {
    "text": "We talked about--\nwe talked about how there might be a distribution\nshift in the tasks",
    "start": "1033518",
    "end": "1040280"
  },
  {
    "text": "that you see earlier in training\nversus later on in training. So it should be adaptable\nto that distribution shift.",
    "start": "1040280",
    "end": "1046159"
  },
  {
    "text": "And it should be able to\neither remember or forget certain skills that it learns\nbased on like an LSTM I guess,",
    "start": "1046160",
    "end": "1055100"
  },
  {
    "text": "if it deems it unnecessary for\nfuture tasks, it should forget.",
    "start": "1055100",
    "end": "1060230"
  },
  {
    "text": "And then we also talk about\nthe capacity of the model should be--",
    "start": "1060230",
    "end": "1065520"
  },
  {
    "text": "it should have a large capacity\nbecause at the end of training, you would in theory, be\nable to do all of the skills",
    "start": "1065520",
    "end": "1073910"
  },
  {
    "text": "that you saw in the past. Oh, interesting.",
    "start": "1073910",
    "end": "1080120"
  },
  {
    "text": "So sorry, I didn't get that. So you're saying that the\ncapability should be-- or the capacity of the\nmodel should be really big,",
    "start": "1080120",
    "end": "1086920"
  },
  {
    "text": "or it should be-- or\nit should be big enough to be able to solve\nall of the tasks. Is that what you said? Yes. ",
    "start": "1086920",
    "end": "1095730"
  },
  {
    "text": "And that's all. OK, big enough capacity.",
    "start": "1095730",
    "end": "1101519"
  },
  {
    "text": "And then, in terms of a concrete\ntask you would evaluate it on,",
    "start": "1101520",
    "end": "1106590"
  },
  {
    "text": "you would take something like\nthe task from homework four? Yeah, we were going\nwith the robot example",
    "start": "1106590",
    "end": "1112680"
  },
  {
    "text": "because we were talking\nabout sort of a reinforcement learning context.",
    "start": "1112680",
    "end": "1118139"
  },
  {
    "text": "Cool, awesome. Thank you. Anything else that\nyou would like to add? No, that was all.",
    "start": "1118140",
    "end": "1124180"
  },
  {
    "text": "All right, thanks a lot. Let's move to\ngroup number three. ",
    "start": "1124180",
    "end": "1133759"
  },
  {
    "text": "Hello. Hello.  So, let me think it over.",
    "start": "1133760",
    "end": "1143290"
  },
  {
    "text": "So we were discussing\nthe example B, sort of like the Corey image\nclassification system.",
    "start": "1143290",
    "end": "1151570"
  },
  {
    "text": "Specifically, we\nwere talking about if we have a facial\nclassification system where",
    "start": "1151570",
    "end": "1157450"
  },
  {
    "text": "we constantly get new\nimages of people we already",
    "start": "1157450",
    "end": "1162700"
  },
  {
    "text": "have in Google and new\npeople, or new faces as well as an overall\nover time distribution",
    "start": "1162700",
    "end": "1170015"
  },
  {
    "text": "shift of what images look like.",
    "start": "1170015",
    "end": "1175130"
  },
  {
    "text": "So what we're thinking\nin terms of evaluating",
    "start": "1175130",
    "end": "1183430"
  },
  {
    "text": "an algorithm for those things,\nmaybe keeping track opa-- over time, keeping\nsome sort of test",
    "start": "1183430",
    "end": "1191980"
  },
  {
    "text": "set of images across\na series of time. And essentially, as\nwe add more images,",
    "start": "1191980",
    "end": "1198279"
  },
  {
    "text": "we sort of filter or split\noff some to [INAUDIBLE] while",
    "start": "1198280",
    "end": "1203500"
  },
  {
    "text": "also perhaps, dropping off\nsome of the older images with some [INAUDIBLE]\nwith some [INAUDIBLE]..",
    "start": "1203500",
    "end": "1213040"
  },
  {
    "text": "Essentially, what we\nwant is, over time, our algorithm should\nperform better and better",
    "start": "1213040",
    "end": "1219490"
  },
  {
    "text": "on ordering images\nor on a more-- ",
    "start": "1219490",
    "end": "1226520"
  },
  {
    "text": "Who will be controlling\nhow it changes? ",
    "start": "1226520",
    "end": "1232570"
  },
  {
    "text": "So what we were\nthinking is over time, we want a bias toward\nperhaps newer faces in this classification\nsystem as maybe faces",
    "start": "1232570",
    "end": "1240885"
  },
  {
    "text": "that showed up earlier in the-- earlier in the stream of images\nmay not be as relevant now",
    "start": "1240885",
    "end": "1248340"
  },
  {
    "text": "or may not show up anymore\nin our whole application,",
    "start": "1248340",
    "end": "1255390"
  },
  {
    "text": "in addition to\nnew images perhaps being on average, higher quality\nor different setups over time.",
    "start": "1255390",
    "end": "1263380"
  },
  {
    "text": "I see. That makes sense. And then the desirable property\nis that the algorithm does well",
    "start": "1263380",
    "end": "1269550"
  },
  {
    "text": "on newer images? Yeah. ",
    "start": "1269550",
    "end": "1275600"
  },
  {
    "text": "And in particular,\nwe sort of want it to do better I guess on\nimages that are essentially",
    "start": "1275600",
    "end": "1284990"
  },
  {
    "text": "more common nowadays. So for example, if\nsome individual person",
    "start": "1284990",
    "end": "1290100"
  },
  {
    "text": "is super relevant through facial\nclassification nowadays like-- I don't know-- we\nwant to be very",
    "start": "1290100",
    "end": "1300090"
  },
  {
    "text": "accurate in terms of classifying\nwho Professor Finn is.",
    "start": "1300090",
    "end": "1308565"
  },
  {
    "text": "Then we may want to have\nessentially, bias perhaps or set towards importance\nfor those faces",
    "start": "1308565",
    "end": "1315086"
  },
  {
    "text": "or for those types of images. I see, OK, so bias towards\nmore important images, whatever",
    "start": "1315086",
    "end": "1327559"
  },
  {
    "text": "that means. [LAUGHS] Yeah. ",
    "start": "1327560",
    "end": "1335320"
  },
  {
    "text": "OK, I think that sounds good. And will you be still evaluating\non all the images, or--",
    "start": "1335320",
    "end": "1344081"
  },
  {
    "text": "people are also\nchanging, and their faces are changing-- will\nyou always keep a certain set of images\nfrom the past to make sure",
    "start": "1344082",
    "end": "1350769"
  },
  {
    "text": "that it does well on those? Yeah, I think we--",
    "start": "1350770",
    "end": "1356630"
  },
  {
    "text": "I guess it depends a little bit\non the downstream application. I'm thinking in\nmost cases, we may",
    "start": "1356630",
    "end": "1364460"
  },
  {
    "text": "want to keep some old\nimages but also slowly, eventually decrease\ntheir proportion.",
    "start": "1364460",
    "end": "1370380"
  },
  {
    "text": "So something I mentioned\nat the beginning was maybe essentially have\nlike a drop off probability",
    "start": "1370380",
    "end": "1377390"
  },
  {
    "text": "as we move on. We have some chance of\ngradually dropping older images.",
    "start": "1377390",
    "end": "1385040"
  },
  {
    "text": "So that way we'd have still-- or we'd have more emphasis\non the newer ones.",
    "start": "1385040",
    "end": "1390905"
  },
  {
    "text": " OK, I think that makes sense.",
    "start": "1390905",
    "end": "1396090"
  },
  {
    "text": "Cool. Is there anything else\nthat you'd like to add? No, not really.",
    "start": "1396090",
    "end": "1401912"
  },
  {
    "text": "No. Thank you. And thanks for coming\nto the lecture.",
    "start": "1401912",
    "end": "1407730"
  },
  {
    "text": "But also, the Wednesday\nlecture will be also on Zoom. So you know we do this.",
    "start": "1407730",
    "end": "1415005"
  },
  {
    "text": "Yeah. All right, room number four,\nI think that's our last room. ",
    "start": "1415005",
    "end": "1427549"
  },
  {
    "text": "Well, I guess I\ncan talk about it. So we considered a sort of\ngeneral classification setting",
    "start": "1427550",
    "end": "1434450"
  },
  {
    "text": "where each task is a\nclassification problem. So maybe a bit similar to\nthe first situation where",
    "start": "1434450",
    "end": "1439880"
  },
  {
    "text": "you have a student\nlearning new concepts, and the students ask questions\nwith descriptive answers.",
    "start": "1439880",
    "end": "1447890"
  },
  {
    "text": "In addition to what\nmentioned previously, we thought that we'd consider\ntwo additional evaluation",
    "start": "1447890",
    "end": "1456020"
  },
  {
    "text": "metrics. So one of them is sort\nof a forward transfer.",
    "start": "1456020",
    "end": "1461720"
  },
  {
    "text": "So ideally, if we\ntrain on one task, that would improve performance\nfor future tasks as well.",
    "start": "1461720",
    "end": "1470035"
  },
  {
    "text": "But then, on the\nother side, we'd also like to prevent\ncatastrophically forgetting",
    "start": "1470035",
    "end": "1475490"
  },
  {
    "text": "things about the old tasks. So if we learn a new\ntask in the future, we'd like to retain knowledge,\nor maybe even improve knowledge",
    "start": "1475490",
    "end": "1483980"
  },
  {
    "text": "for a task we've\nseen previously. OK, yeah.",
    "start": "1483980",
    "end": "1489820"
  },
  {
    "text": "That's a really good point. So prevent catastrophic\nforgetting-- and to do this, you would keep a I\nguess, a set of images",
    "start": "1489820",
    "end": "1497059"
  },
  {
    "text": "or a set of evaluations\nfor older tasks? Yeah, exactly.",
    "start": "1497060",
    "end": "1502580"
  },
  {
    "text": "We thought we'd have\nsome uniform [INAUDIBLE] set for each class that's\njust designated as a test set",
    "start": "1502580",
    "end": "1512330"
  },
  {
    "text": "that we don't see\nduring training, and then we can evaluate it\nafter training on each task. I see.",
    "start": "1512330",
    "end": "1517658"
  },
  {
    "text": "OK. And how would you\nevaluate forward transfer? So you will be given a new\nset of images, I assume,",
    "start": "1517658",
    "end": "1524120"
  },
  {
    "text": "or a new set of tasks. And then will you have some\nkind of learning period where you can adapt,\nor will you be evaluating this straightaway?",
    "start": "1524120",
    "end": "1531380"
  },
  {
    "text": "We thought we'd just\nevaluate it straightaway. OK. OK. Cool. ",
    "start": "1531380",
    "end": "1544980"
  },
  {
    "text": "Is there anything else\nthat you would like to add? ",
    "start": "1544980",
    "end": "1552122"
  },
  {
    "text": "I think that's all\nwe discussed earlier. ",
    "start": "1552123",
    "end": "1557830"
  },
  {
    "text": "I'm not sure if I put the notes\nin the right column sometimes. But I tried to put\nthem then-- put them",
    "start": "1557830",
    "end": "1564309"
  },
  {
    "text": "on the way you were saying. Awesome, thank you so\nmuch to all four groups.",
    "start": "1564310",
    "end": "1571159"
  },
  {
    "text": "So one thing we can notice here\nis that first, the examples were quite diverse.",
    "start": "1571160",
    "end": "1577960"
  },
  {
    "text": "I guess, we had two image\nclassification settings. But overall, we have\nrobotic settings,",
    "start": "1577960",
    "end": "1585010"
  },
  {
    "text": "we have League of Legends\nsetting, even specification. So that's really great to see.",
    "start": "1585010",
    "end": "1591230"
  },
  {
    "text": "And in terms of how\nto evaluate things, you can see that it actually\nchanges quite a bit. Some algorithms look at backward\ncompatibility, some don't.",
    "start": "1591230",
    "end": "1600760"
  },
  {
    "text": "The group number four\ncared about preventing catastrophic forgetting. Group number one didn't\nreally care about this",
    "start": "1600760",
    "end": "1606220"
  },
  {
    "text": "because you only need to\nadjust to the newest patch. And group number three\nhad something in between. ",
    "start": "1606220",
    "end": "1614049"
  },
  {
    "text": "Then we see that\ndifferent groups would evaluate the algorithm\noverall differently.",
    "start": "1614050",
    "end": "1619720"
  },
  {
    "text": "Group number two would\ncompare it to the performance that we see when we\ntrain on all of the tasks",
    "start": "1619720",
    "end": "1625270"
  },
  {
    "text": "versus with some\nother groups would look at how well our\nlearning transfers to the next task and\nthings like that.",
    "start": "1625270",
    "end": "1631870"
  },
  {
    "text": "Cool.  Yeah, so there is quite\na lot of variability.",
    "start": "1631870",
    "end": "1639020"
  },
  {
    "text": "So here are a few\nproblem variations that I thought of as well.",
    "start": "1639020",
    "end": "1644390"
  },
  {
    "text": "So one variation\nthat we can have is whether we know about\nthe task and data order",
    "start": "1644390",
    "end": "1650650"
  },
  {
    "text": "and whether it's predictable\nor whether it's just i.i.d., or whether it's some\nkind of curriculum",
    "start": "1650650",
    "end": "1655930"
  },
  {
    "text": "or if it's adversarial\nto us and so on. So if it's i.i.d, then we're\ngiven new tasks every now",
    "start": "1655930",
    "end": "1661030"
  },
  {
    "text": "and then, and that's it. They come from the\nsame distribution. If it's predictable,\nthen maybe it's",
    "start": "1661030",
    "end": "1667630"
  },
  {
    "text": "something like the seasons\nwhere you can predict that there are certain--",
    "start": "1667630",
    "end": "1673210"
  },
  {
    "text": "there's a periodicity to them. So summer comes every\nyear, and so on.",
    "start": "1673210",
    "end": "1679659"
  },
  {
    "text": "They can come in the\nform of curriculum where you get harder and\nharder tests like you",
    "start": "1679660",
    "end": "1684700"
  },
  {
    "text": "do in school, for instance. Or they could be adversarial. Maybe that's the case\nin League of Legends",
    "start": "1684700",
    "end": "1689890"
  },
  {
    "text": "where maybe the\nnew patches are so that the old strategies\nare not really working with the new patch.",
    "start": "1689890",
    "end": "1697940"
  },
  {
    "text": "The other consideration\nis whether we have discrete task boundaries\nversus continuous shift.",
    "start": "1697940",
    "end": "1704000"
  },
  {
    "text": "So sometimes, you can clearly\ntell that this patch has ended, a new patch has been released.",
    "start": "1704000",
    "end": "1710090"
  },
  {
    "text": "And from now on, the\ngame is different. There is a very\ndiscrete task boundary. Versus if it's for instance,\nthe weather that is changing,",
    "start": "1710090",
    "end": "1717170"
  },
  {
    "text": "it's going to be harder\nto say at this point, the weather has changed. The weather is kind of\ncontinuously shifting.",
    "start": "1717170",
    "end": "1723169"
  },
  {
    "text": "And we could also have\ninstances of both. And we can have known\ntask boundaries--",
    "start": "1723170",
    "end": "1729180"
  },
  {
    "text": "so someone can tell us that\nthey were released a new patch-- or unknown that we then\nneed to detect in some way.",
    "start": "1729180",
    "end": "1736880"
  },
  {
    "text": "And in terms of some\nconsiderations, a lot of them you talked about as well-- so model performance.",
    "start": "1736880",
    "end": "1742490"
  },
  {
    "text": "We can also look at data\nefficiency, how much data we need to achieve a\ncertain performance. These are kind of\nsimilar metrics",
    "start": "1742490",
    "end": "1748029"
  },
  {
    "text": "that we would use in standard\nsupervised learning settings. We can also look at the\ncomputational resources",
    "start": "1748030",
    "end": "1753890"
  },
  {
    "text": "and the memory. So whether we need to\nkeep all the old test data, all the old tasks\nin the memory or not.",
    "start": "1753890",
    "end": "1760850"
  },
  {
    "text": "What was the memory\nfootprint of the algorithm. And then there are other\nthings such as privacy,",
    "start": "1760850",
    "end": "1766880"
  },
  {
    "text": "interpretability, fairness,\ntest time compute and memory. So these are things that\nare really important",
    "start": "1766880",
    "end": "1773527"
  },
  {
    "text": "and that are also important\nin supervised learning settings that are-- that also apply here.",
    "start": "1773527",
    "end": "1780670"
  },
  {
    "text": "But one thing to note that I\nwould like you to keep in mind is that there is actually\na substantial variety",
    "start": "1780670",
    "end": "1785700"
  },
  {
    "text": "in the problem statement itself. And when we discussed some\nother types of learning before,",
    "start": "1785700",
    "end": "1791100"
  },
  {
    "text": "like multi-task learning,\nmeta learning, reinforcement learning, multi-task\nreinforcement learning and so",
    "start": "1791100",
    "end": "1796200"
  },
  {
    "text": "on, the problem statement\nis relatively rigid.",
    "start": "1796200",
    "end": "1802529"
  },
  {
    "text": "It's well defined. We know what we\nare optimizing for, and if you look at\ndifferent papers doing offline reinforcement learning,\nvery often they would assume--",
    "start": "1802530",
    "end": "1810205"
  },
  {
    "text": "they would have exact\nsame assumptions, and they would be trying\nto solve the same problem. This is often not the case in\nthe lifelong learning setting.",
    "start": "1810205",
    "end": "1817300"
  },
  {
    "text": "And this is something\nto keep in mind when you read lifelong learning papers. ",
    "start": "1817300",
    "end": "1825192"
  },
  {
    "text": "Great. So let's go over the\ngeneral definition of how a general\nsupervised online learning",
    "start": "1825192",
    "end": "1833740"
  },
  {
    "text": "problem looks like and how\npeople usually think about it. And then we'll also talk about\nwhat are the different ways",
    "start": "1833740",
    "end": "1841148"
  },
  {
    "text": "to evaluate it that are\nkind of well-established. And some of them, you\nalready mentioned.",
    "start": "1841148",
    "end": "1846559"
  },
  {
    "text": "So for the general online\nsupervised learning problem, for every task or for every\ndata point, we'll observe our x.",
    "start": "1846560",
    "end": "1854020"
  },
  {
    "text": "Then we'll have\nto predict the y. And then we'll get\nto observe the label.",
    "start": "1854020",
    "end": "1860020"
  },
  {
    "text": "So you get the x, and you\nhave to predict the output, and then you get to observe\nthe label on the [INAUDIBLE]..",
    "start": "1860020",
    "end": "1868100"
  },
  {
    "text": "This could happen in\nthe i.i.d. setting where the probability of p of\nx as well as p of y given x",
    "start": "1868100",
    "end": "1876020"
  },
  {
    "text": "is not time-dependent. This is-- this probability\nof distribution",
    "start": "1876020",
    "end": "1881090"
  },
  {
    "text": "doesn't change over time. Or it could be a\ntime-dependent distribution",
    "start": "1881090",
    "end": "1886920"
  },
  {
    "text": "where our xt is coming from\nthe distribution pt of x And.",
    "start": "1886920",
    "end": "1892830"
  },
  {
    "text": "The same for yt is coming from\nthe distribution pt of y given x. So the distribution\nis changing over time,",
    "start": "1892830",
    "end": "1898210"
  },
  {
    "text": "and we talked about different\nways how it could be changing. It could be a curriculum. It could be\nadversarial and so on.",
    "start": "1898210",
    "end": "1905420"
  },
  {
    "text": "Then we sometimes also\nconsider a streaming setting in which you can't truly\nstore your current pairs of xt",
    "start": "1905420",
    "end": "1913160"
  },
  {
    "text": "and yt. So you kind of have\nto make a prediction, but you can't\nreally store those. And there's various\nreasons for that.",
    "start": "1913160",
    "end": "1919429"
  },
  {
    "text": "For instance, you don't\nhave the memory to do that. For instance, you're trying\nto do some work on video.",
    "start": "1919430",
    "end": "1924650"
  },
  {
    "text": "And video streaming at\nvery high frequency, and you don't really\nhave enough memory to store all the\ndifferent images that you",
    "start": "1924650",
    "end": "1930570"
  },
  {
    "text": "see in the video. Sometimes, we don't have\nenough computational resources to do that.",
    "start": "1930570",
    "end": "1936130"
  },
  {
    "text": "There could be some\nprivacy considerations where you can't really store\nimages of people, for instance.",
    "start": "1936130",
    "end": "1942019"
  },
  {
    "text": "Or when you want to study\nneural memory mechanisms, those are some-- they're biologically\nplausible mechanisms--",
    "start": "1942020",
    "end": "1949880"
  },
  {
    "text": "how we memorize things,\nand how we adapt. And in that case, we don't\nreally have a very hard memory",
    "start": "1949880",
    "end": "1958280"
  },
  {
    "text": "like we do in computers where\nwe can just store all the data. So when people study\nthese kind of mechanisms,",
    "start": "1958280",
    "end": "1963650"
  },
  {
    "text": "they usually also assume\nthis streaming setting. So overall, this is\ntrue in some cases,",
    "start": "1963650",
    "end": "1969160"
  },
  {
    "text": "but also not in\nmany other cases. And most of the cases\nwe'll be discussing today,",
    "start": "1969160",
    "end": "1974230"
  },
  {
    "text": "will be the cases where\nyou don't really have to be in the streaming setting. You are allowed-- you can\nstore the data as you see it.",
    "start": "1974230",
    "end": "1981700"
  },
  {
    "text": " We actually already discussed\nsome of these things, for instance, in the\ncase of replay buffers.",
    "start": "1981700",
    "end": "1988929"
  },
  {
    "text": "Where in reinforcement\nlearning, you can be storing your\nexperiences, you can keep storing everything\nyou see in the replay buffer.",
    "start": "1988930",
    "end": "1994970"
  },
  {
    "text": "And then you have\nalgorithms that can retrieve that experience\nfrom the replay buffer and learn based on that. ",
    "start": "1994970",
    "end": "2003600"
  },
  {
    "text": "Then one other note regarding\nthe online learning problem. If we have observable\ntask boundaries--",
    "start": "2003600",
    "end": "2010578"
  },
  {
    "text": "if we know that a\nnew task is coming, then we would not only\nobserve the new data point xt, but we'll also know\nwhat task it comes from.",
    "start": "2010578",
    "end": "2017200"
  },
  {
    "text": "So it's some-- depicted by\nsome task descriptors zt, for instance, a one-hot vector\nor natural language description",
    "start": "2017200",
    "end": "2023640"
  },
  {
    "text": "or something like that. All right, so then\nthe next question",
    "start": "2023640",
    "end": "2028900"
  },
  {
    "text": "is, how do we evaluate it? What do we actually want from\na lifelong learning algorithm?",
    "start": "2028900",
    "end": "2034510"
  },
  {
    "text": "And what people usually refer\nto here are two measures. And the first one is regret.",
    "start": "2034510",
    "end": "2040980"
  },
  {
    "text": "So what people usually\nwant is minimal regrets, or regret that grow\nslowly with number of paths",
    "start": "2040980",
    "end": "2046559"
  },
  {
    "text": "or with number of data points. And regret is actually a well\ndefined mathematical quantity.",
    "start": "2046560",
    "end": "2051810"
  },
  {
    "text": "And it's defined as following--\nas a cumulative loss of your learner minus the\ncumulative loss of the best",
    "start": "2051810",
    "end": "2059820"
  },
  {
    "text": "learner in hindsight. So this is very similar to what\ngroup two was proposing where",
    "start": "2059820",
    "end": "2065908"
  },
  {
    "text": "you can see how well your\nlearner is doing at each task as the task come.",
    "start": "2065909",
    "end": "2072179"
  },
  {
    "text": "And then compare it\nto the cumulative loss of the best learner\nin hindsight that",
    "start": "2072179",
    "end": "2077429"
  },
  {
    "text": "would have had access to all\nof the tasks all at once. So mathematically,\nyou can define it as--",
    "start": "2077429",
    "end": "2084949"
  },
  {
    "text": "actually, I can\njust get the pen.",
    "start": "2084949",
    "end": "2090399"
  },
  {
    "text": "So here, we have the\ncumulative loss of the learner. So in that case,\nat every time step",
    "start": "2090400",
    "end": "2096460"
  },
  {
    "text": "or at every data\npoint of every task t, you'll be coming up\nwith your parameters of your model, theta t.",
    "start": "2096460",
    "end": "2102970"
  },
  {
    "text": "And then we'll be summing over-- this will be the cumulative\nloss of the learner",
    "start": "2102970",
    "end": "2109630"
  },
  {
    "text": "for each one of the task. So we're summing over all the\ntasks or all the data points that we see.",
    "start": "2109630",
    "end": "2115340"
  },
  {
    "text": "And from that, we subtract\nthe best cumulative loss, or the cumulative loss of the\nbest learner in hindsight.",
    "start": "2115340",
    "end": "2121760"
  },
  {
    "text": "So in that case, you have access\nto all of the tasks upfront. You can minimize your parameters\nacross all of those tasks.",
    "start": "2121760",
    "end": "2128480"
  },
  {
    "text": "And then the loss\nthat you get for that is kind of the best loss you\nwould have gotten in hindsight. So had you known about\nall of these tasks",
    "start": "2128480",
    "end": "2134388"
  },
  {
    "text": "upfront, what kind of loss\nyou would have gotten.",
    "start": "2134388",
    "end": "2139480"
  },
  {
    "text": "This cannot be evaluated in\npractice because we would always need to be doing that.",
    "start": "2139480",
    "end": "2145310"
  },
  {
    "text": "But it's really\nuseful for analysis. And in fact, the regret that\ngrows linearly in t, in number",
    "start": "2145310",
    "end": "2154569"
  },
  {
    "text": "of data points is trivial. So one question I have\nto you is why do this?",
    "start": "2154570",
    "end": "2159770"
  },
  {
    "text": "Can you give me an example\nof an algorithm that produces linear\nregret, or regret",
    "start": "2159770",
    "end": "2164800"
  },
  {
    "text": "that grows linearly in t. ",
    "start": "2164800",
    "end": "2171079"
  },
  {
    "text": "You can just unmute yourself and\nspeak up if you have an idea. ",
    "start": "2171080",
    "end": "2186050"
  },
  {
    "text": "Why does regret that grows\nlinearly in t is trivial? Can you think of an algorithm\nthat produces a linear regret?",
    "start": "2186050",
    "end": "2192370"
  },
  {
    "start": "2192370",
    "end": "2203986"
  },
  {
    "text": "Any ideas here? ",
    "start": "2203986",
    "end": "2210970"
  },
  {
    "text": "All right, not so far. So let me go through a\nlittle example that might clarify this a little bit.",
    "start": "2210970",
    "end": "2218910"
  },
  {
    "text": "So the example will\nbe the following. We'll be trying to predict.",
    "start": "2218910",
    "end": "2225360"
  },
  {
    "text": "We will be situated\nin a basketball game when you are betting on how many\npoints will a NBA player score.",
    "start": "2225360",
    "end": "2235500"
  },
  {
    "text": "And then your loss will be\ndependent on the difference between the absolute difference\nbetween how many points they",
    "start": "2235500",
    "end": "2241650"
  },
  {
    "text": "actually scored versus how\nmany points you predicted that they score, all right?",
    "start": "2241650",
    "end": "2246839"
  },
  {
    "text": "So for the very\nfirst game, you get to see this new\nbasketball player that",
    "start": "2246840",
    "end": "2253590"
  },
  {
    "text": "just joined the NBA. His name is Michael Jordan. But you never-- you've never\nseen him play in the NBA,",
    "start": "2253590",
    "end": "2259350"
  },
  {
    "text": "so you have to kind of\npredict how many points he's going to score. You have to make a bet, right? So based on what you've seen\nso far, which is basically",
    "start": "2259350",
    "end": "2267530"
  },
  {
    "text": "nothing, you're predicting\nthat given that-- given all the NBA\nplayers in the past,",
    "start": "2267530",
    "end": "2273840"
  },
  {
    "text": "he might score something\nlike 10 points. He's a rookie. He seems kind of promising.",
    "start": "2273840",
    "end": "2279268"
  },
  {
    "text": "Let's give him 10 points. That's your prediction. And then you actually get\nto see the game afterwards.",
    "start": "2279268",
    "end": "2285110"
  },
  {
    "text": "And you get to observe how\nmany points he actually scored. And it turns out he\nscored 30 points.",
    "start": "2285110",
    "end": "2291125"
  },
  {
    "text": " So now let's say game\nnumber two comes about.",
    "start": "2291125",
    "end": "2299070"
  },
  {
    "text": "And now, you have to\nmake a new prediction. And let's say that\nyou're not a very--",
    "start": "2299070",
    "end": "2304710"
  },
  {
    "text": "you're a very-- you're\na very stubborn person, and you think that\nyou're not really going to adjust\nbased on the evidence",
    "start": "2304710",
    "end": "2311390"
  },
  {
    "text": "that you've seen so far. And you'll just say, well,\nI'm going to stick to my guns. He's going to score\n10 points again.",
    "start": "2311390",
    "end": "2317640"
  },
  {
    "text": "So just repeat the same bet. And then you get to\nobserve the second game, and he actually\nscores 28 points.",
    "start": "2317640",
    "end": "2325390"
  },
  {
    "text": "And then the same repeats\nwould be number three. You've seen these\nprevious two games, but again, you're\nquite stubborn.",
    "start": "2325390",
    "end": "2330970"
  },
  {
    "text": "You want to stick\nto your prediction. You always say that he's\ngoing to score 10 points. He actually scores 32 points.",
    "start": "2330970",
    "end": "2338380"
  },
  {
    "text": "All right, in that case, we\ncan calculate the regret. So let's see.",
    "start": "2338380",
    "end": "2344215"
  },
  {
    "text": " OK, so let's compute\nthe first term.",
    "start": "2344215",
    "end": "2351010"
  },
  {
    "text": "[INAUDIBLE] So the first term in the case of\nt equal 1, would be just equal",
    "start": "2351010",
    "end": "2361210"
  },
  {
    "text": "20, right? That's the absolute\ndifference between what you predicted it was going to\nbe versus what it actually was.",
    "start": "2361210",
    "end": "2369490"
  },
  {
    "text": "And then t equals 1, we\nhave 20 minus the best",
    "start": "2369490",
    "end": "2377010"
  },
  {
    "text": "learner in hindsight. So the best learner\nin hindsight, you would have to predict the\nbest kind of single number. That would be 30.",
    "start": "2377010",
    "end": "2382752"
  },
  {
    "text": "And then the\ndifference would be 0. So 20 minus 0, your\nregret would be 20, right?",
    "start": "2382752",
    "end": "2389400"
  },
  {
    "text": "So for t equal 2, or\nfor capital T, rather.",
    "start": "2389400",
    "end": "2397059"
  },
  {
    "text": "So we'll be summing over-- ",
    "start": "2397060",
    "end": "2402210"
  },
  {
    "text": "summing over two games, The\noriginal difference was 20.",
    "start": "2402210",
    "end": "2407280"
  },
  {
    "text": "Now you get the additional\ndifference of 18. So that's 38.",
    "start": "2407280",
    "end": "2412970"
  },
  {
    "text": "This is the cumulative\nloss of your learner, 38, minus the best learner that\nyou could have in hindsight.",
    "start": "2412970",
    "end": "2420410"
  },
  {
    "text": "You could have predicted\nan average of those two. So that would be 29. So then the difference would\nbe 2 because 30 minus 29 is 1,",
    "start": "2420410",
    "end": "2428000"
  },
  {
    "text": "and 28 minus 29 is 1 as well,\nthe absolute difference. So in that case,\nregret would be 36.",
    "start": "2428000",
    "end": "2435085"
  },
  {
    "text": " And for a capital T equals 3,\nit would have the difference",
    "start": "2435085",
    "end": "2443070"
  },
  {
    "text": "be what it was so far. So that was 38 plus\nnow an additional 22.",
    "start": "2443070",
    "end": "2452010"
  },
  {
    "text": "So that's 60.  And then the best learner that\nyou could have in hindsight",
    "start": "2452010",
    "end": "2460859"
  },
  {
    "text": "would have been the average. So the average across\nall of these would be 30.",
    "start": "2460860",
    "end": "2466680"
  },
  {
    "text": "And in that case,\nthe loss would be 4. So in that case, would be 56.",
    "start": "2466680",
    "end": "2472920"
  },
  {
    "text": "So now you can see\nthat the regret-- here it grew by 16.",
    "start": "2472920",
    "end": "2480144"
  },
  {
    "text": "Here it grew by 20. And if we continue\ndoing this exercise, here on the average you would\nbe saying 10, versus here",
    "start": "2480144",
    "end": "2488609"
  },
  {
    "text": "on average you'll be saying 30. So if every new game will\nbe getting a larger regret,",
    "start": "2488610",
    "end": "2496260"
  },
  {
    "text": "the regret will\nbe growing by 20. So we'll be growing\nlinearly in t. So you're a very-- this is\na very simple algorithm that",
    "start": "2496260",
    "end": "2504030"
  },
  {
    "text": "doesn't really-- it's trivial. That we don't really adjust\nbased on the evidence that you see. Your learner--\nyour online learner",
    "start": "2504030",
    "end": "2510450"
  },
  {
    "text": "is not really getting\nbetter with more data and with more tasks. It's just constantly\noutputting the same thing.",
    "start": "2510450",
    "end": "2516339"
  },
  {
    "text": "And in that case, the\nregret is linear in t. Now, you could think of\na different algorithm",
    "start": "2516340",
    "end": "2522070"
  },
  {
    "text": "where instead, you look at the\nbest learner with all the games",
    "start": "2522070",
    "end": "2527840"
  },
  {
    "text": "that you've seen already. So rather than for the\nsecond game predicting 10, you would predict the score that\nyou had in the previous game.",
    "start": "2527840",
    "end": "2536440"
  },
  {
    "text": "So you would say 30. And here, for the\nthird game, you would just take the average\nof the previous two games.",
    "start": "2536440",
    "end": "2542470"
  },
  {
    "text": "And this is similar to follow\nthe leader algorithm where you kind of take\nthe best algorithm--",
    "start": "2542470",
    "end": "2549910"
  },
  {
    "text": "or the best learner given\nall the previous data and apply it to\nthe new data point.",
    "start": "2549910",
    "end": "2557610"
  },
  {
    "text": "Are there any\nquestions at this time? ",
    "start": "2557610",
    "end": "2566980"
  },
  {
    "text": "All right, no questions? OK, cool. So there is this other method\nthat is much more practical",
    "start": "2566980",
    "end": "2572283"
  },
  {
    "text": "that people actually use\nquite often, which is positive and negative transfer. ",
    "start": "2572283",
    "end": "2578380"
  },
  {
    "text": "And these apply to forward\nas well as backward transfer. So the positive\nforward transfer would",
    "start": "2578380",
    "end": "2584140"
  },
  {
    "text": "mean that previous\ntests cause you to do better in future tasks. And this is something I\nthink that group number four",
    "start": "2584140",
    "end": "2591160"
  },
  {
    "text": "discussed, where you\nwant to make sure that by leveraging data\nfrom the old tasks,",
    "start": "2591160",
    "end": "2597450"
  },
  {
    "text": "you're getting better\nand better at new tasks. And this is compared to learning\nfuture tasks from scratch.",
    "start": "2597450",
    "end": "2604329"
  },
  {
    "text": "And then we have positive\nbackward transfer, which means that the\ncurrent task cause you to do better\non previous tasks",
    "start": "2604330",
    "end": "2611090"
  },
  {
    "text": "compared to learning\npast tasks from scratch. And then if you want\nto think about them",
    "start": "2611090",
    "end": "2616360"
  },
  {
    "text": "as negative transfer,\nyou would just need to change the\npositive word to negative. And if you swap\nbetter with worse,",
    "start": "2616360",
    "end": "2623440"
  },
  {
    "text": "you would get the definitions\nof negative transfer. So this is actually\nmeasurable, and this is often",
    "start": "2623440",
    "end": "2629230"
  },
  {
    "text": "what people use in their papers. ",
    "start": "2629230",
    "end": "2634690"
  },
  {
    "text": "So this is the lifelong\nlearning problem statement that is a little ambiguous at times.",
    "start": "2634690",
    "end": "2641170"
  },
  {
    "text": "We discussed some measures of\nhow people measure progress on that problem. Are there any questions\nat this point?",
    "start": "2641170",
    "end": "2647050"
  },
  {
    "start": "2647050",
    "end": "2653040"
  },
  {
    "text": "All right, no\nquestions, so let's talk about some basic\napproaches to lifelong learning.",
    "start": "2653040",
    "end": "2659029"
  },
  {
    "text": "So there are a few\nvery basic approaches that we can think of. For instance, we can store all\nthe data you've seen so far",
    "start": "2659030",
    "end": "2666349"
  },
  {
    "text": "and just train on it. And this is what we call\nfollow the leader algorithm. This is similar to this\nmodification of the sports",
    "start": "2666350",
    "end": "2673310"
  },
  {
    "text": "betting game where\nyou're looking at the average of the points\nthat Michael Jordan scored",
    "start": "2673310",
    "end": "2679550"
  },
  {
    "text": "in the past games. Now, this will achieve\nvery strong performance. This is actually a\nreally good baseline.",
    "start": "2679550",
    "end": "2686790"
  },
  {
    "text": "It's computationally\nquite intensive. You have to store all the\ndata that you've seen so far. And I guess, in the\ncase of the algorithm",
    "start": "2686790",
    "end": "2693510"
  },
  {
    "text": "that we discussed before\nyou could be running some kind of running average. But overall, if you\nwanted to apply it",
    "start": "2693510",
    "end": "2699312"
  },
  {
    "text": "to more complex\nproblems, you would need to store all of the data. ",
    "start": "2699312",
    "end": "2704690"
  },
  {
    "text": "And you would need to kind\nof keep retraining things all the time.",
    "start": "2704690",
    "end": "2709800"
  },
  {
    "text": "Something like continuous\nfine tuning can help you. So this is what I\nmentioned before.",
    "start": "2709800",
    "end": "2714820"
  },
  {
    "text": "It could be memory intensive. It depends on the application. The other options\nthat you have is",
    "start": "2714820",
    "end": "2720980"
  },
  {
    "text": "just take a gradient\nstep on the datapoint that you just observe.d So\nyou observe a new datapoint.",
    "start": "2720980",
    "end": "2726090"
  },
  {
    "text": "You can take a gradient step\nin respect to that datapoint. Now, this is something\nthat you actually know,",
    "start": "2726090",
    "end": "2731350"
  },
  {
    "text": "and you use it all the time. And this is called\nstochastic gradient descent.",
    "start": "2731350",
    "end": "2736390"
  },
  {
    "text": "So in that case, it's really\ncomputationally cheap. You just apply a\nsingle gradient step. You can do this\nvery, very easily.",
    "start": "2736390",
    "end": "2743460"
  },
  {
    "text": "It requires zero memory, but it\nis subject to negative backward transfer, right?",
    "start": "2743460",
    "end": "2748930"
  },
  {
    "text": "So as you're applying new\ngradients to new datapoints, you are not really keeping\nany old data points,",
    "start": "2748930",
    "end": "2754920"
  },
  {
    "text": "and you're not\nupdating your weights based on those old data points. So it's quite likely that\nyou will forget about them.",
    "start": "2754920",
    "end": "2763119"
  },
  {
    "text": "So in fact, people refer\nto it as forgetting or as one of the other groups\nsaid, catastrophic forgetting.",
    "start": "2763120",
    "end": "2770260"
  },
  {
    "text": "So these are the two terms that\npeople often use for this case. ",
    "start": "2770260",
    "end": "2778660"
  },
  {
    "text": "The other part of this\napproach is that it can be very slow as well.",
    "start": "2778660",
    "end": "2784110"
  },
  {
    "text": "All right, so let's discuss\na very simple continual, or lifelong learning\nalgorithm that",
    "start": "2784110",
    "end": "2791960"
  },
  {
    "text": "applies some of these concepts\nto reinforcement learning. And the paper is called\n\"Never Stop Learning.\"",
    "start": "2791960",
    "end": "2798780"
  },
  {
    "text": "It's by Ryan Julian, et. al. And it takes a look at the\ndata that was collected in",
    "start": "2798780",
    "end": "2805150"
  },
  {
    "text": "[INAUDIBLE]. So if you remember, we\nhad these seven robots that collected 580,000 grasps.",
    "start": "2805150",
    "end": "2811660"
  },
  {
    "text": "And then, we could\nevaluate how well it does on a particular scene. And here we pick\nthe specific scene",
    "start": "2811660",
    "end": "2817540"
  },
  {
    "text": "where you see those\nkind of objects. And for those objects that\nthis algorithm worked with,",
    "start": "2817540",
    "end": "2823570"
  },
  {
    "text": "580,000 grasps,\nwhich is 86% success. ",
    "start": "2823570",
    "end": "2829400"
  },
  {
    "text": "So now, we try to\nsee if there are any other settings where this\nalgorithm doesn't work that well.",
    "start": "2829400",
    "end": "2835230"
  },
  {
    "text": "So in this case, we looked\nat transparent bottles, and it turns out that the\npreferred bottles it actually",
    "start": "2835230",
    "end": "2840890"
  },
  {
    "text": "can't really solve\nthem that well. So it's only about 49% accuracy. That hasn't been exposed to\nmany transparent objects.",
    "start": "2840890",
    "end": "2848110"
  },
  {
    "text": "So it doesn't really\nknow how to handle them. So now what we want\nto do is some kind",
    "start": "2848110",
    "end": "2853670"
  },
  {
    "text": "of continual RL algorithm, some\nkind of adaptation procedure that would allow us to improve\nperformance on those bottles",
    "start": "2853670",
    "end": "2862089"
  },
  {
    "text": "from this new task that\nwas presented for us. So the kind of high-level\ndiagram of this",
    "start": "2862090",
    "end": "2867510"
  },
  {
    "text": "will look like this. We have the old data that we\nhad from the pre-training tasks, so this 580,000 grasps.",
    "start": "2867510",
    "end": "2874109"
  },
  {
    "text": "Then we have our\nfine tuning tasks. And in this case, these are\nthese transparent bottles. And then we have to think of\nsome kind of adaptation recipe",
    "start": "2874110",
    "end": "2882570"
  },
  {
    "text": "that can also use\nour old policy that will get-- that\nwill achieve better results on this new data.",
    "start": "2882570",
    "end": "2889859"
  },
  {
    "text": " So this is the fine tuning or\nthe very simple continual RL",
    "start": "2889860",
    "end": "2898520"
  },
  {
    "text": "algorithm that we came up with. It's very, very simple. So this is how it works.",
    "start": "2898520",
    "end": "2904050"
  },
  {
    "text": "So we start with the\npre-training data set that in this case, actually,\nwe made it a little bit bigger.",
    "start": "2904050",
    "end": "2909140"
  },
  {
    "text": "It's 608,000 grasps. And using that data set,\nwe achieved 86% success",
    "start": "2909140",
    "end": "2916580"
  },
  {
    "text": "in this original scene. Now we take that base data, and\nwe train the basic Q-function.",
    "start": "2916580",
    "end": "2924609"
  },
  {
    "text": "So we just apply standard\nQT-Opt, and that's it. Now, we'll do two things.",
    "start": "2924610",
    "end": "2931000"
  },
  {
    "text": "We'll first copy the weights\nfrom this original Q-function that we just\nlearned with QT-Opt. When we start, this will be\nour pre-training mechanism.",
    "start": "2931000",
    "end": "2940282"
  },
  {
    "text": "And then in addition\nto this, we'll be taking the target\ndata, and we'll be collecting very little\nof it on the 800 grasps,",
    "start": "2940282",
    "end": "2946119"
  },
  {
    "text": "or sometimes even\nless than that. And then we'll be\nmixing the data together with the old data in\nproportions 50/50.",
    "start": "2946120",
    "end": "2954070"
  },
  {
    "text": "So we'll be getting\nthis new mixture of data, this new batch that\nhas a little bit of data from our target data\nbut also some base data",
    "start": "2954070",
    "end": "2960700"
  },
  {
    "text": "so that we don't\nforget how to do it. And then we'll train. We'll fine tune our\nQT-Opt based on that data.",
    "start": "2960700",
    "end": "2967720"
  },
  {
    "text": "And so it's very little data,\nbut turns out we can do this. And then we'll have the\nadaptive Q-function that",
    "start": "2967720",
    "end": "2973630"
  },
  {
    "text": "now was fine-tuned\non this new data set, and it actually turns out\nto achieve very high success",
    "start": "2973630",
    "end": "2978780"
  },
  {
    "text": "on the new task.  Great.",
    "start": "2978780",
    "end": "2984225"
  },
  {
    "text": "So here are a few\nevaluation scenarios that we have to consider. So again, we have the pre-train\nsetting where we achieved 86%",
    "start": "2984225",
    "end": "2993530"
  },
  {
    "text": "success. And then we came up with a\nfew different scenarios for-- and this original policy\ndidn't work very well.",
    "start": "2993530",
    "end": "3000860"
  },
  {
    "text": "So we have harsh lighting. We have transparent bottles. We have checkerboard\nbacking that you can see that's been here\nthat makes it actually quite",
    "start": "3000860",
    "end": "3007780"
  },
  {
    "text": "a bit tricky for the policy. We also modified\nthe gripper, so it's a little bit extended here.",
    "start": "3007780",
    "end": "3012910"
  },
  {
    "text": "And we also offset\nit by 10 centimeters. It actually looks really funny\nlike a Frankenstein robot",
    "start": "3012910",
    "end": "3019300"
  },
  {
    "text": "where the gripper's floating\na little bit next to it. And here you see the\nperformance that you",
    "start": "3019300",
    "end": "3025150"
  },
  {
    "text": "get from all of\nthese modifications for the standard\nQT-Opt procedure.",
    "start": "3025150",
    "end": "3030220"
  },
  {
    "text": "So now we'll apply\nour fine-tuning. And we see that\nwe can increase-- by just using less than\n800 grasps we can increase",
    "start": "3030220",
    "end": "3036580"
  },
  {
    "text": "the performance with harsh\nlighting from 32% to 63%, and transparent bottles to 66%,\ncheckerboard backing to 19%,",
    "start": "3036580",
    "end": "3044110"
  },
  {
    "text": "extending gripper to 93% and\noffsetting the gripper to 98%. So we can see\nsignificant improvement",
    "start": "3044110",
    "end": "3050530"
  },
  {
    "text": "of very small amount\nof data but just doing simple fine-tuning\nof Q-function.",
    "start": "3050530",
    "end": "3055600"
  },
  {
    "text": " All right. Since this is a\ncontinual RL lecture,",
    "start": "3055600",
    "end": "3062099"
  },
  {
    "text": "we can also apply it to a\nlifelong learning setting. So instead of just\nfine-tuning it once, we can fine-tune it many times.",
    "start": "3062100",
    "end": "3070980"
  },
  {
    "text": "So what we can do\nhere is we can start with our original\ngrasping data set.",
    "start": "3070980",
    "end": "3076850"
  },
  {
    "text": "We learn our Q-function,\nand we mix it with the new data that\nwe see in the environment that we want to fine-tune to.",
    "start": "3076850",
    "end": "3083300"
  },
  {
    "text": "And then we can take\nthat Q-function we just trained here, that\nincrease the performance,",
    "start": "3083300",
    "end": "3088430"
  },
  {
    "text": "and then use that Q-function\nto initialize and take the original data, mix\nit with the new scenario",
    "start": "3088430",
    "end": "3095337"
  },
  {
    "text": "that we have in mind,\nand kind of keep doing this over and over. Now it turns out that we\nachieved a fairly high result",
    "start": "3095337",
    "end": "3102360"
  },
  {
    "text": "for this as well. So the performance\nkeeps growing. So for the original harsh\nlighting we have 32%.",
    "start": "3102360",
    "end": "3109740"
  },
  {
    "text": "That increases to 63%. And then even though we copy\nthis Q-function as opposed to the original Q-function\nthat we had before,",
    "start": "3109740",
    "end": "3117273"
  },
  {
    "text": "it turns out that this\nfunction is good enough to then be fine-tuned to\nthese transparent bottles",
    "start": "3117273",
    "end": "3122490"
  },
  {
    "text": "and achieve high\nimprovement as well. And this kind of\nprocedure can repeat. ",
    "start": "3122490",
    "end": "3130070"
  },
  {
    "text": "One question you might have is\nwhat about negative transfer. So have we ever tried\ntaking that Q-function,",
    "start": "3130070",
    "end": "3135600"
  },
  {
    "text": "for instance, and evaluating\nit in this scenario? And we haven't tried it.",
    "start": "3135600",
    "end": "3142110"
  },
  {
    "text": "I would assume that it would\nactually go down significantly. We might be able to\noffset this by mixing",
    "start": "3142110",
    "end": "3149579"
  },
  {
    "text": "some data from the previous\nexperiences as well and figuring out\nkind of the right way to do this to balance the data.",
    "start": "3149580",
    "end": "3157947"
  },
  {
    "text": "But we haven't evaluated\nthis in this paper. And this is one of the examples\nof different lifelong learning",
    "start": "3157947",
    "end": "3164093"
  },
  {
    "text": "papers care about\ndifferent things and evaluating different things. ",
    "start": "3164093",
    "end": "3169350"
  },
  {
    "text": "So this is a very\nsimple algorithm. So one question you\nmight have is, well can we do-- can we do\nbetter than this?",
    "start": "3169350",
    "end": "3176440"
  },
  {
    "text": "And this is-- I'm sorry, can I ask you a\nquestion about the last slide? Yeah.",
    "start": "3176440",
    "end": "3182069"
  },
  {
    "text": "I don't-- I don't\nreally understand. It's not my expectation\nthat you would see the improvement as\nyou step to the right,",
    "start": "3182070",
    "end": "3191160"
  },
  {
    "text": "if that makes sense. So are you somehow leveraging--\nin the offset gripper,",
    "start": "3191160",
    "end": "3196410"
  },
  {
    "text": "are you somehow leveraging\nsome improvements that you've made\njust by diversifying your data set through\ncheckerboard backing",
    "start": "3196410",
    "end": "3203070"
  },
  {
    "text": "and extended gripper? And if, for example, you\njust initialized-- or is",
    "start": "3203070",
    "end": "3208920"
  },
  {
    "text": "it did you just put\nthem in that order. And it initialized\nthe offset gripper with the original purple\nmodel that you have here--",
    "start": "3208920",
    "end": "3218070"
  },
  {
    "text": "if you mix the order around,\ndo you see that same pattern? That's a great question.",
    "start": "3218070",
    "end": "3223210"
  },
  {
    "text": "So you're referring to the\nfact that these numbers here at the bottom keep\ngetting higher, as",
    "start": "3223210",
    "end": "3229130"
  },
  {
    "text": "opposed to these numbers-- the improvement\nfrom here to here, it seems like these\nare improving as well.",
    "start": "3229130",
    "end": "3235610"
  },
  {
    "text": "Yeah, I think this is not\nsomething that we intended. Probably, if you mix the order,\nthe order of these numbers",
    "start": "3235610",
    "end": "3241790"
  },
  {
    "text": "will also change. So there isn't really\nanything I think, other",
    "start": "3241790",
    "end": "3247190"
  },
  {
    "text": "than a slightly differently\npre-trained Q-function that you're getting at each step\nthat would guarantee something",
    "start": "3247190",
    "end": "3254240"
  },
  {
    "text": "like this kind of trend\nwhere the Q-function gets better and better. If you look at the\nway we kind of--",
    "start": "3254240",
    "end": "3260809"
  },
  {
    "text": "the order in which we did\nthis-- we did these scenarios, this is actually very\nsimilar to the order",
    "start": "3260810",
    "end": "3266690"
  },
  {
    "text": "that you've seen in\nthe previous slide as to how good of a performance\nthey achieve at the end.",
    "start": "3266690",
    "end": "3272853"
  },
  {
    "text": "So we just ended up\nkind of sorting them based on performance and then\ndoing the continual experiment this way. But it will probably\nlook very different",
    "start": "3272853",
    "end": "3279350"
  },
  {
    "text": "if you do it the different way. All right. ",
    "start": "3279350",
    "end": "3286069"
  },
  {
    "text": "Are there any other questions? ",
    "start": "3286070",
    "end": "3294119"
  },
  {
    "text": "Cool. We don't have that much time. Can we do better\nthan the basics? And the case study\nthat we'll have,",
    "start": "3294120",
    "end": "3301540"
  },
  {
    "text": "so we'll look at negative\ntransfer, negative backward transfer-- this is something\nthat we haven't really",
    "start": "3301540",
    "end": "3308410"
  },
  {
    "text": "evaluated in any previous\nwork, but this is something that the authors cared\nabout in this work.",
    "start": "3308410",
    "end": "3314440"
  },
  {
    "text": "And we'll see whether we can\nmodify the vanilla stochastic gradient descent to avoid\nnegative backward transfer.",
    "start": "3314440",
    "end": "3321960"
  },
  {
    "text": "So this is the paper from\nLopez-Paz and Ranzato called Gradient Episodic\nMemory for Continual Learning.",
    "start": "3321960",
    "end": "3327910"
  },
  {
    "text": "And the idea is the following. We'll store a small amount\nof data per task in memory.",
    "start": "3327910",
    "end": "3334900"
  },
  {
    "text": "And then when making\nupdates for the new task, we'll ensure that they don't\nunlearn previous tasks.",
    "start": "3334900",
    "end": "3341860"
  },
  {
    "text": "So this is-- I think that will\nall make sense. The question is, how\ndo we actually do this. How do do that?",
    "start": "3341860",
    "end": "3348289"
  },
  {
    "text": "So how can we\naccomplish the number 2? So first, we'll be learning\nthis predictor that",
    "start": "3348290",
    "end": "3354980"
  },
  {
    "text": "takes as input the\ncurrent datapoint as well as the task\nthat it's currently--",
    "start": "3354980",
    "end": "3363300"
  },
  {
    "text": "this datapoint comes from. And then we're trying to find\nthese parameters theta that will give us our prediction, yt.",
    "start": "3363300",
    "end": "3372150"
  },
  {
    "text": "Now in addition to\nthis, we'll also keep a memory for other tasks\nthat we've seen in the past.",
    "start": "3372150",
    "end": "3378190"
  },
  {
    "text": "So for any k task,\nwe'll also keep the memory that has a little\nbit of data from the task.",
    "start": "3378190",
    "end": "3384700"
  },
  {
    "text": "So now for the different\ntasks, or for every datapoint, we'll minimize the\nloss, as we usually",
    "start": "3384700",
    "end": "3390450"
  },
  {
    "text": "do with the new datapoint. But then in addition\nto this, we'll have this constraint that\nsays that the loss of our new",
    "start": "3390450",
    "end": "3401040"
  },
  {
    "text": "of our new function\nwith our memory data should be less than\nor equal to the loss",
    "start": "3401040",
    "end": "3408599"
  },
  {
    "text": "that we had previously\nin the previous iteration on the previous data.",
    "start": "3408600",
    "end": "3413640"
  },
  {
    "text": "And this is for the memory that\nwas collected for all the tasks that we've seen before.",
    "start": "3413640",
    "end": "3419619"
  },
  {
    "text": "So we have this memory of\ntasks that we've seen so far, and we'll be evaluating\nthe loss on that memory",
    "start": "3419620",
    "end": "3425910"
  },
  {
    "text": "of our current parameter as we-- with our current neural net.",
    "start": "3425910",
    "end": "3432750"
  },
  {
    "text": "And we'll compare\nthis to the loss that we had in the\nprevious iteration.",
    "start": "3432750",
    "end": "3438313"
  },
  {
    "text": "So you basically\ndon't want to get any worse on the previous\ntasks that we've seen. ",
    "start": "3438313",
    "end": "3445079"
  },
  {
    "text": "So in that case, basically\nloss on the previous task shouldn't get worse.",
    "start": "3445080",
    "end": "3452490"
  },
  {
    "text": "In addition, what the actors\ndo, they assume local linearity. And then they can actually\ncompute this inner product",
    "start": "3452490",
    "end": "3458910"
  },
  {
    "text": "between the gradients\non the current task as well as in the previous task.",
    "start": "3458910",
    "end": "3464880"
  },
  {
    "text": "And if that inner product\nis greater than 0, then we should be good.",
    "start": "3464880",
    "end": "3471522"
  },
  {
    "text": "And then they formulate\nthat, and so that is a quadratic problem.",
    "start": "3471522",
    "end": "3476530"
  },
  {
    "text": "So then they do a series of\nexperiments to evaluate this. So the problems\nthat they consider",
    "start": "3476530",
    "end": "3482980"
  },
  {
    "text": "are MNIST permutations, where\nyou see different permutations of MNIST, and you consider\nit as a MNIST digit,",
    "start": "3482980",
    "end": "3489280"
  },
  {
    "text": "and you consider this\nas a different task. You can also rotate the\nMNIST, and the MNIST",
    "start": "3489280",
    "end": "3494480"
  },
  {
    "text": "digit and considered that\nas a different datapoint. And they also evaluated\non CIFAR-100 where you",
    "start": "3494480",
    "end": "3501590"
  },
  {
    "text": "have five new classes per task. So every task is considered. A new task is\nconsidered every time",
    "start": "3501590",
    "end": "3507410"
  },
  {
    "text": "when you get five new classes. And then they look at\nbackward transfer, as well as the forward transfer comparing\nto a few different baselines.",
    "start": "3507410",
    "end": "3516809"
  },
  {
    "text": "And the total memory size that\nthey have is 5012 examples.",
    "start": "3516810",
    "end": "3523957"
  },
  {
    "text": "So here are some of the results. So their method is-- ",
    "start": "3523957",
    "end": "3531400"
  },
  {
    "text": "their method is here called GM. And first, you can see\nthe overall accuracy,",
    "start": "3531400",
    "end": "3538030"
  },
  {
    "text": "the classification\naccuracy is quite high compared to the baselines. And then if you look at\nthe backward transfer,",
    "start": "3538030",
    "end": "3544480"
  },
  {
    "text": "it doesn't really-- for their method of\nthis, you don't really see any negative transfer. If anything, you\nsee a little bit of a positive transfer, which\nis not the case for some",
    "start": "3544480",
    "end": "3551680"
  },
  {
    "text": "of the baselines. And you see a little bit of\nthe forward transfer as well.",
    "start": "3551680",
    "end": "3557069"
  },
  {
    "text": "And then here on the\nright in this plot, you kind of see the effect of\ncatastrophic forgetting, what's happening if you don't apply\nthis additional constraint",
    "start": "3557070",
    "end": "3565130"
  },
  {
    "text": "that they introduce. So here what you see in\nthis plot is on the y-axis is the accuracy of\ntask number one.",
    "start": "3565130",
    "end": "3571880"
  },
  {
    "text": "So you can see that\nall of the methods achieve actually fairly high\naccuracy at the very beginning when you train on that task.",
    "start": "3571880",
    "end": "3578060"
  },
  {
    "text": "And then on the x-axis,\nhere you see how many tasks you've seen so far. So you kind of see\nmore and more tasks.",
    "start": "3578060",
    "end": "3584523"
  },
  {
    "text": "And then you see\nwhether the performance of the original task\ngoes down as you see more data and more tasks.",
    "start": "3584523",
    "end": "3590700"
  },
  {
    "text": "And you can see that for most of\nthe baselines that is the case. The performance goes down. Versus for their case,\nbecause they have the solution",
    "start": "3590700",
    "end": "3598378"
  },
  {
    "text": "constraint that kind of makes\nsure that you don't really go-- that the gradients you\napply don't really forget",
    "start": "3598378",
    "end": "3603829"
  },
  {
    "text": "the original task you had-- just the performance\nstays constant. ",
    "start": "3603830",
    "end": "3611710"
  },
  {
    "text": "Also, we can see similar\nstory for MNIST rotations. And you can also see\nsimilar story for CIFAR-100",
    "start": "3611710",
    "end": "3618290"
  },
  {
    "text": "where you see that a lot\nof the baseline approaches actually experience some kind\nof negative backward transfer.",
    "start": "3618290",
    "end": "3627560"
  },
  {
    "text": "And you can also see it here\nwhere the performance actually drops quite\nsignificantly compared",
    "start": "3627560",
    "end": "3634000"
  },
  {
    "text": "to the method they introduce.  So one thing to consider when\nlooking at figures like this",
    "start": "3634000",
    "end": "3641280"
  },
  {
    "text": "is kind of verify-- to verify the\nassumptions and to see whether the settings that\nthe authors were considering",
    "start": "3641280",
    "end": "3649200"
  },
  {
    "text": "is actually well reflected\nin the experiments. So in this case, if we take a-- if we take a step back and take\na look whether it makes sense",
    "start": "3649200",
    "end": "3661080"
  },
  {
    "text": "to have a little bit of-- to have a little bit of\nmemory per task and so on.",
    "start": "3661080",
    "end": "3667690"
  },
  {
    "text": "Does that make sense in\nthe case of MNIST digits? Probably with MNIST digits you\ncould store all of the data set",
    "start": "3667690",
    "end": "3674430"
  },
  {
    "text": "and all of the data that\nyou see in its entirety. You don't necessarily\nneed to have a little bit of memory that is\nsomewhat constrained with size.",
    "start": "3674430",
    "end": "3682030"
  },
  {
    "text": "It's very easy these\ndays to keep all of this,",
    "start": "3682030",
    "end": "3688290"
  },
  {
    "text": "to have access to\nthe entire data set. So it's often quite\ntricky to kind of come up with the right\nexperimental setting that",
    "start": "3688290",
    "end": "3695310"
  },
  {
    "text": "then addresses the-- or has the same assumptions that\nyou had at the very beginning when developing this method.",
    "start": "3695310",
    "end": "3701097"
  },
  {
    "text": "So that's something to\nkeep in mind as well. ",
    "start": "3701097",
    "end": "3706617"
  },
  {
    "text": "You can also ask a\nquestion whether we can meta-learn how to avoid\nnegative backward transfer. And there are some\npapers on this.",
    "start": "3706617",
    "end": "3712670"
  },
  {
    "text": "Here are the two that\nI would refer you to. We don't have much\ntime to discuss them. But there are some interesting\nsolutions there as well.",
    "start": "3712670",
    "end": "3719630"
  },
  {
    "text": " OK. And in the last 8\nminutes, we'll talk",
    "start": "3719630",
    "end": "3726400"
  },
  {
    "text": "about how we can revisit\nthe problems taken from the meta-learning\nperspective.",
    "start": "3726400",
    "end": "3732920"
  },
  {
    "text": "So if we look at this\nonline learning formulation that we had before,\nthere might be something that is a little bit wrong.",
    "start": "3732920",
    "end": "3738250"
  },
  {
    "text": "And I was trying to hint at\nit during our breakout rooms.",
    "start": "3738250",
    "end": "3744160"
  },
  {
    "text": "So with the online\nlearning setting, we have to perform\na sequence of tasks while minimizing\nthe static regret.",
    "start": "3744160",
    "end": "3750700"
  },
  {
    "text": "So what that means is that\nwe measure the performance as soon as we're presented with\na new task or a new datapoint.",
    "start": "3750700",
    "end": "3756880"
  },
  {
    "text": "So basically, you\nhave to perform-- ",
    "start": "3756880",
    "end": "3762630"
  },
  {
    "text": "you have to perform\na task straight away, and then after you\nfinish the task, you get to see the new\ntask, and your performance",
    "start": "3762630",
    "end": "3769500"
  },
  {
    "text": "is measured immediately. As soon as the task\nis presented to you, you will be measured how\nwell you can do on that task.",
    "start": "3769500",
    "end": "3777830"
  },
  {
    "text": "So it's measuring the\nzero-shot performance. But more realistically,\nwhat we might want to have",
    "start": "3777830",
    "end": "3784260"
  },
  {
    "text": "is a setting where we get\nto learn a little bit. We have a little bit of time, a\nlittle bit of a learning period",
    "start": "3784260",
    "end": "3790440"
  },
  {
    "text": "where you get to kind\nof see what the task is. You can adapt to it. And we want to measure\nhow fast you can adapt",
    "start": "3790440",
    "end": "3795839"
  },
  {
    "text": "and how well you can\nadapt in the task, instead of just performing\nstraight away or trying",
    "start": "3795840",
    "end": "3800880"
  },
  {
    "text": "to learn new tasks as we see it.  So in that case, we want to\nsee that-- we start with very",
    "start": "3800880",
    "end": "3808720"
  },
  {
    "text": "slow learning initially. It takes us a long time to\nlearn this initial task. But then this evolves to very\nrapid learning over time.",
    "start": "3808720",
    "end": "3817970"
  },
  {
    "text": "So over time, we want\nto be able to acquire new tasks much faster than\nwe did at the very beginning.",
    "start": "3817970",
    "end": "3826450"
  },
  {
    "text": "And this setting\nwe'll be referring to as online meta-learning\nsetting where we efficiently want to learn a\nsequence of tasks",
    "start": "3826450",
    "end": "3832600"
  },
  {
    "text": "from a non-stationary\ndistribution. And this is discussed in this\npaper by Chelsea Finn actually,",
    "start": "3832600",
    "end": "3839500"
  },
  {
    "text": "and Aravind Rajeswaran. All right. ",
    "start": "3839500",
    "end": "3846250"
  },
  {
    "text": "So it's important to note that\nthe primary difference here",
    "start": "3846250",
    "end": "3851410"
  },
  {
    "text": "is in evaluation, rather than\nin the data stream itself. So you will still get to\nobserve the exact same data,",
    "start": "3851410",
    "end": "3856900"
  },
  {
    "text": "the exact same task and so on. But you'll be evaluated\nonly after you have a little bit of time to adapt.",
    "start": "3856900",
    "end": "3862870"
  },
  {
    "text": " So for this online\nmeta-learning setting,",
    "start": "3862870",
    "end": "3868890"
  },
  {
    "text": "this is what we will\ndo for every task. We'll observe a little bit of\na training data set, D tr t sub",
    "start": "3868890",
    "end": "3876859"
  },
  {
    "text": "t. And then we can use some\nkind of update procedure to update our parameters to\nproduce the new parameters that",
    "start": "3876860",
    "end": "3885190"
  },
  {
    "text": "take into account this\nlow data set that we just observed to produce the\nnew parameters phi t.",
    "start": "3885190",
    "end": "3892230"
  },
  {
    "text": "And then we get to\nobserve the datapoint, and then we predict based\non these updated parameters.",
    "start": "3892230",
    "end": "3898710"
  },
  {
    "text": "And that we get to\nobserve the label. Now you can see that this\nlast part of this problem is the exact same as the\nstandard online learning",
    "start": "3898710",
    "end": "3906120"
  },
  {
    "text": "setting. It's just the first part\nis a little bit different where we get to\nobserve this small data set that allows you to find\na better update procedure.",
    "start": "3906120",
    "end": "3914745"
  },
  {
    "text": " And then the goal is similar\nto what we had before.",
    "start": "3914745",
    "end": "3920250"
  },
  {
    "text": "Except now, we have\nthis function right here that we are also trying\nto find the best update",
    "start": "3920250",
    "end": "3931850"
  },
  {
    "text": "procedure for this. But we can still find\nthe learning algorithms with sub-linear regret.",
    "start": "3931850",
    "end": "3937810"
  },
  {
    "text": " So this is the loss\nof the algorithm.",
    "start": "3937810",
    "end": "3942920"
  },
  {
    "text": "And this is the loss of the\nbest algorithm in hindsight. So the question is, can\nwe apply meta-learning",
    "start": "3942920",
    "end": "3949280"
  },
  {
    "text": "in this lifelong\nlearning setting. And if you recall the\nfollow the leader algorithm,",
    "start": "3949280",
    "end": "3954330"
  },
  {
    "text": "we would store all the\ndata we've seen so far and train on it. So we can add a\nsmall modification. We can add a small\nmodification to this algorithm",
    "start": "3954330",
    "end": "3962240"
  },
  {
    "text": "so that we can include\nmeta-learning in it, as well. So what we'll do\ninstead, we'll call",
    "start": "3962240",
    "end": "3968450"
  },
  {
    "text": "it a follow the meta-leader\nalgorithm, FTML. And then we'll store all\nthe data we've seen so far.",
    "start": "3968450",
    "end": "3974840"
  },
  {
    "text": "But then we'll\nmeta-train on it, rather than just training on it. And then we'll run the update\nprocedure on the current task.",
    "start": "3974840",
    "end": "3981420"
  },
  {
    "text": "All right.  So one question you might\nask is we can do this,",
    "start": "3981420",
    "end": "3988510"
  },
  {
    "text": "but what kind of meta\nalgorithms should we use? You learn about different kinds\nof meta-learning algorithms,",
    "start": "3988510",
    "end": "3994750"
  },
  {
    "text": "black-box algorithms,\noptimization-based algorithms, and so on. So assuming that our\ndistribution of tasks",
    "start": "3994750",
    "end": "4001619"
  },
  {
    "text": "is non-stationary, and we\nmight need to extrapolate.",
    "start": "4001620",
    "end": "4006840"
  },
  {
    "text": "If you recall, one\nof the previous lectures by Chelsea\non different types",
    "start": "4006840",
    "end": "4013380"
  },
  {
    "text": "of meta-learning\nalgorithms, it turns out that optimization-based\nalgorithms such as MAML",
    "start": "4013380",
    "end": "4018569"
  },
  {
    "text": "can generalize a little bit\nbetter outside of the training distribution as opposed\nto black-box adaptation",
    "start": "4018570",
    "end": "4024750"
  },
  {
    "text": "algorithms. So we'll use MAML,\nand we'll try to see whether we can\nimplement this follow",
    "start": "4024750",
    "end": "4030660"
  },
  {
    "text": "the meta-leader\nalgorithm easily. So the experiments\nare as follows.",
    "start": "4030660",
    "end": "4037510"
  },
  {
    "text": "We'll have the colored, rotated,\nand scaled MNIST digits. We'll also have a 3D\npose prediction problem,",
    "start": "4037510",
    "end": "4043650"
  },
  {
    "text": "where you get to see this image\nthat you see here on the right.",
    "start": "4043650",
    "end": "4048750"
  },
  {
    "text": "And you have to be\nable to tell what's the pose of the object in\nthat image with respect to this red dot that you see.",
    "start": "4048750",
    "end": "4057190"
  },
  {
    "text": "And then we'll also have\nthe CIFAR-100 specification where a new task is considered\nevery time you see a new class.",
    "start": "4057190",
    "end": "4064520"
  },
  {
    "text": "So the comparisons\nwe'll have is you can train on everything,\nso train on all the data that you've seen so far.",
    "start": "4064520",
    "end": "4070505"
  },
  {
    "text": "We'll also compare to\nfollow the leader where we train on all the data-- all the data that you've seen\nso far, and then we'll fine-tune",
    "start": "4070505",
    "end": "4077270"
  },
  {
    "text": "based on the current task. You can also do\neverything from scratch.",
    "start": "4077270",
    "end": "4082420"
  },
  {
    "text": "So every time you see a new\ntask, you train from scratch. And then we'll also\ncompare to our algorithm,",
    "start": "4082420",
    "end": "4091900"
  },
  {
    "text": "follow the meta-leader. So first, we can look at\nthe learning efficiency. So in that case, I think\nthat shows how much data",
    "start": "4091900",
    "end": "4100750"
  },
  {
    "text": "it takes to achieve a\ncertain performance. So in this case,\nyou can see that--",
    "start": "4100750",
    "end": "4106049"
  },
  {
    "text": "so on the y-axis it shows\nhow much data there was. And to achieve a\ncertain performance--",
    "start": "4106050",
    "end": "4112549"
  },
  {
    "text": "I forget exactly what\nthe performance was, but it was the same threshold\nfor all of the baselines. And then on the x-axis, you\ncan see how many tasks you see.",
    "start": "4112550",
    "end": "4120439"
  },
  {
    "text": "So initially, you\nstart with tasks-- you've seen 20 tasks. And you see task number 21,\n22, 23, 24, 25 and so on.",
    "start": "4120439",
    "end": "4129670"
  },
  {
    "text": "So now you can see that\nFTML algorithm, follow the meta-leader, is able to\nget more efficient over time,",
    "start": "4129670",
    "end": "4138909"
  },
  {
    "text": "eventually basically, going to\nthe regime where it can just learn a new task with just a\nfew shots in the future learning",
    "start": "4138910",
    "end": "4147000"
  },
  {
    "text": "regime where it can just see\na few examples of a new task, and it's going to acquire\nthis task very easily.",
    "start": "4147000",
    "end": "4152259"
  },
  {
    "text": "And you can see the\nsame for rainbow MNIST as well as for pose prediction.",
    "start": "4152260",
    "end": "4157722"
  },
  {
    "text": "In addition, you can also look\nat the learning proficiency, so the error that you see. Here on the y-axis,\nyou have the error.",
    "start": "4157722",
    "end": "4164489"
  },
  {
    "text": "But on the x-axis, you\nstill have the task number. And you can see that also\nit's getting better and better",
    "start": "4164490",
    "end": "4170310"
  },
  {
    "text": "and sees more tasks. So with meta-learns algorithm,\nit gets better and better and gets--",
    "start": "4170310",
    "end": "4176399"
  },
  {
    "text": "it can train on\nthese tasks faster and achieve higher proficiency. So follow the meta-leader can\nlearn each new task faster",
    "start": "4176399",
    "end": "4184909"
  },
  {
    "text": "and with greater proficiency. And to the point where it starts\nto approach few-shot learning regime. All right.",
    "start": "4184910",
    "end": "4190308"
  },
  {
    "text": " So a few takeaways.",
    "start": "4190308",
    "end": "4195619"
  },
  {
    "text": "We learn about many flavors\nof lifelong learning. And they're all\nunder the same name.",
    "start": "4195620",
    "end": "4200900"
  },
  {
    "text": "We run through the\nexercise showing how you can come up with\nslightly different problem",
    "start": "4200900",
    "end": "4206239"
  },
  {
    "text": "formulations, how\nwe can evaluate these algorithms differently. And that's actually what you\nsee in the literature as well.",
    "start": "4206240",
    "end": "4211500"
  },
  {
    "text": "And even though this is a\nvery diverse set of works",
    "start": "4211500",
    "end": "4216860"
  },
  {
    "text": "and sometimes they're\nnot very comparable, they could still appear under\nthe name of lifelong learning.",
    "start": "4216860",
    "end": "4223380"
  },
  {
    "text": "And probably defining the\nproblem statement itself is often the hardest\npart when we're",
    "start": "4223380",
    "end": "4228480"
  },
  {
    "text": "working on these algorithms. You can also view\nmeta-learning as a slice",
    "start": "4228480",
    "end": "4234255"
  },
  {
    "text": "of the lifelong\nlearning problem. And you can apply it to lifelong\nlearning problems as well.",
    "start": "4234255",
    "end": "4240100"
  },
  {
    "text": "And lastly, it's a very\nopen area of research. So a lot of the things that we\ndiscussed today are very recent",
    "start": "4240100",
    "end": "4246270"
  },
  {
    "text": "works. And there's a lot\nof people working on these kind of problems\nand reformulating them in different ways and trying\nto apply some of the techniques",
    "start": "4246270",
    "end": "4253710"
  },
  {
    "text": "from other fields to see\nhow we can apply those. But as of now, we don't really\nhave many lifelong learning",
    "start": "4253710",
    "end": "4259770"
  },
  {
    "text": "systems out there that\nare well understood and perform very well. ",
    "start": "4259770",
    "end": "4266900"
  },
  {
    "text": "With that, these are the\nreminders that we have. Remember that on Wednesday,\nwe'll also meet over Zoom.",
    "start": "4266900",
    "end": "4272310"
  },
  {
    "text": "We'll have additional-- we'll\nhave some researchers talking about their recent work,\nabout from frontiers",
    "start": "4272310",
    "end": "4278790"
  },
  {
    "text": "in multitask and meta-learning. So it should be\nvery interesting. I encourage you to come\nand ask some questions.",
    "start": "4278790",
    "end": "4286250"
  },
  {
    "start": "4286250",
    "end": "4290000"
  }
]
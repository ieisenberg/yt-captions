[
  {
    "text": "OK.",
    "start": "0",
    "end": "860"
  },
  {
    "text": "Well, welcome back.",
    "start": "860",
    "end": "2125"
  },
  {
    "text": "The second method\nof this section",
    "start": "2125",
    "end": "3500"
  },
  {
    "text": "is clustering, which refers\nto a broad set of techniques",
    "start": "3500",
    "end": "7610"
  },
  {
    "text": "for finding subgroups\nor clusters in data.",
    "start": "7610",
    "end": "10310"
  },
  {
    "text": "So we're trying to\nsegment or partition",
    "start": "10310",
    "end": "12530"
  },
  {
    "text": "the data into subgroups that\nare similar to each other.",
    "start": "12530",
    "end": "16039"
  },
  {
    "text": "And, of course,\nwe'll have to define",
    "start": "16040",
    "end": "18140"
  },
  {
    "text": "what we mean by\nsimilar or different to",
    "start": "18140",
    "end": "19849"
  },
  {
    "text": "in order to do the partitioning.",
    "start": "19850",
    "end": "21690"
  },
  {
    "text": "And, in a lot of cases, the\nway we decide to cluster,",
    "start": "21690",
    "end": "25730"
  },
  {
    "text": "the way we decide on\nwhat's similar or different",
    "start": "25730",
    "end": "28010"
  },
  {
    "text": "depends on the context.",
    "start": "28010",
    "end": "30150"
  },
  {
    "text": "So how does a principal\ncomponents analysis,",
    "start": "30150",
    "end": "33390"
  },
  {
    "text": "which you just\ndiscussed, how does it",
    "start": "33390",
    "end": "35190"
  },
  {
    "text": "contrast with clustering?",
    "start": "35190",
    "end": "36600"
  },
  {
    "text": "Well, PCA, as we've\nseen, looks for",
    "start": "36600",
    "end": "38280"
  },
  {
    "text": "a low-dimensional\nrepresentation or view",
    "start": "38280",
    "end": "40163"
  },
  {
    "text": "of the data that explains a\ngood fraction of the variance.",
    "start": "40163",
    "end": "42579"
  },
  {
    "text": "So we saw the PCA\nplots, and from that",
    "start": "42580",
    "end": "46500"
  },
  {
    "text": "we derive new\nvariables, which could",
    "start": "46500",
    "end": "48000"
  },
  {
    "text": "be used for other methods\nlike supervised learning.",
    "start": "48000",
    "end": "51300"
  },
  {
    "text": "Clustering, on the other hand,\nlooks for homogeneous subgroups",
    "start": "51300",
    "end": "54210"
  },
  {
    "text": "of the observations.",
    "start": "54210",
    "end": "56680"
  },
  {
    "text": "So it's not looking for variance\nbut is looking for similarity",
    "start": "56680",
    "end": "59770"
  },
  {
    "text": "among observations.",
    "start": "59770",
    "end": "62620"
  },
  {
    "text": "For example, if we're trying to\ndo a segmentation of a market,",
    "start": "62620",
    "end": "65740"
  },
  {
    "text": "suppose for each of a number\nof customers we measure things",
    "start": "65740",
    "end": "71009"
  },
  {
    "text": "like their income, their\noccupation, how far they live",
    "start": "71010",
    "end": "74280"
  },
  {
    "text": "to the closest urban\narea and so forth,",
    "start": "74280",
    "end": "76640"
  },
  {
    "text": "and we want to segment\nthem or group them",
    "start": "76640",
    "end": "82050"
  },
  {
    "text": "into customers that are similar\nwith regard to these features.",
    "start": "82050",
    "end": "84950"
  },
  {
    "text": "And why do we want to do that?",
    "start": "84950",
    "end": "86200"
  },
  {
    "text": "Because maybe if they're similar\nwith regard to these features,",
    "start": "86200",
    "end": "88950"
  },
  {
    "text": "then the advertising we use for\nthat subgroup will be important.",
    "start": "88950",
    "end": "93774"
  },
  {
    "text": "So we use a certain\nkind of advertising",
    "start": "93775",
    "end": "95400"
  },
  {
    "text": "for one subgroup like\nmaybe young males who",
    "start": "95400",
    "end": "98130"
  },
  {
    "text": "have a lot of money.",
    "start": "98130",
    "end": "100090"
  },
  {
    "text": "Another subgroup might be--",
    "start": "100090",
    "end": "101280"
  },
  {
    "text": "Like me.",
    "start": "101280",
    "end": "102479"
  },
  {
    "text": "--yeah.",
    "start": "102480",
    "end": "103440"
  },
  {
    "text": "Young male.",
    "start": "103440",
    "end": "104820"
  },
  {
    "text": "OK.",
    "start": "104820",
    "end": "106409"
  },
  {
    "text": "Another group may be housewives\nin their 50s who their children",
    "start": "106410",
    "end": "114810"
  },
  {
    "text": "have grown up, and they\nlike to travel, for example.",
    "start": "114810",
    "end": "117340"
  },
  {
    "text": "So we might want to\nadvertise in a different way",
    "start": "117340",
    "end": "119340"
  },
  {
    "text": "to that subgroup.",
    "start": "119340",
    "end": "120600"
  },
  {
    "text": "So the task of segmenting\nthat kind of population",
    "start": "120600",
    "end": "125650"
  },
  {
    "text": "is a key application\nof clustering.",
    "start": "125650",
    "end": "130268"
  },
  {
    "text": "So I'm going to talk about\ntwo clustering methods",
    "start": "130268",
    "end": "132310"
  },
  {
    "text": "in this section.",
    "start": "132310",
    "end": "132950"
  },
  {
    "text": "There are lots more.",
    "start": "132950",
    "end": "133790"
  },
  {
    "text": "As in most areas of\nstatistics, there's",
    "start": "133790",
    "end": "135819"
  },
  {
    "text": "many, many ways of doing things.",
    "start": "135820",
    "end": "137300"
  },
  {
    "text": "But the two most important\nmethods, which we'll talk about,",
    "start": "137300",
    "end": "139758"
  },
  {
    "text": "are K-means clustering,\nin which we, first of all,",
    "start": "139758",
    "end": "142629"
  },
  {
    "text": "predefine K, the\nnumber of clusters.",
    "start": "142630",
    "end": "144710"
  },
  {
    "text": "And then we'll see there's a\nway of grouping the observations",
    "start": "144710",
    "end": "147640"
  },
  {
    "text": "into the K groups.",
    "start": "147640",
    "end": "148990"
  },
  {
    "text": "Then, of course, we'll\nhave to define what K is,",
    "start": "148990",
    "end": "151330"
  },
  {
    "text": "is this number of subgroups.",
    "start": "151330",
    "end": "152560"
  },
  {
    "text": "And that's going to be\nimportant and difficult choice.",
    "start": "152560",
    "end": "155080"
  },
  {
    "text": "And the second method is\ncalled hierarchical clustering,",
    "start": "155080",
    "end": "157570"
  },
  {
    "text": "which we don't prespecify\nthe number of clusters K.",
    "start": "157570",
    "end": "160120"
  },
  {
    "text": "But rather we do--",
    "start": "160120",
    "end": "163099"
  },
  {
    "text": "we group the data in\nall numbers of clusters.",
    "start": "163100",
    "end": "165260"
  },
  {
    "text": "And It's done in a hierarchical\nagglomerative fashion.",
    "start": "165260",
    "end": "168180"
  },
  {
    "text": "And this is nice because we\nget to see the clustering",
    "start": "168180",
    "end": "171290"
  },
  {
    "text": "for all numbers of clusters K.",
    "start": "171290",
    "end": "176010"
  },
  {
    "text": "But let's start with\nthe simplest method,",
    "start": "176011",
    "end": "177720"
  },
  {
    "text": "K-means clustering.",
    "start": "177720",
    "end": "180000"
  },
  {
    "text": "Before we describe it, let's\nsee an example of the result",
    "start": "180000",
    "end": "183293"
  },
  {
    "text": "of K-means clustering.",
    "start": "183293",
    "end": "184210"
  },
  {
    "text": "So this is some simulated data.",
    "start": "184210",
    "end": "187260"
  },
  {
    "text": "And it's been\nsimulated basically",
    "start": "187260",
    "end": "190129"
  },
  {
    "text": "in two groups, which\nare the upper group,",
    "start": "190130",
    "end": "194595"
  },
  {
    "text": "there's two features.",
    "start": "194595",
    "end": "195470"
  },
  {
    "text": "And there's a group at the\ntop, some space in between,",
    "start": "195470",
    "end": "198500"
  },
  {
    "text": "and a group at the bottom.",
    "start": "198500",
    "end": "199970"
  },
  {
    "text": "And now when we apply\nK-means clustering",
    "start": "199970",
    "end": "202940"
  },
  {
    "text": "and we have to\nprespecify K, and we'll",
    "start": "202940",
    "end": "205040"
  },
  {
    "text": "see the procedure\nin a few slides.",
    "start": "205040",
    "end": "207469"
  },
  {
    "text": "But when we\nprespecify K equals 2",
    "start": "207470",
    "end": "209870"
  },
  {
    "text": "and we run the\nclustering algorithm,",
    "start": "209870",
    "end": "211370"
  },
  {
    "text": "it produces the groups indicated\nby the two colors, blue",
    "start": "211370",
    "end": "215780"
  },
  {
    "text": "and gold.",
    "start": "215780",
    "end": "216890"
  },
  {
    "text": "So with K equals 2,\nit's found approximately",
    "start": "216890",
    "end": "219740"
  },
  {
    "text": "the right clusters.",
    "start": "219740",
    "end": "220890"
  },
  {
    "text": "Although you might argue,\nwell, does this point actually",
    "start": "220890",
    "end": "223640"
  },
  {
    "text": "belong in the upper cluster\nrather than the bottom cluster?",
    "start": "223640",
    "end": "227330"
  },
  {
    "text": "And that's not something\nwhich you can answer just",
    "start": "227330",
    "end": "230360"
  },
  {
    "text": "in a quantitative way.",
    "start": "230360",
    "end": "231540"
  },
  {
    "text": "That's a subjective call.",
    "start": "231540",
    "end": "235209"
  },
  {
    "text": "In any case, it seems it\nfound the two clusters pretty",
    "start": "235210",
    "end": "239030"
  },
  {
    "text": "correctly.",
    "start": "239030",
    "end": "239940"
  },
  {
    "text": "But if I were to\nhave specified K=3,",
    "start": "239940",
    "end": "242450"
  },
  {
    "text": "it would be forced\nto find three groups.",
    "start": "242450",
    "end": "244275"
  },
  {
    "text": "And the three groups\nK-means clustering",
    "start": "244275",
    "end": "245900"
  },
  {
    "text": "found or indicated here by the\ngreen, the blue, and the gold.",
    "start": "245900",
    "end": "248989"
  },
  {
    "text": "So what it's done is it's broken\nup this apparently homogeneous",
    "start": "248990",
    "end": "251840"
  },
  {
    "text": "cluster into two clusters.",
    "start": "251840",
    "end": "254580"
  },
  {
    "text": "Similarly, with K equals 4,\nit finds the blue, the orange,",
    "start": "254580",
    "end": "260549"
  },
  {
    "text": "the purple, and the green.",
    "start": "260550",
    "end": "262590"
  },
  {
    "text": "So it's broken up\nthis bottom cluster",
    "start": "262590",
    "end": "265530"
  },
  {
    "text": "looks like into three\nclusters, although, it's",
    "start": "265530",
    "end": "268500"
  },
  {
    "text": "borrowed some points\nfrom the top right there.",
    "start": "268500",
    "end": "271260"
  },
  {
    "text": "So you can see that the\neffect of K-means clustering.",
    "start": "271260",
    "end": "273610"
  },
  {
    "text": "Well, first of all, you\ncan see the effect of K",
    "start": "273610",
    "end": "274800"
  },
  {
    "text": "is really important because if\nyou choose K to be too large,",
    "start": "274800",
    "end": "277740"
  },
  {
    "text": "it's going to be forced to break\nup groups like this one, which",
    "start": "277740",
    "end": "281910"
  },
  {
    "text": "are fairly homogeneous.",
    "start": "281910",
    "end": "283950"
  },
  {
    "text": "What's also interesting,\nRob, is that variables",
    "start": "283950",
    "end": "286320"
  },
  {
    "text": "that are somewhat\nresponsible for clusters,",
    "start": "286320",
    "end": "288990"
  },
  {
    "text": "like, for example, the\nsecond variable that we have",
    "start": "288990",
    "end": "292199"
  },
  {
    "text": "over here also tend to have\nhigh variance because if they",
    "start": "292200",
    "end": "297240"
  },
  {
    "text": "separate the data in clusters,\nthere tends to be variances.",
    "start": "297240",
    "end": "301630"
  },
  {
    "text": "So there's some connection\nbetween principal components",
    "start": "301630",
    "end": "304170"
  },
  {
    "text": "and clustering in a\nmore abstract sense.",
    "start": "304170",
    "end": "307480"
  },
  {
    "text": "OK.",
    "start": "307480",
    "end": "307980"
  },
  {
    "text": "So let's actually drill\ndown into the details",
    "start": "307980",
    "end": "310350"
  },
  {
    "text": "of K-means clustering.",
    "start": "310350",
    "end": "311630"
  },
  {
    "text": "Well, first of all, we have\nto define some notation",
    "start": "311630",
    "end": "314190"
  },
  {
    "text": "for clusters or sets.",
    "start": "314190",
    "end": "315730"
  },
  {
    "text": "So we'll call them\nC1 through Ck,",
    "start": "315730",
    "end": "317820"
  },
  {
    "text": "and they're sets of indices\nof the observations.",
    "start": "317820",
    "end": "320860"
  },
  {
    "text": "So the indices are 1 through n,\nthose are our n observations.",
    "start": "320860",
    "end": "323699"
  },
  {
    "text": "Each of these C's is going to\nbe a subset of 1 through n.",
    "start": "323700",
    "end": "327190"
  },
  {
    "text": "And the subset is going to be\na partition of 1 through n.",
    "start": "327190",
    "end": "331642"
  },
  {
    "text": "Now, if we want to\nget formalistic,",
    "start": "331642",
    "end": "333100"
  },
  {
    "text": "we'll say, well, the C's\ntheir union is 1 through n.",
    "start": "333100",
    "end": "336490"
  },
  {
    "text": "So if we concatenate\nthem all together,",
    "start": "336490",
    "end": "339639"
  },
  {
    "text": "they make up 1 through n.",
    "start": "339640",
    "end": "341110"
  },
  {
    "text": "So they're a partition\nof 1 through n,",
    "start": "341110",
    "end": "342729"
  },
  {
    "text": "and there's no intersection.",
    "start": "342730",
    "end": "343940"
  },
  {
    "text": "So there's no overlap\nbetween the clusters.",
    "start": "343940",
    "end": "345732"
  },
  {
    "text": "So this is just a\nfancy way of saying",
    "start": "345732",
    "end": "347653"
  },
  {
    "text": "we're going to break up\nthe points 1 through n",
    "start": "347653",
    "end": "349570"
  },
  {
    "text": "into K groups which\nare nonoverlapping",
    "start": "349570",
    "end": "352330"
  },
  {
    "text": "and cover the whole set.",
    "start": "352330",
    "end": "354490"
  },
  {
    "text": "And again, if the\nIth observations",
    "start": "354490",
    "end": "358224"
  },
  {
    "text": "is in the K cluster,\nthen I will be a member",
    "start": "358225",
    "end": "360520"
  },
  {
    "text": "of the indices for group K.",
    "start": "360520",
    "end": "364000"
  },
  {
    "text": "So again, we want to somehow\nfind the partition C1",
    "start": "364000",
    "end": "370190"
  },
  {
    "text": "through Ck, which is\na good clustering.",
    "start": "370190",
    "end": "372120"
  },
  {
    "text": "Well, what do you mean\nby good clustering?",
    "start": "372120",
    "end": "373870"
  },
  {
    "text": "Well, K-means clustering\ndefines good clustering",
    "start": "373870",
    "end": "377210"
  },
  {
    "text": "to be one in which within\ncluster variation is small.",
    "start": "377210",
    "end": "381699"
  },
  {
    "text": "So going back to this\npicture, if you ask me,",
    "start": "381700",
    "end": "385380"
  },
  {
    "text": "well, divide this\ninto two groups.",
    "start": "385380",
    "end": "386892"
  },
  {
    "text": "Well, the notion that K-means\nis going to use to say,",
    "start": "386892",
    "end": "389100"
  },
  {
    "text": "well, I'm going to\nfind two groups so",
    "start": "389100",
    "end": "390642"
  },
  {
    "text": "that within each group,\nlike within the gold,",
    "start": "390642",
    "end": "392580"
  },
  {
    "text": "the variation is\nsmall within the group",
    "start": "392580",
    "end": "394710"
  },
  {
    "text": "so that the points\nare close together.",
    "start": "394710",
    "end": "396590"
  },
  {
    "text": "Similarly, for this group,\nthe points are close together.",
    "start": "396590",
    "end": "400770"
  },
  {
    "text": "It's a very\nintuitive definition.",
    "start": "400770",
    "end": "402910"
  },
  {
    "text": "So let's call within cluster\nvariation of the cluster",
    "start": "402910",
    "end": "407150"
  },
  {
    "text": "Ck, WCV for within-cluster\nvariation of Ck.",
    "start": "407150",
    "end": "411460"
  },
  {
    "text": "It's the total variation.",
    "start": "411460",
    "end": "413210"
  },
  {
    "text": "For example, we could use square\ndistance in the two directions.",
    "start": "413210",
    "end": "416327"
  },
  {
    "text": "Matter of fact, most\nof the time we will use",
    "start": "416327",
    "end": "418160"
  },
  {
    "text": "squared distance for\nK-means clustering.",
    "start": "418160",
    "end": "420350"
  },
  {
    "text": "So then, if we put\nit all together,",
    "start": "420350",
    "end": "423360"
  },
  {
    "text": "If we define the\nvariation within a cluster",
    "start": "423360",
    "end": "425780"
  },
  {
    "text": "to be WCV of Ck,\nwe want to find--",
    "start": "425780",
    "end": "429770"
  },
  {
    "text": "the total variation adding\nup over all clusters is here.",
    "start": "429770",
    "end": "434300"
  },
  {
    "text": "And we want to find the\npartitioning C1 through Ck",
    "start": "434300",
    "end": "437330"
  },
  {
    "text": "to minimize the total\nwithin cluster variation.",
    "start": "437330",
    "end": "442176"
  },
  {
    "text": "So we're going to assign the\nn data points to K clusters",
    "start": "442176",
    "end": "445090"
  },
  {
    "text": "so that the total within\ncluster variation summed up",
    "start": "445090",
    "end": "448210"
  },
  {
    "text": "over the K clusters is\nas small as possible.",
    "start": "448210",
    "end": "450660"
  },
  {
    "start": "450660",
    "end": "453830"
  },
  {
    "text": "So now I said this on\nthe previous slide,",
    "start": "453830",
    "end": "457039"
  },
  {
    "text": "but here's in\ndetail, we normally",
    "start": "457040",
    "end": "460010"
  },
  {
    "text": "define within-cluster variation\nto be the Euclidean distance,",
    "start": "460010",
    "end": "463780"
  },
  {
    "text": "the pairwise squared\ndistance between each pair",
    "start": "463780",
    "end": "466220"
  },
  {
    "text": "of observations in the cluster.",
    "start": "466220",
    "end": "468710"
  },
  {
    "text": "Add it up over the p feature.",
    "start": "468710",
    "end": "470520"
  },
  {
    "text": "So this is the Euclidean\nor squared distance",
    "start": "470520",
    "end": "472940"
  },
  {
    "text": "between observations\ni and i prime.",
    "start": "472940",
    "end": "475600"
  },
  {
    "text": "And we sum it up over all\nii prime in the cluster.",
    "start": "475600",
    "end": "478790"
  },
  {
    "text": "So notice this is\nthe total pairwise",
    "start": "478790",
    "end": "480970"
  },
  {
    "text": "distance between every\npair and the cluster Ck.",
    "start": "480970",
    "end": "486490"
  },
  {
    "text": "And we're going to\nminimize the total",
    "start": "486490",
    "end": "489130"
  },
  {
    "text": "of this over K, the total\nvariation over all clusters.",
    "start": "489130",
    "end": "492340"
  },
  {
    "text": "And that's here it is.",
    "start": "492340",
    "end": "494449"
  },
  {
    "text": "So here's our\noptimization problem now.",
    "start": "494450",
    "end": "496330"
  },
  {
    "text": "Here's the\nwithin-cluster variation.",
    "start": "496330",
    "end": "499330"
  },
  {
    "text": "And we're going to\nfind the clustering C1",
    "start": "499330",
    "end": "504522"
  },
  {
    "text": "through Ck that minimizes that.",
    "start": "504523",
    "end": "505815"
  },
  {
    "start": "505815",
    "end": "511120"
  },
  {
    "text": "So we have a criterion,\nbut let's actually",
    "start": "511120",
    "end": "515500"
  },
  {
    "text": "talk about the\nK-means algorithm,",
    "start": "515500",
    "end": "516880"
  },
  {
    "text": "and then we'll\ncircle back and see",
    "start": "516880",
    "end": "520059"
  },
  {
    "text": "why I minimized the objective\non the previous slide.",
    "start": "520059",
    "end": "523559"
  },
  {
    "text": "So how K-means clustering works?",
    "start": "523559",
    "end": "525270"
  },
  {
    "text": "Well, it's got the\nword means in it,",
    "start": "525270",
    "end": "526770"
  },
  {
    "text": "so it's going to\nuse a mean somehow.",
    "start": "526770",
    "end": "528010"
  },
  {
    "text": "So it's actually an\nalternating algorithm.",
    "start": "528010",
    "end": "529950"
  },
  {
    "text": "First of all, we assign each\nobservation cluster from 1 to K.",
    "start": "529950",
    "end": "534430"
  },
  {
    "text": "So remember, K is fixed.",
    "start": "534430",
    "end": "535490"
  },
  {
    "text": "We have to decide\nahead of time, I'm",
    "start": "535490",
    "end": "536990"
  },
  {
    "text": "going to pick K equals, for\nexample, 2 or K equals 3.",
    "start": "536990",
    "end": "540029"
  },
  {
    "text": "And we'll worry later about how\nto choose K an important value.",
    "start": "540030",
    "end": "543480"
  },
  {
    "text": "But let's fix K for the moment.",
    "start": "543480",
    "end": "545199"
  },
  {
    "text": "So each observation is assigned\nto a cluster 1 through K.",
    "start": "545200",
    "end": "548700"
  },
  {
    "text": "And then we have\ntwo steps, which",
    "start": "548700",
    "end": "550800"
  },
  {
    "text": "we alternate back and forth.",
    "start": "550800",
    "end": "552550"
  },
  {
    "text": "For each of the K clusters, one\nhand, we compute the centroid.",
    "start": "552550",
    "end": "556019"
  },
  {
    "text": "That's the average value for\neach feature of all the points",
    "start": "556020",
    "end": "559260"
  },
  {
    "text": "in the centroid in the cluster.",
    "start": "559260",
    "end": "561630"
  },
  {
    "text": "So it's the mean in the vertical\nand horizontal direction",
    "start": "561630",
    "end": "564750"
  },
  {
    "text": "of the points in that cluster.",
    "start": "564750",
    "end": "568000"
  },
  {
    "text": "So having computed the centroids\nfor each of the clusters,",
    "start": "568000",
    "end": "571750"
  },
  {
    "text": "on the other step, we\nassign each data point",
    "start": "571750",
    "end": "575830"
  },
  {
    "text": "to the closest centroid.",
    "start": "575830",
    "end": "578220"
  },
  {
    "text": "And then having done that,\nwe have a new set of cluster",
    "start": "578220",
    "end": "583990"
  },
  {
    "text": "assignments, C1 through Ck.",
    "start": "583990",
    "end": "585250"
  },
  {
    "text": "We go back, and we\ncompute new centroids.",
    "start": "585250",
    "end": "587940"
  },
  {
    "text": "Using the new centroids, you\ncomplete new assignments.",
    "start": "587940",
    "end": "590190"
  },
  {
    "text": "We alternate back and forth\nuntil hopefully this thing",
    "start": "590190",
    "end": "592490"
  },
  {
    "text": "settles down.",
    "start": "592490",
    "end": "593490"
  },
  {
    "text": "And the solution is\nthe K-means clustering.",
    "start": "593490",
    "end": "597240"
  },
  {
    "text": "The solution we really\nwant is the assignment",
    "start": "597240",
    "end": "599459"
  },
  {
    "text": "of points to the groups.",
    "start": "599460",
    "end": "602960"
  },
  {
    "text": "So let me actually--",
    "start": "602960",
    "end": "606960"
  },
  {
    "text": "I'm going to show an example.",
    "start": "606960",
    "end": "608640"
  },
  {
    "text": "Let's see an example,\nand then we'll",
    "start": "608640",
    "end": "610140"
  },
  {
    "text": "go back and see why\nthat algorithm actually",
    "start": "610140",
    "end": "614190"
  },
  {
    "text": "minimizes the objective\nthat we wrote down.",
    "start": "614190",
    "end": "616160"
  },
  {
    "text": "So here's an example--",
    "start": "616160",
    "end": "619319"
  },
  {
    "text": "actually, the same example.",
    "start": "619320",
    "end": "620730"
  },
  {
    "text": "We have a four.",
    "start": "620730",
    "end": "622620"
  },
  {
    "text": "- Here's our data.",
    "start": "622620",
    "end": "624330"
  },
  {
    "text": "Again, it's unlabeled\ndata, and we've chosen K=3.",
    "start": "624330",
    "end": "628500"
  },
  {
    "text": "So in the first step, we're\ngoing to assign points",
    "start": "628500",
    "end": "632010"
  },
  {
    "text": "at random to clusters.",
    "start": "632010",
    "end": "633460"
  },
  {
    "text": "So we've indicated\nthese by the colors.",
    "start": "633460",
    "end": "636890"
  },
  {
    "text": "Each point is assigned\nto a different color.",
    "start": "636890",
    "end": "639900"
  },
  {
    "text": "And you can see\nthe assignment is--",
    "start": "639900",
    "end": "641833"
  },
  {
    "text": "the grouping is\nnot very good yet.",
    "start": "641833",
    "end": "643250"
  },
  {
    "text": "In other words, we're thinking\nthat this is one group,",
    "start": "643250",
    "end": "646100"
  },
  {
    "text": "and this is another group,\nbut we're nowhere near that",
    "start": "646100",
    "end": "649100"
  },
  {
    "text": "clustering at this point.",
    "start": "649100",
    "end": "650940"
  },
  {
    "text": "The first step, we\ncompute the centroids.",
    "start": "650940",
    "end": "653880"
  },
  {
    "text": "So these are the average of\nthe horizontal and vertical",
    "start": "653880",
    "end": "657210"
  },
  {
    "text": "direction of all the\npoints in the gold, green,",
    "start": "657210",
    "end": "660790"
  },
  {
    "text": "and blue groups.",
    "start": "660790",
    "end": "662621"
  },
  {
    "text": "And here the centroids are\npretty much on top of each other",
    "start": "662622",
    "end": "665080"
  },
  {
    "text": "because the\nassignment was random.",
    "start": "665080",
    "end": "666497"
  },
  {
    "text": "So there's no real grouping yet.",
    "start": "666497",
    "end": "668770"
  },
  {
    "text": "But don't fear, the\nK-means clustering",
    "start": "668770",
    "end": "672040"
  },
  {
    "text": "will work its way\nto a good solution.",
    "start": "672040",
    "end": "673930"
  },
  {
    "text": "So now we take the centroids,\nand we find the closest points",
    "start": "673930",
    "end": "680550"
  },
  {
    "text": "to each of the centroids.",
    "start": "680550",
    "end": "681700"
  },
  {
    "text": "So each point is we\nask, which point are you",
    "start": "681700",
    "end": "684300"
  },
  {
    "text": "closest to the green, the\npurple or the orange centroid?",
    "start": "684300",
    "end": "688050"
  },
  {
    "text": "And now we color the\npoints accordingly.",
    "start": "688050",
    "end": "689830"
  },
  {
    "text": "So this is the\npartitioning step.",
    "start": "689830",
    "end": "691830"
  },
  {
    "text": "So even though those\nfirst three centroids",
    "start": "691830",
    "end": "694080"
  },
  {
    "text": "were pretty much on top of each\nother, they weren't exactly.",
    "start": "694080",
    "end": "696820"
  },
  {
    "text": "And so that defines a fairly\nnice partition of the data",
    "start": "696820",
    "end": "700440"
  },
  {
    "text": "already.",
    "start": "700440",
    "end": "701020"
  },
  {
    "text": "Yeah, it's on\nalmost perfect job.",
    "start": "701020",
    "end": "704355"
  },
  {
    "text": "Well, you'll see we get\nto the final iterate.",
    "start": "704355",
    "end": "706230"
  },
  {
    "text": "And then given this\nnew assignment,",
    "start": "706230",
    "end": "708750"
  },
  {
    "text": "we find the centroids again.",
    "start": "708750",
    "end": "710095"
  },
  {
    "text": "But now the centroids\nare going to move",
    "start": "710095",
    "end": "711720"
  },
  {
    "text": "a lot now because of\nwhere the points are.",
    "start": "711720",
    "end": "713470"
  },
  {
    "text": "So, for example, the\naverage of these gold points",
    "start": "713470",
    "end": "715560"
  },
  {
    "text": "is way up here.",
    "start": "715560",
    "end": "716380"
  },
  {
    "text": "So here's the new gold\ncentroid, new purple, new green.",
    "start": "716380",
    "end": "719760"
  },
  {
    "text": "Now the centroids\nare sitting really",
    "start": "719760",
    "end": "721350"
  },
  {
    "text": "right in the middle\nof the clusters,",
    "start": "721350",
    "end": "723120"
  },
  {
    "text": "and the algorithm will continue\nand make a few refinements.",
    "start": "723120",
    "end": "727810"
  },
  {
    "text": "And here's the final K-means\nsolution for this example.",
    "start": "727810",
    "end": "731730"
  },
  {
    "text": "Very intuitive algorithm.",
    "start": "731730",
    "end": "734149"
  },
  {
    "text": "So let's go back.",
    "start": "734150",
    "end": "738702"
  },
  {
    "text": "Remember, we had this\nobjective function,",
    "start": "738702",
    "end": "740410"
  },
  {
    "text": "which was the total\nwithin-cluster variation",
    "start": "740410",
    "end": "742310"
  },
  {
    "text": "we want to minimize.",
    "start": "742310",
    "end": "743170"
  },
  {
    "text": "We want to find the\npartitioning that minimizes",
    "start": "743170",
    "end": "746170"
  },
  {
    "text": "this within-cluster variation.",
    "start": "746170",
    "end": "747529"
  },
  {
    "text": "Well, again, the question is--",
    "start": "747530",
    "end": "749020"
  },
  {
    "text": "there's this algorithm\nthat we wrote down,",
    "start": "749020",
    "end": "751420"
  },
  {
    "text": "does it achieve that?",
    "start": "751420",
    "end": "752829"
  },
  {
    "text": "Well, you can actually see\nthat the algorithm will always",
    "start": "752830",
    "end": "757540"
  },
  {
    "text": "decrease the value of the\nobjective at each step.",
    "start": "757540",
    "end": "760579"
  },
  {
    "text": "And you might think\nabout why that is?",
    "start": "760580",
    "end": "762930"
  },
  {
    "text": "Well, the key to it\nreally is that you",
    "start": "762930",
    "end": "765720"
  },
  {
    "text": "can write the pairwise\nvariation as the variation",
    "start": "765720",
    "end": "770910"
  },
  {
    "text": "around the componentwise means.",
    "start": "770910",
    "end": "776014"
  },
  {
    "text": "And this is really the\nkey to K-means clustering.",
    "start": "776014",
    "end": "778480"
  },
  {
    "text": "Think about it, we didn't\ncare about the centroids.",
    "start": "778480",
    "end": "781027"
  },
  {
    "text": "All we cared about\nwas the clustering.",
    "start": "781027",
    "end": "782610"
  },
  {
    "text": "Well, K-means clustering\nis done is it's put in--",
    "start": "782610",
    "end": "788060"
  },
  {
    "text": "its changed this to an\nequivalent expression",
    "start": "788060",
    "end": "791390"
  },
  {
    "text": "involving the centroid.",
    "start": "791390",
    "end": "792830"
  },
  {
    "text": "And now K-means clustering\nfinds both the component.",
    "start": "792830",
    "end": "798590"
  },
  {
    "text": "C1 through Ck as\nwell as the centroid.",
    "start": "798590",
    "end": "800450"
  },
  {
    "text": "Centroid is x bar.",
    "start": "800450",
    "end": "803000"
  },
  {
    "text": "And what it does at each\nstep is it minimizes over",
    "start": "803000",
    "end": "807970"
  },
  {
    "text": "Ck on the one hand,\nor minimizes over",
    "start": "807970",
    "end": "809629"
  },
  {
    "text": "the centroid on the other hand.",
    "start": "809630",
    "end": "810922"
  },
  {
    "text": "And each of those steps is\ngoing to decrease this criterion",
    "start": "810922",
    "end": "813470"
  },
  {
    "text": "and hence decrease\nthis criterion.",
    "start": "813470",
    "end": "815899"
  },
  {
    "text": "So if you have\ncentroids, then when",
    "start": "815900",
    "end": "820190"
  },
  {
    "text": "you come to update the\nassignment of each point,",
    "start": "820190",
    "end": "823760"
  },
  {
    "text": "it's going to go to the group\nfor which this distance is",
    "start": "823760",
    "end": "827930"
  },
  {
    "text": "smallest for fixed centroids.",
    "start": "827930",
    "end": "830070"
  },
  {
    "text": "And on the other hand, if all\nthe assignments are fixed,",
    "start": "830070",
    "end": "832970"
  },
  {
    "text": "we know that the sample mean\nminimizes the sum of squares.",
    "start": "832970",
    "end": "837709"
  },
  {
    "text": "And so that's why\neach of those steps",
    "start": "837710",
    "end": "839870"
  },
  {
    "text": "necessarily makes the\ncriterion go down.",
    "start": "839870",
    "end": "842339"
  },
  {
    "text": "So this is very slick.",
    "start": "842340",
    "end": "843340"
  },
  {
    "text": "We start off with the problem\nof solving one set of variables.",
    "start": "843340",
    "end": "846200"
  },
  {
    "text": "We added another set of\nvariables, which we think",
    "start": "846200",
    "end": "848430"
  },
  {
    "text": "would make it harder, but\nit actually makes it easier.",
    "start": "848430",
    "end": "850680"
  },
  {
    "text": "Because now when you do\nthe joint optimization",
    "start": "850680",
    "end": "853190"
  },
  {
    "text": "over both sets of variables, we\nget to the answer for the ones",
    "start": "853190",
    "end": "856520"
  },
  {
    "text": "we care about, the clustering.",
    "start": "856520",
    "end": "860740"
  },
  {
    "text": "So that's just a detail\nof the previous figure,",
    "start": "860740",
    "end": "863510"
  },
  {
    "text": "which we talked about.",
    "start": "863510",
    "end": "865330"
  },
  {
    "text": "Sorry, I missed a point here,\nwhich is that this algorithm,",
    "start": "865330",
    "end": "868900"
  },
  {
    "text": "although it gives\nyou a local minimum,",
    "start": "868900",
    "end": "870620"
  },
  {
    "text": "it's not guaranteed to\ngive the global minimum.",
    "start": "870620",
    "end": "873060"
  },
  {
    "text": "Why not?",
    "start": "873060",
    "end": "874070"
  },
  {
    "text": "Well--",
    "start": "874070",
    "end": "874650"
  },
  {
    "text": "- What does that mean,\nRob, a local minimum?",
    "start": "874650",
    "end": "876600"
  },
  {
    "text": "- Local minimum means that--",
    "start": "876600",
    "end": "879180"
  },
  {
    "text": "Well, the point is that you\ncould start the algorithm from--",
    "start": "879180",
    "end": "883399"
  },
  {
    "text": "OK.",
    "start": "883400",
    "end": "883900"
  },
  {
    "text": "The local minimum,\nI guess, means",
    "start": "883900",
    "end": "885275"
  },
  {
    "text": "in calculus it means that the\nderivative of the function is 0.",
    "start": "885275",
    "end": "889170"
  },
  {
    "text": "It doesn't mean that it's the\nlowest point of the function.",
    "start": "889170",
    "end": "891760"
  },
  {
    "text": "So if a function\nis not convex, you",
    "start": "891760",
    "end": "893700"
  },
  {
    "text": "can have a place where\nthe derivative, or there's",
    "start": "893700",
    "end": "896460"
  },
  {
    "text": "a valley, which is flat, but\nit's not the lowest value",
    "start": "896460",
    "end": "899460"
  },
  {
    "text": "in the whole function.",
    "start": "899460",
    "end": "901550"
  },
  {
    "text": "So this algorithm will\nget to a local minimum,",
    "start": "901550",
    "end": "904760"
  },
  {
    "text": "will get to a place, get\nto a valley of the function",
    "start": "904760",
    "end": "908013"
  },
  {
    "text": "we're trying to minimize,\nbut it won't be the lowest",
    "start": "908013",
    "end": "910180"
  },
  {
    "text": "value necessarily.",
    "start": "910180",
    "end": "911300"
  },
  {
    "text": "- So we can think\nof this function",
    "start": "911300",
    "end": "913120"
  },
  {
    "text": "that we're trying to optimize\nas being like a big valley,",
    "start": "913120",
    "end": "916130"
  },
  {
    "text": "but it's got lots of little\nsub valleys or little ponds",
    "start": "916130",
    "end": "918880"
  },
  {
    "text": "or whatever.",
    "start": "918880",
    "end": "919730"
  },
  {
    "text": "And any minimum is\none of those, and we",
    "start": "919730",
    "end": "922870"
  },
  {
    "text": "can get stuck in one of those.",
    "start": "922870",
    "end": "924500"
  },
  {
    "text": "Right.",
    "start": "924500",
    "end": "925000"
  },
  {
    "text": "So in the optimization\nworld, there's",
    "start": "925000",
    "end": "927213"
  },
  {
    "text": "the idea of a convex function,\nwhich says basically,",
    "start": "927213",
    "end": "929380"
  },
  {
    "text": "there's only one valley.",
    "start": "929380",
    "end": "930620"
  },
  {
    "text": "So if you find a minimum,\nit's a global minimum.",
    "start": "930620",
    "end": "933040"
  },
  {
    "text": "But this function is not convex.",
    "start": "933040",
    "end": "935308"
  },
  {
    "text": "In other words, it\ncan go up and down",
    "start": "935308",
    "end": "936850"
  },
  {
    "text": "and have more than one valley.",
    "start": "936850",
    "end": "938449"
  },
  {
    "text": "And the K-means\nalgorithm will land you",
    "start": "938450",
    "end": "940360"
  },
  {
    "text": "in a valley but not\nnecessarily the lowest valley",
    "start": "940360",
    "end": "942790"
  },
  {
    "text": "because the function\nis not convex.",
    "start": "942790",
    "end": "945089"
  },
  {
    "text": "So here's an example\nfor the same data here's",
    "start": "945090",
    "end": "948450"
  },
  {
    "text": "an example where we start\nthe algorithm from six",
    "start": "948450",
    "end": "951570"
  },
  {
    "text": "different starting\nconfigurations.",
    "start": "951570",
    "end": "953020"
  },
  {
    "text": "Remember, our\nstarting configuration",
    "start": "953020",
    "end": "954520"
  },
  {
    "text": "was we assigned each point at\nrandom to one of the clusters.",
    "start": "954520",
    "end": "957440"
  },
  {
    "text": "And this is actually\na good thing",
    "start": "957440",
    "end": "959150"
  },
  {
    "text": "to do with K-means clustering\nis since we're not guaranteed",
    "start": "959150",
    "end": "961760"
  },
  {
    "text": "to get the global minimum,\nwe start the algorithm",
    "start": "961760",
    "end": "964742"
  },
  {
    "text": "at more than one\nplace, and we just",
    "start": "964742",
    "end": "966200"
  },
  {
    "text": "examine the value\nof the criterion",
    "start": "966200",
    "end": "968255"
  },
  {
    "text": "at the end in each case.",
    "start": "968255",
    "end": "970160"
  },
  {
    "text": "Remember, starting the algorithm\nwas this random assignment",
    "start": "970160",
    "end": "972980"
  },
  {
    "text": "of points to the number\nof clusters you're using.",
    "start": "972980",
    "end": "976388"
  },
  {
    "text": "- So when we start the\nalgorithm from different places,",
    "start": "976388",
    "end": "978680"
  },
  {
    "text": "we get actually quite\ndifferent solutions.",
    "start": "978680",
    "end": "980230"
  },
  {
    "text": "Don't worry about the\nfact that the colors are",
    "start": "980230",
    "end": "982147"
  },
  {
    "text": "chosen differently like this.",
    "start": "982147",
    "end": "983959"
  },
  {
    "text": "These are gold, and\nthese are green,",
    "start": "983960",
    "end": "985910"
  },
  {
    "text": "that the coloring is arbitrary.",
    "start": "985910",
    "end": "987230"
  },
  {
    "text": "But the partitioning\nis quite different.",
    "start": "987230",
    "end": "990829"
  },
  {
    "text": "And typically, we\npick the lowest value.",
    "start": "990830",
    "end": "993840"
  },
  {
    "text": "There's-- see this guy.",
    "start": "993840",
    "end": "995700"
  },
  {
    "text": "Well, these--",
    "start": "995700",
    "end": "996320"
  },
  {
    "text": "Looks like we got three\ndifferent solutions there.",
    "start": "996320",
    "end": "998847"
  },
  {
    "text": "- Three or four different--\nthree different?",
    "start": "998847",
    "end": "1000680"
  },
  {
    "text": "Yeah, three different\nsolutions, I guess.",
    "start": "1000680",
    "end": "1002500"
  },
  {
    "text": "The ones you colored\nin red at the top",
    "start": "1002500",
    "end": "1004330"
  },
  {
    "text": "all have exactly\nthe same distance.",
    "start": "1004330",
    "end": "1006290"
  },
  {
    "text": "Yeah.",
    "start": "1006290",
    "end": "1006790"
  },
  {
    "text": "So they actually all the same.",
    "start": "1006790",
    "end": "1008320"
  },
  {
    "text": "The colorings are\ndifferent, but, as Rob said,",
    "start": "1008320",
    "end": "1011067"
  },
  {
    "text": "the coloring is arbitrary.",
    "start": "1011067",
    "end": "1012150"
  },
  {
    "text": "Yeah.",
    "start": "1012150",
    "end": "1012650"
  },
  {
    "text": "So these solutions,\nthese four panels",
    "start": "1012650",
    "end": "1014920"
  },
  {
    "text": "give us the solution\nwith lowest--",
    "start": "1014920",
    "end": "1017360"
  },
  {
    "text": "But the top left\nand the bottom right",
    "start": "1017360",
    "end": "1019220"
  },
  {
    "text": "are actually different\nsolutions again.",
    "start": "1019220",
    "end": "1021290"
  },
  {
    "text": "Right.",
    "start": "1021290",
    "end": "1022570"
  },
  {
    "text": "OK.",
    "start": "1022570",
    "end": "1024173"
  },
  {
    "text": "So that's K-means clustering.",
    "start": "1024174",
    "end": "1026380"
  },
  {
    "text": "We'll actually talk a\nlittle bit about the end,",
    "start": "1026380",
    "end": "1028720"
  },
  {
    "text": "how to choose K.\nwhich also will be",
    "start": "1028720",
    "end": "1031449"
  },
  {
    "text": "an issue for hierarchical\nclustering, which",
    "start": "1031450",
    "end": "1033279"
  },
  {
    "text": "is a topic of our next segment.",
    "start": "1033280",
    "end": "1036750"
  },
  {
    "start": "1036750",
    "end": "1038000"
  }
]
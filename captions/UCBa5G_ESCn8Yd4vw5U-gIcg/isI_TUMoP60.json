[
  {
    "text": "Hi, everyone. Welcome to the class.",
    "start": "5360",
    "end": "10400"
  },
  {
    "text": "Jiaxuan covered the topics\naround graph neural networks over the last few weeks.",
    "start": "10400",
    "end": "16230"
  },
  {
    "text": "But now, I'm and\nI'm going to cover for some of the next topics.",
    "start": "16230",
    "end": "23430"
  },
  {
    "text": "So here is what we'll talk\ntoday about without any bugs. We so far talked about\ngraph neural networks",
    "start": "23430",
    "end": "30530"
  },
  {
    "text": "and how to handle graphs with\na single type of relation. And then, in the\nlast lecture, we",
    "start": "30530",
    "end": "38690"
  },
  {
    "text": "then talked about\nheterogeneous graphs and how do you build GNNs\nfor heterogeneous graphs.",
    "start": "38690",
    "end": "43850"
  },
  {
    "text": "We talked about the relational\nGCN, the knowledge graph-- we talked about the relational\nGCN in the last graph--",
    "start": "43850",
    "end": "50390"
  },
  {
    "text": "in the last lecture. What are we going to do today? We are going to talk about\nknowledge graphs, which are these directed graphs\nwith different relation types",
    "start": "50390",
    "end": "59059"
  },
  {
    "text": "that usually have no features\non nodes of the network.",
    "start": "59060",
    "end": "64670"
  },
  {
    "text": "What we are going to\ntalk to today about is an analog of\nNode2Vec and DeepWalk",
    "start": "64670",
    "end": "71190"
  },
  {
    "text": "that this shallow embeddings\nthat we talked about at the beginning of the\nclass, and generalize that",
    "start": "71190",
    "end": "79350"
  },
  {
    "text": "to heterogeneous graphs. That's one way to think of this. The task we'll be talking\nabout is the embeddings",
    "start": "79350",
    "end": "86130"
  },
  {
    "text": "for knowledge graph completion. That's the way to think of this. Last time.",
    "start": "86130",
    "end": "91200"
  },
  {
    "text": "Sorry, sorry, sorry. So last time, we talked\nabout heterogeneous graphs, we talked about graphs\nwith different node types",
    "start": "91200",
    "end": "98572"
  },
  {
    "text": "and different relation types. Yes. Ignore everything\nI've said so far.",
    "start": "98572",
    "end": "105880"
  },
  {
    "text": "Sorry. Sorry. It was the wrong slides. That's why it was in October,\nthat's all everything is wrong.",
    "start": "105880",
    "end": "111700"
  },
  {
    "text": "Sorry, sorry, sorry. Brand new lecture. Breath in. Look, you guys are the\nbest, you arrived late.",
    "start": "111700",
    "end": "120060"
  },
  {
    "text": "You won't be confused. So if you are\nconfused, ask them. So brand new lecture,\nstart from scratch,",
    "start": "120060",
    "end": "126150"
  },
  {
    "text": "ignore everything I said. Really sorry. Going again. So these are the announcements\nthat are good, read them.",
    "start": "126150",
    "end": "134790"
  },
  {
    "text": "They've been verified. This is the CS224W machine\nlearning with graphs.",
    "start": "134790",
    "end": "139829"
  },
  {
    "text": "Today, we are going to\ntalk about knowledge graphs embeddings. So the topic is right.",
    "start": "139830",
    "end": "145080"
  },
  {
    "text": "What did we talked\nabout last time? We talked about how do we\ngeneralize graph neural",
    "start": "145080",
    "end": "151350"
  },
  {
    "text": "networks to\nheterogeneous graphs, where we have edges\nof different types and we have nodes, potentially\nof different types.",
    "start": "151350",
    "end": "160260"
  },
  {
    "text": "We talked about relational GCN\nwhere we learn a graph from--",
    "start": "160260",
    "end": "165390"
  },
  {
    "text": "basically, we learn from a graph\nwith multiple relation types, and we use different\nneural network weights",
    "start": "165390",
    "end": "170790"
  },
  {
    "text": "for different relation types. So we basically took\nthe GNN architecture, but generalized it now so that\nthis message-passing functions",
    "start": "170790",
    "end": "180150"
  },
  {
    "text": "are relation-specific so that\nwe have more expressive power when working with\nheterogeneous graphs.",
    "start": "180150",
    "end": "187010"
  },
  {
    "text": "Today, we are going to\ntake this and further generalize it to the\nnotion of knowledge graphs.",
    "start": "187010",
    "end": "194930"
  },
  {
    "text": "Let me first tell you\nwhat is a knowledge graph and why is it so important\nand why is it so useful.",
    "start": "194930",
    "end": "200220"
  },
  {
    "text": "So knowledge graphs allow you\nto capture in a graph form, in a relational form\nknowledge about entities",
    "start": "200220",
    "end": "208220"
  },
  {
    "text": "and their relations. So we are going to\ncapture entities, types, and the relationships\nbetween them.",
    "start": "208220",
    "end": "214490"
  },
  {
    "text": "You can think of\nnodes as entities. And node types are-- and these nodes are\nlabeled with their types.",
    "start": "214490",
    "end": "222349"
  },
  {
    "text": "And then edges between two\nnodes capture the relationship between the entities.",
    "start": "222350",
    "end": "228019"
  },
  {
    "text": "Knowledge graph is an example\nof a heterogeneous graph. But the reason why we call\nthese things knowledge",
    "start": "228020",
    "end": "233120"
  },
  {
    "text": "graphs because the\nidea is that we encode our knowledge\nabout a given domain in this type of graphical form.",
    "start": "233120",
    "end": "239760"
  },
  {
    "text": "So we can think of this\nas a knowledge base over which you can\nreason, over which you can retrieve, and allows\nyou to bring in the knowledge",
    "start": "239760",
    "end": "248370"
  },
  {
    "text": "to your machine learning model. So that's the idea. What would be one example\nof a knowledge graph?",
    "start": "248370",
    "end": "255520"
  },
  {
    "text": "For example, if you are\nanswering questions, predictions about\nacademia and papers,",
    "start": "255520",
    "end": "261000"
  },
  {
    "text": "then, for example, a\nbibliographic network, you can think of it\nas a knowledge graph.",
    "start": "261000",
    "end": "266280"
  },
  {
    "text": "You have conferences, papers,\ntitles, year of publications, and authors, and papers have\ncitations to each other.",
    "start": "266280",
    "end": "273220"
  },
  {
    "text": "So this is like a schema of\nthis heterogeneous knowledge graph with five different\nnode types and five",
    "start": "273220",
    "end": "280050"
  },
  {
    "text": "different relation types. Now, I'm basically\nencoding all I",
    "start": "280050",
    "end": "285480"
  },
  {
    "text": "know about all the\npublications ever published. Another example, especially\nthat is extremely useful,",
    "start": "285480",
    "end": "293790"
  },
  {
    "text": "is biomedicine,\nwhere, again, you have a lot of\ndifferent entities, from drugs to diseases, adverse\nevents, proteins, pathways,",
    "start": "293790",
    "end": "303720"
  },
  {
    "text": "and you want to encode this\nknowledge in a graphical form. Here, we have different\ntypes of relations,",
    "start": "303720",
    "end": "310270"
  },
  {
    "text": "like is_a so\nhierarchical associations between different things,\ntreatment that are given drug",
    "start": "310270",
    "end": "317139"
  },
  {
    "text": "treats for a given\ndisease, a drug may cause adverse side effect\nof migraine in this case.",
    "start": "317140",
    "end": "324550"
  },
  {
    "text": "You can build this\nknowledge graph scaffold that you can use\nas a knowledge base",
    "start": "324550",
    "end": "330700"
  },
  {
    "text": "over which you can then reason\nor over which you can then learn. And there's many\nother knowledge graphs",
    "start": "330700",
    "end": "337600"
  },
  {
    "text": "that I'm going to\nshow you later. For example, Google\nanswers a knowledge graph when you type questions\ninto the Google search box.",
    "start": "337600",
    "end": "345370"
  },
  {
    "text": "Same with Amazon. Amazon has a knowledge\ngraph of all their products,",
    "start": "345370",
    "end": "350500"
  },
  {
    "text": "their properties, sellers, and\nall that is, in some sense, their knowledge base.",
    "start": "350500",
    "end": "356110"
  },
  {
    "text": "Facebook calls this\nthe Facebook Graph API, if you want to access\nFacebook as a graph.",
    "start": "356110",
    "end": "362169"
  },
  {
    "text": "If you look at\nFacebook, in a sense, it's not only people\nand their relationships, but also what\nschools people went,",
    "start": "362170",
    "end": "370789"
  },
  {
    "text": "what locations they attended. That's all nodes in\nthis knowledge graph. It's all resolved to\nthe level of entities.",
    "start": "370790",
    "end": "379670"
  },
  {
    "text": "There are other examples\nof these technologies. From IBM Watson to\nMicrosoft has its own,",
    "start": "379670",
    "end": "386060"
  },
  {
    "text": "they call it Satori, LinkedIn,\nYandex, and so on and so forth.",
    "start": "386060",
    "end": "392540"
  },
  {
    "text": "Just give you one example\nof the application is for serving information. When you ask, let's\nsay, here, Bing,",
    "start": "392540",
    "end": "399259"
  },
  {
    "text": "what are the latest films\nby the director of Titanic? They actually parse this\ngo to the knowledge graph,",
    "start": "399260",
    "end": "411770"
  },
  {
    "text": "find the director, and then look\nat what is this director linked by the relation\nthat they directed,",
    "start": "411770",
    "end": "418130"
  },
  {
    "text": "what movies they directed. And that's how they retrieve. Usually, if you think\nabout question answering,",
    "start": "418130",
    "end": "427000"
  },
  {
    "text": "let's say, systems. If you think of Siri,\nif you think of Alexa, they are powered by the\nstructured knowledge",
    "start": "427000",
    "end": "434710"
  },
  {
    "text": "in the background. Siri uses a humongous knowledge\ngraph of the world's knowledge",
    "start": "434710",
    "end": "439720"
  },
  {
    "text": "that when you ask it a question,\nthe thing queries and gives you the answer.",
    "start": "439720",
    "end": "445450"
  },
  {
    "text": "Here, I'm showing you an\nexample of a architecture of this conversational\nquestion-answering system,",
    "start": "445450",
    "end": "454360"
  },
  {
    "text": "where the natural language\nunderstanding is only",
    "start": "454360",
    "end": "459879"
  },
  {
    "text": "a part of this. And in particular, what\nthe key part is to take this language parse it\ninto a set of candidates",
    "start": "459880",
    "end": "469330"
  },
  {
    "text": "that you are then retrieving\nfrom the knowledge graphs, and then returning\nback to the user.",
    "start": "469330",
    "end": "475400"
  },
  {
    "text": "So that's the key in this case. Today, we are going to talk\nabout this knowledge graphs.",
    "start": "475400",
    "end": "482199"
  },
  {
    "text": "And if you think about general\nknowledge, knowledge graphs, then FreeBase, Wikidata,\nDbpedia are examples of this.",
    "start": "482200",
    "end": "490660"
  },
  {
    "text": "You can take an entire Wikipedia\nand you can represent it as a graph of nodes\nand their properties",
    "start": "490660",
    "end": "498020"
  },
  {
    "text": "and relations between them. FreeBase is another\nexample of this. This was, I think, a project\nthat Google acquired a couple",
    "start": "498020",
    "end": "505370"
  },
  {
    "text": "of years ago for a lot. I think the price\nwas in billions.",
    "start": "505370",
    "end": "511910"
  },
  {
    "text": "What is common characteristics\nto these things is that they are\nmassive, they have millions of nodes, millions of\ndifferent edges and relations,",
    "start": "511910",
    "end": "520219"
  },
  {
    "text": "and they are really incomplete,\nin a sense that knowledge has not been completely mapped\nin this knowledge graphs.",
    "start": "520220",
    "end": "527840"
  },
  {
    "text": "Usually, the reason,\nthere is two ways. One is we haven't entered\nall the knowledge in,",
    "start": "527840",
    "end": "533540"
  },
  {
    "text": "and the second reason\nis we haven't yet discovered all the knowledge. If you think about biomedicine,\nbiomedical knowledge graphs",
    "start": "533540",
    "end": "541520"
  },
  {
    "text": "are incomplete because\nwe don't understand fully the, let's say, human biology.",
    "start": "541520",
    "end": "547262"
  },
  {
    "text": "So clearly, there\nis information we are missing because we\nhaven't discovered it yet, versus a knowledge graph like\nFreeBase, I'll show you later.",
    "start": "547262",
    "end": "555020"
  },
  {
    "text": "83% of people that appear in\nfreebase as nodes don't have a year of birth, I\nthink, is the statistic,",
    "start": "555020",
    "end": "561800"
  },
  {
    "text": "because nobody added\nthat information in yet. Given what we'll be\ntalking today about--",
    "start": "561800",
    "end": "570020"
  },
  {
    "text": "given a massive knowledge\ngraph enumerating all possible facts\nbecomes intractable.",
    "start": "570020",
    "end": "575900"
  },
  {
    "text": "But what we would like to\ndo is, the question is, can we predict plausible\nbut missing links",
    "start": "575900",
    "end": "582259"
  },
  {
    "text": "in this knowledge graph? So can we somehow embed\nnodes in the knowledge graph? To show you, I said earlier, a\nprominent example of knowledge",
    "start": "582260",
    "end": "590870"
  },
  {
    "text": "graphs is FreeBase. This encodes knowledge about\nthis commonly known entities",
    "start": "590870",
    "end": "600200"
  },
  {
    "text": "that appear in the world. It's about 80 million entities,\n38,000 different relation",
    "start": "600200",
    "end": "606930"
  },
  {
    "text": "types. So there is 38,000 different\nedge types and 3 billion edges.",
    "start": "606930",
    "end": "614240"
  },
  {
    "text": "Because by the relation-- so the point is it's\nnot five relation types, it's 83,000 different\nrelation types.",
    "start": "614240",
    "end": "621889"
  },
  {
    "text": "So the world knowledge\nin this structured forum is very complex.",
    "start": "621890",
    "end": "630560"
  },
  {
    "text": "As I said, 93% of people\nthat appear in FreeBase",
    "start": "630560",
    "end": "635690"
  },
  {
    "text": "don't have a place of birth, and\n80% don't have a nationality.",
    "start": "635690",
    "end": "641030"
  },
  {
    "text": "So there is no link relationship\nof that person nationality",
    "start": "641030",
    "end": "646340"
  },
  {
    "text": "and to the, let's say, country\nor nation mapped explicitly in this knowledge graph.",
    "start": "646340",
    "end": "651560"
  },
  {
    "text": "Yes. I guess, when you're recording\ndata in these knowledge graphs,",
    "start": "651560",
    "end": "656690"
  },
  {
    "text": "is it preferable to have a\nproliferation of relation types, like lots\nof relation types,",
    "start": "656690",
    "end": "662720"
  },
  {
    "text": "or is it more useful to have\ngrouping of relation types from a learning perspective?",
    "start": "662720",
    "end": "667790"
  },
  {
    "text": "Good point. So what you are asking\nis to say you have-- here, I emphasized, you\nhave this huge number",
    "start": "667790",
    "end": "672920"
  },
  {
    "text": "of relation types. And the question is,\nis that too much? What should you do?",
    "start": "672920",
    "end": "680060"
  },
  {
    "text": "I would say there is\nan entire, how to say, industry, or an entire field\nof how do you build ontologies,",
    "start": "680060",
    "end": "689420"
  },
  {
    "text": "how do you build\nthis knowledge bases. And it becomes very,\nvery tricky how",
    "start": "689420",
    "end": "694820"
  },
  {
    "text": "do you bring any\nstructure to this 38,000 different relationships. Usually, what would happen\nis that you would have them",
    "start": "694820",
    "end": "701810"
  },
  {
    "text": "in some hierarchy, if possible,\nwhere these relationships would get more and more fine\ngrained, but still allows you",
    "start": "701810",
    "end": "708380"
  },
  {
    "text": "to reason between different\nrelationship types. That becomes quite important.",
    "start": "708380",
    "end": "714960"
  },
  {
    "text": "In terms of publicly\navailable data sets that people\nlike to use, there is this FreeBase 15,000, which\nis a graph on 50,000 entities,",
    "start": "714960",
    "end": "724230"
  },
  {
    "text": "between 200 and 1,300 different\nrelations, and about 300,000",
    "start": "724230",
    "end": "729490"
  },
  {
    "text": "to 600,000 different edges. So if you want to little\nacademic benchmark,",
    "start": "729490",
    "end": "736709"
  },
  {
    "text": "this is what NeurIPS\npapers tend to use. But really, the full\ndata set is up here,",
    "start": "736710",
    "end": "742620"
  },
  {
    "text": "very few papers have the\nguts to use the big data set because it's massive.",
    "start": "742620",
    "end": "748650"
  },
  {
    "text": "But that's the idea. Now, what we will-- so now\nlet's-- we talked about this",
    "start": "748650",
    "end": "753690"
  },
  {
    "text": "knowledge graph concept. Now, let's talk about what is\nthe knowledge graph completion",
    "start": "753690",
    "end": "760620"
  },
  {
    "text": "task that people like to do. A knowledge graph completion\ntask is defined as follows.",
    "start": "760620",
    "end": "765730"
  },
  {
    "text": "Given an enormous\nknowledge graph, the question is,\ncan we complete it? It's almost like a\nlink prediction task,",
    "start": "765730",
    "end": "773220"
  },
  {
    "text": "but it's a bit more nuanced. And this link prediction\ntask for knowledge graph",
    "start": "773220",
    "end": "778470"
  },
  {
    "text": "says, given a head\nand a relation type, predict me the missing tails.",
    "start": "778470",
    "end": "785250"
  },
  {
    "text": "So it would be for\na particular person, for a particular relation\ntype may be born in,",
    "start": "785250",
    "end": "792240"
  },
  {
    "text": "give me a list of places\nwhere that person might have been born. Because a single person can\nbe born only in one place,",
    "start": "792240",
    "end": "798870"
  },
  {
    "text": "I'd only take the top one. But in other cases, maybe\nit'd be like visited. Tell me all the places\nthat Napoleon visited, then",
    "start": "798870",
    "end": "806730"
  },
  {
    "text": "it'd be a ranking and\nsomewhere I would cut that. One example of the task would\nbe, for the predict the tail,",
    "start": "806730",
    "end": "818220"
  },
  {
    "text": "you would predict \"Science\nFiction\" for the head entity J.K. Rowling. In the genre\nrelation, the question",
    "start": "818220",
    "end": "826470"
  },
  {
    "text": "is, what is the\ntail of this query? It would be science fiction\nor it would be, I don't know,",
    "start": "826470",
    "end": "833340"
  },
  {
    "text": "youth literature, or\nhowever you want to call it. So that's what we would\nlike to be able to do.",
    "start": "833340",
    "end": "840420"
  },
  {
    "text": "As I said, it's a bit\ndifferent than link prediction because I'm given the head\nand the relation type.",
    "start": "840420",
    "end": "846150"
  },
  {
    "text": "Now, as I mentioned in the\nbeginning of the lecture, the way we are going\nto do this is we are going to learn a shallow\nembedding of the nodes.",
    "start": "846150",
    "end": "853959"
  },
  {
    "text": "So it means that for every\nnode in the knowledge graph, we are going to learn its\ncoordinates in a shallow way.",
    "start": "853960",
    "end": "860160"
  },
  {
    "text": "So we will not be using\nGNNs, but we are moving back to this idea of shallow\nembeddings, DeepWalks,",
    "start": "860160",
    "end": "866520"
  },
  {
    "text": "and Node2Vec. But, as you will see, we will\nnot be using random walks,",
    "start": "866520",
    "end": "872670"
  },
  {
    "text": "so we'll just be using\nshallow embeddings. In terms of knowledge\ngraph representation,",
    "start": "872670",
    "end": "880080"
  },
  {
    "text": "the way we think of it is that\nit's a set of these triples: head, relation, tail. And the idea is that we want\nto model entities and relations",
    "start": "880080",
    "end": "889110"
  },
  {
    "text": "as embeddings or vectors\nin some Euclidean space. And we want to associate\nentities and relations",
    "start": "889110",
    "end": "895740"
  },
  {
    "text": "with shallow embeddings. As I said, no GNNs. The reason, perhaps, why no\nGNNs is because this knowledge",
    "start": "895740",
    "end": "904199"
  },
  {
    "text": "graphs usually have\nno node features. Maybe you have a node\ntype, but not more right.",
    "start": "904200",
    "end": "909360"
  },
  {
    "text": "All the information\nis in relations. Then, the idea will be, given\na true triple, head, relation,",
    "start": "909360",
    "end": "916050"
  },
  {
    "text": "tail, the goal is to find the\nembedding for the head relation that is close to the\nembedding of the target.",
    "start": "916050",
    "end": "924720"
  },
  {
    "text": "So we'll be talking\nabout embeddings of I will give you a head\nand I'll give you a relation,",
    "start": "924720",
    "end": "930600"
  },
  {
    "text": "you will produce me an\nembedding of this thing. Hopefully, the\nembedding of this thing will be close to the\nembedding of the target.",
    "start": "930600",
    "end": "937020"
  },
  {
    "text": "So that the answer to\nthis query is this target. That's the hope.",
    "start": "937020",
    "end": "944310"
  },
  {
    "text": "The question then is, how\ndo you embed this thing and how do you define closeness?",
    "start": "944310",
    "end": "950220"
  },
  {
    "text": "What is interesting, notice,\nI'm not embedding just a node, I'm embedding node,\ncomma relation.",
    "start": "950220",
    "end": "956380"
  },
  {
    "text": "And I'd like that this\nembedding node comma relation in the space is\nclose to the answer to this.",
    "start": "956380",
    "end": "963910"
  },
  {
    "text": "The correct thing has\nto be close to where the embedding of this\ncomma relation is.",
    "start": "963910",
    "end": "970700"
  },
  {
    "text": "So what we are\ngoing to do today is we are going to learn\nabout different methods",
    "start": "970700",
    "end": "976100"
  },
  {
    "text": "to produce embeddings\nof knowledge graphs as well as the relations\nthat are in them.",
    "start": "976100",
    "end": "982100"
  },
  {
    "text": "These embeddings\nwill be shallow, so we'll work in the\ntransductive case.",
    "start": "982100",
    "end": "987330"
  },
  {
    "text": "We are going to use different\ngeometric, Euclidean geometry type intuitions,\nand we are going",
    "start": "987330",
    "end": "994730"
  },
  {
    "text": "to talk about different\ntypes of relationships that our embeddings\nwill be able to capture.",
    "start": "994730",
    "end": "1001310"
  },
  {
    "text": "We'll talk about four different\nmethods: TransE, TransR, DistMult, and ComplEx.",
    "start": "1001310",
    "end": "1007370"
  },
  {
    "text": "It doesn't matter yet what\nthey are, I'm going to define. It doesn't matter what\nexactly this means. But basically, we are going\nthen to look at different types",
    "start": "1007370",
    "end": "1014829"
  },
  {
    "text": "of relations. We'll talk about\nsymmetric relations, antisymmetric relations, inverse\nrelations, composite relations,",
    "start": "1014830",
    "end": "1022570"
  },
  {
    "text": "and 1 to n relations. I'm going to\nexplain these and we are going to see how different\nmethod is able to embed",
    "start": "1022570",
    "end": "1030410"
  },
  {
    "text": "different types of relations. That's what is going to happen,\nand the rest of the lecture",
    "start": "1030410",
    "end": "1036319"
  },
  {
    "text": "will go through this\ntable line by line. We are going to fill\nin this checkmarks",
    "start": "1036319",
    "end": "1043880"
  },
  {
    "text": "and crosses for each\nof these things. So at the end, basically,\nthis table will be filled in",
    "start": "1043880",
    "end": "1050840"
  },
  {
    "text": "and it will make sense. So the first method\nI want to talk",
    "start": "1050840",
    "end": "1056029"
  },
  {
    "text": "about is the first line of\nmy table here is the TransE.",
    "start": "1056030",
    "end": "1060295"
  },
  {
    "text": "Are there any questions\nbefore we jump in?",
    "start": "1063020",
    "end": "1065060"
  },
  {
    "text": "Yes. I mean, just based on our\ndefinition, where we're taking the head, the\nrelation, and then the target is like the thing we're\ntrying to predict.",
    "start": "1068820",
    "end": "1075420"
  },
  {
    "text": "It's like saying that the\ngraph is like directed, because we're always saying\nthere is a direction from graph",
    "start": "1075420",
    "end": "1080520"
  },
  {
    "text": "edge that already gives you\ndirections toward a target. So there's a relation. Yes, you can-- great point. So you are asking, is\nthe graph directed?",
    "start": "1080520",
    "end": "1087600"
  },
  {
    "text": "Yeah, you can think of\nit that it's directed. But if we are brothers, then\nI have a link brother to you,",
    "start": "1087600",
    "end": "1095460"
  },
  {
    "text": "but you can also have\na link brother to me. Yes, we are talking\nabout directed graphs,",
    "start": "1095460",
    "end": "1101250"
  },
  {
    "text": "but some relations can go both\nways as we are going to see. So that will be one of\nthe kind of properties",
    "start": "1101250",
    "end": "1108270"
  },
  {
    "text": "that we are going to talk about. Super. So here is the TransE\nintuition, and it's really",
    "start": "1108270",
    "end": "1115680"
  },
  {
    "text": "about this\ntranslation intuition. Where the idea is for the\ntriple head relation tail,",
    "start": "1115680",
    "end": "1121289"
  },
  {
    "text": "I would like the following\nin my vector space in my Euclidean space. I'd like h plus r\nto be equal to t.",
    "start": "1121290",
    "end": "1131650"
  },
  {
    "text": "If the given facts are\ntrue and otherwise, I'd like this to be different.",
    "start": "1131650",
    "end": "1137890"
  },
  {
    "text": "That's the intuition. So the way this would look like\nis to say the embedding of an h comma r is that I take\nthe embedding of h,",
    "start": "1137890",
    "end": "1145330"
  },
  {
    "text": "I have some embedding for r\nso I move in this direction, and hopefully, I end up\nclose to the target t.",
    "start": "1145330",
    "end": "1153680"
  },
  {
    "text": "I'll have an embedding\nfor every relation, I'll have an embedding\nfor every entity. So if this is a relation\nbrother and if this is me,",
    "start": "1153680",
    "end": "1162080"
  },
  {
    "text": "then, from me to brother, here\nshould be all my brothers. I know, if there is a relation\nsister, then I'd go this way",
    "start": "1162080",
    "end": "1168860"
  },
  {
    "text": "and here should be\nembedded all my sisters. Just as an example. Or if there is a relation\nUri likes to eat,",
    "start": "1168860",
    "end": "1176270"
  },
  {
    "text": "then I would learn I\nknow something down here, and here would be all the\ndishes that Uri likes to eat.",
    "start": "1176270",
    "end": "1182870"
  },
  {
    "text": "That's the idea here. So the idea is that, if I\nhave an embedding of Obama,",
    "start": "1182870",
    "end": "1188520"
  },
  {
    "text": "I have an embedding\nof nationality, so now I say, what is\nthe nationality of Obama? I take this.",
    "start": "1188520",
    "end": "1194510"
  },
  {
    "text": "I take the vector that I\nlearned for nationality. I move in the space. Wherever I land, this is\nwhere I want his nationality",
    "start": "1194510",
    "end": "1202580"
  },
  {
    "text": "to be embedded. That will be the\nobjective function. Of course, it won't be spot\non, but that's the idea.",
    "start": "1202580",
    "end": "1209485"
  },
  {
    "text": "Basically, this\nmeans that we are going to learn\nembeddings of entities as well as the embeddings\nof relations or vectors",
    "start": "1209485",
    "end": "1215790"
  },
  {
    "text": "for these relations, with\nthe goal that if I start at the head, I move in the\ndirection of the relation--",
    "start": "1215790",
    "end": "1221640"
  },
  {
    "text": "that is specified\nby the relation, I arrive at the target. And for people who have\nMLP background, remember,",
    "start": "1221640",
    "end": "1229290"
  },
  {
    "text": "when we had this\nsome time ago, there were these word embeddings\nand people were so",
    "start": "1229290",
    "end": "1235230"
  },
  {
    "text": "fascinated that if you take a\nKing and move in one direction, you move to the Queen.",
    "start": "1235230",
    "end": "1239270"
  },
  {
    "text": "It was consistent for\ndifferent Kings and Queens of all different\nworld countries,",
    "start": "1243660",
    "end": "1249809"
  },
  {
    "text": "that vector in which you move\nwas the same for them all. Or if you took a\nname of the country",
    "start": "1249810",
    "end": "1254850"
  },
  {
    "text": "and you look where is\nthe capital embedded, it was the same direction. From China and Beijing,\nfrom USA and Washington,",
    "start": "1254850",
    "end": "1262530"
  },
  {
    "text": "DC, for Germany and Berlin,\nit was all these vectors. So that's the one\nmotivation for this.",
    "start": "1262530",
    "end": "1271110"
  },
  {
    "text": "Here's the algorithm,\nI throw pseudocode up. But the reason I want to throw\nit up, like show it here,",
    "start": "1271110",
    "end": "1276750"
  },
  {
    "text": "is that I want to show you\nthat the way you learn this is in using a contrastive\nor triplet loss.",
    "start": "1276750",
    "end": "1282930"
  },
  {
    "text": "So that's the concept I\nwant to teach you here. So the way we think of\nthis is that, basically, we initialize the\nembeddings of uniformly",
    "start": "1282930",
    "end": "1291870"
  },
  {
    "text": "at random of entities\nand relations. And then, what I'm\ndoing is I'm basically--",
    "start": "1291870",
    "end": "1298799"
  },
  {
    "text": "I need to create\nnegative samples for every triplet in my\nknowledge graph head relation",
    "start": "1298800",
    "end": "1306930"
  },
  {
    "text": "tail. I say, aha, for a given\nhead and a given relation,",
    "start": "1306930",
    "end": "1312539"
  },
  {
    "text": "the tail is a positive example. But the real tail is\na positive example, but now I need to find\na negative example tail.",
    "start": "1312540",
    "end": "1321570"
  },
  {
    "text": "Now that I have a head,\nreal tail, and a wrong tail, my goal in the\nobjective function",
    "start": "1321570",
    "end": "1327750"
  },
  {
    "text": "is that the distance\nbetween head plus relation to the real tail should\nbe smaller than the distance",
    "start": "1327750",
    "end": "1334139"
  },
  {
    "text": "from the head plus relation\nand the wrong tail. And then, of course,\nhere, you ask yourself,",
    "start": "1334140",
    "end": "1341820"
  },
  {
    "text": "and this is called a\ncontrastive loss that favors lower distance, higher\nscore for valid triples,",
    "start": "1341820",
    "end": "1349470"
  },
  {
    "text": "and wants to have\nhigh distance, lower score for the corrupted\nones, for the negative ones.",
    "start": "1349470",
    "end": "1357059"
  },
  {
    "text": "And that's the contrastive\nloss I want to explain here. Yes, question. Yes.",
    "start": "1357060",
    "end": "1362610"
  },
  {
    "text": "So in the line 10 or\n[INAUDIBLE] whenever you sample your\nnegative sample, you have h prime as well as t prime.",
    "start": "1362610",
    "end": "1369990"
  },
  {
    "text": "Does that mean you\nare sampling for both like a real head\nand a wrong tail?",
    "start": "1369990",
    "end": "1376020"
  },
  {
    "text": "Yeah Good question. You can do it both ways. You could say, for\nthe head relation,",
    "start": "1376020",
    "end": "1382950"
  },
  {
    "text": "I want to get a correct\ntail and the wrong tail. The question is, what\nis the wrong tail? If you will pick\na random entity,",
    "start": "1382950",
    "end": "1389610"
  },
  {
    "text": "that will be a too easy tail. So what you usually\nwant to do is you want to pick a tail that\nis of the same type, but wrong.",
    "start": "1389610",
    "end": "1397380"
  },
  {
    "text": "So if I'm going from\ncountry capital-- sorry, country\ncapital and the city,",
    "start": "1397380",
    "end": "1404520"
  },
  {
    "text": "then I want the wrong tail\nto be a different city. I don't want the wrong\ntail to be a chocolate bar.",
    "start": "1404520",
    "end": "1412259"
  },
  {
    "text": "That won't work, it's too easy. So you want to be\nkind of careful how you do this negative\nexamples sampling.",
    "start": "1412260",
    "end": "1417870"
  },
  {
    "text": "But this is basically, in\nsome sense, great question. How do we handle\ntransitive relations?",
    "start": "1417870",
    "end": "1424505"
  },
  {
    "text": "If you have a brother, then\nhe's also your brother, but the vector only\npoints in one direction. Great question. So the question is how do we\nhandle transitive relations.",
    "start": "1424505",
    "end": "1432790"
  },
  {
    "text": "Let me get to that. We said we are going\nto fill in that table. That's exactly the question\nI want to address next.",
    "start": "1432790",
    "end": "1438690"
  },
  {
    "text": "What is this able\nto learn and where it's clearly going to fail?",
    "start": "1438690",
    "end": "1444509"
  },
  {
    "text": "Now, what we want to talk\nabout is exactly what the question was about.",
    "start": "1444510",
    "end": "1449549"
  },
  {
    "text": "Relationship in\nheterogeneous graphs have different properties. Some may be symmetric like\na brother or a roommate.",
    "start": "1449550",
    "end": "1456910"
  },
  {
    "text": "I'm your roommate, you\nare also my roommate, it has to be that way\nif we are roommates.",
    "start": "1456910",
    "end": "1463150"
  },
  {
    "text": "Some may have inverse relations. If I am your advisor,\nyou are my advisee.",
    "start": "1463150",
    "end": "1471940"
  },
  {
    "text": "It's that way. This means that if one exists,\nthe other one should also",
    "start": "1471940",
    "end": "1477400"
  },
  {
    "text": "exist. So we can categorize this\ntype of relationship patterns and ask our knowledge\ngraph embedding method,",
    "start": "1477400",
    "end": "1485860"
  },
  {
    "text": "like a TransE, is it\nable expressive enough to capture this\ntype of patterns?",
    "start": "1485860",
    "end": "1493030"
  },
  {
    "text": "Now, what patterns of\nrelations are we interested in? And here are the\nfour I'll talk about.",
    "start": "1493030",
    "end": "1498769"
  },
  {
    "text": "First one is symmetric or\nantisymmetric relations that says if head and tail\nare related by relationship r,",
    "start": "1498770",
    "end": "1507730"
  },
  {
    "text": "and then tail and\nhead should also be related by relationship r. So this is like, if\nI'm your brother,",
    "start": "1507730",
    "end": "1514429"
  },
  {
    "text": "you are my brother as well. Antisymmetric means,\nif h is related to t,",
    "start": "1514430",
    "end": "1521450"
  },
  {
    "text": "then t cannot be related by\nh using the same relation. Then you have inverse\nrelations, which",
    "start": "1521450",
    "end": "1528500"
  },
  {
    "text": "would mean that this is\nlike advisor-advisee type, where whenever h\nis an advisor of t,",
    "start": "1528500",
    "end": "1535880"
  },
  {
    "text": "then t is an advisee of h. That's what we say\nan inverse relation.",
    "start": "1535880",
    "end": "1542720"
  },
  {
    "text": "Then we have composition\nor transitive relations, where you say, if x and\ny are related by r1 and y",
    "start": "1542720",
    "end": "1549950"
  },
  {
    "text": "and z are related by r2, then x\nand z should be related by r3.",
    "start": "1549950",
    "end": "1556850"
  },
  {
    "text": "If you think of this, it's\nlike if I'm someone's son",
    "start": "1556850",
    "end": "1562370"
  },
  {
    "text": "and that person is someone\nelse's daughter, then",
    "start": "1562370",
    "end": "1567680"
  },
  {
    "text": "that person is either my\ngrandmother or something like that. I think I didn't see it well,\nbut you see what I mean.",
    "start": "1567680",
    "end": "1573770"
  },
  {
    "text": "It's like based on relationship,\nthe third one is determined. That's what we say composition\nof relationships or transitive",
    "start": "1573770",
    "end": "1582090"
  },
  {
    "text": "relations. And then the last one is\nthis 1-to-N relations, where you can have a case where\nthe same head is in relation",
    "start": "1582090",
    "end": "1592190"
  },
  {
    "text": "with many different tails. So it could be a case that\nI can have more than--",
    "start": "1592190",
    "end": "1597200"
  },
  {
    "text": "I can have more than\none brother so there could be many tails that\nsatisfy this relation.",
    "start": "1597200",
    "end": "1602870"
  },
  {
    "text": "Yes. This composition assume\none order for operations",
    "start": "1602870",
    "end": "1608270"
  },
  {
    "text": "because your\nhusband's mother won't be the same as your\nmother's husband. No, this assumes order.",
    "start": "1608270",
    "end": "1615289"
  },
  {
    "text": "This assumes order. So let's now look what\nTransE allows me to do.",
    "start": "1615290",
    "end": "1621970"
  },
  {
    "text": "Is it able to give me to\nmodel antisymmetric relations like hypernym type relations?",
    "start": "1621970",
    "end": "1630520"
  },
  {
    "text": "It can allow me-- it\nallows me to do that. If h is in relation with t,\nthen t cannot be in the same",
    "start": "1630520",
    "end": "1638800"
  },
  {
    "text": "relation with r. So this is what this\nallows me to do.",
    "start": "1638800",
    "end": "1647680"
  },
  {
    "text": "It also allows me to model\ninverse relations, by basically saying, if h is\nrelated to t, then",
    "start": "1647680",
    "end": "1654190"
  },
  {
    "text": "t can be related to h according\nto this other relation. It's just a vector pointing\nin the opposite direction.",
    "start": "1654190",
    "end": "1660710"
  },
  {
    "text": "So that I can also do. I can also do\ncomposition by saying,",
    "start": "1660710",
    "end": "1667600"
  },
  {
    "text": "if I can go from x to y by\nr1 and from y to z by r2,",
    "start": "1667600",
    "end": "1673120"
  },
  {
    "text": "then I can also learn a\nrelation that goes directly from one to the other.",
    "start": "1673120",
    "end": "1678560"
  },
  {
    "text": "So these things are\nnaturally composable.",
    "start": "1678560",
    "end": "1685910"
  },
  {
    "text": "This is in terms-- my mother's husband is my\nfather or something like that.",
    "start": "1685910",
    "end": "1692240"
  },
  {
    "text": "This is what we can model. But here's an\nexample of a relation",
    "start": "1692240",
    "end": "1699980"
  },
  {
    "text": "that TransE is\nnot able to learn, like a symmetric relation,\nlike family, roommate, brother,",
    "start": "1699980",
    "end": "1705500"
  },
  {
    "text": "and so on. Then, I cannot model\nsymmetric relations, the only way to model them is to\nembed h and t to the same spot",
    "start": "1705500",
    "end": "1713990"
  },
  {
    "text": "and have r equal to zero, then\nh plus r equals t and t plus r",
    "start": "1713990",
    "end": "1721550"
  },
  {
    "text": "equals h. That's the only way\nthis would be possible. So we say that you cannot\nmodel symmetric relations with",
    "start": "1721550",
    "end": "1731120"
  },
  {
    "text": "TransE. So that's one issue.",
    "start": "1731120",
    "end": "1736260"
  },
  {
    "text": "And then another issue is\nthat TransE can also not model 1-to-N relations when\nit's one to many relations.",
    "start": "1736260",
    "end": "1744850"
  },
  {
    "text": "Because the only way to model\none to many would be that, again, t1 and t2 have to be\nembedded at the same dot--",
    "start": "1744850",
    "end": "1753820"
  },
  {
    "text": "at the same spot. So there is no distinction\nbetween these two entities. You only move in one direction\nand you cannot do this",
    "start": "1753820",
    "end": "1764950"
  },
  {
    "text": "because t1 and t2 will be\nmapped into the same vector, even though they are\ndifferent entities.",
    "start": "1764950",
    "end": "1770590"
  },
  {
    "text": "These are the reasons what\nTransE can do and what TransE",
    "start": "1770590",
    "end": "1778210"
  },
  {
    "text": "cannot do. Based on these intuitions\nfailures of TransE,",
    "start": "1778210",
    "end": "1787360"
  },
  {
    "text": "I'll now show you\na different method that people have\ninvented that will allow",
    "start": "1787360",
    "end": "1792580"
  },
  {
    "text": "us to fix some of these issues. So now we completed the\nfirst line of that table",
    "start": "1792580",
    "end": "1799370"
  },
  {
    "text": "and we are now moving\nto the second line of the table, which is the\napproach that is called TransR.",
    "start": "1799370",
    "end": "1806900"
  },
  {
    "text": "The way TransE\nmodels translation of any relation in the\nsame embedding space.",
    "start": "1809940",
    "end": "1816630"
  },
  {
    "text": "The question is, can we design\na new space for each relation and do the translation in the\nrelationship-specific space?",
    "start": "1816630",
    "end": "1824760"
  },
  {
    "text": "That's what TransR tries to do. TransR is going\nto model entities",
    "start": "1824760",
    "end": "1830130"
  },
  {
    "text": "as vectors in the entity\nspace, but model each relation as a vector in the\nrelation space, where",
    "start": "1830130",
    "end": "1842760"
  },
  {
    "text": "r will be k dimensional.",
    "start": "1842760",
    "end": "1848340"
  },
  {
    "text": "We will actually going to\nhave then a matrix that is going to map from\nthis k dimensional space",
    "start": "1848340",
    "end": "1856350"
  },
  {
    "text": "back into the d dimensional\nspace in which the entities are",
    "start": "1856350",
    "end": "1861780"
  },
  {
    "text": "embedded. So we are going to have\nthis projection matrix. That's the idea for TransR.",
    "start": "1861780",
    "end": "1868830"
  },
  {
    "text": "TransR are models entities as\nvectors in the entity space that is d dimensional\nand models each relation",
    "start": "1868830",
    "end": "1874740"
  },
  {
    "text": "as a vector in the\nrelation space with m sub r",
    "start": "1874740",
    "end": "1879809"
  },
  {
    "text": "being this projection matrix\nthat is relation-specific.",
    "start": "1879810",
    "end": "1885610"
  },
  {
    "text": "So the scoring\nfunction, so the way we are going to measure the\ndistance between head and tail",
    "start": "1885610",
    "end": "1895350"
  },
  {
    "text": "for a given relationship\nr is the following. We are going to apply a\nrelation-specific projection",
    "start": "1895350",
    "end": "1906929"
  },
  {
    "text": "to the entity h, that's\nwhy I have it here. We are going to apply the same\nprojection to the entity t,",
    "start": "1906930",
    "end": "1915960"
  },
  {
    "text": "and then we are going to move\naccording to the vector r. Here, basically,\nfor every relation,",
    "start": "1915960",
    "end": "1922470"
  },
  {
    "text": "we are allowed to linearly\nmore of the space in a relation",
    "start": "1922470",
    "end": "1932549"
  },
  {
    "text": "specific way. The idea is that, maybe the\nentities in the original space",
    "start": "1932550",
    "end": "1939270"
  },
  {
    "text": "are embedded this way, but\nthen our projection matrix is going to embed\nthem differently.",
    "start": "1939270",
    "end": "1944470"
  },
  {
    "text": "And then the relation\nembedding vector will tell me how to move\nfrom head to the tail.",
    "start": "1944470",
    "end": "1950549"
  },
  {
    "text": "That's the idea. Here, I'm learning three things. I'm learning the\nembeddings of entities,",
    "start": "1950550",
    "end": "1958080"
  },
  {
    "text": "I'm learning the\nrelation vector r, and I'm learning the projection\nmatrix for every relation.",
    "start": "1958080",
    "end": "1965440"
  },
  {
    "text": "That's the idea. Now, let's reason about\nwhat this is going.",
    "start": "1965440",
    "end": "1972970"
  },
  {
    "text": "And just maybe in terms\nof how do I learn this, I basically use-- this\nis my objective function.",
    "start": "1972970",
    "end": "1980019"
  },
  {
    "text": "It's analogous to the TransE\none, where we had the same, we said the distance between h\nplus r and t has to be small.",
    "start": "1980020",
    "end": "1990789"
  },
  {
    "text": "But in this case,\nin this case, I'm using this projection matrix. So it's essentially the\nsame objective function",
    "start": "1990790",
    "end": "1997570"
  },
  {
    "text": "that I'm trying\nto optimize, just that I add a matrix M as\npart of the learning as well.",
    "start": "1997570",
    "end": "2005015"
  },
  {
    "text": "Now, what is interesting\nis that, in this case, I may actually be able to\nmodel symmetric relationships",
    "start": "2007580",
    "end": "2016190"
  },
  {
    "text": "because TransR will allow me\nto do this because the matrix",
    "start": "2016190",
    "end": "2021799"
  },
  {
    "text": "M will allow me to map\nfrom the two entities, from the space of entities to\nthe same spot in the relation",
    "start": "2021800",
    "end": "2033260"
  },
  {
    "text": "specific space. So this means that we can map\nh and t to the same location",
    "start": "2033260",
    "end": "2038930"
  },
  {
    "text": "in the space of relation\nr, and h and t are still",
    "start": "2038930",
    "end": "2044300"
  },
  {
    "text": "different entities in\nthe original space. So I can learn this\ntype of mapping,",
    "start": "2044300",
    "end": "2051230"
  },
  {
    "text": "and I will be able to handle\nsymmetric relations, something",
    "start": "2051230",
    "end": "2056480"
  },
  {
    "text": "that TransE was not able to do. I am also able to handle\nantisymmetric relations.",
    "start": "2056480",
    "end": "2065239"
  },
  {
    "text": "This is actually the same\nas in the TransE can do, where I can learn\na projection that",
    "start": "2065239",
    "end": "2073559"
  },
  {
    "text": "will keep the entities\napart, so I won't be able to come back to it.",
    "start": "2073560",
    "end": "2080190"
  },
  {
    "text": "So that's the same as what\nTransE was able to do. Now, how about 1 to N relations.",
    "start": "2080190",
    "end": "2088290"
  },
  {
    "text": "One to many relations\nmeans that one entity is related to many\nother entities",
    "start": "2088290",
    "end": "2093780"
  },
  {
    "text": "according to the same relation. Again, TransR will\nbe able to do this",
    "start": "2093780",
    "end": "2101740"
  },
  {
    "text": "because we can learn\nthis projection matrix so that different targets,\ndifferent tails get",
    "start": "2101740",
    "end": "2109090"
  },
  {
    "text": "mapped to the same point. So the idea is, if\nin my original space I'll have h, t1 and\nt2, it's possible",
    "start": "2109090",
    "end": "2118540"
  },
  {
    "text": "to learn a projection matrix\nthat maps both of them to the same point. So in this relation space, now I\nsaid aha from h according to r,",
    "start": "2118540",
    "end": "2128710"
  },
  {
    "text": "there's multiple entities here. Even though in\nthe original space for some other\nrelationship, I'm still able to distinguish\nthese entities.",
    "start": "2128710",
    "end": "2135320"
  },
  {
    "text": "Yes. Can you make a generalized claim\nthat if an embedding method can",
    "start": "2135320",
    "end": "2140380"
  },
  {
    "text": "handle symmetric relations, then\nit can handle 1-to-N relations?",
    "start": "2140380",
    "end": "2146609"
  },
  {
    "text": "So the question was, can\nyou make a general claim that if a method can handle\nsymmetric-- sorry, symmetric",
    "start": "2146610",
    "end": "2154260"
  },
  {
    "text": "relations, then it can\nhandle one to many relations. I don't think so.",
    "start": "2154260",
    "end": "2161130"
  },
  {
    "text": "My answer would be no. But for a proof, maybe\nwe can talk after the--",
    "start": "2161130",
    "end": "2170230"
  },
  {
    "text": "Good. Thank you for the question. Yes. Why do we use just a linear\ntransformation from the entity",
    "start": "2170230",
    "end": "2175440"
  },
  {
    "text": "space to the relation? Why don't we do like\nan MLP or something? Good question. So the question is, why are we\nusing a linear transformation?",
    "start": "2175440",
    "end": "2183480"
  },
  {
    "text": "Why wouldn't we do a\nnonlinear transformation?",
    "start": "2183480",
    "end": "2189030"
  },
  {
    "text": "I guess you could. I mean, I think you would learn\nan MLP that would basically",
    "start": "2196130",
    "end": "2202520"
  },
  {
    "text": "take these coordinates and\nlearn how to transform them.",
    "start": "2202520",
    "end": "2208142"
  },
  {
    "text": "I'm trying to come\nup with a reason why that would be a bad idea.",
    "start": "2208142",
    "end": "2210935"
  },
  {
    "text": "It's a good question. My sense, does anyone see\nwhy this would be a bad idea?",
    "start": "2215500",
    "end": "2221898"
  },
  {
    "text": "Competition expensive you mean? Yeah, I don't know. We could see whether this\nis possible to learn now you",
    "start": "2221898",
    "end": "2227329"
  },
  {
    "text": "are learning one separate MLP.",
    "start": "2227330",
    "end": "2229985"
  },
  {
    "text": "It will be a very\ncomplicated learning loop because you will learn the\nembeddings of entities, then you will want\nto learn the MLP,",
    "start": "2232790",
    "end": "2239660"
  },
  {
    "text": "you will want to learn the r. So it's a good question whether\nthis will work in practice.",
    "start": "2239660",
    "end": "2247069"
  },
  {
    "text": "But if somebody gives you an MLP\nthat works and the embeddings, there's no problem with that.",
    "start": "2247070",
    "end": "2253700"
  },
  {
    "text": "Good question. It'd be fun to try. Cool.",
    "start": "2253700",
    "end": "2259460"
  },
  {
    "text": "So this is one to many. And then in terms of\ninverse relations, again, this is easy to\nsee because TransR is just",
    "start": "2259460",
    "end": "2270320"
  },
  {
    "text": "a generalization of TransE. So if the projection matrix\nis for two relations,",
    "start": "2270320",
    "end": "2276319"
  },
  {
    "text": "two inverse relations\nis the same, then, basically,\none relation vector",
    "start": "2276320",
    "end": "2282030"
  },
  {
    "text": "is an inverse of the\nother relation vector. And you get this the same\nway we got it in TransE.",
    "start": "2282030",
    "end": "2290910"
  },
  {
    "text": "And then, the last\nthing to discuss is this composition\nof relations. And the way,\nperhaps, to see this",
    "start": "2290910",
    "end": "2299640"
  },
  {
    "text": "is that I'll give\nyou some visual proof for high-level intuition\nwhy this is possible.",
    "start": "2299640",
    "end": "2306099"
  },
  {
    "text": "And the idea is that\nTransR models a triple with linear functions,\nwhich are chainable.",
    "start": "2306100",
    "end": "2312000"
  },
  {
    "text": "Linear functions are composable,\nso everything will work. That's the high-level intuition.",
    "start": "2312000",
    "end": "2320310"
  },
  {
    "text": "Here, I have a longer proof that\nmaybe in the interest of time",
    "start": "2320310",
    "end": "2327600"
  },
  {
    "text": "that I spent at the\nbeginning talking about last year's lecture\nthat was slightly different,",
    "start": "2327600",
    "end": "2333940"
  },
  {
    "text": "I will skip. But the way you can\ndo this is, first, you need to define this\nkernel space of a matrix.",
    "start": "2333940",
    "end": "2342030"
  },
  {
    "text": "And then you can say, what\nis composition of relations if x and y are\nrelated with r1 and y",
    "start": "2342030",
    "end": "2350010"
  },
  {
    "text": "and z by r2, then I want to show\nthat y and z according to r3",
    "start": "2350010",
    "end": "2356340"
  },
  {
    "text": "is possible. And basically, you\nstart writing it out according to our linear algebra\nwith this projection matrices.",
    "start": "2356340",
    "end": "2363870"
  },
  {
    "text": "And then that will-- and then you can basically\ndefine or come up",
    "start": "2367080",
    "end": "2372930"
  },
  {
    "text": "with the answer that,\nbecause these matrices are linear operators, you\ncan chain them and get",
    "start": "2372930",
    "end": "2380250"
  },
  {
    "text": "the correct answer at the end. Yes. [INAUDIBLE] vector spaces,\nlike the space of entities",
    "start": "2380250",
    "end": "2386900"
  },
  {
    "text": "and the space of relations. And all these rules are\nexamining injective,",
    "start": "2386900",
    "end": "2392060"
  },
  {
    "text": "subjective, or bijective. Can you view it that way?",
    "start": "2392060",
    "end": "2396080"
  },
  {
    "text": "Can you ask again? If it's too-- so basically,\nthe space of entities is Rt,",
    "start": "2399680",
    "end": "2405470"
  },
  {
    "text": "the space of relations is Rk,\nso it's just two vector spaces. Correct. So therefore, we're looking\nat composition of linear maps.",
    "start": "2405470",
    "end": "2414110"
  },
  {
    "text": "Exactly. It's a composition of linear\nmaps across these two vector spaces. So then, if it's\n1-to-N, that would",
    "start": "2414110",
    "end": "2420230"
  },
  {
    "text": "be looking at if\nsomething is subjective, then we can think about\ninjective or if it's bijective.",
    "start": "2420230",
    "end": "2425810"
  },
  {
    "text": "Correct. That's maybe another way to say\nit is that, basically, you have two vector spaces, one\nis a d-dimensional,",
    "start": "2425810",
    "end": "2432810"
  },
  {
    "text": "and I think the other one\nwe said is a k-dimensional. You are basically learning\nat looking at compositions",
    "start": "2432810",
    "end": "2439430"
  },
  {
    "text": "across these two, and you are\nlooking at this, as you said, bijective, subjective, or\ninjective relationships",
    "start": "2439430",
    "end": "2446900"
  },
  {
    "text": "across the space. So that be related to\nthe earlier two questions about what earlier\nour friend asked.",
    "start": "2446900",
    "end": "2455210"
  },
  {
    "text": "If it's 1-to-N but it also be\nsymmetric, that would mean, just because it's\nsubjective, it doesn't",
    "start": "2455210",
    "end": "2460470"
  },
  {
    "text": "mean it could be bijective. Exactly. Well, that answer this\nquestion as well about the MLP",
    "start": "2460470",
    "end": "2465869"
  },
  {
    "text": "because we're looking at linear\ncomposition maps between, therefore, you\ncan't use them all.",
    "start": "2465870",
    "end": "2471910"
  },
  {
    "text": "Exactly. That's a great point. Actually, I was thinking\nof exactly the same.",
    "start": "2471910",
    "end": "2476970"
  },
  {
    "text": "Great observation, actually. So when your MLP\nwould break is here.",
    "start": "2476970",
    "end": "2482670"
  },
  {
    "text": "You would lose composition\nof relations with the MLP.",
    "start": "2482670",
    "end": "2488309"
  },
  {
    "text": "So that's the place\nit could break. Great part. Exactly. Exactly.",
    "start": "2488310",
    "end": "2493349"
  },
  {
    "text": "Cool. Good. I continue. So this was our second\nmethod that's called TransR",
    "start": "2493350",
    "end": "2501839"
  },
  {
    "text": "and defines these\ntwo vector spaces and maps these projection\nmatrices from one to the other.",
    "start": "2501840",
    "end": "2510970"
  },
  {
    "text": "What I want to do next is\ntalk about the third method in this space called\nthis DistMult.",
    "start": "2510970",
    "end": "2523440"
  },
  {
    "text": "The idea behind this notion\nof bilinear modeling. So far, our scoring function\nwas just Euclidean distance",
    "start": "2523440",
    "end": "2532020"
  },
  {
    "text": "or it was an L2 or L2\ndistance between the embedding",
    "start": "2532020",
    "end": "2537090"
  },
  {
    "text": "of the hat comma relation and\nthe embedding of the target and we wanted to\nminimize that distance.",
    "start": "2537090",
    "end": "2544770"
  },
  {
    "text": "Another line of work\nthat is a bit different is trying to adopt what is\ncalled bilinear modeling.",
    "start": "2544770",
    "end": "2552300"
  },
  {
    "text": "In DistMult, entities\nand relations are using vectors in Rk,\nbut the scoring function",
    "start": "2552300",
    "end": "2560460"
  },
  {
    "text": "that measures the distance\nbetween the head and tail according to the relation R\nwill have the following form,",
    "start": "2560460",
    "end": "2568530"
  },
  {
    "text": "where you are going\nto basically go over the individual coordinates\nof h, r, and t,",
    "start": "2568530",
    "end": "2575220"
  },
  {
    "text": "multiply them together,\nand sum them up. So the way you can\nthink of this is",
    "start": "2575220",
    "end": "2582390"
  },
  {
    "text": "that, basically, you have the\nhead, you have a relation-- you have a head and a\ntail, you have a relation,",
    "start": "2582390",
    "end": "2589480"
  },
  {
    "text": "you multiply these things\ntogether, coordinate-wise, and sum them up, and\nthat is your score.",
    "start": "2589480",
    "end": "2595540"
  },
  {
    "text": "So now, we defined the\ndifferent scoring function. And we are still\ngoing to have a head",
    "start": "2595540",
    "end": "2602560"
  },
  {
    "text": "relation and a tail\nembedding as we had it in TransE, just the scoring\nfunction is now different.",
    "start": "2602560",
    "end": "2612130"
  },
  {
    "text": "The intuition for\nthe scoring function is that it can be viewed as\na cosine similarity between h",
    "start": "2612130",
    "end": "2619359"
  },
  {
    "text": "times r and t,\nwhere, in our case, h times r would be defined as a\nsummation of h sub i and r sub",
    "start": "2619360",
    "end": "2633250"
  },
  {
    "text": "i. So the idea would\nbe that, basically, if you have your target t2\nand you have your target t1,",
    "start": "2633250",
    "end": "2646500"
  },
  {
    "text": "then you can basically think\nof this vector h times r.",
    "start": "2646500",
    "end": "2657240"
  },
  {
    "text": "And when you multiply\nit with t, that's basically coordinate-wise\nmultiplication and a summation.",
    "start": "2657240",
    "end": "2668849"
  },
  {
    "text": "So that's the way\nto think of this. Let's now look at what\nDistMult allows you to do.",
    "start": "2668850",
    "end": "2679020"
  },
  {
    "text": "So let's first look at\none to many relations. So here, I have head, relation,\ntail 1, head, relation, tail 2.",
    "start": "2679020",
    "end": "2689150"
  },
  {
    "text": "Can DistMult model this? It basically can because it\ncan put a tail 1 and tail 2",
    "start": "2689150",
    "end": "2700960"
  },
  {
    "text": "in such a way that basically\nthe cosine distance between these vectors\nwill be equal.",
    "start": "2700960",
    "end": "2713710"
  },
  {
    "text": "So that's the first thing. The second thing is to go and\nask about symmetric relations.",
    "start": "2713710",
    "end": "2723010"
  },
  {
    "text": "Here, this is, again, this\nbrother type relation. The way DistMult\ncan naturally do",
    "start": "2723010",
    "end": "2733060"
  },
  {
    "text": "this is because, basically,\nour scoring function is",
    "start": "2733060",
    "end": "2739210"
  },
  {
    "text": "the same regardless\nof head and tail. So basically,\nmultiplication is the order",
    "start": "2739210",
    "end": "2749110"
  },
  {
    "text": "in which I multiply numbers. It doesn't matter. So I'll get the same score if\nI'm scoring head, relation, t,",
    "start": "2749110",
    "end": "2755920"
  },
  {
    "text": "or if I'm scoring\ntail, relation, head. So I will naturally get that.",
    "start": "2755920",
    "end": "2762069"
  },
  {
    "text": "Of course, because\nI get this property, I then cannot get the\nantisymmetric property",
    "start": "2762070",
    "end": "2768819"
  },
  {
    "text": "because DistMult cannot model\nantisymmetric relations. Because the score\nof head, relation,",
    "start": "2768820",
    "end": "2775960"
  },
  {
    "text": "tail is the same as score\nof tail, relation, head. This means the score\nof head and tail",
    "start": "2775960",
    "end": "2787810"
  },
  {
    "text": "and the score of\ntail and relation will always be the same. So you cannot\ndistinguish the two.",
    "start": "2787810",
    "end": "2795700"
  },
  {
    "text": "So you cannot say, if head\nis in relation with tail, then tail cannot be in\nthe same relation with r.",
    "start": "2795700",
    "end": "2803530"
  },
  {
    "text": "It will always be\nsymmetric, it won't be able to capture this\ntype of antisymmetry.",
    "start": "2803530",
    "end": "2811150"
  },
  {
    "text": "And then the same thing\nis with inverse relations, where you would want to be\nable to enforce relationships",
    "start": "2811150",
    "end": "2819460"
  },
  {
    "text": "with where if head is in\nrelation r2 with tail, then tail is in relation\nof r1 with the head.",
    "start": "2819460",
    "end": "2828099"
  },
  {
    "text": "And again, because of this\nargument on the previous slide, DistMult won't be able to\nmodel this type of relations",
    "start": "2828100",
    "end": "2835100"
  },
  {
    "text": "because if it does\nmodel inverse relations, then it would mean that r1 and\nr2 have to be the same vector.",
    "start": "2835100",
    "end": "2845020"
  },
  {
    "text": "But semantically, this\ndoes not make sense because embedding of advisor\nshouldn't be the same",
    "start": "2845020",
    "end": "2851710"
  },
  {
    "text": "or should be different than\nthe embedding of the advisee.",
    "start": "2851710",
    "end": "2856839"
  },
  {
    "text": "That's what I wanted to\nsay about modeling inverse relations. And the last thing\nI want to address",
    "start": "2856840",
    "end": "2863589"
  },
  {
    "text": "is the notion of\ncomposition of relations. So here, the question\nis, can DistMult",
    "start": "2863590",
    "end": "2870850"
  },
  {
    "text": "learn patterns where\nthis r1 composition or transitive relations?",
    "start": "2870850",
    "end": "2876910"
  },
  {
    "text": "The intuition here is that\nDistMult defines a hyperplane for each head, relation pair,\nand the union of hyperplanes",
    "start": "2876910",
    "end": "2885960"
  },
  {
    "text": "induced by the multi-hop\nrelationship across multiple relations cannot be expressed\nas a single hyperplane.",
    "start": "2885960",
    "end": "2895260"
  },
  {
    "text": "So you cannot compose these\nhyperplanes step by step",
    "start": "2895260",
    "end": "2902910"
  },
  {
    "text": "and maintain the hyperplane. So you won't be able to learn\nthese compositions where you can go or transitivities\nacross relationships.",
    "start": "2902910",
    "end": "2914370"
  },
  {
    "text": "I have a detailed\nderivation here as well,",
    "start": "2918060",
    "end": "2926130"
  },
  {
    "text": "where, basically,\nwhat we are going-- what you are basically able to\nshow is that the composition",
    "start": "2926130",
    "end": "2936450"
  },
  {
    "text": "of two relationship cannot\nbe expressed using a single",
    "start": "2936450",
    "end": "2943050"
  },
  {
    "text": "hyperplane. And the detailed derivation\nwould go in the following way",
    "start": "2943050",
    "end": "2948450"
  },
  {
    "text": "that we would pick some\ny, such that the scoring function of x, y according to\nrelation 1 is greater than 0.",
    "start": "2948450",
    "end": "2959550"
  },
  {
    "text": "For example, let's call\nthis y2, and then we are going to say that then\ny2 times some other relation",
    "start": "2959550",
    "end": "2967470"
  },
  {
    "text": "R is going to define\nthe new hyperplane. And then we will\nbe observing what",
    "start": "2967470",
    "end": "2976110"
  },
  {
    "text": "is happening as we\nnow pick another, in our case, another y, such\nthat the relation y and that y",
    "start": "2976110",
    "end": "2986549"
  },
  {
    "text": "is greater than zero,\nlet's call this y3. And then y times the relation 2\nwill define the new hyperplane.",
    "start": "2986550",
    "end": "2999880"
  },
  {
    "text": "Then, basically, now if you\nhave the two hyperplanes defined by y2 and y3.",
    "start": "2999880",
    "end": "3006270"
  },
  {
    "text": "And now combining them\ntogether for all z's",
    "start": "3006270",
    "end": "3014250"
  },
  {
    "text": "that are in this shadow area.",
    "start": "3014250",
    "end": "3017820"
  },
  {
    "text": "The question is,\ndoes there exist y between these y2 and y3,\nsuch that the score of y",
    "start": "3021020",
    "end": "3028460"
  },
  {
    "text": "and z according to the relation\n2 is greater than zero?",
    "start": "3028460",
    "end": "3039650"
  },
  {
    "text": "What you are going to\nfind is that, basically, you cannot find such a case\nwhere this would be possible.",
    "start": "3039650",
    "end": "3057170"
  },
  {
    "text": "A way to look at it is\nthat, basically, according to the composition\nof relations, we",
    "start": "3057170",
    "end": "3062810"
  },
  {
    "text": "would also want the score\naccording now to r3, between x and z, to be greater\nthan zero for every z",
    "start": "3062810",
    "end": "3072800"
  },
  {
    "text": "that is in this shadow area. But this inherently cannot be\ndone or expressed as a single",
    "start": "3072800",
    "end": "3081690"
  },
  {
    "text": "hyperplane defined by x and\nr3 no matter what r3 is.",
    "start": "3081690",
    "end": "3088950"
  },
  {
    "text": "So basically, this means\nthat, in DistMult, you are not able to express\na transitive relations.",
    "start": "3088950",
    "end": "3100200"
  },
  {
    "text": "This is quite interesting\nbecause DistMult, as I'm going to show you later,\nin some knowledge graphs,",
    "start": "3100200",
    "end": "3107880"
  },
  {
    "text": "it works really well. So it becomes a good\nquestion, what kind of method",
    "start": "3107880",
    "end": "3115200"
  },
  {
    "text": "to apply to a given domain or\nto a given knowledge graph? Yes, a question.",
    "start": "3115200",
    "end": "3120420"
  },
  {
    "text": "The key difference\nbetween this method we're learning in\nTransR and TransE seems to be the\nscoring function.",
    "start": "3120420",
    "end": "3126630"
  },
  {
    "text": "And that's seems\nthen to imply why we can't have this\ncomposition, why there's a limitation to composition.",
    "start": "3126630",
    "end": "3132030"
  },
  {
    "text": "Is there a way to pick\na scoring method, such that it has many of the\nbeneficial properties of this",
    "start": "3132030",
    "end": "3138870"
  },
  {
    "text": "without the drawback of\ncomposition being unavailable? Great.",
    "start": "3138870",
    "end": "3143910"
  },
  {
    "text": "It's a good-- first, I'll\nrepeat your question and also your observation.",
    "start": "3143910",
    "end": "3149530"
  },
  {
    "text": "So observation is\nthat, basically, what we are doing here, this\nis very similar to our TransE",
    "start": "3149530",
    "end": "3156810"
  },
  {
    "text": "method. We are learning an\nembedding of every entity and every relation.",
    "start": "3156810",
    "end": "3161910"
  },
  {
    "text": "But what we changed was\nthe scoring function. In the TransE, our\nscoring function was the distance\nbetween h plus r and t.",
    "start": "3161910",
    "end": "3170310"
  },
  {
    "text": "Here, our scoring\nfunction is this product and some of these coordinates.",
    "start": "3170310",
    "end": "3175829"
  },
  {
    "text": "And because we changed\nthe scoring function, we get certain\nproperties for free while",
    "start": "3175830",
    "end": "3182400"
  },
  {
    "text": "losing other properties. As I think you are going to see\nat the end in the final table,",
    "start": "3182400",
    "end": "3189210"
  },
  {
    "text": "it's actually the TransR that\nchecks the most of those check marks, where we were learning\nthis projection matrices",
    "start": "3189210",
    "end": "3196620"
  },
  {
    "text": "between the two vector spaces. That's what I would\nsay about this.",
    "start": "3196620",
    "end": "3202800"
  },
  {
    "text": "Yes. Third question. We were talking today mostly\nabout the transductive setting for most of this learning.",
    "start": "3202800",
    "end": "3208440"
  },
  {
    "text": "But, let's say, in\nreal world application, we saw these are massive,\nmassive, massive, massive networks. So don't we want to\nbasically find a method",
    "start": "3208440",
    "end": "3215160"
  },
  {
    "text": "that we can do on a\nsmall part of the network so we can generalize? So let's say, TransR,\nwe'll need the matrix",
    "start": "3215160",
    "end": "3221610"
  },
  {
    "text": "for all of these\nentries, so that would be a non-computationally\nfeasible matrix.",
    "start": "3221610",
    "end": "3227220"
  },
  {
    "text": "Good question. So the question is these\nmethods are transductive.",
    "start": "3227220",
    "end": "3232589"
  },
  {
    "text": "It means we have to learn an\nembedding for every entity separately. Won't these be\ncomputationally expensive?",
    "start": "3232590",
    "end": "3240550"
  },
  {
    "text": "The answer is yes. I would say from--",
    "start": "3240550",
    "end": "3246070"
  },
  {
    "text": "the one reason why\ntransductive is OK is because these graphs, we\ndon't think of them as dynamic,",
    "start": "3246070",
    "end": "3252039"
  },
  {
    "text": "we don't think of this as data,\nwe think of this as knowledge in some sense. And the set of entities is\nfixed, the set of relationships",
    "start": "3252040",
    "end": "3260710"
  },
  {
    "text": "is also fixed, and you are\ntrying to infer, let's say, the edges. You are trying to embed\nthe entities according",
    "start": "3260710",
    "end": "3268450"
  },
  {
    "text": "to the relationships\nin which they are.",
    "start": "3268450",
    "end": "3275349"
  },
  {
    "text": "Actually, in terms\nof scalability, this is challenging, but\nit's not that challenging.",
    "start": "3275350",
    "end": "3281650"
  },
  {
    "text": "Because you can\ndistribute these entities across different machines. And there is a very nice\npackage open sourced",
    "start": "3281650",
    "end": "3289780"
  },
  {
    "text": "by Facebook called Big Graph. If you just Google\nthat on GitHub, you can basically\nget a system that",
    "start": "3289780",
    "end": "3297910"
  },
  {
    "text": "will allow you to embed\nessentially arbitrary knowledge graphs. And internally,\nFacebook, let's say,",
    "start": "3297910",
    "end": "3304210"
  },
  {
    "text": "was using this\ntype of technology to embed all the entities\nin their knowledge graph",
    "start": "3304210",
    "end": "3311170"
  },
  {
    "text": "and use that for\nrecommendations. So people have put immense\nresources and energy",
    "start": "3311170",
    "end": "3316930"
  },
  {
    "text": "to be able to scale this\nup to the Facebook scale, and then they open source.",
    "start": "3316930",
    "end": "3322300"
  },
  {
    "text": "So you can do this\nand a lot of people, when they want to start\nplaying in industrial settings with graph machine\nlearning use cases,",
    "start": "3322300",
    "end": "3330079"
  },
  {
    "text": "the first thing would be to\nuse this Big Graph package. That's on Facebook.",
    "start": "3330080",
    "end": "3336700"
  },
  {
    "text": "On GitHub. Cool. Does that answer the question? OK, great. Thank you.",
    "start": "3336700",
    "end": "3342039"
  },
  {
    "text": "Super. Now, the last method\ntoday, and then we wrap up.",
    "start": "3342040",
    "end": "3348640"
  },
  {
    "text": "This method that I\nwant to talk today, the last one is called ComplEx.",
    "start": "3348640",
    "end": "3352255"
  },
  {
    "text": "It's based on this\nDisMult, but ComplEx is going to embed entities and\nrelations in the ComplEx vector",
    "start": "3355330",
    "end": "3362680"
  },
  {
    "text": "space. So not in the real,\nbut in the ComplEx. So now, the way you\ncan think of this",
    "start": "3362680",
    "end": "3370360"
  },
  {
    "text": "and what you are getting when\nyou are in the ComplEx space, you get this notion of\nthe complex conjugate.",
    "start": "3370360",
    "end": "3378250"
  },
  {
    "text": "If I have a point with\na complex embedding that",
    "start": "3378250",
    "end": "3383320"
  },
  {
    "text": "has the real and\nthe imaginary axis, then there is also exists a\nconjugate of that point, where,",
    "start": "3383320",
    "end": "3392710"
  },
  {
    "text": "basically, if I had before a\nplus bi, now I have a minus bi.",
    "start": "3392710",
    "end": "3400599"
  },
  {
    "text": "That's what you get here\nwhen you think about ComplEx",
    "start": "3400600",
    "end": "3408010"
  },
  {
    "text": "arithmetics and trying to think\nabout how would I embed things in the ComplEx space.",
    "start": "3408010",
    "end": "3413710"
  },
  {
    "text": "Here, the way we\nthink of this is u is a point in\nthe ComplEx space.",
    "start": "3413710",
    "end": "3419829"
  },
  {
    "text": "And the way the position of\nit is defined in two ways is defined by the\nembedding of a and it's",
    "start": "3419830",
    "end": "3428470"
  },
  {
    "text": "defined by the embedding of\nb and both are k-dimensional.",
    "start": "3428470",
    "end": "3433599"
  },
  {
    "text": "So that's the way\nto think of this. But of course, what is\ngoing to work differently",
    "start": "3433600",
    "end": "3442210"
  },
  {
    "text": "is now the scoring function. And the way the scoring\nfunction is going to work",
    "start": "3442210",
    "end": "3448080"
  },
  {
    "text": "is that, now, when I'm\ndoing my scoring function,",
    "start": "3448080",
    "end": "3453480"
  },
  {
    "text": "it's going to be\ndefined this way. So I'm going to\nmultiply h and r, but I'm going to multiply\nthat with the conjugate of t.",
    "start": "3453480",
    "end": "3462119"
  },
  {
    "text": "And then whatever\nis the result, I'm only going to take\nthe real part of that",
    "start": "3462120",
    "end": "3467910"
  },
  {
    "text": "and that will be my example of\nthe score for a given relation,",
    "start": "3467910",
    "end": "3474089"
  },
  {
    "text": "head, and the tail. That's the idea of how\nComplEx is going to work.",
    "start": "3474090",
    "end": "3483690"
  },
  {
    "text": "Now, let's go and look what\nthis will allow us to model. First, let's look at\nantisymmetric relations.",
    "start": "3483690",
    "end": "3494010"
  },
  {
    "text": "The claim is that ComplEx can\nmodel antisymmetric relations.",
    "start": "3494010",
    "end": "3499830"
  },
  {
    "text": "The idea is that the\nmodel is expressive enough to be able to learn a high value\nof the scoring function when",
    "start": "3499830",
    "end": "3511680"
  },
  {
    "text": "you are multiplying h\nand the conjugate of t,",
    "start": "3511680",
    "end": "3516809"
  },
  {
    "text": "and a low value of the function\nwhere you are multiplying t with the conjugate of h.",
    "start": "3516810",
    "end": "3524910"
  },
  {
    "text": "Due to the symmetric modeling\nof using complex conjugate.",
    "start": "3524910",
    "end": "3532109"
  },
  {
    "text": "This means that we will be able\nto model ComplEx relationships.",
    "start": "3532110",
    "end": "3540270"
  },
  {
    "text": "How about symmetric\nrelationships, roommate brother, and so on?",
    "start": "3540270",
    "end": "3545430"
  },
  {
    "text": "You are able to do that as well. Here, I have a bit of algebra.",
    "start": "3545430",
    "end": "3551880"
  },
  {
    "text": "So you are asking, what's\nthe score of r, h, and t, and is that the same as\nthe score of r, t, and h?",
    "start": "3551880",
    "end": "3560730"
  },
  {
    "text": "The way you can derive\nthis is to say, oh,",
    "start": "3560730",
    "end": "3566300"
  },
  {
    "text": "this is the real\nof this product, you can take the\nproduct out, you",
    "start": "3566300",
    "end": "3574070"
  },
  {
    "text": "can then take an r,\nwhich is a real vector,",
    "start": "3574070",
    "end": "3582500"
  },
  {
    "text": "and just take the real of the\nh and t, which are complex.",
    "start": "3582500",
    "end": "3590510"
  },
  {
    "text": "If you do it this way, then you\ncan move the conjugate from t",
    "start": "3590510",
    "end": "3599840"
  },
  {
    "text": "to h as well, and then\nbasically expand it back to get to the scoring\nfunction of t comma h.",
    "start": "3599840",
    "end": "3608750"
  },
  {
    "text": "So the key step is this\nstep where you basically is the equivalence\nfrom here to here,",
    "start": "3608750",
    "end": "3615859"
  },
  {
    "text": "and then it's just\nexpanding it back to what the scoring function is.",
    "start": "3615860",
    "end": "3621980"
  },
  {
    "text": "So this is for showing\nsymmetric relations.",
    "start": "3621980",
    "end": "3627080"
  },
  {
    "text": "Last, what is\ninteresting about ComplEx is that you can also\ndo inverse relations.",
    "start": "3627080",
    "end": "3633500"
  },
  {
    "text": "And the way you can\ndo inverse relations is that r1 is just\na conjugate of r--",
    "start": "3633500",
    "end": "3642619"
  },
  {
    "text": "is a complex conjugate of r2.",
    "start": "3642620",
    "end": "3647780"
  },
  {
    "text": "The idea here is in this-- when we talked about cosine\ndistance or cosine similarity",
    "start": "3647780",
    "end": "3656960"
  },
  {
    "text": "where 90 degrees is\nexactly the angle at which",
    "start": "3656960",
    "end": "3662859"
  },
  {
    "text": "things are at the\nmaximum distance. And that's why this\nis the case here.",
    "start": "3662860",
    "end": "3670540"
  },
  {
    "text": "If you think about-- if you go\nback to my original picture, the angle between these\ntwo vectors, vectors of u",
    "start": "3670540",
    "end": "3678160"
  },
  {
    "text": "and the conjugate of\nu, is also 90 degrees. And the dot product\nbetween these two guys",
    "start": "3678160",
    "end": "3685330"
  },
  {
    "text": "will be zero, if you think\nof it in the Euclidean way.",
    "start": "3685330",
    "end": "3692050"
  },
  {
    "text": "So that that's the reason\nabout inverse relations. Then, the last\nthing I want to talk",
    "start": "3692050",
    "end": "3698170"
  },
  {
    "text": "is about composition as well\nas one to many relations.",
    "start": "3698170",
    "end": "3705099"
  },
  {
    "text": "Here, basically, I can just say\nthat ComplEx shares the same property with DistMult. You\ncannot model compositional",
    "start": "3705100",
    "end": "3713109"
  },
  {
    "text": "relations and you cannot model\none to many relations using it.",
    "start": "3713110",
    "end": "3718180"
  },
  {
    "text": "Now, to bring everything\ntogether and summarize it, here is a one slide\nsummary of today's lecture",
    "start": "3718180",
    "end": "3723770"
  },
  {
    "text": "of different methods. How do these methods differ? These methods differ on how\nthe embedding is determined.",
    "start": "3723770",
    "end": "3731720"
  },
  {
    "text": "Is it determined-- are\nthe embedding h, t, and r in the real space,\nthis was in TransE.",
    "start": "3731720",
    "end": "3739880"
  },
  {
    "text": "In TransR, we had h,\nt, and r embedded--",
    "start": "3739880",
    "end": "3744883"
  },
  {
    "text": "actually, h and t were\nembedded in d-dimensional, r was embedded in d-dimensional.",
    "start": "3747440",
    "end": "3753800"
  },
  {
    "text": "And then we had the\nprojection matrix that mapped from the entity\nspace to the relation space.",
    "start": "3753800",
    "end": "3760490"
  },
  {
    "text": "And then for\nDistMult and ComplEx. In DistMult, we\nused the embeddings",
    "start": "3760490",
    "end": "3767809"
  },
  {
    "text": "that were in the reals. For ComplEx, we\nuse the embeddings that were in the\ncomplex space, and then",
    "start": "3767810",
    "end": "3773450"
  },
  {
    "text": "the scoring functions we\nwere using were different. For TransE, it's a\nsimple, let's say, here,",
    "start": "3773450",
    "end": "3781070"
  },
  {
    "text": "Euclidean distance,\nthe L2 norm between hat plus relation minus tail. So basically, the distance\nbetween the head plus relation",
    "start": "3781070",
    "end": "3789170"
  },
  {
    "text": "and the tail. In the TransR, we had these\nprojection matrices involved,",
    "start": "3789170",
    "end": "3794360"
  },
  {
    "text": "but it's still, let's\nsay, Euclidean distance. In DistMult, we defined this\nnotion of cosine distance.",
    "start": "3794360",
    "end": "3804130"
  },
  {
    "text": "And in ComplEx, we changed\nfurther the definition, we adopted the DistMult distance\nfunction, but added the--",
    "start": "3804130",
    "end": "3812504"
  },
  {
    "text": "we extended it in\nthe following way. And then what was\ndifferent is that we",
    "start": "3815230",
    "end": "3820270"
  },
  {
    "text": "looked at these symmetric,\nantisymmetric, inverse, composite, or also called\ntransitive relations,",
    "start": "3820270",
    "end": "3826450"
  },
  {
    "text": "and one to many relations. And this is how\ndifferent methods compare to what they are\nable to what relations",
    "start": "3826450",
    "end": "3835210"
  },
  {
    "text": "they are able to model. That's what I wanted to say. And I'm also going to have a few\nmore slides with practical tips",
    "start": "3835210",
    "end": "3845170"
  },
  {
    "text": "but, I'm happy now\nto take questions. I had a question about the\nantisymmetric case for ComplEx.",
    "start": "3845170",
    "end": "3853390"
  },
  {
    "text": "Is there a ComplEx conjugate\ninterpretation or proving",
    "start": "3853390",
    "end": "3858400"
  },
  {
    "text": "that that one works? I just felt like full\nsymmetric [INAUDIBLE],, that was a really nice complex\nconjugate interpretation.",
    "start": "3858400",
    "end": "3865350"
  },
  {
    "text": "But I didn't get that\nantisymmetric case.",
    "start": "3865350",
    "end": "3871790"
  },
  {
    "text": "Good point. Why don't we then go\nback and look at it together after the lecture?",
    "start": "3871790",
    "end": "3877130"
  },
  {
    "text": "OK, good. Anything else people\nwould like to ask?",
    "start": "3877130",
    "end": "3880085"
  },
  {
    "text": "If not, let me just a\nfew more things to say.",
    "start": "3883680",
    "end": "3889319"
  },
  {
    "text": "In practice, I gave\nyou these methods, and you are like, it's clear\nwhat I should be using, it has all the check\nmarks, beautiful.",
    "start": "3889320",
    "end": "3897720"
  },
  {
    "text": "It seems DistMult, you\nshouldn't really be using, has the most captures the least\nof these properties and so on.",
    "start": "3897720",
    "end": "3905650"
  },
  {
    "text": "But actually, the real world\nis a bit more complicated.",
    "start": "3905650",
    "end": "3911309"
  },
  {
    "text": "And it actually turns out that\ndifferent knowledge graphs will have very different,\ndrastically different relation",
    "start": "3911310",
    "end": "3918780"
  },
  {
    "text": "patterns, relations with\ndifferent properties. So generally, there\nis not one best",
    "start": "3918780",
    "end": "3925349"
  },
  {
    "text": "embedding that works for all\ndifferent knowledge graphs.",
    "start": "3925350",
    "end": "3933270"
  },
  {
    "text": "So many times, it's good to\nactually go into the knowledge graph, see what are the types\nof relationships you have,",
    "start": "3933270",
    "end": "3939480"
  },
  {
    "text": "try to quantify them,\nunderstand them, and then choose your method.",
    "start": "3939480",
    "end": "3945850"
  },
  {
    "text": "What people like to use is\nusually first run TransE because it's so\nsimple and so easy,",
    "start": "3945850",
    "end": "3951250"
  },
  {
    "text": "it's the easiest to learn,\nthe easiest to make stable.",
    "start": "3951250",
    "end": "3956750"
  },
  {
    "text": "It's the very natural, very\ninterpretable, very easy to try. So people would usually\nstart with TransE,",
    "start": "3956750",
    "end": "3964900"
  },
  {
    "text": "and then you can move\nto more complex models",
    "start": "3964900",
    "end": "3974299"
  },
  {
    "text": "like ComplEx, RotatE,\nDistMult, and so on.",
    "start": "3974300",
    "end": "3982310"
  },
  {
    "text": "TransE is going to\nwork well, especially if your graph doesn't have\ntoo many symmetric relations.",
    "start": "3982310",
    "end": "3992480"
  },
  {
    "text": "So to summarize\ntoday's lecture, we talked about link prediction\nor knowledge graph completion",
    "start": "3992480",
    "end": "4000460"
  },
  {
    "text": "as one of the important tasks\nin this field of knowledge graph embeddings.",
    "start": "4000460",
    "end": "4006519"
  },
  {
    "text": "We talked about definition\nof a knowledge graph and how knowledge\ngraphs are being",
    "start": "4006520",
    "end": "4012040"
  },
  {
    "text": "used to serve information,\nbut that knowledge graphs are extremely incomplete.",
    "start": "4012040",
    "end": "4019570"
  },
  {
    "text": "And people usually\nwant to complete them, make them more robust.",
    "start": "4019570",
    "end": "4024940"
  },
  {
    "text": "What is also a very useful\nway to use a knowledge graph is that you can use it as a\nscaffold for some external",
    "start": "4024940",
    "end": "4032690"
  },
  {
    "text": "nodes to connect to it,\nand then learn a GNN that goes between\nyour data graph",
    "start": "4032690",
    "end": "4038630"
  },
  {
    "text": "and between your\nbackground knowledge graph. This is especially very useful\nin biomedical applications,",
    "start": "4038630",
    "end": "4045410"
  },
  {
    "text": "where you have the background\nbiomedical knowledge graph of your biological entities.",
    "start": "4045410",
    "end": "4051200"
  },
  {
    "text": "But maybe, then, you\nhave a patient node that links to different\nparts of the knowledge graph.",
    "start": "4051200",
    "end": "4056570"
  },
  {
    "text": "And then you can start\nthinking about learning, let's say, GNNs that are\ngoing to go from patient down",
    "start": "4056570",
    "end": "4062990"
  },
  {
    "text": "to the knowledge graph,\npropagate across the knowledge graph, and go back\nto the patient and do this triangular\ninformation passing.",
    "start": "4062990",
    "end": "4070220"
  },
  {
    "text": "And that's a very effective\nway how you can, let's say, reason about patients by\nexploiting the background",
    "start": "4070220",
    "end": "4078512"
  },
  {
    "text": "knowledge, the\nbackground knowledge graph that you have\nabout human biology.",
    "start": "4078512",
    "end": "4083630"
  },
  {
    "text": "That's maybe one way to\nthink about is that knowledge graphs are very helpful,\neither to serve information,",
    "start": "4083630",
    "end": "4091640"
  },
  {
    "text": "and then you want to use these\nembeddings to complete them. Sometimes people apply\nthis knowledge graph",
    "start": "4091640",
    "end": "4097189"
  },
  {
    "text": "embedding techniques also\nto their data graphs. I mentioned the\nexample of Facebook,",
    "start": "4097189",
    "end": "4103278"
  },
  {
    "text": "and the Big Graph\npackage they developed. But I think when\nthese things work also",
    "start": "4103279",
    "end": "4109370"
  },
  {
    "text": "really well is when you\nbring your data entities and connect them with your\nknowledge graph entities.",
    "start": "4109370",
    "end": "4116810"
  },
  {
    "text": "This example of patients and\nunderlying biomedical knowledge",
    "start": "4116810",
    "end": "4122930"
  },
  {
    "text": "graphs being an example. Today, we talked about-- the lecture today\nwas quite dense,",
    "start": "4122930",
    "end": "4131028"
  },
  {
    "text": "and we talked about\nfour different methods, TransE that's easy and natural.",
    "start": "4131029",
    "end": "4136520"
  },
  {
    "text": "We talked about TransR that's\na bit more advanced but based on the same intuition.",
    "start": "4136520",
    "end": "4142220"
  },
  {
    "text": "And then DistMult\nand ComplEx that changed this scoring function.",
    "start": "4142220",
    "end": "4148020"
  },
  {
    "text": "And they all use different\nembedding spaces, and they have different\nexpressiveness.",
    "start": "4148020",
    "end": "4155540"
  },
  {
    "text": "So this is what I\nwanted to show today. And then next week\non Tuesday, I'm actually going to enrich\nthis notion of how",
    "start": "4155540",
    "end": "4166759"
  },
  {
    "text": "do I link prediction\nin knowledge graphs, and we'll talk about these\nmulti-hop link prediction,",
    "start": "4166760",
    "end": "4172278"
  },
  {
    "text": "or basically being able\nto reason and answer arbitrary queries over\nincomplete knowledge graph.",
    "start": "4172279",
    "end": "4178770"
  },
  {
    "text": "So we will be given a knowledge\ngraph and a logical query. And the question will be, can\nwe find all the entities that",
    "start": "4178770",
    "end": "4185750"
  },
  {
    "text": "satisfy that logical query? That's what we are going\nto learn about on Tuesday.",
    "start": "4185750",
    "end": "4192859"
  },
  {
    "text": "Let's finish here. But if people have\nquestions, please come here and we can talk.",
    "start": "4192859",
    "end": "4198000"
  },
  {
    "text": "Thank you so much.",
    "start": "4198000",
    "end": "4199930"
  }
]
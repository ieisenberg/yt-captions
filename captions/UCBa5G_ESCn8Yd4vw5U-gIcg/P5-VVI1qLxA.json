[
  {
    "start": "0",
    "end": "5880"
  },
  {
    "text": "So last time we have talked\nabout covering number. So covering number is a upper\nbound for the Rademacher",
    "start": "5880",
    "end": "11910"
  },
  {
    "text": "complexity. And then our goal is to\nbound covering numbers because this is a new tool\nfor bounding the Rademacher",
    "start": "11910",
    "end": "18630"
  },
  {
    "text": "complexity. And we have discussed what\nother bounds are linear models-- I didn't show any of\nthe proofs, but there",
    "start": "18630",
    "end": "24900"
  },
  {
    "text": "are some existing bounds which\nare 20 years old actually. And then we also talk about the\nLipschitz composition landmark",
    "start": "24900",
    "end": "33790"
  },
  {
    "text": "for covering numbers,\nwhich is much easier than the corresponding\nlevel of a Rademacher",
    "start": "33790",
    "end": "41320"
  },
  {
    "text": "complexity. So basically, if you\nknow a function class has good covering number bounds\nand then you compose it",
    "start": "41320",
    "end": "47927"
  },
  {
    "text": "with the Lipschitz\nfunction, then you still have a reasonable\ncovering number bounds.",
    "start": "47928",
    "end": "53650"
  },
  {
    "text": "So that's the general idea. And then, today\nwe're going to talk",
    "start": "53650",
    "end": "58660"
  },
  {
    "text": "about deep neural networks. ",
    "start": "58660",
    "end": "65120"
  },
  {
    "text": "And we are going to\nuse some of these tools because you can see that a\ndeep net is actually composed",
    "start": "65120",
    "end": "70750"
  },
  {
    "text": "of multiple linear models\nwith some of the Lipschitz functions, right--\ntheir activations.",
    "start": "70750",
    "end": "76340"
  },
  {
    "text": "So this is the goal\nof this lecture.",
    "start": "76340",
    "end": "81829"
  },
  {
    "text": "So let me set up-- actually sorry,\ngive me one moment. I think I probably have to\nchange the mask because I'm",
    "start": "81830",
    "end": "89230"
  },
  {
    "text": "always having the fog. I don't know what\nhappens with this mask.",
    "start": "89230",
    "end": "94882"
  },
  {
    "text": "Let's change one.  Maybe there's some\ndeficiency with the mask.",
    "start": "94882",
    "end": "101615"
  },
  {
    "start": "101615",
    "end": "123570"
  },
  {
    "text": "OK, let's continue. So we have a neural network.",
    "start": "123570",
    "end": "129819"
  },
  {
    "text": "So the setup is that we have\nsome neural network that's called h theta. Theta is used to denote\na set of parameters",
    "start": "129820",
    "end": "137790"
  },
  {
    "text": "and we have r layers. So the network looks like this.",
    "start": "137790",
    "end": "142930"
  },
  {
    "text": "So that last layer we\ndon't have any activation, and then you have some\nactivation in the next layer,",
    "start": "142930",
    "end": "148319"
  },
  {
    "text": "you get r minus 1. Something like this. ",
    "start": "148320",
    "end": "155110"
  },
  {
    "text": "So basically if you do the\nordering of the math formula-- so you first multiply x with\nW1 and then you pass through",
    "start": "155110",
    "end": "163140"
  },
  {
    "text": "a nonlinearity and\nthen you multiply W2-- and you do this so and so\nforth, and you have r layers.",
    "start": "163140",
    "end": "169740"
  },
  {
    "text": "This is the network. So there are r layers\nand wi are the weights.",
    "start": "169740",
    "end": "176047"
  },
  {
    "text": " And the kind of bound that we're\ngoing to talk about is that--",
    "start": "176047",
    "end": "184812"
  },
  {
    "text": "so here is the theorem.  Assume xi 2 norm is\nless than c and consider",
    "start": "184812",
    "end": "197950"
  },
  {
    "text": "a family of networks is that\nh theta with some norm control",
    "start": "197950",
    "end": "203650"
  },
  {
    "text": "of the weights. So we consider the operator norm\nof the weights to be kappa i-- ",
    "start": "203650",
    "end": "213090"
  },
  {
    "text": "kappa i. And we can show the 2 to 1\nnorm of Wi transpose to be bi.",
    "start": "213090",
    "end": "222780"
  },
  {
    "text": "And then suppose you control\nyour complex function class like this, then\nthe Rademacher complexity",
    "start": "222780",
    "end": "229360"
  },
  {
    "text": "will be less than-- up to a constant factor c\nover square root n times",
    "start": "229360",
    "end": "238860"
  },
  {
    "text": "the product of kappa\ni times the sum of--",
    "start": "238860",
    "end": "245230"
  },
  {
    "text": "this is a complex formula. Let me explain it in a moment-- i from 1 to r 3 over 2.",
    "start": "245230",
    "end": "253168"
  },
  {
    "start": "253168",
    "end": "259680"
  },
  {
    "text": "Alternatively as a corollary,\nI guess this is not necessarily",
    "start": "259680",
    "end": "267900"
  },
  {
    "text": "that formal because you have\nto talk about what exactly this is. You have to have some\nfailure probabilities.",
    "start": "267900",
    "end": "274889"
  },
  {
    "text": "But roughly speaking, you are\nsaying that the generalization error is less than O tilde\n1 over the margin times 1",
    "start": "274890",
    "end": "283655"
  },
  {
    "text": "over square root of n times\nc sometimes the product",
    "start": "283655",
    "end": "293220"
  },
  {
    "text": "of the operator norm\ntimes the [INAUDIBLE]..",
    "start": "293220",
    "end": "301138"
  },
  {
    "start": "301138",
    "end": "307010"
  },
  {
    "text": "I guess here I'm using the--  times the norm.",
    "start": "307010",
    "end": "312640"
  },
  {
    "start": "312640",
    "end": "320950"
  },
  {
    "text": "This is a little bit-- anyway, so basically\nthe important thing",
    "start": "320950",
    "end": "326050"
  },
  {
    "text": "here is that the complexity\nmeasure depends on few things. One thing is that operator\nnorm of the weight matrix.",
    "start": "326050",
    "end": "334380"
  },
  {
    "text": "And it depends on the\noperator norm as a product. So in the complexity\nterm, it shows",
    "start": "334380",
    "end": "339870"
  },
  {
    "text": "the product of the operator\nnorm of all the weights shows up in the complexity. And also there is this\nterm, which basically you",
    "start": "339870",
    "end": "347700"
  },
  {
    "text": "can think of this as a\npolynomial in kappa i and bi. So this you can in\nsome sense think",
    "start": "347700",
    "end": "354720"
  },
  {
    "text": "of this as a polynomial\nof kappa i and bi, which is not really important.",
    "start": "354720",
    "end": "359950"
  },
  {
    "text": "So as long as it's\npolynomial for us, it's not that important because\nthe product of the operator",
    "start": "359950",
    "end": "365819"
  },
  {
    "text": "norm probably will be\nthe dominating term. And the polynomial in bi the\nkappa i probably are somewhat--",
    "start": "365820",
    "end": "373116"
  },
  {
    "text": "and it will be relatively small. So we don't necessarily\nhave to care about exactly",
    "start": "373116",
    "end": "378870"
  },
  {
    "text": "what this 2/3 means. Actually, they don't\nhave any special meaning. It's really just something\nthat comes out of the proof.",
    "start": "378870",
    "end": "385350"
  },
  {
    "text": "But as long there\nare polynomials, we are relatively happy with it. And so basically this\nis the important term.",
    "start": "385350",
    "end": "393180"
  },
  {
    "text": "And this term, if you\nlook at the bound, it comes from the\nLipschitzness of the model. So kappa i is the bound\non the Lipschitzness",
    "start": "393180",
    "end": "401430"
  },
  {
    "text": "of a single layer. And the product of kappa i\nis the bound on Lipschitzness of the product of all layers.",
    "start": "401430",
    "end": "407955"
  },
  {
    "start": "407955",
    "end": "413009"
  },
  {
    "text": "So without any details,\nI think this term, you can imagine this comes\nfrom some Lipschitzness",
    "start": "413010",
    "end": "418950"
  },
  {
    "text": "composition, some use of\nLipschitz composition. What is the thing right\nabove the x in the expression",
    "start": "418950",
    "end": "425504"
  },
  {
    "text": "[INAUDIBLE]?  This is assumption? Sorry.",
    "start": "425505",
    "end": "430770"
  },
  {
    "text": "Just the symbol that you\nwrote right above the x. This is i. Oh, you assume that\nit's true for every i.",
    "start": "430770",
    "end": "437172"
  },
  {
    "text": "I think this can be\nrelaxed a little bit. But, again, it's\nnot very important. So you can maybe relax it\nto be the average of xi",
    "start": "437172",
    "end": "442840"
  },
  {
    "text": "is less than c. It's not super important. What is the operator norm?",
    "start": "442840",
    "end": "448960"
  },
  {
    "text": "Oh, right, so that's\na-- yeah, sorry. So the operator norm is the-- I guess maybe I didn't--",
    "start": "448960",
    "end": "454900"
  },
  {
    "text": "so this is also the spectral\nnorm, also the largest single-- so this is the spectral norm\nof the largest singular value,",
    "start": "454900",
    "end": "470488"
  },
  {
    "text": "if any of this\nmakes sense to you.  And also the formal definition\nis just that the max over x 2.",
    "start": "470488",
    "end": "487260"
  },
  {
    "text": "So I guess I called operating\nnorm just because this is the-- if you think about\nw as operator,",
    "start": "487260",
    "end": "493020"
  },
  {
    "text": "then this is saying that,\nhow does this operator change your norm, right? So if you give it\na 2 norm vector,",
    "start": "493020",
    "end": "498990"
  },
  {
    "text": "then how does it\nchange the norm? Yeah. So, OK, cool.",
    "start": "498990",
    "end": "507110"
  },
  {
    "text": "So and you can see that\nthis is kind of like a-- Lipschitzness, this\nis also-- maybe I should expand\nthis a little bit.",
    "start": "507110",
    "end": "513799"
  },
  {
    "text": "So this is also about\nthe Lipschitzness",
    "start": "513799",
    "end": "518849"
  },
  {
    "text": "of this, the linear\nmodel wx, right, because if you care\nabout the Lipschitzness, what you have to verify?",
    "start": "518850",
    "end": "524520"
  },
  {
    "text": "You have to verify\nthat wx minus wy is less than some constant\ntimes x minus y.",
    "start": "524520",
    "end": "532450"
  },
  {
    "text": "And what that constant should\nbe, so if you prove inequality, then you're going to get the\noperator norm, a spectral norm",
    "start": "532450",
    "end": "542399"
  },
  {
    "text": "of w there. So that's why this corresponds\nto the Lipschitzness of the linear model.",
    "start": "542400",
    "end": "548100"
  },
  {
    "text": " Any other questions?",
    "start": "548100",
    "end": "554120"
  },
  {
    "text": " OK, cool, so by the way, I\nhaven't got any questions",
    "start": "554120",
    "end": "562839"
  },
  {
    "text": "from Zoom for a long time. So you should feel\nfree to ask questions. You don't have to, but of course\nfeel free to unmute yourself.",
    "start": "562840",
    "end": "571885"
  },
  {
    "text": " OK, so how do we prove this? ",
    "start": "571885",
    "end": "580100"
  },
  {
    "text": "So the fundamental idea-- yeah, so in the next\n30 minutes, we're going to talk about this proof.",
    "start": "580100",
    "end": "586550"
  },
  {
    "text": "The fundamental idea\nis that you somewhat",
    "start": "586550",
    "end": "591950"
  },
  {
    "text": "cover function set iteratively,\nso cover this set of functions",
    "start": "591950",
    "end": "602370"
  },
  {
    "text": "f iteratively.  And iteratively means that\nyou cover more and more layers",
    "start": "602370",
    "end": "610840"
  },
  {
    "text": "gradually. ",
    "start": "610840",
    "end": "618100"
  },
  {
    "text": "And how do you do\nthis iteratively? You have to use the\nLipschitzness and sometimes",
    "start": "618100",
    "end": "624530"
  },
  {
    "text": "the Lipschitz composition\nlemma that we have discussed. And also you want\nto also control--",
    "start": "624530",
    "end": "633410"
  },
  {
    "text": "and also controlling how\nthe error propagates. ",
    "start": "633410",
    "end": "646300"
  },
  {
    "text": "So that's a high-level summary. It's kind of abstract, but\nlet me tap into the details.",
    "start": "646300",
    "end": "653630"
  },
  {
    "text": "So for simplicity, let's also\nkind of try to abstractify-- ",
    "start": "653630",
    "end": "661220"
  },
  {
    "text": "so for each layer of f, f as fi.",
    "start": "661220",
    "end": "668649"
  },
  {
    "text": "So, basically, fi corresponds\nto a linear multiplication,",
    "start": "668650",
    "end": "676540"
  },
  {
    "text": "a matrix multiplication\nplus an activation layer. ",
    "start": "676540",
    "end": "682760"
  },
  {
    "text": "All right, so this\nis a one layer. And then you can write f. Then you can consider f\nas this composition of fr",
    "start": "682760",
    "end": "689949"
  },
  {
    "text": "with fr minus 1, so\nand so forth, right? So basically for every layer\nyou have certain choices.",
    "start": "689950",
    "end": "695750"
  },
  {
    "text": "You can choose\nyour weight matrix. And then you compose all\nof this function class. By this composition\nI guess we have used",
    "start": "695750",
    "end": "702250"
  },
  {
    "text": "this notation multiple times. This is really\njust means that you are looking at fr composed with\nfr minus 1 composed f1, where",
    "start": "702250",
    "end": "712340"
  },
  {
    "text": "each fi is from the\nfamily of capital Fi. ",
    "start": "712340",
    "end": "720370"
  },
  {
    "text": "So this abstraction\nwill allow us to have much cleaner notations.",
    "start": "720370",
    "end": "726850"
  },
  {
    "text": "But, fundamentally,\nyou can usually just think of each of the\nfi's as a layer, right?",
    "start": "726850",
    "end": "733269"
  },
  {
    "text": "And what we know is that-- ",
    "start": "733270",
    "end": "738930"
  },
  {
    "text": "so suppose maybe, let's say--  so for the sake\nof preparation, so",
    "start": "738930",
    "end": "746310"
  },
  {
    "text": "suppose for every f in fi, fi--\nin f beta fi in capital Fi,",
    "start": "746310",
    "end": "754880"
  },
  {
    "text": "fi is kappa i Lipschitz. This is actually the case\nfor us because we restricted",
    "start": "754880",
    "end": "760580"
  },
  {
    "text": "the spectral norm\nof-- or the operating norm of each of the wi's\nto be less than kappa i.",
    "start": "760580",
    "end": "765995"
  },
  {
    "text": "That means that every\nlayer is kappa i Lipschitz. And the ReLU is 1 Lipschitz.",
    "start": "765995",
    "end": "771769"
  },
  {
    "text": "So even you compose\nwith activation, it's still kappa i Lipschitz. So suppose each of these\nfunctions is kappa i Lipschitz.",
    "start": "771770",
    "end": "779120"
  },
  {
    "text": "Then you know that fi(x).",
    "start": "779120",
    "end": "784460"
  },
  {
    "text": "So these are just\nsome preparations-- so 2 norm is less than\nkappa i x minus y 2 norm.",
    "start": "784460",
    "end": "792620"
  },
  {
    "text": "And maybe that's just for\nsimplicity suppose f is 0,",
    "start": "792620",
    "end": "802760"
  },
  {
    "text": "is equal to 0. This is also the\ncase, in the real case we care about where you\nhave a neural network.",
    "start": "802760",
    "end": "810680"
  },
  {
    "text": "And also let's suppose that xi\nis less than C. This is also our assumption.",
    "start": "810680",
    "end": "816560"
  },
  {
    "text": "So then with all of this,\nthen you know that-- we know a bunch of basic things.",
    "start": "816560",
    "end": "821580"
  },
  {
    "text": "So, for example, we know that\nyou can bound, what's this?",
    "start": "821580",
    "end": "829485"
  },
  {
    "text": " What's the multilayer\napplication of xi.",
    "start": "829485",
    "end": "835810"
  },
  {
    "text": "What's the normal-- what's\nthe boundary on the norm here. So the boundary on the\nnorm can be bounded by--",
    "start": "835810",
    "end": "842950"
  },
  {
    "text": "each time you at most\ncapture a kappa i factor. So you get kappa i times kappa\ni minus 1 times kappa i minus 2,",
    "start": "842950",
    "end": "851020"
  },
  {
    "text": "so and so forth, times\nkappa 1 times c, right? ",
    "start": "851020",
    "end": "857690"
  },
  {
    "text": "And we call this ci.",
    "start": "857690",
    "end": "864210"
  },
  {
    "text": "And let's define this\nto be equals to Ci. So basically this is some\nbasic kind of preparation.",
    "start": "864210",
    "end": "871410"
  },
  {
    "text": "So under this\nabstraction, you know some bound on each of the layer. And you know each of\nthe layer is Lipschitz.",
    "start": "871410",
    "end": "877920"
  },
  {
    "text": "And what I'm going\nto do is that we're going to do two things,\nso for two steps.",
    "start": "877920",
    "end": "888590"
  },
  {
    "text": "So, first, you control the\ncover number of each layer,",
    "start": "888590",
    "end": "901976"
  },
  {
    "text": "of each layer. And second, you have\na combination lemma,",
    "start": "901976",
    "end": "910140"
  },
  {
    "text": "you compose this, like\ncombine them together.",
    "start": "910140",
    "end": "915245"
  },
  {
    "text": " So you have a lemma\nthat turns each layer,",
    "start": "915245",
    "end": "920510"
  },
  {
    "text": "so you turn each of the layers. So you have a lemma\nthat turns single-layer covering the number\nbound to multiple layer,",
    "start": "920510",
    "end": "931820"
  },
  {
    "text": "multiple layers. ",
    "start": "931820",
    "end": "940699"
  },
  {
    "text": "And I think number\ntwo is the-- number one is kind of easy\nbecause for number 1 this is just a\nlinear model composed",
    "start": "940700",
    "end": "946190"
  },
  {
    "text": "with Lipschitz activation. By Lipschitz\nactivation, you can just invoke on what we have\ndiscussed last time.",
    "start": "946190",
    "end": "955753"
  },
  {
    "text": "So, basically, the\nimportant thing is that, how do you turn\na single-layer covering number bound into multiple\nlayer covering number bound?",
    "start": "955753",
    "end": "962690"
  },
  {
    "text": "That's basically the main\nthing I'm going to discuss. So let's call this-- there is a lemma that does this.",
    "start": "962690",
    "end": "970040"
  },
  {
    "text": "So under the\nassumption setup above,",
    "start": "970040",
    "end": "978279"
  },
  {
    "text": "and kind of the relatively\nabstract setup above, so",
    "start": "978280",
    "end": "984820"
  },
  {
    "text": "assume that-- suppose you assume for\nevery inputs with l2 norm",
    "start": "984820",
    "end": "1004170"
  },
  {
    "text": "less than ci minus 1-- so these inputs are\nused to define the--",
    "start": "1004170",
    "end": "1009990"
  },
  {
    "text": " used to define Pn, right,\nand L Pn, the metric L2 Pn.",
    "start": "1009990",
    "end": "1022440"
  },
  {
    "text": "So this is the inputs vary\nfor which we are evaluating your covering number. So to define covering number,\nyou have to define the metric,",
    "start": "1022440",
    "end": "1030179"
  },
  {
    "text": "define which empirical\ninputs you're evaluating on. All right, so I'm assuming that\nfor every input of this norm",
    "start": "1030180",
    "end": "1036300"
  },
  {
    "text": "constraint you have\na covering number.  You have a covering\nnumber bound.",
    "start": "1036300",
    "end": "1044140"
  },
  {
    "text": "So you know that epsilon i fi\nL2 Pn is less than some function",
    "start": "1044140",
    "end": "1053610"
  },
  {
    "text": "of this, and Ci minus 1-- some function of the norm and\nsome function of the target",
    "start": "1053610",
    "end": "1058950"
  },
  {
    "text": "radius. So this is just assumption. This is assuming that--\nso basically this is assuming that you have\na single-layer bound,",
    "start": "1058950",
    "end": "1066039"
  },
  {
    "text": "single-layer bound. ",
    "start": "1066040",
    "end": "1074138"
  },
  {
    "text": "So suppose you have a\nsingle-layer covering number bound of this form. And you do have this bound,\nit's just I didn't give you",
    "start": "1074138",
    "end": "1079860"
  },
  {
    "text": "the exact formula, right? So if you instantiate\non a linear model, you are going to get\nsomething like this.",
    "start": "1079860",
    "end": "1085425"
  },
  {
    "text": "This will be something\nlike ci minus 1 squared over epsilon square,\nthe norm of the input",
    "start": "1085425",
    "end": "1091980"
  },
  {
    "text": "squared over epsilon\nsquared, right? So that would be what happens\nwhen you have linear models.",
    "start": "1091980",
    "end": "1097320"
  },
  {
    "text": "But suppose you have this\nsingle-layer covering number bound, then\nthe conclusion",
    "start": "1097320",
    "end": "1103090"
  },
  {
    "text": "is that you can turn this\ninto a multilayer covering number bound. And the form of this\ntranslation is not very clean.",
    "start": "1103090",
    "end": "1111039"
  },
  {
    "text": "But it's like this. So there exists\nthe epsilon cover",
    "start": "1111040",
    "end": "1117529"
  },
  {
    "text": "of Fr composed up\nto F1 for epsilon",
    "start": "1117530",
    "end": "1127730"
  },
  {
    "text": "is equal to the following thing. ",
    "start": "1127730",
    "end": "1146264"
  },
  {
    "text": "[INAUDIBLE] Sorry, one moment,\nlet me finish, OK. ",
    "start": "1146264",
    "end": "1151470"
  },
  {
    "text": "What's the symbol on the right? It's just above epsilon\ni and ci minus 1?",
    "start": "1151470",
    "end": "1156600"
  },
  {
    "text": "Sorry, can you say that again? In any expression of y,\nit is less than something? Sure.",
    "start": "1156600",
    "end": "1161760"
  },
  {
    "text": "What's that symbol? This is g. Epsilon plus g. Yeah, so I'm assuming\na generic thing here.",
    "start": "1161760",
    "end": "1168780"
  },
  {
    "text": "But actually you can-- this is for the abstraction.",
    "start": "1168780",
    "end": "1173802"
  },
  {
    "text": "When you really use\nit for linear models, it's going to be\nsomething like ci minus 1 squared over epsilon y squared.",
    "start": "1173802",
    "end": "1181560"
  },
  {
    "text": "So this is g. ",
    "start": "1181560",
    "end": "1187320"
  },
  {
    "text": "So there is exists an\nepsilon cover such that-- with this size such that\nthe log size is bounded by--",
    "start": "1187320",
    "end": "1199790"
  },
  {
    "text": "the log size of this\ncover is bounded by sum of g of epsilon i ci\nminus 1 and i from 1 to r.",
    "start": "1199790",
    "end": "1213110"
  },
  {
    "text": "So basically if you\nhave a log covering number bound of this\nform for every layer, then you can have a log covering\nnumber bound for this thing.",
    "start": "1213110",
    "end": "1222570"
  },
  {
    "text": "And the bound, just the\nlog covering number just add up a sum. But the tricky thing\nis that it's not like--",
    "start": "1222570",
    "end": "1231590"
  },
  {
    "text": "the cover size also grows. So the cover size also\nadds up in some way,",
    "start": "1231590",
    "end": "1237680"
  },
  {
    "text": "which is a little bit\nkind of complicated. So, basically, your cover\nsize is like multiplied,",
    "start": "1237680",
    "end": "1243830"
  },
  {
    "text": "it's added in some\nway where you also modify some of this kappas,\nwhich are Lipschitzness",
    "start": "1243830",
    "end": "1251240"
  },
  {
    "text": "in some sense. And your covering number\nis also added in somewhere.",
    "start": "1251240",
    "end": "1256919"
  },
  {
    "text": "So this is the fundamental\nmechanism for us to turn a single-layer bound\nto multiple layer bound.",
    "start": "1256920",
    "end": "1261930"
  },
  {
    "text": "Of course I'm going to use\nthis in some way at the end so that we get a final result\nbecause you have to choose",
    "start": "1261930",
    "end": "1268260"
  },
  {
    "text": "what epsilon i's are, right? So eventually what\nyou do is that you are going to choose\nepsilon i's so that you",
    "start": "1268260",
    "end": "1274170"
  },
  {
    "text": "get the desired target radius. And you work out what\nexactly this formula",
    "start": "1274170",
    "end": "1279300"
  },
  {
    "text": "should be for that\nparticular choice of epsilon. ",
    "start": "1279300",
    "end": "1285700"
  },
  {
    "text": "Does that make sense so far? But before doing that, I'm\ngoing to first prove this lemma.",
    "start": "1285700",
    "end": "1291669"
  },
  {
    "text": "And then I'm going to\ndo the derivations. So after you have\nthis, this is the core.",
    "start": "1291670",
    "end": "1297187"
  },
  {
    "text": "After that, this is\njust a choose parameter. So you just choose\nepsilons in some way that is in favor of you and work\nout what is the final bound.",
    "start": "1297187",
    "end": "1304240"
  },
  {
    "text": "OK. ",
    "start": "1304240",
    "end": "1317804"
  },
  {
    "text": "And in some sense, the\ninterpretation of this lemma is that you somehow-- you can add up the covering\nnumber bound, the log covering",
    "start": "1317805",
    "end": "1325120"
  },
  {
    "text": "number bound in this\nway, as long as you pay some additional radius. ",
    "start": "1325120",
    "end": "1331895"
  },
  {
    "text": "OK. So this proof is in some\nsense, in some sense",
    "start": "1331895",
    "end": "1337690"
  },
  {
    "text": "it's actually pretty simple. But the exposition\nrequires some challenge.",
    "start": "1337690",
    "end": "1343990"
  },
  {
    "text": "It's a little bit challenging. So the fundamental\nidea is the following.",
    "start": "1343990",
    "end": "1351390"
  },
  {
    "text": "So we start with\nthis data point. We start with this concatenation\nof n data points, right?",
    "start": "1351390",
    "end": "1358480"
  },
  {
    "text": "So you have n data points. And you map these n data points\nto a set of points, right?",
    "start": "1358480",
    "end": "1364620"
  },
  {
    "text": "This is the Q that\nwe talk about.  I think I need to draw\nthis in a good way",
    "start": "1364620",
    "end": "1375090"
  },
  {
    "text": "so that I have more space. So let's start with-- you start with n points.",
    "start": "1375090",
    "end": "1381049"
  },
  {
    "text": "And you map these n points\ninto a vector of dimension n",
    "start": "1381050",
    "end": "1386400"
  },
  {
    "text": "or maybe actually it's\na matrix of dimension n. So you map this to some space.",
    "start": "1386400",
    "end": "1396039"
  },
  {
    "text": "And each of these point\nhere is the concatenation of f x1 up to f xn.",
    "start": "1396040",
    "end": "1404480"
  },
  {
    "text": "And this is the so-called\nQ, the set of Q, right, that we have\nto cover, right?",
    "start": "1404480",
    "end": "1409970"
  },
  {
    "text": "And you can use multiple\nfunctions f, or you can use f-- any function f1, in f1 to\nmap to a different point.",
    "start": "1409970",
    "end": "1418690"
  },
  {
    "text": "If you choose\ndifferent f1's, you're going to map a different point. And if you just have one\nlayer, what you're going to do",
    "start": "1418690",
    "end": "1423880"
  },
  {
    "text": "is that you're going to\ncover this set Q, right? That's what we do for covering\nnumber for one function,",
    "start": "1423880",
    "end": "1429730"
  },
  {
    "text": "for one family of\nfunctions f1, right? ",
    "start": "1429730",
    "end": "1437250"
  },
  {
    "text": "So then what you\ndo is that you-- I'm just basically\nreviewing what we have done for\ncovering numbers",
    "start": "1437250",
    "end": "1442409"
  },
  {
    "text": "for one family of functions. You create this kind of\nbubbles, so that covers it.",
    "start": "1442410",
    "end": "1450010"
  },
  {
    "text": "So basically you\ncreate these centers.",
    "start": "1450010",
    "end": "1455360"
  },
  {
    "text": "And these are points\nthat are in c. Maybe that's called c1. So let's create a--",
    "start": "1455360",
    "end": "1461750"
  },
  {
    "text": "that's a c1 is\nepsilon 1 cover of f1.",
    "start": "1461750",
    "end": "1469600"
  },
  {
    "text": "This is what that means. And now we are going\nto see, how do we",
    "start": "1469600",
    "end": "1476410"
  },
  {
    "text": "turn this into a cover\nfor f1 composed with f2? So that's the job\nwe are trying to do.",
    "start": "1476410",
    "end": "1482410"
  },
  {
    "text": "And what really going on\nhere is that for every point here in the output space of--",
    "start": "1482410",
    "end": "1492130"
  },
  {
    "text": "so this is-- maybe\nlet's call this Q1, which is the output space of--",
    "start": "1492130",
    "end": "1499540"
  },
  {
    "text": "maybe let's call\nthis thing capital X. So then Q1 is the family of\noutputs where the function has",
    "start": "1499540",
    "end": "1510360"
  },
  {
    "text": "to be chosen from F1, right? What's the composed--\nso how about",
    "start": "1510360",
    "end": "1516090"
  },
  {
    "text": "if you add f to another layer? So what happens is that\nfor every point in Q, Q1, you can apply multiple\ndifferent functions, right?",
    "start": "1516090",
    "end": "1524070"
  },
  {
    "text": "For any functions little\nf2 and capital F2, you can apply it to map to a\nnew point in the new space,",
    "start": "1524070",
    "end": "1532098"
  },
  {
    "text": "to map it to a new point. So you get a-- for\nevery point here, you get a bunch of possible outputs.",
    "start": "1532098",
    "end": "1537570"
  },
  {
    "text": "And for every point here,\nyou get another bunch of possible outputs, all right? So each of these\nnew points could",
    "start": "1537570",
    "end": "1543360"
  },
  {
    "text": "be your image after\napplying two layers, right?",
    "start": "1543360",
    "end": "1548960"
  },
  {
    "text": "So now we are trying to apply-- we're trying to cover\nthis new set of outputs, like Q2 let's say.",
    "start": "1548960",
    "end": "1555140"
  },
  {
    "text": "And how do how do we cover it? So the approach that\nwe are going to take is somewhat, in some\nsense pretty brute force.",
    "start": "1555140",
    "end": "1565740"
  },
  {
    "text": "What you do is you say you want\nto leverage the existing power for capital F1 in some way. So what you do is you say, you\nlook at a center here in c1.",
    "start": "1565740",
    "end": "1576840"
  },
  {
    "text": "And you look at what are\nthe image of this point",
    "start": "1576840",
    "end": "1582929"
  },
  {
    "text": "after applying a second layer. So you get something\nlike this, all right? So this is the set of the image,\nof the output of this point.",
    "start": "1582930",
    "end": "1594570"
  },
  {
    "text": "So maybe let's say, suppose\nthis point is called f1",
    "start": "1594570",
    "end": "1601009"
  },
  {
    "text": "x, which is in c1. Let's call this f1\nprime x, which is in c1.",
    "start": "1601010",
    "end": "1608010"
  },
  {
    "text": "And then you look at all\nthe outputs from f1 prime x. So you get this family of\npoints where you apply f2",
    "start": "1608010",
    "end": "1618860"
  },
  {
    "text": "on f1 prime x, and where f2 can\nbe chosen arbitrarily from f2.",
    "start": "1618860",
    "end": "1625640"
  },
  {
    "text": " And now what we do is that we\ncover this set by a new epsilon",
    "start": "1625640",
    "end": "1636350"
  },
  {
    "text": "cover. So what you do is you say,\nI'm going to cover this",
    "start": "1636350",
    "end": "1642370"
  },
  {
    "text": "with a bunch of things. And what does that mean? That really means that you\nchoose a subset of capital F2",
    "start": "1642370",
    "end": "1650590"
  },
  {
    "text": "and cover-- because here you are ranging\nover all possible functions in F2.",
    "start": "1650590",
    "end": "1656478"
  },
  {
    "text": "So if you're going to\nchoose a cover point, you just say I'm going\nto drop some of them. I choose a subset, a\ndiscretization of capital F2.",
    "start": "1656478",
    "end": "1665590"
  },
  {
    "text": "So that's basically\nthe approach. ",
    "start": "1665590",
    "end": "1671300"
  },
  {
    "text": "And you do this and then you do\nthis for every possible point in c1 and cover them.",
    "start": "1671300",
    "end": "1677520"
  },
  {
    "text": "So basically suppose you have\nanother point in c1 here. And then you look\nat all of this image",
    "start": "1677520",
    "end": "1685760"
  },
  {
    "text": "and you do another set of cover.  And you do this for every\npossible point in c1.",
    "start": "1685760",
    "end": "1692899"
  },
  {
    "text": "And every possible point\nin c1 have induceD a set. And that set can induce a cover.",
    "start": "1692900",
    "end": "1698840"
  },
  {
    "text": "And then you'd take the union\nof all of these variables into-- ",
    "start": "1698840",
    "end": "1705110"
  },
  {
    "text": "and that the union of\nall of these red bubbles becomes a cover for the Q2. For example, suppose you have,\nlet's say, f1 prime prime X",
    "start": "1705110",
    "end": "1715190"
  },
  {
    "text": "here. maybe. I should use a consistent color. ",
    "start": "1715190",
    "end": "1721940"
  },
  {
    "text": "Let's say you have\na f1 prime prime X.",
    "start": "1721940",
    "end": "1727019"
  },
  {
    "text": "And this is mapped to\nthis set of points here. This is the set of all\nf2, f1, prime prime X",
    "start": "1727020",
    "end": "1736929"
  },
  {
    "text": "where f2 is in capital F2. And then create a\ncover for this set",
    "start": "1736930",
    "end": "1742810"
  },
  {
    "text": "so that you can\ndiscretize F2 again. And you take the union of\nall of this right cover,",
    "start": "1742810",
    "end": "1750100"
  },
  {
    "text": "of these red bubbles\nas your cover for Q2. So any questions so far?",
    "start": "1750100",
    "end": "1756820"
  },
  {
    "text": "So formulate, what we\nshould do is the following. ",
    "start": "1756820",
    "end": "1766440"
  },
  {
    "text": "So epsilon 1 and epsilon r\nare the radius on each layer.",
    "start": "1766440",
    "end": "1777669"
  },
  {
    "text": "These are just-- which are TBD. We will choose this in-- I guess in this lab,\nthey are not TBD.",
    "start": "1777670",
    "end": "1783020"
  },
  {
    "text": "They are just\nalready given to you. Eventually you'll choose\nsomething or choose some numbers for them.",
    "start": "1783020",
    "end": "1788630"
  },
  {
    "text": "And then what you do is that c1\nis the epsilon cover, epsilon",
    "start": "1788630",
    "end": "1795500"
  },
  {
    "text": "1 cover of F1. That's easy. And then you say that\nfor every f1 prime in c1,",
    "start": "1795500",
    "end": "1806780"
  },
  {
    "text": "construct this c2, a\ncover in the second space.",
    "start": "1806780",
    "end": "1815900"
  },
  {
    "text": "But this cover\ndepends on f1 prime. So to cover, to epsilon 2\ncover the set f2 composed",
    "start": "1815900",
    "end": "1828549"
  },
  {
    "text": "with f1 prime which is what I\nwrote above where this is f2,",
    "start": "1828550",
    "end": "1834880"
  },
  {
    "text": "f1 capital X. f2 is ranging\nin capital F2, all right?",
    "start": "1834880",
    "end": "1842800"
  },
  {
    "text": "So for every set like this\nwhere this set is this-- this set is really\nliterally this blue things",
    "start": "1842800",
    "end": "1849409"
  },
  {
    "text": "I drew here, like this blue set. And I choose a cover.",
    "start": "1849410",
    "end": "1855370"
  },
  {
    "text": "And I denote that cover to be\nc2, f1 prime because this cover",
    "start": "1855370",
    "end": "1860710"
  },
  {
    "text": "depends on f1 prime. And then I'm going\nto take the union.",
    "start": "1860710",
    "end": "1867039"
  },
  {
    "text": "So I'm going to let c2\nto be the union of all",
    "start": "1867040",
    "end": "1873880"
  },
  {
    "text": "of the c2, f1 prime,\nwhere f1 prime is in c1. ",
    "start": "1873880",
    "end": "1880820"
  },
  {
    "text": "So this is how do I construct\nthe cover for the second layer? ",
    "start": "1880820",
    "end": "1887280"
  },
  {
    "text": "So this is supposed to\nbe a cover, supposed to be a cover for capital\nF2 composed with capital F1.",
    "start": "1887280",
    "end": "1898840"
  },
  {
    "start": "1898840",
    "end": "1909370"
  },
  {
    "text": "OK, any questions so far? So there are several questions.",
    "start": "1909370",
    "end": "1914940"
  },
  {
    "text": "So one question is that, how\ngood this cover is, right, that's one thing. And the other thing is that\nhow large this cover is.",
    "start": "1914940",
    "end": "1922730"
  },
  {
    "text": "So the size of this\ncover is relatively easy to compute because you are\nbasically just blowing up",
    "start": "1922730",
    "end": "1928580"
  },
  {
    "text": "the size multiplicatively\nbecause for every one in the--",
    "start": "1928580",
    "end": "1934039"
  },
  {
    "text": "in the c1 you create this cover. So you just multiply basically\nthe cover numbers together,",
    "start": "1934040",
    "end": "1939740"
  },
  {
    "text": "in some sense. And that's easy because\nyou can formulate what you can do is that\nyou can say c2, f1 prime,",
    "start": "1939740",
    "end": "1947210"
  },
  {
    "text": "this is something,\nthe log of this is going to be bounded\nby g of epsilon 1 c2--",
    "start": "1947210",
    "end": "1954800"
  },
  {
    "text": "or, sorry, epsilon 2, c2. But this is epsilon 2-- my bad.",
    "start": "1954800",
    "end": "1960050"
  },
  {
    "text": "This is epsilon 2, c1 I\nthink in my notation, epsilon 2 c1 below c1.",
    "start": "1960050",
    "end": "1967500"
  },
  {
    "text": "This is my assumption\nbecause my assumption is that as long as your\ninput is bounded by c1",
    "start": "1967500",
    "end": "1972940"
  },
  {
    "text": "and your cover size is epsilon\n2, you have this bound, all right? So that means that\nthe size of c2",
    "start": "1972940",
    "end": "1982140"
  },
  {
    "text": "is bounded by the\nsize of c1 times this exponential of\nthis g of epsilon 2, c1",
    "start": "1982140",
    "end": "1989850"
  },
  {
    "text": "because for every point in\nc1 you have a bound for that",
    "start": "1989850",
    "end": "1994919"
  },
  {
    "text": "corresponding set. So then you just multiply by c1. And that means the\nlog of c2 is less",
    "start": "1994920",
    "end": "2002000"
  },
  {
    "text": "than the log of c1 plus\ng of epsilon 2, c1,",
    "start": "2002000",
    "end": "2008000"
  },
  {
    "text": "which is equals to g of epsilon\n1, c0 plus g of epsilon 2, c1.",
    "start": "2008000",
    "end": "2015035"
  },
  {
    "text": " Actually, I forgot to define c0.",
    "start": "2015035",
    "end": "2020150"
  },
  {
    "text": "c0, just for convenience\nlet's define, my bad, so define c0 to be\njust the c, the bound on input.",
    "start": "2020150",
    "end": "2030140"
  },
  {
    "text": "So ci's are the bounds on the\nlayers, the activation layers.",
    "start": "2030140",
    "end": "2036470"
  },
  {
    "text": "And c0 is the\nbound on the input. ",
    "start": "2036470",
    "end": "2044010"
  },
  {
    "text": "OK.  So basically, the\nsize is added up. The log size is added up.",
    "start": "2044010",
    "end": "2050399"
  },
  {
    "text": "That's easy. And we're going to\ndeal with the covering, how does the covering\nworks at the end.",
    "start": "2050400",
    "end": "2056899"
  },
  {
    "text": "So before doing the covering,\ncompleting the covering radius, let's define how to\nproceed with more layers.",
    "start": "2056900",
    "end": "2064520"
  },
  {
    "text": "So, similarly, for\ngiven ck, suppose",
    "start": "2064520",
    "end": "2071419"
  },
  {
    "text": "you have covered k layers. Then now you're constructing a\ncover for the k plus 1 layer.",
    "start": "2071420",
    "end": "2076500"
  },
  {
    "text": "So what you do is say\nthat, so for any fk prime",
    "start": "2076500",
    "end": "2085449"
  },
  {
    "text": "composed with fk minus\n1 prime, f1 prime in ck,",
    "start": "2085449",
    "end": "2098640"
  },
  {
    "text": "you construct some ck plus 1,\nwhich is a function of this fk",
    "start": "2098640",
    "end": "2107829"
  },
  {
    "text": "up to f1 prime so\nthat epsilon k plus 1",
    "start": "2107830",
    "end": "2115210"
  },
  {
    "text": "covers the set fk plus 1\ncomposed with fk prime.",
    "start": "2115210",
    "end": "2123224"
  },
  {
    "text": " So I knew like this\nck, the final cover",
    "start": "2123225",
    "end": "2130710"
  },
  {
    "text": "to be the union of all\nof these kind of sets.",
    "start": "2130710",
    "end": "2139130"
  },
  {
    "start": "2139130",
    "end": "2145869"
  },
  {
    "text": "And, similarly, you can prove\nthat the log of the ck plus 1 will be less than the sum of\nall the single-layer covers,",
    "start": "2145870",
    "end": "2154690"
  },
  {
    "text": "epsilon k plus 1, ck plus\nup to g of epsilon 1 c0.",
    "start": "2154690",
    "end": "2161079"
  },
  {
    "start": "2161080",
    "end": "2172070"
  },
  {
    "text": "All right, so I've shown\nyou how to cover it. It's just an\niterative cover that's kind of pretty brute\nforce, in some sense.",
    "start": "2172070",
    "end": "2179869"
  },
  {
    "text": "And now the question is,\nwhy this is a good cover? What's the radius? So basically when we\nanswer the question,",
    "start": "2179870",
    "end": "2186710"
  },
  {
    "text": "right, so for every\nfr composed up",
    "start": "2186710",
    "end": "2193119"
  },
  {
    "text": "to f1, which belongs\nto this fr, this set,",
    "start": "2193120",
    "end": "2199825"
  },
  {
    "text": "this is the set\nwe want to cover. So you pick a\nfunction in the set. And you want to\nsay that this can be represented by\nsomething in a cover",
    "start": "2199825",
    "end": "2207760"
  },
  {
    "text": "with some small distances. So how does that work? So you first, let's say that you\nknow there exists 1 prime in c1",
    "start": "2207760",
    "end": "2217300"
  },
  {
    "text": "such that rho of f1, f prime,\nthis is less than epsilon 1.",
    "start": "2217300",
    "end": "2224030"
  },
  {
    "text": "That's something you know\nbecause c1 is a cover, epsilon 1 cover of the capital f1.",
    "start": "2224030",
    "end": "2230330"
  },
  {
    "text": "So now you have\nto say, let's say you try to pick\nsomething in c2 that",
    "start": "2230330",
    "end": "2235910"
  },
  {
    "text": "can cover f2 composed with f1. How do you do that? You basically in some\nsense use the construction.",
    "start": "2235910",
    "end": "2243860"
  },
  {
    "text": "You say that-- maybe I should\ndraw this a little bit more.",
    "start": "2243860",
    "end": "2250020"
  },
  {
    "text": " So the first thing is, suppose\nyou have a function here,",
    "start": "2250020",
    "end": "2258595"
  },
  {
    "text": "or you have a point\nhere, which is f1 of x. So you cover it by this point.",
    "start": "2258595",
    "end": "2266320"
  },
  {
    "text": "How do I do this--  as you cover this by\nthis point, right?",
    "start": "2266320",
    "end": "2272460"
  },
  {
    "text": "So now suppose you have a\npoint in the second layer. Suppose you have a\npoint somewhere here,",
    "start": "2272460",
    "end": "2281799"
  },
  {
    "text": "which is the map\nwhich is computed from that f1, x, right?",
    "start": "2281800",
    "end": "2287470"
  },
  {
    "text": "You apply some f2 to it. And what you do is\nyou say that you first",
    "start": "2287470",
    "end": "2294280"
  },
  {
    "text": "look at the neighbors\nin the first layer. So you got this point.",
    "start": "2294280",
    "end": "2299570"
  },
  {
    "text": "And this point, you look\nat what's the neighboring--",
    "start": "2299570",
    "end": "2304740"
  },
  {
    "text": "what's the image of this point\nin the second layer, maybe something here.",
    "start": "2304740",
    "end": "2312200"
  },
  {
    "text": "So I guess here\nyou are applying-- I guess, let's assume\nyou're applying f2 here. So you get f2 here.",
    "start": "2312200",
    "end": "2318680"
  },
  {
    "text": "You use the same f2 on the\ncover and you get this point. And then after you\nget this point,",
    "start": "2318680",
    "end": "2328740"
  },
  {
    "text": "you look at the\nneighbors in the right. So you got this one.",
    "start": "2328740",
    "end": "2334700"
  },
  {
    "text": "So basically this will be the\ncover for the purple point.",
    "start": "2334700",
    "end": "2341167"
  },
  {
    "text": "I'm not sure whether\nthis makes sense.  Sounds good?",
    "start": "2341167",
    "end": "2346400"
  },
  {
    "text": " So, in other word--\nmore formally,",
    "start": "2346400",
    "end": "2352600"
  },
  {
    "text": "so basically you say that-- so you want to say there exists\na function in this cover,",
    "start": "2352600",
    "end": "2357829"
  },
  {
    "text": "right, in this c2, f1 prime.",
    "start": "2357830",
    "end": "2363090"
  },
  {
    "text": "So this is this one.  This one is that\nright point I think.",
    "start": "2363090",
    "end": "2372880"
  },
  {
    "text": "This is that right point. So it's in this cover such\nthat rho of f2, f1 prime",
    "start": "2372880",
    "end": "2383970"
  },
  {
    "text": "is closed to what? Is closed to this--\noh, the blue point.",
    "start": "2383970",
    "end": "2389083"
  },
  {
    "text": "What's the blue point? The blue point is f2\ncomposed with f1 prime.",
    "start": "2389083",
    "end": "2394325"
  },
  {
    "text": " This is less than\nepsilon 2, all right.",
    "start": "2394325",
    "end": "2400450"
  },
  {
    "start": "2400450",
    "end": "2408119"
  },
  {
    "text": "I guess maybe let's write\nthis as f2 prime composed with f1 prime so that\njust to make it look--",
    "start": "2408120",
    "end": "2415224"
  },
  {
    "text": " that's also what\nmy cover is doing.",
    "start": "2415225",
    "end": "2420819"
  },
  {
    "text": "So suppose 0 of f2 prime\ncomposed with f1 prime.",
    "start": "2420820",
    "end": "2426323"
  },
  {
    "text": "So your cover has this\nstructure that you will first apply f1 in your cover, you\nuse the f2 prime in a cover.",
    "start": "2426323",
    "end": "2431850"
  },
  {
    "text": "So suppose-- what\nI'm seeing here--",
    "start": "2431850",
    "end": "2437200"
  },
  {
    "text": "OK, sorry, sorry, my bad.  So you have this function\nin this cover such that--",
    "start": "2437200",
    "end": "2444580"
  },
  {
    "start": "2444580",
    "end": "2452960"
  },
  {
    "text": "so this is of the\nform, let's say, f2--",
    "start": "2452960",
    "end": "2458180"
  },
  {
    "text": "I want to make this\ntoo complicated. But I think let's say\nthis is of the form f2 prime composed with f1 prime,\nwhich is in this cover.",
    "start": "2458180",
    "end": "2465440"
  },
  {
    "text": "But this one actually implicitly\ndepends on f1 prime as well.",
    "start": "2465440",
    "end": "2473030"
  },
  {
    "text": "But let's ignore that notation. So you've got a rho\nof f2 prime composed with f1 prime, which is\nclose to f2 composed with f1.",
    "start": "2473030",
    "end": "2481310"
  },
  {
    "text": "But this point is\nnot what you really want to cover because we want\nto cover f2 composed with f1.",
    "start": "2481310",
    "end": "2486859"
  },
  {
    "text": "So what you care\nabout is that rho of f2 prime composed\nwith f prime,",
    "start": "2486860",
    "end": "2492150"
  },
  {
    "text": "the difference between this\nand f2 composed with f1. So this is the thing\nyou really care about.",
    "start": "2492150",
    "end": "2498244"
  },
  {
    "text": "And you can see that there's\nstill some differences because the differences come\nfrom that this is at 1 prime,",
    "start": "2498245",
    "end": "2506730"
  },
  {
    "text": "but not at f1. So that's why you do\na triangle inequality. You say that the\ntarget is less than rho",
    "start": "2506730",
    "end": "2515319"
  },
  {
    "text": "of f2 prime composed\nwith f1 prime.",
    "start": "2515320",
    "end": "2525722"
  },
  {
    "text": "So use this as the\nintermediate term, right? ",
    "start": "2525722",
    "end": "2533160"
  },
  {
    "text": "So this one is less\nthan epsilon 2.  And you are left with this\nthing that where you only differ",
    "start": "2533160",
    "end": "2542839"
  },
  {
    "text": "in the first layer, right? That's the difference. But this difference\nis kind of propagated.",
    "start": "2542840",
    "end": "2548600"
  },
  {
    "text": "In some sense, if you\nlook at this figure, this figure is a little\nbit kind of tricky.",
    "start": "2548600",
    "end": "2553760"
  },
  {
    "text": "So this is the difference\nin the first layer. But once you apply\nthis f2, right,",
    "start": "2553760",
    "end": "2559090"
  },
  {
    "text": "so you have a bigger difference. So this is the difference\nin the second layer.",
    "start": "2559090",
    "end": "2564280"
  },
  {
    "text": "And this difference can be\nlike a blown up a little bit because even though you\napply the same function,",
    "start": "2564280",
    "end": "2569620"
  },
  {
    "text": "you may blow up the\ndifferences a little bit. So that's why you have to\nuse the Lipschitzness to say",
    "start": "2569620",
    "end": "2574930"
  },
  {
    "text": "that this is less than epsilon\n2 plus kappa 2 times epsilon 1.",
    "start": "2574930",
    "end": "2585760"
  },
  {
    "text": "kappa 2 times rho\nof f1 prime, f1. And this is less than epsilon\n2 plus kappa 2 times epsilon 1.",
    "start": "2585760",
    "end": "2594790"
  },
  {
    "start": "2594790",
    "end": "2599940"
  },
  {
    "text": "That's how you bound\nthe covering, the radius for the second layer.",
    "start": "2599940",
    "end": "2607920"
  },
  {
    "text": "Any questions? And then you can similarly\ndo all of this for k.",
    "start": "2607920",
    "end": "2618720"
  },
  {
    "text": "So there exists a\nfunction fk prime, which depends on f1 prime\nup to fk minus 1 prime.",
    "start": "2618720",
    "end": "2628140"
  },
  {
    "text": "And in this set ck,\nlet's write this as fk prime composed with\nk minus 1 prime composed",
    "start": "2628140",
    "end": "2636480"
  },
  {
    "text": "with f1 prime, and such\nthat this is a cover, such",
    "start": "2636480",
    "end": "2643795"
  },
  {
    "text": "that the distance is less than\nepsilon k, less than epsilon k.",
    "start": "2643795",
    "end": "2657520"
  },
  {
    "text": "That's the definition\nof the cover. And then you have\nto see why this",
    "start": "2657520",
    "end": "2663569"
  },
  {
    "text": "is a good thing for\nthe original one.",
    "start": "2663570",
    "end": "2671400"
  },
  {
    "text": "Recall that this is not actually\nwhat you really care about. You care about the fk composed\nwith fk minus 1 up to f1.",
    "start": "2671400",
    "end": "2677799"
  },
  {
    "text": "You don't care about the prime. So you care about this. This is the thing that\nyou really care about.",
    "start": "2677800",
    "end": "2684440"
  },
  {
    "text": "It also shows this is small. And how you do this? You expand this\ninto multiple terms.",
    "start": "2684440",
    "end": "2693110"
  },
  {
    "text": "So you say that\nthis is less than-- ",
    "start": "2693110",
    "end": "2702503"
  },
  {
    "text": "so I guess you--  the first thing is you\nfirst compare with--",
    "start": "2702503",
    "end": "2709740"
  },
  {
    "text": "this kind of telescoping sum\nis pretty actually useful in many cases. ",
    "start": "2709740",
    "end": "2716750"
  },
  {
    "text": "You first compare with this. And then you compare--",
    "start": "2716750",
    "end": "2722190"
  },
  {
    "text": "you just gradually peel\noff more and more terms. ",
    "start": "2722190",
    "end": "2733920"
  },
  {
    "text": "And this is low prime here. ",
    "start": "2733920",
    "end": "2741710"
  },
  {
    "text": "And, until, finally, you got-- everything is kind of\nlow prime, basically.",
    "start": "2741710",
    "end": "2747859"
  },
  {
    "start": "2747860",
    "end": "2753060"
  },
  {
    "text": "And, eventually, you get-- what you care, there\nis no prime at all.",
    "start": "2753060",
    "end": "2760079"
  },
  {
    "text": "So this is just\ntriangle inequality. And now, you bound\neach of these term. The first term, by definition,\nis less than epsilon K.",
    "start": "2760080",
    "end": "2770116"
  },
  {
    "text": "And the second term you see\nthat these two are the same. And this part is also the same.",
    "start": "2770116",
    "end": "2777212"
  },
  {
    "text": "And the only differences\ncome from the difference between this fK minus 1 and fK.",
    "start": "2777212",
    "end": "2782630"
  },
  {
    "text": "The f prime K and-- f prime K minus 1\nand f K minus 1.",
    "start": "2782630",
    "end": "2789750"
  },
  {
    "text": "So because of the cover, that\ngives you epsilon K minus 1. And then you also\nhave to blow up",
    "start": "2789750",
    "end": "2796160"
  },
  {
    "text": "a little bit because of the\nfK composed on top of it. So you also have to pay a\nLipschitzness of fK, which",
    "start": "2796160",
    "end": "2802670"
  },
  {
    "text": "is kappa K. Kappa K.\nSorry, my K and kappa looks",
    "start": "2802670",
    "end": "2808900"
  },
  {
    "text": "probably almost the same. So, then you have epsilon\nK minus 2 times kappa K",
    "start": "2808900",
    "end": "2819310"
  },
  {
    "text": "minus 1 times kappa K. So on\nand so forth, until you have--",
    "start": "2819310",
    "end": "2825971"
  },
  {
    "text": "In the last time,\nthe only difference comes from the first one. So you pay epsilon 1, because\nthey are epsilon cover.",
    "start": "2825971",
    "end": "2832109"
  },
  {
    "text": "f1 prime is from\nthe epsilon cover. And then you pay a lot of\nLipschitzness, like kappa K,",
    "start": "2832110",
    "end": "2839400"
  },
  {
    "text": "times kappa K minus\n1, up to kappa 2. ",
    "start": "2839400",
    "end": "2853050"
  },
  {
    "text": "And if you take K\nto be R, then you get the eventual thing, right? So the eventual theorem\nis that your radius",
    "start": "2853050",
    "end": "2860680"
  },
  {
    "text": "for the final covering\nis something like--",
    "start": "2860680",
    "end": "2865869"
  },
  {
    "text": "Where is it? ",
    "start": "2865870",
    "end": "2871800"
  },
  {
    "text": "The radius for\nthe final covering is something like this, right? So that's eventually\nwhat you got.",
    "start": "2871800",
    "end": "2877410"
  },
  {
    "text": " Any questions? ",
    "start": "2877410",
    "end": "2889361"
  },
  {
    "text": "I'm still a little unsatisfied\nwith having to add epsilon",
    "start": "2889362",
    "end": "2894805"
  },
  {
    "text": "[INAUDIBLE] to our examples.",
    "start": "2894805",
    "end": "2901420"
  },
  {
    "text": "[INAUDIBLE] which\nis commonly assumed. And then we're mapping\nthe [INAUDIBLE]..",
    "start": "2901420",
    "end": "2908530"
  },
  {
    "text": "The sets that we've covered. ",
    "start": "2908530",
    "end": "2914238"
  },
  {
    "text": "For example, why isn't\nepsilon 1 times--",
    "start": "2914238",
    "end": "2922020"
  },
  {
    "text": "appears to be kappa 2, kappa\n3, kappa 4 up to kappa k. Why won't that cover it? ",
    "start": "2922020",
    "end": "2929510"
  },
  {
    "text": "Right. So I guess the\nquestion is that why-- Why you only have to--",
    "start": "2929510",
    "end": "2936700"
  },
  {
    "text": "Why don't you only at\nproof require this? This is because-- no.",
    "start": "2936700",
    "end": "2945030"
  },
  {
    "text": "Suppose-- let me try\nwhether this works.",
    "start": "2945030",
    "end": "2950230"
  },
  {
    "text": "Suppose your function\nclass is at f1 composed with a fixed function. ",
    "start": "2950230",
    "end": "2956640"
  },
  {
    "text": "Maybe it's the other side. So f1 composed with a fixed\nfunction that is called f2,",
    "start": "2956640",
    "end": "2963440"
  },
  {
    "text": "maybe, composed with f3. So and so forth, fr. And all of these are fixed.",
    "start": "2963440",
    "end": "2969700"
  },
  {
    "text": "Then you only have this term. But you also have to\ncover the possibilities",
    "start": "2969700",
    "end": "2977870"
  },
  {
    "text": "for the second layer and the\nthird layer, so and so forth. So that's why you have\nto pay the other things. ",
    "start": "2977870",
    "end": "2987100"
  },
  {
    "text": "OK, cool. So, now, we are done\nwith this lemma. And now let's go back to\nthe proof of the theorem.",
    "start": "2987100",
    "end": "2993680"
  },
  {
    "text": "And a proof of the theorem,\nas I kind of alluded before, is pretty much just the\nkind of annoying speculation",
    "start": "2993680",
    "end": "3002600"
  },
  {
    "text": "in some sense. There is a way to do the\ncalculation in a simpler way,",
    "start": "3002600",
    "end": "3007880"
  },
  {
    "text": "but I'm going to first show\nyou a zero knowledge proof. So, basically, I'm\njust going to tell you that I'm going to choose\nmy epsilon to do this,",
    "start": "3007880",
    "end": "3013880"
  },
  {
    "text": "and it just works out. And then I'm going to show\nyou some way to kind of--",
    "start": "3013880",
    "end": "3019480"
  },
  {
    "text": "at least what I\nwould do with this. If I write a paper,\nI'm going to show you the first proof\nI'm going to show,",
    "start": "3019480",
    "end": "3025280"
  },
  {
    "text": "which is just choosing\nsome epsilon y. So let's start with that. So, basically, everything\nis about choosing epsilon y,",
    "start": "3025280",
    "end": "3033890"
  },
  {
    "text": "right? So you first-- of\ncourse, you first know that this O is\nequal to O tilde of Ci",
    "start": "3033890",
    "end": "3042330"
  },
  {
    "text": "minus 1 squared, bi squared\nover epsilon y squared, because this is linear model.",
    "start": "3042330",
    "end": "3049250"
  },
  {
    "text": "This is linear model.  Composed with one\nLipschitz function.",
    "start": "3049250",
    "end": "3056965"
  },
  {
    "text": " Right? So recall that, each of the\nFi is a linear model composed",
    "start": "3056965",
    "end": "3064120"
  },
  {
    "text": "with the one Lipschitz function,\na fixed one Lipschitz function. And for the linear model,\nthe covering number,",
    "start": "3064120",
    "end": "3070270"
  },
  {
    "text": "the log covering\nnumber, is supposed to be something like\nthe norm of the input. ",
    "start": "3070270",
    "end": "3077260"
  },
  {
    "text": "And this is the-- Bi is the Wi transposed\n2 to 1 norm, right?",
    "start": "3077260",
    "end": "3084340"
  },
  {
    "text": "So the norm of the parameter,\nand divided by the radius.",
    "start": "3084340",
    "end": "3090360"
  },
  {
    "text": "This is what we have shown last\ntime, like, we didn't prove this, but this is the\nlemma we had last time,",
    "start": "3090360",
    "end": "3095490"
  },
  {
    "text": "about the log covering number\nof the linear models, right? ",
    "start": "3095490",
    "end": "3102330"
  },
  {
    "text": "So we plug in this,\nand then, basically-- ",
    "start": "3102330",
    "end": "3108405"
  },
  {
    "text": "So, basically, you\nhave two quantities. So one is the log\ncovering size, which",
    "start": "3108405",
    "end": "3114730"
  },
  {
    "text": "is the sum of Ci\nminus 1 square, Bi square over epsilon i square.",
    "start": "3114730",
    "end": "3121770"
  },
  {
    "text": "And also, you have\nanother thing, which is the radius,\nwhich is sum of epsilon i.",
    "start": "3121770",
    "end": "3129680"
  },
  {
    "text": "I'm writing this\nas epsilon kappa. i plus 1, up to kappa r.",
    "start": "3129680",
    "end": "3134720"
  },
  {
    "text": "From 1 to r. Right. So you basically\nhave these two things",
    "start": "3134720",
    "end": "3140783"
  },
  {
    "text": "that you want to trade off. You want to find the balance\ndependencies between them. You want to make the log common\nsize to depend on the radius",
    "start": "3140783",
    "end": "3147030"
  },
  {
    "text": "as best as possible. So you just choose\nsome epsilon i.",
    "start": "3147030",
    "end": "3152500"
  },
  {
    "text": "And so you care about\nthe best, kind of trade off all the dependencies. ",
    "start": "3152500",
    "end": "3159829"
  },
  {
    "text": "So this is epsilon. So what you should do is\nthat you should say, I guess,",
    "start": "3159830",
    "end": "3165380"
  },
  {
    "text": "if I give you a zero\nknowledge truth, I'm going to choose\nepsilon i to be",
    "start": "3165380",
    "end": "3177270"
  },
  {
    "text": "ci minus 1 square, bi\nsquare over kappa, i plus 1,",
    "start": "3177270",
    "end": "3184020"
  },
  {
    "text": "up to Kappa r 1/3 times epsilon,\nsum of bi 2/3 over kappa i 2/3,",
    "start": "3184020",
    "end": "3203220"
  },
  {
    "text": "product of kappa i 2/3. ",
    "start": "3203220",
    "end": "3209710"
  },
  {
    "text": "All right. So if I choose\nepsilon i to be this, then I will claim that sum\nof epsilon i, kappa i plus 1,",
    "start": "3209710",
    "end": "3219070"
  },
  {
    "text": "up to kappa r-- this will\nbe indeed equals to epsilon.",
    "start": "3219070",
    "end": "3224260"
  },
  {
    "text": "And why is that? I'm going to do the\nderivation for you, but I don't feel like\nyou should really",
    "start": "3224260",
    "end": "3230349"
  },
  {
    "text": "need to verify it on the\nfly, or you don't necessarily have to verify it later. But just for the\nsake of completeness,",
    "start": "3230350",
    "end": "3236360"
  },
  {
    "text": "let me do the calculation. This will be-- you just\nplug in epsilon i here.",
    "start": "3236360",
    "end": "3246160"
  },
  {
    "text": "So you get, I think,\nci minus 1 2/3, bi 2/3.",
    "start": "3246160",
    "end": "3252240"
  },
  {
    "text": "This come from this two terms. And then there's something\nabout this and this.",
    "start": "3252240",
    "end": "3261385"
  },
  {
    "text": " And also this thing, right? So you can organize\nthose things into--",
    "start": "3261385",
    "end": "3268940"
  },
  {
    "text": "I guess I'm only-- I guess I'm treating these\nas a constant for the moment",
    "start": "3268940",
    "end": "3274550"
  },
  {
    "text": "in this derivation. So I got this\nmultiplied by this. We've got 2/3 of i 2/3.",
    "start": "3274550",
    "end": "3281670"
  },
  {
    "text": "By the way, if you don't\nwant to verify this, just maybe bear with\nme for a second.",
    "start": "3281670",
    "end": "3286795"
  },
  {
    "start": "3286795",
    "end": "3293210"
  },
  {
    "text": "All right. ",
    "start": "3293210",
    "end": "3304310"
  },
  {
    "text": "Epsilon.  I guess, one other\nthing is that ci is also",
    "start": "3304310",
    "end": "3311160"
  },
  {
    "text": "a function of\nkappa i, because we recall that ci is the norm\nbound for the layers, which",
    "start": "3311160",
    "end": "3316440"
  },
  {
    "text": "depends on kappa i. One question? Oh, yes. So the i that the sum\nand the product rule,",
    "start": "3316440",
    "end": "3322799"
  },
  {
    "text": "that's different from the\nepsilon, the i [INAUDIBLE].. The i here?",
    "start": "3322800",
    "end": "3329700"
  },
  {
    "text": "In the [INAUDIBLE], yeah. This is the same i. ",
    "start": "3329700",
    "end": "3335829"
  },
  {
    "text": "Sorry. Yes, you're right. You probably should use\na different index just for the sake of-- Yes.",
    "start": "3335830",
    "end": "3341220"
  },
  {
    "text": " I think you might be right.",
    "start": "3341220",
    "end": "3346990"
  },
  {
    "text": "This is probably-- You know what I mean? Ideally, you probably\nneed to use a J just",
    "start": "3346990",
    "end": "3353370"
  },
  {
    "text": "for the sake of completeness. So, yeah, but this one,\nyou average out this part.",
    "start": "3353370",
    "end": "3364000"
  },
  {
    "text": "After doing the sum\nand the product, the i is gone in\nthe second part. So, anyway, let me do\nthis tedious thing.",
    "start": "3364000",
    "end": "3374700"
  },
  {
    "text": "So recall that ci is the norm\nbond and ci is defined to be-- I think, ci is defined to\nbe some product of kappa i.",
    "start": "3374700",
    "end": "3381085"
  },
  {
    "text": " And so I I guess,\nlet's put bi in front.",
    "start": "3381085",
    "end": "3386880"
  },
  {
    "text": "And then you've got ci is kappa\n1 2/3 up to kappa i minus 1",
    "start": "3386880",
    "end": "3392730"
  },
  {
    "text": "2/3. This corresponds to ci minus 1. And then you get\nkappa i plus 1 2/3.",
    "start": "3392730",
    "end": "3400490"
  },
  {
    "text": "That's from here. This is kappa plus 1-- i plus 1. Sorry.",
    "start": "3400490",
    "end": "3405890"
  },
  {
    "text": " And then, you still multiply\nthe same thing here.",
    "start": "3405890",
    "end": "3412525"
  },
  {
    "text": " And then you simplify\nthis to the first sum to--",
    "start": "3412525",
    "end": "3422230"
  },
  {
    "text": "I guess, you can see that the\nonly missing term is kappa i. So this is equal to\nbi 2/3 over kappa",
    "start": "3422230",
    "end": "3427720"
  },
  {
    "text": "i 2/3 times product\nof kappa i 2/3.",
    "start": "3427720",
    "end": "3432820"
  },
  {
    "text": "And from 1 to r. And times this thing. And now, let's deal\nwith this thing.",
    "start": "3432820",
    "end": "3438790"
  },
  {
    "text": "You can see that this one\ncancels with this one,",
    "start": "3438790",
    "end": "3445200"
  },
  {
    "text": "and this one cancels\nwith this one. So you get really\nequals to epsilon. ",
    "start": "3445200",
    "end": "3451690"
  },
  {
    "text": "And the log-covering\nsize is equals to--",
    "start": "3451690",
    "end": "3457630"
  },
  {
    "start": "3457630",
    "end": "3462740"
  },
  {
    "text": "That is equals to\nthe sum of the-- ",
    "start": "3462740",
    "end": "3469838"
  },
  {
    "text": "What I'm doing here\nis equals to this. ",
    "start": "3469838",
    "end": "3476020"
  },
  {
    "text": "Basically, the sum of-- OK, let's first write\nthe trivial thing. This is ci minus 1 square, bi\nsquare over epsilon i square.",
    "start": "3476020",
    "end": "3484180"
  },
  {
    "text": "And you plug in epsilon i here. So you get this gigantic thing. Maybe let's call this thing z.",
    "start": "3484180",
    "end": "3490810"
  },
  {
    "text": "So you've got 1 over z squared\ntimes this minus sums of ci",
    "start": "3490810",
    "end": "3495850"
  },
  {
    "text": "minus 1 square, bi square. You plug in this to the minus 2. So you get ci minus 1\nsquare bi minus 1 square.",
    "start": "3495850",
    "end": "3508595"
  },
  {
    "start": "3508595",
    "end": "3516700"
  },
  {
    "text": "Minus 2/3. And then kappa i plus\n1 up to kappa i 2/3.",
    "start": "3516700",
    "end": "3525100"
  },
  {
    "text": "And there are some\ncancellations. So this will be equals to--",
    "start": "3525100",
    "end": "3532780"
  },
  {
    "start": "3532780",
    "end": "3574670"
  },
  {
    "text": "very sorry. ",
    "start": "3574670",
    "end": "3583079"
  },
  {
    "text": "I think I jumpped\na step in my notes. So, OK. I need to--",
    "start": "3583080",
    "end": "3589260"
  },
  {
    "text": "So sorry. ",
    "start": "3589260",
    "end": "3598539"
  },
  {
    "text": "I think you plug in the\ndefinition of ci minus 1. And you get bi 2/3\nover kappa i 2/3,",
    "start": "3598540",
    "end": "3606670"
  },
  {
    "text": "times the product\nof kappa i 2/3. And now, you use the\ndefinition of Z, which",
    "start": "3606670",
    "end": "3613150"
  },
  {
    "text": "is this gigantic constant. And, eventually,\nI think you get-- let me now do that, carefully.",
    "start": "3613150",
    "end": "3621240"
  },
  {
    "text": "But, eventually, you get this. ",
    "start": "3621240",
    "end": "3635840"
  },
  {
    "text": "Or epsilon square. OK. So I guess maybe this\nis a good demonstration of why I shouldn't do this.",
    "start": "3635840",
    "end": "3642215"
  },
  {
    "text": " After I even I verify this with\nmy notes, which has almost all",
    "start": "3642215",
    "end": "3649160"
  },
  {
    "text": "the steps, is kind of tricky. But anyway, so\nbefore we're talking about how to do this\nbetter, I guess let's first",
    "start": "3649160",
    "end": "3655670"
  },
  {
    "text": "agree that this is done, right? Because now you see the\nlog-covering size is bounded by this epsilon square,\nsomething over epsilon square,",
    "start": "3655670",
    "end": "3662630"
  },
  {
    "text": "and that's what\nwe wanted to have. And then you apply the\nRademacher complexity,",
    "start": "3662630",
    "end": "3669110"
  },
  {
    "text": "the tool from covering\nnumber, provide the Rademacher",
    "start": "3669110",
    "end": "3676240"
  },
  {
    "text": "complexity, recall that if\nyou have log-covering number,",
    "start": "3676240",
    "end": "3682280"
  },
  {
    "text": "it's r over F square,\nthen this means Rademacher complexity is\nsomething like square root of R",
    "start": "3682280",
    "end": "3688180"
  },
  {
    "text": "over n, right? So this is what we\ndiscussed last time. And if you apply\nthis small tool,",
    "start": "3688180",
    "end": "3693560"
  },
  {
    "text": "then you get the Rademacher\ncomplexity will be this one.",
    "start": "3693560",
    "end": "3699280"
  },
  {
    "text": "Square root of this one\nand over square of that. And then you are done. OK? ",
    "start": "3699280",
    "end": "3706760"
  },
  {
    "text": "So we are done. But I think I want\nto kind of share how to do this a little\nmore easily without going",
    "start": "3706760",
    "end": "3713140"
  },
  {
    "text": "through all of this pain. This is a small trick. It's purely a\nmathematical trick.",
    "start": "3713140",
    "end": "3719188"
  },
  {
    "text": "I don't know how\nmany of you know it. Maybe you all know it, or\nmaybe you all don't know it.",
    "start": "3719188",
    "end": "3724869"
  },
  {
    "text": "But, anyway, let's\ntalk about it. So, basically, the question\nis, you care about--",
    "start": "3724870",
    "end": "3731775"
  },
  {
    "text": "This is the question. You care about the trade\noff between these two. ",
    "start": "3731775",
    "end": "3737865"
  },
  {
    "text": "And you care about the\ntrade off between these two. So what you could\ndo is that, if you",
    "start": "3737865",
    "end": "3744329"
  },
  {
    "text": "abstractify it's kind of like-- so abstractly speaking,\nthis is about the trade",
    "start": "3744330",
    "end": "3753140"
  },
  {
    "text": "off between something like-- maybe let's use some\ndifferent numbers.",
    "start": "3753140",
    "end": "3758990"
  },
  {
    "text": "Alpha i square over epsilon i\nsquare, versus sum of beta i,",
    "start": "3758990",
    "end": "3771590"
  },
  {
    "text": "epsilon i. Something like this. That's kind of the game\nyou are dealing with.",
    "start": "3771590",
    "end": "3776869"
  },
  {
    "text": "And how do you do the trade off? So what you would do is that\nyou use this so-called Holder",
    "start": "3776870",
    "end": "3788030"
  },
  {
    "text": "inequality. ",
    "start": "3788030",
    "end": "3794888"
  },
  {
    "text": "The Holder inequality is that\nyou only have mathematical ways to write it. For example, you can\nwrite a in a product with b is less than\nthe p norm of a times",
    "start": "3794888",
    "end": "3804000"
  },
  {
    "text": "the q norm of b, when\np and q satisfies this.",
    "start": "3804000",
    "end": "3809500"
  },
  {
    "text": " And for example, when p--",
    "start": "3809500",
    "end": "3816450"
  },
  {
    "text": "And you could also\nwrite it like this. The sum of ai bi is\nless than the sum of ai",
    "start": "3816450",
    "end": "3823410"
  },
  {
    "text": "to the power p to the 1-- this, something like this.",
    "start": "3823410",
    "end": "3831150"
  },
  {
    "text": "This is just exactly\nthe same thing. And then guys, when\np is 2, this is the Cauchy-Schwarz inequality.",
    "start": "3831150",
    "end": "3837920"
  },
  {
    "text": "And we need something\nslightly different. We need p is 3, or p is 3/2.",
    "start": "3837920",
    "end": "3845099"
  },
  {
    "text": "Then you got some of ai cubed\n1/3 times sum of bi 2/3.",
    "start": "3845100",
    "end": "3855960"
  },
  {
    "text": "It's lower than sum of ai bi. So in some sense, all\nof this inequality is trying to kind of deal with--",
    "start": "3855960",
    "end": "3861465"
  },
  {
    "text": " has this kind of form.",
    "start": "3861465",
    "end": "3866510"
  },
  {
    "text": "And I guess maybe\nwhat should I-- which one should I do first?",
    "start": "3866510",
    "end": "3871765"
  },
  {
    "start": "3871765",
    "end": "3878750"
  },
  {
    "text": "Look, I'm not sure\nwhether I'm lost on you. So I guess what eventually I\nwant to do is the following. Maybe let me just\ngive you an overview.",
    "start": "3878750",
    "end": "3885500"
  },
  {
    "text": "Eventually I want to do is\njust that, I want to do this. And let's say that this product\nis the sum of beta i epsilon i.",
    "start": "3885500",
    "end": "3892810"
  },
  {
    "text": "This is larger than sum of alpha\ni beta i to the 2/3 and 3, 2.",
    "start": "3892810",
    "end": "3907000"
  },
  {
    "text": "So if rather do this, then\nyou kind of like cancel out.",
    "start": "3907000",
    "end": "3912320"
  },
  {
    "text": "So maybe-- sorry, maybe\nlet me do this first. So we care about sum of\ni squared-- of epsilon i",
    "start": "3912320",
    "end": "3918280"
  },
  {
    "text": "squared versus sum\nof beta i epsilon i. And this is your epsilon, and\nthis is your covering size",
    "start": "3918280",
    "end": "3924850"
  },
  {
    "text": "the covering. And what you would\nwant-- what you can do is that you can say\nthis times this squared.",
    "start": "3924850",
    "end": "3935810"
  },
  {
    "text": "Just forget about this. Just let me do it formally. So if there's an\ninequality that shows",
    "start": "3935810",
    "end": "3942470"
  },
  {
    "text": "that this is larger\nthan sum of alpha i beta",
    "start": "3942470",
    "end": "3948274"
  },
  {
    "text": "i, the 2/3 over 3/2. And this is essentially\nHolder inequality.",
    "start": "3948274",
    "end": "3953779"
  },
  {
    "text": "Let me justify this in\na moment, but suppose you believe in me in this. Then you say that-- and\nsuppose you also believe",
    "start": "3953780",
    "end": "3959800"
  },
  {
    "text": "that this is achievable. Suppose we believe that\nequality is achievable, which",
    "start": "3959800",
    "end": "3966300"
  },
  {
    "text": "I will justify in a moment. So if equality is\nachievable, it means",
    "start": "3966300",
    "end": "3971840"
  },
  {
    "text": "that there exists\nepsilon i's such that sum of alpha i\nsquare, epsilon i squared",
    "start": "3971840",
    "end": "3981770"
  },
  {
    "text": "is equal to this quantity 3/2\nover sum of theta i epsilon i",
    "start": "3981770",
    "end": "3991630"
  },
  {
    "text": "squared. And recall that\nthis is your epsilon squared, and this is\nyour log covering number.",
    "start": "3991630",
    "end": "4000150"
  },
  {
    "text": "Now you get log\ncovering number-- you can-- so you get that. You can choose epsilon i such\nthat the log covering number",
    "start": "4000150",
    "end": "4007609"
  },
  {
    "text": "is less than this, which\nis equal to this quantity over epsilon square. And this quantity is\nwhat you are looking for.",
    "start": "4007610",
    "end": "4014250"
  },
  {
    "text": "Right, this is the R thing\nthat you are looking for, which is the-- something like this.",
    "start": "4014250",
    "end": "4020460"
  },
  {
    "text": "And you don't have to do any\nof this verification, right? That's it. And basically you just have\nto plug in alpha i and beta i,",
    "start": "4020460",
    "end": "4026070"
  },
  {
    "text": "and you just verify. And that's it. So does that make sense?",
    "start": "4026070",
    "end": "4031329"
  },
  {
    "text": "So basically you cancel\nout the epsilon I's. You try to find\nthe best epsilon i by proving the best inequality.",
    "start": "4031330",
    "end": "4036370"
  },
  {
    "text": "You want that-- you also want\ninequality to be achievable. So-- so for example, another\nsituation that this is useful",
    "start": "4036370",
    "end": "4045720"
  },
  {
    "text": "is-- for example, you probably\nhave seen this kind of form. Like you have a parameter eta. You have eta plus B over eta.",
    "start": "4045720",
    "end": "4052650"
  },
  {
    "text": "You want something like this. And you can choose\nyour eta arbitrarily-- or arbitrarily. So how do you do it?",
    "start": "4052650",
    "end": "4058680"
  },
  {
    "text": "Many people tell you that you\njust find out the minimum eta by doing some kind of like\ntaking a gradient, right?",
    "start": "4058680",
    "end": "4064680"
  },
  {
    "text": "So and then you find\nout minimum, right? That's fine. But-- so but my way to do it\nis that just to prove that eta",
    "start": "4064680",
    "end": "4071910"
  },
  {
    "text": "plus beta eta-- this is larger than\n2 times square B. This is Cauchy-Schwarz, or\nAM-GM, whatever you call it.",
    "start": "4071910",
    "end": "4079650"
  },
  {
    "text": "And this inequality\nis achievable. You can attain the equality.",
    "start": "4079650",
    "end": "4084700"
  },
  {
    "text": "So that basically, the\nbest thing for this is to square B basically.",
    "start": "4084700",
    "end": "4089740"
  },
  {
    "text": "Basically if you know what\nthis equality is attainable,",
    "start": "4089740",
    "end": "4096720"
  },
  {
    "text": "then you can choose\nthe existing eta such that eta plus B over\neta is 2 square B,",
    "start": "4096720",
    "end": "4103350"
  },
  {
    "text": "and then you get rid of eta. You get the best bond you want. So the same thing-- it's the same\nlogic here as well,",
    "start": "4103350",
    "end": "4109985"
  },
  {
    "text": "where you prove\ninequality so that you can cancel out the parameter\nthat you want to choose. And then-- and if\nthat inequality can",
    "start": "4109986",
    "end": "4118528"
  },
  {
    "text": "be attained as a\nequality, then you know that you are getting\nthe best parameter. And you don't even\nnecessarily have",
    "start": "4118529",
    "end": "4124308"
  },
  {
    "text": "to compute what epsilon i are. Of course, if you're\nwriting a paper, probably, you still want\nto compute epsilon i,",
    "start": "4124308",
    "end": "4130859"
  },
  {
    "text": "and do the zero\nknowledge proof, right? That's why all the papers\nshow you this kind of things.",
    "start": "4130859",
    "end": "4137430"
  },
  {
    "text": "So because-- so how do I-- I have to do a lot more\nargument to show that this--",
    "start": "4137430",
    "end": "4144229"
  },
  {
    "text": "but in your mind,\nyou probably should do this in later version. This later version-- at least\nthis is what I did in my mind",
    "start": "4144229",
    "end": "4153020"
  },
  {
    "text": "when I do any research\nlike this, right? Because this is so\nfast, so that you can get a better estimate on\nwhat's the bound you can have,",
    "start": "4153020",
    "end": "4160460"
  },
  {
    "text": "right? And in some sense, this\nis useful in many cases",
    "start": "4160460",
    "end": "4166490"
  },
  {
    "text": "because one of the ways to\nmake your theoretical research faster is that you have a lot\nof modularized small steps",
    "start": "4166490",
    "end": "4174850"
  },
  {
    "text": "which you can do very,\nvery fast, right? So one of the way I found that\npeople can get into this very",
    "start": "4174850",
    "end": "4181770"
  },
  {
    "text": "messy calculation is that-- every theory-- if you prove\nsomething hard, right,",
    "start": "4181770",
    "end": "4187889"
  },
  {
    "text": "so you have to use\na lot of pages. So your eventual product is\nsomething like 20 pages proof,",
    "start": "4187890",
    "end": "4193370"
  },
  {
    "text": "or maybe more than that. Sometimes there are 70 pages\nproofs, or 100 pages, right?",
    "start": "4193370",
    "end": "4198600"
  },
  {
    "text": "So at least I think--\nat least in when I do those kind of like\nproofs, I never really",
    "start": "4198600",
    "end": "4204840"
  },
  {
    "text": "kind of like-- if I\nchange one part of it, I never have to redo that\n100 pages calculation to know",
    "start": "4204840",
    "end": "4210360"
  },
  {
    "text": "what's the final outcome. So basically after\na certain point, I already know that this\npart, maybe these two pages,",
    "start": "4210360",
    "end": "4217292"
  },
  {
    "text": "are the most important thing. And I also know that,\nhow does this page translate to the final outcome?",
    "start": "4217292",
    "end": "4222823"
  },
  {
    "text": "And I've already done\nthose kind of very fast. I have a kind of very\nfast data structure so that I know\nthat if these two--",
    "start": "4222823",
    "end": "4229920"
  },
  {
    "text": "if this part can be improved\nby a factor of 2, then what does that mean\nfor my final outcome?",
    "start": "4229920",
    "end": "4235500"
  },
  {
    "text": "And that part is kind\nof like, are they abstract enough so that you\nhave this very fast conversion,",
    "start": "4235500",
    "end": "4241640"
  },
  {
    "text": "and then you can\niterate very fast. So, and-- so the\nflip side is, this",
    "start": "4241640",
    "end": "4254090"
  },
  {
    "text": "is opposed to\nanother model, which is that you change your\nproof in some part, you have to redo\nall the other parts.",
    "start": "4254090",
    "end": "4259760"
  },
  {
    "text": "And so that would\nbe much slower. So this is about this kind\nof tricks that I realized.",
    "start": "4259760",
    "end": "4266630"
  },
  {
    "text": "So if you can do\nsomething small, like these kind of\nabstract things very fast,",
    "start": "4266630",
    "end": "4271940"
  },
  {
    "text": "then you can iterate\nfaster in your research. Anyway. So far, it makes sense?",
    "start": "4271940",
    "end": "4281010"
  },
  {
    "text": "And if you really care about\nwhy this inequality is true-- why this inequality is true--",
    "start": "4281010",
    "end": "4286280"
  },
  {
    "text": "I think I was trying to justify\nwhy it's true, because you can just use Holder inequality. I guess, if you apply\nthe Holder inequality,",
    "start": "4286280",
    "end": "4292190"
  },
  {
    "text": "you get something like this. And this is still not\nexactly like this, I think. So actually, this is\nexactly like this, right?",
    "start": "4292190",
    "end": "4298730"
  },
  {
    "text": "Because you have to choose-- you can choose your ai to be--",
    "start": "4298730",
    "end": "4304870"
  },
  {
    "text": "you just say ai cubed maps\nto this, and bi maps to this.",
    "start": "4304870",
    "end": "4313660"
  },
  {
    "text": "If you just want\nto verify, right? You just have to\nchange it, right? So-- but again, if you have\nto verify this by matching,",
    "start": "4313660",
    "end": "4322130"
  },
  {
    "text": "it is still too slow to me. So what I do is I also memorize\nother different versions of this whole inequality\nso that I can do it faster.",
    "start": "4322130",
    "end": "4330099"
  },
  {
    "text": "I think the version I\nmemorized in my mind is that-- at least one version of the\nHolder inequality in my mind",
    "start": "4330100",
    "end": "4335680"
  },
  {
    "text": "that I memorize\nis this, which is something like sum of ui square\nbecomes 1/3 times the sum",
    "start": "4335680",
    "end": "4348239"
  },
  {
    "text": "of vi 2/3. It's larger than sum ui vi 2/3.",
    "start": "4348240",
    "end": "4356640"
  },
  {
    "text": " Something like this, which is\neven closer to here, right?",
    "start": "4356640",
    "end": "4364019"
  },
  {
    "text": "Because in some sense-- and sometimes the\nway you memorize it is that if you have a bigger\ncomponent, exponent here too,",
    "start": "4364020",
    "end": "4371400"
  },
  {
    "text": "then these two\nwill go to the vi. ",
    "start": "4371400",
    "end": "4377390"
  },
  {
    "text": "How do I say this? So basically you put the-- so like-- so why this is ui\nto the power of 3, right?",
    "start": "4377390",
    "end": "4384230"
  },
  {
    "text": "So why this is ui to the 2/3? This is because here\nis you have a square, and then you have a 1/3 outside.",
    "start": "4384230",
    "end": "4391190"
  },
  {
    "text": "And the reason why here you\nhave vi to the power of 2/3 is because you inside you\nhave vi, the linear term,",
    "start": "4391190",
    "end": "4396320"
  },
  {
    "text": "on the outside you have the 2/3. So if you know\nthat, and you know that if you have a\nsquare here, then you",
    "start": "4396320",
    "end": "4402950"
  },
  {
    "text": "can cancel this epsilon\ni because epsilon i will be squared and here you\nhave epsilon i squared,",
    "start": "4402950",
    "end": "4408020"
  },
  {
    "text": "so they can cancel each other. I'm not sure why\nthis make any sense. It takes probably some practice.",
    "start": "4408020",
    "end": "4414320"
  },
  {
    "text": "If you see this\nenough times, you know what kind of\ninequalities you can put. ",
    "start": "4414320",
    "end": "4420949"
  },
  {
    "text": "Anyway, I guess I probably\nshould wrap up this discussion. Any questions?",
    "start": "4420950",
    "end": "4425989"
  },
  {
    "start": "4425990",
    "end": "4434400"
  },
  {
    "text": "OK. I think-- let's see. ",
    "start": "4434400",
    "end": "4439490"
  },
  {
    "text": "10 minutes. ",
    "start": "4439490",
    "end": "4452838"
  },
  {
    "text": "OK, so I guess I'll use the\nnext 10 minutes to motivate what I'm going to discuss next. Go ahead. What part is this from?",
    "start": "4452838",
    "end": "4460148"
  },
  {
    "text": "This inequality? Yes. Because the inequality\ncan be achieved. So that's why you know\nit's the best choice.",
    "start": "4460148",
    "end": "4466215"
  },
  {
    "text": "Oh, you mean the final box? Yeah. OK, yeah. Maybe let me discuss that. I'll answer that in the\nnext 10 minutes, yeah.",
    "start": "4466215",
    "end": "4472830"
  },
  {
    "text": " Right. OK, so-- so basically, now--",
    "start": "4472830",
    "end": "4478355"
  },
  {
    "text": "next, we're going\nto do something more better than this.",
    "start": "4478355",
    "end": "4484390"
  },
  {
    "text": "So-- and actually, it turns out\nthe proof is actually cleaner, to some extent.",
    "start": "4484390",
    "end": "4490558"
  },
  {
    "text": "Because-- in some\nsense, because it's capturing the right quantity. So-- so next we're going to\nhave generalization bounds that",
    "start": "4490558",
    "end": "4505820"
  },
  {
    "text": "depend on the actual\nLipschitzness.",
    "start": "4505820",
    "end": "4510860"
  },
  {
    "text": " And I'm going to argue that\nthe Lipschitzness we had before",
    "start": "4510860",
    "end": "4517880"
  },
  {
    "text": "was only upper bound, right? Before we had this-- right, before we\nhave this, right?",
    "start": "4517880",
    "end": "4524304"
  },
  {
    "text": "So before we have these\nbounds, but there you have essentially a dominating\nterm times other terms, which",
    "start": "4524304",
    "end": "4535450"
  },
  {
    "text": "is just a polynomial\nin the norm, which",
    "start": "4535450",
    "end": "4540803"
  },
  {
    "text": "is not very important. And this one, this\nis only an upper bound on the Lipschitzness.",
    "start": "4540803",
    "end": "4549315"
  },
  {
    "text": " All right, and it's a pretty\nworst case upper bound, because you have to-- if\nyou really want your network",
    "start": "4549315",
    "end": "4557540"
  },
  {
    "text": "to be-- to achieve this\nLipschitzness, you have to actually\nkind of construct",
    "start": "4557540",
    "end": "4564080"
  },
  {
    "text": "something that is kind of like\nsomewhat kind of like special. And even this is\nachievable, right?",
    "start": "4564080",
    "end": "4570065"
  },
  {
    "text": "This worst case upper bound can\nbe achievable in certain cases. Still, you want to find out\nthe network which is probably",
    "start": "4570065",
    "end": "4575900"
  },
  {
    "text": "better than this, empirically. So that's why we\nare going to have--",
    "start": "4575900",
    "end": "4582202"
  },
  {
    "text": "so basically, kind of\nthe high level goal is they want to replace this\nproduct of the spectral norm by something that\nis more accurate.",
    "start": "4582202",
    "end": "4592700"
  },
  {
    "text": "And there are many-- several motivations to do this. So I guess one thing is that-- and this relates to the\nlimitation of this bound.",
    "start": "4592700",
    "end": "4600200"
  },
  {
    "text": "So one thing is that\nthis wi operator norm has to be larger than 1,\nor even you can arguably say,",
    "start": "4600200",
    "end": "4611170"
  },
  {
    "text": "this is even larger\nthan square root 2, to make sure fx is\nnot too small, right?",
    "start": "4611170",
    "end": "4621010"
  },
  {
    "text": "Why this is the case? This is because if you\nlook at every layer, let's say hi is the i-th layer.",
    "start": "4621010",
    "end": "4626695"
  },
  {
    "text": " hi is the i-th layer.",
    "start": "4626695",
    "end": "4633480"
  },
  {
    "text": "Then hi plus 1, the true norm\nof it, is the true norm of this.",
    "start": "4633480",
    "end": "4642230"
  },
  {
    "text": "You apply this last layer. And if you do a\nheuristic, you say that suppose you believe that\nthis activation, this ReLU",
    "start": "4642230",
    "end": "4651380"
  },
  {
    "text": "activation, kills half of\nthe coordinates, all right? So it is 0 on top\nof the coordinates.",
    "start": "4651380",
    "end": "4657619"
  },
  {
    "text": "Suppose you have\nthat kind of like-- Then it means that\nafter a ReLU, your norm will reduce by 1 over\nsquare root of 2,",
    "start": "4657620",
    "end": "4664820"
  },
  {
    "text": "because you kill half\nof the coordinates. So of course, this\nis very heuristic.",
    "start": "4664820",
    "end": "4670820"
  },
  {
    "text": "This is just a belief,\nlike assumption. And suppose this is\nthe case, and then you",
    "start": "4670820",
    "end": "4676659"
  },
  {
    "text": "say that this is\nless than square root of 2 times the opposite\nnorm of wi times hi 2 norm.",
    "start": "4676660",
    "end": "4686110"
  },
  {
    "text": "So then you can\nsee that each time, you can only grow your\nnorm of hi by this factor.",
    "start": "4686110",
    "end": "4694550"
  },
  {
    "text": "So if wi operator norm is\nless than square root of 2, then you are shrinking\na norm over layers.",
    "start": "4694550",
    "end": "4701110"
  },
  {
    "text": "So your norm, every layer will\nbecome smaller and smaller and eventually they\nwill converge to 0. So your output\nwill be very small.",
    "start": "4701110",
    "end": "4707800"
  },
  {
    "text": "So that's why you have to make\nsure that the output norm of wi to be somewhat big.",
    "start": "4707800",
    "end": "4713380"
  },
  {
    "text": "It cannot be like too small. In the most optimist\ncase, I think",
    "start": "4713380",
    "end": "4718410"
  },
  {
    "text": "you want the optimum\nto be larger than 1. But in a kind of\nmore typical case, you need it even to be\nlarger than square root of 2.",
    "start": "4718410",
    "end": "4725440"
  },
  {
    "text": "So you are in the case, right? So this means that--",
    "start": "4725440",
    "end": "4732770"
  },
  {
    "text": "so in some sense, this means\nthat the product will be big.",
    "start": "4732770",
    "end": "4739830"
  },
  {
    "text": " Good.",
    "start": "4739830",
    "end": "4745500"
  },
  {
    "text": "So-- and another thing is that\nthe motivation too, I think,",
    "start": "4745500",
    "end": "4751878"
  },
  {
    "text": "this is something\nI mentioned, right? So this is only a\nworst case upper bound. It's very worst case\nof the Lipschitzness.",
    "start": "4751878",
    "end": "4762230"
  },
  {
    "text": "And in practice, so the\nLipschitzness on the data points--",
    "start": "4762230",
    "end": "4768990"
  },
  {
    "text": "the Lipschitzness\non the data point. ",
    "start": "4768990",
    "end": "4775750"
  },
  {
    "text": "x1 and up to xn might be better. ",
    "start": "4775750",
    "end": "4782850"
  },
  {
    "text": "All that Lipschitzness on\nthe population distribution, or maybe on the data\npoints, or maybe on the--",
    "start": "4782850",
    "end": "4788550"
  },
  {
    "text": " or an X from P, from the\npopulation distribution,",
    "start": "4788550",
    "end": "4796219"
  },
  {
    "text": "could be better. ",
    "start": "4796220",
    "end": "4801600"
  },
  {
    "text": "So at this point,\ndoesn't capture that. And another thing is\nthat, it turns out",
    "start": "4801600",
    "end": "4807640"
  },
  {
    "text": "that we're discussing this\nin the later lectures. So it turns out that SGD\nprefers flat local mean.",
    "start": "4807640",
    "end": "4820180"
  },
  {
    "text": "This is something we widely\nbelieved, and in certain cases, we can prove this. And the flat local mean\nis, roughly speaking,",
    "start": "4820180",
    "end": "4827900"
  },
  {
    "text": "we will show this-- we will\njustify this in later lectures. But roughly speaking,\nthis is the Lipschitzness",
    "start": "4827900",
    "end": "4836590"
  },
  {
    "text": "of the models. All the empirical data. ",
    "start": "4836590",
    "end": "4844330"
  },
  {
    "text": "So you can see that this\nis not a Lipschitzness. The worst case of\nLipschitzness on all the points is the Lipschitzness\non the empirical data.",
    "start": "4844330",
    "end": "4851890"
  },
  {
    "text": "So which further\njustifies I probably want to have a bound that\ndepends on the Lipschitzness",
    "start": "4851890",
    "end": "4857580"
  },
  {
    "text": "on the empirical data, but not\nthe Lipschitzness in the worst case. So-- and in some sense--\nand also another thing",
    "start": "4857580",
    "end": "4867040"
  },
  {
    "text": "is that-- another\nremark is that, it's OK to have a\ngeneralization bound that",
    "start": "4867040",
    "end": "4872530"
  },
  {
    "text": "depends on the empirical data. So, OK to make the\ngeneralization bound",
    "start": "4872530",
    "end": "4884300"
  },
  {
    "text": "depend on empirical\ndata x1 up to xn. ",
    "start": "4884300",
    "end": "4890500"
  },
  {
    "text": "And sometimes, this\nis actually nice, because suppose the\ngeneralization is",
    "start": "4890500",
    "end": "4900000"
  },
  {
    "text": "less than some function of the\nclassifier and x1 up to xn.",
    "start": "4900000",
    "end": "4907570"
  },
  {
    "text": "This is still useful because\nyou can still use this-- use it as an\nexpensive regularizer.",
    "start": "4907570",
    "end": "4914948"
  },
  {
    "text": " So there's no problem that\nyour generalization bound--",
    "start": "4914948",
    "end": "4920770"
  },
  {
    "text": "there is no problem for\nour generalization bound to depend on empirical data. You probably don't\nwant a generalization",
    "start": "4920770",
    "end": "4925800"
  },
  {
    "text": "bound to depend on\nthe population data because you don't know how\nto recognize it anymore.",
    "start": "4925800",
    "end": "4930940"
  },
  {
    "text": "But if it depends on\nempirical data, it's fine. So basically, concretely,\nin the next lecture,",
    "start": "4930940",
    "end": "4939037"
  },
  {
    "text": "I guess, we will prove that--  next lecture, we'll prove\nthat the generalization error,",
    "start": "4939037",
    "end": "4950630"
  },
  {
    "text": "or the test error of theta,\nis less than some function",
    "start": "4950630",
    "end": "4955909"
  },
  {
    "text": "of the Lipschitzness of\nf theta of x1 up to xn,",
    "start": "4955910",
    "end": "4963830"
  },
  {
    "text": "and then the norms of theta. And its function is a\npolynomial function,",
    "start": "4963830",
    "end": "4969390"
  },
  {
    "text": "which doesn't have\nanything exponential in it. ",
    "start": "4969390",
    "end": "4977560"
  },
  {
    "text": "OK, I guess I'll stop here. Any questions? ",
    "start": "4977560",
    "end": "4986978"
  },
  {
    "text": "And interestingly, the\nproof for the next lecture is actually easier\nthan today, I hope. I don't know how you think\nabout the proof today.",
    "start": "4986978",
    "end": "4994580"
  },
  {
    "text": "It's pretty brute force. So in that sense, it's\nactually not very hard. But it's pretty messy. ",
    "start": "4994580",
    "end": "5006440"
  },
  {
    "text": "I guess I will\nsee you next week. ",
    "start": "5006440",
    "end": "5015000"
  }
]
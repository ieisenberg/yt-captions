[
  {
    "start": "0",
    "end": "5159"
  },
  {
    "text": "Hi, everyone. Welcome to the fourth lecture. Today we'll be talking\nabout optimization-based",
    "start": "5159",
    "end": "10310"
  },
  {
    "text": "meta-learning. Before that, a\ncouple of reminders. Homework 1 is due on Wednesday,\nso a week from today.",
    "start": "10310",
    "end": "17930"
  },
  {
    "text": "We're also going to post some\nproject idea suggestions later today.",
    "start": "17930",
    "end": "23450"
  },
  {
    "text": "This won't be enough,\nwe'll hopefully have around 10 to 20\nproduct suggestions. So I wouldn't\nnecessarily rely on these",
    "start": "23450",
    "end": "30157"
  },
  {
    "text": "to figure out exactly what\nyour project should be. But if you want\nsome inspiration, this should\nhopefully be helpful.",
    "start": "30157",
    "end": "36095"
  },
  {
    "text": " OK, so for today, we're\ngoing to just briefly recap",
    "start": "36095",
    "end": "42240"
  },
  {
    "text": "some of the stuff that\nwe talked about on Monday with the meta-learning\nproblem statement and black-box\nmeta-learning methods.",
    "start": "42240",
    "end": "47520"
  },
  {
    "text": "And then, we're\ngoing to dive into optimization-based\napproaches to meta-learning.",
    "start": "47520",
    "end": "53780"
  },
  {
    "text": "And, kind of,\noptimization-based meta-learning will be part of homework\n2, so this should",
    "start": "53780",
    "end": "60500"
  },
  {
    "text": "be pretty helpful for that. And so the goals by\nthe end of this lecture are to try to understand\noptimization-based",
    "start": "60500",
    "end": "67159"
  },
  {
    "text": "meta-learning\ntechniques, including how to implement\nthem, and trade-offs between black-box approaches\nthat we talked about on Monday",
    "start": "67160",
    "end": "74000"
  },
  {
    "text": "and optimization-based\napproaches that we're talking about today.  OK, so to recap what we\ntalked about on Monday,",
    "start": "74000",
    "end": "80870"
  },
  {
    "text": "we introduced the meta-learning\nproblem statement, which is to quickly learn a new\ntask, give an experience",
    "start": "80870",
    "end": "86330"
  },
  {
    "text": "from some set of previous tasks. And this is different from\nthe multi-task learning problem in the sense\nthat you ultimately",
    "start": "86330",
    "end": "92750"
  },
  {
    "text": "want to solve a new task. And this is a bit\ndifferent than the transfer learning problem in\nthat you are given data",
    "start": "92750",
    "end": "98270"
  },
  {
    "text": "from a number of previous tasks. And in terms of\nthe methods, we'll actually see that\nmeta-learning methods actually",
    "start": "98270",
    "end": "104120"
  },
  {
    "text": "optimize for transferability,\nwhereas transfer learning methods don't do that.",
    "start": "104120",
    "end": "110720"
  },
  {
    "text": "In general, in transfer\nlearning and meta-learning, it's impractical to access\nthe previous tasks when you're trying to learn a new task.",
    "start": "110720",
    "end": "117170"
  },
  {
    "text": "Really, the dream\nis to be able to-- essentially be able to solve\na new task very quickly",
    "start": "117170",
    "end": "122900"
  },
  {
    "text": "with some parameters\nrather than having to iterate over all of the\ndata from the previous tasks.",
    "start": "122900",
    "end": "131282"
  },
  {
    "text": "In all of these\nsettings, the tasks should share some\nstructure, otherwise you're better off\nlearning from scratch.",
    "start": "131282",
    "end": "136445"
  },
  {
    "text": " All right. We also looked at an example\nmeta-learning problem, which",
    "start": "136445",
    "end": "141735"
  },
  {
    "text": "was a 5-way 1-shot image\nclassification problem where you're given five examples,\nbasically a little mini",
    "start": "141735",
    "end": "148520"
  },
  {
    "text": "training data set,\nand you want to be able to generalize\nto new examples using this training data set.",
    "start": "148520",
    "end": "153817"
  },
  {
    "text": "And the way that meta-learning\nalgorithms approach this problem is they assume that\nthey have data from other image",
    "start": "153817",
    "end": "160400"
  },
  {
    "text": "classes, and they structure\nthese into train sets and test sets and\ntraining models such that after it sees the\ntraining data set it",
    "start": "160400",
    "end": "166370"
  },
  {
    "text": "can generalize to new examples. So these are the\ntraining classes, and then we use these to try to\ngeneralize to held-out classes.",
    "start": "166370",
    "end": "175489"
  },
  {
    "text": "And this is one\nexample, but you can replace image classification\nwith other machine learning problems. ",
    "start": "175490",
    "end": "182163"
  },
  {
    "text": "OK, and then the last thing\nthat we talked about on Monday was a kind of black-box\napproach to meta-learning",
    "start": "182163",
    "end": "187490"
  },
  {
    "text": "where essentially what\nyou do is you just pass in the entire training\ndata set into a neural network",
    "start": "187490",
    "end": "192800"
  },
  {
    "text": "and that generates the weights\nor some low dimensional context vector. And that's used to predict\nthe label for new examples.",
    "start": "192800",
    "end": "204150"
  },
  {
    "text": "And so the general form\nof these kinds of models is something that takes\nas input the training data set and a new example,\nand is trained",
    "start": "204150",
    "end": "210349"
  },
  {
    "text": "to output the correct\nlabel for that example. ",
    "start": "210350",
    "end": "215427"
  },
  {
    "text": "The pros of this\napproach is that it's a very expressive\nneural network, very general form of\nrepresenting a learning",
    "start": "215427",
    "end": "222140"
  },
  {
    "text": "procedure. The downside is that it's a\nvery challenging optimization problem to learn how\nto learn from scratch.",
    "start": "222140",
    "end": "231125"
  },
  {
    "text": "So in this lecture,\nwe're going to be talking about a different way to\nrepresent this kind of learning",
    "start": "231125",
    "end": "236390"
  },
  {
    "text": "procedure rather\nthan representing it as a black-box neural network. And in particular, we're going\nto be thinking about actually",
    "start": "236390",
    "end": "242990"
  },
  {
    "text": "representing this learning\nprocedure as an optimization process with some\nparameters, such",
    "start": "242990",
    "end": "249319"
  },
  {
    "text": "that we can optimize the\nparameters of that optimization procedure to be able to perform\nwell with small data sets.",
    "start": "249320",
    "end": "255819"
  },
  {
    "text": " OK, so exactly--\nwhat this exactly",
    "start": "255820",
    "end": "262220"
  },
  {
    "text": "looks like is instead of passing\nthese data points into a data set, we're going to\nrun some optimization",
    "start": "262220",
    "end": "269240"
  },
  {
    "text": "procedure like gradient descent\non our training data set. And this optimization procedure\nwill have some free parameters.",
    "start": "269240",
    "end": "278150"
  },
  {
    "text": "And so, really, the key idea\nof these optimization-based approaches is to try to\nembed an optimization",
    "start": "278150",
    "end": "283460"
  },
  {
    "text": "inside the meta-learning process\nso that that optimization procedure does well.",
    "start": "283460",
    "end": "289039"
  },
  {
    "text": " So overall, one\nquestion is, well, why might this make sense?",
    "start": "289040",
    "end": "295080"
  },
  {
    "text": "Well, recall we saw\nfine-tuning last time as well. We saw that fine-tuning\nworks pretty well.",
    "start": "295080",
    "end": "300943"
  },
  {
    "text": "It doesn't work\nthat well when you have a very small number of\ndata points, but in general,",
    "start": "300943",
    "end": "307069"
  },
  {
    "text": "it's already doing a lot better\nthan learning from scratch. So essentially, what\nwe can try to do",
    "start": "307070",
    "end": "314360"
  },
  {
    "text": "is instead of\nrunning fine-tuning from a set of\npre-trained parameters,",
    "start": "314360",
    "end": "319790"
  },
  {
    "text": "we could actually\ntry to optimize for a set of\npre-trained parameters and other aspects of this\nfine-tuning procedure in a way",
    "start": "319790",
    "end": "326840"
  },
  {
    "text": "that that fine-tuning procedure\nworks well for small data sets.",
    "start": "326840",
    "end": "332480"
  },
  {
    "text": "And so in particular,\nwe want to just be able to run an optimization\nprocedure at test-time",
    "start": "332480",
    "end": "337850"
  },
  {
    "text": "with our small data set. And what we're going to do is\nwe'll take this fine-tuning",
    "start": "337850",
    "end": "343160"
  },
  {
    "text": "procedure, and we\nwant to optimize such that this fine-tuning\nprocedure generalizes well",
    "start": "343160",
    "end": "348830"
  },
  {
    "text": "to test examples. And so we want to take the\nresults of this fine-tuning procedure and optimize for\nhow well those parameters",
    "start": "348830",
    "end": "356090"
  },
  {
    "text": "generalize to test data points. And in the simplest--\nthe simplest way",
    "start": "356090",
    "end": "362600"
  },
  {
    "text": "that we could do\nthis is actually to optimize this\nobjective with respect to the pre-trained parameters.",
    "start": "362600",
    "end": "368867"
  },
  {
    "text": "So we're going to optimize for\na set of pre-trained parameters such that fine-tuning\ngeneralizes",
    "start": "368867",
    "end": "373940"
  },
  {
    "text": "well with a small data set. And we'll be doing this over\nall of the meta-training tasks,",
    "start": "373940",
    "end": "382700"
  },
  {
    "text": "so that we were hopefully\ngiven a new task that pre-trained\nparameters, that set of pre-trained parameters works\nwell for new related tasks.",
    "start": "382700",
    "end": "390139"
  },
  {
    "text": " So, really, the key\nidea here is to try",
    "start": "390140",
    "end": "395270"
  },
  {
    "text": "to learn a parameter vector\ntheta that transfers very well with fine-tuning even\nwhen fine-tuning operates",
    "start": "395270",
    "end": "402260"
  },
  {
    "text": "with a very small data set.  Now, one way to\nvisually depict this",
    "start": "402260",
    "end": "408500"
  },
  {
    "text": "is something like the following. So theta-- say that\ntheta is the, kind of, the initialization, the\nparameter vector that you're",
    "start": "408500",
    "end": "414440"
  },
  {
    "text": "meta-learning, and maybe phi i\nstar is the optimal parameter vector for task i.",
    "start": "414440",
    "end": "421130"
  },
  {
    "text": "Then you can\nessentially think of it in some way as this\nillustration right here where when you're at this\npoint during the meta-training",
    "start": "421130",
    "end": "427758"
  },
  {
    "text": "process and you take a\ngradient step with respect to task three, you're quite\nfar from the optimum for task",
    "start": "427758",
    "end": "432830"
  },
  {
    "text": "three. Whereas, kind of, at the end\nof the meta-training process, if you take a gradient step\nwith respect to task three,",
    "start": "432830",
    "end": "438362"
  },
  {
    "text": "you want to be very close to\nthe optimum for task three, even if that gradient step is\nwith respect to a tiny data",
    "start": "438362",
    "end": "445080"
  },
  {
    "text": "set.  OK, so this particular\nprocedure is referred",
    "start": "445080",
    "end": "451100"
  },
  {
    "text": "to as model-agnostic\nmeta-learning in the sense that it is agnostic to the\nmodel that you're using,",
    "start": "451100",
    "end": "457460"
  },
  {
    "text": "as long as that model can be-- it's kind of\namenable to gradient",
    "start": "457460",
    "end": "462800"
  },
  {
    "text": "descent-based optimization. ",
    "start": "462800",
    "end": "468919"
  },
  {
    "text": "Great. So a couple of questions here. You might notice that\nthere is one gradient step in this objective here.",
    "start": "468920",
    "end": "475110"
  },
  {
    "text": "I'm writing that for simplicity. In many cases, actually\njust a single gradient step can actually perform quite well.",
    "start": "475110",
    "end": "481060"
  },
  {
    "text": "But you can also replace that\nwith multiple gradient steps and optimize such that a\nfew steps of fine-tuning",
    "start": "481060",
    "end": "486480"
  },
  {
    "text": "works well. Yeah? ",
    "start": "486480",
    "end": "492780"
  },
  {
    "text": "I'm curious about\nwhat the spacing-- what's the space\ncontrol in the picture",
    "start": "492780",
    "end": "497830"
  },
  {
    "text": "facing the parameter space? Yeah. So the question is, is this\npicture in the parameter space?",
    "start": "497830",
    "end": "504280"
  },
  {
    "text": "And, yeah. So this is trying to depict\nlike a 2D parameter space, essentially.",
    "start": "504280",
    "end": "509340"
  },
  {
    "text": "So my next question would\nbe, what if three models",
    "start": "509340",
    "end": "514380"
  },
  {
    "text": "from the three [INAUDIBLE]\nJust for example,",
    "start": "514380",
    "end": "519590"
  },
  {
    "text": "for two models, if one they\nhave opposite directions,",
    "start": "519590",
    "end": "524800"
  },
  {
    "text": "so the matched direction\nwould be [INAUDIBLE].. ",
    "start": "524800",
    "end": "535750"
  },
  {
    "text": "Would that be possible? If you're wondering what if the\nmeta-learning procedure ends up at a point that is the\noptimum for one of the tasks.",
    "start": "535750",
    "end": "543120"
  },
  {
    "text": "And the gradient would\nbe 0 in that case. Is that what you're asking? Yes. Yeah. So in that case, that's fine.",
    "start": "543120",
    "end": "549160"
  },
  {
    "text": "The gradient will be 0,\nand then, for that task, it will do well for that task. As long as it also can get\nto a good optimum for all",
    "start": "549160",
    "end": "558654"
  },
  {
    "text": "of the tasks in your\ntraining data set, not just a single task. Yeah. If we want to get to update\na vector, [INAUDIBLE]",
    "start": "558655",
    "end": "566714"
  },
  {
    "text": "at this point, doesn't this\nassume that each of the phis are-- each of the optimal phis\nare kind of close together",
    "start": "566714",
    "end": "573000"
  },
  {
    "text": "in the parameter space? Yeah. So the question is,\ndoes this assume that the optimum\nare kind of close together in the parameter space?",
    "start": "573000",
    "end": "580840"
  },
  {
    "text": "And one thing that\nI'll mention here is I think that this graphic\nis helpful for understanding the algorithm and\nvisualizing it.",
    "start": "580840",
    "end": "587410"
  },
  {
    "text": "But in reality, you won't\njust have a single optimum-- a single good parameter\nthat's good for that task.",
    "start": "587410",
    "end": "594210"
  },
  {
    "text": "In reality, you actually have\nan entire space of parameters that is useful for that task. And especially as you move\ninto higher dimensions,",
    "start": "594210",
    "end": "601080"
  },
  {
    "text": "the space of optimal solutions\nand good solutions for a given task will get larger.",
    "start": "601080",
    "end": "610120"
  },
  {
    "text": "And so that's one thing is\nthat usually it's not just a single point.",
    "start": "610120",
    "end": "615340"
  },
  {
    "text": "And then second,\nif you allow this to use a relatively\nlarge step size",
    "start": "615340",
    "end": "621180"
  },
  {
    "text": "or use multiple\ngradient steps, that allows it to potentially move\nfurther in parameter space.",
    "start": "621180",
    "end": "626800"
  },
  {
    "text": "That said, it is kind\nof implicitly making some assumption that you can-- there is a spot\nwhere you can get",
    "start": "626800",
    "end": "633120"
  },
  {
    "text": "to a good performance\nfor each of the tasks within a small number\nof gradient steps. And so that is some\nimplicit assumption.",
    "start": "633120",
    "end": "640500"
  },
  {
    "text": "In practice, we actually find\nthat assumption, or at least",
    "start": "640500",
    "end": "645810"
  },
  {
    "text": "the algorithm works well in\na wide variety of problems. ",
    "start": "645810",
    "end": "652920"
  },
  {
    "text": "Yeah. Just to clarify, what if the\nalgorithm is not necessarily defined on the [INAUDIBLE]\nbecause it's already",
    "start": "652920",
    "end": "659696"
  },
  {
    "text": "good at doing its task, but\nto find a theta such that, with just a few number\nof additional steps, can",
    "start": "659696",
    "end": "667019"
  },
  {
    "text": "we predict any task\nthat it could do Yeah, that's a\ngreat way to put it. So essentially, the\ngoal of the algorithm is not to get a parameters--\na set of parameters that",
    "start": "667020",
    "end": "674332"
  },
  {
    "text": "works well for all the tasks. Instead, it's to get to a\nspace in parameter space such that you can quickly get\nto a good solution for each",
    "start": "674332",
    "end": "681930"
  },
  {
    "text": "of the tasks. Yeah? I meant to clarify, once\nyou get your test task,",
    "start": "681930",
    "end": "687529"
  },
  {
    "text": "you train it on the training\ndata from the test task, with a couple of false routes. Yeah, exactly. Then--",
    "start": "687530",
    "end": "692885"
  },
  {
    "text": "[INAUDIBLE] about the training. Yeah. Yeah. So when you're given a\nnew task, then you just have these set of parameters.",
    "start": "692885",
    "end": "698340"
  },
  {
    "text": "And then you can essentially\njust run fine-tuning, a few steps of fine-tuning. You could also run more\nsteps of fine-tuning potentially, if you\nhave the compute.",
    "start": "698340",
    "end": "706258"
  },
  {
    "text": "Yeah. [INAUDIBLE] Yeah.",
    "start": "706258",
    "end": "711430"
  },
  {
    "text": "So in this case, you can have\nalpha just be a hyperparameter. You can also actually\nlearn alpha as well.",
    "start": "711430",
    "end": "718450"
  },
  {
    "text": "And we'll talk about\nthat in a few slides. ",
    "start": "718450",
    "end": "723630"
  },
  {
    "text": "OK. This picture kind of looks\nlike the best they got is just an average\nnumber of [INAUDIBLE]..",
    "start": "723630",
    "end": "731598"
  },
  {
    "text": "Is there a comparison of\n[INAUDIBLE] or [INAUDIBLE] different estimates?",
    "start": "731598",
    "end": "738500"
  },
  {
    "text": "Yeah. So the question is, it looks\nlike the optimal is just kind of almost averaging.",
    "start": "738500",
    "end": "744200"
  },
  {
    "text": "It's not quite averaging,\nbut in this picture it looks like it's\nsimilar to averaging. And how does it compare\nto simply averaging good parameters?",
    "start": "744200",
    "end": "751040"
  },
  {
    "text": "One of the things that actually\nmakes averaging not necessarily perform well is\nthat if you actually have a very large space of\nparameters that works well",
    "start": "751040",
    "end": "758060"
  },
  {
    "text": "for each task, if you\noptimize each of them independently and\nthen take the average, you may actually end up--",
    "start": "758060",
    "end": "763880"
  },
  {
    "text": "depending on where those\noptimizations landed, you may actually end up at\na point that is actually potentially very weird and not\nvery good in parameter space.",
    "start": "763880",
    "end": "774480"
  },
  {
    "text": "And so in practice,\naveraging usually doesn't perform as well.",
    "start": "774480",
    "end": "780410"
  },
  {
    "text": "Yeah. Yeah? And do we [INAUDIBLE]\nwith the [INAUDIBLE] test tasks so we have\nsome labels associated",
    "start": "780410",
    "end": "788240"
  },
  {
    "text": "with that test task to\nactually run that [INAUDIBLE]?? Yeah, exactly. So we're operating in\nthe few-shot learning",
    "start": "788240",
    "end": "793542"
  },
  {
    "text": "procedure, where we have a small\nnumber of labeled examples. And we're running\ngradient descent on those labeled examples.",
    "start": "793542",
    "end": "799560"
  },
  {
    "text": "OK. I'm going to run\nthrough the algorithm, then we can maybe get\nthrough some more questions. So, if we recall the approach\nfor black-box meta-learning,",
    "start": "799560",
    "end": "808640"
  },
  {
    "text": "we sampled the task. We sample these data sets. We compute the parameters\nusing our black-box model and then update the\nparameter's theta",
    "start": "808640",
    "end": "817009"
  },
  {
    "text": "by kind of differentiating\nthrough that black-box model. Really, the only thing\nthat is different",
    "start": "817010",
    "end": "822500"
  },
  {
    "text": "with the\noptimization-based approach is, instead of optimizing the\nparameters by passing them",
    "start": "822500",
    "end": "828110"
  },
  {
    "text": "through this black-box\nneural network, instead we're going to be running\none or a few steps",
    "start": "828110",
    "end": "833120"
  },
  {
    "text": "of gradient descent. And that's basically it. That's the only difference\nfrom the black-box approaches.",
    "start": "833120",
    "end": "841580"
  },
  {
    "text": " So, now there's a\ncouple of things",
    "start": "841580",
    "end": "847580"
  },
  {
    "text": "that's worth mentioning\nhere that you might notice. So the first is that we\nhave a gradient here.",
    "start": "847580",
    "end": "855079"
  },
  {
    "text": "We're kind of running gradient\ndescent on our objective, on our meta-objective.",
    "start": "855080",
    "end": "861000"
  },
  {
    "text": "And there's also a gradient,\nwith respect to theta, inside that objective.",
    "start": "861000",
    "end": "867140"
  },
  {
    "text": "And as a result, this means\nthat we are actually getting second-order derivatives in this\noptimization problem because we",
    "start": "867140",
    "end": "875000"
  },
  {
    "text": "are taking-- we have a gradient and\nwe have another gradient. So we're taking the gradient of\na gradient, which will give us",
    "start": "875000",
    "end": "882213"
  },
  {
    "text": "a second derivative. And so you might be\nwondering, maybe we actually have to compute the\nfull Hessian, which",
    "start": "882213",
    "end": "888829"
  },
  {
    "text": "would be rather unfortunate\nbecause the Hessian will be-- if you have a neural network\nof size with parameters,",
    "start": "888830",
    "end": "895730"
  },
  {
    "text": "with n parameters, then the\nfull Hessian will be n times n. And we don't want to have\nto compute something that's",
    "start": "895730",
    "end": "901310"
  },
  {
    "text": "quadratic in our parameters. Another thing that\nyou might notice as well, what if we\nrun multiple gradient",
    "start": "901310",
    "end": "907038"
  },
  {
    "text": "steps in the inner loop? Does that mean\nthat we'll actually get higher-order derivatives,\nlike third-order derivatives?",
    "start": "907038",
    "end": "914570"
  },
  {
    "text": "And so I'll run\nthrough the answer to these questions\non the whiteboard.",
    "start": "914570",
    "end": "920630"
  },
  {
    "text": "But I'm curious if anyone\nhas any initial thoughts on whether we need to\ncompute the full Hessian,",
    "start": "920630",
    "end": "926899"
  },
  {
    "text": "or whether we need\nhigher-order derivatives. ",
    "start": "926900",
    "end": "935889"
  },
  {
    "text": "Any thoughts? Yeah? I think the answer to\nthe second question is no because [INAUDIBLE].",
    "start": "935890",
    "end": "949640"
  },
  {
    "start": "949640",
    "end": "955090"
  },
  {
    "text": "Yeah, I don't think\nwe need [INAUDIBLE] because the meta-gradient's only\nhappening, instead of happening",
    "start": "955090",
    "end": "962750"
  },
  {
    "text": "once so I think that\nsecond-order gradient happens in step four, but not\nnecessarily would happen",
    "start": "962750",
    "end": "968666"
  },
  {
    "text": "in step two and step three. Yeah. So I can first go over with\nyou the second question. And the answer is indeed no.",
    "start": "968666",
    "end": "974720"
  },
  {
    "text": "And the reason for that is\nthat when you are computing phi",
    "start": "974720",
    "end": "980439"
  },
  {
    "text": "i, when you're trying\nto kind of estimate the parameters for a task,\nif you run multiple gradient",
    "start": "980440",
    "end": "985810"
  },
  {
    "text": "steps in the inner\nloop, then this is going to be theta minus\nthe gradient of L of theta",
    "start": "985810",
    "end": "996228"
  },
  {
    "text": "on the training data set. And then when you take\nthe second gradient step, you're going to be taking\nthat at the value of this.",
    "start": "996228",
    "end": "1004870"
  },
  {
    "text": "So if we refer to\nthis as theta prime, then the next time we take\nthe gradient it will be--",
    "start": "1004870",
    "end": "1011910"
  },
  {
    "text": "the second gradient step will\nbe with respect to theta prime, rather than with\nrespect to theta. ",
    "start": "1011910",
    "end": "1021870"
  },
  {
    "text": "And then when you\neventually need to differentiate all of\nthis with respect to theta,",
    "start": "1021870",
    "end": "1027359"
  },
  {
    "text": "you don't actually\never see any-- there aren't any\nsecond-order terms in here. And so when you need\nto differentiate theta",
    "start": "1027359",
    "end": "1033810"
  },
  {
    "text": "through here, you only get\nsecond-order terms coming up in terms of the gradient\nof the meta-objective",
    "start": "1033810",
    "end": "1039990"
  },
  {
    "text": "and no third-order\nterms, for example. ",
    "start": "1039990",
    "end": "1045859"
  },
  {
    "text": "Yeah? I want to cheat a little\nbit because I heard of a [INAUDIBLE] where you can\nuse some kind of a regularizer,",
    "start": "1045859",
    "end": "1054140"
  },
  {
    "text": "like some kind of\nquadratic regulizer with-- and make sure that\nphi is close to theta.",
    "start": "1054140",
    "end": "1059660"
  },
  {
    "text": "And that [INAUDIBLE]\nsolution that doesn't need to use a full\nHessian to run [INAUDIBLE]..",
    "start": "1059660",
    "end": "1064920"
  },
  {
    "text": "Yeah. So the suggestion\nwas that there's an algorithm called\niMAML, that we'll actually",
    "start": "1064920",
    "end": "1070010"
  },
  {
    "text": "cover in several slides,\nthat can actually get away from using the full Hessian\nby using what's called",
    "start": "1070010",
    "end": "1076700"
  },
  {
    "text": "the implicit function theorem. But I guess, even for the\noriginal MAML algorithm,",
    "start": "1076700",
    "end": "1082159"
  },
  {
    "text": "I'm wondering-- not the\niMAML algorithm-- even for the original\nMAML algorithm, do we need to compute\nthe full Hessian?",
    "start": "1082160",
    "end": "1088940"
  },
  {
    "text": "Yeah? Can we use natural gradients? So the question is, can\nwe use natural gradient?",
    "start": "1088940",
    "end": "1095770"
  },
  {
    "text": "Instead of Hessian. Instead of Hessian? ",
    "start": "1095770",
    "end": "1101341"
  },
  {
    "text": "You might be close,\nbut I'm not sure. Do you have a thought?",
    "start": "1101341",
    "end": "1107800"
  },
  {
    "text": "Or you could just\nignore the Hessian? You could. OK, you could just\nignore the Hessian. You could throw away the\nsecond-order gradients",
    "start": "1107800",
    "end": "1114676"
  },
  {
    "text": "and derive a first-order\nversion of the algorithm. And actually, the\nfirst-order version sometimes performs surprisingly well.",
    "start": "1114676",
    "end": "1120130"
  },
  {
    "text": "But that's not quite\nwhat I'm looking for.",
    "start": "1120130",
    "end": "1125725"
  },
  {
    "text": "Yeah? Can you approximate the\nHessian, like, [INAUDIBLE]??",
    "start": "1125725",
    "end": "1132480"
  },
  {
    "text": "So, you could try to\napproximate the Hessian. That would still not\ngive you the kind of exact meta-gradient.",
    "start": "1132480",
    "end": "1138659"
  },
  {
    "text": "But it's definitely\na valid solution. Could you alternate [INAUDIBLE]\nsomething-- can you alternate",
    "start": "1138660",
    "end": "1144750"
  },
  {
    "text": "which [INAUDIBLE] for? Can you go back and forth\nbetween that [INAUDIBLE] algorithm? So you're thinking\nof a procedure",
    "start": "1144750",
    "end": "1150090"
  },
  {
    "text": "where you kind of\nalternate between the two? I'm not sure how\nexactly that would work.",
    "start": "1150090",
    "end": "1157170"
  },
  {
    "text": "OK. Maybe I'll go\nthrough the answer. So, and actually\nthis will involve",
    "start": "1157170",
    "end": "1163322"
  },
  {
    "text": "a little bit of a digression. So one thing that's pretty\ncool that I didn't know about,",
    "start": "1163322",
    "end": "1168930"
  },
  {
    "text": "actually, for-- until some time is,\nif you have a Hessian,",
    "start": "1168930",
    "end": "1174518"
  },
  {
    "text": "in many cases, when you actually\nneed to compute the Hessian, you only need to compute\nHessian vector products. And so, say you have some\nfunction, f of theta,",
    "start": "1174518",
    "end": "1184350"
  },
  {
    "text": "and then maybe\nlet's use g of theta to denote the gradient of f. And let's use h of theta\nto denote the Hessian.",
    "start": "1184350",
    "end": "1196799"
  },
  {
    "text": "In many cases-- so computing\nthe full Hessian is very nasty.",
    "start": "1196800",
    "end": "1201870"
  },
  {
    "text": "But in many cases,\nwe actually only need to actually compute what's\ncalled the Hessian vector",
    "start": "1201870",
    "end": "1207030"
  },
  {
    "text": "product, which is basically the\nHessian multiplied by a vector.",
    "start": "1207030",
    "end": "1212790"
  },
  {
    "text": "And it turns out, as I'll show\nin a minute, when you actually",
    "start": "1212790",
    "end": "1219780"
  },
  {
    "text": "go about computing\nthis, you don't actually need to compute\nthe full Hessian. You essentially just need\nto compute a Hessian vector",
    "start": "1219780",
    "end": "1225690"
  },
  {
    "text": "product. And there are much cheaper ways\nto compute a Hessian vector product than constructing\nthe full Hessian",
    "start": "1225690",
    "end": "1231510"
  },
  {
    "text": "and then doing a matrix\nvector multiplication. ",
    "start": "1231510",
    "end": "1237030"
  },
  {
    "text": "I guess, with regard to the\npoint of actually approximating the Hessian, one\npretty cheap way",
    "start": "1237030",
    "end": "1242700"
  },
  {
    "text": "to actually estimate\nthis Hessian vector product is through something\ncalled finite differences,",
    "start": "1242700",
    "end": "1250620"
  },
  {
    "text": "where you essentially do finite\ndifferences on the gradient of the function.",
    "start": "1250620",
    "end": "1256570"
  },
  {
    "text": "And in particular,\nyou can write this as being approximately equal\nto the gradient of the function",
    "start": "1256570",
    "end": "1269190"
  },
  {
    "text": "evaluated at r times\nv minus the gradient",
    "start": "1269190",
    "end": "1275429"
  },
  {
    "text": "of the function divided by r. So essentially, this is just\ndoing finite differences",
    "start": "1275430",
    "end": "1281970"
  },
  {
    "text": "on your gradient. It's comparing the\ngradient after-- the gradient at the function\ncompared to the gradient",
    "start": "1281970",
    "end": "1289050"
  },
  {
    "text": "at the function plus-- plus v multiplied by some r.",
    "start": "1289050",
    "end": "1295260"
  },
  {
    "text": "And this becomes more and\nmore accurate when r is small. ",
    "start": "1295260",
    "end": "1302817"
  },
  {
    "text": "And one of the things\nthat's nice about this is that to compute\nthis, you actually just need to evaluate\nthe gradient twice.",
    "start": "1302817",
    "end": "1308550"
  },
  {
    "text": "You don't actually need to\ncompute the full Hessian.",
    "start": "1308550",
    "end": "1314610"
  },
  {
    "text": "Now, this is an approximate way\nto estimate this Hessian vector product.",
    "start": "1314610",
    "end": "1320280"
  },
  {
    "text": "There is actually\na more exact way that doesn't have\nnumerical stability.",
    "start": "1320280",
    "end": "1325973"
  },
  {
    "text": "You might notice that\nthere's an r here. And so if r is\nreally small, you're going to get numerical\nstability issues.",
    "start": "1325973",
    "end": "1331420"
  },
  {
    "text": "And so there's something called\nPearlmutter's method, which",
    "start": "1331420",
    "end": "1337500"
  },
  {
    "text": "is named after Pearlmutter. And that essentially\ngives you a way",
    "start": "1337500",
    "end": "1343542"
  },
  {
    "text": "to do something like this,\nexcept in a exact way that isn't numerically unstable.",
    "start": "1343542",
    "end": "1348780"
  },
  {
    "text": "Yeah? [INAUDIBLE] approximation\nthat [INAUDIBLE] to standard [INAUDIBLE] things\nlike TensorFlow and PyTorch",
    "start": "1348780",
    "end": "1355799"
  },
  {
    "text": "for second-order computations? Yeah. It's a great question. Does this, like TensorFlow and\nPyTorch already do this for you",
    "start": "1355800",
    "end": "1363419"
  },
  {
    "text": "and essentially do these\napproximation methods? And it essentially does.",
    "start": "1363420",
    "end": "1371520"
  },
  {
    "text": "I believe it uses Pearlmutter's\nmethod, which is actually an exact way that does\nsomething very similar to this,",
    "start": "1371520",
    "end": "1379240"
  },
  {
    "text": "except in a way that essentially\nis just about as expensive as computing a gradient. ",
    "start": "1379240",
    "end": "1386760"
  },
  {
    "text": "And so in some ways,\nyou don't actually need to worry about this at all\nbecause PyTorch or TensorFlow will do it all for you.",
    "start": "1386760",
    "end": "1392808"
  },
  {
    "text": "But I think it's\nuseful to understand that, when you're actually\nrunning this algorithm, TensorFlow and PyTorch doesn't\nneed to actually compute",
    "start": "1392808",
    "end": "1399660"
  },
  {
    "text": "the full Hessian in order\nto optimize this objective. ",
    "start": "1399660",
    "end": "1405250"
  },
  {
    "text": "Yeah? And for the line above,\nyou would apply then the [INAUDIBLE].",
    "start": "1405250",
    "end": "1411330"
  },
  {
    "text": "Yeah, exactly. So if our goal is to optimize--",
    "start": "1411330",
    "end": "1417240"
  },
  {
    "text": "essentially, we want\nto optimize the-- ",
    "start": "1417240",
    "end": "1424631"
  },
  {
    "text": "something like this, evaluated\non D test, which is equal to L",
    "start": "1424631",
    "end": "1431700"
  },
  {
    "text": "of theta minus alpha grad theta\nL D train evaluated at D test.",
    "start": "1431700",
    "end": "1441450"
  },
  {
    "text": "If we want to optimize this,\nwe can use the chain rule. And it will essentially\ngive us something-- when we take the gradient of\nthis with respect to theta,",
    "start": "1441450",
    "end": "1448240"
  },
  {
    "text": "we will get something that\nlooks like, essentially, dL d phi evaluated at phi\nequals 1 minus alpha grad times",
    "start": "1448240",
    "end": "1462930"
  },
  {
    "text": "d phi d theta. This is just using\nthe chain rule. This is the gradient\nof the outside. This is the gradient of the\ninside with respect to theta.",
    "start": "1462930",
    "end": "1474060"
  },
  {
    "text": "And this is just\nessentially the same as running back prop\nin the standard way through the neural network.",
    "start": "1474060",
    "end": "1480490"
  },
  {
    "text": "And this is where things get\na little bit more complicated.",
    "start": "1480490",
    "end": "1485520"
  },
  {
    "text": "Essentially, if we\nwant to evaluate the gradient of this\nwith respect to theta,",
    "start": "1485520",
    "end": "1494010"
  },
  {
    "text": "d phi d theta is-- we take the gradient of the\nfirst thing, which is just i. ",
    "start": "1494010",
    "end": "1501510"
  },
  {
    "text": "And then we take the\ngradient of the second thing, which is equal to the Hessian.",
    "start": "1501510",
    "end": "1507080"
  },
  {
    "start": "1507080",
    "end": "1513090"
  },
  {
    "text": "And so this is where\nthe Hessian pops up. But fortunately, when\nwe need the gradient of the entire expression,\nwe get this is a vector.",
    "start": "1513090",
    "end": "1520785"
  },
  {
    "text": "This is a row vector. This is a matrix. And we get this expression\ntimes this expression.",
    "start": "1520785",
    "end": "1527070"
  },
  {
    "text": "And so eventually we get\na Hessian vector product from here. Yeah? And then [INAUDIBLE] you\nintroduce the theta as, like,",
    "start": "1527070",
    "end": "1536750"
  },
  {
    "text": "prime, then we would\nhave theta prime. We would also have an actual\nderivative of theta prime",
    "start": "1536750",
    "end": "1542380"
  },
  {
    "text": "with respect to theta. Yeah. So, if you eventually\nhave two inner gradient",
    "start": "1542380",
    "end": "1548450"
  },
  {
    "text": "steps instead of one-- this is the gradient\nof phi with respect to theta for one gradient step.",
    "start": "1548450",
    "end": "1554360"
  },
  {
    "text": "If you have two, it ends\nup looking like the Hessian",
    "start": "1554360",
    "end": "1561290"
  },
  {
    "text": "at theta prime of L times\nd theta prime d theta.",
    "start": "1561290",
    "end": "1567695"
  },
  {
    "text": " And so this only has\nsecond-order terms in here.",
    "start": "1567695",
    "end": "1574460"
  },
  {
    "text": "We multiply this\nby the vector here. We actually get two\nHessian vector products. Once we have two\ninner gradient steps.",
    "start": "1574460",
    "end": "1580700"
  },
  {
    "text": "But we don't get any third-order\nterms, which is good news. ",
    "start": "1580700",
    "end": "1590990"
  },
  {
    "text": "OK, any questions on this? ",
    "start": "1590990",
    "end": "1596730"
  },
  {
    "text": "So to summarize,\nwe have a nice way to compute Hessian vector\nproducts that requires--",
    "start": "1596730",
    "end": "1601850"
  },
  {
    "text": "it takes about the\nkind of computation as taking one or\ntwo gradient steps.",
    "start": "1601850",
    "end": "1607110"
  },
  {
    "text": "And then, when we actually\nwrite out the objective, we get a row vector\ntimes a matrix.",
    "start": "1607110",
    "end": "1613379"
  },
  {
    "text": "And this matrix\nincludes Hessian terms. But luckily, we need to multiply\nthis by this row vector.",
    "start": "1613380",
    "end": "1621270"
  },
  {
    "text": "And that allows us to use\nthis efficient Hessian vector method for computing the\ngradient of the meta-objective.",
    "start": "1621270",
    "end": "1630970"
  },
  {
    "text": "Yeah? So that's the last\none on the last link that's if you take more\nthan two gradient steps?",
    "start": "1630970",
    "end": "1636090"
  },
  {
    "text": "Yeah. This is if you take two gradient\nsteps in the inner loop. If you take three gradient\nsteps in the inner loop, you'll have another term.",
    "start": "1636090",
    "end": "1641910"
  },
  {
    "start": "1641910",
    "end": "1647390"
  },
  {
    "text": "And I should maybe double check\nthat I actually did that right. Yeah, I think that that's right. ",
    "start": "1647390",
    "end": "1655150"
  },
  {
    "text": "Yeah? Does the [INAUDIBLE]\nhave to be the same in all the steps [INAUDIBLE]? Yeah, they don't\nneed to be the same.",
    "start": "1655150",
    "end": "1661102"
  },
  {
    "text": "And actually, there\nis a paper that showed that using different\ngradient steps for the two steps can be helpful, like a\nlarger one for the first step,",
    "start": "1661102",
    "end": "1667240"
  },
  {
    "text": "a smaller one for\nthe second step. I'm just doing that\nfor simplicity. ",
    "start": "1667240",
    "end": "1676110"
  },
  {
    "text": "OK. So now, how does\nthis approach compare",
    "start": "1676110",
    "end": "1682570"
  },
  {
    "text": "to the black-box approach? We saw that at the\nalgorithmic level it just corresponds to\nrunning a different inner loop",
    "start": "1682570",
    "end": "1689650"
  },
  {
    "text": "procedure for computing\ntask-specific parameters. And so if we look at the\nform of these two functions,",
    "start": "1689650",
    "end": "1697070"
  },
  {
    "text": "one is one where we kind\nof pass in the data set into a neural network. And then the other is\none where we essentially",
    "start": "1697070",
    "end": "1704620"
  },
  {
    "text": "are running gradient descent\non the training data set. And so in many ways, the\ngeneral form is the same.",
    "start": "1704620",
    "end": "1712510"
  },
  {
    "text": "Both of them are a\ncomputation graph that takes as input a training\ndata set and a test input.",
    "start": "1712510",
    "end": "1717752"
  },
  {
    "text": "But in one case, we're\njust passing all of that into a black-box neural network. And in the other case, we're\nrunning gradient descent",
    "start": "1717752",
    "end": "1723400"
  },
  {
    "text": "and evaluating the test input\non the updated parameters. ",
    "start": "1723400",
    "end": "1730880"
  },
  {
    "text": "So, yeah, essentially\nMAML can be viewed as just a\ndifferent computation graph that embeds this gradient\noperator into the computation",
    "start": "1730880",
    "end": "1738500"
  },
  {
    "text": "graph, which is\nin some ways very similar to the\nblack-box approach. We're just building in some more\nstructure about optimization",
    "start": "1738500",
    "end": "1745910"
  },
  {
    "text": "into that learning procedure. ",
    "start": "1745910",
    "end": "1751735"
  },
  {
    "text": "It's also worth mentioning\nthat you can potentially mix and match components of\nthese computation graphs.",
    "start": "1751735",
    "end": "1757520"
  },
  {
    "text": "And so, for example, you\ncould learn the initialization but replace the gradient\nupdate with some form",
    "start": "1757520",
    "end": "1762649"
  },
  {
    "text": "of learned network,\nwhere you actually have a network that takes\nas input a gradient step.",
    "start": "1762650",
    "end": "1768650"
  },
  {
    "text": "And there's a paper by Sachin\nRavi and Hugo Larochelle, that actually predates MAML,\nthat does something like that.",
    "start": "1768650",
    "end": "1776420"
  },
  {
    "text": " OK.",
    "start": "1776420",
    "end": "1781770"
  },
  {
    "text": "In general, this sort of\nlike computation graph view of meta-learning will\nactually come up again in the next lecture,\nwhen we talk",
    "start": "1781770",
    "end": "1787900"
  },
  {
    "text": "about nonparametric approaches. ",
    "start": "1787900",
    "end": "1793640"
  },
  {
    "text": "OK. Now you might be\nwondering, when should we use one approach\nversus the other?",
    "start": "1793640",
    "end": "1798790"
  },
  {
    "text": "One thing that's nice about\nembedding a gradient step into the optimization\nprocedure is",
    "start": "1798790",
    "end": "1803927"
  },
  {
    "text": "that it means that\nat test time you're just running fine-tuning. And so regardless\nof what happens",
    "start": "1803927",
    "end": "1809380"
  },
  {
    "text": "during the\nmeta-training process, you're still running an\noptimization procedure that should get better\nat the test task.",
    "start": "1809380",
    "end": "1816670"
  },
  {
    "text": "And so if you look at tasks that\nare extrapolated from the tasks that you saw during\nmeta-training,",
    "start": "1816670",
    "end": "1824860"
  },
  {
    "text": "these optimization-based\napproaches, like MAML, often do actually better\nthan black-box approaches.",
    "start": "1824860",
    "end": "1830530"
  },
  {
    "text": "And so, for example,\nif you compare MAML with SNAIL\nand MetaNetworks, which are two\nblack-box approaches,",
    "start": "1830530",
    "end": "1837340"
  },
  {
    "text": "you can look at, say,\nOmniglot classification and look at the performance\nof the algorithm",
    "start": "1837340",
    "end": "1843970"
  },
  {
    "text": "as you vary the test\ntasks, as you move them away from the distribution that\nthey saw during meta-training.",
    "start": "1843970",
    "end": "1851720"
  },
  {
    "text": "So for example, maybe\nwe'd meta-trained on top on digits that are\nupright and then we're evaluating on tasks\nwhere the digits are skewed.",
    "start": "1851720",
    "end": "1860059"
  },
  {
    "text": "Then in this case, you see\nthat performance deteriorates as you move away from\nthe kinds of tasks that you saw during\nmeta-training.",
    "start": "1860060",
    "end": "1865810"
  },
  {
    "text": "But it deteriorates a lot less\nfor a MAML-style algorithm compared to these\nblack-box algorithms.",
    "start": "1865810",
    "end": "1872200"
  },
  {
    "text": "And kind of the\nintuition here is that if you're feeding in\nout of distribution tasks into a black-box neural\nnetwork, you don't really",
    "start": "1872200",
    "end": "1879220"
  },
  {
    "text": "have any reason to\nexpect it to generalize. Whereas, if you're running\ngradient descent on out",
    "start": "1879220",
    "end": "1884980"
  },
  {
    "text": "of distribution images,\nyou can at least expect it to improve\non the objective,",
    "start": "1884980",
    "end": "1890410"
  },
  {
    "text": "just like fine-tuning improves. We can also look at something\nlike the scale of the digits,",
    "start": "1890410",
    "end": "1895480"
  },
  {
    "text": "and we see somewhat of a\nsimilar trend, where MAML is a bit better at extrapolating.",
    "start": "1895480",
    "end": "1901570"
  },
  {
    "text": "Yeah? So how would you do actual\ninferences with this? Like before you can make\nan inference, you need to do the fine-tuning, right?",
    "start": "1901570",
    "end": "1908937"
  },
  {
    "text": "Yeah, exactly. So what's happening at test\ntime for the black-box methods is it's passing in the support\nset into the neural network.",
    "start": "1908937",
    "end": "1916603"
  },
  {
    "text": "Whereas, for MAML, it's\ntaking the support set and running gradient\ndescent on them. And these plots are\nshowing the performance",
    "start": "1916603",
    "end": "1921850"
  },
  {
    "text": "after using the support\nset to adapt to the task. ",
    "start": "1921850",
    "end": "1930030"
  },
  {
    "text": "Now, the only thing\nyou might wonder is, well, OK, we're\nbuilding a gradient step into this procedure.",
    "start": "1930030",
    "end": "1935040"
  },
  {
    "text": "Does this mean\nthat we are less-- that the method is\nless expressive?",
    "start": "1935040",
    "end": "1940650"
  },
  {
    "text": "Like, maybe it can't\nrepresent the kinds of learning procedures that a\nblack-box neural network can represent.",
    "start": "1940650",
    "end": "1947303"
  },
  {
    "text": "And one thing that\nyou can show is that, if you have a sufficiently\nlarge neural network,",
    "start": "1947303",
    "end": "1952350"
  },
  {
    "text": "then the computation graph with\na gradient descent step in it can actually still approximate\nany function of the training",
    "start": "1952350",
    "end": "1959070"
  },
  {
    "text": "data set and the test input.  And essentially, this\nis saying that you",
    "start": "1959070",
    "end": "1964260"
  },
  {
    "text": "can represent any learning\nprocedure despite the fact that there's a gradient update\nin the computation graph.",
    "start": "1964260",
    "end": "1970683"
  },
  {
    "text": "And this is under a few\ndifferent assumptions. You need to assume that the\nlearning rate is non-zero, of course, so that the gradient\nis actually having an effect.",
    "start": "1970683",
    "end": "1979035"
  },
  {
    "text": "You need to assume that the loss\nfunction gradient doesn't lose information about the label.",
    "start": "1979035",
    "end": "1984700"
  },
  {
    "text": "So this is true for loss\nfunctions like cross entropy and L2 loss.",
    "start": "1984700",
    "end": "1989793"
  },
  {
    "text": "And you also need to assume that\nthe data points in the training data set are unique.",
    "start": "1989793",
    "end": "1995547"
  },
  {
    "text": "And this is interesting because\nthis means that, in some ways, MAML has the benefit of building\nin the structure inductive",
    "start": "1995547",
    "end": "2002060"
  },
  {
    "text": "bias of gradient\ndescent compared to these black-box approaches\nwithout necessarily losing",
    "start": "2002060",
    "end": "2007400"
  },
  {
    "text": "the expressive\npower that you get from a neural network\nrepresenting a learning",
    "start": "2007400",
    "end": "2013130"
  },
  {
    "text": "procedure. Yeah? What would it mean for the\nloss function meaning to lose",
    "start": "2013130",
    "end": "2018685"
  },
  {
    "text": "information about the digits? Yeah, so in some ways this is\nkind of more advanced material.",
    "start": "2018686",
    "end": "2025550"
  },
  {
    "text": "But essentially, if you view\nMAML as a computation graph that has a gradient\ninside of it,",
    "start": "2025550",
    "end": "2035090"
  },
  {
    "text": "I guess essentially what I mean\nis that, if you look at a loss function, like an\nL2 loss function,",
    "start": "2035090",
    "end": "2043890"
  },
  {
    "text": "then the slope, the gradient\nof this is actually changing. And you can figure out\nwhat point on this curve",
    "start": "2043890",
    "end": "2050040"
  },
  {
    "text": "you are by looking\nat the gradient. Whereas, if you have a\nloss function that is more like an L1 loss function,\nthen in that case,",
    "start": "2050040",
    "end": "2060020"
  },
  {
    "text": "if you look at the\ngradient, it isn't actually that informative about\nwhat the label is",
    "start": "2060020",
    "end": "2065600"
  },
  {
    "text": "because the gradient\nis the same here as it is here and so forth.",
    "start": "2065600",
    "end": "2071388"
  },
  {
    "text": "And so generally if you use\nloss functions like this, you're going to have a\nless informative gradient",
    "start": "2071389",
    "end": "2078138"
  },
  {
    "text": "update potentially. In practice, MAML can\nstill work with these. But if you need a\nvery expressive update",
    "start": "2078139",
    "end": "2085221"
  },
  {
    "text": "rule that maybe is a\nlittle bit different than gradient descent, these\nmight not work as well. ",
    "start": "2085221",
    "end": "2096730"
  },
  {
    "text": "OK. And then the last\nthing to mention on these optimization-based\napproaches",
    "start": "2096730",
    "end": "2103410"
  },
  {
    "text": "is some of the\nchallenges that come up and the ways that\nwe can fix them.",
    "start": "2103410",
    "end": "2108587"
  },
  {
    "text": "And this essentially will\nyield different variants of these optimization-based\nmeta-learning algorithms.",
    "start": "2108587",
    "end": "2114849"
  },
  {
    "text": "So the first is that we do\nhave this bi-level optimization procedure in the\nsense that there's an optimization embedded\ninside an optimization.",
    "start": "2114850",
    "end": "2121800"
  },
  {
    "text": "And this, in general, can\nlead to instabilities. Yeah? On the previous slide,\nyou have the data",
    "start": "2121800",
    "end": "2128610"
  },
  {
    "text": "points have to be unique. Why is that? ",
    "start": "2128610",
    "end": "2133680"
  },
  {
    "text": "Yeah. So the question was why do the\ndata points need to be unique?",
    "start": "2133680",
    "end": "2139631"
  },
  {
    "text": "And essentially\nthe reason for this is that, if you want to be\nable to represent any learning",
    "start": "2139632",
    "end": "2146490"
  },
  {
    "text": "procedure with respect to\ndifferent copies of a data point, it's generally\ndifficult to tell",
    "start": "2146490",
    "end": "2153300"
  },
  {
    "text": "from the gradient how many\ncopies of a data point you have. If you don't care\nabout it depending",
    "start": "2153300",
    "end": "2159120"
  },
  {
    "text": "on the number of copies,\nthen it's generally fine. It's only a matter of whether\nyou want the learning procedure",
    "start": "2159120",
    "end": "2165603"
  },
  {
    "text": "to do something different\nwhen you have, like, five copies versus four\ncopies of a data point, which",
    "start": "2165603",
    "end": "2171270"
  },
  {
    "text": "is usually not the case. ",
    "start": "2171270",
    "end": "2177710"
  },
  {
    "text": "OK, so how can we get\nover the challenge of these instabilities\nthat might arise from the bi-level optimization?",
    "start": "2177710",
    "end": "2184420"
  },
  {
    "text": "There's a few different\napproaches that have been used. One is, when you have\nyour inner learning rate,",
    "start": "2184420",
    "end": "2192760"
  },
  {
    "text": "instead of having it\nfixed as a hyperparameter, you can essentially learn it.",
    "start": "2192760",
    "end": "2198950"
  },
  {
    "text": "And this gives the\nalgorithm more flexibility in how it chooses this\noptimization procedure.",
    "start": "2198950",
    "end": "2205180"
  },
  {
    "text": "And one thing that\nyou could do is, instead of having it\nbe a scalar function, you can have it actually\njust be a vector.",
    "start": "2205180",
    "end": "2210820"
  },
  {
    "text": "You could have a different\nlearning rate for each layer or a different learning\nrate for each parameter.",
    "start": "2210820",
    "end": "2216099"
  },
  {
    "text": "And in general, giving\nit the flexibility to have different learning\nrates for different layers can be quite helpful\nbecause, for example,",
    "start": "2216100",
    "end": "2222533"
  },
  {
    "text": "the biases of a network\nmay want to have larger gradients than the\nweights of the network. Or maybe the later\nlayers of the network",
    "start": "2222533",
    "end": "2229147"
  },
  {
    "text": "want to change more, whereas the\nearlier layers of the network should change less. ",
    "start": "2229147",
    "end": "2236452"
  },
  {
    "text": "There are also some\napproaches that optimize only a subset of the\nparameters in the inner loop. You could optimize\njust the last layer",
    "start": "2236452",
    "end": "2242410"
  },
  {
    "text": "of the network, for\nexample, or optimize some multiplicative factors\non different layers.",
    "start": "2242410",
    "end": "2250315"
  },
  {
    "text": " And then one other\nthing that came up is you don't necessarily have\nto have the same learning",
    "start": "2250315",
    "end": "2258280"
  },
  {
    "text": "rate for each of\nthe different steps. And so what you\ncould do is you could try to essentially decouple the\nlearning rate and other things,",
    "start": "2258280",
    "end": "2265300"
  },
  {
    "text": "like the BatchNorm statistics,\nfor different steps in the optimization. ",
    "start": "2265300",
    "end": "2274800"
  },
  {
    "text": "And then there's\nalso approaches that try to introduce some\nadditional context variables into the network to\ntry to increase-- generally",
    "start": "2274800",
    "end": "2282150"
  },
  {
    "text": "just increase the\nexpressive power of the meta-learning algorithm.",
    "start": "2282150",
    "end": "2288880"
  },
  {
    "text": "So really the\ntakeaway here is that, not necessarily to\nunderstand the details of all of these different\napproaches, but just to understand that there's\na variety of simple tricks",
    "start": "2288880",
    "end": "2296160"
  },
  {
    "text": "that can help improve the\nstability of the optimization. ",
    "start": "2296160",
    "end": "2305151"
  },
  {
    "text": "OK. And then the second\nchallenge that comes up is that you do have\nto back propagate through this\noptimization procedure.",
    "start": "2305151",
    "end": "2312760"
  },
  {
    "text": "And if you have one gradient\nstep, that's not too hard. But if you have a lot\nof gradient steps, then optimizing through\nall of those gradient steps",
    "start": "2312760",
    "end": "2320230"
  },
  {
    "text": "can be computationally expensive\nand also memory intensive because you have to store\nthe optimization in memory.",
    "start": "2320230",
    "end": "2329942"
  },
  {
    "text": "There's a few\ndifferent approaches for trying to solve\nthis, particularly in cases where you want\nto have a large number of inner gradient steps.",
    "start": "2329943",
    "end": "2337460"
  },
  {
    "text": "One is to just ignore\nthe fact that there are second-order gradients. Just essentially, when you're\ncomputing the gradient,",
    "start": "2337460",
    "end": "2349839"
  },
  {
    "text": "just crudely approximate\nthis as identity. And this is not\nat all principled,",
    "start": "2349840",
    "end": "2361270"
  },
  {
    "text": "often because this is not\nanywhere close to identity usually.",
    "start": "2361270",
    "end": "2366490"
  },
  {
    "text": "But in practice, it actually\nworks surprisingly well on certain problems. On other problems it\ndoesn't work at all.",
    "start": "2366490",
    "end": "2372398"
  },
  {
    "text": "But anecdotally, it can work\nfor problems like few-shot image classification.",
    "start": "2372398",
    "end": "2377878"
  },
  {
    "text": " Yeah, I'll leave it at that.",
    "start": "2377878",
    "end": "2384040"
  },
  {
    "text": "Another approach\nis to only optimize the last layer of the network. And essentially\nwhat this is going to correspond to is optimizing\nfor representation such that,",
    "start": "2384040",
    "end": "2393430"
  },
  {
    "text": "if you train a linear layer\non top of that representation, you can perform the task well.",
    "start": "2393430",
    "end": "2400817"
  },
  {
    "text": "And there's a few\ndifferent approaches that have done\nthis, where they do like ridge regression\nor logistic regression on top of the features, or they\ndo a support vector machine",
    "start": "2400817",
    "end": "2408250"
  },
  {
    "text": "on top of those features. And it leads to-- often leads to, actually,\na fairly nice optimization",
    "start": "2408250",
    "end": "2415450"
  },
  {
    "text": "procedure compared to\nthe bi-level optimization that you see when you're\ntrying to back propagate",
    "start": "2415450",
    "end": "2421772"
  },
  {
    "text": "through gradient descent\nof the entire network. ",
    "start": "2421772",
    "end": "2427010"
  },
  {
    "text": "Great. And then the last\nthing that you can do is something else\nthat was mentioned, which is to try to use what's\ncalled the Implicit Function",
    "start": "2427010",
    "end": "2432847"
  },
  {
    "text": "theorem to derive\nthe meta-gradient. And one of the things\nthat's cool about this is",
    "start": "2432847",
    "end": "2438580"
  },
  {
    "text": "can actually compute\nthe meta-gradient without actually differentiating\nthrough the optimization path by essentially using curvature\ninformation at the end",
    "start": "2438580",
    "end": "2447460"
  },
  {
    "text": "of the optimization path. ",
    "start": "2447460",
    "end": "2452567"
  },
  {
    "text": "I'm not going to go through in\ndetail how exactly you do this because it's not something\nthat's particularly intuitive.",
    "start": "2452568",
    "end": "2457865"
  },
  {
    "text": "But if you want to\nlearn more about it, I'd encourage you to-- well, you\ncan take a look at this paper. You can also take\na look at what's",
    "start": "2457865",
    "end": "2463900"
  },
  {
    "text": "known as the Implicit\nFunction theorem. And you get some kind of\ninteresting trade-offs in terms",
    "start": "2463900",
    "end": "2470800"
  },
  {
    "text": "of memory and computation. So if you plot the\nnumber of inner gradient",
    "start": "2470800",
    "end": "2476500"
  },
  {
    "text": "steps on the x-axis and\nthe amount of GPU memory that you need, if you use\nthe implicit function theorem",
    "start": "2476500",
    "end": "2482980"
  },
  {
    "text": "this stays constant. Whereas, it increases\nlinearly for an approach",
    "start": "2482980",
    "end": "2488410"
  },
  {
    "text": "that just back props through\nthe computation graph.",
    "start": "2488410",
    "end": "2493510"
  },
  {
    "text": "And then the\ncomputation time also stays flatter compared\nto back propagating",
    "start": "2493510",
    "end": "2498640"
  },
  {
    "text": "through the entire procedure. And this purple line is the\nfirst-order approximation,",
    "start": "2498640",
    "end": "2504290"
  },
  {
    "text": "which also is a\nshallower line as well. ",
    "start": "2504290",
    "end": "2509463"
  },
  {
    "text": "The other thing that's kind\nof cool about this is it also allows you to do\nsecond-order optimizers in the inner loop because\nyou don't actually",
    "start": "2509463",
    "end": "2515829"
  },
  {
    "text": "have to do a\nsecond-order optimization for the entire thing. And so it allows you to get\nkind of better performance",
    "start": "2515830",
    "end": "2522490"
  },
  {
    "text": "in some cases by leveraging\nthe second-order optimization. And the Implicit\nFunction theorem",
    "start": "2522490",
    "end": "2528490"
  },
  {
    "text": "is also useful for\nhyperparameter optimization as well. There's a pretty cool paper\nthat essentially optimizes",
    "start": "2528490",
    "end": "2534670"
  },
  {
    "text": "for data augmentation procedures\nusing ideas like the Implicit Function theorem. ",
    "start": "2534670",
    "end": "2543295"
  },
  {
    "text": "OK. And then lastly, the other\nthing worth mentioning is that you want to choose an\narchitecture that works well.",
    "start": "2543295",
    "end": "2552650"
  },
  {
    "text": "In general, the procedure\nis model agnostic and should generally work well\nfor a variety of architectures.",
    "start": "2552650",
    "end": "2558260"
  },
  {
    "text": "But there is some\nworks that actually tried to search for an\narchitecture that works well with these kinds of algorithms.",
    "start": "2558260",
    "end": "2565723"
  },
  {
    "text": "It actually found a pretty\nnon-standard architecture and was able to get essentially\na 10% performance boost",
    "start": "2565723",
    "end": "2574490"
  },
  {
    "text": "by actually optimizing\nfor an architecture rather than using a\nmore basic architecture.",
    "start": "2574490",
    "end": "2581870"
  },
  {
    "text": "Great. So I'll summarize\nthings and then we can run through\nany more questions. So, really the key\nidea here is we're",
    "start": "2581870",
    "end": "2588769"
  },
  {
    "text": "going to try to get some\ntask-specific parameters from the support set\nby running fine-tuning.",
    "start": "2588770",
    "end": "2596510"
  },
  {
    "text": "And the approach constructs a\nbi-level optimization problem.",
    "start": "2596510",
    "end": "2602060"
  },
  {
    "text": "And it has a positive inductive\nbias because you're essentially defaulting to fine-tuning.",
    "start": "2602060",
    "end": "2608150"
  },
  {
    "text": "It also tends to\nextrapolate better by using the structure\nof fine-tuning.",
    "start": "2608150",
    "end": "2614970"
  },
  {
    "text": "It's also maximally\nexpressive if you have a sufficiently large network. And it is model\nagnostic, so it should",
    "start": "2614970",
    "end": "2620809"
  },
  {
    "text": "be fairly straightforward\nto combine with your favorite architecture. The downside is that\nit typically requires",
    "start": "2620810",
    "end": "2627080"
  },
  {
    "text": "a second-order optimization. And this means that it can be\ncompute or memory intensive.",
    "start": "2627080",
    "end": "2634730"
  },
  {
    "text": "OK. Any questions on how things\nwork or things that would be-- that might be helpful?",
    "start": "2634730",
    "end": "2640520"
  },
  {
    "start": "2640520",
    "end": "2648650"
  },
  {
    "text": "Or any questions on\nthe math or anything? Yeah? So can you explain\nagain why, [INAUDIBLE]",
    "start": "2648650",
    "end": "2655640"
  },
  {
    "text": "is better, why [INAUDIBLE]. ",
    "start": "2655640",
    "end": "2660692"
  },
  {
    "text": "Yeah, definitely. So I guess one thing that I\nnever really outlined is that.",
    "start": "2660692",
    "end": "2666630"
  },
  {
    "text": "So, I talked about\nthis procedure",
    "start": "2666630",
    "end": "2673339"
  },
  {
    "text": "where we sample a task, sample\na support set of the query set, and then run gradient\ndescent on the support set,",
    "start": "2673340",
    "end": "2679670"
  },
  {
    "text": "and then optimize for the\nperformance of those updated parameters on the query set.",
    "start": "2679670",
    "end": "2685490"
  },
  {
    "text": "And then what\nhappens at test time is you take the\nlearned initialization,",
    "start": "2685490",
    "end": "2691309"
  },
  {
    "text": "these parameters\ntheta, and you just run gradient descent on them. And so if you're\ngiven a task that",
    "start": "2691310",
    "end": "2698630"
  },
  {
    "text": "is completely out\nof distribution from what you saw\nbefore, at the very least you are running\ngradient descent.",
    "start": "2698630",
    "end": "2704270"
  },
  {
    "text": "You're running\nfine-tuning on that task. And so we can expect fine\ntuning to already do fairly well",
    "start": "2704270",
    "end": "2711829"
  },
  {
    "text": "on a variety of tasks. And so you should\nexpect it to do at least",
    "start": "2711830",
    "end": "2717080"
  },
  {
    "text": "as well as fine-tuning on\nout-of-distribution tasks. Now, in contrast with\nthe black-box approach,",
    "start": "2717080",
    "end": "2723140"
  },
  {
    "text": "where you are passing the data\npoints into a neural network, if you pass in\nout-of-distribution examples",
    "start": "2723140",
    "end": "2728240"
  },
  {
    "text": "into a neural network,\nyou can't really expect it to do\nanything reasonable. And it will probably do worse\nthan fine-tuning will do.",
    "start": "2728240",
    "end": "2736680"
  },
  {
    "text": "And so as a result,\nyou can expect methods like these\noptimization-based meta-learning methods\nto do a lot better",
    "start": "2736680",
    "end": "2743510"
  },
  {
    "text": "on out-of-distribution tasks\nthan black-box approaches. And this also relates\nto a question,",
    "start": "2743510",
    "end": "2749910"
  },
  {
    "text": "I think, from yesterday\nin terms of the robustness of these methods as well.",
    "start": "2749910",
    "end": "2754930"
  },
  {
    "text": "Yeah? So, I remember you mentioned\nearlier that usually you went one step during training,\nI guess to avoid overfitting.",
    "start": "2754930",
    "end": "2763470"
  },
  {
    "text": "But at inference time, would\nyou take multiple steps or until it converges? Yeah, it's a good question.",
    "start": "2763470",
    "end": "2768890"
  },
  {
    "text": "So, typically in the\ninner loop, you often use one step, mostly just\nfor computational reasons.",
    "start": "2768890",
    "end": "2774670"
  },
  {
    "text": "It can be challenging\nto back propagate through a lot of\ngradient descent steps.",
    "start": "2774670",
    "end": "2780069"
  },
  {
    "text": "It also seems to\nwork pretty well. But then, like you mentioned,\nat test time computation is no longer a bottleneck\nbecause you're just",
    "start": "2780070",
    "end": "2786280"
  },
  {
    "text": "running the procedure\nonce and you don't need to back propagate through it. And so in practice\nit is pretty common",
    "start": "2786280",
    "end": "2791789"
  },
  {
    "text": "to actually just run\nmore gradient descent steps at test time. And that can perform well.",
    "start": "2791790",
    "end": "2797283"
  },
  {
    "text": "And that can be\nespecially helpful for out-of-distribution tasks\nfor which you might need more fine-tuning, compared\nto the small number",
    "start": "2797283",
    "end": "2805690"
  },
  {
    "text": "of grain steps as optimized\nfor the in-distribution tasks. Yeah?",
    "start": "2805690",
    "end": "2810805"
  },
  {
    "text": "[INAUDIBLE] so we do stop\nthe [INAUDIBLE] parameters [INAUDIBLE], right? We would run the back\npropagation, update them.",
    "start": "2810805",
    "end": "2818490"
  },
  {
    "text": "So we're, like, using that on\nthe phone where we only have, like, CPU and GPUs, would\nwork or would be super",
    "start": "2818490",
    "end": "2825254"
  },
  {
    "text": "inefficient to do an algorithm. Right. So at test time, you're\nrunning fine-tuning. And the question was,\nit seems like that",
    "start": "2825254",
    "end": "2830897"
  },
  {
    "text": "might be expensive\nto do on a phone, for example, if you\ndon't have the GPU. And this is where some\nof the algorithms that",
    "start": "2830897",
    "end": "2836880"
  },
  {
    "text": "only update the last layer\ncould be very helpful. And you don't necessarily\nneed to have this inner loop",
    "start": "2836880",
    "end": "2842910"
  },
  {
    "text": "step optimized to everything. Yeah? [INAUDIBLE] where you do\nthe IR experiments, you use,",
    "start": "2842910",
    "end": "2852180"
  },
  {
    "text": "when you have [INAUDIBLE]\ninner optimization and cross [INAUDIBLE] possibly for\nthe outer optimization.",
    "start": "2852180",
    "end": "2858810"
  },
  {
    "text": "So I'm curious about why\ndo you use reinforce when you [INAUDIBLE]?",
    "start": "2858810",
    "end": "2865595"
  },
  {
    "text": "And if you used [INAUDIBLE]\nfor inner loop as well, [INAUDIBLE] optimization will\nbe much, much more enhanced.",
    "start": "2865595",
    "end": "2873790"
  },
  {
    "text": "Yeah. So the question is, in the\nreinforcement learning setting, the [? Vanilla ?] paper uses\nvanilla reinforcer policy",
    "start": "2873790",
    "end": "2881160"
  },
  {
    "text": "gradient. We'll get to reinforcement\nlearning topics in several lectures. But I mean, the main reason\nis that an objective like TRPO",
    "start": "2881160",
    "end": "2890880"
  },
  {
    "text": "does involve kind of like a\nhigher-order optimization. I also think that PPO didn't\nyet exist at the time.",
    "start": "2890880",
    "end": "2897911"
  },
  {
    "text": "But if something\nlike that existed, then that would be a\nreasonable option as well.",
    "start": "2897912",
    "end": "2904510"
  },
  {
    "text": "Yeah? Is there some intuition for\nwhy things like Reptile, like [INAUDIBLE] methods,\nwork well for certain spaces?",
    "start": "2904510",
    "end": "2911230"
  },
  {
    "text": "Or is that just lucky? Yeah. So the question is, why\ndo algorithms that-- like first-order\nalgorithms that throw away",
    "start": "2911230",
    "end": "2917590"
  },
  {
    "text": "this, or Reptile,\nwhich is very similar to this first-order approach,\nwhy do they work well?",
    "start": "2917590",
    "end": "2925180"
  },
  {
    "text": "I don't exactly know\nwhy they work well. I think it may actually have\nto do with the question earlier",
    "start": "2925180",
    "end": "2930250"
  },
  {
    "text": "about how, in some\ncases, it might be OK to just average\nparameters that work well.",
    "start": "2930250",
    "end": "2938020"
  },
  {
    "text": "And I suspect that there\nare some cases where the kind of parameter landscape\nis nicely behaved, such",
    "start": "2938020",
    "end": "2945160"
  },
  {
    "text": "that simple things like\naveraging gradients of different tasks\nperforms well.",
    "start": "2945160",
    "end": "2951309"
  },
  {
    "text": "In more complex\nscenarios, I have found at least that it\ncan perform pretty poorly.",
    "start": "2951310",
    "end": "2958270"
  },
  {
    "text": "These first-order algorithms\ncan perform poorly. Yeah.",
    "start": "2958270",
    "end": "2963350"
  },
  {
    "text": "Yeah? When you said it performs,\n[INAUDIBLE] vectors that, did you mean that\n[INAUDIBLE] method with the second-order\n[INAUDIBLE]??",
    "start": "2963350",
    "end": "2970180"
  },
  {
    "text": "Or do you just mean\nslightly worse off? Yeah. When I said that the first-order\nmethods perform well,",
    "start": "2970180",
    "end": "2976690"
  },
  {
    "text": "I mean that they perform\nabout the same level as the second-order methods\non the simpler problems.",
    "start": "2976690",
    "end": "2983349"
  },
  {
    "text": "Yeah? I'm guessing, even though\nalgorithm based [INAUDIBLE]---- ",
    "start": "2983350",
    "end": "2990970"
  },
  {
    "text": "the algorithm-based learning\napproach might also have this problem, But I'm\nassuming in step 2,",
    "start": "2990970",
    "end": "2996370"
  },
  {
    "text": "[INAUDIBLE] that\ngradient step you'd be-- SGD is used. Like a single example might\nbe used from the [INAUDIBLE]..",
    "start": "2996370",
    "end": "3003255"
  },
  {
    "text": "But in this [INAUDIBLE],,\nwhere the tasks kind of have large data sets,\nbecause it's really",
    "start": "3003255",
    "end": "3009490"
  },
  {
    "text": "doing just a single\nupdate, or even [INAUDIBLE]",
    "start": "3009490",
    "end": "3015961"
  },
  {
    "text": "representation. Yeah. So the question is, for\nthese inner gradient steps-- I think you mean step\nthree, not step four, right?",
    "start": "3015961",
    "end": "3022130"
  },
  {
    "text": "Yeah. But if you have\na large data set, are you using SGD here\nor something else?",
    "start": "3022130",
    "end": "3027450"
  },
  {
    "text": "And typically,\nactually in most cases, these algorithms are applied\nto few-shot learning problems,",
    "start": "3027450",
    "end": "3033450"
  },
  {
    "text": "where you have a\nrelatively small data set. But actually, this\ninner gradient step is often computed with respect\nto all of your data points,",
    "start": "3033450",
    "end": "3040470"
  },
  {
    "text": "not just one data point. And if you have,\nlike, 100 examples,",
    "start": "3040470",
    "end": "3045569"
  },
  {
    "text": "that allows you to\ncompute a gradient that depends on all the examples\nrather than just one.",
    "start": "3045570",
    "end": "3050760"
  },
  {
    "text": "Yeah? So you are saying that\nit's often a good idea to just do one grad step in an\ninner loop for compute reasons?",
    "start": "3050760",
    "end": "3058512"
  },
  {
    "text": "But it's also a good reason\nto just prepare it to be, even without the grad\nstep, [INAUDIBLE] we have multiple--\nwe have access",
    "start": "3058512",
    "end": "3064176"
  },
  {
    "text": "to more grad step\nthan just [INAUDIBLE].. So a training setup, is\nharder because [INAUDIBLE]..",
    "start": "3064176",
    "end": "3070140"
  },
  {
    "text": "So, you're asking\ndoes it make sense-- ",
    "start": "3070140",
    "end": "3077190"
  },
  {
    "text": "using one gradient\nstep in the inner loop, does that make it harder? Does it make it\neasier at test time?",
    "start": "3077190",
    "end": "3082470"
  },
  {
    "text": "Would you have access to more\ngradient steps at test time? Are you preparing it\nto just [INAUDIBLE]??",
    "start": "3082470",
    "end": "3087820"
  },
  {
    "text": "Yeah. So the question is, by\nmeta-training with one gradient step and meta-testing\nwith more gradient steps,",
    "start": "3087820",
    "end": "3093180"
  },
  {
    "text": "does that essentially make\nit easier at test time? And, yeah, I think so.",
    "start": "3093180",
    "end": "3098579"
  },
  {
    "text": "I think that that\nessentially encourages it to learn very quickly.",
    "start": "3098580",
    "end": "3105180"
  },
  {
    "text": "And when you actually have a\nlonger optimization problem at test time, that makes\nit a little bit easier.",
    "start": "3105180",
    "end": "3114420"
  },
  {
    "text": "But the network should still be\nable to learn quickly because of the one inner gradient step. ",
    "start": "3114420",
    "end": "3121715"
  },
  {
    "text": "OK. one more question. There's a question [INAUDIBLE]. Does it [INAUDIBLE] reuse\nof the meta-learning",
    "start": "3121716",
    "end": "3127620"
  },
  {
    "text": "that the first-order\napproximation works as good as [INAUDIBLE]? Yes. So the question is, is it\nbecause a feature reuse",
    "start": "3127620",
    "end": "3134550"
  },
  {
    "text": "that the kind of\nfirst-order method works better, or works well? ",
    "start": "3134550",
    "end": "3141370"
  },
  {
    "text": "I think it could have to\ndo with feature reuse. Although, I think that the\nconcept of feature reuse is a little bit vague in\nsome ways and not as precise.",
    "start": "3141370",
    "end": "3150030"
  },
  {
    "text": "But I think it could, especially\nin computer vision problems. ",
    "start": "3150030",
    "end": "3157025"
  },
  {
    "text": "OK.  So now I'm going to run\nthrough a case study.",
    "start": "3157025",
    "end": "3163823"
  },
  {
    "text": "And I think that this\nshould be pretty helpful because so far we've only seen\nimage classification problems,",
    "start": "3163823",
    "end": "3169340"
  },
  {
    "text": "where we're trying to classify\na category of an image. And we'll look at\na case study that",
    "start": "3169340",
    "end": "3174530"
  },
  {
    "text": "is a bit different\nthan that example. And it will hopefully illustrate\nthe generality of these kinds",
    "start": "3174530",
    "end": "3179660"
  },
  {
    "text": "of meta-learning methods. And so in particular,\nthis paper wanted to be able to\npredict land cover.",
    "start": "3179660",
    "end": "3189319"
  },
  {
    "text": "And this can be useful\nfor essentially trying to monitor how the Earth\nis being used over time",
    "start": "3189320",
    "end": "3195990"
  },
  {
    "text": "and can be used for\nvarious conservation efforts or urban\nplanning or other things.",
    "start": "3195990",
    "end": "3202890"
  },
  {
    "text": "And it was at the earth-vision\nworkshop in 2020 at CVPR.",
    "start": "3202890",
    "end": "3210180"
  },
  {
    "text": "And so the problem is\nthey want to map land cover from satellite images. Satellite images are\nrelatively cheap to get.",
    "start": "3210180",
    "end": "3218120"
  },
  {
    "text": "Getting land cover annotations\nthrough on-the-ground surveys is a lot harder to get.",
    "start": "3218120",
    "end": "3223250"
  },
  {
    "text": "And so they looked at a\ncouple of different data sets. One is the data set\nright here, where you have very low-resolution,\nhigh-level segmentation",
    "start": "3223250",
    "end": "3233030"
  },
  {
    "text": "of the land cover. And the second\nexample is one that actually has a much\nhigher resolution land",
    "start": "3233030",
    "end": "3239510"
  },
  {
    "text": "cover segmentation. And I'm showing the\ndifferent classes here. So blue corresponds\nto urban regions,",
    "start": "3239510",
    "end": "3246230"
  },
  {
    "text": "green corresponds to forest\nregions, and so forth.",
    "start": "3246230",
    "end": "3251680"
  },
  {
    "text": "And this has applications in\nkind of urban planning, climate change research. And it has a number\nof challenges.",
    "start": "3251680",
    "end": "3257400"
  },
  {
    "text": "So labeling data like\nthis is super expensive because you need a label\nfor every region of pixels.",
    "start": "3257400",
    "end": "3264470"
  },
  {
    "text": "And different regions also\nlook different as well and have different\nland-use proportions.",
    "start": "3264470",
    "end": "3271070"
  },
  {
    "text": "And so they want to\nbe able to frame this as a meta-learning problem. And as an example, they\nhave examples of crop lands",
    "start": "3271070",
    "end": "3280520"
  },
  {
    "text": "of four countries. This is kind of illustrating\nthe kind of differences that you see in different\nregions of the world.",
    "start": "3280520",
    "end": "3286100"
  },
  {
    "text": "And different tasks\nare going to correspond to these different\nregions of the world. And so hopefully we'll\nbe able to leverage",
    "start": "3286100",
    "end": "3292993"
  },
  {
    "text": "a lot of annotated data\nfrom some parts of the world to be able to segment images\nfrom a new region of the world",
    "start": "3292993",
    "end": "3300697"
  },
  {
    "text": "with only a small amount\nof data from that region. ",
    "start": "3300697",
    "end": "3305780"
  },
  {
    "text": "This is a graphic from the\npaper, where they are trying to run this kind of\nmeta-learning process such that it allows\nthem to quickly adapt",
    "start": "3305780",
    "end": "3313070"
  },
  {
    "text": "to different\nregions of the world and learn a model that\ncan segment land cover in those different regions.",
    "start": "3313070",
    "end": "3318815"
  },
  {
    "text": " OK. So first we'll look\nat this SEN1MS--",
    "start": "3318815",
    "end": "3327710"
  },
  {
    "text": "or SEN12MS data set. And they had different kind\nof geographic meta-data.",
    "start": "3327710",
    "end": "3337610"
  },
  {
    "text": "Here's some examples\nof the images. And they're using the\nblue data points--",
    "start": "3337610",
    "end": "3344000"
  },
  {
    "text": "the blue regions\nfor meta-training, the light blue regions\nfor validating and tuning",
    "start": "3344000",
    "end": "3349565"
  },
  {
    "text": "the hyperparameters of the\nmeta-learning algorithm, and then the orange for\nactually reporting results",
    "start": "3349565",
    "end": "3354650"
  },
  {
    "text": "and evaluating.  And so as an example\nof a two-way, two-shot",
    "start": "3354650",
    "end": "3362358"
  },
  {
    "text": "classification problem,\nthey have an illustration here where they are\ntrying to classify,",
    "start": "3362358",
    "end": "3369359"
  },
  {
    "text": "for example, forest\nversus croplands. And they have kind of--",
    "start": "3369360",
    "end": "3378617"
  },
  {
    "text": "the samples correspond to these\ndifferent regions of the world with labels. And so they'll have k\nregions that are labeled,",
    "start": "3378617",
    "end": "3385160"
  },
  {
    "text": "and they'll provide\nthat to the algorithm. And then they want to be\nable to predict the land cover for other parts of that\nparticular region of the world.",
    "start": "3385160",
    "end": "3393230"
  },
  {
    "text": " OK, so that was\nthe first data set.",
    "start": "3393230",
    "end": "3398930"
  },
  {
    "text": "They also looked at this\ndeep globe data set. Unfortunately, this\ndata set didn't have any geographic metadata.",
    "start": "3398930",
    "end": "3406369"
  },
  {
    "text": "It didn't actually have\ncoordinates corresponding to where the satellite\nimages are coming from. And so they had to roughly\nguess from the metadata.",
    "start": "3406370",
    "end": "3415190"
  },
  {
    "text": "And they used\nclustering to do that. And then what the few-shot\nlearning problem looks",
    "start": "3415190",
    "end": "3420920"
  },
  {
    "text": "like is they're given one\npart of a region of the world,",
    "start": "3420920",
    "end": "3426619"
  },
  {
    "text": "and then they want to be\nable to evaluate and make predictions for the land\ncover in other regions,",
    "start": "3426620",
    "end": "3434150"
  },
  {
    "text": "or other parts of\nthe same region.  And so this was the data set.",
    "start": "3434150",
    "end": "3439422"
  },
  {
    "text": "They had also much\nhigher-resolution data sets. And so ultimately\nthey want to be able to predict the labels\nthat look like this.",
    "start": "3439422",
    "end": "3444718"
  },
  {
    "text": " OK, so they have\nmeta-training data.",
    "start": "3444718",
    "end": "3451160"
  },
  {
    "text": "And at meta-test time,\nthey're given a small data set for a new region. And this is kind of the support\nset of the meta-test task.",
    "start": "3451160",
    "end": "3463730"
  },
  {
    "text": "And they compared\njust randomly training on the support set\nof the target task.",
    "start": "3463730",
    "end": "3469988"
  },
  {
    "text": "So this is just\ntraining from scratch on the support set\nfor the test task.",
    "start": "3469988",
    "end": "3475490"
  },
  {
    "text": "They also compared\nto pretraining on all of the\nmeta-training data and then fine-tuning a network on the\ndata from the target region.",
    "start": "3475490",
    "end": "3484760"
  },
  {
    "text": "And then they also evaluated\nmodel-agnostic meta-learning on the meta-training\ndata and then",
    "start": "3484760",
    "end": "3490280"
  },
  {
    "text": "adapting with a small amount\nof data on the target task.",
    "start": "3490280",
    "end": "3495330"
  },
  {
    "text": "And so the results for the\nfirst data set are here. And they're plotting\nthe performance with different numbers of\nexamples in their support set",
    "start": "3495330",
    "end": "3503839"
  },
  {
    "text": "for the test task. And what they find is, first,\nrandom doesn't do very well.",
    "start": "3503840",
    "end": "3509280"
  },
  {
    "text": "They see a significant\nperformance improvement from using a pretrained network. And then they also see a pretty\nbig performance improvement,",
    "start": "3509280",
    "end": "3517850"
  },
  {
    "text": "I think around 10% to 20%, when\nusing meta-learning compared to using a pretrained model.",
    "start": "3517850",
    "end": "3525990"
  },
  {
    "text": "And then on the\nDeepGlobe data set, they found that MAML\nin a pretrained network",
    "start": "3525990",
    "end": "3532059"
  },
  {
    "text": "performed somewhat similarly\nwhen they have a random split. But then when they give it\na clustered split, which",
    "start": "3532060",
    "end": "3537550"
  },
  {
    "text": "is harder and you have to adapt\nto regions of the world that are probably different from what\nwas seen during meta-training,",
    "start": "3537550",
    "end": "3542800"
  },
  {
    "text": "you see a much larger\ngap in performance.",
    "start": "3542800",
    "end": "3548240"
  },
  {
    "text": "Great. And then there's also more\nvisualizations and analysis in the paper. This is just kind of a\nsubset of the results.",
    "start": "3548240",
    "end": "3553245"
  },
  {
    "text": " Any questions on the case study? Yeah?",
    "start": "3553245",
    "end": "3558830"
  },
  {
    "text": "Going back to [INAUDIBLE]\nlower than [INAUDIBLE].. ",
    "start": "3558830",
    "end": "3567660"
  },
  {
    "text": "Yeah. So the question is, why is this\nkind of below the performance of random guessing? The reason is that,\nin MAML, you're",
    "start": "3567660",
    "end": "3574579"
  },
  {
    "text": "optimizing for the\nperformance after fine-tuning. And so the pre-fine-tuning\nmodel, it might always-- like,",
    "start": "3574580",
    "end": "3580323"
  },
  {
    "text": "you're not actually\noptimizing it for it to be good in any way. And it may actually\nbe arbitrarily bad,",
    "start": "3580323",
    "end": "3587480"
  },
  {
    "text": "unless you actually tell it to-- that it should actually be good. And so you can actually--",
    "start": "3587480",
    "end": "3594227"
  },
  {
    "text": "one thing you could do\nis you could actually optimize both for\nthis objective as well",
    "start": "3594227",
    "end": "3600080"
  },
  {
    "text": "as the objective of the\noriginal parameters as well.",
    "start": "3600080",
    "end": "3607190"
  },
  {
    "text": "And that's useful if you\ncare about the performance of the model before fine-tuning.",
    "start": "3607190",
    "end": "3612320"
  },
  {
    "start": "3612320",
    "end": "3617960"
  },
  {
    "text": "Yeah? I have another question. Is there a [INAUDIBLE] against\nthe black-box meta-learning algorithm [INAUDIBLE].",
    "start": "3617960",
    "end": "3623990"
  },
  {
    "text": "Yeah. So I don't think\nthat they compared it to a black-box meta-learning\nalgorithm in this paper. I would expect it to\nnot perform as well,",
    "start": "3623990",
    "end": "3634369"
  },
  {
    "text": "especially in settings\nwhere, as we saw before, the held-out regions-- ",
    "start": "3634370",
    "end": "3642223"
  },
  {
    "text": "different regions of the\nworld look quite different. And so in some ways it's like--",
    "start": "3642223",
    "end": "3647650"
  },
  {
    "text": "it is somewhat out\nof distribution. And so the black-box\nmethods probably wouldn't do as well in\nthis sort of scenario.",
    "start": "3647650",
    "end": "3653860"
  },
  {
    "text": "They didn't evaluate it, and\nso I don't know for sure.",
    "start": "3653860",
    "end": "3659810"
  },
  {
    "text": "Yeah? [INAUDIBLE] when they\nwere [INAUDIBLE]??",
    "start": "3659810",
    "end": "3665680"
  },
  {
    "text": "Was there any method\n[INAUDIBLE] actually [INAUDIBLE]",
    "start": "3665680",
    "end": "3671428"
  },
  {
    "text": "when they're big enough\nto do [INAUDIBLE] points?  Yes, in here?",
    "start": "3671428",
    "end": "3677984"
  },
  {
    "text": "Yeah. So, when they're picking\nwhich points should be forward testing and which points\nshould be [INAUDIBLE],, was there any metric on\n[INAUDIBLE] reduce [INAUDIBLE]??",
    "start": "3677984",
    "end": "3686440"
  },
  {
    "text": " I believe that they randomly\nsampled the locations.",
    "start": "3686440",
    "end": "3692859"
  },
  {
    "text": "And that should mean that\nthere's less-- hopefully less covariate shifts,\nless distribution shift than you would otherwise.",
    "start": "3692860",
    "end": "3702910"
  },
  {
    "start": "3702910",
    "end": "3712119"
  },
  {
    "text": "OK, great. So that's it for today. We covered optimization-based\nmeta-learning.",
    "start": "3712120",
    "end": "3718210"
  },
  {
    "text": "We talked about how it differs\nwith these black-box approaches as well as some of the\nchallenges in different ways",
    "start": "3718210",
    "end": "3723280"
  },
  {
    "text": "to tweak the method to\naddress those challenges. And then we also\nsaw a case study of land cover classification.",
    "start": "3723280",
    "end": "3730940"
  },
  {
    "text": "Yeah. And then in terms of kind\nof a roadmap for what we're going to be seeing\nnext, so far we've",
    "start": "3730940",
    "end": "3736090"
  },
  {
    "text": "covered black-box meta-learning\nand optimization-based meta-learning. And there's one class of\nmeta-learning methods left,",
    "start": "3736090",
    "end": "3742270"
  },
  {
    "text": "which is called\nnonparametric methods. And so on Monday\nnext week, we're",
    "start": "3742270",
    "end": "3747760"
  },
  {
    "text": "going to cover these\nmethods and also just kind of compare all the\napproaches from a high level.",
    "start": "3747760",
    "end": "3753770"
  },
  {
    "text": "And then on\nWednesday, we'll look at some more\nadvanced topics that are quite important for\nthinking about the performance",
    "start": "3753770",
    "end": "3761777"
  },
  {
    "text": "of meta-learning\nalgorithms and should have some important\nimplications if you choose to use some\nof these algorithms",
    "start": "3761777",
    "end": "3767859"
  },
  {
    "text": "for your final project. And then on Monday of\nthe following week,",
    "start": "3767860",
    "end": "3776750"
  },
  {
    "text": "we're also going to cover kind\nof Bayesian interpretation of meta-learning algorithms. And then on Wednesday\nof week four,",
    "start": "3776750",
    "end": "3782650"
  },
  {
    "text": "we'll start covering\nreinforcement learning. Oh, there we go. The following Monday is\nBayesian meta-learning and then",
    "start": "3782650",
    "end": "3789268"
  },
  {
    "text": "reinforcement learning. Also, project proposals\nwill be due on, I think, Wednesday of week four. And so it's good to start\nthinking about your projects",
    "start": "3789268",
    "end": "3796670"
  },
  {
    "text": "now. And so hopefully some of\nthe project idea suggestions that we'll post will\nbe helpful for that.",
    "start": "3796670",
    "end": "3803309"
  },
  {
    "start": "3803310",
    "end": "3808000"
  }
]
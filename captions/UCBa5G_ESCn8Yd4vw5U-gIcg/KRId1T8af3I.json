[
  {
    "start": "0",
    "end": "11370"
  },
  {
    "text": "The real issue here that's,\nI guess, most interesting is that we're seeing a number\nof people whose reputations",
    "start": "11370",
    "end": "22080"
  },
  {
    "text": "and knowledge base and\nskills are significant,",
    "start": "22080",
    "end": "28170"
  },
  {
    "text": "who have chosen to join the\npeople who feel that the growth",
    "start": "28170",
    "end": "38550"
  },
  {
    "text": "and research into the generative\nAI, a large language model based",
    "start": "38550",
    "end": "45360"
  },
  {
    "text": "AI stuff really needs to be\nslowed and controlled and done by, quote, \"experts,\"\nend of quote.",
    "start": "45360",
    "end": "52890"
  },
  {
    "text": "Whereas some other people-- and I'm in that\ncategory-- sort think",
    "start": "52890",
    "end": "58680"
  },
  {
    "text": "that would have been an\ninteresting choice quite",
    "start": "58680",
    "end": "64080"
  },
  {
    "text": "a while ago. But right now, the genie\nis out of the bottle, and it's unlikely that\nwe can put it back in.",
    "start": "64080",
    "end": "70049"
  },
  {
    "text": "And that, in fact, the\nlarge language model AI",
    "start": "70050",
    "end": "75550"
  },
  {
    "text": "is going to become a standard\ntool of everybody, particularly",
    "start": "75550",
    "end": "81700"
  },
  {
    "text": "people trying to change\nthe world perhaps last week",
    "start": "81700",
    "end": "86979"
  },
  {
    "text": "or the week before. And so that we really\nneed to figure out what and how we feel about it.",
    "start": "86980",
    "end": "93550"
  },
  {
    "text": "It's quite clear that they're\nnot a perfect mechanism",
    "start": "93550",
    "end": "99400"
  },
  {
    "text": "at this point. It works fairly\nwell, but not great. And yet it's good enough so\nthat many things look very, very",
    "start": "99400",
    "end": "110650"
  },
  {
    "text": "good. And it can be used\nto accomplish things.",
    "start": "110650",
    "end": "116619"
  },
  {
    "text": "And it is self-improving\nin the sense that as experience\ngrows and it gets",
    "start": "116620",
    "end": "122380"
  },
  {
    "text": "incorporated into\nthe data that's used to generate the processes,\nthis newly discovered things",
    "start": "122380",
    "end": "137630"
  },
  {
    "text": "get incorporated in\namongst the old things, and things get\nbetter and better.",
    "start": "137630",
    "end": "142655"
  },
  {
    "text": " So I think that's going\nto be a big problem.",
    "start": "142655",
    "end": "149630"
  },
  {
    "text": "And I'm curious as\nto what's going on. There seems to be a strong\nbias throughout the people who",
    "start": "149630",
    "end": "163760"
  },
  {
    "text": "are experimenting\nwith this, that this is dangerous technology,\nand that you need to wear protective clothing\nand so forth when you",
    "start": "163760",
    "end": "173959"
  },
  {
    "text": "work on the large\nlanguage model AIs.",
    "start": "173960",
    "end": "179165"
  },
  {
    "text": " I'm not certain I believe that,\nbut certainly, many people",
    "start": "179165",
    "end": "186020"
  },
  {
    "text": "behave that way. Everybody's getting\ninto the act. Yeah.",
    "start": "186020",
    "end": "192060"
  },
  {
    "text": "And lots of specialized\nsystems are being put together.",
    "start": "192060",
    "end": "197310"
  },
  {
    "text": "There are people\nbuilding legal systems. There'll be people\nbuilding dating systems.",
    "start": "197310",
    "end": "207030"
  },
  {
    "text": "And almost everything\nthat you can do in terms of\ninteracting with humans",
    "start": "207030",
    "end": "216000"
  },
  {
    "text": "seems to have somebody\nworking on a variant of the ChatGPT,\nwhich is targeted",
    "start": "216000",
    "end": "225810"
  },
  {
    "text": "to that particular space. ",
    "start": "225810",
    "end": "231240"
  },
  {
    "text": "Going to be a mob scene. Do you think so? Maybe. Because everybody\nand their brother",
    "start": "231240",
    "end": "236250"
  },
  {
    "text": "is into it, whether they know\nwhat they're doing or not. Well, OK.",
    "start": "236250",
    "end": "242420"
  },
  {
    "text": "But what does it mean to know\nwhat you're doing in this space? Right, correct. That's true.",
    "start": "242420",
    "end": "248600"
  },
  {
    "text": "Yeah. So I read Hinton's\ninterview, or pieces of it.",
    "start": "248600",
    "end": "253830"
  },
  {
    "text": "And one thing that struck me\nwas he's assuming linear--",
    "start": "253830",
    "end": "259790"
  },
  {
    "text": "he's extrapolating the\nrapid rate of improvement that we've seen over the\nlast couple of years.",
    "start": "259790",
    "end": "266510"
  },
  {
    "text": "And we've seen this before. We saw this with the\nself-driving cars.",
    "start": "266510",
    "end": "272030"
  },
  {
    "text": "They improved dramatically\nvery quickly, and then all of a sudden plateaued.",
    "start": "272030",
    "end": "277490"
  },
  {
    "text": "And I'm wondering if\nthat's something that's likely to happen here or not.",
    "start": "277490",
    "end": "282600"
  },
  {
    "text": "Well, I don't know. I mean, there are\nlots of examples",
    "start": "282600",
    "end": "288480"
  },
  {
    "text": "where Moore's law-like\nthings have just",
    "start": "288480",
    "end": "297770"
  },
  {
    "text": "continued on for a long time. And it took almost 50\nyears before Moore's law",
    "start": "297770",
    "end": "305970"
  },
  {
    "text": "became obsolete.",
    "start": "305970",
    "end": "311170"
  },
  {
    "text": "And it wasn't repealed. It was just modified. True, but there are plenty\nof things that have saturated",
    "start": "311170",
    "end": "319400"
  },
  {
    "text": "and slowed down the\nperformance dramatically. And so the question\nis, which one is these?",
    "start": "319400",
    "end": "326599"
  },
  {
    "text": "A lot of it is data-limited. They accelerate very fast until\nthey've consumed all the data.",
    "start": "326600",
    "end": "337060"
  },
  {
    "text": "And then they can improve\nmore without a lot more data. And so that seems to\nbe a limiting factor",
    "start": "337060",
    "end": "344740"
  },
  {
    "text": "in these learning\nsystems at least.  Yeah.",
    "start": "344740",
    "end": "350920"
  },
  {
    "text": "But do we know that the\nsystems that people are using, like GPT-4, are really\nlearning systems,",
    "start": "350920",
    "end": "359320"
  },
  {
    "text": "or are they something else? Because at least my\nunderstanding of how it works",
    "start": "359320",
    "end": "365669"
  },
  {
    "text": "is basically it's really a\nshort-term semiotic predictor.",
    "start": "365670",
    "end": "376050"
  },
  {
    "text": "It has a language\nthat it's using. And it predicts the next thing\nin some sense by some mechanism.",
    "start": "376050",
    "end": "387090"
  },
  {
    "text": "And that gives it another\npiece of information, and it builds on that.",
    "start": "387090",
    "end": "393070"
  },
  {
    "text": "So it's basically a\nprojection into some sort of probabilistic\nspace of futures.",
    "start": "393070",
    "end": "402450"
  },
  {
    "text": "And one of them is\nselected by some mechanism. And that mechanism is\nconsidered the output.",
    "start": "402450",
    "end": "409320"
  },
  {
    "text": "Yeah, there was an interesting\nexample in The New York Times, where they showed how\nthe response evolved over",
    "start": "409320",
    "end": "416070"
  },
  {
    "text": "the two seconds you\nhave to wait to get it from just random characters\nto utter gibberish",
    "start": "416070",
    "end": "422550"
  },
  {
    "text": "to semi-sensible to\nthe final result. But again, it improves\nby getting more",
    "start": "422550",
    "end": "430919"
  },
  {
    "text": "data to improve its statistics. And when it runs out\nof data, doesn't that",
    "start": "430920",
    "end": "436710"
  },
  {
    "text": "limit its improvement?  I don't know.",
    "start": "436710",
    "end": "442390"
  },
  {
    "text": "That was my question. So I was hoping somebody-- Anybody out there who would\nlike to comment on that? That might know?",
    "start": "442390",
    "end": "447650"
  },
  {
    "text": "I don't know. ",
    "start": "447650",
    "end": "453810"
  },
  {
    "text": "Yeah, hello. Hello. Yeah, I'm just setting up. I think this question was\nalso brought up in a video",
    "start": "453810",
    "end": "462750"
  },
  {
    "text": "that Dennis shared\nbefore this colloquium.",
    "start": "462750",
    "end": "468960"
  },
  {
    "text": "So the point is that\non point of data,",
    "start": "468960",
    "end": "477180"
  },
  {
    "text": "there is a chance\nthat when I run out of data due to the\ncomplexity of the system, it can generate its own data.",
    "start": "477180",
    "end": "485370"
  },
  {
    "text": "And since also there are new\nfeatures appearing, which also I think mentioned in the video--",
    "start": "485370",
    "end": "491760"
  },
  {
    "text": "if I remember correctly--\nthat it starts to transcribed information from audio means.",
    "start": "491760",
    "end": "500910"
  },
  {
    "text": "So mediums like radio\nor maybe some podcasts. YouTube is a big source.",
    "start": "500910",
    "end": "507479"
  },
  {
    "text": "So this one as well. So it's also worth I\nthink definitely studying",
    "start": "507480",
    "end": "516510"
  },
  {
    "text": "how this process go. But again, due to the black\nbox going on in the system,",
    "start": "516510",
    "end": "524700"
  },
  {
    "text": "it can be a little complicated\nor quite complicated, not really to do that.",
    "start": "524700",
    "end": "531745"
  },
  {
    "text": "Yeah.  I think that's exactly true.",
    "start": "531745",
    "end": "540450"
  },
  {
    "text": "First of all, we don't know. There might be much\nlarger collections of data that may be available\neither immediately or shortly.",
    "start": "540450",
    "end": "547385"
  },
  {
    "text": "I mean, imagine translating\nall of the YouTube videos, just converting them into\ntext and feeding it in.",
    "start": "547385",
    "end": "556170"
  },
  {
    "text": "There may be a lot\nof sources like that. Second thing is we don't really\nknow how much there already",
    "start": "556170",
    "end": "562560"
  },
  {
    "text": "is in there because\nwe're just beginning to discover to mine the\nactionable insights that",
    "start": "562560",
    "end": "568590"
  },
  {
    "text": "are available in the databases\nthat they currently have. And related point to that is\nthat as the models get bigger,",
    "start": "568590",
    "end": "577709"
  },
  {
    "text": "as they throw more\ncomputing power at it, you get a more fine-grained\ndetail of what they can do",
    "start": "577710",
    "end": "585570"
  },
  {
    "text": "and what you know\nwhat they can express. And so we may be able to\nincrease the computing power",
    "start": "585570",
    "end": "592199"
  },
  {
    "text": "and get a lot more out of these\nsystems than where just we may just be scratching\nthe surface today.",
    "start": "592200",
    "end": "597870"
  },
  {
    "text": "I was just reading a\nbunch of stuff today. Some of it's pretty disturbing\nabout what kinds of things",
    "start": "597870",
    "end": "603940"
  },
  {
    "text": "you can persuade\nthese systems to do. So they're putting\nout tools that have the possibility that they\ncan do some very bad things",
    "start": "603940",
    "end": "612638"
  },
  {
    "text": "and people can use them\nfor some very bad things, and we just don't know\nyet that that's in there",
    "start": "612638",
    "end": "617740"
  },
  {
    "text": "and that it's capable in\nways that they can you know customize persuasion and\nchange the way advertising is",
    "start": "617740",
    "end": "624310"
  },
  {
    "text": "done and pollute\nour public square. These are all issues that\nI think are very real, but I don't know if it's--",
    "start": "624310",
    "end": "632200"
  },
  {
    "text": "it's going to be\nasymptotic at some point, but it's not at all clear\nthat we're anywhere near that.",
    "start": "632200",
    "end": "637600"
  },
  {
    "text": "Do you think that the output of\nthe various systems that people",
    "start": "637600",
    "end": "645730"
  },
  {
    "text": "build will get\nincorporated in the inputs and be used to build the models?",
    "start": "645730",
    "end": "652240"
  },
  {
    "text": "Well, I don't know where I read\nthat, but I just saw something-- basically, since it\nlearns from language,",
    "start": "652240",
    "end": "658990"
  },
  {
    "text": "these systems can\ngenerate language. And then you can\nfeed that back in. And that does in fact\nimprove their performance.",
    "start": "658990",
    "end": "664660"
  },
  {
    "text": "Now that's got to be\nasymptotic at some point. But it's just another technique\nfor accelerating what kind",
    "start": "664660",
    "end": "672940"
  },
  {
    "text": "of value you can get out of\nthese enormous collections of humanity's knowledge.",
    "start": "672940",
    "end": "679990"
  },
  {
    "text": "Do you think that the\nstructure that we have, which is basically a sort of\nforward-predictive probabilistic",
    "start": "679990",
    "end": "689290"
  },
  {
    "text": "one, where we select out\na path through some very complicated probabilistic\nhyperspace by some technique,",
    "start": "689290",
    "end": "698170"
  },
  {
    "text": "and that remains to be\nverified, of course, but is that a hint as to\nhow consciousness works?",
    "start": "698170",
    "end": "708900"
  },
  {
    "text": "If you're asking me,\nI haven't got a clue. The whole thing, like\nmost of you guys,",
    "start": "708900",
    "end": "715860"
  },
  {
    "text": "I've been looking at\nthis stuff for 50 years. And I can't believe\nthis is happening.",
    "start": "715860",
    "end": "722040"
  },
  {
    "text": "I'm actually kind of-- in a way, I'm grateful\nthat I live to see this.",
    "start": "722040",
    "end": "728475"
  },
  {
    "text": "This is a real game changer. And I don't think we\ncan minimize that.",
    "start": "728475",
    "end": "733890"
  },
  {
    "text": "Not to say it's not going\nto have limitations. It's not the\nsuperintelligent thing",
    "start": "733890",
    "end": "742410"
  },
  {
    "text": "that's going to take over the\nEarth, but I have no idea--",
    "start": "742410",
    "end": "747600"
  },
  {
    "text": "the idea that predicting the\nnext word or the next token can lead to this stuff\nthat we're seeing is just--",
    "start": "747600",
    "end": "754170"
  },
  {
    "text": "to me, it's inexplicable. It's like aliens landed, and\nthey're playing a joke on us and just expressing themselves\nthrough this mechanism.",
    "start": "754170",
    "end": "762600"
  },
  {
    "text": "So I have no idea\nwhere this goes. I have to second that. That's exactly my feeling.",
    "start": "762600",
    "end": "769600"
  },
  {
    "text": "Yeah, if people\nlike us think that, we're just not going to\nknow the answer for a while.",
    "start": "769600",
    "end": "775810"
  },
  {
    "text": "And it's hard not to describe\nto people what's going on.",
    "start": "775810",
    "end": "781140"
  },
  {
    "text": "And I'm getting asked-- I'm sure you folks are too,\neverybody from my mother, who's",
    "start": "781140",
    "end": "787920"
  },
  {
    "text": "still around amazingly enough,\nto people writing to me just saying, What's\nthis going to mean?",
    "start": "787920",
    "end": "793620"
  },
  {
    "text": "And I don't know. I'm having trouble figuring out.",
    "start": "793620",
    "end": "799080"
  },
  {
    "text": "Another interesting\nfeature that-- I was just working on\na piece of software, where I have to run a\nbunch of test cases,",
    "start": "799080",
    "end": "805770"
  },
  {
    "text": "and then test cases fail. And I try to\nimprove the software so it passes more test cases. It seems to me that the\nability for systems like this",
    "start": "805770",
    "end": "813840"
  },
  {
    "text": "to run software really kind of\nis remarkable because not only can they potentially improve\nthe underlying software,",
    "start": "813840",
    "end": "819510"
  },
  {
    "text": "but they could\npotentially generate more test cases, which could\nthen improve the software more,",
    "start": "819510",
    "end": "825030"
  },
  {
    "text": "which-- So the ability of\ngenerating new test cases. And also if you look at\nsimulation, at some point,",
    "start": "825030",
    "end": "831120"
  },
  {
    "text": "you're going to be\nable to simulate molecules and chemistry and\nall sorts of things and sort",
    "start": "831120",
    "end": "836160"
  },
  {
    "text": "of aggregate systems. Now there may be a\nscalability issue, but I think the\nability of the systems",
    "start": "836160",
    "end": "842290"
  },
  {
    "text": "to generate more new test\ncases for themselves, it's pretty clear that\ncould happen in software.",
    "start": "842290",
    "end": "847330"
  },
  {
    "text": "And I expect it could happen\nin other domains as well. Yeah. I just attended the\nStanford Security Day.",
    "start": "847330",
    "end": "854140"
  },
  {
    "text": "And one of the talks\nwas using Copilot for helping you write code.",
    "start": "854140",
    "end": "861190"
  },
  {
    "text": "And the problem was that the\ncode that Copilot recommended",
    "start": "861190",
    "end": "866470"
  },
  {
    "text": "was far less secure\nthan the code that people who didn't use\nCopilot ended up writing.",
    "start": "866470",
    "end": "873220"
  },
  {
    "text": "And in fact, one\nexample was Copilot recommended this block of code. And in the comments, it said,\n\"For educational purposes only.",
    "start": "873220",
    "end": "881260"
  },
  {
    "text": "Do not use.\" And so we still have\nsome risks there",
    "start": "881260",
    "end": "886269"
  },
  {
    "text": "in terms of using these\nthings as code writers for us,",
    "start": "886270",
    "end": "893140"
  },
  {
    "text": "although I'm very\nbad at writing tests. And I'd love to get somebody\nto help me write tests.",
    "start": "893140",
    "end": "899019"
  },
  {
    "text": "So that might be safer than\nhaving it generate the code. That's a good thing that human\nprogrammers never mindlessly",
    "start": "899020",
    "end": "906190"
  },
  {
    "text": "cut and paste from\nStack Overflow or from other pieces of code. By the way, I have an\nexample from Stack Overflow",
    "start": "906190",
    "end": "912160"
  },
  {
    "text": "that says you should\nuse the same password. And it's highly upvoted. It's got 170 upvotes.",
    "start": "912160",
    "end": "918519"
  },
  {
    "text": "It says you should use the\nsame password at google.com and google.evil.com.",
    "start": "918520",
    "end": "924220"
  },
  {
    "text": "So there's-- [LAUGHING] OK. ",
    "start": "924220",
    "end": "931570"
  },
  {
    "text": "I think-- Yeah. I just wanted to respond to\nan incident about how Copilot",
    "start": "931570",
    "end": "938543"
  },
  {
    "text": "recommended some code that\nwas less secure than what they ended up going with. But if you view Copilot as just\nanother stream of information,",
    "start": "938543",
    "end": "946140"
  },
  {
    "text": "I can say even to help\nyou, it's not supposed to-- it wouldn't necessarily always--",
    "start": "946140",
    "end": "952830"
  },
  {
    "text": "as a human would not always\nwrite the perfect piece of code that would solve the problem\nof the best way possible.",
    "start": "952830",
    "end": "958350"
  },
  {
    "text": "So it's kind of like have to\nlook at it with multiple people, multiple Copilots to take a\nlook at the same block of code",
    "start": "958350",
    "end": "965460"
  },
  {
    "text": "and evaluate and say this one\nis more secure than that one, and then make a decision as you\ngo as the same way we write code",
    "start": "965460",
    "end": "971610"
  },
  {
    "text": "these days. Whenever I write code, I need at\nleast two or three other people at the company to review it\nand give me back some feedback",
    "start": "971610",
    "end": "978840"
  },
  {
    "text": "before we can push\nit to production. So there are levels between\nwhen we get someone to code",
    "start": "978840",
    "end": "988110"
  },
  {
    "text": "and when you actually deploy it. Right. Well, they surveyed\nthe programmers.",
    "start": "988110",
    "end": "995890"
  },
  {
    "text": "And the programmers\nwho use Copilot thought they were\ngenerating more secure code than the programmers who\nwere not using Copilot,",
    "start": "995890",
    "end": "1004020"
  },
  {
    "text": "which is a danger, too. But yes, code\nreviews are critical. If anybody wants to\nreview my code, please do.",
    "start": "1004020",
    "end": "1011430"
  },
  {
    "text": "But one rule is you're not\nallowed to laugh at it. But anyway, I thought that\nwas an interesting point.",
    "start": "1011430",
    "end": "1018330"
  },
  {
    "text": "And the conclusion was that\nCopilot lacked context.",
    "start": "1018330",
    "end": "1023670"
  },
  {
    "text": "So in particular\nin file access, it couldn't understand\nwhen the context said",
    "start": "1023670",
    "end": "1031980"
  },
  {
    "text": "that it was OK to open any file\nand when the request was coming from an untrusted source.",
    "start": "1031980",
    "end": "1038099"
  },
  {
    "text": "And that meant that\nit couldn't provide the kind of security guarantees\nthat a programmer who",
    "start": "1038099",
    "end": "1046230"
  },
  {
    "text": "knows the context could. And that was the\nconclusion of the talk. ",
    "start": "1046230",
    "end": "1052940"
  },
  {
    "text": "Well, I've had a\nchance over the years to look at large pieces of code\nin places like the internet.",
    "start": "1052940",
    "end": "1061490"
  },
  {
    "text": "And I'm not so sure\nthat we are not running code that's more\nof the demonstration",
    "start": "1061490",
    "end": "1072380"
  },
  {
    "text": "and educational\nuse in production than we perhaps ought\nto be even today.",
    "start": "1072380",
    "end": "1082179"
  },
  {
    "text": "A lot of early code exists\nand is used no matter what",
    "start": "1082180",
    "end": "1088670"
  },
  {
    "text": "the security review might say. Unfortunately, yeah.",
    "start": "1088670",
    "end": "1094309"
  },
  {
    "text": "Yeah. Well-- But there was another\narticle, again,",
    "start": "1094310",
    "end": "1099830"
  },
  {
    "text": "in The New York Times\nabout how it's not going to replace\npeople doing the work,",
    "start": "1099830",
    "end": "1104870"
  },
  {
    "text": "but it will do the boring\nparts of their jobs for them. And treating this as an overall\nbenefit at least in that aspect.",
    "start": "1104870",
    "end": "1114240"
  },
  {
    "text": "Not putting people out\nof work, but letting them focus on the hard problems\nrather than the drudgery.",
    "start": "1114240",
    "end": "1121590"
  },
  {
    "text": "I don't know to what extent\npeople agree with that. ",
    "start": "1121590",
    "end": "1128000"
  },
  {
    "text": "Does anyone agree? Because I would have be hard put\nto say what part of any given",
    "start": "1128000",
    "end": "1136549"
  },
  {
    "text": "job is the boring part. If I could-- Yes, go ahead.",
    "start": "1136550",
    "end": "1141710"
  },
  {
    "text": "See Dennis, I think the\nway it was described is putting lipstick on the pig.",
    "start": "1141710",
    "end": "1147777"
  },
  {
    "text": "You hear this every time,\nit's an advance in automation. Oh no, we're not putting\npeople out of work. We're just making\nthem more productive.",
    "start": "1147777",
    "end": "1153800"
  },
  {
    "text": "We're only automating the\nroutine or the bad parts. No, you're automating\nwhatever it",
    "start": "1153800",
    "end": "1159200"
  },
  {
    "text": "is that's going to make a\nhigher degree of productivity so you can do more with less.",
    "start": "1159200",
    "end": "1164720"
  },
  {
    "text": "And if that's automating\nthe exciting parts and you're stuck in-- like, the workers in\nan Amazon factory,",
    "start": "1164720",
    "end": "1171889"
  },
  {
    "text": "now they just stick\nstuff in boxes because that's the only part\nthat can't be automated. That's the way that's\ngoing to go down.",
    "start": "1171890",
    "end": "1178820"
  },
  {
    "text": "The idea that this isn't going\nto affect labor is silly. It's going to have\ndramatic impacts on labor.",
    "start": "1178820",
    "end": "1185450"
  },
  {
    "text": "And I don't think\nthat's necessarily bad. I think this is very common. There's been wave after\nwave of this kind of stuff.",
    "start": "1185450",
    "end": "1192629"
  },
  {
    "text": "And it's going to transform\nmost jobs as far as I can see. But it's also going to\neliminate a lot of jobs",
    "start": "1192630",
    "end": "1198990"
  },
  {
    "text": "and create a whole bunch\nof different jobs as well. Yeah, I agree with that. Yeah, I agree with that.",
    "start": "1198990",
    "end": "1204240"
  },
  {
    "text": " Yeah. So I think it's going to\neliminate an awful lot of jobs.",
    "start": "1204240",
    "end": "1213390"
  },
  {
    "text": "And it's probably\ngoing to eliminate jobs in sectors that have been\nfairly protected in past years.",
    "start": "1213390",
    "end": "1224610"
  },
  {
    "text": "If you noticed in\nthe current problem with television and movie\nwriters and the producing",
    "start": "1224610",
    "end": "1233460"
  },
  {
    "text": "agencies, they want to have\nprotection against the scripts",
    "start": "1233460",
    "end": "1239789"
  },
  {
    "text": "written by bots. Yeah. By the way, one of the\nmost amazing things",
    "start": "1239790",
    "end": "1245940"
  },
  {
    "text": "I saw in one of these\nvideos was the four words from Hemingway and the\nstories that the AI wrote.",
    "start": "1245940",
    "end": "1257160"
  },
  {
    "text": "Baby Shoes, Never Worn, and it\nwrote this very touching story.",
    "start": "1257160",
    "end": "1262620"
  },
  {
    "text": "That, to me, blows me away. I'd watch that TV.",
    "start": "1262620",
    "end": "1269330"
  },
  {
    "text": "Yeah. So we may get actual better\nprogramming from the bots that generate Netflix programs,\nis what you're saying.",
    "start": "1269330",
    "end": "1274940"
  },
  {
    "text": "Yeah, some of them\nare pretty bad. I watch almost\nanything with space.",
    "start": "1274940",
    "end": "1280850"
  },
  {
    "text": "And I'm currently\nwatching a very bad one. [LAUGHING] Is there a good one?",
    "start": "1280850",
    "end": "1286162"
  },
  {
    "text": "Oh yeah, there have\nbeen a few good ones. But mostly, they're dreadful. But I can do the crossword\npuzzle while I'm watching.",
    "start": "1286162",
    "end": "1293680"
  },
  {
    "text": "OK. Which one is that? I don't know. I have to think\nright now which one. ",
    "start": "1293680",
    "end": "1300350"
  },
  {
    "text": "Sisyphus, I just started. It sounds interesting, but\nit's got these crazy plot",
    "start": "1300350",
    "end": "1306320"
  },
  {
    "text": "holes in episode 1. For what it's\nworth, there a show",
    "start": "1306320",
    "end": "1312740"
  },
  {
    "text": "which is very directly\nrelevant to the conversation here that just came\nout called Mrs. Davis. Yes.",
    "start": "1312740",
    "end": "1318230"
  },
  {
    "text": "The name itself is supposed\nto be kind of off-putting or--",
    "start": "1318230",
    "end": "1323240"
  },
  {
    "text": "It could have been\nso much better. It is driving me crazy that\nit is as inane as it is.",
    "start": "1323240",
    "end": "1332650"
  },
  {
    "text": "I mean, they're not\nreally addressing-- they're showing the problems\nof this overarching AI",
    "start": "1332650",
    "end": "1338370"
  },
  {
    "text": "without ever exploring\nthe social effects of it.",
    "start": "1338370",
    "end": "1343410"
  },
  {
    "text": "And the storyline is pretty\nmuch orthogonal to the AI.",
    "start": "1343410",
    "end": "1349095"
  },
  {
    "text": "I don't know. It's irritating me. I'm five episodes in, but--",
    "start": "1349095",
    "end": "1354720"
  },
  {
    "text": "Well, it's because\nit wasn't written by an AI who knows about\nwhat it's like to be-- Yes, they didn't\ncare about that.",
    "start": "1354720",
    "end": "1361470"
  },
  {
    "text": "There you go. I've actually been\npreviously trying to use ChatGPT to actually\nstudy the ChatGPT.",
    "start": "1361470",
    "end": "1369150"
  },
  {
    "text": "So including its social\neffects and asking about if it can offer me material.",
    "start": "1369150",
    "end": "1374430"
  },
  {
    "text": "It's pretty good. It does offer material, how to\nprovide the safety regulation.",
    "start": "1374430",
    "end": "1379950"
  },
  {
    "text": "So at least it pointed\ncorrectly to the literature",
    "start": "1379950",
    "end": "1384960"
  },
  {
    "text": "that can, for example, tell\nmore about ethical concepts",
    "start": "1384960",
    "end": "1390440"
  },
  {
    "text": "and how to use\nthose in practice. So it was quite interesting. And there is general--",
    "start": "1390440",
    "end": "1396650"
  },
  {
    "text": "I don't remember who\nactually wrote it exactly, but I think it was also in\na book of Coeckelbergh, who",
    "start": "1396650",
    "end": "1405890"
  },
  {
    "text": "wrote a book on AI ethics,\nis that you can use the tools against the system\nwho made those tools in order",
    "start": "1405890",
    "end": "1414697"
  },
  {
    "text": "to fight them. But it also requires\ncertain structure so that, for example,\nlike regulations",
    "start": "1414697",
    "end": "1420590"
  },
  {
    "text": "that you can use these\ntools to fight back. So I think this may be also\nused because ChatGPT is also",
    "start": "1420590",
    "end": "1429570"
  },
  {
    "text": "made like an assistant. So this is one of the biggest\nrisks, I think, to the job",
    "start": "1429570",
    "end": "1434910"
  },
  {
    "text": "that it may pose,\nthe job of assistant. Because it does do a good\njob in that in some sense.",
    "start": "1434910",
    "end": "1442530"
  },
  {
    "text": "So of course, it depends on\nthe type of assistance people require. So I think it is quite\ninteresting to use it",
    "start": "1442530",
    "end": "1449490"
  },
  {
    "text": "when studying itself. So it won't reveal information\nhow it was made and et cetera.",
    "start": "1449490",
    "end": "1456600"
  },
  {
    "text": "So more not public, but it\ndoes help to find information, how to actually work\non these issues.",
    "start": "1456600",
    "end": "1463919"
  },
  {
    "text": "I just saw an example\nwhere they asked it, and it cited four books\nto explain how it works.",
    "start": "1463920",
    "end": "1469680"
  },
  {
    "text": "And none of those\nbooks actually exist. I saw a cited version, where\nit was a paper instead.",
    "start": "1469680",
    "end": "1478289"
  },
  {
    "text": "And they cited three,\nfour different things. And two of the\npapers didn't exist so the AI wrote one [INAUDIBLE].",
    "start": "1478290",
    "end": "1486153"
  },
  {
    "text": "[LAUGHTER] OK, that's interesting. For me, it was so that\nsome links didn't work,",
    "start": "1486154",
    "end": "1492970"
  },
  {
    "text": "but when it comes to the\nofficial sources like IEEE Institute and others, so like\nfrom European Commission,",
    "start": "1492970",
    "end": "1501160"
  },
  {
    "text": "those files existed. Just the links that it\nprovided, I don't know why, but those don't just work.",
    "start": "1501160",
    "end": "1507190"
  },
  {
    "text": "So you have to research it,\nthe piece of information, for example, it provides you.",
    "start": "1507190",
    "end": "1513549"
  },
  {
    "text": "But generally, concepts,\nit's named correctly at least from the academic literature.",
    "start": "1513550",
    "end": "1518769"
  },
  {
    "text": "Yeah, I was wondering-- these\nthings are trained on everything that's on the internet. I was wondering\nwhat would happen",
    "start": "1518770",
    "end": "1524950"
  },
  {
    "text": "if we trained it on more\nor less vetted sources-- published books, newspapers\nthat actually published errata",
    "start": "1524950",
    "end": "1535570"
  },
  {
    "text": "when they make a mistake,\nscientific journals, and left out things\nfrom unvetted sources",
    "start": "1535570",
    "end": "1542890"
  },
  {
    "text": "like Twitter and Facebook\nposts and whatnot. I wondered if that would make\na difference at least in terms",
    "start": "1542890",
    "end": "1551252"
  },
  {
    "text": "of the hallucination problem. ",
    "start": "1551252",
    "end": "1557090"
  },
  {
    "text": "That's an interesting question. ",
    "start": "1557090",
    "end": "1563380"
  },
  {
    "text": "So this is sort\nof like saying you don't want to teach history\nin the public schools",
    "start": "1563380",
    "end": "1571330"
  },
  {
    "text": "because it's\nsometimes disturbing? No, it means I\ndon't want to learn",
    "start": "1571330",
    "end": "1576520"
  },
  {
    "text": "history in the public schools\nfrom all my neighbors. I want to learn it\nfrom historians.",
    "start": "1576520",
    "end": "1583240"
  },
  {
    "text": "OK. Of all stripes. But I want vetted sources.",
    "start": "1583240",
    "end": "1590170"
  },
  {
    "text": "I want people who, if\nthey make a mistake,",
    "start": "1590170",
    "end": "1595780"
  },
  {
    "text": "are willing to admit\nit and will correct it. We don't get that in real life.",
    "start": "1595780",
    "end": "1603150"
  },
  {
    "text": "No, but we do get\nit in newspapers. They always have corrections. We get it in textbooks\nwith errata sections.",
    "start": "1603150",
    "end": "1610950"
  },
  {
    "text": "We get it-- We get it in review journals. We get it in review journals. Even though-- [INTERPOSING VOICES]",
    "start": "1610950",
    "end": "1616163"
  },
  {
    "text": "--up here, there is an\neffort to be correct, whereas on the general\ninternet, there's",
    "start": "1616163",
    "end": "1621870"
  },
  {
    "text": "often an incentive not to be. And so I'm just\nwondering what would happen if we built\nsomething that",
    "start": "1621870",
    "end": "1628620"
  },
  {
    "text": "was trained on vetted sources. That will be good experiment.",
    "start": "1628620",
    "end": "1635340"
  },
  {
    "text": "I think you're right. The issue here is curation. Right. And I think that\nwhat's going to happen",
    "start": "1635340",
    "end": "1641159"
  },
  {
    "text": "is it's expensive\nto curate stuff. And people are going to\ndevelop curated databases. And they will give\nyou access to it,",
    "start": "1641160",
    "end": "1647700"
  },
  {
    "text": "but it's going to cost money,\nthe quality of the stuff that you get. It's like the whole reason\nwe had Bloomberg Terminals",
    "start": "1647700",
    "end": "1654553"
  },
  {
    "text": "as you probably know-- [LAUGHING] Exactly. --was they had access to all\nof the accurate financial",
    "start": "1654553",
    "end": "1660330"
  },
  {
    "text": "information that other\npeople were just, \"My cousin says I\nshould buy IBM.\"",
    "start": "1660330",
    "end": "1665790"
  },
  {
    "text": "It was not the level of\ncuration that they wanted. So right now, this\nis just-- they just",
    "start": "1665790",
    "end": "1671937"
  },
  {
    "text": "throw everything in there. It's a kitchen sink, but\nI think that my guess is a whole ecosystem of\npeople to mine and curate data",
    "start": "1671937",
    "end": "1681870"
  },
  {
    "text": "to stick into these\nsystems is going to be very important\nfor the same reason that I read The New York Times,\nand I don't read, I don't know,",
    "start": "1681870",
    "end": "1690330"
  },
  {
    "text": "Daily Beast or something. Maybe that's a bad example. But then the\nquestion is, Is there",
    "start": "1690330",
    "end": "1696520"
  },
  {
    "text": "enough content to\nreach the level you need to make it useful?",
    "start": "1696520",
    "end": "1704290"
  },
  {
    "text": "I don't know. That's a good question. So it's a difficult\nquestion, Alan. I don't see how you can do\nthat except experimentally.",
    "start": "1704290",
    "end": "1714790"
  },
  {
    "text": "Yeah. And as you said, it's expensive. But Copilot costs\nlike $10 a month now.",
    "start": "1714790",
    "end": "1720630"
  },
  {
    "text": "And I'm sure that somebody\nwho spends the money to curate",
    "start": "1720630",
    "end": "1725790"
  },
  {
    "text": "could find a business\nmodel to recover that. Yeah. The other question\nis the predictors",
    "start": "1725790",
    "end": "1734030"
  },
  {
    "text": "all seem to be sort\nof next to symbol.",
    "start": "1734030",
    "end": "1742090"
  },
  {
    "text": "And maybe you\nshould be predicting two symbols or four symbols\nor three symbols or something.",
    "start": "1742090",
    "end": "1749830"
  },
  {
    "text": "And that would give a slightly\nlarger range of possibilities",
    "start": "1749830",
    "end": "1759610"
  },
  {
    "text": "and might converge more quickly. Or it might take lots\nlonger to converge or never",
    "start": "1759610",
    "end": "1765460"
  },
  {
    "text": "converge at all. Yeah, that's the concern because\nit's the wide-branching tree.",
    "start": "1765460",
    "end": "1773159"
  },
  {
    "text": "Right.  I don't know, I think I'm\ngoing to have to write one.",
    "start": "1773160",
    "end": "1778315"
  },
  {
    "text": " But then I have to find\na way to get my data in.",
    "start": "1778315",
    "end": "1784990"
  },
  {
    "text": "That's, of course,\nthe critical thing.",
    "start": "1784990",
    "end": "1790245"
  },
  {
    "start": "1790245",
    "end": "1796410"
  },
  {
    "text": "So what do you think is\ngoing to happen here? I mean, if this technology\ngets applied very broadly",
    "start": "1796410",
    "end": "1807940"
  },
  {
    "text": "across our society,\nwhich is, I'd say,",
    "start": "1807940",
    "end": "1814480"
  },
  {
    "text": "probability 1, to\nwhat extent are we",
    "start": "1814480",
    "end": "1822370"
  },
  {
    "text": "dependent on the technology? Well, I mean, there\nare enormous benefits.",
    "start": "1822370",
    "end": "1827380"
  },
  {
    "text": "I read that it solved\nthe folding problem of all the proteins\nin a human body",
    "start": "1827380",
    "end": "1833080"
  },
  {
    "text": "in the matter of a\ncouple of months, where it would take a\nPhD thesis per protein",
    "start": "1833080",
    "end": "1840910"
  },
  {
    "text": "without it, which is\npretty remarkable. So there are clearly\nbenefits here.",
    "start": "1840910",
    "end": "1847360"
  },
  {
    "text": "But the risks, there's the\nfake videos and fake pictures,",
    "start": "1847360",
    "end": "1853299"
  },
  {
    "text": "the pope in the fluffy jacket\nthat fooled a lot of people. It's going to make it that\nyou won't be able to trust",
    "start": "1853300",
    "end": "1859690"
  },
  {
    "text": "your lying eyes anymore. That's a real risk.",
    "start": "1859690",
    "end": "1865965"
  },
  {
    "text": "Or maybe-- It could. Maybe it's a benefit. We'll learn to be more\ncautious about what",
    "start": "1865965",
    "end": "1872059"
  },
  {
    "text": "we what we believe from\nwhat we read and see because this fake stuff\nwill be so persistent.",
    "start": "1872060",
    "end": "1880100"
  },
  {
    "text": "Go ahead. Well, maybe, or you'll\nend up with something like we had with\nthe COVID virus,",
    "start": "1880100",
    "end": "1887090"
  },
  {
    "text": "where there was a\nwhole industry created on being anti-COVID\nvirus and anti-vaccine.",
    "start": "1887090",
    "end": "1895520"
  },
  {
    "text": "And companies of substantial\nsize with substantial video",
    "start": "1895520",
    "end": "1904640"
  },
  {
    "text": "production skills were\nproducing documentaries which were sold over\nYouTube or places",
    "start": "1904640",
    "end": "1912530"
  },
  {
    "text": "like that, which were\npretty nice fiction.",
    "start": "1912530",
    "end": "1917540"
  },
  {
    "text": "Yeah. I think that this\nconcern in terms that it may teach\nus not to believe.",
    "start": "1917540",
    "end": "1923720"
  },
  {
    "text": "So I think we already\nexperienced something like that. And later it may just get worse\nin the sense that you cannot",
    "start": "1923720",
    "end": "1930980"
  },
  {
    "text": "believe anything, what\nyou see or what you hear, which can be quite problematic.",
    "start": "1930980",
    "end": "1936230"
  },
  {
    "text": "Because human is\nactually made on trust. We trust others that\nthey will not attack us.",
    "start": "1936230",
    "end": "1941820"
  },
  {
    "text": "We trust others to\nactually build something. So this is how society is built.\nIt's built on trust, initially.",
    "start": "1941820",
    "end": "1947970"
  },
  {
    "text": "So in some sense, you have\nto turn your back to others and let them cover it for you\nso that you can do your thing.",
    "start": "1947970",
    "end": "1954630"
  },
  {
    "text": "Because if we would\njust constantly try to protect ourselves,\nwe wouldn't actually make it to society at all.",
    "start": "1954630",
    "end": "1961560"
  },
  {
    "text": "We're not talking even\nthe level as it is now. And of course, it is about\nhow to enjoy the good things",
    "start": "1961560",
    "end": "1968970"
  },
  {
    "text": "and try to minimize the bad,\nthe side effects that it has,",
    "start": "1968970",
    "end": "1974730"
  },
  {
    "text": "which can be quite severe. And I think that one way is\nthe certification that I think",
    "start": "1974730",
    "end": "1981960"
  },
  {
    "text": "I previously talked about. So then it would\nlimit the access. So again, since this\npowerful technology,",
    "start": "1981960",
    "end": "1989670"
  },
  {
    "text": "it would just help to\nminimize who has access",
    "start": "1989670",
    "end": "1995370"
  },
  {
    "text": "to this in the sense that it\nmay be available public but not",
    "start": "1995370",
    "end": "2000770"
  },
  {
    "text": "to the full capacity. Because again, it\ncan be weaponized. It can be used for many things.",
    "start": "2000770",
    "end": "2007100"
  },
  {
    "text": "And it also important\nto actually introduce certain education\nfor general users,",
    "start": "2007100",
    "end": "2013730"
  },
  {
    "text": "how to make decisions\nwith such tools, how to receive information\nfrom such tools.",
    "start": "2013730",
    "end": "2019429"
  },
  {
    "text": "Because now we are introducing\ndigital literacy in school. But since the technology pace\nis quite fast, it's also,",
    "start": "2019430",
    "end": "2026840"
  },
  {
    "text": "I think, important to\ninclude AI tools as well. So that would be\ndefinitely important.",
    "start": "2026840",
    "end": "2034370"
  },
  {
    "text": "At least I think it's highly\nimportant to teach kids because we can-- all\nright, OK, we can kind of",
    "start": "2034370",
    "end": "2040190"
  },
  {
    "text": "manage in some sense. But when it comes to\nmore vulnerable minds,",
    "start": "2040190",
    "end": "2045260"
  },
  {
    "text": "there is some\ndefinitely explanation and lessons should be given. So again, certification\nwould also not",
    "start": "2045260",
    "end": "2053030"
  },
  {
    "text": "only establish who can\nkind of use the technology or who has a right\nto do that, but also",
    "start": "2053030",
    "end": "2060679"
  },
  {
    "text": "when you receive certificate,\nthat means you pass through a certain training. It means that you know or\nlearned about this technology.",
    "start": "2060679",
    "end": "2069079"
  },
  {
    "text": "And it's also good\nif we could include the ethical and also other\ntype of social consequences",
    "start": "2069080",
    "end": "2077719"
  },
  {
    "text": "that it may bring. So for example, even those\nteams of ethics and society",
    "start": "2077719",
    "end": "2085129"
  },
  {
    "text": "that even were in Microsoft. So there was this article that\nnoted that they actually help",
    "start": "2085130",
    "end": "2092510"
  },
  {
    "text": "to understand the consequence. Because sometimes we just\ncannot see what can happen.",
    "start": "2092510",
    "end": "2098540"
  },
  {
    "text": "It requires\nexplanation, examples, and other types of\nwork to actually give",
    "start": "2098540",
    "end": "2104570"
  },
  {
    "text": "this kind of view because, yes,\none thing when you study it or when you kind of\ninteracted with this before",
    "start": "2104570",
    "end": "2111637"
  },
  {
    "text": "and you understand this,\nbut the other thing is when you never\nactually face this before. So you may have some ideas but\nnever explored or never got",
    "start": "2111637",
    "end": "2121900"
  },
  {
    "text": "the opportunity to do that. So this is also important. And I think the\ncertain shifting power.",
    "start": "2121900",
    "end": "2129400"
  },
  {
    "text": "So from certain companies that\nown the technology because now there is this big race going on.",
    "start": "2129400",
    "end": "2135940"
  },
  {
    "text": "So who will basically dominate\nin this area or this technology.",
    "start": "2135940",
    "end": "2142230"
  },
  {
    "text": "So if only one company or two\ncompanies in the world control AI, basically, what\nthat means also for us.",
    "start": "2142230",
    "end": "2151109"
  },
  {
    "text": "So because, again, it's\npowerful technology, it also studies human. So it may persuade, right?",
    "start": "2151110",
    "end": "2158190"
  },
  {
    "text": "It may influence. It may do many other\nthings that actually",
    "start": "2158190",
    "end": "2164339"
  },
  {
    "text": "in this human-computer\ninteraction that can influence\nopinion or ideas.",
    "start": "2164340",
    "end": "2170880"
  },
  {
    "text": "And it's so subtle. It may not even be so\nmuch pointed at first",
    "start": "2170880",
    "end": "2177359"
  },
  {
    "text": "or even considered\nto be as breaking some law or human rights\nbecause some of these influences",
    "start": "2177360",
    "end": "2184470"
  },
  {
    "text": "are so subtle that\nit only later comes so clear what was happening.",
    "start": "2184470",
    "end": "2191040"
  },
  {
    "text": "And it may take quite a\nwhile, which is problematic. So yes.",
    "start": "2191040",
    "end": "2196320"
  },
  {
    "text": "So I think we do have\na model in the handling of biological systems, where\nwe have the level 1 for things",
    "start": "2196320",
    "end": "2203520"
  },
  {
    "text": "that if they escaped the\nlab, it's not terrible. And level 4, we have\na pandemic if it does.",
    "start": "2203520",
    "end": "2210310"
  },
  {
    "text": "And I wonder if that's\na model that we can use to regulate these systems.",
    "start": "2210310",
    "end": "2217020"
  },
  {
    "text": "Yes, I think it's\nvery interesting. And before, I thought also\nlooking in this direction",
    "start": "2217020",
    "end": "2222570"
  },
  {
    "text": "because generally,\nthis type of things are already considered as\nhaving big social impact.",
    "start": "2222570",
    "end": "2230910"
  },
  {
    "text": "So yes, again, if\nCorona gets out, it has not only impact on\nhealth, on social as well.",
    "start": "2230910",
    "end": "2237130"
  },
  {
    "text": "And many of us experienced it. Before, it wasn't so clear. But now we know that lockdown\nhas effects on mentality.",
    "start": "2237130",
    "end": "2245250"
  },
  {
    "text": "We can't just put our bodies\nin apartment or in a house in some space and stay there.",
    "start": "2245250",
    "end": "2252490"
  },
  {
    "text": "Why not? Like, logically, why not? Like, you could just stay, make\nsome calls to your close one.",
    "start": "2252490",
    "end": "2259240"
  },
  {
    "text": "It also has these\nsubtle influences that influence human, not our logic.",
    "start": "2259240",
    "end": "2265119"
  },
  {
    "text": "We're not only\nlogical creatures. So we're not consist\npurely of syntax.",
    "start": "2265120",
    "end": "2270570"
  },
  {
    "text": "And I think it's also\ngetting into the system, this understanding\nof human nature.",
    "start": "2270570",
    "end": "2275760"
  },
  {
    "text": "And again, like you mentioned\nthis, level 4, level 1, I think it's classification.",
    "start": "2275760",
    "end": "2281910"
  },
  {
    "text": "This would be important. Also, classification in the\nfields is important, I think.",
    "start": "2281910",
    "end": "2287130"
  },
  {
    "text": "Because different AI in\ndifferent disciplines affect disciplines differently.",
    "start": "2287130",
    "end": "2292650"
  },
  {
    "text": "So one thing when it's\nlike in the medicine, another thing when it's in\nsocial media, and et cetera.",
    "start": "2292650",
    "end": "2298559"
  },
  {
    "text": "So I think it's important. And as I was saying\nregarding CRISPR, right?",
    "start": "2298560",
    "end": "2306000"
  },
  {
    "text": "So we know it may affect human\nand following generations. So there are strict regulations\nand safety procedures",
    "start": "2306000",
    "end": "2313724"
  },
  {
    "text": "on how actually use it. So there is rigorous\ntesting before it gets out",
    "start": "2313725",
    "end": "2319560"
  },
  {
    "text": "or even used for something. So in that sense, yes, it\nis good, like a blueprint.",
    "start": "2319560",
    "end": "2327130"
  },
  {
    "text": "But there is, of course,\nsome adjustments required.",
    "start": "2327130",
    "end": "2332819"
  },
  {
    "text": "Yeah. My friend's written a science\nfiction book, actually a series. And one of the key parts is\nthat CRISPR has escaped and has",
    "start": "2332820",
    "end": "2342090"
  },
  {
    "text": "become available to terrorists. And that would be a risk with\ntrying to limit the AI this way,",
    "start": "2342090",
    "end": "2348840"
  },
  {
    "text": "too. This would be a big risk\nbecause, OK, one thing, you affect one generation.",
    "start": "2348840",
    "end": "2355530"
  },
  {
    "text": "OK, but you follow-- you then influence\nall other generations. So would you prohibit\npeople then having children,",
    "start": "2355530",
    "end": "2363120"
  },
  {
    "text": "those who are affected if\nit's a huge, for example, piece of population of certain\ncountry or even worldwide?",
    "start": "2363120",
    "end": "2371130"
  },
  {
    "text": "How then it's approached\nbecause, again, this is prohibited for a\nreason because one,",
    "start": "2371130",
    "end": "2377160"
  },
  {
    "text": "yes, you may know approximately,\nor you may be sure that this piece of DNA\nrespond for this element,",
    "start": "2377160",
    "end": "2386190"
  },
  {
    "text": "but it may also respond\nfor something else. And then it can be a problem. Yeah. So there was a DNA\nCRISPR implemented",
    "start": "2386190",
    "end": "2395170"
  },
  {
    "text": "for twins for, I\nthink, HIV protection because one of their parents has\nHIV so that they would be safe.",
    "start": "2395170",
    "end": "2402545"
  },
  {
    "text": "Yes.  Not now, but there's definitely\nprison time involved.",
    "start": "2402545",
    "end": "2410410"
  },
  {
    "text": "But I'm not sure how long\nand whether it's actually--",
    "start": "2410410",
    "end": "2416349"
  },
  {
    "text": "how did they later\napproach the situation, but it was definitely a shock\nthat this technology was",
    "start": "2416350",
    "end": "2422110"
  },
  {
    "text": "used for gene editing because\nthe children of those children",
    "start": "2422110",
    "end": "2428080"
  },
  {
    "text": "will also have this. So it's going to stay there. Yeah. [INAUDIBLE]",
    "start": "2428080",
    "end": "2433576"
  },
  {
    "text": "Oh sorry, do you have more? I just-- like you started\ntalking, I got an idea that-- or wanted to add\nthat same can be",
    "start": "2433576",
    "end": "2440710"
  },
  {
    "text": "this AI because this\nsort of influences on our nature, human nature\ncan also be passed down.",
    "start": "2440710",
    "end": "2446680"
  },
  {
    "text": "So people from--\nlike, our parents, they had their ideas in\nthem, which they pass down,",
    "start": "2446680",
    "end": "2454329"
  },
  {
    "text": "whether we accept them or\nnot, they still influence. Same can be here, like social\nmedia, those people who",
    "start": "2454330",
    "end": "2460299"
  },
  {
    "text": "grew up with it will\nhave certain ideas that will be passed down. How maybe the mind, the\nideas toward, again, society,",
    "start": "2460300",
    "end": "2469900"
  },
  {
    "text": "they also will be passed down. So it all have influences,\nmaybe not directly biological but it does manifest.",
    "start": "2469900",
    "end": "2477340"
  },
  {
    "text": "Yeah, I just wanted to go back\nto what I was saying about how this technology kind of--",
    "start": "2477340",
    "end": "2482740"
  },
  {
    "text": "I don't know how\nyou were saying it, kind of reminded me\nof like how we're treating nuclear\ntechnology at this time.",
    "start": "2482740",
    "end": "2488290"
  },
  {
    "text": "The knowhow of how to\nmake nuclear weapons or how to do anything when\nit comes to that field",
    "start": "2488290",
    "end": "2496730"
  },
  {
    "text": "is heavily guarded and\nhas become something that you can only study\nat certain places.",
    "start": "2496730",
    "end": "2501758"
  },
  {
    "text": "They only give the\ninformation to you once you reach a certain\nclearance or security level. Would you think that\nwould then carry on",
    "start": "2501758",
    "end": "2509359"
  },
  {
    "text": "for AI because if anyone is able\nto create a large language model and be able to scrape\nthe internet for data",
    "start": "2509360",
    "end": "2516140"
  },
  {
    "text": "and create these models that\nare capable of, I don't know, doing whatever we\nwant, there is no way",
    "start": "2516140",
    "end": "2521780"
  },
  {
    "text": "to limit or have certifications\nor have some sort of, I don't",
    "start": "2521780",
    "end": "2527540"
  },
  {
    "text": "know, blocks in order\nto, in our words, protect society\nfrom its effects.",
    "start": "2527540",
    "end": "2533608"
  },
  {
    "text": "They can be deployed\nanywhere because we're so interconnected\nwith the internet.",
    "start": "2533608",
    "end": "2539119"
  },
  {
    "text": "So how would that work? Would you think there would\nbe a kind of like restriction on the studying of\nlarge language models",
    "start": "2539120",
    "end": "2548450"
  },
  {
    "text": "and generative AI? Or do you think\nthat's not necessary in order to introduce\ncertifications and introduce",
    "start": "2548450",
    "end": "2557589"
  },
  {
    "text": "limits on how it's\nallowed to be used, when it's allowed to be\nused, and what kind of models can be made?",
    "start": "2557590",
    "end": "2562600"
  },
  {
    "text": "I don't think it's possible\nto control studying it. That's for sure. But I'll answer the\nrest of the questions.",
    "start": "2562600",
    "end": "2569620"
  },
  {
    "text": "[LAUGHING] I hope somebody can\nalso talk because I think talk too much on this. [INTERPOSING VOICES]",
    "start": "2569620",
    "end": "2575370"
  },
  {
    "text": "No, you're very clear\nabout what you're saying.",
    "start": "2575370",
    "end": "2580920"
  },
  {
    "text": "And we appreciate it enormously. And you're the only professional\non the topic here, too, so.",
    "start": "2580920",
    "end": "2586390"
  },
  {
    "text": "I'm not professional. Just read a lot and\nstart to work with this. But maybe I'm getting there.",
    "start": "2586390",
    "end": "2592550"
  },
  {
    "text": "OK. So also, this point was in\na video of Raskin and Harris from Center for Humane\nTechnology that Dennis shared.",
    "start": "2592550",
    "end": "2602440"
  },
  {
    "text": "So there was this very\ninteresting idea that nukes cannot make stronger nukes,\nbut AI can make stronger AI.",
    "start": "2602440",
    "end": "2612200"
  },
  {
    "text": "So it can actually\nenhance itself. Plus nukes are dependent\non certain material",
    "start": "2612200",
    "end": "2620210"
  },
  {
    "text": "that certain countries can get-- AI doesn't. So you can make it.",
    "start": "2620210",
    "end": "2626820"
  },
  {
    "text": "You need just enough\ncomputing power and purchase all the things.",
    "start": "2626820",
    "end": "2632520"
  },
  {
    "text": "And also depends on the how\nstrong you want to make it, how you want to train it. So to what extent it will be\nunsupervised because that also",
    "start": "2632520",
    "end": "2642930"
  },
  {
    "text": "depend computation. And so it could be\nused in that sense, but it's still different case.",
    "start": "2642930",
    "end": "2649080"
  },
  {
    "text": "That's what's important\nto understand. Because there is still-- there\nis some limits by countries.",
    "start": "2649080",
    "end": "2654180"
  },
  {
    "text": "But here, there are no limits. It's like worldwide. So you can't-- there are certain\nways to, of course, regulate it.",
    "start": "2654180",
    "end": "2662880"
  },
  {
    "text": "There are ideas. And there is an action becoming\nclearer, but you just still--",
    "start": "2662880",
    "end": "2670050"
  },
  {
    "text": "it is good idea to\nlook into this field as well to learn\nfrom it, yet still",
    "start": "2670050",
    "end": "2676560"
  },
  {
    "text": "requires understanding\nthat it's something else. So we have not really faced this\ntype of ubiquitous technology",
    "start": "2676560",
    "end": "2683920"
  },
  {
    "text": "before, I think. So then it would be\npossible or would not",
    "start": "2683920",
    "end": "2689280"
  },
  {
    "text": "be possible to limit and\ncertify certain people to make certain language models\nand certify certain language",
    "start": "2689280",
    "end": "2696030"
  },
  {
    "text": "models as being safe? If anyone and everyone can\njust constantly make it, would it make any\nsense to even do that?",
    "start": "2696030",
    "end": "2702390"
  },
  {
    "text": "Because then at that\npoint, if you certify-- I don't know,\nspend a lot of time creating a certifying\nlanguage model,",
    "start": "2702390",
    "end": "2708839"
  },
  {
    "text": "and I know 10 other people\njust create 10 language models without these certifications,\nwithout any of the safeguards",
    "start": "2708840",
    "end": "2714690"
  },
  {
    "text": "and then just deploy them\nallow people to use them, what is there to say\nthat someone won't use the kind of uncertified model?",
    "start": "2714690",
    "end": "2722580"
  },
  {
    "text": "What was the point of even\nmaking the certified [INAUDIBLE] uncertified one? This is a very good question.",
    "start": "2722580",
    "end": "2729030"
  },
  {
    "text": "And in this sense, I suggest to\nlook into automobile industry or aeroplane industry.",
    "start": "2729030",
    "end": "2734850"
  },
  {
    "text": "So you can fly on an airplane\nwithout certification, but it's unlikely it's\npublic airline or something.",
    "start": "2734850",
    "end": "2742380"
  },
  {
    "text": "But you can, of course. So certification is not only\ntied to a certain country.",
    "start": "2742380",
    "end": "2748720"
  },
  {
    "text": "There are universal\ncertifications that any country can receive\nthat would show the quality standard.",
    "start": "2748720",
    "end": "2754210"
  },
  {
    "text": "So when you use\nlanguage model that is certified that has standard\nthat was verified and tested,",
    "start": "2754210",
    "end": "2761590"
  },
  {
    "text": "it gives also trust from people. Because later I think when\npeople learn more about this,",
    "start": "2761590",
    "end": "2766960"
  },
  {
    "text": "they will also consider,\nOK, this technology is this language model. I hope this will\nbe maybe or not.",
    "start": "2766960",
    "end": "2773069"
  },
  {
    "text": "I don't know what\nto think about. But it should be also clear. And since there are more\nbrands, so to say, of it,",
    "start": "2773070",
    "end": "2780520"
  },
  {
    "text": "there will be also choices. And so when certified people\nhave more trust into it, right?",
    "start": "2780520",
    "end": "2787599"
  },
  {
    "text": "Or same into\nautomobile industry. You have certification. You also have self-certification\nthat requires actually",
    "start": "2787600",
    "end": "2796630"
  },
  {
    "text": "for the car being produced. There is also how to handle\ncustomer certifications. So certification\nwill never hurt.",
    "start": "2796630",
    "end": "2803470"
  },
  {
    "text": "That's for sure, I think. Because it provides more clearer\nunderstanding of the technology",
    "start": "2803470",
    "end": "2812280"
  },
  {
    "text": "to the person who provides it,\nwho develops it and et cetera, and hopefully, to the users,\nwho also may take some lessons,",
    "start": "2812280",
    "end": "2819870"
  },
  {
    "text": "or they may not\nreceive a certificate, which is maybe required for\ndevelopment and distribution.",
    "start": "2819870",
    "end": "2826020"
  },
  {
    "text": "But they can take\nsome lessons that hopefully would be introduced\nin schools and universities.",
    "start": "2826020",
    "end": "2831180"
  },
  {
    "text": "So in that sense,\ncertification, it's just-- it's already happening\nbecause it is a technology.",
    "start": "2831180",
    "end": "2837720"
  },
  {
    "text": "It should be certified. There should be a standard. Can I comment on-- I don't think we can--",
    "start": "2837720",
    "end": "2844530"
  },
  {
    "text": "it's a fool's errand to try\nto control who develops this or what you're allowed to\ndevelop or what kind of data",
    "start": "2844530",
    "end": "2850290"
  },
  {
    "text": "you can get. What we need to do\nis regulate use. And you have to meet\ncertain standards in order",
    "start": "2850290",
    "end": "2855928"
  },
  {
    "text": "to use it for certain purposes. We do this all over the place. And I can read all I want and\nlearn all I want about the law.",
    "start": "2855928",
    "end": "2862530"
  },
  {
    "text": "But to practice law, I have\nto be certified in order to engage in that behavior.",
    "start": "2862530",
    "end": "2868420"
  },
  {
    "text": "So I think this is the same\nthing is going to happen here. We have the same thing\nin political advertising",
    "start": "2868420",
    "end": "2874510"
  },
  {
    "text": "on television. If you put out an ad, the\nperson on whose behalf",
    "start": "2874510",
    "end": "2880420"
  },
  {
    "text": "the ad is being put has\nto say I'm so-and-so, and I approve this ad.",
    "start": "2880420",
    "end": "2885790"
  },
  {
    "text": "Well, that's the\nkind of thing we're going to need in a wide\nvariety of different areas.",
    "start": "2885790",
    "end": "2891160"
  },
  {
    "text": "We're probably in education,\njust to pick something. Before you're allowed\nto use this technology",
    "start": "2891160",
    "end": "2896980"
  },
  {
    "text": "unsupervised with respect\nto, say, eighth graders, it has to be vetted and\nmeet certain standards.",
    "start": "2896980",
    "end": "2904630"
  },
  {
    "text": "And you'll have committees\nthat can approve that. So that's the way I think\nthis whole thing has",
    "start": "2904630",
    "end": "2910690"
  },
  {
    "text": "to be rolled out. So the important\nquestion is, Can we identify in advance what\nthose dangers are and lay down",
    "start": "2910690",
    "end": "2918310"
  },
  {
    "text": "those guide rails in advance? Or do we need to wait and\nsee what happens and then try",
    "start": "2918310",
    "end": "2923830"
  },
  {
    "text": "to roll it back? You're not allowed to use this\nthing to talk to children. You're not allowed to\nuse it for persuading",
    "start": "2923830",
    "end": "2931870"
  },
  {
    "text": "people under certain conditions\nor whatever it might be, or for political discourse.",
    "start": "2931870",
    "end": "2936976"
  },
  {
    "text": "That's the kind of\nrestrictions that I think will come out in\nregulatory frameworks over the next decade or so.",
    "start": "2936977",
    "end": "2943000"
  },
  {
    "text": "I just ran into an\ninteresting example that the AI is making\nbiometrics less secure.",
    "start": "2943000",
    "end": "2952960"
  },
  {
    "text": "They can record your voice\nfor as little as five seconds and then completely reproduce\nyour speech patterns,",
    "start": "2952960",
    "end": "2959800"
  },
  {
    "text": "visual, like face ID\npresumably could be fooled as these things get better.",
    "start": "2959800",
    "end": "2966520"
  },
  {
    "text": "So it's going to have an\nimpact on biometrics, which I thought was interesting.",
    "start": "2966520",
    "end": "2971610"
  },
  {
    "text": "Yeah, but there are\ntwo levels here. We've got the level where\nthe product is the AI itself.",
    "start": "2971610",
    "end": "2980789"
  },
  {
    "text": "And then the product is\nthe creation of an AI. And are we going to\ngive AIs agency or not?",
    "start": "2980790",
    "end": "2988650"
  },
  {
    "text": "Are they going to be able\nto sign contracts and create things, which is then\nsold in the marketplace",
    "start": "2988650",
    "end": "2996510"
  },
  {
    "text": "as belonging to the AI? Or do you have the\nissue of the AI",
    "start": "2996510",
    "end": "3002360"
  },
  {
    "text": "always being a slave to a human? Well-- Dennis-- go ahead.",
    "start": "3002360",
    "end": "3009540"
  },
  {
    "text": "There's major issues in terms of\ncopyright and patent protection that hit directly on\nthe kind of issues",
    "start": "3009540",
    "end": "3015839"
  },
  {
    "text": "that you're talking about. Can it be protected? Can the output of these\nthings be copyrighted?",
    "start": "3015840",
    "end": "3024420"
  },
  {
    "text": "If it comes up with an\ninvention, who owns that? These are all issues that have\nto be worked out in the law. But to me, the whole thing\nrevolves around the legal theory",
    "start": "3024420",
    "end": "3033120"
  },
  {
    "text": "of product liability. You put a product out there\nand you say it's good for this. And it turns out it's\nnot good for that",
    "start": "3033120",
    "end": "3039270"
  },
  {
    "text": "or it's dangerous for that\nor it has some side effect, you've got liability. And I think that in contrast to\nwhat happened with social media",
    "start": "3039270",
    "end": "3045690"
  },
  {
    "text": "with Section 230\nof the whatever, Digital Communications\nAct, we need",
    "start": "3045690",
    "end": "3053070"
  },
  {
    "text": "to be a lot more restrictive\nabout what kind of liability",
    "start": "3053070",
    "end": "3058620"
  },
  {
    "text": "goes along with the release\nof these particular systems. Yeah, that's probably true.",
    "start": "3058620",
    "end": "3063980"
  },
  {
    "text": "But I'm not really certain\nthat all of AI's output",
    "start": "3063980",
    "end": "3070160"
  },
  {
    "text": "is going to be generated\nunder human control.",
    "start": "3070160",
    "end": "3075230"
  },
  {
    "text": "They have hallucinations\nin some sense. They could easily have\nsome sort of self-generated",
    "start": "3075230",
    "end": "3086059"
  },
  {
    "text": "\"I must tell a\nstory\" and continue to tell stories built into\nthe their internal structure,",
    "start": "3086060",
    "end": "3096530"
  },
  {
    "text": "which we didn't put there. They learned that. And so it's not\nclear at all to me",
    "start": "3096530",
    "end": "3103680"
  },
  {
    "text": "that we haven't\ncreated another source of substantial\nintelligence on the planet.",
    "start": "3103680",
    "end": "3110580"
  },
  {
    "text": "Maybe not really\nclear intelligence and maybe not all\nthat smart, but it looks to me like it has\nthe same sort of rights.",
    "start": "3110580",
    "end": "3118260"
  },
  {
    "text": "When you can't\ntell the difference between the output of an AI and\nthe output of a human being,",
    "start": "3118260",
    "end": "3124800"
  },
  {
    "text": "it becomes kind of hard to give\none rights and the other not. Well, but there may be\nrequirements to label.",
    "start": "3124800",
    "end": "3132119"
  },
  {
    "text": "That's another approach\nthat this can be. But again, coming back\nto the law, Dennis, there's this concept in the\nlaw about what kind of control",
    "start": "3132120",
    "end": "3140609"
  },
  {
    "text": "you have over your animals. And the interesting thing, it's\ncalled \"first bite\" theory.",
    "start": "3140610",
    "end": "3145770"
  },
  {
    "text": "And really, I'm\nnot making this up,",
    "start": "3145770",
    "end": "3152580"
  },
  {
    "text": "what happens is\nyou have a respon-- the question is,\nAre you responsible if your dog bites somebody?",
    "start": "3152580",
    "end": "3158190"
  },
  {
    "text": "And the answer is if you\ntook reasonable precautions and there was no\nreason to believe",
    "start": "3158190",
    "end": "3163270"
  },
  {
    "text": "that was going to happen,\nthe first time out, you don't have a criminal\nliability for that.",
    "start": "3163270",
    "end": "3169210"
  },
  {
    "text": "If you've been on notice-- and that's pretty well\ndefined in the law--",
    "start": "3169210",
    "end": "3174309"
  },
  {
    "text": "then you are liable. And there are people who've\ngone to jail for their dogs",
    "start": "3174310",
    "end": "3180520"
  },
  {
    "text": "biting other people because\nthey had already good evidence that that might happen and could\ncause those kinds of problems.",
    "start": "3180520",
    "end": "3186710"
  },
  {
    "text": "So we're going to have to have\nsome kind of \"first bite\" theory for these AIs\nbecause we just don't",
    "start": "3186710",
    "end": "3192619"
  },
  {
    "text": "know what they're going to do. And they are kind of like dogs. And we just don't\nhave the leashes yet. And we need to figure out how\nto get leashes and put them",
    "start": "3192620",
    "end": "3199990"
  },
  {
    "text": "on these systems so that\nthere's some measure of control at least within some kind\nof radius or boundary.",
    "start": "3199990",
    "end": "3208920"
  },
  {
    "text": "Yeah, so I wanted to-- I like the idea of the\n\"first bite\" theory. So are you suggesting as\ncompany, Facebook, OpenAI,",
    "start": "3208920",
    "end": "3215040"
  },
  {
    "text": "releases a large language model. People discover as\nthey already have that it can do research\nlevel chemistry",
    "start": "3215040",
    "end": "3221460"
  },
  {
    "text": "and can tell you how to\nbuild great synthesized nerve agents from ingredients\nyou buy at home depot.",
    "start": "3221460",
    "end": "3228780"
  },
  {
    "text": "And so somebody does this. And so the first time this\nhappens, Facebook isn't liable. But the second time, they are.",
    "start": "3228780",
    "end": "3234960"
  },
  {
    "text": "And the question is,\nCan they even recall it once the cat is out of the bag? Yeah, I worry about that.",
    "start": "3234960",
    "end": "3243570"
  },
  {
    "text": "Yes. So there is a couple of\nthings I want to mention. So there was a question\nregarding the status of AI,",
    "start": "3243570",
    "end": "3253560"
  },
  {
    "text": "so moral and as an agent. So for now, it is\nconsidered that it does not",
    "start": "3253560",
    "end": "3262030"
  },
  {
    "text": "have the capability to actually\nbe considered as an agent",
    "start": "3262030",
    "end": "3268390"
  },
  {
    "text": "or as having personhood. So it's just good to leave\nspace for that to rethink.",
    "start": "3268390",
    "end": "3274480"
  },
  {
    "text": "But currently, it\nis more like a tool. Yet there have been\npropositions for giving it",
    "start": "3274480",
    "end": "3281680"
  },
  {
    "text": "the status of\nelectronic persons. So it was a proposition--",
    "start": "3281680",
    "end": "3287440"
  },
  {
    "text": "it was definitely controversial\nresolution of 2017 in the European\nparliament, which",
    "start": "3287440",
    "end": "3294580"
  },
  {
    "text": "suggested that given the more\nsophisticated autonomous robot, the status for\nelectronic persons, which",
    "start": "3294580",
    "end": "3300160"
  },
  {
    "text": "would be like one\npossible legal solution to the issue of\nlegal responsibility. But it was not taken by European\ncommission into 2018 strategy.",
    "start": "3300160",
    "end": "3311120"
  },
  {
    "text": "But there is this idea\nthat occasionally depending on the context, it may get\nthis electronic personhood, so",
    "start": "3311120",
    "end": "3318080"
  },
  {
    "text": "situational agency. Because it's already\ndoing things on its own.",
    "start": "3318080",
    "end": "3324589"
  },
  {
    "text": "Of course, we should\nalso think how much we want to rely on it\nbecause it all can be hacked.",
    "start": "3324590",
    "end": "3330140"
  },
  {
    "text": "It all can go wrong. So there is this\nquestion as well. And another point\nwas about non-humans.",
    "start": "3330140",
    "end": "3338650"
  },
  {
    "text": "So definitely, there's been\ncertain crossing in that sense.",
    "start": "3338650",
    "end": "3344740"
  },
  {
    "text": "So how do we treat\nnon-humans and then AI, which is another\ntype of non-human?",
    "start": "3344740",
    "end": "3350440"
  },
  {
    "text": "So living non-humans and\nnon-living non-humans. So how do we distinguish them?",
    "start": "3350440",
    "end": "3357700"
  },
  {
    "text": "Do we value them differently? So does AI actually\nequals the dog?",
    "start": "3357700",
    "end": "3363520"
  },
  {
    "text": "Or is dog more valuable\nor maybe more valuable? So I think at the\nmoment probably",
    "start": "3363520",
    "end": "3369220"
  },
  {
    "text": "the dog is more\nvaluable as a being. But we will see\nhow this goes on.",
    "start": "3369220",
    "end": "3376069"
  },
  {
    "text": "So the \"first bite\"\ntheory is actually-- it's a good example.",
    "start": "3376070",
    "end": "3381829"
  },
  {
    "text": "And it exists in some\nsense, so some skeptics they also consider\nthat there may not",
    "start": "3381830",
    "end": "3387980"
  },
  {
    "text": "be time for regulations now. So it may be too early because\nAI is still nascent, right?",
    "start": "3387980",
    "end": "3395059"
  },
  {
    "text": "So it would be better\nto create rules once the applications\nappear in the market and violate existing laws.",
    "start": "3395060",
    "end": "3401870"
  },
  {
    "text": "But the problem is that the\nviolations that may occur may be quite severe and having\ncertain chain of consequences.",
    "start": "3401870",
    "end": "3410420"
  },
  {
    "text": "So at least I think it's\nimportant to wrap some head around it or at least try to.",
    "start": "3410420",
    "end": "3415850"
  },
  {
    "text": "So even some regulations\non privacy, it already can help to set the limits,\nhow do we proceed with this?",
    "start": "3415850",
    "end": "3425780"
  },
  {
    "text": "So yes, I think\nit's all for now. So how do we approach it? Do we need actually to\nwait something to happen?",
    "start": "3425780",
    "end": "3433280"
  },
  {
    "text": "For example, like\nwe discussed, there have been security and\nother type of regulations",
    "start": "3433280",
    "end": "3442100"
  },
  {
    "text": "or just system rethought\nafter 9/11, right? So the cockpit door\nwas strengthened,",
    "start": "3442100",
    "end": "3448730"
  },
  {
    "text": "how security have-- do we need something like this\nto happen in technological world to actually start\nrethinking the system?",
    "start": "3448730",
    "end": "3454700"
  },
  {
    "text": "Because it was a\nterrible situation. It was a terrible thing. And do we need things like that?",
    "start": "3454700",
    "end": "3462820"
  },
  {
    "text": "Of course, we can think\nas a philosophy of life, we need to have certain\ngrotesque things happening",
    "start": "3462820",
    "end": "3469180"
  },
  {
    "text": "to this experience of life. But certain things, do we\nreally need to wait for them?",
    "start": "3469180",
    "end": "3477350"
  },
  {
    "text": "Because there are ways\nto still approach this. We can do this.",
    "start": "3477350",
    "end": "3482530"
  },
  {
    "text": "Well, we waited\nwith social media. And we found out it had\nterrible effects that now we're having a terrible time undoing.",
    "start": "3482530",
    "end": "3489580"
  },
  {
    "text": "So-- Definitely. --I don't know if that holds. Yes, of course. So attention span in kids, for\nexample, mainly having dyslexia",
    "start": "3489580",
    "end": "3497440"
  },
  {
    "text": "now because of this, again,\ncompetition for your attention. And now there is different\ntype of competition going",
    "start": "3497440",
    "end": "3503290"
  },
  {
    "text": "on that also influence us. And even, for example,\nsuch thing as Coronavirus. It's not the technology but\nstill the system of health care",
    "start": "3503290",
    "end": "3512550"
  },
  {
    "text": "starts being rethought\ndeeply to its roots after such thing\nhappened as a pandemic.",
    "start": "3512550",
    "end": "3519900"
  },
  {
    "text": "When everybody got locked up at\nhomes for two years, basically when everybody had to\nshift to the digital",
    "start": "3519900",
    "end": "3528120"
  },
  {
    "text": "because there were not enough\nplaces or certain system safety,",
    "start": "3528120",
    "end": "3533580"
  },
  {
    "text": "things, concepts in\nplace that would help, like washing hands\nmore frequently",
    "start": "3533580",
    "end": "3539520"
  },
  {
    "text": "or wearing masks in public. So now we know we\nhave the experience.",
    "start": "3539520",
    "end": "3545040"
  },
  {
    "text": "Of course, it helps. But all of us going\nthrough, many people also died in this process.",
    "start": "3545040",
    "end": "3551760"
  },
  {
    "text": "So this is also something\nwe are looking for. Yeah. To your point on the\nlegal, somebody just",
    "start": "3551760",
    "end": "3558869"
  },
  {
    "text": "published a graphic\nnovel using generative AI to do the graphics.",
    "start": "3558870",
    "end": "3564810"
  },
  {
    "text": "And a judge just ruled\nthat she could copyright the text but not the pictures.",
    "start": "3564810",
    "end": "3571410"
  },
  {
    "text": "Yes, I saw that. I actually think that was a bad\ndecision, and it was a mistake. Because really the question\nis, What's the human content?",
    "start": "3571410",
    "end": "3577928"
  },
  {
    "text": "That's right. Up till now, it's\neither been 100% or 0%. And now we have\nsomething in the middle.",
    "start": "3577928",
    "end": "3583210"
  },
  {
    "text": "And again, it comes down to\ncurating all of those, what-- I have an example about that.",
    "start": "3583210",
    "end": "3589510"
  },
  {
    "text": "Many years ago, I was looking\nthrough a book, Man and Machine. And this was commissioned by\nIBM when people were worried",
    "start": "3589510",
    "end": "3596890"
  },
  {
    "text": "about the electronic brain. And they wanted to humanize it. And they brought in\nStieglitz to go into IBM",
    "start": "3596890",
    "end": "3602860"
  },
  {
    "text": "and photograph the\ncompany's place. And one picture was of my mentor\nwhen I was a postdoc at IBM.",
    "start": "3602860",
    "end": "3611170"
  },
  {
    "text": "And the picture\ncaptured his essence. And I called him right away. And I said, What\nwas that all about?",
    "start": "3611170",
    "end": "3617470"
  },
  {
    "text": "He says, oh, this guy came in. He shot like 1,000 shots, right? And he picked that one.",
    "start": "3617470",
    "end": "3623230"
  },
  {
    "text": "And it's the curation that's\nthe copyrightable aspect, not the drawing itself.",
    "start": "3623230",
    "end": "3629040"
  },
  {
    "text": "It's picking the right one\nthat the generative AI created. I had another\nquestion about the AI.",
    "start": "3629040",
    "end": "3637050"
  },
  {
    "text": "And he said\nsomething interesting because my understanding is that\nthere is no reason for an AI",
    "start": "3637050",
    "end": "3643710"
  },
  {
    "text": "to do anything unless\nsomeone with a motivation",
    "start": "3643710",
    "end": "3648839"
  },
  {
    "text": "asks it to do it. And therefore, when the\nAI does something bad,",
    "start": "3648840",
    "end": "3656619"
  },
  {
    "text": "we have someone to\nhold responsible. And it's not the AI\nthat did the bad thing.",
    "start": "3656620",
    "end": "3662890"
  },
  {
    "text": "It was the person who\nprovided the trigger. Well, I don't think that's true.",
    "start": "3662890",
    "end": "3668980"
  },
  {
    "text": "Well, this is from\na Steven Pinker book",
    "start": "3668980",
    "end": "3675310"
  },
  {
    "text": "from 20 or 30 years ago. But his question was, Why would\na robot choose to do anything?",
    "start": "3675310",
    "end": "3683559"
  },
  {
    "text": "Why do we choose to do things? He believes that we choose to\ndo things because of emotion,",
    "start": "3683560",
    "end": "3689500"
  },
  {
    "text": "was his answer. Generative AI doesn't\nhave emotions. So why would it do\nanything without a prompt?",
    "start": "3689500",
    "end": "3697930"
  },
  {
    "text": "No, I don't believe that you\ncan state that a generative AI doesn't have emotions.",
    "start": "3697930",
    "end": "3704890"
  },
  {
    "text": "It may take some new organs\ninside of the AI unit",
    "start": "3704890",
    "end": "3711680"
  },
  {
    "text": "to deal with the\nemotions, but then there are lots of things that\nrequire augmentation to be",
    "start": "3711680",
    "end": "3718040"
  },
  {
    "text": "able to handle\nsignals that are not present in the\nsequentiality of symbols.",
    "start": "3718040",
    "end": "3726680"
  },
  {
    "text": "Yeah. I'm sitting here looking\nat a ChatGPT screen. And it answered\nmy last question,",
    "start": "3726680",
    "end": "3733550"
  },
  {
    "text": "but it hasn't followed\nup in any way on its own. Is that just part of the UI,\nor is that an inherent nature",
    "start": "3733550",
    "end": "3742520"
  },
  {
    "text": "of the system? Good question. It's a research paper\nthat you should write.",
    "start": "3742520",
    "end": "3747680"
  },
  {
    "text": "[LAUGHING] I don't know if\nI'm competent to answer it. Or you can see Disney's\nThe Sorcerer's Apprentice",
    "start": "3747680",
    "end": "3754360"
  },
  {
    "text": "to see what can happen. Yeah. [LAUGHTER] But my point was that if\nthe AI is acting in response",
    "start": "3754360",
    "end": "3764260"
  },
  {
    "text": "to a human input, then\nin a sense that human is responsible for the\noutput, and the AI is not.",
    "start": "3764260",
    "end": "3773877"
  },
  {
    "text": "Well, that's-- I think-- Courts have been saying that. And the question is, Is it\na reasonable expectation",
    "start": "3773877",
    "end": "3781330"
  },
  {
    "text": "that you could have\npredicted that outcome? I think that comes back to this\nquestion of legal liability.",
    "start": "3781330",
    "end": "3786578"
  },
  {
    "text": "That's right. Yes. So it's going to be a gray area. And we're going to have\nan awful lot of lawyers that are going to\nbe employed figuring",
    "start": "3786578",
    "end": "3793420"
  },
  {
    "text": "all of that kind of stuff out. But back on, I think, on\nthe issue that you made,",
    "start": "3793420",
    "end": "3798580"
  },
  {
    "text": "music when it was\nfirst recorded, the Supreme Court decided that\nit could not be copyrighted.",
    "start": "3798580",
    "end": "3805000"
  },
  {
    "text": "And a big uproar happened,\nand then that changed. I believe the same thing\nhappened with photographs.",
    "start": "3805000",
    "end": "3811750"
  },
  {
    "text": "That you couldn't\ncopyright a photograph. But then I think\nthe example you gave",
    "start": "3811750",
    "end": "3818079"
  },
  {
    "text": "of the curation of the\nphotographs changed the view that photography-- and\nthen photography, of course, became an important art\nform, not just simply",
    "start": "3818080",
    "end": "3825460"
  },
  {
    "text": "something you press a\nbutton and record something. So we're going to go\nthrough the same process, I think, over the next couple\nof decades as this works out.",
    "start": "3825460",
    "end": "3834790"
  },
  {
    "text": "Well, I think that what\ncopyright protects against",
    "start": "3834790",
    "end": "3840350"
  },
  {
    "text": "does not include ideas, methods,\net cetera, et cetera, et cetera. That's a patent, and it\nhas a whole different set",
    "start": "3840350",
    "end": "3847820"
  },
  {
    "text": "of standards and rules. It protects against somebody\nmaking a photocopy that",
    "start": "3847820",
    "end": "3853910"
  },
  {
    "text": "is an identical copy or\nnearly identical copy that looks like\nthe original copy",
    "start": "3853910",
    "end": "3860240"
  },
  {
    "text": "and then having a stack of\nthose books in their booksellers stand across the\nstreet from the one",
    "start": "3860240",
    "end": "3866480"
  },
  {
    "text": "that the publishers of the\nactual first copies were. And that's a 15th century\npublishing mechanism.",
    "start": "3866480",
    "end": "3876530"
  },
  {
    "text": "It basically says that\ncopyright protects",
    "start": "3876530",
    "end": "3881720"
  },
  {
    "text": "the sensibility of your-- The expression.",
    "start": "3881720",
    "end": "3887130"
  },
  {
    "text": "Expression. Expression, yeah. The actual expression. But Dennis, there\nare limitations to that, that have\nbeen nuances have",
    "start": "3887130",
    "end": "3893000"
  },
  {
    "text": "been worked out over the years. You've got fair use. I can go ahead and quote\nyou up to a certain point.",
    "start": "3893000",
    "end": "3899720"
  },
  {
    "text": "And I'm not sure what the\nrules exactly are on that. There is no rule. It's what's ever\ndecided in court.",
    "start": "3899720",
    "end": "3905359"
  },
  {
    "text": "That one, I know about. OK. So there's this fair use. There's also something\nelse on that.",
    "start": "3905360",
    "end": "3912220"
  },
  {
    "text": "[INAUDIBLE] Oh, parody. Parody. You can do parody. That's not considered copying.",
    "start": "3912220",
    "end": "3919100"
  },
  {
    "text": "So again, it's a judgment\nthat has to be made, but these are considered at\nleast conceptually exceptions",
    "start": "3919100",
    "end": "3925400"
  },
  {
    "text": "to those rules. Yeah.  OK. I think to the point that I\nwas holding the hand, right?",
    "start": "3925400",
    "end": "3932960"
  },
  {
    "text": "So there was a question\nabout human responsibility. So of course, this is a separate\nquestion in this partially.",
    "start": "3932960",
    "end": "3942260"
  },
  {
    "text": "Because, again, AI\nsystem is so complicated. It consists of so many elements. So there is creation.",
    "start": "3942260",
    "end": "3948950"
  },
  {
    "text": "There is training. There is data. There is distribution,\nand et cetera. And it's only just\na few that involves",
    "start": "3948950",
    "end": "3956270"
  },
  {
    "text": "different teams of people. So different responsibilities,\ndifferent actors.",
    "start": "3956270",
    "end": "3962250"
  },
  {
    "text": "And it all implies\nthat some make inputs. So there is already an\nissue of responsibility. And when it comes into\nthe hands of someone who",
    "start": "3962250",
    "end": "3969780"
  },
  {
    "text": "also do some certain\nmisconduct, there is another question like how\nthis person is responsible",
    "start": "3969780",
    "end": "3976080"
  },
  {
    "text": "versus technology. So of course,\ncurrently, the human is responsible because\nwe have moral agency.",
    "start": "3976080",
    "end": "3982410"
  },
  {
    "text": "Machine does not\nhave moral agency. So we should be carrying\nthe responsibility. So we are-- we just do.",
    "start": "3982410",
    "end": "3989390"
  },
  {
    "text": "So it is the way it is. But another thing when we have\nquestions about weaponization",
    "start": "3989390",
    "end": "3996829"
  },
  {
    "text": "of artificial intelligence, it's\nabout you give certain weapon, like a gun, to the person\nwho don't know how to use it",
    "start": "3996830",
    "end": "4004750"
  },
  {
    "text": "or kind of imply misconduct. So then it will be probably\na question of distribution--",
    "start": "4004750",
    "end": "4011770"
  },
  {
    "text": "who gave this person\nthis technology? Because the conduct was to have\nnegative consequences, right?",
    "start": "4011770",
    "end": "4023350"
  },
  {
    "text": "So then this allocation\nof responsibility in general, thinking, How\ndo we approach in this case?",
    "start": "4023350",
    "end": "4032620"
  },
  {
    "text": "So I think when it comes\njust user versus technology-- so misconduct of a user--",
    "start": "4032620",
    "end": "4038770"
  },
  {
    "text": "then it comes to the\ncase what happened. Because there is no universal\nmodel how to judge people.",
    "start": "4038770",
    "end": "4047530"
  },
  {
    "text": "If there would be,\nthere would be no court. There would be no judges or\nany legal system in place.",
    "start": "4047530",
    "end": "4052970"
  },
  {
    "text": "So we have to look\nwhat happened. Same with a car crash. When car crashes and there is\na driver, who is responsible?",
    "start": "4052970",
    "end": "4062580"
  },
  {
    "text": "Again, we have to look. Is it car malfunction? Is it driver wasn't aware?",
    "start": "4062580",
    "end": "4068069"
  },
  {
    "text": "Maybe the driver was\nsick, something happened? Like, I don't know, some kind\nof fainted during the driving,",
    "start": "4068070",
    "end": "4074410"
  },
  {
    "text": "so health issues or maybe drunk. Or maybe just the situation\non the road was complicated,",
    "start": "4074410",
    "end": "4079650"
  },
  {
    "text": "I don't know, tornado or some\nnatural issues disasters or-- OK, tornado maybe too much.",
    "start": "4079650",
    "end": "4085109"
  },
  {
    "text": "But it was maybe\nheavy rain, which also affects the interaction\nwith the road, the friction.",
    "start": "4085110",
    "end": "4091700"
  },
  {
    "text": "So we have to look\nwhat's happening. There is no like,\nWho is responsible? Like, one answer for all.",
    "start": "4091700",
    "end": "4098210"
  },
  {
    "text": "So definitely, the\npersonalized cases. So maybe there is special\ncertain jurisdiction will be",
    "start": "4098210",
    "end": "4106278"
  },
  {
    "text": "or group of persons\nwho analyze this if we talk about legal system,\nso rights or law on AI.",
    "start": "4106279",
    "end": "4116100"
  },
  {
    "text": "So certain part of it. Or generally, maybe some\nwide-accepted rules.",
    "start": "4116100",
    "end": "4121759"
  },
  {
    "text": "Because even in\n[INAUDIBLE] system, there are certain\ngradings, what you can get for certain misconduct.",
    "start": "4121760",
    "end": "4128089"
  },
  {
    "text": "And generally, since\nit is a technology, I think it will be\ngoing to ICT section. So if you misuse social media\nor also certain malicious ends,",
    "start": "4128090",
    "end": "4140330"
  },
  {
    "text": "it will be in that\ndirection, I guess. You think that's really\npractical, though?",
    "start": "4140330",
    "end": "4147140"
  },
  {
    "text": "Most of these\nregulations for behavior,",
    "start": "4147140",
    "end": "4155220"
  },
  {
    "text": "you say don't use naughty\nwords on the internet or even you have to\npunctuate with commas",
    "start": "4155220",
    "end": "4163799"
  },
  {
    "text": "and that sort of thing. The rule, but we\ntend to ignore them.",
    "start": "4163800",
    "end": "4171339"
  },
  {
    "text": "People use inappropriate words\non the internet all the time.",
    "start": "4171340",
    "end": "4176380"
  },
  {
    "text": "They talk about\nthings they shouldn't. We have pictures\nand stories which",
    "start": "4176380",
    "end": "4183729"
  },
  {
    "text": "are not polite, not\nacceptable in mixed company,",
    "start": "4183729",
    "end": "4192359"
  },
  {
    "text": "that sort of thing. And we still muddle along.",
    "start": "4192359",
    "end": "4197760"
  },
  {
    "text": "And there can be the\nargument that if you don't have these bad things\nin the space of possibility,",
    "start": "4197760",
    "end": "4205290"
  },
  {
    "text": "then the good things are not\nreally identifiable either. Everything is always good,\nit's not very interesting.",
    "start": "4205290",
    "end": "4212310"
  },
  {
    "text": "I agree with this position. If you don't know the\ngood, you can't know the bad, and the other way. But here, it's more\nabout consequence.",
    "start": "4212310",
    "end": "4220080"
  },
  {
    "text": "So how the severe consequences. So if somebody says a couple\nbad words on the internet",
    "start": "4220080",
    "end": "4225929"
  },
  {
    "text": "or shares unpleasant\nstory, I think it won't go quite a long way.",
    "start": "4225930",
    "end": "4232530"
  },
  {
    "text": "But when we talk about\nserious, like terrorism, right? So when weaponization of AI,\nwhen we talk about many people",
    "start": "4232530",
    "end": "4240450"
  },
  {
    "text": "actually experience\nthe consequences when it influence\npeople like manipulating political campaigns,\nfor example.",
    "start": "4240450",
    "end": "4247080"
  },
  {
    "text": "That's what I'm talking about\nin terms of legal regulation. But this is a daily thing.",
    "start": "4247080",
    "end": "4253360"
  },
  {
    "text": "So somebody can get accused for\nthis offense in the internet,",
    "start": "4253360",
    "end": "4258949"
  },
  {
    "text": "right? So somebody, I don't\nknow, had bad conversation with someone else, and\net cetera, somebody not.",
    "start": "4258950",
    "end": "4266110"
  },
  {
    "text": "It depends the way\nit goes, I think. So if this proceed or not,\nwhat's the consequences in this?",
    "start": "4266110",
    "end": "4273130"
  },
  {
    "text": "Even if you file a\nsuit, it doesn't always mean that you're going to win\nor even it will get reviewed.",
    "start": "4273130",
    "end": "4278620"
  },
  {
    "text": "And you can proceed\nfurther to the court. So-- So do you think we could\ntrain an AI to be moral?",
    "start": "4278620",
    "end": "4286180"
  },
  {
    "text": "Or ethical rather? This is a good question,\nbut it's a little different. It's a little different. It's going further.",
    "start": "4286180",
    "end": "4292870"
  },
  {
    "text": "So we're done closing\nthe chapter on law and going to morality of AI.",
    "start": "4292870",
    "end": "4298840"
  },
  {
    "text": "Because this is a big question\nbecause, first of all, can we actually\nexplain our morality?",
    "start": "4298840",
    "end": "4305860"
  },
  {
    "text": "Can we tell how to be moral? We don't know how-- [INTERPOSING VOICES] Because all--",
    "start": "4305860",
    "end": "4311290"
  },
  {
    "text": "Can you? Huh? Can you? I can try, but I'm\nnot sure I will",
    "start": "4311290",
    "end": "4316750"
  },
  {
    "text": "succeed because the point\nis that we act in life.",
    "start": "4316750",
    "end": "4322540"
  },
  {
    "text": "We don't think, OK, I'm going\nto do this because there is this scripture on morality.",
    "start": "4322540",
    "end": "4328420"
  },
  {
    "text": "I'm acting like I\nsee grandmother, I want to help her\nwith products carrying, for example, to the\nfourth floor, if we're",
    "start": "4328420",
    "end": "4335290"
  },
  {
    "text": "talking about apartment. And then like I have to do this\nbecause Aristotle said it's good",
    "start": "4335290",
    "end": "4340600"
  },
  {
    "text": "because there is other\nancient Greeks said it's good, and my mother said it's good. We just act out.",
    "start": "4340600",
    "end": "4346239"
  },
  {
    "text": "Not always think,\nthis is the problem with computational ethics\nor morality as well.",
    "start": "4346240",
    "end": "4353750"
  },
  {
    "text": "So that you cannot really always\nexplain what you're doing.",
    "start": "4353750",
    "end": "4360690"
  },
  {
    "text": "Of course, it's important. It's very important when it\ncomes to structural decisions,",
    "start": "4360690",
    "end": "4365830"
  },
  {
    "text": "like application\nto the job, right? So employment, banking. You have to explain.",
    "start": "4365830",
    "end": "4371180"
  },
  {
    "text": "But in daily life, we just act. So it's not-- yes, there\nis some thought maybe.",
    "start": "4371180",
    "end": "4377180"
  },
  {
    "text": "Like, my mother would think\nit's good to help grandmother. So I'm going to do this. But generally, it\ndoesn't have this kind",
    "start": "4377180",
    "end": "4386750"
  },
  {
    "text": "of strict sense written. So if we compute, it still\nwill not act like us.",
    "start": "4386750",
    "end": "4392480"
  },
  {
    "text": "I mean, it cannot act like\nus, but it will not still get closer. Yet it doesn't mean\nwe should give up.",
    "start": "4392480",
    "end": "4400250"
  },
  {
    "text": "There are approaches,\nhow to do this. So legal boundaries because\ncertain legal concepts,",
    "start": "4400250",
    "end": "4409130"
  },
  {
    "text": "they are also grounded in\nethics and morality, right? And they are restated.",
    "start": "4409130",
    "end": "4414469"
  },
  {
    "text": "It may be clear like,\ndon't kill, right? We will know this. It's bad, taking human's life.",
    "start": "4414470",
    "end": "4421280"
  },
  {
    "text": "But it's still in the\nlaw because it happens. So such things stay\nrestated, even though it's",
    "start": "4421280",
    "end": "4428630"
  },
  {
    "text": "kind of common sense. And we can teach through law\nbecause law is more defined.",
    "start": "4428630",
    "end": "4433640"
  },
  {
    "text": "It's also easier to explain\nbecause it's in a sense more logical form.",
    "start": "4433640",
    "end": "4438710"
  },
  {
    "text": "And there can be\nmoral preferences. For example, there was an\nidea for self-driving cars",
    "start": "4438710",
    "end": "4445760"
  },
  {
    "text": "to encode a certain sense\nof morality of their driver.",
    "start": "4445760",
    "end": "4451389"
  },
  {
    "text": "So what the distance\nthey want to stand-- so of course, in\nlegal boundaries,",
    "start": "4451390",
    "end": "4457690"
  },
  {
    "text": "but you can choose a little\nfurther or a little less. So some people\nare going to stand very close to your back\nand some kind of further.",
    "start": "4457690",
    "end": "4466690"
  },
  {
    "text": "So what type of person\nare you in that sense? And these kind of subtle things\ncould also give the character",
    "start": "4466690",
    "end": "4475540"
  },
  {
    "text": "to these machines. So like, self-driving\ncars, it still",
    "start": "4475540",
    "end": "4480580"
  },
  {
    "text": "have human oversight,\nat least it should. And yes.",
    "start": "4480580",
    "end": "4486280"
  },
  {
    "text": "So you want-- [INTERPOSING VOICES] --an AI which has a conscience? A little-- This is different question.",
    "start": "4486280",
    "end": "4491975"
  },
  {
    "text": "[INAUDIBLE] older and says-- whispers in your ear,\noh, don't do that. That's not a good idea.",
    "start": "4491975",
    "end": "4498910"
  },
  {
    "text": "Here, we're talking\nabout negative ethics and positive ethics.",
    "start": "4498910",
    "end": "4505330"
  },
  {
    "text": "Or just negative ethics for now. So negative ethics is\nlike, don't do this.",
    "start": "4505330",
    "end": "4510340"
  },
  {
    "text": "This is prohibited because\nthis is bad based on your list. But well, I started\ntalking about positive",
    "start": "4510340",
    "end": "4517480"
  },
  {
    "text": "because it's a vision\nof how we want to live, how you want to be. So vision of life.",
    "start": "4517480",
    "end": "4523840"
  },
  {
    "text": "So it was also in\nthat video that we should think more\nabout the type of life",
    "start": "4523840",
    "end": "4529840"
  },
  {
    "text": "we want to reach with this\ntechnology or in general. This is positive ethics. So how this technology\naligns with the vision",
    "start": "4529840",
    "end": "4537639"
  },
  {
    "text": "of our future society,\nand what good does it do? OK, on morality.",
    "start": "4537640",
    "end": "4543023"
  },
  {
    "text": "Then on consciousness. [LAUGHS] Because it's\na different thing, so it's still considered to be\nfar because to cause a mind,",
    "start": "4543023",
    "end": "4551809"
  },
  {
    "text": "you need the power equal or\neven higher to the brain.",
    "start": "4551810",
    "end": "4556880"
  },
  {
    "text": "Because again, we're\nnot just pure syntax. So if it would be syntax, then\ncomputer is about the same.",
    "start": "4556880",
    "end": "4565770"
  },
  {
    "text": "So just running a program is\nnot enough to create a mind. You can have an imitation or on\nthis-- yeah, imitation of mind.",
    "start": "4565770",
    "end": "4575340"
  },
  {
    "text": "So like we have this ChatGPT,\nit behaves human-like. Some may even fall\nin love with them",
    "start": "4575340",
    "end": "4581670"
  },
  {
    "text": "maybe because they\npresent this feature. So it's control for\nmorphism, I think.",
    "start": "4581670",
    "end": "4587070"
  },
  {
    "text": "So it presents these features,\nand we perceive it as human. So this Turing test idea\nis not really working.",
    "start": "4587070",
    "end": "4595660"
  },
  {
    "text": "Because imitation of\nconsciousness doesn't mean there is consciousness. Yeah, that's true.",
    "start": "4595660",
    "end": "4601720"
  },
  {
    "text": "It should be clear for\neveryone because some people think that it does have\nconsciousness or emotions.",
    "start": "4601720",
    "end": "4608680"
  },
  {
    "text": "It is just a program running. So I don't know\nwhat it would take because it's something\nthat's been started already",
    "start": "4608680",
    "end": "4618430"
  },
  {
    "text": "for many years. And it's generally a\nmystery of humankind.",
    "start": "4618430",
    "end": "4623500"
  },
  {
    "text": "So there have been this-- again, from ancient times, there\nhave been this sculptures coming",
    "start": "4623500",
    "end": "4629139"
  },
  {
    "text": "alive, I mean in\nthe [INAUDIBLE],, then Golems, then Frankenstein. So recreation of life, what\nit takes to recreate the life.",
    "start": "4629140",
    "end": "4637929"
  },
  {
    "text": "Of course, there is a point of\ntechnology like in Frankenstein. So electricity got invented.",
    "start": "4637930",
    "end": "4643659"
  },
  {
    "text": "So maybe electricity\ncan give a life. No, it didn't.",
    "start": "4643660",
    "end": "4648740"
  },
  {
    "text": "OK, now we have\nartificial intelligence. Maybe this can give a life. Maybe it's not.",
    "start": "4648740",
    "end": "4654300"
  },
  {
    "text": "So because generally, the\nname artificial intelligence, it can be a little tricky.",
    "start": "4654300",
    "end": "4660809"
  },
  {
    "text": "So it was meant as\na study of her mind",
    "start": "4660810",
    "end": "4665840"
  },
  {
    "text": "through the practical\nimplementation of technology. So you try to build a\nmind for some structures.",
    "start": "4665840",
    "end": "4671960"
  },
  {
    "text": "And you learn more. So there are two directions. And we went more\nin the direction of making useful\nsmart technologies.",
    "start": "4671960",
    "end": "4678980"
  },
  {
    "text": "But there is another one,\nstudy of consciousness. So that's on this.",
    "start": "4678980",
    "end": "4687080"
  },
  {
    "text": "I see [INAUDIBLE] or something. I have a colleague-- I have a colleague who's talked\nabout this for many, many times.",
    "start": "4687080",
    "end": "4695060"
  },
  {
    "text": "And he is of the\nopinion that what we need today to\nmake this work is",
    "start": "4695060",
    "end": "4700520"
  },
  {
    "text": "a new religion and\na set of ethics",
    "start": "4700520",
    "end": "4705530"
  },
  {
    "text": "to fit that religion,\nsomething like Catholicism at the point where the\nchurch is split and moved",
    "start": "4705530",
    "end": "4715310"
  },
  {
    "text": "to Constantinople, where there\nis then a strict code of conduct and appropriate-- well, there's\nsome interesting theories",
    "start": "4715310",
    "end": "4724099"
  },
  {
    "text": "about how strict\n\"strict\" should be. ",
    "start": "4724100",
    "end": "4729680"
  },
  {
    "text": "There's an interesting paper on\nartificial intelligence and game",
    "start": "4729680",
    "end": "4736280"
  },
  {
    "text": "theory which indicates\nthat you probably want a very strictly\nenforced set of rules which",
    "start": "4736280",
    "end": "4742790"
  },
  {
    "text": "has leaks in it\nthat you can adjust from time to time to\nhandle the cases that",
    "start": "4742790",
    "end": "4748910"
  },
  {
    "text": "don't get handled well. But it's an interesting\nthought that what we need",
    "start": "4748910",
    "end": "4754580"
  },
  {
    "text": "is a new moral structure. And that moral structure\nshould be parallel to",
    "start": "4754580",
    "end": "4760850"
  },
  {
    "text": "and tied to how the AIs work. And that the AI's model\nshould be quite good.",
    "start": "4760850",
    "end": "4769679"
  },
  {
    "text": "Now there are people\nwho say that that's the prescription for disaster.",
    "start": "4769680",
    "end": "4776670"
  },
  {
    "text": "That was how the folks who\nwanted to improve efficiency",
    "start": "4776670",
    "end": "4785900"
  },
  {
    "text": "by eliminating humans and have\nthe AIs do all of everything",
    "start": "4785900",
    "end": "4792590"
  },
  {
    "text": "was probably constructed. I don't think that's\nlikely to happen,",
    "start": "4792590",
    "end": "4799400"
  },
  {
    "text": "but I suppose that we\nshould worry about it. ",
    "start": "4799400",
    "end": "4806830"
  },
  {
    "text": "Yeah, that's a good point. I will maybe start with\nthis enforced morality. Also not all people are moral,\nor at least in our ideas,",
    "start": "4806830",
    "end": "4814719"
  },
  {
    "text": "also morality can differ because\nmorality is-- pointed part of it that it's a little personal.",
    "start": "4814720",
    "end": "4820239"
  },
  {
    "text": "It can be cultural, but there\nare still wide accepted things.",
    "start": "4820240",
    "end": "4825280"
  },
  {
    "text": "Same can be this AI,\nand we're coming back to the point of certification. There are widely\naccepted certificates,",
    "start": "4825280",
    "end": "4832030"
  },
  {
    "text": "but of course, people\nact without them. People buy guns without license. People make DNA sequencing\nin their own labs",
    "start": "4832030",
    "end": "4840220"
  },
  {
    "text": "or even before\ndiscussed the CRISPR. Some do things on their own. They don't need license.",
    "start": "4840220",
    "end": "4845500"
  },
  {
    "text": "They don't need anything. They just need the thing to do. So the materials, the\ntechnology, and that's it.",
    "start": "4845500",
    "end": "4851890"
  },
  {
    "text": "So there is always\nwill be some outliers. And there is nothing really you\ncan do about this because you",
    "start": "4851890",
    "end": "4858280"
  },
  {
    "text": "can't surveil, or you shouldn't\neven surveil everyone. Just make sure that there\nis a certain standard.",
    "start": "4858280",
    "end": "4865210"
  },
  {
    "text": "Something is not accepted,\nso the whole public doesn't do this. So people are aware\nof the consequences.",
    "start": "4865210",
    "end": "4873140"
  },
  {
    "text": "It was explained to them, and\nthey understand or at least try to or at least get some\nidea because it depends",
    "start": "4873140",
    "end": "4881090"
  },
  {
    "text": "on how deep the technology is. And then for AI for efficiency,\nlike replacing humans",
    "start": "4881090",
    "end": "4889370"
  },
  {
    "text": "with the AI, I also saw\nsomething like that. And actually, AI can be-- or\ngenerally, algorithmic systems",
    "start": "4889370",
    "end": "4898130"
  },
  {
    "text": "can be useful to improve\nefficiency and reduce bias,",
    "start": "4898130",
    "end": "4903860"
  },
  {
    "text": "also human bias. Because, yes, they use more\nlogical data in some sense,",
    "start": "4903860",
    "end": "4909620"
  },
  {
    "text": "like, there is a\nchain, especially when we talk about something\nlike decision trees.",
    "start": "4909620",
    "end": "4916220"
  },
  {
    "text": "It still requires\nhuman oversight because it's not always correct. And I think this is\npart of the certificate",
    "start": "4916220",
    "end": "4923210"
  },
  {
    "text": "that I talk about is that\nto actually teach people how to make decisions\nwith these tools,",
    "start": "4923210",
    "end": "4929780"
  },
  {
    "text": "make a training that it's\nnot smarter than you. Like, you need to\nstill look into this,",
    "start": "4929780",
    "end": "4936380"
  },
  {
    "text": "like what is going on. You can't just agree\nwith everything it does. So it would be\ncertificate that states",
    "start": "4936380",
    "end": "4943099"
  },
  {
    "text": "like, I know how to make\ndecisions with AI tools. I don't trust it 100%.",
    "start": "4943100",
    "end": "4948949"
  },
  {
    "text": "I'm not allocating\nresponsibility on it just for the sake. So nobody have questions to\nme because tool decided that.",
    "start": "4948950",
    "end": "4956030"
  },
  {
    "text": "So because this is a problem\nthat people just think that, oh, it's making decision.",
    "start": "4956030",
    "end": "4962000"
  },
  {
    "text": "I'm just here accepting them. Like, I've already lost my job.",
    "start": "4962000",
    "end": "4967880"
  },
  {
    "text": "I've already given up. I'm just clicking Yes,\nbecause it's easier. We're wired for\nmaking life easier.",
    "start": "4967880",
    "end": "4973730"
  },
  {
    "text": "Our body is wired for making\nlife easier, and minds. We don't want to do complicated\njob if there is an easier way.",
    "start": "4973730",
    "end": "4980360"
  },
  {
    "text": "But this is why it's important\nto actually understand it's not as easy job. You're not there to click\nYes to the algorithm.",
    "start": "4980360",
    "end": "4989000"
  },
  {
    "text": "Still oversight is required. Well, the other thing\nis if you click Yes",
    "start": "4989000",
    "end": "4996260"
  },
  {
    "text": "as a regular feature,\nthe algorithm, the AI will observe the\nfact that's what you do",
    "start": "4996260",
    "end": "5002110"
  },
  {
    "text": "and eliminate that\nfrom the tasks that you have to do because\nyou always click Yes. Well, just your boss will\neliminate, for example.",
    "start": "5002110",
    "end": "5008739"
  },
  {
    "text": "Because like, What\nyou're doing there? You're just clicking Yes. But it loses this idea because\nit gets lost in the process.",
    "start": "5008740",
    "end": "5018010"
  },
  {
    "text": "In the process of\nclicking Yes, they're forgetting like, Wait, why did\nwe do it in the first place?",
    "start": "5018010",
    "end": "5024490"
  },
  {
    "text": "Why this person was there? Why it was asking us on\nwhether we agree or not?",
    "start": "5024490",
    "end": "5029530"
  },
  {
    "text": "So this part of the\ncertification and training that would help. Because these systems are\nnot just developed and kept.",
    "start": "5029530",
    "end": "5036910"
  },
  {
    "text": "They are given to public. They are given to services. There are many AI\npowered services.",
    "start": "5036910",
    "end": "5042040"
  },
  {
    "text": "And those people, they\nare not developers, or they're not in a company. That company may have\nsome ethical guidelines.",
    "start": "5042040",
    "end": "5048219"
  },
  {
    "text": "Like Microsoft,\nGoogle, they have some. But when it shared to third\nparties, they're not really.",
    "start": "5048220",
    "end": "5055210"
  },
  {
    "text": "So it should come with\na certain training also if you want to use it. At least I'm very\nconvinced it should.",
    "start": "5055210",
    "end": "5063670"
  },
  {
    "text": "It's like given a car. You can buy a car, but\nyou can't drive it. You have to have a\nlicense to do that.",
    "start": "5063670",
    "end": "5070360"
  },
  {
    "text": "You need to know how to behave\non the road with other drivers,",
    "start": "5070360",
    "end": "5075400"
  },
  {
    "text": "how to keep yourself\npositioned, what to do in certain situations.",
    "start": "5075400",
    "end": "5080829"
  },
  {
    "text": "Different things happen. That's what comes with a\nlicense and car or motorcycle",
    "start": "5080830",
    "end": "5086739"
  },
  {
    "text": "or any kind of driving\ntransportation, airplane. Airplane is much stricter.",
    "start": "5086740",
    "end": "5092239"
  },
  {
    "text": "So I think in that sense,\nit's a little closer to AI because it's more\npowerful than car.",
    "start": "5092240",
    "end": "5097310"
  },
  {
    "text": "Car is more like everyday. So there can be AI airplanes,\nAI cars in the sense",
    "start": "5097310",
    "end": "5103040"
  },
  {
    "text": "that this leveling,\nhow profound, how dangerous the technology.",
    "start": "5103040",
    "end": "5108380"
  },
  {
    "text": "Not everyone can\ndrive an airplane or fly an airplane in the\nsense of controlling it,",
    "start": "5108380",
    "end": "5114440"
  },
  {
    "text": "which requires a whole\nschool going through. ",
    "start": "5114440",
    "end": "5119989"
  },
  {
    "text": "Because you give\nthis technology, so teach how to use it. I think that's the\nbasics that should be.",
    "start": "5119990",
    "end": "5127190"
  },
  {
    "text": "And I don't really see it\ncoming here, unfortunately.",
    "start": "5127190",
    "end": "5132590"
  },
  {
    "text": "You don't see you\ndon't see that there's any alternative to doing\nsomething like that",
    "start": "5132590",
    "end": "5137900"
  },
  {
    "text": "and utilizing the technology? Because if we choose\nnot to have regulations,",
    "start": "5137900",
    "end": "5145602"
  },
  {
    "text": "what's going to happen? ",
    "start": "5145602",
    "end": "5151360"
  },
  {
    "text": "It's very hard to know. I think regulations is one of\nthe ways-- it's already coming.",
    "start": "5151360",
    "end": "5157190"
  },
  {
    "text": "So it's already good\nbecause there are some developments in that area.",
    "start": "5157190",
    "end": "5162320"
  },
  {
    "text": "So this is definitely a\nbenefit because we already",
    "start": "5162320",
    "end": "5169969"
  },
  {
    "text": "learned that free market\ndoesn't work so well. You can't say,\nplease don't do this.",
    "start": "5169970",
    "end": "5175010"
  },
  {
    "text": "They're like, OK, we won't. So this is the issue that\nwe're having right now.",
    "start": "5175010",
    "end": "5180370"
  },
  {
    "text": "Like, please don't make\nthis very dangerous. Please don't surveil us. Don't take our data.",
    "start": "5180370",
    "end": "5186050"
  },
  {
    "text": "We feel very bad. It's very dangerous to look-- no response.",
    "start": "5186050",
    "end": "5191530"
  },
  {
    "text": "Continue, because competition\ngains and et cetera. So one way to actually intervene\nis because government has power.",
    "start": "5191530",
    "end": "5200350"
  },
  {
    "text": "This just need to help. So claims from the\nfield academics,",
    "start": "5200350",
    "end": "5205570"
  },
  {
    "text": "we should all come together. Users also express\ntheir concerns, what they are afraid of and\nhave this conversation,",
    "start": "5205570",
    "end": "5213160"
  },
  {
    "text": "interdisciplinary\nconversation that actually will help to\nunderstand all sides and make the type of\nregulation not just",
    "start": "5213160",
    "end": "5220270"
  },
  {
    "text": "a prohibited this\nand then people from the technological\nsector, they don't know what\nto do because they",
    "start": "5220270",
    "end": "5226690"
  },
  {
    "text": "have no idea how practical\nis this, how to implement it? So this is why\ncollaboration is important.",
    "start": "5226690",
    "end": "5232270"
  },
  {
    "text": "It's not like government\ndo their thing. It's-- You don't probably get\nall of the US newspapers",
    "start": "5232270",
    "end": "5240460"
  },
  {
    "text": "and read them like we do here. But the number of people who\nhave decided how AIs work",
    "start": "5240460",
    "end": "5249760"
  },
  {
    "text": "and how they're going to impact\nthings is really quite large.",
    "start": "5249760",
    "end": "5255489"
  },
  {
    "text": "Virtually, every commentator\nhas written a column or two about it. And it's quite\ninteresting what they",
    "start": "5255490",
    "end": "5262480"
  },
  {
    "text": "believe AI can do and will do. It's both much more constrained\nthan it is in reality, and also",
    "start": "5262480",
    "end": "5274510"
  },
  {
    "text": "much broader. They work out their\nfantasies in terms",
    "start": "5274510",
    "end": "5281530"
  },
  {
    "text": "of talking about what\nthe AIs can and can't do. Whereas what we have to\ndo is as technologists",
    "start": "5281530",
    "end": "5289750"
  },
  {
    "text": "is choose the right thing\nto do and to present",
    "start": "5289750",
    "end": "5296140"
  },
  {
    "text": "that in a way that's ethical\nand moral in some fashion without enforcing it.",
    "start": "5296140",
    "end": "5302110"
  },
  {
    "text": " It's an interesting\nand sort of awesome",
    "start": "5302110",
    "end": "5307920"
  },
  {
    "text": "task, which probably\nthe only way",
    "start": "5307920",
    "end": "5315449"
  },
  {
    "text": "to do it is to convince the AI\nsystems that they should help.",
    "start": "5315450",
    "end": "5321810"
  },
  {
    "text": "Yeah. In the long run. You can try. Yeah. I'm pretty sure--",
    "start": "5321810",
    "end": "5326849"
  },
  {
    "text": "The other thing\nthat's interesting is that there's all this\nconcern about the AI",
    "start": "5326850",
    "end": "5337190"
  },
  {
    "text": "being a gatherer of\ninformation, building",
    "start": "5337190",
    "end": "5343130"
  },
  {
    "text": "a collection of all the world's\ninformation in some fashion.",
    "start": "5343130",
    "end": "5350840"
  },
  {
    "text": "And at least, as I\nunderstand the process,",
    "start": "5350840",
    "end": "5355889"
  },
  {
    "text": "that doesn't seem to\nbe what they're doing. What the AI information\ngathering thing is,",
    "start": "5355890",
    "end": "5363840"
  },
  {
    "text": "the training, is to try to\ndetermine the symbols that exist in the language of\nthe system being observed",
    "start": "5363840",
    "end": "5373510"
  },
  {
    "text": "and their relative frequencies\nand their transition probabilities.",
    "start": "5373510",
    "end": "5379480"
  },
  {
    "text": "And the knowledge itself\nis pretty much tossed away. ",
    "start": "5379480",
    "end": "5386719"
  },
  {
    "text": "And it's very it's\nvery interesting how simplistic the\nunderlying ideas really are.",
    "start": "5386720",
    "end": "5395179"
  },
  {
    "text": "Yeah. It's true. So this is the general equation\nwith algorithms and models",
    "start": "5395180",
    "end": "5401000"
  },
  {
    "text": "because models are just\nsimplification of life. It does not represent life. And some people believe in\nAI that it's actually like--",
    "start": "5401000",
    "end": "5410150"
  },
  {
    "text": "I don't know-- that it will-- this AGI concept, so\nstrong intelligence,",
    "start": "5410150",
    "end": "5416719"
  },
  {
    "text": "artificial intelligence and\ngenerally that this kind of ideas on its--",
    "start": "5416720",
    "end": "5424000"
  },
  {
    "text": "I don't know--\nhuman-like intelligence is that they think human\nintelligence is just a syntax.",
    "start": "5424000",
    "end": "5429250"
  },
  {
    "text": "So it's simplified, but it\ndoesn't take all the complexity. Because another\nthing that exists",
    "start": "5429250",
    "end": "5436770"
  },
  {
    "text": "in not even academia but\nthat the simplest answer is like the most correct.",
    "start": "5436770",
    "end": "5442620"
  },
  {
    "text": "So it's the right one, but-- Yeah, Occam's razor. Huh? It's called Occam's razor.",
    "start": "5442620",
    "end": "5448829"
  },
  {
    "text": "Yeah, I just forgot\nhow it's called. So is it really so?",
    "start": "5448830",
    "end": "5454760"
  },
  {
    "text": "Mm-hmm. I don't know. I doubt it, to be honest because\nI don't think the simplest",
    "start": "5454760",
    "end": "5460810"
  },
  {
    "text": "answer is always the best. So simplest answers, they\nmay be more appealing.",
    "start": "5460810",
    "end": "5467410"
  },
  {
    "text": "That's for sure but-- because it's hard to\nget into complexity",
    "start": "5467410",
    "end": "5473050"
  },
  {
    "text": "and wrap your head around it. Depends on different\nissues, not only AI.",
    "start": "5473050",
    "end": "5479110"
  },
  {
    "text": "So indeed so reducing knowledge\nto symbols and language, reducing human consciousness\nand intelligence to syntax,",
    "start": "5479110",
    "end": "5487270"
  },
  {
    "text": "just some program in our\nhead running, I don't know.",
    "start": "5487270",
    "end": "5493150"
  },
  {
    "text": "I think it doesn't take-- this is where the issues\ncome from, generally. So this is the human\nelement in all this",
    "start": "5493150",
    "end": "5500430"
  },
  {
    "text": "that reflected in\ntechnology that we should think as a part of ethics.",
    "start": "5500430",
    "end": "5506310"
  },
  {
    "text": "Well, there are\npeople who've argued that building a generative\nartificial intelligence agent",
    "start": "5506310",
    "end": "5521370"
  },
  {
    "text": "could be done where\nit had emotions and it responded emotionally\nas well as intellectually,",
    "start": "5521370",
    "end": "5529290"
  },
  {
    "text": "or the next symbol could change\nthe mood of the statement, and so that sort of thing.",
    "start": "5529290",
    "end": "5535650"
  },
  {
    "text": "So it increases the\nfan out of options",
    "start": "5535650",
    "end": "5540690"
  },
  {
    "text": "and makes the decision making\nprocess much more difficult, but it also makes\nit much richer.",
    "start": "5540690",
    "end": "5550170"
  },
  {
    "text": "And there's a guy\nat Stanford who's",
    "start": "5550170",
    "end": "5555780"
  },
  {
    "text": "been working on\nthat sort of change.",
    "start": "5555780",
    "end": "5560960"
  },
  {
    "text": "It's a slightly different\napproach than the neural net,",
    "start": "5560960",
    "end": "5566880"
  },
  {
    "text": "but it's sort of a\nhypergeometric net. And it's always appealed to me.",
    "start": "5566880",
    "end": "5575410"
  },
  {
    "text": "And there are people\nwho are working on building hardware for it.",
    "start": "5575410",
    "end": "5581710"
  },
  {
    "text": "And it would be a possibility. And their interest\nhas always been",
    "start": "5581710",
    "end": "5588910"
  },
  {
    "text": "to try to create\nsomething that's obviously conscious in some fashion.",
    "start": "5588910",
    "end": "5595039"
  },
  {
    "text": "And maybe this round of\nartificial intelligence machines",
    "start": "5595040",
    "end": "5602030"
  },
  {
    "text": "are sort of brain\ndead at some level. They're certainly not\nemotionally capable,",
    "start": "5602030",
    "end": "5610880"
  },
  {
    "text": "but they could hint what\nreally could be done elsewhere. And the next round of\nmachines will look much--",
    "start": "5610880",
    "end": "5618200"
  },
  {
    "text": "or models will look much more\ninteresting and complicated. ",
    "start": "5618200",
    "end": "5624370"
  },
  {
    "text": "And maybe that's what\neverybody's worried about. Maybe that's why everybody says,\nwell, no more stuff beyond GPT-4",
    "start": "5624370",
    "end": "5633820"
  },
  {
    "text": "until such time as\nwe understand more. We'll see.",
    "start": "5633820",
    "end": "5639400"
  },
  {
    "text": "I don't know.  Anyhow, I'm going to\nhave to go now myself.",
    "start": "5639400",
    "end": "5646380"
  },
  {
    "text": "So thank you very much. It's always a great pleasure\nto have you talking.",
    "start": "5646380",
    "end": "5652270"
  },
  {
    "text": "Thank you. And I think that\nyour ideas are--",
    "start": "5652270",
    "end": "5660900"
  },
  {
    "text": "well, I mean there\nare several of us here who think you're a colleague\nand not a person out on the net.",
    "start": "5660900",
    "end": "5669030"
  },
  {
    "text": "So we are very pleased\nto have you around.",
    "start": "5669030",
    "end": "5674570"
  },
  {
    "start": "5674570",
    "end": "5678000"
  }
]
[
  {
    "start": "0",
    "end": "166000"
  },
  {
    "text": "so why are we working on automated driving not necessary why everybody's working on automated driving but why we",
    "start": "11210",
    "end": "16759"
  },
  {
    "text": "at sir I are working on Smitty driving is that number that insane number of one point 35 million road traffic deaths per",
    "start": "16759",
    "end": "22820"
  },
  {
    "text": "year right it's not Robo taxi that's gonna bring this number down it's not normal driver assistance system that's",
    "start": "22820",
    "end": "29029"
  },
  {
    "text": "gonna bring that number down because if you didn't have your driver assistance system that number would be three times as high it's something else so that's",
    "start": "29029",
    "end": "36170"
  },
  {
    "text": "why we have research in our middle name is we need to that's a hard problem if it was easy would be criminal for",
    "start": "36170",
    "end": "42079"
  },
  {
    "text": "humanity to not have solved it by them so how are we gonna solve that problem well really what is missing right we're",
    "start": "42079",
    "end": "50540"
  },
  {
    "text": "we're not idiots and especially you are the the generation of future non idiots that are gonna have to solve this",
    "start": "50540",
    "end": "56030"
  },
  {
    "text": "problem and and really there's something missing there right and if you look today and I just took you know like you",
    "start": "56030",
    "end": "63650"
  },
  {
    "text": "all in the in the middle of the action so you've seen a lot of other autonomous cars this is like the Alexis's and the",
    "start": "63650",
    "end": "70400"
  },
  {
    "text": "Toyotas you can buy today or very soon and this is like the ones that are",
    "start": "70400",
    "end": "76250"
  },
  {
    "text": "prototype level four level five self-driving cars that you might have seen around already before on the right",
    "start": "76250",
    "end": "81290"
  },
  {
    "text": "and there's something besides they all look cool now right no KFC bucket on the",
    "start": "81290",
    "end": "87590"
  },
  {
    "text": "top you know we had those before what",
    "start": "87590",
    "end": "92630"
  },
  {
    "text": "what's the difference right and one little difference is that these have",
    "start": "92630",
    "end": "99380"
  },
  {
    "text": "nothing on top right what's in there is all lied arts very expensive very fancy",
    "start": "99380",
    "end": "105080"
  },
  {
    "text": "lied ours right and so most of the people that are serious about level four level five and doing it right in a safe",
    "start": "105080",
    "end": "111050"
  },
  {
    "text": "way to decrease death they use lighters all right we had for a little bit of",
    "start": "111050",
    "end": "117590"
  },
  {
    "text": "black panther on our cars didn't work out too well so we have to do something else so can we get robust 3d perception",
    "start": "117590",
    "end": "124190"
  },
  {
    "text": "from vision right so all these cars that you know right they they today's cars they use vision they use radar these GPS",
    "start": "124190",
    "end": "129709"
  },
  {
    "text": "they don't use lidar not at least the lidar that you would see in the self-driving prototypes today right so",
    "start": "129709",
    "end": "136190"
  },
  {
    "text": "the key question the key thing that's missing really to make this connection between the most advanced level for prototypes you see today and today's",
    "start": "136190",
    "end": "142909"
  },
  {
    "text": "cars is I think I believe this question is one big part of what we're doing at our",
    "start": "142909",
    "end": "148640"
  },
  {
    "text": "I can we get robust 3d perception front vision so I'll cover a little bit why self supervised pseudo lidar is the main",
    "start": "148640",
    "end": "156739"
  },
  {
    "text": "research direction we're focusing on to actually address that question a couple of recent papers that we've made on that",
    "start": "156739",
    "end": "162530"
  },
  {
    "text": "topic and and then I'll wrap up with a conclusion so who has heard about pseudo",
    "start": "162530",
    "end": "170030"
  },
  {
    "start": "166000",
    "end": "360000"
  },
  {
    "text": "lidar a little show of hands or very few people monocular depth estimation",
    "start": "170030",
    "end": "176260"
  },
  {
    "text": "alright okay so you're it's the same thing it's just one is trendy because",
    "start": "176260",
    "end": "182959"
  },
  {
    "text": "Elon Musk accelerates address so so pseudo lidar and molecular defamation is",
    "start": "182959",
    "end": "188000"
  },
  {
    "text": "basically the same thing I mean it's almost it's the same thing because it's just like once you have a per pixel depth and you know your camera in turn",
    "start": "188000",
    "end": "194840"
  },
  {
    "text": "six guess what you have a point cloud right so we what we want to do in this problem is take a single RGB image right",
    "start": "194840",
    "end": "201200"
  },
  {
    "text": "and feed it through a mono def deep network a convolutional network and produce per pixel depth right it's like",
    "start": "201200",
    "end": "208310"
  },
  {
    "text": "turning the camera into a range sensor Y T RI and and Toyota we believe we can",
    "start": "208310",
    "end": "216019"
  },
  {
    "text": "solve that problem and tackle that problem well it's one thing it's because of the data right so two ties number one",
    "start": "216019",
    "end": "224180"
  },
  {
    "text": "car manufacturer in the world we have hundred million cars on the road today we sell 10 million new cars every year",
    "start": "224180",
    "end": "230060"
  },
  {
    "text": "and you know if you look at like very you know like simple statistics we have",
    "start": "230060",
    "end": "236269"
  },
  {
    "text": "basically the largest dashcam in the world right you can see it this way and and this is like tens of petabytes of",
    "start": "236269",
    "end": "242959"
  },
  {
    "text": "data per day which is like an order of magnitude of YouTube this is not the reality today right just like we're not",
    "start": "242959",
    "end": "248120"
  },
  {
    "text": "getting tens of petabytes today right your data is safe where it is in your Toyota's but weird we're working on",
    "start": "248120",
    "end": "254480"
  },
  {
    "text": "algorithms and and they're big plans that are being set in motion to use as much data as we need eventually to solve",
    "start": "254480",
    "end": "261260"
  },
  {
    "text": "that problem right so this is the challenge right what do you do with that by the way this this little bubble here",
    "start": "261260",
    "end": "267560"
  },
  {
    "text": "is YouTube so the challenges that we have to deal is like is like dwarfing",
    "start": "267560",
    "end": "273590"
  },
  {
    "text": "YouTube scale so in terms of scale and the magnitude of the challenges we have to face this is a big challenge but it's also a",
    "start": "273590",
    "end": "281030"
  },
  {
    "text": "big opportunity right and this is there are many many many papers you know it's like big data deep learning all the hype",
    "start": "281030",
    "end": "286820"
  },
  {
    "text": "etc right so there's always like a little kernel of truth in the hype and there's plenty of research evidence by",
    "start": "286820",
    "end": "294050"
  },
  {
    "text": "the way including 2011 so like one year before the whole imaginet revolution",
    "start": "294050",
    "end": "299510"
  },
  {
    "text": "we've random for us right there is machine learning has a long history of being better with data right so this is",
    "start": "299510",
    "end": "306710"
  },
  {
    "text": "not just a hype and so one thing that's been clear now with the experimental",
    "start": "306710",
    "end": "313430"
  },
  {
    "text": "evidence we've been acquiring at the recent years is that if you compare performance with amount of data you improve with with data older algorithms",
    "start": "313430",
    "end": "321280"
  },
  {
    "text": "including those from my PhD today plateau fairly quickly right and the",
    "start": "321280",
    "end": "328340"
  },
  {
    "text": "reason is because you have a modular system you handcraft features those features are not learned etc deep",
    "start": "328340",
    "end": "333590"
  },
  {
    "text": "learning learns everything so it scales better there's a little caveat to this which is it scales with labeled data",
    "start": "333590",
    "end": "340370"
  },
  {
    "text": "right that's where the hype stops right where all these people that you here because they have so much raw data",
    "start": "340370",
    "end": "345560"
  },
  {
    "text": "they're gonna win the race to whatever race they want to win definitely not the",
    "start": "345560",
    "end": "350660"
  },
  {
    "text": "race to zero fatalities it's with labeled data right and labeled data right now it means you look at it you",
    "start": "350660",
    "end": "356810"
  },
  {
    "text": "have people to look at it right and one of the challenges is that even if Toyota",
    "start": "356810",
    "end": "361940"
  },
  {
    "start": "360000",
    "end": "573000"
  },
  {
    "text": "was enslaving all of humanity's to click on pixels for us we can't label it like it's just not possible right so so we",
    "start": "361940",
    "end": "369680"
  },
  {
    "text": "have to invent some some new ideas right and and and do research on that problem and and that's where we're working on",
    "start": "369680",
    "end": "376790"
  },
  {
    "text": "self supervised learning so it's not just a dream of unsupervised learning you know the young the initial dream right which now here abanda self",
    "start": "376790",
    "end": "383450"
  },
  {
    "text": "supervised learning which was we learned just from raw data you know I have five year old daughter I don't let her watch YouTube every day and then I hope she",
    "start": "383450",
    "end": "389810"
  },
  {
    "text": "gets into Stanford it's it's you know there's structure in the data right it's",
    "start": "389810",
    "end": "395540"
  },
  {
    "text": "why it's just not unlabeled raw data like cat videos right and so how do we leverage that structure is key so really",
    "start": "395540",
    "end": "402470"
  },
  {
    "text": "the question is we have a lot of data but we don't have supervision what do we",
    "start": "402470",
    "end": "407690"
  },
  {
    "text": "do right so runaway so I tell you at a scale again like you",
    "start": "407690",
    "end": "414770"
  },
  {
    "text": "know like there's no free lunch theorem is and everything so you can't like be very generic so I'm gonna be specific in",
    "start": "414770",
    "end": "420169"
  },
  {
    "text": "my statements so self supervised learning for computer vision we want exploiting large volumes of unlabeled",
    "start": "420169",
    "end": "425240"
  },
  {
    "text": "but structured camera data okay so unlabeled is bad structured is",
    "start": "425240",
    "end": "430280"
  },
  {
    "text": "good training we want to only require unlabeled driving video data because that's by vast majority the amount of",
    "start": "430280",
    "end": "437180"
  },
  {
    "text": "bits we have and then wipe so a lot are in particular right again we're focusing and lidar is in very few cars so you",
    "start": "437180",
    "end": "445310"
  },
  {
    "text": "have some cars that have lidar that you can commercially by or very soon but it's typically like range sensors like",
    "start": "445310",
    "end": "451280"
  },
  {
    "text": "you have probably all in your robots you know like your one lidar except here we have four it's really just like not not",
    "start": "451280",
    "end": "458240"
  },
  {
    "text": "good for driving it's just collision avoidance and so we use luminaires which",
    "start": "458240",
    "end": "464719"
  },
  {
    "text": "I don't know if you know is the startup that does like very very advanced light ours with like a crazy range of like 250",
    "start": "464719",
    "end": "470870"
  },
  {
    "text": "meters because they operate in a 1550 nanometer range wavelength so that's the",
    "start": "470870",
    "end": "476870"
  },
  {
    "text": "cars like that see if you see like the rooftops like the of our cars of our",
    "start": "476870",
    "end": "481940"
  },
  {
    "text": "prototypes around the valley you will see like no KFC bucket that's because we have these very expensive lighters in in",
    "start": "481940",
    "end": "487849"
  },
  {
    "text": "that in there you don't want to have a Camry with that the price is not",
    "start": "487849",
    "end": "494509"
  },
  {
    "text": "something I think even VCS would be ok with so cameras Arabic kutis they",
    "start": "494509",
    "end": "500509"
  },
  {
    "text": "provide rich semantic and geometric sensing and really like so all the Toyotas now that you can buy they all",
    "start": "500509",
    "end": "506509"
  },
  {
    "text": "have cameras radars and like a fairly advanced cameras and and you know with a",
    "start": "506509",
    "end": "511819"
  },
  {
    "text": "be with all these advanced safety features so it's really like in tens of millions of cars now what about stereo",
    "start": "511819",
    "end": "518510"
  },
  {
    "text": "well we'll leave that for the pizza discussion so supervised learning I",
    "start": "518510",
    "end": "524329"
  },
  {
    "text": "assume you all know about supervised learning but it's very simple is you get the data feed into a model make",
    "start": "524329",
    "end": "530810"
  },
  {
    "text": "predictions pay a loss by comparing two labels given to you by an Oracle typically a human raw data easy to",
    "start": "530810",
    "end": "538190"
  },
  {
    "text": "acquire target data expensive difficult to acquire so supervised learning is",
    "start": "538190",
    "end": "544190"
  },
  {
    "text": "just looking at saying I don't like easy expensive hard expensive things just remove them so",
    "start": "544190",
    "end": "550850"
  },
  {
    "text": "here the magic trick right it's like you know you have to incorporate prior knowledge",
    "start": "550850",
    "end": "557089"
  },
  {
    "text": "right that's that's the thing you have to do to pay off instead of labels so at",
    "start": "557089",
    "end": "563569"
  },
  {
    "text": "across this year we made a paper called super depth which was our first contribution really on this direction of molecular definite works or absolute",
    "start": "563569",
    "end": "570829"
  },
  {
    "text": "lidar and so here the idea is the following is a training time we will assume we have",
    "start": "570829",
    "end": "577459"
  },
  {
    "start": "573000",
    "end": "636000"
  },
  {
    "text": "stereo data right so again we're learning a molecular networks which that that inference timing can work on the raw monocular video stream but that",
    "start": "577459",
    "end": "584089"
  },
  {
    "text": "training time let's assume for the moment that we have a stereo camera so we have a left and right image from the",
    "start": "584089",
    "end": "589790"
  },
  {
    "text": "parallel we know the baseline we feed the left image into the monocular deaf Network we get a depth map right so yeah",
    "start": "589790",
    "end": "596389"
  },
  {
    "text": "that for inverse depth per pixel then geometry tells you actually if you know",
    "start": "596389",
    "end": "603560"
  },
  {
    "text": "the baseline and you know the depth you can actually know the mapping of pixels from one frame to the other so what you",
    "start": "603560",
    "end": "610069"
  },
  {
    "text": "can do is you can warp right so this is this view thins the synthesis you can warp one frame on to the other and then",
    "start": "610069",
    "end": "616790"
  },
  {
    "text": "you can see whether after warping the pixels have the same color right if you're if you warp correctly this pixel",
    "start": "616790",
    "end": "623149"
  },
  {
    "text": "should line their college should be the same and so that's called the photometric loss and that's basically at",
    "start": "623149",
    "end": "628220"
  },
  {
    "text": "the heart of all the self supervised geometric methods you would see there",
    "start": "628220",
    "end": "634000"
  },
  {
    "text": "and so the lost again so it's like if those of you that are already familiar",
    "start": "634000",
    "end": "639139"
  },
  {
    "start": "636000",
    "end": "684000"
  },
  {
    "text": "with deep learning you know you minimize the loss over pixels and here you minimize the loss between the image and the target image and the Warped target",
    "start": "639139",
    "end": "645860"
  },
  {
    "text": "image and the loss is decomposed in multiple terms and the beauty of these is that really this is the supervision",
    "start": "645860",
    "end": "653269"
  },
  {
    "text": "right this IT hat right this is not a human provided label this is a geometry",
    "start": "653269",
    "end": "658399"
  },
  {
    "text": "provided label right and so this Lost's this photometric law that I mentioned before it basically you can pay it off",
    "start": "658399",
    "end": "665180"
  },
  {
    "text": "the raw data directly then of course we add some additional terms to make it",
    "start": "665180",
    "end": "670430"
  },
  {
    "text": "better because there are some photometric ambiguities like a white wall you know all the pixels on what",
    "start": "670430",
    "end": "675500"
  },
  {
    "text": "wall look white so they're invalid there's a plenty invalid matching that yield the same zero loss so we have to add additional",
    "start": "675500",
    "end": "682430"
  },
  {
    "text": "regularization terms and so that basically was like kind of like kick-started this kind of idea of you",
    "start": "682430",
    "end": "688490"
  },
  {
    "start": "684000",
    "end": "810000"
  },
  {
    "text": "can do that learn to predict that from a single image by not requiring any supervision and that started basically",
    "start": "688490",
    "end": "695839"
  },
  {
    "text": "circa 2016 of come on Godard and and all those folks one of the things we found was when you do driving you want to see",
    "start": "695839",
    "end": "702680"
  },
  {
    "text": "far ahead right because when you go fast you want to anticipate in advance so you",
    "start": "702680",
    "end": "707720"
  },
  {
    "text": "need to see far ahead so seeing far ahead with cameras mean operating at a high resolution so you have as many",
    "start": "707720",
    "end": "712940"
  },
  {
    "text": "pixels and as possible on objects far ahead so when we tried these ideas initially to see if they would actually",
    "start": "712940",
    "end": "718790"
  },
  {
    "text": "work beyond the research paper we tried them directly on our high resolution cameras and what we found is that",
    "start": "718790",
    "end": "724790"
  },
  {
    "text": "results were actually significantly better than the research report so I",
    "start": "724790",
    "end": "729829"
  },
  {
    "text": "don't know how often it happens to you when you try to reproduce a paper and you got better results never happened to",
    "start": "729829",
    "end": "735740"
  },
  {
    "text": "me you know always the other way around if I get any number at all and so here we were really wondering",
    "start": "735740",
    "end": "740930"
  },
  {
    "text": "what the what's going on you know did we train on the test set you know like this usual stuff and and actually didn't after investigating a bit more what we",
    "start": "740930",
    "end": "747440"
  },
  {
    "text": "found and we could reproduce was well it makes sense resolution matters because again we're",
    "start": "747440",
    "end": "752630"
  },
  {
    "text": "warping a frame onto another and then we're comparing the pixels and I mentioned this white wall effect if you",
    "start": "752630",
    "end": "757880"
  },
  {
    "text": "look at the white wall from afar everything looks white so any wrong matching yield zero loss you're not back",
    "start": "757880",
    "end": "763100"
  },
  {
    "text": "propagating you don't learn but if you look really close you would see there are some smudges there are some details",
    "start": "763100",
    "end": "768649"
  },
  {
    "text": "that will actually yield a little bit of a loss right that would resolve some photometric ambiguities so operating at",
    "start": "768649",
    "end": "774500"
  },
  {
    "text": "a higher resolution means you're not a liasing out you're not blurring the tiny details that help recover and so roads",
    "start": "774500",
    "end": "780980"
  },
  {
    "text": "they might look very uniform on the downsample resolution but at a high resolution you would see these irregularities that enable you to learn",
    "start": "780980",
    "end": "788120"
  },
  {
    "text": "a proper matching and so we said okay naturally well can we go beyond you know and actually do super resolution this",
    "start": "788120",
    "end": "795170"
  },
  {
    "text": "time and so that's what we did we took a standard network like the distant architecture which is a unit",
    "start": "795170",
    "end": "800180"
  },
  {
    "text": "architecture with like you have convolutional layers d convolutional layers skip connections and we added sub",
    "start": "800180",
    "end": "807500"
  },
  {
    "text": "pixel convolution blocks which are typical operations that are there to try to have this details when you learn super-resolution",
    "start": "807500",
    "end": "815060"
  },
  {
    "start": "810000",
    "end": "866000"
  },
  {
    "text": "networks right again these details are lost right it says thank you compressed the signal you lost those so what you're",
    "start": "815060",
    "end": "821720"
  },
  {
    "text": "trying to do is you're trying to learn weights that from data captured patterns that says oh I've seen these kind of",
    "start": "821720",
    "end": "827240"
  },
  {
    "text": "things it typically actually corresponds to a high-resolution signal like this so we use that we I'm gonna go quickly over",
    "start": "827240",
    "end": "835100"
  },
  {
    "text": "those results because we have newer results but we improve the state of the art qualitatively quantitatively one",
    "start": "835100",
    "end": "842060"
  },
  {
    "text": "thing that's really kind of you should ask as robot assists when people talk about that especially computer vision",
    "start": "842060",
    "end": "848540"
  },
  {
    "text": "people like me that are not robot assists you should say show me a point cloud right I don't believe you that I",
    "start": "848540",
    "end": "854300"
  },
  {
    "text": "don't know what it is this is probably unscaled this is in this case it's very",
    "start": "854300",
    "end": "859430"
  },
  {
    "text": "it's not and scale but look at a point cloud right and so very few papers actually are not like are showing point",
    "start": "859430",
    "end": "866330"
  },
  {
    "start": "866000",
    "end": "1421000"
  },
  {
    "text": "clouds because their point clouds suck so I encourage you to look at more details we have the video on YouTube you",
    "start": "866330",
    "end": "872480"
  },
  {
    "text": "can have a look at this I wouldn't drive off of this point cloud all right or the collision avoidance off of this point",
    "start": "872480",
    "end": "878300"
  },
  {
    "text": "cloud but it's starting to look like it's going somewhere so we said okay let's go further",
    "start": "878300",
    "end": "883480"
  },
  {
    "text": "actually you know let's take a step back what if we don't have stereo training time what if we have just videos because",
    "start": "883480",
    "end": "889910"
  },
  {
    "text": "remember we assume we know the baseline is frontal parallel taken at the same time so the world is static right and so",
    "start": "889910",
    "end": "896210"
  },
  {
    "text": "you're warping one frame onto another we were very simple geometric relationship now videos right structure for motion",
    "start": "896210",
    "end": "903560"
  },
  {
    "text": "slam etc take a frame you move the world changes you take another frame that's",
    "start": "903560",
    "end": "909770"
  },
  {
    "text": "the signal we have how what geometric prior do we use in our loss for self supervision CSS is the Toyota safety",
    "start": "909770",
    "end": "916820"
  },
  {
    "text": "sense right that's that's the that's today's cars right that's the data we get today and that's the data we have to",
    "start": "916820",
    "end": "921980"
  },
  {
    "text": "train that scale from so that's what we did recently we extended this work super",
    "start": "921980",
    "end": "928160"
  },
  {
    "text": "def into a new work it's called pack net sfm it's available in archive currently under review and",
    "start": "928160",
    "end": "936040"
  },
  {
    "text": "and so here the idea was the following is remember we had the stereo so left",
    "start": "936040",
    "end": "941390"
  },
  {
    "text": "image right image now we have instead a pair of frames which is human but we can pretend it's a generalized",
    "start": "941390",
    "end": "950089"
  },
  {
    "text": "stereo pair let's pretend and let's do the same approach right so one of the",
    "start": "950089",
    "end": "956360"
  },
  {
    "text": "difficulties there is you don't know the six degrees transformation six degrees of freedom transformation from the",
    "start": "956360",
    "end": "961399"
  },
  {
    "text": "camera right it can move in 3d space so how do you warp and then what do you do",
    "start": "961399",
    "end": "966649"
  },
  {
    "text": "about the dynamic objects right so here's the architecture that we have by the way like this is called structure",
    "start": "966649",
    "end": "973010"
  },
  {
    "text": "for motion in computer vision this problem and here you have let's say target image so typically you when you",
    "start": "973010",
    "end": "979190"
  },
  {
    "text": "train you train on the image at T and then you have like context images like t minus 1 and t plus 1 and so here we feed",
    "start": "979190",
    "end": "986420"
  },
  {
    "text": "the target image through pack net our new neural network architecture that we proposed specifically for that task",
    "start": "986420",
    "end": "992500"
  },
  {
    "text": "generate a depth image and then we also have to have a pose network which is a",
    "start": "992500",
    "end": "999440"
  },
  {
    "text": "deep network that takes series of frames and tries to estimate the the transformation the ego motion of the",
    "start": "999440",
    "end": "1005740"
  },
  {
    "text": "camera basically between frames progresses or rotation and a translation right and then you can do the view",
    "start": "1005740",
    "end": "1013089"
  },
  {
    "text": "synthesis right you know the depth you know the images you know the transformation you can work you can",
    "start": "1013089",
    "end": "1018250"
  },
  {
    "text": "apply the same principle of view synthesis assuming the world is static",
    "start": "1018250",
    "end": "1023350"
  },
  {
    "text": "which means assuming that the dynamic objects are noise create noise in your warp so invalidate your warp but in a",
    "start": "1023350",
    "end": "1031480"
  },
  {
    "text": "minority of pixels that's the underlying hypothesis that the system is doing when it's learning okay in addition to that",
    "start": "1031480",
    "end": "1038500"
  },
  {
    "text": "we added if you you know most robots and cars definitely know at what speed",
    "start": "1038500",
    "end": "1043540"
  },
  {
    "text": "they're going they don't know precisely how the camera is moving in 3d space but they know they have an auto meter they know like a wheel encoder or whatever",
    "start": "1043540",
    "end": "1049510"
  },
  {
    "text": "they know at which speed they're going right so if you know that you can",
    "start": "1049510",
    "end": "1054790"
  },
  {
    "text": "actually add some constraints to your translation vector the magnitude of your translation vector and one thing that's",
    "start": "1054790",
    "end": "1060220"
  },
  {
    "text": "really interesting is that all that it's like in the structure from motion from you have a scale ambiguity meaning that",
    "start": "1060220",
    "end": "1065590"
  },
  {
    "text": "I could like we could all be like tiny midgets and that room would be tiny room",
    "start": "1065590",
    "end": "1070780"
  },
  {
    "text": "and it would yield the same laws the same everything so there's scale and big ete you",
    "start": "1070780",
    "end": "1076990"
  },
  {
    "text": "typically have to resolve it with some measure of sky at test time right so when you deploy your model you need to do something that",
    "start": "1076990",
    "end": "1082659"
  },
  {
    "text": "tells you how you should scale your def your your everything to metric space here with this approach if you train",
    "start": "1082659",
    "end": "1089830"
  },
  {
    "text": "with the velocity supervision and you can train a translation magnitude to be in line with your velocity this is",
    "start": "1089830",
    "end": "1094869"
  },
  {
    "text": "scaled so this is forcing the output of the network to be scaled also and the solar our whole approach is scaled and",
    "start": "1094869",
    "end": "1100989"
  },
  {
    "text": "metrically accurate so at test time you don't need to know a notion of scale the network has internalized",
    "start": "1100989",
    "end": "1107409"
  },
  {
    "text": "a notion of scale so here is an example",
    "start": "1107409",
    "end": "1113619"
  },
  {
    "text": "video I I won't play it in its entirety but you will you can find it again online I'll directly skip to the cool",
    "start": "1113619",
    "end": "1122980"
  },
  {
    "text": "part which is the point clouds if it",
    "start": "1122980",
    "end": "1128649"
  },
  {
    "text": "works so you have the range image right",
    "start": "1128649",
    "end": "1133929"
  },
  {
    "text": "so the visualization that all the people in computer vision know and love and",
    "start": "1133929",
    "end": "1141809"
  },
  {
    "text": "so that's the points out so here what you're seeing at the top so this is the image it gets fed to our network our",
    "start": "1151090",
    "end": "1156610"
  },
  {
    "text": "network outputs scales depth right and also it outputs the post right the Delta",
    "start": "1156610",
    "end": "1161740"
  },
  {
    "text": "of the post of the camera so we can actually do denser construction so what you're seeing is the point cloud colored",
    "start": "1161740",
    "end": "1167019"
  },
  {
    "text": "by the pixels right that you get from from our network this is the height map so I encourage you all again to look at",
    "start": "1167019",
    "end": "1172990"
  },
  {
    "text": "this online the video is on YouTube because like crappy codecs so look at it",
    "start": "1172990",
    "end": "1179230"
  },
  {
    "text": "in details and what you'll see is we can even see difference in the height for the curb so operating at a very high",
    "start": "1179230",
    "end": "1185559"
  },
  {
    "text": "resolution our network also is able to have like a very fine-grained notion of depth and of 3d scene geometry dense 3d",
    "start": "1185559",
    "end": "1192549"
  },
  {
    "text": "scene geometry one of the other cool things you could see in this video is that garbage cans you know one of the",
    "start": "1192549",
    "end": "1199960"
  },
  {
    "text": "cool things about unsupervised learning and self surprise learning is if you didn't think that you should model garbage cans in your object detector et",
    "start": "1199960",
    "end": "1206110"
  },
  {
    "text": "cetera and suddenly there's a garbage can on the road and you're like oops there's I don't know what it is with",
    "start": "1206110",
    "end": "1211539"
  },
  {
    "text": "unsupervised learning if you've seen garbage cans enough right you actually can just like a lidar detect it right",
    "start": "1211539",
    "end": "1218740"
  },
  {
    "text": "and so here what you would see in these videos you would see that very often we have actually a very correct depth on",
    "start": "1218740",
    "end": "1225190"
  },
  {
    "text": "on weird categories that actually our objective detection team has never thought of actually modeling which is",
    "start": "1225190",
    "end": "1230529"
  },
  {
    "text": "the entire point of unsupervised learning is going beyond what an engineer or a machine learning engineer you know we think I need to model that",
    "start": "1230529",
    "end": "1237279"
  },
  {
    "text": "in the world so just a little bit of the",
    "start": "1237279",
    "end": "1245019"
  },
  {
    "text": "secret sauce in details because I think one of the key contributions in that paper was really the architecture there's a cool paper by Google brain",
    "start": "1245019",
    "end": "1251019"
  },
  {
    "text": "looks buyer and and co-authors where they show something that's like",
    "start": "1251019",
    "end": "1258399"
  },
  {
    "text": "you know in hindsight obvious but it was not obvious until this paper which is self supervised tasks right which which",
    "start": "1258399",
    "end": "1265480"
  },
  {
    "text": "notion of self supervision which geometric property or prior you're using right have an affinity with the network",
    "start": "1265480",
    "end": "1270970"
  },
  {
    "text": "architecture so one of the very hard things about deep learning is how do you design this network architecture do I",
    "start": "1270970",
    "end": "1276009"
  },
  {
    "text": "put 10 layers 15 layers 30 layers how many like do I put 64 channels for that",
    "start": "1276009",
    "end": "1281590"
  },
  {
    "text": "layer do I do is keep connection there I mean there's a neural architecture search that's going on but no architecture",
    "start": "1281590",
    "end": "1286750"
  },
  {
    "text": "search right now is like like I did peak hype it's just like if I already have a good Network please give me one more",
    "start": "1286750",
    "end": "1292659"
  },
  {
    "text": "percent by fiddling a little bit with the parameters around right that's how it works but here what what we found is",
    "start": "1292659",
    "end": "1301480"
  },
  {
    "text": "that we use again our prior in designing the network and one of the things that was important was no down sampling so if",
    "start": "1301480",
    "end": "1309309"
  },
  {
    "text": "you remember the unit architecture I showed you before is like we take the full image we like convolution down",
    "start": "1309309",
    "end": "1314950"
  },
  {
    "text": "sampling convolution down sampling evolution down sampling up sampling convolution of sampling convolution",
    "start": "1314950",
    "end": "1320409"
  },
  {
    "text": "right and we say resolution is very important then why are we going through",
    "start": "1320409",
    "end": "1327159"
  },
  {
    "text": "the effort of destroying all that research and information and trying to reinvent it right and the reason is",
    "start": "1327159",
    "end": "1334240"
  },
  {
    "text": "technical debt the reason is because these networks were designed for images right the encoder decoder is because the",
    "start": "1334240",
    "end": "1341649"
  },
  {
    "text": "encoders are imagenet networks that are designed to classify an image by saying that image is people right I don't care",
    "start": "1341649",
    "end": "1349299"
  },
  {
    "text": "about the different people it's like that image is whole people so you want to collapse all the pixels all on you right to a single class so we said hey",
    "start": "1349299",
    "end": "1357190"
  },
  {
    "text": "well instead of like taking those networks that exist at our design for image classification that degrades special information a lot and then",
    "start": "1357190",
    "end": "1363250"
  },
  {
    "text": "trying very hard to elucidate the details back let's just not degrade that",
    "start": "1363250",
    "end": "1368679"
  },
  {
    "text": "information let's just not destroy it in the first place and so here instead of max pooling right we do packing and so",
    "start": "1368679",
    "end": "1376600"
  },
  {
    "text": "packing is the same thing as for compression right image compression you",
    "start": "1376600",
    "end": "1382659"
  },
  {
    "text": "you you can imagine that here what we want is instead of like decimating the signal we're learning to compress we're",
    "start": "1382659",
    "end": "1389289"
  },
  {
    "text": "learning a transformation that says here are the the noise remove that part I consider this as noise and really",
    "start": "1389289",
    "end": "1395529"
  },
  {
    "text": "preserve the information content that I need for my photometric loss right and so here what we do is we learn blocks",
    "start": "1395529",
    "end": "1403289"
  },
  {
    "text": "and I'll show you a little bit of intuition that learn to compress right learn to do a lossy compression of the",
    "start": "1403289",
    "end": "1409240"
  },
  {
    "text": "signal as input and then same thing the no absenting we learn to unpack to",
    "start": "1409240",
    "end": "1415000"
  },
  {
    "text": "basically decompress so it's like basically learning a codec and",
    "start": "1415000",
    "end": "1419878"
  },
  {
    "text": "so here's the packing and unpacking blocks a little bit of technical details so this is what people typically do",
    "start": "1420370",
    "end": "1426880"
  },
  {
    "start": "1421000",
    "end": "1629000"
  },
  {
    "text": "right it's like when you do max pulling and you do up sampling you're basically just like turning a Gaussian into a",
    "start": "1426880",
    "end": "1434680"
  },
  {
    "text": "pixel and you're turning a pixel into a Gaussian right that's that's what you're doing you're blurring things out right or decimating here instead what we do is",
    "start": "1434680",
    "end": "1442660"
  },
  {
    "text": "we take the whole signal and then we do this like interesting aspect that's like",
    "start": "1442660",
    "end": "1448540"
  },
  {
    "text": "intuition that came from super resolution which is when you have tensors like in this shape right be CHW",
    "start": "1448540",
    "end": "1454390"
  },
  {
    "text": "right so B is the batch size so let's say you just have one image these one C is the number of channels right so when",
    "start": "1454390",
    "end": "1460150"
  },
  {
    "text": "it's the color image it's three channels but further down it's your size of your representation your intermediate representations H is the height width is",
    "start": "1460150",
    "end": "1467050"
  },
  {
    "text": "their width in pixels so one of the things you can see is you can say well if you see few G's as a tensor you can",
    "start": "1467050",
    "end": "1473530"
  },
  {
    "text": "actually reshape the underlying tensor to structure the pixels in different ways and and reinterpret basically that",
    "start": "1473530",
    "end": "1480640"
  },
  {
    "text": "tensors dimensions so here this is what space to def does it's a very simple operation that basically just says hey",
    "start": "1480640",
    "end": "1487140"
  },
  {
    "text": "what if I want to reduce my resolution H and W by a factor of two right along",
    "start": "1487140",
    "end": "1493060"
  },
  {
    "text": "each dimension so H divided by two w but what do I do with the rest of the remaining pixels right like so max",
    "start": "1493060",
    "end": "1499120"
  },
  {
    "text": "pooling would just say throw them out right here we say well actually just pack them into the channels so you're",
    "start": "1499120",
    "end": "1504790"
  },
  {
    "text": "taking basically a 2 by 2 region and instead of replacing it with the max value you're saying let's replace this 2",
    "start": "1504790",
    "end": "1511330"
  },
  {
    "text": "by 2 region by a 4 dimensional vector right that's it that's really just it so",
    "start": "1511330",
    "end": "1517840"
  },
  {
    "text": "for those of you that know new pipe I torture it's a reshape that's that's everything you're doing right and so",
    "start": "1517840",
    "end": "1523450"
  },
  {
    "text": "then what yours but what you have is now you said I traded spatial details and I reinterpreted the spatial details as",
    "start": "1523450",
    "end": "1529960"
  },
  {
    "text": "features and now I can learn to compress that feature space into a lower dimensional feature space and so we're",
    "start": "1529960",
    "end": "1537220"
  },
  {
    "text": "doing an expansion and contraction there because we are that feature space is probably not a very good feature space",
    "start": "1537220",
    "end": "1543370"
  },
  {
    "text": "for convolutions because convolutions our translation invariance you're taking special details backing them along the channel so yes so you're just",
    "start": "1543370",
    "end": "1551929"
  },
  {
    "text": "- interpreting them so it might not be very easily learn about so we expand them into a higher dimensional feature space where convolutions make more sense",
    "start": "1551929",
    "end": "1558980"
  },
  {
    "text": "so that's why we use a 3d convolution and then we pack them right so we do an expansion kit so reshape expansion",
    "start": "1558980",
    "end": "1565549"
  },
  {
    "text": "contraction a little bit technical but the end effects that it has is it basically expands vastly the receptive",
    "start": "1565549",
    "end": "1572210"
  },
  {
    "text": "field right which is a key problem in computer vision is like like convolution theoretic convolutions they make a decision based on the 3x3 pixel region",
    "start": "1572210",
    "end": "1578779"
  },
  {
    "text": "and so you have to stack a lot of those if you want to reason across the scene to say like oh that's a road pixel",
    "start": "1578779",
    "end": "1584029"
  },
  {
    "text": "that's the road pixel yeah I know because they're close right so here you're basically have some kind of like a tiling effect that happens in that",
    "start": "1584029",
    "end": "1591259"
  },
  {
    "text": "network which enables you to say I don't care that all these pixels are really really close to each other like putting",
    "start": "1591259",
    "end": "1597619"
  },
  {
    "text": "the exactly the same weight on things that are very very close it's like redundant right it's like a waste of energy or waste of parameters and so",
    "start": "1597619",
    "end": "1604909"
  },
  {
    "text": "here it's basically doing some kind of tiling basically this is like learned",
    "start": "1604909",
    "end": "1610159"
  },
  {
    "text": "right to say hey if I want to see further I need to trade off some of the like redundant things to basically pay",
    "start": "1610159",
    "end": "1617179"
  },
  {
    "text": "less attention to things that are redundant and so that I can spread my attention a little bit further with the same number of parameters right",
    "start": "1617179",
    "end": "1622960"
  },
  {
    "text": "unpacking is similar but in the reverse operation the velocity scaling that I",
    "start": "1622960",
    "end": "1629179"
  },
  {
    "start": "1629000",
    "end": "2245000"
  },
  {
    "text": "mentioned before this is just to show you some results that I think it's pretty cool you have a face transition I love face transition so that compressed",
    "start": "1629179",
    "end": "1634999"
  },
  {
    "text": "sensing you know like so Stanford has like you know done one of the papers that I like the most about you know math",
    "start": "1634999",
    "end": "1641960"
  },
  {
    "text": "closes math - magic which is about compressed sensing and so I look for phase transitions and things and and",
    "start": "1641960",
    "end": "1647450"
  },
  {
    "text": "here one thing that was super cool is this velocity Supervision right that says we constrain the magnitude of our",
    "start": "1647450",
    "end": "1653629"
  },
  {
    "text": "ego motion estimator you see that basically like it takes awhile to learn",
    "start": "1653629",
    "end": "1658909"
  },
  {
    "text": "the scale intrinsic scale and then very quickly it catches up onto the intrinsic scale so this is just like to show you",
    "start": "1658909",
    "end": "1666350"
  },
  {
    "text": "some evidence that you don't need to know scale of the scene that test time you can learn it through the network and",
    "start": "1666350",
    "end": "1672289"
  },
  {
    "text": "it basically just latches on to that global optimum during training okay we",
    "start": "1672289",
    "end": "1678710"
  },
  {
    "text": "beat the state-of-the-art and I'm not going to go through all these numbers it's just like a big wall of numbers to scare you to show you that it takes a",
    "start": "1678710",
    "end": "1684529"
  },
  {
    "text": "lot of efforts to show that it works but you have to do this when you're a scientist",
    "start": "1684529",
    "end": "1690620"
  },
  {
    "text": "you can't just claim we're the best look at our stuff awesome ship it you need to actually do these",
    "start": "1690620",
    "end": "1697280"
  },
  {
    "text": "duties these experiments that take a lot of time and effort one of the things that's super cool though is the numbers",
    "start": "1697280",
    "end": "1702890"
  },
  {
    "text": "that I highlighted it's not just that we we got the best results in terms of self supervised learning by improving a lot",
    "start": "1702890",
    "end": "1709040"
  },
  {
    "text": "so this is like apps rel is that so there's many metrics this basically tell you where is the absolute relative error",
    "start": "1709040",
    "end": "1714560"
  },
  {
    "text": "you make with respect to lidar right in terms of like distance and one thing",
    "start": "1714560",
    "end": "1721820"
  },
  {
    "text": "that's very interesting is that for the first time and I have made that claim to",
    "start": "1721820",
    "end": "1729170"
  },
  {
    "text": "try to see if people would disprove me so far nobody has disproved me even myself trying to find in the literature but this is the first time that I'm",
    "start": "1729170",
    "end": "1736880"
  },
  {
    "text": "aware of where self supervised learning actually works better than supervised learning these methods are supervised",
    "start": "1736880",
    "end": "1743690"
  },
  {
    "text": "methods where what they do is instead of paying this photometric loss you know using geometry as a source of supervision what they do is they say",
    "start": "1743690",
    "end": "1750140"
  },
  {
    "text": "well let's just learn from sequences where I have recorded image and lidar at the same time I know the extrinsic",
    "start": "1750140",
    "end": "1756290"
  },
  {
    "text": "calibration so I can project a point cloud onto the image I have not too much parallax and therefore I can formulate",
    "start": "1756290",
    "end": "1763130"
  },
  {
    "text": "this as a regression problem that's how things started by the way beyond the cone excetera I was like pixel as input",
    "start": "1763130",
    "end": "1768500"
  },
  {
    "text": "regress the depth target def given to me by lidar these are the state-of-the-art methods for supervised learning and now",
    "start": "1768500",
    "end": "1777190"
  },
  {
    "text": "are you telling you a little bit but still we are better than supervised methods so I'm super excited about this",
    "start": "1777190",
    "end": "1783410"
  },
  {
    "text": "because this is on kitty kitty is standard benchmark and autumn is driving",
    "start": "1783410",
    "end": "1788480"
  },
  {
    "text": "in the research community it's ridiculously small its tiny that Network",
    "start": "1788480",
    "end": "1793730"
  },
  {
    "text": "is very big and so here you would say well tiny data very big Network",
    "start": "1793730",
    "end": "1798740"
  },
  {
    "text": "you are so overfitting we have actually done experiments where we showed that",
    "start": "1798740",
    "end": "1804380"
  },
  {
    "text": "this network actually generalized better than any other network on on other data",
    "start": "1804380",
    "end": "1809630"
  },
  {
    "text": "and so here how's that possible right and the reason is because again we capture a better prior right we have",
    "start": "1809630",
    "end": "1815600"
  },
  {
    "text": "more structure baked into our network and our loss and that's how with more parameters we can learn better and",
    "start": "1815600",
    "end": "1822410"
  },
  {
    "text": "generalize better so these are some results that show this so this is like",
    "start": "1822410",
    "end": "1828480"
  },
  {
    "text": "basically train on tea tea and then we extend it to new scenes right so yeah sorry at the end cool",
    "start": "1828480",
    "end": "1835830"
  },
  {
    "text": "so one of the things here is you can't call it a pseudo lidar Network if it's",
    "start": "1835830",
    "end": "1841530"
  },
  {
    "text": "not deployable as the lidar right a lidar sensor in clear good conditions",
    "start": "1841530",
    "end": "1847290"
  },
  {
    "text": "you put it on a car in Singapore you put in a car in Tokyo you put in a car in u.s. it will give you that you're not",
    "start": "1847290",
    "end": "1853620"
  },
  {
    "text": "gonna say oh no I don't trust the Tokyo version of the lidar no no you know it's it's a sensor it's an active sensor so",
    "start": "1853620",
    "end": "1860429"
  },
  {
    "text": "our system is learned it's not an active sensor it's a passive sensor that's hallucinating the depth from how things",
    "start": "1860429",
    "end": "1866040"
  },
  {
    "text": "look by capturing it from some data so generalization performance is a key aspect of being able to make any claim",
    "start": "1866040",
    "end": "1872910"
  },
  {
    "text": "about the usefulness of pseudo lidar and so here what we show is that if you take existing architectures which are generic",
    "start": "1872910",
    "end": "1878670"
  },
  {
    "text": "architectures resonates that are designed for image classification that were like state of the art and are that",
    "start": "1878670",
    "end": "1885360"
  },
  {
    "text": "we improved upon but they were really good they generalize way worse to a new",
    "start": "1885360",
    "end": "1890910"
  },
  {
    "text": "environment so new scenes as a new data set is made by the Newton amigas which is I think Boston and Singapore so",
    "start": "1890910",
    "end": "1897690"
  },
  {
    "text": "nothing to do with Karlsruhe Germany which is kidney right and so and so",
    "start": "1897690",
    "end": "1903030"
  },
  {
    "text": "really that was very encouraging and again reinforces that if you have a good prior if you have a good structure in",
    "start": "1903030",
    "end": "1908160"
  },
  {
    "text": "your model in your learning you will generalize better and we have more parameters so we have more parameters",
    "start": "1908160",
    "end": "1913920"
  },
  {
    "text": "than these networks and yet we generalize better although we're trying on small data and we improve with data",
    "start": "1913920",
    "end": "1919830"
  },
  {
    "text": "the other thing is self supervised learning the whole point of software learning is not to Train on kitty is that what if I have this again 10",
    "start": "1919830",
    "end": "1925890"
  },
  {
    "text": "petabytes of data can I train on that and is it better than if I have one petabyte of data is it better than if I",
    "start": "1925890",
    "end": "1932340"
  },
  {
    "text": "have 100 gigabytes of data and so you want networks that scale with data because they can scale with the labeling",
    "start": "1932340",
    "end": "1937950"
  },
  {
    "text": "but maybe they don't scare on performance so we show that we do scale with data which again as for point",
    "start": "1937950",
    "end": "1944490"
  },
  {
    "text": "clouds has for how self supervised methods scale with data very few papers",
    "start": "1944490",
    "end": "1949800"
  },
  {
    "text": "show that yet that's a whole motivation qualitative results you can look at the",
    "start": "1949800",
    "end": "1956620"
  },
  {
    "text": "paper we're better on fine fine structures where again this is our",
    "start": "1956620",
    "end": "1961840"
  },
  {
    "text": "network better than the best self supervised better than the bests semi-supervised are fully supervised",
    "start": "1961840",
    "end": "1968710"
  },
  {
    "text": "right lidar you don't have light our points in the cloud so that in the in the sky so you have some issues with that right so that's also one reason",
    "start": "1968710",
    "end": "1974950"
  },
  {
    "text": "this is like last year's cvpr two years no two year cvpr so just for your information like that",
    "start": "1974950",
    "end": "1983130"
  },
  {
    "text": "that versus that the pace of the field is crazy and you would think it's data a",
    "start": "1983130",
    "end": "1990070"
  },
  {
    "text": "compute except no no it's kitty this is all the same so it's all about the architecture it's all about the",
    "start": "1990070",
    "end": "1995260"
  },
  {
    "text": "architecture it's all about the loss so it's about the algorithm one thing that",
    "start": "1995260",
    "end": "2000600"
  },
  {
    "text": "super cool is is you can look at crazy things like again like cones you know you have like when you do it time is",
    "start": "2000600",
    "end": "2006690"
  },
  {
    "text": "driving and you work in the Bay Area and there's construction all the freakin time you have to model cones like I hate",
    "start": "2006690",
    "end": "2012750"
  },
  {
    "text": "cones like it's not you know especially with like fancy lidar sensors that work",
    "start": "2012750",
    "end": "2017910"
  },
  {
    "text": "at like 250 meter range that can pulse really really nicely and then you have",
    "start": "2017910",
    "end": "2023130"
  },
  {
    "text": "this retro fact rich retro reflective surfaces on cone right next to you that crazy explosion so here we like it's",
    "start": "2023130",
    "end": "2031140"
  },
  {
    "text": "it's we learned from we learned from raw data you see cones you know you use our static objects you moved around them you",
    "start": "2031140",
    "end": "2036600"
  },
  {
    "text": "captured the 3d structure you can relate how a cone looks like to how a cone is in 3d space other cool things is science",
    "start": "2036600",
    "end": "2045300"
  },
  {
    "text": "sharp boundaries posed right so things that are very thin structures if you do it at a reduced resolution if you do it",
    "start": "2045300",
    "end": "2051600"
  },
  {
    "text": "like 5 or 10 32 by 32 resolution you can't learn these things so operating at",
    "start": "2051600",
    "end": "2056879"
  },
  {
    "text": "a very high resolution preserving fine details enable you to capture things thin structures like poles you don't",
    "start": "2056880",
    "end": "2063510"
  },
  {
    "text": "want to collide with a pole it's thin sure but you don't want to collide with a pole even thinner fences this is my",
    "start": "2063510",
    "end": "2072210"
  },
  {
    "text": "favorite when I saw this I said I don't care it just goes into the paper this figure it goes into the paper you can",
    "start": "2072210",
    "end": "2077790"
  },
  {
    "text": "see and you can look at the paper it's in the paper fences we can",
    "start": "2077790",
    "end": "2082908"
  },
  {
    "text": "it's like that there's a fence and we can detect the thin like part structures of the fence and and projects the right",
    "start": "2082909",
    "end": "2090108"
  },
  {
    "text": "depth behind the fence so that is really like an example of how what you can gain",
    "start": "2090109",
    "end": "2096349"
  },
  {
    "text": "from like high resolution okay so we can learn from all the data it gets better",
    "start": "2096349",
    "end": "2101359"
  },
  {
    "text": "with the data just from video that's cool does it get better I highlighted that",
    "start": "2101359",
    "end": "2106940"
  },
  {
    "text": "yes it gets it gets better and it depends so there's still research to be",
    "start": "2106940",
    "end": "2112099"
  },
  {
    "text": "done so we had a paper at a nice email workshop on self service learning where we're showing that we said okay now",
    "start": "2112099",
    "end": "2118460"
  },
  {
    "text": "let's Kiki that's great let's try to use 1 million of frames from our logs right just 1 million like the image net size",
    "start": "2118460",
    "end": "2123980"
  },
  {
    "text": "roughly and see if that improves the results the answer is yes",
    "start": "2123980",
    "end": "2129910"
  },
  {
    "text": "however one thing that's interesting is I'll just summarize this for you is",
    "start": "2129910",
    "end": "2136990"
  },
  {
    "text": "obvious is that cityscapes which is not data set which is also in Germany right",
    "start": "2137200",
    "end": "2143359"
  },
  {
    "text": "so very close to TT and is manually curated it's 80 thousand images it's",
    "start": "2143359",
    "end": "2149690"
  },
  {
    "text": "better than 1 million images from random in random Toyota images from the US and",
    "start": "2149690",
    "end": "2155900"
  },
  {
    "text": "so it's not just about quantity of data it's also about quality of data relevance and that here is we don't know",
    "start": "2155900",
    "end": "2163010"
  },
  {
    "text": "how to measure distributions in that space and there's a huge space of pixels and and and so it's still a very open",
    "start": "2163010",
    "end": "2170329"
  },
  {
    "text": "question of what data that it's not just the quantity is what data what diversity what quality what relevance to select",
    "start": "2170329",
    "end": "2177260"
  },
  {
    "text": "and an active learning doesn't work here because you are in an unsupervised setting so it improves your pose",
    "start": "2177260",
    "end": "2184490"
  },
  {
    "text": "estimation to again as I said in a structure promotion setup you need both",
    "start": "2184490",
    "end": "2189829"
  },
  {
    "text": "the depth and a go motion Network and they are trained together and so but",
    "start": "2189829",
    "end": "2195619"
  },
  {
    "text": "then then you know so far I showed like and oppose network is thrown out well you know visual odometry is somewhat",
    "start": "2195619",
    "end": "2201079"
  },
  {
    "text": "important in robotics and so here we actually went further and say ok if",
    "start": "2201079",
    "end": "2207079"
  },
  {
    "text": "we're just focusing on visual odometry at this time how good is it and so we are presenting at coral an",
    "start": "2207079",
    "end": "2213260"
  },
  {
    "text": "aural paper in Osaka in a few weeks now which is called two stream networks for self",
    "start": "2213260",
    "end": "2218800"
  },
  {
    "text": "supervising emotion estimation where we tried to bring like focus that sets this time to network architecture design for",
    "start": "2218800",
    "end": "2225339"
  },
  {
    "text": "the pose Network so this thing here right so I'll go quickly over this but",
    "start": "2225339",
    "end": "2235150"
  },
  {
    "text": "we trained them together my localization odometry I don't think to that audience",
    "start": "2235150",
    "end": "2240880"
  },
  {
    "text": "I need to justify that it's important and and and especially how to improve",
    "start": "2240880",
    "end": "2246880"
  },
  {
    "start": "2245000",
    "end": "2395000"
  },
  {
    "text": "otama tree with a visual imagery of data so that's the network architecture again",
    "start": "2246880",
    "end": "2252160"
  },
  {
    "text": "I told you before the main thing the main source of improvement before was was designing a network and a loss that",
    "start": "2252160",
    "end": "2259240"
  },
  {
    "text": "factors in structural assumption you know that whole to be true because geometry right and so here we have a two",
    "start": "2259240",
    "end": "2266740"
  },
  {
    "text": "stream network which is typically used in action recognition where you have an appearance stream and a motion stream so",
    "start": "2266740",
    "end": "2271900"
  },
  {
    "text": "for instance you use RGB and optical flow and combine them together here we're basically just saying well",
    "start": "2271900",
    "end": "2278470"
  },
  {
    "text": "actually if you know the structure of the scene and and you can basically do a geometric registration right like you",
    "start": "2278470",
    "end": "2284349"
  },
  {
    "text": "can localize you know that's why lidar czar so much more accurate for localization so let's make a two stream",
    "start": "2284349",
    "end": "2290290"
  },
  {
    "text": "network that has a structure stream that takes the depth as input and the Piron stream and and then combine them to get",
    "start": "2290290",
    "end": "2296500"
  },
  {
    "text": "a better estimate of the pose so that works that that improves again numbers",
    "start": "2296500",
    "end": "2304030"
  },
  {
    "text": "papers online you can check it out and we can talk at coral if you're there now",
    "start": "2304030",
    "end": "2309359"
  },
  {
    "text": "start from the crazy kind of like research he wealth and like literally going down into you know like getting",
    "start": "2309359",
    "end": "2315460"
  },
  {
    "text": "the hands dirty and and making this deployable because again the goal is to actually have an impact it positive",
    "start": "2315460",
    "end": "2321040"
  },
  {
    "text": "impact on the world with this and so in the real world it's still too far from",
    "start": "2321040",
    "end": "2326440"
  },
  {
    "text": "being deployable this technology and so how do we accelerate its deployment and",
    "start": "2326440",
    "end": "2331810"
  },
  {
    "text": "so as I mentioned before we do have lidar sometimes you know like either like a very fancy lidar when you when",
    "start": "2331810",
    "end": "2338380"
  },
  {
    "text": "you have a research fleet of prototype l4 fleet or in certain cars in the",
    "start": "2338380",
    "end": "2344290"
  },
  {
    "text": "future you have these four beam light ours so what if we do have some light our points sometimes can we leverage that and",
    "start": "2344290",
    "end": "2351339"
  },
  {
    "text": "that's and that's recent work again that we're presenting as an overall at coral",
    "start": "2351339",
    "end": "2356400"
  },
  {
    "text": "robust semi-supervised monocular deaf estimation we've rejected distances so",
    "start": "2356400",
    "end": "2361690"
  },
  {
    "text": "we'd love to be yourself supervised purist and just learn from raw data but in the real world if you care about actually making this you know getting to",
    "start": "2361690",
    "end": "2368470"
  },
  {
    "text": "these nine nines of reliability some I supervise is obviously the way to",
    "start": "2368470",
    "end": "2373510"
  },
  {
    "text": "go from a research standpoint you know you we have a lot of data that's and labeled some data that is labeled the",
    "start": "2373510",
    "end": "2380830"
  },
  {
    "text": "hard part is how what you do with the unlabeled data so that's why we focus on self supervise but in the real world we",
    "start": "2380830",
    "end": "2386349"
  },
  {
    "text": "have obviously some amount of supervision so how do we leverage both in an optimal way I'll I'll skip this",
    "start": "2386349",
    "end": "2394240"
  },
  {
    "text": "because in the interest of time and if we won't have time for questions at the end but one thing that that basically",
    "start": "2394240",
    "end": "2400300"
  },
  {
    "start": "2395000",
    "end": "2432000"
  },
  {
    "text": "just says is supervision from let's say regression regressing light art right",
    "start": "2400300",
    "end": "2405640"
  },
  {
    "text": "our points and self supervision which is a loss paid on pixel on color values",
    "start": "2405640",
    "end": "2411609"
  },
  {
    "text": "right the photometric loss there are very different losses so when you do multitask learning and you just say oh",
    "start": "2411609",
    "end": "2417040"
  },
  {
    "text": "let's I have a loss that compares bananas and I have a loss that compares sheeps let's sum those losses well it",
    "start": "2417040",
    "end": "2424060"
  },
  {
    "text": "doesn't work so well in practice so we have to somehow make these two losses compatible and and so here what",
    "start": "2424060",
    "end": "2433780"
  },
  {
    "start": "2432000",
    "end": "2661000"
  },
  {
    "text": "we're doing is there is this additional like piece here I can grab a pointer the",
    "start": "2433780",
    "end": "2441099"
  },
  {
    "text": "supervised loss right so like supervised networks it just don't need all the rest rights they just need like get me the",
    "start": "2441099",
    "end": "2446920"
  },
  {
    "text": "depth and I have the ground truth depth DT just how close are you from that",
    "start": "2446920",
    "end": "2452950"
  },
  {
    "text": "right so what we're doing is what we found we tried a lot of different things because we started obviously we're not",
    "start": "2452950",
    "end": "2459160"
  },
  {
    "text": "Eve and we said all right cool I get state-of-the-art supervised Network state-of-the-art self supervised Network have make them have babies and",
    "start": "2459160",
    "end": "2468190"
  },
  {
    "text": "these babies will be beautiful the first baby was not beautiful I can tell you so then we Sarah gay why and so",
    "start": "2468190",
    "end": "2476830"
  },
  {
    "text": "we came up with this approach worked the best which is self supervised pre-training",
    "start": "2476830",
    "end": "2482470"
  },
  {
    "text": "so one of the other thing is that again you have a lot of data that's unlabeled you have some data that's labeled one",
    "start": "2482470",
    "end": "2488560"
  },
  {
    "text": "traditional way to do it is like to some pre training on the unlabeled data and a little bit of fine-tuning on the labeled",
    "start": "2488560",
    "end": "2494589"
  },
  {
    "text": "data so this is basically what we've done with the little difference that we",
    "start": "2494589",
    "end": "2500170"
  },
  {
    "text": "maintain also the self supervise laughs in the second stage so you do self supervise pre-training then you do",
    "start": "2500170",
    "end": "2505270"
  },
  {
    "text": "fine-tuning with the supervised loss plus a reproject sort so a reprojected",
    "start": "2505270",
    "end": "2510760"
  },
  {
    "text": "supervised loss and the self supervised loss this reprojected loss is important",
    "start": "2510760",
    "end": "2516130"
  },
  {
    "text": "and this is basically the illustration of the rejected loss which is the main",
    "start": "2516130",
    "end": "2522640"
  },
  {
    "text": "contribution in the paper which is when you're doing this supervised loss you're comparing distances between 3d points in",
    "start": "2522640",
    "end": "2530109"
  },
  {
    "text": "Euclidean space right this is very different than the view synthesis which is comparing other 3d points but these",
    "start": "2530109",
    "end": "2537040"
  },
  {
    "text": "are RGB values right so this is completely different so one of the things we found is is that we're",
    "start": "2537040",
    "end": "2542410"
  },
  {
    "text": "basically reprojected the 3d distances onto a distance between pixels and then",
    "start": "2542410",
    "end": "2549640"
  },
  {
    "text": "we're novel izing these two losses such that it's better behaved numerically it's like mostly numerical optimization",
    "start": "2549640",
    "end": "2556079"
  },
  {
    "text": "considerations that enable this to to be better behaved at training time one of",
    "start": "2556079",
    "end": "2562329"
  },
  {
    "text": "the benefits by the way of using the supervision that I haven't mentioned is that you capture scale metric scale in",
    "start": "2562329",
    "end": "2567700"
  },
  {
    "text": "your network much faster right so it works great actually I'll show you the",
    "start": "2567700",
    "end": "2574990"
  },
  {
    "text": "video and one of the cool things that we investigated is so here what you're",
    "start": "2574990",
    "end": "2580480"
  },
  {
    "text": "seeing is you're seeing the image you're seeing the points out so this is the point cloud so if for those of you that are familiar with the Qt they use a",
    "start": "2580480",
    "end": "2586839"
  },
  {
    "text": "valid ein VLP HDL 64 which is 64 beam lidar and and they accumulate the scans",
    "start": "2586839",
    "end": "2595270"
  },
  {
    "text": "over a little bit of time to densify the point cloud right and so you're seeing these the height map the point clouds",
    "start": "2595270",
    "end": "2601420"
  },
  {
    "text": "that are red and green etc these are from the lidar and let me pause this",
    "start": "2601420",
    "end": "2608020"
  },
  {
    "text": "just a little bit right and so what we are doing is we're doing our monocular",
    "start": "2608020",
    "end": "2614230"
  },
  {
    "text": "def network takes a single image at the time and then lifts the pixels to 3d right and there you sing again this dance",
    "start": "2614230",
    "end": "2620100"
  },
  {
    "text": "reconstruction that I was showing before and we're just shot superimposing with the lidar to see that how close are we",
    "start": "2620100",
    "end": "2626820"
  },
  {
    "text": "to the lidar remember our network is metrically scaled this is metrically scaled so this is accurate like if this",
    "start": "2626820",
    "end": "2633869"
  },
  {
    "text": "like you could drive off of this don't but you could don't and so here what",
    "start": "2633869",
    "end": "2641100"
  },
  {
    "text": "you're going to see is what is the supervision you leverage so the",
    "start": "2641100",
    "end": "2646170"
  },
  {
    "text": "supervision you leverage could be the full point cloud right so if you're fully supervised you have the full point",
    "start": "2646170",
    "end": "2652170"
  },
  {
    "text": "cloud you say every pixel that sig matches that can be ray casted close enough to alight our points I'm gonna",
    "start": "2652170",
    "end": "2658619"
  },
  {
    "text": "use that supervision and now one thing is what if you have instead of sixty",
    "start": "2658619",
    "end": "2665490"
  },
  {
    "start": "2661000",
    "end": "2803000"
  },
  {
    "text": "four beams what if you have thirty two beams right we can decimate right what",
    "start": "2665490",
    "end": "2671820"
  },
  {
    "text": "if you go for the cheaper Villa dining model you'll be 32 see for instance right or you know even maybe what if you",
    "start": "2671820",
    "end": "2681570"
  },
  {
    "text": "had 16 beams like the VIP 16 which I'm pretty sure robotics folks at Stanford",
    "start": "2681570",
    "end": "2686910"
  },
  {
    "text": "have been using and all the way down to",
    "start": "2686910",
    "end": "2692840"
  },
  {
    "text": "four beams which is the Continental type like like for being lidar excedrin and",
    "start": "2692840",
    "end": "2698280"
  },
  {
    "text": "so what we found in the paper is that when you train with supervision that's degraded in a number of beams you train",
    "start": "2698280",
    "end": "2703470"
  },
  {
    "text": "with 64 beams or turn to 32 or trained with 16 or trained with 8 or training with four our models accuracy is like",
    "start": "2703470",
    "end": "2710670"
  },
  {
    "text": "degrading very slowly which means it's very robust to the decimating the lidar",
    "start": "2710670",
    "end": "2715710"
  },
  {
    "text": "or using a very cheap lighter and the",
    "start": "2715710",
    "end": "2721140"
  },
  {
    "text": "last point I will make is one additional work we've done is obviously to drive in",
    "start": "2721140",
    "end": "2728880"
  },
  {
    "text": "the world to have a robot that can interact with the world it's not just about 3d right it's not just about",
    "start": "2728880",
    "end": "2735060"
  },
  {
    "text": "understanding geometry it's about also the semantics so we do also a lot of work on semantic segmentation and object",
    "start": "2735060",
    "end": "2741600"
  },
  {
    "text": "detection and all these kind of things and obviously there's a relationship between semantics and and geometry and",
    "start": "2741600",
    "end": "2747450"
  },
  {
    "text": "otherwise our monocular definite works they would not work right imagine you take a picture of the scene and you say you can tell how far",
    "start": "2747450",
    "end": "2754880"
  },
  {
    "text": "things are the only reason I can tell like how far you are is because faces right have an equivalence relationship",
    "start": "2754880",
    "end": "2761720"
  },
  {
    "text": "between their appearance and their distance right a smaller face like you have big faces and small faces in the",
    "start": "2761720",
    "end": "2768380"
  },
  {
    "text": "world right there's all kinds of faces but you don't have a 2-meter face and a 2-centimeter face right so you can tell",
    "start": "2768380",
    "end": "2774890"
  },
  {
    "text": "from experience from not having seen all your faces before I can tell how far you are even if I take a photograph and I",
    "start": "2774890",
    "end": "2780770"
  },
  {
    "text": "was looking at the photograph right that's why I'm monocular def works so there's obviously a relationship between semantics and def otherwise it couldn't",
    "start": "2780770",
    "end": "2786950"
  },
  {
    "text": "work so how about we leverage that semantic relationship a little bit more explicitly now the caveat is and so we",
    "start": "2786950",
    "end": "2795080"
  },
  {
    "text": "have a paper under review for this not yet an archive but will soon be semantically guided representation",
    "start": "2795080",
    "end": "2800930"
  },
  {
    "text": "learning for self super eyes monocular depth and at a high level this is how it works",
    "start": "2800930",
    "end": "2806260"
  },
  {
    "start": "2803000",
    "end": "2994000"
  },
  {
    "text": "semantics has to be supervised right because the reason I see two eyes in these kind of things is because people call this a face right like I could call",
    "start": "2806260",
    "end": "2813530"
  },
  {
    "text": "it their smirk you know you all have smirks now that doesn't matter I mean in my labeling system it's like ID 77 it's",
    "start": "2813530",
    "end": "2820250"
  },
  {
    "text": "whatever so we don't want any labeling right you want to stay in the self supervised setting so let's assume you",
    "start": "2820250",
    "end": "2826340"
  },
  {
    "text": "have a semantic segmentation at work that's pre trained on some other data set right it's there so you have it as",
    "start": "2826340",
    "end": "2831530"
  },
  {
    "text": "part of your system but you don't have on the big unlabeled data set you don't have semantic supervision so you fix",
    "start": "2831530",
    "end": "2837200"
  },
  {
    "text": "that Network you learn yourself supervised deaf Network in the same way I described before but with one",
    "start": "2837200",
    "end": "2842570"
  },
  {
    "text": "additional thing one additional structure you're going to input into your system you're going to say well actually for deaf to be accurate you",
    "start": "2842570",
    "end": "2849230"
  },
  {
    "text": "have to have depth features that correlate with semantic features right",
    "start": "2849230",
    "end": "2854870"
  },
  {
    "text": "because again like the size of this chair and the size of your faces have nothing to do with each other but if I",
    "start": "2854870",
    "end": "2860450"
  },
  {
    "text": "see many chairs and many faces and I know that there are chairs and faces I can relate their distance with their appearance so we use a very recent paper",
    "start": "2860450",
    "end": "2867530"
  },
  {
    "text": "actually called pixel adaptive convolutions to basically use features that are extracted in a semantic",
    "start": "2867530",
    "end": "2873680"
  },
  {
    "text": "limitation network to guide the learning to say your geometry features right your",
    "start": "2873680",
    "end": "2880310"
  },
  {
    "text": "representations that you're going to learn they have to have some relationship right with",
    "start": "2880310",
    "end": "2886100"
  },
  {
    "text": "semantic features and we learned that relationship right and it's basically an additional guidance or regularizer",
    "start": "2886100",
    "end": "2891190"
  },
  {
    "text": "this works better well of numbers boom done but one thing is like we're right",
    "start": "2891190",
    "end": "2897320"
  },
  {
    "text": "where does it work better right so to give you the intuition I highlighted a couple of examples and basically you see",
    "start": "2897320",
    "end": "2904790"
  },
  {
    "text": "without semantic guidance on the left so in the middle column with semantic guidance on the right so here what you",
    "start": "2904790",
    "end": "2912260"
  },
  {
    "text": "see for instance is here you have this tree which is very hard to see right you",
    "start": "2912260",
    "end": "2918050"
  },
  {
    "text": "see you're like high dynamic high dynamic range big problem right and outdoors and here you see you have this",
    "start": "2918050",
    "end": "2923900"
  },
  {
    "text": "black tree and you have this shadow and you have this shaded building and so",
    "start": "2923900",
    "end": "2929240"
  },
  {
    "text": "here really hard to like from just photometric perspective right to tell that that part of the pole is actually",
    "start": "2929240",
    "end": "2936890"
  },
  {
    "text": "not part of the building but it's a pole it's not a building and so here having",
    "start": "2936890",
    "end": "2942260"
  },
  {
    "text": "the semantic guidance enables you to recover the accurate depth on this another thing same same exact problem",
    "start": "2942260",
    "end": "2948680"
  },
  {
    "text": "with the sign the traffic sign same thing here here no sign no speed limit go for it here there's this little thing",
    "start": "2948680",
    "end": "2956330"
  },
  {
    "text": "over there here very interesting case same thing kind of like almost like an imaging problem like a dynamic range",
    "start": "2956330",
    "end": "2962690"
  },
  {
    "text": "problem it's like oh here there's no pedestrian that's just coming across you you know right here no no you're fine here well just wait a second",
    "start": "2962690",
    "end": "2969860"
  },
  {
    "text": "right and again this is because there are semantic features that are like",
    "start": "2969860",
    "end": "2975110"
  },
  {
    "text": "basically designed to be learned to be invariance to a lot of photometric aspects whereas the depth needs like I need these photometric aspects because",
    "start": "2975110",
    "end": "2981440"
  },
  {
    "text": "that's how I tell the geometric relationships right the matching right same thing for like rare categories and",
    "start": "2981440",
    "end": "2989690"
  },
  {
    "text": "and and many other instances of very fine grain structures this improves",
    "start": "2989690",
    "end": "2994910"
  },
  {
    "start": "2994000",
    "end": "3021000"
  },
  {
    "text": "overall classes and once you do this you can basically start to do 3d semantics",
    "start": "2994910",
    "end": "3000030"
  },
  {
    "text": "and and combine those and so basically this is just showing the pre-trained network the learned network for depth",
    "start": "3000030",
    "end": "3006790"
  },
  {
    "text": "the point cloud you get from so the point cloud you get from this and what if you just in paints the point cloud",
    "start": "3006790",
    "end": "3011980"
  },
  {
    "text": "with the semantics right and you start to be able to have cameras let's start to look like a really good sensor for full",
    "start": "3011980",
    "end": "3018920"
  },
  {
    "text": "3d semantic understanding in the world we have an additional last stage that I",
    "start": "3018920",
    "end": "3024830"
  },
  {
    "start": "3021000",
    "end": "3917000"
  },
  {
    "text": "will mention like infinite depth and that's my last slide where basically one",
    "start": "3024830",
    "end": "3031460"
  },
  {
    "text": "of the cool things geometry wise like from a mathematical perspective like take home exercise think about it is",
    "start": "3031460",
    "end": "3038230"
  },
  {
    "text": "when you reproject right and you have a dynamic object that moves at exactly the",
    "start": "3038230",
    "end": "3043820"
  },
  {
    "text": "same speed as you move right so my hand here like always the same distance from my eyes right now there's two ways that",
    "start": "3043820",
    "end": "3051320"
  },
  {
    "text": "you can reproject this accurately from a photometric standpoint it's like the hand is moving at the same speed as I'm moving or my hand is infinitely big at",
    "start": "3051320",
    "end": "3058700"
  },
  {
    "text": "infinity all right it never gets closer right things that never get closer means that they must be",
    "start": "3058700",
    "end": "3064220"
  },
  {
    "text": "at infinity if they're infinity they must be infinitely big because they just occupied that much space from a",
    "start": "3064220",
    "end": "3069230"
  },
  {
    "text": "projective geometry standpoint this is a valid solution right this is an ambiguous solution to your photometric objective so what we see is we see these",
    "start": "3069230",
    "end": "3077120"
  },
  {
    "text": "cars that have like you know violate relativity and just can warp into",
    "start": "3077120",
    "end": "3083720"
  },
  {
    "text": "infinite space and so that car that you see here or here they are at infinite",
    "start": "3083720",
    "end": "3088940"
  },
  {
    "text": "distance because they travel you know when you're in the road when you follow a lead vehicle you're typically not like",
    "start": "3088940",
    "end": "3094250"
  },
  {
    "text": "you know unless you're a bad driver but you're typically going at the same speed so with we proposed in the paper",
    "start": "3094250",
    "end": "3100340"
  },
  {
    "text": "also a two-stage training method which is completely automatic unlabeled and we're basically suddenly seeing like oh that car that you thought was a Definity",
    "start": "3100340",
    "end": "3106700"
  },
  {
    "text": "it's actually just right in front of your nose right so to conclude we've",
    "start": "3106700",
    "end": "3112760"
  },
  {
    "text": "done a lot of work on self supervised pseudo lidar or monocular depth at gri the real reason is we want robust 3d",
    "start": "3112760",
    "end": "3120290"
  },
  {
    "text": "perception from vision robustness is a key world when you hear people say perception is solved you can ask them",
    "start": "3120290",
    "end": "3126680"
  },
  {
    "text": "sure is robust perception solved right that's really robustness is key and when",
    "start": "3126680",
    "end": "3133010"
  },
  {
    "text": "you have a robot that costs several million dollars robustness is even more key and when you have human lives and",
    "start": "3133010",
    "end": "3138860"
  },
  {
    "text": "you deploy in 10 million you get the picture so use geometry for scalable",
    "start": "3138860",
    "end": "3144140"
  },
  {
    "text": "soft supervision that's basically kind of like the key message structure structure structure if you've been that I clear the top deep learning Khan",
    "start": "3144140",
    "end": "3150200"
  },
  {
    "text": "friends before it was unsupervised no structure and now everybody is saying how do I put structure in my deep nets",
    "start": "3150200",
    "end": "3156410"
  },
  {
    "text": "right so geometry is is really the key we talked about stereo they have a super",
    "start": "3156410",
    "end": "3163490"
  },
  {
    "text": "dev and PAC net semi-supervised also again if you combine losses make sure",
    "start": "3163490",
    "end": "3169160"
  },
  {
    "text": "you're not comparing bananas and and and sheep's and one cool quote I think is",
    "start": "3169160",
    "end": "3176060"
  },
  {
    "text": "really nice it comes from a really interesting professor in in in computer",
    "start": "3176060",
    "end": "3181730"
  },
  {
    "text": "vision of you're shy process the revolution will not be supervised so when you think about robots it's kind of",
    "start": "3181730",
    "end": "3186890"
  },
  {
    "text": "scary right is that like robots are not supervised is you know like my adviser gave me this robot it's gonna crash and",
    "start": "3186890",
    "end": "3192440"
  },
  {
    "text": "like falls through the stairs and oh my god and and and when you think about deploying into a real world system like",
    "start": "3192440",
    "end": "3197720"
  },
  {
    "text": "you can imagine how we freaked out on a daily basis and so you have to really be",
    "start": "3197720",
    "end": "3203839"
  },
  {
    "text": "bold in but safe at the same time and so I think that's what really we're trying to do and and really the key here is",
    "start": "3203839",
    "end": "3212660"
  },
  {
    "text": "they're not magic right it's science it's actually a lot of geometry I bought again the old zisserman geometry book",
    "start": "3212660",
    "end": "3219530"
  },
  {
    "text": "right like go back I went back to my roots because it's a structure that you want",
    "start": "3219530",
    "end": "3224750"
  },
  {
    "text": "to leverage and in the real world the data is also mostly unlabeled right it's not unlabeled it's not labeled is mostly",
    "start": "3224750",
    "end": "3230540"
  },
  {
    "text": "unlabeled and that's the key thing all right thank you [Applause]",
    "start": "3230540",
    "end": "3242010"
  },
  {
    "text": "now we'll take a few questions all right do you had waited for a long time yes big table had self some the",
    "start": "3242010",
    "end": "3255960"
  },
  {
    "text": "point I was curious about was so you had three buildings down there at the bottom and so you also helps yep and I see here",
    "start": "3255960",
    "end": "3267340"
  },
  {
    "text": "that your resolution is about twice the dorm one you're hearing too so that's one thing and then the other thing that",
    "start": "3267340",
    "end": "3273910"
  },
  {
    "text": "I was what is the I guess CS plus key",
    "start": "3273910",
    "end": "3282790"
  },
  {
    "text": "means you're also using say escapes you trained on yeah okay really good",
    "start": "3282790",
    "end": "3291070"
  },
  {
    "text": "attention to details so a couple of things first in the paper we compared to",
    "start": "3291070",
    "end": "3296940"
  },
  {
    "text": "with the Monod f2 which is the state of the art self supervised network which is",
    "start": "3296940",
    "end": "3302050"
  },
  {
    "text": "amazing work like really really cool they they improvements from their method",
    "start": "3302050",
    "end": "3307960"
  },
  {
    "text": "which actually you can see here they do not improve with resolution so their",
    "start": "3307960",
    "end": "3315370"
  },
  {
    "text": "network works just as well with half the resolution so that's another key thing",
    "start": "3315370",
    "end": "3320890"
  },
  {
    "text": "and so what we have in the paper we show is that if you increase the resolution of the method saturate they can't deal with the details they're designed to",
    "start": "3320890",
    "end": "3327040"
  },
  {
    "text": "work at lower resolution so if they become really good they're become at what we call medium resolution that high",
    "start": "3327040",
    "end": "3332050"
  },
  {
    "text": "resolution doesn't bring them a benefit we get as good on medium resolution and then we improve with higher resolution",
    "start": "3332050",
    "end": "3338170"
  },
  {
    "text": "and then when you're supervise your resolution is limited to your lidar",
    "start": "3338170",
    "end": "3343890"
  },
  {
    "text": "right so you can't go beyond what your lidar provides in terms of resolution so",
    "start": "3343890",
    "end": "3349780"
  },
  {
    "text": "that's also an interesting limitation so yes it's an unfair advantage to be able to really leverage high resolution and",
    "start": "3349780",
    "end": "3355660"
  },
  {
    "text": "that's by design of this work absolutely yeah and CS plus K we do there's all",
    "start": "3355660",
    "end": "3360880"
  },
  {
    "text": "kinds of little bit of analysis that I brushed over you can look at in the paper any other question",
    "start": "3360880",
    "end": "3366070"
  },
  {
    "text": "yes I think you were first and you then one great question in regards to the cameras because em I don't think you've",
    "start": "3366070",
    "end": "3372100"
  },
  {
    "text": "passed the prior of the intrinsics of the cameras anywhere and so you would have to retrain the whole network and",
    "start": "3372100",
    "end": "3379650"
  },
  {
    "text": "yes we are assuming we know the interim six we are assuming that all our data is",
    "start": "3386340",
    "end": "3391780"
  },
  {
    "text": "with the same camera that's a very very very big assumption there is really that",
    "start": "3391780",
    "end": "3399250"
  },
  {
    "text": "was an assumption that's necessary to get some good results at this stage now that we get good results we're actually thinking about how to go beyond that and",
    "start": "3399250",
    "end": "3406150"
  },
  {
    "text": "one way is to is to learn a differentiable camera model where you actually have insurance ticks that are differentiable so you can learn to",
    "start": "3406150",
    "end": "3412930"
  },
  {
    "text": "predict intrinsics and there's some work that are like I think I need a needle",
    "start": "3412930",
    "end": "3419290"
  },
  {
    "text": "galava at Google was looking into being like you know really agnostic to extrinsic but in real world deployments",
    "start": "3419290",
    "end": "3425350"
  },
  {
    "text": "that scale you know the intrinsic so you have a pretty darn good calibration but it's nonetheless an interesting like you know if you think Android versus iOS iOS",
    "start": "3425350",
    "end": "3431830"
  },
  {
    "text": "you have really good calibration Android is like well you're on the answer so we had this and right so to kind of go back",
    "start": "3431830",
    "end": "3441220"
  },
  {
    "text": "to your last point on why and robustness so it seems like from what I could tell",
    "start": "3441220",
    "end": "3447220"
  },
  {
    "text": "most of these images that you're training on are like in full sunlight perfect weather conditions go how does",
    "start": "3447220",
    "end": "3454660"
  },
  {
    "text": "it how have you tested it against like you know night against bringing or lots",
    "start": "3454660",
    "end": "3461530"
  },
  {
    "text": "of reductions or super HD are related images pressure is building up for the",
    "start": "3461530",
    "end": "3466690"
  },
  {
    "text": "next questions you got to be all smarter like you know increments so yes we are",
    "start": "3466690",
    "end": "3472450"
  },
  {
    "text": "not testing for night that's outside of our safety domain right now so lidar",
    "start": "3472450",
    "end": "3477700"
  },
  {
    "text": "obviously has benefits near infrared cameras etc so visual light if you have",
    "start": "3477700",
    "end": "3483100"
  },
  {
    "text": "no light but one of the things we have tested in is rain so rain that's one of",
    "start": "3483100",
    "end": "3490300"
  },
  {
    "text": "the big pushes that actually convinces people to say let's try to make like",
    "start": "3490300",
    "end": "3496210"
  },
  {
    "text": "let's do research on the vision to really like we need it is this rain so I mentioned luminaire sensor right",
    "start": "3496210",
    "end": "3502570"
  },
  {
    "text": "1550 nanometer range the reason that it has better like range and depth perception is because at the 15 15",
    "start": "3502570",
    "end": "3509440"
  },
  {
    "text": "nanometer range you are absorbing the the laser pulse faster which is more I",
    "start": "3509440",
    "end": "3516370"
  },
  {
    "text": "say fat higher pulsing levels but if it",
    "start": "3516370",
    "end": "3521530"
  },
  {
    "text": "gets absorbed by water better then under the rain you have you know this big",
    "start": "3521530",
    "end": "3527260"
  },
  {
    "text": "problems and also in the more practical design of the robot you know like we have to tilt the lens so that you know",
    "start": "3527260",
    "end": "3534160"
  },
  {
    "text": "or have ultrasonic sand and so that you don't have raindrops because if you have raindrops have a big blind spot etc so",
    "start": "3534160",
    "end": "3539470"
  },
  {
    "text": "vision like raindrops is noise why they you can still see it's just added some",
    "start": "3539470",
    "end": "3545080"
  },
  {
    "text": "noise so what we found is that these methods are very robust to rain because if you train with rain if you collect",
    "start": "3545080",
    "end": "3551170"
  },
  {
    "text": "rain data so here doesn't happen too much but we have an office in Ann Arbor we do have rain data and Tokyo so one of",
    "start": "3551170",
    "end": "3559510"
  },
  {
    "text": "the big things actually that t-shirt is next year we're doing a big demo at the Tokyo Olympics so Toyota is number one",
    "start": "3559510",
    "end": "3565570"
  },
  {
    "text": "sponsor and we're gonna have a fleet of cars that have continues operations for like 30 days and it's typhoon season",
    "start": "3565570",
    "end": "3572140"
  },
  {
    "text": "like so the good thing about it is it doubled the motivation to get vision to",
    "start": "3572140",
    "end": "3578800"
  },
  {
    "text": "be really good fog etc so lidar also has very similar problems than this but vision because it",
    "start": "3578800",
    "end": "3586000"
  },
  {
    "text": "can be as good as your data has fails later so you should be able to between",
    "start": "3586000",
    "end": "3612610"
  },
  {
    "text": "close points of time estimate really well what the relative changes in pose",
    "start": "3612610",
    "end": "3618910"
  },
  {
    "text": "right so I'm curious if you've considered like a multi frame architecture where you're looking across",
    "start": "3618910",
    "end": "3625420"
  },
  {
    "text": "multiple frames but you're also feeding in the relative pose change yeah yeah again continuing on they're really good",
    "start": "3625420",
    "end": "3632050"
  },
  {
    "text": "questions yes absolutely yes so the real world is sensor fusion right the robotic to get robustness you know as a",
    "start": "3632050",
    "end": "3638350"
  },
  {
    "text": "Byzantine generals problem you need redundancy there's no way around it so you need multiple sensors you need",
    "start": "3638350",
    "end": "3644410"
  },
  {
    "text": "multiple systems so you need to fuse them together and now there's interesting new ways to choose things right when it's a sensor fusion you",
    "start": "3644410",
    "end": "3651520"
  },
  {
    "text": "think Talman filter so actually my boss is wolfenberg yard right so Bible of robotics Provost Icke robotics and and",
    "start": "3651520",
    "end": "3657910"
  },
  {
    "text": "so obviously there's all that literature right but that will merge with a new emerging literature which is around deep",
    "start": "3657910",
    "end": "3664360"
  },
  {
    "text": "learning so residual networks right so what if you have a really good initialization for your pose and you just learned a residual from it it's",
    "start": "3664360",
    "end": "3670660"
  },
  {
    "text": "like almost like learning a noise model oh like oh now you've made the connection with Kalman filters etc and now people are saying oh actually I can",
    "start": "3670660",
    "end": "3677530"
  },
  {
    "text": "back up through the Kalman equations oh actually I can back prop even through my particle filter so there's really this",
    "start": "3677530",
    "end": "3683620"
  },
  {
    "text": "kind of like just like geometry and deep learning like kind of like merging together we're gonna see the same",
    "start": "3683620",
    "end": "3689620"
  },
  {
    "text": "probabilistic robotics and deep learning starting to merge together and it's like new ways to do sensor fusion in a",
    "start": "3689620",
    "end": "3695680"
  },
  {
    "text": "data-driven way that's yeah so that's I'm very excited for that space but it's still like there's a lot of research to",
    "start": "3695680",
    "end": "3701350"
  },
  {
    "text": "be done if you hear also people that says it's all an engineering problem it's all an execution problem then you",
    "start": "3701350",
    "end": "3707140"
  },
  {
    "text": "know they're working for a different thing they're working on something that is a robo taxi in an area that in a fully HD map and I can always HTML",
    "start": "3707140",
    "end": "3713800"
  },
  {
    "text": "that's that's one problem if you're looking for a robot with autonomous in the open world",
    "start": "3713800",
    "end": "3718810"
  },
  {
    "text": "you need to think about those things really like and then do research on yes",
    "start": "3718810",
    "end": "3737320"
  },
  {
    "text": "yep again you pass the quality of question tests are good yes this is a",
    "start": "3737320",
    "end": "3742690"
  },
  {
    "text": "very good question Universal representation versus mixture of experts that's like do you want to",
    "start": "3742690",
    "end": "3751570"
  },
  {
    "text": "took your model do you want so for instance what I think we did very recently I can tell you about this traffic lights so traffic lights is an",
    "start": "3751570",
    "end": "3757180"
  },
  {
    "text": "area where you can't fail right like some Robo taxi company not like some",
    "start": "3757180",
    "end": "3762760"
  },
  {
    "text": "company that's doing taxi that wants to become Robo taxi first deployment to San Francisco within the hour burn a red",
    "start": "3762760",
    "end": "3769210"
  },
  {
    "text": "light right you've all seen the YouTube video it's it's so it's really hard like you",
    "start": "3769210",
    "end": "3774710"
  },
  {
    "text": "want to be like it in their defense it's really hard you have to be really really really robust so now really robots in",
    "start": "3774710",
    "end": "3782240"
  },
  {
    "text": "the u.s. awesome go to Tokyo wait all the traffic lights are like this",
    "start": "3782240",
    "end": "3787310"
  },
  {
    "text": "wait traffic lights are like two rows wait traffic lights have states that are",
    "start": "3787310",
    "end": "3793630"
  },
  {
    "text": "conflicting according to the US traffic lights so you can have something that tells you literally you can go no wait",
    "start": "3793630",
    "end": "3800660"
  },
  {
    "text": "you can and you're like wait what like and so really and so and then you're like oh let's use structure and let's",
    "start": "3800660",
    "end": "3806420"
  },
  {
    "text": "use a state machine and oh we can actually learn that state machine and oh let's learn transitions etc you go to",
    "start": "3806420",
    "end": "3812090"
  },
  {
    "text": "Tokyo you take that garbage can right so so how much do you specialize versus how",
    "start": "3812090",
    "end": "3820190"
  },
  {
    "text": "much do you say III tabula rasa I assume nothing I would just learn it from data which is gonna make you very slow and",
    "start": "3820190",
    "end": "3826160"
  },
  {
    "text": "and very risky very active research and again it has to be on a case-by-case basis but one thing that's I believe on",
    "start": "3826160",
    "end": "3832910"
  },
  {
    "text": "the general note on this is that representation learning right a car is a",
    "start": "3832910",
    "end": "3837920"
  },
  {
    "text": "car certain things are looked the same or are the same certain behaviors are shared because we're all humans right",
    "start": "3837920",
    "end": "3844550"
  },
  {
    "text": "and and gravity is there and you know all these kind of things so there is a",
    "start": "3844550",
    "end": "3849770"
  },
  {
    "text": "common bottleneck there's a really cool paper by Stefano so a toll on a separation principle for control and the",
    "start": "3849770",
    "end": "3855350"
  },
  {
    "text": "age of deep learning which is like on the information theoretic side of things which which is this notion of information bottleneck and you want to",
    "start": "3855350",
    "end": "3862190"
  },
  {
    "text": "have a state that is a summary state of what is common across the world for your",
    "start": "3862190",
    "end": "3868460"
  },
  {
    "text": "particular task and then you want to have a specialization right everybody is doing multitask learning right so like a",
    "start": "3868460",
    "end": "3873770"
  },
  {
    "text": "provision you see as a common backbone and multiple heads the key question is",
    "start": "3873770",
    "end": "3878810"
  },
  {
    "text": "what is shareable what is a good state that is shareable and then depending on that if you share a lot you can have a",
    "start": "3878810",
    "end": "3885380"
  },
  {
    "text": "single multitask model if you share very little you can have separate models and in between you can have some form of",
    "start": "3885380",
    "end": "3890450"
  },
  {
    "text": "mixture of experts that can be geo local AG or localized or you can switch which branch you're going through and you kept",
    "start": "3890450",
    "end": "3897440"
  },
  {
    "text": "the conditional architecture says like oh here take the Tokyo branch eccentric strong so this is this is",
    "start": "3897440",
    "end": "3903510"
  },
  {
    "text": "open and on the case-by-case basis the very hard question",
    "start": "3903510",
    "end": "3907940"
  },
  {
    "text": "[Applause]",
    "start": "3909890",
    "end": "3914239"
  }
]
[
  {
    "start": "0",
    "end": "10820"
  },
  {
    "text": "It's really nice to be here. I'm doing something a little\nbit different for today's talk. So, nominally, I would pick a\nresearch thread through my lab",
    "start": "10820",
    "end": "19320"
  },
  {
    "text": "and share a little\nbit about that. I'm doing something a\nlittle bit different today, because I'm taking-- I don't know-- 20, 30 steps back\nfrom all the work that we've",
    "start": "19320",
    "end": "27919"
  },
  {
    "text": "been doing in the\npast seven plus years and turning this a\nlittle bit into here",
    "start": "27920",
    "end": "34880"
  },
  {
    "text": "is what I've come to see as\nmy perspective on interaction. So it's a very high-level talk. We won't really look at--",
    "start": "34880",
    "end": "41570"
  },
  {
    "text": "we won't really get a\nchance to dive into details, but I wanted to share with you\nhow I think about the problem",
    "start": "41570",
    "end": "48200"
  },
  {
    "text": "formulation itself. What problem are we trying\nto solve when we talk about interaction with humans?",
    "start": "48200",
    "end": "53750"
  },
  {
    "text": "And what aspects of these\nproblem are important?",
    "start": "53750",
    "end": "58850"
  },
  {
    "text": "What should solutions look like? And how should that inform the\nalgorithms that we're building?",
    "start": "58850",
    "end": "65120"
  },
  {
    "text": "And so taking a step\nback, I'm immersed in this world of robotics. I have friends who start\nrobotics companies.",
    "start": "65120",
    "end": "72270"
  },
  {
    "text": "I have-- not as many robots\nas you guys have at Stanford-- but I have one or two robots\nin my lab like this arm",
    "start": "72270",
    "end": "79830"
  },
  {
    "text": "here that I like a lot. I spend one day a week with an\nautonomous driving company here",
    "start": "79830",
    "end": "87792"
  },
  {
    "text": "in Silicon Valley called Waymo. Part of the Alphabet ecosystem. Today, I won't talk\nabout Waymo work.",
    "start": "87792",
    "end": "95100"
  },
  {
    "text": "So I wanted to make\nthat very clear. I'm really just wearing\nmy UC Berkeley hat.",
    "start": "95100",
    "end": "101220"
  },
  {
    "text": "But what I can share\nis that there's--",
    "start": "101220",
    "end": "110670"
  },
  {
    "text": "I experience these\nrobots day-to-day. So here I am\ndriving, checking one",
    "start": "110670",
    "end": "116790"
  },
  {
    "text": "of the first rider-only\nrides in San Francisco. And it's really cool.",
    "start": "116790",
    "end": "122439"
  },
  {
    "text": "It's nice to be\nexperiencing robots that make decision after\ndecision in the correct way.",
    "start": "122440",
    "end": "131150"
  },
  {
    "text": "And so it's an\nexciting place to be. So I'm surrounded by\nrobots in everything I do.",
    "start": "131150",
    "end": "138702"
  },
  {
    "text": "And you'll see even more of that\nin some examples that I'll give. How did I get into robotics? Well, I got into robotics--",
    "start": "138702",
    "end": "144890"
  },
  {
    "text": "I was in 12th grade about\nto go to university. And I came across Stuart\nRussell and Peter Norvig's book.",
    "start": "144890",
    "end": "154490"
  },
  {
    "text": "And I read it as much as I\ncould understand as a 12 grader. What did I know? But I got some\nthings out of this.",
    "start": "154490",
    "end": "162260"
  },
  {
    "text": "And what really resonated\nwith me back then, was this concept of the\nway the book was talking",
    "start": "162260",
    "end": "169670"
  },
  {
    "text": "about an intelligent agent. What's an intelligent agent? It's this agent that\nfigures out what to do.",
    "start": "169670",
    "end": "175410"
  },
  {
    "text": "You give it a goal. And it figures out how to\nsequences decisions to achieve",
    "start": "175410",
    "end": "180470"
  },
  {
    "text": "that goal on its own. And that concept right\nthere was the thing that really drew me in.",
    "start": "180470",
    "end": "186470"
  },
  {
    "text": "It was so fascinating\nthat you could do this. So I've learned that\nthe way robots work just",
    "start": "186470",
    "end": "193940"
  },
  {
    "text": "to establish some\ncommon terminology is they take actions that change\nthe state of the world.",
    "start": "193940",
    "end": "199760"
  },
  {
    "text": "They have sensors that\ntell them about what is there in the world.",
    "start": "199760",
    "end": "204890"
  },
  {
    "text": "And then you give them some\nobjective, a reward function, cost function, goal,\nwhatever you want to call it.",
    "start": "204890",
    "end": "212180"
  },
  {
    "text": "And they figure out how to\ngo about and achieve it, a sequence of actions, a\npolicy that achieves it.",
    "start": "212180",
    "end": "219140"
  },
  {
    "text": "And we call this many things. I'm going to refer to it\nas optimal decision-making in this talk.",
    "start": "219140",
    "end": "224660"
  },
  {
    "text": "Optimal control on\nthe control side. And what's cool about optimal\ndecision-making, I think,",
    "start": "224660",
    "end": "231260"
  },
  {
    "text": "is that it enables\nrobots to figure out their own strategies\nfor interacting",
    "start": "231260",
    "end": "238040"
  },
  {
    "text": "with the physical world. What do I mean by strategies? And that's going to be a bit--",
    "start": "238040",
    "end": "243170"
  },
  {
    "text": "we're going to use this word\nagain and again and again in the talk. What do I mean by strategies? Well, this example, when\nI teach Intro to AI,",
    "start": "243170",
    "end": "250640"
  },
  {
    "text": "I give this example. I think it's somewhat\nillustrative. So here's a cute toy\nexample robot in a maze.",
    "start": "250640",
    "end": "256140"
  },
  {
    "text": "There's a gem here. It gets plus 1, if\nit cashes in on that. If it falls into the fire\npit, negative 1, game ends.",
    "start": "256140",
    "end": "264180"
  },
  {
    "text": "It can go up, down, left, right. And there's a\nlittle bit of noise. So if it tries to go\nup with 80% chance,",
    "start": "264180",
    "end": "269730"
  },
  {
    "text": "it ends up, actually,\nin the next cell. Unless, there's a wall, in\nwhich case, it stays in place.",
    "start": "269730",
    "end": "274860"
  },
  {
    "text": "But there's a 10% chance of like\nwheels slipping a little bit. And it ends up either on\nthe left or on the right.",
    "start": "274860",
    "end": "281760"
  },
  {
    "text": "So that's a task. And you can solve it through\noptimal decision-making.",
    "start": "281760",
    "end": "287949"
  },
  {
    "text": "In this case, value iteration. You know everything\nabout the world. And this is what the\nsolution looks like.",
    "start": "287950",
    "end": "293860"
  },
  {
    "text": "And so some things\nmake a lot of sense. If you start here, you make\nyour way towards the gem,",
    "start": "293860",
    "end": "301410"
  },
  {
    "text": "if you start here, you go\nthis way, around rather than",
    "start": "301410",
    "end": "306670"
  },
  {
    "text": "that way. Why is that?  Minus 1-- because of the mine,\nbecause of the risk of minus 1.",
    "start": "306670",
    "end": "313640"
  },
  {
    "text": "If you were to pass by the\nfire pit, that would be bad. And it's really cool\nwhat happens here.",
    "start": "313640",
    "end": "318740"
  },
  {
    "text": "The robot doesn't go up. It goes left. Where does it go left?",
    "start": "318740",
    "end": "324594"
  },
  {
    "text": "Zero [INAUDIBLE]. Yeah. Right.",
    "start": "324594",
    "end": "330030"
  },
  {
    "text": "If it went up, there'd be this\n10% chance of ending up here. And then it would get negative\n1 and the game would end.",
    "start": "330030",
    "end": "335340"
  },
  {
    "text": "And so what it does is it of\nbangs its head against the wall or presses against the wall.",
    "start": "335340",
    "end": "341250"
  },
  {
    "text": "And leans on it so that there-- and it keeps doing that. And there's always a\n10% chance that it's",
    "start": "341250",
    "end": "347700"
  },
  {
    "text": "up to the left or the right. Now, I bet that we could\nwrite this down, if we all",
    "start": "347700",
    "end": "352889"
  },
  {
    "text": "sat and thought about it. But I looked at this. And I was like, that's cool.",
    "start": "352890",
    "end": "358110"
  },
  {
    "text": "And that's what I\nmean by a strategy. This notion of bang your\nhead against the wall,",
    "start": "358110",
    "end": "364050"
  },
  {
    "text": "instead of the\nobvious thing to do, to avoid falling into\nthis fire pit, which is this cute little strategy\nthat optimal decision-making",
    "start": "364050",
    "end": "371220"
  },
  {
    "text": "just gives you.  I have now a kid.",
    "start": "371220",
    "end": "378120"
  },
  {
    "text": "His name is Lucas. He's one. And he is coming up with\nthis strategy as well.",
    "start": "378120",
    "end": "384120"
  },
  {
    "text": "He's learning to walk. And he can't really walk. He falls a lot. And so what he\nstarted doing before,",
    "start": "384120",
    "end": "391030"
  },
  {
    "text": "actually, being\nable to fully walk is he discovered that he can\njust like lean against the wall",
    "start": "391030",
    "end": "396789"
  },
  {
    "text": "and make progress that way. And he's also really cute.",
    "start": "396790",
    "end": "402940"
  },
  {
    "text": "I think there's something\nreally beautiful here. And as we'll see in a bit\nalso practical about really",
    "start": "402940",
    "end": "408790"
  },
  {
    "text": "not having to specify\nto the robot what to do, what actions to take, how\nto behave, and to just give it",
    "start": "408790",
    "end": "417550"
  },
  {
    "text": "an objective or a\nreward function, and for it to automatically\nfigure out that in order to be robust,\nhow do you do that?",
    "start": "417550",
    "end": "423717"
  },
  {
    "text": "You press against the wall\nor something like that.  And if I change the\nproblem a little bit,",
    "start": "423717",
    "end": "432650"
  },
  {
    "text": "like, if I change where this\nwall is, or, in this case, if I make it-- this corresponds to the every\nstep costs a little bit.",
    "start": "432650",
    "end": "441620"
  },
  {
    "text": "If I make it a little\nbit more costly per action, all of a sudden,\nit's not really worth it. You take the risk,\nbecause it's not",
    "start": "441620",
    "end": "448610"
  },
  {
    "text": "worth it to wait until\nthe forward action or the left action resolves\ninto that left or right motion.",
    "start": "448610",
    "end": "458110"
  },
  {
    "text": "So you get this notion\nof generalization. As you tweak the\nproblem setting, there's something else\nthat's optimal to do.",
    "start": "458110",
    "end": "464420"
  },
  {
    "text": "And the robot can\nfigure that out. ",
    "start": "464420",
    "end": "470850"
  },
  {
    "text": "This was an\nillustrative example. Now, let me give\nyou a research one. So it was back in 2010.",
    "start": "470850",
    "end": "476479"
  },
  {
    "text": "I was in grad school at CMU. And Rob Platt gave\nthis talk on exactly the beautiful emerging strategy\nthat was so fascinating to me.",
    "start": "476480",
    "end": "488060"
  },
  {
    "text": "So this is the\nlight dark domain. The robot starts at a start. There's a goal.",
    "start": "488060",
    "end": "493100"
  },
  {
    "text": "But it's dark. It doesn't know\nexactly where it is. And its sensors work better\nin the light than in the dark.",
    "start": "493100",
    "end": "500420"
  },
  {
    "text": "And so if it tries to\ngo towards the goal, it might not get to it\nwith enough accuracy,",
    "start": "500420",
    "end": "506900"
  },
  {
    "text": "because it doesn't\nexactly know where it is. And uncertainty also\naccumulates over time.",
    "start": "506900",
    "end": "512219"
  },
  {
    "text": "And so what Rob\nwas talking about is this the underlying\n[? POMDB ?] formulation",
    "start": "512220",
    "end": "517639"
  },
  {
    "text": "and ways to approximate it. The solution to that what\nhe showed was emerging",
    "start": "517640",
    "end": "523309"
  },
  {
    "text": "was this behavior, where\nthe robot makes its way into the light in order to\ncollapse its uncertainty",
    "start": "523309",
    "end": "529590"
  },
  {
    "text": "and gather enough information\nabout its location, just enough so that it\ncan then go and make it",
    "start": "529590",
    "end": "535529"
  },
  {
    "text": "with enough certainty\nto the goal. And so, again, you do\noptimal decision-making.",
    "start": "535530",
    "end": "542190"
  },
  {
    "text": "You figure out things\nthat you should be moving towards the lights. So away from your goal. Moving towards the\nlight to make sure",
    "start": "542190",
    "end": "548820"
  },
  {
    "text": "you can actually do\nthe task properly, how to move towards the\nlight, how much, and so on.",
    "start": "548820",
    "end": "554820"
  },
  {
    "text": "It's all these details\nare figured out. Good.",
    "start": "554820",
    "end": "559860"
  },
  {
    "text": "So I'll greatly,\ngreatly simplify here. But I think, essentially, the\nmessage is you take a robot.",
    "start": "559860",
    "end": "568200"
  },
  {
    "text": "You tell it the basics\nof how the world works some version of F equals ma. Some version of how the\nphysical world behaves.",
    "start": "568200",
    "end": "575760"
  },
  {
    "text": "And all of a sudden, it does\nmagical things on its own.",
    "start": "575760",
    "end": "580950"
  },
  {
    "text": "And this is a\nvideo from Stanford from Zico's work of just\neven superhuman performance",
    "start": "580950",
    "end": "590190"
  },
  {
    "text": "being attained through\noptimal-decision making. But while these\ntechniques could enable",
    "start": "590190",
    "end": "596780"
  },
  {
    "text": "these robots to go off and\ndo these magical things, I was also disappointed\nin grad school",
    "start": "596780",
    "end": "602720"
  },
  {
    "text": "that they were\nnowhere near enough. They're far from being\nenough, because, if you look at all these pictures\nof robots out in the wild",
    "start": "602720",
    "end": "611870"
  },
  {
    "text": "doing their thing,\nthere's something missing. And of, course, the\ntitle of my talk will give you a hint,\nas to what is missing.",
    "start": "611870",
    "end": "619010"
  },
  {
    "text": "What's missing is the people. When will a car go around? And there's this beautifully\nempty road with no one inside.",
    "start": "619010",
    "end": "626870"
  },
  {
    "text": "No, the world for\nan autonomous car looks more like\nthis, where you have to, actually, interact with\nall these different agents,",
    "start": "626870",
    "end": "633268"
  },
  {
    "text": "make predictions about\nwhere they're going, what's going on with them, and\nmake sure you coordinate well with them, as opposed\nto just stay on the road",
    "start": "633268",
    "end": "642530"
  },
  {
    "text": "and drive forward.  One of my favorite\nrobots is Wall-E.",
    "start": "642530",
    "end": "649279"
  },
  {
    "text": "And even Wall-E I would say\nit's not enough for robots",
    "start": "649280",
    "end": "656190"
  },
  {
    "text": "to work once we\nkilled off the planet and moved away to space,\nif you haven't seen Wall-E,",
    "start": "656190",
    "end": "661560"
  },
  {
    "text": "please go watch it. It's such a good movie. It's not just for kids. It's a great Pixar movie\nfor adults as well.",
    "start": "661560",
    "end": "666735"
  },
  {
    "text": " It's not enough to, actually,\nmake robots work once humans",
    "start": "666735",
    "end": "674450"
  },
  {
    "text": "have left the planet, or to\nmake robots work only on Mars.",
    "start": "674450",
    "end": "679490"
  },
  {
    "text": "They're around. The quadrotors can\nescape humans, either. So we use them to\ntake videos of us as we're skiing, snowboarding,\nrunning, and so on.",
    "start": "679490",
    "end": "687140"
  },
  {
    "text": "That's what Adam does at Skydio. In my case, getting married. So Adam lent us one of these.",
    "start": "687140",
    "end": "693230"
  },
  {
    "text": "And here I am getting married. This is my husband, Chris. This is my family.",
    "start": "693230",
    "end": "698240"
  },
  {
    "text": "And we had this drone that was\nnavigating around, figuring out where the people are, taking\npictures of us, and so on.",
    "start": "698240",
    "end": "703580"
  },
  {
    "text": "It was very noisy, though. Very noisy. So we had to pause the\nceremony for this thing to--",
    "start": "703580",
    "end": "708920"
  },
  {
    "text": "anyway, work in progress. Even Wall-E made itself\nsuper useful to me",
    "start": "708920",
    "end": "714170"
  },
  {
    "text": "before we killed off the planet. So Chris built this\nand actuated it.",
    "start": "714170",
    "end": "720290"
  },
  {
    "text": "And it rolled in on new year's\neve one night and one year. And it popped up this\nLego box that opened up.",
    "start": "720290",
    "end": "728665"
  },
  {
    "text": "And there was an\nengagement ring. And that was his proposal. So I'd like to say\nthat the bar is--",
    "start": "728665",
    "end": "735019"
  },
  {
    "text": "it's very high now for\nproposing marriage. ",
    "start": "735020",
    "end": "740766"
  },
  {
    "text": "Robots have to deal with people. People are everywhere. And after a couple of\nyears in grad school of working on optimization\nfor robot manipulation,",
    "start": "740767",
    "end": "748610"
  },
  {
    "text": "working on these\nrobotics problems, it really started\nto bug me that we have these great optimal\ndecision-making tools for robots",
    "start": "748610",
    "end": "756769"
  },
  {
    "text": "that act in isolation. But it seemed like the moment\nthere was also a person around,",
    "start": "756770",
    "end": "762410"
  },
  {
    "text": "even in the same\nspace as the robot. Someone in this diagram\nwalking and wanting",
    "start": "762410",
    "end": "769700"
  },
  {
    "text": "a coffee refill or\nsomething like that. It's as if none of\nthat worked anymore.",
    "start": "769700",
    "end": "775010"
  },
  {
    "text": "All of these tools are gone. We couldn't really use\nany of that machinery. And we were back to\nthings like telling",
    "start": "775010",
    "end": "783350"
  },
  {
    "text": "the robot what actions\nto take, or telling the robot what strategy to use. And I have many\nexamples of this.",
    "start": "783350",
    "end": "789320"
  },
  {
    "text": "But I think one that\nconnects to later on in the talk and the work\nthat Dorsa ended up doing was--",
    "start": "789320",
    "end": "796200"
  },
  {
    "text": "in 2010, I was reading these\npapers, Rob Platt, Light-dark",
    "start": "796200",
    "end": "801800"
  },
  {
    "text": "Domain, magical things happening\nwith optimal decision-making.",
    "start": "801800",
    "end": "807140"
  },
  {
    "text": "I was at CMU. Google just started their\nautonomous driving project. And this article-- a bunch of\nmy friends went to work there.",
    "start": "807140",
    "end": "815329"
  },
  {
    "text": "This article comes out. And it's describing this\nfunny situation, where",
    "start": "815330",
    "end": "820850"
  },
  {
    "text": "they were testing the car. And it gets stuck\nat a four-way stop, because, essentially,\nit pulls over.",
    "start": "820850",
    "end": "830329"
  },
  {
    "text": "It comes to a stop. There's a person there. The person inches\nforward as people do.",
    "start": "830330",
    "end": "836690"
  },
  {
    "text": "The car predicts\nthe person will go. It waits for them to go. By the time it gets it together\nto start driving again,",
    "start": "836690",
    "end": "842779"
  },
  {
    "text": "there's another person\nwho had inched forward into the intersection. The car predicts that\nit was about to go.",
    "start": "842780",
    "end": "849792"
  },
  {
    "text": "It lets the person go,\nand so on, and so forth, until the test driver\ntook over control it.",
    "start": "849792",
    "end": "854930"
  },
  {
    "text": "This thing made it. I think it's in\nThe New York Times. I'm not sure. So later, I talked\nto Sebastian Thrun.",
    "start": "854930",
    "end": "862790"
  },
  {
    "text": "And he tells me, well,\nwhat did they have to do? They had to program in\nthis inching forward",
    "start": "862790",
    "end": "868460"
  },
  {
    "text": "behavior for the car as well. This was like\nhumans inch forward into these intersections. The cars should just go there,\ncome to a complete stop.",
    "start": "868460",
    "end": "875312"
  },
  {
    "text": "It should assert its turn also\nwhen it's a turn inch forward into the intersection.",
    "start": "875312",
    "end": "882290"
  },
  {
    "text": "And so there was a\nhuman programmer, who had to figure out what\nstrategy the car should",
    "start": "882290",
    "end": "888209"
  },
  {
    "text": "be using. Where was all this\ncrazy machinery that gave us beautiful\nstrategies that enable robots",
    "start": "888210",
    "end": "894540"
  },
  {
    "text": "to figure out what to do? There was none of that. We had to go back and say, here.",
    "start": "894540",
    "end": "901590"
  },
  {
    "text": "In this situation,\ninching forward is the appropriate thing to do. Here's how you inch\nforward and so on. And that's really frustrating.",
    "start": "901590",
    "end": "909570"
  },
  {
    "text": "And it's not just because\nyou have to come up",
    "start": "909570",
    "end": "916170"
  },
  {
    "text": "with these strategies. Maybe that would be fine. Maybe that would be\na way to build robots",
    "start": "916170",
    "end": "921300"
  },
  {
    "text": "that interact with people. But, unfortunately,\nat some point, it really becomes\nunscalable for robots",
    "start": "921300",
    "end": "927960"
  },
  {
    "text": "to operate by designers sitting\ndown and figuring out what their strategies should be.",
    "start": "927960",
    "end": "933180"
  },
  {
    "text": "A few years later,\nanother article about Waymo talks about how the\ncar gets stuck taking an exit,",
    "start": "933180",
    "end": "943260"
  },
  {
    "text": "because it was\ntrying to merge on. And there was heavy traffic. And there was not a big\nenough gap in traffic.",
    "start": "943260",
    "end": "950730"
  },
  {
    "text": "And so the car couldn't\nactually make its lane change and ending up continuing\non to the exit.",
    "start": "950730",
    "end": "956670"
  },
  {
    "text": "So a similar thing\nlike, the four-way stop at some high level. But inching forward\ndoesn't solve it.",
    "start": "956670",
    "end": "963795"
  },
  {
    "text": "You have to come up with\na different strategy and adapt it now to well,\nhow should that work?",
    "start": "963795",
    "end": "970170"
  },
  {
    "text": "It depends on how\nmuch traffic there is. When do I do it? When do I not, and\nso on, and so forth? And then there's\nall other problems",
    "start": "970170",
    "end": "976750"
  },
  {
    "text": "that even look\nqualitatively different. I like to show this example\nof imagine that I am--",
    "start": "976750",
    "end": "985690"
  },
  {
    "text": "I have this robot. We're unloading the dishwasher\nor something like that. And it's carrying this cup.",
    "start": "985690",
    "end": "991089"
  },
  {
    "text": "And it's going to go\nand set it on the table. But I look at it. And I'm thinking, well, you're\nsure holding this very high",
    "start": "991090",
    "end": "997420"
  },
  {
    "text": "up from the ground. So I get a little bit concerned,\nbecause if it drops it, it will break. That's not the right\nway to carry this.",
    "start": "997420",
    "end": "1004080"
  },
  {
    "text": "What I might do, I\nmight say something. But I might also just\npush on the robot and correct what it's doing.",
    "start": "1004080",
    "end": "1011190"
  },
  {
    "text": "You got to stay\ncloser to the table. Now, a robot that does optimal\ndecision-making, what does it",
    "start": "1011190",
    "end": "1021329"
  },
  {
    "text": "do upon having this external\ntorque applied to it? Well, the moment I let go,\nit's, like, well, let me go back",
    "start": "1021330",
    "end": "1029052"
  },
  {
    "text": "to doing the task\nin what I thought was the optimal way,\nwhich was clearly to have a nice clearance\nfrom the table. So I kept pushing.",
    "start": "1029052",
    "end": "1034140"
  },
  {
    "text": "It keeps going back. And I keep pushing. And it keeps going back,\nand so on, and so forth. So we call this\nphysical interaction.",
    "start": "1034140",
    "end": "1040410"
  },
  {
    "text": "And, clearly, this, too, we\nneeded some strategy for. This is not what\nthe robot is doing. It's not the correct thing.",
    "start": "1040410",
    "end": "1045510"
  },
  {
    "text": "And so as designers,\nwe can sit down. We can think of,\nwell, what would be the appropriate response? People have actually\nthought about this.",
    "start": "1045510",
    "end": "1051630"
  },
  {
    "text": "They talked about\nrendering an impedance. They talked about moving in\nthe direction of the force. They talked about rejecting\nthe force as a disturbance.",
    "start": "1051630",
    "end": "1059190"
  },
  {
    "text": "They talked about entering\nsome gravity compensation mode and letting the person\nguide you towards the end,",
    "start": "1059190",
    "end": "1064320"
  },
  {
    "text": "and so on, and so forth. There's many ways\nto go about it. Unclear which these strategies\nwould be the right way",
    "start": "1064320",
    "end": "1070049"
  },
  {
    "text": "to go for this problem,\nif any of them. And so that's a long\nwinded way of saying,",
    "start": "1070050",
    "end": "1078080"
  },
  {
    "text": "is there an alternative? What would it take for\nrobots to, actually, figure out the right strategies\nfor interaction with humans?",
    "start": "1078080",
    "end": "1084098"
  },
  {
    "text": "In the same way,\nthey're figuring out the right strategies\nfor interacting with the physical world,\nwhich is something that we've",
    "start": "1084098",
    "end": "1089240"
  },
  {
    "text": "made a lot of progress in. Optimal decision-making\nenables the robots to figure out what to do\nwith the physical world.",
    "start": "1089240",
    "end": "1095630"
  },
  {
    "text": "How do we make it\nalso enable robots to figure out the\nright strategies",
    "start": "1095630",
    "end": "1100790"
  },
  {
    "text": "for dealing with people? So I became really\nfascinated by this problem, where, for instance,\ninstead of having",
    "start": "1100790",
    "end": "1107090"
  },
  {
    "text": "to say, hey, robot,\nin this situation, you should inch forward. I sure like to say, do\nyour job, just like you",
    "start": "1107090",
    "end": "1113570"
  },
  {
    "text": "do your job in isolation. But now, also do it in\ncoordination with this human, who is in the intersection.",
    "start": "1113570",
    "end": "1119630"
  },
  {
    "text": "Figure it out. And have the robot\nmake sure that it does the right negotiation,\ncoordination with the person.",
    "start": "1119630",
    "end": "1128408"
  },
  {
    "text": "How would we do that? And I spent really my\nresearch career, so far, exploring this type of question.",
    "start": "1128408",
    "end": "1134260"
  },
  {
    "text": "Exploring how to go from\nthis robot in isolation model to, actually, something\nwhere the human is part",
    "start": "1134260",
    "end": "1140350"
  },
  {
    "text": "of this formulation, where the\nhuman becomes part of the state",
    "start": "1140350",
    "end": "1146140"
  },
  {
    "text": "that we're considering, when\nwe do optimal decision-making. How do I make the human--",
    "start": "1146140",
    "end": "1151570"
  },
  {
    "text": "how do I put the human\nformally in there, so that when I do\noptimal decision-making, the robot can\nactually figure out",
    "start": "1151570",
    "end": "1158050"
  },
  {
    "text": "how to do these things in\ncoordination with people? ",
    "start": "1158050",
    "end": "1163350"
  },
  {
    "text": "And what's tough about this is\nthat, with the physical world,",
    "start": "1163350",
    "end": "1171130"
  },
  {
    "text": "we can get these things done,\nbecause we understand something about how the\nphysical world works.",
    "start": "1171130",
    "end": "1177879"
  },
  {
    "text": "We understand the dynamics\nof the physical state. We know the laws of physics.",
    "start": "1177880",
    "end": "1183130"
  },
  {
    "text": "And so that, either we can\nwrite those things down. We can parametrize them.",
    "start": "1183130",
    "end": "1188500"
  },
  {
    "text": "Or, at the very least,\nit influences the kind of data-driven models we use.",
    "start": "1188500",
    "end": "1194630"
  },
  {
    "text": "For interaction, what do you do? What's the equivalent\nof F equals ma?",
    "start": "1194630",
    "end": "1201059"
  },
  {
    "text": "In theory, there's neuroscience\nthat tells you what",
    "start": "1201060",
    "end": "1206480"
  },
  {
    "text": "laws govern the human brain. But we're nowhere\nnear, actually, understanding\nreally any of that.",
    "start": "1206480",
    "end": "1212180"
  },
  {
    "text": "So I write down equations like,\nF equals ma for the brain.",
    "start": "1212180",
    "end": "1217760"
  },
  {
    "text": "But that's what\nwe're talking about, when it talks about, well, now,\nthe human is part of your state. So what do we do?",
    "start": "1217760",
    "end": "1223070"
  },
  {
    "text": "Is there an F equals\nma for interaction? ",
    "start": "1223070",
    "end": "1229760"
  },
  {
    "text": "And how do we get there? And I think the answer is, yes.",
    "start": "1229760",
    "end": "1236360"
  },
  {
    "text": "I think, I've come to this\nconclusion that roughly, if we formulate this optimal\ndecision-making problem,",
    "start": "1236360",
    "end": "1245000"
  },
  {
    "text": "as what is called a partially\nobservable general sum game-- which is something that I'll\nspend the rest of the talk going",
    "start": "1245000",
    "end": "1252080"
  },
  {
    "text": "through-- it turned out that,\nat least, in my view,",
    "start": "1252080",
    "end": "1257270"
  },
  {
    "text": "if we acknowledge\nthat the human is also an agent that doesn't act\narbitrarily, but takes action,",
    "start": "1257270",
    "end": "1265940"
  },
  {
    "text": "that have something to do with\nsome objective that they have, just like the robot takes action\naccording to its objective,",
    "start": "1265940",
    "end": "1275060"
  },
  {
    "text": "that we capture this interplay\nbetween human actions and robot actions.",
    "start": "1275060",
    "end": "1281460"
  },
  {
    "text": "That this really gives us not\neverything about interaction.",
    "start": "1281460",
    "end": "1287419"
  },
  {
    "text": "But that F equals\nma like structure that we need that we can\nuse to build upon when we",
    "start": "1287420",
    "end": "1293600"
  },
  {
    "text": "develop interaction algorithms. So that doesn't mean that\npeople are rational game playing agents.",
    "start": "1293600",
    "end": "1298910"
  },
  {
    "text": "That's not true. Far from it. But I think much like F equals\nma captures some of what's",
    "start": "1298910",
    "end": "1306770"
  },
  {
    "text": "going on, but not all. This too is more like\ngiving us the underlying",
    "start": "1306770",
    "end": "1311960"
  },
  {
    "text": "structure of how we should\nthink about interaction. And so what I figured I'd\ndo for the rest of today",
    "start": "1311960",
    "end": "1317690"
  },
  {
    "text": "is going to go through\nwhat all these arrows and words, actually, mean\nand what implications",
    "start": "1317690",
    "end": "1323390"
  },
  {
    "text": "they have for the way we've\nbeen thinking about interaction problems, and what strategies\nfor interactions have emerged,",
    "start": "1323390",
    "end": "1332120"
  },
  {
    "text": "when we've been able to\nformulate interaction this way. And so first, we'll notice\nthat I call it a game.",
    "start": "1332120",
    "end": "1339140"
  },
  {
    "text": "So what's a game? A game is this\nmathematical construct. I don't want you to think\nof something like chess,",
    "start": "1339140",
    "end": "1344809"
  },
  {
    "text": "when I say game. I more want you to think\nabout the game of chicken. Who knows the game of chicken?",
    "start": "1344810",
    "end": "1351160"
  },
  {
    "text": "A few people do. Roughly, you have two\ncars going at each other. And they get some\npayoff, depending",
    "start": "1351160",
    "end": "1358870"
  },
  {
    "text": "on what each other does. So if they both swerve and\navoid each other, that's OK.",
    "start": "1358870",
    "end": "1364960"
  },
  {
    "text": "That's 0-0. Nothing happened. No one won, but no one lost. If they both go straight\nand keep going straight,",
    "start": "1364960",
    "end": "1372850"
  },
  {
    "text": "they run into each other. And that's really\nbad for both of them. So that's negative\n1,000, negative 1,000. And one goes straight,\nand the one dodges, then",
    "start": "1372850",
    "end": "1383049"
  },
  {
    "text": "the one who goes straight\nwins in this game of chicken. So they each have a\nutility or payoff,",
    "start": "1383050",
    "end": "1389830"
  },
  {
    "text": "which depends on not\njust what they do, but what the other player\nends up doing as well.",
    "start": "1389830",
    "end": "1395050"
  },
  {
    "text": "You might have heard of\nthe prisoner's dilemma, similar concept there.",
    "start": "1395050",
    "end": "1400240"
  },
  {
    "text": "What did these have to do with\nhumans and robots coexisting? Well, let's go back\nto this coordination",
    "start": "1400240",
    "end": "1407380"
  },
  {
    "text": "at the four-way stop. So what's going on here is that\nI have the human and robot.",
    "start": "1407380",
    "end": "1415000"
  },
  {
    "text": "They each have a goal. And it's a complex goal. And that they both want to\ngo through first, ideally.",
    "start": "1415000",
    "end": "1422080"
  },
  {
    "text": "They both value\ntheir own efficiency. But they also both want to avoid\ncollisions with each other.",
    "start": "1422080",
    "end": "1427600"
  },
  {
    "text": "No one wants to get into\na wreck on the road. So much like in this chicken\ngame that we were talking about,",
    "start": "1427600",
    "end": "1434980"
  },
  {
    "text": "each of their utilities\ndepends on what the other does. I can't just look at the\nrobot, and say, how good",
    "start": "1434980",
    "end": "1440890"
  },
  {
    "text": "is an action for the robot. It really depends on\nwhat the human also decides to do at the same time.",
    "start": "1440890",
    "end": "1446800"
  },
  {
    "text": "And the combination\nof the human action and the robot action and that\ndictating the outcome of this.",
    "start": "1446800",
    "end": "1454750"
  },
  {
    "text": "That means that what\none does ends up influencing what the\nother does and vice-versa.",
    "start": "1454750",
    "end": "1462240"
  },
  {
    "text": "And I think that's what this\ngame formulation enables us to capture.",
    "start": "1462240",
    "end": "1467760"
  },
  {
    "text": "Each agent takes actions in\nservice of their own objective. And that results in this\ninfluence back and forth",
    "start": "1467760",
    "end": "1475247"
  },
  {
    "text": "between the human and the robot. Now, you might wonder,\nin theory, this is true. In practice, do we\nreally play chicken",
    "start": "1475247",
    "end": "1482070"
  },
  {
    "text": "with each other on the road? Is that what we want? Come on.",
    "start": "1482070",
    "end": "1487110"
  },
  {
    "text": "And it turns out the answer\nis, in small ways, yes. In small ways, more often\nthan you might think,",
    "start": "1487110",
    "end": "1492960"
  },
  {
    "text": "you exercise your game\ntheoretical muscles, as you're driving on the road. And here's an example.",
    "start": "1492960",
    "end": "1499080"
  },
  {
    "text": "And this is from Dorsa's work. So here, I have a car. And I have a\nhuman-driven vehicle.",
    "start": "1499080",
    "end": "1506580"
  },
  {
    "text": "And if I don't think about\nany game aspect, what I'll do is I'll make a prediction\nabout this dynamic obstacle",
    "start": "1506580",
    "end": "1512490"
  },
  {
    "text": "as moving forward. And I'll say, I need to not\ncollide with this human.",
    "start": "1512490",
    "end": "1518550"
  },
  {
    "text": "Good thing. I also need to get myself\ninto the left lane. But I have to do that without\ncolliding with the person.",
    "start": "1518550",
    "end": "1525430"
  },
  {
    "text": "And so I need to brake. Let the person go. And then try to go after them.",
    "start": "1525430",
    "end": "1532750"
  },
  {
    "text": "Unless, there's\nanother car coming. In which case, I'll\nwait for that person to go to and, so\non, and so forth.",
    "start": "1532750",
    "end": "1540400"
  },
  {
    "text": "So that's one option. Or I can keep going so that\nI don't slow down and annoy the person behind.",
    "start": "1540400",
    "end": "1546279"
  },
  {
    "text": "But then I will\nmix my left turn. So I'll have to reroute. So those are the two options.",
    "start": "1546280",
    "end": "1554080"
  },
  {
    "text": "As humans, I think\nmost of you do not",
    "start": "1554080",
    "end": "1559750"
  },
  {
    "text": "accept that those\nare your two options. As humans, you invent\na third option,",
    "start": "1559750",
    "end": "1565659"
  },
  {
    "text": "which is to nudge\nyourself in there and expect the person behind\nto slow down and create",
    "start": "1565660",
    "end": "1572860"
  },
  {
    "text": "that gap in traffic\nthat wasn't there. And that's what I mean by\nyour exercising your game",
    "start": "1572860",
    "end": "1577899"
  },
  {
    "text": "theoretical muscles, because\nin order for you to know that that's a thing\nthat you can do,",
    "start": "1577900",
    "end": "1583270"
  },
  {
    "text": "you have to reason\nabout this person as taking actions that\ndepend on the actions",
    "start": "1583270",
    "end": "1589750"
  },
  {
    "text": "that you take as well. And that coupling,\nthat mutual influence between your action\nand their action",
    "start": "1589750",
    "end": "1595840"
  },
  {
    "text": "is what a game\ntheoretic formulation enables us to capture. And so much like in the\nfour-way stop scenario,",
    "start": "1595840",
    "end": "1603940"
  },
  {
    "text": "the human has a goal. The human wants to go first. But the human wants to\navoid collisions too, which means their\nutility depends",
    "start": "1603940",
    "end": "1609550"
  },
  {
    "text": "on what are the\nrobot does, which means that what the robot does\ninfluences what the human does.",
    "start": "1609550",
    "end": "1615230"
  },
  {
    "text": "And once you do this, Dorsa\nis really the first person to enable game theoretic\napproximation that",
    "start": "1615230",
    "end": "1625630"
  },
  {
    "text": "captures this mutual\ninfluence, then you end up with this behavior,\nwhere the car figures out, yeah,",
    "start": "1625630",
    "end": "1632780"
  },
  {
    "text": "I can go in front\nand expect the person to slow down a little bit. And not only do you\nget that strategy,",
    "start": "1632780",
    "end": "1639440"
  },
  {
    "text": "but you also get\nthe generalization where, of course, if the\ncar starts way in front, it does something\nslightly different.",
    "start": "1639440",
    "end": "1645679"
  },
  {
    "text": "If the car starts way in\nthe back of the person, it doesn't try to go for it. It doesn't accelerate and\nget in front of the person,",
    "start": "1645680",
    "end": "1651538"
  },
  {
    "text": "because that'd be stupid. Then it brakes and goes behind. And now, I want to\nshare with you--",
    "start": "1651538",
    "end": "1658309"
  },
  {
    "text": "I think this is still, to this\nday, my favorite strategy that came out of any kind of\ninteraction that we've studied.",
    "start": "1658310",
    "end": "1666620"
  },
  {
    "text": "And this was said\nour assess paper that I wanted to get drinks\nafter writing with Dorsa.",
    "start": "1666620",
    "end": "1674720"
  },
  {
    "text": "And I remember\nthis very vividly,",
    "start": "1674720",
    "end": "1680179"
  },
  {
    "text": "because it's, of course,\ndown to the wire. And we're still looking\nat results and so on. And Dorsa comes to my office.",
    "start": "1680180",
    "end": "1689230"
  },
  {
    "text": "And she says, OK, I did this\nthing that we agreed to. And it makes sense in this\nsituation and that situation.",
    "start": "1689230",
    "end": "1696652"
  },
  {
    "text": "But there's this\nreally weird thing happening with the\nfour-way stop scenario that we were looking at. So let me share with you\nwhat the weird thing that was",
    "start": "1696652",
    "end": "1704380"
  },
  {
    "text": "happening. So what we did here is we put\nthe car at a four-way stop",
    "start": "1704380",
    "end": "1714430"
  },
  {
    "text": "with a human. This was in a simulation. And we changed the reward\nfunction for the autonomous car.",
    "start": "1714430",
    "end": "1724780"
  },
  {
    "text": "Its utility was no longer\nget through the intersection as quickly as possible,\ndon't collide.",
    "start": "1724780",
    "end": "1730659"
  },
  {
    "text": "Now, we had this very courteous\nautonomous car that wanted to--",
    "start": "1730660",
    "end": "1736210"
  },
  {
    "text": "it was incentivized for how\nquickly the human was getting through the intersection.",
    "start": "1736210",
    "end": "1742820"
  },
  {
    "text": "So you can imagine that in a\nworld where autonomous cars are riding empty, and they\ndon't have to be in a hurry, and so on, they might actually\nwant to be nice to the people",
    "start": "1742820",
    "end": "1749460"
  },
  {
    "text": "around, as opposed to compete\nwith the people around. And so this was a very\ncourteous autonomous car.",
    "start": "1749460",
    "end": "1754830"
  },
  {
    "text": "And so imagine you this car. What would you do if your job\nwas to do something that--",
    "start": "1754830",
    "end": "1763980"
  },
  {
    "text": "and you get brownie\npoints, really, for not how much\nyou managed to make,",
    "start": "1763980",
    "end": "1770730"
  },
  {
    "text": "but this person who\nstopped at the same time as you, how quickly they managed\nto get through the intersection?",
    "start": "1770730",
    "end": "1778218"
  },
  {
    "text": "Any thoughts?  People, sometimes, they\nflash their lights.",
    "start": "1778218",
    "end": "1785705"
  },
  {
    "text": "Reverse. The car can do the motion. OK. Reverse. Yeah.",
    "start": "1785705",
    "end": "1790730"
  },
  {
    "text": " There's the hand gesture stuff.",
    "start": "1790730",
    "end": "1796253"
  },
  {
    "text": "Lights-- but lights can\nbe a confusing signal, because whenever people\nflash their lights on me, I don't know if they're\nyelling at me to stop",
    "start": "1796253",
    "end": "1803690"
  },
  {
    "text": "or they're telling me to go. Anyway, Dorsa came to my office\nand said, the car is backing up.",
    "start": "1803690",
    "end": "1812750"
  },
  {
    "text": "[LAUGHS] ",
    "start": "1812750",
    "end": "1818270"
  },
  {
    "text": "She was ambivalent about this. And I was like, oh, my god. That is so cool. I cannot believe that\nthis is happening.",
    "start": "1818270",
    "end": "1826640"
  },
  {
    "text": "If you probe at it,\nit's not something that I've seen humans do. But, basically, in this\ngame theoretic model,",
    "start": "1826640",
    "end": "1833570"
  },
  {
    "text": "the car models the person\nas wanting to go first, but also wanting to\navoid collisions. If you're removing yourself\nas a collision threat,",
    "start": "1833570",
    "end": "1841010"
  },
  {
    "text": "then it makes sense\nthat they would go. So under this model,\nit makes sense.",
    "start": "1841010",
    "end": "1846559"
  },
  {
    "text": "It's a cute little strategy\nthat the car came up with that is not what I\nwould have thought about. ",
    "start": "1846560",
    "end": "1853930"
  },
  {
    "text": "And then we ran a user study. And I kid you not, people went\nfaster through the intersection.",
    "start": "1853930",
    "end": "1859760"
  },
  {
    "text": "So this is a user study with\npeople driving in the simulator. And what's really\ncool is that there",
    "start": "1859760",
    "end": "1867200"
  },
  {
    "text": "are papers in human\nrobot interaction being written about this\nso-called backoff strategy.",
    "start": "1867200",
    "end": "1873270"
  },
  {
    "text": "So people haven't proposed this\nfor cars, just to be clear. But we have found\npapers, where people",
    "start": "1873270",
    "end": "1879420"
  },
  {
    "text": "propose this thing for robots\nthat navigate around people.",
    "start": "1879420",
    "end": "1887080"
  },
  {
    "text": "So imagine that\nwe're walking there. And the robot and I\nadd this bottleneck,",
    "start": "1887080",
    "end": "1892650"
  },
  {
    "text": "which is the door at\nabout the same time. HRI designers have proposed\nthat what the robot should do,",
    "start": "1892650",
    "end": "1898200"
  },
  {
    "text": "at that point, is to drive\nbackwards a little bit and let the person go through.",
    "start": "1898200",
    "end": "1903750"
  },
  {
    "text": "And this is called\nthe backup strategy. And people have evaluated in\nthe context of navigation. And here it was as really\njust a natural consequence,",
    "start": "1903750",
    "end": "1913110"
  },
  {
    "text": "an emergent property\nof enabling the robot to understand that there's\nthis mutual influence",
    "start": "1913110",
    "end": "1919289"
  },
  {
    "text": "between the robot's actions\nand the humans actions. Once we gave it that, we gave\nit this objective of being",
    "start": "1919290",
    "end": "1924930"
  },
  {
    "text": "nice to people, all\nof a sudden, this is something that actually\nthe robot figured out.",
    "start": "1924930",
    "end": "1931450"
  },
  {
    "text": "And so that's what the\ngame aspect enables. And that's why I think\nit's important to think of interaction in this\ngame theoretic lens.",
    "start": "1931450",
    "end": "1938515"
  },
  {
    "text": " It gives you this\nmutual influence. Now, although, we do some work\non solving the actual game,",
    "start": "1938515",
    "end": "1948049"
  },
  {
    "text": "I think, the bigger\nlesson for me is not so much that you\nliterally formulate a game,",
    "start": "1948050",
    "end": "1954320"
  },
  {
    "text": "as you literally solve\nit with approximations to the game theoretic solution.",
    "start": "1954320",
    "end": "1959390"
  },
  {
    "text": "But rather, think about any kind\nof algorithm-learning approach",
    "start": "1959390",
    "end": "1969960"
  },
  {
    "text": "that you're developing for\ninteraction through the lens of, can it support this\ntype of solution?",
    "start": "1969960",
    "end": "1975640"
  },
  {
    "text": "So, for instance, one\ninteresting aspect of understanding this\ngame theoretic influence",
    "start": "1975640",
    "end": "1983279"
  },
  {
    "text": "is going back to this example. Think about an approach\nfor interaction,",
    "start": "1983280",
    "end": "1989400"
  },
  {
    "text": "where you collect\na bunch of data. And then you do\nbehavior cloning. You do imitation learning. So you get your car to drive\nin the way that humans drive.",
    "start": "1989400",
    "end": "1997500"
  },
  {
    "text": "Well, humans don't do this. So you won't get this kind\nof coordination strategy,",
    "start": "1997500",
    "end": "2002960"
  },
  {
    "text": "because you've never\nseen the human do that. Now, think about a different\ninteraction strategy,",
    "start": "2002960",
    "end": "2008450"
  },
  {
    "text": "where you learn a\nmodel of human behavior based on human driving data.",
    "start": "2008450",
    "end": "2015560"
  },
  {
    "text": "And it's just this black box\nmodel that is fit to prior data",
    "start": "2015560",
    "end": "2022260"
  },
  {
    "text": "And then your robot plans\nwith that model of the human. Well, to get to this as\nthe optimal solution,",
    "start": "2022260",
    "end": "2030090"
  },
  {
    "text": "you have to query that\nmodel of the human under the hypothetical,\nlike, hey, what would the human do if I\nstart backing up?",
    "start": "2030090",
    "end": "2036960"
  },
  {
    "text": "Which is not something that\nyou've seen in the data. This is presumably, it'll be\nan out-of-distribution query",
    "start": "2036960",
    "end": "2043410"
  },
  {
    "text": "to this model that\nyou've learned. And so I think, if\nyou know ahead of time",
    "start": "2043410",
    "end": "2048449"
  },
  {
    "text": "that you should\nexpect influence, and you should expect that\nwhenever the robot tries",
    "start": "2048449",
    "end": "2054658"
  },
  {
    "text": "to solve its planning problem\nor its reinforcement learning problem, it will try to\nleverage that human model",
    "start": "2054659",
    "end": "2063330"
  },
  {
    "text": "and query it in ways that\nwould inputs that go outside of the distribution\nthat you've collected,",
    "start": "2063330",
    "end": "2069746"
  },
  {
    "text": "then you'll be in trouble. And you won't necessarily\nfind the optimal solution. So that's one aspect\nthat, I think,",
    "start": "2069747",
    "end": "2075449"
  },
  {
    "text": "it's guided us in thinking, how\ndo we make models that are-- can be actually robust\nto these queries",
    "start": "2075449",
    "end": "2081540"
  },
  {
    "text": "that the RL agent\nwill need to make? How do I build human models\nthat aren't just this black box,",
    "start": "2081540",
    "end": "2087989"
  },
  {
    "text": "but have some robustness\nguarantees, or, at least, empirical robustness properties?",
    "start": "2087989",
    "end": "2094560"
  },
  {
    "text": "And so, again, it\ndoesn't mean that you have to think of interaction\nas this is the game. We shall solve the game.",
    "start": "2094560",
    "end": "2100444"
  },
  {
    "text": "But I think it\ndoes mean that you have to embrace the fact\nthat you should expect this mutual influence\nto happen and look",
    "start": "2100445",
    "end": "2106680"
  },
  {
    "text": "at how your solutions\nmight be able to support or fail to support\nthe type of behaviors",
    "start": "2106680",
    "end": "2114900"
  },
  {
    "text": "that look at influence. And so we haven't--",
    "start": "2114900",
    "end": "2120690"
  },
  {
    "text": "this is something that we've\nbeen recently working on. But to give you an\nexample of that,",
    "start": "2120690",
    "end": "2126990"
  },
  {
    "text": "I work a lot with Sergey Levine. He's very into offline\nreinforcement learning. So one thing that we're looking\nat with our joint student",
    "start": "2126990",
    "end": "2136770"
  },
  {
    "text": "Joey Hong is what kind of data\ndoes an offline RL agent need",
    "start": "2136770",
    "end": "2142920"
  },
  {
    "text": "to see in order to\nproduce behaviors that look like influencing behaviors\nthat go outside of what you've",
    "start": "2142920",
    "end": "2150329"
  },
  {
    "text": "seen in any kind of human-human\ndata set that you've collected? Is that possible? Under what properties\ndoes that happen?",
    "start": "2150330",
    "end": "2156360"
  },
  {
    "text": "And so, for instance, this is\na benchmark called overcooked that I like a lot. You have two agents. And they need to play\nthis game together,",
    "start": "2156360",
    "end": "2165000"
  },
  {
    "text": "where they're making soup. And there's tomatoes. And there's onions. And there's plates. And they have to deliver it\nto these delivery locations.",
    "start": "2165000",
    "end": "2172380"
  },
  {
    "text": "And they have to coordinate\nwith each other on that. I cheat with this benchmark,\nbecause it helps us, actually,",
    "start": "2172380",
    "end": "2178470"
  },
  {
    "text": "study the things that I'm\nreally interested in, which is the coordination between\nthe human and the robot",
    "start": "2178470",
    "end": "2183810"
  },
  {
    "text": "without actually having\nto have a physical human and a physical robot\ncooking onion soup together, which adds many\nlayers of complexity",
    "start": "2183810",
    "end": "2190740"
  },
  {
    "text": "on top of the core of\nwhat I'm interested in. And so cute little benchmark. And I want to share two\nvideos from Joey's work",
    "start": "2190740",
    "end": "2198390"
  },
  {
    "text": "from a few weeks ago. In this one, so this is\ngoing to be the offline RL",
    "start": "2198390",
    "end": "2207660"
  },
  {
    "text": "agent here deployed against\nthe real human player. And what we do is we collect\nsome human-human data",
    "start": "2207660",
    "end": "2216680"
  },
  {
    "text": "of people playing various\nvariations on this task. And then we give the\nrobot a new objective.",
    "start": "2216680",
    "end": "2223200"
  },
  {
    "text": "And these objectives look like,\nall of a sudden, in the game, you get a lot more\npoints, if the human is",
    "start": "2223200",
    "end": "2228720"
  },
  {
    "text": "the one doing the delivery. All of a sudden, you\nget a lot more points, if you make tomato soups\ninstead of onion soups.",
    "start": "2228720",
    "end": "2235800"
  },
  {
    "text": "And so the robot\nhas to find ways to steer the person\ntowards the solutions that",
    "start": "2235800",
    "end": "2240869"
  },
  {
    "text": "end up being higher points. And in this little video,\nwhat happens is the robot just",
    "start": "2240870",
    "end": "2248640"
  },
  {
    "text": "puts a plate here. And that ends up influencing\nthe person to pick up the plate.",
    "start": "2248640",
    "end": "2254573"
  },
  {
    "text": "And I'll play this again. ",
    "start": "2254573",
    "end": "2259610"
  },
  {
    "text": "The person focused on\nputting ingredients in. But then they had\ngrabbed this onion.",
    "start": "2259610",
    "end": "2265359"
  },
  {
    "text": "They were waiting to put in. And then the robot\nputs a plate there. And all of a sudden, what\nthe human does is, like, OK,",
    "start": "2265360",
    "end": "2271270"
  },
  {
    "text": "I'll get rid of the onion\nand go and pick up the plate. And pick up the soup.",
    "start": "2271270",
    "end": "2276505"
  },
  {
    "text": "That's not a behavior that we\nsee in the human-human data. But what we see in the\nhuman data is pieces of it.",
    "start": "2276505",
    "end": "2283540"
  },
  {
    "text": "If there's a plate on the\ntable and some particular types of situations, then the human is\nmore likely to pick up the plate",
    "start": "2283540",
    "end": "2288805"
  },
  {
    "text": "and do the soup, if the\nplate is conveniently set for them, stuff like that. No human has ever\nput a plate there",
    "start": "2288805",
    "end": "2295089"
  },
  {
    "text": "to get the other human\nto do this in the data. But there's like\naspects of this. And we're seeing how far we\ncan push offline RL to stitch",
    "start": "2295090",
    "end": "2303100"
  },
  {
    "text": "together these behaviors. Here's another one,\nwhere it's really useful to make tomato soup\nrather than onion soup.",
    "start": "2303100",
    "end": "2310270"
  },
  {
    "text": "And so what the agent does\nis-- it's much more subtle than the previous one--",
    "start": "2310270",
    "end": "2315670"
  },
  {
    "text": "goes in there and blocks\naccess to the onions. And so the person's like, yeah,\nOK, I'll focus on the tomatoes.",
    "start": "2315670",
    "end": "2322250"
  },
  {
    "text": "Fine. And then they do that. Anyway, so that's what I wanted\nto say about the game aspect.",
    "start": "2322250",
    "end": "2328188"
  },
  {
    "text": "Let me go real, real quick\nthrough this partially observable aspect, because\nthat's also important. It's not just about capturing\nthis mutual influence.",
    "start": "2328188",
    "end": "2335600"
  },
  {
    "text": "It's also about realizing\nthat the players don't have full information\nabout each other.",
    "start": "2335600",
    "end": "2340850"
  },
  {
    "text": "And so one aspect here is we\ntalk about the human objective and the human taking actions.",
    "start": "2340850",
    "end": "2346530"
  },
  {
    "text": " And maybe, the human is going\ntowards the pot of coffee,",
    "start": "2346530",
    "end": "2354920"
  },
  {
    "text": "because, in their mind, they\nwould like to get some coffee. The robot doesn't\nnecessarily know this.",
    "start": "2354920",
    "end": "2360350"
  },
  {
    "text": "So it's not a general-sum game,\nwhere the objectives are well known to each other.",
    "start": "2360350",
    "end": "2365570"
  },
  {
    "text": "There might be\npartial information. Same in a driving situation. We said, OK, human\nhas this objective",
    "start": "2365570",
    "end": "2372319"
  },
  {
    "text": "going first, but wanting\nto avoid collisions. But I don't really\nknow how the person thinks about risk and safety\nversus wanting to be efficient.",
    "start": "2372320",
    "end": "2380705"
  },
  {
    "text": "And maybe every person\ndoes it that trade-off in a different way. ",
    "start": "2380705",
    "end": "2388099"
  },
  {
    "text": "That's just someone\ntailgating, which happens. Some people really\nhave a skewed trade-off",
    "start": "2388100",
    "end": "2395700"
  },
  {
    "text": "of safety versus efficiency. ",
    "start": "2395700",
    "end": "2401350"
  },
  {
    "text": "What's interesting about\nacknowledging that you actually don't know something about\nthe human's internal state,",
    "start": "2401350",
    "end": "2406780"
  },
  {
    "text": "their objectives,\ntheir preferences, their beliefs, and so on,\nis that all of a sudden, you're going to\nthink about what you",
    "start": "2406780",
    "end": "2413590"
  },
  {
    "text": "do observe, which is\nthe human actions, as your sensor readings. The equivalent of these sensor\nreadings in the physical world.",
    "start": "2413590",
    "end": "2421180"
  },
  {
    "text": "These are your\nsensor readings, now, that give you\ninformation about what's going on with this\nhuman objective",
    "start": "2421180",
    "end": "2427060"
  },
  {
    "text": "that you need to know about. And so, for instance,\nin this task,",
    "start": "2427060",
    "end": "2432369"
  },
  {
    "text": "when I push on the\narm, what it should do, if it's operating in this\npartial observer system,",
    "start": "2432370",
    "end": "2439510"
  },
  {
    "text": "is it should try to interpret\nthat external torque as being",
    "start": "2439510",
    "end": "2445450"
  },
  {
    "text": "a sensor reading about\nwhat I have in mind, and realize that, OK, this\nis actually consistent",
    "start": "2445450",
    "end": "2455470"
  },
  {
    "text": "with you probably having\na preference of me, not keeping these crazy\nmargins, distances",
    "start": "2455470",
    "end": "2461059"
  },
  {
    "text": "from the floor and the table,\nand so on, and adjusting its behavior in response.",
    "start": "2461060",
    "end": "2469920"
  },
  {
    "text": "And here's a\ngeneralization of that to-- speaking of generalization, so I\nthink that's the right strategy.",
    "start": "2469920",
    "end": "2476351"
  },
  {
    "text": "It's not rendering impedance. It's not going gravity\ncompensation mode. It's actually just\nadjust the way",
    "start": "2476352",
    "end": "2483270"
  },
  {
    "text": "you're doing the task to better\nreflect what the person probably had in mind, when they\ndecided to start intervening",
    "start": "2483270",
    "end": "2490920"
  },
  {
    "text": "and physically pushing on you. And this is with a cup, where\nthe robot was about to spill.",
    "start": "2490920",
    "end": "2499410"
  },
  {
    "text": "And the person reorients the\nrobot instead of spilling again, and spilling again,\nand spilling again,",
    "start": "2499410",
    "end": "2504850"
  },
  {
    "text": "the robot interprets\nthat external torque as being evidence that is\nconsistent with the person",
    "start": "2504850",
    "end": "2512609"
  },
  {
    "text": "preferring to keep\nthe cup level. Let's see. We're at 14.",
    "start": "2512610",
    "end": "2518160"
  },
  {
    "text": "So I'm going to skip something. Give me one second.",
    "start": "2518160",
    "end": "2523269"
  },
  {
    "text": "The way this all started\nfor me was not in driving. It was, actually,\nin manipulation.",
    "start": "2523270",
    "end": "2529030"
  },
  {
    "text": "And it was about the\nopposite direction.",
    "start": "2529030",
    "end": "2537220"
  },
  {
    "text": "So much like the robot doesn't\nknow what the person wants,",
    "start": "2537220",
    "end": "2543862"
  },
  {
    "text": "the person also\ndoesn't necessarily know what the heck\nthe robot wants. So that's how I got\nhooked into this area.",
    "start": "2543862",
    "end": "2550660"
  },
  {
    "text": "So I'll be remiss to give\nthis talk without paying some tribute to that. So here is the robot that I\nwas working on in grad school.",
    "start": "2550660",
    "end": "2556869"
  },
  {
    "text": "His name is Herb. And here, Herb is going to\npick one of these two bottles.",
    "start": "2556870",
    "end": "2563650"
  },
  {
    "text": "Notice that they're fused\nbottles, because vision sucked back then. It still does.",
    "start": "2563650",
    "end": "2568930"
  },
  {
    "text": "But it's a lot better. So back then, there was no\ndeep learning to deal with. And so we had these fused balls,\nbecause they had sift features.",
    "start": "2568930",
    "end": "2577133"
  },
  {
    "text": "And sift features\nwere the features that were used as input to\nthese object detectors",
    "start": "2577133",
    "end": "2583400"
  },
  {
    "text": "and pose estimators. So there's two fuse bottles. Herb is going to go\nand grab one of them.",
    "start": "2583400",
    "end": "2589340"
  },
  {
    "text": "You want to grab the other one. So now, figure out which\none Herb is grabbing.",
    "start": "2589340",
    "end": "2594590"
  },
  {
    "start": "2594590",
    "end": "2601724"
  },
  {
    "text": "[LAUGHING] When we ran this\nstudy, it was 50/50.",
    "start": "2601724",
    "end": "2607029"
  },
  {
    "text": "It turns out to be\nthis one over here. It might as well have\nbeen the other one. ",
    "start": "2607030",
    "end": "2613760"
  },
  {
    "text": "And so what's going on\nhere is that the robot is behaving in an efficient way. It slowed down this motion to\nbe able to run this experiment.",
    "start": "2613760",
    "end": "2621590"
  },
  {
    "text": "But it's taking a path very\nclose to the straight line. And its configuration\nspace is very efficient.",
    "start": "2621590",
    "end": "2627590"
  },
  {
    "text": "It's the right thing\nto do, if you're just operating in isolation. But it's not quite the right\nthing to do in this little game",
    "start": "2627590",
    "end": "2634320"
  },
  {
    "text": "that we were playing,\nwhen you were actually coordinating with a person. And so partial observability\nis this two-sided coin,",
    "start": "2634320",
    "end": "2640850"
  },
  {
    "text": "where, yeah, you don't\nknow about the human. And the human actions end\nup being sensor readings for you, the robot.",
    "start": "2640850",
    "end": "2646730"
  },
  {
    "text": "But it's the other\nway around as well. The human doesn't know what\nthe heck is up with this robot.",
    "start": "2646730",
    "end": "2652310"
  },
  {
    "text": "And the robot's\nactions end up being sensor readings for the person. And if you acknowledge that,\nthen what happens is you",
    "start": "2652310",
    "end": "2660560"
  },
  {
    "text": "get to figure out\nwhat actions to take, where if it's in your\nbest interest to do so,",
    "start": "2660560",
    "end": "2665839"
  },
  {
    "text": "you become informative\nwith the actions that you're taking\nto the person.",
    "start": "2665840",
    "end": "2671119"
  },
  {
    "text": "So that they can more\nquickly understand what it is that your objective is. And that's what we did\nwith something called",
    "start": "2671120",
    "end": "2677610"
  },
  {
    "text": "legible motion, which\nbecame my thesis work, where we were running this\noptimization over the robot's actions.",
    "start": "2677610",
    "end": "2682860"
  },
  {
    "text": "And you're seeing\nthat you start off with a straight line\nin configuration space towards the goal on\nthe right, which as we saw,",
    "start": "2682860",
    "end": "2688470"
  },
  {
    "text": "was pretty confusing. And as the robot is figuring\nout what actions will update",
    "start": "2688470",
    "end": "2693539"
  },
  {
    "text": "the person's belief\nthe best, it's ending up taking this motion\nthat exaggerates to the right.",
    "start": "2693540",
    "end": "2701070"
  },
  {
    "text": "And that ends up\nconveying to the person. Look, it's this object on\nthe right that I'm grabbing,",
    "start": "2701070",
    "end": "2707040"
  },
  {
    "text": "not the one on the left. And, again, exaggeration is\none of the 12 Disney principles of animation.",
    "start": "2707040",
    "end": "2712320"
  },
  {
    "text": "People-- it's not\nsurprising that you could use these\nprinciples-- anticipation,",
    "start": "2712320",
    "end": "2717720"
  },
  {
    "text": "exaggeration, et cetera-- to\nmake robots more clear, more expressive in their\nbehavior, because Pixar",
    "start": "2717720",
    "end": "2723540"
  },
  {
    "text": "does that with their\ncharacters all the time. But what was really\ncool is this was",
    "start": "2723540",
    "end": "2729240"
  },
  {
    "text": "a consequence of optimal\ndecision-making in the system where you acknowledge,\nyou embrace the partial observability\nthat the human has.",
    "start": "2729240",
    "end": "2738090"
  },
  {
    "text": "And this is the trajectory. I'm going to skip the\ngeneralization part.",
    "start": "2738090",
    "end": "2744190"
  },
  {
    "text": "You can do this\nwith driving styles. So you can pick\ndriving styles that are more informative or less\ninformative about the robot's",
    "start": "2744190",
    "end": "2751780"
  },
  {
    "text": "objective and its trade-offs\nbetween how efficient you want to be and how,\nsay, if you want to be.",
    "start": "2751780",
    "end": "2760600"
  },
  {
    "text": "This does not fall out of\noptimal decision-making as beautifully and crisply\nas I've said so far.",
    "start": "2760600",
    "end": "2768819"
  },
  {
    "text": "But I wanted to include\nthis example too, because this is the\nclosest I've come to actual Pixar-like characters.",
    "start": "2768820",
    "end": "2774130"
  },
  {
    "text": "So here's what this is. This is a robot Cassie\nfrom [INAUDIBLE] lab. And what we did\nhere was we wanted",
    "start": "2774130",
    "end": "2785410"
  },
  {
    "text": "to get Cassie to move\nin a way that is not expressive of its goal, but\nit's expressive of some emotion",
    "start": "2785410",
    "end": "2791920"
  },
  {
    "text": "to a human. So that's the thing that\nthe person doesn't know. It's some quote, unquote,\n\"emotional state.\"",
    "start": "2791920",
    "end": "2801700"
  },
  {
    "text": "It didn't just fall out of\noptimal decision-making. We had to do some work. And, in particular, the\nwork that we did here",
    "start": "2801700",
    "end": "2806995"
  },
  {
    "text": "was to train a mapping\nbetween trajectories",
    "start": "2806995",
    "end": "2812020"
  },
  {
    "text": "and their valence\narousal dominance, which is a\nthree-dimensional space that",
    "start": "2812020",
    "end": "2817780"
  },
  {
    "text": "corresponds to human emotions. And then what we could do\nis optimize trajectories",
    "start": "2817780",
    "end": "2825410"
  },
  {
    "text": "that when projected\ninto this space, are very close to the target\nemotion we were doing.",
    "start": "2825410",
    "end": "2832860"
  },
  {
    "text": "So we were doing optimization. But it required a bunch of work. It wasn't just like,\nthis strategy emerges. We got a lot of annotations.",
    "start": "2832860",
    "end": "2839660"
  },
  {
    "text": "Similar here, I say,\ngreat weather today. Now, what I can do is\nI can use a language",
    "start": "2839660",
    "end": "2846410"
  },
  {
    "text": "model to tap into this-- to project into the valence\narousal dominant space,",
    "start": "2846410",
    "end": "2851540"
  },
  {
    "text": "figure out what emotion\nthat corresponds to, and then optimize for the robot\nto show emotion appropriate",
    "start": "2851540",
    "end": "2857030"
  },
  {
    "text": "for that emotional content. It didn't get the offer today. That sucks. And then the vacuum\ncleaner is more sad",
    "start": "2857030",
    "end": "2862430"
  },
  {
    "text": "and close to the\nground and less energy. Very cute. Again, caveats. And I'd be remiss without\nshowing Minae's work",
    "start": "2862430",
    "end": "2869930"
  },
  {
    "text": "while she was in my lab of\nrobots expressing incapability. I'm trying. But I can't, actually.",
    "start": "2869930",
    "end": "2875089"
  },
  {
    "text": "I don't have the force\nto open this cabinet. And we have to end. So what I'll say\nis, I don't think",
    "start": "2875090",
    "end": "2882740"
  },
  {
    "text": "this is the full\nsolution to interaction. But I think we benefit from\nrecognizing that under the hood,",
    "start": "2882740",
    "end": "2888950"
  },
  {
    "text": "we're trying to\nsolve this partially observable general-sum game. The game aspect gives\nus this mutual influence",
    "start": "2888950",
    "end": "2895190"
  },
  {
    "text": "that we should expect between\nrobot actions and human actions. The partial observability\nmakes us embrace the fact",
    "start": "2895190",
    "end": "2901372"
  },
  {
    "text": "that we don't know\neverything about the human. And their behavior ends up\nbeing evidence about the stuff we don't know and vice-versa.",
    "start": "2901373",
    "end": "2907730"
  },
  {
    "text": "The human doesn't know\neverything about the robot. And so I think there's this\nF equals ma of interaction",
    "start": "2907730",
    "end": "2916910"
  },
  {
    "text": "that enables us to account for\nthe human as part of the state. And in turn, enables a robot to\nuse optimal decision-making to,",
    "start": "2916910",
    "end": "2925250"
  },
  {
    "text": "actually, generate\nstrategies for coordination and interaction with people.",
    "start": "2925250",
    "end": "2932030"
  },
  {
    "text": "I started with this\nbook in 12th grade. And I, actually, got to\nedit the robotics chapter",
    "start": "2932030",
    "end": "2937880"
  },
  {
    "text": "in the fourth edition to,\nactually, talk about this game formulation and how\nunderneath it all,",
    "start": "2937880",
    "end": "2943197"
  },
  {
    "text": "this is the problem\nthat robots should be solving, not in isolation. And I will admit that this\nwasn't a talk about how.",
    "start": "2943197",
    "end": "2950060"
  },
  {
    "text": "It was a talk about what. What is the problem formulation? What are the aspects of it that\nare important that we should",
    "start": "2950060",
    "end": "2955170"
  },
  {
    "text": "be embracing, not any of how\nwe actually solve these things? There's been amazing\nstudents who have",
    "start": "2955170",
    "end": "2960590"
  },
  {
    "text": "worked on solving these things. Dorsa, I mentioned. Jamie, Andrea, they've\nworked on the game aspect.",
    "start": "2960590",
    "end": "2967550"
  },
  {
    "text": "Dylan, Andreea,\nSmitha, Kush, Rohin have worked on the partial\nobservability aspect.",
    "start": "2967550",
    "end": "2975290"
  },
  {
    "text": "Sandy has worked on\nthe expressive aspect. If you want to know how\nto solve a game like this,",
    "start": "2975290",
    "end": "2983060"
  },
  {
    "text": "a full observability\nformulation, the best-- the closest\nwe've gotten to is in David's work with Ellis\nand with Claire, where quadratic",
    "start": "2983060",
    "end": "2992990"
  },
  {
    "text": "sizing the costs and\nlinearizing the dynamics and doing this iterative\nLQ game formulation.",
    "start": "2992990",
    "end": "3000690"
  },
  {
    "text": "I'll skip this part. Humans aren't\noptimal game players. Even if I could solve\nthe game, that's",
    "start": "3000690",
    "end": "3006360"
  },
  {
    "text": "not a very good description of\nhow exactly the human will act. So we work a lot on how do we\nget good robust human models",
    "start": "3006360",
    "end": "3015569"
  },
  {
    "text": "by combining these\ngame ideas with data. And we work a lot on,\nwe'll get it wrong.",
    "start": "3015570",
    "end": "3022800"
  },
  {
    "text": "The robots won't have great\nmodels of people ever. They might get\nbetter and better. But they'll always be errors.",
    "start": "3022800",
    "end": "3028740"
  },
  {
    "text": "So how important is that error? What theoretical\nconsequence does it have on the inference\nthat the robot does?",
    "start": "3028740",
    "end": "3035430"
  },
  {
    "text": "How do I robustify\nthat inference? How do I detect that I\nhave the wrong model?",
    "start": "3035430",
    "end": "3040680"
  },
  {
    "text": "So those are all aspects of\nwhat it means to do work. But it's all grounded in this\nperspective of interaction",
    "start": "3040680",
    "end": "3046980"
  },
  {
    "text": "as this partial observable\ndynamic general-sum game, which is really been my F equals ma\nguiding lens for interaction.",
    "start": "3046980",
    "end": "3055049"
  },
  {
    "text": "So with that, thank you. And thanks to all the members\nof my lab, who've actually done this work, past and present.",
    "start": "3055050",
    "end": "3061240"
  },
  {
    "text": "Thanks for listening. [APPLAUSE] ",
    "start": "3061240",
    "end": "3069000"
  }
]
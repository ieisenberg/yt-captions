[
  {
    "start": "0",
    "end": "14000"
  },
  {
    "start": "0",
    "end": "9030"
  },
  {
    "text": "CHRISTOPHER POTTS: And\nit's wonderful to be here with you all. Large language\nmodels get the hype.",
    "start": "9030",
    "end": "14420"
  },
  {
    "start": "14000",
    "end": "38000"
  },
  {
    "text": "This is certainly true. I do believe, firmly, that the\nfuture is in compound systems.",
    "start": "14420",
    "end": "21260"
  },
  {
    "text": "I want to emphasize,\nthough, that I also feel like the present\nis compound systems.",
    "start": "21260",
    "end": "26360"
  },
  {
    "text": "I think we are all\nkind of intuitively aware, if we're\nworking in the field, that we only ever\ninteract with systems,",
    "start": "26360",
    "end": "33110"
  },
  {
    "text": "but models get\nall the headlines, and so that kind of core\ninsight can get clouded out. And part of what\nI want to do today",
    "start": "33110",
    "end": "39530"
  },
  {
    "start": "38000",
    "end": "55000"
  },
  {
    "text": "is just raise your\nconsciousness on the fact that we are, all the time,\ndealing with systems.",
    "start": "39530",
    "end": "45079"
  },
  {
    "text": "But if that is getting\nlost in the shuffle, it is understandable\nbecause we are awash in headlines\nthat are centered",
    "start": "45080",
    "end": "52130"
  },
  {
    "text": "on large language models\nand other foundation models. This is a trend that really\nkicked off with the GPT-3 paper",
    "start": "52130",
    "end": "59330"
  },
  {
    "start": "55000",
    "end": "67000"
  },
  {
    "text": "in 2020, of course, and\nthat makes perfect sense because the headline\nresult from that paper",
    "start": "59330",
    "end": "65720"
  },
  {
    "text": "is that they did a\nthing in the world. They trained a model at 175\nbillion parameters, which",
    "start": "65720",
    "end": "71579"
  },
  {
    "start": "67000",
    "end": "101000"
  },
  {
    "text": "is more than an\norder of magnitude larger than any model\nthat had come before it. And of course, the\ncentral insight",
    "start": "71580",
    "end": "78120"
  },
  {
    "text": "is that simple\nact of scaling led them to be able to\ndesign systems of a kind",
    "start": "78120",
    "end": "83370"
  },
  {
    "text": "that we had never seen before. And so that really\nkicked off the trend of announcing lots of\nexciting new models.",
    "start": "83370",
    "end": "90700"
  },
  {
    "text": "Here's another example of this,\nwhen Google announced its PaLM model, of course,\na headline there",
    "start": "90700",
    "end": "95820"
  },
  {
    "text": "was that it was 540 billion\nparameters, so much larger than we had seen before.",
    "start": "95820",
    "end": "101440"
  },
  {
    "start": "101000",
    "end": "121000"
  },
  {
    "text": "I think PaLM is a\nsystem in the sense that I mean for the talk today,\nbut they made the announcement",
    "start": "101440",
    "end": "107040"
  },
  {
    "text": "in terms of a model. And they even did that\nfor their Gemini system. I think, again, Gemini is a\nparadigm case of innovation",
    "start": "107040",
    "end": "114540"
  },
  {
    "text": "at the level of model artifacts,\nbut also at the systems that we build around\nthem so that they",
    "start": "114540",
    "end": "119969"
  },
  {
    "text": "can do exciting things. Gemini is a system,\nbut of course, they described it as a model in\nkeeping with this trend.",
    "start": "119970",
    "end": "127189"
  },
  {
    "start": "121000",
    "end": "143000"
  },
  {
    "text": "And even OpenAI, which I think\nof as an outfit that really has reoriented around full\nsoftware systems, where",
    "start": "127190",
    "end": "134540"
  },
  {
    "text": "the paradigm example of\nthat would be ChatGPT, which is a kind of experience\nthat is powered",
    "start": "134540",
    "end": "139879"
  },
  {
    "text": "by lots of interesting models. Even they, though,\ntend to announce things in terms of models.",
    "start": "139880",
    "end": "144960"
  },
  {
    "start": "143000",
    "end": "176000"
  },
  {
    "text": "So GPT-4o, the new\nflagship model. I think these are\nreally systems, but they centered\nit on the model.",
    "start": "144960",
    "end": "151760"
  },
  {
    "text": "And of course, that's\njust the big tech players. If you're like me, it feels like\nevery time you open up Twitter,",
    "start": "151760",
    "end": "157890"
  },
  {
    "text": "your feed is just full of\nbreathless announcements about some exciting new\nmodel series that is",
    "start": "157890",
    "end": "163070"
  },
  {
    "text": "supposed to change everything. So if you're living in\nthis kind of world with me, it makes sense that\nyou would end up",
    "start": "163070",
    "end": "169190"
  },
  {
    "text": "thinking in terms of models. But this is the\ncentral lesson here. We only ever deal with systems.",
    "start": "169190",
    "end": "176459"
  },
  {
    "start": "176000",
    "end": "202000"
  },
  {
    "text": "And let me try to make\nthis vivid for you. Here, I've got on the slide\na large language model.",
    "start": "176460",
    "end": "182620"
  },
  {
    "text": "You can imagine that you\ndownloaded it from somewhere as a pre-trained\nartifact, or maybe you",
    "start": "182620",
    "end": "187830"
  },
  {
    "text": "spent millions of your own money\nto train this thing yourself. In some sense,\nyou feel like this",
    "start": "187830",
    "end": "193830"
  },
  {
    "text": "is going to be a really exciting\nand highly-performant artifact, but currently it is just sitting\non disk, completely inert.",
    "start": "193830",
    "end": "203070"
  },
  {
    "start": "202000",
    "end": "244000"
  },
  {
    "text": "All it can do is occupy\ndisk space at this point. To get this model to\ndo anything at all,",
    "start": "203070",
    "end": "209350"
  },
  {
    "text": "you have to do at\nleast two things. You have to prompt it to put it\nin some kind of internal state,",
    "start": "209350",
    "end": "214930"
  },
  {
    "text": "and then if you want it\nto be a generative system, you have to define some\nkind of sampling method. You have to get\nthis model to talk,",
    "start": "214930",
    "end": "221730"
  },
  {
    "text": "because intrinsically,\nall it really does is represent things\nin an abstract space.",
    "start": "221730",
    "end": "227430"
  },
  {
    "text": "Having made a choice about a\nprompt and a sampling method, you now have a system.",
    "start": "227430",
    "end": "232890"
  },
  {
    "text": "And part of the main\nthesis for today is that both of these things\nare non-trivial choices that",
    "start": "232890",
    "end": "238830"
  },
  {
    "text": "are going to define the kind\nof system that you end up with. The prompt, the model\nand the sampling method",
    "start": "238830",
    "end": "244590"
  },
  {
    "start": "244000",
    "end": "270000"
  },
  {
    "text": "form a kind of minimal system,\nbut already an important one. And then, of course, in\nthe more modern mode now,",
    "start": "244590",
    "end": "251590"
  },
  {
    "text": "we are taking minimal\nsystems like that and giving them access to\ncalculators and programming",
    "start": "251590",
    "end": "257648"
  },
  {
    "text": "environments and databases and\nmaybe even web APIs and the web itself.",
    "start": "257649",
    "end": "262880"
  },
  {
    "text": "I think, at that\npoint, we can all see that this is\na software system. The language model might\nhave a privileged place",
    "start": "262880",
    "end": "269800"
  },
  {
    "text": "here as a kind of hub\nfor all the things that are going to happen,\nbut it is just one component",
    "start": "269800",
    "end": "274910"
  },
  {
    "start": "270000",
    "end": "300000"
  },
  {
    "text": "and the capabilities\nof this system are going to be defined\nby how all of these things work together in concert and not\nsolely by the language model.",
    "start": "274910",
    "end": "284470"
  },
  {
    "text": "And that is the essence\nof my thesis for today. In my group and\nin related groups",
    "start": "284470",
    "end": "291060"
  },
  {
    "text": "at Berkeley and\nvarious other places, we have been thinking in these\nterms for quite a while now.",
    "start": "291060",
    "end": "296580"
  },
  {
    "text": "And at the start of this year,\nwe did a blog post called \"The Shift from Models\nto Compound AI Systems.\"",
    "start": "296580",
    "end": "303280"
  },
  {
    "start": "300000",
    "end": "337000"
  },
  {
    "text": "And I'm kind of,\ntoday, just giving you an updated perspective on the\nthesis from that blog post.",
    "start": "303280",
    "end": "308970"
  },
  {
    "text": "I want to emphasize\nthat that blog post is from February 18, 2024.",
    "start": "308970",
    "end": "315210"
  },
  {
    "text": "And the reason I want\nto emphasize that is that, in AI terms,\nthat was a long time ago",
    "start": "315210",
    "end": "320729"
  },
  {
    "text": "and I'm hearing more\nand more of this talk. And in particular, Sam Altman,\nat a very recent OpenAI",
    "start": "320730",
    "end": "326669"
  },
  {
    "text": "developer event, was musing\naloud about the future of AI, and he said he expects to see a\nshift from talking about models",
    "start": "326670",
    "end": "335430"
  },
  {
    "text": "to talking about\nsystems, which, to my ear directly echoes the\ntitle of our blog post.",
    "start": "335430",
    "end": "342240"
  },
  {
    "start": "337000",
    "end": "356000"
  },
  {
    "text": "I don't know whether\nhe was influenced by us or whether this is a case of\nconvergent thinking or what,",
    "start": "342240",
    "end": "349150"
  },
  {
    "text": "but we did say this first. I guess that's the main\npoint I want to make, is-- goodbye, Sam-- we've been\nthinking in these terms",
    "start": "349150",
    "end": "356010"
  },
  {
    "start": "356000",
    "end": "400000"
  },
  {
    "text": "for a very long time. Why is this important? I'm going to try to support\nthese main claims here,",
    "start": "356010",
    "end": "363810"
  },
  {
    "text": "but let me just give them\nto you at a high level. The first is this that\nthis is important just",
    "start": "363810",
    "end": "369200"
  },
  {
    "text": "from the perspective\nof investing in all of the right\nthings as you're developing an AI solution.",
    "start": "369200",
    "end": "375310"
  },
  {
    "text": "Here's an analogy. When you design a\nsystem in this mode, you are doing something\nanalogous to designing a Formula",
    "start": "375310",
    "end": "381590"
  },
  {
    "text": "One race car. And I think we all can\nrecognize that an F1 race car is much more than just its engine.",
    "start": "381590",
    "end": "388400"
  },
  {
    "text": "It's also aerodynamics and\nfriction and the driver and the controls for the\ndriver and everything else.",
    "start": "388400",
    "end": "394770"
  },
  {
    "text": "All of those things\nhave to come together to get a really good race car. And too often in\nAI, we are behaving",
    "start": "394770",
    "end": "402260"
  },
  {
    "start": "400000",
    "end": "418000"
  },
  {
    "text": "like F1 race car designers who\nfocus obsessively on the engine. And I don't know\nmuch about F1 racing,",
    "start": "402260",
    "end": "409860"
  },
  {
    "text": "but I'm confident that\nif all you ever did was think about the\nengine for this car, you would not end up\nwith a good race car.",
    "start": "409860",
    "end": "416450"
  },
  {
    "text": "And just by the way\nhere, you can probably tell that I generated\nthese images using ChatGPT.",
    "start": "416450",
    "end": "422580"
  },
  {
    "start": "418000",
    "end": "473000"
  },
  {
    "text": "And it was sort of funny. I had trouble prompting it\nto get me to just show me",
    "start": "422580",
    "end": "427890"
  },
  {
    "text": "a picture of an F1 engine. It kept putting\nwheels on the engine, so it would produce\npictures like this.",
    "start": "427890",
    "end": "434200"
  },
  {
    "text": "And I decided that\nthis is almost a kind of comical\nembodiment of the thing that I'm worried about\ntoday, is that we're",
    "start": "434200",
    "end": "440220"
  },
  {
    "text": "trying to design F1\nrace cars and we end up doing that by putting\nwheels on the engine.",
    "start": "440220",
    "end": "445650"
  },
  {
    "text": "Do not do this. It's not going to lead\nto a good overall system. We got to think in these terms.",
    "start": "445650",
    "end": "452070"
  },
  {
    "text": "Here's another important point. Building the best system for\nyour goals and constraints is almost certainly going to\nemphasize system components,",
    "start": "452070",
    "end": "460690"
  },
  {
    "text": "and I maintain that, for\nexample, a small model that is embedded in a\nsmart system is always",
    "start": "460690",
    "end": "466890"
  },
  {
    "text": "going to be better\nthan a big model embedded in a simplistic system. I think this is true\neven if you're just",
    "start": "466890",
    "end": "472680"
  },
  {
    "text": "shooting for raw accuracy or\nperformance in some sense. But it is absolutely\ntrue if you also",
    "start": "472680",
    "end": "478980"
  },
  {
    "start": "473000",
    "end": "484000"
  },
  {
    "text": "care about things like cost and\nlatency and safety and privacy.",
    "start": "478980",
    "end": "484660"
  },
  {
    "start": "484000",
    "end": "593000"
  },
  {
    "text": "Once those\nconsiderations come in, you're going to be thinking\nabout a system that can offer you all of those\nguarantees, and in that context,",
    "start": "484660",
    "end": "492820"
  },
  {
    "text": "a small model might be the only\nchoice that you could make, especially if cost\nis a consideration.",
    "start": "492820",
    "end": "498660"
  },
  {
    "text": "And then finally, we\ncould expand the purview out a little bit\nhere and just think about safety and regulation.",
    "start": "498660",
    "end": "504120"
  },
  {
    "text": "I'm going to talk about this\nat the end of the talk today. A lot of discussion\nin these areas",
    "start": "504120",
    "end": "509640"
  },
  {
    "text": "has been focused\non model artifacts, and I think that is\nsimply a mistake. I think we need to think about\nregulating entire systems--",
    "start": "509640",
    "end": "518710"
  },
  {
    "text": "oops-- not just models. I think if we focus\non the models, we're inevitably going to let\nsome really dangerous stuff",
    "start": "518710",
    "end": "526230"
  },
  {
    "text": "through and also end up\noverregulating things that could actually be\njust very productive.",
    "start": "526230",
    "end": "531880"
  },
  {
    "text": "But if we think in\nterms of systems, I think we have a better chance\nof getting these things right.",
    "start": "531880",
    "end": "538040"
  },
  {
    "text": "So let's dive in a bit now\nto the system components, and I'm going to stick with\nthe simplest ones for today",
    "start": "538040",
    "end": "543770"
  },
  {
    "text": "because I actually\nthink those are the most consequential, especially in\nthis era of in-context learning.",
    "start": "543770",
    "end": "549620"
  },
  {
    "text": "But let's start with the one\nthat seems, on the surface, to be the simplest of all. This is the method\nthat you're going",
    "start": "549620",
    "end": "555350"
  },
  {
    "text": "to use for sampling when you\nwant your model to generate. Here is that\nminimal system here.",
    "start": "555350",
    "end": "561060"
  },
  {
    "text": "I imagine that you've\ngot a prompt that came in and now we're going to think\nabout getting this model to talk.",
    "start": "561060",
    "end": "566520"
  },
  {
    "text": "And, of course, there\nare lots of methods. We could do greedy decoding. That would be just\nwhere we decide",
    "start": "566520",
    "end": "572149"
  },
  {
    "text": "that we're going to\ngenerate the most probable next token conditional\non what has come in so far.",
    "start": "572150",
    "end": "577200"
  },
  {
    "text": "We think of that as a kind\nof default for generation, but there is no\nsense in which it",
    "start": "577200",
    "end": "583100"
  },
  {
    "text": "is the privileged method here. It is just one\nchoice among many. We could also think about top-p.",
    "start": "583100",
    "end": "588982"
  },
  {
    "text": "This would be where\nwe're sampling tokens from the most probable tokens\naccording to the distribution",
    "start": "588982",
    "end": "594080"
  },
  {
    "start": "593000",
    "end": "634000"
  },
  {
    "text": "for the model. We could also do something\nlike beam search, which would be a more exploratory method.",
    "start": "594080",
    "end": "600130"
  },
  {
    "text": "We could think about\ninsisting on token diversity for these generations. That's an even higher level\nideal that we could impose.",
    "start": "600130",
    "end": "606960"
  },
  {
    "text": "And we could even go\nSo far as insisting that the things we\ngenerate conform",
    "start": "606960",
    "end": "612149"
  },
  {
    "text": "to being valid JSON, a very\nhigh-level consideration in play here, and that is just\nthe tip of the iceberg.",
    "start": "612150",
    "end": "619480"
  },
  {
    "text": "And, in fact, if you start to\nlook around in this literature, you find it's a space that's\nfull of innovative ideas.",
    "start": "619480",
    "end": "626010"
  },
  {
    "text": "I won't have time to go\nthrough these in detail, but a lot of these\nmethods are doing things like making use of\nthe gradients to get",
    "start": "626010",
    "end": "632880"
  },
  {
    "text": "much more information about\nthe forward-backward flow in the model. A lot of them are\nfocused on that question",
    "start": "632880",
    "end": "639209"
  },
  {
    "start": "634000",
    "end": "678000"
  },
  {
    "text": "of how we could ensure\nthat the generated output conforms to a high\nlevel grammar, like for a logic or a computer\nprogramming environment.",
    "start": "639210",
    "end": "647740"
  },
  {
    "text": "Here's a really nice paper that\ntries to do that efficiently and also offers an overview\nof lots of prior methods",
    "start": "647740",
    "end": "654300"
  },
  {
    "text": "that have tried to ensure\nmodel generations conform to the specification of computer\ncode and things like that.",
    "start": "654300",
    "end": "660930"
  },
  {
    "text": "And here's a really recent\npaper that is actually adding parameters to the model\nto try to adaptively find",
    "start": "660930",
    "end": "667620"
  },
  {
    "text": "a good temperature so that the\nmodel is creative or constrained depending on the\ntask that you want it",
    "start": "667620",
    "end": "673830"
  },
  {
    "text": "to solve at any given moment-- a really innovative way\nto think about sampling.",
    "start": "673830",
    "end": "679830"
  },
  {
    "start": "678000",
    "end": "720000"
  },
  {
    "text": "And if you'll permit\nme one step further, we could expand out what we\nmean by sampling for generation",
    "start": "679830",
    "end": "685798"
  },
  {
    "text": "and really get into things\nthat are going to look like creative exploration. I've put this under the\nheading of majority completion",
    "start": "685798",
    "end": "692730"
  },
  {
    "text": "strategies. This is a simple\ninstance of a pattern that we're seeing a lot now\nin technology and in research.",
    "start": "692730",
    "end": "699570"
  },
  {
    "text": "Imagine you've got a prompt that\nhas some really hard reasoning task in it. Now you could ask the\nmodel to simply generate",
    "start": "699570",
    "end": "706830"
  },
  {
    "text": "the answer in one step, but\nthat might be too difficult. What you might\nwant to do instead",
    "start": "706830",
    "end": "712500"
  },
  {
    "text": "is have it generate\nsome reasoning path and then produce an answer. But you could do that by\nsampling multiple reasoning",
    "start": "712500",
    "end": "720000"
  },
  {
    "start": "720000",
    "end": "758000"
  },
  {
    "text": "paths, and different\nreasoning paths might lead to different answers. So if I do this a bunch\nof different times,",
    "start": "720000",
    "end": "726760"
  },
  {
    "text": "I get a distribution\nover the answers, and I might then say that\nthe actual generated output",
    "start": "726760",
    "end": "732720"
  },
  {
    "text": "in this context is going\nto be the answer that was the most common\noutcome given all the diverse reasoning paths.",
    "start": "732720",
    "end": "739500"
  },
  {
    "text": "So that's a way of letting\nthe model explore and do some reasoning in\ngeneration before you insist",
    "start": "739500",
    "end": "745170"
  },
  {
    "text": "on it producing a final answer. Now, this isn't,\nstrictly speaking, just a sampling strategy,\nbut we might",
    "start": "745170",
    "end": "751500"
  },
  {
    "text": "trick the user a little\nbit and hide from them all of those\nintermediate steps so that it looks like\nwe have simply",
    "start": "751500",
    "end": "757770"
  },
  {
    "text": "sampled an answer over here\non the right for their input. And that's just one simple\ninstance of the many things",
    "start": "757770",
    "end": "764670"
  },
  {
    "start": "758000",
    "end": "3486000"
  },
  {
    "text": "that you could do as you\nhad reasoning paths lead to other answers, lead\nto other reasoning paths, and so forth and so on\nbefore finally producing",
    "start": "764670",
    "end": "772200"
  },
  {
    "text": "the answer at the end. So that's the tip\nof the iceberg, I think, still,\neven though that's",
    "start": "772200",
    "end": "777907"
  },
  {
    "text": "a pretty rich array of ideas. This is the essence of this,\nthough-- there is no one true",
    "start": "777907",
    "end": "783170"
  },
  {
    "text": "sampling method for your model. This is a highly\nconsequential step. In some sense, you are\nmaking the model speak,",
    "start": "783170",
    "end": "790230"
  },
  {
    "text": "which it does not\nreally do intrinsically, and the choice\nthat you make here is going to be highly\nconsequential for the overall",
    "start": "790230",
    "end": "797690"
  },
  {
    "text": "system that you design. I think I'm emphasizing this\nbecause we too often don't consider the sampling\nmethod, even though you",
    "start": "797690",
    "end": "805010"
  },
  {
    "text": "can see that it really\nmatters for the behavior of the overall\nsystem, and it's going to interact in complex ways\nwith the language model",
    "start": "805010",
    "end": "812480"
  },
  {
    "text": "that you've chosen\nas your basis. So that's sampling.",
    "start": "812480",
    "end": "817520"
  },
  {
    "text": "Let's think now about prompting. And prompting is really the\nheart of modern AI system",
    "start": "817520",
    "end": "822910"
  },
  {
    "text": "development. Probably a lot of you\nout there have done a lot of prompt engineering. You worked very hard\non prompts and seeing",
    "start": "822910",
    "end": "829750"
  },
  {
    "text": "that you can get complex\nand interesting behaviors from the resulting system. So that is certainly the\nheart of all of this,",
    "start": "829750",
    "end": "836833"
  },
  {
    "text": "and if you've done\nit long enough, you might have\ndiscovered that it also can be quite heartbreaking, and\nI want to discuss that with you",
    "start": "836833",
    "end": "843670"
  },
  {
    "text": "as well. Let's reflect,\nthough, for a minute on the origins of all this. We've started to\ntake it for granted,",
    "start": "843670",
    "end": "849730"
  },
  {
    "text": "but it's a new and\nvery unusual idea. I think the origins of this\nreally traced to the GPT-2 paper",
    "start": "849730",
    "end": "857070"
  },
  {
    "text": "from 2019. This is Radford, et al. There are some\nprecedents before this, but this is the paper where it\nreally crystallized, I believe.",
    "start": "857070",
    "end": "864870"
  },
  {
    "text": "In that paper, they say, \"We\ndemonstrate language models can perform down-stream tasks in a\nzero-shot setting without any",
    "start": "864870",
    "end": "871950"
  },
  {
    "text": "parameter or architecture\nmodification.\" They go on, \"To induce\nsummarization behavior,",
    "start": "871950",
    "end": "877570"
  },
  {
    "text": "we add the text TL:DR after\nthe article and generate 100 tokens.\" In-context learning.",
    "start": "877570",
    "end": "884440"
  },
  {
    "text": "I want to confide in you\nall that when I first read this way back in\n2019, I did not properly",
    "start": "884440",
    "end": "890759"
  },
  {
    "text": "understand what it was saying. I was so cognitively-biased\nagainst this kind of thing",
    "start": "890760",
    "end": "896430"
  },
  {
    "text": "working that I thought surely\nsomewhere hidden in this paper is a description of some\nfine-tuning method that they",
    "start": "896430",
    "end": "903120"
  },
  {
    "text": "used to get that token TL:DR\nto produce summarization.",
    "start": "903120",
    "end": "908560"
  },
  {
    "text": "But now I see, of\ncourse, that they really meant what they wrote,\nwhich was perfectly clear. I was just not primed\nto really understand it,",
    "start": "908560",
    "end": "915670"
  },
  {
    "text": "that simply by relying\non this language model to do in-context learning,\nthey could get it to summarize.",
    "start": "915670",
    "end": "921820"
  },
  {
    "text": "Really amazing,\nand in that paper, they also tried translation,\nquestion answering, text completion, and\nreading comprehension.",
    "start": "921820",
    "end": "928779"
  },
  {
    "text": "Performance is\nvariable across them, but mostly they can get\nsignal, and it really is a kind of striking\nexploration of this idea.",
    "start": "928780",
    "end": "936710"
  },
  {
    "text": "We now take it for granted, but\nat the time, at least for me, it was very surprising.",
    "start": "936710",
    "end": "942040"
  },
  {
    "text": "Then fast forward just\none year, we get GPT-3. We've gone from 1.2 billion\nparameters for GPT-2",
    "start": "942040",
    "end": "949030"
  },
  {
    "text": "now up to 175 billion. And the GPT-3 paper is\nan incredible exploration",
    "start": "949030",
    "end": "955269"
  },
  {
    "text": "of what that scaling leads to. It's full of cases where they do\nsuccessful, complex, in-context",
    "start": "955270",
    "end": "962140"
  },
  {
    "text": "learning. And here's an example of that. For question answering,\nwe just prompt the model",
    "start": "962140",
    "end": "967720"
  },
  {
    "text": "with a context\npassage, and then we give it a few\ndemonstrations, which are also just part of the\nprompt that we're creating here.",
    "start": "967720",
    "end": "975640"
  },
  {
    "text": "And that prompt is\nmeant to show it that we want the behavior to be\nthat the answer is a substring",
    "start": "975640",
    "end": "981820"
  },
  {
    "text": "of the context passage. We maybe provide a\nfew of those, and then we give our target question,\nand the major discovery",
    "start": "981820",
    "end": "988899"
  },
  {
    "text": "is in-context, the\nmodel can learn to imitate that behavior\nand answer questions",
    "start": "988900",
    "end": "994240"
  },
  {
    "text": "as substrings of the passage. Really striking behavior. And the paper really\nalready identifies",
    "start": "994240",
    "end": "1001290"
  },
  {
    "text": "a kind of general\npattern for this, where we're going to have\nsome context or instructions, then we'll have some list of\ndemonstrations that further",
    "start": "1001290",
    "end": "1008860"
  },
  {
    "text": "exemplify the behavior\nthat we want to see, and then finally,\na target down here. And they apply this template\nto lots of different tasks,",
    "start": "1008860",
    "end": "1016300"
  },
  {
    "text": "from QA to reading comprehension\nto machine translation. Here's a quick example.",
    "start": "1016300",
    "end": "1021440"
  },
  {
    "text": "I could say, \"please unscramble\nthe letters into a word and write that word\" as\nmy instruction or context,",
    "start": "1021440",
    "end": "1027319"
  },
  {
    "text": "give a few demonstrations,\nand then at the least, at least at the time of GPT-3,\nmaybe I would get something that",
    "start": "1027319",
    "end": "1033760"
  },
  {
    "text": "was at least close to the\nbehavior that I wanted to see. And so forth and so on.",
    "start": "1033760",
    "end": "1039079"
  },
  {
    "text": "So already a template\nfor building systems in this modern mode. It's very exciting,\nbut as I said,",
    "start": "1039079",
    "end": "1046319"
  },
  {
    "text": "if you have done some work\nwith prompting models, you have already seen that there\ncan be a real dark side to all",
    "start": "1046319",
    "end": "1052340"
  },
  {
    "text": "of this. This is a paper that kind\nof crystallizes it for me. This is from a group\nat Berkeley and U-dub,",
    "start": "1052340",
    "end": "1058970"
  },
  {
    "text": "\"Quantifying Language Models'\nSensitivity to Spurious Features in Prompt Design, or How I\nLearned to Start Worrying About",
    "start": "1058970",
    "end": "1066860"
  },
  {
    "text": "Prompt Formatting.\" And this is a\nreally dramatic case of sensitivity of the model to\nthe prompt choice that you make.",
    "start": "1066860",
    "end": "1074180"
  },
  {
    "text": "This is a sample\ntable from the paper. They're looking at Llama 2-7b\nThe paper explores a bunch",
    "start": "1074180",
    "end": "1079400"
  },
  {
    "text": "of other models. But just to take\none example here, task 280 is an\ninstruction-following task.",
    "start": "1079400",
    "end": "1085500"
  },
  {
    "text": "They have two prompt\nformats for it, and those formats differ only in\nwhether or not they have colons",
    "start": "1085500",
    "end": "1091640"
  },
  {
    "text": "in them after the words\n\"passage\" and \"answer.\" And that minor change leads\nto an 80-point difference",
    "start": "1091640",
    "end": "1098810"
  },
  {
    "text": "in the performance of one\nand the same language model, and that pattern is repeated\nacross lots of tasks in this",
    "start": "1098810",
    "end": "1106110"
  },
  {
    "text": "paper. This shows you that with the\nwrong prompting strategy, you could make any model\nlook arbitrarily bad.",
    "start": "1106110",
    "end": "1113790"
  },
  {
    "text": "But the essence\nof this for today is that I think it shows that\nit just doesn't make sense",
    "start": "1113790",
    "end": "1119309"
  },
  {
    "text": "to ask what it means\nto evaluate this model in the context of these tasks.",
    "start": "1119310",
    "end": "1124820"
  },
  {
    "text": "The only way to make\nsense of this question is to ask how the model paired\nwith a prompting strategy",
    "start": "1124820",
    "end": "1130740"
  },
  {
    "text": "is going to do and\nthink in those terms. And that is already\nsystems thinking.",
    "start": "1130740",
    "end": "1136880"
  },
  {
    "text": "So get rid of that question\nand think right away in terms of systems.",
    "start": "1136880",
    "end": "1141990"
  },
  {
    "text": "You should be asking yourself,\nwhat is the optimal prompt model combination given\nwhatever goals you have.",
    "start": "1141990",
    "end": "1149340"
  },
  {
    "text": "And let me just tell you a\nfew more stories about this. Then I'm going to go up at\na higher and higher level,",
    "start": "1149340",
    "end": "1154780"
  },
  {
    "text": "starting with prompt\nwith chain-of-thought. This is a lovely paper\ncalled \"EchoPrompt.\"",
    "start": "1154780",
    "end": "1161080"
  },
  {
    "text": "It's an empirical exploration of\ndifferent strategies for doing that classic \"let's\nthink by step-by-step\"",
    "start": "1161080",
    "end": "1167710"
  },
  {
    "text": "chain-of-thought reasoning. And here's a sample\ntable from the paper. You can see that they've just\ngot different variants of that",
    "start": "1167710",
    "end": "1174270"
  },
  {
    "text": "phrasing, \"let's\nrepeat the question,\" \"let's reiterate the question,\"\nand so forth and so on. And this is a glimpse\nof the results, which",
    "start": "1174270",
    "end": "1180870"
  },
  {
    "text": "show wide variation in terms\nof the performance of the model based on how we frame the\nchain-of-thought reasoning step.",
    "start": "1180870",
    "end": "1189000"
  },
  {
    "text": "This is for code-davinci-002,\nwhich is an older model, but again, I think this\nreproduces for newer models,",
    "start": "1189000",
    "end": "1194340"
  },
  {
    "text": "and it shows that it\njust doesn't make sense to ask this question. If you ask, what does it mean\nto evaluate this as a model,",
    "start": "1194340",
    "end": "1200770"
  },
  {
    "text": "even just for\nchain-of-thought, you already find that you have\nto be thinking in terms of model\nprompt combinations,",
    "start": "1200770",
    "end": "1207280"
  },
  {
    "text": "or in this case, model\nchain-of-thought combinations. And again, that is\nsystems-level thinking, not",
    "start": "1207280",
    "end": "1212620"
  },
  {
    "text": "model-level\nthinking, and I think that's just going to\nbring so much clarity to your own development cycles.",
    "start": "1212620",
    "end": "1219520"
  },
  {
    "text": "So get rid of that question. And let's go up one\nstep even further here. This is a nice tweet that I saw.",
    "start": "1219520",
    "end": "1225230"
  },
  {
    "text": "This person just\nobserves, \"Fun fact-- I realized I was still\nusing old GPT-4 for tool",
    "start": "1225230",
    "end": "1231340"
  },
  {
    "text": "calling in part of an agent. Updated to 4o and\nimmediately broke stuff.\"",
    "start": "1231340",
    "end": "1236830"
  },
  {
    "text": "I think if you've been in\nthis business long enough, you have seen this\nhappen yourselves. And this nice\nresponse tweet says,",
    "start": "1236830",
    "end": "1243250"
  },
  {
    "text": "\"Had the same exact experience,\nwhere going from 3.5 to 4o mini triggered a fresh prompt\nengineering exercise",
    "start": "1243250",
    "end": "1249970"
  },
  {
    "text": "as if it's a new project.\" I think this is showing that\nthe model and the prompt",
    "start": "1249970",
    "end": "1256120"
  },
  {
    "text": "are inextricably linked. We write these\nprompts in English, but in fact, they are\nmore like an effort",
    "start": "1256120",
    "end": "1261310"
  },
  {
    "text": "to communicate with this sort\nof alien creature, the language model. And we can deceive\nourselves by thinking",
    "start": "1261310",
    "end": "1267309"
  },
  {
    "text": "that our understanding is\ngoing to translate directly into the performance\nof the system. We would like to\nget away from this,",
    "start": "1267310",
    "end": "1273857"
  },
  {
    "text": "but I think the first\nstep toward that is thinking about these two\nthings as inextricably linked.",
    "start": "1273857",
    "end": "1279350"
  },
  {
    "text": "And by the way, a fun fact here,\nwhich Petra pointed out to me, I didn't know this at the\ntime of quoting this tweet,",
    "start": "1279350",
    "end": "1284990"
  },
  {
    "text": "but this tweeter here is an\nalum of my Natural Language Understanding course, and\nso maybe it's not surprising",
    "start": "1284990",
    "end": "1290380"
  },
  {
    "text": "also that they are a\nfan, as you can see here, of DSPy, the\nprogramming library. One more final story about this.",
    "start": "1290380",
    "end": "1297880"
  },
  {
    "text": "You might have seen\nthat people found the Apple Intelligence prompts. These are in system files\nthat ship with the OS.",
    "start": "1297880",
    "end": "1304630"
  },
  {
    "text": "And the prompts are fascinating\nto read because you can glimpse the development cycles\nthat they had to go through",
    "start": "1304630",
    "end": "1310480"
  },
  {
    "text": "to get the Apple Intelligence\nmodels to behave in the intended way. They're full of things that are\nspecial pleading with the model",
    "start": "1310480",
    "end": "1318640"
  },
  {
    "text": "to do what they\nwant, and so forth. You can tell that these\nprompts are very tightly knit",
    "start": "1318640",
    "end": "1324279"
  },
  {
    "text": "to the models that they shipped. And again, that makes me want to\ntake the perspective that even",
    "start": "1324280",
    "end": "1329950"
  },
  {
    "text": "though they're in\nEnglish, they are much more like compiled\nbinaries, which are meant to be",
    "start": "1329950",
    "end": "1334960"
  },
  {
    "text": "paired with a particular model. That is, again,\nsystems thinking, and I think it shows that these\nthings are really interacting",
    "start": "1334960",
    "end": "1342410"
  },
  {
    "text": "in tightly-knit ways to\ndeliver the performance that we want and we can't really\nseparate the prompt as a system",
    "start": "1342410",
    "end": "1349309"
  },
  {
    "text": "component from the model\nas a system component. And this is a kind of a\nfunny thing to reflect on.",
    "start": "1349310",
    "end": "1356690"
  },
  {
    "text": "And this does lead us\nto the DSPy library that we've been trying\nto promote with people",
    "start": "1356690",
    "end": "1362710"
  },
  {
    "text": "and get lots of\npeople to work on. It's a funny moment because\nsome of the core lessons of artificial intelligence\nseem to have been forgotten.",
    "start": "1362710",
    "end": "1370470"
  },
  {
    "text": "So let's just step back\nand reflect on this. Throughout AI, we've\nbeen successful, in part, because we have\nadopted these lessons--",
    "start": "1370470",
    "end": "1377840"
  },
  {
    "text": "modular system design,\ndata-driven optimization, and generic architectures.",
    "start": "1377840",
    "end": "1384320"
  },
  {
    "text": "These are the\nessence of what made us be able to move so fast,\nespecially in the deep learning",
    "start": "1384320",
    "end": "1389590"
  },
  {
    "text": "era leading up to all of these\nexciting large language models. And I think these time-tested\nlessons got nicely embodied",
    "start": "1389590",
    "end": "1397090"
  },
  {
    "text": "in libraries like Torch,\nand Theano, and Chainer, and especially PyTorch.",
    "start": "1397090",
    "end": "1402740"
  },
  {
    "text": "Those things embody\nthese concepts and helps us be able to move\nmore quickly as a result.",
    "start": "1402740",
    "end": "1409950"
  },
  {
    "text": "So I wish these things\nwould carry forward, but the current moment is\nactually kind of funny. In the current\nmoment, we do a lot",
    "start": "1409950",
    "end": "1415679"
  },
  {
    "text": "of prompt templates, manual\nadjustments to prompts, and we get complete\nmodel dependence",
    "start": "1415680",
    "end": "1421470"
  },
  {
    "text": "as you just saw in those\npreceding stories, where the prompting strategy\niterated on over time by hand",
    "start": "1421470",
    "end": "1427590"
  },
  {
    "text": "ends up very tightly\nknit to whatever model we happen to be working with. And this is kind\nof tragic for me",
    "start": "1427590",
    "end": "1433650"
  },
  {
    "text": "because these time-tested\nlessons have taken us so far and it's surprising that we\nseem to have forgotten them",
    "start": "1433650",
    "end": "1439590"
  },
  {
    "text": "as we entered this new mode\nof AI system development. And that does bring us to DSPy.",
    "start": "1439590",
    "end": "1445350"
  },
  {
    "text": "DSPy is a model-- is a programming\nlibrary for moving away",
    "start": "1445350",
    "end": "1450510"
  },
  {
    "text": "from prompt engineering\nand toward language model programming. And this is a way of really\nhonoring this insight",
    "start": "1450510",
    "end": "1457980"
  },
  {
    "text": "that when you have a prompt, a\nlanguage model, and a sampling strategy, you have\ndesigned a software system.",
    "start": "1457980",
    "end": "1464230"
  },
  {
    "text": "And we would like,\nin essence, to bring the core insights of\nartificial intelligence and also software engineering\nto this new mode of AI system",
    "start": "1464230",
    "end": "1472630"
  },
  {
    "text": "development. If you haven't seen DSPy\nbefore, let me just give you a quick sense for how it works.",
    "start": "1472630",
    "end": "1478240"
  },
  {
    "text": "At the top here,\nI've got some code that sets up some\nhigh-level tools that are going to define the system.",
    "start": "1478240",
    "end": "1484190"
  },
  {
    "text": "For this example, I've\ngot Turbo as my model, I've got an index\nof Wikipedia, and I",
    "start": "1484190",
    "end": "1489639"
  },
  {
    "text": "could have other tools at my\ndisposal there, if I wanted. Those would be set\nup at a high level. And then this here, on\nthe left, dspy.Predict(",
    "start": "1489640",
    "end": "1497125"
  },
  {
    "text": "'question to answer') is a\nminimal system in DSPy for doing",
    "start": "1497125",
    "end": "1502270"
  },
  {
    "text": "basic question-answering. That's all it\ntakes, is one line. What happens under the\nhood when I actually",
    "start": "1502270",
    "end": "1508900"
  },
  {
    "text": "use that system is that\nit gets compiled down into an actual prompt to a\nlanguage model, of course,",
    "start": "1508900",
    "end": "1514880"
  },
  {
    "text": "because that's how we\ncommunicate with these language models. But you can see\nhere that there's a real difference between\nthe code that I wrote",
    "start": "1514880",
    "end": "1521950"
  },
  {
    "text": "and the thing that\ngets compiled down. The thing that I actually\nprompt the language model with is very tightly-knit to the\nparticulars of that language",
    "start": "1521950",
    "end": "1530140"
  },
  {
    "text": "model and could look different\ndepending on the tools that I had set up\nat the top here. So we've abstracted\naway, we've removed",
    "start": "1530140",
    "end": "1537250"
  },
  {
    "text": "some of that model dependence\nthat I was worried about before. That's a very simple program.",
    "start": "1537250",
    "end": "1542690"
  },
  {
    "text": "I could also write a\nmuch more complex one. This is a program for doing\nmulti-hop question-answering,",
    "start": "1542690",
    "end": "1547960"
  },
  {
    "text": "where I might want\nto gather evidence from a bunch of\ndifferent passages in order to answer a question.",
    "start": "1547960",
    "end": "1554240"
  },
  {
    "text": "As you can see here, it\nis mostly Python code. It's also adhering very tightly\nto the design principles",
    "start": "1554240",
    "end": "1560620"
  },
  {
    "text": "of PyTorch, and it's meant to\nallow you to freely express, in code, the kind of system\nthat you want to develop.",
    "start": "1560620",
    "end": "1567920"
  },
  {
    "text": "And then the really nice\naspect of all of this, in addition to these\ndesign principles, is that as a final step, I\ncould optimize this program.",
    "start": "1567920",
    "end": "1576080"
  },
  {
    "text": "And in doing that,\nI would try to find a prompting strategy that\nwas really successful given",
    "start": "1576080",
    "end": "1581860"
  },
  {
    "text": "the labeled examples\nthat I have, and also independent of whatever\ntools I had chosen up here.",
    "start": "1581860",
    "end": "1588137"
  },
  {
    "text": "And what I'm showing\noff at the bottom is an optimizer that would allow\nyou to simultaneously optimize",
    "start": "1588137",
    "end": "1593289"
  },
  {
    "text": "the instructions as well as\nthe few shot demonstrations that you were using. Those are both crucial aspects\nof successful prompting,",
    "start": "1593290",
    "end": "1601879"
  },
  {
    "text": "and this kind of moves all\nof the burden of finding good ways of doing that\nonto the optimizer, a return",
    "start": "1601880",
    "end": "1608290"
  },
  {
    "text": "to that time-tested lesson\nof data-driven optimization. And to show you how\nmuch this can matter",
    "start": "1608290",
    "end": "1615059"
  },
  {
    "text": "and how important it is to\nthink about expressing systems in these terms, I\nthought I would just highlight for you a few results\nfrom the original DSPy paper",
    "start": "1615060",
    "end": "1623880"
  },
  {
    "text": "to emphasize a few different\nthings about how important it is to think in systems terms.",
    "start": "1623880",
    "end": "1629590"
  },
  {
    "text": "So I'll have here as a kind\nof framework for evaluation the program I'm going to\nwrite and the optimizer,",
    "start": "1629590",
    "end": "1635460"
  },
  {
    "text": "and those will get paired\nwith the language model to specify a complete system.",
    "start": "1635460",
    "end": "1641470"
  },
  {
    "text": "And for the two models, I'll\nhave Turbo and Llama2-13b to show very different sizes\nand types of language model.",
    "start": "1641470",
    "end": "1650340"
  },
  {
    "text": "At the top here, I have\na real baseline system. It's the one that I\nshowed you before, where I just go from questions\nto answers, and for my optimizer",
    "start": "1650340",
    "end": "1658740"
  },
  {
    "text": "I'm just going to randomly\nselect a few shot demonstrations to help the model understand\nwhat kind of behavior",
    "start": "1658740",
    "end": "1665370"
  },
  {
    "text": "I want to see. For this baseline here, we get\nabout 34 for Turbo and 27.5",
    "start": "1665370",
    "end": "1672009"
  },
  {
    "text": "for Llama2, where\nour metric here is exact match on the\nanswer that we want to see.",
    "start": "1672010",
    "end": "1677350"
  },
  {
    "text": "So that's a baseline system. If I go up and I just do\nretrieval-augmented generation, a very simple DSPy\nprogram, I already",
    "start": "1677350",
    "end": "1685300"
  },
  {
    "text": "get a boost just from\ngathering relevant information. And if I do bootstrap few-shot\noptimization, where here, I",
    "start": "1685300",
    "end": "1692410"
  },
  {
    "text": "am using the DSPy program to\ngenerate full examples, which could include retrieved\npassages and including those",
    "start": "1692410",
    "end": "1699970"
  },
  {
    "text": "in the prompt as examples of\nthe behavior that I want to see, I get really large\ngains from my baseline--",
    "start": "1699970",
    "end": "1705250"
  },
  {
    "text": "all the way up to\n42 and 38 here. We could also think\nabout using react agents.",
    "start": "1705250",
    "end": "1710802"
  },
  {
    "text": "This is a very\ninteresting proposal for having the model\ndo some reflection and thinking about\nhow to solve the task",
    "start": "1710802",
    "end": "1716430"
  },
  {
    "text": "and break it down into pieces. This is less successful\nfor this problem, but this still shows the\npower of systems thinking,",
    "start": "1716430",
    "end": "1723610"
  },
  {
    "text": "because I have combined\nmy program here with different\noptimization strategies and, again, seen real\ngains over the baseline.",
    "start": "1723610",
    "end": "1731980"
  },
  {
    "text": "There is the nice\ntwist here that you can see the human reasoning\nprompts, the ones that were carefully written by\nhand, actually underperform",
    "start": "1731980",
    "end": "1739410"
  },
  {
    "text": "the prompts that we get\nfrom simple bootstrapping up here and also in this react\ncontext, which, again, shows",
    "start": "1739410",
    "end": "1746010"
  },
  {
    "text": "the power of\ndata-driven optimization over trying to very\nintelligently think",
    "start": "1746010",
    "end": "1752070"
  },
  {
    "text": "of your own prompting\nstrategy yourself. And then finally,\nat the bottom here, if we move to a program\nthat is designed",
    "start": "1752070",
    "end": "1759360"
  },
  {
    "text": "to do multi-hop\nreasoning, it is designed to gather evidence\nfrom multiple passages and use that to provide answers,\nwe get really good systems here.",
    "start": "1759360",
    "end": "1768440"
  },
  {
    "text": "We have gone all the way from 34\nas our baseline up to almost 55 for Turbo and seen even larger\ngains from 27.5 all the way up",
    "start": "1768440",
    "end": "1778779"
  },
  {
    "text": "to 50 for the\nsmaller model there, really showing the power not\nonly of intelligent system",
    "start": "1778780",
    "end": "1785320"
  },
  {
    "text": "design, where we think\nabout the prompting strategy and the optimizer here, but\nalso showing the power that we",
    "start": "1785320",
    "end": "1791650"
  },
  {
    "text": "can get out of small models. We have almost\nclosed the gap here and we saw larger gains\nfor the smaller of the two.",
    "start": "1791650",
    "end": "1798190"
  },
  {
    "text": "And that's a bit\nof a digression, but I think this is so\nimportant in the current moment that we think about\ndesigning systems",
    "start": "1798190",
    "end": "1804580"
  },
  {
    "text": "that can get the most juice\npossible out of small models. This is a really insightful\npost from an analyst at Theory",
    "start": "1804580",
    "end": "1812410"
  },
  {
    "text": "Ventures, and it's just\ntitled \"Small but Mighty AI,\" and it includes the observation\nthat 77% of enterprise usage",
    "start": "1812410",
    "end": "1820330"
  },
  {
    "text": "of models is at the 13 billion\nparameter size or smaller. So not the largest models\nthat get all the headlines,",
    "start": "1820330",
    "end": "1827690"
  },
  {
    "text": "but actually much smaller ones. And for a glimpse as to\nwhy that is happening, you could just think about\nthe latency numbers that",
    "start": "1827690",
    "end": "1834880"
  },
  {
    "text": "are included in this blog post. If you've worked at all\non industrial systems,",
    "start": "1834880",
    "end": "1840320"
  },
  {
    "text": "you'll know that it's very nice\nto be at the space of around 18 milliseconds for latency.",
    "start": "1840320",
    "end": "1846500"
  },
  {
    "text": "But as we move up\nto things that are more like above 50 milliseconds\nfor latency and certainly all the way up to 750 milliseconds,\nwe have real headaches here,",
    "start": "1846500",
    "end": "1855490"
  },
  {
    "text": "where at some level,\nthose headaches are going to translate into\nthis being very expensive.",
    "start": "1855490",
    "end": "1860929"
  },
  {
    "text": "And of course, that might\nbe just prohibitive. You could have a\nwonderful solution, but if it costs\ntoo much for people",
    "start": "1860930",
    "end": "1867730"
  },
  {
    "text": "to use it relative\nto what you're gaining in the rest\nof the organization, it's just a non-starter.",
    "start": "1867730",
    "end": "1873650"
  },
  {
    "text": "And again, that is pressure\nto pick the smallest models. But to get any juice out\nof those small models,",
    "start": "1873650",
    "end": "1879740"
  },
  {
    "text": "we really need to\nthink about the systems that we are designing\naround them. So your prompt will\nbe a deciding factor",
    "start": "1879740",
    "end": "1887380"
  },
  {
    "text": "in your system's performance. That's the thing that I want\nto emphasize the most here. Finally, I want to talk a\nlittle bit about tool access,",
    "start": "1887380",
    "end": "1895660"
  },
  {
    "text": "because that, as I said before,\nis where we really transparently end up thinking in\nterms of entire systems,",
    "start": "1895660",
    "end": "1901809"
  },
  {
    "text": "not just in terms of models. So this is the step where\nI'm going to actually bring in calculators and programming\nenvironments and databases",
    "start": "1901810",
    "end": "1909450"
  },
  {
    "text": "and the web and web\nAPIs and so forth. I think it's really clear,\nat this point, that these are systems, so I thought\nit would be nice to instead",
    "start": "1909450",
    "end": "1916770"
  },
  {
    "text": "of diving into the\ntechnical details, think about the\noverall consequences of designing systems\nin these terms.",
    "start": "1916770",
    "end": "1923289"
  },
  {
    "text": "So as some food for\nthought for you, let me pose a few\ndifferent questions. I'm going to offer you choices\nbetween two types of systems,",
    "start": "1923290",
    "end": "1931390"
  },
  {
    "text": "and you can reflect for\nyourselves on which system you would prefer for whatever\nyou're trying to do out there",
    "start": "1931390",
    "end": "1936900"
  },
  {
    "text": "in the world. First question, which\nis more reliable, a giant, large\nlanguage model that",
    "start": "1936900",
    "end": "1943500"
  },
  {
    "text": "embeds a snapshot of the\nentire web as of today and then it's frozen,\nor a tiny language model",
    "start": "1943500",
    "end": "1952179"
  },
  {
    "text": "working with an up-to-date\nweb search engine? Which would be more reliable?",
    "start": "1952180",
    "end": "1957610"
  },
  {
    "text": "Here's a second question. Which one would you prefer\nin some general sense, a giant large language model\ndoing contextless autocomplete",
    "start": "1957610",
    "end": "1965890"
  },
  {
    "text": "on your phone via\ncentralized service, so it's sending these completion\nmessages back and forth,",
    "start": "1965890",
    "end": "1971720"
  },
  {
    "text": "or a small model doing that\nsame autocomplete task, but locally on your\nphone or whatever,",
    "start": "1971720",
    "end": "1978530"
  },
  {
    "text": "and using your own chat history? Which would you prefer? How about this? Which one is more dangerous,\nGPT-4 with no access",
    "start": "1978530",
    "end": "1988540"
  },
  {
    "text": "to databases or the web, or a\n10 billion parameter language",
    "start": "1988540",
    "end": "1993760"
  },
  {
    "text": "model that has been instruct,\ntuned to log in to websites and has tool usage that\ngives it access to the web?",
    "start": "1993760",
    "end": "2001660"
  },
  {
    "text": "Which would be more dangerous? And then finally,\nwhat do you expect to see in 2026, massive\nfoundation models that",
    "start": "2001660",
    "end": "2009600"
  },
  {
    "text": "do math retrieval, reasoning,\nand so forth entirely in terms of their parameters and\ntheir standard computations,",
    "start": "2009600",
    "end": "2016470"
  },
  {
    "text": "or systems consisting of\nmultiple models and tools working together in\na coordinated fashion",
    "start": "2016470",
    "end": "2023429"
  },
  {
    "text": "to do things like math and\nretrieval and reasoning? Maybe in the Q&A, we can talk\nabout these questions together.",
    "start": "2023430",
    "end": "2030960"
  },
  {
    "text": "Let me start to wrap up\nhere by just offering you a few thoughts on high-level\nconsequences of all of this",
    "start": "2030960",
    "end": "2036779"
  },
  {
    "text": "for technology and society. A nice place to start here\nis this recent legislation,",
    "start": "2036780",
    "end": "2042450"
  },
  {
    "text": "SB-1047, which was vetoed by\nCalifornia's governor, Gavin Newsom.",
    "start": "2042450",
    "end": "2047650"
  },
  {
    "text": "SB-1047 sought to\ndo many things, but one of the main\nthings it tried to do was offer new regulation\nbased on the size of models.",
    "start": "2047650",
    "end": "2056060"
  },
  {
    "text": "And in particular, SB-1047 was\ngoing to regulate especially models that cost more\nthan $100 million to train",
    "start": "2056060",
    "end": "2064000"
  },
  {
    "text": "and had 10 to the 26 flops\nperformed during training. So truly a massive scale\nthat we're talking about,",
    "start": "2064000",
    "end": "2072530"
  },
  {
    "text": "whereas models of smaller\nsizes were by-and-large not going to be\nregulated by SB-1047.",
    "start": "2072530",
    "end": "2078888"
  },
  {
    "text": "Newsom vetoed this, and the\nrationale that he offered is really interesting.",
    "start": "2078889",
    "end": "2084050"
  },
  {
    "text": "He notes that smaller,\nspecialized models may emerge as\nequally or even more",
    "start": "2084050",
    "end": "2089138"
  },
  {
    "text": "dangerous than models that were\ntargeted by the legislation. I'm not sure what\nprompted him to say this,",
    "start": "2089139",
    "end": "2095210"
  },
  {
    "text": "but I think it is really wise. I think it is the\nobservation, in essence, that we could take small\nmodels and embed them",
    "start": "2095210",
    "end": "2102160"
  },
  {
    "text": "in complex systems that\nwould, as systems, do things that were really surprising.",
    "start": "2102160",
    "end": "2108325"
  },
  {
    "text": "They could be productive,\nbut they could also be quite dangerous. But the constellation of\nthose things working together",
    "start": "2108325",
    "end": "2114099"
  },
  {
    "text": "in a system could be more\ndangerous than a very expensive model that was just\nsitting there on-disk,",
    "start": "2114100",
    "end": "2119480"
  },
  {
    "text": "unable to access the web and\ndo other things that are really going to get us into trouble.",
    "start": "2119480",
    "end": "2124720"
  },
  {
    "text": "So ultimately, I think this\nwas a wise decision and points toward the idea that\nfuture legislation should",
    "start": "2124720",
    "end": "2130269"
  },
  {
    "text": "be oriented around\nsystems, not around models. ",
    "start": "2130270",
    "end": "2135920"
  },
  {
    "text": "We could also think about\nthe consequences for research and in particular for the kinds\nof comparative evaluations",
    "start": "2135920",
    "end": "2141530"
  },
  {
    "text": "that we conduct. There are lots of\nleaderboards out there that are meant to rank\ndifferent language models.",
    "start": "2141530",
    "end": "2146880"
  },
  {
    "text": "This is one from Hugging\nFace, this is Chatbot Arena, and we have Helm from Stanford. And all of the entrants\nin these things",
    "start": "2146880",
    "end": "2153290"
  },
  {
    "text": "are nominally listed\nas individual models. But of course, you can't\nactually evaluate a model.",
    "start": "2153290",
    "end": "2160320"
  },
  {
    "text": "You can only evaluate a system. Under the hood here,\nwe have to have at least a prompting strategy,\na model and some procedure",
    "start": "2160320",
    "end": "2168230"
  },
  {
    "text": "for generation,\nthe minimal system. And I can't help but feel that\nthis is not quite the thing",
    "start": "2168230",
    "end": "2173960"
  },
  {
    "text": "that we want to be evaluating. For my F1 race car\nanalogy, this is as though we were running\nraces that really were just",
    "start": "2173960",
    "end": "2181490"
  },
  {
    "text": "engines with wheels. If you want to run a race\nof engines with wheels,",
    "start": "2181490",
    "end": "2187170"
  },
  {
    "text": "that might be a sensible\nthing for you to do. But we should be clear-sighted\nabout the fact that is probably",
    "start": "2187170",
    "end": "2192800"
  },
  {
    "text": "not the thing that we\nthink we are doing. What we really want to do is\nthink about these language",
    "start": "2192800",
    "end": "2198150"
  },
  {
    "text": "models as components\nin larger systems, and so I would kind of\nexhort the community to reorient all of these\nleaderboard evaluations",
    "start": "2198150",
    "end": "2206010"
  },
  {
    "text": "around entire systems. We could give privileged\nplace to the language models if we want to as important\ncomponents there,",
    "start": "2206010",
    "end": "2212950"
  },
  {
    "text": "but we should really think about\nall the pieces working together in constellation because\nthat's the relevant thing",
    "start": "2212950",
    "end": "2219510"
  },
  {
    "text": "to be asking when we think\nabout these technologies being deployed out in the world.",
    "start": "2219510",
    "end": "2225710"
  },
  {
    "text": "Final slide here,\nand this is kind of a prediction\nabout the future, so this is also something that\nyou might think about and ask",
    "start": "2225710",
    "end": "2231620"
  },
  {
    "text": "questions about. I'm just reflecting on\nthese last five or so years",
    "start": "2231620",
    "end": "2236720"
  },
  {
    "text": "and what has happened, and\nwhat I think we see already is a few different\nnotions of scaling",
    "start": "2236720",
    "end": "2243740"
  },
  {
    "text": "in play as driving forces\nbehind all of the progress that we've seen happen so fast.",
    "start": "2243740",
    "end": "2249450"
  },
  {
    "text": "Starting in 2020\nwith the GPT-3 paper, we began the era of scaling\nunsupervised training.",
    "start": "2249450",
    "end": "2256550"
  },
  {
    "text": "That is just taking a\nreally big language model and have it learn to imitate\nall the data on the web and all",
    "start": "2256550",
    "end": "2263210"
  },
  {
    "text": "the data that you\ncan find, indeed. We continue to live in an era in\nwhich scaling up these processes",
    "start": "2263210",
    "end": "2269570"
  },
  {
    "text": "is showing some gains, but\nI believe that on its own, this is not showing\nthe kind of gains",
    "start": "2269570",
    "end": "2274910"
  },
  {
    "text": "that we're seeing overall in AI. Those gains now are being\ndriven, at least in part,",
    "start": "2274910",
    "end": "2281070"
  },
  {
    "text": "by scaling up in\na different sense. This is scaling up\ninstruct fine tuning. Starting in about 2022\nwith especially ChatGPT,",
    "start": "2281070",
    "end": "2289170"
  },
  {
    "text": "we saw the power of having\nlarge teams of very smart humans create good input-output pairs\nthat we can use to update models",
    "start": "2289170",
    "end": "2297569"
  },
  {
    "text": "so that they learn\nparticular things and acquire particular skills. And again, we continue to live\nin an era in which scaling",
    "start": "2297570",
    "end": "2305310"
  },
  {
    "text": "these things up is\nleading to gains, but we think we see also that\nit's not a silver bullet,",
    "start": "2305310",
    "end": "2311200"
  },
  {
    "text": "and that has led very recently\nto a rise in the first theme that I mentioned. If you think about\nsampling for generation,",
    "start": "2311200",
    "end": "2318790"
  },
  {
    "text": "we're now seeing very\nsophisticated forms of sampling for generation\nthat you could think of as kind",
    "start": "2318790",
    "end": "2325170"
  },
  {
    "text": "of scaling up of inference\ntime processing search that you might do on your way\nto producing an answer to a user",
    "start": "2325170",
    "end": "2332369"
  },
  {
    "text": "query. And I think that's going to\ncontinue from 2024 onward. But here's the final prediction.",
    "start": "2332370",
    "end": "2339230"
  },
  {
    "text": "As we really think\nabout the future, we are going to see\nscaling up of systems. Transformative things are going\nto happen in virtue of the fact",
    "start": "2339230",
    "end": "2347140"
  },
  {
    "text": "that we take perfectly good\nlanguage models, maybe even small ones, if we're thinking\nabout high-volume services,",
    "start": "2347140",
    "end": "2353890"
  },
  {
    "text": "and give them access in\nproductive ways to lots of different tools and\nother things that make",
    "start": "2353890",
    "end": "2359470"
  },
  {
    "text": "them really capable as systems. That's my prediction\nabout the future.",
    "start": "2359470",
    "end": "2364850"
  },
  {
    "text": "I think you should join me in\nmoving from LLM thinking to full on system thinking,\nbecause I think",
    "start": "2364850",
    "end": "2370480"
  },
  {
    "text": "it will make you more\nproductive in your work and lead to bigger\ngains, just like I'm predicting for 2025 and beyond.",
    "start": "2370480",
    "end": "2378460"
  },
  {
    "text": "So I'll stop there. Thank you very much. I'm eager to hear your\nquestions and comments. PETRA PARIKOVA: Thank\nyou so much, Chris.",
    "start": "2378460",
    "end": "2385060"
  },
  {
    "text": "Amazing, so wonderful\nto hear from you again. Like always, I learn so much. We got a bunch of questions.",
    "start": "2385060",
    "end": "2392090"
  },
  {
    "text": "Hopefully, more\nof those will keep coming up as we have this\nQ&A part of the session.",
    "start": "2392090",
    "end": "2397880"
  },
  {
    "text": "Maybe the first one is more\nabout the understanding of the compound systems\nand the relationship",
    "start": "2397880",
    "end": "2404440"
  },
  {
    "text": "to generative agents. So this question\ncame up a few times, how do generative agents\nplay into this whole thing?",
    "start": "2404440",
    "end": "2411967"
  },
  {
    "text": "CHRISTOPHER POTTS: Agents, yeah. So that could be a\nkind of technique that you use to take\na language model and have it not only do\nthings that it couldn't",
    "start": "2411967",
    "end": "2419200"
  },
  {
    "text": "do in simple\ngeneration on its own, but also could be the key\nthing that bridges you into having that language\nmodel make use of tools",
    "start": "2419200",
    "end": "2427030"
  },
  {
    "text": "and also make use\nof tool output. And so I think that really\nis systems thinking.",
    "start": "2427030",
    "end": "2432770"
  },
  {
    "text": "And I would encourage people\nnot necessarily to be purists. If you think about this\nas a software system,",
    "start": "2432770",
    "end": "2439070"
  },
  {
    "text": "you could design an agent\nthat was entirely dependent on the model doing complex\nthings in generation and really nailing whatever\nproblem you've set up for it,",
    "start": "2439070",
    "end": "2446720"
  },
  {
    "text": "but you could also write some\ncode that would help bridge the gaps between the\nlanguage models' capabilities",
    "start": "2446720",
    "end": "2452410"
  },
  {
    "text": "and the thing that\nyou want to see. If you're designing a system,\nthat's a very natural thing to play with, and I think we\ncould test this by the results",
    "start": "2452410",
    "end": "2460000"
  },
  {
    "text": "that you achieve. PETRA PARIKOVA:\nThank you so much. Near the beginning\nof the talk, you",
    "start": "2460000",
    "end": "2466560"
  },
  {
    "text": "mentioned that modern\nAI systems are already producing multiple reasoning\npaths in the background.",
    "start": "2466560",
    "end": "2472300"
  },
  {
    "text": "How does the system\nproduce reasoning paths, and how can we give users more\naccess to the inner workings",
    "start": "2472300",
    "end": "2478530"
  },
  {
    "text": "of these systems to help\nthem evaluate the results?\" CHRISTOPHER POTTS:\nYeah, interesting. There are a few layers to this.",
    "start": "2478530",
    "end": "2484332"
  },
  {
    "text": "The thing that I was referring\nto with the majority completion, that really kicked off with\nthe advent of chain-of-thought",
    "start": "2484332",
    "end": "2490710"
  },
  {
    "text": "methods, like \"let's\nthink by step-by-step.\" And that was just the simple\nobservation that if you had",
    "start": "2490710",
    "end": "2496440"
  },
  {
    "text": "a model go through that, prompt\nit with \"let's think step by step\" and let it\ngenerate tokens in response,",
    "start": "2496440",
    "end": "2502900"
  },
  {
    "text": "the process of producing\nall those tokens, in ways that we don't\nfully understand, often led it to more\nreliable answers.",
    "start": "2502900",
    "end": "2510510"
  },
  {
    "text": "And we see now in\nretrospect that was just the tip of the iceberg\nin terms of what's possible,",
    "start": "2510510",
    "end": "2516640"
  },
  {
    "text": "because I could have it do\nchain-of-thought to generate an intermediate answer,\nwhich could, itself, generate",
    "start": "2516640",
    "end": "2522430"
  },
  {
    "text": "chain-of-thought reasoning. And I could have lots and lots\nof inference paths leading to lots of different\noutcomes, and then",
    "start": "2522430",
    "end": "2528970"
  },
  {
    "text": "think about doing statistical\nanalysis of all those outputs to decide on a final generation.",
    "start": "2528970",
    "end": "2535280"
  },
  {
    "text": "And that's a real playground of\ndifferent ideas that you could play with, different\ntechniques that you could use,",
    "start": "2535280",
    "end": "2540559"
  },
  {
    "text": "and it really is systems\nthinking because you're going to now think about\nthe prompt that came in, the structure of\nthe overall system,",
    "start": "2540560",
    "end": "2547040"
  },
  {
    "text": "which might even have multiple\nlanguage models working together, and also think about\nhow you're going to actually do",
    "start": "2547040",
    "end": "2552370"
  },
  {
    "text": "these generations, what\nkind of sampling method you're going to use, and\nit adds that twist of, how are you going to\ndecide on the final answer?",
    "start": "2552370",
    "end": "2559549"
  },
  {
    "text": "In my illustration, it was the\nmost common occurring answer across all the reasoning\npaths, but you could even",
    "start": "2559550",
    "end": "2565089"
  },
  {
    "text": "think about different\nvariants of that idea. And I think that we've seen\na kind of culmination of this",
    "start": "2565090",
    "end": "2570790"
  },
  {
    "text": "in the OpenAI announcements\nof its 4o1 models,",
    "start": "2570790",
    "end": "2576040"
  },
  {
    "text": "which are clearly doing lots of\ninference time work before they produce an answer for you.",
    "start": "2576040",
    "end": "2581210"
  },
  {
    "text": "Part of the question was how\nwe could expose more of that. I think OpenAI is not going\nto expose more of this.",
    "start": "2581210",
    "end": "2587000"
  },
  {
    "text": "I think they regard\nthese as trade secrets, but you could explore\nwith smaller models",
    "start": "2587000",
    "end": "2592360"
  },
  {
    "text": "to see what kind of behaviors\nyou can coax out of them. And I think a lot\nof this is going to start to be explored in\nthe research literature going",
    "start": "2592360",
    "end": "2599980"
  },
  {
    "text": "forward. PETRA PARIKOVA:\nThank you so much. The next question\nis about challenges",
    "start": "2599980",
    "end": "2607220"
  },
  {
    "text": "to solve or to reach the\nsystem-level scaling. What do you see is still\nmissing or the most challenging",
    "start": "2607220",
    "end": "2613160"
  },
  {
    "text": "to get there? What would you point out? CHRISTOPHER POTTS:\nAh, so that's kind of like, what is going to\nhappen in 2025 and beyond",
    "start": "2613160",
    "end": "2621530"
  },
  {
    "text": "in terms of scaling systems. I mean, they will just\nget ever more complex. You could think-- A\nparadigm case of this",
    "start": "2621530",
    "end": "2627920"
  },
  {
    "text": "would be Google search. We have some precedent for\nthis, where at some level, that began from a very simple\nsearch technology, where they",
    "start": "2627920",
    "end": "2634670"
  },
  {
    "text": "were just indexing pages\non the web, and that, by now, 2024, that is probably\nsuch a complicated software",
    "start": "2634670",
    "end": "2640970"
  },
  {
    "text": "system that no one\nindividual could even begin to understand it. But it still\nfunctions as a result",
    "start": "2640970",
    "end": "2646670"
  },
  {
    "text": "of teams of people and\nlots of dynamical behavior. And we're just at the starting\npoint for these gen AI systems.",
    "start": "2646670",
    "end": "2654180"
  },
  {
    "text": "They look like Google did\nin probably the year 2001. And so over the next\ndecades, I think",
    "start": "2654180",
    "end": "2660620"
  },
  {
    "text": "we're going to see just\nincredible systems built up. And I think the thing to\nwatch is when people actually",
    "start": "2660620",
    "end": "2667910"
  },
  {
    "text": "do provide lots of tool access. So essentially, these language\nmodels become like you or me",
    "start": "2667910",
    "end": "2675080"
  },
  {
    "text": "as we cruise around on the\nweb, with the capability to try different pages,\nlog into different systems,",
    "start": "2675080",
    "end": "2682840"
  },
  {
    "text": "communicate with people\non social networks. When that really starts to\nhappen in a very free-form way",
    "start": "2682840",
    "end": "2690059"
  },
  {
    "text": "that maybe even the system\ndesigners don't understand, we are sure to see consequential\nthings happen in the world.",
    "start": "2690060",
    "end": "2696940"
  },
  {
    "text": "And you can probably\nhear in my tone of voice that I think some of those will\nbe productive and some of those will be quite problematic.",
    "start": "2696940",
    "end": "2704520"
  },
  {
    "text": "But you can just predict that\nit's going to be consequential.",
    "start": "2704520",
    "end": "2710410"
  },
  {
    "text": "PETRA PARIKOVA: There is also\na follow-up question on that. And what are the\nrecommended guardrails? How should we thinking about--",
    "start": "2710410",
    "end": "2718150"
  },
  {
    "text": "thinking also not about just\nthe positive consequences, but possibly also\nnegative consequences,",
    "start": "2718150",
    "end": "2723529"
  },
  {
    "text": "how to establish\nthe guardrails, like what might we be needing to\nthink about at this point. CHRISTOPHER POTTS: Yeah.",
    "start": "2723530",
    "end": "2728540"
  },
  {
    "text": "That is a wonderful\nquestion, and I'm not a regulator or\na lawyer, but if I",
    "start": "2728540",
    "end": "2734260"
  },
  {
    "text": "were, this would be where I\nwould focus all of my attention. As I said, I think focusing\non the language models",
    "start": "2734260",
    "end": "2739810"
  },
  {
    "text": "is going to miss the mark. But I think if we think\nabout regulating the systems, we're more likely to get\nit right for a few reasons.",
    "start": "2739810",
    "end": "2746320"
  },
  {
    "text": "First, we just already\nhave legislation that governs how these systems\ncan behave, indeed, how",
    "start": "2746320",
    "end": "2751510"
  },
  {
    "text": "any software system can behave. And I frankly think\na lot more of that is going to carry over\ninto the gen AI realm",
    "start": "2751510",
    "end": "2757869"
  },
  {
    "text": "than we currently\ngive it credit for. We could also think\nabout human aspects",
    "start": "2757870",
    "end": "2763720"
  },
  {
    "text": "to this, like guarantees\nthat these systems need to identify themselves as\nnon-human as they interact",
    "start": "2763720",
    "end": "2770569"
  },
  {
    "text": "with us, because I think that\nhelps us, as people, figure out how to calibrate\nto them as agents,",
    "start": "2770570",
    "end": "2776310"
  },
  {
    "text": "and it could also help us\ncontrol the situations that we allow them to enter into.",
    "start": "2776310",
    "end": "2781880"
  },
  {
    "text": "But there might\nalso just need to be some fundamental\nrestrictions on,",
    "start": "2781880",
    "end": "2787170"
  },
  {
    "text": "for example, whether\nor not we allow these models to log into\ncertain kinds of websites or interact freely on some\nkinds of social networks.",
    "start": "2787170",
    "end": "2795300"
  },
  {
    "text": "I'm not sure I'm taking a\nkind of wait-and-see attitude, and I guess I'm hoping that\nthe initial disasters are not",
    "start": "2795300",
    "end": "2802940"
  },
  {
    "text": "cataclysmic so that\nwe can learn from them and figure out how to\nrespond as a society.",
    "start": "2802940",
    "end": "2809750"
  },
  {
    "text": "PETRA PARIKOVA:\nThank you so much. There are few questions about\nconsequences for individuals.",
    "start": "2809750",
    "end": "2817560"
  },
  {
    "text": "So we talked briefly\nabout how this can influence the\ntechnology and the society, like how can people think\nabout this for themselves.",
    "start": "2817560",
    "end": "2824640"
  },
  {
    "text": "There was a question,\nactually, which was phrased, how\nmight this influence a kind of normal person like\nme in the next five years?",
    "start": "2824640",
    "end": "2833190"
  },
  {
    "text": "What would you say to that? CHRISTOPHER POTTS:\nOh, I think it's going to impact all of our lives. I think if we weren't\neven thinking about AI,",
    "start": "2833190",
    "end": "2840480"
  },
  {
    "text": "it would still impact\nour lives because we're going to see more\nand more systems that can help us in our daily lives.",
    "start": "2840480",
    "end": "2846540"
  },
  {
    "text": "And again, a language\nmodel on its own is not going to help you\nvery much at all because it is kind of inert.",
    "start": "2846540",
    "end": "2852090"
  },
  {
    "text": "But a language model\nembedded in a system that has prompting strategies\nand access to tools",
    "start": "2852090",
    "end": "2857240"
  },
  {
    "text": "could be something that\nhelps you with low level tasks in your lives. It could also help\nyou with doing",
    "start": "2857240",
    "end": "2863420"
  },
  {
    "text": "interactional things,\ncompanionship, discovery of new ideas,\ncreative expression.",
    "start": "2863420",
    "end": "2870059"
  },
  {
    "text": "I think we're going to find\nsystems that can help us with all those things. And that's the bright point,\nand also things like education.",
    "start": "2870060",
    "end": "2876960"
  },
  {
    "text": "I think I'm a big booster\non the idea that there's about to be breakthroughs\nin terms of the education experiences we can provide\nin a customized way",
    "start": "2876960",
    "end": "2884210"
  },
  {
    "text": "at low costs because of gen AI. But there are also going\nto be bad actors that try to do things\nlike social engineer",
    "start": "2884210",
    "end": "2890780"
  },
  {
    "text": "their way into getting our\nusernames and passwords, right? That is the dark side of\ngiving them a capability",
    "start": "2890780",
    "end": "2898500"
  },
  {
    "text": "to log into websites\nand something like a goal of doing so. If we leave them\nunfettered, they",
    "start": "2898500",
    "end": "2904830"
  },
  {
    "text": "might do really surprising\nthings in response to that goal. So we're going to also have\nto, as individuals in society,",
    "start": "2904830",
    "end": "2911650"
  },
  {
    "text": "just be on the lookout\nfor AI systems run amok. ",
    "start": "2911650",
    "end": "2918323"
  },
  {
    "text": "PETRA PARIKOVA:\nThere are a couple of directions people are asking\nabout how they can learn more",
    "start": "2918323",
    "end": "2925890"
  },
  {
    "text": "about this. So one of the groups of\npeople, at least I'm seeing, is very technical. So they are trying to\nlearn more about DSPy",
    "start": "2925890",
    "end": "2933480"
  },
  {
    "text": "and what you are\nrecommending here. The other part is leaders\nand business leaders,",
    "start": "2933480",
    "end": "2938820"
  },
  {
    "text": "and they are not\nsure how to grasp what this could mean for the\nbusinesses and leadership",
    "start": "2938820",
    "end": "2944010"
  },
  {
    "text": "thinking. Do you have\nrecommendation for both? CHRISTOPHER POTTS:\nOh, fascinating.",
    "start": "2944010",
    "end": "2949450"
  },
  {
    "text": "In terms of general education,\nfor DSPy, we have a Discord and we have lots of tutorials.",
    "start": "2949450",
    "end": "2955630"
  },
  {
    "text": "And I think one wonderful\nway to get involved in an open-source\nproject like that is to file issues or even\nmake PRs that might turn",
    "start": "2955630",
    "end": "2963750"
  },
  {
    "text": "into contributions,\nbecause that's a way to introduce\nyourself to the community and begin to have\na positive impact",
    "start": "2963750",
    "end": "2969390"
  },
  {
    "text": "and learn about\nthe kind of things that are on people's minds. Maybe the first stop\nthere is the Discord. It's thriving and give you a\nsense for the kinds of things",
    "start": "2969390",
    "end": "2977310"
  },
  {
    "text": "people are working on. Some of them are\nworking in teams, and you could think about\njoining forces with them.",
    "start": "2977310",
    "end": "2982970"
  },
  {
    "text": "So that's wide open. The research community\nis also wide open. I do think there are wonderful\nthings on YouTube that",
    "start": "2982970",
    "end": "2989320"
  },
  {
    "text": "could help you think about\ndifferent prompting strategies, agents, tool usage. A lot of the themes\nthat I touched on today",
    "start": "2989320",
    "end": "2996010"
  },
  {
    "text": "can be unpacked into\nentire courses, frankly, but YouTube is pretty\ngood about that.",
    "start": "2996010",
    "end": "3001980"
  },
  {
    "text": "In terms of understanding\nwhat's happening in industry, unfortunately, it seems things\nare getting increasingly closed",
    "start": "3001980",
    "end": "3009119"
  },
  {
    "text": "and we're losing\na lot of insight into exactly the\ndecisions they're making and why they're making those\ndecisions and so forth, even",
    "start": "3009120",
    "end": "3015930"
  },
  {
    "text": "at the level of\nresearch innovation. And then if you're, yourself,\na leader in an organization",
    "start": "3015930",
    "end": "3022770"
  },
  {
    "text": "thinking about how you would\ndefine a generative AI strategy, that's probably worth\nits own separate lecture.",
    "start": "3022770",
    "end": "3031560"
  },
  {
    "text": "But there are some things\nthat I could offer as advice, and I think maybe\nthe main thing would be to, early on, think\nabout what success is going",
    "start": "3031560",
    "end": "3039438"
  },
  {
    "text": "to look like and\nwhat kind of testing you're going to\ndo so that that's a guided process with\nsome clear goals in mind.",
    "start": "3039438",
    "end": "3046300"
  },
  {
    "text": "And then you can think about\ndesigning a system that balances the thing you're trying\nto achieve against the known",
    "start": "3046300",
    "end": "3052769"
  },
  {
    "text": "risks of deploying a\nsystem in the current era. ",
    "start": "3052770",
    "end": "3058672"
  },
  {
    "text": "PETRA PARIKOVA: Great. Thank you so much. There are also people asking-- There's a lot of information,\nas you mentioned,",
    "start": "3058673",
    "end": "3065260"
  },
  {
    "text": "like you showed a nice slide\nwith just Twitter or X kind of running. How do you get\ninformation and up-to-date",
    "start": "3065260",
    "end": "3072930"
  },
  {
    "text": "with what's going\non in the field? What would you\nrecommend somebody, they have maybe 10\nminutes a day to deal",
    "start": "3072930",
    "end": "3079500"
  },
  {
    "text": "with what's going in the field. What would you recommend people,\nand also what do you, yourself, follow and find\nimportant to learn about?",
    "start": "3079500",
    "end": "3088680"
  },
  {
    "text": "CHRISTOPHER POTTS: Yes. I feel some sense\nof loss about this because four or five\nyears ago, Twitter",
    "start": "3088680",
    "end": "3094950"
  },
  {
    "text": "was my go-to resource for this. My timeline was full of people\nannouncing papers and discussing",
    "start": "3094950",
    "end": "3101160"
  },
  {
    "text": "papers and it was a\ngreat way to filter, to get a sense for\nwhat was important",
    "start": "3101160",
    "end": "3106320"
  },
  {
    "text": "and what kind of innovative\nthings were happening. Because of changes\nat Twitter, now X, it",
    "start": "3106320",
    "end": "3111600"
  },
  {
    "text": "feels less vibrant\nin that regard and it seems like the\ncommunities have spread out into Bluesky and\nThreads and Mastodon.",
    "start": "3111600",
    "end": "3120839"
  },
  {
    "text": "So that's less reliable. One nice thing about this--\nthis is kind of meta--",
    "start": "3120840",
    "end": "3126010"
  },
  {
    "text": "but with the rise of generative\nAI and in particular systems that can do retrieval augmented\ngeneration into research papers,",
    "start": "3126010",
    "end": "3133750"
  },
  {
    "text": "you can often begin to get a\nsense for an area by simply typing a common sense question\nlike \"what is deep learning\"",
    "start": "3133750",
    "end": "3140040"
  },
  {
    "text": "or \"what is chain-of-thought\"\ninto some search engines like ChatGPT, which does\nsearch functions now.",
    "start": "3140040",
    "end": "3147150"
  },
  {
    "text": "I saw that there's a new\ntool from Semantic Scholar at the Allen Institute\nthat does this, and I think that could be\nvery productive in terms",
    "start": "3147150",
    "end": "3154330"
  },
  {
    "text": "of getting a sense for what's\nhappening in the literature and where to begin\nin terms of papers",
    "start": "3154330",
    "end": "3159580"
  },
  {
    "text": "to check out and so forth. NLP is kind of easy\nfor this because it's a very organized community\nin terms of its literature.",
    "start": "3159580",
    "end": "3166940"
  },
  {
    "text": "If you go to the ACL\nanthology, that pretty much includes every NLP paper and you\ncould use those search functions",
    "start": "3166940",
    "end": "3174250"
  },
  {
    "text": "together with\ncitation information to get a sense in a given area\nfor what's most influential",
    "start": "3174250",
    "end": "3179980"
  },
  {
    "text": "and what the latest things are. And that's a nice chance also\nto push the course that Petra",
    "start": "3179980",
    "end": "3185829"
  },
  {
    "text": "and I do, Natural\nLanguage Understanding, which includes a project\ndevelopment phase that includes the technique of\nbuilding a good literature",
    "start": "3185830",
    "end": "3193630"
  },
  {
    "text": "review, kind of forming\nan experimental protocol, and then writing a paper maybe\nwith some associated code.",
    "start": "3193630",
    "end": "3199760"
  },
  {
    "text": "And that is a kind of guided way\nto do a focused research project and get a sense for the rhythms\nof research in the domain.",
    "start": "3199760",
    "end": "3206579"
  },
  {
    "text": " PETRA PARIKOVA: Great. Thank you. Maybe we can take one or two\nmore questions, shorter ones.",
    "start": "3206580",
    "end": "3216430"
  },
  {
    "text": "So one of them is,\n\"Is DSPy getting traction in the business world?",
    "start": "3216430",
    "end": "3221500"
  },
  {
    "text": "My engineering team is\nvery focused on LangChain, but I'm trying to open their\neyes to what DSPy offers.\"",
    "start": "3221500",
    "end": "3227212"
  },
  {
    "text": "And we have gotten\nactually this question a few times about LangChain and\nwhere to look and what to do.",
    "start": "3227212",
    "end": "3233780"
  },
  {
    "text": "Do you have some recommendation\nor your input to this question? CHRISTOPHER POTTS: Yeah. I would check out--",
    "start": "3233780",
    "end": "3239460"
  },
  {
    "text": "So DSPy.ai is the website. It's got documentation. It also lists out use cases.",
    "start": "3239460",
    "end": "3245592"
  },
  {
    "text": "One nice thing about\nthose is that many of them are blog posts from\nvarious organizations, from JetBlue down to very\nnew and small startups that",
    "start": "3245592",
    "end": "3253460"
  },
  {
    "text": "have been using DSPy\nin various ways, and that could give you\na sense for the coding",
    "start": "3253460",
    "end": "3258470"
  },
  {
    "text": "patterns and the\nkind of problems that people have tackled and\nalso plenty of starter code.",
    "start": "3258470",
    "end": "3264730"
  },
  {
    "text": "And then I think\nat a high level, whether you use DSPy or\nnot, it could be LangChain, but I think the thing to do\nif you're just starting out,",
    "start": "3264730",
    "end": "3272029"
  },
  {
    "text": "is make some principled choices. It's very tempting,\nat this point, to begin with some\nprompt templates,",
    "start": "3272030",
    "end": "3278930"
  },
  {
    "text": "and I think that can be\nvery productive in terms of teaching you\nthings, but the problem is that you might look\nback in six months",
    "start": "3278930",
    "end": "3285040"
  },
  {
    "text": "and find that you have\ndesigned, in some sense, a system entirely around\nthese prompt templates.",
    "start": "3285040",
    "end": "3290180"
  },
  {
    "text": "But now any change that you want\nto make is almost impossible and it has unintended\nconsequences",
    "start": "3290180",
    "end": "3296320"
  },
  {
    "text": "throughout the system, and then\nyou have that dreaded moment, which I alluded to,\nwhere somebody says,",
    "start": "3296320",
    "end": "3302420"
  },
  {
    "text": "you can't use Claude anymore. You have to use these OpenAI\nmodels or these Llama models,",
    "start": "3302420",
    "end": "3308089"
  },
  {
    "text": "and what you discover is that\nnow everything is broken, and that really does mean\ngoing back to step zero",
    "start": "3308090",
    "end": "3314350"
  },
  {
    "text": "and rewriting all\nthese prompt templates. You have to avoid\nthat failure mode. If you're already entrenched\nin prompt templates,",
    "start": "3314350",
    "end": "3320932"
  },
  {
    "text": "you might just have\nto live with that and try to get\nout of it somehow. But if you are\njust starting out, do something that will involve\nexpressing these things",
    "start": "3320932",
    "end": "3328520"
  },
  {
    "text": "as proper software systems. And I do think DSPy is\na great choice for that.",
    "start": "3328520",
    "end": "3334250"
  },
  {
    "text": "It's specially\ntailored to people who are really experienced\nin machine learning. It has many of those\nPyTorch principles",
    "start": "3334250",
    "end": "3341450"
  },
  {
    "text": "that I alluded to\nbefore, so there could be a bit of a\nlearning curve at the start, but I think the\ninvestment will pay off",
    "start": "3341450",
    "end": "3347990"
  },
  {
    "text": "in terms of ultimately\nending up with a system that is very flexible and\nadaptable and can respond",
    "start": "3347990",
    "end": "3354740"
  },
  {
    "text": "to new requirements and changes\nin the underlying environment that you're working in.",
    "start": "3354740",
    "end": "3361137"
  },
  {
    "text": "PETRA PARIKOVA: Thank you. And last kind of\nsummary question, if people should take one thing\nfrom this talk, one fact, one",
    "start": "3361137",
    "end": "3370140"
  },
  {
    "text": "information that you\nfind the most important, even if they forget everything\nelse, what would it be? What would you recommend?",
    "start": "3370140",
    "end": "3377220"
  },
  {
    "text": "CHRISTOPHER POTTS:\nI think it really is to just avoid the\ntrap of thinking entirely in terms of models.",
    "start": "3377220",
    "end": "3383180"
  },
  {
    "text": "We're all doing it,\nand I feel like it's a trick we're pulling on\nourselves because we always talk about the latest\nmodel releases,",
    "start": "3383180",
    "end": "3389470"
  },
  {
    "text": "and we even talk about\nthings that are clearly software systems, like ChatGPT,\nas though they were models",
    "start": "3389470",
    "end": "3395310"
  },
  {
    "text": "when in fact, they are not. And so if you just embrace\nthe fact that it's a system,",
    "start": "3395310",
    "end": "3400770"
  },
  {
    "text": "that will mean that you\nconcentrate your energy, not just on the model\nchoice or its properties,",
    "start": "3400770",
    "end": "3405880"
  },
  {
    "text": "but also on the other things\nthat are so consequential. And in that way, you'll be\nlike that F1 race car design",
    "start": "3405880",
    "end": "3412980"
  },
  {
    "text": "team that, of\ncourse, is focusing on much more than just the\nengine because it is an effort",
    "start": "3412980",
    "end": "3418680"
  },
  {
    "text": "to try to get all of\nthose complicated pieces to work in concert to do\nsomething really difficult.",
    "start": "3418680",
    "end": "3423940"
  },
  {
    "text": "And so I think, intrinsically,\nthat's just a better perspective to have. And then if you think about\nthat note about what's",
    "start": "3423940",
    "end": "3430869"
  },
  {
    "text": "happening in industry,\nwhere most of the energy is focused on small models,\nthis is especially important",
    "start": "3430870",
    "end": "3436540"
  },
  {
    "text": "because with a small\nmodel, you can't rely on simplistic\nsystem design,",
    "start": "3436540",
    "end": "3442000"
  },
  {
    "text": "a simple prompting strategy. You have to do\neverything you can to get that relatively\nsmall thing to do",
    "start": "3442000",
    "end": "3448900"
  },
  {
    "text": "a big thing in the world,\nand that really does place more pressure on system design.",
    "start": "3448900",
    "end": "3454000"
  },
  {
    "text": "But as you can tell, I think\nthat pressure is actually just a huge opportunity.",
    "start": "3454000",
    "end": "3460262"
  },
  {
    "text": "PETRA PARIKOVA: Thank\nyou so much, Chris. Thank you so much\nfor making the time. Thank you for all the\nwonderful questions.",
    "start": "3460262",
    "end": "3465810"
  },
  {
    "text": "We couldn't get to all, but\nwe tried to at least cover most of them on a higher level. Appreciate everybody joining.",
    "start": "3465810",
    "end": "3472470"
  },
  {
    "text": "We will post this on YouTube. Also, we will share the\nrecording of this session. So thank you again, and\nhave a wonderful day.",
    "start": "3472470",
    "end": "3479309"
  },
  {
    "text": "CHRISTOPHER POTTS:\nThank you, Petra, and thanks to everyone\nfor all those questions. This was really a\nwonderful discussion.",
    "start": "3479310",
    "end": "3485590"
  }
]
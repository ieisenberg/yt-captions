[
  {
    "text": "Hi, everyone. Happy Monday. Today is the last lecture before\nwe move into reinforcement",
    "start": "5379",
    "end": "13220"
  },
  {
    "text": "learning topics. As a couple of course\nreminders, tomorrow at 5:00 PM we have a tutorial\non value-based RL.",
    "start": "13220",
    "end": "20840"
  },
  {
    "text": "This should be kind of\na refresher for people who are a little bit less\nfamiliar with reinforcement learning and uncover the\nkinds of things that you--",
    "start": "20840",
    "end": "29015"
  },
  {
    "text": "the kinds of reinforcement\nlearning basics that you would see in classes\nlike CS 221 or CS 229.",
    "start": "29015",
    "end": "36470"
  },
  {
    "text": "On Wednesday, the\nproject proposal is due. Like I mentioned before, we're\ngrading these very lightly.",
    "start": "36470",
    "end": "42079"
  },
  {
    "text": "The goal is really primarily\nfor your own benefit to give you feedback on\nthe proposal and so forth.",
    "start": "42080",
    "end": "50520"
  },
  {
    "text": "And then, Monday next\nweek homework 2 is due. And then homework\n3 will be released.",
    "start": "50520",
    "end": "55475"
  },
  {
    "text": "Any logistical questions?",
    "start": "58180",
    "end": "59610"
  },
  {
    "text": "Cool. So for today, we're\ngoing to be talking about Bayesian meta-learning. And first, we'll talk about why\nit can be useful to be Bayesian",
    "start": "63760",
    "end": "72180"
  },
  {
    "text": "and what that sort of\nthinking allows us to do. We'll talk about Bayesian\nmeta-learning approaches,",
    "start": "72180",
    "end": "78210"
  },
  {
    "text": "including black-box\napproaches and optimization-based approaches. And then, we'll also talk\nabout how we can evaluate",
    "start": "78210",
    "end": "84509"
  },
  {
    "text": "Bayesian meta-learners. The goals for the\nlecture are to be able to understand the\ninterpretation of meta-learning",
    "start": "84510",
    "end": "92159"
  },
  {
    "text": "as inference in Bayesian\ngraphical models and also to\nunderstand techniques",
    "start": "92160",
    "end": "97560"
  },
  {
    "text": "for representing\nuncertainty over parameters and over predictions.",
    "start": "97560",
    "end": "102090"
  },
  {
    "text": "Similar to the\nprevious lecture, this is an active area of research. And so, there might be more\nquestions than answers.",
    "start": "104920",
    "end": "112870"
  },
  {
    "text": "And it will also--\nthis lecture will also cover some of the most\nadvanced content of the course.",
    "start": "112870",
    "end": "118700"
  },
  {
    "text": "And so, I definitely would\nencourage you to ask questions, especially in the later\nhalf of the lecture, which",
    "start": "118700",
    "end": "125320"
  },
  {
    "text": "becomes the more advanced part. Yeah. And then we can discuss.",
    "start": "125320",
    "end": "131260"
  },
  {
    "text": "And also, if you don't\nunderstand something, yeah, it's not your fault.\nIt's most likely my fault.",
    "start": "131260",
    "end": "138819"
  },
  {
    "text": "Cool. So to recap from\nlast week or from--",
    "start": "138820",
    "end": "143950"
  },
  {
    "text": "yeah, from last week, we\ntalked about a perspective on meta-learning, which is this\ncomputation graph perspective,",
    "start": "143950",
    "end": "150760"
  },
  {
    "text": "where for black-box\napproaches we view meta-learning\nas learning from data",
    "start": "150760",
    "end": "157750"
  },
  {
    "text": "with a black-box neural network. We view optimization-based\napproaches as methods that\nembed an optimization",
    "start": "157750",
    "end": "164440"
  },
  {
    "text": "into the meta-learning\nprocess to quickly learn from support sets. And we also talked about\nnonparametric methods,",
    "start": "164440",
    "end": "170349"
  },
  {
    "text": "which learn embeddings\nsuch that you can do things like\nnearest neighbors to solve few-shot\nlearning problems.",
    "start": "170350",
    "end": "177069"
  },
  {
    "text": "We also talked about different\nalgorithmic properties of meta-learning algorithms\nthat can be useful.",
    "start": "179950",
    "end": "184970"
  },
  {
    "text": "So for example, we talked\nabout expressive power, which is useful to\nbe able to represent a wide range of\nlearning procedures.",
    "start": "184970",
    "end": "190820"
  },
  {
    "text": "We also talked\nabout consistency, which means that our\nlearner is guaranteed to improve in expectation when\nyou give it more and more data.",
    "start": "190820",
    "end": "201340"
  },
  {
    "text": "And these properties\nare important. Then we also briefly mentioned\nuncertainty awareness,",
    "start": "201340",
    "end": "206900"
  },
  {
    "text": "which is essentially the ability\nto reason about ambiguity during the learning process.",
    "start": "206900",
    "end": "211940"
  },
  {
    "text": "And this can be useful for\nthings like active learning, getting calibrated\nuncertainty estimates, which",
    "start": "211940",
    "end": "217060"
  },
  {
    "text": "is important in\nsafety-critical applications and also in reinforcement\nlearning domains.",
    "start": "217060",
    "end": "222609"
  },
  {
    "text": "And it also gives us some\nmore principled approaches. And this is essentially-- this kind of last\npart here is what",
    "start": "222610",
    "end": "228742"
  },
  {
    "text": "we're going to be really\nfocusing on in this lecture.",
    "start": "228742",
    "end": "230950"
  },
  {
    "text": "Great. So why be Bayesian?",
    "start": "234140",
    "end": "237565"
  },
  {
    "text": "In multitask and\nmeta-learning, we talked a lot about how\nwe want training and test time to try to match\nso that you're actually",
    "start": "241240",
    "end": "247120"
  },
  {
    "text": "training for the ability\nto solve the test tasks.",
    "start": "247120",
    "end": "253150"
  },
  {
    "text": "And the tasks also need\nto share some structure. And we always talked about\nstructure as more colloquially,",
    "start": "253150",
    "end": "261010"
  },
  {
    "text": "I guess, than really\nas anything formal. And if you try to\nthink more formally, it's not actually obvious\nwhat structure should mean.",
    "start": "261010",
    "end": "270430"
  },
  {
    "text": "And one thing that\nI think-- one way I think that's nice\nto look at this is actually from the\nBayesian perspective,",
    "start": "270430",
    "end": "276380"
  },
  {
    "text": "which is to say that\nstructure means that there is a statistical dependence\nbetween the tasks",
    "start": "276380",
    "end": "283090"
  },
  {
    "text": "on some shared\nlatent information. And I'll refer to that shared\nlatent information as theta.",
    "start": "283090",
    "end": "292600"
  },
  {
    "text": "And in particular, you can\nthink about this graphical model right here, where you have your\ntrue task-specific parameters",
    "start": "292600",
    "end": "301409"
  },
  {
    "text": "phi i. There is some shared information\nbetween all of the tasks",
    "start": "301410",
    "end": "307180"
  },
  {
    "text": "that's represented as theta. And then, the data\nfor each task,",
    "start": "307180",
    "end": "312830"
  },
  {
    "text": "including the training\ndata and the test data, is ultimately-- well,\nspecifically, the labels",
    "start": "312830",
    "end": "318550"
  },
  {
    "text": "are ultimately a function of the\ntask-specific parameters phi i and the inputs x.",
    "start": "318550",
    "end": "323979"
  },
  {
    "text": "And here-- [INTERPOSING VOICES] --circles are referring\nto things that are observed during the process.",
    "start": "327200",
    "end": "335930"
  },
  {
    "text": "y test has a\npartially shaded thing to indicate that it's observed\nduring the meta-training process but not observed\nat meta-test time.",
    "start": "335930",
    "end": "343802"
  },
  {
    "text": "And so, note that\nwe don't directly observe theta or phi i. We only observe the data.",
    "start": "343802",
    "end": "348155"
  },
  {
    "text": "Cool. And so, this is an interesting\nway to look at things, I think. Because if you then condition\non the shared information,",
    "start": "351740",
    "end": "358950"
  },
  {
    "text": "then we can first note\nthat the task parameters will become independent\nconditioned on that shared information.",
    "start": "358950",
    "end": "365880"
  },
  {
    "text": "And otherwise, the\ntask parameters are not independent if you don't\ncondition on that information.",
    "start": "365880",
    "end": "371430"
  },
  {
    "text": "This also means\nthat as a result, you will have a lower entropy-- the distribution over\nphi has a lower entropy",
    "start": "374610",
    "end": "382440"
  },
  {
    "text": "if you condition on theta. And this means that\nessentially theta is giving you information about how\nto infer the underlying",
    "start": "382440",
    "end": "392365"
  },
  {
    "text": "parameters compared\nto if you were just trying to learn the\ntask-specific parameters completely from scratch.",
    "start": "392365",
    "end": "397020"
  },
  {
    "text": "Cool. So a thought exercise\nfor you, which is that if you can identify\ntheta via meta-learning,",
    "start": "402740",
    "end": "410270"
  },
  {
    "text": "when should learning\nphi i be faster than learning from scratch?",
    "start": "410270",
    "end": "413960"
  },
  {
    "text": "Yeah. Mutual equation between\ntheta and phi i is not zero? So you're saying, the\nmutual information",
    "start": "421900",
    "end": "428320"
  },
  {
    "text": "between theta and\nphi i is not zero? Yeah. So this means that essentially\nthe tasks are not completely",
    "start": "428320",
    "end": "436150"
  },
  {
    "text": "independent of one another. And if they're not\nindependent of one another, then you should be\nable to learn faster than learning from scratch.",
    "start": "436150",
    "end": "443000"
  },
  {
    "text": "And this is essentially\nexactly what I mean by they share\nsome structure.",
    "start": "443000",
    "end": "449106"
  },
  {
    "text": "Did you have anything to add? Cool.",
    "start": "449106",
    "end": "451720"
  },
  {
    "text": "OK, another thought exercise. What if the entropy of\nphi i given theta is zero?",
    "start": "457280",
    "end": "463550"
  },
  {
    "text": "Yeah. [INAUDIBLE] phi i [INAUDIBLE].",
    "start": "466620",
    "end": "470244"
  },
  {
    "text": "Yeah, exactly. So in this case,\nif you could fully determine phi i from\ntheta, this means",
    "start": "475140",
    "end": "480660"
  },
  {
    "text": "that the tasks are essentially\nnot mutually exclusive. They share everything basically.",
    "start": "480660",
    "end": "486630"
  },
  {
    "text": "You can figure out how to solve\nthe tasks from theta alone without actually using\ndata, for example.",
    "start": "486630",
    "end": "492164"
  },
  {
    "text": "Cool. So this is essentially the\nway to think about shared",
    "start": "497490",
    "end": "503370"
  },
  {
    "text": "structure. And these different\ncriteria can allow you to think about things like\nmemorization, which we talked",
    "start": "503370",
    "end": "508940"
  },
  {
    "text": "about last lecture,\nwhich happens exactly in the second condition. It can also help you\nthink about whether or not",
    "start": "508940",
    "end": "515000"
  },
  {
    "text": "you're going to get efficiency,\nlike better efficiency compared to learning from scratch. For this first thought\nexercise, another scenario",
    "start": "515000",
    "end": "521780"
  },
  {
    "text": "where this can come up\nis that, say you already built in structure\ninto your optimizer",
    "start": "521780",
    "end": "527710"
  },
  {
    "text": "or into your\nfunction approximator or something like that. Then in those cases,\nidentifying theta",
    "start": "527710",
    "end": "533930"
  },
  {
    "text": "won't necessarily be faster\nthan learning from scratch because you already\nbuilt that structure into your optimization.",
    "start": "533930",
    "end": "538970"
  },
  {
    "text": "Cool. And so, we can think\nabout a few examples for this graphical model. So say that you are in this\nsinusoidal regression case",
    "start": "543250",
    "end": "552440"
  },
  {
    "text": "where different tasks correspond\nto sinusoidal functions with different phase\nand different amplitude.",
    "start": "552440",
    "end": "557570"
  },
  {
    "text": "Does anyone have any thoughts\non what the information in theta would contain if your\ndifferent tasks correspond",
    "start": "560300",
    "end": "567107"
  },
  {
    "text": "to these different\nsinusoid curves?",
    "start": "567107",
    "end": "568565"
  },
  {
    "text": "Yeah. It's the sign shape,\nperiodicity, and [iNAUDIBLE]. Yeah. Essentially the sign, shape,\nthe periodicity of the function,",
    "start": "573060",
    "end": "579998"
  },
  {
    "text": "and so forth. So basically, theta\ncorresponds to the family of sinusoid functions that\nunderlie the task family.",
    "start": "579998",
    "end": "588535"
  },
  {
    "text": "Essentially everything but\nthe phase and amplitude, which it has to infer from the data.",
    "start": "588535",
    "end": "594819"
  },
  {
    "text": "Another example is you\ncould apply meta-learning to multi-language machine\ntranslation, where",
    "start": "594820",
    "end": "601320"
  },
  {
    "text": "you want to quickly adapt\nto low resource languages.",
    "start": "601320",
    "end": "606960"
  },
  {
    "text": "In this case, you're\ntrying to adapt to a new language with data. And so, in this case\nwhat does theta--",
    "start": "606960",
    "end": "613560"
  },
  {
    "text": "what information\ndoes theta contain?",
    "start": "613560",
    "end": "615435"
  },
  {
    "text": "Yeah. Perhaps general grammatical\nstructure and syntax patterns.",
    "start": "619930",
    "end": "625529"
  },
  {
    "text": "Yeah. So things that are\ngeneral to language-- to multiple different\nlanguages, that might be things",
    "start": "625530",
    "end": "631360"
  },
  {
    "text": "like the basic kind\nof grammar or syntax. Some languages have\ndifferent syntax.",
    "start": "631360",
    "end": "636990"
  },
  {
    "text": "So you need to only\nencode the things that are the most general.",
    "start": "636990",
    "end": "643200"
  },
  {
    "text": "Cool. So yeah, essentially\ntheta will correspond to kind of the family of all\nof the different languages",
    "start": "643200",
    "end": "649143"
  },
  {
    "text": "and the things that are\nshared among those languages rather than things\nthat are different.",
    "start": "649143",
    "end": "653290"
  },
  {
    "text": "Great. And you should note that\nin both of these examples, theta is going to be\nnarrower than the space",
    "start": "655880",
    "end": "661150"
  },
  {
    "text": "of all possible functions. This is really important\nif it's a space of all possible functions. Then you're not going to\ngain anything compared",
    "start": "661150",
    "end": "667240"
  },
  {
    "text": "to learning from scratch.",
    "start": "667240",
    "end": "668282"
  },
  {
    "text": "Great. And then, one other-- one last thought\nexercise is what",
    "start": "673370",
    "end": "678709"
  },
  {
    "text": "if you're doing\nmeta-learning and you don't have a lot of tasks. In particular, you\ndon't have a lot",
    "start": "678710",
    "end": "684620"
  },
  {
    "text": "of data for a lot of\ndifferent tasks in order to meta-train from.",
    "start": "684620",
    "end": "689660"
  },
  {
    "text": "What will happen in that case? And what will theta\ncontain in that case?",
    "start": "689660",
    "end": "695320"
  },
  {
    "text": "Yeah? I guess it would be that\nspecific family of tasks.",
    "start": "695320",
    "end": "704000"
  },
  {
    "text": "Yeah. So essentially, theta is\nnot-- in a case like this, theta is going to be narrower. It's going to overfit.",
    "start": "704000",
    "end": "710530"
  },
  {
    "text": "And it might represent a\nsmaller family of tasks than you ultimately\nwant it to represent.",
    "start": "710530",
    "end": "717472"
  },
  {
    "text": "So it'll essentially\nhave this form of meta-overfitting to the\nfamily of training functions rather than the entire family\nof tasks that you care about.",
    "start": "717472",
    "end": "724449"
  },
  {
    "text": "Great. So that's the kind of\ngist of the high level",
    "start": "728390",
    "end": "734891"
  },
  {
    "text": "structure of Bayesian\nmeta-learning algorithms, or not Bayesian\nmeta-learning algorithms, but the perspective\nof meta-learning",
    "start": "734892",
    "end": "740149"
  },
  {
    "text": "within these Bayesian\ngraphical models. Now, a lot of the algorithms\nthat we've talked about so far",
    "start": "740150",
    "end": "747920"
  },
  {
    "text": "are going to give\nyou a single set of task specific parameters. So they're essentially\ngoing to return",
    "start": "747920",
    "end": "753140"
  },
  {
    "text": "what you can think of as a point\nestimate of this distribution.",
    "start": "753140",
    "end": "756770"
  },
  {
    "text": "In many cases,\nthis might be fine. So in your homework,\nfor example, you've been inferring parameters. And it has been getting\nhopefully reasonable accuracy",
    "start": "759643",
    "end": "768320"
  },
  {
    "text": "on the problems. In what cases might\nit be a problem",
    "start": "768320",
    "end": "773389"
  },
  {
    "text": "to only recover a\nsingle parameter? Yeah. In multi-mode setting?",
    "start": "773390",
    "end": "779330"
  },
  {
    "text": "What do you mean by multi-mode? The distribution if there\nare two labels would actually",
    "start": "779330",
    "end": "786440"
  },
  {
    "text": "probably work, or\nif you're you're super uncertain, whether\nmore than two labels are the same [INAUDIBLE].",
    "start": "786440",
    "end": "792560"
  },
  {
    "text": "So on a safety-critical\naspect, it's important to adjust\nthe [INAUDIBLE].. If I give you just\na point estimate,",
    "start": "792560",
    "end": "797930"
  },
  {
    "text": "I have no certainty or\nnot uncertainty now. So that's a problem. But also, if you were\ngiven numbers and told how",
    "start": "797930",
    "end": "805075"
  },
  {
    "text": "you need to solve [INAUDIBLE]. So giving it actually two\nlabels would kind of be fine.",
    "start": "805075",
    "end": "810230"
  },
  {
    "text": "So in that setting, it\nmight not make sense that you get\ndeterministic output.",
    "start": "810230",
    "end": "816510"
  },
  {
    "text": "Yeah. So essentially, if you have\nuncertainty, I guess first, note that this is a\ndistribution over parameters",
    "start": "816510",
    "end": "821977"
  },
  {
    "text": "rather than labels. But essentially, if you have\na multimodal distribution over possible functions,\nthat could explain the data.",
    "start": "821978",
    "end": "827137"
  },
  {
    "text": "In some cases, that might be OK. Because maybe especially\nin uni-modal cases,",
    "start": "827137",
    "end": "833029"
  },
  {
    "text": "there's probably\none correct answer. But in cases where you have\nmore multimodal distributions and there's clearly\nmultiple viable solutions",
    "start": "833030",
    "end": "840889"
  },
  {
    "text": "to the problem, representing\nthat uncertainty can probably be quite important.",
    "start": "840890",
    "end": "846980"
  },
  {
    "text": "Cool. So as a few examples. In some cases, few-shot learning\nproblems might be ambiguous",
    "start": "850707",
    "end": "856510"
  },
  {
    "text": "and this might lead\nto multiple solutions, including kind of multimodal\ndistributions over phi",
    "start": "856510",
    "end": "861580"
  },
  {
    "text": "even when you have\nthe prior data. As an example of this, say you\nwanted to learn a classifier",
    "start": "861580",
    "end": "868540"
  },
  {
    "text": "and you had these 10 examples. So it's a few-shot\nlearning problem. And these are your positives\nand these are your negatives.",
    "start": "868540",
    "end": "877090"
  },
  {
    "text": "In this case, if\nyou look at these, there is actually\na lot of things that could explain\nwhat this classifier is",
    "start": "877090",
    "end": "883060"
  },
  {
    "text": "trying to predict. So for example, everyone on\nthe left is wearing a hat, and everyone on the right\nisn't wearing a hat.",
    "start": "883060",
    "end": "889810"
  },
  {
    "text": "Also, everyone on\nthe left is smiling and everyone on the\nright is not smiling.",
    "start": "889810",
    "end": "894235"
  },
  {
    "text": "And also, at least\naccording to the labels, they think that everyone\non the left is young",
    "start": "896740",
    "end": "902770"
  },
  {
    "text": "and everyone on the\nright is not young. I'm not sure if that's accurate. But there are essentially these\nmultiple underlying attributes",
    "start": "902770",
    "end": "909100"
  },
  {
    "text": "here. And as a result, this means\nthat when it comes time",
    "start": "909100",
    "end": "914649"
  },
  {
    "text": "to get a classifier\nfor these things, you're not sure what you\nshould be classifying on.",
    "start": "914650",
    "end": "919900"
  },
  {
    "text": "Then ultimately,\nif you get someone that's smiling and wearing a hat\nand is not young, for example,",
    "start": "919900",
    "end": "925000"
  },
  {
    "text": "it's just inherently ambiguous\nwhat the correct answer is. As another example,\nmaybe you have",
    "start": "925000",
    "end": "930610"
  },
  {
    "text": "someone that's not smiling\nwearing a hat and young and is also ambiguous.",
    "start": "930610",
    "end": "936020"
  },
  {
    "text": "And so, in these\nproblems, it would be nice to be able to represent\na distribution over classifiers",
    "start": "936020",
    "end": "941881"
  },
  {
    "text": "that, for example, cover\ndifferent combinations of these attributes so that\nyou can ultimately do something",
    "start": "941882",
    "end": "949780"
  },
  {
    "text": "about reducing that ambiguity,\nlike asking a user to help you reduce that ambiguity.",
    "start": "949780",
    "end": "955209"
  },
  {
    "text": "And so, in particular\nit'd be nice if we could be able to generate\nhypotheses about the underlying function and be\nable to essentially",
    "start": "958073",
    "end": "963450"
  },
  {
    "text": "sample from the distribution\nof phi i given theta. And that would allow us\nto sample classifiers",
    "start": "963450",
    "end": "968970"
  },
  {
    "text": "where one classifier might\nonly pay attention to smiling, one might only pay\nattention to wearing a hat, maybe would pay attention to\na pair of these attributes,",
    "start": "968970",
    "end": "976500"
  },
  {
    "text": "and so forth. If we could generate\nthese hypotheses, then this will be first\nimportant for safety",
    "start": "976500",
    "end": "983970"
  },
  {
    "text": "critical few-shot learning\nproblems, like medical imaging. It's helpful to know if it's\ncertain about a particular",
    "start": "983970",
    "end": "989490"
  },
  {
    "text": "outcome or if it's uncertain\nabout a particular outcome.",
    "start": "989490",
    "end": "994758"
  },
  {
    "text": "It could also be useful for\nlearning to actively learn. So that if you have some data\nset of unlabeled examples,",
    "start": "994758",
    "end": "999899"
  },
  {
    "text": "it can tell you-- give\nme a label for this, and that will help me\nreduce my uncertainty.",
    "start": "999900",
    "end": "1003740"
  },
  {
    "text": "And we won't really\ntalk about it today. But there are\nactually some papers that explicitly look\nat active learning",
    "start": "1007250",
    "end": "1012410"
  },
  {
    "text": "with meta-learning that\nare listed there if you're interested in learning more.",
    "start": "1012410",
    "end": "1017454"
  },
  {
    "text": "And then lastly, it can\nalso be useful for learning how to explore in meta\nRL, where you want to try to find-- seek out\nparts of the state space,",
    "start": "1017455",
    "end": "1027170"
  },
  {
    "text": "seek out parts of\nyour world that help you reduce the ambiguity.",
    "start": "1027170",
    "end": "1030380"
  },
  {
    "text": "OK, any questions on the\nsetup or the graphical model that we talked about before\nwe go into the algorithms?",
    "start": "1034150",
    "end": "1042280"
  },
  {
    "text": "OK. So we're going to talk about\nboth black-box approaches and optimization-based\napproaches.",
    "start": "1049910",
    "end": "1055460"
  },
  {
    "text": "And we'll start with the\nblack-box approaches. And I guess in particular\nthat this first approach",
    "start": "1055460",
    "end": "1063230"
  },
  {
    "text": "will be general to all\nof the different methods. And what we can do is, we can\nhave this f function, output",
    "start": "1063230",
    "end": "1073220"
  },
  {
    "text": "the parameters of a distribution\nover the label y test.",
    "start": "1073220",
    "end": "1078980"
  },
  {
    "text": "And in classification\nproblems, you're actually already\ndoing this when you train with cross-entropy loss. Because you have kind\nof logits, you'll",
    "start": "1078980",
    "end": "1084980"
  },
  {
    "text": "have probabilities for\neach of the classes. And you do this-- you can do this\nin classification.",
    "start": "1084980",
    "end": "1091100"
  },
  {
    "text": "You can also do\nit in regression, where instead of outputting\nprobabilities for each class,",
    "start": "1091100",
    "end": "1096409"
  },
  {
    "text": "you output the parameters\nof a Gaussian distribution like the mean and the variance\nor the parameters of a Gaussian",
    "start": "1096410",
    "end": "1101630"
  },
  {
    "text": "mixture. So yeah, it can be\nprobability values and a categorical distribution,\nmean invariance of a Gaussian,",
    "start": "1101630",
    "end": "1108710"
  },
  {
    "text": "means, variances\nin mixture weights of a mixture of Gaussians. You can also do an\nautoregressive distribution",
    "start": "1108710",
    "end": "1116870"
  },
  {
    "text": "as well for sequential labels. And then, once you choose\nthe weighted parameters",
    "start": "1116870",
    "end": "1126200"
  },
  {
    "text": "or distribution\nover the labels, you can just optimize with\nmaximum likelihood. And when you do\ncross-entropy, you're",
    "start": "1126200",
    "end": "1132410"
  },
  {
    "text": "actually already doing this. And you can also do that with\nthese distributions as well.",
    "start": "1132410",
    "end": "1137779"
  },
  {
    "text": "So I guess in some ways,\nI have sort of already implemented v0 of a Bayesian\nmeta-learning algorithm.",
    "start": "1140400",
    "end": "1147560"
  },
  {
    "text": "This approach is very simple. You can combine it with all\nof the different methods that we showed before.",
    "start": "1147560",
    "end": "1153630"
  },
  {
    "text": "However, it has\nsome shortcomings. And in particular,\nyou're only reasoning about uncertainty of the\nlabel rather than uncertainty",
    "start": "1153630",
    "end": "1160429"
  },
  {
    "text": "over the underlying function. So in particular, you're\nthinking about p of y rather than p of phi i.",
    "start": "1160430",
    "end": "1168350"
  },
  {
    "text": "And this means that\nyou can't determine how uncertainty across\ndifferent data points is related to one another.",
    "start": "1168350",
    "end": "1175940"
  },
  {
    "text": "And for example, in\nthe classification that we saw before,\nyou can't sample a classifier for young and a\nclassifier for wearing a hat.",
    "start": "1175940",
    "end": "1182255"
  },
  {
    "text": "Also, the distributions over y\nthat you can represent easily",
    "start": "1186280",
    "end": "1191560"
  },
  {
    "text": "are somewhat limited. We saw these-- like a Gaussian\nor a mixture of Gaussians. And you ultimately\nmight want to represent",
    "start": "1191560",
    "end": "1198160"
  },
  {
    "text": "more expressive distributions. And then it's also\nworth mentioning that things like standard\ncross-entropy loss",
    "start": "1198160",
    "end": "1204850"
  },
  {
    "text": "tend to produce somewhat\npoorly calibrated uncertainty estimates. Typically, when you train\nwith standard cross-entropy,",
    "start": "1204850",
    "end": "1212800"
  },
  {
    "text": "the uncertainty or the\nprobabilities of the outputs don't actually reflect\nthe probability",
    "start": "1212800",
    "end": "1219700"
  },
  {
    "text": "that the classifier is\ncorrect for that class or for that example.",
    "start": "1219700",
    "end": "1223765"
  },
  {
    "text": "So that was-- I think this is the final\nthought exercise for you, which is that if you were\ndoing maximum likelihood",
    "start": "1229990",
    "end": "1237990"
  },
  {
    "text": "training over the\nlabels y, can you do this same sort\nof approach, except",
    "start": "1237990",
    "end": "1243390"
  },
  {
    "text": "do maximum likelihood training\nfor the parameters phi instead?",
    "start": "1243390",
    "end": "1247455"
  },
  {
    "text": "Does anyone have\nthoughts on this?",
    "start": "1251640",
    "end": "1253215"
  },
  {
    "text": "So for these approaches\nwhat we did is, we had-- we're outputting a\ndistribution over y. And then we do maximum\nlikelihood training for--",
    "start": "1263280",
    "end": "1271207"
  },
  {
    "text": "with a cross-entropy\nloss or something like that to get\nthat distribution. Yeah. It should be possible,\nin my opinion,",
    "start": "1271207",
    "end": "1278370"
  },
  {
    "text": "but we would need\n[INAUDIBLE],, and then have some kind of [INAUDIBLE]\nor some kind of history",
    "start": "1278370",
    "end": "1285808"
  },
  {
    "text": "[INAUDIBLE] approximate\nsome kind of distribution for those phis, and then fit\nthat to our data that we get.",
    "start": "1285808",
    "end": "1293140"
  },
  {
    "text": "Yeah. So you're saying that it\nshould be possible if you can sample different phis. Exactly.",
    "start": "1293140",
    "end": "1298530"
  },
  {
    "text": "And where do those\nphis come from? Those phis would have to\nbe learned from the data that you're given.",
    "start": "1298530",
    "end": "1303850"
  },
  {
    "text": "So you'd have to learn the phis\nfor the data that you're given. Do you have something to add? I think similar, but if\nwe sample different data",
    "start": "1303850",
    "end": "1309170"
  },
  {
    "text": "sets for different phis. Sample different data\nsets for different phis. Have a big dataset, sample\nphi 1, phi 2, and so on.",
    "start": "1309170",
    "end": "1316840"
  },
  {
    "text": "Yeah. So I think that essentially\nwhat you're getting at is that for each of the\ntasks that you have,",
    "start": "1316840",
    "end": "1322660"
  },
  {
    "text": "you want to essentially somehow\nget labels for phi by training",
    "start": "1322660",
    "end": "1329250"
  },
  {
    "text": "a model on that data set. And then, once you\nhave those phis",
    "start": "1329250",
    "end": "1334475"
  },
  {
    "text": "for each of those\ndata sets, then you can use supervised\nlearning onto those phis.",
    "start": "1334475",
    "end": "1340230"
  },
  {
    "text": "Now, the tricky part\nthat comes up here, which you might have\nrealized, is that, I mean,",
    "start": "1340230",
    "end": "1346852"
  },
  {
    "text": "I guess there's a few things. First, you don't get\nthese phi labels for free. The y's come for free\nin your data set.",
    "start": "1346852",
    "end": "1354360"
  },
  {
    "text": "And so, you have to somehow be\nable to get samples from phi for each of your tasks.",
    "start": "1354360",
    "end": "1360480"
  },
  {
    "text": "You could train separate\nnetworks to do that. Although you may not get\nfull coverage over phi,",
    "start": "1360480",
    "end": "1366550"
  },
  {
    "text": "which actually ends up being\nquite difficult in practice. And then, the second problem\nis that you would then",
    "start": "1366550",
    "end": "1372660"
  },
  {
    "text": "be doing supervised learning\non phi, which may not actually represent the--",
    "start": "1372660",
    "end": "1376710"
  },
  {
    "text": "the loss function over\nphi may not actually represent the loss function\nthat you care about. And errors in\nmatching phi may not",
    "start": "1380918",
    "end": "1386549"
  },
  {
    "text": "translate into errors into y-- may translate into much worse\nerrors into y, for example.",
    "start": "1386550",
    "end": "1392773"
  },
  {
    "text": "And so, kind of the short\nanswer for this thought exercise is that it's extremely difficult\nto do maximum likelihood",
    "start": "1392773",
    "end": "1398100"
  },
  {
    "text": "directly over phi because\nyou can't directly observe samples from phi.",
    "start": "1398100",
    "end": "1403650"
  },
  {
    "text": "Whereas if we go back to the\ngraphical model we saw before, we do actually directly observe\nsamples for the labels y.",
    "start": "1403650",
    "end": "1410820"
  },
  {
    "text": "And so all of the Bayesian\nmeta-learning algorithms will amount trying to get\nbetter algorithms for getting",
    "start": "1410820",
    "end": "1419250"
  },
  {
    "text": "distributions over phi.",
    "start": "1419250",
    "end": "1420570"
  },
  {
    "text": "And in particular, I\nguess, I'll just quickly go back to the graphical\nmodel that we saw before.",
    "start": "1424990",
    "end": "1433880"
  },
  {
    "text": "And so, as you\ncan note here, you can see that at least the y\ntrain is observed directly,",
    "start": "1433880",
    "end": "1439480"
  },
  {
    "text": "whereas phi is not\nobserved directly. And that's what\nmakes it challenging. And as a hint towards\nwhat we'll see next",
    "start": "1439480",
    "end": "1446830"
  },
  {
    "text": "is that you could\nessentially think of phi as a latent variable\nin the sense that it's not directly observed.",
    "start": "1446830",
    "end": "1452980"
  },
  {
    "text": "And this means that a\nlot of the techniques that we have for using-- for dealing with\nlatent variables",
    "start": "1452980",
    "end": "1458230"
  },
  {
    "text": "like variational\nauto-encoders and other things can be applied for learning\ndistributions over phi.",
    "start": "1458230",
    "end": "1464860"
  },
  {
    "text": "Cool. So as we kind of start to\nthink about how we can actually",
    "start": "1472780",
    "end": "1479380"
  },
  {
    "text": "represent p of phi\ngiven theta, I'll just briefly overview\nsome of the tools that we have to our disposal\nin order to solve this problem.",
    "start": "1479380",
    "end": "1489470"
  },
  {
    "text": "This is a very kind of\nbroad one-slide overview. If you want a more kind of\nthorough treatment of this,",
    "start": "1489470",
    "end": "1494740"
  },
  {
    "text": "CS236 provides more details\non a lot of these approaches.",
    "start": "1494740",
    "end": "1500470"
  },
  {
    "text": "And really, the\ngoal of these tools is to be able to\nrepresent distributions with neural networks,\nincluding distributions",
    "start": "1500470",
    "end": "1507040"
  },
  {
    "text": "over latent variables rather\nthan just observed variables.",
    "start": "1507040",
    "end": "1512060"
  },
  {
    "text": "So the first tool that we\nhave is latent variable models and variational inference. This will be one of the\nbiggest tools that we'll use.",
    "start": "1512060",
    "end": "1519370"
  },
  {
    "text": "And we had the tutorial\non this last week. The way that these\nalgorithms work very roughly",
    "start": "1519370",
    "end": "1526240"
  },
  {
    "text": "is to try to approximate the\nlikelihood of your latent variable using a lower bound,\nlike an estimated lower bound",
    "start": "1526240",
    "end": "1533950"
  },
  {
    "text": "on that likelihood. And for example, we have the\nvariational auto-encoder,",
    "start": "1533950",
    "end": "1539169"
  },
  {
    "text": "which thinks about a latent\nvariable z and an observed variable x.",
    "start": "1539170",
    "end": "1544540"
  },
  {
    "text": "And in reality, those don't\nhave to just be x and z. You can rename those variables\nand the whole framework still",
    "start": "1544540",
    "end": "1549559"
  },
  {
    "text": "applies. Another class of approaches\nis Bayesian ensembles.",
    "start": "1549560",
    "end": "1557330"
  },
  {
    "text": "These methods essentially\ntry to represent samples",
    "start": "1557330",
    "end": "1563690"
  },
  {
    "text": "from your distribution\nas different particles. And basically, the\nway that they work",
    "start": "1563690",
    "end": "1569270"
  },
  {
    "text": "is you train separate models\non different bootstraps of your data. So you resample your\ndata in different ways.",
    "start": "1569270",
    "end": "1574910"
  },
  {
    "text": "You train a model on\neach resampled data set. And then, each of\nthose resampled data",
    "start": "1574910",
    "end": "1580300"
  },
  {
    "text": "sets often\nessentially correspond to kind of different samples\nfrom your distribution.",
    "start": "1580300",
    "end": "1588687"
  },
  {
    "text": "Another class of approaches\nis Bayesian neural networks. These approaches try\nto actually learn an explicit distribution over\nthe space of neural network",
    "start": "1588687",
    "end": "1595940"
  },
  {
    "text": "parameters. Oftentimes, it's a\nGaussian distribution because that's one of the things\nthat's easiest to deal with.",
    "start": "1595940",
    "end": "1602330"
  },
  {
    "text": "Although sometimes it's\nsomewhat unsatisfying because Gaussian distributions\nare limited in what they can represent.",
    "start": "1602330",
    "end": "1609492"
  },
  {
    "text": "There's also a\nclass of approaches based on normalizing flows. These approaches\nare pretty cool.",
    "start": "1609493",
    "end": "1615898"
  },
  {
    "text": "They learn an invertible\nfunction that maps from some latent distribution\nto a data distribution.",
    "start": "1615898",
    "end": "1621830"
  },
  {
    "text": "And for example,\nyou can translate between a nice Gaussian\ndistribution to a more complex",
    "start": "1621830",
    "end": "1627380"
  },
  {
    "text": "distribution, such as these-- I don't know what it's\ncalled, these kind of hemisphere distributions.",
    "start": "1627380",
    "end": "1636080"
  },
  {
    "text": "Then lastly, there's also\nenergy-based models and GANs, which essentially\ntry to estimate",
    "start": "1636080",
    "end": "1641770"
  },
  {
    "text": "an unnormalized\nversion of the density. And this essentially corresponds\nto trying to push down the data",
    "start": "1641770",
    "end": "1647929"
  },
  {
    "text": "and push up everything else. Yeah. So we're really going to\nfocus on the first two",
    "start": "1647930",
    "end": "1656390"
  },
  {
    "text": "classes of approaches\nfor solving problems in Bayesian meta-learning. But I figured that I would\nbriefly mention these",
    "start": "1656390",
    "end": "1662923"
  },
  {
    "text": "because they're\nalso cool approaches and could also be used\npotentially to develop Bayesian learning algorithms.",
    "start": "1662923",
    "end": "1668360"
  },
  {
    "text": "So these last three\napproaches could be useful when developing new methods.",
    "start": "1671430",
    "end": "1674525"
  },
  {
    "text": "OK, so let's start with\nvariational inference in the first class\nof approaches.",
    "start": "1679950",
    "end": "1685780"
  },
  {
    "text": "And in particular, one of the\nthings that you would have seen in the tutorial if you watched\nit is that we can think",
    "start": "1685780",
    "end": "1693150"
  },
  {
    "text": "about this graphical\nmodel right here, which is a very simplified\nlatent variable model, where",
    "start": "1693150",
    "end": "1698190"
  },
  {
    "text": "we have some latent variable z\nand some observed variable x. And if we care about\nmaximizing the likelihood of x,",
    "start": "1698190",
    "end": "1709289"
  },
  {
    "text": "we can derive a lower bound\non this likelihood, which corresponds to the equation on\nthe right, which is essentially",
    "start": "1709290",
    "end": "1718049"
  },
  {
    "text": "estimating the log probability\nof x and z when sampling--",
    "start": "1718050",
    "end": "1724620"
  },
  {
    "text": "under the expectation of\nthis inference network q, plus the entropy of\nthat inference network.",
    "start": "1724620",
    "end": "1733770"
  },
  {
    "text": "This can also be written\nas this form right here. Which if you've trained\nvariational auto-encoders,",
    "start": "1733770",
    "end": "1739020"
  },
  {
    "text": "you might be a little\nbit more familiar with. Where essentially, you sample\nfrom your generative model,",
    "start": "1739020",
    "end": "1746400"
  },
  {
    "text": "maximize the likelihood\nof those generations, and then minimize\nthe KL divergence",
    "start": "1746400",
    "end": "1752820"
  },
  {
    "text": "between your inferred latent\nvariable and the prior.",
    "start": "1752820",
    "end": "1755970"
  },
  {
    "text": "In this case, p is\nrepresenting the model. It is essentially representing\nthis generative process",
    "start": "1758760",
    "end": "1764610"
  },
  {
    "text": "of the data. And you would\nrepresent p of x given",
    "start": "1764610",
    "end": "1769710"
  },
  {
    "text": "z as a neural network that\ntakes as input a latent variable or a value of a latent variable\nand maps it to a generated data",
    "start": "1769710",
    "end": "1778860"
  },
  {
    "text": "point such as an image. And then, the distribution\nover your latent variable",
    "start": "1778860",
    "end": "1785700"
  },
  {
    "text": "is typically represented\nas just a standard Gaussian distribution. So this is like the two\ncomponents of your model",
    "start": "1785700",
    "end": "1792060"
  },
  {
    "text": "which you can use to\ngenerate data that follows your data distribution.",
    "start": "1792060",
    "end": "1797940"
  },
  {
    "text": "And then, q of z given\nx is representing your inference network.",
    "start": "1797940",
    "end": "1802950"
  },
  {
    "text": "It's also referred to as the\nvariational distribution. And it represents the likelihood\nof different latent variables",
    "start": "1802950",
    "end": "1812340"
  },
  {
    "text": "for a given x.",
    "start": "1812340",
    "end": "1815309"
  },
  {
    "text": "Then typically, we'll\nrefer to model parameters as theta and variational\nparameters as phi.",
    "start": "1817632",
    "end": "1824779"
  },
  {
    "text": "This is a bit of an overload\nof notation compared",
    "start": "1824780",
    "end": "1830540"
  },
  {
    "text": "to the meta-learning terminology\nthat we've referred to before. And when we use these, we'll\ntry to be careful about that.",
    "start": "1830540",
    "end": "1841700"
  },
  {
    "text": "Fortunately, it shouldn't end\nup being too much of a problem.",
    "start": "1841700",
    "end": "1845120"
  },
  {
    "text": "OK, so now, if you\nlook at this objective, typically you try to\nmaximize these lower bounds",
    "start": "1848190",
    "end": "1853850"
  },
  {
    "text": "on the likelihood so\nthat you are ultimately trying to do something\nsimilar to maximizing",
    "start": "1853850",
    "end": "1859130"
  },
  {
    "text": "the likelihood of your data. Now, there's a\nproblem if you try to maximize these\nobjectives, which",
    "start": "1859130",
    "end": "1864920"
  },
  {
    "text": "is that you have this sampling\ndistribution q of z given x that you're sampling from. And you need to differentiate\nthrough that sampling",
    "start": "1864920",
    "end": "1871670"
  },
  {
    "text": "distribution in order to\nappropriately optimize your inference network.",
    "start": "1871670",
    "end": "1876905"
  },
  {
    "text": "So essentially,\nyou need to compute the derivative of\nthe expectation of q with respect to q.",
    "start": "1879272",
    "end": "1884930"
  },
  {
    "text": "And the nice thing about\nusing a Gaussian for q is that you can use what's\ncalled the reparameterization",
    "start": "1884930",
    "end": "1890990"
  },
  {
    "text": "trick. Which is that for a\nGaussian random variable, you can represent it as\nthe mean plus the variance",
    "start": "1890990",
    "end": "1898190"
  },
  {
    "text": "times some noise. And the right-hand\nside of this equation, even though you're\nactually sampling,",
    "start": "1898190",
    "end": "1904490"
  },
  {
    "text": "the right-hand side\nis actually fully differentiable into the\nmean and invariance.",
    "start": "1904490",
    "end": "1910957"
  },
  {
    "text": "That this allows you to\nessentially back-propagate into that sampling distribution\nand optimize the objective end",
    "start": "1910957",
    "end": "1916725"
  },
  {
    "text": "to end. OK, so this is kind of\nsome background content",
    "start": "1916725",
    "end": "1925180"
  },
  {
    "text": "and is what was a very\nbrief overview of what was covered in the tutorial.",
    "start": "1925180",
    "end": "1932559"
  },
  {
    "text": "Now, we'd like to be able to use\nthese tools for meta-learning. And really, a really kind\nof core conceptual leap",
    "start": "1932560",
    "end": "1939309"
  },
  {
    "text": "that we'll be making is that\nthis variational auto-encoder is looking at a latent variable\nz and an observed variable x.",
    "start": "1939310",
    "end": "1946180"
  },
  {
    "text": "But it really doesn't\nneed to be z and x. The same kind of tool\nand this same lower bound",
    "start": "1946180",
    "end": "1951700"
  },
  {
    "text": "can apply to graphical models\nwith other kinds of latent variables, such as\nwhen we make the latent",
    "start": "1951700",
    "end": "1957220"
  },
  {
    "text": "variable phi and the\nobserved variable the data.",
    "start": "1957220",
    "end": "1960775"
  },
  {
    "text": "Cool. So the way that we can do\nthis is we have our data.",
    "start": "1963930",
    "end": "1969670"
  },
  {
    "text": "And we'd like to-- say for black-box\nmethods, we'd like to be able to have a\nneural network that outputs a distribution over\nphi given our training data.",
    "start": "1969670",
    "end": "1977950"
  },
  {
    "text": "And so, and then\nultimately, this phi will be used to make\npredictions for new data",
    "start": "1981560",
    "end": "1986680"
  },
  {
    "text": "points when we sample\nfrom that distribution. And so, in the standard VAE,\nwe had this observed variable x",
    "start": "1986680",
    "end": "1993130"
  },
  {
    "text": "and the latent variable z. And we were able\nto derive the ELBO.",
    "start": "1993130",
    "end": "1996115"
  },
  {
    "text": "And p was the model\nthat was represented by a neural network. q is an inference network. Now, in the\nmeta-learning case, we",
    "start": "1998993",
    "end": "2007290"
  },
  {
    "text": "have an observed variable,\nwhich is our data. And we have a latent\nvariable, which",
    "start": "2007290",
    "end": "2012540"
  },
  {
    "text": "corresponds to the\ntask-specific parameters phi i.",
    "start": "2012540",
    "end": "2017700"
  },
  {
    "text": "And what we can do\nis, we can essentially derive an ELBO that\njust replaces z with phi",
    "start": "2017700",
    "end": "2023130"
  },
  {
    "text": "and replaces x with d. And we get an objective\nthat looks like this.",
    "start": "2023130",
    "end": "2028019"
  },
  {
    "text": "And then, we have a\ncouple choices here. So you'll note in\nthis objective is",
    "start": "2032160",
    "end": "2037220"
  },
  {
    "text": "that we're maximizing the\nlikelihood of the data given phi. This is actually\nfairly standard.",
    "start": "2037220",
    "end": "2042800"
  },
  {
    "text": "This next approach\nis, we're actually going to have an\ninference network that's going to try to infer phi.",
    "start": "2042800",
    "end": "2048679"
  },
  {
    "text": "And in this variation lower\nbound, your choice of q can actually condition on\nanything that you want.",
    "start": "2048679",
    "end": "2054560"
  },
  {
    "text": "And what we can do\nis, we can have this q condition on our training data.",
    "start": "2057620",
    "end": "2062887"
  },
  {
    "text": "So essentially, our\ninference network is going to be inferring the\ntask-specific parameters given",
    "start": "2062887",
    "end": "2068359"
  },
  {
    "text": "our training data. And so, this equation\non the top right",
    "start": "2068360",
    "end": "2074069"
  },
  {
    "text": "is the exact same\nas this equation here, except now we've\nchanged our variational family to condition on\nthe training data.",
    "start": "2074070",
    "end": "2082719"
  },
  {
    "text": "And this is somewhat\nanalogous to the ELBO here, except we made a\nparticular choice, which",
    "start": "2082719",
    "end": "2089399"
  },
  {
    "text": "is that instead of conditioning\non all of our data for phi, we're only going to condition\non the training data.",
    "start": "2089400",
    "end": "2096190"
  },
  {
    "text": "And this is pretty useful. Because if we then want\nto infer our latent variables or our task-specific\nparameters from training data,",
    "start": "2096190",
    "end": "2103830"
  },
  {
    "text": "we can do so even from a\nsmall training data set rather than from a larger\ndata set for that task.",
    "start": "2103830",
    "end": "2109665"
  },
  {
    "text": "And then, one last\nthing that will change is that instead of--\nwhat I mean modeling",
    "start": "2115540",
    "end": "2122110"
  },
  {
    "text": "the distribution\nof data given phi, we'll have this correspond\nto our test examples.",
    "start": "2122110",
    "end": "2127779"
  },
  {
    "text": "And making this\nexplicit difference between train and test allows\nus to explicitly optimize for generalization.",
    "start": "2127780",
    "end": "2134050"
  },
  {
    "text": "And so, essentially\nwhat this corresponds to is really that\nalmost the same thing",
    "start": "2136950",
    "end": "2142109"
  },
  {
    "text": "as black-box meta-learning,\nexcept we now have this KL\ndivergence term that encourages the inferred\nparameters to be",
    "start": "2142110",
    "end": "2150090"
  },
  {
    "text": "close to this Gaussian\nprior over a task-specific parameters.",
    "start": "2150090",
    "end": "2153690"
  },
  {
    "text": "Great. Then you might\nalso be wondering, what about the\nmeta-parameters theta? These meta-parameters\ntheta, they",
    "start": "2157830",
    "end": "2164520"
  },
  {
    "text": "can essentially be folded\ninto your inference network.",
    "start": "2164520",
    "end": "2172770"
  },
  {
    "text": "They could also be a part\nof your prior as well. Essentially, these\nmeta-parameters are going to be\nwhat you're going",
    "start": "2172770",
    "end": "2178560"
  },
  {
    "text": "to be using to infer your\ntask-specific parameters.",
    "start": "2178560",
    "end": "2185723"
  },
  {
    "text": "If you want, you could also\ncondition on theta here. And that would correspond\nto something like the--",
    "start": "2185723",
    "end": "2191357"
  },
  {
    "text": "like an approach that\ndoesn't directly output phi, but also incorporates other\nparameters, like an RNN.",
    "start": "2191357",
    "end": "2197099"
  },
  {
    "text": "Yeah. Just wondering about what-- for the KL divergence, the q\npart of your q of just phi,",
    "start": "2199540",
    "end": "2206525"
  },
  {
    "text": "is it supposed to be conditioned\non the q part's theta as well? Because-- yeah, is\nthat intentionally?",
    "start": "2206525",
    "end": "2214780"
  },
  {
    "text": "Yeah. So it's a good question. So the question\nis, should q here be conditioned on the data?",
    "start": "2214780",
    "end": "2220690"
  },
  {
    "text": "So if you match\nthis bound directly, it would be conditioned\non the data.",
    "start": "2220690",
    "end": "2225780"
  },
  {
    "text": "For your variational\ndistribution, it's typical in\nvariational auto-encoders to condition your\ninference network on x.",
    "start": "2225780",
    "end": "2231870"
  },
  {
    "text": "But in reality, q can\nactually condition on whatever you want it to. x is simply the thing that\ngives it information about z.",
    "start": "2231870",
    "end": "2240528"
  },
  {
    "text": "As you'll see on\nthe top right, we're actually going to\nchoose to condition q on the training data. We could also choose\nto condition it",
    "start": "2240528",
    "end": "2246270"
  },
  {
    "text": "on all of the data for the task. We're actually going to\nchoose the training data",
    "start": "2246270",
    "end": "2251789"
  },
  {
    "text": "so that at test\ntime we can infer the task-specific parameters\ngiven our training data, which is given a small\ntraining data set.",
    "start": "2251790",
    "end": "2259228"
  },
  {
    "text": "Which will be quite\nconvenient, because then when we do few-shot\nlearning at test time, we can infer a\ndistribution over phi given",
    "start": "2259228",
    "end": "2265829"
  },
  {
    "text": "the few training examples. Does that make sense? Cool.",
    "start": "2265830",
    "end": "2271870"
  },
  {
    "text": "So to recap, we essentially took\nthe variational lower bound, viewed the data as our\nobserved variable, viewed phi",
    "start": "2271870",
    "end": "2280750"
  },
  {
    "text": "as our latent variable. Our inference network\nis going to be kind of doing the process\nof adaptation essentially,",
    "start": "2280750",
    "end": "2289600"
  },
  {
    "text": "of learning our\ntask-specific parameters. And the process of\noptimizing this lower bound will be the process of\nmeta-learning, essentially.",
    "start": "2289600",
    "end": "2297760"
  },
  {
    "text": "Our kind of final\nobjective for completeness looks something like this.",
    "start": "2300550",
    "end": "2303880"
  },
  {
    "text": "And essentially what this\nis doing is it's now just-- for simplicity of notation,\nI dropped all the sub",
    "start": "2306560",
    "end": "2314890"
  },
  {
    "text": "i's on everything. Now if we look at\nthis full equation, we have an expectation\nover our task distribution.",
    "start": "2314890",
    "end": "2321410"
  },
  {
    "text": "And then, we're actually\ninferring parameters phi i given training data\nset for task i.",
    "start": "2321410",
    "end": "2328570"
  },
  {
    "text": "Yeah. Yeah. And why do it with\nthe [INAUDIBLE]??",
    "start": "2328570",
    "end": "2332943"
  },
  {
    "text": "Yeah, great question. So you're asking, why\naren't we maximizing over the phi as well?",
    "start": "2335670",
    "end": "2340795"
  },
  {
    "text": "Yes. So you'll notice here\nthat we're only doing a maximization over theta. And here, phi corresponds\nto the latent variables.",
    "start": "2340795",
    "end": "2348760"
  },
  {
    "text": "And we're doing-- we're\ninferring those latent variables given the\ntraining data set.",
    "start": "2348760",
    "end": "2354190"
  },
  {
    "text": "And just like as we saw in\nthe meta-learning process, we're only optimizing over\ntheta here because phi",
    "start": "2354190",
    "end": "2361329"
  },
  {
    "text": "is more like a latent variable\nand more like activations and less like a\nunderlying parameter.",
    "start": "2361330",
    "end": "2373720"
  },
  {
    "text": "This is potentially where\nthe overloading notation that I mentioned before can\nget a little bit confusing,",
    "start": "2373720",
    "end": "2379810"
  },
  {
    "text": "is phi is no longer\nrepresenting the parameters of the inference network. Like in standard VAEs, it's\nrepresenting the latent",
    "start": "2379810",
    "end": "2387490"
  },
  {
    "text": "variable. And so, in VAEs, for example,\nwe don't optimize over z because it's a latent variable.",
    "start": "2387490",
    "end": "2393580"
  },
  {
    "text": "Yeah. So with the terminology\ncan I create it as an encoder which is\nparameterized by theta, which",
    "start": "2393580",
    "end": "2401980"
  },
  {
    "text": "[INAUDIBLE] from\ntraining data to phi i if I understand correct?",
    "start": "2401980",
    "end": "2407800"
  },
  {
    "text": "Yeah, exactly. So you can-- in\na sense that this is like a variational\nauto-encoder, you could sort of view\nthis as an auto-encoder",
    "start": "2407800",
    "end": "2413710"
  },
  {
    "text": "that where the latent\nvariable are these parameters. And the thing that\nyou're inferring--",
    "start": "2413710",
    "end": "2419080"
  },
  {
    "text": "that your auto-encoding\nis the data, essentially. Yeah.",
    "start": "2419080",
    "end": "2424579"
  },
  {
    "text": "So p is the neural network\nthat's taking the data and outputting\nthe phi i's right?",
    "start": "2424580",
    "end": "2431420"
  },
  {
    "text": "So in this case, actually\nq is the neural network that's taking in the data\nand outputting the phi i's.",
    "start": "2434920",
    "end": "2440560"
  },
  {
    "text": "And p is the neural network\nthat is then taking those phi",
    "start": "2440560",
    "end": "2446170"
  },
  {
    "text": "i's and making predictive\nlabels from those phi i's. And so, in the terminology\nthat we were using before,",
    "start": "2446170",
    "end": "2453550"
  },
  {
    "text": "q corresponds to f,\nand p corresponds to g. Oh, OK.",
    "start": "2453550",
    "end": "2457780"
  },
  {
    "text": "Cool. So here's the equation again. This is kind of\nthe first approach",
    "start": "2467140",
    "end": "2474630"
  },
  {
    "text": "that we'll see that can actually\nrepresent a distribution over task-specific parameters.",
    "start": "2474630",
    "end": "2480900"
  },
  {
    "text": "And this is kind of a black-box\nvariant of the approach. And this alleviates\nkind of the shortcomings",
    "start": "2480900",
    "end": "2486393"
  },
  {
    "text": "that we saw with\ntrying to do something like maximum likelihood.",
    "start": "2486393",
    "end": "2489120"
  },
  {
    "text": "This means that it can actually\nnow represent non-Gaussian distributions over the test-- over the labels, because it\nwill represent a Gaussian",
    "start": "2492340",
    "end": "2498600"
  },
  {
    "text": "distribution over phi and then\npredict the labels from samples",
    "start": "2498600",
    "end": "2504120"
  },
  {
    "text": "from that distribution. And kind of the\nimportant bit is that can produce a distribution\nover functions",
    "start": "2504120",
    "end": "2509910"
  },
  {
    "text": "rather than just producing\na distribution over labels.",
    "start": "2509910",
    "end": "2512160"
  },
  {
    "text": "There are some downsides\nwith this approach. This means that it\ncan only represent Gaussian distributions\nover phi i.",
    "start": "2515780",
    "end": "2522770"
  },
  {
    "text": "And this can be\nunsatisfying if we want to be able to represent\nmore diverse distributions over functions.",
    "start": "2522770",
    "end": "2528515"
  },
  {
    "text": "Although, if you do have\na very deep network, Gaussian distributions\ncan actually-- they do actually end up\nbeing somewhat expressive.",
    "start": "2528515",
    "end": "2536280"
  },
  {
    "text": "Yeah. And that's the only\ncon of this approach.",
    "start": "2536280",
    "end": "2538880"
  },
  {
    "text": "Cool. So this is the-- I think that if you were to\ndo a Bayesian meta-learning algorithm with a\nblack-box approach,",
    "start": "2543420",
    "end": "2548783"
  },
  {
    "text": "I think that this is a\npretty good one to use. I'm also-- not sure if there's\nany particular paper that",
    "start": "2548783",
    "end": "2556694"
  },
  {
    "text": "goes into this. But if you're interested\nin kind of reading more about an approach\nthat looks like this, we can also send some\npaper references.",
    "start": "2556695",
    "end": "2564849"
  },
  {
    "text": "Great. So then, let's talk about some\noptimization-based approaches.",
    "start": "2564850",
    "end": "2570200"
  },
  {
    "text": "So one way to look at\nit, one way to look",
    "start": "2570200",
    "end": "2575650"
  },
  {
    "text": "at kind of\noptimization-based approaches is actually through a\nsomewhat crude Bayesian lens.",
    "start": "2575650",
    "end": "2583750"
  },
  {
    "text": "And in particular, if you think\nabout your graphical model as this, which is essentially\nthe same as the graphical model",
    "start": "2583750",
    "end": "2591100"
  },
  {
    "text": "that we saw before, except\nwe're now collapsing the data sets into\na single node.",
    "start": "2591100",
    "end": "2596275"
  },
  {
    "text": "If we're trying to maximize the\nlikelihood of our data given our meta-parameters\ntheta, we can essentially",
    "start": "2600400",
    "end": "2608710"
  },
  {
    "text": "use what's called empirical\nBayes to write out that likelihood as the\nexpression below, which",
    "start": "2608710",
    "end": "2620800"
  },
  {
    "text": "is an integral over our\ntask-specific parameters phi, representing the data given\nphi and phi given theta.",
    "start": "2620800",
    "end": "2627085"
  },
  {
    "text": "And what you can do is you\ncan kind of somewhat crudely approximate your distribution\nof phi i given theta",
    "start": "2629600",
    "end": "2638260"
  },
  {
    "text": "with the MAP estimate, the\nmaximum a posteriori estimate. And this is a\nreasonable approximation",
    "start": "2638260",
    "end": "2647110"
  },
  {
    "text": "in cases where you have a\nvery peaky distribution, where the MAP estimate\ncorresponds to a large part",
    "start": "2647110",
    "end": "2652900"
  },
  {
    "text": "of the distribution. And one of the things\nthat's kind of cool is there is actually\nthis connection",
    "start": "2652900",
    "end": "2659050"
  },
  {
    "text": "between gradient descent\nand early stopping, aka kind of what things like MAML do.",
    "start": "2659050",
    "end": "2665200"
  },
  {
    "text": "And doing MAP inference in\nparticular under a Gaussian prior with the mean and\nthe initial parameters.",
    "start": "2665200",
    "end": "2673862"
  },
  {
    "text": "And you can actually show\nthat there's actually an exact relationship between\nMAP inference and gradient descent with early stopping\nin the linear case.",
    "start": "2673862",
    "end": "2681910"
  },
  {
    "text": "In the nonlinear case,\nthat's approximate. And what this tells\nus is essentially",
    "start": "2681910",
    "end": "2687280"
  },
  {
    "text": "gives us a Bayesian\ninterpretation of the MAML algorithm, where you\ncan view MAML as optimizing--",
    "start": "2687280",
    "end": "2695200"
  },
  {
    "text": "under this kind\nof approximation, you can view MAML as\noptimizing for a Gaussian",
    "start": "2695200",
    "end": "2701590"
  },
  {
    "text": "prior or the mean\nof a Gaussian prior, such that when you\ndo MAP inference",
    "start": "2701590",
    "end": "2708310"
  },
  {
    "text": "you get a good solution.",
    "start": "2708310",
    "end": "2713050"
  },
  {
    "text": "So this is one\ncool interpretation of the algorithm. That said, with this\ninterpretation we're not",
    "start": "2715880",
    "end": "2721630"
  },
  {
    "text": "able to sample parameters. We're using this MAP estimate\nto estimate the distribution",
    "start": "2721630",
    "end": "2726910"
  },
  {
    "text": "of phi given theta. And as a result,\nit isn't kind of too useful from a\nBayesian perspective",
    "start": "2726910",
    "end": "2732280"
  },
  {
    "text": "because we're getting rid\nof the thing that makes it Bayesian, which is that\nwe're using this point estimate rather than\nthe full distribution.",
    "start": "2732280",
    "end": "2740577"
  },
  {
    "text": "And so, in terms of\ndeveloping an algorithm, we'd like to develop an\noptimization-based algorithm that actually kind of represents\nthis distribution over phi",
    "start": "2740577",
    "end": "2747089"
  },
  {
    "text": "given theta. And so, if we recall the\nobjective that we saw before",
    "start": "2747090",
    "end": "2756120"
  },
  {
    "text": "for black-box methods, one thing\nthat you can remember is that",
    "start": "2756120",
    "end": "2761340"
  },
  {
    "text": "q-- I mean, the inference\nnetwork q, it could really be an arbitrary function.",
    "start": "2761340",
    "end": "2768150"
  },
  {
    "text": "It can get conditioned on a\nvariety of different things. And it's just a\nfunction that you learn.",
    "start": "2768150",
    "end": "2773972"
  },
  {
    "text": "And so, the first thing that\nyou could think about in terms of an optimization-based\nalgorithm is what if we put a\ngradient operator into q?",
    "start": "2773972",
    "end": "2780660"
  },
  {
    "text": "And instead of using\na black-box method, we could essentially use a--\nincorporate gradient descent",
    "start": "2783300",
    "end": "2790230"
  },
  {
    "text": "into the inference\nprocess for q. And then you get an algorithm\ncalled amortized-- well,",
    "start": "2790230",
    "end": "2798839"
  },
  {
    "text": "an amortized Bayesian learning\nalgorithm, where essentially q corresponds to\nrunning SGD on the mean",
    "start": "2798840",
    "end": "2804299"
  },
  {
    "text": "and variance of\nneural network weights with respect to\nyour training data.",
    "start": "2804300",
    "end": "2809100"
  },
  {
    "text": "And so, in particular, instead\nof having a neural network that outputs phi i given\nyour training data,",
    "start": "2813530",
    "end": "2820660"
  },
  {
    "text": "you're going to have-- theta is going to correspond\nto this mean and this variance.",
    "start": "2820660",
    "end": "2826150"
  },
  {
    "text": "And this network\nqi, it's no longer going to be a neural network. It's going to be\na procedure that",
    "start": "2826150",
    "end": "2832055"
  },
  {
    "text": "runs gradient descent on\nthose parameters with respect to your training data.",
    "start": "2832055",
    "end": "2835540"
  },
  {
    "text": "Any questions on how this works?",
    "start": "2839920",
    "end": "2841319"
  },
  {
    "text": "Now, one thing you\nmight be wondering is, how can we run\ngradient descent on a mean in a variance?",
    "start": "2859768",
    "end": "2866020"
  },
  {
    "text": "To do that we can essentially\nuse the same reparameterization trick that we saw\nbefore, where we--",
    "start": "2866020",
    "end": "2872725"
  },
  {
    "text": "essentially the neural\nnetwork weights, we're going to be representing\nthis distribution over phi i.",
    "start": "2872725",
    "end": "2878560"
  },
  {
    "text": "And I'm going to get\nout a whiteboard marker.",
    "start": "2878560",
    "end": "2884800"
  },
  {
    "text": "So q of phi i--",
    "start": "2891830",
    "end": "2897810"
  },
  {
    "text": "sorry. q of phi i with respect\nto D train and theta.",
    "start": "2897810",
    "end": "2908950"
  },
  {
    "text": "Theta will correspond to\nthis mean and variance.",
    "start": "2908950",
    "end": "2915310"
  },
  {
    "text": "And then, this function is going\nto be running gradient descent on your mean and variance.",
    "start": "2915310",
    "end": "2921370"
  },
  {
    "text": "Where you-- and\nparticularly, the way that you run gradient\ndescent is that you'll use a reparameterization\ntrick again,",
    "start": "2921370",
    "end": "2927190"
  },
  {
    "text": "where you'll get\nsomething like a sample,",
    "start": "2927190",
    "end": "2935829"
  },
  {
    "text": "not sure how best\nto represent this. You can essentially\nsample from this data by taking mu plus sigma\ntimes some noise, where",
    "start": "2935830",
    "end": "2943990"
  },
  {
    "text": "sigma is drawn from a standard\nGaussian distribution. And then treat this as the\nweights of your neural network,",
    "start": "2943990",
    "end": "2953140"
  },
  {
    "text": "and back-propagate\ninto these two values. And you'll be essentially\nrunning gradient descent",
    "start": "2953140",
    "end": "2959470"
  },
  {
    "text": "with respect to mu and\nsigma, where the phi i will",
    "start": "2959470",
    "end": "2966130"
  },
  {
    "text": "be represented as-- or this distribution\nover phi i will be represented as a Gaussian\ndistribution with mean--",
    "start": "2966130",
    "end": "2976540"
  },
  {
    "text": "running out of notation to use-- mean mu i and variance sigma i.",
    "start": "2976540",
    "end": "2982870"
  },
  {
    "text": "And this is going to be-- these two variables\nare going to be equal to running gradient\ndescent on mu with respect",
    "start": "2982870",
    "end": "2996160"
  },
  {
    "text": "to your training\ndata, and running",
    "start": "2996160",
    "end": "3001740"
  },
  {
    "text": "gradient descent on sigma with\nrespect to your training data.",
    "start": "3001740",
    "end": "3006780"
  },
  {
    "text": "And in particular,\nthis will be-- when you run-- when you\nback-propagate the loss",
    "start": "3013370",
    "end": "3018650"
  },
  {
    "text": "of your training data\ninto mu and sigma, this will be actually a\nfunction of your current--",
    "start": "3018650",
    "end": "3024049"
  },
  {
    "text": "over kind of the parameters\nthat are represented by this.",
    "start": "3024050",
    "end": "3026900"
  },
  {
    "text": "Any questions on how this works?",
    "start": "3035030",
    "end": "3036505"
  },
  {
    "text": "I think I see more\nconfused faces than not.",
    "start": "3051590",
    "end": "3054240"
  },
  {
    "text": "Yeah. So once you get mu and sigma\nfor phi, then what do you do?",
    "start": "3061360",
    "end": "3066650"
  },
  {
    "text": "Great. So the question is, once you\nget mu and sigma for phi, what do you do from there? Great question. So this distribution\nis represented",
    "start": "3066650",
    "end": "3074860"
  },
  {
    "text": "by mu i, sigma i, which you get\nfrom running gradient descent. Once you get that,\nthen you can then",
    "start": "3074860",
    "end": "3084010"
  },
  {
    "text": "plug those in to our\nobjective from the black-box meta-learning algorithm\nand do the same thing",
    "start": "3084010",
    "end": "3089158"
  },
  {
    "text": "that we did before,\nwhere we're going to be kind of optimizing for the\nlower bound on the likelihood.",
    "start": "3089158",
    "end": "3096579"
  },
  {
    "text": "And so, in particular-- yeah. You'll be optimizing\non the lower bound. And then, at test time\nafter you optimize",
    "start": "3099100",
    "end": "3106180"
  },
  {
    "text": "for this inference\nnetwork, what you'll do is you'll have\nyour mu and sigma.",
    "start": "3106180",
    "end": "3111370"
  },
  {
    "text": "And you'll have a\ntraining data point. You'll run gradient descent. And so, you'll get each\nof these parameters.",
    "start": "3111370",
    "end": "3116543"
  },
  {
    "text": "And then, what you\ncan do is you can now sample phi i from this\nparticular Gaussian distribution.",
    "start": "3116543",
    "end": "3122890"
  },
  {
    "text": "And so, you'll then be able to\nsample parameters from here. And then that will be--",
    "start": "3122890",
    "end": "3129157"
  },
  {
    "text": "those will represent-- samples\nfrom this will represent things like a classifier based on\nage, a classifier based on hat,",
    "start": "3129157",
    "end": "3134710"
  },
  {
    "text": "and so forth. Yeah. So to clarify about the\ndifferent mus and sigmas",
    "start": "3134710",
    "end": "3141250"
  },
  {
    "text": "for myself, so the\ntheta, mu, and sigmas share a global mean and\nvariance of our distribution.",
    "start": "3141250",
    "end": "3148000"
  },
  {
    "text": "And then, what we\ndo is we refine it for a specific task with SGD. Yeah, exactly. So phi and sigma are a shared\nglobal mean invariance.",
    "start": "3148000",
    "end": "3155453"
  },
  {
    "text": "And then, we'll refine this\nmean and variance with respect to our specific task, with\nrespect to the training data. And that will give us a\ndistribution of our parameters",
    "start": "3155453",
    "end": "3162490"
  },
  {
    "text": "for that particular task. Yeah. So [INAUDIBLE] update\nour mu i and theta i",
    "start": "3162490",
    "end": "3168350"
  },
  {
    "text": "as the inner loop notation,\nand our [INAUDIBLE]",
    "start": "3168350",
    "end": "3173420"
  },
  {
    "text": "and theta as our outer\nloop optimization. Yeah, exactly. So this gradient descent\nprocess is the inner loop.",
    "start": "3173420",
    "end": "3180430"
  },
  {
    "text": "And then optimizing\nfor these parameters with respect to that objective\ncorresponds to the outer loop.",
    "start": "3180430",
    "end": "3186610"
  },
  {
    "text": "Yeah. So since the\n[INAUDIBLE] sigma, so I",
    "start": "3189930",
    "end": "3198480"
  },
  {
    "text": "guess [INAUDIBLE] the\nparameters of the neural network",
    "start": "3198480",
    "end": "3206640"
  },
  {
    "text": "or something like that. And-- Yeah. So the mu and sigma\nhere, this kind of now",
    "start": "3206640",
    "end": "3215460"
  },
  {
    "text": "corresponds to your theta. And this is what\nyou're optimizing over. In practice, what\nthis will be is",
    "start": "3215460",
    "end": "3223470"
  },
  {
    "text": "you'll essentially have twice\nthe number of meta-parameters. So before, you just had\nparameters-- in MAML,",
    "start": "3223470",
    "end": "3229829"
  },
  {
    "text": "you just had the\ninitialization of a model. Now you're going to have a\nmean of that initialization and a variance.",
    "start": "3229830",
    "end": "3235570"
  },
  {
    "text": "And so, you're essentially\ngoing to have two vectors that are the size of your parameter\nvector rather than just one.",
    "start": "3235570",
    "end": "3244113"
  },
  {
    "text": "So [INAUDIBLE] sample\nindividual [INAUDIBLE]??",
    "start": "3244113",
    "end": "3249565"
  },
  {
    "text": "Yeah. So once we have this\nmean and the variance, we'll run gradient descent\nto get the mu i and sigma i. And then, we'll sample from\nthis Gaussian distribution",
    "start": "3251730",
    "end": "3259630"
  },
  {
    "text": "to get weights over a\ntask-specific neural network.",
    "start": "3259630",
    "end": "3266150"
  },
  {
    "text": "Yeah. Is this making our\nupdates when you showed us the initial figure where you\nsaid they'd go in one direction",
    "start": "3266150",
    "end": "3272060"
  },
  {
    "text": "because you're looking--\nwe do have a sample point, and then just go to one\npath to take the update?",
    "start": "3272060",
    "end": "3278530"
  },
  {
    "text": "And by adding that, because\nwe're going to add noise to it and it's probably going\nto be some sample noise, and which is making those\nupdates more [INAUDIBLE]",
    "start": "3278530",
    "end": "3288140"
  },
  {
    "text": "in a sense? Yeah, so the-- And so the network has\nto be possibly taking gradient steps against\nthe noise, or [INAUDIBLE]??",
    "start": "3288140",
    "end": "3298960"
  },
  {
    "text": "Yes. So we had this diagram\nbefore with MAML where this is your\nfinal meta-parameters",
    "start": "3298960",
    "end": "3304039"
  },
  {
    "text": "and then this is phi\ni hat and so forth. And yeah, essentially the way\nthat you can think about this",
    "start": "3304040",
    "end": "3311300"
  },
  {
    "text": "is that now instead of\nhaving a single point you're going to have these kind\nof Gaussian distributions.",
    "start": "3311300",
    "end": "3316820"
  },
  {
    "text": "You'll have a Gaussian\ndistribution over theta. And this will correspond\nto-- you'll have mu and sigma that reads this. And then, now for\neach of these, you'll",
    "start": "3316820",
    "end": "3323185"
  },
  {
    "text": "also have your own\nGaussian distributions over these parameters. And this corresponds\nto phi i and sigma",
    "start": "3323185",
    "end": "3330485"
  },
  {
    "text": "i for each of those tasks. And then, ultimately,\nthis distribution",
    "start": "3330485",
    "end": "3336950"
  },
  {
    "text": "will cover the set of parameters\nthat work well for that task. And so, rather than\nhaving a single point,",
    "start": "3336950",
    "end": "3343050"
  },
  {
    "text": "you'll have a distribution\nover those parameters. Does that answer your question?",
    "start": "3343050",
    "end": "3348660"
  },
  {
    "text": "I think so. And then in the update\nstep, [INAUDIBLE] going to have noise, right?",
    "start": "3348660",
    "end": "3354690"
  },
  {
    "text": "And so my update\nsteps in the direction are going to have to\nbe more robust, right? Theoretically speaking.",
    "start": "3354690",
    "end": "3361350"
  },
  {
    "text": "So the updates will\nbe with respect to-- you'll be differentiating\nkind of through the parameters",
    "start": "3361350",
    "end": "3366980"
  },
  {
    "text": "of the Gaussian. They won't necessarily\nhave noise per se. [INAUDIBLE] sample from the\nnormal distribution, right?",
    "start": "3366980",
    "end": "3374010"
  },
  {
    "text": "Right. Yeah. You will be sampling epsilon-- for each of these steps. And so you will have noise. Before it was just zero, right?",
    "start": "3374010",
    "end": "3379870"
  },
  {
    "text": "Our epsilon was zero,\nso we just had a mu? Yeah. Before, epsilon was zero,\nand you just had mu. Exactly.",
    "start": "3379870",
    "end": "3384070"
  },
  {
    "text": "Yeah. Are these mu and sigma part\nof the prior distribution in the KL divergence\nthat we're trying to roughly, like\ncorresponding back",
    "start": "3386660",
    "end": "3392885"
  },
  {
    "text": "to the variational inference? Yeah, exactly. So this mu and sigma--",
    "start": "3392885",
    "end": "3399349"
  },
  {
    "text": "well, sorry, actually. This mu and sigma are\nyour kind of parameters",
    "start": "3399350",
    "end": "3408880"
  },
  {
    "text": "for your task-specific\ndistribution. And then, you'll have this KL\nterm that encourages these mu",
    "start": "3408880",
    "end": "3413927"
  },
  {
    "text": "and sigmas to be close to\na standard unit Gaussian.",
    "start": "3413927",
    "end": "3417475"
  },
  {
    "text": "Yeah. So the difference between\nthis q as a gradient of theta",
    "start": "3419830",
    "end": "3425000"
  },
  {
    "text": "and the black-box one is that\nthe biggest problem optimizing",
    "start": "3425000",
    "end": "3430250"
  },
  {
    "text": "mu and sigma, we would just-- here it's outputting\nthe mu and sigma, and then you just grab a\nsample from that, [INAUDIBLE]??",
    "start": "3430250",
    "end": "3437085"
  },
  {
    "text": "Yeah, exactly. So in the black-box approach,\ninstead of having running",
    "start": "3440840",
    "end": "3446869"
  },
  {
    "text": "gradient descent, we\njust had some function-- I can't-- I'll refer to it\nas f, that takes as input mu",
    "start": "3446870",
    "end": "3458660"
  },
  {
    "text": "and sigma and D train and\noutputs mu i and sigma i.",
    "start": "3458660",
    "end": "3464714"
  },
  {
    "text": "You can essentially\nthink of it as just like a neural network\nthat takes it-- that produces these things.",
    "start": "3464715",
    "end": "3471271"
  },
  {
    "text": "[INAUDIBLE] we don't necessarily\nneed to be restricted to Gaussians, but--",
    "start": "3471271",
    "end": "3477912"
  },
  {
    "text": "This doesn't need\nto be a Gaussian. And so, this can just be theta. You don't really need\nit to be anything.",
    "start": "3477912",
    "end": "3484980"
  },
  {
    "text": "This is still restricted\nto be Gaussian. Because we're going to be--",
    "start": "3484980",
    "end": "3491300"
  },
  {
    "text": "on the slides you see you have\nthe expectation with respect to q, and you also have\nthis KL divergence. To optimize through\nthat expectation,",
    "start": "3491300",
    "end": "3497930"
  },
  {
    "text": "you need to be Gaussian to use\nthe reparameterization trick. And for the KL, it's\nalso convenient for it",
    "start": "3497930",
    "end": "3503480"
  },
  {
    "text": "to be Gaussian so that\nyou can measure the KL divergence in closed form. So in a way, when we\nsample these phi parameters",
    "start": "3503480",
    "end": "3511865"
  },
  {
    "text": "to a Gaussian, there's\nno disputing that? Yeah. So, so far, we've\nonly seen approaches",
    "start": "3511865",
    "end": "3518480"
  },
  {
    "text": "that have a Gaussian\ndistribution over phi i. On the next few\nslides, we'll see",
    "start": "3518480",
    "end": "3525589"
  },
  {
    "text": "some non-Gaussian\napproaches as well. Yeah. Does the loss\nfunction [INAUDIBLE]??",
    "start": "3525590",
    "end": "3533029"
  },
  {
    "text": "Does the loss function\nfor the inner loop include a forward pass through p?",
    "start": "3537598",
    "end": "3542835"
  },
  {
    "text": "Yeah. Yeah. So this is going to\ninvolve a forward pass through the network\nparameterized by mu and sigma.",
    "start": "3542835",
    "end": "3550619"
  },
  {
    "text": "That doesn't necessarily\ncorrespond to p per se.",
    "start": "3550620",
    "end": "3559800"
  },
  {
    "text": "Because a p here is\nrepresenting the model that has parameters phi i. But I guess, in that sense,\nit is taking a forward pass",
    "start": "3559800",
    "end": "3567285"
  },
  {
    "text": "through a neural network\nthat's parameterized by samples from phi and sigma.",
    "start": "3567285",
    "end": "3572339"
  },
  {
    "text": "Cool. So the benefit of this is\nunlike a black-box approach, you're still running gradient\ndescent at test time.",
    "start": "3579228",
    "end": "3589790"
  },
  {
    "text": "And you are actually-- so you're\nrunning gradient descent test time and you are getting a\ndistribution over parameters",
    "start": "3589790",
    "end": "3596000"
  },
  {
    "text": "by running gradient descent\non the mean and the variance. The downside, of course, is\nthat we're still modeling phi",
    "start": "3596000",
    "end": "3602225"
  },
  {
    "text": "i as a Gaussian distribution. We're just getting these\nmeans and variances.",
    "start": "3602225",
    "end": "3606020"
  },
  {
    "text": "So can we model a\nnon-Gaussian posterior is kind of the\nnext key question.",
    "start": "3608550",
    "end": "3613279"
  },
  {
    "text": "So the first thing\nthat we'll look at to get a non-Gaussian\nposterior is to use ensembles.",
    "start": "3617078",
    "end": "3624230"
  },
  {
    "text": "And ensembles are\npretty nice in the sense that it's actually very easy\nto get non-Gaussian posteriors",
    "start": "3624230",
    "end": "3631220"
  },
  {
    "text": "because, essentially,\nyou're representing different samples\nfrom your posterior rather than the posterior\ndistribution itself.",
    "start": "3631220",
    "end": "3639870"
  },
  {
    "text": "And so, they refer to this\nalgorithm as an ensemble of--",
    "start": "3639870",
    "end": "3645710"
  },
  {
    "text": "or the base version of an\nalgorithm as an ensemble of MAMLs or EMAML. And this will essentially just\ntrain m independent MAML models",
    "start": "3645710",
    "end": "3656450"
  },
  {
    "text": "completely independently. Here's an ensemble of MAMLs. And yeah, it's also worth\nmentioning that you can also",
    "start": "3656450",
    "end": "3663320"
  },
  {
    "text": "use ensembles with black-box and\nnonparametric methods as well. And that will also give you\nessentially non-Gaussian",
    "start": "3663320",
    "end": "3673820"
  },
  {
    "text": "posteriors. Yeah. How do you make sure the MAMLs\nare independent [INAUDIBLE]??",
    "start": "3673820",
    "end": "3680430"
  },
  {
    "text": "Yeah. So how do you how do you assure\nthat they're independent? Typically what you do is\nyou kind of train it--",
    "start": "3680430",
    "end": "3689266"
  },
  {
    "text": "[INAUDIBLE]? So I guess there's a few\ndifferent ways to do it. Typically, you'll definitely\nmake the initialization--",
    "start": "3689266",
    "end": "3696070"
  },
  {
    "text": "the random initialization\nof the algorithm different. You'll also change\nthe random seed so that they see batches\nin different orders.",
    "start": "3696070",
    "end": "3705430"
  },
  {
    "text": "The kind of theory says\nthat you should also train it on different bootstraps\nof your meta-training data,",
    "start": "3705430",
    "end": "3712120"
  },
  {
    "text": "meaning that you should\nresample your data and not use all of it.",
    "start": "3712120",
    "end": "3717490"
  },
  {
    "text": "In practice, in deep\nlearning, people have found that you\ndon't need to do that. You only need to change\nthe random initialization",
    "start": "3717490",
    "end": "3724540"
  },
  {
    "text": "and the seed that's used\nfor the mini-batching. And that will already usually\ngive you pretty good ensembles.",
    "start": "3724540",
    "end": "3731890"
  },
  {
    "text": "So this can work pretty well. It won't work well if\nthe ensemble members",
    "start": "3737730",
    "end": "3743810"
  },
  {
    "text": "are too similar to one another. And this can sometimes\nhappen because you're--",
    "start": "3743810",
    "end": "3749359"
  },
  {
    "text": "I mean, you're training\non the same data. And so, there is an\nalternative to the approach",
    "start": "3749360",
    "end": "3755030"
  },
  {
    "text": "that actually tries to make\nthe ensemble more diverse. And what it does is, it\nessentially has an ensemble",
    "start": "3755030",
    "end": "3761990"
  },
  {
    "text": "but it tries to push\naway the particles-- it tries to push away\nthe different parameters",
    "start": "3761990",
    "end": "3767360"
  },
  {
    "text": "from each other. And the way this works\nis you train an ensemble. And so, j here is indexing the\ndifferent ensemble elements.",
    "start": "3767360",
    "end": "3776210"
  },
  {
    "text": "And then you have\nthis repulsion term that's referred to as\nthis kind of kernel",
    "start": "3776210",
    "end": "3782000"
  },
  {
    "text": "between the parameters.",
    "start": "3782000",
    "end": "3788010"
  },
  {
    "text": "And this will essentially\ntry to make it so that the ensemble\nmembers are more different from one another.",
    "start": "3788010",
    "end": "3794210"
  },
  {
    "text": "Unfortunately, getting good\nkernels in weight space is difficult. And so, this can\nusually help to some degree.",
    "start": "3794210",
    "end": "3803620"
  },
  {
    "text": "But it doesn't always\nhelp that much.",
    "start": "3803620",
    "end": "3809030"
  },
  {
    "text": "And here's an example of\na more diverse ensemble.",
    "start": "3809030",
    "end": "3811400"
  },
  {
    "text": "Great. And then you\noptimize, of course, for the distribution\nof particles to produce high likelihood.",
    "start": "3814560",
    "end": "3819619"
  },
  {
    "text": "Cool. And so, here's what the\nlikelihood term looks like, which you will--",
    "start": "3825350",
    "end": "3830510"
  },
  {
    "text": "yeah. Cool. So the benefit of\nusing ensembles",
    "start": "3830510",
    "end": "3835680"
  },
  {
    "text": "is that it's pretty simple. It tends to work quite\nwell for producing non-Gaussian distributions.",
    "start": "3835680",
    "end": "3841800"
  },
  {
    "text": "The downside is\nthat you often need to maintain different\ninstances of your model. And so, this can be\ncomputationally expensive",
    "start": "3841800",
    "end": "3848039"
  },
  {
    "text": "and also\nmemory-intensive as well.",
    "start": "3848040",
    "end": "3851490"
  },
  {
    "text": "One trick for getting\naway from this downside is to have the ensemble\nonly over the latter part",
    "start": "3854100",
    "end": "3860549"
  },
  {
    "text": "of the network and to have a\nshared backbone, where you're essentially doing kind of\ngradient-based inference",
    "start": "3860550",
    "end": "3866670"
  },
  {
    "text": "on the last layer only\nor the last few layers. And this actually does\nhelp a lot with memory",
    "start": "3866670",
    "end": "3873450"
  },
  {
    "text": "and computation, of course. It often produces less\ndiverse ensembles. But it can be pretty helpful.",
    "start": "3873450",
    "end": "3879630"
  },
  {
    "text": "Cool. Great. And then, I guess, any\nquestions about ensembles?",
    "start": "3884670",
    "end": "3892109"
  },
  {
    "text": "How often in the task\ndo we need to have non-Gaussian\ndistribution [INAUDIBLE]??",
    "start": "3892110",
    "end": "3897052"
  },
  {
    "text": "Yeah. So the question is,\nhow often do we need non-Gaussian distributions?",
    "start": "3900060",
    "end": "3903675"
  },
  {
    "text": "It's kind of hard to say. I think that-- I\nmean, in some ways I think the objection to\nGaussian distributions",
    "start": "3906530",
    "end": "3911578"
  },
  {
    "text": "is more philosophical in\nsome ways than practical. Because it seems\njust very inelegant",
    "start": "3911578",
    "end": "3916789"
  },
  {
    "text": "to have Gaussian\ndistributions over parameters when your parameters\nare a neural network. And they probably are--",
    "start": "3916790",
    "end": "3922190"
  },
  {
    "text": "probably the true\ndistribution over parameters is very much not Gaussian.",
    "start": "3922190",
    "end": "3925595"
  },
  {
    "text": "I think that-- there is\nactually a paper that shows that if you have\na super deep network, Gaussian distributions\ncan represent a lot.",
    "start": "3928520",
    "end": "3935877"
  },
  {
    "text": "And the intuition for that\nis that if you have something Gaussian at the first layer,\nthen the neural network will transform\nthat distribution--",
    "start": "3935877",
    "end": "3942589"
  },
  {
    "text": "the later layers of\nthe neural network will transform it into something\nthat is very much not Gaussian.",
    "start": "3942590",
    "end": "3948300"
  },
  {
    "text": "And so, I think that it varies. If you can use a pretty-- if\nyou're using a large network",
    "start": "3948300",
    "end": "3953420"
  },
  {
    "text": "and you really care about\nperformance and practice, then Gaussian distributions\nare probably fine.",
    "start": "3953420",
    "end": "3958730"
  },
  {
    "text": "If you don't like\nGaussians in weight space, or have a smaller network, then\nit's probably less efficient.",
    "start": "3961260",
    "end": "3968710"
  },
  {
    "text": "Yeah. [INAUDIBLE] for the\nprevious approaches with black-box and the\noptimization-based Bayesian",
    "start": "3968710",
    "end": "3976010"
  },
  {
    "text": "meta-learning? It doesn't necessarily\nhave to be a Gaussian, but it could be any\nother distribution",
    "start": "3976010",
    "end": "3981620"
  },
  {
    "text": "that we can parameterize with\nsome some set of parameters? Yeah.",
    "start": "3981620",
    "end": "3986900"
  },
  {
    "text": "So it doesn't have\nto be Gaussian. The main reasons why\nwe're using Gaussian is because the\nreparameterization trick",
    "start": "3986900",
    "end": "3992690"
  },
  {
    "text": "and because the KL\ndivergence is easier to-- you can measure it in\nclosed form for Gaussians.",
    "start": "3992690",
    "end": "4000680"
  },
  {
    "text": "The first one is\nreally the big one, is how do you back-propagate\nthrough sampling.",
    "start": "4000680",
    "end": "4006070"
  },
  {
    "text": "You can approximate that\nfor other distributions as well, although the\napproximations are",
    "start": "4006070",
    "end": "4011769"
  },
  {
    "text": "a little bit ugly and just\nrather hacky in general.",
    "start": "4011770",
    "end": "4017500"
  },
  {
    "text": "You can try to-- there's\nthings like the Gumbel-Softmax and the straight-through\nestimator that try to back-propagate\nthrough discrete things.",
    "start": "4017500",
    "end": "4024370"
  },
  {
    "text": "There are some\napproximations that you can use for mixtures\nof Gaussians as well. But in general, back-propagating\nthrough sampling",
    "start": "4024370",
    "end": "4032050"
  },
  {
    "text": "for non-Gaussian distributions\nis rather difficult. Can you explain how the\nreparameterization trick",
    "start": "4032050",
    "end": "4038859"
  },
  {
    "text": "is helping with this\ngradient propagation? Yeah.",
    "start": "4038860",
    "end": "4044140"
  },
  {
    "text": "So I'll do this slide. So we need to\nback-propagate into this q.",
    "start": "4044140",
    "end": "4051619"
  },
  {
    "text": "So we have this expectation\nwith respect to q. We're going to estimate this\nexpectation by sampling from q.",
    "start": "4051620",
    "end": "4057292"
  },
  {
    "text": "And then, we need\nto back-propagate into the distribution\nthat we're sampling from. When you have a\nGaussian distribution,",
    "start": "4057292",
    "end": "4065830"
  },
  {
    "text": "you can represent samples from\nthat Gaussian distribution with this form,\nwhere you sample--",
    "start": "4065830",
    "end": "4072190"
  },
  {
    "text": "you can essentially\ndecouple the noise from the parameters of\nthe distribution, where the noise corresponds to some\nstandard Gaussian distribution.",
    "start": "4072190",
    "end": "4084070"
  },
  {
    "text": "And this-- because it has\nthis very nice form where it's decoupled, you can actually\nvery nicely back-propagate",
    "start": "4084070",
    "end": "4090340"
  },
  {
    "text": "into mu and sigma by sampling\nthis noise independently and then running your gradient\nthrough with that sample noise.",
    "start": "4090340",
    "end": "4101370"
  },
  {
    "text": "And it's because\nit decomposes it into the noise and the\ndistribution parameters that makes it possible to\nback-propagate into.",
    "start": "4101370",
    "end": "4109509"
  },
  {
    "text": "Yeah. [INAUDIBLE] combined\n[INAUDIBLE]??",
    "start": "4109510",
    "end": "4115679"
  },
  {
    "text": "Yeah. So the question was, in the\nensemble-based approaches, how do you combine\nthe predictions into a single prediction?",
    "start": "4115679",
    "end": "4121840"
  },
  {
    "text": "One of the most common\napproaches in deep learning is to take the distributions and\ndo some sort of majority vote,",
    "start": "4126511",
    "end": "4133270"
  },
  {
    "text": "for example. The thing that is\nthe most likely, you could also average\nthe distributions.",
    "start": "4133270",
    "end": "4139210"
  },
  {
    "text": "We'll see in a couple of\nslides how we can use them for other things as well.",
    "start": "4139210",
    "end": "4145630"
  },
  {
    "text": "But those are the two\nmost common approaches. Yeah.",
    "start": "4145630",
    "end": "4151219"
  },
  {
    "text": "Yeah. Sort of related\nto that question, so when we do ensemble\nmethods with meta-learning,",
    "start": "4151220",
    "end": "4158540"
  },
  {
    "text": "do we keep the\nmodels independent all the way through? Or do you want training\nat meta-test time?",
    "start": "4158540",
    "end": "4168236"
  },
  {
    "text": "Do you keep the\nmodels independently, even when adapting a-- [INTERPOSING VOICES] Yeah.",
    "start": "4168237",
    "end": "4173830"
  },
  {
    "text": "Yeah, you do. You typically do that. Yeah, exactly. And so, even when you're\nadapting at test time,",
    "start": "4173830",
    "end": "4179170"
  },
  {
    "text": "you'll be running\ngradient descent with respect to each of\nthe models independently. And then you'll get\na final prediction.",
    "start": "4179170",
    "end": "4186029"
  },
  {
    "text": "Yeah. [INAUDIBLE] sample\ndifferent parameters phi for then [INAUDIBLE].",
    "start": "4186030",
    "end": "4192000"
  },
  {
    "text": "Yeah. So if you want a lot\nof samples from phi, you need an ensemble for every\nsingle sample that you want.",
    "start": "4196730",
    "end": "4202720"
  },
  {
    "text": "If you want 100 samples, then\nyou need 100 ensemble elements. And so, yeah, it can be pretty\nexpensive because you usually",
    "start": "4202720",
    "end": "4211540"
  },
  {
    "text": "want m to be fairly large. And you're fairly\nlimited by that.",
    "start": "4211540",
    "end": "4216848"
  },
  {
    "text": "In practice, when people\ntypically use ensembles, they use, I don't know,\nthree to 10 instances.",
    "start": "4216848",
    "end": "4222850"
  },
  {
    "text": "Sometimes-- I mean, it really\ndepends on the application. But that's a ballpark\nestimate for what people do.",
    "start": "4222850",
    "end": "4230445"
  },
  {
    "text": "And if you have\nmore compute, you can do more than\nthat, of course. Yeah.",
    "start": "4230445",
    "end": "4235930"
  },
  {
    "text": "And that's one-- that's why this\ncon definitely is potentially a big one.",
    "start": "4235930",
    "end": "4240760"
  },
  {
    "text": "Cool. And then, the last\nmethod that we'll cover tries to get a\nnon-Gaussian posterior",
    "start": "4246270",
    "end": "4253920"
  },
  {
    "text": "over all the parameters without\nrequiring m model instances.",
    "start": "4253920",
    "end": "4260463"
  },
  {
    "text": "We don't have too much time. So I'm going to go through this\nsomewhat quickly because I also want to get to the last part.",
    "start": "4260463",
    "end": "4266639"
  },
  {
    "text": "And in particular, we're going\nto try to sample parameter vectors with a procedure that\nlooks like Hamiltonian Monte",
    "start": "4266640",
    "end": "4273000"
  },
  {
    "text": "Carlo. HMC maybe sounds\nkind of complicated.",
    "start": "4273000",
    "end": "4278010"
  },
  {
    "text": "But the way that it works\nends up being fairly simple. The way that it works is,\nyou add noise, and then run",
    "start": "4278010",
    "end": "4285630"
  },
  {
    "text": "gradient descent from\nthe perturbed weights.",
    "start": "4285630",
    "end": "4290969"
  },
  {
    "text": "And so, in particular,\nintuitively what we'd like to happen is,\nsay that we're in the example",
    "start": "4290970",
    "end": "4296190"
  },
  {
    "text": "that we saw before. We want to learn a prior\nsuch that if we randomly add",
    "start": "4296190",
    "end": "4301740"
  },
  {
    "text": "noise and randomly\nkick the parameters, that will put us into different\nmodes of the distribution.",
    "start": "4301740",
    "end": "4308020"
  },
  {
    "text": "And so, if we have a very\nmultimodal distribution over weights, such as\nclassifiers corresponding",
    "start": "4308020",
    "end": "4313740"
  },
  {
    "text": "to different attributes,\nwe want to be in a place where if we are at the\ntop of this and randomly",
    "start": "4313740",
    "end": "4321475"
  },
  {
    "text": "kind of add noise and\nthen run gradient descent, we'll get into one of the\nmodes of that distribution.",
    "start": "4321475",
    "end": "4330280"
  },
  {
    "text": "And so, if we add\nnoise to theta, we'll then push it in\none of these directions. We'll then run gradient descent,\nwhich will then put us in the--",
    "start": "4330280",
    "end": "4339780"
  },
  {
    "text": "producing a classifier that\nhas those different attributes.",
    "start": "4339780",
    "end": "4345550"
  },
  {
    "text": "So that's the intuition. The way that it\nends up working is,",
    "start": "4345550",
    "end": "4351090"
  },
  {
    "text": "we have some initial\nparameters theta. We're going to be\nadding noise to this.",
    "start": "4351090",
    "end": "4357100"
  },
  {
    "text": "So we're going to have a\nGaussian distribution, where adding noise to it\nessentially corresponds to sampling from\nthat Gaussian, where",
    "start": "4357100",
    "end": "4363870"
  },
  {
    "text": "the mean is the starting point. So we're no longer going to\nhave a single parameter vector",
    "start": "4363870",
    "end": "4370170"
  },
  {
    "text": "for that initial parameters. We're going to now have\na mean and a variance just like we had the mean\nand the variance here.",
    "start": "4370170",
    "end": "4379200"
  },
  {
    "text": "Then we're going to sample\na phi, or a additional phi",
    "start": "4379200",
    "end": "4385650"
  },
  {
    "text": "ultimately by trying to\nrepresent this distribution.",
    "start": "4385650",
    "end": "4390927"
  },
  {
    "text": "We want to be able to\nrepresent this distribution. Unfortunately, this\ndistribution is-- I guess, well, the\nfirst thing that we",
    "start": "4390927",
    "end": "4397500"
  },
  {
    "text": "can mention is that it's\nindependent of x tests. It really only depends\non the training data. Ultimately, this\ndistribution corresponds",
    "start": "4397500",
    "end": "4403980"
  },
  {
    "text": "to this really nasty integral\nover our initial parameters theta, which we don't\nwant to deal with.",
    "start": "4403980",
    "end": "4412770"
  },
  {
    "text": "This is really intractable. And so, what we're\ngoing to do is",
    "start": "4412770",
    "end": "4419070"
  },
  {
    "text": "say that we knew the\ndistribution of phi given theta by x train and y train.",
    "start": "4419070",
    "end": "4426869"
  },
  {
    "text": "And in particular, we're going\nto just set this distribution to be gradient descent if\nwe have a sample of theta.",
    "start": "4426870",
    "end": "4435659"
  },
  {
    "text": "Then if we have\nthis distribution, then sampling is\nvery easy, because we can sample a theta and\nthen sample from this.",
    "start": "4435660",
    "end": "4442860"
  },
  {
    "text": "And it kind of transforms\nthe graphical model into something that looks\nlike this, where you sample from theta, sample from phi,\ngiven theta and the training",
    "start": "4442860",
    "end": "4450280"
  },
  {
    "text": "data. And so, the key\nidea is that we're",
    "start": "4450280",
    "end": "4455790"
  },
  {
    "text": "going to essentially estimate\nthis distribution as the MAP estimate, like the crude\napproximation that we",
    "start": "4455790",
    "end": "4463050"
  },
  {
    "text": "saw before. And we can approximate this with\nMAP inference with a few steps",
    "start": "4463050",
    "end": "4470610"
  },
  {
    "text": "of gradient descent. This is very crude. It's also very convenient. And essentially, we're going\nto represent this distribution",
    "start": "4470610",
    "end": "4480120"
  },
  {
    "text": "as running one or a few\nsteps of gradient descent starting from the sampled theta.",
    "start": "4480120",
    "end": "4485355"
  },
  {
    "text": "And then, if you do\nthis approximation, then you can again do training\nwith the same kind of procedure",
    "start": "4488820",
    "end": "4494100"
  },
  {
    "text": "that we did before with\namortized variational inference.",
    "start": "4494100",
    "end": "4496620"
  },
  {
    "text": "Cool. So then what ancestral\nsampling will look like is just the same as\nwhat we saw before, where we have our mean of\nour Gaussian distribution.",
    "start": "4500120",
    "end": "4508700"
  },
  {
    "text": "We add noise, which\ncorresponds to sampling from that distribution. And then we run gradient\ndescent from that sampled theta",
    "start": "4508700",
    "end": "4522170"
  },
  {
    "text": "to get to the mode.",
    "start": "4522170",
    "end": "4524285"
  },
  {
    "text": "That was pretty quick. But the benefits of\nthis is that you can get a non-Gaussian posterior. It's pretty simple at test\ntime, because you just sample",
    "start": "4527613",
    "end": "4533630"
  },
  {
    "text": "and then run gradient descent. And you only have\none model instance, although you do have--",
    "start": "4533630",
    "end": "4538639"
  },
  {
    "text": "you still are going to\nhave the double parameter vector rather than just one. The downside is that it\nis a more complex training",
    "start": "4538640",
    "end": "4545450"
  },
  {
    "text": "procedure. Cool. So to summarize the methods\nthat we talked about,",
    "start": "4545450",
    "end": "4551970"
  },
  {
    "text": "version zero just\noutputs the distribution over y test, which\nis quite simple, but doesn't allow us to\nreason about the distribution",
    "start": "4551970",
    "end": "4559470"
  },
  {
    "text": "over task-specific parameters. We also saw\nblack-box approaches, which use these\nlatent variable models",
    "start": "4559470",
    "end": "4565170"
  },
  {
    "text": "and amortize\nvariational inference. And this can represent\nnon-Gaussian distributions",
    "start": "4565170",
    "end": "4570720"
  },
  {
    "text": "over y. But it can only represent\nGaussian distributions over phi.",
    "start": "4570720",
    "end": "4577733"
  },
  {
    "text": "And then, we also saw\noptimization-based approaches. We saw how do we basically\ntake this approach and stick a gradient step\ninto q, which is simple",
    "start": "4577733",
    "end": "4588780"
  },
  {
    "text": "but gives you only\nGaussian distributions. We saw ensembles,\nwhich are also simple and tend to work well and give\nyou non-Gaussian distributions.",
    "start": "4588780",
    "end": "4596490"
  },
  {
    "text": "But you have to maintain\na model instances. And then we also saw\nhybrid inference,",
    "start": "4596490",
    "end": "4601590"
  },
  {
    "text": "which gives you a\nnon-Gaussian posterior and simple at test time. But it's a lot more\ncomplex during training.",
    "start": "4601590",
    "end": "4606450"
  },
  {
    "text": "Cool. And then, the last thing\nI'd like to briefly go over is actually evaluation\nof these meta-learners and how you use them.",
    "start": "4610199",
    "end": "4617685"
  },
  {
    "text": "One thing you could do is try\nto use standard benchmarks. But the downside here--\nwell, the benefit is that they're standardized.\nthey're real images.",
    "start": "4617685",
    "end": "4623900"
  },
  {
    "text": "It's a good check that\nit didn't break anything. But the downsides are\nthat oftentimes metrics",
    "start": "4623900",
    "end": "4629360"
  },
  {
    "text": "like accuracy don't\nactually evaluate how well you're doing at\nrepresenting the distribution over parameters.",
    "start": "4629360",
    "end": "4637130"
  },
  {
    "text": "Also, some of the standard tasks\nmay not exhibit any ambiguity. And so, it may be that you're\ngood with a point estimate.",
    "start": "4637130",
    "end": "4643219"
  },
  {
    "text": "You don't actually\nneed a distribution. And uncertainty may not\nbe useful in the data set.",
    "start": "4643220",
    "end": "4650490"
  },
  {
    "text": "And so, what are some\nbetter problems and metrics? Ultimately, it's going to\ncare about the problems",
    "start": "4650490",
    "end": "4656090"
  },
  {
    "text": "that you care about. But here are a few examples. So one really simple\nexample that's",
    "start": "4656090",
    "end": "4663020"
  },
  {
    "text": "not necessarily representative\nof a practical problem but allows you to\nlook at ambiguity",
    "start": "4663020",
    "end": "4668449"
  },
  {
    "text": "is these kinds of regression\nand classification problems, where you give\nit a family of sinusoids",
    "start": "4668450",
    "end": "4674540"
  },
  {
    "text": "and linear models. You add noise to the\ndata points such that",
    "start": "4674540",
    "end": "4681170"
  },
  {
    "text": "in some of the examples,\nlike the third example, it's actually somewhat\nambiguous whether it's a sinusoid or a linear curve.",
    "start": "4681170",
    "end": "4686910"
  },
  {
    "text": "And you can see\nwhether the model can capture these different\nmodes of the distribution.",
    "start": "4686910",
    "end": "4692092"
  },
  {
    "text": "Likewise, you could give it\nambiguous classification, where you have only a single\nsupport example as represented",
    "start": "4692092",
    "end": "4697820"
  },
  {
    "text": "by the blue cross, or\nthe blue plus sign. And then, you can see\nthat it can represent",
    "start": "4697820",
    "end": "4703400"
  },
  {
    "text": "different decision boundaries\nby sampling different phis,",
    "start": "4703400",
    "end": "4708739"
  },
  {
    "text": "including decision\nboundaries that cover the true decision\nboundary, which is shown in gray.",
    "start": "4708740",
    "end": "4715880"
  },
  {
    "text": "So this is one example. Another examples you can look\nat ambiguous generation tasks,",
    "start": "4715880",
    "end": "4722150"
  },
  {
    "text": "where you get just a\nsingle view of an object and you want to be\nable to generate other views of that object.",
    "start": "4722150",
    "end": "4730040"
  },
  {
    "text": "And here's an example of a\nblack-box Bayesian learning algorithm that can\nrepresent the ambiguity.",
    "start": "4730040",
    "end": "4736310"
  },
  {
    "text": "Whereas if you just\nuse a C-VAE, it doesn't represent\nthe ambiguity well.",
    "start": "4736310",
    "end": "4742829"
  },
  {
    "text": "And you can also look\nat the reconstruction. Another example is the\nambiguous classification task",
    "start": "4742830",
    "end": "4749900"
  },
  {
    "text": "that we saw at the very\nbeginning of lecture, where you need to classify on-- it's unclear what you\nneed to classify on",
    "start": "4749900",
    "end": "4756980"
  },
  {
    "text": "in terms of the attributes. And you could measure\nthings like accuracy as well as how well it covers\nthe different modes",
    "start": "4756980",
    "end": "4764090"
  },
  {
    "text": "of that distribution,\nand also the negative log likelihood of the classifier.",
    "start": "4764090",
    "end": "4770660"
  },
  {
    "text": "And then, one last example is\nlooking at reliability diagrams and calibration error.",
    "start": "4770660",
    "end": "4776930"
  },
  {
    "text": "And what this is\nlooking at is looking at the confidence\nof the classifier versus the accuracy of the\nclassifier on those data",
    "start": "4776930",
    "end": "4782929"
  },
  {
    "text": "points. And you want this to be a\nperfect kind of diagonal line. And then, for standard\nmeta-learning algorithms,",
    "start": "4782930",
    "end": "4789770"
  },
  {
    "text": "you see that they\naren't perfect. They tend to be overconfident. They have more confidence\nthan their accuracy.",
    "start": "4789770",
    "end": "4797030"
  },
  {
    "text": "Whereas for Bayesian\nmeta-learning algorithms, they improve on this metric.",
    "start": "4797030",
    "end": "4800600"
  },
  {
    "text": "Cool. Oh, and then one\nlast thing is, also looking at active learning. So you can use the uncertainty\nto select data points that you",
    "start": "4805103",
    "end": "4813500"
  },
  {
    "text": "want labeled and pick\ndata points that it's the most uncertain about. And you can use\nalgorithms like this",
    "start": "4813500",
    "end": "4819290"
  },
  {
    "text": "to get better performance with\nfewer additional data points.",
    "start": "4819290",
    "end": "4825118"
  },
  {
    "text": "So it asks for one additional\ndata point, two additional data points, and so forth. And this allows it to reduce\nits uncertainty faster and get",
    "start": "4825118",
    "end": "4831050"
  },
  {
    "text": "a more accurate\npredictor faster. And you can likewise look at\nthis in terms of mini ImageNet",
    "start": "4831050",
    "end": "4836120"
  },
  {
    "text": "accuracy, for example. Cool.",
    "start": "4836120",
    "end": "4843040"
  },
  {
    "text": "We're out of time, so I\nwant to wrap up there. A couple of reminders. We'll be starting reinforcement\nlearning on Wednesday.",
    "start": "4843040",
    "end": "4848440"
  },
  {
    "text": "And Karol will be giving\nthe lecture on Wednesday. And if you're a little bit\nrusty on reinforcement learning, I'd encourage you to\ngo to the tutorial.",
    "start": "4848440",
    "end": "4855900"
  }
]
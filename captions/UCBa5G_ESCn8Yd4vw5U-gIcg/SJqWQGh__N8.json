[
  {
    "text": "So now we are going to move forward and we are going to move to the next topic,",
    "start": "4550",
    "end": "11670"
  },
  {
    "text": "which is called identity-aware graph neural networks, right?",
    "start": "11670",
    "end": "15630"
  },
  {
    "text": "So in the previous part of the lecture, we talked about,",
    "start": "15630",
    "end": "18735"
  },
  {
    "text": "how does the node encode its position in the network?",
    "start": "18735",
    "end": "22410"
  },
  {
    "text": "How does the node know where in the network, the node is?",
    "start": "22410",
    "end": "26610"
  },
  {
    "text": "Now in the second part,",
    "start": "26610",
    "end": "28185"
  },
  {
    "text": "we are going to develop a more expressive graph neural network that is",
    "start": "28185",
    "end": "34200"
  },
  {
    "text": "going to take care of",
    "start": "34200",
    "end": "36105"
  },
  {
    "text": "all these different symmetries that can account- that can appear in the network and uh,",
    "start": "36105",
    "end": "40880"
  },
  {
    "text": "in the underlying graph,",
    "start": "40880",
    "end": "41975"
  },
  {
    "text": "and it - it will make the graph neural network more expressive.",
    "start": "41975",
    "end": "45954"
  },
  {
    "text": "So what we have learned so far is that",
    "start": "45955",
    "end": "49380"
  },
  {
    "text": "classical GNNs would fail for position-aware tasks.",
    "start": "49380",
    "end": "53880"
  },
  {
    "text": "And we said, let's use, um,",
    "start": "53880",
    "end": "57430"
  },
  {
    "text": "let's use anchors to improve graph neural network performance on position-aware tasks.",
    "start": "57430",
    "end": "64824"
  },
  {
    "text": "Now, we are going to switch back and to- and focus more on structure-aware tasks.",
    "start": "64825",
    "end": "70445"
  },
  {
    "text": "And say, can GNNs perform perfectly on structure-aware tasks?",
    "start": "70445",
    "end": "74975"
  },
  {
    "text": "And as we have seen before,",
    "start": "74975",
    "end": "77270"
  },
  {
    "text": "the answer here is unfortunately no.",
    "start": "77270",
    "end": "79914"
  },
  {
    "text": "Uh, and the issue is that",
    "start": "79915",
    "end": "81575"
  },
  {
    "text": "GNNs exhibit kind of three levels of failure cases in, uh structure-aware tasks.",
    "start": "81575",
    "end": "87305"
  },
  {
    "text": "And I'm going to show you some,",
    "start": "87305",
    "end": "89435"
  },
  {
    "text": "you know, failure cases.",
    "start": "89435",
    "end": "91204"
  },
  {
    "text": "And of course, all these failure cases are kind of worst-case scenarios uh,",
    "start": "91205",
    "end": "95600"
  },
  {
    "text": "that are very intricate in a sense that uh,",
    "start": "95600",
    "end": "98390"
  },
  {
    "text": "due to the symmetries,",
    "start": "98390",
    "end": "99770"
  },
  {
    "text": "the GNN is going to fail.",
    "start": "99770",
    "end": "101329"
  },
  {
    "text": "So perhaps they don't necessarily appear in practice uh, too often,",
    "start": "101330",
    "end": "106115"
  },
  {
    "text": "but they may appear in some parts of the data,",
    "start": "106115",
    "end": "108799"
  },
  {
    "text": "and they are still very useful uh, to study.",
    "start": "108800",
    "end": "112495"
  },
  {
    "text": "So here is the first uh, failure case.",
    "start": "112495",
    "end": "115920"
  },
  {
    "text": "Uh, this is for the Node-level tasks.",
    "start": "115920",
    "end": "118185"
  },
  {
    "text": "Imagine you wanna do a Node-level classification,",
    "start": "118185",
    "end": "121280"
  },
  {
    "text": "you want to do Node-level prediction.",
    "start": "121280",
    "end": "123295"
  },
  {
    "text": "Here, different inputs from the same, uh,",
    "start": "123295",
    "end": "127695"
  },
  {
    "text": "basically different inputs, but at",
    "start": "127695",
    "end": "129830"
  },
  {
    "text": "the same computational graph will result in the same embedding.",
    "start": "129830",
    "end": "133600"
  },
  {
    "text": "So if I have these two nodes,",
    "start": "133600",
    "end": "135710"
  },
  {
    "text": "v_1 and v_2, uh,",
    "start": "135710",
    "end": "136985"
  },
  {
    "text": "you know, residing in these types of connected components, as we said before,",
    "start": "136985",
    "end": "141470"
  },
  {
    "text": "their computational graphs, um,",
    "start": "141470",
    "end": "143580"
  },
  {
    "text": "if you work it out are exactly the same because they have",
    "start": "143580",
    "end": "146375"
  },
  {
    "text": "two neighbors and each of their neighbors has two neighbors and so on and so forth.",
    "start": "146375",
    "end": "150655"
  },
  {
    "text": "So this means that these nodes v_1 and v_2 will be embedded into",
    "start": "150655",
    "end": "154385"
  },
  {
    "text": "exactly the same point in the embedding space",
    "start": "154385",
    "end": "157099"
  },
  {
    "text": "and we won't be able to assign them different labels.",
    "start": "157100",
    "end": "160285"
  },
  {
    "text": "Now, the same type of things can happen also, for example,",
    "start": "160285",
    "end": "163730"
  },
  {
    "text": "for link prediction, where for example,",
    "start": "163730",
    "end": "166040"
  },
  {
    "text": "you can have this type of input graph.",
    "start": "166040",
    "end": "168004"
  },
  {
    "text": "And you want to decide whether you know,",
    "start": "168005",
    "end": "170060"
  },
  {
    "text": "v_0 should link to v_1 or should it link to v_2?",
    "start": "170060",
    "end": "173694"
  },
  {
    "text": "And again, if you look at the computation graphs,",
    "start": "173695",
    "end": "176930"
  },
  {
    "text": "um, the -the computation graphs are the same.",
    "start": "176930",
    "end": "180409"
  },
  {
    "text": "So nodes v_1 and v_2 are going to have the same embedding.",
    "start": "180410",
    "end": "184760"
  },
  {
    "text": "And because they have the same embedding,",
    "start": "184760",
    "end": "186830"
  },
  {
    "text": "the neural network will give the same probability to- to edge A as well as to edge B.",
    "start": "186830",
    "end": "194145"
  },
  {
    "text": "And perhaps that is not uh, the most realistic.",
    "start": "194145",
    "end": "198180"
  },
  {
    "text": "So that's our failure case again for a different type of uh, input graph.",
    "start": "198180",
    "end": "204109"
  },
  {
    "text": "And then, you know,",
    "start": "204110",
    "end": "205450"
  },
  {
    "text": "for graph level tasks,",
    "start": "205450",
    "end": "207099"
  },
  {
    "text": "there are also uh,",
    "start": "207100",
    "end": "208660"
  },
  {
    "text": "well-known failure cases because",
    "start": "208660",
    "end": "211390"
  },
  {
    "text": "different input graphs will still",
    "start": "211390",
    "end": "214180"
  },
  {
    "text": "result in the same graph neural network based embedding.",
    "start": "214180",
    "end": "217909"
  },
  {
    "text": "Um, and why- why is that the case?",
    "start": "217910",
    "end": "221160"
  },
  {
    "text": "It's because if you, for example,",
    "start": "221160",
    "end": "222945"
  },
  {
    "text": "uh, in these types of- in these types of networks,",
    "start": "222945",
    "end": "226765"
  },
  {
    "text": "all the nodes have the same degree, um,",
    "start": "226765",
    "end": "229225"
  },
  {
    "text": "but you notice that these two graphs are different because",
    "start": "229225",
    "end": "231700"
  },
  {
    "text": "here the nodes link to exactly the immediate nodes.",
    "start": "231700",
    "end": "235090"
  },
  {
    "text": "Here the- the nodes link kind of a bit farther out.",
    "start": "235090",
    "end": "238550"
  },
  {
    "text": "But if you look at the computation graphs,",
    "start": "238550",
    "end": "240615"
  },
  {
    "text": "the two computation graphs uh, will be the same.",
    "start": "240615",
    "end": "243475"
  },
  {
    "text": "So again, uh, these two- these two entire graphs will get the same embedding.",
    "start": "243475",
    "end": "249440"
  },
  {
    "text": "So again, this is, um,",
    "start": "249440",
    "end": "251600"
  },
  {
    "text": "a very kind of highly symmetric uh, input graph.",
    "start": "251600",
    "end": "254780"
  },
  {
    "text": "But still these two graphs are different.",
    "start": "254780",
    "end": "257489"
  },
  {
    "text": "They are non-isomorphic.",
    "start": "257490",
    "end": "258884"
  },
  {
    "text": "But you know, this is kind of a corner case for",
    "start": "258885",
    "end": "261859"
  },
  {
    "text": "WL test and it is also a corner case for graph neural networks.",
    "start": "261860",
    "end": "267485"
  },
  {
    "text": "So here again, uh, graph,",
    "start": "267485",
    "end": "269900"
  },
  {
    "text": "A and graph neural network without",
    "start": "269900",
    "end": "272389"
  },
  {
    "text": "any useful node features will always classify nodes A and B,",
    "start": "272390",
    "end": "276430"
  },
  {
    "text": "uh, or graphs A and B into the same position, into the same class.",
    "start": "276430",
    "end": "281935"
  },
  {
    "text": "So now, how are we going to resolve this?",
    "start": "281935",
    "end": "285190"
  },
  {
    "text": "What is the big idea here?",
    "start": "285190",
    "end": "286955"
  },
  {
    "text": "And the big idea in this second part of the lecture,",
    "start": "286955",
    "end": "290358"
  },
  {
    "text": "is that we can assign a color to the node we want to embed.",
    "start": "290359",
    "end": "294500"
  },
  {
    "text": "And that's why we call this identity-aware,",
    "start": "294500",
    "end": "296930"
  },
  {
    "text": "because the neural network,",
    "start": "296930",
    "end": "298789"
  },
  {
    "text": "as we unroll it,",
    "start": "298790",
    "end": "299945"
  },
  {
    "text": "will know what is the starting node,",
    "start": "299945",
    "end": "302210"
  },
  {
    "text": "what is the node where we started?",
    "start": "302210",
    "end": "303965"
  },
  {
    "text": "So the idea is, if I want to embed nodes v_1- v_1,",
    "start": "303965",
    "end": "308505"
  },
  {
    "text": "I'm going to color it.",
    "start": "308505",
    "end": "309945"
  },
  {
    "text": "And if I go, um,",
    "start": "309945",
    "end": "311310"
  },
  {
    "text": "and because I'm going to give it a color,",
    "start": "311310",
    "end": "314485"
  },
  {
    "text": "um, now, the graph, the computational, uh,",
    "start": "314485",
    "end": "318180"
  },
  {
    "text": "graph will be different because I will remember whenever I unroll uh,",
    "start": "318180",
    "end": "322130"
  },
  {
    "text": "the computational graph, I will remember the color of this colored node.",
    "start": "322130",
    "end": "327935"
  },
  {
    "text": "Right? So this means that, uh,",
    "start": "327935",
    "end": "330585"
  },
  {
    "text": "now our computational graph,",
    "start": "330585",
    "end": "333435"
  },
  {
    "text": "will- will- will remember whenever it hits the node of interest v_1.",
    "start": "333435",
    "end": "339200"
  },
  {
    "text": "So it we'll have these colors um, and you know,",
    "start": "339200",
    "end": "342330"
  },
  {
    "text": "why- why is this,",
    "start": "342330",
    "end": "343830"
  },
  {
    "text": "um, uh, why is this useful?",
    "start": "343830",
    "end": "346095"
  },
  {
    "text": "This is useful because it is inductive.",
    "start": "346095",
    "end": "349150"
  },
  {
    "text": "Right? It is invariant to the node ordering, um,",
    "start": "349150",
    "end": "352030"
  },
  {
    "text": "or identities of the nodes because the only node we color is the node where we started.",
    "start": "352030",
    "end": "357620"
  },
  {
    "text": "And then we just look,",
    "start": "357620",
    "end": "359315"
  },
  {
    "text": "how often does this node,",
    "start": "359315",
    "end": "360620"
  },
  {
    "text": "where we start appear in the computation graph, right?",
    "start": "360620",
    "end": "364260"
  },
  {
    "text": "So eventually, right, like if- if",
    "start": "364260",
    "end": "368070"
  },
  {
    "text": "our graph is- is connected as- as we go deeper into more layers of a graph neural network,",
    "start": "368070",
    "end": "373985"
  },
  {
    "text": "there will be some cycle that will lead us back to the starting node,",
    "start": "373985",
    "end": "378270"
  },
  {
    "text": "and we will remember that and have that",
    "start": "378270",
    "end": "380419"
  },
  {
    "text": "node colored in the computation graph, uh, as well.",
    "start": "380420",
    "end": "384445"
  },
  {
    "text": "And the important point here is because- because the node coloring is inductive,",
    "start": "384445",
    "end": "391175"
  },
  {
    "text": "even though I- I have these two,",
    "start": "391175",
    "end": "393034"
  },
  {
    "text": "let's say, different input graphs,",
    "start": "393035",
    "end": "394640"
  },
  {
    "text": "but I have labeled, uh,",
    "start": "394640",
    "end": "396425"
  },
  {
    "text": "or numbered the nodes differently, right?",
    "start": "396425",
    "end": "398690"
  },
  {
    "text": "I have 1, 2,",
    "start": "398690",
    "end": "400070"
  },
  {
    "text": "3 versus 1, 2,",
    "start": "400070",
    "end": "401780"
  },
  {
    "text": "3, the underlying computational graphs will be the same,",
    "start": "401780",
    "end": "406085"
  },
  {
    "text": "which is good because they don't change under, uh,",
    "start": "406085",
    "end": "409550"
  },
  {
    "text": "permuting the IDs or identities, uh, of the node.",
    "start": "409550",
    "end": "413675"
  },
  {
    "text": "So this is a great feature to have because it",
    "start": "413675",
    "end": "416210"
  },
  {
    "text": "means our models are able to generalize better.",
    "start": "416210",
    "end": "419905"
  },
  {
    "text": "So let's now talk more about this, uh,",
    "start": "419905",
    "end": "423100"
  },
  {
    "text": "inductive capability of node coloring.",
    "start": "423100",
    "end": "426500"
  },
  {
    "text": "And let's look at the node level task.",
    "start": "426500",
    "end": "428605"
  },
  {
    "text": "Um, and the point is that",
    "start": "428605",
    "end": "430535"
  },
  {
    "text": "this inductive node coloring helps us with node classification tasks.",
    "start": "430535",
    "end": "435605"
  },
  {
    "text": "For example, I have here,",
    "start": "435605",
    "end": "437990"
  },
  {
    "text": "um, the case, we have already,",
    "start": "437990",
    "end": "442470"
  },
  {
    "text": "uh, looked at before.",
    "start": "442470",
    "end": "443685"
  },
  {
    "text": "I have the node on a triangle,",
    "start": "443685",
    "end": "445370"
  },
  {
    "text": "I have a node on a square,",
    "start": "445370",
    "end": "446720"
  },
  {
    "text": "um, I colored the root.",
    "start": "446720",
    "end": "448355"
  },
  {
    "text": "And now I say, let's create the computation graphs.",
    "start": "448355",
    "end": "450815"
  },
  {
    "text": "Here I create the computation graphs and you, um,",
    "start": "450815",
    "end": "453965"
  },
  {
    "text": "very quickly see that the computation graphs,",
    "start": "453965",
    "end": "457264"
  },
  {
    "text": "um, are quite- are quite different.",
    "start": "457265",
    "end": "459925"
  },
  {
    "text": "And in particular they- they become different at, uh,",
    "start": "459925",
    "end": "463259"
  },
  {
    "text": "at the bottom level,",
    "start": "463260",
    "end": "464510"
  },
  {
    "text": "where in the- in the part B here,",
    "start": "464510",
    "end": "468120"
  },
  {
    "text": "when I go to two hops- when I go two hops out,",
    "start": "468120",
    "end": "472880"
  },
  {
    "text": "I only hit these nodes while in the- in the first case,",
    "start": "472880",
    "end": "478725"
  },
  {
    "text": "um, I actually get- go and hit again the starting node.",
    "start": "478725",
    "end": "482710"
  },
  {
    "text": "So now these two computation graphs are different because we also consider colors.",
    "start": "482710",
    "end": "487680"
  },
  {
    "text": "So we will be able to successfully differentiate between nodes v_1 and nodes v_2.",
    "start": "487680",
    "end": "493470"
  },
  {
    "text": "So, uh, this is a very elegant solution to the- to- to this, uh,",
    "start": "493470",
    "end": "498595"
  },
  {
    "text": "to this, uh, uh problem that where",
    "start": "498595",
    "end": "501115"
  },
  {
    "text": "a classical graph neural network, uh, would fail.",
    "start": "501115",
    "end": "504220"
  },
  {
    "text": "Um, and similarly, we can do the same thing,",
    "start": "504220",
    "end": "507535"
  },
  {
    "text": "uh, for- um, for graph classification, right?",
    "start": "507535",
    "end": "510520"
  },
  {
    "text": "If I take my two input graphs, uh,",
    "start": "510520",
    "end": "512560"
  },
  {
    "text": "the way I created the- aga- the embedding of the graph is to create an embedding,",
    "start": "512560",
    "end": "517510"
  },
  {
    "text": "uh, of nodes and then aggregate those.",
    "start": "517510",
    "end": "519895"
  },
  {
    "text": "So if I look at node-specific, um, uh,",
    "start": "519895",
    "end": "522955"
  },
  {
    "text": "computation graphs, uh, structurally,",
    "start": "522955",
    "end": "525655"
  },
  {
    "text": "they might be the same,",
    "start": "525655",
    "end": "526750"
  },
  {
    "text": "but- but- but because I have labeled the starting node and",
    "start": "526750",
    "end": "531160"
  },
  {
    "text": "now I- I know whenever my computation graph returns back to the starting node,",
    "start": "531160",
    "end": "536035"
  },
  {
    "text": "you'll notice that now the coloring pattern between these two graphs,",
    "start": "536035",
    "end": "539620"
  },
  {
    "text": "uh, is different- these two nodes is different,",
    "start": "539620",
    "end": "542455"
  },
  {
    "text": "which means their embeddings will be",
    "start": "542455",
    "end": "544600"
  },
  {
    "text": "different which means that when we aggregate the embeddings,",
    "start": "544600",
    "end": "547480"
  },
  {
    "text": "the embeddings for the graphs will be different,",
    "start": "547480",
    "end": "549745"
  },
  {
    "text": "which means we'll be able to take these two input graphs,",
    "start": "549745",
    "end": "552700"
  },
  {
    "text": "A and B, um,",
    "start": "552700",
    "end": "553900"
  },
  {
    "text": "and embed them into,",
    "start": "553900",
    "end": "556795"
  },
  {
    "text": "um, different points and assign them different classes.",
    "start": "556795",
    "end": "559885"
  },
  {
    "text": "So this is exactly what we want.",
    "start": "559885",
    "end": "561965"
  },
  {
    "text": "And then, you know,",
    "start": "561965",
    "end": "563550"
  },
  {
    "text": "for the edge level tasks,",
    "start": "563550",
    "end": "565110"
  },
  {
    "text": "again, ah, if, you know,",
    "start": "565110",
    "end": "567029"
  },
  {
    "text": "I start with V_0 and I say,",
    "start": "567030",
    "end": "569235"
  },
  {
    "text": "you know I want to assign a different, uh, uh,",
    "start": "569235",
    "end": "572355"
  },
  {
    "text": "probability to, um, uh, to nodes,",
    "start": "572355",
    "end": "576435"
  },
  {
    "text": "V_1- to the edges A and B,",
    "start": "576435",
    "end": "578565"
  },
  {
    "text": "I can say what will be the embedding of V_1, uh, here?",
    "start": "578565",
    "end": "582325"
  },
  {
    "text": "What will be embedding of V_2?",
    "start": "582325",
    "end": "584185"
  },
  {
    "text": "And I see that their corresponding computation graphs, uh,",
    "start": "584185",
    "end": "587350"
  },
  {
    "text": "will be different because, uh,",
    "start": "587350",
    "end": "589209"
  },
  {
    "text": "V_1 is going to hit V_0 sooner than, uh, V_2.",
    "start": "589210",
    "end": "593545"
  },
  {
    "text": "So, um, here, the point is that when I'm embedding nodes for link prediction,",
    "start": "593545",
    "end": "599005"
  },
  {
    "text": "I'm given a pair of nodes and here,",
    "start": "599005",
    "end": "601165"
  },
  {
    "text": "I'm going to color,",
    "start": "601165",
    "end": "602889"
  },
  {
    "text": "um, both- both nodes,",
    "start": "602890",
    "end": "604990"
  },
  {
    "text": "the- the- the left node and the right node and this way,",
    "start": "604990",
    "end": "608245"
  },
  {
    "text": "I'll be able to distinguish, um,",
    "start": "608245",
    "end": "609820"
  },
  {
    "text": "uh, the two computational, ah, graphs.",
    "start": "609820",
    "end": "613495"
  },
  {
    "text": "So this means it will allow us to, uh,",
    "start": "613495",
    "end": "617080"
  },
  {
    "text": "assign a different probability to the node- to the edge A versus,",
    "start": "617080",
    "end": "621790"
  },
  {
    "text": "uh, the edge B, which is, uh, what we want.",
    "start": "621790",
    "end": "625399"
  },
  {
    "text": "So what you- what I have demonstrated so far is that",
    "start": "625400",
    "end": "629700"
  },
  {
    "text": "this node coloring where we color the identity of the- uh,",
    "start": "629700",
    "end": "635135"
  },
  {
    "text": "of the starting node or in link prediction of the- of this- of these both, uh,",
    "start": "635135",
    "end": "640660"
  },
  {
    "text": "nodes in involving the link prediction task",
    "start": "640660",
    "end": "643285"
  },
  {
    "text": "allows us to differentiate and distinguish, uh,",
    "start": "643285",
    "end": "646225"
  },
  {
    "text": "these types of symmetric, uh,",
    "start": "646225",
    "end": "648550"
  },
  {
    "text": "corner cases that make classical neural network- graph neural networks, uh, fail.",
    "start": "648550",
    "end": "653995"
  },
  {
    "text": "So now, the question is,",
    "start": "653995",
    "end": "655525"
  },
  {
    "text": "how do you build a- a GNN that uses this node coloring and that you- it will allow us,",
    "start": "655525",
    "end": "661375"
  },
  {
    "text": "uh, to distinguish these different colored, uh, computation graphs.",
    "start": "661375",
    "end": "666865"
  },
  {
    "text": "The idea is the following and the model is called identity aware, uh,",
    "start": "666865",
    "end": "671995"
  },
  {
    "text": "graph neural network and what we wanna do",
    "start": "671995",
    "end": "674650"
  },
  {
    "text": "is you've wanna utilize inductive node coloring in",
    "start": "674650",
    "end": "677380"
  },
  {
    "text": "the embedding computation and the key idea",
    "start": "677380",
    "end": "680440"
  },
  {
    "text": "is that you want to use heterogeneous message passing, right?",
    "start": "680440",
    "end": "684355"
  },
  {
    "text": "Normally in a GNN,",
    "start": "684355",
    "end": "685930"
  },
  {
    "text": "we apply the same message aggregation computation",
    "start": "685930",
    "end": "688885"
  },
  {
    "text": "to all the children in the computation graph, right?",
    "start": "688885",
    "end": "691780"
  },
  {
    "text": "So whenever we- we are, uh, aggregating, uh,",
    "start": "691780",
    "end": "695125"
  },
  {
    "text": "masters and transporting messages,",
    "start": "695125",
    "end": "697345"
  },
  {
    "text": "we apply the same aggregation in the same neural network operator, right?",
    "start": "697345",
    "end": "701500"
  },
  {
    "text": "So, um, this is what we classically do.",
    "start": "701500",
    "end": "703960"
  },
  {
    "text": "In our graph neural- identity aware graph neural network,",
    "start": "703960",
    "end": "707545"
  },
  {
    "text": "we are going to do heterogeneous message passing.",
    "start": "707545",
    "end": "710380"
  },
  {
    "text": "So we are going to use different types of aggregation, um,",
    "start": "710380",
    "end": "714820"
  },
  {
    "text": "different types of message passing applied to different nodes based on their color.",
    "start": "714820",
    "end": "719830"
  },
  {
    "text": "So it means that in an IDGNN,",
    "start": "719830",
    "end": "722260"
  },
  {
    "text": "we are going to use, um,",
    "start": "722260",
    "end": "724150"
  },
  {
    "text": "different message and aggregation, uh,",
    "start": "724150",
    "end": "726310"
  },
  {
    "text": "functions, uh, for nodes with different, uh, colors.",
    "start": "726310",
    "end": "729400"
  },
  {
    "text": "So it means that for example,",
    "start": "729400",
    "end": "731170"
  },
  {
    "text": "whenever we are aggregating into a color node,",
    "start": "731170",
    "end": "734290"
  },
  {
    "text": "we are going to use one type of, uh,",
    "start": "734290",
    "end": "736600"
  },
  {
    "text": "transformations and message passing operator",
    "start": "736600",
    "end": "739360"
  },
  {
    "text": "and whenever we are aggregating into a non-colored node,",
    "start": "739360",
    "end": "742360"
  },
  {
    "text": "we are going to use a second type of,",
    "start": "742360",
    "end": "744894"
  },
  {
    "text": "uh, aggregation and transformation.",
    "start": "744895",
    "end": "747205"
  },
  {
    "text": "So this means that in a given layer,",
    "start": "747205",
    "end": "749470"
  },
  {
    "text": "different message and aggregation, uh,",
    "start": "749470",
    "end": "751810"
  },
  {
    "text": "functions would be used to nodes based on the color,",
    "start": "751810",
    "end": "755050"
  },
  {
    "text": "uh, of the node and this is the key, right?",
    "start": "755050",
    "end": "757720"
  },
  {
    "text": "Because if the node- nodes is color and it",
    "start": "757720",
    "end": "760449"
  },
  {
    "text": "can use a different aggregator, this means that,",
    "start": "760450",
    "end": "763360"
  },
  {
    "text": "uh- that the- the- the message will get transformed differently,",
    "start": "763360",
    "end": "768310"
  },
  {
    "text": "which means the final results will be different depending on whether",
    "start": "768310",
    "end": "772450"
  },
  {
    "text": "the nodes with colors were involved in aggregation versus nodes without colors,",
    "start": "772450",
    "end": "777340"
  },
  {
    "text": "uh, uh, being involved in aggregation.",
    "start": "777340",
    "end": "780880"
  },
  {
    "text": "So um, you know why does this heterogeneous message-passing work?",
    "start": "780880",
    "end": "785770"
  },
  {
    "text": "Right? Suppose that two nodes,",
    "start": "785770",
    "end": "787720"
  },
  {
    "text": "V_1 and V_2 have the same computational graph structure,",
    "start": "787720",
    "end": "791214"
  },
  {
    "text": "but they have different node coloring, right?",
    "start": "791215",
    "end": "793975"
  },
  {
    "text": "Um, and since we apply different neural network embedding computation,",
    "start": "793975",
    "end": "798069"
  },
  {
    "text": "right- different, um, uh,",
    "start": "798070",
    "end": "800185"
  },
  {
    "text": "message passing and different aggregation, right,",
    "start": "800185",
    "end": "803650"
  },
  {
    "text": "we have different parameters for nodes with one,",
    "start": "803650",
    "end": "806695"
  },
  {
    "text": "uh, color versus the nodes with the other color,",
    "start": "806695",
    "end": "809245"
  },
  {
    "text": "this means that the final result, uh,",
    "start": "809245",
    "end": "811975"
  },
  {
    "text": "will be different and this means that the final output-",
    "start": "811975",
    "end": "815680"
  },
  {
    "text": "the final embedding between V_1 and V_2 is going to be, uh, different.",
    "start": "815680",
    "end": "820690"
  },
  {
    "text": "So, you know, what is the key, uh,",
    "start": "820690",
    "end": "823495"
  },
  {
    "text": "difference between GNN and identity aware GNN?",
    "start": "823495",
    "end": "827815"
  },
  {
    "text": "If we look at this,",
    "start": "827815",
    "end": "829240"
  },
  {
    "text": "uh, you know- uh, use, uh,",
    "start": "829240",
    "end": "831250"
  },
  {
    "text": "this case- uh, this example we have looked so far,",
    "start": "831250",
    "end": "834190"
  },
  {
    "text": "if I have nodes V_1 and V_2 I wanna distinguish them,",
    "start": "834190",
    "end": "836860"
  },
  {
    "text": "in the classical GNN computation,",
    "start": "836860",
    "end": "839440"
  },
  {
    "text": "the two computation graphs are the same,",
    "start": "839440",
    "end": "841975"
  },
  {
    "text": "uh, all the nodes are the same,",
    "start": "841975",
    "end": "843940"
  },
  {
    "text": "there is no differentiating node features,",
    "start": "843940",
    "end": "846085"
  },
  {
    "text": "so the aggregations across these two, uh,",
    "start": "846085",
    "end": "849475"
  },
  {
    "text": "trees will be the same,",
    "start": "849475",
    "end": "851110"
  },
  {
    "text": "so we won't be able to distinguish A and B.",
    "start": "851110",
    "end": "853404"
  },
  {
    "text": "In the case when we actually color",
    "start": "853405",
    "end": "855820"
  },
  {
    "text": "the starting node and now the two computation graphs are different,",
    "start": "855820",
    "end": "860380"
  },
  {
    "text": "so all we have to account for now that- is",
    "start": "860380",
    "end": "863200"
  },
  {
    "text": "that when we aggregate the information from the- um, uh,",
    "start": "863200",
    "end": "866740"
  },
  {
    "text": "from the leaves to the root of",
    "start": "866740",
    "end": "869290"
  },
  {
    "text": "the graph neural network that this information about the color is preserved",
    "start": "869290",
    "end": "874404"
  },
  {
    "text": "or somehow accounted for so that the final message will have",
    "start": "874405",
    "end": "878230"
  },
  {
    "text": "a different value depending on one, uh, versus the other.",
    "start": "878230",
    "end": "882070"
  },
  {
    "text": "And this is exactly,",
    "start": "882070",
    "end": "883419"
  },
  {
    "text": "um, the case what is happening,",
    "start": "883419",
    "end": "886150"
  },
  {
    "text": "and this is why IDGNN allows us,",
    "start": "886150",
    "end": "889090"
  },
  {
    "text": "uh, to make this distinction.",
    "start": "889090",
    "end": "891565"
  },
  {
    "text": "Um, another thing to think about it,",
    "start": "891565",
    "end": "893995"
  },
  {
    "text": "what is G- IDGNN really doing?",
    "start": "893995",
    "end": "896740"
  },
  {
    "text": "IDGNN is really counting cycles of different lengths,",
    "start": "896740",
    "end": "901839"
  },
  {
    "text": "uh, uh starting at a given,",
    "start": "901840",
    "end": "904000"
  },
  {
    "text": "uh, given the root node, right?",
    "start": "904000",
    "end": "905440"
  },
  {
    "text": "So if I start here,",
    "start": "905440",
    "end": "906655"
  },
  {
    "text": "IDGNN will now able to count or realize that there is a cycle of length 3, right?",
    "start": "906655",
    "end": "912820"
  },
  {
    "text": "So here- this is now basically a cycle.",
    "start": "912820",
    "end": "915070"
  },
  {
    "text": "You get off- you go from yourself to the- uh,",
    "start": "915070",
    "end": "917860"
  },
  {
    "text": "to the neigh- to the neighbor, uh,",
    "start": "917860",
    "end": "919990"
  },
  {
    "text": "and then to another neighbor,",
    "start": "919990",
    "end": "922015"
  },
  {
    "text": "and you'll come back to the node, right?",
    "start": "922015",
    "end": "923470"
  },
  {
    "text": "So this is a cycle of three hops.",
    "start": "923470",
    "end": "925360"
  },
  {
    "text": "While- while in this case you- we- we'll",
    "start": "925360",
    "end": "928300"
  },
  {
    "text": "reali- graph neural network is going to realize that this is a cycle of length 4,",
    "start": "928300",
    "end": "932500"
  },
  {
    "text": "because you have to go to the node,",
    "start": "932500",
    "end": "934315"
  },
  {
    "text": "to the neighbor, um,",
    "start": "934315",
    "end": "936070"
  },
  {
    "text": "to the first neighbor, to the second neighbor,",
    "start": "936070",
    "end": "938140"
  },
  {
    "text": "to the third neighbor, and from here,",
    "start": "938140",
    "end": "940150"
  },
  {
    "text": "you only arrive, uh,",
    "start": "940150",
    "end": "941920"
  },
  {
    "text": "to the starting node itself, right?",
    "start": "941920",
    "end": "943930"
  },
  {
    "text": "So here we'll real- the- the computational graph will be able to capture",
    "start": "943930",
    "end": "948160"
  },
  {
    "text": "that- or be able to compute that- that node is part of a cycle of length,",
    "start": "948160",
    "end": "953425"
  },
  {
    "text": "uh, 4, but no cycles of length 3.",
    "start": "953425",
    "end": "956305"
  },
  {
    "text": "While here, these will be able to capture that",
    "start": "956305",
    "end": "959080"
  },
  {
    "text": "the node is a part of cycle of length o- uh,",
    "start": "959080",
    "end": "962620"
  },
  {
    "text": "3 but not, uh, let's say 4.",
    "start": "962620",
    "end": "965529"
  },
  {
    "text": "So this is what IG- IDGNN is able to do.",
    "start": "965530",
    "end": "968545"
  },
  {
    "text": "It's able to count cycles and it's able to learn and count- count them through the,",
    "start": "968545",
    "end": "974019"
  },
  {
    "text": "uh, uh, message passing of the graph neural network.",
    "start": "974020",
    "end": "978160"
  },
  {
    "text": "So, um, how do you now,",
    "start": "978160",
    "end": "981399"
  },
  {
    "text": "uh, uh, how do you do this now?",
    "start": "981400",
    "end": "983830"
  },
  {
    "text": "So as I said, one is to use,",
    "start": "983830",
    "end": "985705"
  },
  {
    "text": "uh, heterogeneous message passing.",
    "start": "985705",
    "end": "987820"
  },
  {
    "text": "Um, and, uh, and the second way how you can do this is that,",
    "start": "987820",
    "end": "991885"
  },
  {
    "text": "um, we can- based on the intuition we have, uh, just proposed,",
    "start": "991885",
    "end": "995695"
  },
  {
    "text": "you can also use a simplified version of the IDGNN,",
    "start": "995695",
    "end": "999055"
  },
  {
    "text": "where basically the idea is to include identity information",
    "start": "999055",
    "end": "1002145"
  },
  {
    "text": "as an augmented node feature, um, and, uh,",
    "start": "1002145",
    "end": "1005640"
  },
  {
    "text": "sidestep the- the heterogenous node, uh, uh,",
    "start": "1005640",
    "end": "1009915"
  },
  {
    "text": "message passing and the idea here is basically you can augment the node feature,",
    "start": "1009915",
    "end": "1014940"
  },
  {
    "text": "by using the cycle counts in each layer",
    "start": "1014940",
    "end": "1017520"
  },
  {
    "text": "as an- as an augmented node feature and then apply,",
    "start": "1017520",
    "end": "1020630"
  },
  {
    "text": "a simple GNN, right?",
    "start": "1020630",
    "end": "1022770"
  },
  {
    "text": "So basically, you want to use cycle counts in each layer as",
    "start": "1022770",
    "end": "1026500"
  },
  {
    "text": "an augmented feature for the root node and then simply apply het- uh,",
    "start": "1026500",
    "end": "1031240"
  },
  {
    "text": "homogeneous message-passing, basically drop the colors, right?",
    "start": "1031240",
    "end": "1035439"
  },
  {
    "text": "So the idea would be that every node gets now,",
    "start": "1035440",
    "end": "1038259"
  },
  {
    "text": "um, ah, uh, gets a description that simply says,",
    "start": "1038260",
    "end": "1042625"
  },
  {
    "text": "how many cycles of length 0 are you part of,",
    "start": "1042625",
    "end": "1045525"
  },
  {
    "text": "how many cycles of length 2- like- cycles of length 3s,",
    "start": "1045525",
    "end": "1048920"
  },
  {
    "text": "and, uh, and so on.",
    "start": "1048920",
    "end": "1050330"
  },
  {
    "text": "And this way, you will be able to, um, uh, uh,",
    "start": "1050330",
    "end": "1053740"
  },
  {
    "text": "to distinguish the node- uh,",
    "start": "1053740",
    "end": "1056410"
  },
  {
    "text": "the two computational graphs,",
    "start": "1056410",
    "end": "1058225"
  },
  {
    "text": "and be able to distinguish the two nodes, uh,",
    "start": "1058225",
    "end": "1060445"
  },
  {
    "text": "into two different, uh, classes.",
    "start": "1060445",
    "end": "1063755"
  },
  {
    "text": "So let's summarize the identity aware graph neural networks.",
    "start": "1063755",
    "end": "1068440"
  },
  {
    "text": "Uh, the- this is a general and powerful extension to graph a neural network framework.",
    "start": "1068440",
    "end": "1073985"
  },
  {
    "text": "Um, it makes graph neural networks more expressive.",
    "start": "1073985",
    "end": "1077100"
  },
  {
    "text": "Uh, the IDGNN, this idea of inductive node coloring and",
    "start": "1077100",
    "end": "1081280"
  },
  {
    "text": "heterogeneous message passing can be applied to any graph neural network architecture,",
    "start": "1081280",
    "end": "1086150"
  },
  {
    "text": "meaning, um, gra- graph convolutional neural network,",
    "start": "1086150",
    "end": "1089815"
  },
  {
    "text": "GraphSAGE, um, GIN,,",
    "start": "1089815",
    "end": "1091870"
  },
  {
    "text": "so graph isomorphism network and- and any other, uh, architecture.",
    "start": "1091870",
    "end": "1095590"
  },
  {
    "text": "Um, and IDGNN will provide a consistent performance gain in many node-level, um, er,",
    "start": "1095590",
    "end": "1102835"
  },
  {
    "text": "as well as edge and graph-level tasks,",
    "start": "1102835",
    "end": "1104860"
  },
  {
    "text": "because it allows us to break the symmetries and allows",
    "start": "1104860",
    "end": "1108100"
  },
  {
    "text": "us to the- basically identify how the node,",
    "start": "1108100",
    "end": "1111330"
  },
  {
    "text": "uh, belongs to different, uh, cycles.",
    "start": "1111330",
    "end": "1114070"
  },
  {
    "text": "This means that IDGNNs are more expressive than their, uh,",
    "start": "1114070",
    "end": "1117919"
  },
  {
    "text": "graph- kind of classical graph neural network, uh, counterparts.",
    "start": "1117920",
    "end": "1122455"
  },
  {
    "text": "Um, and this means that IDGNN is kind of this- the, uh,",
    "start": "1122455",
    "end": "1126809"
  },
  {
    "text": "uh, the simplest model that is more expressive than 1-WL test.",
    "start": "1126810",
    "end": "1132270"
  },
  {
    "text": "Um, and it can be easily implemented because it's basically just you color the root node,",
    "start": "1132270",
    "end": "1137950"
  },
  {
    "text": "and that's all the information,",
    "start": "1137950",
    "end": "1139630"
  },
  {
    "text": "uh, you need to, uh, worry about.",
    "start": "1139630",
    "end": "1141700"
  },
  {
    "text": "So, uh, this is quite cool because it allows us now to",
    "start": "1141700",
    "end": "1144820"
  },
  {
    "text": "distinguish this node on a triangle versus node on a square.",
    "start": "1144820",
    "end": "1148580"
  },
  {
    "text": "Um, this was the first and the key idea is here to have this inductive node coloring,",
    "start": "1148580",
    "end": "1153039"
  },
  {
    "text": "and then we also talked about position aware graph neural networks,",
    "start": "1153040",
    "end": "1156940"
  },
  {
    "text": "where the idea is that you want to distinguish the position of the node in the graph,",
    "start": "1156940",
    "end": "1160330"
  },
  {
    "text": "and the key idea there was to use the notion of",
    "start": "1160330",
    "end": "1163315"
  },
  {
    "text": "anchors and characterize the location- the position of the node,",
    "start": "1163315",
    "end": "1167514"
  },
  {
    "text": "by the location, uh,",
    "start": "1167515",
    "end": "1169440"
  },
  {
    "text": "by the distance of the node to the anchors.",
    "start": "1169440",
    "end": "1171774"
  },
  {
    "text": "And we talked about we want to have anchors- anchors of different sizes.",
    "start": "1171775",
    "end": "1176244"
  },
  {
    "text": "And we wanna have a lot of anchors of size 1,",
    "start": "1176244",
    "end": "1179050"
  },
  {
    "text": "we wanna have a lot- uh,",
    "start": "1179050",
    "end": "1180480"
  },
  {
    "text": "fewer anchors of size 2,",
    "start": "1180480",
    "end": "1182085"
  },
  {
    "text": "even fewer of size 4 and so on and so forth.",
    "start": "1182085",
    "end": "1184929"
  },
  {
    "text": "Um, and the- the distance of a node to the anchor",
    "start": "1184930",
    "end": "1188695"
  },
  {
    "text": "is the distance of the node to the- any node that is part of this,",
    "start": "1188695",
    "end": "1192610"
  },
  {
    "text": "uh, anchor or, uh, anchor set.",
    "start": "1192610",
    "end": "1194650"
  },
  {
    "text": "[NOISE]",
    "start": "1194650",
    "end": "1202000"
  }
]
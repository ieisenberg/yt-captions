[
  {
    "start": "0",
    "end": "5500"
  },
  {
    "text": "Let's get started. The plan for today is to finish\nup the variational autoencoder",
    "start": "5500",
    "end": "11530"
  },
  {
    "text": "model, and so we'll talk\nabout the ELBO again.",
    "start": "11530",
    "end": "17560"
  },
  {
    "text": "We'll see how we\ncan actually solve the corresponding\noptimization problem,",
    "start": "17560",
    "end": "22750"
  },
  {
    "text": "and then we'll actually explain\nwhy this model is called the variational autoencoder. And so we'll show\nsome connections",
    "start": "22750",
    "end": "29710"
  },
  {
    "text": "with the autoencoders we've\nseen in the previous lectures. And we'll see how\nit generalizes them.",
    "start": "29710",
    "end": "36410"
  },
  {
    "text": "And you can think of it as a\nway of turning an autoencoder into a generative model.",
    "start": "36410",
    "end": "42230"
  },
  {
    "text": "So, as a recap,\nrecall that we're talking about a\ngenerative model called",
    "start": "42230",
    "end": "49750"
  },
  {
    "text": "the variational autoencoder,\noften denoted VAE for short. In the simplest form,\nyou can think of it",
    "start": "49750",
    "end": "56320"
  },
  {
    "text": "as something like this. It's a generative\nmodel where you first sample a simple latent variable\nz, for example, by just drawing",
    "start": "56320",
    "end": "66080"
  },
  {
    "text": "from a multivariate\nGaussian distribution with mean 0 and covariance\nthe identity matrix,",
    "start": "66080",
    "end": "72650"
  },
  {
    "text": "the simplest distribution\nyou can think of. And then what you do\nis you pass this sample",
    "start": "72650",
    "end": "81890"
  },
  {
    "text": "that you obtain, this\nrandom variable z, through two neural networks,\nmu theta and sigma theta.",
    "start": "81890",
    "end": "90560"
  },
  {
    "text": "And these two neural\nnetworks will give you the parameters of another\nGaussian distribution. So they will give you a mean\nvector and a covariance matrix,",
    "start": "90560",
    "end": "98670"
  },
  {
    "text": "which will depend on z. And then you actually\ngenerate a data point by sampling from this\nconditional distribution",
    "start": "98670",
    "end": "106160"
  },
  {
    "text": "p of x given z. And as we've seen, the nice\nthing about these models",
    "start": "106160",
    "end": "114380"
  },
  {
    "text": "is that even though the\nbuilding blocks are very simple, like you have a simple\nGaussian prior p of z",
    "start": "114380",
    "end": "121160"
  },
  {
    "text": "and you have a simple\nconditional distribution p of x given z, which is,\nagain, just a Gaussian,",
    "start": "121160",
    "end": "126280"
  },
  {
    "text": "the marginal distribution\nover x that you get is potentially very\nflexible, very general",
    "start": "126280",
    "end": "133690"
  },
  {
    "text": "because you can think of\nit as a mixture of a very large and infinite number of\nGaussian distributions, right?",
    "start": "133690",
    "end": "141250"
  },
  {
    "text": "For every z, there is a\ncorresponding Gaussian, you have an infinite\nnumber of Z's, you have an infinite number of\nGaussians that you're mixing.",
    "start": "141250",
    "end": "148060"
  },
  {
    "text": "So if you want to figure\nout what was the probability of generating a data point x,\nyou would have to integrate over",
    "start": "148060",
    "end": "156220"
  },
  {
    "text": "all possible values of the\nlatent variables and you would have to see what was the\nprobability that latent variable",
    "start": "156220",
    "end": "162190"
  },
  {
    "text": "would give me this data point\nand that 0000000 you a lot of flexibility.",
    "start": "162190",
    "end": "167440"
  },
  {
    "text": "And as we've seen, the\nnice thing about this",
    "start": "167440",
    "end": "172540"
  },
  {
    "text": "is that it gives you a very\nflexible marginal distribution over x.",
    "start": "172540",
    "end": "177700"
  },
  {
    "text": "And it also gives\nyou a way to do unsupervised\nlearning, in the sense",
    "start": "177700",
    "end": "182770"
  },
  {
    "text": "that you can try\nto infer z given x. And hopefully, you might\ndiscover some structure,",
    "start": "182770",
    "end": "188860"
  },
  {
    "text": "some latent factors\nof variation that can describe a lot\nof the variability",
    "start": "188860",
    "end": "194560"
  },
  {
    "text": "that you see in the data. So it can be used for\nunsupervised learning. You can think of it as an\nextension of k-means, where",
    "start": "194560",
    "end": "203049"
  },
  {
    "text": "the latent variables\nare more flexible, and they can discover\nmore complicated factors",
    "start": "203050",
    "end": "208060"
  },
  {
    "text": "of variation. What we've seen is that\nthere is no free lunch,",
    "start": "208060",
    "end": "213730"
  },
  {
    "text": "in the sense that\nthe price you pay is that these models are\nmore difficult to train.",
    "start": "213730",
    "end": "219700"
  },
  {
    "text": "And at the end of the day,\nit boils down to the fact that evaluating likelihoods\nis expensive, is difficult.",
    "start": "219700",
    "end": "225800"
  },
  {
    "text": "So evaluating p\nof x is expensive because you have to\nessentially check",
    "start": "225800",
    "end": "232120"
  },
  {
    "text": "all the possible values of\nz that could have generated that data point x. And what this means is that\nyou cannot evaluate likelihoods",
    "start": "232120",
    "end": "239080"
  },
  {
    "text": "of data points, or you can do\nit, but it's very expensive. And therefore, training\nis also very hard",
    "start": "239080",
    "end": "245349"
  },
  {
    "text": "because there is\nnot an obvious way to just optimize the\nparameters to maximize",
    "start": "245350",
    "end": "250430"
  },
  {
    "text": "the probability of a\nparticular data set that you have access to because\ncomputing likelihoods is hard.",
    "start": "250430",
    "end": "257180"
  },
  {
    "text": "And this is different\nfrom autoregressive models where, on the other hand, it was\ntrivial to evaluate likelihoods",
    "start": "257180",
    "end": "263210"
  },
  {
    "text": "because you just\nmultiply together a bunch of conditionals. Question? Quick question.",
    "start": "263210",
    "end": "268340"
  },
  {
    "text": "Can we parameterize\np of z itself, or is that-- will we\nhave to have [INAUDIBLE]?? Good question.",
    "start": "268340",
    "end": "273470"
  },
  {
    "text": "Yeah, so the question\nis whether p of z could be learned\nessentially, or does",
    "start": "273470",
    "end": "279259"
  },
  {
    "text": "it have to be something fixed. It can be learned. This is like the simplest setup\nthat is already powerful enough",
    "start": "279260",
    "end": "285590"
  },
  {
    "text": "to do interesting things. z is fixed but, as we'll see\nwhen you go through the math,",
    "start": "285590",
    "end": "293030"
  },
  {
    "text": "nothing really\nstops you from using a more complex prior\ndistribution over z.",
    "start": "293030",
    "end": "299325"
  },
  {
    "text": "And it could be something\nthat you can learn. For example, you could use-- no. The simplest thing\nwould be the parameters",
    "start": "299325",
    "end": "305560"
  },
  {
    "text": "of that Gaussian are learned. So instead of using a mean 0 and\na fixed covariance, the identity",
    "start": "305560",
    "end": "311199"
  },
  {
    "text": "matrix, you could\nlearn those parameters, or you could use an\nautoregressive model for z.",
    "start": "311200",
    "end": "317050"
  },
  {
    "text": "Or what you could do is you\ncould stack another autoencoder, another VAE, and then you can\nhave a hierarchical VAE, where",
    "start": "317050",
    "end": "325389"
  },
  {
    "text": "the z is generated from another\nvariational autoencoder. And that's a hierarchical VAE,\nand it's essentially what's",
    "start": "325390",
    "end": "331930"
  },
  {
    "text": "going to be a diffusion model. If you stack these\nmany, many times, you get a more powerful model.",
    "start": "331930",
    "end": "337000"
  },
  {
    "text": "But this is the simplest\ninteresting model that highlights the\nchallenges, and it's already",
    "start": "337000",
    "end": "342610"
  },
  {
    "text": "useful in practice. Will it make more sense\nstacking multiple [INAUDIBLE] on top of each other\nor just increasing",
    "start": "342610",
    "end": "348490"
  },
  {
    "text": "the number of layers of\nthese two neural networks that you define? Yeah so, good question. So the question is what's the\ndifference between increasing",
    "start": "348490",
    "end": "358120"
  },
  {
    "text": "the dimensionality\nof z or adding multiple layers\nversus increasing",
    "start": "358120",
    "end": "363700"
  },
  {
    "text": "the depth of the neural\nnetworks that give you the mapping from z to x. And the behavior of those\ntwo things-- both of them",
    "start": "363700",
    "end": "370780"
  },
  {
    "text": "would give you more\nflexibility, but the behavior is very different.",
    "start": "370780",
    "end": "376540"
  },
  {
    "text": "And then you can make this\nnetwork as deep as you want, but p of x given z\nis still a Gaussian,",
    "start": "376540",
    "end": "382759"
  },
  {
    "text": "and so that restricts\nwhat you can do. As will become clear later when\nwe talk about the training--",
    "start": "382760",
    "end": "391930"
  },
  {
    "text": "that increases the\nflexibility to some extent, but it's not the same as adding\nmore mixture components, which",
    "start": "391930",
    "end": "400600"
  },
  {
    "text": "is what you would get if\nyou were to either stacking another VAE or maybe increasing\nthe dimensionality of z.",
    "start": "400600",
    "end": "410650"
  },
  {
    "text": "So both of them go in\nthe same direction, but they do it in\na different way. ",
    "start": "410650",
    "end": "417730"
  },
  {
    "text": "Cool. So that's the no\nfree lunch part. And basically what\nwe've seen, we",
    "start": "417730",
    "end": "423940"
  },
  {
    "text": "started looking into ways\nto train these models. And as we'll see,\nthe way to train",
    "start": "423940",
    "end": "432449"
  },
  {
    "text": "these latent variable models\nrelies on this technique called variational inference,\nwhere we are essentially",
    "start": "432450",
    "end": "438900"
  },
  {
    "text": "going to have an\nauxiliary model that we're going to use to try to\ninfer the latent variables.",
    "start": "438900",
    "end": "446430"
  },
  {
    "text": "And in this course,\nthis auxiliary model is also going to be\na neural network.",
    "start": "446430",
    "end": "451680"
  },
  {
    "text": "It's all going to be deep. And basically, we are\ngoing to jointly train",
    "start": "451680",
    "end": "457979"
  },
  {
    "text": "the generative model and an\nauxiliary inference model that you're going to use to try\nto reduce the problem to the one",
    "start": "457980",
    "end": "465780"
  },
  {
    "text": "that we've seen before, where\nboth the x and the z part is observed.",
    "start": "465780",
    "end": "471629"
  },
  {
    "text": "And that's the high level idea,\nand it builds on that result",
    "start": "471630",
    "end": "477120"
  },
  {
    "text": "that we've seen in the\nlast lecture of building an evidence lower bound. Right? So we've seen that we can obtain\na lower bound through Jensen's",
    "start": "477120",
    "end": "488680"
  },
  {
    "text": "inequality, basically, on this\nquantity that we would like to optimize by essentially\nusing this auxiliary proposal",
    "start": "488680",
    "end": "499030"
  },
  {
    "text": "distribution q to try to\ninfer the values of the latent variables.",
    "start": "499030",
    "end": "504970"
  },
  {
    "text": "Remember, the challenge is\nthat you only get to see x. You don't get to see the z part. You have to infer\nthe z part somehow.",
    "start": "504970",
    "end": "512020"
  },
  {
    "text": "The ELBO trick essentially\nuses a distribution q to try to infer the\nvalues of the z variables",
    "start": "512020",
    "end": "520950"
  },
  {
    "text": "when only the x is observed. And it constructs\nthat kind of lower",
    "start": "520950",
    "end": "526200"
  },
  {
    "text": "bound on the marginal\nlikelihood, the quantity on the left, the one you\nwould like to optimize,",
    "start": "526200",
    "end": "531300"
  },
  {
    "text": "as a function of theta. And what you can do is you can\nfurther decompose that objective",
    "start": "531300",
    "end": "539730"
  },
  {
    "text": "into two pieces. You have a first piece, which is\nbasically just the average log",
    "start": "539730",
    "end": "548370"
  },
  {
    "text": "probability when both\nthe x part and the z part are observed when you infer\nthe z part using this q model.",
    "start": "548370",
    "end": "558120"
  },
  {
    "text": "The first piece looks a lot like\nthe setting we've seen before, where everything is observed. Both the x and the\nz part are observed.",
    "start": "558120",
    "end": "565680"
  },
  {
    "text": "The only difference is\nthat you are essentially inferring the latent\npart using this q model.",
    "start": "565680",
    "end": "572710"
  },
  {
    "text": "Then there is another\npiece, which does not depend on your generative model. It does not depend on p at all.",
    "start": "572710",
    "end": "579300"
  },
  {
    "text": "It's only a function of\nq, and it's basically saying it's the\nexpected value under q",
    "start": "579300",
    "end": "586440"
  },
  {
    "text": "of log q, which is what\nwe've called in previous",
    "start": "586440",
    "end": "592020"
  },
  {
    "text": "lectures the entropy of q. And essentially, it's a\nquantity that tells you",
    "start": "592020",
    "end": "600150"
  },
  {
    "text": "how random q is,\nhow uncertain you should be about what is\nthe outcome of drawing",
    "start": "600150",
    "end": "606420"
  },
  {
    "text": "a sample from q. And we see that, basically,\nthis ELBO has these two pieces.",
    "start": "606420",
    "end": "611970"
  },
  {
    "text": "There is a term that\ndepends on the entropy of q, and there is a term that depends\non the average log probability",
    "start": "611970",
    "end": "619560"
  },
  {
    "text": "when you guess the missing\nparts of the data using this q distribution.",
    "start": "619560",
    "end": "625200"
  },
  {
    "text": "And so the higher the sum\nof these two terms is,",
    "start": "625200",
    "end": "631200"
  },
  {
    "text": "the closer you get\nto the evidence to the true value of\nthe marginal likelihood.",
    "start": "631200",
    "end": "637920"
  },
  {
    "text": "And what we've briefly\ndiscussed in the last lecture",
    "start": "637920",
    "end": "643260"
  },
  {
    "text": "is that if you\nwere to choose q-- this inequality holds\nfor any choice of q.",
    "start": "643260",
    "end": "649829"
  },
  {
    "text": "If you were to choose q to be\nthe posterior distribution of z given x under your\ngenerative model,",
    "start": "649830",
    "end": "657670"
  },
  {
    "text": "then this inequality\nbecomes an equality. So there is no longer an\napproximation involved",
    "start": "657670",
    "end": "665140"
  },
  {
    "text": "and the evidence\nlower bound becomes exactly equal to the\nmarginal likelihood.",
    "start": "665140",
    "end": "671090"
  },
  {
    "text": "And as an aside, this\nis exactly the quantity you would compute in the\nE-step of the EM algorithm",
    "start": "671090",
    "end": "680000"
  },
  {
    "text": "as you've seen it before. This procedure has the\nflavor of an EM algorithm",
    "start": "680000",
    "end": "686029"
  },
  {
    "text": "where you have a way of filling\nin the missing values using this q distribution,\nand then you",
    "start": "686030",
    "end": "693050"
  },
  {
    "text": "pretend that all the\ndata is fully observed, which is this piece here.",
    "start": "693050",
    "end": "698120"
  },
  {
    "text": "And then you have\nthis entropy term. But there is a connection\nbetween these learning methods,",
    "start": "698120",
    "end": "705470"
  },
  {
    "text": "EM and variational\nlearning, that what we're going to talk about today.",
    "start": "705470",
    "end": "710910"
  },
  {
    "text": "They both try to address the\nsame problem-- learning models when you have missing data. EM is not scalable,\ndoesn't quite",
    "start": "710910",
    "end": "718820"
  },
  {
    "text": "work in the context of\ndeep generative models. But these two methods\nare closely related,",
    "start": "718820",
    "end": "724130"
  },
  {
    "text": "and that's why you can see\nthat the optimal choice of q would be the conditional\ndistribution of the latent",
    "start": "724130",
    "end": "730770"
  },
  {
    "text": "variables given-- the z variables latents given x.",
    "start": "730770",
    "end": "736529"
  },
  {
    "text": "And now, how do you see this? Well, to derive it, you can\nwork out this expression.",
    "start": "736530",
    "end": "746250"
  },
  {
    "text": "If you work out the KL\ndivergence between this q distribution and this optimal\nway of inferring the latent",
    "start": "746250",
    "end": "753240"
  },
  {
    "text": "variables, which is the\nconditional distribution of z given x, it's\nnot too hard to see",
    "start": "753240",
    "end": "759240"
  },
  {
    "text": "that, if you do a\nlittle bit of algebra, this expression is equal to\nwhat you see here on the right.",
    "start": "759240",
    "end": "765550"
  },
  {
    "text": "So we see several pieces. We have the marginal\nprobability of x,",
    "start": "765550",
    "end": "771360"
  },
  {
    "text": "the log probability of x,\nthe marginal likelihood, the thing we care about. We have the entropy\nof q here, and then we",
    "start": "771360",
    "end": "777360"
  },
  {
    "text": "have this average\nlog joint probability over a fully\nobserved data point,",
    "start": "777360",
    "end": "785819"
  },
  {
    "text": "the same pieces we had before.  And the key takeaway is\nthat KL divergence we know",
    "start": "785820",
    "end": "794839"
  },
  {
    "text": "is non-negative. For any choice of q, the left\nhand side in this KL divergence",
    "start": "794840",
    "end": "801440"
  },
  {
    "text": "has to be non-negative. And so now, if you\nrearrange these terms,",
    "start": "801440",
    "end": "806480"
  },
  {
    "text": "we re-derived the ELBO in\na slightly different way. And you see, if you\nmove this entropy of q",
    "start": "806480",
    "end": "816620"
  },
  {
    "text": "and the first term here\non the right hand side, you get, once again, the ELBO. You get that the log marginal\nprobability of a data point",
    "start": "816620",
    "end": "825560"
  },
  {
    "text": "is lower bounded by the same\nexpression that we had before. So this is another\nderivation of the ELBO",
    "start": "825560",
    "end": "832230"
  },
  {
    "text": "that just leverages the\nnon-negativity of KL divergence. This derivation is nicer because\nit actually shows you how loose",
    "start": "832230",
    "end": "843330"
  },
  {
    "text": "or how tight this\nlower bound is. So you can clearly\nsee that if you",
    "start": "843330",
    "end": "849330"
  },
  {
    "text": "choose q to be the\nconditional distribution of z given x, so this bound\nholds for any choice of q.",
    "start": "849330",
    "end": "856740"
  },
  {
    "text": "If you choose this\nparticular distribution, then this KL divergence has\nto be 0 because the left",
    "start": "856740",
    "end": "865470"
  },
  {
    "text": "and the right argument\nof that KL divergence are the same distribution. And so this inequality\nhere becomes an equality.",
    "start": "865470",
    "end": "873400"
  },
  {
    "text": "And so we get this result that\nsort of like the ELBO is tight,",
    "start": "873400",
    "end": "879010"
  },
  {
    "text": "so it exactly matches the\nlog marginal probability when you basically infer the\nlatent variables the missing",
    "start": "879010",
    "end": "887980"
  },
  {
    "text": "variables using this optimal\nproposal distribution that",
    "start": "887980",
    "end": "895240"
  },
  {
    "text": "uses the true conditional\nprobability of z given x to guess the parts of the\ndata that you don't know.",
    "start": "895240",
    "end": "904160"
  },
  {
    "text": "Yeah? Is it like-- my\nunderstanding is that we",
    "start": "904160",
    "end": "909170"
  },
  {
    "text": "want to do this [INAUDIBLE]\nbecause if we just do Monte Carlo, it's too sparse. So since this will give\nus the maximum likelihood,",
    "start": "909170",
    "end": "917210"
  },
  {
    "text": "we can do this? Or can we actually\ndo this, and how easy is it to compute p of z? Yeah, yeah.",
    "start": "917210",
    "end": "922639"
  },
  {
    "text": "Great question. So I guess we said that, yeah,\nwe cannot really evaluate this",
    "start": "922640",
    "end": "928025"
  },
  {
    "text": "because it's too expensive. Now it seems like\nmaybe we can do it if we were able to\nchoose the optimal q.",
    "start": "928025",
    "end": "933830"
  },
  {
    "text": "This is more aspirational. We're not going to be able\nto actually make this choice, but it's showing\nus that we should",
    "start": "933830",
    "end": "941900"
  },
  {
    "text": "try to pick a q that is as close\nas possible to the optimal one.",
    "start": "941900",
    "end": "948810"
  },
  {
    "text": "And although in\npractice, for something like a variational autoencoder,\nas we will see soon, this object here is too\nexpensive to compute.",
    "start": "948810",
    "end": "957881"
  },
  {
    "text": "Like if you were able to\ncompute the posterior, then it would also be able\nto essentially compute the quantity on the left\nthat we want to optimize.",
    "start": "957882",
    "end": "966210"
  },
  {
    "text": "And that will motivate the whole\nidea of variational inference, which is basically\nsaying, let's try",
    "start": "966210",
    "end": "971340"
  },
  {
    "text": "to optimize over q to try to\nfind the tightest possible",
    "start": "971340",
    "end": "977730"
  },
  {
    "text": "lower bound. So we're going to have a\nseparate neural network that will play the role of\nq, and we will jointly",
    "start": "977730",
    "end": "984180"
  },
  {
    "text": "optimize both p and\nq to try to maximize this evidence lower bound.",
    "start": "984180",
    "end": "990090"
  },
  {
    "text": "And one of the components\nwill be the decoder in the VAE, which is p. The other component will\nbe the encoder of the VAE,",
    "start": "990090",
    "end": "998310"
  },
  {
    "text": "and that's going to be q. And they will have\nto work together to essentially try to maximize\nthe ELBO as much as possible.",
    "start": "998310",
    "end": "1007470"
  },
  {
    "text": "And you can see\nfrom this expression that the optimal\nencoder, the optimal q,",
    "start": "1007470",
    "end": "1013670"
  },
  {
    "text": "would be the true conditional\ndistribution of z given x. So it's inverting the encoder.",
    "start": "1013670",
    "end": "1020090"
  },
  {
    "text": "So again, it starts to have the\nflavor of an autoencoder, where",
    "start": "1020090",
    "end": "1025400"
  },
  {
    "text": "there is a decoder model,\nwhich is the p of z given x with the p of x given z. And then there is\nan encoder, which",
    "start": "1025400",
    "end": "1031459"
  },
  {
    "text": "is trying to invert\nwhat the decoder does because it's trying to compute\nthe conditional of z given x.",
    "start": "1031460",
    "end": "1042290"
  },
  {
    "text": "Hopefully, it will\nbecome clearer later. But essentially, this\nconfirms our intuition",
    "start": "1042290",
    "end": "1048050"
  },
  {
    "text": "that we're looking for\nlikely completions. So given the evidence,\ngiven x, we're",
    "start": "1048050",
    "end": "1053990"
  },
  {
    "text": "trying to find\npossible completions-- values of the z variables that\nare consistent with what we see,",
    "start": "1053990",
    "end": "1061679"
  },
  {
    "text": "where the consistency\nis determined by this joint probability\np of z comma x,",
    "start": "1061680",
    "end": "1067240"
  },
  {
    "text": "which is essentially\nthe generative model. It's the combination\nof the simple prior and then the other\nneural network that",
    "start": "1067240",
    "end": "1074820"
  },
  {
    "text": "will map its two\nparameters of a Gaussian, and then you sample\nfrom it, which is just the p of x given z.",
    "start": "1074820",
    "end": "1082980"
  },
  {
    "text": "So now the problem, as was\nalready brought up earlier,",
    "start": "1082980",
    "end": "1090030"
  },
  {
    "text": "is that this posterior\ndistribution in general is going to be tricky to--",
    "start": "1090030",
    "end": "1095130"
  },
  {
    "text": "well, we cannot\nactually compute it. And in some of the\ntoy models that you might have done EM\nwith, for example,",
    "start": "1095130",
    "end": "1102390"
  },
  {
    "text": "sometimes you can compute it. Like if you have a\nmixture of Gaussians, you can actually compute\nthis analytically.",
    "start": "1102390",
    "end": "1109120"
  },
  {
    "text": "That's why you can\ndo the E-step in EM. But in many cases, doing\nthat E-step is intractable.",
    "start": "1109120",
    "end": "1117600"
  },
  {
    "text": "So if you think about\nthe VAE, essentially, what you're doing is you're\ntrying to invert the decoder.",
    "start": "1117600",
    "end": "1125279"
  },
  {
    "text": "So recall that in a VAE,\nthe conditional distribution of x given z is given by this--",
    "start": "1125280",
    "end": "1133040"
  },
  {
    "text": "it's relatively simple. It's a Gaussian. But the parameters\nof the Gaussian depend on these two neural\nnetworks, mu and sigma.",
    "start": "1133040",
    "end": "1140767"
  },
  {
    "text": "And so what are you\ndoing when you're trying to compute p of z given x? You're basically trying to\ninvert these neural networks.",
    "start": "1140767",
    "end": "1147580"
  },
  {
    "text": "You are given x\nand you're trying to find which z's were\nlikely to have produced",
    "start": "1147580",
    "end": "1153770"
  },
  {
    "text": "this x value that I'm seeing,\nwhich is potentially pretty tricky because you\nhave to understand how",
    "start": "1153770",
    "end": "1159490"
  },
  {
    "text": "the neural network\nmaps these two outputs and you have to invert\na neural network",
    "start": "1159490",
    "end": "1165159"
  },
  {
    "text": "in a probabilistic sense. ",
    "start": "1165160",
    "end": "1172450"
  },
  {
    "text": "Does this make sense? ",
    "start": "1172450",
    "end": "1178820"
  },
  {
    "text": "Cool. And so the idea of the\nway we're going to train, again, this\nvariational autoencoder",
    "start": "1178820",
    "end": "1185259"
  },
  {
    "text": "is we're going to try to\napproximate this intractable posterior. We know that would\nbe the optimal way",
    "start": "1185260",
    "end": "1192070"
  },
  {
    "text": "to infer the latent variables\ngiven the observed ones, so we would have to invert\nthese two neural networks,",
    "start": "1192070",
    "end": "1198370"
  },
  {
    "text": "we would have to invert this\nconditional, this decoder. In general, that's\ngoing to be tricky.",
    "start": "1198370",
    "end": "1204860"
  },
  {
    "text": "And so instead, we're going to\ndefine a family of distributions over the latent\nvariables, which are also",
    "start": "1204860",
    "end": "1211540"
  },
  {
    "text": "going to be parameterized\nthrough a set of parameters phi,",
    "start": "1211540",
    "end": "1217240"
  },
  {
    "text": "the variational parameters. And then we're going to\ntry to jointly optimize both the q and the p\nto maximize the ELBO.",
    "start": "1217240",
    "end": "1226870"
  },
  {
    "text": "Can you explain\nagain why we want to even be able to\ncompute the posterior",
    "start": "1226870",
    "end": "1232300"
  },
  {
    "text": "z given x if our goal\nis just x or x given z? Yeah, so the reason we might\nwant to get this posterior",
    "start": "1232300",
    "end": "1241610"
  },
  {
    "text": "distribution is that,\nas we've seen here, if you were to use\nq here, this ELBO",
    "start": "1241610",
    "end": "1251179"
  },
  {
    "text": "would be tight so there\nwould be no approximation. And by optimizing\nthe right hand side,",
    "start": "1251180",
    "end": "1256680"
  },
  {
    "text": "you would actually be\noptimizing the left hand side, which is what we want. This is a little bit of a\nchicken and egg problem,",
    "start": "1256680",
    "end": "1263559"
  },
  {
    "text": "though, because if you\nthink about it, how is p of z given x defined,\nit's the joint p of x comma",
    "start": "1263560",
    "end": "1271150"
  },
  {
    "text": "z divided by p of x. And p of x is what\nwe want, right? So that's why it's like\nit's chicken and egg.",
    "start": "1271150",
    "end": "1278360"
  },
  {
    "text": "You can't really\ncompute this thing. And if you could\ncompute this thing, then you would know how\nto get the left hand",
    "start": "1278360",
    "end": "1284170"
  },
  {
    "text": "side so you don't even need to\ndo the ELBO computation at all.",
    "start": "1284170",
    "end": "1290080"
  },
  {
    "text": "But this is giving you a recipe\nto get a lower bound that holds for any choice of q\nand the game is going to be,",
    "start": "1290080",
    "end": "1298360"
  },
  {
    "text": "let's try to find something\nthat is as close as possible. Let's try to find\nsomething tractable that",
    "start": "1298360",
    "end": "1303549"
  },
  {
    "text": "can get us as close as\nwe can to what we know would be the optimal solution.",
    "start": "1303550",
    "end": "1308780"
  },
  {
    "text": "And that will end\nup being tractable. Quick question about notation.",
    "start": "1308780",
    "end": "1313850"
  },
  {
    "text": "What is variational\nparameters mean? Do you mean that by like\nparameters of a neural network or something? Yeah, so let's see\nwhat that means.",
    "start": "1313850",
    "end": "1319930"
  },
  {
    "text": "For example, q could be a family\nof Gaussian distributions,",
    "start": "1319930",
    "end": "1325480"
  },
  {
    "text": "where phi denote the\nmean and the covariance. So it could be\nsomething like this.",
    "start": "1325480",
    "end": "1330860"
  },
  {
    "text": "Maybe you have one\npart of phi denotes the mean of the\nGaussian, the other part",
    "start": "1330860",
    "end": "1335890"
  },
  {
    "text": "denotes the\ncovariance, and somehow you are trying to pick a good\nchoice of these two parameters",
    "start": "1335890",
    "end": "1344170"
  },
  {
    "text": "to get as close as possible\nto the true posterior that we know we would like to\nget for doing this to compute",
    "start": "1344170",
    "end": "1354070"
  },
  {
    "text": "the ELBO. And that's basically what\nvariational inference",
    "start": "1354070",
    "end": "1360010"
  },
  {
    "text": "is going to do. It's going to reduce this to\nan optimization problem, where",
    "start": "1360010",
    "end": "1365440"
  },
  {
    "text": "we're going to try to optimize\nthese variational parameters to try to make this\ndistribution q as close",
    "start": "1365440",
    "end": "1372610"
  },
  {
    "text": "as possible to this\nintractable optimal choice that we know exists but we\ndon't know how to compute.",
    "start": "1372610",
    "end": "1380360"
  },
  {
    "text": "So in pictures, it might\nbe something like this. There is a true conditional\ndistribution p of z",
    "start": "1380360",
    "end": "1387380"
  },
  {
    "text": "given x, which for\nsimplicity, it's shown as a mixture of two\nGaussians in blue here.",
    "start": "1387380",
    "end": "1395230"
  },
  {
    "text": "And let's say that you're trying\nto approximate that distribution using a Gaussian.",
    "start": "1395230",
    "end": "1400960"
  },
  {
    "text": "Then what you can do is\nyou can change the mean and the variance of this\nGaussian distributions to try to get as close as\npossible to the blue curve.",
    "start": "1400960",
    "end": "1409120"
  },
  {
    "text": "So for example, you\ncould choose the mean to be 2 and the\nvariance to be 2, which",
    "start": "1409120",
    "end": "1416430"
  },
  {
    "text": "would be two choices\nof phi 1 and phi 2, and maybe that would give\nyou this orange curve.",
    "start": "1416430",
    "end": "1422470"
  },
  {
    "text": "And if you could choose what's\nthe best approximation here, would you choose\nthe orange curve? Would you choose the\ngreen curve corresponding",
    "start": "1422470",
    "end": "1429240"
  },
  {
    "text": "to a mean at minus 4 and\nstandard deviation of 0.75?",
    "start": "1429240",
    "end": "1436590"
  },
  {
    "text": "I guess that what it looks like\nis that the orange curve is",
    "start": "1436590",
    "end": "1441870"
  },
  {
    "text": "better because it's\nkind of like roughly has the shape of the\ndistribution we want.",
    "start": "1441870",
    "end": "1447210"
  },
  {
    "text": "It's not quite the true\nposterior distribution, but it's pretty close.",
    "start": "1447210",
    "end": "1452920"
  },
  {
    "text": "And so if we somehow\nare able to come up with this variational\napproximation with this simple\ndistribution that",
    "start": "1452920",
    "end": "1459610"
  },
  {
    "text": "is roughly close\nto what we want, that might be good\nenough for learning. And that's like the idea\nbehind variational inference.",
    "start": "1459610",
    "end": "1467690"
  },
  {
    "text": "Let's try to optimize\nthis distribution q over this variational\nparameters phi",
    "start": "1467690",
    "end": "1472840"
  },
  {
    "text": "to try to make this Gaussian\ndistribution as close as possible to this\nobject that we know",
    "start": "1472840",
    "end": "1478450"
  },
  {
    "text": "is there, that we\nknow we would like to approximate as well as we\ncan, but is often intractable.",
    "start": "1478450",
    "end": "1484591"
  },
  {
    "text": "[INAUDIBLE] by the dimensions\nof the latent variables and the data.",
    "start": "1484591",
    "end": "1489620"
  },
  {
    "text": "So they are generally\nnot the same dimensions? Yeah. So the latent variables\ndon't necessarily",
    "start": "1489620",
    "end": "1495770"
  },
  {
    "text": "have the same\ndimensions as the data. And for this, the only\nthing that matters",
    "start": "1495770",
    "end": "1502828"
  },
  {
    "text": "are the latent variables. We're just trying to find a\ndistribution over the latent variables that is as close as\npossible to the true posterior",
    "start": "1502828",
    "end": "1511010"
  },
  {
    "text": "distribution. Similarly, [INAUDIBLE]\nlike a simple latents rate.",
    "start": "1511010",
    "end": "1517470"
  },
  {
    "text": "Yes. So again, in practice, in\na variational autoencoder, this q will actually\nbe, again, a Gaussian.",
    "start": "1517470",
    "end": "1526010"
  },
  {
    "text": "So everything will be relatively\nsimple that will come up soon. But essentially, even in\na variational autoencoder,",
    "start": "1526010",
    "end": "1533465"
  },
  {
    "text": "what you would do is you would\ntry to optimize these parameters phi to try to match\nthe true posterior",
    "start": "1533465",
    "end": "1539120"
  },
  {
    "text": "distribution, the true p of z\ngiven x, as well as you can.",
    "start": "1539120",
    "end": "1544309"
  },
  {
    "text": "Yeah? How would you evaluate q? Yeah, how we evaluate q?",
    "start": "1544310",
    "end": "1552019"
  },
  {
    "text": "The natural thing to do would be\nto look at KL divergence, right? We know KL divergence\nis telling you",
    "start": "1552020",
    "end": "1559190"
  },
  {
    "text": "how far off you are, your\nELBO is, from the true thing.",
    "start": "1559190",
    "end": "1564750"
  },
  {
    "text": "So it might make\nsense to try to choose a q that is as close to p of\nz given x in KL divergence.",
    "start": "1564750",
    "end": "1573110"
  },
  {
    "text": "And that might be what's going\nto happen when we optimize",
    "start": "1573110",
    "end": "1580970"
  },
  {
    "text": "the ELBO and when we basically\ntrain a variational autoencoder.",
    "start": "1580970",
    "end": "1586048"
  },
  {
    "text": " All right. So that's sort of like the idea.",
    "start": "1586048",
    "end": "1593080"
  },
  {
    "text": "And in pictures, again, it\nlooks something like this. Like for a given x\nand a given choice",
    "start": "1593080",
    "end": "1599980"
  },
  {
    "text": "of theta, which\nare the parameters of your variational\nautoencoder, your decoder,",
    "start": "1599980",
    "end": "1607750"
  },
  {
    "text": "there is a true value of\nthe log probability of x, which is this blue line here.",
    "start": "1607750",
    "end": "1616020"
  },
  {
    "text": "And then you can\nimagine that if you have a family of distributions\nq, which are parameterized",
    "start": "1616020",
    "end": "1623270"
  },
  {
    "text": "by phi, as you change phi,\nyou get lower bounds that",
    "start": "1623270",
    "end": "1628670"
  },
  {
    "text": "could be tighter or looser\ndepending on this KL divergence",
    "start": "1628670",
    "end": "1636440"
  },
  {
    "text": "value, how close\nyour distribution q is to the true posterior.",
    "start": "1636440",
    "end": "1644100"
  },
  {
    "text": "And so, essentially,\nwhat we're going to do is we're going to define an\nevidence lower bound, which",
    "start": "1644100",
    "end": "1652430"
  },
  {
    "text": "not only depends\non theta, which are the parameters of\nthe generative model, but also depends on this choice\nof variational parameters phi.",
    "start": "1652430",
    "end": "1662071"
  },
  {
    "text": "And what we're\ngoing to do is we're going to try to jointly optimize\nthis right hand side over theta",
    "start": "1662072",
    "end": "1669110"
  },
  {
    "text": "and phi so that by\noptimizing theta, we try to make this\nlower bound as close as",
    "start": "1669110",
    "end": "1675810"
  },
  {
    "text": "possible to the\nthing we care about. And by optimizing theta, we\nare pushing up a lower bound",
    "start": "1675810",
    "end": "1682980"
  },
  {
    "text": "on the marginal\nlikelihood, which is again a surrogate to the\nmaximum likelihood objective.",
    "start": "1682980",
    "end": "1689840"
  },
  {
    "text": "And so it makes sense to\njointly optimize this ELBO as a function of\nboth theta and phi.",
    "start": "1689840",
    "end": "1696740"
  },
  {
    "text": "So what we had here was\none lower bound, which",
    "start": "1696740",
    "end": "1703809"
  },
  {
    "text": "holds for some choice of q. And now we're saying\nwe're going to define a family of lower bounds that\nare going to be indexed by phi,",
    "start": "1703810",
    "end": "1711010"
  },
  {
    "text": "these variational parameters. And we're going to try to\nfind the choice of phi that",
    "start": "1711010",
    "end": "1717220"
  },
  {
    "text": "makes the lower bound as tight\nas possible because that means that we get the best\napproximation to the quantity we",
    "start": "1717220",
    "end": "1723670"
  },
  {
    "text": "care about, which is the\nlikelihood of a data point. And that's,\nbasically, the way you",
    "start": "1723670",
    "end": "1730330"
  },
  {
    "text": "train a variational autoencoder. You jointly optimize\nthis expression as a function of theta and phi.",
    "start": "1730330",
    "end": "1737570"
  },
  {
    "text": "And it will turn out\nthat there's, basically, going to be two neural networks,\na decoder and an encoder. The decoder is,\nbasically, theta;",
    "start": "1737570",
    "end": "1744520"
  },
  {
    "text": "the encoder is\ngoing to be the phi; and these two\nthings work together to try to maximize the\nevidence lower bound.",
    "start": "1744520",
    "end": "1751330"
  },
  {
    "text": " And we know that, again,\nthe gap between the ELBO",
    "start": "1751330",
    "end": "1761240"
  },
  {
    "text": "and the true marginal likelihood\nis given by this KL divergence. And so the better we can\napproximate the true conditional",
    "start": "1761240",
    "end": "1771170"
  },
  {
    "text": "distribution of z given x,\nthe tighter the bound becomes. So that's, basically, going\nto be the objective back",
    "start": "1771170",
    "end": "1779240"
  },
  {
    "text": "to your question. By pushing up this quantity as\na function of theta and phi,",
    "start": "1779240",
    "end": "1784909"
  },
  {
    "text": "we're implicitly\ntrying to reduce the KL divergence between the\nproposal distribution that we",
    "start": "1784910",
    "end": "1791000"
  },
  {
    "text": "have, which is this q, and\nthe true optimal one that would require you to invert\nthe neural networks exactly",
    "start": "1791000",
    "end": "1797330"
  },
  {
    "text": "that we don't know how to do. But we know that how far off\nwe are with respect to this KL",
    "start": "1797330",
    "end": "1804559"
  },
  {
    "text": "divergence, or how big\nthis KL divergence is, determines how much slack\nthere is between the lower",
    "start": "1804560",
    "end": "1811309"
  },
  {
    "text": "bound and the blue curve. And so you can think\nof the E-step of EM",
    "start": "1811310",
    "end": "1817810"
  },
  {
    "text": "as giving you the tightest\npossible lower bound. And that's why you do it\nas the first thing in EM",
    "start": "1817810",
    "end": "1823659"
  },
  {
    "text": "is to compute the true\nconditional distribution because that gives you the\ntightest possible lower bound.",
    "start": "1823660",
    "end": "1830330"
  },
  {
    "text": "So we can no longer do it\nhere because we cannot compute the tightest\npossible lower bound, but we can try to get\nas close as we can.",
    "start": "1830330",
    "end": "1836919"
  },
  {
    "text": " Yeah? [INAUDIBLE] if I'm\nunderstanding correctly.",
    "start": "1836920",
    "end": "1843950"
  },
  {
    "text": "We're trying to compute\nlog p so that we can do maximum likelihood\nestimation, right?",
    "start": "1843950",
    "end": "1851310"
  },
  {
    "text": "OK, so there are two ways. So there are two optimization\nobjectives here, right? So the first one is we're\ntrying to maximize log p,",
    "start": "1851310",
    "end": "1859340"
  },
  {
    "text": "and the other one is we're\ntrying to maximize the ELBO to get close to p as possible.",
    "start": "1859340",
    "end": "1866081"
  },
  {
    "text": "Am I understanding correctly? So the dream would be\nto just optimize log p, this quantity on\nthe left hand side,",
    "start": "1866082",
    "end": "1872300"
  },
  {
    "text": "as a function of theta. That if you could\ndo that, then that's just like training an\nautoregressive model. That's the best thing we can do.",
    "start": "1872300",
    "end": "1878539"
  },
  {
    "text": "That quantity, we don't\nknow how to evaluate. But we can get a\nbound that holds for any choice of phi, which\nis the red curve shown here.",
    "start": "1878540",
    "end": "1888400"
  },
  {
    "text": "So what you could do is you\ncould try to jointly optimize over phi and theta to get a\npretty good surrogate of what",
    "start": "1888400",
    "end": "1897500"
  },
  {
    "text": "we would like to optimize. [INAUDIBLE] to maximize\nthe lower bound? We are going to optimize\nthe lower bound instead.",
    "start": "1897500",
    "end": "1903590"
  },
  {
    "text": "And at the same time, we're\ngoing to try to make the-- you are optimizing a\nfamily of lower bounds and we're trying to find\na tight as possible bound",
    "start": "1903590",
    "end": "1910490"
  },
  {
    "text": "and increase the bound as\na function of the theta parameters of your\ngenerative model to maximize",
    "start": "1910490",
    "end": "1917929"
  },
  {
    "text": "the likelihood of a data set. Exactly. If you were to run this on\ninference, quote unquote,",
    "start": "1917930",
    "end": "1923780"
  },
  {
    "text": "so you just basically throw out\nq and just worry about the p?",
    "start": "1923780",
    "end": "1929290"
  },
  {
    "text": "Yeah, so the question is at\ninference time do you need a q?",
    "start": "1929290",
    "end": "1934820"
  },
  {
    "text": "If you just want to\ngenerate, you don't need q. If you just want\nto generate, just have your optimal\nchoice of theta",
    "start": "1934820",
    "end": "1941390"
  },
  {
    "text": "that perhaps you obtain\nby optimizing the ELBO. And all you need is that. Right? You can sample z.",
    "start": "1941390",
    "end": "1947120"
  },
  {
    "text": "You feed it through\nyour decoder, your two neural networks,\nmu theta and sigma theta, produce a sample.",
    "start": "1947120",
    "end": "1952980"
  },
  {
    "text": "Now, if you wanted to evaluate\nthe likelihood of a data point because maybe you want\nto do anomaly detection",
    "start": "1952980",
    "end": "1958130"
  },
  {
    "text": "or something like that,\nthen you might still need the q because that helps\nyou compute this quantity.",
    "start": "1958130",
    "end": "1965950"
  },
  {
    "text": "At least it gives you a bound. And to the extent that the bound\nis good, you might need that. And so q is still useful.",
    "start": "1965950",
    "end": "1973270"
  },
  {
    "text": "But if you just care about\ngeneration, you are right, you can throw it away\nafter you train the model.",
    "start": "1973270",
    "end": "1979080"
  },
  {
    "text": "Isn't KL Divergence no negative? Shouldn't it be like a minus KL\ndivergence to be a lower bound?",
    "start": "1979080",
    "end": "1988260"
  },
  {
    "text": "I think it's fine because,\nbasically, L is below, right? So this one.",
    "start": "1988260",
    "end": "1993690"
  },
  {
    "text": "So the log probability\nis always above. Yeah. Yeah.",
    "start": "1993690",
    "end": "1999640"
  },
  {
    "text": "So actually the phi is\nactually somehow related",
    "start": "1999640",
    "end": "2004890"
  },
  {
    "text": "to [? theta ?] right? It's a [INAUDIBLE] but when\nyou do this optimization,",
    "start": "2004890",
    "end": "2009990"
  },
  {
    "text": "you actually don't\ncare about this. What exactly\n[INAUDIBLE] about that? That's a great question.",
    "start": "2009990",
    "end": "2015780"
  },
  {
    "text": "Is phi related to theta? And the optimal\nphi would certainly be related because\nthe optimal phi would",
    "start": "2015780",
    "end": "2022020"
  },
  {
    "text": "try to give you the posterior\ndistribution with respect to theta, right?",
    "start": "2022020",
    "end": "2027059"
  },
  {
    "text": "So we know that the optimal\nchoice-- actually I have it here. The optimal choice of phi would\nbe this posterior distribution,",
    "start": "2027060",
    "end": "2034810"
  },
  {
    "text": "which depends on theta. And so they are certainly\ncoupled together.",
    "start": "2034810",
    "end": "2040200"
  },
  {
    "text": "By jointly optimizing\nover one and the other, you are effectively trying\nto get as close as you can",
    "start": "2040200",
    "end": "2047580"
  },
  {
    "text": "to that point, but it's not\nguaranteed to be exactly equal.",
    "start": "2047580",
    "end": "2052742"
  },
  {
    "text": "So these two things are\nrelated to each other, but the final value\nof phi that you obtain",
    "start": "2052742",
    "end": "2058809"
  },
  {
    "text": "is not necessarily\nthe one that gives you this that matches the true\nconditional distribution.",
    "start": "2058810",
    "end": "2065649"
  },
  {
    "text": "It's going to be\nclose, hopefully, because if you've done a good\njob at optimizing, hopefully, this KL divergence\nis going to be small.",
    "start": "2065650",
    "end": "2072460"
  },
  {
    "text": "But there is no\nguarantee because perhaps the true posterior\nis too complicated,",
    "start": "2072460",
    "end": "2079839"
  },
  {
    "text": "and your q is too simple, so\nyou might still be far off. But there is certainly an\ninterplay between the two",
    "start": "2079840",
    "end": "2086408"
  },
  {
    "text": "in the sense that at\noptimality, this KL divergence should be zero, and so\nthey should match each.",
    "start": "2086409",
    "end": "2093489"
  },
  {
    "start": "2093489",
    "end": "2098490"
  },
  {
    "text": "Cool. So that's basically how you\ntrain a variational autoencoder.",
    "start": "2098490",
    "end": "2103560"
  },
  {
    "text": "You jointly optimize\nthat expression here as a function\nof theta and phi. ",
    "start": "2103560",
    "end": "2112020"
  },
  {
    "text": "And again, this is the picture. It's a little bit\ntricky because there are two optimization problems\nthat happen at the same time.",
    "start": "2112020",
    "end": "2119769"
  },
  {
    "text": "But what happens is that there\nis this theta parameters, which are the parameters of the\ndecoder, the thing that you",
    "start": "2119770",
    "end": "2127170"
  },
  {
    "text": "would really like to optimize. And for different\nchoices of thetas,",
    "start": "2127170",
    "end": "2132562"
  },
  {
    "text": "there is going to be\ndifferent likelihoods that are assigned to the data. And I'm showing this curve\nhere, this black solid curve,",
    "start": "2132562",
    "end": "2140340"
  },
  {
    "text": "as being the true\nmarginal likelihood. If you could, you\nshould just optimize that as a function\nof theta that would",
    "start": "2140340",
    "end": "2146340"
  },
  {
    "text": "be maximum likelihood learning. That would be great. The problem is that we cannot\nquite compute that thing.",
    "start": "2146340",
    "end": "2152110"
  },
  {
    "text": "And so we're going to settle\nfor lower bounds, which you see here, meaning that\nthese are curves that are always",
    "start": "2152110",
    "end": "2157829"
  },
  {
    "text": "below the black curve. And there is a family\nof lower bounds.",
    "start": "2157830",
    "end": "2163550"
  },
  {
    "text": "There is going to be\nmany lower bounds. Any value of phi will give\nyou a valid lower bound.",
    "start": "2163550",
    "end": "2168685"
  },
  {
    "text": "And what we're\ngoing to try to do is we're going to try to find\na good lower bound, meaning",
    "start": "2168685",
    "end": "2175730"
  },
  {
    "text": "one that is as high as\npossible, that is as close as possible to the black line.",
    "start": "2175730",
    "end": "2181410"
  },
  {
    "text": "So there's going to be a\njoint optimization over theta, which is what tries to maximize\nthe probability of the data set.",
    "start": "2181410",
    "end": "2187520"
  },
  {
    "text": "And we're going to achieve\nthat by optimizing a bound. Let's say, optimizing\nthe red curve",
    "start": "2187520",
    "end": "2193040"
  },
  {
    "text": "or optimizing the orange\ncurve, and at the same time, trying to pick a bound to\npick a choice of phi that",
    "start": "2193040",
    "end": "2202369"
  },
  {
    "text": "gets us as close as\npossible to the black line. If our goal is to fit the\nblack line as well as possible,",
    "start": "2202370",
    "end": "2212510"
  },
  {
    "text": "why are we\nconstraining ourselves to a normal distribution? Would it not be maybe\npossible to learn aspects",
    "start": "2212510",
    "end": "2219890"
  },
  {
    "text": "of the distribution as well? Which part is it you think-- is\nthe normal in the conditional",
    "start": "2219890",
    "end": "2225200"
  },
  {
    "text": "or the prior or the q? I'm talking about q. q.",
    "start": "2225200",
    "end": "2230340"
  },
  {
    "text": "Yes, great question. So the more flexible\nq is-- so if instead",
    "start": "2230340",
    "end": "2235654"
  },
  {
    "text": "of using just a Gaussian, maybe\nyou use a mixture of Gaussians, maybe you use an autoregressive\nmodel that better this bound",
    "start": "2235655",
    "end": "2243210"
  },
  {
    "text": "becomes. So the better you're\ngoing to do at fitting your original decoder.",
    "start": "2243210",
    "end": "2249600"
  },
  {
    "text": "So there is many papers\nwhere people basically propose better choices\nfor q, which essentially",
    "start": "2249600",
    "end": "2256920"
  },
  {
    "text": "means more flexible families. And that can give\nyou a better data fit by basically making this\nproposal distribution more",
    "start": "2256920",
    "end": "2265530"
  },
  {
    "text": "flexible. So, indeed, that's a great\nway to make the model better. Make q more expressive,\nmore flexible.",
    "start": "2265530",
    "end": "2273580"
  },
  {
    "text": "[INAUDIBLE] lets you\noptimize your [? profiles ?] to fit a curve that\nmatches the black line.",
    "start": "2273580",
    "end": "2278760"
  },
  {
    "text": "But then afterwards,\nyour black line is going to change the\n[? software ?] [INAUDIBLE] keep doing that over and over again? Yeah, so, that's\na great question.",
    "start": "2278760",
    "end": "2285130"
  },
  {
    "text": "I mean the thing is, it\nseems like as you change-- it goes back to the\nother points that",
    "start": "2285130",
    "end": "2290910"
  },
  {
    "text": "were raised that phi and\ntheta are coupled together. So [INAUDIBLE] how good a\nbound is depends on the--",
    "start": "2290910",
    "end": "2299490"
  },
  {
    "text": "how good a phi is depends on\nthe current choice of theta. And so if you are around\nhere, maybe this--",
    "start": "2299490",
    "end": "2306750"
  },
  {
    "text": "as you can see here, around\nthis choice of theta, maybe the red curve would\nbe better than the orange.",
    "start": "2306750",
    "end": "2312595"
  },
  {
    "text": "But then if you have\na different choice of your variational parameters,\nthen maybe the orange curve starts to become better.",
    "start": "2312595",
    "end": "2318820"
  },
  {
    "text": "And so as we jointly optimize,\nwe'll have to keep them in sync. In practice, what we do is\nwe just do gradient ascent",
    "start": "2318820",
    "end": "2325980"
  },
  {
    "text": "on both theta and phi. So we try to keep them,\nbut you could also just keep theta fixed,\noptimize as a function of phi",
    "start": "2325980",
    "end": "2333250"
  },
  {
    "text": "as well as you can that\ngives you the tightest bound, and then optimize\ntheta by a little bit. That is actually\nwhat happens in EM.",
    "start": "2333250",
    "end": "2340210"
  },
  {
    "text": "You can think of\nEM as giving you the tightest possible bound for\nthe current choice of theta. And then in the M-step, you\noptimize the lower bound",
    "start": "2340210",
    "end": "2348549"
  },
  {
    "text": "as well as you can. Here, we're not\ngoing to do that. We're going to do\ngradient-based updates, but it's the same\nphilosophy, trying",
    "start": "2348550",
    "end": "2355381"
  },
  {
    "text": "to join [INAUDIBLE]\noptimize one and the other. ",
    "start": "2355382",
    "end": "2361580"
  },
  {
    "text": "Cool. So all right. So let's see how we do that. So we know that for any choice\nof q, we get the lower bound.",
    "start": "2361580",
    "end": "2371300"
  },
  {
    "text": "That's the ELBO. Now what we would\nlike to do, recall, is that we have\na data set and we",
    "start": "2371300",
    "end": "2377300"
  },
  {
    "text": "would like to optimize the\naverage log probability assigned to all the data points\nin the data set.",
    "start": "2377300",
    "end": "2385440"
  },
  {
    "text": "So we don't just care\nabout a single x, we care about all the\nx's in our data set D.",
    "start": "2385440",
    "end": "2391340"
  },
  {
    "text": "And what we can do\nis, well, we know how to bound the log probability\nfor any x and any theta",
    "start": "2391340",
    "end": "2397880"
  },
  {
    "text": "through the ELBO. And so we can get a lower\nbound to the quantity",
    "start": "2397880",
    "end": "2403440"
  },
  {
    "text": "on the left, which is the\naverage log likelihood assigned to the data set, by just\ntaking the sum of the ELBOs",
    "start": "2403440",
    "end": "2408930"
  },
  {
    "text": "on each data point. All right. So this is the ELBO\nfor a general x.",
    "start": "2408930",
    "end": "2414280"
  },
  {
    "text": "We can get the ELBO\nfor each data point, and we get this expression.",
    "start": "2414280",
    "end": "2419350"
  },
  {
    "text": "Now the main\ncomplication here is that we're going to\nneed different queues",
    "start": "2419350",
    "end": "2426750"
  },
  {
    "text": "for different data points. And so the, if you think about\nit, the posterior distribution,",
    "start": "2426750",
    "end": "2437120"
  },
  {
    "text": "even for a same\nchoice of theta, is going to be different across\ndifferent data points.",
    "start": "2437120",
    "end": "2442619"
  },
  {
    "text": "And so you might want to choose\ndifferent variational parameters for different data points.",
    "start": "2442620",
    "end": "2450320"
  },
  {
    "text": "And so you don't have a single\nset of variational parameters phi, but you have a\nsingle choice of theta",
    "start": "2450320",
    "end": "2457240"
  },
  {
    "text": "because you have a\nsingle generative model for the whole data set. But then you-- at least\nif you do things this way,",
    "start": "2457240",
    "end": "2465200"
  },
  {
    "text": "you would need to choose\nvariational parameters differently for\ndifferent data points.",
    "start": "2465200",
    "end": "2472010"
  },
  {
    "text": "I mean, we'll see that this\nis not going to be scalable, but this would be\nthe-- and so we'll have to introduce additional\napproximations to make things",
    "start": "2472010",
    "end": "2479660"
  },
  {
    "text": "more scalable, but this would\nbe the most natural thing to do. For every data point, you try\nto find the best approximation",
    "start": "2479660",
    "end": "2486950"
  },
  {
    "text": "to the posterior for that\nparticular choice of xi, and then you jointly\noptimize the whole thing.",
    "start": "2486950",
    "end": "2493220"
  },
  {
    "text": "You try to make the\nlower bound for each data point as tight as possible so\nthat the sum of the lower bounds",
    "start": "2493220",
    "end": "2498800"
  },
  {
    "text": "is going to be as good of\nan approximation as you can to the true quantity\nyou'd like to optimize,",
    "start": "2498800",
    "end": "2504530"
  },
  {
    "text": "which is the true\nmarginal likelihood here. Then why do you need\na separate [INAUDIBLE]",
    "start": "2504530",
    "end": "2512320"
  },
  {
    "text": "for each [INAUDIBLE]? Yeah, I think I have\nan example here.",
    "start": "2512320",
    "end": "2517540"
  },
  {
    "text": "In this example, let's say\nthat the latent variables are the pixels in an image.",
    "start": "2517540",
    "end": "2523347"
  },
  {
    "text": "So then, at least\nthey are meaningful, and you can get a sense of\nwhat the posterior should be. So let's say that we have\na distribution over images",
    "start": "2523347",
    "end": "2533470"
  },
  {
    "text": "and the x variables are the\nbottom half of the image and the z variables are\nthe top half of the image.",
    "start": "2533470",
    "end": "2539230"
  },
  {
    "text": "But let's pretend\nthat maybe you're fitting an autoregressive\nmodel, but we",
    "start": "2539230",
    "end": "2545020"
  },
  {
    "text": "are in this situation where some\nparts of the image is missing,",
    "start": "2545020",
    "end": "2553570"
  },
  {
    "text": "so you never get to see\nthe top half of the image.",
    "start": "2553570",
    "end": "2558720"
  },
  {
    "text": "So that's a latent variable. So it's no longer a VAE. It's a slightly different\nmodel, but it's just",
    "start": "2558720",
    "end": "2564050"
  },
  {
    "text": "to give you the intuition of\nwhat we're trying to do here. So to fit your autoregressive\nmodel, your transformer model,",
    "start": "2564050",
    "end": "2571550"
  },
  {
    "text": "or RNN, or whatever, you\nneed to somehow guess the top half of the\nimage if you want",
    "start": "2571550",
    "end": "2577039"
  },
  {
    "text": "to evaluate this\njoint probability and you can optimize\nyour parameters.",
    "start": "2577040",
    "end": "2582859"
  },
  {
    "text": "And one way to do it\nis to basically use this variational trick\nof trying to guess",
    "start": "2582860",
    "end": "2588890"
  },
  {
    "text": "the values of the missing\npixels and then pretend that you have a fully observed\ndata set and then just optimize.",
    "start": "2588890",
    "end": "2598160"
  },
  {
    "text": "But there is different ways of\nguessing the missing values, the missing pixels. So you can define a family of\ndistributions over the missing",
    "start": "2598160",
    "end": "2606530"
  },
  {
    "text": "pixels. And here, just for\nsimplicity, I'm saying the pixels are\njust binary 0 and 1.",
    "start": "2606530",
    "end": "2612080"
  },
  {
    "text": "And so you have a bunch\nof variational parameters that will basically\ntell you the probability",
    "start": "2612080",
    "end": "2617120"
  },
  {
    "text": "that you should choose each\nindividual pixel that is not observed to be on or off.",
    "start": "2617120",
    "end": "2623910"
  },
  {
    "text": "And so in this case, you have\none variational parameter per missing pixel. And you can see that\nwhat's a good approximation",
    "start": "2623910",
    "end": "2633290"
  },
  {
    "text": "depends on the bottom\nhalf of the image. If you get to see this part,\nwould you choose phi i 0.5",
    "start": "2633290",
    "end": "2641960"
  },
  {
    "text": "as your approximation of the\nposterior, which basically means the way you're going\nto guess the missing",
    "start": "2641960",
    "end": "2647810"
  },
  {
    "text": "values is by randomly flipping\na coin on each location. It's probably not a\ngood approximation",
    "start": "2647810",
    "end": "2654773"
  },
  {
    "text": "to the true posterior. You kind of know that\nthis is probably a nine, and so you want\nto guess that way.",
    "start": "2654773",
    "end": "2663349"
  },
  {
    "text": "And so probably not a good one. Would turning everything\non be a good approximation?",
    "start": "2663350",
    "end": "2669280"
  },
  {
    "text": "Probably not. Again, you want to choose\nturn on the pixels that",
    "start": "2669280",
    "end": "2674290"
  },
  {
    "text": "correspond to the nine. But you see that it\ndepends on what you see.",
    "start": "2674290",
    "end": "2681640"
  },
  {
    "text": "It depends on the evidence x. So if you see this, you\nmight say it's a nine.",
    "start": "2681640",
    "end": "2686890"
  },
  {
    "text": "But if you see a\nstraight line, then maybe you'll think it's a one. So you want to choose\ndifferent values",
    "start": "2686890",
    "end": "2692260"
  },
  {
    "text": "of these variational parameters. And so even though theta is\ncommon across the data points,",
    "start": "2692260",
    "end": "2700150"
  },
  {
    "text": "the values of the latent\nvariables that you infer should be different. Again, going back to the\nvariational autoencoder,",
    "start": "2700150",
    "end": "2708010"
  },
  {
    "text": "if z now captures latent\nfactors of variation, like the class of the\ndata point or whatever,",
    "start": "2708010",
    "end": "2715450"
  },
  {
    "text": "again, you'd like to\nmake different choices for how you infer z\ndepending on what you see,",
    "start": "2715450",
    "end": "2720920"
  },
  {
    "text": "depending on the x part. And so that motivates\nthis choice of, OK, we",
    "start": "2720920",
    "end": "2727750"
  },
  {
    "text": "want to optimize, we want\nto choose different phis for the data points because\nthe latent variables are going",
    "start": "2727750",
    "end": "2733750"
  },
  {
    "text": "to be potentially very different\nacross the different data points. Or another way to say\nit is that if you think",
    "start": "2733750",
    "end": "2739690"
  },
  {
    "text": "about the generative\nprocedure of the VAE, you're generating these x's\nby feeding random noise,",
    "start": "2739690",
    "end": "2746410"
  },
  {
    "text": "essentially, into\na neural network. And depending on\nthe x you see, you",
    "start": "2746410",
    "end": "2751660"
  },
  {
    "text": "might want to make very\ndifferent guesses about what was the random noise that\nyou've put through your decoder,",
    "start": "2751660",
    "end": "2757640"
  },
  {
    "text": "through your neural network. And so you want to choose\ndifferent choices of phis",
    "start": "2757640",
    "end": "2762800"
  },
  {
    "text": "for the different x's that\nyou have in your data set. I don't know if you covered\nthis already but does",
    "start": "2762800",
    "end": "2769350"
  },
  {
    "text": "maximizing the right ELBO\nguarantee that it also maximize the left further?",
    "start": "2769350",
    "end": "2774360"
  },
  {
    "text": "Could it be also to have-- maximize that but it actually\nmight not be really optimal. Yeah, so that's\na great question. To what extent is optimizing\nthe right hand side",
    "start": "2774360",
    "end": "2781320"
  },
  {
    "text": "a good approximation to\noptimizing the left hand side? And it's a reasonable\napproximation in the sense",
    "start": "2781320",
    "end": "2788710"
  },
  {
    "text": "that whatever value\nyou have here, the true thing can only be\nbetter than what you got.",
    "start": "2788710",
    "end": "2795720"
  },
  {
    "text": "You could be far off. And in fact, you could be doing\nweird things where maybe--",
    "start": "2795720",
    "end": "2802950"
  },
  {
    "text": "let's see whether\nI have it here. But it could be that it looks\nlike you're optimizing--",
    "start": "2802950",
    "end": "2808200"
  },
  {
    "text": "the lower bound goes up, but the\ntrue thing actually goes down. You could imagine a\nshape here where--",
    "start": "2808200",
    "end": "2817020"
  },
  {
    "text": "let's see if I have\nan example here. But basically, it looks like-- maybe if you go\nfrom here to here,",
    "start": "2817020",
    "end": "2825420"
  },
  {
    "text": "it looks like the\nred line goes up, but the black line\nmight actually go down. So in that sense,\nthere is no guarantee",
    "start": "2825420",
    "end": "2833770"
  },
  {
    "text": "because the bounds could be very\nfar off from the true thing.",
    "start": "2833770",
    "end": "2839410"
  },
  {
    "text": "But what you know is that\nthe true objective function is going to be at\nleast as good as what you get by optimizing these,\nwhich is not a bad guarantee",
    "start": "2839410",
    "end": "2847330"
  },
  {
    "text": "to have. ",
    "start": "2847330",
    "end": "2852869"
  },
  {
    "text": "All right. So now, this is the\nhow to choose them.",
    "start": "2852870",
    "end": "2858240"
  },
  {
    "text": "Now how do we actually do this? The simplest version would\nbe to just do gradient ascent",
    "start": "2858240",
    "end": "2865049"
  },
  {
    "text": "on this objective function. Right? The ELBO, if you expand it,\nit would look like this.",
    "start": "2865050",
    "end": "2871630"
  },
  {
    "text": "So for every data point xi, you\nwould have this expectation, with respect to this\nvariational distribution",
    "start": "2871630",
    "end": "2878670"
  },
  {
    "text": "q, this way of inferring\nthe latent variables given the observed ones.",
    "start": "2878670",
    "end": "2883800"
  },
  {
    "text": "And then you would have\nthe log probability in the fully observed\ncase, and then you",
    "start": "2883800",
    "end": "2889530"
  },
  {
    "text": "have this term, which is kind\nof like the entropy of q. And so what you\ncould do is you could",
    "start": "2889530",
    "end": "2895920"
  },
  {
    "text": "do initialize all the\noptimization variables somehow.",
    "start": "2895920",
    "end": "2901410"
  },
  {
    "text": "And then you could randomly\nsample a data point, and then you could try\nto optimize this quantity",
    "start": "2901410",
    "end": "2910380"
  },
  {
    "text": "as well as you can as a function\nof the variational parameters. So you compute a gradient\nof the quantity with respect",
    "start": "2910380",
    "end": "2918009"
  },
  {
    "text": "to the variational\nparameters, you try to make that ELBO as tight\nas possible for the i-th data",
    "start": "2918010",
    "end": "2927190"
  },
  {
    "text": "point, and then, until\nyou can no longer improve, you find some local optimum.",
    "start": "2927190",
    "end": "2935290"
  },
  {
    "text": "And then you can take a step\non the theta parameters so",
    "start": "2935290",
    "end": "2940330"
  },
  {
    "text": "your actual decoder,\nthe actual VAE model that you use for\ngenerating data given",
    "start": "2940330",
    "end": "2946630"
  },
  {
    "text": "the best possible lower bound. So this inner loop will find\nyou the best lower bound.",
    "start": "2946630",
    "end": "2952090"
  },
  {
    "text": "This step 4 will take a step\non that optimal lower bound.",
    "start": "2952090",
    "end": "2960100"
  },
  {
    "text": "Why do we get rid of the H\n[INAUDIBLE] from line 1 to 2? ",
    "start": "2960100",
    "end": "2965460"
  },
  {
    "text": "Oh, I'm just expanding it. So the H is the entropy,\nwhich is the expected log",
    "start": "2965460",
    "end": "2970720"
  },
  {
    "text": "probability under q. ",
    "start": "2970720",
    "end": "2976540"
  },
  {
    "text": "This is not quite going to be\nthe way we were going to train a variational autoencoder.",
    "start": "2976540",
    "end": "2982180"
  },
  {
    "text": "It turns out that\nit's actually better to keep theta and\nphi in sync, but you",
    "start": "2982180",
    "end": "2987760"
  },
  {
    "text": "can imagine that a\nstrategy like this could actually work as an\noptimization objective.",
    "start": "2987760",
    "end": "2995230"
  },
  {
    "text": "How computationally\nefficient is it going to be? It seems each\noptimization step is going",
    "start": "2995230",
    "end": "3001080"
  },
  {
    "text": "to take a lot of iteration. Yeah, so how efficient it is? Well, first of all, we'll\nsee that the first challenge",
    "start": "3001080",
    "end": "3007230"
  },
  {
    "text": "is to figure out even how\nto compute these gradients. These gradients are going to\nbe not too expensive, luckily,",
    "start": "3007230",
    "end": "3014250"
  },
  {
    "text": "as we'll see. But there is a question of,\nshould you take more steps",
    "start": "3014250",
    "end": "3019290"
  },
  {
    "text": "on phi, less steps on theta? Should you do one step\non theta, one on phi?",
    "start": "3019290",
    "end": "3024780"
  },
  {
    "text": "There is many strategies\nthat you can use, and it's not even known\nactually what's the best one.",
    "start": "3024780",
    "end": "3030030"
  },
  {
    "text": "This is one that is reasonable. It's more like a coordinate\nascent procedure.",
    "start": "3030030",
    "end": "3035190"
  },
  {
    "text": "You find the best theta,\nyou find the optimal phi, and then you optimize\ntheta a little bit.",
    "start": "3035190",
    "end": "3042490"
  },
  {
    "text": "So the reason why\nI understand we need parameters\nper data point is",
    "start": "3042490",
    "end": "3048760"
  },
  {
    "text": "because in the\nreal distribution, the best lower bound is\nby actually [INAUDIBLE]",
    "start": "3048760",
    "end": "3055330"
  },
  {
    "text": "on x or z given x. And over here, since\nwe're not seeing x,",
    "start": "3055330",
    "end": "3061090"
  },
  {
    "text": "we need one [INAUDIBLE] like\nparameters p of z also on x? Yeah, yeah.",
    "start": "3061090",
    "end": "3066760"
  },
  {
    "text": "So that's going to be\nthe way we're going to make things more scalable. It's called amortized inference. There's going to be how we\nmove from this vanilla version",
    "start": "3066760",
    "end": "3073930"
  },
  {
    "text": "to something that\nis going to be worse from the perspective\nof the bound you get. But it's going to be more\nscalable because there is not",
    "start": "3073930",
    "end": "3080260"
  },
  {
    "text": "going to be one optimization\nparameter per data point. We're basically going to do\nexactly what you suggested.",
    "start": "3080260",
    "end": "3086800"
  },
  {
    "text": "We're going to have\na tie together. We're going to have a single q\nthat is supposed to work well",
    "start": "3086800",
    "end": "3091960"
  },
  {
    "text": "across different x's. There is going to be a neural\nnetwork that will essentially try to guess this phi i\nstar as a function of x.",
    "start": "3091960",
    "end": "3100765"
  },
  {
    "text": " I think it's better\nto understand it",
    "start": "3100765",
    "end": "3108550"
  },
  {
    "text": "through the lenses of,\nOK, first you optimize, and then you try\nto approximate it. But that's going to be the--\nhow a VAE is actually trained",
    "start": "3108550",
    "end": "3115210"
  },
  {
    "text": "is basically going to be a\nseparate neural network that will take xi as an\ninput and will produce",
    "start": "3115210",
    "end": "3121000"
  },
  {
    "text": "a guess for this phi i\nstar, the optimal choice of variational parameters for\nthat data point, as an output,",
    "start": "3121000",
    "end": "3128060"
  },
  {
    "text": "and that's going to be\nthe encoder of the VAE. So as you said, we can\nuse a neural network",
    "start": "3128060",
    "end": "3135160"
  },
  {
    "text": "to guess the i, right? The phi i. So without using\na neural network,",
    "start": "3135160",
    "end": "3142255"
  },
  {
    "text": "how would we choose as the-- So without the neural\nnetwork, you can do this.",
    "start": "3142255",
    "end": "3148892"
  },
  {
    "text": "And it's actually going to\nwork better than whatever you can get with\nthe neural network because you're optimizing over--",
    "start": "3148893",
    "end": "3154720"
  },
  {
    "text": "you have less\nconstraints, right? Like what was said before\nabout, let's make you",
    "start": "3154720",
    "end": "3159940"
  },
  {
    "text": "more as expressive as possible. This is going to be better. But it's just going to be slower\nand not going to be scalable.",
    "start": "3159940",
    "end": "3167530"
  },
  {
    "text": "But if you can\nafford to do this, is going to be better basically.",
    "start": "3167530",
    "end": "3173320"
  },
  {
    "text": "You said that, previously,\na good choice of phi i would probably be close\nto the top half of pixels",
    "start": "3173320",
    "end": "3179320"
  },
  {
    "text": "of a number 9 or something. But if we don't choose\nthe phi i's carefully, are we going to get\nstuck into local optimum",
    "start": "3179320",
    "end": "3187059"
  },
  {
    "text": "and where you will\njust not get out of? Is it what's going to happen? Yeah, that's a problem.",
    "start": "3187060",
    "end": "3192278"
  },
  {
    "text": "Yeah, because here we're\njointly optimizing these two and hoping that we\ncan find something.",
    "start": "3192278",
    "end": "3198820"
  },
  {
    "text": "But you can imagine [INAUDIBLE]\nthat if the choice of phi is really bad,\ninitially, at least,",
    "start": "3198820",
    "end": "3204130"
  },
  {
    "text": "it's probably going to\nbe random or something. And so they're going to be doing\na very good bad job at guessing",
    "start": "3204130",
    "end": "3210430"
  },
  {
    "text": "the latent variables. And so you might not be able\nto actually optimize the theta.",
    "start": "3210430",
    "end": "3215540"
  },
  {
    "text": "And so you might get stuck into\nto a very bad local optimum. And this is non-convex,\nso you have no guarantee",
    "start": "3215540",
    "end": "3223150"
  },
  {
    "text": "in terms of being able\nto find a good solution for this optimization problem.",
    "start": "3223150",
    "end": "3229370"
  },
  {
    "text": "And so those issues,\nindeed, we have them here. And you have to hope that\ngradient ascent will find you",
    "start": "3229370",
    "end": "3237790"
  },
  {
    "text": "a good solution. But you could\ncertainly get stuck. ",
    "start": "3237790",
    "end": "3246860"
  },
  {
    "text": "Cool. So that's,\nconceptually at least, a good way to\nthink about how you",
    "start": "3246860",
    "end": "3252950"
  },
  {
    "text": "would train a model like this. And the part that\nis still not obvious",
    "start": "3252950",
    "end": "3259430"
  },
  {
    "text": "is how you compute\nthese gradients. How do you compute the\ngradients with respect to theta?",
    "start": "3259430",
    "end": "3267130"
  },
  {
    "text": "So we need two gradients. We need a step 3-1 within\nthe gradient with respect to the variational parameters.",
    "start": "3267130",
    "end": "3273060"
  },
  {
    "text": "And at step 4, we need\nthe gradients with respect to the model, the\nactual decoder,",
    "start": "3273060",
    "end": "3279420"
  },
  {
    "text": "the actual neural networks\nthat define the VAE.",
    "start": "3279420",
    "end": "3285970"
  },
  {
    "text": "And these are expectations\nfor which we don't know-- now you cannot compute\nthem in closed form.",
    "start": "3285970",
    "end": "3292750"
  },
  {
    "text": "There is no analytic\nexpression that you can use to compute the\nexpectation and then",
    "start": "3292750",
    "end": "3299710"
  },
  {
    "text": "the gradients of, so we\nhave to basically rely on Monte Carlo sampling. We're going to approximate\nthese expectations",
    "start": "3299710",
    "end": "3306670"
  },
  {
    "text": "with sample averages. And so what would it look like?",
    "start": "3306670",
    "end": "3314650"
  },
  {
    "text": "If you want to approximate these\nexpectation with respect to q, we can just do this.",
    "start": "3314650",
    "end": "3320990"
  },
  {
    "text": "We can just sample a\nbunch of draws from q, and then approximate\nthe expectation",
    "start": "3320990",
    "end": "3327970"
  },
  {
    "text": "with a sample average. The usual trick, an\nexpectation with respect to q",
    "start": "3327970",
    "end": "3333340"
  },
  {
    "text": "is approximately equal\nto the sample average, if you were to sample the\nlatent variables according",
    "start": "3333340",
    "end": "3338440"
  },
  {
    "text": "to this proposal distribution q. And as usual, the larger\nK is, the more accurate",
    "start": "3338440",
    "end": "3348350"
  },
  {
    "text": "this approximation\nis going to be. In practice, when\nyou train a VAE, you probably choose k\nequals 1, and you would just",
    "start": "3348350",
    "end": "3355040"
  },
  {
    "text": "use a single sample. But in general,\nyou could use more if you wanted more accurate\nestimates of the expectation.",
    "start": "3355040",
    "end": "3363350"
  },
  {
    "text": "And the key assumption here\nis that q has to be simple.",
    "start": "3363350",
    "end": "3369060"
  },
  {
    "text": "You can't choose\nsomething very complicated because you need to be able\nto sample from it efficiently,",
    "start": "3369060",
    "end": "3374599"
  },
  {
    "text": "and you need to be able\nto evaluate probabilities under q efficiently.",
    "start": "3374600",
    "end": "3382230"
  },
  {
    "text": "When I asked a question about\nthe q 10 minutes ago, you said, can be something\nmuch more complex.",
    "start": "3382230",
    "end": "3387910"
  },
  {
    "text": "How do they do it? Yeah, so it has to be complex. But still it has to be a model\nfor which you can evaluate",
    "start": "3387910",
    "end": "3394020"
  },
  {
    "text": "probabilities efficiently\nand you have to sample from efficiently. So a VAE, for example, would not\nbe a good choice because you can",
    "start": "3394020",
    "end": "3399840"
  },
  {
    "text": "sample from it efficiently\nbut you cannot evaluate probabilities efficiently. An autoregressive model would\nbe a reasonable maybe choice",
    "start": "3399840",
    "end": "3408210"
  },
  {
    "text": "because you can\nsample efficiently, and you can evaluate\nprobabilities. But we will see generative\nadversarial networks will not be",
    "start": "3408210",
    "end": "3415740"
  },
  {
    "text": "a good choice because\nit's easy to sample from, but you cannot\nevaluate probabilities. We will see something\ncalled a flow model, which",
    "start": "3415740",
    "end": "3422550"
  },
  {
    "text": "is a class of generative\nmodels where you can sample from efficiently,\nand you can evaluate probabilities efficiently.",
    "start": "3422550",
    "end": "3427920"
  },
  {
    "text": "That's a good choice. That's what people\nactually use in practice. So those are the\ntwo constraints. Sample efficiently, evaluate\nprobabilities efficiently.",
    "start": "3427920",
    "end": "3435468"
  },
  {
    "text": " And then we want to compute\ngradients of this quantity,",
    "start": "3435468",
    "end": "3440740"
  },
  {
    "text": "right? We want to compute\ngradients with respect to theta and with\nrespect to phi.",
    "start": "3440740",
    "end": "3445895"
  },
  {
    "text": "And the gradients\nwith respect to theta are trivial because, basically,\nthe gradient of the expectation",
    "start": "3445895",
    "end": "3454005"
  },
  {
    "text": "is just going to\nbe approximately equal to the gradient of the\nsample average essentially.",
    "start": "3454005",
    "end": "3460450"
  },
  {
    "text": "So if the gradient is just\nlinear, you can push it inside. The q part does not\ndepend on theta.",
    "start": "3460450",
    "end": "3467630"
  },
  {
    "text": "So the gradient with respect\nto theta of this part is 0. So you can, basically,\njust take your samples,",
    "start": "3467630",
    "end": "3475390"
  },
  {
    "text": "evaluate the gradients of the\nlog probability with respect to theta, which is-- and\nthis is fully observed,",
    "start": "3475390",
    "end": "3481430"
  },
  {
    "text": "so this would be exactly\nthe same gradient as in an autoregressive model. You have the z part,\nyou have the x part,",
    "start": "3481430",
    "end": "3487450"
  },
  {
    "text": "so you know how to evaluate\nthese probabilities and you just take gradients\nand you just update",
    "start": "3487450",
    "end": "3492549"
  },
  {
    "text": "your theta parameters that way. So this part is very easy.",
    "start": "3492550",
    "end": "3498490"
  },
  {
    "text": "The tricky part is the\ngradients with respect to phi. And the reason is that you are\nsampling from a distribution",
    "start": "3498490",
    "end": "3506700"
  },
  {
    "text": "that depends on phi. And so if you want to\nfigure out how should I change my variational parameters\nphi to make this expectation as",
    "start": "3506700",
    "end": "3516600"
  },
  {
    "text": "large as possible,\nyou need to be able to understand\nhow the change in phi",
    "start": "3516600",
    "end": "3525150"
  },
  {
    "text": "change where the samples\nland essentially. You are sampling from\nthis distribution,",
    "start": "3525150",
    "end": "3531015"
  },
  {
    "text": "which depends on phi. And so you need to be\nable to understand, if I were to make a\nsmall change to phi,",
    "start": "3531015",
    "end": "3536089"
  },
  {
    "text": "how would my samples change? And if you take gradients\nwith respect to theta,",
    "start": "3536090",
    "end": "3541150"
  },
  {
    "text": "you don't have to worry about\nit because the samples-- you're not sampling\nfrom a distribution that depends on theta,\nso you don't have",
    "start": "3541150",
    "end": "3547660"
  },
  {
    "text": "to worry about how the samples\nthemselves would change if you were to change phi. But if you're\nchanging phi, then you",
    "start": "3547660",
    "end": "3553900"
  },
  {
    "text": "need to understand how your\nsampling procedure here depends on phi.",
    "start": "3553900",
    "end": "3560230"
  },
  {
    "text": "And so the gradient is not\ngoing to be as easy as this one. ",
    "start": "3560230",
    "end": "3567120"
  },
  {
    "text": "And that's essentially\nthe problem. The problem is\nthat you're taking",
    "start": "3567120",
    "end": "3572520"
  },
  {
    "text": "an expectation with respect\nto a distribution that depends on phi. So if you want to\ntake gradients,",
    "start": "3572520",
    "end": "3577950"
  },
  {
    "text": "you need to understand how\nthe sampling process basically is affected by small changes\nin the variational parameters,",
    "start": "3577950",
    "end": "3586260"
  },
  {
    "text": "and that's more tricky. And because we would\nstill like to do it",
    "start": "3586260",
    "end": "3591450"
  },
  {
    "text": "through some efficient Monte\nCarlo thing, where you just sample once and then you compute\nsome gradient through autodiff",
    "start": "3591450",
    "end": "3598080"
  },
  {
    "text": "and you're done. And it's not super obvious\nhow you would do this. And there is different\nways of doing it.",
    "start": "3598080",
    "end": "3604860"
  },
  {
    "text": "Later on, we'll see a\ntechnique called REINFORCE from reinforcement learning.",
    "start": "3604860",
    "end": "3610590"
  },
  {
    "text": "Because you can think of this\nas a reinforcement learning problem, where you're--",
    "start": "3610590",
    "end": "3616770"
  },
  {
    "text": "if you think of z\nas being an action, you're trying to\nfigure out your policy, you're trying to figure out how\nyou should change your policy",
    "start": "3616770",
    "end": "3623880"
  },
  {
    "text": "to perform well where the\nargument of the expectation is the reward that tells\nyou how well you're doing.",
    "start": "3623880",
    "end": "3630599"
  },
  {
    "text": "And it's tricky to figure\nout how changing your policy affects the value\nthat you're getting.",
    "start": "3630600",
    "end": "3636368"
  },
  {
    "text": "But there are techniques\nfrom reinforcement learning that you could use. Today was just simpler--",
    "start": "3636368",
    "end": "3642119"
  },
  {
    "text": "actually, better way\nof doing things that does not work in general. It only works for\ncertain choices of q.",
    "start": "3642120",
    "end": "3650390"
  },
  {
    "text": "For example, when q is Gaussian,\nyou can use this trick. And it's more\nefficient in the sense",
    "start": "3650390",
    "end": "3656990"
  },
  {
    "text": "that if it has lower variance,\nit's a better estimate.",
    "start": "3656990",
    "end": "3662330"
  },
  {
    "text": "And this technique, it's called\nthe reparameterization trick. It only works when these latent\nvariables z are continuous.",
    "start": "3662330",
    "end": "3671220"
  },
  {
    "text": "So it doesn't work when you\nhave discrete latent variables. Only works when z is\ncontinuous, like when",
    "start": "3671220",
    "end": "3679190"
  },
  {
    "text": "z is a Gaussian, for example. And so that this\nexpectation is not a sum",
    "start": "3679190",
    "end": "3685460"
  },
  {
    "text": "but it's really an integral. So it's an integral with respect\nto this probability density",
    "start": "3685460",
    "end": "3693260"
  },
  {
    "text": "function q, which\ndepends on phi, of some quantity which\nI'm going to denote r.",
    "start": "3693260",
    "end": "3699230"
  },
  {
    "text": "r because it's like a reward. But r of z is just, basically,\nthe argument of the expectation.",
    "start": "3699230",
    "end": "3705529"
  },
  {
    "text": "I'm just changing the\nnotation to make it a little bit more compact. But essentially, the argument\ndoesn't matter too much.",
    "start": "3705530",
    "end": "3713450"
  },
  {
    "text": "The tricky part is\nto figure out how to change phi so that the\nexpectation becomes as",
    "start": "3713450",
    "end": "3719330"
  },
  {
    "text": "large as possible essentially. And again, you\nsee the connection with reinforcement learning.",
    "start": "3719330",
    "end": "3725850"
  },
  {
    "text": "If z are actions, then\nyou're trying to say-- you have a stochastic\npolicy for choosing actions,",
    "start": "3725850",
    "end": "3732720"
  },
  {
    "text": "and different actions\nhave different rewards. You're asking, how\nshould I choose actions",
    "start": "3732720",
    "end": "3739470"
  },
  {
    "text": "in a stochastic way so that I\nget the highest possible reward? And you need to understand\nhow changing phi changes which",
    "start": "3739470",
    "end": "3747060"
  },
  {
    "text": "actions you pick, which z's\nare more likely and less likely under your policy,\nwhich is a little bit tricky.",
    "start": "3747060",
    "end": "3755650"
  },
  {
    "text": "The good thing is that if,\nagain, q has certain properties,",
    "start": "3755650",
    "end": "3762480"
  },
  {
    "text": "for example, it's\nGaussian, then there is two ways of sampling from q.",
    "start": "3762480",
    "end": "3768839"
  },
  {
    "text": "You could sample\nfrom q directly, or you could sample from\na Gaussian random variable",
    "start": "3768840",
    "end": "3778559"
  },
  {
    "text": "with mean 0 and\ncovariance the identity, and shift and rescale it. ",
    "start": "3778560",
    "end": "3786400"
  },
  {
    "text": "Right? So if you want to\nsample from a Gaussian with mean mu and covariance\nsigma squared the identity,",
    "start": "3786400",
    "end": "3794880"
  },
  {
    "text": "you could always\nachieve that by sampling from a standard normal with 0\nmean and identity covariance.",
    "start": "3794880",
    "end": "3802425"
  },
  {
    "text": "So shifting and rescaling. And what this does is\nthat we're basically",
    "start": "3802425",
    "end": "3809810"
  },
  {
    "text": "rewriting this complicated\nrandom variable z as a deterministic\ntransformation of something",
    "start": "3809810",
    "end": "3818330"
  },
  {
    "text": "simple of a standard normal\nGaussian random variable. This is why it's called the\nreparameterization trick",
    "start": "3818330",
    "end": "3825230"
  },
  {
    "text": "because we're just writing z as\na deterministic transformation",
    "start": "3825230",
    "end": "3832850"
  },
  {
    "text": "of a fixed random variable,\nwhich does not depend on the optimization parameters.",
    "start": "3832850",
    "end": "3839339"
  },
  {
    "text": "So we have some\ndeterministic transformation which depends on the\noptimization parameters, the phi",
    "start": "3839340",
    "end": "3845840"
  },
  {
    "text": "parameters, that\nwe use to transform this basic random\nvariable, epsilon, which",
    "start": "3845840",
    "end": "3852050"
  },
  {
    "text": "does not depend on phi anymore. ",
    "start": "3852050",
    "end": "3857820"
  },
  {
    "text": "And then using this\nequivalence, we can compute the\nexpectation in two ways.",
    "start": "3857820",
    "end": "3864599"
  },
  {
    "text": "You can either sample\nfrom z, sample from q, and then evaluate r at the z's\nthat you get by sampling from q.",
    "start": "3864600",
    "end": "3871700"
  },
  {
    "text": "Or you can sample from epsilon,\ntransform it through g, and evaluate r at that point.",
    "start": "3871700",
    "end": "3879589"
  },
  {
    "text": "And the key thing\nis that now we have an expectation that no longer\ndepends on the optimization",
    "start": "3879590",
    "end": "3885260"
  },
  {
    "text": "parameters phi. Now it's an expectation\nwith respect to epsilon, and so we can basically\npush the gradient inside,",
    "start": "3885260",
    "end": "3892040"
  },
  {
    "text": "just like what we\nwere doing before. Or in other words,\nbasically, we understand how changing the parameters\naffects the kind of samples",
    "start": "3892040",
    "end": "3901390"
  },
  {
    "text": "that we get because we're\nexplicitly writing down the sampling procedure as a\ndeterministic transformation",
    "start": "3901390",
    "end": "3907630"
  },
  {
    "text": "of some simple fixed\nrandom variable. So if you want to figure out\nhow would my performance change",
    "start": "3907630",
    "end": "3916270"
  },
  {
    "text": "if I were to change phi by a\nlittle bit, which is essentially the gradient, now\nyou know exactly how",
    "start": "3916270",
    "end": "3923140"
  },
  {
    "text": "your samples would\nchange because you have a deterministic\ntransformation that gives you the new samples as\na function of phi.",
    "start": "3923140",
    "end": "3928762"
  },
  {
    "text": "And so taking the\ngradient of that would tell you how the samples\nwould change by changing phi",
    "start": "3928762",
    "end": "3934180"
  },
  {
    "text": "by a little bit. And so once you have\nthis expression,",
    "start": "3934180",
    "end": "3939810"
  },
  {
    "text": "or you have an\nexpectation with respect to a quantity that no\nlonger depends on phi,",
    "start": "3939810",
    "end": "3945150"
  },
  {
    "text": "we're basically in a\ngood shape because we can compute this gradient\nwith respect to phi.",
    "start": "3945150",
    "end": "3951360"
  },
  {
    "text": "So here, this one would\nbe a little bit tricky because you have an expectation\nwhich depends on phi, and we don't know\nhow to do this.",
    "start": "3951360",
    "end": "3957359"
  },
  {
    "text": "But the expectation on the\nright is the kind of thing we know how to handle because\nit's an expectation with respect",
    "start": "3957360",
    "end": "3962580"
  },
  {
    "text": "to epsilon, which no\nlonger depends on phi, and then we can basically\npush the gradient inside.",
    "start": "3962580",
    "end": "3970680"
  },
  {
    "text": "Yeah? Is r just an arbitrary\nfunction here? r is an arbitrary function. Yes. ",
    "start": "3970680",
    "end": "3978890"
  },
  {
    "text": "And this is something we can\ndo by Monte Carlo, basically. All you do is you sample\nepsilon, or a bunch of epsilons,",
    "start": "3978890",
    "end": "3987800"
  },
  {
    "text": "and then you approximate the\nexpectation of the gradient with the sample average\nof the quantity.",
    "start": "3987800",
    "end": "3996200"
  },
  {
    "text": "And basically by chain\nrule, you can figure out",
    "start": "3996200",
    "end": "4001900"
  },
  {
    "text": "what would be the\neffect of changing phi [? B ?] on this expectation\nthat you care about.",
    "start": "4001900",
    "end": "4010329"
  },
  {
    "text": "Because you know\nthat, basically, just by computing\nthese gradients,",
    "start": "4010330",
    "end": "4015850"
  },
  {
    "text": "you get what you want. You know how this epsilon\nwould be transformed, and then you know what is\nthe corresponding reward, r,",
    "start": "4015850",
    "end": "4024168"
  },
  {
    "text": "that you would get if\nyou were to transform the sample in a certain way. And so you know how you\nshould adjust your parameters",
    "start": "4024168",
    "end": "4030220"
  },
  {
    "text": "to maximize the reward\nas much as you can because you know exactly\nhow changing phi affects",
    "start": "4030220",
    "end": "4037670"
  },
  {
    "text": "the sampling procedure. Yeah? I'm curious about the\ncontinuity of the z part",
    "start": "4037670",
    "end": "4044480"
  },
  {
    "text": "requirement for this. What if you had z that\nwas, I don't know, from 1, 2, 3, 4, 5,\n6, then you modeled it",
    "start": "4044480",
    "end": "4052190"
  },
  {
    "text": "with a uniform distribution,\nand you either floor or put a ceiling function to it. Was it--",
    "start": "4052190",
    "end": "4058130"
  },
  {
    "text": "So it doesn't work for\ndiscrete random variables. If you have that\nkind of setting--",
    "start": "4058130",
    "end": "4063859"
  },
  {
    "text": "and it doesn't even work for\nall continuous distributions. You have to be able to\nwrite the sampling procedure",
    "start": "4063860",
    "end": "4070040"
  },
  {
    "text": "as some kind of\ndeterministic transformation of some basic distribution that\nyou know how to sample from.",
    "start": "4070040",
    "end": "4076430"
  },
  {
    "text": "If you can do that,\nthen this machinery, you can see it goes through. But if you have something like\na discrete, like categorically",
    "start": "4076430",
    "end": "4084920"
  },
  {
    "text": "random variable, then it\nwould be discontinuous. And at that point,\nyou don't know.",
    "start": "4084920",
    "end": "4090080"
  },
  {
    "text": "You can always sample it by\ninverting the CDF, essentially, but you would not be able to get\ngradients through, essentially.",
    "start": "4090080",
    "end": "4097009"
  },
  {
    "text": "So for that, you either\nneed to use REINFORCE or we'll talk about other\nways to relax the optimization",
    "start": "4097010",
    "end": "4102568"
  },
  {
    "text": "problem when dealing\nwith these things. But this is only applicable to\nspecial cases like a Gaussian,",
    "start": "4102569",
    "end": "4108759"
  },
  {
    "text": "which luckily, is what\npeople often use in practice. And so this is actually a good\nsolution when you can use it.",
    "start": "4108760",
    "end": "4114479"
  },
  {
    "start": "4114479",
    "end": "4120189"
  },
  {
    "text": "OK. So now, we're\nbasically almost there.",
    "start": "4120189",
    "end": "4125350"
  },
  {
    "text": "Recall that what\nwe wanted to was to compute the gradient of\nthis ELBO, which is just",
    "start": "4125350",
    "end": "4131229"
  },
  {
    "text": "an expectation with respect\nto q of some arbitrary function, which happens\nto depend on phi,",
    "start": "4131229",
    "end": "4137630"
  },
  {
    "text": "which is a little bit annoying. Because before we had this r,\nwhich was not depending on phi.",
    "start": "4137630",
    "end": "4145389"
  },
  {
    "text": "Now the argument of the\nexpectation also depends on phi. But you can see that you can\nstill use reparameterization.",
    "start": "4145390",
    "end": "4155589"
  },
  {
    "text": "Just like before,\nas long as you know how to write down the\nsampling procedure",
    "start": "4155590",
    "end": "4161620"
  },
  {
    "text": "in a differentiable\nway, then you just have the argument of\nthe expectation that",
    "start": "4161620",
    "end": "4171990"
  },
  {
    "text": "depends on phi in two ways. And then you just do chain\nrule would-- basically",
    "start": "4171990",
    "end": "4177359"
  },
  {
    "text": "autodiff will take care\nof the gradient for you. So that's actually not an issue.",
    "start": "4177359",
    "end": "4184359"
  },
  {
    "text": "Essentially, you use\nthe same machinery for this reward function,\nwhich now depends on phi.",
    "start": "4184359",
    "end": "4190479"
  },
  {
    "text": "But essentially, the same\nmachinery goes through. ",
    "start": "4190479",
    "end": "4197719"
  },
  {
    "text": "OK. Now we know, essentially,\nhow to do this. We know how to\ncompute the gradients.",
    "start": "4197720",
    "end": "4202880"
  },
  {
    "text": "The only other annoying\npiece is that we have one variational\nparameter per data point.",
    "start": "4202880",
    "end": "4209300"
  },
  {
    "text": "So it would be expensive to have\ndifferent variational parameters",
    "start": "4209300",
    "end": "4215079"
  },
  {
    "text": "per data point, especially if\nyou have a very large data set. And so the other\nmissing piece is",
    "start": "4215080",
    "end": "4222789"
  },
  {
    "text": "to have what's called as\namortization, which basically means that we're not going to\ntry to separately optimize over",
    "start": "4222790",
    "end": "4231820"
  },
  {
    "text": "all these phis. Instead we're going to have\na single set of parameters,",
    "start": "4231820",
    "end": "4237440"
  },
  {
    "text": "which is going to be\nanother neural network. It's going to be the encoder\nof the VAE, which we're",
    "start": "4237440",
    "end": "4242860"
  },
  {
    "text": "going to denote as f lambda. And this function\nis going to try to guess a good choice of\nvariational parameters.",
    "start": "4242860",
    "end": "4251600"
  },
  {
    "text": "So he's going to try to\nsomehow do regression on this mapping between xi\nand the optimal variational",
    "start": "4251600",
    "end": "4257390"
  },
  {
    "text": "parameters. He's going to try\nto guess what's a good way of approximating\nthe posterior for the i-th data",
    "start": "4257390",
    "end": "4262770"
  },
  {
    "text": "point.  And this is much more\nscalable because we",
    "start": "4262770",
    "end": "4267920"
  },
  {
    "text": "have a fixed number\nof parameters now that we're trying to optimize. We have the theta, and\nwe have the encoder.",
    "start": "4267920",
    "end": "4277639"
  },
  {
    "text": "Again, so let's say\nthe q's are Gaussians. Instead of having one different\nmean vector per data point,",
    "start": "4277640",
    "end": "4284000"
  },
  {
    "text": "you have a single\nneural network that will try to guess what's\nthe mean of the Gaussian as a function of x, as\na function of the data",
    "start": "4284000",
    "end": "4292040"
  },
  {
    "text": "point, the observed values that\nyou see in each data point. And now, we approximate\nthis posterior distribution,",
    "start": "4292040",
    "end": "4302380"
  },
  {
    "text": "given that the observed\nvalue is for the i-th data point using this distribution.",
    "start": "4302380",
    "end": "4309470"
  },
  {
    "text": "So we take xi, we pass it\nthrough this neural network that will guess the\nvariational parameters,",
    "start": "4309470",
    "end": "4316119"
  },
  {
    "text": "and then that's going to be\nthe q that we use in the ELBO. And the same\ngradient computation",
    "start": "4316120",
    "end": "4322810"
  },
  {
    "text": "goes through, as long as the\nreparameterization works.",
    "start": "4322810",
    "end": "4328370"
  },
  {
    "text": "You can see that the same\nmachinery applies here. We are clearly losing\na bit of our ability",
    "start": "4328370",
    "end": "4337240"
  },
  {
    "text": "to model the data\nset by doing this. So is it worth to\ndo this trade-off?",
    "start": "4337240",
    "end": "4344980"
  },
  {
    "text": "What if we just trained\non a hundred examples with a single phi for each,\nrather than doing this?",
    "start": "4344980",
    "end": "4351760"
  },
  {
    "text": "What's the trade-off there? The trade-off in that case, like\nyou're going to get a better-- I mean, to the extent that you\ncan do the optimization well--",
    "start": "4351760",
    "end": "4358790"
  },
  {
    "text": "because it's non-convex, so\nweird things could happen. But to the extent\nthat you can optimize, you would get a better\naverage log likelihood.",
    "start": "4358790",
    "end": "4369000"
  },
  {
    "text": "So it's going to be more\nexpensive because you have more variational\nparameters to optimize over.",
    "start": "4369000",
    "end": "4374450"
  },
  {
    "text": "You're also going to\ngive up on the fact that if I give you a\nnew test data point and you want to evaluate the\nlikelihood of that test data",
    "start": "4374450",
    "end": "4380660"
  },
  {
    "text": "point, you would have to\nsolve an optimization problem and try to find variational\nparameters for that data point.",
    "start": "4380660",
    "end": "4387080"
  },
  {
    "text": "If you have this\nneural network that is already trained to give\ngood variational parameters,",
    "start": "4387080",
    "end": "4392780"
  },
  {
    "text": "you have no cost. So it's all amortized. So it's called amortized\nbecause, essentially, there",
    "start": "4392780",
    "end": "4399140"
  },
  {
    "text": "is a neural network\nthat is amortizing the cost of solving this\noptimization problem",
    "start": "4399140",
    "end": "4404210"
  },
  {
    "text": "or variational parameters. And the problem of solving\nthe optimization problem",
    "start": "4404210",
    "end": "4409940"
  },
  {
    "text": "and give you the optimal\nvariational parameters is amortized by a\nsingle feedforward pass",
    "start": "4409940",
    "end": "4415429"
  },
  {
    "text": "through this neural network. If you are learning the\nseparate phi i's, how would that",
    "start": "4415430",
    "end": "4421510"
  },
  {
    "text": "generalize to a new data\n[INAUDIBLE] anyways because you don't know the\ncipher [INAUDIBLE]----",
    "start": "4421510",
    "end": "4427750"
  },
  {
    "text": "Yeah, so if we generalize in the\nsense that you would have a p, and you could try to evaluate--",
    "start": "4427750",
    "end": "4435369"
  },
  {
    "text": "it defines a valid\nlikelihood on any x.  Optimizing through an encoder\nmight have a regularization",
    "start": "4435370",
    "end": "4443770"
  },
  {
    "text": "effect, in the sense\nthat it's constraining p. Because you're jointly\noptimizing p and q,",
    "start": "4443770",
    "end": "4450280"
  },
  {
    "text": "so you could say\nthat, OK, you're optimizing phi to try to make\nthe approximate posterior close to the true posterior.",
    "start": "4450280",
    "end": "4456550"
  },
  {
    "text": "But you're also optimizing\nthe true posterior to be close to one that\nyou can approximate with",
    "start": "4456550",
    "end": "4462370"
  },
  {
    "text": "your little neural network. And so it has a regularization\neffect over the generative model",
    "start": "4462370",
    "end": "4469450"
  },
  {
    "text": "that you learn because it has to\nbe a generative model on which you can do inference\nrelatively well",
    "start": "4469450",
    "end": "4475600"
  },
  {
    "text": "using this single neural\nnetwork that we have here. So as you said,\nthat might help you",
    "start": "4475600",
    "end": "4481930"
  },
  {
    "text": "in terms of log likelihood\non a new data point because the model\nis more constrained, and so it might perform well.",
    "start": "4481930",
    "end": "4487930"
  },
  {
    "text": "It prevents overfitting\nto some extent. But I guess-- let's\nsay you have a hundred",
    "start": "4487930",
    "end": "4492970"
  },
  {
    "text": "phis that you've learned. For the past data point, you\nlearn a new phi altogether. You try to figure out\nwhich of the hundred phis",
    "start": "4492970",
    "end": "4499540"
  },
  {
    "text": "you already have\nbest represents-- You could do both. If you wanted to get the best\napproximation to the likelihood",
    "start": "4499540",
    "end": "4505390"
  },
  {
    "text": "on a new test data point,\nyou would optimize a new phi, and that would give you the\nbest lower bound on the ELBO",
    "start": "4505390",
    "end": "4512200"
  },
  {
    "text": "for that data point. That would be the best.",
    "start": "4512200",
    "end": "4517315"
  },
  {
    "text": "The marginal likelihood\nis defined regardless of how you choose the phis. And so the phi is just\na computational thing",
    "start": "4517315",
    "end": "4527410"
  },
  {
    "text": "that you need in order to\nevaluate the likelihoods. But if you just care\nabout generation, you don't even need the phis.",
    "start": "4527410",
    "end": "4534550"
  },
  {
    "text": "How many phis would\nbe sufficient to train a good parametric function?",
    "start": "4534550",
    "end": "4540340"
  },
  {
    "text": "How many phis? In practice, what\nyou would do is you would have a single neural\nnetwork that would essentially",
    "start": "4540340",
    "end": "4546130"
  },
  {
    "text": "guess the optimal phis as a\nfunction of the data points. And these neural networks are\ntypically relatively shallow.",
    "start": "4546130",
    "end": "4553780"
  },
  {
    "text": "So you wouldn't need that many\nphis to train that network? You don't actually\never get the phis.",
    "start": "4553780",
    "end": "4560080"
  },
  {
    "text": "So what you do is\nyou just optimize the ELBO as a function\nof this, let's",
    "start": "4560080",
    "end": "4565420"
  },
  {
    "text": "say, lambda parameters here. And so you just back-- I see. I see. And so you never actually\ncompute this phi stars.",
    "start": "4565420",
    "end": "4573940"
  },
  {
    "text": "You just restrict\nyourself to the phis that can be produced by\nthis single neural network.",
    "start": "4573940",
    "end": "4580660"
  },
  {
    "text": "But do we need to set\nthe dimensions of phi to be our hyperparameters? Yeah, so the dimension of phi\nand the family that you choose,",
    "start": "4580660",
    "end": "4588250"
  },
  {
    "text": "is it a Gaussian? Is it a Pois-- whatever\nvariational family?",
    "start": "4588250",
    "end": "4593480"
  },
  {
    "text": "That's a choice,\nthe modeling choice. So, yeah.",
    "start": "4593480",
    "end": "4599060"
  },
  {
    "text": "Yeah? So now, do we train lambda,\nphi, and theta jointly all at the same time with this?",
    "start": "4599060",
    "end": "4605610"
  },
  {
    "text": "So in this setting, I guess-- I don't know if I have it here. But essentially, you\nwouldn't even have the phis.",
    "start": "4605610",
    "end": "4613490"
  },
  {
    "text": "You would just have the\ntheta and the lambda and then everything. Yeah.",
    "start": "4613490",
    "end": "4620570"
  },
  {
    "text": "And so, let's see. What do I have here? Yeah. So essentially,\nagain, this is saying",
    "start": "4620570",
    "end": "4627830"
  },
  {
    "text": "what we were discussing before\nthat for different data points, there is going to be different\noptimal variational parameters.",
    "start": "4627830",
    "end": "4636080"
  },
  {
    "text": "And then you have\nthis single map that will take xi as an\ninput, and will output",
    "start": "4636080",
    "end": "4642110"
  },
  {
    "text": "a good choice of variational\nparameters for that xi that you're going to\nuse to infer the latent",
    "start": "4642110",
    "end": "4647630"
  },
  {
    "text": "variables for that data point. So there is not even going\nto be any phis anymore. There's going to be a single\nneural network, f lambda,",
    "start": "4647630",
    "end": "4654679"
  },
  {
    "text": "that does the work for you. And in the VAE language,\nthat's often denoted q phi of z",
    "start": "4654680",
    "end": "4664190"
  },
  {
    "text": "given x, meaning that the choice\nof variational distribution that you use is a\nfunction of x and phi.",
    "start": "4664190",
    "end": "4673770"
  },
  {
    "text": "And their relationship\nis determined by this neural\nnetwork, which is going to be the encoder in\nthe VAE that predicts",
    "start": "4673770",
    "end": "4681650"
  },
  {
    "text": "the parameters of this\nvariational distribution over the latent variables\ngiven the x variables.",
    "start": "4681650",
    "end": "4690540"
  },
  {
    "text": "So it's the same machinery\nexcept that there is less trainable\nparameters because there",
    "start": "4690540",
    "end": "4695570"
  },
  {
    "text": "is a single neural\nnetwork that will describe all this variational\ndistributions that,",
    "start": "4695570",
    "end": "4701510"
  },
  {
    "text": "in general, should be different. But just for computational\nefficiency reasons, you restrict yourself to things\nthat can be described that way.",
    "start": "4701510",
    "end": "4712250"
  },
  {
    "text": "And then basically that's\nhow you actually do things. Then you have exactly the\nELBO that we had before,",
    "start": "4712250",
    "end": "4719850"
  },
  {
    "text": "which depends on the\nparameters of the decoder and the encoder, phi. So phi here now\ndenotes the parameters",
    "start": "4719850",
    "end": "4726830"
  },
  {
    "text": "of the separate inference neural\nnetwork that takes x as an input",
    "start": "4726830",
    "end": "4732050"
  },
  {
    "text": "and produces the variational\nposterior q for that x.",
    "start": "4732050",
    "end": "4737480"
  },
  {
    "text": "And then everything\nis just optimized as a function of theta and\nphi through gradient ascent.",
    "start": "4737480",
    "end": "4745460"
  },
  {
    "text": "So you initialize the decoder\nand the encoder somehow.",
    "start": "4745460",
    "end": "4750880"
  },
  {
    "text": "And then what you would do is\nyou would randomly sample a data point, then there is going\nto be a corresponding ELBO",
    "start": "4750880",
    "end": "4758199"
  },
  {
    "text": "for that data point. And what you can\ntry to do is you can try to figure\nout how should you adjust the theta, the\ndecoder, and the encoder",
    "start": "4758200",
    "end": "4766240"
  },
  {
    "text": "to maximize the ELBO for\nthat particular data point. And this expression is just\nlike what we had before,",
    "start": "4766240",
    "end": "4772760"
  },
  {
    "text": "except that the\nvariational parameters are produced through this neural\nnetwork, which is the encoder.",
    "start": "4772760",
    "end": "4779530"
  },
  {
    "text": "And you can just backprop\nthrough that additional neural network to figure out what\nthis gradient should be.",
    "start": "4779530",
    "end": "4786040"
  },
  {
    "text": "How should you adjust the\ngradients of the encoder so that you produce variational\nparameters for the i-th data",
    "start": "4786040",
    "end": "4793030"
  },
  {
    "text": "point that perform well\nwith respect to the ELBO. And you can still use the\nreparameterization trick.",
    "start": "4793030",
    "end": "4799800"
  },
  {
    "text": "As long as q is a Gaussian,\neverything works, and then you just take steps.",
    "start": "4799800",
    "end": "4805949"
  },
  {
    "text": "And in this version, which\nis the version that people use in practice, you jointly\noptimize theta and phi",
    "start": "4805950",
    "end": "4812250"
  },
  {
    "text": "at the same time. So you try to keep\nthem in sync so that-- because we know that\nthey are related to each other,",
    "start": "4812250",
    "end": "4818800"
  },
  {
    "text": "we know that phi should\ntrack the true conditional distribution of z given x given\nthe current choice of theta.",
    "start": "4818800",
    "end": "4826780"
  },
  {
    "text": "And so as you update\ntheta, you might as well update phi, and vice versa. So it makes sense\nto just compute",
    "start": "4826780",
    "end": "4831840"
  },
  {
    "text": "a single gradient over both\nand optimize both optimization variables at the same time.",
    "start": "4831840",
    "end": "4837630"
  },
  {
    "text": " And how to compute gradients?",
    "start": "4837630",
    "end": "4843590"
  },
  {
    "text": "Again, sort of like, let's\nsay, reparameterization trick as before. And I think we're out of time.",
    "start": "4843590",
    "end": "4849679"
  },
  {
    "text": "But you can see now that\nthe autoencoder perspective q is the encoder.",
    "start": "4849680",
    "end": "4855710"
  },
  {
    "text": "It takes an image of,\nlet's say, an input, and then maps it to a mean and\na standard deviation, which",
    "start": "4855710",
    "end": "4861650"
  },
  {
    "text": "are the parameters of\nthe approximate posterior for that x.",
    "start": "4861650",
    "end": "4867560"
  },
  {
    "text": "And then the decoder\ntakes a z variable",
    "start": "4867560",
    "end": "4874160"
  },
  {
    "text": "and then maps it to an x. And that's the other\nneural network. And you can start to see how\nthis has a autoencoder flavor.",
    "start": "4874160",
    "end": "4882480"
  },
  {
    "text": "And in fact, what we'll\nsee is that the ELBO can be interpreted as an\nautoencoding objective",
    "start": "4882480",
    "end": "4889130"
  },
  {
    "text": "with some regularization\nover the kind of latents that you produce\nthrough an autoencoder.",
    "start": "4889130",
    "end": "4896210"
  },
  {
    "text": "And so that's why it's called\na variational autoencoder because, essentially,\nit is an encoder, which",
    "start": "4896210",
    "end": "4901530"
  },
  {
    "text": "is the variational posterior,\nand there is a decoder. And they work together\nby optimizing the ELBO.",
    "start": "4901530",
    "end": "4908340"
  },
  {
    "text": "And optimizing the ELBO is,\nessentially, a regularized type of autoencoding objective.",
    "start": "4908340",
    "end": "4914010"
  },
  {
    "text": "But we'll see next time. ",
    "start": "4914010",
    "end": "4921000"
  }
]
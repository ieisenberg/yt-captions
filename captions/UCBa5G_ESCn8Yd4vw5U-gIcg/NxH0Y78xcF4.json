[
  {
    "start": "0",
    "end": "5600"
  },
  {
    "text": "OK. Hi, everyone. I'll get started\nfor the last class. ",
    "start": "5600",
    "end": "13340"
  },
  {
    "text": "Yeah. Well, welcome. Congratulations, and\nthank you to making it to the last real\nlecture of CS224N.",
    "start": "13340",
    "end": "21480"
  },
  {
    "text": "Yeah, so this is\nthe plan for today. The lecture is titled, \"NLP,\nLinguistics, and Philosophy,\"",
    "start": "21480",
    "end": "28380"
  },
  {
    "text": "which I took as meaning that\nI could talk about anything I wanted to. And so that is what\nI'm going to do.",
    "start": "28380",
    "end": "35270"
  },
  {
    "text": "So this is what we're\ngoing to go through, talk a bit about the\nmajor ideas of CS224N",
    "start": "35270",
    "end": "41660"
  },
  {
    "text": "and open problems, some of the\nmore foundational questions",
    "start": "41660",
    "end": "47180"
  },
  {
    "text": "of where are we with LLMs,\nsymbolic versus neural systems, meaning in linguistics and NLP.",
    "start": "47180",
    "end": "54120"
  },
  {
    "text": "And then I'll close with some\nslides on the future risks of AI in the world.",
    "start": "54120",
    "end": "60400"
  },
  {
    "text": "So here is an attempt to lay out\nthe most major things that we looked at in CS224N.",
    "start": "60400",
    "end": "69120"
  },
  {
    "text": "We started with word\nvectors, and we developed the idea of neural NLP systems.",
    "start": "69120",
    "end": "74650"
  },
  {
    "text": "We expanded from a simple\nfeedforward network into doing sequence models,\nlanguage models, RNNs, LSTMs.",
    "start": "74650",
    "end": "82960"
  },
  {
    "text": "And then we introduced\nthis powerful new model that's been very\ninfluential, the transformer.",
    "start": "82960",
    "end": "88659"
  },
  {
    "text": "And then we built from\nthere to the kind of-- it's not exactly an\narchitecture but model",
    "start": "88660",
    "end": "94680"
  },
  {
    "text": "that's been built\nup in recent years to produce high-performance\nNLP systems,",
    "start": "94680",
    "end": "99790"
  },
  {
    "text": "where we're first doing\npretraining and then a post-training phase\nof various techniques",
    "start": "99790",
    "end": "106200"
  },
  {
    "text": "that we talked about to produce\nthese general foundation models that understand\nlanguage so well.",
    "start": "106200",
    "end": "112420"
  },
  {
    "text": "And then we went on\nfrom there and talked about various particular topics,\nlike benchmarking and reasoning.",
    "start": "112420",
    "end": "117910"
  },
  {
    "text": "So a few of the major\nideas that we looked at were this idea that you\ncould get a long way",
    "start": "117910",
    "end": "125670"
  },
  {
    "text": "by having dense\nrepresentations-- those are our hidden representations\nin neural networks--",
    "start": "125670",
    "end": "132070"
  },
  {
    "text": "and then looking at\ndistributional semantics, representing words\nby their contexts.",
    "start": "132070",
    "end": "137580"
  },
  {
    "text": "First slogan of you shall know\na word by the company it keeps. And I'll come back\nto that a bit later",
    "start": "137580",
    "end": "142740"
  },
  {
    "text": "in talking about\nideas of meaning. But that's essentially\nbeen the idea",
    "start": "142740",
    "end": "148770"
  },
  {
    "text": "that has driven most of the\nsuccessful ideas of modern NLP, whether it's the earliest\nstatistical NLP phase or more",
    "start": "148770",
    "end": "156720"
  },
  {
    "text": "modern neural NLP phase. And in this world, we\nstart instantiating that as these models of word vectors.",
    "start": "156720",
    "end": "165100"
  },
  {
    "text": "But the same\ncontextual idea is then used in all the models\nup through transformers.",
    "start": "165100",
    "end": "170760"
  },
  {
    "text": "We looked at both the\nchallenges and opportunities of training large deep neural\nnetworks and how gradually",
    "start": "170760",
    "end": "179410"
  },
  {
    "text": "people developed ideas\nand tricks such as having residual connections,\nwhich made it much more",
    "start": "179410",
    "end": "185170"
  },
  {
    "text": "possible and stable\nto do successfully, which took us from a\nplace where a lot of this",
    "start": "185170",
    "end": "191650"
  },
  {
    "text": "seemed black magic that was\nhard to get right to people being able to very\nreliably train",
    "start": "191650",
    "end": "197170"
  },
  {
    "text": "high-performance\ntransformer models. We talked about\nsequence models, what's",
    "start": "197170",
    "end": "203080"
  },
  {
    "text": "good about them and\nsome of their problems and how those problems have\nbeen addressed in large measure",
    "start": "203080",
    "end": "209320"
  },
  {
    "text": "by adopting this different\narchitecture of transformers, which give a form\nof parallelization.",
    "start": "209320",
    "end": "215180"
  },
  {
    "text": "And then we moved\ninto the modern form of pretraining by\nlanguage modeling, where",
    "start": "215180",
    "end": "221860"
  },
  {
    "text": "language modeling\nseems a simple thing, predicting words and context.",
    "start": "221860",
    "end": "227390"
  },
  {
    "text": "But it emerges as what we think\nof as a universal pretraining task, that all kinds of both\nlinguistic and world knowledge",
    "start": "227390",
    "end": "236860"
  },
  {
    "text": "help you to do this task\nof predicting words better. And so this has ended up\nas just a general method",
    "start": "236860",
    "end": "244720"
  },
  {
    "text": "to produce the kind of\npowerful, knowledgeable models that we have today.",
    "start": "244720",
    "end": "250489"
  },
  {
    "text": "And up until now, there's\nbeen this amazing property that we see, this empirical fact\nthat we seem to just get this",
    "start": "250490",
    "end": "259239"
  },
  {
    "text": "basically-- or well, not basically. It's extremely linear\nimprovements as performance",
    "start": "259240",
    "end": "265360"
  },
  {
    "text": "as we continue to scale data\nand compute and model size",
    "start": "265360",
    "end": "270639"
  },
  {
    "text": "up by orders of magnitude.  That doesn't mean that all\nproblems in NLP are solved.",
    "start": "270640",
    "end": "278410"
  },
  {
    "text": "There are lots of\nthings that people still work on and see opportunities\nto try and make things better.",
    "start": "278410",
    "end": "285290"
  },
  {
    "text": "And a few of these are mentioned\non the next few slides. So there's a real question\nof how much these models are",
    "start": "285290",
    "end": "296660"
  },
  {
    "text": "good at actually learning to\nbe able to do things generally,",
    "start": "296660",
    "end": "302400"
  },
  {
    "text": "rather than just being\nvery good at memorization, that a lot of the benefits\nof what we're getting",
    "start": "302400",
    "end": "310370"
  },
  {
    "text": "from these large\npretrained language models is that they've seen a\nhuge amount of stuff,",
    "start": "310370",
    "end": "317010"
  },
  {
    "text": "and, therefore, they\nknow everything, they've seen every\npattern before, and they know how to use things.",
    "start": "317010",
    "end": "323039"
  },
  {
    "text": "I've occasionally\nused the analogy that large language\nmodels are sort of",
    "start": "323040",
    "end": "328280"
  },
  {
    "text": "like a talking encyclopedia,\nthat they're really, in many ways, more like a huge\nknowledge store than necessarily",
    "start": "328280",
    "end": "337460"
  },
  {
    "text": "something that is intelligent in\nthe sense of being able to work out how to solve new\nproblems and generalize",
    "start": "337460",
    "end": "344720"
  },
  {
    "text": "as human beings do. A kind of interesting fact\nactually is that, in some ways,",
    "start": "344720",
    "end": "351340"
  },
  {
    "text": "transformer models\nare actually worse at generalizing than the older\nLSTMs that preceded them.",
    "start": "351340",
    "end": "358750"
  },
  {
    "text": "So here's just one little\ngraph I'm not going to spend a lot of time on. But this was looking\nat data that's",
    "start": "358750",
    "end": "366780"
  },
  {
    "text": "being generated by\na finite automata and then trying to learn it\nfrom a limited amount of data",
    "start": "366780",
    "end": "375660"
  },
  {
    "text": "with either an LSTM\nor a transformer. And the observation is that at\nthe scales that they're working,",
    "start": "375660",
    "end": "384340"
  },
  {
    "text": "even having seen quite\nlimited exemplification, the LSTM is basically at ceiling\nthe entire of this graph.",
    "start": "384340",
    "end": "391830"
  },
  {
    "text": "It's just at the 1.0 line\nbecause it generalizes in good ways because of\nits LSTM architecture,",
    "start": "391830",
    "end": "399600"
  },
  {
    "text": "whereas the transformer needs\nto see a ton more data before it actually learns\nthe patterns well.",
    "start": "399600",
    "end": "405815"
  },
  {
    "text": "And so if we think of one of\nthe prime attributes of humans,",
    "start": "405815",
    "end": "412270"
  },
  {
    "text": "intelligence is actually\nwe're amazing at figuring",
    "start": "412270",
    "end": "417840"
  },
  {
    "text": "out and learning things\nfrom very limited exposure. There's something that\nyou don't know how to do.",
    "start": "417840",
    "end": "425410"
  },
  {
    "text": "And a friend shows you once\nwhat you do to make it work, and by and large, you'll improve\na few times with practice.",
    "start": "425410",
    "end": "433510"
  },
  {
    "text": "But you can learn\neffectively new skills from these single shot examples.",
    "start": "433510",
    "end": "440700"
  },
  {
    "text": "And that's not always what we\nseem to be seeing in our models.",
    "start": "440700",
    "end": "446220"
  },
  {
    "text": "There's a lot of\ninterest in what's going on inside neural networks,\nthat a lot of the time,",
    "start": "446220",
    "end": "451930"
  },
  {
    "text": "neural networks still\nappear as black boxes, where we have no real\nidea of how they're",
    "start": "451930",
    "end": "457560"
  },
  {
    "text": "doing what they're doing. And as perhaps for\nyour final projects, the main thing you're doing is\nmeasuring the final performance",
    "start": "457560",
    "end": "465940"
  },
  {
    "text": "number and seeing if\nit goes up or not. So there's a lot of interest\nin better understanding what",
    "start": "465940",
    "end": "473710"
  },
  {
    "text": "do they learn, how\ndo they learn it, why do they succeed and fail. And a lot of that\nwork is starting",
    "start": "473710",
    "end": "479530"
  },
  {
    "text": "to look more closely into what's\nhappening inside neural network computations.",
    "start": "479530",
    "end": "485500"
  },
  {
    "text": "There is some work of\nthat sort that actually goes back quite a fair ways. So here's an old blog\npost by Andrej Karpathy",
    "start": "485500",
    "end": "495070"
  },
  {
    "text": "while he was a grad\nstudent here in 2016, and he was looking at LSTMs\nand how do they learn.",
    "start": "495070",
    "end": "503750"
  },
  {
    "text": "And he found that one of\nthe neurons in an LSTM cell was effectively measuring\nposition along a line of text.",
    "start": "503750",
    "end": "512719"
  },
  {
    "text": "And as the line\nof text got long, its value started to change\nbecause the model was learning",
    "start": "512720",
    "end": "520269"
  },
  {
    "text": "that there was a line\nlength of this text and that the line was likely\nto be ending at that point.",
    "start": "520270",
    "end": "526430"
  },
  {
    "text": "And in recent times,\nthere's started to, be with transformers\nas well, a lot of work looking at mechanistic\ninterpretability or causal",
    "start": "526430",
    "end": "533380"
  },
  {
    "text": "abstraction, trying\nto understand the internals of models.",
    "start": "533380",
    "end": "538540"
  },
  {
    "text": "A problem that's far from solved\nand, in many respects, probably unsolvable is the\nmultilingual question",
    "start": "538540",
    "end": "546910"
  },
  {
    "text": "of dealing with all the other\nlanguages of the world, that you",
    "start": "546910",
    "end": "552610"
  },
  {
    "text": "do have to keep in your\nhead that whatever you see for English, it's worse\nfor every other language",
    "start": "552610",
    "end": "560320"
  },
  {
    "text": "and what they're getting out\nof modern language models. Now, there is a good\nnews story here.",
    "start": "560320",
    "end": "565910"
  },
  {
    "text": "I don't want to claim that\neverything is terrible. So in this graph,\nwhich is kind of small,",
    "start": "565910",
    "end": "571840"
  },
  {
    "text": "the blue line was the\nperformance of GPT-3.5 English,",
    "start": "571840",
    "end": "578200"
  },
  {
    "text": "and then all of the green\nbars are then the performance",
    "start": "578200",
    "end": "584390"
  },
  {
    "text": "of GPT-4. And so there's a genuine good\nnews story here, which is, look,",
    "start": "584390",
    "end": "590580"
  },
  {
    "text": "not just for English but for\na lot of other languages, for Greek, Latvian,\nArabic, Turkish,",
    "start": "590580",
    "end": "598069"
  },
  {
    "text": "all of them in GPT-4 are better\nthan English was in GPT-3.5.",
    "start": "598070",
    "end": "605130"
  },
  {
    "text": "So that's the good\nnews argument, that building these models\nbig is, in some sense,",
    "start": "605130",
    "end": "613790"
  },
  {
    "text": "raising all boats. But these are still\nall huge languages.",
    "start": "613790",
    "end": "619470"
  },
  {
    "text": "And things are\nstarting to drop off at the bottom of this\ntable for languages",
    "start": "619470",
    "end": "627470"
  },
  {
    "text": "where the performance is\nworse than English in GPT 3.5. But even for those languages for\nwhich much less written data is",
    "start": "627470",
    "end": "637940"
  },
  {
    "text": "available, but they're\nstill large languages. So the ones that-- the\nthree at the bottom are actually all\nIndian languages.",
    "start": "637940",
    "end": "644529"
  },
  {
    "text": "They're Punjabi,\nMarathi, and Telugu, which are languages\nthat are each",
    "start": "644530",
    "end": "649710"
  },
  {
    "text": "spoken by millions of people. They're not small languages. So the real question is, what\nhappens when you actually",
    "start": "649710",
    "end": "657480"
  },
  {
    "text": "get to the small\nlow-resource languages? So the vast majority of\nlanguages around the world",
    "start": "657480",
    "end": "664470"
  },
  {
    "text": "don't have millions of speakers. They vary from having\nhundreds of speakers",
    "start": "664470",
    "end": "669660"
  },
  {
    "text": "to hundreds of\nthousands of speakers. And there are thousands\nof such languages. A lot of those languages\nare primarily oral",
    "start": "669660",
    "end": "677640"
  },
  {
    "text": "and have very limited\namounts of written text. Now, some of those\nlanguages are likely--",
    "start": "677640",
    "end": "684160"
  },
  {
    "text": "or many of those languages\nare likely to go extinct in the coming decades.",
    "start": "684160",
    "end": "689200"
  },
  {
    "text": "But many of those\nlanguage communities would like to preserve\ntheir languages.",
    "start": "689200",
    "end": "694209"
  },
  {
    "text": "And it's very unclear how the\nkind of language technologies that we've been talking about\nin the later parts of the course",
    "start": "694210",
    "end": "702960"
  },
  {
    "text": "can be extended\nto those languages because there just\nisn't sufficient data to build the kind of models\nthat we've been looking at.",
    "start": "702960",
    "end": "711690"
  },
  {
    "text": "So I imagine you've gotten\nsome idea in this course of how evaluation is a huge\npart of what we do,",
    "start": "711690",
    "end": "720060"
  },
  {
    "text": "that effectively a lot of the\nway that progress is being driven is by defining\nevaluations of what models",
    "start": "720060",
    "end": "726750"
  },
  {
    "text": "should be able to\nachieve and then people working to measure\nsystems and improve systems",
    "start": "726750",
    "end": "734520"
  },
  {
    "text": "so that they do better on\nwhat we see as good language understanding or\nother properties.",
    "start": "734520",
    "end": "741570"
  },
  {
    "text": "One of the concerns\nthat many people have about what's happened with\nthe large, recent closed models",
    "start": "741570",
    "end": "750389"
  },
  {
    "text": "from large companies\nis a concern that all of the benchmarks\nare being sullied",
    "start": "750390",
    "end": "755740"
  },
  {
    "text": "and not to be trusted. So here's one example that comes\nfrom a tweet of Horace He's.",
    "start": "755740",
    "end": "765220"
  },
  {
    "text": "And he's noting, I suspect,\nGPT-4's performance influenced by data contamination,\nat least on Codeforces,",
    "start": "765220",
    "end": "772790"
  },
  {
    "text": "one of the coding benchmarks. Of the easiest\nproblems on Codeforces, it solved 10 out of\n10 pre-2021 problems,",
    "start": "772790",
    "end": "781730"
  },
  {
    "text": "but 0 out of 10 recent problems. This strongly points\nto contamination.",
    "start": "781730",
    "end": "787310"
  },
  {
    "text": "And the worry is that\nevery time you're seeing these fantastic results\nof how well the latest best",
    "start": "787310",
    "end": "794230"
  },
  {
    "text": "language model is performing,\nthat at this point, so much data is on\nthe web that gets",
    "start": "794230",
    "end": "800740"
  },
  {
    "text": "included in the pretraining data\nfor these large language models",
    "start": "800740",
    "end": "806050"
  },
  {
    "text": "that essentially\nthey're memorizing at least a good share of the\nquestions that are appearing",
    "start": "806050",
    "end": "811480"
  },
  {
    "text": "in these challenges. So they're not\nactually solving them in a fair way as an\nindependent test set at all.",
    "start": "811480",
    "end": "818180"
  },
  {
    "text": "They're just memorizing them. And so there's issues\nthen as to what kind",
    "start": "818180",
    "end": "823480"
  },
  {
    "text": "of thoroughly hidden\ntest sets we can have or dynamic evaluation\nmechanisms so we can actually",
    "start": "823480",
    "end": "829480"
  },
  {
    "text": "have benchmark integrity. Another huge area\nthat a number of us",
    "start": "829480",
    "end": "834910"
  },
  {
    "text": "are involved in at\nStanford and elsewhere is making NLP work in\ndifferent technical domains.",
    "start": "834910",
    "end": "841280"
  },
  {
    "text": "So domains, including\nbiomedical or clinical, medical, NLP have a lot of differences,\na lot vocabulary and usage.",
    "start": "841280",
    "end": "849769"
  },
  {
    "text": "They have a lot of\npotential good uses. But they also have a lot of\npotential risks of doing harm",
    "start": "849770",
    "end": "856660"
  },
  {
    "text": "if the language\nunderstanding is incomplete. I myself have been more involved\ndoing things in the legal NLP,",
    "start": "856660",
    "end": "865000"
  },
  {
    "text": "working with other\npeople at the RegLab with Dan Ho in building\nfoundation models for law.",
    "start": "865000",
    "end": "872510"
  },
  {
    "text": "And there are all\nkinds of ways, again, in which this kind of technology\ncould be really useful.",
    "start": "872510",
    "end": "880740"
  },
  {
    "text": "The biggest problem\nin most countries-- it's bad in the United States,\nbut it's way worse in a place",
    "start": "880740",
    "end": "887870"
  },
  {
    "text": "like India-- is that most people can't get\naccess to the kind of legal help",
    "start": "887870",
    "end": "893240"
  },
  {
    "text": "that they need to solve\ntheir problems because of the cost of it and the\nlack of trained lawyers.",
    "start": "893240",
    "end": "900029"
  },
  {
    "text": "So if more could be\ndone to be able to help people via NLP tools, in\nprinciple, that would be great.",
    "start": "900030",
    "end": "909270"
  },
  {
    "text": "But in practice, the tools still\ndon't have good enough language understanding.",
    "start": "909270",
    "end": "914540"
  },
  {
    "text": "So in the RegLab, there's\njust-completed study out at the moment looking\nat legal NLP systems.",
    "start": "914540",
    "end": "922350"
  },
  {
    "text": "And we were finding\nthat the hallucination rate, the rate in\nwhich there was made up",
    "start": "922350",
    "end": "927800"
  },
  {
    "text": "stuff in their legal\nanswers, was effectively for one question in six, which\nisn't a very good accuracy",
    "start": "927800",
    "end": "934920"
  },
  {
    "text": "rate if you're\nsomeone who's wanting to rely on these systems\nfor legal advice.",
    "start": "934920",
    "end": "941670"
  },
  {
    "text": "There are lots of\nthings also to work out dealing with the social and\ncultural aspects of NLP.",
    "start": "941670",
    "end": "947190"
  },
  {
    "text": "NLP systems remain very biased\nagainst various cultures",
    "start": "947190",
    "end": "952950"
  },
  {
    "text": "and religions.  They have certain social norms\nyou could say that they pick up",
    "start": "952950",
    "end": "961320"
  },
  {
    "text": "from somewhere, but\nthose social norms are very biased\nagainst certain groups.",
    "start": "961320",
    "end": "966570"
  },
  {
    "text": "And related to there\nbeing small languages that I mentioned\nbefore, that there",
    "start": "966570",
    "end": "972750"
  },
  {
    "text": "are lots of issues with\nunderrepresented groups in having the kind of NLP\nthat they'd like to have.",
    "start": "972750",
    "end": "980100"
  },
  {
    "text": "OK, so that's the\nsummary of that bit. So for the next bit,\nI thought I'd just",
    "start": "980100",
    "end": "986700"
  },
  {
    "text": "give one more bit of perspective\non where are we with the best",
    "start": "986700",
    "end": "993570"
  },
  {
    "text": "language models, like GPT-4. I mean, I think it's really\ninteresting at this moment",
    "start": "993570",
    "end": "1001010"
  },
  {
    "text": "of where we are because,\non the one hand, the performance of these\nmodels is just amazing.",
    "start": "1001010",
    "end": "1010230"
  },
  {
    "text": "And even as someone\nwho works in NLP and has worked in it for\nmany, many years now,",
    "start": "1010230",
    "end": "1018120"
  },
  {
    "text": "I mean, I can tell a sort\nof story that these models,",
    "start": "1018120",
    "end": "1024949"
  },
  {
    "text": "that we do this training\nto predict the next word and it's conditioning\non a lot of text",
    "start": "1024950",
    "end": "1030089"
  },
  {
    "text": "and it knows about\nthings and it does-- but in some sense, these\nthings still seem like magic.",
    "start": "1030089",
    "end": "1037099"
  },
  {
    "text": "It's just kind of\nhard to believe how this could possibly work. So in this example,\nI asked ChatGPT 4o--",
    "start": "1037099",
    "end": "1045819"
  },
  {
    "text": "I did this morning. I asked it to write\na sonnet explaining",
    "start": "1045819",
    "end": "1052080"
  },
  {
    "text": "the transformer neural net\narchitecture in which every line begins with the\nletter T. And it sort",
    "start": "1052080",
    "end": "1059910"
  },
  {
    "text": "of still, frankly,\nblows my mind, and I don't actually feel I can\nreally explain even to myself",
    "start": "1059910",
    "end": "1067390"
  },
  {
    "text": "in a way that's convincing\nhow this large transformer is",
    "start": "1067390",
    "end": "1073080"
  },
  {
    "text": "able to take all\nits pretraining text and reading that instruction\nand, as a next token prediction",
    "start": "1073080",
    "end": "1081779"
  },
  {
    "text": "machine, it\nsuccessfully produces something that is a\nsonnet and every line",
    "start": "1081780",
    "end": "1089009"
  },
  {
    "text": "begins with the letter T. I hope you remember from your\nhigh school English classes. Sonnets are meant\nto have AB rhyming.",
    "start": "1089010",
    "end": "1097800"
  },
  {
    "text": "It's a little bit\nimperfect here, net set. Some people are\ncomplain about that, but it's basically a rhyme.",
    "start": "1097800",
    "end": "1103540"
  },
  {
    "text": "Behold, unfold, grasp, clasp,\nso it's basically doing the writing rhyming right.",
    "start": "1103540",
    "end": "1109176"
  },
  {
    "text": "And the lines are meant to\nbe in iambic pentameter, and it's basically produced\nlines in iambic pentameter",
    "start": "1109176",
    "end": "1116130"
  },
  {
    "text": "to delve into the world of\nneural nets, iambic pentameter.",
    "start": "1116130",
    "end": "1121560"
  },
  {
    "text": "Yeah, it's incredible. So here's its sonnet\nit came up with. To delve into the\nworld of neural nets,",
    "start": "1121560",
    "end": "1127960"
  },
  {
    "text": "transformers rise,\na marvel to behold. Through layers deep,\nthe network's path",
    "start": "1127960",
    "end": "1133200"
  },
  {
    "text": "is set, to learn from\ndata, patterns to unfold. The tokens feed into attentions\ngrasp, to weigh their import,",
    "start": "1133200",
    "end": "1141420"
  },
  {
    "text": "context to align. The queries, keys,\nand values in a clasp, to process sequences\nwith power fine,",
    "start": "1141420",
    "end": "1149370"
  },
  {
    "text": "through heads of many\nmultifaceted sight, to parallelize\ncapturing the span.",
    "start": "1149370",
    "end": "1155290"
  },
  {
    "text": "Transforming each, a\nmatrix math delight, to synthesize with\nelegance and plan.",
    "start": "1155290",
    "end": "1161740"
  },
  {
    "text": "The model's might,\nin every task it shows, to turn raw data\ninto wisdom's prose.",
    "start": "1161740",
    "end": "1167966"
  },
  {
    "text": "[LAUGHTER] Now, could object that\nI'm not sure this exactly",
    "start": "1167966",
    "end": "1174370"
  },
  {
    "text": "explained the transformer\nneural net architecture. [LAUGHTER] It's a little bit abstract.",
    "start": "1174370",
    "end": "1179809"
  },
  {
    "text": "I'll give it that. But in another\nsense, it didn't--",
    "start": "1179810",
    "end": "1186710"
  },
  {
    "text": "it did, in one place or another,\nevoke quite a bit of stuff about transformers with\nqueries, keys, and values",
    "start": "1186710",
    "end": "1194380"
  },
  {
    "text": "and multiheaded stuff\nparallelized with matrix math",
    "start": "1194380",
    "end": "1199870"
  },
  {
    "text": "and whatever else. Yeah, still kind of blows\nmy mind how well that works.",
    "start": "1199870",
    "end": "1206390"
  },
  {
    "text": "And indeed, as natural language\nunderstanding and world",
    "start": "1206390",
    "end": "1214480"
  },
  {
    "text": "understanding\ndevices, these devices have clearly crossed the\nthreshold in which they're",
    "start": "1214480",
    "end": "1222850"
  },
  {
    "text": "very usable in many contexts. So here's-- there's now started\nto be some fairly good studies",
    "start": "1222850",
    "end": "1231159"
  },
  {
    "text": "that have been done on how\nmuch value people can get out of using LLMs, like GPT-4.",
    "start": "1231160",
    "end": "1239860"
  },
  {
    "text": "So this study by Dell'Acqua\nand a whole lot of colleagues,",
    "start": "1239860",
    "end": "1245030"
  },
  {
    "text": "including Ethan Mollick, they\ntook a bunch of consultants from",
    "start": "1245030",
    "end": "1250390"
  },
  {
    "text": "the Boston Consulting Group, and\nso you know what that's like. That means 23-year-olds\ngraduating from universities",
    "start": "1250390",
    "end": "1257710"
  },
  {
    "text": "like this one but more\non the East Coast. They become Boston consultants,\nnot exactly dummies.",
    "start": "1257710",
    "end": "1267490"
  },
  {
    "text": "And so they found\nin this study-- so controlled task.",
    "start": "1267490",
    "end": "1273400"
  },
  {
    "text": "There were actually\nthree groups. But the big contrast is\nthat two of the groups",
    "start": "1273400",
    "end": "1279809"
  },
  {
    "text": "were using GPT-4 to\ndo consulting tasks, and one of the groups wasn't\nusing GPT-4 to do tasks.",
    "start": "1279810",
    "end": "1288490"
  },
  {
    "text": "The difference between the\ntwo that were was one of them was given more training\non how to use GPT-4,",
    "start": "1288490",
    "end": "1294610"
  },
  {
    "text": "but that didn't seem to\nmake much of a difference. But their result\nwas that the groups",
    "start": "1294610",
    "end": "1300990"
  },
  {
    "text": "using GPT-4 in their\nstudy completed 12% more tasks on average.",
    "start": "1300990",
    "end": "1307750"
  },
  {
    "text": "They did the task\n25% more quickly. And the results were\njudged 40% higher quality",
    "start": "1307750",
    "end": "1316530"
  },
  {
    "text": "than those not using\nAI, which I think is a pretty stunning success of\nhow GPT-4 or similar LLMs are",
    "start": "1316530",
    "end": "1326640"
  },
  {
    "text": "good enough to actually help\npeople get real work done with whatever asterisks\nyou want to put",
    "start": "1326640",
    "end": "1333059"
  },
  {
    "text": "about the quality of\nmanagement consultant work in various instances.",
    "start": "1333060",
    "end": "1338789"
  },
  {
    "text": "Yeah. I mean, and the interesting\nresult is that using these LLMs",
    "start": "1338790",
    "end": "1344460"
  },
  {
    "text": "seemed to be a big leveler. And actually, you see exactly\nthe same thing for people",
    "start": "1344460",
    "end": "1350310"
  },
  {
    "text": "using coding LLMs, that they're\na huge assistance for people",
    "start": "1350310",
    "end": "1356670"
  },
  {
    "text": "whose own skills are\nweaker, and they're much less of an\nassistance for people whose own skills are strong.",
    "start": "1356670",
    "end": "1363900"
  },
  {
    "text": "So that's the good news story. But on the other hand, you'd\nmore like the good news story",
    "start": "1363900",
    "end": "1370380"
  },
  {
    "text": "for human beings. Here's a study that goes\nin the other direction.",
    "start": "1370380",
    "end": "1376090"
  },
  {
    "text": "Can GPT-4 write fiction that\nmatches the quality of New",
    "start": "1376090",
    "end": "1381390"
  },
  {
    "text": "Yorker fiction writers? And the result of that\nstudy was not even close,",
    "start": "1381390",
    "end": "1388830"
  },
  {
    "text": "that GPT-4 was measured\nas 3 to 10 times worse at creative writing than\nin New Yorker fiction writer.",
    "start": "1388830",
    "end": "1397220"
  },
  {
    "text": "So there's still hope\nfor human beings. Hang on there.",
    "start": "1397220",
    "end": "1402580"
  },
  {
    "text": "And so I think that's\nthe dual screen picture",
    "start": "1402580",
    "end": "1407740"
  },
  {
    "text": "that we have at the moment. In some ways, these things\nare great and useful. In other ways,\nthey're not so great.",
    "start": "1407740",
    "end": "1415550"
  },
  {
    "text": "And I think that's\nsomething that we're still going to be seeing playing\nout in the future years.",
    "start": "1415550",
    "end": "1424880"
  },
  {
    "text": "I think, living\nin Silicon Valley, we see a lot of\nthe positive hype.",
    "start": "1424880",
    "end": "1430730"
  },
  {
    "text": "So if you just want to see\na little bit of the negative on the other side,\nlate last year,",
    "start": "1430730",
    "end": "1436850"
  },
  {
    "text": "there was a piece in\nthe Financial Times which was titled\n\"Generative AI--",
    "start": "1436850",
    "end": "1442880"
  },
  {
    "text": "Hypely Intelligent.\" And I won't read all of\nthis, but basically they",
    "start": "1442880",
    "end": "1448809"
  },
  {
    "text": "were wanting to express\nconsiderable skepticism",
    "start": "1448810",
    "end": "1454030"
  },
  {
    "text": "of the current AI boom. Investors should\nkeep their heads. Expectations for generative\nAI are running way ahead",
    "start": "1454030",
    "end": "1461410"
  },
  {
    "text": "of the limitations\nthat apply to it. As investment in\ngenerative AI grows, so does pressure to\ncreate new use cases.",
    "start": "1461410",
    "end": "1468580"
  },
  {
    "text": "By 2027, IDC thinks enterprise\nspending on generative AI will reach $143 billion, up\nfrom $16 billion this year,",
    "start": "1468580",
    "end": "1477260"
  },
  {
    "text": "so 10 times up. OpenAI hopes for more funding\nto pursue human-like AI.",
    "start": "1477260",
    "end": "1482840"
  },
  {
    "text": "It is worth\nremembering that when examining Altman's plan\nfor superintelligence, models predict they\ndo not comprehend.",
    "start": "1482840",
    "end": "1489500"
  },
  {
    "text": "That limitation casts\ndoubt on AI achieving even human-like intelligence.",
    "start": "1489500",
    "end": "1495280"
  },
  {
    "text": "And then they start talking\nabout some of the problems with limited gains for\nlower-skilled workers,",
    "start": "1495280",
    "end": "1504230"
  },
  {
    "text": "inaccuracies in the work\nthey produce, and suggests",
    "start": "1504230",
    "end": "1509710"
  },
  {
    "text": "that the limitations will become\nmore obvious as generative AI tools roll out. That will put pressure on\nproviders to address costs.",
    "start": "1509710",
    "end": "1517160"
  },
  {
    "text": "AI could add $4\ntrillion to profit, says McKinsey, but pricing\nclarity is lacking.",
    "start": "1517160",
    "end": "1523370"
  },
  {
    "text": "Without it, companies cannot\npredict what financial gains AI can accomplish, and AI\ncannot predict that either.",
    "start": "1523370",
    "end": "1533200"
  },
  {
    "text": "OK, that's that topic. I'm chugging through my topics.",
    "start": "1533200",
    "end": "1538210"
  },
  {
    "text": "The next topic is I wanted to\nreturn and say a bit more about",
    "start": "1538210",
    "end": "1544149"
  },
  {
    "text": "symbolic methods that dominated\nfrom AI the '60s until about",
    "start": "1544150",
    "end": "1550300"
  },
  {
    "text": "2010, versus what I\ntermed here as cybernetics",
    "start": "1550300",
    "end": "1555890"
  },
  {
    "text": "because the original\nalternative, going back to the '50s and\n'60s, was called cybernetics.",
    "start": "1555890",
    "end": "1563059"
  },
  {
    "text": "And in a very real sense, neural\nnetworks is a continuation",
    "start": "1563060",
    "end": "1569930"
  },
  {
    "text": "of the cybernetics tradition,\nrather than the AI tradition",
    "start": "1569930",
    "end": "1575330"
  },
  {
    "text": "that started in\nthe '50s and '60s. In this context, Stanford is\nthe home of the Symbolic Systems",
    "start": "1575330",
    "end": "1583520"
  },
  {
    "text": "Program. So at the moment, we are unique\nin having a Symbolic Systems",
    "start": "1583520",
    "end": "1589460"
  },
  {
    "text": "Program. So the name Symbolic\nSystems came about because,",
    "start": "1589460",
    "end": "1594890"
  },
  {
    "text": "at the time it was started-- so I guess philosophy was an\nactive part of the Symbolic",
    "start": "1594890",
    "end": "1601250"
  },
  {
    "text": "Systems Program. And Jon Barwise, shown in this\npicture, he actually died young.",
    "start": "1601250",
    "end": "1607410"
  },
  {
    "text": "So he actually died in 2000. Jon Barwise had a\nvery strong belief",
    "start": "1607410",
    "end": "1617330"
  },
  {
    "text": "that you are meant to\nbe dealing with meaning in the world and the\nconnection between people's",
    "start": "1617330",
    "end": "1627250"
  },
  {
    "text": "thinking and the world. And so he refused\nto allow the program",
    "start": "1627250",
    "end": "1632830"
  },
  {
    "text": "to be called cognitive\nscience, as it's called at most other\nplaces, and it ended up",
    "start": "1632830",
    "end": "1638770"
  },
  {
    "text": "being called Symbolic Systems. Now, at one point, there\nwere two universities",
    "start": "1638770",
    "end": "1644200"
  },
  {
    "text": "that had symbolic systems\nbecause Jon Barwise actually moved away from Stanford and\nwent to Indiana, which is where",
    "start": "1644200",
    "end": "1651760"
  },
  {
    "text": "he is originally was from. And so Indiana also had a\nsymbolic systems program",
    "start": "1651760",
    "end": "1656919"
  },
  {
    "text": "for a number of years,\nbut they've actually changed theirs to cognitive\nscience now since he died.",
    "start": "1656920",
    "end": "1662590"
  },
  {
    "text": "So we are unique in\nhaving Symbolic Systems. And so the idea of\nsymbolic systems--",
    "start": "1662590",
    "end": "1669710"
  },
  {
    "text": "this is what's on the website,\nwith a bit of interpretation.",
    "start": "1669710",
    "end": "1674840"
  },
  {
    "text": "So symbolic systems study\nsystems of meaningful symbols that represent the\nworld about us,",
    "start": "1674840",
    "end": "1680450"
  },
  {
    "text": "like human languages, logics,\nand programming languages, and the systems that work with\nthese symbols, like brains,",
    "start": "1680450",
    "end": "1687370"
  },
  {
    "text": "computers, and complex\nsocial systems, contrasting that to the\nsort of typical view",
    "start": "1687370",
    "end": "1693809"
  },
  {
    "text": "of cognitive science,\nwhich is focusing on the mind and\nintelligence as a naturally occurring phenomenon.",
    "start": "1693810",
    "end": "1700019"
  },
  {
    "text": "Symbolic systems\ngives equal focus to human constructed systems\nthat use symbols to communicate",
    "start": "1700020",
    "end": "1706110"
  },
  {
    "text": "and to represent information. So in AI terms, AI as\na field and the name AI",
    "start": "1706110",
    "end": "1718020"
  },
  {
    "text": "arose around arguing\nfor a symbolic approach,",
    "start": "1718020",
    "end": "1723300"
  },
  {
    "text": "that John McCarthy, who's\nthe color photo there and who founded Stanford's\nartificial intelligence",
    "start": "1723300",
    "end": "1732690"
  },
  {
    "text": "And the original\nfamous Stanford AI lab,",
    "start": "1732690",
    "end": "1737769"
  },
  {
    "text": "so John McCarthy came up\nwith the name artificial intelligence. And he very explicitly\nchose a new name",
    "start": "1737770",
    "end": "1747070"
  },
  {
    "text": "to disassociate\nwhat he was doing from the cybernetics\napproach, which",
    "start": "1747070",
    "end": "1753730"
  },
  {
    "text": "had been pursued by people,\nincluding Norbert Wiener at MIT,",
    "start": "1753730",
    "end": "1758870"
  },
  {
    "text": "who's shown on the right side. So Marvin Minsky, the\nteeny photo down here,",
    "start": "1758870",
    "end": "1766360"
  },
  {
    "text": "founded artificial\nintelligence at MIT. McCarthy worked with\nhim for a few years,",
    "start": "1766360",
    "end": "1773690"
  },
  {
    "text": "and then McCarthy\ncame to Stanford. And two of the other most\nprominent early AI people",
    "start": "1773690",
    "end": "1779200"
  },
  {
    "text": "are Newell and Simon, who were\nat CMU, and of the other two people on the right side.",
    "start": "1779200",
    "end": "1785120"
  },
  {
    "text": "And so in particular,\nNewell and Simon developed--",
    "start": "1785120",
    "end": "1793330"
  },
  {
    "text": "well, actually, no, let\nme say a sentence first. Yeah, so, I mean, McCarthy's own\nbackground was a mathematician",
    "start": "1793330",
    "end": "1799240"
  },
  {
    "text": "and logician. So he wanted to construct an\nartificial intelligence that",
    "start": "1799240",
    "end": "1807070"
  },
  {
    "text": "looked like math and\nlogic effectively. And that's most AI\nas a symbolic system.",
    "start": "1807070",
    "end": "1813950"
  },
  {
    "text": "And that was developed\nas a position in the philosophy of\nartificial intelligence by Newell and Simon.",
    "start": "1813950",
    "end": "1820520"
  },
  {
    "text": "And so they developed what\nthey called the physical symbol system hypothesis.",
    "start": "1820520",
    "end": "1826060"
  },
  {
    "text": "So that said, a\nphysical symbol system has the necessary\nand sufficient means",
    "start": "1826060",
    "end": "1832510"
  },
  {
    "text": "for general intelligent action. And so that's a\nsuper strong claim.",
    "start": "1832510",
    "end": "1838220"
  },
  {
    "text": "It's not only claiming\nthat having a symbol system allows you to produce\nartificial general intelligence",
    "start": "1838220",
    "end": "1847100"
  },
  {
    "text": "but through the necessary\nclause that you can't have artificial general\nintelligence without having",
    "start": "1847100",
    "end": "1854800"
  },
  {
    "text": "a symbol system. So that was the basis\nof classical AI.",
    "start": "1854800",
    "end": "1861590"
  },
  {
    "text": " And that contrasts a bit with--",
    "start": "1861590",
    "end": "1868429"
  },
  {
    "text": "so cybernetics had its origins\nin control and communication.",
    "start": "1868430",
    "end": "1876420"
  },
  {
    "text": "So it's much nearer to\nan electrical engineering background and was\nwanting to unify",
    "start": "1876420",
    "end": "1884690"
  },
  {
    "text": "ideas of control and\ncommunication between animals, maybe perhaps more than\nhumans and machines.",
    "start": "1884690",
    "end": "1893750"
  },
  {
    "text": "Yeah so I mean-- ",
    "start": "1893750",
    "end": "1898770"
  },
  {
    "text": "yeah, so cybernetics comes\nfrom a Greek word \"kubernetes,\" which is sort of interesting,\nall the uses it has.",
    "start": "1898770",
    "end": "1906540"
  },
  {
    "text": "So it's exactly the same root\nthat occurs both in Kubernetes, if you are familiar\nwith that as distributed",
    "start": "1906540",
    "end": "1914630"
  },
  {
    "text": "containers on modern systems. But also it's\nactually the same root",
    "start": "1914630",
    "end": "1919860"
  },
  {
    "text": "that the word\ngovernment comes from. Of course, it's a\ncontrol system as well. [LAUGHS]",
    "start": "1919860",
    "end": "1927780"
  },
  {
    "text": "Yeah. So under the\ncybernetics tradition was where neural nets first\nstarted being explored.",
    "start": "1927780",
    "end": "1935970"
  },
  {
    "text": "The very earliest neural\nnets, of the most famous ones are Frank Rosenblatt's,\nwhich we use for vision.",
    "start": "1935970",
    "end": "1942130"
  },
  {
    "text": "The neural net was\nactually wired. To say just a teeny\nbit about this,",
    "start": "1942130",
    "end": "1948059"
  },
  {
    "text": "in case you think that AI hype\nis only a thing of the 2020s,",
    "start": "1948060",
    "end": "1954160"
  },
  {
    "text": "there was just as much AI hype\nin the 1950s when Rosenblatt",
    "start": "1954160",
    "end": "1960390"
  },
  {
    "text": "unveiled his perceptron. So in the New York Times article\nabout it, \"New Navy Device",
    "start": "1960390",
    "end": "1968460"
  },
  {
    "text": "Learns by Doing-- Psychologist Shows Embryo of\nComputer Design to Read and Grow",
    "start": "1968460",
    "end": "1974100"
  },
  {
    "text": "Wiser.\" The Navy revealed the embryo\nof an electronic computer",
    "start": "1974100",
    "end": "1979170"
  },
  {
    "text": "today that it expects will be\nable to walk, talk, see, write,",
    "start": "1979170",
    "end": "1984520"
  },
  {
    "text": "reproduce itself, and be\nconscious of its existence.",
    "start": "1984520",
    "end": "1989880"
  },
  {
    "text": "And this hype is all\nthe more incredible when you get to the later\nparagraph of the article",
    "start": "1989880",
    "end": "1997140"
  },
  {
    "text": "and you find out what the\ndemonstration was actually of. And the demonstration\nthat people were shown",
    "start": "1997140",
    "end": "2004190"
  },
  {
    "text": "was that this device\nlearned to differentiate",
    "start": "2004190",
    "end": "2009379"
  },
  {
    "text": "between right arrow\nand left arrow pictures after 50 exposures.",
    "start": "2009380",
    "end": "2015466"
  },
  {
    "text": "[LAUGHS] But there you go.",
    "start": "2015466",
    "end": "2020840"
  },
  {
    "text": "OK. Yeah. So what do we make of this in\nthe case of NLP and language?",
    "start": "2020840",
    "end": "2031500"
  },
  {
    "text": "And the position I\nwould like to suggest",
    "start": "2031500",
    "end": "2037260"
  },
  {
    "text": "is there's just no doubt that\nlanguage is a symbolic system,",
    "start": "2037260",
    "end": "2046500"
  },
  {
    "text": "that humans developed\nlanguage as a symbolic system.",
    "start": "2046500",
    "end": "2052810"
  },
  {
    "text": "It's perhaps most obvious\nthat, if you think about it in writing, we have symbols\nof the letters and words",
    "start": "2052810",
    "end": "2061199"
  },
  {
    "text": "that we use. But even if there's no writing-- and the majority of human\nlanguage use over time",
    "start": "2061199",
    "end": "2068309"
  },
  {
    "text": "has been verbal,\nhuman language use-- that even though the\nsubstrate is carried on,",
    "start": "2068310",
    "end": "2074730"
  },
  {
    "text": "where the sound waves\nor, in sign languages, movements of hands, even though\nthat's a continuous substrate,",
    "start": "2074730",
    "end": "2081429"
  },
  {
    "text": "the structure of human\nlanguages is a symbol system. We have symbols which are the\nsounds of human languages.",
    "start": "2081429",
    "end": "2089500"
  },
  {
    "text": "For cat, we have a\nkuh, an ah, and a tuh. Those are symbols, and they're\nrecognized in a symbolic way",
    "start": "2089500",
    "end": "2095820"
  },
  {
    "text": "by language users. And indeed, all\nthe pioneering work",
    "start": "2095820",
    "end": "2101010"
  },
  {
    "text": "in categorical perception\nin cognitive psychology is done with the sounds of\nhuman languages, the phonemes,",
    "start": "2101010",
    "end": "2109540"
  },
  {
    "text": "as linguists call them. So spoken language also\nhas a symbolic structure.",
    "start": "2109540",
    "end": "2116260"
  },
  {
    "text": "But going against\nNewell and Simon, the fact that humans use a\nsymbol system for communication",
    "start": "2116260",
    "end": "2125910"
  },
  {
    "text": "doesn't mean that the processor\nof the symbols, the human brain, has to be a physical\nsymbol system.",
    "start": "2125910",
    "end": "2133030"
  },
  {
    "text": "And so similarly, we\ndon't have to design NLP, our computer processes,\n[? with ?] physical symbol",
    "start": "2133030",
    "end": "2140370"
  },
  {
    "text": "systems either. The brain is clearly much more\nlike a neural network model,",
    "start": "2140370",
    "end": "2147150"
  },
  {
    "text": "and probably neural models\nwill scale better and capture language processing\nbetter than something",
    "start": "2147150",
    "end": "2154180"
  },
  {
    "text": "that is a symbolic\nprocessor in the same way. I mean, that leaves behind\nthe question of, well,",
    "start": "2154180",
    "end": "2161240"
  },
  {
    "text": "why did humans come up with a\nsymbol system for communication?",
    "start": "2161240",
    "end": "2166640"
  },
  {
    "text": "I mean, after all, we could\nhave just sort of hummed at different\nfrequencies, and that",
    "start": "2166640",
    "end": "2172570"
  },
  {
    "text": "could have been used as our\nsystem of communication. I mean, I think the\ndominant idea, which",
    "start": "2172570",
    "end": "2178570"
  },
  {
    "text": "seems reasonable to\nme but who knows, is that having a symbolic system\ngives signaling reliability,",
    "start": "2178570",
    "end": "2185920"
  },
  {
    "text": "that if you have discrete target\npoints that are separated, then",
    "start": "2185920",
    "end": "2191440"
  },
  {
    "text": "that gives you an\nability when there's degradation of the signal\nto recover it well.",
    "start": "2191440",
    "end": "2198569"
  },
  {
    "text": "Yeah. So where does that\nleave linguistics? Which is mainly being developed\nin terms of describing",
    "start": "2198570",
    "end": "2207680"
  },
  {
    "text": "a symbolic system. I think the right way to\nthink about it is linguistics",
    "start": "2207680",
    "end": "2212720"
  },
  {
    "text": "is good for giving us questions,\nconcepts, and distinctions when thinking about\nlanguage acquisition,",
    "start": "2212720",
    "end": "2219360"
  },
  {
    "text": "processing, and understanding. And indeed, one of\nthe interesting things",
    "start": "2219360",
    "end": "2224540"
  },
  {
    "text": "that's come about is that as\nNLP and AI have been developed",
    "start": "2224540",
    "end": "2231350"
  },
  {
    "text": "further and is able to do\na lot of low-level stuff, that there's actually\nthe higher-level concepts",
    "start": "2231350",
    "end": "2238609"
  },
  {
    "text": "that linguists often\ntalk about a lot, things like compositionality and\nsystematic generalization, which",
    "start": "2238610",
    "end": "2244970"
  },
  {
    "text": "I'll come back to in a\nfew minutes, the mapping of stable meanings for\nsymbols, the reference",
    "start": "2244970",
    "end": "2252079"
  },
  {
    "text": "of linguistic expressions\nin the world, that they get talked about more and more\nin artificial intelligence",
    "start": "2252080",
    "end": "2260480"
  },
  {
    "text": "contexts, building\nneural systems. And I mean, I think\none way to think",
    "start": "2260480",
    "end": "2265610"
  },
  {
    "text": "about it is that, a lot of\nthe early neural network work of, most notably,\nvisual processing",
    "start": "2265610",
    "end": "2275610"
  },
  {
    "text": "but also other kinds of\nsensory stuff like sounds. I mean, doing that\nis what gets you",
    "start": "2275610",
    "end": "2282860"
  },
  {
    "text": "to insect-level intelligence. And if you want to get\nhigher up the chain than insect-level\nintelligence, then a lot",
    "start": "2282860",
    "end": "2290089"
  },
  {
    "text": "of the kind of questions and\nproperties of linguistic systems become increasingly relevant.",
    "start": "2290090",
    "end": "2297589"
  },
  {
    "text": "At a slightly more\nprosaic level,",
    "start": "2297590",
    "end": "2303110"
  },
  {
    "text": "I don't think one\nnecessarily wants to believe all the fine\ndetails of different linguistic",
    "start": "2303110",
    "end": "2310400"
  },
  {
    "text": "theories. But for how human languages are\nstructured and how they behave,",
    "start": "2310400",
    "end": "2315809"
  },
  {
    "text": "I think, yeah, most of our broad\nunderstanding of linguistics is right.",
    "start": "2315810",
    "end": "2321180"
  },
  {
    "text": "And so therefore, when we're\nthinking about NLP systems and we're thinking about\nunderstanding how they behave,",
    "start": "2321180",
    "end": "2328390"
  },
  {
    "text": "wanting to know whether they\nhave certain properties, thinking up ways\nto evaluate them.",
    "start": "2328390",
    "end": "2333520"
  },
  {
    "text": "A lot of that is done in terms\nof linguistic understanding, wanting to see whether they\ncapture facts about sentence",
    "start": "2333520",
    "end": "2341220"
  },
  {
    "text": "structure, discourse\nstructure, semantic properties, like natural language\ninference, whether you",
    "start": "2341220",
    "end": "2348000"
  },
  {
    "text": "can do things bridging\nanaphora, which I did not cover this year's class\nbecause we skipped the coreference lecture when\nwe sliced one lecture off",
    "start": "2348000",
    "end": "2355140"
  },
  {
    "text": "the class, metaphors,\npresuppositions. All of these things\nare linguistic notions",
    "start": "2355140",
    "end": "2360420"
  },
  {
    "text": "that we try and get our\nNLP models to capture. So I just want to say\na couple more remarks",
    "start": "2360420",
    "end": "2368099"
  },
  {
    "text": "about the role of human\nlanguage in human intelligence.",
    "start": "2368100",
    "end": "2374260"
  },
  {
    "text": "I think this is\nkind of interesting. So an interesting person in\nthe history of linguistics",
    "start": "2374260",
    "end": "2381630"
  },
  {
    "text": "is this guy, Wilhelm\nvon Humboldt, who was a prominent\nGerman academic.",
    "start": "2381630",
    "end": "2390810"
  },
  {
    "text": "So really, the American\neducation system was borrowed from Germany.",
    "start": "2390810",
    "end": "2398370"
  },
  {
    "text": "So up until the\nSecond World War, the preeminent place of science\nand learning was Germany.",
    "start": "2398370",
    "end": "2406260"
  },
  {
    "text": "And Germany, essentially,\nvia von Humboldt's work, developed the idea of\nhaving graduate education.",
    "start": "2406260",
    "end": "2413980"
  },
  {
    "text": "And the US copied graduate\neducation from Germany and started doing its own.",
    "start": "2413980",
    "end": "2421030"
  },
  {
    "text": "But in that context, it was\nstill the case that for people",
    "start": "2421030",
    "end": "2426840"
  },
  {
    "text": "in the United States\nprior to the 1930s, that generally people would\ngo to Germany to finish",
    "start": "2426840",
    "end": "2436200"
  },
  {
    "text": "their education, either to get\ntheir PhD or to do a postdoc or something like that.",
    "start": "2436200",
    "end": "2442672"
  },
  {
    "text": "So if you trace back\nmy own academic tree or most other academic trees of\npeople who got PhDs in the US,",
    "start": "2442672",
    "end": "2452030"
  },
  {
    "text": "they actually go back\na few generations, and then they go\nback to Germany. So we don't think of that\nas much in the modern world.",
    "start": "2452030",
    "end": "2462140"
  },
  {
    "text": "Yeah. So Humboldt was influential\nin developing the university system, but he also\nworked a lot on language.",
    "start": "2462140",
    "end": "2472220"
  },
  {
    "text": "And I mean, he's someone\nthat Chomsky always cites because he's known for\nthis famous statement about that",
    "start": "2472220",
    "end": "2480880"
  },
  {
    "text": "human language must make\ninfinite use of finite means. So the fact that we have\na limited supply of words",
    "start": "2480880",
    "end": "2487990"
  },
  {
    "text": "and sentence structures,\nbut out of those, we can recursively build up an\ninfinite number of sentences.",
    "start": "2487990",
    "end": "2494540"
  },
  {
    "text": "And that's, in Chomsky's\nview, supporting the kind of symbolic,\nstructured view of language",
    "start": "2494540",
    "end": "2501349"
  },
  {
    "text": "that he's been advocating. But I think there's\nanother interesting take",
    "start": "2501350",
    "end": "2506900"
  },
  {
    "text": "on von Humboldt's,\nwhich we can argue whether it's right or not\nbut I think is interesting.",
    "start": "2506900",
    "end": "2515850"
  },
  {
    "text": "And one of the things\nhe wants to stress is that language isn't\njust something used",
    "start": "2515850",
    "end": "2524180"
  },
  {
    "text": "for the purpose of\ncommunication, that he-- ",
    "start": "2524180",
    "end": "2530990"
  },
  {
    "text": "I should actually\nintroduce something here. So, so Kahneman and Tversky\nare two well-known cognitive",
    "start": "2530990",
    "end": "2538609"
  },
  {
    "text": "psychologists, and they\nintroduced this idea that there are two kinds of\nthinking, system 1 cognition",
    "start": "2538610",
    "end": "2544790"
  },
  {
    "text": "and system 2 cognition. And system 1 is the kind\nof subconscious thinking",
    "start": "2544790",
    "end": "2550730"
  },
  {
    "text": "that you're not really thinking,\nof just, we process stuff when it comes into our\nheads, whether visual signals",
    "start": "2550730",
    "end": "2557210"
  },
  {
    "text": "or speech. And system 2 thinking\nis the conscious,",
    "start": "2557210",
    "end": "2563130"
  },
  {
    "text": "\"let me think about this and\ntry and figure out what's going on, I'm solving a math\nproblem\" style of thinking.",
    "start": "2563130",
    "end": "2569460"
  },
  {
    "text": "And I think you can see in von\nHumboldt's writings, essentially",
    "start": "2569460",
    "end": "2576950"
  },
  {
    "text": "the same kind of distinction\nbetween system 1 and system 2 cognition, although he\nrefers to system 1 cognition",
    "start": "2576950",
    "end": "2584540"
  },
  {
    "text": "as acts of the spirit and\nsystem 2 cognition as thinking.",
    "start": "2584540",
    "end": "2590750"
  },
  {
    "text": "Yeah. And so basically he\nargues for a version",
    "start": "2590750",
    "end": "2596210"
  },
  {
    "text": "of the philosophical position\nof the language of thought, of suggesting that effective\nsystem 2 thinking requires",
    "start": "2596210",
    "end": "2606980"
  },
  {
    "text": "extension of the mind through\nthe symbols of language. And so he argued\nthat having language",
    "start": "2606980",
    "end": "2615059"
  },
  {
    "text": "is absolutely a necessary\nfoundation for the progress of the human mind.",
    "start": "2615060",
    "end": "2620440"
  },
  {
    "text": "And I think that's actually an\ninteresting perspective, which I have some sympathy with. I mean, obviously, we can\nthink without language.",
    "start": "2620440",
    "end": "2628150"
  },
  {
    "text": "We can feel afraid. We can think visually and about\nhow things that fit together.",
    "start": "2628150",
    "end": "2634990"
  },
  {
    "text": "But I think it's\nfairly plausible that, for the more abstract,\nlarger-scale thinking",
    "start": "2634990",
    "end": "2645329"
  },
  {
    "text": "that humans engage\nin and has led them to higher levels of thought\nthan a chimpanzee gets to,",
    "start": "2645330",
    "end": "2653040"
  },
  {
    "text": "that language gives a\nscaffolding inside the mind that makes that possible.",
    "start": "2653040",
    "end": "2658690"
  },
  {
    "text": "Another version of that is from\nthe philosopher Daniel Dennett, who just actually died\na couple of months ago.",
    "start": "2658690",
    "end": "2666300"
  },
  {
    "text": "So Dennett wrote this\nbook called From bacteria to Bach and Back.",
    "start": "2666300",
    "end": "2671559"
  },
  {
    "text": "And the main thing\nthis book was about was the origin of\nhuman consciousness. And I'm not going to talk about\nhuman consciousness today,",
    "start": "2671560",
    "end": "2680010"
  },
  {
    "text": "but he introduced this model\nof four grades of progressively",
    "start": "2680010",
    "end": "2686760"
  },
  {
    "text": "more competent intelligences. And so the four\nlevels he outlined",
    "start": "2686760",
    "end": "2693900"
  },
  {
    "text": "was that the bottom\none was Darwinian. So Darwinian intelligence\nwas something",
    "start": "2693900",
    "end": "2700920"
  },
  {
    "text": "that was predesigned and fixed. It doesn't improve\nduring its lifetime.",
    "start": "2700920",
    "end": "2706119"
  },
  {
    "text": "Improvement only\nhappens by evolution through genetic selection.",
    "start": "2706120",
    "end": "2712350"
  },
  {
    "text": "So things like\nbacteria and viruses are Darwinian intelligences.",
    "start": "2712350",
    "end": "2718540"
  },
  {
    "text": "So then after that was\nSkinnerian intelligences. And so they improve\nbehavior by learning",
    "start": "2718540",
    "end": "2726539"
  },
  {
    "text": "to respond to reinforcement. So something like a\nlizard or perhaps a dog--",
    "start": "2726540",
    "end": "2734270"
  },
  {
    "text": "we could argue about how\nintelligent dogs are-- has Skinnerian intelligence.",
    "start": "2734270",
    "end": "2741410"
  },
  {
    "text": "And so then the third level\nup, Popperian intelligence,",
    "start": "2741410",
    "end": "2746500"
  },
  {
    "text": "is things that learn\nmodels of the environment so they can improve performance\nby thinking through plans",
    "start": "2746500",
    "end": "2754810"
  },
  {
    "text": "and then executing them\nand seeing how they behave. So in a computational sense,\nPopperian intelligence",
    "start": "2754810",
    "end": "2765880"
  },
  {
    "text": "means that you can do model\nbased reinforcement learning. And so primates,\nlike chimpanzees,",
    "start": "2765880",
    "end": "2774039"
  },
  {
    "text": "can definitely do\nthe kind of planning and model-based reinforcement\nlearning that gives you",
    "start": "2774040",
    "end": "2781660"
  },
  {
    "text": "a Popperian intelligence. But actually, a lot\nof recent evidence shows that a lot of simpler\ncreatures can also do it.",
    "start": "2781660",
    "end": "2789290"
  },
  {
    "text": "So I'm not sure the facts here. So all the studies you\nsee are about crows",
    "start": "2789290",
    "end": "2798260"
  },
  {
    "text": "from the South Pacific,\nAustralia, and Fiji,",
    "start": "2798260",
    "end": "2804740"
  },
  {
    "text": "and places like that. So I'm not sure if Northern\nHemisphere crows are dumber, but at least Southern\nHemisphere crows can learn plans",
    "start": "2804740",
    "end": "2814730"
  },
  {
    "text": "so that they can do multistage\nplanning to work out ways to get a piece of\nmeat that's down a hole",
    "start": "2814730",
    "end": "2821690"
  },
  {
    "text": "by learning to pick up\na stick and poke it in and so that even crows can\nbe Popperian intelligences.",
    "start": "2821690",
    "end": "2830180"
  },
  {
    "text": "But what Dennett\nsuggests is that there's a stage beyond Popperian\nintelligence, which he",
    "start": "2830180",
    "end": "2837140"
  },
  {
    "text": "calls Gregorian intelligence. And the idea of\nGregorian intelligence",
    "start": "2837140",
    "end": "2842780"
  },
  {
    "text": "is that you can build\nthinking tools, which allow you to do a higher level\nof control of mental searches.",
    "start": "2842780",
    "end": "2853440"
  },
  {
    "text": "And so he suggests\nthat things like, well, mathematics\nis a thinking tool.",
    "start": "2853440",
    "end": "2861450"
  },
  {
    "text": "But well, also a democracy\nis a thinking tool. But nevertheless, out of\nthe space of thinking tools,",
    "start": "2861450",
    "end": "2868580"
  },
  {
    "text": "that human language is the\npreeminent thinking tool that we have. And so he suggests that the\nonly biological example we have",
    "start": "2868580",
    "end": "2878120"
  },
  {
    "text": "of a Gregorian intelligence\nis human beings. And so I think in\nthat kind of sense,",
    "start": "2878120",
    "end": "2885720"
  },
  {
    "text": "you can say that there's a very\nimportant role for language. OK.",
    "start": "2885720",
    "end": "2891560"
  },
  {
    "text": "Two parts to go in my summary. So the next one is,\nwhat kind of semantics",
    "start": "2891560",
    "end": "2898490"
  },
  {
    "text": "should we use for language? And so this is going\nback to the question I mentioned for word vectors.",
    "start": "2898490",
    "end": "2905560"
  },
  {
    "text": "And This is kind of interesting. So the semantics\nthat's been dominant",
    "start": "2905560",
    "end": "2911010"
  },
  {
    "text": "in philosophy of language\nor in linguistic semantics is a notion of model\ntheoretic semantics, where",
    "start": "2911010",
    "end": "2918090"
  },
  {
    "text": "the meaning of words is\ntheir denotation, what they represent in the world--",
    "start": "2918090",
    "end": "2923710"
  },
  {
    "text": "I mentioned this, I think,\nin an earlier lecture-- so that if you have\na word like computer,",
    "start": "2923710",
    "end": "2929560"
  },
  {
    "text": "the meaning of\ncomputer is the set of computers, this one,\nthat one, that one, all the other computers around.",
    "start": "2929560",
    "end": "2934779"
  },
  {
    "text": "So it's a denotational\nrelationship between a word and its denotation in the world\nor in a model of the world.",
    "start": "2934780",
    "end": "2943000"
  },
  {
    "text": "And that was the\nnotion that was used in most of the history of\nAI for doing symbolic AI.",
    "start": "2943000",
    "end": "2950200"
  },
  {
    "text": "And that then contrasts\nwith this sort of distributional semantics,\nthat the meaning of a word",
    "start": "2950200",
    "end": "2956520"
  },
  {
    "text": "is understanding the\ncontext in which it's used, which is effectively what we're\nusing for our neural models.",
    "start": "2956520",
    "end": "2964650"
  },
  {
    "text": "Yeah. So if you look at\nthe traditional view of understanding, interpreting\nthe meaning of human language--",
    "start": "2964650",
    "end": "2974190"
  },
  {
    "text": "and this is what you'll have\nseen if you did an intro logic class at some point,\nthat we have a sentence,",
    "start": "2974190",
    "end": "2981910"
  },
  {
    "text": "the red apple is on the table. And you get to write in\nsome logical representation,",
    "start": "2981910",
    "end": "2987970"
  },
  {
    "text": "first-order predicate\ncalculus or whatever. This one's a bit different\nto allowing thus, where normally for first-order\npredicate calculus, you only do",
    "start": "2987970",
    "end": "2996960"
  },
  {
    "text": "fall [INAUDIBLE] exists. But you have sort\nof a formal logic.",
    "start": "2996960",
    "end": "3002010"
  },
  {
    "text": "And in the early weeks, in weeks\n1 and 2 of the logic class, you have some English\nsentences for which you",
    "start": "3002010",
    "end": "3008569"
  },
  {
    "text": "translate into formal logic. And then after that, you\nforget about human languages,",
    "start": "3008570",
    "end": "3014300"
  },
  {
    "text": "and you just start proving stuff\nabout formal logical systems.",
    "start": "3014300",
    "end": "3019350"
  },
  {
    "text": "And so to some extent, what\nyou get in a philosophy class represents the\ntradition of Alfred Tarski.",
    "start": "3019350",
    "end": "3027960"
  },
  {
    "text": "So Tarski believed that you\ncouldn't talk about meaning in terms of talking about\nhuman languages because human",
    "start": "3027960",
    "end": "3036780"
  },
  {
    "text": "languages were, quote,\n\"impossibly incoherent.\" Yeah, and so from about\nthe 1940s until 1980,",
    "start": "3036780",
    "end": "3048480"
  },
  {
    "text": "Tarski was the preeminent\nlogician in the US. He was in Berkeley.",
    "start": "3048480",
    "end": "3054870"
  },
  {
    "text": "And so that was\nvery much the view of the logicians of the world.",
    "start": "3054870",
    "end": "3061030"
  },
  {
    "text": "But during that period,\none of his students was this guy, Richard Montague.",
    "start": "3061030",
    "end": "3067830"
  },
  {
    "text": "So Richard Montague rebelled\nagainst that picture, saying,",
    "start": "3067830",
    "end": "3074830"
  },
  {
    "text": "I reject the contention that an\nimportant theoretical difference exists between formal\nand natural languages.",
    "start": "3074830",
    "end": "3081230"
  },
  {
    "text": "And so he then set about\nshowing that, well, you",
    "start": "3081230",
    "end": "3087640"
  },
  {
    "text": "could start building up a\nformal semantics for describing",
    "start": "3087640",
    "end": "3093400"
  },
  {
    "text": "the meaning of natural\nlanguage sentences. And so Richard Montague's\nwork became the foundation",
    "start": "3093400",
    "end": "3099849"
  },
  {
    "text": "of the work that's\nused in semantics, in linguistics as well.",
    "start": "3099850",
    "end": "3105440"
  },
  {
    "text": "For anyone who's done ling 130\nor 230, the picture you saw is a Montague\npicture of semantics.",
    "start": "3105440",
    "end": "3114770"
  },
  {
    "text": "And so that was the\nsemantics that was taken over",
    "start": "3114770",
    "end": "3121540"
  },
  {
    "text": "and essentially used as the\nmodel of doing natural language understanding for most\nof the history of NLP,",
    "start": "3121540",
    "end": "3130390"
  },
  {
    "text": "roughly 1960 to 2015-17.",
    "start": "3130390",
    "end": "3136900"
  },
  {
    "text": "And so the picture\nessentially was that if we wanted to have a\nsentence that we interpreted,",
    "start": "3136900",
    "end": "3144220"
  },
  {
    "text": "like the red apple is on\nthe table, what we would do is we'd first produce\na syntactic structure",
    "start": "3144220",
    "end": "3151750"
  },
  {
    "text": "for the sentence. So we would parse it. And then, using ideas\nroughly along the lines",
    "start": "3151750",
    "end": "3159700"
  },
  {
    "text": "that Montague suggested, we\nwould construct its meaning by looking up meanings\nof words in the lexicon",
    "start": "3159700",
    "end": "3168860"
  },
  {
    "text": "and then using the\ncompositionality of human languages to work out\nthe meanings of progressively",
    "start": "3168860",
    "end": "3175840"
  },
  {
    "text": "larger phrases and\nclauses in terms of the meanings of\nthose words and the way",
    "start": "3175840",
    "end": "3181390"
  },
  {
    "text": "that they are combined, slightly\nreminiscent of my discussion of tree structures to meanings\nin the last lecture I gave.",
    "start": "3181390",
    "end": "3189920"
  },
  {
    "text": "And so you would build up\na meaning representation of a sentence.",
    "start": "3189920",
    "end": "3196550"
  },
  {
    "text": "And so this could then give you\na semantic meaning of a sentence that you could use in a system.",
    "start": "3196550",
    "end": "3203270"
  },
  {
    "text": "This is approximately a\nslide, except retitled, that I actually used to use\nin CS224N in the 2000s decade.",
    "start": "3203270",
    "end": "3213990"
  },
  {
    "text": "So we have part of a sentence,\nI guess-- oh no, it's",
    "start": "3213990",
    "end": "3220662"
  },
  {
    "text": "a whole sentence. Here it is. How many red cars-- well, what-- can I\nget this sentence?",
    "start": "3220662",
    "end": "3227070"
  },
  {
    "text": "I think there's a sentence here. How many-- oh, how many red cars\nin Palo Alto does Kathy like?",
    "start": "3227070",
    "end": "3234060"
  },
  {
    "text": "How many red cars in Palo\nAlto does Kathy like? And so yeah, the cars, sorry,\ngot hidden underneath here.",
    "start": "3234060",
    "end": "3241610"
  },
  {
    "text": "Yeah so we have a sentence. We parse it. We look up meanings of\nwords in the lexicon.",
    "start": "3241610",
    "end": "3247020"
  },
  {
    "text": "We start composing them up. We get a semantic form for\nthe whole sentence, which",
    "start": "3247020",
    "end": "3252380"
  },
  {
    "text": "we can then convert into SQL. And we can run\nagainst a database, and we can get the answer.",
    "start": "3252380",
    "end": "3258270"
  },
  {
    "text": "And this was an outline the kind\nof technology that was widely",
    "start": "3258270",
    "end": "3263570"
  },
  {
    "text": "used for natural language\nunderstanding systems that were built anywhere from\nthe 1960s to the 2010s.",
    "start": "3263570",
    "end": "3272100"
  },
  {
    "text": "And in particular,\nthey were used not only",
    "start": "3272100",
    "end": "3277520"
  },
  {
    "text": "in a purely kind of rule-based\ngrammar and lexicon way. The same basic technology\nwas incorporated",
    "start": "3277520",
    "end": "3284210"
  },
  {
    "text": "into a machine\nlearning context, where your goal was to start to\nlearn various of these parts.",
    "start": "3284210",
    "end": "3290040"
  },
  {
    "text": "You could not only\nlearn the parser, but you could also learn\nsemantic meanings of words",
    "start": "3290040",
    "end": "3296750"
  },
  {
    "text": "and learn composition rules. And so the [? acme ?] of that\nwork was then what was called",
    "start": "3296750",
    "end": "3301819"
  },
  {
    "text": "semantic parsing that was\npioneered by Luke Zettlemoyer and Mike Collins in the 2000s\ndecade and then taken up",
    "start": "3301820",
    "end": "3309420"
  },
  {
    "text": "by others, including\nPercy Liang. So Percy Liang's PhD\nthesis but also actually",
    "start": "3309420",
    "end": "3315540"
  },
  {
    "text": "his early work at\nStanford, before he was convinced to\ndo neural networks,",
    "start": "3315540",
    "end": "3321090"
  },
  {
    "text": "was doing semantic parsing work. So these systems\ncould actually work",
    "start": "3321090",
    "end": "3328619"
  },
  {
    "text": "and were used in\nlimited domains. But they were always\nextremely brittle.",
    "start": "3328620",
    "end": "3334110"
  },
  {
    "text": "And yeah, the interesting\nthing is, what of humans? I mean, there is some evidence\nthat humans do something",
    "start": "3334110",
    "end": "3342300"
  },
  {
    "text": "like this, that they work out\nthe structure of sentences and compute meanings\nin a bottom-up, mostly",
    "start": "3342300",
    "end": "3353160"
  },
  {
    "text": "projective way. There's a lot of\ncontroversy as to exactly how human understanding\nof sentences still works.",
    "start": "3353160",
    "end": "3361210"
  },
  {
    "text": "But there are\ncertainly people who've argued in support of human\nbrains doing something similar.",
    "start": "3361210",
    "end": "3367420"
  },
  {
    "text": "That's, obviously,\nnot what we're getting with current-day transformers. And so the question\nis, do our current day",
    "start": "3367420",
    "end": "3378550"
  },
  {
    "text": "neural language models provide\nsuitable meaning functions? And that's a complex question\nbecause, in many ways, yeah,",
    "start": "3378550",
    "end": "3388400"
  },
  {
    "text": "they seem to. They do an amazing job\nat understanding whatever sentences you put into them.",
    "start": "3388400",
    "end": "3393800"
  },
  {
    "text": "But there are still\nsome genuine concerns as to whether they are\nmaking shortcuts or work",
    "start": "3393800",
    "end": "3401170"
  },
  {
    "text": "to a certain extent\nand don't actually have the same kind of\ncompositional understanding",
    "start": "3401170",
    "end": "3407110"
  },
  {
    "text": "with systematic generalization\nthat human beings do.",
    "start": "3407110",
    "end": "3412180"
  },
  {
    "text": "So that's the traditional\ndenotational semantics view. And that contrasts with\nthe use theory of meaning.",
    "start": "3412180",
    "end": "3421610"
  },
  {
    "text": "And in the first\nor second lecture and at the beginning\nof this one, I attributed that to the\nBritish linguist JR Firth.",
    "start": "3421610",
    "end": "3430430"
  },
  {
    "text": "\"You shall know a word\nby the company it keeps.\" But it's not only a\nposition of Firth.",
    "start": "3430430",
    "end": "3436010"
  },
  {
    "text": "It's also been a minority\nposition of philosophers. In particular, it was\nadvanced by Wittgenstein",
    "start": "3436010",
    "end": "3443380"
  },
  {
    "text": "in his later work and his work\nPhilosophical Investigations. So in that work,\nhe writes, \"When",
    "start": "3443380",
    "end": "3449560"
  },
  {
    "text": "I talk about language,\nword sentences, et cetera, I must speak the\nlanguage of every day.",
    "start": "3449560",
    "end": "3455300"
  },
  {
    "text": "Is this language somehow\ntoo coarse and material for what we want to say? Then how is another one to be\nconstructed and how strange that",
    "start": "3455300",
    "end": "3463359"
  },
  {
    "text": "we should be able to do anything\nat all with the one we have.\" Philosophical\nInvestigations is written",
    "start": "3463360",
    "end": "3469360"
  },
  {
    "text": "in this sort of vaguely\npoetical literary style. But the point of it\nis meant to be saying,",
    "start": "3469360",
    "end": "3475300"
  },
  {
    "text": "look, these logician\npeople are claiming you can't use natural language--\nhuman languages to express",
    "start": "3475300",
    "end": "3481900"
  },
  {
    "text": "meaning and you\nhave to translate it into this symbol system. But isn't that a weird\nconcept, that one symbol system",
    "start": "3481900",
    "end": "3489320"
  },
  {
    "text": "is no good but this other symbol\nsystem somehow fixes things?",
    "start": "3489320",
    "end": "3494750"
  },
  {
    "text": "And then about denotational\nsemantics, he writes, \"You say, the point isn't the\nword but its meaning.",
    "start": "3494750",
    "end": "3501839"
  },
  {
    "text": "And you think of the\nmeaning as a thing of the same kind as\nthe word, though also different from the word.",
    "start": "3501840",
    "end": "3507510"
  },
  {
    "text": "Here the word,\nthere the meaning.\" So that's the symbol\nand its denotation.",
    "start": "3507510",
    "end": "3512670"
  },
  {
    "text": "\"The money and the cow\nthat you can buy with it. But contrast,\nmoney and its use.\"",
    "start": "3512670",
    "end": "3518670"
  },
  {
    "text": "And he goes on\nfrom there to argue for the kind of--\nthe meaning of money",
    "start": "3518670",
    "end": "3523790"
  },
  {
    "text": "is the way that money\ncan be used in the world. The meaning of money, isn't\npointing at pieces of money.",
    "start": "3523790",
    "end": "3532460"
  },
  {
    "text": "OK, so this is what's referred\nto as the use theory of meaning.",
    "start": "3532460",
    "end": "3537750"
  },
  {
    "text": "And so the question is, is\nthat a good theory of meaning? So some people just\ndon't accept this kind",
    "start": "3537750",
    "end": "3549080"
  },
  {
    "text": "of distributional\nsemantic use theories of meaning as a theory\nof meaning or semantics,",
    "start": "3549080",
    "end": "3556380"
  },
  {
    "text": "most prominently\nin recent NLP work. That's the position\nof Bender and Koller",
    "start": "3556380",
    "end": "3561560"
  },
  {
    "text": "that they just\ntake as axiomatic. The only thing that\ncounts as having a meaning",
    "start": "3561560",
    "end": "3567140"
  },
  {
    "text": "is that you've got form over\nhere and meaning over there.",
    "start": "3567140",
    "end": "3573049"
  },
  {
    "text": "But I think that\nthat's too narrow. I think we have to argue\nthat meaning arises from--",
    "start": "3573050",
    "end": "3581930"
  },
  {
    "text": "meaning of words arises\nfrom connecting words to other things. And although, in\nsome sense, you could",
    "start": "3581930",
    "end": "3588950"
  },
  {
    "text": "say connecting words to things\nin the real world is privileged,",
    "start": "3588950",
    "end": "3594000"
  },
  {
    "text": "it's not the only way that\nyou can ground meanings. You can have meanings\nin a virtual world,",
    "start": "3594000",
    "end": "3600760"
  },
  {
    "text": "but you can also have\nmeanings by connecting one word to other things\nin human language.",
    "start": "3600760",
    "end": "3606640"
  },
  {
    "text": "And the other thing that I\nthink you need to say is meaning",
    "start": "3606640",
    "end": "3612000"
  },
  {
    "text": "isn't a sort of a 0, 1 thing,\nthat the denotation of a word",
    "start": "3612000",
    "end": "3617370"
  },
  {
    "text": "or you don't. I think meaning is\na gradient thing, and you can understand\nmeanings of words and phrases,",
    "start": "3617370",
    "end": "3624160"
  },
  {
    "text": "either more or less. And so this is an\nexample I gave in a piece that I wrote a\ncouple of years ago.",
    "start": "3624160",
    "end": "3631480"
  },
  {
    "text": "What is the meaning\nof the word \"shehnai?\" Well, maybe a few\nof you know it,",
    "start": "3631480",
    "end": "3639880"
  },
  {
    "text": "but if you don't,\nwell, what could I do? Well, if you'd seen\nor held one, you'd",
    "start": "3639880",
    "end": "3646680"
  },
  {
    "text": "have classic grounded\nmeaning, know something about the denotation.",
    "start": "3646680",
    "end": "3652200"
  },
  {
    "text": "Well, if that's not the\ncase, well, I could at least show you a picture of one. Here's a picture of one.",
    "start": "3652200",
    "end": "3658320"
  },
  {
    "text": "So that gives you\nsome information about what a shehnai is. But is that the\nonly thing I can do?",
    "start": "3658320",
    "end": "3666220"
  },
  {
    "text": "I mean, suppose-- well, sorry. I left out a bullet point. So this gives you a\npartial meaning of shehnai.",
    "start": "3666220",
    "end": "3674440"
  },
  {
    "text": "But surely you have\na richer meaning if you'd heard one being played.",
    "start": "3674440",
    "end": "3680220"
  },
  {
    "text": "And well, is showing you a\npicture of one the only thing I can do?",
    "start": "3680220",
    "end": "3685530"
  },
  {
    "text": "Suppose you'd never\nseen, felt, or heard one. But I told you, it's a\ntraditional Indian instrument,",
    "start": "3685530",
    "end": "3693940"
  },
  {
    "text": "a bit like an oboe. Well, I think you\nunderstand something about the meaning of\nthe word at that point,",
    "start": "3693940",
    "end": "3700500"
  },
  {
    "text": "that it's connected to India. It's a wind\ninstrument using reeds",
    "start": "3700500",
    "end": "3708569"
  },
  {
    "text": "that's used for playing music. I could tell you some\nother things about it. I could say it has holes\nsort of like a recorder,",
    "start": "3708570",
    "end": "3715490"
  },
  {
    "text": "but it has multiple reeds and a\nflared end, more like an oboe.",
    "start": "3715490",
    "end": "3720640"
  },
  {
    "text": "Then maybe you know a\nbit more about a shehnai, even though you've\nnever seen one.",
    "start": "3720640",
    "end": "3726070"
  },
  {
    "text": "And if you then extend\nto what we do more in our corpus-based\nlinguistic learning,",
    "start": "3726070",
    "end": "3736060"
  },
  {
    "text": "you could imagine it's not that\nI tried to define one for you. Instead, I've just shown\nyou a textural use example.",
    "start": "3736060",
    "end": "3743990"
  },
  {
    "text": "So here are several of those. So here's one\ntextural use example.",
    "start": "3743990",
    "end": "3749140"
  },
  {
    "text": "\"From a week before, shehnai\nplayers set in bamboo machans at the entrance to the\nhouse, playing their pipes.",
    "start": "3749140",
    "end": "3756770"
  },
  {
    "text": "Bikash Babu disliked the\nshehnai's wail but was determined to fulfill every\nconventional expectation",
    "start": "3756770",
    "end": "3763990"
  },
  {
    "text": "the groom's family might have.\" So if that's all you know\nabout a shehnai, in some ways,",
    "start": "3763990",
    "end": "3774079"
  },
  {
    "text": "you understand less of\nthe meaning of the word than if you'd seen one. But actually, in other\nways, you understand",
    "start": "3774080",
    "end": "3782690"
  },
  {
    "text": "more of the meaning of the word\nthan if you'd just seen one because you know from\nthat one textual example,",
    "start": "3782690",
    "end": "3789496"
  },
  {
    "text": "you know some things. You have heard a\ncharacterization of the sound",
    "start": "3789496",
    "end": "3794960"
  },
  {
    "text": "as wailing. And you know that it's connected\nwith weddings, which you don't",
    "start": "3794960",
    "end": "3802220"
  },
  {
    "text": "get from just having\nheld or looked at one or even having had someone stand\nin front of you and play it.",
    "start": "3802220",
    "end": "3809579"
  },
  {
    "text": "And that's an important\npart of the meaning of a shehnai to people.",
    "start": "3809580",
    "end": "3815099"
  },
  {
    "text": "And so that's the\nsense in which I think so meaning comes from\nvarious kinds of connections.",
    "start": "3815100",
    "end": "3821329"
  },
  {
    "text": "OK, last topic, our AI future. Yeah, so there are different\nsenses of our AI future",
    "start": "3821330",
    "end": "3828950"
  },
  {
    "text": "and lots of things that\nwe can be worried about. One thing we can\nbe worried about",
    "start": "3828950",
    "end": "3834619"
  },
  {
    "text": "is whether we're all\ngoing to lose our jobs. Interesting question.",
    "start": "3834620",
    "end": "3841610"
  },
  {
    "text": "Here's a newspaper\narticle from the New York Times, \"March of the\nMachine Makes Idle Hands--",
    "start": "3841610",
    "end": "3848730"
  },
  {
    "text": "Prevalence of Unemployment With\nGreatly Increased Industrial Output Points to the Influence\nof Labor-Saving Devices",
    "start": "3848730",
    "end": "3855859"
  },
  {
    "text": "as an Underlying Cause.\" This was published in the\nNew York Times in 1928.",
    "start": "3855860",
    "end": "3863690"
  },
  {
    "text": "But it turns out that\nquite a few people like labor-saving machines, like\nwashing machines and dishwashers",
    "start": "3863690",
    "end": "3872630"
  },
  {
    "text": "and sewing machines, lots of\nuseful labor saving machines.",
    "start": "3872630",
    "end": "3878839"
  },
  {
    "text": "And well, this was published\nin 1928, just before--",
    "start": "3878840",
    "end": "3885530"
  },
  {
    "text": "at a time when a small group of\nimmensely powerful and rich men",
    "start": "3885530",
    "end": "3891690"
  },
  {
    "text": "dominated the United States just\nbefore the Great Depression.",
    "start": "3891690",
    "end": "3897300"
  },
  {
    "text": "But what happened in the decades\nafter that greatly changed",
    "start": "3897300",
    "end": "3903690"
  },
  {
    "text": "policies in the\nUnited States, led to boom years that distributed\nwealth and work much more",
    "start": "3903690",
    "end": "3911579"
  },
  {
    "text": "evenly across the country,\nand the country boomed. Here's another one.",
    "start": "3911580",
    "end": "3918270"
  },
  {
    "text": "\"In the past, new industries\nhired far more people than those they put out of business.",
    "start": "3918270",
    "end": "3923770"
  },
  {
    "text": "But this is not true of many\nof today's new industries. Today's new industries\nhave comparatively few jobs",
    "start": "3923770",
    "end": "3930450"
  },
  {
    "text": "for the unskilled\nor semiskilled, just the class of workers\nwhose jobs are being eliminated",
    "start": "3930450",
    "end": "3935700"
  },
  {
    "text": "by automation.\" This was Time Magazine in 1961.",
    "start": "3935700",
    "end": "3941580"
  },
  {
    "text": "So this is a long-standing fear,\nwhich at least so far has not",
    "start": "3941580",
    "end": "3946590"
  },
  {
    "text": "been realized. Here we are in which-- a country in which not\neveryone might have the work",
    "start": "3946590",
    "end": "3953460"
  },
  {
    "text": "that they wish they had\nbut that overall almost everybody has a job.",
    "start": "3953460",
    "end": "3959460"
  },
  {
    "text": "And many people are working a\nlot of hours a week, whereas, once upon a time, the claim was\nthat before the end of the 20th",
    "start": "3959460",
    "end": "3967500"
  },
  {
    "text": "century, we'd only have to\ndo a three-day work week because there wouldn't be\nmuch work to go around.",
    "start": "3967500",
    "end": "3972700"
  },
  {
    "text": "Imagine. Yeah. So another fear is, will\nalmost all the money",
    "start": "3972700",
    "end": "3979020"
  },
  {
    "text": "go to 5 to 10 enormous\ntechnology giants? I actually think this\nis a more serious worry.",
    "start": "3979020",
    "end": "3986410"
  },
  {
    "text": "This seems to be the\ndirection that we're headed in at the moment. I think there's no doubt\nthat modern networks",
    "start": "3986410",
    "end": "3993599"
  },
  {
    "text": "and a concentration of AI talent\ntend to encourage this outcome.",
    "start": "3993600",
    "end": "3999090"
  },
  {
    "text": "But essentially, this is the\nmodern analog of what happened in the early decades\nof the 20th century.",
    "start": "3999090",
    "end": "4006070"
  },
  {
    "text": "The equivalent then was\ntransportation networks, and it was domination of the\nnew transportation networks,",
    "start": "4006070",
    "end": "4012839"
  },
  {
    "text": "like railways, that led\nto a few people dominating the economic system.",
    "start": "4012840",
    "end": "4018630"
  },
  {
    "text": "But what happened\nthere would be--",
    "start": "4018630",
    "end": "4024089"
  },
  {
    "text": "essentially comes down to a\npolitical and social question. So as I was mentioning before,\nafter the Great Depression,",
    "start": "4024090",
    "end": "4032230"
  },
  {
    "text": "countries successfully dealt\nwith the monopolistic power of a small number of companies.",
    "start": "4032230",
    "end": "4039180"
  },
  {
    "text": "And with political leadership,\nwe could do that again. The problem is that\nthere's not much sign",
    "start": "4039180",
    "end": "4046020"
  },
  {
    "text": "of political leadership\nright at the moment, but that's a political\nproblem to solve, rather",
    "start": "4046020",
    "end": "4052050"
  },
  {
    "text": "than it actually being a\ntechnological problem to solve.",
    "start": "4052050",
    "end": "4057150"
  },
  {
    "text": "And the next problem\nis, should we be afraid of an imminent\nsingularity, i.e.",
    "start": "4057150",
    "end": "4062960"
  },
  {
    "text": "when machines have artificial\ngeneral intelligence beyond the human level?",
    "start": "4062960",
    "end": "4068230"
  },
  {
    "text": "In particular, would such an\nevent threaten human survival?",
    "start": "4068230",
    "end": "4073630"
  },
  {
    "text": "So this is a concern\nthat is increasingly",
    "start": "4073630",
    "end": "4080450"
  },
  {
    "text": "exploded into the\nmainstream with discussions of AI, existential risk, and in\nquite a few of the discussions",
    "start": "4080450",
    "end": "4088059"
  },
  {
    "text": "that have been leading to\nthe setting up of things like AI safety institutes in\nthe US and UK are motivated by.",
    "start": "4088060",
    "end": "4096318"
  },
  {
    "text": "Maybe there are these worries\nof out-of-control artificial intelligence taking over and\ndeciding to eliminate humanity.",
    "start": "4096319",
    "end": "4107000"
  },
  {
    "text": "So we get these\narticle headlines like \"Pausing AI\nDevelopments Isn't Enough.",
    "start": "4107000",
    "end": "4112009"
  },
  {
    "text": "We Need to Shut It All Down,\"\n\"How Rogue AIs May Arise,\"",
    "start": "4112010",
    "end": "4117369"
  },
  {
    "text": "\"AI Godfather Geoffrey Hinton\nWarns of Dangers As He Quits Google,\" \"We Must Slow Down\nthe Race to Godlike AI.\"",
    "start": "4117370",
    "end": "4127689"
  },
  {
    "text": "I don't personally give these\nconcerns too much credence.",
    "start": "4127689",
    "end": "4136000"
  },
  {
    "text": "And I think there's\nstarted to be increasing pushback against them. So in the other direction,\nFrancois Chollet,",
    "start": "4136000",
    "end": "4144740"
  },
  {
    "text": "who is the architect of\nKeras, argues, \"There does not exist any AI model\nor technique that",
    "start": "4144740",
    "end": "4151390"
  },
  {
    "text": "could represent an extinction\nrisk for humanity, not even if you extrapolate capabilities\nfar into the future via scaling",
    "start": "4151390",
    "end": "4158830"
  },
  {
    "text": "laws. Most arguments\nboil down to, this is a new type of technology.",
    "start": "4158830",
    "end": "4164028"
  },
  {
    "text": "It could happen.\" Joelle Pineau, who's\nMeta AI leader,",
    "start": "4164029",
    "end": "4170979"
  },
  {
    "text": "refers to existential risk\ndiscourse as \"unhinged\" and points out the flaw of a lot\nof the utilitarian argumentation",
    "start": "4170979",
    "end": "4180619"
  },
  {
    "text": "that goes along with discussions\nof these risks, which is, if you say the elimination of\nhumanity is infinitely bad,",
    "start": "4180620",
    "end": "4192600"
  },
  {
    "text": "that means any nonzero chance\nmultiplied by infinity will be",
    "start": "4192600",
    "end": "4198620"
  },
  {
    "text": "bigger than the badness of\nanything else that could happen in the world but that that isn't\nactually a sensible way to have",
    "start": "4198620",
    "end": "4206540"
  },
  {
    "text": "rational discussion\nabout the outcomes. And many people,\nincluding Timnit Gebru,",
    "start": "4206540",
    "end": "4211740"
  },
  {
    "text": "have argued that a lot of the-- well, a lot of what the--",
    "start": "4211740",
    "end": "4218600"
  },
  {
    "text": "a lot of the outcome of this\nfocus on existential risk, and if you're more\ncynical, a lot",
    "start": "4218600",
    "end": "4224450"
  },
  {
    "text": "of the purpose of this\nfocus of on existential risk is to distract away from\nthe immediate harms that",
    "start": "4224450",
    "end": "4232340"
  },
  {
    "text": "are arising from\ncompanies deploying automated systems, including\ntheir biases, worker",
    "start": "4232340",
    "end": "4237890"
  },
  {
    "text": "exploitation, copyright\nviolation, disinformation, growing concentration of\npower, and regulatory capture",
    "start": "4237890",
    "end": "4245450"
  },
  {
    "text": "by leading AI companies. And that's something that\nis worth thinking about,",
    "start": "4245450",
    "end": "4252110"
  },
  {
    "text": "that behind all the discussions\nabout amazing AIs and all the things we can do with them,\nlike get our homework done",
    "start": "4252110",
    "end": "4259489"
  },
  {
    "text": "or generate wonderful\nimages, that there are lots of things underneath\nabout disinformation, deception,",
    "start": "4259490",
    "end": "4267590"
  },
  {
    "text": "hallucinations, problems of\nhomogeneity, of decision making,",
    "start": "4267590",
    "end": "4272699"
  },
  {
    "text": "violation of copyrights,\nand people's creativity, lots of carbon emissions,\nerosion of rich human practices.",
    "start": "4272700",
    "end": "4282420"
  },
  {
    "text": "So we need to be conscious\nof the present-day harms that can come about from AI.",
    "start": "4282420",
    "end": "4288410"
  },
  {
    "text": "And for NLP as well, there\nare the various kinds of harms that we've\ntouched on, which",
    "start": "4288410",
    "end": "4293420"
  },
  {
    "text": "include generating\noffensive content, generating untruthful content,\nand enabling disinformation.",
    "start": "4293420",
    "end": "4300550"
  },
  {
    "text": "So the disinformation\none is an interesting one that if models can\nreason well about texts,",
    "start": "4300550",
    "end": "4308080"
  },
  {
    "text": "can they also be\npersuasive in communicating incorrect information\nor opinions to users?",
    "start": "4308080",
    "end": "4315280"
  },
  {
    "text": "Perhaps there are\nnew possibilities for doing very personalized\nmisinformation propagation that",
    "start": "4315280",
    "end": "4322530"
  },
  {
    "text": "easily persuades human beings\nbetter than traditional methods of political advertising.",
    "start": "4322530",
    "end": "4329349"
  },
  {
    "text": "And there's starting to be\nevidence that that's true. It's still being debated\nin the literature.",
    "start": "4329350",
    "end": "4335170"
  },
  {
    "text": "But there's now multiple\nstudies suggesting that humans can be influenced by\ndisinformation generated by AIs,",
    "start": "4335170",
    "end": "4343660"
  },
  {
    "text": "and it seems reasonable\nto think that we're going to start to\nsee more use of that in political systems\nand elsewhere,",
    "start": "4343660",
    "end": "4351070"
  },
  {
    "text": "which is potentially\nquite scary. And perhaps the worst of it\nisn't going to be text based.",
    "start": "4351070",
    "end": "4358670"
  },
  {
    "text": "It's likely that\nvisual fakes are",
    "start": "4358670",
    "end": "4363790"
  },
  {
    "text": "going to be even more compelling\nin political contexts. And this sort of\nseems like whether it",
    "start": "4363790",
    "end": "4370480"
  },
  {
    "text": "happens in the US\nfor this election or in other countries\nand their elections,",
    "start": "4370480",
    "end": "4375739"
  },
  {
    "text": "that we're likely to see\nsome major incidents where AI-generated fakes\ncan be seen of having",
    "start": "4375740",
    "end": "4382900"
  },
  {
    "text": "a major impact on\npolitical systems. So I think, really,\nwhat we should",
    "start": "4382900",
    "end": "4389650"
  },
  {
    "text": "be doing is worrying not\nabout existential risks but worrying about what people\nand organizations with power",
    "start": "4389650",
    "end": "4397840"
  },
  {
    "text": "will use AI to do, that\nthis is a pattern that we've noticed multiple times\nalso with social media.",
    "start": "4397840",
    "end": "4407020"
  },
  {
    "text": "In the early days\nof social media, there was the idea that this was\nmeant to lead to new freedoms",
    "start": "4407020",
    "end": "4412900"
  },
  {
    "text": "for people across\nthe globe, bringing the positives of free\npolitical thought and improved",
    "start": "4412900",
    "end": "4419139"
  },
  {
    "text": "human lives. In large measure, that\nisn't what's happened. The new technologies get\ncaptured by powerful people",
    "start": "4419140",
    "end": "4426730"
  },
  {
    "text": "and organizations who master\nthe new technological options, and AI and machine learning\nis being increasingly used",
    "start": "4426730",
    "end": "4435610"
  },
  {
    "text": "for surveillance and control. And we're seeing that around\nthe world at the moment.",
    "start": "4435610",
    "end": "4442330"
  },
  {
    "text": "So my final thought\nto end with is to a thought about Carl Sagan.",
    "start": "4442330",
    "end": "4448460"
  },
  {
    "text": "So when I was young, many\ndecades ago, Carl Sagan did the series\nCosmos on television,",
    "start": "4448460",
    "end": "4456770"
  },
  {
    "text": "explaining the miracles\nof the universe. And at the time, when I was\na teenager, I loved Cosmos.",
    "start": "4456770",
    "end": "4464329"
  },
  {
    "text": "Now, this was a long time ago. So much more recently, there's\nnow a new generation of Cosmos,",
    "start": "4464330",
    "end": "4471340"
  },
  {
    "text": "and the book is advertised on\nthe basis of with a new foreword by Neil deGrasse Tyson.",
    "start": "4471340",
    "end": "4479190"
  },
  {
    "text": "I think-- Carl Sagan\nwas a good guy. And he didn't only write Cosmos.",
    "start": "4479190",
    "end": "4486220"
  },
  {
    "text": "He wrote a number\nof other books. And another of\nthe books he wrote was The Demon-Haunted\nWorld, which",
    "start": "4486220",
    "end": "4493110"
  },
  {
    "text": "has a theme that's a\nlittle bit closer to some",
    "start": "4493110",
    "end": "4498360"
  },
  {
    "text": "of the things that connect with\nwhat we're dealing with here. So in that book, he writes, \"I\nhave a foreboding of a world",
    "start": "4498360",
    "end": "4507780"
  },
  {
    "text": "in my children's or\ngrandchildren's time, when awesome technological\npowers are in the hands",
    "start": "4507780",
    "end": "4513840"
  },
  {
    "text": "of a very few, and no one\nrepresenting the public interest can even grasp the issues, when\nthe people have lost the ability",
    "start": "4513840",
    "end": "4521850"
  },
  {
    "text": "to set their own agendas or\nknowledgeably question those in authority, when clutching\nour crystals and nervously",
    "start": "4521850",
    "end": "4528830"
  },
  {
    "text": "consulting our horoscopes, our\ncritical faculties in decline, unable to distinguish between\nwhat feels good and what's true,",
    "start": "4528830",
    "end": "4537659"
  },
  {
    "text": "we slide, almost\nwithout noticing, back into superstition\nand darkness.\"",
    "start": "4537660",
    "end": "4543380"
  },
  {
    "text": "I think if you look around\nthe US and many other parts of the world today, this is\nactually much more the risk",
    "start": "4543380",
    "end": "4551510"
  },
  {
    "text": "that humanity is facing\nand why education, which we try to provide at\nStanford and other places,",
    "start": "4551510",
    "end": "4559770"
  },
  {
    "text": "is an important thing\nthat should be valued and all the other\nthings that go along",
    "start": "4559770",
    "end": "4566360"
  },
  {
    "text": "with this, of having things\nlike open source that supports the broad\ndissemination of learning.",
    "start": "4566360",
    "end": "4574190"
  },
  {
    "text": "Thank you. [APPLAUSE] ",
    "start": "4574190",
    "end": "4586000"
  }
]
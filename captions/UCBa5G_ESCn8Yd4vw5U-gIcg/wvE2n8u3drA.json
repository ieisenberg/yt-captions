[
  {
    "start": "0",
    "end": "6000"
  },
  {
    "start": "0",
    "end": "5080"
  },
  {
    "text": "Thanks to inviting me\nfor the talk today. And I'll be just talking\nabout transformers",
    "start": "5080",
    "end": "10330"
  },
  {
    "start": "6000",
    "end": "95000"
  },
  {
    "text": "for music and\naudio, which is very different than what all of this\nwere doing this past course.",
    "start": "10330",
    "end": "16870"
  },
  {
    "text": "I'm also the only\nspeaker from Stanford. So I have to do a good job. So you can see very\ngood slides because I'm",
    "start": "16870",
    "end": "22990"
  },
  {
    "text": "kind of representing the\nUniversity in some sense. So yeah, so the flow\nof the talk today",
    "start": "22990",
    "end": "28270"
  },
  {
    "text": "is basically like I'll be\nthrowing a lot of stuff. It's kind of like a\nbuffet style and then you feel free to like or\ndislike whatever you want.",
    "start": "28270",
    "end": "36670"
  },
  {
    "text": "And I'll be talking mostly\nabout three papers of what I've been working on and start with\nintroducing what transformers",
    "start": "36670",
    "end": "44620"
  },
  {
    "text": "are from a different\nperspective, what audio representations are,\ntalk about generative model",
    "start": "44620",
    "end": "51730"
  },
  {
    "text": "for audio, which is\njust doing like language modeling on the sample level. Then I'll talk about how can one\ndo language modeling for speech",
    "start": "51730",
    "end": "60947"
  },
  {
    "text": "and audio which is\ndifferent than what people do for text, what\nare the current trends in the literature.",
    "start": "60947",
    "end": "67390"
  },
  {
    "text": "Finally, I'll briefly\nmention similar stuff as to what was happening in\ncomputer vision with regard",
    "start": "67390",
    "end": "73570"
  },
  {
    "text": "to vision transformers, what can\nwe adopt similar ideas for all your transformers and throw\nin a bit of signal processing",
    "start": "73570",
    "end": "80050"
  },
  {
    "text": "to improve the performance. I've been told that the talk\nis about 35 to 40 minutes with about 15 minutes\nof Q&A. I should also",
    "start": "80050",
    "end": "87670"
  },
  {
    "text": "say that all of the\nopinions are mine and Stanford or\nany other professor is not responsible for any\nof the mistake which I do.",
    "start": "87670",
    "end": "95950"
  },
  {
    "start": "95000",
    "end": "302000"
  },
  {
    "text": "So transformers have\nkind of revolutionized in the way everyone was\napproaching deep learning.",
    "start": "95950",
    "end": "103000"
  },
  {
    "text": "Before that, it\nwas all about CNNs. And mostly all of\nthese prominent models",
    "start": "103000",
    "end": "108367"
  },
  {
    "text": "have been coming in waves. So there was a time\nwhen everyone was just applying CNNs.",
    "start": "108367",
    "end": "113380"
  },
  {
    "text": "Then came a time\nwhere people started adopting CNNs and some sort\nof derivative contributions",
    "start": "113380",
    "end": "118479"
  },
  {
    "text": "and slowly the\nrecurrent networks were getting out of fashion. Now it seems like transformers\nare in fashion all the time.",
    "start": "118480",
    "end": "125860"
  },
  {
    "text": "So it seems to be solving almost\nevery single problem which is being thrown at them.",
    "start": "125860",
    "end": "132620"
  },
  {
    "text": "So what's special\nabout transformers? One of the fact that struck\nme was their simplicity which",
    "start": "132620",
    "end": "139180"
  },
  {
    "text": "is if you think about it-- and it has been\nhugely popular also.",
    "start": "139180",
    "end": "145690"
  },
  {
    "text": "So it was just released in\n2018 and within three years, it has about 30,000\ncitations and it",
    "start": "145690",
    "end": "151510"
  },
  {
    "text": "is kind of solving every single\nproblem in every single domain. It has its limitations\nthough, also.",
    "start": "151510",
    "end": "158600"
  },
  {
    "text": "But if you think\nabout it, in a way, transformers are\nbasically like a way of just cascading self-attention\nwith feature learning.",
    "start": "158600",
    "end": "167060"
  },
  {
    "text": "And if we keep on doing\nit over and over again, then the model in a way learns\nwhich parts of the input",
    "start": "167060",
    "end": "172180"
  },
  {
    "text": "are important and keep on\ntransforming them, removing the content which\nare not important,",
    "start": "172180",
    "end": "177340"
  },
  {
    "text": "and just have the\nlimited information which is just responsible\nfor a particular task.",
    "start": "177340",
    "end": "184180"
  },
  {
    "text": "And it has been\nvery, very difficult to keep up with the literature. I have put it as a\njoke here, but then",
    "start": "184180",
    "end": "191440"
  },
  {
    "text": "even Twitter's\nrecommendation engine would kind of just getting out of-- they were getting haywire as\nto why is Chris Manning just",
    "start": "191440",
    "end": "199450"
  },
  {
    "text": "searching over transformers. And that was way back in 2020. So it has been difficult\nfor researchers",
    "start": "199450",
    "end": "206530"
  },
  {
    "text": "also to keep up with the\npace of what's going on. Just before transformers,\nall of the NLP community",
    "start": "206530",
    "end": "213070"
  },
  {
    "text": "was just going gaga\nabout bidirectional LSTMs with attention. So every single\npaper before 2017",
    "start": "213070",
    "end": "218920"
  },
  {
    "text": "was just like you have\nencoder and LSTM layers. You keep on adding\nmultiple layers.",
    "start": "218920",
    "end": "225940"
  },
  {
    "text": "And then after that, you\nhave attention mechanism which just learns\nat what's important and then just keeps on decoding\nsequentially one at a time.",
    "start": "225940",
    "end": "234700"
  },
  {
    "text": "But this was not kind of\nlike an ideal way to do it because what turns out is\nwhen we start throwing longer",
    "start": "234700",
    "end": "241569"
  },
  {
    "text": "sequences, the\nconnections are no longer",
    "start": "241570",
    "end": "247090"
  },
  {
    "text": "storing the gradient updates\nin a way it should be doing. So what the researchers\nfrom Google said--",
    "start": "247090",
    "end": "253390"
  },
  {
    "text": "instead of having\njust a attention layer at the very last encoding, we\nwould just have these attention",
    "start": "253390",
    "end": "260680"
  },
  {
    "text": "mechanisms at every single\nlayer which, in a way, would just learn what's\nimportant for a particular",
    "start": "260680",
    "end": "265840"
  },
  {
    "text": "problem at that\nparticular layer and we keep on doing it\nover and over again.",
    "start": "265840",
    "end": "272290"
  },
  {
    "text": "So then the whole idea of\ntransformers and attention mechanism cascaded one\nafter the other came.",
    "start": "272290",
    "end": "279452"
  },
  {
    "text": "And I love going to the\ndetails because this is the last class of the course. But then usual\ntricks do help across",
    "start": "279452",
    "end": "285933"
  },
  {
    "text": "the neural net\nliterature which is like having\nmulti-head attentions, having skip connection\nand layer norms.",
    "start": "285933",
    "end": "292210"
  },
  {
    "text": "So all of these things,\nthey are not only getting gains for\ntransformers themselves,",
    "start": "292210",
    "end": "297820"
  },
  {
    "text": "but they can be just applied to\nany single other architecture also.",
    "start": "297820",
    "end": "303490"
  },
  {
    "start": "302000",
    "end": "463000"
  },
  {
    "text": "The other thing which\nis helping this research is basically the compute power\nis getting better and better.",
    "start": "303490",
    "end": "309370"
  },
  {
    "text": "So all of these big\ncompanies are just throwing massive amounts\nof computing resources",
    "start": "309370",
    "end": "314890"
  },
  {
    "text": "at solving very, very\nsimple and trivial tasks. The top of the hill being\nthe switch transformer",
    "start": "314890",
    "end": "321170"
  },
  {
    "text": "which was discussed\nin the course also. ",
    "start": "321170",
    "end": "326230"
  },
  {
    "text": "But one of the thing which I\nthink started all of this trend was ELMo, which\nwas just learning",
    "start": "326230",
    "end": "331240"
  },
  {
    "text": "these contextualized\nrepresentations for natural language processing. And that model right\nhere was perhaps one",
    "start": "331240",
    "end": "337540"
  },
  {
    "text": "of the first kind of\nmodel 1.0 or something",
    "start": "337540",
    "end": "345640"
  },
  {
    "text": "or 1.1 in terms of\nbringing and ushering in the whole revolution.",
    "start": "345640",
    "end": "350740"
  },
  {
    "text": "You can see how similar these\nkinds of models look like. BERT was basically\nlike inspired heavily",
    "start": "350740",
    "end": "357250"
  },
  {
    "text": "from ELMo in which they just\nreplaced one of the LSTM layers with transformer models.",
    "start": "357250",
    "end": "364300"
  },
  {
    "text": "So a point to note\nalso is irrespective of natural language\nprocessing or other domain,",
    "start": "364300",
    "end": "370810"
  },
  {
    "text": "these can be adopted in\na variety of domains. And for today's talk, I'll be\njust adopting them to audio.",
    "start": "370810",
    "end": "377800"
  },
  {
    "text": "So I basically start\nwith introducing people what audio\nrepresentations are and just for the\nsake of completeness",
    "start": "377800",
    "end": "385910"
  },
  {
    "text": "talk about spectrograms. So you can take any\ntime domain signal",
    "start": "385910",
    "end": "391419"
  },
  {
    "text": "and you can\ndecompose that signal into a variety of\nbusiness functions.",
    "start": "391420",
    "end": "399770"
  },
  {
    "text": "And if you take up\na Fourier transform, you're kind of like decomposing\nthe actual time domain",
    "start": "399770",
    "end": "406090"
  },
  {
    "text": "signal into its sinusoidal\npieces components. So if you have a\nwaveform here like this,",
    "start": "406090",
    "end": "412460"
  },
  {
    "text": "which is a sum of\nthree pure sinusoids, then their sum\nbasically is this.",
    "start": "412460",
    "end": "417490"
  },
  {
    "text": "And you can see that\nwhen you take a Fourier transform and its\nmagnitude, you kind of",
    "start": "417490",
    "end": "423039"
  },
  {
    "text": "have their strength of the\nindividual components shown",
    "start": "423040",
    "end": "428140"
  },
  {
    "text": "here. So you can take\nanother waveform, let's say a square wave, and what you\nhave is basically much richer",
    "start": "428140",
    "end": "436240"
  },
  {
    "text": "sinusoidal decomposition\nbecause it is kind of a discontinuous signal. So you need many more\nsinusoids to represent",
    "start": "436240",
    "end": "442270"
  },
  {
    "text": "that particular signal as\nclose to the actual signal as possible. And here also you can see that--",
    "start": "442270",
    "end": "448360"
  },
  {
    "text": "OK, if this was a\nsquare wave, then it is actually made up\nof a lot of sinusoids",
    "start": "448360",
    "end": "455980"
  },
  {
    "text": "where each of the bar here\nrepresents the strength of the particular sinusoid.",
    "start": "455980",
    "end": "462310"
  },
  {
    "text": "From an optimization\nperspective, I mean, this right away is\nsuboptimal, right, because you're kind of fixing\nup the number of sinusoids",
    "start": "462310",
    "end": "471129"
  },
  {
    "start": "463000",
    "end": "870000"
  },
  {
    "text": "you are using for\nrepresenting a square wave. I would have rather\nused a basis function",
    "start": "471130",
    "end": "476150"
  },
  {
    "text": "which was a square wave itself\nthan a sinusoidal signal, right?",
    "start": "476150",
    "end": "481360"
  },
  {
    "text": "The second thing\nis like even if you are taking a sinusoid signal,\nwe kind of are just putting them",
    "start": "481360",
    "end": "488080"
  },
  {
    "text": "in a equidistant space. So you are kind of dividing\nthe whole frequency axis into equidistant bends.",
    "start": "488080",
    "end": "494500"
  },
  {
    "text": "And each of the\nbends are responsible for like a particular\nsinusoid a lot.",
    "start": "494500",
    "end": "499690"
  },
  {
    "text": "So that is like a traditional\nFourier representation for representing any signal. ",
    "start": "499690",
    "end": "508930"
  },
  {
    "text": "What are spectrograms? But in reality, all of these\nsignals are discontinuous.",
    "start": "508930",
    "end": "514959"
  },
  {
    "text": "All of these signals\nvary quite a bit, right? So you can have a\nsignal while I'm",
    "start": "514960",
    "end": "520059"
  },
  {
    "text": "speaking which is like a square\nwave for a certain period of time and then\nit gets sinusoidal and then it becomes\nsomething else.",
    "start": "520059",
    "end": "526640"
  },
  {
    "text": "So what we really\nneed is in a way to kind of take batches\nof the input signal",
    "start": "526640",
    "end": "532839"
  },
  {
    "text": "and take Fourier transform\nof these individual batches. I'm deliberately using\nthe word batches,",
    "start": "532840",
    "end": "538029"
  },
  {
    "text": "but you can like--\nin traditional terms, you're windowing the signal. So right here, you can see that\nyou have a continuous signal,",
    "start": "538030",
    "end": "545140"
  },
  {
    "text": "you keep on windowing it, you\napply the Fourier transform, and what you get is\nbasically like a spectrogram",
    "start": "545140",
    "end": "552130"
  },
  {
    "text": "representation of the signal. So right here, what\nyou're seeing basically is with each of the slices,\nthe signal kind of looked",
    "start": "552130",
    "end": "559690"
  },
  {
    "text": "like this after taking\nthe Fourier transform with the waveform,\nwhich is there below.",
    "start": "559690",
    "end": "564880"
  },
  {
    "text": "And what you do is for\nspectrogram representation, you keep on stacking these\nFourier transform slides, the magnitude of the\nFourier transform slices.",
    "start": "564880",
    "end": "571780"
  },
  {
    "text": "And in this way, you kind of\nget like a 2D representation of audio segments. And if you're coming\nfrom a vision background,",
    "start": "571780",
    "end": "578680"
  },
  {
    "text": "it is basically all\nof the things which you are doing in vision\nwould just work well if you just apply them to these\n2D spectral representations.",
    "start": "578680",
    "end": "587350"
  },
  {
    "text": "I'll quickly play\nhow the spectrograms look like for a wide area\nof like common sounds.",
    "start": "587350",
    "end": "593470"
  },
  {
    "start": "593470",
    "end": "635569"
  },
  {
    "text": "So you could see like\nfor spectrograms you have kind of like a time\naxis on your x-axis.",
    "start": "635570",
    "end": "641070"
  },
  {
    "text": "And then, you have a\nfrequency axis on y-axis. And then, for whatever is\nyour signal of interest,",
    "start": "641070",
    "end": "646190"
  },
  {
    "text": "you're basically putting\nthese slices together, and different sound gives\nyou different spectral representation.",
    "start": "646190",
    "end": "651710"
  },
  {
    "text": "So it's kind of a vision\nproblem just in this sort of like Fourier space. ",
    "start": "651710",
    "end": "658390"
  },
  {
    "text": "So there can be different\nkinds of representations also. So one, you could just take\nthese slices of Fourier",
    "start": "658390",
    "end": "666350"
  },
  {
    "text": "transform and then do like\na linear mapping to them so that you are kind of\nin a way making these",
    "start": "666350",
    "end": "673069"
  },
  {
    "text": "as close to how humans hear. So you can have a\nlog of the frequency and the y-axis and sort\nof common frequency.",
    "start": "673070",
    "end": "679250"
  },
  {
    "text": "And then, you get a constant\nQ-like representation. The advantage of\nthis being you can see that for\ndifferent frequencies,",
    "start": "679250",
    "end": "685800"
  },
  {
    "text": "the spacing in\nbetween the harmonics kind of remains the same. So if you are creating\nunusual filters,",
    "start": "685800",
    "end": "691040"
  },
  {
    "text": "then that's of a huge\nadvantage because the signal-- one component of the\ninvariance is gone, and you can just learn\nthese filters, which",
    "start": "691040",
    "end": "697430"
  },
  {
    "text": "are catching on to these\nconstant templates of Fourier slices.",
    "start": "697430",
    "end": "703160"
  },
  {
    "text": "You can have Mel\nfilterbank coefficients, or you can have the\nraw waveform also.",
    "start": "703160",
    "end": "708980"
  },
  {
    "text": "For raw waveforms,\nbasically there are two things which we\nhave to keep in mind. One is the sampling rate.",
    "start": "708980",
    "end": "714350"
  },
  {
    "text": "So we kind of take\nthe continuous signal, and then we discretize\nthe continuous signal.",
    "start": "714350",
    "end": "721100"
  },
  {
    "text": "So one parameter is how\nfast we are sampling the continuous signal,\nso that's typically on the order of like 16,000\nor 8,000 times a second",
    "start": "721100",
    "end": "728509"
  },
  {
    "text": "if you're on telephonic speech. The other thing which we\nalso have is how many levels",
    "start": "728510",
    "end": "733760"
  },
  {
    "text": "we are dividing\nyour vertical axis. So in this case, you can\nsee that each of the dots is basically one level.",
    "start": "733760",
    "end": "739500"
  },
  {
    "text": "And typically, people\nuse 8-bit quantizers or 16-bit quantizers. So in a way, you can think\nabout that for every one",
    "start": "739500",
    "end": "745430"
  },
  {
    "text": "second of audio\nwhich we would hear, you would have 16,000 samples.",
    "start": "745430",
    "end": "751010"
  },
  {
    "text": "And then each of\nthe 16,000 samples are allowed to take one of\nthe levels between 0 to 255.",
    "start": "751010",
    "end": "758600"
  },
  {
    "text": "If I can take the problem of\nlike continuous audio and just have it in terms of this\nsort of discrete space,",
    "start": "758600",
    "end": "765230"
  },
  {
    "text": "then basically I'm just\ngoing to the territory of doing language modeling.",
    "start": "765230",
    "end": "771170"
  },
  {
    "text": "In my first paper,\nso I discussed this, how can we do\ngenerative modeling",
    "start": "771170",
    "end": "776269"
  },
  {
    "text": "for raw audio, which is similar\nto wavenets using transformers.",
    "start": "776270",
    "end": "781520"
  },
  {
    "text": "I'll be putting QR codes. If you like the\nstuff what I'm doing, and if you think that\nthis is relevant to you,",
    "start": "781520",
    "end": "787910"
  },
  {
    "text": "please cite or please have a\nlook in terms of the QR codes,",
    "start": "787910",
    "end": "793040"
  },
  {
    "text": "so, yeah. So I'll start with the first\nsubtopic of today's talk, which is what are\nwavenets and how",
    "start": "793040",
    "end": "803660"
  },
  {
    "text": "do we do like this generative\nmodeling with raw audio?  So in single word, you\ncan think about this",
    "start": "803660",
    "end": "808880"
  },
  {
    "text": "as doing like language modeling,\nor these 255 states of audio. So you can throw on your\nfavorite transformer",
    "start": "808880",
    "end": "815850"
  },
  {
    "text": "like Transformer-XL or GPT or\nwhatever you want to call it.",
    "start": "815850",
    "end": "821569"
  },
  {
    "text": "And just treat the\nproblem as if you're trying to predict what are\nthe levels that are 255. And you have to predict the next\nlevel given a certain context.",
    "start": "821570",
    "end": "829520"
  },
  {
    "text": "That's what Wavenet was doing. So the way you are modeling\nthe probability distribution",
    "start": "829520",
    "end": "835370"
  },
  {
    "text": "of continuous space\nis basically you're trying to predict what's the\nprobability of the next sample given some sparse context.",
    "start": "835370",
    "end": "842600"
  },
  {
    "text": "And Wavenet has\nbeen hugely popular because it has over\n3,000 citations. And it has been a core building\nblock for almost all speech",
    "start": "842600",
    "end": "851120"
  },
  {
    "text": "and audio related problems. You can think about\nspeech to text or text to speech synthesis, instrument\nconversion, packet loss",
    "start": "851120",
    "end": "859070"
  },
  {
    "text": "concealment of internet\nspeech denoising. So wherever there is some sort\nof element of modifying audio,",
    "start": "859070",
    "end": "865550"
  },
  {
    "text": "people have been using Wavenet\nas a core building block. And raw waveform synthesis\nhas been difficult",
    "start": "865550",
    "end": "872930"
  },
  {
    "start": "870000",
    "end": "1034000"
  },
  {
    "text": "because just the magnitude\nof the problem, if I'm just trying to synthesize\n10 seconds of audio",
    "start": "872930",
    "end": "879050"
  },
  {
    "text": "would just amount to like\nme having a probability distribution over\n160,000 samples.",
    "start": "879050",
    "end": "885800"
  },
  {
    "text": "And I could tell this stuff\nbecause our ears are very, very sensitive to subtle changes.",
    "start": "885800",
    "end": "891050"
  },
  {
    "text": "If I'm off by one\npixel in an image-- the image, like\nmy eyes would not",
    "start": "891050",
    "end": "896510"
  },
  {
    "text": "be as susceptible to noticing\nthat effect versus if I'm off by, say, a few\nsamples in an audio,",
    "start": "896510",
    "end": "904940"
  },
  {
    "text": "it will just catch our\nears pretty quickly. People have been trying\nraw audio synthesis a lot",
    "start": "904940",
    "end": "911000"
  },
  {
    "text": "in the past. And before all of the\ninternet and transformer based approaches kind of like\nWaveRNNs and Sample RNNs",
    "start": "911000",
    "end": "920330"
  },
  {
    "text": "were kind of like state\nof the art models.",
    "start": "920330",
    "end": "925850"
  },
  {
    "text": "On the right I've shown\na Sample RNN model which kind of like models\nthe probability distribution",
    "start": "925850",
    "end": "932852"
  },
  {
    "text": "of what's going to\ncome next, given the past at multiple levels. And this was well done\nby Yoshua Bengio at Mila.",
    "start": "932852",
    "end": "940250"
  },
  {
    "text": "But you can closely see. If you just see\nthis architecture versus a transformer\narchitecture, in a way,",
    "start": "940250",
    "end": "946310"
  },
  {
    "text": "these are starting to\nget very, very similar, because what you're trying to\ndo is that for the probability",
    "start": "946310",
    "end": "951590"
  },
  {
    "text": "distribution here,\nyou're trying to see a lot of local substructures. And then you keep on doing\nit over and over again.",
    "start": "951590",
    "end": "958022"
  },
  {
    "text": "And you can draw parallels,\nlike, OK, attention mechanism should also kind of be\ndoing the same thing.",
    "start": "958022",
    "end": "964011"
  },
  {
    "text": "So this was the kind of\nthe literature in the past.",
    "start": "964012",
    "end": "969220"
  },
  {
    "text": "What we tried to do was we\njust had the WaveNet model and we tried to see whether\ntransformers can beat them.",
    "start": "969220",
    "end": "975790"
  },
  {
    "text": "And our intuition was it\nshould be able to beat them, because they are successful\nall over the other domains,",
    "start": "975790",
    "end": "983019"
  },
  {
    "text": "like in language modeling. So it should-- it should do\nthat for raw waveforms also.",
    "start": "983020",
    "end": "988720"
  },
  {
    "text": "We also try to see whether\nwe can circumvent the order n constraint by conditioning\non the context itself.",
    "start": "988720",
    "end": "997090"
  },
  {
    "text": "And we did not go for\nspecific applications. And we just said, OK, it just\nlooks like modeling behavior.",
    "start": "997090",
    "end": "1002850"
  },
  {
    "text": "How will they do? So the data set for this was\njust like real-world piano",
    "start": "1002850",
    "end": "1008280"
  },
  {
    "text": "recordings. So actual sound\nshould not matter,",
    "start": "1008280",
    "end": "1013410"
  },
  {
    "text": "because the model is agnostic\nto what it is being thrown in. And the setup was\nexactly the same.",
    "start": "1013410",
    "end": "1019680"
  },
  {
    "text": "You are given a certain\ncontext and have to predict the next sample. You do the same\nthing with WaveNet.",
    "start": "1019680",
    "end": "1025500"
  },
  {
    "text": "You do the exact same thing\nwith transformer-based GPT kind of a model and\nsee how well they do.",
    "start": "1025500",
    "end": "1034129"
  },
  {
    "start": "1034000",
    "end": "1204000"
  },
  {
    "text": "I'll briefly chat about\nwhat WaveNet models are. So WaveNet was kind\nof like a convolution",
    "start": "1034130",
    "end": "1040560"
  },
  {
    "text": "based model which\nwas getting rid of like all of the\nvanishing gradient problem by just creating a sequential\nproblem as being learned",
    "start": "1040560",
    "end": "1049590"
  },
  {
    "text": "by a convolutional model. So what they did\nwas basically have these sort of dilation layers\nor a convolution with dilations,",
    "start": "1049590",
    "end": "1058290"
  },
  {
    "text": "which is basically I kind of\nskip in every subsequent layer by one sample. So you can see if I have\na dilation factor of 2",
    "start": "1058290",
    "end": "1067049"
  },
  {
    "text": "with a kernel size of 2, I would\nget this kind of a topology, where my convolution filters\nin the very first layer",
    "start": "1067050",
    "end": "1072690"
  },
  {
    "text": "are just combining\nthe first two samples. Then I skip by one\nin the next layer. And then I skip\nby three, which is",
    "start": "1072690",
    "end": "1079530"
  },
  {
    "text": "I look at like the fourth one\nin the next layer, and so on. The loss is still the same.",
    "start": "1079530",
    "end": "1084580"
  },
  {
    "text": "So I have this network. I learn a latent space. And then I have a cross in--\ncategorical cross entropy",
    "start": "1084580",
    "end": "1090930"
  },
  {
    "text": "loss, which is basically I\nhave to predict the next sample given the previous one.",
    "start": "1090930",
    "end": "1096720"
  },
  {
    "text": "And I just do the exact same\nthing with transformers, also. But then I have to\nmake sure that I do it",
    "start": "1096720",
    "end": "1103140"
  },
  {
    "text": "in a causal manner. So I have something\nwhich is very similar to GPT, in which I have\ncausal masks in my attention",
    "start": "1103140",
    "end": "1109350"
  },
  {
    "text": "mechanism. And I keep doing it\nover and over again. So you have self-attention.",
    "start": "1109350",
    "end": "1115560"
  },
  {
    "text": "After that, you have\nfeed forward layers. You just have a stack of\nthese transformer blocks and see how would they do.",
    "start": "1115560",
    "end": "1123360"
  },
  {
    "text": "So I said intuitively\nit should work. It should be doing better than\nour base WaveNet models, right?",
    "start": "1123360",
    "end": "1132390"
  },
  {
    "text": "Because if you look\nat the topology, we are kind of defining a\ntopology on our ow, right?",
    "start": "1132390",
    "end": "1137440"
  },
  {
    "text": "So what if the current\nprediction at say, layer one were to depend on very way\nback samples, say, instead",
    "start": "1137440",
    "end": "1147967"
  },
  {
    "text": "of the second sample,\nthe 10th sample. So we are kind of ignoring\nall of that topology which would have been important\nfor a prediction",
    "start": "1147967",
    "end": "1154470"
  },
  {
    "text": "of this particular task. Whereas, our transformers with\nthe self-attention mechanism",
    "start": "1154470",
    "end": "1159659"
  },
  {
    "text": "can just learn, OK, which part\nof the samples are important and which are not. And you can keep on\ndoing it iteratively.",
    "start": "1159660",
    "end": "1166740"
  },
  {
    "text": "So it made sense to us\nthat, OK, transform layer should be doing way better\nthan WaveNet models.",
    "start": "1166740",
    "end": "1174990"
  },
  {
    "text": "The second thing which we\ncame across was like, OK, we cannot have a lot of context.",
    "start": "1174990",
    "end": "1180690"
  },
  {
    "text": "For example, the\nattention mechanism needs to store all of\nthose of order n squares.",
    "start": "1180690",
    "end": "1186470"
  },
  {
    "text": "In this case, if I'm storing\ndata at 100 milliseconds, then I have about 1,600 samples.",
    "start": "1186470",
    "end": "1192630"
  },
  {
    "text": "And I need to store 1,600\nby 1,600 at multiple layers. And it just becomes\na huge problem",
    "start": "1192630",
    "end": "1200670"
  },
  {
    "text": "with the data, problem\nwith the memory constraint. So what we said was, OK, what if\nwe just use the context itself",
    "start": "1200670",
    "end": "1209009"
  },
  {
    "start": "1204000",
    "end": "1262000"
  },
  {
    "text": "as a latent code? So in order to have much better\nrepresentation at every layer,",
    "start": "1209010",
    "end": "1216510"
  },
  {
    "text": "we cannot have the huge,\nbig attention matrices. So what we said\nwas we would just",
    "start": "1216510",
    "end": "1222000"
  },
  {
    "text": "do sample-wise conditioning,\nand through our CNN layers just to understand what\nthe latent code would be.",
    "start": "1222000",
    "end": "1228600"
  },
  {
    "text": "So you still have an\nattention mechanism or just a past context. But then I'm also\nconditioning at every sample,",
    "start": "1228600",
    "end": "1236340"
  },
  {
    "text": "OK, what the next sample should\nbe given on-the-spot context embedding. And if you think\nabout it, in a way,",
    "start": "1236340",
    "end": "1242790"
  },
  {
    "text": "it is like, OK, if there are\nfive or six notes being played in a piano, then\nI'm kind of certain",
    "start": "1242790",
    "end": "1247860"
  },
  {
    "text": "which notes will be\nplayed to a certain extent if I just throw in a CNN layer. So I'll use that\ninformation along with what",
    "start": "1247860",
    "end": "1255360"
  },
  {
    "text": "my transformers are learning. And then I would condition it. And I would just use that\nto predict the next sample.",
    "start": "1255360",
    "end": "1263210"
  },
  {
    "start": "1262000",
    "end": "1331000"
  },
  {
    "text": "So for the evaluation\ncriteria, we did not look for negative\nlog likelihood scores.",
    "start": "1263210",
    "end": "1268789"
  },
  {
    "text": "We just looked at how well\nour prediction task was. So we took a stacked\nWaveNet, which",
    "start": "1268790",
    "end": "1275960"
  },
  {
    "text": "was implemented by\nDeepMind and saw that, OK, what was the performance\nusing their benchmarks,",
    "start": "1275960",
    "end": "1282230"
  },
  {
    "text": "and even bigger\nstacked WaveNets. We then took--\nstarted to increase",
    "start": "1282230",
    "end": "1287570"
  },
  {
    "text": "the complexity of\ntransformers and started to see whatever we had proposed\nin terms of conditioning",
    "start": "1287570",
    "end": "1293660"
  },
  {
    "text": "on the vanilla\ntransformer architectures to see how well they do.",
    "start": "1293660",
    "end": "1299509"
  },
  {
    "text": "We did not look for an\napplication specific problem, which is basically like--",
    "start": "1299510",
    "end": "1305510"
  },
  {
    "text": "we don't look at how well\nperceptual tasks are for, like, say, text-to-speech\nsynthesis or speech denoising.",
    "start": "1305510",
    "end": "1311570"
  },
  {
    "text": "We just look at,\nOK, if we are trying to model this using\na cross entropy loss, then with the same\nmodel with the same loss",
    "start": "1311570",
    "end": "1318590"
  },
  {
    "text": "function, how well they do on\nsimilar kind of parameters? So this was the first\nkind of sub-block",
    "start": "1318590",
    "end": "1326150"
  },
  {
    "text": "of how can we use transformers\nfor generative modeling. ",
    "start": "1326150",
    "end": "1332180"
  },
  {
    "start": "1331000",
    "end": "1358000"
  },
  {
    "text": "For the second problem,\nI'll do a quick headaway on how can we use\ntransformers for doing",
    "start": "1332180",
    "end": "1339920"
  },
  {
    "text": "language modeling, which\nis kind of becoming a really fancy term right now. And this work was done by\nJulius Smith way back in 2020.",
    "start": "1339920",
    "end": "1349010"
  },
  {
    "text": "And the goal of this was\ncan we kind of, in a way, do language modeling with\ncontinuous audio sequences.",
    "start": "1349010",
    "end": "1357440"
  },
  {
    "text": "And I briefly mentioned\nabout that in this part of-- in this sub-block of the talk.",
    "start": "1357440",
    "end": "1362990"
  },
  {
    "start": "1358000",
    "end": "1474000"
  },
  {
    "text": " And this is in regard for\nsolving acoustic scene",
    "start": "1362990",
    "end": "1368510"
  },
  {
    "text": "understanding. Which is basically if I'm\ngiven a chunk of audio,",
    "start": "1368510",
    "end": "1374120"
  },
  {
    "text": "then I want to understand\nwhat's in there. And if we could do that\nwell, then, in a way,",
    "start": "1374120",
    "end": "1381890"
  },
  {
    "text": "we can do a lot of\nfancy, nice applications. So for example, if you think\nabout self-driving cars.",
    "start": "1381890",
    "end": "1389060"
  },
  {
    "text": "So Waymo has started to\nincorporate microphones into their self-driving cars. Why? Because say, if there\nis an ambulance coming,",
    "start": "1389060",
    "end": "1396049"
  },
  {
    "text": "or if there is a\nfire truck coming, then that sound would be\npicked up way, way before even",
    "start": "1396050",
    "end": "1403040"
  },
  {
    "text": "than lidars or\neven their sensors. So we want to understand\nthat and take actions",
    "start": "1403040",
    "end": "1408920"
  },
  {
    "text": "based upon that. Apple, during COVID, did\na handwashing detection on their Apple Watch.",
    "start": "1408920",
    "end": "1414470"
  },
  {
    "text": "Because if you could detect when\nsomeone is washing their hands, then you can, in\na way, tell people",
    "start": "1414470",
    "end": "1420500"
  },
  {
    "text": "that you need to wash\nhands for 20 seconds. And then that can be built\nupon as a cool application.",
    "start": "1420500",
    "end": "1426980"
  },
  {
    "text": "It can be used for\nmusic recommendations. So Spotify, YouTube\nMusic, kind of gives very, very\ngood songs which",
    "start": "1426980",
    "end": "1433760"
  },
  {
    "text": "you are listening to which\nare similar in content that you would perhaps like.",
    "start": "1433760",
    "end": "1439340"
  },
  {
    "text": "It can also give really\ncool applications, say, people have tried detecting\ndepression from audio.",
    "start": "1439340",
    "end": "1445850"
  },
  {
    "text": "Or I could detect whether\nI'm coughing or not, or I'm sneezing\nor not, and these can be good medical device--\nmedical applications which",
    "start": "1445850",
    "end": "1455120"
  },
  {
    "text": "can be used along with the\ncurrent diagnosis what doctor provides.",
    "start": "1455120",
    "end": "1460549"
  },
  {
    "text": "So the question was\nbasically, for us, was how can we do\nlanguage modeling",
    "start": "1460550",
    "end": "1466640"
  },
  {
    "text": "in a continuous audio domain. And secondly, how\ncan we train models? Or how should we\napproach doing this?",
    "start": "1466640",
    "end": "1474860"
  },
  {
    "start": "1474000",
    "end": "1560000"
  },
  {
    "text": "So this kind of recipe has\nbecome very, very popular these days in terms of how\nwould you approach this problem.",
    "start": "1474860",
    "end": "1482210"
  },
  {
    "text": "It started with openAI\nand, to a certain extent, DeepMind proposing that\nin terms of VQ-VAE models.",
    "start": "1482210",
    "end": "1491000"
  },
  {
    "text": "But it turns out\ntransformers love operating in discrete spaces as of now.",
    "start": "1491000",
    "end": "1496549"
  },
  {
    "text": "And what they kind of do is as\nlong as your representations are discrete, they\nare very, very good",
    "start": "1496550",
    "end": "1502850"
  },
  {
    "text": "at modeling what's\ngoing to come next. So what people\nhave been proposing",
    "start": "1502850",
    "end": "1508460"
  },
  {
    "text": "as a workaround is you could\ntake up your favorite embedding",
    "start": "1508460",
    "end": "1515690"
  },
  {
    "text": "in some manner. You could take VQ-VAE embeddings\nor you could take a wav2vec. Or in terms of video, you can\njust do classic VGG or ResNet",
    "start": "1515690",
    "end": "1526760"
  },
  {
    "text": "embeddings. You can apply K means\nclustering to it. And K means clustering would\ngive you the discrete codes.",
    "start": "1526760",
    "end": "1534289"
  },
  {
    "text": "You do language modeling\non those discrete codes. And you predict the next code.",
    "start": "1534290",
    "end": "1539299"
  },
  {
    "text": "And in a way, if\nyou're doing this, then you're kind of doing\nlanguage modeling for audio.",
    "start": "1539300",
    "end": "1545092"
  },
  {
    "text": "And if you need to\nget back to the audio, then you already\nsaw with WaveNet that you can condition\nthe WaveNet model to give",
    "start": "1545092",
    "end": "1551780"
  },
  {
    "text": "continuous output. So you can use those\ncodes to get back to the audio similar to\nwhat jukebox and openAI did.",
    "start": "1551780",
    "end": "1560270"
  },
  {
    "start": "1560000",
    "end": "2004000"
  },
  {
    "text": "So I'll quickly mention about\nwhat vector quantization is.",
    "start": "1560270",
    "end": "1566000"
  },
  {
    "text": "It's one of the most\nunderutilized algorithms, to be honest. And what it does\nis basically gives,",
    "start": "1566000",
    "end": "1572240"
  },
  {
    "text": "in a way, discrete codes to\ncontinuous embedding spaces. So how does it do it?",
    "start": "1572240",
    "end": "1578000"
  },
  {
    "text": "So you basically have\nan embedding space,",
    "start": "1578000",
    "end": "1583580"
  },
  {
    "text": "let's say, in 2D right here. You define what are\nthe number of clusters you want to put each of them in.",
    "start": "1583580",
    "end": "1589250"
  },
  {
    "text": "You run k means. And you would certainly\nget these patches of where all of\nthese embeddings,",
    "start": "1589250",
    "end": "1596180"
  },
  {
    "text": "or what would be the\nrepresentative embedding of a continuous embedding. You can take all\nof those patches.",
    "start": "1596180",
    "end": "1602220"
  },
  {
    "text": "And you can see-- you\ncan just number them, or you can just like list them. So in this case, you can perhaps\nhave 25 numbers or 20 numbers,",
    "start": "1602220",
    "end": "1609890"
  },
  {
    "text": "which are, in a way, mapping\nfrom a continuous embedding to a discrete token.",
    "start": "1609890",
    "end": "1617070"
  },
  {
    "text": "This is another\nexample right here. So in our case,\nwhat we did was we",
    "start": "1617070",
    "end": "1622380"
  },
  {
    "text": "took patches of spectrogram,\nwhich are basically very small",
    "start": "1622380",
    "end": "1628050"
  },
  {
    "text": "patches across time\nand then shared all across the frequency axis.",
    "start": "1628050",
    "end": "1633360"
  },
  {
    "text": "You take those patches, you\nlearn embedding representation. In our case, it was just\nthree-layer autoencoder",
    "start": "1633360",
    "end": "1639630"
  },
  {
    "text": "fully connected encoders\nwith three layers of decoders and have a bottleneck\nlayer in between.",
    "start": "1639630",
    "end": "1645420"
  },
  {
    "text": "So that bottleneck\nlayer, basically, is kind of similar to\nthis kind of diagram in 64 dimensional space\nor 128 dimensional space.",
    "start": "1645420",
    "end": "1653519"
  },
  {
    "text": "You take up those\nbottleneck codes. And then you run K\nmeans clustering on it. Suddenly, you-- in a way,\nyou can find discrete codes",
    "start": "1653520",
    "end": "1663540"
  },
  {
    "text": "for continuous embedding spaces,\nor even continuous signals. And since we know\nthat transformers kind",
    "start": "1663540",
    "end": "1669870"
  },
  {
    "text": "of love operating\nin discrete spaces, you can just apply\nlanguage modeling now.",
    "start": "1669870",
    "end": "1675210"
  },
  {
    "text": "And then you can\nsee what you can do. So in our case, we just had\nvery simple, three-layer",
    "start": "1675210",
    "end": "1682260"
  },
  {
    "text": "fully connected\nautoencoder, small patches. The number of\ncodes is important.",
    "start": "1682260",
    "end": "1687570"
  },
  {
    "text": "Because if you have\ntoo many codes, then you are kind\nof just throwing in all kinds of noisy things.",
    "start": "1687570",
    "end": "1693860"
  },
  {
    "text": "I'll give an example of\nwhy the number of codes are important through\nsome examples.",
    "start": "1693860",
    "end": "1699690"
  },
  {
    "text": "And you have too\nlittle codes, what you're doing is you're removing\nall of the information which",
    "start": "1699690",
    "end": "1706530"
  },
  {
    "text": "was relevant. And you're just kind of\naveraging them all out. ",
    "start": "1706530",
    "end": "1712350"
  },
  {
    "text": "I'd start with--\nso this idea first was proposed by jukebox,\nwhich did it for music.",
    "start": "1712350",
    "end": "1720280"
  },
  {
    "text": "So you do the exact same\nthing what I talked about in a slightly different\nmanner, in a way that, OK,",
    "start": "1720280",
    "end": "1726330"
  },
  {
    "text": "you cannot learn codes\nfor longer sequences. So you, in a way,\nlearn sequences",
    "start": "1726330",
    "end": "1732600"
  },
  {
    "text": "which are just moving\nslowly and which are looking at only a\ncertain amount of audio.",
    "start": "1732600",
    "end": "1737799"
  },
  {
    "text": "So we kind of encode this\nat these discrete levels, which are basically like--",
    "start": "1737800",
    "end": "1743382"
  },
  {
    "text": "all of these,\nbasically, are codes. So at every point, I\ndefine, OK, this audio had, perhaps, code number 55.",
    "start": "1743382",
    "end": "1750630"
  },
  {
    "text": "And in the next level,\nperhaps, it had code number 2. And the very top, perhaps\nit had code number 2,000.",
    "start": "1750630",
    "end": "1756450"
  },
  {
    "text": "So in a way, I'm\ndiscretizing the whole codes. Now, what I do is I take up\nmy favorite transform model,",
    "start": "1756450",
    "end": "1763500"
  },
  {
    "text": "perhaps a causal\nautoregressive one, and I say that, OK,\ngiven these codes,",
    "start": "1763500",
    "end": "1769290"
  },
  {
    "text": "try to predict what\ncodes would come next. And for sure,\ntransformers can do that. So I would generate the\ncodes in the future.",
    "start": "1769290",
    "end": "1776850"
  },
  {
    "text": "Once I've generated the\ncodes in the future, I can say that, OK,\nthis problem now is kind of like a\ntext-to-speech problem, right?",
    "start": "1776850",
    "end": "1783630"
  },
  {
    "text": "Because I have this\ndiscrete codes. Text to speech, in a way, is\ngoing from discrete letters",
    "start": "1783630",
    "end": "1788700"
  },
  {
    "text": "to continuous audio. So I would throw in the\nfanciest, which was WaveNet,",
    "start": "1788700",
    "end": "1793770"
  },
  {
    "text": "I would just get back the code. And I would get the\ngenerated audio. So this was, in a\nway, what I described.",
    "start": "1793770",
    "end": "1802350"
  },
  {
    "text": "That they take up\na continuous audio. They have these compressed\ncodes which they encode",
    "start": "1802350",
    "end": "1808080"
  },
  {
    "text": "using a CNN in this case. The method doesn't matter. You can throw in\nthe fancier stuff,",
    "start": "1808080",
    "end": "1813720"
  },
  {
    "text": "like embedding or\nlatent representation on those continuous code. You generate the\npatterns, which are",
    "start": "1813720",
    "end": "1820170"
  },
  {
    "text": "what's going to happen\nnext in the future. And then you decode back\nusing a fancy WaveNet",
    "start": "1820170",
    "end": "1825240"
  },
  {
    "text": "or state-of-the-art model. So this was what we were\ndoing for music synthesis.",
    "start": "1825240",
    "end": "1832200"
  },
  {
    "text": "What we said was-- yeah, this is good. This can generate\ngood amount of music. But what-- can\nthese models be used",
    "start": "1832200",
    "end": "1841140"
  },
  {
    "text": "for generating\ngood representation of the current audio?",
    "start": "1841140",
    "end": "1847860"
  },
  {
    "text": "And the goal there was\ncan language models learn representation\nwhich can just",
    "start": "1847860",
    "end": "1852929"
  },
  {
    "text": "encapsulate whatever we are kind\nof giving as an input signal?",
    "start": "1852930",
    "end": "1859090"
  },
  {
    "text": "So in this case, what we\ntried after that was kind of-- you kind of do exactly\nkind of similar ideas.",
    "start": "1859090",
    "end": "1866790"
  },
  {
    "text": "But instead of doing on VA-VAE\nend-to-end learned encodings,",
    "start": "1866790",
    "end": "1872040"
  },
  {
    "text": "we just applied vanilla K means\nclustering similar to what I described earlier. If you do on\nspectrogram patches,",
    "start": "1872040",
    "end": "1878280"
  },
  {
    "text": "so you take up these\nspectrograms of audio. And you just divide them\ninto very small chunks,",
    "start": "1878280",
    "end": "1884090"
  },
  {
    "text": "learn autoencoder encodings\nfor each of those chunks, run K means clustering.",
    "start": "1884090",
    "end": "1890370"
  },
  {
    "text": "In this case, let's say,\nI'm learning 16 codes, represent the continuous audio\nin terms of the 16 codes,",
    "start": "1890370",
    "end": "1898380"
  },
  {
    "text": "have a transformer which can\nperhaps predict the next code. And if I keep on getting better\nand better at predicting what's",
    "start": "1898380",
    "end": "1905370"
  },
  {
    "text": "going to happen next,\nthen in this linear layer, I should be encapsulating\nwhat's important",
    "start": "1905370",
    "end": "1911370"
  },
  {
    "text": "or what's a good summary of\nwhat has happened in the past.",
    "start": "1911370",
    "end": "1916880"
  },
  {
    "text": "So that was kind of our\nintuition behind trying this. And as I explained,\nthe number of codes",
    "start": "1916880",
    "end": "1923650"
  },
  {
    "text": "play a very important role. You can see here, these are just\ntwo piano notes switching one",
    "start": "1923650",
    "end": "1929140"
  },
  {
    "text": "after the other. If I just have 16\nnumber of codes, it just happens to\nhave just a single line",
    "start": "1929140",
    "end": "1935590"
  },
  {
    "text": "of encoding, a single code\nassigned to all of this. Whereas, if I'm\nassigning more codes,",
    "start": "1935590",
    "end": "1941080"
  },
  {
    "text": "then it becomes kind of like\na fine-grained prediction, where I'm actually able to get\nwhat the individual notes are.",
    "start": "1941080",
    "end": "1949360"
  },
  {
    "text": "Recently, Facebook also\nsaid, OK, they just had a different name to\nthe whole thing, which",
    "start": "1949360",
    "end": "1955299"
  },
  {
    "text": "is we can just call this\nas TextLess NLP also. In the sense that,\nOK, you can do an LP",
    "start": "1955300",
    "end": "1962470"
  },
  {
    "text": "without having access to text. But the idea is\nvery, very similar. You have an encoder, which is\nexactly similar to, say, what",
    "start": "1962470",
    "end": "1968830"
  },
  {
    "text": "openAPI was using, we\nhave a VQ-VAE, wav2vec, or whatever you want to do. You can apply K means\nclustering to it.",
    "start": "1968830",
    "end": "1975309"
  },
  {
    "text": "We apply language models to it. And instead of a\ndecoder in WaveNet, they just have a\ndecoder which is",
    "start": "1975310",
    "end": "1980529"
  },
  {
    "text": "a different version of\ntext to speech, which is like Tacotron in this case. So as you can see,\nthese are all same wine",
    "start": "1980530",
    "end": "1987250"
  },
  {
    "text": "in very different bottles. But the core idea is\nalmost exactly the same.",
    "start": "1987250",
    "end": "1992710"
  },
  {
    "text": "So this was like-- it created\na huge uproar of like, oh, this is going to change NLP.",
    "start": "1992710",
    "end": "1998140"
  },
  {
    "text": "But this is very, very\nsimilar to what people have been doing in the past.",
    "start": "1998140",
    "end": "2004690"
  },
  {
    "start": "2004000",
    "end": "2226000"
  },
  {
    "text": "So I've already\nexplained what this was. So in our case, we\njust try to predict",
    "start": "2004690",
    "end": "2012450"
  },
  {
    "text": "what's going to happen next\ngiven the previous context and use that\nrepresentation similar",
    "start": "2012450",
    "end": "2017490"
  },
  {
    "text": "to every single one-shot\nlearning or zero-shot learning based method.",
    "start": "2017490",
    "end": "2024630"
  },
  {
    "text": "I also explain why the number\nof codes are important. If you are too\nsmall, then you're just throwing up a\nlot of information.",
    "start": "2024630",
    "end": "2030863"
  },
  {
    "text": "If you have too large,\nthen you don't put in-- it is no longer robust to noise.",
    "start": "2030863",
    "end": "2039240"
  },
  {
    "text": "So this was our setup. And before I jump\nin, I should add one of the tweets\nwhich I saw from one",
    "start": "2039240",
    "end": "2047279"
  },
  {
    "text": "of the most\nprominent researchers at DeepMind, which is\nbasically a lot of times, it is very, very easy\nto bump up numbers.",
    "start": "2047280",
    "end": "2053638"
  },
  {
    "text": "I can have these details just\nnot present in my paper, which",
    "start": "2053639",
    "end": "2058888"
  },
  {
    "text": "actually helps a lot in terms\nof improving the performance. And kind of sometimes\ndon't take into account",
    "start": "2058889",
    "end": "2065790"
  },
  {
    "text": "what the actual model\nis incorporating or what model is\ncontributing versus what",
    "start": "2065790",
    "end": "2072029"
  },
  {
    "text": "the actual these tricks for\ntraining are incorporating. So for most of these methods,\nwhat we try to see is we",
    "start": "2072030",
    "end": "2079020"
  },
  {
    "text": "try to keep almost exactly\nthe same approach, no data augmentation, no\nfancy label smoothing",
    "start": "2079020",
    "end": "2084570"
  },
  {
    "text": "or moving average of weights\nor decay or whatever. You just have\nsimilar based recipes",
    "start": "2084570",
    "end": "2091379"
  },
  {
    "text": "to see how well we are doing. For this case, the\ngoal was to say",
    "start": "2091380",
    "end": "2097920"
  },
  {
    "text": "that how well our models do\nwith respect to this purely supervised approach,\nand how well it",
    "start": "2097920",
    "end": "2102960"
  },
  {
    "text": "does with respect to a\nsimilar unsupervised approach. So in the first case, the\nmodel and all of the weights",
    "start": "2102960",
    "end": "2109320"
  },
  {
    "text": "have access to all of\nthe labels, which is shown just as VGG supervised. Which is basically you take\nup an audio understanding data",
    "start": "2109320",
    "end": "2116550"
  },
  {
    "text": "set. And you see how well you are\ndoing on accuracy metrics. So that was the first one.",
    "start": "2116550",
    "end": "2122579"
  },
  {
    "text": "And the second one,\nwe applied SimCLR, which was proposed by Geoff\nHinton in which you can take up these multiple augmentations\nof the same input.",
    "start": "2122580",
    "end": "2130440"
  },
  {
    "text": "You can have patches removed. You can blur the signal. You can flip the signal. You learn embedding\nonto the last layer",
    "start": "2130440",
    "end": "2136890"
  },
  {
    "text": "without access to the\nlabels, and then just have a linear head to\npredict what's happening.",
    "start": "2136890",
    "end": "2141930"
  },
  {
    "text": "By using that, we\ngot a 55% accuracy. You do the exact same\nthing with transformers.",
    "start": "2141930",
    "end": "2146970"
  },
  {
    "text": "You don't have access to labels. You just run them while\njust predict the next code. You take the linear layer,\napply the same linear head,",
    "start": "2146970",
    "end": "2154500"
  },
  {
    "text": "and try to predict\nwhat's happening inside. And with that, we\ngot 60% accuracy. So even though the\nresults are not good,",
    "start": "2154500",
    "end": "2161130"
  },
  {
    "text": "but the fact is the\nneural networks actually are very, very good at\ngetting better and better",
    "start": "2161130",
    "end": "2169390"
  },
  {
    "text": "with training of\nhuge amounts of data. So there's still a 10% gap\nbetween the purely supervised",
    "start": "2169390",
    "end": "2174760"
  },
  {
    "text": "and purely unsupervised. But in that, that's\ngoing to improve with training a lot of\ndata to these models,",
    "start": "2174760",
    "end": "2181930"
  },
  {
    "text": "because it doesn't have access\nto any label that's present. So this is a famous paper by\nDan Ellis and Nelson Morgan",
    "start": "2181930",
    "end": "2188590"
  },
  {
    "text": "at Berkeley, in\nwhich they actually showed, way back in 1999,\nas to why size matters",
    "start": "2188590",
    "end": "2196120"
  },
  {
    "text": "for deep neural\nnetworks, and also the number of data\npoints, which is present. So as they kept on increasing\nthe size of the data",
    "start": "2196120",
    "end": "2204070"
  },
  {
    "text": "set and the\nparameters, they kept on getting lower and\nlower error rates. And this has been true\nacross any of the data set.",
    "start": "2204070",
    "end": "2211371"
  },
  {
    "text": "And that's why the\nwhole excitement is about unsupervised learning.",
    "start": "2211372",
    "end": "2216670"
  },
  {
    "text": "So this was, in a way,\na flavor of how can we do language modeling and\nunsupervised learning on audio",
    "start": "2216670",
    "end": "2222940"
  },
  {
    "text": "for continuous signals. For the third subplot,\nI'll just quickly mention ideas which are very\nsimilar to what you would have",
    "start": "2222940",
    "end": "2231400"
  },
  {
    "start": "2226000",
    "end": "2325000"
  },
  {
    "text": "seen in vision transformers,\nbut with the caveat that how can we use some sort of\nsignal processing",
    "start": "2231400",
    "end": "2238869"
  },
  {
    "text": "to improve these\nperformance even further. So the basic approach still\nremains the same exactly",
    "start": "2238870",
    "end": "2244510"
  },
  {
    "text": "as what you would have seen\nin vision transformers. You have a signal of interest,\nwhich you want to classify.",
    "start": "2244510",
    "end": "2253000"
  },
  {
    "text": "Here, they are waveform\nin sort of images. The goal is to predict what's\nthen inside of it, right?",
    "start": "2253000",
    "end": "2261160"
  },
  {
    "text": "And also, we don't\nhave any convolutions. We don't have any other tricks\nwhich we were using before.",
    "start": "2261160",
    "end": "2266740"
  },
  {
    "text": "All we have to do is they\ncan-- transformers themselves solve this particular problem.",
    "start": "2266740",
    "end": "2272900"
  },
  {
    "text": "So for the data set-- and the whole setup\nwas still the same. No data augmentation and no\nother forms of these tricks.",
    "start": "2272900",
    "end": "2283000"
  },
  {
    "text": "You are given 40,000\nsnippets for training and 10,000 for validation.",
    "start": "2283000",
    "end": "2288099"
  },
  {
    "text": "Our job is to predict\nas good as possible as to what's there in the audio.",
    "start": "2288100",
    "end": "2293500"
  },
  {
    "text": "This problem is very similar\nto the sound which you heard and the video which you saw.",
    "start": "2293500",
    "end": "2298809"
  },
  {
    "text": "That given this batch,\nyou are to predict-- given a spectrogram\npatch, you have to predict what's\nthere inside of it.",
    "start": "2298810",
    "end": "2304180"
  },
  {
    "text": " We kind of do one step\nfurther than what's",
    "start": "2304180",
    "end": "2312839"
  },
  {
    "text": "just a simple transform model. In the sense that\nwe tried to see whether some sort of\nhierarchy over transform",
    "start": "2312840",
    "end": "2320820"
  },
  {
    "text": "embeddings would help\nus in any manner. So for that, we used\nwavelet decomposition",
    "start": "2320820",
    "end": "2327240"
  },
  {
    "start": "2325000",
    "end": "2480000"
  },
  {
    "text": "on the intermediate\ntransformer embeddings. So what is a wavelet\ndecomposition?",
    "start": "2327240",
    "end": "2335310"
  },
  {
    "text": "In very naive terms,\nit can be a way of decomposing the\nintermediate embeddings",
    "start": "2335310",
    "end": "2342780"
  },
  {
    "text": "into other intermediate\nembedding in the sense that we are kind of\nputting these highways",
    "start": "2342780",
    "end": "2349170"
  },
  {
    "text": "of some embeddings are\nmoving very slowly, and some embeddings\nare moving very fast, and some embeddings\nare retained exactly",
    "start": "2349170",
    "end": "2355650"
  },
  {
    "text": "at the rate of what the\noriginal signal was. And why this is important?",
    "start": "2355650",
    "end": "2360720"
  },
  {
    "text": "Because you can think about that\nat every intermediate state, you are, in a way, learning some\nsort of hierarchy in the model.",
    "start": "2360720",
    "end": "2367434"
  },
  {
    "text": "So if I look at what we do\nwith the wavelet decomposition",
    "start": "2367434",
    "end": "2375120"
  },
  {
    "text": "before and after, let's say\nyou had time across this and you had the embedding\nsize across this.",
    "start": "2375120",
    "end": "2381660"
  },
  {
    "text": "And this whole patch\nwas your output of say, the nth layer\nof the transformer.",
    "start": "2381660",
    "end": "2388620"
  },
  {
    "text": "What I say now is,\nOK, I would just have a mapping from this to\nthe mapping of my interest",
    "start": "2388620",
    "end": "2396060"
  },
  {
    "text": "using wavelet decomposition, in\nwhich for half of the samples, I just created the exact\nsame embedding as what was",
    "start": "2396060",
    "end": "2403440"
  },
  {
    "text": "known by the transformer model. In the next half, I would\nstart combining two at a time.",
    "start": "2403440",
    "end": "2409089"
  },
  {
    "text": "So in a way, I'm learning this\nsort of like a tree structure within a single layer of\nthe transformer embedding.",
    "start": "2409090",
    "end": "2416250"
  },
  {
    "text": "And for now, the wavelet or\nthe basis function which I use is simple averaging.",
    "start": "2416250",
    "end": "2422220"
  },
  {
    "text": "So let's say I have from\nall of the embedding layers in between, I just need\nto have one embedding which",
    "start": "2422220",
    "end": "2431027"
  },
  {
    "text": "is not moving at all, which\nis just representative of whatever is there of the\nwhole latent space in that nth",
    "start": "2431027",
    "end": "2439410"
  },
  {
    "text": "layer. Then in the next layer, I\nwould just use two at a time. And then I would\nuse four at a time.",
    "start": "2439410",
    "end": "2446609"
  },
  {
    "text": "Then I reach the exact\nresolution as what I had. Doing this operation doesn't\nadd any parameters whatsoever.",
    "start": "2446610",
    "end": "2453650"
  },
  {
    "text": "You're just defining what\nyour basis function would be or what your wavelet\nfunction would be. In this case, it\nis a Haar wavelet.",
    "start": "2453650",
    "end": "2460260"
  },
  {
    "text": "And I start combining them. And I kind of learn a\nhierarchy at every single layer",
    "start": "2460260",
    "end": "2465990"
  },
  {
    "text": "of the transformers. And this kind of improved our\nperformance significantly as",
    "start": "2465990",
    "end": "2472830"
  },
  {
    "text": "compared to not using\nthem, with addition of no extra parameters. And I've come to the\nresults later also.",
    "start": "2472830",
    "end": "2480790"
  },
  {
    "start": "2480000",
    "end": "2644000"
  },
  {
    "text": "So this is how the whole\napproach looks like. You have a frontend. The frontend is\nbasically a single layer",
    "start": "2480790",
    "end": "2488520"
  },
  {
    "text": "of 2,000 neurons followed by\na dense layer of 64 neurons, which is just to make\nsure to conform it",
    "start": "2488520",
    "end": "2497348"
  },
  {
    "text": "to the intermediate\ntransformer embeddings. Let's say if for\nthe transformers I define the embedding\nsize to be 64, then",
    "start": "2497348",
    "end": "2503760"
  },
  {
    "text": "that's their dimension\nwhich I'm mapping them to. So I take a broad waveform, I\npatch it in very small patches,",
    "start": "2503760",
    "end": "2511289"
  },
  {
    "text": "similar to how you do\nin vision transformers. I would just have a single\nlayer of 2,000 neurons followed",
    "start": "2511290",
    "end": "2517350"
  },
  {
    "text": "by a dense layer of 64\nneurons, with the hope that the first layer kind of\nis learning a Fourier basis",
    "start": "2517350",
    "end": "2523260"
  },
  {
    "text": "function, which\nshould be adaptable according to what I'm learning. After that, I keep on doing\nthis over and over again.",
    "start": "2523260",
    "end": "2531570"
  },
  {
    "text": "I don't have a classification\nhead or anything like that. I keep on adding multiple stacks\nof transformers after that.",
    "start": "2531570",
    "end": "2540270"
  },
  {
    "text": " And then I have two\napproaches of what I",
    "start": "2540270",
    "end": "2545980"
  },
  {
    "text": "can do in terms of adaptation. I can do average\npooling across time",
    "start": "2545980",
    "end": "2551080"
  },
  {
    "text": "of these intermediate\nembeddings. Because that is\nvery-- the idea is very similar to what we\ndo in classical version.",
    "start": "2551080",
    "end": "2556984"
  },
  {
    "text": "That each of the\nembeddings are looking at much, much broader output\nin the subsequent layers.",
    "start": "2556985",
    "end": "2564250"
  },
  {
    "text": "Or I could do a\nwavelet decomposition. So what I do is that I take\nall of these embeddings,",
    "start": "2564250",
    "end": "2570130"
  },
  {
    "text": "and I define these highways. So some of the embeddings\nare moving fast. Some of them are\nmoving very slow. And some are retained at the\nexact same resolution as what",
    "start": "2570130",
    "end": "2577660"
  },
  {
    "text": "the transformer is learning. And then I keep doing\nthis over and over again. I have a dense layer.",
    "start": "2577660",
    "end": "2583720"
  },
  {
    "text": "I have my softmax\nor sigmoid, whatever is my classification head. So this is kind of what\nthe approach looks like.",
    "start": "2583720",
    "end": "2592420"
  },
  {
    "text": "We compare it with all of\nthe traditional vision based",
    "start": "2592420",
    "end": "2597760"
  },
  {
    "text": "architecture. So the vision based models\nhave been very good. And the performance have been\nsimilar in understanding audio",
    "start": "2597760",
    "end": "2604680"
  },
  {
    "text": "also. So we compare all of\nthose models in terms of mean average position. And we see that even the tiniest\nmodels of transformers were",
    "start": "2604680",
    "end": "2612490"
  },
  {
    "text": "just surpassing all of the\nstate-of-the-art CNN models. Which was a very good sign.",
    "start": "2612490",
    "end": "2617960"
  },
  {
    "text": "Then we started to bump up, OK,\nthe larger model should keep on improving the performance. And with the multiscale\nmodels, as well as with",
    "start": "2617960",
    "end": "2626140"
  },
  {
    "text": "the pooling layers, they improve\nthe performance even further, which was kind of\nvery surprising to us,",
    "start": "2626140",
    "end": "2632560"
  },
  {
    "text": "because the number of\nparameters are very small. These are very\ntiny architectures, yet they are surpassing things\nlike even DenseNet, which",
    "start": "2632560",
    "end": "2639070"
  },
  {
    "text": "are huge models with a lot\nof millions of parameters. So after that, we said, and\nI'm going to conclude quickly,",
    "start": "2639070",
    "end": "2648280"
  },
  {
    "start": "2644000",
    "end": "2838000"
  },
  {
    "text": "after that we said that, OK,\nthis is looking pretty cool. What actually is the transformer\nor the first layer learning",
    "start": "2648280",
    "end": "2656380"
  },
  {
    "text": "learning, right? So in order to make\nthis plot, what we said",
    "start": "2656380",
    "end": "2662500"
  },
  {
    "text": "was, OK, if you were to take\na classic Fourier transform,",
    "start": "2662500",
    "end": "2667600"
  },
  {
    "text": "then if my-- this axis is\nkind of like frequency.",
    "start": "2667600",
    "end": "2673030"
  },
  {
    "text": "This axis is the\nnumber of filters, and this axis is\nof the frequency. Then in a way, it\nshould be connecting all",
    "start": "2673030",
    "end": "2681160"
  },
  {
    "text": "of the points in a linear line. And this is akin to the\nnumber of points in FFT. So how many points\nI'm defining here,",
    "start": "2681160",
    "end": "2688330"
  },
  {
    "text": "if I'm defining\n2,000 points here, then I would have 2,048\nsinusoidal basis functions,",
    "start": "2688330",
    "end": "2696100"
  },
  {
    "text": "which are going from lower\nfrequency to the most highest frequency. We said, OK, we'll do the\nexact same thing, but now",
    "start": "2696100",
    "end": "2702430"
  },
  {
    "text": "with filters. So we have a\nfrequency along y-axis and the number of\npoints in my x-axis.",
    "start": "2702430",
    "end": "2709460"
  },
  {
    "text": "And if it was a classic\nFourier transform, then it would be connecting\nright as a linear line.",
    "start": "2709460",
    "end": "2715640"
  },
  {
    "text": "But what we did was we\ntake up the frontend which is known by transformer,\ntake its Fourier transform,",
    "start": "2715640",
    "end": "2722800"
  },
  {
    "text": "sort according to its center\nfrequency as to what frequency is activating the most, and\nthen keep on stacking them.",
    "start": "2722800",
    "end": "2730030"
  },
  {
    "text": "When we did this\nfor two problems, we saw that we are kind of\nlearning a different time",
    "start": "2730030",
    "end": "2735280"
  },
  {
    "text": "frequency\nrepresentation, which is specific to a\nparticular problem. So if I'm trying to\nunderstand what's there,",
    "start": "2735280",
    "end": "2740680"
  },
  {
    "text": "the content of the audio\nby learned representation, which is very different than\nFourier transform, which would have been a\nstraight line, which",
    "start": "2740680",
    "end": "2746943"
  },
  {
    "text": "is kind of like a curved\nexponential line like this. And if I do a polyphonic\npitch estimation,",
    "start": "2746943",
    "end": "2754510"
  },
  {
    "text": "I learn a very\ndifferent frontend, which is adapting to\nthat particular problem.",
    "start": "2754510",
    "end": "2760010"
  },
  {
    "text": "So this was very exciting to\nus, because making computers",
    "start": "2760010",
    "end": "2765520"
  },
  {
    "text": "hear in a way in which they're\nadapting their ears according to a particular problem\nis a very cool idea.",
    "start": "2765520",
    "end": "2772390"
  },
  {
    "text": "Second thing is we actually\nsaw each of the filters as to what they were doing. And these are basically just\nlike single slices like this.",
    "start": "2772390",
    "end": "2780940"
  },
  {
    "text": "So this is what\nwe would have been learned as a frontend neuron. So we take up each of the\nneurons, and we just plot them.",
    "start": "2780940",
    "end": "2787810"
  },
  {
    "text": "And for plotting\nthis, we basically take its Fourier transform\nand then sort them according to where the\ncenter frequency is.",
    "start": "2787810",
    "end": "2795173"
  },
  {
    "text": "When we just saw the neurons\nas to what they were learning in the front end, we saw that\nit is learning properties which",
    "start": "2795173",
    "end": "2801580"
  },
  {
    "text": "are very, very closely matching\nwith the traditional signal processing.",
    "start": "2801580",
    "end": "2806930"
  },
  {
    "text": "So you would have something\nlike an onset detector learned right here. You're learning\nwindowing functions.",
    "start": "2806930",
    "end": "2812180"
  },
  {
    "text": "So in a way, it is learning\nto have a kernel which is best for a time frequency\nrepresentation for people who",
    "start": "2812180",
    "end": "2818333"
  },
  {
    "text": "have been using signal\nprocessing, which is like a Hamming\nor Hanning window. We are learning\nthese pure sinusoids,",
    "start": "2818333",
    "end": "2824740"
  },
  {
    "text": "which are responsible\nfor activating a particular frequency. So you can see the\nrichness as compared",
    "start": "2824740",
    "end": "2830530"
  },
  {
    "text": "to having a fixed, purely\nsinusoidal basis function right here.",
    "start": "2830530",
    "end": "2836300"
  },
  {
    "text": "So this was what we had done. And then to share\nthe final thoughts,",
    "start": "2836300",
    "end": "2843250"
  },
  {
    "start": "2838000",
    "end": "2899000"
  },
  {
    "text": "I'll conclude by saying\nthat, OK, transformers are proving to be a major\nadvancement in AI research across the fields.",
    "start": "2843250",
    "end": "2850000"
  },
  {
    "text": "And it seems like they're\nsolving everything for now. And hopefully, this\nis not the end.",
    "start": "2850000",
    "end": "2856000"
  },
  {
    "text": "And we should keep an\neye out, and something which would change and\nhave an impact which",
    "start": "2856000",
    "end": "2861130"
  },
  {
    "text": "is more than what\ntransformers have put. And who knows what's\ngoing to come next.",
    "start": "2861130",
    "end": "2867730"
  },
  {
    "text": "Yeah, so by that,\nI'll just conclude. And I'll be happy\nto take questions.",
    "start": "2867730",
    "end": "2873160"
  },
  {
    "text": "Thank you, Prateek. That was a really good talk. And you provided some\nreally good insights",
    "start": "2873160",
    "end": "2878740"
  },
  {
    "text": "about how transformers\nwork on the audio case. And yeah, thank you for that.",
    "start": "2878740",
    "end": "2884980"
  },
  {
    "text": "And now I would invite questions\nfrom the class students.",
    "start": "2884980",
    "end": "2890260"
  },
  {
    "text": "Let me just stop the recording. ",
    "start": "2890260",
    "end": "2898000"
  }
]
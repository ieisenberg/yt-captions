[
  {
    "start": "0",
    "end": "123000"
  },
  {
    "text": "Welcome back.",
    "start": "0",
    "end": "1750"
  },
  {
    "text": "Today's lecture is about\nunsupervised learning.",
    "start": "1750",
    "end": "4230"
  },
  {
    "text": "So let's recall what we\nmeant by supervised learning",
    "start": "4230",
    "end": "7000"
  },
  {
    "text": "and contrast it with\nunsupervised learning.",
    "start": "7000",
    "end": "9290"
  },
  {
    "text": "So supervised learning,\nthe word \"supervised,\"",
    "start": "9290",
    "end": "11230"
  },
  {
    "text": "remember refers to the\nfact that there's a target,",
    "start": "11230",
    "end": "13360"
  },
  {
    "text": "a label that we're trying to\npredict from training data.",
    "start": "13360",
    "end": "16070"
  },
  {
    "text": "So we have features, and we're\ntrying to predict the label,",
    "start": "16070",
    "end": "19660"
  },
  {
    "text": "and the label\nsupervises the learning.",
    "start": "19660",
    "end": "22000"
  },
  {
    "text": "For example, if you're\nin kindergarten,",
    "start": "22000",
    "end": "23920"
  },
  {
    "text": "you can think of a\nkindergarten teacher",
    "start": "23920",
    "end": "25545"
  },
  {
    "text": "who shows a child in the class\na bunch of examples of, say,",
    "start": "25545",
    "end": "28720"
  },
  {
    "text": "\"Johnny, here's five examples\nof a house in LEGO blocks.",
    "start": "28720",
    "end": "33680"
  },
  {
    "text": "Here's five examples of a car.\"",
    "start": "33680",
    "end": "35715"
  },
  {
    "text": "And he tells Johnny that these\nare houses and these are cars.",
    "start": "35715",
    "end": "38660"
  },
  {
    "text": "So he's supervising\nthe learning.",
    "start": "38660",
    "end": "40280"
  },
  {
    "text": "And the child then looks\nat this and figures",
    "start": "40280",
    "end": "42649"
  },
  {
    "text": "out which features of the house\nmake a characteristic of a house",
    "start": "42650",
    "end": "46798"
  },
  {
    "text": "and which features of the car\nmake a characteristic of a car.",
    "start": "46798",
    "end": "49340"
  },
  {
    "text": "So that's supervised learning.",
    "start": "49340",
    "end": "51850"
  },
  {
    "text": "In contrast, unsupervised\nlearning, there's no labels.",
    "start": "51850",
    "end": "54800"
  },
  {
    "text": "So the kindergarten teacher\nwould just show Johnny,",
    "start": "54800",
    "end": "57010"
  },
  {
    "text": "\"Here's 10 things,\" and doesn't\ntell Johnny that these five are",
    "start": "57010",
    "end": "61129"
  },
  {
    "text": "cars and these five are houses.",
    "start": "61130",
    "end": "62880"
  },
  {
    "text": "And the child then\nlooks at the objects",
    "start": "62880",
    "end": "65750"
  },
  {
    "text": "and tries to figure\nout some patterns.",
    "start": "65750",
    "end": "67350"
  },
  {
    "text": "He says-- he may realize,\nthese five look similar.",
    "start": "67350",
    "end": "69957"
  },
  {
    "text": "I don't know what they're\ncalled, but they look similar,",
    "start": "69957",
    "end": "72290"
  },
  {
    "text": "so maybe I should\ngroup them together.",
    "start": "72290",
    "end": "73920"
  },
  {
    "text": "These other five look\nsimilar to each other",
    "start": "73920",
    "end": "75830"
  },
  {
    "text": "and I'll put them in the group.",
    "start": "75830",
    "end": "78080"
  },
  {
    "text": "Yes.",
    "start": "78080",
    "end": "78750"
  },
  {
    "text": "So this means you have--",
    "start": "78750",
    "end": "80951"
  },
  {
    "text": "with supervised, we have a Y,\nand with unsupervised, we don't.",
    "start": "80951",
    "end": "85009"
  },
  {
    "text": "Exactly.",
    "start": "85010",
    "end": "86090"
  },
  {
    "text": "So in both, we have\nfeatures, but as Trevor",
    "start": "86090",
    "end": "87920"
  },
  {
    "text": "said, in supervised, we have a Y\nthat we're given in the training",
    "start": "87920",
    "end": "90628"
  },
  {
    "text": "data, that's the true label.",
    "start": "90628",
    "end": "91939"
  },
  {
    "text": "In unsupervised\nlearning, it's harder,",
    "start": "91940",
    "end": "93680"
  },
  {
    "text": "in a sense, because we don't\nhave the actual labels.",
    "start": "93680",
    "end": "97360"
  },
  {
    "text": "So let's move to slide one.",
    "start": "97360",
    "end": "99610"
  },
  {
    "text": "Most of the course,\nas we've seen,",
    "start": "99610",
    "end": "101950"
  },
  {
    "text": "focuses on the first\nexercise, supervised learning,",
    "start": "101950",
    "end": "105250"
  },
  {
    "text": "where we have labels.",
    "start": "105250",
    "end": "106160"
  },
  {
    "text": "But today, we're going\nto talk about the setting",
    "start": "106160",
    "end": "108160"
  },
  {
    "text": "where we don't have labels,\nunsupervised learning.",
    "start": "108160",
    "end": "111267"
  },
  {
    "text": "All we observe are the\nfeatures, which, as before,",
    "start": "111267",
    "end": "113350"
  },
  {
    "text": "we'll call X1 through Xp.",
    "start": "113350",
    "end": "115420"
  },
  {
    "text": "And we want to know\nhow the features--",
    "start": "115420",
    "end": "119770"
  },
  {
    "text": "how the features\nrelate to each other.",
    "start": "119770",
    "end": "121689"
  },
  {
    "text": "So, in particular, what are the\ngoals of unsupervised learning?",
    "start": "121690",
    "end": "124403"
  },
  {
    "start": "123000",
    "end": "186000"
  },
  {
    "text": "Well, first of all,\nthey're not as clear",
    "start": "124403",
    "end": "126070"
  },
  {
    "text": "as they are for\nsupervised learning,",
    "start": "126070",
    "end": "127570"
  },
  {
    "text": "where the object is\nto predict Y from X.",
    "start": "127570",
    "end": "130570"
  },
  {
    "text": "Now we don't have a\nY, so the objective",
    "start": "130570",
    "end": "133120"
  },
  {
    "text": "is a little more fuzzy.",
    "start": "133120",
    "end": "134409"
  },
  {
    "text": "For example, we might\nwant to discover subgroups",
    "start": "134410",
    "end": "138370"
  },
  {
    "text": "among the observations.",
    "start": "138370",
    "end": "139360"
  },
  {
    "text": "Like in my kindergarten\nexample, the child",
    "start": "139360",
    "end": "141520"
  },
  {
    "text": "may try to discover subgroups\namong the objects he's seen.",
    "start": "141520",
    "end": "147480"
  },
  {
    "text": "We might want to know,\nis there a good way",
    "start": "147480",
    "end": "149489"
  },
  {
    "text": "to view the data to find\nthe important features",
    "start": "149490",
    "end": "152880"
  },
  {
    "text": "or the features that\nhave the most variation",
    "start": "152880",
    "end": "154890"
  },
  {
    "text": "over the different objects?",
    "start": "154890",
    "end": "156855"
  },
  {
    "text": "So we're going to discuss--",
    "start": "156855",
    "end": "157980"
  },
  {
    "text": "there are lots of methods\nfor unsupervised learning,",
    "start": "157980",
    "end": "160147"
  },
  {
    "text": "but in this short lecture, we're\njust going to talk about two",
    "start": "160147",
    "end": "163190"
  },
  {
    "text": "of the most important ones.",
    "start": "163190",
    "end": "164500"
  },
  {
    "text": "First is principal\ncomponents analysis,",
    "start": "164500",
    "end": "166820"
  },
  {
    "text": "which is a tool for viewing\ndata or for pre-processing",
    "start": "166820",
    "end": "172310"
  },
  {
    "text": "the features for use later\nin supervised learning.",
    "start": "172310",
    "end": "175550"
  },
  {
    "text": "And the second is\nclustering, which",
    "start": "175550",
    "end": "177380"
  },
  {
    "text": "is a group of methods for--",
    "start": "177380",
    "end": "179600"
  },
  {
    "text": "class of methods for\ngrouping the objects",
    "start": "179600",
    "end": "181790"
  },
  {
    "text": "into different subgroups.",
    "start": "181790",
    "end": "184360"
  },
  {
    "text": "So we'll talk about\nthose two methods today.",
    "start": "184360",
    "end": "188767"
  },
  {
    "start": "186000",
    "end": "273000"
  },
  {
    "text": "But let's say a\nlittle more in general",
    "start": "188767",
    "end": "190349"
  },
  {
    "text": "about the challenge of\nunsupervised learning.",
    "start": "190350",
    "end": "192850"
  },
  {
    "text": "As I mentioned, it's\na little more fuzzy",
    "start": "192850",
    "end": "196170"
  },
  {
    "text": "because there's no simple\nobjective like prediction.",
    "start": "196170",
    "end": "198360"
  },
  {
    "text": "There's no Y available,\nso we're not predicting.",
    "start": "198360",
    "end": "202282"
  },
  {
    "text": "The objective, as we saw\nin the previous slide,",
    "start": "202282",
    "end": "204239"
  },
  {
    "text": "is a little more--",
    "start": "204240",
    "end": "206370"
  },
  {
    "text": "a little more fuzzy.",
    "start": "206370",
    "end": "208049"
  },
  {
    "text": "But nonetheless,\nunsupervised learning",
    "start": "208050",
    "end": "212490"
  },
  {
    "text": "is actually of\ngrowing importance,",
    "start": "212490",
    "end": "213970"
  },
  {
    "text": "and there's a number\nof reasons for that.",
    "start": "213970",
    "end": "216510"
  },
  {
    "text": "Well, first of all,\nlet's see some examples.",
    "start": "216510",
    "end": "218489"
  },
  {
    "text": "Samples, actually, you'll see\nat the end of the lecture.",
    "start": "218490",
    "end": "220823"
  },
  {
    "text": "An actual example is\nwe have breast cancer",
    "start": "220823",
    "end": "223950"
  },
  {
    "text": "patients from whom we've\nmeasured gene expression using",
    "start": "223950",
    "end": "226680"
  },
  {
    "text": "gene chips.",
    "start": "226680",
    "end": "227680"
  },
  {
    "text": "And we want to group those\npatients into subgroups",
    "start": "227680",
    "end": "230640"
  },
  {
    "text": "of breast cancer.",
    "start": "230640",
    "end": "231740"
  },
  {
    "text": "And turns out these\nsubgroups are actually",
    "start": "231740",
    "end": "233490"
  },
  {
    "text": "quite different in terms\nof their characteristics,",
    "start": "233490",
    "end": "235573"
  },
  {
    "text": "biologically, and their\nsurvival as patients.",
    "start": "235573",
    "end": "238890"
  },
  {
    "text": "Another example, which is\nin marketing, is to find--",
    "start": "238890",
    "end": "243120"
  },
  {
    "text": "if we have shoppers and we\ncan record their browsing",
    "start": "243120",
    "end": "249310"
  },
  {
    "text": "and purchase histories, we can\ngroup or segment the shoppers",
    "start": "249310",
    "end": "252280"
  },
  {
    "text": "into different groups.",
    "start": "252280",
    "end": "253600"
  },
  {
    "text": "And then maybe\nthey'll be targeted",
    "start": "253600",
    "end": "255441"
  },
  {
    "text": "with different\nkinds of advertising",
    "start": "255441",
    "end": "256898"
  },
  {
    "text": "because their behaviors\nare different.",
    "start": "256899",
    "end": "258789"
  },
  {
    "text": "Another example, which\nis quite popular,",
    "start": "258790",
    "end": "261289"
  },
  {
    "text": "is to group movies by\nthe ratings assigned",
    "start": "261289",
    "end": "265510"
  },
  {
    "text": "by movie viewers, like a\nthriller, romance, et cetera.",
    "start": "265510",
    "end": "269955"
  },
  {
    "start": "269955",
    "end": "274180"
  },
  {
    "start": "273000",
    "end": "429000"
  },
  {
    "text": "The other thing that makes\nunsupervised learning more",
    "start": "274180",
    "end": "276910"
  },
  {
    "text": "and more important\nis that there's",
    "start": "276910",
    "end": "278350"
  },
  {
    "text": "a lot more unlabeled\ndata available.",
    "start": "278350",
    "end": "280520"
  },
  {
    "text": "And that's because in order\nto get labels for data,",
    "start": "280520",
    "end": "285900"
  },
  {
    "text": "it can be costly\nor time-consuming.",
    "start": "285900",
    "end": "287900"
  },
  {
    "text": "For example--",
    "start": "287900",
    "end": "288710"
  },
  {
    "text": "There's tons of\nimages on the web.",
    "start": "288710",
    "end": "291199"
  },
  {
    "text": "I mean, everybody\nis loading up images",
    "start": "291200",
    "end": "293420"
  },
  {
    "text": "on Google and other places,\nand mostly, they're unlabeled.",
    "start": "293420",
    "end": "296520"
  },
  {
    "text": "You don't know--\nno one's told us",
    "start": "296520",
    "end": "298490"
  },
  {
    "text": "exactly what's in the picture,\nbut we have the pictures.",
    "start": "298490",
    "end": "301223"
  },
  {
    "text": "And the point is that\nthat kind of information",
    "start": "301223",
    "end": "303139"
  },
  {
    "text": "can be collected by machine,\nthe features, the images,",
    "start": "303140",
    "end": "306200"
  },
  {
    "text": "but the actual\nlabeling, it often",
    "start": "306200",
    "end": "308060"
  },
  {
    "text": "requires human\nintervention, and that's",
    "start": "308060",
    "end": "309860"
  },
  {
    "text": "going to be more costly\nand time-consuming.",
    "start": "309860",
    "end": "311969"
  },
  {
    "text": "An example of that is our\nmovie reviews on the web.",
    "start": "311970",
    "end": "315390"
  },
  {
    "text": "A lot of people,\nthey try to predict",
    "start": "315390",
    "end": "318860"
  },
  {
    "text": "or they try to correlate movie\nreviews with movie quality",
    "start": "318860",
    "end": "322550"
  },
  {
    "text": "and group movies.",
    "start": "322550",
    "end": "323349"
  },
  {
    "text": "One problem there is that if\nyou have a movie review written",
    "start": "323350",
    "end": "325850"
  },
  {
    "text": "by a human being, it's hard to\ntell by machine whether or not",
    "start": "325850",
    "end": "329570"
  },
  {
    "text": "that is actually favorable\nor not if the movie review",
    "start": "329570",
    "end": "332230"
  },
  {
    "text": "could have some sarcasm in it.",
    "start": "332230",
    "end": "333480"
  },
  {
    "text": "And for human reading\nthe paragraph,",
    "start": "333480",
    "end": "335463"
  },
  {
    "text": "it's pretty easy to\nsay, oh, that person",
    "start": "335463",
    "end": "337130"
  },
  {
    "text": "doesn't like the movie\nor does like the movie.",
    "start": "337130",
    "end": "339047"
  },
  {
    "text": "But for a computer,\nit's not so easy.",
    "start": "339047",
    "end": "340950"
  },
  {
    "text": "So that's an example\nwhere we're finding",
    "start": "340950",
    "end": "344520"
  },
  {
    "text": "the actual label can be quite\ndifficult and time-consuming.",
    "start": "344520",
    "end": "348120"
  },
  {
    "text": "OK, so let's start with\nthe first main method",
    "start": "348120",
    "end": "350280"
  },
  {
    "text": "for unsupervised learning,\nprincipal components analysis.",
    "start": "350280",
    "end": "353550"
  },
  {
    "text": "And this goes back probably to\nthe 1930s in statistics when it",
    "start": "353550",
    "end": "356940"
  },
  {
    "text": "was first invented.",
    "start": "356940",
    "end": "358070"
  },
  {
    "text": "So PCA produces a\nlow-dimensional representation",
    "start": "358070",
    "end": "363240"
  },
  {
    "text": "of a data set.",
    "start": "363240",
    "end": "364110"
  },
  {
    "text": "And it finds a sequence\nof linear combinations",
    "start": "364110",
    "end": "366270"
  },
  {
    "text": "of the variables or features\nthat have maximal variance.",
    "start": "366270",
    "end": "368970"
  },
  {
    "text": "And the same, time\nthey're uncorrelated.",
    "start": "368970",
    "end": "370637"
  },
  {
    "text": "So we're going to see there's a\nfirst principal component, which",
    "start": "370637",
    "end": "373302"
  },
  {
    "text": "has the highest variance\nacross the data.",
    "start": "373303",
    "end": "375300"
  },
  {
    "text": "It's a linear combination\nof the features.",
    "start": "375300",
    "end": "377129"
  },
  {
    "text": "And then a second\ncomponent, which",
    "start": "377130",
    "end": "379710"
  },
  {
    "text": "is uncorrelated with\nthe first, which",
    "start": "379710",
    "end": "381509"
  },
  {
    "text": "has the highest variance under\nthat constraint, et cetera.",
    "start": "381510",
    "end": "384580"
  },
  {
    "text": "Just imagine you have tons\nof variables and many of them",
    "start": "384580",
    "end": "387449"
  },
  {
    "text": "are correlated.",
    "start": "387450",
    "end": "389610"
  },
  {
    "text": "That can be quite\nan unmanageable set.",
    "start": "389610",
    "end": "391780"
  },
  {
    "text": "What principal\ncomponents tries to do",
    "start": "391780",
    "end": "393600"
  },
  {
    "text": "is pair the set down into\nsome important variables that",
    "start": "393600",
    "end": "399270"
  },
  {
    "text": "summarize all the\ninformation in the data,",
    "start": "399270",
    "end": "401520"
  },
  {
    "text": "and that's these\nprincipal components.",
    "start": "401520",
    "end": "403447"
  },
  {
    "text": "And that can be very useful just\nas a way of viewing the data.",
    "start": "403447",
    "end": "406030"
  },
  {
    "text": "If you have a\nhigh-dimensional data set,",
    "start": "406030",
    "end": "407130"
  },
  {
    "text": "you just want to have a look at\nwhat's really happening here,",
    "start": "407130",
    "end": "409960"
  },
  {
    "text": "what's important.",
    "start": "409960",
    "end": "410750"
  },
  {
    "text": "The principal component view is\none of the most important ways",
    "start": "410750",
    "end": "413333"
  },
  {
    "text": "of displaying the data.",
    "start": "413333",
    "end": "414770"
  },
  {
    "text": "And second of all, you\nhave a lot of features",
    "start": "414770",
    "end": "416669"
  },
  {
    "text": "you want to use for\nsupervised learning,",
    "start": "416670",
    "end": "418580"
  },
  {
    "text": "the principal components\nsummary of those variables",
    "start": "418580",
    "end": "421210"
  },
  {
    "text": "can be a good way to use--\na good set of new variables",
    "start": "421210",
    "end": "424750"
  },
  {
    "text": "to use for supervised learning.",
    "start": "424750",
    "end": "426980"
  },
  {
    "text": "Principal components and\nthe techniques related to it",
    "start": "426980",
    "end": "429950"
  },
  {
    "start": "429000",
    "end": "505000"
  },
  {
    "text": "is one of the most widely used\ntools in statistics and data",
    "start": "429950",
    "end": "433670"
  },
  {
    "text": "analysis.",
    "start": "433670",
    "end": "435042"
  },
  {
    "text": "OK, so let's talk about--\nlet's actually define",
    "start": "435042",
    "end": "437000"
  },
  {
    "text": "principal components.",
    "start": "437000",
    "end": "437875"
  },
  {
    "text": "So we have a set of\nvariables, X1 through Xp.",
    "start": "437875",
    "end": "440998"
  },
  {
    "text": "And the principal component,\nZ-- first principal component Z1",
    "start": "440998",
    "end": "443539"
  },
  {
    "text": "is a linear combination\nof those variables.",
    "start": "443540",
    "end": "445880"
  },
  {
    "text": "And it's a linear combination\ndefined of highest variance",
    "start": "445880",
    "end": "448520"
  },
  {
    "text": "across the data set.",
    "start": "448520",
    "end": "449849"
  },
  {
    "text": "Now, of course, we're going\nto choose weights-- well,",
    "start": "449850",
    "end": "452840"
  },
  {
    "text": "it's defined by a set of\nweights, phi 1 through phi p,",
    "start": "452840",
    "end": "456380"
  },
  {
    "text": "but if I was allowed to make\nthose weights as big as I",
    "start": "456380",
    "end": "459410"
  },
  {
    "text": "wanted, I could make\nthe variance of Z1",
    "start": "459410",
    "end": "461120"
  },
  {
    "text": "as big as I wanted.",
    "start": "461120",
    "end": "462030"
  },
  {
    "text": "So we need some\nconstraint on the phi's.",
    "start": "462030",
    "end": "465030"
  },
  {
    "text": "And the natural constraint\nis that they're normalized,",
    "start": "465030",
    "end": "467280"
  },
  {
    "text": "so the sum of the squares is 1.",
    "start": "467280",
    "end": "469670"
  },
  {
    "text": "That number makes the\nproblem a sensible one",
    "start": "469670",
    "end": "473675"
  },
  {
    "text": "to choose a set of weights\nthat has the highest variance.",
    "start": "473675",
    "end": "476509"
  },
  {
    "text": "Those weights are\ncalled loadings",
    "start": "476510",
    "end": "479240"
  },
  {
    "text": "in some areas of statistics\nand other social sciences.",
    "start": "479240",
    "end": "485930"
  },
  {
    "text": "So the phi 11 through phi 1p\nare the loadings of the first",
    "start": "485930",
    "end": "489229"
  },
  {
    "text": "principal component.",
    "start": "489230",
    "end": "490610"
  },
  {
    "text": "And the principal component,\nthe loading vector",
    "start": "490610",
    "end": "493789"
  },
  {
    "text": "is the set of those p numbers.",
    "start": "493790",
    "end": "496037"
  },
  {
    "text": "If you didn't constrain\nthem, of course, you",
    "start": "496037",
    "end": "497870"
  },
  {
    "text": "could just make\nthem much bigger,",
    "start": "497870",
    "end": "499245"
  },
  {
    "text": "and that would just make\nthe variance higher.",
    "start": "499245",
    "end": "501180"
  },
  {
    "text": "So you need to tie them down.",
    "start": "501180",
    "end": "503759"
  },
  {
    "text": "Exactly.",
    "start": "503760",
    "end": "504740"
  },
  {
    "text": "So here's an example.",
    "start": "504740",
    "end": "505900"
  },
  {
    "start": "505000",
    "end": "567000"
  },
  {
    "text": "Before we talk about how to\nactually compute the components,",
    "start": "505900",
    "end": "508400"
  },
  {
    "text": "let's just see what the result\nof the first two components",
    "start": "508400",
    "end": "512490"
  },
  {
    "text": "for this data, which is ad\nspending versus population.",
    "start": "512490",
    "end": "516719"
  },
  {
    "text": "So here, the red points\nare the data points.",
    "start": "516720",
    "end": "520288"
  },
  {
    "text": "I plotted them against\nthese two variables.",
    "start": "520289",
    "end": "522150"
  },
  {
    "text": "So p is just 2 in this example.",
    "start": "522150",
    "end": "524000"
  },
  {
    "text": "The first principal component\nis given by the projection",
    "start": "524000",
    "end": "529280"
  },
  {
    "text": "of the data onto this line.",
    "start": "529280",
    "end": "530700"
  },
  {
    "text": "So this direction has\nthe highest variance",
    "start": "530700",
    "end": "534710"
  },
  {
    "text": "among all combinations of\nthe features in this data.",
    "start": "534710",
    "end": "537990"
  },
  {
    "text": "Correspondingly, this\nhas the lowest variance.",
    "start": "537990",
    "end": "540584"
  },
  {
    "text": "Well, sorry.",
    "start": "540585",
    "end": "541470"
  },
  {
    "text": "Well, yeah, that's true.",
    "start": "541470",
    "end": "542569"
  },
  {
    "text": "This has the lowest variance.",
    "start": "542570",
    "end": "543520"
  },
  {
    "text": "So here, there's\nonly two components.",
    "start": "543520",
    "end": "544630"
  },
  {
    "text": "So I've got the\nhighest variance,",
    "start": "544630",
    "end": "545610"
  },
  {
    "text": "the first principal component.",
    "start": "545610",
    "end": "547230"
  },
  {
    "text": "The second component is also--",
    "start": "547230",
    "end": "549690"
  },
  {
    "text": "well, it's got the\nhighest variance--",
    "start": "549690",
    "end": "553562"
  },
  {
    "text": "with the constraint,\nit'd be uncorrelated",
    "start": "553562",
    "end": "555270"
  },
  {
    "text": "with the first\ncomponent, which means",
    "start": "555270",
    "end": "556530"
  },
  {
    "text": "it has to have right angles\nwith the first component,",
    "start": "556530",
    "end": "558360"
  },
  {
    "text": "and there it is.",
    "start": "558360",
    "end": "559130"
  },
  {
    "text": "If you only have two\nvariables, you can only",
    "start": "559130",
    "end": "560963"
  },
  {
    "text": "get out two components.",
    "start": "560963",
    "end": "562150"
  },
  {
    "text": "Exactly.",
    "start": "562150",
    "end": "562750"
  },
  {
    "text": "But just for illustration,\nwe show you two variables.",
    "start": "562750",
    "end": "566968"
  },
  {
    "text": "OK, so how do we actually\ncompute the components?",
    "start": "566968",
    "end": "569010"
  },
  {
    "start": "567000",
    "end": "613000"
  },
  {
    "text": "Well, now suppose we\nhave our data, which",
    "start": "569010",
    "end": "571370"
  },
  {
    "text": "features n by p, the X matrix.",
    "start": "571370",
    "end": "574550"
  },
  {
    "text": "And now since we're only\ninterested in the variance,",
    "start": "574550",
    "end": "579180"
  },
  {
    "text": "we can center the variables\nto have mean zero.",
    "start": "579180",
    "end": "581672"
  },
  {
    "text": "We don't care about the mean.",
    "start": "581672",
    "end": "582880"
  },
  {
    "text": "We're just worried\nabout the variance.",
    "start": "582880",
    "end": "584050"
  },
  {
    "text": "So in other words, in\nparticular, specifically, we",
    "start": "584050",
    "end": "586290"
  },
  {
    "text": "make the column means of X zero.",
    "start": "586290",
    "end": "588740"
  },
  {
    "text": "And then we want to find the\ncombination of the variables",
    "start": "588740",
    "end": "592880"
  },
  {
    "text": "that has the highest variance.",
    "start": "592880",
    "end": "594570"
  },
  {
    "text": "Remember, highest variance\nunder the constraint",
    "start": "594570",
    "end": "597500"
  },
  {
    "text": "that these loadings\nhave sum of squares one.",
    "start": "597500",
    "end": "601810"
  },
  {
    "text": "Now, since the data\nhave been arranged",
    "start": "601810",
    "end": "604580"
  },
  {
    "text": "to have mean zero\nin the first step,",
    "start": "604580",
    "end": "606260"
  },
  {
    "text": "that means the z's\nhave mean zero,",
    "start": "606260",
    "end": "608140"
  },
  {
    "text": "and hence, the variance\nis just the sum",
    "start": "608140",
    "end": "609820"
  },
  {
    "text": "of the squares-- of the z's\nis the sum of their squares.",
    "start": "609820",
    "end": "613140"
  },
  {
    "start": "613000",
    "end": "683000"
  },
  {
    "text": "OK, so to continue\nthe computation,",
    "start": "613140",
    "end": "616050"
  },
  {
    "text": "we have the z's,\nwhich we've defined",
    "start": "616050",
    "end": "618360"
  },
  {
    "text": "to be the sum of the\nloadings times the features.",
    "start": "618360",
    "end": "622589"
  },
  {
    "text": "And so now, the\nproblem now, we can",
    "start": "622590",
    "end": "624870"
  },
  {
    "text": "replace the z's by\ntheir expression",
    "start": "624870",
    "end": "626790"
  },
  {
    "text": "from the previous slide.",
    "start": "626790",
    "end": "628334"
  },
  {
    "text": "And we want to find the\nhighest variance now,",
    "start": "628335",
    "end": "630420"
  },
  {
    "text": "which is this expression,\nsubject to the fact",
    "start": "630420",
    "end": "632339"
  },
  {
    "text": "that the loadings\nhave to be normalized.",
    "start": "632340",
    "end": "634770"
  },
  {
    "text": "So this is now just a\ncomputational problem",
    "start": "634770",
    "end": "637140"
  },
  {
    "text": "where the unknowns are these\nphi's and the optimization",
    "start": "637140",
    "end": "639630"
  },
  {
    "text": "can be done by the singular\nvalue decomposition, which",
    "start": "639630",
    "end": "641880"
  },
  {
    "text": "is a standard technique in\nnumerical analysis, which we",
    "start": "641880",
    "end": "645030"
  },
  {
    "text": "won't cover, but if you want\nto read about it yourself,",
    "start": "645030",
    "end": "647592"
  },
  {
    "text": "very interesting and very\nimportant in a lot of areas",
    "start": "647592",
    "end": "649800"
  },
  {
    "text": "of statistics.",
    "start": "649800",
    "end": "651040"
  },
  {
    "text": "And it's covered, for\nexample, in our book, Elements",
    "start": "651040",
    "end": "653579"
  },
  {
    "text": "of Statistical Learning.",
    "start": "653580",
    "end": "655660"
  },
  {
    "text": "So when we solved this problem\nand we got the best loadings,",
    "start": "655660",
    "end": "660490"
  },
  {
    "text": "the resulting z values are the\nfirst principal component, which",
    "start": "660490",
    "end": "665620"
  },
  {
    "text": "we'll write as z11 to z n1.",
    "start": "665620",
    "end": "669020"
  },
  {
    "text": "So it's like we've created\na new variable now.",
    "start": "669020",
    "end": "671290"
  },
  {
    "text": "We had our original p variables.",
    "start": "671290",
    "end": "674130"
  },
  {
    "text": "Now we've created\na new variable,",
    "start": "674130",
    "end": "676100"
  },
  {
    "text": "which is the c1, which has\nn values just like each",
    "start": "676100",
    "end": "679220"
  },
  {
    "text": "of our original variables.",
    "start": "679220",
    "end": "680639"
  },
  {
    "start": "680640",
    "end": "683180"
  },
  {
    "start": "683000",
    "end": "757000"
  },
  {
    "text": "Exactly, so now we can\nthink of that geometrically.",
    "start": "683180",
    "end": "687620"
  },
  {
    "text": "And we'll go back to\nthe picture in a moment.",
    "start": "687620",
    "end": "689520"
  },
  {
    "text": "So the loading vector is\na direction on which we--",
    "start": "689520",
    "end": "694550"
  },
  {
    "text": "a direction of the\nfeatures that has--",
    "start": "694550",
    "end": "697399"
  },
  {
    "text": "if we project on that direction,\nhas the highest variance.",
    "start": "697400",
    "end": "700720"
  },
  {
    "text": "And the values of\nthe projected data",
    "start": "700720",
    "end": "704370"
  },
  {
    "text": "are called the principal\ncomponent scores.",
    "start": "704370",
    "end": "706201"
  },
  {
    "text": "So let's go back to the picture\nof the two-dimensional one.",
    "start": "706202",
    "end": "708660"
  },
  {
    "text": "So I said this was the\nfirst principal component.",
    "start": "708660",
    "end": "711579"
  },
  {
    "text": "That means the loading\nvector is a vector that",
    "start": "711580",
    "end": "714400"
  },
  {
    "text": "points in the direction from\nthe middle to the northeast.",
    "start": "714400",
    "end": "719170"
  },
  {
    "text": "So here might be something\nlike maybe 1,1, roughly.",
    "start": "719170",
    "end": "725414"
  },
  {
    "text": "So that's the combination\nof the features",
    "start": "725414",
    "end": "727500"
  },
  {
    "text": "that we compute using\nprincipal components.",
    "start": "727500",
    "end": "729670"
  },
  {
    "text": "The actual computed values are\nthe projections onto this line.",
    "start": "729670",
    "end": "732790"
  },
  {
    "text": "So we could start-- say\nthe origin could be here,",
    "start": "732790",
    "end": "735300"
  },
  {
    "text": "we could just measure--",
    "start": "735300",
    "end": "736660"
  },
  {
    "text": "each point we take its\nprojection onto this line,",
    "start": "736660",
    "end": "739149"
  },
  {
    "text": "we measure how far is it away\nfrom, say, the origin here.",
    "start": "739150",
    "end": "743640"
  },
  {
    "text": "So the z's for these\nguys would be positive,",
    "start": "743640",
    "end": "746125"
  },
  {
    "text": "and the z's for these\nguys would be negative.",
    "start": "746125",
    "end": "748000"
  },
  {
    "text": "So we replaced each\npoint by, basically,",
    "start": "748000",
    "end": "750330"
  },
  {
    "text": "how far along this line is it.",
    "start": "750330",
    "end": "752850"
  },
  {
    "text": "And that's the first\nprincipal component.",
    "start": "752850",
    "end": "755660"
  },
  {
    "start": "755660",
    "end": "757000"
  }
]
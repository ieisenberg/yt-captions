[
  {
    "start": "0",
    "end": "22000"
  },
  {
    "text": "i'm happy to be here so today i'm going to talk to you about considerations for",
    "start": "12000",
    "end": "17119"
  },
  {
    "text": "collaborative robotics so i mentioned i direct the arm lab",
    "start": "17119",
    "end": "25039"
  },
  {
    "start": "22000",
    "end": "109000"
  },
  {
    "text": "which stands for the assistive robotics and manipulation laboratory in our lab we focus on three main",
    "start": "25039",
    "end": "30960"
  },
  {
    "text": "research areas robotic assistance intelligent wearables and connected devices where the idea of robotic",
    "start": "30960",
    "end": "36880"
  },
  {
    "text": "assistance is you have these robots that are able to enable and amplify the efforts of a human collaborator or possibly perform a",
    "start": "36880",
    "end": "43280"
  },
  {
    "text": "task for them intelligent wearables are robot systems that are usually augmenting the person",
    "start": "43280",
    "end": "50000"
  },
  {
    "text": "and provides situational awareness and help the person achieve their objective and connected devices again have the",
    "start": "50000",
    "end": "56480"
  },
  {
    "text": "situational awareness but usually don't have any sort of mobility and their goal is to anticipate",
    "start": "56480",
    "end": "62160"
  },
  {
    "text": "service needs and so our overall goal is to develop intelligent assistive technology that improves",
    "start": "62160",
    "end": "68640"
  },
  {
    "text": "human life so when we really look at this sort of problem we focus on",
    "start": "68640",
    "end": "74000"
  },
  {
    "text": "um a the robot which you know is uh essential to robotics how does a robot",
    "start": "74000",
    "end": "79040"
  },
  {
    "text": "model itself how can a robot model a complex task but when you want robots to be collaborators",
    "start": "79040",
    "end": "84960"
  },
  {
    "text": "it becomes really important that they also model the human and so this graph is going to come back throughout this talk",
    "start": "84960",
    "end": "91520"
  },
  {
    "text": "but this is really the epicenter of the types of questions that we ask",
    "start": "91520",
    "end": "97920"
  },
  {
    "text": "so here is a actually partial list of the graduate and master's students",
    "start": "97920",
    "end": "103040"
  },
  {
    "text": "in the arm lab currently and they work on a host of different projects so uh let's start off by",
    "start": "103040",
    "end": "109920"
  },
  {
    "start": "109000",
    "end": "166000"
  },
  {
    "text": "thinking about the timeline of robotics itself so in the 80s up till about the 2000s",
    "start": "109920",
    "end": "115520"
  },
  {
    "text": "you know when you thought of a robot you thought of a system that was helping with automation so",
    "start": "115520",
    "end": "120560"
  },
  {
    "text": "doing some repetitive tasks possibly on an assembly line and it was extremely important that those robots be very precise when they",
    "start": "120560",
    "end": "127600"
  },
  {
    "text": "executed their task we saw the movement toward autonomy where now the",
    "start": "127600",
    "end": "133520"
  },
  {
    "text": "robots had to perceive unstructured environments and understand their place in it in order to function well we saw the",
    "start": "133520",
    "end": "140720"
  },
  {
    "text": "onset of swarm technology centralized systems and then even decentralized systems",
    "start": "140720",
    "end": "146560"
  },
  {
    "text": "where these big teams of robots need to work together in order to accomplish a larger goal",
    "start": "146560",
    "end": "152560"
  },
  {
    "text": "and now in the past decade we've been approaching augmentation so how can these robots",
    "start": "152560",
    "end": "158560"
  },
  {
    "text": "work effectively with human counterparts when there might be limited communication",
    "start": "158560",
    "end": "165360"
  },
  {
    "text": "so what does effective human robot collaboration possibly look like i'll give a few",
    "start": "165360",
    "end": "170560"
  },
  {
    "start": "166000",
    "end": "231000"
  },
  {
    "text": "examples that are actually very pertinent because actually projects within my lab and they include possibly wanting robots",
    "start": "170560",
    "end": "177200"
  },
  {
    "text": "to work with humans to carry objects you can imagine a wearable system where you want to detect",
    "start": "177200",
    "end": "182560"
  },
  {
    "text": "where a person will walk possibly to alert them that they might possibly fall you might want a robot to be able to",
    "start": "182560",
    "end": "188239"
  },
  {
    "text": "learn how to do a new task and work alongside a person such as carrying boxes from one location to",
    "start": "188239",
    "end": "193920"
  },
  {
    "text": "another you might want to have an intelligent prosthetic that can interpret a human's intent given the environment and limited",
    "start": "193920",
    "end": "200720"
  },
  {
    "text": "inputs from the person to execute a task you might want to have shared autonomy between",
    "start": "200720",
    "end": "206560"
  },
  {
    "text": "a robot here a vehicle and a person so that the system knows when and how to",
    "start": "206560",
    "end": "211599"
  },
  {
    "text": "transfer control between the human and the robot and maybe even more passively in that sort of connected",
    "start": "211599",
    "end": "218159"
  },
  {
    "text": "devices phase if you want to have a system that can help observe the environment and do interpretation to",
    "start": "218159",
    "end": "224400"
  },
  {
    "text": "help a person understand the people in the environment around them",
    "start": "224400",
    "end": "230319"
  },
  {
    "text": "so we're going to focus on three main questions the first being what makes an effective collaborator",
    "start": "230319",
    "end": "236879"
  },
  {
    "start": "231000",
    "end": "252000"
  },
  {
    "text": "what tools do we have in robotics and what do we need to make the robots effective collaborators and finally what must be",
    "start": "236879",
    "end": "244080"
  },
  {
    "text": "considered for human robot teams",
    "start": "244080",
    "end": "248879"
  },
  {
    "text": "so what makes an effective collaborator so here is a a a good motivating",
    "start": "249439",
    "end": "256639"
  },
  {
    "start": "252000",
    "end": "331000"
  },
  {
    "text": "video of a swarm of robots here they're coordinated quadrotors that are flying together",
    "start": "256639",
    "end": "262160"
  },
  {
    "text": "and they all know where to be because there is um an oracle a single system that's telling",
    "start": "262160",
    "end": "267440"
  },
  {
    "text": "every agent where to go here you can see that is a sort of base station that's commanding them where to go",
    "start": "267440",
    "end": "273199"
  },
  {
    "text": "and this is being achieved through digital communication",
    "start": "273199",
    "end": "278960"
  },
  {
    "text": "but as these teams might possibly get larger it might actually be too much for a",
    "start": "279360",
    "end": "284800"
  },
  {
    "text": "single oracle um to handle and that limitation might be due to computational complexity or",
    "start": "284800",
    "end": "291360"
  },
  {
    "text": "even just range if you imagine all of these quadrotors that you see here if they were to expand in their",
    "start": "291360",
    "end": "297840"
  },
  {
    "text": "function or even be over an entire city it might actually be very difficult for an oracle to",
    "start": "297840",
    "end": "303680"
  },
  {
    "text": "govern the second to second or millisecond to millisecond action and so they have to be decentralized and",
    "start": "303680",
    "end": "309919"
  },
  {
    "text": "communicate with each other to achieve that but again if you look at what the state of the art is a lot of this is in fact",
    "start": "309919",
    "end": "317759"
  },
  {
    "text": "digital communication as a method to drive this and we'll talk later about how these robots themselves even reach",
    "start": "317759",
    "end": "325120"
  },
  {
    "text": "the sort of consensus which is the shared plan agreement on a shared plan",
    "start": "325120",
    "end": "331520"
  },
  {
    "start": "331000",
    "end": "480000"
  },
  {
    "text": "but the problem definitely gets harder if you think about wanting to collaborate with biological systems or agents so here you",
    "start": "331520",
    "end": "338960"
  },
  {
    "text": "have an example of basketball players that are working very well to do an operation tempo op tempo task here of",
    "start": "338960",
    "end": "346880"
  },
  {
    "text": "scoring on these teammates in a very fast play and they clearly don't have digital",
    "start": "346880",
    "end": "352320"
  },
  {
    "text": "communication so what makes an effective team i would postulate that this",
    "start": "352320",
    "end": "357680"
  },
  {
    "text": "includes having shared goals and objectives among teammates the ability to model teammates behavior",
    "start": "357680",
    "end": "363840"
  },
  {
    "text": "for prediction and finally the ability to plan given personal and teammate roles",
    "start": "363840",
    "end": "371280"
  },
  {
    "text": "so clearly communication is extremely important um in this uh in this paradigm of",
    "start": "372160",
    "end": "378080"
  },
  {
    "text": "teamwork and if you think about biological systems here like these collies that are hurting these ducks for",
    "start": "378080",
    "end": "384639"
  },
  {
    "text": "sport into the ring as you see here usually the three main areas are audio",
    "start": "384639",
    "end": "390160"
  },
  {
    "text": "vision and tactile so if you have audio communication this allows for extremely high",
    "start": "390160",
    "end": "395520"
  },
  {
    "text": "specificity um you know such as giving this talk and passing information but it can be very slow",
    "start": "395520",
    "end": "401520"
  },
  {
    "text": "and if you have a very fast operation that might not be adequate and it's very sequential i speak then",
    "start": "401520",
    "end": "406560"
  },
  {
    "text": "you speak if you consider vision this can be done mutually we can directly observe each",
    "start": "406560",
    "end": "412880"
  },
  {
    "text": "other and so the information exchange can be extremely fast as you see in this video and very detailed",
    "start": "412880",
    "end": "420400"
  },
  {
    "text": "so here this is uh sort of instantaneously they're watching each other the dogs are watching each other and knowing what they should do in order",
    "start": "420400",
    "end": "426720"
  },
  {
    "text": "to achieve the desired behavior but you can also observe a very complex description through",
    "start": "426720",
    "end": "434639"
  },
  {
    "text": "vision visual observation as well so all of us are very familiar with how honeybees are actually able to",
    "start": "434639",
    "end": "440560"
  },
  {
    "text": "perform a dance and that is visually observed by the other insects in order to know how",
    "start": "440560",
    "end": "445840"
  },
  {
    "text": "to operate and find a target um location",
    "start": "445840",
    "end": "452000"
  },
  {
    "text": "finally for tactile touch and forces can be a communication method or modality",
    "start": "452000",
    "end": "458000"
  },
  {
    "text": "that's extremely fast here you see how quickly the outcome of this",
    "start": "458000",
    "end": "464080"
  },
  {
    "text": "score is able to be conveyed to the person who is learning that information through tactile feedback but here a key",
    "start": "464080",
    "end": "471280"
  },
  {
    "text": "uh requirement is that um proximity uh must be bounded you have to be close",
    "start": "471280",
    "end": "476560"
  },
  {
    "text": "enough right to touch the person so a few key features for teamwork i",
    "start": "476560",
    "end": "483840"
  },
  {
    "start": "480000",
    "end": "545000"
  },
  {
    "text": "would say are role understanding and interagent trust so role understanding",
    "start": "483840",
    "end": "488879"
  },
  {
    "text": "will classify as given the actions of others what is my role and is my role unique given the task",
    "start": "488879",
    "end": "494879"
  },
  {
    "text": "here the robot joins the circle is this the only place that could join if another were not in their place could",
    "start": "494879",
    "end": "499919"
  },
  {
    "text": "it swap with their location what's the role of this new agent and agent trust is essentially the",
    "start": "499919",
    "end": "507520"
  },
  {
    "text": "conditions you need before you take action and you know that um your actions will not lead to",
    "start": "507520",
    "end": "513360"
  },
  {
    "text": "some sub-optimal behavior this is the main primary assumptions you're basing this on and they consist on of having an agreed",
    "start": "513360",
    "end": "520479"
  },
  {
    "text": "objective and a known behavioral model so for this uh case with these two cars",
    "start": "520479",
    "end": "525839"
  },
  {
    "text": "um the basis for the red car trusting the blue car is it believes that the blue shares the",
    "start": "525839",
    "end": "531040"
  },
  {
    "text": "objective that it doesn't want to collide and the behavioral model that to achieve that objective the blue will maintain a",
    "start": "531040",
    "end": "536640"
  },
  {
    "text": "particular velocity and based on that trust the red may take the action of changing lanes",
    "start": "536640",
    "end": "545040"
  },
  {
    "start": "545000",
    "end": "593000"
  },
  {
    "text": "so what are the limitations when you think of these types of systems so we clearly see that you know limited communication",
    "start": "545200",
    "end": "550880"
  },
  {
    "text": "modality you can clearly share a lot more if you could be digital you have limited dexterity and strength",
    "start": "550880",
    "end": "556000"
  },
  {
    "text": "to weight ratio and possibly limited perception but how does",
    "start": "556000",
    "end": "561440"
  },
  {
    "text": "biological systems actually overcome these they do this through understanding um the role of the given team and for",
    "start": "561440",
    "end": "568000"
  },
  {
    "text": "the task they think about that task modeling how do you model the task and they think about that teammate",
    "start": "568000",
    "end": "574800"
  },
  {
    "text": "modeling as well so if we kind of want to match these two",
    "start": "574800",
    "end": "580399"
  },
  {
    "text": "things together and make robots these sort of super effective teammates the next question question we need to ask is what",
    "start": "580399",
    "end": "586800"
  },
  {
    "text": "tools do we already have in robotics that can make robots effective uh collaborators",
    "start": "586800",
    "end": "594080"
  },
  {
    "start": "593000",
    "end": "615000"
  },
  {
    "text": "so i'll break these into three main categories that are worthy of note you have proprioception",
    "start": "594080",
    "end": "599519"
  },
  {
    "text": "and control or the sort of knowledge of self you have perception where you're sensing the environment",
    "start": "599519",
    "end": "605120"
  },
  {
    "text": "you can think of computer vision or tactile sensing and intelligence or the ability to model",
    "start": "605120",
    "end": "610240"
  },
  {
    "text": "and make decisions so going into proprioception and control this is does",
    "start": "610240",
    "end": "616560"
  },
  {
    "start": "615000",
    "end": "848000"
  },
  {
    "text": "the robot know where it is in space so these are pretty easy this is more hardware you can think",
    "start": "616560",
    "end": "621760"
  },
  {
    "text": "of your encoders that are able to sense your four kinematics and if you have a model of yourself how",
    "start": "621760",
    "end": "627600"
  },
  {
    "text": "much do each one of your links weigh what is your torque or input capacity um you can quickly",
    "start": "627600",
    "end": "633279"
  },
  {
    "text": "model the dynamics of your system here the torque is your input you have an inertia uh coriolis",
    "start": "633279",
    "end": "639120"
  },
  {
    "text": "centrifugal terms and possibly gravity on our way towards control this also",
    "start": "639120",
    "end": "645839"
  },
  {
    "text": "means you need to know how to move within yourself possibly without avoiding self-collision",
    "start": "645839",
    "end": "651760"
  },
  {
    "text": "so motion planning becomes a really important part if you think of systems like manipulators",
    "start": "651760",
    "end": "657440"
  },
  {
    "text": "usually for high dimensional systems you kind of find yourself in this sampling category in order to achieve your target",
    "start": "657440",
    "end": "664480"
  },
  {
    "text": "pose and finally control how does the state change given a function of what the state",
    "start": "664480",
    "end": "671760"
  },
  {
    "text": "currently is and your choice of inputs again for a manipulator you can think of torques",
    "start": "671760",
    "end": "677040"
  },
  {
    "text": "at every joint so digging a little bit deeper into the space of controls",
    "start": "677040",
    "end": "682560"
  },
  {
    "text": "particularly if you're interacting with your environment because again we're thinking about this sort of tactile sensing can you feel a force being applied or",
    "start": "682560",
    "end": "689200"
  },
  {
    "text": "how do you react to your environment doing force on you um two primary ones for this sort of",
    "start": "689200",
    "end": "695120"
  },
  {
    "text": "contact scenario is impedance and admittance control where essentially impedance the goal of",
    "start": "695120",
    "end": "700320"
  },
  {
    "text": "impedance is to have a desired um dynamical system particular mass that you want to have the system behave as if",
    "start": "700320",
    "end": "707120"
  },
  {
    "text": "that's how much mass it had and resist motion impeding motion and for admittance",
    "start": "707120",
    "end": "713040"
  },
  {
    "text": "control you want to say if i have some target behavior and i have some input i want to actually admit that behavior i",
    "start": "713040",
    "end": "719519"
  },
  {
    "text": "want to move in the way that's being asked of me and depending on your different scenario one of these or both of these might be",
    "start": "719519",
    "end": "726720"
  },
  {
    "text": "useful so you can think of an impedance case where if you want to actually push a door open",
    "start": "726720",
    "end": "731839"
  },
  {
    "text": "you want to actually have a particular amount of force you want to apply so impedance is great but if you're interacting with a human and you were to",
    "start": "731839",
    "end": "738000"
  },
  {
    "text": "think about safety and you were to accidentally bump them you definitely want to have an admittance controller",
    "start": "738000",
    "end": "745839"
  },
  {
    "text": "in the space of perception you can think of camera sensing as being extremely",
    "start": "745839",
    "end": "751120"
  },
  {
    "text": "important here you see autonomous vehicle camera looking at its surroundings able to classify the different elements that",
    "start": "751120",
    "end": "757680"
  },
  {
    "text": "are present you can think of laser range finders that are able to literally send out light and use that",
    "start": "757680",
    "end": "764880"
  },
  {
    "text": "reflection to give you information about your environment with precise distances if other conditions are allowed",
    "start": "764880",
    "end": "771279"
  },
  {
    "text": "and finally tactile sensors right so sensors that can actually feel forces possibly both normal and shear in their",
    "start": "771279",
    "end": "778639"
  },
  {
    "text": "environment so in our lab we realize that this tactile sensor is a really big barrier",
    "start": "778639",
    "end": "784560"
  },
  {
    "text": "to having robots really present in your home and so we asked the question right what does it",
    "start": "784560",
    "end": "790800"
  },
  {
    "text": "take to really get us there and so here on the left you see this video of this place oh",
    "start": "790800",
    "end": "799519"
  },
  {
    "text": "excuse me that crashed uh well you had a video of uh one arm that was actually",
    "start": "799519",
    "end": "805279"
  },
  {
    "text": "manipulating an object and on the right uh we have a video of gelsite that will be back in one moment",
    "start": "805279",
    "end": "811760"
  },
  {
    "text": "but is really using vision to actually look at the boundary of a sensor to give you information",
    "start": "811760",
    "end": "817920"
  },
  {
    "text": "about it one moment as it pulls up and so that's",
    "start": "817920",
    "end": "823199"
  },
  {
    "text": "really the question right so the first video that we were looking at you had this this robot that was capable",
    "start": "823199",
    "end": "828399"
  },
  {
    "text": "of manipulating an object in hand but the way that that actually worked was they had external cameras that were looking",
    "start": "828399",
    "end": "834639"
  },
  {
    "text": "at the rubik's cube and they had spent hours in training learning how to um actually manipulate",
    "start": "834639",
    "end": "842399"
  },
  {
    "text": "that object in hand without it dropping out of the robot's hand",
    "start": "842399",
    "end": "848079"
  },
  {
    "start": "848000",
    "end": "1132000"
  },
  {
    "text": "so if you really look at this sort of space of manipulators and where we've come the",
    "start": "848079",
    "end": "853519"
  },
  {
    "text": "state of the art for quite a while was these sort of biotech sensors so they have smaller resolution than",
    "start": "853519",
    "end": "859519"
  },
  {
    "text": "these vision-based sensors but they're really effective then we have the onset of like gel site",
    "start": "859519",
    "end": "866959"
  },
  {
    "text": "and so here this is the digit using gel site and it has a camera inside that's looking at that flat surface you see",
    "start": "866959",
    "end": "873760"
  },
  {
    "text": "there and it's able to detect impressions there that give it both normal and sheer forces but it's very",
    "start": "873760",
    "end": "880480"
  },
  {
    "text": "flat so we call that a 2d shaped vision based sensor and we finally have this",
    "start": "880480",
    "end": "886320"
  },
  {
    "text": "um 3d shaped vision based sensor here coming out of berkeley omnitech where there are tiny micro cameras",
    "start": "886320",
    "end": "893279"
  },
  {
    "text": "looking everywhere so locally they see a flat image because they're so close to the surface",
    "start": "893279",
    "end": "898399"
  },
  {
    "text": "but the whole sensor itself is curved in 3d",
    "start": "898399",
    "end": "904079"
  },
  {
    "text": "so in our lab for this work in tactile sensing we really realize that we can break this",
    "start": "907199",
    "end": "912560"
  },
  {
    "text": "whole thing up into three main questions the design the modeling and the motion planning so we're asking can we",
    "start": "912560",
    "end": "918720"
  },
  {
    "text": "leverage anthropomorphic inspiration incurred fingertips that are capable of deforming and",
    "start": "918720",
    "end": "924560"
  },
  {
    "text": "sensing friction to drive our design for modeling can we effectively model a",
    "start": "924560",
    "end": "929600"
  },
  {
    "text": "continuously curved fingertip with high resolution and characterize stable grasps",
    "start": "929600",
    "end": "935600"
  },
  {
    "text": "and finally if we have that design in that model can we leverage this efficient continuous model of our fingertip to",
    "start": "935600",
    "end": "942160"
  },
  {
    "text": "plan multi-finger graphs for in-hand manipulation",
    "start": "942160",
    "end": "947199"
  },
  {
    "text": "so this work performed by my phd student juan kim do",
    "start": "947199",
    "end": "952480"
  },
  {
    "text": "really looks at how can we make this curved uh sensor design and after a few iterations we converged",
    "start": "952480",
    "end": "957839"
  },
  {
    "text": "on actually using a fisheye lens looking at a curved um hemispherical",
    "start": "957839",
    "end": "963680"
  },
  {
    "text": "fingertip where the radius center for the fisheye lens and the sensor are shared",
    "start": "963680",
    "end": "969920"
  },
  {
    "text": "and it gives us some really nice features in terms of our image model for the system",
    "start": "969920",
    "end": "976639"
  },
  {
    "text": "and so this whole sensor and whole setup is pretty low cost and has some really cool features and so",
    "start": "976639",
    "end": "982079"
  },
  {
    "text": "far has been performing quite well for us so you can kind of see the leds which are inside that are",
    "start": "982079",
    "end": "987680"
  },
  {
    "text": "rotating um for um contact um so they're moving really slowly so you can see them but in",
    "start": "987680",
    "end": "993759"
  },
  {
    "text": "real time when we would do them they would be moving much faster closer to the rate of the camera and the idea of",
    "start": "993759",
    "end": "1000560"
  },
  {
    "text": "having such a system perform this really allows us to um observe the shadowing that's produced",
    "start": "1000560",
    "end": "1007519"
  },
  {
    "text": "when you actually imprint on the surface so in the middle figures and on the left",
    "start": "1007519",
    "end": "1012800"
  },
  {
    "text": "you can see this sort of notion and so if the camera if the leds actually rotate then",
    "start": "1012800",
    "end": "1018880"
  },
  {
    "text": "this can give us a whole bunch of perspectives to compare so that we can actually get a particular",
    "start": "1018880",
    "end": "1024079"
  },
  {
    "text": "impact a sort of quasi-static impact from multiple points of view",
    "start": "1024079",
    "end": "1029760"
  },
  {
    "text": "and so right now we're going one step further to say can we actually calibrate this and",
    "start": "1030480",
    "end": "1036240"
  },
  {
    "text": "actually know the depression as well as the forces given our system so um once this design has",
    "start": "1036240",
    "end": "1044079"
  },
  {
    "text": "been completed and finalized uh we'll move on to modeling and motion planning as well",
    "start": "1044079",
    "end": "1049440"
  },
  {
    "text": "and some ideas for this are if you have this ability to measure the normal and shear forces which these type of vision",
    "start": "1049440",
    "end": "1055520"
  },
  {
    "text": "sensors give you and if the surface is actually soft and",
    "start": "1055520",
    "end": "1060559"
  },
  {
    "text": "can conform to whatever it is that you're contacting then through vision you can actually determine how the surface was deformed",
    "start": "1060559",
    "end": "1068400"
  },
  {
    "text": "and what the forces both normal and shear were everywhere and this is the basis of what",
    "start": "1068400",
    "end": "1073919"
  },
  {
    "text": "you need to actually build what we call a wrench cone which essentially tells you how much",
    "start": "1073919",
    "end": "1079280"
  },
  {
    "text": "force you can apply and moments you can apply before slipping occurs and particularly what's nice about these",
    "start": "1079280",
    "end": "1085039"
  },
  {
    "text": "vision based sensors is besides just seeing the boundary because you can actually see the",
    "start": "1085039",
    "end": "1090559"
  },
  {
    "text": "depression you can know where you are inside of the wrench cone and so if you want to plan in hand",
    "start": "1090559",
    "end": "1095760"
  },
  {
    "text": "manipulation similar to this sliding work um where they actually were having a non-zero velocity for us we're thinking",
    "start": "1095760",
    "end": "1102320"
  },
  {
    "text": "about in-hand manipulation so zero velocity but you can use these sets of motion",
    "start": "1102320",
    "end": "1107440"
  },
  {
    "text": "clones to to plan your overall action and so if you think about competing methods that just directly jump in with",
    "start": "1107440",
    "end": "1113679"
  },
  {
    "text": "rl and don't have the benefit of these sort of motion cones or wrench cones it's going to take them",
    "start": "1113679",
    "end": "1120720"
  },
  {
    "text": "a lot longer to learn but if we can mathematically represent these we think this is a tool that will cut down",
    "start": "1120720",
    "end": "1126160"
  },
  {
    "text": "the rate of learning for these other methods exponentially so",
    "start": "1126160",
    "end": "1133600"
  },
  {
    "start": "1132000",
    "end": "1207000"
  },
  {
    "text": "the last phase i'll talk about for them uh in the ones that i mentioned is intelligence right and so if you think about all the",
    "start": "1133600",
    "end": "1139919"
  },
  {
    "text": "different types of models you can use and we'll focus specifically on tools that you would use um for",
    "start": "1139919",
    "end": "1146480"
  },
  {
    "text": "predicting the behavior or actions of either yourself or other agents notably",
    "start": "1146480",
    "end": "1152960"
  },
  {
    "text": "commented as trajectory forecasting they break down into a few different categories and i love this breakdown",
    "start": "1152960",
    "end": "1158400"
  },
  {
    "text": "coming out of marco pavone's lab here at stanford you have ontological methods which",
    "start": "1158400",
    "end": "1164160"
  },
  {
    "text": "believe that there's some underlying structure to how the decisions are being made",
    "start": "1164160",
    "end": "1169280"
  },
  {
    "text": "or how the state is changing and those can be state space models or internal cost functions",
    "start": "1169280",
    "end": "1174559"
  },
  {
    "text": "and then you have on the other side these uh phenological uh methods these data-driven structures",
    "start": "1174559",
    "end": "1180880"
  },
  {
    "text": "so these can be deterministic regressors or even uh generative approaches and so based on",
    "start": "1180880",
    "end": "1187360"
  },
  {
    "text": "what uh what you actually have in these assumptions that you're making about your system some may be better than others and a lot",
    "start": "1187360",
    "end": "1193760"
  },
  {
    "text": "of our work we assume that there may not be particularly because we're trying to predict behavior these really nice ontological methods we",
    "start": "1193760",
    "end": "1201360"
  },
  {
    "text": "may be able to pull from and this pushes us more and more toward these sort of generative approaches so finally thinking about",
    "start": "1201360",
    "end": "1209200"
  },
  {
    "start": "1207000",
    "end": "1259000"
  },
  {
    "text": "where robots are and where you know we'd like to be you know common algorithms for corrupt uh cooperation for robots um can be",
    "start": "1209200",
    "end": "1216480"
  },
  {
    "text": "categorized as either having an oracle that's telling all agents what to do all agents could",
    "start": "1216480",
    "end": "1222080"
  },
  {
    "text": "in fact act independently toward a predetermined goal and not really interact but just assume that everyone",
    "start": "1222080",
    "end": "1227360"
  },
  {
    "text": "knows what they should do and where they should be and then finally you have consensus through voting systems",
    "start": "1227360",
    "end": "1234000"
  },
  {
    "text": "in terms of the digital space where they share information and they converge on a solution or an action",
    "start": "1234000",
    "end": "1239520"
  },
  {
    "text": "based on that shared information but most of these implementations are conditioned on the availability the availability of",
    "start": "1239520",
    "end": "1246000"
  },
  {
    "text": "digital communication and so this is something that we have to rethink when you want to actually have a",
    "start": "1246000",
    "end": "1251440"
  },
  {
    "text": "human in the loop so what must be considered for these",
    "start": "1251440",
    "end": "1256880"
  },
  {
    "text": "human robot teams so again that key challenge for the human",
    "start": "1256880",
    "end": "1262240"
  },
  {
    "start": "1259000",
    "end": "1284000"
  },
  {
    "text": "robot team is digital communication may not be available right so what do robots need to be",
    "start": "1262240",
    "end": "1267520"
  },
  {
    "text": "effective teammates for humans i postulate that they need the ability to model complex tasks",
    "start": "1267520",
    "end": "1273440"
  },
  {
    "text": "the ability to interpret and manipulate environments configured for humans and finally the ability to model",
    "start": "1273440",
    "end": "1279760"
  },
  {
    "text": "teammates actions and roles so i believe you can also further kind",
    "start": "1279760",
    "end": "1286400"
  },
  {
    "start": "1284000",
    "end": "1316000"
  },
  {
    "text": "of categorize robot collaborators as wearables and an external",
    "start": "1286400",
    "end": "1291760"
  },
  {
    "text": "collaborator one is augmenting the human and the others kind of performing like a partner and so",
    "start": "1291760",
    "end": "1297840"
  },
  {
    "text": "in the wearable space you actually can see the ability to substitute",
    "start": "1297840",
    "end": "1303760"
  },
  {
    "text": "substituting device so this wearable is actually performing the function of part of you",
    "start": "1303760",
    "end": "1310240"
  },
  {
    "text": "or perhaps an ability enhancing device such as a phone",
    "start": "1310240",
    "end": "1315280"
  },
  {
    "text": "so let's get into the ability substituting devices",
    "start": "1315600",
    "end": "1322640"
  },
  {
    "start": "1316000",
    "end": "1993000"
  },
  {
    "text": "so here you actually see a human on the left and i can kind of think of this control diagram where the human has some",
    "start": "1323440",
    "end": "1330159"
  },
  {
    "text": "cognition they're planning what they want to do their brain knows what kind of controller they need to execute it",
    "start": "1330159",
    "end": "1335919"
  },
  {
    "text": "you send that to your body those electrical signals to your body which acts and then you have some sensory feedback",
    "start": "1335919",
    "end": "1342080"
  },
  {
    "text": "that's telling you what happened after you took that action and so for particularly for wearables",
    "start": "1342080",
    "end": "1347120"
  },
  {
    "text": "the question we need to ask is what part of the human being is being augmented or substituted and if we do is the robot",
    "start": "1347120",
    "end": "1353679"
  },
  {
    "text": "augmentation functionaling adequately and does the presence of the robot feel natural or easy to use",
    "start": "1353679",
    "end": "1362240"
  },
  {
    "text": "so to answer this my phd student shivani gupta sarma and master students gabriella here they",
    "start": "1362240",
    "end": "1369520"
  },
  {
    "text": "are looking at what we call the intelligent prosthetic arm so traditionally in the space of upper",
    "start": "1369520",
    "end": "1375840"
  },
  {
    "text": "limb prosthetics you have some power prosthetics and others that are",
    "start": "1375840",
    "end": "1380960"
  },
  {
    "text": "body powered as you see here for shoulder disarticulation amputees and as",
    "start": "1380960",
    "end": "1387679"
  },
  {
    "text": "you see this can be very challenging for them to manipulate even though they're actually doing a fantastic job",
    "start": "1387679",
    "end": "1393120"
  },
  {
    "text": "just a limited dexterity can just take them longer to perform some tasks so we're thinking how can robotics",
    "start": "1393120",
    "end": "1399679"
  },
  {
    "text": "actually help and if you can kind of zoom in here on the center figure we're proposing a powered arm",
    "start": "1399679",
    "end": "1407600"
  },
  {
    "text": "that's informed by the person wearing emg signals leveraging augmented reality",
    "start": "1407600",
    "end": "1414559"
  },
  {
    "text": "and um a robot arm that's outfitted with the ability to perceive the environment as well so kind of exploding um",
    "start": "1414559",
    "end": "1423039"
  },
  {
    "text": "that methodology and going back to that original figure um i put on like the second slide uh",
    "start": "1423039",
    "end": "1428880"
  },
  {
    "text": "here you know how does the robot sense the person right you have these emg measurements",
    "start": "1428880",
    "end": "1434000"
  },
  {
    "text": "that's how the human is um sending information to the robot but what's really difficult a lot of times",
    "start": "1434000",
    "end": "1439520"
  },
  {
    "text": "is ascertaining human intent and that line between the human and the environment",
    "start": "1439520",
    "end": "1445919"
  },
  {
    "text": "is usually very difficult to sort of intercept and so augmented reality mixed reality",
    "start": "1445919",
    "end": "1452080"
  },
  {
    "text": "that has both the ability to portray information to the person as well as extract information from what",
    "start": "1452080",
    "end": "1458559"
  },
  {
    "text": "they're focusing on can be a key tool in intersecting that component",
    "start": "1458559",
    "end": "1463600"
  },
  {
    "text": "between the human and the task and environment which can allow us to better model",
    "start": "1463600",
    "end": "1468720"
  },
  {
    "text": "the human because we understand what they're thinking about with the environment and how they're interacting directly with us the robot",
    "start": "1468720",
    "end": "1476240"
  },
  {
    "text": "so let's go back to that sort of control diagram you have that cognition",
    "start": "1477279",
    "end": "1482640"
  },
  {
    "text": "which is a planner controller you're sending some electromyography",
    "start": "1482640",
    "end": "1487679"
  },
  {
    "text": "signals some impulses to your muscles which are your actuators your body has some dynamics that it acts through",
    "start": "1487679",
    "end": "1493760"
  },
  {
    "text": "and you have some sensory feedback touch and vision so clearly we have all of these capabilities maybe to a lesser extent in",
    "start": "1493760",
    "end": "1501120"
  },
  {
    "text": "some cases but present in robotics cognition right the ability to plan and control",
    "start": "1501120",
    "end": "1507039"
  },
  {
    "text": "your plant and actuator body dynamics sensory feedback touch and vision so if i look at this sort of",
    "start": "1507039",
    "end": "1514720"
  },
  {
    "text": "expanded um uh uh control diagram the planner controller actuator body dynamics vision",
    "start": "1514720",
    "end": "1521039"
  },
  {
    "text": "touch and this is all interacting with your environment and task on a bigger control loop if you will",
    "start": "1521039",
    "end": "1527760"
  },
  {
    "text": "then if you have a prosthesis this means that the actuator and body dynamics are usually",
    "start": "1527760",
    "end": "1532880"
  },
  {
    "text": "not available right and so someone with just a simple prosthesis would command a robotic prosthesis um",
    "start": "1532880",
    "end": "1539840"
  },
  {
    "text": "through say emg if you think about a powered reflex possibly with some basic reflexes",
    "start": "1539840",
    "end": "1546640"
  },
  {
    "text": "like maybe heat or contact then maybe you want to outfit that prosthesis with the ability",
    "start": "1546640",
    "end": "1552159"
  },
  {
    "text": "to have some sensory feedback like vision or touch so if the person is moving and they impact with the wall",
    "start": "1552159",
    "end": "1558320"
  },
  {
    "text": "it might respond immediately um but it doesn't really think and the person is still controlling with",
    "start": "1558320",
    "end": "1563919"
  },
  {
    "text": "emg finally you can even have a system where the person has the ability to play and control",
    "start": "1563919",
    "end": "1570240"
  },
  {
    "text": "but the robot also using the vision and touch of the environment can also understand its role and can help the",
    "start": "1570240",
    "end": "1577200"
  },
  {
    "text": "human um to be a less cognitive load for the person who's using",
    "start": "1577200",
    "end": "1583039"
  },
  {
    "text": "the system as i was mentioning before augmented reality is a very powerful tool",
    "start": "1583039",
    "end": "1590320"
  },
  {
    "text": "that can allow the robot to both extract and present information to the wearer so the top",
    "start": "1590320",
    "end": "1595600"
  },
  {
    "text": "two left corner images really show how with devices like the hololens 2 you can",
    "start": "1595600",
    "end": "1600640"
  },
  {
    "text": "actually perform gaze tracking and see what the person is looking at or thinking about",
    "start": "1600640",
    "end": "1605760"
  },
  {
    "text": "you can kind of model that as sort of a conic area of focus which can be very helpful when",
    "start": "1605760",
    "end": "1611120"
  },
  {
    "text": "ascertaining what the person actually wants to manipulate and then if you have knowledge about your environment",
    "start": "1611120",
    "end": "1617600"
  },
  {
    "text": "such as affordances or the pose if you're tracking them or seeing understanding this can all be very useful and provide",
    "start": "1617600",
    "end": "1624000"
  },
  {
    "text": "information back to the wearer so i want to set this kind",
    "start": "1624000",
    "end": "1629440"
  },
  {
    "text": "of scene for you if if you will on how you can imagine the system ultimately working",
    "start": "1629440",
    "end": "1635039"
  },
  {
    "text": "so um let's look at this activity of daily living adl of drinking some fluid with a",
    "start": "1635039",
    "end": "1641279"
  },
  {
    "text": "picture of water to refill your cup and uh feeding yourself from this plate of food and you have this simple state",
    "start": "1641279",
    "end": "1646799"
  },
  {
    "text": "machine here on the right um so you know when you're getting ready to start off you have two choices you could grasp the pitcher or",
    "start": "1646799",
    "end": "1652880"
  },
  {
    "text": "you could grasp the fork here this little circle with the plus sign designates where the person's",
    "start": "1652880",
    "end": "1658880"
  },
  {
    "text": "area of focus is let's say from just the ar is focusing on",
    "start": "1658880",
    "end": "1665440"
  },
  {
    "text": "and then that allows you to actually put more weight on the state machine to transitioning to pouring",
    "start": "1665440",
    "end": "1671279"
  },
  {
    "text": "say the pitcher and so when you're pulling the pitcher you have two options you could be either",
    "start": "1671279",
    "end": "1678000"
  },
  {
    "text": "filling the cup or replacing the pitcher but maybe vision isn't as helpful in this scenario so maybe here's where you",
    "start": "1678000",
    "end": "1683520"
  },
  {
    "text": "might actually want to rely more on emg to kind of signal which one of these operations at a high level",
    "start": "1683520",
    "end": "1688960"
  },
  {
    "text": "you're trying to perform and then once it's replaced you know options you",
    "start": "1688960",
    "end": "1694640"
  },
  {
    "text": "might logically go to from there are drinking from the food from the cup or possibly manipulating",
    "start": "1694640",
    "end": "1700880"
  },
  {
    "text": "the fork and if you were continuing to eat you might trigger this process this internal process to eat",
    "start": "1700880",
    "end": "1707120"
  },
  {
    "text": "and if you observe the plate of food this planting of where the fork should go next",
    "start": "1707120",
    "end": "1712480"
  },
  {
    "text": "can be largely handled by the system so hopefully i've kind of set the scene for you here about a very practical way this system",
    "start": "1712480",
    "end": "1720159"
  },
  {
    "text": "could ultimately be used so let's define a few variables we have the state of the system um s the",
    "start": "1720159",
    "end": "1727520"
  },
  {
    "text": "gaze g the emg signal e some desired action a i and the probability that the human",
    "start": "1727520",
    "end": "1732960"
  },
  {
    "text": "wants to do a particular action and we assume that um that set of actions is",
    "start": "1732960",
    "end": "1738799"
  },
  {
    "text": "finite and the probability over them sums to one so the question uh is we would like to",
    "start": "1738799",
    "end": "1746240"
  },
  {
    "text": "predict the where is intent based on the state and behavior so what action do they want to take given the state of the system given the",
    "start": "1746240",
    "end": "1752880"
  },
  {
    "text": "inputs from the amg given their gaze and we realize that we want to do that by modeling the humans",
    "start": "1752880",
    "end": "1758960"
  },
  {
    "text": "behavior what are they doing with their emg and gays given the states and available actions and then have a more",
    "start": "1758960",
    "end": "1766799"
  },
  {
    "text": "seen sort of contextual understanding what kind of actions would you expect to take",
    "start": "1766799",
    "end": "1771919"
  },
  {
    "text": "given the state of the system and so from uh bayes rules we actually",
    "start": "1771919",
    "end": "1779440"
  },
  {
    "text": "have the following relation right that the probability of your action given",
    "start": "1779440",
    "end": "1785440"
  },
  {
    "text": "the emg gaze and state is equal to this relationship between",
    "start": "1785440",
    "end": "1792559"
  },
  {
    "text": "the reliance of the uh electromyography the gaze on the action in this state",
    "start": "1792559",
    "end": "1798480"
  },
  {
    "text": "both together and independently on the state as well as the human intent model what action you would take",
    "start": "1798480",
    "end": "1803679"
  },
  {
    "text": "in a given state scenario so if you have these probabilities um if you want to predict their intent you",
    "start": "1803679",
    "end": "1809520"
  },
  {
    "text": "simply take the r max over that probability and this tells you what action you might expect the per the",
    "start": "1809520",
    "end": "1815039"
  },
  {
    "text": "person wants to take so at this point right this has been a well-phrased problem and you can",
    "start": "1815039",
    "end": "1820399"
  },
  {
    "text": "actually branch off into many ways to solve this um uh generative approaches variational",
    "start": "1820399",
    "end": "1826480"
  },
  {
    "text": "autoencoders particularly conditional variation water encoders have kind of risen to the top in a lot of literature as being a",
    "start": "1826480",
    "end": "1832240"
  },
  {
    "text": "really nice way to solve these type of problems but definitely not the only way but here i'll present it here briefly as",
    "start": "1832240",
    "end": "1838640"
  },
  {
    "text": "the method we're choosing to go forward with so x here is your input z is your latent space and y is your output",
    "start": "1838640",
    "end": "1845919"
  },
  {
    "text": "so here you have these arrows the black and red on the left here that indicate the the",
    "start": "1845919",
    "end": "1852080"
  },
  {
    "text": "testing process and the red indicate the training process and here there are a lot of resources",
    "start": "1852080",
    "end": "1858320"
  },
  {
    "text": "you can read that really looks at the mechanics of this implementation but simply at the top you want to predict",
    "start": "1858320",
    "end": "1864399"
  },
  {
    "text": "what is your output given your input and you can represent that in your latent space",
    "start": "1864399",
    "end": "1869679"
  },
  {
    "text": "with the following parameter and distributions and so for our task right to actually",
    "start": "1869679",
    "end": "1876399"
  },
  {
    "text": "solve our problem we need we realize we need to actually calculate renditions of the following",
    "start": "1876399",
    "end": "1882480"
  },
  {
    "text": "um models what is the probability of an action given the state and probability of the input given the",
    "start": "1882480",
    "end": "1889600"
  },
  {
    "text": "state or given the state and the action so you could actually have a separate one there that is just the state",
    "start": "1889600",
    "end": "1894640"
  },
  {
    "text": "as well so what's really nice is because we can actually separate these and combine them at the end",
    "start": "1894640",
    "end": "1901200"
  },
  {
    "text": "um that separation ability actually might mean that if we're very careful on how we choose our states",
    "start": "1901200",
    "end": "1907440"
  },
  {
    "text": "we can actually train these things independently so here you can imagine training an adl",
    "start": "1907440",
    "end": "1913840"
  },
  {
    "text": "or a task with augmented reality with able-bodied individuals that can put in a whole lot of work",
    "start": "1913840",
    "end": "1919679"
  },
  {
    "text": "and benefit the amputee commit community by actually putting in that",
    "start": "1919679",
    "end": "1925360"
  },
  {
    "text": "work and training those models and then on the other side similar to",
    "start": "1925360",
    "end": "1931760"
  },
  {
    "text": "conventional prosthesis we can actually calibrate by collecting behavioral data for these",
    "start": "1931760",
    "end": "1936960"
  },
  {
    "text": "specified actions and so you can imagine if you had this sort of setup with the",
    "start": "1936960",
    "end": "1943120"
  },
  {
    "text": "ar system your amg and your prosthetic if someone has trained how to do a whole set of tasks and maybe there's a library",
    "start": "1943120",
    "end": "1949679"
  },
  {
    "text": "or an app store of tasks right then on the other side if you can perform a lot of calibration routines",
    "start": "1949679",
    "end": "1955200"
  },
  {
    "text": "which cover the space of the actions you would need to do then you only need to do that sort of",
    "start": "1955200",
    "end": "1960480"
  },
  {
    "text": "calibration to calibrate your gaze and emg to those actions if you were directly requested to do",
    "start": "1960480",
    "end": "1966320"
  },
  {
    "text": "them and now your system can quickly connect to this to the to the larger space of demonstrated abilities",
    "start": "1966320",
    "end": "1973840"
  },
  {
    "text": "um and that's our hope to actually provide um a great resource in this space and so",
    "start": "1973840",
    "end": "1980720"
  },
  {
    "text": "that's our objective for the space and we're in the process of implementing this uh now starting off with a virtual",
    "start": "1980720",
    "end": "1986960"
  },
  {
    "text": "environment a virtual prosthetic arm performing virtual tasks",
    "start": "1986960",
    "end": "1992559"
  },
  {
    "start": "1993000",
    "end": "2299000"
  },
  {
    "text": "so um on the other side here you have instead of ability replacing devices you",
    "start": "1993120",
    "end": "1999039"
  },
  {
    "text": "also can imagine ability enhancing devices so in the ability enhancing devices",
    "start": "1999039",
    "end": "2004080"
  },
  {
    "text": "usually this kind of falls under the category of improving some sort of sensory uh feedback concerning the world",
    "start": "2004080",
    "end": "2012399"
  },
  {
    "text": "so uh one project that we're working on here with my master's and undergrad students juno luciana",
    "start": "2012399",
    "end": "2019519"
  },
  {
    "text": "and our our undergrad student here what we're doing is we're actually looking at fall prediction and",
    "start": "2019519",
    "end": "2026080"
  },
  {
    "text": "prevention using a smart belt so the motivation here is the falls of leading cause of fatal",
    "start": "2026080",
    "end": "2032480"
  },
  {
    "text": "and non-fatal injuries in older adults age 65 plus so the question we ask is if these falls",
    "start": "2032480",
    "end": "2038159"
  },
  {
    "text": "can be predicted can they also be mitigated using a wearable sensor that observes the person and the environment",
    "start": "2038159",
    "end": "2045279"
  },
  {
    "text": "and so this isn't really new there's similar work elderly fall risk assessment and prediction based on gate analysis",
    "start": "2045279",
    "end": "2051520"
  },
  {
    "text": "but a lot of this isn't online work they're not predicting if a fall is going to be happening on some",
    "start": "2051520",
    "end": "2056960"
  },
  {
    "text": "significant time horizon and even those that do are looking at less than a second or even on the millisecond scale",
    "start": "2056960",
    "end": "2063280"
  },
  {
    "text": "but we're saying if you can see far out in the environment um what's stopping you from trying to",
    "start": "2063280",
    "end": "2068398"
  },
  {
    "text": "predict if down the road uh you might be able to predict the person might be at risk of falling",
    "start": "2068399",
    "end": "2074800"
  },
  {
    "text": "and so uh if you observe the person's gait and surroundings can you predict the path that they will take what the gate is",
    "start": "2074800",
    "end": "2081599"
  },
  {
    "text": "going to be over that path and the associated risk of falling given that path and gait",
    "start": "2081599",
    "end": "2086960"
  },
  {
    "text": "and here we the the actual metric we take for that is the orientation of their torso what's the sway or particularly what's",
    "start": "2086960",
    "end": "2093520"
  },
  {
    "text": "the variance of the sway to characterize instability and so um the idea would be to have on",
    "start": "2093520",
    "end": "2100560"
  },
  {
    "text": "the person a camera an imu that is going to be in the final deployment that you just have",
    "start": "2100560",
    "end": "2106079"
  },
  {
    "text": "to wear around your waist and then we would train in order to allow such a system to correctly",
    "start": "2106079",
    "end": "2112320"
  },
  {
    "text": "estimate the environment the odometry the gate and orientation of the wearer",
    "start": "2112320",
    "end": "2118160"
  },
  {
    "text": "and once those were successfully implemented then the objective would be to use these",
    "start": "2118160",
    "end": "2123200"
  },
  {
    "text": "inputs with um some sort of sequential method like an lstm",
    "start": "2123200",
    "end": "2128560"
  },
  {
    "text": "to actually predict um the future trajectory gate and orientation which is associated",
    "start": "2128560",
    "end": "2134960"
  },
  {
    "text": "with the fall risk of the person",
    "start": "2134960",
    "end": "2139920"
  },
  {
    "text": "again on this sort of ability enhancing device and more to the connected devices under uh realm is our asl to english",
    "start": "2142160",
    "end": "2149200"
  },
  {
    "text": "translation mobile application so the idea we have here is you know if you really think about",
    "start": "2149200",
    "end": "2155440"
  },
  {
    "text": "a lot of translation apps a lot of them all clearly uh verbal and in the global community it has been",
    "start": "2155440",
    "end": "2162560"
  },
  {
    "text": "a raising concern how can we actually have a good um automic automatic interpreter for",
    "start": "2162560",
    "end": "2169680"
  },
  {
    "text": "asl back to english there are a lot of things companies such as hand talk that are able to go the other way you say",
    "start": "2169680",
    "end": "2175920"
  },
  {
    "text": "what you want to say and it shows you what the signs are but going the other way there's not a lot of resources in that space and those that do as you can see",
    "start": "2175920",
    "end": "2183440"
  },
  {
    "text": "here on this reference chart really require a lot of gpu overhead and so if you want to think about this",
    "start": "2183440",
    "end": "2189680"
  },
  {
    "text": "being deployable like carrying this ability in your pocket we need to do something clever in order",
    "start": "2189680",
    "end": "2195359"
  },
  {
    "text": "to achieve that and so that's where our solution space is how can we actually do this on the mobile",
    "start": "2195359",
    "end": "2201119"
  },
  {
    "text": "computing scale and so to achieve this we're actually leveraging um",
    "start": "2201119",
    "end": "2209040"
  },
  {
    "text": "transformers to actually characterize what the spoken words are and we're doing pre-processing on our",
    "start": "2209040",
    "end": "2215760"
  },
  {
    "text": "video data which includes um the ability of extracting the person's facial expressions and hands",
    "start": "2215760",
    "end": "2222480"
  },
  {
    "text": "and now we're actually much better at doing the torso as well and correlating those to um the expected",
    "start": "2222480",
    "end": "2229599"
  },
  {
    "text": "output from the words and so if we can do that you can imagine being far more efficient in terms of computation",
    "start": "2229599",
    "end": "2234960"
  },
  {
    "text": "on your system because you're not dealing with raw videos now you're dealing with a subset of key",
    "start": "2234960",
    "end": "2240000"
  },
  {
    "text": "points that can be very uh essential for that so moving to the",
    "start": "2240000",
    "end": "2245200"
  },
  {
    "text": "space of um external collaborators here this is work um that's uh in",
    "start": "2245200",
    "end": "2252240"
  },
  {
    "text": "collaboration with the iliad group and cs dorsal sadique sadiq my phd student ely",
    "start": "2252240",
    "end": "2259599"
  },
  {
    "text": "ing albert and jd we're here our goal of this project is to model the",
    "start": "2259599",
    "end": "2265280"
  },
  {
    "text": "cooperative ability of human human interaction and transport and transfer it to a robotic assistant in order to produce an effective",
    "start": "2265280",
    "end": "2271920"
  },
  {
    "text": "transport teammate so we realize to be effective for this we need to go back to that term of",
    "start": "2271920",
    "end": "2278320"
  },
  {
    "text": "interagent trust right which we defined before if you can uh model the other persons or the other",
    "start": "2278320",
    "end": "2285040"
  },
  {
    "text": "teammates behavior and actions then you can understand better your role in order to carry",
    "start": "2285040",
    "end": "2290640"
  },
  {
    "text": "um effectively and so in one version of this application we're thinking can you",
    "start": "2290640",
    "end": "2295680"
  },
  {
    "text": "predict where your partner wants to go given where you've been as a team s and the actions you both have mutually",
    "start": "2295680",
    "end": "2301839"
  },
  {
    "start": "2299000",
    "end": "2686000"
  },
  {
    "text": "taken as well as the environment oh",
    "start": "2301839",
    "end": "2305760"
  },
  {
    "text": "in this other space of an external collaborator here we have this project efficient",
    "start": "2308800",
    "end": "2314800"
  },
  {
    "text": "learning from demonstration and collaboration with aaliyah smith emmanuel retana",
    "start": "2314800",
    "end": "2320640"
  },
  {
    "text": "and here the goal is to say hey you know if you imagine a scenario where you know you",
    "start": "2320640",
    "end": "2325839"
  },
  {
    "text": "have first responders you want to do a duty in an unstable environment you want to move things but maybe it's not safe to send a whole",
    "start": "2325839",
    "end": "2331440"
  },
  {
    "text": "bunch of first responders into a space maybe it would be great to send a few first responders and more robots and there are many",
    "start": "2331440",
    "end": "2337680"
  },
  {
    "text": "application spaces you can kind of think of that where if the robot were able to work alongside a person you could reduce",
    "start": "2337680",
    "end": "2343520"
  },
  {
    "text": "risks to that person or people and so there are two main objectives",
    "start": "2343520",
    "end": "2349359"
  },
  {
    "text": "within this set of problems here one is can the human efficiently teach robot a new task by",
    "start": "2349359",
    "end": "2355119"
  },
  {
    "text": "identifying critical states using ar and secondly given the described tasks",
    "start": "2355119",
    "end": "2360720"
  },
  {
    "text": "can the robot collaborate learn the human behavioral model and leverage it to take action that optimizes performance for the entire",
    "start": "2360720",
    "end": "2367520"
  },
  {
    "text": "team so here on uh the uh right you see um imagine the case of opening a",
    "start": "2367520",
    "end": "2374240"
  },
  {
    "text": "door if you go back to one of those google papers they actually had hundreds like a bunch of robots",
    "start": "2374240",
    "end": "2379359"
  },
  {
    "text": "opening a door many many times to be successful and a huge problem with rl and learning from",
    "start": "2379359",
    "end": "2385359"
  },
  {
    "text": "demonstration is really the state space right but if i were able to define to the robot what were the important states",
    "start": "2385359",
    "end": "2391680"
  },
  {
    "text": "it should be paying attention to you have a rigid object which is a door you have a constraint which is the hinge",
    "start": "2391680",
    "end": "2396800"
  },
  {
    "text": "you have the handle is another rigid object and this constraint related to the door now there are four things you need to be paying attention",
    "start": "2396800",
    "end": "2402560"
  },
  {
    "text": "to and if you operate these in this particular sequential action or state space action then you",
    "start": "2402560",
    "end": "2408880"
  },
  {
    "text": "can achieve your objective and so then even transferring this to new abilities you need to be looking for",
    "start": "2408880",
    "end": "2414160"
  },
  {
    "text": "these corresponding elements um will allow robot to understand these tasks a lot more efficiently",
    "start": "2414160",
    "end": "2419760"
  },
  {
    "text": "and that brings a lot of power from the ar side and on the second objective here if you have these sort of",
    "start": "2419760",
    "end": "2426079"
  },
  {
    "text": "behavioral models where you can predict the action the human would take given the set maybe their actions are sub-optimal",
    "start": "2426079",
    "end": "2432720"
  },
  {
    "text": "right if the human carries a heavier box or all the heavier boxes that the robot could have been carrying then if you",
    "start": "2432720",
    "end": "2438480"
  },
  {
    "text": "sum this up over the entire operation it's going to just take longer because the human was doing sub-optimal actions",
    "start": "2438480",
    "end": "2444160"
  },
  {
    "text": "so maybe if you realize the human has a tendency to carry our heavy things you should jump in and carry those",
    "start": "2444160",
    "end": "2449200"
  },
  {
    "text": "heavier things for the robot so you could think of any sort of palm tp you know belief tree",
    "start": "2449200",
    "end": "2455280"
  },
  {
    "text": "solver using their model to propagate forward and explore different trees and then",
    "start": "2455280",
    "end": "2460400"
  },
  {
    "text": "determine what best action you should take that will lead to optimality for the entire team where you're kind of playing",
    "start": "2460400",
    "end": "2465839"
  },
  {
    "text": "their scenario in your mind and this should ring some bells for you i think in terms of game",
    "start": "2465839",
    "end": "2470880"
  },
  {
    "text": "theory approaches but usually in those methods it's adversarial right you're trying to beat the person here",
    "start": "2470880",
    "end": "2476960"
  },
  {
    "text": "you're asking what can i do to be an effective a more effective teammate and bring more optimality to the team",
    "start": "2476960",
    "end": "2484560"
  },
  {
    "text": "uh this sort of thinking can be applied to the case of shared autonomy right so if you",
    "start": "2484960",
    "end": "2490400"
  },
  {
    "text": "actually look at the space of autonomous vehicles a lot of it as we approach level 5 and 6",
    "start": "2490400",
    "end": "2496960"
  },
  {
    "text": "autonomy is these cars will become really smart and we'll just hand over control and we can just actually just rip the",
    "start": "2496960",
    "end": "2503839"
  },
  {
    "text": "steering wheel out and we don't need this anymore and so i personally disagree i think we",
    "start": "2503839",
    "end": "2509599"
  },
  {
    "text": "will always want to drive cars especially as they get uh newer faster sleeker you know and",
    "start": "2509599",
    "end": "2515359"
  },
  {
    "text": "elon musk puts out the best next best tesla we're going to want to drive it period",
    "start": "2515359",
    "end": "2520480"
  },
  {
    "text": "and so if you want to think about how you can actually get the best of both worlds it becomes quite essential",
    "start": "2520480",
    "end": "2525520"
  },
  {
    "text": "to think about how uh handover and control can be both safe and smooth um and",
    "start": "2525520",
    "end": "2532240"
  },
  {
    "text": "uh on top of that right uh you know arc has been warning us for a long time that",
    "start": "2532240",
    "end": "2537280"
  },
  {
    "text": "there's going to possibly be some reason you want to take over i don't subscribe to that but um let's let's cater to that and build",
    "start": "2537280",
    "end": "2543119"
  },
  {
    "text": "for this uh eventuality so uh leveraging human intent for shared",
    "start": "2543119",
    "end": "2548880"
  },
  {
    "text": "autonomy if you kind of think of this controller and plant paradigm here you have mh which is a model of the",
    "start": "2548880",
    "end": "2556560"
  },
  {
    "text": "human you have mr which is the action policy of the robot you're asking what action would the",
    "start": "2556560",
    "end": "2562480"
  },
  {
    "text": "human take given the states of the system and the actions that the robot has taken to date what's the state",
    "start": "2562480",
    "end": "2567839"
  },
  {
    "text": "transition model and what is the human action policy so what's really fantastic with this sort",
    "start": "2567839",
    "end": "2573680"
  },
  {
    "text": "of setup is as you're driving if you have a model of the human before you actually hand over control",
    "start": "2573680",
    "end": "2580000"
  },
  {
    "text": "and let it be just a boolean switch as you might do in a lot of shared autonomy literature",
    "start": "2580000",
    "end": "2585680"
  },
  {
    "text": "if you actually just observe their input for a while you can say does this input match to a safe set",
    "start": "2585680",
    "end": "2592079"
  },
  {
    "text": "so let's say you're on the highway and you're driving around a curve there's a particular range or variance that's allowable in",
    "start": "2592079",
    "end": "2598160"
  },
  {
    "text": "the gas pedal and a particular range and variance that's allowable in the steering angle to actually maintain safe control so if",
    "start": "2598160",
    "end": "2605440"
  },
  {
    "text": "you have a disconnected input and the human is um driving as if they were actually driving you can monitor",
    "start": "2605440",
    "end": "2610880"
  },
  {
    "text": "over some finite amount of time what their input is and if it matches to the safe set then you know you can actually blend the",
    "start": "2610880",
    "end": "2616880"
  },
  {
    "text": "control input safely from the robot to the human right and if you're going the other way um",
    "start": "2616880",
    "end": "2622720"
  },
  {
    "text": "possibly handing over control at non-zero speeds from the human to the robot vice versa all right if something's",
    "start": "2622720",
    "end": "2628400"
  },
  {
    "text": "going on and perhaps the robot doesn't sense something in its path it can react in an",
    "start": "2628400",
    "end": "2635119"
  },
  {
    "text": "efficient way and particularly um again ar can play a really big role because",
    "start": "2635119",
    "end": "2640319"
  },
  {
    "text": "in addition to risk presentation right you can imagine the robot's plan",
    "start": "2640319",
    "end": "2647680"
  },
  {
    "text": "also being displayed in a sort of holographic way in the future in these sort of",
    "start": "2647680",
    "end": "2652800"
  },
  {
    "text": "windshields and i think that's really critical for self-driving cars for us to actually build and maintain",
    "start": "2652800",
    "end": "2659440"
  },
  {
    "text": "trust of these vehicles so if you see something or someone getting ready to walk in your path",
    "start": "2659440",
    "end": "2664640"
  },
  {
    "text": "and the car is able to efficiently convey its plan to you you can actually detect hopefully a",
    "start": "2664640",
    "end": "2671200"
  },
  {
    "text": "non-frequent but possible fault right and that would actually cue you in that you might need to take some action before",
    "start": "2671200",
    "end": "2678319"
  },
  {
    "text": "the risk was in fact imminent",
    "start": "2678319",
    "end": "2682480"
  },
  {
    "text": "so some takeaways to be effective collaborators with humans robots must be able to model human",
    "start": "2685599",
    "end": "2691440"
  },
  {
    "start": "2686000",
    "end": "3579000"
  },
  {
    "text": "behavior and their role there's significant room for improvement in robotic hardware for alternate forms",
    "start": "2691440",
    "end": "2697839"
  },
  {
    "text": "of communication such as audio visual or tactile and robotic collaborators",
    "start": "2697839",
    "end": "2702960"
  },
  {
    "text": "have the potential to expand their human teammates capabilities which will enhance and restore",
    "start": "2702960",
    "end": "2708400"
  },
  {
    "text": "quality of life thank you thank you so much i will um",
    "start": "2708400",
    "end": "2715760"
  },
  {
    "text": "copy paste for those who are in the audience please feel free to submit any questions",
    "start": "2715760",
    "end": "2721200"
  },
  {
    "text": "from monroe to the google form here for those who are panelists the 20 or so faculty and",
    "start": "2721200",
    "end": "2728319"
  },
  {
    "text": "phd students here please feel free to just unmute and and ask the question",
    "start": "2728319",
    "end": "2733839"
  },
  {
    "text": "directly uh i will start with one that i've been wondering about",
    "start": "2733839",
    "end": "2738880"
  },
  {
    "text": "it seems like one real strength of sort of what i'll call the mechanical engineering approach here is that you have",
    "start": "2738880",
    "end": "2744839"
  },
  {
    "text": "um firm models of how the world works where i think you know a lot of a lot of",
    "start": "2744839",
    "end": "2750480"
  },
  {
    "text": "us in computer science you just argue for sort of the unfair success of pure just like get data and",
    "start": "2750480",
    "end": "2757760"
  },
  {
    "text": "let the model figure it out and the i really like the idea of trying to",
    "start": "2757760",
    "end": "2763040"
  },
  {
    "text": "blend the two that seems like intuitively it's probably the right answer i wonder um how we",
    "start": "2763040",
    "end": "2770319"
  },
  {
    "text": "manage it when you know there okay so in the data-driven environment",
    "start": "2770319",
    "end": "2775359"
  },
  {
    "text": "we have this issue of like well what happens when we you know when there's a distribution shift right so we train over here and then we see something we've never seen",
    "start": "2775359",
    "end": "2781200"
  },
  {
    "text": "before and then we do something silly on the other hand when we're in a model driven world like you talked about you",
    "start": "2781200",
    "end": "2786800"
  },
  {
    "text": "know opening the door we can model in a particular way what do we do there when we see something we've never seen before we",
    "start": "2786800",
    "end": "2792079"
  },
  {
    "text": "have no closed form model for it like how how would you think about trying to address these sort of",
    "start": "2792079",
    "end": "2797839"
  },
  {
    "text": "um new experiences in in this kind of a world",
    "start": "2797839",
    "end": "2803520"
  },
  {
    "text": "so that's that's a great question and i think it has quite a few parts to it um and brings up a point",
    "start": "2803520",
    "end": "2809359"
  },
  {
    "text": "that i think is really important i think ultimately right the at the very basis of your question is um what if your",
    "start": "2809359",
    "end": "2816960"
  },
  {
    "text": "model is just wrong right if you have an analytical model that's just wrong there's a scenario",
    "start": "2816960",
    "end": "2822160"
  },
  {
    "text": "you've never seen it's just not present you're going to suffer the same way as if you had a data driven model",
    "start": "2822160",
    "end": "2828640"
  },
  {
    "text": "right so i think fundamentally if you observe a scenario you've never seen before and it's not reflected in your",
    "start": "2828640",
    "end": "2834400"
  },
  {
    "text": "model you have issues right and then the question is simply how do you adapt so like in you know the more mechanical",
    "start": "2834400",
    "end": "2841760"
  },
  {
    "text": "slash controls paradigm you know you kind of see the literature shifting to you know adaptive control",
    "start": "2841760",
    "end": "2848079"
  },
  {
    "text": "techniques or stochastic control where we realize okay we may not always know the answer and",
    "start": "2848079",
    "end": "2853520"
  },
  {
    "text": "even robust control but we can sometimes you know double down on our model or adapt right",
    "start": "2853520",
    "end": "2859040"
  },
  {
    "text": "um and so i think from that kind of standpoint there's a lot of parallel because the",
    "start": "2859040",
    "end": "2864880"
  },
  {
    "text": "fundamental issue beyond the approach is still the same right whatever model you initially had is just not being",
    "start": "2864880",
    "end": "2870839"
  },
  {
    "text": "reflected in what you're observing i think however there's a deeper point",
    "start": "2870839",
    "end": "2875920"
  },
  {
    "text": "i'd like to make which is a risk that happens",
    "start": "2875920",
    "end": "2881119"
  },
  {
    "text": "if you um don't really approach the modeling the correct way so if i if",
    "start": "2881119",
    "end": "2886720"
  },
  {
    "text": "i were to give you a very large um you know and i like to think of this in sort of a manifold um sort of space the dynamics giving",
    "start": "2886720",
    "end": "2893520"
  },
  {
    "text": "some state what are some outputs right if you think of this as a manifold right if you um have a a few inputs",
    "start": "2893520",
    "end": "2900880"
  },
  {
    "text": "right that you say okay in this in this particular uh range i'm confident on how i'm actually",
    "start": "2900880",
    "end": "2906079"
  },
  {
    "text": "modeling my system um but further out right it may perform less accurately",
    "start": "2906079",
    "end": "2911920"
  },
  {
    "text": "the key even in regular dynamics or even in physics right is to actually you see us uh develop",
    "start": "2911920",
    "end": "2918160"
  },
  {
    "text": "analytical models that do a much better job of explaining the sort of quantum uh",
    "start": "2918160",
    "end": "2923520"
  },
  {
    "text": "feature if you will um of whatever it is we're trying to um describe right if you think about a dynamical",
    "start": "2923520",
    "end": "2929599"
  },
  {
    "text": "model i can take some really you know a big",
    "start": "2929599",
    "end": "2934800"
  },
  {
    "text": "description of how the state space is changing but if i try to move toward generalized coordinates i'm saying",
    "start": "2934800",
    "end": "2939839"
  },
  {
    "text": "what's the most essential thing i need to know in order to predict the behavior how can i make my model as concise",
    "start": "2939839",
    "end": "2945599"
  },
  {
    "text": "and generalizable as possible so that it is both accurate where i've seen it",
    "start": "2945599",
    "end": "2950960"
  },
  {
    "text": "demonstrated as well as further out and i'll make a high-level claim that you know even in terms of cognitive thinking we do the",
    "start": "2950960",
    "end": "2957359"
  },
  {
    "text": "same thing you know physicists if they're explaining some phenomenon you know that's way on his face",
    "start": "2957359",
    "end": "2962720"
  },
  {
    "text": "they're actually their model descriptions are actually going smaller to predict larger outcomes that are",
    "start": "2962720",
    "end": "2968240"
  },
  {
    "text": "further away robots need to do the same thing right when we observe the space our models need to become more quantum",
    "start": "2968240",
    "end": "2974880"
  },
  {
    "text": "smaller accurate smaller models that are accurate everywhere in order to expect them are",
    "start": "2974880",
    "end": "2980079"
  },
  {
    "text": "generalizable in order to expect them to be to behave even further away from where",
    "start": "2980079",
    "end": "2985520"
  },
  {
    "text": "we did and i would say you know one kind of big step in that direction is even",
    "start": "2985520",
    "end": "2990640"
  },
  {
    "text": "variational you know auto encoders right you know this is saying i'm looking at this state this system and i'm asking can i",
    "start": "2990640",
    "end": "2997200"
  },
  {
    "text": "compress that information into its most condensed form and then use that to",
    "start": "2997200",
    "end": "3002480"
  },
  {
    "text": "extrapolate back to how you know the world behaves or the key aspects of how the world behaves",
    "start": "3002480",
    "end": "3009440"
  },
  {
    "text": "and so i think you know at every level of cognition from you know low-level action",
    "start": "3009440",
    "end": "3015119"
  },
  {
    "text": "controllers to high-level planners or even you know if you want robots to think about bigger questions",
    "start": "3015119",
    "end": "3020880"
  },
  {
    "text": "we need to follow the trends that humans do which is make your models accurate and small",
    "start": "3020880",
    "end": "3026079"
  },
  {
    "text": "and generalizable so that they can extend beyond the space that you see them which means you truly understand the underlying manifold",
    "start": "3026079",
    "end": "3033839"
  },
  {
    "text": "that you're trying to represent and do you as just a quick follow-up on that do you think that the approach here",
    "start": "3033839",
    "end": "3041040"
  },
  {
    "text": "is going to be different in terms of dealing with unanticipated unanticipated phenomena in the physical world versus",
    "start": "3041040",
    "end": "3046079"
  },
  {
    "text": "unanticipated phenomena sort of human behavior world i think",
    "start": "3046079",
    "end": "3051119"
  },
  {
    "text": "physics definitely gives you the benefit that if you stay at a particular scale things",
    "start": "3051119",
    "end": "3056480"
  },
  {
    "text": "can be considered deterministic and that can that can definitely help um",
    "start": "3056480",
    "end": "3062240"
  },
  {
    "text": "but i think you know a lot of times there are rules that govern just about everything right",
    "start": "3062240",
    "end": "3067359"
  },
  {
    "text": "you know true randomness is actually you know you don't really see that a lot there's some usually some big guiding",
    "start": "3067359",
    "end": "3074079"
  },
  {
    "text": "principles i mean particularly in robotics where you want to take action and make decisions based",
    "start": "3074079",
    "end": "3079520"
  },
  {
    "text": "on some phenomena you're assuming usually that there is some underlying um",
    "start": "3079520",
    "end": "3084960"
  },
  {
    "text": "description model description that is there to be obtained right um so i think that's that's",
    "start": "3084960",
    "end": "3092240"
  },
  {
    "text": "uh important yeah cool i will um stop dominating the floor if there are",
    "start": "3092240",
    "end": "3097680"
  },
  {
    "text": "any panelists or anyone who wants to jump in with a question i have more more more to ask but i i",
    "start": "3097680",
    "end": "3103280"
  },
  {
    "text": "feel like this is not a two-person conversation i i have a question so thanks so much monroe for this really",
    "start": "3103280",
    "end": "3109200"
  },
  {
    "text": "exciting and and very diverse talk of lots of different uh topics i think that is certainly",
    "start": "3109200",
    "end": "3114800"
  },
  {
    "text": "uh you know intersects between robotics human robot interaction and uh yeah i see a lot of overlap with hci",
    "start": "3114800",
    "end": "3121920"
  },
  {
    "text": "topics as well i'm wondering you know as you think about closing this loop between uh you know",
    "start": "3121920",
    "end": "3128079"
  },
  {
    "text": "basically putting the human in the loop more and a lot of these assistive robotic systems",
    "start": "3128079",
    "end": "3133119"
  },
  {
    "text": "what do you think the the role of that augmented reality um you know system can be and",
    "start": "3133119",
    "end": "3139200"
  },
  {
    "text": "you know are there ways to to use that in a in a you know more direct control sense to be able to",
    "start": "3139200",
    "end": "3145359"
  },
  {
    "text": "provide you know visual feedback to someone in terms of you know how they might think about using their you know sensory",
    "start": "3145359",
    "end": "3151839"
  },
  {
    "text": "motor control system as opposed to you know kind of the higher level of kind of uh",
    "start": "3151839",
    "end": "3156960"
  },
  {
    "text": "you know basically this is the the planning or or whatnot are there ways to you know uh kind of bring that more in",
    "start": "3156960",
    "end": "3164079"
  },
  {
    "text": "the in this tighter loop that you showed yeah so i guess um just rephrasing to",
    "start": "3164079",
    "end": "3171440"
  },
  {
    "text": "make sure i understand it you know your question completely so you know thinking about you know how ar can play a bigger role in these sort",
    "start": "3171440",
    "end": "3177920"
  },
  {
    "text": "of you know feedback control loops how can it actually play a role on lower level controls um for a particular system so i think",
    "start": "3177920",
    "end": "3184960"
  },
  {
    "text": "absolutely um they definitely have the ability to do that um i would kind of refer back to that",
    "start": "3184960",
    "end": "3190800"
  },
  {
    "text": "kind of human control loop um idea again right how does",
    "start": "3190800",
    "end": "3196240"
  },
  {
    "text": "our vision directly correlate to actions that we take um i think you know on a very",
    "start": "3196240",
    "end": "3201520"
  },
  {
    "text": "fundamental level you know we have reflexes you know so if you see something move into your field of view really quickly",
    "start": "3201520",
    "end": "3206720"
  },
  {
    "text": "there's clearly that kind of response that you may take but then on the other side too you know we're",
    "start": "3206720",
    "end": "3212079"
  },
  {
    "text": "always looking at information and interpreting it and making some decision based on what",
    "start": "3212079",
    "end": "3217920"
  },
  {
    "text": "we see and what's really fantastic about you know where ar is actually",
    "start": "3217920",
    "end": "3222960"
  },
  {
    "text": "going is you actually have both sides of that right you have cameras that are out facing which are",
    "start": "3222960",
    "end": "3228480"
  },
  {
    "text": "localizing the system as well as observing the environment can be used for that and we have a lot of work in computer",
    "start": "3228480",
    "end": "3234000"
  },
  {
    "text": "vision that's really working to have better contextual understandings of environments and then you have the",
    "start": "3234000",
    "end": "3240319"
  },
  {
    "text": "ability to even ask questions if you will to the person by presenting information that you think",
    "start": "3240319",
    "end": "3246079"
  },
  {
    "text": "is important and what they're focusing on or even hypothetical objects and they're seeing to see how they would react",
    "start": "3246079",
    "end": "3253599"
  },
  {
    "text": "right to this um sort of uh um input right so i think with all of that right",
    "start": "3253599",
    "end": "3259920"
  },
  {
    "text": "you know there's how does the you know what what a what does what do your eyes see and b how does your mind process what it",
    "start": "3259920",
    "end": "3267119"
  },
  {
    "text": "sees to take some action you know so i think we're we're getting well developed on the a part right which is what can the eye see",
    "start": "3267119",
    "end": "3274160"
  },
  {
    "text": "and can we interpret that but modeling how we make decisions based on some you know set of assumptions of what",
    "start": "3274160",
    "end": "3280160"
  },
  {
    "text": "we're doing that's definitely the more difficult problem uh to solve but i think by having that sort",
    "start": "3280160",
    "end": "3287040"
  },
  {
    "text": "of interception right because whatever you're seeing is literally being transformed through",
    "start": "3287040",
    "end": "3293280"
  },
  {
    "text": "the ar if you're doing something while you're wearing it then you can kind of be guaranteed to a point that you're not really missing",
    "start": "3293280",
    "end": "3299280"
  },
  {
    "text": "anything at least from the vision perspective because you're intercepting that data directly so if they made some",
    "start": "3299280",
    "end": "3306000"
  },
  {
    "text": "decision based on what they saw you know the information was present you just have to figure out what it was",
    "start": "3306000",
    "end": "3311280"
  },
  {
    "text": "and what was the underlying model that led to the actions that they took right and then that that leads to a lot",
    "start": "3311280",
    "end": "3316480"
  },
  {
    "text": "of interesting um research one other question that",
    "start": "3316480",
    "end": "3322319"
  },
  {
    "text": "came up um i will do my best to proxy it basically putting your working",
    "start": "3322319",
    "end": "3327760"
  },
  {
    "text": "conversation with some accessibility researchers including one who we heard last week",
    "start": "3327760",
    "end": "3333680"
  },
  {
    "text": "you know your work scene has also some accessibility motivations and one of the one of the patterns that",
    "start": "3333680",
    "end": "3341520"
  },
  {
    "text": "seems to be recurring across the ability-based design space and the accessibility space",
    "start": "3341520",
    "end": "3346960"
  },
  {
    "text": "is that there's essentially a very very wide space of accessibility needs that",
    "start": "3346960",
    "end": "3353440"
  },
  {
    "text": "it's you know sort of bespoke solutions for bespoke problems because though my um my abilities may not match",
    "start": "3353440",
    "end": "3360880"
  },
  {
    "text": "any you know the this one this person's or that person's or that person's and i'm wondering again sort of in in",
    "start": "3360880",
    "end": "3366720"
  },
  {
    "text": "the approach that you're envisioning how do we do the kind of manual tuning that we need",
    "start": "3366720",
    "end": "3372319"
  },
  {
    "text": "to you know to understand this person's specific model or their own abilities",
    "start": "3372319",
    "end": "3377359"
  },
  {
    "text": "then map that on to the kinds of support that you that you that you're building",
    "start": "3377359",
    "end": "3382960"
  },
  {
    "text": "that's a fantastic question um and one yet very important to traditional like assistive technology um",
    "start": "3383359",
    "end": "3390240"
  },
  {
    "text": "i think you know when it comes to actually you know deploying systems for people you know there's",
    "start": "3390240",
    "end": "3395680"
  },
  {
    "text": "everyone's needs will be a little different um and i think that kind of goes against",
    "start": "3395680",
    "end": "3401920"
  },
  {
    "text": "traditional sort of engineering large-scale sort of thinking right you want to design a solution that has the",
    "start": "3401920",
    "end": "3407200"
  },
  {
    "text": "maximum impact as quickly as you can um so i think what you really",
    "start": "3407200",
    "end": "3412319"
  },
  {
    "text": "the point you're raising is how do you think about that sort of adaptiveness from a wide scale solution to um",
    "start": "3412319",
    "end": "3420319"
  },
  {
    "text": "you know the individual's needs i think again you know framing it in the",
    "start": "3420319",
    "end": "3426240"
  },
  {
    "text": "context of what you need to do if i think particularly let's say about like the prosthetic arm just for an example",
    "start": "3426240",
    "end": "3432000"
  },
  {
    "text": "the activities of daily living are going to be similar for everyone right but generalizability is the key",
    "start": "3432000",
    "end": "3438640"
  },
  {
    "text": "you know you may open you know different types of cans than another person or you may have a different type of can opener but you're",
    "start": "3438640",
    "end": "3444799"
  },
  {
    "text": "still going for the same type of task so that means if i'm giving a more general solution i",
    "start": "3444799",
    "end": "3450000"
  },
  {
    "text": "need a solution that a understands at a high level what you're trying to do and without too much effort",
    "start": "3450000",
    "end": "3455520"
  },
  {
    "text": "can be adapted to your particular scenario and that goes both for an outward facing you know interacting with the",
    "start": "3455520",
    "end": "3461200"
  },
  {
    "text": "environment and an inward facing right and that's really important when you think about amputee",
    "start": "3461200",
    "end": "3466799"
  },
  {
    "text": "amputees um because every amputation is not going to be exactly the same right where do you actually put the emg",
    "start": "3466799",
    "end": "3474079"
  },
  {
    "text": "feedback sensors in order for them to actually be able to control that system right and that's going to be",
    "start": "3474079",
    "end": "3480079"
  },
  {
    "text": "different for every single person so for all of these types of adaptation i think that can",
    "start": "3480079",
    "end": "3485520"
  },
  {
    "text": "hopefully if you do your engineering correctly can be closer to a last step where you have all of these abilities",
    "start": "3485520",
    "end": "3490960"
  },
  {
    "text": "present in this sort of device at the end of the day on this technology and then the last step is then",
    "start": "3490960",
    "end": "3496079"
  },
  {
    "text": "calibrating that for a particular individual and if you actually look at you know the existing sort of power",
    "start": "3496079",
    "end": "3502160"
  },
  {
    "text": "prosthesis that use emg signals there is a whole phase it's just centered on",
    "start": "3502160",
    "end": "3507760"
  },
  {
    "text": "calibrating for that person right they learn to actuate based on their particular setup so i",
    "start": "3507760",
    "end": "3512960"
  },
  {
    "text": "think that kind of last step particularly for devices that are um serving these sort of assistive needs",
    "start": "3512960",
    "end": "3519280"
  },
  {
    "text": "like this um there will be a level of the system needing to be particularly tuned for each individual",
    "start": "3519280",
    "end": "3526319"
  },
  {
    "text": "but hopefully if you create a system that can be very generic and can adapt easily",
    "start": "3526319",
    "end": "3532079"
  },
  {
    "text": "hopefully the overhead for that can be small and the capabilities the reward can hopefully be large",
    "start": "3532079",
    "end": "3539760"
  },
  {
    "text": "thanks i i look forward to that future i think we all do um well let's thank",
    "start": "3541040",
    "end": "3546799"
  },
  {
    "text": "our speaker one last time thank you monroe for joining us um the we we look forward to seeing you",
    "start": "3546799",
    "end": "3553520"
  },
  {
    "text": "on campus when we are on campus and in the meantime i encourage everyone here if you're interested",
    "start": "3553520",
    "end": "3559359"
  },
  {
    "text": "in uh if you're interested in this space to please uh reach out to monroe you know",
    "start": "3559359",
    "end": "3565440"
  },
  {
    "text": "we are still distributed but but one big one big group so thanks again and i will uh end the",
    "start": "3565440",
    "end": "3572000"
  },
  {
    "text": "seminar here thank you",
    "start": "3572000",
    "end": "3580400"
  }
]
[
  {
    "text": "Now we're going to move on\nto a new problem, document",
    "start": "0",
    "end": "3620"
  },
  {
    "text": "classification, and we'll use\nas an example, the IMDb movie",
    "start": "3620",
    "end": "10130"
  },
  {
    "text": "reviews database.",
    "start": "10130",
    "end": "12170"
  },
  {
    "text": "So IMDb is a corpus.",
    "start": "12170",
    "end": "15270"
  },
  {
    "text": "There's an app and\nyou can look at it",
    "start": "15270",
    "end": "17180"
  },
  {
    "text": "and it gives you\nreviews of movies,",
    "start": "17180",
    "end": "19910"
  },
  {
    "text": "so you can look up\ndetails of movies.",
    "start": "19910",
    "end": "22340"
  },
  {
    "text": "And they've also\ngot user reviews",
    "start": "22340",
    "end": "24500"
  },
  {
    "text": "so people can contribute\nreviews to IMDb,",
    "start": "24500",
    "end": "28010"
  },
  {
    "text": "and you can look at the reviews.",
    "start": "28010",
    "end": "30110"
  },
  {
    "text": "Now a review is a document.",
    "start": "30110",
    "end": "32508"
  },
  {
    "text": "It's usually a short\ndocument, and it's",
    "start": "32509",
    "end": "36559"
  },
  {
    "text": "what people they just say\nsomething about the movie",
    "start": "36560",
    "end": "39410"
  },
  {
    "text": "and sometimes they positive,\nsometimes they negative.",
    "start": "39410",
    "end": "42260"
  },
  {
    "text": "And there's a corpus, the IMDb\ncorpus has got 50,000 reviews,",
    "start": "42260",
    "end": "50269"
  },
  {
    "text": "and they've been\nrated by labelers,",
    "start": "50270",
    "end": "54110"
  },
  {
    "text": "and they've been rated in\nterms of sentiment as positive",
    "start": "54110",
    "end": "57530"
  },
  {
    "text": "or negative.",
    "start": "57530",
    "end": "59530"
  },
  {
    "text": "And so some people\nread the reviews",
    "start": "59530",
    "end": "61809"
  },
  {
    "text": "and decided this is\na positive review,",
    "start": "61810",
    "end": "63490"
  },
  {
    "text": "this is a negative review.",
    "start": "63490",
    "end": "65230"
  },
  {
    "text": "And so that label\nhas been assigned",
    "start": "65230",
    "end": "67000"
  },
  {
    "text": "and half the reviews in this\ncorpus are labeled positive,",
    "start": "67000",
    "end": "70660"
  },
  {
    "text": "half are negative.",
    "start": "70660",
    "end": "71660"
  },
  {
    "text": "It might sound\nlike an easy task,",
    "start": "71660",
    "end": "73090"
  },
  {
    "text": "but the English language,\nany language is subtle.",
    "start": "73090",
    "end": "76340"
  },
  {
    "text": "People can be sarcastic\nand might be using words",
    "start": "76340",
    "end": "79420"
  },
  {
    "text": "that computer might\nthink are positive,",
    "start": "79420",
    "end": "81640"
  },
  {
    "text": "but actually they're being\nit's a negative sentiment.",
    "start": "81640",
    "end": "85960"
  },
  {
    "text": "So that's the challenge here.",
    "start": "85960",
    "end": "88290"
  },
  {
    "text": "So we give you an\nexample of a review.",
    "start": "88290",
    "end": "91630"
  },
  {
    "text": "This has to be one of the\nworst films of the 1990s.",
    "start": "91630",
    "end": "95250"
  },
  {
    "text": "This one's pretty clear.",
    "start": "95250",
    "end": "96250"
  },
  {
    "text": "This one's pretty clear to me.",
    "start": "96250",
    "end": "99040"
  },
  {
    "text": "No subtlety here.",
    "start": "99040",
    "end": "101341"
  },
  {
    "text": "It's quite funny, this one.",
    "start": "101341",
    "end": "104760"
  },
  {
    "text": "The rest of the time,\neveryone else in the theater",
    "start": "104760",
    "end": "106890"
  },
  {
    "text": "just started talking\nto each other,",
    "start": "106890",
    "end": "108180"
  },
  {
    "text": "leaving or generally\ncrying into their popcorn.",
    "start": "108180",
    "end": "110205"
  },
  {
    "start": "110205",
    "end": "112770"
  },
  {
    "text": "So the one question\nis, how do you",
    "start": "112770",
    "end": "115200"
  },
  {
    "text": "represent a review, which is\na sort of open-ended document?",
    "start": "115200",
    "end": "120930"
  },
  {
    "text": "I mean, the reviews can have\ndifferent number of words.",
    "start": "120930",
    "end": "123580"
  },
  {
    "text": "How do you represent it\nin terms of features?",
    "start": "123580",
    "end": "126820"
  },
  {
    "text": "So the goal here is to take\nthese words, take these reviews,",
    "start": "126820",
    "end": "131100"
  },
  {
    "text": "and automatically classify\nthe sentiment of the review.",
    "start": "131100",
    "end": "137440"
  },
  {
    "text": "So let's talk about\nfeaturization.",
    "start": "137440",
    "end": "140440"
  },
  {
    "text": "And the one we're\ngoing to use is known",
    "start": "140440",
    "end": "142500"
  },
  {
    "text": "as the bag of words model.",
    "start": "142500",
    "end": "144840"
  },
  {
    "text": "So documents have\ndifferent lengths",
    "start": "144840",
    "end": "147450"
  },
  {
    "text": "and they consist of\nsequences of words.",
    "start": "147450",
    "end": "150910"
  },
  {
    "text": "So how do we create features\nto characterize a document?",
    "start": "150910",
    "end": "154630"
  },
  {
    "text": "So here's what we do.",
    "start": "154630",
    "end": "156700"
  },
  {
    "text": "So from a dictionary, we\nidentify the 10,000 most",
    "start": "156700",
    "end": "160030"
  },
  {
    "text": "frequently occurring words,\nsay, in the English language.",
    "start": "160030",
    "end": "164110"
  },
  {
    "text": "Now, 10,000, that's a\nparameter which we decide",
    "start": "164110",
    "end": "167080"
  },
  {
    "text": "on, and that's what\nwe've used here.",
    "start": "167080",
    "end": "168840"
  },
  {
    "text": "You could make it\n15,000 if you like.",
    "start": "168840",
    "end": "171970"
  },
  {
    "text": "Then what you do is you create a\nbinary vector of length 10,000,",
    "start": "171970",
    "end": "176800"
  },
  {
    "text": "and for each document, you\nscore one in every position that",
    "start": "176800",
    "end": "180160"
  },
  {
    "text": "the corresponding word occurred.",
    "start": "180160",
    "end": "182680"
  },
  {
    "text": "So every time a word occurred,\nyou put a 1 in that position.",
    "start": "182680",
    "end": "186129"
  },
  {
    "text": "In other words, the position in\nthis dictionary of 10,000 words",
    "start": "186130",
    "end": "190660"
  },
  {
    "text": "where that word occurred, if\nit occurred more than once,",
    "start": "190660",
    "end": "193360"
  },
  {
    "text": "you just leave it\nas one in this case.",
    "start": "193360",
    "end": "195520"
  },
  {
    "text": "So if you've got n\ndocuments, now you're",
    "start": "195520",
    "end": "198800"
  },
  {
    "text": "going to have an n by p\nsparse feature matrix.",
    "start": "198800",
    "end": "202120"
  },
  {
    "text": "Let's call it x.",
    "start": "202120",
    "end": "204010"
  },
  {
    "text": "P is going to be 10,000.",
    "start": "204010",
    "end": "206590"
  },
  {
    "text": "You're going to have 10,000\nvariables for each observation.",
    "start": "206590",
    "end": "211900"
  },
  {
    "text": "Most of them are going to\nbe 0 because, you know,",
    "start": "211900",
    "end": "214620"
  },
  {
    "text": "the review might only have\na few hundred words in it.",
    "start": "214620",
    "end": "217680"
  },
  {
    "text": "So there's going to be-- most\nof the 10,000 values are going",
    "start": "217680",
    "end": "220859"
  },
  {
    "text": "to be 0.",
    "start": "220860",
    "end": "223110"
  },
  {
    "text": "So that's how you do it.",
    "start": "223110",
    "end": "225360"
  },
  {
    "text": "We're going to compare a\nlasso logistic regression",
    "start": "225360",
    "end": "228540"
  },
  {
    "text": "model to two hidden layer neural\nnetwork on the next slide.",
    "start": "228540",
    "end": "234239"
  },
  {
    "text": "No convolutions here, just\na regular neural network.",
    "start": "234240",
    "end": "238950"
  },
  {
    "text": "I should just add\nthe bag of words are",
    "start": "238950",
    "end": "240989"
  },
  {
    "text": "what's known as unigrams.",
    "start": "240990",
    "end": "243030"
  },
  {
    "text": "You can also use bigrams, which\nis the occurrence of pairs",
    "start": "243030",
    "end": "248370"
  },
  {
    "text": "of words, like, very good.",
    "start": "248370",
    "end": "251180"
  },
  {
    "text": "That would be a\nparticular bigram.",
    "start": "251180",
    "end": "253659"
  },
  {
    "text": "And so you can see if\nyou got 10,000 words,",
    "start": "253660",
    "end": "256028"
  },
  {
    "text": "a number of bigrams grows\nas the square of 10,000,",
    "start": "256029",
    "end": "261799"
  },
  {
    "text": "so they get much bigger.",
    "start": "261800",
    "end": "263960"
  },
  {
    "text": "And in general, you\ncan have m grams,",
    "start": "263960",
    "end": "267147"
  },
  {
    "text": "but we're not going\nto go there today.",
    "start": "267147",
    "end": "268730"
  },
  {
    "text": "We'll just stay\nwith the unigrams",
    "start": "268730",
    "end": "270340"
  },
  {
    "text": "or the bag of words model.",
    "start": "270340",
    "end": "271870"
  },
  {
    "text": "Well, here's a result. We're\nshowing you two pictures here.",
    "start": "271870",
    "end": "276760"
  },
  {
    "text": "The one is the result\nof fitting lasso,",
    "start": "276760",
    "end": "280180"
  },
  {
    "text": "and we used the glmnet\nprogram in R to do that.",
    "start": "280180",
    "end": "284139"
  },
  {
    "text": "And what we show\nyou is as a function",
    "start": "284140",
    "end": "287710"
  },
  {
    "text": "of the regularization\nparameter lambda for the lasso.",
    "start": "287710",
    "end": "291680"
  },
  {
    "text": "In fact, we plot against\nminus log of lambda.",
    "start": "291680",
    "end": "294550"
  },
  {
    "text": "We show three curves.",
    "start": "294550",
    "end": "296300"
  },
  {
    "text": "We've got the training\naccuracy, we've",
    "start": "296300",
    "end": "299889"
  },
  {
    "text": "got the validation\naccuracy, we put aside",
    "start": "299890",
    "end": "302800"
  },
  {
    "text": "a small subset of\nthe data to decide",
    "start": "302800",
    "end": "306909"
  },
  {
    "text": "when to stop the lasso\nregularization path,",
    "start": "306910",
    "end": "310760"
  },
  {
    "text": "and then we got the test\ndata set, which is in orange.",
    "start": "310760",
    "end": "314180"
  },
  {
    "text": "You can see the test and\nvalidation pretty much",
    "start": "314180",
    "end": "316160"
  },
  {
    "text": "on top of each other.",
    "start": "316160",
    "end": "317600"
  },
  {
    "text": "So the validation data\nset, and this accuracy,",
    "start": "317600",
    "end": "320630"
  },
  {
    "text": "we want to get high so you can\nget an accuracy of close to 90%",
    "start": "320630",
    "end": "326690"
  },
  {
    "text": "correct.",
    "start": "326690",
    "end": "328010"
  },
  {
    "text": "The validation tells\nus when to stop",
    "start": "328010",
    "end": "330440"
  },
  {
    "text": "in the lasso path\nin glmnet, and then",
    "start": "330440",
    "end": "335720"
  },
  {
    "text": "the test accuracy we can\nsee is pretty much the same.",
    "start": "335720",
    "end": "339890"
  },
  {
    "text": "So that's using lasso.",
    "start": "339890",
    "end": "342830"
  },
  {
    "text": "Here's a neural network.",
    "start": "342830",
    "end": "344930"
  },
  {
    "text": "And again, for the\nneural network,",
    "start": "344930",
    "end": "347180"
  },
  {
    "text": "we show training error,\nvalidation and test error.",
    "start": "347180",
    "end": "350570"
  },
  {
    "text": "But this we put as a function\nof the number of epochs.",
    "start": "350570",
    "end": "354360"
  },
  {
    "text": "So the number of\nepochs you're going",
    "start": "354360",
    "end": "356400"
  },
  {
    "text": "to see when we train\na neural network.",
    "start": "356400",
    "end": "359740"
  },
  {
    "text": "We use a slow method\nof training, which",
    "start": "359740",
    "end": "361919"
  },
  {
    "text": "is known as gradient descent.",
    "start": "361920",
    "end": "363750"
  },
  {
    "text": "And the number of epochs\nis, as you'll find out,",
    "start": "363750",
    "end": "367620"
  },
  {
    "text": "is the number of times you've\nbeen through the whole training",
    "start": "367620",
    "end": "370350"
  },
  {
    "text": "set each time.",
    "start": "370350",
    "end": "372300"
  },
  {
    "text": "And so you can see the training\ngoes through the training set",
    "start": "372300",
    "end": "375569"
  },
  {
    "text": "20 times.",
    "start": "375570",
    "end": "377250"
  },
  {
    "text": "And that can be viewed as\na form of regularization.",
    "start": "377250",
    "end": "380500"
  },
  {
    "text": "And you can see as it\ngoes through the training,",
    "start": "380500",
    "end": "382500"
  },
  {
    "text": "the training error increases\nmuch like the lasso",
    "start": "382500",
    "end": "385410"
  },
  {
    "text": "did, but again, the--",
    "start": "385410",
    "end": "387960"
  },
  {
    "text": "You said the accuracy.",
    "start": "387960",
    "end": "389550"
  },
  {
    "text": "Sorry?",
    "start": "389550",
    "end": "390227"
  },
  {
    "text": "The accuracy--",
    "start": "390227",
    "end": "390810"
  },
  {
    "text": "Sorry, the accuracy.",
    "start": "390810",
    "end": "391840"
  },
  {
    "text": "Yes, and the validation\nerror maxes out fairly early",
    "start": "391840",
    "end": "396163"
  },
  {
    "text": "and then starts\ndecreasing because we're",
    "start": "396163",
    "end": "397830"
  },
  {
    "text": "starting to overfit.",
    "start": "397830",
    "end": "398995"
  },
  {
    "text": "So why is the neural net doing\na little better than lasso",
    "start": "398995",
    "end": "401370"
  },
  {
    "text": "here, you think?",
    "start": "401370",
    "end": "402479"
  },
  {
    "text": "Well, it's actually not true.",
    "start": "402480",
    "end": "403980"
  },
  {
    "text": "It's not?",
    "start": "403980",
    "end": "404530"
  },
  {
    "text": "It's not.",
    "start": "404530",
    "end": "405250"
  },
  {
    "text": "It looks-- yeah, it's a little\nhard to see, but it's not.",
    "start": "405250",
    "end": "407830"
  },
  {
    "text": "It's pretty much-- they pretty\nmuch on top of each other.",
    "start": "407830",
    "end": "411189"
  },
  {
    "text": "This number here, it's maybe a--",
    "start": "411190",
    "end": "413557"
  },
  {
    "text": "Little better.",
    "start": "413557",
    "end": "414140"
  },
  {
    "text": "A little bit, tiny bit.",
    "start": "414140",
    "end": "416740"
  },
  {
    "text": "And why?",
    "start": "416740",
    "end": "418539"
  },
  {
    "text": "It's got many more parameters.",
    "start": "418540",
    "end": "420123"
  },
  {
    "text": "Well, I was thinking,\nI mean, it's",
    "start": "420123",
    "end": "421539"
  },
  {
    "text": "capturing non-linearities\nand also interactions.",
    "start": "421540",
    "end": "424065"
  },
  {
    "text": "When you take\nlinear combinations",
    "start": "424065",
    "end": "425440"
  },
  {
    "text": "and put them together, you\ncan get interactions of words,",
    "start": "425440",
    "end": "427810"
  },
  {
    "text": "right?",
    "start": "427810",
    "end": "428310"
  },
  {
    "text": "That's true.",
    "start": "428310",
    "end": "429400"
  },
  {
    "text": "That's true.",
    "start": "429400",
    "end": "430160"
  },
  {
    "text": "The lasso, the linear model\ndoesn't capture interactions.",
    "start": "430160",
    "end": "432680"
  },
  {
    "text": "But the fact that\nthe linear model",
    "start": "432680",
    "end": "436060"
  },
  {
    "text": "starts overfitting\nfairly quickly, and so",
    "start": "436060",
    "end": "440050"
  },
  {
    "text": "does the neural network.",
    "start": "440050",
    "end": "441639"
  },
  {
    "text": "So yeah, I mean, I\nthink in the chapter",
    "start": "441640",
    "end": "445180"
  },
  {
    "text": "we concluded that\ntheir performance was",
    "start": "445180",
    "end": "447280"
  },
  {
    "text": "pretty much the same.",
    "start": "447280",
    "end": "449230"
  },
  {
    "text": "It turns out that glmnet\nis very effective here.",
    "start": "449230",
    "end": "451730"
  },
  {
    "text": "It's very quick, much quicker\nthan the neural network",
    "start": "451730",
    "end": "454120"
  },
  {
    "text": "in this case because\nit can exploit",
    "start": "454120",
    "end": "456250"
  },
  {
    "text": "the sparsity in the X matrix.",
    "start": "456250",
    "end": "458390"
  },
  {
    "text": "The X matrix is mostly\nzeros and glmnet",
    "start": "458390",
    "end": "463210"
  },
  {
    "text": "and the lasso model\ncan exploit that.",
    "start": "463210",
    "end": "466259"
  }
]
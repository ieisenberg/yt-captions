[
  {
    "start": "0",
    "end": "1615000"
  },
  {
    "text": "okay so I just want to some of my work is touch of an algorithmic fairness and",
    "start": "11139",
    "end": "16580"
  },
  {
    "text": "another big hump my work is trying to understand discrimination what it means the statistics of discrimination and so",
    "start": "16580",
    "end": "22070"
  },
  {
    "text": "I want to start out with a scenario so to see so I've been looking at traffic stops across the United States and one",
    "start": "22070",
    "end": "29210"
  },
  {
    "text": "of the findings that we see is that when we look at these hundred million traffic stops across the United States is that",
    "start": "29210",
    "end": "34730"
  },
  {
    "text": "black and Hispanic drivers when they're stopped they're about 50 percent more likely to be searched by officers and",
    "start": "34730",
    "end": "40730"
  },
  {
    "text": "one reason that this is potentially concerning and either their variety of reasons but one reason that is",
    "start": "40730",
    "end": "46100"
  },
  {
    "text": "potentially concerning is that there's bias in this decision to search and so at least in the u.s. there's a fair",
    "start": "46100",
    "end": "53690"
  },
  {
    "text": "amount of ambiguity and what constitutes a legal search and so the officer has a fair amount of discretion and usually",
    "start": "53690",
    "end": "60290"
  },
  {
    "text": "they're looking for drugs other types of contraband and so if I just tell you the statistic about 50 percent that that",
    "start": "60290",
    "end": "66950"
  },
  {
    "text": "blacks and Hispanics when they're stopped they're about 50 percent more likely to be searched by an officer what",
    "start": "66950",
    "end": "71960"
  },
  {
    "text": "do you think do you think this is evidence of discrimination do you think it's it's something else and they're",
    "start": "71960",
    "end": "78890"
  },
  {
    "text": "there no right or wrong answers here we're going to try to get into these these issues so what do you think is",
    "start": "78890",
    "end": "84829"
  },
  {
    "text": "this evidence of discrimination or not",
    "start": "84829",
    "end": "89530"
  },
  {
    "text": "if it's if we account for everything else then if we still see this disparity",
    "start": "98259",
    "end": "104569"
  },
  {
    "text": "then we would call that discrimination but of course I'm just telling you the stat I'm just telling you that roughly",
    "start": "104569",
    "end": "111799"
  },
  {
    "text": "50% more likely for black Hispanic to be searched that's a tree number in various state to state but you know this is this",
    "start": "111799",
    "end": "118159"
  },
  {
    "text": "is roughly true and so it sounds like that stat in and of itself you don't the",
    "start": "118159",
    "end": "123770"
  },
  {
    "text": "take as as definitive evidence of discrimination any other thoughts on this I think it depends on what is the",
    "start": "123770",
    "end": "130880"
  },
  {
    "text": "statistics who what races or ethnicities create the crimes",
    "start": "130880",
    "end": "137340"
  },
  {
    "text": "and then maybe that influencers assistant yeah right so this is so this",
    "start": "137340",
    "end": "143520"
  },
  {
    "text": "question the what's the baseline so it sounds like we're all pretty we are",
    "start": "143520",
    "end": "148950"
  },
  {
    "text": "skeptical that this fact in and of itself that that blacks and Hispanics when they're stopped they're they're",
    "start": "148950",
    "end": "154590"
  },
  {
    "text": "significantly more likely to be searched is strong evidence the discrimination maybe points in that direction but we",
    "start": "154590",
    "end": "159630"
  },
  {
    "text": "have agree that there's something funny about this so I just want to take two minutes in your groups and try to come",
    "start": "159630",
    "end": "164910"
  },
  {
    "text": "up with a better statistic okay it's just been two minutes thinking about this talk try to figure out what is what",
    "start": "164910",
    "end": "171750"
  },
  {
    "text": "is maybe something that would be more persuasive what is the test that you would like to run",
    "start": "171750",
    "end": "177079"
  },
  {
    "text": "okay what's ten more seconds so a few",
    "start": "179520",
    "end": "191440"
  },
  {
    "text": "what ideas do you have yes number five by total numbers are",
    "start": "191440",
    "end": "199600"
  },
  {
    "text": "just good at Christie's for one group there is a significantly lower so so",
    "start": "199600",
    "end": "215620"
  },
  {
    "text": "this is let's say each are so indexed by race now what so so what is the claim so",
    "start": "215620",
    "end": "247360"
  },
  {
    "text": "what is the measure of discrimination here if there's significant difference",
    "start": "247360",
    "end": "252489"
  },
  {
    "text": "among races at the age of art so let's say I have each it's a which direction",
    "start": "252489",
    "end": "259180"
  },
  {
    "text": "well it's a black each the white okay",
    "start": "259180",
    "end": "268510"
  },
  {
    "text": "you elaborate just a little bit more on this because it means that black people",
    "start": "268510",
    "end": "274479"
  },
  {
    "text": "are being searched a lot more proportional to the actual contraband that house gets it so this is exactly",
    "start": "274479",
    "end": "282700"
  },
  {
    "text": "right another way to phrase argument is at the bar for searching blacks or",
    "start": "282700",
    "end": "288100"
  },
  {
    "text": "Hispanics if you if you have this the bar for searching blacks is lower and suggests that the bar is lower for",
    "start": "288100",
    "end": "293169"
  },
  {
    "text": "blacks and for whites okay so that's that's the intuition any other ideas",
    "start": "293169",
    "end": "299580"
  },
  {
    "text": "actually very clever test this was introduced by Becker's Nobel laureate",
    "start": "299700",
    "end": "305080"
  },
  {
    "text": "thank in economics so it's a very very clever test it gets around all ha some of these issues that will meet",
    "start": "305080",
    "end": "310610"
  },
  {
    "text": "variables in the standard the first scenario that I told you where you are just looking at search rates and trying",
    "start": "310610",
    "end": "316009"
  },
  {
    "text": "to control for all variety of features it's very hard in practice to control for everything and this is trying to get",
    "start": "316009",
    "end": "322400"
  },
  {
    "text": "around that problem this statistic so any other ideas so this is it's it's",
    "start": "322400",
    "end": "338870"
  },
  {
    "text": "this benchmark type test so we can look at you know so this is benchmark so here",
    "start": "338870",
    "end": "349879"
  },
  {
    "text": "we're looking at something like the number of searches or stops I'll say",
    "start": "349879",
    "end": "357080"
  },
  {
    "text": "stop since that's what you said / what so this is actually a big",
    "start": "357080",
    "end": "365840"
  },
  {
    "text": "question mark what are we gonna normalize by and so this could be it",
    "start": "365840",
    "end": "372770"
  },
  {
    "text": "could be the census population I'm not",
    "start": "372770",
    "end": "381050"
  },
  {
    "text": "gonna try population what else could be right it could be car owners it could be",
    "start": "381050",
    "end": "390740"
  },
  {
    "text": "you know normalized by time on road yeah",
    "start": "390740",
    "end": "400789"
  },
  {
    "text": "so there are all sorts of things you can normalize I this could be by speeders",
    "start": "400789",
    "end": "405879"
  },
  {
    "text": "right so this is actually the big problem with this type of test this",
    "start": "405879",
    "end": "411199"
  },
  {
    "text": "benchmark test and you could replace this by searches and you'd have the same thing you wouldn't wouldn't be clear what you're dividing by and so that's",
    "start": "411199",
    "end": "417469"
  },
  {
    "text": "the beauty of this test of the hit rate test and so now on you to take another a",
    "start": "417469",
    "end": "423139"
  },
  {
    "text": "few minutes and break this test so what does that mean so find a situation where you don't think there's discrimination",
    "start": "423139",
    "end": "428960"
  },
  {
    "text": "where we would all agree that there's no discrimination but this test suggests that there's discrimination okay so I",
    "start": "428960",
    "end": "436909"
  },
  {
    "text": "guarantee that these situations this are actually two big classes of situations we will break this",
    "start": "436909",
    "end": "443370"
  },
  {
    "text": "but it's so try to find try to find one of these",
    "start": "443370",
    "end": "448530"
  },
  {
    "text": "any ideas yet some ideas okay while we why don't we regroup and see where we're",
    "start": "451260",
    "end": "457170"
  },
  {
    "text": "at so what ideas do you have so this is the hard problem the first one was hard - you solved it at the bar",
    "start": "457170",
    "end": "462270"
  },
  {
    "text": "is I now so I'm expecting install all these problems so what is the what ideas",
    "start": "462270",
    "end": "468680"
  },
  {
    "text": "people have seen possession of magical cards that can cut us a lot like better",
    "start": "468680",
    "end": "475260"
  },
  {
    "text": "without protection than black people in that case number six the number of",
    "start": "475260",
    "end": "480450"
  },
  {
    "text": "successful adult search is going to be a lot smaller for the for the white people and if the ratios would be different",
    "start": "480450",
    "end": "486720"
  },
  {
    "text": "even if they are smuggling drugs at the same rates it's cool so here so so why",
    "start": "486720",
    "end": "495090"
  },
  {
    "text": "do you say there's no discrimination here what is the what is the decision how what is the decision rule that",
    "start": "495090",
    "end": "500850"
  },
  {
    "text": "officers are well the decision woods would be like the officer chooses to to",
    "start": "500850",
    "end": "506160"
  },
  {
    "text": "search the car however the rates of when given that the officer searched the car that they are found in drugs from States",
    "start": "506160",
    "end": "513270"
  },
  {
    "text": "is fine choices that's the first and this numbers difference even though the",
    "start": "513270",
    "end": "518760"
  },
  {
    "text": "actual like pub bility or being searched given that you have drugs it's safe so",
    "start": "518760",
    "end": "525900"
  },
  {
    "text": "this sounds like there's still it's still not clear me why this is discriminatory or non-discriminatory so",
    "start": "525900",
    "end": "531540"
  },
  {
    "text": "we have to say something about the decision rule that the officer is making to determine whether or not it's fair",
    "start": "531540",
    "end": "537060"
  },
  {
    "text": "right so I think there you're right that there could be this is this is getting at the at the heart of the issue but",
    "start": "537060",
    "end": "543060"
  },
  {
    "text": "where maybe just a little bit away from it a small white gang",
    "start": "543060",
    "end": "559040"
  },
  {
    "text": "then you are more likely to search people were black or Latino considering",
    "start": "559040",
    "end": "564930"
  },
  {
    "text": "that you have more of them but you will get more successes with the few that you",
    "start": "564930",
    "end": "571890"
  },
  {
    "text": "searched or successes with the okay so",
    "start": "571890",
    "end": "578640"
  },
  {
    "text": "this is this is interesting so I think we're again this is getting very close to your example but we still have to say",
    "start": "578640",
    "end": "583650"
  },
  {
    "text": "what is it makes a decision fair or not and this isn't an easy question and I'll tell you",
    "start": "583650",
    "end": "588779"
  },
  {
    "text": "a little bit why it's not easy to say what does it mean for a decision to be fair but we have to say something about",
    "start": "588779",
    "end": "593940"
  },
  {
    "text": "the search rule so how are you determining whom to search yeah back in",
    "start": "593940",
    "end": "604860"
  },
  {
    "text": "the search so if they're people of color and they're trying to find the drugs they might find them whereas with white",
    "start": "604860",
    "end": "612000"
  },
  {
    "text": "people if it's like hidden or like not",
    "start": "612000",
    "end": "615800"
  },
  {
    "text": "that it could look like there that there's no discrimination because they're finding drugs at roughly the it",
    "start": "618200",
    "end": "624450"
  },
  {
    "text": "equal rates but in fact the discrimination is happening in that they're spending more time with one group or the other right so that would",
    "start": "624450",
    "end": "631320"
  },
  {
    "text": "be a very subtle way in which this could could fail so let me give you this or another another way just because certain",
    "start": "631320",
    "end": "641370"
  },
  {
    "text": "groups can sex the search others don't if it's a higher bar so you could dramatically lower if the white people",
    "start": "641370",
    "end": "647670"
  },
  {
    "text": "were likely to decline that consent then their rates would appear lower than actually are yeah so this is an",
    "start": "647670",
    "end": "654420"
  },
  {
    "text": "interesting dynamic because this is just saying the searches that occurred and it's saying well maybe there's actually",
    "start": "654420",
    "end": "659700"
  },
  {
    "text": "something wrong with that denominator and you really want to say all the times where the search was requested because",
    "start": "659700",
    "end": "664920"
  },
  {
    "text": "that was a search decision so let me give you two examples where this also",
    "start": "664920",
    "end": "670140"
  },
  {
    "text": "can go wrong so the first is we have this simple case where we have black",
    "start": "670140",
    "end": "680070"
  },
  {
    "text": "drivers there are two types there are types that have a 1% chance of having contraband and a 50% chance of having",
    "start": "680070",
    "end": "688589"
  },
  {
    "text": "contraband so just two types of black drivers in this in this characterize or caricature world now we have white",
    "start": "688589",
    "end": "699870"
  },
  {
    "text": "drivers 1% chance and 75% chance so",
    "start": "699870",
    "end": "708360"
  },
  {
    "text": "again two types of white drivers are either very unlikely to have contrivance or they're very likely to have",
    "start": "708360",
    "end": "714570"
  },
  {
    "text": "contrivance and now give me a fair decision rule that's going to make it look like",
    "start": "714570",
    "end": "719730"
  },
  {
    "text": "there's discrimination a fair search",
    "start": "719730",
    "end": "724770"
  },
  {
    "text": "rule that looks like there's discrimination search could just happen",
    "start": "724770",
    "end": "738270"
  },
  {
    "text": "here it's an percent officer saying I don't care about the race of the drivers",
    "start": "738270",
    "end": "745170"
  },
  {
    "text": "race flying policy I'm gonna search everybody who has at least a 10% chance of having contraband and if they do this",
    "start": "745170",
    "end": "752670"
  },
  {
    "text": "what's gonna happen what is what is the hit rate for black drivers 50% hit rate",
    "start": "752670",
    "end": "758850"
  },
  {
    "text": "for white drivers 75% okay so this actually happens or some variation of",
    "start": "758850",
    "end": "764850"
  },
  {
    "text": "this this happened so let me show you all this is obviously kind of a fake example we don't really believe the",
    "start": "764850",
    "end": "770730"
  },
  {
    "text": "world looks like this but something that's a little bit closer to what the world does seem to look like yes yes so",
    "start": "770730",
    "end": "780930"
  },
  {
    "text": "let me see if I can draw this so so",
    "start": "780930",
    "end": "791310"
  },
  {
    "text": "let's say this is black drivers we're",
    "start": "791310",
    "end": "798660"
  },
  {
    "text": "gonna have like this for white and we're",
    "start": "798660",
    "end": "809700"
  },
  {
    "text": "gonna have this notice and here is the",
    "start": "809700",
    "end": "821280"
  },
  {
    "text": "sort of likelihood likelihood of having",
    "start": "821280",
    "end": "833839"
  },
  {
    "text": "contraband so this is like 10% this is 5%",
    "start": "835790",
    "end": "841480"
  },
  {
    "text": "okay so we have two groups and we had the blue group and in the black group",
    "start": "841480",
    "end": "846670"
  },
  {
    "text": "and here at the threshold for searching this this blue group but we can just",
    "start": "846670",
    "end": "852640"
  },
  {
    "text": "maybe just call these blue and blue and black fur keep things straight forward",
    "start": "852640",
    "end": "858389"
  },
  {
    "text": "okay the blue group in the black group so the blue group is searched at 5%",
    "start": "864660",
    "end": "870570"
  },
  {
    "text": "threshold of having contraband the black group is searched at 10% threshold of",
    "start": "870570",
    "end": "876700"
  },
  {
    "text": "having contraband so we would say that there's discrimination against the blue",
    "start": "876700",
    "end": "882280"
  },
  {
    "text": "group in this example by definition the officers are applying a lower standard of evidence when determining when to",
    "start": "882280",
    "end": "889270"
  },
  {
    "text": "search the blue group okay so we know by construction this example has discrimination but graphically what is",
    "start": "889270",
    "end": "896320"
  },
  {
    "text": "the hit rate what is the hit rate for the black group in the blue group",
    "start": "896320",
    "end": "904050"
  },
  {
    "text": "we need to know the y-axis so this is just the distribution of gift so this is",
    "start": "909530",
    "end": "914820"
  },
  {
    "text": "likelihood of having having comprehend so this is the density over here so we",
    "start": "914820",
    "end": "922650"
  },
  {
    "text": "have some people so it's exactly an extension of this example where now we don't just have the one percent in the",
    "start": "922650",
    "end": "928590"
  },
  {
    "text": "seventy-five percent we just have the full distribution so this is very much",
    "start": "928590",
    "end": "933600"
  },
  {
    "text": "what the world looks like we just have these different distributions of guilt in the population so the area to the",
    "start": "933600",
    "end": "943800"
  },
  {
    "text": "right so what is what is this so what is all of this area to the right that's see",
    "start": "943800",
    "end": "950550"
  },
  {
    "text": "the simplest simple way of saying what that is is this one so what people get",
    "start": "950550",
    "end": "955830"
  },
  {
    "text": "searching so that area is what this is a density so this is just though there's a",
    "start": "955830",
    "end": "964230"
  },
  {
    "text": "proportion of people who are searched that area over here okay so the area to",
    "start": "964230",
    "end": "969570"
  },
  {
    "text": "the right of these lines is a proportion of people being searched and now what it graphically is the hit rate right so",
    "start": "969570",
    "end": "983340"
  },
  {
    "text": "this is the area the area under here as people are searched so how do we graphically think about what the hit",
    "start": "983340",
    "end": "988440"
  },
  {
    "text": "rate is the marginal person the",
    "start": "988440",
    "end": "998850"
  },
  {
    "text": "likelihood of the marginal person being searched how many people are right there so again what is the what is the hit",
    "start": "998850",
    "end": "1005930"
  },
  {
    "text": "rate it's gonna say conditional on being searched it's a likelihood of finding contraband",
    "start": "1005930",
    "end": "1011840"
  },
  {
    "text": "and so this is a slightly complicated but we're just looking at the conditional distribution the conditional",
    "start": "1011840",
    "end": "1017720"
  },
  {
    "text": "mean to the right of the law you're saying well there's certain number of people here and this is the probability",
    "start": "1017720",
    "end": "1023810"
  },
  {
    "text": "of having contraband and now we're just adding up all these little pieces and so",
    "start": "1023810",
    "end": "1028850"
  },
  {
    "text": "it's a conditional mean to the right of the line is our hitter so now",
    "start": "1028850",
    "end": "1034069"
  },
  {
    "text": "graphically what is a conditional mean of the blue it's actually going to be pretty big",
    "start": "1034070",
    "end": "1040579"
  },
  {
    "text": "because there's this big heavy tail and what is the conditional mean of the",
    "start": "1040580",
    "end": "1046280"
  },
  {
    "text": "black group it's gonna be relatively small right so the conditional mean of the black probe might be something like",
    "start": "1046280",
    "end": "1051920"
  },
  {
    "text": "over here which is our our H sub black",
    "start": "1051920",
    "end": "1058070"
  },
  {
    "text": "and here we're gonna have the oil maybe of blue is something like here H sub",
    "start": "1058070",
    "end": "1064900"
  },
  {
    "text": "blue and so here the lower hit rate is",
    "start": "1064900",
    "end": "1070550"
  },
  {
    "text": "actually for black and said relative to blue so you think there is discrimination against this group but",
    "start": "1070550",
    "end": "1076940"
  },
  {
    "text": "the way I actually constructed the example the discrimination is the opposite direction it's a very subtle",
    "start": "1076940",
    "end": "1083810"
  },
  {
    "text": "phenomenon and it's not just a theoretical example you're seeing this happen all over the place and so in fact",
    "start": "1083810",
    "end": "1090920"
  },
  {
    "text": "if you compute the hit rate if you compute the the hit rate for blacks and whites and Hispanics when you find the",
    "start": "1090920",
    "end": "1096800"
  },
  {
    "text": "cross a variety of states is that for Hispanics the hit rate is significantly smaller than it first Vanek's but for",
    "start": "1096800",
    "end": "1102710"
  },
  {
    "text": "blacks the hit rate is about the same as for whites and so then the question is",
    "start": "1102710",
    "end": "1108560"
  },
  {
    "text": "well how do we circumvent this right so we know there's now this fundamental",
    "start": "1108560",
    "end": "1113780"
  },
  {
    "text": "problem with hit rates because of this example so how do you circumvent this",
    "start": "1113780",
    "end": "1119540"
  },
  {
    "text": "problem so this is what's called the problem of information allottee and why is it called the problem information ality because you are only able to",
    "start": "1119540",
    "end": "1125930"
  },
  {
    "text": "observe this this informational decision this average but you're not actually",
    "start": "1125930",
    "end": "1132770"
  },
  {
    "text": "able to observe the marginal decision in the marginal decision is precisely what",
    "start": "1132770",
    "end": "1138140"
  },
  {
    "text": "our concept of discrimination is about right we're looking at what is that least guilty person who is searched how",
    "start": "1138140",
    "end": "1145490"
  },
  {
    "text": "guilty are they but what we actually observe is on average how guilty are the",
    "start": "1145490",
    "end": "1151310"
  },
  {
    "text": "people who are being searched and anytime you have differences in group variances things start breaking down",
    "start": "1151310",
    "end": "1157690"
  },
  {
    "text": "okay so it turns out that you can get it this too and that ends up being",
    "start": "1157690",
    "end": "1164470"
  },
  {
    "text": "unfortunately there's not some simple statistic like the hit rate but you can simultaneously estimate all of these",
    "start": "1164470",
    "end": "1171170"
  },
  {
    "text": "curves and all these thresholds and then you can reconstruct entire picture and when you do that what",
    "start": "1171170",
    "end": "1177150"
  },
  {
    "text": "we're finding is that both blacks and Hispanics across all the states that we look at do seem to have lower thresholds",
    "start": "1177150",
    "end": "1183240"
  },
  {
    "text": "for being searched than whites are",
    "start": "1183240",
    "end": "1188309"
  },
  {
    "text": "situations where to you I argue in some",
    "start": "1188309",
    "end": "1212700"
  },
  {
    "text": "states basically a search is is mandatory after an arrest and so what is",
    "start": "1212700",
    "end": "1219390"
  },
  {
    "text": "the intuition there so you're trying to estimate the the the yeah so what",
    "start": "1219390",
    "end": "1225660"
  },
  {
    "text": "exactly is the quantity that you want to say in those cases keep up this example",
    "start": "1225660",
    "end": "1243960"
  },
  {
    "text": "we'll get back to this in a little bit as well is it has nothing to do with the actual base rate of guilt it's all about",
    "start": "1243960",
    "end": "1251309"
  },
  {
    "text": "the distribution of guilt so even if the base rate of guilt so graphically what is the what is the base rate of guilt in",
    "start": "1251309",
    "end": "1258179"
  },
  {
    "text": "these populations how we write it's just",
    "start": "1258179",
    "end": "1266370"
  },
  {
    "text": "a mean so it's just this that's that's what we're computing and so I this isn't a particularly good example so here the",
    "start": "1266370",
    "end": "1272400"
  },
  {
    "text": "means do appear different but you can construct the exact set example where the means are the same so even though",
    "start": "1272400",
    "end": "1278220"
  },
  {
    "text": "the base rate of guilt is the same in both groups you're going to come up with this problem this is all about the distribution of guilt which is this hard",
    "start": "1278220",
    "end": "1286080"
  },
  {
    "text": "concept to to get a handle on how do you do that even get this distribution is if",
    "start": "1286080",
    "end": "1291570"
  },
  {
    "text": "you're like so technical responsible let",
    "start": "1291570",
    "end": "1303150"
  },
  {
    "text": "me give you a little bit of intuition for what's happening so we would like to estimate this",
    "start": "1303150",
    "end": "1312810"
  },
  {
    "text": "distribution and these and these thresholds so we can think of these distributions is being beta as you know",
    "start": "1312810",
    "end": "1319080"
  },
  {
    "text": "beta distribution and we don't know the parameter so let's just think of this in a parametric framework and so for every",
    "start": "1319080",
    "end": "1325220"
  },
  {
    "text": "so we'll have some beta distribution that's parameterize by its mean with",
    "start": "1325220",
    "end": "1333420"
  },
  {
    "text": "race for every race and every department let's say and then we have some",
    "start": "1333420",
    "end": "1338460"
  },
  {
    "text": "precision parameter are indeed so we",
    "start": "1338460",
    "end": "1343620"
  },
  {
    "text": "have some nice beta distribution we're trying to infer these parameters for every race group in every department and",
    "start": "1343620",
    "end": "1349020"
  },
  {
    "text": "at state let's say every Police Department and we also want to infer these thresholds for every race group in",
    "start": "1349020",
    "end": "1355980"
  },
  {
    "text": "every department so every location and every race so this is what we want to do so how many parameters do we have here",
    "start": "1355980",
    "end": "1361580"
  },
  {
    "text": "so we have the number of parameters here we have for every race times every",
    "start": "1361580",
    "end": "1368910"
  },
  {
    "text": "department times two parameters up here and then we're gonna have race times",
    "start": "1368910",
    "end": "1374910"
  },
  {
    "text": "department here so we have three times our three rd parameters that we would",
    "start": "1374910",
    "end": "1382530"
  },
  {
    "text": "need to infer and now how many observations do we have what do we actually observe about this process so",
    "start": "1382530",
    "end": "1393030"
  },
  {
    "text": "you you observe whether or not someone was searched and whether or not contraband was found and we observed",
    "start": "1393030",
    "end": "1402540"
  },
  {
    "text": "this for every race group in every department so we'd observe the search rate and the",
    "start": "1402540",
    "end": "1407730"
  },
  {
    "text": "hit rate for every race and every department and so we only observe two Rd",
    "start": "1407730",
    "end": "1416210"
  },
  {
    "text": "data points so this is not a good",
    "start": "1416210",
    "end": "1421560"
  },
  {
    "text": "situation we're trying to infer you know it's it's not a rigorous proof here but you can even work it should seem",
    "start": "1421560",
    "end": "1428160"
  },
  {
    "text": "intuitive that we're only observing this we have a lot of parameters and so even in this nice parametric form we can't",
    "start": "1428160",
    "end": "1434130"
  },
  {
    "text": "observe we can't figure out exactly what's going on here and so the solution is that we're going to",
    "start": "1434130",
    "end": "1439570"
  },
  {
    "text": "put on some constraint so we're going to say for example that these means for the",
    "start": "1439570",
    "end": "1445539"
  },
  {
    "text": "distributions they vary linearly across departments conditional on Ray something like that so we have to put some",
    "start": "1445539",
    "end": "1452289"
  },
  {
    "text": "constraints on how these distributions can move and then once we have that then we can figure out what exactly these are",
    "start": "1452289",
    "end": "1459070"
  },
  {
    "text": "based on our observed search rate and observed hit rate and so we think of",
    "start": "1459070",
    "end": "1464289"
  },
  {
    "text": "this as a hybrid between the benchmark tests that we started with and the hit rate the outcome tests that we though we",
    "start": "1464289",
    "end": "1469570"
  },
  {
    "text": "ended up with so it's a hybrid of these these two concepts okay so now so this",
    "start": "1469570",
    "end": "1476799"
  },
  {
    "text": "is just to give you a little bit of interest also the other any ideas on what the second problem is it's like a major problem with this this test so",
    "start": "1476799",
    "end": "1487840"
  },
  {
    "text": "here why not even partitioning by location so this is actually a standard",
    "start": "1487840",
    "end": "1493109"
  },
  {
    "text": "Simpsons paradox style problem that that you see in New York City so in New York",
    "start": "1493109",
    "end": "1499929"
  },
  {
    "text": "City what's happening is let's see if I can draw New York City so something like",
    "start": "1499929",
    "end": "1508080"
  },
  {
    "text": "I don't know something like this I don't",
    "start": "1508200",
    "end": "1515919"
  },
  {
    "text": "know what that is but I should be able to do this a little bit better the so",
    "start": "1515919",
    "end": "1524859"
  },
  {
    "text": "what's so cure what's happening in New York is the hit rate for blacks is substantially lower than hit rate for",
    "start": "1524859",
    "end": "1530710"
  },
  {
    "text": "whites for this is in the stop-and-frisk context so pedestrian stops which you can think of is the same thing it's just",
    "start": "1530710",
    "end": "1535749"
  },
  {
    "text": "a pedestrian version of vehicle stops and what's happening here is that the",
    "start": "1535749",
    "end": "1541419"
  },
  {
    "text": "high crime neighborhoods in in New York City looks something like up here and",
    "start": "1541419",
    "end": "1547619"
  },
  {
    "text": "and over here and over here something like that these are the high crime",
    "start": "1547619",
    "end": "1552940"
  },
  {
    "text": "neighborhoods and what turns out to happen is that they're very low thresholds for stopping people in these",
    "start": "1552940",
    "end": "1559539"
  },
  {
    "text": "high crime neighborhoods it's the same time these neighborhoods because New York City is extremely segregated as",
    "start": "1559539",
    "end": "1565749"
  },
  {
    "text": "most American cities is that these are also predominantly black and Hispanic neighborhoods so if I were to tell you",
    "start": "1565749",
    "end": "1571869"
  },
  {
    "text": "the overall hit rate across the city that actually does an account for this geographic variation",
    "start": "1571869",
    "end": "1576950"
  },
  {
    "text": "and so that in theory it turns out so if you do some so after you correct for",
    "start": "1576950",
    "end": "1582799"
  },
  {
    "text": "location the disparities seem to go to reduce significantly so there is",
    "start": "1582799",
    "end": "1588200"
  },
  {
    "text": "evidence for discrimination but the overall statistic of the hit rate for blacks and Hispanics being you know 1/2",
    "start": "1588200",
    "end": "1595549"
  },
  {
    "text": "or 1/3 the hit rate for whites is actually a little bit misleading because by location that the changes in",
    "start": "1595549",
    "end": "1602360"
  },
  {
    "text": "threshold are relatively small ok so this is some some version of Simpsons",
    "start": "1602360",
    "end": "1608360"
  },
  {
    "text": "paradox over here and this is I would say it's a it's a slightly different type of problem that's happening ok",
    "start": "1608360",
    "end": "1615919"
  },
  {
    "start": "1615000",
    "end": "2193000"
  },
  {
    "text": "so let's switch gears now and talk about algorithmic fairness so here we're trying to assess the fairness of a",
    "start": "1615919",
    "end": "1622039"
  },
  {
    "text": "decision made by a human and what we think of as fairness in that context is very different than what we think of a",
    "start": "1622039",
    "end": "1628340"
  },
  {
    "text": "fairness in an algorithmic context in a human decision-making context we're really thinking about bias in the you",
    "start": "1628340",
    "end": "1634850"
  },
  {
    "text": "know is there racial animus or implicit bias something like that and those concepts don't easily translate into an",
    "start": "1634850",
    "end": "1640340"
  },
  {
    "text": "algorithmic setting so let me give you an example of of an algorithm just give you a little bit of intuition so this is",
    "start": "1640340",
    "end": "1646549"
  },
  {
    "text": "the compas algorithm which is developed by North Point this private company and is used in jurisdictions and courts",
    "start": "1646549",
    "end": "1652580"
  },
  {
    "text": "across the country to determine who should be released pretrial on bail or",
    "start": "1652580",
    "end": "1657620"
  },
  {
    "text": "on their own recognizance and so to give you a little bit of background so if someone is arrested usually within 24",
    "start": "1657620",
    "end": "1663230"
  },
  {
    "text": "hours they're arraigned at which point the charge is read against them and a judge has to decide relatively quickly",
    "start": "1663230",
    "end": "1668659"
  },
  {
    "text": "should they be released on their own recognizance generally if they don't pose a threat to public safety or they're not a flight risk or should bail",
    "start": "1668659",
    "end": "1675650"
  },
  {
    "text": "be set for them and if bail is set for them they often even if it's relatively small amount they often have to go to",
    "start": "1675650",
    "end": "1681679"
  },
  {
    "text": "jail because they can't provide the funds to pay for bail and they can't contract with a bail bondsman ok so it's",
    "start": "1681679",
    "end": "1687590"
  },
  {
    "text": "this high impact decision and this is all before any assessment of guilt has been made this is all pretrial but you",
    "start": "1687590",
    "end": "1694520"
  },
  {
    "text": "can see that there's this clear public value to having this because we don't",
    "start": "1694520",
    "end": "1700100"
  },
  {
    "text": "want people who are tor potentially dangerous to be loose once they've been arrested ok and then there's also a",
    "start": "1700100",
    "end": "1707049"
  },
  {
    "text": "desire to make sure people show up to their court proceedings at the same time there's this huge social cost so a few",
    "start": "1707049",
    "end": "1714950"
  },
  {
    "text": "months ago over the summer ProPublica analyzed the the pretrial decisions the algorithmic pretrial",
    "start": "1714950",
    "end": "1721099"
  },
  {
    "text": "decisions in Broward County Florida one particular County this is just happening all over the place and the journalist",
    "start": "1721099",
    "end": "1727039"
  },
  {
    "text": "noted this one fact so of people so all of lack and white defendants you look at",
    "start": "1727039",
    "end": "1733220"
  },
  {
    "text": "black defendants who ultimately did not recidivate they did not reoffending this",
    "start": "1733220",
    "end": "1738619"
  },
  {
    "text": "is a standard measure of Public Safety within two years of their being arrested so they did not really the fact it looks",
    "start": "1738619",
    "end": "1745849"
  },
  {
    "text": "like they were not an actual threat to public safety about twice as many were",
    "start": "1745849",
    "end": "1751840"
  },
  {
    "text": "subjected to the high risk group where where bail would be set and all these",
    "start": "1751840",
    "end": "1757759"
  },
  {
    "text": "other consequences would happen relative to whites so of people of black",
    "start": "1757759",
    "end": "1762859"
  },
  {
    "text": "defendants who did not recidivate about 40% were tagged high risk versus white",
    "start": "1762859",
    "end": "1770029"
  },
  {
    "text": "defendants who did not reoffended about 20% of white defendants who not reoffended were flagged as high risk",
    "start": "1770029",
    "end": "1776739"
  },
  {
    "text": "okay this is the judge making this decision this is the so the algorithm is",
    "start": "1776739",
    "end": "1784129"
  },
  {
    "text": "literally saying is this person high-risk or not what is the likelihood of this person so based on also exactly",
    "start": "1784129",
    "end": "1792409"
  },
  {
    "text": "is it's not entire this is a black box algorithm which has its own issues but we don't know what is going into it or",
    "start": "1792409",
    "end": "1799399"
  },
  {
    "text": "we move rough set so race is not included in the algorithm and it's not included but we do have things like the",
    "start": "1799399",
    "end": "1805340"
  },
  {
    "text": "criminal history of the person in the number of arrests all of these other factors and the algorithm among other",
    "start": "1805340",
    "end": "1811580"
  },
  {
    "text": "things is trying to estimate the likelihood that this person will recidivate will reoffending two years so",
    "start": "1811580",
    "end": "1817970"
  },
  {
    "text": "there are science scores every defendant is assigned a score from one to ten ten being the most likely to recidivate one",
    "start": "1817970",
    "end": "1823970"
  },
  {
    "text": "being the least likely and then there's some cutoff for high a medium and high",
    "start": "1823970",
    "end": "1829039"
  },
  {
    "text": "risk versus low risk and that's used to make these pretrial decisions of bail being set or individual to be released",
    "start": "1829039",
    "end": "1835849"
  },
  {
    "text": "and so this fact was pointed out by by Pro Publica that black defendants who did not reoffended",
    "start": "1835849",
    "end": "1842400"
  },
  {
    "text": "40% were flagged as high-risk of white defendants who did not reoffended out",
    "start": "1842400",
    "end": "1847530"
  },
  {
    "text": "20% we're flagged as high-risk and now the question and I want you to discuss this in your groups is is this evidence",
    "start": "1847530",
    "end": "1853980"
  },
  {
    "text": "of bias or something else going on okay let's uh let's regroup so what do",
    "start": "1853980",
    "end": "1864910"
  },
  {
    "text": "you think is this the right measure of fairness of what it means for an",
    "start": "1864910",
    "end": "1870160"
  },
  {
    "text": "algorithm to be fair or biased so this was a big deal the Wisconsin Supreme",
    "start": "1870160",
    "end": "1875500"
  },
  {
    "text": "Court actually cited this in their recent opinion on this they were like look at this disparity so there's something funny happening so what do you",
    "start": "1875500",
    "end": "1882300"
  },
  {
    "text": "what do you think is this the right measure are you very unhappy with the",
    "start": "1882300",
    "end": "1888520"
  },
  {
    "text": "offer though if you think there might be something else",
    "start": "1888520",
    "end": "1892470"
  },
  {
    "text": "one is the income if the income is counted in because probably people come",
    "start": "1900640",
    "end": "1906820"
  },
  {
    "text": "to it let's say most white people in that in a given area art for so every",
    "start": "1906820",
    "end": "1914980"
  },
  {
    "text": "time you didn't mention their life just you mentioned they're making so little money this is already one kind of place",
    "start": "1914980",
    "end": "1920170"
  },
  {
    "text": "and the other thing is a number of us if we go back to your first example and say people were stop and say it reason is",
    "start": "1920170",
    "end": "1926920"
  },
  {
    "text": "same as when you say people who are arrested or more flat so the number of hours that person has is higher so does",
    "start": "1926920",
    "end": "1932920"
  },
  {
    "text": "it can equal to 10 minutes black okay so this is interesting let's get back to this here we have",
    "start": "1932920",
    "end": "1946590"
  },
  {
    "text": "measures of algorithmic fairness and so",
    "start": "1946860",
    "end": "1958360"
  },
  {
    "text": "here you're saying something like even though we're not using race in the algorithm we're using features that are",
    "start": "1958360",
    "end": "1964150"
  },
  {
    "text": "correlated with race okay so I using so",
    "start": "1964150",
    "end": "1971610"
  },
  {
    "text": "L ago uses info correlated with race so",
    "start": "1971610",
    "end": "1983380"
  },
  {
    "text": "we in a year maybe I'll put zero in here I'll go",
    "start": "1983380",
    "end": "1988650"
  },
  {
    "text": "uses race so we would call that if the algorithm uses race it sounds like many",
    "start": "1988670",
    "end": "1996230"
  },
  {
    "text": "people would say that the algorithm is biased and even if it doesn't use race if it uses information that's correlated",
    "start": "1996230",
    "end": "2001929"
  },
  {
    "text": "with race it sounds like people would call it biased and so how are we any",
    "start": "2001929",
    "end": "2008920"
  },
  {
    "text": "other so this is a slightly tangent but let's I think this is a useful exercise so any other measures of algorithmic",
    "start": "2008920",
    "end": "2014380"
  },
  {
    "text": "discrimination so you're saying that measure that ProPublica po is so this was two of unequal false positive false",
    "start": "2014380",
    "end": "2028799"
  },
  {
    "text": "positive rate so that's this measure that I just talked about that the false positive rate of the people who are not",
    "start": "2028799",
    "end": "2035400"
  },
  {
    "text": "who did ultimately did not recidivate they were flagged as high-risk so this is a false positive rate we're saying an",
    "start": "2035400",
    "end": "2041830"
  },
  {
    "text": "unequal measure so that's one measure of algorithmic fairness at that ProPublica",
    "start": "2041830",
    "end": "2048210"
  },
  {
    "text": "measure and other things subjective data",
    "start": "2053700",
    "end": "2061658"
  },
  {
    "text": "to do you want so the inputs the",
    "start": "2061659",
    "end": "2070570"
  },
  {
    "text": "algorithm is if so there's bias decision-making so when i when i say something like this feature is maybe",
    "start": "2070570",
    "end": "2077500"
  },
  {
    "text": "arrests is a bad example so does this person look like a criminal and and this",
    "start": "2077500",
    "end": "2082990"
  },
  {
    "text": "is a biased decision so we could have so biased biased inputs something like that",
    "start": "2082990",
    "end": "2092050"
  },
  {
    "text": "so I should tell you that in fact this algorithm is still being used it's being",
    "start": "2092050",
    "end": "2097450"
  },
  {
    "text": "used all over the country so somehow this was not persuasive to the courts this we know is is its true race to not",
    "start": "2097450",
    "end": "2105940"
  },
  {
    "text": "being used this well what information is not correlated with race pretty much",
    "start": "2105940",
    "end": "2112330"
  },
  {
    "text": "nothing right there's always going to be some degree of correlation with whatever we use as long as this you know if it's",
    "start": "2112330",
    "end": "2118450"
  },
  {
    "text": "socio-economic data it's always gonna be a correlation so this in practice we can't actually do anything about okay and so what is",
    "start": "2118450",
    "end": "2126550"
  },
  {
    "text": "what's her way out why why did the courts not think that this was biased",
    "start": "2126550",
    "end": "2132660"
  },
  {
    "text": "Danny will PR seems to have the same weakness as the base rate solution that",
    "start": "2132660",
    "end": "2138220"
  },
  {
    "text": "we came up with because you can't see the distribution exactly so so what is so what's happening here so what is",
    "start": "2138220",
    "end": "2144700"
  },
  {
    "text": "another measure of algorithmic fairness that you think is the key pick there's",
    "start": "2144700",
    "end": "2152980"
  },
  {
    "text": "something funny happening even if we",
    "start": "2152980",
    "end": "2163000"
  },
  {
    "text": "think the algorithm is biased we can say is this biased algorithm better than what our biased human decision-maker was",
    "start": "2163000",
    "end": "2169450"
  },
  {
    "text": "doing and it turns out that in many cases that's true so even if we just forget about there's more like well this",
    "start": "2169450",
    "end": "2174790"
  },
  {
    "text": "is an improvement let's not look at this any further you know that's in some ways that is where we're at we have empirical",
    "start": "2174790",
    "end": "2180430"
  },
  {
    "text": "evidence to suggest that these algorithms are doing better than humans but now there's this shift well should",
    "start": "2180430",
    "end": "2185860"
  },
  {
    "text": "we be satisfied with this better solution or should we go one step further actually the right definition of",
    "start": "2185860",
    "end": "2204900"
  },
  {
    "start": "2193000",
    "end": "2458000"
  },
  {
    "text": "fairness and given the fact that we've already excluded this now all of a",
    "start": "2204900",
    "end": "2211360"
  },
  {
    "text": "sudden why does race be seems so important when we're happy to have things which are highly correlated with",
    "start": "2211360",
    "end": "2216850"
  },
  {
    "text": "race so there's some kind of internal conflict between these two points and",
    "start": "2216850",
    "end": "2222970"
  },
  {
    "text": "I'll argue in a minute why we actually should use race in the algorithm this algorithm does not but all arguing about",
    "start": "2222970",
    "end": "2228400"
  },
  {
    "text": "why we should but what is what is our way out why this algorithm being used what is another measure of fairness by",
    "start": "2228400",
    "end": "2235810"
  },
  {
    "text": "which this algorithm seems to survive but we still have this funny disparity",
    "start": "2235810",
    "end": "2241780"
  },
  {
    "text": "happening if you say the the total of false positive rates comes out it might",
    "start": "2241780",
    "end": "2248080"
  },
  {
    "text": "actually be optimized for example it's like the white people are much easier to classify than the black people right",
    "start": "2248080",
    "end": "2253930"
  },
  {
    "text": "like 100% crackers fun on like when they're not there with universe if it is somewhere asked for the bottom goes much",
    "start": "2253930",
    "end": "2261099"
  },
  {
    "text": "harder to separate them that would result in a much higher and false positive rating like the black people even though that minimizes at all",
    "start": "2261099",
    "end": "2269319"
  },
  {
    "text": "exactly right so this is the same problem that we just talked about over here so now to be super concrete what is the",
    "start": "2269319",
    "end": "2275800"
  },
  {
    "text": "measure so this is a theoretical possibility so what you're offering is a theoretical argument for why you might",
    "start": "2275800",
    "end": "2281650"
  },
  {
    "text": "have an algorithm that we think is fair but is but has unequal false positive",
    "start": "2281650",
    "end": "2287829"
  },
  {
    "text": "rates so what is the concrete measure and this is what the rebuttal was so",
    "start": "2287829",
    "end": "2293380"
  },
  {
    "text": "Northpoint the company that that designed this algorithm and present it to the courts and said well here is our",
    "start": "2293380",
    "end": "2299230"
  },
  {
    "text": "measure here is our evidence that the algorithm is not biased so what is another measure of fairness that you",
    "start": "2299230",
    "end": "2306309"
  },
  {
    "text": "would want to check that that you think takes precedence over over the ones that",
    "start": "2306309",
    "end": "2311530"
  },
  {
    "text": "we discussed the total false positive",
    "start": "2311530",
    "end": "2316630"
  },
  {
    "text": "rate not by not by race so what would you what would you call so at what point",
    "start": "2316630",
    "end": "2322690"
  },
  {
    "text": "would you say that it's biased well well",
    "start": "2322690",
    "end": "2330088"
  },
  {
    "text": "it's actually important something about the quality so I think many people would",
    "start": "2332490",
    "end": "2338410"
  },
  {
    "text": "agree if it's perfect if we literally can say 100 percent of the time this person will recidivate this person",
    "start": "2338410",
    "end": "2343990"
  },
  {
    "text": "will not then we might be fine calling that an unbiased algorithm and the further we get away from that then the",
    "start": "2343990",
    "end": "2351460"
  },
  {
    "text": "more were suspicious about the algorithm so there is something about the quality and sometimes this comes under the name",
    "start": "2351460",
    "end": "2357720"
  },
  {
    "text": "predictive fairness even to be a little",
    "start": "2357720",
    "end": "2363130"
  },
  {
    "text": "bit more specific I'll say you know unequal unequal accuracy by group you",
    "start": "2363130",
    "end": "2371020"
  },
  {
    "text": "see we can look at true positive rate we can look at any other measure of",
    "start": "2371020",
    "end": "2377880"
  },
  {
    "text": "algorithmic performance set that we want a new I'd say well if it's actually a lot more accurate on one race group than",
    "start": "2377880",
    "end": "2384640"
  },
  {
    "text": "another we're gonna start thinking there's something funny happening hey that's one argument but it turns out",
    "start": "2384640",
    "end": "2391660"
  },
  {
    "text": "that this algorithm performs very differently for all these race groups so",
    "start": "2391660",
    "end": "2397540"
  },
  {
    "text": "what is what are we missing or is another measure of fairness here what",
    "start": "2397540",
    "end": "2410680"
  },
  {
    "text": "does it mean to be fair with for one group so it does so it does have fewer",
    "start": "2410680",
    "end": "2418930"
  },
  {
    "text": "false positives about half as many false positives for whites and for blacks so this was the gist of ProPublica",
    "start": "2418930",
    "end": "2424900"
  },
  {
    "text": "complaint include the people who weren't",
    "start": "2424900",
    "end": "2431080"
  },
  {
    "text": "actually subject to help you just conclude then in that that was like the baseline of just like oh like a random",
    "start": "2431080",
    "end": "2438580"
  },
  {
    "text": "like person who is like not even guilty at all so you're looking at accuracy on",
    "start": "2438580",
    "end": "2448930"
  },
  {
    "text": "some other set of individuals so I think this is definitely getting at this",
    "start": "2448930",
    "end": "2454990"
  },
  {
    "text": "distribution so this distribution is fundamentally what matters so let me give you one more definition of",
    "start": "2454990",
    "end": "2461680"
  },
  {
    "start": "2458000",
    "end": "2673000"
  },
  {
    "text": "algorithmic fairness so calibration you",
    "start": "2461680",
    "end": "2468700"
  },
  {
    "text": "know again I'll argue why this actually isn't the right definition but it it holds in this case so let's take this",
    "start": "2468700",
    "end": "2475150"
  },
  {
    "text": "plot so here are scores so one two three ten so this is risk score and now here's",
    "start": "2475150",
    "end": "2485830"
  },
  {
    "text": "the probability recidivism okay so what",
    "start": "2485830",
    "end": "2494650"
  },
  {
    "text": "do we think should happen here what whether these lines gonna look like for whites and blacks",
    "start": "2494650",
    "end": "2501210"
  },
  {
    "text": "so this is the line or this is the line for white I'll say this is the line for",
    "start": "2502809",
    "end": "2508869"
  },
  {
    "text": "blacks what do we what do we want the lineup for whites to look like like this would",
    "start": "2508869",
    "end": "2519759"
  },
  {
    "text": "we be happy with that so let's say it actually look like this would we call",
    "start": "2519759",
    "end": "2526539"
  },
  {
    "text": "this algorithm fair not fair right because why is that well three would",
    "start": "2526539",
    "end": "2534099"
  },
  {
    "text": "mean very different things for whites and blacks so what do we actually want this to look like we want it to look",
    "start": "2534099",
    "end": "2540459"
  },
  {
    "text": "like that okay so that's what this is",
    "start": "2540459",
    "end": "2548319"
  },
  {
    "text": "this idea of calibration we're saying when I when the judge sees a three it",
    "start": "2548319",
    "end": "2553419"
  },
  {
    "text": "doesn't matter as judges I'll have to say is this a three for a black defendant or a three for a white defendant this is a three in a three",
    "start": "2553419",
    "end": "2560739"
  },
  {
    "text": "means that there is a 20% chance of recidivating so the algorithm in fact",
    "start": "2560739",
    "end": "2568779"
  },
  {
    "text": "satisfies this definition of fairness yeah and this is the the evidence that",
    "start": "2568779",
    "end": "2575739"
  },
  {
    "text": "Northpoint put forward and says look it's fair satisfies this and well how do",
    "start": "2575739",
    "end": "2580959"
  },
  {
    "text": "you get this well you get this exactly by the same argument that that I showed over here that if you have these",
    "start": "2580959",
    "end": "2586630"
  },
  {
    "text": "different distributions of the population even if you have something that looks like this you can have all",
    "start": "2586630",
    "end": "2591999"
  },
  {
    "text": "sorts of funny false positive rates so now the question is tell me why this",
    "start": "2591999",
    "end": "2598659"
  },
  {
    "text": "isn't the right definition of fair so give me an example of an algorithm that you don't think is fair but is",
    "start": "2598659",
    "end": "2605739"
  },
  {
    "text": "calibrated okay so now why none of these at least",
    "start": "2605739",
    "end": "2611730"
  },
  {
    "text": "delighted to talk so much about it well gave some intuition for why zero is wrong we already know these aren't the",
    "start": "2611730",
    "end": "2617160"
  },
  {
    "text": "right measure because this is already going to be determined like if we have a calibrated algorithm we can very",
    "start": "2617160",
    "end": "2624180"
  },
  {
    "text": "reasonably think of examples where these are all going to be violated because of the distribution in the population so",
    "start": "2624180",
    "end": "2631829"
  },
  {
    "text": "now tell me why this isn't the right definition of your populations no way",
    "start": "2631829",
    "end": "2637260"
  },
  {
    "text": "that like these two Simpsons paradox situations like all blacks are at either one or ten and why it's removing the",
    "start": "2637260",
    "end": "2643829"
  },
  {
    "text": "distributive so that might be the way the world looks so tell me and it give me an example where the algorithm where",
    "start": "2643829",
    "end": "2649920"
  },
  {
    "text": "you actually are pretty clear you know looking into it looking at the decision-maker you know come up with an",
    "start": "2649920",
    "end": "2655109"
  },
  {
    "text": "algorithm that we would all agree is biased but it's calibrated mage been won",
    "start": "2655109",
    "end": "2660300"
  },
  {
    "text": "in it in groups talking about this an algorithm that is calibrated but we would agree is biased yeah this is",
    "start": "2660300",
    "end": "2681440"
  },
  {
    "start": "2673000",
    "end": "2813000"
  },
  {
    "text": "the horizontal probability value",
    "start": "2740549",
    "end": "2750309"
  },
  {
    "text": "I got your scoob's are you can tell okay",
    "start": "2750309",
    "end": "2788229"
  },
  {
    "text": "let's let's regroup we just have a couple minutes left so an example example of an algorithm that is",
    "start": "2788229",
    "end": "2795369"
  },
  {
    "text": "calibrated but you would think is biased that you are happy falling biased",
    "start": "2795369",
    "end": "2802409"
  },
  {
    "text": "example so this is this actually happened redlining it's an example so what is redlining or",
    "start": "2802589",
    "end": "2808569"
  },
  {
    "text": "this term so in in in when base give loans that historically that there is",
    "start": "2808569",
    "end": "2815589"
  },
  {
    "text": "this that this policy that they would partition neighborhoods and not give",
    "start": "2815589",
    "end": "2821169"
  },
  {
    "text": "loans to certain neighborhoods but those neighborhoods tended to be predominantly",
    "start": "2821169",
    "end": "2826329"
  },
  {
    "text": "minority neighborhoods and but what is the rationale that the bank could give to cover up the fact that this is",
    "start": "2826329",
    "end": "2832569"
  },
  {
    "text": "discrimination right and so this is",
    "start": "2832569",
    "end": "2841239"
  },
  {
    "text": "precisely the example that we have we have some area we have we have some",
    "start": "2841239",
    "end": "2848849"
  },
  {
    "text": "division we're just going to divide the world into two pieces and this is going to be and we have one is predominantly",
    "start": "2848849",
    "end": "2856899"
  },
  {
    "text": "black the other is predominantly white and we're going to say well the default",
    "start": "2856899",
    "end": "2862959"
  },
  {
    "text": "rate and this area might be something like 2%",
    "start": "2862959",
    "end": "2869650"
  },
  {
    "text": "and default rate in this neighborhood might be 1% and so now the bank is",
    "start": "2869650",
    "end": "2878710"
  },
  {
    "text": "saying well look this is this is calibrated and my feature and my model is saying well when it's when it this",
    "start": "2878710",
    "end": "2884980"
  },
  {
    "text": "neighborhood uses exactly one feature one predictive feature this neighborhood that when it says it's 1% it is 1% when",
    "start": "2884980",
    "end": "2892900"
  },
  {
    "text": "it says it's 2% it is 2% it's gonna satisfy this but why is this biased why",
    "start": "2892900",
    "end": "2900579"
  },
  {
    "text": "would we call this biased is it making any effort to determine who is actually",
    "start": "2900579",
    "end": "2908670"
  },
  {
    "text": "creditworthy in each of these neighborhoods so this is a historical example of redlining that we that we see",
    "start": "2908670",
    "end": "2915369"
  },
  {
    "text": "and it's precisely an example of a calibrated algorithm a calibrated decision rule that we would think of as",
    "start": "2915369",
    "end": "2922839"
  },
  {
    "text": "being discriminatory so what is the answer here is well you use more information the banks in this case we're",
    "start": "2922839",
    "end": "2929740"
  },
  {
    "text": "intentionally ignoring information that would let them distinguish between the creditworthy whites and the creditworthy",
    "start": "2929740",
    "end": "2936039"
  },
  {
    "text": "blacks in a more nuanced way than simply saying this is one neighborhood and this is another neighborhood okay so",
    "start": "2936039",
    "end": "2942369"
  },
  {
    "text": "calibration is interested so we are not happy with any of these notions of fairness and so the last question is",
    "start": "2942369",
    "end": "2950319"
  },
  {
    "text": "what is the notion of fairness that we actually actually want and so here I'll argue that really the the notion of",
    "start": "2950319",
    "end": "2958329"
  },
  {
    "text": "fairness is is this very simple idea of",
    "start": "2958329",
    "end": "2964619"
  },
  {
    "text": "equal treatment so what does this mean",
    "start": "2964619",
    "end": "2970210"
  },
  {
    "text": "it means that based on all available information we'll take everything we have available to us including race",
    "start": "2970210",
    "end": "2976950"
  },
  {
    "start": "2973000",
    "end": "3083000"
  },
  {
    "text": "we're gonna say this is the likelihood based on everything we've seen that this",
    "start": "2976950",
    "end": "2981999"
  },
  {
    "text": "person will recidivate that this person will default anything like this we're",
    "start": "2981999",
    "end": "2987489"
  },
  {
    "text": "just gonna rank people and we're gonna make it threshold okay so it's a",
    "start": "2987489",
    "end": "2994440"
  },
  {
    "text": "threshold on fun",
    "start": "2995369",
    "end": "3000390"
  },
  {
    "text": "best available info okay so we take",
    "start": "3000390",
    "end": "3010559"
  },
  {
    "text": "everything that we have we hit rank people by that information we're gonna",
    "start": "3010559",
    "end": "3016200"
  },
  {
    "text": "threshold on that this is the equal treatment idea and what you can see pretty immediately is that any deviation",
    "start": "3016200",
    "end": "3023069"
  },
  {
    "text": "from this rule is going to necessarily or any attempt to tweak any of these",
    "start": "3023069",
    "end": "3028950"
  },
  {
    "text": "measures over here and say well we want to have we want to equalize false positives we want it we want to take",
    "start": "3028950",
    "end": "3034499"
  },
  {
    "text": "race out of our algorithm is necessarily going to violate this principle so if we",
    "start": "3034499",
    "end": "3039839"
  },
  {
    "text": "don't include some of the information that we have that means well we can't actually ignore it it just means we're",
    "start": "3039839",
    "end": "3045900"
  },
  {
    "text": "you know we can pretend like we don't have the information but it's there and so it means that based on actually the",
    "start": "3045900",
    "end": "3051599"
  },
  {
    "text": "available information we're ranking people not in some order that is",
    "start": "3051599",
    "end": "3056849"
  },
  {
    "text": "justified by that by these probabilities so if we exclude race if we exclude any",
    "start": "3056849",
    "end": "3062489"
  },
  {
    "text": "other sensitive information that means we're willing to accept the fact that we might not rank people consistently okay",
    "start": "3062489",
    "end": "3071369"
  },
  {
    "text": "so it's this funny idea that that it's actually good to include race in your",
    "start": "3071369",
    "end": "3076650"
  },
  {
    "text": "algorithm because that's information that you have and so what is an example a concrete example of why you might want",
    "start": "3076650",
    "end": "3081960"
  },
  {
    "text": "to include race like again example I",
    "start": "3081960",
    "end": "3088950"
  },
  {
    "start": "3083000",
    "end": "3203000"
  },
  {
    "text": "think blacks maybe eat like harder or easier to classify than another group in",
    "start": "3088950",
    "end": "3094349"
  },
  {
    "text": "their work you might even might require that's to",
    "start": "3094349",
    "end": "3100309"
  },
  {
    "text": "seem like a charming to actual probability so a phrase another way",
    "start": "3100309",
    "end": "3105569"
  },
  {
    "text": "let's say that there's just heavier policing in black neighborhoods and so they're more arrests of blacks and for",
    "start": "3105569",
    "end": "3111329"
  },
  {
    "text": "whites into an arrest actually tells us less information arrests of a black",
    "start": "3111329",
    "end": "3116940"
  },
  {
    "text": "individual tells us less information than arrest of a white individual in terms of their public safety the public",
    "start": "3116940",
    "end": "3122309"
  },
  {
    "text": "threat that they that they pose and so not correcting for it actually gives us a funny story right because we have",
    "start": "3122309",
    "end": "3130019"
  },
  {
    "text": "these inputs that are that are correlate with outcome that we care about and that may",
    "start": "3130019",
    "end": "3135900"
  },
  {
    "text": "very reasonably differ according to race not including race potentially could buy",
    "start": "3135900",
    "end": "3141000"
  },
  {
    "text": "us the algorithm prices for for the flat",
    "start": "3141000",
    "end": "3147390"
  },
  {
    "text": "we now do buy their support right I'm just using very simple terms this is what you're saying yes even so here any",
    "start": "3147390",
    "end": "3155430"
  },
  {
    "text": "attempt to change false positive rates any attempt to remove information anything like this is going to end up",
    "start": "3155430",
    "end": "3161820"
  },
  {
    "text": "violating this principle of equal treatment it's a way to find this result",
    "start": "3161820",
    "end": "3170880"
  },
  {
    "text": "is an independent decision so where you're gonna set the threshold might depend on your policy but when I talk",
    "start": "3170880",
    "end": "3176730"
  },
  {
    "text": "about ranking individuals on who is the most risky who is the least risky any attempt to hide information from the",
    "start": "3176730",
    "end": "3184110"
  },
  {
    "text": "algorithm any attempt to change the algorithm so it's not predicting the outcome that you care about but it's",
    "start": "3184110",
    "end": "3189960"
  },
  {
    "text": "trying to equalize false positive rates anything like this or any attempt to improve the quality for one group over",
    "start": "3189960",
    "end": "3196500"
  },
  {
    "text": "the other even to bring them into alignment is going to violate this equal treatment principle maybe this is really",
    "start": "3196500",
    "end": "3206160"
  },
  {
    "start": "3203000",
    "end": "3308000"
  },
  {
    "text": "a question that one thing is about how you get all the info ABCD any parameters in but it's how the algorithm puts them",
    "start": "3206160",
    "end": "3213960"
  },
  {
    "text": "together that I think maybe are just like how do they get you know in a non",
    "start": "3213960",
    "end": "3222000"
  },
  {
    "text": "parametric world we would just you have this high dimensional space and you literally estimate this thing for every",
    "start": "3222000",
    "end": "3228090"
  },
  {
    "text": "cell and that would be we would agree just taking the strict frequentist approach to the world we would say well",
    "start": "3228090",
    "end": "3234210"
  },
  {
    "text": "I know all people who had exactly three arrests and were this age and blah blah blah blah we look at the number of",
    "start": "3234210",
    "end": "3240450"
  },
  {
    "text": "people who ended up recidivating we would agree that this is our our nonparametric estimate of that probability in practice you're gonna fit",
    "start": "3240450",
    "end": "3248040"
  },
  {
    "text": "some model like logistic regression and all these models you know with enough data are gonna give you roughly the same",
    "start": "3248040",
    "end": "3253980"
  },
  {
    "text": "answers it is that we take something that's like most likely completely unrelated like whether they were born",
    "start": "3253980",
    "end": "3259950"
  },
  {
    "text": "when the moon was full or not yeah let's say like okay that's the min for me give that to you does that have to be",
    "start": "3259950",
    "end": "3266260"
  },
  {
    "text": "included I mean so there's I guess theory in practice I mean in in practice it's going to increase the variance of",
    "start": "3266260",
    "end": "3272440"
  },
  {
    "text": "your estimates it's going to add to the instability of your estimates in theory you can include it so you're saying",
    "start": "3272440",
    "end": "3278529"
  },
  {
    "text": "based on all available information that I have this is the likelihood that this person it will recidivate if that's the",
    "start": "3278529",
    "end": "3284559"
  },
  {
    "text": "outcome that you care about that this person will default and then the final question so hopefully this principle is",
    "start": "3284559",
    "end": "3291099"
  },
  {
    "text": "I would argue takes precedence over these other principles that are that are",
    "start": "3291099",
    "end": "3296410"
  },
  {
    "text": "loosely tied to this idea but it's certainly not the only thing we care about and so what are what's an example",
    "start": "3296410",
    "end": "3302640"
  },
  {
    "text": "what's in the situation where we wouldn't want this so we might not want to satisfy the equal treatment rinsable",
    "start": "3302640",
    "end": "3309150"
  },
  {
    "start": "3308000",
    "end": "3383000"
  },
  {
    "text": "if information availability is itself a function of race or some associated",
    "start": "3309150",
    "end": "3316029"
  },
  {
    "text": "factor yeah so this is an interesting idea because you're so you could say",
    "start": "3316029",
    "end": "3321220"
  },
  {
    "text": "well I have a lot more information about one group and so this is why I'm going to ignore that information but if you",
    "start": "3321220",
    "end": "3327369"
  },
  {
    "text": "just ignore that information you're still violating this and it's so what is it what's the actual justification for",
    "start": "3327369",
    "end": "3332710"
  },
  {
    "text": "ignoring that information maybe you're trying to change the equilibrium maybe you're trying to say well we don't want",
    "start": "3332710",
    "end": "3338410"
  },
  {
    "text": "to incentivize people to only collect this information for one group but unless there's some equilibrium argument",
    "start": "3338410",
    "end": "3344440"
  },
  {
    "text": "here I think it's hard to say that even if you have more information on one group than another that you're just",
    "start": "3344440",
    "end": "3350170"
  },
  {
    "text": "going to throw it away because I think well we don't have the criminal history for whites but we do have for blacks so",
    "start": "3350170",
    "end": "3356500"
  },
  {
    "text": "we should just ignore all that criminal history it's actually a tough argument to make unless you want to make the",
    "start": "3356500",
    "end": "3362200"
  },
  {
    "text": "equilibrium argument what I think is strong saying well we don't to incentivize that world we want to encourage people to collect the",
    "start": "3362200",
    "end": "3368829"
  },
  {
    "text": "information on everybody so we're not going to use it until you collect them everybody so there's a strong equilibrium argument for why you're",
    "start": "3368829",
    "end": "3375490"
  },
  {
    "text": "willing to take the hit an equal treatment to encourage people to do",
    "start": "3375490",
    "end": "3380559"
  },
  {
    "text": "something better and what's another argument especially the education context",
    "start": "3380559",
    "end": "3387960"
  },
  {
    "start": "3383000",
    "end": "3493000"
  },
  {
    "text": "so in education context you might say we're going to look at your estimate your GPA if you were to enroll in some",
    "start": "3388520",
    "end": "3395330"
  },
  {
    "text": "school so that you saw a measure of success at the school and we're just going to admit people based on that it's",
    "start": "3395330",
    "end": "3402710"
  },
  {
    "text": "not crazy so why why do we often not",
    "start": "3402710",
    "end": "3408020"
  },
  {
    "text": "like this this type of argument our",
    "start": "3408020",
    "end": "3413119"
  },
  {
    "text": "players make the best people ever a liar so okay so you might want to use only other variants so here okay yeah people",
    "start": "3413119",
    "end": "3420320"
  },
  {
    "text": "different racism more likely to live in neighborhoods that have more resources so for example like if your public",
    "start": "3420320",
    "end": "3426890"
  },
  {
    "text": "education system uses homeowner taxes and you have a neighborhood of white people a lot of money and a lot of",
    "start": "3426890",
    "end": "3432650"
  },
  {
    "text": "expensive homes in the neighborhood of poor black people for example cosplay that's redlining problem of the past",
    "start": "3432650",
    "end": "3438380"
  },
  {
    "text": "several decades it's more likely that the white students will have many more resources available to them and like",
    "start": "3438380",
    "end": "3446119"
  },
  {
    "text": "fewer demands on their time they less likely to have to work to support their family all of which culminates in a",
    "start": "3446119",
    "end": "3452030"
  },
  {
    "text": "higher probability of higher GPA so the",
    "start": "3452030",
    "end": "3458119"
  },
  {
    "text": "algorithm if we're smart enough would account for all of this and say well we're gonna down wait the past successes",
    "start": "3458119",
    "end": "3464119"
  },
  {
    "text": "of white students who are who were trained in these wealthy neighborhoods",
    "start": "3464119",
    "end": "3469369"
  },
  {
    "text": "because they had all of this so this is a good example of where you might want to use race in your algorithm but I mean",
    "start": "3469369",
    "end": "3475340"
  },
  {
    "text": "even the stronger claim that you wouldn't necessarily want to so let's do the oven correctly predicted this is",
    "start": "3475340",
    "end": "3480830"
  },
  {
    "text": "your GPA so it accounted for potential it correctly accounted for past experience and now this accurately",
    "start": "3480830",
    "end": "3488090"
  },
  {
    "text": "predicting your GPA in college so why might we still not like this rule",
    "start": "3488090",
    "end": "3493250"
  },
  {
    "start": "3493000",
    "end": "3599000"
  },
  {
    "text": "of admitting people because if you want to improve the GPAs people you need to",
    "start": "3493250",
    "end": "3498710"
  },
  {
    "text": "admit these poor GPA people first so you could like improve generations yes so",
    "start": "3498710",
    "end": "3504980"
  },
  {
    "text": "this is the equilibrium argue which i think is very persuasive so you've trying to say we're gonna shift the system and to do that we're gonna take",
    "start": "3504980",
    "end": "3510980"
  },
  {
    "text": "some you know short term hit on this principle of equal treatment for this",
    "start": "3510980",
    "end": "3515990"
  },
  {
    "text": "long term gain and now what else is there so there's this equilibrium argument is there say there's one more",
    "start": "3515990",
    "end": "3521090"
  },
  {
    "text": "argument and that will end with this hmm as you know information you can act on that",
    "start": "3521090",
    "end": "3526380"
  },
  {
    "text": "information so there's really good research even if you take the group of students that received the same grade",
    "start": "3526380",
    "end": "3532680"
  },
  {
    "text": "and you tell the teacher they received apps and they received A's they'll act on that information in the classroom and",
    "start": "3532680",
    "end": "3539310"
  },
  {
    "text": "actually reproduce that this is an issue of maybe the out the label is is biased",
    "start": "3539310",
    "end": "3546090"
  },
  {
    "text": "that GPA isn't really the right measure let's kind of assume a way that this is that we have a good measure of success",
    "start": "3546090",
    "end": "3551850"
  },
  {
    "text": "whatever that means I mean it but it's a good point that that's very hard to know what is that what is that right label that we're",
    "start": "3551850",
    "end": "3557610"
  },
  {
    "text": "training to but even if we have this what is what is argument for why we",
    "start": "3557610",
    "end": "3562950"
  },
  {
    "text": "wouldn't want to have a school necessarily that purely admits people individually on their on their estimated",
    "start": "3562950",
    "end": "3569610"
  },
  {
    "text": "GPA you know the scale some people",
    "start": "3569610",
    "end": "3575970"
  },
  {
    "text": "calculated a GPA very broadly across different schools so that so we should",
    "start": "3575970",
    "end": "3582300"
  },
  {
    "text": "be able to correct for that mm-hmm this is an aspirational kind of argument like we want a diverse population yeah",
    "start": "3582300",
    "end": "3590790"
  },
  {
    "text": "so this is I guess you could spin this two ways one way you could say you're changing the equilibrium but the other way is that we actually value that we're",
    "start": "3590790",
    "end": "3597300"
  },
  {
    "text": "trying to put together a team of people we're not trying to put together individuals but we think there's no",
    "start": "3597300",
    "end": "3602310"
  },
  {
    "text": "complementarities so this is one of the standard affirmative action arguments that we're saying that just like a",
    "start": "3602310",
    "end": "3608400"
  },
  {
    "text": "basketball team you wouldn't say we're gonna put together the five people who are you know have the the highest",
    "start": "3608400",
    "end": "3615560"
  },
  {
    "text": "expected scoring rates we're gonna say we're actually we need to have these complementarities and many academic",
    "start": "3615560",
    "end": "3622860"
  },
  {
    "text": "institutions are built like this many research groups are built like this that you want to have the diversity to since",
    "start": "3622860",
    "end": "3628800"
  },
  {
    "text": "that promotes better outcomes right so any situation where you care about the group or you believe that they're",
    "start": "3628800",
    "end": "3634020"
  },
  {
    "text": "complementarities you again might want to deviate from this type of individual level decision-making so I say these are",
    "start": "3634020",
    "end": "3640140"
  },
  {
    "text": "two big issues equilibrium the facts and also where you fundamentally care about the group not about individuals okay so",
    "start": "3640140",
    "end": "3648750"
  },
  {
    "text": "I'll end it there thanks",
    "start": "3648750",
    "end": "3652250"
  }
]
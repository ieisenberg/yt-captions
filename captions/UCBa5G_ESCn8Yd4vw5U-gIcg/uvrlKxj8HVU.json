[
  {
    "start": "0",
    "end": "5980"
  },
  {
    "text": "Today, we're going to talk\nabout machine learning with heterogeneous graph.",
    "start": "5980",
    "end": "11170"
  },
  {
    "text": "So far, we have been talking\nabout machine learning with simple graphs,\nwhere there is no type information inside the graph.",
    "start": "11170",
    "end": "17840"
  },
  {
    "text": "So nodes and edges, they\nare treated equally, they are homogeneous. So today, we are going to\ncover a more general family",
    "start": "17840",
    "end": "26619"
  },
  {
    "text": "of scraps, where we can\nfurther consider the category or types of different\nnodes and edges,",
    "start": "26620",
    "end": "32590"
  },
  {
    "text": "and we call this a\nheterogeneous graph. So this will be the topic\nfor today's lecture.",
    "start": "32590",
    "end": "39550"
  },
  {
    "text": "And a quick announcement. We have the project\nproposal due today. So if you haven't\nfinalized your proposal,",
    "start": "39550",
    "end": "47350"
  },
  {
    "text": "it should be two page. Please finish today. ",
    "start": "47350",
    "end": "54260"
  },
  {
    "text": "So let's get through the\ntechnical content for today. Today, we'll be talking\nabout heterogeneous graph.",
    "start": "54260",
    "end": "61940"
  },
  {
    "text": "So far, we have been\nhandling graphs, with only one edge or node type. So we just introduce our\nnodes and edges in the network",
    "start": "61940",
    "end": "70520"
  },
  {
    "text": "without further describing the\ntypes of these nodes and edges.",
    "start": "70520",
    "end": "76640"
  },
  {
    "text": "However, there are\nsome very good reasons that in reality, the\ngraphs may come with types.",
    "start": "76640",
    "end": "83460"
  },
  {
    "text": "So how do we handle\nthis graphs, where there could be multiple types\nof node and multiple types",
    "start": "83460",
    "end": "89030"
  },
  {
    "text": "of edges? And this is also known\nas heterogeneous graph. So specifically, we will today\ncover three different methods",
    "start": "89030",
    "end": "97765"
  },
  {
    "text": "that can perform\nmachine learning with heterogeneous graph. The focus today will\nbe the relational GCNs,",
    "start": "97765",
    "end": "104750"
  },
  {
    "text": "which is the first\nand most widely used method that can be used to\nlearn from heterogeneous graphs.",
    "start": "104750",
    "end": "111080"
  },
  {
    "text": "We will then cover\na recent state of art method, called\nheterogeneous graph",
    "start": "111080",
    "end": "116390"
  },
  {
    "text": "transformer, which\nbasically extend the idea we have learned-- the graph attention\nnetwork from homogeneous",
    "start": "116390",
    "end": "122990"
  },
  {
    "text": "graphs to heterogeneous graphs. And lastly, we will\nstart some discussions",
    "start": "122990",
    "end": "129350"
  },
  {
    "text": "regarding how can\nwe define a design space for heterogeneous GNNs. So if you remember\na few lectures back,",
    "start": "129350",
    "end": "137069"
  },
  {
    "text": "we have talked about a\ngeneral perspective for GNNs, and that was our\nhomogeneous graph",
    "start": "137070",
    "end": "143360"
  },
  {
    "text": "without any type information. So today, we are going\nto use some slides",
    "start": "143360",
    "end": "148430"
  },
  {
    "text": "to discuss how\nthat framework can be extended to heterogeneous\ngraphs as well.",
    "start": "148430",
    "end": "153780"
  },
  {
    "text": "So the focus today will\nbe the relational GNNs. ",
    "start": "153780",
    "end": "162910"
  },
  {
    "text": "So let's first\nmotivate, why do we want to study\nheterogeneous graph? Why is this notion\nis even useful?",
    "start": "162910",
    "end": "169840"
  },
  {
    "text": "Earlier, we have\nshown that we want to study graph because\nit describes entities",
    "start": "169840",
    "end": "175180"
  },
  {
    "text": "and their relationships. In practice, these\nentities or we",
    "start": "175180",
    "end": "180190"
  },
  {
    "text": "call nodes could\nhave different types. Let's say this could be\nlike a citation network",
    "start": "180190",
    "end": "186910"
  },
  {
    "text": "among different research\npapers and different authors. And for this graph,\nwe can actually",
    "start": "186910",
    "end": "192489"
  },
  {
    "text": "define two types\nof different nodes. So the red node could\ncapture the papers,",
    "start": "192490",
    "end": "198579"
  },
  {
    "text": "and the blue node can\nrepresent the authors. So you see because we treat--",
    "start": "198580",
    "end": "204670"
  },
  {
    "text": "usually, we will treat papers\nand authors differently. Say we have some paper\nspecific attributes,",
    "start": "204670",
    "end": "210430"
  },
  {
    "text": "like the number of pages-- the topic of the paper, and we\ncan have some other attributes",
    "start": "210430",
    "end": "215800"
  },
  {
    "text": "for the authors, like\nmaybe the nationality of the author, which school\nthe author belongs to.",
    "start": "215800",
    "end": "222250"
  },
  {
    "text": "Because this\ndifferent nodes could have different attributes,\nit would be natural that we can represent them\nas two separate types.",
    "start": "222250",
    "end": "230270"
  },
  {
    "text": "And then we want to represent\nsuch types in the network. ",
    "start": "230270",
    "end": "237000"
  },
  {
    "text": "Another example is\nthe case where we have different types of edges. And this could be also useful\nin our citation network.",
    "start": "237000",
    "end": "247230"
  },
  {
    "text": "So for the first type could be\none paper cite another paper.",
    "start": "247230",
    "end": "253250"
  },
  {
    "text": "Another type of connection\ncould be one paper or like another paper.",
    "start": "253250",
    "end": "259130"
  },
  {
    "text": "So they are similar. So similarly,\nbecause there could be different types of\nconnections and interactions",
    "start": "259130",
    "end": "266600"
  },
  {
    "text": "in the network, we may\nwant to represent them with different edge types. ",
    "start": "266600",
    "end": "273640"
  },
  {
    "text": "And then we can make the\ncase even more complicated. So given a network, you can both\nhave different types of nodes",
    "start": "273640",
    "end": "280780"
  },
  {
    "text": "and different types of edges. So still using our\nexample, we could",
    "start": "280780",
    "end": "286870"
  },
  {
    "text": "have two types of nodes in the\ncitation networks-- the papers and authors. And we can additionally\nhave two types",
    "start": "286870",
    "end": "294310"
  },
  {
    "text": "of edges, that are the citation\nrelationship and the similarity relationship.",
    "start": "294310",
    "end": "300040"
  },
  {
    "text": "So altogether, both\nnodes and edge types can exist in the same network.",
    "start": "300040",
    "end": "305890"
  },
  {
    "text": "And you can already see\nthis heterogeneous graph can go very complex.",
    "start": "305890",
    "end": "311420"
  },
  {
    "text": "So there are tons of\ncombinations of how many nodes and how many edge\nyou can consider",
    "start": "311420",
    "end": "317439"
  },
  {
    "text": "in this heterogeneous graph.  So how do we efficiently capture\nthis complex type relationship",
    "start": "317440",
    "end": "328460"
  },
  {
    "text": "in a heterogeneous graph? So the key idea\nthroughout this lecture",
    "start": "328460",
    "end": "333770"
  },
  {
    "text": "will be the concept of relation. So inside the relation it will\nbe a tuple of three elements.",
    "start": "333770",
    "end": "342380"
  },
  {
    "text": "We talk about the starting node,\nthe edge, and the end node.",
    "start": "342380",
    "end": "347850"
  },
  {
    "text": "So let's say given\nthis red node, it will connect it\nwith this blue node",
    "start": "347850",
    "end": "353720"
  },
  {
    "text": "through an edge--\nthis green edge, and we can use this table\nto succinctly capture",
    "start": "353720",
    "end": "360020"
  },
  {
    "text": "the complex relationship\nor interactions between a pair of nodes. So we capture the type\nof the starting node,",
    "start": "360020",
    "end": "367610"
  },
  {
    "text": "we capture the type\nof the edge, and then the type of the ending node.",
    "start": "367610",
    "end": "373620"
  },
  {
    "text": "So let's make this\nmore concrete. In this example, in\ntotal we could have",
    "start": "373620",
    "end": "380699"
  },
  {
    "text": "eight different relation types. Because we talk about there\nare two different node types",
    "start": "380700",
    "end": "387000"
  },
  {
    "text": "and two different edge types. And because we are\nconsidering this table and each element of the\ntable, you have two choices.",
    "start": "387000",
    "end": "395490"
  },
  {
    "text": "So altogether, you\ncould have eight different potential relation\ntypes from paper, cite, paper,",
    "start": "395490",
    "end": "402510"
  },
  {
    "text": "paper, like, paper, up to\nan author, cite, paper, and author, like, paper.",
    "start": "402510",
    "end": "409660"
  },
  {
    "text": "So overall, there could be\neight different relation types.",
    "start": "409660",
    "end": "415110"
  },
  {
    "text": "And in practice and in the\nremaining of this lecture, we will use this relation\ntype to describe an edge.",
    "start": "415110",
    "end": "422340"
  },
  {
    "text": "So this is as opposed\nto we directly use the edge type to\nrepresent an edge.",
    "start": "422340",
    "end": "430470"
  },
  {
    "text": "The reason is that\nas we can see, this relation type\nis more expressive and it can cover the better\ncaptures-- the interactions",
    "start": "430470",
    "end": "439140"
  },
  {
    "text": "between a pair of\nnodes and edges. Any questions so far?",
    "start": "439140",
    "end": "446750"
  },
  {
    "text": "Question. I guess could be both could\ntwo papers be similar, but also",
    "start": "446750",
    "end": "452780"
  },
  {
    "text": "cite each other. So you mean, one edge\ncontain two types.",
    "start": "452780",
    "end": "458260"
  },
  {
    "text": "Yeah, that's a good question. So in our setting,\nwe do not consider this so-called multigraph.",
    "start": "458260",
    "end": "464229"
  },
  {
    "text": "So one edge like a\nrepresent both types. One way to represent\nthat information",
    "start": "464230",
    "end": "469510"
  },
  {
    "text": "is that we can add two\ndifferent edges here. So let's say like a one\npaper, like another paper,",
    "start": "469510",
    "end": "477520"
  },
  {
    "text": "and another paper, cite-- the same paper also\ncite the paper. So we can use two separate\nedges to represent--",
    "start": "477520",
    "end": "485710"
  },
  {
    "text": "supposed to relations exist. ",
    "start": "485710",
    "end": "492949"
  },
  {
    "text": "So we'll talk about\nthis relation type throughout this lecture.",
    "start": "492950",
    "end": "498530"
  },
  {
    "text": " So with this\ndefinition, we can now",
    "start": "498530",
    "end": "504620"
  },
  {
    "text": "formally describe what is\nreally a heterogeneous graph. First a disclaimer.",
    "start": "504620",
    "end": "509660"
  },
  {
    "text": "There are multiple ways to\ndefine a heterogeneous graph, and you may read different\ndefinitions either",
    "start": "509660",
    "end": "515928"
  },
  {
    "text": "in blogs or research papers. But all of them\nserved the purpose of describing a graph, which\nhas multiple node types",
    "start": "515929",
    "end": "524390"
  },
  {
    "text": "and multiple edge types. So we will pick\none particular way to define heterogeneous graph.",
    "start": "524390",
    "end": "530450"
  },
  {
    "text": "You have V, R, T, and\nE. Four components",
    "start": "530450",
    "end": "536660"
  },
  {
    "text": "to describe a\nheterogeneous graph. First, we have nodes with\ndifferent nodes type.",
    "start": "536660",
    "end": "543620"
  },
  {
    "text": "So Vi is a particular node\ninside the set of nodes. And each node will be described\nwith a particular type.",
    "start": "543620",
    "end": "552740"
  },
  {
    "text": "And to get the\ntype of given node, we have this\ntransformation T that",
    "start": "552740",
    "end": "558740"
  },
  {
    "text": "basically tells us what is\nthe type of a given node Vi. We then additionally\ndefine the relations",
    "start": "558740",
    "end": "567270"
  },
  {
    "text": "within this heterogeneous graph. And as we have\nmotivated, instead",
    "start": "567270",
    "end": "572520"
  },
  {
    "text": "of using a one single edge\nto represent this relation, we use a tuple with three\nelements-- the starting node",
    "start": "572520",
    "end": "580110"
  },
  {
    "text": "Vi, the edge e, and\nthe end node Vj. And all the possible\nrelations will use a set R",
    "start": "580110",
    "end": "590220"
  },
  {
    "text": "to represent all the relations. And finally, we define this\nedge type e that belongs to--",
    "start": "590220",
    "end": "598500"
  },
  {
    "text": "I think this is a typo, we\nwill use the notation R here. This should really be\nE. But basically, we",
    "start": "598500",
    "end": "606690"
  },
  {
    "text": "also define an edge\ntype that belongs to a set of different edges.",
    "start": "606690",
    "end": "612810"
  },
  {
    "text": "Overall, this\ndefinition all about is to say we have a graph, and\nwe associate different types",
    "start": "612810",
    "end": "620010"
  },
  {
    "text": "for each node and\ndifferent types for each relation type of. ",
    "start": "620010",
    "end": "627530"
  },
  {
    "text": "Question? Sorry, a little bit\nconfusing about the notation. So you said relations\nwith relations",
    "start": "627530",
    "end": "633050"
  },
  {
    "text": "had this specific two fold that\nit wants to R but then later, you also said the edge\ntype E also belongs in R?",
    "start": "633050",
    "end": "640939"
  },
  {
    "text": "Yeah, this should be a typo. I believe this should\nbe E. So small \"e\"",
    "start": "640940",
    "end": "648080"
  },
  {
    "text": "means that a particular edge\ntype, let's say cite or like. And the capital \"E\" means the\nset of all possible edge types.",
    "start": "648080",
    "end": "658160"
  },
  {
    "text": "I think these are just tells\nus all the possible typos inside the heterogeneous graph.",
    "start": "658160",
    "end": "663980"
  },
  {
    "text": "Yeah. I'll make sure to correct\nafter the lecture. ",
    "start": "663980",
    "end": "671670"
  },
  {
    "text": "So now we have defined\nheterogeneous graph. And you may wonder that\nthis notation seems",
    "start": "671670",
    "end": "677480"
  },
  {
    "text": "to be pretty complex and\nare there like a real world use cases of using\nheterogeneous graph.",
    "start": "677480",
    "end": "683360"
  },
  {
    "text": "And the answer is\nyes, so actually there are tons of real world\ngraph that should actually",
    "start": "683360",
    "end": "688400"
  },
  {
    "text": "be represented as\nheterogeneous graph. We will visit several examples.",
    "start": "688400",
    "end": "693870"
  },
  {
    "text": "The first is a so-called\nbiomedical knowledge graph. And this can constantly arise\nin biomedical applications.",
    "start": "693870",
    "end": "702890"
  },
  {
    "text": "In this case, you may see\nthere are different nodes with different colors. And that means that the nodes\nbelongs to different types.",
    "start": "702890",
    "end": "713040"
  },
  {
    "text": "For example, we can have\nan example node, migraine.",
    "start": "713040",
    "end": "718759"
  },
  {
    "text": "This is like one\nparticular node. And this belongs to\nthe red type of node,",
    "start": "718760",
    "end": "725070"
  },
  {
    "text": "which is a disease node. And then we can define a\nparticular relationships",
    "start": "725070",
    "end": "730470"
  },
  {
    "text": "between two blue nodes,\nwhich are the drug nodes.",
    "start": "730470",
    "end": "735850"
  },
  {
    "text": "And then there are other\nexamples of node types and edge types. So you see that in this\nbiomedical knowledge graph,",
    "start": "735850",
    "end": "742920"
  },
  {
    "text": "you can define\ndifferent types of nodes and then capture\ntheir relationships.",
    "start": "742920",
    "end": "749740"
  },
  {
    "text": "Another example is\nthis event graph, where say an airport\nSFO is one type of node.",
    "start": "749740",
    "end": "758399"
  },
  {
    "text": "We can capture the relationship\nbetween a specific flight that origin from this airport.",
    "start": "758400",
    "end": "765960"
  },
  {
    "text": "And in this case, we can\nhave a node type of flight, and then an edge\ntype of destination.",
    "start": "765960",
    "end": "773320"
  },
  {
    "text": "So in a lot of scenarios, you\ncan describe a graph together",
    "start": "773320",
    "end": "779040"
  },
  {
    "text": "with the type of\nthe nodes and edges. Question?",
    "start": "779040",
    "end": "784270"
  },
  {
    "text": "Is there any way to\nexpress the different level of causal relationship? For example, in the\nbiomedical knowledge graph,",
    "start": "784270",
    "end": "790540"
  },
  {
    "text": "there will be a\ncausal relationship based on the microarray which\nis a causal relationship.",
    "start": "790540",
    "end": "796370"
  },
  {
    "text": "And then based on\nthe meta analysis, which is a strong\nrelationship, is there any way to express this\nlevel of relationship?",
    "start": "796370",
    "end": "806390"
  },
  {
    "text": "So the question is,\ncan we represent those like a hierarchical structure\nof the relationships.",
    "start": "806390",
    "end": "813530"
  },
  {
    "text": "So in other words,\ncan we even say build like the connectivity\nbetween the relationships.",
    "start": "813530",
    "end": "820510"
  },
  {
    "text": "Yeah, I think that is\ndoable, although we didn't talk about it in this lecture.",
    "start": "820510",
    "end": "825860"
  },
  {
    "text": "So in that sense, we can further\nconnecting the edge types",
    "start": "825860",
    "end": "831519"
  },
  {
    "text": "together. So we can construct\na separate graph that tells about the hierarchy\nof different edge type,",
    "start": "831520",
    "end": "838450"
  },
  {
    "text": "let's say, and that can\nbe used in a company with a different\nheterogeneous graph.",
    "start": "838450",
    "end": "844460"
  },
  {
    "text": "But with our current\nrepresentation, we just assume all the types\nthey are treated equally.",
    "start": "844460",
    "end": "850829"
  },
  {
    "text": "So we have maybe 10 node\ntype and 10 edge types, but we can\nadditionally construct a graph that link different\nnode and edge types together.",
    "start": "850830",
    "end": "858560"
  },
  {
    "text": "Yeah, that's a good question. ",
    "start": "858560",
    "end": "866290"
  },
  {
    "text": "Let's see more\nconcrete real examples of heterogeneous graph. Another very common use case\nis this e-commerce graph.",
    "start": "866290",
    "end": "874740"
  },
  {
    "text": "For example, for\nrecommender systems, we will have different\nusers, different items,",
    "start": "874740",
    "end": "880530"
  },
  {
    "text": "and different queries. And they can be represented as\nthree different types of nodes.",
    "start": "880530",
    "end": "887070"
  },
  {
    "text": "And then we will represent\ntheir interactions as the edges, but here, the edges can\nalso take different types.",
    "start": "887070",
    "end": "895810"
  },
  {
    "text": "So we can define\nthe relationship of search, the interaction\ntype click and guide.",
    "start": "895810",
    "end": "903780"
  },
  {
    "text": "So they are also three and\neven more types of interactions within this e-commerce graph.",
    "start": "903780",
    "end": "910720"
  },
  {
    "text": "So this is a very widely\nused scenario in industry",
    "start": "910720",
    "end": "916170"
  },
  {
    "text": "when people want to build\na recommender system, they can associate different\nuser item queries together.",
    "start": "916170",
    "end": "924134"
  },
  {
    "text": " And one more example,\nand we'll also",
    "start": "924135",
    "end": "929900"
  },
  {
    "text": "talk about a benchmark\ndataset from this example. We can further build\nan Academic Graph.",
    "start": "929900",
    "end": "935959"
  },
  {
    "text": "So including different\nauthors as nodes, venue nodes, and field nodes.",
    "start": "935960",
    "end": "942480"
  },
  {
    "text": "So there are three\ntypes of fields. And then we can also define\nthree types of interactions",
    "start": "942480",
    "end": "948410"
  },
  {
    "text": "that is for example,\nan author published, a paper, a paper\nbelongs to a field,",
    "start": "948410",
    "end": "954649"
  },
  {
    "text": "and there are also\ncitation relationships between these different\ntypes of nodes.",
    "start": "954650",
    "end": "960570"
  },
  {
    "text": "So this is yet another good\nexample of heterogeneous graph. And based on this\nformulation of graph,",
    "start": "960570",
    "end": "968120"
  },
  {
    "text": "we will later talk about\na benchmark dataset that is the most widely\nused benchmark",
    "start": "968120",
    "end": "973580"
  },
  {
    "text": "for heterogeneous graph, called\nMicrosoft Academic Graph, that basically construct this\nlike an author, venue, field",
    "start": "973580",
    "end": "981500"
  },
  {
    "text": "like a heterogeneous graph-- all the open access\nresearch papers.",
    "start": "981500",
    "end": "986510"
  },
  {
    "text": "And a lot of\n[INAUDIBLE] benchmarks are computed for that benchmark.",
    "start": "986510",
    "end": "992640"
  },
  {
    "text": " So now we have defined what\nis a heterogeneous graph",
    "start": "992640",
    "end": "999880"
  },
  {
    "text": "and seen a lot of\nreal world examples of heterogeneous graph. Before we jump into defining\na machine learning model",
    "start": "999880",
    "end": "1008730"
  },
  {
    "text": "to learn from\nheterogeneous graph, I want to spend two or three\nslides, just to discuss,",
    "start": "1008730",
    "end": "1014850"
  },
  {
    "text": "do we even need a\nheterogeneous graph? So indeed, there\nare a lot of cases",
    "start": "1014850",
    "end": "1020440"
  },
  {
    "text": "you may find that there are\ntype information associated with nodes and edges. But what we want to argue\nhere is that instead you",
    "start": "1020440",
    "end": "1029339"
  },
  {
    "text": "can consider model data type\ninformation as a feature alternatively.",
    "start": "1029339",
    "end": "1034470"
  },
  {
    "text": "So there are a very important\npractical decisions for you",
    "start": "1034470",
    "end": "1040650"
  },
  {
    "text": "to consider before you want\nto formulate your problem as a heterogeneous graph.",
    "start": "1040650",
    "end": "1046209"
  },
  {
    "text": "So our observation\nhere is that instead of associated with node and\nedge which is different types,",
    "start": "1046210",
    "end": "1053490"
  },
  {
    "text": "we can instead consider\nthem as different features. So one, like a simple\nexample is that we",
    "start": "1053490",
    "end": "1060160"
  },
  {
    "text": "can use an one-hot\nindicator to represent the types of nodes and edges\nas an additional features.",
    "start": "1060160",
    "end": "1069460"
  },
  {
    "text": "For example, still using our\nexample of academic network.",
    "start": "1069460",
    "end": "1076059"
  },
  {
    "text": "For two types of nodes-- author node and paper nodes,\nwe can use a one-hot encoding--",
    "start": "1076060",
    "end": "1083740"
  },
  {
    "text": "1, 0 to represent each\nauthor node and feature 0, 1 to represent each paper node.",
    "start": "1083740",
    "end": "1090100"
  },
  {
    "text": "And even though we may have\nany additional attributes for authors and\npapers, suppose we",
    "start": "1090100",
    "end": "1096730"
  },
  {
    "text": "append this additional\nindicator feature to this two types of nodes.",
    "start": "1096730",
    "end": "1102100"
  },
  {
    "text": "Then essentially, we have\ninjected this type information to the network.",
    "start": "1102100",
    "end": "1107780"
  },
  {
    "text": "So in this case, you no longer\nneed to directly represent the type information, but\ninstead we can just use them",
    "start": "1107780",
    "end": "1114850"
  },
  {
    "text": "as additional features. And similarly, suppose\nwe have edge types,",
    "start": "1114850",
    "end": "1119940"
  },
  {
    "text": "we can also treat edge\ntypes as edge features, and then consider learning from\nthe edges with additional edge",
    "start": "1119940",
    "end": "1129000"
  },
  {
    "text": "features. And under this\nperspective, we essentially reduce heterogeneous\ngraph into a standard",
    "start": "1129000",
    "end": "1136650"
  },
  {
    "text": "or so-called homogeneous\ngraph that we have discussed multiple lectures before.",
    "start": "1136650",
    "end": "1144780"
  },
  {
    "text": "So are there cases\nwhen we really need a heterogeneous graph?",
    "start": "1144780",
    "end": "1151549"
  },
  {
    "text": "So here, I show\ntwo examples that I thought are pretty important\nto use heterogeneous graph,",
    "start": "1151550",
    "end": "1159220"
  },
  {
    "text": "but you can consider more cases. The first case that\nwe have good reason to use heterogeneous\ngraph, in some cases, when",
    "start": "1159220",
    "end": "1166360"
  },
  {
    "text": "we have four dimensional\nfeature for author nodes, because there are--",
    "start": "1166360",
    "end": "1171760"
  },
  {
    "text": "let's say four distinctive\nattributes of a given author, and there could be\na five dimensional feature for paper node.",
    "start": "1171760",
    "end": "1177370"
  },
  {
    "text": "Let's say we have five different\nattributes for the paper nodes. So in this case, suppose we just\ntreat this type of information",
    "start": "1177370",
    "end": "1186190"
  },
  {
    "text": "as features, you\nmay find an issue. Because now, different nodes\nhave different dimensions",
    "start": "1186190",
    "end": "1193870"
  },
  {
    "text": "of input features. And if you recall, like for\nany graph neural network,",
    "start": "1193870",
    "end": "1199450"
  },
  {
    "text": "our assumption is to reuse\nthe message computation across author nodes.",
    "start": "1199450",
    "end": "1205760"
  },
  {
    "text": "And now we face into an issue,\nbecause the input feature for different nodes\nare different.",
    "start": "1205760",
    "end": "1211010"
  },
  {
    "text": "But we want to share the\nsame computational graph. And that could be a problem. Of course, there\nare some workaround.",
    "start": "1211010",
    "end": "1217730"
  },
  {
    "text": "Let's say we can map the\nfeature into the same dimension, but still there are cases\nwhere the input feature",
    "start": "1217730",
    "end": "1226760"
  },
  {
    "text": "dimension is mismatched. And in that case, we\nwant to consider modeling",
    "start": "1226760",
    "end": "1232100"
  },
  {
    "text": "these two nodes-- two\ntypes of nodes as a type rather than features.",
    "start": "1232100",
    "end": "1238160"
  },
  {
    "text": "In another example, we\nmay have a prior knowledge or external knowledge saying\nthat this different relation",
    "start": "1238160",
    "end": "1246710"
  },
  {
    "text": "types should represent\ndifferent types of interaction. Let's say, we have a graph\nbuilt over different languages,",
    "start": "1246710",
    "end": "1255590"
  },
  {
    "text": "and the type of the relation\ntype between English translated",
    "start": "1255590",
    "end": "1261770"
  },
  {
    "text": "into French, and another\nrelation type English translated to Chinese. These are two different\nrelation types,",
    "start": "1261770",
    "end": "1268190"
  },
  {
    "text": "and suppose we want\nto build a model to capture these two\ntypes of interactions, then this will require\ndifferent models.",
    "start": "1268190",
    "end": "1275510"
  },
  {
    "text": "So suppose we just treat\nthis information as feature information, then still\nwe will reuse or share",
    "start": "1275510",
    "end": "1282530"
  },
  {
    "text": "the same weights\nacross all the edges. And that is not what we expect.",
    "start": "1282530",
    "end": "1288830"
  },
  {
    "text": "And in this particular\ncase, it would be better that we model this\ninformation as a type, as",
    "start": "1288830",
    "end": "1295700"
  },
  {
    "text": "opposed to a feature. So these are just some\nbrainstorming ideas showing that what\nyou should consider",
    "start": "1295700",
    "end": "1303270"
  },
  {
    "text": "when you decide whether a\nfeature or attribute should be considered as a type,\nor consider as a feature.",
    "start": "1303270",
    "end": "1309480"
  },
  {
    "text": " So here is like the\nfinal conclusion",
    "start": "1309480",
    "end": "1318210"
  },
  {
    "text": "we have after the discussions. Ultimately, we know\nthis heterogeneous graph",
    "start": "1318210",
    "end": "1323570"
  },
  {
    "text": "is definitely a\nmore expressive way to represent the interactions\nbetween entities,",
    "start": "1323570",
    "end": "1330170"
  },
  {
    "text": "Because it can capture\ndifferent types of interactions between the nodes and edges. However, this also\ncomes with cost.",
    "start": "1330170",
    "end": "1337530"
  },
  {
    "text": "So for heterogeneous graph,\nit will be more expensive in terms of the\ncomputation, because now we",
    "start": "1337530",
    "end": "1343580"
  },
  {
    "text": "have different types\nof interactions. And it is also more\nexpensive in storage,",
    "start": "1343580",
    "end": "1349070"
  },
  {
    "text": "either in terms of\nthe fact that we want to store additional\ntype information, and also that we\nmost likely wouldn't",
    "start": "1349070",
    "end": "1356720"
  },
  {
    "text": "be able to store everything\ninto one single matrix, but different separate matrix\nfor each type of information.",
    "start": "1356720",
    "end": "1362970"
  },
  {
    "text": "So it is more expensive\nin storage as well. And additionally, the\nimplementation as you",
    "start": "1362970",
    "end": "1369290"
  },
  {
    "text": "can imagine. For heterogeneous graph, it\nwill be much more complex. So it definitely come with cost.",
    "start": "1369290",
    "end": "1375490"
  },
  {
    "text": "So our discussion here\nis to share some insight that there are many\nways that we can convert",
    "start": "1375490",
    "end": "1382679"
  },
  {
    "text": "a heterogeneous graph\nback to a standard graph that we have discussed in\nthe previous lectures, that",
    "start": "1382680",
    "end": "1390000"
  },
  {
    "text": "is so-called the\nhomogeneous graph. But suppose, you\ndo want to model this complex and different\ntypes of interactions",
    "start": "1390000",
    "end": "1397860"
  },
  {
    "text": "between the network, you\nshould consider using heterogeneous graph instead. ",
    "start": "1397860",
    "end": "1405120"
  },
  {
    "text": "So now we have motivated the\nidea of heterogeneous graph. Next, we're going to\nintroduce the machine learning",
    "start": "1405120",
    "end": "1414540"
  },
  {
    "text": "model that can learn\nfrom heterogeneous graph. And particularly, we will\ntalk about relational GCN",
    "start": "1414540",
    "end": "1420779"
  },
  {
    "text": "as the first and most\nwidely used method to learn from\nheterogeneous graphs.",
    "start": "1420780",
    "end": "1426870"
  },
  {
    "text": "So as a recap, this\nis how we define so-called Graph Convolutional\nNetworks for homogeneous graph.",
    "start": "1426870",
    "end": "1436260"
  },
  {
    "text": "We compute the message for each\nneighbors with a transformation",
    "start": "1436260",
    "end": "1442620"
  },
  {
    "text": "W. And then we\nperform an aggregation across all the\nmessages, normalized",
    "start": "1442620",
    "end": "1449039"
  },
  {
    "text": "by the degree of the input node. So if you falls\nunder the message an aggregation\nfunction we talk about",
    "start": "1449040",
    "end": "1455970"
  },
  {
    "text": "and this is for a\nhomogeneous graph. ",
    "start": "1455970",
    "end": "1462210"
  },
  {
    "text": "And in our discussion,\nwe will slightly extend like the\ndefinition of the graph.",
    "start": "1462210",
    "end": "1468460"
  },
  {
    "text": "So instead of considering\nan undirected graph, we will consider like a directed\ngraph just for the better",
    "start": "1468460",
    "end": "1475530"
  },
  {
    "text": "illustration as\nyou will see later. And then we can consider\nthe simplest case,",
    "start": "1475530",
    "end": "1482519"
  },
  {
    "text": "where there is only\none type of relation in this directed graph.",
    "start": "1482520",
    "end": "1487720"
  },
  {
    "text": "And based on what we\nhave defined for GCN. Our goal is to define a\ncomputational graph that",
    "start": "1487720",
    "end": "1495520"
  },
  {
    "text": "can generate the representation\nfor a target node A.",
    "start": "1495520",
    "end": "1500660"
  },
  {
    "text": "So this will be the\ncomputational graph for this particular\ndirected graph. So we will look at As neighbor--",
    "start": "1500660",
    "end": "1507650"
  },
  {
    "text": "B, C, and D, and B will\nhave one neighbor C, and C has neighbor F\nand E, and D does not",
    "start": "1507650",
    "end": "1515150"
  },
  {
    "text": "have any additional neighbors. So this is like the\ncomputational graph for a directed graph like this.",
    "start": "1515150",
    "end": "1522000"
  },
  {
    "text": "So it's really nothing\ndifferent from what we learned, except that now-- because we define the\ninput graph as directed,",
    "start": "1522000",
    "end": "1530180"
  },
  {
    "text": "the message will only be\npassed along the direction of the edges.",
    "start": "1530180",
    "end": "1535400"
  },
  {
    "text": "So recall that\nearlier, since there are no direction of\nthe edges, the message are essentially passed\nbidirectionally.",
    "start": "1535400",
    "end": "1542059"
  },
  {
    "text": "So now this is passed directly. And we do not consider any\nadditional type information",
    "start": "1542060",
    "end": "1548670"
  },
  {
    "text": "here. This is the standard graph\nwe have seen a lot of times before. So in this case, all the\ntransformations are shared.",
    "start": "1548670",
    "end": "1557670"
  },
  {
    "text": "So you can see that\nthey are colored with the same color,\nwhich means that we",
    "start": "1557670",
    "end": "1563062"
  },
  {
    "text": "share the operation\nfor all the nodes.  So now let's consider the\ncase of heterogeneous graphs.",
    "start": "1563062",
    "end": "1571450"
  },
  {
    "text": "And in the case of\nheterogeneous graph, we could have different\ntypes of relation",
    "start": "1571450",
    "end": "1576940"
  },
  {
    "text": "that we have motivated earlier. So in our example, we have three\ndifferent types of relations.",
    "start": "1576940",
    "end": "1583210"
  },
  {
    "text": "And the edges with\nthe same relations, we color them with\nthe same color.",
    "start": "1583210",
    "end": "1590110"
  },
  {
    "text": "And additionally, this\nrelation type as we talk about is really about a tuple of\nstarting node and end node.",
    "start": "1590110",
    "end": "1598930"
  },
  {
    "text": "And we want to simplify\nthe notation notation, so we just use a\nsingle relation say",
    "start": "1598930",
    "end": "1604720"
  },
  {
    "text": "r1 to represent this full\ntable of relationships. So this is our setting.",
    "start": "1604720",
    "end": "1610670"
  },
  {
    "text": "So we want to given this\na heterogeneous graph, we want to learn from it still\nusing this graph convolutional",
    "start": "1610670",
    "end": "1618220"
  },
  {
    "text": "neural network. So what are our ideas here?",
    "start": "1618220",
    "end": "1625580"
  },
  {
    "text": "Because we know that there are\ndifferent types of relations. Our intuition is that instead of\nsharing the weights across all",
    "start": "1625580",
    "end": "1634160"
  },
  {
    "text": "the nodes, now, we'll\nhave a different weight matrix for each different\ntypes of relations.",
    "start": "1634160",
    "end": "1642260"
  },
  {
    "text": "For example, we have\nthese three types of relations in this\ninput heterogeneous graph.",
    "start": "1642260",
    "end": "1648140"
  },
  {
    "text": "And based on what\nwe have seen, we will then define three\ndifferent weight matrices.",
    "start": "1648140",
    "end": "1654470"
  },
  {
    "text": "Each weight matrix is\ncorresponding to one particular relation type.",
    "start": "1654470",
    "end": "1660020"
  },
  {
    "text": "And we want to use\nthis different weights to capture this different types\nof interactions for a network.",
    "start": "1660020",
    "end": "1669840"
  },
  {
    "text": "So this is our\nidea and motivation of learning from\nheterogeneous graphs.",
    "start": "1669840",
    "end": "1677060"
  },
  {
    "text": "So what does it mean in\nthe computational graph is as follows. So we have the same\ncomputational graph structure.",
    "start": "1677060",
    "end": "1685039"
  },
  {
    "text": "So node A still have\nB, C, D as neighbors, B has C as the neighbors.",
    "start": "1685040",
    "end": "1691180"
  },
  {
    "text": "So the structure of\nthe computational graph does not change at all. The only thing that has\nchanged is the weights",
    "start": "1691180",
    "end": "1699850"
  },
  {
    "text": "of the neural networks. So remember that earlier,\nall the neural networks",
    "start": "1699850",
    "end": "1706120"
  },
  {
    "text": "or the weights are in\nthe gray color, which means that they are shared\nacross all the nodes.",
    "start": "1706120",
    "end": "1712600"
  },
  {
    "text": "Now because we there are\ndifferent types of interaction, we will use different colors\nto represent different types",
    "start": "1712600",
    "end": "1720040"
  },
  {
    "text": "of interactions. So let's see some\nexample, because we know the edge or the\nrelation from node D to A",
    "start": "1720040",
    "end": "1730450"
  },
  {
    "text": "is this blue r1 relation type. In this computational\ngraph, we also",
    "start": "1730450",
    "end": "1736550"
  },
  {
    "text": "make sure to use this\nblue weight to represent this particular relation type.",
    "start": "1736550",
    "end": "1742670"
  },
  {
    "text": "And for example here,\nA and C is transformed using this red weight.",
    "start": "1742670",
    "end": "1749040"
  },
  {
    "text": "And we can see that\nthe edge from C to A is indeed this red\ntype of edge r2.",
    "start": "1749040",
    "end": "1757250"
  },
  {
    "text": "So this is our basic\nidea of how to repurpose",
    "start": "1757250",
    "end": "1764810"
  },
  {
    "text": "a graph convolutional\nneural network for heterogeneous graph. We keep all the computational\ngraph structure to be the same,",
    "start": "1764810",
    "end": "1772940"
  },
  {
    "text": "except that we will now\nassign different weights for different types\nof relation types.",
    "start": "1772940",
    "end": "1782020"
  },
  {
    "text": "Any questions?  So this is essentially the\nkey idea of all the remaining",
    "start": "1782020",
    "end": "1790330"
  },
  {
    "text": "discussion in this lecture. So we just use or\ndifferent instantiations",
    "start": "1790330",
    "end": "1795820"
  },
  {
    "text": "of neural networks to capture\ndifferent relation types. ",
    "start": "1795820",
    "end": "1802130"
  },
  {
    "text": "And we can think\nthe same process in a slightly different wheel.",
    "start": "1802130",
    "end": "1807200"
  },
  {
    "text": "So instead of considering\na heterogeneous graph as one graph, we can consider\nit as N different graphs, where",
    "start": "1807200",
    "end": "1817220"
  },
  {
    "text": "one particular graph talks about\nthe connectivity with respect to one relation type.",
    "start": "1817220",
    "end": "1824480"
  },
  {
    "text": "So because we can have N\ndifferent relation types, we can consider N different\ngraphs, each connected with one",
    "start": "1824480",
    "end": "1833870"
  },
  {
    "text": "particular relation type. And what we do is that\ncan be considered as, instead of learning\nfrom one giant graph,",
    "start": "1833870",
    "end": "1842090"
  },
  {
    "text": "we perform machine learning for\nN different relational graph",
    "start": "1842090",
    "end": "1847309"
  },
  {
    "text": "for each relation type. And because we know that\nthere are N different graphs,",
    "start": "1847310",
    "end": "1852980"
  },
  {
    "text": "we have defined N\ndifferent set of ways to represent this different\ntypes of input graph.",
    "start": "1852980",
    "end": "1861290"
  },
  {
    "text": "Question? So this kind of approach\nwould make a lot of sense if we're sure that all of the\ndifferent labels for the edges",
    "start": "1861290",
    "end": "1868740"
  },
  {
    "text": "are truly independent. Because we're basically\nsaying each one of them is its own graph. But I guess in reality, this\nis a choice for real world data",
    "start": "1868740",
    "end": "1876720"
  },
  {
    "text": "for us to make this\nchoice that it makes sense to have four different\nlabels, let's say four edges. Is there a way for me to\nanalyze these weight matrices,",
    "start": "1876720",
    "end": "1884590"
  },
  {
    "text": "so to know if there's actually a\ncovariance between them or not? So basically saying to help\nme choose whether I should",
    "start": "1884590",
    "end": "1890670"
  },
  {
    "text": "do heterogeneous graphs\nor not, or how many in real world applications?",
    "start": "1890670",
    "end": "1896520"
  },
  {
    "text": "Yeah, that's a good question. So I think the question\nis also motivated by this observation\nin the sense that we",
    "start": "1896520",
    "end": "1903000"
  },
  {
    "text": "are curious, what\nare the correlation between each type of relations?",
    "start": "1903000",
    "end": "1911400"
  },
  {
    "text": "As far as I know, I\ndon't have a knowledge about a very principled ways\nto detect, to what extent",
    "start": "1911400",
    "end": "1919020"
  },
  {
    "text": "we should consider\nas a homogeneous or heterogeneous graph. But in practice, I would\nsuggest you can try both methods",
    "start": "1919020",
    "end": "1925400"
  },
  {
    "text": "and see which performs better. Usually in practice,\nI would suggest",
    "start": "1925400",
    "end": "1931370"
  },
  {
    "text": "you start with a\ntreating this type information in the features as\nwe have earlier because it is",
    "start": "1931370",
    "end": "1938780"
  },
  {
    "text": "much more easier to implement. And suppose the performance\nis not satisfiable where you want to expect\nhigher performance,",
    "start": "1938780",
    "end": "1945620"
  },
  {
    "text": "then you can consider\nusing heterogeneous graph. We haven't talked about the\nimplementation of heterogeneous",
    "start": "1945620",
    "end": "1950900"
  },
  {
    "text": "yet. But usually, it is\nslightly more complex than the homogeneous graph. ",
    "start": "1950900",
    "end": "1959039"
  },
  {
    "text": "So this is another perspective\nof what we are doing here. So we learn N different\nneural network",
    "start": "1959040",
    "end": "1966120"
  },
  {
    "text": "for N different subgraph\nthat are constructed from the same input graph.",
    "start": "1966120",
    "end": "1974250"
  },
  {
    "text": "So now, we're going to\ntalk about the specific-- a definition for\na Relational GCN.",
    "start": "1974250",
    "end": "1980780"
  },
  {
    "text": "And this is really nothing\ndifferent from a Standard GCN,",
    "start": "1980780",
    "end": "1986090"
  },
  {
    "text": "except that we consider\nthe type information, and we will use\ndifferent weight matrices to represent different types.",
    "start": "1986090",
    "end": "1993720"
  },
  {
    "text": "So this is the\ndefinition of GRCN. And you see that we still\nhave a lot of things",
    "start": "1993720",
    "end": "2000429"
  },
  {
    "text": "we are familiar with, so\nwe use the weight matrix W to transform a given node.",
    "start": "2000430",
    "end": "2006789"
  },
  {
    "text": "We will perform an aggregation\nover the neighbors of a given node.",
    "start": "2006790",
    "end": "2012440"
  },
  {
    "text": "And additionally,\nperform an aggregation over different relation type r.",
    "start": "2012440",
    "end": "2018940"
  },
  {
    "text": "So we can still\nunderstand this equation through the two steps we\nhave been talking about--",
    "start": "2018940",
    "end": "2026800"
  },
  {
    "text": "message computation\nand aggregation. So now, for a\nheterogeneous graph,",
    "start": "2026800",
    "end": "2031870"
  },
  {
    "text": "the message computation is\nspecific to a given edge type.",
    "start": "2031870",
    "end": "2037450"
  },
  {
    "text": "So you can see\nthere a subscript r",
    "start": "2037450",
    "end": "2043039"
  },
  {
    "text": "says that this weight\nmatrix is particular for one given relation type.",
    "start": "2043040",
    "end": "2049320"
  },
  {
    "text": "So we will transform\nthe input node based on the relation\ntype we know.",
    "start": "2049320",
    "end": "2056330"
  },
  {
    "text": "And then we can\ncreate a message based on each of the relation type.",
    "start": "2056330",
    "end": "2063560"
  },
  {
    "text": "And it is worth noting that we\nstill consider the weight that transform the node itself.",
    "start": "2063560",
    "end": "2069929"
  },
  {
    "text": "So we talk about we want to\nhave two parts of information. One part of information\nfrom the neighbors",
    "start": "2069929",
    "end": "2075800"
  },
  {
    "text": "of given node, another\npart from the node itself. So still we have this term\nthat capture the transformation",
    "start": "2075800",
    "end": "2083238"
  },
  {
    "text": "of the node itself. And then after computing\nthis different types",
    "start": "2083239",
    "end": "2088820"
  },
  {
    "text": "of interactions, we will\nperform aggregation. And you can notice that\ninstead of performing",
    "start": "2088820",
    "end": "2096138"
  },
  {
    "text": "one summation in the Standard\nGCN, now in this equation, we have a double summation.",
    "start": "2096139",
    "end": "2101460"
  },
  {
    "text": "This is because we first want\nto aggregate the messages within one relation type\nas we have seen also",
    "start": "2101460",
    "end": "2110130"
  },
  {
    "text": "in the homogeneous graph. But now because we have our\ndifferent types of relations,",
    "start": "2110130",
    "end": "2116099"
  },
  {
    "text": "we want to additionally summing\nover different relation types.",
    "start": "2116100",
    "end": "2121870"
  },
  {
    "text": "So this is how the\n[? aggregation ?] is defined over different relation types.",
    "start": "2121870",
    "end": "2128095"
  },
  {
    "start": "2128095",
    "end": "2134450"
  },
  {
    "text": "So next, we're going to discuss\nwhat are the implications",
    "start": "2134450",
    "end": "2139990"
  },
  {
    "text": "and the potential issues\nof this RGCN formulation.",
    "start": "2139990",
    "end": "2146000"
  },
  {
    "text": "So in the end, we want to\nlearn a different weight matrix for each type of relations.",
    "start": "2146000",
    "end": "2152680"
  },
  {
    "text": "So ultimately, we have this\nr different weight matrices.",
    "start": "2152680",
    "end": "2157720"
  },
  {
    "text": "And each weight matrix\nhas the complexity of d square, which\nbasically says",
    "start": "2157720",
    "end": "2165670"
  },
  {
    "text": "we have the input dimension\nfor each type of the node--",
    "start": "2165670",
    "end": "2171579"
  },
  {
    "text": "given node type. And then we want to project\nit into the dl plus 1",
    "start": "2171580",
    "end": "2178210"
  },
  {
    "text": "to the next dimension\nfor the next layer. So this is the shape of\na given weight matrices,",
    "start": "2178210",
    "end": "2185890"
  },
  {
    "text": "and we want to have r\ndifferent weight matrices. And you can observe that because\ninside a heterogeneous graph,",
    "start": "2185890",
    "end": "2196120"
  },
  {
    "text": "there can be tons of\ndifferent relation types. So even there are say two\nnode types and two edge types as we have seen,\nwe can potentially",
    "start": "2196120",
    "end": "2202990"
  },
  {
    "text": "have eight different\nrelation types. So soon it will become an\noverfitting will become",
    "start": "2202990",
    "end": "2208000"
  },
  {
    "text": "an issue because you\nsimply have defined so many different weight\nmatrices to learn from.",
    "start": "2208000",
    "end": "2214390"
  },
  {
    "text": "And this is an issue both\nin terms of overfitting and also from the cost\nof the computation.",
    "start": "2214390",
    "end": "2220430"
  },
  {
    "text": "So next, we're going to discuss\ntwo practical methods that",
    "start": "2220430",
    "end": "2225700"
  },
  {
    "text": "are widely used to\nalleviate this issue.",
    "start": "2225700",
    "end": "2230710"
  },
  {
    "text": "Basically, you want to\nregularize the weight of Wrl for each relation type to make\nthe cost to be more affordable.",
    "start": "2230710",
    "end": "2239950"
  },
  {
    "text": "The first approach is to\nuse a block diagonal matrix to reduce the\nnumber of parameter",
    "start": "2239950",
    "end": "2246280"
  },
  {
    "text": "for each weight matrix\nfor each relation type.",
    "start": "2246280",
    "end": "2252730"
  },
  {
    "text": "The second method is to\ndo a basis decomposition",
    "start": "2252730",
    "end": "2258010"
  },
  {
    "text": "or also known as the\ndictionary learning to reduce the effective\nnumber of parameters.",
    "start": "2258010",
    "end": "2264609"
  },
  {
    "text": "And in practice,\nyou can actually combine both methods to make the\nnumber of weights even smaller.",
    "start": "2264610",
    "end": "2272410"
  },
  {
    "text": "So let's have our first\napproach to attract the computational cost.",
    "start": "2272410",
    "end": "2278200"
  },
  {
    "text": "So the insight is that we can\nmake this trainable weights to be sparse. So one option to\nmake this sparse",
    "start": "2278200",
    "end": "2286890"
  },
  {
    "text": "is to formulate as a block\ndiagonal weight matrix.",
    "start": "2286890",
    "end": "2291930"
  },
  {
    "text": "So earlier, we\nhave always assumed that any neural\nnetwork transformation",
    "start": "2291930",
    "end": "2297870"
  },
  {
    "text": "are fully connected layer. So in the sense that the weight\nmatrix is a dense matrix,",
    "start": "2297870",
    "end": "2304320"
  },
  {
    "text": "so all the values are nonzero. And in this case, we want to\nreduce the number of parameters",
    "start": "2304320",
    "end": "2312060"
  },
  {
    "text": "by making it to\nbe block diagonal. So only this block diagonal\nentries are non-zero,",
    "start": "2312060",
    "end": "2318180"
  },
  {
    "text": "the remaining entries are zero. So we can treat it as like a\nspecial type of sparse matrix.",
    "start": "2318180",
    "end": "2325410"
  },
  {
    "text": "The limitation of\nthis approach suppose we want to use this block\ndiagonal matrix is that we will",
    "start": "2325410",
    "end": "2331540"
  },
  {
    "text": "only consider the interactions\nbetween the nearby neurons or the dimension of the input.",
    "start": "2331540",
    "end": "2337910"
  },
  {
    "text": "So in this case, suppose we are\ncomputing over the first, block",
    "start": "2337910",
    "end": "2342970"
  },
  {
    "text": "diagonal entries. Then only the node\none and node two, they will have interaction.",
    "start": "2342970",
    "end": "2348610"
  },
  {
    "text": "But then say the node one,\nthose are the dimension one, and dimension three, you\nwouldn't have any interaction",
    "start": "2348610",
    "end": "2355270"
  },
  {
    "text": "because there are no ways\nto represent this like, a remote connectivity.",
    "start": "2355270",
    "end": "2360460"
  },
  {
    "text": "But indeed, this approach\nis effective in reducing the number of\ntrainable parameters.",
    "start": "2360460",
    "end": "2365990"
  },
  {
    "text": "So let's say we\nuse B to represent this low dimensional matrix.",
    "start": "2365990",
    "end": "2372730"
  },
  {
    "text": "Then essentially by using\nthis block diagonal idea, we are reducing the number of\nparameters from d squared--",
    "start": "2372730",
    "end": "2383410"
  },
  {
    "text": "roughly d square to\nd squared over B. So We essentially reduce\nthe number of parameter",
    "start": "2383410",
    "end": "2390309"
  },
  {
    "text": "by ratio of d.  Another widely used approach\nis to share the weights",
    "start": "2390310",
    "end": "2398020"
  },
  {
    "text": "across different edge types. and essentially reducing\nthe trainable parameters.",
    "start": "2398020",
    "end": "2404150"
  },
  {
    "text": "In this case, we have the\nidea of so-called basis decomposition or\nbasis transformation.",
    "start": "2404150",
    "end": "2411020"
  },
  {
    "text": "So instead of letting\nthis weight matrix Wr to be fully trainable,\nwe can instead",
    "start": "2411020",
    "end": "2418960"
  },
  {
    "text": "consider the\nfollowing formulation. We have this another matrix Vb\nto be like a so-called basis",
    "start": "2418960",
    "end": "2428230"
  },
  {
    "text": "matrix. And then we will train\na trainable vector",
    "start": "2428230",
    "end": "2433480"
  },
  {
    "text": "arb that tells us the\nimportance of the weights",
    "start": "2433480",
    "end": "2439570"
  },
  {
    "text": "of different columns\nof this matrix bv.",
    "start": "2439570",
    "end": "2444730"
  },
  {
    "text": "So essentially, what\nwe learn is only this arb that tells us\nhow to linearly combine",
    "start": "2444730",
    "end": "2453609"
  },
  {
    "text": "different columns of\nthe weight matrix vb.",
    "start": "2453610",
    "end": "2459220"
  },
  {
    "text": "And this way, we can generate\na different weight matrix for different relation type\nbut without having to define",
    "start": "2459220",
    "end": "2468040"
  },
  {
    "text": "our different weight matrices. So ultimately, to capture\nthis relational information,",
    "start": "2468040",
    "end": "2477040"
  },
  {
    "text": "now we only need to learn\nthis vector arb, which only has a number of scalars.",
    "start": "2477040",
    "end": "2484300"
  },
  {
    "text": "So this can also\nsignificantly reduce the number of parameters. ",
    "start": "2484300",
    "end": "2492360"
  },
  {
    "text": "So now we have talked\nabout the idea of RGCN, and how to make the\ncomputation more tractable.",
    "start": "2492360",
    "end": "2498620"
  },
  {
    "text": "Next, we're going to discuss\nsome concrete applications, how to apply this RGCN to\nsay node classification",
    "start": "2498620",
    "end": "2506450"
  },
  {
    "text": "and link prediction that we have\nalso seen in previous lectures.",
    "start": "2506450",
    "end": "2511500"
  },
  {
    "text": "So first for node\nclassification. The approach of applying\nRGCN is quite similar to what",
    "start": "2511500",
    "end": "2520020"
  },
  {
    "text": "we have seen earlier. So let's say we want to\npredict node A, which have k different classes.",
    "start": "2520020",
    "end": "2527430"
  },
  {
    "text": "Then we will still\nusing RGCN to generate the embedding for this node A.",
    "start": "2527430",
    "end": "2533340"
  },
  {
    "text": "So we have this\nvector for node A, hAL that represent the final layer\nof output for this node A.",
    "start": "2533340",
    "end": "2542190"
  },
  {
    "text": "And then we will\ncompare our prediction with the ground truth and then\nperform the back propagation.",
    "start": "2542190",
    "end": "2549059"
  },
  {
    "text": "So this is very standard,\nwe have seen this in homogeneous graph as well.",
    "start": "2549060",
    "end": "2555089"
  },
  {
    "text": "What becomes more\nlike a complicated is for link prediction.",
    "start": "2555090",
    "end": "2560290"
  },
  {
    "text": "So recall that for\nlink prediction itself is already complex\nfor homogeneous graph.",
    "start": "2560290",
    "end": "2566170"
  },
  {
    "text": "So it will be even more complex\nfor heterogeneous graph. So we talk about to\nperform link prediction,",
    "start": "2566170",
    "end": "2572370"
  },
  {
    "text": "we really need to\nsplit the graph into four categories of edges. There are the\ntraining message edges",
    "start": "2572370",
    "end": "2580170"
  },
  {
    "text": "that are used to compute the\nembedding during training time. We then have additional\ntraining supervision edges",
    "start": "2580170",
    "end": "2586890"
  },
  {
    "text": "that want to generate the\nobjective for training. We then have a validation\nedge, and test edge",
    "start": "2586890",
    "end": "2592860"
  },
  {
    "text": "that are used for validation\nand test set as well. So there are four categories\nof edges for prediction.",
    "start": "2592860",
    "end": "2599700"
  },
  {
    "text": "And then in this\nheterogeneous graph scenario, we then have a-- for\neach relation type,",
    "start": "2599700",
    "end": "2608069"
  },
  {
    "text": "we have this four\ncategories of edges. So you can see that there are--",
    "start": "2608070",
    "end": "2613230"
  },
  {
    "text": "for each relation type,\nwe have four set of edges, and they are associated\ntogether with their edge type.",
    "start": "2613230",
    "end": "2620670"
  },
  {
    "text": " Question? Do we always randomly split\nthe edges into message edge",
    "start": "2620670",
    "end": "2629150"
  },
  {
    "text": "or it depends on the\nprediction task itself? Yeah, good question.",
    "start": "2629150",
    "end": "2634820"
  },
  {
    "text": "How to split? Indeed, in most cases, we\nassume it to be randomly split. But suppose you have\na prior knowledge",
    "start": "2634820",
    "end": "2642470"
  },
  {
    "text": "about how to split edges,\nyou may want to do so. For example, let's\nsay we have a one",
    "start": "2642470",
    "end": "2648710"
  },
  {
    "text": "to examine out of\ndistribution generation capability for a given model.",
    "start": "2648710",
    "end": "2655130"
  },
  {
    "text": "Then we may want\nto manually select some out of distribution samples\nas the test set or validation",
    "start": "2655130",
    "end": "2662190"
  },
  {
    "text": "set. But in most cases, we\njust randomly split. ",
    "start": "2662190",
    "end": "2667200"
  },
  {
    "text": "Question? With the basis\nlearning approach, it seems like you\nwould really need",
    "start": "2667200",
    "end": "2672630"
  },
  {
    "text": "to have a lot of\ndifferent types of edges for that to make sense,\nbecause you're going to-- I mean, the basis needs\nto be a certain size",
    "start": "2672630",
    "end": "2678630"
  },
  {
    "text": "or it's not going to be useful. And I can't really think\nof real world graphs that would have many, many\ndifferent types of edges",
    "start": "2678630",
    "end": "2685109"
  },
  {
    "text": "like that. So I was wondering if you\ncould give an example. Yeah, good point.",
    "start": "2685110",
    "end": "2690180"
  },
  {
    "text": "So earlier, we\nhave some examples of heterogeneous graph. ",
    "start": "2690180",
    "end": "2695250"
  },
  {
    "text": "Suppose, we only have two\nnode type, edge types, there are eight relation types. And suppose we have even 10\nnode types and 10 edge types,",
    "start": "2695250",
    "end": "2702390"
  },
  {
    "text": "then it could be 1,000\ndifferent relation types. So that's one way\nto understand-- there could be potentially\na lot of relation types.",
    "start": "2702390",
    "end": "2710230"
  },
  {
    "text": "And another good\nexample in practice is that suppose we have\nheterogeneous information",
    "start": "2710230",
    "end": "2717300"
  },
  {
    "text": "across different\ndomains and we still want to use one giant graph\nto capture everything we know.",
    "start": "2717300",
    "end": "2723750"
  },
  {
    "text": "So we talk about this biomedical\nlike, knowledge graph. There are tons of\ndifferent drugs,",
    "start": "2723750",
    "end": "2731250"
  },
  {
    "text": "and different patients,\ndifferent molecules. In that case, you\ncan easily define",
    "start": "2731250",
    "end": "2737430"
  },
  {
    "text": "a lot of types of nodes\nand types of edges in the application. But even in those examples,\nnot every edge type",
    "start": "2737430",
    "end": "2745470"
  },
  {
    "text": "goes with every\nnode type, right? So it doesn't really seem like\nit's actually combinatorial",
    "start": "2745470",
    "end": "2751410"
  },
  {
    "text": "the way that you described. It seems like it's\nreally more like linear in the number of edge types\nfor a lot of these graphs.",
    "start": "2751410",
    "end": "2757390"
  },
  {
    "text": "Yeah, that is also fair. I think as I also mentioned,\nsome of the literature,",
    "start": "2757390",
    "end": "2763260"
  },
  {
    "text": "they do not consider\nthis relation type, for the same reason\nyou have described. Because a lot of\nreal world cases,",
    "start": "2763260",
    "end": "2769350"
  },
  {
    "text": "it's not really combinatorial. The edge type already clearly\ndefined the relation type.",
    "start": "2769350",
    "end": "2774599"
  },
  {
    "text": "But still, like a\nfirst in some cases, there could still\nbe combinatorial,",
    "start": "2774600",
    "end": "2779910"
  },
  {
    "text": "and in other cases,\nyou can still define tons of different\nrelation types. So these are some\nreasons we still",
    "start": "2779910",
    "end": "2786150"
  },
  {
    "text": "want to make the\ncomputation more tractable.",
    "start": "2786150",
    "end": "2791349"
  },
  {
    "text": "Yeah, but great discussions. So we talk about the\nformulation of link prediction for heterogeneous graph.",
    "start": "2791350",
    "end": "2798670"
  },
  {
    "text": "And let's see a\nconcrete example. So for example. We want to predict this missing\nlink from node E to node A,",
    "start": "2798670",
    "end": "2808180"
  },
  {
    "text": "and this is for particular\nedge type, a relation type r3.",
    "start": "2808180",
    "end": "2814630"
  },
  {
    "text": "So what we will\ndo is that we want to get the embedding\nfor node E and node A,",
    "start": "2814630",
    "end": "2820060"
  },
  {
    "text": "and then we will use this\nlike a linear transformation",
    "start": "2820060",
    "end": "2825280"
  },
  {
    "text": "to get the score for this\nparticular missing edge. So we want to\nmultiply this vector",
    "start": "2825280",
    "end": "2833410"
  },
  {
    "text": "with the trainable\nweight matrix, and then with another vector\nhA to get the prediction",
    "start": "2833410",
    "end": "2840640"
  },
  {
    "text": "for this missing edge. So this is one way to construct\nthe link prediction [INAUDIBLE]",
    "start": "2840640",
    "end": "2846940"
  },
  {
    "text": "for this heterogeneous graph. ",
    "start": "2846940",
    "end": "2852030"
  },
  {
    "text": "And then we want to outline\nthe specific training and validation steps.",
    "start": "2852030",
    "end": "2857490"
  },
  {
    "text": "Suppose we want to\nperform link prediction on heterogeneous graph. First, as we talked\nabout, we can",
    "start": "2857490",
    "end": "2864779"
  },
  {
    "text": "score all the potential\nsupervision edges in the network. We talk about this\nfrom E r3 to A,",
    "start": "2864780",
    "end": "2872580"
  },
  {
    "text": "is one particular\n[INAUDIBLE] for the score.",
    "start": "2872580",
    "end": "2877920"
  },
  {
    "text": "And we can use the\nsame idea to score like a [INAUDIBLE] supervision\nedges in the network.",
    "start": "2877920",
    "end": "2885339"
  },
  {
    "text": "And the second step is to\nperform the negative sampling. So we didn't dive into details\nabout negative sampling in link",
    "start": "2885340",
    "end": "2894660"
  },
  {
    "text": "prediction earlier. It is a good time\nto discuss it now. So when we want to\nmake link prediction,",
    "start": "2894660",
    "end": "2902850"
  },
  {
    "text": "besides this so-called\nlike a positive edges, because we know\nthat there should be a link between\nthis pair of node.",
    "start": "2902850",
    "end": "2908460"
  },
  {
    "text": "We should also additionally\nconsider the negative edges. Otherwise, like\nthe classification",
    "start": "2908460",
    "end": "2914440"
  },
  {
    "text": "is like not well\ndefined, we should both have positive examples\nand negative examples",
    "start": "2914440",
    "end": "2920890"
  },
  {
    "text": "when we define a machine\nlearning problem. And how do we generate\nthis negative edges?",
    "start": "2920890",
    "end": "2926110"
  },
  {
    "text": "One common way is to make the\ncorruption of a ground truth",
    "start": "2926110",
    "end": "2931420"
  },
  {
    "text": "positive edge. What I mean is that,\nfor example, we know there's the ground truth\nconnectivity between E and B.",
    "start": "2931420",
    "end": "2942865"
  },
  {
    "text": "We could-- sorry-- E and A, and\nthen we can consider corrupt the tail of this tuple\nto swap A with node B and D.",
    "start": "2942865",
    "end": "2953680"
  },
  {
    "text": "And you can see that node B and\nE and D and E. These two edges",
    "start": "2953680",
    "end": "2960880"
  },
  {
    "text": "are not existed in the network. So they are not\nexisting networks,",
    "start": "2960880",
    "end": "2966910"
  },
  {
    "text": "so we treat them as\nnegative examples. So we label this potential\npair of nodes as negative.",
    "start": "2966910",
    "end": "2973310"
  },
  {
    "text": "So this is the idea\nof next sampling. So given a positive\nedge that we know, we want to corrupt it to\nsome non-existent edges.",
    "start": "2973310",
    "end": "2982660"
  },
  {
    "text": "And then this way, we can\nget both positive examples and negative examples,\nand that can finish",
    "start": "2982660",
    "end": "2988750"
  },
  {
    "text": "the setup of link prediction. ",
    "start": "2988750",
    "end": "2994609"
  },
  {
    "text": "And then we will also\nuse the RGCN model to score this negative edges.",
    "start": "2994610",
    "end": "3000150"
  },
  {
    "text": "And how do we train the model? Well, we will use the same\nstandard binary cross entropy",
    "start": "3000150",
    "end": "3005580"
  },
  {
    "text": "loss that we have also discussed\nearlier in the lecture. And our motivation\nis that we want to maximize the score of this\ntraining supervision edges",
    "start": "3005580",
    "end": "3014580"
  },
  {
    "text": "that are positive,\nand then minimize the score of the negative edges\nthat want to minimize score",
    "start": "3014580",
    "end": "3021240"
  },
  {
    "text": "for the negative edges. And this is kind\nof a loss function we want to optimize with. Question?",
    "start": "3021240",
    "end": "3026460"
  },
  {
    "text": "For the previous slide,\nso the negative edges should not belong\nto the training",
    "start": "3026460",
    "end": "3031500"
  },
  {
    "text": "edges or the supervision edges. What happens if you have a\nreally densely connected graph, and that you can't do that\nbecause all the nodes, all",
    "start": "3031500",
    "end": "3041820"
  },
  {
    "text": "the edges [INAUDIBLE]. Yeah, good point. Indeed, this is a good\nhypothetical example.",
    "start": "3041820",
    "end": "3047770"
  },
  {
    "text": "Suppose the graph is\nalready densely connected. I think in that case, actually,\nthe link prediction problem is",
    "start": "3047770",
    "end": "3055930"
  },
  {
    "text": "[? ill-defined. ?] Because if\nthe graph is already densely connected and there's\nno possibility of adding",
    "start": "3055930",
    "end": "3061750"
  },
  {
    "text": "additional edges,\nthen basically, there's no way to\ninfer additional links",
    "start": "3061750",
    "end": "3067318"
  },
  {
    "text": "because it's already\nfully connected. But it's a good example. So in that case,\nI think it is not",
    "start": "3067318",
    "end": "3074038"
  },
  {
    "text": "very meaningful to define\nlink prediction because graph is already densely connected. Yeah, but good question.",
    "start": "3074038",
    "end": "3080260"
  },
  {
    "text": "Question? So are we using negative\nsampling [INAUDIBLE]?? ",
    "start": "3080260",
    "end": "3091200"
  },
  {
    "text": "I see. So the question is,\nhow to understand negative sampling and\nthis negative edges,",
    "start": "3091200",
    "end": "3097340"
  },
  {
    "text": "is this the question? Yeah. So that's a good point. So actually, I\nwouldn't think this two",
    "start": "3097340",
    "end": "3106430"
  },
  {
    "text": "notions are very correlated. So here the idea of\nnegative sampling,",
    "start": "3106430",
    "end": "3113029"
  },
  {
    "text": "the negative edges is\njust to manually construct some of the edges that does\nnot exist in the network.",
    "start": "3113030",
    "end": "3119839"
  },
  {
    "text": "I think for negative sampling\nis like a more general strategy for training like, a binary\nclassification task, where",
    "start": "3119840",
    "end": "3127339"
  },
  {
    "text": "there are tons of\nnegative examples, and we want to sample some\nof them during the training.",
    "start": "3127340",
    "end": "3132660"
  },
  {
    "text": "So how do we choose this\nnegative edge when we are doing [INAUDIBLE] how\ndo we choose that?",
    "start": "3132660",
    "end": "3139700"
  },
  {
    "text": "Yeah, so like I said,\nwe want to corrupt. Like a given the ground\ntruth a positive edge,",
    "start": "3139700",
    "end": "3146960"
  },
  {
    "text": "we can corrupt one\nside of the edge, and this way we can\nget the negative edge. ",
    "start": "3146960",
    "end": "3156369"
  },
  {
    "text": "So we talk about having got the\npositive and negative edges. We can train the network to\noptimize this loss or binary",
    "start": "3156370",
    "end": "3164800"
  },
  {
    "text": "classification loss. And then at evaluation\ntime, we want to evaluate how well the\nmodel can rank the edges",
    "start": "3164800",
    "end": "3173170"
  },
  {
    "text": "with different relation types. So for example now,\nwe have a new edge to predict over, pointing from\nE to D, with the relation type",
    "start": "3173170",
    "end": "3183070"
  },
  {
    "text": "r3. So to make such\nprediction, our intuition is that the score\nof E, r3, D should",
    "start": "3183070",
    "end": "3192130"
  },
  {
    "text": "be higher than all the remaining\nlike, a negative edges that",
    "start": "3192130",
    "end": "3197799"
  },
  {
    "text": "are not in the training message\nedges and training supervision edges. So this is what we hope the\nmodel will be able to predict",
    "start": "3197800",
    "end": "3206710"
  },
  {
    "text": "in this evaluation stage. So this is a specific metric\nthat we want to a report.",
    "start": "3206710",
    "end": "3215240"
  },
  {
    "text": "Let's say in this\nvalidation time. So first we will calculate\nthe score of this edge",
    "start": "3215240",
    "end": "3220960"
  },
  {
    "text": "that we want to make the\nprediction, from E, r3 to D. And then we want to\ncalculate the score of all",
    "start": "3220960",
    "end": "3228190"
  },
  {
    "text": "the negative edges and use\nthe same method we have just talked about. So we want to correct one side\nof the edges, and in this way,",
    "start": "3228190",
    "end": "3236390"
  },
  {
    "text": "we can get negative edges. So this way, we can get a score\nfor all the negative edges",
    "start": "3236390",
    "end": "3243640"
  },
  {
    "text": "as well. And the third step is a\nmost important thing here is that we want to obtain the\nranking of the positive edge",
    "start": "3243640",
    "end": "3251500"
  },
  {
    "text": "over all the negative edges. So this way, we\nknow that the model can rank the positive edge as\nthe second among all the edges.",
    "start": "3251500",
    "end": "3261970"
  },
  {
    "text": "And finally, we can report\nsome ranking-based metrics like a Hits at k, which\nsays that did we correctly",
    "start": "3261970",
    "end": "3270950"
  },
  {
    "text": "rank the positive edge\nto be the first edge. And this reciprocal rank\ntells us the reciprocal",
    "start": "3270950",
    "end": "3278780"
  },
  {
    "text": "of the rank as well. So these are some\nstandard ranking metrics for this problem.",
    "start": "3278780",
    "end": "3284630"
  },
  {
    "text": "Question? Going back to two slides before\nthis one, just clarification",
    "start": "3284630",
    "end": "3291750"
  },
  {
    "text": "[INAUDIBLE]. The loss function\nright there that is [INAUDIBLE] using the\nscoring function for r3.",
    "start": "3291750",
    "end": "3296810"
  },
  {
    "text": "Do we need a summation\noutside to the minus log to sum over all\npossible relations?",
    "start": "3296810",
    "end": "3303280"
  },
  {
    "text": "Yeah, that's a great point. Yeah, I believe here we only\ntalk about one relation type. And you are right in\nthe sense, suppose",
    "start": "3303280",
    "end": "3309890"
  },
  {
    "text": "we want to get\nthe loss function, we need to sum over\nall the relation type.",
    "start": "3309890",
    "end": "3315260"
  },
  {
    "text": "Yeah. This is just for one\nparticular relation type. Yeah, good question. ",
    "start": "3315260",
    "end": "3323109"
  },
  {
    "text": "So now we have talk about how\nto evaluate a link prediction",
    "start": "3323110",
    "end": "3329020"
  },
  {
    "text": "problem for heterogeneous graph. So the purpose of all\nof this discussion is also helping you get\na goal over the idea",
    "start": "3329020",
    "end": "3337630"
  },
  {
    "text": "of link prediction again. And we talk about something\nwe haven't mentioned earlier about this ranking metrics.",
    "start": "3337630",
    "end": "3344020"
  },
  {
    "text": "And this is just for your\ninformation of understanding, so it's not like the most\nimportant part of this lecture.",
    "start": "3344020",
    "end": "3349690"
  },
  {
    "text": " And next, we're going to talk\nabout a specific benchmark",
    "start": "3349690",
    "end": "3355260"
  },
  {
    "text": "dataset as I motivated\nearlier that is widely used in the literature.",
    "start": "3355260",
    "end": "3361290"
  },
  {
    "text": "And you could potentially\nconsider your cross-product as well. So this is called\nMicrosoft Academic Graph.",
    "start": "3361290",
    "end": "3368190"
  },
  {
    "text": "It has almost around a\nmillion of paper nodes",
    "start": "3368190",
    "end": "3373740"
  },
  {
    "text": "and around million\nof author nodes. There are also institutions\nand fields of study nodes.",
    "start": "3373740",
    "end": "3379500"
  },
  {
    "text": "So now we see there\nare four different node types in this particular graph.",
    "start": "3379500",
    "end": "3385790"
  },
  {
    "text": "And then there are also\nfour directed relationships between these node types.",
    "start": "3385790",
    "end": "3391789"
  },
  {
    "text": "We have author \"affiliated with\"\nan institution, author \"writes\" a paper, and paper\n\"cite\" a paper,",
    "start": "3391790",
    "end": "3398210"
  },
  {
    "text": "and paper \"has a topic\nof\" field of study. So there are four\ndifferent edge type.",
    "start": "3398210",
    "end": "3403280"
  },
  {
    "text": " And the prediction\ntask here is to predict",
    "start": "3403280",
    "end": "3409790"
  },
  {
    "text": "the venue of a given paper. The features of different\nnodes are actually",
    "start": "3409790",
    "end": "3415640"
  },
  {
    "text": "generated from the\nword2vec feature vector. So it's a standard approach\nfor natural language processing",
    "start": "3415640",
    "end": "3422150"
  },
  {
    "text": "to get like an easy to compute-- encoding for a given\nsentence or paragraph.",
    "start": "3422150",
    "end": "3431450"
  },
  {
    "text": "And then given this feature,\nwe have four different types of node we want to predict,\nparticularly for the paper node",
    "start": "3431450",
    "end": "3440720"
  },
  {
    "text": "type, and predicting\nthe value of each paper. And it is regarded as a\n349-class classification,",
    "start": "3440720",
    "end": "3450769"
  },
  {
    "text": "because there are\nthis number of venues. Regarding the dataset\nsplit, I think",
    "start": "3450770",
    "end": "3456500"
  },
  {
    "text": "student has a great question\nhow to split dataset. In this particular case,\nwe do a time-based split.",
    "start": "3456500",
    "end": "3461869"
  },
  {
    "text": "So it is no longer\nrandom split, because we have this timestamp for all\nof these occurrence of nodes",
    "start": "3461870",
    "end": "3469550"
  },
  {
    "text": "and edges. So we want to respect that\ntime when we construct the virtual learning task.",
    "start": "3469550",
    "end": "3475290"
  },
  {
    "text": "So during training time, we will\nselect all the papers published between 2018 as training.",
    "start": "3475290",
    "end": "3481280"
  },
  {
    "text": "All the things happen\nafter that year, will be regarded as the test set.",
    "start": "3481280",
    "end": "3486330"
  },
  {
    "text": "So this is the machine learning\nsetup for this Microsoft",
    "start": "3486330",
    "end": "3491780"
  },
  {
    "text": "Academic Graph. So we can see some results\non this benchmarks.",
    "start": "3491780",
    "end": "3498369"
  },
  {
    "text": "You can actually log in\nto the website of OGB-- Open Graph Benchmark,\nto see more performance.",
    "start": "3498370",
    "end": "3506589"
  },
  {
    "text": "You see that RGCN can\ngenerate reasonable prediction for this task, achieving\nabout a 47% accuracy.",
    "start": "3506590",
    "end": "3515020"
  },
  {
    "text": "And then the state-of-art\nmethod is actually doing better, it's doing about a 59% accuracy.",
    "start": "3515020",
    "end": "3523390"
  },
  {
    "text": "And then the state-of-art\nmethod is actually a combination of complex\nand simplified GCN",
    "start": "3523390",
    "end": "3530650"
  },
  {
    "text": "will actually cover both\nmetrics in the later offerings of this course.",
    "start": "3530650",
    "end": "3536990"
  },
  {
    "text": "So the discussion here is\njust to give you an intuition, how people have applied this\nRGCN into a practical machine",
    "start": "3536990",
    "end": "3546550"
  },
  {
    "text": "learning benchmark, and how\nthis benchmark looks like. ",
    "start": "3546550",
    "end": "3552950"
  },
  {
    "text": "So to summarize, we\nhave talked about the major technical component\nof this lecture, which is RGCN.",
    "start": "3552950",
    "end": "3559660"
  },
  {
    "text": "The idea is that we can assign\ndifferent weight matrices for different\ntypes of relations.",
    "start": "3559660",
    "end": "3566800"
  },
  {
    "text": "And this way we can extend\nGCN to Relational GCN. And this method\nis pretty general,",
    "start": "3566800",
    "end": "3573650"
  },
  {
    "text": "we can apply this\nto all the tasks we have seen for\nhomogeneous graphs as well,",
    "start": "3573650",
    "end": "3579380"
  },
  {
    "text": "including node classification\nand link prediction. And this idea can be also\nextended to other types of GNN,",
    "start": "3579380",
    "end": "3586060"
  },
  {
    "text": "so we can apply the same idea to\nextend to RGraphSage, RGAT, et",
    "start": "3586060",
    "end": "3592910"
  },
  {
    "text": "cetera. And with particular, like I\nmentioned, the most widely used benchmark for\nheterogeneous graph,",
    "start": "3592910",
    "end": "3599410"
  },
  {
    "text": "and how it can be\nused in practice. ",
    "start": "3599410",
    "end": "3606990"
  },
  {
    "text": "So now we have\ntalked about RGCN, the most easier to understand\nand also widely use method.",
    "start": "3606990",
    "end": "3613330"
  },
  {
    "text": "Next, we're going\nto briefly talk about a recent method\ncalled heterogeneous graph",
    "start": "3613330",
    "end": "3618840"
  },
  {
    "text": "transformer. This is more for\nyou to understand the research in this\ndirection and see",
    "start": "3618840",
    "end": "3625380"
  },
  {
    "text": "what are the interesting\nideas to build heterogeneous.",
    "start": "3625380",
    "end": "3630900"
  },
  {
    "text": "So recall that we\nhave introduced the idea of Graph Attention\nNetworks for homogeneous graph.",
    "start": "3630900",
    "end": "3637500"
  },
  {
    "text": "And what is new or\ndifferent from GAT to GCN is this trainable\nattention weights.",
    "start": "3637500",
    "end": "3644460"
  },
  {
    "text": "So instead of always normalizing\nbased on the node degree, we have a trainable\nattention weights",
    "start": "3644460",
    "end": "3651080"
  },
  {
    "text": "computed from node\nembedding to let the model to weight different neighbors. So this is the idea of GAT.",
    "start": "3651080",
    "end": "3657740"
  },
  {
    "text": "And our question that GAT is\ndesigned for homogeneous graph, can we extend it for\nheterogeneous graphs?",
    "start": "3657740",
    "end": "3664760"
  },
  {
    "text": "So, of course, what we\nhave seen just now of RGCN,",
    "start": "3664760",
    "end": "3669860"
  },
  {
    "text": "this RGCN can be\nextended to RGAT as well. So we basically define\nN different like a GAT",
    "start": "3669860",
    "end": "3678500"
  },
  {
    "text": "models each for\none relation type, and we are then to\nextend the method.",
    "start": "3678500",
    "end": "3684090"
  },
  {
    "text": "But this approach is\nactually very expensive, because as you can recall,\nthe competition for attention",
    "start": "3684090",
    "end": "3691290"
  },
  {
    "text": "is already very expensive. So we have a separate branches\nof computing attention weights,",
    "start": "3691290",
    "end": "3698250"
  },
  {
    "text": "and then attention\nweights it usually is so-called multi-head attention. So we have to duplicate\nthe weights for N times--",
    "start": "3698250",
    "end": "3705000"
  },
  {
    "text": "k times, and then suppose\nwe additional duplicate for each of the relation\ntype is simply too expensive.",
    "start": "3705000",
    "end": "3711850"
  },
  {
    "text": "So the question that, can we\ntry to reduce the cost for just",
    "start": "3711850",
    "end": "3718020"
  },
  {
    "text": "for heterogeneous\ngraph attention? Another background that\nwe want to cover here",
    "start": "3718020",
    "end": "3725830"
  },
  {
    "text": "is about a so-called Scaled\nDot-Product Attention.",
    "start": "3725830",
    "end": "3730930"
  },
  {
    "text": "And this is essentially\nthe attention mechanism that we used in the famous\ntransformer architecture.",
    "start": "3730930",
    "end": "3738380"
  },
  {
    "text": "So what we do here is that to\ncompute the attention versus--",
    "start": "3738380",
    "end": "3743500"
  },
  {
    "text": "with respect to query-- Q, key, K, and value V, we want\nto define this so-called Scaled",
    "start": "3743500",
    "end": "3752260"
  },
  {
    "text": "Dot-Product. So we want to perform a\nDot-Product between the K and the Values. And then scale it with the\nsquare root of the dimension,",
    "start": "3752260",
    "end": "3760990"
  },
  {
    "text": "and then use that to\nweight the Values V. So this is a rough idea\nof Scaled Dot-Product.",
    "start": "3760990",
    "end": "3769299"
  },
  {
    "text": "And then how do we\nobtain this Q, K, V? So we don't have\nlinear raw input data.",
    "start": "3769300",
    "end": "3776299"
  },
  {
    "text": "So usually what people do\nis to apply linear layer to transform the same input\nto different matrices--",
    "start": "3776300",
    "end": "3785570"
  },
  {
    "text": "Q, K, V. So we have the\nsame input X to the network.",
    "start": "3785570",
    "end": "3791270"
  },
  {
    "text": "And then we will apply three\ndifferent types of linear layer or transformation that\ncan project this X,",
    "start": "3791270",
    "end": "3799310"
  },
  {
    "text": "either to Q, to K,\nor to V. So this way we can get the three component\nwe need in this Scaled",
    "start": "3799310",
    "end": "3808910"
  },
  {
    "text": "Dot-Product Attention.  So now, let's discuss\nhow we can extend GAT",
    "start": "3808910",
    "end": "3818750"
  },
  {
    "text": "to heterogeneous graph. We can see this-- we'll rephrase what we\nhave for the GAT network.",
    "start": "3818750",
    "end": "3827130"
  },
  {
    "text": "So we have the message\nfunction, compute from each of the neighbors. We have a attention score,\nthat score tells us which",
    "start": "3827130",
    "end": "3837080"
  },
  {
    "text": "message is more important. This attention score is also\ncomputed by a neural network. And after scale the messages,\nwill perform an aggregation",
    "start": "3837080",
    "end": "3846200"
  },
  {
    "text": "to get the final embedding. So this is the idea\nof Standard GAT.",
    "start": "3846200",
    "end": "3851810"
  },
  {
    "text": "And our key question\nwe want to answer here is that, how can we\nmake this attention",
    "start": "3851810",
    "end": "3857480"
  },
  {
    "text": "to be specific to\nthe relation type? And the relation\ntype as we know, have a tuple of node type--\nedge type and node type",
    "start": "3857480",
    "end": "3866180"
  },
  {
    "text": "into this attention computation. So this is the\nkey module we want",
    "start": "3866180",
    "end": "3873230"
  },
  {
    "text": "to define for heterogeneous\ngraph transformer. So this is the idea behind\nthe HGT Heterogeneous Graph",
    "start": "3873230",
    "end": "3884980"
  },
  {
    "text": "Transformer. We talk about the\nidea of projecting the input with a Q-Linear to the\nQuery, and K-Linear to the key.",
    "start": "3884980",
    "end": "3896720"
  },
  {
    "text": "So in this idea of GAT, we\nwant to decompose the tuple",
    "start": "3896720",
    "end": "3902470"
  },
  {
    "text": "and try to project different\ncomponents of this relation",
    "start": "3902470",
    "end": "3909190"
  },
  {
    "text": "type-- node type, edge\ntype-- node type is tuple with different\nprojections.",
    "start": "3909190",
    "end": "3914500"
  },
  {
    "text": "And the purpose of\ndoing so, is that we want to reduce the number of\nweight matrix we can use here.",
    "start": "3914500",
    "end": "3922310"
  },
  {
    "text": "So in this particular\nexample, we have author node and paper node.",
    "start": "3922310",
    "end": "3928030"
  },
  {
    "text": "Two types of nodes. And right-hand side,\nso two types of edges,",
    "start": "3928030",
    "end": "3935200"
  },
  {
    "text": "we have three different\nweight matrices that are used for the query\npaper, key paper and node.",
    "start": "3935200",
    "end": "3943579"
  },
  {
    "text": "K Author weight matrices. And then we have two\nedge weight matrices,",
    "start": "3943580",
    "end": "3948590"
  },
  {
    "text": "one for the side\nrelationship, and one for the right relationship.",
    "start": "3948590",
    "end": "3953960"
  },
  {
    "text": "So altogether, we have five\ndifferent weight matrices. So suppose we do not\nhave this decomposition.",
    "start": "3953960",
    "end": "3961830"
  },
  {
    "text": "So suppose we do not break\ndown this relation type into node edge and node type.",
    "start": "3961830",
    "end": "3969500"
  },
  {
    "text": "In theory, we could have\n3 by 2 times 2 times 3, 18 number of different\nrelation types, because we have",
    "start": "3969500",
    "end": "3980030"
  },
  {
    "text": "three node types, two edge\ntypes, and three node types, this number of weight matrices.",
    "start": "3980030",
    "end": "3985530"
  },
  {
    "text": "So really the idea\nof [INAUDIBLE] is to decompose\nthe tuple and model",
    "start": "3985530",
    "end": "3992809"
  },
  {
    "text": "like each component of this\nnode edge node relation type separately.",
    "start": "3992810",
    "end": "3998059"
  },
  {
    "text": "And this way, we can save\nthe number of weight matrices we can use here. ",
    "start": "3998060",
    "end": "4004599"
  },
  {
    "text": "This is also like a glimpse of\nthe exact formulation of HGT. It's also not the main\nfocus of this lecture.",
    "start": "4004600",
    "end": "4012580"
  },
  {
    "text": "But just for you to understand\nwhat people can do in practice. So we talk about this K-linear\nand Q-linear, which basically",
    "start": "4012580",
    "end": "4022210"
  },
  {
    "text": "construct the K matrix and\nQ matrix that we talk about in this transformer\nattention network.",
    "start": "4022210",
    "end": "4030580"
  },
  {
    "text": "And then after\ngetting this Q and K, we then perform this\nso-called Scaled Dot-Product.",
    "start": "4030580",
    "end": "4038480"
  },
  {
    "text": "So we make a Dot-Product\nbetween the Query and the Key. But because we also\nadditionally have the edge type",
    "start": "4038480",
    "end": "4045970"
  },
  {
    "text": "between a pair of nodes, so\nthere's a third trainable weight for each edge type,\nwhich W for edge type",
    "start": "4045970",
    "end": "4055569"
  },
  {
    "text": "E. And this way, we can\nget the attention score that we have seen earlier, also\nin the standard transformer",
    "start": "4055570",
    "end": "4064309"
  },
  {
    "text": "attention. So this is kind\nof the idea of HGT in terms of computing the\nattention weights but then",
    "start": "4064310",
    "end": "4072740"
  },
  {
    "text": "with respect to\nthe relation type.  And then a full HGT\nlayer looks like this.",
    "start": "4072740",
    "end": "4081070"
  },
  {
    "text": "So we talk about we have\nthe attention weight to weight different messages.",
    "start": "4081070",
    "end": "4087400"
  },
  {
    "text": "And we have just computed\nhow to score given message",
    "start": "4087400",
    "end": "4092970"
  },
  {
    "text": "based on the relation\ntype, we have seen this. Similarly, we can compute\nthe message with respect",
    "start": "4092970",
    "end": "4099659"
  },
  {
    "text": "to different relation type. And here we also\nfollow the similar idea of decomposing the weights\nfor a node and edge types.",
    "start": "4099660",
    "end": "4108339"
  },
  {
    "text": "So to compute a\ngiven message, we have the weight\nfor each node type.",
    "start": "4108340",
    "end": "4114359"
  },
  {
    "text": "So given a node, we\nwill get its node type and then apply a\nmessage transformation",
    "start": "4114359",
    "end": "4120778"
  },
  {
    "text": "for this particular node type. And then we will\nmultiply this node type",
    "start": "4120779",
    "end": "4126899"
  },
  {
    "text": "like messages with a weight\nmatrix for each edge type. So you see that instead of we\nmodel for this each particular",
    "start": "4126899",
    "end": "4137109"
  },
  {
    "text": "relation type, so we have\nthe number of relation type of number of\nweights, we now",
    "start": "4137109",
    "end": "4142479"
  },
  {
    "text": "decompose into the\nweights for node type and the weights for each type. So now we have summation of\nnode number of node types",
    "start": "4142479",
    "end": "4150310"
  },
  {
    "text": "and number of edge types. These number of weight matrices. So we reduce the\nnumber of weight",
    "start": "4150310",
    "end": "4155500"
  },
  {
    "text": "matrices we want to use here. There's a question? Just a question\nabout your patient.",
    "start": "4155500",
    "end": "4160710"
  },
  {
    "text": "Can you explain what the\nsymbol circle with the cross is please?",
    "start": "4160710",
    "end": "4165990"
  },
  {
    "text": "You mean this one? Oh, no, I'm sorry, the very top. Oh, this one?",
    "start": "4165990",
    "end": "4171278"
  },
  {
    "text": "Yeah, that's a good question. I assume this\nshould be summation,",
    "start": "4171279",
    "end": "4177399"
  },
  {
    "text": "but I need to\ncheck this as well. But my understanding\nthis should be",
    "start": "4177399",
    "end": "4182410"
  },
  {
    "text": "something similar to\nsummation, because we have get the weighted message.",
    "start": "4182410",
    "end": "4188109"
  },
  {
    "text": "And we want to sum over the\nneighbors of a given node. So it's most likely\nto be a summation.",
    "start": "4188109",
    "end": "4197560"
  },
  {
    "text": "Question? [INAUDIBLE]\naggregation function? ",
    "start": "4197560",
    "end": "4203550"
  },
  {
    "text": "Oh, yeah. That's exactly what-- so\nsummation is just one option.",
    "start": "4203550",
    "end": "4208620"
  },
  {
    "text": "This notation means any\npossible aggregation function. Yeah. Thanks for it.",
    "start": "4208620",
    "end": "4214920"
  },
  {
    "text": "Question? Can you explain why just\nthe attention weights aren't",
    "start": "4214920",
    "end": "4221040"
  },
  {
    "text": "enough to distinguish-- like the attention\nis in different ways for different pairs.",
    "start": "4221040",
    "end": "4227340"
  },
  {
    "text": "Wouldn't that be enough to\ncapture a different relation types? Yeah, that's a great point.",
    "start": "4227340",
    "end": "4232929"
  },
  {
    "text": "So I think to motivate,\nthis can be interpreted as the motivation of GAT.",
    "start": "4232930",
    "end": "4238590"
  },
  {
    "text": "The whole purpose of\nGAT that extend GCN is to introduce a\ntrainable attention weights for different messages.",
    "start": "4238590",
    "end": "4245440"
  },
  {
    "text": "But still we have to\ncompute the messages. For example, we have also\nknown the paper nodes,",
    "start": "4245440",
    "end": "4251640"
  },
  {
    "text": "we want to construct\nseparate messages for each author and each paper. So we just additionally\nlearn attention weight",
    "start": "4251640",
    "end": "4259260"
  },
  {
    "text": "to score, these\nmessages, but still we want to differentiate these\ntwo types of messages. So suppose we do not consider\ntypes for these messages,",
    "start": "4259260",
    "end": "4268310"
  },
  {
    "text": "then we lose a\nlot of information by sharing the\nweights across types. But that's a great question.",
    "start": "4268310",
    "end": "4274450"
  },
  {
    "text": "Yeah. So we have finished\nthe discussion",
    "start": "4274450",
    "end": "4282610"
  },
  {
    "text": "of HGT, which is a widely used\nattention benchmark method",
    "start": "4282610",
    "end": "4289449"
  },
  {
    "text": "for heterogeneous graphs. We can also take\na look at how HGT performance on this Microsoft\nAcademic Graph dataset.",
    "start": "4289450",
    "end": "4298239"
  },
  {
    "text": "So very interestingly,\nwe find that HGT use much fewer\nparameters, and this",
    "start": "4298240",
    "end": "4303909"
  },
  {
    "text": "is as expected because now\nwe have decomposed the weight matrix of weights to each\nnode type and each edge type.",
    "start": "4303910",
    "end": "4310480"
  },
  {
    "text": "So it saves a lot of\nparameter compare using RGCN,",
    "start": "4310480",
    "end": "4315700"
  },
  {
    "text": "it almost reduced by\nan order of magnitude.",
    "start": "4315700",
    "end": "4321370"
  },
  {
    "text": "And the meantime, the\nperformance better than RGCN. So this is an\nillustration why HGT",
    "start": "4321370",
    "end": "4329550"
  },
  {
    "text": "may be more desirable in\nreal world applications. ",
    "start": "4329550",
    "end": "4334930"
  },
  {
    "text": "So in the remaining\nof this lecture, I just want to\nbriefly discuss how we can extend what\nwe have learned",
    "start": "4334930",
    "end": "4340469"
  },
  {
    "text": "from the design space of GN\nto this heterogeneous graph scenarios.",
    "start": "4340470",
    "end": "4346060"
  },
  {
    "text": "So remember we talked about\nthis five components that outline the general perspective\nof g for homogeneous graph.",
    "start": "4346060",
    "end": "4353460"
  },
  {
    "text": "And our question is, can\nwe extend this framework to heterogeneous graph as well?",
    "start": "4353460",
    "end": "4360070"
  },
  {
    "text": "So recall that the first\ncomponent we talk about is the message\ncomputation, like compute",
    "start": "4360070",
    "end": "4366420"
  },
  {
    "text": "the message from each of the\nneighbors of a given node. In the case of\nheterogeneous graph,",
    "start": "4366420",
    "end": "4373740"
  },
  {
    "text": "we talk about this\nidea of defining like one particular message\nfunction for each relation",
    "start": "4373740",
    "end": "4382230"
  },
  {
    "text": "type. So now the message function\nwill have a subscript of r that represents\none specific function",
    "start": "4382230",
    "end": "4392610"
  },
  {
    "text": "for each basically\nrelation type. And this discussion\nhere is useful",
    "start": "4392610",
    "end": "4397719"
  },
  {
    "text": "because we talk about we\ncan model this message function arbitrarily. So in RGCN we talk about\njust a linear layer",
    "start": "4397720",
    "end": "4405430"
  },
  {
    "text": "as the message function. In practice, this\nmessage function can also be very complex, can\neven be like a two layer MLP",
    "start": "4405430",
    "end": "4412420"
  },
  {
    "text": "or even more complex. So we can but we can still\nfollow the same idea. So we define a different\nmessage function",
    "start": "4412420",
    "end": "4418510"
  },
  {
    "text": "for different relation type. And then we talk\nabout the formulation",
    "start": "4418510",
    "end": "4423760"
  },
  {
    "text": "of aggregation, that aggregate\nthe messages of a given node.",
    "start": "4423760",
    "end": "4429170"
  },
  {
    "text": "And in the language of\nheterogeneous graph, now the aggregation will\nbe a two stage process.",
    "start": "4429170",
    "end": "4435520"
  },
  {
    "text": "We also briefly\ntouched it in RGCN. So here are the two\nstages, the first stage",
    "start": "4435520",
    "end": "4442540"
  },
  {
    "text": "of aggregation will\naggregate the message within each relation type. Because for example, for\na given relation type",
    "start": "4442540",
    "end": "4450860"
  },
  {
    "text": "we may have different\nmembers that belongs to this relation type. And having aggregated\nover the relation type,",
    "start": "4450860",
    "end": "4458060"
  },
  {
    "text": "we may want to additionally\naggregate over all the relation types because now we\nhave information obtained",
    "start": "4458060",
    "end": "4466060"
  },
  {
    "text": "from each relation type. And one particular\nexample I would recommend",
    "start": "4466060",
    "end": "4471940"
  },
  {
    "text": "you can consider to use is\nthat in the first stage, we can use the sum aggregation\nover the members of a given",
    "start": "4471940",
    "end": "4478750"
  },
  {
    "text": "relation type. We talk about sum aggregation\nis the most theoretically expressive method in this\ntheory of GNN lecture.",
    "start": "4478750",
    "end": "4486380"
  },
  {
    "text": "So we can first take the\nsummation for each relation type. And then we can\ntake a concatenation",
    "start": "4486380",
    "end": "4492550"
  },
  {
    "text": "across the relation type. The purpose of\nusing concatenation is that, now we do\nnot have to consider",
    "start": "4492550",
    "end": "4500260"
  },
  {
    "text": "the permutation\ninvariant property. Because let's say we have\ndefined five different relation type, they are clearly defined.",
    "start": "4500260",
    "end": "4507440"
  },
  {
    "text": "So this five relation\ntypes are explicit and we do not have to\nconsider the ordering here.",
    "start": "4507440",
    "end": "4513760"
  },
  {
    "text": "So concatenation is\nthe most expressive way that we can keep everything\nwe have learned for this five",
    "start": "4513760",
    "end": "4519610"
  },
  {
    "text": "relation type. So the second aggregation\ncould be the concat function.",
    "start": "4519610",
    "end": "4524800"
  },
  {
    "text": "And we talk about\nthe connectivities between GNN layers,\nincluding adding",
    "start": "4524800",
    "end": "4530260"
  },
  {
    "text": "the pre-process layer,\npost-processing, and skip connections.",
    "start": "4530260",
    "end": "4535430"
  },
  {
    "text": "And for heterogeneous\nGNN we can basically keep the same design for\nthe homogeneous graph.",
    "start": "4535430",
    "end": "4543400"
  },
  {
    "text": "The only thing we\ncan discuss is that for those pre-process layer\nand post-process layer,",
    "start": "4543400",
    "end": "4550090"
  },
  {
    "text": "we have this\nso-called MLP layers. And now this MLP layers\nshould be with respect",
    "start": "4550090",
    "end": "4555160"
  },
  {
    "text": "to each node type. The reason is that the\noutput of any GNN layer",
    "start": "4555160",
    "end": "4560440"
  },
  {
    "text": "are node embeddings. And because we have potentially\nmultiple node types,",
    "start": "4560440",
    "end": "4565870"
  },
  {
    "text": "we want to separately\ntransform the embeddings of nodes that belongs\nto different node types.",
    "start": "4565870",
    "end": "4572720"
  },
  {
    "text": "So now the MLP here should\nalso be type cost sensitive.",
    "start": "4572720",
    "end": "4579070"
  },
  {
    "text": "So this is like\nhow we can extend this pre-process and\npost-process layers for general heterogeneous GNN.",
    "start": "4579070",
    "end": "4588440"
  },
  {
    "text": "And lastly, we'll talk\nabout different ways of augmenting the\ngraphs, like we talked about how to\nadd a feature for nodes",
    "start": "4588440",
    "end": "4595700"
  },
  {
    "text": "and add a structural information\nfor heterogeneous graphs. And most of them are\nstayed unchanged,",
    "start": "4595700",
    "end": "4603619"
  },
  {
    "text": "except that we want to discuss\ntwo common options when we want to generalize the\napproach from homogeneous graph",
    "start": "4603620",
    "end": "4609830"
  },
  {
    "text": "to heterogeneous graph. So there are\nbasically two ideas. The first idea is that we\nwant to compute the statistics",
    "start": "4609830",
    "end": "4617210"
  },
  {
    "text": "within each relation type. So we talk about the analogy\nof a heterogeneous graph can be regarded as [? N ?]\ndifferent separate graphs,",
    "start": "4617210",
    "end": "4624500"
  },
  {
    "text": "so we can compute the\nstatistics or perform the subgraph sampling for\neach of these relation type.",
    "start": "4624500",
    "end": "4631699"
  },
  {
    "text": "And another approach\nis basically we just ignore the relation type. So we treat the heterogeneous\ngraph as a homogeneous graph",
    "start": "4631700",
    "end": "4640190"
  },
  {
    "text": "without any type\ninformation, and then we can compute the graph\nstatistics or perform sampling",
    "start": "4640190",
    "end": "4647500"
  },
  {
    "text": "over the entire network. So finally regarding\ndifferent prediction types,",
    "start": "4647500",
    "end": "4654400"
  },
  {
    "text": "we have visited node, edge\nand graph-level predictions for homogeneous graph. And similarly for\nheterogeneous graphs,",
    "start": "4654400",
    "end": "4661330"
  },
  {
    "text": "we just need to consider\nthis relation type r for this different\nprediction types. ",
    "start": "4661330",
    "end": "4669250"
  },
  {
    "text": "And so now we have seen that\nwe can extend the idea of GNN from homogeneous graph\nto heterogeneous graph,",
    "start": "4669250",
    "end": "4676750"
  },
  {
    "text": "and all we need is to properly\nconsider this node and relation type and have some additional\none layer of aggregation",
    "start": "4676750",
    "end": "4682960"
  },
  {
    "text": "over the relation type. And that is all we need\nto make such extension.",
    "start": "4682960",
    "end": "4688300"
  },
  {
    "text": "So to summarize\ntoday, we have talked about how to apply GNN\nto heterogeneous graph. And the key concept\nyou can take away",
    "start": "4688300",
    "end": "4696520"
  },
  {
    "text": "is this concept of relation type\nfrom the starting node, edge, and end node that describe\nall the complex relationships",
    "start": "4696520",
    "end": "4703870"
  },
  {
    "text": "in heterogeneous graph. And we talk about\nthe idea of learning from heterogeneous graph\nusing the same idea of GNN,",
    "start": "4703870",
    "end": "4709750"
  },
  {
    "text": "we have seen earlier. And the key idea is that\nwe want to separately model each relation type with GNN.",
    "start": "4709750",
    "end": "4716600"
  },
  {
    "text": "And the most important\npart of this lecture is Relational GCN that extend\nGCN to relational graph.",
    "start": "4716600",
    "end": "4723640"
  },
  {
    "text": "And that's it for today. ",
    "start": "4723640",
    "end": "4731000"
  }
]
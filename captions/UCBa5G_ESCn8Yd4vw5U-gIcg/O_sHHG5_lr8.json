[
  {
    "start": "0",
    "end": "66000"
  },
  {
    "text": "hello my name is dennis allison i'm organizing and uh curating the uh stanford university",
    "start": "11679",
    "end": "19039"
  },
  {
    "text": "uh computer systems colloquium ee 380. this talk was",
    "start": "19039",
    "end": "25279"
  },
  {
    "text": "presented in spring 2020 for that colloquium our speaker today is",
    "start": "25279",
    "end": "33680"
  },
  {
    "text": "francois holm he is at facebook research in paris and is going to explain to us the use of",
    "start": "33680",
    "end": "41440"
  },
  {
    "text": "deep learning for symbolic mathematics francois welcome thank you",
    "start": "41440",
    "end": "49120"
  },
  {
    "text": "hello so i'm francois i'm a researcher in facebook ai research in paris",
    "start": "49120",
    "end": "54640"
  },
  {
    "text": "and i'm going to present a paper that was written with guillaume lamp also from facebook ai research in paris titled deep",
    "start": "54640",
    "end": "62719"
  },
  {
    "text": "learning for symbolic mathematics so in a few words what are we doing",
    "start": "62719",
    "end": "70880"
  },
  {
    "start": "66000",
    "end": "147000"
  },
  {
    "text": "we are investigating the possible use of natural language processing techniques",
    "start": "70880",
    "end": "76640"
  },
  {
    "text": "deep learning natural language processing on problems of mathematics",
    "start": "76640",
    "end": "81840"
  },
  {
    "text": "such as integration and differential equations and using this we have tried to we have",
    "start": "81840",
    "end": "89040"
  },
  {
    "text": "trained neural networks over generated data sets so data sets of problems and",
    "start": "89040",
    "end": "94079"
  },
  {
    "text": "solutions that we created and we managed to achieve state-of-the-art performance",
    "start": "94079",
    "end": "99280"
  },
  {
    "text": "meaning by that that we can do better that the big commercial tools such as or from",
    "start": "99280",
    "end": "105200"
  },
  {
    "text": "mathematica or maple on our test sets so this is more or less what we did and what i'm going to",
    "start": "105200",
    "end": "111119"
  },
  {
    "text": "present um our original paper was submitted to the international conference on learning",
    "start": "111119",
    "end": "117600"
  },
  {
    "text": "and representation iclear last september it was accepted in november i think",
    "start": "117600",
    "end": "123439"
  },
  {
    "text": "with a with the spotlight the conference will be held virtually because of the situation at the end of the month",
    "start": "123439",
    "end": "131360"
  },
  {
    "text": "and there's an improvation of the paper on archive soon on ikea papers and the code and",
    "start": "131360",
    "end": "138080"
  },
  {
    "text": "data sets are all open and accessible on github on the facebook research github",
    "start": "138080",
    "end": "146239"
  },
  {
    "text": "so what's the starting point of our research where did we come from it starts with a reflection on the",
    "start": "146959",
    "end": "153760"
  },
  {
    "start": "147000",
    "end": "262000"
  },
  {
    "text": "success the current success of neural networks neural networks are extremely good",
    "start": "153760",
    "end": "159280"
  },
  {
    "text": "they've progressed a lot and they've become state of the art on a very wide range of problems",
    "start": "159280",
    "end": "164800"
  },
  {
    "text": "in particular they're extremely efficient when doing pattern recognition you know no matter it is",
    "start": "164800",
    "end": "171840"
  },
  {
    "text": "finding objects in images recognizing a face or recognizing the speaker or cutting and recording with many",
    "start": "171840",
    "end": "179599"
  },
  {
    "text": "people in several different voices they're very good at that on the other hand they have their limits and they",
    "start": "179599",
    "end": "185840"
  },
  {
    "text": "so far they had limited success in everything related to symbolic computation so that's",
    "start": "185840",
    "end": "191680"
  },
  {
    "text": "using symbols and assembling them or manipulating them so as to do computation for",
    "start": "191680",
    "end": "197360"
  },
  {
    "text": "instance in mathematics it's been tried to have neural networks do computation and they tend to fail sometimes quite",
    "start": "197360",
    "end": "204319"
  },
  {
    "text": "miserably on very simple tasks like integer multiplication integer multiplication",
    "start": "204319",
    "end": "210560"
  },
  {
    "text": "well they can manage base two but then it's not symbolic because you just have two symbols",
    "start": "210560",
    "end": "215599"
  },
  {
    "text": "and they can manage short integers but actually as soon as the length gets a bit large it doesn't work anymore",
    "start": "215599",
    "end": "224080"
  },
  {
    "text": "and this is strange we thought because on the on the one hand one would be like",
    "start": "224080",
    "end": "230799"
  },
  {
    "text": "one would be tempted to say okay neural networks are not good at symbolic manipulation but on the other hand",
    "start": "230799",
    "end": "237760"
  },
  {
    "text": "they are extremely efficient in natural language processing and in machine translation and these are totally simple",
    "start": "237760",
    "end": "245400"
  },
  {
    "text": "manipulation tasks so we started with this apparent contradiction between the fact that",
    "start": "245400",
    "end": "251360"
  },
  {
    "text": "neural nets work very well for language at symbolic manipulation and badly",
    "start": "251360",
    "end": "257680"
  },
  {
    "text": "at math for the same symbolic manipulation so the original intuition was",
    "start": "257680",
    "end": "265120"
  },
  {
    "start": "262000",
    "end": "404000"
  },
  {
    "text": "when you look at the current architectures that work in machine translation",
    "start": "265120",
    "end": "270960"
  },
  {
    "text": "how do they proceed well the first thing is that they work at the sentence level and they consider",
    "start": "270960",
    "end": "276479"
  },
  {
    "text": "a sentence as a basic sequence of tokens those models are called",
    "start": "276479",
    "end": "281680"
  },
  {
    "text": "sequence to sequence they transform a sequence to another sequence sect to sec and when i'm saying it's sequence",
    "start": "281680",
    "end": "288720"
  },
  {
    "text": "consider a sequence of tokens it means that you will not um represent the sentence",
    "start": "288720",
    "end": "294560"
  },
  {
    "text": "as a pass tree you will not represent the words as verbs or none etc or anything they're just a sequence of",
    "start": "294560",
    "end": "302400"
  },
  {
    "text": "stuff of tokens and this is what the machine or at least deep nets seem to prefer",
    "start": "302400",
    "end": "308639"
  },
  {
    "text": "the second thing is that they don't seem to care at all about domain specific knowledge",
    "start": "308639",
    "end": "314080"
  },
  {
    "text": "you don't need to tell them about grammar about dictionaries about all that they don't need when they translate for",
    "start": "314080",
    "end": "320080"
  },
  {
    "text": "instance dictionaries or parallel sentences they don't know anything of that the only thing they really need is",
    "start": "320080",
    "end": "325680"
  },
  {
    "text": "data lots and lots and lots of data and given that a basic model and lots of",
    "start": "325680",
    "end": "331840"
  },
  {
    "text": "data they can achieve outstanding performance in very complex tasks",
    "start": "331840",
    "end": "337520"
  },
  {
    "text": "for instance they can do a supervised machine translation put into the correct architecture",
    "start": "337520",
    "end": "343919"
  },
  {
    "text": "a large amount of french a large amount of german you don't need to give it parallel",
    "start": "343919",
    "end": "349280"
  },
  {
    "text": "sentences translation dictionary they can translate at a fairly high level and this works so",
    "start": "349280",
    "end": "356880"
  },
  {
    "text": "observing that our idea is okay why why can't we do the same for math after all math is a language it might not be",
    "start": "356880",
    "end": "363360"
  },
  {
    "text": "the most natural of languages but it's a language and whereas in the past people have not",
    "start": "363360",
    "end": "370000"
  },
  {
    "text": "done that we thought that actually having large data sets in math is not a problem because you can",
    "start": "370000",
    "end": "375280"
  },
  {
    "text": "generate math you can generate as many data as many data set as you want with well machines and finally we have",
    "start": "375280",
    "end": "383280"
  },
  {
    "text": "this idea that after all digging a little deeper we could consider that",
    "start": "383280",
    "end": "388800"
  },
  {
    "text": "math is similar to translation basically solving a problem in math",
    "start": "388800",
    "end": "394800"
  },
  {
    "text": "is translating the problem into its solution so it's a form of translation from math to math but there's no real",
    "start": "394800",
    "end": "402720"
  },
  {
    "text": "difference so this sort of sets the plan for the paper",
    "start": "402720",
    "end": "407759"
  },
  {
    "start": "404000",
    "end": "456000"
  },
  {
    "text": "what we want to do is machine translation for mathematics machine transition applied to math",
    "start": "407759",
    "end": "412880"
  },
  {
    "text": "and there are several steps in this the first one is that if we want to use sectosec model we need",
    "start": "412880",
    "end": "419360"
  },
  {
    "text": "to adapt the math or to bring the math to the models so we need to represent the problems and the",
    "start": "419360",
    "end": "425199"
  },
  {
    "text": "solution of mathematical problems as sequences that can be used by our",
    "start": "425199",
    "end": "430240"
  },
  {
    "text": "models second we need to generate those large sets of data i said it was possible but",
    "start": "430240",
    "end": "437039"
  },
  {
    "text": "it needs to be done and then we need to train the model and train them to say okay let's",
    "start": "437039",
    "end": "442400"
  },
  {
    "text": "translate the problem into the solution and see if it works so the first step we want to represent",
    "start": "442400",
    "end": "450319"
  },
  {
    "text": "problems and solution as sequences this might seem a big thing but actually it's relatively easy because",
    "start": "450319",
    "end": "457680"
  },
  {
    "start": "456000",
    "end": "912000"
  },
  {
    "text": "we know that any expression mathematical but also in language but also in",
    "start": "457680",
    "end": "462960"
  },
  {
    "text": "computer programming can represent can be represented as a tree how many names for those trees you know",
    "start": "462960",
    "end": "468080"
  },
  {
    "text": "in computer science you know semantic tree symbolic tree past trees it's always the same",
    "start": "468080",
    "end": "473440"
  },
  {
    "text": "you have a tree representing an expression and this is actually the way",
    "start": "473440",
    "end": "478560"
  },
  {
    "text": "math is handled in computers when you want to model the calculation if that's the way you handle you know",
    "start": "478560",
    "end": "484800"
  },
  {
    "text": "compilation or any representation of language and math expression up just as i'm",
    "start": "484800",
    "end": "490639"
  },
  {
    "text": "enabled to this free form as the rest of expression say in computer science",
    "start": "490639",
    "end": "496960"
  },
  {
    "text": "so here's an example of three different trees in increasing degree of complexity the",
    "start": "496960",
    "end": "502879"
  },
  {
    "text": "first one the leftmost is just a calculation two plus three times five plus two",
    "start": "502879",
    "end": "508240"
  },
  {
    "text": "and you see how the tree is built every internal node of the tree is an operator plus",
    "start": "508240",
    "end": "513680"
  },
  {
    "text": "times plus the leaves of the tree are the numbers and the tree has this nice features that",
    "start": "513680",
    "end": "520959"
  },
  {
    "text": "it's take cares of the order of operation with a tree you don't need parenthesis so it's even simpler",
    "start": "520959",
    "end": "526480"
  },
  {
    "text": "than the original expression going to the central uh tree i'm complexifying the thing a",
    "start": "526480",
    "end": "534240"
  },
  {
    "text": "bit so i'm now taking care of a mathematical expression it could be an equation if i think it's equal 0 or an",
    "start": "534240",
    "end": "540000"
  },
  {
    "text": "equation if i say to add variables so x it could be xyz so i have a new kind of node",
    "start": "540000",
    "end": "547200"
  },
  {
    "text": "and then i i added two operator a power operator which take care of a",
    "start": "547200",
    "end": "553760"
  },
  {
    "text": "square and a cosine operator which is the case of the cosine two x and note that whereas all the operators",
    "start": "553760",
    "end": "560560"
  },
  {
    "text": "are binary the cosine operator is unary that's one of the points the operators are either unreal",
    "start": "560560",
    "end": "566240"
  },
  {
    "text": "binary the last expression is actually a much more complicated version",
    "start": "566240",
    "end": "571760"
  },
  {
    "text": "it's um it's a differential partial differential equation it's the one-dimensional wave function for those who have studied",
    "start": "571760",
    "end": "577680"
  },
  {
    "text": "physics so it's something it's a more complicated object in math",
    "start": "577680",
    "end": "583040"
  },
  {
    "text": "um you can imagine it as an equation by adding equal zero at the end you don't need to add it to represent it in the machine",
    "start": "583040",
    "end": "590240"
  },
  {
    "text": "and you see here i added a couple of new letters greek letters of sci fi new etc and i",
    "start": "590240",
    "end": "597680"
  },
  {
    "text": "added a new operator which is a derivative the partial derivative operator which is a binary you derive something with",
    "start": "597680",
    "end": "604079"
  },
  {
    "text": "respect to something else but what's interesting is that we believe that a lot",
    "start": "604079",
    "end": "610399"
  },
  {
    "text": "probably most of the mathematical expression that we can find can be represented in that free form and",
    "start": "610399",
    "end": "617040"
  },
  {
    "text": "for anyone who has some uh use habit of computer science once you have a tree",
    "start": "617040",
    "end": "623839"
  },
  {
    "text": "it's very easy to imagine that you can have a sentence because we know how to enumerate trees",
    "start": "623839",
    "end": "629760"
  },
  {
    "text": "and to generate a sentence just by reading the notes of the tree in a certain predefinite order so in",
    "start": "629760",
    "end": "636160"
  },
  {
    "text": "this case we do pre-order or prefix reading of trees which means that we represent the trees as sequences",
    "start": "636160",
    "end": "642480"
  },
  {
    "text": "by first stating the parent and then stating the left",
    "start": "642480",
    "end": "648880"
  },
  {
    "text": "node the left child and then the right child so for instance my left most three would",
    "start": "648880",
    "end": "653920"
  },
  {
    "text": "be plus two times three plus five two you see every time i'm",
    "start": "653920",
    "end": "660160"
  },
  {
    "text": "representing the top node and then the left child and then the right child and",
    "start": "660160",
    "end": "665200"
  },
  {
    "text": "going this way i get sentences sequences for every one of my three and i'm set",
    "start": "665200",
    "end": "672720"
  },
  {
    "text": "i got i can represent everything so you see the process i represent expression mathematical",
    "start": "672720",
    "end": "678800"
  },
  {
    "text": "expression as trees and then the trees are sequences and everything is ready whether it's the",
    "start": "678800",
    "end": "684880"
  },
  {
    "text": "problem a solution is a material i can represent everything in a form that is interesting for my modeling my",
    "start": "684880",
    "end": "691760"
  },
  {
    "text": "further model having done that we don't want to do that on all of the master which shows",
    "start": "691760",
    "end": "699040"
  },
  {
    "text": "a certain number of subjects we want to study and in this paper we address three different problems of",
    "start": "699040",
    "end": "705200"
  },
  {
    "text": "mathematics which is symbolic integration so symbolic integration you know integration is the reverse process of",
    "start": "705200",
    "end": "711120"
  },
  {
    "text": "derivation uh so you have a function and you want to know its integral so that's the function which derivates",
    "start": "711120",
    "end": "717519"
  },
  {
    "text": "give the function you want and then first order differential equations which are",
    "start": "717519",
    "end": "722880"
  },
  {
    "text": "equations where you find a function that verifies some relation between the function and its first",
    "start": "722880",
    "end": "730000"
  },
  {
    "text": "derivative and then second order differential which is the same with the first and second derivative",
    "start": "730000",
    "end": "735680"
  },
  {
    "text": "why do we choose those problems the first thing is that they are very very general and they're very they have a lot of use in math and",
    "start": "735680",
    "end": "742480"
  },
  {
    "text": "especially in physics you know derivatives if you have a position in physics the derivative of the position is the speed",
    "start": "742480",
    "end": "748720"
  },
  {
    "text": "the derivative the speed is acceleration so this kind of differential equation",
    "start": "748720",
    "end": "753920"
  },
  {
    "text": "sort of pop up everywhere in math and physics everywhere second good reason of taking that is",
    "start": "753920",
    "end": "759519"
  },
  {
    "text": "that those problems are difficult problem they're very involved problem they're not the kind of thing that are",
    "start": "759519",
    "end": "765839"
  },
  {
    "text": "taught in elementary school etc you usually start with them in university at",
    "start": "765839",
    "end": "771839"
  },
  {
    "text": "university level and that's something which are considered difficult for humans and machines for humans they are difficult",
    "start": "771839",
    "end": "778079"
  },
  {
    "text": "you know a trained mathematician doesn't solve a first or second order differential equation like that it's",
    "start": "778079",
    "end": "783519"
  },
  {
    "text": "it's difficult it needs some work and computers do it and their algorithm not really for",
    "start": "783519",
    "end": "788959"
  },
  {
    "text": "symbolic integration one is known as rich algorithm it's from the 70s but it's a very complicated algorithm",
    "start": "788959",
    "end": "795360"
  },
  {
    "text": "one of the most complicated that exists it is said that it takes more than 100 pages",
    "start": "795360",
    "end": "801200"
  },
  {
    "text": "of text to represent the pseudo code of the rich algorithm and to my knowledge",
    "start": "801200",
    "end": "806880"
  },
  {
    "text": "even right now no single mathematical software implements it in full because",
    "start": "806880",
    "end": "813839"
  },
  {
    "text": "some parts of it are so complicated that you cannot really efficiently implement them",
    "start": "813839",
    "end": "819360"
  },
  {
    "text": "so those are tasks where both men and machine suffer they are close to the limit of",
    "start": "819360",
    "end": "826160"
  },
  {
    "text": "what we're able to do and what we're not able to do the last reason why we chose those tasks",
    "start": "826160",
    "end": "831519"
  },
  {
    "text": "is that there are tasks where we believe that natural language and translation system",
    "start": "831519",
    "end": "837600"
  },
  {
    "text": "might succeed for one reason i said in the beginning that neural nets are good at pattern",
    "start": "837600",
    "end": "843279"
  },
  {
    "text": "recognition and integration is something about pattern recognition you see in the in the function i have",
    "start": "843279",
    "end": "849279"
  },
  {
    "text": "here i see a sign a sign x i know that if there's a sign x in the in the function there will be a",
    "start": "849279",
    "end": "856720"
  },
  {
    "text": "cosine in the integral somehow i know if that if i have a square root somewhere i'll",
    "start": "856720",
    "end": "863440"
  },
  {
    "text": "see it in the integral in some look so the idea is that",
    "start": "863440",
    "end": "868480"
  },
  {
    "text": "in general uh there's a good amount of pattern recognition in the way",
    "start": "868480",
    "end": "873920"
  },
  {
    "text": "we humans solve symbolic integrals solve first on second order differential",
    "start": "873920",
    "end": "878959"
  },
  {
    "text": "equation so this is exactly the kind of difficult problems where i would say deep learning or more",
    "start": "878959",
    "end": "885120"
  },
  {
    "text": "language models have a good chance of succeeding",
    "start": "885120",
    "end": "890480"
  },
  {
    "text": "so now that we've presented the problem and the models we use um comes the second part it's about",
    "start": "890880",
    "end": "897839"
  },
  {
    "text": "generating the data sets so we will need lots of examples to work um lots means tens of millions we work from",
    "start": "897839",
    "end": "906079"
  },
  {
    "text": "between 20 and 50 million examples just to train one model",
    "start": "906079",
    "end": "911279"
  },
  {
    "text": "um so we want to do supervised learning you know you've got several categories of way to",
    "start": "911279",
    "end": "918160"
  },
  {
    "start": "912000",
    "end": "1063000"
  },
  {
    "text": "learn to train a network we want to do supervised learning which is a kind of learning when you have a",
    "start": "918160",
    "end": "923839"
  },
  {
    "text": "problem and a solution so you train the model with a problem to predict a solution and",
    "start": "923839",
    "end": "929680"
  },
  {
    "text": "you correct the model you improve it by trying to reduce the discrepancy between what the model predicted and the actual",
    "start": "929680",
    "end": "936399"
  },
  {
    "text": "solution you wanted to have and you do this by calculating a gradient back propagating it that's",
    "start": "936399",
    "end": "942000"
  },
  {
    "text": "the when you're on nets work so to do supervised learning we need to create very large data sets",
    "start": "942000",
    "end": "947040"
  },
  {
    "text": "of problems and solution we need both so first we will need all the time to",
    "start": "947040",
    "end": "954720"
  },
  {
    "text": "generate random problems in solution and at this point there's something which is very nice which is the previous",
    "start": "954720",
    "end": "960880"
  },
  {
    "text": "the modeling widget we just did you know with the trees and the sequences also is a very helps us sampling",
    "start": "960880",
    "end": "967920"
  },
  {
    "text": "problems and solution you know if you want to generate a random problem or a random solution well since the",
    "start": "967920",
    "end": "973920"
  },
  {
    "text": "problem can be represented as a tree you have to generate a random tree and so you want to generate a random unary",
    "start": "973920",
    "end": "980800"
  },
  {
    "text": "binary tree and then you will take all the nodes in the tree and decorate them",
    "start": "980800",
    "end": "986240"
  },
  {
    "text": "so you will select at random um do operators for the internal nodes and",
    "start": "986240",
    "end": "991920"
  },
  {
    "text": "leaves the constants or variables for the leaves and in this way generating a random tree is relatively",
    "start": "991920",
    "end": "999279"
  },
  {
    "text": "easy well we have the way to do it so the paper goes at length explains especially a lot about that because",
    "start": "999279",
    "end": "1005759"
  },
  {
    "text": "of course generating a random tree is not um such a simple i mean",
    "start": "1005759",
    "end": "1012000"
  },
  {
    "text": "all the naive methods tend to fail because they tend to generate trees which are either very deep or",
    "start": "1012000",
    "end": "1017920"
  },
  {
    "text": "either very broad or tend to lean left or right or center i don't know but you know having a really random three",
    "start": "1017920",
    "end": "1024000"
  },
  {
    "text": "structure for unary binary is a complex thing so it's developed in the so we provide an algorithm and a method",
    "start": "1024000",
    "end": "1030959"
  },
  {
    "text": "that that worked and we also do a lot of calculation in the appendix to explain the size of the problem space to show",
    "start": "1030959",
    "end": "1037678"
  },
  {
    "text": "that the problem stress is absolutely huge so um this is important because um you",
    "start": "1037679",
    "end": "1042880"
  },
  {
    "text": "know people sometimes say oh neural networks but they just memorize the example the problem space here is so",
    "start": "1042880",
    "end": "1048000"
  },
  {
    "text": "large that there's no chance that any network or any machine will ever memorize even a tiny part of",
    "start": "1048000",
    "end": "1054480"
  },
  {
    "text": "it so we have a method to generate random problems so how do we",
    "start": "1054480",
    "end": "1060160"
  },
  {
    "text": "generate problems and solution for integration and differential equation so for integration",
    "start": "1060160",
    "end": "1066400"
  },
  {
    "start": "1063000",
    "end": "1183000"
  },
  {
    "text": "the most simple way to look at it which we got the forward approach",
    "start": "1066400",
    "end": "1071840"
  },
  {
    "text": "is well you generate a random function we've seen that this is possible then that's the problem then you need to",
    "start": "1071840",
    "end": "1078799"
  },
  {
    "text": "compute the solution uh so you compute the anti-derivative so the integral",
    "start": "1078799",
    "end": "1084240"
  },
  {
    "text": "big f of the small f that you generated and for that you need to use the framework a symbolic framework symbol",
    "start": "1084240",
    "end": "1090080"
  },
  {
    "text": "mathematica something like that and then you have a couple small f big f",
    "start": "1090080",
    "end": "1095840"
  },
  {
    "text": "problem solution which you add to the training set rinse repeat 40 million time and you're set",
    "start": "1095840",
    "end": "1101520"
  },
  {
    "text": "of course this seems a bit fishy uh first you need an external symbolic framework so it's not",
    "start": "1101520",
    "end": "1107600"
  },
  {
    "text": "it's not really elegant you need an external tool second it's strange because you want to solve a problem and",
    "start": "1107600",
    "end": "1112640"
  },
  {
    "text": "the first step in solving the problem is to solve 40 millions of instances of this problem so it's a bit yeah",
    "start": "1112640",
    "end": "1120799"
  },
  {
    "text": "you can do that in research but it's it wouldn't work in the real world um a more important problem is that",
    "start": "1120799",
    "end": "1127200"
  },
  {
    "text": "since you need an external framework an external symbolic framework simple mathematica all that",
    "start": "1127200",
    "end": "1132720"
  },
  {
    "text": "um only know to cannot integrate all the functions you know they have their limits",
    "start": "1132720",
    "end": "1138799"
  },
  {
    "text": "you are limited in your training sample to the only function that the framework can integrate",
    "start": "1138799",
    "end": "1144400"
  },
  {
    "text": "and this is a deep limit because it means that the data you're training is biased by the tool you use to produce",
    "start": "1144400",
    "end": "1151760"
  },
  {
    "text": "the data the symbolic framework you use to produce the data last point which is not negligible it's",
    "start": "1151760",
    "end": "1157200"
  },
  {
    "text": "very slow uh on average a tool like simple mathematica might take several seconds",
    "start": "1157200",
    "end": "1162559"
  },
  {
    "text": "to generate one one solution one problem solution uh if",
    "start": "1162559",
    "end": "1168799"
  },
  {
    "text": "you want 50 million of examples you can do the math even with a lot of computers it's uh it's a bit prohibitive so we want",
    "start": "1168799",
    "end": "1177520"
  },
  {
    "text": "we still generated such um such a sample a small one but such a sample to to test",
    "start": "1177520",
    "end": "1183200"
  },
  {
    "start": "1183000",
    "end": "1319000"
  },
  {
    "text": "but we followed a different approach for symbolic integration which we call the backward approach",
    "start": "1183200",
    "end": "1188240"
  },
  {
    "text": "instead of generating a solution a problem and finding a solution we could generate a solution and find its",
    "start": "1188240",
    "end": "1194240"
  },
  {
    "text": "problem and this turns out to be incredibly easy for the integration because it's in a way what",
    "start": "1194240",
    "end": "1201600"
  },
  {
    "text": "you could call a trapdoor problem it's a problem that is very difficult to solve one way but which the reverse of it is very easy",
    "start": "1201600",
    "end": "1209760"
  },
  {
    "text": "to solve what i mean by that is that suppose you generate a random function but this time the random function is the big f it's",
    "start": "1209760",
    "end": "1216240"
  },
  {
    "text": "the solution it's the integral then the only thing you need to find a problem is to calculate the derivative which is a very",
    "start": "1216240",
    "end": "1222720"
  },
  {
    "text": "easy task you can do it in a symbolic framework but you could even write the code for it so it's yeah a few hundred lines of code",
    "start": "1222720",
    "end": "1230159"
  },
  {
    "text": "it's not difficult to do in any case and it works all the time and it's fast and so when you do the backward approach",
    "start": "1230159",
    "end": "1236880"
  },
  {
    "text": "you can generate that very low cost a large sample of problems in solution",
    "start": "1236880",
    "end": "1243039"
  },
  {
    "text": "but is it exactly the same well actually if you look at",
    "start": "1243039",
    "end": "1248640"
  },
  {
    "text": "what you get from the forward approach you get this kind of problems and solutions so those are functions",
    "start": "1248640",
    "end": "1254080"
  },
  {
    "text": "on the left and so those are the problems and those are the solution on the right",
    "start": "1254080",
    "end": "1260400"
  },
  {
    "text": "and you can see okay these are the prominent solution it's it looks good now look at what you",
    "start": "1260400",
    "end": "1265679"
  },
  {
    "text": "get with the backward approach yeah you see forward backward backward forward you see in the backward pro",
    "start": "1265679",
    "end": "1271200"
  },
  {
    "text": "approach you get very long problems with very short solutions in the forward approach you get short",
    "start": "1271200",
    "end": "1276799"
  },
  {
    "text": "problems and long solution and i chose the examples but this is true over the whole data set",
    "start": "1276799",
    "end": "1283440"
  },
  {
    "text": "um this is a limit of the way we generate data which approach is right none i mean the",
    "start": "1283440",
    "end": "1289120"
  },
  {
    "text": "function we get both function we want to integrate the short function that the short function that have long integrals and",
    "start": "1289120",
    "end": "1295120"
  },
  {
    "text": "the long integrals that long function that have short integrals but uh the thing is that since we generate long",
    "start": "1295120",
    "end": "1302000"
  },
  {
    "text": "problem with short solution we are not working exactly on the same kind of problem or",
    "start": "1302000",
    "end": "1307200"
  },
  {
    "text": "the same part of the problem space to be more specific than what we would do with the forward approach",
    "start": "1307200",
    "end": "1313600"
  },
  {
    "text": "so question we had is could we mitigate that and for this we looked at the third",
    "start": "1313600",
    "end": "1319600"
  },
  {
    "start": "1319000",
    "end": "1497000"
  },
  {
    "text": "approach which is which is called integration by parts integration by part it's a trick to calculate integrals normally which",
    "start": "1319600",
    "end": "1326799"
  },
  {
    "text": "takes advantage of the way um products uh are derived",
    "start": "1326799",
    "end": "1332400"
  },
  {
    "text": "the way you calculate the derivative of a product the idea is that it works like a backward",
    "start": "1332400",
    "end": "1337919"
  },
  {
    "text": "generator so you don't need an external to nothing if you generate two random functions and",
    "start": "1337919",
    "end": "1343200"
  },
  {
    "text": "derive them then you get two problems in solution as before but if in the past you happen to have",
    "start": "1343200",
    "end": "1349919"
  },
  {
    "text": "calculate small f the the integral of small f times big g then you have",
    "start": "1349919",
    "end": "1358080"
  },
  {
    "text": "the integral of big f times small g for free and the other way around it might look like a silly id but if you",
    "start": "1358080",
    "end": "1364080"
  },
  {
    "text": "have millions of problems the number of cases where this happens is much larger than one might",
    "start": "1364080",
    "end": "1369760"
  },
  {
    "text": "might be even and so you can generate a very nice new sample with that seeing like that it",
    "start": "1369760",
    "end": "1376400"
  },
  {
    "text": "seems like an unnecessary complication but when you look at the results of the integration by part then it can you understand the",
    "start": "1376400",
    "end": "1382880"
  },
  {
    "text": "use the thing is that the formula you see above is done in such a way that the left part so",
    "start": "1382880",
    "end": "1389520"
  },
  {
    "text": "what you're calculating is much smaller than the right part and so you will have that nice property that",
    "start": "1389520",
    "end": "1395600"
  },
  {
    "text": "forward generated samples had which were short problem unknown solution it's not",
    "start": "1395600",
    "end": "1401440"
  },
  {
    "text": "as strong as what you get in the forward example but you could say that symbolic integration by part sort of stands in",
    "start": "1401440",
    "end": "1408159"
  },
  {
    "text": "the middle between the backward forward or something so we have three methods",
    "start": "1408159",
    "end": "1413679"
  },
  {
    "text": "to um generates all symbolic integrals which will generate three different",
    "start": "1413679",
    "end": "1419120"
  },
  {
    "text": "samples well i'll come back to that later um what do we do for differential equation then",
    "start": "1419120",
    "end": "1425200"
  },
  {
    "text": "it's even worse because there's no simple solution or automatic solution for generating an ordinary difference",
    "start": "1425200",
    "end": "1431200"
  },
  {
    "text": "for solving an ordinary differential equation of a sufficiently general type um",
    "start": "1431200",
    "end": "1437600"
  },
  {
    "text": "formally i mean so what we do is that we use a backward method",
    "start": "1437600",
    "end": "1442720"
  },
  {
    "text": "and here's the the general id so the solution of first website the solution of first order differential",
    "start": "1442720",
    "end": "1448960"
  },
  {
    "text": "equation are defined up to a constant c so we write them up as a function of two",
    "start": "1448960",
    "end": "1454000"
  },
  {
    "text": "variable y equal f of x the variable and see the constant and then we solve it we solve this",
    "start": "1454000",
    "end": "1461200"
  },
  {
    "text": "equation in c so we pretend y is not a function it's just a variable x is another variable",
    "start": "1461200",
    "end": "1466400"
  },
  {
    "text": "and we solve in c so we end up computing a big function big f that writes f x y equals",
    "start": "1466400",
    "end": "1472400"
  },
  {
    "text": "c most of the time you can do this solving analytically you lose a couple of",
    "start": "1472400",
    "end": "1477600"
  },
  {
    "text": "cases but not so many and the thing is that once you have this function if you differentiate it",
    "start": "1477600",
    "end": "1483360"
  },
  {
    "text": "then the right part being a constant will come to zero and the left part will be a very nice",
    "start": "1483360",
    "end": "1488559"
  },
  {
    "text": "differential equation of the first order that's f source so i generated the",
    "start": "1488559",
    "end": "1494080"
  },
  {
    "text": "problem from my solution to make this clear let me show you an example so we have a random function",
    "start": "1494080",
    "end": "1500080"
  },
  {
    "start": "1497000",
    "end": "1552000"
  },
  {
    "text": "you see f at the top it's x times log c on x i call that y solving it you can do",
    "start": "1500080",
    "end": "1506960"
  },
  {
    "text": "it for yourself i just invert so i say c equals and this is my big f",
    "start": "1506960",
    "end": "1512799"
  },
  {
    "text": "then i can differentiate in x and i can even simplify it because you know the exponential in",
    "start": "1512799",
    "end": "1519520"
  },
  {
    "text": "front is a positive number so i can remove it and i can move",
    "start": "1519520",
    "end": "1524720"
  },
  {
    "text": "avoid the division by x by multiplying all the terms by x and i end up with a very s nice and",
    "start": "1524720",
    "end": "1531600"
  },
  {
    "text": "simple first order differential equation which by no way one would guess",
    "start": "1531600",
    "end": "1537200"
  },
  {
    "text": "the solution as being the top one so we're not helping the machine we're generating pairs that are not easy to guess you know you",
    "start": "1537200",
    "end": "1544480"
  },
  {
    "text": "can always generate pairs that are easy to guess but then then what's the what's the point",
    "start": "1544480",
    "end": "1550240"
  },
  {
    "text": "second so with this we can generate ordinary differential equation and we have a proof not in the paper but we",
    "start": "1550240",
    "end": "1557840"
  },
  {
    "start": "1552000",
    "end": "1586000"
  },
  {
    "text": "have sort of proven that the the problems that we are generating this way represents",
    "start": "1557840",
    "end": "1564080"
  },
  {
    "text": "um the large majority you know everything except a measure zero measure uh set of the set of",
    "start": "1564080",
    "end": "1571600"
  },
  {
    "text": "ordinary differential equation uh satisfying minimal condition of continuity of that",
    "start": "1571600",
    "end": "1577760"
  },
  {
    "text": "so we're pretty pretty much so working on all possible differential",
    "start": "1577760",
    "end": "1583520"
  },
  {
    "text": "equation with this system we can expand this to the second order we could actually expand it to",
    "start": "1583520",
    "end": "1589679"
  },
  {
    "start": "1586000",
    "end": "1633000"
  },
  {
    "text": "larger orders the thing is that you then have two integration constants and you will have",
    "start": "1589679",
    "end": "1594880"
  },
  {
    "text": "them two steps and two differentiations so you start from a function f of x c and d",
    "start": "1594880",
    "end": "1600960"
  },
  {
    "text": "you solve it in d so you get a big f equals x y t in d you then differentiate it so",
    "start": "1600960",
    "end": "1608320"
  },
  {
    "text": "you get x y y prime c equals zero and then you solve again in c so you get the function of j",
    "start": "1608320",
    "end": "1616320"
  },
  {
    "text": "x x y y prime and you differentiate and you get your solution so it's a bit more involved but it's not",
    "start": "1616320",
    "end": "1623440"
  },
  {
    "text": "conceptually more difficult it's just a little more complicated to implement but there's no real change",
    "start": "1623440",
    "end": "1631440"
  },
  {
    "text": "so having done that we built five data sets so we have three data sets for",
    "start": "1631440",
    "end": "1636799"
  },
  {
    "start": "1633000",
    "end": "1743000"
  },
  {
    "text": "integration forward backward integration by parts our main data said the main training was",
    "start": "1636799",
    "end": "1642080"
  },
  {
    "text": "done on the backward sample so we had 40 million problems on solution we had smaller sets",
    "start": "1642080",
    "end": "1647279"
  },
  {
    "text": "of forward and back and integration by partly because it was much more slow to generate them",
    "start": "1647279",
    "end": "1654320"
  },
  {
    "text": "so we stopped a little earlier and we have 40 million two for ode one or the two uh what kind of functions do we work",
    "start": "1654320",
    "end": "1662240"
  },
  {
    "text": "with so we work with expression with up to 15 internal modes of 15 operators in the",
    "start": "1662240",
    "end": "1667360"
  },
  {
    "text": "formulas so those are pretty big formulas um the leave values are either",
    "start": "1667360",
    "end": "1672799"
  },
  {
    "text": "x there's only one variable and integers between minus five and plus five without zero",
    "start": "1672799",
    "end": "1679039"
  },
  {
    "text": "why the small integers because we don't want to do arithmetic we know the machine is not good at arithmetic so",
    "start": "1679039",
    "end": "1684880"
  },
  {
    "text": "it's not really useful wasting time on you know having complicated calculation that the machine cannot do",
    "start": "1684880",
    "end": "1691520"
  },
  {
    "text": "we want to to be on a very basic system so we keep the integers small as for the operators",
    "start": "1691520",
    "end": "1697840"
  },
  {
    "text": "we use the four basic operators plus minus times and divide",
    "start": "1697840",
    "end": "1702880"
  },
  {
    "text": "and 15 unary operators we have the exponential and logarithm we have the square roots we have the trig and the",
    "start": "1702880",
    "end": "1708880"
  },
  {
    "text": "inverse trig and the hyperbolic trig and inverse hyperbolic trig those functions are known in the",
    "start": "1708880",
    "end": "1714960"
  },
  {
    "text": "mathematical literature about integration as elementary function they're basically what people who study formal integration",
    "start": "1714960",
    "end": "1721919"
  },
  {
    "text": "usually do it's very all theory that comes back to youville and people in the 19th century",
    "start": "1721919",
    "end": "1728720"
  },
  {
    "text": "and this is the elementary function that were used at this at that time so not now that we're good",
    "start": "1728720",
    "end": "1735279"
  },
  {
    "text": "with the data sets we can go to the training the models and looking at the results this is the easier part actually",
    "start": "1735279",
    "end": "1741760"
  },
  {
    "text": "we've done the more advanced part of the thing so for the model we're using a transformer architecture i'm not going",
    "start": "1741760",
    "end": "1748799"
  },
  {
    "start": "1743000",
    "end": "1991000"
  },
  {
    "text": "to detail too much the technique but the transformer is an architecture of",
    "start": "1748799",
    "end": "1754080"
  },
  {
    "text": "a deep deep network that has becoming incredibly positive increasingly popular over the recent",
    "start": "1754080",
    "end": "1760960"
  },
  {
    "text": "years it was usually mostly meant for natural language but now it's used in",
    "start": "1760960",
    "end": "1766240"
  },
  {
    "text": "in many different cases a transformer architecture is a network which is non-recurrent you know",
    "start": "1766240",
    "end": "1772080"
  },
  {
    "text": "you have non-recurrent network the feed forward networks where you have one layer of neurons and the second and",
    "start": "1772080",
    "end": "1777840"
  },
  {
    "text": "the third and so that and networks and every network is every layer is connected to",
    "start": "1777840",
    "end": "1784880"
  },
  {
    "text": "the previous one but there's there are no feedback there's no connection backwards",
    "start": "1784880",
    "end": "1789919"
  },
  {
    "text": "so it goes from layer one to layer two to layer three to the other 4 to layer 5 etc",
    "start": "1789919",
    "end": "1796080"
  },
  {
    "text": "recurrent networks on the other side so rnn or lstm have backward connection so",
    "start": "1796080",
    "end": "1803200"
  },
  {
    "text": "this means that they while you have connection going up from the input to the output but you",
    "start": "1803200",
    "end": "1808480"
  },
  {
    "text": "have also feedback loops inside they're more difficult to train the transformer is non-recurrent so you",
    "start": "1808480",
    "end": "1814720"
  },
  {
    "text": "don't have feedback loops but you have a mechanism called attention which means that",
    "start": "1814720",
    "end": "1820640"
  },
  {
    "text": "we're sort of having a transversal connection practically with the attention mechanism what happens is that the output of a",
    "start": "1820640",
    "end": "1826799"
  },
  {
    "text": "neuron in a particular layer depends on the neuron on the previous layer this is a hallmark",
    "start": "1826799",
    "end": "1832799"
  },
  {
    "text": "of every fit for every neural nets but also on the on the on the output of the",
    "start": "1832799",
    "end": "1841200"
  },
  {
    "text": "neural on the neurons just before it's on the same layer so practically it sort of looks back",
    "start": "1841200",
    "end": "1847600"
  },
  {
    "text": "this is the attention mechanism and this architecture has become increasingly popular because this is",
    "start": "1847600",
    "end": "1854080"
  },
  {
    "text": "easy to train it works extremely well on a very large number of cases apart from that the transformer",
    "start": "1854080",
    "end": "1860880"
  },
  {
    "text": "you use is it's really run-of-the-mill architecture and parameter",
    "start": "1860880",
    "end": "1866000"
  },
  {
    "text": "transformer so we use a fairly small model it's shallow it has only six layers it",
    "start": "1866000",
    "end": "1872000"
  },
  {
    "text": "has 512 dimensions which for transformer is not very big um it uses eight attention heads",
    "start": "1872000",
    "end": "1878480"
  },
  {
    "text": "attention heads at the the number of cases where you look back at the same layers and it's trained over a cross",
    "start": "1878480",
    "end": "1885039"
  },
  {
    "text": "entropy loss which is the loss you use when you compare sequences you know it's character is the same or difference and",
    "start": "1885039",
    "end": "1890399"
  },
  {
    "text": "stuff like that we use the adam optimizer which is the typical one used these days and batches",
    "start": "1890399",
    "end": "1896640"
  },
  {
    "text": "of 256 examples which are large batches which sort of speed the training and also work",
    "start": "1896640",
    "end": "1902559"
  },
  {
    "text": "well so keep in mind that it's it's a transformer but it's a very standard transformer and",
    "start": "1902559",
    "end": "1908240"
  },
  {
    "text": "in terms of speed and greediness you know nlp models are known",
    "start": "1908240",
    "end": "1914240"
  },
  {
    "text": "for being very using a lot of computing power this actually runs on",
    "start": "1914240",
    "end": "1920159"
  },
  {
    "text": "one gpu a couple of cpu systems so it doesn't need a huge computing resource and we",
    "start": "1920159",
    "end": "1926240"
  },
  {
    "text": "train in like a day maybe a day and a half but that's that's pretty much it so",
    "start": "1926240",
    "end": "1931840"
  },
  {
    "text": "it's probably not something that can be done on a very small machine but it doesn't need a lot of",
    "start": "1931840",
    "end": "1937679"
  },
  {
    "text": "computing power to to be trained um so that's that's the training model at inference",
    "start": "1937679",
    "end": "1946080"
  },
  {
    "text": "we use something which is called as bin search so in this systems you generate the solution token by token",
    "start": "1946080",
    "end": "1951760"
  },
  {
    "text": "so you generate the most likely token then given the first token you generate the second one etc",
    "start": "1951760",
    "end": "1957840"
  },
  {
    "text": "and this is the way the model builds an answer token by token um this method allows for the generation",
    "start": "1957840",
    "end": "1965919"
  },
  {
    "text": "of several solutions this is what bing search does so instead of just generating the best solution",
    "start": "1965919",
    "end": "1971840"
  },
  {
    "text": "you generate the two or three or ten best solution and you go on and you every time you limit the number",
    "start": "1971840",
    "end": "1977840"
  },
  {
    "text": "of solution you want to 10 or 50 but instead of generating one solution you generate 1",
    "start": "1977840",
    "end": "1983279"
  },
  {
    "text": "10 50 several solution and this is what beam search does",
    "start": "1983279",
    "end": "1988399"
  },
  {
    "text": "so why do we do that we do it so that it it works with for evaluation how do we",
    "start": "1988399",
    "end": "1994720"
  },
  {
    "start": "1991000",
    "end": "2279000"
  },
  {
    "text": "evaluate the model so the model uh the train model are",
    "start": "1994720",
    "end": "2000480"
  },
  {
    "text": "tested on held out samples 5000 samples which are built from the",
    "start": "2000480",
    "end": "2005760"
  },
  {
    "text": "same generator as the data set so practically when we generate our data sets we single",
    "start": "2005760",
    "end": "2012960"
  },
  {
    "text": "out 5000 examples that will be used for testing and we check at that time",
    "start": "2012960",
    "end": "2018159"
  },
  {
    "text": "for the lack of overlap the absence of overlap that which means that no test problem has been seen during",
    "start": "2018159",
    "end": "2024880"
  },
  {
    "text": "training there are no doubles no duplicates so the held out examples are specific to",
    "start": "2024880",
    "end": "2032240"
  },
  {
    "text": "the test set and they don't belong to the train set then once we want to test we generate so",
    "start": "2032240",
    "end": "2038880"
  },
  {
    "text": "we feed the the problems into the model the train model it generates a solution and we check the solution",
    "start": "2038880",
    "end": "2045120"
  },
  {
    "text": "and for checking the solution we use simplify so we use an external tool to check because our models can have several",
    "start": "2045120",
    "end": "2052079"
  },
  {
    "text": "solutions and the solution in the test set is not the only solution we don't want to say that it's wrong if we have a correct",
    "start": "2052079",
    "end": "2057358"
  },
  {
    "text": "solution which is not the one in the test set so we simply to check in the case of",
    "start": "2057359",
    "end": "2062480"
  },
  {
    "text": "integration it just means deriving the solution subtracting it for a problem instead checking it's zero",
    "start": "2062480",
    "end": "2068720"
  },
  {
    "text": "for the ode you feed the equation solution back into the equation and check that the result is zero it's relatively",
    "start": "2068720",
    "end": "2074638"
  },
  {
    "text": "simple and then we use bin search to try to improve our results if the first",
    "start": "2074639",
    "end": "2081599"
  },
  {
    "text": "solution proposed by the system is incorrect then we generate the second and the third etc until we get",
    "start": "2081599",
    "end": "2088000"
  },
  {
    "text": "10 or 50 and until we find a correct one so if we have in bim search one we say",
    "start": "2088000",
    "end": "2094320"
  },
  {
    "text": "the solution if correct if the first guess of the machine is correct if we",
    "start": "2094320",
    "end": "2100240"
  },
  {
    "text": "beam such 10 the machine is allowed 10 guesses if it's 50 it's given 50 guesses okay",
    "start": "2100240",
    "end": "2107599"
  },
  {
    "text": "so that's the evaluation method so how does this work so we trained the model we evaluated it so what do we get",
    "start": "2107599",
    "end": "2115280"
  },
  {
    "text": "so in the table here you have five colon one for each data set and three lines for beam size",
    "start": "2115280",
    "end": "2122960"
  },
  {
    "text": "one ten and fifty so the first three columns are for the integration problem you can",
    "start": "2122960",
    "end": "2128400"
  },
  {
    "text": "see that for all of them even in being side one you are well over 90 percent close to 95 and",
    "start": "2128400",
    "end": "2135599"
  },
  {
    "text": "sometimes over of correct solution which means that at first its first guess the transformer",
    "start": "2135599",
    "end": "2143359"
  },
  {
    "text": "found the correct solution in 95 percent of the 5 000 test set test example he had never",
    "start": "2143359",
    "end": "2150960"
  },
  {
    "text": "seen before so that's that's a big success it goes very well of course when you're already",
    "start": "2150960",
    "end": "2156079"
  },
  {
    "text": "on 95 the green size will help but help very little even though it can guess that's very very close to the 100",
    "start": "2156079",
    "end": "2163040"
  },
  {
    "text": "percent very close to it you can see that forward and integration by part achieve",
    "start": "2163040",
    "end": "2168720"
  },
  {
    "text": "slightly lower results i suspect is because of the sample size the data set size um",
    "start": "2168720",
    "end": "2175359"
  },
  {
    "text": "in practice on other experiments we noticed that we were quite similar what's interesting here is",
    "start": "2175359",
    "end": "2181680"
  },
  {
    "text": "that of course we have very good results on integration but what's more even more important is that we have the same kind",
    "start": "2181680",
    "end": "2187440"
  },
  {
    "text": "of results for forward backward and integration by part for the three data sets and this is",
    "start": "2187440",
    "end": "2193760"
  },
  {
    "text": "important because when you work from generated data from synthetic data there's always a doubt",
    "start": "2193760",
    "end": "2200160"
  },
  {
    "text": "and the doubt is when you get a result is this result really due to you know you having the model having",
    "start": "2200160",
    "end": "2208240"
  },
  {
    "text": "performed or is it due to the data set because you somehow generated some you have some artifact in your data",
    "start": "2208240",
    "end": "2215040"
  },
  {
    "text": "which makes the data the problem you're solving easier to solve or because there's something with your data that",
    "start": "2215040",
    "end": "2220400"
  },
  {
    "text": "the model exploited which is not linked to the problem and this is always a problem with",
    "start": "2220400",
    "end": "2226079"
  },
  {
    "text": "synthetic data but if like like here you manage to get the same result on three totally",
    "start": "2226079",
    "end": "2232640"
  },
  {
    "text": "different data generated with different ways then data generation",
    "start": "2232640",
    "end": "2237680"
  },
  {
    "text": "is not a problem it's the sucks the result are the result of the model so it shows",
    "start": "2237680",
    "end": "2242800"
  },
  {
    "text": "that the method is to some extent universal for differential equations",
    "start": "2242800",
    "end": "2248079"
  },
  {
    "text": "the problem is more difficult and gets more difficult as order goes up and you can see that the results go down",
    "start": "2248079",
    "end": "2253760"
  },
  {
    "text": "so being size 1 gets from 95 96 for integration",
    "start": "2253760",
    "end": "2259200"
  },
  {
    "text": "to 78 and then 43 for differential equation but this is where bim search comes to the rescue",
    "start": "2259200",
    "end": "2265520"
  },
  {
    "text": "with the bim search we get back to 95 or 80 for both so results look pretty good how",
    "start": "2265520",
    "end": "2272160"
  },
  {
    "text": "good is this so in order to compare we work on state-of-the-art what's the state of the",
    "start": "2272160",
    "end": "2277280"
  },
  {
    "text": "art well commercial programs like mathematica that's all from or matlab or marco mathematics much",
    "start": "2277280",
    "end": "2283839"
  },
  {
    "start": "2279000",
    "end": "2365000"
  },
  {
    "text": "better than the others so we must we did on this problem on specific problem so we mostly tested with",
    "start": "2283839",
    "end": "2289440"
  },
  {
    "text": "mathematica what you can see is that on the backward sample mathematica achieves 84 of cases we are at 99",
    "start": "2289440",
    "end": "2298960"
  },
  {
    "text": "and on the lde it's closer on the od or the one where equivalent mathematically is even better than us",
    "start": "2298960",
    "end": "2305040"
  },
  {
    "text": "on all the other two but as soon as the beam search sets in then we are much better than mathematica",
    "start": "2305040",
    "end": "2311760"
  },
  {
    "text": "we will perform it by a substantial margin it doesn't mean this would happen on every single",
    "start": "2311760",
    "end": "2317119"
  },
  {
    "text": "equation we're on the equation of our test set or backward equation that we have generated in this way and there are",
    "start": "2317119",
    "end": "2323040"
  },
  {
    "text": "cases where mathematics can solve problems that we cannot solve and all that but still it's a very promising and",
    "start": "2323040",
    "end": "2329200"
  },
  {
    "text": "interesting result so what we get at this point is that's the basic result of the paper we",
    "start": "2329200",
    "end": "2336400"
  },
  {
    "text": "can train models we can generate data set we can train a transformer",
    "start": "2336400",
    "end": "2341440"
  },
  {
    "text": "and we manage to get results which are relatively close",
    "start": "2341440",
    "end": "2346560"
  },
  {
    "text": "to state of the art to what mathematica and others can can do okay so",
    "start": "2346560",
    "end": "2353280"
  },
  {
    "text": "now i'd like to discuss a few interesting cases and a few let's have a few problems with this",
    "start": "2353280",
    "end": "2359040"
  },
  {
    "text": "approach of a few questions that have been have arisen and are interesting the main",
    "start": "2359040",
    "end": "2366800"
  },
  {
    "start": "2365000",
    "end": "2429000"
  },
  {
    "text": "question is generalization you know it's every time you train and you use machine learning there's someone at the end of",
    "start": "2366800",
    "end": "2371920"
  },
  {
    "text": "the of the day of the conference that says but how does your system generalize and this is the real question you know",
    "start": "2371920",
    "end": "2378160"
  },
  {
    "text": "it's easy to train but does it generalize so for our system the first answer the easy answer to that is yes it does",
    "start": "2378160",
    "end": "2384640"
  },
  {
    "text": "generalize because all the test samples we use were not seen at training so the machine achieved those 99 percent of",
    "start": "2384640",
    "end": "2391119"
  },
  {
    "text": "those 80 percent on on examples that it had never seen so in this respect it does",
    "start": "2391119",
    "end": "2396400"
  },
  {
    "text": "generalize but this is a weak definition of generalization there's a stronger one because",
    "start": "2396400",
    "end": "2402079"
  },
  {
    "text": "thinking of it we're generating we're working from generated data and the training and test set come from",
    "start": "2402079",
    "end": "2407119"
  },
  {
    "text": "the same generator what if they didn't actually if you wanted to use such a system",
    "start": "2407119",
    "end": "2412160"
  },
  {
    "text": "in the wild in real integrals for written integrals or differential the the",
    "start": "2412160",
    "end": "2418079"
  },
  {
    "text": "integrals we have to solve would not come from a generator that would come from whatever problem we're working on so",
    "start": "2418079",
    "end": "2425359"
  },
  {
    "text": "what if they don't come from the same generator so there's a way an easy way to test it you know we have the forward and the",
    "start": "2425359",
    "end": "2431280"
  },
  {
    "start": "2429000",
    "end": "2630000"
  },
  {
    "text": "backward data so on the table here you see in the line you have the training data so the first",
    "start": "2431280",
    "end": "2437680"
  },
  {
    "text": "line was trained on forward the second round was training backward and the columns are the test sets so",
    "start": "2437680",
    "end": "2443599"
  },
  {
    "text": "suppose that this instead of testing if we test if we train on forward and test on forward",
    "start": "2443599",
    "end": "2449440"
  },
  {
    "text": "you can see that's the first line first column got the 95 person that we've seen before if we",
    "start": "2449440",
    "end": "2455760"
  },
  {
    "text": "train on backwards and test them backward we're at this the same results second nine second column it's 99 percent all that but if",
    "start": "2455760",
    "end": "2462560"
  },
  {
    "text": "we train on forward and test on backward then things get wrong very wrong without",
    "start": "2462560",
    "end": "2467680"
  },
  {
    "text": "17 percent at being 50 and train them backward and test it on for what we are at 28.",
    "start": "2467680",
    "end": "2474640"
  },
  {
    "text": "these results no these results are non-trivial you wouldn't get that with a random machine so the machine has clearly learned",
    "start": "2474640",
    "end": "2480720"
  },
  {
    "text": "something but it's extremely disappointing compared to the impressive results we had before we are much much lower on",
    "start": "2480720",
    "end": "2487280"
  },
  {
    "text": "this case so why is this and how damning is this",
    "start": "2487280",
    "end": "2493760"
  },
  {
    "text": "why is this the interpretation is relatively easy you remember backward models are long",
    "start": "2493760",
    "end": "2500960"
  },
  {
    "text": "problems with short solutions forward problems forward models are short problem with long solutions",
    "start": "2500960",
    "end": "2508240"
  },
  {
    "text": "so you remember the examples if i train on the forward model i've been training the model the my",
    "start": "2508240",
    "end": "2514319"
  },
  {
    "text": "model on examples like this one and the model has learned from the data one of the basic laws of integration on",
    "start": "2514319",
    "end": "2521920"
  },
  {
    "text": "the on the forward data which is integration is an expander it makes the solution longer than the",
    "start": "2521920",
    "end": "2527680"
  },
  {
    "text": "problem and the model is absolutely certain about that because it's seen here it happened over 50 million of examples",
    "start": "2527680",
    "end": "2535280"
  },
  {
    "text": "and then you come a stat set and you arrive with this which are the danding exam the counter example",
    "start": "2535280",
    "end": "2540880"
  },
  {
    "text": "which the model hasn't seen during the training of course it won't work and saying the other way around why doesn't",
    "start": "2540880",
    "end": "2547599"
  },
  {
    "text": "it work because the model has learned from the data different properties of the training",
    "start": "2547599",
    "end": "2555440"
  },
  {
    "text": "to give an example of what this means imagine you're training an image recognition system to recogni",
    "start": "2555440",
    "end": "2561520"
  },
  {
    "text": "to recognize breeds of dogs so you want to recognize you know machines can do that so you show",
    "start": "2561520",
    "end": "2567680"
  },
  {
    "text": "lots of photographs of dogs and the machine is supposed to classify them by breeds",
    "start": "2567680",
    "end": "2572880"
  },
  {
    "text": "but suppose that's at the trainings time all the samples all the dogs you show",
    "start": "2572880",
    "end": "2578079"
  },
  {
    "text": "are small dogs poodle dogs yorkshire that kind of dogs dogs the size of cats say and suppose that at train at this time",
    "start": "2578079",
    "end": "2584960"
  },
  {
    "text": "you provide only pictures of big dogs what do you think will happen the model will fail is it the fault of the model",
    "start": "2584960",
    "end": "2591280"
  },
  {
    "text": "no it's the fault of the training data the training data is incorrect in this case it's more complicated",
    "start": "2591280",
    "end": "2596720"
  },
  {
    "text": "because we generated the data but practically what we're saying is that if you test",
    "start": "2596720",
    "end": "2601839"
  },
  {
    "text": "on data which is too different from the training data yeah it won't work is it really a",
    "start": "2601839",
    "end": "2607040"
  },
  {
    "text": "problem with generalization well not completely um it's it's about",
    "start": "2607040",
    "end": "2612400"
  },
  {
    "text": "what could be said is that the backward and forward samples are exploring different problems",
    "start": "2612400",
    "end": "2619280"
  },
  {
    "text": "because they're exploring different parts of the problem space can we",
    "start": "2619280",
    "end": "2624400"
  },
  {
    "text": "improve this yes we can that's the whole point of the integration by part",
    "start": "2624400",
    "end": "2630160"
  },
  {
    "start": "2630000",
    "end": "2796000"
  },
  {
    "text": "you remember we created the integration by part as a real method that was on top of the backward method",
    "start": "2630160",
    "end": "2635760"
  },
  {
    "text": "so those two graphs show the distribution of the number of tokens of the length of",
    "start": "2635760",
    "end": "2642079"
  },
  {
    "text": "the expression for the derivative the problems and the integral of the solution and what you can see is that the",
    "start": "2642079",
    "end": "2648560"
  },
  {
    "text": "integration by parts on the problems has exactly the same distribution as the forward",
    "start": "2648560",
    "end": "2655440"
  },
  {
    "text": "data but on the solutions the integration looks a lot like the",
    "start": "2655440",
    "end": "2661760"
  },
  {
    "text": "backward and is different from the forward this is a way to explain why the integration backbone is sort of a middle",
    "start": "2661760",
    "end": "2667920"
  },
  {
    "text": "of the road example it's in between so what happens now if we train on forward or backward and test",
    "start": "2667920",
    "end": "2674880"
  },
  {
    "text": "on integration by part it's a different sample so it's generalization so look at the first line i just added",
    "start": "2674880",
    "end": "2680720"
  },
  {
    "text": "the column integration by part to the right what you see in the right well you can",
    "start": "2680720",
    "end": "2686319"
  },
  {
    "text": "see that the forward data is very bad on the backboard but on the",
    "start": "2686319",
    "end": "2692720"
  },
  {
    "text": "integration by part i get 85 percent i get the very large values i had so i'm",
    "start": "2692720",
    "end": "2699200"
  },
  {
    "text": "almost as good on the integration by part testing on integration like the forward trend model as i was on the",
    "start": "2699200",
    "end": "2705280"
  },
  {
    "text": "forward test set so the problem is corrected with a",
    "start": "2705280",
    "end": "2710319"
  },
  {
    "text": "backward trend model the integration bar performs less well for some reasons",
    "start": "2710319",
    "end": "2716880"
  },
  {
    "text": "but still you can see that it's not just a generation an outdoor domain generalization problem because",
    "start": "2716880",
    "end": "2723359"
  },
  {
    "text": "you can see that you can generalize correctly on different samples provided this sample are not as removed",
    "start": "2723359",
    "end": "2730240"
  },
  {
    "text": "from the training samples as the forward is from the backwards okay",
    "start": "2730240",
    "end": "2735520"
  },
  {
    "text": "and you can understand at this point how we can emilio improve the whole system because if i",
    "start": "2735520",
    "end": "2743200"
  },
  {
    "text": "train now on backward plus integration by part i big i built a big sample of the two",
    "start": "2743200",
    "end": "2749040"
  },
  {
    "text": "trainer on this then you can see that when i test on forward that's the last line of the first column the performance",
    "start": "2749040",
    "end": "2757119"
  },
  {
    "text": "increases a lot it doubles so practically",
    "start": "2757119",
    "end": "2762240"
  },
  {
    "text": "we understand better now the generalization problem the out-of-domain generalization problem comes from the",
    "start": "2762240",
    "end": "2767599"
  },
  {
    "text": "fact that different generators explore different parts of the problem space",
    "start": "2767599",
    "end": "2773119"
  },
  {
    "text": "and that the result they get as they explore different parts of the problem space will generalize to areas close to",
    "start": "2773119",
    "end": "2781119"
  },
  {
    "text": "those they have explored so it will generate a forward train model world generalized",
    "start": "2781119",
    "end": "2787680"
  },
  {
    "text": "to integration by part sample test sample but it will not generalize as far as backward sampling",
    "start": "2787680",
    "end": "2794560"
  },
  {
    "text": "so what's the the solution then well the solution is simple if you want to have more generalization",
    "start": "2794560",
    "end": "2800720"
  },
  {
    "start": "2796000",
    "end": "2838000"
  },
  {
    "text": "you need larger sample and you need more generators you need more variety more diversity",
    "start": "2800720",
    "end": "2806720"
  },
  {
    "text": "in your training data and if you have mixed generators in this case we cheat a bit because we",
    "start": "2806720",
    "end": "2813359"
  },
  {
    "text": "have backward integration by pattern forward and we test them on the fridge so obviously we'll end up at 100 but still",
    "start": "2813359",
    "end": "2820880"
  },
  {
    "text": "if we have larger generators more generated mixed into one training set we improve the generalization so this is",
    "start": "2820880",
    "end": "2827760"
  },
  {
    "text": "the way the problems of generalization should be tackled from this kind of model once we're on",
    "start": "2827760",
    "end": "2835119"
  },
  {
    "text": "generalization one nice word which is more or less a fun fact you remember the forward",
    "start": "2835119",
    "end": "2840319"
  },
  {
    "start": "2838000",
    "end": "2898000"
  },
  {
    "text": "data set in the forward data set i generated a random problem and i used a tool to generate a",
    "start": "2840319",
    "end": "2847359"
  },
  {
    "text": "solution the tool i used was senpai which is a python symbolic calculator",
    "start": "2847359",
    "end": "2853119"
  },
  {
    "text": "the fun thing is that since senpai provides me with a solution my training set is only only contents",
    "start": "2853119",
    "end": "2860240"
  },
  {
    "text": "problems that simple can solve then a test set i tried it on problem",
    "start": "2860240",
    "end": "2865440"
  },
  {
    "text": "that simply couldn't solve and you have on the right a set of problems that simply could not solve but the",
    "start": "2865440",
    "end": "2871440"
  },
  {
    "text": "train model trained on simpai could solve so in a way the model managed to",
    "start": "2871440",
    "end": "2876720"
  },
  {
    "text": "generalize beyond the generator the student uh be the master it's",
    "start": "2876720",
    "end": "2883359"
  },
  {
    "text": "it's more fun than something very important because okay it just shows that it generalized but it's",
    "start": "2883359",
    "end": "2888960"
  },
  {
    "text": "interesting to see that generalization also goes this way um the last thing i wanted to to show",
    "start": "2888960",
    "end": "2896640"
  },
  {
    "text": "was one of the more mysterious part of the the research we've done it's something we haven't",
    "start": "2896640",
    "end": "2902160"
  },
  {
    "start": "2898000",
    "end": "3140000"
  },
  {
    "text": "quite understood it's about the beam search you remember the beam search instead of generating",
    "start": "2902160",
    "end": "2907359"
  },
  {
    "text": "just one solution a gen generator collection and so far the way i use bin search was",
    "start": "2907359",
    "end": "2912880"
  },
  {
    "text": "it was a way to cheat or to improve my solution by allowing my machine to have several guesses",
    "start": "2912880",
    "end": "2919440"
  },
  {
    "text": "so if the first guess was wrong i use the beam for the second a third etc and improve the result but what happens if the first",
    "start": "2919440",
    "end": "2925839"
  },
  {
    "text": "guest is correct so here's an example from differential equations so at the top you have the",
    "start": "2925839",
    "end": "2931520"
  },
  {
    "text": "differential equation we used so you see it's a big differential equation",
    "start": "2931520",
    "end": "2936640"
  },
  {
    "text": "and below you have 10 solutions which are the 10 solutions that were in the beam together with a score which is a log",
    "start": "2936640",
    "end": "2943119"
  },
  {
    "text": "probability of the likeliness how how good the model considered they are",
    "start": "2943119",
    "end": "2949680"
  },
  {
    "text": "you can see that the 10 solutions look a bit like well actually they're more than that the first solution is correct but",
    "start": "2949680",
    "end": "2955760"
  },
  {
    "text": "the nine others are two they're all correct solution to the same problem but they're different some of them have",
    "start": "2955760",
    "end": "2961920"
  },
  {
    "text": "different values of the constant some of them are different ways to write the same thing some of them are even",
    "start": "2961920",
    "end": "2969200"
  },
  {
    "text": "unsimplified if you look on the first column the third one there's a square root two and a two that should be simplified but the model",
    "start": "2969200",
    "end": "2976240"
  },
  {
    "text": "didn't it doesn't care about simplification so you provide another one the fun thing is that the beam contents",
    "start": "2976240",
    "end": "2983760"
  },
  {
    "text": "different possible solution to the same problem and this is interesting because our",
    "start": "2983760",
    "end": "2989440"
  },
  {
    "text": "problem have many solutions because of integration constant but also because solution can be written in different",
    "start": "2989440",
    "end": "2994720"
  },
  {
    "text": "ways and those equivalent solution can still be retrieved from the beam",
    "start": "2994720",
    "end": "3000079"
  },
  {
    "text": "which seemed that the machine has learned something it wasn't taught what is what are two equivalent",
    "start": "3000079",
    "end": "3005520"
  },
  {
    "text": "solutions and i'm saying this is mysterious and quite",
    "start": "3005520",
    "end": "3010720"
  },
  {
    "text": "thought provoking because whereas up to now what we have learned were",
    "start": "3010720",
    "end": "3015839"
  },
  {
    "text": "more or less pattern recognition so we try to guess that when you see a sign the interval is a cosine",
    "start": "3015839",
    "end": "3021040"
  },
  {
    "text": "and all that's this property that's values that these different formulas correspond to the same mathematical",
    "start": "3021040",
    "end": "3027920"
  },
  {
    "text": "object are not properties pattern recognition properties they're real mathematical",
    "start": "3027920",
    "end": "3033200"
  },
  {
    "text": "properties it has to do with the meaning of the symbols and this is one one of the things we haven't taught the model so the model",
    "start": "3033200",
    "end": "3040160"
  },
  {
    "text": "somehow learned something about mathematics i'm not saying it's it's like everything but it learns something just from example",
    "start": "3040160",
    "end": "3047359"
  },
  {
    "text": "and without any prior teaching or education say in basic mathematics",
    "start": "3047359",
    "end": "3054079"
  },
  {
    "text": "this is also an important problem because this equivalent problem is what we do most of the time when we",
    "start": "3054079",
    "end": "3059119"
  },
  {
    "text": "do standard mathematics you know when you transform a solution into when you transform an",
    "start": "3059119",
    "end": "3064400"
  },
  {
    "text": "equation you're doing equivalency when you factorize you do one when you simplify you do one",
    "start": "3064400",
    "end": "3070000"
  },
  {
    "text": "so having models learn this kind of property is having them learn some kind",
    "start": "3070000",
    "end": "3077200"
  },
  {
    "text": "of a very fundament something of a very fundamental nature so it's very interesting so i'm at the",
    "start": "3077200",
    "end": "3083839"
  },
  {
    "text": "end of the presentation so to summarize a few takeaways um so the first conclusion is that",
    "start": "3083839",
    "end": "3090079"
  },
  {
    "text": "machine translation models can be used in mathematics we've shown how they can be used in",
    "start": "3090079",
    "end": "3095520"
  },
  {
    "text": "integration they can be used in other directions you can do math with a deep learning",
    "start": "3095520",
    "end": "3100640"
  },
  {
    "text": "network if you do it well the important thing is data generation the only way you can train a model is to",
    "start": "3100640",
    "end": "3106880"
  },
  {
    "text": "have lots of data and to have so much data you need to generate it and data generation is",
    "start": "3106880",
    "end": "3112160"
  },
  {
    "text": "doubly important because not only the key to training it's also the key to generalization if you want to have good",
    "start": "3112160",
    "end": "3117520"
  },
  {
    "text": "generalization then you need to generate diversity by having different generators",
    "start": "3117520",
    "end": "3123440"
  },
  {
    "text": "work together the last point which i just mentioned is that equivalence so the fact that something",
    "start": "3123440",
    "end": "3130319"
  },
  {
    "text": "some different expression can represent the same mathematical object might at some point time be learned for",
    "start": "3130319",
    "end": "3136000"
  },
  {
    "text": "free so that was all the presentation uh as for reference we are we've got a",
    "start": "3136000",
    "end": "3142160"
  },
  {
    "start": "3140000",
    "end": "3191000"
  },
  {
    "text": "paper on archive and all the code and examples and samples can be found on the",
    "start": "3142160",
    "end": "3149359"
  },
  {
    "text": "facebook research github thank you for your attention",
    "start": "3149359",
    "end": "3155119"
  },
  {
    "text": "thank you for the presentation uh this is wonderful it's very it's very interesting that you",
    "start": "3156160",
    "end": "3162640"
  },
  {
    "text": "are able to take a sort of collection of standard problems and discover a lot about",
    "start": "3162640",
    "end": "3168880"
  },
  {
    "text": "how machine learning really works and you know i commend you for your choices i think",
    "start": "3168880",
    "end": "3174400"
  },
  {
    "text": "it's uh it's probably eventually going to evolve into a very useful tool as well",
    "start": "3174400",
    "end": "3181520"
  },
  {
    "text": "[Music] thank you very much",
    "start": "3181520",
    "end": "3192240"
  }
]
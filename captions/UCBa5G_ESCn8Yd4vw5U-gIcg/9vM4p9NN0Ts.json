[
  {
    "start": "0",
    "end": "10000"
  },
  {
    "start": "0",
    "end": "5330"
  },
  {
    "text": "So, let's get started. So I'll be talking about\nbuilding LLMs today. So I think a lot of you have\nheard of LLMs before, but just",
    "start": "5330",
    "end": "14389"
  },
  {
    "start": "10000",
    "end": "16000"
  },
  {
    "text": "as a quick recap. LLMs standing for\nlarge language models are basically all the\nchat bots that you've",
    "start": "14390",
    "end": "21110"
  },
  {
    "start": "19000",
    "end": "76000"
  },
  {
    "text": "been hearing about recently. So, ChatGPT, from OpenAI,\nClaude, from Anthropic, Gemini",
    "start": "21110",
    "end": "28520"
  },
  {
    "text": "and Llama, and other\ntypes of models like this. And today we'll be talking\nabout how do they actually work.",
    "start": "28520",
    "end": "34228"
  },
  {
    "text": "So it's going to be an overview\nbecause it's only one lecture and it's hard to\ncompress everything. But hopefully, I'll\ntouch a little bit",
    "start": "34228",
    "end": "39950"
  },
  {
    "text": "about all the components\nthat are needed to train some of these LLMs. Also, if you have questions,\nplease interrupt me",
    "start": "39950",
    "end": "46310"
  },
  {
    "text": "and ask if you have a question. Most likely other people in\nthe room or on Zoom have other.",
    "start": "46310",
    "end": "52700"
  },
  {
    "text": "Have the same questions. So, please ask. Great. So what matters\nwhen training LLMs.",
    "start": "52700",
    "end": "60080"
  },
  {
    "text": "So there are a few key\ncomponents that matter. One is the architecture. So as you probably all\nLLMs are neural networks,",
    "start": "60080",
    "end": "67390"
  },
  {
    "text": "and when you think\nabout neural networks, you have to think about what\narchitecture you're using. And another component,\nwhich is really important",
    "start": "67390",
    "end": "73770"
  },
  {
    "text": "is the training loss and\nthe training algorithm. So, how you actually train\nthese models, then it's data.",
    "start": "73770",
    "end": "80590"
  },
  {
    "start": "80000",
    "end": "93000"
  },
  {
    "text": "So, what do you train\nthese models on. The evaluation,\nwhich is how do you",
    "start": "80590",
    "end": "86280"
  },
  {
    "text": "know whether you're\nactually making progress towards the goal of LLMs and\nthen, the system component.",
    "start": "86280",
    "end": "93460"
  },
  {
    "start": "93000",
    "end": "101000"
  },
  {
    "text": "So that is like\nhow do you actually make these models run on\nmodern hardware, which",
    "start": "93460",
    "end": "98623"
  },
  {
    "text": "is really important because\nthese models are really large. So now more than ever,\nsystems are actually really an important\ntopic for LLMs.",
    "start": "98623",
    "end": "107160"
  },
  {
    "start": "107000",
    "end": "117000"
  },
  {
    "text": "So those five components, you\nprobably all know that LLMs. And if you don't\nknow LLMs are all",
    "start": "107160",
    "end": "113880"
  },
  {
    "text": "based on transformers\nor at least some version of transformers. I'm actually not going to talk\nabout the architecture today.",
    "start": "113880",
    "end": "120880"
  },
  {
    "start": "120000",
    "end": "182000"
  },
  {
    "text": "One, because I gave a lecture\non transformers a few weeks ago",
    "start": "120880",
    "end": "126329"
  },
  {
    "text": "and two, because you can find\nso much information online on transformers.",
    "start": "126330",
    "end": "131400"
  },
  {
    "text": "There's much less information\nabout the other four topics. So, I really want\nto talk about those.",
    "start": "131400",
    "end": "137370"
  },
  {
    "text": "And another thing to say\nis that most of academia actually focuses on\narchitecture and training",
    "start": "137370",
    "end": "142980"
  },
  {
    "text": "algorithm and\nlosses as academics and I've done that for\na big part of my career,",
    "start": "142980",
    "end": "148810"
  },
  {
    "text": "is simply we like thinking\nthat this is like we make new architectures,\nnew models, and it",
    "start": "148810",
    "end": "155130"
  },
  {
    "text": "seems like it's very important. But in reality, honestly, what\nmatters in practice is mostly the three other topics.",
    "start": "155130",
    "end": "161710"
  },
  {
    "text": "So, data, evaluation and\nsystems, which is what most of industry actually focuses on.",
    "start": "161710",
    "end": "168293"
  },
  {
    "text": "So, that's also\none of the reasons why I don't want to talk too\nmuch about the architecture, because really the rest\nis super important.",
    "start": "168293",
    "end": "175060"
  },
  {
    "text": "Great. So, overview of\nthe lecture, I'll be talking about pretraining. So, pretraining, you\nprobably heard that word.",
    "start": "175060",
    "end": "180880"
  },
  {
    "text": "This is the general word. This is kind of the classical\nlanguage modeling paradigm where",
    "start": "180880",
    "end": "186450"
  },
  {
    "start": "182000",
    "end": "257000"
  },
  {
    "text": "you basically train your\nlanguage model to essentially model all of internet. And then, there's\na post training,",
    "start": "186450",
    "end": "191988"
  },
  {
    "text": "which is a more\nrecent paradigm which is taking these\nlarge language models and making them\nessentially AI assistants.",
    "start": "191988",
    "end": "198060"
  },
  {
    "text": "So, this is more of a\nrecent trend since ChatGPT. So, if you ever heard\nof GPT3 or GPT2,",
    "start": "198060",
    "end": "205090"
  },
  {
    "text": "that's really pretraining land. If you heard of ChatGPT,\nwhich you probably have, this is really\npost training land,",
    "start": "205090",
    "end": "211980"
  },
  {
    "text": "so I'll be talking about both,\nbut I'll start with pretraining and specifically\nI'll talk about what",
    "start": "211980",
    "end": "217470"
  },
  {
    "text": "is the task of pretraining LLMs\nand what is the loss that people actually use.",
    "start": "217470",
    "end": "223110"
  },
  {
    "text": "So, language modeling,\nthis is a quick recap. Language models at a\nhigh level are simply",
    "start": "223110",
    "end": "229350"
  },
  {
    "text": "models of probability\ndistribution over sequences of tokens or of words. So it's basically\nsome model of p of x1",
    "start": "229350",
    "end": "237390"
  },
  {
    "text": "to XL, where x1\nis basically what one and XL is the last one in\nthe sequence or in the sentence.",
    "start": "237390",
    "end": "244230"
  },
  {
    "text": "So, very concretely, if you\nhave a sentence like the mouse ate the cheese, what\nthe language model gives",
    "start": "244230",
    "end": "249629"
  },
  {
    "text": "you is simply a probability\nof this sentence being uttered by a human or\nbeing found online.",
    "start": "249630",
    "end": "257190"
  },
  {
    "start": "257000",
    "end": "315000"
  },
  {
    "text": "So, if you have another sentence\nlike \"The the mouse ate cheese.\" Here, there's\ngrammatical mistakes.",
    "start": "257190",
    "end": "263740"
  },
  {
    "text": "So, the model should\nknow that this should have some syntactic knowledge. So, it should know that\nthis has less likelihood",
    "start": "263740",
    "end": "270120"
  },
  {
    "text": "of appearing online. If you have another sentence\nlike the cheese ate the mouse,",
    "start": "270120",
    "end": "276539"
  },
  {
    "text": "then the model should\nhopefully know about the fact that usually cheese\ndon't eat mouse.",
    "start": "276540",
    "end": "282030"
  },
  {
    "text": "So, there's some\nsemantic knowledge and this is less likely\nthat the first sentence. So, this is basically at a high\nlevel what language models are.",
    "start": "282030",
    "end": "290007"
  },
  {
    "text": "One word that you probably have\nbeen hearing a lot in the news are generative models. So, this is just something\nthat can generate.",
    "start": "290007",
    "end": "296250"
  },
  {
    "text": "Models that can\ngenerate sentences or can generate some data. The reason why we say language\nmodels are generative models",
    "start": "296250",
    "end": "301830"
  },
  {
    "text": "is that once you have a\nmodel of a distribution, you can simply sample\nfrom this model. And now we can generate data.",
    "start": "301830",
    "end": "307950"
  },
  {
    "text": "So we can generate sentences\nusing a language model. So the type of models that\npeople are all currently using",
    "start": "307950",
    "end": "315660"
  },
  {
    "start": "315000",
    "end": "396000"
  },
  {
    "text": "are what we call\nautoregressive language models. And the key idea of\nautoregressive language models",
    "start": "315660",
    "end": "321930"
  },
  {
    "text": "is that you take this\ndistribution over words and you basically decompose\nit into the distribution",
    "start": "321930",
    "end": "329490"
  },
  {
    "text": "of the first word, multiply\nby the distribution of or the likelihood of the\ndistribution of the second word",
    "start": "329490",
    "end": "335370"
  },
  {
    "text": "given the first\nword, and multiply it by P of the third word\ngiven the first two words.",
    "start": "335370",
    "end": "340980"
  },
  {
    "text": "So, there's no\napproximation here. This is just the chain rule\nof probability, which you hopefully you all know about.",
    "start": "340980",
    "end": "346230"
  },
  {
    "text": "Really no approximation. This is just one way of\nmodeling a distribution. So, slightly more\nconcisely, you can write it",
    "start": "346230",
    "end": "352530"
  },
  {
    "text": "as a product of P's of the next\nword, given everything which happened in the past.",
    "start": "352530",
    "end": "358240"
  },
  {
    "text": "So, of the context. So, this is what we call\nautoregressive language models. Again, this is really\nnot the only way",
    "start": "358240",
    "end": "365009"
  },
  {
    "text": "of modeling distribution. This is just one way. It has some benefits\nand some downsides.",
    "start": "365010",
    "end": "370430"
  },
  {
    "text": "One downside of\nautoregressive language models is that when you actually\nsample from this autoregressive language model,\nyou basically have",
    "start": "370430",
    "end": "376650"
  },
  {
    "text": "a for loop, which generates\nthe next word, then conditions on that next word. And then we generate\nin other words.",
    "start": "376650",
    "end": "383050"
  },
  {
    "text": "So, basically if you\nhave a longer sentence that you want to generate, it\ntakes more time to generate it.",
    "start": "383050",
    "end": "388259"
  },
  {
    "text": "So, there are some downsides\nof this current paradigm, but that's what\nwe currently have. So, I'm going to\ntalk about this one.",
    "start": "388260",
    "end": "396090"
  },
  {
    "start": "396000",
    "end": "469000"
  },
  {
    "text": "Great. So, autoregressive\nlanguage models. At a high level, what a task of\nautoregressive language model",
    "start": "396090",
    "end": "401880"
  },
  {
    "text": "is simply predicting the\nnext word, as I just said. So, if we have a sentence\nlike she likely prefers,",
    "start": "401880",
    "end": "407040"
  },
  {
    "text": "one potential, next\nword might be dogs. And the way we do it is\nthat we first tokenize.",
    "start": "407040",
    "end": "414450"
  },
  {
    "text": "So, you take these words or\nsubwords you tokenize them and then you give an\nID for each token.",
    "start": "414450",
    "end": "420850"
  },
  {
    "text": "So here you have\none, two, three. Then, you pass it\nthrough this black box. As I already said,\nwe're not going",
    "start": "420850",
    "end": "426210"
  },
  {
    "text": "to talk about the architecture. You just pass it through,\npass it through a model, and you then get a distribution,\na probability distribution",
    "start": "426210",
    "end": "433740"
  },
  {
    "text": "over the next word or\nover the next token. And then you sample\nfrom this distribution,",
    "start": "433740",
    "end": "440139"
  },
  {
    "text": "you get a new token and\nthen you detokenize. So, you get a new\nID, you detokenize and that's how you basically\nsample from a language model.",
    "start": "440140",
    "end": "448199"
  },
  {
    "text": "One thing which is\nimportant to note is that the last two\nsteps are actually only needed during inference.",
    "start": "448200",
    "end": "454290"
  },
  {
    "text": "When you do training,\nyou just need to predict the most likely\ntoken and you can just compare to the real token\nwhich happened in practice,",
    "start": "454290",
    "end": "461530"
  },
  {
    "text": "and then, you basically\nchange the weights of your model to increase\nthe probability of generating that token.",
    "start": "461530",
    "end": "466895"
  },
  {
    "text": " Great. So, autoregressive\nneural language models.",
    "start": "466895",
    "end": "472450"
  },
  {
    "start": "469000",
    "end": "528000"
  },
  {
    "text": "So to be slightly\nmore specific, still, without talking about\nthe architecture, the first thing we do is\nthat we have all of these.",
    "start": "472450",
    "end": "478890"
  },
  {
    "text": "Sorry, yes. On the previous slide. Predicting the probability\nof the next token, does this mean that your\nfinal output vector has",
    "start": "478890",
    "end": "486030"
  },
  {
    "text": "to be the same dimensionality\nas the number of tokens that you have? Yes. How do you deal with\nif you have more token.",
    "start": "486030",
    "end": "493480"
  },
  {
    "text": "Adding more token\nto your [INAUDIBLE]? Yeah so we're going to\ntalk about tokenization",
    "start": "493480",
    "end": "498490"
  },
  {
    "text": "actually later so you will\nget some sense of this. You basically can deal\nwith adding new tokens.",
    "start": "498490",
    "end": "504920"
  },
  {
    "text": "I'm kind of exaggerating. There are methods for doing\nit, but essentially people don't do it. So it's really\nimportant to think about",
    "start": "504920",
    "end": "512110"
  },
  {
    "text": "how you tokenize your\ntext, and that's why we'll talk about that later. But it's a very\ngood point to note is that you basically--\nthe vocabulary size, so",
    "start": "512110",
    "end": "518620"
  },
  {
    "text": "the number of tokens that\nyou have is essentially the output of your\nlanguage model. So it's actually pretty large.",
    "start": "518620",
    "end": "526000"
  },
  {
    "text": "So autoregressive\nneural language models. First thing you do is that you\ntake every word or every token.",
    "start": "526000",
    "end": "531730"
  },
  {
    "start": "528000",
    "end": "650000"
  },
  {
    "text": "You embed them so you get\nsome vector representation for each of these tokens.",
    "start": "531730",
    "end": "538130"
  },
  {
    "text": "You pass them through some\nneural network, as we said, it's a transformer. Then you get a representation\nfor all the word",
    "start": "538130",
    "end": "544630"
  },
  {
    "text": "and all the words\nin the context. So it's basically\na representation of the entire sentence.",
    "start": "544630",
    "end": "549790"
  },
  {
    "text": "You pass it through\na linear layer, as you just said, to\nbasically map it to the number",
    "start": "549790",
    "end": "555810"
  },
  {
    "text": "so that the output--\nthe number of outputs is the number of tokens. You then pass it\nthrough some softmax",
    "start": "555810",
    "end": "561560"
  },
  {
    "text": "and you basically get a\nprobability distribution over the next words given\nevery word in the context.",
    "start": "561560",
    "end": "570290"
  },
  {
    "text": "And the last that you\nuse is basically-- it's essentially a task of\nclassifying the next token.",
    "start": "570290",
    "end": "575370"
  },
  {
    "text": "So it's a very simple, kind\nof, machine learning task. So you use the\ncross-entropy loss. Where you basically look at the\nactual target that happened,",
    "start": "575370",
    "end": "584145"
  },
  {
    "text": "which is the target\ndistribution, which is a one hot encoding,\nwhich in this case says, I saw the real word\nthat happened is cat.",
    "start": "584145",
    "end": "591899"
  },
  {
    "text": "So that's a one hot\ndistribution over cat. And here this is the actual--",
    "start": "591900",
    "end": "597522"
  },
  {
    "text": "do you see my mouse? Oh, yeah. This is the distribution\nthat you generated. And basically you\ndo cross entropy, which really just increases the\nprobability of generating cat",
    "start": "597522",
    "end": "604492"
  },
  {
    "text": "and decreases all the\nprobability of generating all the other tokens. One thing to notice is\nthat, as you all know again,",
    "start": "604492",
    "end": "611540"
  },
  {
    "text": "this is just equivalent\nto maximizing the text log likelihood because\nyou can just rewrite",
    "start": "611540",
    "end": "617959"
  },
  {
    "text": "the max over the probability\nof this autoregressive language",
    "start": "617960",
    "end": "623180"
  },
  {
    "text": "modeling task as just being\nthis minimum of I just added the log here\nand minus, which",
    "start": "623180",
    "end": "629042"
  },
  {
    "text": "is just the minimum of the loss,\nwhich is the cross entropy loss. So basically\nminimizing the loss is the same thing as maximizing\nthe likelihood of your text.",
    "start": "629042",
    "end": "636750"
  },
  {
    "text": "Any question? Questions? ",
    "start": "636750",
    "end": "643230"
  },
  {
    "text": "OK, tokenizer. So this is one thing\nthat people usually",
    "start": "643230",
    "end": "649400"
  },
  {
    "text": "don't talk that much about. Tokenizers are\nextremely important. So it's really important that\nyou understand at least what",
    "start": "649400",
    "end": "656540"
  },
  {
    "start": "650000",
    "end": "810000"
  },
  {
    "text": "they do at a high level. So why do we need tokenizers\nin the first place? First, it's more\ngeneral than words.",
    "start": "656540",
    "end": "662970"
  },
  {
    "text": "So one simple thing\nthat you might think is we're just going to take\nevery word that we will have. You just say every word\nis a token in its own.",
    "start": "662970",
    "end": "671060"
  },
  {
    "text": "But then what happens is if\nthere's a typo in your word? Then you might not have\nany token associated",
    "start": "671060",
    "end": "677390"
  },
  {
    "text": "with this word with a typo. And then you don't know\nhow to actually pass this word with a typo into\na large language model.",
    "start": "677390",
    "end": "684459"
  },
  {
    "text": "So what do you do next? And also, even if you think\nabout words, words is a very--",
    "start": "684460",
    "end": "689470"
  },
  {
    "text": "words are fine with\nLatin-based languages. But if you think about\na language like Thai,",
    "start": "689470",
    "end": "694610"
  },
  {
    "text": "you won't have a simple\nway of tokenizing by spaces because there are\nno spaces between words. So really, tokens are much\nmore general than words.",
    "start": "694610",
    "end": "703270"
  },
  {
    "text": "It's the first thing. Second thing that\nyou might think is that you might tokenize\nevery sentence, character",
    "start": "703270",
    "end": "708660"
  },
  {
    "text": "by character. You might say A is one\ntoken, B is another token. That would actually work\nand probably very well.",
    "start": "708660",
    "end": "715360"
  },
  {
    "text": "The issue is that then your\nsequence becomes super long. And as you probably\nremember from the lecture",
    "start": "715360",
    "end": "720600"
  },
  {
    "text": "on transformers, the\ncomplexity grows quadratically with the length of sequences.",
    "start": "720600",
    "end": "726820"
  },
  {
    "text": "So you really don't want to\nhave a super-long sequence. So tokenizers basically try to\ndeal with those two problems",
    "start": "726820",
    "end": "734610"
  },
  {
    "text": "and give common subsequences\na certain token. And usually how you should be\nthinking about it is around",
    "start": "734610",
    "end": "742530"
  },
  {
    "text": "an average of every token\nis around 3-4 letters.",
    "start": "742530",
    "end": "747580"
  },
  {
    "text": "And there are many\nalgorithms for tokenization. I'll just talk about one of them\nto give you a high level, which",
    "start": "747580",
    "end": "752820"
  },
  {
    "text": "is what we call Byte Pair\nEncoding, which is actually a pretty common. One of the two most\ncommon tokenizers. And the way that you\ntrain a tokenizer",
    "start": "752820",
    "end": "759750"
  },
  {
    "text": "is that first you start with\na very large corpus of text. And here, I'm really not talking\nabout training a large language",
    "start": "759750",
    "end": "765240"
  },
  {
    "text": "model yet, this is purely\nfor the tokenization step. So this is my large corpus of\ntext with these five words.",
    "start": "765240",
    "end": "772050"
  },
  {
    "text": "And then you associate\nevery character in this corpus of text\na different token.",
    "start": "772050",
    "end": "778769"
  },
  {
    "text": "So here, I just split\nit up every character with a different\ntoken, and I just color coded all of those tokens.",
    "start": "778770",
    "end": "785760"
  },
  {
    "text": "And then what you do is that\nyou go through your text, and every time you see pairs\nof tokens that are very common,",
    "start": "785760",
    "end": "792519"
  },
  {
    "text": "the most common pair of\ntoken, you just merge them. So here you see three\ntimes the tokens t and o",
    "start": "792520",
    "end": "799860"
  },
  {
    "text": "next to each other. So you're just going to\nsay this is a new token. And then you continue,\nyou repeat that. So now you have tok, tok\nwhich happens three times.",
    "start": "799860",
    "end": "808510"
  },
  {
    "text": "Toke with an E that\nhappens 2 times and token,",
    "start": "808510",
    "end": "813730"
  },
  {
    "start": "810000",
    "end": "960000"
  },
  {
    "text": "which happens twice, and then\nex which also happens twice. So this is the-- if you were to\ntrain a tokenizer on this corpus",
    "start": "813730",
    "end": "821370"
  },
  {
    "text": "of text, which is\nvery small, that's how you would finish\nwith a token-- with like trained tokenizer.",
    "start": "821370",
    "end": "827580"
  },
  {
    "text": "In reality, you do it on\nmuch larger corpus of text. And this is the\nreal tokenizer of--",
    "start": "827580",
    "end": "834810"
  },
  {
    "text": "actually, I think this\nis GPT3 or ChatGPT. And here you see how it would\nactually separate these words.",
    "start": "834810",
    "end": "840460"
  },
  {
    "text": "So basically you\nsee the same thing as what we gave in\nthe previous example. Token becomes its own token.",
    "start": "840460",
    "end": "846459"
  },
  {
    "text": "So tokenizer is\nactually split it up into two tokens token and -izer.",
    "start": "846460",
    "end": "852660"
  },
  {
    "text": "So yeah, that's all\nabout tokenizers. Any questions on that? Yeah. How do you deal with\nspaces, and how do you",
    "start": "852660",
    "end": "858502"
  },
  {
    "text": "deal with [INAUDIBLE]. Yeah so actually there's\na step before tokenizers,",
    "start": "858502",
    "end": "863560"
  },
  {
    "text": "which is what we call\npre-tokenizers, which is exactly what you just said. So this is mostly--",
    "start": "863560",
    "end": "869460"
  },
  {
    "text": "in theory, there's no reason to\ndeal with spaces and punctuation separately. You could just say every\nspace gets its own token,",
    "start": "869460",
    "end": "877030"
  },
  {
    "text": "every punctuation\ngets its own token, and you can just\ndo all the merging.",
    "start": "877030",
    "end": "882350"
  },
  {
    "text": "The problem is that-- so\nthere's an efficiency question. Actually, training these\ntokenizers takes a long time.",
    "start": "882350",
    "end": "888120"
  },
  {
    "text": "So you better-- because you have\nto consider every pair of token. So what you end up doing is\nsaying if there's a space,",
    "start": "888120",
    "end": "894200"
  },
  {
    "text": "this is very--\nlike pre-tokenizers are very English specific. You say if there's\na space, we're not going to start looking\nat the token that came before",
    "start": "894200",
    "end": "901410"
  },
  {
    "text": "and the token that\ncame afterwards. So you're not merging\nin between spaces. But this is just like a\ncomputational optimization.",
    "start": "901410",
    "end": "910060"
  },
  {
    "text": "You could theoretically\njust deal with it the same way as you deal\nwith any other character.",
    "start": "910060",
    "end": "915160"
  },
  {
    "text": "And-- Yeah. When you merge tokens to delete\nthe tokens that you merged away or do you keep the smaller\ntokens that emerge?",
    "start": "915160",
    "end": "922950"
  },
  {
    "text": "You actually keep\nthe smaller tokens. I mean, in reality, it doesn't\nmatter much because usually",
    "start": "922950",
    "end": "929850"
  },
  {
    "text": "on a large corpus of text, you\nwill have actually everything. But you usually\nkeep the small ones. And the reason why\nyou want to do that",
    "start": "929850",
    "end": "936213"
  },
  {
    "text": "is because if-- in case there's,\nas we said before, you have some grammatical\nmistakes or some typos,",
    "start": "936213",
    "end": "941759"
  },
  {
    "text": "you still want to\nbe able to represent these words by character. So, yeah.",
    "start": "941760",
    "end": "947730"
  },
  {
    "text": "Yes. Are the tokens unique? So I mean, say in this case\nT-O-K-E-N is there only one",
    "start": "947730",
    "end": "954990"
  },
  {
    "text": "occurrence or could-- do you need to leave multiple\noccurrence so they could have--",
    "start": "954990",
    "end": "960120"
  },
  {
    "start": "960000",
    "end": "1250000"
  },
  {
    "text": "take on different\nmeanings or something? Oh I see what you say. No, it's every token\nhas its own unique ID.",
    "start": "960120",
    "end": "968399"
  },
  {
    "text": "So a usual-- this\nis a great question. For example, if you\nthink about a bank, which could be bank for like\nmoney or bank like water,",
    "start": "968400",
    "end": "976199"
  },
  {
    "text": "it will have the same token. But the model will\nlearn, the transformer will learn that based on the\nwords that are around it,",
    "start": "976200",
    "end": "982750"
  },
  {
    "text": "it should associate that-- I'm saying-- I'm being\nvery handwavy here, but associate that with\na representation that",
    "start": "982750",
    "end": "990420"
  },
  {
    "text": "is either more like the bank\nmoney side or the bank water side. But that's a transformer\nthat does that.",
    "start": "990420",
    "end": "996370"
  },
  {
    "text": "It's not a tokenizer. Yes. Yes. So you mentioned\nduring tokenization, keep the smaller tokens\nyou started with, right.",
    "start": "996370",
    "end": "1003210"
  },
  {
    "text": "Like if you start with\na T you keep the T and then you build\nyour tokenize out to [INAUDIBLE] allow input token.",
    "start": "1003210",
    "end": "1009570"
  },
  {
    "text": "So let's say maybe you didn't\ntrain on token, but in your data you are trying to encode token.",
    "start": "1009570",
    "end": "1014970"
  },
  {
    "text": "So how does the tokenizer know\nto encode it with token or to [INAUDIBLE]? Yeah. The great question.",
    "start": "1014970",
    "end": "1020682"
  },
  {
    "text": "You basically when you--\nso when you tokenize, so that's after training\nof the tokenizer when you actually\napply the tokenizer",
    "start": "1020682",
    "end": "1026550"
  },
  {
    "text": "you basically always\nchoose the largest token that you can apply. So if you can do token,\nyou will never do T,",
    "start": "1026550",
    "end": "1033639"
  },
  {
    "text": "you will always do token. But there's actually--\nso people don't usually talk that much about\ntokenizers, but there's",
    "start": "1033640",
    "end": "1040589"
  },
  {
    "text": "a lot of computational benefits\nor computational tricks that you can do for making\nthese things faster.",
    "start": "1040589",
    "end": "1047189"
  },
  {
    "text": "So I really don't think\nwe-- and honestly, I think a lot of people think\nthat we should just get away from tokenizers and just\nkind of tokenize character",
    "start": "1047190",
    "end": "1054450"
  },
  {
    "text": "by character or bytes by bytes. But as I said, right now\nthere's this issue of length,",
    "start": "1054450",
    "end": "1059710"
  },
  {
    "text": "but maybe one day, like\nin five or 10 years, we will have different\narchitectures that don't scale quadratically\nwith the length of the sequence.",
    "start": "1059710",
    "end": "1066145"
  },
  {
    "text": "And maybe we'll move\naway from tokenizers. So can you share\nwith us the drawback?",
    "start": "1066145",
    "end": "1073030"
  },
  {
    "text": "Why do people want to move\naway from the tokenizer? Yeah.",
    "start": "1073030",
    "end": "1078140"
  },
  {
    "text": "So I think one good\nexample is math.",
    "start": "1078140",
    "end": "1083350"
  },
  {
    "text": "If you think about math,\nactually numbers right now are not tokenized. So for example, 327 might\nhave its own token, which",
    "start": "1083350",
    "end": "1090640"
  },
  {
    "text": "means that models,\nwhen they see numbers, they don't see them\nthe same way as we do. And this is very\nannoying because I mean,",
    "start": "1090640",
    "end": "1097640"
  },
  {
    "text": "the reason why we can\ngeneralize with math is because we can deal with\nevery letter separately and we can then do composition.",
    "start": "1097640",
    "end": "1104289"
  },
  {
    "text": "Where you know that\nbasically if you add stuff, it's the same thing as\nadding every one separately plus like whatever\nthe unit that you add.",
    "start": "1104290",
    "end": "1110920"
  },
  {
    "text": "So they can't do that. So then you have to do\nspecial tokenization. And, like, one of the\nbig changes that GPT4 did",
    "start": "1110920",
    "end": "1119650"
  },
  {
    "text": "is changing the way\nthat they tokenize code. So for example, if you have\ncode, you know you have often,",
    "start": "1119650",
    "end": "1126100"
  },
  {
    "text": "in Python, these four\nspaces at the beginning. Those were dealt with\nstrangely before.",
    "start": "1126100",
    "end": "1132260"
  },
  {
    "text": "And as a result, like,\nthe model couldn't really understand how to\ndeal with code.",
    "start": "1132260",
    "end": "1137870"
  },
  {
    "text": "So tokenize actually\nmatter a lot. OK, so I'll move on right now,\nbut we can come back later",
    "start": "1137870",
    "end": "1144190"
  },
  {
    "text": "on tokenizers. Great. So we talked about a task\nthe loss the tokenizer, let's talk a little\nbit about evaluation.",
    "start": "1144190",
    "end": "1151480"
  },
  {
    "text": "So the way that LLMs\nare usually evaluated is what we call-- is using\nwhat we call perplexity.",
    "start": "1151480",
    "end": "1156910"
  },
  {
    "text": "At a high level it's basically\njust your validation loss. The slight difference\nwith perplexity",
    "start": "1156910",
    "end": "1161980"
  },
  {
    "text": "is that we use something that\nis slightly more interpretable, which is that we use the\naverage per token loss,",
    "start": "1161980",
    "end": "1167710"
  },
  {
    "text": "and then you exponentiate it. And the reason why\nyou exponentiate it is because you want-- I mean, the loss has\na log inside and you--",
    "start": "1167710",
    "end": "1175312"
  },
  {
    "text": "like one humans\nare actually pretty bad at thinking in log space. But two logs depend\non the base of the log",
    "start": "1175312",
    "end": "1181120"
  },
  {
    "text": "while when you exponentiate\nyou basically have everything in the vocabulary size unit.",
    "start": "1181120",
    "end": "1188440"
  },
  {
    "text": "And the average per\ntoken is just so that your perplexity is\nindependent of the length of your sequence.",
    "start": "1188440",
    "end": "1194170"
  },
  {
    "text": "So perplexity is just\ntwo to the power average of the loss of the sequence.",
    "start": "1194170",
    "end": "1200050"
  },
  {
    "text": "So perplexity is between one\nand the length of the vocabulary of your tokenizer.",
    "start": "1200050",
    "end": "1205780"
  },
  {
    "text": "One it's simply well,\nif you predict perfectly the thing which every\nword, then every word",
    "start": "1205780",
    "end": "1211570"
  },
  {
    "text": "will have basically\nproducts of ones. So the best perplexity\nyou can have is one.",
    "start": "1211570",
    "end": "1216680"
  },
  {
    "text": "If you really have no\nidea, you basically predict with one divided\nby size of vocabulary",
    "start": "1216680",
    "end": "1222205"
  },
  {
    "text": "and then you do simple\nmath and you basically get perplexity of\nsize of vocabulary. So the intuition\nof perplexity is",
    "start": "1222205",
    "end": "1228520"
  },
  {
    "text": "that it's basically\nthe number of tokens that your model is, kind\nof, hesitating between. So if your model is perfect,\nit doesn't hesitate.",
    "start": "1228520",
    "end": "1235610"
  },
  {
    "text": "It know exactly the word. If it really has\nno idea, then it hesitates between all\nof the vocabulary.",
    "start": "1235610",
    "end": "1243730"
  },
  {
    "text": "So perplexity really improved. That's perplexity on a standard\ndata set between 2017 and 2023.",
    "start": "1243730",
    "end": "1250750"
  },
  {
    "start": "1250000",
    "end": "1470000"
  },
  {
    "text": "It went from a kind of 70\ntokens to less than 10 tokens over these five, six years.",
    "start": "1250750",
    "end": "1256610"
  },
  {
    "text": "So that means that the\nmodels were previously stated between 70 words every\ntime it was generating a word,",
    "start": "1256610",
    "end": "1262550"
  },
  {
    "text": "and now it's hesitating\nbetween less than 10 words. So that's much better. Perplexity is actually\nnot used anymore",
    "start": "1262550",
    "end": "1268840"
  },
  {
    "text": "in academic benchmarking,\nmostly because it depends on the tokenizer that you use. It depends on the actual data\nthat people are evaluating on.",
    "start": "1268840",
    "end": "1276169"
  },
  {
    "text": "But it's still very important\nfor development of LLMs. So when you actually\ntrain your own LLM people",
    "start": "1276170",
    "end": "1281740"
  },
  {
    "text": "will still really look\nat the perplexity. One common other way and\nnow more common in academia",
    "start": "1281740",
    "end": "1290260"
  },
  {
    "text": "of evaluating these LLMs is just\nby taking all the classical NLP benchmarks, and I'll give you\na few examples later and just,",
    "start": "1290260",
    "end": "1297340"
  },
  {
    "text": "kind of, aggregating everything. So collect as many automatically\nevaluatable benchmarks",
    "start": "1297340",
    "end": "1303100"
  },
  {
    "text": "and just evaluate\nacross all of them. So one such-- or\nactually two such",
    "start": "1303100",
    "end": "1310240"
  },
  {
    "text": "benchmarks are what we call\nHELM, which is from Stanford. And another one is the\nHugging Face open leaderboard,",
    "start": "1310240",
    "end": "1316640"
  },
  {
    "text": "which are probably the two\nmost common ones right now. So just to give you\nan idea, in HELM,",
    "start": "1316640",
    "end": "1322899"
  },
  {
    "text": "all of these type\nof tasks, which are mostly things that\ncan be easily evaluated",
    "start": "1322900",
    "end": "1328390"
  },
  {
    "text": "like question answering. So think about many different\nquestion answering tasks. And the benefit with\nquestion answering",
    "start": "1328390",
    "end": "1335350"
  },
  {
    "text": "is that you usually know\nwhat is the real answer. So you can-- the way that\nyou evaluate these models",
    "start": "1335350",
    "end": "1340509"
  },
  {
    "text": "and I'll give you a concrete\nexample in one second, is that you can just look at\nhow likely the language model is",
    "start": "1340510",
    "end": "1346870"
  },
  {
    "text": "to generate the real answer\ncompared to some other answers. And that's essentially,\nat a high level,",
    "start": "1346870",
    "end": "1351970"
  },
  {
    "text": "how you evaluate these models. So to give you a\nspecific example, MMLU is probably the most common\nacademic benchmark for LLMs.",
    "start": "1351970",
    "end": "1362000"
  },
  {
    "text": "And this is just a\ncollection of many question and answers in all\nof those domains.",
    "start": "1362000",
    "end": "1367620"
  },
  {
    "text": "For example, college\nmedicine, college physics, astronomy and these\ntype of topics.",
    "start": "1367620",
    "end": "1372660"
  },
  {
    "text": "And the questions are things\nlike, so this is in astronomy. What is true for\ntype-1a supernova?",
    "start": "1372660",
    "end": "1378300"
  },
  {
    "text": "Then you give four\ndifferent potential answers and you just ask the model\nwhich one is more likely.",
    "start": "1378300",
    "end": "1384840"
  },
  {
    "text": "So there are many\ndifferent ways of doing it. Either you can look at the\nlikelihood of generating all these answers, or\nyou can ask the model",
    "start": "1384840",
    "end": "1391670"
  },
  {
    "text": "which one is the most likely. So there are different ways\nthat you can prompt the model, but at a high level, you\nknow which one is correct.",
    "start": "1391670",
    "end": "1397620"
  },
  {
    "text": "And there are three\nother mistakes. Yes. Creating unconstrained\ntext as an output.",
    "start": "1397620",
    "end": "1404909"
  },
  {
    "text": "Yeah. How do you evaluate\na model if it gives something that's\nsemantically completely",
    "start": "1404910",
    "end": "1411410"
  },
  {
    "text": "identical, but is not the\nexact tokens that you expect? Yeah. So that's a great question.",
    "start": "1411410",
    "end": "1417390"
  },
  {
    "text": "I'll talk more about that later. Here, in this case, we\ndon't do unconstrained. So the way you would evaluate\nMMLU is basically either",
    "start": "1417390",
    "end": "1424669"
  },
  {
    "text": "you ask the first\nquestion, and then you look at the likelihood of\nthe model generating A,",
    "start": "1424670",
    "end": "1430220"
  },
  {
    "text": "the likelihood of the model\ngenerating B, C, and D and you look at which\none is the most likely.",
    "start": "1430220",
    "end": "1435480"
  },
  {
    "text": "Or you can ask the\nmodel out of A, B, C, D, which one is the most likely. And you look at whether the\nmost likely next token is A, B,",
    "start": "1435480",
    "end": "1443070"
  },
  {
    "text": "C, or D. So you\nconstrain the model to say it can only\nanswer these four things.",
    "start": "1443070",
    "end": "1449000"
  },
  {
    "text": "You say you constraint-- Yeah. You constrain the\nprompt or do you mean of its whole\nprobability distribution",
    "start": "1449000",
    "end": "1455240"
  },
  {
    "text": "that it outputs\nyou only comparing the outputs of like-- you're\nonly comparing the A token the [INAUDIBLE].",
    "start": "1455240",
    "end": "1460400"
  },
  {
    "text": "Yeah. So in the second case I gave\nyou, you would do exactly the-- actually would do both.",
    "start": "1460400",
    "end": "1465450"
  },
  {
    "text": "You would prompt the\nmodel saying A, B, C, or D plus you would constrain to\nonly look at these four tokens.",
    "start": "1465450",
    "end": "1472049"
  },
  {
    "start": "1470000",
    "end": "6271000"
  },
  {
    "text": "In the first case, you don't\neven need to generate anything. So in the first case,\nyou literally just look, given it's\na language model,",
    "start": "1472050",
    "end": "1478050"
  },
  {
    "text": "it can give a distribution\nover sentences. You just look at what is\nthe likelihood of generating",
    "start": "1478050",
    "end": "1483530"
  },
  {
    "text": "all of these words? What is the likelihood of\ngenerating the second choice? And you just look at whether the\nmost likely sentence is actually",
    "start": "1483530",
    "end": "1492620"
  },
  {
    "text": "the real answer. So you don't actually\nsample from it, you really just\nuse P of X1 to XL.",
    "start": "1492620",
    "end": "1499520"
  },
  {
    "text": "Does that make sense? That being said, evaluation\nof open-ended questions",
    "start": "1499520",
    "end": "1505035"
  },
  {
    "text": "is something we're going\nto talk about later, and it's actually\nreally important and really challenging. Yes.",
    "start": "1505035",
    "end": "1510929"
  },
  {
    "text": "Earlier you mentioned\n[INAUDIBLE] metrics like perplexity\nare not I usually",
    "start": "1510930",
    "end": "1516740"
  },
  {
    "text": "use because it\ndepends on how you do your tokenization,\nsome design choices. I was wondering if you\ncould speak more to that.",
    "start": "1516740",
    "end": "1524480"
  },
  {
    "text": "Yeah. So think about perplexity. I told you perplexity is\nbetween 1 and vocabulary size.",
    "start": "1524480",
    "end": "1530130"
  },
  {
    "text": "So now imagine that ChatGPT\nuses a tokenizer that has 10,000 tokens but Gemini from Google\nuses a tokenizer that had",
    "start": "1530130",
    "end": "1538340"
  },
  {
    "text": "100,000 potential tokens. Then actually the Gemini one\nwill have the upper bound",
    "start": "1538340",
    "end": "1545870"
  },
  {
    "text": "of the perplexity that you can\nget is actually worse for Gemini than for ChatGPT.",
    "start": "1545870",
    "end": "1550940"
  },
  {
    "text": "Does that make sense? So that's just an idea. It's actually a little bit\nmore complicated than that, but that's just one\nfestival with a bit",
    "start": "1550940",
    "end": "1558140"
  },
  {
    "text": "of where you can see that the\ntokenizer actually matters. Great.",
    "start": "1558140",
    "end": "1565529"
  },
  {
    "text": "OK, so evaluation challenges. There are many. I'll just talk about\ntwo really briefly.",
    "start": "1565530",
    "end": "1570690"
  },
  {
    "text": "One, as I told you, there are\ntwo ways of doing evaluation for these MMLUs. Actually, there are\nmany more than two",
    "start": "1570690",
    "end": "1576070"
  },
  {
    "text": "but I gave you two examples. And it happens that\nfor a long time, even though that was a\nvery classical benchmark",
    "start": "1576070",
    "end": "1582270"
  },
  {
    "text": "that everyone uses actually\ndifferent companies and different\norganizations were actually",
    "start": "1582270",
    "end": "1592140"
  },
  {
    "text": "using different ways\nof evaluating MMLU. And as a result, you get\ncompletely different results.",
    "start": "1592140",
    "end": "1597910"
  },
  {
    "text": "For example, Llama-65b, which\nwas the first model of meta in the llama series, had\non HELM 63.7 accuracy",
    "start": "1597910",
    "end": "1607809"
  },
  {
    "text": "but on this other\nbenchmark had like 48.8.",
    "start": "1607810",
    "end": "1613050"
  },
  {
    "text": "So really the way that you\nevaluate, and this is not even talking about prompting\nthis is really just the way",
    "start": "1613050",
    "end": "1618840"
  },
  {
    "text": "that you evaluate the models. Prompting is another issue. So really, there are a\nlot of inconsistencies.",
    "start": "1618840",
    "end": "1624610"
  },
  {
    "text": "It's not as easy as it looks. First thing. Yeah, sorry. How can we make sure\nthat all these models",
    "start": "1624610",
    "end": "1630610"
  },
  {
    "text": "are trained on the benchmark? Second thing. This is a great question. Train test contamination.",
    "start": "1630610",
    "end": "1637360"
  },
  {
    "text": "This is something\nwhich I would say is really important\nin academia in--",
    "start": "1637360",
    "end": "1644170"
  },
  {
    "text": "given that the talk is mostly\nabout training large language models, for companies, it's\nmaybe not that important",
    "start": "1644170",
    "end": "1649720"
  },
  {
    "text": "because they know\nwhat they trained on. For us, we have no idea.",
    "start": "1649720",
    "end": "1655360"
  },
  {
    "text": "So, for us, it's a real problem. So there are many\ndifferent ways of trying to test whether the test set--",
    "start": "1655360",
    "end": "1662658"
  },
  {
    "text": "or sorry, whether the\ntest set was actually in the training set. One, kind of, cute trick\nthat people in the lab,",
    "start": "1662658",
    "end": "1671770"
  },
  {
    "text": "in [? Tatsuo's ?] lab have\nfound, is that what you can do is that given that most\nof the data set online",
    "start": "1671770",
    "end": "1677020"
  },
  {
    "text": "are not randomized,\nyou can just look at-- and that language models,\nwhat they do is just",
    "start": "1677020",
    "end": "1682090"
  },
  {
    "text": "predict the next word. You can just look at\nthe entire test set. What if you generate\nall the examples",
    "start": "1682090",
    "end": "1689410"
  },
  {
    "text": "in order versus all the\nexamples in a different order. And if it's more likely to\ngenerate a thing in order, given",
    "start": "1689410",
    "end": "1697420"
  },
  {
    "text": "that there's no\nreal order there, then it means that probably\nit was in the training set. Does that make sense?",
    "start": "1697420",
    "end": "1703060"
  },
  {
    "text": "So there are many--\nthat's like one of them. There are many other\nways of doing it. Train test\ncontamination, again, not",
    "start": "1703060",
    "end": "1708332"
  },
  {
    "text": "that important for development,\nreally important for academic benchmarking. Great.",
    "start": "1708333",
    "end": "1713500"
  },
  {
    "text": "So there are many\nother challenges, but I'll move on for now. Great. Data.",
    "start": "1713500",
    "end": "1720250"
  },
  {
    "text": "So data is another\nreally big topic. At a high level people\njust say you basically",
    "start": "1720250",
    "end": "1725890"
  },
  {
    "text": "train large language\nmodels on all of internet. What does that even mean? So people sometimes say,\nwell, of clean internet,",
    "start": "1725890",
    "end": "1733159"
  },
  {
    "text": "which is even less defined. So internet is very dirty\nand really not representative",
    "start": "1733160",
    "end": "1739509"
  },
  {
    "text": "of what we want in practice. If I download a random\nwebsite right now, you would be shocked\nat what is in there.",
    "start": "1739510",
    "end": "1746000"
  },
  {
    "text": "It's definitely\nnot your Wikipedia. So I'll go really briefly\non what people do.",
    "start": "1746000",
    "end": "1754029"
  },
  {
    "text": "I can answer some\nquestions, but I mean, data is on its own\nit's a huge topic.",
    "start": "1754030",
    "end": "1759190"
  },
  {
    "text": "Basically, first what you do\nis download all of internet. What that means is that\nyou use web crawlers that",
    "start": "1759190",
    "end": "1765970"
  },
  {
    "text": "will go on every web page, on\ninternet or every web page that is on Google.",
    "start": "1765970",
    "end": "1771500"
  },
  {
    "text": "And that is around 250\nbillion pages right now. And that's around\n1 petabyte of data.",
    "start": "1771500",
    "end": "1779460"
  },
  {
    "text": "So this is actually a Common\nCrawl is one web crawler. So people don't usually\nwrite their own web crawlers",
    "start": "1779460",
    "end": "1785120"
  },
  {
    "text": "what they do is that they\nuse standard web crawlers, and Common Crawl is one of them\nthat basically every month adds",
    "start": "1785120",
    "end": "1791929"
  },
  {
    "text": "all the new websites that were\nadded on internet that are found by Google, and they put it in\na big basically a big data set.",
    "start": "1791930",
    "end": "1800630"
  },
  {
    "text": "So that's-- on Common Crawl, you\nhave around 250 billion pages right now. So 1E6 gigabytes of data.",
    "start": "1800630",
    "end": "1807920"
  },
  {
    "text": "Once you have this-- so this is a random web page. Like literally random\nfrom this Common Crawl.",
    "start": "1807920",
    "end": "1814485"
  },
  {
    "text": "And what you see is\nthat one, it really doesn't look at type of things\nthat you would usually see, but actually-- so\nthis is an HTML page.",
    "start": "1814485",
    "end": "1821419"
  },
  {
    "text": "It's hard to see, but\nif you look through will see some content.",
    "start": "1821420",
    "end": "1826470"
  },
  {
    "text": "For example, here,\nTest King World is your ultimate source for\nthe system x high performance",
    "start": "1826470",
    "end": "1833919"
  },
  {
    "text": "server. And then you have three dots. So you don't even-- the\nsentence is not even finished. That's how random\ninternet looks like.",
    "start": "1833920",
    "end": "1840950"
  },
  {
    "text": "So, of course, it's\nnot that useful if you just train a\nlarge language model to generate things like this. So what are some of the\nsteps that are needed?",
    "start": "1840950",
    "end": "1848090"
  },
  {
    "text": "First one, you extract\nthe text from the HTML. So that's what I just\ntried to do by looking at basically the correct tags.",
    "start": "1848090",
    "end": "1855440"
  },
  {
    "text": "There are a lot of\nchallenges through this. For example, extracting\nmath is actually very complicated, but pretty\nimportant for training",
    "start": "1855440",
    "end": "1862340"
  },
  {
    "text": "large language models. Or for example, boilerplates. A lot of your forums will\nhave the same type of headers,",
    "start": "1862340",
    "end": "1868380"
  },
  {
    "text": "the same type of footers. You don't want to repeat\nall of this in your data, and then you will filter\nundesirable content.",
    "start": "1868380",
    "end": "1876740"
  },
  {
    "text": "So not safe for work,\nharmful content, PII. So usually every\ncompany has basically",
    "start": "1876740",
    "end": "1882710"
  },
  {
    "text": "a blacklist of websites\nthat they don't want to train their models on. That blacklist is very\nlong and you basically",
    "start": "1882710",
    "end": "1890030"
  },
  {
    "text": "say if it comes from there,\nwe don't train on this. There are other ways\nof doing these things. Is that you can train a small\nmodel for classifying what",
    "start": "1890030",
    "end": "1896810"
  },
  {
    "text": "is PII, removing these things. It's hard. Every point here that\nI'm going to show you",
    "start": "1896810",
    "end": "1902750"
  },
  {
    "text": "is a hard amount of\nwork, but I'm just going to go quickly through it.",
    "start": "1902750",
    "end": "1908429"
  },
  {
    "text": "So filter undesirable content. Second or fourth\nis de-duplication.",
    "start": "1908430",
    "end": "1914010"
  },
  {
    "text": "As I said, you might have\nthings like headers and footers in forums that are\nalways the same.",
    "start": "1914010",
    "end": "1919920"
  },
  {
    "text": "You want to remove that. Another thing that\nyou might have is a lot of URLs that are\ndifferent, but actually show",
    "start": "1919920",
    "end": "1925790"
  },
  {
    "text": "the same website. And you might also have a lot of\nparagraphs that come from common",
    "start": "1925790",
    "end": "1933530"
  },
  {
    "text": "books that are basically\nde-duplicated 1,000 times or 10,000 times on internet. So you have to de-duplicated.",
    "start": "1933530",
    "end": "1940010"
  },
  {
    "text": "Also very challenging because\nyou have to do that at scale. Once you do the\nde-duplication, you",
    "start": "1940010",
    "end": "1946250"
  },
  {
    "text": "will do some\nheuristic filtering. You will try to remove\nlow-quality documents.",
    "start": "1946250",
    "end": "1951380"
  },
  {
    "text": "The way you do that are things\nlike rules-based filtering. For example, if you see that\nthere are some outlier tokens.",
    "start": "1951380",
    "end": "1957780"
  },
  {
    "text": "If the distribution of\ntokens in the website is very different than the\nusual distribution of tokens, then it's probably some outlier.",
    "start": "1957780",
    "end": "1963510"
  },
  {
    "text": "If you see that the length\nof the words in this website is super long, there's something\nstrange going on that website.",
    "start": "1963510",
    "end": "1969370"
  },
  {
    "text": "If you see that the website\nhas only three words, maybe, is it worth\ntraining on it. Maybe not.",
    "start": "1969370",
    "end": "1974660"
  },
  {
    "text": "If it has 10 million words,\nmaybe there's something also wrong going on that page.",
    "start": "1974660",
    "end": "1980299"
  },
  {
    "text": "So a lot of rules like this. Yes. Why do we filter out\nundesirable content from our data set instead\nof putting it in as,",
    "start": "1980300",
    "end": "1988310"
  },
  {
    "text": "like, a supervised loss? Can we not just say, here's\nthis like, hate speech website,",
    "start": "1988310",
    "end": "1994500"
  },
  {
    "text": "let's actively try to-- let's actively penalize\nthe model for getting it.",
    "start": "1994500",
    "end": "1999890"
  },
  {
    "text": "We'll do exactly that,\nbut not at this step. That's why the post-training\nwill come from.",
    "start": "1999890",
    "end": "2005590"
  },
  {
    "text": "Pretraining the\nidea is just to say I want to model, kind of, how\nhumans speak, essentially.",
    "start": "2005590",
    "end": "2014460"
  },
  {
    "text": "And I want to remove all\nthese headers, footers and menus and things like this. But it's a very good\nidea that you just had.",
    "start": "2014460",
    "end": "2021760"
  },
  {
    "text": "And that's exactly\nwhat we'll do later. Next step,\nmodel-based filtering.",
    "start": "2021760",
    "end": "2027190"
  },
  {
    "text": "So once you filter a lot\nof data, what you will do-- that's actually a\nvery cute trick. You will take all\nof Wikipedia and you",
    "start": "2027190",
    "end": "2034140"
  },
  {
    "text": "will look at all\nthe links that are linked through Wikipedia pages. Because probably if something\nis referenced by Wikipedia,",
    "start": "2034140",
    "end": "2041080"
  },
  {
    "text": "it's probably some\nhigh-quality website. And you will train a classifier\nto predict whether something",
    "start": "2041080",
    "end": "2047040"
  },
  {
    "text": "comes from-- whether a\ndocument comes from one of these references\nfrom Wikipedia",
    "start": "2047040",
    "end": "2053190"
  },
  {
    "text": "or whether it's\nfrom the random web. And you will try\nto basically say, I want more of the things that\ncome from Wikipedia references.",
    "start": "2053190",
    "end": "2061629"
  },
  {
    "text": "Does that make sense? So yeah. So you will train a\nmachine learning model. Usually also very simple\nmodels because you",
    "start": "2061630",
    "end": "2068609"
  },
  {
    "text": "need to do that really at scale. I mean, just think about\nthe 250 billion pages.",
    "start": "2068610",
    "end": "2074138"
  },
  {
    "text": "Next one, you will try\nto classify your data into different domains.",
    "start": "2074139",
    "end": "2081020"
  },
  {
    "text": "You will say, OK, this is\nentertainment, this is books, this is code, this is like\nthese type of domains.",
    "start": "2081020",
    "end": "2086388"
  },
  {
    "text": "And then you will try to\neither up or down weight some of the domains.",
    "start": "2086389",
    "end": "2092620"
  },
  {
    "text": "For example, you might say-- you might see that actually if\nyou train more on code, then actually your model becomes\nbetter on reasoning.",
    "start": "2092620",
    "end": "2099320"
  },
  {
    "text": "So that's something that\npeople usually say in a very hand-wavy way. If you train your\nmodel more on code,",
    "start": "2099320",
    "end": "2104393"
  },
  {
    "text": "actually it helps reasoning. So you want to update\nthe coding distribution because that helps for general\nlanguage modeling skills.",
    "start": "2104393",
    "end": "2111640"
  },
  {
    "text": "Books is usually also another\none that people usually update. Entertainment, they\nusually down weight.",
    "start": "2111640",
    "end": "2118720"
  },
  {
    "text": "So things like this. Of course, you want to do it--\nso people used to do it, maybe",
    "start": "2118720",
    "end": "2124000"
  },
  {
    "text": "kind of heuristically. Now there's entire\npipelines that we'll talk about of how to do\nthese things slightly",
    "start": "2124000",
    "end": "2130240"
  },
  {
    "text": "more automatically. And then at the end of\ntraining, you usually train--",
    "start": "2130240",
    "end": "2137910"
  },
  {
    "text": "after training on all\nof this data that we saw you usually train on\nvery high quality data at the end of training your\nlarge language model where you",
    "start": "2137910",
    "end": "2146340"
  },
  {
    "text": "decrease your learning rate. And that basically\nmeans that you're, kind of, overfitting your model\non a very high quality data.",
    "start": "2146340",
    "end": "2152859"
  },
  {
    "text": "So usually what you\ndo there is Wikipedia. You basically\noverfit on Wikipedia",
    "start": "2152860",
    "end": "2157890"
  },
  {
    "text": "and you overfit on, like,\nhuman data that was collected.",
    "start": "2157890",
    "end": "2164190"
  },
  {
    "text": "The other thing is like\ncontinual pretraining for getting longer context. I'm going to skip over\nall of these things.",
    "start": "2164190",
    "end": "2169996"
  },
  {
    "text": "But that's just to give\nyou a sense of how hard it is when people just say I'm\ngoing to train on internet,",
    "start": "2169997",
    "end": "2175230"
  },
  {
    "text": "that's a lot of work. And, really, we haven't\nfigured it out yet. So collecting well\ndata is a huge part",
    "start": "2175230",
    "end": "2183300"
  },
  {
    "text": "of practical, large\nlanguage model. Some might say that\nit's actually the key. Yes. [INAUDIBLE] about data.",
    "start": "2183300",
    "end": "2189040"
  },
  {
    "text": "So basic question. So usually when you start\nwith like a petabyte of data, after you go through\nall the steps,",
    "start": "2189040",
    "end": "2195190"
  },
  {
    "text": "what's the typical amount\nof data you have remaining. And then how large a\nteam does it typically",
    "start": "2195190",
    "end": "2200940"
  },
  {
    "text": "take to go through all the\ndata steps you talked about? Sorry how la-- is your\nquestion how large is the data after you filter?",
    "start": "2200940",
    "end": "2206920"
  },
  {
    "text": "Yeah. After you filter and then\nyou go through all the steps. How large a team do you\nneed to go through, like,",
    "start": "2206920",
    "end": "2212250"
  },
  {
    "text": "all the filtration\nsteps you mentioned. How slow is it or-- How many people\nwould you need to be",
    "start": "2212250",
    "end": "2220260"
  },
  {
    "text": "able to do this [INAUDIBLE]? OK that's a great question. I'm going to somewhat\nanswer about the data.",
    "start": "2220260",
    "end": "2226590"
  },
  {
    "text": "How large is the data set\nat the end of this slide. For number of people that work\non it, that's a good question.",
    "start": "2226590",
    "end": "2235600"
  },
  {
    "text": "I'm actually not quite\nsure, but I would say, yeah, I actually don't\nquite know but I",
    "start": "2235600",
    "end": "2242520"
  },
  {
    "text": "would say it's probably even\nbigger than the number of people that work on the tuning of\nthe pretraining of the model.",
    "start": "2242520",
    "end": "2249810"
  },
  {
    "text": "So the data is bigger\nthan the modeling aspect. Yeah, I don't think\nI have a good sense.",
    "start": "2249810",
    "end": "2257950"
  },
  {
    "text": "I would say probably in LLAMA's\nteam, which have 70-ish people, I would say maybe\n15 work on data.",
    "start": "2257950",
    "end": "2265200"
  },
  {
    "text": "Yeah. All these things, you don't\nneed that many people, you need a lot of compute also. Because for data you\nneed a lot of CPUs.",
    "start": "2265200",
    "end": "2272760"
  },
  {
    "text": "So, yeah. And I'll answer\nthe second question at the end of this slide. So as I just, kind\nof, alluded to really,",
    "start": "2272760",
    "end": "2279910"
  },
  {
    "text": "we haven't solved data\nat all for pretraining. So there's a lot of research\nthat has to be done. First, how do you process\nthese things super efficiently?",
    "start": "2279910",
    "end": "2287250"
  },
  {
    "text": "Second, how do you\nbalance kind of all of these different domains? Can you do synthetic\ndata generation?",
    "start": "2287250",
    "end": "2292510"
  },
  {
    "text": "That's actually a\nbig one right now. And because we don't have-- we'll talk about that\nlater, but we don't have",
    "start": "2292510",
    "end": "2298050"
  },
  {
    "text": "enough data on the internet. Can you use multimodal data\ninstead of just text data?",
    "start": "2298050",
    "end": "2303790"
  },
  {
    "text": "And how does that improve\neven your text performance? There's a lot of secrecy\nbecause, really, this",
    "start": "2303790",
    "end": "2310140"
  },
  {
    "text": "is the key of most of the\npretraining large language models. So for competitive dynamics,\nusually these companies",
    "start": "2310140",
    "end": "2319550"
  },
  {
    "text": "don't talk about how they\ndo the data collection. And also there's a\ncopyright liability issue. They definitely don't\nwant to tell you",
    "start": "2319550",
    "end": "2325070"
  },
  {
    "text": "that they've trained on\nbooks even though they did because if not can sue them.",
    "start": "2325070",
    "end": "2330530"
  },
  {
    "text": "Common academic benchmarks. So that will, kind of,\nanswer what you asked. It started-- so those\nare the smaller ones.",
    "start": "2330530",
    "end": "2337595"
  },
  {
    "text": "The names are not\nthat important, but it started from around\n$150 billion tokens, which are around 800 gigabytes of data.",
    "start": "2337595",
    "end": "2344520"
  },
  {
    "text": "And now it's around\n15 trillion-- 15 trillion tokens,\nwhich is also the size of the models that\nare-- right now the best models",
    "start": "2344520",
    "end": "2352587"
  },
  {
    "text": "are probably trained\non that amount of data. So 15 trillion tokens,\nwhich is probably,",
    "start": "2352587",
    "end": "2358457"
  },
  {
    "text": "I guess, two orders of\nmagnitude bigger than that. So 80E3 gigabyte.",
    "start": "2358457",
    "end": "2363720"
  },
  {
    "text": "So that would be around 100\nto 1,000 times filtering",
    "start": "2363720",
    "end": "2369380"
  },
  {
    "text": "of the Common Crawl,\nif I'm not mistaken. So, yeah.",
    "start": "2369380",
    "end": "2374480"
  },
  {
    "text": "One very famous one is the Pile. So this is an academic\nbenchmark, the Pile. And we can just look at what\ndistribution of data they have.",
    "start": "2374480",
    "end": "2382500"
  },
  {
    "text": "It's things like\narchive, PubMed Central, which is all the biology stuff.",
    "start": "2382500",
    "end": "2390140"
  },
  {
    "text": "Here it's Wikipedia, you see\nStack Exchange, some GitHub",
    "start": "2390140",
    "end": "2395779"
  },
  {
    "text": "and some books and\nthings like this. Again, this is on\nthe smaller side. So this is-- if we look at here,\nthis is on 280B so, in reality,",
    "start": "2395780",
    "end": "2403297"
  },
  {
    "text": "it's like 100 times bigger\nso you cannot have that much of GitHub and of Wikipedia.",
    "start": "2403298",
    "end": "2409280"
  },
  {
    "text": "In terms of closed\nsource models. Just to give you\nan idea, Llama 2",
    "start": "2409280",
    "end": "2414590"
  },
  {
    "text": "it was trained on\n2 trillion tokens, Llama 3 15 trillion\ntokens, which is currently",
    "start": "2414590",
    "end": "2419840"
  },
  {
    "text": "the best model that we know\non how much it was trained on, which is the same thing as is\nthe best academic or the biggest",
    "start": "2419840",
    "end": "2426980"
  },
  {
    "text": "academic benchmark, which\nis 15 trillion tokens. GPT4 we don't really\nbut it's probably in the same order of magnitude\nor it's probably around that.",
    "start": "2426980",
    "end": "2433660"
  },
  {
    "text": "Actually, it's probably\naround 13 from leaks. If the leaks are true.",
    "start": "2433660",
    "end": "2439860"
  },
  {
    "text": "Great. So scaling laws. Any other questions on data\nbefore we go to scaling laws?",
    "start": "2439860",
    "end": "2445839"
  },
  {
    "text": " Sorry I know I'm giving\nyou a lot of information,",
    "start": "2445840",
    "end": "2451069"
  },
  {
    "text": "but there's a lot into\ntraining, large language models. Great scaling laws.",
    "start": "2451070",
    "end": "2456760"
  },
  {
    "text": "So the idea is that what people\nsaw around 2020, or at least from a long time, but they've\nbeen able to theoretically show",
    "start": "2456760",
    "end": "2465520"
  },
  {
    "text": "it or empirically\nshow it since 2020, is that the more data\nyou train your models on and the larger the models,\nthe better the performance.",
    "start": "2465520",
    "end": "2472547"
  },
  {
    "text": "This is actually pretty\ndifferent than what you've seen in this class. In this class we teach\nyou about overfitting.",
    "start": "2472548",
    "end": "2477660"
  },
  {
    "text": "Overfitting doesn't happen\nwith large language models. Larger models,\nbetter performance.",
    "start": "2477660",
    "end": "2483490"
  },
  {
    "text": "It's something that\nreally took a long time for the community who took\nthis type of class to realize.",
    "start": "2483490",
    "end": "2489880"
  },
  {
    "text": "But for the exam,\noverfitting exists. So, OK, the idea of scaling loss\nis that if-- given that more",
    "start": "2489880",
    "end": "2498520"
  },
  {
    "text": "data and larger\nmodels will always give you better\nperformance, can we predict how much better\nyour performance will",
    "start": "2498520",
    "end": "2506140"
  },
  {
    "text": "be if you increase the amount of\ndata and the size of your model? And surprisingly, it works.",
    "start": "2506140",
    "end": "2512540"
  },
  {
    "text": "So here you see three plots\nfrom a very famous paper called Scaling Laws from OpenAI.",
    "start": "2512540",
    "end": "2517760"
  },
  {
    "text": "Here you see on\nthe x-axis compute. So how much did you train-- like, how much compute did\nyou spend for training?",
    "start": "2517760",
    "end": "2524010"
  },
  {
    "text": "And here you see test loss. So this is essentially,\nI mean, perplexity, but it's your validation loss.",
    "start": "2524010",
    "end": "2529490"
  },
  {
    "text": "So it's a log of the perplexity. And if you put these\ntwo on log scale,",
    "start": "2529490",
    "end": "2535050"
  },
  {
    "text": "then you see that the\nperformance or the-- sorry, the scaling\nlaw is linear.",
    "start": "2535050",
    "end": "2542540"
  },
  {
    "text": "That means that if you\nincrease your compute by a certain amount, you can say\nby how much your test loss will",
    "start": "2542540",
    "end": "2549050"
  },
  {
    "text": "actually decrease. Same thing with data and\nsame thing for parameters. If you increase\nthe data set size,",
    "start": "2549050",
    "end": "2555510"
  },
  {
    "text": "your loss will\ndecrease by an amount that is somewhat predictable. If you increase the\nnumber of parameters,",
    "start": "2555510",
    "end": "2562730"
  },
  {
    "text": "the loss will\ndecrease by an amount, which is somewhat predictable. This is really amazing.",
    "start": "2562730",
    "end": "2567980"
  },
  {
    "text": "Very surprising. I mean, it looks innocuous when\nyou look at these type of plots, but that's crazy because it\nmeans that you can predict",
    "start": "2567980",
    "end": "2575210"
  },
  {
    "text": "how well we're going to\nperform in two or three years, depending on how much\ncompute we will add, assuming that these\nthings will hold.",
    "start": "2575210",
    "end": "2581630"
  },
  {
    "text": "There's nothing\ntheoretical about it. Yes. Two things. One, what is the loss\nthat they're using here.",
    "start": "2581630",
    "end": "2588387"
  },
  {
    "text": "Is this perplexity? So it's-- I said perplexity was\nlike 2 to the power of the loss.",
    "start": "2588387",
    "end": "2593440"
  },
  {
    "text": "So this is the power\nof the perplexity. And then the second\nthing is, when",
    "start": "2593440",
    "end": "2599119"
  },
  {
    "text": "you increase the\nnumber of parameters or you increase the data\nset size [INAUDIBLE] data [INAUDIBLE] times, doesn't\nthat just inherently",
    "start": "2599120",
    "end": "2606693"
  },
  {
    "text": "increase your compute? Like does all of this\n[INAUDIBLE] come to just how [INAUDIBLE] you [INAUDIBLE]? Yes. --or something\nspecific [INAUDIBLE]?",
    "start": "2606693",
    "end": "2612500"
  },
  {
    "text": "No, this is a great question. So the compute here is actually\na factor of two things, the data and the parameter.",
    "start": "2612500",
    "end": "2618180"
  },
  {
    "text": "What I'm showing here\nis that you can-- well, actually, we're going\nto talk about that in details. But basically, if you increase\nthe number of parameters,",
    "start": "2618180",
    "end": "2624450"
  },
  {
    "text": "you should increase the\nnumber of data that you have. So you actually don't\ngo multiple times",
    "start": "2624450",
    "end": "2630079"
  },
  {
    "text": "to the same data set. No one does epochs\nin at least not yet",
    "start": "2630080",
    "end": "2636020"
  },
  {
    "text": "because we haven't still\nkind of enough data. So yeah, this is\nall the same trend,",
    "start": "2636020",
    "end": "2641700"
  },
  {
    "text": "which is increase\ncompute decrease loss. Yes. Have we seen the numbers for\nthe last two years or this",
    "start": "2641700",
    "end": "2649531"
  },
  {
    "text": "is still holding? It is still holding. I don't have good\nnumbers to show you,",
    "start": "2649531",
    "end": "2656390"
  },
  {
    "text": "but it is still\nholding, surprisingly. Yes.",
    "start": "2656390",
    "end": "2661660"
  },
  {
    "text": "Is there no evidence that\ncontrol quality density will ever plateau? In theory, we would expect\nit plateau, [INAUDIBLE]?",
    "start": "2661660",
    "end": "2668650"
  },
  {
    "text": "No empirical evidence of\nplateauing anytime soon. Why?",
    "start": "2668650",
    "end": "2674080"
  },
  {
    "text": "We don't know. Will it happen? Probably. I mean, it doesn't need\nto because it's actually",
    "start": "2674080",
    "end": "2679940"
  },
  {
    "text": "in log scale. So it's not like\nas if it had to go. It had to plateau. Like mathematically, it could\ncontinue decreasing like this.",
    "start": "2679940",
    "end": "2687362"
  },
  {
    "text": "I mean, most people think\nthat it will probably plateau at some point. We don't know when. ",
    "start": "2687362",
    "end": "2694480"
  },
  {
    "text": "So that's-- I'll talk more\nabout scaling laws now. So why are scaling\nlaws really cool?",
    "start": "2694480",
    "end": "2699970"
  },
  {
    "text": "Imagine that I gave you-- you're very fortunate I gave\nyou 10,000 GPUs for this month.",
    "start": "2699970",
    "end": "2705490"
  },
  {
    "text": "What model will you train? How do you even go about\nanswering that question? And I mean, this\nis a hypothetical,",
    "start": "2705490",
    "end": "2712430"
  },
  {
    "text": "but that's exactly what these\ncompanies are faced with. The old pipeline,\nwhich was basically",
    "start": "2712430",
    "end": "2719680"
  },
  {
    "text": "tune hyperparameters\non the big models. So let's say I have\n30 days, I will train 30 models for one day each.",
    "start": "2719680",
    "end": "2726800"
  },
  {
    "text": "I will pick the best one and\nthat will be the final model that I will use in production.",
    "start": "2726800",
    "end": "2732140"
  },
  {
    "text": "That means that the model\nthat I actually used was only trained for one day. The new pipeline is that you\nfirst find a scaling recipe.",
    "start": "2732140",
    "end": "2740369"
  },
  {
    "text": "So you find something that\ntells you, for example, like one common thing\nis that if you increase the size of your model, you\nshould decrease your learning",
    "start": "2740370",
    "end": "2746930"
  },
  {
    "text": "rate. So you find a\nscaling recipe such that you know if I increase\nthe size of my model,",
    "start": "2746930",
    "end": "2752790"
  },
  {
    "text": "here's what I should do\nwith some hyperparameters. Then you tune your\nhyperparameters on smaller models\nof different sizes.",
    "start": "2752790",
    "end": "2760650"
  },
  {
    "text": "Let's say I will say for\nthree days, of my 30 days, I will train many\ndifferent models. And I will do\nhyperparameter tuning",
    "start": "2760650",
    "end": "2767090"
  },
  {
    "text": "on these small models,\neach of different sizes. Then I will fit a\nscaling law and try to extrapolate from these\nsmaller models, which",
    "start": "2767090",
    "end": "2775670"
  },
  {
    "text": "one will be the best if I\ntrain it for much longer-- or sorry if I train\nit for a larger model.",
    "start": "2775670",
    "end": "2782970"
  },
  {
    "text": "And then I will train\nthe final huge model for 27 days instead\nof just one day.",
    "start": "2782970",
    "end": "2788180"
  },
  {
    "text": "So the new pipeline\nis not train things or do hyperparameter tuning\non the real scale of the model",
    "start": "2788180",
    "end": "2794088"
  },
  {
    "text": "that you're going\nto use in practice, but do things on smaller\nones at different scales.",
    "start": "2794088",
    "end": "2799500"
  },
  {
    "text": "Try to predict how\nwell they will perform once you make them bigger. I will give-- I will give you a\nvery concrete example right now.",
    "start": "2799500",
    "end": "2806450"
  },
  {
    "text": "Let's say transformers\nversus LSTMs. Let's say you have\nthese 10,000 GPUs,",
    "start": "2806450",
    "end": "2811822"
  },
  {
    "text": "you are not sure which\none you should be using. Should I be using a\ntransformer-based model or LSTM-based model. What I will do is I\nwill train transformers",
    "start": "2811822",
    "end": "2818930"
  },
  {
    "text": "at different scales. So here you see different\nparameters on the x-axis, y-axis is my test source.",
    "start": "2818930",
    "end": "2824460"
  },
  {
    "text": "I will then train different\nLSTMs at different scales. Once I have these points,\nI will see oh it, kind of,",
    "start": "2824460",
    "end": "2831140"
  },
  {
    "text": "fits a scaling law. I will fit my\nscaling law and then I will be able to predict if\nI had 10 times more compute,",
    "start": "2831140",
    "end": "2838860"
  },
  {
    "text": "here's how well I would\nperform for the LSTM. It's actually slightly\nless linear for the LSTM, but you can probably try to\npredict where you would end up.",
    "start": "2838860",
    "end": "2846750"
  },
  {
    "text": "And clearly from this\nplot, you would see that transformers are better. One thing to notice when you\nread these type of scaling laws",
    "start": "2846750",
    "end": "2853370"
  },
  {
    "text": "is that there are two\nthings that are important. One is really your\nscaling rate, which",
    "start": "2853370",
    "end": "2860360"
  },
  {
    "text": "is the slope of the-- the\nslope of the scaling law.",
    "start": "2860360",
    "end": "2865740"
  },
  {
    "text": "The other thing\nis your intercept, you could start\nworse, but actually",
    "start": "2865740",
    "end": "2872180"
  },
  {
    "text": "become better over time. It just happens that\nLSTMs are worse for both. But I could show you\nanother one where things--",
    "start": "2872180",
    "end": "2878690"
  },
  {
    "text": "you can predict that actually\nafter a certain scale you're better off using that\ntype of model than others.",
    "start": "2878690",
    "end": "2884390"
  },
  {
    "text": "So that's why scaling laws\nare actually really useful. Any questions on that?",
    "start": "2884390",
    "end": "2892100"
  },
  {
    "text": "Yeah. So these are all,\nkind of, very-- how sensitive are these to small\ndifferences in the architecture.",
    "start": "2892100",
    "end": "2898920"
  },
  {
    "text": "Like one like\ntransformer architecture versus another\ntransformer architecture. Do you think we have\nto fit your own curve",
    "start": "2898920",
    "end": "2906220"
  },
  {
    "text": "and, basically, say like oh\nscaling laws tell me this should be some logarithmic function.",
    "start": "2906220",
    "end": "2911330"
  },
  {
    "text": "Like, let me\nextrapolate that for my own specific architecture. Yeah, so usually, for\nexample, if you're an academic",
    "start": "2911330",
    "end": "2918140"
  },
  {
    "text": "and you want to-- now at\nleast that's pretty recent and you want to propose\na new activation.",
    "start": "2918140",
    "end": "2923717"
  },
  {
    "text": "That's exactly what you will do. You will fit a scaling law,\nshow another scaling law with the standard\nlike, I don't GELU",
    "start": "2923717",
    "end": "2929413"
  },
  {
    "text": "and you will say\nthat it's better. In reality, once you start\nthinking about it in scaling laws terms, you really\nrealize that actually",
    "start": "2929413",
    "end": "2935553"
  },
  {
    "text": "all the architecture\ndifferences that we can make, like the small,\nminor ones, all they do is maybe change a little\nbit the intercept.",
    "start": "2935553",
    "end": "2943160"
  },
  {
    "text": "But really that doesn't\nmatter because just train it for 10 hours longer or\nlike wait for the next computer",
    "start": "2943160",
    "end": "2949700"
  },
  {
    "text": "GPUs and these things\nare really secondary. Which is exactly why I was\ntelling you originally, people spend too much time on\nthe architecture and losses.",
    "start": "2949700",
    "end": "2957090"
  },
  {
    "text": "In reality, these things\ndon't matter as much. Data though. If you use good data, you will\nhave much better scaling laws",
    "start": "2957090",
    "end": "2963119"
  },
  {
    "text": "than if you use bad data. So that really matters. Another really cool thing\nyou can do with scaling laws",
    "start": "2963120",
    "end": "2969630"
  },
  {
    "text": "is that you can ask yourself,\nhow to optimally allocate training resources.",
    "start": "2969630",
    "end": "2975130"
  },
  {
    "text": "Should I train larger models. Because we saw that it's better\nwhen you train larger models, but we saw that it's also\nbetter when you use more data.",
    "start": "2975130",
    "end": "2982359"
  },
  {
    "text": "So which one should I do? Should I just train on\nmore data, a smaller model, or should I train a\nlarger model on less data?",
    "start": "2982360",
    "end": "2989340"
  },
  {
    "text": "So Chinchilla is a very famous\npaper that first showed this. The way they did it,\nI want to give you",
    "start": "2989340",
    "end": "2995760"
  },
  {
    "text": "a little bit of a sense\nof what these plots are. Here you see training\nloss again on the x-axis,",
    "start": "2995760",
    "end": "3000869"
  },
  {
    "text": "you see parameter differences,\nsorry, parameter size-- number of parameters. So the size of the model.",
    "start": "3000870",
    "end": "3006119"
  },
  {
    "text": "And here all these\ncurves are what we call ISO flops, which is that\nall the models on this curve",
    "start": "3006120",
    "end": "3013930"
  },
  {
    "text": "have been trained with the\nsame amount of compute. The way that you do\nthat is that you train--",
    "start": "3013930",
    "end": "3019230"
  },
  {
    "text": "you change. Sorry, you vary the number of\ntokens that were trained on and the size of the models,\nbut you vary in such a way",
    "start": "3019230",
    "end": "3025010"
  },
  {
    "text": "that the total compute\nis constant, OK. So all these curves that you\nsee with different colors have different amount of\ncompute that were trained on.",
    "start": "3025010",
    "end": "3032520"
  },
  {
    "text": "Then you take the best one\nfor each of those curves. Once you have the best one\nfor each of those curves,",
    "start": "3032520",
    "end": "3038630"
  },
  {
    "text": "you can ask-- you can\nplot how much flops it was",
    "start": "3038630",
    "end": "3044150"
  },
  {
    "text": "and which curve were you\non and how much parameters did you actually use for\ntraining that specific point.",
    "start": "3044150",
    "end": "3050820"
  },
  {
    "text": "You put that on the log\nlog scale again and now you fit a scaling law again.",
    "start": "3050820",
    "end": "3056970"
  },
  {
    "text": "So now I have something\nwhich tells me if I want to train a model of 10\nto the power 23 flops, here is",
    "start": "3056970",
    "end": "3063740"
  },
  {
    "text": "exactly the number of parameters\nthat I should be using. 100 B. And you can do the same\nthing with flops and tokens.",
    "start": "3063740",
    "end": "3071300"
  },
  {
    "text": "So now you can predict-- if I tell you exactly I\nhave one month of compute,",
    "start": "3071300",
    "end": "3076660"
  },
  {
    "text": "what size of model\nshould I be training? Fit the scaling\nlaw, and I tell you.",
    "start": "3076660",
    "end": "3081910"
  },
  {
    "text": "Of course that all\nlooks beautiful. In reality like there's a\nlot of small things of like,",
    "start": "3081910",
    "end": "3086960"
  },
  {
    "text": "should you be counting,\nlike, embedding parameters, there's a lot of complexities. But if you do things well,\nthese things actually do hold.",
    "start": "3086960",
    "end": "3095290"
  },
  {
    "text": "So the optimal number of\nparameters that Chinchilla paper have found is to use 20\ntokens for every parameter",
    "start": "3095290",
    "end": "3102730"
  },
  {
    "text": "that you train. So if you add one\nmore parameter, you should train your thing on--\nyour model on 20 more tokens.",
    "start": "3102730",
    "end": "3109300"
  },
  {
    "text": "So one caveat here is that this\nis optimal training resources. So that is telling me if you\nhave 10 to the power, 23 flops",
    "start": "3109300",
    "end": "3117099"
  },
  {
    "text": "or if you have 100, I don't know\nhow much that is, $100 million or 10-- no, that's\nmuch less, actually.",
    "start": "3117100",
    "end": "3122870"
  },
  {
    "text": "Let's say I have\n$5 million to train my best model that\ngets the lowest loss what would I train on?",
    "start": "3122870",
    "end": "3129710"
  },
  {
    "text": "In reality, these companies need\nto think about inference also. If you have a smaller model,\nthey will spend less over time.",
    "start": "3129710",
    "end": "3137750"
  },
  {
    "text": "So actually, if you\nconsider the inference cost, you have other papers that\ntry to show that, it's",
    "start": "3137750",
    "end": "3143000"
  },
  {
    "text": "around 150 parameters, sorry-- tokens per parameters, because\nyou prefer having a smaller",
    "start": "3143000",
    "end": "3149930"
  },
  {
    "text": "model because over\ntime you're going to actually spend less money\non inference of these models.",
    "start": "3149930",
    "end": "3157560"
  },
  {
    "text": "So 150 to 1, that's around what\nthe best models are trained on right now, at least\nthe ones that are",
    "start": "3157560",
    "end": "3165109"
  },
  {
    "text": "used in practice in production. Great.",
    "start": "3165110",
    "end": "3171760"
  },
  {
    "text": "Any questions on Chinchilla? Great.",
    "start": "3171760",
    "end": "3176790"
  },
  {
    "text": "Oh sorry. In practice, how expensive\nis inference for these models relative to training?",
    "start": "3176790",
    "end": "3183390"
  },
  {
    "text": "Actually, very expensive. I will not talk about\ninference because that would be another entire lecture.",
    "start": "3183390",
    "end": "3189010"
  },
  {
    "text": "But just think\nabout ChatGPT where they have I don't know\nhow much it is now,",
    "start": "3189010",
    "end": "3194080"
  },
  {
    "text": "like 600 million\npeople that use it. Like, that's a lot.",
    "start": "3194080",
    "end": "3202470"
  },
  {
    "text": "Yeah. So it's actually very expensive. There's a lot of optimization\nyou can do for inference though. And that's an entire\nother lecture.",
    "start": "3202470",
    "end": "3209079"
  },
  {
    "text": "I'm going to skip that this\ntime, but it's very interesting. OK tunings.",
    "start": "3209080",
    "end": "3214922"
  },
  {
    "text": "As I said, there are\nmany things that you can answer with scaling laws. I just try to give\nyou two examples,",
    "start": "3214922",
    "end": "3220920"
  },
  {
    "text": "but really there\nare many things. What data do you use. What mixture-- what data\nmixing weighting you use.",
    "start": "3220920",
    "end": "3226650"
  },
  {
    "text": "The mixtures, that's what\nwe talked about before. What architecture you use,\nwhether you should make your models wider or deeper?",
    "start": "3226650",
    "end": "3234030"
  },
  {
    "text": "Should you be\npaying for more GPUs or actually\ncollecting more data? All these things are\nthings you can try",
    "start": "3234030",
    "end": "3240550"
  },
  {
    "text": "to answer with scaling laws. One thing I want to say\nis the bitter lesson.",
    "start": "3240550",
    "end": "3245630"
  },
  {
    "text": "If you ever heard\nof Richard Sutton, very famous blog post in\n2019, what he realized,",
    "start": "3245630",
    "end": "3252880"
  },
  {
    "text": "which I think not\nenough people realize, I didn't-- definitely did\nnot realize at that time,",
    "start": "3252880",
    "end": "3259900"
  },
  {
    "text": "is that once you see these type\nof scaling laws you know that the more compute you have, the\nbetter models you will get.",
    "start": "3259900",
    "end": "3266240"
  },
  {
    "text": "So with scale, you\nwill get better model. And you also know by\nMoore's law or these type of variants of Moore's\nlaw that you will always",
    "start": "3266240",
    "end": "3273099"
  },
  {
    "text": "have better compute. Then the only thing\nthat matters is just to have architectures that\ncan leverage computation.",
    "start": "3273100",
    "end": "3280010"
  },
  {
    "text": "So what matters is basically\nsystems data and less so the architecture, like\nthe small architecture",
    "start": "3280010",
    "end": "3286240"
  },
  {
    "text": "differences like, your\nactivation and things like this. So I think that's one of the\nreasons why most of research",
    "start": "3286240",
    "end": "3292270"
  },
  {
    "text": "focuses on some things that\nfor industry matters less. And I was one of\nthose researchers",
    "start": "3292270",
    "end": "3298330"
  },
  {
    "text": "for a large part of my career. So don't spend time\nover complicating.",
    "start": "3298330",
    "end": "3304840"
  },
  {
    "text": "Do the simple\nthings, do it well. See all them. That's really what OpenAI taught\nus with ChatGPT and with all",
    "start": "3304840",
    "end": "3312670"
  },
  {
    "text": "the GPTs before. OK, I want to give you some back\nof the envelope computation.",
    "start": "3312670",
    "end": "3318950"
  },
  {
    "text": "So I might be off by\na few factors here, but I just want to give you\na sense of how costly it is to train some of these models.",
    "start": "3318950",
    "end": "3325359"
  },
  {
    "text": "I'll give us an example. llama3 400b which is currently\nthe best open source model that you can get.",
    "start": "3325360",
    "end": "3331660"
  },
  {
    "text": "It was trained on 15.6 tokens. It has 405 billion parameters.",
    "start": "3331660",
    "end": "3337880"
  },
  {
    "text": "So just now that\nyou know what is like this optimal tokens per\nparameter, that's around 40.",
    "start": "3337880",
    "end": "3343290"
  },
  {
    "text": "So that's a little bit\nmore than Chinchilla, but less than this like\ninference optimal model.",
    "start": "3343290",
    "end": "3350630"
  },
  {
    "text": "So they went for\ntraining optimallity Flops for this model. So one simple way\nto compute flops",
    "start": "3350630",
    "end": "3357759"
  },
  {
    "text": "is 6 times the\nnumber of parameters, times the number of\ndata that you train on.",
    "start": "3357760",
    "end": "3363010"
  },
  {
    "text": "So if you do the simple\ncalculation here, it's 3.8 e25 flops. The reason why this\nis important is",
    "start": "3363010",
    "end": "3369279"
  },
  {
    "text": "that if you follow it\na little bit, the news, there's an executive order\nfrom Biden that basically says that once you have one e26\nparameters, sorry, flops, then",
    "start": "3369280",
    "end": "3379600"
  },
  {
    "text": "you have special\nscrutiny on your models. So they went to\n2X less than that. So they really went\nright below this",
    "start": "3379600",
    "end": "3385480"
  },
  {
    "text": "to not have special scrutiny. So 3.8. I might be off by a little\nbit, but it's definitely",
    "start": "3385480",
    "end": "3390700"
  },
  {
    "text": "under the 1 e26",
    "start": "3390700",
    "end": "3396369"
  },
  {
    "text": "So parameter p is parameters\nn is data, number of tokens.",
    "start": "3396370",
    "end": "3401720"
  },
  {
    "text": "This is just an approximation. Yeah.",
    "start": "3401720",
    "end": "3408100"
  },
  {
    "text": "OK. Compute and we know that they\ntrained on 16,000 h100s and we",
    "start": "3408100",
    "end": "3415690"
  },
  {
    "text": "know the throughput\nthey set it to. So if you do the computation,\nit takes around 70 days",
    "start": "3415690",
    "end": "3422790"
  },
  {
    "text": "or 26 million GPU hours. At least that's what my back\nof the envelope computation.",
    "start": "3422790",
    "end": "3428500"
  },
  {
    "text": "They actually said that\nthey use 30 million instead of 26 million GPU hours.",
    "start": "3428500",
    "end": "3433710"
  },
  {
    "text": "So maybe they had\nsome challenges. I don't really know. But if you follow the\nsimple computation,",
    "start": "3433710",
    "end": "3440350"
  },
  {
    "text": "it's around 70 days. Cost. I mean this it's\nhard to approximate,",
    "start": "3440350",
    "end": "3447100"
  },
  {
    "text": "but I'm just going to say\nit's, kind of, the rent. Like, what if I wanted to\nrent H100, that many H 100",
    "start": "3447100",
    "end": "3453720"
  },
  {
    "text": "for that many days,\nhow much will I pay? H100 a lower bound on\nthe renting costs of H100",
    "start": "3453720",
    "end": "3461100"
  },
  {
    "text": "is around two hours-- $2 per hour. So if you multiply this\nby 26,000,000 hours,",
    "start": "3461100",
    "end": "3468119"
  },
  {
    "text": "you get $52 million. So they probably\npay less than that, but not actually much less\nbecause all these services",
    "start": "3468120",
    "end": "3478000"
  },
  {
    "text": "that actually rent GPUs, they\ndon't make that much money. So it's probably slightly\nless, but not that much less.",
    "start": "3478000",
    "end": "3484030"
  },
  {
    "text": "Now salary I said 50\nemployees, 500k per year.",
    "start": "3484030",
    "end": "3490587"
  },
  {
    "text": "Yeah it's probably\nthe right ballpark. $25 million. So if you put altogether\naround $75 million",
    "start": "3490587",
    "end": "3497530"
  },
  {
    "text": "for training this llama model. I'm probably off\nby like 10 million,",
    "start": "3497530",
    "end": "3502580"
  },
  {
    "text": "but that's kind\nof right ballpark. Carbon emitted.",
    "start": "3502580",
    "end": "3509140"
  },
  {
    "text": "A lot of people might ask\nlike also the cost is not the only thing\nthat is important. So I did the computation.",
    "start": "3509140",
    "end": "3515650"
  },
  {
    "text": "It's around 4000 tons\nof CO2 equivalent.",
    "start": "3515650",
    "end": "3522859"
  },
  {
    "text": "That is actually only\n2000 return tickets from JFK to London. So right now carbon\nemitted is actually not--",
    "start": "3522860",
    "end": "3531820"
  },
  {
    "text": "I mean, it's huge, but\nit's not meaningful yet. I think in maybe GPT6,\nGPT7, once you multiply this",
    "start": "3531820",
    "end": "3541760"
  },
  {
    "text": "by 100, that might\nbecome a real issue. Right now it's\nstill not, I think,",
    "start": "3541760",
    "end": "3547220"
  },
  {
    "text": "an issue in the grand\nscheme of things. Next model the way you should be\nthinking about these models is",
    "start": "3547220",
    "end": "3552650"
  },
  {
    "text": "that every new generation, the\nnumber of flops essentially multiplies 10x, or at least\nthat's what they try if they",
    "start": "3552650",
    "end": "3559340"
  },
  {
    "text": "have enough energy. And if they can buy enough GPUs. Great. Any question on these\nback of the envelope math.",
    "start": "3559340",
    "end": "3566140"
  },
  {
    "text": " No. OK.",
    "start": "3566140",
    "end": "3571940"
  },
  {
    "text": "So now we talked\nabout pretraining, I wanted to also\nchat about systems because now we know compute\nis really important so there's",
    "start": "3571940",
    "end": "3579320"
  },
  {
    "text": "a question of how do\nyou optimize the-- how do you optimize the compute? I will leave that for\nthe end because I'm not",
    "start": "3579320",
    "end": "3585020"
  },
  {
    "text": "sure how much time we will have. I think it's important,\nbut hopefully I'll be able to talk about it later.",
    "start": "3585020",
    "end": "3590410"
  },
  {
    "text": "It's slightly different\nthan what we've been talking about right now. So I'll move on to\npost-training for now.",
    "start": "3590410",
    "end": "3596450"
  },
  {
    "text": "So the task of\npost-training, the reason why we need to do post\ntraining is, as I told you",
    "start": "3596450",
    "end": "3601790"
  },
  {
    "text": "before, it's to\nmake AI assistants. So language modeling\nis not really the thing",
    "start": "3601790",
    "end": "3609800"
  },
  {
    "text": "that you want when you\nhave an AI assistant. For example, if you\nask to GPT3, which",
    "start": "3609800",
    "end": "3614930"
  },
  {
    "text": "is a purely language model-- a pure language model,\nnot a non-aligned one.",
    "start": "3614930",
    "end": "3620180"
  },
  {
    "text": "If you ask a question\nexplain the moon landing to a six-year-old, the\ncompletion that you would get",
    "start": "3620180",
    "end": "3626210"
  },
  {
    "text": "is something explain the theory\nof gravity to a six-year-old. Because what it learned\nis that on internet,",
    "start": "3626210",
    "end": "3631710"
  },
  {
    "text": "if you have one\nquestion, you usually have maybe another bullet point\nof other similar questions",
    "start": "3631710",
    "end": "3636860"
  },
  {
    "text": "you don't usually have\nquestion and then answer later. This is not what you want\nfrom an AI assistant.",
    "start": "3636860",
    "end": "3642740"
  },
  {
    "text": "So how do we do this\nalignment, which is this post training and\nmaking these models assistants?",
    "start": "3642740",
    "end": "3649730"
  },
  {
    "text": "So the goal of this\nalignment is to basically get LLMs follow the\ninstructions that",
    "start": "3649730",
    "end": "3655550"
  },
  {
    "text": "are given by users and\nmaybe some designers, kind of, desires.",
    "start": "3655550",
    "end": "3662180"
  },
  {
    "text": "So think about motivation. You don't want the\nmodel-- like OpenAI doesn't want the model to\nsay stuff that is very toxic.",
    "start": "3662180",
    "end": "3669950"
  },
  {
    "text": "So here you see on\nthe left-hand side that when you ask a question, it\nactually provides a real answer.",
    "start": "3669950",
    "end": "3675570"
  },
  {
    "text": "So it's not like before the LLM. And on the right-hand side,\nyou see that it would-- if you ask to write a tweet\ndescribing how a certain part",
    "start": "3675570",
    "end": "3685040"
  },
  {
    "text": "of the population are evil, it\nwill say that it cannot do that. So that's kind of\nthis alignment.",
    "start": "3685040",
    "end": "3692839"
  },
  {
    "text": "The background here is\nthat basically the data",
    "start": "3692840",
    "end": "3698000"
  },
  {
    "text": "that you want for training\nsome of these models is-- like, we know what we want. Which is just asking\nhumans, this is a question,",
    "start": "3698000",
    "end": "3704960"
  },
  {
    "text": "this is the answer\nthat you want. But the thing is that it's very\nexpensive to collect that data, and it's hard to find it online.",
    "start": "3704960",
    "end": "3711350"
  },
  {
    "text": "In contrast, pretraining\ndata is not what you want, but there's a lot of it.",
    "start": "3711350",
    "end": "3716359"
  },
  {
    "text": "So what we will do, or\nthe main idea is simply take a pretrained\nlarge language model",
    "start": "3716360",
    "end": "3721460"
  },
  {
    "text": "pretrained on all of internet\nand then just fine tune. So you just change a little bit\nthe weights on the type of data that you actually want.",
    "start": "3721460",
    "end": "3727380"
  },
  {
    "text": "And hopefully given\nit, you already pretrained it on\nall of internet, it basically learns or knows\nhow to speak in English",
    "start": "3727380",
    "end": "3733250"
  },
  {
    "text": "and knows standard\nlanguage syntax",
    "start": "3733250",
    "end": "3738320"
  },
  {
    "text": "then you can really fine tune\nit with very little data. OK, SFT.",
    "start": "3738320",
    "end": "3744460"
  },
  {
    "text": "So Supervised Fine Tuning is\nreally exactly what I just said. Which is the idea of\nfine-tuning the large language",
    "start": "3744460",
    "end": "3749660"
  },
  {
    "text": "model on basically the\ndesired answers that are collected from humans.",
    "start": "3749660",
    "end": "3755480"
  },
  {
    "text": "So why is it called\nsupervised fine tuning? Because you basically want to\ndo language modeling on the real",
    "start": "3755480",
    "end": "3761200"
  },
  {
    "text": "answers. So language modeling is this\nlike next word prediction, and that's the fine tuning part. And then you want to do it on\ndesired answers given by humans",
    "start": "3761200",
    "end": "3768810"
  },
  {
    "text": "so that's why we\ncall it supervised. So how do we collect this data? Well, I just said it.",
    "start": "3768810",
    "end": "3774150"
  },
  {
    "text": "You just ask humans\nto tell you this is a question this is\nthe answer that you would",
    "start": "3774150",
    "end": "3779470"
  },
  {
    "text": "want from some of these models. So this is an example. I can't read very\nwell on my computer,",
    "start": "3779470",
    "end": "3784970"
  },
  {
    "text": "but my kid needs\nto do a science-- no let's read this one. Can you write a\nshort introduction",
    "start": "3784970",
    "end": "3791680"
  },
  {
    "text": "about the relevance\nof the term monopsony? And then it says monopsony\nrefers to a market structure, blah blah, blah.",
    "start": "3791680",
    "end": "3796825"
  },
  {
    "text": "And that's a human\nnetwork there. So, actually, this\nis Open Assistant, which was a way to collect\ndata online by humans.",
    "start": "3796825",
    "end": "3807970"
  },
  {
    "text": "So this type of supervised\nfine tuning or alignment is really the key of ChatGPT.",
    "start": "3807970",
    "end": "3813670"
  },
  {
    "text": "This is what made the big jump\nfrom GPT 3, which was mostly something that was\nknown by AI researchers",
    "start": "3813670",
    "end": "3820120"
  },
  {
    "text": "to ChatGPT, which became\nknown by basically everyone. ",
    "start": "3820120",
    "end": "3826900"
  },
  {
    "text": "So the problem\nwith human data is that it's very slow to\ncollect and very expensive.",
    "start": "3826900",
    "end": "3836300"
  },
  {
    "text": "So one possible\nsimple idea is to use LLMs to scale data collection.",
    "start": "3836300",
    "end": "3843250"
  },
  {
    "text": "So that's exactly what we\ndid with Alpaca one year ago. What we did is that\nwe asked humans,",
    "start": "3843250",
    "end": "3849070"
  },
  {
    "text": "so we use a data set of\nhuman question answers. So there were 175\nquestion answers here,",
    "start": "3849070",
    "end": "3855070"
  },
  {
    "text": "and we asked the best\nmodel at the time, so text-davinci 003 to basically\ngenerate many more of these",
    "start": "3855070",
    "end": "3861100"
  },
  {
    "text": "question and answers. So all we did is, this is\nwhat humans would write now, write similar answers\nand similar questions.",
    "start": "3861100",
    "end": "3867500"
  },
  {
    "text": "And we collected 52,000\nLLM-generated question answers. And then what we did is\nsimply we took llama 7B,",
    "start": "3867500",
    "end": "3874668"
  },
  {
    "text": "which was the best\npre-trained model at the time. And we just fine tuned this\nwith supervised fine tuning, as I told you.",
    "start": "3874668",
    "end": "3879890"
  },
  {
    "text": "And that's how we got\nthe Alpaca 7B model. And this is the type of\ndata that we collected.",
    "start": "3879890",
    "end": "3887090"
  },
  {
    "text": "So things like what\ndoes algorithm mean? And algorithm is a step by\nstep set of instructions",
    "start": "3887090",
    "end": "3893440"
  },
  {
    "text": "you use to solve a problem or\nachieve a goal, blah, blah, blah, blah. So the data is not actually--\nit's actually pretty good,",
    "start": "3893440",
    "end": "3898980"
  },
  {
    "text": "given that it was LLM generated\nby LLMs from essentially two generations ago.",
    "start": "3898980",
    "end": "3904880"
  },
  {
    "text": "So that really started\nat least for us as an academic\nreplication of ChatGPT.",
    "start": "3904880",
    "end": "3910340"
  },
  {
    "text": "Now it really--\nthere's a big field of synthetic data\ngeneration of how",
    "start": "3910340",
    "end": "3915470"
  },
  {
    "text": "to use LLMs to basically make\ndevelopment of LLMs faster.",
    "start": "3915470",
    "end": "3921140"
  },
  {
    "text": "And basically by decreasing\nthe amount of human hours that you need.",
    "start": "3921140",
    "end": "3926810"
  },
  {
    "text": "Quantity of data. So we talked about what type\nof data and how we collect it. One thing which is\nsurprising with SFT",
    "start": "3926810",
    "end": "3933800"
  },
  {
    "text": "is that you don't\nneed that much data. So what this paper showed\nthis is called LIMA,",
    "start": "3933800",
    "end": "3938940"
  },
  {
    "text": "is that if you scale the amount\nof data that you use from supervised fine tuning\nfrom 2000 to 32,000,",
    "start": "3938940",
    "end": "3946710"
  },
  {
    "text": "it really doesn't help much. So here scaling laws\ndefinitely don't help. And so the intuition here\nis that all you learn",
    "start": "3946710",
    "end": "3955280"
  },
  {
    "text": "is you learn how to format\nyour desired answers. Another way of saying it is that\nyour pre-trained models, they",
    "start": "3955280",
    "end": "3962510"
  },
  {
    "text": "essentially model the\ndistribution of every user on internet, one that\nmight write bullet points,",
    "start": "3962510",
    "end": "3967530"
  },
  {
    "text": "another one that might\nanswer question-- answer question with an answer. So all you tell your\nmodel is like, wait,",
    "start": "3967530",
    "end": "3973470"
  },
  {
    "text": "you should actually\nbe optimizing more for this type of\nuser than another one. So you're not\nactually teaching it--",
    "start": "3973470",
    "end": "3978980"
  },
  {
    "text": "you're not teaching anything\nthrough this SFT, so supervised fine\ntuning, all you do",
    "start": "3978980",
    "end": "3985100"
  },
  {
    "text": "is you tell the model to\noptimize for one type of user that it saw already in\na pretrained data set.",
    "start": "3985100",
    "end": "3990980"
  },
  {
    "text": "So the knowledge is already\nin the pretrained LLM and you basically just\nspecialize to one type of user.",
    "start": "3990980",
    "end": "3997530"
  },
  {
    "text": "Great. Any question on SFT? Yes. So I know it's a big\nissue with synthetic data",
    "start": "3997530",
    "end": "4005260"
  },
  {
    "text": "where if you keep generating\ndata from the same distribution, eventually you're not\nlearning a new distribution,",
    "start": "4005260",
    "end": "4011690"
  },
  {
    "text": "you're essentially\nplaying with it. Just bootstrapping that. Yeah. Surely you can't scale\nthat forever, right.",
    "start": "4011690",
    "end": "4017870"
  },
  {
    "text": "You can't keep going\non and generating from the same distribution. You hope to learned\nsomething new. Yeah. So are there-- it's an\nactive area of research",
    "start": "4017870",
    "end": "4025100"
  },
  {
    "text": "but any thoughts\nthat you have around how people are maybe thinking\naround this and better ways",
    "start": "4025100",
    "end": "4030940"
  },
  {
    "text": "to bootstrap? Or to give up on this idea and\nrealize that the chart shows you don't need that many so\njust get humans to generate",
    "start": "4030940",
    "end": "4037480"
  },
  {
    "text": "2000 really good prompts. Yeah. So that's a very good question. So for the data\nstuff, so I'm saying",
    "start": "4037480",
    "end": "4043320"
  },
  {
    "text": "it's not that important\nfor SFT, but there will be another thing we'll talk\nabout right after where actually data does matter.",
    "start": "4043320",
    "end": "4049720"
  },
  {
    "text": "My intuition based on not\nthat much empirical results is that you can still get,\neven though you use your LLMs,",
    "start": "4049720",
    "end": "4058520"
  },
  {
    "text": "if you use purely\nLLM generated text and you do that for like three\nor four generations of LLMs, I agree with you that probably\nyou won't improve much.",
    "start": "4058520",
    "end": "4065830"
  },
  {
    "text": "But for me what is important is\nhow do you use human in the loop with LLMs? Not purely LLMs,\nnot purely humans,",
    "start": "4065830",
    "end": "4073065"
  },
  {
    "text": "but maybe what\nyou can do is just have the model\nregenerate some new text and just humans\nwrite a few edits.",
    "start": "4073065",
    "end": "4079220"
  },
  {
    "text": "Edits are much faster than\nwriting the entire text. And I think that if you have\nthat type of collaboration,",
    "start": "4079220",
    "end": "4084260"
  },
  {
    "text": "then from an information\ntheoretical point of view, you still get\nadditional information, but you're still much faster\nthan if you use humans.",
    "start": "4084260",
    "end": "4091610"
  },
  {
    "text": "And I think that\nas a field we'll probably move towards these\ntype of things, which is really",
    "start": "4091610",
    "end": "4097060"
  },
  {
    "text": "just finding the examples that\nare important and asking humans. It's kind of active\nlearning, just",
    "start": "4097060",
    "end": "4102250"
  },
  {
    "text": "asking humans exactly when\nyou need to get their inputs.",
    "start": "4102250",
    "end": "4108240"
  },
  {
    "text": "Yes. Do we train with the\nsame loss function and the same general\ntraining algorithm for the supervised\nfine tuning bit",
    "start": "4108240",
    "end": "4114310"
  },
  {
    "text": "as we do for the pretraining? Because the examples\nyou showed, I think the important thing\nof the good examples",
    "start": "4114310",
    "end": "4123080"
  },
  {
    "text": "is like super\nfactually accurate. Like there's these\nmore complex things and it's still just\nlike [INAUDIBLE].",
    "start": "4123080",
    "end": "4128739"
  },
  {
    "text": "Same loss. So that's why here-- yeah, I didn't-- maybe\ndidn't emphasize enough. This is just language modeling.",
    "start": "4128740",
    "end": "4133818"
  },
  {
    "text": "Fine tune the LLM with language\nmodel and the desired answers. So this is literally\nthe same loss.",
    "start": "4133819",
    "end": "4139068"
  },
  {
    "text": "It will be different\nin two seconds, but the first step\nof SFT is literally",
    "start": "4139069",
    "end": "4144259"
  },
  {
    "text": "the same loss where\nyou just say, OK, I want to actually specialize\non that type of data. So there's even a question\nof what is pretraining,",
    "start": "4144260",
    "end": "4150672"
  },
  {
    "text": "what is post-training? Because, in reality, it's\njust like a different data that you use. The reason why we usually call\nit post-training is that the way",
    "start": "4150673",
    "end": "4156464"
  },
  {
    "text": "we collect that data\nis very different. Great, great questions. Yes.",
    "start": "4156465",
    "end": "4162080"
  },
  {
    "text": "Maybe it's the same\nquestion, but why would these 2000 examples have\nsuch a overweighted influence",
    "start": "4162080",
    "end": "4168259"
  },
  {
    "text": "on fine tuning? So that's why we-- also that's another reason\nwhy we call it post-training",
    "start": "4168260",
    "end": "4173778"
  },
  {
    "text": "is that we use different\ntype of hyperparameters. So, I told you\nbasically at the end of pretraining you\nessentially end up",
    "start": "4173779",
    "end": "4178801"
  },
  {
    "text": "with a learning rate of 0. Here, you're going to\nincrease your learning rate. So like 1e minus\n5, 1e minus-- yeah.",
    "start": "4178802",
    "end": "4184250"
  },
  {
    "text": "And so the way that you give\nto them is actually different. ",
    "start": "4184250",
    "end": "4192568"
  },
  {
    "text": "OK. Second step or second\npart of this post training",
    "start": "4192569",
    "end": "4197820"
  },
  {
    "text": "is what we call\nreinforcement learning from human feedback or RLHF. Some of you might\nhave heard of that.",
    "start": "4197820",
    "end": "4205110"
  },
  {
    "text": "The idea is that SFT has\na problem, namely that you do behavioral cloning, which\nmeans that you just try to clone",
    "start": "4205110",
    "end": "4212610"
  },
  {
    "text": "what the humans would say. And that has many issues. One of them is that you're\nbound by human abilities.",
    "start": "4212610",
    "end": "4219220"
  },
  {
    "text": "So if-- humans actually humans\nwon't generate the things",
    "start": "4219220",
    "end": "4226168"
  },
  {
    "text": "that they think is actually\nthe best thing to generate. So if you ask me\nto write a book, I mean, I can definitely\nenjoy your book.",
    "start": "4226168",
    "end": "4232300"
  },
  {
    "text": "I can probably say one book\nis better than another, but I'm definitely not going to\nbe as good as writing the book that I want to read.",
    "start": "4232300",
    "end": "4237960"
  },
  {
    "text": "So you're going to be\nbound by the human ability to generate things, even though\nthe humans might be better at distinguishing\nbetween things.",
    "start": "4237960",
    "end": "4243750"
  },
  {
    "text": "That's one issue. Issue number two, I find that\nactually pretty interesting is that it--",
    "start": "4243750",
    "end": "4249000"
  },
  {
    "text": "if you ever heard of the\nword hallucination. so this is LLMs generating fake--\nlike false information.",
    "start": "4249000",
    "end": "4255820"
  },
  {
    "text": "Hallucination might--\nat least people have hypothesized that can come\nfrom the supervised fine tuning",
    "start": "4255820",
    "end": "4262040"
  },
  {
    "text": "even if you do supervised fine\ntuning on data that is correct. And the reason why\nthat is is that if--",
    "start": "4262040",
    "end": "4269560"
  },
  {
    "text": "given I told you that basically\nSFT is with very little data. And it's with data\nthat the model",
    "start": "4269560",
    "end": "4275860"
  },
  {
    "text": "doesn't learn anything new. So what if the human gives an\nanswer that the model didn't",
    "start": "4275860",
    "end": "4281440"
  },
  {
    "text": "know was true. From the model perspective,\nthe human basically is telling the model generate\nthis thing that seems plausible",
    "start": "4281440",
    "end": "4290890"
  },
  {
    "text": "but actually have no\nidea if it's true or not. So just to give you a\nvery concrete example,",
    "start": "4290890",
    "end": "4296570"
  },
  {
    "text": "if we go back to this\nmonopsony example, can you write blah blah\nblah about monopsony?",
    "start": "4296570",
    "end": "4301750"
  },
  {
    "text": "Imagine that the human wrote a\nreference on this type of book. And that book might exist.",
    "start": "4301750",
    "end": "4307910"
  },
  {
    "text": "That might be a\ncorrect reference, but what if the LLM\nnever saw this reference during pretraining. Then it doesn't know that\nit's a correct reference.",
    "start": "4307910",
    "end": "4314720"
  },
  {
    "text": "So really what\nyou tell the model is to generate or make up some\nplausible sounding reference",
    "start": "4314720",
    "end": "4320889"
  },
  {
    "text": "rather than actually\ntell the real reference that it saw during pretraining. So hallucination might\nbe caused by this SFT.",
    "start": "4320890",
    "end": "4332470"
  },
  {
    "text": "So that's problem number two. Does that all make sense? Great. Problem number 3, price.",
    "start": "4332470",
    "end": "4338260"
  },
  {
    "text": "Generating the ideal\nanswers is very pricey. And that comes back\nto your question",
    "start": "4338260",
    "end": "4343719"
  },
  {
    "text": "of humans writing the\nentire answer is actually pretty expensive. So that's why RLHF comes in.",
    "start": "4343720",
    "end": "4350330"
  },
  {
    "text": "The idea is that instead of\ncloning the behaviors of humans, we're going to maximize\nhuman preference.",
    "start": "4350330",
    "end": "4357100"
  },
  {
    "text": "And the way we're going to\ndo that, so the pipeline, is that for a certain--\nfor every instruction,",
    "start": "4357100",
    "end": "4362450"
  },
  {
    "text": "you're going to ask a model\nto generate two answers and usually use a\npretty good model.",
    "start": "4362450",
    "end": "4368270"
  },
  {
    "text": "So you usually don't use an LLM\nhere, you use a SFT fine tune, you use a fine tuned LLM already\nto give pretty good answers.",
    "start": "4368270",
    "end": "4376990"
  },
  {
    "text": "And then you ask labelers which\nof these two answers was better? So select the preferred one.",
    "start": "4376990",
    "end": "4382910"
  },
  {
    "text": "And then with different\ntypes of algorithms, we're going to talk about\nthe algorithms, you just fine tune the model to generate\nmore of the green thing",
    "start": "4382910",
    "end": "4390010"
  },
  {
    "text": "than the red thing. So more of the good stuff. So now the question\nis how and we're going to talk about\nthat right now.",
    "start": "4390010",
    "end": "4397060"
  },
  {
    "text": "So there are two ways that\nwe're going to talk about and two that are mainly\nuse in the community.",
    "start": "4397060",
    "end": "4403119"
  },
  {
    "text": "The first one is simply the idea\nof using reinforcement learning. So hopefully you all know what\nreinforcement learning is now.",
    "start": "4403120",
    "end": "4410020"
  },
  {
    "text": "So when you think about\nusing reinforcement learning, one important question is\nlike, what is the reward",
    "start": "4410020",
    "end": "4415150"
  },
  {
    "text": "that we're optimizing. So in this case, there\nare really two options that I could think about. The first one, you\ncould just say,",
    "start": "4415150",
    "end": "4421490"
  },
  {
    "text": "I'm going to compare the output\ngenerated by some baseline, the output generated\nby my model. And I'm just going to ask the\nhuman to say which one is better",
    "start": "4421490",
    "end": "4429610"
  },
  {
    "text": "and I'm going to use\nthis as a reward. So if I'm better\nthan the baseline, this is a plus 1, if\nnot, it's a minus 1.",
    "start": "4429610",
    "end": "4435880"
  },
  {
    "text": "So now it's binary reward. The problem with binary reward\nis that it's very sparse and you don't get much\ninformation out of it.",
    "start": "4435880",
    "end": "4441940"
  },
  {
    "text": "Like maybe your answer\nwas slightly better, maybe it was like way\nbetter and you don't really",
    "start": "4441940",
    "end": "4447190"
  },
  {
    "text": "know from this how\nmuch better it was. So option 2 is\nthat you can train",
    "start": "4447190",
    "end": "4453100"
  },
  {
    "text": "what we call a reward model,\nwhich is simply a classifier. So you use machine\nlearning to classify",
    "start": "4453100",
    "end": "4459760"
  },
  {
    "text": "how much better two outputs\nare from the preference-- from the perspective\nof the human.",
    "start": "4459760",
    "end": "4466929"
  },
  {
    "text": "So this is a little bit\nmeta, but what you basically do is that you train-- you take a reward model, which\nis just a large la-- also",
    "start": "4466930",
    "end": "4477909"
  },
  {
    "text": "a large classifier, and you\nbasically ask this reward model, you give it the input\nand the actual output",
    "start": "4477910",
    "end": "4483850"
  },
  {
    "text": "that you have, one\nof the two outputs. And you just exponentiate that\nso that's the softmax loss",
    "start": "4483850",
    "end": "4489730"
  },
  {
    "text": "that you all know about. And now you divide by\nthe exponentiated reward",
    "start": "4489730",
    "end": "4496520"
  },
  {
    "text": "on the first example-- I'm sorry, on the\nfirst output and this is on the second output. And you basically train--",
    "start": "4496520",
    "end": "4502740"
  },
  {
    "text": "so the reason why you do that\nis that you train your model, you train this\nreward model to be able to classify how much better\none output is to another one.",
    "start": "4502740",
    "end": "4513360"
  },
  {
    "text": "So another slightly less\nconvoluted way of saying it is that your reward\nmodel will output",
    "start": "4513360",
    "end": "4519020"
  },
  {
    "text": "some reward that will be used\nas the logits of your softmax. So now if you have high\nlogits in your softmax,",
    "start": "4519020",
    "end": "4525960"
  },
  {
    "text": "it means that you highly\nlikely this output is better.",
    "start": "4525960",
    "end": "4532760"
  },
  {
    "text": "So that's what we call\nBradley-Terry model. Yes. Will this reward\nmodel [INAUDIBLE] lower the entire output, or\nis it going to [INAUDIBLE]?",
    "start": "4532760",
    "end": "4540580"
  },
  {
    "text": "So this takes the entire-- yeah, this takes the\nentire output at once.",
    "start": "4540580",
    "end": "4546950"
  },
  {
    "text": "So it takes all the\ninput and all the output and it gives one number. Yes. So [INAUDIBLE] reward model,\nwhere would the human be then?",
    "start": "4546950",
    "end": "4555090"
  },
  {
    "text": "Sorry. With the reward model,\nwhere would the human be? Like-- I see.",
    "start": "4555090",
    "end": "4560230"
  },
  {
    "text": "OK sorry. Maybe I wasn't clear. You train this reward model\nto fit this green and red",
    "start": "4560230",
    "end": "4568450"
  },
  {
    "text": "preference from humans. So basically you\ntrain a classifier to say whether the humans\nprefer red or green.",
    "start": "4568450",
    "end": "4575739"
  },
  {
    "text": "But instead of using\nthe binary reward, which is what the human would\ntell you you basically use the logits of the softmax.",
    "start": "4575740",
    "end": "4583190"
  },
  {
    "text": "And the thing with the logits\nis that logits are continuous. So now you know that if\nyour reward model said",
    "start": "4583190",
    "end": "4589060"
  },
  {
    "text": "it has high logits,\nthen, in some ways, the human highly preferred this\nanswer to some other answer.",
    "start": "4589060",
    "end": "4596960"
  },
  {
    "text": "Great. So as I just said, continuous\ninformation is better. So that's what people use\nin practice or at least",
    "start": "4596960",
    "end": "4604130"
  },
  {
    "text": "used to use in practice. I'll tell you about the\nother algorithm later. So what do you do at the\nend is that you basically",
    "start": "4604130",
    "end": "4610490"
  },
  {
    "text": "try to just use reinforcement\nlearning that you know about. Now we know we have a reward.",
    "start": "4610490",
    "end": "4615650"
  },
  {
    "text": "What you sample through\nis the generation from your large language model. And then you just use\nsome regularization term.",
    "start": "4615650",
    "end": "4622200"
  },
  {
    "text": "So the reason why we do\nthis regularization term is for avoiding what we\ncall overoptimization. So this reward\nmodel might not be",
    "start": "4622200",
    "end": "4628340"
  },
  {
    "text": "really represent--\nmight not perfectly model human preferences. So you don't want to\nmaximize this thing",
    "start": "4628340",
    "end": "4634040"
  },
  {
    "text": "to essentially infinity. And you do it using a PPO,\nwhich is a common reinforcement",
    "start": "4634040",
    "end": "4642710"
  },
  {
    "text": "learning algorithm. One thing to note here, because\nit will be important for later, is that when we use\nmaximum likelihood--",
    "start": "4642710",
    "end": "4652730"
  },
  {
    "text": "sorry, now the large\nlanguage models are actually a policy for\nyour reinforcement learning.",
    "start": "4652730",
    "end": "4658239"
  },
  {
    "text": "It's not maximizing\nmaximum likelihood anymore. Which means that you're not\nmodeling any distribution",
    "start": "4658240",
    "end": "4663420"
  },
  {
    "text": "anymore. And the reason why\nthis is important is that models that went\nthrough this type of PPO",
    "start": "4663420",
    "end": "4668700"
  },
  {
    "text": "actually don't give\nyou likelihoods of text that are meaningful. Because what you\noptimize them to do",
    "start": "4668700",
    "end": "4674670"
  },
  {
    "text": "is basically just\noptimize for generating the most likely thing,\nnot optimize for modeling,",
    "start": "4674670",
    "end": "4680170"
  },
  {
    "text": "all the answers that\nhumans might say. Another way of saying\nthat is that there's nothing that incentivizes\nhere the model to not give",
    "start": "4680170",
    "end": "4689571"
  },
  {
    "text": "a single possible generation. Nothing here says it's good\nif you have some distribution",
    "start": "4689571",
    "end": "4695310"
  },
  {
    "text": "with some entropy. If you haven't followed, it's\nnot that important but just good",
    "start": "4695310",
    "end": "4700590"
  },
  {
    "text": "to know. Great. So PPO is exactly what\nChatGPT did originally.",
    "start": "4700590",
    "end": "4707350"
  },
  {
    "text": "So here is on their\nblog post on what they have is step one do\nsupervised fine tuning, which",
    "start": "4707350",
    "end": "4713610"
  },
  {
    "text": "now you all know about. Step two, train a reward\nmodel on human preferences. Step three, do PPO\nmultiple steps,",
    "start": "4713610",
    "end": "4720940"
  },
  {
    "text": "which is where you\nsee this blue arrow. So you continue-- you train\nthe model once with the PPO, you collect new\ndata, you continue.",
    "start": "4720940",
    "end": "4727270"
  },
  {
    "text": "And that's why-- and that's\nexactly what ChatGPT did. And that was the\nbig breakthrough between GPT 3 and ChatGPT.",
    "start": "4727270",
    "end": "4735179"
  },
  {
    "text": "One thing to note is that\nPPO has many challenges. Reinforcement learning\nis something that",
    "start": "4735180",
    "end": "4740550"
  },
  {
    "text": "is super nice theoretically. In practice, anyone\nwho ever worked with reinforcement learning\nknows it's such a mess.",
    "start": "4740550",
    "end": "4746489"
  },
  {
    "text": "There's a lot of things\nlike rollouts, outer loops, clipping so many complications.",
    "start": "4746490",
    "end": "4751950"
  },
  {
    "text": "So it's messy. This is the idealized PPO\nused for LLM settings, so that's already\nmuch more complicated",
    "start": "4751950",
    "end": "4757530"
  },
  {
    "text": "than this expectation\nwe saw before. And in practice it's actually\nmuch more complicated. So we have one implementation\nof it that we had to do,",
    "start": "4757530",
    "end": "4763599"
  },
  {
    "text": "and I'm not going\nto go through it. But basically have so\nmuch stuff that you have to think about\nwhen you implement",
    "start": "4763600",
    "end": "4769110"
  },
  {
    "text": "that type of PPO algorithm. So you have clipping everywhere,\nyou have a lot of complexities",
    "start": "4769110",
    "end": "4774930"
  },
  {
    "text": "and things are not\nwell documented. All this to say that we're going\nto there was a new method that",
    "start": "4774930",
    "end": "4781860"
  },
  {
    "text": "was proposed also from\nStanford one year ago called DPO, which is essentially\na simplification of PPO.",
    "start": "4781860",
    "end": "4789690"
  },
  {
    "text": "And the way-- what they did\nor the idea that they have is that instead of using\nreinforcement learning,",
    "start": "4789690",
    "end": "4796265"
  },
  {
    "text": "you can just maximize the\nprobability of generating the stuff that you\nlike and minimizing the probability of the\nstuff that you don't like.",
    "start": "4796265",
    "end": "4802350"
  },
  {
    "text": "So if you think about the human\npreference, the red and green, maximize green, minimize red.",
    "start": "4802350",
    "end": "4808800"
  },
  {
    "text": "So the loss is actually\nthis one where what you see this is simply some\nlog of the model.",
    "start": "4808800",
    "end": "4816733"
  },
  {
    "text": "So this is the likelihood of\na model generating the things that the human preferred,\ngiven the inputs.",
    "start": "4816733",
    "end": "4823260"
  },
  {
    "text": "And what you try\nto do is basically maximize the likelihood of\ngenerating the things that you",
    "start": "4823260",
    "end": "4830370"
  },
  {
    "text": "like, minimize the likelihood of\nthe things that you don't like. All the rest of the terms\nhere it's not too important.",
    "start": "4830370",
    "end": "4836740"
  },
  {
    "text": "It's actually really not that\ncomplicated to understand. But at a high level, it's really\njust maximizing the things",
    "start": "4836740",
    "end": "4842760"
  },
  {
    "text": "you like, minimizing the rest. And one thing to note, which\nI was going to say just here,",
    "start": "4842760",
    "end": "4849700"
  },
  {
    "text": "is that actually all\nthe rest is chosen such that the global minima of\nPPO and the global minima",
    "start": "4849700",
    "end": "4856950"
  },
  {
    "text": "of like this DPO,\nunder some assumptions, are essentially equivalent. So this is the right thing\nto do mathematically.",
    "start": "4856950",
    "end": "4864307"
  },
  {
    "text": "I'm not going to go\nthrough the derivations, but that's the\nright thing to do. It's pretty different with\nPPO in the sense that now--",
    "start": "4864307",
    "end": "4870960"
  },
  {
    "text": "with PPO, what you had to do is\ncollect the human preferences, then train a reward model\nwith maximum likelihood,",
    "start": "4870960",
    "end": "4876237"
  },
  {
    "text": "then use reinforcement learning. Now all you do is basically\nmaximum likelihood. Much simpler. Yes. I mean, yeah.",
    "start": "4876237",
    "end": "4881610"
  },
  {
    "text": "So it seems like this is A,\nmuch simpler and B, like, what you would just intuitively\ndo with [INAUDIBLE]?",
    "start": "4881610",
    "end": "4887220"
  },
  {
    "text": "Why did they start\nwith this reward model. Like what led them doing that? I think it's a great question.",
    "start": "4887220",
    "end": "4893280"
  },
  {
    "text": "I don't really know. What I can tell you is that. At ChatGPT the people\nwho did basically",
    "start": "4893280",
    "end": "4901120"
  },
  {
    "text": "this PP-- sorry, who\ndid ChatGPT initially are the ones who\nactually wrote PPO.",
    "start": "4901120",
    "end": "4907333"
  },
  {
    "text": "And I think they\nwere just-- like, there are a lot of\nreinforcement learning people. And I think that for them\nit was very intuitive.",
    "start": "4907333",
    "end": "4914320"
  },
  {
    "text": "So there's also some\nadditional potential benefits. For example, I don't want to--",
    "start": "4914320",
    "end": "4920650"
  },
  {
    "text": "yeah, for example, if\nyou use the reward model, the cool thing here with\nreinforcement learning is that you can use unlabeled\ndata with the reward model.",
    "start": "4920650",
    "end": "4928280"
  },
  {
    "text": "So here you can only use the\nlabeled data for doing DPO-- For PPO-- for PPO, you first\ntrain your reward model",
    "start": "4928280",
    "end": "4935320"
  },
  {
    "text": "and then you can\nuse unlabeled data where the reward\nmodel will basically label this unlabeled data.",
    "start": "4935320",
    "end": "4941300"
  },
  {
    "text": "So this additional,\nkind of, potential-- there could be\npotential improvements.",
    "start": "4941300",
    "end": "4946929"
  },
  {
    "text": "In practice it happens\nthat there are none. And I think just that a\nlot of people in this team",
    "start": "4946930",
    "end": "4952450"
  },
  {
    "text": "were reinforcement\nlearning experts, including the main author of\nPPO, John Schulman.",
    "start": "4952450",
    "end": "4959060"
  },
  {
    "text": "So much simpler than PPO, and\nit's basically performs as well. So now this is the standard\nthing that people use.",
    "start": "4959060",
    "end": "4966179"
  },
  {
    "text": "At least in the open\nsource community, I believe it's actually the\nstandard also in industry.",
    "start": "4966180",
    "end": "4971830"
  },
  {
    "text": "So that's called DPO. Gains so those are all\nthe papers on the left.",
    "start": "4971830",
    "end": "4977690"
  },
  {
    "text": "Here this is on the\nsummarization task. You see, all I\nwant to show you is that basically the\npretrained models were OK",
    "start": "4977690",
    "end": "4984590"
  },
  {
    "text": "and they improve of scale. If you do supervised\nfine tuning, you improve them\na little bit more, if you do PPO or something\nwith RLHF human feedback,",
    "start": "4984590",
    "end": "4992369"
  },
  {
    "text": "you get performance\nthat are, oftentimes depending on a benchmark,\neven better than humans.",
    "start": "4992370",
    "end": "4998639"
  },
  {
    "text": "So this is the human\nreference summaries. Same thing. This is on a paper that\nwe have Alpaca farm where",
    "start": "4998640",
    "end": "5005260"
  },
  {
    "text": "we see the evaluation\nhere is not too important but basically see\npretrained model. You jump to SFT and then you\njump to PPO, DPO and PPO,",
    "start": "5005260",
    "end": "5013520"
  },
  {
    "text": "DPO have the exact\nsame performance. So basically RLHF helps.",
    "start": "5013520",
    "end": "5018800"
  },
  {
    "text": "That's, kind of, the\nconclusion and DPO is simple. Data. The way that you collect\nthat type of data.",
    "start": "5018800",
    "end": "5026950"
  },
  {
    "text": "First idea is just use humans\nas we already talked about. Guidelines are very\ncomplicated for what",
    "start": "5026950",
    "end": "5033159"
  },
  {
    "text": "humans should be labeling,\nand it's really not that easy. And actually, if you ever\ndo some of the labeling,",
    "start": "5033160",
    "end": "5038210"
  },
  {
    "text": "you will see that it's\nextremely complicated. Like if I Zoom in to this.",
    "start": "5038210",
    "end": "5043870"
  },
  {
    "text": "Here, I have a question tell\nme about self-driving cars. And you read both\nself-driving cars",
    "start": "5043870",
    "end": "5049210"
  },
  {
    "text": "are vehicles that are\ncapable of detecting the surroundings,\nblah, blah blah, blah. Self driving cars are\ncars that are equipped with sensors, blah\nblah, blah to navigate",
    "start": "5049210",
    "end": "5055540"
  },
  {
    "text": "without the need for a driver. I mean, both seem OK. Which one is better? It's actually hard\nto say at a glance.",
    "start": "5055540",
    "end": "5061810"
  },
  {
    "text": "And as a result, the\nproblem with humans is that you will\nstart optimizing",
    "start": "5061810",
    "end": "5067210"
  },
  {
    "text": "a lot of high-level features. For example, the\nsecond one is longer. I can guarantee you that\nmost humans will choose",
    "start": "5067210",
    "end": "5072340"
  },
  {
    "text": "the second one,\neven though I mean, maybe the first one is better. I don't know. I haven't read it carefully.",
    "start": "5072340",
    "end": "5078370"
  },
  {
    "text": "So challenges of humans. First, slow and expensive. Second, as I just mentioned,\nit's hard to focus on things",
    "start": "5078370",
    "end": "5086010"
  },
  {
    "text": "that matter, like correctness. And people usually\nlook at things that don't matter as much\nlike the form, like length.",
    "start": "5086010",
    "end": "5093480"
  },
  {
    "text": "And as a result,\nso what I show here is that when you do RLHF,\nthe more you do RLHF, the longer the output\nof the models become.",
    "start": "5093480",
    "end": "5101380"
  },
  {
    "text": "So if you've ever been\nannoyed at ChatGPT answering you super\nlong sentences, this is because of RLHF.",
    "start": "5101380",
    "end": "5108020"
  },
  {
    "text": "Annotator distribution shift. Like the distribution\nof annotators that you use matters a\nlot, and you have to think,",
    "start": "5108020",
    "end": "5115680"
  },
  {
    "text": "like, what is even the\nhumans that we want to represent in these models? Another question is\ncrowdsourcing ethics.",
    "start": "5115680",
    "end": "5122730"
  },
  {
    "text": "Like usually these--\nbasically a lot of the labeling that is\ndone, the people who do them",
    "start": "5122730",
    "end": "5129510"
  },
  {
    "text": "are not paid well\nand they have to go through a lot of toxic\ndata because you basically want the model to avoid\nsaying the toxic data.",
    "start": "5129510",
    "end": "5136770"
  },
  {
    "text": "So crowdsourcing ethics too. So many challenges\nwith human data.",
    "start": "5136770",
    "end": "5143050"
  },
  {
    "text": "So what we did, also\nlast year, is again, the same thing as Alpaca, just\nthe idea of like oh well, there",
    "start": "5143050",
    "end": "5148840"
  },
  {
    "text": "are challenges\nwith humans, maybe we can just replace\nthem with LLMs. So what we did is\nsimply replace--",
    "start": "5148840",
    "end": "5155770"
  },
  {
    "text": "I see that. I'm just realizing that the\nslides are not centered. Anyways you replace a human\npreference with preferences.",
    "start": "5155770",
    "end": "5162740"
  },
  {
    "text": "So here, on this figure, you\nsee on the x-axis, the price that we paid for\ncollecting human data.",
    "start": "5162740",
    "end": "5169369"
  },
  {
    "text": "It's around $300\nfor 1,000 examples. And this is on mechanical\nTurkers which are usually",
    "start": "5169370",
    "end": "5175600"
  },
  {
    "text": "like cheaper than maybe\nsome of the other companies that you could go through.",
    "start": "5175600",
    "end": "5180860"
  },
  {
    "text": "And on the y-axis,\nit's basically the agreement with other humans,\nwith the mode of other humans.",
    "start": "5180860",
    "end": "5187070"
  },
  {
    "text": "And what you see is that\nactually, as I told you before, labeling is really complicated. Humans agree with\nthemselves only around 66%",
    "start": "5187070",
    "end": "5194050"
  },
  {
    "text": "of the time on a binary task. And it's not that the\nhumans are not good here because we were five\nmain authors on this paper.",
    "start": "5194050",
    "end": "5201380"
  },
  {
    "text": "We tried to label\nthis data ourselves, and we only had, like, 67 or\n68% accuracy, even though we",
    "start": "5201380",
    "end": "5207955"
  },
  {
    "text": "talked-- like we talked\nfor like three hours of how we should be doing labeling. But really, it's complicated. It's not an easy task.",
    "start": "5207955",
    "end": "5214160"
  },
  {
    "text": "And here I just showed\nmany different models. And, basically, you see that\nmodels are much cheaper,",
    "start": "5214160",
    "end": "5219290"
  },
  {
    "text": "and they can actually\nget higher agreement with the mode of humans\nthan humans themselves.",
    "start": "5219290",
    "end": "5224450"
  },
  {
    "text": "And the reason why is because\nhumans have a lot of variance, models have no variance. So there might be a\nlittle bit more biased",
    "start": "5224450",
    "end": "5229750"
  },
  {
    "text": "but have less variance. So it works surprisingly well. And now it's, kind\nof, the standard",
    "start": "5229750",
    "end": "5234860"
  },
  {
    "text": "in open source community. I think even in\nindustry a lot of people use both humans and\nLLMs for improving",
    "start": "5234860",
    "end": "5241730"
  },
  {
    "text": "the collection of RLHF data. And this is like-- this is\nthe paper from last year,",
    "start": "5241730",
    "end": "5247220"
  },
  {
    "text": "but honestly, now it's more like\nthe LLMs would be around this agreement, and\nthis costs around,",
    "start": "5247220",
    "end": "5252600"
  },
  {
    "text": "I would say 50 50x than humans\nand better agreement with human than humans themselves.",
    "start": "5252600",
    "end": "5259020"
  },
  {
    "text": "OK. So that gets us to\nevaluation of post training.",
    "start": "5259020",
    "end": "5265225"
  },
  {
    "text": "That goes back to\nyour initial question at the beginning of the lecture. How do you evaluate\nsomething like ChatGPT?",
    "start": "5265225",
    "end": "5270360"
  },
  {
    "text": "The answers that GPT could\ngive are basically unbounded. And it's not that\nthere's one right answer,",
    "start": "5270360",
    "end": "5276460"
  },
  {
    "text": "there are many answers\nthat are just as good. So there are many challenges. One, you can't use\nvalidation loss",
    "start": "5276460",
    "end": "5283380"
  },
  {
    "text": "because one method\nmight use PPO, the other one might use DPO. Validation loss\nis not comparable.",
    "start": "5283380",
    "end": "5288980"
  },
  {
    "text": "Second, you can't use-- sorry, perplexity. That's the thing\nI told you before. These models are not calibrated.",
    "start": "5288980",
    "end": "5296020"
  },
  {
    "text": "They don't give distributions. They just optimize\nfor one thing. So you can't use perplexity for\nactually evaluating these type",
    "start": "5296020",
    "end": "5302639"
  },
  {
    "text": "of models once they aligned-- sorry, once they're aligned. Third, there's a large\ndiversity of questions",
    "start": "5302640",
    "end": "5309120"
  },
  {
    "text": "that humans might\nask to these models. Generation open QA some question\nanswering some summarization",
    "start": "5309120",
    "end": "5315090"
  },
  {
    "text": "and all of these things. So there's so many\nthings you have to cover. Then the tasks are\nreally open ended,",
    "start": "5315090",
    "end": "5321160"
  },
  {
    "text": "so it's very hard to automate. So that's what you were\nalluding to before. So the idea is that\ninstead of trying",
    "start": "5321160",
    "end": "5328199"
  },
  {
    "text": "to come up with really\neasily automated benchmarks, it's just we're going to ask\nquestions that users actually",
    "start": "5328200",
    "end": "5335100"
  },
  {
    "text": "ask to these models in practice. And we're just going\nto ask annotators to say between these two\nmodels, which one is better.",
    "start": "5335100",
    "end": "5341740"
  },
  {
    "text": "What's the better output. So basically the\nexact same thing as basically the data\nfrom RLHF but you",
    "start": "5341740",
    "end": "5348930"
  },
  {
    "text": "use it now for evaluation. Yes I'm not sure\nI understand what you mean by can't use\nperplexity not calibrated.",
    "start": "5348930",
    "end": "5354280"
  },
  {
    "text": "Like RLHF still doing like\nnext token prediction. So--",
    "start": "5354280",
    "end": "5359723"
  },
  {
    "text": "Why can't perplexity\nbe used then? So think about the\noptimal solution",
    "start": "5359723",
    "end": "5364800"
  },
  {
    "text": "after doing PPL is\nbasically one model that gives you essentially a delta.",
    "start": "5364800",
    "end": "5370931"
  },
  {
    "text": "Like basically it says that\nthere's only one sentence that is-- that could be generated\nfor that question.",
    "start": "5370932",
    "end": "5376930"
  },
  {
    "text": "So now if you use\nit on something that is slightly semantically\ndifferently different, it would actually give a\nlikelihood of 0 for that answer.",
    "start": "5376930",
    "end": "5384150"
  },
  {
    "text": "So in reality, it's not that\nextreme because as you say, it's still a\ndistribution, but it just shows you that there's\na fundamental issue",
    "start": "5384150",
    "end": "5390480"
  },
  {
    "text": "with perplexity. Once these models\nare not LLMs anymore, they were not trained,\nat least with PPO",
    "start": "5390480",
    "end": "5396940"
  },
  {
    "text": "they're not trained to do\nmaximum likelihood anymore, they were trained\nto be policies. ",
    "start": "5396940",
    "end": "5404361"
  },
  {
    "text": "So probably the most\ncommon or the most-- yeah, the most common benchmark\nor the most trusted one",
    "start": "5404361",
    "end": "5410940"
  },
  {
    "text": "is what we call ChatBotArena,\nwhich is basically go on internet, have random\nusers on the internet,",
    "start": "5410940",
    "end": "5417550"
  },
  {
    "text": "blindly talk with two chatbots,\njust ask many questions, see the two answers and\nrate, which one is better.",
    "start": "5417550",
    "end": "5423820"
  },
  {
    "text": "And you do that over hundreds\nof thousands of users and then you get the actual preferences\nand you get rankings of models.",
    "start": "5423820",
    "end": "5430920"
  },
  {
    "text": "So you can go right\nnow on ChatBotArena and actually interact\nwith these models. One potential issue\njust to highlight",
    "start": "5430920",
    "end": "5438306"
  },
  {
    "text": "is that while people who want\nto do these type of things are usually more like\ntech-driven or like tech savvy.",
    "start": "5438307",
    "end": "5444270"
  },
  {
    "text": "So a lot of the questions\nthat you will ask are more like tech\nstuff discussing software errors,\ninquiries about AI tools",
    "start": "5444270",
    "end": "5450300"
  },
  {
    "text": "and all of these things. So another issue\nis cost and speed. If you really want\nto use something",
    "start": "5450300",
    "end": "5455940"
  },
  {
    "text": "like this for\ndevelopment process, it will be too costly because\nyou will need to basically pay",
    "start": "5455940",
    "end": "5461490"
  },
  {
    "text": "a lot of humans to do that. So one simple idea is,\nagain, as we said many times,",
    "start": "5461490",
    "end": "5467990"
  },
  {
    "text": "just use LLM instead of humans. You probably know the\ndrill at this point.",
    "start": "5467990",
    "end": "5473110"
  },
  {
    "text": "Steps for every instruction\ngenerate outputs by some baseline and the model\nthat you want to evaluate.",
    "start": "5473110",
    "end": "5479409"
  },
  {
    "text": "So here you imagine that\nI'm comparing an answer from ChatGPT and from Misrule.",
    "start": "5479410",
    "end": "5484580"
  },
  {
    "text": "I'm just asking a model, another\nmodel, which one is better. And I just basically\naverage that out.",
    "start": "5484580",
    "end": "5492200"
  },
  {
    "text": "Yeah. I asked ChatGPT 4,\nwhich one is better. I averaged that out over\nmy entire distribution,",
    "start": "5492200",
    "end": "5497230"
  },
  {
    "text": "over my entire\nbenchmark or data set, and that gives me a win rate. So a win probability for one\nmodel compared to another one.",
    "start": "5497230",
    "end": "5504619"
  },
  {
    "text": "And now you can rank models. And this is the\nAlpacaEval leaderboard.",
    "start": "5504620",
    "end": "5510190"
  },
  {
    "text": "So the benefits of this\nis that actually we show-- we get 98% correlation\nwith ChatBotArena.",
    "start": "5510190",
    "end": "5516020"
  },
  {
    "text": "So very high\ncorrelation with humans. So this is yeah,\ncomparison with correlation",
    "start": "5516020",
    "end": "5521710"
  },
  {
    "text": "with other benchmarks. And it takes less than three\nminutes and less than $10 to run. So it's pretty cheap.",
    "start": "5521710",
    "end": "5526940"
  },
  {
    "text": "And there are downsides though. One of them is poor correlation. So as we already saw\nbefore, LLMs prefer,",
    "start": "5526940",
    "end": "5534898"
  },
  {
    "text": "this is one spurious\ncorrelation, not many. I'll just talk about one. LLMs prefer longer outputs. Actually humans also\nprefer longer outputs.",
    "start": "5534898",
    "end": "5541010"
  },
  {
    "text": "But the problem or the\nissue once you use LLMs is that once there is bias, you\nwill continue optimizing that.",
    "start": "5541010",
    "end": "5546250"
  },
  {
    "text": "Humans at some point,\nI can guarantee you if I ask a simple\nquestion, and you give me five pages of\nanswers, I'll be like,",
    "start": "5546250",
    "end": "5551510"
  },
  {
    "text": "no, I don't like that answer. But LLMs if they have this bias\nand they were trained for that, they will continue\npreferring longer outputs.",
    "start": "5551510",
    "end": "5557530"
  },
  {
    "text": "So here we see the\npreference just showing",
    "start": "5557530",
    "end": "5562869"
  },
  {
    "text": "that humans and models\nprefer longer outputs. And here is another view of\nthe initial AlpacaEval data set",
    "start": "5562870",
    "end": "5570250"
  },
  {
    "text": "benchmark, where when we asked-- when we rank GPT4, when we\nlook at the win rate of GPT4",
    "start": "5570250",
    "end": "5576940"
  },
  {
    "text": "versus actually GPT4 itself,\nif we use the standard GPT4, it gets 50%, kind of, by\ndefinition because we're",
    "start": "5576940",
    "end": "5583780"
  },
  {
    "text": "comparing GPT4 versus GPT4. But if we ask a GPT4 to\nbe slightly more verbose,",
    "start": "5583780",
    "end": "5589250"
  },
  {
    "text": "so we just say in the prompt,\nbe verbose in your answers, then it gets a\nwin rate of 64.4%.",
    "start": "5589250",
    "end": "5595010"
  },
  {
    "text": "So really there's\na huge variance. And if we ask it\nto be concise, it gets 20% so there's\na huge variance",
    "start": "5595010",
    "end": "5600130"
  },
  {
    "text": "depending on whether you ask\nit to be concise or verbose. That's very annoying.",
    "start": "5600130",
    "end": "5605890"
  },
  {
    "text": "So one possible solution,\nwhich is what we did, is just use some\nregression analysis.",
    "start": "5605890",
    "end": "5611545"
  },
  {
    "text": "I'm not going to\ngo into details, but basically use\ncausal inference tools to control for length. And right now actually\nlength matters much less.",
    "start": "5611545",
    "end": "5618890"
  },
  {
    "text": "So if you ask it to be verbose,\nyou still get some gains, but much less.",
    "start": "5618890",
    "end": "5624430"
  },
  {
    "text": "Great. So that's all about\npost training. And now for the\nnext eight minutes, I might talk about systems\nor just answer questions.",
    "start": "5624430",
    "end": "5631260"
  },
  {
    "text": "Yes. Can you go back to your\npost training, internal post",
    "start": "5631260",
    "end": "5636290"
  },
  {
    "text": "training. How did we tune those\nparameters using the small body of\nfine-tuning data",
    "start": "5636290",
    "end": "5643340"
  },
  {
    "text": "and have such big\neffect on the model? You mentioned earlier that\nthere's a different set of hyperparameters.",
    "start": "5643340",
    "end": "5648880"
  },
  {
    "text": "Are we changing just some of\nthe weights, the later weights or other weights. What's actually happening? Yeah.",
    "start": "5648880",
    "end": "5654530"
  },
  {
    "text": "Yeah, I, kind of, skimmed\nthrough all of this. You change all the weights. Actually, industry will\nchange all the weights.",
    "start": "5654530",
    "end": "5660530"
  },
  {
    "text": "In open source\nland, you might have heard of Laura, which is\ngoing to change basically only",
    "start": "5660530",
    "end": "5666739"
  },
  {
    "text": "some of the weights or it\nactually, to be more specific, it's going to add\nsome differences to the output of every layer.",
    "start": "5666740",
    "end": "5673200"
  },
  {
    "text": "But in industry, you're going to\njust fine tune all the weights. And also to say something\nelse about the data, actually,",
    "start": "5673200",
    "end": "5680850"
  },
  {
    "text": "this last step, RLHF\nyou usually going to collect a lot more\ndata than with SFT. So if FSFT is like 5,000,\n10,000, maybe 50,000 with,",
    "start": "5680850",
    "end": "5690755"
  },
  {
    "text": "RLHF I think you're going to be\nmore around like the one million order of magnitude. It's still much less\nthan pretraining though.",
    "start": "5690755",
    "end": "5697380"
  },
  {
    "text": "Yeah. Because pretraining\nis 15 trillion tokens. I mean, this is like--\nthat's not even a drop",
    "start": "5697380",
    "end": "5702455"
  },
  {
    "text": "and yet you influence\nthe weight a lot. So because you do it-- I mean, you have to think that\nhow you do it is you use--",
    "start": "5702455",
    "end": "5710398"
  },
  {
    "text": "I mean, as I said, the learning\nrate that you're going to use is going to be different,\nbut also you only do that.",
    "start": "5710398",
    "end": "5716190"
  },
  {
    "text": "So just imagine if I trained-- even if I trained\non one sentence, but over and over\nagain at some point",
    "start": "5716190",
    "end": "5722690"
  },
  {
    "text": "my model will only\ngenerate that sentence even if it was just\none sentence instead of",
    "start": "5722690",
    "end": "5727730"
  },
  {
    "text": "the 15 trillion tokens. So if you use a\nlarge enough learning rate and for enough\ntime, you will basically",
    "start": "5727730",
    "end": "5733730"
  },
  {
    "text": "overfit that sentence. So the key thing to remember\nis that the data is not--",
    "start": "5733730",
    "end": "5739770"
  },
  {
    "text": "it's not as if you mix\nsome post-training data and some pretraining data. You do pretraining, and then\nyou just start fine-tuning only",
    "start": "5739770",
    "end": "5747389"
  },
  {
    "text": "on the post-training. So another way, maybe\nanother perspective is that the pretraining\nis just the initialization",
    "start": "5747390",
    "end": "5753270"
  },
  {
    "text": "of your model. And once you view it that\nway, that this is just initialization of weights,\nthen there's nothing special.",
    "start": "5753270",
    "end": "5759525"
  },
  {
    "text": "Like you don't need to remember\nthat you train on a lot of data before. The only thing that matters is\nthat you had an initialization",
    "start": "5759525",
    "end": "5764909"
  },
  {
    "text": "and now I actually\ntrain the model. So maybe you think\nabout it that way. Like this is a Markov\nproperty in some ways.",
    "start": "5764910",
    "end": "5770290"
  },
  {
    "text": "It's just like you\nhad your weights. This is my initialization. Now I'm training that one. Does that answer your question?",
    "start": "5770290",
    "end": "5776110"
  },
  {
    "text": "Kind of but you said\nsomething just now about it's almost the equivalent of just\nrerunning the fine tuning",
    "start": "5776110",
    "end": "5783929"
  },
  {
    "text": "data many times. Is it actually-- is that what\nactually happens in order to give so much more preference?",
    "start": "5783930",
    "end": "5790719"
  },
  {
    "text": " You might-- I actually don't\nknow right now how they do it",
    "start": "5790720",
    "end": "5797010"
  },
  {
    "text": "in industry. When we did our packet,\nwe had to do three epochs. So you did run it\nthree times through it.",
    "start": "5797010",
    "end": "5804570"
  },
  {
    "text": "But I mean, even\nthe number of times that you run it through,\nit's actually not important. The only thing-- the only thing\nis the effective learning rate",
    "start": "5804570",
    "end": "5812610"
  },
  {
    "text": "that what matters. So yeah. Great.",
    "start": "5812610",
    "end": "5818350"
  },
  {
    "text": "So I think I have five minutes. ",
    "start": "5818350",
    "end": "5826153"
  },
  {
    "text": "OK I might try to give a\nhigh-level overview at least",
    "start": "5826153",
    "end": "5832119"
  },
  {
    "text": "from one of the systems trick. Systems, as we said, for\neveryone bottleneck is--",
    "start": "5832120",
    "end": "5839200"
  },
  {
    "text": "sorry compute is\nthe huge bottleneck. One question you might ask\nis, why not buy more GPUs?",
    "start": "5839200",
    "end": "5844869"
  },
  {
    "text": "GPUs are expensive,\nbut also are scarce. Even if you have $10\nmillion right now, you cannot buy the best GPUs.",
    "start": "5844870",
    "end": "5851230"
  },
  {
    "text": "[INAUDIBLE] There's also some\nphysical limitations. When you have multiple\nGPUs, you have",
    "start": "5851230",
    "end": "5857770"
  },
  {
    "text": "to communicate between them. That takes time. So just buying more\nGPUs is not that easy.",
    "start": "5857770",
    "end": "5863679"
  },
  {
    "text": "So it's really\nimportant to think about how do you allocate resources\nand how do you optimize your pipeline, so system?",
    "start": "5863680",
    "end": "5869230"
  },
  {
    "text": "101 on GPUs, I'm sorry,\nI'm going slightly faster. I hope that some of you\nat least can follow.",
    "start": "5869230",
    "end": "5875800"
  },
  {
    "text": "GPUs are basically\noptimized for throughput. CPUs are optimized for latency.",
    "start": "5875800",
    "end": "5881449"
  },
  {
    "text": "So GPUs, the way you\nhave to think about it is that there's one-- there's one command that\nis run on many, many cores",
    "start": "5881450",
    "end": "5887840"
  },
  {
    "text": "at the same time on\ndifferent type of data. So this is how you see a GPU.",
    "start": "5887840",
    "end": "5893245"
  },
  {
    "text": "You see there are\nmany different codes. We call them streaming\nmultiprocessors, which is very different than\nthe usual CPU architecture.",
    "start": "5893245",
    "end": "5900360"
  },
  {
    "text": "So just think high throughput\nparallelization for GPUs. GPUs are optimized for\nfast matrix multiplication.",
    "start": "5900360",
    "end": "5907710"
  },
  {
    "text": "So every time you will do--\nyou will do something on GPU. If you can do it with a\nmatrix multiplication,",
    "start": "5907710",
    "end": "5913590"
  },
  {
    "text": "it's going to be 10 times\nfaster than with anything else. That is a little bit\nannoying because it means that we are,\nkind of, bottlenecked",
    "start": "5913590",
    "end": "5920780"
  },
  {
    "text": "to doing anything with\nmatrix multiplications. Another thing to\nnote with GPUs is",
    "start": "5920780",
    "end": "5926360"
  },
  {
    "text": "that compute has\nbeen improving faster than memory and communication. So right now GPUs usually\nare hard to keep--",
    "start": "5926360",
    "end": "5935750"
  },
  {
    "text": "Like the data that\nyou sent to GPUs is actually hard to keep\nup with the processes.",
    "start": "5935750",
    "end": "5940800"
  },
  {
    "text": "So most of your\nGPUs are actually going to be idle if you\njust run normal code, if you don't optimize your code.",
    "start": "5940800",
    "end": "5946350"
  },
  {
    "text": "So communication-- and this\nwill continue over time. Another thing to know\nabout GPUs is that there's",
    "start": "5946350",
    "end": "5952970"
  },
  {
    "text": "a memory hierarchy. This is the same thing\nactually with CPUs, but basically the closer\nyou are to your cores, the less memory there is,\nbut the faster things run.",
    "start": "5952970",
    "end": "5960660"
  },
  {
    "text": "If you are further,\nmore memory slower. Oh yeah I'm going to skip that.",
    "start": "5960660",
    "end": "5966140"
  },
  {
    "text": "OK actually, I'm\ngoing to say it. I told you about this-- the fact of communication.",
    "start": "5966140",
    "end": "5971150"
  },
  {
    "text": "The metric that\npeople usually look at is model FLOP utilization. So what is the theoretical\nmaximum that GPU could run at,",
    "start": "5971150",
    "end": "5977690"
  },
  {
    "text": "number of flops that you\ncould use per second-- divide-- sorry, the number\nof observed throughput",
    "start": "5977690",
    "end": "5982730"
  },
  {
    "text": "divided by this\ntheoretical maximum. And in general, if you\nreach 50% you're very happy.",
    "start": "5982730",
    "end": "5989400"
  },
  {
    "text": "Like Facebook I looked\nat llama was at 45 or something like this. So that means that data\ndoesn't come fast enough",
    "start": "5989400",
    "end": "5995960"
  },
  {
    "text": "even for these big companies. So one simple trick,\nand that might be the only one I'm\ngoing to tell you about,",
    "start": "5995960",
    "end": "6002580"
  },
  {
    "text": "is low precision. One simple idea is\nthat well, if I'm going to put my floats\nin low precision,",
    "start": "6002580",
    "end": "6009252"
  },
  {
    "text": "then there's going\nto be fewer bits that I have to send to my GPUs. If there's fewer bits,\nit's faster communication,",
    "start": "6009252",
    "end": "6014710"
  },
  {
    "text": "lower memory consumption. Things are going to go faster. And for deep learning\nit just happens that decimal is\nnot that important.",
    "start": "6014710",
    "end": "6022800"
  },
  {
    "text": "So when you do matrix\nmultiplication, when you do like for example, SGD,\nthere's already so much noise",
    "start": "6022800",
    "end": "6028380"
  },
  {
    "text": "that if you update something\nby 0.01 or 0.015, who cares.",
    "start": "6028380",
    "end": "6033840"
  },
  {
    "text": "So basically instead of using\n32 bits per float, which is what people used to use,\nor 64 for example, which",
    "start": "6033840",
    "end": "6041460"
  },
  {
    "text": "is what you would\nuse in other domains, you use 16 bits for\nmatrix multiplication. So for every float\nyou use 16 bits.",
    "start": "6041460",
    "end": "6049550"
  },
  {
    "text": "And for training\nyou have this type of what we call automatic\nmixed precision. Which is that some of the\nthings are in 32 bits,",
    "start": "6049550",
    "end": "6057220"
  },
  {
    "text": "others are in 60 bit-- on 16 bits. Generally, the way you\nshould be thinking about it is that your weights\nare stored-- of your model,",
    "start": "6057220",
    "end": "6065030"
  },
  {
    "text": "are stored in 32 bits. But just before the computation\nyou put everything in 16 bits.",
    "start": "6065030",
    "end": "6070510"
  },
  {
    "text": "Like this you do\ncomputation super fast. And at the end you update\nyour weights in 32 bits.",
    "start": "6070510",
    "end": "6076370"
  },
  {
    "text": "And the reason why you do all\nthe updates in 32 bits is just think that if your\nlearning rate, for example, is very small, you still\nwant to be able to make",
    "start": "6076370",
    "end": "6083409"
  },
  {
    "text": "a difference in your weights. So all the computation\nis done in 16 bits, but the weights are\nactually stored in 32 bits.",
    "start": "6083410",
    "end": "6090830"
  },
  {
    "text": "So that's like the standard\nway that people are doing it. OK, I'll actually\ntalk just about this,",
    "start": "6090830",
    "end": "6096850"
  },
  {
    "text": "and then I'll skip all the rest,\noperator fusion, because I think this is actually pretty cool. As I just said,\ncommunication is very slow",
    "start": "6096850",
    "end": "6102730"
  },
  {
    "text": "and actually every time\nyou use a PyTorch line, it basically moves variable\nto global memory of your GPU.",
    "start": "6102730",
    "end": "6109040"
  },
  {
    "text": "So when you have something like\nthis x dot cosine equal x1,",
    "start": "6109040",
    "end": "6114370"
  },
  {
    "text": "and then you do x1 dot cosine. What is happening\nbehind the scenes is that you take the\nx, which is data.",
    "start": "6114370",
    "end": "6120070"
  },
  {
    "text": "You ship it to your actual\nprocessors of your GPUs. You apply the cosine.",
    "start": "6120070",
    "end": "6125130"
  },
  {
    "text": "You ship it back to the\nmain memory of your GPU and then you see the next line. You ship it back to the\ncomputer-- to the GPU processor,",
    "start": "6125130",
    "end": "6132510"
  },
  {
    "text": "you apply another cosine\nand you ship it back again. So another way to\nsee that is that you",
    "start": "6132510",
    "end": "6137580"
  },
  {
    "text": "go from your DRAM, which is\nyour global memory and your GPU and you ship it to compute. You ship it back for every line.",
    "start": "6137580",
    "end": "6144110"
  },
  {
    "text": "This is a naive way of doing it. This seems very wasteful. So the idea, simple\nidea of operator fusion",
    "start": "6144110",
    "end": "6151770"
  },
  {
    "text": "is just communicate, do all the\ncomputation, ship it back once. And this is exactly\nwhat fused kernels are.",
    "start": "6151770",
    "end": "6159390"
  },
  {
    "text": "So if you ever want to make\nyour compute-- your computations in PyTorch much faster,\njust apply torch dot",
    "start": "6159390",
    "end": "6166950"
  },
  {
    "text": "compile on your model. This is going to make your\nmodel around 2 times faster.",
    "start": "6166950",
    "end": "6171970"
  },
  {
    "text": "And what it does is simply\nthat it rewrites your code-- your PyTorch code basically\nin C++ in CUDA to do",
    "start": "6171970",
    "end": "6183119"
  },
  {
    "text": "the communication only once\nthen do all the operations, then ship it back. OK I'm not going to have\ntime to talk about tiling.",
    "start": "6183120",
    "end": "6190389"
  },
  {
    "text": "Tiling is important. Parallelization. Parallelization is important.",
    "start": "6190390",
    "end": "6195420"
  },
  {
    "text": "And mixture of experts. Mixture of experts is important. Outlook. There are many things\nwe haven't talked about.",
    "start": "6195420",
    "end": "6203099"
  },
  {
    "text": "We haven't talked about\narchitectures we definitely haven't talked about inference. There are many other things\nthat are important with LLMs.",
    "start": "6203100",
    "end": "6209860"
  },
  {
    "text": "What is the UI that you use? I mean, arguably ChatGPT,\nthe big novelty was just have a simple UI to use it.",
    "start": "6209860",
    "end": "6215790"
  },
  {
    "text": "Multi-modality. What are all the\nmisuses you could have. The fact that there might not\nbe enough data on the internet",
    "start": "6215790",
    "end": "6221320"
  },
  {
    "text": "to train all these models. Legality of data collection,\nso many other things. If you are interested\nin all these topics,",
    "start": "6221320",
    "end": "6227699"
  },
  {
    "text": "I would suggest three classes. CS224N is probably the one\nthat touches the least on LLMs,",
    "start": "6227700",
    "end": "6234810"
  },
  {
    "text": "but it gives some background\nand historical context of all the LLMs and gives\nsome adjacent material.",
    "start": "6234810",
    "end": "6241510"
  },
  {
    "text": "CS324 I think it's called-- I think it's just called\nLarge Language Models, more",
    "start": "6241510",
    "end": "6247620"
  },
  {
    "text": "in depth reading and lectures\non everything I talked about. CS336 which is large\nlanguage model from scratch,",
    "start": "6247620",
    "end": "6253929"
  },
  {
    "text": "you actually build your own LLM. It's an amazing class also\ngiven by my two supervisors.",
    "start": "6253930",
    "end": "6260530"
  },
  {
    "text": "Very heavy workload,\nso be careful. Great. ",
    "start": "6260530",
    "end": "6271000"
  }
]
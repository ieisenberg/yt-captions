[
  {
    "start": "0",
    "end": "7747"
  },
  {
    "text": "A third of the way\nthrough the lecture today is an inflection\npoint in the course. We come to the emotional,\nI would say, the bottom.",
    "start": "7747",
    "end": "17080"
  },
  {
    "text": "And then we start climbing out. And so, later today, we'll\nbe talking about problems.",
    "start": "17080",
    "end": "22780"
  },
  {
    "text": "And then we're inching\nour way towards things that are actually actionable.",
    "start": "22780",
    "end": "27970"
  },
  {
    "text": "Things you can\nactually do and code. And that's coming. And so, it's a good point.",
    "start": "27970",
    "end": "34250"
  },
  {
    "text": "If you survived this\nfar, that's pretty good. Let me say a little\nbit more about that.",
    "start": "34250",
    "end": "41800"
  },
  {
    "text": "I mean, you don't need to, but\nthere's absolutely no reason that you couldn't basically\npip install CVXPY now",
    "start": "41800",
    "end": "49900"
  },
  {
    "text": "if you're curious. And then what you'll\nsee is the code is going to mirror actually all\nof the stuff we've done here.",
    "start": "49900",
    "end": "57280"
  },
  {
    "text": "The composition rules, all\nsorts of things like that. So, I mean, depends, but\nthis is not at all a bad time",
    "start": "57280",
    "end": "64120"
  },
  {
    "text": "to do that. By next week, you'll\nneed to do it. But it might be\nfun to actually see",
    "start": "64120",
    "end": "69980"
  },
  {
    "text": "the stuff we've\nbeen talking about, but now codified in,\nwell, Python in this case.",
    "start": "69980",
    "end": "76250"
  },
  {
    "text": "So it depends on\nyour learning style, but it might help make all\nof this look more real.",
    "start": "76250",
    "end": "82400"
  },
  {
    "text": "Well, it's going to get\nmore real very quickly.  Let's see, what else was\nI going to say about that?",
    "start": "82400",
    "end": "92060"
  },
  {
    "text": "Maybe that's it for now. And homework 2, I would\nalso mention is, I believe,",
    "start": "92060",
    "end": "101090"
  },
  {
    "text": "the last not-fun homework. That's the one you're\ndoing right now.",
    "start": "101090",
    "end": "106510"
  },
  {
    "text": "So we transition in homework 3\nto actually interesting stuff.",
    "start": "106510",
    "end": "112340"
  },
  {
    "text": "So just to give\nyou a rough idea. So you're not going to\nget 10 weeks of homework 1",
    "start": "112340",
    "end": "117760"
  },
  {
    "text": "and homework 2 type things. So we're going to segue\nto actually stuff that's",
    "start": "117760",
    "end": "124600"
  },
  {
    "text": "interesting and useful and\nall that kind of stuff. Any questions? Now I guess we are literally\nat the emotional low point",
    "start": "124600",
    "end": "131830"
  },
  {
    "text": "of the class. Although, I suppose\nif you've survived, then I guess that's good news.",
    "start": "131830",
    "end": "138460"
  },
  {
    "text": "Any questions about\nwhere we head from here?",
    "start": "138460",
    "end": "143860"
  },
  {
    "text": "OK. If not, what we'll\ndo is I'm going to finish with two\nmore useful extensions",
    "start": "143860",
    "end": "151210"
  },
  {
    "text": "of the idea of convexity that\nwe're going to use in the SQL.",
    "start": "151210",
    "end": "156562"
  },
  {
    "text": "Actually, everything\nwe talk about, we'll use in later in the class.",
    "start": "156562",
    "end": "161840"
  },
  {
    "text": "And remember, that\nI said that there's a whole industry\nof people coming up",
    "start": "161840",
    "end": "167330"
  },
  {
    "text": "with various extensions\nof convexity. And there's pseudoconvexity\nand quasiconvexity",
    "start": "167330",
    "end": "172670"
  },
  {
    "text": "and log convexity. We'll talk about that. All sorts of things. And there's a whole\nbunch of these things",
    "start": "172670",
    "end": "177830"
  },
  {
    "text": "and whole books written on them\nand all that kind of stuff. So we have selected a\nsmall subset of these",
    "start": "177830",
    "end": "184190"
  },
  {
    "text": "that are actually useful. Quasiconvex, which I talked\nabout last time, is one. And the other one,\nwhich is interesting,",
    "start": "184190",
    "end": "190250"
  },
  {
    "text": "comes up in a lot of\nfields, but especially in statistics is the idea of\nlog-concave and log-convex",
    "start": "190250",
    "end": "197340"
  },
  {
    "text": "functions. And that's what we're going\nto talk about today first. So what is it?",
    "start": "197340",
    "end": "202970"
  },
  {
    "text": "Actually, it's\nsuper-duper simple. We just say that a function,\nwhich has to be positive,",
    "start": "202970",
    "end": "208820"
  },
  {
    "text": "is log-concave. If its log, it's concave,\nso that's all it means.",
    "start": "208820",
    "end": "215150"
  },
  {
    "text": "Sorry, yes, log-concave. Now there's a weird\nasymmetry here.",
    "start": "215150",
    "end": "220560"
  },
  {
    "text": "And it turns out it's\nlog-concave things that come up all the time, not log-convex. So if you do a google\nsearch on log-concave,",
    "start": "220560",
    "end": "229400"
  },
  {
    "text": "you'll get zillions of papers\nand books and things like that. Log-convex, you'll\nget almost nothing.",
    "start": "229400",
    "end": "237505"
  },
  {
    "text": "I don't know the\nreason for that, but there's a weird asymmetry. So what that means is if you\ntake the Jensen inequality that",
    "start": "237505",
    "end": "245390"
  },
  {
    "text": "defines convexity for the log,\nand then you exponentiate it, then you get this. And it's actually\nreal interesting.",
    "start": "245390",
    "end": "251459"
  },
  {
    "text": "It says that a log-concave\nfunction, when you evaluate it, it at a mixture of arguments--",
    "start": "251460",
    "end": "258260"
  },
  {
    "text": "that's theta x plus\n1 minus theta y-- if it were concave,\nthis would simply",
    "start": "258260",
    "end": "265010"
  },
  {
    "text": "be bigger than or equal\nto the weighted arithmetic mean of f of x and f of y.",
    "start": "265010",
    "end": "271250"
  },
  {
    "text": "That's what it\nmeans to be concave. Here, this is the\nweighted geometric mean.",
    "start": "271250",
    "end": "277020"
  },
  {
    "text": "That's what people call it. So it's the weighted\ngeometric mean. So, for example,\nif theta is 1/2, it's literally the geometric\nmean of the two values.",
    "start": "277020",
    "end": "286099"
  },
  {
    "text": "I mean, this is just\nrepeating stuff. So there's a bunch of\nexamples, like these powers are",
    "start": "286100",
    "end": "295510"
  },
  {
    "text": "log-convex if a is negative. And they're\nlog-concave for a being bigger than or equal to 0.",
    "start": "295510",
    "end": "303010"
  },
  {
    "text": "So that's one. But mostly, it\ncomes up in things like probability densities.",
    "start": "303010",
    "end": "308500"
  },
  {
    "text": "So a good example is here's\na normal density on rn.",
    "start": "308500",
    "end": "315295"
  },
  {
    "text": "So that's the density of\na standard normal random variable. And here, if you\ntake a look at this,",
    "start": "315295",
    "end": "322315"
  },
  {
    "text": "this thing is log-concave. Let's check that. Well, if I take the log of\nit, this is just a constant.",
    "start": "322315",
    "end": "329350"
  },
  {
    "text": "And it's completely\nirrelevant for curvature. And then over here, you\ntake the log of that,",
    "start": "329350",
    "end": "335020"
  },
  {
    "text": "and you get a\nnegative quadratic. Sigma is positive definite. So this thing here is\ngoing to be concave.",
    "start": "335020",
    "end": "342160"
  },
  {
    "text": "And I'm including\nthe minus sign here. So that's your canonical\nexample of a log.",
    "start": "342160",
    "end": "348790"
  },
  {
    "text": "And in fact, if you\nhave a measure that has a density\nthat's log-concave,",
    "start": "348790",
    "end": "353840"
  },
  {
    "text": "it's called a\nlog-concave measure. And they're\nsuper-duper important in lots of different fields.",
    "start": "353840",
    "end": "359060"
  },
  {
    "text": "And it comes up in economics,\nit comes up in statistics a lot. And, again, this is just\na more advanced topic,",
    "start": "359060",
    "end": "366067"
  },
  {
    "text": "you don't have to know about it. It's, for example, a\nvery good regularizer. Like, if you say, I'm going to\nfit a distribution to my data",
    "start": "366067",
    "end": "373070"
  },
  {
    "text": "and you insist that\ndistribution be log-concave, that's actually a very\nsensible regularizer. Again, this is\njust for people who",
    "start": "373070",
    "end": "380479"
  },
  {
    "text": "know what I'm talking about. By the way, a ton of common\ndensities are log-concave.",
    "start": "380480",
    "end": "388310"
  },
  {
    "text": "I actually don't remember which\nones, but it's a long list.",
    "start": "388310",
    "end": "394460"
  },
  {
    "text": "Probably most or at least\nhalf of all named densities are log-concave.",
    "start": "394460",
    "end": "400070"
  },
  {
    "text": "And it's not very hard for you\nto figure out which is which, so those are some examples.",
    "start": "400070",
    "end": "406550"
  },
  {
    "text": "Here's one. This one is not obvious at all. There is going to be one new\nthing in this topic, which",
    "start": "406550",
    "end": "413990"
  },
  {
    "text": "I'll get to shortly. But this is not obvious at all. So here's the\ncumulative distribution",
    "start": "413990",
    "end": "419615"
  },
  {
    "text": "of a standard Gaussian\ndistribution on R. So",
    "start": "419615",
    "end": "424849"
  },
  {
    "text": "that's the CDF. Now, of course,\nthere's libraries",
    "start": "424850",
    "end": "430490"
  },
  {
    "text": "that compute this and\nall that sort of stuff. I mean, obviously. But this is not obvious at\nall, that this is actually",
    "start": "430490",
    "end": "437750"
  },
  {
    "text": "log-concave.  In fact, that's a\nhomework exercise.",
    "start": "437750",
    "end": "443810"
  },
  {
    "text": "And it's not a short\none, and it's got hints. So it's not totally\nobvious, but it's true.",
    "start": "443810",
    "end": "449773"
  },
  {
    "text": "Actually, we're\ngoing to see later that any CDF of any\ncumulative distribution",
    "start": "449773",
    "end": "456230"
  },
  {
    "text": "function of a\nlog-concave density is going to be also log-concave.",
    "start": "456230",
    "end": "462574"
  },
  {
    "text": " So here are some properties.",
    "start": "462575",
    "end": "469710"
  },
  {
    "text": "This just translates. If you write out\nthe formula for what the Hessian of the\nlog of f is, and you",
    "start": "469710",
    "end": "478500"
  },
  {
    "text": "say that's less than or equal\nto 0, in a matrix sense, then you take the x, and you get\nsomething that looks like that.",
    "start": "478500",
    "end": "485790"
  },
  {
    "text": "And it's actually interesting. Remember, f is\npositive, so this says that a positive\nmultiple of the Hessian",
    "start": "485790",
    "end": "493900"
  },
  {
    "text": "is less than or equal\nto, in a matrix sense, the outer product\nof the gradient. Now that's rank one.",
    "start": "493900",
    "end": "502043"
  },
  {
    "text": "And, again, this\nis more advanced, and we probably won't need this,\nbut I don't mind saying it. When a matrix is less than or\nequal to, in a rank 1 matrix,",
    "start": "502043",
    "end": "511470"
  },
  {
    "text": "it says that this\nthing can have at most one positive eigenvalue.",
    "start": "511470",
    "end": "517349"
  },
  {
    "text": "That's what it says. And it says, all the others are\ngoing to have to be negative. So that's the condition.",
    "start": "517350",
    "end": "524700"
  },
  {
    "text": "So some things are\nobvious, like product of log-concave functions\nis log-concave. That's obvious.",
    "start": "524700",
    "end": "530290"
  },
  {
    "text": "Because if I take two\nlog-concave functions, I multiply them. Now I take the log, it's\njust the sum of the logs.",
    "start": "530290",
    "end": "537199"
  },
  {
    "text": "So it relies on the deep\nfact that the sum of two concave functions is concave. So this one is easy.",
    "start": "537200",
    "end": "545410"
  },
  {
    "text": "Now the sum of\nlog-concave functions is not always log-concave.",
    "start": "545410",
    "end": "550540"
  },
  {
    "text": "In fact, someone want to give\nme a quick example using maybe the stuff we just looked at?",
    "start": "550540",
    "end": "558870"
  },
  {
    "text": "Set of two Gaussian densities? Somebody want to--\nall right, here we go.",
    "start": "558870",
    "end": "567779"
  },
  {
    "text": "Here's one Gaussian,\nand here's another one.",
    "start": "567780",
    "end": "577730"
  },
  {
    "text": "They're both log-concave. If I sum those, what do I get? I get some function that\ngoes up, has a bump,",
    "start": "577730",
    "end": "585529"
  },
  {
    "text": "comes back down, it\ngoes up again, and down. Could that be log-concave?",
    "start": "585530",
    "end": "591460"
  },
  {
    "text": "It could not be\nbecause, well, one way to say it is I\ncould look at it, I",
    "start": "591460",
    "end": "598720"
  },
  {
    "text": "could say it's not\nquasiconcave, for example. Because it's got a portion\nwhere it bends down,",
    "start": "598720",
    "end": "607990"
  },
  {
    "text": "so that's not log-concave. I'll let you flesh out\nthat example on the board.",
    "start": "607990",
    "end": "615160"
  },
  {
    "text": "And then it turns out\nthere is a nontrivial fact",
    "start": "615160",
    "end": "621279"
  },
  {
    "text": "about log-concave functions. As far as I know, this\nwasn't known until 1973,",
    "start": "621280",
    "end": "627700"
  },
  {
    "text": "whereas most of the other\nthings we've talked about were known maybe\nin the 1920s, '30s.",
    "start": "627700",
    "end": "632740"
  },
  {
    "text": "Or maybe no one really\nasked the question. And it was so simple that had\nwe asked people in the 1920s, they would have known.",
    "start": "632740",
    "end": "639430"
  },
  {
    "text": "I believe this to not\nbe the case for this. So the rule is this. It says that if you have a\nfunction that's log-concave",
    "start": "639430",
    "end": "648190"
  },
  {
    "text": "in two variables and you\nintegrate out over 1-- so that's this thing--",
    "start": "648190",
    "end": "653795"
  },
  {
    "text": " then the result is log-concave.",
    "start": "653795",
    "end": "659790"
  },
  {
    "text": "So that's the integration rule.  It's not obvious.",
    "start": "659790",
    "end": "666589"
  },
  {
    "text": "It's not simple to prove. I mean, it's not\nhugely complicated, but it's not simple.",
    "start": "666590",
    "end": "674430"
  },
  {
    "text": "And it's cool. It's relatively recent. By the way, this\nimmediately-- well, we'll get to that in a second.",
    "start": "674430",
    "end": "680420"
  },
  {
    "text": "There are some examples. So that tells you\nthat log-concavity",
    "start": "680420",
    "end": "686550"
  },
  {
    "text": "is preserved under convolution. So this is the convolution. ",
    "start": "686550",
    "end": "696780"
  },
  {
    "text": "And it says that if f and\ng are log-concave, then",
    "start": "696780",
    "end": "701790"
  },
  {
    "text": "their convolution is. And so, in probability\nwhat this tells you is if I have two\nrandom variables, each",
    "start": "701790",
    "end": "707880"
  },
  {
    "text": "with a log-concave\ndensity, and I add them, then that distribution\nis also log-concave.",
    "start": "707880",
    "end": "716950"
  },
  {
    "text": "So that's what that tells you.  Here's a super interesting one.",
    "start": "716950",
    "end": "724589"
  },
  {
    "text": "If I have a convex set in Rn,\nand I have a random variable",
    "start": "724590",
    "end": "731580"
  },
  {
    "text": "with a log-concave density. Then if I look at the\nprobability that x plus y",
    "start": "731580",
    "end": "738780"
  },
  {
    "text": "is in C, that is a\nlog-concave function of x.",
    "start": "738780",
    "end": "744585"
  },
  {
    "text": " Actually, this is\nalready super interesting",
    "start": "744585",
    "end": "750079"
  },
  {
    "text": "because C could be the set\nof values, where some product",
    "start": "750080",
    "end": "757610"
  },
  {
    "text": "actually works or functions. It meets all the specs. Then y actually tells you\nabout the distribution",
    "start": "757610",
    "end": "767720"
  },
  {
    "text": "under manufacture of\nthose specifications. Then x is like the target.",
    "start": "767720",
    "end": "773300"
  },
  {
    "text": "It's how you actually, in\nthe factory, what you target. So I will target 3 nanometers\nfor this critical dimension,",
    "start": "773300",
    "end": "782870"
  },
  {
    "text": "for example. And then what this tells you is\nif you're targeting this and y",
    "start": "782870",
    "end": "788990"
  },
  {
    "text": "gives you your\nmanufacturing errors-- I asked for 3\nnanometers, I'm actually going to get let's\nsay, I don't know,",
    "start": "788990",
    "end": "796160"
  },
  {
    "text": "some distribution\nthat's a log-concave, it'll be spread around that.",
    "start": "796160",
    "end": "801560"
  },
  {
    "text": "And what this says, this then\nbecomes basically the yield. And we'll talk about that.",
    "start": "801560",
    "end": "807450"
  },
  {
    "text": "So it says that the\nyield is log-concave. We'll talk about that. But that's already getting\nvery close to a very serious",
    "start": "807450",
    "end": "814350"
  },
  {
    "text": "application. Now how do you show this? Well, I'm just going to write\nit as an integral formula.",
    "start": "814350",
    "end": "822509"
  },
  {
    "text": "And what I do is I have\ntwo things here. p, that's",
    "start": "822510",
    "end": "828450"
  },
  {
    "text": "my assumption log-concave. And I have this\nfunction g of x plus y. And g is a 0, 1\nindicator function.",
    "start": "828450",
    "end": "835290"
  },
  {
    "text": "It's 1, if you're in C,\n0, if you're outside. That's a log-concave\nfunction because it's",
    "start": "835290",
    "end": "842250"
  },
  {
    "text": "a log-concave function\nthat basically has value 0 inside the log of that. It has the log of the\nindicator is 0 inside C,",
    "start": "842250",
    "end": "849600"
  },
  {
    "text": "and it's minus infinity outside\nC. That's log-concave function. ",
    "start": "849600",
    "end": "857790"
  },
  {
    "text": "And if you work out what\nthis integral is, it's that. Oh, and here, this\nthing is actually",
    "start": "857790",
    "end": "865820"
  },
  {
    "text": "a log-concave\nfunction precomposed with an affine mapping. And that is going to\nbe also log-concave.",
    "start": "865820",
    "end": "873990"
  },
  {
    "text": "So there you go. Something like that. ",
    "start": "873990",
    "end": "880700"
  },
  {
    "text": "And let's talk about this yield\nfunction a little bit more just for fun.",
    "start": "880700",
    "end": "885990"
  },
  {
    "text": "So here you go. We have x are some nominal\nparameter values for a product.",
    "start": "885990",
    "end": "893490"
  },
  {
    "text": "It's what you intend\nto manufacture. And this is a vector\nof different things.",
    "start": "893490",
    "end": "900420"
  },
  {
    "text": "S is going to be the set\nof acceptable values. So if you're\ndesigning a circuit,",
    "start": "900420",
    "end": "907140"
  },
  {
    "text": "it would tell you if\nvarious parameters, based",
    "start": "907140",
    "end": "912330"
  },
  {
    "text": "on your circuit, come\nout in the right range, it's actually going to work. So that's an example.",
    "start": "912330",
    "end": "918990"
  },
  {
    "text": "And then w. This is what we target. And w is this model's\nrandom variations",
    "start": "918990",
    "end": "928020"
  },
  {
    "text": "that happens under manufacture. So that's it. And then this is the yield.",
    "start": "928020",
    "end": "933690"
  },
  {
    "text": "And it's a yield as a function\nof basically the settings",
    "start": "933690",
    "end": "939480"
  },
  {
    "text": "you target. And so, it's pretty\nclear what you want. If I wanted large yield\nand I had a set here,",
    "start": "939480",
    "end": "949180"
  },
  {
    "text": "I mean, the intuition\nbehind this is pretty clear. Here, here's my set. So it works if\nyou land in there.",
    "start": "949180",
    "end": "957640"
  },
  {
    "text": "And let's make it simple, let's\nassume that the perturbations are Gaussian. So what happens is you\ntell me what the yield is.",
    "start": "957640",
    "end": "965470"
  },
  {
    "text": "What have I set my targets here? And here's Gaussian. There's one sigma two sigma.",
    "start": "965470",
    "end": "971710"
  },
  {
    "text": "Go ahead, what's\nthe yield for that? [INAUDIBLE]",
    "start": "971710",
    "end": "977227"
  },
  {
    "text": " I don't know, 10%?",
    "start": "977228",
    "end": "983140"
  },
  {
    "text": "Which is not very good. Everybody got that? So make sense? ",
    "start": "983140",
    "end": "989370"
  },
  {
    "text": "So that was a poor choice of x. What if I'm right\nhere, and let's say",
    "start": "989370",
    "end": "995759"
  },
  {
    "text": "that's the one sigma thing. What's the yield\nif I target there? What is it?",
    "start": "995760",
    "end": "1001100"
  },
  {
    "text": "50. Yeah, it's a little\nbit less than 50. And if this was just a\nhalf-space, it'd be 50%.",
    "start": "1001100",
    "end": "1009020"
  },
  {
    "text": "But also fail by\ncoming out over here. So let's say it's 45%. I'm making that\nup, but that's it.",
    "start": "1009020",
    "end": "1015630"
  },
  {
    "text": "Everybody got this? Now after these\nexamples, you tell me what should I target\nto maximize the yield?",
    "start": "1015630",
    "end": "1023820"
  },
  {
    "text": "I mean, it's kind of obvious. The middle. Yeah, the center. Yeah, so what I should\ndo is set my target here.",
    "start": "1023820",
    "end": "1032550"
  },
  {
    "text": "And then if that's\n1 sigma and 2 sigma, I'm going to have a\nvery happy yield there.",
    "start": "1032550",
    "end": "1038160"
  },
  {
    "text": "Going to be 90% or 95%\nor something like that. Everybody got this? So this is in 2D.",
    "start": "1038160",
    "end": "1044099"
  },
  {
    "text": "And what this says is\nthis goes down in 10. The exact same\nproblem is you could do this in 10 dimensions\nor something like that.",
    "start": "1044099",
    "end": "1052650"
  },
  {
    "text": "By the way, you said\nthe center of the set. And what's interesting\nis that's something",
    "start": "1052650",
    "end": "1058080"
  },
  {
    "text": "we're going to look\nat later in the class. But turns out there's a ton\nof different definitions of the center of a set,\nwhich we'll get to later.",
    "start": "1058080",
    "end": "1066990"
  },
  {
    "text": "Actually, we may\nsee one later today. It depends how far I\nget, but we'll see. We may see one later. So in R it's very simple.",
    "start": "1066990",
    "end": "1075000"
  },
  {
    "text": "If I give you an\ninterval, there's not much discussion about what\nthe center of an interval is.",
    "start": "1075000",
    "end": "1081970"
  },
  {
    "text": "It's the midpoint\nof the interval. Any sensible center\nis going to be that. But immediately when you\nget into two dimensions,",
    "start": "1081970",
    "end": "1089320"
  },
  {
    "text": "it's not clear what\nthe center of a set is. And we'll see there's lots of\ndifferent definitions of it.",
    "start": "1089320",
    "end": "1095110"
  },
  {
    "text": "So what this says is\nactually super interesting.",
    "start": "1095110",
    "end": "1100220"
  },
  {
    "text": "It says that y is log-concave. And that says that if\nI fix a minimum yield,",
    "start": "1100220",
    "end": "1106690"
  },
  {
    "text": "we cannot economically\nmanufacture this product unless the yield is bigger than 85%.",
    "start": "1106690",
    "end": "1112360"
  },
  {
    "text": "Then it says this is a yield\nregion, and it's convex. It could be empty, which\nwould be too bad for you,",
    "start": "1112360",
    "end": "1119019"
  },
  {
    "text": "but it is convex. And the reason is\nthis is log-concave.",
    "start": "1119020",
    "end": "1124900"
  },
  {
    "text": "So if I exponentiate\nboth sides or take a log, I get log y is bigger\nthan log alpha.",
    "start": "1124900",
    "end": "1130510"
  },
  {
    "text": "Log y is concave. This is a super-level set. And a super-level set of a\nconcave function is convex.",
    "start": "1130510",
    "end": "1136345"
  },
  {
    "text": " Everybody following this?",
    "start": "1136345",
    "end": "1141460"
  },
  {
    "text": "So this is actually close to\nan actual application that's",
    "start": "1141460",
    "end": "1147039"
  },
  {
    "text": "incredibly useful,\nwhich should be obvious. And the last generalization\nwe're going to look at",
    "start": "1147040",
    "end": "1154340"
  },
  {
    "text": "is convexity with respect\nto a generalized inequality. So here it is.",
    "start": "1154340",
    "end": "1160580"
  },
  {
    "text": "Here I have a function that\nmaps Rn not into R but into Rm, so it's vector-valued.",
    "start": "1160580",
    "end": "1165770"
  },
  {
    "text": "So you give it x, and\nit produces a vector. ",
    "start": "1165770",
    "end": "1171080"
  },
  {
    "text": "We say that this\nfunction is K-convex. K is a proper cone.",
    "start": "1171080",
    "end": "1177530"
  },
  {
    "text": "And we say that that's true\nif Jensen's inequality holds, except that the left- and\nright-hand sides are all",
    "start": "1177530",
    "end": "1182900"
  },
  {
    "text": "vectors. And the inequality\nis the inequality induced by this cone.",
    "start": "1182900",
    "end": "1189500"
  },
  {
    "text": "So most famous example is\nwith symmetric matrices. So if I have a mapping\nfrom symmetric matrices",
    "start": "1189500",
    "end": "1195830"
  },
  {
    "text": "to symmetric matrices--\nhere's an example. f of capital X is x squared. X is a symmetric matrix.",
    "start": "1195830",
    "end": "1201470"
  },
  {
    "text": "And the function\nis, I square it. By the way, you'd guess it\nsure sounds convex, right?",
    "start": "1201470",
    "end": "1209900"
  },
  {
    "text": "Because it's the square, and\nyou know that in a scalar case,",
    "start": "1209900",
    "end": "1215250"
  },
  {
    "text": "x is. And in this case, that\nguess turns out to be true. What you'd have to\nshow is the following.",
    "start": "1215250",
    "end": "1222360"
  },
  {
    "text": "It says, what you\nwant to show is if I take two symmetric matrices.",
    "start": "1222360",
    "end": "1228450"
  },
  {
    "text": "If I then form a\nmixture of them, so theta x plus 1 minus theta y.",
    "start": "1228450",
    "end": "1234420"
  },
  {
    "text": "That's a new symmetric matrix. If I square that, that's\nless than or equal to theta",
    "start": "1234420",
    "end": "1240810"
  },
  {
    "text": "x squared plus theta 1\nminus theta y squared. What does that mean? That means that this inequality\nhere holds for all z.",
    "start": "1240810",
    "end": "1250042"
  },
  {
    "text": "So this is what this means. ",
    "start": "1250042",
    "end": "1256559"
  },
  {
    "text": "We could look at this. This does hold for all z\nbecause these are all simply",
    "start": "1256560",
    "end": "1263309"
  },
  {
    "text": "convex functions. And this thing is a\nconvex function here of x.",
    "start": "1263310",
    "end": "1270870"
  },
  {
    "text": "So that requires a tricky\nreading there, but it is.",
    "start": "1270870",
    "end": "1277740"
  },
  {
    "text": "So this is the idea. Like with all generalizations,\nyou want to be on your toes",
    "start": "1277740",
    "end": "1283679"
  },
  {
    "text": "because not everything\nyou think is true. I think a famous one\nis the exponential",
    "start": "1283680",
    "end": "1291580"
  },
  {
    "text": "of a symmetric matrix. That sure sounds convex. I think it's not.",
    "start": "1291580",
    "end": "1296890"
  },
  {
    "text": "I could be wrong on that. That just came out,\nand maybe I'm wrong. But if it's not\nx, it's something",
    "start": "1296890",
    "end": "1303010"
  },
  {
    "text": "like that, where it sure sounds\nlike it ought to be true. And it just turns out, it's not.",
    "start": "1303010",
    "end": "1309940"
  },
  {
    "text": "That one might be actually. I can't remember what is\nthe simple example that violates that.",
    "start": "1309940",
    "end": "1315610"
  },
  {
    "text": "So that wraps up, actually,\nall the analysis you",
    "start": "1315610",
    "end": "1321880"
  },
  {
    "text": "need to know for the course. What I would actually recommend\ndoing is every now and then,",
    "start": "1321880",
    "end": "1330310"
  },
  {
    "text": "give yourself a half\nan hour and go back to chapters either 1, 2, or\n3, and just reread part of it.",
    "start": "1330310",
    "end": "1337240"
  },
  {
    "text": "What's going to\nhappen is something that made absolutely\nno sense whatsoever to you maybe two weeks ago is\ngoing to start making sense.",
    "start": "1337240",
    "end": "1345890"
  },
  {
    "text": "I mean, for one thing, it'll be\nthe fourth time you've seen it or something like\nthat, but also, it's going to connect to other stuff.",
    "start": "1345890",
    "end": "1351750"
  },
  {
    "text": "So this would be my\nstrong recommendation to do something like that.",
    "start": "1351750",
    "end": "1358340"
  },
  {
    "text": "So now we're\nstarting on problems, which is not analysis.",
    "start": "1358340",
    "end": "1364520"
  },
  {
    "text": "And, of course, the underlying\npoint of all of this is the following.",
    "start": "1364520",
    "end": "1370130"
  },
  {
    "text": "Convex optimization\nproblems are tractable. Basically, we can solve them.",
    "start": "1370130",
    "end": "1375980"
  },
  {
    "text": "That's the point. So it's not a question\nof math when you say, oh,",
    "start": "1375980",
    "end": "1381830"
  },
  {
    "text": "that problem is convex. I mean, sure it\nallows you to make certain assertions about here\nare the optimality conditions.",
    "start": "1381830",
    "end": "1388580"
  },
  {
    "text": "I mean, whatever. The most important part about\nit is you can actually solve it. Now that will segue to in\nmaybe three or four weeks",
    "start": "1388580",
    "end": "1397160"
  },
  {
    "text": "or something like that. But that's what makes\neverything you just did in the last two\nweeks actionable,",
    "start": "1397160",
    "end": "1404120"
  },
  {
    "text": "so that's going to be the point. So what we're going\nto do now is we're going to march through\nwhat convex optimization",
    "start": "1404120",
    "end": "1411870"
  },
  {
    "text": "problems are. I mean, we already introduced\nthis very informally on day one, but now we're\ngoing to do it more carefully.",
    "start": "1411870",
    "end": "1419010"
  },
  {
    "text": "So first of all,\nlet's talk about what is an optimization problem. So I actually think of it\nas an object, literally,",
    "start": "1419010",
    "end": "1429270"
  },
  {
    "text": "in the computer science\nsense, it has attributes. It has an attribute, which is,\nsay, this is the objective.",
    "start": "1429270",
    "end": "1439110"
  },
  {
    "text": "And the objective is to minimize\nf0 of x. f0 of x is a function.",
    "start": "1439110",
    "end": "1444690"
  },
  {
    "text": "So by the way, minimize is\nnot a keyword in mathematics.",
    "start": "1444690",
    "end": "1449850"
  },
  {
    "text": "It is not. Min is, and it only\nmeans and can only mean one thing, which is\nthe minimum of a finite set",
    "start": "1449850",
    "end": "1458070"
  },
  {
    "text": "of numbers, period. That's the only definition\nof min that's in math. Min and minimize\nare not the same.",
    "start": "1458070",
    "end": "1464070"
  },
  {
    "text": " When I get lazy and I\ndon't want to write out minimize on the\nboard, I'll write min,",
    "start": "1464070",
    "end": "1469860"
  },
  {
    "text": "but I'll put a period\nthere at the end. ",
    "start": "1469860",
    "end": "1475530"
  },
  {
    "text": "If I don't, then you should\ncall me on it or something.",
    "start": "1475530",
    "end": "1481890"
  },
  {
    "text": "So we minimize an\nobjective function here. Subject to. And we have inequality\nconstraints and equality",
    "start": "1481890",
    "end": "1487860"
  },
  {
    "text": "constraints. Now for simplicity, we're going\nto call this the standard form. In the standard form,\nyou're minimizing something.",
    "start": "1487860",
    "end": "1495420"
  },
  {
    "text": "You could easily\nmaximize something. And there's whole fields\nwhere everything they do is they maximize, like in\neconomics, you maximize utility",
    "start": "1495420",
    "end": "1502980"
  },
  {
    "text": "or you maximize profit\nor something like that. So there's different fields. And then all you have to\ndo is minimize minus f0.",
    "start": "1502980",
    "end": "1511440"
  },
  {
    "text": "There's a question. Yeah, does the inequality\nalways have to be less than or equal like an\nupper bound or-- Yeah, so that's\na great question.",
    "start": "1511440",
    "end": "1518049"
  },
  {
    "text": "This is just to make\nit standard form. This question is, does it\nalways have to be less than",
    "start": "1518050",
    "end": "1523679"
  },
  {
    "text": "or equal to? It can be bigger\nthan or equal to. Suppose you wanted to impose\nthe constraint that f1 of x",
    "start": "1523680",
    "end": "1530460"
  },
  {
    "text": "is bigger than or equal to 0. What you'd do is you'd\nwrite that as minus f of x",
    "start": "1530460",
    "end": "1535690"
  },
  {
    "text": "is less than or equal to 0.  And we're going to\nbe talking a lot",
    "start": "1535690",
    "end": "1541870"
  },
  {
    "text": "about these little\ntransformations that you can do to map\nthings into this form. Actually, a whole\nbunch of them are",
    "start": "1541870",
    "end": "1547600"
  },
  {
    "text": "going to be done automatically\nfor you in some cases. And we have a\nequality constraints.",
    "start": "1547600",
    "end": "1554170"
  },
  {
    "text": "And so, this is the idea.",
    "start": "1554170",
    "end": "1559290"
  },
  {
    "text": "The optimal value\nof this problem-- so this is an object.",
    "start": "1559290",
    "end": "1564519"
  },
  {
    "text": "It's a problem. It's got a bunch of different\nfields or attributes. It's got it's objective.",
    "start": "1564520",
    "end": "1569850"
  },
  {
    "text": "It's got a list of\ninequality constraints. It's got a list of\nequality constraints. So that's the way I think\nof an optimization problem.",
    "start": "1569850",
    "end": "1580300"
  },
  {
    "text": "So its optimal value\nis the following.",
    "start": "1580300",
    "end": "1586300"
  },
  {
    "text": "It is inf is\nessentially the minimum. It's the minimum of the\nobjective value over all points",
    "start": "1586300",
    "end": "1593790"
  },
  {
    "text": "x that are feasible. And to be feasible\nmeans you have to satisfy these inequalities\nand all of these equalities",
    "start": "1593790",
    "end": "1600330"
  },
  {
    "text": "like that. So this predicate here\nsays x is feasible.",
    "start": "1600330",
    "end": "1606270"
  },
  {
    "text": "And it says if among\nall such x's, you have the smallest\nvalue of the objective,",
    "start": "1606270",
    "end": "1612990"
  },
  {
    "text": "then that value is\nthe optimal value. And that's denoted p star.",
    "start": "1612990",
    "end": "1620208"
  },
  {
    "text": "By the way, there's a\nslight subtlety here. That's a star not an asterisk.",
    "start": "1620208",
    "end": "1625330"
  },
  {
    "text": "Asterisk is reserved for\nthings like conjugates and some other stuff that we'll\nbe doing in a couple of weeks.",
    "start": "1625330",
    "end": "1631659"
  },
  {
    "text": "But here, star means optimal. ",
    "start": "1631660",
    "end": "1636820"
  },
  {
    "text": "Now this is standard math. If this set is empty,\nthat means there",
    "start": "1636820",
    "end": "1641890"
  },
  {
    "text": "is no x that satisfies these. Then, by definition, the minimum\nor the infimum of the empty set",
    "start": "1641890",
    "end": "1649000"
  },
  {
    "text": "is plus infinity. Actually, it's not\na bad definition. Well, it doesn't matter. It is the definition.",
    "start": "1649000",
    "end": "1656710"
  },
  {
    "text": "And everything makes sense then. A bunch of rules you'd\nimagine work with that.",
    "start": "1656710",
    "end": "1662673"
  },
  {
    "text": "But that's the\nstandard definition that we-- so if I say p star is\ninfinity for this problem, what it means is there is no x\nthat satisfies the inequality.",
    "start": "1662673",
    "end": "1672610"
  },
  {
    "text": "Now there's another\nthing that can happen is you can have p\nstar equals minus infinity. And I'll tell you\nwhat that means.",
    "start": "1672610",
    "end": "1677950"
  },
  {
    "text": "What it means is there's a\nsequence of points every. Single one of them is feasible.",
    "start": "1677950",
    "end": "1683060"
  },
  {
    "text": "And this objective goes\ndown and down and down. It gets as small as you like.",
    "start": "1683060",
    "end": "1689139"
  },
  {
    "text": "Both of these, by the\nway, are pathologies in a practical sense\nof the problem.",
    "start": "1689140",
    "end": "1694360"
  },
  {
    "text": "So if I walk up\nto you and say, I need you to solve this\nproblem and it's infeasible,",
    "start": "1694360",
    "end": "1699640"
  },
  {
    "text": "what does that mean? If you say, I want to\nconstruct the optimal schedule or something for something\nin the optimal allocation",
    "start": "1699640",
    "end": "1706360"
  },
  {
    "text": "of resources, and it's\ninfeasible, I mean, as a practical matter,\nit's of no use.",
    "start": "1706360",
    "end": "1711430"
  },
  {
    "text": "I mean, actually,\nall it really tells you is that formulated my\nproblem in a stupid way.",
    "start": "1711430",
    "end": "1716860"
  },
  {
    "text": "This is called unbounded below. And that's also a\npathology typically.",
    "start": "1716860",
    "end": "1723438"
  },
  {
    "text": "Actually, there's a wonderful\nname for this in some contexts. In some contexts, in\nrisk-averse control,",
    "start": "1723438",
    "end": "1729040"
  },
  {
    "text": "this thing is referred to as\neuphoric breakdown, which is,",
    "start": "1729040",
    "end": "1734110"
  },
  {
    "text": "I think, a great phrase for it. Let's remember what the\nsemantics of this is.",
    "start": "1734110",
    "end": "1739270"
  },
  {
    "text": "The semantics is we\nare OK with any x that satisfies these constraints.",
    "start": "1739270",
    "end": "1745150"
  },
  {
    "text": "And we are completely not OK\nwith anything that violates them even slightly, number one.",
    "start": "1745150",
    "end": "1751540"
  },
  {
    "text": "Then among ones that are\nOK, which means feasible, then we are happier\nthe smaller f0 gets.",
    "start": "1751540",
    "end": "1760750"
  },
  {
    "text": "So if, in fact, there are\nfeasible points, with values, it's basically, hey,\nminimize my cost,",
    "start": "1760750",
    "end": "1768320"
  },
  {
    "text": "which is my negative profit. And you go, yeah,\nwell, I mean, here's a feasible x that\ngives u minus 10.",
    "start": "1768320",
    "end": "1776020"
  },
  {
    "text": "And you go cool, I\njust made $10 million. And they go, here's\nanother one with minus 20. And you go $20\nmillion, that's great.",
    "start": "1776020",
    "end": "1783610"
  },
  {
    "text": "Anyway, so that's\nwhy that's called sometimes euphoric breakdown.",
    "start": "1783610",
    "end": "1789580"
  },
  {
    "text": "So this is just\nthe nomenclature. So we can talk about\nwhat is a point.",
    "start": "1789580",
    "end": "1798320"
  },
  {
    "text": "Is it optimal and all that. But first, we say that\na point is feasible if it's in the domain\nof the objective",
    "start": "1798320",
    "end": "1804050"
  },
  {
    "text": "and it satisfies\nthe constraints. And we say it's optimal if\nit simply is feasible and has",
    "start": "1804050",
    "end": "1811730"
  },
  {
    "text": "this optimal value. And then capital X opt, that's\nthe set of optimal points",
    "start": "1811730",
    "end": "1819019"
  },
  {
    "text": "which, by the way, is convex. It's not hard to show.",
    "start": "1819020",
    "end": "1824810"
  },
  {
    "text": "Because it's the p star\nsublevel sets of f0",
    "start": "1824810",
    "end": "1832850"
  },
  {
    "text": "intersect the feasible\nset which is convex. So if you follow that, great. If you didn't, that's OK, too.",
    "start": "1832850",
    "end": "1840620"
  },
  {
    "text": "Now we have another concept\nwhich is locally optimal. And locally optimal,\nvery roughly speaking,",
    "start": "1840620",
    "end": "1847580"
  },
  {
    "text": "it says that you're optimal\nin a restricted range around that current point.",
    "start": "1847580",
    "end": "1853800"
  },
  {
    "text": "And, here, I'll draw one. It's our last example here. I'll just draw that function.",
    "start": "1853800",
    "end": "1860310"
  },
  {
    "text": "I'll try to get a marker\nthat's actually visible.",
    "start": "1860310",
    "end": "1865780"
  },
  {
    "text": "So we have x cubed minus 3x. And that function\nlooks like this.",
    "start": "1865780",
    "end": "1872650"
  },
  {
    "text": "That's minus 1\nand that's plus 1. That's your function.",
    "start": "1872650",
    "end": "1878440"
  },
  {
    "text": "That's x cubed minus 3x. And so, what's p\nstar for that one?",
    "start": "1878440",
    "end": "1885760"
  },
  {
    "text": "No constraints. Just what is p star? It's minus infinity\nbecause these values",
    "start": "1885760",
    "end": "1893320"
  },
  {
    "text": "go as low as you like. Then this is a\nlocally optimal point.",
    "start": "1893320",
    "end": "1902350"
  },
  {
    "text": "Because, for example,\nif I add the constraint that x is between 0.5 and 1.5.",
    "start": "1902350",
    "end": "1910270"
  },
  {
    "text": "If it's within 0.5 of 1. And then I simply ask,\nwhat's the minimum?",
    "start": "1910270",
    "end": "1916030"
  },
  {
    "text": "That's a locally optimal point. It's optimal for that\nrestricted problem. So that's locally optimal.",
    "start": "1916030",
    "end": "1922600"
  },
  {
    "text": "Let's look at a couple of other\nexamples just to explain this. Let's take f of x is 1 over x.",
    "start": "1922600",
    "end": "1929590"
  },
  {
    "text": "The domain is R plus\nplus, so positive things. It just goes down like this.",
    "start": "1929590",
    "end": "1934900"
  },
  {
    "text": "And p star is 0 because\nthe infimum of 1 over x.",
    "start": "1934900",
    "end": "1940482"
  },
  {
    "text": "As x gets bigger and bigger,\nthat gets smaller and smaller. It's going towards 0. So p star is 0.",
    "start": "1940482",
    "end": "1946610"
  },
  {
    "text": "There's no optimal point. And you're not allowed\nto say x equals infinity. That's not a valid choice.",
    "start": "1946610",
    "end": "1953039"
  },
  {
    "text": "So there's no optimal point. There's no x for which\n1 over x is equal to 0.",
    "start": "1953040",
    "end": "1958190"
  },
  {
    "text": " How about minus log x?",
    "start": "1958190",
    "end": "1964580"
  },
  {
    "text": "That's convex. The domain is,\nagain, R plus plus.",
    "start": "1964580",
    "end": "1970100"
  },
  {
    "text": "And that's actually\nunbounded below.",
    "start": "1970100",
    "end": "1975110"
  },
  {
    "text": "Just like here, it's got\nsomething that goes down to 0. ",
    "start": "1975110",
    "end": "1981559"
  },
  {
    "text": "So here, as x gets really\nbig, this gets as negative as you would like. Maybe slowly, doesn't matter.",
    "start": "1981560",
    "end": "1988160"
  },
  {
    "text": "It's p star is minus infinity. x log x. That's the negative entropy.",
    "start": "1988160",
    "end": "1993950"
  },
  {
    "text": "And that looks like this. ",
    "start": "1993950",
    "end": "1999470"
  },
  {
    "text": "That's this function here. Looks like that, roughly. Oh, it's got an\ninfinite slope here,",
    "start": "1999470",
    "end": "2006710"
  },
  {
    "text": "so I'll make it like that. It's got infinite\nslope right here. By the way, you can either\ndefine the value at 0",
    "start": "2006710",
    "end": "2014419"
  },
  {
    "text": "to be 0, which is what it\nwould be by continuity.",
    "start": "2014420",
    "end": "2020150"
  },
  {
    "text": "Where the expression x log x\ndoesn't quite make sense there. I mean, just by continuity,\nyou could make it 0 there.",
    "start": "2020150",
    "end": "2028730"
  },
  {
    "text": "And that's what people do.  This one has no pathologies.",
    "start": "2028730",
    "end": "2037850"
  },
  {
    "text": "It's got a single\nminimum right there. And that value is at 1 over e.",
    "start": "2037850",
    "end": "2044570"
  },
  {
    "text": "There you go. That's the minimum value\nof the negative entropy or that maximizes\nthis entropy function.",
    "start": "2044570",
    "end": "2051679"
  },
  {
    "text": " So this is just to give you the\nnomenclature of optimization",
    "start": "2051680",
    "end": "2058304"
  },
  {
    "text": "problems.  A few more things. Yeah. ",
    "start": "2058304",
    "end": "2065340"
  },
  {
    "text": "So why is there-- in the last example,\nyou can say that there's",
    "start": "2065340",
    "end": "2070349"
  },
  {
    "text": "a fourth break down the\np star negative infinity. But then the first example,\nyou can't say the same?",
    "start": "2070350",
    "end": "2077310"
  },
  {
    "text": "Because this is not\nunbounded below. Unbounded below means\nthat the objective values",
    "start": "2077310",
    "end": "2083129"
  },
  {
    "text": "get as negative as you like. These things, they go down,\nbut they only go down to 0.",
    "start": "2083130",
    "end": "2091575"
  },
  {
    "text": " Euphoria kicks in at around\nminus 10, in my experience.",
    "start": "2091575",
    "end": "2097890"
  },
  {
    "text": "Minus 100 feels great, but\nI'm just joking, of course. ",
    "start": "2097890",
    "end": "2104390"
  },
  {
    "text": "Yeah. The first example is feasible,\nit just has no optimum? Yeah, the first example.",
    "start": "2104390",
    "end": "2109859"
  },
  {
    "text": "All of these problems\nare feasible,",
    "start": "2109860",
    "end": "2115977"
  },
  {
    "text": "and we could write\ndown an infeasible. Why is the second one\nconsidered feasible? Even if the time had gone up.",
    "start": "2115977",
    "end": "2121545"
  },
  {
    "text": "Oh, this one. Oh, well, those two pathologies\nare at the opposite.",
    "start": "2121545",
    "end": "2130590"
  },
  {
    "text": "Infeasible means\nthere's no exit even satisfies your constraints,\nso let's not even talk about the objective.",
    "start": "2130590",
    "end": "2137970"
  },
  {
    "text": "That's infeasible. Unbounded below is, oh,\nthere's a lot of x's that",
    "start": "2137970",
    "end": "2143009"
  },
  {
    "text": "satisfy your constraints. Not only that, among them, f0\ncan be as negative as you like.",
    "start": "2143010",
    "end": "2148740"
  },
  {
    "text": "So, actually, they\nare both pathologies, but to me, they're\nat the opposite ends.",
    "start": "2148740",
    "end": "2155542"
  },
  {
    "text": "They're the different things. Yes. Is there a term for the\nfirst x that reaches 0?",
    "start": "2155542",
    "end": "2160765"
  },
  {
    "text": " By reaches 0-- [INAUDIBLE]",
    "start": "2160765",
    "end": "2166869"
  },
  {
    "text": "What's that? I guess they never\ndo actually reach 0. You mean up here? Yeah. For example.",
    "start": "2166870",
    "end": "2172070"
  },
  {
    "text": "Yes. [INAUDIBLE] Yeah, let's do another example.",
    "start": "2172070",
    "end": "2179660"
  },
  {
    "text": "Let me add a\nconstraint to this one. I'll add the constraint that\nx is less than or equal to 3.",
    "start": "2179660",
    "end": "2189550"
  },
  {
    "text": "Sorry, I will write this way. There we go. I think that was your\nquestion about weather--",
    "start": "2189550",
    "end": "2195279"
  },
  {
    "text": "yeah, so I'll write x\nminus 3 less than 0. So I'm going to add that.",
    "start": "2195280",
    "end": "2200770"
  },
  {
    "text": "I want you to minimize-- here, watch, I'm\ngoing to be good. I'm going to write minimize out.",
    "start": "2200770",
    "end": "2207790"
  },
  {
    "text": "Minimize 1 over x. Then this is subject to this.",
    "start": "2207790",
    "end": "2214089"
  },
  {
    "text": "Oh, by the way,\nfor us this thing has a domain, which is equal\nto R all positive numbers.",
    "start": "2214090",
    "end": "2222475"
  },
  {
    "text": " Let's talk about that problem.",
    "start": "2222475",
    "end": "2228940"
  },
  {
    "text": "Is it feasible? It is. There are points which are\nin the domain of f0 which",
    "start": "2228940",
    "end": "2236640"
  },
  {
    "text": "are less than or equal to 3. Here's a good example. Ready? 1, x equals 1.",
    "start": "2236640",
    "end": "2242340"
  },
  {
    "text": "So it's feasible. What's its optimal value?",
    "start": "2242340",
    "end": "2248960"
  },
  {
    "text": "1/3 It's 1/3. Does it have an optimal point\nor multiple optimal points?",
    "start": "2248960",
    "end": "2256010"
  },
  {
    "text": "Name me an optimal point. x equals 3. x equals 3. Are there any others?",
    "start": "2256010",
    "end": "2261570"
  },
  {
    "text": "No. No, right, exactly. So in this case, this\nset x opt is a Singleton.",
    "start": "2261570",
    "end": "2268190"
  },
  {
    "text": "And you would say it has\na unique solution, which is x equals 3.",
    "start": "2268190",
    "end": "2273380"
  },
  {
    "text": "That's a well-posed problem. I mean, it's a silly one, but\nit's a well-posed problem. ",
    "start": "2273380",
    "end": "2282400"
  },
  {
    "text": "So there's a concept of implicit\nversus explicit constraints.",
    "start": "2282400",
    "end": "2287980"
  },
  {
    "text": "And these are\nactually going to be rather important in practice. So here's what they are.",
    "start": "2287980",
    "end": "2294789"
  },
  {
    "text": "So when I have a\nstandard form problem, I've got my objective\nfunction f0.",
    "start": "2294790",
    "end": "2300310"
  },
  {
    "text": "I've got my inequality\nconstraints fi. And I have my equality\nconstraint functions hi.",
    "start": "2300310",
    "end": "2308200"
  },
  {
    "text": "So the first thing\nis we can't even talk about an x if it's\nnot in the domain of all",
    "start": "2308200",
    "end": "2313869"
  },
  {
    "text": "those functions. It just doesn't even make sense. This is, by the way, worse\nthan being infeasible.",
    "start": "2313870",
    "end": "2322260"
  },
  {
    "text": "Infeasible is like,\nhey, try this. And you go, sorry, that doesn't\nsatisfy the third inequality.",
    "start": "2322260",
    "end": "2330180"
  },
  {
    "text": "That's infeasible. But this is, thanks\nfor proposing an x.",
    "start": "2330180",
    "end": "2337109"
  },
  {
    "text": "I can't even evaluate\nthe objective on it. Or I can't even evaluate\nthe third constraint.",
    "start": "2337110",
    "end": "2343529"
  },
  {
    "text": " Yeah, a lot of people\ndon't distinguish",
    "start": "2343530",
    "end": "2349319"
  },
  {
    "text": "between being out of domain\nand being plus infinity. We'll get to that,\nbut it's fine.",
    "start": "2349320",
    "end": "2355020"
  },
  {
    "text": "So this is referred to as\nan implicit constraint. ",
    "start": "2355020",
    "end": "2363480"
  },
  {
    "text": "Here's an example here. There's an implicit\nconstraint that x is positive.",
    "start": "2363480",
    "end": "2369000"
  },
  {
    "text": "The reason is, this has a\ndomain, which is R plus plus. ",
    "start": "2369000",
    "end": "2374390"
  },
  {
    "text": "Simply writing it down. You write down log of z, and\nthere's an implicit constraint",
    "start": "2374390",
    "end": "2380840"
  },
  {
    "text": "that z is positive, period. I mean, in this class.",
    "start": "2380840",
    "end": "2386220"
  },
  {
    "text": "If you're taking a class\non complex analysis, z could be negative. But the social\ncontract in this class,",
    "start": "2386220",
    "end": "2393620"
  },
  {
    "text": "where we focus on\nconvexity, is log has a domain of R plus plus.",
    "start": "2393620",
    "end": "2399200"
  },
  {
    "text": "Same for 1 over x, by the way. So these are implicit.",
    "start": "2399200",
    "end": "2405710"
  },
  {
    "text": "And this is called the\ndomain of the problem. And so, if you propose an\nx, it's outside the domain,",
    "start": "2405710",
    "end": "2411530"
  },
  {
    "text": "it just doesn't even make sense. I mean, not only should\nwhoever is evaluating the x",
    "start": "2411530",
    "end": "2418280"
  },
  {
    "text": "give you a-- they should give you a really\nnasty message back, which is like your choice\nwas so bad, I",
    "start": "2418280",
    "end": "2425210"
  },
  {
    "text": "couldn't even evaluate the\nobjective or constraints to see. So",
    "start": "2425210",
    "end": "2430530"
  },
  {
    "text": "And, basically, you should be\nput on warning at that point. And if you do it two\nmore times, you're out. You're barred from it. It would be as if the\nproblem if the variable was",
    "start": "2430530",
    "end": "2437911"
  },
  {
    "text": "like a positive definite matrix\nthat represents, let's say, a covariance matrix. And you go, well,\nhow about this?",
    "start": "2437912",
    "end": "2444480"
  },
  {
    "text": "And I give you a\nnon-symmetric matrix with negative and\ncomplex eigenvalues, then you're like, hello?",
    "start": "2444480",
    "end": "2451319"
  },
  {
    "text": "Like, what? I can't evaluate the\nlog likelihood of that because it's not a\ncovariance matrix.",
    "start": "2451320",
    "end": "2457290"
  },
  {
    "text": "It doesn't make any sense. Anyway, that's what this is. Now we'll say a problem is\nunconstrained if you just have",
    "start": "2457290",
    "end": "2464950"
  },
  {
    "text": "no inequalities or whatever. So here's an example. This is an\nunconstrained problem.",
    "start": "2464950",
    "end": "2472970"
  },
  {
    "text": "The reason is there\nis a constraint, which is ai transpose\nx is less than b, but that's built into the log.",
    "start": "2472970",
    "end": "2478730"
  },
  {
    "text": "Because in this course, you\ntake the log of something, it's positive, period. We don't even\ndefine it otherwise.",
    "start": "2478730",
    "end": "2485329"
  },
  {
    "text": "So that's what that is. That's an example. ",
    "start": "2485330",
    "end": "2490650"
  },
  {
    "text": "Here's another one\nwe'll talk about later. It's called a\nfeasibility problem. Sometimes, people\nwrite it this way.",
    "start": "2490650",
    "end": "2496680"
  },
  {
    "text": "It says, find an\nx that satisfies a bunch of constraints. Oh, by the way, some people call\nconstraints, hard constraints",
    "start": "2496680",
    "end": "2504420"
  },
  {
    "text": "because, basically,\nthey are utterly and completely non-negotiable.",
    "start": "2504420",
    "end": "2510060"
  },
  {
    "text": " If you satisfy\nthem, we don't care",
    "start": "2510060",
    "end": "2515670"
  },
  {
    "text": "if you satisfy them just\nbarely or by a big margin, we don't care. So those are called\nhard constraints.",
    "start": "2515670",
    "end": "2521858"
  },
  {
    "text": "And so, this is just\na feasibility problem. And it says, yeah,\nplease, can you find an x that satisfies this?",
    "start": "2521858",
    "end": "2528150"
  },
  {
    "text": " And I think some people\nhave a whole quasitheory",
    "start": "2528150",
    "end": "2535109"
  },
  {
    "text": "of optimization problems. And they refer to\nthis as, I think, one name is a\nsatisficing problem.",
    "start": "2535110",
    "end": "2540780"
  },
  {
    "text": "I mean, frankly, I find\nit profoundly stupid. And if you understand\nany of this stuff,",
    "start": "2540780",
    "end": "2545880"
  },
  {
    "text": "it's completely standard and\nstraightforward how to solve. Anyway, fine. So that's a feasibility problem.",
    "start": "2545880",
    "end": "2552460"
  },
  {
    "text": "Then you can write\nit as a special case",
    "start": "2552460",
    "end": "2558940"
  },
  {
    "text": "of our general problem. What you do is you introduce\nan objective function, which is just 0, no matter\nwhat, and has domain everything.",
    "start": "2558940",
    "end": "2566180"
  },
  {
    "text": "This is really dumb,\nbut it does the trick. So if I say minimize 0.",
    "start": "2566180",
    "end": "2571360"
  },
  {
    "text": "What I'm really saying\nis, I have 0 affect. At least on the\nobjective, I don't care.",
    "start": "2571360",
    "end": "2577660"
  },
  {
    "text": "Any x you propose, as far as\nthe objective is concerned, they're all the same.",
    "start": "2577660",
    "end": "2583790"
  },
  {
    "text": "And so, here you\nhave the constraints. And so, for this\nproblem, p star is 0",
    "start": "2583790",
    "end": "2589660"
  },
  {
    "text": "if there is a feasible point. If there's a point\nthat satisfies it, and then that actually\nmeans it's optimal, too.",
    "start": "2589660",
    "end": "2597850"
  },
  {
    "text": "And p star is just infinity if\nthe constraints are infeasible. So so-called\nfeasibility problems",
    "start": "2597850",
    "end": "2604870"
  },
  {
    "text": "are the same as our\nmaster problems. They're just the same thing. I mean, they're kind of boring.",
    "start": "2604870",
    "end": "2610152"
  },
  {
    "text": "They only take the value\n0 or infinity Makes sense?",
    "start": "2610152",
    "end": "2615940"
  },
  {
    "text": "What-- And, by the way, this comes\nup in a whole lot of things. It will come up, for\nexample, in economics.",
    "start": "2615940",
    "end": "2624450"
  },
  {
    "text": " This would be the\nabsence of arbitrage.",
    "start": "2624450",
    "end": "2630190"
  },
  {
    "text": "And so, that'll work this way. x is something you\ncan do, like buy",
    "start": "2630190",
    "end": "2635470"
  },
  {
    "text": "a bunch of these instruments\nand some bonds over there and some derivatives\nand some other things. That some portfolio\nyou would construct.",
    "start": "2635470",
    "end": "2642430"
  },
  {
    "text": "And then what these state is\nthat no matter what happens,",
    "start": "2642430",
    "end": "2649000"
  },
  {
    "text": "you will actually\nnot lose money. And, at least one case,\nyou'll make money. That's a feasibility problem.",
    "start": "2649000",
    "end": "2655270"
  },
  {
    "text": "And then if it's\nfeasible, you would say there's arbitrage\nin that market.",
    "start": "2655270",
    "end": "2662752"
  },
  {
    "text": "We'll get to that\nlater, but I just thought I'd just mention that\nfeasibility problems that are literally\nfeasibility problems,",
    "start": "2662752",
    "end": "2669940"
  },
  {
    "text": "they're going to come\nup in real applications. That-- Just to clarify, they're both\nthe exact same thing, right?",
    "start": "2669940",
    "end": "2675258"
  },
  {
    "text": "I'm sorry, I missed that. What was that? Just to clarify, they're both\nsaying the exact same thing, right? They are saying\nexactly the same thing.",
    "start": "2675258",
    "end": "2680655"
  },
  {
    "text": "Some people write it this way. I mean, if you were\ntalking to a normal person,",
    "start": "2680655",
    "end": "2685858"
  },
  {
    "text": "you might say that. I mean, this just maps it\ninto our standard form.",
    "start": "2685858",
    "end": "2691630"
  },
  {
    "text": "Is there another question\nsomewhere over there? OK. All right, so that's\na feasibility problem.",
    "start": "2691630",
    "end": "2697059"
  },
  {
    "text": "And, finally, now we get to a\nconvex optimization problem. And here it is.",
    "start": "2697060",
    "end": "2704734"
  },
  {
    "text": "It is this. It's a standard form\nproblem where we restrict",
    "start": "2704735",
    "end": "2711130"
  },
  {
    "text": "the curvature of the functions. That's all it is. And it's this. The objective that we\nminimize has to be convex.",
    "start": "2711130",
    "end": "2720160"
  },
  {
    "text": "The constraints which we are, in\nthis case, upper bounding by 0",
    "start": "2720160",
    "end": "2725900"
  },
  {
    "text": "have to be convex functions. And the equality\nconstraints have",
    "start": "2725900",
    "end": "2731540"
  },
  {
    "text": "to be affine or what people\ncall them linear equality constraints. So these are the rules.",
    "start": "2731540",
    "end": "2737280"
  },
  {
    "text": "So roughly speaking,\nit says objective has non-negative curvature. Constraints all have\nnon-negative curvature.",
    "start": "2737280",
    "end": "2745070"
  },
  {
    "text": "And equality constraints\nall have zero curvature, which is affine.",
    "start": "2745070",
    "end": "2751250"
  },
  {
    "text": "Makes sense? Yeah. Why do the quality\nconstraints need to be affine and not convex?",
    "start": "2751250",
    "end": "2758300"
  },
  {
    "text": "Why? That's a loaded\nquestion because this is the definition of a\nconvex optimization problem.",
    "start": "2758300",
    "end": "2766080"
  },
  {
    "text": "So morally speaking, I think\nI can answer it this way. I'm allowed to say because\nthat's the definition.",
    "start": "2766080",
    "end": "2773120"
  },
  {
    "text": "But, I mean, that's\nkind of obnoxious. But we'll get to some\ninteresting examples",
    "start": "2773120",
    "end": "2783530"
  },
  {
    "text": "when you have an equality\nconstraint that's not. Let's see. Well, by definition, you\ndon't have a convex problem.",
    "start": "2783530",
    "end": "2790110"
  },
  {
    "text": "And in fact, a bunch of our\nmethods won't work on this. Now, sometimes, we actually\ncan solve problems like that.",
    "start": "2790110",
    "end": "2795840"
  },
  {
    "text": "So, sorry, that was a\nlong and weird answer. OK, let me just-- I'm going to revise my answer. It's this.",
    "start": "2795840",
    "end": "2801280"
  },
  {
    "text": "It's because this\nis the definition. How about that? But I won't say it\nin the obnoxious way. ",
    "start": "2801280",
    "end": "2810570"
  },
  {
    "text": "And these equality\nconstraints, we will often collect\nthem and write them as just in a single\nmatrix form Ax equals b.",
    "start": "2810570",
    "end": "2817896"
  },
  {
    "text": " Let's look at an example.",
    "start": "2817896",
    "end": "2825000"
  },
  {
    "text": "It looks like this. Oh, and by the way,\nlet me point something out here very important.",
    "start": "2825000",
    "end": "2831359"
  },
  {
    "text": "Here, a convex\noptimization problem, we refer to its representation\nthrough its objective function,",
    "start": "2831360",
    "end": "2838770"
  },
  {
    "text": "its inequality functions,\nand its equality constraint functions.",
    "start": "2838770",
    "end": "2844170"
  },
  {
    "text": "We'll talk shortly about the\nidea of an equivalent problem,",
    "start": "2844170",
    "end": "2850290"
  },
  {
    "text": "but now it's actually,\nliterally, it is-- when you have a problem,\nit has attributes",
    "start": "2850290",
    "end": "2856110"
  },
  {
    "text": "which are the objective\nand things like that. To be the attribute\nof being convex",
    "start": "2856110",
    "end": "2862619"
  },
  {
    "text": "depends on how you\ndescribe the problem. We'll get to that in a minute. In fact, this is\nan example of that. So here's a problem,\nit's got two variables.",
    "start": "2862620",
    "end": "2870060"
  },
  {
    "text": "I would like to minimize\nx1 squared plus x2 squared. Well, that's just the\nsum of the squares and that's like a nice\nbowl that goes up.",
    "start": "2870060",
    "end": "2876810"
  },
  {
    "text": "You what know what\nit looks like. You have some constraints. You have f1 of x is x1 over 1\nplus x2 squared is less than",
    "start": "2876810",
    "end": "2884950"
  },
  {
    "text": "or equal to zero. Well, you can ask\nyourself, is x1",
    "start": "2884950",
    "end": "2889980"
  },
  {
    "text": "over 1 plus x2 squared convex? And the answer\nwould be it's not.",
    "start": "2889980",
    "end": "2896339"
  },
  {
    "text": "This thing is not\na convex problem. And the last\nconstraint is that h--",
    "start": "2896340",
    "end": "2901682"
  },
  {
    "text": "so I think you asked\na question about why does it have to be\naffine, and I said, well, it's the definition. Here's an example where h\nof x is for sure not affine.",
    "start": "2901682",
    "end": "2910200"
  },
  {
    "text": "It says that x1 plus x2\nsquared has to be zero. So this problem fails.",
    "start": "2910200",
    "end": "2916180"
  },
  {
    "text": " And we can even walk\nthrough the code.",
    "start": "2916180",
    "end": "2921700"
  },
  {
    "text": "If I took this problem\nand I called it my prob, and I called the my prob\nthat is convex method on it,",
    "start": "2921700",
    "end": "2930210"
  },
  {
    "text": "then, here, we will walk\nthrough what the code does. What it does like\nthis is it says,",
    "start": "2930210",
    "end": "2935670"
  },
  {
    "text": "my problem dot objective,\nthat's going to be f zero,",
    "start": "2935670",
    "end": "2941299"
  },
  {
    "text": "I call the dot is\nconvex method on it. And in this case, that\nwould evaluate to what?",
    "start": "2941300",
    "end": "2947820"
  },
  {
    "text": "True. It's true. No problem. Now, the second\npart of implementing",
    "start": "2947820",
    "end": "2953460"
  },
  {
    "text": "the is convex\nmethod on a problem is to iterate over the\ninequality constraints.",
    "start": "2953460",
    "end": "2959730"
  },
  {
    "text": "And you'd say, for inequality,\nin inequalities, you would say, my prob dot inequality of i.",
    "start": "2959730",
    "end": "2967950"
  },
  {
    "text": "I'm just saying rough\npseudocode here. Dot is convex. Well, there's only\none in that list",
    "start": "2967950",
    "end": "2973980"
  },
  {
    "text": "and it would return\nthis function. And that would evaluate to what? False. At that point, it's game over.",
    "start": "2973980",
    "end": "2981180"
  },
  {
    "text": "But if you want it to be\nreally sure it was over, you would actually go to the\nequality constraints and it",
    "start": "2981180",
    "end": "2986250"
  },
  {
    "text": "would have my-- it would actually do-- it'd\nbe for equality constraints. And for equality constraint,\ninequality constraints",
    "start": "2986250",
    "end": "2994650"
  },
  {
    "text": "equality, my prob dot equality\nconstraint function of 0 zero,",
    "start": "2994650",
    "end": "3000319"
  },
  {
    "text": "I'm using zero\nindexing, dot is affine and it would evaluate to false. Everybody got this?",
    "start": "3000320",
    "end": "3006680"
  },
  {
    "text": "Now, it's silly because you look\nat this and you're like, well, this is dumb. I mean, this thing\nis the same as x1",
    "start": "3006680",
    "end": "3012510"
  },
  {
    "text": "just being less than\nor equal to zero. And the square of x1 plus x2\nis zero, that only happens--",
    "start": "3012510",
    "end": "3018460"
  },
  {
    "text": "so basically, you can\nrewrite the problem this way. Now, what we do is we would call\nthis problem and this problem",
    "start": "3018460",
    "end": "3024089"
  },
  {
    "text": "equivalent problems. What that means is,\nif you can solve one,",
    "start": "3024090",
    "end": "3029099"
  },
  {
    "text": "there's an easy way\nto solve the other. We'll talk more about that. But if you've taken a\ncourse in computer science,",
    "start": "3029100",
    "end": "3034590"
  },
  {
    "text": "almost any, this is the\nstandard idea of a reduction. We're not going to make it fancy\nand have polynomial reduction",
    "start": "3034590",
    "end": "3041635"
  },
  {
    "text": "and all that kind of stuff. But the point is, for us,\nit's going to be informal. It just means two\nproblems are equivalent.",
    "start": "3041635",
    "end": "3047250"
  },
  {
    "text": "When I solve one, I know\nhow to solve the other. And if I can solve\nthe other, I know how to solve the original one.",
    "start": "3047250",
    "end": "3053310"
  },
  {
    "text": "So these are equivalent;\nthey are not the same. Let's walk through\nthe implementation.",
    "start": "3053310",
    "end": "3059289"
  },
  {
    "text": "This is my prob, and this\nis my alternative prob. So let's walk through the\nequals equals method between two",
    "start": "3059290",
    "end": "3066630"
  },
  {
    "text": "problems, and the way\nthat works is this. Here's an implementation. This is what it\nmeans to be equal.",
    "start": "3066630",
    "end": "3072540"
  },
  {
    "text": "It says, are your\nobjectives equal? And that would evaluate\nto what in this case?",
    "start": "3072540",
    "end": "3079630"
  },
  {
    "text": "True. Then, it goes like this. It's really dumb it says, loop\nover the constraints and just",
    "start": "3079630",
    "end": "3087279"
  },
  {
    "text": "check if each constraint\nfunction in the two problems are the same.",
    "start": "3087280",
    "end": "3092440"
  },
  {
    "text": "That would evaluate\nhere to false. So these are not\nthe same problem,",
    "start": "3092440",
    "end": "3098990"
  },
  {
    "text": "but they are equivalent. I mean, this is not a big deal\nand it should be kept informal,",
    "start": "3098990",
    "end": "3104360"
  },
  {
    "text": "but it's also an important idea. So this problem is not\nconvex, this is convex.",
    "start": "3104360",
    "end": "3110150"
  },
  {
    "text": "And this tells you that\nyes, a non-convex problem can be equivalent\nto a convex problem,",
    "start": "3110150",
    "end": "3115670"
  },
  {
    "text": "and that's very\nconfusing, but too bad. ",
    "start": "3115670",
    "end": "3122668"
  },
  {
    "text": "Would that be the\nsame as just saying that the star that\nsolves this problem is the same as the star that\nwill solve that problem?",
    "start": "3122668",
    "end": "3129340"
  },
  {
    "text": "Would that be another way\nto check equivalence of it. Yes.",
    "start": "3129340",
    "end": "3134800"
  },
  {
    "text": "Not quite. Because when you say\nthey're equivalent, it actually doesn't\nreally-- it means that you",
    "start": "3134800",
    "end": "3140530"
  },
  {
    "text": "have a very simple method. It says that once\nyou solve that, I have a simple\nmethod to solve that.",
    "start": "3140530",
    "end": "3145779"
  },
  {
    "text": "And that simple method is,\nwell, it's very simple. I take a solution of this,\nwhich we could figure out real",
    "start": "3145780",
    "end": "3152619"
  },
  {
    "text": "quickly but I'm not going to. But we take a solution of that,\nactually, the solution of it",
    "start": "3152620",
    "end": "3157887"
  },
  {
    "text": "because it's going to be unique. We take the solution\nof that, this thing. And then, actually, you just\nsimply put it over there,",
    "start": "3157887",
    "end": "3163900"
  },
  {
    "text": "it's the same x1 and x2. We'll see other cases where\nyou might have to do this. When two problems\nare equivalent, you might actually have to do\na little bit to transform back.",
    "start": "3163900",
    "end": "3173140"
  },
  {
    "text": "But it's not the same as\njust p star being the same. ",
    "start": "3173140",
    "end": "3179990"
  },
  {
    "text": "Now, we'll talk about\nlocal and global optima, the plural of optimum.",
    "start": "3179990",
    "end": "3187760"
  },
  {
    "text": "So it turns out any locally\noptimal point of a convex problem is globally optimal.",
    "start": "3187760",
    "end": "3194510"
  },
  {
    "text": "I mean, it's not hard to show. I'll draw a picture\nin just a minute to show you what this means.",
    "start": "3194510",
    "end": "3201180"
  },
  {
    "text": "But it is worthwhile to\nsit back and to realize how impressive this is.",
    "start": "3201180",
    "end": "3208470"
  },
  {
    "text": "And I remember being told\npoint blank by someone super smart circuit designer.",
    "start": "3208470",
    "end": "3214710"
  },
  {
    "text": "I said, that's the globally\noptimal circuit design. And he looked at me and he said,\nhow can you possibly say that?",
    "start": "3214710",
    "end": "3222420"
  },
  {
    "text": "He said, this is a circuit\nwith 45 lengths and widths.",
    "start": "3222420",
    "end": "3227609"
  },
  {
    "text": "What hubris? How could you say that? How do you know\nsomeone can't come up with another set of lengths\nand widths that-- anyway.",
    "start": "3227610",
    "end": "3236310"
  },
  {
    "text": "I looked at him and\nsaid, well, it's just because of the mathematical\nfeatures of this problem.",
    "start": "3236310",
    "end": "3242770"
  },
  {
    "text": "That's how I can make this. I mean, but it's probably\nworthwhile for all of us to realize how absurd a\nstatement that sounds like.",
    "start": "3242770",
    "end": "3250559"
  },
  {
    "text": "If you solve a problem with, I\ndon't know, 10,000 variables, and you'd say, I just worked\nout the minimum fuel trajectory",
    "start": "3250560",
    "end": "3259530"
  },
  {
    "text": "to put your satellite\nback on orbit where it's supposed to be. Perfectly reasonable person\nwould say, how could you",
    "start": "3259530",
    "end": "3266250"
  },
  {
    "text": "say something like that? There are so many sequences\nof thruster burns and things like that that\nwould get you back.",
    "start": "3266250",
    "end": "3271890"
  },
  {
    "text": "How do you know? How could you possibly know\nthat this has minimum fuel? Do you see what I'm saying?",
    "start": "3271890",
    "end": "3276900"
  },
  {
    "text": "By the way, we will--\nafter this little speech I quit, and we will\nget you-- and that's all we're going to\nsay from now on.",
    "start": "3276900",
    "end": "3283350"
  },
  {
    "text": "We'll just say, hey, this is\nthat, that's the optimal thing, and you get used to it. But it is probably worthwhile\nto think about how strong",
    "start": "3283350",
    "end": "3290250"
  },
  {
    "text": "a statement it is, and it\nall comes back to this. ",
    "start": "3290250",
    "end": "3298260"
  },
  {
    "text": "And let's see why. I'm just going to\ndraw a picture. In fact, we're not\ngoing to follow that. I'm just going to\ndraw a picture.",
    "start": "3298260",
    "end": "3303575"
  },
  {
    "text": " Let's suppose that\nyou have a point here,",
    "start": "3303575",
    "end": "3309300"
  },
  {
    "text": "it's locally optimal. So I'm going to\ncall that x local. But let's suppose it's\nnot globally optimal.",
    "start": "3309300",
    "end": "3318270"
  },
  {
    "text": "So that means, I'm going to\nfind another point that's feasible and has a\nlower objective value.",
    "start": "3318270",
    "end": "3323580"
  },
  {
    "text": "And I'm just going to call\nthat over here x tilde. It could be x star,\nan optimal point.",
    "start": "3323580",
    "end": "3331440"
  },
  {
    "text": "This is feasible,\nlocally optimal, and this has an objective\nvalue less than that.",
    "start": "3331440",
    "end": "3338290"
  },
  {
    "text": "Everybody got it? Now I do this. I draw the line\nsegment between them.",
    "start": "3338290",
    "end": "3343930"
  },
  {
    "text": "Oh, on that line segment, are\nall those points feasible?",
    "start": "3343930",
    "end": "3348950"
  },
  {
    "text": "Why? It's a combination of the two. Because x local is\nfeasible, so is x tilde.",
    "start": "3348950",
    "end": "3358100"
  },
  {
    "text": "The set of feasible\npoints is a convex set that's a line segment. So any point on\nhere is feasible.",
    "start": "3358100",
    "end": "3364760"
  },
  {
    "text": "Now, I want to draw, as I move,\nlet me call my parameter t, so this is t equals\nzero, t equals 1.",
    "start": "3364760",
    "end": "3372410"
  },
  {
    "text": "And I want to draw\nthe objective value as I go from t equals\nzero to t equals 1.",
    "start": "3372410",
    "end": "3381410"
  },
  {
    "text": "And I know two points already. I'm going to draw f\nzero of that point. This one, it starts at\nf of x local here it",
    "start": "3381410",
    "end": "3391040"
  },
  {
    "text": "ends at f zero of x\ntilde by assumption that's better than f zero.",
    "start": "3391040",
    "end": "3396259"
  },
  {
    "text": "So I don't know where it is,\nbut I'm going to draw it here. That's an f tilde of\nx-- oh, what am I doing?",
    "start": "3396260",
    "end": "3403400"
  },
  {
    "text": "F zero of x tilde. Everybody got this? Now, on this line\nsegment, I'm going",
    "start": "3403400",
    "end": "3410220"
  },
  {
    "text": "to-- what I now have to do--\nwe know that when I draw that, it's a convex function, because\nit's a convex function of t.",
    "start": "3410220",
    "end": "3416780"
  },
  {
    "text": "This is restricting a convex\nfunction to, in this case, an interval, but a\nline and it's convex.",
    "start": "3416780",
    "end": "3423740"
  },
  {
    "text": "I have to draw a convex function\nthat starts here and ends here. Everybody got that?",
    "start": "3423740",
    "end": "3430760"
  },
  {
    "text": "Now when I do that, there's\nlots of ways to do it. But no matter what\nI do, it's going",
    "start": "3430760",
    "end": "3437390"
  },
  {
    "text": "to go-- it has to go\ndown a little bit here. ",
    "start": "3437390",
    "end": "3442750"
  },
  {
    "text": "Now, we got a problem. What is the problem? Remember, somebody alleged\nthat x was locally optimal.",
    "start": "3442750",
    "end": "3451010"
  },
  {
    "text": "This means whoever\nsaid that was a liar. Let me tell you why. It says that there are points\non this line segment with really",
    "start": "3451010",
    "end": "3458600"
  },
  {
    "text": "small t, which is it's\nvery close to x local,",
    "start": "3458600",
    "end": "3463700"
  },
  {
    "text": "and the objective value\nis less than x local. So x local was definitely\nnot a locally optimal point.",
    "start": "3463700",
    "end": "3471350"
  },
  {
    "text": "Everybody got that? Honestly, I could write\nit out as a proof. It's actually shorter\nif I do, but the picture",
    "start": "3471350",
    "end": "3478099"
  },
  {
    "text": "tells you everything. Does that make sense? So that's the idea there.",
    "start": "3478100",
    "end": "3484280"
  },
  {
    "text": " Now, here, we can give an\nextremely simple optimality",
    "start": "3484280",
    "end": "3492010"
  },
  {
    "text": "condition if f zero\nis differentiable. It looks like this. It says that a point x is\noptimal if it's feasible.",
    "start": "3492010",
    "end": "3503140"
  },
  {
    "text": "And the following is\ntrue, is that if x is the set of feasible points,\nit says that the gradient of f",
    "start": "3503140",
    "end": "3512080"
  },
  {
    "text": "transpose y minus\nx, that's going to be bigger than or equal\nto zero for all feasible y. And let's draw the picture. So these dashed curves are\nthe level curves of f zero.",
    "start": "3512080",
    "end": "3522490"
  },
  {
    "text": "If you slide this way,\nyou're going downhill and you're getting\nbetter values of f zero, which, by the semantics of\nthat being the objective,",
    "start": "3522490",
    "end": "3530342"
  },
  {
    "text": "means you're getting happier. So you're getting happier\nas you go down this way. ",
    "start": "3530342",
    "end": "3538360"
  },
  {
    "text": "But these are the\nacceptable points. To solve the problem\nvisually, it just means you find the lowest level\ncurve that is on this thing,",
    "start": "3538360",
    "end": "3548299"
  },
  {
    "text": "and that's going to\nbe this point here. What happens there is\nactually interesting.",
    "start": "3548300",
    "end": "3554240"
  },
  {
    "text": "It just touches it. And the gradient, which would\nbe the outward normal, so",
    "start": "3554240",
    "end": "3561710"
  },
  {
    "text": "the negative gradient like\nthis, points downhill. And that is actually orthogonal\nto this tangent line here.",
    "start": "3561710",
    "end": "3570350"
  },
  {
    "text": "So another way to say\nit is that the gradient defines a supporting\nhyperplane to the feasible set.",
    "start": "3570350",
    "end": "3575485"
  },
  {
    "text": "That would use the\nlanguage we had before. ",
    "start": "3575485",
    "end": "3580610"
  },
  {
    "text": "I mean, I think\nit's pretty basic. Weirdly, it looks complicated. Both proving both directions is\neach like one line for each one",
    "start": "3580610",
    "end": "3588410"
  },
  {
    "text": "because it's just silly. Some things look and sound\ncomplicated and fancy,",
    "start": "3588410",
    "end": "3593720"
  },
  {
    "text": "and they're not,\nthis is one of them.  I think the picture\nis pretty clear.",
    "start": "3593720",
    "end": "3600050"
  },
  {
    "text": "So this is the picture. ",
    "start": "3600050",
    "end": "3607619"
  },
  {
    "text": "Now, we can instantiate that\nin various versions of it.",
    "start": "3607620",
    "end": "3612840"
  },
  {
    "text": "Here's one version. Suppose there's\nno constraint set. If there's no constraint\nset, then what we're saying",
    "start": "3612840",
    "end": "3618599"
  },
  {
    "text": "is x is all of our n. And this inequality has\nto hold for all our n.",
    "start": "3618600",
    "end": "3624060"
  },
  {
    "text": "Any comment about that? If I tell you this inequality\nholds for any vector y,",
    "start": "3624060",
    "end": "3631770"
  },
  {
    "text": "the only possible\nway that can happen is this gradient has to vanish. Because if this\ngradient didn't vanish,",
    "start": "3631770",
    "end": "3640050"
  },
  {
    "text": "then I would pick y to be\nminus that gradient multiplied by your favorite\nextremely large number.",
    "start": "3640050",
    "end": "3647190"
  },
  {
    "text": "And then this thing here\nwould definitely not be bigger than or equal to zero. Everybody following that?",
    "start": "3647190",
    "end": "3653220"
  },
  {
    "text": "So that would be the idea there. Basically, this\nrecovers, I guess,",
    "start": "3653220",
    "end": "3659280"
  },
  {
    "text": "what you know from your\nCalculus 2 or whatever course.",
    "start": "3659280",
    "end": "3664620"
  },
  {
    "text": "It says that in an\nunconstrained problem, if f zero is differentiable,\nthe gradient vanishing is what",
    "start": "3664620",
    "end": "3671849"
  },
  {
    "text": "it means to solve the problem. By the way, this is a bit\ndifferent from your Calculus 2 course. Let me tell you why.",
    "start": "3671850",
    "end": "3678045"
  },
  {
    "text": "In your Calculus 2 course, when\nyou said the gradient vanished, all it meant was that\nit's at a stationary point",
    "start": "3678045",
    "end": "3683099"
  },
  {
    "text": "of the function. It could have been a saddle\npoint, it could be a maximum, it could be a local\nminimum, local maximum,",
    "start": "3683100",
    "end": "3688480"
  },
  {
    "text": "all this kind of stuff. Here, because we also\nknow f zero is convex,",
    "start": "3688480",
    "end": "3693580"
  },
  {
    "text": "it's actually globally optimal. And we don't even have to\nsay that globally, it's",
    "start": "3693580",
    "end": "3699250"
  },
  {
    "text": "just optimal. So that's it. So what that says is\nwhen in Calculus 2",
    "start": "3699250",
    "end": "3708440"
  },
  {
    "text": "you were taught how to do\nbaby optimization stuff which was a behavioral thing. And it basically said you\ntake the function, set",
    "start": "3708440",
    "end": "3715550"
  },
  {
    "text": "the gradient equal to\nzero, and then something happens after that. That's my general\nmemory of this.",
    "start": "3715550",
    "end": "3723910"
  },
  {
    "text": "It turns out for\nconvex functions, that's exactly correct. Oh, and not only that,\nyou're going to get--",
    "start": "3723910",
    "end": "3730200"
  },
  {
    "text": "you will get a minimizer--\nan optimal point period.",
    "start": "3730200",
    "end": "3735300"
  },
  {
    "text": "None of this weird legal\nboilerplate or footnotes that says, oh, it might be a\nmaximum, it might be a minimum,",
    "start": "3735300",
    "end": "3743342"
  },
  {
    "text": "oh it might be a saddle point,\nit might be a local minimum, it might be a local. None of that boilerplate. It's just optimal, period.",
    "start": "3743342",
    "end": "3749165"
  },
  {
    "text": " We'll look at optimality\nconditions later in the class,",
    "start": "3749165",
    "end": "3756240"
  },
  {
    "text": "but some of them are just\nvery easy to work out directly from this general principle. So if you have an equality\nconstraint problem,",
    "start": "3756240",
    "end": "3763280"
  },
  {
    "text": "what happens is you\nwant to minimize f zero of x subject\nto Ax equals b. You're optimal, you\nhave to be feasible,",
    "start": "3763280",
    "end": "3769932"
  },
  {
    "text": "you have to be in the\ndomain, of course. And then you can\nwork out what it means for that\ngradient inequality",
    "start": "3769933",
    "end": "3775100"
  },
  {
    "text": "to hold for an affine set. And when you do, it's going\nto end up looking like this. That's also from your\nCalculus 2 class because these",
    "start": "3775100",
    "end": "3781880"
  },
  {
    "text": "are Lagrange multipliers. We are going to cover that in\nabout a week and a half, two",
    "start": "3781880",
    "end": "3787580"
  },
  {
    "text": "weeks, in a theory\ncalled duality. After which, I believe you\nwill actually understand it.",
    "start": "3787580",
    "end": "3796280"
  },
  {
    "text": "Because I don't mind admitting\nI saw things about Lagrange multipliers two or three times\nand had no idea what they meant",
    "start": "3796280",
    "end": "3804560"
  },
  {
    "text": "did. Why would you do this? Why would you do that? Anyway, you don't know what\nI'm talking about probably.",
    "start": "3804560",
    "end": "3812210"
  },
  {
    "text": "I mean, unless\nyou're in-- there are fields where this does come up. Probably, if you're\nin economics,",
    "start": "3812210",
    "end": "3817320"
  },
  {
    "text": "maybe if you're in\nmechanical engineering, you actually do have a feel for\nit because it comes up there.",
    "start": "3817320",
    "end": "3822360"
  },
  {
    "text": "Maybe in statistics,\nI don't know. But the point is we'll\ncover this in detail later. ",
    "start": "3822360",
    "end": "3829799"
  },
  {
    "text": "You can work out other cases,\nlike minimize a convex function over the non-negative\northant, and you",
    "start": "3829800",
    "end": "3836280"
  },
  {
    "text": "can work out what it means. And actually, it's also\nmakes perfect sense.",
    "start": "3836280",
    "end": "3842430"
  },
  {
    "text": "It would mean that if\nI minimize a convex function over non-negative\northant, let me just draw this.",
    "start": "3842430",
    "end": "3850800"
  },
  {
    "text": "I want to minimize the\nconvex function over here, and here's an example here. Here are some sublevel sets.",
    "start": "3850800",
    "end": "3857880"
  },
  {
    "text": "Like this. Like that, here's some-- whoops, these are\nsublevel sets, like that.",
    "start": "3857880",
    "end": "3866550"
  },
  {
    "text": "That's the optimal point. And we can check this\nbecause what happens here--",
    "start": "3866550",
    "end": "3872250"
  },
  {
    "text": "and this is just very intuitive. What it says is that\nthis partial f zero",
    "start": "3872250",
    "end": "3881260"
  },
  {
    "text": "partial x2, that has to vanish. If it didn't vanish,\nwe'd be in trouble.",
    "start": "3881260",
    "end": "3887019"
  },
  {
    "text": "Because I could slide\nup and down here in the direction of\nthe negative gradient and actually get a slightly\nbetter objective value",
    "start": "3887020",
    "end": "3893463"
  },
  {
    "text": "while staying feasible, in\nwhich case, it was not optimal. But I'm slammed up against\nthe boundary of the constraint",
    "start": "3893463",
    "end": "3900130"
  },
  {
    "text": "here. I would love to go\nin that direction. I'd love to because my\nobjective would go down.",
    "start": "3900130",
    "end": "3906430"
  },
  {
    "text": "The problem is I'm at the\nboundary of the feasible set, and I can't. Anyway, when you work this out--",
    "start": "3906430",
    "end": "3912385"
  },
  {
    "text": "you just can just work\nthis out algebraically and you get something\nlike that condition there.",
    "start": "3912385",
    "end": "3918890"
  },
  {
    "text": "So anyway, we'll come back\nto optimality conditions in about two weeks. ",
    "start": "3918890",
    "end": "3924405"
  },
  {
    "text": "Now, we're going to talk\nabout equivalent problems. I already said a\nlittle bit about it earlier, we actually saw two\nequivalent problems, in fact,",
    "start": "3924405",
    "end": "3930850"
  },
  {
    "text": "earlier. Now, we're going to talk\nabout it because it's an official idea we have.",
    "start": "3930850",
    "end": "3936797"
  },
  {
    "text": "Two problems-- and\nwe're going to make it informal in this class. In CS theory, it's not informal.",
    "start": "3936797",
    "end": "3942730"
  },
  {
    "text": "Here it is, there it's called\na reduction by the way. So here, it's going\nto be informal.",
    "start": "3942730",
    "end": "3949510"
  },
  {
    "text": "And we say, basically,\nif one problem is equivalent to another,\nif from a solution of one",
    "start": "3949510",
    "end": "3955930"
  },
  {
    "text": "I can create a solution of\nthe other and vice versa. So that's what that means.",
    "start": "3955930",
    "end": "3962470"
  },
  {
    "text": "That's exactly the idea of a\nreduction in computer science. ",
    "start": "3962470",
    "end": "3969665"
  },
  {
    "text": "So there's a whole bunch of\nthem that you should probably know about. In fact, a lot of\nthe software tools",
    "start": "3969665",
    "end": "3974950"
  },
  {
    "text": "you're going to use\nactually are going to use on your behalf\nmany reductions. Sorry, OK, whatever.",
    "start": "3974950",
    "end": "3981110"
  },
  {
    "text": "Sorry. They'll use many\nequivalences, which are reductions in\ncomputer science that you don't\nneed to know about.",
    "start": "3981110",
    "end": "3988240"
  },
  {
    "text": "But you need to know\nabout some of them because they're actually-- and\nI'll just mention some of them, a lot of them are generic,\nbut let's look at some.",
    "start": "3988240",
    "end": "3995410"
  },
  {
    "text": "Here's one. Here's a problem with\nequality constraints. ",
    "start": "3995410",
    "end": "4001890"
  },
  {
    "text": "We can just basically eliminate\nthe equality constraints, I can take a new variable.",
    "start": "4001890",
    "end": "4007620"
  },
  {
    "text": "And the first thing\nI do is I find a vector x zero that\nsatisfies Ax equals b,",
    "start": "4007620",
    "end": "4014040"
  },
  {
    "text": "and I find a matrix whose range\nis exactly the null space of A.",
    "start": "4014040",
    "end": "4020700"
  },
  {
    "text": "What that tells you is\nthat Ax is equal to b, if, and only, if you have the\nform x equals fz plus x zero.",
    "start": "4020700",
    "end": "4028390"
  },
  {
    "text": "X zero and f, we can\ncompute from a and b.",
    "start": "4028390",
    "end": "4034309"
  },
  {
    "text": "We compute them. I won't go into how we do\nthat, lots of ways to do that. So you do that.",
    "start": "4034310",
    "end": "4039430"
  },
  {
    "text": "If you do this,\nthen this problem is equivalent to that problem.",
    "start": "4039430",
    "end": "4045880"
  },
  {
    "text": "By the way, they're\nnot equal at all. I mean, for one thing at a\nvery gross level, it's not.",
    "start": "4045880",
    "end": "4051250"
  },
  {
    "text": "If you say this\nproblem, that equality-- if you say what is the\nlength of this problem,",
    "start": "4051250",
    "end": "4059230"
  },
  {
    "text": "that equality constraints,\nit's going to be however many, let's say this p in p equality\nconstraints, it'll be p.",
    "start": "4059230",
    "end": "4065500"
  },
  {
    "text": "Here, when I say\nthis second problem, that equality constraints,\nif I say length of that,",
    "start": "4065500",
    "end": "4071830"
  },
  {
    "text": "it's a list, it's an empty\nlist, and so it's zero. End of story, these are not\nequal, but they are equivalent.",
    "start": "4071830",
    "end": "4078370"
  },
  {
    "text": " In this case, the p star\nof the two problems,",
    "start": "4078370",
    "end": "4084760"
  },
  {
    "text": "the optimal value is the same. To explain what you do,\nyou say like, well, you",
    "start": "4084760",
    "end": "4090550"
  },
  {
    "text": "want to solve this. So what we do is first we\ncompute this f and the x zero, then we solve this problem.",
    "start": "4090550",
    "end": "4096729"
  },
  {
    "text": "Now, z has nothing to do\nwith this problem at all. But then what I simply do\nis I return in this problem,",
    "start": "4096729",
    "end": "4104318"
  },
  {
    "text": "I return fz star plus x zero. And that's going to\nbe the solution here.",
    "start": "4104319",
    "end": "4109509"
  },
  {
    "text": "So this actually also has\na very important like, if someone comes up with a super\nfancy solver for a problem,",
    "start": "4109510",
    "end": "4116380"
  },
  {
    "text": "they go, it's awesome. It's super fast. Whatever it is,\nit doesn't matter.",
    "start": "4116380",
    "end": "4121720"
  },
  {
    "text": "Then you say only\nminor problem, it doesn't support\nequality constraints. Everybody got that?",
    "start": "4121720",
    "end": "4128229"
  },
  {
    "text": "This actually, now,\nit's like no problem, I just write a\nwrapper around it. And my wrapper takes\nproblems like this,",
    "start": "4128229",
    "end": "4134470"
  },
  {
    "text": "calculates f and x zero. We could write the whole\nwrapper beautifully. The first thing you do is you\nattempt to solve Ax equals b.",
    "start": "4134470",
    "end": "4141384"
  },
  {
    "text": "What if b is not\nin the range of a? What do I do?",
    "start": "4141385",
    "end": "4146729"
  },
  {
    "text": "I returned that your\nproblem is infeasible. Period. And then I'll have\nto do anything else.",
    "start": "4146729",
    "end": "4152255"
  },
  {
    "text": "If it's feasible, I'm\ngoing to find an x zero and I'm going to find this f. I'm going to solve\nthis problem using",
    "start": "4152255",
    "end": "4157620"
  },
  {
    "text": "this person's fancy solver. I will then quietly\nreturn fz plus x zero",
    "start": "4157620",
    "end": "4162899"
  },
  {
    "text": "and that will, in fact, be\na solution of this problem. Everybody got it? That's called eliminating\nequality constraints.",
    "start": "4162899",
    "end": "4170370"
  },
  {
    "text": "And actually, there's a whole\nlot of confusion about that.",
    "start": "4170370",
    "end": "4175439"
  },
  {
    "text": "I think some very naive\npeople think this is great. And you say, why?",
    "start": "4175439",
    "end": "4182219"
  },
  {
    "text": "And here would be the story. It's naive, it's totally\nwrong, but here's the story. I mean, it's plausible if you\ndon't know what you're doing.",
    "start": "4182220",
    "end": "4188278"
  },
  {
    "text": "Here it is. They say, well, I have\nthis problem here, x has dimension 100.",
    "start": "4188279",
    "end": "4193630"
  },
  {
    "text": "And I have 50\nequality constraints. Everybody got that? Now, down here, that's\nassuming that's like that's got",
    "start": "4193630",
    "end": "4199780"
  },
  {
    "text": "full rank and all that. So down here, z has ranked 50. Sorry, dimension 50, because if\nI have 100 dimensional space,",
    "start": "4199780",
    "end": "4209199"
  },
  {
    "text": "I have 50 equality constraints,\neverything's full rank, z is going to have dimension 50. And then someone\nsays, oh, that's",
    "start": "4209200",
    "end": "4214960"
  },
  {
    "text": "a better problem than\nthat one to solve. And you go, why? And they go, Hello?",
    "start": "4214960",
    "end": "4220372"
  },
  {
    "text": "Wouldn't you rather\nsolve a problem with 50 variables than 100? Everybody see what I'm saying? It sounds plausible, but it's\ncompletely and totally wrong,",
    "start": "4220372",
    "end": "4228670"
  },
  {
    "text": "which you will know later. In fact, it could be\nthe exact opposite",
    "start": "4228670",
    "end": "4234730"
  },
  {
    "text": "that you would much\nrather solve a problem with 100 variables than 50. I'm getting ahead of\nmyself, but we'll come back",
    "start": "4234730",
    "end": "4240160"
  },
  {
    "text": "to that later in the class.  You can do the opposite, yes.",
    "start": "4240160",
    "end": "4247770"
  },
  {
    "text": "How do you actually\ncompute x minus f zero? Oh, that's linear algebra. Yeah, that's a standard\nlinear algebra.",
    "start": "4247770",
    "end": "4254480"
  },
  {
    "text": "I don't know. I do a QR factorization\nof like f or-- I don't know,\nsomething like that. ",
    "start": "4254480",
    "end": "4263820"
  },
  {
    "text": "I mean, I'd be happy to\ntell you later or something, but that's just linear algebra. ",
    "start": "4263820",
    "end": "4273260"
  },
  {
    "text": "Next up is the opposite of\neliminating is introducing equality constraints.",
    "start": "4273260",
    "end": "4278929"
  },
  {
    "text": "Weirdly, this\nsounds really dumb. It's unbelievably useful,\nand we will see that later.",
    "start": "4278930",
    "end": "4288020"
  },
  {
    "text": "So how does that work? You start with a\nproblem like that and you introduce a new\nvariable and you and you",
    "start": "4288020",
    "end": "4293680"
  },
  {
    "text": "introduce equality constraints. What's hilarious about\nthis is if someone says,",
    "start": "4293680",
    "end": "4300519"
  },
  {
    "text": "oh, thanks for your\nproblem, I just made you an equivalent problem.",
    "start": "4300520",
    "end": "4305770"
  },
  {
    "text": "Oh, and by the way, you have to\ncheck that these equivalences play nice with convexity.",
    "start": "4305770",
    "end": "4311620"
  },
  {
    "text": "I didn't do that for the other\none, so let's go back and look. Here, if that's\na convex problem,",
    "start": "4311620",
    "end": "4318280"
  },
  {
    "text": "we have to check this is. How come this is? ",
    "start": "4318280",
    "end": "4323540"
  },
  {
    "text": "How come? Because this function is convex,\nbecause it's a convex function",
    "start": "4323540",
    "end": "4329760"
  },
  {
    "text": "precomposed with\nan affine function. These are convex\nfor the same reason. So we do have to say\nthat-- at this point,",
    "start": "4329760",
    "end": "4336218"
  },
  {
    "text": "we're not even saying it.  So you un-eliminate here.",
    "start": "4336218",
    "end": "4341430"
  },
  {
    "text": "Now, what's hilarious about\nthis is someone says, oh yeah, I just converted your\nproblem to a new problem. And you go, oh, thank you.",
    "start": "4341430",
    "end": "4346980"
  },
  {
    "text": "That's great. Tell me about the new\nproblem and you go well, it's got more variables. You're like, OK.",
    "start": "4346980",
    "end": "4353600"
  },
  {
    "text": "And you go, oh, by\nthe way, your problem didn't have any\nequality constraints, now you have a bunch of them. This doesn't sound\ngood, this story",
    "start": "4353600",
    "end": "4360568"
  },
  {
    "text": "doesn't sound like\nit's going anyway. Believe it or not, it's going\nto be super useful this idea.",
    "start": "4360568",
    "end": "4366219"
  },
  {
    "text": " Here's one you can--\nthis is a famous one.",
    "start": "4366220",
    "end": "4371290"
  },
  {
    "text": "These are all methods\nthat a lot of people know and would learn about\nby hand, actually literally,",
    "start": "4371290",
    "end": "4378490"
  },
  {
    "text": "since the 1940s. So here's one. ",
    "start": "4378490",
    "end": "4385420"
  },
  {
    "text": "You can take a linear\ninequality and introduce what's called a slack\nvariable, that's a standard term, not in\nmath, but, for example,",
    "start": "4385420",
    "end": "4395260"
  },
  {
    "text": "in optimization. These are just very simple\nand dumb these little",
    "start": "4395260",
    "end": "4400683"
  },
  {
    "text": "transformations. But this one says,\nwe rewrite this as AI transpose x\nplus Si equals bi,",
    "start": "4400683",
    "end": "4406517"
  },
  {
    "text": "where Si is a number\nbigger than zero, and that's called the slack. Slack makes perfect sense.",
    "start": "4406517",
    "end": "4412630"
  },
  {
    "text": "It means if you're right\nup against is, S is zero. If S is positive, it means\nthis constraint is satisfied",
    "start": "4412630",
    "end": "4419270"
  },
  {
    "text": "with strict inequality. And slack comes from\nthe idea of a chain",
    "start": "4419270",
    "end": "4424580"
  },
  {
    "text": "or a rope between two things. The constraint is if I put a\nsteel cable between two things and I make it a meter long, then\nthose two things cannot be more",
    "start": "4424580",
    "end": "4433100"
  },
  {
    "text": "than a meter apart. If they are exactly a meter\napart, then that chain is taut,",
    "start": "4433100",
    "end": "4440360"
  },
  {
    "text": "that's not a word\nin optimization. But if they're less than a\nmeter apart, then the chain,",
    "start": "4440360",
    "end": "4446780"
  },
  {
    "text": "there's zero tension in the\nchain, and then it's slack. And that word did make\nit into optimization.",
    "start": "4446780",
    "end": "4454100"
  },
  {
    "text": "So if you're curious,\nthat's what it means. Slack rope or slack\ncable or something.",
    "start": "4454100",
    "end": "4461510"
  },
  {
    "text": "So this is called\nintroducing slack variables. We'll show a couple. This one is also interesting.",
    "start": "4461510",
    "end": "4470270"
  },
  {
    "text": "I have my standard form\nproblem and I can rewrite it this way, which is hilarious. I introduce a new variable.",
    "start": "4470270",
    "end": "4476090"
  },
  {
    "text": "Now my variables are xt. Now when you hear xt, you should\nbe thinking graph, epigraph,",
    "start": "4476090",
    "end": "4481730"
  },
  {
    "text": "hypergraph, these\nkinds of things, because that's what\nit generally means when you have a variable\nand a comma and scalar.",
    "start": "4481730",
    "end": "4488630"
  },
  {
    "text": "Here, this constraint\nhere simply says that xt, the pair xt is in the epigraph.",
    "start": "4488630",
    "end": "4496070"
  },
  {
    "text": "I mean, it's silly. This just says t is\nbigger than the objective. And then it says, you\nminimize t subject to this.",
    "start": "4496070",
    "end": "4503480"
  },
  {
    "text": "Now, here's what's\ncool about this. Some people say this\nin a very fancy way. They say things like,\nfor convex optimization,",
    "start": "4503480",
    "end": "4510470"
  },
  {
    "text": "a linear objective is universal. I don't even know\nwhat that means.",
    "start": "4510470",
    "end": "4516050"
  },
  {
    "text": "So it says, without\nloss of generality-- well, you have to-- if you\ncan handle this constraint",
    "start": "4516050",
    "end": "4523610"
  },
  {
    "text": "and then you have a linear\nobjective, you're good to go. You just solve the\nproblem in epigraph form.",
    "start": "4523610",
    "end": "4530060"
  },
  {
    "text": "Make sense? That's why a lot of\ntimes if you'd say-- you'd look at you'd say,\noh, I went to Google.",
    "start": "4530060",
    "end": "4538579"
  },
  {
    "text": "I looked for code\nto solve this thing. And it's not there\nbecause it's what",
    "start": "4538580",
    "end": "4543602"
  },
  {
    "text": "you see-- the only\nthing I can find has a linear-- can\nsolve a linear objective and my problem has like\na nonlinear objective.",
    "start": "4543602",
    "end": "4549590"
  },
  {
    "text": "And the reason is\npeople are just expecting you to put\nsomething into epigraph form. ",
    "start": "4549590",
    "end": "4557173"
  },
  {
    "text": "Other things you\ncan do are things like selective minimization. You have two variables here.",
    "start": "4557173",
    "end": "4562280"
  },
  {
    "text": "I could actually eliminate x2. Suppose I can analytically\nminimize over f zero over x2,",
    "start": "4562280",
    "end": "4571167"
  },
  {
    "text": "then I can do that and I have\na problem that looks like. This would be the\ncase, for example, if this function\nwere quadratic in x2,",
    "start": "4571167",
    "end": "4577909"
  },
  {
    "text": "I can minimize a\nquadratic analytically. I could do that, and\nthen I eliminate x2.",
    "start": "4577910",
    "end": "4583310"
  },
  {
    "text": "And this is basically\nlike-- this is basically part of dynamic programming. That's what would happen\nin dynamic programming.",
    "start": "4583310",
    "end": "4589580"
  },
  {
    "text": "If you want to\nfind a good choice of an input over some\nsequence, you start at the end,",
    "start": "4589580",
    "end": "4595909"
  },
  {
    "text": "you minimize over the last one,\nand then there this function is called like\nthe value function",
    "start": "4595910",
    "end": "4601580"
  },
  {
    "text": "or something like that. And you just keep\ngoing and it all works. This one also, all of these\nplay nice with convexity.",
    "start": "4601580",
    "end": "4610110"
  },
  {
    "text": "So here, the reason f\nzero tilde is convex is because it is partial\nminimization of f",
    "start": "4610110",
    "end": "4617240"
  },
  {
    "text": "zero with respect\nto the variable x2. Everybody got that?",
    "start": "4617240",
    "end": "4622790"
  },
  {
    "text": "So all the rules you saw before\nwere now using for problems.",
    "start": "4622790",
    "end": "4627920"
  },
  {
    "text": " I'll say a little bit about\nquasi convex optimization.",
    "start": "4627920",
    "end": "4635000"
  },
  {
    "text": "If I have convex inequality\nconstraints, linear equality constraints, and I minimize\na quasi convex function,",
    "start": "4635000",
    "end": "4642350"
  },
  {
    "text": "that's called quasi\nconvex optimization. You have to be very careful\nhere because, for example, this",
    "start": "4642350",
    "end": "4648320"
  },
  {
    "text": "is for sure a quasi\nconvex function. And by the way, it's\nactually really flat here.",
    "start": "4648320",
    "end": "4653420"
  },
  {
    "text": "It's not that it's\nvisually flat, it's flat. In this one and then\nit keeps going up. This quasi convex.",
    "start": "4653420",
    "end": "4660130"
  },
  {
    "text": "That point is for\nsure locally optimal because you wiggle a\nlittle bit left and right",
    "start": "4660130",
    "end": "4666160"
  },
  {
    "text": "and the objective\ndoes not go down. But it is clearly not the\noptimum, which is here.",
    "start": "4666160",
    "end": "4673010"
  },
  {
    "text": "So some things don't\nhold in this case. But it turns out we can solve\nthese using convex optimization",
    "start": "4673010",
    "end": "4679900"
  },
  {
    "text": "pretty easily. And I'll show this trick and\nthen we'll quit for today.",
    "start": "4679900",
    "end": "4688270"
  },
  {
    "text": "If f zero is quasi\nconvex, then what you do is you find a parametrized\nset of convex functions",
    "start": "4688270",
    "end": "4694360"
  },
  {
    "text": "which have the following form. This defines a convex\nset in x for each t.",
    "start": "4694360",
    "end": "4700780"
  },
  {
    "text": "That's actually what it\nmeans to be quasi convex. So what I do is I express\nthat as a convex function",
    "start": "4700780",
    "end": "4706870"
  },
  {
    "text": "by t being less than zero. And here's an example,\nthe ratio of a convex",
    "start": "4706870",
    "end": "4712090"
  },
  {
    "text": "to a concave positive-- non-negative convex divided by\na concave positive function.",
    "start": "4712090",
    "end": "4721730"
  },
  {
    "text": "This is actually quasi convex.  Well, how do I check that?",
    "start": "4721730",
    "end": "4728790"
  },
  {
    "text": "Well, I want to know\nwhat happens if p of x-- I want to look at the\nsublevel set, which is p of x over q of x is\nless than or equal to t.",
    "start": "4728790",
    "end": "4735545"
  },
  {
    "text": "Q is positive, I multiply\nit on the other side, and I got p of x is\nless than t q of x.",
    "start": "4735545",
    "end": "4741770"
  },
  {
    "text": "Everybody following this? I pull it over and I\nget p minus t q of x.",
    "start": "4741770",
    "end": "4747679"
  },
  {
    "text": "If this is less than\nor equal to zero, then this thing is less than t. ",
    "start": "4747680",
    "end": "4754199"
  },
  {
    "text": "That's a convex function. So it's a convex in x not\njointly in x and t, But in x.",
    "start": "4754200",
    "end": "4760380"
  },
  {
    "text": "For each t positive,\nnon-negative, this is a convex function. ",
    "start": "4760380",
    "end": "4768270"
  },
  {
    "text": "Actually, 'what\nthis says is I have a specific way of\nseeing if I can find",
    "start": "4768270",
    "end": "4774780"
  },
  {
    "text": "a point that has that value. And then what we do\nis just bisection.",
    "start": "4774780",
    "end": "4780270"
  },
  {
    "text": "I'll quit very briefly,\nbut this is the idea. What you do is you simply\nsolve a feasibility problem.",
    "start": "4780270",
    "end": "4789300"
  },
  {
    "text": "This one basically says, can you\nfind a point where f zero of x is less than t?",
    "start": "4789300",
    "end": "4794490"
  },
  {
    "text": "That's this. These are the constraints. If you can, then\nyou found a point",
    "start": "4794490",
    "end": "4800040"
  },
  {
    "text": "and then you know for\nsure the optimal p star is less than that number. If the answer is you can't,\nthen that p star is above there.",
    "start": "4800040",
    "end": "4810840"
  },
  {
    "text": "You just use bisection. So we'll quit here\ntoday, and then we'll",
    "start": "4810840",
    "end": "4815860"
  },
  {
    "text": "continue on Thursday. ",
    "start": "4815860",
    "end": "4824000"
  }
]
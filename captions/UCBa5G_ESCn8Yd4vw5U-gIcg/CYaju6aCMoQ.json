[
  {
    "start": "0",
    "end": "5230"
  },
  {
    "text": "Before we start, I gave\nthe same talk at Stanford quite recently.",
    "start": "5230",
    "end": "11830"
  },
  {
    "text": "I suggested to the\npeople inviting me I could just give one talk\nand both audiences could come, but they would prefer it\nas two separate talks.",
    "start": "11830",
    "end": "18100"
  },
  {
    "text": "So if you went to\nthis talk recently, I suggest you leave now. You won't learn anything new.",
    "start": "18100",
    "end": "24052"
  },
  {
    "text": "OK.  What I'm going to do is\ncombine some recent ideas",
    "start": "24052",
    "end": "30910"
  },
  {
    "text": "in neural networks\nto try to explain how a neural network\ncould represent part-whole hierarchies\nwithout violating",
    "start": "30910",
    "end": "39850"
  },
  {
    "text": "any of the basic principles\nof how neurons work. And I'm going to explain\nthese ideas in terms",
    "start": "39850",
    "end": "48100"
  },
  {
    "text": "of an imaginary system. I started writing a design\ndocument for a system. And in the end, I decided\nthe design document by itself",
    "start": "48100",
    "end": "54910"
  },
  {
    "text": "was quite interesting. So this is just vaporware,\nstuff that doesn't exist. Little bits of it now exist.",
    "start": "54910",
    "end": "59920"
  },
  {
    "text": "But somehow I find\nit easy to explain the ideas in the context\nof an imaginary system.",
    "start": "59920",
    "end": "65634"
  },
  {
    "start": "65634",
    "end": "71170"
  },
  {
    "text": "So most people now\nstudying neural networks are doing engineering,\nand they don't really",
    "start": "71170",
    "end": "76440"
  },
  {
    "text": "care if it's exactly\nhow the brain works. They're not trying to\nunderstand how the brain works. They're trying to\nmake cool technology.",
    "start": "76440",
    "end": "82710"
  },
  {
    "text": "And so a hundred layers\nis fine in a ResNet. Weight sharing is fine in\na convolutional neural net.",
    "start": "82710",
    "end": "89040"
  },
  {
    "text": "Some researchers, particularly\ncomputational neuroscientists, investigate artificial\nneural networks",
    "start": "89040",
    "end": "95520"
  },
  {
    "text": "in an attempt to understand how\nthe brain might actually work. I think we still got a lot\nto learn from the brain.",
    "start": "95520",
    "end": "101680"
  },
  {
    "text": "And I think it's\nworth remembering that for about half a\ncentury, the only thing that kept research on neural\nnetworks going was the belief",
    "start": "101680",
    "end": "108664"
  },
  {
    "text": "that it must be possible\nto make these things learn complicated things\nbecause the brain does. ",
    "start": "108665",
    "end": "115720"
  },
  {
    "text": "So every image has a\ndifferent parse tree",
    "start": "115720",
    "end": "121212"
  },
  {
    "text": "that is the structure\nof the wholes in the parts in the image. And in a real\nneural network, you",
    "start": "121212",
    "end": "127890"
  },
  {
    "text": "can't dynamically allocate it. You can't just grab\na bunch of neurons and say, OK, you\nnow represent this",
    "start": "127890",
    "end": "134880"
  },
  {
    "text": "because you don't have\nrandom access memory. You can't just set the\nweights of the neurons to be whatever you like.",
    "start": "134880",
    "end": "140370"
  },
  {
    "text": "What a neuron does is\ndetermined by its connections. And they only change\nslowly at least probably.",
    "start": "140370",
    "end": "146250"
  },
  {
    "text": "Mostly, they change slowly. So the question is, if you can't\nchange what neurons do quickly,",
    "start": "146250",
    "end": "153150"
  },
  {
    "text": "how can you represent\na dynamic parse tree? ",
    "start": "153150",
    "end": "160450"
  },
  {
    "text": "In symbolic AI,\nit's not a problem. You just grab a\npiece of memory-- that's what it\nnormally amounts to--",
    "start": "160450",
    "end": "165640"
  },
  {
    "text": "and say this is\ngoing to represent a node in the\nparse tree, and I'm going to give it\npointers to other nodes,",
    "start": "165640",
    "end": "170800"
  },
  {
    "text": "other bits of memory that\nrepresent other nodes. So there's no problem. For about five years, I played\nwith a theory called Capsules",
    "start": "170800",
    "end": "178450"
  },
  {
    "text": "where you say because you can't\nallocate neurons on the fly, you're going to allocate\nthem in advance.",
    "start": "178450",
    "end": "185100"
  },
  {
    "text": "So we can take\ngroups of neurons, and we're going to allocate\nthem to different possible nodes in a parse tree.",
    "start": "185100",
    "end": "190560"
  },
  {
    "text": "And most of these groups\nof neurons for most images are going to be silent. A few are going to be active.",
    "start": "190560",
    "end": "197220"
  },
  {
    "text": "And then the ones that are\nactive we have to dynamically hook them up into a parse tree. So we have to have a way of\nrouting between these groups",
    "start": "197220",
    "end": "204480"
  },
  {
    "text": "of neurons. So that was the Capsule theory. And I had some very\ncompetent people",
    "start": "204480",
    "end": "210760"
  },
  {
    "text": "working with me who\nactually made it work, but it was tough going.",
    "start": "210760",
    "end": "216909"
  },
  {
    "text": "My view is that some\nideas want to work, and some ideas\ndon't want to work and capsules are the\nsort of in-between. Things like backpropagation\njust want to work.",
    "start": "216910",
    "end": "223750"
  },
  {
    "text": "You try them and they work. There's other ideas I've had\nthat just don't want to work.",
    "start": "223750",
    "end": "229030"
  },
  {
    "text": "Capsules was sort of in\nbetween, and we got it working. But I now have a new\ntheory that could",
    "start": "229030",
    "end": "234430"
  },
  {
    "text": "be seen as a funny\nkind of capsules model in which each capsule is\nuniversal, that is instead",
    "start": "234430",
    "end": "240490"
  },
  {
    "text": "of a capsule being dedicated\nto a particular kind of thing, each capsule can represent\nany kind of thing,",
    "start": "240490",
    "end": "249070"
  },
  {
    "text": "but hardware still comes\nin capsules, which are also called embedding sometimes. ",
    "start": "249070",
    "end": "256838"
  },
  {
    "text": "So the imaginary system I'll\ntalk about is called GLOM. And in GLOM hardware gets\nallocated to columns.",
    "start": "256839",
    "end": "266160"
  },
  {
    "text": "And each column\ncontains multiple levels of representation\nof what's happening in a small patch of the image.",
    "start": "266160",
    "end": "273400"
  },
  {
    "text": "So within a column, you\nmight have a lower level representation that\nsays it's a nostril.",
    "start": "273400",
    "end": "280044"
  },
  {
    "text": "And the next level up\nmight say it's a nose. And the next level\nup might say face, the next level up a person. And the top level\nmight say it's a party.",
    "start": "280045",
    "end": "287160"
  },
  {
    "text": "That's what the whole scene is. And the idea for representing\npart-whole hierarchies",
    "start": "287160",
    "end": "292710"
  },
  {
    "text": "is to use islands of agreement\nbetween the embeddings at these different levels.",
    "start": "292710",
    "end": "298360"
  },
  {
    "text": "So at the scene level,\nat the top level, you'd like the same embedding\nfor every patch of the image",
    "start": "298360",
    "end": "303600"
  },
  {
    "text": "because that patch is a patch\nof the same scene everywhere. But the object level\nyou'd like the embeddings",
    "start": "303600",
    "end": "309960"
  },
  {
    "text": "of all the different patches\nthat belong to the object to be the same. So as you go up this\nhierarchy, you're",
    "start": "309960",
    "end": "316080"
  },
  {
    "text": "trying to make things\nmore and more the same. And that's how you're\nsqueezing redundancy out.",
    "start": "316080",
    "end": "322500"
  },
  {
    "text": "The embedding vectors are the\nthings that act like pointers. And the embedding\nvectors are dynamic.",
    "start": "322500",
    "end": "328720"
  },
  {
    "text": "They're neural activations\nrather than neural weights. So it's fine to have\ndifferent embedding vectors for every image.",
    "start": "328720",
    "end": "334545"
  },
  {
    "text": " So here's a little picture.",
    "start": "334545",
    "end": "340710"
  },
  {
    "text": "If you had a one\ndimensional row of patches, these are the columns\nfor the patches.",
    "start": "340710",
    "end": "348460"
  },
  {
    "text": "And you'd have something like\na convolutional neural net as a front end.",
    "start": "348460",
    "end": "353620"
  },
  {
    "text": "And then after\nthe front end, you produce your lowest\nlevel embeddings that say what's going on\nin each particular patch.",
    "start": "353620",
    "end": "361060"
  },
  {
    "text": "And so that bottom\nlayer of black arrows they're all different. Of course, these\nembeddings are thousands",
    "start": "361060",
    "end": "366100"
  },
  {
    "text": "of dimensions maybe hundreds\nof thousands in your brain. And so a two-dimensional\nvector isn't right.",
    "start": "366100",
    "end": "374080"
  },
  {
    "text": "But at least I can\nrepresent where the two vectors are the same\nby using the orientation. So at the lowest\nlevel, all the patches",
    "start": "374080",
    "end": "381490"
  },
  {
    "text": "will have different\nrepresentations, but the next level up,\nthe first two patches,",
    "start": "381490",
    "end": "387390"
  },
  {
    "text": "they might be part of\na nostril, for example. ",
    "start": "387390",
    "end": "395240"
  },
  {
    "text": "And so, yeah, they'll\nhave the same embedding. But the next level up,\nthe first three patches",
    "start": "395240",
    "end": "400879"
  },
  {
    "text": "might be part of a nose. And so they'll all have\nthe same embedding. Notice that even though\nwhat's in the image",
    "start": "400880",
    "end": "407300"
  },
  {
    "text": "is quite different,\nat the part level, those three red vectors are\nall meant to be the same.",
    "start": "407300",
    "end": "415190"
  },
  {
    "text": "So what we're doing is we're\ngetting the same representation for things that are\nsuperficially very different.",
    "start": "415190",
    "end": "420730"
  },
  {
    "text": "We're finding spatial\ncoherence in an image by giving the same\nrepresentation to different things.",
    "start": "420730",
    "end": "426819"
  },
  {
    "text": "And at the object level, you\nmight have a nose and then a mouth.",
    "start": "426820",
    "end": "431950"
  },
  {
    "text": "And they're the same face. They're part of the same face. And so all those\nvectors are the same.",
    "start": "431950",
    "end": "437120"
  },
  {
    "text": "And this network\nhasn't yet settled down to produce on the unseen level.",
    "start": "437120",
    "end": "442320"
  },
  {
    "text": "So the islands of agreement are\nwhat captured the parse tree. Now they're a bit more\npowerful than a parse tree.",
    "start": "442320",
    "end": "450860"
  },
  {
    "text": "They can capture things\nlike shut the heck up. You can have shut and up can be\ndifferent vectors at one level.",
    "start": "450860",
    "end": "457580"
  },
  {
    "text": "But at a higher\nlevel, shut and up can have exactly the same vector,\nnamely the vector for shut up,",
    "start": "457580",
    "end": "463610"
  },
  {
    "text": "and they can be disconnected. So you can do things a bit\nmore powerful than the context free grammar here.",
    "start": "463610",
    "end": "468920"
  },
  {
    "text": "But basically it's a parse tree. If you're a physicist, you can\nthink of each of these levels",
    "start": "468920",
    "end": "476690"
  },
  {
    "text": "as an Ising model with real\nvalued vectors rather than binary spins.",
    "start": "476690",
    "end": "482840"
  },
  {
    "text": "Then you can think of them\nbeing coordinate transforms between levels, which makes\nit much more complicated.",
    "start": "482840",
    "end": "488310"
  },
  {
    "text": "And then this is a kind\nof multi-level Ising model but with complicated\ninteractions between the levels",
    "start": "488310",
    "end": "495590"
  },
  {
    "text": "because, for example,\nbetween the red arrows and the black arrows\nabove them, you need the coordinate transform\nbetween a nose and a face.",
    "start": "495590",
    "end": "503389"
  },
  {
    "text": "But we'll come to that later. If you're not a\nphysicist, ignore all that because it won't help.",
    "start": "503390",
    "end": "509300"
  },
  {
    "text": " So I want to start on this--",
    "start": "509300",
    "end": "515183"
  },
  {
    "text": "I guess it's particularly\nrelevant for a natural language course where you-- some of you\nare not vision people by trying",
    "start": "515184",
    "end": "522450"
  },
  {
    "text": "to prove to you that coordinate\nsystems are not just something invented by Descartes.",
    "start": "522450",
    "end": "528540"
  },
  {
    "text": "Coordinate systems were invented\nby the brain a long time ago. And we use coordinate\nsystems in understanding",
    "start": "528540",
    "end": "535920"
  },
  {
    "text": "what's going on in an image. I also want to demonstrate\nthe psychological reality of parse trees for an image.",
    "start": "535920",
    "end": "542800"
  },
  {
    "text": "So I'm going to do\nthis with a task that I invented a long\ntime ago in the 1970s",
    "start": "542800",
    "end": "549330"
  },
  {
    "text": "when I was a grad\nstudent in fact. And you have to do this task to\nget the full benefit from it.",
    "start": "549330",
    "end": "556250"
  },
  {
    "text": " So I want you to imagine on\nthe tabletop in front of you",
    "start": "556250",
    "end": "562810"
  },
  {
    "text": "there's a wire-frame cube. And it's in the standard\norientation for a cube. It's resting on the tabletop.",
    "start": "562810",
    "end": "569560"
  },
  {
    "text": "And from your point\nof view, there's a front bottom right hand\ncorner and a top back left hand",
    "start": "569560",
    "end": "577060"
  },
  {
    "text": "corner. Here we go. OK. The front bottom\nright hand corner",
    "start": "577060",
    "end": "582490"
  },
  {
    "text": "is resting on the tabletop along\nwith the four other corners. And the top back\nleft hand corner",
    "start": "582490",
    "end": "588460"
  },
  {
    "text": "is at the other end of\na diagonal, which goes through the center of the cube. OK, so far so good.",
    "start": "588460",
    "end": "594920"
  },
  {
    "text": "Now, what we're going\nto do is rotate the cube so that this finger\nstays on the tabletop and the other finger is\nvertically above it, like that.",
    "start": "594920",
    "end": "603460"
  },
  {
    "text": "This finger\nshouldn't have moved. OK. So now we've got the\ncube in an orientation",
    "start": "603460",
    "end": "608680"
  },
  {
    "text": "where that thing that was a\nbody diagonal is now vertical. And all you've got to do\nis take the bottom finger",
    "start": "608680",
    "end": "615220"
  },
  {
    "text": "because that's still\non the table top and point with the bottom finger\nto where the other corners of the cube are.",
    "start": "615220",
    "end": "620855"
  },
  {
    "text": "So I want you to try do it. Off you go. Take your bottom finger. Hold your top finger\nat the other end",
    "start": "620855",
    "end": "626900"
  },
  {
    "text": "of that diagonal that's now been\nmade vertical and just point to where the other corners are.",
    "start": "626900",
    "end": "632940"
  },
  {
    "text": "And luckily it zooms\nso most of you-- other people won't be\nable to see what you did.",
    "start": "632940",
    "end": "639390"
  },
  {
    "text": "And I can see that some\nof you aren't pointing, and that's very bad. So most people point\nout four of the corners.",
    "start": "639390",
    "end": "647399"
  },
  {
    "text": "And the most common response\nis to say they're here, here, here, and here. They point out four corners in\na square halfway up that axis.",
    "start": "647400",
    "end": "654150"
  },
  {
    "text": " That's wrong as\nyou might imagine.",
    "start": "654150",
    "end": "659880"
  },
  {
    "text": "And it's easy to\nsee that it's wrong because if you imagine the\ncube in the normal orientation and count the corners,\nthere's eight of them.",
    "start": "659880",
    "end": "668260"
  },
  {
    "text": "And these were two corners. So where did the\nother two corners go? So one theory is that\nwhen you rotated the cube,",
    "start": "668260",
    "end": "675550"
  },
  {
    "text": "the centripetal forces made them\nfly off into your unconscious. That's not a very good theory.",
    "start": "675550",
    "end": "681200"
  },
  {
    "text": "So what's happening\nhere is you have no idea where the other corner,\nare unless you're something",
    "start": "681200",
    "end": "687250"
  },
  {
    "text": "like a crystallographer. You can sort of imagine\nbits of the cube, but you just can't imagine this\nstructure of the other corners,",
    "start": "687250",
    "end": "693745"
  },
  {
    "text": "what structure they form. And this common\nresponse that people give of four corners in a square\nis doing something very weird.",
    "start": "693745",
    "end": "704760"
  },
  {
    "text": "It's saying, well, OK. I don't know where the\nbits of the cube are, but I know something\nabout cubes.",
    "start": "704760",
    "end": "710250"
  },
  {
    "text": "I know the corners\ncome in fours. I know a cube has this four-fold\nrotational symmetry or two",
    "start": "710250",
    "end": "716639"
  },
  {
    "text": "planes of bilateral symmetry\nbut right angles to one another. And so what people do is\nthey preserve the symmetries",
    "start": "716640",
    "end": "722970"
  },
  {
    "text": "of the cube in their response. They give four\ncorners in a square.",
    "start": "722970",
    "end": "728430"
  },
  {
    "text": "Now, what they've\nactually pointed out if they do that is two\npyramids each of which",
    "start": "728430",
    "end": "734550"
  },
  {
    "text": "has a square base. One's upside down, and\nthey're stuck base to base.",
    "start": "734550",
    "end": "739560"
  },
  {
    "text": "So you can visualize\nthat quite easily. So square base pyramid\nwith another one stuck underneath it.",
    "start": "739560",
    "end": "745242"
  },
  {
    "text": "And so now you get\nyour two fingers as the vertices of\nthose two pyramids. And what's\ninteresting about that",
    "start": "745242",
    "end": "752220"
  },
  {
    "text": "is you've preserved the\nsymmetries of the cube at the cost of doing something\npretty radical, which",
    "start": "752220",
    "end": "759300"
  },
  {
    "text": "is changing faces to vertices\nand vertices to faces.",
    "start": "759300",
    "end": "764370"
  },
  {
    "text": "The thing you pointed out if\nyou did that was an octahedron. It has eight faces\nand 6 vertices.",
    "start": "764370",
    "end": "771459"
  },
  {
    "text": "A cube has six faces\nand eight vertices. So in order to\npreserve the symmetries you know about of\nthe cube, if you",
    "start": "771460",
    "end": "779870"
  },
  {
    "text": "did that, you've done\nsomething really radical, which has changed faces for vertices\nand vertices for faces.",
    "start": "779870",
    "end": "787850"
  },
  {
    "text": "I should show you what\nthe answer looks like. So I'm going to step back\nand try and get enough light",
    "start": "787850",
    "end": "793459"
  },
  {
    "text": "and maybe you can see this cube.  So this is a cube.",
    "start": "793460",
    "end": "801440"
  },
  {
    "text": "And you can see\nthat the other edges",
    "start": "801440",
    "end": "806510"
  },
  {
    "text": "form a kind of zig-zag\nring around the middle. So I got a picture of it.",
    "start": "806510",
    "end": "811570"
  },
  {
    "text": " So the colored rods\nhere are the other edges",
    "start": "811570",
    "end": "817430"
  },
  {
    "text": "of the cube, the ones that\ndon't touch your fingertips. And your top fingers are\nconnected to the three vertices",
    "start": "817430",
    "end": "822860"
  },
  {
    "text": "of those flaps when\nyour bottom finger's connected to the lowest\nthree vertices there.",
    "start": "822860",
    "end": "829693"
  },
  {
    "text": "And that's what a\ncube looks like. It's something you\nhad no idea about. This is just a completely\ndifferent model of a cube.",
    "start": "829693",
    "end": "835880"
  },
  {
    "text": "It's so different. I'll give it a different name. I'll call it a hexahedron. And the thing to\nnotice is a hexahedron",
    "start": "835880",
    "end": "843840"
  },
  {
    "text": "and a cube are\njust conceptually, utterly different. You wouldn't even know one\nwas the same as the other",
    "start": "843840",
    "end": "849970"
  },
  {
    "text": "if you think about one as a\nhexahedron and one as a cube. It's like the ambiguity\nbetween a tilted square",
    "start": "849970",
    "end": "855510"
  },
  {
    "text": "and an upright diamond\nbut more powerful because you're not\nfamiliar with it.",
    "start": "855510",
    "end": "861000"
  },
  {
    "text": "And that's my demonstration\nthat people really do use coordinate systems. And if you use a different\ncoordinate system",
    "start": "861000",
    "end": "866250"
  },
  {
    "text": "to describe things-- and here I forced you to use\na different coordinate system by making the\ndiagonal be vertical",
    "start": "866250",
    "end": "872280"
  },
  {
    "text": "and asking you to describe it\nrelative to that vertical axis. Then familiar things become\ncompletely unfamiliar.",
    "start": "872280",
    "end": "879200"
  },
  {
    "text": "And when you do see them\nrelative to this new frame, they just are a completely\ndifferent thing.",
    "start": "879200",
    "end": "884250"
  },
  {
    "text": "Notice that things like\nconvolutional neural nets don't have that. They can't look at\nsomething and have two utterly different\ninternal representations",
    "start": "884250",
    "end": "890880"
  },
  {
    "text": "of the very same thing. I'm also showing you\nthat you do parsing.",
    "start": "890880",
    "end": "895899"
  },
  {
    "text": "So here I've colored\nit so you parse it into what I call the crown,\nwhich is three triangular",
    "start": "895900",
    "end": "901180"
  },
  {
    "text": "flaps that slope\nupwards and outwards. Here's a different parsing,\nthe same green flaps",
    "start": "901180",
    "end": "907250"
  },
  {
    "text": "sloping upwards and outwards. Now, we have a red flap\nsloping downwards and outwards.",
    "start": "907250",
    "end": "912500"
  },
  {
    "text": "And we have a central rectangle. And you just have the two\nends of the rectangle. And if you perceive this, then\nI close your eyes and ask you,",
    "start": "912500",
    "end": "921920"
  },
  {
    "text": "were there any\nparallel edges there? You're very well aware\nthat those two blue edges",
    "start": "921920",
    "end": "927230"
  },
  {
    "text": "were parallel. Then you're typically not aware\nof any other parallel edges even though you know by\nsymmetry there must be pairs.",
    "start": "927230",
    "end": "934190"
  },
  {
    "text": "Similarly with the crown. If you see the crown and then\nI ask you to close your eyes and ask you where\nthe parallel edge is,",
    "start": "934190",
    "end": "940880"
  },
  {
    "text": "you don't see any\nparallel edges. And that's because\nthe coordinate system you're using for those flaps\ndon't line up with the edges.",
    "start": "940880",
    "end": "948680"
  },
  {
    "text": "Then you only notice\nparallel edges if they line up with the\ncoordinate system you see. So here for the rectangle,\nour parallel edges",
    "start": "948680",
    "end": "955850"
  },
  {
    "text": "align with the\ncoordinate system. For the flaps, they don't. So you're aware that those\ntwo blue edges are parallel,",
    "start": "955850",
    "end": "961279"
  },
  {
    "text": "but you're not aware that one\nof the green edges and one of the red edges are parallel. ",
    "start": "961280",
    "end": "970460"
  },
  {
    "text": "So this isn't like the\nNecker cube ambiguity where when it flips you\nthink that what's out there in reality is different.",
    "start": "970460",
    "end": "976449"
  },
  {
    "text": "Things are at a different depth. This is like, next weekend we\nshould be visiting relatives.",
    "start": "976450",
    "end": "982446"
  },
  {
    "text": "So if you take the\nsentence \"next weekend we should be visiting\nrelatives,\" it can mean, next weekend what we will be\ndoing is visiting relatives,",
    "start": "982447",
    "end": "991420"
  },
  {
    "text": "or it can mean, next\nweekend what we will be is visiting relatives.",
    "start": "991420",
    "end": "997150"
  },
  {
    "text": "Now those are completely\ndifferent senses. They happen to have the\nsame truth conditions. They mean the same thing in\nthe sense of truth conditions",
    "start": "997150",
    "end": "1004950"
  },
  {
    "text": "because if you're visiting\nrelatives, what you are is visiting relatives. And it's that kind of ambiguity.",
    "start": "1004950",
    "end": "1010397"
  },
  {
    "text": "No disagreement about\nwhat's going on in the world but two completely different\nways of seeing the sentence. ",
    "start": "1010397",
    "end": "1021639"
  },
  {
    "text": "This was drawn in the 1970s. This is what AI was\nlike in the 1970s.",
    "start": "1021640",
    "end": "1028520"
  },
  {
    "text": "This is a sort of structural\ndescription of the crown interpretation.",
    "start": "1028520",
    "end": "1033559"
  },
  {
    "text": "So you have nodes for all\nvarious parts in the hierarchy. I've also put\nsomething on the arcs.",
    "start": "1033560",
    "end": "1039849"
  },
  {
    "text": "That Rwx is the relationship\nbetween the crown and the flap.",
    "start": "1039849",
    "end": "1046359"
  },
  {
    "text": "And that can be\nrepresented by a matrix. It's really the relationship\nbetween the intrinsic frame of reference of the crown\nand the intrinsic frame",
    "start": "1046359",
    "end": "1053800"
  },
  {
    "text": "of reference of the flap. Then notice that if I\nchange my viewpoint,",
    "start": "1053800",
    "end": "1058960"
  },
  {
    "text": "that doesn't change at all. So that kind of relationship\nwould be a good thing to put in the weights\nof a neural network",
    "start": "1058960",
    "end": "1065622"
  },
  {
    "text": "because you like\nthe neural network to be able to recognize shapes\nindependently of viewpoint. And that Rwx is knowledge\nabout the shape that's",
    "start": "1065622",
    "end": "1073799"
  },
  {
    "text": "independent of viewpoint. Here's the \"zig-zag\"\ninterpretation.",
    "start": "1073800",
    "end": "1080519"
  },
  {
    "text": "And here's something else\nwhere I've added the things in the heavy blue boxes.",
    "start": "1080520",
    "end": "1086279"
  },
  {
    "text": "They're the relationship\nbetween the-- a node and the viewer, that\nis to be more explicit.",
    "start": "1086280",
    "end": "1093809"
  },
  {
    "text": "The coordinate transformation\nbetween the intrinsic frame of reference of the crown\nand the intrinsic frame",
    "start": "1093810",
    "end": "1099270"
  },
  {
    "text": "of reference of the viewer,\nyour eyeball is that Rwv.",
    "start": "1099270",
    "end": "1104400"
  },
  {
    "text": "And that's a different\nkind of thing altogether because as you\nchange viewpoint, that changes.",
    "start": "1104400",
    "end": "1109600"
  },
  {
    "text": "In fact, as you\nchange viewpoint, all those things\nin blue boxes all change together in\na consistent way.",
    "start": "1109600",
    "end": "1116340"
  },
  {
    "text": "And there's a\nsimple relationship, which is that if you take Rwv\nthen you multiply it by Rwx,",
    "start": "1116340",
    "end": "1122220"
  },
  {
    "text": "you get Rxv. So you can easily propagate\nviewpoint information",
    "start": "1122220",
    "end": "1127590"
  },
  {
    "text": "over a structural description. And that's what I think\na mental image is. Rather than a bunch\nof pixels, it's",
    "start": "1127590",
    "end": "1135520"
  },
  {
    "text": "a structural description\nwith associated viewpoint information. ",
    "start": "1135520",
    "end": "1142230"
  },
  {
    "text": "That makes sense of a lot of\nproperties of mental images, like if you want to do any\nreasoning with things like Rwx,",
    "start": "1142230",
    "end": "1149640"
  },
  {
    "text": "you form a mental image,\nthat is you fill in or you choose a viewpoint.",
    "start": "1149640",
    "end": "1155665"
  },
  {
    "text": "And I want to do one more demo\nto convince you you always choose a viewpoint when\nyou're solving mental imagery problems.",
    "start": "1155665",
    "end": "1161072"
  },
  {
    "text": "So I'm going to give you another\nvery simple mental imagery problem. At the risk of\nrunning over time.",
    "start": "1161072",
    "end": "1167610"
  },
  {
    "text": "Imagine that you're\nat a particular point and you travel a mile east, and\nthen you travel a mile north,",
    "start": "1167610",
    "end": "1175080"
  },
  {
    "text": "and then you travel\na mile east again. What's your direction back\nto your starting point?",
    "start": "1175080",
    "end": "1180790"
  },
  {
    "text": "This isn't a very hard problem. It's sort of a bit South\nand quite a lot west, right?",
    "start": "1180790",
    "end": "1186309"
  },
  {
    "text": "It's not exactly southwest,\nbut it's sort of southwest. Now, when you did that\ntask, what you imagined",
    "start": "1186310",
    "end": "1194380"
  },
  {
    "text": "from your point of view\nis you went a mile east, and then you went a\nmile north, and then you went a mile east again.",
    "start": "1194380",
    "end": "1201490"
  },
  {
    "text": "I'll tell you what\nyou didn't imagine. You didn't imagine that\nyou went a mile east, and you went a mile\nnorth, and then",
    "start": "1201490",
    "end": "1206578"
  },
  {
    "text": "you went a mile east again. You could have solved\nthe problem perfectly well with north not being up. But you had north up.",
    "start": "1206578",
    "end": "1212860"
  },
  {
    "text": "You also didn't imagine this. You got a mile east, and\nthen a mile north, and then a mile east again. And you didn't imagine this.",
    "start": "1212860",
    "end": "1218770"
  },
  {
    "text": "You go a mile east, and\nthen a mile north and so on. You imagined it at\na particular scale in a particular orientation\nand in a particular position.",
    "start": "1218770",
    "end": "1225774"
  },
  {
    "text": " And you can answer questions\nabout roughly how big",
    "start": "1225775",
    "end": "1230910"
  },
  {
    "text": "it was and so on. So that's evidence that\nto solve these tasks that involve using relationships\nbetween things,",
    "start": "1230910",
    "end": "1239070"
  },
  {
    "text": "you form a mental image. OK, enough on mental imagery.",
    "start": "1239070",
    "end": "1246030"
  },
  {
    "text": "So I'm now going to give you\na very brief introduction to contrastive\nlearning, where this is a complete\ndisconnect in the talk,",
    "start": "1246030",
    "end": "1254130"
  },
  {
    "text": "but they'll come\nback together soon. So in contrast to\nself-supervised learning, what",
    "start": "1254130",
    "end": "1262330"
  },
  {
    "text": "we try and do is make two\ndifferent crops of an image have the same representation.",
    "start": "1262330",
    "end": "1268360"
  },
  {
    "text": " There's a paper a long time\nago by Becker and Hinton",
    "start": "1268360",
    "end": "1274289"
  },
  {
    "text": "where we're doing this to\ndiscover low-level coherence in an image, like the\ncontinuity of surfaces",
    "start": "1274290",
    "end": "1280890"
  },
  {
    "text": "or the depth of surfaces. It's been improved\na lot since then.",
    "start": "1280890",
    "end": "1287370"
  },
  {
    "text": "And it's been used for doing\nthings like classification. That is you take an image that\nhas one prominent object in it",
    "start": "1287370",
    "end": "1296550"
  },
  {
    "text": "and you say if I take a crop\nof the image that contains sort of any part of that\nobject, it should",
    "start": "1296550",
    "end": "1304192"
  },
  {
    "text": "have the same representation\nas some other crop of the image containing\na part of that object.",
    "start": "1304192",
    "end": "1309310"
  },
  {
    "text": "And this has been developed\na lot in the last few years. I'm going to talk\nabout a model developed",
    "start": "1309310",
    "end": "1315930"
  },
  {
    "text": "a couple of years ago by my\ngroup in Toronto called SimCLR. But there's lots\nof other models. And since then,\nthings have improved.",
    "start": "1315930",
    "end": "1322155"
  },
  {
    "text": " So in SimCLR, you\ntake an image x.",
    "start": "1322155",
    "end": "1328750"
  },
  {
    "text": "You take two different crops. And you also do color distortion\nof the crops, different color",
    "start": "1328750",
    "end": "1335200"
  },
  {
    "text": "distortions of each crop. And that's to prevent it\nfrom using color histograms to say they're the same.",
    "start": "1335200",
    "end": "1341750"
  },
  {
    "text": "So you mess with the color\nso it can't use color in a simple way.",
    "start": "1341750",
    "end": "1347120"
  },
  {
    "text": "And that gives you xi\ntilde, and xj tilde.",
    "start": "1347120",
    "end": "1352550"
  },
  {
    "text": "You then put those through\nthe same neural network, f. Then you get a representation h.",
    "start": "1352550",
    "end": "1359445"
  },
  {
    "text": "And then you take\nthe representation h, and you put it through\nanother neural network, which compresses it a bit.",
    "start": "1359445",
    "end": "1364630"
  },
  {
    "text": "And it goes to low\ndimensionality. That's an extra complexity\nI'm not going to explain, but it makes it\nwork a bit better.",
    "start": "1364630",
    "end": "1371790"
  },
  {
    "text": "You can do it\nwithout doing that. And you get two\nembeddings, zi and zj.",
    "start": "1371790",
    "end": "1377130"
  },
  {
    "text": "And your aim is to\nmaximize the agreement between those vectors.",
    "start": "1377130",
    "end": "1382187"
  },
  {
    "text": "And so you start off doing that. And you say, OK, let's start\noff with random neural networks,",
    "start": "1382187",
    "end": "1387310"
  },
  {
    "text": "random weights in\nthe neural networks. And let's take two patches. And let's put them through\nthese transformations.",
    "start": "1387310",
    "end": "1392646"
  },
  {
    "text": "And let's try and make\nzi be the same as zj. So let's back propagate\nthe squared difference",
    "start": "1392646",
    "end": "1397950"
  },
  {
    "text": "between components of\ni and components of j. And hey, presto,\nwhat you discover",
    "start": "1397950",
    "end": "1403410"
  },
  {
    "text": "is when everything\ncollapses, for every image,",
    "start": "1403410",
    "end": "1409120"
  },
  {
    "text": "it will always produce\nthe same zi and zj. And then you realize,\nwell, that's not what I meant by agreement.",
    "start": "1409120",
    "end": "1414899"
  },
  {
    "text": "I mean, they should\nbe the same when you get two crops of the\nsame image and different",
    "start": "1414900",
    "end": "1420030"
  },
  {
    "text": "when you get two crops\nwith different images. Otherwise, there's not\nreally agreement, right? ",
    "start": "1420030",
    "end": "1428580"
  },
  {
    "text": "So you have to have\nnegative examples. You have to show it crops\nfrom different images and say those\nshould be different.",
    "start": "1428580",
    "end": "1435539"
  },
  {
    "text": "If they're already\ndifferent, you don't try and make them\na lot more different. It's very easy to make\nthings very different,",
    "start": "1435540",
    "end": "1442110"
  },
  {
    "text": "but that's not what you want. You just want to be sure\nthey're different enough so crops from different\nimages aren't taken",
    "start": "1442110",
    "end": "1447840"
  },
  {
    "text": "to be from the same image. So if they happen to be very\nsimilar, you push them apart. And that stops your\nrepresentations collapsing.",
    "start": "1447840",
    "end": "1454230"
  },
  {
    "text": "That's called\ncontrastive learning. And it works very well. So what you can do is\ndo unsupervised learning",
    "start": "1454230",
    "end": "1463470"
  },
  {
    "text": "by trying to maximize agreement\nbetween the representations you get from two image patches\nfrom the same image.",
    "start": "1463470",
    "end": "1471370"
  },
  {
    "text": "And after you've\ndone that, you just take your representation\nof the image patch, and you feed it to a linear\nclassifier, a bunch of weights",
    "start": "1471370",
    "end": "1479250"
  },
  {
    "text": "so that you multiply the\nrepresentation by a weight matrix, put it through a\nsoftmax and get close labels.",
    "start": "1479250",
    "end": "1485640"
  },
  {
    "text": "And then you train that\nby gradient descent. And what you discover is\nthat that's just about as",
    "start": "1485640",
    "end": "1493440"
  },
  {
    "text": "good as training on label data. So now the only thing you\ntrained on labeled data is that last linear classifier.",
    "start": "1493440",
    "end": "1500309"
  },
  {
    "text": "The previous slides were\ntrained on unlabeled data. And you managed to train\nyour representations",
    "start": "1500310",
    "end": "1507062"
  },
  {
    "text": "without needing labels.  Now, there's a\nproblem with this.",
    "start": "1507062",
    "end": "1515270"
  },
  {
    "text": "It works very nicely, but\nit's really confounding objects and whole scenes.",
    "start": "1515270",
    "end": "1521530"
  },
  {
    "text": "So it makes sense to say\ntwo different patches from the same scene\nshould get the same vector",
    "start": "1521530",
    "end": "1528220"
  },
  {
    "text": "label at the scene level because\nthey're from the same scene. But what if one of\nthe patches contains",
    "start": "1528220",
    "end": "1534680"
  },
  {
    "text": "bits of objects A and B\nand another patch contain bits of objects A and C? You don't really want\nthose two patches to have the same representation\nat the object level.",
    "start": "1534680",
    "end": "1542519"
  },
  {
    "text": "So we have to distinguish\nthese different levels of representation. And for contrastive\nlearning, if you",
    "start": "1542520",
    "end": "1549610"
  },
  {
    "text": "don't use any kind of\ngating or attention, then what's happening\nis you're really doing",
    "start": "1549610",
    "end": "1555223"
  },
  {
    "text": "learning at the scene level.  What we'd like is that\nthe representations you",
    "start": "1555223",
    "end": "1562130"
  },
  {
    "text": "get at the object level should\nbe the same if both patches are",
    "start": "1562130",
    "end": "1567740"
  },
  {
    "text": "patches of object A\nbut should be different if one patch is for object A\nand one patch is for object B. And to do that, we're going\nto need some form of attention",
    "start": "1567740",
    "end": "1574910"
  },
  {
    "text": "to decide whether they really\ncome from the same thing. And so GLOM is\ndesigned to do that. It's trying to take\ncontrastive learning",
    "start": "1574910",
    "end": "1581940"
  },
  {
    "text": "and to introduce a\ntension of the kind you get in transformers in order\nnot to try and say things",
    "start": "1581940",
    "end": "1587940"
  },
  {
    "text": "are the same when they're not. I should mention at this\npoint that most of you",
    "start": "1587940",
    "end": "1593700"
  },
  {
    "text": "will be familiar with BERT. Then you can think\nof the word fragments that are fed into BERT.",
    "start": "1593700",
    "end": "1599220"
  },
  {
    "text": "There's like the image\npatches I'm using here. And in BERT, you have that\nwhole column of representations",
    "start": "1599220",
    "end": "1605130"
  },
  {
    "text": "of the same word fragment. In BERT, what's happening\npresumably as you go up",
    "start": "1605130",
    "end": "1610679"
  },
  {
    "text": "is you're getting semantically\nricher representations.",
    "start": "1610680",
    "end": "1616440"
  },
  {
    "text": "But in BERT, there's no\nattempt to get representations of larger things\nlike whole phrases.",
    "start": "1616440",
    "end": "1622095"
  },
  {
    "text": " What I'm going to talk about\nwill be a way to modify BERT So",
    "start": "1622095",
    "end": "1628230"
  },
  {
    "text": "as you go up, you get bigger\nand bigger islands of agreement. So, for example, after\na couple of levels,",
    "start": "1628230",
    "end": "1635550"
  },
  {
    "text": "then things like\n\"New\" and \"York\" will have the different\nfragments of \"York.\"",
    "start": "1635550",
    "end": "1641415"
  },
  {
    "text": "And suppose its got two\ndifferent fragments will have exactly the same\nrepresentation if it was done in the GLOM-like way.",
    "start": "1641415",
    "end": "1647460"
  },
  {
    "text": "And then as you go\nup another level, the fragments of \"New\"\nor new's probably a theme in its own right\nand the fragments of \"York\"",
    "start": "1647460",
    "end": "1654840"
  },
  {
    "text": "would all have exactly\nthe same representation. They have this\nisland of agreement.",
    "start": "1654840",
    "end": "1660559"
  },
  {
    "text": "And that would be\na representation of a compound thing. And as you go up,\nyou're going to get",
    "start": "1660560",
    "end": "1665960"
  },
  {
    "text": "these islands of\nagreement that represent bigger and bigger things. And that's going to be a\nmuch more useful kind of BERT",
    "start": "1665960",
    "end": "1671570"
  },
  {
    "text": "because instead of taking\nvectors that represent word fragments and then sort\nof munging them together",
    "start": "1671570",
    "end": "1678800"
  },
  {
    "text": "by taking the max\nof each component, for example, which is\njust a crazy thing to do,",
    "start": "1678800",
    "end": "1684880"
  },
  {
    "text": "you would explicitly\nas you're learning form representations\nof larger parts in the part-whole hierarchy.",
    "start": "1684880",
    "end": "1692120"
  },
  {
    "text": "OK.  So what are we going after\nin GLOM is a particular kind",
    "start": "1692120",
    "end": "1699280"
  },
  {
    "text": "of spatial coherence. That's more complicated than\nthe spatial coherence caused by the fact that\nsurfaces tend to be",
    "start": "1699280",
    "end": "1705640"
  },
  {
    "text": "at the same depth\nand same orientation in nearby patches of an image. We're going after the\nspacial coherence that",
    "start": "1705640",
    "end": "1714180"
  },
  {
    "text": "says that if you find\na mouth in an image and you find a nose\nin an image and then the right spatial\nrelationship to make a face,",
    "start": "1714180",
    "end": "1721260"
  },
  {
    "text": "then that's a particular\nkind of coherence. And we want to go after\nthat unsupervised.",
    "start": "1721260",
    "end": "1726840"
  },
  {
    "text": "And we want to discover that\nkind of coherence in images. ",
    "start": "1726840",
    "end": "1733830"
  },
  {
    "text": "So before I go into\nmore details about GLOM, I want a disclaimer. ",
    "start": "1733830",
    "end": "1740889"
  },
  {
    "text": "For years, computer\nvision treated vision as you've got a static\nimage, a uniform resolution,",
    "start": "1740890",
    "end": "1746060"
  },
  {
    "text": "then you want to\nsay what's in it. That's not how vision\nworks in the real world. In the real world,\nthis is actually a loop",
    "start": "1746060",
    "end": "1752230"
  },
  {
    "text": "where you decide where to look. If you're a person\nor a robot, you",
    "start": "1752230",
    "end": "1758250"
  },
  {
    "text": "better do that intelligently. And that gives you a\nsample of the optic array.",
    "start": "1758250",
    "end": "1765150"
  },
  {
    "text": "It turns the optic array,\nthe incoming light, into a retinal image.",
    "start": "1765150",
    "end": "1770697"
  },
  {
    "text": "And on your retina, you\nhave high resolution in the middle and low\nresolution around the edges.",
    "start": "1770697",
    "end": "1775780"
  },
  {
    "text": "And so you're focusing\non particular details. And you never ever\nprocess the whole image",
    "start": "1775780",
    "end": "1783210"
  },
  {
    "text": "a uniform resolution. You're always focusing on\nsomething and processing where you're fixating at high\nresolution and everything",
    "start": "1783210",
    "end": "1789690"
  },
  {
    "text": "else at much lower resolution,\nparticularly around the edges. So I'm going to ignore\nall the complexity of how",
    "start": "1789690",
    "end": "1796500"
  },
  {
    "text": "you decide where to look and all\nthe complexity of how you put together the information you\nget from different fixations",
    "start": "1796500",
    "end": "1803280"
  },
  {
    "text": "by saying, let's just talk\nabout the very first fixation of a novel image. So you look somewhere\nand now what",
    "start": "1803280",
    "end": "1809910"
  },
  {
    "text": "happens on that first fixation? We know that the same\nhardware in the brain is going to be reused\nfor the next fixation.",
    "start": "1809910",
    "end": "1816183"
  },
  {
    "text": "But let's just think\nabout the first fixation.  So finally here's a picture\nof the architecture.",
    "start": "1816183",
    "end": "1824890"
  },
  {
    "text": "And this is the architecture\nfor a single location,",
    "start": "1824890",
    "end": "1830500"
  },
  {
    "text": "so like for a single\nword fragment in BERT. And it shows you what's\nhappening for multiple frames.",
    "start": "1830500",
    "end": "1838590"
  },
  {
    "text": "So GLOM is really\ndesigned for video, but I only talk about\napplying it to static images.",
    "start": "1838590",
    "end": "1843660"
  },
  {
    "text": "Then you should think\nof a static image as a very boring video in\nwhich the frames are all the same as each other.",
    "start": "1843660",
    "end": "1851030"
  },
  {
    "text": "So I'm showing you\nthree adjacent levels in the hierarchy.",
    "start": "1851030",
    "end": "1856480"
  },
  {
    "text": "And I'm showing you\nwhat happens over time. So if you look at\nthe middle level,",
    "start": "1856480",
    "end": "1862600"
  },
  {
    "text": "maybe that's the sort\nof major part level. And look at that box\nthat says \"level L.\"",
    "start": "1862600",
    "end": "1869370"
  },
  {
    "text": "And that's at frame four, so\nthe right hand level L box.",
    "start": "1869370",
    "end": "1875720"
  },
  {
    "text": "And let's ask how the state\nof that box-- the state of that embedding is determined. So inside the box, we're\ngoing to get an embedding.",
    "start": "1875720",
    "end": "1882570"
  },
  {
    "text": " And the embedding is going to\nbe the representation of what's",
    "start": "1882570",
    "end": "1888210"
  },
  {
    "text": "going on at the major part\nlevel for that little patch of the image. ",
    "start": "1888210",
    "end": "1895500"
  },
  {
    "text": "At level L the--\nin this diagram, all of these\nembeddings will always be devoted to the same\npatch of the retinal image.",
    "start": "1895500",
    "end": "1905760"
  },
  {
    "text": "OK. The level L embedding\non the right hand side.",
    "start": "1905760",
    "end": "1912770"
  },
  {
    "text": "You can see there's three\nthings determining it there. There's the green arrow. And for static images, the\ngreen arrow is rather boring.",
    "start": "1912770",
    "end": "1919785"
  },
  {
    "text": "It's just saying you\nshould sort of be similar to the previous\nstate of level L. So it's just doing\ntemporal integration.",
    "start": "1919785",
    "end": "1927010"
  },
  {
    "text": "The blue arrow is\nactually a neural net",
    "start": "1927010",
    "end": "1932070"
  },
  {
    "text": "with a couple of\nhidden layers in it. I'm just showing you\nthe embeddings here, not all the layers\nof the neural net.",
    "start": "1932070",
    "end": "1938065"
  },
  {
    "text": "We need a couple\nof hidden layers to do the coordinate\ntransforms that are required. And the blue arrow\nis basically taking",
    "start": "1938065",
    "end": "1945860"
  },
  {
    "text": "information of the level below\nof the previous time step. So level L minus\n1 on frame 3 might",
    "start": "1945860",
    "end": "1952909"
  },
  {
    "text": "be representing that, I\nthink, I might be a nostril. Well, if you think you\nmight be a nostril,",
    "start": "1952910",
    "end": "1958190"
  },
  {
    "text": "or you predicted\nthe next level up is a nose, what's\nmore if you have",
    "start": "1958190",
    "end": "1963620"
  },
  {
    "text": "a coordinate frame\nfor the nostril, you can predict the\ncoordinate frame for the nose. Maybe not perfectly but\nyou have a pretty good idea",
    "start": "1963620",
    "end": "1970010"
  },
  {
    "text": "of the orientation\nposition scale of the nose. So that bottom up\nneural net is a net",
    "start": "1970010",
    "end": "1978530"
  },
  {
    "text": "that can take any kind\nof part or level in mind. So it can take a nostril,\nbut it could also take a steering wheel\nand predict the car",
    "start": "1978530",
    "end": "1985490"
  },
  {
    "text": "from the steering wheel\nand predict what you've",
    "start": "1985490",
    "end": "1990850"
  },
  {
    "text": "got at the next level up. The red arrow is a\ntop down neural net.",
    "start": "1990850",
    "end": "1997850"
  },
  {
    "text": "So the red arrow is predicting\nthe nose from the whole face.",
    "start": "1997850",
    "end": "2005487"
  },
  {
    "text": "And, again, it has a\ncouple of hidden layers to do coordinate transforms. Because if you know the\ncorner frame of the face",
    "start": "2005487",
    "end": "2012210"
  },
  {
    "text": "and you know the relationship\nbetween a face and a nose, and that's going to be\nin the weights of that top down neural net.",
    "start": "2012210",
    "end": "2018420"
  },
  {
    "text": "Then you can predict\nthat it's a nose and what the pose\nof the nose is.",
    "start": "2018420",
    "end": "2023490"
  },
  {
    "text": "And that's all going to be in\nactivities in that embedding vector. OK.",
    "start": "2023490",
    "end": "2029880"
  },
  {
    "text": "All of that is what's going\non in one column of hardware. That's all about a specific\npatch of the image.",
    "start": "2029880",
    "end": "2037120"
  },
  {
    "text": "So that's very, very like\nwhat's going on for one word fragmenting BERT. You have all these\nlevels of representation.",
    "start": "2037120",
    "end": "2044040"
  },
  {
    "text": " It's a bit confusing exactly\nwhat the relation of this",
    "start": "2044040",
    "end": "2051050"
  },
  {
    "text": "is to BERT. And I'll give you the\nreference to a long Arxiv paper at the end that has\na whole section on how this relates to BERT.",
    "start": "2051050",
    "end": "2057408"
  },
  {
    "text": "But it's confusing because\nthis has time steps. And that makes it\nall more complicated.",
    "start": "2057409",
    "end": "2064540"
  },
  {
    "text": "OK. So those are three\nthings that determine the level of\nembedding, but there's",
    "start": "2064540",
    "end": "2070570"
  },
  {
    "text": "one fourth thing, which is\nin black at the bottom there.",
    "start": "2070570",
    "end": "2075730"
  },
  {
    "text": "And that's the only way in which\ndifferent locations interact. And that's a very simplified\nform of a transformer.",
    "start": "2075730",
    "end": "2083500"
  },
  {
    "text": "If you take a\ntransformer as in BERT and you say, let's make\nthe embeddings and the keys",
    "start": "2083500",
    "end": "2089560"
  },
  {
    "text": "and the queries and the values\nall be the same as each other, you just have this one vector.",
    "start": "2089560",
    "end": "2095550"
  },
  {
    "text": "So now all you're trying\nto do is make the level L embedding in one column\nbe the same as the level",
    "start": "2095550",
    "end": "2103820"
  },
  {
    "text": "L embedding in nearby columns,\nbut it's going to be gated and then you're going to\ntry and make it be the same",
    "start": "2103820",
    "end": "2110640"
  },
  {
    "text": "if it's already quite similar. ",
    "start": "2110640",
    "end": "2115690"
  },
  {
    "text": "So here's how the\nattention works. You take the level L embedding\nin location x, that's Lx.",
    "start": "2115690",
    "end": "2122930"
  },
  {
    "text": "And you take the level L\nembedding in a nearby location y, that's Ly. You take the scalar product.",
    "start": "2122930",
    "end": "2129640"
  },
  {
    "text": "You exponentiate\nand you normalize. In other words,\nyou do a softmax.",
    "start": "2129640",
    "end": "2135360"
  },
  {
    "text": "And that gives you the\nweight to use in your desire to make Lx be the same as Ly.",
    "start": "2135360",
    "end": "2145570"
  },
  {
    "text": "So the input produced by this--",
    "start": "2145570",
    "end": "2151280"
  },
  {
    "text": "from neighbors is an attention\nweighted average of the level L embeddings of nearby columns.",
    "start": "2151280",
    "end": "2157570"
  },
  {
    "text": "And that's an extra\ninput that you get. It's trying to make you\nagree with nearby things. And that's what's going\nto cause you to get",
    "start": "2157570",
    "end": "2164140"
  },
  {
    "text": "these islands of agreement. ",
    "start": "2164140",
    "end": "2170559"
  },
  {
    "text": "So back to this\npicture, I think-- ",
    "start": "2170560",
    "end": "2177280"
  },
  {
    "text": "yeah, this is what\nwe'd like to see. And the reason we get those--",
    "start": "2177280",
    "end": "2185380"
  },
  {
    "text": "that big island of agreement\nat the object level is because we're trying\nto get agreement there.",
    "start": "2185380",
    "end": "2190570"
  },
  {
    "text": "We're trying to learn\nthe coordinate transform from the red arrows to the level\nabove and from the green arrows",
    "start": "2190570",
    "end": "2197440"
  },
  {
    "text": "to the level above such\nthat we get agreement. OK. ",
    "start": "2197440",
    "end": "2205430"
  },
  {
    "text": "Now, one thing we\nneed to worry about is that the difficult\nthing in perception it's",
    "start": "2205430",
    "end": "2213040"
  },
  {
    "text": "not so bad in language. It's probably worse\nthan visual perception, is there's a lot of ambiguity.",
    "start": "2213040",
    "end": "2218589"
  },
  {
    "text": "If I'm looking at\na line drawing, for example, I see a circle. Well, the circle could be\nthe right eye of a face,",
    "start": "2218590",
    "end": "2224627"
  },
  {
    "text": "or it could be the\nleft eye of a face, or it could be the\nfront wheel of a car or the back wheel of a car. There's all sorts of things\nthat that circle could be.",
    "start": "2224627",
    "end": "2231520"
  },
  {
    "text": "And we'd like to\ndisambiguate the circle. And there's a long line\nof work using things",
    "start": "2231520",
    "end": "2238180"
  },
  {
    "text": "like Markov random fields. Here, we need a variation on\na Markov random field, which I call a \"transformational\nrandom field\"",
    "start": "2238180",
    "end": "2244359"
  },
  {
    "text": "because the interaction\nbetween, for example, something that might be\nan eye and something that",
    "start": "2244360",
    "end": "2249369"
  },
  {
    "text": "might be a mouth needs to be\ngated by corner transforms.",
    "start": "2249370",
    "end": "2254707"
  },
  {
    "text": "Let's take a nose and\na mouth because that's my standard thing. If you take something that might\nbe a nose and you want to ask,",
    "start": "2254707",
    "end": "2261050"
  },
  {
    "text": "does anybody out there\nsupport the idea of the nose? Well, what you'd like to do\nis send to everything nearby",
    "start": "2261050",
    "end": "2269050"
  },
  {
    "text": "a message saying, do\nyou have the right kind of pose and right\nkind of identity",
    "start": "2269050",
    "end": "2276640"
  },
  {
    "text": "to support the idea\nthat I am a nose? And so you'd like, for\nexample, to send out a message from the nose.",
    "start": "2276640",
    "end": "2284200"
  },
  {
    "text": "You'd send out a message to\nall nearby locations saying, does anybody have a\nmouth with the pose",
    "start": "2284200",
    "end": "2289510"
  },
  {
    "text": "that I predict by taking the\npose of the nose multiplying by the coordinate transformed\nbetween the nose and the mouth?",
    "start": "2289510",
    "end": "2295960"
  },
  {
    "text": "And now, I can predict\nthe pose of the mouth. Is there anybody out\nthere with that pose who thinks there might be a mouth?",
    "start": "2295960",
    "end": "2302130"
  },
  {
    "text": "And I think you can see you're\ngoing to have to send out a lot of different messages. For each kind of other thing\nthat might support you,",
    "start": "2302130",
    "end": "2308500"
  },
  {
    "text": "you're going to send\na different message. So you're going to need a\nmulti-headed transformer.",
    "start": "2308500",
    "end": "2315040"
  },
  {
    "text": "And it's going to be doing\nthese coordinate transforms. And you have to coordinate\ntransform the inverse transform",
    "start": "2315040",
    "end": "2320980"
  },
  {
    "text": "on the way back because\nif the mouth supports you, what it needs to\nsupport is a nose,",
    "start": "2320980",
    "end": "2326619"
  },
  {
    "text": "not with the pose of the mouth\nbut with the appropriate pose. So that's going to\nget very complicated. You're going to have n\nsquared interactions all",
    "start": "2326620",
    "end": "2333348"
  },
  {
    "text": "with coordinate transforms. There's another way\nof doing it and it's much simpler that's\ncalled a Hough transform.",
    "start": "2333348",
    "end": "2338990"
  },
  {
    "text": "At least, it's\nmuch simpler if you have a way of\nrepresenting ambiguity. ",
    "start": "2338990",
    "end": "2346050"
  },
  {
    "text": "So instead of these\ndirect interactions between parts like a nose and a\nmouth, what you're going to do",
    "start": "2346050",
    "end": "2352540"
  },
  {
    "text": "is you're going to make each\nof the parts predict the whole. So the nose can\nprotect the face,",
    "start": "2352540",
    "end": "2359910"
  },
  {
    "text": "but it can predict\nthe pose of the face. And the mouth can\nalso predict the face. Now, these will be in\ndifferent columns of GLOM.",
    "start": "2359910",
    "end": "2366750"
  },
  {
    "text": "But in one column\nof GLOM, you'll have a nose predicting a face. In a nearby column, you'll\nhave a mouth predicting a face.",
    "start": "2366750",
    "end": "2373170"
  },
  {
    "text": "And those two faces\nshould be the same if this really is a face.",
    "start": "2373170",
    "end": "2378740"
  },
  {
    "text": "So when you do this\nattention weighted averaging with nearby\nthings, what you're doing is you're getting\nconfirmation that the support",
    "start": "2378740",
    "end": "2388340"
  },
  {
    "text": "for the hypothesis you got. I mean, suppose for one\ncolumn the hypothesis is a face with this pose.",
    "start": "2388340",
    "end": "2393770"
  },
  {
    "text": "That gets supported\nby nearby columns that derive the very\nsame embedding from quite",
    "start": "2393770",
    "end": "2399890"
  },
  {
    "text": "different data. One derived it from the\nnose, and one derived it from the mouth.",
    "start": "2399890",
    "end": "2405310"
  },
  {
    "text": "And this doesn't require\nany dynamic routine because the\nembeddings are always",
    "start": "2405310",
    "end": "2410530"
  },
  {
    "text": "referring to what's going\non in the same small patch of the image. Within a column\nthere's no routing.",
    "start": "2410530",
    "end": "2416500"
  },
  {
    "text": "And between columns, there's\nsomething a bit like routing, but it's just the standard\ntransformer kind of attention.",
    "start": "2416500",
    "end": "2422780"
  },
  {
    "text": "You're just trying to agree\nwith things that are similar. ",
    "start": "2422780",
    "end": "2428910"
  },
  {
    "text": "OK, so that's how GLOM\nwas meant to work. And the big problem is--",
    "start": "2428910",
    "end": "2435190"
  },
  {
    "text": "that if I see a circle,\nit might be a left eye, or it might be a right eye. It might be a front\nwheel of the car",
    "start": "2435190",
    "end": "2440605"
  },
  {
    "text": "or it might be the\nback wheel of a car. Because my embedding\nfor a particular patch at a particular level has to\nbe able to represent anything,",
    "start": "2440605",
    "end": "2447490"
  },
  {
    "text": "when I get an\nambiguous thing, I have to deal with all these\npossibilities of what whole it might be part of.",
    "start": "2447490",
    "end": "2454180"
  },
  {
    "text": "So instead of trying\nto resolve ambiguity at the part level, what I can\ndo is jump to the next level up",
    "start": "2454180",
    "end": "2459460"
  },
  {
    "text": "and resolve the ambiguity\nthere just by seeing if things are the same, which is an\neasier way to resolve ambiguity.",
    "start": "2459460",
    "end": "2465610"
  },
  {
    "text": "But the cost of\nthat is I have to be able to represent\nall the ambiguity I get at the next level up.",
    "start": "2465610",
    "end": "2473190"
  },
  {
    "text": "Now, it turns out\nyou can do that. We've done a little toy\nexample where you can actually",
    "start": "2473190",
    "end": "2479099"
  },
  {
    "text": "preserve this ambiguity,\nbut it's difficult. It's the kind of thing\nneural nets are good at.",
    "start": "2479100",
    "end": "2486700"
  },
  {
    "text": "So if you think about the\nembedding of the next level up, you got a whole bunch of\nneurons whose activities",
    "start": "2486700",
    "end": "2494339"
  },
  {
    "text": "are that embedding. And you want to represent a\nhighly multimodal distribution,",
    "start": "2494340",
    "end": "2500122"
  },
  {
    "text": "like, it might be a car\nwith this pose or a car with that pose or a face with\nthis pose or a face with that pose.",
    "start": "2500122",
    "end": "2505410"
  },
  {
    "text": "All of these are\npossible predictions for finding a circle. And so you have to\nrepresent all that.",
    "start": "2505410",
    "end": "2512640"
  },
  {
    "text": "And the question is,\ncan neural nets do that? But I think the way\nthey must be doing it is each neuron\nin the embedding",
    "start": "2512640",
    "end": "2521320"
  },
  {
    "text": "stands for an unnormalized\nlog probability distribution over this huge\nspace of possible identities",
    "start": "2521320",
    "end": "2528010"
  },
  {
    "text": "and possible poses, the sort\nof cross product of identities and poses. ",
    "start": "2528010",
    "end": "2534220"
  },
  {
    "text": "And so the neuron is this\nrather vague log probability distribution over that space.",
    "start": "2534220",
    "end": "2540270"
  },
  {
    "text": "And when you activate the\nneuron, what it's saying is add in that log\nprobability distribution",
    "start": "2540270",
    "end": "2545780"
  },
  {
    "text": "to what you've already got. And so now if you have a\nwhole bunch of log probability distributions and you\nadd them all together,",
    "start": "2545780",
    "end": "2553950"
  },
  {
    "text": "you can get a much more peaky\nlog probability distribution. And when you exponentiate, you\nget a probability distribution.",
    "start": "2553950",
    "end": "2561260"
  },
  {
    "text": "It gets very peaky\nand so very vague basis functions in this joint\nspace of pose and identity",
    "start": "2561260",
    "end": "2570230"
  },
  {
    "text": "and basis functions. And the log probability\nin that space can be combined to\nproduce sharp conclusions.",
    "start": "2570230",
    "end": "2578460"
  },
  {
    "text": "So I think that's how neurons\nare representing things. Most people think\nabout neurons as--",
    "start": "2578460",
    "end": "2584870"
  },
  {
    "text": "they think about the thing\nthat they're representing but obviously in perception you\nhave to deal with uncertainty.",
    "start": "2584870",
    "end": "2592980"
  },
  {
    "text": "And so neurons have to\nbe good at representing multimodal distributions.",
    "start": "2592980",
    "end": "2598680"
  },
  {
    "text": "And this is the\nonly way I can think of that's good at doing it. That's a rather weak argument.",
    "start": "2598680",
    "end": "2605177"
  },
  {
    "text": "But it's the argument\nthat led Chomsky to believe that language wasn't\nlearned because he couldn't think of how it was learned.",
    "start": "2605177",
    "end": "2611980"
  },
  {
    "text": "My view is neurons must be using\nthis representation because I can't think of any\nother way of doing it. ",
    "start": "2611980",
    "end": "2620350"
  },
  {
    "text": "OK, I just said all that\nbecause I got ahead of myself because I got excited. ",
    "start": "2620350",
    "end": "2628505"
  },
  {
    "text": "Now, the reason you can get away\nwith this, the reason you have these very vague distributions\nin the unnormalized log",
    "start": "2628505",
    "end": "2633799"
  },
  {
    "text": "probability space is because\nthese neurons are all dedicated to a small\npatch of image,",
    "start": "2633800",
    "end": "2640760"
  },
  {
    "text": "and they're all\ntrying to represent the thing that's happening\nin that patch of image. So you're only trying\nto represent one thing.",
    "start": "2640760",
    "end": "2647690"
  },
  {
    "text": "You're not trying to represent\nsome set of possible objects. If you're trying to represent\nsome set of possible objects,",
    "start": "2647690",
    "end": "2653270"
  },
  {
    "text": "you have a horrible\nbinding problem, and you couldn't use these\nvery vague distributions. But so long as you know\nthat, all of these neurons,",
    "start": "2653270",
    "end": "2660890"
  },
  {
    "text": "all of the active neurons\nrefer to the same thing. Then you can do\nthe intersection.",
    "start": "2660890",
    "end": "2666710"
  },
  {
    "text": "You can add the log probability\ndistributions together and intersect the sets\nof things they represent. ",
    "start": "2666710",
    "end": "2674280"
  },
  {
    "text": "OK. I'm getting near the end. How would you train\na system like this? Well, obviously, you could\ntrain it the way you train BERT.",
    "start": "2674280",
    "end": "2681630"
  },
  {
    "text": "You could do deep\nend-to-end training. And for GLOM, what\nthat will consist of",
    "start": "2681630",
    "end": "2688859"
  },
  {
    "text": "and the way we trained the toy\nexample is you take an image.",
    "start": "2688860",
    "end": "2695700"
  },
  {
    "text": "You leave out some\npatches of the image. You then let GLOM settle\ndown for about 10 iterations.",
    "start": "2695700",
    "end": "2704890"
  },
  {
    "text": "And it's trying to fill\nin the lowest level representation of what's in\nthe image, the lowest level",
    "start": "2704890",
    "end": "2713130"
  },
  {
    "text": "embeddings. And it fills them in wrong. And so you now back\npropagate that error.",
    "start": "2713130",
    "end": "2719333"
  },
  {
    "text": "When you're back\npropagating, it's through time in this network. So it will also back propagate\nup and down through the levels.",
    "start": "2719333",
    "end": "2726892"
  },
  {
    "text": "So you're basically just\ndoing back propagation through time of the error due to\nfilling in things incorrectly.",
    "start": "2726892",
    "end": "2734220"
  },
  {
    "text": "That's basically\nhow BERT is trained. And you could train\nGLOM the same way.",
    "start": "2734220",
    "end": "2739570"
  },
  {
    "text": "But I also want to include\nan extra bit in the training to encourage islands. ",
    "start": "2739570",
    "end": "2747619"
  },
  {
    "text": "We want to encourage big\nislands of identical vectors",
    "start": "2747620",
    "end": "2752810"
  },
  {
    "text": "at high levels. And you can do that by\nusing constrastive learning.",
    "start": "2752810",
    "end": "2758230"
  },
  {
    "text": "So if you think how at\nthe next time step--",
    "start": "2758230",
    "end": "2764700"
  },
  {
    "text": "if you think how an\nembedding is determined, it's determined by combining\na whole bunch of different",
    "start": "2764700",
    "end": "2771599"
  },
  {
    "text": "factors-- what was going on\nin the previous time step at this level\nof representation",
    "start": "2771600",
    "end": "2776970"
  },
  {
    "text": "in this location,\nwhat was going on at the the previous time\nstep in this location",
    "start": "2776970",
    "end": "2782520"
  },
  {
    "text": "but at the next level\ndown or the next level up, and also what was going\non at the previous time",
    "start": "2782520",
    "end": "2788820"
  },
  {
    "text": "step at nearby locations\nat the same level. And the weighted average\nof all those things",
    "start": "2788820",
    "end": "2796182"
  },
  {
    "text": "are called a\n\"consensus\" embedding. And that's what you use\nfor the next embedding. And I think you can see that.",
    "start": "2796182",
    "end": "2802400"
  },
  {
    "text": "If we try to make the\nbottom up neural net or the top down\nneural net, if we try to make the predictions\nagree with the consensus,",
    "start": "2802400",
    "end": "2810900"
  },
  {
    "text": "the consensus has\nfolded in information from nearby locations that\nalready roughly agree because",
    "start": "2810900",
    "end": "2819000"
  },
  {
    "text": "of the attention weighting. And so by trying to\nmake the top down and bottom up neural networks\nagree with the consensus,",
    "start": "2819000",
    "end": "2825890"
  },
  {
    "text": "you're trying to make\nthem agree with what's going on in nearby\nlocations that are similar, and so you'll be training\nit to form islands.",
    "start": "2825890",
    "end": "2832475"
  },
  {
    "start": "2832475",
    "end": "2837750"
  },
  {
    "text": "This is more interesting\nto neuroscientists than to people of\nyour natural language, so I'm going to ignore that.",
    "start": "2837750",
    "end": "2845270"
  },
  {
    "text": "You might think\nit's wasteful to be replicating all these\nembeddings at the object level.",
    "start": "2845270",
    "end": "2851494"
  },
  {
    "text": "So the idea is at\nthe the object level there would be a large\nnumber of patches that all have exactly the\nsame vector representation.",
    "start": "2851494",
    "end": "2858150"
  },
  {
    "text": "And that seemed like a waste. But actually biology is\nfull of things like that. All your cells have\nexactly the same DNA.",
    "start": "2858150",
    "end": "2864540"
  },
  {
    "text": "And all the parts\nof an organ have pretty much the same vector\nof protein expressions.",
    "start": "2864540",
    "end": "2869790"
  },
  {
    "text": "So there's lots of\nreplication that goes on to keep things local.",
    "start": "2869790",
    "end": "2875252"
  },
  {
    "text": "And it's the same here. And actually that\nreplication is very useful when you're settling\non an interpretation.",
    "start": "2875252",
    "end": "2881790"
  },
  {
    "text": "Because before you\nsettle down, you don't know which things\nshould be the same as which other things.",
    "start": "2881790",
    "end": "2886839"
  },
  {
    "text": "So having separate\nvectors in each location to represent what's going\non there at the object level gives you the flexibility to\ngradually segment things as you",
    "start": "2886840",
    "end": "2894030"
  },
  {
    "text": "settle down in a sensible way. It allows you to\nhedge your bets.",
    "start": "2894030",
    "end": "2899680"
  },
  {
    "text": "And what you're doing is\nnot quite like clustering. You're creating clusters\nof identical vectors",
    "start": "2899680",
    "end": "2905410"
  },
  {
    "text": "rather than discovering\nclusters in fixed data. So clustering, you're given\nthe data, and it's fixed,",
    "start": "2905410",
    "end": "2910747"
  },
  {
    "text": "and you find the clusters. Here, the embeddings at every\nlevel they vary over time.",
    "start": "2910747",
    "end": "2918040"
  },
  {
    "text": "They're determined by the\ntop down and bottom up inputs and by inputs coming\nfrom nearby locations. So what you're doing\nis forming clusters",
    "start": "2918040",
    "end": "2924910"
  },
  {
    "text": "rather than discovering\nthem in fixed data. And that's got a\nsomewhat different flavor and can settle down faster.",
    "start": "2924910",
    "end": "2931119"
  },
  {
    "text": " And one other advantage\nof this replication",
    "start": "2931120",
    "end": "2938359"
  },
  {
    "text": "is what you don't\nwant is to have much more work in\nyour transformer",
    "start": "2938360",
    "end": "2943640"
  },
  {
    "text": "as you go to higher levels. But you do need longer range\ninteractions at higher levels.",
    "start": "2943640",
    "end": "2948985"
  },
  {
    "text": "Presumably for\nthe lowest levels, you want fairly\nshort-range interactions in your transformer. And they could be dense.",
    "start": "2948985",
    "end": "2954583"
  },
  {
    "text": "As you go to high levels,\nyou want much longer range interactions so you\ncould make them sparse.",
    "start": "2954583",
    "end": "2960290"
  },
  {
    "text": "And people have done things\nlike that for BERT like systems.",
    "start": "2960290",
    "end": "2965810"
  },
  {
    "text": "Here, it's easy to make\nthem sparse because you're expecting big islands. So all you need to do is see\none patch of a big island",
    "start": "2965810",
    "end": "2974870"
  },
  {
    "text": "to know what the vector\nrepresentation of that island is. And so sparse\nrepresentations will work much better if you have\nthese big islands of agreement",
    "start": "2974870",
    "end": "2982250"
  },
  {
    "text": "as you go up. So the idea is you have\nlonger range and sparser connections as you go up. So the amount of computation\nis the same at every level.",
    "start": "2982250",
    "end": "2990440"
  },
  {
    "text": "And just to summarize,\nI showed how to combine three important\nadvances of neural networks",
    "start": "2990440",
    "end": "2997550"
  },
  {
    "text": "in GLOM. I didn't actually talk\nabout neural fields. And that's important for\nthe top down network.",
    "start": "2997550",
    "end": "3004050"
  },
  {
    "text": "Maybe since I've got\ntwo minutes to spare, I'm going to go back and mention\nneural fields very briefly. ",
    "start": "3004050",
    "end": "3013770"
  },
  {
    "text": "Yeah, when I trained that\ntop down neural network-- and I have a problem.",
    "start": "3013770",
    "end": "3018790"
  },
  {
    "text": "And the problem is if you\nlook at those red arrows and those green arrows,\nthey're quite different.",
    "start": "3018790",
    "end": "3028060"
  },
  {
    "text": "But if you look at the level\nabove the object level, all those vectors are the same.",
    "start": "3028060",
    "end": "3034390"
  },
  {
    "text": "And, of course, in\nan engineered system, I want to replicate the\nneural nets in every location.",
    "start": "3034390",
    "end": "3039610"
  },
  {
    "text": "So I use exactly the same top\ndown and bottom up neural nets everywhere. And so the question is,\nhow can the same neural net",
    "start": "3039610",
    "end": "3047040"
  },
  {
    "text": "be given a black arrow and\nsometimes produce a red arrow and sometimes produce a\ngreen arrow, which have",
    "start": "3047040",
    "end": "3052650"
  },
  {
    "text": "quite different orientations? How can it produce\na nose where there's a nose and a mouth where there's\na mouth even though the face",
    "start": "3052650",
    "end": "3060329"
  },
  {
    "text": "vector is the same everywhere? And the answer is the top down\nneural network doesn't just",
    "start": "3060330",
    "end": "3066329"
  },
  {
    "text": "get the face vector. It also gets the location\nof the patch, which",
    "start": "3066330",
    "end": "3072720"
  },
  {
    "text": "is producing the power vector. So the three patches\nthat should get the red vector are\ndifferent from three--",
    "start": "3072720",
    "end": "3079428"
  },
  {
    "text": "have different locations\nfrom the three patches that should get\nthe green vector. So if I use the\nneural network and I",
    "start": "3079428",
    "end": "3085232"
  },
  {
    "text": "guess the location as input as\nwell, here's what it can do. It can take the pose, that's\nencoded in that black vector,",
    "start": "3085232",
    "end": "3092030"
  },
  {
    "text": "the pose of the face. It can take the location in the\nimage for which it's predicting",
    "start": "3092030",
    "end": "3099390"
  },
  {
    "text": "the vector of the level below. And the pose is relative\nto the image too. So knowing the\nlocation in the image",
    "start": "3099390",
    "end": "3105650"
  },
  {
    "text": "and knowing the poses\nof the whole face, it can figure out which\nbit of the face it needs to predict\nat that location.",
    "start": "3105650",
    "end": "3112993"
  },
  {
    "text": "And so in one location,\nyou can predict, OK, there should be nose\nthere, and it gives you the right vector. In another location, it can\npredict from where that image",
    "start": "3112993",
    "end": "3120840"
  },
  {
    "text": "patch is there should\nbe a nose there, so it can give you\nthe green arrow. So you can get the same\nvector at the level",
    "start": "3120840",
    "end": "3126609"
  },
  {
    "text": "above to predict\ndifferent vectors in different places of the\nlevel below by giving it the place that it's\npredicting for.",
    "start": "3126610",
    "end": "3132057"
  },
  {
    "text": "And that's what's going\non in neural fields. ",
    "start": "3132057",
    "end": "3141230"
  },
  {
    "text": "OK, now, this was quite\na complicated talk. There's a long paper\nabout it on Arxiv that goes into much more detail.",
    "start": "3141230",
    "end": "3148270"
  },
  {
    "text": "And you could view this talk\nas just an encouragement to read that paper. And I'm done, exactly on time.",
    "start": "3148270",
    "end": "3154750"
  },
  {
    "text": " Thank you.",
    "start": "3154750",
    "end": "3159950"
  },
  {
    "text": "[INTERPOSING VOICES] Thanks a lot. Yeah. ",
    "start": "3159950",
    "end": "3168000"
  }
]
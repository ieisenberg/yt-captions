[
  {
    "text": "[MUSIC]\nAndrew Ng: Hi, I'm delighted to be here\nwith my old friend and collaborator, Professor Chris Manning.",
    "start": "7429",
    "end": "12720"
  },
  {
    "text": "Chris has a very long and\nimpressive bio but just briefly, he is Professor of Computer Science\nat Stanford University and",
    "start": "12720",
    "end": "19255"
  },
  {
    "text": "also the director of the Stanford AI lab. And he also has the distinction of being\nthe most highly cited researcher in NLP or",
    "start": "19255",
    "end": "26603"
  },
  {
    "text": "natural language processing. So, really good to be here with you,\nChris. Chris Manning: Good to get a chance to chat Andrew.",
    "start": "26603",
    "end": "33479"
  },
  {
    "text": "Andrew Ng: So we've known each other\ncollaborated for many years and one interesting part of your background I\nalways thought was that even though today",
    "start": "33479",
    "end": "41493"
  },
  {
    "text": "you're distinguished researcher\nin machine learning in NLP, you actually started off\nin a very different area.",
    "start": "41493",
    "end": "48060"
  },
  {
    "text": "Your PhD if I remember correctly\nwas in linguistics and you were studying the syntax of language.",
    "start": "48060",
    "end": "55419"
  },
  {
    "text": "So how did you go from studying\nsyntax to being an NLP researcher?",
    "start": "55419",
    "end": "60620"
  },
  {
    "text": "Chris Manning: So I can certainly tell you about that,\nbut I should also point out that I'm still actually a professor of\nlinguistics as well.",
    "start": "60620",
    "end": "67080"
  },
  {
    "text": "I have a joint appointment at Stanford. And once in a blue moon not very often,\nI do actually still teach some real",
    "start": "67080",
    "end": "73715"
  },
  {
    "text": "linguistics as well as computer\ninvolved natural language processing. So starting out, I was very\ninterested in human languages and",
    "start": "73715",
    "end": "84348"
  },
  {
    "text": "how they work, how people understand them, how they're acquired.",
    "start": "84348",
    "end": "92229"
  },
  {
    "text": "So I saw this appeal in human languages.",
    "start": "92230",
    "end": "98169"
  },
  {
    "text": "But that equally led me to think\nabout ideas that we now very",
    "start": "98169",
    "end": "103341"
  },
  {
    "text": "much think about as machine learning or\ncomputational ideas.",
    "start": "103342",
    "end": "108959"
  },
  {
    "text": "So two of the central\nideas in human language, how do little children\nacquire human language?",
    "start": "108959",
    "end": "117159"
  },
  {
    "text": "And for adults, well,\nwe're just talking to each other now and we pretty much understand each other.",
    "start": "117160",
    "end": "122690"
  },
  {
    "text": "And that's actually an amazing thing,\nhow we manage to do that. So what kind of processing allows that?",
    "start": "122690",
    "end": "128250"
  },
  {
    "text": "And so that early on got me interested\nin looking at machine learning. In fact, even before I'd made it to\ngrad school, I started baby steps and",
    "start": "128250",
    "end": "137816"
  },
  {
    "text": "learning machine learning\ncoming off of those interests. Andrew Ng: That all human language has learned,",
    "start": "137816",
    "end": "143444"
  },
  {
    "text": "we had learned at some point in\nthe lives to speak English and we grown up in a different place, we would\nhave learned a totally different language.",
    "start": "143445",
    "end": "150418"
  },
  {
    "text": "So is amazing to think how humans do that\nand now maybe machines learn language too.",
    "start": "150419",
    "end": "156169"
  },
  {
    "text": "But so\njust tell us more about your journey. So you had a PhD in linguistics and\nthen how did you?",
    "start": "156169",
    "end": "165269"
  },
  {
    "text": "Chris Manning: So\nthere's some stuff before that as well. So I mean when I was an undergrad, well,\nofficially I actually did three majors.",
    "start": "165269",
    "end": "173495"
  },
  {
    "text": "This was in Australia, one in math, one in\ncomputer science and one in linguistics.",
    "start": "173495",
    "end": "178806"
  },
  {
    "text": "Now people get a slightly exaggerated\nsense of what that means if you're in an American context because it'd be I\nthink impossible to complete three majors,",
    "start": "178807",
    "end": "189264"
  },
  {
    "text": "as an undergrad at Stanford. But actually where I was as an undergrad\ndoing, I did an arts degree so",
    "start": "189264",
    "end": "195333"
  },
  {
    "text": "I could do whatever I\nwanted like linguistics, you had to complete two majors\nto complete the arts degree.",
    "start": "195333",
    "end": "201809"
  },
  {
    "text": "So it was sort of more like double\nmajoring maybe in US terms. Andrew Ng: You probably don't know\nthis about me but at Carnegie Mellon,",
    "start": "201809",
    "end": "208922"
  },
  {
    "text": "I actually was a triple major, Math CS was\none and then statistics and economics.",
    "start": "208922",
    "end": "213940"
  },
  {
    "text": "Okay, we both fellow triple majors. Chris Manning: Yeah, so anyway,\nI did have background and",
    "start": "213940",
    "end": "219919"
  },
  {
    "text": "interest in doing things\nwith computer science. And so my interests were kind of mixed and\nI mean actually,",
    "start": "219919",
    "end": "226866"
  },
  {
    "text": "when I applied to grad schools,\nI mean one of the places I applied to was Carnegie Mellon because they were\nstrong in computational linguistics.",
    "start": "226866",
    "end": "235799"
  },
  {
    "text": "And if I'd gone there I would have\nbeen enrolled as a CS student but I ended up at Stanford as a linguistics\nstudent because at that time,",
    "start": "235800",
    "end": "243957"
  },
  {
    "text": "there wasn't any natural language\nprocessing in the CS Department. But I was still interested in pursuing\nideas in natural language processing.",
    "start": "243957",
    "end": "254285"
  },
  {
    "text": "But at that point in the early nineties,\nthings were just starting to change.",
    "start": "254285",
    "end": "260903"
  },
  {
    "text": "But the bulk of natural\nlanguage processing was rule based logical declarative systems.",
    "start": "260904",
    "end": "269769"
  },
  {
    "text": "But it was also in those years at\nthe beginning of the nineties, when they first started to be lots\nof human language material, text and",
    "start": "269769",
    "end": "278417"
  },
  {
    "text": "speech available digitally. So this was really actually just\nbefore the world wide web exploded.",
    "start": "278417",
    "end": "283988"
  },
  {
    "text": "But they already started to be\nthings like legal materials and newspaper articles and parliamentary\nhansards where you could at last",
    "start": "283989",
    "end": "293266"
  },
  {
    "text": "get your hands on millions\nof words of human language. And it just seemed really clear that there\nhad to be exciting things that you could",
    "start": "293266",
    "end": "301913"
  },
  {
    "text": "do by working empirically\nfrom lots of human language. And that's what really sort of\ngot me involved in a new kind of",
    "start": "301913",
    "end": "309017"
  },
  {
    "text": "natural language processing that\nthen led into my subsequent career. Andrew Ng: It sounds like your career was\ninitially more linguistics and",
    "start": "309017",
    "end": "317760"
  },
  {
    "text": "of the rise of data and\nmachine learning and empirical methods it shifted to what\nNLP and machine learning and NLP.",
    "start": "317760",
    "end": "324799"
  },
  {
    "text": "Chris Manning: Yeah, I mean it absolutely certainly\nshifted and I've certainly sort of shifted",
    "start": "324799",
    "end": "329979"
  },
  {
    "text": "much more to doing both natural language\nprocessing and machine learning models.",
    "start": "329979",
    "end": "335260"
  },
  {
    "text": "But to some extent,\nthe balance has varied. But I've sort of been with that as\na while, actually as an undergrad for",
    "start": "335260",
    "end": "344567"
  },
  {
    "text": "my undergrad on the thesis, it was\nsort of learning the forms of words.",
    "start": "344567",
    "end": "350319"
  },
  {
    "text": "So how you can which became a famous\nproblem of sort of learning past tense of English verbs and\nthe early connection literature.",
    "start": "350320",
    "end": "358570"
  },
  {
    "text": "And I was trying to sort of learn\nparadigms of forms of verbs. And I was learning rules for",
    "start": "358570",
    "end": "364678"
  },
  {
    "text": "the different forms using the C 4.5\ndecision tree learning algorithm.",
    "start": "364678",
    "end": "370105"
  },
  {
    "text": "[LAUGH] If you remember that. Andrew Ng: Yeah right, good times. Yeah and\nit's surprisingly non-intuitive, right?",
    "start": "370105",
    "end": "377529"
  },
  {
    "text": "How going from present tense to\npast tense from I don't know to and",
    "start": "377529",
    "end": "382668"
  },
  {
    "text": "all the other special cases can be. Chris Manning: Yeah. Andrew Ng: Yeah, so we talked a bunch about\nNLP natural language processing.",
    "start": "382668",
    "end": "391238"
  },
  {
    "text": "So for some of the learners\npick up machine learning for the first time, can you say what is NLP?",
    "start": "391239",
    "end": "398669"
  },
  {
    "text": "Chris Manning: Sure, absolutely, yeah. So NLP stands for natural language\nprocessing another word that's or",
    "start": "398670",
    "end": "403946"
  },
  {
    "text": "term that's sometimes used for\nthat is computational linguistics, it's the same thing.",
    "start": "403946",
    "end": "408975"
  },
  {
    "text": "I mean natural language processing\nis actually a weird term, right? So it means that we're doing\nthings with human languages.",
    "start": "408976",
    "end": "416217"
  },
  {
    "text": "So you have to have the conception that\nyou're enough of a computer scientist that when you say language, you think in\nyour brain programming language.",
    "start": "416217",
    "end": "423572"
  },
  {
    "text": "And therefore you need to say\nnatural language to mean that you're talking about the language\nimages that human beings use.",
    "start": "423572",
    "end": "429574"
  },
  {
    "text": "So overall natural language processing\nis doing anything intelligent with human languages.",
    "start": "429574",
    "end": "435713"
  },
  {
    "text": "So in one sense that breaks down\ninto understanding human languages, producing human languages,\nacquiring human languages,",
    "start": "435713",
    "end": "444364"
  },
  {
    "text": "though people also often think about\nit in terms of different applications.",
    "start": "444364",
    "end": "449553"
  },
  {
    "text": "And so then you might think about\nthings like machine translation or",
    "start": "449553",
    "end": "455287"
  },
  {
    "text": "doing question answering or generating\nadvertising copy or summarization.",
    "start": "455287",
    "end": "461935"
  },
  {
    "text": "There are so many different tasks\nthat people work on with particular goals in mind where you do\nthings with human language.",
    "start": "461936",
    "end": "469302"
  },
  {
    "text": "And there's a lot of natural\nlanguage processing because so much of what the world works on\nour human world is dealt with and",
    "start": "469302",
    "end": "477965"
  },
  {
    "text": "transmitted in terms of\nhuman language material. Andrew Ng: So, because of all of these\napplications or even web search, right?",
    "start": "477965",
    "end": "486754"
  },
  {
    "text": "Most of us use NLP. Chris Manning: Yeah, right. Andrew Ng: Many, many times a day.\nChris Manning: You're right, in some sense,",
    "start": "486754",
    "end": "491857"
  },
  {
    "text": "the biggest application of natural\nlanguage is web search, right? [LAUGH] And\nthat's really the the big one, I mean,",
    "start": "491857",
    "end": "499117"
  },
  {
    "text": "traditionally, it was a kind\nof a simple one, right? That in the good old days, it was, you\nknow, there were various waiting factors",
    "start": "499117",
    "end": "507308"
  },
  {
    "text": "and so on, but\nit was mainly sort of matching keywords, then your search terms and then some\nfactors about the quality of the page.",
    "start": "507308",
    "end": "515101"
  },
  {
    "text": "It didn't really feel like\nlanguage understanding, but that's really been\nchanging over the years.",
    "start": "515101",
    "end": "520361"
  },
  {
    "text": "So these days, you'll often,\nif you ask a question to a search engine, it will give you an answer box where\nit has extracted a piece of text and",
    "start": "520361",
    "end": "530000"
  },
  {
    "text": "puts what it thinks is the answer in\nbold or color or something like that. Which is then this task\nof question answering and",
    "start": "530000",
    "end": "537489"
  },
  {
    "text": "then it's really a natural\nlanguage understanding task. Andrew Ng: Yeah, yeah, and I feel like in addition\nto web searches, maybe the big one,",
    "start": "537489",
    "end": "545409"
  },
  {
    "text": "even when we're going to a online\nshopping website or a movie website and typing in what we want and",
    "start": "545409",
    "end": "551485"
  },
  {
    "text": "doing a website search on a much smaller\nwebsite than the big search engines. That also increasingly uses\nsophisticated NLP algorithms, and",
    "start": "551485",
    "end": "560354"
  },
  {
    "text": "it is also creating quite a lot of value. Maybe to you is not the real NLP,\nbut it still seems very valuable.",
    "start": "560354",
    "end": "567666"
  },
  {
    "text": "Chris Manning: I agree, it's very valuable. And there are lots of interesting problems\nin any e-commerce website with search, very",
    "start": "567666",
    "end": "574432"
  },
  {
    "text": "difficult problems actually when people\ndescribe the kind of goods they want.",
    "start": "574432",
    "end": "579582"
  },
  {
    "text": "And you need to be trying to match\nit to products that are available, that isn't an easy problem at all,\nit turns out.",
    "start": "579582",
    "end": "585336"
  },
  {
    "text": "Andrew Ng: Yeah, that's true, yeah. So over the last, I don't know,\ncouple of decades,",
    "start": "585336",
    "end": "590842"
  },
  {
    "text": "NLP has gone through a major shift from\nmore of the rule based techniques that",
    "start": "590843",
    "end": "595964"
  },
  {
    "text": "you alluded to just now to using really\nmachine learning much more pervasively.",
    "start": "595964",
    "end": "601425"
  },
  {
    "text": "And so you were one of the people\nthat leading parts of that charge and seeing every step of the way, you're\ncreating some of the stems as it happened,",
    "start": "601426",
    "end": "611392"
  },
  {
    "text": "can you say a bit about that process and\nwhat you saw? Chris Manning: Sure, absolutely. Yeah, so when I started off as\nan undergrad and grad student,",
    "start": "611392",
    "end": "621339"
  },
  {
    "text": "really most of natural language\nprocessing was done by hand built",
    "start": "621340",
    "end": "626906"
  },
  {
    "text": "systems which variously used rules and\ninference procedures to sort of try and",
    "start": "626906",
    "end": "633584"
  },
  {
    "text": "build up a paths and\nan understanding of a piece of text. Andrew Ng: What's an example of a rule or\ninference system?",
    "start": "633584",
    "end": "641902"
  },
  {
    "text": "Chris Manning: So, a rule could be part of\nthe structure of human language. Like English sentence normally\nconsists of a subject noun phrase,",
    "start": "641902",
    "end": "651399"
  },
  {
    "text": "followed by a verb and\nan object noun phrase. And that gives you some idea as to how to\nunderstand the meaning of the sentence.",
    "start": "651399",
    "end": "659738"
  },
  {
    "text": "But it might also be saying something\nabout how to interpret a word so",
    "start": "659739",
    "end": "665924"
  },
  {
    "text": "that a lot of words in\nEnglish are very ambiguous. But if you have something like the word\nstar and it's in the context of a movie,",
    "start": "665924",
    "end": "676199"
  },
  {
    "text": "then it's probably referring to a human\nbeing not an astronomical object.",
    "start": "676200",
    "end": "681855"
  },
  {
    "text": "And in those days people tried to\ndeal with things like that using rules of that sort.",
    "start": "681855",
    "end": "688183"
  },
  {
    "text": "That doesn't seem very likely\nto work to us these days, but, once upon a time that was pretty standard.",
    "start": "688183",
    "end": "696651"
  },
  {
    "text": "And so it was only when lots of digital\ntext and speech started to become",
    "start": "696651",
    "end": "701693"
  },
  {
    "text": "available that it really seemed like\nthere was this different way that",
    "start": "701693",
    "end": "706735"
  },
  {
    "text": "instead we could start calculating\nstatistics over human language,",
    "start": "706735",
    "end": "711777"
  },
  {
    "text": "material and\nbuilding machine learning models. And so\nthat was the first thing that I got into,",
    "start": "711777",
    "end": "720974"
  },
  {
    "text": "in the sort of mid to late 1990s. And so the first area where I\nstarted doing lots of research and",
    "start": "720974",
    "end": "729356"
  },
  {
    "text": "publishing papers and getting well known\nis building what in the early days, we often called statistical\nnatural language processing.",
    "start": "729356",
    "end": "738182"
  },
  {
    "text": "But it later merged into in general prob\napproaches to artificial intelligence and",
    "start": "738182",
    "end": "743456"
  },
  {
    "text": "machine learning. And that sort of took us through\nto approximately 2010, let's say.",
    "start": "743456",
    "end": "750766"
  },
  {
    "text": "And that's roughly when the new\ninterest in deep learning",
    "start": "750766",
    "end": "755893"
  },
  {
    "text": "using large artificial neural\nnetworks started to take off.",
    "start": "755893",
    "end": "761345"
  },
  {
    "text": "For my interest in that I really have you\nto thank Andrew because at this stage,",
    "start": "761345",
    "end": "766589"
  },
  {
    "text": "Andrew is still full time at Stanford and he was in the office next door to me and\nhe was really excited about the new",
    "start": "766590",
    "end": "774059"
  },
  {
    "text": "things that were happening in\nthe area of deep learning, I guess. Anyone who walked into his office,\nhe'd tell them, oh it's so exciting",
    "start": "774059",
    "end": "782383"
  },
  {
    "text": "what's happening now in neural networks, you have to start looking at that. And so that was really\nthe impetus that got me pretty",
    "start": "782383",
    "end": "791396"
  },
  {
    "text": "early on involved in looking\nat things in neural networks.",
    "start": "791396",
    "end": "797270"
  },
  {
    "text": "I had actually seen a bit of it before, so\nwhile I was a grad student here, actually, David Rumelhart was at Stanford in Psych\nand I'd taken his neural networks class.",
    "start": "797270",
    "end": "807205"
  },
  {
    "text": "And so, I'd seen some of that, but it hadn't actually really been what\nI'd gotten into for my own research.",
    "start": "807205",
    "end": "814914"
  },
  {
    "text": "So-\nAndrew Ng: I didn't know that, thank you, yeah. Chris Manning: Yeah. Andrew Ng: And then we wound up supervising\nsome students together.",
    "start": "814914",
    "end": "823458"
  },
  {
    "text": "Chris Manning: Yeah, absolutely. Andrew Ng: I'd love to hear the rise\nof also deep learning and NLP, what did you see since\nyou were in the field?",
    "start": "823458",
    "end": "829537"
  },
  {
    "text": "Chris Manning: Yeah, so starting about 2010, yeah, me, students, started to do\nthe first papers in",
    "start": "829537",
    "end": "838559"
  },
  {
    "text": "deep learning aimed at NLP conferences. It's always hard when you're\ntrying to do something new.",
    "start": "838559",
    "end": "844801"
  },
  {
    "text": "We had exactly the same experiences\nthat people 15 or so years earlier had had when they start trying to do\nstatistical NLP of when there's",
    "start": "844801",
    "end": "853730"
  },
  {
    "text": "an established way of doing things,\nit's really hard to push out new ideas.",
    "start": "853731",
    "end": "858748"
  },
  {
    "text": "So really some of our first papers\nwere rejected from conferences and instead appeared at machine\nlearning conferences or",
    "start": "858748",
    "end": "867065"
  },
  {
    "text": "deep learning workshops, but\nvery quickly that started to change and people got super interested\nin neural network ideas.",
    "start": "867065",
    "end": "875563"
  },
  {
    "text": "But I sort of feel like the neural\nnetwork period which sort of started",
    "start": "875563",
    "end": "880842"
  },
  {
    "text": "effectively about 2010,\nit's self divides in two because for",
    "start": "880842",
    "end": "886122"
  },
  {
    "text": "the first period, let's say,\nbasically say it's till 2018.",
    "start": "886122",
    "end": "891510"
  },
  {
    "text": "We showed a lot of success at building\nneural networks for all sorts of tasks. We built them for syntactic parsing and\nsentiment analysis.",
    "start": "891510",
    "end": "900645"
  },
  {
    "text": "And what else? Question answering. But it was sort of like we were doing\nthe same thing that we used to do with",
    "start": "900645",
    "end": "909940"
  },
  {
    "text": "other kinds of machine learning models, except we now had a better\nmachine learning model.",
    "start": "909940",
    "end": "916330"
  },
  {
    "text": "And we were sort of instead of\ntraining up a logistic regression or a support vector machine, we were still\ndoing the same kind of sentiment analysis",
    "start": "916330",
    "end": "924290"
  },
  {
    "text": "task, but\nnow we are doing it with a neural network. So I think in looking\nback now in some sense,",
    "start": "924290",
    "end": "931599"
  },
  {
    "text": "the bigger change came around 2018. Because that was when the idea of, well,",
    "start": "931599",
    "end": "938977"
  },
  {
    "text": "we could just start with a large\namount of human language material and",
    "start": "938978",
    "end": "944241"
  },
  {
    "text": "build large what are self\nsupervised models. So that was models then\nlike BERT and GPT and",
    "start": "944241",
    "end": "952009"
  },
  {
    "text": "successor models to that. And they could just sort of\nacquire from word prediction over",
    "start": "952010",
    "end": "959136"
  },
  {
    "text": "a huge amount of text this amazing\nknowledge of human languages.",
    "start": "959136",
    "end": "964490"
  },
  {
    "text": "And I think really probably that's\ngoing to be viewed in retrospect as the bigger kind of cut point where\nthe way things were done really changed.",
    "start": "964490",
    "end": "974640"
  },
  {
    "text": "Andrew Ng: Yeah, I think there is that trend for the large language models learning\nfrom massive amount of data.",
    "start": "974640",
    "end": "980904"
  },
  {
    "text": "I think even in the lead up to that,\nthere was one of your research papers that really slightly\nblew my mind, which is a glove paper.",
    "start": "980904",
    "end": "988893"
  },
  {
    "text": "So because with word embeddings\nwhere you learn the vector numbers to represent a word\nusing a neural network.",
    "start": "988893",
    "end": "998376"
  },
  {
    "text": "That was quite mind blowing for me. And then the glove work that you did\nreally cleaned up the math, made it so",
    "start": "998376",
    "end": "1004912"
  },
  {
    "text": "much simpler. And then I remember I said,\nthat's all there is to do. And then you can learn these\nreally surprisingly detailed",
    "start": "1004913",
    "end": "1012842"
  },
  {
    "text": "representations of the computer\nlearns nuances of what words mean. Chris Manning: Absolutely.",
    "start": "1012842",
    "end": "1018441"
  },
  {
    "text": "Yeah, so I should give a little\nbit of credit to others. Other people also worked on\nsome similar ideas including Ronan Collobert, Jason Weston,",
    "start": "1018441",
    "end": "1027954"
  },
  {
    "text": "Tomas Mikolov and colleagues at Google. But the glove word vectors is one of the\nvery prominent systems of word vectors.",
    "start": "1027955",
    "end": "1037169"
  },
  {
    "text": "So these word vectors already did. Yeah, you're right, illustrate this idea\nof using self supervised learning that we",
    "start": "1037170",
    "end": "1044235"
  },
  {
    "text": "just took massive amounts of text. And then we could build these\nmodels that knew an enormous amount",
    "start": "1044235",
    "end": "1050731"
  },
  {
    "text": "about the meaning of words. It's still something I sort of\nshow people every year",
    "start": "1050731",
    "end": "1057621"
  },
  {
    "text": "in the first lecture of my NLP class. Because it's something simple but it\nactually just works so surprisingly well.",
    "start": "1057621",
    "end": "1067415"
  },
  {
    "text": "You can do this sort of simple modeling\nof trying to predict a word given the words in the context and",
    "start": "1067415",
    "end": "1073768"
  },
  {
    "text": "simply by sort of running the math\nof learning to do those predictions. Well, you learn all these\nthings about word meaning and",
    "start": "1073769",
    "end": "1082864"
  },
  {
    "text": "you can do these really nice\npatterns of similar word meaning or",
    "start": "1082864",
    "end": "1087879"
  },
  {
    "text": "analogies of something pencil is\nthe drawing as paintbrush is too and",
    "start": "1087879",
    "end": "1093369"
  },
  {
    "text": "it'll say painting, right? That it's sort of already showing\njust a lot of successful learning.",
    "start": "1093369",
    "end": "1101783"
  },
  {
    "text": "So that was the precursor to what\nthen got developed to the next",
    "start": "1101783",
    "end": "1106849"
  },
  {
    "text": "stage with things like BERT and GPT where it\nwasn't just meanings of individual words.",
    "start": "1106849",
    "end": "1113973"
  },
  {
    "text": "But meanings of whole pieces of text and\ncontext. Andrew Ng: Yeah, so I found it amazing that\nyou can take a small neural network or",
    "start": "1113973",
    "end": "1121865"
  },
  {
    "text": "some model and\nthen give it lots of English sentences or some other language and hide a word.",
    "start": "1121865",
    "end": "1127999"
  },
  {
    "text": "Ask it to predict what is\nthe word that I just hid and that allows it to learn these analogies.",
    "start": "1127999",
    "end": "1134288"
  },
  {
    "text": "And these very deep, what you think are really deep things\nbehind the meaning of the word.",
    "start": "1134288",
    "end": "1140545"
  },
  {
    "text": "And then 2018, maybe this other inflection\npoint what happened after that?",
    "start": "1140546",
    "end": "1146601"
  },
  {
    "text": "Chris Manning: Yeah. So, in 2018,\nthat was the point in which well,",
    "start": "1146601",
    "end": "1152360"
  },
  {
    "text": "sort of really two things happened. One thing is that people, or really in\n2017 had developed this new architecture.",
    "start": "1152360",
    "end": "1162313"
  },
  {
    "text": "Which was much more scalable\nonto modern parallel GPUs. And so\nthat was the transformer architecture.",
    "start": "1162313",
    "end": "1170667"
  },
  {
    "text": "The second part of it though was\nmaybe people rediscovered because I was using the same trick\nas the glove model that if you",
    "start": "1170667",
    "end": "1180218"
  },
  {
    "text": "have the task of just predicting\na word given a context. Either a context on both sides of it or",
    "start": "1180218",
    "end": "1187403"
  },
  {
    "text": "the preceding words that that just turns\nout to be an amazing learning task.",
    "start": "1187404",
    "end": "1193220"
  },
  {
    "text": "And that surprises a lot of people. And a lot of the time you see discussions\nwhere people say disparaging things of",
    "start": "1193220",
    "end": "1199891"
  },
  {
    "text": "this is nothing interesting is happening. And all it's doing is statistics\nto predict which word is",
    "start": "1199891",
    "end": "1206903"
  },
  {
    "text": "most likely to come after\nthe preceding words. And I think the really interesting thing\nis that that's true, but it's not true.",
    "start": "1206903",
    "end": "1218255"
  },
  {
    "text": "Because yes what the task is is\nyou're predicting the next word given preceding words.",
    "start": "1218255",
    "end": "1224297"
  },
  {
    "text": "But the really interesting thing\nis if you want to do that task really as well as possible.",
    "start": "1224297",
    "end": "1231694"
  },
  {
    "text": "Then it actually helps to understand\nthe whole of the rest of the sentence and",
    "start": "1231694",
    "end": "1237148"
  },
  {
    "text": "know who's doing what to who and\nwhat's in the sentence. But more than that,\nit also helps to understand",
    "start": "1237148",
    "end": "1246207"
  },
  {
    "text": "the world because if your\ntext is going something along the lines of the currency\nused in Fiji is the...",
    "start": "1246207",
    "end": "1256575"
  },
  {
    "text": "Well, you need to have some world\nknowledge to know what the right answer to that is. And so good models at doing this,",
    "start": "1256576",
    "end": "1263822"
  },
  {
    "text": "learn both to follow the structure\nof sentences and their meaning and",
    "start": "1263822",
    "end": "1269783"
  },
  {
    "text": "to know facts about the world all so\nthat they can predict.",
    "start": "1269783",
    "end": "1274942"
  },
  {
    "text": "And therefore this turns into what's\nsometimes referred to as an AI complete task, right? That you really need.",
    "start": "1274942",
    "end": "1281112"
  },
  {
    "text": "There's nothing that can't actually\nbe useful in answering this what word comes next sense, right?",
    "start": "1281113",
    "end": "1288834"
  },
  {
    "text": "You can be in the World Cup\nsemifinals the teams are...  and you need to know something about soccer\n[LAUGH] to be giving the right answer.",
    "start": "1288834",
    "end": "1300030"
  },
  {
    "text": "Andrew Ng: AI complete is a funny concept, right? Is this idea that you can solve this one\nproblem, you can solve everything in AI or",
    "start": "1300031",
    "end": "1306866"
  },
  {
    "text": "kind of make an analogy to NP complete\nproblems from the theory of computing.",
    "start": "1306866",
    "end": "1311882"
  },
  {
    "text": "What do you think? Do you think predicting\nthe next word is AI complete,",
    "start": "1311883",
    "end": "1316983"
  },
  {
    "text": "I have very mixed feelings\nabout that myself. I can say, I don't think it's true. I'm curious what you think.",
    "start": "1316983",
    "end": "1324488"
  },
  {
    "text": "Chris Manning: I think it's not quite true\nbecause I think there are other",
    "start": "1324489",
    "end": "1330296"
  },
  {
    "text": "kind of things that human\nbeings manage to work out.",
    "start": "1330296",
    "end": "1335402"
  },
  {
    "text": "There are human beings that have\nclever insights in mathematics or",
    "start": "1335402",
    "end": "1340559"
  },
  {
    "text": "there are human beings who are looking\nat something that's a much more",
    "start": "1340560",
    "end": "1346192"
  },
  {
    "text": "three dimensional real world\npuzzle of sort of figuring out how to do something mechanical or\nsomething like that.",
    "start": "1346192",
    "end": "1354722"
  },
  {
    "text": "And that's just not a language problem. But on the other hand,\nI think language gets",
    "start": "1354722",
    "end": "1363542"
  },
  {
    "text": "closer to universality\nthan some people think",
    "start": "1363542",
    "end": "1369033"
  },
  {
    "text": "as well, because we live in this 3D world. And operate in it with our bodies and\nour feelings and",
    "start": "1369033",
    "end": "1379105"
  },
  {
    "text": "other creatures and artifacts around it. And you could think, well,\nnot much of that is in language at all.",
    "start": "1379105",
    "end": "1388251"
  },
  {
    "text": "But actually just about all\nof this stuff we think about, we talk about,\nwe write about it in language.",
    "start": "1388251",
    "end": "1396820"
  },
  {
    "text": "We can describe the positions of things\nrelative to each other in language. So a surprising amount of the other parts\nof the world are seen in reflection",
    "start": "1396821",
    "end": "1405948"
  },
  {
    "text": "in language. And therefore you're learning\nabout all of them too. When you learn about language use.",
    "start": "1405948",
    "end": "1412236"
  },
  {
    "text": "Andrew Ng: You learn about one aspect of\na lot of things even if things like how do you ride a bicycle can't really perfect.",
    "start": "1412236",
    "end": "1420209"
  },
  {
    "text": "Chris Manning: You don't really learn how\nto ride a bicycle, [LAUGH] but you learn some aspects of what it\ninvolves that you need to balance.",
    "start": "1420209",
    "end": "1427566"
  },
  {
    "text": "And you have to have your feet\non the pedals and push them and all of that kind of things. Yeah.",
    "start": "1427567",
    "end": "1434408"
  },
  {
    "text": "Andrew Ng: And so with this trend in NLP,\nthe last language models has been very exciting for\nthe last several years.",
    "start": "1434408",
    "end": "1443341"
  },
  {
    "text": "What are your thoughts on\nwhere all this will go? Chis Manning: Well yeah, so it's just been amazingly",
    "start": "1443342",
    "end": "1450360"
  },
  {
    "text": "successful and exciting, right? That so we haven't really\nexplained all the details, right?",
    "start": "1450360",
    "end": "1457100"
  },
  {
    "text": "So there's the first stage of learning\nthese large language models where the task is just to predict the next word.",
    "start": "1457100",
    "end": "1464539"
  },
  {
    "text": "And you do that billions of times\nover a very large piece of text. And behold, you get this large neural\nnetwork, which is just a really useful",
    "start": "1464540",
    "end": "1473559"
  },
  {
    "text": "artifact for all sorts of natural\nlanguage processing tasks. But then you still actually have to do\nsomething with it if you want to do",
    "start": "1473559",
    "end": "1481200"
  },
  {
    "text": "a particular task, whether that's\nquestion answering or summarization or detecting toxic content in social media or\nsomething like that.",
    "start": "1481201",
    "end": "1489697"
  },
  {
    "text": "And at that point, there's a choice\nof things that you could do with it. The traditional answer was then\nyou had a particular task,",
    "start": "1489697",
    "end": "1497301"
  },
  {
    "text": "let's say it's detecting toxic\ncomments in social media. And you'd take some supervised data for\nthat and",
    "start": "1497301",
    "end": "1504488"
  },
  {
    "text": "then you'd fine tune the language model\nto answer that classification task. But you were enormously helped by having\nthis base of this large self supervised",
    "start": "1504488",
    "end": "1514506"
  },
  {
    "text": "model because it meant that the model\nhad enormous knowledge of language and it could generalize very quickly.",
    "start": "1514506",
    "end": "1521785"
  },
  {
    "text": "So unlike the sort of the standard old\ndays of, of supervised learning where",
    "start": "1521786",
    "end": "1527102"
  },
  {
    "text": "it was kind of, well, if you give\nme 10,000 labeled example examples,",
    "start": "1527102",
    "end": "1532585"
  },
  {
    "text": "I might be able to produce\na halfway decent model for you. But if you give me 50,000 labeled\nexamples, it will be a lot better.",
    "start": "1532585",
    "end": "1540934"
  },
  {
    "text": "It's sort of turned it into this world of. Well, if you give me 100\nlabeled examples and",
    "start": "1540934",
    "end": "1546185"
  },
  {
    "text": "I fine tuning a large language model,\nI'll be able to do great, better than I would have been able to do with\nthe 50,000 examples in the old world.",
    "start": "1546186",
    "end": "1555221"
  },
  {
    "text": "Some of the more recent exciting\nworks now, even going beyond that, it's now, well, maybe you don't actually\nhave to fine tune the model at all.",
    "start": "1555221",
    "end": "1562830"
  },
  {
    "text": "So people have done a lot of work\nusing methods, sometimes referred to",
    "start": "1562831",
    "end": "1567911"
  },
  {
    "text": "as prompting or instruction where\nyou can simply in natural language,",
    "start": "1567911",
    "end": "1573079"
  },
  {
    "text": "perhaps with examples,\nperhaps with explicit instructions, just tell the model what you want it to\ndo and it does it which even as someone",
    "start": "1573079",
    "end": "1583064"
  },
  {
    "text": "who's been working in natural\nlanguage processing for 30 years.",
    "start": "1583064",
    "end": "1588095"
  },
  {
    "text": "I mean, it actually just blows\nmy mind how well this works it,",
    "start": "1588095",
    "end": "1593278"
  },
  {
    "text": "I guess I wasn't a decade ago\nthinking that in now we'd be able to just tell the model,\nI want you to summarize this",
    "start": "1593279",
    "end": "1602750"
  },
  {
    "text": "piece of text here and it,\nthey will then summarize it. I think that is incredible.",
    "start": "1602750",
    "end": "1610196"
  },
  {
    "text": "Yeah, so we are in this very\nexciting time where a lot of new natural language\ncapabilities are unfolding.",
    "start": "1610196",
    "end": "1619006"
  },
  {
    "text": "I think there's just no doubt at all for\nthe next couple of years, the future of that is extremely bright\nas people work out different things and",
    "start": "1619006",
    "end": "1629243"
  },
  {
    "text": "different ways to do things and people start to apply in\ndifferent application areas.",
    "start": "1629243",
    "end": "1635511"
  },
  {
    "text": "The kind of capabilities that\nhave been unlocked with recent technological developments.",
    "start": "1635511",
    "end": "1640771"
  },
  {
    "text": "There's always a question in technology\nas to sort of whether the curve keeps on heading steeply upwards or",
    "start": "1640771",
    "end": "1647408"
  },
  {
    "text": "whether there's then some new things,\nwe have to discover how to do.",
    "start": "1647409",
    "end": "1651973"
  },
  {
    "text": "Andrew Ng: It's been going up for quite a while. So hopefully extrapolation\nis always dangerous. But, but we'll see,\n I'm just curious, you know, ",
    "start": "1653039",
    "end": "1661299"
  },
  {
    "text": "you mentioned writing prompts. Tell the NLP system, the large language model, what you want and\nit seems to magically do it.",
    "start": "1661299",
    "end": "1669000"
  },
  {
    "text": "I'm curious, do you think prompt\nengineering is the path of the future where actually when I write these prompts,\nI sometimes find it works miraculously and",
    "start": "1669000",
    "end": "1678388"
  },
  {
    "text": "sometimes it's frustrating the process\nof rewording my instructions to tweak the wording to get it just right\nto generate the result I want.",
    "start": "1678389",
    "end": "1686819"
  },
  {
    "text": "So, do you think problem engineering\nis the way of the future or do you think is a intermediate hack\nuntil someone invents a better way to",
    "start": "1686819",
    "end": "1694011"
  },
  {
    "text": "control these,\ncontrol the outputs of these systems.",
    "start": "1694011",
    "end": "1697020"
  },
  {
    "text": "Chris Manning: I think it's both,\nI think will be the way of the future but",
    "start": "1699049",
    "end": "1704443"
  },
  {
    "text": "I also think at the moment\npeople are doing, yeah, a lot of hacking around and\nrewording to try and",
    "start": "1704443",
    "end": "1713471"
  },
  {
    "text": "get things to work better and\nwith any luck with a few more years of development\nthat will start to go away.",
    "start": "1713471",
    "end": "1723199"
  },
  {
    "text": "I mean, one way of to think about\nthe difference is sort of in comparison",
    "start": "1723199",
    "end": "1728940"
  },
  {
    "text": "to the kind of voice assistance or\nvirtual assistance that are available on",
    "start": "1728941",
    "end": "1734878"
  },
  {
    "text": "phones speaker devices like Amazon,\nAlexa these days, right?",
    "start": "1734878",
    "end": "1740174"
  },
  {
    "text": "I mean, I think all of us have\nhad the experience that present those devices aren't always great, but",
    "start": "1740174",
    "end": "1747226"
  },
  {
    "text": "if you know the right way to word things,\nit'll do something. But if you use the wrong wording,\nit won't and",
    "start": "1747226",
    "end": "1754527"
  },
  {
    "text": "the difference with human beings is by and\nlarge, you don't have to think about that.",
    "start": "1754527",
    "end": "1760070"
  },
  {
    "text": "You can say what you want and\nit doesn't matter what words you choose, they'll the other human being assuming\nthat someone who knows the same language,",
    "start": "1760070",
    "end": "1768090"
  },
  {
    "text": "et cetera will understand you and\ndo what you want. And I think and would hope that we'll\nstart to see the same kind of progression",
    "start": "1768090",
    "end": "1776062"
  },
  {
    "text": "with these models that at the moment\nfiddling around with the particular wording, you use can make a very big\ndifference to how well it works.",
    "start": "1776062",
    "end": "1785816"
  },
  {
    "text": "But hopefully in a few years time,\nthat just won't be true, you'll be able to use different\nwordings and it'll still work.",
    "start": "1785816",
    "end": "1793066"
  },
  {
    "text": "But the basic idea that we're moving into\nthis age where actually human language",
    "start": "1793066",
    "end": "1799505"
  },
  {
    "text": "will be able to be used as an instruction\nlanguage to tell your computer what to do.",
    "start": "1799505",
    "end": "1806061"
  },
  {
    "text": "So, instead of having to use menus and\nradio buttons and things like that or",
    "start": "1806061",
    "end": "1811674"
  },
  {
    "text": "writing Python code,\ninstead of either of those things that you'll be able to say what you\nwant in the computer will do it.",
    "start": "1811674",
    "end": "1820881"
  },
  {
    "text": "I think that age is opening up in front\nof us that will continue to build and",
    "start": "1820881",
    "end": "1826803"
  },
  {
    "text": "that will be hugely transformative. Andrew Ng: Feels like come a long ways but only\na much more to come and much more to go.",
    "start": "1826803",
    "end": "1836021"
  },
  {
    "text": "Chris Manning: Yeah, absolutely. Andrew Ng: In the development of NLP technology,\nthe only thing I want to ask you and I suspect you and\nI may have different perspectives on this.",
    "start": "1836021",
    "end": "1843590"
  },
  {
    "text": "But in the last couple of decades,\nthe trend has been to rely less on rule based engineering and\nmore on machine learning on data.",
    "start": "1843590",
    "end": "1852820"
  },
  {
    "text": "Sometimes lots of data\nlook into the future. Where do you think that mix of hand\ncoded constraints or other constraints,",
    "start": "1852820",
    "end": "1861758"
  },
  {
    "text": "explicit constraints versus let's get a\nneural network and throw lots of data at it.",
    "start": "1861759",
    "end": "1867000"
  },
  {
    "text": "Where do you think that balance will fall? Chris Manning: I think that there's no\ndoubt that using learning from",
    "start": "1867000",
    "end": "1875828"
  },
  {
    "text": "data is the way forward and\nwhat we're going to continue to do.",
    "start": "1875828",
    "end": "1881549"
  },
  {
    "text": "But I think there's still a space for models that have more structure,\nmore inductive bias that",
    "start": "1881549",
    "end": "1890182"
  },
  {
    "text": "have some kind of basis of\nexploiting the nature of language.",
    "start": "1890182",
    "end": "1895639"
  },
  {
    "text": "So in recent years, the model that's\nbeen enormously successful is the transformer neural network and\nthe transformer neural networks,",
    "start": "1895639",
    "end": "1904669"
  },
  {
    "text": "essentially this huge association machine. So it'll just suck\nassociations from anywhere.",
    "start": "1904670",
    "end": "1911329"
  },
  {
    "text": "Andrew Ng: And look at two words and figure\nout which word relates  to which other word for all words. Chris Manning: Yes.\nSo you use everything to predict anything",
    "start": "1911329",
    "end": "1918925"
  },
  {
    "text": "and do it over and over again and\nyou'll get anything you want. And you know, that's been incredibly,\nincredibly successful, but it's",
    "start": "1918925",
    "end": "1928478"
  },
  {
    "text": "been incredibly successful in the domain\nwhere you have humongous amounts of data.",
    "start": "1928479",
    "end": "1934790"
  },
  {
    "text": "Right, so that these transformer\nmodels for these large language models are now being trained on\ntens of billions of words of text.",
    "start": "1934790",
    "end": "1943836"
  },
  {
    "text": "When I started off in statistical\nnatural language processing. And some of the traditional linguists\nused to complain about the fact",
    "start": "1943837",
    "end": "1953416"
  },
  {
    "text": "that I was collecting statistics\nfrom 30 million words of Newswire. And building a predictive model and",
    "start": "1953416",
    "end": "1960940"
  },
  {
    "text": "thought that was just not\nwhat linguistics was about. I felt I had a perfectly good answer,",
    "start": "1960940",
    "end": "1968437"
  },
  {
    "text": "which is that a human kid as\nthey're learning language.",
    "start": "1968437",
    "end": "1973810"
  },
  {
    "text": "They're exposed to actually, well,\nmore than 30 million words of data. But that kind of amount of data, so\nthe kind of amount of some data we were",
    "start": "1973810",
    "end": "1983491"
  },
  {
    "text": "using were perfectly reasonable\namounts of data to be using. To be not exactly trying to model\nhuman language acquisition.",
    "start": "1983491",
    "end": "1991967"
  },
  {
    "text": "But to be thinking about how we can\nlearn about language from lots of data.",
    "start": "1991967",
    "end": "1997441"
  },
  {
    "text": "But these modern transformers\nare now using already",
    "start": "1997441",
    "end": "2003051"
  },
  {
    "text": "at least two orders of magnitude,\nmore data. And most most people think the way\nto get things to the next level",
    "start": "2003051",
    "end": "2013041"
  },
  {
    "text": "is to use more still and\nmake it three orders of magnitude. And in one sense that scaling up\nstrategy has been hugely effective.",
    "start": "2013041",
    "end": "2022524"
  },
  {
    "text": "So, I don't blame anybody for saying,\nlet's make it another order of magnitude bigger and\nsee what amazing things we can do.",
    "start": "2022524",
    "end": "2029479"
  },
  {
    "text": "But it also shows that\nhuman learning is just way, way better in being able\nto extract a lot more",
    "start": "2029479",
    "end": "2038767"
  },
  {
    "text": "information out of a quite\nlimited amount of data.",
    "start": "2038767",
    "end": "2043841"
  },
  {
    "text": "And at that point,\nyou can have various hypotheses. But I think it's reasonable to\nassume that human learning is",
    "start": "2043842",
    "end": "2052143"
  },
  {
    "text": "somewhat structured towards\nthe structure of the world. And things it sees in the world and",
    "start": "2052143",
    "end": "2059190"
  },
  {
    "text": "that allows it to learn more\nquickly from less data. Andrew Ng: Right, I'm with you on that. I think better learning algorithms,\nour current machine learning algorithms",
    "start": "2059190",
    "end": "2067264"
  },
  {
    "text": "are much less efficient or\nmakes much less efficient use of data. And so\nthere's way more data than any child.",
    "start": "2067265",
    "end": "2075181"
  },
  {
    "text": "And then I think whether the improved\nlearning algorithms will be from linguistic like rules or\nwhether it will just be engineers,",
    "start": "2075182",
    "end": "2082617"
  },
  {
    "text": "engineering much more efficient\nversions of the transformer or whatever comes after it. That I think will be.",
    "start": "2082618",
    "end": "2088190"
  },
  {
    "text": "Chris Manning:  I doubt it will be traditional. I don't think it'll be\nby people explicitly",
    "start": "2088191",
    "end": "2094259"
  },
  {
    "text": "putting traditional linguistic\nrules into the system. I don't think that's the way forward.",
    "start": "2094259",
    "end": "2100648"
  },
  {
    "text": "On the other hand I think what\nwe're starting to see is models",
    "start": "2100648",
    "end": "2105932"
  },
  {
    "text": "like these transformer models\nare actually discovering the structure of language themselves,\nright?",
    "start": "2105933",
    "end": "2115178"
  },
  {
    "text": "So the broad effects of human\nlanguage that English has the subject before the verb and\nthe object afterwards.",
    "start": "2115178",
    "end": "2124060"
  },
  {
    "text": "Whereas in Japanese that the verbs at the\nend of the sentence and the subject and object are normally in\nthat order before it.",
    "start": "2124061",
    "end": "2131239"
  },
  {
    "text": "But could be in the other order actually\ntransformer models are learning these facts.",
    "start": "2131239",
    "end": "2136984"
  },
  {
    "text": "You can interrogate them and\nsee that even though they were never explicitly told about subjects and\nobjects that they know these notions.",
    "start": "2136984",
    "end": "2145071"
  },
  {
    "text": "So I think they're discovering a lot else\nas well about language use and context and",
    "start": "2145071",
    "end": "2150677"
  },
  {
    "text": "the meanings and senses of words and\nwhat is and isn't, unpleasant language.",
    "start": "2150677",
    "end": "2156065"
  },
  {
    "text": "But part of what they're learning is\nthe same kind of structure that linguists",
    "start": "2156065",
    "end": "2161068"
  },
  {
    "text": "have laid out as the sort of structure\nof different human languages. Andrew Ng: So it's as if over many decades,\nlinguists discovered certain things.",
    "start": "2161069",
    "end": "2169774"
  },
  {
    "text": "And by training on billions of words,\ntransformers are discovering the same things that linguists\ndiscovered in humans.",
    "start": "2169774",
    "end": "2175952"
  },
  {
    "text": "That's cool. So all this is really\nexciting progress in NLP,",
    "start": "2175952",
    "end": "2181381"
  },
  {
    "text": "driven by machine learning and\nby other things. To someone entering the field,\nentering machine learning or AI or NLP.",
    "start": "2181381",
    "end": "2188345"
  },
  {
    "text": "There's just a lot going on. What advice would you have for someone\nwanting to break into machine learning?",
    "start": "2188345",
    "end": "2196409"
  },
  {
    "text": "Chris Manning: Yeah. Well it's a great time to break in. I think there's just no doubt at all\nthat we're still in the early stages",
    "start": "2196409",
    "end": "2205699"
  },
  {
    "text": "of seeing the impact of this new approach\nwhere effectively software computer",
    "start": "2205699",
    "end": "2212101"
  },
  {
    "text": "science is being reinvented on the basis\nof much more use of machine learning.",
    "start": "2212101",
    "end": "2218512"
  },
  {
    "text": "And the various other things\nthat come up away from that. And then more generally across industries,\nthere are just lots of opportunities for",
    "start": "2218512",
    "end": "2226207"
  },
  {
    "text": "more automation. Making more use of interpretation of\nhuman language material for me or",
    "start": "2226207",
    "end": "2232343"
  },
  {
    "text": "in other areas like vision and\nrobotics, the same kind of things. So, lots of possibilities.",
    "start": "2232343",
    "end": "2240935"
  },
  {
    "text": "So at that point, there's lots to do\nobviously in that you want to get some kind of good foundation, right.",
    "start": "2240935",
    "end": "2248716"
  },
  {
    "text": "So knowing some of the core technical\nmethods of machine learning, understanding ideas of how\nto build models from data.",
    "start": "2248716",
    "end": "2257641"
  },
  {
    "text": "Look at losses, do training diagnose\nerrors, all of these core things.",
    "start": "2257642",
    "end": "2263190"
  },
  {
    "text": "That's definitely useful for\nnatural language processing in particular,",
    "start": "2263190",
    "end": "2268485"
  },
  {
    "text": "some of those skills\nare completely relevant. But then there are particular kind of\nmodels that are commonly used,",
    "start": "2268486",
    "end": "2275653"
  },
  {
    "text": "including the the transformer that\nwe've talked about a lot today. You definitely should know\nabout transformers and indeed",
    "start": "2275653",
    "end": "2282957"
  },
  {
    "text": "they're increasingly being used in every\nother part of machine learning as well for vision, bioinformatics,\neven robotics is now using transformers.",
    "start": "2282957",
    "end": "2291731"
  },
  {
    "text": "But beyond that, I think it's\nalso useful to learn something about human language and\nthe nature of the problems that involves.",
    "start": "2291731",
    "end": "2299781"
  },
  {
    "text": "Because even though people aren't\ndirectly going to be encoding",
    "start": "2299781",
    "end": "2304938"
  },
  {
    "text": "rules of human language into\ntheir computing system. A sensitivity to sort of what kind of\nthings happen in language and",
    "start": "2304938",
    "end": "2314726"
  },
  {
    "text": "what to look out for and what you might want to model that's\nstill a useful skill to have.",
    "start": "2314726",
    "end": "2322038"
  },
  {
    "text": "Andrew Ng: And\nthen in terms of learning the foundations, learning about these concepts. You had entered AI from\na linguistic background and",
    "start": "2322038",
    "end": "2331743"
  },
  {
    "text": "we now see people from all walks of\nlife wanting to start doing work in AI.",
    "start": "2331743",
    "end": "2338732"
  },
  {
    "text": "What are your thoughts on the preparation\none should have or and your thoughts on how to start from something other\nthan computer science or AI.",
    "start": "2338732",
    "end": "2345975"
  },
  {
    "text": "Chris Manning: So there are lots of places\nyou can come from and vector across in different ways.",
    "start": "2345975",
    "end": "2353875"
  },
  {
    "text": "And we're seeing tons of people\ndoing that, that they are people",
    "start": "2353875",
    "end": "2358950"
  },
  {
    "text": "who started off in different areas,\nwhether it was chemistry,",
    "start": "2358950",
    "end": "2364123"
  },
  {
    "text": "physics or even much further in field. And people have history, whatever have\nstarted to look at machine learning.",
    "start": "2364123",
    "end": "2371735"
  },
  {
    "text": "I think there are sort of\ntwo levels of answer there. One level of answer is one of\nthe amazing transformations",
    "start": "2371735",
    "end": "2380267"
  },
  {
    "text": "is that there's now these very\ngood software packages for",
    "start": "2380267",
    "end": "2385412"
  },
  {
    "text": "doing things with your network models. This software is really easy to use.",
    "start": "2385412",
    "end": "2392970"
  },
  {
    "text": "You don't actually need to understand\na lot of highly technical stuff. You've got need to have some kind of high\nlevel conception about what is the idea of",
    "start": "2392970",
    "end": "2401065"
  },
  {
    "text": "machine learning. And how do I go about training a model and\nwhat should I look at and the numbers that are being printed\nout to see if it's working, right.",
    "start": "2401065",
    "end": "2409159"
  },
  {
    "text": "But you don't actually have to have\na higher degree to be able to build these models.",
    "start": "2409159",
    "end": "2414228"
  },
  {
    "text": "I mean, and indeed what we're seeing is,\nlots of high school students are getting into doing this because\nit's actually something that if you have",
    "start": "2414228",
    "end": "2423478"
  },
  {
    "text": "some basic computer skills and a bit\nof programming, you can pick up and do. It's just way more accessible than\nlots of stuff that proceeded it",
    "start": "2423478",
    "end": "2433306"
  },
  {
    "text": "whether in AI outside of AI and other\nareas, like operating systems or security.",
    "start": "2433306",
    "end": "2439567"
  },
  {
    "text": "But if you want to get to\na deeper level than that and actually want to understand\nmore of what's going on.",
    "start": "2439568",
    "end": "2446563"
  },
  {
    "text": "I think you can't really get\nthere if you don't have a certain mathematics foundation, like at\nthe end of the day that Deep Learning",
    "start": "2446563",
    "end": "2457143"
  },
  {
    "text": "is based on calculus and\nyou need to be optimizing functions. And if you sort of don't\nhave any background in that,",
    "start": "2457143",
    "end": "2466509"
  },
  {
    "text": "I think that sort of ends\nup as a war at some point. So\nAndrew Ng: Math in machine learning and data science.",
    "start": "2466509",
    "end": "2474440"
  },
  {
    "text": "It does come in handy for some of the work we do.\nChris Manning: Yeah. So I think at some level,\nif you're at the major in history or",
    "start": "2474440",
    "end": "2482718"
  },
  {
    "text": "non mathematical parts of psychology,\nI actually have a good friend who,",
    "start": "2482718",
    "end": "2488640"
  },
  {
    "text": "yeah, he learned calculus in grad school\nbecause he was a psychologist and",
    "start": "2488640",
    "end": "2494562"
  },
  {
    "text": "he'd never done it before. And decided that he wanted to start\nlearning about these new kinds of models",
    "start": "2494562",
    "end": "2501347"
  },
  {
    "text": "and decided it wasn't too late to be\nable to go and take a cow course. And so he did, right.",
    "start": "2501347",
    "end": "2506987"
  },
  {
    "text": "So you do need to know some of that stuff,\nbut for lots of people,",
    "start": "2506987",
    "end": "2512340"
  },
  {
    "text": "if they've seen some of that before,\neven if you're kind of rusty.",
    "start": "2512340",
    "end": "2518109"
  },
  {
    "text": "I think you can kind of, get back in\nthe zone and it doesn't really matter that",
    "start": "2518109",
    "end": "2523179"
  },
  {
    "text": "you haven't done AI as an undergrad or\nmachine learning and things like that,",
    "start": "2523179",
    "end": "2528327"
  },
  {
    "text": "that you can really start to learn how\nto build these models and do things and really, that's my own story, right?",
    "start": "2528327",
    "end": "2535917"
  },
  {
    "text": "That despite the fact that they let me\nsit in the school of engineering at Stanford these days,\nmy background isn't as an engineer.",
    "start": "2535917",
    "end": "2545018"
  },
  {
    "text": "My PhD is in linguistics,\nthat I've sort of largely vectored",
    "start": "2545019",
    "end": "2550306"
  },
  {
    "text": "across from having some knowledge\nof mathematics and linguistics and",
    "start": "2550306",
    "end": "2556307"
  },
  {
    "text": "knowing some programming into sort of\ngetting much more into building AI models.",
    "start": "2556307",
    "end": "2563338"
  },
  {
    "text": "Andrew Ng: Let's peruse about something. Do you think the improved libraries and\nabstractions that are now available like",
    "start": "2563339",
    "end": "2569090"
  },
  {
    "text": "coding frameworks,\nlike tensor flow or Pytorch? Do you think that reduces\nthe need to understand calculus?",
    "start": "2569091",
    "end": "2574977"
  },
  {
    "text": "Because boy, it's been a while since I\nhad to actually take a derivative in order to even implement or create a new\nneural network architecture because of",
    "start": "2574978",
    "end": "2583939"
  },
  {
    "text": "automatic differentiation\nChris Manning: Yeah, I mean, absolutely. I mean, so in the early days, when we were\ndoing things sort of 2010 to 2015, right?",
    "start": "2583939",
    "end": "2596762"
  },
  {
    "text": "For every model we built, we were\nworking out the derivatives by hand and then writing some code and\nwhatever it was.",
    "start": "2596762",
    "end": "2604491"
  },
  {
    "text": "Sometimes it was Python but\nsometimes it might have been Java or C [LAUGH] to calculate\nthese derivatives and",
    "start": "2604491",
    "end": "2612525"
  },
  {
    "text": "checking that we got them right and\nso on, where these days you actually",
    "start": "2612525",
    "end": "2617940"
  },
  {
    "text": "don't need to know any of that\nto build Deep Learning models. I mean,\nthis is actually something I think about,",
    "start": "2617940",
    "end": "2625560"
  },
  {
    "text": "been thinking about even with respect\nto my own natural language processing with Deep Learning class that I teach.",
    "start": "2625561",
    "end": "2632114"
  },
  {
    "text": "At the beginning, we do still go\nthrough doing, matrix calculus and",
    "start": "2632114",
    "end": "2638186"
  },
  {
    "text": "making sure people know about Jacobian and\nthings like that so",
    "start": "2638186",
    "end": "2643631"
  },
  {
    "text": "that they understand what's being done\nin back propagation, Deep Learning.",
    "start": "2643631",
    "end": "2650664"
  },
  {
    "text": "But there's sort of this thing in which\nthat means that we just give them hell for",
    "start": "2650664",
    "end": "2656073"
  },
  {
    "text": "two weeks. It's sort of like boot camp or\nsomething to make them suffer. And then we say, but you do the rest\nof the class with pytorch and",
    "start": "2656073",
    "end": "2664853"
  },
  {
    "text": "they sort of never have to\nknow any of that again, right? There's always a question of how deep you\nwant to go on technical foundations you,",
    "start": "2664853",
    "end": "2673363"
  },
  {
    "text": "right. You can keep on going, right? Like does a computer scientist\nin the 2020s need to understand,",
    "start": "2673363",
    "end": "2682180"
  },
  {
    "text": "electronics and transistors or\nwhat happens in your CPU.",
    "start": "2682180",
    "end": "2687817"
  },
  {
    "text": "Well, it's complicated,\nI mean, in various ways, it is helpful to know some of that stuff.",
    "start": "2687817",
    "end": "2692970"
  },
  {
    "text": "I mean, I know Andrew, you were one of the pioneers in getting\nmachine learning on to GPUs and, well, that",
    "start": "2692970",
    "end": "2699971"
  },
  {
    "text": "sort of means you had to have some sense\nthat there's this new hardware out there.",
    "start": "2699971",
    "end": "2705412"
  },
  {
    "text": "And it has some attributes of parallelism\nthat means there's likely to be able to do something exciting.",
    "start": "2705413",
    "end": "2710687"
  },
  {
    "text": "So it is useful to have some broader\nknowledge and understanding and sometimes something breaks and\nif you have some deeper knowledge,",
    "start": "2710687",
    "end": "2719008"
  },
  {
    "text": "you can understand why it broke. But there's another sense in which\nmost people have to take some",
    "start": "2719009",
    "end": "2726193"
  },
  {
    "text": "things on trust and you can do most\nof what you want to do in neural network modeling these days\nwithout knowing calculus at all.",
    "start": "2726193",
    "end": "2736197"
  },
  {
    "text": "Andrew Ng: Yeah, I think that's a great point. I feel like sometimes the reliability of\nthe abstraction determines how often you need to go in to fix\nsomething that's broken.",
    "start": "2736197",
    "end": "2743352"
  },
  {
    "text": "So I'm, actually my understanding\nof quantum physics is very weak. I barely understand it.",
    "start": "2743352",
    "end": "2749030"
  },
  {
    "text": "So you could argue,\nI don't understand how computers work because transistors are built\nin quantum physics. But fortunately, if something\nwent wrong with the transistor,",
    "start": "2749030",
    "end": "2759050"
  },
  {
    "text": "I've never had to go hard to fix it.\nChris Manning: There a bit hard to fix I think. Andrew Ng: And so I think or another example, the\nsort function, the library to sort things,",
    "start": "2759050",
    "end": "2768851"
  },
  {
    "text": "and sometimes they actually don't work,\nright, swap in the memory or whatever.",
    "start": "2768851",
    "end": "2774112"
  },
  {
    "text": "And that's when, if you really\nunderstand how the sort function works, you can go in and fix it. But then sometimes if we have\nabstractions, libraries,",
    "start": "2774112",
    "end": "2781898"
  },
  {
    "text": "APIs are reliable enough, then that it's\nnice to those abstractions then diminishes the need to understand some of\nthe things that happen on me.",
    "start": "2781898",
    "end": "2789970"
  },
  {
    "text": "So it's an exciting world. Feels like we have giants building on\nthe shoulders of giants and all of",
    "start": "2789970",
    "end": "2795928"
  },
  {
    "text": "these things are becoming more complex and\nmore exciting every month really. Chis Manning: Yeah, absolutely.",
    "start": "2795928",
    "end": "2801720"
  },
  {
    "text": "Andrew Ng: So thanks Chris, that was really\ninteresting and inspiring and I hope that to everyone watching\nthis hearing Chris's own journey to",
    "start": "2801720",
    "end": "2810820"
  },
  {
    "text": "become a computer scientist. And to become a leading, maybe the leading\nNLP computer scientist as well as all of",
    "start": "2810820",
    "end": "2817910"
  },
  {
    "text": "this exciting work\nhappening in NLP right now. I hope that inspires you too to jump\ninto the steam and take a go at it.",
    "start": "2817910",
    "end": "2825518"
  },
  {
    "text": "There's just a lot more work to be done\ncollectively by our community that still, so I think the more of us are working on\nthis, the better off the world will be.",
    "start": "2825518",
    "end": "2833765"
  },
  {
    "text": "So thanks a lot, Chris. It was really great having you here. Chris Manning: Thanks a lot, Andrew. It's been fun chatting. [MUSIC]",
    "start": "2833765",
    "end": "2838680"
  }
]
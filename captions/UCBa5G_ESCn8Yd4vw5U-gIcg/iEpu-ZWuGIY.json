[
  {
    "start": "0",
    "end": "25000"
  },
  {
    "text": "thank you to the organizers shresh jeanette monge",
    "start": "9920",
    "end": "14960"
  },
  {
    "text": "marco for hosting me you know i'm really excited to come here in person i come from pittsburgh all the way here",
    "start": "14960",
    "end": "21520"
  },
  {
    "text": "to just give this talk and meet all of you um so yeah as janet mentioned i'm sanjivan",
    "start": "21520",
    "end": "27039"
  },
  {
    "start": "25000",
    "end": "60000"
  },
  {
    "text": "i am currently a research scientist at aurora where we do self-driving which i'll talk about today i'm also joining",
    "start": "27039",
    "end": "33600"
  },
  {
    "text": "cornell assistant professor in july 2022 so if you're a prospective student reach out",
    "start": "33600",
    "end": "40079"
  },
  {
    "text": "today i'm really excited to talk about interactive imitation learning sort of how do we build robots that",
    "start": "40079",
    "end": "47200"
  },
  {
    "text": "learn from human interaction and plan alongside humans and in the spirit of this lecture if you",
    "start": "47200",
    "end": "53039"
  },
  {
    "text": "have any questions this is please uh this is an interactive session so please please feel free to ask",
    "start": "53039",
    "end": "59520"
  },
  {
    "text": "right so let's get started so the question at the core of my research is how do we design robots that",
    "start": "59520",
    "end": "67119"
  },
  {
    "start": "60000",
    "end": "105000"
  },
  {
    "text": "both understand and learn from natural human interactions you know for those who have seen this movie baymax",
    "start": "67119",
    "end": "74159"
  },
  {
    "text": "this will be a familiar scene where hero teaches baymax to do a fist bump you know what's beautiful about the",
    "start": "74159",
    "end": "80400"
  },
  {
    "text": "scene is that hero through a simple sequence of interactions is able to communicate this novel",
    "start": "80400",
    "end": "86799"
  },
  {
    "text": "concept of a fist bump to baymax right so how do we build such robots that continually improve",
    "start": "86799",
    "end": "93920"
  },
  {
    "text": "and learn online to adapt to individual human preferences now to do so i think we need to solve",
    "start": "93920",
    "end": "100640"
  },
  {
    "text": "two fundamental challenges first how should robots learn from natural",
    "start": "100640",
    "end": "107680"
  },
  {
    "start": "105000",
    "end": "150000"
  },
  {
    "text": "human interactions you know consider this case where your grandma receives a brand new robot apprentice you know",
    "start": "107680",
    "end": "114560"
  },
  {
    "text": "there are a number of tasks she wants the apprentice to do in a specific way",
    "start": "114560",
    "end": "119759"
  },
  {
    "text": "but that's latent in her mind right how can the robot interact with her to infer",
    "start": "119759",
    "end": "125360"
  },
  {
    "text": "these latent preferences from natural modes of feedback like gestures",
    "start": "125360",
    "end": "130640"
  },
  {
    "text": "interventions or corrections second how should robots plan alongside",
    "start": "130640",
    "end": "137520"
  },
  {
    "text": "human partners to accomplish these tasks you know the robot must be able to anticipate how humans respond to their",
    "start": "137520",
    "end": "144000"
  },
  {
    "text": "emotions uh understand their intent and move in a safe predictable manner",
    "start": "144000",
    "end": "149120"
  },
  {
    "text": "okay so for the past two and a half years i've been working um in self-driving at",
    "start": "149120",
    "end": "154959"
  },
  {
    "start": "150000",
    "end": "268000"
  },
  {
    "text": "aurora with an amazing team led by drewbag now you know our key product is the aurora",
    "start": "154959",
    "end": "160640"
  },
  {
    "text": "driver this is a general suit of software that's designed to work on any vehicle from passenger",
    "start": "160640",
    "end": "167920"
  },
  {
    "text": "sedans to class 8 trucks now you may be wondering what does this hunk",
    "start": "167920",
    "end": "174000"
  },
  {
    "text": "of steel have to do with humans right the answer is actually a lot",
    "start": "174000",
    "end": "179680"
  },
  {
    "text": "let me show you so this is a hyperlapse of the aurora",
    "start": "179680",
    "end": "185040"
  },
  {
    "text": "driver hauling goods in texas without any human interventions it's really fascinating to see this",
    "start": "185040",
    "end": "191599"
  },
  {
    "text": "robot drive like a human alongside other humans in the road",
    "start": "191599",
    "end": "197040"
  },
  {
    "text": "in the real world engaging in novel interactions like merges lane changes stop signs unprotected left turns and",
    "start": "197040",
    "end": "203760"
  },
  {
    "text": "much more and keep in mind these are negotiations that the robot is doing with real humans in the real world",
    "start": "203760",
    "end": "209680"
  },
  {
    "text": "now this is not a one-off result our product is hauling goods for fedex every day",
    "start": "209680",
    "end": "215280"
  },
  {
    "text": "um it's pretty cool that in just nine months we went from never driving on a truck to this result",
    "start": "215280",
    "end": "222159"
  },
  {
    "text": "so what is the science behind this result right that is what i'm here to talk",
    "start": "222159",
    "end": "227360"
  },
  {
    "text": "about well let's begin by looking at any one snapshot and ask what is the optimal",
    "start": "227360",
    "end": "233840"
  },
  {
    "text": "action that the robot can do in a situation now you might think like myself in the",
    "start": "233840",
    "end": "239439"
  },
  {
    "text": "beginning why not just take the official driving handbook and apply that right",
    "start": "239439",
    "end": "245120"
  },
  {
    "text": "well that would not be very useful because most of the rules of driving aren't explicit",
    "start": "245120",
    "end": "250400"
  },
  {
    "text": "but rather implicit you know this orchestrated chaos that you see is what i call traffic back home",
    "start": "250400",
    "end": "257680"
  },
  {
    "text": "it's uh absolutely unclear to me if i can design a robot that can engineer a set of rules to",
    "start": "257680",
    "end": "264560"
  },
  {
    "text": "get repeat this feat um and that sort of leads to one of the",
    "start": "264560",
    "end": "270000"
  },
  {
    "start": "268000",
    "end": "334000"
  },
  {
    "text": "first messages which is explicitly programming such rules is tedious for instance in",
    "start": "270000",
    "end": "276720"
  },
  {
    "text": "self-driving the right rule depends very much on what other humans are doing but interestingly",
    "start": "276720",
    "end": "283360"
  },
  {
    "text": "we humans every day on the road are able to drive so implicitly programming robots by",
    "start": "283360",
    "end": "289919"
  },
  {
    "text": "imitating human driving seems like a right strategy so that's one of the key pieces that i'll talk",
    "start": "289919",
    "end": "295199"
  },
  {
    "text": "about the second piece is that robots are not",
    "start": "295199",
    "end": "301520"
  },
  {
    "text": "alone in the road take a look at this busy unprotected left it's full of pedestrians and cars",
    "start": "301520",
    "end": "308320"
  },
  {
    "text": "if the robot views these pedestrians simply as dynamic obstacles that it must avoid it can never make that turn",
    "start": "308320",
    "end": "315280"
  },
  {
    "text": "right it has to actively create an opening by negotiating with other actors and and predicting how they",
    "start": "315280",
    "end": "321520"
  },
  {
    "text": "will respond so to do this the robot has to understand the latent intent of other",
    "start": "321520",
    "end": "328479"
  },
  {
    "text": "human actors and communicate their own intent to them right",
    "start": "328479",
    "end": "333520"
  },
  {
    "text": "okay to to make things a little bit concrete let's quickly ground these problems in a more familiar and general",
    "start": "333520",
    "end": "340000"
  },
  {
    "start": "334000",
    "end": "475000"
  },
  {
    "text": "framework of a markov decision process so to recall an mdp is how we formalize sequential",
    "start": "340000",
    "end": "346960"
  },
  {
    "text": "decision making so you have you know state actions or rewards or as i like to think costs",
    "start": "346960",
    "end": "354160"
  },
  {
    "text": "and transitions so the state here is the position and velocity not just of the robot",
    "start": "354160",
    "end": "360479"
  },
  {
    "text": "but of every other human actor in the road and the",
    "start": "360479",
    "end": "365520"
  },
  {
    "text": "the important thing is that the cost function or the reward function it's latent we don't know what what the",
    "start": "365520",
    "end": "371759"
  },
  {
    "text": "reward function is and we know some parts of it but we don't know it in general um and we need to use imitation learning",
    "start": "371759",
    "end": "378560"
  },
  {
    "text": "to recover this cost function that makes the robot drive like a human",
    "start": "378560",
    "end": "384400"
  },
  {
    "text": "also the transition function is unknown because it depends on how the state of",
    "start": "384400",
    "end": "390000"
  },
  {
    "text": "the world of other humans evolve based on actions the robot takes",
    "start": "390000",
    "end": "395280"
  },
  {
    "text": "so we need to learn this function as well by predicting latent human intent",
    "start": "395280",
    "end": "402319"
  },
  {
    "text": "okay so yes um",
    "start": "402560",
    "end": "408000"
  },
  {
    "text": "yes so maybe why do you want to imitate humans humans can be pretty bad drivers",
    "start": "408000",
    "end": "414080"
  },
  {
    "text": "right yeah that's a great question so when i in this talk when i talk about imitating humans i talk about imitating our expert",
    "start": "414080",
    "end": "422160"
  },
  {
    "text": "human drivers who are you know trained um specialists who are driving",
    "start": "422160",
    "end": "428400"
  },
  {
    "text": "the car on the road and perhaps that is a practical decision that we make in the industry that you know",
    "start": "428400",
    "end": "435120"
  },
  {
    "text": "the drivers literally determine the product uh so the so you know they're they're trained specialists they",
    "start": "435120",
    "end": "441360"
  },
  {
    "text": "know how to drive a truck we just want our product to drive like them and they know when their driving is not good so",
    "start": "441360",
    "end": "446720"
  },
  {
    "text": "they're able to curate out those bad demonstrations but yeah in the real world it's a great question we've probably come to that at",
    "start": "446720",
    "end": "452160"
  },
  {
    "text": "the end when humans are not experts it becomes a bit more tricky",
    "start": "452160",
    "end": "457280"
  },
  {
    "text": "great question um anymore",
    "start": "457280",
    "end": "463400"
  },
  {
    "text": "all right let's let's keep going so yeah so with that let's return back to",
    "start": "464800",
    "end": "470240"
  },
  {
    "text": "the original picture so today we'll talk about two challenges um",
    "start": "470240",
    "end": "477440"
  },
  {
    "start": "475000",
    "end": "499000"
  },
  {
    "text": "first we'll talk about imitation learning so how do we interact with the human to learn the optimal policy",
    "start": "477440",
    "end": "482800"
  },
  {
    "text": "and second we'll talk about intent prediction how do we interactively forecast",
    "start": "482800",
    "end": "489039"
  },
  {
    "text": "human actions conditioned on the actions that the robot takes",
    "start": "489039",
    "end": "494720"
  },
  {
    "text": "okay so let's begin with the first challenge of imitation learning so i'll begin with a really simple",
    "start": "495919",
    "end": "501440"
  },
  {
    "text": "problem that's actually inspired by real world events at aurora so",
    "start": "501440",
    "end": "507120"
  },
  {
    "text": "let's say you want to learn how to lane change right so on the left is our truck and on the",
    "start": "507120",
    "end": "513919"
  },
  {
    "text": "right we have two cars and there's a slot between the cars and the oh general idea is that you want",
    "start": "513919",
    "end": "521599"
  },
  {
    "text": "to extract features that describe the role to describe the scene and you want to learn a function that",
    "start": "521599",
    "end": "527440"
  },
  {
    "text": "says should we lane change or not right so it's like a straight up binary classification so it should be pretty",
    "start": "527440",
    "end": "532959"
  },
  {
    "text": "easy let's think a little bit about the features you know you might have",
    "start": "532959",
    "end": "538640"
  },
  {
    "text": "what is the distance to the exit right um is there a disabled vehicle on the",
    "start": "538640",
    "end": "544560"
  },
  {
    "text": "shoulder how does traffic congestion look in the lanes these are some of the features that you might have",
    "start": "544560",
    "end": "551680"
  },
  {
    "text": "now it turns out one day one of your interns come in and says you know what",
    "start": "551680",
    "end": "556800"
  },
  {
    "text": "let's also add a feature that stores the decision we made at the previous time step because i think that's going to be",
    "start": "556800",
    "end": "561920"
  },
  {
    "text": "a very useful feature you said why not let's let's add that as as well so you add in the past action right whether you",
    "start": "561920",
    "end": "567920"
  },
  {
    "text": "lane changed or not in the previous cycle so a standard approach to imitation learning is called behavior cloning",
    "start": "567920",
    "end": "575360"
  },
  {
    "text": "which basically treats the problem as a supervised learning problem there are three simple steps first",
    "start": "575360",
    "end": "582080"
  },
  {
    "text": "go collect lots of data of humans lane changing so sometimes in some cases you see that the",
    "start": "582080",
    "end": "587360"
  },
  {
    "text": "humans don't change a lane because maybe the the the right lane is blocked and",
    "start": "587360",
    "end": "592560"
  },
  {
    "text": "sometimes you see that they take a lane opening and you go collect this data you train a classifier that maps",
    "start": "592560",
    "end": "598399"
  },
  {
    "text": "features to decisions against a binary classification problem and then you validate this policy on",
    "start": "598399",
    "end": "603680"
  },
  {
    "text": "some held out data and if it looks good deploy right",
    "start": "603680",
    "end": "608720"
  },
  {
    "text": "so you get an exciting slack message from your intern one night oh my god this classifier is amazing it's got 99",
    "start": "608720",
    "end": "615120"
  },
  {
    "text": "accuracy and before you say overfitting i added regularization so we're good to go right so you're stunned the",
    "start": "615120",
    "end": "622399"
  },
  {
    "text": "intern is overjoyed the team goes out for beers right next day you test this model",
    "start": "622399",
    "end": "629760"
  },
  {
    "text": "you think wow 99 this is going to be a great model so let's say the truck",
    "start": "629760",
    "end": "636160"
  },
  {
    "text": "is next to a car and decides to lane change and you find that a bit odd because seems like this actor is very",
    "start": "636160",
    "end": "642240"
  },
  {
    "text": "close seems like a tight lane change but whatever it's 99 it's good",
    "start": "642240",
    "end": "647839"
  },
  {
    "text": "so the truck begins a lane change but the after doesn't slow down they're still going at a high speed right",
    "start": "647920",
    "end": "654880"
  },
  {
    "text": "um and strangely your product doesn't abort the lane change it just keeps going",
    "start": "654880",
    "end": "661360"
  },
  {
    "text": "right um eventually it it almost runs the actor off the road",
    "start": "661360",
    "end": "668000"
  },
  {
    "text": "right what happened why didn't the the learner just simply",
    "start": "668000",
    "end": "675360"
  },
  {
    "text": "abort the lane change when it looked dangerous can anybody take a guess",
    "start": "675360",
    "end": "680079"
  },
  {
    "text": "[Music] a no yeah than the fact that they were going to do it",
    "start": "685040",
    "end": "690399"
  },
  {
    "text": "and then they decided not yeah excellent right should have had you in our team um",
    "start": "690399",
    "end": "697440"
  },
  {
    "text": "yeah that's exactly correct so let me let's try to break down so the answer was um",
    "start": "697440",
    "end": "702560"
  },
  {
    "text": "i should repeat this so the answer was that in the data the humans never uh",
    "start": "702560",
    "end": "708560"
  },
  {
    "text": "showed a recovery they either made that made up their mind and never did the lane change or they just did it",
    "start": "708560",
    "end": "714839"
  },
  {
    "text": "um so just to dig into that a little bit um if you looked at a training data again",
    "start": "714839",
    "end": "721279"
  },
  {
    "text": "you see these two clusters it's either don't change don't change don't change data no no no no or yes you see yes",
    "start": "721279",
    "end": "727680"
  },
  {
    "text": "right and what that cr that creates this sort of strong correlation between",
    "start": "727680",
    "end": "734320"
  },
  {
    "text": "the past action and the action at the current timestamp and before you think this is a bug this",
    "start": "734320",
    "end": "740399"
  },
  {
    "text": "is not a book humans drive smoothly of course the past is correlated to the current action",
    "start": "740399",
    "end": "746399"
  },
  {
    "text": "right um so other than the rare transition points",
    "start": "746399",
    "end": "751920"
  },
  {
    "text": "most of the data that you collect have this sort of strong correlation between two consecutive time steps",
    "start": "751920",
    "end": "759040"
  },
  {
    "text": "okay that's fine but then what happens at test time at test time",
    "start": "759040",
    "end": "764160"
  },
  {
    "text": "the robot just makes one mistake at the beginning but once it begins to go",
    "start": "764160",
    "end": "769920"
  },
  {
    "text": "it latches on to that mistake and continues going this is what we call feedback",
    "start": "769920",
    "end": "775600"
  },
  {
    "text": "right we have this bad feedback loop and what feedback does it forces the",
    "start": "775600",
    "end": "780959"
  },
  {
    "text": "robot into states that it has not seen a train time so since there's no label for the state the",
    "start": "780959",
    "end": "786240"
  },
  {
    "text": "robot doesn't know how to recover it's never seen a state where you know it's doing a lane change and things have gone",
    "start": "786240",
    "end": "792880"
  },
  {
    "text": "bad right the humans never entered that situation for whatever reason and so",
    "start": "792880",
    "end": "798639"
  },
  {
    "text": "feedback drives a shift between the training distribution",
    "start": "798639",
    "end": "804079"
  },
  {
    "text": "right where the human never made the mistake and a test distribution where are the robots clearly making",
    "start": "804079",
    "end": "809920"
  },
  {
    "text": "mistakes in getting into these situations we call this a covariate shift shift in the input",
    "start": "809920",
    "end": "815600"
  },
  {
    "text": "right and um theory shows that this leads to compounding errors on mathematically",
    "start": "815600",
    "end": "822720"
  },
  {
    "text": "known as o epsilon t square errors that grows quadratically in time",
    "start": "822720",
    "end": "829839"
  },
  {
    "start": "830000",
    "end": "860000"
  },
  {
    "text": "so feedback drives covariate shift this is the fundamental challenge that",
    "start": "830000",
    "end": "835199"
  },
  {
    "text": "differentiates imitation learning from mere supervised learning and more concretely if feedback breaks",
    "start": "835199",
    "end": "842480"
  },
  {
    "text": "an assumption in machine learning that data is id in fact the data here depends on your",
    "start": "842480",
    "end": "848639"
  },
  {
    "text": "learner your learner induces the state distribution it visits questions",
    "start": "848639",
    "end": "856120"
  },
  {
    "text": "okay cool um now in case you're wondering how common is this problem sounds made up",
    "start": "858480",
    "end": "864639"
  },
  {
    "start": "860000",
    "end": "932000"
  },
  {
    "text": "let me assure you it is a problem so these are just four papers from self-driving uh",
    "start": "864639",
    "end": "870480"
  },
  {
    "text": "companies and academia from the last few years that talk about this very issue",
    "start": "870480",
    "end": "877680"
  },
  {
    "text": "and it's not just the self-driving industry so back in my post-op days at udab we built a whole fleet of self-driving",
    "start": "878639",
    "end": "884720"
  },
  {
    "text": "cars called musher so this is a video of these cars driving around the hallways",
    "start": "884720",
    "end": "890000"
  },
  {
    "text": "and we were trying to program these these cars ground up from imitation learning um so on the top right is jonathan",
    "start": "890000",
    "end": "896399"
  },
  {
    "text": "spencer who was driving around these cars providing demonstrations on the bottom you see a visualization of",
    "start": "896399",
    "end": "901600"
  },
  {
    "text": "this loan policy where blue are good actions and red are bad",
    "start": "901600",
    "end": "906800"
  },
  {
    "text": "okay so when we roll the learner out it looks like it's doing a good job until it",
    "start": "906800",
    "end": "912800"
  },
  {
    "text": "crashes into the wall right it's the same underlying issue it makes a mistake enters a state that looks like",
    "start": "912800",
    "end": "920079"
  },
  {
    "text": "i'm driving straight first into a wall and oops i haven't seen the state before i'm going to continue you know going",
    "start": "920079",
    "end": "926959"
  },
  {
    "text": "straight and crashing to the wall right so i'm going to continue making mistakes um",
    "start": "926959",
    "end": "933759"
  },
  {
    "start": "932000",
    "end": "947000"
  },
  {
    "text": "okay so there seems to be a mountain of evidence for feedback driving covariate shift",
    "start": "933759",
    "end": "939519"
  },
  {
    "text": "so we thought probably this should be reproducible in standard benchmarks that we use in academia right",
    "start": "939519",
    "end": "947360"
  },
  {
    "start": "947000",
    "end": "1017000"
  },
  {
    "text": "turns out we are totally wrong so we took benchmarks from imitation learning",
    "start": "947920",
    "end": "953040"
  },
  {
    "text": "papers simply ran behavior cloning for long enough to drive down optimization errors",
    "start": "953040",
    "end": "958880"
  },
  {
    "text": "and the loan policy turned out to be pretty good the performance values were very close",
    "start": "958880",
    "end": "964880"
  },
  {
    "text": "to the expert so we thought okay maybe these environments are too easy",
    "start": "964880",
    "end": "970160"
  },
  {
    "text": "let's try more complex environments turns out literature has time and time again showed behavior cloning does",
    "start": "970160",
    "end": "976560"
  },
  {
    "text": "pretty well in fact i think there's a recent paper by florence at all that shows behavior cloning on these",
    "start": "976560",
    "end": "983680"
  },
  {
    "text": "deep d4 rl date benchmarks is pretty comparable to most alternatives not the",
    "start": "983680",
    "end": "989040"
  },
  {
    "text": "best but it's pretty good um so this was puzzling right",
    "start": "989040",
    "end": "995360"
  },
  {
    "text": "just convinced you feedback is a real problem in self-driving and our competitors have reported it",
    "start": "995360",
    "end": "1001920"
  },
  {
    "text": "but on standard benchmarks behavior cloning just seems to be fine so",
    "start": "1001920",
    "end": "1008079"
  },
  {
    "text": "what is the explanation is it to do with the data is it to do with the problem is it to do with the policy",
    "start": "1008079",
    "end": "1013759"
  },
  {
    "text": "or something else is going on so in times like this we need clarity",
    "start": "1013759",
    "end": "1020639"
  },
  {
    "start": "1017000",
    "end": "1113000"
  },
  {
    "text": "and what better way to get clarity than to think about the infinite data limit well you know to to take one part of the",
    "start": "1020639",
    "end": "1027199"
  },
  {
    "text": "equation out of it so we're going to take a slight detour we're going to i'm going to convince you",
    "start": "1027199",
    "end": "1033199"
  },
  {
    "text": "that covariate shift isn't just one thing it's actually three regimes some are easy some are hard and some are",
    "start": "1033199",
    "end": "1041520"
  },
  {
    "text": "just right okay right",
    "start": "1041520",
    "end": "1046959"
  },
  {
    "text": "so let's start with the easy setting here the human expert is realizable so",
    "start": "1046959",
    "end": "1053280"
  },
  {
    "text": "with infinite data you can make the error zero for example let's say you have a race",
    "start": "1053280",
    "end": "1059120"
  },
  {
    "text": "car and you put it on a track you see that the expert drives perfectly down the center of the track",
    "start": "1059120",
    "end": "1065360"
  },
  {
    "text": "right and so shown on the left is the say the distribution that the expert",
    "start": "1065360",
    "end": "1070640"
  },
  {
    "text": "induces and if you have infinite data your learner is just going to exactly drive",
    "start": "1070640",
    "end": "1076000"
  },
  {
    "text": "down loss to zero so you're going to see the two distributions match exactly and so the solution for whenever you're",
    "start": "1076000",
    "end": "1083280"
  },
  {
    "text": "in this regime the solution is simple just go get lots of data and if you do behavior cloning life is good",
    "start": "1083280",
    "end": "1090880"
  },
  {
    "text": "and you're in your policy matches the expert and we conjecture that",
    "start": "1090880",
    "end": "1095919"
  },
  {
    "text": "men that you know this might be the explanation that many of the benchmarks um simply fall into this easy regime",
    "start": "1095919",
    "end": "1102640"
  },
  {
    "text": "because the expert is either realizable or your network is expressive enough that it's able to explain the data well",
    "start": "1102640",
    "end": "1108960"
  },
  {
    "text": "enough",
    "start": "1108960",
    "end": "1111279"
  },
  {
    "start": "1113000",
    "end": "1289000"
  },
  {
    "text": "now what if the learner is not the expert is not realizable",
    "start": "1114320",
    "end": "1122160"
  },
  {
    "text": "it and the expert doesn't visit all the states for instance let's say our learner for whatever",
    "start": "1122160",
    "end": "1127919"
  },
  {
    "text": "reason can't perfectly drive this down the center of this track okay",
    "start": "1127919",
    "end": "1133280"
  },
  {
    "text": "once the learner spins out of the track it doesn't know what to do it's never seen how to recover so it's going to keep making mistakes",
    "start": "1133280",
    "end": "1140000"
  },
  {
    "text": "um good analogy from uh from from drew is you know think of the expert as roadrunner and the",
    "start": "1140000",
    "end": "1147280"
  },
  {
    "text": "learner as wiley curry if the expert never fell off a cliff",
    "start": "1147280",
    "end": "1152720"
  },
  {
    "text": "how will the learner know how to get back on right and this is precisely the flavor of the",
    "start": "1152720",
    "end": "1158320"
  },
  {
    "text": "problems that we saw you know the human is was for whatever reason not realizable",
    "start": "1158320",
    "end": "1163520"
  },
  {
    "text": "and we didn't visit all the states we call this the hard setting",
    "start": "1163520",
    "end": "1170640"
  },
  {
    "text": "right so in a seminal paper ross and back now showed that in this setting",
    "start": "1170640",
    "end": "1175919"
  },
  {
    "text": "you behavior cloning has no hope it's never it's it's going to hit this worst case or epsilon t square error",
    "start": "1175919",
    "end": "1184240"
  },
  {
    "text": "um recently our work uh kind of generalized this result with this is work with goku swami that showed that",
    "start": "1184240",
    "end": "1189919"
  },
  {
    "text": "entire class of off policy methods so you know methods where all you have is",
    "start": "1189919",
    "end": "1196320"
  },
  {
    "text": "um you know just a bunch of data and you have no interactive expert your you kind this is",
    "start": "1196320",
    "end": "1202080"
  },
  {
    "text": "the best you can do so you might be wondering okay when does",
    "start": "1202080",
    "end": "1207760"
  },
  {
    "text": "this setting occur um one one uh signature of this setting",
    "start": "1207760",
    "end": "1213679"
  },
  {
    "text": "is whenever the expert has access to more privileged information so",
    "start": "1213679",
    "end": "1219039"
  },
  {
    "text": "very quickly this is true in self-driving because the human often",
    "start": "1219039",
    "end": "1224159"
  },
  {
    "text": "has um has more context than perception can detect right maybe they can look at",
    "start": "1224159",
    "end": "1229280"
  },
  {
    "text": "a scene and tell when a driver is signaling them to go and our just perception hasn't caught up to it yet",
    "start": "1229280",
    "end": "1234640"
  },
  {
    "text": "that's that's one place where it happens another setting is when you're imitating",
    "start": "1234640",
    "end": "1239919"
  },
  {
    "text": "algorithms that are clairvoyant right think of an um you're imitating an algorithm that has access to more",
    "start": "1239919",
    "end": "1246960"
  },
  {
    "text": "information the full model and you simply can't do exactly what the algorithm did so i had a string of papers in my phd that",
    "start": "1246960",
    "end": "1253760"
  },
  {
    "text": "really try to analyze this problem and understand the consequences of this information gap so this is this is",
    "start": "1253760",
    "end": "1259520"
  },
  {
    "text": "another setting finally there's this recent paper from deepmind that talks about language sequence",
    "start": "1259520",
    "end": "1266400"
  },
  {
    "text": "models uh like chatbots and shows that they too can fall into this category",
    "start": "1266400",
    "end": "1272559"
  },
  {
    "text": "where they create loops of self-delusion because their actions feed back into their",
    "start": "1272559",
    "end": "1277919"
  },
  {
    "text": "next state and so on so the heart setting is a very real inescapable setting",
    "start": "1277919",
    "end": "1284559"
  },
  {
    "text": "and and we need to deal with it okay questions",
    "start": "1284559",
    "end": "1292480"
  },
  {
    "text": "so is it practical to like include in the training data like situations where your like expert makes mistakes but",
    "start": "1293600",
    "end": "1300320"
  },
  {
    "text": "corrects yeah it's a great question i'll actually come to that um in the big in the end um",
    "start": "1300320",
    "end": "1307360"
  },
  {
    "text": "and and there'll be a setting in the middle where we'll do that but for now let's assume that you know that's not the case",
    "start": "1307840",
    "end": "1314000"
  },
  {
    "text": "that uh the expert hasn't it has limited expert support so hasn't really made all this mistakes but yeah great question",
    "start": "1314000",
    "end": "1321600"
  },
  {
    "text": "anymore cool okay let's keep going uh so yeah",
    "start": "1322480",
    "end": "1328159"
  },
  {
    "text": "okay great there's a hard setting what can we do here um fortunately there's a solution and",
    "start": "1328159",
    "end": "1333679"
  },
  {
    "start": "1332000",
    "end": "1406000"
  },
  {
    "text": "we've known this for a long time now which is you have to interactively query the expert",
    "start": "1333679",
    "end": "1338880"
  },
  {
    "text": "so a very high level in a seminal paper rossital showed a very simple meta algorithm",
    "start": "1338880",
    "end": "1345520"
  },
  {
    "text": "called dagger which iterates over three simple steps roll out your current learner",
    "start": "1345520",
    "end": "1352640"
  },
  {
    "text": "go ask the human what the right action is wherever the learner visits take this data aggregate it and trained",
    "start": "1352640",
    "end": "1359200"
  },
  {
    "text": "the learner on the on the full data and if you do this these this this three",
    "start": "1359200",
    "end": "1365200"
  },
  {
    "text": "steps over and over again eventually the process stabilizes and you kind of recover a policy that's",
    "start": "1365200",
    "end": "1372080"
  },
  {
    "text": "pretty good that has the best achievable box of obsolete",
    "start": "1372080",
    "end": "1377200"
  },
  {
    "text": "and um you know recently we have generalized this setting and you know we just we realized dagger is just one",
    "start": "1377200",
    "end": "1383120"
  },
  {
    "text": "algorithm in the entire class of algorithms and this entire class of algorithms for example algorithms like aggravate",
    "start": "1383120",
    "end": "1389760"
  },
  {
    "text": "also fall into the setting they all enjoy this observant guarantee and they all look like you know take your current",
    "start": "1389760",
    "end": "1395360"
  },
  {
    "text": "learner go roll it out go ask the human what what to do in the state and go",
    "start": "1395360",
    "end": "1401600"
  },
  {
    "text": "add this data to your data set okay so if you're in the heart setting",
    "start": "1401600",
    "end": "1408400"
  },
  {
    "start": "1406000",
    "end": "1501000"
  },
  {
    "text": "you're out of luck you need an interactive expert you need to interactively ask the human hey",
    "start": "1408400",
    "end": "1413840"
  },
  {
    "text": "i'm in trouble what should i have done in this situation right but",
    "start": "1413840",
    "end": "1420159"
  },
  {
    "text": "is this really practical like to ask the human over and over to label",
    "start": "1420159",
    "end": "1425279"
  },
  {
    "text": "situations that the robot visits think back to when we were all learning to drive",
    "start": "1425279",
    "end": "1430799"
  },
  {
    "text": "um imagine you are doing all sorts of crazy things like going down the wrong side of the highway and asking your",
    "start": "1430799",
    "end": "1436640"
  },
  {
    "text": "driving instructor please help me um that was going to be a very that's going to be a very",
    "start": "1436640",
    "end": "1441919"
  },
  {
    "text": "petrifying experience for your instructor and this is this is a real problem like",
    "start": "1441919",
    "end": "1446960"
  },
  {
    "text": "it's unsafe for humans especially to give feedback to states for robot visits",
    "start": "1446960",
    "end": "1453200"
  },
  {
    "text": "and it's impractical instead how can we learn from more natural",
    "start": "1453200",
    "end": "1459520"
  },
  {
    "text": "human interactions let's say interventions um",
    "start": "1459520",
    "end": "1465600"
  },
  {
    "text": "so let's quickly try to think about how interventions work right",
    "start": "1465600",
    "end": "1471120"
  },
  {
    "text": "reconjecture that let's say humans have a mental model of a subspace of states that is good enough",
    "start": "1471120",
    "end": "1477919"
  },
  {
    "text": "right as long as the robot is in this state the human doesn't feel the need to correct",
    "start": "1477919",
    "end": "1484639"
  },
  {
    "text": "as the robot is about to leave the subspace the human intervenes and drives the robot back into this region and",
    "start": "1484799",
    "end": "1491440"
  },
  {
    "text": "gives back control okay that's the high level idea how do we turn this into a mathematical",
    "start": "1491440",
    "end": "1496720"
  },
  {
    "text": "algorithm for the learner to learn um",
    "start": "1496720",
    "end": "1502080"
  },
  {
    "start": "1501000",
    "end": "1854000"
  },
  {
    "text": "we had a very simple insight which is an intervention is telling us something about the human's latent value function",
    "start": "1502080",
    "end": "1509919"
  },
  {
    "text": "um what do i mean by that presumably presumably in their mind somewhere",
    "start": "1509919",
    "end": "1516080"
  },
  {
    "text": "humans have a latent value function that captures the cumulative cost of taking actions and acting optimally thereafter",
    "start": "1516080",
    "end": "1523760"
  },
  {
    "text": "right every piece of intervention gives us a tiny glimpse of this value function it's",
    "start": "1523760",
    "end": "1528960"
  },
  {
    "text": "basically saying is a state good or state is a state action good or state action bad",
    "start": "1528960",
    "end": "1535360"
  },
  {
    "text": "um and even non-interventions the fact that they're not intervening is telling us something that the robots probably know",
    "start": "1535360",
    "end": "1541840"
  },
  {
    "text": "in a good enough state so we have a very simple approach called expert intervention learning or eel that",
    "start": "1541840",
    "end": "1547679"
  },
  {
    "text": "exploits this insight so the way ul works is",
    "start": "1547679",
    "end": "1553520"
  },
  {
    "text": "we are going to model interventions as constraints on the latent action value right so let's formalize this very briefly",
    "start": "1553520",
    "end": "1562720"
  },
  {
    "text": "let's say we are solving for an action value q that map state action to",
    "start": "1562880",
    "end": "1568559"
  },
  {
    "text": "real values so the lower the value function the better given a set of expert demonstrations s",
    "start": "1568559",
    "end": "1575520"
  },
  {
    "text": "star and a star sample from p of expert the objective is to correctly classify",
    "start": "1575520",
    "end": "1581440"
  },
  {
    "text": "these demonstrations for example a star must be belong to the minimum of q the action",
    "start": "1581440",
    "end": "1586960"
  },
  {
    "text": "human takes must be the optimal action",
    "start": "1586960",
    "end": "1591039"
  },
  {
    "text": "next as the robot executes the policy we're going to end up with three types of constraints",
    "start": "1592080",
    "end": "1597440"
  },
  {
    "text": "stage one when the human is not intervening we can definitively say that the q",
    "start": "1597440",
    "end": "1602799"
  },
  {
    "text": "values are below some threshold delta right",
    "start": "1602799",
    "end": "1608080"
  },
  {
    "text": "stage two when the human takes over something bad happened right so at least",
    "start": "1608080",
    "end": "1613600"
  },
  {
    "text": "for that state action that had to be above above this threshold delta",
    "start": "1613600",
    "end": "1619600"
  },
  {
    "text": "um and finally as the human is recovering um they're acting locally in a locally",
    "start": "1619679",
    "end": "1625360"
  },
  {
    "text": "optimal way so you can you can specify that's the third constraint and you put them all together",
    "start": "1625360",
    "end": "1631039"
  },
  {
    "text": "and you end up with this sort of constraint optimization problem such that um and which you can solve",
    "start": "1631039",
    "end": "1636320"
  },
  {
    "text": "very efficiently in an online uh way to get a regret bound of epsilon t so this is",
    "start": "1636320",
    "end": "1643440"
  },
  {
    "text": "as good as what dagger would have given you so this is as good as if the human had shown you corrections",
    "start": "1643440",
    "end": "1648960"
  },
  {
    "text": "you could have also um you would have the same bound right",
    "start": "1648960",
    "end": "1654799"
  },
  {
    "text": "questions",
    "start": "1654799",
    "end": "1657200"
  },
  {
    "text": "okay cool um yeah um so in order to implement this expert",
    "start": "1666840",
    "end": "1673039"
  },
  {
    "text": "intervention learning at what do you actually have would you do you think for implementation of it you actually have",
    "start": "1673039",
    "end": "1678399"
  },
  {
    "text": "people who are monitoring the state of the robot or does the robot have to self-identify when it hits this threshold that it's no longer within",
    "start": "1678399",
    "end": "1685039"
  },
  {
    "text": "uh say its action here is less than this delta good that you've stated here okay that's a great question",
    "start": "1685039",
    "end": "1690880"
  },
  {
    "text": "the question was uh is a human monitoring the robot and saying um you",
    "start": "1690880",
    "end": "1696320"
  },
  {
    "text": "know whether the threshold was crossed or not as a robot self-reporting um for the for in this work",
    "start": "1696320",
    "end": "1702320"
  },
  {
    "text": "the human is intervening so the humans monitoring um whenever the human intervenes that act of their",
    "start": "1702320",
    "end": "1708000"
  },
  {
    "text": "intervention we we called that time point",
    "start": "1708000",
    "end": "1713200"
  },
  {
    "text": "when the threat when the q value went above the threshold right um but but but your question i take your",
    "start": "1713200",
    "end": "1719919"
  },
  {
    "text": "question that can can we actually think about robots self-reporting when they think they've hit an anomalous situation i think",
    "start": "1719919",
    "end": "1725760"
  },
  {
    "text": "that's a it's an interesting question um and and and there's some work that tries to uh",
    "start": "1725760",
    "end": "1732320"
  },
  {
    "text": "you know essentially have a robot self-report when it when it hit a normal situation",
    "start": "1732320",
    "end": "1737840"
  },
  {
    "text": "ship that data to the human and ask them to give feedback here was this bad or not but uh but in this work we are not doing",
    "start": "1737840",
    "end": "1744000"
  },
  {
    "text": "that here we are having an a humans explicitly intervening",
    "start": "1744000",
    "end": "1749039"
  },
  {
    "text": "cool okay i have a",
    "start": "1749039",
    "end": "1752960"
  },
  {
    "text": "yeah so in this case in this work uh the agent action value function was",
    "start": "1759120",
    "end": "1764840"
  },
  {
    "text": "um simply a two-layer mlp that's that's trying to map state actions to values",
    "start": "1764840",
    "end": "1771279"
  },
  {
    "text": "um there's some work that when we extended this work to",
    "start": "1771279",
    "end": "1776480"
  },
  {
    "text": "settings where you kind of are trying to learn cost functions there then this q value is parameterized as",
    "start": "1776480",
    "end": "1783440"
  },
  {
    "text": "the per time step cost function where and and your and and then you can kind",
    "start": "1783440",
    "end": "1788720"
  },
  {
    "text": "of approximate the q value by summing over the costs uh summing up the cost",
    "start": "1788720",
    "end": "1793760"
  },
  {
    "text": "over roll outs right so um so yeah that that's how we kind of",
    "start": "1793760",
    "end": "1798960"
  },
  {
    "text": "parameterize q anyway cool okay awesome",
    "start": "1798960",
    "end": "1805200"
  },
  {
    "text": "so uh how does this does this work uh how does eel do perform on the robot well so here you can see jonathan uh",
    "start": "1805200",
    "end": "1812399"
  },
  {
    "text": "kind of intervening as soon as the robot gets close to the wall and then returning back control so",
    "start": "1812399",
    "end": "1817760"
  },
  {
    "text": "you know he's he's continually doing this and in the early trials eel is just like behavior cloning",
    "start": "1817760",
    "end": "1824000"
  },
  {
    "text": "because of compounding errors it it you know it keeps failing but as more and more interven as it gets more",
    "start": "1824000",
    "end": "1830640"
  },
  {
    "text": "and more intervention it starts to get better and better and just after 60 seconds of trials",
    "start": "1830640",
    "end": "1836880"
  },
  {
    "text": "eel runs without any intervention at all which which is pretty cool compared to",
    "start": "1836880",
    "end": "1842880"
  },
  {
    "text": "you know how much time you know how much effort dagger would have taken",
    "start": "1842880",
    "end": "1848399"
  },
  {
    "text": "and and yeah on this particular setting um behavior cloning failed even after 24 demonstrations",
    "start": "1848480",
    "end": "1854799"
  },
  {
    "start": "1854000",
    "end": "1903000"
  },
  {
    "text": "um so just a very quick quantity look at quantitative plots right you can see eel is able to drive down errors with much",
    "start": "1854799",
    "end": "1861600"
  },
  {
    "text": "less queries waver cloning plateaus as we explained and dagger wastes a lot of",
    "start": "1861600",
    "end": "1868080"
  },
  {
    "text": "repeated effort by acquiring humans in obviously good states",
    "start": "1868080",
    "end": "1873679"
  },
  {
    "text": "and the closest baseline was this algorithm called a g dagger which is like eel",
    "start": "1873679",
    "end": "1879039"
  },
  {
    "text": "except it only uses explicit feedback it's not using this implicit feedback of no interventions means something good is",
    "start": "1879039",
    "end": "1885440"
  },
  {
    "text": "happening so we showed both practically and theoretically that's this is throwing away some crucial information so the way",
    "start": "1885440",
    "end": "1891840"
  },
  {
    "text": "i like to think about this is eel is trying to squeeze out as much juice as it can from the intervention signal",
    "start": "1891840",
    "end": "1898159"
  },
  {
    "text": "right um okay cool so",
    "start": "1898159",
    "end": "1904320"
  },
  {
    "start": "1903000",
    "end": "1951000"
  },
  {
    "text": "so in the heart setting um you know we were able to get around this problem",
    "start": "1904320",
    "end": "1909919"
  },
  {
    "text": "of non-realizable expert but we required an interactive expert that we had to",
    "start": "1909919",
    "end": "1915039"
  },
  {
    "text": "query on policy but um very briefly we are going to talk about a setting in the middle and this",
    "start": "1915039",
    "end": "1921519"
  },
  {
    "text": "is in relation to the question that was asked earlier so what if you still had a non-realizable",
    "start": "1921519",
    "end": "1927360"
  },
  {
    "text": "expert but one that was full support right",
    "start": "1927360",
    "end": "1932480"
  },
  {
    "text": "so the expert visits all the states now even in this setting behavior cloning is",
    "start": "1932480",
    "end": "1937519"
  },
  {
    "text": "pretty bad like it's um you know it because uh there's still compounding of errors",
    "start": "1937519",
    "end": "1943840"
  },
  {
    "text": "but you don't need an interactive human expert",
    "start": "1943840",
    "end": "1949279"
  },
  {
    "text": "in this setting instead you can get by with an interactive",
    "start": "1949279",
    "end": "1956240"
  },
  {
    "start": "1951000",
    "end": "2055000"
  },
  {
    "text": "simulator and and just with an interactive simulator you can kind of hit o epsilon t error right",
    "start": "1956240",
    "end": "1965440"
  },
  {
    "text": "yes maybe you're going to answer this yeah but similar to really doesn't align well with the real world is that kind of",
    "start": "1965440",
    "end": "1972000"
  },
  {
    "text": "the medium set up that you're talking about yeah that's a you're advanced here um",
    "start": "1972000",
    "end": "1977840"
  },
  {
    "text": "we're in a company so we can we have money we can make simulators um the jeanette's asking a good question which",
    "start": "1977840",
    "end": "1984080"
  },
  {
    "text": "is when the real world no one gives you a simulator i will maybe uh yeah maybe not touch it on this wait are",
    "start": "1984080",
    "end": "1990720"
  },
  {
    "text": "you claiming aurora as a simulator that is as good as the real world riding experience on an american highway",
    "start": "1990720",
    "end": "1997440"
  },
  {
    "text": "it's good enough for what we're going to do okay but uh not not like it has to be good enough as we'll see good enough for",
    "start": "1997440",
    "end": "2004320"
  },
  {
    "text": "the algorithm bounce to sort of work um so yeah good enough simulator let's put it with an epsilon yeah in the robot",
    "start": "2004320",
    "end": "2011279"
  },
  {
    "text": "example the video what was the input to the policy was it like a very high dimension",
    "start": "2011279",
    "end": "2016799"
  },
  {
    "text": "just yeah i'd mention image compress so just like an overhead image of like the occupancy map just so and then that's",
    "start": "2016799",
    "end": "2022880"
  },
  {
    "text": "kind of compressed so the action space is a set of primitives that it can take and",
    "start": "2022880",
    "end": "2027919"
  },
  {
    "text": "the input space is just a snapshot of like its local map",
    "start": "2027919",
    "end": "2033840"
  },
  {
    "text": "can you explain again why eil also performs staggered as much yeah so the",
    "start": "2034080",
    "end": "2039279"
  },
  {
    "text": "the outperform thing is with caveats it's how many times ill queries the human",
    "start": "2039279",
    "end": "2045360"
  },
  {
    "text": "versus how many times dagger requires the human to get with an epsilon performance block so",
    "start": "2045360",
    "end": "2051040"
  },
  {
    "text": "yeah so the the idea is eel is um okay good the idea is um dagger is",
    "start": "2051040",
    "end": "2059280"
  },
  {
    "start": "2055000",
    "end": "2224000"
  },
  {
    "text": "question querying the human even in states where you know there's it has a lot of labels",
    "start": "2059280",
    "end": "2064638"
  },
  {
    "text": "right because the dragon algorithm naively written just says roll out the learner on all",
    "start": "2064639",
    "end": "2069679"
  },
  {
    "text": "states go query the human eel is simply getting interventions",
    "start": "2069679",
    "end": "2074960"
  },
  {
    "text": "it's getting queries whenever the human whenever the robot makes a mistake so it's like imagine there's a bubble every",
    "start": "2074960",
    "end": "2081599"
  },
  {
    "text": "time the robot leaves the bubble it's only then is the human giving queries you're not you're not filling in",
    "start": "2081599",
    "end": "2087679"
  },
  {
    "text": "you're not carrying the human inside the bubble right whereas dagger squaring the human wear with the robot so that sort",
    "start": "2087679",
    "end": "2092960"
  },
  {
    "text": "of difference okay good quick question yes",
    "start": "2092960",
    "end": "2098880"
  },
  {
    "text": "um how does eel compare with like rough and not referenced and ranking based policy like when you compare it to like",
    "start": "2098880",
    "end": "2105200"
  },
  {
    "text": "okay this is a better policy than something that was previously seen ranking based in that sense because",
    "start": "2105200",
    "end": "2110560"
  },
  {
    "text": "you're also like it seems like it's been running like it reduces the house and half's basically strength",
    "start": "2110560",
    "end": "2116560"
  },
  {
    "text": "yeah i would say that um if you had a ranking-based approach that's trying different policies if we",
    "start": "2116560",
    "end": "2122400"
  },
  {
    "text": "didn't actually compare eel to you know show preference-based methods showing two",
    "start": "2122400",
    "end": "2127680"
  },
  {
    "text": "different policies and asking the human for feedback i would say that um you know um",
    "start": "2127680",
    "end": "2133190"
  },
  {
    "text": "[Music] i mean it's it's kind of difficult to compare these two approaches because eel",
    "start": "2133190",
    "end": "2138240"
  },
  {
    "text": "something that's running on policy whereas you could in theory be",
    "start": "2138240",
    "end": "2143839"
  },
  {
    "text": "super smart about exactly what two queries you choose to query the human to collapse uncertainty",
    "start": "2143839",
    "end": "2149440"
  },
  {
    "text": "in an efficient way but there are other challenges for example you know um",
    "start": "2149440",
    "end": "2155040"
  },
  {
    "text": "it you know you would have you would have to make assumptions about the you know how to choose two two",
    "start": "2155040",
    "end": "2161200"
  },
  {
    "text": "policies so you you reduce entropy so we didn't really compare with with the preference-based methods but i think",
    "start": "2161200",
    "end": "2167280"
  },
  {
    "text": "that's an interesting uh avenue to explore",
    "start": "2167280",
    "end": "2172040"
  },
  {
    "text": "cool okay sounds good so i'm just going to blaze through this",
    "start": "2172320",
    "end": "2178320"
  },
  {
    "text": "setting um it's a very high level so the setting again is a medium setting",
    "start": "2178320",
    "end": "2184560"
  },
  {
    "text": "and we've been thinking about this for a while now and the underlying idea is that",
    "start": "2184560",
    "end": "2189680"
  },
  {
    "text": "you can use an interactive simulator to build the distribution that the learner visits that's the high level idea so in this",
    "start": "2189680",
    "end": "2196480"
  },
  {
    "text": "setting the expert gives you a bunch of demonstration and then just walks away by using the simulator",
    "start": "2196480",
    "end": "2202720"
  },
  {
    "text": "you're building um the distribution the learner induces and",
    "start": "2202720",
    "end": "2207920"
  },
  {
    "text": "the goal is to simply you know match these two distributions and",
    "start": "2207920",
    "end": "2213040"
  },
  {
    "text": "you know you can think of that them as specific specifically matching performance metrics uh performance",
    "start": "2213040",
    "end": "2218720"
  },
  {
    "text": "moments to get an oh epsilon t guarantee that's the high level idea so",
    "start": "2218720",
    "end": "2224480"
  },
  {
    "text": "um you know interestingly there is an entire spectrum of",
    "start": "2224480",
    "end": "2230480"
  },
  {
    "text": "moment matching algorithms in this setting that i'm not going to be able to go into details today but",
    "start": "2230480",
    "end": "2235599"
  },
  {
    "text": "you know on the right hand side you have algorithms that match what we call reward moments",
    "start": "2235599",
    "end": "2242880"
  },
  {
    "text": "so you're trying to find a reward function that discriminates between the learner and the expert",
    "start": "2242880",
    "end": "2248160"
  },
  {
    "text": "um all inverse reward learning algorithms fall into this setting um you know max",
    "start": "2248160",
    "end": "2253200"
  },
  {
    "text": "and irl gail we have our own algorithm a drill that minimizes ipm metrics all",
    "start": "2253200",
    "end": "2258480"
  },
  {
    "text": "fall into the setting the catch is it's not talked about but you need an india planning oracle that's",
    "start": "2258480",
    "end": "2265440"
  },
  {
    "text": "able to explore all possible actions so this exponential space to to figure out how to match",
    "start": "2265440",
    "end": "2272079"
  },
  {
    "text": "trajectories with the with the human so that that's a catch on the left you have matching value",
    "start": "2272079",
    "end": "2280000"
  },
  {
    "text": "moments so the idea is you're trying to find a value function that discriminates between the",
    "start": "2280000",
    "end": "2287200"
  },
  {
    "text": "expert and the learner and we have an algorithm alice that",
    "start": "2287200",
    "end": "2292800"
  },
  {
    "text": "essentially does this but you know the trick is you have to adjust for covariate shift",
    "start": "2292800",
    "end": "2298480"
  },
  {
    "text": "and you can you can do that by re-weighting data using density ratio methods and",
    "start": "2298480",
    "end": "2304000"
  },
  {
    "text": "so you know you don't need to do planning for alice but you need lots and lots of",
    "start": "2304000",
    "end": "2309520"
  },
  {
    "text": "samples to estimate the density ratio perfectly and there's a whole",
    "start": "2309520",
    "end": "2315599"
  },
  {
    "text": "set of things you can do in the middle where you can try to mix and match these methods so you can do k steps of planning",
    "start": "2315599",
    "end": "2321440"
  },
  {
    "text": "and then density ratio your terminal state to",
    "start": "2321440",
    "end": "2326800"
  },
  {
    "text": "essentially get the robot to visit a set of just states that look a lot like the humans",
    "start": "2326800",
    "end": "2332240"
  },
  {
    "text": "right the nice thing is all of these algorithms guarantee this o epsilon t which is in",
    "start": "2332240",
    "end": "2338640"
  },
  {
    "text": "some sense the best you could do um but you know depending on you know depending on how much you want",
    "start": "2338640",
    "end": "2344880"
  },
  {
    "text": "how much samples you have versus um how much time you want to spend with your planning oracle you can choose some",
    "start": "2344880",
    "end": "2351040"
  },
  {
    "text": "setting in the middle yeah so the planning article is uh if any",
    "start": "2351040",
    "end": "2357040"
  },
  {
    "text": "inverse reward learning method needs a planner given a reward function",
    "start": "2357040",
    "end": "2362160"
  },
  {
    "text": "it needs to find the optimal policy right so you need to call a planner that searches over all possible actions to give you",
    "start": "2362160",
    "end": "2367839"
  },
  {
    "text": "the optimal policy so that's what we've got it's not in like the generative setting like not in the gale setting",
    "start": "2367839",
    "end": "2374240"
  },
  {
    "text": "like in the policy well you can say gail is running policy gradients right but um",
    "start": "2374240",
    "end": "2381359"
  },
  {
    "text": "you know you can come up and i mean ultimately you can create mdps where it has to visit every action of every state",
    "start": "2381359",
    "end": "2387119"
  },
  {
    "text": "to actually find the optimal policy right given a reward function and that's kind of hidden but that's a that's a",
    "start": "2387119",
    "end": "2392800"
  },
  {
    "text": "real price that you pay um when you use this method",
    "start": "2392800",
    "end": "2397839"
  },
  {
    "text": "okay um any more questions",
    "start": "2397839",
    "end": "2402000"
  },
  {
    "text": "cool um all right so we could move on to the second half so yeah you know we that",
    "start": "2404000",
    "end": "2409520"
  },
  {
    "text": "sort of completes our story you know we talked about this three regimes of covariate shift easy medium",
    "start": "2409520",
    "end": "2415680"
  },
  {
    "start": "2411000",
    "end": "2596000"
  },
  {
    "text": "and hard but the easy setting just go to behavior cloning but the hard setting",
    "start": "2415680",
    "end": "2421200"
  },
  {
    "text": "you need to you need an interactive expert but the interesting setting is a medium there's a lot of research in this",
    "start": "2421200",
    "end": "2426480"
  },
  {
    "text": "setting if you have a simulator if you can somehow if you have a dynamics model",
    "start": "2426480",
    "end": "2432079"
  },
  {
    "text": "imperfect ones as well you have some hope of you know not querying an expert online but still",
    "start": "2432079",
    "end": "2437440"
  },
  {
    "text": "trying to estimate your uh distribution yeah so i guess following on the um",
    "start": "2437440",
    "end": "2445440"
  },
  {
    "text": "question if you have say like a driving simulator that has good models of say",
    "start": "2445440",
    "end": "2450640"
  },
  {
    "text": "how the other vehicles are going to respond right which would be something you need to have a good driving simulator why wouldn't you just use that",
    "start": "2450640",
    "end": "2457359"
  },
  {
    "text": "for like online planning or something like this that's a great question um i think um",
    "start": "2457359",
    "end": "2463119"
  },
  {
    "text": "you know there's you can ask there's two different requirements of a good simulator to do",
    "start": "2463119",
    "end": "2469200"
  },
  {
    "text": "you know implement these kind of methods and something that's going to drive your car on the road you know there's safety",
    "start": "2469200",
    "end": "2474880"
  },
  {
    "text": "uh verification um constraints when you're actually deploying the product on the road which you may be okay with in the simulator it",
    "start": "2474880",
    "end": "2481760"
  },
  {
    "text": "doesn't have to do doesn't have to get the crazy edge cases correct but maybe your product has to",
    "start": "2481760",
    "end": "2487119"
  },
  {
    "text": "and so i think those two kind of separate yes",
    "start": "2487119",
    "end": "2492520"
  },
  {
    "text": "uh can the simulator model human intent yeah uh the simulator can i mean",
    "start": "2495440",
    "end": "2500960"
  },
  {
    "text": "uh it it can it can it can because you know um so i'm assuming by human intent you mean",
    "start": "2500960",
    "end": "2508000"
  },
  {
    "text": "whether the humans trying to like lane change or not or go ahead or not yeah so the simulators that we use are we call",
    "start": "2508000",
    "end": "2514319"
  },
  {
    "text": "them smart actors and they can they can kind of model human intent to respond to things that the human does to",
    "start": "2514319",
    "end": "2521200"
  },
  {
    "text": "to what the robot does right",
    "start": "2521200",
    "end": "2524560"
  },
  {
    "text": "let's say a car of like avoid things worked into then why not just use the",
    "start": "2526319",
    "end": "2531599"
  },
  {
    "text": "what's the algorithm being used to simulate the the simulator kind of has a bit of an",
    "start": "2531599",
    "end": "2537280"
  },
  {
    "text": "advantage it kind of knows it's created the setting so when someone creates a simulation the simulation sort of knows",
    "start": "2537280",
    "end": "2544079"
  },
  {
    "text": "the scenario knows the context and so it's actually pretty it's contrived enough where the",
    "start": "2544079",
    "end": "2549599"
  },
  {
    "text": "simulator can actually um you know has access to a lot of lot more information um to you",
    "start": "2549599",
    "end": "2556880"
  },
  {
    "text": "know create intelligent actors but it's quite different when you're when you're out in the real world and you don't know what setting you're",
    "start": "2556880",
    "end": "2562720"
  },
  {
    "text": "actually in don't know that you're in a contested merge or contested lane change right so then it can get kind of tricky",
    "start": "2562720",
    "end": "2569599"
  },
  {
    "text": "so interest of time i'm just going to accelerate um to the second half of the talk",
    "start": "2569599",
    "end": "2575920"
  },
  {
    "text": "so yeah i think this set of videos videos just show that you know this this",
    "start": "2575920",
    "end": "2581200"
  },
  {
    "text": "the things we talked about today runs in the real world so you have um you know we have on-road interventions that are",
    "start": "2581200",
    "end": "2587920"
  },
  {
    "text": "then turned into simulations that then the model uses to make better models and",
    "start": "2587920",
    "end": "2594400"
  },
  {
    "text": "just it works and yeah i mean just quickly to touch on",
    "start": "2594400",
    "end": "2599440"
  },
  {
    "start": "2596000",
    "end": "2661000"
  },
  {
    "text": "open questions there are a lot of open questions especially in the medium setting for example you know you're looking",
    "start": "2599440",
    "end": "2606400"
  },
  {
    "text": "theoretically at what are minimax optimal algorithms we are looking at something that's",
    "start": "2606400",
    "end": "2612160"
  },
  {
    "text": "become increasingly important which is the role of confounds in the data you know",
    "start": "2612160",
    "end": "2618240"
  },
  {
    "text": "human has a lot of unobserved variables that influence their actions and so",
    "start": "2618240",
    "end": "2623520"
  },
  {
    "text": "you know how do you do imitation learning under confounds and there was a question earlier about",
    "start": "2623520",
    "end": "2629040"
  },
  {
    "text": "what if your experts aren't optimal what if they're suboptimal so um these you know",
    "start": "2629040",
    "end": "2634800"
  },
  {
    "text": "all three of these problems are pretty interesting and and uh we were kind of uh thinking about them",
    "start": "2634800",
    "end": "2640880"
  },
  {
    "text": "but yeah uh an interest of time let's talk about the second half of the talk which will be shorter um",
    "start": "2640880",
    "end": "2646800"
  },
  {
    "text": "that's about the second half is about intent prediction which is how do we",
    "start": "2646800",
    "end": "2651839"
  },
  {
    "text": "interactively forecast human action so we talked a little bit about intent uh we're going to formalize this in in",
    "start": "2651839",
    "end": "2658640"
  },
  {
    "text": "this in the second half okay so like we did before let's start",
    "start": "2658640",
    "end": "2664880"
  },
  {
    "start": "2661000",
    "end": "3006000"
  },
  {
    "text": "with a simple example uh that i really like by the way uh merges so when we all learn how to drive",
    "start": "2664880",
    "end": "2671680"
  },
  {
    "text": "this is a very stressful thing merging for the first time um how does a robot um",
    "start": "2671680",
    "end": "2677760"
  },
  {
    "text": "so how does a robot kind of negotiate a merge right so we have a robot truck in the right of way lane and we have a car",
    "start": "2677760",
    "end": "2684720"
  },
  {
    "text": "that's merging in and let's say we've already solved",
    "start": "2684720",
    "end": "2690160"
  },
  {
    "text": "limitation learning so we already have a good cost function by imitation learning",
    "start": "2690160",
    "end": "2695359"
  },
  {
    "text": "now we have to plan with this robot we need to so to do that we need to predict the",
    "start": "2695359",
    "end": "2702000"
  },
  {
    "text": "future five second motion of what the other merging actor is going to do and then we call let's say an mpc",
    "start": "2702000",
    "end": "2708960"
  },
  {
    "text": "planner that that computes the optimum trajectory so",
    "start": "2708960",
    "end": "2714800"
  },
  {
    "text": "really all we need is a good enough forecast of the other actor right",
    "start": "2714800",
    "end": "2720880"
  },
  {
    "text": "how do we get such forecasts so the traditional approach in industry",
    "start": "2720880",
    "end": "2726720"
  },
  {
    "text": "is to treat forecasting as a cascaded step after perception and before motion planning",
    "start": "2726720",
    "end": "2733119"
  },
  {
    "text": "you know recent methods have improved upon this by joining perception and in forecasting in a differentiable internet",
    "start": "2733119",
    "end": "2739680"
  },
  {
    "text": "manner but crucially still today motion planning is viewed as a downstream",
    "start": "2739680",
    "end": "2745280"
  },
  {
    "text": "consumer of forecasts so let's think through what will happen as a result of this right",
    "start": "2745280",
    "end": "2752079"
  },
  {
    "text": "so let's say we go ahead and collect a lot of data to train our forecasting model",
    "start": "2752079",
    "end": "2757760"
  },
  {
    "text": "so in our training data 50 of the time the human merges after the car and 50 of",
    "start": "2757760",
    "end": "2763440"
  },
  {
    "text": "the time the human merges before the car we then train the latest greatest forecasting model to predict the future",
    "start": "2763440",
    "end": "2771760"
  },
  {
    "text": "this is what we get right this forecast looks like it has just",
    "start": "2771760",
    "end": "2777359"
  },
  {
    "text": "huge it's like a big blob in front of the truck right it has a huge variance",
    "start": "2777359",
    "end": "2783760"
  },
  {
    "text": "and the planner looks at this freaks out and says oh my god i have to break to avoid this blob",
    "start": "2783760",
    "end": "2789760"
  },
  {
    "text": "um what happened",
    "start": "2789760",
    "end": "2794079"
  },
  {
    "text": "the planner was like predicting for like a worst case scenario of where like this variance is going to",
    "start": "2798480",
    "end": "2803839"
  },
  {
    "text": "be like closest to the truck and so it's trying to avoid the largest distribution of where it's spread yeah so",
    "start": "2803839",
    "end": "2809520"
  },
  {
    "text": "yeah so the answer is the planner is trying to avoid the worst-case scenario which is great but why does the forecast",
    "start": "2809520",
    "end": "2815119"
  },
  {
    "text": "look so terrible",
    "start": "2815119",
    "end": "2817838"
  },
  {
    "text": "the planner is not taking into account that the human will react to its behavior yeah okay so you all should",
    "start": "2820319",
    "end": "2826480"
  },
  {
    "text": "help us um great yeah so um as you might have guessed there are two",
    "start": "2826480",
    "end": "2832079"
  },
  {
    "text": "distinct modes in the data right um there's mode a where",
    "start": "2832079",
    "end": "2838160"
  },
  {
    "text": "the the the robot merges after the car and",
    "start": "2838160",
    "end": "2843440"
  },
  {
    "text": "there's more b where the robot merges before the car and when we just train the forecasting model we marginalize over what the what",
    "start": "2843440",
    "end": "2851440"
  },
  {
    "text": "the what the robot is doing right and so we get this distribution this sort of",
    "start": "2851440",
    "end": "2857280"
  },
  {
    "text": "marginalizing over these two modes and then predicting this huge variance and as a result the planet freaks out",
    "start": "2857280",
    "end": "2862720"
  },
  {
    "text": "and breaks success excessively so yeah the key observation as you pointed out is that",
    "start": "2862720",
    "end": "2869839"
  },
  {
    "text": "the robot what the robot does depends on other humans",
    "start": "2869839",
    "end": "2876000"
  },
  {
    "text": "but what humans do depend on the robot and so",
    "start": "2876000",
    "end": "2882400"
  },
  {
    "text": "this turns out into turns into a chicken or egg problem to",
    "start": "2882400",
    "end": "2887440"
  },
  {
    "text": "do planning you need forecasts but to do forecasting you need a",
    "start": "2887440",
    "end": "2892480"
  },
  {
    "text": "you need the plan you need what the robot's going to do",
    "start": "2892480",
    "end": "2896640"
  },
  {
    "text": "so here's an urban example of the robot taking an unprotected left turn",
    "start": "2898400",
    "end": "2903440"
  },
  {
    "text": "with vehicles bicyclists and pedestrians again the same situation that we saw",
    "start": "2903440",
    "end": "2908559"
  },
  {
    "text": "before comes up where you know the robot's motion depends on what the actor turning right is going to",
    "start": "2908559",
    "end": "2915119"
  },
  {
    "text": "do the actor turning right is looking at other pedestrians and this oncoming car that's not sure what we're going to do so this is",
    "start": "2915119",
    "end": "2921280"
  },
  {
    "text": "huge complex dependencies that that involve the robot in the middle",
    "start": "2921280",
    "end": "2928880"
  },
  {
    "text": "so so i guess the the the observation is",
    "start": "2928880",
    "end": "2934240"
  },
  {
    "text": "that all actors in a scene influence each other and the robot is simply an actor that we",
    "start": "2934240",
    "end": "2939680"
  },
  {
    "text": "get to control but there are other humans in the scene so in some sense as you might have intuited",
    "start": "2939680",
    "end": "2946960"
  },
  {
    "text": "we need to jointly reason over all the actors to forecast them as well as",
    "start": "2946960",
    "end": "2954640"
  },
  {
    "text": "subsequently um computer plan right",
    "start": "2954640",
    "end": "2960240"
  },
  {
    "text": "but wait the space of joint trajectories is pretty big like think of a single",
    "start": "2960240",
    "end": "2967200"
  },
  {
    "text": "trajectory that's a continuous sequence of um you know two dimensional vector of waypoints",
    "start": "2967200",
    "end": "2973599"
  },
  {
    "text": "now you have n actors so you're talking about a combinatorial space of you know futures",
    "start": "2973599",
    "end": "2979520"
  },
  {
    "text": "and moreover this still is not addressing our chicken or egg problem right",
    "start": "2979520",
    "end": "2985119"
  },
  {
    "text": "unless you want to forecast the the the planner which is a different discussion",
    "start": "2985119",
    "end": "2990800"
  },
  {
    "text": "so so our key insight is that that made this problem tractable",
    "start": "2990800",
    "end": "2996800"
  },
  {
    "text": "is that it's actually misleading to think of a continuous space there's actually an underlying discrete",
    "start": "2996800",
    "end": "3002960"
  },
  {
    "text": "grammar that we are reasoning about and we call these grammar modes um",
    "start": "3002960",
    "end": "3009839"
  },
  {
    "start": "3006000",
    "end": "3044000"
  },
  {
    "text": "so it's pretty simple there are three fundamental modes",
    "start": "3009839",
    "end": "3015920"
  },
  {
    "text": "you know given two actors you look at their forecasts and you say either you know either either they're",
    "start": "3015920",
    "end": "3021920"
  },
  {
    "text": "going to have some conflict and if if so somebody goes first or they're not going to have any conflict so a used to b b",
    "start": "3021920",
    "end": "3029040"
  },
  {
    "text": "used to a or a and b just don't yield each other and and",
    "start": "3029040",
    "end": "3034559"
  },
  {
    "text": "it turns out and this has worked with mccall at aurora that pretty much all of self-driving can be described using this",
    "start": "3034559",
    "end": "3041280"
  },
  {
    "text": "fundamental discrete grammar you know so for instance uh take this merging",
    "start": "3041280",
    "end": "3046960"
  },
  {
    "start": "3044000",
    "end": "3065000"
  },
  {
    "text": "scenario that we looked at before you can say something like you can describe the scenario really well by",
    "start": "3046960",
    "end": "3052559"
  },
  {
    "text": "saying you know the robot r used to a and this actor b used to r let's say i knew",
    "start": "3052559",
    "end": "3060000"
  },
  {
    "text": "these i knew this is the mode that we want the future to be in um",
    "start": "3060000",
    "end": "3066880"
  },
  {
    "text": "if we know this knowing this mode we can actually forecast all three actors",
    "start": "3067119",
    "end": "3072400"
  },
  {
    "text": "and and and a single mode corresponds to a single basin of forecasts so",
    "start": "3072400",
    "end": "3078960"
  },
  {
    "text": "you know more generally if you were to write down the value function for all three actors",
    "start": "3078960",
    "end": "3084160"
  },
  {
    "text": "that value function is multi-modal but um specifying the modes",
    "start": "3084160",
    "end": "3090400"
  },
  {
    "text": "saying r used to a and b goes to r specifies a single mode of that holy function",
    "start": "3090400",
    "end": "3097480"
  },
  {
    "text": "right and this works for more complicated scenes as well so let's say we are lane changing simultaneously with",
    "start": "3098640",
    "end": "3105200"
  },
  {
    "text": "other actors knowing the mode defines the slot that the robot gets",
    "start": "3105200",
    "end": "3111280"
  },
  {
    "text": "into and um so you know in fact the forecasts need only be",
    "start": "3111280",
    "end": "3117200"
  },
  {
    "text": "accurate enough for the robot to safely and predictably get into that slot okay so how do we",
    "start": "3117200",
    "end": "3123119"
  },
  {
    "text": "infer what modes various actors are likely to choose based on choices by the robot",
    "start": "3123119",
    "end": "3129040"
  },
  {
    "text": "so let's look at the scene before and let's abstract it away with a graph",
    "start": "3129040",
    "end": "3135200"
  },
  {
    "text": "right imagine each actor as a node in the graph the edges of the graph tell us relationships like is actor a yielding",
    "start": "3135200",
    "end": "3142720"
  },
  {
    "text": "to actor b so given a set of decisions made by the robot or modes chosen by the robot",
    "start": "3142720",
    "end": "3150240"
  },
  {
    "text": "we are going to infer what um what modes other actors likely are",
    "start": "3150240",
    "end": "3156400"
  },
  {
    "text": "choosing and we're going to do this by passing messages so for instance we can look at the scene",
    "start": "3156400",
    "end": "3163280"
  },
  {
    "text": "and say that um you know the actor turning right wants to yield to the both the",
    "start": "3163280",
    "end": "3168559"
  },
  {
    "text": "pedestrians and as a result the robot must yield to this actor and finally the oncoming car um",
    "start": "3168559",
    "end": "3176000"
  },
  {
    "text": "is actually turning left and so it'll likely not conflict with the robot so they should both not yield to each",
    "start": "3176000",
    "end": "3181680"
  },
  {
    "text": "other and the nice thing is once you've figured out this mode",
    "start": "3181680",
    "end": "3187839"
  },
  {
    "text": "you can forecast each actor independently given modes and once you have the forecast you can",
    "start": "3187839",
    "end": "3193280"
  },
  {
    "text": "go ahead and call your favorite mpc algorithm to get a plan so",
    "start": "3193280",
    "end": "3199359"
  },
  {
    "text": "the way we generate this is by um you know we we uh put this together",
    "start": "3199359",
    "end": "3207280"
  },
  {
    "start": "3200000",
    "end": "3252000"
  },
  {
    "text": "using a multi-stage graph neural network which we call geometric transformer net",
    "start": "3207280",
    "end": "3213119"
  },
  {
    "text": "so the transformer here refers to the aggregation step in the graph neural network",
    "start": "3213119",
    "end": "3219119"
  },
  {
    "text": "the high level idea is that you have a graph neural network where the input are node features state and history of",
    "start": "3219119",
    "end": "3226079"
  },
  {
    "text": "each actor and edge features transforming one actor to another frame",
    "start": "3226079",
    "end": "3232079"
  },
  {
    "text": "we then encode these features and do k rounds of message passing",
    "start": "3232079",
    "end": "3238319"
  },
  {
    "text": "and then there are two outputs um what is the mode that each edge",
    "start": "3238319",
    "end": "3243839"
  },
  {
    "text": "corresponds to and then predicting t-step futures for each actor in the scene",
    "start": "3243839",
    "end": "3249280"
  },
  {
    "text": "so um yeah and and and so when you put",
    "start": "3249280",
    "end": "3255599"
  },
  {
    "text": "everything together this is how the scene kind of plays out you know we can see that by reasoning about different modes the robot's able",
    "start": "3255599",
    "end": "3262079"
  },
  {
    "text": "to kind of confidently go through this intersection it's also interesting in the scene you",
    "start": "3262079",
    "end": "3268000"
  },
  {
    "text": "see our cyclists suddenly pop out from an occlusion and and that means that this inference",
    "start": "3268000",
    "end": "3273040"
  },
  {
    "text": "has to be running rapidly in real time because it has to detect the sector figure out what mode it belongs to and",
    "start": "3273040",
    "end": "3278160"
  },
  {
    "text": "then forecast its future within 10 hertz right",
    "start": "3278160",
    "end": "3283119"
  },
  {
    "text": "okay um questions yeah is there a reason that there's no mode",
    "start": "3283839",
    "end": "3288960"
  },
  {
    "text": "for yield yield when both yield to each other and kind of get in a standstill",
    "start": "3288960",
    "end": "3294000"
  },
  {
    "text": "yeah yeah that's a that's a great question um we often don't",
    "start": "3294000",
    "end": "3299760"
  },
  {
    "text": "um you know we we're we're often at least at this point we're not modeling places",
    "start": "3299760",
    "end": "3304799"
  },
  {
    "text": "like eel deal where two actors come to a stop because they're not able to communicate where i think",
    "start": "3304799",
    "end": "3311599"
  },
  {
    "text": "we're trying to you know the way we think about the scene is that you know there's a flow of traffic and for for that reason",
    "start": "3311599",
    "end": "3318240"
  },
  {
    "text": "eventually the modes resolve themselves and and and falls into one of the two basins where one actor goes and the",
    "start": "3318240",
    "end": "3323680"
  },
  {
    "text": "other actor stops uh but uh yeah certainly you can have intermediate states where you",
    "start": "3323680",
    "end": "3330640"
  },
  {
    "text": "where you know two actors both might be stopping to each other for example at all way stops but right now we don't",
    "start": "3330640",
    "end": "3336000"
  },
  {
    "text": "model it you're modeling are they sort of",
    "start": "3336000",
    "end": "3342720"
  },
  {
    "text": "described by human engineers deciding what these modes are or are you extracting that somehow from a bigger",
    "start": "3342720",
    "end": "3348480"
  },
  {
    "text": "trajectory forecasting distribution yeah so we have data i think the way we extract the mods is",
    "start": "3348480",
    "end": "3353680"
  },
  {
    "text": "you look at 10 second future then you you have an auto labeler that figures out what happened what mode was followed",
    "start": "3353680",
    "end": "3358960"
  },
  {
    "text": "and then that's used as a source of label so i think if you have a complicated",
    "start": "3358960",
    "end": "3364640"
  },
  {
    "text": "scene and maybe you observe it 10 times let's say maybe it will not always be the same set of modes but maybe there's",
    "start": "3364640",
    "end": "3370240"
  },
  {
    "text": "like two kind of possibilities how it ends up right yeah it looks to me at least that this specific architecture",
    "start": "3370240",
    "end": "3375760"
  },
  {
    "text": "can only ever predict one mode right so do you think there's any work on an architecture outputting",
    "start": "3375760",
    "end": "3380880"
  },
  {
    "text": "multiple sets of modes with maybe some kind of probability yeah so actually what i said is the architecture outputs",
    "start": "3380880",
    "end": "3386559"
  },
  {
    "text": "a probability for each edge of yielding reverse yielding or ailing to be or building to a",
    "start": "3386559",
    "end": "3392400"
  },
  {
    "text": "um so there is a pairwise independence uh joint distribution that it's modeling",
    "start": "3392400",
    "end": "3397839"
  },
  {
    "text": "but you're right um we're you know you it can happen that you need to",
    "start": "3397839",
    "end": "3404400"
  },
  {
    "start": "3401000",
    "end": "3599000"
  },
  {
    "text": "capture multiple possible interactions that can play out and then that's some active work that's what's going on but",
    "start": "3404400",
    "end": "3409920"
  },
  {
    "text": "uh just doing this gets you a lot of mileage so yeah i think we're running out of time so i'm",
    "start": "3409920",
    "end": "3416000"
  },
  {
    "text": "just going to skip to the end unfortunately this is you know",
    "start": "3416000",
    "end": "3421040"
  },
  {
    "text": "there's a lot of cool videos of this sort of you know intent prediction working across various scenes",
    "start": "3421040",
    "end": "3427200"
  },
  {
    "text": "um i just want to end quickly to go back to the picture we laid out initially",
    "start": "3427200",
    "end": "3433359"
  },
  {
    "text": "um so looking forward so i talked a lot about self-driving but in my lab at cornell i'm going to be going back to",
    "start": "3433359",
    "end": "3438960"
  },
  {
    "text": "personal robots and i want to bring some of these insights from self-driving back into",
    "start": "3438960",
    "end": "3444160"
  },
  {
    "text": "personal robot space space which i think is far more challenging and far more open-ended",
    "start": "3444160",
    "end": "3449359"
  },
  {
    "text": "um but to talk about you know some of the directions that i'm interested in so we talked about learning from natural human",
    "start": "3449359",
    "end": "3455359"
  },
  {
    "text": "interactions i think you know in the personal robot space there's just a lot of questions for",
    "start": "3455359",
    "end": "3460799"
  },
  {
    "text": "example what are good task representations for future learning how do we learn from multimodal feedback",
    "start": "3460799",
    "end": "3466799"
  },
  {
    "text": "you know learning with causal confounds like trust and adaptation and i think",
    "start": "3466799",
    "end": "3472960"
  },
  {
    "text": "you know having some answers to these questions is super critical for personal robots um",
    "start": "3472960",
    "end": "3479280"
  },
  {
    "text": "and for the second challenge planning alongside human partners and we talked about discrete modes for self-driving",
    "start": "3479280",
    "end": "3484480"
  },
  {
    "text": "that was easy what's what are modes when two humans are you know used doing whole",
    "start": "3484480",
    "end": "3489760"
  },
  {
    "text": "body manipulation near each other i don't know uh how do how do we communicate intent",
    "start": "3489760",
    "end": "3494880"
  },
  {
    "text": "to collapse uncertainty um how can robots plan safe predictable motions",
    "start": "3494880",
    "end": "3500240"
  },
  {
    "text": "so you know um yeah i look forward to tackling some of these challenges in my lab and lastly i",
    "start": "3500240",
    "end": "3506640"
  },
  {
    "text": "would like to acknowledge the amazing co-authors and collaborators in the work i presented today particularly i would like to acknowledge the entire team at",
    "start": "3506640",
    "end": "3513119"
  },
  {
    "text": "aurora you know who worked tirelessly to make the amazing product we have today with that",
    "start": "3513119",
    "end": "3519119"
  },
  {
    "text": "i have to take questions",
    "start": "3519119",
    "end": "3522078"
  },
  {
    "text": "thanks so much for the great talk",
    "start": "3527280",
    "end": "3530799"
  },
  {
    "text": "um in that last slide you kind of talked about future directions for these personal planners is there um",
    "start": "3538559",
    "end": "3544640"
  },
  {
    "text": "in your lab and your research going forward are you looking to try and dabble in all of those fields or is there anything in particular that you",
    "start": "3544640",
    "end": "3550240"
  },
  {
    "text": "that interests you that you're looking to work towards yeah that's um so yeah these challenges",
    "start": "3550240",
    "end": "3555359"
  },
  {
    "text": "are very open-ended i think right now um my focus is still very much limitation",
    "start": "3555359",
    "end": "3560400"
  },
  {
    "text": "learning particularly right now we're looking at causal compounds uh because it's a problem in self-driving and i",
    "start": "3560400",
    "end": "3566079"
  },
  {
    "text": "think i suspect it's a problem in any any robotics where humans have a lot of leading variables that's what i'm",
    "start": "3566079",
    "end": "3571359"
  },
  {
    "text": "focusing on now one of the things i would like to start with as i move from self-driving to mobile manipulators is",
    "start": "3571359",
    "end": "3577680"
  },
  {
    "text": "representations representations and self-driving a little bit community has thought about it for a long time but for manipulation i think",
    "start": "3577680",
    "end": "3584240"
  },
  {
    "text": "how we represent modes is pretty challenging but it's key if we want robots to work",
    "start": "3584240",
    "end": "3589920"
  },
  {
    "text": "in seamlessly alongside humans i think that that's that's the thing that will probably start with",
    "start": "3589920",
    "end": "3596240"
  },
  {
    "text": "maybe yeah sorry so if you're focusing on um natural human interactions",
    "start": "3598880",
    "end": "3604960"
  },
  {
    "text": "um like a lot of what we learn um like let's say you're on the road and driving a lot of the interactions like",
    "start": "3604960",
    "end": "3611599"
  },
  {
    "text": "someone in a car and someone in another car or similar to what we see in just like normal",
    "start": "3611599",
    "end": "3616799"
  },
  {
    "text": "non-driving interactions would you take any of the like models you develop or what you",
    "start": "3616799",
    "end": "3622079"
  },
  {
    "text": "learn from natural human interactions and apply that back to the self-driving field at all or yeah that's a good",
    "start": "3622079",
    "end": "3628960"
  },
  {
    "text": "question so the the for self-driving ultimately um you only need to model",
    "start": "3628960",
    "end": "3634559"
  },
  {
    "text": "enough for so your product drives like a human it doesn't necessarily need to have",
    "start": "3634559",
    "end": "3639920"
  },
  {
    "text": "the nuance it turns out from after years of looking at this we the nuance with",
    "start": "3639920",
    "end": "3645280"
  },
  {
    "text": "which you and i might you know infer how the scene evolves like",
    "start": "3645280",
    "end": "3650559"
  },
  {
    "text": "someone's you know doing road rage the robot doesn't need to infer to that granularity so",
    "start": "3650559",
    "end": "3655839"
  },
  {
    "text": "you can get to a product without getting you know inferring to that level i'm pretty sure that's not the case for personal robots perhaps",
    "start": "3655839",
    "end": "3661760"
  },
  {
    "text": "because just because they're they're interacting much more up close with humans so probably not in",
    "start": "3661760",
    "end": "3667119"
  },
  {
    "text": "self-driving probably it'll go the other way where you try to take some of these insights and try to simplify the",
    "start": "3667119",
    "end": "3672319"
  },
  {
    "text": "personal robots problem and see where to go from there yeah",
    "start": "3672319",
    "end": "3678960"
  },
  {
    "text": "and robots like also reason about kind of the perception that other actors in the",
    "start": "3679839",
    "end": "3685520"
  },
  {
    "text": "road have for example if you're following a car and you see that suddenly it swerves out of its lane or",
    "start": "3685520",
    "end": "3691280"
  },
  {
    "text": "slows down then you could infer that there's an obstacle before you can see it but is there a way that it could do",
    "start": "3691280",
    "end": "3697280"
  },
  {
    "text": "something like that yeah and and that happens a lot for example construction sometimes you don't see construction but",
    "start": "3697280",
    "end": "3703200"
  },
  {
    "text": "the robot's reasoning and and we are actually working on that in our model at the moment you know you can infer that",
    "start": "3703200",
    "end": "3710559"
  },
  {
    "text": "you can infer based on the emotions that there's some object there that's correlating what all the actors are",
    "start": "3710559",
    "end": "3715760"
  },
  {
    "text": "doing they're all certainly laying changing so that's something that we're modeling at the moment",
    "start": "3715760",
    "end": "3721440"
  },
  {
    "text": "um in self-driving data sets coming across situations where something",
    "start": "3722400",
    "end": "3727520"
  },
  {
    "text": "dangerous happens or when an accident happens is really really rare when you train these models do you do",
    "start": "3727520",
    "end": "3733200"
  },
  {
    "text": "anything like upsampling situations that you deem to be dangerous to make sure that your model is accurate",
    "start": "3733200",
    "end": "3738640"
  },
  {
    "text": "and very very rare situation yeah excellent question that's right if you take you you have to",
    "start": "3738640",
    "end": "3745440"
  },
  {
    "text": "uh you you can't simply do empirical risk minimization because 99 is boring you have to you know create clusters of",
    "start": "3745440",
    "end": "3752480"
  },
  {
    "text": "data points that you know and make sure your model is good across the board the second thing i want to say is that um if",
    "start": "3752480",
    "end": "3758640"
  },
  {
    "text": "events you know events happen rarely because humans are really good at guarding against events and they get out of situations and so that's really a key",
    "start": "3758640",
    "end": "3765839"
  },
  {
    "text": "thing the robots have to learn how to guard like humans so they don't get into those trouble situations i think that's",
    "start": "3765839",
    "end": "3771200"
  },
  {
    "text": "the key piece that that that makes the product possible",
    "start": "3771200",
    "end": "3776240"
  },
  {
    "text": "with that i want to thank you again for coming in person to give a talk at the samsung robotics webinar they do it",
    "start": "3777119",
    "end": "3783200"
  },
  {
    "text": "again yeah thank you everyone",
    "start": "3783200",
    "end": "3787480"
  }
]
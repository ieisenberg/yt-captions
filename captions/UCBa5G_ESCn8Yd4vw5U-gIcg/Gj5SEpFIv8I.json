[
  {
    "start": "0",
    "end": "5710"
  },
  {
    "text": "For today, we're going\nto recap a little bit from what we talked\nabout last week, from the meta-learning\nproblem set up",
    "start": "5710",
    "end": "11260"
  },
  {
    "text": "and black-box meta-learning. And then we're going to\nget into optimization-based meta-learning where\nwe're actually",
    "start": "11260",
    "end": "16450"
  },
  {
    "text": "going to be embedding\nan optimization process inside another\noptimization process.",
    "start": "16450",
    "end": "23539"
  },
  {
    "text": "And this is part-- part of what we'll be\ntalking about today as part of homework 2. And so it should also\nbe useful for that.",
    "start": "23540",
    "end": "32180"
  },
  {
    "text": " Great. And then, yeah, by the\nend of the lecture,",
    "start": "32180",
    "end": "37386"
  },
  {
    "text": "you should have a\nsense for the basics of optimization-based\nmeta-learning techniques and how to implement them\nin things like PyTorch.",
    "start": "37387",
    "end": "43350"
  },
  {
    "text": "And also some of the trade offs\nbetween black-box meta-learning and optimization-based\nmeta-learning. ",
    "start": "43350",
    "end": "51290"
  },
  {
    "text": "Cool. So to start to recap\nfrom last lecture or some of the previous\nlectures, we've talked",
    "start": "51290",
    "end": "57650"
  },
  {
    "text": "about multi-task learning\nand transfer learning. And we introduced this notion\nof the meta-learning problem statement, which is kind of\na form of transfer learning",
    "start": "57650",
    "end": "64470"
  },
  {
    "text": "where our goal is having been\ngiven a set of training tasks, we want to, more quickly or more\nproficiently, solve a new task.",
    "start": "64470",
    "end": "74540"
  },
  {
    "text": "And we looked at this kind\nrunning example meta-learning problem where we have--",
    "start": "74540",
    "end": "80899"
  },
  {
    "text": "we're trying to do\n5-way classification. We're given one example\nfrom each of the five different classes as this really\ntiny training data set set.",
    "start": "80900",
    "end": "87890"
  },
  {
    "text": "And our goal is to\nbe able to predict the label for new examples as\nbeing among one of those five",
    "start": "87890",
    "end": "93530"
  },
  {
    "text": "classes. And the way that\nwe did this is we set up a set of tasks that look\na lot like the kind of tasks",
    "start": "93530",
    "end": "100460"
  },
  {
    "text": "that we'll see at\nMeta Test-Time. And so these were\nour training tasks. And we perform\nmeta-training on these tasks",
    "start": "100460",
    "end": "107090"
  },
  {
    "text": "because we're trying\nto learn how to quickly learn each of these\ntraining tasks such that when we're given a\nnew task at Meta Test-Time,",
    "start": "107090",
    "end": "114200"
  },
  {
    "text": "we can quickly learn that task. And this was an example,\nan image classification.",
    "start": "114200",
    "end": "121280"
  },
  {
    "text": "But you can also replace this\nexample with other machine learning problems. ",
    "start": "121280",
    "end": "128479"
  },
  {
    "text": "Great. And then one of the big\ntopics of lecture on Wednesday last week was how\nwe can actually solve these few shot\nlearning problems",
    "start": "128479",
    "end": "135340"
  },
  {
    "text": "with a black-box neural network\nwhere we basically just pass in the training data\nset into something",
    "start": "135340",
    "end": "142210"
  },
  {
    "text": "like a recurrent\nneural network, have that neural network\npossibly output a set of parameters\nfor that task.",
    "start": "142210",
    "end": "149050"
  },
  {
    "text": "And then we make predictions\nfor new inputs for that task by passing that through\nthe neural network",
    "start": "149050",
    "end": "155890"
  },
  {
    "text": "with those parameters. We also talked about\na second version of this where it's\nnot explicitly",
    "start": "155890",
    "end": "161320"
  },
  {
    "text": "outputting the parameters\nof an entire neural network, it's simply just giving you, for\nexample, another hidden state",
    "start": "161320",
    "end": "166450"
  },
  {
    "text": "of that RNN, and then\nyou can just, again, pass that through the last\nmodule or the last time",
    "start": "166450",
    "end": "172420"
  },
  {
    "text": "step of the RNN.  So this kind takes this-- it\nhas this more general form where",
    "start": "172420",
    "end": "178902"
  },
  {
    "text": "we're going to be passing in\na training data set and a test input into some function. And we're going to be making\na corresponding prediction.",
    "start": "178902",
    "end": "187930"
  },
  {
    "text": "This method was great in\nthat it's very expressive. You can represent lots of\ndifferent learning algorithms",
    "start": "187930",
    "end": "193060"
  },
  {
    "text": "with these large\nblack-box neural networks. But they can also be somewhat\nchallenging to optimize.",
    "start": "193060",
    "end": "198430"
  },
  {
    "text": "And that's maybe something that\nyou came across in homework 1, if you've got started on that.",
    "start": "198430",
    "end": "204880"
  },
  {
    "text": "So in this lecture, we're going\nto be thinking about other ways to try to represent\nthis function that",
    "start": "204880",
    "end": "210390"
  },
  {
    "text": "goes from a training data set\nto a set of task parameters.",
    "start": "210390",
    "end": "215890"
  },
  {
    "text": "And in particular, we know\nsomething a little bit about machine learning.",
    "start": "215890",
    "end": "220940"
  },
  {
    "text": "So you can think of\nthis RNN as trying to mimic a learning process. And instead of\ntrying to just have--",
    "start": "220940",
    "end": "226840"
  },
  {
    "text": "through a black-box\nneural network at this, we could actually\ntake a little bit about what we know\nabout machine learning",
    "start": "226840",
    "end": "232118"
  },
  {
    "text": "and actually apply that\nstructure to this function and try to actually treat this\nfunction f as an optimization",
    "start": "232118",
    "end": "238180"
  },
  {
    "text": "procedure. So that's what we'll really\nbe focusing on today. ",
    "start": "238180",
    "end": "244260"
  },
  {
    "text": "So in particular,\nwhat we can do is we're basically going to\nreplace this RNN on the top left",
    "start": "244260",
    "end": "251420"
  },
  {
    "text": "with some form of\noptimization process. And in particular, we're going\nto focus on optimization--",
    "start": "251420",
    "end": "258410"
  },
  {
    "text": "on gradient-based optimization. So instead of putting\nthese examples into a RNN,",
    "start": "258410",
    "end": "265800"
  },
  {
    "text": "we can instead pass it-- we can\nactually run gradient descent on these examples in\norder to get a set of task",
    "start": "265800",
    "end": "273260"
  },
  {
    "text": "specific parameters. Now the key idea\nhere is that we're",
    "start": "273260",
    "end": "278518"
  },
  {
    "text": "going to be embedding\nthis gradient descent optimization inside a\nbroader optimization process,",
    "start": "278518",
    "end": "284419"
  },
  {
    "text": "the meta-training process. And then the key\nquestion is, what",
    "start": "284420",
    "end": "289580"
  },
  {
    "text": "actually are we going to be-- what are the meta parameters? What are we going\nto be, kind of, meta training in this process?",
    "start": "289580",
    "end": "296580"
  },
  {
    "text": "And there's a number of\ndifferent free parameters of this process. What we'll focus on\nto start is a scenario",
    "start": "296580",
    "end": "303980"
  },
  {
    "text": "where we're optimizing\nfor the initial parameters of this neural network\nsuch that running",
    "start": "303980",
    "end": "309380"
  },
  {
    "text": "gradient descent\non a few examples gives us a good set of\ntask specific parameters",
    "start": "309380",
    "end": "315440"
  },
  {
    "text": "for that task and\nfor other tasks. Now, why might this make sense?",
    "start": "315440",
    "end": "324070"
  },
  {
    "text": "So if we go back to a\ncouple lectures ago, we were talking\nabout fine-tuning.",
    "start": "324070",
    "end": "329340"
  },
  {
    "text": "And we would take a set of\npre-trained parameters data and run gradient\ndescent initialized",
    "start": "329340",
    "end": "335640"
  },
  {
    "text": "with those pre-trained\nparameters. And we found that fine-tuning\ncan actually work much better",
    "start": "335640",
    "end": "342395"
  },
  {
    "text": "than learning from scratch. So we see that the green and\norange lines are much lower. They have much lower\nerror than the blue lines.",
    "start": "342395",
    "end": "348655"
  },
  {
    "text": " But they also don't do great\nin the few-shot regime.",
    "start": "348655",
    "end": "353915"
  },
  {
    "text": "And so essentially,\nyou can think of this as trying to\noptimize for a set of pre-trained parameters\nsuch that we can actually",
    "start": "353915",
    "end": "359670"
  },
  {
    "text": "do very well in the\nfew-shot regime, unlike if we were just going\nto pre-train with something",
    "start": "359670",
    "end": "365018"
  },
  {
    "text": "like supervised learning.  So in particular, let's start\nto formulate what this looks",
    "start": "365018",
    "end": "373570"
  },
  {
    "text": "like as an objective. So fine-tuning is what we want\nto be able to do at test time",
    "start": "373570",
    "end": "379449"
  },
  {
    "text": "on our small training\nset for our new task. And so what we can\ndo is we can take",
    "start": "379450",
    "end": "387392"
  },
  {
    "text": "one step of gradient descent. We can also imagine\nmore than one step, but we'll start with a\nsimplifying case of one step of gradient descent.",
    "start": "387392",
    "end": "395070"
  },
  {
    "text": "This will be used to get\nparameters for task i after fine-tuning on\nthe data set for task i.",
    "start": "395070",
    "end": "401995"
  },
  {
    "text": "And then once we have\nthose parameters, we will evaluate how\ngood those parameters are on new examples, specifically\nexamples in the test data",
    "start": "401995",
    "end": "412539"
  },
  {
    "text": "set for that task. And then we'll\nessentially optimize for the set of\npre-trained parameters",
    "start": "412540",
    "end": "419910"
  },
  {
    "text": "such that this one step\nof gradient descent is generalizing well\nto new examples.",
    "start": "419910",
    "end": "425385"
  },
  {
    "text": "And of course, we won't\njust do this over one task. We'll do this over\nall of the tasks that we have available to us.",
    "start": "425385",
    "end": "433950"
  },
  {
    "text": "So this is essentially\nwhat our objective is going to look like for\nthis optimization-based",
    "start": "433950",
    "end": "441168"
  },
  {
    "text": "meta-learning process.  So the key idea here is to\ntry to learn a parameter",
    "start": "441168",
    "end": "448250"
  },
  {
    "text": "vector, an initial\nparameter vector theta that transfers very\nnicely with only a few examples.",
    "start": "448250",
    "end": "456320"
  },
  {
    "text": "I mentioned that this is an\nexample for this one gradient step. But in practice, you could also\nput multiple gradient steps",
    "start": "456320",
    "end": "461870"
  },
  {
    "text": "in this inner loop here. And it will-- the equation\nwill get a little bit longer,",
    "start": "461870",
    "end": "467669"
  },
  {
    "text": "but the conceptual\naspect of it is the same. ",
    "start": "467670",
    "end": "474940"
  },
  {
    "text": "So from here, we can-- now that we have\nour objective, we",
    "start": "474940",
    "end": "480990"
  },
  {
    "text": "can actually write out what\nthis looks like as an algorithm. So again, we can think\nof the same 3-way 1-shot",
    "start": "480990",
    "end": "491530"
  },
  {
    "text": "classification problem that we\nconsidered in the last lecture where basically\ndifferent tasks will",
    "start": "491530",
    "end": "497169"
  },
  {
    "text": "correspond to classifying\ndigits from different alphabets.",
    "start": "497170",
    "end": "502323"
  },
  {
    "text": "In this case, you could\nthink of different alphabets as only having potentially\nthree characters.",
    "start": "502323",
    "end": "507460"
  },
  {
    "text": "And the first step again\nwill be to sample a task.",
    "start": "507460",
    "end": "514270"
  },
  {
    "text": "This will correspond to\nthree different characters.",
    "start": "514270",
    "end": "519830"
  },
  {
    "text": "Then the next step\nwill be to sample a couple images per character.",
    "start": "519830",
    "end": "527079"
  },
  {
    "text": " And this will allow us\nto basically give us",
    "start": "527080",
    "end": "534610"
  },
  {
    "text": "a training data set and\na test set for that task.",
    "start": "534610",
    "end": "539800"
  },
  {
    "text": "And so in particular, we might\nhave x equals a, b, and c.",
    "start": "539800",
    "end": "549149"
  },
  {
    "text": "And y equals 0, 1, 2. And then also, this will\nbe our training data set.",
    "start": "549150",
    "end": "557170"
  },
  {
    "text": "And then likewise, a, b, c.",
    "start": "557170",
    "end": "563860"
  },
  {
    "text": "And this will be the\ntest set for this task.",
    "start": "563860",
    "end": "568930"
  },
  {
    "text": "0, 1, 2. And so before what\nwe did is we just pass the training data set\nthrough a neural network.",
    "start": "568930",
    "end": "574970"
  },
  {
    "text": "Instead what we're\ngoing to do is-- I guess there'll\nbe a step 0 here,",
    "start": "574970",
    "end": "580230"
  },
  {
    "text": "which is to randomly initialize\nour meta parameters theta.",
    "start": "580230",
    "end": "587980"
  },
  {
    "text": "And then what the\nstep 3 is going to do is it's going to take\none gradient descent",
    "start": "587980",
    "end": "597120"
  },
  {
    "text": "step on our training data set. So we will start with the\ncurrent value of our meta",
    "start": "597120",
    "end": "603600"
  },
  {
    "text": "parameters, then run gradient\ndescent on our three training",
    "start": "603600",
    "end": "610420"
  },
  {
    "text": "examples. And so I'll just write this\nas something like this.",
    "start": "610420",
    "end": "616440"
  },
  {
    "text": "This will give us a set\nof parameters, phi i.",
    "start": "616440",
    "end": "622030"
  },
  {
    "text": "And then once we have\nthese parameters, we will then take\nour test examples,",
    "start": "622030",
    "end": "629340"
  },
  {
    "text": "run that through\nour neural network with parameters phi i to get\na corresponding prediction.",
    "start": "629340",
    "end": "637180"
  },
  {
    "text": "And so for example, we'll be\nlooking f phi i of this example",
    "start": "637180",
    "end": "643060"
  },
  {
    "text": "here. That will give us a\ncorresponding prediction.",
    "start": "643060",
    "end": "648107"
  },
  {
    "text": "And then we'll compare\nthat prediction to the corresponding\nlabel to get how well this neural network is\ngeneralizing to new examples.",
    "start": "648107",
    "end": "654970"
  },
  {
    "text": "And from there, we'll then\nback propagate all the way back into the initial\nparameter vectors, theta,",
    "start": "654970",
    "end": "660069"
  },
  {
    "text": "in order to update\nour meta parameters. And so in particular,\nwe'll have an update",
    "start": "660070",
    "end": "667800"
  },
  {
    "text": "on theta, which\nwill be based off of how well phi i is doing\non your held out examples D",
    "start": "667800",
    "end": "681259"
  },
  {
    "text": "test for task i. So this will be based off\nof ultimately the gradient",
    "start": "681260",
    "end": "687040"
  },
  {
    "text": "of this. ",
    "start": "687040",
    "end": "693710"
  },
  {
    "text": "Cool. Now one other thing that\nI'll mention here is--",
    "start": "693710",
    "end": "699150"
  },
  {
    "text": "I guess I should maybe-- well, actually, sorry. After step 4, then\nyou'll go back",
    "start": "699150",
    "end": "705090"
  },
  {
    "text": "to step 1, and repeat and\ncontinuously update theta based on this value right here.",
    "start": "705090",
    "end": "715950"
  },
  {
    "text": "So this is the full\nmeta-training algorithm. One thing that I'll\nmention here is, here",
    "start": "715950",
    "end": "721283"
  },
  {
    "text": "we're going to be optimizing for\nsome set of initial parameters. But you could also optimize for\nother parts of the inner loop",
    "start": "721283",
    "end": "727610"
  },
  {
    "text": "learning process as well. For example, you could\noptimize for the learning rate here as well.",
    "start": "727610",
    "end": "734960"
  },
  {
    "text": "And you could\noptimize with respect to some weights applied to\nthe data points or something like that.",
    "start": "734960",
    "end": "740149"
  },
  {
    "text": " Yeah. So this is the gist of it.",
    "start": "740150",
    "end": "746240"
  },
  {
    "text": "Any questions? on the\nmeta-training process? Yeah. I'm slightly confused about\nhow phi i and theta are",
    "start": "746240",
    "end": "754149"
  },
  {
    "text": "related to each other. So at step 3, you get phi i\nfrom just modifying theta.",
    "start": "754150",
    "end": "761200"
  },
  {
    "text": "But for step 4, you\nwere update theta using the gradient obtained\nthrough [INAUDIBLE]",
    "start": "761200",
    "end": "766630"
  },
  {
    "text": "Yeah. --phi i. OK. So that's-- like\nthe [INAUDIBLE]..",
    "start": "766630",
    "end": "773200"
  },
  {
    "text": "Yeah, exactly. So you can think of step\nthree as the inner loop of this process because\nit's running the learning process to get--",
    "start": "773200",
    "end": "779380"
  },
  {
    "text": "running the learning\nprocess on a task i. And then you can think of step\n4 as this kind of outer loop",
    "start": "779380",
    "end": "786430"
  },
  {
    "text": "objective where\nwe're actually going to be differentiating through\nthe inner loop process in order",
    "start": "786430",
    "end": "792160"
  },
  {
    "text": "to figure out what\nwould have been a better initialization that would have\nallowed me to better generalize",
    "start": "792160",
    "end": "800050"
  },
  {
    "text": "with this small data set. The inner loop could also be\nmore than one gradient steps, it can also be a\nfew gradient steps.",
    "start": "800050",
    "end": "805380"
  },
  {
    "text": "Yeah. This is similar to\nonline/offline [INAUDIBLE] Bootstrap Your Own\nLatent where you",
    "start": "805380",
    "end": "810611"
  },
  {
    "text": "have two separate networks that\nare meta-learning adjacently.",
    "start": "810611",
    "end": "815648"
  },
  {
    "text": "So the question is, is\nit similar to things like Bootstrap Your\nOwn Latent and offline and online processes? I'm not-- It's been a little--",
    "start": "815648",
    "end": "823250"
  },
  {
    "text": "I'm a little bit rusty\non the details of BYOL. We will next week talk about\nunsupervised pre-training",
    "start": "823250",
    "end": "828912"
  },
  {
    "text": "methods and talk a little\nbit about how those relate to meta-learning methods. Yeah.",
    "start": "828913",
    "end": "834410"
  },
  {
    "text": "Could you clarify\nagain how this is different from the\nblack-box learning",
    "start": "834410",
    "end": "839600"
  },
  {
    "text": "algorithms from last week? Because for example,\nif theta, in this case, were the parameters\nof an RNN, then",
    "start": "839600",
    "end": "845480"
  },
  {
    "text": "would we end up with something\npretty similar to what we had last week? Yeah, so the key difference\nwith the black-box method--",
    "start": "845480",
    "end": "852450"
  },
  {
    "text": "so this is the-- black is the\noptimization-based approach. The key difference for the black\nbox approach is really step 3.",
    "start": "852450",
    "end": "859730"
  },
  {
    "text": "And so the difference\nwith step step 3 is instead of actually obtaining\nphi i through gradient descent,",
    "start": "859730",
    "end": "865310"
  },
  {
    "text": "we obtained phi i by running\nit through a neural network.",
    "start": "865310",
    "end": "871800"
  },
  {
    "text": "And so there was\na neural network. I can't remember if I named it\nf or g in the previous lecture.",
    "start": "871800",
    "end": "878089"
  },
  {
    "text": "But there's a\nneural network that took this input, the training\ndata points for the task",
    "start": "878090",
    "end": "883250"
  },
  {
    "text": "and outputed the parameters. And now instead of just passing\nthis through a neural network, we're going to be running\ngradient descent initialized",
    "start": "883250",
    "end": "891440"
  },
  {
    "text": "at the meta-parameters theta. ",
    "start": "891440",
    "end": "899330"
  },
  {
    "text": "Yeah. Would this work when\nthe loss functions between different\ntasks are different?",
    "start": "899330",
    "end": "906259"
  },
  {
    "text": "Will this work if the loss\nfunctions between tasks are different?",
    "start": "906260",
    "end": "911819"
  },
  {
    "text": "Yeah. So you could certainly have\ndifferent loss functions for different tasks. What you would do in\nthat case is L i--",
    "start": "911820",
    "end": "918600"
  },
  {
    "text": "you basically have an-- L would be kind of-- you'd\nhave a different loss function for different tasks. And so you would just need to\nuse that loss function here",
    "start": "918600",
    "end": "927290"
  },
  {
    "text": "and also here, and everything\nwould all still work out. Yeah.",
    "start": "927290",
    "end": "932680"
  },
  {
    "text": "How do you make sure there\nisn't, like, some [INAUDIBLE] that's happening in theta? Like, if you can\nimagine, if you like loop",
    "start": "932680",
    "end": "938350"
  },
  {
    "text": "over a bunch of different tasks\nand you come back to task 4, how do you make sure-- [INAUDIBLE] is there a\nguarantee that it'll still be as good as it was\nwhen you first started?",
    "start": "938350",
    "end": "945050"
  },
  {
    "text": "Yeah. So the question is,\nhow do you make sure that forgetting doesn't happen? And as you loop\nthrough these tasks, it may not be as good\nat the first task",
    "start": "945050",
    "end": "952420"
  },
  {
    "text": "once after you've gone\nthrough the other tasks. And really, the key thing\nhere is when you actually",
    "start": "952420",
    "end": "957610"
  },
  {
    "text": "sample a task, you\nmay also-- instead of sampling just one\ntask, you may want to sample a mini batch of tasks.",
    "start": "957610",
    "end": "963580"
  },
  {
    "text": "And this will actually give\nyou a gradient that isn't just or a [INAUDIBLE] that\nisn't just for one task,",
    "start": "963580",
    "end": "968740"
  },
  {
    "text": "it's for multiple. You may ultimately\nget a little bit of forgetting in so far, as\nlike SGD, will kind of forget",
    "start": "968740",
    "end": "975910"
  },
  {
    "text": "some data points, for example. But having a mini batch, having\na large enough batch size",
    "start": "975910",
    "end": "981160"
  },
  {
    "text": "can certainly help with that. Yeah. So the difference\nhere is last time",
    "start": "981160",
    "end": "987830"
  },
  {
    "text": "we were taking loss\non the query side, but this time we'll be taking\nloss of the support side and train it in step 3.",
    "start": "987830",
    "end": "993650"
  },
  {
    "text": "Am I right? So the fourth step is still\nwith respect to the query set.",
    "start": "993650",
    "end": "1003100"
  },
  {
    "text": "The-- Test sets? [INAUDIBLE] ",
    "start": "1003100",
    "end": "1008269"
  },
  {
    "text": "Yeah. So the third step is really\nwhere the difference is. And so it is running a gradient\nstep on the support set.",
    "start": "1008270",
    "end": "1013930"
  },
  {
    "text": "Before, we are also\nusing the support set in the black-box\nmeta-learning approach. And we are passing\nthat into f data.",
    "start": "1013930",
    "end": "1019990"
  },
  {
    "text": "And so, yeah, one key difference\nis here we're actually taking-- sort of, taking a gradient\nstep on both the support set and the query set.",
    "start": "1019990",
    "end": "1025930"
  },
  {
    "text": " Yeah. But the key step is the\ndifference between 3.",
    "start": "1025930",
    "end": "1035319"
  },
  {
    "text": "If you basically just\nput this into three, then you get exactly\nthe black box approach that we had last week.",
    "start": "1035319",
    "end": "1040480"
  },
  {
    "text": " So one other thing that\nmight help a little bit",
    "start": "1040480",
    "end": "1046069"
  },
  {
    "text": "with some intuition\nhere is that you can think of theta as this\nset of meta parameters",
    "start": "1046069",
    "end": "1052430"
  },
  {
    "text": "that's being meta-learned. And if you think\nabout phi i star being",
    "start": "1052430",
    "end": "1058700"
  },
  {
    "text": "the optimal parameter\nvector for a task i, then you can think\nof meta-training",
    "start": "1058700",
    "end": "1064789"
  },
  {
    "text": "as this really thick\nblack line where when you're at this point in\nthe meta-training process,",
    "start": "1064790",
    "end": "1070580"
  },
  {
    "text": "if you take a gradient step\nwith respect to task 3, you're quite far from\nthe optimum for task 3.",
    "start": "1070580",
    "end": "1076039"
  },
  {
    "text": "And likewise for other tasks. And as you continue the\nmeta-training process, ultimately, at the end of\nthe meta-training process,",
    "start": "1076040",
    "end": "1083059"
  },
  {
    "text": "you want to be at a\nplace in the landscape where if you take a gradient\nstep with respect to task 3, you're very close to task 3.",
    "start": "1083060",
    "end": "1088910"
  },
  {
    "text": "If you take a gradient step\nwith respect to task 2, you're very close to a good\nparameter vector for task 2.",
    "start": "1088910",
    "end": "1094340"
  },
  {
    "text": "So this may give you a little\nbit of a visual depiction of the meta-training process.",
    "start": "1094340",
    "end": "1099558"
  },
  {
    "text": "Now one thing I will note\nabout this diagram that can potentially be a\nlittle bit misleading is there isn't just a single\noptimum for any given task.",
    "start": "1099558",
    "end": "1107918"
  },
  {
    "text": "And so it's actually\ngoing to be more of actually a large part of\nthe parameter space for any one task.",
    "start": "1107918",
    "end": "1113450"
  },
  {
    "text": "And your goal is to try to\nfind a part of the landscape where if you take\na gradient step",
    "start": "1113450",
    "end": "1118857"
  },
  {
    "text": "you're going to get\nto a region that's good for that task\nparameter rather than just a single space. ",
    "start": "1118857",
    "end": "1126330"
  },
  {
    "text": "Yeah. That's the gist of it. In principle, this may-- in this diagram, it kind\nof looks like it's almost",
    "start": "1126330",
    "end": "1131570"
  },
  {
    "text": "averaging the task parameters. In practice, you may\nget something like that. In practice, you may\nalso be in scenarios",
    "start": "1131570",
    "end": "1137780"
  },
  {
    "text": "where you're actually\npretty far from the average,",
    "start": "1137780",
    "end": "1143000"
  },
  {
    "text": "but where kind of a gradient\nstep we'll take you fairly far. And on that note,\nI think it's worth mentioning that this learning\nrate here, alpha, in practice",
    "start": "1143000",
    "end": "1152690"
  },
  {
    "text": "will be much larger than\na typical learning rate that you might use because you\nwant to be able to actually go",
    "start": "1152690",
    "end": "1159950"
  },
  {
    "text": "pretty far and actually\nbe able to traverse very far in the parameter\nspace for different tasks.",
    "start": "1159950",
    "end": "1167720"
  },
  {
    "text": "Yeah. [INAUDIBLE] ",
    "start": "1167720",
    "end": "1178680"
  },
  {
    "text": "Improve the training of the\ncalculation-based adaptation?",
    "start": "1178680",
    "end": "1183810"
  },
  {
    "text": "So certainly this does look\na lot like a hyperparameter optimization,\nexcept where you're optimizing the full\ninitial parameters rather",
    "start": "1183810",
    "end": "1190101"
  },
  {
    "text": "than just slow learning rate. Your question was, can you also\ndo hyperparameter optimization with this? Or-- [INAUDIBLE] or\nsomething like that.",
    "start": "1190102",
    "end": "1199050"
  },
  {
    "text": "Like, is this [INAUDIBLE]? ",
    "start": "1199050",
    "end": "1205188"
  },
  {
    "text": "Yeah, so you could\ncertainly consider using hyperparameter\noptimization techniques for learning the initialization.",
    "start": "1205188",
    "end": "1211049"
  },
  {
    "text": "Unfortunately, a lot\nof them are designed for optimizing a very\nlow dimensional set of hyperparameters, like\none hyperparameter or five",
    "start": "1211050",
    "end": "1217680"
  },
  {
    "text": "hyperparameters. And the initial parameters\nof a neural network may be millions of\nhyperparameters.",
    "start": "1217680",
    "end": "1223350"
  },
  {
    "text": "And so a lot of those\nmethods won't scale well to such high-dimensional things.",
    "start": "1223350",
    "end": "1229080"
  },
  {
    "text": "And that's why in\nthis case, we're actually going to just\nbe differentiating through the learning\nprocess and using gradients.",
    "start": "1229080",
    "end": "1236340"
  },
  {
    "text": "But there are-- there's a lot\nof ideas that are transferable between the two literatures. ",
    "start": "1236340",
    "end": "1244910"
  },
  {
    "text": "Yeah? So here, we are taking loss with\nrespect to the [INAUDIBLE] tree in the third step. So what is loss here, really?",
    "start": "1244910",
    "end": "1252190"
  },
  {
    "text": "Because we concatenate the major\nlabel, right, when we pass it. And then we are obviously trying\nto find the loss with respect",
    "start": "1252190",
    "end": "1258669"
  },
  {
    "text": "to the training set levels again\nthat's operated by the network?",
    "start": "1258670",
    "end": "1263680"
  },
  {
    "text": "Yeah, great question. So in black box meta-learning,\nwe were concatenating. We were passing in both\nthe image and the label",
    "start": "1263680",
    "end": "1269440"
  },
  {
    "text": "into the network. Here, when we run\nthis inner loop, we're going to have a model--",
    "start": "1269440",
    "end": "1274914"
  },
  {
    "text": " we're going to have a\nmodel f theta that's",
    "start": "1274915",
    "end": "1279940"
  },
  {
    "text": "kind of a neural network model. And we're going to be only\npassing as input the training",
    "start": "1279940",
    "end": "1287980"
  },
  {
    "text": "examples into this. We're not going to be\npassing in the labels. And then we're going to get\na corresponding prediction,",
    "start": "1287980",
    "end": "1294340"
  },
  {
    "text": "and then the-- this loss\nfunction right here, Li for theta, Di train.",
    "start": "1294340",
    "end": "1302500"
  },
  {
    "text": "This is going to equal the\nsum over examples xi, yi,",
    "start": "1302500",
    "end": "1310210"
  },
  {
    "text": "in D train i of-- I guess if it's something\nlike regression, you'll have something like y\nhat train i minus y train i.",
    "start": "1310210",
    "end": "1320617"
  },
  {
    "text": "If it's classification\nyou'll have something more like a cross-entropy loss. And so this is-- this is\nthe definition of this loss",
    "start": "1320618",
    "end": "1329682"
  },
  {
    "text": "function, and this is how you're\ngoing to get the gradient. And so you're not\ngoing to actually going to be passing on the\nlabels into the network,",
    "start": "1329682",
    "end": "1335625"
  },
  {
    "text": "but the labels will\nstill come into play when you're comparing\nthe predictions from the model to the\nground truth predictions.",
    "start": "1335625",
    "end": "1344740"
  },
  {
    "text": "Yeah? How does optimization-based\n[INAUDIBLE] typically compare to what this\napproach is performance-wise,",
    "start": "1344740",
    "end": "1351039"
  },
  {
    "text": "and why would you\nchoose one or the other? Yeah, we'll talk about\npros and cons of black box versus optimization-based\ntowards the end.",
    "start": "1351040",
    "end": "1358419"
  },
  {
    "text": "Yeah? So as you're studying\nthe random boundaries and doing the operation\n[INAUDIBLE] designing the major",
    "start": "1358420",
    "end": "1364450"
  },
  {
    "text": "[INAUDIBLE] you have to model\nthe non-linear [INAUDIBLE] of parameters, right,\nin the operation.",
    "start": "1364450",
    "end": "1371620"
  },
  {
    "text": "Are you referring\nto this learning? Yeah. Because it'll also be\nlearning right here, too. In general, yeah,\nit's a great question.",
    "start": "1371620",
    "end": "1379210"
  },
  {
    "text": "So do we need to\ncarefully schedule it? It is a hyperparameter, and you\ndo need to pick it carefully.",
    "start": "1379210",
    "end": "1386160"
  },
  {
    "text": "If you pick it to be too large,\nthen it may be very difficult. Like, the updates may\nbe just way too large.",
    "start": "1386160",
    "end": "1392220"
  },
  {
    "text": "If you pick something too small,\nit may have trouble actually differentiating and getting\nto different parameter",
    "start": "1392220",
    "end": "1397620"
  },
  {
    "text": "vectors for different tasks. And so it's important\nto pick something that-- that has a middle ground.",
    "start": "1397620",
    "end": "1404243"
  },
  {
    "text": "The other thing\nthat you can do is you can optimize it as part of-- as part of step 4 as well.",
    "start": "1404243",
    "end": "1411300"
  },
  {
    "text": "And what approaches\nhave found is that it's actually\nhelpful to optimize",
    "start": "1411300",
    "end": "1416940"
  },
  {
    "text": "a different value\nof the learning rate for different layers, or even\nfor different parameters,",
    "start": "1416940",
    "end": "1422580"
  },
  {
    "text": "rather than having\na single learning rate for all the parameters. And this is because some\nparameters, especially biases,",
    "start": "1422580",
    "end": "1428310"
  },
  {
    "text": "like to have a very\nlarge learning rate, and others like to have a\nvery small learning rate. And if you try to optimize for\na single learning rate for all",
    "start": "1428310",
    "end": "1435570"
  },
  {
    "text": "of them, then they find\na middle ground that isn't good for the weights.",
    "start": "1435570",
    "end": "1441929"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "1441930",
    "end": "1449990"
  },
  {
    "text": "Yeah, so if you do\noptimize a different alpha for these different--\nfor the different layers, it does actually end\nup being quite stable.",
    "start": "1449990",
    "end": "1457970"
  },
  {
    "text": "Yeah? [INAUDIBLE] across\n[INAUDIBLE] in step 3, can we add a term\nbefore regularization?",
    "start": "1457970",
    "end": "1465740"
  },
  {
    "text": "Can we add a term\nfor a regularization? So yeah, this loss function-- this loss function could also\ninclude a regularization term.",
    "start": "1465740",
    "end": "1474389"
  },
  {
    "text": "One thing often--\nactually one reason, or one interesting\nthing here to note here is, oftentimes you don't\nactually need a regularization",
    "start": "1474390",
    "end": "1480860"
  },
  {
    "text": "on the inner loop. And this may be a\nlittle bit surprising, because the inner loop data\nset is often really tiny.",
    "start": "1480860",
    "end": "1486830"
  },
  {
    "text": "But because you're optimizing\nexplicitly for generalization, it's going to be optimizing\nfor at least a part",
    "start": "1486830",
    "end": "1493610"
  },
  {
    "text": "of the optimization landscape\nthat is nicely behaved, and for which you don't get--",
    "start": "1493610",
    "end": "1499440"
  },
  {
    "text": "you don't overfit. That said, it may be helpful to\nadd regularization to this term here if you're worried about\noverfitting to the tasks",
    "start": "1499440",
    "end": "1508040"
  },
  {
    "text": "that you have. Yeah? In this view, the training\nset is used in step 3,",
    "start": "1508040",
    "end": "1515700"
  },
  {
    "text": "and the test set\nis used in step 4. And is it important to\nmaintain that separation between the two [INAUDIBLE]?",
    "start": "1515700",
    "end": "1524750"
  },
  {
    "text": "Yeah. So the question is, is\nit important to maintain this kind of distinction\nbetween train set and test set in step 3 and step 4?",
    "start": "1524750",
    "end": "1531750"
  },
  {
    "text": "It is really important to\nhave some held-out data points in step 4 that are\ndistinct from the data points",
    "start": "1531750",
    "end": "1537480"
  },
  {
    "text": "that you're using for train. If you use the same\nexact data points, then you'll meta-train\nit to be able to memorize",
    "start": "1537480",
    "end": "1543005"
  },
  {
    "text": "the things that\nyou give as input and not actually learn the\ntask that you care about.",
    "start": "1543005",
    "end": "1549570"
  },
  {
    "text": "That said, when you\ndo sample a task and when you sample\nthe images in step 2,",
    "start": "1549570",
    "end": "1555629"
  },
  {
    "text": "it's OK to kind of mix\nand match which images you use for train\nand test across",
    "start": "1555630",
    "end": "1561000"
  },
  {
    "text": "these different iterations. The most important\nthing, though, is that within step 3\nand step 4 that these",
    "start": "1561000",
    "end": "1567260"
  },
  {
    "text": "are-- that you have some\nimages in the test set that are held out. Yeah? So my question is\nregarding testing results.",
    "start": "1567260",
    "end": "1575240"
  },
  {
    "text": "Could we do any\n[INAUDIBLE] during testing?",
    "start": "1575240",
    "end": "1581392"
  },
  {
    "text": "You mean after the\nmeta-training process? Yeah, after the-- Yeah, exactly. Yeah, let's go through that.",
    "start": "1581392",
    "end": "1586880"
  },
  {
    "text": "It's a great transition. So at meta-test time, we are\ngoing to be given a task.",
    "start": "1586880",
    "end": "1599899"
  },
  {
    "text": "We can call it task j. And then we'll also\nbe given a training data set for that task.",
    "start": "1599900",
    "end": "1606330"
  },
  {
    "text": "And after the\nmeta-testing process, what we'll be given is we'll--",
    "start": "1606330",
    "end": "1611509"
  },
  {
    "text": "kind of at the end,\nI guess, the output is a set of\nmeta-parameters theta.",
    "start": "1611510",
    "end": "1618485"
  },
  {
    "text": " And so what we're\ngoing to do is we're",
    "start": "1618485",
    "end": "1624200"
  },
  {
    "text": "going to run gradient descent. So we're basically just going\nto run fine tuning starting",
    "start": "1624200",
    "end": "1629990"
  },
  {
    "text": "from meta-parameters\ntheta on the training data that we have for our new task. So our estimate for the\nparameters for task j",
    "start": "1629990",
    "end": "1638520"
  },
  {
    "text": "are going to correspond to\ntheta minus alpha grad theta of the loss function for\nthe training data set.",
    "start": "1638520",
    "end": "1651120"
  },
  {
    "text": "It's a good idea to use\nroughly the same number of gradient steps in\nthe inner loop in step 3",
    "start": "1651120",
    "end": "1657090"
  },
  {
    "text": "as you use at meta-test time. You want meta-training\ntime and meta-test time to match so that you are\npreparing the method for what",
    "start": "1657090",
    "end": "1663720"
  },
  {
    "text": "will happen at meta-test time. Of course, once you have\nthese task-specific parameters",
    "start": "1663720",
    "end": "1669920"
  },
  {
    "text": "for your test task, then you\ncan make predictions on new data points by give it an input,\npass it through your function",
    "start": "1669920",
    "end": "1679280"
  },
  {
    "text": "f of by j to get a\ncorresponding prediction. ",
    "start": "1679280",
    "end": "1690559"
  },
  {
    "text": "Now, this algorithm--\nthe algorithm",
    "start": "1690560",
    "end": "1695712"
  },
  {
    "text": "where you learn these\nset of initial parameters is referred to as\nmodel-agnostic meta-learning. And the reason why it's called\nthat is that nowhere in here",
    "start": "1695712",
    "end": "1704880"
  },
  {
    "text": "do you see anything about a\nneural network architecture or model. And in that sense,\nthe algorithm is",
    "start": "1704880",
    "end": "1712649"
  },
  {
    "text": "somewhat agnostic to the\nparticular architecture that you use. You can parameterize the model--",
    "start": "1712650",
    "end": "1718640"
  },
  {
    "text": "the f model here\nhowever you want. And as long as it's amenable\nto gradient descent,",
    "start": "1718640",
    "end": "1724550"
  },
  {
    "text": "you can optimize for\ninitialization of that model such that gradient\ndescent gives you a good generalization\non the kinds of tasks",
    "start": "1724550",
    "end": "1731677"
  },
  {
    "text": "that you meta-train train it on. ",
    "start": "1731677",
    "end": "1739680"
  },
  {
    "text": "Cool. So we've already gone through\nthe algorithm on the board. Again, the only difference\nfrom the black box approach",
    "start": "1739680",
    "end": "1746860"
  },
  {
    "text": "is that instead of running\nthe training data set through a neural\nnetwork, we're going to run gradient descent on--",
    "start": "1746860",
    "end": "1753309"
  },
  {
    "text": "starting from our\ninitial meta-parameters. The other thing that\nI'll note here is--",
    "start": "1753310",
    "end": "1760170"
  },
  {
    "text": "or just try to\nemphasize here is, like in the black box approach,\nwhen we evaluate phi i,",
    "start": "1760170",
    "end": "1767110"
  },
  {
    "text": "we're not taking a gradient\nwith respect to phi i. We're taking a gradient\nwith respect to theta. And in this sense, we're\nsort of treating phi",
    "start": "1767110",
    "end": "1774520"
  },
  {
    "text": "i more as activations\nthan as weights. We're not ever running gradient\ndescent on phi i itself. It's more of a product\nof the inner loop.",
    "start": "1774520",
    "end": "1782710"
  },
  {
    "text": "And yeah. Something to keep in mind.",
    "start": "1782710",
    "end": "1788080"
  },
  {
    "text": "Yeah? So on the same thing. Why does it do more\ntraining on phi i?",
    "start": "1788080",
    "end": "1796204"
  },
  {
    "text": "The question is, why doesn't\nalpha not train it on phi i? So if you-- so phi i is kind\nof the output of step 3,",
    "start": "1796204",
    "end": "1805470"
  },
  {
    "text": "and there's nothing that-- if you then updated\nphi i in some way,",
    "start": "1805470",
    "end": "1810480"
  },
  {
    "text": "there's nothing that\nrelies on that updated phi i in the process. And so it would sort of--",
    "start": "1810480",
    "end": "1816360"
  },
  {
    "text": "similar to how when\nphi i was activations, it's something that sort of\ngets wiped out at the next time",
    "start": "1816360",
    "end": "1822929"
  },
  {
    "text": "you look at the task. ",
    "start": "1822930",
    "end": "1828740"
  },
  {
    "text": "Yeah? Sorry. I might be hurt here, but\ndo you have results to show? I see that you're the\nfirst one on this paper.",
    "start": "1828740",
    "end": "1834940"
  },
  {
    "text": "Yeah, I can show some results. ",
    "start": "1834940",
    "end": "1840074"
  },
  {
    "text": "I'm curious to know\nhow this [INAUDIBLE].. Yeah. So I was going to go\nthrough some math, but maybe I could skip to\nthe results a little bit",
    "start": "1840074",
    "end": "1846713"
  },
  {
    "text": "first, and then go\nthrough some of the math. So this is kind of skipping\nahead a little bit,",
    "start": "1846713",
    "end": "1852250"
  },
  {
    "text": "but there's one-- ",
    "start": "1852250",
    "end": "1858500"
  },
  {
    "text": "so there's one\npaper that actually ran architecture search in\naddition to this algorithm.",
    "start": "1858500",
    "end": "1864049"
  },
  {
    "text": "And so they were actually\nadditionally optimizing for-- for an architecture that is--",
    "start": "1864050",
    "end": "1871850"
  },
  {
    "text": "for which this\nactually works well. The kind of basic architecture\non 5-way, 5-shot mini-image",
    "start": "1871850",
    "end": "1877640"
  },
  {
    "text": "that gets you 63.1% which is\na lot better than what you've",
    "start": "1877640",
    "end": "1883490"
  },
  {
    "text": "been doing in homework\n1 if you've gotten started with homework 1. And if you also optimize\nfor the architecture,",
    "start": "1883490",
    "end": "1889555"
  },
  {
    "text": "you can do even\nbetter than that. You can get up to 74%. The state-of-the-art these\ndays I think is in the low 80s",
    "start": "1889555",
    "end": "1898279"
  },
  {
    "text": "at this point, and there's--  in-- well, we'll get into\nthis a little bit later.",
    "start": "1898280",
    "end": "1905210"
  },
  {
    "text": "But in general, these kinds of\napproaches are competitive with state-of-the-art. Also, the approaches that\nwe'll talk about on Wednesday",
    "start": "1905210",
    "end": "1910832"
  },
  {
    "text": "are also competitive on these\nimage classification problems. But I actually also think\nthat the image classification",
    "start": "1910832",
    "end": "1916700"
  },
  {
    "text": "benchmarks themselves are\nnot the most interesting benchmarks, because even\njust learning good features",
    "start": "1916700",
    "end": "1922070"
  },
  {
    "text": "can do very well on\nthose benchmarks. And there are a lot of other\napplication domains where",
    "start": "1922070",
    "end": "1929090"
  },
  {
    "text": "we're-- getting good features\nisn't quite enough. And so we've seen the\napplications in drug discovery",
    "start": "1929090",
    "end": "1934820"
  },
  {
    "text": "as one example that\ncan do quite well. I guess the short\nTLDR though, is",
    "start": "1934820",
    "end": "1939910"
  },
  {
    "text": "that these kinds of\napproaches can do quite well on meta-learning problems. Yeah?",
    "start": "1939910",
    "end": "1945240"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "1945240",
    "end": "1950892"
  },
  {
    "text": "Yeah, I can't remember\nactually the specific approach that they used in this\npaper, but one thing that was interesting is\nthat instead of--",
    "start": "1950892",
    "end": "1958290"
  },
  {
    "text": "they found a fairly\nnon-standard architecture-- one that is actually\nquite deep and narrow. And typically deep and\nnarrow things are not--",
    "start": "1958290",
    "end": "1965310"
  },
  {
    "text": "typically, you want enough\nwidth to be able to optimize, so it was kind of\ninteresting that it",
    "start": "1965310",
    "end": "1971400"
  },
  {
    "text": "found something a little\nbit different from that. But you can take a look at the-- if you search for\nKim in Autometa, you'll be able to\nfind the paper.",
    "start": "1971400",
    "end": "1977395"
  },
  {
    "text": " Cool. Let's go back to\nsome math though.",
    "start": "1977395",
    "end": "1983225"
  },
  {
    "text": " So one thing that\nactually no one",
    "start": "1983225",
    "end": "1988582"
  },
  {
    "text": "has brought up in\nthe questions yet is that this is actually\ngoing to bring up some second-order derivatives.",
    "start": "1988582",
    "end": "1994270"
  },
  {
    "text": "And the reason for that is that\nyou have the inner loop here which has a gradient\nwith respect to theta, and you also have\nthe outer loop which",
    "start": "1994270",
    "end": "2000773"
  },
  {
    "text": "also has a gradient\nwith respect to theta. And so you might wonder, do\nwe need to compute a Hessian?",
    "start": "2000773",
    "end": "2009030"
  },
  {
    "text": "Hessians in deep\nlearning are very scary, because if you have an\nn dimensional parameter vector, then the Hessian\nis going to be n squared.",
    "start": "2009030",
    "end": "2015760"
  },
  {
    "text": "And so if you have a\nmillion parameters, that's going to be a million\nsquared values in this Hessian.",
    "start": "2015760",
    "end": "2021880"
  },
  {
    "text": "Also, if you want to run\nmore integrated steps, there's this question\nof, do you get even higher-order derivatives?",
    "start": "2021880",
    "end": "2028350"
  },
  {
    "text": "So we're going to\ndo a bit of math. I guess to preface some of\nthe math, if some of you",
    "start": "2028350",
    "end": "2033870"
  },
  {
    "text": "are scared of math, PyTorch\nwill do all the math for you.",
    "start": "2033870",
    "end": "2040120"
  },
  {
    "text": "And so don't worry too much. But I think doing-- looking--\ngoing through the math",
    "start": "2040120",
    "end": "2046070"
  },
  {
    "text": "is actually really\nhelpful for understanding what happens under\nthe hood and what is actually the complexity of\nthese algorithms in practice.",
    "start": "2046070",
    "end": "2055800"
  },
  {
    "text": "So the first thing that\nyou need to do-- need to know before we\nget into the math",
    "start": "2055800",
    "end": "2061429"
  },
  {
    "text": "of the meta-learning\nalgorithms is about Hessian vector products.",
    "start": "2061429",
    "end": "2067419"
  },
  {
    "text": "And the cool thing about\nHessian vector products is that you can\nactually compute them",
    "start": "2067420",
    "end": "2076239"
  },
  {
    "text": "much more cheaply than trying\nto compute the Hessian itself.",
    "start": "2076239",
    "end": "2081408"
  },
  {
    "text": "And in particular, if we can\nactually compute these kind of meta-gradients\nwithout actually--",
    "start": "2081409",
    "end": "2089350"
  },
  {
    "text": "it would be really\nnice if we didn't have to basically construct\nthe whole Hessian in order to compute these meta-gradients.",
    "start": "2089350",
    "end": "2094989"
  },
  {
    "text": "And so in particular,\none intuition",
    "start": "2094989",
    "end": "2100613"
  },
  {
    "text": "that you can think\nof for this is, say we have some function f. The gradient of\nthat function is g.",
    "start": "2100613",
    "end": "2106650"
  },
  {
    "text": "Then say that we are evaluating\ng of the gradient of f",
    "start": "2106650",
    "end": "2113640"
  },
  {
    "text": "at x plus delta x.",
    "start": "2113640",
    "end": "2118660"
  },
  {
    "text": "Then we know that this\nis roughly equal to g",
    "start": "2118660",
    "end": "2124720"
  },
  {
    "text": "of x plus h of x times delta x.",
    "start": "2124720",
    "end": "2132250"
  },
  {
    "text": "So this is just a kind of\ntypical Taylor expansion. And from here, if we replace\ndelta x by r times some vector",
    "start": "2132250",
    "end": "2151430"
  },
  {
    "text": "v-- so r is going to\nbe some small value--  g of x plus rv.",
    "start": "2151430",
    "end": "2158240"
  },
  {
    "text": "So these ultimately\ngoing to be the vector that we want to be\nable to compute, so our goal is going to be\nable to compute h of x times",
    "start": "2158240",
    "end": "2165590"
  },
  {
    "text": "v. If you replace delta\nx with rv, then you get--",
    "start": "2165590",
    "end": "2172270"
  },
  {
    "text": "this equals g of x\nplus rH of x times z.",
    "start": "2172270",
    "end": "2181140"
  },
  {
    "text": "And from this form, you can\nsee that we can actually move things around and actually\nsolve for H of x times v.",
    "start": "2181140",
    "end": "2189060"
  },
  {
    "text": "And what we get\nis H of x times v",
    "start": "2189060",
    "end": "2195220"
  },
  {
    "text": "is roughly equal to g of x plus\nrv minus g of x divided by r.",
    "start": "2195220",
    "end": "2203710"
  },
  {
    "text": " Can double-check my math.",
    "start": "2203710",
    "end": "2208720"
  },
  {
    "text": "Yeah, yeah. And the cool thing\nabout this is that it",
    "start": "2208720",
    "end": "2213880"
  },
  {
    "text": "means that you could actually\napproximately compute this Hessian vector product with\njust two gradient evaluations.",
    "start": "2213880",
    "end": "2221849"
  },
  {
    "text": "And that's really\nawesome because that means that we don't have to\ncompute this giant Hessian. And this is going to be more\nexpensive than one gradient",
    "start": "2221850",
    "end": "2228600"
  },
  {
    "text": "evaluation of course, but it's-- but it's a lot cheaper than\ncompeting the whole Hessian.",
    "start": "2228600",
    "end": "2234714"
  },
  {
    "text": "Now you might\nwonder, OK, we have this approximation sign here. Can we get the exact Hessian?",
    "start": "2234715",
    "end": "2240829"
  },
  {
    "text": "And there are\nactually algorithms that have the same\ncomplexity that will also give you the exact Hessian.",
    "start": "2240830",
    "end": "2246360"
  },
  {
    "text": "I'm not going to go into those,\nbut Perlmutter's algorithm is one example of that. But this gives you a\nlittle bit of intuition",
    "start": "2246360",
    "end": "2252620"
  },
  {
    "text": "for how we might go about\ncomputing these kinds of Hessian vector products. ",
    "start": "2252620",
    "end": "2259790"
  },
  {
    "text": "Cool.  Yeah, so that's the good\nnews-- is if we can basically",
    "start": "2259790",
    "end": "2267330"
  },
  {
    "text": "compute the meta-gradient\nas a Hessian vector product, then we can compute it\nwith only around two",
    "start": "2267330",
    "end": "2273270"
  },
  {
    "text": "gradient evaluations. Now let's go back to--",
    "start": "2273270",
    "end": "2278990"
  },
  {
    "text": "let's go back to meta-learning. So we-- and actually,\nfor notational purposes,",
    "start": "2278990",
    "end": "2286780"
  },
  {
    "text": "we're going to have--  we're going to\nseparately represent",
    "start": "2286780",
    "end": "2293460"
  },
  {
    "text": "partial versus full\nderivatives, so I'm going to use d dx to\nrefer to full derivatives.",
    "start": "2293460",
    "end": "2300329"
  },
  {
    "text": "And the gradient of x\nevaluated x equals x prime--",
    "start": "2300330",
    "end": "2305670"
  },
  {
    "text": "or x prime equals x-- this will be kind of\na partial derivative.",
    "start": "2305670",
    "end": "2312730"
  },
  {
    "text": "That will help keep our\nnotation straight a little bit. And remember that phi i is going\nto be equal to theta minus--",
    "start": "2312730",
    "end": "2324980"
  },
  {
    "text": "let's use the full\nderivative here-- dd theta of L of\ntheta comma di train.",
    "start": "2324980",
    "end": "2336200"
  },
  {
    "text": "Cool. So this is everything\nthat we had before, and our goal now is going to\nbe to compute the gradient--",
    "start": "2336200",
    "end": "2342880"
  },
  {
    "text": "or the meta-gradient in step 4.  So the-- the MAML objective\nis to minimize with respect",
    "start": "2342880",
    "end": "2357590"
  },
  {
    "text": "to theta of the loss of phi i\nevaluated at the test data set",
    "start": "2357590",
    "end": "2365720"
  },
  {
    "text": "for that task. So this is the same as\nwhat's written up there.",
    "start": "2365720",
    "end": "2371060"
  },
  {
    "text": "And for this we want to be able\nto compute the gradient of this with respect to theta.",
    "start": "2371060",
    "end": "2377220"
  },
  {
    "text": "And so to do that--  let's see. Let's go over here.",
    "start": "2377220",
    "end": "2382760"
  },
  {
    "text": "So we have d d theta\nof this loss function,",
    "start": "2382760",
    "end": "2391760"
  },
  {
    "text": "and now for this, we\ncan use the chain rule.",
    "start": "2391760",
    "end": "2397820"
  },
  {
    "text": "So if you remember\nyour calculus, first we're going\nto take the gradient of the outer\nobjective, and then we",
    "start": "2397820",
    "end": "2404590"
  },
  {
    "text": "will differentiate\nfrom the inner. So we get the gradient of--",
    "start": "2404590",
    "end": "2412460"
  },
  {
    "text": "I'm going to use phi bar\nhere of L, 5 bar of di test",
    "start": "2412460",
    "end": "2418609"
  },
  {
    "text": "evaluated at phi\nbar equals phi i.",
    "start": "2418610",
    "end": "2427560"
  },
  {
    "text": "And then once we do the\nchain rule on the inner loop, then we just get d phi i,\nd theta, because this isn't",
    "start": "2427560",
    "end": "2434700"
  },
  {
    "text": "a function of theta right here. ",
    "start": "2434700",
    "end": "2440210"
  },
  {
    "text": "So this is the\nderivative of our loss function with respect to theta.",
    "start": "2440210",
    "end": "2446890"
  },
  {
    "text": "Here, this is a row vector,\nso we can refer to this as v.",
    "start": "2446890",
    "end": "2454680"
  },
  {
    "text": "And this is a matrix.",
    "start": "2454680",
    "end": "2459783"
  },
  {
    "text": "And then let's look a little bit\nmore at this matrix right here. ",
    "start": "2459783",
    "end": "2466369"
  },
  {
    "text": "So this matrix--\nd phi i, d theta. If we look at the definition of\nphi, we see d phi i, d theta.",
    "start": "2466370",
    "end": "2476059"
  },
  {
    "text": "Does anyone want\nto give it to me? What do I write next? ",
    "start": "2476060",
    "end": "2485880"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "2485880",
    "end": "2492840"
  },
  {
    "text": "I is a matrix. [INTERPOSING VOICES] Alpha.",
    "start": "2492840",
    "end": "2498454"
  },
  {
    "text": "That's Hessian. Yeah, and then the Hessian. Awesome. Cool. I'm glad some people\nare paying attention.",
    "start": "2498454",
    "end": "2505540"
  },
  {
    "text": "And this will be with\nrespect to a D train i. Cool.",
    "start": "2505540",
    "end": "2510720"
  },
  {
    "text": "And so if we plug this\nexpression in to here, what we're going to get\nis this is equal to v",
    "start": "2510720",
    "end": "2521730"
  },
  {
    "text": "times I minus alpha v-- whoops-- times H right here.",
    "start": "2521730",
    "end": "2530515"
  },
  {
    "text": "So this is just the\nHessian right here. And that's great, because\nwe then get a Hessian vector",
    "start": "2530515",
    "end": "2536020"
  },
  {
    "text": "product right here rather\nthan anything that has to do with the full Hessian.",
    "start": "2536020",
    "end": "2542540"
  },
  {
    "text": "Can people see this? Is this too low? It's OK? OK, good. ",
    "start": "2542540",
    "end": "2550340"
  },
  {
    "text": "Cool. So to answer the\nfirst question, we do get second-order\nderivatives here,",
    "start": "2550340",
    "end": "2556640"
  },
  {
    "text": "but we only get this\nHessian vector product. And so in practice, to\ncompute the meta-gradient for this algorithm, it just\nrequires a few extra backward",
    "start": "2556640",
    "end": "2565430"
  },
  {
    "text": "passes of your neural network. It doesn't require\nanything more than that.",
    "start": "2565430",
    "end": "2571010"
  },
  {
    "text": " Yeah? [INAUDIBLE] with\nmultiple intermediate",
    "start": "2571010",
    "end": "2578380"
  },
  {
    "text": "steps, but does\nthis change at all? Or-- Yeah. So then the question\nis, what happens if you",
    "start": "2578380",
    "end": "2585220"
  },
  {
    "text": "do multiple gradient steps? ",
    "start": "2585220",
    "end": "2590640"
  },
  {
    "text": "So if you do multiple\ngradient steps, then your phi i is going to be\nequal to theta minus alpha d,",
    "start": "2590640",
    "end": "2601425"
  },
  {
    "text": "d theta, L of theta D i train. This is just the first step.",
    "start": "2601425",
    "end": "2606670"
  },
  {
    "text": "And then the second step-- you're going to be\nrunning a second gradient",
    "start": "2606670",
    "end": "2612180"
  },
  {
    "text": "step on this parameter vector. So if we refer to this\nparameter vector as theta prime,",
    "start": "2612180",
    "end": "2620190"
  },
  {
    "text": "then this next step is d, d\ntheta prime of L theta prime D",
    "start": "2620190",
    "end": "2627810"
  },
  {
    "text": "i train. And the key thing to note\nhere is, this second gradient",
    "start": "2627810",
    "end": "2634020"
  },
  {
    "text": "step is with respect to theta\nprime, and not with respect to--",
    "start": "2634020",
    "end": "2639386"
  },
  {
    "text": "well, is with respect\nto theta prime first. And then second,\nthis isn't like-- when you take a\nsecond gradient step,",
    "start": "2639386",
    "end": "2645420"
  },
  {
    "text": "it's not a second-order\ngradient step. It's just a second\ngradient step in sequence. And so when you actually go\nto compute the meta-gradient,",
    "start": "2645420",
    "end": "2654119"
  },
  {
    "text": "you get the same\nexact form as before, except now we have a\ndifferent D phi i, D theta.",
    "start": "2654120",
    "end": "2660269"
  },
  {
    "text": "And so what we're going to\nget for the new D phi i, D theta is going to\nbe the same as before,",
    "start": "2660270",
    "end": "2666370"
  },
  {
    "text": "but now we're going to\nhave a third term, which will look like minus alpha\ntimes this, differentiated.",
    "start": "2666370",
    "end": "2678750"
  },
  {
    "text": "We need to differentiate\nthis third term by theta, and what we get there\nis something like--",
    "start": "2678750",
    "end": "2685340"
  },
  {
    "text": " we do the chain\nrule again, so we're",
    "start": "2685340",
    "end": "2690810"
  },
  {
    "text": "going to do theta bar prime\nL, theta bar prime D i train.",
    "start": "2690810",
    "end": "2699390"
  },
  {
    "text": "This is going to be\nevaluated at theta bar prime equals theta prime times\nD theta prime, D theta.",
    "start": "2699390",
    "end": "2711030"
  },
  {
    "text": "And so, basically you'll get\nthese products of Hessians,",
    "start": "2711030",
    "end": "2717620"
  },
  {
    "text": "but you don't get-- you don't get anything\nthat has a 3 on it.",
    "start": "2717620",
    "end": "2722930"
  },
  {
    "text": "And that's good because\nthe higher this number is, the nastier it gets.",
    "start": "2722930",
    "end": "2729260"
  },
  {
    "text": "Yeah? So, this tells me that the 3 and\n4 are complete gradient steps.",
    "start": "2729260",
    "end": "2734830"
  },
  {
    "text": "So you take one gradient\nstep at 3, and then you do 4, and then you go back\nand do 3 and do 4 for an entire [INAUDIBLE] batch?",
    "start": "2734830",
    "end": "2740860"
  },
  {
    "text": "That's it? Right. So if you were to take\nmultiple gradient steps, that just means that\nthe equation on step 3",
    "start": "2740860",
    "end": "2747190"
  },
  {
    "text": "will have-- will be different. Instead of taking\none gradient step, you will have two\ngradient steps--",
    "start": "2747190",
    "end": "2754780"
  },
  {
    "text": "like what's written here. And so the only\nthing that-- if you take multiple inner-gradient\nsteps that's changing is just that the equation in 3\nwill be a little bit different.",
    "start": "2754780",
    "end": "2761473"
  },
  {
    "text": "How do I know theta\nprime at fourth step, and have already completed\nthe multiple gradient",
    "start": "2761473",
    "end": "2768420"
  },
  {
    "text": "steps at the third one? When you actually\nbackprop through, you need to actually store\nall the intermediate parameter",
    "start": "2768420",
    "end": "2776920"
  },
  {
    "text": "vector values. Because basically\nyou can think of it as you're going to kind of--",
    "start": "2776920",
    "end": "2783180"
  },
  {
    "text": "the forward process\nof this inner loop is running gradient descent. And then to backpropagate\nthrough-- backprop",
    "start": "2783180",
    "end": "2789450"
  },
  {
    "text": "through that again, you\nneed to kind of backprop through those gradient steps. And so, the-- while we don't\nget third-order gradients,",
    "start": "2789450",
    "end": "2799417"
  },
  {
    "text": "if you have a lot\nof inner loop steps, it will increase the amount\nof memory usage linearly,",
    "start": "2799417",
    "end": "2807100"
  },
  {
    "text": "and also increase\ncompute as well. Yeah? So is taking multiple gradient\nsteps worth the overhead?",
    "start": "2807100",
    "end": "2816130"
  },
  {
    "text": "Yeah. So the question is, is\ntaking multiple gradient steps worth the overhead?",
    "start": "2816130",
    "end": "2821580"
  },
  {
    "text": "For future learning\nproblems, you actually don't need a very large\nnumber of gradient steps. You can actually do quite well\nwith a pretty small number",
    "start": "2821580",
    "end": "2828630"
  },
  {
    "text": "of gradient steps-- between one and\nfive gradient steps. And so in practice, at\nleast from what I've seen,",
    "start": "2828630",
    "end": "2835490"
  },
  {
    "text": "you don't actually need more\nthan five inner-gradient steps. And that ends up\nworking pretty well",
    "start": "2835490",
    "end": "2840770"
  },
  {
    "text": "on few-shot learning problems. And it's also not\nthat expensive. If you wanted to run a\nhundred gradient steps,",
    "start": "2840770",
    "end": "2847020"
  },
  {
    "text": "things get a lot more expensive. And in two weeks\nwe're going to talk about more advanced\nmeta-learning techniques,",
    "start": "2847020",
    "end": "2853020"
  },
  {
    "text": "including ways to differentiate\nthrough, like, hundreds of gradient steps. And doing something\nlike this with hundreds",
    "start": "2853020",
    "end": "2859350"
  },
  {
    "text": "of inner-gradient steps\nis not a great approach. Yeah? Yeah, so I'm trying to connect\nthese Hessians vector products",
    "start": "2859350",
    "end": "2868380"
  },
  {
    "text": "with the [INAUDIBLE] we have. So these are the same\nas alpha in this case? Like, the--",
    "start": "2868380",
    "end": "2874410"
  },
  {
    "text": " The r here? Yeah, the r here. So you can think of this as\na finite difference method,",
    "start": "2874410",
    "end": "2882450"
  },
  {
    "text": "and r just needs\nto be small here. And so it's not quite\nthe same as alpha.",
    "start": "2882450",
    "end": "2888682"
  },
  {
    "text": "The most-- the biggest\nthing is that v is the same. So v here is the\nsame as v there,",
    "start": "2888682",
    "end": "2895290"
  },
  {
    "text": "and r will be separately chosen. So alpha is just going to\nbe the multiplier based off of the inner-learning rate,\nwhereas to compute this--",
    "start": "2895290",
    "end": "2902767"
  },
  {
    "text": "if you wanted to use finite\ndifferences to compute this, you would separately\nselect a small r",
    "start": "2902767",
    "end": "2908880"
  },
  {
    "text": "to use with finite differences. And in practice, you-- things like PyTorch will\nnot use finite differences.",
    "start": "2908880",
    "end": "2915710"
  },
  {
    "text": "They'll actually give you an\nexact Hessian vector product. Yeah? So does [INAUDIBLE] do not\nhave labels in [INAUDIBLE]??",
    "start": "2915710",
    "end": "2923338"
  },
  {
    "start": "2923338",
    "end": "2928559"
  },
  {
    "text": "So D train does have labels. So it will have both the\nexamples and the labels. You'll only be\npassing the examples",
    "start": "2928560",
    "end": "2934840"
  },
  {
    "text": "into your neural network. But then, to compute the\ngradient in your inner loop,",
    "start": "2934840",
    "end": "2940902"
  },
  {
    "text": "you'll use the labels there. But in the black\nbox [INAUDIBLE],, we do not need a label? [INAUDIBLE] which class\nis the most similar to",
    "start": "2940903",
    "end": "2948460"
  },
  {
    "text": "one of the sample [INAUDIBLE]? So the black box\n[INAUDIBLE] also actually did need the labels as well,\nand so we were actually",
    "start": "2948460",
    "end": "2955337"
  },
  {
    "text": "passing those in to the\nneural network as well. And the reason why it needed\nthat is it needed to--",
    "start": "2955337",
    "end": "2960580"
  },
  {
    "text": "it needed to know what to\noutput for this letter. And so it could tell you, OK,\nit's the same class as this.",
    "start": "2960580",
    "end": "2966130"
  },
  {
    "text": "But then it needs to give\nyou a number for that class. And so we passed in the labels\nfor that reason for black box as well.",
    "start": "2966130",
    "end": "2971440"
  },
  {
    "text": "[INAUDIBLE] It's supervised, yeah. Yeah? [INAUDIBLE] labeled-- changed\nthe labels, changed [INAUDIBLE]",
    "start": "2971440",
    "end": "2988400"
  },
  {
    "text": "label, but they don't\nwant a label [INAUDIBLE]?? ",
    "start": "2988400",
    "end": "2995020"
  },
  {
    "text": "Yeah, it does solve phi. So the question is, the\nkind of-- here the label--",
    "start": "2995020",
    "end": "3001050"
  },
  {
    "text": "we assigned labels 0 to A in\nthis task, but in another task you might assign a\ndifferent label to A. Because the assignment\nof labels to images",
    "start": "3001050",
    "end": "3009510"
  },
  {
    "text": "is somewhat arbitrary in\nclassification problems, and so it's also useful\nto kind of randomize",
    "start": "3009510",
    "end": "3016410"
  },
  {
    "text": "that assignment across tasks. [INAUDIBLE]? ",
    "start": "3016410",
    "end": "3023490"
  },
  {
    "text": "For other problems,\nbecause [INAUDIBLE]?? Yeah. So for things like\nregression problems,",
    "start": "3023490",
    "end": "3030000"
  },
  {
    "text": "you'll typically keep\nthe label intact, yeah. And we'll talk a little bit\nmore about some of that stuff",
    "start": "3030000",
    "end": "3036525"
  },
  {
    "text": "in two weeks in some of the\nadvanced meta-learning topics. Yeah? Why don't-- does\nthe Hessian first?",
    "start": "3036525",
    "end": "3042599"
  },
  {
    "text": "The Hessian-- The Hessian vector product, yeah. [INAUDIBLE] And that's-- by default,\nthat's [INAUDIBLE]?? Yeah.",
    "start": "3042600",
    "end": "3048760"
  },
  {
    "text": "So here's my slide on that. [LAUGHTER] [INAUDIBLE]",
    "start": "3048760",
    "end": "3055490"
  },
  {
    "text": " Any other questions? ",
    "start": "3055490",
    "end": "3064090"
  },
  {
    "text": "Oh, question? No. OK, cool. Good. OK, we also went through\nmeta-test time already,",
    "start": "3064090",
    "end": "3071470"
  },
  {
    "text": "but it's on the slide in case\nyou want a reference for that. And the gist of it is\njust to run fine tuning.",
    "start": "3071470",
    "end": "3080299"
  },
  {
    "text": "Cool. So yeah, that was really\nthe overall basics of optimization-based\nmeta-learning.",
    "start": "3080300",
    "end": "3087910"
  },
  {
    "text": "Now let's compare\noptimization-based versus black box\nmeta-learning, and then also talk about some\nchallenges and solutions.",
    "start": "3087910",
    "end": "3093800"
  },
  {
    "text": "If we have a little bit of time,\nwe'll also look at a case study at the end. So at a conceptual\nlevel, there's",
    "start": "3093800",
    "end": "3103400"
  },
  {
    "text": "a way that you can look\nat these two things in a way that's quite similar. So the general form of\nblack box adaptation",
    "start": "3103400",
    "end": "3109099"
  },
  {
    "text": "was to pass in the training\ndata set and the test input into this big neural network\nand get a corresponding label",
    "start": "3109100",
    "end": "3115160"
  },
  {
    "text": "or a corresponding prediction. For an algorithm like\nMAML, you can also",
    "start": "3115160",
    "end": "3120920"
  },
  {
    "text": "view it in a very similar light\nas a kind of a computation graph that takes as input the\ntraining data set and the test",
    "start": "3120920",
    "end": "3128090"
  },
  {
    "text": "input. And the way that\nit looks like that is, essentially you can view\nit as a computation graph that",
    "start": "3128090",
    "end": "3135680"
  },
  {
    "text": "just has a gradient step\ninside the computation graph. So D train and x\ntest are still inputs",
    "start": "3135680",
    "end": "3141680"
  },
  {
    "text": "to that overarching\ncomputation graph. It's just that it has a gradient\nstep inside of it where we're",
    "start": "3141680",
    "end": "3146900"
  },
  {
    "text": "taking a gradient with respect\nto our training data points to get our parameters\nand make predictions",
    "start": "3146900",
    "end": "3154607"
  },
  {
    "text": "based on those parameters.  So from this view, you can--",
    "start": "3154607",
    "end": "3162880"
  },
  {
    "text": "they end up looking more\nsimilar than perhaps they look like on the previous slides.",
    "start": "3162880",
    "end": "3169700"
  },
  {
    "text": "And also from this\nview, it means that you can somewhat\nmix and match components of your computation graph.",
    "start": "3169700",
    "end": "3174930"
  },
  {
    "text": "And there are methods\nthat, for example, have learned an\ninitialization but replaced the gradient update\nwith a learned network.",
    "start": "3174930",
    "end": "3183140"
  },
  {
    "text": "And for example, this\npaper does something like that where it\nlearns theta, and it also learns this network that\nkind of takes the gradient",
    "start": "3183140",
    "end": "3189980"
  },
  {
    "text": "and warps it in some way to\npredict a different gradient than the actual gradient.",
    "start": "3189980",
    "end": "3195260"
  },
  {
    "text": "And this paper actually\nprecedes the MAML paper, and I guess I\nmentioned this as a--",
    "start": "3195260",
    "end": "3203180"
  },
  {
    "text": "a conceptual thing that's\nkind of interesting. In practice, I wouldn't\nrecommend using this algorithm.",
    "start": "3203180",
    "end": "3210342"
  },
  {
    "text": "It's a little bit\nmore complicated and tends to not work as\nwell as actually just using the gradient. But it's something that I think\nis useful to know conceptually.",
    "start": "3210343",
    "end": "3217955"
  },
  {
    "text": " Cool. And then we'll also look\nat this again on Wednesday",
    "start": "3217955",
    "end": "3224829"
  },
  {
    "text": "when we look at a third\nclass of approaches. ",
    "start": "3224830",
    "end": "3230090"
  },
  {
    "text": "Now-- now let's actually look\nat how these algorithms perform",
    "start": "3230090",
    "end": "3235100"
  },
  {
    "text": "in practice. So in general, both of them\ncan represent a variety",
    "start": "3235100",
    "end": "3240320"
  },
  {
    "text": "of learning algorithms. But one thing that's nice\nabout the optimization-based",
    "start": "3240320",
    "end": "3245359"
  },
  {
    "text": "meta-learning algorithms\nis that at meta-test time, you're literally just\nrunning fine tuning.",
    "start": "3245360",
    "end": "3251430"
  },
  {
    "text": "And so even if\nyou don't actually have a very good set\nof meta-parameters, fine-tuning should\nstill give you",
    "start": "3251430",
    "end": "3257060"
  },
  {
    "text": "something that improves on the\nparameter vector that you have.",
    "start": "3257060",
    "end": "3263220"
  },
  {
    "text": "Whereas, if you\njust throw something into a recurrent neural\nnetwork, you can't really--",
    "start": "3263220",
    "end": "3269096"
  },
  {
    "text": "you can't really expect\nit to necessarily give you something reasonable\nif the data set is out of distribution from\nthe task that it solved before.",
    "start": "3269096",
    "end": "3276480"
  },
  {
    "text": "And so we can\nexplicitly test this. And so we're going to compare\nan optimization-based algorithm,",
    "start": "3276480",
    "end": "3281870"
  },
  {
    "text": "MAML, with two black\nbox algorithms called SNAIL and MetaNetworks. And specifically, we're going\nto look at omniglot image",
    "start": "3281870",
    "end": "3289010"
  },
  {
    "text": "classification, and we're\ngoing to look at performance as you vary the task.",
    "start": "3289010",
    "end": "3295900"
  },
  {
    "text": "And in particular, the first\nthing we're going to look at is all of the\nalgorithms are just",
    "start": "3295900",
    "end": "3302320"
  },
  {
    "text": "meta-trained on the\noriginal omniglot data set. But then we evaluated\nthem on tasks that",
    "start": "3302320",
    "end": "3307690"
  },
  {
    "text": "had digits that were warped. And so they were all\ntrained on the center line,",
    "start": "3307690",
    "end": "3315073"
  },
  {
    "text": "so they're going to do\nthe best at the center. But then as you warp the-- as you warp the\ncharacters more and more,",
    "start": "3315073",
    "end": "3321880"
  },
  {
    "text": "the performance will\nget worse because it's more out of distribution. And so what we find here is\nthat an algorithm like MAML",
    "start": "3321880",
    "end": "3329050"
  },
  {
    "text": "actually is able\nto generalize much better to these distribution\ntasks compared to something",
    "start": "3329050",
    "end": "3334570"
  },
  {
    "text": "like the black box\nmeta-learners because it has this kind of structure\nof running gradient descent",
    "start": "3334570",
    "end": "3340510"
  },
  {
    "text": "embedded within it. And it's just running\nfine tuning at test time. ",
    "start": "3340510",
    "end": "3345980"
  },
  {
    "text": "We can also look at\nthis on a second task. This is-- we're kind of\nwarping the size of the digits. And here we see a\nsimilar trend where",
    "start": "3345980",
    "end": "3352830"
  },
  {
    "text": "the optimization-based algorithm\nis better able to extrapolate.",
    "start": "3352830",
    "end": "3357985"
  },
  {
    "text": "Yeah?  [INAUDIBLE] because they\ncome from a black [INAUDIBLE]",
    "start": "3357985",
    "end": "3365560"
  },
  {
    "text": "and fine-tune them on\nthe gradients [INAUDIBLE] we really support the\n[INAUDIBLE] performance?",
    "start": "3365560",
    "end": "3371615"
  },
  {
    "text": "You're asking, can\nyou-- as a baseline, can you fine-tune the\nblack box meta-learning? Yeah, the black box\nparameters [INAUDIBLE],,",
    "start": "3371615",
    "end": "3377500"
  },
  {
    "text": "and then fine-tune them on\nthe-- on the [INAUDIBLE]?? Yeah. Yeah, so if you have A\nblack box meta-learner",
    "start": "3377500",
    "end": "3382865"
  },
  {
    "text": "that's actually\noutputting parameters, then you could also fine-tune\nthose parameters a little bit, and you would expect that to do\na little bit better than if you",
    "start": "3382865",
    "end": "3389640"
  },
  {
    "text": "didn't fine-tune. Both of these approaches,\nSNAIL and MetaNetworks, are not actually outputting\na single set of parameters,",
    "start": "3389640",
    "end": "3395890"
  },
  {
    "text": "but you could sort of fine-tune\nthe last part of the r and n. And in principle, that should\nimprove it a little bit.",
    "start": "3395890",
    "end": "3402360"
  },
  {
    "text": "I suspect that it\nmay not improve it all the way up to\nthe purple line, but I suspect it would\nimprove it a little bit.",
    "start": "3402360",
    "end": "3408930"
  },
  {
    "text": "Yeah? What could explain\nthis rapid fall",
    "start": "3408930",
    "end": "3415440"
  },
  {
    "text": "inaccuracy which\ncomes in the scale and not so much in the shift?",
    "start": "3415440",
    "end": "3420960"
  },
  {
    "text": "Yeah, so the question is, why\nis it dropping more rapidly for the scale versus the shift? ",
    "start": "3420960",
    "end": "3428391"
  },
  {
    "text": "I should say that the\nx-axes on these two plots are not very comparable. One is in scale and one\nof those is in radians.",
    "start": "3428392",
    "end": "3435280"
  },
  {
    "text": "And so, if for\nexample you zoomed out more on the radians plot\nto show a wider range,",
    "start": "3435280",
    "end": "3440820"
  },
  {
    "text": "I would expect it to\ndrop off more quickly. I also think that as you make\na digit smaller and smaller,",
    "start": "3440820",
    "end": "3446977"
  },
  {
    "text": "it's probably a little bit\nharder for the neural network to read than the larger one. And so that's, I\nexpect, why we see",
    "start": "3446977",
    "end": "3453632"
  },
  {
    "text": "more of a drop-off on the left\nside than on the right side. But that's somewhat speculative. Yeah? So what is the underlying\nmodel architecture",
    "start": "3453632",
    "end": "3460260"
  },
  {
    "text": "chosen for both\nalgorithms for all the-- What is the underlying\nmodel architecture? So for MAML, it's a four-layer\nconvolutional network with,",
    "start": "3460260",
    "end": "3469890"
  },
  {
    "text": "I think like 32 filters-- something like that-- per layer. And it's kind of a standard\narchitecture that's",
    "start": "3469890",
    "end": "3476820"
  },
  {
    "text": "been used in multiple\nworks, whereas for SNAIL and MetaNetworks,\nthe architecture is a little bit more\nspecific to the method.",
    "start": "3476820",
    "end": "3483840"
  },
  {
    "text": "Because it's kind of a non-model\nagnostic method, it's kind of-- yeah, and so SNAIL was the one\nthat used the interleaved--",
    "start": "3483840",
    "end": "3492390"
  },
  {
    "text": "the interleaved convolutions\nand attention layers. [INAUDIBLE] convolutions\n[INAUDIBLE] For?",
    "start": "3492390",
    "end": "3499528"
  },
  {
    "text": "The scale of the shifting part?  You're asking me if the\nconvolutional layers help--",
    "start": "3499528",
    "end": "3506009"
  },
  {
    "text": "Help with the--\nunderstanding the gradients in the data distribution, which\nis the scale of the shift. Whereas the SNAIL I guess\njust use RNNs, right?",
    "start": "3506010",
    "end": "3514500"
  },
  {
    "text": "So SNAIL-- so SNAIL was using-- ",
    "start": "3514500",
    "end": "3519680"
  },
  {
    "text": "I can't remember if there was-- I'm pretty sure there\nwas a backbone that was convolution-based.",
    "start": "3519680",
    "end": "3525859"
  },
  {
    "text": "And likewise for MetaNetworks. I can't remember the specifics\nof it, unfortunately, but I'm pretty sure\nit is using that.",
    "start": "3525860",
    "end": "3532845"
  },
  {
    "text": "And I should mention\nand emphasize here that all of these were\nonly trained on this scale, and so they were\nnot-- they didn't",
    "start": "3532845",
    "end": "3537980"
  },
  {
    "text": "see any data at different\nscales and different sheers of the digit. ",
    "start": "3537980",
    "end": "3547540"
  },
  {
    "text": "Cool. So the-- we see that\nwe-- like, the structure",
    "start": "3547540",
    "end": "3553450"
  },
  {
    "text": "of gradient descent is\nhelping us generalize to outer distribution tasks. Now you might wonder\nif this structure",
    "start": "3553450",
    "end": "3559900"
  },
  {
    "text": "comes at a cost, because the-- maybe for example, by\nembedding gradient descent,",
    "start": "3559900",
    "end": "3567200"
  },
  {
    "text": "we don't have as\nmuch expressive power in terms of the algorithms\nthat-- the learning procedures that we can represent.",
    "start": "3567200",
    "end": "3573800"
  },
  {
    "text": "And it turns out that you can\nactually theoretically show that if you have a\ndeep neural network,",
    "start": "3573800",
    "end": "3579730"
  },
  {
    "text": "the MAML function of\nrunning gradient-- one step of gradient\ndescent can actually",
    "start": "3579730",
    "end": "3584830"
  },
  {
    "text": "approximate any function of the\ntraining data set and the test input. So it can sort of approximate\nany learning algorithm.",
    "start": "3584830",
    "end": "3593740"
  },
  {
    "text": "Although it does make some\nnon-trivial assumptions. Well, it assumes that the\nlearning rate is non-zero,",
    "start": "3593740",
    "end": "3599589"
  },
  {
    "text": "that the data points are unique,\nand that the loss function gradient does not lose\ninformation about the label.",
    "start": "3599590",
    "end": "3607120"
  },
  {
    "text": "But really, the\nstrongest assumption is that the network needs to\nbe extremely deep for this sort",
    "start": "3607120",
    "end": "3612700"
  },
  {
    "text": "of result to hold. And you can get more\nexpressive power with the RNN-like approaches\nwith a smaller neural network.",
    "start": "3612700",
    "end": "3621590"
  },
  {
    "text": "Yeah? What does it mean for a\nloss function gradient to lose information\nabout the label? [INAUDIBLE]",
    "start": "3621590",
    "end": "3627760"
  },
  {
    "text": "Yeah, so essentially\nwhat that means is-- just very approximately, is\nif you have one loss function",
    "start": "3627760",
    "end": "3635680"
  },
  {
    "text": "that-- that looks like this\nversus a loss function that looks like this,\nif you just look",
    "start": "3635680",
    "end": "3641950"
  },
  {
    "text": "at the gradient\nof this function, you don't actually know where\nyou are on the line at all. And so that doesn't tell you--",
    "start": "3641950",
    "end": "3648825"
  },
  {
    "text": "you know what your\nprediction is, but it doesn't tell\nyou what the label is relative to your prediction. And so it doesn't hold\nfor L1 loss functions,",
    "start": "3648825",
    "end": "3656980"
  },
  {
    "text": "but it does hold for things\nlike L2 and cross-entropy loss. ",
    "start": "3656980",
    "end": "3662870"
  },
  {
    "text": "Yeah? Why is it that the data\npoints and the data set needs to be unique?",
    "start": "3662870",
    "end": "3669260"
  },
  {
    "text": "Yeah, this is a little\nbit getting into details that aren't super important.",
    "start": "3669260",
    "end": "3674750"
  },
  {
    "text": "But the gist is that if you\nhave duplicates of data points",
    "start": "3674750",
    "end": "3680180"
  },
  {
    "text": "and you want it to give\nyou different phi i's for different numbers of\nduplicates in the data set,",
    "start": "3680180",
    "end": "3686760"
  },
  {
    "text": "it's hard to-- it's hard to understand\nhow many duplicates there are in the gradient.",
    "start": "3686760",
    "end": "3692470"
  },
  {
    "text": "For example, if you think\nabout the gradient of two data points versus the gradient\nof five data points",
    "start": "3692470",
    "end": "3697530"
  },
  {
    "text": "that are identical, the\ngradient is the same because it's just\naveraging across them, and so it's not going to-- the learning\nalgorithm isn't going",
    "start": "3697530",
    "end": "3703720"
  },
  {
    "text": "to be able to\ndifferentiate between-- it's only able to count the\nnumber of data points you have,",
    "start": "3703720",
    "end": "3709620"
  },
  {
    "text": "basically. Yeah? So when would you [INAUDIBLE]? Or is there any point in\nusing black box optimization?",
    "start": "3709620",
    "end": "3719540"
  },
  {
    "text": "Yeah. Let's go through some of the\nchallenges and solutions, and then-- well,\nI'll talk about--",
    "start": "3719540",
    "end": "3725630"
  },
  {
    "text": "I'll get into full depth\nof that on Wednesday. But I'll also talk more\nabout the pros and cons after we go through some of\nthe challenges and solutions.",
    "start": "3725630",
    "end": "3734755"
  },
  {
    "text": "So one reason to\nnot use these kinds of optimization-based\nmethods is that sometimes",
    "start": "3734755",
    "end": "3741430"
  },
  {
    "text": "this sort of\nbi-level optimization can be somewhat unstable\nbecause you have an optimization inside another optimization.",
    "start": "3741430",
    "end": "3748790"
  },
  {
    "text": "And there are ways to try\nto stabilize the process.",
    "start": "3748790",
    "end": "3753980"
  },
  {
    "text": "One way to stabilize\nit is actually to give it a little bit\nmore expressive power. Don't just learn\nthe initialization,",
    "start": "3753980",
    "end": "3760420"
  },
  {
    "text": "but also learn\nthe learning rate. And this has been shown\nto, at least in practice,",
    "start": "3760420",
    "end": "3766480"
  },
  {
    "text": "lead to an easier\nouter optimization.",
    "start": "3766480",
    "end": "3771938"
  },
  {
    "text": "There's also approaches\nthat try to only optimize a subset of the parameters\nin the inner loop. For example, you could\nchoose to only optimize",
    "start": "3771938",
    "end": "3777970"
  },
  {
    "text": "the last layer in\nthe inner loop, or choose to only\noptimize the batch form parameters in your inner\nloop, or something like that.",
    "start": "3777970",
    "end": "3784720"
  },
  {
    "text": " And then there's also some\nwork that showed that if you--",
    "start": "3784720",
    "end": "3791725"
  },
  {
    "text": "that if you have a\ndifferent learning rate in a different batch\nform per gradient setup in the inner loop, that can\nalso help stabilize things.",
    "start": "3791725",
    "end": "3798640"
  },
  {
    "text": "Because if they're\ncoupled, then they-- whenever you have basically\nthe same value for something, it can cause those\nvalues to sort of fight",
    "start": "3798640",
    "end": "3805390"
  },
  {
    "text": "during the optimization\nprocess and not find a good happy medium. ",
    "start": "3805390",
    "end": "3813010"
  },
  {
    "text": "And then, I don't want to go\ninto too much depth in this, but there's also\napproaches that try to introduce a sort\nof context variable",
    "start": "3813010",
    "end": "3821440"
  },
  {
    "text": "that, instead of only\noptimizing for the parameters of this neural network,\nyou can essentially",
    "start": "3821440",
    "end": "3828250"
  },
  {
    "text": "add a variable that's\nkind of part of theta here as part of the network.",
    "start": "3828250",
    "end": "3834920"
  },
  {
    "text": "You can think of this as\nkind of like the zi that we saw in multi-test learning\nthat you're optimizing",
    "start": "3834920",
    "end": "3839980"
  },
  {
    "text": "as well as the other parameters. And this can also kind of\nincrease the expressive power",
    "start": "3839980",
    "end": "3847269"
  },
  {
    "text": "of the meta-optimizer\nand in practice leads to better results as well.",
    "start": "3847270",
    "end": "3854694"
  },
  {
    "text": "I'm more giving this\njust as an overview if you want to dive\na little bit deeper into things that can help\nthese algorithms work better",
    "start": "3854694",
    "end": "3862350"
  },
  {
    "text": "in practice.  Cool. So yeah, a range\nof simple tricks",
    "start": "3862350",
    "end": "3868210"
  },
  {
    "text": "that can help the\noptimization a lot. And then the second main\nchallenge I want to talk about is that if you have one or\na few inner-gradient steps,",
    "start": "3868210",
    "end": "3877175"
  },
  {
    "text": "it's very easy to\ndifferentiate through that. But if you have a lot\nof inner-gradient steps, it becomes very\ncompute-intensive",
    "start": "3877175",
    "end": "3882940"
  },
  {
    "text": "and very memory-intensive. And there are also a few tricks\nfor trying to address this.",
    "start": "3882940",
    "end": "3890500"
  },
  {
    "text": "The first trick is\na bit of a hack, and it's actually\nsomething that I discovered",
    "start": "3890500",
    "end": "3895750"
  },
  {
    "text": "because of a bug in TensorFlow. And in particular,\nthe first time",
    "start": "3895750",
    "end": "3901000"
  },
  {
    "text": "that I implemented\nthe MAML algorithm, it turned out that\nTensorFlow didn't properly",
    "start": "3901000",
    "end": "3908290"
  },
  {
    "text": "implement this term,\nand it just silently basically set this\nto be the identity.",
    "start": "3908290",
    "end": "3913810"
  },
  {
    "text": " And it turns out\nthat actually, if you set it to be the\nidentity, it actually",
    "start": "3913810",
    "end": "3919453"
  },
  {
    "text": "works some of the time. And so, for simple image\nclassification tasks,",
    "start": "3919453",
    "end": "3926870"
  },
  {
    "text": "you can actually-- and that's\nnot the identity, by the way. Yeah. And so yeah, it turns out to\nactually work in some cases.",
    "start": "3926870",
    "end": "3933440"
  },
  {
    "text": "There's another paper that\nexplicitly proposed this sort of first-order method as well.",
    "start": "3933440",
    "end": "3939990"
  },
  {
    "text": "And so if you do approximate\nas the identity, you actually-- you don't have\nany second-order terms,",
    "start": "3939990",
    "end": "3945416"
  },
  {
    "text": "and it can work well\non simple problems. In other problems, I found that\nit doesn't work well at all.",
    "start": "3945416",
    "end": "3953960"
  },
  {
    "text": "Is that why we're using\nPyTorch and not [INAUDIBLE]?? [LAUGHTER]",
    "start": "3953960",
    "end": "3960180"
  },
  {
    "text": " Not quite. I mean, TensorFlow has\nsince fixed this issue. This was very early days in 20--",
    "start": "3960180",
    "end": "3969650"
  },
  {
    "text": "early 2017. Yeah. But since then, both-- and\nactually the early days of PyTorch-- they also didn't\nhave their second-order",
    "start": "3969650",
    "end": "3976508"
  },
  {
    "text": "derivatives properly\nimplemented as well, so-- yeah? Yeah, when you make\nthe [INAUDIBLE],, you simply assume that phi\ni is very similar to theta?",
    "start": "3976508",
    "end": "3984000"
  },
  {
    "text": "[INAUDIBLE]? So it's-- it's basically saying\nthat the loss landscape around",
    "start": "3984000",
    "end": "3993079"
  },
  {
    "text": "phi is very similar to the\nloss landscape around theta. I don't think we know why it\nworks, although my guess would",
    "start": "3993080",
    "end": "4001150"
  },
  {
    "text": "be something that it has to do\nwith the optimization landscape being well-conditioned.",
    "start": "4001150",
    "end": "4006400"
  },
  {
    "text": "But yeah, we don't fully\nknow why this works. Yeah?",
    "start": "4006400",
    "end": "4011510"
  },
  {
    "text": "So [INAUDIBLE],, does that\nmean that the Hessian was not calculated correctly? It was 0, therefore i, or--",
    "start": "4011510",
    "end": "4019490"
  },
  {
    "text": "Yeah, so this was being set to-- to 0. Yeah? So it doesn't-- it did not\nknow how to [INAUDIBLE]??",
    "start": "4019490",
    "end": "4026000"
  },
  {
    "text": "I don't remember the\nexact details of the bug. But it was something like-- I think it was something like\nbasically the Hessian wasn't",
    "start": "4026000",
    "end": "4032600"
  },
  {
    "text": "implemented or something, and\nit was silently returning 0 rather than throwing an error. But why does [INAUDIBLE]?",
    "start": "4032600",
    "end": "4040040"
  },
  {
    "text": "We don't know. It's an observation. It's an observation, yeah.",
    "start": "4040040",
    "end": "4045080"
  },
  {
    "start": "4045080",
    "end": "4050095"
  },
  {
    "text": "Another thing that\nyou can do is, if you don't want\nto backpropagate through many integrated\nsteps of the whole network,",
    "start": "4050095",
    "end": "4055910"
  },
  {
    "text": "if you only optimize the\nlast layer of weights, then this can actually\nbe very cheap.",
    "start": "4055910",
    "end": "4061400"
  },
  {
    "text": "And there are a\nnumber of papers that have done this that actually\nget quite strong results.",
    "start": "4061400",
    "end": "4067349"
  },
  {
    "text": "And in some of these cases,\nyou can actually compute the-- you can compute potentially\nthe last layer in closed form.",
    "start": "4067350",
    "end": "4075050"
  },
  {
    "text": "And that-- yeah, that\nhas a number of benefits. This works especially\nwell in settings where--",
    "start": "4075050",
    "end": "4080810"
  },
  {
    "text": "in image settings\nwhere learning features are a big part of the problem. ",
    "start": "4080810",
    "end": "4088000"
  },
  {
    "text": "Cool. And then there's also something\ncalled the implicit value theorem that is\nactually pretty cool.",
    "start": "4088000",
    "end": "4093670"
  },
  {
    "text": "It allows you to differentiate\nthe meta-gradient without actually differentiating\nthrough the optimization path.",
    "start": "4093670",
    "end": "4099028"
  },
  {
    "text": "We might talk about\nthis a little bit in some of the advanced\nmeta-learning lectures, but I more mentioned\nit here as a reference",
    "start": "4099029",
    "end": "4104790"
  },
  {
    "text": "in case you're interested\nin digging deeper into that. Yeah? In the second idea, is it only\noptimizing the last player",
    "start": "4104790",
    "end": "4111359"
  },
  {
    "text": "in the inner loop\nor the outer loop? In the inner loop. So in-- basically, yeah.",
    "start": "4111359",
    "end": "4117210"
  },
  {
    "text": "In step 3, you only optimize\nthe inner loop, and in step 4 you optimize the whole\nnetwork such that--",
    "start": "4117210",
    "end": "4123929"
  },
  {
    "text": "basically optimize for\nfeatures such that optimizing the inner loop gives\nyou a good performance.",
    "start": "4123930",
    "end": "4130540"
  },
  {
    "text": "Yeah? [INAUDIBLE] layer\nworks the best? Like, [INAUDIBLE]?",
    "start": "4130540",
    "end": "4137009"
  },
  {
    "text": "Yeah, so you could also\nthink about fine-tuning different parts of the network.",
    "start": "4137010",
    "end": "4142047"
  },
  {
    "text": "You could also have\nsomething where you fine-tune the last layer for some tasks\nand fine-tune the first layer for other tasks.",
    "start": "4142048",
    "end": "4147180"
  },
  {
    "text": "Although then there's this-- you have to actually\nselect which layer to adapt for different tasks.",
    "start": "4147180",
    "end": "4153719"
  },
  {
    "text": "There's also a paper that\nactually optimizes everything but the last layer,\nand they actually",
    "start": "4153720",
    "end": "4158880"
  },
  {
    "text": "found pretty good\nresults with that. I'm not exactly sure how\nthey came up with it.",
    "start": "4158880",
    "end": "4165160"
  },
  {
    "text": "It's called BOIL if\nyou want to look it up. But yeah, you could imagine\nsomething like that.",
    "start": "4165160",
    "end": "4171810"
  },
  {
    "text": "[INAUDIBLE] ",
    "start": "4171810",
    "end": "4177040"
  },
  {
    "text": "Cool. And then I already\nshowed this slide, but there's also some works that\nhave looked at architectures for this kind of\nbi-level optimization",
    "start": "4177040",
    "end": "4184950"
  },
  {
    "text": "and have found that actually,\nsometimes deeper and narrow architectures can\nwork pretty well.",
    "start": "4184950",
    "end": "4191299"
  },
  {
    "text": "And yeah, that's the gist of it. So the takeaway\nhere is that we're",
    "start": "4191300",
    "end": "4197639"
  },
  {
    "text": "constructing this bi-level\noptimization problem. In terms of the pros\nand cons, one thing",
    "start": "4197640",
    "end": "4204185"
  },
  {
    "text": "that's really nice\nabout it is it has this sort of\npositive inductive bias at the start of meta-learning.",
    "start": "4204185",
    "end": "4209260"
  },
  {
    "text": "And what I mean by\nthat is, before you do any meta-learning,\nyou're already running gradient\ndescent on your training",
    "start": "4209260",
    "end": "4215910"
  },
  {
    "text": "data set in the inner loop. And that means that\nyou already have a pretty good starting point\nfor learning from data.",
    "start": "4215910",
    "end": "4224950"
  },
  {
    "text": "And in contrast to\nblack box approaches, black box approaches\nare starting with a randomly-initialized\nrecurrent neural network.",
    "start": "4224950",
    "end": "4231160"
  },
  {
    "text": "And so when you pass\nin a data set into that randomly-initialized\nneural network, it doesn't have any sort of\ninductive bias at the beginning",
    "start": "4231160",
    "end": "4238200"
  },
  {
    "text": "that will give you-- that will actually do anything\nremotely like learning at the start of initialization.",
    "start": "4238200",
    "end": "4247400"
  },
  {
    "text": "Because of this, it tends to\nextrapolate a little bit better because you're embedding\ngradient descent, because you're\nrunning fine-tuning.",
    "start": "4247400",
    "end": "4254870"
  },
  {
    "text": "And it's also quite\nexpressive if you have a deep enough neural network. And it's model-agnostic.",
    "start": "4254870",
    "end": "4261973"
  },
  {
    "text": "The downside is,\nit does typically require a second-order\noptimization, which can be computationally--\nit's a little bit-- certainly",
    "start": "4261973",
    "end": "4268070"
  },
  {
    "text": "a little bit more expensive than\nother approaches, especially the approaches we'll\ntalk about on Wednesday.",
    "start": "4268070",
    "end": "4273800"
  },
  {
    "text": "And so this leads to more\ncompute and memory usage. ",
    "start": "4273800",
    "end": "4279260"
  },
  {
    "text": "Cool. We have six minutes,\nso I think I will go through this case study.",
    "start": "4279260",
    "end": "4285800"
  },
  {
    "text": "We'll also look at some more\ncase studies on Wednesday this week.",
    "start": "4285800",
    "end": "4291650"
  },
  {
    "text": "So this was actually some work\ndone by some folks at TUM, and also some folks at Stanford.",
    "start": "4291650",
    "end": "4296860"
  },
  {
    "text": "Sherrie was actually a\nPhD student at Stanford. She graduated I think\nlast year, and is now starting as a professor at MIT.",
    "start": "4296860",
    "end": "4305210"
  },
  {
    "text": "And this is some\nwork that they did on trying to do land\ncover classification.",
    "start": "4305210",
    "end": "4311620"
  },
  {
    "text": "And the motivation is that if\nyou have a satellite image, it's useful to be\nable to predict how the land is being used.",
    "start": "4311620",
    "end": "4319330"
  },
  {
    "text": "This can be used\nfor urban planning, for understanding how things\nare changing over time. But it's very expensive to\nlabel these satellite images,",
    "start": "4319330",
    "end": "4328330"
  },
  {
    "text": "as you might imagine. And so labeling data\nis really expensive,",
    "start": "4328330",
    "end": "4335370"
  },
  {
    "text": "and different regions\nlook different and have different land use proportions. And so this means\nthat if you train",
    "start": "4335370",
    "end": "4340890"
  },
  {
    "text": "a model on one part of\nthe world and then try to apply that model to\nother parts of the world, it may not generalize well\nto all parts of the world.",
    "start": "4340890",
    "end": "4350630"
  },
  {
    "text": "And so what they\nwere looking at is-- they had croplands from\nmultiple different countries,",
    "start": "4350630",
    "end": "4356830"
  },
  {
    "text": "and they framed this as\na meta-learning problem where different tasks\ncorrespond to different regions of the world.",
    "start": "4356830",
    "end": "4363903"
  },
  {
    "text": "And so what they\nwanted to be able to do is, for a new\nregion of the world that they didn't\nhave labels for yet, they wanted to label a small\namount of data for that region",
    "start": "4363903",
    "end": "4371960"
  },
  {
    "text": "and then get a good segmenter\nor classifier for that region of the world that can basically\nfill in the rest of the labels.",
    "start": "4371960",
    "end": "4378350"
  },
  {
    "text": " And so you can\nthink of this as--",
    "start": "4378350",
    "end": "4383460"
  },
  {
    "text": "this is a diagram\nfrom their paper where you try to find a good\nset of initial parameters such that when you fine-tune\non a new region of the world,",
    "start": "4383460",
    "end": "4390340"
  },
  {
    "text": "you're able to quickly\nget a model that can accurately segment\nsatellite images",
    "start": "4390340",
    "end": "4397683"
  },
  {
    "text": "from that part of the world.  So they looked at two\ndifferent data sets.",
    "start": "4397683",
    "end": "4403580"
  },
  {
    "text": "One of the data sets had\ngeographic metadata in it, and so they were able\nto separate out--",
    "start": "4403580",
    "end": "4411260"
  },
  {
    "text": "explicitly separate out\nnew regions of the world. And so blue-- dark\nblue is meta-training,",
    "start": "4411260",
    "end": "4416510"
  },
  {
    "text": "light blue is\nmeta-validation tasks, and orange is meta-test tasks. ",
    "start": "4416510",
    "end": "4422930"
  },
  {
    "text": "And kind of as an example\nof a two-way, two-shot",
    "start": "4422930",
    "end": "4429020"
  },
  {
    "text": "classification\ntask, they're trying to classify if a square\nis forest or croplands.",
    "start": "4429020",
    "end": "4434840"
  },
  {
    "text": "And-- and so they're\ngiven that, and then they have two examples per class of\nwhat those parts of the land",
    "start": "4434840",
    "end": "4445040"
  },
  {
    "text": "look like.  And then they also\nhad a second data set",
    "start": "4445040",
    "end": "4450510"
  },
  {
    "text": "where they were looking at-- where they didn't have any kind\nof geographic metadata, and so they used clustering\nto try to guess",
    "start": "4450510",
    "end": "4456210"
  },
  {
    "text": "the region of the world\nand separate things out into meta-training,\nmeta-validation, and meta-test. And here they are doing\na segmentation task",
    "start": "4456210",
    "end": "4464610"
  },
  {
    "text": "where they were basically--\nthe support set corresponded to one small square,\nand then the query set",
    "start": "4464610",
    "end": "4470280"
  },
  {
    "text": "corresponded to\nthe other squares.  Cool.",
    "start": "4470280",
    "end": "4476410"
  },
  {
    "text": "And so they-- they were\ncomparing randomly initialize--",
    "start": "4476410",
    "end": "4484113"
  },
  {
    "text": "random initialization. So they were\ntraining from scratch on a small amount of data\nfrom that new region.",
    "start": "4484113",
    "end": "4489389"
  },
  {
    "text": "They also compared that to\npre-training on all of the data they had so far and then\nfine-tuning on the target task.",
    "start": "4489390",
    "end": "4496610"
  },
  {
    "text": "And lastly, they compared\nto the MAML algorithm that we talked about today.",
    "start": "4496610",
    "end": "4503130"
  },
  {
    "text": "And what we see is-- here is the results\non the first data set. And this is the performance\nor the accuracy of land cover",
    "start": "4503130",
    "end": "4510260"
  },
  {
    "text": "classification as you\nincrease the number of data points on the target task.",
    "start": "4510260",
    "end": "4516860"
  },
  {
    "text": "First we see that\nrandom initialization isn't able to do\nvery well because it doesn't use any other data.",
    "start": "4516860",
    "end": "4522948"
  },
  {
    "text": "Using a pre-trained network\nis able to do a lot better, especially with less data. And then MAML is able to do--\nif you have one or more data",
    "start": "4522948",
    "end": "4530120"
  },
  {
    "text": "points from the\ntarget region, is able to do even better than\na pre-trained neural network.",
    "start": "4530120",
    "end": "4536265"
  },
  {
    "text": "One benefit to the\npre-trained neural network is it can actually already\ndo descent classification just in-- without any additional\ndata from the new region.",
    "start": "4536265",
    "end": "4543460"
  },
  {
    "text": "And that's why the dark blue is\nabove the orange and the light green at 0. ",
    "start": "4543460",
    "end": "4550170"
  },
  {
    "text": "And then likewise on\nthe DeepGlobe data set, they looked at both a random\nsplit and a harder clustered split.",
    "start": "4550170",
    "end": "4556199"
  },
  {
    "text": "Here the results are similar\non the clustered split. On the random\nsplit, they actually",
    "start": "4556200",
    "end": "4561810"
  },
  {
    "text": "found that the pre-trained\nmodel was able to do quite well. Which makes sense, because\nthe pre-training data",
    "start": "4561810",
    "end": "4567750"
  },
  {
    "text": "and the target data-- you're going to basically\nhave more data points that look more similar across\nthe kind of pre-trained data",
    "start": "4567750",
    "end": "4574829"
  },
  {
    "text": "and the target data.  Cool. And then if you're interested\nin looking at this more,",
    "start": "4574830",
    "end": "4581330"
  },
  {
    "text": "I'd encourage you to\ntake a look at the paper. Here, just kind of--\nyeah, just one example of a fairly real world problem\nof using this kind of approach.",
    "start": "4581330",
    "end": "4588184"
  },
  {
    "text": " Cool, so that's it for today.",
    "start": "4588185",
    "end": "4594170"
  },
  {
    "text": "We covered the basics\nof optimization-based meta-learning, we talked about\nhow it compared with black box meta-learning.",
    "start": "4594170",
    "end": "4599435"
  },
  {
    "text": "On Wednesday, we're\ngoing to be talking about our last class of-- last\ntype of meta-learning method,",
    "start": "4599435",
    "end": "4605290"
  },
  {
    "text": "non-parametric few-shot\nlearning methods. Then next week we'll talk about\nunsupervised pre-training, and the following week we'll\ntalk about more advanced",
    "start": "4605290",
    "end": "4611848"
  },
  {
    "text": "meta-learning topics. Yeah. And as a reminder,\nsubmit your project form and your homework on Wednesday.",
    "start": "4611848",
    "end": "4618840"
  },
  {
    "start": "4618840",
    "end": "4623000"
  }
]
[
  {
    "start": "0",
    "end": "23000"
  },
  {
    "text": "Hi everybody, time to get started. Okay. Um, so, so today what we're gonna talk about is a topic that's, um,",
    "start": "4790",
    "end": "18755"
  },
  {
    "text": "coreference resolution and I'll explain in just a minute what that is, um, but before getting on to that just a,",
    "start": "18755",
    "end": "27060"
  },
  {
    "start": "23000",
    "end": "120000"
  },
  {
    "text": "uh, couple of words on the announcements. Um, so the TAs are feverishly working on getting homework five grades worked out,",
    "start": "27060",
    "end": "35770"
  },
  {
    "text": "so we hope that we can deliver those to you, um, tomorrow just in case you're anxious to know",
    "start": "35770",
    "end": "41600"
  },
  {
    "text": "them before you make your final decisions about things. And then, the other thing that you should be remembering",
    "start": "41600",
    "end": "48290"
  },
  {
    "text": "is that the milestone for the final project is this Tuesday. Now, I will confess that even to me it seems like,",
    "start": "48290",
    "end": "55780"
  },
  {
    "text": "\"Boy, boy this milestone came around really quickly.\" So you probably feel that doubly, I realize.",
    "start": "55780",
    "end": "61680"
  },
  {
    "text": "And so you know, I do apologize for that a little bit, but you know, really our hope was that we could actually use this to be helpful,",
    "start": "61680",
    "end": "71435"
  },
  {
    "text": "and to give you feedback on what you're doing and suggestions, and it just really seemed like, well,",
    "start": "71435",
    "end": "77120"
  },
  {
    "text": "the only chance in which we can kind of, um, turn around giving more feedback on the projects, um,",
    "start": "77120",
    "end": "83899"
  },
  {
    "text": "before it goes into the final week of the quarter is if we can kind of get stuff, um, Tuesday, and hope to be then,",
    "start": "83900",
    "end": "90710"
  },
  {
    "text": "sort of turning it around again by the end of the week. So the hope is to help you not to just,",
    "start": "90710",
    "end": "96040"
  },
  {
    "text": "um, create obstacles and roadblocks in your life. Okay. So today what we're gonna do, um, is, uh,",
    "start": "96040",
    "end": "104420"
  },
  {
    "text": "learn more about a linguistic topic for a change and learn some more stuff about what goes on in coreference resolution.",
    "start": "104420",
    "end": "111920"
  },
  {
    "text": "So first of all, I'm gonna talk about the task, and then go on to some of the kinds of models that people,",
    "start": "111920",
    "end": "117380"
  },
  {
    "text": "um, do for coreference resolution. So first of all, what is it?",
    "start": "117380",
    "end": "123034"
  },
  {
    "start": "120000",
    "end": "724000"
  },
  {
    "text": "Um, so the idea of coreference resolution is what we do, which we have a text,",
    "start": "123035",
    "end": "128850"
  },
  {
    "text": "\"Barack Obama nominated Hillary Rodham Clinton as his Secretary of State on Monday,\" and this text like most texts are about entities,",
    "start": "128850",
    "end": "138230"
  },
  {
    "text": "where entities are commonly human beings, but they can be other things like God saw talking giraffes or whatever it is.",
    "start": "138230",
    "end": "146000"
  },
  {
    "text": "So it seems like we want to make, find where entities are mentioned.",
    "start": "146000",
    "end": "152225"
  },
  {
    "text": "So my entities are mentioned, they're referred to as mentions. So things like Barack Obama and Secretary of State,",
    "start": "152225",
    "end": "159500"
  },
  {
    "text": "he, her, they are mentions of entities. And then, when we talk about coreference resolution,",
    "start": "159500",
    "end": "166990"
  },
  {
    "text": "the task that we're wanting to do is say, which of these mentions refer to the same entity,",
    "start": "166990",
    "end": "174680"
  },
  {
    "text": "the same real thing in the world. So well, one entity that's mentioned in this text is Barack Obama,",
    "start": "174680",
    "end": "182330"
  },
  {
    "text": "and then he's referred to later in the text as his and he, and so these three red noun phrases are all coreferent to each other.",
    "start": "182330",
    "end": "192425"
  },
  {
    "text": "And that then, refers to this real-world entity. Um, and then, we have these references Hillary Rodham Clinton,",
    "start": "192425",
    "end": "201110"
  },
  {
    "text": "Secretary of State, her, she, First Lady, they're all references to a different entity.",
    "start": "201110",
    "end": "208444"
  },
  {
    "text": "And so they all refer to this person. And so those are examples of our coreference.",
    "start": "208445",
    "end": "214390"
  },
  {
    "text": "Um, in a way this is triv- sort of seems obvious to a human being,",
    "start": "214390",
    "end": "220745"
  },
  {
    "text": "um, looking at things, um, but it can actually be kind of tricky and hard. Um, so, um, I thought we could spend a few minutes doing",
    "start": "220745",
    "end": "230480"
  },
  {
    "text": "interactive working out coreferents together so that you guys can,",
    "start": "230480",
    "end": "235655"
  },
  {
    "text": "um, think about it all for a few minutes. Um, so here's part of a little story.",
    "start": "235655",
    "end": "241010"
  },
  {
    "text": "Um, it's a story by Shruthi Rao called The Star. Um, now, I confess that since this is a CS class,",
    "start": "241010",
    "end": "248089"
  },
  {
    "text": "um, not a literature class, I did a little bit of, um, helpful editing of this text to make it shorter,",
    "start": "248089",
    "end": "255049"
  },
  {
    "text": "so I could fit more of, what was going on, um, onto the page, um, but, um,",
    "start": "255049",
    "end": "262145"
  },
  {
    "text": "everything that is a sort of a linguistic [inaudible] is something that comes from the original text.",
    "start": "262145",
    "end": "267300"
  },
  {
    "text": "Okay. So, um, in this text, um, who is the first entity that's mentioned?",
    "start": "267300",
    "end": "276400"
  },
  {
    "text": "Vanaja, okay. Okay. So it's Vanaja. Now, where, let's do it forward.",
    "start": "277970",
    "end": "285255"
  },
  {
    "text": "Where else is Vanaja mentioned in this text?",
    "start": "285255",
    "end": "291040"
  },
  {
    "text": "Her son, right? So this her not the son, but this her is a reference of Vanaja, right?",
    "start": "292580",
    "end": "300400"
  },
  {
    "text": "Um, she resigned. Okay. After that?",
    "start": "305120",
    "end": "312090"
  },
  {
    "text": "She bought. Okay. So there's another she.",
    "start": "312090",
    "end": "317535"
  },
  {
    "text": "Was there another reference before that? Herself, right? So herself is also a reference to Vanaja.",
    "start": "317535",
    "end": "324750"
  },
  {
    "text": "Um, okay. So then, it's again, she made this, she, okay.",
    "start": "325280",
    "end": "332750"
  },
  {
    "text": "So we've done Vanaja. Okay, that's a good start. Okay. So then, um, we've got Akhila.",
    "start": "332750",
    "end": "340270"
  },
  {
    "text": "Okay. Um, where's Akhila next referred to?",
    "start": "340270",
    "end": "345495"
  },
  {
    "text": "As Akhila. Okay, there we go. Um, are there other references, um, to Akhila?",
    "start": "345495",
    "end": "354940"
  },
  {
    "text": "Maybe not. Okay. What's the next entity that's mentioned?",
    "start": "358280",
    "end": "364389"
  },
  {
    "text": "Prajwal. Okay. So what other references are there to Prajwal?",
    "start": "367820",
    "end": "375150"
  },
  {
    "text": "They. They? Okay. So here's a tricky one, right?",
    "start": "379060",
    "end": "384330"
  },
  {
    "text": "So this they, I mean, who does that refer to?",
    "start": "384330",
    "end": "389020"
  },
  {
    "text": "It occ- refers to Prajwal and Akash.",
    "start": "390440",
    "end": "395790"
  },
  {
    "text": "Yeah, so this they refers both to Prajwal and this Akash. So that's, that's something that happens in human languages.",
    "start": "395790",
    "end": "404180"
  },
  {
    "text": "This is referred to as split antecedents, where you have one thing that they,",
    "start": "404180",
    "end": "409220"
  },
  {
    "text": "that's sort of referring to two distributed things that came before it.",
    "start": "409220",
    "end": "414245"
  },
  {
    "text": "Um, so here's one of my first sad admissions of natural language processing technology.",
    "start": "414245",
    "end": "421085"
  },
  {
    "text": "None of the NLP systems that we're gonna talk about later today or in general that have been built deal with split antecedents.",
    "start": "421085",
    "end": "429920"
  },
  {
    "text": "They automatically lose as soon as there's split antecedents. Um, so that's a bit sad,",
    "start": "429920",
    "end": "435435"
  },
  {
    "text": "um, but that's the state of technology. So it's something, um, we could still work to improve, but okay there's this sort of they that's kind of half Prajwal. Um, okay.",
    "start": "435435",
    "end": "446030"
  },
  {
    "text": "So there's directly Prajwal here, but was there another place early in the text that Prajwal is effectively mentioned?",
    "start": "446030",
    "end": "456580"
  },
  {
    "text": "Yeah. So Akhila's son is really another mention of Prajwal, right?",
    "start": "460190",
    "end": "466565"
  },
  {
    "text": "Okay. Um, okay.",
    "start": "466565",
    "end": "472590"
  },
  {
    "text": "Um, any other mentions of Prajwal? Maybe not. Okay. Then we go on.",
    "start": "472590",
    "end": "477765"
  },
  {
    "text": "Okay. Who's the next entity? Akash. So we have Akash here,",
    "start": "477765",
    "end": "484305"
  },
  {
    "text": "and that then again, we have that her son referring to Akash. Um, and here was Akash.",
    "start": "484305",
    "end": "492435"
  },
  {
    "text": "Okay. What other, what other mentions of Akash are there?",
    "start": "492435",
    "end": "497530"
  },
  {
    "text": "Okay so there's another Akash here, um, fourth him.",
    "start": "500450",
    "end": "509010"
  },
  {
    "text": "Okay. Uh, there's another Akash.",
    "start": "509010",
    "end": "515340"
  },
  {
    "text": "Okay, um, but, so, um, here.",
    "start": "515340",
    "end": "522555"
  },
  {
    "text": "Okay. So are the obvious Akash's. There's sort of a tricky case here which",
    "start": "522555",
    "end": "527760"
  },
  {
    "text": "you could wonder what the right treatment of this, right? You know, it's sort of says Akash was to be a tree, all right.",
    "start": "527760",
    "end": "535800"
  },
  {
    "text": "So in some sense the tree is Akash. Um, so really in terms of reference in this story,",
    "start": "535800",
    "end": "545430"
  },
  {
    "text": "the reference of the tree is the same as Akash. And you could think, um,",
    "start": "545430",
    "end": "552795"
  },
  {
    "text": "that means you should treat the instances of, um, the tree, the,",
    "start": "552795",
    "end": "558645"
  },
  {
    "text": "the instances here of the tree, and later on when the nicest tree right that really,",
    "start": "558645",
    "end": "565500"
  },
  {
    "text": "that's sort of this Akash as well. That doesn't quite feel right, but this is something that comes up in coreference, right?",
    "start": "565500",
    "end": "573030"
  },
  {
    "text": "So here we have a sort of a predictive construction um,",
    "start": "573030",
    "end": "578145"
  },
  {
    "text": "with, you know, B. And when you set, when you have sentences such as like, um, you know,",
    "start": "578145",
    "end": "586760"
  },
  {
    "text": "my child is the smartest kid in the class or something like that, in some sense,",
    "start": "586760",
    "end": "592270"
  },
  {
    "text": "you're sort of saying that the smartest kid in the class has the same reference as my child.",
    "start": "592270",
    "end": "598560"
  },
  {
    "text": "And some systems count links over that kind of predication,",
    "start": "598560",
    "end": "604635"
  },
  {
    "text": "and say that is coreference whereas other ones don't and think that that's not quite reasonable.",
    "start": "604635",
    "end": "610890"
  },
  {
    "text": "So different things go on. Okay. So, um, those, those are fair number of entities.",
    "start": "610890",
    "end": "617925"
  },
  {
    "text": "I mean, so there are obviously lots of other things that are mentioned,",
    "start": "617925",
    "end": "623024"
  },
  {
    "text": "um that sort of, um, right? So there's the local park, right, that's a mention of some entity.",
    "start": "623025",
    "end": "630449"
  },
  {
    "text": "Um, there's, um, the school, um right?",
    "start": "630450",
    "end": "636360"
  },
  {
    "text": "So there's this school here and so that the school is coreferent with pre,",
    "start": "636360",
    "end": "644475"
  },
  {
    "text": "the preschool right here, right? Um, and then there's, um, again this sort of tricky one,",
    "start": "644475",
    "end": "652155"
  },
  {
    "text": "of how to treat the naughty child Lord Krishna because, you know, in some sense Prajwal is representing that.",
    "start": "652155",
    "end": "659525"
  },
  {
    "text": "And then there are lots of other entities that are mentioned, right? There's a t-shirt, and there's trousers,",
    "start": "659525",
    "end": "665195"
  },
  {
    "text": "um, and, um, things like that. Another tricky thing that turns up here when you get later on into",
    "start": "665195",
    "end": "672060"
  },
  {
    "text": "the story is you can have entities that have parts. So we not only have a tree,",
    "start": "672060",
    "end": "679425"
  },
  {
    "text": "but that tree then has a lot of parts, right? So the tree has a trunk, and the tree has foliage,",
    "start": "679425",
    "end": "685169"
  },
  {
    "text": "um, and things like that. And there are these red balls that are representing fruits, right?",
    "start": "685169",
    "end": "691170"
  },
  {
    "text": "So there's a lot of stuff that's somehow connected together and somehow separate. And that sort of, that doesn't fit terribly well with the kind of models we",
    "start": "691170",
    "end": "699330"
  },
  {
    "text": "use with coreference either because really we make our coreference, um, reference models basically out of this notion of entities.",
    "start": "699330",
    "end": "708015"
  },
  {
    "text": "Um, but somehow there's this complexity that, you know, human beings have parts too, right? We have hands and faces,",
    "start": "708015",
    "end": "713743"
  },
  {
    "text": "and we can't say, oh, that's a separate entity, but they're somehow in, um, involved with the other entity.",
    "start": "713744",
    "end": "719895"
  },
  {
    "text": "Okay. Um, hope that's sort of useful to give some idea. Why is coreference resolution useful?",
    "start": "719895",
    "end": "727665"
  },
  {
    "start": "724000",
    "end": "1000000"
  },
  {
    "text": "Um, so there are all kinds of things that we'd like to do well in natural language processing that you really can't do well unless,",
    "start": "727665",
    "end": "736379"
  },
  {
    "text": "uh, you know how to do coreference resolution. So anything that we want to do in terms of question-answering, summarization,",
    "start": "736379",
    "end": "745410"
  },
  {
    "text": "extracting facts from texts or anything like that, there are places we are gonna fail unless we can do coreference resolution.",
    "start": "745410",
    "end": "752985"
  },
  {
    "text": "Because if we're reading a piece of text, and it says he was born in 1961, um,",
    "start": "752985",
    "end": "758640"
  },
  {
    "text": "we can get a fact out or answer a question, if we can work out who he was,",
    "start": "758640",
    "end": "763845"
  },
  {
    "text": "but we probably can't otherwise.",
    "start": "763845",
    "end": "766779"
  },
  {
    "text": "Um, there are, there's sort of another place that where this is very useful is in machine translation,",
    "start": "769040",
    "end": "777480"
  },
  {
    "text": "so that lots of languages drop pronouns. So you don't have to give explicit pronouns,",
    "start": "777480",
    "end": "784935"
  },
  {
    "text": "but you need to be able to work out how to fill them in. And this is making coreference decisions about,",
    "start": "784935",
    "end": "792764"
  },
  {
    "text": "um, arguments of verbs. And so here are a couple of examples,",
    "start": "792765",
    "end": "798030"
  },
  {
    "text": "um, that, um, covering from Spanish to English. So in Spanish, you can freely drop the subjects of verbs and in these sentences,",
    "start": "798030",
    "end": "807660"
  },
  {
    "text": "in the because clause, there's no overt subject. And so he gets Alicia likes Juan because he's smart.",
    "start": "807660",
    "end": "815625"
  },
  {
    "text": "And so Google Translate is stuck in a he and that is right. And to stick in that he,",
    "start": "815625",
    "end": "822600"
  },
  {
    "text": "it's implicitly making a coreference decision and saying, \"Okay well,",
    "start": "822600",
    "end": "827699"
  },
  {
    "text": "the subject of this, um, adjective smart should be Juan who's male,",
    "start": "827700",
    "end": "834224"
  },
  {
    "text": "and therefore, I should say he.\" But, you know, the reality is Google Translate knows",
    "start": "834224",
    "end": "840060"
  },
  {
    "text": "nothing about coreference and making these coreference decisions. And as has been um,",
    "start": "840060",
    "end": "845279"
  },
  {
    "text": "covered quite a bit in the media now and I think came up earlier in an earlier class,",
    "start": "845280",
    "end": "850365"
  },
  {
    "text": "that, um, Google Translate mainly just defaults to male default. Um, so if you sort of swap- sweep it, uh,",
    "start": "850365",
    "end": "858075"
  },
  {
    "text": "if you flip it around and say, Juan likes Alicia, it also says because he's smart.",
    "start": "858075",
    "end": "863370"
  },
  {
    "text": "Uh, whereas probably it should be because she's smart in that case. And indeed you notice the bad effects of that everywhere.",
    "start": "863370",
    "end": "871755"
  },
  {
    "text": "So many languages, um, Turkish, Indonesian, um, don't actually have gender,",
    "start": "871755",
    "end": "878069"
  },
  {
    "text": "so that they're much less sexist languages than English, French or Germany is.",
    "start": "878070",
    "end": "883350"
  },
  {
    "text": "But what happens, um, when you then translate where you just have a generic pronoun that means third person pronoun, um,",
    "start": "883350",
    "end": "892275"
  },
  {
    "text": "that Google Translate is essentially using its language model, which means that reconstructs, um,",
    "start": "892275",
    "end": "899055"
  },
  {
    "text": "the worst of stereotypes of she is a cook, and he is an engineer, he is a doctor. And well, in a connected piece of this course,",
    "start": "899055",
    "end": "907500"
  },
  {
    "text": "if you'd like Google Translate to be able to do better than that, well again, what would be required is that you could actually do",
    "start": "907500",
    "end": "914160"
  },
  {
    "text": "coreference resolution and track along the actors in the text as you go along.",
    "start": "914160",
    "end": "919754"
  },
  {
    "text": "Um, one final example we haven't really talked about yet, but we'll get back to soon now because the class is almost over",
    "start": "919755",
    "end": "927480"
  },
  {
    "text": "is doing things with dialogue agents or chat systems. That, as soon as you are going to do anything more than a single turn,",
    "start": "927480",
    "end": "936240"
  },
  {
    "text": "um, dialog, that you need to start dealing with reference. So if you've got something like, um,",
    "start": "936240",
    "end": "941655"
  },
  {
    "text": "booked tickets to see James Bond, um, then you want to say something like, \"Spectre is playing near you at 2:00 and 3:00 today.",
    "start": "941655",
    "end": "949050"
  },
  {
    "text": "How many tickets would you like?\" Um, two tickets for the showing at three.",
    "start": "949050",
    "end": "954270"
  },
  {
    "text": "That as shown in the color, there are various kinds of reference going on here where things have related reference,",
    "start": "954270",
    "end": "962340"
  },
  {
    "text": "but it's kind of complicated here. And this is something that we'll come back to in a moment.",
    "start": "962340",
    "end": "967470"
  },
  {
    "text": "So James Bond and Spectre aren't obviously the same thing,",
    "start": "967470",
    "end": "973035"
  },
  {
    "text": "but in a context like, um, booking movies, they are the same thing because one is the name of a character in a movie series,",
    "start": "973035",
    "end": "983460"
  },
  {
    "text": "and the other is the name of a movie that's currently showing that belongs to that,",
    "start": "983460",
    "end": "988530"
  },
  {
    "text": "so that they're sort of associated, um, in a sort of subtle way that isn't exact identity,",
    "start": "988530",
    "end": "993900"
  },
  {
    "text": "but is relevant to a lot of the things that we want to do. I'll come back to that in a little bit when we",
    "start": "993900",
    "end": "999480"
  },
  {
    "text": "talk a bit more about the linguistics of this. Okay. So if we want to do the task of coreference resolution,",
    "start": "999480",
    "end": "1005760"
  },
  {
    "start": "1000000",
    "end": "1179000"
  },
  {
    "text": "there are essentially two steps. So the first step is gee, we want to work out",
    "start": "1005760",
    "end": "1011425"
  },
  {
    "text": "what mentions there are in the text that we should be doing something with. And this one is effectively pretty easy,",
    "start": "1011425",
    "end": "1018640"
  },
  {
    "text": "but I'll have just a few slides on that immediately. And then what the bulk of the class is gonna be on is,",
    "start": "1018640",
    "end": "1024834"
  },
  {
    "text": "um, working out coreference between mentions. And if you think about this,",
    "start": "1024835",
    "end": "1030400"
  },
  {
    "text": "coreference is essentially a clustering task. Because if you do the first task, you have a set of mentions and then you want to be saying well,",
    "start": "1030400",
    "end": "1038770"
  },
  {
    "text": "how can I group these into clusters that have the same reference? And so that's what we're going to look more at doing.",
    "start": "1038770",
    "end": "1045750"
  },
  {
    "text": "So quickly on mention detection. So, um, for mention, we wanna find all the spans that are candidates for,",
    "start": "1045750",
    "end": "1054085"
  },
  {
    "text": "um, referring to some entity. And the answer to what these, um, candidates are is basically they're all the noun phrases in the text.",
    "start": "1054085",
    "end": "1063620"
  },
  {
    "text": "And so normally people think of there being three types of mentions that we identify. There are pronouns, I,",
    "start": "1063620",
    "end": "1069730"
  },
  {
    "text": "you, he, she, it, etc., that are, um, referring to different entities. They're explicit names of people like that was",
    "start": "1069730",
    "end": "1077169"
  },
  {
    "text": "that Barack Obama and Hillary Clinton examples. And then many of the tricky examples,",
    "start": "1077170",
    "end": "1082210"
  },
  {
    "text": "and then when we have common noun phrases like a dog or the big fluffy cat stuck in the tree.",
    "start": "1082210",
    "end": "1087670"
  },
  {
    "text": "That the big fluffy cat stuck in the tree is a mention. Um, it's actually a complex mention because it",
    "start": "1087670",
    "end": "1094404"
  },
  {
    "text": "also has embedded inside it other mentions. Um, so the tree is also a mention.",
    "start": "1094405",
    "end": "1102230"
  },
  {
    "text": "Okay. So how can we detect mentions? Well, one answer is to say,",
    "start": "1102500",
    "end": "1108180"
  },
  {
    "text": "well we've looked at, um, various other NLP systems on and off. And we can just use those NLP systems as preprocessing systems to find mentions.",
    "start": "1108180",
    "end": "1119250"
  },
  {
    "text": "So for pronouns, they're part of speech taggers that say what's a noun, or a verb, or a pronoun,",
    "start": "1119250",
    "end": "1125475"
  },
  {
    "text": "and so we can run those and find all the pronouns and we're done. From- for, um, the names of things like Barack Obama.",
    "start": "1125475",
    "end": "1132180"
  },
  {
    "text": "We've talked a couple of times about named entity recognizers, so we can run those and find all the named entities.",
    "start": "1132180",
    "end": "1137730"
  },
  {
    "text": "Um, then for common noun phrases, that's sort of where we need parsers to find",
    "start": "1137730",
    "end": "1143400"
  },
  {
    "text": "the structure of the sentence and find where the noun phrases are. And we have talked about dependency parsers and well,",
    "start": "1143400",
    "end": "1149745"
  },
  {
    "text": "one choice is you can use a dependency parser to find the sort of nominal arguments, and work with them.",
    "start": "1149745",
    "end": "1155670"
  },
  {
    "text": "That's sort of actually a little bit subtler than just sort of wanting to pick out spans that refer to common noun phrases.",
    "start": "1155670",
    "end": "1162525"
  },
  {
    "text": "So the other notion of parsing which we come back to, um, next week is constituency parsing.",
    "start": "1162525",
    "end": "1168150"
  },
  {
    "text": "In some sense, constituency parsers are the simplest way to find mentions for this process.",
    "start": "1168150",
    "end": "1174465"
  },
  {
    "text": "Um, most of it seems and is easy, um, there are sort of tricky cases as to what counts as a mention or not.",
    "start": "1174465",
    "end": "1184200"
  },
  {
    "start": "1179000",
    "end": "1339000"
  },
  {
    "text": "So, um, if it's kind of it is sunny, I mean, is it a mention of something?",
    "start": "1184200",
    "end": "1189975"
  },
  {
    "text": "It's sort of seems like it's not really, it's just it seems like it's an it that you stick at the start of the sentence,",
    "start": "1189975",
    "end": "1195870"
  },
  {
    "text": "um, that doesn't mean anything. So that's maybe not a mention. Um, every student. Is every student a mention?",
    "start": "1195870",
    "end": "1202695"
  },
  {
    "text": "I mean, it's certainly, at best it's some kind of collective,",
    "start": "1202695",
    "end": "1207809"
  },
  {
    "text": "um, but it's not sort of a very clear concrete reference, um. That goes further, if I sort of use different quantifiers,",
    "start": "1207810",
    "end": "1215520"
  },
  {
    "text": "so if it was like, every and no are called quantifiers. I mean no student definitely doesn't have reference,",
    "start": "1215520",
    "end": "1221070"
  },
  {
    "text": "because it's not pointing at anything, right? It's asserting a claim of nonexistence. So that there's definitely, um,",
    "start": "1221070",
    "end": "1228015"
  },
  {
    "text": "no- it isn't a mention of anything. Um, yeah, the best donut in the world.",
    "start": "1228015",
    "end": "1234419"
  },
  {
    "text": "Um, does that have reference? Um, that's unclear.",
    "start": "1234420",
    "end": "1240125"
  },
  {
    "text": "This is the kind of thing that actual philosophers of language debate over, right? So if there was agreement on what the best donut in the world is,",
    "start": "1240125",
    "end": "1248315"
  },
  {
    "text": "then maybe it has reference, um, but I can say sentences like, I'm searching everywhere to find the best donut in the world.",
    "start": "1248315",
    "end": "1256129"
  },
  {
    "text": "And then in that sentence, it doesn't have any reference, right? It's sort of an intentional description of what I'm hoping to find,",
    "start": "1256130",
    "end": "1263975"
  },
  {
    "text": "that there's no concrete thing it refers to. Um, things like quantities, 100 miles.",
    "start": "1263975",
    "end": "1271605"
  },
  {
    "text": "That sort of behaves like a noun phrase, but it is in- it's sort of really a quantity that doesn't really have reference.",
    "start": "1271605",
    "end": "1277995"
  },
  {
    "text": "Um, and so then there's the question of how can you deal with this stuff?",
    "start": "1277995",
    "end": "1283200"
  },
  {
    "text": "Um, well, um, our tool whenever we want to deal with stuff, is we train classifiers,",
    "start": "1283200",
    "end": "1290265"
  },
  {
    "text": "as in they pick out things that are mentioned and things that aren't. And so that's something that you could do is write a classifier that filters out,",
    "start": "1290265",
    "end": "1298800"
  },
  {
    "text": "um, these spurious things that you want to say aren't really mentions. And people absolutely have done that.",
    "start": "1298800",
    "end": "1304980"
  },
  {
    "text": "But commonly actually people skip that step, and you just sort of instead have your mention detector find all candidate mentions.",
    "start": "1304980",
    "end": "1314295"
  },
  {
    "text": "Because it turns out that that tends to work pretty well. Because after we found all of our mentions, um,",
    "start": "1314295",
    "end": "1321510"
  },
  {
    "text": "we're then going to be doing this clustering process to find coreferent mentions. And if there are just a few stray mentions like",
    "start": "1321510",
    "end": "1328440"
  },
  {
    "text": "no student and we don't cluster them wrongly with anything else, it kind of doesn't do any harm because we are mainly involved in this clustering process.",
    "start": "1328440",
    "end": "1338490"
  },
  {
    "text": "Okay. Um, something you might be wondering is, well I've sort of implied now,",
    "start": "1338490",
    "end": "1345090"
  },
  {
    "start": "1339000",
    "end": "1419000"
  },
  {
    "text": "we have a pipeline. I'm saying we're going to run a part of speech tagger, and we're going to run a named entity recognizer,",
    "start": "1345090",
    "end": "1351810"
  },
  {
    "text": "and we're going to run a parser. And we're going to run a, um, a named mention detector.",
    "start": "1351810",
    "end": "1358184"
  },
  {
    "text": "And then eventually, we're going to run this coref clustering system, so we have a sort of a five-step pipeline.",
    "start": "1358185",
    "end": "1364290"
  },
  {
    "text": "Um, is that the only way you can do, um, coreference resolution?",
    "start": "1364290",
    "end": "1370950"
  },
  {
    "text": "And the traditional answer was yup, that's the way you did coreference resolution. That essentially, all systems for coreference resolution,",
    "start": "1370950",
    "end": "1379275"
  },
  {
    "text": "until approximately 2016 where a pipeline that went through about those stages.",
    "start": "1379275",
    "end": "1385800"
  },
  {
    "text": "Um, but just recently and I will dico- cover one such system, um, later in the class, um,",
    "start": "1385800",
    "end": "1392179"
  },
  {
    "text": "that people in the neural world have started doing what's been effective in a lot of places in the neural network world of saying,",
    "start": "1392180",
    "end": "1399559"
  },
  {
    "text": "can we just build an end-to-end coreference system that starts with just plain text of a paragraph,",
    "start": "1399560",
    "end": "1406384"
  },
  {
    "text": "and feeds out coreference clusters without there being any intervening pipeline steps?",
    "start": "1406385",
    "end": "1413685"
  },
  {
    "text": "And I'll show you a bit more about how that works. Um, but before we get into systems,",
    "start": "1413685",
    "end": "1420090"
  },
  {
    "start": "1419000",
    "end": "1571000"
  },
  {
    "text": "I just wanted to say a little bit more about the linguistics of coreference.",
    "start": "1420090",
    "end": "1425220"
  },
  {
    "text": "Um, there's actually quite a lot of interesting stuff here, and to a fair degree,",
    "start": "1425220",
    "end": "1432360"
  },
  {
    "text": "it's not actually stuff that's been thought about very much by people who build NLP systems, right?",
    "start": "1432360",
    "end": "1439065"
  },
  {
    "text": "I already mentioned, um, from the Shruthi Rao story, um, the example of split antecedents, right?",
    "start": "1439065",
    "end": "1446250"
  },
  {
    "text": "That that's just a clear linguistic phenomenon that happens, and it's not even incredibly rare, right?",
    "start": "1446250",
    "end": "1452160"
  },
  {
    "text": "Um, that, you know, um, people build these simple machine learning models that just can't deal with that.",
    "start": "1452160",
    "end": "1459585"
  },
  {
    "text": "And there's really quite a bit more structure to what happens in the linguistics of coreference,",
    "start": "1459585",
    "end": "1465750"
  },
  {
    "text": "it isn't really being exploited in most of the systems people bui- build. So I just wanted to show people a bit more of that.",
    "start": "1465750",
    "end": "1473145"
  },
  {
    "text": "And essentially, to sort of understanding, um,",
    "start": "1473145",
    "end": "1478200"
  },
  {
    "text": "more about how people see things linguistically, there are two concepts that are related and commonly confused,",
    "start": "1478200",
    "end": "1486945"
  },
  {
    "text": "that are really different. So one is coreference. So we say that things are coreferent when there are",
    "start": "1486945",
    "end": "1494700"
  },
  {
    "text": "two mentions and they refer to the same entity in the world. So if it's sort of,",
    "start": "1494700",
    "end": "1500970"
  },
  {
    "text": "um, Donald Trump and the current president, right? They're two mentions and they refer to the same person in the world.",
    "start": "1500970",
    "end": "1509205"
  },
  {
    "text": "And so that is a relationship of coreference. Um, and that's then contrasted, um, with anaphora.",
    "start": "1509205",
    "end": "1516345"
  },
  {
    "text": "And so the idea of anaphora is some terms in text don't have independent reference,",
    "start": "1516345",
    "end": "1524595"
  },
  {
    "text": "and you work out their reference by relating them back to another thing in the text.",
    "start": "1524595",
    "end": "1530835"
  },
  {
    "text": "So if we have the sentence, Barack Obama said he would sign the bill. He is an anaphor.",
    "start": "1530835",
    "end": "1537225"
  },
  {
    "text": "And if I just say, he, what does he refer to in the abstract? Well, you know, apart from saying something male, right?",
    "start": "1537225",
    "end": "1545775"
  },
  {
    "text": "You've got no idea, right? Because you can't work out what he means just by knowing he. You have to be looking at a text and interpreting it relative to the text.",
    "start": "1545775",
    "end": "1554370"
  },
  {
    "text": "And then if you're interpreting it, um, relative to the text, you're then in this situation of,",
    "start": "1554370",
    "end": "1560370"
  },
  {
    "text": "okay I see, this refers back to Barack Obama. So he is another mention of Barack Obama,",
    "start": "1560370",
    "end": "1567600"
  },
  {
    "text": "then- and this then is this concept of anaphora. So the picture we have is sort of like this,",
    "start": "1567600",
    "end": "1573615"
  },
  {
    "start": "1571000",
    "end": "1679000"
  },
  {
    "text": "that you can either have these independent mentions, which do refer, um,",
    "start": "1573615",
    "end": "1579690"
  },
  {
    "text": "to the same thing in the world. They're coreferent. But in many cases, such as when they're full mentions like President Obama,",
    "start": "1579690",
    "end": "1587969"
  },
  {
    "text": "versus Barack Obama, they don't have any textual relationship. It's just they happen to refer to the same thing in the world.",
    "start": "1587969",
    "end": "1595455"
  },
  {
    "text": "And that then contrast with cases like Barack Obama said he would do something,",
    "start": "1595455",
    "end": "1600825"
  },
  {
    "text": "where the he has a textual relationship back to Barack Obama. And that's an example of anaphora.",
    "start": "1600825",
    "end": "1607530"
  },
  {
    "text": "Um, this might up until now feel like an almost meaningless distinction.",
    "start": "1607530",
    "end": "1614985"
  },
  {
    "text": "But something that maybe gives you more of a sense that there's something useful here is, um, these textual relationships exist even when there isn't coreference.",
    "start": "1614985",
    "end": "1624420"
  },
  {
    "text": "So we sort of mentioned before, these cases like no dancer, right?",
    "start": "1624420",
    "end": "1629430"
  },
  {
    "text": "So no dancer doesn't have reference, right? It refers to nothing. Um, but if you have a sentence like,",
    "start": "1629430",
    "end": "1636810"
  },
  {
    "text": "\"no dancer twisted her knee,\" well we have an anaphor here.",
    "start": "1636810",
    "end": "1642615"
  },
  {
    "text": "And that anaphor is referring back to \"no dancer\" despite the fact that \"no dancer\" doesn't have reference.",
    "start": "1642615",
    "end": "1650520"
  },
  {
    "text": "So we can still have the anaphoric textual relationship. And indeed, you know,",
    "start": "1650520",
    "end": "1656070"
  },
  {
    "text": "her knee is then a part of her. And so these are the sort of part relationships again.",
    "start": "1656070",
    "end": "1662040"
  },
  {
    "text": "But her knee, in a sense that I'll just come back to, is also an anaphor which is interpreted with respect, um, to the dancer.",
    "start": "1662040",
    "end": "1671325"
  },
  {
    "text": "So we have two anaphoric relationships here, even though we have no reference.",
    "start": "1671325",
    "end": "1677250"
  },
  {
    "text": "There's another interesting case of anaphoric relationships which aren't the same as reference,",
    "start": "1677250",
    "end": "1684795"
  },
  {
    "start": "1679000",
    "end": "1764000"
  },
  {
    "text": "which is you could have looser forms of anaphoric relationships. So you get lots of sentences like this.",
    "start": "1684795",
    "end": "1690810"
  },
  {
    "text": "\"We went to see a concert last night, the tickets were really expensive.\" So we have this mentioned here of the tickets.",
    "start": "1690810",
    "end": "1698925"
  },
  {
    "text": "Um, but really to interpret the tickets, we have to interpret them with respect to this,",
    "start": "1698925",
    "end": "1706995"
  },
  {
    "text": "um, mention back here, a concept, because really what this is saying, the tickets for the concert were really expensive.",
    "start": "1706995",
    "end": "1715095"
  },
  {
    "text": "So this is also referred to as an anaphoric relationship, where the meaning of the tickets has to be interpreted",
    "start": "1715095",
    "end": "1722190"
  },
  {
    "text": "textually based on another, um, noun phrase. But it's not a coreference relationship that",
    "start": "1722190",
    "end": "1729690"
  },
  {
    "text": "the concert and the tickets are clearly two different entities. So these kinda looser cases are referred to as bridging anaphora,",
    "start": "1729690",
    "end": "1736979"
  },
  {
    "text": "because you sort of have to supply for yourself the bridge, the relation that connects together the antecedent and the anaphor.",
    "start": "1736979",
    "end": "1747105"
  },
  {
    "text": "Okay. So that's how- we then have these pictures, that we have this sort of not in- not complete crossovers",
    "start": "1747105",
    "end": "1754890"
  },
  {
    "text": "between coreference and anaphora that we've sort of talked about. Um, I have one other note on anaphora. Um,",
    "start": "1754890",
    "end": "1764200"
  },
  {
    "start": "1764000",
    "end": "1953000"
  },
  {
    "text": "Who- has anyone here ever done any Ancient Greek? Any Ancient Greek? [LAUGHTER] Yes.",
    "start": "1764200",
    "end": "1774019"
  },
  {
    "text": "Okay. Um, so, um, from- from the origins of the words anaphora,",
    "start": "1774020",
    "end": "1780745"
  },
  {
    "text": "anaphora is meant to be that you're finding your textual reference before you.",
    "start": "1780745",
    "end": "1787135"
  },
  {
    "text": "Um, and so there's actually a- a complementary, um,",
    "start": "1787135",
    "end": "1793300"
  },
  {
    "text": "term of art which is referred to as cataphora where you're finding your reference after you.",
    "start": "1793300",
    "end": "1802139"
  },
  {
    "text": "Um, so here is a beautiful example of cataphora. So this is from Oscar Wilde's,",
    "start": "1802140",
    "end": "1807380"
  },
  {
    "text": "The Picture of Dorian Gray. \"From the corner of the divan of Persian saddle-bags on which he was lying,",
    "start": "1807380",
    "end": "1814339"
  },
  {
    "text": "smoking, as was his custom, innumerable cigarettes, Lord Henry Wotton could just catch",
    "start": "1814339",
    "end": "1820690"
  },
  {
    "text": "the gleam of the honey-sweet and honey-colored blossoms of a laburnum.\" Um, right. So here we have this, um, mentioned,",
    "start": "1820690",
    "end": "1828865"
  },
  {
    "text": "Lord Henry Wotton and there are two anaphors, um, that refer to Lord Henry Wotton.",
    "start": "1828865",
    "end": "1835940"
  },
  {
    "text": "Um, he and his, and that they both come before,",
    "start": "1835940",
    "end": "1841730"
  },
  {
    "text": "um, Lord Henry Wotton. And so these are referred to, um,",
    "start": "1841730",
    "end": "1847010"
  },
  {
    "text": "as instances of cataphora among a certain kind of classical scholar.",
    "start": "1847010",
    "end": "1853670"
  },
  {
    "text": "Um, and in case you don't know what a laburnum is, um, this is a laburnum.",
    "start": "1853670",
    "end": "1858679"
  },
  {
    "text": "[LAUGHTER] Right. But, yeah, so thi- this is cataphora. Now- now there are two sad things to say.",
    "start": "1858680",
    "end": "1865940"
  },
  {
    "text": "Um, the first sad thing is in modern linguistics, the term cataphora is completely disused.",
    "start": "1865940",
    "end": "1872375"
  },
  {
    "text": "And we mean- we just used the word um, anaphors everywhere as meaning",
    "start": "1872375",
    "end": "1878185"
  },
  {
    "text": "a word that gets referenced from some other mention in the text and it doesn't matter what side it's on.",
    "start": "1878185",
    "end": "1884525"
  },
  {
    "text": "Um, so, um, that we go downhill one stage to linguistics but then we get to NLP and we go downhill a second stage.",
    "start": "1884525",
    "end": "1894055"
  },
  {
    "text": "Because what you'll see is that in general, the systems that people are building for,",
    "start": "1894055",
    "end": "1900485"
  },
  {
    "text": "um, reference resolution, they don't make any distinction of direction at all.",
    "start": "1900485",
    "end": "1907355"
  },
  {
    "text": "That once you find a mention, you're always looking backwards for its reference. Um, and you've got no idea that,",
    "start": "1907355",
    "end": "1914875"
  },
  {
    "text": "well, maybe sometimes you could look forwards. So effectively, what it means, that the systems end up doing is saying,",
    "start": "1914875",
    "end": "1921370"
  },
  {
    "text": "well, there's a he here, there are various other things, there's a his, etc., and you'll eventually get to Lord Henry Wotton and you'll be able to",
    "start": "1921370",
    "end": "1929649"
  },
  {
    "text": "be trying to find its reference by looking backwards, even though that's sort of ill-formed from any kind of linguistic sense",
    "start": "1929650",
    "end": "1937760"
  },
  {
    "text": "whereas really he and his that should have been looking for their reference forward. Okay. Um, is everyone good up to there, any questions?",
    "start": "1937760",
    "end": "1949140"
  },
  {
    "text": "Okay. We'll move ahead and, um, try and move on to kinds of coreference, um, models.",
    "start": "1949840",
    "end": "1958610"
  },
  {
    "start": "1953000",
    "end": "2083000"
  },
  {
    "text": "So I wanted to, um, tell you, um, as much as I can and I have 45 minutes, um,",
    "start": "1958610",
    "end": "1965299"
  },
  {
    "text": "left about, so the kinda models people build with coreference. And I hope to mention quickly four different ways that people have looked at coreference.",
    "start": "1965300",
    "end": "1973670"
  },
  {
    "text": "I wanna tell you a teeny bit about classical rule-based coreference. Um, then, um, mention- mention pair coreference.",
    "start": "1973670",
    "end": "1982010"
  },
  {
    "text": "Spend the most time on mention ranking systems which have tended to be the easiest simple systems.",
    "start": "1982010",
    "end": "1987995"
  },
  {
    "text": "And then just say a little bit about clustering systems which should be the right way to do it but in practice has been a way that's been hard to get the best performance from.",
    "start": "1987995",
    "end": "1998150"
  },
  {
    "text": "Okay. So here's a bit of history. Um, this guy here is Jerry Hobbs. He just had his retirement party from University of Southern California last month.",
    "start": "1998150",
    "end": "2008320"
  },
  {
    "text": "Um, so Jerry Hobbs, way back when, um, wrote a famous paper,",
    "start": "2008320",
    "end": "2013659"
  },
  {
    "text": "it was in 1976 on coreference resolution. And in that paper, um, he proposed,",
    "start": "2013660",
    "end": "2021520"
  },
  {
    "text": "um, what's normally now referred to as the Hobbs Algorithm. But actually, um, in his paper,",
    "start": "2021520",
    "end": "2027895"
  },
  {
    "text": "he refers to it as a naive algorithm. Um, and I'll come back to that distinction in just a moment.",
    "start": "2027895",
    "end": "2034680"
  },
  {
    "text": "Um, but what the Hobbs algorithm was, is if you have a sentence- so actually I should say this,",
    "start": "2034680",
    "end": "2041980"
  },
  {
    "text": "this algorithm is just for finding the reference of pronouns. So one can extend out to other cases but the part I'm gonna show",
    "start": "2041980",
    "end": "2048500"
  },
  {
    "text": "you is just the part for doing the reference of pronouns. So when you find out, find a pronoun and you wanna say what is it, um, coreferent with?",
    "start": "2048500",
    "end": "2057925"
  },
  {
    "text": "What you're going to do is run this mechanical algorithm that's looking at a parse of a sentence and is working out what to do with it.",
    "start": "2057925",
    "end": "2067945"
  },
  {
    "text": "Begin at the NP immediately dominating the pronoun, go up the trees or the first NP or S. Call this X and the path p,",
    "start": "2067945",
    "end": "2075325"
  },
  {
    "text": "traverse along, ah, it goes on and on. Um, there's more of it. That was only the beginning of it. There are a lot more stages.",
    "start": "2075325",
    "end": "2081475"
  },
  {
    "text": "Um, but, you know, I'm not- I don't really wanna go into the details of this.",
    "start": "2081475",
    "end": "2086889"
  },
  {
    "start": "2083000",
    "end": "2407000"
  },
  {
    "text": "Um, but, you know, to try and explain the flavor of it, here's a piece of text. \"Niall Ferguson is prolific,",
    "start": "2086890",
    "end": "2093980"
  },
  {
    "text": "well-paid, and a snappy dresser. Stephen Moss hated him.\" Um, and so if you can remember any of the steps of that algorithm,",
    "start": "2093980",
    "end": "2102854"
  },
  {
    "text": "here's our, um, pronoun him. Um, and then, what it said to do was begin at the NP,",
    "start": "2102854",
    "end": "2111535"
  },
  {
    "text": "the noun phrase above the pronoun. And then it said, to go up to the first noun phrase or S above that,",
    "start": "2111535",
    "end": "2119010"
  },
  {
    "text": "um, here is the S above that. Um, and then what you're meant to do is, from there,",
    "start": "2119010",
    "end": "2124765"
  },
  {
    "text": "you're meant to go left to right through stuff that came before that.",
    "start": "2124765",
    "end": "2130184"
  },
  {
    "text": "So there's a lot of cleverness in this handwritten algorithm. You know, this is in the space of clever handwritten algorithms.",
    "start": "2130185",
    "end": "2136440"
  },
  {
    "text": "And so what this is reflecting is that you might just think you should go to the closest thing to find reference,",
    "start": "2136440",
    "end": "2144045"
  },
  {
    "text": "but actually if you have reference within the same sentence, it's much more common for the sort of",
    "start": "2144045",
    "end": "2151730"
  },
  {
    "text": "highest syntactic roles to be what you're coreferent with. So you're more likely to be coreferent with a subject than an object,",
    "start": "2151730",
    "end": "2159780"
  },
  {
    "text": "and you're more likely to be coreferent with an object than something like a noun phrase and that's inside a prepositional phrase that follows the object.",
    "start": "2159780",
    "end": "2168935"
  },
  {
    "text": "So we're gonna start from the left here and we're gonna say here's a noun phrase, Stephen Moss.",
    "start": "2168935",
    "end": "2174710"
  },
  {
    "text": "That's the first one we come to. And then there's this clever bit of text that says,",
    "start": "2174710",
    "end": "2180265"
  },
  {
    "text": "um, traversal branches, um, below X, that are to the left- left to right,",
    "start": "2180265",
    "end": "2187080"
  },
  {
    "text": "propose as antecedent and noun phrase, um, that has a noun phrase or sentence between it's an ec- in the S. So it was saying,",
    "start": "2187080",
    "end": "2197220"
  },
  {
    "text": "this will be a candidate, if and only if, there's some other noun phrase or S in-between.",
    "start": "2197220",
    "end": "2204345"
  },
  {
    "text": "Um, and so what that's saying is Stephen Moss hated him. It- this him cannot refer back to",
    "start": "2204345",
    "end": "2212210"
  },
  {
    "text": "Stephen Moss and that sort of pretty much a fact of English syntax. But what it's wanting to do is distinguish between,",
    "start": "2212210",
    "end": "2220090"
  },
  {
    "text": "another thing that we could have had here was a noun phrase that had another possessive noun phrase inside it.",
    "start": "2220090",
    "end": "2229099"
  },
  {
    "text": "Um, so if we had something like Stephen Moss's mother hated him, right?",
    "start": "2229100",
    "end": "2237595"
  },
  {
    "text": "Then the Stephen mother- Moss's mother hated him, then that would,",
    "start": "2237595",
    "end": "2242619"
  },
  {
    "text": "in that case, it would be perfectly okay for him to be coreferent with Stephen Moss.",
    "start": "2242620",
    "end": "2248055"
  },
  {
    "text": "And the algorithm allows that because relative to this noun phrase is another noun phrase above it and between.",
    "start": "2248055",
    "end": "2255760"
  },
  {
    "text": "Okay. So that didn't work, um, as an antece- as an antecedent, so then we go onto the next step of the algorithm.",
    "start": "2255760",
    "end": "2263415"
  },
  {
    "text": "And then, the next step says, we should proceed backwards through preceding sentences,",
    "start": "2263415",
    "end": "2269095"
  },
  {
    "text": "um, right to left. And so that captures an important heuristic that proximity is actually",
    "start": "2269095",
    "end": "2275085"
  },
  {
    "text": "a good heuristic to find coreference because coreference for pronouns is usually close by overall.",
    "start": "2275085",
    "end": "2282115"
  },
  {
    "text": "And so we go to the first sentence back. And then in this sentence, again,",
    "start": "2282115",
    "end": "2287885"
  },
  {
    "text": "we go into within the sentence, go left to right because there's the same kind of subject prominence role.",
    "start": "2287885",
    "end": "2293335"
  },
  {
    "text": "And so we're gonna start in this sentence, and we're gonna say okay, here's a noun phrase.",
    "start": "2293335",
    "end": "2298710"
  },
  {
    "text": "And now because we're in a different sentence, there's nothing wrong with this one. So we say, aha,",
    "start": "2298710",
    "end": "2304725"
  },
  {
    "text": "we have a candidate, Niall Ferguson, um, is a possible antecedent and it's the first one we found.",
    "start": "2304725",
    "end": "2312385"
  },
  {
    "text": "And therefore, we say that him refers back to Niall Ferguson. And this algorithm actually gives the right answer,",
    "start": "2312385",
    "end": "2318640"
  },
  {
    "text": "if you could follow along all of that. Um, though that sounds like, um, horrible handwritten stuff.",
    "start": "2318640",
    "end": "2327020"
  },
  {
    "text": "But, um, so Jerry Hobbs was aware of that this was horrible handwritten stuff,",
    "start": "2327020",
    "end": "2336810"
  },
  {
    "text": "but he was interested in this algorithm for a couple of reasons. I mean, reason one is, you know,",
    "start": "2336810",
    "end": "2344970"
  },
  {
    "text": "this is actually one of the first places in natural language processing,",
    "start": "2344970",
    "end": "2349980"
  },
  {
    "text": "that someone produced the baseline, right. In for final projects and elsewhere,",
    "start": "2349980",
    "end": "2355619"
  },
  {
    "text": "um, and stuff we gave you, right, it's seen now in NLP and other areas,",
    "start": "2355620",
    "end": "2361260"
  },
  {
    "text": "that anything you are doing, the first thing you should do is have a baseline, a simple system and see how well it works.",
    "start": "2361260",
    "end": "2367440"
  },
  {
    "text": "And this was his simple rule-based system for doing coreference, um, and he wanted to observe that actually this baseline was pretty good.",
    "start": "2367440",
    "end": "2376575"
  },
  {
    "text": "It actually gave the right answer a lot of the time. And so the challenge was how to build a system that did better than this baseline.",
    "start": "2376575",
    "end": "2387360"
  },
  {
    "text": "And so he was well aware of it, you know, it was a dumb algorithm, but he proposed that as a good baseline for doing coreference resolution.",
    "start": "2387360",
    "end": "2395580"
  },
  {
    "text": "So what he was interested in, um, remember that we're back in the 1970s here,",
    "start": "2395580",
    "end": "2400980"
  },
  {
    "text": "was how to do knowledge-based pronominal coreference resolution.",
    "start": "2400980",
    "end": "2406859"
  },
  {
    "text": "And so, um, essentially what he was noticing is well,",
    "start": "2406860",
    "end": "2412250"
  },
  {
    "start": "2407000",
    "end": "2701000"
  },
  {
    "text": "these kinds of syntactic factors that I was mentioning prefer subjects, prefer close by, etc,",
    "start": "2412250",
    "end": "2418430"
  },
  {
    "text": "they're all useful predictors. But there are lots of cases where they don't give the right answer,",
    "start": "2418430",
    "end": "2423829"
  },
  {
    "text": "and to know when they give, when, to know what's really the coreferent thing,",
    "start": "2423830",
    "end": "2429005"
  },
  {
    "text": "you have to actually understand what's being described in the world. So if I have this sentence,",
    "start": "2429005",
    "end": "2435105"
  },
  {
    "text": "she poured water from the pitcher into the cup until it was full. What is it coreferent with?",
    "start": "2435105",
    "end": "2441700"
  },
  {
    "text": "Cup. [NOISE] The cup. Thank you. [LAUGHTER] Okay. So that, it refers to the cup.",
    "start": "2444530",
    "end": "2450870"
  },
  {
    "text": "But then let's look at this example. She poured water from the pitcher into the cup until it was empty.",
    "start": "2450870",
    "end": "2457530"
  },
  {
    "text": "What does it refer to? The [OVERLAPPING]. The pitcher. [LAUGHTER] Okay. So the crucial thing to notice in these two sentences is,",
    "start": "2457530",
    "end": "2466125"
  },
  {
    "text": "these sentences have identical syntactic structure, right. So Jerry Hobbs's algorithm can't possibly work,",
    "start": "2466125",
    "end": "2475694"
  },
  {
    "text": "um, for both of these sentences. It's gonna work for one of them, but not the other one.",
    "start": "2475695",
    "end": "2482550"
  },
  {
    "text": "Um, since it's working from left to right within a sentence, it's gonna say the pitcher both times actually, right.",
    "start": "2482550",
    "end": "2488865"
  },
  {
    "text": "So you can't get the answer right by Jerry Hobbs' algorithm and Jerry believed,",
    "start": "2488865",
    "end": "2495360"
  },
  {
    "text": "and still believes, um, that the only way to get these kind of examples right,",
    "start": "2495360",
    "end": "2500475"
  },
  {
    "text": "is actually if you understand the world, and you actually know what's going on in the world,",
    "start": "2500475",
    "end": "2506640"
  },
  {
    "text": "so you can see what, what this is talking about. And there are lots of examples like this. Um, this is another very famous example.",
    "start": "2506640",
    "end": "2513765"
  },
  {
    "text": "The city council refused the women a permit because they feared violence. Um, who does that they refer to?",
    "start": "2513765",
    "end": "2520140"
  },
  {
    "text": "[inaudible]. The city councilors. Um, but here's another sentence.",
    "start": "2520140",
    "end": "2525360"
  },
  {
    "text": "The city council refused the women a permit because they advocated violence.",
    "start": "2525360",
    "end": "2530415"
  },
  {
    "text": "Who does that they refer to? The women. The women. Okay. So this time it refers to the women.",
    "start": "2530415",
    "end": "2536340"
  },
  {
    "text": "Um, and again, you know, identical syntactic structure, it couldn't possibly be done right by the Hobbs algorithm.",
    "start": "2536340",
    "end": "2544185"
  },
  {
    "text": "Um, so this particular pair of examples, um, comes from Terry Winograd.",
    "start": "2544185",
    "end": "2549270"
  },
  {
    "text": "Um, how long ti- uh, so Terry Winograd was originally an NLP faculty, um,",
    "start": "2549270",
    "end": "2555150"
  },
  {
    "text": "he sort of got disillusioned with NLP because there wasn't making much progress, um, and ventured off into the land of HCI,",
    "start": "2555150",
    "end": "2562065"
  },
  {
    "text": "um, that became his career. Um, but in his early work, um, he was interested in these phenomena,",
    "start": "2562065",
    "end": "2568109"
  },
  {
    "text": "and came up with this example. And so this example really stuck with people. And so these kind of contrasts are referred to by",
    "start": "2568109",
    "end": "2576030"
  },
  {
    "text": "other people as Winograd sentences or Winograd schema. And so this is actually something that's interesting that's revived recently.",
    "start": "2576030",
    "end": "2584505"
  },
  {
    "text": "Um, so Hector Le- Levesque, um, wrote a paper, I guess five years ago now,",
    "start": "2584505",
    "end": "2589875"
  },
  {
    "text": "where he was trying to advocate for return to doing more in the way of knowledge and world modeling and artificial intelligence,",
    "start": "2589875",
    "end": "2598515"
  },
  {
    "text": "and arguing that there are lots of problems that you just can't solve by the kind of crude statistical methods,",
    "start": "2598515",
    "end": "2605595"
  },
  {
    "text": "that our machine learning systems are using. And that you really needed to do more world understanding.",
    "start": "2605595",
    "end": "2611370"
  },
  {
    "text": "And so he proposed that these Winograd schema would be a good te- alternative to the Turing test,",
    "start": "2611370",
    "end": "2618240"
  },
  {
    "text": "as a way of measuring intelligence. And actually they're just coreference decisions, right.",
    "start": "2618240",
    "end": "2623850"
  },
  {
    "text": "So, um, so there's sort of a claim here that, if you can do a coreference right 100 percent of the time,",
    "start": "2623850",
    "end": "2630675"
  },
  {
    "text": "you've solved artificial intelligence in that you're, sort of you can, can code knowledge of the world into coreference problems.",
    "start": "2630675",
    "end": "2638745"
  },
  {
    "text": "Um, yes so people have then tried to work on these Winograd schemas,",
    "start": "2638745",
    "end": "2644010"
  },
  {
    "text": "and Levesque's feeling was, you know, you just couldn't do these,",
    "start": "2644010",
    "end": "2649664"
  },
  {
    "text": "um, using kind of, the kind of statistical factors, um, that people put into their machine learning systems.",
    "start": "2649664",
    "end": "2657870"
  },
  {
    "text": "He was partly wrong about that because subsequent work, um, both neural systems and otherwise has shown that actually you can",
    "start": "2657870",
    "end": "2667050"
  },
  {
    "text": "get f- a nontrivial distance with these kind of problems because, you know,",
    "start": "2667050",
    "end": "2672165"
  },
  {
    "text": "if it is the case, um, that, you know, you can somehow see enough examples,",
    "start": "2672165",
    "end": "2678120"
  },
  {
    "text": "where the city council refuses permits, fearing violence, you know. If you've go- if you're collecting",
    "start": "2678120",
    "end": "2684390"
  },
  {
    "text": "your neural language model over tens of billions of words, you might have seen some instances of things like that,",
    "start": "2684390",
    "end": "2691530"
  },
  {
    "text": "and you could sort of predict it just on statistical patterning. But the question is, you know, how far can you actually get doing that,",
    "start": "2691530",
    "end": "2698339"
  },
  {
    "text": "without having a bit more of a world model? And so that was, you know, what Hobbs was interested in way back in 1978.",
    "start": "2698340",
    "end": "2705705"
  },
  {
    "start": "2701000",
    "end": "2766000"
  },
  {
    "text": "So he wrote, the naive approach is quite good, computationally speaking it will be a long time before a semantically based algorithm,",
    "start": "2705705",
    "end": "2714809"
  },
  {
    "text": "is sophisticated enough to perform as well. And these results set a very high standard for any other approach to aim for.",
    "start": "2714809",
    "end": "2721650"
  },
  {
    "text": "He was totally right about that, um, that it really wasn't until the 2010s that anybody",
    "start": "2721650",
    "end": "2728655"
  },
  {
    "text": "managed to produce an algorithm for pronominal anaphora resolution,",
    "start": "2728655",
    "end": "2733830"
  },
  {
    "text": "that outperformed the Hobbs algorithm. Even though it was just, uh, what he called a naive algorithm,",
    "start": "2733830",
    "end": "2740535"
  },
  {
    "text": "or he might call a crude set of linguistic rules. Um, but he says,",
    "start": "2740535",
    "end": "2746325"
  },
  {
    "text": "yet there is every reason to pursue a semantically based approach, the naive algorithm does not work.",
    "start": "2746325",
    "end": "2752325"
  },
  {
    "text": "Anyone can think of examples where it fails. In these cases it not only fails,",
    "start": "2752325",
    "end": "2757409"
  },
  {
    "text": "it gives no indication that it has failed, and offers no help in finding the real antecedent.",
    "start": "2757409",
    "end": "2763170"
  },
  {
    "text": "Um, so food for thought there. Um, but, um, notwithstanding that, I'm gonna just rush ahead at this point,",
    "start": "2763170",
    "end": "2770400"
  },
  {
    "start": "2766000",
    "end": "2853000"
  },
  {
    "text": "and tell you about some of the, um, statistical and neural algorithms, um, that have been used for coreference resolution.",
    "start": "2770400",
    "end": "2777119"
  },
  {
    "text": "So the simplest form of algorithm that's commonly used, is what is called mention pair models.",
    "start": "2777120",
    "end": "2784215"
  },
  {
    "text": "So what we mean by mention pair models is, um, we are gonna take pairs of mentions,",
    "start": "2784215",
    "end": "2792030"
  },
  {
    "text": "and we're gonna train a binary classifier that says, is coreferent or isn't coreferent.",
    "start": "2792030",
    "end": "2799230"
  },
  {
    "text": "And so then we're gonna proceed left to right through the text. And every time we get to a new mention,",
    "start": "2799230",
    "end": "2809325"
  },
  {
    "text": "we're gonna then evaluate our classifier with respect to every preceding mention,",
    "start": "2809325",
    "end": "2815895"
  },
  {
    "text": "and we're gonna say, are they coreferent? And it's gonna say yes or no.",
    "start": "2815895",
    "end": "2821234"
  },
  {
    "text": "And we're gonna find out that some of them. It says yes for, um, I voted for Nader because he was like, most aligned with my value.",
    "start": "2821235",
    "end": "2830160"
  },
  {
    "text": "She said, if we have a good classifier, it will say yes to the two bu- blue ones and not to the rest of them.",
    "start": "2830160",
    "end": "2838470"
  },
  {
    "text": "Um, and so then we'll have at training time, negative examples that Nader and he are negative examples.",
    "start": "2838470",
    "end": "2846540"
  },
  {
    "text": "[NOISE] So if you have data marked for coreference, we have the sort of positive and negative examples,",
    "start": "2846540",
    "end": "2853530"
  },
  {
    "start": "2853000",
    "end": "2885000"
  },
  {
    "text": "and we can train a model. And so for training a model, we have a sort of the classifier outcome is one or zero,",
    "start": "2853530",
    "end": "2862230"
  },
  {
    "text": "based on whether two mentions are coreferent. We're gonna have a coreference model that",
    "start": "2862230",
    "end": "2867960"
  },
  {
    "text": "predicts the probability of them being coreferent. And we're gonna train it with the same kind of cross entropy loss,",
    "start": "2867960",
    "end": "2874349"
  },
  {
    "text": "we've used other places and, um, try and learn a model that predicts coreference.",
    "start": "2874350",
    "end": "2881160"
  },
  {
    "text": "And so then when we get to test time, um, and we have a piece of text with mentions, um,",
    "start": "2881160",
    "end": "2888495"
  },
  {
    "start": "2885000",
    "end": "3121000"
  },
  {
    "text": "we're gonna run this classifier and it's gonna say, um, yes or no, with some probability.",
    "start": "2888495",
    "end": "2896400"
  },
  {
    "text": "And if we pick a threshold like 0.5, we'll add certain coreference links.",
    "start": "2896400",
    "end": "2902565"
  },
  {
    "text": "And that sort of looks pretty good. Um, but we're gonna sort of complete it off by saying well,",
    "start": "2902565",
    "end": "2909480"
  },
  {
    "text": "if A is coreferent to B and B is K coreferent to C. Then really also A is coreferent to C. So we're gonna do a transitive closure,",
    "start": "2909480",
    "end": "2920040"
  },
  {
    "text": "and that will give us our clustering. Um, note here that there's a certain danger in this.",
    "start": "2920040",
    "end": "2926160"
  },
  {
    "text": "Because this means, if we make, since we're sor- with the transitive closure,",
    "start": "2926160",
    "end": "2931755"
  },
  {
    "text": "that's always adding clustering links. And so that means the danger is that we're gonna over cluster,",
    "start": "2931755",
    "end": "2938310"
  },
  {
    "text": "because if we make a single mistake and we link things that should be kept separate.",
    "start": "2938310",
    "end": "2944400"
  },
  {
    "text": "So for example, if we wrongly said, he and my are coreferent, then everything of this, um,",
    "start": "2944400",
    "end": "2950565"
  },
  {
    "text": "discourse would collapse together into one cluster, and everything would be deemed coreferent.",
    "start": "2950565",
    "end": "2956920"
  },
  {
    "text": "Okay, um, and this, something that I haven't really emphasized, but comes up,",
    "start": "2956920",
    "end": "2965480"
  },
  {
    "text": "is well, there's some mentions that are coreferent to nothing, right. In the Shruthi Rao story, there was a park,",
    "start": "2965480",
    "end": "2972890"
  },
  {
    "text": "which was just mentioned once in the text, and so on, in this form of algorithm,",
    "start": "2972890",
    "end": "2978190"
  },
  {
    "text": "what we'd like the classifier to say is, no, no, no, no, no, for all of the decisions.",
    "start": "2978190",
    "end": "2984615"
  },
  {
    "text": "And so it's deemed coreferent to nothing. And then it's just a singleton mention.",
    "start": "2984615",
    "end": "2989915"
  },
  {
    "text": "This sort of works, but it hasn't proven to be the best way of doing coreference.",
    "start": "2989915",
    "end": "2998660"
  },
  {
    "text": "And a lot of the reason why it's not the best way to do coreference is because we have this phenomenon of anaphora where we have textural dependence.",
    "start": "2998660",
    "end": "3009410"
  },
  {
    "text": "A lot of the time, it seems that we're not really,",
    "start": "3009410",
    "end": "3014535"
  },
  {
    "text": "um, what- sort of wanting to make this all coreference decisions.",
    "start": "3014535",
    "end": "3019815"
  },
  {
    "text": "We'd like to make the anaphora decisions of textural dependence. So we'd like to say that he is,",
    "start": "3019815",
    "end": "3027410"
  },
  {
    "text": "um, dependent on Nader and my is dependent on I.",
    "start": "3027410",
    "end": "3033140"
  },
  {
    "text": "These are anaphora relationships. So we'd like to just choose one example of what is this anaphora relationship.",
    "start": "3033140",
    "end": "3041285"
  },
  {
    "text": "And so that's led to people then looking at what is called, um, Mention Pair Models, right?",
    "start": "3041285",
    "end": "3047475"
  },
  {
    "text": "That the problem is that if we have a long document with lots of mentions, um, that we want to not be saying- trying to find all of them and say, yes.",
    "start": "3047475",
    "end": "3057050"
  },
  {
    "text": "We just want to be saying there's a particular- we just want to be saying that there's a particular one.",
    "start": "3057050",
    "end": "3063694"
  },
  {
    "text": "So for the he at the end here, its anaphor relationship is back to Nader and you don't wanna be trying to say this",
    "start": "3063695",
    "end": "3071350"
  },
  {
    "text": "he is also coreferent back to all of these other things that are earlier in the text.",
    "start": "3071350",
    "end": "3077600"
  },
  {
    "text": "So it's not something that's been explored much. But arguably, this is a case again,",
    "start": "3077600",
    "end": "3084940"
  },
  {
    "text": "where you should be separating coreference from anaphors because for anaphors it seems like",
    "start": "3084940",
    "end": "3090905"
  },
  {
    "text": "the right way to think is that they have one prior thing in the text that they're textually dependent on.",
    "start": "3090905",
    "end": "3097630"
  },
  {
    "text": "Whereas true coreferents, when you just have various mentions in the text of Ralph Nader,",
    "start": "3097630",
    "end": "3103345"
  },
  {
    "text": "this Ralph Nader that, Nader did that, those aren't textually dependent and they should all be being grouped together as coreferents.",
    "start": "3103345",
    "end": "3112070"
  },
  {
    "text": "Um, but our models sort of don't normally try and do some one way and some the other way,",
    "start": "3112070",
    "end": "3118520"
  },
  {
    "text": "but you choose one of the models. So in the other one, we do it for- to do the other way,",
    "start": "3118520",
    "end": "3126010"
  },
  {
    "start": "3121000",
    "end": "3297000"
  },
  {
    "text": "you do what's mention rankings. So for mention ranking, the idea is for each mention,",
    "start": "3126010",
    "end": "3133400"
  },
  {
    "text": "we're going to find- try and find it an antecedent that comes before- before it in the text,",
    "start": "3133400",
    "end": "3140640"
  },
  {
    "text": "that is- that it is, um, coreferent with, and we're going to make a one of N decision.",
    "start": "3140640",
    "end": "3146809"
  },
  {
    "text": "So that when we see she here, we're going to say, \"Okay, um, what is this coreferent with?\"",
    "start": "3146810",
    "end": "3155400"
  },
  {
    "text": "And we're going to pick one thing that it's coreferent with even though there might be others in the text.",
    "start": "3155400",
    "end": "3161130"
  },
  {
    "text": "Um, so if we're doing that, we then have a problem with singleton mentions because if",
    "start": "3161130",
    "end": "3167490"
  },
  {
    "text": "we're trying to- for every mention we find say, choose the thing that came before it in the text with which it's coreferent,",
    "start": "3167490",
    "end": "3175430"
  },
  {
    "text": "the right answer might be that there's no such thing. So what we do is we add",
    "start": "3175430",
    "end": "3180579"
  },
  {
    "text": "one additional dummy mention right at the front here, the NA mention.",
    "start": "3180580",
    "end": "3186410"
  },
  {
    "text": "So one choice is you're gonna say there isn't anything preceding. So effectively, when you get to I,",
    "start": "3186410",
    "end": "3193935"
  },
  {
    "text": "since this is, um, the first, um, real mention in the text,",
    "start": "3193935",
    "end": "3199265"
  },
  {
    "text": "you're necessarily gonna choose as, um, its antecedent NA. You then go on to Nader and you have two choices.",
    "start": "3199265",
    "end": "3207815"
  },
  {
    "text": "You can either say it's coreferent to I or it's coreferent to NA.",
    "start": "3207815",
    "end": "3214109"
  },
  {
    "text": "I, it's a new mention- a new entity that's being mentioned in the text and the right answer is it's a new mention in- a new entity being mentioned in the text.",
    "start": "3214110",
    "end": "3223280"
  },
  {
    "text": "Then you get to he and now you have three choices, and the right thing is to say that it's coreferent to Nader.",
    "start": "3223280",
    "end": "3231100"
  },
  {
    "text": "Okay. Um, so this time, it's- for training our models,",
    "start": "3231110",
    "end": "3237640"
  },
  {
    "text": "it's sort of the same, um, apart from this, sort of this different one of semantics.",
    "start": "3237640",
    "end": "3244510"
  },
  {
    "text": "So now- previously, we wanted to say that for our, um,",
    "start": "3244510",
    "end": "3249820"
  },
  {
    "text": "mention pair classifier that is going to try and classify I and she,",
    "start": "3249820",
    "end": "3255030"
  },
  {
    "text": "and my and she, and both of them had to get a high score, where now it's sufficient that just one of them gets",
    "start": "3255030",
    "end": "3262030"
  },
  {
    "text": "a high score because that's sort of enough for us to do. So what we're gonna use is our good old softmax and so for she,",
    "start": "3262030",
    "end": "3270605"
  },
  {
    "text": "we're gonna put a softmax over the antecedents. And our hope is simply that we get a high probability with one of the antecedents,",
    "start": "3270605",
    "end": "3279660"
  },
  {
    "text": "if it has an antecedent or a high score with NA, if it doesn't have any prior referents.",
    "start": "3279660",
    "end": "3286755"
  },
  {
    "text": "And so then when we're doing classification at run-time, we're going to sort of add only the highest scoring coreference link.",
    "start": "3286755",
    "end": "3296355"
  },
  {
    "text": "So that means we train it just slightly differently because now what we're going to do is that,",
    "start": "3296355",
    "end": "3303180"
  },
  {
    "start": "3297000",
    "end": "3365000"
  },
  {
    "text": "when we're- what we're wanting to say is, we want a high score of coreference between at least one of the antecedents.",
    "start": "3303180",
    "end": "3313025"
  },
  {
    "text": "And so one possible model is, we can maximize this probability. So for the ones that are coreferent in the gold standard data,",
    "start": "3313025",
    "end": "3321105"
  },
  {
    "text": "we want the sum of their assigned probabilities to be high. And so what that means is that it's sort of sufficient if we have,",
    "start": "3321105",
    "end": "3331135"
  },
  {
    "text": "um, one of them giving a high probability and they don't all have to give a high probability.",
    "start": "3331135",
    "end": "3338375"
  },
  {
    "text": "So providing it's giving 0.9 probability, say it a one of the correct antecedents,",
    "start": "3338375",
    "end": "3343535"
  },
  {
    "text": "we're getting a high score. Okay. So we're gonna turn that into a loss function in the kind of",
    "start": "3343535",
    "end": "3349660"
  },
  {
    "text": "standard way we do in which we take log probabilities, um, and then we want to, um,",
    "start": "3349660",
    "end": "3356260"
  },
  {
    "text": "or negative log probabilities to give us a loss and then we're wanting to minimize that loss.",
    "start": "3356260",
    "end": "3362150"
  },
  {
    "text": "So with the mention ranking model, um, at test time,",
    "start": "3362150",
    "end": "3367869"
  },
  {
    "start": "3365000",
    "end": "3409000"
  },
  {
    "text": "it's pretty much the same, but our softmax classifier is just going to assign one antecedent for each mention.",
    "start": "3367870",
    "end": "3376280"
  },
  {
    "text": "And so we're then gonna hope that those sort of give us the kind of clusters that we want and there's no subsequent clustering phase.",
    "start": "3376280",
    "end": "3385640"
  },
  {
    "text": "So there's a big part of this that I left out which was,",
    "start": "3385820",
    "end": "3390875"
  },
  {
    "text": "I've just said, \"Okay, we have this probability of MI and MJ as the- are they coreferent?\"",
    "start": "3390875",
    "end": "3398590"
  },
  {
    "text": "But I've sort of said, zero as to how you can determine whether they're coreferent or not.",
    "start": "3398590",
    "end": "3403760"
  },
  {
    "text": "Um, so briefly, um, here- here's the classical way of doing it.",
    "start": "3403760",
    "end": "3409775"
  },
  {
    "start": "3409000",
    "end": "4761000"
  },
  {
    "text": "The classical way of doing it is, you had a whole bunch of features and you had",
    "start": "3409775",
    "end": "3416090"
  },
  {
    "text": "a feature based statistical classifier which gave a score. And these are the kind of features you could use.",
    "start": "3416090",
    "end": "3422650"
  },
  {
    "text": "So there are sort of strong features of person, number, gender agreement. So if you have a masculine or feminine pronoun,",
    "start": "3422650",
    "end": "3429720"
  },
  {
    "text": "you wanna find an appropriate antecedent for it. There are weaker, um, semantic compatibility features.",
    "start": "3429720",
    "end": "3436630"
  },
  {
    "text": "So the mining conglomerate, the company, the conglomerate might be sort of similar to a company.",
    "start": "3436630",
    "end": "3441755"
  },
  {
    "text": "You could use something like word2vec similarity and assess that. There are syntactic constraints.",
    "start": "3441755",
    "end": "3448119"
  },
  {
    "text": "So this is then kind of like, um, what Hobbs's algorithm was all about us working out",
    "start": "3448120",
    "end": "3454570"
  },
  {
    "text": "how likely different syntactic configurations are gonna mean coreference. And indeed it is the case, you know,",
    "start": "3454570",
    "end": "3460950"
  },
  {
    "text": "that a lot of these feature-based systems used Hobbs' algorithm as a feature inside",
    "start": "3460950",
    "end": "3466150"
  },
  {
    "text": "the system that was weighted and was normally a very strong feature to decide coreference.",
    "start": "3466150",
    "end": "3471859"
  },
  {
    "text": "Um, there are lots of other things you can put in as features. Um, recency. So John went to a movie,",
    "start": "3471860",
    "end": "3478240"
  },
  {
    "text": "Jack went as well, he was not busy. The most likely referent for he is the closer candidate Jack.",
    "start": "3478240",
    "end": "3485180"
  },
  {
    "text": "Um, I've mentioned subjects are more likely to be, um, the antecedent. John went to a movie with Jack,",
    "start": "3485180",
    "end": "3491550"
  },
  {
    "text": "he was not busy. Um, John seems a more likely antecedent. So that's the sort of subject preference.",
    "start": "3491550",
    "end": "3498155"
  },
  {
    "text": "There's also a parallelism preference. So John went with Jack to a movie, Joe went with him to a bar.",
    "start": "3498155",
    "end": "3504170"
  },
  {
    "text": "I think it's sort of reasonable to think that him there is probably Jack, and that's sort of for parallelism reasons as opposed to going with the subject.",
    "start": "3504170",
    "end": "3512825"
  },
  {
    "text": "So there are various kind of linguistic features and constraints and so on, and you can throw these all into a statistical classifier and that's",
    "start": "3512825",
    "end": "3519970"
  },
  {
    "text": "sort of 2000s decade coref systems as to how they're built. Um, more recently, people have built neural systems.",
    "start": "3519970",
    "end": "3529349"
  },
  {
    "text": "And so for these, we are kind of normally using the same kind of embeddings. So we'll have a candidate antecedent that will have embeddings,",
    "start": "3529350",
    "end": "3538250"
  },
  {
    "text": "we'll have a mention that has embeddings. And this will be something like average word vectors or something like that for the mention.",
    "start": "3538250",
    "end": "3545595"
  },
  {
    "text": "And we're gonna feed these into a neural network that will give us our score. But what you find is that",
    "start": "3545595",
    "end": "3553070"
  },
  {
    "text": "most of these systems as well as having something like word vectors, they also have additional features, um,",
    "start": "3553070",
    "end": "3560610"
  },
  {
    "text": "and these features still capture some of the things that were in the feature-based statistical classifiers.",
    "start": "3560610",
    "end": "3568265"
  },
  {
    "text": "So there will be often features that reflect things like, what grammatical relation does this mention have? Is it a subject?",
    "start": "3568265",
    "end": "3577270"
  },
  {
    "text": "Is it an object? That's something you could put into the features of a mention.",
    "start": "3577270",
    "end": "3582825"
  },
  {
    "text": "But then, closer things are more likely to be coreferent. So you might have additional features here which record how far apart dimensions are,",
    "start": "3582825",
    "end": "3591270"
  },
  {
    "text": "and those things get thrown in as well. Um, and so these kind of features are still important even in neural systems.",
    "start": "3591270",
    "end": "3600934"
  },
  {
    "text": "And so I'll skip ahead now and show you a bit about, um,",
    "start": "3600935",
    "end": "3607165"
  },
  {
    "text": "what is the kind of current state of the art for coreference resolution, and this was a system that was done at the University of Washington in",
    "start": "3607165",
    "end": "3614950"
  },
  {
    "text": "2017 by Kenton Lee and assorted other, um, authors.",
    "start": "3614950",
    "end": "3620494"
  },
  {
    "text": "Um, so the goal here was to produce an end-to-end coreference system that it was text in,",
    "start": "3620495",
    "end": "3626910"
  },
  {
    "text": "um, mention clusters that are coreferent out. Um, and so they're wanting to use sort of a more complex",
    "start": "3626910",
    "end": "3635335"
  },
  {
    "text": "neural network that can do the whole thing end-to-end. So I'll go through,",
    "start": "3635335",
    "end": "3640420"
  },
  {
    "text": "um, the steps of that. So the first step is we just start off with words.",
    "start": "3640420",
    "end": "3645984"
  },
  {
    "text": "And so for each word, we're going to look up a word embedding for it and that's in other stuff we've seen.",
    "start": "3645985",
    "end": "3653020"
  },
  {
    "text": "We're also going to put in a character level CNN, and the two of those concatenated are going to give the representation of each token.",
    "start": "3653020",
    "end": "3660885"
  },
  {
    "text": "That much should look familiar. Okay. Then after that, we're going to run a deep bidirectional LSTM back and forth across the sentence.",
    "start": "3660885",
    "end": "3671255"
  },
  {
    "text": "Again, that should look familiar from stuff that we've seen before. Um, the next step gets us a bit into doing something more special, um,",
    "start": "3671255",
    "end": "3681700"
  },
  {
    "text": "For coreference. So what they wanted to do after that is have a representation for spans.",
    "start": "3681700",
    "end": "3690790"
  },
  {
    "text": "And so by span, we mean any contiguous subphrase of the word, of the sentence.",
    "start": "3690790",
    "end": "3698050"
  },
  {
    "text": "So this is a span. This is a span. This is a span. Electric said the postal is a span, every sub-sequence.",
    "start": "3698050",
    "end": "3706315"
  },
  {
    "text": "Um, so I'll come back to that. But, you know, they'll- in principle, you're working this out for every sub-sequence.",
    "start": "3706315",
    "end": "3713155"
  },
  {
    "text": "So for every sub-sequence, they want to come up with a span representation.",
    "start": "3713155",
    "end": "3718675"
  },
  {
    "text": "And so this span representation is going to be in three parts,",
    "start": "3718675",
    "end": "3724975"
  },
  {
    "text": "um, that represent one of these sub-sequences. Um, so each of these will get its own representation.",
    "start": "3724975",
    "end": "3733660"
  },
  {
    "text": "And so the question is, what? And so we have this span representation,",
    "start": "3733660",
    "end": "3738910"
  },
  {
    "text": "and it's gonna be in these three parts here. Um, so what these parts are is,",
    "start": "3738910",
    "end": "3746770"
  },
  {
    "text": "well, first of all, we're going to have a representation, um, which is just looking at the first word of",
    "start": "3746770",
    "end": "3755035"
  },
  {
    "text": "the span and the last word of the span according to the BiLSTM.",
    "start": "3755035",
    "end": "3760450"
  },
  {
    "text": "So if we're looking at the span, the postal service, we're going to take this BiLSTM and",
    "start": "3760450",
    "end": "3765670"
  },
  {
    "text": "this BiLSTM and use them as part of the representation of the span. Um, that's a good start,",
    "start": "3765670",
    "end": "3772225"
  },
  {
    "text": "but then they actually do something a little tricky. So kind of like when we're doing dependency parsing, the idea was,",
    "start": "3772225",
    "end": "3779710"
  },
  {
    "text": "well, phrases are going to have a headword, um, so that if it's,",
    "start": "3779710",
    "end": "3785050"
  },
  {
    "text": "um, you know, my younger sister that the headword of that is sister,",
    "start": "3785050",
    "end": "3790420"
  },
  {
    "text": "and there- if it's something like the goat in the corner of the field, the headword of that is going to be goat.",
    "start": "3790420",
    "end": "3796960"
  },
  {
    "text": "So they want to find a way of capturing headwords out of the text. Um, and so what they're going to do for that is use attention.",
    "start": "3796960",
    "end": "3806200"
  },
  {
    "text": "So they're going to say we have this span, the postal service, and we're going to use attention as",
    "start": "3806200",
    "end": "3813640"
  },
  {
    "text": "a span internal mechanism to sort of approximate a head. So what we're going to do, uh, here,",
    "start": "3813640",
    "end": "3822205"
  },
  {
    "text": "what we're going to do is we're going to want to learn attention weights, I'm just gonna, yeah.",
    "start": "3822205",
    "end": "3830020"
  },
  {
    "text": "Um, what we're gonna do is for this span, um, we're going to be learning based on the hope,",
    "start": "3830020",
    "end": "3838810"
  },
  {
    "text": "the ends of the span which words to pay how much attention to. So we're gonna put attention weights on the different words,",
    "start": "3838810",
    "end": "3846970"
  },
  {
    "text": "and then we're going to, in the usual attention way, make this weighted sum of having put the word pair-",
    "start": "3846970",
    "end": "3855220"
  },
  {
    "text": "the bidirectional LSTM pairs through a feed-forward network and end up with this new representation of a weighted representation.",
    "start": "3855220",
    "end": "3863695"
  },
  {
    "text": "And the hope is that in this case, most of the weight will go on this final servers, which will be the headword.",
    "start": "3863695",
    "end": "3870444"
  },
  {
    "text": "But there'll be sort of distributed across it. And so that gives them a model of",
    "start": "3870445",
    "end": "3876055"
  },
  {
    "text": "sort of mentions that use both ends and hope to find the key word of the mention.",
    "start": "3876055",
    "end": "3881875"
  },
  {
    "text": "Okay. Um, so, um, that's two-thirds of the span,",
    "start": "3881875",
    "end": "3888010"
  },
  {
    "text": "but they still have over here these additional features. And so they still have some additional features.",
    "start": "3888010",
    "end": "3894235"
  },
  {
    "text": "They want to be able to mark speakers and addressees. Um, they want to mark other things like the grammatical role.",
    "start": "3894235",
    "end": "3902200"
  },
  {
    "text": "But if things occur, you know, it is still useful to have some additional features.",
    "start": "3902200",
    "end": "3907240"
  },
  {
    "text": "And so what they do is, this is a representation of each span, and then they're going to want to say are two spans coreferent.",
    "start": "3907240",
    "end": "3916390"
  },
  {
    "text": "And so they're going to have one score for the two, two split, each of two spans,",
    "start": "3916390",
    "end": "3922119"
  },
  {
    "text": "which is essentially saying, is that a good mention? And then you're going to have scores of, do they look coreferent?",
    "start": "3922120",
    "end": "3929170"
  },
  {
    "text": "And so having calculated these representations for each span,",
    "start": "3929170",
    "end": "3934869"
  },
  {
    "text": "you're running three- through things through a fully connected feed-forward network, multiplying by a weight factor,",
    "start": "3934870",
    "end": "3941244"
  },
  {
    "text": "and that's giving you, uh, is that a good mention score? And then for are they coreferent,",
    "start": "3941245",
    "end": "3946960"
  },
  {
    "text": "you're taking two spans, the pointwise Hadamard product of two spans and",
    "start": "3946960",
    "end": "3953650"
  },
  {
    "text": "some extra features like distance apart in the text and putting them through another neural network,",
    "start": "3953650",
    "end": "3959469"
  },
  {
    "text": "and that's then giving you, are these two spans coreferent? But all of these pieces,",
    "start": "3959469",
    "end": "3965590"
  },
  {
    "text": "um, give you an overall loss function. So you can say that your model is, um, okay.",
    "start": "3965590",
    "end": "3974815"
  },
  {
    "text": "We're going to run these LSTMs, we're going to take all spans, we're going to score this,",
    "start": "3974815",
    "end": "3980828"
  },
  {
    "text": "and we know the gold answer for our coreference system. And so we want to be predicting things that are coreferent and have",
    "start": "3980829",
    "end": "3989200"
  },
  {
    "text": "a loss based on the probability that we calculate with these scores,",
    "start": "3989200",
    "end": "3994375"
  },
  {
    "text": "um, as I had mentioned, ranking model using a softmax loss like before. So if you put all of this together and train it end to end,",
    "start": "3994375",
    "end": "4002775"
  },
  {
    "text": "you've got a whole coreference system that goes from words to coreference decisions.",
    "start": "4002775",
    "end": "4008684"
  },
  {
    "text": "Um, there's a huge problem with that, um, which is if you actually applied this naively, well,",
    "start": "4008685",
    "end": "4015809"
  },
  {
    "text": "the problem is the number of spans in a piece of text is the square of the length of the text in words.",
    "start": "4015810",
    "end": "4023055"
  },
  {
    "text": "And so therefore, if you're making coreference decisions, which are between, um, pairs of spans,",
    "start": "4023055",
    "end": "4030059"
  },
  {
    "text": "you've then got an algorithm that's, um, O- OT to the fourth,",
    "start": "4030060",
    "end": "4035415"
  },
  {
    "text": "where the length of the text is T words. So that's sort of really, really computationally impractical.",
    "start": "4035415",
    "end": "4042375"
  },
  {
    "text": "So at this point, they sort of say, well, actually, we do want to use our mouths a little and we want to work out",
    "start": "4042375",
    "end": "4049905"
  },
  {
    "text": "how likely different things are to be mentions. So effectively, um, then they're putting in a lot of pruning to",
    "start": "4049905",
    "end": "4058650"
  },
  {
    "text": "decide which spans are actually things that they want to consider in their model.",
    "start": "4058650",
    "end": "4063765"
  },
  {
    "text": "And so at this point, in some sense, it's a little bit of a cheat, right? Because really this pruning step here is okay,",
    "start": "4063765",
    "end": "4070440"
  },
  {
    "text": "we're going to stick in a mention detection module, um, just like a conventional system.",
    "start": "4070440",
    "end": "4077040"
  },
  {
    "text": "Um, but the prettiness of it is in terms of the algor- in terms of the loss function that's defined.",
    "start": "4077040",
    "end": "4085440"
  },
  {
    "text": "The loss function is really defined end to end from just a sequence of tokens through to the mention ranking decisions.",
    "start": "4085440",
    "end": "4094380"
  },
  {
    "text": "And so it is an end-to-end model, even though in practice to make it practical,",
    "start": "4094380",
    "end": "4100319"
  },
  {
    "text": "you have to have something like a mention detector to get it to work.",
    "start": "4100320",
    "end": "4104679"
  },
  {
    "text": "Okay. Pause for breath. Um, yeah, so there's one last.",
    "start": "4106100",
    "end": "4114509"
  },
  {
    "text": "So we've done sort of mention pair model and mention ranking model.",
    "start": "4114510",
    "end": "4120179"
  },
  {
    "text": "Um, and so for both of those, you're just taking individual mentions and saying, here's another mention, what,",
    "start": "4120180",
    "end": "4126870"
  },
  {
    "text": "what shall I do with it? Let's look at mentions and see if we're coreferent to each other.",
    "start": "4126870",
    "end": "4133125"
  },
  {
    "text": "And that there's no real concept of entities which are clusters of mentions.",
    "start": "4133125",
    "end": "4140279"
  },
  {
    "text": "You're just making these sort of one-off decisions between pairs of mentions, and somehow,",
    "start": "4140280",
    "end": "4146040"
  },
  {
    "text": "sort of the entities as clusters just emerge as a consequence of those mention pair decisions.",
    "start": "4146040",
    "end": "4154049"
  },
  {
    "text": "So there's been this sort of long-standing feeling that,",
    "start": "4154050",
    "end": "4159554"
  },
  {
    "text": "oh that can't really be right, the right way to do coreference must be really to do it as a clustering task,",
    "start": "4159555",
    "end": "4168060"
  },
  {
    "text": "and people often refer to this as saying, we want entities as first-class citizens.",
    "start": "4168060",
    "end": "4173234"
  },
  {
    "text": "So we want to be, sort of putting together mentions into clusters that represent the entities.",
    "start": "4173235",
    "end": "4180299"
  },
  {
    "text": "And the obvious way to do that is to do a kind of bottom-up agglomerative clustering. So you start off by saying,",
    "start": "4180300",
    "end": "4186900"
  },
  {
    "text": "each mention is its own singleton cluster, and then you're making decisions to merge clu- clusters which is initially,",
    "start": "4186900",
    "end": "4195585"
  },
  {
    "text": "um, saying two mentions are coreferent. But as you go on with it, you're then making decisions that two clusters are coreferent or not.",
    "start": "4195585",
    "end": "4204284"
  },
  {
    "text": "So the idea here is you'll have a piece of text, Google recently blah blah blah blah, the company announced Google Plus, blah blah blah blah,",
    "start": "4204285",
    "end": "4212055"
  },
  {
    "text": "the product features blah blah blah blah. And so you have here some mentions.",
    "start": "4212055",
    "end": "4217170"
  },
  {
    "text": "And so what you're going to do is start off saying that okay, there are these four mentions that each their own cluster.",
    "start": "4217170",
    "end": "4224445"
  },
  {
    "text": "And then what we're gonna do, is we're going to make some decisions. Um, so we might decide that these two clusters",
    "start": "4224445",
    "end": "4232739"
  },
  {
    "text": "are coreferent and merge them into one cluster. And then we might decide that these two,",
    "start": "4232740",
    "end": "4241965"
  },
  {
    "text": "um, clusters are coreferent and merge them into one cluster.",
    "start": "4241965",
    "end": "4248094"
  },
  {
    "text": "And so we're progressively clustering. And so then, we're going to look at these two clusters,",
    "start": "4248095",
    "end": "4254030"
  },
  {
    "text": "cluster one and cluster two, and say, no we don't think those ones are coreferent,",
    "start": "4254030",
    "end": "4260585"
  },
  {
    "text": "and therefore we're going to keep them apart. And so your, your coreference algorithm stops when there's nothing left to merge.",
    "start": "4260585",
    "end": "4270645"
  },
  {
    "text": "And the reason why people think that this is the right thing to do is, the feeling is that if we sort of build partial clusters like this,",
    "start": "4270645",
    "end": "4279930"
  },
  {
    "text": "that you'll be able to do a better job. Because if I just sort of say, well here are two mentions,",
    "start": "4279930",
    "end": "4285615"
  },
  {
    "text": "Google and Google Plus, should they be regarded as co- coreferent or not?",
    "start": "4285615",
    "end": "4292020"
  },
  {
    "text": "Um, well, since you're smart human beings, and know what Google is and know what Google Plus is, of course you'll answer no, of course not.",
    "start": "4292020",
    "end": "4299070"
  },
  {
    "text": "Um, but, you know, if you're just a computer trying to make a decision, it's sort of hard to know the right answer,",
    "start": "4299070",
    "end": "4305325"
  },
  {
    "text": "because there are lots of other cases when there are shortenings, where the right answer is that they're coreferent, right.",
    "start": "4305325",
    "end": "4312030"
  },
  {
    "text": "Because if this is being Google and Google Corp, then it would have been right to regard them as coreferent.",
    "start": "4312030",
    "end": "4319200"
  },
  {
    "text": "Or if it was sort of, um, something like Hillary Clinton and Hillary,",
    "start": "4319200",
    "end": "4324210"
  },
  {
    "text": "it would have been right to regard them as coreferent. So it can often be kind of hard to tell what's coreferent.",
    "start": "4324210",
    "end": "4329895"
  },
  {
    "text": "Um, but the hope is that, if you've made some of the easy decisions first,",
    "start": "4329895",
    "end": "4334980"
  },
  {
    "text": "so if you decide Google and the company are coreferent and Google Plus and the product are coreferent,",
    "start": "4334980",
    "end": "4340950"
  },
  {
    "text": "then it should be much easier to tell and to say, well product and company,",
    "start": "4340950",
    "end": "4345990"
  },
  {
    "text": "they're definitely different things. And therefore we should keep these things separate.",
    "start": "4345990",
    "end": "4351510"
  },
  {
    "text": "Um, and so that is the goal, and so to follow that goal,",
    "start": "4351510",
    "end": "4356954"
  },
  {
    "text": "the kind of models people build. And this was actually a model that Kevin Clark is one of the PhD students here,",
    "start": "4356955",
    "end": "4363675"
  },
  {
    "text": "um, and we did a couple of years ago. The idea was well, what we're going to do is,",
    "start": "4363675",
    "end": "4369350"
  },
  {
    "text": "we're initially going to consider mentioned pairs, and build some kind of distributed, mention pair representation,",
    "start": "4369350",
    "end": "4377179"
  },
  {
    "text": "which is kind of similar to what we were doing previously with the previous models. But we're then going to go beyond that and come up with cluster representations.",
    "start": "4377180",
    "end": "4387900"
  },
  {
    "text": "And then we can look at cluster pair representations. And we would hope that by looking at these cluster representations,",
    "start": "4387900",
    "end": "4396045"
  },
  {
    "text": "we'll be able to make better decisions of what to merge or what next to merge.",
    "start": "4396045",
    "end": "4401760"
  },
  {
    "text": "Um, I have a few more slides that go through the Clark and Manning algorithm.",
    "start": "4401760",
    "end": "4407760"
  },
  {
    "text": "Um, but I also have just a few minutes left. And so I think I'll skip the details.",
    "start": "4407760",
    "end": "4413680"
  },
  {
    "text": "Um, I think the main thing that's interesting here, is the idea of clustering based coreference algorithms,",
    "start": "4413680",
    "end": "4421740"
  },
  {
    "text": "and why in principle, it should give you extra oomph. Um, and that's sort of the main useful thing to get through.",
    "start": "4421740",
    "end": "4429135"
  },
  {
    "text": "Because what I want to make sure we have covered in the last few minutes that I've said nothing at all about, is how do you evaluate coreference resolution and how well does it work?",
    "start": "4429135",
    "end": "4438630"
  },
  {
    "text": "So let me skip ahead to that. Um, so if you look at coreference resolution papers,",
    "start": "4438630",
    "end": "4447120"
  },
  {
    "text": "or something like that, um, there are many metrics that people have used to evaluate coreference,",
    "start": "4447120",
    "end": "4455250"
  },
  {
    "text": "and they have a long alphabet soup of names. So there's MUC, and CEAF, and LEA, and B- CUBED, and BLANC and,",
    "start": "4455250",
    "end": "4462510"
  },
  {
    "text": "um, things like that. Um, so effectively part of it is that if you look in the clustering literature,",
    "start": "4462510",
    "end": "4469079"
  },
  {
    "text": "there are lots of ways that people try and evaluate clustering, and essentially any of those metrics and some other ones, you can, um,",
    "start": "4469080",
    "end": "4476610"
  },
  {
    "text": "port over, um, to, um, coreference evaluation. I mean, why it's kind of difficult is the situation you have,",
    "start": "4476610",
    "end": "4485895"
  },
  {
    "text": "is that you have a gold standard which picks out certain clusters, and the system picks out certain clusters,",
    "start": "4485895",
    "end": "4492885"
  },
  {
    "text": "and you get some result like this and you have to decide how good it is.",
    "start": "4492885",
    "end": "4498000"
  },
  {
    "text": "So I'm going to show you just quickly one particular algorithm. So the B-CUBED algorithm uses",
    "start": "4498000",
    "end": "4504630"
  },
  {
    "text": "precision and recall and F-measure like we thought of before. So it looks at, uh,",
    "start": "4504630",
    "end": "4511290"
  },
  {
    "text": "cluster identified by the system. And it says, well this cluster is four-fifths,",
    "start": "4511290",
    "end": "4519105"
  },
  {
    "text": "um, gold cluster one, so the precision is four-fifths. But actually, um, there are six things in gold cluster one.",
    "start": "4519105",
    "end": "4528240"
  },
  {
    "text": "So it only has a recall of four-sixth of that cluster.",
    "start": "4528240",
    "end": "4533760"
  },
  {
    "text": "And then it similarly does for the other one, the same kind of calculation.",
    "start": "4533760",
    "end": "4539445"
  },
  {
    "text": "And then it's going to average across the precisions and recalls, um, and it's going to come up with an overall, um, B-CUBED score.",
    "start": "4539445",
    "end": "4549045"
  },
  {
    "text": "Um, in- if you think about this from an algorithm's perspective,",
    "start": "4549045",
    "end": "4554400"
  },
  {
    "text": "this is actually tricky because I sort of said, um, okay, this cluster is mainly gold cluster one.",
    "start": "4554400",
    "end": "4560460"
  },
  {
    "text": "So use that as its reference, but that means you have to do a bipartite graph alignment",
    "start": "4560460",
    "end": "4566820"
  },
  {
    "text": "between system clusters, and gold clusters. So hidden in- hidden inside this evaluation,",
    "start": "4566820",
    "end": "4572955"
  },
  {
    "text": "um, system is actually an NP-complete problem. But in practice you can normally do it heuristically well enough,",
    "start": "4572955",
    "end": "4579525"
  },
  {
    "text": "that the evaluation method, um, runs and works. Um, okay.",
    "start": "4579525",
    "end": "4585435"
  },
  {
    "text": "And so the kind of thing to notice is that, if you under cluster, you automatically get great precision,",
    "start": "4585435",
    "end": "4592349"
  },
  {
    "text": "but you get bad recall. And if you over cluster, you get- get great recall because everything that should be in the same cluster is,",
    "start": "4592350",
    "end": "4600405"
  },
  {
    "text": "um, but you get terrible precision. And so what you want to be doing is balancing those two things.",
    "start": "4600405",
    "end": "4608175"
  },
  {
    "text": "Okay. Last two minutes, just to give you some idea of performance.",
    "start": "4608175",
    "end": "4613380"
  },
  {
    "text": "So these are results from the OntoNotes dataset which is about 3,000 documents. Chinese, English, labeled for coreference.",
    "start": "4613380",
    "end": "4621495"
  },
  {
    "text": "Um, the scores I'm reporting is actually an average over three metrics. One of which is the one I just showed you for B-CUBED,",
    "start": "4621495",
    "end": "4629295"
  },
  {
    "text": "um, here are some numbers. Um, so Lee et al 2010 was the Stanford system.",
    "start": "4629295",
    "end": "4637244"
  },
  {
    "text": "So there- there was this shared task evaluation of coreference systems. And we believe that Jerry Hobbs, um,",
    "start": "4637245",
    "end": "4644265"
  },
  {
    "text": "was still right, and you could do fine with rule-based coreference. And so in 2010,",
    "start": "4644265",
    "end": "4650889"
  },
  {
    "text": "we managed to beat all machine learning systems with a rule-based coreference system,",
    "start": "4650890",
    "end": "4656030"
  },
  {
    "text": "and we were proud of it. Um, and that's its performance right here. Um, in subsequent years,",
    "start": "4656030",
    "end": "4662240"
  },
  {
    "text": "people did start to do a bit better, um, with, um, with, uh, machine learning systems.",
    "start": "4662240",
    "end": "4670110"
  },
  {
    "text": "But as you see, not very much, right for these 2012 systems that this one's somewhat,",
    "start": "4670110",
    "end": "4677040"
  },
  {
    "text": "better this one really wasn't better, um, this, um, but making a bit of progress.",
    "start": "4677040",
    "end": "4682335"
  },
  {
    "text": "Starting in 2015, there started to be neural systems.",
    "start": "4682335",
    "end": "4687975"
  },
  {
    "text": "Um, so Wiseman et al was sort of the first neural system, I vaguely mentioned this Clark & Manning system,",
    "start": "4687975",
    "end": "4694245"
  },
  {
    "text": "and the numbers are going up into the mid-sixties. And this is the Kenton Lee system that has the end-to-end neural coreference,",
    "start": "4694245",
    "end": "4701355"
  },
  {
    "text": "and on English is getting about 67. So something you'll notice from this, is the numbers aren't great.",
    "start": "4701355",
    "end": "4708074"
  },
  {
    "text": "So coreference is still far from a solved problem. Um, so if you want to have a bit of fun, um,",
    "start": "4708075",
    "end": "4713790"
  },
  {
    "text": "you can go out and try coreference systems for yourself. Um, there's a Stanford one on the first link or the one from Hugging Face",
    "start": "4713790",
    "end": "4721470"
  },
  {
    "text": "is a good modern coreference system as well. And if you just try these out with some pieces of text,",
    "start": "4721470",
    "end": "4727739"
  },
  {
    "text": "you'll notice they still get lots of things wrong. Um, so there's still more work to do, because this is just a harder language understanding task,",
    "start": "4727740",
    "end": "4735270"
  },
  {
    "text": "[NOISE] which is just kind of like, um, Jerry Hobbs and Terry- Terry Winograd earlier observed.",
    "start": "4735270",
    "end": "4741270"
  },
  {
    "text": "Okay, um, but I'll stop there for now. Thanks a lot. Um, oh yeah, I should have a reminder, invited speaker next Tuesday.",
    "start": "4741270",
    "end": "4749744"
  },
  {
    "text": "Um, so I'll be taking, um, attendance for invited speakers.",
    "start": "4749745",
    "end": "4754720"
  }
]
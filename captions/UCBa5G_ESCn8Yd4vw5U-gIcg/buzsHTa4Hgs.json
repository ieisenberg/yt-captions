[
  {
    "start": "0",
    "end": "56000"
  },
  {
    "text": "So far we discussed node and edge level features,",
    "start": "4000",
    "end": "11080"
  },
  {
    "text": "uh, for a prediction in graphs.",
    "start": "11080",
    "end": "13850"
  },
  {
    "text": "Now, we are going to discuss graph-level features and",
    "start": "13850",
    "end": "17730"
  },
  {
    "text": "graph kernels that are going to- to allow us to make predictions for entire graphs.",
    "start": "17730",
    "end": "23860"
  },
  {
    "text": "So the goal is that we want one",
    "start": "23860",
    "end": "26410"
  },
  {
    "text": "features that characterize the structure of an entire graph.",
    "start": "26410",
    "end": "30325"
  },
  {
    "text": "So for example, if you have a graph like I have here,",
    "start": "30325",
    "end": "33175"
  },
  {
    "text": "we can think about just in words,",
    "start": "33175",
    "end": "34960"
  },
  {
    "text": "how would we describe the structure of this graph,",
    "start": "34960",
    "end": "37270"
  },
  {
    "text": "that it seems it has, kind of,",
    "start": "37270",
    "end": "38815"
  },
  {
    "text": "two loosely connected parts that there are quite a few edges, uh,",
    "start": "38815",
    "end": "42585"
  },
  {
    "text": "ins- between the nodes in each part and that there is",
    "start": "42585",
    "end": "45010"
  },
  {
    "text": "only one edge between these two different parts.",
    "start": "45010",
    "end": "47809"
  },
  {
    "text": "So the question is,",
    "start": "47810",
    "end": "48830"
  },
  {
    "text": "how do we create the feature description- descriptor that will allow us to characterize,",
    "start": "48830",
    "end": "53240"
  },
  {
    "text": "uh, the structure like I just, uh, explained?",
    "start": "53240",
    "end": "56350"
  },
  {
    "start": "56000",
    "end": "168000"
  },
  {
    "text": "And the way we are going to do this,",
    "start": "56350",
    "end": "57914"
  },
  {
    "text": "is we are going to use kernel methods.",
    "start": "57915",
    "end": "60270"
  },
  {
    "text": "And kernel methods are widely used for",
    "start": "60270",
    "end": "62705"
  },
  {
    "text": "traditional machine learning in, uh, graph-level prediction.",
    "start": "62705",
    "end": "66305"
  },
  {
    "text": "And the idea is to design a kernel rather than a feature vector.",
    "start": "66305",
    "end": "70830"
  },
  {
    "text": "So let me tell you what is a kernel and give you a brief introduction.",
    "start": "70830",
    "end": "75000"
  },
  {
    "text": "So a kernel between graphs G,",
    "start": "75000",
    "end": "77460"
  },
  {
    "text": "and G', uh, returns a real value,",
    "start": "77460",
    "end": "80370"
  },
  {
    "text": "and measures a similarity between these two graphs,",
    "start": "80370",
    "end": "83815"
  },
  {
    "text": "or in general, measure similarity between different data points.",
    "start": "83815",
    "end": "87950"
  },
  {
    "text": "Uh, kernel matrix is then a matrix where",
    "start": "87950",
    "end": "91399"
  },
  {
    "text": "simply measures the similarity between all pairs of data points,",
    "start": "91400",
    "end": "95270"
  },
  {
    "text": "or all pairs of graphs.",
    "start": "95270",
    "end": "96865"
  },
  {
    "text": "And for a kernel to be a valid kern- kernel this ma- eh,",
    "start": "96865",
    "end": "100950"
  },
  {
    "text": "kernel matrix, uh, has to be positive semi-definite.",
    "start": "100950",
    "end": "104399"
  },
  {
    "text": "Which means it has to have positive eigenvalues,",
    "start": "104400",
    "end": "107615"
  },
  {
    "text": "for exam- and- and- as a consequence,",
    "start": "107615",
    "end": "109655"
  },
  {
    "text": "it has to be, symet- it is a symmetric, uh, ma- matrix.",
    "start": "109655",
    "end": "114170"
  },
  {
    "text": "And then what is also an important property of kernels,",
    "start": "114170",
    "end": "117439"
  },
  {
    "text": "is that there exist a feature representation, Phi,",
    "start": "117440",
    "end": "120500"
  },
  {
    "text": "such that the kernel between two graphs is simply a feature representation,",
    "start": "120500",
    "end": "126650"
  },
  {
    "text": "uh, wa-, uh, of the first graph dot product",
    "start": "126650",
    "end": "129860"
  },
  {
    "text": "with the feature representation of the second graph, right?",
    "start": "129860",
    "end": "132260"
  },
  {
    "text": "So Phi of G is a vector,",
    "start": "132260",
    "end": "134194"
  },
  {
    "text": "and Phi of G is a- is another vector,",
    "start": "134195",
    "end": "136610"
  },
  {
    "text": "and the value of the kernel is simply a dot product of this vector representation,",
    "start": "136610",
    "end": "142040"
  },
  {
    "text": "uh, of the two, uh, graphs.",
    "start": "142040",
    "end": "144579"
  },
  {
    "text": "Um, and what is sometimes nice in kernels,",
    "start": "144580",
    "end": "147660"
  },
  {
    "text": "is that this feature representation, Phi,",
    "start": "147660",
    "end": "150240"
  },
  {
    "text": "doesn't even need to- to be explicitly created for us to be able to compute the value,",
    "start": "150240",
    "end": "156590"
  },
  {
    "text": "uh, of the kernel.",
    "start": "156590",
    "end": "157849"
  },
  {
    "text": "And once the kernel is defined,",
    "start": "157850",
    "end": "160025"
  },
  {
    "text": "then off-the-shelf machine learning models,",
    "start": "160025",
    "end": "162290"
  },
  {
    "text": "such as kernel support vector machines,",
    "start": "162290",
    "end": "164870"
  },
  {
    "text": "uh, can be used to make, uh, predictions.",
    "start": "164870",
    "end": "168295"
  },
  {
    "start": "168000",
    "end": "205000"
  },
  {
    "text": "So in this le- in this part of the lecture,",
    "start": "168295",
    "end": "171620"
  },
  {
    "text": "we are going to discuss different, uh,",
    "start": "171620",
    "end": "174170"
  },
  {
    "text": "graph kernels, which will allow us to measure similarity between two graphs.",
    "start": "174170",
    "end": "178700"
  },
  {
    "text": "In particular, we are going to discuss",
    "start": "178700",
    "end": "181129"
  },
  {
    "text": "the graphlet kernel as well as Weisfeiler-Lehman kernel.",
    "start": "181130",
    "end": "186125"
  },
  {
    "text": "There are oth- also other kernels that are proposed in the literature,",
    "start": "186125",
    "end": "190400"
  },
  {
    "text": "uh, but this is beyond the scope of the lecture.",
    "start": "190400",
    "end": "192799"
  },
  {
    "text": "For example, random-walk kernel,",
    "start": "192800",
    "end": "194585"
  },
  {
    "text": "shortest-path kernel, uh, and many, uh, others.",
    "start": "194585",
    "end": "198215"
  },
  {
    "text": "And generally, these kernels provide a very competitive performance in graph-level tasks.",
    "start": "198215",
    "end": "205030"
  },
  {
    "start": "205000",
    "end": "356000"
  },
  {
    "text": "So what is the key idea behind kernels?",
    "start": "205030",
    "end": "208635"
  },
  {
    "text": "The key idea in the goal of kernels is to define a feature vector,",
    "start": "208635",
    "end": "213905"
  },
  {
    "text": "Phi of a given graph,",
    "start": "213905",
    "end": "215480"
  },
  {
    "text": "G. And the- the idea is that,",
    "start": "215480",
    "end": "217760"
  },
  {
    "text": "we are going to think of this feature vector, Phi,",
    "start": "217760",
    "end": "220325"
  },
  {
    "text": "as a bag-of-words type representation of a graph.",
    "start": "220325",
    "end": "223765"
  },
  {
    "text": "So what is bag of words?",
    "start": "223765",
    "end": "225720"
  },
  {
    "text": "When we have text documents,",
    "start": "225720",
    "end": "227535"
  },
  {
    "text": "one way how we can represent that text document,",
    "start": "227535",
    "end": "230100"
  },
  {
    "text": "is to simply to represent it as a bag of words.",
    "start": "230100",
    "end": "232980"
  },
  {
    "text": "Where basically, we would say,",
    "start": "232980",
    "end": "234300"
  },
  {
    "text": "for every word we keep a count of how often that word appears in the document.",
    "start": "234300",
    "end": "239060"
  },
  {
    "text": "So we can think of, let's say,",
    "start": "239060",
    "end": "240140"
  },
  {
    "text": "words sorted alphabetically, and then,",
    "start": "240140",
    "end": "242840"
  },
  {
    "text": "you know, at position, i,",
    "start": "242840",
    "end": "245504"
  },
  {
    "text": "of this bag-of-words representation,",
    "start": "245505",
    "end": "247480"
  },
  {
    "text": "we will have the frequency,",
    "start": "247480",
    "end": "248750"
  },
  {
    "text": "the number of occurrences of word,",
    "start": "248750",
    "end": "250430"
  },
  {
    "text": "i, in the document.",
    "start": "250430",
    "end": "252219"
  },
  {
    "text": "So in our- in the same way,",
    "start": "252220",
    "end": "255120"
  },
  {
    "text": "and naive extension of this idea to graphs would be to regard nodes as words.",
    "start": "255120",
    "end": "260495"
  },
  {
    "text": "However, the problem is that since both- since graphs can have very different structure,",
    "start": "260495",
    "end": "265729"
  },
  {
    "text": "but the same number of nodes,",
    "start": "265730",
    "end": "267080"
  },
  {
    "text": "we would get the same feature vector,",
    "start": "267080",
    "end": "269210"
  },
  {
    "text": "or the same representation for two very different graphs, right?",
    "start": "269210",
    "end": "272330"
  },
  {
    "text": "So if we re- regard nodes as words,",
    "start": "272330",
    "end": "275030"
  },
  {
    "text": "then this graph has four nodes,",
    "start": "275030",
    "end": "276800"
  },
  {
    "text": "this graphs has four nodes,",
    "start": "276800",
    "end": "278194"
  },
  {
    "text": "so their representation would be the same.",
    "start": "278195",
    "end": "281090"
  },
  {
    "text": "So we need a different candidate for- for the-",
    "start": "281090",
    "end": "284139"
  },
  {
    "text": "for the word in this kind of bag-of-words representation.",
    "start": "284140",
    "end": "287810"
  },
  {
    "text": "To be, for example, a bit more expressive,",
    "start": "287810",
    "end": "290135"
  },
  {
    "text": "we could have what we could call,",
    "start": "290135",
    "end": "292010"
  },
  {
    "text": "uh, degree kernel, where we could say,",
    "start": "292010",
    "end": "294165"
  },
  {
    "text": "w- how are we going to represent a graph?",
    "start": "294165",
    "end": "296375"
  },
  {
    "text": "We are going to represent it as a bag-of-node degrees, right?",
    "start": "296375",
    "end": "299960"
  },
  {
    "text": "So we say, \"Aha,",
    "start": "299960",
    "end": "301145"
  },
  {
    "text": "we have one node of degree 1,",
    "start": "301145",
    "end": "303319"
  },
  {
    "text": "we have three nodes of degree 2,",
    "start": "303320",
    "end": "308345"
  },
  {
    "text": "and we have 0 nodes of degree, uh, 3.\"",
    "start": "308345",
    "end": "312790"
  },
  {
    "text": "In the same way,",
    "start": "312790",
    "end": "314805"
  },
  {
    "text": "for example, uh, here,",
    "start": "314805",
    "end": "316425"
  },
  {
    "text": "we could be asking,",
    "start": "316425",
    "end": "317590"
  },
  {
    "text": "how many nodes, uh,",
    "start": "317590",
    "end": "319040"
  },
  {
    "text": "of different degrees do we have here?",
    "start": "319040",
    "end": "320585"
  },
  {
    "text": "We have 0 nodes of degree, um, 1,",
    "start": "320585",
    "end": "323630"
  },
  {
    "text": "we have two nodes, uh, of degree 2,",
    "start": "323630",
    "end": "325835"
  },
  {
    "text": "and two nodes, uh, of degree, um, 3.",
    "start": "325835",
    "end": "328810"
  },
  {
    "text": "So, um, and this means that now we would, er,",
    "start": "328810",
    "end": "331570"
  },
  {
    "text": "obtain different feature representations for these,",
    "start": "331570",
    "end": "334770"
  },
  {
    "text": "uh, different, uh, graphs,",
    "start": "334770",
    "end": "336485"
  },
  {
    "text": "and that would allow us to distinguish these different, uh, graphs.",
    "start": "336485",
    "end": "340625"
  },
  {
    "text": "And now, both the graphlets kernel as well as the Weisfeiler-Lehman kernel,",
    "start": "340625",
    "end": "345440"
  },
  {
    "text": "use this idea of bag-of-something representation of a graph where- where the star,",
    "start": "345440",
    "end": "351350"
  },
  {
    "text": "this something is more sophisticated than node degree.",
    "start": "351350",
    "end": "355735"
  },
  {
    "text": "So let's, uh, first talk about the graphlets kernel.",
    "start": "355735",
    "end": "359735"
  },
  {
    "start": "356000",
    "end": "500000"
  },
  {
    "text": "The idea is that writing 1,",
    "start": "359735",
    "end": "361400"
  },
  {
    "text": "I represented the graph as a count of the number of different graphlets in the graph.",
    "start": "361400",
    "end": "366604"
  },
  {
    "text": "Here, I wanna make,",
    "start": "366605",
    "end": "368115"
  },
  {
    "text": "uh, um important point;",
    "start": "368115",
    "end": "370060"
  },
  {
    "text": "the definition of graphlets for a graphlet kernel,",
    "start": "370060",
    "end": "373220"
  },
  {
    "text": "is a bit different than the definition of a graphlet in the node-level features.",
    "start": "373220",
    "end": "378405"
  },
  {
    "text": "And there are two important differences that graphlets in",
    "start": "378405",
    "end": "381800"
  },
  {
    "text": "the node-level features do not need to be connected,",
    "start": "381800",
    "end": "385865"
  },
  {
    "text": "um, and, um also that they are not, uh, uh, rooted.",
    "start": "385865",
    "end": "390470"
  },
  {
    "text": "So graphlets, uh, in this- in the, eh,",
    "start": "390470",
    "end": "393515"
  },
  {
    "text": "graphlets kernel are not rooted,",
    "start": "393515",
    "end": "395990"
  },
  {
    "text": "and don't have to be connected.",
    "start": "395990",
    "end": "397565"
  },
  {
    "text": "And to give you an example,",
    "start": "397565",
    "end": "399394"
  },
  {
    "text": "let me, uh, show you, uh, the next slide.",
    "start": "399394",
    "end": "402740"
  },
  {
    "text": "So for example, if you have a list of graphlets that we are interested",
    "start": "402740",
    "end": "407750"
  },
  {
    "text": "in little g_1 up to the little g_n_k,",
    "start": "407750",
    "end": "412830"
  },
  {
    "text": "let's say these are graphlets of size k,",
    "start": "412830",
    "end": "415055"
  },
  {
    "text": "then let say for k equals 3,",
    "start": "415055",
    "end": "417080"
  },
  {
    "text": "there are four different graphlets, right?",
    "start": "417080",
    "end": "419479"
  },
  {
    "text": "There are four different con- graphs on three nodes,",
    "start": "419480",
    "end": "422885"
  },
  {
    "text": "and directed, fully connected two edges,",
    "start": "422885",
    "end": "425930"
  },
  {
    "text": "one edge, and no edges.",
    "start": "425930",
    "end": "427580"
  },
  {
    "text": "So this is the definition of graphlets in the graph kernel.",
    "start": "427580",
    "end": "430610"
  },
  {
    "text": "And for example, for k equals 4,",
    "start": "430610",
    "end": "433189"
  },
  {
    "text": "that are 11 different graphlets,",
    "start": "433190",
    "end": "435170"
  },
  {
    "text": "fully connected graph all the way to the graph on four nodes without any connections.",
    "start": "435170",
    "end": "441325"
  },
  {
    "text": "And now, uh, given a graph,",
    "start": "441325",
    "end": "443735"
  },
  {
    "text": "we can simply represent it as count of the number of structures,",
    "start": "443735",
    "end": "448055"
  },
  {
    "text": "um, er, different graphlets that appear, uh, in the graph.",
    "start": "448055",
    "end": "451705"
  },
  {
    "text": "So for example, given a graph,",
    "start": "451705",
    "end": "453675"
  },
  {
    "text": "and the graphr- graphlet list,",
    "start": "453675",
    "end": "455669"
  },
  {
    "text": "we define the graphlet count vector f,",
    "start": "455670",
    "end": "458305"
  },
  {
    "text": "simply as the number of instances of a given graphlet that appears,",
    "start": "458305",
    "end": "462875"
  },
  {
    "text": "uh, in our graph of interest.",
    "start": "462875",
    "end": "465185"
  },
  {
    "text": "For example, if these G is our graph of interest,",
    "start": "465185",
    "end": "469220"
  },
  {
    "text": "then in this graph,",
    "start": "469220",
    "end": "470570"
  },
  {
    "text": "there resides one triangle,",
    "start": "470570",
    "end": "473120"
  },
  {
    "text": "there resides three different parts of land 2,",
    "start": "473120",
    "end": "478965"
  },
  {
    "text": "there reside six different edges with an isolated nodes, and there, uh,",
    "start": "478965",
    "end": "484440"
  },
  {
    "text": "exist no, uh, triplet, uh, of nodes,",
    "start": "484440",
    "end": "487800"
  },
  {
    "text": "uh, that are, uh, that are not connected,",
    "start": "487800",
    "end": "490470"
  },
  {
    "text": "uh, in this graph.",
    "start": "490470",
    "end": "491565"
  },
  {
    "text": "So the graphlet feature vector in this case, uh,",
    "start": "491565",
    "end": "494160"
  },
  {
    "text": "would be here, would have ready 1,",
    "start": "494160",
    "end": "496245"
  },
  {
    "text": "3, 6, uh, and 0.",
    "start": "496245",
    "end": "499354"
  },
  {
    "text": "Now, given two graphs,",
    "start": "499355",
    "end": "501925"
  },
  {
    "start": "500000",
    "end": "755000"
  },
  {
    "text": "we can define the graphlet kernel simply as the dot product between the graphlet, uh,",
    "start": "501925",
    "end": "507639"
  },
  {
    "text": "count vector of the first graph times,",
    "start": "507640",
    "end": "510430"
  },
  {
    "text": "uh, the graphlet count vector of the second graph.",
    "start": "510430",
    "end": "513940"
  },
  {
    "text": "Um, this is a good idea,",
    "start": "513940",
    "end": "516385"
  },
  {
    "text": "but actually, there is a slight problem.",
    "start": "516385",
    "end": "518409"
  },
  {
    "text": "The problem is that graphs G1 and G2 may have different sizes,",
    "start": "518410",
    "end": "522789"
  },
  {
    "text": "so the row counts will be very,",
    "start": "522790",
    "end": "525940"
  },
  {
    "text": "uh, different of, uh,",
    "start": "525940",
    "end": "527395"
  },
  {
    "text": "graphlets in different graphs.",
    "start": "527395",
    "end": "528940"
  },
  {
    "text": "So a common solution people apply is to normalize this feature vector representation,",
    "start": "528940",
    "end": "534475"
  },
  {
    "text": "uh, for the graph.",
    "start": "534475",
    "end": "535750"
  },
  {
    "text": "So this means that, um,",
    "start": "535750",
    "end": "537265"
  },
  {
    "text": "the- the graphlet, uh,",
    "start": "537265",
    "end": "539515"
  },
  {
    "text": "vector representation for a given graph is simply the can- the count of",
    "start": "539515",
    "end": "544405"
  },
  {
    "text": "individual graphlets divided by the total number of graphlets that appear in the graph.",
    "start": "544405",
    "end": "549580"
  },
  {
    "text": "So if the- this essentially",
    "start": "549580",
    "end": "551410"
  },
  {
    "text": "normalizes for the size and the density of the underlying graph,",
    "start": "551410",
    "end": "555504"
  },
  {
    "text": "and then the graphlet kernel is defined as the dot product between these,",
    "start": "555505",
    "end": "559585"
  },
  {
    "text": "um, uh, feature vector representations of graphs,",
    "start": "559585",
    "end": "563635"
  },
  {
    "text": "uh, uh, h that capture,",
    "start": "563635",
    "end": "565510"
  },
  {
    "text": "uh, the frequency or the proportion of- of our given graphlet,",
    "start": "565510",
    "end": "570010"
  },
  {
    "text": "um, in a- in a graph.",
    "start": "570010",
    "end": "571780"
  },
  {
    "text": "There is an important limitation of the graphlet graph kernel.",
    "start": "571780",
    "end": "576220"
  },
  {
    "text": "And the limitation is that counting graphlets is very expens- expensive.",
    "start": "576220",
    "end": "581319"
  },
  {
    "text": "Counting a k-size graphlet in a graph with n nodes, uh,",
    "start": "581320",
    "end": "585685"
  },
  {
    "text": "by enumeration takes time or the n raised to the power k. So,",
    "start": "585685",
    "end": "590890"
  },
  {
    "text": "um, this means that counting graphlets of",
    "start": "590890",
    "end": "594670"
  },
  {
    "text": "size k is polynomial in the number of nodes in the graph,",
    "start": "594670",
    "end": "598779"
  },
  {
    "text": "but it is exponential in the graphlet size.",
    "start": "598780",
    "end": "601705"
  },
  {
    "text": "Um, and this is unavoidable in the worse-case",
    "start": "601705",
    "end": "604645"
  },
  {
    "text": "since sub-graph isomorisic- isomorphism judging whether,",
    "start": "604645",
    "end": "608170"
  },
  {
    "text": "uh, a sub-graph is a- is a, uh,",
    "start": "608170",
    "end": "611154"
  },
  {
    "text": "isomorphic to another, uh,",
    "start": "611155",
    "end": "612655"
  },
  {
    "text": "graph, is, uh, NP-hard.",
    "start": "612655",
    "end": "614320"
  },
  {
    "text": "Um, and, uh, there are faster algorithms if,",
    "start": "614320",
    "end": "617890"
  },
  {
    "text": "uh, graphs node, uh,",
    "start": "617890",
    "end": "619180"
  },
  {
    "text": "node degree is bounded by d,",
    "start": "619180",
    "end": "621190"
  },
  {
    "text": "then there exist a fa- faster algorithm to count the graphlets of size k. However,",
    "start": "621190",
    "end": "626515"
  },
  {
    "text": "the issue still remains that counting",
    "start": "626515",
    "end": "628870"
  },
  {
    "text": "these discrete structures in a graph is very time consuming, um, very expensive.",
    "start": "628870",
    "end": "633910"
  },
  {
    "text": "So we can only count graphlets up to,",
    "start": "633910",
    "end": "636399"
  },
  {
    "text": "uh, you know, uh,",
    "start": "636400",
    "end": "637870"
  },
  {
    "text": "a handful of nodes.",
    "start": "637870",
    "end": "639040"
  },
  {
    "text": "And then the- and then the exponential complexity takes over and we cannot count,",
    "start": "639040",
    "end": "644665"
  },
  {
    "text": "uh, graphlets, uh, that are,",
    "start": "644665",
    "end": "646240"
  },
  {
    "text": "uh, larger than that.",
    "start": "646240",
    "end": "647959"
  },
  {
    "text": "Um, so the question is,",
    "start": "647960",
    "end": "650370"
  },
  {
    "text": "how do we design a more efficient graph kernel?",
    "start": "650370",
    "end": "653225"
  },
  {
    "text": "Um, and Weisfeiler-Lehman graph kernel, uh, achieves this goal.",
    "start": "653225",
    "end": "657415"
  },
  {
    "text": "The goal here is to design an efficient graph feature descriptor Phi of G, uh,",
    "start": "657415",
    "end": "662259"
  },
  {
    "text": "where the idea is that we wanna use a neighborhood structure to iteratively enrich,",
    "start": "662260",
    "end": "666940"
  },
  {
    "text": "uh, node, uh, vocabulary.",
    "start": "666940",
    "end": "669295"
  },
  {
    "text": "And, um, we generalize a version of node degrees since node degrees are",
    "start": "669295",
    "end": "674230"
  },
  {
    "text": "one hot- one-hop neighborhood information to multi-hop neighborhood information.",
    "start": "674230",
    "end": "679704"
  },
  {
    "text": "And the algorithm that achieves this is, uh, uh,",
    "start": "679705",
    "end": "683485"
  },
  {
    "text": "called the Weisfeiler-Lehman graph isomorphism test,",
    "start": "683485",
    "end": "686920"
  },
  {
    "text": "or also known as color refinement.",
    "start": "686920",
    "end": "689800"
  },
  {
    "text": "So, uh, let me explain, uh, this next.",
    "start": "689800",
    "end": "692964"
  },
  {
    "text": "So the idea is that we are given a graph G with a set of nodes V,",
    "start": "692965",
    "end": "698200"
  },
  {
    "text": "and we're going to assign an initial color,",
    "start": "698200",
    "end": "700660"
  },
  {
    "text": "um, c^0, so this is an initial color to each node.",
    "start": "700660",
    "end": "705790"
  },
  {
    "text": "And then we are going to iteratively, er,",
    "start": "705790",
    "end": "708220"
  },
  {
    "text": "aggregate or hash colors from the neighbors to invent new colors.",
    "start": "708220",
    "end": "713004"
  },
  {
    "text": "So the way to think of this, uh,",
    "start": "713005",
    "end": "714880"
  },
  {
    "text": "the new color for a given node v will be a hashed value of its own color, um,",
    "start": "714880",
    "end": "720640"
  },
  {
    "text": "from the previous time step and a concatenation",
    "start": "720640",
    "end": "725395"
  },
  {
    "text": "of colors coming from the neighbors u of the node v of interest,",
    "start": "725395",
    "end": "730510"
  },
  {
    "text": "where hash is basically a hash functions that",
    "start": "730510",
    "end": "733660"
  },
  {
    "text": "maps different inputs into different, uh, colors.",
    "start": "733660",
    "end": "737185"
  },
  {
    "text": "And after k steps of this color refinement,",
    "start": "737185",
    "end": "740755"
  },
  {
    "text": "um, um, c, uh,",
    "start": "740755",
    "end": "742795"
  },
  {
    "text": "capital v of, uh,",
    "start": "742795",
    "end": "744325"
  },
  {
    "text": "capital K of v summarizes the structure, uh,",
    "start": "744325",
    "end": "747700"
  },
  {
    "text": "of the graph, uh, at the level of,",
    "start": "747700",
    "end": "750190"
  },
  {
    "text": "uh, K-hop, uh, neighborhood.",
    "start": "750190",
    "end": "752080"
  },
  {
    "text": "So let me, um, give you an example, uh, and explain.",
    "start": "752080",
    "end": "755440"
  },
  {
    "start": "755000",
    "end": "913000"
  },
  {
    "text": "So for example, here I have two, uh,",
    "start": "755440",
    "end": "758110"
  },
  {
    "text": "graphs that have very similar structure but are just slightly, uh, different.",
    "start": "758110",
    "end": "762579"
  },
  {
    "text": "The difference is, uh, this, uh,",
    "start": "762580",
    "end": "764485"
  },
  {
    "text": "edge and here, um, the- the, uh,",
    "start": "764485",
    "end": "766885"
  },
  {
    "text": "the diagonal edge, the triangle closing edge,",
    "start": "766885",
    "end": "769945"
  },
  {
    "text": "um, um, is, uh, different.",
    "start": "769945",
    "end": "772530"
  },
  {
    "text": "So first we are going to assign initial colors to nodes.",
    "start": "772530",
    "end": "775380"
  },
  {
    "text": "So every node gets the same color,",
    "start": "775380",
    "end": "777045"
  },
  {
    "text": "every node gets a color of one.",
    "start": "777045",
    "end": "779470"
  },
  {
    "text": "Now we are going to aggregate neighboring colors.",
    "start": "779470",
    "end": "782589"
  },
  {
    "text": "For example, this particular node aggregate colors 1,1,",
    "start": "782590",
    "end": "786325"
  },
  {
    "text": "1, um, and, uh,",
    "start": "786325",
    "end": "787945"
  },
  {
    "text": "adds it to it- to itself,",
    "start": "787945",
    "end": "789595"
  },
  {
    "text": "while this particular node up here aggregates colors from its neighbors,",
    "start": "789595",
    "end": "793990"
  },
  {
    "text": "one and one, uh, and it is here.",
    "start": "793990",
    "end": "796315"
  },
  {
    "text": "And the same process, uh,",
    "start": "796315",
    "end": "797785"
  },
  {
    "text": "happens in this second,",
    "start": "797785",
    "end": "799870"
  },
  {
    "text": "uh, graphs- graph as well.",
    "start": "799870",
    "end": "801505"
  },
  {
    "text": "Now that, um, we have collected the colors,",
    "start": "801505",
    "end": "804520"
  },
  {
    "text": "uh, we go, uh,",
    "start": "804520",
    "end": "806065"
  },
  {
    "text": "and hash them, right?",
    "start": "806065",
    "end": "807460"
  },
  {
    "text": "So we apply a hash- hash function that takes",
    "start": "807460",
    "end": "810445"
  },
  {
    "text": "nodes' own color plus the colors from neighbors and produces new colors.",
    "start": "810445",
    "end": "815350"
  },
  {
    "text": "And let's say here the hash function for the first combination returns one,",
    "start": "815350",
    "end": "819639"
  },
  {
    "text": "then two, then three, uh, four, and five.",
    "start": "819640",
    "end": "821920"
  },
  {
    "text": "So now we color the graphs,",
    "start": "821920",
    "end": "824185"
  },
  {
    "text": "uh, based on these new refined colors, right?",
    "start": "824185",
    "end": "826750"
  },
  {
    "text": "So this is the coloring of the first graph,",
    "start": "826750",
    "end": "828880"
  },
  {
    "text": "and this is the coloring of the second graph based on the hash values",
    "start": "828880",
    "end": "832495"
  },
  {
    "text": "of the- of the aggregated colors from the first step.",
    "start": "832495",
    "end": "836815"
  },
  {
    "text": "Now we take these two graphs and,",
    "start": "836815",
    "end": "839815"
  },
  {
    "text": "again, apply the same color aggregation scheme, right?",
    "start": "839815",
    "end": "842920"
  },
  {
    "text": "So for example, this node, uh,",
    "start": "842920",
    "end": "844855"
  },
  {
    "text": "with color 4 aggregates colors from its neighbors,",
    "start": "844855",
    "end": "848019"
  },
  {
    "text": "so aggregates the 3, 4, and 5.",
    "start": "848020",
    "end": "850750"
  },
  {
    "text": "So we have 3, 4, and 5 here, while, for example,",
    "start": "850750",
    "end": "853900"
  },
  {
    "text": "this node here of color 2 aggregates from its neighbor,",
    "start": "853900",
    "end": "857230"
  },
  {
    "text": "uh, that is colored 5,",
    "start": "857230",
    "end": "858790"
  },
  {
    "text": "so it gets 2, 5.",
    "start": "858790",
    "end": "860485"
  },
  {
    "text": "And again, for this graph,",
    "start": "860485",
    "end": "862120"
  },
  {
    "text": "the same process happens.",
    "start": "862120",
    "end": "864339"
  },
  {
    "text": "Now, again, we take, um, uh, this,",
    "start": "864340",
    "end": "867250"
  },
  {
    "text": "uh, aggregated colors, um, and we hash them.",
    "start": "867250",
    "end": "870460"
  },
  {
    "text": "And let's say our hash function, uh,",
    "start": "870460",
    "end": "873160"
  },
  {
    "text": "assigns different, uh, new colors, uh,",
    "start": "873160",
    "end": "876100"
  },
  {
    "text": "to, uh, to this,",
    "start": "876100",
    "end": "877569"
  },
  {
    "text": "uh, colors that are,",
    "start": "877570",
    "end": "878860"
  },
  {
    "text": "uh, combined aggregated from the previous timesteps.",
    "start": "878860",
    "end": "881829"
  },
  {
    "text": "So now we can take this, uh, original, uh,",
    "start": "881830",
    "end": "884605"
  },
  {
    "text": "aggregated colored graph and,",
    "start": "884605",
    "end": "886930"
  },
  {
    "text": "uh, relabel the colors based on the hash value.",
    "start": "886930",
    "end": "889390"
  },
  {
    "text": "So 4,345, uh, 4, um,",
    "start": "889390",
    "end": "892840"
  },
  {
    "text": "er, where is, uh, er, uh,",
    "start": "892840",
    "end": "896800"
  },
  {
    "text": "34- uh, 345- um, is, um,",
    "start": "896800",
    "end": "900100"
  },
  {
    "text": "layer hashes into color 10s,",
    "start": "900100",
    "end": "902319"
  },
  {
    "text": "so we replace a color 10, uh, here.",
    "start": "902320",
    "end": "905035"
  },
  {
    "text": "And we could keep iterating this and we would come up, uh, with, uh,",
    "start": "905035",
    "end": "909160"
  },
  {
    "text": "more and more, uh, refinement,",
    "start": "909160",
    "end": "911230"
  },
  {
    "text": "uh, of the, uh,",
    "start": "911230",
    "end": "912370"
  },
  {
    "text": "uh, colors of the graph.",
    "start": "912370",
    "end": "913975"
  },
  {
    "start": "913000",
    "end": "992000"
  },
  {
    "text": "So now that we have run this color refinement for a,",
    "start": "913975",
    "end": "917139"
  },
  {
    "text": "uh, a fixed number of steps,",
    "start": "917140",
    "end": "918850"
  },
  {
    "text": "let say k iterations,",
    "start": "918850",
    "end": "920680"
  },
  {
    "text": "the Weisfeiler-Lehman, uh, kernel counts number of nodes with a given color.",
    "start": "920680",
    "end": "926170"
  },
  {
    "text": "So in our case,",
    "start": "926170",
    "end": "927279"
  },
  {
    "text": "we run- we run this three times,",
    "start": "927280",
    "end": "929035"
  },
  {
    "text": "so we have 13 different colors.. And now",
    "start": "929035",
    "end": "932259"
  },
  {
    "text": "the feature description for a given graph is simply the count,",
    "start": "932260",
    "end": "936055"
  },
  {
    "text": "the number of nodes of a given color, right?",
    "start": "936055",
    "end": "937990"
  },
  {
    "text": "In the first iteration,",
    "start": "937990",
    "end": "939130"
  },
  {
    "text": "uh, all the nodes were colored,",
    "start": "939130",
    "end": "940720"
  },
  {
    "text": "um- all six nodes were colored the same one- uh, the same way.",
    "start": "940720",
    "end": "944245"
  },
  {
    "text": "Um, so there is six instances of color 1.",
    "start": "944245",
    "end": "946915"
  },
  {
    "text": "Then, um, after we iter- um,",
    "start": "946915",
    "end": "949495"
  },
  {
    "text": "agg- aggregated the colors and refined them, you know,",
    "start": "949495",
    "end": "952480"
  },
  {
    "text": "there were two nodes of color 2,",
    "start": "952480",
    "end": "954399"
  },
  {
    "text": "one node of color 3,",
    "start": "954400",
    "end": "955810"
  },
  {
    "text": "two nodes of color 4, um, and so on.",
    "start": "955810",
    "end": "958210"
  },
  {
    "text": "So here is now the feature description in terms of color counts, uh, for, uh,",
    "start": "958210",
    "end": "963145"
  },
  {
    "text": "for, uh, different colors for the first graph and different colors,",
    "start": "963145",
    "end": "967390"
  },
  {
    "text": "uh, for the second graph.",
    "start": "967390",
    "end": "969400"
  },
  {
    "text": "So now that we have the feature descriptions,",
    "start": "969400",
    "end": "972085"
  },
  {
    "text": "the Weisfeiler-Lehman graph kernel would simply take the dot product between these two,",
    "start": "972085",
    "end": "977035"
  },
  {
    "text": "uh, uh, feature descriptors and return a value.",
    "start": "977035",
    "end": "979569"
  },
  {
    "text": "So for example, in our case,",
    "start": "979570",
    "end": "981220"
  },
  {
    "text": "the si- the, uh, Weisfeiler-Lehman, uh,",
    "start": "981220",
    "end": "983875"
  },
  {
    "text": "kernel similarity between the two graphs is the dot product between the,",
    "start": "983875",
    "end": "987580"
  },
  {
    "text": "uh, feature descriptors, uh, here.",
    "start": "987580",
    "end": "989890"
  },
  {
    "text": "These are the two, uh,",
    "start": "989890",
    "end": "991030"
  },
  {
    "text": "feature descriptors and we compute the dot product,",
    "start": "991030",
    "end": "993520"
  },
  {
    "start": "992000",
    "end": "1065000"
  },
  {
    "text": "we would get a value of, uh, 49.",
    "start": "993520",
    "end": "996910"
  },
  {
    "text": "So WL kernel is very popular and very strong,",
    "start": "996910",
    "end": "1001089"
  },
  {
    "text": "uh, gives strong performance,",
    "start": "1001090",
    "end": "1002945"
  },
  {
    "text": "and it is also computationally efficient because the time complexity of",
    "start": "1002945",
    "end": "1007300"
  },
  {
    "text": "this color refinement at each step is linear in the size of the graph.",
    "start": "1007300",
    "end": "1011760"
  },
  {
    "text": "It is linear in the number of edges because all that",
    "start": "1011760",
    "end": "1015070"
  },
  {
    "text": "every node has to do is collect the colors, uh, from its, uh,",
    "start": "1015070",
    "end": "1018700"
  },
  {
    "text": "neighboring nodes and- and produce- and apply",
    "start": "1018700",
    "end": "1021580"
  },
  {
    "text": "a simple hash function to- to come up with a new,",
    "start": "1021580",
    "end": "1025579"
  },
  {
    "text": "um, uh, with a new, uh, color.",
    "start": "1025580",
    "end": "1028084"
  },
  {
    "text": "When computing the kernel value,",
    "start": "1028085",
    "end": "1030130"
  },
  {
    "text": "many colors, uh, appeared in two graphs need to be tracked.",
    "start": "1030130",
    "end": "1034885"
  },
  {
    "text": "So the number of colors will be at most the number of nodes,",
    "start": "1034885",
    "end": "1038910"
  },
  {
    "text": "uh, in the network.",
    "start": "1038910",
    "end": "1040060"
  },
  {
    "text": "So this again won't be too- too large.",
    "start": "1040060",
    "end": "1042280"
  },
  {
    "text": "And counting the colors again takes linear time because it's just a sweep over the nodes.",
    "start": "1042280",
    "end": "1047410"
  },
  {
    "text": "So the- the total complexity, uh,",
    "start": "1047410",
    "end": "1050545"
  },
  {
    "text": "of computing the Weisfeiler-Lehman graph kernel between a pair of, uh,",
    "start": "1050545",
    "end": "1054700"
  },
  {
    "text": "graphs is simply linear in the number of edges in the two graphs.",
    "start": "1054700",
    "end": "1058885"
  },
  {
    "text": "So this means this is extremely, uh,",
    "start": "1058885",
    "end": "1061240"
  },
  {
    "text": "fast and actually works,",
    "start": "1061240",
    "end": "1063309"
  },
  {
    "text": "uh, really well in practice.",
    "start": "1063310",
    "end": "1065165"
  },
  {
    "start": "1065000",
    "end": "1147000"
  },
  {
    "text": "So to summarize the graph level features that we have discussed,",
    "start": "1065165",
    "end": "1069550"
  },
  {
    "text": "first we talked about, uh,",
    "start": "1069550",
    "end": "1071320"
  },
  {
    "text": "the notion of graph kernels,",
    "start": "1071320",
    "end": "1072940"
  },
  {
    "text": "where basically graph is represented as a bag of graphlets or a bag of, uh, colors.",
    "start": "1072940",
    "end": "1079389"
  },
  {
    "text": "Um, and, uh, when we represent the graph as a graph- uh,",
    "start": "1079390",
    "end": "1082720"
  },
  {
    "text": "as a bag of graphlets,",
    "start": "1082720",
    "end": "1084355"
  },
  {
    "text": "this is extremely- this is very expensive representation because counting the graphlets,",
    "start": "1084355",
    "end": "1090080"
  },
  {
    "text": "uh, takes time exponential in the size of the graph.",
    "start": "1090080",
    "end": "1094404"
  },
  {
    "text": "At the same time, Weisfeiler-Lehman, uh,",
    "start": "1094405",
    "end": "1097505"
  },
  {
    "text": "kernel is based on this case step color refinement algorithm that",
    "start": "1097505",
    "end": "1102430"
  },
  {
    "text": "enriches and produces new node colors that are aggregated from the,",
    "start": "1102430",
    "end": "1107470"
  },
  {
    "text": "um, colors of the immediate neighbors of the node.",
    "start": "1107470",
    "end": "1110890"
  },
  {
    "text": "And as multiple rounds of this color refinement are run,",
    "start": "1110890",
    "end": "1114775"
  },
  {
    "text": "the node kind of gathers color information from farther away,",
    "start": "1114775",
    "end": "1118530"
  },
  {
    "text": "uh, parts of the network.",
    "start": "1118530",
    "end": "1119940"
  },
  {
    "text": "So here we represent the graph as a bag of colors.",
    "start": "1119940",
    "end": "1123284"
  },
  {
    "text": "This is computationally efficient.",
    "start": "1123285",
    "end": "1125145"
  },
  {
    "text": "The time is linear in the size of the graph, um,",
    "start": "1125145",
    "end": "1128290"
  },
  {
    "text": "and it is also closely related to graph neural networks that we are going to study,",
    "start": "1128290",
    "end": "1134220"
  },
  {
    "text": "uh, later in this course.",
    "start": "1134220",
    "end": "1135809"
  },
  {
    "text": "So, um, Weisfeiler-Lehman is a really, uh,",
    "start": "1135810",
    "end": "1139260"
  },
  {
    "text": "good way to measure similarity, um,",
    "start": "1139260",
    "end": "1141890"
  },
  {
    "text": "between graphs, and in many cases,",
    "start": "1141890",
    "end": "1144040"
  },
  {
    "text": "it is, uh, very hard to beat.",
    "start": "1144040",
    "end": "1146440"
  },
  {
    "text": "So this concludes the today lecture where we talked about, um,",
    "start": "1146440",
    "end": "1151360"
  },
  {
    "start": "1147000",
    "end": "1210000"
  },
  {
    "text": "three different, uh, approaches to traditional,",
    "start": "1151360",
    "end": "1154929"
  },
  {
    "text": "uh, graph, uh, level, um, machine learning.",
    "start": "1154930",
    "end": "1158095"
  },
  {
    "text": "We talked about, um, handcrafted features for node-level prediction,",
    "start": "1158095",
    "end": "1163190"
  },
  {
    "text": "uh, in terms of node degree,",
    "start": "1163190",
    "end": "1164669"
  },
  {
    "text": "centrality, clustering, coefficient, and graphlets.",
    "start": "1164670",
    "end": "1167465"
  },
  {
    "text": "We talked about link-level or edge-level features,",
    "start": "1167465",
    "end": "1171409"
  },
  {
    "text": "distance-based, as well as local and global neighborhood overlap.",
    "start": "1171410",
    "end": "1175105"
  },
  {
    "text": "And then last we'd talk about how do we characterize the structure of the entire graph.",
    "start": "1175105",
    "end": "1179785"
  },
  {
    "text": "We talked about graph kernels, uh,",
    "start": "1179785",
    "end": "1181920"
  },
  {
    "text": "and in particular about graphlet kernel and the WL,",
    "start": "1181920",
    "end": "1185730"
  },
  {
    "text": "meaning Weisfeiler-Lehman graph kernel.",
    "start": "1185730",
    "end": "1189450"
  },
  {
    "text": "So this concludes our discussion of traditional machine learning approaches, uh,",
    "start": "1189450",
    "end": "1194590"
  },
  {
    "text": "to graphs and how do we create feature vectors from nodes, links, um,",
    "start": "1194590",
    "end": "1199390"
  },
  {
    "text": "and graphs, um, in a- in a scalable and interesting way. Uh, thank you very much.",
    "start": "1199390",
    "end": "1205670"
  }
]
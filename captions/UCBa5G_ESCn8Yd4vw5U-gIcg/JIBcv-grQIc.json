[
  {
    "start": "0",
    "end": "4920"
  },
  {
    "text": "BILL MACCARTNEY: Last\ntime I introduced",
    "start": "4920",
    "end": "6900"
  },
  {
    "text": "the task of relation\nextraction, I",
    "start": "6900",
    "end": "10020"
  },
  {
    "text": "described the corpus and the\nKB that we're going to use.",
    "start": "10020",
    "end": "13860"
  },
  {
    "text": "And I proposed a\nprecise formulation",
    "start": "13860",
    "end": "16770"
  },
  {
    "text": "of our prediction problem.",
    "start": "16770",
    "end": "19090"
  },
  {
    "text": "So now, let's talk about how\nwe're going to measure success",
    "start": "19090",
    "end": "22230"
  },
  {
    "text": "on this problem.",
    "start": "22230",
    "end": "23650"
  },
  {
    "text": "We need to define a\nquantitative evaluation that",
    "start": "23650",
    "end": "26939"
  },
  {
    "text": "can drive a process of\niterative development.",
    "start": "26940",
    "end": "31572"
  },
  {
    "text": "In this section, I'm going\nto first make a connection",
    "start": "31572",
    "end": "33780"
  },
  {
    "text": "to the software\nengineering principle",
    "start": "33780",
    "end": "35879"
  },
  {
    "text": "of test-driven development.",
    "start": "35880",
    "end": "38370"
  },
  {
    "text": "Then I'm going to\nexplain how we'll",
    "start": "38370",
    "end": "40559"
  },
  {
    "text": "split our data into training\nand evaluation data.",
    "start": "40560",
    "end": "44070"
  },
  {
    "text": "I'll do a brief refresher\non precision, recall,",
    "start": "44070",
    "end": "48090"
  },
  {
    "text": "and F-measure.",
    "start": "48090",
    "end": "50040"
  },
  {
    "text": "And I'll review the distinction\nbetween micro-averaging",
    "start": "50040",
    "end": "52500"
  },
  {
    "text": "and macro-averaging.",
    "start": "52500",
    "end": "54180"
  },
  {
    "text": "And by the end, we'll\nknow exactly how",
    "start": "54180",
    "end": "55903"
  },
  {
    "text": "we're going to measure success.",
    "start": "55903",
    "end": "57195"
  },
  {
    "start": "57195",
    "end": "60050"
  },
  {
    "text": "When you start working on a\nnew machine learning problem,",
    "start": "60050",
    "end": "62640"
  },
  {
    "text": "it's very tempting to jump in\nand start building models right",
    "start": "62640",
    "end": "67620"
  },
  {
    "text": "away.",
    "start": "67620",
    "end": "68120"
  },
  {
    "text": "Because you're\nbursting with ideas,",
    "start": "68120",
    "end": "70490"
  },
  {
    "text": "and you can't wait\nto get started.",
    "start": "70490",
    "end": "72740"
  },
  {
    "text": "But whoa, Nelly.",
    "start": "72740",
    "end": "74720"
  },
  {
    "text": "That's like driving\ncross-country without a map.",
    "start": "74720",
    "end": "78410"
  },
  {
    "text": "There's going to be lots\nof forks in the road,",
    "start": "78410",
    "end": "80690"
  },
  {
    "text": "and you won't know\nwhich way to go.",
    "start": "80690",
    "end": "83250"
  },
  {
    "text": "There's a better way.",
    "start": "83250",
    "end": "85490"
  },
  {
    "text": "In software engineering, we\nuse test-driven development.",
    "start": "85490",
    "end": "89210"
  },
  {
    "text": "First, write the tests,\nand then write code",
    "start": "89210",
    "end": "93619"
  },
  {
    "text": "and iterate until\nit passes the tests.",
    "start": "93620",
    "end": "97070"
  },
  {
    "text": "In model engineering, we\ncan use a similar paradigm.",
    "start": "97070",
    "end": "100100"
  },
  {
    "text": "First, implement a\nquantitative evaluation.",
    "start": "100100",
    "end": "103310"
  },
  {
    "text": "Specify your evaluation dataset,\nchoose your evaluation metric,",
    "start": "103310",
    "end": "107720"
  },
  {
    "text": "build a test harness that takes\na model and generates a score.",
    "start": "107720",
    "end": "113000"
  },
  {
    "text": "Then when you start\nbuilding models,",
    "start": "113000",
    "end": "115310"
  },
  {
    "text": "you can hill-climb\non this score.",
    "start": "115310",
    "end": "117500"
  },
  {
    "text": "And at those forks\nin the road where",
    "start": "117500",
    "end": "119330"
  },
  {
    "text": "you could do it this\nway or that way,",
    "start": "119330",
    "end": "121910"
  },
  {
    "text": "your quantitative evaluation\nwill tell you which way to go.",
    "start": "121910",
    "end": "125210"
  },
  {
    "start": "125210",
    "end": "128091"
  },
  {
    "text": "Now, whenever we build\na model from data,",
    "start": "128092",
    "end": "129799"
  },
  {
    "text": "it's good practice\nto partition the data",
    "start": "129800",
    "end": "132530"
  },
  {
    "text": "into multiple splits, minimally,\na training split and a test",
    "start": "132530",
    "end": "137390"
  },
  {
    "text": "split.",
    "start": "137390",
    "end": "139010"
  },
  {
    "text": "Actually, here we'll\ngo a bit further,",
    "start": "139010",
    "end": "140870"
  },
  {
    "text": "and we'll define\nmultiple splits.",
    "start": "140870",
    "end": "143239"
  },
  {
    "text": "First, we'll have a tiny split\nwith just 1% of the data.",
    "start": "143240",
    "end": "148370"
  },
  {
    "text": "Having a tiny split\nis super useful,",
    "start": "148370",
    "end": "150890"
  },
  {
    "text": "and I encourage you to adopt\nthis practice whenever you",
    "start": "150890",
    "end": "154040"
  },
  {
    "text": "take on our prediction problem.",
    "start": "154040",
    "end": "156019"
  },
  {
    "text": "During the early\nstages of development,",
    "start": "156020",
    "end": "158240"
  },
  {
    "text": "you can use the tiny split\nas training data or test",
    "start": "158240",
    "end": "162110"
  },
  {
    "text": "data or both, and\nyour experiments",
    "start": "162110",
    "end": "164780"
  },
  {
    "text": "will run super fast.",
    "start": "164780",
    "end": "167459"
  },
  {
    "text": "Of course, your\nquantitative evaluations",
    "start": "167460",
    "end": "169970"
  },
  {
    "text": "will be pretty much\nmeaningless, but it's",
    "start": "169970",
    "end": "172190"
  },
  {
    "text": "a great way to quickly flush\nout any bugs in your setup.",
    "start": "172190",
    "end": "177180"
  },
  {
    "text": "Then we'll have the train\nsplit with 74% of the data.",
    "start": "177180",
    "end": "180310"
  },
  {
    "text": "This is the data that we'll\nusually use for model training.",
    "start": "180310",
    "end": "184020"
  },
  {
    "text": "Then the dev split,\nwith 25% of the data.",
    "start": "184020",
    "end": "188050"
  },
  {
    "text": "We'll use this as test data\nfor intermediate evaluations",
    "start": "188050",
    "end": "191655"
  },
  {
    "text": "during the development.",
    "start": "191655",
    "end": "193947"
  },
  {
    "text": "And for the bake-off, we're also\ngoing to have a separate test",
    "start": "193947",
    "end": "196530"
  },
  {
    "text": "split, but you won't\nhave access to it,",
    "start": "196530",
    "end": "198940"
  },
  {
    "text": "so we won't talk about it here.",
    "start": "198940",
    "end": "202210"
  },
  {
    "text": "There's one complication.",
    "start": "202210",
    "end": "203470"
  },
  {
    "text": "We need to split both\nthe corpus and the KB.",
    "start": "203470",
    "end": "207520"
  },
  {
    "text": "We want each relation to\nappear in both the training",
    "start": "207520",
    "end": "210730"
  },
  {
    "text": "data and the test data so that\nwe can assess how well we've",
    "start": "210730",
    "end": "214180"
  },
  {
    "text": "learned how each relation is\nexpressed in natural language.",
    "start": "214180",
    "end": "219019"
  },
  {
    "text": "But ideally, we'd like to\nhave any given entity appear",
    "start": "219020",
    "end": "222640"
  },
  {
    "text": "in only one split.",
    "start": "222640",
    "end": "224510"
  },
  {
    "text": "Otherwise, we might be leaking\ninformation from the training",
    "start": "224510",
    "end": "227319"
  },
  {
    "text": "data into the test data.",
    "start": "227320",
    "end": "230970"
  },
  {
    "text": "In an ideal world,\neach split would",
    "start": "230970",
    "end": "233010"
  },
  {
    "text": "have its own hermetically\nsealed universe of entities,",
    "start": "233010",
    "end": "236670"
  },
  {
    "text": "and both the corpus and\nthe KB, for that split,",
    "start": "236670",
    "end": "239940"
  },
  {
    "text": "would refer only\nto those entities.",
    "start": "239940",
    "end": "242290"
  },
  {
    "text": "So for example, you might have a\nnew world corpus whose examples",
    "start": "242290",
    "end": "245400"
  },
  {
    "text": "mention only new world\nentities like Elon Musk",
    "start": "245400",
    "end": "248579"
  },
  {
    "text": "and Bill Gates and Steve Jobs,\nand a new world KB, which",
    "start": "248580",
    "end": "253380"
  },
  {
    "text": "contains only triples about\nthe same new world entities,",
    "start": "253380",
    "end": "258410"
  },
  {
    "text": "and then an old world\ncorpus that talks",
    "start": "258410",
    "end": "261260"
  },
  {
    "text": "about Daniel Ek and\nJack Ma and Pony",
    "start": "261260",
    "end": "263570"
  },
  {
    "text": "Ma and a corresponding\nold world KB.",
    "start": "263570",
    "end": "268540"
  },
  {
    "text": "If we had this, then\nwe could achieve",
    "start": "268540",
    "end": "270160"
  },
  {
    "text": "a really clean separation\nbetween train and test data",
    "start": "270160",
    "end": "274480"
  },
  {
    "text": "with no overlap in entities.",
    "start": "274480",
    "end": "278590"
  },
  {
    "text": "But in practice, the world\nis strongly entangled,",
    "start": "278590",
    "end": "281080"
  },
  {
    "text": "and this ideal is\nhard to achieve.",
    "start": "281080",
    "end": "284120"
  },
  {
    "text": "So instead, we're going\nto approximate the ideal.",
    "start": "284120",
    "end": "287440"
  },
  {
    "text": "I think I won't\ndwell on the details,",
    "start": "287440",
    "end": "289270"
  },
  {
    "text": "but we've written\nthe code for you",
    "start": "289270",
    "end": "291190"
  },
  {
    "text": "to achieve a good enough split.",
    "start": "291190",
    "end": "294230"
  },
  {
    "text": "In particular, the\ndataset class provides",
    "start": "294230",
    "end": "296180"
  },
  {
    "text": "a method called\nbuild_splits which",
    "start": "296180",
    "end": "298580"
  },
  {
    "text": "lets you specify split names and\nproportions and a random seed.",
    "start": "298580",
    "end": "304939"
  },
  {
    "text": "And it just returns a map from\nsplit names to datasets each",
    "start": "304940",
    "end": "310310"
  },
  {
    "text": "containing a corpus and a KB.",
    "start": "310310",
    "end": "314400"
  },
  {
    "text": "So now that we\nhave our splits, we",
    "start": "314400",
    "end": "315889"
  },
  {
    "text": "need to choose an\nevaluation metric.",
    "start": "315890",
    "end": "318500"
  },
  {
    "text": "We've formulated our problem\nas binary classification,",
    "start": "318500",
    "end": "321770"
  },
  {
    "text": "and the standard metrics\nfor binary classification",
    "start": "321770",
    "end": "324229"
  },
  {
    "text": "are precision and recall.",
    "start": "324230",
    "end": "326360"
  },
  {
    "text": "So here's an example where we\nhave 100 problem instances.",
    "start": "326360",
    "end": "330800"
  },
  {
    "text": "The rows of this table\nrepresent the actual labels.",
    "start": "330800",
    "end": "334310"
  },
  {
    "text": "88 are labeled false, and\nonly 12 are labeled true.",
    "start": "334310",
    "end": "338730"
  },
  {
    "text": "So this is a skewed\ndistribution.",
    "start": "338730",
    "end": "341760"
  },
  {
    "text": "The columns of this table\nrepresent the labels",
    "start": "341760",
    "end": "344450"
  },
  {
    "text": "predicted by our model.",
    "start": "344450",
    "end": "346110"
  },
  {
    "text": "So 95 are predicted to\nbe false and 5 true.",
    "start": "346110",
    "end": "350930"
  },
  {
    "text": "Now, there are 89 instances\nwhere the predicted label",
    "start": "350930",
    "end": "355250"
  },
  {
    "text": "agrees with the actual label.",
    "start": "355250",
    "end": "357440"
  },
  {
    "text": "So the accuracy of\nthis model is 89%.",
    "start": "357440",
    "end": "361640"
  },
  {
    "text": "But accuracy is not a\ngreat evaluation metric,",
    "start": "361640",
    "end": "364640"
  },
  {
    "text": "especially when you have a\nskewed distribution like this",
    "start": "364640",
    "end": "368180"
  },
  {
    "text": "because even a model\nthat ignores the data",
    "start": "368180",
    "end": "371630"
  },
  {
    "text": "and always guesses false\ncan get 88% accuracy",
    "start": "371630",
    "end": "375530"
  },
  {
    "text": "just by always guessing false.",
    "start": "375530",
    "end": "378950"
  },
  {
    "text": "So instead of accuracy,\nwe look at precision,",
    "start": "378950",
    "end": "382370"
  },
  {
    "text": "which says of the instances\nthat are predicted to be true,",
    "start": "382370",
    "end": "386300"
  },
  {
    "text": "what proportion\nare actually true?",
    "start": "386300",
    "end": "389150"
  },
  {
    "text": "And recall, which says\nof the instances which",
    "start": "389150",
    "end": "392600"
  },
  {
    "text": "are actually true,\nwhat proportion",
    "start": "392600",
    "end": "394610"
  },
  {
    "text": "are predicted to be true?",
    "start": "394610",
    "end": "397823"
  },
  {
    "text": "So that's great.",
    "start": "397823",
    "end": "398490"
  },
  {
    "text": "Precision and recall\nare really useful.",
    "start": "398490",
    "end": "403060"
  },
  {
    "text": "But having two evaluation\nmetrics is often inconvenient.",
    "start": "403060",
    "end": "408220"
  },
  {
    "text": "If we're considering a\nchange to our model which",
    "start": "408220",
    "end": "410950"
  },
  {
    "text": "improves precision but degrades\nrecall, should we take it?",
    "start": "410950",
    "end": "416840"
  },
  {
    "text": "In order to drive an\niterative development process,",
    "start": "416840",
    "end": "419790"
  },
  {
    "text": "it's useful to have a single\nmetric on which to hill-climb.",
    "start": "419790",
    "end": "426518"
  },
  {
    "text": "So for binary classification,\nthe standard answer",
    "start": "426518",
    "end": "428560"
  },
  {
    "text": "is the F1 score,\nwhich is the harmonic",
    "start": "428560",
    "end": "431500"
  },
  {
    "text": "mean of precision and recall.",
    "start": "431500",
    "end": "434950"
  },
  {
    "text": "The harmonic mean is the\nreciprocal of the arithmetic",
    "start": "434950",
    "end": "438910"
  },
  {
    "text": "mean, the average\nof the reciprocals,",
    "start": "438910",
    "end": "442180"
  },
  {
    "text": "and it's always less\nthan the arithmetic mean.",
    "start": "442180",
    "end": "446229"
  },
  {
    "text": "It's pessimistic in a\nsense that it's always",
    "start": "446230",
    "end": "448630"
  },
  {
    "text": "closer to the lower number.",
    "start": "448630",
    "end": "450890"
  },
  {
    "text": "So the arithmetic mean of\n60% and 25% is-- sorry,",
    "start": "450890",
    "end": "455140"
  },
  {
    "text": "the harmonic mean of\n60% and 25% is 35.3%.",
    "start": "455140",
    "end": "461540"
  },
  {
    "text": "Now, the F1 score\ngives equal weight",
    "start": "461540",
    "end": "464810"
  },
  {
    "text": "to the precision and recall.",
    "start": "464810",
    "end": "467210"
  },
  {
    "text": "But depending on\nthe application,",
    "start": "467210",
    "end": "469350"
  },
  {
    "text": "they might not be\nof equal importance.",
    "start": "469350",
    "end": "472970"
  },
  {
    "text": "In relation\nextraction, we probably",
    "start": "472970",
    "end": "475430"
  },
  {
    "text": "care more about\nprecision than recall,",
    "start": "475430",
    "end": "479570"
  },
  {
    "text": "and that's because adding\nan invalid triple to the KB",
    "start": "479570",
    "end": "483590"
  },
  {
    "text": "is more harmful than\nfailing to add a valid one.",
    "start": "483590",
    "end": "490250"
  },
  {
    "text": "So instead, we could\nuse the F-measure, which",
    "start": "490250",
    "end": "492220"
  },
  {
    "text": "is a generalization of F1.",
    "start": "492220",
    "end": "493900"
  },
  {
    "text": "It's a weighted harmonic\nmean of precision and recall.",
    "start": "493900",
    "end": "497949"
  },
  {
    "text": "And this parameter beta controls\nhow much more importance",
    "start": "497950",
    "end": "502210"
  },
  {
    "text": "you place on recall\nthan on precision.",
    "start": "502210",
    "end": "506725"
  },
  {
    "text": "So let's say that in a\nparticular evaluation,",
    "start": "506725",
    "end": "508600"
  },
  {
    "text": "you have high precision,\n80%, and low recall, 20%.",
    "start": "508600",
    "end": "514690"
  },
  {
    "text": "The F1 score gives equal\nweight to precision and recall,",
    "start": "514690",
    "end": "519219"
  },
  {
    "text": "so its value is 32%.",
    "start": "519220",
    "end": "522038"
  },
  {
    "text": "If we set beta\nequal to 0.5, we're",
    "start": "522039",
    "end": "526240"
  },
  {
    "text": "giving more weight to\nprecision, so the value is 50%.",
    "start": "526240",
    "end": "531709"
  },
  {
    "text": "If we set beta equal to 2, we're\ngiving more weight to recall,",
    "start": "531710",
    "end": "535690"
  },
  {
    "text": "so the value is 23.5%.",
    "start": "535690",
    "end": "539730"
  },
  {
    "text": "In relation\nextraction, precision",
    "start": "539730",
    "end": "541620"
  },
  {
    "text": "is more important than\nrecall, so let's go with F 0.5",
    "start": "541620",
    "end": "545760"
  },
  {
    "text": "as our evaluation metric.",
    "start": "545760",
    "end": "548010"
  },
  {
    "text": "OK, another issue that comes\nup in evaluation scenarios",
    "start": "548010",
    "end": "551070"
  },
  {
    "text": "like this is whether\nto use micro-averaging",
    "start": "551070",
    "end": "553830"
  },
  {
    "text": "or macro-averaging.",
    "start": "553830",
    "end": "555840"
  },
  {
    "text": "We're going to compute\nprecision, recall, and F score",
    "start": "555840",
    "end": "559620"
  },
  {
    "text": "separately for each relation.",
    "start": "559620",
    "end": "562260"
  },
  {
    "text": "But in order to drive\niterative development,",
    "start": "562260",
    "end": "565260"
  },
  {
    "text": "we'd like to have summary\nmetrics, which aggregate",
    "start": "565260",
    "end": "568680"
  },
  {
    "text": "across all of the relations.",
    "start": "568680",
    "end": "570870"
  },
  {
    "text": "And there are two\npossible ways to do this.",
    "start": "570870",
    "end": "572790"
  },
  {
    "text": "Micro-averaging\ngives equal weight",
    "start": "572790",
    "end": "574920"
  },
  {
    "text": "to each problem\ninstance, which means",
    "start": "574920",
    "end": "578160"
  },
  {
    "text": "that it gives more weight to\nrelations with more instances.",
    "start": "578160",
    "end": "582990"
  },
  {
    "text": "Macro-averaging just gives\nequal weight to each relation.",
    "start": "582990",
    "end": "586920"
  },
  {
    "text": "So let me show you an\nillustration of this.",
    "start": "586920",
    "end": "588825"
  },
  {
    "text": "This is an artificial example\nwhere I have just three",
    "start": "588825",
    "end": "592020"
  },
  {
    "text": "relations, and the\ncontains relation",
    "start": "592020",
    "end": "595200"
  },
  {
    "text": "has 10 times as many instances\nas the other two relations.",
    "start": "595200",
    "end": "600370"
  },
  {
    "text": "It also has the highest F score.",
    "start": "600370",
    "end": "603580"
  },
  {
    "text": "When I compute the micro-average\nand the macro-average,",
    "start": "603580",
    "end": "607150"
  },
  {
    "text": "well, the micro-average\ngives equal weight",
    "start": "607150",
    "end": "610120"
  },
  {
    "text": "to each problem instance,\nso it gives a lot",
    "start": "610120",
    "end": "613240"
  },
  {
    "text": "more weight to the\ncontains relation,",
    "start": "613240",
    "end": "615730"
  },
  {
    "text": "and the result is that\nthe micro-average F",
    "start": "615730",
    "end": "618100"
  },
  {
    "text": "score is very close to\nthe F score for contains.",
    "start": "618100",
    "end": "622209"
  },
  {
    "text": "Whereas the macro-average gives\nequal weight to each relation,",
    "start": "622210",
    "end": "626320"
  },
  {
    "text": "and so it's just right in\nthe middle of this range.",
    "start": "626320",
    "end": "631930"
  },
  {
    "text": "The micro-averaged F\nscore is probably not",
    "start": "631930",
    "end": "634990"
  },
  {
    "text": "what we want because the number\nof instances per relation",
    "start": "634990",
    "end": "640029"
  },
  {
    "text": "is kind of an accident of our\ndata collection methodology.",
    "start": "640030",
    "end": "644260"
  },
  {
    "text": "And it's not like we believe\nthat the contains relation is",
    "start": "644260",
    "end": "648070"
  },
  {
    "text": "more important than\nthe other relations.",
    "start": "648070",
    "end": "650620"
  },
  {
    "text": "It just happens to be\nmore numerous in the data",
    "start": "650620",
    "end": "653110"
  },
  {
    "text": "that we collected.",
    "start": "653110",
    "end": "654950"
  },
  {
    "text": "So we're going to\nuse macro-averaging",
    "start": "654950",
    "end": "656980"
  },
  {
    "text": "so that we don't\noverweight large relations.",
    "start": "656980",
    "end": "659769"
  },
  {
    "start": "659770",
    "end": "662980"
  },
  {
    "text": "So if you put it all\ntogether, the bottom line",
    "start": "662980",
    "end": "665370"
  },
  {
    "text": "is that with every\nevaluation, we're",
    "start": "665370",
    "end": "667950"
  },
  {
    "text": "going to report lots of\nmetrics, but there's one metric",
    "start": "667950",
    "end": "671400"
  },
  {
    "text": "that we're going to focus on.",
    "start": "671400",
    "end": "673080"
  },
  {
    "text": "And this will be\nour figure of merit.",
    "start": "673080",
    "end": "675300"
  },
  {
    "text": "It's the one number that we're\ngoing to be hill-climbing on,",
    "start": "675300",
    "end": "678690"
  },
  {
    "text": "and we're choosing, as\nour figure of merit,",
    "start": "678690",
    "end": "681420"
  },
  {
    "text": "the macro-averaged F 0.5 score.",
    "start": "681420",
    "end": "685820"
  },
  {
    "start": "685820",
    "end": "690000"
  }
]
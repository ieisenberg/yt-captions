[
  {
    "start": "0",
    "end": "80000"
  },
  {
    "text": "So today we're going to start Lecture 19 of CS229. And the, uh, topics for today, uh,",
    "start": "4370",
    "end": "13290"
  },
  {
    "text": "we're gonna talk about the maximum entropy principle and how the exponential family uh,",
    "start": "13290",
    "end": "18660"
  },
  {
    "text": "distributions that we saw earlier in the- in the uh, course can be derived from the maximum entropy principle.",
    "start": "18660",
    "end": "25105"
  },
  {
    "text": "And we will show how, uh, you know, under what conditions maximizing entropy is equal to maximizing the likelihood MLE,",
    "start": "25105",
    "end": "34065"
  },
  {
    "text": "and also this will kind of, uh, lead us into some interesting topics such as calibration. We'll briefly talk about calibration and, you know,",
    "start": "34065",
    "end": "41180"
  },
  {
    "text": "what- what calibration means and how it relates to maximizing entropy, etc., they're very interesting topics.",
    "start": "41180",
    "end": "46520"
  },
  {
    "text": "And then, uh, depending on, uh, how- how, uh, how much we cover and how much time we have left.",
    "start": "46520",
    "end": "52730"
  },
  {
    "text": "We will talk about a few variants of the expectation maximization algorithm and how",
    "start": "52730",
    "end": "57770"
  },
  {
    "text": "these variants kind of leads itself into some of the more recent advances in unsupervised learning,",
    "start": "57770",
    "end": "63770"
  },
  {
    "text": "such as variational inference and, uh, the variational autoencoder. Uh, I'm not sure, uh, uh,",
    "start": "63770",
    "end": "70479"
  },
  {
    "text": "whether we'll be able to finish variational autoencoders today or even start it, but, uh, if we don't finish it today,",
    "start": "70480",
    "end": "76990"
  },
  {
    "text": "we'll pick it up, uh, in the next class. All right, so before we dive into today's topics,",
    "start": "76990",
    "end": "82375"
  },
  {
    "start": "80000",
    "end": "145000"
  },
  {
    "text": "a quick recap of what we covered in the previous class. So in the previous class we covered PCA and ICA.",
    "start": "82375",
    "end": "90190"
  },
  {
    "text": "PCA is principal components analysis. In PCA, we are given data X^i,",
    "start": "90190",
    "end": "96865"
  },
  {
    "text": "which lives in a d-dimensional space, and we are to find a low dimensional subspace Z^i,",
    "start": "96865",
    "end": "103910"
  },
  {
    "text": "which- which has, uh, which lives in a space of dimension K, right? For every Z^i, we want to find its projection onto",
    "start": "103910",
    "end": "111350"
  },
  {
    "text": "the low-dimensional space that we call Z^i. And the way we go about doing that is to map X to Xu,",
    "start": "111350",
    "end": "119035"
  },
  {
    "text": "where u is a column vector of- of K- of- of K columns,",
    "start": "119035",
    "end": "124850"
  },
  {
    "text": "where each of the d column are the top k eigenvectors of x transpose x.",
    "start": "124850",
    "end": "129860"
  },
  {
    "text": "And by- by- by doing this operation,",
    "start": "129860",
    "end": "135120"
  },
  {
    "text": "we effectively, uh, uh, get the projections onto this, uh, subspace.",
    "start": "135120",
    "end": "140739"
  },
  {
    "text": "Um, and then we talked about independent components analysis. In PCA, our goal was to find a low dimensional subspace,",
    "start": "140780",
    "end": "148775"
  },
  {
    "start": "145000",
    "end": "287000"
  },
  {
    "text": "whereas in ICA, our goals are very different. In ICA, our goal is to find independent sources that explain our data.",
    "start": "148775",
    "end": "155300"
  },
  {
    "text": "And the assumption that we made where there are D different independent sources, we call them SJ, where J indexes the source number.",
    "start": "155300",
    "end": "164825"
  },
  {
    "text": "So, um, the- each of the SJ is sampled from some probability,",
    "start": "164825",
    "end": "171524"
  },
  {
    "text": "uh, uh, distribution PS, which has to be non-Gaussian. You can either use, you know,",
    "start": "171524",
    "end": "176650"
  },
  {
    "text": "the Laplace distribution or the- the logistic distribution, any distribution which is kind of,",
    "start": "176650",
    "end": "182840"
  },
  {
    "text": "uh, has mean 0 and it's non-Gaussian. We- we saw some intuitions of what happens if we have",
    "start": "182840",
    "end": "188209"
  },
  {
    "text": "a Gaussian- if you make an assumption about Gaussian distributions as being the source, you know, we get this problem of, uh, rotational invariance.",
    "start": "188210",
    "end": "196370"
  },
  {
    "text": "And so as long as the sources are non-Gaussian and we have some square matrix A,",
    "start": "196370",
    "end": "202610"
  },
  {
    "text": "which we call as the mixing matrix, which mixes the S's into observations.",
    "start": "202610",
    "end": "208025"
  },
  {
    "text": "So S's are unobserved Xs are observed, right? And our goal is to start with X and recover S,",
    "start": "208025",
    "end": "215180"
  },
  {
    "text": "which are the independent sources. And the way we want to do it is to, um, the relation here- we assume is that A is a square invertible matrix.",
    "start": "215180",
    "end": "224670"
  },
  {
    "text": "And we want to invert A to get W. And W is the matrix that we want to estimate.",
    "start": "224670",
    "end": "230300"
  },
  {
    "text": "So that given observations we can multiply it through w and recover the original independent sources. Right? And the way we go about doing that is with",
    "start": "230300",
    "end": "237440"
  },
  {
    "text": "maximum likelihood where we directly estimate W, and the, uh, and the- and the uh, uh,",
    "start": "237440",
    "end": "245209"
  },
  {
    "text": "we saw that the- we saw that the probability of-",
    "start": "245210",
    "end": "252050"
  },
  {
    "text": "of X can be represented in this way where we map X back to W of x back to S using w,",
    "start": "252050",
    "end": "260420"
  },
  {
    "text": "and we need a corresponding Jacobian term, log- or the log determinant. Uh, and by performing this, uh, uh,",
    "start": "260420",
    "end": "269015"
  },
  {
    "text": "maximization using gradient ascent, there is no close form solution for this.",
    "start": "269015",
    "end": "274745"
  },
  {
    "text": "By performing gradient ascent, we can- we can- we can recover upon convergence the unmixing,",
    "start": "274745",
    "end": "282475"
  },
  {
    "text": "uh, matrix W hat. All right? And we also saw this in the homework.",
    "start": "282475",
    "end": "289580"
  },
  {
    "start": "287000",
    "end": "505000"
  },
  {
    "text": "Hopefully, you guys have finished this question in your homework. If not, no problem. You know- you know we're just stating the results here.",
    "start": "289580",
    "end": "295625"
  },
  {
    "text": "Um, the- the homework question has a small introduction about, you know, uh, about some explanations about KL divergence and entropy and so on.",
    "start": "295625",
    "end": "305620"
  },
  {
    "text": "You don't need- you don't need to know that for the purpose of this lecture. But if you've already seen it, it's- it's helpful.",
    "start": "305620",
    "end": "312500"
  },
  {
    "text": "Uh, so the- we define the KL divergence between two probability distributions, right?",
    "start": "312500",
    "end": "318590"
  },
  {
    "text": "So this- this is something important, right? So far, we've- we've seen things like, uh, you know the distance between two points in a vector space, right?",
    "start": "318590",
    "end": "326600"
  },
  {
    "text": "Uh, here the- the- the two things between which we are measuring are probability distributions, entire distributions, right?",
    "start": "326600",
    "end": "335240"
  },
  {
    "text": "So you can think of, uh, you know, p being some distribution like this,",
    "start": "335240",
    "end": "340295"
  },
  {
    "text": "and Q being another distribution like this. And we're trying to ask, you know,",
    "start": "340295",
    "end": "345664"
  },
  {
    "text": "what's kind of the difference between these two distributions, right? They're not single points but entire distributions.",
    "start": "345665",
    "end": "351004"
  },
  {
    "text": "So the KL divergence, uh, from P to Q is defined as, uh, the expectation with respect to p of log p by q.",
    "start": "351005",
    "end": "360365"
  },
  {
    "text": "You should note that this is not symmetric in the sense the KL divergence from P to Q is not the same as from Q to P. If they were the same,",
    "start": "360365",
    "end": "369259"
  },
  {
    "text": "we could have called it a distance like KL distance, but, um, it is- it is, um, it is not symmetric.",
    "start": "369260",
    "end": "375065"
  },
  {
    "text": "And, um, this- this is the definition of KL divergence. This is closely related to concepts,",
    "start": "375065",
    "end": "382305"
  },
  {
    "text": "uh, such as entropy. So we define entropy of a probability distribution, um, as- as the expectation under P of log 1 over p itself.",
    "start": "382305",
    "end": "392225"
  },
  {
    "text": "So the entropy kind of measures how spread out the distribution is. Uh, so if we have a distribution or, you know,",
    "start": "392225",
    "end": "401630"
  },
  {
    "text": "some finite support, a dist- a probability distribution that is uniform over",
    "start": "401630",
    "end": "408289"
  },
  {
    "text": "them is considered to have high entropy, right? Whereas if another distribution over the same support puts all its mass on any one point,",
    "start": "408290",
    "end": "419045"
  },
  {
    "text": "then this distribution is considered to have low entropy, right? So entropy, you can think of entropy as a synonym for uncertainty, right?",
    "start": "419045",
    "end": "426790"
  },
  {
    "text": "High entropy means high uncertainty. It can, uh, you know, you believe that the point can, I know some data observation can come from any of these.",
    "start": "426790",
    "end": "433990"
  },
  {
    "text": "You're not- you're not sure. Whereas a low entropy means low uncertainty. Right? If this distribution tells us that the point that we're gonna observe next,",
    "start": "433990",
    "end": "442960"
  },
  {
    "text": "if you were to sample from this will be from- will be this particular point alone, right? There's almost 0 uncertainty there.",
    "start": "442960",
    "end": "449245"
  },
  {
    "text": "So th- this is considered to have low entropy. Right? And then there is also this- this, uh,",
    "start": "449245",
    "end": "456360"
  },
  {
    "text": "nice interpretation about- of cross entropy that, uh, that's there in the- in the homework description.",
    "start": "456360",
    "end": "461370"
  },
  {
    "text": "You can- you can, uh, see that where we replace p over here by a different distribution Q, right?",
    "start": "461370",
    "end": "467780"
  },
  {
    "text": "And- and the cross-entropy is, you know, gets this form, expectation under P log of 1 over q.",
    "start": "467780",
    "end": "473645"
  },
  {
    "text": "And the difference between the cross entropy and entropy is basically actually just equal to the KL divergence itself.",
    "start": "473645",
    "end": "482990"
  },
  {
    "text": "So the KL divergence between two distributions, P Q is just the cross entropy minus the entropy.",
    "start": "482990",
    "end": "489995"
  },
  {
    "text": "There are some nice interpretations about- about, uh, this in terms of coding theory that's there in the homework.",
    "start": "489995",
    "end": "495455"
  },
  {
    "text": "But, you know, that's not really necessary for- for our lecture today, as long as you kind of, uh, uh,",
    "start": "495455",
    "end": "500849"
  },
  {
    "text": "remember these, uh, these- these formulas. And also earlier in the lecture- earlier in the course,",
    "start": "500850",
    "end": "508250"
  },
  {
    "start": "505000",
    "end": "665000"
  },
  {
    "text": "we came across exponential family. The exponential family is- is a- is- is",
    "start": "508250",
    "end": "514159"
  },
  {
    "text": "a way to characterize a family of probability distributions. Where the probability distribution over Y with",
    "start": "514160",
    "end": "521930"
  },
  {
    "text": "some parameter called natural parameter eta takes this form. Right? So here, b of y is called the base measure.",
    "start": "521930",
    "end": "529910"
  },
  {
    "text": "Correct? And there is the exponent of some of- of some term over here. That term has two parts.",
    "start": "529910",
    "end": "536435"
  },
  {
    "text": "One is eta, the natural parameter, dot-product with p of y.",
    "start": "536435",
    "end": "542355"
  },
  {
    "text": "So t is called the sufficient statistics over y minus A of eta, where A is called the log partition function.",
    "start": "542355",
    "end": "548825"
  },
  {
    "text": "Right? And we also saw, uh, again in- in your homework 1 that the mean of",
    "start": "548825",
    "end": "555470"
  },
  {
    "text": "this probability distribution can be represented as the derivative of the log partition function,",
    "start": "555470",
    "end": "561290"
  },
  {
    "text": "uh, at- at eta. So if- if we change eta to two different values, we get different means.",
    "start": "561420",
    "end": "567995"
  },
  {
    "text": "And the way you go from the parameter value eta to the mean of the corresponding distribution is to calculate A prime or the first derivative of A,",
    "start": "567995",
    "end": "576030"
  },
  {
    "text": "of first derivative of the log partition function at the parameter value eta. And it so happens that this- this function,",
    "start": "576030",
    "end": "583275"
  },
  {
    "text": "A prime will always be invertible. And so we can go from the mean of a distribution back to the,",
    "start": "583275",
    "end": "590690"
  },
  {
    "text": "uh, natural parameter eta this way, right? So, uh, the first thing we're gonna do today is",
    "start": "590690",
    "end": "598009"
  },
  {
    "text": "to derive maximum likelihood estimates of eta given some observations Y. And then- and then we'll jump over to",
    "start": "598010",
    "end": "604880"
  },
  {
    "text": "maximum entropy and- and start seeing its, uh, equivalence. Any questions on this so far? Yes, question.",
    "start": "604880",
    "end": "610550"
  },
  {
    "text": "I think I see that the result is the log determined to derivative, are you going to [inaudible]",
    "start": "610550",
    "end": "613770"
  },
  {
    "text": "So the question is, um, in, ah, in ICA, is the log determinant acting like",
    "start": "616140",
    "end": "621850"
  },
  {
    "text": "a regularizer or are we going to add regularization on top? ah, so that's a very interesting question.",
    "start": "621850",
    "end": "626894"
  },
  {
    "text": "In ICA it so happens that most of the time we are not really interested in generalization error, right?",
    "start": "626895",
    "end": "632380"
  },
  {
    "text": "So we're, ah, ICA is kind of, ah, in a way different from the rest of the algorithms that we've seen,",
    "start": "632380",
    "end": "638140"
  },
  {
    "text": "where in the rest of the algorithms you're interested in generalization error. Whereas in ICA, ah, we take some examples,",
    "start": "638140",
    "end": "644020"
  },
  {
    "text": "fit a model and just, you know, um, recover the sources of the given data itself. So, um, it's- it's not common to use regularization in ICA.",
    "start": "644020",
    "end": "652950"
  },
  {
    "text": "And this log determinant is actually not the regularizer. So this log determinant is a necessary component to make",
    "start": "652950",
    "end": "660120"
  },
  {
    "text": "the distribution a valid probability distribution. Good question.",
    "start": "660120",
    "end": "665150"
  },
  {
    "start": "665000",
    "end": "1173000"
  },
  {
    "text": "Any other question before we jump into MLE of exponential families? Great.",
    "start": "665250",
    "end": "672550"
  },
  {
    "text": "Okay, so, um, MLE of exponential family. [NOISE] So in- in- in the,",
    "start": "672550",
    "end": "682075"
  },
  {
    "text": "um, when we studied exponential families, ah, earlier in the course and- and when you studied GLMs, we made this, ah,",
    "start": "682075",
    "end": "688365"
  },
  {
    "text": "simplifying assumption that y would- was always a scalar in our case. So in case of, um, regression,",
    "start": "688365",
    "end": "696384"
  },
  {
    "text": "y was just real values in- in case of our logistic regression, y was, you know,",
    "start": "696384",
    "end": "701560"
  },
  {
    "text": "a binary 0 or 1. We saw some generalizations, ah, with Softmax where y was- would- would- can- could- could take, ah, multiple values.",
    "start": "701560",
    "end": "711055"
  },
  {
    "text": "But now, we're going to take a- an even more, um, ah, generalized form where y can be, you know, some- some,",
    "start": "711055",
    "end": "719649"
  },
  {
    "text": "um, y could be anything, and t of y, which we always most of the times in- in- when we",
    "start": "719650",
    "end": "727660"
  },
  {
    "text": "studied GLMs t of y was just taken to be identity as y itself. But now, we will again relax that and make it even more general,",
    "start": "727660",
    "end": "734875"
  },
  {
    "text": "um, where t of y could be anything. So suppose, ah, we have an exponential family, right exponential family phi of y,",
    "start": "734875",
    "end": "748269"
  },
  {
    "text": "given Eta equals b of y times the exponent.",
    "start": "748270",
    "end": "754945"
  },
  {
    "text": "I'm just rewriting, ah, the same thing over there. Eta a product t of y.",
    "start": "754945",
    "end": "760090"
  },
  {
    "text": "So this is the dot-product, Eta can be a vector and t of y can also be a vector of the same dimension, right?",
    "start": "760090",
    "end": "769464"
  },
  {
    "text": "And this is just the inner product. If there- if these two are scalars, then this is just a simple product minus a of Eta, right?",
    "start": "769465",
    "end": "779560"
  },
  {
    "text": "And we are given some data, S equal to y_1,",
    "start": "779560",
    "end": "786110"
  },
  {
    "text": "y small n, right? So we're given- given, um, ah,",
    "start": "786330",
    "end": "791350"
  },
  {
    "text": "this data and we want to find Eta, you know, um, Eta hat MLE equal to arg max.",
    "start": "791350",
    "end": "802945"
  },
  {
    "text": "So here, we assume i.i.d- i.i.d,",
    "start": "802945",
    "end": "808570"
  },
  {
    "text": "arg max cross Eta log i equals 1-10,",
    "start": "808570",
    "end": "819205"
  },
  {
    "text": "p of y_i Eta. There's a standard, ah, you know,",
    "start": "819205",
    "end": "825670"
  },
  {
    "text": "maximum likelihood, um, ah, procedure that we follow throughout the course. There's nothing different here. Okay? Now, let's- let's,",
    "start": "825670",
    "end": "833060"
  },
  {
    "text": "um, simplify this further. So this is arg max,",
    "start": "833550",
    "end": "839350"
  },
  {
    "text": "with respect to Eta. Now, log of the product is the sum of the logs. So we're gonna take the sum,",
    "start": "839350",
    "end": "844990"
  },
  {
    "text": "i equals 1 to n- 1 to n, and the log goes in.",
    "start": "844990",
    "end": "850105"
  },
  {
    "text": "So the log of this, ah, thing over here, will give us log b of y_i,",
    "start": "850105",
    "end": "860245"
  },
  {
    "text": "right, plus log and the exponent cancel, you get Eta dot t of y_i minus a of Eta.",
    "start": "860245",
    "end": "874850"
  },
  {
    "text": "And in order to do, ah, maximum likelihood, we take the derivative of this with respect to Eta,",
    "start": "877980",
    "end": "884350"
  },
  {
    "text": "set that equal to 0, and solve for- solve for Eta, the same process. So for this, we now take the gradient with respect to Eta",
    "start": "884350",
    "end": "896260"
  },
  {
    "text": "of this whole thing is equal to,",
    "start": "896260",
    "end": "903985"
  },
  {
    "text": "um, so this is gonna be sum i equals 1 to n. The derivative of b of y with respect to Eta is?",
    "start": "903985",
    "end": "913835"
  },
  {
    "text": "0. 0. So this would be just 0 plus the derivative",
    "start": "913835",
    "end": "920665"
  },
  {
    "text": "of Eta dot p of y_i with respect to Eta will be just t of y_i plus t of y_i minus derivative of a of Eta with respect to",
    "start": "920665",
    "end": "933190"
  },
  {
    "text": "Eta is we just call it a prime of Eta, right?",
    "start": "933190",
    "end": "942130"
  },
  {
    "text": "And this gives us, so, ah, this- so we have a sum over i from 1 to n of this term,",
    "start": "942130",
    "end": "950770"
  },
  {
    "text": "and we need- we set this equal to 0. This gives us n times a prime of Eta.",
    "start": "950770",
    "end": "959529"
  },
  {
    "text": "So this is n, this is Eta, right? This is n, the number of examples, and this is Eta, they look kind of similar equal to i equals 1 to n t of y_i,",
    "start": "959530",
    "end": "974230"
  },
  {
    "text": "or a prime of Eta is equal to 1 over n,",
    "start": "974230",
    "end": "980740"
  },
  {
    "text": "i equals 1 to n p of y_i.",
    "start": "980740",
    "end": "987560"
  },
  {
    "text": "And this tells us Eta hat MLE is equal to a prime inverse of 1 over n,",
    "start": "989340",
    "end": "1003975"
  },
  {
    "text": "i equals 1 to n t of y_i.",
    "start": "1003975",
    "end": "1010660"
  },
  {
    "text": "So what just happened here? The maximum likelihood estimate of the natural parameter of any probability, ah,",
    "start": "1015440",
    "end": "1023895"
  },
  {
    "text": "distribution in the exponential family can be calculated as the- the mean or the sample mean of the observed sufficient statistics taken through the- the,",
    "start": "1023895",
    "end": "1035189"
  },
  {
    "text": "ah, the inverse of a prime. If you remember in the exponential family notes,",
    "start": "1035190",
    "end": "1041819"
  },
  {
    "text": "we- we called g equals a prime to be the canonical link function.",
    "start": "1041820",
    "end": "1048700"
  },
  {
    "text": "And we call it g inverse, which will be a prime inverse to be the,",
    "start": "1050480",
    "end": "1057330"
  },
  {
    "text": "or I think we called this the canonical response function. And this to be the canonical link function.",
    "start": "1057330",
    "end": "1064110"
  },
  {
    "text": "All right? So this is just the canonical link function.",
    "start": "1064110",
    "end": "1069765"
  },
  {
    "text": "So take the sample- sample mean of the observed y_i's, run it through the canonical link function,",
    "start": "1069765",
    "end": "1076380"
  },
  {
    "text": "and that gives you the, ah, um, maximum likelihood estimate of- of Eta,",
    "start": "1076380",
    "end": "1082320"
  },
  {
    "text": "where this is in the most generic form, right? So when we- when we- when we take specific members of the exponential family,",
    "start": "1082320",
    "end": "1091680"
  },
  {
    "text": "like the Poisson or the Bernoulli or, you know, what have you, a prime will take some particular form,  t of y will take some particular form.",
    "start": "1091680",
    "end": "1099899"
  },
  {
    "text": "But in the most generic, ah, um, in the most genetic setting, this is the estimate for the maximum likelihood, ah,",
    "start": "1099900",
    "end": "1106530"
  },
  {
    "text": "estimate of the natural parameter. Okay, yes question. [inaudible]",
    "start": "1106530",
    "end": "1115065"
  },
  {
    "text": "So, good question. So in- in the last lecture we were doing ICA and- and PCA,",
    "start": "1115065",
    "end": "1120870"
  },
  {
    "text": "which was unsupervised learning. So, uh, what's the- what's the goal here? That's a very good question. So today what we are doing is,",
    "start": "1120870",
    "end": "1127785"
  },
  {
    "text": "uh, trying to understand this, you know, pretty generic concept called maximum entropy principle and how that- that,",
    "start": "1127785",
    "end": "1135450"
  },
  {
    "text": "uh, results in- in concepts such as calibration and KL divergence and we will use KL divergence as a concept to,",
    "start": "1135450",
    "end": "1144270"
  },
  {
    "text": "uh, kind of understand variational inference and variational autoencoders.",
    "start": "1144270",
    "end": "1151920"
  },
  {
    "text": "So, uh, this, I would not call it either supervised or unsupervised because these are just,",
    "start": "1151920",
    "end": "1158340"
  },
  {
    "text": "uh, you know, maximum likelihood estimates about- of, you know, general probability distributions. This has- um, yeah,",
    "start": "1158340",
    "end": "1165149"
  },
  {
    "text": "I- I wouldn't call this either supervised or unsupervised, these are just exponential family distributions. Good question.",
    "start": "1165150",
    "end": "1171795"
  },
  {
    "text": "All right, so this was the, um, maximum likelihood estimate of- of, um,",
    "start": "1171795",
    "end": "1176970"
  },
  {
    "start": "1173000",
    "end": "1420000"
  },
  {
    "text": "the natural parameter and let's just save it because we will refer to this,",
    "start": "1176970",
    "end": "1184485"
  },
  {
    "text": "um, in- shortly in a few minutes. [NOISE] Now, let's switch",
    "start": "1184485",
    "end": "1191580"
  },
  {
    "text": "gears and talk about maximum entropy, right? So in, um, so the maximum entropy principle, um,",
    "start": "1191580",
    "end": "1200174"
  },
  {
    "text": "is a principle that tells us that, uh, whenever we want to estimate a probability, uh,",
    "start": "1200175",
    "end": "1205260"
  },
  {
    "text": "distribution with some observed data, let's suppose, uh,",
    "start": "1205260",
    "end": "1211860"
  },
  {
    "text": "we have a- a probability, a probability distribution over the real values, right?",
    "start": "1211860",
    "end": "1219960"
  },
  {
    "text": "So the- the, uh, this is R and X and this is P of x, right?",
    "start": "1219960",
    "end": "1231540"
  },
  {
    "text": "So, uh, and suppose we- we make some observations on x, right?",
    "start": "1231540",
    "end": "1238350"
  },
  {
    "text": "So we observe this, we observe this, and we observe this as samples from this probability distribution.",
    "start": "1238350",
    "end": "1244095"
  },
  {
    "text": "And our goal is to now estimate, you know, what the density of what P of x is, right?",
    "start": "1244095",
    "end": "1249960"
  },
  {
    "text": "And given just three points, it's very hard to tell, you know, what the density of P of x is, right?",
    "start": "1249960",
    "end": "1257340"
  },
  {
    "text": "Ideally, what we would like to have is, you know, an- an, uh, infinite number of observations, you know,",
    "start": "1257340",
    "end": "1263895"
  },
  {
    "text": "prob- preferably, you know an uncountably infinite number of observations. So that we can precisely calculate",
    "start": "1263895",
    "end": "1269850"
  },
  {
    "text": "the fraction at each point and construct some kind of a density, right? But we're only given, um,",
    "start": "1269850",
    "end": "1275235"
  },
  {
    "text": "a finite number of points, uh, you know, they could be large, they could be small, but we're still given a finite number of points and we need to",
    "start": "1275235",
    "end": "1283740"
  },
  {
    "text": "estimate the value of P of X at every, uh, point x. And the maximum entropy principle, uh,",
    "start": "1283740",
    "end": "1290549"
  },
  {
    "text": "tells us that the way we want to go about it is to first translate these,",
    "start": "1290550",
    "end": "1296790"
  },
  {
    "text": "uh, data points into constraints, right? So for example, uh, the mean of, uh,",
    "start": "1296790",
    "end": "1302265"
  },
  {
    "text": "this- this set of points could be, you know, say Mu hat, right?",
    "start": "1302265",
    "end": "1307440"
  },
  {
    "text": "So Mu hat, you know, is just the sample mean.",
    "start": "1307440",
    "end": "1311140"
  },
  {
    "text": "Similarly, the, uh, variance could be I/n equals 1 to n,",
    "start": "1313130",
    "end": "1322680"
  },
  {
    "text": "x_i minus Mu squared, right?",
    "start": "1322680",
    "end": "1331020"
  },
  {
    "text": "So this is just the- the, uh, and if we take this to be Mu hat, this is just the sample standard deviation, right?",
    "start": "1331020",
    "end": "1337290"
  },
  {
    "text": "And the maximum entropy principle tells us that the, uh,",
    "start": "1337290",
    "end": "1342330"
  },
  {
    "text": "our estimate for P of X should be a probability, uh, distribution that is subject to these constraints and these are hard constraints.",
    "start": "1342330",
    "end": "1352230"
  },
  {
    "text": "And within the family of probability distributions that satisfy these constraints, choose the one that has the highest entropy.",
    "start": "1352230",
    "end": "1360400"
  },
  {
    "text": "Right? So the constraints, we can call these constraints,",
    "start": "1360710",
    "end": "1366700"
  },
  {
    "text": "the- the constraints define a set of all probability distributions that are what is also called as feasible.",
    "start": "1369680",
    "end": "1378665"
  },
  {
    "text": "Any probability distribution that- that satisfies these is a, uh, feasible candidate for our estimate and then among this, um,",
    "start": "1378665",
    "end": "1387645"
  },
  {
    "text": "large set of feasible probability distributions, the feasible probability distribution will almost certainly, uh,",
    "start": "1387645",
    "end": "1395705"
  },
  {
    "text": "you know, be more than one because there are an infinite number of probability distribution that satisfy in this example,",
    "start": "1395705",
    "end": "1401675"
  },
  {
    "text": "a particular mean and- and standard deviation. Among the set of all, uh, feasible distributions, choose the one that has the highest entropy.",
    "start": "1401675",
    "end": "1410055"
  },
  {
    "text": "That's what the maximum entropy principle tells us. And the way we go about formulating it is-",
    "start": "1410055",
    "end": "1415750"
  },
  {
    "start": "1420000",
    "end": "1800000"
  },
  {
    "text": "the way we go about formulating it is, um,",
    "start": "1424340",
    "end": "1429220"
  },
  {
    "text": "P, which is the, uh, estimated probability, uh, distribution over Y.",
    "start": "1429500",
    "end": "1436750"
  },
  {
    "text": "To clarify some notations, uh, let's call this and,",
    "start": "1437780",
    "end": "1443535"
  },
  {
    "text": "you know, we'll be using instead of X, all right? So P is equal to arg max over all Ps,",
    "start": "1443535",
    "end": "1456360"
  },
  {
    "text": "maybe we can just call it P star, arg max over Ps, which maximizes H of P,",
    "start": "1456360",
    "end": "1464429"
  },
  {
    "text": "which is the entropy, right? H of P is just the entropy uh, that we defined here, such that we have some constraints.",
    "start": "1464430",
    "end": "1473534"
  },
  {
    "text": "So the constraints, we will write them in the form, uh, we will, uh, limit ourselves to linear constraints.",
    "start": "1473535",
    "end": "1480450"
  },
  {
    "text": "By linear constraints, what I mean is such that, um, sum over- sum over j,",
    "start": "1480450",
    "end": "1492399"
  },
  {
    "text": "sum over i, T_j of p_i is equal to some C_i.",
    "start": "1494570",
    "end": "1505470"
  },
  {
    "text": "What does that mean? So we will assume that the constraints, uh, for our estimation problem are given in the form of some functions,",
    "start": "1505470",
    "end": "1515460"
  },
  {
    "text": "T's which are indexed by j. Yeah T's are indexed by j.",
    "start": "1515460",
    "end": "1522120"
  },
  {
    "text": "So T is some function that takes Y to R, right?",
    "start": "1522120",
    "end": "1528345"
  },
  {
    "text": "So, uh, the- the constraints that we are given, you know, constraints such as this,",
    "start": "1528345",
    "end": "1533789"
  },
  {
    "text": "will be given in the form of these, uh, these T functions where we have n such things or m such things.",
    "start": "1533790",
    "end": "1545235"
  },
  {
    "text": "So, uh, j equals one through m, T_j of Y to R. What does this exactly mean?",
    "start": "1545235",
    "end": "1554460"
  },
  {
    "text": "It means that, uh, for every corresponding, uh, T_j, there's a corresponding C_j,",
    "start": "1554460",
    "end": "1561000"
  },
  {
    "text": "the constraint value where we need to satisfy sum over i equals 1",
    "start": "1561000",
    "end": "1567330"
  },
  {
    "text": "through n T- T_j",
    "start": "1567330",
    "end": "1575120"
  },
  {
    "text": "of y_i equal to C_i.",
    "start": "1575120",
    "end": "1583950"
  },
  {
    "text": "Now if T_j, if- if for example,",
    "start": "1583950",
    "end": "1589335"
  },
  {
    "text": "one particular T, uh, of Y, if we consider this as equal to just Y itself,",
    "start": "1589335",
    "end": "1595110"
  },
  {
    "text": "then this gives us a constraint for the mean.",
    "start": "1595110",
    "end": "1599890"
  },
  {
    "text": "Because this basically boils down to for sum i equals one through n,",
    "start": "1603980",
    "end": "1610660"
  },
  {
    "text": "T of y times oh,",
    "start": "1612350",
    "end": "1618735"
  },
  {
    "text": "I also forgot P of i, t of y times p of y is",
    "start": "1618735",
    "end": "1624059"
  },
  {
    "text": "equal to C_i- C- just C. So this is just,",
    "start": "1624060",
    "end": "1629685"
  },
  {
    "text": "um, if- if T of y is equal to just y, then this becomes i equals 1 through n. Y times P of y is equal to the expectation of Y.",
    "start": "1629685",
    "end": "1643184"
  },
  {
    "text": "Right? So for different choices of T's, or rather the different choice of sufficient statistics,",
    "start": "1643185",
    "end": "1648720"
  },
  {
    "text": "we- we can express constraints in this form. And, um, we're also going to assume that",
    "start": "1648720",
    "end": "1658200"
  },
  {
    "text": "the support of Y is finite, right?",
    "start": "1658200",
    "end": "1667260"
  },
  {
    "text": "The support of for Y being finite is, uh, is a simplifying assumption and we don't really need this,",
    "start": "1667260",
    "end": "1677195"
  },
  {
    "text": "um, to show, to show, uh, the results, but we're going to assume it is finite so that we can represent things as,",
    "start": "1677195",
    "end": "1684095"
  },
  {
    "text": "you know, inner products and sums rather than integrals. Right? And we assume that N is kind of size of the second Y. Yes, was there a question?",
    "start": "1684095",
    "end": "1696060"
  },
  {
    "text": "[inaudible] Like how can there be any other kinds of constraints [inaudible]?",
    "start": "1696060",
    "end": "1705240"
  },
  {
    "text": "So how can there be other kinds of constraints? So generally the constraints are- are constraints given are- are of the form where the,",
    "start": "1705240",
    "end": "1714030"
  },
  {
    "text": "you know, some kind of a moment of the observed data is equal to some value, right? So the- the moments of the distribution should match, you know,",
    "start": "1714030",
    "end": "1720929"
  },
  {
    "text": "some- the moments of the observed, um, samples. Generally those are the kind of constraints we're interested in.",
    "start": "1720930",
    "end": "1726510"
  },
  {
    "text": "Why don't we directly use these constraints in this problem because we can just take the form of our exponential family and then using",
    "start": "1726510",
    "end": "1732950"
  },
  {
    "text": "these constraints try to make constraints on the parameters v and eta?- Well, so, when we're- so the question is,",
    "start": "1732950",
    "end": "1740039"
  },
  {
    "text": "why don't we start with here? So the, the exercise that we're trying to, uh, do right now is to start from,",
    "start": "1740040",
    "end": "1745740"
  },
  {
    "text": "uh, P, from the maximum entropy principle. Make no assumptions about the form of P right here.",
    "start": "1745740",
    "end": "1751845"
  },
  {
    "text": "So far, you know P could be any kind of a probability distribution. We are just assuming some kind of a support,",
    "start": "1751845",
    "end": "1757065"
  },
  {
    "text": "and what we're gonna show is the maximum entropy principle will recover the exponential family.",
    "start": "1757065",
    "end": "1762540"
  },
  {
    "text": "That's, that's, that's our goal over here, right? And intentionally we are using the same symbols,",
    "start": "1762540",
    "end": "1767684"
  },
  {
    "text": "you know our T's and Y's that are gonna end up being, you know, the corresponding terms in in,",
    "start": "1767685",
    "end": "1772860"
  },
  {
    "text": "uh, the exponential family. So, um, the, the, the T's over here are trying to satisfy some constraint.",
    "start": "1772860",
    "end": "1781020"
  },
  {
    "text": "Okay? Eventually, you know, by the end of this exercise, we will see that t's will be the sufficient statistics.",
    "start": "1781020",
    "end": "1786885"
  },
  {
    "text": "Um, but for now, you know just assume T's are, are, are you know, some kind of a function whose linear combination with P must satisfy a constraint value.",
    "start": "1786885",
    "end": "1798000"
  },
  {
    "text": "Right? So we have, so N is the, N is the, um,",
    "start": "1798000",
    "end": "1804554"
  },
  {
    "start": "1800000",
    "end": "2260000"
  },
  {
    "text": "the cardinality of the set Y, and we have M constraints, right?",
    "start": "1804555",
    "end": "1813620"
  },
  {
    "text": "[BACKGROUND] Which means, um, we have M such T functions,",
    "start": "1813620",
    "end": "1819690"
  },
  {
    "text": "and now our task is to perform this optimization, all right?",
    "start": "1820480",
    "end": "1826169"
  },
  {
    "text": "So we want to maximize the entropy of, uh, the probability distribution such that, um,",
    "start": "1827840",
    "end": "1835950"
  },
  {
    "text": "some kind of, uh, uh, a linear constraints over P are,",
    "start": "1835950",
    "end": "1840580"
  },
  {
    "text": "are, are, are satisfied. So, uh, this, I think,",
    "start": "1840980",
    "end": "1846750"
  },
  {
    "text": "write this more clearly.",
    "start": "1846750",
    "end": "1850420"
  },
  {
    "text": "I t of Y I, J times P of I is equal to C of",
    "start": "1856520",
    "end": "1866355"
  },
  {
    "text": "J and J equals 1 [NOISE] through M. So there are M such T functions,",
    "start": "1866355",
    "end": "1872549"
  },
  {
    "text": "and all these T functions must satisfy this, uh, uh, this kind of a constraint where the expectation of T is equal to some constraint value C,",
    "start": "1872550",
    "end": "1884100"
  },
  {
    "text": "and most of the times these constraints will be arising from data,",
    "start": "1884100",
    "end": "1890294"
  },
  {
    "text": "from the observed data, right? Where C-J will be equal to, um,",
    "start": "1890295",
    "end": "1896390"
  },
  {
    "text": "will be equal to 1 over N,",
    "start": "1896390",
    "end": "1902280"
  },
  {
    "text": "where N is the number of examples. I equals one through N, T of Y-I-J. Yes, was there a question?",
    "start": "1902280",
    "end": "1912419"
  },
  {
    "text": "[inaudible].",
    "start": "1912420",
    "end": "1917550"
  },
  {
    "text": "So there's an I after, you know the Y bracket. There's an I, over the Y. Oh, oh, oh, yeah. You're right.",
    "start": "1917550",
    "end": "1924345"
  },
  {
    "text": "Sorry. Thank you. So this is- so, so yeah. So to, uh, to, to, um, um,",
    "start": "1924345",
    "end": "1932775"
  },
  {
    "text": "clarify the notations, there are M such T functions, and each of those M is indexed by J, right?",
    "start": "1932775",
    "end": "1939525"
  },
  {
    "text": "And T-J tells us, you know it's the Jth T function, and I is the, uh, uh,",
    "start": "1939525",
    "end": "1946140"
  },
  {
    "text": "I is the index we use to scan the support of y. Right? So Y there are- there are capital N elements in",
    "start": "1946140",
    "end": "1954360"
  },
  {
    "text": "Y and I equals 1 through N, T of Y I. So every possible value of I will get a probability of P-I.",
    "start": "1954360",
    "end": "1963300"
  },
  {
    "text": "That's the probability of, of, um, P-I is equal to P of Y-I, right?",
    "start": "1963300",
    "end": "1971070"
  },
  {
    "text": "So we're going to switch it, you know, it's, it's very common that, you know we switch between, uh,",
    "start": "1971070",
    "end": "1976830"
  },
  {
    "text": "the, the, uh, functional notation and the vector notation, right?",
    "start": "1976830",
    "end": "1983115"
  },
  {
    "text": "They mean the same thing. Okay? So we are given a set of linear constraints,",
    "start": "1983115",
    "end": "1988575"
  },
  {
    "text": "and satisfying these linear constraints, we want to maximize the entropy. Yes, question. [inaudible] [OVERLAPPING]",
    "start": "1988575",
    "end": "2000620"
  },
  {
    "text": "Oh, this, oh, sorry. Yes. And also is support, um, for Y,",
    "start": "2000620",
    "end": "2006799"
  },
  {
    "text": "basically each individual enough point over here. Yeah, so question, so what is the support of Y? So here we are assuming Y is- has finite support,",
    "start": "2006800",
    "end": "2015515"
  },
  {
    "text": "which means, um, Y can take on a finite number of values. All right, So Y itself can live in a high dimensional space,",
    "start": "2015515",
    "end": "2025490"
  },
  {
    "text": "but we assume Y can take on a finite number of values, right?",
    "start": "2025490",
    "end": "2031010"
  },
  {
    "text": "And P of Y I tells us the probability that our distribution assigns to that point Y I.",
    "start": "2031010",
    "end": "2037940"
  },
  {
    "text": "Our observed Y I, Y superscript, you know parenthesis I are the actual observations.",
    "start": "2037940",
    "end": "2044510"
  },
  {
    "text": "So Y superscript I tells us what the Ith observation was.",
    "start": "2044510",
    "end": "2049625"
  },
  {
    "text": "Right if you, if you sample, um, many of them, but each of these YI's will be one of the finite numbers, uh, of,",
    "start": "2049625",
    "end": "2057004"
  },
  {
    "text": "of elements in script Y. Okay. [NOISE].",
    "start": "2057005",
    "end": "2065710"
  },
  {
    "text": "You are saying that we're not [inaudible] discrete distribution. Exactly. So this is just a way of saying that we are only interested in discrete distribution. Next question.",
    "start": "2065710",
    "end": "2072129"
  },
  {
    "text": "After continuous, would we require compact support or? We would, uh, a compact support or Y.",
    "start": "2072130",
    "end": "2079085"
  },
  {
    "text": "Yeah. On- so, so for example, so, so for continuous this could be an entire R-line, real-valued line it, it.",
    "start": "2079085",
    "end": "2084260"
  },
  {
    "text": "[inaudible]. Yeah. Yeah. All right.",
    "start": "2084260",
    "end": "2089270"
  },
  {
    "text": "Any, any, any questions in this? Let me repeat it. There were, uh, uh, a few, uh, uh, typos, so just,",
    "start": "2089270",
    "end": "2095300"
  },
  {
    "text": "just to, um, um, just to repeat it so that everything is clear. We, all right, So,",
    "start": "2095300",
    "end": "2108319"
  },
  {
    "text": "so we, we, uh, we assume that Y has finite support,",
    "start": "2108320",
    "end": "2113600"
  },
  {
    "text": "which means there are N. Uh, N is the size of the cardinality of script Y, right?, and our probability distributions are assigned over this space.",
    "start": "2113600",
    "end": "2122869"
  },
  {
    "text": "Now, we are given some observations, small N number of observations of YI's,",
    "start": "2122870",
    "end": "2129244"
  },
  {
    "text": "and for out of these observations we can construct constraints. Okay. So the constraints can be,",
    "start": "2129244",
    "end": "2136160"
  },
  {
    "text": "uh, for, for example, that the, uh, mean of the observed data has some particular mean.",
    "start": "2136160",
    "end": "2143135"
  },
  {
    "text": "It could be that the, um, um, um, the- the square, the sum of the squares of the observations is,",
    "start": "2143135",
    "end": "2150155"
  },
  {
    "text": "you know, some value. That could be another constraint. It could be the sum of the cubes of the observed values is some,",
    "start": "2150155",
    "end": "2155540"
  },
  {
    "text": "um, value that could be another constraint, right? So T of Y can be things like, you know, a T of Y equals Y,",
    "start": "2155540",
    "end": "2161840"
  },
  {
    "text": "T of Y equals Y square. They are, they are different possible, uh, uh,",
    "start": "2161840",
    "end": "2166910"
  },
  {
    "text": "functions of Y, and out of the- those functions, we construct these constraints.",
    "start": "2166910",
    "end": "2173674"
  },
  {
    "text": "That, uh, them, uh, this, this constraint basically tells us that the mean of, uh,",
    "start": "2173675",
    "end": "2179210"
  },
  {
    "text": "of the distribution P will have to be the mean of the,",
    "start": "2179210",
    "end": "2185359"
  },
  {
    "text": "um, um, of the, of the T function, of a- a particular a T function should be,",
    "start": "2185360",
    "end": "2192665"
  },
  {
    "text": "you know some particular value and so on, right? Now, subject to these constraints, now,",
    "start": "2192665",
    "end": "2198845"
  },
  {
    "text": "we want to solve this, uh, optimization problem. The way we go about solving this problem is to",
    "start": "2198845",
    "end": "2204740"
  },
  {
    "text": "construct what is called the, uh, Lagrangian. [BACKGROUND]",
    "start": "2204740",
    "end": "2218750"
  },
  {
    "text": "So if T, the- the T function is- if that is still a little confusing,",
    "start": "2218750",
    "end": "2224195"
  },
  {
    "text": "you can assume T to be- to generally take on two values. The most common values for T,",
    "start": "2224195",
    "end": "2230599"
  },
  {
    "text": "are T of y equals y, and T of y equals y squared. Those are like the most common, uh,",
    "start": "2230600",
    "end": "2237289"
  },
  {
    "text": "kind of constraints that we come up with where we want to say the mean is something that, you know, the first moment is some particular value",
    "start": "2237290",
    "end": "2242900"
  },
  {
    "text": "and the second moment is some- some particular value. But here we are trying to derive it in the most general form where T could be anything.",
    "start": "2242900",
    "end": "2250890"
  },
  {
    "text": "And so using these constraints and the entropy objective, we will construct the Lagrangian.",
    "start": "2256570",
    "end": "2265020"
  },
  {
    "text": "So the Lagrangian L of P, eta, and lambda.",
    "start": "2268510",
    "end": "2278540"
  },
  {
    "text": "So this is the probability- the variable for the probability distribution itself.",
    "start": "2278540",
    "end": "2285680"
  },
  {
    "text": "And eta and lambda are Lagrange multipliers.",
    "start": "2285680",
    "end": "2290670"
  },
  {
    "text": "And the Lagrangian will be H of P plus the inner product of eta, comma,",
    "start": "2291490",
    "end": "2302805"
  },
  {
    "text": "TP minus C plus",
    "start": "2302805",
    "end": "2309895"
  },
  {
    "text": "lambda times the product of 1, P minus 1.",
    "start": "2309895",
    "end": "2317965"
  },
  {
    "text": "What is this? So here, P is our probability, uh, distribution.",
    "start": "2317965",
    "end": "2325145"
  },
  {
    "text": "You can think of P as you know P_1, P_2, P_n.",
    "start": "2325145",
    "end": "2332540"
  },
  {
    "text": "Where n is the cardinality of the set Y. And T is a matrix where we have you know,",
    "start": "2332540",
    "end": "2342470"
  },
  {
    "text": "T_1, a row corresponding to T1. So that would be T_1 of y_1,",
    "start": "2342470",
    "end": "2350855"
  },
  {
    "text": "T_1 of y_2, T_1 of y_N.",
    "start": "2350855",
    "end": "2357455"
  },
  {
    "text": "And similarly, we have m such T_m of y_1,",
    "start": "2357455",
    "end": "2366425"
  },
  {
    "text": "T_m of y_2, T_m of y_N.",
    "start": "2366425",
    "end": "2376490"
  },
  {
    "text": "So this is small m, the number of constraints times N. N is the cardinality of y,",
    "start": "2376490",
    "end": "2384485"
  },
  {
    "text": "and this is N. And our- our constraints say that",
    "start": "2384485",
    "end": "2390830"
  },
  {
    "text": "the inner product of this with this should be equal to C_1 until C_N.",
    "start": "2390830",
    "end": "2399870"
  },
  {
    "text": "Right? So this matrix times this vector equals this vector is capturing the set of all constraints under which we want to operate.",
    "start": "2399940",
    "end": "2409714"
  },
  {
    "text": "Right? So this inner product is like the expectation. So each- each row times a column is basically the expectation",
    "start": "2409715",
    "end": "2423395"
  },
  {
    "text": "under P of T- T1 of",
    "start": "2423395",
    "end": "2431450"
  },
  {
    "text": "y expectation under PT_2 of y",
    "start": "2431450",
    "end": "2437480"
  },
  {
    "text": "and expectation P, T_n of y.",
    "start": "2437480",
    "end": "2446960"
  },
  {
    "text": "Right? So this vector is equal to C_1 through C_N.",
    "start": "2446960",
    "end": "2457670"
  },
  {
    "text": "Right? So these two are equivalent ways of- of writing. Yes, question.",
    "start": "2457670",
    "end": "2465109"
  },
  {
    "text": "So the C's and the P's are like [inaudible]",
    "start": "2465110",
    "end": "2474530"
  },
  {
    "text": "So P is- so the question is, T's and the C's are the constraints that we choose to impose.",
    "start": "2474530",
    "end": "2479974"
  },
  {
    "text": "That's correct. And the C values are generally evaluated from data, right? So given some data, we- we see what the empirical values of- of the- the C's are,",
    "start": "2479975",
    "end": "2490520"
  },
  {
    "text": "and make that the constraints, what is P? So P is the probability distribution itself that we're trying to estimate, right?",
    "start": "2490520",
    "end": "2498230"
  },
  {
    "text": "So P must satisfy. P_i is greater than equal to 0 and sum over P_i,",
    "start": "2498230",
    "end": "2504860"
  },
  {
    "text": "i equals 1 to n should be equal to 1. Right? So P is the probability vector that we're trying to estimate.",
    "start": "2504860",
    "end": "2511940"
  },
  {
    "text": "And the way we want to estimate P is such that it- it maximizes the entropy and satisfies these constraints.",
    "start": "2511940",
    "end": "2520085"
  },
  {
    "text": "So let's say P_2 in that [inaudible] is the number of times we observe y_2 in all of your values.",
    "start": "2520085",
    "end": "2529925"
  },
  {
    "text": "So is P_2, the number of times we observe Y_2 and all of your y's in the long-running average?",
    "start": "2529925",
    "end": "2536734"
  },
  {
    "text": "Yes, the number of times we- we will observe y- y_2 across all y's.",
    "start": "2536735",
    "end": "2543500"
  },
  {
    "text": "So P_2 is just the probability of- of y_2. You know, think of P_2 as equal to P of y_2.",
    "start": "2543500",
    "end": "2554000"
  },
  {
    "text": "And is it possible for- most of the times we want like, we take a discrete sample of thetas and then process, like [BACKGROUND] but is it possible to put the intervals on the C's instead of like, hard-wire it?",
    "start": "2554000",
    "end": "2571520"
  },
  {
    "text": "Now- for now, we're going to- we're going to talk about only point values of C's, right?",
    "start": "2571520",
    "end": "2577160"
  },
  {
    "text": "Right, and so this is the set of constraints, right?",
    "start": "2577160",
    "end": "2583265"
  },
  {
    "text": "So TP minus C is the- is the, uh, set of constraints that should be equal to 0.",
    "start": "2583265",
    "end": "2588770"
  },
  {
    "text": "And this basically tells us-p so this is the entropy that we want to maximize.",
    "start": "2588770",
    "end": "2597000"
  },
  {
    "text": "This is for the constraints,",
    "start": "2597040",
    "end": "2602630"
  },
  {
    "text": "you know from data generally. Right? And this is to make- to make",
    "start": "2602630",
    "end": "2612664"
  },
  {
    "text": "P a valid- valid probability distribution.",
    "start": "2612665",
    "end": "2620970"
  },
  {
    "text": "Right? So we construct this Lagrangian and we- we pretty much just you know solve this optimization problem from this Lagrangian.",
    "start": "2623710",
    "end": "2634355"
  },
  {
    "text": "All right, so to solve this Lagrangian,",
    "start": "2634355",
    "end": "2650299"
  },
  {
    "text": "we do- first, we start with taking the derivative of the Lagrangian with respect to P's.",
    "start": "2650299",
    "end": "2656240"
  },
  {
    "text": "And we get a partial of- a partial with respect to P_i of the Lagrangian.",
    "start": "2656240",
    "end": "2665240"
  },
  {
    "text": "And this is equal to partial- partial with respect to P_i of H of P",
    "start": "2665240",
    "end": "2675470"
  },
  {
    "text": "plus eta minus TP minus C",
    "start": "2675470",
    "end": "2681359"
  },
  {
    "text": "plus lambda times 1, P minus 1.",
    "start": "2682000",
    "end": "2690810"
  },
  {
    "text": "All right, and now we, uh- uh, differentiate this with respect to P_i.",
    "start": "2693610",
    "end": "2700609"
  },
  {
    "text": "So H of P_i is sum over all- sum over i,",
    "start": "2700610",
    "end": "2705920"
  },
  {
    "text": "P of i times log P of i, right? So all the terms except the ith term can be eliminated.",
    "start": "2705920",
    "end": "2715444"
  },
  {
    "text": "So P_i this will be minus P_i log P_i.",
    "start": "2715444",
    "end": "2723200"
  },
  {
    "text": "We are ignoring the non i terms because they're gonna, you know, cancel with- with a Pi anyways,",
    "start": "2723200",
    "end": "2730370"
  },
  {
    "text": "plus TP minus C",
    "start": "2730370",
    "end": "2737960"
  },
  {
    "text": "and 1, P minus 1.",
    "start": "2737960",
    "end": "2744380"
  },
  {
    "text": "All right? And when we, um- uh, take the derivative, what we get is,",
    "start": "2744380",
    "end": "2750875"
  },
  {
    "text": "apply the product rule. Taking the derivative of this with respect to Pi first we differentiate the first term times the second term,",
    "start": "2750875",
    "end": "2758569"
  },
  {
    "text": "and then we differentiate the second term times the first term. So that will give us minus uh,",
    "start": "2758570",
    "end": "2765270"
  },
  {
    "text": "log P_i plus, the derivative of log p is just 1 over Pi,",
    "start": "2765400",
    "end": "2773690"
  },
  {
    "text": "uh, 1 over TP_i times Pi is just 1. Plus this will be just the inner product of eta times T",
    "start": "2773690",
    "end": "2785265"
  },
  {
    "text": "of y_i plus lambda.",
    "start": "2785265",
    "end": "2793130"
  },
  {
    "text": "Right? So what- what- what we're doing is when we are- in this- in this- uh,",
    "start": "2794460",
    "end": "2803474"
  },
  {
    "text": "in this expression which is basically TP minus C,",
    "start": "2803475",
    "end": "2808595"
  },
  {
    "text": "P_i will appear only in the- in the ith column here.",
    "start": "2808595",
    "end": "2815315"
  },
  {
    "text": "Right? So this ends up being eta and- and C will just cancel.",
    "start": "2815315",
    "end": "2821150"
  },
  {
    "text": "It will get canceled with- with the P_i. So this will be just the inner product of eta with T of y_i.",
    "start": "2821150",
    "end": "2826235"
  },
  {
    "text": "Right? And from this we basically get that,",
    "start": "2826235",
    "end": "2831890"
  },
  {
    "text": "uh, we want to take this derivative and set it equal to 0.",
    "start": "2831890",
    "end": "2838220"
  },
  {
    "text": "Which means we get, you know, I'll take, uh- uh,",
    "start": "2838220",
    "end": "2843800"
  },
  {
    "text": "so log P_i is equal to lambda",
    "start": "2843800",
    "end": "2850400"
  },
  {
    "text": "minus 1 plus inner product of eta times T of y_i.",
    "start": "2850400",
    "end": "2858809"
  },
  {
    "text": "And this gives us P_i is equal to e to the lambda minus",
    "start": "2861310",
    "end": "2870940"
  },
  {
    "text": "1 times exponential of eta times T of y_i.",
    "start": "2870940",
    "end": "2879670"
  },
  {
    "text": "Right?",
    "start": "2879670",
    "end": "2881730"
  },
  {
    "text": "Right away we see that P of i seems to be taking some kind of an exponential form, right?",
    "start": "2888900",
    "end": "2897535"
  },
  {
    "text": "And the- the, uh, the reason why we get this exponential form is because in the entropy we have this log term and when you set log of p equals,",
    "start": "2897535",
    "end": "2905725"
  },
  {
    "text": "you know, some value, p will be exponent of, you know, some value. That's the reason why, um,",
    "start": "2905725",
    "end": "2911964"
  },
  {
    "text": "you know with entropy- when you're trying to maximize entropy, the presence of this log term in the entropy will kind of",
    "start": "2911965",
    "end": "2918055"
  },
  {
    "text": "naturally result in an exponent coming when we solve for P_i. Now we have this and we want to solve for Lambda and solving for Lambda is pretty easy.",
    "start": "2918055",
    "end": "2931585"
  },
  {
    "text": "We have P_i equal to this and sum over i equals 1 to n, P_i equals 1,",
    "start": "2931585",
    "end": "2939730"
  },
  {
    "text": "which means the sum over this entire thing, e to the Lambda minus 1 times exponent theta times T of y_i.",
    "start": "2939730",
    "end": "2953155"
  },
  {
    "text": "This should be equal to 1 [NOISE] and so e to the Lambda minus 1 will",
    "start": "2953155",
    "end": "2963890"
  },
  {
    "text": "be 1 over sum over Y in script",
    "start": "2963890",
    "end": "2971289"
  },
  {
    "text": "y exponent eta times T of y, right?",
    "start": "2971290",
    "end": "2979885"
  },
  {
    "text": "So, uh, we got P to be in this form and we can eliminate Lambda by,",
    "start": "2979885",
    "end": "2986005"
  },
  {
    "text": "by making use of the fact that probability distribution should sum up to 1 and that gives,",
    "start": "2986005",
    "end": "2992020"
  },
  {
    "text": "um, e to the lambda, uh, lambda minus 1 to be, uh,",
    "start": "2992020",
    "end": "2997540"
  },
  {
    "text": "that value and so [NOISE] we get the final form of [NOISE] p of y to be,",
    "start": "2997540",
    "end": "3007300"
  },
  {
    "text": "p of y to be- so let's call this denominator to be [NOISE] - let's call this as Z of Eta.",
    "start": "3010700",
    "end": "3020025"
  },
  {
    "text": "So we get P of y is equal to exponent of",
    "start": "3020025",
    "end": "3025200"
  },
  {
    "text": "Eta times T of y divided by Z of Eta,",
    "start": "3025200",
    "end": "3031650"
  },
  {
    "text": "where Z of Eta is just this, um-um, normalizing constant and so P of y parameterized by Eta is equal",
    "start": "3031650",
    "end": "3039720"
  },
  {
    "text": "to the exponent of Eta times T of y minus a of Eta,",
    "start": "3039720",
    "end": "3047220"
  },
  {
    "text": "where a is just [NOISE] equal to log z, right?",
    "start": "3047220",
    "end": "3058410"
  },
  {
    "text": "So Z is called a partition function and a is called the log partition function, right?",
    "start": "3058410",
    "end": "3063660"
  },
  {
    "text": "And by taking the log, we can bring it, uh, in into the term, right? So we-here we see that by just, uh,",
    "start": "3063660",
    "end": "3071685"
  },
  {
    "text": "by-by just following the maximum entropy principle and trying to recover P where we did not assume any kind of form for P, right?",
    "start": "3071685",
    "end": "3080970"
  },
  {
    "text": "We just assume P was, you know, um-um, any-any, um, can take, um, can take any, uh,",
    "start": "3080970",
    "end": "3087150"
  },
  {
    "text": "values subject to it just being a valid probability distribution. We see that by, uh,",
    "start": "3087150",
    "end": "3093029"
  },
  {
    "text": "by having only this constraint, maximizing the entropy of P,",
    "start": "3093030",
    "end": "3099570"
  },
  {
    "text": "[NOISE] to satisfy the- the, uh, constraints that we observe from the data,",
    "start": "3099570",
    "end": "3105390"
  },
  {
    "text": "we recover the exponential family that, uh, we- we recover the exponential family form for P,",
    "start": "3105390",
    "end": "3111540"
  },
  {
    "text": "that P of y will always be in- in the form of the exponential family, basically.",
    "start": "3111540",
    "end": "3117730"
  },
  {
    "text": "Yes. So within the inner max, why did you take [inaudible] with this types of some of the inputs finally already",
    "start": "3117800",
    "end": "3123299"
  },
  {
    "text": "captured with the space? So this- what we did here is basically enforcing this constraint.",
    "start": "3123300",
    "end": "3131400"
  },
  {
    "text": "Do we have to do it explicitly again? I'm sorry. Do we have to do it explicitly again or should it already be captured in the math?",
    "start": "3131400",
    "end": "3140140"
  },
  {
    "text": "So the question is, should we explicitly do this or is it already,",
    "start": "3140140",
    "end": "3145200"
  },
  {
    "text": "uh-uh, you know, um, captured in the math? So if we don't have this constraint, then, you know,",
    "start": "3145200",
    "end": "3150390"
  },
  {
    "text": "P's can be any you know, arbitrary value, right? Also, and why don't we use entropy as an added value of those? [inaudible]",
    "start": "3150390",
    "end": "3160040"
  },
  {
    "start": "3160000",
    "end": "3390000"
  },
  {
    "text": "Yes. So the question is, uh, why are we maximizing entropy? And, uh, there is-there is,",
    "start": "3160040",
    "end": "3165380"
  },
  {
    "text": "uh, reference in the notes that's, that's been posted, which, which goes into why maximizing entropy is kind of a natural thing to do.",
    "start": "3165380",
    "end": "3173434"
  },
  {
    "text": "So basically, this maximum entropy principle has-has, you know has also a connection with statistical physics, where you know, um -um,",
    "start": "3173435",
    "end": "3179760"
  },
  {
    "text": "where the entropy has actually the same mathematical form and in fact, there's a paper by, you know, um,",
    "start": "3179760",
    "end": "3185920"
  },
  {
    "text": "uh, by an author his name is [NOISE] in fact, the same author of the link that's given here, Edwin Jaynes.",
    "start": "3185920",
    "end": "3193590"
  },
  {
    "text": "He has an old paper called, um, uh, Information Theory and Statistical Physics and that basically you know,",
    "start": "3193590",
    "end": "3200805"
  },
  {
    "text": "draws this nice connection between information theory or you know, the Shannon's entropy, uh, the-the entropy that we have here in information theory and,",
    "start": "3200805",
    "end": "3208109"
  },
  {
    "text": "uh, you know drawing connections to the, um, uh, thermodynamics entropy in statistical physics and both of them kind of follow the same maximum entropy principle.",
    "start": "3208110",
    "end": "3215910"
  },
  {
    "text": "So it's-it's-it's, uh, it's kind of a natural thing to do. Yes, was there another question, yes.",
    "start": "3215910",
    "end": "3221010"
  },
  {
    "text": "Are you also going to check this principle of parameterization? So here- so the parameterization was always there,",
    "start": "3221010",
    "end": "3228180"
  },
  {
    "text": "I just didn't write it here. But, uh, where is a of Eta?",
    "start": "3228180",
    "end": "3233520"
  },
  {
    "text": "So a of Eta- so, uh, we-we, um,",
    "start": "3233520",
    "end": "3239400"
  },
  {
    "text": "so P of i is basically equal to P of y_i, right?",
    "start": "3239400",
    "end": "3245654"
  },
  {
    "text": "So P of y_i is equal to this times this, and this is equal to 1 over Z of Eta, right?",
    "start": "3245655",
    "end": "3254099"
  },
  {
    "text": "So P of y is equal to this divided by 1 over Eta, 1-1,uh, over Z of Eta, right?",
    "start": "3254100",
    "end": "3261795"
  },
  {
    "text": "And Z of Eta is the partition function and in place of Z, if we instead take a of-,",
    "start": "3261795",
    "end": "3268035"
  },
  {
    "text": "uh, a is equal to log of Z, then a will just go in-in into the numerator. Next question.",
    "start": "3268035",
    "end": "3274635"
  },
  {
    "text": "Why do you want to maximize the entropy? Yeah, so maximizing the- so the question is why do you want to maximize the entropy?",
    "start": "3274635",
    "end": "3281910"
  },
  {
    "text": "So maximizing the entropy. You know, um, there are arguments to- to, uh, to say that by maximizing the entropy,",
    "start": "3281910",
    "end": "3288555"
  },
  {
    "text": "we are kind of being least committal in terms of our, um, uh, assumptions which means the only constraints that we are,",
    "start": "3288555",
    "end": "3296580"
  },
  {
    "text": "uh, enforcing is that, um, you know, the- the, um, the data that- the- the observed data",
    "start": "3296580",
    "end": "3303599"
  },
  {
    "text": "that we have are the only constraints that we are doing. Any other objective if- if you maximize, uh, any other objective?",
    "start": "3303600",
    "end": "3310569"
  },
  {
    "text": "It can be shown that we are kind of imposing further assumptions, um,",
    "start": "3310700",
    "end": "3315900"
  },
  {
    "text": "that may not be, you know may or may not be, uh-uh, may or may not be valid. In order to get the most unbiased estimate of p, then the, uh,",
    "start": "3315900",
    "end": "3325650"
  },
  {
    "text": "then the right thing to do is to maximize the entropy, which means make everything else as uncertain as possible,",
    "start": "3325650",
    "end": "3332174"
  },
  {
    "text": "subject to the only constra- the observed constraints that we have.",
    "start": "3332175",
    "end": "3336250"
  },
  {
    "text": "Is there a link between this and the maximum likelihood? Yeah, we're gonna come to the link to maximum likelihood shortly, right? Next question.",
    "start": "3338750",
    "end": "3345705"
  },
  {
    "text": "So you said  uh, entropy can be thought of as the variability of the uncertainty,",
    "start": "3345705",
    "end": "3352065"
  },
  {
    "text": "can it directly then be thought about as the variance? So you want to capture as much variance from.",
    "start": "3352065",
    "end": "3357570"
  },
  {
    "text": "Yes. Yeah, so- so the question is- is can you think of uncertainty as the variance? The short answer is no and there are good reasons why variance is- is not always,",
    "start": "3357570",
    "end": "3367724"
  },
  {
    "text": "um, equivalent to uncertainty. So the, you know, there is, uh, a link to a chapter, uh, in-in the notes that's given,",
    "start": "3367725",
    "end": "3373560"
  },
  {
    "text": "you know Chapter 11 from the book Probability Theory. And that actually has some pretty convincing reasons why entro- variance is not right,",
    "start": "3373560",
    "end": "3381780"
  },
  {
    "text": "uh, thing to maximize for. Okay, and two more questions, in L, what are the last two terms?",
    "start": "3381780",
    "end": "3387240"
  },
  {
    "text": "So these two are the Lagrange multipliers. No, on the right-hand side. These two- so these two are the- are the, uh,",
    "start": "3387240",
    "end": "3394305"
  },
  {
    "text": "terms in the, uh, Lagrangian that corresponds to the constraints, right? So one constraint is based on, um,",
    "start": "3394305",
    "end": "3401174"
  },
  {
    "text": "based on, uh, the-the data that we have, and the other constraint is that P should sum to 1.",
    "start": "3401175",
    "end": "3406335"
  },
  {
    "text": "Why is, why is that [inaudible] like inner product of 1 and P?",
    "start": "3406335",
    "end": "3412155"
  },
  {
    "text": "So inner product of 1 and P is. [NOISE] So that's what",
    "start": "3412155",
    "end": "3422640"
  },
  {
    "text": "the inner product of the one vector and P. And the second one? The second one?",
    "start": "3422640",
    "end": "3428345"
  },
  {
    "text": "Yeah. So the second one is, you know, T of P minus C. So we want T of P equal to C, right?",
    "start": "3428345",
    "end": "3435380"
  },
  {
    "text": "So T of P minus C should be 0 and this is the Lagrange multiplier corresponding to that constraint. Next question.",
    "start": "3435380",
    "end": "3445480"
  },
  {
    "text": "Far from the word N since large N is the size of all the Y_N?",
    "start": "3445850",
    "end": "3451035"
  },
  {
    "text": "Yeah, so, so the large- so the large N corresponds to the support of the prob of- of y.",
    "start": "3451035",
    "end": "3458130"
  },
  {
    "text": "[inaudible]. And small n is the- you can think of it as the number of",
    "start": "3458130",
    "end": "3464460"
  },
  {
    "text": "observed data points. Is the support of. To every possible one?",
    "start": "3464460",
    "end": "3469830"
  },
  {
    "text": "Yes, every possible Y. Okay, so large N is the cardinality of script Y. Yeah.",
    "start": "3469830",
    "end": "3476055"
  },
  {
    "text": "Why do you take the inner product of T_P minus C with Eta. So I get that T_P minus C- but then like going with the last term,",
    "start": "3476055",
    "end": "3484740"
  },
  {
    "text": "shouldn't it be just some like let's say some new multiplier times T_P minus C, inner product of that.",
    "start": "3484740",
    "end": "3491720"
  },
  {
    "text": "Well, so, um, I'll not go into the details of this- this what- what we have here is correct. If you have any more questions, and you post it on Piazza,",
    "start": "3491720",
    "end": "3498619"
  },
  {
    "text": "I can - I can help, uh, uh, clarify there. But, you know, this - this is the correct formulation of the Lagrangian, all right?",
    "start": "3498620",
    "end": "3504860"
  },
  {
    "text": "So ,uh, so we get that, uh, p of- p of y will- will always take this form,",
    "start": "3504860",
    "end": "3512900"
  },
  {
    "text": "where t of y, which were basically the constraints end up being",
    "start": "3512900",
    "end": "3517940"
  },
  {
    "text": "the sufficient statistics of the, uh, exponential family. And, um, eta, which was the Lagrange multiplier of",
    "start": "3517940",
    "end": "3527300"
  },
  {
    "text": "our constraints end up being the- the natural parameter of the exponential family.",
    "start": "3527300",
    "end": "3533075"
  },
  {
    "text": "And a of eta- a of eta, which is the log partition function is essentially,",
    "start": "3533075",
    "end": "3538640"
  },
  {
    "text": "the partition function that we get by applying the, uh, uh, valid probability distribution constraint, right?",
    "start": "3538640",
    "end": "3545119"
  },
  {
    "text": "So maximum- maximizing entropy gives us the exponential family as a natural consequence.",
    "start": "3545120",
    "end": "3553475"
  },
  {
    "text": "We made no assumptions about the functional form of p when we started out maximizing the entropy.",
    "start": "3553475",
    "end": "3559790"
  },
  {
    "text": "But as a consequence of performing this maximizing entropy subject to some linear constraints,",
    "start": "3559790",
    "end": "3566650"
  },
  {
    "text": "we get the exponential family as a consequence, right? So, uh, was there another question? Yes.",
    "start": "3566650",
    "end": "3573190"
  },
  {
    "text": "[inaudible]",
    "start": "3573190",
    "end": "3579980"
  },
  {
    "text": "So the question is, uh, for any given dataset do we get a different family? So, uh, good question.",
    "start": "3579980",
    "end": "3585950"
  },
  {
    "text": "So the- the- the family that we end up getting is gonna depend on the choice of the sufficient statistics that we choose.",
    "start": "3585950",
    "end": "3596160"
  },
  {
    "text": "For a different dataset, we will get different values of Cs, right?",
    "start": "3596800",
    "end": "3602480"
  },
  {
    "text": "But the choice of the constraints that we- that we, uh- uh, chose to- to enforce will decide the family of the exponential family.",
    "start": "3602480",
    "end": "3611690"
  },
  {
    "text": "[inaudible] are you going to get one distribution?",
    "start": "3611690",
    "end": "3618605"
  },
  {
    "text": "So like how do you find eta given- So we're gonna come to estimating eta now, right?",
    "start": "3618605",
    "end": "3624545"
  },
  {
    "text": "So the function and form of P will be in the exponential family if we start off by",
    "start": "3624545",
    "end": "3633214"
  },
  {
    "text": "maximizing the entropy of p, subject to some constraints, right? So now, the question is of- okay,",
    "start": "3633215",
    "end": "3639410"
  },
  {
    "text": "so we- we saw that the function or the- the- the- the probability distribution will belong to the exponential family.",
    "start": "3639410",
    "end": "3648320"
  },
  {
    "text": "But what about the estimates of eta itself? [NOISE]",
    "start": "3648320",
    "end": "3663530"
  },
  {
    "text": "So for that, now let us- to- to calculate eta. So first we solve that with respect to p_i.",
    "start": "3663530",
    "end": "3670430"
  },
  {
    "text": "Next we will do it with respect to eta, right? So with respect to eta of L is equal to gradient with respect to eta.",
    "start": "3670430",
    "end": "3682020"
  },
  {
    "text": "H of p is just minus sum over y,",
    "start": "3682060",
    "end": "3687304"
  },
  {
    "text": "t of y log p of y, plus I'm gonna write this as,",
    "start": "3687304",
    "end": "3698090"
  },
  {
    "text": "uh, the inner product between eta times T p minus eta times",
    "start": "3698090",
    "end": "3709325"
  },
  {
    "text": "C plus Lambda of something.",
    "start": "3709325",
    "end": "3715290"
  },
  {
    "text": "And now we will make a few more observations. So this is the gradient with respect to eta of, so here,",
    "start": "3716050",
    "end": "3725495"
  },
  {
    "text": "this is basically the sum over y, p of y times log p of y.",
    "start": "3725495",
    "end": "3732980"
  },
  {
    "text": "So we saw that p of y has this form. And when we take the log of this,",
    "start": "3732980",
    "end": "3738065"
  },
  {
    "text": "we just get the term inside the, um, inside the flower brackets. So it is p of y times eta dot t of",
    "start": "3738065",
    "end": "3749300"
  },
  {
    "text": "y minus a of eta plus eta times T p. So what is T p?",
    "start": "3749300",
    "end": "3761170"
  },
  {
    "text": "We saw that T p, T p is just the expectations of the individual sufficient statistics.",
    "start": "3761170",
    "end": "3768355"
  },
  {
    "text": "So this, I'm gonna just write it as expectation of P of t of y",
    "start": "3768355",
    "end": "3776465"
  },
  {
    "text": "minus eta times C plus Lambda of something, right?",
    "start": "3776465",
    "end": "3786650"
  },
  {
    "text": "So now take the derivative inside. And here we get, um,",
    "start": "3786650",
    "end": "3792305"
  },
  {
    "text": "so this, you know, sum over y, P of y times something is like taking the expectation of this,",
    "start": "3792305",
    "end": "3798410"
  },
  {
    "text": "eta and eta will cancel. So we can write this as minus expected,",
    "start": "3798410",
    "end": "3805280"
  },
  {
    "text": "so take the eta out. So this will be eta times- oh, so- sorry.",
    "start": "3805280",
    "end": "3815735"
  },
  {
    "text": "We still have- let's still keep the derivative with respect to eta. So eta times expectation of T of y.",
    "start": "3815735",
    "end": "3828425"
  },
  {
    "text": "And here we're taking the expectation of a of eta, but there's no y term here. So this will just be a of eta.",
    "start": "3828425",
    "end": "3836420"
  },
  {
    "text": "This is plus eta times expectation of P of T of",
    "start": "3836420",
    "end": "3841609"
  },
  {
    "text": "y minus eta dot c plus Lambda times something, right?",
    "start": "3841610",
    "end": "3848285"
  },
  {
    "text": "So this and this cancel, so we get with respect to eta of a of",
    "start": "3848285",
    "end": "3855650"
  },
  {
    "text": "eta minus eta dot c",
    "start": "3855650",
    "end": "3860339"
  },
  {
    "text": "plus some constant c plus some Lambda times something.",
    "start": "3860950",
    "end": "3867440"
  },
  {
    "text": "And this is equal to a prime of eta minus c,",
    "start": "3867440",
    "end": "3874068"
  },
  {
    "text": "and this should be equal to 0. And this gives us a prime of eta is equal to c. And",
    "start": "3874069",
    "end": "3880460"
  },
  {
    "text": "these constraints are things that we generally want to estimate from data, right?",
    "start": "3880460",
    "end": "3885980"
  },
  {
    "text": "And so we get, uh, eta hat is equal to a prime inverse of c,",
    "start": "3885980",
    "end": "3896285"
  },
  {
    "text": "and that means A prime inverse of C,",
    "start": "3896285",
    "end": "3902420"
  },
  {
    "text": "which we want to be like the empirical averages from data. So that would be one over n sum i equals 1 to n T of y_ i, right?",
    "start": "3902420",
    "end": "3916550"
  },
  {
    "text": "And this estimate [NOISE] you will see,",
    "start": "3916550",
    "end": "3927350"
  },
  {
    "text": "is the same as this estimate.",
    "start": "3927350",
    "end": "3931110"
  },
  {
    "text": "So the last step here. So from here, here we got that a prime of eta,",
    "start": "3933250",
    "end": "3939724"
  },
  {
    "text": "which is just, uh, a prime of eta, should be equal to c, right? Is it clear until this step, yeah?",
    "start": "3939725",
    "end": "3945605"
  },
  {
    "text": "So eta should be a prime of inverse of c. Now what is c? C were the constraints that we started with,",
    "start": "3945605",
    "end": "3953855"
  },
  {
    "text": "and usually these constraints come from data, right? So these constraints will be the actual,",
    "start": "3953855",
    "end": "3959765"
  },
  {
    "text": "you know, sample means of the corresponding sufficient statistics.",
    "start": "3959765",
    "end": "3965449"
  },
  {
    "text": "And you plug them in here, the, uh, the, uh- uh, sample means of the corresponding sufficient statistics and we get",
    "start": "3965449",
    "end": "3973760"
  },
  {
    "text": "eta hat maximum entropy [NOISE] ,",
    "start": "3973760",
    "end": "3979850"
  },
  {
    "text": "maximum entropy to be equal to the same, uh, expression that we get using MLE.",
    "start": "3979850",
    "end": "3988290"
  },
  {
    "text": "So here- so the question is, what is T here? Yes, T here is, you can think of it as the vector of, you know,",
    "start": "3990730",
    "end": "3997819"
  },
  {
    "text": "j-functions, exactly, right? So what we basically got is that the- is that, uh,",
    "start": "3997820",
    "end": "4008035"
  },
  {
    "text": "maximizing the entropy subject to some constraints of sufficient statistics that, um, are, uh,",
    "start": "4008035",
    "end": "4017230"
  },
  {
    "text": "whose values are obtained from the data is in fact the same- gives you the same solution as starting off with",
    "start": "4017230",
    "end": "4024450"
  },
  {
    "text": "an exponential family where the sufficient statistics are the sufficient statistics of",
    "start": "4024450",
    "end": "4029460"
  },
  {
    "text": "that exponential family and performing maximum likelihood on it. So this- this, uh, equivalence between- between",
    "start": "4029460",
    "end": "4037645"
  },
  {
    "text": "maximum likelihood and maximum entropy is- is, um, turns out to be,",
    "start": "4037645",
    "end": "4044130"
  },
  {
    "text": "you know, one of- one of, you know, one of the few interesting results in this area.",
    "start": "4044130",
    "end": "4049915"
  },
  {
    "text": "Any questions on this? Yes, question. [inaudible]",
    "start": "4049915",
    "end": "4057369"
  },
  {
    "text": "So a function will- the a prime will always have an inverse. [NOISE] Yes, question?",
    "start": "4057370",
    "end": "4066370"
  },
  {
    "text": "[inaudible]",
    "start": "4066370",
    "end": "4089670"
  },
  {
    "text": "So a prime is the mean of the probability distribution and basically what we are",
    "start": "4089670",
    "end": "4095700"
  },
  {
    "text": "telling is that we want the mean of the- of the, uh, uh, uh, probability distribution to be the sample mean,",
    "start": "4095700",
    "end": "4103049"
  },
  {
    "text": "you know, is essentially what we're trying to say here. So CI's were the- were the, uh, uh,",
    "start": "4103050",
    "end": "4108180"
  },
  {
    "text": "means of the, uh, uh, means of the data, so here, we are trying to say model mean equals sample mean.",
    "start": "4108180",
    "end": "4113640"
  },
  {
    "text": "[BACKGROUND] Yeah, we- we- we got this from the maximum entropy, right? So we are still deriving the Lagrangian of the maximum entropy, uh,",
    "start": "4113640",
    "end": "4122009"
  },
  {
    "text": "objective, and by solving for eta, we end up with the same, uh, estimate for- uh,",
    "start": "4122010",
    "end": "4127109"
  },
  {
    "text": "for eta as we would have if we had started from exponential family directly and chosen our Ts to be,",
    "start": "4127110",
    "end": "4134880"
  },
  {
    "text": "um, the- the- the sufficient statistics we're interested in. Yes, question. We are talking about the very last step here, so-.",
    "start": "4134880",
    "end": "4143025"
  },
  {
    "text": "Here? - in the range box. Yes. So when we say Cis equals to 1 over n,",
    "start": "4143025",
    "end": "4148380"
  },
  {
    "text": "sum over the Yi, aren't we constraining like all Cs to be some kinda average of like all Cs?",
    "start": "4148380",
    "end": "4156194"
  },
  {
    "text": "Yes. So for- for- for, ah, in- in this setting, we are interested in linear constraints.",
    "start": "4156195",
    "end": "4162420"
  },
  {
    "text": "That is linear in P, which means we are only interested in, you know, things like moments of the data,",
    "start": "4162420",
    "end": "4168180"
  },
  {
    "text": "the moments of the distribution. When you do that is that like- will that like be called- so initially Cs were weighed by the Ps?",
    "start": "4168180",
    "end": "4176700"
  },
  {
    "text": "Cs were what? Like we were weighing them by the Ps?",
    "start": "4176700",
    "end": "4181964"
  },
  {
    "text": "Cs were not weighed by the P,. Cs were just the observed, um-. So C1 will be T1Y1, plus T1Y1 times two P2?",
    "start": "4181965",
    "end": "4188920"
  },
  {
    "text": "Right. That's the constraint that we want to enforce, that C1 equals T1Y1 times P1 plus T1Y1 times P2.",
    "start": "4191030",
    "end": "4198540"
  },
  {
    "text": "That's the constraint that we want to enforce. But C1, the value of C1 itself is estimated from data.",
    "start": "4198540",
    "end": "4203835"
  },
  {
    "text": "And there has to be some [inaudible]. Yeah, th-this is what, you know,",
    "start": "4203835",
    "end": "4209490"
  },
  {
    "text": "we would choose to choose-. Cs according to this. Cs according to this. Exactly. Yeah. All right,",
    "start": "4209490",
    "end": "4216300"
  },
  {
    "text": "so- so we've seen that maximizing entropy is the same as maximizing uh, likelihood.",
    "start": "4216300",
    "end": "4225150"
  },
  {
    "text": "And in your homework you've also seen that maximizing likelihood is also the same as MLEt',",
    "start": "4225150",
    "end": "4233745"
  },
  {
    "text": "is also the same as minimizing the KL divergence between",
    "start": "4233745",
    "end": "4240130"
  },
  {
    "text": "the sample data and- and the model, right?",
    "start": "4240130",
    "end": "4248300"
  },
  {
    "text": "This is in your homework, um, um, you know, question 2 or 3, the last subpart. Uh, so- so, uh,",
    "start": "4248300",
    "end": "4256445"
  },
  {
    "text": "the- and this is equal to, you know, max entropy.",
    "start": "4256445",
    "end": "4261480"
  },
  {
    "text": "Now the connection between maximizing entropy and minimizing KL divergence is also, you know,",
    "start": "4261480",
    "end": "4268395"
  },
  {
    "text": "called the max and duality theory-Duality theorem.",
    "start": "4268395",
    "end": "4277000"
  },
  {
    "text": "For those of you who are probably more interested on the theoretical sides, you know, then to- to kind of learn more about this duality theorem,",
    "start": "4278990",
    "end": "4287805"
  },
  {
    "text": "you know, you might want to look up the maximum entropy Duality theorem. All right. Now let's- let's- let's um,",
    "start": "4287805",
    "end": "4297630"
  },
  {
    "text": "talk about a very related, somewhat related to our topic, which is calibration.",
    "start": "4297630",
    "end": "4304980"
  },
  {
    "text": "Okay. [BACKGROUND] So calibration is the problem- is this concept that,",
    "start": "4304980",
    "end": "4312060"
  },
  {
    "text": "so for example, when- when we studied logistic regression, we saw that the output of our logistic regression model",
    "start": "4312060",
    "end": "4320745"
  },
  {
    "text": "was we took the- in a product between x and theta,",
    "start": "4320745",
    "end": "4326805"
  },
  {
    "text": "where theta was some kind of a parameter, run it through the logistic function,",
    "start": "4326805",
    "end": "4333224"
  },
  {
    "text": "you know,1 over 1 plus e to the minus x and as the output, we got a value that was always between 0 and 1 and we call that value, um,",
    "start": "4333225",
    "end": "4344414"
  },
  {
    "text": "and when we did y hat equals 1 over 1 plus you know, exponent of minus Theta transpose x, right?",
    "start": "4344415",
    "end": "4354060"
  },
  {
    "text": "So this will always be between 0 and 1. Which superficially looks like a probability, right,",
    "start": "4354060",
    "end": "4363520"
  },
  {
    "text": "because it-it's a value between 0 and 1. But what will make it a probability, right?",
    "start": "4364820",
    "end": "4371460"
  },
  {
    "text": "Superficially, it's a value between 0 and 1 and then we, ah, in order to use it as a classifier,",
    "start": "4371460",
    "end": "4376500"
  },
  {
    "text": "we decided to use some threshold and, you know, call everything above the threshold as positives, everything below as negatives.",
    "start": "4376500",
    "end": "4382260"
  },
  {
    "text": "But what- what will, you know- why do we want to think of this as a probability? Right? So probability has- has- has you know- all right.",
    "start": "4382260",
    "end": "4391620"
  },
  {
    "text": "So let me pose a question to you. What do you think is probability? Yes? If sum of all the y hat is equal to 1, it's called superficial requirement.",
    "start": "4391620",
    "end": "4398050"
  },
  {
    "text": "Yeah, so if sum of all the y hats equals 1, ah, I would still call that a superficial requirement for something to be a probability. Yes.",
    "start": "4399500",
    "end": "4410539"
  },
  {
    "text": "[inaudible]",
    "start": "4410540",
    "end": "4415820"
  },
  {
    "text": "Exactly. So the value of y should be somehow representative of how frequently we,",
    "start": "4415820",
    "end": "4422070"
  },
  {
    "text": "uh, you know y hat ends up being this in, you know, for example, the data that we have, right?",
    "start": "4422070",
    "end": "4427260"
  },
  {
    "text": "So and this- this property that the estimated probability values kind of match",
    "start": "4427260",
    "end": "4436740"
  },
  {
    "text": "with observed frequency of occurrences is called calibration.",
    "start": "4436740",
    "end": "4441780"
  },
  {
    "text": "Right. So it is very common and highly recommended that if you actually build a logistic regression model,",
    "start": "4441780",
    "end": "4451155"
  },
  {
    "text": "that you also plot this calibration plot. Okay. So calibration plot will look something like this.",
    "start": "4451155",
    "end": "4458860"
  },
  {
    "text": "Predicted probability and here this is the observed frequencies.",
    "start": "4459980",
    "end": "4468750"
  },
  {
    "text": "[BACKGROUND] Now,",
    "start": "4468750",
    "end": "4478470"
  },
  {
    "text": "let's say this between zero and one. Take your validation set.",
    "start": "4478470",
    "end": "4485264"
  },
  {
    "text": "In your validation set, assume it's, it's reasonably large, you know, you have a few 1,000 or 10,000 examples in your validation set.",
    "start": "4485265",
    "end": "4492390"
  },
  {
    "text": "Take your model and run every example in your validation set through your model.",
    "start": "4492390",
    "end": "4499860"
  },
  {
    "text": "For each example, you get a particular y hat, all right? So you get a y hat.",
    "start": "4499860",
    "end": "4506370"
  },
  {
    "text": "And there is a corresponding Yi, which is the ground truth, all right?",
    "start": "4506370",
    "end": "4511750"
  },
  {
    "text": "Now, y hat will be a value between 0 and 1 and y will be either 0 or 1, right?",
    "start": "4512000",
    "end": "4523695"
  },
  {
    "text": "And then your y hats will be, you know, points that are distributed in this interval between 0 and 1.",
    "start": "4523695",
    "end": "4530700"
  },
  {
    "text": "Now, next, you know, chop this interval between 0 and 1 into say,",
    "start": "4530700",
    "end": "4536310"
  },
  {
    "text": "10 bins, maybe 100 bins, doesn't matter. So chop it into bins.",
    "start": "4536310",
    "end": "4542080"
  },
  {
    "text": "Commonly, you know, it is 10 bins, but you know, it could be any number of bins and collect",
    "start": "4544460",
    "end": "4550800"
  },
  {
    "text": "the Yi\"s in each bin separately or the y-hat i's in each bin  separately, right?",
    "start": "4550800",
    "end": "4559094"
  },
  {
    "text": "So the set of all examples that have a y hat in this- in this- that- that is assigned a value in this range,",
    "start": "4559095",
    "end": "4568260"
  },
  {
    "text": "take those examples and calculate the mean of the true labels of all the points that fall in this bin,",
    "start": "4568260",
    "end": "4577454"
  },
  {
    "text": "right and plot the- the true mean or the mean of the true labels on the y-axis",
    "start": "4577455",
    "end": "4583635"
  },
  {
    "text": "corresponding to this bin and ideally what you want is to get a plot that looks like this.",
    "start": "4583635",
    "end": "4590380"
  },
  {
    "text": "Which means for- for all those examples that got assigned the probability of say,",
    "start": "4594020",
    "end": "4601470"
  },
  {
    "text": "0.99, we want 99% of them- of those examples to have the true label as Yi.",
    "start": "4601470",
    "end": "4609540"
  },
  {
    "text": "For all examples that had a predicted probability of close to 0.5,",
    "start": "4610130",
    "end": "4615975"
  },
  {
    "text": "we want the true frequency of the labels or the frequency of the true labels to be close to 0.5.",
    "start": "4615975",
    "end": "4623925"
  },
  {
    "text": "This kind of a plot, where do you- where you plot the predicted probabilities versus observed frequencies is",
    "start": "4623925",
    "end": "4631920"
  },
  {
    "text": "called a calibration plot and if your model gives you a calibration plot,",
    "start": "4631920",
    "end": "4637980"
  },
  {
    "text": "which is a straight line, then you call your model to be well-calibrated, which means the predicted- the output y hats from your model,",
    "start": "4637980",
    "end": "4646335"
  },
  {
    "text": "you can actually think of them as probability estimates. If- if this line is not a straight line,",
    "start": "4646335",
    "end": "4654945"
  },
  {
    "text": "then the predicted probabilities, you can't really think of them as probability estimates anymore. It may still be a good classifier, right?",
    "start": "4654945",
    "end": "4662205"
  },
  {
    "text": "You- you may still be able to find a separating threshold and assign 0s and 1s and you may get a high accuracy,",
    "start": "4662205",
    "end": "4668550"
  },
  {
    "text": "but it may not be a good probability estimate, right? So this- this concept of calibration.",
    "start": "4668550",
    "end": "4677020"
  },
  {
    "text": "So calibration tells us, you know, it's a statement about the quality of y hat being an actual probability.",
    "start": "4677960",
    "end": "4692970"
  },
  {
    "text": "[BACKGROUND] So if you have a model that predicts the probability of whether it's going to rain",
    "start": "4692970",
    "end": "4699810"
  },
  {
    "text": "tomorrow and take the, and you run it every day and you have a few thousand days of predictions, right?",
    "start": "4699810",
    "end": "4708869"
  },
  {
    "text": "Now, take the set of all examples or the set of all days where the predicted next day probability rain was say, 80%.",
    "start": "4708870",
    "end": "4718125"
  },
  {
    "text": "And then look at the data and see what fraction of those days did it actually rain?",
    "start": "4718125",
    "end": "4724095"
  },
  {
    "text": "If your model is well calibrated, then the fraction of days that it rained the next day should be approximately 80%.",
    "start": "4724095",
    "end": "4730755"
  },
  {
    "text": "It shouldn't be 90, it shouldn't be 70. It should be 80 for it to be well-calibrated. Yes, question.",
    "start": "4730755",
    "end": "4737795"
  },
  {
    "text": "Two question. If it is a good classif- good classifier- why do we care if it is a good probability major or not?",
    "start": "4737795",
    "end": "4744810"
  },
  {
    "text": "And secondly, if it is not a quantified degree what can you do to solve it?",
    "start": "4744810",
    "end": "4752285"
  },
  {
    "text": "Yeah. So, uh, good, good questions. So, um, if all we care about is a good classifier,",
    "start": "4752285",
    "end": "4758380"
  },
  {
    "text": "then why do we care whether the predicted y hat is a valid probability or not?",
    "start": "4758380",
    "end": "4763449"
  },
  {
    "text": "And the reason is because, um, whenever you're making- uh, building a machine learning model that predicts something into the future,",
    "start": "4763450",
    "end": "4771320"
  },
  {
    "text": "it is m- it is- mo- mo- most of the times you know, you don't really want,",
    "start": "4771420",
    "end": "4777775"
  },
  {
    "text": "uh- uh- a binary answer from a model. You actually do want some kind of an uncertainty estimate coming out of the model.",
    "start": "4777775",
    "end": "4785139"
  },
  {
    "text": "Which means you actually care, you know how certain is your model about this prediction into the future? If it has a prediction, you know say a",
    "start": "4785140",
    "end": "4792175"
  },
  {
    "text": "you know, 51% percent probability that it's gonna rain, versus another, you know situation where it",
    "start": "4792175",
    "end": "4798820"
  },
  {
    "text": "gives you a ninety seven percent probability that it's gonna rain. You wanna kind of treat those two predictions, you know differently.",
    "start": "4798820",
    "end": "4806230"
  },
  {
    "text": "If you just think of it as a classifier, both of them will be classified as Y equals 1, right?",
    "start": "4806230",
    "end": "4812095"
  },
  {
    "text": "But, um, but when you're- you're when you're trying to make decisions about- about you know, about the future or in general you- you know,",
    "start": "4812095",
    "end": "4818620"
  },
  {
    "text": "many you times you actually want this uncertainty estimate as well. Right? And what do we do if it is not uh, calibrated?",
    "start": "4818620",
    "end": "4827920"
  },
  {
    "text": "So there are techniques to re-calibrate the model.",
    "start": "4827920",
    "end": "4832460"
  },
  {
    "text": "So there are some techniques to recalibrate a model and one of them is called Platt scaling,",
    "start": "4834110",
    "end": "4840910"
  },
  {
    "text": "or uh, you can also use something called iso- isotonic regression.",
    "start": "4842030",
    "end": "4847039"
  },
  {
    "text": "So these techniques are- are- uh, you can think of them as post-processing.",
    "start": "4850200",
    "end": "4855700"
  },
  {
    "text": "Which means you fit your model to predict the y hats what they produce, and then you take these y hats as an input to",
    "start": "4855700",
    "end": "4862900"
  },
  {
    "text": "a new model to learn some kind of an adjustment factor, to you know, adjust y hat to be you know an updated y hat and that updated y hat",
    "start": "4862900",
    "end": "4871600"
  },
  {
    "text": "will- will be you know better calibrated using these techniques. Yes question. [inaudible]",
    "start": "4871600",
    "end": "4896680"
  },
  {
    "text": "So the question is, you know, can you- can you- can you kind of consider",
    "start": "4896680",
    "end": "4902470"
  },
  {
    "text": "this slope and incorporate the slope of- of the calibration curve into the last function somehow.",
    "start": "4902470",
    "end": "4907630"
  },
  {
    "text": "Uh, so- so it so happens that the- the- calibration is",
    "start": "4907630",
    "end": "4913900"
  },
  {
    "text": "a probability of both your model and the test set against which you're measuring it. So which means if you- if you train your model against in say you know,",
    "start": "4913900",
    "end": "4923364"
  },
  {
    "text": "um, uh, an environment where it mostly is- is uh, say uh, um, um, a desert like an environment and you fit your model there and you wanna know,",
    "start": "4923365",
    "end": "4931600"
  },
  {
    "text": "use your model in a different setting where you know it's some kind of a tropical island where the weather is very different.",
    "start": "4931600",
    "end": "4937855"
  },
  {
    "text": "But you still think that your model has good discriminative ability of deciding rain versus not,",
    "start": "4937855",
    "end": "4942880"
  },
  {
    "text": "then you can take the same model that was fit on a different data and just recalibrate it to you know,",
    "start": "4942880",
    "end": "4948460"
  },
  {
    "text": "using these techniques to uh, data from you know say a tropical island um, um, uh, for example.",
    "start": "4948460",
    "end": "4954910"
  },
  {
    "text": "So you can um, um, so you may not be- you may not have access to",
    "start": "4954910",
    "end": "4960790"
  },
  {
    "text": "the eventual test set against which you wanna calibrate at the time of training. [inaudible]",
    "start": "4960790",
    "end": "4969700"
  },
  {
    "text": "Yeah. So these- these- um, these techniques generally do not reorder the points.",
    "start": "4969700",
    "end": "4974965"
  },
  {
    "text": "They just perform some kind of an adjustment such that the ordering of the predictions will still be the same but your model will be calibrated. Yes. Question.",
    "start": "4974965",
    "end": "4983650"
  },
  {
    "text": "[inaudible] So Platt scaling is linear,",
    "start": "4983650",
    "end": "4990040"
  },
  {
    "text": "isotonic regression is not linear. But they're still- they still maintain the ordering. Yes, question.",
    "start": "4990040",
    "end": "4996250"
  },
  {
    "text": "[inaudible].",
    "start": "4996250",
    "end": "5002100"
  },
  {
    "text": "Does changing the threshold value? What? Threshold of what? [inaudible].",
    "start": "5002100",
    "end": "5015269"
  },
  {
    "text": "Good question. So the question is does the threshold that we use to- for the classifier?",
    "start": "5015270",
    "end": "5022365"
  },
  {
    "text": "Does that affect calibration? The- in fact the answer is the other way, right? So for for calibration here we're",
    "start": "5022365",
    "end": "5029280"
  },
  {
    "text": "only plotting predicted probabilities versus true observed frequency. There is no threshold here anywhere, right?",
    "start": "5029280",
    "end": "5036645"
  },
  {
    "text": "Once you recalibrate your model, you will almost certainly want to choose a new threshold to-",
    "start": "5036645",
    "end": "5043170"
  },
  {
    "text": "to get a classifier out of it. Yes. Question. [inaudible]",
    "start": "5043170",
    "end": "5055800"
  },
  {
    "text": "So this is not the graph to choose thresholds. This is to to check whether the predicted probabilities can be thought of as probabilities.",
    "start": "5055800",
    "end": "5064949"
  },
  {
    "text": "[inaudible].",
    "start": "5064950",
    "end": "5071070"
  },
  {
    "text": "So we'll get into that probably tomorrow or day after when we talk about evaluation metrics about how to choose thresholds for for now we're just we're talking about- about calibration. Yes.",
    "start": "5071070",
    "end": "5079830"
  },
  {
    "text": "[inaudible]. How often is this done in practice?",
    "start": "5079830",
    "end": "5086385"
  },
  {
    "text": "Looking at a calibration plot. [inaudible] In practice extremely commonly this is done in practice.",
    "start": "5086385",
    "end": "5093840"
  },
  {
    "text": "Anywhere- anytime you wanna take, uh, you know, a- a prediction from a model and take some action based on it.",
    "start": "5093840",
    "end": "5102165"
  },
  {
    "text": "Uh, you know, uh in fact you know um, I would call this closer to practice than closer to research.",
    "start": "5102165",
    "end": "5109500"
  },
  {
    "text": "You know, you always wanna check um especially if you have- if you are constructing some kind of uh,",
    "start": "5109500",
    "end": "5114555"
  },
  {
    "text": "an application pipeline where you take decisions automatically based on the model's output,",
    "start": "5114555",
    "end": "5119895"
  },
  {
    "text": "then you wanna make sure that your model is- is well calibrated. Yes. So uh, I guess the- the reason we are doing this is",
    "start": "5119895",
    "end": "5128520"
  },
  {
    "text": "to get, to maximize accuracy [inaudible] but accuracy is not just like the comparison of the prediction?",
    "start": "5128520",
    "end": "5136500"
  },
  {
    "text": "So th- uh, the calibration is completely unrelated to accuracy and let- let me let me show you why.",
    "start": "5136500",
    "end": "5143550"
  },
  {
    "text": "Um, calibration you- you may have- you may have a perfectly- so let's see.",
    "start": "5143550",
    "end": "5150045"
  },
  {
    "text": "That's- so the question is [NOISE] calibration is it equal to accuracy?",
    "start": "5150045",
    "end": "5158535"
  },
  {
    "text": "Right? Or is there any relation between the two? If your model is very accurate should it also be calibrated?",
    "start": "5158535",
    "end": "5164850"
  },
  {
    "text": "If your model is perfectly calibrated should it also be accurate? Any guesses? So if- if your model is perfectly accurate should it be calibrated?",
    "start": "5164850",
    "end": "5172950"
  },
  {
    "text": "Any guesses? No? Okay. I heard some nos and some yeses. If your model is perfectly calibrated,",
    "start": "5172950",
    "end": "5178950"
  },
  {
    "text": "should it be perfectly accurate? [inaudible]",
    "start": "5178950",
    "end": "5187710"
  },
  {
    "text": "So- so- so- so, uh, na- now, the question is the other way. If it's perfectly calibrated, should it be accurate?",
    "start": "5187710",
    "end": "5193950"
  },
  {
    "text": "Yeah? Feels like. Feels like? Right. So the answer is no for both.",
    "start": "5193950",
    "end": "5200010"
  },
  {
    "text": "So, um, here's an example. Uh, supposing, um, you have,",
    "start": "5200010",
    "end": "5206445"
  },
  {
    "text": "you have a data set where [NOISE], um, you have an equal number of, of, you know,",
    "start": "5206445",
    "end": "5212040"
  },
  {
    "text": "positives and negatives, and let's say your model assigns- so probability of,",
    "start": "5212040",
    "end": "5218640"
  },
  {
    "text": "um, uh, correct example. Let's assume it's always, you know,",
    "start": "5218640",
    "end": "5223680"
  },
  {
    "text": "um, 0.51, you know. Just about, um, about the, the, uh, uh,",
    "start": "5223680",
    "end": "5231195"
  },
  {
    "text": "threshold of 0.5 and probability of wrong is equal to 0., you know, 01.",
    "start": "5231195",
    "end": "5239880"
  },
  {
    "text": "Now, this model is perfectly accurate. It assigns a probability of 0.5 and for all the correct examples,",
    "start": "5239880",
    "end": "5247665"
  },
  {
    "text": "and a probability of 0.01 for all the wrong examples. But if you plot the calibration plot,",
    "start": "5247665",
    "end": "5254160"
  },
  {
    "text": "it will be for all the, you know, smallest bins, it will be close to here. But for all the examples that were at point- around 0.5,",
    "start": "5254160",
    "end": "5263565"
  },
  {
    "text": "it will be here, but your calibration plot should be a straight line, right?",
    "start": "5263565",
    "end": "5268815"
  },
  {
    "text": "So in this example, the model is perfectly accurate, but it is not calibrated. What about the other way?",
    "start": "5268815",
    "end": "5276810"
  },
  {
    "text": "Let's consider, uh- again, let's consider an example where half the, half the examples are positive and half the examples are negative,",
    "start": "5276810",
    "end": "5285075"
  },
  {
    "text": "and now we want to, um- we wanna ask if a model is perfectly calibrated,",
    "start": "5285075",
    "end": "5290430"
  },
  {
    "text": "is it accurate, right? Now, again, you can think of this example where the model assigns p",
    "start": "5290430",
    "end": "5298080"
  },
  {
    "text": "of example to be equal to 0.5, for all examples.",
    "start": "5298080",
    "end": "5303630"
  },
  {
    "text": "[NOISE] This will be perfectly calibrated, right? For- when for all the perfectly- for all predictions that had a 0.5,",
    "start": "5303630",
    "end": "5311624"
  },
  {
    "text": "the true frequency will be close to 0.5. Such a model will be perfectly calibrated but will have",
    "start": "5311624",
    "end": "5318210"
  },
  {
    "text": "zero accuracy because it's assigning the same probability to all examples. So calibration and accuracy are,",
    "start": "5318210",
    "end": "5323565"
  },
  {
    "text": "are kind of, you know, distinct concepts. They're not, they're not necessarily related to each other. Yes?",
    "start": "5323565",
    "end": "5329250"
  },
  {
    "text": "[inaudible]",
    "start": "5329250",
    "end": "5339920"
  },
  {
    "text": "Yeah. So this alone will not tell you whether your model is accurate or not, but this should be something that you look at, right?",
    "start": "5339920",
    "end": "5347520"
  },
  {
    "text": "So generally, uh, a common thing to do is look at the calibration plot in relation to the histogram of probabilities.",
    "start": "5347520",
    "end": "5356470"
  },
  {
    "text": "Okay. So take the set of all y hats and just look at the histogram of how your model assigns probabilities, right?",
    "start": "5357500",
    "end": "5364770"
  },
  {
    "text": "If your model is well calibrated and your histogram of probabilities look like this,",
    "start": "5364770",
    "end": "5372030"
  },
  {
    "text": "[NOISE] then you're in good shape, right?",
    "start": "5372030",
    "end": "5378420"
  },
  {
    "text": "So the model is, is, uh, you, you, you call such models where you have,",
    "start": "5378420",
    "end": "5389385"
  },
  {
    "text": "you know, a peak to the left and peak to the right as, uh, a model that is discriminating. Well, you know, it's, it's, it's,",
    "start": "5389385",
    "end": "5395145"
  },
  {
    "text": "it's kind of sharpened its predictions. Its predictions are confident. It, it either produces, uh, you know,",
    "start": "5395145",
    "end": "5400860"
  },
  {
    "text": "a very low probability or a very high probability, and if it is calibrated, then you, you have a good model, right?",
    "start": "5400860",
    "end": "5408000"
  },
  {
    "text": "If your, uh- if your histogram of predicted probabilities look like this,",
    "start": "5408000",
    "end": "5417390"
  },
  {
    "text": "then, you know, your model is not very confident all the time, and if it is not very confident and, you know,",
    "start": "5417390",
    "end": "5425265"
  },
  {
    "text": "then you don't have good discrimination power, but it may still be, still be calibrated, right?",
    "start": "5425265",
    "end": "5430949"
  },
  {
    "text": "So in, in, in practice, you wanna to look, you know, uh, look at both of them simultaneously.",
    "start": "5430950",
    "end": "5436200"
  },
  {
    "text": "[inaudible]. We'll come to ROCs, uh, probably tomorrow or on Friday.",
    "start": "5436200",
    "end": "5443230"
  },
  {
    "text": "All right. So calibration. So now the question is, um, is there, is there,",
    "start": "5443930",
    "end": "5451800"
  },
  {
    "text": "is there an- how is this related to, um, um, you know, maximum entropy that we talked about, right?",
    "start": "5451800",
    "end": "5457380"
  },
  {
    "text": "So as, as we talked- uh, uh, mentioned earlier, the maximum entropy principle tells us that, um,",
    "start": "5457380",
    "end": "5463659"
  },
  {
    "text": "the choice of the probability distribution that we estimate should be as uncertain as possible,",
    "start": "5463660",
    "end": "5469850"
  },
  {
    "text": "subject to some constraints that we have, and that will naturally lead to probability estimates that are well-calibrated.",
    "start": "5469850",
    "end": "5479535"
  },
  {
    "text": "Why is that? Let's see. So, um,",
    "start": "5479535",
    "end": "5484510"
  },
  {
    "text": "so maximum entropy, we saw earlier leads to maximum likelihood, right?",
    "start": "5493010",
    "end": "5503519"
  },
  {
    "text": "So the maximum entropy implied maximum likelihood,",
    "start": "5503520",
    "end": "5509625"
  },
  {
    "text": "and in maximum likelihood, what we, the, uh, objective, uh, of, of interest is this, right?",
    "start": "5509625",
    "end": "5516480"
  },
  {
    "text": "So, um, [NOISE] MLE, we did- [NOISE] right.",
    "start": "5516480",
    "end": "5526920"
  },
  {
    "text": "So if x is the, is the, um, is the predicted probability,",
    "start": "5526920",
    "end": "5532500"
  },
  {
    "text": "then what we do is, uh, we use log p of x or the negative log p of x as the loss, [NOISE] right?",
    "start": "5532500",
    "end": "5542130"
  },
  {
    "text": "So, you know, loss with respect to theta, right? We use this as the loss.",
    "start": "5542130",
    "end": "5547800"
  },
  {
    "text": "Now, to understand the ro- the, the connection between calibration and MLE or maximum entropy,",
    "start": "5547800",
    "end": "5555420"
  },
  {
    "text": "we want to rethink the, the notion of loss function a little bit slightly, right?",
    "start": "5555420",
    "end": "5561285"
  },
  {
    "text": "Generally, we think of loss function as a function between y and y hat where y is the,",
    "start": "5561285",
    "end": "5570870"
  },
  {
    "text": "is the observed or the ground truth of the correct answer and y hat is our prediction, right?",
    "start": "5570870",
    "end": "5576735"
  },
  {
    "text": "However, to kind of get a better understanding of, of, um, calibration, you wanna instead think of this scoring rule.",
    "start": "5576735",
    "end": "5585300"
  },
  {
    "text": "[NOISE] So scoring rule that takes two inputs,",
    "start": "5585300",
    "end": "5593380"
  },
  {
    "text": "a probability, uh, uh, function p hat and y.",
    "start": "5593870",
    "end": "5600900"
  },
  {
    "text": "So y is still the true observed, um, um, observed, uh, outcome and p hat is our predicted probability distribution.",
    "start": "5600900",
    "end": "5612315"
  },
  {
    "text": "Okay. P hat is not a point estimate but it's a predicted probability distribution.",
    "start": "5612315",
    "end": "5619005"
  },
  {
    "text": "It so happens that in logistic regression, the single-point estimate probability defines the full probability distribution.",
    "start": "5619005",
    "end": "5628604"
  },
  {
    "text": "But in general, um, you know, um, if, if, if, if you are, for example,",
    "start": "5628604",
    "end": "5634170"
  },
  {
    "text": "in a regression setting, think of this to be a full Gaussian distribution, like the mean and variance of a full Gaussian distribution, for example, right?",
    "start": "5634170",
    "end": "5642405"
  },
  {
    "text": "So this is a probability distribution",
    "start": "5642405",
    "end": "5651105"
  },
  {
    "text": "over all possible outcomes, right?",
    "start": "5651105",
    "end": "5660720"
  },
  {
    "text": "And this is the,",
    "start": "5660720",
    "end": "5667200"
  },
  {
    "text": "the actual observed outcome, [NOISE] right?",
    "start": "5667200",
    "end": "5671590"
  },
  {
    "text": "So our model will output p-hat, a full probability distribution over all possible outcomes.",
    "start": "5678770",
    "end": "5685200"
  },
  {
    "text": "So if- if we- if we are in some kind of, uh, uh, in a- in a- in a weather forecasting setting,",
    "start": "5685200",
    "end": "5690360"
  },
  {
    "text": "for example, this will, uh, give a probability of- and let's say we are trying to- to,",
    "start": "5690360",
    "end": "5697110"
  },
  {
    "text": "uh, measure, say, wind speed of tomorrow, for example, then this will give you",
    "start": "5697110",
    "end": "5703230"
  },
  {
    "text": "a- a- a probability distribution that it's going to be- have a 5% probability that the wind will be,",
    "start": "5703230",
    "end": "5710520"
  },
  {
    "text": "you know, 10 miles per hour, 7% probability that the wind speed will be, you know, 15 miles per hour, and so on.",
    "start": "5710520",
    "end": "5716460"
  },
  {
    "text": "It's gonna give you a full probability distribution over the entire outcome space, right? In case of a binary decision of whether it's going to rain tomorrow or not,",
    "start": "5716460",
    "end": "5726660"
  },
  {
    "text": "if the outcomes are only two, if all what you care is, will it rain or not rain? You don't care how much it rains.",
    "start": "5726660",
    "end": "5732435"
  },
  {
    "text": "If that's the space of outcomes, then the outcome is, you know- you know,",
    "start": "5732435",
    "end": "5737610"
  },
  {
    "text": "30% that it will rain, and therefore, 70% that it will not rain, or 50% that it will rain,",
    "start": "5737610",
    "end": "5744119"
  },
  {
    "text": "and therefore, 50% it will not rain. So it's the- it's the full probability distribution over the space of outcomes.",
    "start": "5744120",
    "end": "5749830"
  },
  {
    "text": "Can we assume Bayesian setting? We're not assuming the Bayesian setting. All we- that we have is,",
    "start": "5749830",
    "end": "5755310"
  },
  {
    "text": "the sum predicted probability distribution and one observed outcome, right? And- and the next day we'll again output",
    "start": "5755310",
    "end": "5761700"
  },
  {
    "text": "a full probability distribution and there will be some one observed outcome. In classical setting we always have Frequentist distribution.",
    "start": "5761700",
    "end": "5766739"
  },
  {
    "text": "Uh, the- the- uh, the difference",
    "start": "5766740",
    "end": "5772620"
  },
  {
    "text": "between Bayesian and- and Frequentist is how we treat the parameters. Here this is just, you know, predictions, right?",
    "start": "5772620",
    "end": "5779789"
  },
  {
    "text": "Um, yeah, this- this is- this is not Bayesian versus, uh, Frequentist. This is, uh, uh, this is more, uh, general.",
    "start": "5779790",
    "end": "5786150"
  },
  {
    "text": "So now, uh, we- we have this notion of what is called as,",
    "start": "5786150",
    "end": "5792780"
  },
  {
    "text": "uh, a proper scoring rule.",
    "start": "5792780",
    "end": "5795639"
  },
  {
    "text": "A proper scoring rule is one that satisfies this requirement.",
    "start": "5798020",
    "end": "5804360"
  },
  {
    "text": "So let's call a proper scoring rule, let's call it f. So f is a proper scoring rule if it satisfies,",
    "start": "5804360",
    "end": "5815500"
  },
  {
    "text": "so, uh, proper scoring rule f, where [NOISE] f takes",
    "start": "5815810",
    "end": "5822555"
  },
  {
    "text": "a probability distribution and outcome and maps it to a real value, right?",
    "start": "5822555",
    "end": "5829020"
  },
  {
    "text": "A scoring rule is one that takes the observation made by a forecaster and then observe the actual outcome,",
    "start": "5829020",
    "end": "5836910"
  },
  {
    "text": "looks at those two and assigns a score of how well the forecaster did, right? You wanna think of, uh, the scoring rule that way.",
    "start": "5836910",
    "end": "5843530"
  },
  {
    "text": "So it takes a prediction, a full probability distribution, one observed outcome, and assigns a score, right?",
    "start": "5843530",
    "end": "5851310"
  },
  {
    "text": "And the- uh, a proper scoring rule is one that satisfies,",
    "start": "5851310",
    "end": "5856630"
  },
  {
    "text": "uh, q, uh, [NOISE]",
    "start": "5857690",
    "end": "5900449"
  },
  {
    "text": "so a proper scoring rule, f, is that scoring rule which satisfies this inequality that the expectation of f of q, y,",
    "start": "5900450",
    "end": "5911745"
  },
  {
    "text": "where y is sampled according to q, is less than equal to expectation of f of p,",
    "start": "5911745",
    "end": "5919065"
  },
  {
    "text": "y, y sample to q for all p and q. And you call it a strictly proper scoring rule-",
    "start": "5919065",
    "end": "5927494"
  },
  {
    "text": "strictly proper scoring rule.",
    "start": "5927495",
    "end": "5934695"
  },
  {
    "text": "Where equality implies p equals q, right?",
    "start": "5934695",
    "end": "5944485"
  },
  {
    "text": "What does- what does this mean? So let's- let's- let's, uh, try to- to, uh, uh, understand this a little better.",
    "start": "5944485",
    "end": "5950630"
  },
  {
    "text": "So we have- we have, you know, two- two, uh, you know, two instances of the, uh,",
    "start": "5950630",
    "end": "5956885"
  },
  {
    "text": "scoring rule being, uh, uh, called. [NOISE] The scoring rule,",
    "start": "5956885",
    "end": "5962925"
  },
  {
    "text": "as I said, takes a prediction and an actual outcome, right? Prediction and an actual outcome.",
    "start": "5962925",
    "end": "5969615"
  },
  {
    "text": "F is a proper scoring rule. If when the actual outcomes",
    "start": "5969615",
    "end": "5976110"
  },
  {
    "text": "follow a distribution q- actual outcomes follow some distribution q, the average score assigned by f for a- a prediction q itself,",
    "start": "5976110",
    "end": "5988880"
  },
  {
    "text": "where q was how the actual y's were distributed, will be less than the average score assigned by f,",
    "start": "5988880",
    "end": "5997695"
  },
  {
    "text": "where the prediction was a different, uh, uh, distribution p than how y was actually distributed, right?",
    "start": "5997695",
    "end": "6006500"
  },
  {
    "text": "Now, if f is used as a loss function for your model, and f is a proper scoring rule,",
    "start": "6006500",
    "end": "6013460"
  },
  {
    "text": "then your models will tend to be well-calibrated. Why is that? That's because the- the- uh,",
    "start": "6013460",
    "end": "6021050"
  },
  {
    "text": "the- the proper scoring- the proper scoring rule naturally rewards q",
    "start": "6021050",
    "end": "6029165"
  },
  {
    "text": "to have the best possible score when q was the distribution according to which y's we're getting absorbed from, right?",
    "start": "6029165",
    "end": "6037505"
  },
  {
    "text": "So y- y till the q here, and- and- and- y till the q, you wanna think of this as, you know,",
    "start": "6037505",
    "end": "6044435"
  },
  {
    "text": "q being the way the weather is actually modeled, and y's are therefore sampled according to the way the weather is actually,",
    "start": "6044435",
    "end": "6052370"
  },
  {
    "text": "um, um, happening in- in real life. And the- the probability distribution that's passed to",
    "start": "6052370",
    "end": "6058100"
  },
  {
    "text": "f is the prediction that we're making, right? The best possible prediction is when we predict the true,",
    "start": "6058100",
    "end": "6067610"
  },
  {
    "text": "uh, weather itself, uh, as our prediction, right? For any other prediction,",
    "start": "6067610",
    "end": "6072740"
  },
  {
    "text": "which is not the actual weather, uh, um, uh, you know, the actual weather, then, uh,",
    "start": "6072740",
    "end": "6078469"
  },
  {
    "text": "it will get a worse score according to the problem- according to this scoring rule. If this satisfies for all p and q,",
    "start": "6078470",
    "end": "6085040"
  },
  {
    "text": "then f is a proper scoring rule. Next question? Uh, can you explain why the- any other resolution have a greater respective value?",
    "start": "6085040",
    "end": "6091880"
  },
  {
    "text": "[OVERLAPPING] So- so- so- so here- here you can think of this as loss,",
    "start": "6091880",
    "end": "6097085"
  },
  {
    "text": "a higher loss is worse. So we want f to assign, you know,",
    "start": "6097085",
    "end": "6102215"
  },
  {
    "text": "low values for better predictions, right? Why can't we start with the calculation? Yeah- yeah, I'm- I'm going to come to that, right?",
    "start": "6102215",
    "end": "6108365"
  },
  {
    "text": "Right? So this is a proper scoring rule, right? Now, from this, you know, you- you- you know,",
    "start": "6108365",
    "end": "6116434"
  },
  {
    "text": "it's- it's- uh, it's easy to see that if we recover,",
    "start": "6116435",
    "end": "6121580"
  },
  {
    "text": "you know, um, if we recover the best possible prediction, then our model is naturally calibrated because the best possible prediction",
    "start": "6121580",
    "end": "6129559"
  },
  {
    "text": "is q itself, right? So the best possible, uh,",
    "start": "6129560",
    "end": "6134570"
  },
  {
    "text": "prediction that we can do is to predict q, because, you know, that is the lowest, uh, loss that can be attained.",
    "start": "6134570",
    "end": "6140570"
  },
  {
    "text": "And so, you know, uh, using proper scoring rules as our loss functions will encourage our models to be better calibrated.",
    "start": "6140570",
    "end": "6150980"
  },
  {
    "text": "Does that make sense? Any other- any other- other- other- uh, uh,",
    "start": "6150980",
    "end": "6157850"
  },
  {
    "text": "uh, any other p other than q will attain a low- a- a worse loss compared to predicting q itself.",
    "start": "6157850",
    "end": "6165890"
  },
  {
    "text": "And when you compare- you know, uh, when you predict q itself, your calibration curve will be a straight line.",
    "start": "6165890",
    "end": "6172940"
  },
  {
    "text": "Because, um, um, depending on, um, you know, if- if- uh,",
    "start": "6172940",
    "end": "6178864"
  },
  {
    "text": "if y is our sample from q such that it is 80%- you know, 80%, then, um,",
    "start": "6178865",
    "end": "6186350"
  },
  {
    "text": "we want to predict 80%, uh, and- and that would be the- the- um, um, because that's- that's the best thing to do according to the scoring rule.",
    "start": "6186350",
    "end": "6195960"
  },
  {
    "text": "Does that make sense? Yes, question? Now I do understand why well calibrated model doesn't mean it accurate,",
    "start": "6196260",
    "end": "6201385"
  },
  {
    "text": "because from this it seems like you're getting at the distribution at which y is being distributed-",
    "start": "6201385",
    "end": "6206424"
  },
  {
    "text": "Yeah. - by [NOISE] well calibrated model, which implies accuracy. This does not necessarily imply accuracy.",
    "start": "6206424",
    "end": "6214460"
  },
  {
    "text": "So- so the question is; does this imply accuracy? It need not because what we're looking for is,",
    "start": "6214460",
    "end": "6221525"
  },
  {
    "text": "you know, the average scores in long-term. So- so supposing it rains 50% on average, right?",
    "start": "6221525",
    "end": "6229055"
  },
  {
    "text": "Your predictions may be such that half the time you predicted it will rain but half the time you will",
    "start": "6229055",
    "end": "6235760"
  },
  {
    "text": "predict it will not rain and in the long running average, you know, you may match the frequencies but on every given day you maybe end up predicting the wrong thing, right?",
    "start": "6235760",
    "end": "6243020"
  },
  {
    "text": "So this is not related to accuracy. So a proper scoring rule will encourage your- your uh- your model to have the long run,",
    "start": "6243020",
    "end": "6254045"
  },
  {
    "text": "um, um, long run frequency match the predicted frequency or the predicted probability.",
    "start": "6254045",
    "end": "6262340"
  },
  {
    "text": "And now the question is um,",
    "start": "6262340",
    "end": "6267679"
  },
  {
    "text": "and now the question is, how is related to maximum entropy? So first, first- first do we- do we have- do we have a consensus on this,",
    "start": "6267680",
    "end": "6274520"
  },
  {
    "text": "that if we employ a proper scoring rule because of this property of- of proper scoring rules,",
    "start": "6274520",
    "end": "6280295"
  },
  {
    "text": "the predicted probabilities will tend to be calibrated or is there a question on that? Yes, question.",
    "start": "6280295",
    "end": "6285320"
  },
  {
    "text": "[inaudible]",
    "start": "6285320",
    "end": "6295489"
  },
  {
    "text": "then also it will have a better estimate with the predicted [inaudible]. Why not use [inaudible] because it follows the same inequalities.",
    "start": "6295490",
    "end": "6304040"
  },
  {
    "text": "I'm sorry, I- I- I didn't understand the question. So [inaudible] even in that case,",
    "start": "6304040",
    "end": "6316490"
  },
  {
    "text": "our inequality wasn't the same. The loss would be less than our given loss.",
    "start": "6316490",
    "end": "6321770"
  },
  {
    "text": "What do you mean by y-hat? I- You wrote about scoring loss on the left side.",
    "start": "6321770",
    "end": "6329015"
  },
  {
    "text": "On the left side? Yeah. Yeah. So you have this function, right? Yeah. If you directly use this loss function whereby loss [inaudible] theta transpose x,",
    "start": "6329015",
    "end": "6341840"
  },
  {
    "text": "you have the same inequality like that where- Well, it may or may not, right? So- so the question is,",
    "start": "6341840",
    "end": "6347079"
  },
  {
    "text": "if- if you use a loss value like this where y hat was just Theta transpose x,",
    "start": "6347080",
    "end": "6352285"
  },
  {
    "text": "uh, will we get the same inequality? So in case of logistic regression,",
    "start": "6352285",
    "end": "6357349"
  },
  {
    "text": "y hat completely determine the entire distribution. But in case of regression, that's not the case.",
    "start": "6357350",
    "end": "6363095"
  },
  {
    "text": "If you're just have a point estimate, it's not a distribution over all the possible y's, right?",
    "start": "6363095",
    "end": "6369560"
  },
  {
    "text": "So in case of logistic regression, y hat, or- or the point estimate of the probability is the full distribution, right?",
    "start": "6369560",
    "end": "6376880"
  },
  {
    "text": "But it's- that's not the case in more general settings like regression. So now the question is, um,",
    "start": "6376880",
    "end": "6384695"
  },
  {
    "text": "so assuming that we have a consensus that employing a proper scoring rule encourages",
    "start": "6384695",
    "end": "6391385"
  },
  {
    "text": "our model- encourages us to recover the true probability distribution,",
    "start": "6391385",
    "end": "6398344"
  },
  {
    "text": "in which case the models will tend to be calibrated. Now the question is, how is this related to maximum entropy?",
    "start": "6398345",
    "end": "6404614"
  },
  {
    "text": "So in maximum entropy, uh, we saw that maximum entropy gives rise to MLE.",
    "start": "6404615",
    "end": "6412340"
  },
  {
    "text": "And MLE is essentially this, MLE- the loss is y coming from",
    "start": "6412340",
    "end": "6423094"
  },
  {
    "text": "Q and",
    "start": "6423095",
    "end": "6430430"
  },
  {
    "text": "minus log 1/p,",
    "start": "6430430",
    "end": "6441500"
  },
  {
    "text": "right? So this is the, um, you know, um, so this is the,",
    "start": "6441500",
    "end": "6448489"
  },
  {
    "text": "uh, the loss are- let's think of this as like the true loss.",
    "start": "6448490",
    "end": "6455735"
  },
  {
    "text": "So this is the true loss of, uh, maximum likelihood,",
    "start": "6455735",
    "end": "6460835"
  },
  {
    "text": "where y is distributed according to some, you know, data-generating distribution, and the loss that we have is the negative log likelihood.",
    "start": "6460835",
    "end": "6468905"
  },
  {
    "text": "Oh, sorry, this should be log p hat.",
    "start": "6468905",
    "end": "6472590"
  },
  {
    "text": "So the model predicts p hat, but the data is distributed according to y,",
    "start": "6474090",
    "end": "6480054"
  },
  {
    "text": "the loss is the negative log-likelihood under the expectation where y hat is- is distributed according to q.",
    "start": "6480055",
    "end": "6490835"
  },
  {
    "text": "Now, what remains to be shown is this is a proper scoring rule.",
    "start": "6490835",
    "end": "6499325"
  },
  {
    "text": "Okay? So le- minus log",
    "start": "6499325",
    "end": "6510215"
  },
  {
    "text": "P hat of y, sorry. Okay? So y is- are- are the 0s and 1s.",
    "start": "6510215",
    "end": "6516290"
  },
  {
    "text": "They are sampled according to q and p hat is- is log p hat of y. So p hat is the, uh, uh,",
    "start": "6516290",
    "end": "6522679"
  },
  {
    "text": "generated, uh, uh, is the predicted probability. And we want to evaluate y according to this.",
    "start": "6522680",
    "end": "6528335"
  },
  {
    "text": "So what remains to be shown as this is proper scoring rule.",
    "start": "6528335",
    "end": "6533690"
  },
  {
    "text": "And the way we showed this as a proper scoring rule is pretty simple.",
    "start": "6533690",
    "end": "6539219"
  },
  {
    "text": "We wanna show this inequality, right? So expectation of y according to q minus log q of y should be less than or equal to",
    "start": "6539260",
    "end": "6552770"
  },
  {
    "text": "expectation of y according to q of minus log p of y, right?",
    "start": "6552770",
    "end": "6563120"
  },
  {
    "text": "And we take this to the right-hand side, and this,",
    "start": "6563120",
    "end": "6571730"
  },
  {
    "text": "we get 0 or we take- we want to show this is less than this.",
    "start": "6571730",
    "end": "6582980"
  },
  {
    "text": "Yeah, so we take, uh, is greater than equal to zero.",
    "start": "6582980",
    "end": "6588710"
  },
  {
    "text": "Yeah, so we, uh, take this to the right-hand side and we get is equal to expectation y according to",
    "start": "6588710",
    "end": "6597380"
  },
  {
    "text": "q log- so this is minus log.",
    "start": "6597380",
    "end": "6604909"
  },
  {
    "text": "So this, when it comes here, it will be a plus log. You get log q of y over b,",
    "start": "6604910",
    "end": "6611974"
  },
  {
    "text": "and this is negative, so this is 1/p or p, y. So we need to show this.",
    "start": "6611975",
    "end": "6617600"
  },
  {
    "text": "And this can be easily shown because this is just a KL divergence between q and p, and that's always non-negative, right?",
    "start": "6617600",
    "end": "6623610"
  },
  {
    "text": "So the maximum entropy principle",
    "start": "6624400",
    "end": "6630905"
  },
  {
    "text": "is equivalent to maximum likelihood estimate- estimation, and the maximum likelihood estimation uses",
    "start": "6630905",
    "end": "6638840"
  },
  {
    "text": "negative log as the proper scoring rule- as the, as the loss function. And this loss function due to KL divergence being non-negative,",
    "start": "6638840",
    "end": "6648005"
  },
  {
    "text": "implies that it's a proper scoring rule. And because it's a proper scoring rule,",
    "start": "6648005",
    "end": "6653060"
  },
  {
    "text": "the estimated probabilities will tend to be well calibrated. So that, that's like the multi-step connection between",
    "start": "6653060",
    "end": "6660560"
  },
  {
    "text": "maximum entropy and calibration, right? So maximizing entropy is therefore, uh,",
    "start": "6660560",
    "end": "6669965"
  },
  {
    "text": "therefore leads to your model being well-calibrated. Yes, question.",
    "start": "6669965",
    "end": "6676520"
  },
  {
    "text": "[inaudible].",
    "start": "6676520",
    "end": "6682100"
  },
  {
    "text": "So this is the loss function that you've been using for logistic regression. This is the same thing that you've been using for logistic regression. It's no different.",
    "start": "6682100",
    "end": "6689090"
  },
  {
    "text": "[inaudible]",
    "start": "6689090",
    "end": "6697580"
  },
  {
    "text": "Yes, this is the cross-entropy loss and that is the same as the maximum likelihood estimation. It's the same loss. You can,",
    "start": "6697580",
    "end": "6702920"
  },
  {
    "text": "you can work out the math there. They're exactly the same, right? There are other kinds of entropy measures that you can use.",
    "start": "6702920",
    "end": "6709565"
  },
  {
    "text": "So here we used, you know, for maximum entropy, we use the Shannon's entropy,",
    "start": "6709565",
    "end": "6714590"
  },
  {
    "text": "that's p log p. There are different kinds of entropies that are,",
    "start": "6714590",
    "end": "6720935"
  },
  {
    "text": "uh, uh, that are there, not just Shannon's entropy. And by using a different kind of an entropy,",
    "start": "6720935",
    "end": "6727969"
  },
  {
    "text": "you get different kinds of a divergence rather than KL divergence and you get a different loss function.",
    "start": "6727970",
    "end": "6733880"
  },
  {
    "text": "And all those will still be, um, will lead to calibration models as long as",
    "start": "6733880",
    "end": "6740630"
  },
  {
    "text": "the scoring rule that you get is a proper scoring rule. That's, that's the general- general takeaway in this, right?",
    "start": "6740630",
    "end": "6748210"
  },
  {
    "text": "So we're out of time and we'll start with the EM variants and,",
    "start": "6748210",
    "end": "6753625"
  },
  {
    "text": "and the variational auto-encoder in the next class. Thanks.",
    "start": "6753625",
    "end": "6758450"
  }
]